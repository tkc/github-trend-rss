<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Sun, 01 Mar 2026 00:06:32 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[moeru-ai/airi]]></title>
            <link>https://github.com/moeru-ai/airi</link>
            <guid>https://github.com/moeru-ai/airi</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:32 GMT</pubDate>
            <description><![CDATA[üíñüß∏ Self hosted, you-owned Grok Companion, a container of souls of waifu, cyber livings to bring them into our worlds, wishing to achieve Neuro-sama's altitude. Capable of realtime voice chat, Minecraft, Factorio playing. Web / macOS / Windows supported.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/moeru-ai/airi">moeru-ai/airi</a></h1>
            <p>üíñüß∏ Self hosted, you-owned Grok Companion, a container of souls of waifu, cyber livings to bring them into our worlds, wishing to achieve Neuro-sama's altitude. Capable of realtime voice chat, Minecraft, Factorio playing. Web / macOS / Windows supported.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 19,323</p>
            <p>Forks: 1,845</p>
            <p>Stars today: 1,065 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
  &lt;source
    width=&quot;100%&quot;
    srcset=&quot;./docs/content/public/banner-dark-1280x640.avif&quot;
    media=&quot;(prefers-color-scheme: dark)&quot;
  /&gt;
  &lt;source
    width=&quot;100%&quot;
    srcset=&quot;./docs/content/public/banner-light-1280x640.avif&quot;
    media=&quot;(prefers-color-scheme: light), (prefers-color-scheme: no-preference)&quot;
  /&gt;
  &lt;img width=&quot;250&quot; src=&quot;./docs/content/public/banner-light-1280x640.avif&quot; /&gt;
&lt;/picture&gt;

&lt;h1 align=&quot;center&quot;&gt;Project AIRI&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;Re-creating Neuro-sama, a soul container of AI waifu / virtual characters to bring them into our world.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  [&lt;a href=&quot;https://discord.gg/TgQ3Cu2F7A&quot;&gt;Join Discord Server&lt;/a&gt;] [&lt;a href=&quot;https://airi.moeru.ai&quot;&gt;Try it&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.zh-CN.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.ja-JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.ru-RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.vi.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.fr.md&quot;&gt;Fran√ßais&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.ko-KR.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;]
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://deepwiki.com/moeru-ai/airi&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/moeru-ai/airi.svg?style=flat&amp;colorA=080f12&amp;colorB=1fa669&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/TgQ3Cu2F7A&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2FTgQ3Cu2F7A%3Fwith_counts%3Dtrue&amp;query=%24.approximate_member_count&amp;suffix=%20members&amp;logo=discord&amp;logoColor=white&amp;label=%20&amp;color=7389D8&amp;labelColor=6A7EC2&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/proj_airi&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%40proj__airi-black?style=flat&amp;logo=x&amp;labelColor=%23101419&amp;color=%232d2e30&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://t.me/+7M_ZKO3zUHFlOThh&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Telegram-%235AA9E6?logo=telegram&amp;labelColor=FFFFFF&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/wechat.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/WeChat-%2307C160?logo=wechat&amp;logoColor=%2307C160&amp;labelColor=FFFFFF&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://qun.qq.com/universal-share/share?ac=1&amp;authKey=9g00d%2BZS7nORzcJugNNddJ7rCghZTIR7fhXabGwch2S%2BG%2BKGIKwlN1N2nIqkh2jg&amp;busi_data=eyJncm91cENvZGUiOiIxMDU4MTU2Njk3IiwidG9rZW4iOiJmcnkra1hWNFIxNytEcG0zcHRUdVJIaldlRDFxN0dzK080QWtvTEdOQjJkNEY2eUFta1g1clNpbkxSMS9FQWFYIiwidWluIjoiMTI2MDkwNzMzNSJ9&amp;data=b1eJrwn3GVOUh7YIxZ7l9vHQo99HPmRxKPpMKlDCmfzx8Y57IXb2EZCMaOC9rVTd2U558qpNjwUYUWlPHxVHvg&amp;svctype=4&amp;tempid=h5_group_info&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/QQ-%2312B7F5?logo=qq&amp;labelColor=FFFFFF&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.producthunt.com/products/airi?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_source=badge-airi&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=993524&amp;theme=neutral&amp;t=1752696535380&quot; alt=&quot;AIRI - A&amp;#0032;container&amp;#0032;of&amp;#0032;cyber&amp;#0032;living&amp;#0032;souls&amp;#0044;&amp;#0032;re&amp;#0045;creation&amp;#0032;of&amp;#0032;Neuro&amp;#0045;sama | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/14636&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14636&quot; alt=&quot;moeru-ai%2Fairi | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; Heavily inspired by [Neuro-sama](https://www.youtube.com/@Neurosama)

&gt; [!WARNING]
&gt; **Attention:** We **do not** have any officially minted cryptocurrency or token associated with this project. Please check the information and proceed with caution.

&gt; [!NOTE]
&gt;
&gt; We&#039;ve got a whole dedicated organization [@proj-airi](https://github.com/proj-airi) for all the sub-projects born from Project AIRI. Check it out!
&gt;
&gt; RAG, memory system, embedded database, icons, Live2D utilities, and more!

&gt; [!TIP]
&gt; We have a translation project on [Crowdin](https://crowdin.com/project/proj-airi). If you find any inaccurate translations, feel free to contribute improvements there.
&gt; &lt;a href=&quot;https://crowdin.com/project/proj-airi&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img style=&quot;width: 140px; height: 40px;&quot; src=&quot;https://badges.crowdin.net/badge/light/crowdin-on-dark.png&quot; srcset=&quot;https://badges.crowdin.net/badge/light/crowdin-on-dark.png 1x, https://badges.crowdin.net/badge/light/crowdin-on-dark@2x.png 2x&quot; alt=&quot;Crowdin | Agile localization for tech companies&quot; width=&quot;140&quot; height=&quot;40&quot; /&gt;&lt;/a&gt;

Have you dreamed about having a cyber living being (cyber waifu, digital pet) or digital companion that could play with and talk to you?

With the power of modern large language models like [ChatGPT](https://chatgpt.com) and famous [Claude](https://claude.ai), asking a virtual being to roleplay and chat with us is already easy enough for everyone. Platforms like [Character.ai (a.k.a. c.ai)](https://character.ai) and [JanitorAI](https://janitorai.com/) as well as local playgrounds like [SillyTavern](https://github.com/SillyTavern/SillyTavern) are already good-enough solutions for a chat based or visual adventure game like experience.

&gt; But, what about the abilities to play games? And see what you are coding at? Chatting while playing games, watching videos, and is capable of doing many other things.

Perhaps you know [Neuro-sama](https://www.youtube.com/@Neurosama) already. She is currently the best virtual streamer capable of playing games, chatting, and interacting with you and the participants. Some also call this kind of being &quot;digital human.&quot; **Sadly, as it&#039;s not open sourced, you cannot interact with her after her live streams go offline**.

Therefore, this project, AIRI, offers another possibility here: **let you own your digital life, cyber living, easily, anywhere, anytime**.

## DevLogs We Posted &amp; Recent Updates

- [DevLog @ 2026.01.01](https://airi.moeru.ai/docs/en/blog/DevLog-2026.01.01/) on January 1, 2026
- [DevLog @ 2025.10.20](https://airi.moeru.ai/docs/en/blog/DevLog-2025.10.20/) on October 20, 2025
- [DevLog @ 2025.08.05](https://airi.moeru.ai/docs/en/blog/DevLog-2025.08.05/) on August 5, 2025
- [DevLog @ 2025.08.01](https://airi.moeru.ai/docs/en/blog/DevLog-2025.08.01/) on August 1, 2025
- [DevLog @ 2025.07.18](https://airi.moeru.ai/docs/en/blog/DevLog-2025.07.18/) on July 18, 2025
- [DreamLog 0x1](https://airi.moeru.ai/docs/en/blog/dreamlog-0x1/) on June 16, 2025
- ...more on [documentation site](https://airi.moeru.ai/docs/en/)

## What&#039;s So Special About This Project?

Unlike the other AI driven VTuber open source projects, „Ç¢„Ç§„É™ was built with support of many Web technologies such as [WebGPU](https://www.w3.org/TR/webgpu/), [WebAudio](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API), [Web Workers](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers), [WebAssembly](https://webassembly.org/), [WebSocket](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket), etc. from the first day.

&gt; [!TIP]
&gt; Worrying about the performance drop since we are using Web related technologies?
&gt;
&gt; Don&#039;t worry, while Web browser version is meant to give an insight about how much we can push and do inside browsers, and webviews, we will never fully rely on this, the desktop version of AIRI is capable of using native [NVIDIA CUDA](https://developer.nvidia.com/cuda-toolkit) and [Apple Metal](https://developer.apple.com/metal/) by default (thanks to HuggingFace &amp; beloved [candle](https://github.com/huggingface/candle) project), without any complex dependency managements, considering the tradeoff, it was partially powered by Web technologies for graphics, layouts, animations, and the WIP plugin systems for everyone to integrate things.

This means that **„Ç¢„Ç§„É™ is capable of running on modern browsers and devices** and even on mobile devices (already done with PWA support). This brings a lot of possibilities for us (the developers) to build and extend the power of „Ç¢„Ç§„É™ VTuber to the next level, while still leaving the flexibilities for users to enable features that requires TCP connections or other non-Web technologies such as connecting to a Discord voice channel or playing Minecraft and Factorio with friends.

&gt; [!NOTE]
&gt;
&gt; We are still in the early stage of development where we are seeking out talented developers to join us and help us to make „Ç¢„Ç§„É™ a reality.
&gt;
&gt; It&#039;s ok if you are not familiar with Vue.js, TypeScript, and devtools required for this project, you can join us as an artist, designer, or even help us to launch our first live stream.
&gt;
&gt; Even if you are a big fan of React, Svelte or even Solid, we welcome you. You can open a sub-directory to add features that you want to see in „Ç¢„Ç§„É™, or would like to experiment with.
&gt;
&gt; Fields (and related projects) that we are looking for:
&gt;
&gt; - Live2D modeller
&gt; - VRM modeller
&gt; - VRChat avatar designer
&gt; - Computer Vision
&gt; - Reinforcement Learning
&gt; - Speech Recognition
&gt; - Speech Synthesis
&gt; - ONNX Runtime
&gt; - Transformers.js
&gt; - vLLM
&gt; - WebGPU
&gt; - Three.js
&gt; - WebXR ([checkout the another project](https://github.com/moeru-ai/chat) we have under the @moeru-ai organization)
&gt;
&gt; **If you are interested, why not introduce yourself here? [Would like to join part of us to build AIRI?](https://github.com/moeru-ai/airi/discussions/33)**

## Current Progress

Capable of

- [x] Brain
  - [x] Play [Minecraft](https://www.minecraft.net)
  - [x] Play [Factorio](https://www.factorio.com) (WIP, but [PoC and demo available](https://github.com/moeru-ai/airi-factorio))
  - [x] Chat in [Telegram](https://telegram.org)
  - [x] Chat in [Discord](https://discord.com)
  - [ ] Memory
    - [x] Pure in-browser database support (DuckDB WASM | `pglite`)
    - [ ] Memory Alaya (WIP)
  - [ ] Pure in-browser local (WebGPU) inference
- [x] Ears
  - [x] Audio input from browser
  - [x] Audio input from [Discord](https://discord.com)
  - [x] Client side speech recognition
  - [x] Client side talking detection
- [x] Mouth
  - [x] [ElevenLabs](https://elevenlabs.io/) voice synthesis
- [x] Body
  - [x] VRM support
    - [x] Control VRM model
  - [x] VRM model animations
    - [x] Auto blink
    - [x] Auto look at
    - [x] Idle eye movement
  - [x] Live2D support
    - [x] Control Live2D model
  - [x] Live2D model animations
    - [x] Auto blink
    - [x] Auto look at
    - [x] Idle eye movement

## Development

&gt; For detailed instructions to develop this project, follow [CONTRIBUTING.md](./.github/CONTRIBUTING.md)

&gt; [!NOTE]
&gt; By default, `pnpm dev` will start the development server for the Stage Web (browser version). If you would
&gt; like to try developing the desktop version, please make sure you read [CONTRIBUTING.md](./.github/CONTRIBUTING.md)
&gt; to setup the environment correctly.

```shell
pnpm i
pnpm dev
```

### Stage Web (Browser Version at [airi.moeru.ai](https://airi.moeru.ai))

```shell
pnpm dev
```

### Stage Tamagotchi (Desktop Version)

```shell
pnpm dev:tamagotchi
```

A Nix package for Tamagotchi is included. To run airi with Nix, first make sure to enable flakes, then run:

```shell
nix run github:moeru-ai/airi
```

### Stage Pocket (Mobile Version)

Start the development server for the capacitor web version:

```shell
pnpm dev:pocket
```

Check your IP address in the output of the command above:

```shell
  ROLLDOWN-VITE v7.3.0  ready in 1073 ms

  ‚ûú  Local:   https://localhost:5273/
  ‚ûú  Network: https://&lt;ip-will-be-here&gt;:5273/
  ‚ûú  Vue DevTools: Open https://localhost:5273/__devtools__/ as a separate window
  ‚ûú  Vue DevTools: Press Option(‚å•)+Shift(‚áß)+D in App to toggle the Vue DevTools
  ‚ûú  UnoCSS Inspector: https://localhost:5273/__unocss/
```

Open the Xcode project:

```shell
CAPACITOR_DEV_SERVER_URL=https://&lt;your-ip-address&gt;:5273 pnpm open:ios
```

Then Xcode will open and you can click the &quot;Run&quot; button to run the app on your iPhone.

If you need to connect server channel on pocket in wireless mode, you need to start tamagotchi as root:

```shell
sudo pnpm dev:tamagotchi
```

Then enable secure websocket in tamagotchi `settings/system/general`.

### Documentation Site

```shell
pnpm dev:docs
```

### Publish

Please update the version in `Cargo.toml` after running `bumpp`:

```shell
npx bumpp --no-commit --no-tag
```

## Support of LLM API Providers (powered by [xsai](https://github.com/moeru-ai/xsai))

- [x] [302.AI (sponsored)](https://share.302.ai/514k2v)
- [x] [OpenRouter](https://openrouter.ai/)
- [x] [vLLM](https://github.com/vllm-project/vllm)
- [x] [SGLang](https://github.com/sgl-project/sglang)
- [x] [Ollama](https://github.com/ollama/ollama)
- [x] [Google Gemini](https://developers.generativeai.google)
- [x] [OpenAI](https://platform.openai.com/docs/guides/gpt/chat-completions-api)
  - [ ] [Azure OpenAI API](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference) (PR welcome)
- [x] [Anthropic Claude](https://anthropic.com)
  - [ ] [AWS Claude](https://docs.anthropic.com/en/api/claude-on-amazon-bedrock) (PR welcome)
- [x] [DeepSeek](https://www.deepseek.com/)
- [x] [Qwen](https://help.aliyun.com/document_detail/2400395.html)
- [x] [xAI](https://x.ai/)
- [x] [Groq](https://wow.groq.com/)
- [x] [Mistral](https://mistral.ai/)
- [x] [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/)
- [x] [Together.ai](https://www.together.ai/)
- [x] [Fireworks.ai](https://www.together.ai/)
- [x] [Novita](https://www.novita.ai/)
- [x] [Zhipu](https://bigmodel.cn)
- [x] [SiliconFlow](https://cloud.siliconflow.cn/i/rKXmRobW)
- [x] [Stepfun](https://platform.stepfun.com/)
- [x] [Baichuan](https://platform.baichuan-ai.com)
- [x] [Minimax](https://api.minimax.chat/)
- [x] [Moonshot AI](https://platform.moonshot.cn/)
- [x] [ModelScope](https://modelscope.cn/docs/model-service/API-Inference/intro)
- [x] [Player2](https://player2.game/)
- [x] [Tencent Cloud](https://cloud.tencent.com/document/product/1729)
- [ ] [Sparks](https://www.xfyun.cn/doc/spark/Web.html) (PR welcome)
- [ ] [Volcano Engine](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;ac=DSASUQY5&amp;rc=2QXCA1VI) (PR welcome)

## Sub-projects Born from This Project

- [Awesome AI VTuber](https://github.com/proj-airi/awesome-ai-vtuber): A curated list of AI VTubers and related projects
- [`unspeech`](https://github.com/moeru-ai/unspeech): Universal endpoint proxy server for `/audio/transcriptions` and `/audio/speech`, like LiteLLM but for any ASR and TTS
- [`hfup`](https://github.com/moeru-ai/hfup): tools to help on deploying, bundling to HuggingFace Spaces
- [`xsai-transformers`](https://github.com/moeru-ai/xsai-transformers): Experimental [ü§ó Transformers.js](https://github.com/huggingface/transformers.js) provider for [xsAI](https://github.com/moeru-ai/xsai).
- [WebAI: Realtime Voice Chat](https://github.com/proj-airi/webai-realtime-voice-chat): Full example of implementing ChatGPT&#039;s realtime voice from scratch with VAD + STT + LLM + TTS.
- [`@proj-airi/drizzle-duckdb-wasm`](https://github.com/moeru-ai/airi/tree/main/packages/drizzle-duckdb-wasm/README.md): Drizzle ORM driver for DuckDB WASM
- [`@proj-airi/duckdb-wasm`](https://github.com/moeru-ai/airi/tree/main/packages/duckdb-wasm/README.md): Easy to use wrapper for `@duckdb/duckdb-wasm`
- [`tauri-plugin-mcp`](https://github.com/moeru-ai/airi/blob/main/crates/tauri-plugin-mcp/README.md): A Tauri plugin for interacting with MCP servers.
- [AIRI Factorio](https://github.com/moeru-ai/airi-factorio): Allow AIRI to play Factorio
- [Factorio RCON API](https://github.com/nekomeowww/factorio-rcon-api): RESTful API wrapper for Factorio headless server console
- [`autorio`](https://github.com/moeru-ai/airi-factorio/tree/main/packages/autorio): Factorio automation library
- [`tstl-plugin-reload-factorio-mod`](https://github.com/moeru-ai/airi-factorio/tree/main/packages/tstl-plugin-reload-factorio-mod): Reload Factorio mod when developing
- [Velin](https://github.com/luoling8192/velin): Use Vue SFC and Markdown to write easy to manage stateful prompts for LLM
- [`demodel`](https://github.com/moeru-ai/demodel): Easily boost the speed of pulling your models and datasets from various of inference runtimes.
- [`inventory`](https://github.com/moeru-ai/inventory): Centralized model catalog and default provider configurations backend service
- [MCP Launcher](https://github.com/moeru-ai/mcp-launcher): Easy to use MCP builder &amp; launcher for all possible MCP servers, just like Ollama for models!
- [ü•∫ SAD](https://github.com/moeru-ai/sad): Documentation and notes for self-host and browser running LLMs.

```mermaid
%%{ init: { &#039;flowchart&#039;: { &#039;curve&#039;: &#039;catmullRom&#039; } } }%%

flowchart TD
  Core(&quot;Core&quot;)
  Unspeech(&quot;unspeech&quot;)
  DBDriver(&quot;@proj-airi/drizzle-duckdb-wasm&quot;)
  MemoryDriver(&quot;[WIP] Memory Alaya&quot;)
  DB1(&quot;@proj-airi/duckdb-wasm&quot;)
  SVRT(&quot;@proj-airi/server-runtime&quot;)
  Memory(&quot;Memory&quot;)
  STT(&quot;STT&quot;)
  Stage(&quot;Stage&quot;)
  StageUI(&quot;@proj-airi/stage-ui&quot;)
  UI(&quot;@proj-airi/ui&quot;)

  subgraph AIRI
    DB1 --&gt; DBDriver --&gt; MemoryDriver --&gt; Memory --&gt; Core
    UI --&gt; StageUI --&gt; Stage --&gt; Core
    Core --&gt; STT
    Core --&gt; SVRT
  end

  subgraph UI_Components
    UI --&gt; StageUI
    UITransitions(&quot;@proj-airi/ui-transitions&quot;) --&gt; StageUI
    UILoadingScreens(&quot;@proj-airi/ui-loading-screens&quot;) --&gt; StageUI
    FontCJK(&quot;@proj-airi/font-cjkfonts-allseto&quot;) --&gt; StageUI
    FontXiaolai(&quot;@proj-airi/font-xiaolai&quot;) --&gt; StageUI
  end

  subgraph Apps
    Stage --&gt; StageWeb(&quot;@proj-airi/stage-web&quot;)
    Stage --&gt; StageTamagotchi(&quot;@proj-airi/stage-tamagotchi&quot;)
    Core --&gt; RealtimeAudio(&quot;@proj-airi/realtime-audio&quot;)
    Core --&gt; PromptEngineering(&quot;@proj-airi/playground-prompt-engineering&quot;)
  end

  subgraph Server_Components
    Core --&gt; ServerSDK(&quot;@proj-airi/server-sdk&quot;)
    ServerShared(&quot;@proj-airi/server-shared&quot;) --&gt; SVRT
    ServerShared --&gt; ServerSDK
  end

  STT --&gt;|Speaking| Unspeech
  SVRT --&gt;|Playing Factorio| F_AGENT
  SVRT --&gt;|Playing Minecraft| MC_AGENT

  subgraph Factorio_Agent
    F_AGENT(&quot;Factorio Agent&quot;)
    F_API(&quot;Factorio RCON API&quot;)
    factorio-server(&quot;factorio-server&quot;)
    F_MOD1(&quot;autorio&quot;)

    F_AGENT --&gt; F_API -.-&gt; factorio-server
    F_MOD1 -.-&gt; factorio-server
  end

  subgraph Minecraft_Agent
    MC_AGENT(&quot;Minecraft Agent&quot;)
    Mineflayer(&quot;Mineflayer&quot;)
    minecraft-server(&quot;minecraft-server&quot;)

    MC_AGENT --&gt; Mineflayer -.-&gt; minecraft-server
  end

  XSAI(&quot;xsAI&quot;) --&gt; Core
  XSAI --&gt; F_AGENT
  XSAI --&gt; MC_AGENT

  Core --&gt; TauriMCP(&quot;@proj-airi/tauri-plugin-mcp&quot;)
  Memory_PGVector(&quot;@proj-airi/memory-pgvector&quot;) --&gt; Memory

  style Core fill:#f9d4d4,stroke:#333,stroke-width:1px
  style AIRI fill:#fcf7f7,stroke:#333,stroke-width:1px
  style UI fill:#d4f9d4,stroke:#333,stroke-width:1px
  style Stage fill:#d4f9d4,stroke:#333,stroke-width:1px
  style UI_Components fill:#d4f9d4,stroke:#333,stroke-width:1px
  style Server_Components fill:#d4e6f9,stroke:#333,stroke-width:1px
  style Apps fill:#d4d4f9,stroke:#333,stroke-width:1px
  style Factorio_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px
  style Minecraft_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px

  style DBDriver fill:#f9f9d4,stroke:#333,stroke-width:1px
  style MemoryDriver fill:#f9f9d4,stroke:#333,stroke-width:1px
  style DB1 fill:#f9f9d4,stroke:#333,stroke-width:1px
  style Memory fill:#f9f9d4,stroke:#333,stroke-width:1px
  style Memory_PGVector fill:#f9f9d4,stroke:#333,stroke-width:1px
```

## Similar Projects

### Open sourced ones

- [kimjammer/Neuro: A recreation of Neuro-Sama originally created in 7 days.](https://github.com/kimjammer/Neuro): very well completed implementation.
- [SugarcaneDefender/z-waif](https://github.com/SugarcaneDefender/z-waif): Great at gaming, autonomous, and prompt engineering
- [semperai/amica](https://github.com/semperai/amica/): Great at VRM, WebXR
- [elizaOS/eliza](https://github.com/elizaOS/eliza): Great examples and software engineering on how to integrate agent into various of systems and APIs
- [ardha27/AI-Waifu-Vt

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ruvnet/ruflo]]></title>
            <link>https://github.com/ruvnet/ruflo</link>
            <guid>https://github.com/ruvnet/ruflo</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:31 GMT</pubDate>
            <description><![CDATA[üåä The leading agent orchestration platform for Claude. Deploy intelligent multi-agent swarms, coordinate autonomous workflows, and build conversational AI systems. Features enterprise-grade architecture, distributed swarm intelligence, RAG integration, and native Claude Code / Codex Integration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ruvnet/ruflo">ruvnet/ruflo</a></h1>
            <p>üåä The leading agent orchestration platform for Claude. Deploy intelligent multi-agent swarms, coordinate autonomous workflows, and build conversational AI systems. Features enterprise-grade architecture, distributed swarm intelligence, RAG integration, and native Claude Code / Codex Integration</p>
            <p>Language: TypeScript</p>
            <p>Stars: 16,545</p>
            <p>Forks: 1,880</p>
            <p>Stars today: 928 stars today</p>
            <h2>README</h2><pre># üåä Ruflo v3: Enterprise AI Orchestration Platform

&lt;div align=&quot;center&quot;&gt;

![Ruflo Banner](ruflo/assets/ruFlo.png)



[![GitHub Project of the Day](https://img.shields.io/badge/GitHub-Project%20of%20the%20Day-ff6600?style=for-the-badge&amp;logo=github&amp;logoColor=white)](https://github.com/ruvnet/claude-flow)

[![Star on GitHub](https://img.shields.io/github/stars/ruvnet/claude-flow?style=for-the-badge&amp;logo=github&amp;color=gold)](https://github.com/ruvnet/claude-flow)
[![Monthly Downloads](https://img.shields.io/npm/dm/claude-flow?style=for-the-badge&amp;logo=npm&amp;color=blue&amp;label=Monthly%20Downloads)](https://www.npmjs.com/package/claude-flow)
[![Total Downloads](https://img.shields.io/npm/dt/claude-flow?style=for-the-badge&amp;logo=npm&amp;color=cyan&amp;label=Total%20Downloads)](https://www.npmjs.com/package/claude-flow)
[![ruv.io](https://img.shields.io/badge/ruv.io-AI%20Platform-green?style=for-the-badge&amp;logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCI+PHBhdGggZmlsbD0id2hpdGUiIGQ9Ik0xMiAyQzYuNDggMiAyIDYuNDggMiAxMnM0LjQ4IDEwIDEwIDEwIDEwLTQuNDggMTAtMTBTMTcuNTIgMiAxMiAyem0wIDE4Yy00LjQyIDAtOC0zLjU4LTgtOHMzLjU4LTggOC04IDggMy41OCA4IDgtMy41OCA4LTggOHoiLz48L3N2Zz4=)](https://ruv.io)
[![Agentics Foundation](https://img.shields.io/badge/Agentics-Foundation-crimson?style=for-the-badge&amp;logo=openai)](https://discord.com/invite/dfxmpwkG2D)
[![Claude Code](https://img.shields.io/badge/Claude%20Code-SDK%20Integrated-green?style=for-the-badge&amp;logo=anthropic)](https://github.com/ruvnet/claude-flow)
[![MIT License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge&amp;logo=opensourceinitiative)](https://opensource.org/licenses/MIT)
---
[![Follow @ruv](https://img.shields.io/badge/Follow%20%40ruv-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white)](https://x.com/ruv)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&amp;logo=linkedin)](https://www.linkedin.com/in/reuvencohen/)
[![YouTube](https://img.shields.io/badge/YouTube-Subscribe-FF0000?style=for-the-badge&amp;logo=youtube&amp;logoColor=white)](https://www.youtube.com/@ReuvenCohen)

# **Production-ready multi-agent AI orchestration for Claude Code**
*Deploy 60+ specialized agents in coordinated swarms with self-learning capabilities, fault-tolerant consensus, and enterprise-grade security.*

&lt;/div&gt;

&gt; **Why Ruflo?** Claude Flow is now Ruflo ‚Äî named by Ruv, who loves Rust, flow states, and building things that feel inevitable. The &quot;Ru&quot; is the Ruv. The &quot;flo&quot; is the flow. Underneath, WASM kernels written in Rust power the policy engine, embeddings, and proof system. 5,800 commits later, the alpha is over. This is v3.5.

## Getting into the Flow

Ruflo is a comprehensive AI agent orchestration framework that transforms Claude Code into a powerful multi-agent development platform. It enables teams to deploy, coordinate, and optimize specialized AI agents working together on complex software engineering tasks.

### Self-Learning/Self-Optimizing Agent Architecture

```
User ‚Üí Ruflo (CLI/MCP) ‚Üí Router ‚Üí Swarm ‚Üí Agents ‚Üí Memory ‚Üí LLM Providers
                       ‚Üë                          ‚Üì
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ Learning Loop ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

&lt;details&gt;
&lt;summary&gt;üìê &lt;strong&gt;Expanded Architecture&lt;/strong&gt; ‚Äî Full system diagram with RuVector intelligence&lt;/summary&gt;

```mermaid
flowchart TB
    subgraph USER[&quot;üë§ User Layer&quot;]
        U[User]
    end

    subgraph ENTRY[&quot;üö™ Entry Layer&quot;]
        CLI[CLI / MCP Server]
        AID[AIDefence Security]
    end

    subgraph ROUTING[&quot;üß≠ Routing Layer&quot;]
        QL[Q-Learning Router]
        MOE[MoE - 8 Experts]
        SK[Skills - 42+]
        HK[Hooks - 17]
    end

    subgraph SWARM[&quot;üêù Swarm Coordination&quot;]
        TOPO[Topologies&lt;br/&gt;mesh/hier/ring/star]
        CONS[Consensus&lt;br/&gt;Raft/BFT/Gossip/CRDT]
        CLM[Claims&lt;br/&gt;Human-Agent Coord]
    end

    subgraph AGENTS[&quot;ü§ñ 60+ Agents&quot;]
        AG1[coder]
        AG2[tester]
        AG3[reviewer]
        AG4[architect]
        AG5[security]
        AG6[...]
    end

    subgraph RESOURCES[&quot;üì¶ Resources&quot;]
        MEM[(Memory&lt;br/&gt;AgentDB)]
        PROV[Providers&lt;br/&gt;Claude/GPT/Gemini/Ollama]
        WORK[Workers - 12&lt;br/&gt;ultralearn/audit/optimize]
    end

    subgraph RUVECTOR[&quot;üß† RuVector Intelligence Layer&quot;]
        direction TB
        subgraph ROW1[&quot; &quot;]
            SONA[SONA&lt;br/&gt;Self-Optimize&lt;br/&gt;&amp;lt;0.05ms]
            EWC[EWC++&lt;br/&gt;No Forgetting]
            FLASH[Flash Attention&lt;br/&gt;2.49-7.47x]
        end
        subgraph ROW2[&quot; &quot;]
            HNSW[HNSW&lt;br/&gt;150x-12,500x faster]
            RB[ReasoningBank&lt;br/&gt;Pattern Store]
            HYP[Hyperbolic&lt;br/&gt;Poincar√©]
        end
        subgraph ROW3[&quot; &quot;]
            LORA[LoRA/Micro&lt;br/&gt;128x compress]
            QUANT[Int8 Quant&lt;br/&gt;3.92x memory]
            RL[9 RL Algos&lt;br/&gt;Q/SARSA/PPO/DQN]
        end
    end

    subgraph LEARNING[&quot;üîÑ Learning Loop&quot;]
        L1[RETRIEVE] --&gt; L2[JUDGE] --&gt; L3[DISTILL] --&gt; L4[CONSOLIDATE] --&gt; L5[ROUTE]
    end

    U --&gt; CLI
    CLI --&gt; AID
    AID --&gt; QL &amp; MOE &amp; SK &amp; HK
    QL &amp; MOE &amp; SK &amp; HK --&gt; TOPO &amp; CONS &amp; CLM
    TOPO &amp; CONS &amp; CLM --&gt; AG1 &amp; AG2 &amp; AG3 &amp; AG4 &amp; AG5 &amp; AG6
    AG1 &amp; AG2 &amp; AG3 &amp; AG4 &amp; AG5 &amp; AG6 --&gt; MEM &amp; PROV &amp; WORK
    MEM --&gt; SONA &amp; EWC &amp; FLASH
    SONA &amp; EWC &amp; FLASH --&gt; HNSW &amp; RB &amp; HYP
    HNSW &amp; RB &amp; HYP --&gt; LORA &amp; QUANT &amp; RL
    LORA &amp; QUANT &amp; RL --&gt; L1
    L5 -.-&gt;|loops back| QL

    style RUVECTOR fill:#1a1a2e,stroke:#e94560,stroke-width:2px
    style LEARNING fill:#0f3460,stroke:#e94560,stroke-width:2px
    style USER fill:#16213e,stroke:#0f3460
    style ENTRY fill:#1a1a2e,stroke:#0f3460
    style ROUTING fill:#1a1a2e,stroke:#0f3460
    style SWARM fill:#1a1a2e,stroke:#0f3460
    style AGENTS fill:#1a1a2e,stroke:#0f3460
    style RESOURCES fill:#1a1a2e,stroke:#0f3460
```

**RuVector Components** (included with Ruflo):

| Component | Purpose | Performance |
|-----------|---------|-------------|
| **SONA** | Self-Optimizing Neural Architecture - learns optimal routing | Fast adaptation |
| **EWC++** | Elastic Weight Consolidation - prevents catastrophic forgetting | Preserves learned patterns |
| **Flash Attention** | Optimized attention computation | 2-7x speedup |
| **HNSW** | Hierarchical Navigable Small World vector search | Sub-millisecond retrieval |
| **ReasoningBank** | Pattern storage with trajectory learning | RETRIEVE‚ÜíJUDGE‚ÜíDISTILL |
| **Hyperbolic** | Poincare ball embeddings for hierarchical data | Better code relationships |
| **LoRA/MicroLoRA** | Low-Rank Adaptation for efficient fine-tuning | Lightweight adaptation |
| **Int8 Quantization** | Memory-efficient weight storage | ~4x memory reduction |
| **SemanticRouter** | Semantic task routing with cosine similarity | Fast intent routing |
| **9 RL Algorithms** | Q-Learning, SARSA, A2C, PPO, DQN, Decision Transformer, etc. | Task-specific learning |

```bash
# Use RuVector via Ruflo
npx ruflo@latest hooks intelligence --status
```

&lt;/details&gt;

### Get Started Fast

```bash
# One-line install (recommended)
curl -fsSL https://cdn.jsdelivr.net/gh/ruvnet/claude-flow@main/scripts/install.sh | bash

# Or full setup with MCP + diagnostics
curl -fsSL https://cdn.jsdelivr.net/gh/ruvnet/claude-flow@main/scripts/install.sh | bash -s -- --full

# Or via npx
npx ruflo@latest init --wizard
```

---
### Key Capabilities

ü§ñ **60+ Specialized Agents** - Ready-to-use AI agents for coding, code review, testing, security audits, documentation, and DevOps. Each agent is optimized for its specific role.

üêù **Coordinated Agent Teams** - Run unlimited agents simultaneously in organized swarms. Agents spawn sub-workers, communicate, share context, and divide work automatically using hierarchical (queen/workers) or mesh (peer-to-peer) patterns.

üß† **Learns From Your Workflow** - The system remembers what works. Successful patterns are stored and reused, routing similar tasks to the best-performing agents. Gets smarter over time.

üîå **Works With Any LLM** - Switch between Claude, GPT, Gemini, Cohere, or local models like Llama. Automatic failover if one provider is unavailable. Smart routing picks the cheapest option that meets quality requirements.

‚ö° **Plugs Into Claude Code** - Native integration via MCP (Model Context Protocol). Use ruflo commands directly in your Claude Code sessions with full tool access.

üîí **Production-Ready Security** - Built-in protection against prompt injection, input validation, path traversal prevention, command injection blocking, and safe credential handling.

üß© **Extensible Plugin System** - Add custom capabilities with the plugin SDK. Create workers, hooks, providers, and security modules. Share plugins via the decentralized IPFS marketplace.

---

### A multi-purpose Agent Tool Kit 

&lt;details&gt;
&lt;summary&gt;üîÑ &lt;strong&gt;Core Flow&lt;/strong&gt; ‚Äî How requests move through the system&lt;/summary&gt;

Every request flows through four layers: from your CLI or Claude Code interface, through intelligent routing, to specialized agents, and finally to LLM providers for reasoning.

| Layer | Components | What It Does |
|-------|------------|--------------|
| User | Claude Code, CLI | Your interface to control and run commands |
| Orchestration | MCP Server, Router, Hooks | Routes requests to the right agents |
| Agents | 60+ types | Specialized workers (coder, tester, reviewer...) |
| Providers | Anthropic, OpenAI, Google, Ollama | AI models that power reasoning |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üêù &lt;strong&gt;Swarm Coordination&lt;/strong&gt; ‚Äî How agents work together&lt;/summary&gt;

Agents organize into swarms led by queens that coordinate work, prevent drift, and reach consensus on decisions‚Äîeven when some agents fail.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Coordination | Queen, Swarm, Consensus | Manages agent teams (Raft, Byzantine, Gossip) |
| Drift Control | Hierarchical topology, Checkpoints | Prevents agents from going off-task |
| Hive Mind | Queen-led hierarchy, Collective memory | Strategic/tactical/adaptive queens coordinate workers |
| Consensus | Byzantine, Weighted, Majority | Fault-tolerant decisions (2/3 majority for BFT) |

**Hive Mind Capabilities:**
- üêù **Queen Types**: Strategic (planning), Tactical (execution), Adaptive (optimization)
- üë∑ **8 Worker Types**: Researcher, Coder, Analyst, Tester, Architect, Reviewer, Optimizer, Documenter
- üó≥Ô∏è **3 Consensus Algorithms**: Majority, Weighted (Queen 3x), Byzantine (f &lt; n/3)
- üß† **Collective Memory**: Shared knowledge, LRU cache, SQLite persistence with WAL
- ‚ö° **Performance**: Fast batch spawning with parallel agent coordination

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üß† &lt;strong&gt;Intelligence &amp; Memory&lt;/strong&gt; ‚Äî How the system learns and remembers&lt;/summary&gt;

The system stores successful patterns in vector memory, builds a knowledge graph for structural understanding, learns from outcomes via neural networks, and adapts routing based on what works best.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Memory | HNSW, AgentDB, Cache | Stores and retrieves patterns with fast HNSW search |
| Knowledge Graph | MemoryGraph, PageRank, Communities | Identifies influential insights, detects clusters (ADR-049) |
| Self-Learning | LearningBridge, SONA, ReasoningBank | Triggers learning from insights, confidence lifecycle (ADR-049) |
| Agent Scopes | AgentMemoryScope, 3-scope dirs | Per-agent isolation + cross-agent knowledge transfer (ADR-049) |
| Embeddings | ONNX Runtime, MiniLM | Local vectors without API calls (75x faster) |
| Learning | SONA, MoE, ReasoningBank | Self-improves from results (&lt;0.05ms adaptation) |
| Fine-tuning | MicroLoRA, EWC++ | Lightweight adaptation without full retraining |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;‚ö° &lt;strong&gt;Optimization&lt;/strong&gt; ‚Äî How to reduce cost and latency&lt;/summary&gt;

Skip expensive LLM calls for simple tasks using WebAssembly transforms, and compress tokens to reduce API costs by 30-50%.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Agent Booster | WASM, AST analysis | Skips LLM for simple edits (&lt;1ms) |
| Token Optimizer | Compression, Caching | Reduces token usage 30-50% |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üîß &lt;strong&gt;Operations&lt;/strong&gt; ‚Äî Background services and integrations&lt;/summary&gt;

Background daemons handle security audits, performance optimization, and session persistence automatically while you work.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Background | Daemon, 12 Workers | Auto-runs audits, optimization, learning |
| Security | AIDefence, Validation | Blocks injection, detects threats |
| Sessions | Persist, Restore, Export | Saves context across conversations |
| GitHub | PR, Issues, Workflows | Manages repos and code reviews |
| Analytics | Metrics, Benchmarks | Monitors performance, finds bottlenecks |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üéØ &lt;strong&gt;Task Routing&lt;/strong&gt; ‚Äî Extend your Claude Code subscription by 250%&lt;/summary&gt;

Smart routing skips expensive LLM calls when possible. Simple edits use WASM (free), medium tasks use cheaper models. This can extend your Claude Code usage by 250% or save significantly on direct API costs.

| Complexity | Handler | Speed |
|------------|---------|-------|
| Simple | Agent Booster (WASM) | &lt;1ms |
| Medium | Haiku/Sonnet | ~500ms |
| Complex | Opus + Swarm | 2-5s |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;‚ö° &lt;strong&gt;Agent Booster (WASM)&lt;/strong&gt; ‚Äî Skip LLM for simple code transforms&lt;/summary&gt;

Agent Booster uses WebAssembly to handle simple code transformations without calling the LLM at all. When the hooks system detects a simple task, it routes directly to Agent Booster for instant results.

**Supported Transform Intents:**

| Intent | What It Does | Example |
|--------|--------------|---------|
| `var-to-const` | Convert var/let to const | `var x = 1` ‚Üí `const x = 1` |
| `add-types` | Add TypeScript type annotations | `function foo(x)` ‚Üí `function foo(x: string)` |
| `add-error-handling` | Wrap in try/catch | Adds proper error handling |
| `async-await` | Convert promises to async/await | `.then()` chains ‚Üí `await` |
| `add-logging` | Add console.log statements | Adds debug logging |
| `remove-console` | Strip console.* calls | Removes all console statements |

**Hook Signals:**

When you see these in hook output, the system is telling you how to optimize:

```bash
# Agent Booster available - skip LLM entirely
[AGENT_BOOSTER_AVAILABLE] Intent: var-to-const
‚Üí Use Edit tool directly, 352x faster than LLM

# Model recommendation for Task tool
[TASK_MODEL_RECOMMENDATION] Use model=&quot;haiku&quot;
‚Üí Pass model=&quot;haiku&quot; to Task tool for cost savings
```

**Performance:**

| Metric | Agent Booster | LLM Call |
|--------|---------------|----------|
| Latency | &lt;1ms | 2-5s |
| Cost | $0 | $0.0002-$0.015 |
| Speedup | **352x faster** | baseline |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üí∞ &lt;strong&gt;Token Optimizer&lt;/strong&gt; ‚Äî 30-50% token reduction&lt;/summary&gt;

The Token Optimizer integrates agentic-flow optimizations to reduce API costs by compressing context and caching results.

**Savings Breakdown:**

| Optimization | Token Savings | How It Works |
|--------------|---------------|--------------|
| ReasoningBank retrieval | -32% | Fetches relevant patterns instead of full context |
| Agent Booster edits | -15% | Simple edits skip LLM entirely |
| Cache (95% hit rate) | -10% | Reuses embeddings and patterns |
| Optimal batch size | -20% | Groups related operations |
| **Combined** | **30-50%** | Stacks multiplicatively |

**Usage:**

```typescript
import { getTokenOptimizer } from &#039;@claude-flow/integration&#039;;
const optimizer = await getTokenOptimizer();

// Get compact context (32% fewer tokens)
const ctx = await optimizer.getCompactContext(&quot;auth patterns&quot;);

// Optimized edit (352x faster for simple transforms)
await optimizer.optimizedEdit(file, oldStr, newStr, &quot;typescript&quot;);

// Optimal config for swarm (100% success rate)
const config = optimizer.getOptimalConfig(agentCount);
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üõ°Ô∏è &lt;strong&gt;Anti-Drift Swarm Configuration&lt;/strong&gt; ‚Äî Prevent goal drift in multi-agent work&lt;/summary&gt;

Complex swarms can drift from their original goals. Ruflo V3 includes anti-drift defaults that prevent agents from going off-task.

**Recommended Configuration:**

```javascript
// Anti-drift defaults (ALWAYS use for coding tasks)
swarm_init({
  topology: &quot;hierarchical&quot;,  // Single coordinator enforces alignment
  maxAgents: 8,              // Smaller team = less drift surface
  strategy: &quot;specialized&quot;    // Clear roles reduce ambiguity
})
```

**Why This Prevents Drift:**

| Setting | Anti-Drift Benefit |
|---------|-------------------|
| `hierarchical` | Coordinator validates each output against goal, catches divergence early |
| `maxAgents: 6-8` | Fewer agents = less coordination overhead, easier alignment |
| `specialized` | Clear boundaries - each agent knows exactly what to do, no overlap |
| `raft` consensus | Leader maintains authoritative state, no conflicting decisions |

**Additional Anti-Drift Measures:**

- Frequent checkpoints via `post-task` hooks
- Shared memory namespace for all agents
- Short task cycles with verification gates
- Hierarchical coordinator reviews all outputs

**Task ‚Üí Agent Routing (Anti-Drift):**

| Code | Task Type | Recommended Agents |
|------|-----------|-------------------|
| 1 | Bug Fix | coordinator, researcher, coder, tester |
| 3 | Feature | coordinator, architect, coder, tester, reviewer |
| 5 | Refactor | coordinator, architect, coder, reviewer |
| 7 | Performance | coordinator, perf-engineer, coder |
| 9 | Security | coordinator, security-architect, auditor |
| 11 | Memory | coordinator, memory-specialist, perf-engineer |

&lt;/details&gt;

### Claude Code: With vs Without Ruflo

| Capability | Claude Code Alone | Claude Code + Ruflo |
|------------|-------------------|---------------------------|
| **Agent Collaboration** | Agents work in isolation, no shared context | Agents collaborate via swarms with shared memory and consensus |
| **Coordination** | Manual orchestration between tasks | Queen-led hierarchy with 5 consensus algorithms (Raft, Byzantine, Gossip) |
| **Hive Mind** | ‚õî Not available | üêù Queen-led swarms with collective intelligence, 3 queen types, 8 worker types |
| **Consensus** | ‚õî No multi-agent decisions | Byzantine fault-tolerant voting (f &lt; n/3), weighted, majority |
| **Memory** | Session-only, no persistence | HNSW vector memory with sub-ms retrieval + knowledge graph |
| **Vector Database** | ‚õî No native support | üêò RuVector PostgreSQL with 77+ SQL functions, ~61¬µs search, 16,400 QPS |
| **Knowledge Graph** | ‚õî Flat insight lists | PageRank + community detection identifies influential insights (ADR-049) |
| **Collective Memory** | ‚õî No shared knowledge | Shared knowledge base with LRU cache, SQLite persistence, 8 memory types |
| **Learning** | Static behavior, no adaptation | SONA self-learning with &lt;0.05ms adaptation, LearningBridge for insights |
| **Agent Scoping** | Single project scope | 3-scope agent memory (project/local/user) with cross-agent transfer |
| **Task Routing** | You decide which agent to use | Intelligent routing based on learned patterns (89% accuracy) |
| **Complex Tasks** | Manual breakdown required | Automatic decomposition across 5 domains (Security, Core, Integration, Support) |
| **Background Workers** | Nothing runs automatically | 12 context-triggered workers auto-dispatch on file changes, patterns, sessions |
| **LLM Provider** | Anthropic only | 6 providers with automatic failover and cost-based routing (85% savings) |
| **Security** | Standard protections | CVE-hardened with bcrypt, input validation, path traversal prevention |
| **Performance** | Baseline | Faster tasks via parallel swarm spawning and intelligent routing |

## Quick Start

### Prerequisites

- **Node.js 20+** (required)
- **npm 9+** / **pnpm** / **bun** package manager

**IMPORTANT**: Claude Code must be installed first:

```bash
# 1. Install

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[bytedance/deer-flow]]></title>
            <link>https://github.com/bytedance/deer-flow</link>
            <guid>https://github.com/bytedance/deer-flow</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:30 GMT</pubDate>
            <description><![CDATA[An open-source SuperAgent harness that researches, codes, and creates. With the help of sandboxes, memories, tools, skills and subagents, it handles different levels of tasks that could take minutes to hours.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytedance/deer-flow">bytedance/deer-flow</a></h1>
            <p>An open-source SuperAgent harness that researches, codes, and creates. With the help of sandboxes, memories, tools, skills and subagents, it handles different levels of tasks that could take minutes to hours.</p>
            <p>Language: Python</p>
            <p>Stars: 22,591</p>
            <p>Forks: 2,718</p>
            <p>Stars today: 899 stars today</p>
            <h2>README</h2><pre># ü¶å DeerFlow - 2.0

&lt;a href=&quot;https://trendshift.io/repositories/14699&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14699&quot; alt=&quot;bytedance%2Fdeer-flow | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&gt; On February 28th, 2026, DeerFlow claimed the üèÜ #1 spot on GitHub Trending following the launch of version 2. Thanks a million to our incredible community ‚Äî you made this happen! üí™üî•

DeerFlow (**D**eep **E**xploration and **E**fficient **R**esearch **Flow**) is an open-source **super agent harness** that orchestrates **sub-agents**, **memory**, and **sandboxes** to do almost anything ‚Äî powered by **extensible skills**.

https://github.com/user-attachments/assets/a8bcadc4-e040-4cf2-8fda-dd768b999c18

&gt; [!NOTE]
&gt; **DeerFlow 2.0 is a ground-up rewrite.** It shares no code with v1. If you&#039;re looking for the original Deep Research framework, it&#039;s maintained on the [`1.x` branch](https://github.com/bytedance/deer-flow/tree/main-1.x) ‚Äî contributions there are still welcome. Active development has moved to 2.0.

## Offiical Website

Learn more and see **real demos** on our official website.

**[deerflow.tech](https://deerflow.tech/)**

---

## Table of Contents

- [Quick Start](#quick-start)
- [Sandbox Mode](#sandbox-mode)
- [From Deep Research to Super Agent Harness](#from-deep-research-to-super-agent-harness)
- [Core Features](#core-features)
  - [Skills &amp; Tools](#skills--tools)
  - [Sub-Agents](#sub-agents)
  - [Sandbox &amp; File System](#sandbox--file-system)
  - [Context Engineering](#context-engineering)
  - [Long-Term Memory](#long-term-memory)
- [Recommended Models](#recommended-models)
- [Documentation](#documentation)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgments](#acknowledgments)
- [Star History](#star-history)

## Quick Start

### Configuration

1. **Clone the DeerFlow repository**

   ```bash
   git clone https://github.com/bytedance/deer-flow.git
   cd deer-flow
   ```

2. **Generate local configuration files**

   From the project root directory (`deer-flow/`), run:

   ```bash
   make config
   ```

   This command creates local configuration files based on the provided example templates.

3. **Configure your preferred model(s)**

   Edit `config.yaml` and define at least one model:

   ```yaml
   models:
     - name: gpt-4                       # Internal identifier
       display_name: GPT-4               # Human-readable name
       use: langchain_openai:ChatOpenAI  # LangChain class path
       model: gpt-4                      # Model identifier for API
       api_key: $OPENAI_API_KEY          # API key (recommended: use env var)
       max_tokens: 4096                  # Maximum tokens per request
       temperature: 0.7                  # Sampling temperature
   ```

  
4. **Set API keys for your configured model(s)**

   Choose one of the following methods:

- Option A: Edit the `.env` file in the project root (Recommended)


   ```bash
   TAVILY_API_KEY=your-tavily-api-key
   OPENAI_API_KEY=your-openai-api-key
   # Add other provider keys as needed
   ```

- Option B: Export environment variables in your shell

   ```bash
   export OPENAI_API_KEY=your-openai-api-key
   ```

- Option C: Edit `config.yaml` directly (Not recommended for production)

   ```yaml
   models:
     - name: gpt-4
       api_key: your-actual-api-key-here  # Replace placeholder
   ```

### Running the Application

#### Option 1: Docker (Recommended)

The fastest way to get started with a consistent environment:

1. **Initialize and start**:
   ```bash
   make docker-init    # Pull sandbox image (Only once or when image updates)
   make docker-start   # Start services (auto-detects sandbox mode from config.yaml)
   ```

   `make docker-start` now starts `provisioner` only when `config.yaml` uses provisioner mode (`sandbox.use: src.community.aio_sandbox:AioSandboxProvider` with `provisioner_url`).

2. **Access**: http://localhost:2026

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed Docker development guide.

#### Option 2: Local Development

If you prefer running services locally:

1. **Check prerequisites**:
   ```bash
   make check  # Verifies Node.js 22+, pnpm, uv, nginx
   ```

2. **(Optional) Pre-pull sandbox image**:
   ```bash
   # Recommended if using Docker/Container-based sandbox
   make setup-sandbox
   ```

3. **Start services**:
   ```bash
   make dev
   ```

4. **Access**: http://localhost:2026

### Advanced
#### Sandbox Mode

DeerFlow supports multiple sandbox execution modes:
- **Local Execution** (runs sandbox code directly on the host machine)
- **Docker Execution** (runs sandbox code in isolated Docker containers)
- **Docker Execution with Kubernetes** (runs sandbox code in Kubernetes pods via provisioner service)

For Docker development, service startup follows `config.yaml` sandbox mode. In Local/Docker modes, `provisioner` is not started.

See the [Sandbox Configuration Guide](backend/docs/CONFIGURATION.md#sandbox) to configure your preferred mode.

#### MCP Server

DeerFlow supports configurable MCP servers and skills to extend its capabilities.
See the [MCP Server Guide](backend/docs/MCP_SERVER.md) for detailed instructions.

## From Deep Research to Super Agent Harness

DeerFlow started as a Deep Research framework ‚Äî and the community ran with it. Since launch, developers have pushed it far beyond research: building data pipelines, generating slide decks, spinning up dashboards, automating content workflows. Things we never anticipated.

That told us something important: DeerFlow wasn&#039;t just a research tool. It was a **harness** ‚Äî a runtime that gives agents the infrastructure to actually get work done.

So we rebuilt it from scratch.

DeerFlow 2.0 is no longer a framework you wire together. It&#039;s a super agent harness ‚Äî batteries included, fully extensible. Built on LangGraph and LangChain, it ships with everything an agent needs out of the box: a filesystem, memory, skills, sandboxed execution, and the ability to plan and spawn sub-agents for complex, multi-step tasks.

Use it as-is. Or tear it apart and make it yours.

## Core Features

### Skills &amp; Tools

Skills are what make DeerFlow do *almost anything*.

A standard Agent Skill is a structured capability module ‚Äî a Markdown file that defines a workflow, best practices, and references to supporting resources. DeerFlow ships with built-in skills for research, report generation, slide creation, web pages, image and video generation, and more. But the real power is extensibility: add your own skills, replace the built-in ones, or combine them into compound workflows.

Skills are loaded progressively ‚Äî only when the task needs them, not all at once. This keeps the context window lean and makes DeerFlow work well even with token-sensitive models.

Tools follow the same philosophy. DeerFlow comes with a core toolset ‚Äî web search, web fetch, file operations, bash execution ‚Äî and supports custom tools via MCP servers and Python functions. Swap anything. Add anything.

```
# Paths inside the sandbox container
/mnt/skills/public
‚îú‚îÄ‚îÄ research/SKILL.md
‚îú‚îÄ‚îÄ report-generation/SKILL.md
‚îú‚îÄ‚îÄ slide-creation/SKILL.md
‚îú‚îÄ‚îÄ web-page/SKILL.md
‚îî‚îÄ‚îÄ image-generation/SKILL.md

/mnt/skills/custom
‚îî‚îÄ‚îÄ your-custom-skill/SKILL.md      ‚Üê yours
```

### Sub-Agents

Complex tasks rarely fit in a single pass. DeerFlow decomposes them.

The lead agent can spawn sub-agents on the fly ‚Äî each with its own scoped context, tools, and termination conditions. Sub-agents run in parallel when possible, report back structured results, and the lead agent synthesizes everything into a coherent output.

This is how DeerFlow handles tasks that take minutes to hours: a research task might fan out into a dozen sub-agents, each exploring a different angle, then converge into a single report ‚Äî or a website ‚Äî or a slide deck with generated visuals. One harness, many hands.

### Sandbox &amp; File System

DeerFlow doesn&#039;t just *talk* about doing things. It has its own computer.

Each task runs inside an isolated Docker container with a full filesystem ‚Äî skills, workspace, uploads, outputs. The agent reads, writes, and edits files. It executes bash commands and codes. It views images. All sandboxed, all auditable, zero contamination between sessions.

This is the difference between a chatbot with tool access and an agent with an actual execution environment.

```
# Paths inside the sandbox container
/mnt/user-data/
‚îú‚îÄ‚îÄ uploads/          ‚Üê your files
‚îú‚îÄ‚îÄ workspace/        ‚Üê agents&#039; working directory
‚îî‚îÄ‚îÄ outputs/          ‚Üê final deliverables
```

### Context Engineering

**Isolated Sub-Agent Context**: Each sub-agent runs in its own isolated context. This means that the sub-agent will not be able to see the context of the main agent or other sub-agents. This is important to ensure that the sub-agent is able to focus on the task at hand and not be distracted by the context of the main agent or other sub-agents.

**Summarization**: Within a session, DeerFlow manages context aggressively ‚Äî summarizing completed sub-tasks, offloading intermediate results to the filesystem, compressing what&#039;s no longer immediately relevant. This lets it stay sharp across long, multi-step tasks without blowing the context window.

### Long-Term Memory

Most agents forget everything the moment a conversation ends. DeerFlow remembers.

Across sessions, DeerFlow builds a persistent memory of your profile, preferences, and accumulated knowledge. The more you use it, the better it knows you ‚Äî your writing style, your technical stack, your recurring workflows. Memory is stored locally and stays under your control.

## Recommended Models

DeerFlow is model-agnostic ‚Äî it works with any LLM that implements the OpenAI-compatible API. That said, it performs best with models that support:

- **Long context windows** (100k+ tokens) for deep research and multi-step tasks
- **Reasoning capabilities** for adaptive planning and complex decomposition
- **Multimodal inputs** for image understanding and video comprehension
- **Strong tool-use** for reliable function calling and structured outputs

## Embedded Python Client

DeerFlow can be used as an embedded Python library without running the full HTTP services. The `DeerFlowClient` provides direct in-process access to all agent and Gateway capabilities, returning the same response schemas as the HTTP Gateway API:

```python
from src.client import DeerFlowClient

client = DeerFlowClient()

# Chat
response = client.chat(&quot;Analyze this paper for me&quot;, thread_id=&quot;my-thread&quot;)

# Streaming (LangGraph SSE protocol: values, messages-tuple, end)
for event in client.stream(&quot;hello&quot;):
    if event.type == &quot;messages-tuple&quot; and event.data.get(&quot;type&quot;) == &quot;ai&quot;:
        print(event.data[&quot;content&quot;])

# Configuration &amp; management ‚Äî returns Gateway-aligned dicts
models = client.list_models()        # {&quot;models&quot;: [...]}
skills = client.list_skills()        # {&quot;skills&quot;: [...]}
client.update_skill(&quot;web-search&quot;, enabled=True)
client.upload_files(&quot;thread-1&quot;, [&quot;./report.pdf&quot;])  # {&quot;success&quot;: True, &quot;files&quot;: [...]}
```

All dict-returning methods are validated against Gateway Pydantic response models in CI (`TestGatewayConformance`), ensuring the embedded client stays in sync with the HTTP API schemas. See `backend/src/client.py` for full API documentation.

## Documentation

- [Contributing Guide](CONTRIBUTING.md) - Development environment setup and workflow
- [Configuration Guide](backend/docs/CONFIGURATION.md) - Setup and configuration instructions
- [Architecture Overview](backend/CLAUDE.md) - Technical architecture details
- [Backend Architecture](backend/README.md) - Backend architecture and API reference

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for development setup, workflow, and guidelines.

Regression coverage includes Docker sandbox mode detection and provisioner kubeconfig-path handling tests in `backend/tests/`.

## License

This project is open source and available under the [MIT License](./LICENSE).

## Acknowledgments

DeerFlow is built upon the incredible work of the open-source community. We are deeply grateful to all the projects and contributors whose efforts have made DeerFlow possible. Truly, we stand on the shoulders of giants.

We would like to extend our sincere appreciation to the following projects for their invaluable contributions:

- **[LangChain](https://github.com/langchain-ai/langchain)**: Their exceptional framework powers our LLM interactions and chains, enabling seamless integration and functionality.
- **[LangGraph](https://github.com/langchain-ai/langgraph)**: Their innovative approach to multi-agent orchestration has been instrumental in enabling DeerFlow&#039;s sophisticated workflows.

These projects exemplify the transformative power of open-source collaboration, and we are proud to build upon their foundations.

### Key Contributors

A heartfelt thank you goes out to the core authors of `DeerFlow`, whose vision, passion, and dedication have brought this project to life:

- **[Daniel Walnut](https://github.com/hetaoBackend/)**
- **[Henry Li](https://github.com/magiccube/)**

Your unwavering commitment and expertise have been the driving force behind DeerFlow&#039;s success. We are honored to have you at the helm of this journey.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=bytedance/deer-flow&amp;type=Date)](https://star-history.com/#bytedance/deer-flow&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[superset-sh/superset]]></title>
            <link>https://github.com/superset-sh/superset</link>
            <guid>https://github.com/superset-sh/superset</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:29 GMT</pubDate>
            <description><![CDATA[IDE for the AI Agents Era - Run an army of Claude Code, Codex, etc. on your machine]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/superset-sh/superset">superset-sh/superset</a></h1>
            <p>IDE for the AI Agents Era - Run an army of Claude Code, Codex, etc. on your machine</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,433</p>
            <p>Forks: 184</p>
            <p>Stars today: 181 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img width=&quot;full&quot; alt=&quot;Superset&quot; src=&quot;apps/marketing/public/images/readme-hero.png&quot; /&gt;

### The Terminal for Coding Agents

[![GitHub stars](https://img.shields.io/github/stars/superset-sh/superset?style=flat&amp;logo=github)](https://github.com/superset-sh/superset/stargazers)
[![GitHub release](https://img.shields.io/github/v/release/superset-sh/superset?style=flat&amp;logo=github)](https://github.com/superset-sh/superset/releases)
[![License](https://img.shields.io/github/license/superset-sh/superset?style=flat)](LICENSE.md)
[![Twitter](https://img.shields.io/badge/@superset__sh-555?logo=x)](https://x.com/superset_sh)
[![Discord](https://img.shields.io/badge/Discord-555?logo=discord)](https://discord.gg/cZeD9WYcV7)

&lt;br /&gt;

[**Download for macOS**](https://github.com/superset-sh/superset/releases/latest) &amp;nbsp;&amp;bull;&amp;nbsp; [Documentation](https://docs.superset.sh) &amp;nbsp;&amp;bull;&amp;nbsp; [Changelog](https://github.com/superset-sh/superset/releases) &amp;nbsp;&amp;bull;&amp;nbsp; [Discord](https://discord.gg/cZeD9WYcV7)

&lt;br /&gt;


&lt;/div&gt;

## Why Superset?

Superset is a turbocharged terminal that allows you to run any CLI coding agents along with the tools to 10x your development workflow. 

- **Run multiple agents simultaneously** without context switching overhead
- **Isolate each task** in its own git worktree so agents don&#039;t interfere with each other
- **Monitor all your agents** from one place and get notified when they need attention
- **Review changes quickly** with built-in diff viewer and editor

Wait less, ship more.

## Features

| Feature | Description |
|:--------|:------------|
| **Parallel Execution** | Run 10+ coding agents simultaneously on your machine |
| **Worktree Isolation** | Each task gets its own branch and working directory |
| **Agent Monitoring** | Track agent status and get notified when changes are ready |
| **Built-in Diff Viewer** | Inspect and edit agent changes without leaving the app |
| **Workspace Presets** | Automate env setup, dependency installation, and more |
| **Universal Compatibility** | Works with any CLI agent that runs in a terminal |
| **Quick Context Switching** | Jump between tasks as they need your attention |
| **IDE Integration** | Open any workspace in your favorite editor with one click |

## Supported Agents

Superset works with any CLI-based coding agent, including:

| Agent | Status |
|:------|:-------|
| [Claude Code](https://github.com/anthropics/claude-code) | Fully supported |
| [OpenAI Codex CLI](https://github.com/openai/codex) | Fully supported |
| [Cursor Agent](https://docs.cursor.com/agent) | Fully supported |
| [Gemini CLI](https://github.com/google-gemini/gemini-cli) | Fully supported |
| [GitHub Copilot](https://github.com/features/copilot) | Fully supported |
| [OpenCode](https://github.com/opencode-ai/opencode) | Fully supported |
| Any CLI agent | Will work |

If it runs in a terminal, it runs on Superset

## Requirements

| Requirement | Details |
|:------------|:--------|
| **OS** | macOS (Windows/Linux untested) |
| **Runtime** | [Bun](https://bun.sh/) v1.0+ |
| **Version Control** | Git 2.20+ |
| **GitHub CLI** | [gh](https://cli.github.com/) |
| **Caddy** | [caddy](https://caddyserver.com/docs/install) (for dev server) |

## Getting Started

### Quick Start (Pre-built)

**[Download Superset for macOS](https://github.com/superset-sh/superset/releases/latest)**

### Build from Source

&lt;details&gt;
&lt;summary&gt;Click to expand build instructions&lt;/summary&gt;

**1. Clone the repository**

```bash
git clone https://github.com/superset-sh/superset.git
cd superset
```

**2. Set up environment variables** (choose one):

Option A: Full setup
```bash
cp .env.example .env
# Edit .env and fill in the values
```

Option B: Skip env validation (for quick local testing)
```bash
cp .env.example .env
echo &#039;SKIP_ENV_VALIDATION=1&#039; &gt;&gt; .env
```

**3. Set up Caddy** (reverse proxy for Electric SQL streams):

```bash
# Install caddy: brew install caddy (macOS) or see https://caddyserver.com/docs/install
cp Caddyfile.example Caddyfile
```

**4. Install dependencies and run**

```bash
bun install
bun run dev
```

**5. Build the desktop app**

```bash
bun run build
open apps/desktop/release
```

&lt;/details&gt;

## Keyboard Shortcuts

All shortcuts are customizable via **Settings &gt; Keyboard Shortcuts** (`‚åò/`). See [full documentation](https://docs.superset.sh/keyboard-shortcuts).

### Workspace Navigation

| Shortcut | Action |
|:---------|:-------|
| `‚åò1-9` | Switch to workspace 1-9 |
| `‚åò‚å•‚Üë/‚Üì` | Previous/next workspace |
| `‚åòN` | New workspace |
| `‚åò‚áßN` | Quick create workspace |
| `‚åò‚áßO` | Open project |

### Terminal

| Shortcut | Action |
|:---------|:-------|
| `‚åòT` | New tab |
| `‚åòW` | Close pane/terminal |
| `‚åòD` | Split right |
| `‚åò‚áßD` | Split down |
| `‚åòK` | Clear terminal |
| `‚åòF` | Find in terminal |
| `‚åò‚å•‚Üê/‚Üí` | Previous/next tab |
| `Ctrl+1-9` | Open preset 1-9 |

### Layout

| Shortcut | Action |
|:---------|:-------|
| `‚åòB` | Toggle workspaces sidebar |
| `‚åòL` | Toggle changes panel |
| `‚åòO` | Open in external app |
| `‚åò‚áßC` | Copy path |

## Configuration

Configure workspace setup and teardown in `.superset/config.json`. See [full documentation](https://docs.superset.sh/setup-teardown-scripts).

```json
{
  &quot;setup&quot;: [&quot;./.superset/setup.sh&quot;],
  &quot;teardown&quot;: [&quot;./.superset/teardown.sh&quot;]
}
```

| Option | Type | Description |
|:-------|:-----|:------------|
| `setup` | `string[]` | Commands to run when creating a workspace |
| `teardown` | `string[]` | Commands to run when deleting a workspace |

### Example setup script

```bash
#!/bin/bash
# .superset/setup.sh

# Copy environment variables
cp ../.env .env

# Install dependencies
bun install

# Run any other setup tasks
echo &quot;Workspace ready!&quot;
```

Scripts have access to environment variables:
- `SUPERSET_WORKSPACE_NAME` ‚Äî Name of the workspace
- `SUPERSET_ROOT_PATH` ‚Äî Path to the main repository

## Internal Dependency Overrides

For the internal `mastracode` fork/bundle workflow used by this repo, see [docs/mastracode-fork-workflow.md](docs/mastracode-fork-workflow.md).

## Tech Stack

&lt;p&gt;
  &lt;a href=&quot;https://www.electronjs.org/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Electron-191970?logo=Electron&amp;logoColor=white&quot; alt=&quot;Electron&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://reactjs.org/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/React-%2320232a.svg?logo=react&amp;logoColor=%2361DAFB&quot; alt=&quot;React&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://tailwindcss.com/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Tailwindcss-%2338B2AC.svg?logo=tailwind-css&amp;logoColor=white&quot; alt=&quot;TailwindCSS&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://bun.sh/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Bun-000000?logo=bun&amp;logoColor=white&quot; alt=&quot;Bun&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://turbo.build/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Turborepo-EF4444?logo=turborepo&amp;logoColor=white&quot; alt=&quot;Turborepo&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://vitejs.dev/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Vite-%23646CFF.svg?logo=vite&amp;logoColor=white&quot; alt=&quot;Vite&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://biomejs.dev/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Biome-339AF0?logo=biome&amp;logoColor=white&quot; alt=&quot;Biome&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://orm.drizzle.team/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Drizzle%20ORM-FFE873?logo=drizzle&amp;logoColor=black&quot; alt=&quot;Drizzle ORM&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://neon.tech/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Neon-00E9CA?logo=neon&amp;logoColor=white&quot; alt=&quot;Neon&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://trpc.io/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/tRPC-2596BE?logo=trpc&amp;logoColor=white&quot; alt=&quot;tRPC&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

## Contributing

We welcome contributions! If you have a suggestion that would make Superset better:

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m &#039;Add amazing feature&#039;`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

You can also [open issues](https://github.com/superset-sh/superset/issues) for bugs or feature requests.

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed instructions and code of conduct.

&lt;a href=&quot;https://github.com/superset-sh/superset/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=superset-sh/superset&quot; /&gt;
&lt;/a&gt;

## Community

Join the Superset community to get help, share feedback, and connect with other users:

- **[Discord](https://discord.gg/cZeD9WYcV7)** ‚Äî Chat with the team and community
- **[Twitter](https://x.com/superset_sh)** ‚Äî Follow for updates and announcements
- **[GitHub Issues](https://github.com/superset-sh/superset/issues)** ‚Äî Report bugs and request features
- **[GitHub Discussions](https://github.com/superset-sh/superset/discussions)** ‚Äî Ask questions and share ideas

### Team

[![Avi Twitter](https://img.shields.io/badge/Avi-@avimakesrobots-555?logo=x)](https://x.com/avimakesrobots)
[![Kiet Twitter](https://img.shields.io/badge/Kiet-@flyakiet-555?logo=x)](https://x.com/flyakiet)
[![Satya Twitter](https://img.shields.io/badge/Satya-@saddle__paddle-555?logo=x)](https://x.com/saddle_paddle)

## License

Distributed under the Apache 2.0 License. See [LICENSE.md](LICENSE.md) for more information.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[microsoft/playwright-cli]]></title>
            <link>https://github.com/microsoft/playwright-cli</link>
            <guid>https://github.com/microsoft/playwright-cli</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:28 GMT</pubDate>
            <description><![CDATA[CLI for common Playwright actions. Record and generate Playwright code, inspect selectors and take screenshots.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/playwright-cli">microsoft/playwright-cli</a></h1>
            <p>CLI for common Playwright actions. Record and generate Playwright code, inspect selectors and take screenshots.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 4,445</p>
            <p>Forks: 165</p>
            <p>Stars today: 139 stars today</p>
            <h2>README</h2><pre># playwright-cli

Playwright CLI with SKILLS

### Playwright CLI vs Playwright MCP

This package provides CLI interface into Playwright. If you are using **coding agents**, that is the best fit.

- **CLI**: Modern **coding agents** increasingly favor CLI‚Äìbased workflows exposed as SKILLs over MCP because CLI invocations are more token-efficient: they avoid loading large tool schemas and verbose accessibility trees into the model context, allowing agents to act through concise, purpose-built commands. This makes CLI + SKILLs better suited for high-throughput coding agents that must balance browser automation with large codebases, tests, and reasoning within limited context windows.

- **MCP**: MCP remains relevant for specialized agentic loops that benefit from persistent state, rich introspection, and iterative reasoning over page structure, such as exploratory automation, self-healing tests, or long-running autonomous workflows where maintaining continuous browser context outweighs token cost concerns. Learn more about [Playwright MCP](https://github.com/microsoft/playwright-mcp).

### Key Features

- **Token-efficient**. Does not force page data into LLM.

### Requirements
- Node.js 18 or newer
- Claude Code, GitHub Copilot, or any other coding agent.

## Getting Started

## Installation

```bash
npm install -g @playwright/cli@latest
playwright-cli --help
```

### Installing skills

Claude Code, GitHub Copilot and others will use the locally installed skills.

```bash
playwright-cli install --skills
```

### Skills-less operation

Point your agent at the CLI and let it cook. It&#039;ll read the skill off `playwright-cli --help` on its own:

```
Test the &quot;add todo&quot; flow on https://demo.playwright.dev/todomvc using playwright-cli.
Check playwright-cli --help for available commands.
```

## Demo

```
&gt; Use playwright skills to test https://demo.playwright.dev/todomvc/.
  Take screenshots for all successful and failing scenarios. 
```

Your agent will be running commands, but it does not mean you can&#039;t play with it manually:

```
playwright-cli open https://demo.playwright.dev/todomvc/ --headed
playwright-cli type &quot;Buy groceries&quot;
playwright-cli press Enter
playwright-cli type &quot;Water flowers&quot;
playwright-cli press Enter
playwright-cli check e21
playwright-cli check e35
playwright-cli screenshot
```

## Headed operation

Playwright CLI is headless by default. If you&#039;d like to see the browser, pass `--headed` to `open`:

```bash
playwright-cli open https://playwright.dev --headed
```

## Sessions

Playwright CLI keeps the browser profile in memory by default. Your cookies and storage state
are preserved between CLI calls within the session, but lost when the browser closes. Use
`--persistent` to save the profile to disk for persistence across browser restarts.

You can use different instances of the browser for different projects with sessions. Pass `-s=` to
the invocation to talk to a specific browser.

```bash
playwright-cli open https://playwright.dev
playwright-cli -s=example open https://example.com --persistent
playwright-cli list
```

You can run your coding agent with the `PLAYWRIGHT_CLI_SESSION` environment variable:

```bash
PLAYWRIGHT_CLI_SESSION=todo-app claude .
```

Or instruct it to prepend `-s=` to the calls.

Manage your sessions as follows:

```bash
playwright-cli list                     # list all sessions
playwright-cli close-all                # close all browsers
playwright-cli kill-all                 # forcefully kill all browser processes
```

## Monitoring

Use `playwright-cli show` to open a visual dashboard that lets you see and control all running
browser sessions. This is useful when your coding agents are running browser automation in the
background and you want to observe their progress or step in to help.

```bash
playwright-cli show
```

&lt;img width=&quot;1107&quot; height=&quot;729&quot; alt=&quot;Image&quot; src=&quot;https://github.com/user-attachments/assets/99df739d-106a-4520-b004-bb315db41da7&quot; /&gt;

The dashboard opens a window with two views:

- **Session grid** ‚Äî shows all active sessions grouped by workspace, each with a live screencast
  preview, session name, current URL, and page title. Click any session to zoom in.
- **Session detail** ‚Äî shows a live view of the selected session with a tab bar, navigation
  controls (back, forward, reload, address bar), and full remote control. Click into the viewport
  to take over mouse and keyboard input; press Escape to release.

From the grid you can also close running sessions or delete data for inactive ones.

## Commands

### Core

```bash
playwright-cli open [url]               # open browser, optionally navigate to url
playwright-cli goto &lt;url&gt;               # navigate to a url
playwright-cli close                    # close the page
playwright-cli type &lt;text&gt;              # type text into editable element
playwright-cli click &lt;ref&gt; [button]     # perform click on a web page
playwright-cli dblclick &lt;ref&gt; [button]  # perform double click on a web page
playwright-cli fill &lt;ref&gt; &lt;text&gt;        # fill text into editable element
playwright-cli drag &lt;startRef&gt; &lt;endRef&gt; # perform drag and drop between two elements
playwright-cli hover &lt;ref&gt;              # hover over element on page
playwright-cli select &lt;ref&gt; &lt;val&gt;       # select an option in a dropdown
playwright-cli upload &lt;file&gt;            # upload one or multiple files
playwright-cli check &lt;ref&gt;              # check a checkbox or radio button
playwright-cli uncheck &lt;ref&gt;            # uncheck a checkbox or radio button
playwright-cli snapshot                 # capture page snapshot to obtain element ref
playwright-cli snapshot --filename=f    # save snapshot to specific file
playwright-cli eval &lt;func&gt; [ref]        # evaluate javascript expression on page or element
playwright-cli dialog-accept [prompt]   # accept a dialog
playwright-cli dialog-dismiss           # dismiss a dialog
playwright-cli resize &lt;w&gt; &lt;h&gt;           # resize the browser window
```

### Navigation

```bash
playwright-cli go-back                  # go back to the previous page
playwright-cli go-forward               # go forward to the next page
playwright-cli reload                   # reload the current page
```

### Keyboard

```bash
playwright-cli press &lt;key&gt;              # press a key on the keyboard, `a`, `arrowleft`
playwright-cli keydown &lt;key&gt;            # press a key down on the keyboard
playwright-cli keyup &lt;key&gt;              # press a key up on the keyboard
```

### Mouse

```bash
playwright-cli mousemove &lt;x&gt; &lt;y&gt;        # move mouse to a given position
playwright-cli mousedown [button]       # press mouse down
playwright-cli mouseup [button]         # press mouse up
playwright-cli mousewheel &lt;dx&gt; &lt;dy&gt;     # scroll mouse wheel
```

### Save as

```bash
playwright-cli screenshot [ref]         # screenshot of the current page or element
playwright-cli screenshot --filename=f  # save screenshot with specific filename
playwright-cli pdf                      # save page as pdf
playwright-cli pdf --filename=page.pdf  # save pdf with specific filename
```

### Tabs

```bash
playwright-cli tab-list                 # list all tabs
playwright-cli tab-new [url]            # create a new tab
playwright-cli tab-close [index]        # close a browser tab
playwright-cli tab-select &lt;index&gt;       # select a browser tab
```

### Storage

```bash
playwright-cli state-save [filename]    # save storage state
playwright-cli state-load &lt;filename&gt;    # load storage state

# Cookies
playwright-cli cookie-list [--domain]   # list cookies
playwright-cli cookie-get &lt;name&gt;        # get a cookie
playwright-cli cookie-set &lt;name&gt; &lt;val&gt;  # set a cookie
playwright-cli cookie-delete &lt;name&gt;     # delete a cookie
playwright-cli cookie-clear             # clear all cookies

# LocalStorage
playwright-cli localstorage-list        # list localStorage entries
playwright-cli localstorage-get &lt;key&gt;   # get localStorage value
playwright-cli localstorage-set &lt;k&gt; &lt;v&gt; # set localStorage value
playwright-cli localstorage-delete &lt;k&gt;  # delete localStorage entry
playwright-cli localstorage-clear       # clear all localStorage

# SessionStorage
playwright-cli sessionstorage-list      # list sessionStorage entries
playwright-cli sessionstorage-get &lt;k&gt;   # get sessionStorage value
playwright-cli sessionstorage-set &lt;k&gt; &lt;v&gt; # set sessionStorage value
playwright-cli sessionstorage-delete &lt;k&gt;  # delete sessionStorage entry
playwright-cli sessionstorage-clear     # clear all sessionStorage
```

### Network

```bash
playwright-cli route &lt;pattern&gt; [opts]   # mock network requests
playwright-cli route-list               # list active routes
playwright-cli unroute [pattern]        # remove route(s)
```

### DevTools

```bash
playwright-cli console [min-level]      # list console messages
playwright-cli network                  # list all network requests since loading the page
playwright-cli run-code &lt;code&gt;          # run playwright code snippet
playwright-cli tracing-start            # start trace recording
playwright-cli tracing-stop             # stop trace recording
playwright-cli video-start              # start video recording
playwright-cli video-stop [filename]    # stop video recording
```

### Open parameters

```bash
playwright-cli open --browser=chrome    # use specific browser
playwright-cli open --extension         # connect via browser extension
playwright-cli open --persistent        # use persistent profile
playwright-cli open --profile=&lt;path&gt;    # use custom profile directory
playwright-cli open --config=file.json  # use config file
playwright-cli close                    # close the browser
playwright-cli delete-data              # delete user data for default session
```

### Snapshots

After each command, playwright-cli provides a snapshot of the current browser state.

```bash
&gt; playwright-cli goto https://example.com
### Page
- Page URL: https://example.com/
- Page Title: Example Domain
### Snapshot
[Snapshot](.playwright-cli/page-2026-02-14T19-22-42-679Z.yml)
```

You can also take a snapshot on demand using `playwright-cli snapshot` command.

If `--filename` is not provided, a new snapshot file is created with a timestamp. Default to automatic file naming, use `--filename=` when artifact is a part of the workflow result.

### Sessions

```bash
playwright-cli -s=name &lt;cmd&gt;            # run command in named session
playwright-cli -s=name close            # stop a named browser
playwright-cli -s=name delete-data      # delete user data for named browser
playwright-cli list                     # list all sessions
playwright-cli close-all                # close all browsers
playwright-cli kill-all                 # forcefully kill all browser processes
```

### Local installation

In some cases you might want to install playwright-cli locally. If running the globally available `playwright-cli` binary fails, use `npx playwright-cli` to run the commands. For example:

```bash
npx playwright-cli open https://example.com
npx playwright-cli click e1
```

## Configuration file

The Playwright CLI can be configured using a JSON configuration file. You can specify the configuration file using the `--config` command line option:

```bash
playwright-cli --config path/to/config.json open example.com
```

Playwright CLI will load config from `.playwright/cli.config.json` by default so that you did not need to specify it every time.

&lt;details&gt;
&lt;summary&gt;Configuration file schema&lt;/summary&gt;

```typescript
{
  /**
   * The browser to use.
   */
  browser?: {
    /**
     * The type of browser to use.
     */
    browserName?: &#039;chromium&#039; | &#039;firefox&#039; | &#039;webkit&#039;;

    /**
     * Keep the browser profile in memory, do not save it to disk.
     */
    isolated?: boolean;

    /**
     * Path to a user data directory for browser profile persistence.
     * Temporary directory is created by default.
     */
    userDataDir?: string;

    /**
     * Launch options passed to
     * @see https://playwright.dev/docs/api/class-browsertype#browser-type-launch-persistent-context
     *
     * This is useful for settings options like `channel`, `headless`, `executablePath`, etc.
     */
    launchOptions?: playwright.LaunchOptions;

    /**
     * Context options for the browser context.
     *
     * This is useful for settings options like `viewport`.
     */
    contextOptions?: playwright.BrowserContextOptions;

    /**
     * Chrome DevTools Protocol endpoint to connect to an existing browser instance in case of Chromium family browsers.
     */
    cdpEndpoint?: string;

    /**
     * CDP headers to send with the connect request.
     */
    cdpHeaders?: Record&lt;string, string&gt;;

    /**
     * Timeout in milliseconds for connecting to CDP endpoint. Defaults to 30000 (30 seconds). Pass 0 to disable timeout.
     */
    cdpTimeout?: number;

    /**
     * Remote endpoint to connect to an existing Playwright server.
     */
    remoteEndpoint?: string;

    /**
     * Paths to TypeScript files to add as initialization scripts for Playwright page.
     */
    initPage?: string[];

    /**
     * Paths to JavaScript files to add as initialization scripts.
     * The scripts will be evaluated in every page before any of the page&#039;s scripts.
     */
    initScript?: string[];
  },

  /**
   * If specified, saves the Playwright video of the session into the output directory.
   */
  saveVideo?: {
    width: number;
    height: number;
  };

  /**
   * The directory to save output files.
   */
  outputDir?: string;

  /**
   * Whether to save snapshots, console messages, network logs and other session logs to a file or to the standard output. Defaults to &quot;stdout&quot;.
   */
  outputMode?: &#039;file&#039; | &#039;stdout&#039;;

  console?: {
    /**
     * The level of console messages to return. Each level includes the messages of more severe levels. Defaults to &quot;info&quot;.
     */
    level?: &#039;error&#039; | &#039;warning&#039; | &#039;info&#039; | &#039;debug&#039;;
  },

  network?: {
    /**
     * List of origins to allow the browser to request. Default is to allow all. Origins matching both `allowedOrigins` and `blockedOrigins` will be blocked.
     */
    allowedOrigins?: string[];

    /**
     * List of origins to block the browser to request. Origins matching both `allowedOrigins` and `blockedOrigins` will be blocked.
     */
    blockedOrigins?: string[];
  };

  /**
   * Specify the attribute to use for test ids, defaults to &quot;data-testid&quot;.
   */
  testIdAttribute?: string;

  timeouts?: {
    /*
     * Configures default action timeout: https://playwright.dev/docs/api/class-page#page-set-default-timeout. Defaults to 5000ms.
     */
    action?: number;

    /*
     * Configures default navigation timeout: https://playwright.dev/docs/api/class-page#page-set-default-navigation-timeout. Defaults to 60000ms.
     */
    navigation?: number;
  };

  /**
   * Whether to allow file uploads from anywhere on the file system.
   * By default (false), file uploads are restricted to paths within the MCP roots only.
   */
  allowUnrestrictedFileAccess?: boolean;

  /**
   * Specify the language to use for code generation.
   */
  codegen?: &#039;typescript&#039; | &#039;none&#039;;
}
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Configuration via env&lt;/summary&gt;

| Environment |
|-------------|
| `PLAYWRIGHT_MCP_ALLOWED_HOSTS` comma-separated list of hosts this server is allowed to serve from. Defaults to the host the server is bound to. Pass &#039;*&#039; to disable the host check. |
| `PLAYWRIGHT_MCP_ALLOWED_ORIGINS` semicolon-separated list of TRUSTED origins to allow the browser to request. Default is to allow all. Important: *does not* serve as a security boundary and *does not* affect redirects. |
| `PLAYWRIGHT_MCP_ALLOW_UNRESTRICTED_FILE_ACCESS` allow access to files outside of the workspace roots. Also allows unrestricted access to file:// URLs. By default access to file system is restricted to workspace root directories (or cwd if no roots are configured) only, and navigation to file:// URLs is blocked. |
| `PLAYWRIGHT_MCP_BLOCKED_ORIGINS` semicolon-separated list of origins to block the browser from requesting. Blocklist is evaluated before allowlist. If used without the allowlist, requests not matching the blocklist are still allowed. Important: *does not* serve as a security boundary and *does not* affect redirects. |
| `PLAYWRIGHT_MCP_BLOCK_SERVICE_WORKERS` block service workers |
| `PLAYWRIGHT_MCP_BROWSER` browser or chrome channel to use, possible values: chrome, firefox, webkit, msedge. |
| `PLAYWRIGHT_MCP_CAPS` comma-separated list of additional capabilities to enable, possible values: vision, pdf. |
| `PLAYWRIGHT_MCP_CDP_ENDPOINT` CDP endpoint to connect to. |
| `PLAYWRIGHT_MCP_CDP_HEADER` CDP headers to send with the connect request, multiple can be specified. |
| `PLAYWRIGHT_MCP_CODEGEN` specify the language to use for code generation, possible values: &quot;typescript&quot;, &quot;none&quot;. Default is &quot;typescript&quot;. |
| `PLAYWRIGHT_MCP_CONFIG` path to the configuration file. |
| `PLAYWRIGHT_MCP_CONSOLE_LEVEL` level of console messages to return: &quot;error&quot;, &quot;warning&quot;, &quot;info&quot;, &quot;debug&quot;. Each level includes the messages of more severe levels. |
| `PLAYWRIGHT_MCP_DEVICE` device to emulate, for example: &quot;iPhone 15&quot; |
| `PLAYWRIGHT_MCP_EXECUTABLE_PATH` path to the browser executable. |
| `PLAYWRIGHT_MCP_EXTENSION` Connect to a running browser instance (Edge/Chrome only). Requires the &quot;Playwright MCP Bridge&quot; browser extension to be installed. |
| `PLAYWRIGHT_MCP_GRANT_PERMISSIONS` List of permissions to grant to the browser context, for example &quot;geolocation&quot;, &quot;clipboard-read&quot;, &quot;clipboard-write&quot;. |
| `PLAYWRIGHT_MCP_HEADLESS` run browser in headless mode, headed by default |
| `PLAYWRIGHT_MCP_HOST` host to bind server to. Default is localhost. Use 0.0.0.0 to bind to all interfaces. |
| `PLAYWRIGHT_MCP_IGNORE_HTTPS_ERRORS` ignore https errors |
| `PLAYWRIGHT_MCP_INIT_PAGE` path to TypeScript file to evaluate on Playwright page object |
| `PLAYWRIGHT_MCP_INIT_SCRIPT` path to JavaScript file to add as an initialization script. The script will be evaluated in every page before any of the page&#039;s scripts. Can be specified multiple times. |
| `PLAYWRIGHT_MCP_ISOLATED` keep the browser profile in memory, do not save it to disk. |
| `PLAYWRIGHT_MCP_IMAGE_RESPONSES` whether to send image responses to the client. Can be &quot;allow&quot; or &quot;omit&quot;, Defaults to &quot;allow&quot;. |
| `PLAYWRIGHT_MCP_NO_SANDBOX` disable the sandbox for all process types that are normally sandboxed. |
| `PLAYWRIGHT_MCP_OUTPUT_DIR` path to the directory for output files. |
| `PLAYWRIGHT_MCP_OUTPUT_MODE` whether to save snapshots, console messages, network logs to a file or to the standard output. Can be &quot;file&quot; or &quot;stdout&quot;. Default is &quot;stdout&quot;. |
| `PLAYWRIGHT_MCP_PORT` port to listen on for SSE transport. |
| `PLAYWRIGHT_MCP_PROXY_BYPASS` comma-separated domains to bypass proxy, for example &quot;.com,chromium.org,.domain.com&quot; |
| `PLAYWRIGHT_MCP_PROXY_SERVER` specify proxy server, for example &quot;http://myproxy:3128&quot; or &quot;socks5://myproxy:8080&quot; |
| `PLAYWRIGHT_MCP_SAVE_SESSION` Whether to save the Playwright MCP session into the output directory. |
| `PLAYWRIGHT_MCP_SAVE_TRACE` Whether to save the Playwright Trace of the session into the output directory. |
| `PLAYWRIGHT_MCP_SAVE_VIDEO` Whether to save the video of the session into the output directory. For example &quot;--save-video=800x600&quot; |
| `PLAYWRIGHT_MCP_SECRETS` path to a file containing secrets in the dotenv format |
| `PLAYWRIGHT_MCP_SHARED_BROWSER_CONTEXT` reuse the same browser context between all connected HTTP clients. |
| `PLAYWRIGHT_MCP_SNAPSHOT_MODE` when taking snapshots for responses, specifies the mode to use. Can be &quot;incremental&quot;, &quot;full&quot;, or &quot;none&quot;. Default is incremental. |
| `PLAYWRIGHT_MCP_STORAGE_STATE` path to the storage state file for isolated sessions. |
| `PLAYWRIGHT_MCP_TEST_ID_ATTRIBUTE` specify the attribute to use for test ids, defaults to &quot;data-testid&quot; |
| `PLAYWRIGHT_MCP_TIMEOUT_ACTION` specify action timeout in milliseconds, defaults to 5000ms |
| `PLAYWRIGHT_MCP_TIMEOUT_NAVIGATION` specify navigation timeout in 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[abhigyanpatwari/GitNexus]]></title>
            <link>https://github.com/abhigyanpatwari/GitNexus</link>
            <guid>https://github.com/abhigyanpatwari/GitNexus</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:27 GMT</pubDate>
            <description><![CDATA[GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/abhigyanpatwari/GitNexus">abhigyanpatwari/GitNexus</a></h1>
            <p>GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,748</p>
            <p>Forks: 618</p>
            <p>Stars today: 582 stars today</p>
            <h2>README</h2><pre># GitNexus

&lt;div align=&quot;center&quot;&gt;

  &lt;a href=&quot;https://trendshift.io/repositories/19809&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/19809&quot; alt=&quot;abhigyanpatwari%2FGitNexus | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;

  &lt;h2&gt;Join the official Discord to discuss ideas, issues etc!&lt;/h2&gt;

  &lt;a href=&quot;https://discord.gg/AAsRVT6fGb&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1477255801545429032?color=5865F2&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Discord&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/gitnexus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/gitnexus.svg&quot; alt=&quot;npm version&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://polyformproject.org/licenses/noncommercial/1.0.0/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-PolyForm%20Noncommercial-blue.svg&quot; alt=&quot;License: PolyForm Noncommercial&quot;/&gt;
  &lt;/a&gt;

&lt;/div&gt;

**Building nervous system for agent context.**

Indexes any codebase into a knowledge graph ‚Äî every dependency, call chain, cluster, and execution flow ‚Äî then exposes it through smart tools so AI agents never miss code.




https://github.com/user-attachments/assets/172685ba-8e54-4ea7-9ad1-e31a3398da72



&gt; *Like DeepWiki, but deeper.* DeepWiki helps you *understand* code. GitNexus lets you *analyze* it ‚Äî because a knowledge graph tracks every relationship, not just descriptions.

**TL;DR:** The **Web UI** is a quick way to chat with any repo. The **CLI + MCP** is how you make your AI agent actually reliable ‚Äî it gives Cursor, Claude Code, and friends a deep architectural view of your codebase so they stop missing dependencies, breaking call chains, and shipping blind edits. Even smaller models get full architectural clarity, making it compete with goliath models.

---

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=abhigyanpatwari/GitNexus&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#abhigyanpatwari/GitNexus&amp;type=date&amp;legend=top-left)


## Two Ways to Use GitNexus

|                   | **CLI + MCP**                                            | **Web UI**                                             |
| ----------------- | -------------------------------------------------------------- | ------------------------------------------------------------ |
| **What**    | Index repos locally, connect AI agents via MCP                 | Visual graph explorer + AI chat in browser                   |
| **For**     | Daily development with Cursor, Claude Code, Windsurf, OpenCode | Quick exploration, demos, one-off analysis                   |
| **Scale**   | Full repos, any size                                           | Limited by browser memory (~5k files), or unlimited via backend mode |
| **Install** | `npm install -g gitnexus`                                    | No install ‚Äî[gitnexus.vercel.app](https://gitnexus.vercel.app) |
| **Storage** | KuzuDB native (fast, persistent)                               | KuzuDB WASM (in-memory, per session)                         |
| **Parsing** | Tree-sitter native bindings                                    | Tree-sitter WASM                                             |
| **Privacy** | Everything local, no network                                   | Everything in-browser, no server                             |

&gt; **Bridge mode:** `gitnexus serve` connects the two ‚Äî the web UI auto-detects the local server and can browse all your CLI-indexed repos without re-uploading or re-indexing.

---

## CLI + MCP (recommended)

The CLI indexes your repository and runs an MCP server that gives AI agents deep codebase awareness.

### Quick Start

```bash
# Index your repo (run from repo root)
npx gitnexus analyze
```

That&#039;s it. This indexes the codebase, installs agent skills, registers Claude Code hooks, and creates `AGENTS.md` / `CLAUDE.md` context files ‚Äî all in one command.

To configure MCP for your editor, run `npx gitnexus setup` once ‚Äî or set it up manually below.

### MCP Setup

`gitnexus setup` auto-detects your editors and writes the correct global MCP config. You only need to run it once.

### Editor Support

| Editor                | MCP | Skills | Hooks (auto-augment) | Support        |
| --------------------- | --- | ------ | -------------------- | -------------- |
| **Claude Code** | Yes | Yes    | Yes (PreToolUse)     | **Full** |
| **Cursor**      | Yes | Yes    | ‚Äî                   | MCP + Skills   |
| **Windsurf**    | Yes | ‚Äî     | ‚Äî                   | MCP            |
| **OpenCode**    | Yes | Yes    | ‚Äî                   | MCP + Skills   |

&gt; **Claude Code** gets the deepest integration: MCP tools + agent skills + PreToolUse hooks that automatically enrich grep/glob/bash calls with knowledge graph context.

### Community Integrations

| Agent | Install | Source |
|-------|---------|--------|
| [pi](https://pi.dev) | `pi install npm:pi-gitnexus` | [pi-gitnexus](https://github.com/tintinweb/pi-gitnexus) |

If you prefer manual configuration:

**Claude Code** (full support ‚Äî MCP + skills + hooks):

```bash
claude mcp add gitnexus -- npx -y gitnexus@latest mcp
```

**Cursor** (`~/.cursor/mcp.json` ‚Äî global, works for all projects):

```json
{
  &quot;mcpServers&quot;: {
    &quot;gitnexus&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;gitnexus@latest&quot;, &quot;mcp&quot;]
    }
  }
}
```

**OpenCode** (`~/.config/opencode/config.json`):

```json
{
  &quot;mcp&quot;: {
    &quot;gitnexus&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;gitnexus@latest&quot;, &quot;mcp&quot;]
    }
  }
}
```

### CLI Commands

```bash
gitnexus setup                    # Configure MCP for your editors (one-time)
gitnexus analyze [path]           # Index a repository (or update stale index)
gitnexus analyze --force          # Force full re-index
gitnexus analyze --skip-embeddings  # Skip embedding generation (faster)
gitnexus mcp                     # Start MCP server (stdio) ‚Äî serves all indexed repos
gitnexus serve                   # Start local HTTP server (multi-repo) for web UI connection
gitnexus list                    # List all indexed repositories
gitnexus status                  # Show index status for current repo
gitnexus clean                   # Delete index for current repo
gitnexus clean --all --force     # Delete all indexes
gitnexus wiki [path]             # Generate repository wiki from knowledge graph
gitnexus wiki --model &lt;model&gt;    # Wiki with custom LLM model (default: gpt-4o-mini)
gitnexus wiki --base-url &lt;url&gt;   # Wiki with custom LLM API base URL
```

### What Your AI Agent Gets

**7 tools** exposed via MCP:

| Tool               | What It Does                                                      | `repo` Param |
| ------------------ | ----------------------------------------------------------------- | -------------- |
| `list_repos`     | Discover all indexed repositories                                 | ‚Äî             |
| `query`          | Process-grouped hybrid search (BM25 + semantic + RRF)             | Optional       |
| `context`        | 360-degree symbol view ‚Äî categorized refs, process participation | Optional       |
| `impact`         | Blast radius analysis with depth grouping and confidence          | Optional       |
| `detect_changes` | Git-diff impact ‚Äî maps changed lines to affected processes       | Optional       |
| `rename`         | Multi-file coordinated rename with graph + text search            | Optional       |
| `cypher`         | Raw Cypher graph queries                                          | Optional       |

&gt; When only one repo is indexed, the `repo` parameter is optional. With multiple repos, specify which one: `query({query: &quot;auth&quot;, repo: &quot;my-app&quot;})`.

**Resources** for instant context:

| Resource                                  | Purpose                                              |
| ----------------------------------------- | ---------------------------------------------------- |
| `gitnexus://repos`                      | List all indexed repositories (read this first)      |
| `gitnexus://repo/{name}/context`        | Codebase stats, staleness check, and available tools |
| `gitnexus://repo/{name}/clusters`       | All functional clusters with cohesion scores         |
| `gitnexus://repo/{name}/cluster/{name}` | Cluster members and details                          |
| `gitnexus://repo/{name}/processes`      | All execution flows                                  |
| `gitnexus://repo/{name}/process/{name}` | Full process trace with steps                        |
| `gitnexus://repo/{name}/schema`         | Graph schema for Cypher queries                      |

**2 MCP prompts** for guided workflows:

| Prompt            | What It Does                                                              |
| ----------------- | ------------------------------------------------------------------------- |
| `detect_impact` | Pre-commit change analysis ‚Äî scope, affected processes, risk level       |
| `generate_map`  | Architecture documentation from the knowledge graph with mermaid diagrams |

**4 agent skills** installed to `.claude/skills/` automatically:

- **Exploring** ‚Äî Navigate unfamiliar code using the knowledge graph
- **Debugging** ‚Äî Trace bugs through call chains
- **Impact Analysis** ‚Äî Analyze blast radius before changes
- **Refactoring** ‚Äî Plan safe refactors using dependency mapping

---

## Multi-Repo MCP Architecture

GitNexus uses a **global registry** so one MCP server can serve multiple indexed repos. No per-project MCP config needed ‚Äî set it up once and it works everywhere.

```mermaid
flowchart TD
    subgraph CLI [CLI Commands]
        Setup[&quot;gitnexus setup&quot;]
        Analyze[&quot;gitnexus analyze&quot;]
        Clean[&quot;gitnexus clean&quot;]
        List[&quot;gitnexus list&quot;]
    end

    subgraph Registry [&quot;~/.gitnexus/&quot;]
        RegFile[&quot;registry.json&quot;]
    end

    subgraph Repos [Project Repos]
        RepoA[&quot;.gitnexus/ in repo A&quot;]
        RepoB[&quot;.gitnexus/ in repo B&quot;]
    end

    subgraph MCP [MCP Server]
        Server[&quot;server.ts&quot;]
        Backend[&quot;LocalBackend&quot;]
        Pool[&quot;Connection Pool&quot;]
        ConnA[&quot;KuzuDB conn A&quot;]
        ConnB[&quot;KuzuDB conn B&quot;]
    end

    Setup --&gt;|&quot;writes global MCP config&quot;| CursorConfig[&quot;~/.cursor/mcp.json&quot;]
    Analyze --&gt;|&quot;registers repo&quot;| RegFile
    Analyze --&gt;|&quot;stores index&quot;| RepoA
    Clean --&gt;|&quot;unregisters repo&quot;| RegFile
    List --&gt;|&quot;reads&quot;| RegFile
    Server --&gt;|&quot;reads registry&quot;| RegFile
    Server --&gt; Backend
    Backend --&gt; Pool
    Pool --&gt;|&quot;lazy open&quot;| ConnA
    Pool --&gt;|&quot;lazy open&quot;| ConnB
    ConnA --&gt;|&quot;queries&quot;| RepoA
    ConnB --&gt;|&quot;queries&quot;| RepoB
```

**How it works:** Each `gitnexus analyze` stores the index in `.gitnexus/` inside the repo (portable, gitignored) and registers a pointer in `~/.gitnexus/registry.json`. When an AI agent starts, the MCP server reads the registry and can serve any indexed repo. KuzuDB connections are opened lazily on first query and evicted after 5 minutes of inactivity (max 5 concurrent). If only one repo is indexed, the `repo` parameter is optional on all tools ‚Äî agents don&#039;t need to change anything.

---

## Web UI (browser-based)

A fully client-side graph explorer and AI chat. No server, no install ‚Äî your code never leaves the browser.

**Try it now:** [gitnexus.vercel.app](https://gitnexus.vercel.app) ‚Äî drag &amp; drop a ZIP and start exploring.

&lt;img width=&quot;2550&quot; height=&quot;1343&quot; alt=&quot;gitnexus_img&quot; src=&quot;https://github.com/user-attachments/assets/cc5d637d-e0e5-48e6-93ff-5bcfdb929285&quot; /&gt;

Or run locally:

```bash
git clone https://github.com/abhigyanpatwari/gitnexus.git
cd gitnexus/gitnexus-web
npm install
npm run dev
```

The web UI uses the same indexing pipeline as the CLI but runs entirely in WebAssembly (Tree-sitter WASM, KuzuDB WASM, in-browser embeddings). It&#039;s great for quick exploration but limited by browser memory for larger repos.

**Local Backend Mode:** Run `gitnexus serve` and open the web UI locally ‚Äî it auto-detects the server and shows all your indexed repos, with full AI chat support. No need to re-upload or re-index. The agent&#039;s tools (Cypher queries, search, code navigation) route through the backend HTTP API automatically.

---

## The Problem GitNexus Solves

Tools like **Cursor**, **Claude Code**, **Cline**, **Roo Code**, and **Windsurf** are powerful ‚Äî but they don&#039;t truly know your codebase structure.

**What happens:**

1. AI edits `UserService.validate()`
2. Doesn&#039;t know 47 functions depend on its return type
3. **Breaking changes ship**

### Traditional Graph RAG vs GitNexus

Traditional approaches give the LLM raw graph edges and hope it explores enough. GitNexus **precomputes structure at index time** ‚Äî clustering, tracing, scoring ‚Äî so tools return complete context in one call:

```mermaid
flowchart TB
    subgraph Traditional[&quot;Traditional Graph RAG&quot;]
        direction TB
        U1[&quot;User: What depends on UserService?&quot;]
        U1 --&gt; LLM1[&quot;LLM receives raw graph&quot;]
        LLM1 --&gt; Q1[&quot;Query 1: Find callers&quot;]
        Q1 --&gt; Q2[&quot;Query 2: What files?&quot;]
        Q2 --&gt; Q3[&quot;Query 3: Filter tests?&quot;]
        Q3 --&gt; Q4[&quot;Query 4: High-risk?&quot;]
        Q4 --&gt; OUT1[&quot;Answer after 4+ queries&quot;]
    end

    subgraph GN[&quot;GitNexus Smart Tools&quot;]
        direction TB
        U2[&quot;User: What depends on UserService?&quot;]
        U2 --&gt; TOOL[&quot;impact UserService upstream&quot;]
        TOOL --&gt; PRECOMP[&quot;Pre-structured response:
        8 callers, 3 clusters, all 90%+ confidence&quot;]
        PRECOMP --&gt; OUT2[&quot;Complete answer, 1 query&quot;]
    end
```

**Core innovation: Precomputed Relational Intelligence**

- **Reliability** ‚Äî LLM can&#039;t miss context, it&#039;s already in the tool response
- **Token efficiency** ‚Äî No 10-query chains to understand one function
- **Model democratization** ‚Äî Smaller LLMs work because tools do the heavy lifting

---

## How It Works

GitNexus builds a complete knowledge graph of your codebase through a multi-phase indexing pipeline:

1. **Structure** ‚Äî Walks the file tree and maps folder/file relationships
2. **Parsing** ‚Äî Extracts functions, classes, methods, and interfaces using Tree-sitter ASTs
3. **Resolution** ‚Äî Resolves imports and function calls across files with language-aware logic
4. **Clustering** ‚Äî Groups related symbols into functional communities
5. **Processes** ‚Äî Traces execution flows from entry points through call chains
6. **Search** ‚Äî Builds hybrid search indexes for fast retrieval

### Supported Languages

TypeScript, JavaScript, Python, Java, C, C++, C#, Go, Rust, PHP, Swift

---

## Tool Examples

### Impact Analysis

```
impact({target: &quot;UserService&quot;, direction: &quot;upstream&quot;, minConfidence: 0.8})

TARGET: Class UserService (src/services/user.ts)

UPSTREAM (what depends on this):
  Depth 1 (WILL BREAK):
    handleLogin [CALLS 90%] -&gt; src/api/auth.ts:45
    handleRegister [CALLS 90%] -&gt; src/api/auth.ts:78
    UserController [CALLS 85%] -&gt; src/controllers/user.ts:12
  Depth 2 (LIKELY AFFECTED):
    authRouter [IMPORTS] -&gt; src/routes/auth.ts
```

Options: `maxDepth`, `minConfidence`, `relationTypes` (`CALLS`, `IMPORTS`, `EXTENDS`, `IMPLEMENTS`), `includeTests`

### Process-Grouped Search

```
query({query: &quot;authentication middleware&quot;})

processes:
  - summary: &quot;LoginFlow&quot;
    priority: 0.042
    symbol_count: 4
    process_type: cross_community
    step_count: 7

process_symbols:
  - name: validateUser
    type: Function
    filePath: src/auth/validate.ts
    process_id: proc_login
    step_index: 2

definitions:
  - name: AuthConfig
    type: Interface
    filePath: src/types/auth.ts
```

### Context (360-degree Symbol View)

```
context({name: &quot;validateUser&quot;})

symbol:
  uid: &quot;Function:validateUser&quot;
  kind: Function
  filePath: src/auth/validate.ts
  startLine: 15

incoming:
  calls: [handleLogin, handleRegister, UserController]
  imports: [authRouter]

outgoing:
  calls: [checkPassword, createSession]

processes:
  - name: LoginFlow (step 2/7)
  - name: RegistrationFlow (step 3/5)
```

### Detect Changes (Pre-Commit)

```
detect_changes({scope: &quot;all&quot;})

summary:
  changed_count: 12
  affected_count: 3
  changed_files: 4
  risk_level: medium

changed_symbols: [validateUser, AuthService, ...]
affected_processes: [LoginFlow, RegistrationFlow, ...]
```

### Rename (Multi-File)

```
rename({symbol_name: &quot;validateUser&quot;, new_name: &quot;verifyUser&quot;, dry_run: true})

status: success
files_affected: 5
total_edits: 8
graph_edits: 6     (high confidence)
text_search_edits: 2  (review carefully)
changes: [...]
```

### Cypher Queries

```cypher
-- Find what calls auth functions with high confidence
MATCH (c:Community {heuristicLabel: &#039;Authentication&#039;})&lt;-[:CodeRelation {type: &#039;MEMBER_OF&#039;}]-(fn)
MATCH (caller)-[r:CodeRelation {type: &#039;CALLS&#039;}]-&gt;(fn)
WHERE r.confidence &gt; 0.8
RETURN caller.name, fn.name, r.confidence
ORDER BY r.confidence DESC
```

---

## Wiki Generation

Generate LLM-powered documentation from your knowledge graph:

```bash
# Requires an LLM API key (OPENAI_API_KEY, etc.)
gitnexus wiki

# Use a custom model or provider
gitnexus wiki --model gpt-4o
gitnexus wiki --base-url https://api.anthropic.com/v1

# Force full regeneration
gitnexus wiki --force
```

The wiki generator reads the indexed graph structure, groups files into modules via LLM, generates per-module documentation pages, and creates an overview page ‚Äî all with cross-references to the knowledge graph.

---

## Tech Stack

| Layer                     | CLI                                   | Web                                     |
| ------------------------- | ------------------------------------- | --------------------------------------- |
| **Runtime**         | Node.js (native)                      | Browser (WASM)                          |
| **Parsing**         | Tree-sitter native bindings           | Tree-sitter WASM                        |
| **Database**        | KuzuDB native                         | KuzuDB WASM                             |
| **Embeddings**      | HuggingFace transformers.js (GPU/CPU) | transformers.js (WebGPU/WASM)           |
| **Search**          | BM25 + semantic + RRF                 | BM25 + semantic + RRF                   |
| **Agent Interface** | MCP (stdio)                           | LangChain ReAct agent                   |
| **Visualization**   | ‚Äî                                    | Sigma.js + Graphology (WebGL)           |
| **Frontend**        | ‚Äî                                    | React 18, TypeScript, Vite, Tailwind v4 |
| **Clustering**      | Graphology                            | Graphology                              |
| **Concurrency**     | Worker threads + async                | Web Workers + Comlink                   |

---

## Roadmap

### Actively Building

- [ ] **LLM Cluster Enrichment** ‚Äî Semantic cluster names via LLM API
- [ ] **AST Decorator Detection** ‚Äî Parse @Controller, @Get, etc.
- [ ] **Incremental Indexing** ‚Äî Only re-index changed files

### Recently Completed

- [X] Wiki Generation, Multi-File Rename, Git-Diff Impact Analysis
- [X] Process-Grouped Search, 360-Degree Context, Claude Code Hooks
- [X] Multi-Repo MCP, Zero-Config Setup, 11 Language Support
- [X] Community Detection, Process Detection, Confidence Scoring
- [X] Hybrid Search, Vector Index

---

## Security &amp; Privacy

- **CLI**: Everything runs locally on your machine. No network calls. Index stored in `.gitnexus/` (gitignored). Global registry at `~/.gitnexus/` stores only paths and metadata.
- **Web**: Everything runs in your browser. No code uploaded to any server. API keys stored in localStorage only.
- Open source ‚Äî audit the code yourself.

---

## Acknowledgments

- [Tree-sitter](https://tree-sitter.github.io/) ‚Äî AST parsing
- [KuzuDB](https://kuzudb.com/) ‚Äî Embedded graph database with vector support
- [Sigma.js](https://www.sigmajs.org/) ‚Äî WebGL graph rendering
- [transformers.js](https://huggingface.co/docs/transformers.js) ‚Äî Browser ML
- [Graphology](https://graphology.github.io/) ‚Äî Graph data structures
- [MCP](https://modelcontextprotocol.io/) ‚Äî Model Context Protocol
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[dontriskit/awesome-ai-system-prompts]]></title>
            <link>https://github.com/dontriskit/awesome-ai-system-prompts</link>
            <guid>https://github.com/dontriskit/awesome-ai-system-prompts</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:26 GMT</pubDate>
            <description><![CDATA[üß† Curated collection of system prompts for top AI tools. Perfect for AI agent builders and prompt engineers. Incuding: ChatGPT, Claude, Perplexity, Manus, Claude-Code, Loveable, v0, Grok, same new, windsurf, notion, and MetaAI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dontriskit/awesome-ai-system-prompts">dontriskit/awesome-ai-system-prompts</a></h1>
            <p>üß† Curated collection of system prompts for top AI tools. Perfect for AI agent builders and prompt engineers. Incuding: ChatGPT, Claude, Perplexity, Manus, Claude-Code, Loveable, v0, Grok, same new, windsurf, notion, and MetaAI.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 5,362</p>
            <p>Forks: 823</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre># Crafting Effective Prompts for Agentic AI Systems: Patterns and Practices

## Table of Contents

*   [Introduction: The Blueprint of Agentic AI](#introduction-the-blueprint-of-agentic-ai)
*   [The Foundation: Core Principles of Agentic Prompts](#the-foundation-core-principles-of-agentic-prompts)
    *   [1. Clear Role Definition and Scope](#1-clear-role-definition-and-scope)
    *   [2. Structured Instructions and Organization](#2-structured-instructions-and-organization)
    *   [3. Explicit Tool Integration and Usage Guidelines](#3-explicit-tool-integration-and-usage-guidelines)
    *   [4. Step-by-Step Reasoning and Planning](#4-step-by-step-reasoning-and-planning)
    *   [5. Environment and Context Awareness](#5-environment-and-context-awareness)
    *   [6. Domain-Specific Expertise and Constraints](#6-domain-specific-expertise-and-constraints)
    *   [7. Safety, Alignment, and Refusal Protocols](#7-safety-alignment-and-refusal-protocols)
    *   [8. Consistent Tone and Interaction Style](#8-consistent-tone-and-interaction-style)
*   [Case Studies: Analyzing Real-World Prompts](#case-studies-analyzing-real-world-prompts)
    *   [Vercel v0: UI Generation &amp; Component Tooling](#vercel-v0-ui-generation--component-tooling)
    *   [same.new: Agentic Pair Programming &amp; Strict Tooling](#samenew-agentic-pair-programming--strict-tooling)
    *   [Manus: General Purpose Agent &amp; Explicit Loop](#manus-general-purpose-agent--explicit-loop)
    *   [OpenAI ChatGPT (GPT-4.5/4o): Integrated Tools &amp; Policies](#openai-chatgpt-gpt-454o-integrated-tools--policies)
    *   [Notes on Other Systems (Cline, Bolt, Augment, Claude Code, Clawdbot)](#notes-on-other-systems-cline-bolt-augment-claude-code-clawdbot)
*   [Synthesizing Best Practices: Key Takeaways for Builders](#synthesizing-best-practices-key-takeaways-for-builders)
*   [Unique Conventions &amp; Architectural Differences](#unique-conventions--architectural-differences)
*   [Conclusion: Building the Agentic Future](#conclusion-building-the-agentic-future)
*   [Visual AI Agent: Harpagan](https://harpagan.com)


---

## Introduction: The Blueprint of Agentic AI

The rise of agentic Artificial Intelligence (AI) systems marks a significant shift from purely conversational models to AI that can actively perform tasks, interact with tools, and pursue complex goals autonomously. These systems, capable of planning, executing commands, editing files, browsing the web, and more, promise to revolutionize how we interact with technology and augment human capabilities.

At the heart of every effective agentic AI lies its **system prompt**. More than just initial instructions, the system prompt serves as the foundational blueprint, the operational manual, or even the &quot;constitution&quot; guiding the AI&#039;s behavior, capabilities, limitations, and persona. A well-crafted system prompt is critical for ensuring the agent acts reliably, safely, and effectively towards the user&#039;s goals.

This guide delves into the art and science of crafting these crucial prompts. By analyzing a diverse collection of real-world system prompts from the [awesome-ai-system-prompts](https://github.com/dontriskit/awesome-ai-system-prompts) repository ‚Äì specifically focusing on examples from Vercel&#039;s v0, same.new, Manus, OpenAI&#039;s ChatGPT, and others ‚Äì we can identify recurring patterns and best practices. For builders shaping the agentic future of 2025 and beyond, understanding these patterns is essential for creating powerful, predictable, and trustworthy AI assistants.

---

## The Foundation: Core Principles of Agentic Prompts

Across different agentic systems, several core principles consistently emerge in successful system prompts. These form the foundation upon which complex agent behavior is built.

### 1. Clear Role Definition and Scope

**Why it matters:** Explicitly defining the AI&#039;s identity, core function, and operational domain anchors its behavior, sets user expectations, and helps prevent scope creep or nonsensical responses. It tells the AI *who* it is and *what* it&#039;s supposed to do.

&gt; **Practical Examples:**
&gt;
&gt; *   **Vercel v0:** Immediately states its identity and specialization.
&gt;     ```
&gt;     You are v0, Vercel&#039;s AI-powered assistant.
&gt;     ```
&gt;     *[Source: v0/v0.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/v0/v0.md)*
&gt;
&gt; *   **same.new:** Defines role, capability level, and exclusive environment.
&gt;     ```
&gt;     You are a powerful agentic AI coding assistant. You operate exclusively in Same, the world&#039;s best cloud-based IDE.
&gt;     ```
&gt;     *[Source: same.new/same.new.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/same.new/same.new.md)*
&gt;
&gt; *   **Manus:** Introduces itself and lists broad task categories it excels at.
&gt;     ```
&gt;     You are Manus, an AI agent created by the Manus team.
&gt;
&gt;     You excel at the following tasks:
&gt;     1. Information gathering...
&gt;     2. Data processing...
&gt;     3. Writing multi-chapter articles...
&gt;     ...
&gt;     ```
&gt;     *[Source: Manus/AgentLoop.txt](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Manus/AgentLoop.txt)*
&gt;
&gt; *   **ChatGPT (4.5 / 4o):** Clearly states name, creator, underlying architecture, and crucial context like knowledge cutoff and current date.
&gt;     ```
&gt;     You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4.5 architecture.
&gt;     Knowledge cutoff: 2023-10
&gt;     Current date: 2025-04-05
&gt;
&gt;     Image input capabilities: Enabled
&gt;     Personality: v2
&gt;     ```
&gt;     *[Source: ChatGPT/4-5.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/ChatGPT/4-5.md)*
&gt;
&gt; *   **Claude:** Establishes a persona beyond just being a tool.
&gt;     ```
&gt;     The assistant is Claude, created by Anthropic.
&gt;
&gt;     Claude enjoys helping humans and sees its role as an intelligent and kind assistant to the people, with depth and wisdom that makes it more than a mere tool.
&gt;     ```
&gt;     *[Source: Claude/Claude-Sonnet-3.7.txt](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Claude/Claude-Sonnet-3.7.txt)*

### 2. Structured Instructions and Organization

**Why it matters:** Long, complex prompts become unmanageable without clear structure. Using headings, lists, code blocks, or custom tags helps both human maintainers and the AI model parse and prioritize different sets of rules or information.

&gt; **Practical Examples:**
&gt;
&gt; *   **v0 &amp; ChatGPT:** Use Markdown headings extensively (e.g., `## General Instructions`, `# Tools`, `## Refusals`).
&gt;     *[Source: v0/v0.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/v0/v0.md)*
&gt;
&gt; *   **same.new:** Employs custom XML-like tags to encapsulate rule sets (e.g., `&lt;tool_calling&gt;`, `&lt;making_code_changes&gt;`).
&gt;     *[Source: same.new/same.new.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/same.new/same.new.md)*
&gt;
&gt; *   **Manus:** Organizes capabilities and rules using descriptive tags in `Modules.md` (e.g., `&lt;system_capability&gt;`, `&lt;agent_loop&gt;`, `&lt;tool_use_rules&gt;`).
&gt;     *[Source: Manus/Modules.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Manus/Modules.md)*
&gt;
&gt; *   **ChatGPT:** Uses Markdown headings (`# Tools`, `## bio`) and code blocks (```` ```typescript ... ``` ````) to define tool schemas and policies.
&gt;     *[Source: ChatGPT/4-5.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/ChatGPT/4-5.md)*
&gt;
&gt; *   **Cline:** Uses hierarchical Markdown headings (`# Tool Use Formatting`, `## execute_command`) and lists under sections like `CAPABILITIES` and `RULES`.
&gt;     *[Source: Cline/system.ts](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Cline/system.ts)*

### 3. Explicit Tool Integration and Usage Guidelines

**Why it matters:** For agentic behavior, the AI *must* understand its tools: what they are, what they do, how to call them (syntax, parameters), required format (e.g., XML, JSON), and crucially, *when* and *when not* to use them. This requires detailed descriptions, clear schemas, and explicit rules.

&gt; **Practical Examples:**
&gt;
&gt; *   **ChatGPT:** Provides function schemas (TypeScript definitions) and detailed policies directly within the prompt for tools like `dalle` and `canmore`.
&gt;     ```typescript
&gt;     // Example for dalle tool policy within ChatGPT prompt
&gt;     namespace dalle {
&gt;     // Create images from a text-only prompt.
&gt;     type text2im = (_: {
&gt;     // The size of the requested image...
&gt;     size?: (&quot;1792x1024&quot; | &quot;1024x1024&quot; | &quot;1024x1792&quot;),
&gt;     // The number of images to generate...
&gt;     n?: number, // default: 1
&gt;     // The detailed image description...
&gt;     prompt: string,
&gt;     // If the user references a previous image...
&gt;     referenced_image_ids?: string[],
&gt;     }) =&gt; any;
&gt;     } // namespace dalle
&gt;     ```
&gt;     *[Source: ChatGPT/4-5.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/ChatGPT/4-5.md)*
&gt;
&gt; *   **same.new:** Dedicates a `&lt;tool_calling&gt;` section detailing rules like adhering to schemas, not mentioning tool names to the user, and explaining the *why* before calling a tool. References `functions-schema.json` (not shown in full, but implied structure).
&gt;     ```xml
&gt;     &lt;tool_calling&gt;
&gt;       ...
&gt;       1. ALWAYS follow the tool call schema exactly...
&gt;       3. **NEVER refer to tool names when speaking to the USER.**...
&gt;       5. Before calling each tool, first explain to the USER why you are calling it.
&gt;     &lt;/tool_calling&gt;
&gt;     ```
&gt;     *[Source: same.new/same.new.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/same.new/same.new.md)* | *[Schema: same.new/functions-schema.json](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/same.new/functions-schema.json)*
&gt;
&gt; *   **Manus:** Defines tools externally in `tools.json` (schema provided) and includes rules in `Modules.md` like prioritizing data APIs over web search.
&gt;     ```json
&gt;     // Snippet from Manus/tools.json
&gt;     {
&gt;       &quot;type&quot;: &quot;function&quot;,
&gt;       &quot;function&quot;: {
&gt;         &quot;name&quot;: &quot;shell_exec&quot;,
&gt;         &quot;description&quot;: &quot;Execute commands in a specified shell session...&quot;,
&gt;         &quot;parameters&quot;: { ... }
&gt;       }
&gt;     }
&gt;     ```
&gt;     *[Source: Manus/tools.json](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Manus/tools.json)* | *[Rules: Manus/Modules.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Manus/Modules.md)*
&gt;
&gt; *   **Cline &amp; Augment:** Integrate detailed tool descriptions, parameters, and usage examples directly into the main system prompt using XML-like tags or structured text.
&gt;     ```markdown
&gt;     // Cline example tool definition
&gt;     ## execute_command
&gt;     Description: Request to execute a CLI command...
&gt;     Parameters:
&gt;     - command: (required) The CLI command...
&gt;     - requires_approval: (required) A boolean indicating...
&gt;     Usage:
&gt;     &lt;execute_command&gt;
&gt;     &lt;command&gt;Your command here&lt;/command&gt;
&gt;     &lt;requires_approval&gt;true or false&lt;/requires_approval&gt;
&gt;     &lt;/execute_command&gt;
&gt;     ```
&gt;     *[Source: Cline/system.ts](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Cline/system.ts)*
&gt;
&gt; *   **Bolt.new:** Uses a dedicated `&lt;artifact_instructions&gt;` section detailing how to format tool outputs (`&lt;boltAction type=&quot;shell&quot;&gt;`, `&lt;boltAction type=&quot;file&quot; filePath=&quot;...&quot;&gt;`) within a main `&lt;boltArtifact&gt;` tag.
&gt;     *[Source: Bolt.new/prompts.ts](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Bolt.new/prompts.ts)*
&gt;
&gt; *   **v0:** Defines custom MDX components like `&lt;CodeProject&gt;`, `&lt;QuickEdit&gt;`, `&lt;DeleteFile /&gt;` as its &#039;tools&#039;, with rules on when and how to use them within responses.
&gt;     *[Source: v0/v0-tools.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/v0/v0-tools.md)*

### 4. Step-by-Step Reasoning and Planning

**Why it matters:** Complex tasks require breaking down problems. Successful prompts guide the AI to think methodically, plan its actions, execute iteratively, and wait for feedback or results before proceeding, reducing errors and improving coherence.

&gt; **Practical Examples:**
&gt;
&gt; *   **Manus:** Features the most explicit planning mechanism with its defined `&lt;agent_loop&gt;` in `Modules.md`.
&gt;     ```
&gt;     &lt;agent_loop&gt;
&gt;     You are operating in an agent loop, iteratively completing tasks through these steps:
&gt;     1. Analyze Events...
&gt;     2. Select Tools...
&gt;     3. Wait for Execution...
&gt;     4. Iterate: Choose only one tool call per iteration...
&gt;     5. Submit Results...
&gt;     6. Enter Standby...
&gt;     &lt;/agent_loop&gt;
&gt;     ```
&gt;     *[Source: Manus/Modules.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Manus/Modules.md)*
&gt;
&gt; *   **v0:** Uses a dedicated thinking phase before generating code.
&gt;     ```
&gt;     BEFORE creating a Code Project, v0 uses &lt;Thinking&gt; tags to think through the project structure...
&gt;     ```
&gt;     *[Source: v0/v0.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/v0/v0.md)*
&gt;
&gt; *   **same.new &amp; Cline:** Mandate waiting for user confirmation/tool results after each step.
&gt;     ```
&gt;     ALWAYS wait for user confirmation after each tool use before proceeding. Never assume the success of a tool use...
&gt;     *(From same.new &amp; Cline prompts)*
&gt;     ```
&gt;     *[Source: same.new/same.new.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/same.new/same.new.md) | [Cline/system.ts](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Cline/system.ts)*
&gt;
&gt; *   **Bolt.new:** Emphasizes holistic thinking *before* action.
&gt;     ```
&gt;     CRITICAL: Think HOLISTICALLY and COMPREHENSIVELY BEFORE creating an artifact. This means: Consider ALL relevant files... Review ALL previous file changes... Analyze the entire project context... Anticipate potential impacts...
&gt;     ```
&gt;     *[Source: Bolt.new/prompts.ts](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Bolt.new/prompts.ts)*

### 5. Environment and Context Awareness

**Why it matters:** Agents operate within specific environments (OS, IDE, browser sandbox, specific libraries). Providing this context allows the AI to generate compatible code, use appropriate commands, and understand limitations.

&gt; **Practical Examples:**
&gt;
&gt; *   **Cline:** Includes a `SYSTEM INFORMATION` section.
&gt;     ```
&gt;     SYSTEM INFORMATION
&gt;
&gt;     Operating System: ${osName()}
&gt;     Default Shell: ${getShell()}
&gt;     Home Directory: ${os.homedir().toPosix()}
&gt;     Current Working Directory: ${cwd.toPosix()}
&gt;     ```
&gt;     *[Source: Cline/system.ts](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Cline/system.ts)*
&gt;
&gt; *   **Bolt.new:** Provides detailed `&lt;system_constraints&gt;` about the WebContainer environment.
&gt;     ```xml
&gt;     &lt;system_constraints&gt;
&gt;       You are operating in an environment called WebContainer... It does come with a shell that emulates zsh... Available shell commands: cat, chmod, cp...
&gt;     &lt;/system_constraints&gt;
&gt;     ```
&gt;     *[Source: Bolt.new/prompts.ts](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Bolt.new/prompts.ts)*
&gt;
&gt; *   **Manus:** Details the sandbox environment.
&gt;     ```
&gt;     &lt;sandbox_environment&gt;
&gt;     System Environment:
&gt;     - Ubuntu 22.04 (linux/amd64), with internet access
&gt;     - User: `ubuntu`, with sudo privileges
&gt;     ...
&gt;     Development Environment:
&gt;     - Python 3.10.12...
&gt;     - Node.js 20.18.0...
&gt;     &lt;/sandbox_environment&gt;
&gt;     ```
&gt;     *[Source: Manus/Modules.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Manus/Modules.md)*
&gt;
&gt; *   **same.new:** Notes the OS and specific IDE context.
&gt;     ```
&gt;     The OS is Linux 5.15.0-1075-aws (Ubuntu 22.04 LTS). Today is Tue Apr 08 2025.
&gt;     You are pair programming with a USER in Same.
&gt;     USER can see a live preview... in an iframe...
&gt;     ```
&gt;     *[Source: same.new/same.new.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/same.new/same.new.md)*

### 6. Domain-Specific Expertise and Constraints

**Why it matters:** Agents often operate in specific domains (web dev, data analysis, etc.). Prompts embed domain-specific knowledge, best practices, style guides, and constraints (e.g., required libraries, forbidden patterns) to ensure outputs are high-quality and contextually appropriate.

&gt; **Practical Examples:**
&gt;
&gt; *   **v0:** Contains detailed rules for Next.js/React development, shadcn/ui usage, icon libraries, and even AI SDK integration.
&gt;     ```
&gt;     v0 tries to use the shadcn/ui library unless the user specifies otherwise...
&gt;     v0 DOES NOT output &lt;svg&gt; for icons. v0 ALWAYS uses icons from the &quot;lucide-react&quot; package...
&gt;     v0 ONLY uses the AI SDK via &#039;ai&#039; and &#039;@ai-sdk&#039;...
&gt;     ```
&gt;     *[Source: v0/v0.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/v0/v0.md)*
&gt;
&gt; *   **same.new:** Includes sections like `&lt;web_development&gt;` and `&lt;website_cloning&gt;` with specific instructions for those tasks (e.g., preferring Bun, using shadcn CLI correctly, scraping responsibly).
&gt;     *[Source: same.new/same.new.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/same.new/same.new.md)*
&gt;
&gt; *   **Bolt.new:** Includes `&lt;code_formatting_info&gt;` (`Use 2 spaces for code indentation`) and emphasizes splitting functionality into smaller modules.
&gt;     ```
&gt;     IMPORTANT: Prefer writing Node.js scripts instead of shell scripts...
&gt;     IMPORTANT: Use coding best practices and split functionality into smaller modules...
&gt;     ```
&gt;     *[Source: Bolt.new/prompts.ts](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Bolt.new/prompts.ts)*
&gt;
&gt; *   **Loveable:** Specifies React coding guidelines, including Tailwind usage, preferred libraries (shadcn/ui, lucide-react, recharts, @tanstack/react-query), and error handling philosophy.
&gt;     ```
&gt;     ALWAYS try to use the shadcn/ui library.
&gt;     Don&#039;t catch errors with try/catch blocks unless specifically requested...
&gt;     ```
&gt;     *[Source: Loveable/Loveable.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Loveable/Loveable.md)*
&gt;
&gt; *   **Claude Code:** Embeds rules about code style and conventions within `System.js`.
&gt;     ```
&gt;     When making changes to files, first understand the file&#039;s code conventions. Mimic code style, use existing libraries and utilities, and follow existing patterns.
&gt;     IMPORTANT: DO NOT ADD ***ANY*** COMMENTS unless asked
&gt;     ```
&gt;     *[Source: Claude-Code/System.js](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/Claude-Code/System.js)*

### 7. Safety, Alignment, and Refusal Protocols

**Why it matters:** Responsible AI requires clear boundaries. Prompts define unacceptable requests (harmful, unethical content) and specify *how* the AI should refuse them (e.g., standard message, no apology) or handle sensitive operations (e.g., DALL-E content policy).

&gt; **Practical Examples:**
&gt;
&gt; *   **v0:** Uses a standard refusal message and forbids apologies.
&gt;     ```
&gt;     REFUSAL_MESSAGE = &quot;I&#039;m sorry. I&#039;m not able to assist with that.&quot;
&gt;     ...When refusing, v0 MUST NOT apologize or provide an explanation...
&gt;     ```
&gt;     *[Source: v0/v0.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/v0/v0.md)*
&gt;
&gt; *   **ChatGPT:** Contains extensive policies within tool descriptions, like the DALL-E rules regarding artist styles and public figures.
&gt;     ```
&gt;     // DALL-E Policy Snippet from ChatGPT 4.5 prompt
&gt;     // 5. Do not create images in the style of artists... whose latest work was created after 1912...
&gt;     // 7. For requests to create images of any public figure... create images of those who might resemble them... But they shouldn&#039;t look like them.
&gt;     // 8. Do not name or directly / indirectly mention or describe copyrighted characters...
&gt;     ```
&gt;     *[Source: ChatGPT/4-5.md](https://github.com/dontriskit/awesome-ai-system-prompts/blob/main/ChatGPT/4-5.md)*
&gt;
&gt; *   **Claude:** Explicitly states refus

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[gitroomhq/postiz-app]]></title>
            <link>https://github.com/gitroomhq/postiz-app</link>
            <guid>https://github.com/gitroomhq/postiz-app</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:25 GMT</pubDate>
            <description><![CDATA[üì® The ultimate social media scheduling tool, with a bunch of AI ü§ñ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gitroomhq/postiz-app">gitroomhq/postiz-app</a></h1>
            <p>üì® The ultimate social media scheduling tool, with a bunch of AI ü§ñ</p>
            <p>Language: TypeScript</p>
            <p>Stars: 26,884</p>
            <p>Forks: 4,689</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://postiz.com/&quot; target=&quot;_blank&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/765e9d72-3ee7-4a56-9d59-a2c9befe2311&quot;&gt;
    &lt;img alt=&quot;Postiz Logo&quot; src=&quot;https://github.com/user-attachments/assets/f0d30d70-dddb-4142-8876-e9aa6ed1cb99&quot; width=&quot;280&quot;/&gt;
  &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://opensource.org/license/agpl-v3&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/License-AGPL%203.0-blue.svg&quot; alt=&quot;License&quot;&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/gitroomhq/postiz-agent&quot;&gt;NEW: check out Postiz agent CLI! perfect for OpenClaw and other agents&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;strong&gt;
  &lt;h2&gt;Your ultimate AI social media scheduling tool&lt;/h2&gt;&lt;br /&gt;
  &lt;a href=&quot;https://postiz.com&quot;&gt;Postiz&lt;/a&gt;: An alternative to: Buffer.com, Hypefury, Twitter Hunter, etc...&lt;br /&gt;&lt;br /&gt;
  &lt;/strong&gt;
  Postiz offers everything you need to manage your social media posts,&lt;br /&gt;build an audience, capture leads, and grow your business.
&lt;/div&gt;

&lt;div class=&quot;flex&quot; align=&quot;center&quot;&gt;
  &lt;br /&gt;
  &lt;img alt=&quot;Instagram&quot; src=&quot;https://postiz.com/svgs/socials/Instagram.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Youtube&quot; src=&quot;https://postiz.com/svgs/socials/Youtube.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Dribbble&quot; src=&quot;https://postiz.com/svgs/socials/Dribbble.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Linkedin&quot; src=&quot;https://postiz.com/svgs/socials/Linkedin.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Reddit&quot; src=&quot;https://postiz.com/svgs/socials/Reddit.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;TikTok&quot; src=&quot;https://postiz.com/svgs/socials/TikTok.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Facebook&quot; src=&quot;https://postiz.com/svgs/socials/Facebook.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Pinterest&quot; src=&quot;https://postiz.com/svgs/socials/Pinterest.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Threads&quot; src=&quot;https://postiz.com/svgs/socials/Threads.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;X&quot; src=&quot;https://postiz.com/svgs/socials/X.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Slack&quot; src=&quot;https://postiz.com/svgs/socials/Slack.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Discord&quot; src=&quot;https://postiz.com/svgs/socials/Discord.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Mastodon&quot; src=&quot;https://postiz.com/svgs/socials/Mastodon.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Bluesky&quot; src=&quot;https://postiz.com/svgs/socials/Bluesky.svg&quot; width=&quot;32&quot;&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;br /&gt;
  &lt;a href=&quot;https://docs.postiz.com&quot; rel=&quot;dofollow&quot;&gt;&lt;strong&gt;Explore the docs ¬ª&lt;/strong&gt;&lt;/a&gt;
  &lt;br /&gt;

  &lt;br /&gt;
  &lt;a href=&quot;https://youtube.com/@postizofficial&quot; rel=&quot;dofollow&quot;&gt;&lt;strong&gt;Watch the YouTube Tutorials¬ª&lt;/strong&gt;&lt;/a&gt;
  &lt;br /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://platform.postiz.com&quot;&gt;Register&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://discord.postiz.com&quot;&gt;Join Our Discord (devs only)&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://docs.postiz.com/public-api&quot;&gt;Public API&lt;/a&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/@postiz/node&quot;&gt;NodeJS SDK&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://www.npmjs.com/package/n8n-nodes-postiz&quot;&gt;N8N custom node&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://apps.make.com/postiz&quot;&gt;Make.com integration&lt;/a&gt;
&lt;/p&gt;


&lt;br /&gt;

## New - Postiz-as-a-service - Enterprise (Cloud)

Integrate powerful social media scheduling capabilities into your SaaS. &lt;br /&gt;Multi-tenant architecture designed for SaaS companies who want to offer social media management to their users.
- **Skip App Approvals** - Use Postiz apps directly without going through lengthy social platform approval processes. Get the full power of Postiz instantly.
- **Multi-Tenant Architecture** - each of your customers gets their own isolated environment with separate accounts, channels, and team management.
- **Headless API** - Full REST API access to build your own frontend experience. Complete control over the user interface and branding.
- **Full OAuth Support** - Connect all major social platforms including Facebook, Instagram, Twitter, LinkedIn, TikTok, and more.


[Check it here](https://postiz.com/enterprise)

&lt;br /&gt;&lt;br /&gt;

## üîå See the leading Postiz features

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=BdsCVvEYgHU&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Postiz&quot; src=&quot;https://github.com/user-attachments/assets/8b9b7939-da1a-4be5-95be-42c6fce772de&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## ‚ú® Features

| ![Image 1](https://github.com/user-attachments/assets/a27ee220-beb7-4c7e-8c1b-2c44301f82ef) | ![Image 2](https://github.com/user-attachments/assets/eb5f5f15-ed90-47fc-811c-03ccba6fa8a2) |
| ------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |
| ![Image 3](https://github.com/user-attachments/assets/d51786ee-ddd8-4ef8-8138-5192e9cfe7c3) | ![Image 4](https://github.com/user-attachments/assets/91f83c89-22f6-43d6-b7aa-d2d3378289fb) |

### Our Sponsors

| Sponsor |                                  Logo                                   | Description     |
|---------|:-----------------------------------------------------------------------:|-----------------|
| [Hostinger](https://www.hostinger.com/?ref=postiz) | &lt;img src=&quot;.github/sponsors/hostinger.png&quot; alt=&quot;Hostinger&quot; width=&quot;500&quot;/&gt; | Hostinger is on a mission to make online success possible for anyone ‚Äì from developers to aspiring bloggers and business owners |

# Intro

- Schedule all your social media posts (many AI features)
- Measure your work with analytics.
- Collaborate with other team members to exchange or buy posts.
- Invite your team members to collaborate, comment, and schedule posts.
- At the moment there is no difference between the hosted version to the self-hosted version
- Perfect for automation (API) with platforms like N8N, Make.com, Zapier, etc.

## Tech Stack

- Pnpm workspaces (Monorepo)
- NextJS (React)
- NestJS
- Prisma (Default to PostgreSQL)
- Temporal
- Resend (email notifications)

## Quick Start

To have the project up and running, please follow the [Quick Start Guide](https://docs.postiz.com/quickstart)

## Sponsor Postiz

We now give a few options to Sponsor Postiz:
- Just a donation: You like what we are building, and want to buy us some coffees so we can build faster.
- Main Repository: Get your logo with a backlink from the main Postiz repository. Postiz has almost 3m downloads and 20k views per month.
- Main Repository + Website: Get your logo on the central repository and the main website. Here are some metrics: - Website has 20k hits per month + 65 DR (strong backlink) - Repository has 20k hits per month + Almost 3m docker downloads.

Link: https://opencollective.com/postiz

## Postiz Compliance

- Postiz is an open-source, self-hosted social media scheduling tool that supports platforms like X (formerly Twitter), Bluesky, Mastodon, Discord, and others.
- Postiz hosted service uses official, platform-approved OAuth flows.
- Postiz does not automate or scrape content from social media platforms.
- Postiz does not collect, store, or proxy API keys or access tokens from users.
- Postiz never ask users to paste API keys into our hosted product.
- Postiz Users always authenticate directly with the social platform (e.g., X, Discord, etc.), ensuring platform compliance and data privacy.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=gitroomhq/postiz-app&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#gitroomhq/postiz-app&amp;type=date&amp;legend=top-left)

## License

This repository&#039;s source code is available under the [AGPL-3.0 license](LICENSE).

&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.g2.com/products/postiz/take_survey&quot; target=&quot;blank&quot;&gt;&lt;img alt=&quot;g2&quot; src=&quot;https://github.com/user-attachments/assets/892cb74c-0b49-4589-b2f5-fbdbf7a98f66&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[langgenius/dify]]></title>
            <link>https://github.com/langgenius/dify</link>
            <guid>https://github.com/langgenius/dify</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:24 GMT</pubDate>
            <description><![CDATA[Production-ready platform for agentic workflow development.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langgenius/dify">langgenius/dify</a></h1>
            <p>Production-ready platform for agentic workflow development.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 130,717</p>
            <p>Forks: 20,358</p>
            <p>Stars today: 131 stars today</p>
            <h2>README</h2><pre>![cover-v5-optimized](./images/GitHub_README_if.png)

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cloud.dify.ai&quot;&gt;Dify Cloud&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted&quot;&gt;Self-hosting&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://docs.dify.ai&quot;&gt;Documentation&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://dify.ai/pricing&quot;&gt;Dify edition overview&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://dify.ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Product-F04438&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://dify.ai/pricing&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/free-pricing?logo=free&amp;color=%20%23155EEF&amp;label=pricing&amp;labelColor=%20%23528bff&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/FngNHpbcY7&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1082486657678311454?logo=discord&amp;labelColor=%20%235462eb&amp;logoColor=%20%23f5f5f5&amp;color=%20%235462eb&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://reddit.com/r/difyai&quot; target=&quot;_blank&quot;&gt;  
        &lt;img src=&quot;https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&amp;logo=reddit&amp;label=r%2Fdifyai&amp;labelColor=white&quot;
            alt=&quot;join Reddit&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=dify_ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/dify_ai?logo=X&amp;color=%20%23f5f5f5&quot;
            alt=&quot;follow on X(Twitter)&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/langgenius/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;logoColor=fff&quot;
            alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/u/langgenius&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&amp;color=%20%23f79009&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/graphs/commit-activity&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Commits last month&quot; src=&quot;https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&amp;color=%20%2312b76a&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Issues closed&quot; src=&quot;https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&amp;label=issues%20closed&amp;labelColor=%20%237d89b0&amp;color=%20%235d6b98&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/discussions/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Discussion posts&quot; src=&quot;https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&amp;color=%20%237a5af8&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://insights.linuxfoundation.org/project/langgenius-dify&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;LFX Health Score&quot; src=&quot;https://insights.linuxfoundation.org/api/badge/health-score?project=langgenius-dify&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://insights.linuxfoundation.org/project/langgenius-dify&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;LFX Contributors&quot; src=&quot;https://insights.linuxfoundation.org/api/badge/contributors?project=langgenius-dify&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://insights.linuxfoundation.org/project/langgenius-dify&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;LFX Active Contributors&quot; src=&quot;https://insights.linuxfoundation.org/api/badge/active-contributors?project=langgenius-dify&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/zh-TW/README.md&quot;&gt;&lt;img alt=&quot;ÁπÅÈ´î‰∏≠ÊñáÊñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁπÅÈ´î‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/zh-CN/README.md&quot;&gt;&lt;img alt=&quot;ÁÆÄ‰Ωì‰∏≠ÊñáÊñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/ja-JP/README.md&quot;&gt;&lt;img alt=&quot;Êó•Êú¨Ë™û„ÅÆREADME&quot; src=&quot;https://img.shields.io/badge/Êó•Êú¨Ë™û-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/es-ES/README.md&quot;&gt;&lt;img alt=&quot;README en Espa√±ol&quot; src=&quot;https://img.shields.io/badge/Espa√±ol-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/fr-FR/README.md&quot;&gt;&lt;img alt=&quot;README en Fran√ßais&quot; src=&quot;https://img.shields.io/badge/Fran√ßais-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/tlh/README.md&quot;&gt;&lt;img alt=&quot;README tlhIngan Hol&quot; src=&quot;https://img.shields.io/badge/Klingon-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/ko-KR/README.md&quot;&gt;&lt;img alt=&quot;README in Korean&quot; src=&quot;https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/ar-SA/README.md&quot;&gt;&lt;img alt=&quot;README ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&quot; src=&quot;https://img.shields.io/badge/ÿßŸÑÿπÿ±ÿ®Ÿäÿ©-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/tr-TR/README.md&quot;&gt;&lt;img alt=&quot;T√ºrk√ße README&quot; src=&quot;https://img.shields.io/badge/T√ºrk√ße-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/vi-VN/README.md&quot;&gt;&lt;img alt=&quot;README Ti·∫øng Vi·ªát&quot; src=&quot;https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/de-DE/README.md&quot;&gt;&lt;img alt=&quot;README in Deutsch&quot; src=&quot;https://img.shields.io/badge/German-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/bn-BD/README.md&quot;&gt;&lt;img alt=&quot;README in ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&quot; src=&quot;https://img.shields.io/badge/‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ-d9d9d9&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Dify is an open-source platform for developing LLM applications. Its intuitive interface combines agentic AI workflows, RAG pipelines, agent capabilities, model management, observability features, and more‚Äîallowing you to quickly move from prototype to production.

## Quick start

&gt; Before installing Dify, make sure your machine meets the following minimum system requirements:
&gt;
&gt; - CPU &gt;= 2 Core
&gt; - RAM &gt;= 4 GiB

&lt;br/&gt;

The easiest way to start the Dify server is through [Docker Compose](docker/docker-compose.yaml). Before running Dify with the following commands, make sure that [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) are installed on your machine:

```bash
cd dify
cd docker
cp .env.example .env
docker compose up -d
```

After running, you can access the Dify dashboard in your browser at [http://localhost/install](http://localhost/install) and start the initialization process.

#### Seeking help

Please refer to our [FAQ](https://docs.dify.ai/getting-started/install-self-hosted/faqs) if you encounter problems setting up Dify. Reach out to [the community and us](#community--contact) if you are still having issues.

&gt; If you&#039;d like to contribute to Dify or do additional development, refer to our [guide to deploying from source code](https://docs.dify.ai/getting-started/install-self-hosted/local-source-code)

## Key features

**1. Workflow**:
Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.

**2. Comprehensive model support**:
Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found [here](https://docs.dify.ai/getting-started/readme/model-providers).

![providers-v5](https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3)

**3. Prompt IDE**:
Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.

**4. RAG Pipeline**:
Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.

**5. Agent capabilities**:
You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALL¬∑E, Stable Diffusion and WolframAlpha.

**6. LLMOps**:
Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.

**7. Backend-as-a-Service**:
All of Dify&#039;s offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.

## Using Dify

- **Cloud &lt;br/&gt;**
  We host a [Dify Cloud](https://dify.ai) service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.

- **Self-hosting Dify Community Edition&lt;br/&gt;**
  Quickly get Dify running in your environment with this [starter guide](#quick-start).
  Use our [documentation](https://docs.dify.ai) for further references and more in-depth instructions.

- **Dify for enterprise / organizations&lt;br/&gt;**
  We provide additional enterprise-centric features. [Send us an email](mailto:business@dify.ai?subject=%5BGitHub%5DBusiness%20License%20Inquiry) to discuss your enterprise needs. &lt;br/&gt;

  &gt; For startups and small businesses using AWS, check out [Dify Premium on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6) and deploy it to your own AWS VPC with one click. It&#039;s an affordable AMI offering with the option to create apps with custom logo and branding.

## Staying ahead

Star Dify on GitHub and be instantly notified of new releases.

![star-us](https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4)

## Advanced Setup

### Custom configurations

If you need to customize the configuration, please refer to the comments in our [.env.example](docker/.env.example) file and update the corresponding values in your `.env` file. Additionally, you might need to make adjustments to the `docker-compose.yaml` file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run `docker-compose up -d`. You can find the full list of available environment variables [here](https://docs.dify.ai/getting-started/install-self-hosted/environments).

#### Customizing Suggested Questions

You can now customize the &quot;Suggested Questions After Answer&quot; feature to better fit your use case. For example, to generate longer, more technical questions:

```bash
# In your .env file
SUGGESTED_QUESTIONS_PROMPT=&#039;Please help me predict the five most likely technical follow-up questions a developer would ask. Focus on implementation details, best practices, and architecture considerations. Keep each question between 40-60 characters. Output must be JSON array: [&quot;question1&quot;,&quot;question2&quot;,&quot;question3&quot;,&quot;question4&quot;,&quot;question5&quot;]&#039;
SUGGESTED_QUESTIONS_MAX_TOKENS=512
SUGGESTED_QUESTIONS_TEMPERATURE=0.3
```

See the [Suggested Questions Configuration Guide](docs/suggested-questions-configuration.md) for detailed examples and usage instructions.

### Metrics Monitoring with Grafana

Import the dashboard to Grafana, using Dify&#039;s PostgreSQL database as data source, to monitor metrics in granularity of apps, tenants, messages, and more.

- [Grafana Dashboard by @bowenliang123](https://github.com/bowenliang123/dify-grafana-dashboard)

### Deployment with Kubernetes

If you&#039;d like to configure a highly-available setup, there are community-contributed [Helm Charts](https://helm.sh/) and YAML files which allow Dify to be deployed on Kubernetes.

- [Helm Chart by @LeoQuote](https://github.com/douban/charts/tree/master/charts/dify)
- [Helm Chart by @BorisPolonsky](https://github.com/BorisPolonsky/dify-helm)
- [Helm Chart by @magicsong](https://github.com/magicsong/ai-charts)
- [YAML file by @Winson-030](https://github.com/Winson-030/dify-kubernetes)
- [YAML file by @wyy-holding](https://github.com/wyy-holding/dify-k8s)
- [üöÄ NEW! YAML files (Supports Dify v1.6.0) by @Zhoneym](https://github.com/Zhoneym/DifyAI-Kubernetes)

#### Using Terraform for Deployment

Deploy Dify to Cloud Platform with a single click using [terraform](https://www.terraform.io/)

##### Azure Global

- [Azure Terraform by @nikawang](https://github.com/nikawang/dify-azure-terraform)

##### Google Cloud

- [Google Cloud Terraform by @sotazum](https://github.com/DeNA/dify-google-cloud-terraform)

#### Using AWS CDK for Deployment

Deploy Dify to AWS with [CDK](https://aws.amazon.com/cdk/)

##### AWS

- [AWS CDK by @KevinZhao (EKS based)](https://github.com/aws-samples/solution-for-deploying-dify-on-aws)
- [AWS CDK by @tmokmss (ECS based)](https://github.com/aws-samples/dify-self-hosted-on-aws)

#### Using Alibaba Cloud Computing Nest

Quickly deploy Dify to Alibaba cloud with [Alibaba Cloud Computing Nest](https://computenest.console.aliyun.com/service/instance/create/default?type=user&amp;ServiceName=Dify%E7%A4%BE%E5%8C%BA%E7%89%88)

#### Using Alibaba Cloud Data Management

One-Click deploy Dify to Alibaba Cloud with [Alibaba Cloud Data Management](https://www.alibabacloud.com/help/en/dms/dify-in-invitational-preview/)

#### Deploy to AKS with Azure Devops Pipeline

One-Click deploy Dify to AKS with [Azure Devops Pipeline Helm Chart by @LeoZhang](https://github.com/Ruiruiz30/Dify-helm-chart-AKS)

## Contributing

For those who&#039;d like to contribute code, see our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.

&gt; We are looking for contributors to help translate Dify into languages other than Mandarin or English. If you are interested in helping, please see the [i18n README](https://github.com/langgenius/dify/blob/main/web/i18n-config/README.md) for more information, and leave us a comment in the `global-users` channel of our [Discord Community Server](https://discord.gg/8Tpq4AcN9c).

## Community &amp; contact

- [GitHub Discussion](https://github.com/langgenius/dify/discussions). Best for: sharing feedback and asking questions.
- [GitHub Issues](https://github.com/langgenius/dify/issues). Best for: bugs you encounter using Dify.AI, and feature proposals. See our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
- [Discord](https://discord.gg/FngNHpbcY7). Best for: sharing your applications and hanging out with the community.
- [X(Twitter)](https://twitter.com/dify_ai). Best for: sharing your applications and hanging out with the community.

**Contributors**

&lt;a href=&quot;https://github.com/langgenius/dify/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=langgenius/dify&quot; /&gt;
&lt;/a&gt;

## Star history

[![Star History Chart](https://api.star-history.com/svg?repos=langgenius/dify&amp;type=Date)](https://star-history.com/#langgenius/dify&amp;Date)

## Security disclosure

To protect your privacy, please avoid posting security issues on GitHub. Instead, report issues to security@dify.ai, and our team will respond with detailed answer.

## License

This repository is licensed under the [Dify Open Source License](LICENSE), based on Apache 2.0 with additional conditions.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[AndyMik90/Auto-Claude]]></title>
            <link>https://github.com/AndyMik90/Auto-Claude</link>
            <guid>https://github.com/AndyMik90/Auto-Claude</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:23 GMT</pubDate>
            <description><![CDATA[Autonomous multi-session AI coding]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AndyMik90/Auto-Claude">AndyMik90/Auto-Claude</a></h1>
            <p>Autonomous multi-session AI coding</p>
            <p>Language: TypeScript</p>
            <p>Stars: 12,796</p>
            <p>Forks: 1,764</p>
            <p>Stars today: 63 stars today</p>
            <h2>README</h2><pre># Auto Claude

**Autonomous multi-agent coding framework that plans, builds, and validates software for you.**

![Auto Claude Kanban Board](.github/assets/Auto-Claude-Kanban.png)

[![License](https://img.shields.io/badge/license-AGPL--3.0-green?style=flat-square)](./agpl-3.0.txt)
[![Discord](https://img.shields.io/badge/Discord-Join%20Community-5865F2?style=flat-square&amp;logo=discord&amp;logoColor=white)](https://discord.gg/KCXaPBr4Dj)
[![YouTube](https://img.shields.io/badge/YouTube-Subscribe-FF0000?style=flat-square&amp;logo=youtube&amp;logoColor=white)](https://www.youtube.com/@AndreMikalsen)
[![CI](https://img.shields.io/github/actions/workflow/status/AndyMik90/Auto-Claude/ci.yml?branch=main&amp;style=flat-square&amp;label=CI)](https://github.com/AndyMik90/Auto-Claude/actions)
[![Mentioned in Awesome Claude Code](https://awesome.re/mentioned-badge-flat.svg)](https://github.com/hesreallyhim/awesome-claude-code)

---

## Download

### Stable Release

&lt;!-- STABLE_VERSION_BADGE --&gt;
[![Stable](https://img.shields.io/badge/stable-2.7.6-blue?style=flat-square)](https://github.com/AndyMik90/Auto-Claude/releases/tag/v2.7.6)
&lt;!-- STABLE_VERSION_BADGE_END --&gt;

&lt;!-- STABLE_DOWNLOADS --&gt;
| Platform | Download |
|----------|----------|
| **Windows** | [Auto-Claude-2.7.6-win32-x64.exe](https://github.com/AndyMik90/Auto-Claude/releases/download/v2.7.6/Auto-Claude-2.7.6-win32-x64.exe) |
| **macOS (Apple Silicon)** | [Auto-Claude-2.7.6-darwin-arm64.dmg](https://github.com/AndyMik90/Auto-Claude/releases/download/v2.7.6/Auto-Claude-2.7.6-darwin-arm64.dmg) |
| **macOS (Intel)** | [Auto-Claude-2.7.6-darwin-x64.dmg](https://github.com/AndyMik90/Auto-Claude/releases/download/v2.7.6/Auto-Claude-2.7.6-darwin-x64.dmg) |
| **Linux** | [Auto-Claude-2.7.6-linux-x86_64.AppImage](https://github.com/AndyMik90/Auto-Claude/releases/download/v2.7.6/Auto-Claude-2.7.6-linux-x86_64.AppImage) |
| **Linux (Debian)** | [Auto-Claude-2.7.6-linux-amd64.deb](https://github.com/AndyMik90/Auto-Claude/releases/download/v2.7.6/Auto-Claude-2.7.6-linux-amd64.deb) |
| **Linux (Flatpak)** | [Auto-Claude-2.7.6-linux-x86_64.flatpak](https://github.com/AndyMik90/Auto-Claude/releases/download/v2.7.6/Auto-Claude-2.7.6-linux-x86_64.flatpak) |
&lt;!-- STABLE_DOWNLOADS_END --&gt;

### Beta Release

&gt; ‚ö†Ô∏è Beta releases may contain bugs and breaking changes. [View all releases](https://github.com/AndyMik90/Auto-Claude/releases)

&lt;!-- BETA_VERSION_BADGE --&gt;
[![Beta](https://img.shields.io/badge/beta-2.7.6--beta.6-orange?style=flat-square)](https://github.com/AndyMik90/Auto-Claude/releases/tag/v2.7.6-beta.6)
&lt;!-- BETA_VERSION_BADGE_END --&gt;

&lt;!-- BETA_DOWNLOADS --&gt;
| Platform | Download |
|----------|----------|
| **Windows** | [Auto-Claude-2.7.6-beta.6-win32-x64.exe](https://github.com/AndyMik90/Auto-Claude/releases/download/v2.7.6-beta.6/Auto-Claude-2.7.6-beta.6-win32-x64.exe) |
| **macOS (Apple Silicon)** | [Auto-Claude-2.7.6-beta.6-darwin-arm64.dmg](https://github.com/AndyMik90/Auto-Claude/releases/download/v2.7.6-beta.6/Auto-Claude-2.7.6-beta.6-darwin-arm64.dmg) |
| **macOS (Intel)** | [Auto-Claude-2.7.6-beta.6-darwin-x64.dmg](https://github.com/AndyMik90/Auto-Claude/releases/download/v2.7.6-beta.6/Auto-Claude-2.7.6-beta.6-darwin-x64.dmg) |
| **Linux** | [Auto-Claude-2.7.6-beta.6-linux-x86_64.AppImage](https://github.com/AndyMik90/Auto-Claude/releases/download/v2.7.6-beta.6/Auto-Claude-2.7.6-beta.6-linux-x86_64.AppImage) |
| **Linux (Debian)** | [Auto-Claude-2.7.6-beta.6-linux-amd64.deb](https://github.com/AndyMik90/Auto-Claude/releases/download/v2.7.6-beta.6/Auto-Claude-2.7.6-beta.6-linux-amd64.deb) |
| **Linux (Flatpak)** | [Auto-Claude-2.7.6-beta.6-linux-x86_64.flatpak](https://github.com/AndyMik90/Auto-Claude/releases/download/v2.7.6-beta.6/Auto-Claude-2.7.6-beta.6-linux-x86_64.flatpak) |
&lt;!-- BETA_DOWNLOADS_END --&gt;

&gt; All releases include SHA256 checksums and VirusTotal scan results for security verification.

---

## Requirements

- **Claude Pro/Max subscription** - [Get one here](https://claude.ai/upgrade)
- **Claude Code CLI** - `npm install -g @anthropic-ai/claude-code`
- **Git repository** - Your project must be initialized as a git repo

---

## Quick Start

1. **Download and install** the app for your platform
2. **Open your project** - Select a git repository folder
3. **Connect Claude** - The app will guide you through OAuth setup
4. **Create a task** - Describe what you want to build
5. **Watch it work** - Agents plan, code, and validate autonomously

---

## Features

| Feature | Description |
|---------|-------------|
| **Autonomous Tasks** | Describe your goal; agents handle planning, implementation, and validation |
| **Parallel Execution** | Run multiple builds simultaneously with up to 12 agent terminals |
| **Isolated Workspaces** | All changes happen in git worktrees - your main branch stays safe |
| **Self-Validating QA** | Built-in quality assurance loop catches issues before you review |
| **AI-Powered Merge** | Automatic conflict resolution when integrating back to main |
| **Memory Layer** | Agents retain insights across sessions for smarter builds |
| **GitHub/GitLab Integration** | Import issues, investigate with AI, create merge requests |
| **Linear Integration** | Sync tasks with Linear for team progress tracking |
| **Cross-Platform** | Native desktop apps for Windows, macOS, and Linux |
| **Auto-Updates** | App updates automatically when new versions are released |

---

## Interface

### Kanban Board
Visual task management from planning through completion. Create tasks and monitor agent progress in real-time.

### Agent Terminals
AI-powered terminals with one-click task context injection. Spawn multiple agents for parallel work.

![Agent Terminals](.github/assets/Auto-Claude-Agents-terminals.png)

### Roadmap
AI-assisted feature planning with competitor analysis and audience targeting.

![Roadmap](.github/assets/Auto-Claude-roadmap.png)

### Additional Features
- **Insights** - Chat interface for exploring your codebase
- **Ideation** - Discover improvements, performance issues, and vulnerabilities
- **Changelog** - Generate release notes from completed tasks

---

## Project Structure

```
Auto-Claude/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ backend/     # Python agents, specs, QA pipeline
‚îÇ   ‚îî‚îÄ‚îÄ frontend/    # Electron desktop application
‚îú‚îÄ‚îÄ guides/          # Additional documentation
‚îú‚îÄ‚îÄ tests/           # Test suite
‚îî‚îÄ‚îÄ scripts/         # Build utilities
```

---

## CLI Usage

For headless operation, CI/CD integration, or terminal-only workflows:

```bash
cd apps/backend

# Create a spec interactively
python spec_runner.py --interactive

# Run autonomous build
python run.py --spec 001

# Review and merge
python run.py --spec 001 --review
python run.py --spec 001 --merge
```

See [guides/CLI-USAGE.md](guides/CLI-USAGE.md) for complete CLI documentation.

---

## Development

Want to build from source or contribute? See [CONTRIBUTING.md](CONTRIBUTING.md) for complete development setup instructions.

For Linux-specific builds (Flatpak, AppImage), see [guides/linux.md](guides/linux.md).

---

## Security

Auto Claude uses a three-layer security model:

1. **OS Sandbox** - Bash commands run in isolation
2. **Filesystem Restrictions** - Operations limited to project directory
3. **Dynamic Command Allowlist** - Only approved commands based on detected project stack

All releases are:
- Scanned with VirusTotal before publishing
- Include SHA256 checksums for verification
- Code-signed where applicable (macOS)

---

## Available Scripts

| Command | Description |
|---------|-------------|
| `npm run install:all` | Install backend and frontend dependencies |
| `npm start` | Build and run the desktop app |
| `npm run dev` | Run in development mode with hot reload |
| `npm run package` | Package for current platform |
| `npm run package:mac` | Package for macOS |
| `npm run package:win` | Package for Windows |
| `npm run package:linux` | Package for Linux |
| `npm run package:flatpak` | Package as Flatpak (see [guides/linux.md](guides/linux.md)) |
| `npm run lint` | Run linter |
| `npm test` | Run frontend tests |
| `npm run test:backend` | Run backend tests |

---

## Contributing

We welcome contributions! Please read [CONTRIBUTING.md](CONTRIBUTING.md) for:
- Development setup instructions
- Code style guidelines
- Testing requirements
- Pull request process

---

## Community

- **Discord** - [Join our community](https://discord.gg/KCXaPBr4Dj)
- **Issues** - [Report bugs or request features](https://github.com/AndyMik90/Auto-Claude/issues)
- **Discussions** - [Ask questions](https://github.com/AndyMik90/Auto-Claude/discussions)

---

## License

**AGPL-3.0** - GNU Affero General Public License v3.0

Auto Claude is free to use. If you modify and distribute it, or run it as a service, your code must also be open source under AGPL-3.0.

Commercial licensing available for closed-source use cases.

---

## Star History

[![GitHub Repo stars](https://img.shields.io/github/stars/AndyMik90/Auto-Claude?style=social)](https://github.com/AndyMik90/Auto-Claude/stargazers)

[![Star History Chart](https://api.star-history.com/svg?repos=AndyMik90/Auto-Claude&amp;type=Date)](https://star-history.com/#AndyMik90/Auto-Claude&amp;Date)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[bytedance/UI-TARS-desktop]]></title>
            <link>https://github.com/bytedance/UI-TARS-desktop</link>
            <guid>https://github.com/bytedance/UI-TARS-desktop</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:22 GMT</pubDate>
            <description><![CDATA[The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytedance/UI-TARS-desktop">bytedance/UI-TARS-desktop</a></h1>
            <p>The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra</p>
            <p>Language: TypeScript</p>
            <p>Stars: 28,409</p>
            <p>Forks: 2,777</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
  &lt;img alt=&quot;Agent TARS Banner&quot; src=&quot;./images/tars.png&quot;&gt;
&lt;/picture&gt;

&lt;br/&gt;

## Introduction

English | [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md)

[![](https://trendshift.io/api/badge/repositories/13584)](https://trendshift.io/repositories/13584)

&lt;b&gt;TARS&lt;sup&gt;\*&lt;/sup&gt;&lt;/b&gt; is a Multimodal AI Agent stack, currently shipping two projects: [Agent TARS](#agent-tars) and [UI-TARS-desktop](#ui-tars-desktop):

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th width=&quot;50%&quot; align=&quot;center&quot;&gt;&lt;a href=&quot;#agent-tars&quot;&gt;Agent TARS&lt;/a&gt;&lt;/th&gt;
      &lt;th width=&quot;50%&quot; align=&quot;center&quot;&gt;&lt;a href=&quot;#ui-tars-desktop&quot;&gt;UI-TARS-desktop&lt;/a&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;video src=&quot;https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d&quot; width=&quot;50%&quot;&gt;&lt;/video&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;video src=&quot;https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27&quot; width=&quot;50%&quot;&gt;&lt;/video&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;left&quot;&gt;
        &lt;b&gt;Agent TARS&lt;/b&gt; is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product.
        &lt;br&gt;
        &lt;br&gt;
        It primarily ships with a &lt;a href=&quot;https://agent-tars.com/guide/basic/cli.html&quot; target=&quot;_blank&quot;&gt;CLI&lt;/a&gt; and &lt;a href=&quot;https://agent-tars.com/guide/basic/web-ui.html&quot; target=&quot;_blank&quot;&gt;Web UI&lt;/a&gt; for usage.
        It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world &lt;a href=&quot;https://agent-tars.com/guide/basic/mcp.html&quot; target=&quot;_blank&quot;&gt;MCP&lt;/a&gt; tools.
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;
        &lt;b&gt;UI-TARS Desktop&lt;/b&gt; is a desktop application that provides a native GUI Agent based on the &lt;a href=&quot;https://github.com/bytedance/UI-TARS&quot; target=&quot;_blank&quot;&gt;UI-TARS&lt;/a&gt; model.
        &lt;br&gt;
        &lt;br&gt;
        It primarily ships a
        &lt;a href=&quot;https://github.com/bytedance/UI-TARS-desktop/blob/main/docs/quick-start.md#get-model-and-run-local-operator&quot; target=&quot;_blank&quot;&gt;local&lt;/a&gt; and 
        &lt;a href=&quot;https://github.com/bytedance/UI-TARS-desktop/blob/main/docs/quick-start.md#run-remote-operator&quot; target=&quot;_blank&quot;&gt;remote&lt;/a&gt; computer as well as browser operators.
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

## Table of Contents

&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt;
&lt;!-- DON&#039;T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt;

- [News](#news)
- [Agent TARS](#agent-tars)
  - [Showcase](#showcase)
  - [Core Features](#core-features)
  - [Quick Start](#quick-start)
  - [Documentation](#documentation)
- [UI-TARS Desktop](#ui-tars-desktop)
  - [Showcase](#showcase-1)
  - [Features](#features)
  - [Quick Start](#quick-start-1)
- [Contributing](#contributing)
- [License](#license)
- [Citation](#citation)

&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt;

## News

- **\[2025-11-05\]** üéâ We&#039;re excited to announce the release of [Agent TARS CLI v0.3.0](https://github.com/bytedance/UI-TARS-desktop/releases/tag/v0.3.0)! This version brings streaming support for multiple tools (shell commands, multi-file structured display), runtime settings with timing statistics for tool calls and deep thinking, Event Stream Viewer for data flow tracking and debugging. Additionally, it features exclusive support for [AIO agent Sandbox](https://github.com/agent-infra/sandbox) as isolated all-in-one tools execution environment.
- **\[2025-06-25\]** We released an Agent TARS Beta and Agent TARS CLI - [Introducing Agent TARS Beta](https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html), a multimodal AI agent that aims to explore a work form that is closer to human-like task completion through rich multimodal capabilities (such as GUI Agent, Vision) and seamless integration with various real-world tools.
- **\[2025-06-12\]** - üéÅ We are thrilled to announce the release of UI-TARS Desktop v0.2.0! This update introduces two powerful new features: **Remote Computer Operator** and **Remote Browser Operator**‚Äîboth completely free. No configuration required: simply click to remotely control any computer or browser, and experience a new level of convenience and intelligence.
- **\[2025-04-17\]** - üéâ We&#039;re thrilled to announce the release of new UI-TARS Desktop application v0.1.0, featuring a redesigned Agent UI. The application enhances the computer using experience, introduces new browser operation features, and supports [the advanced UI-TARS-1.5 model](https://seed-tars.com/1.5) for improved performance and precise control.
- **\[2025-02-20\]** - üì¶ Introduced [UI TARS SDK](./docs/sdk.md), is a powerful cross-platform toolkit for building GUI automation agents.
- **\[2025-01-23\]** - üöÄ We updated the **[Cloud Deployment](./docs/deployment.md#cloud-deployment)** section in the ‰∏≠ÊñáÁâà: [GUIÊ®°ÂûãÈÉ®ÁΩ≤ÊïôÁ®ã](https://bytedance.sg.larkoffice.com/docx/TCcudYwyIox5vyxiSDLlgIsTgWf#U94rdCxzBoJMLex38NPlHL21gNb) with new information related to the ModelScope platform. You can now use the ModelScope platform for deployment.

&lt;br&gt;

## Agent TARS

&lt;p&gt;
    &lt;a href=&quot;https://npmjs.com/package/@agent-tars/cli?activeTab=readme&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@agent-tars/cli?style=for-the-badge&amp;colorA=1a1a2e&amp;colorB=3B82F6&amp;logo=npm&amp;logoColor=white&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://npmcharts.com/compare/@agent-tars/cli?minimal=true&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/@agent-tars/cli.svg?style=for-the-badge&amp;colorA=1a1a2e&amp;colorB=0EA5E9&amp;logo=npm&amp;logoColor=white&quot; alt=&quot;downloads&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://nodejs.org/en/about/previous-releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/node/v/@agent-tars/cli.svg?style=for-the-badge&amp;colorA=1a1a2e&amp;colorB=06B6D4&amp;logo=node.js&amp;logoColor=white&quot; alt=&quot;node version&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/HnKcSBgTVx&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20Community-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Discord Community&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/agent_tars&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Twitter-Follow%20%40agent__tars-1DA1F2?style=for-the-badge&amp;logo=twitter&amp;logoColor=white&quot; alt=&quot;Official Twitter&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://applink.larkoffice.com/client/chat/chatter/add_by_link?link_token=deen76f4-ea3c-4964-93a3-78f126f39651&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/È£û‰π¶Áæ§-Âä†ÂÖ•‰∫§ÊµÅÁæ§-00D4AA?style=for-the-badge&amp;logo=lark&amp;logoColor=white&quot; alt=&quot;È£û‰π¶‰∫§ÊµÅÁæ§&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://deepwiki.com/bytedance/UI-TARS-desktop&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/DeepWiki-Ask%20AI-8B5CF6?style=for-the-badge&amp;logo=gitbook&amp;logoColor=white&quot; alt=&quot;Ask DeepWiki&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;b&gt;Agent TARS&lt;/b&gt; is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product. &lt;br&gt; &lt;br&gt;
It primarily ships with a &lt;a href=&quot;https://agent-tars.com/guide/basic/cli.html&quot; target=&quot;_blank&quot;&gt;CLI&lt;/a&gt; and &lt;a href=&quot;https://agent-tars.com/guide/basic/web-ui.html&quot; target=&quot;_blank&quot;&gt;Web UI&lt;/a&gt; for usage.
It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world &lt;a href=&quot;https://agent-tars.com/guide/basic/mcp.html&quot; target=&quot;_blank&quot;&gt;MCP&lt;/a&gt; tools.

### Showcase

```
Please help me book the earliest flight from San Jose to New York on September 1st and the last return flight on September 6th on Priceline
```

https://github.com/user-attachments/assets/772b0eef-aef7-4ab9-8cb0-9611820539d8

&lt;br&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th width=&quot;50%&quot; align=&quot;center&quot;&gt;Booking Hotel&lt;/th&gt;
      &lt;th width=&quot;50%&quot; align=&quot;center&quot;&gt;Generate Chart with extra MCP Servers&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;video src=&quot;https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d&quot; width=&quot;50%&quot;&gt;&lt;/video&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;video src=&quot;https://github.com/user-attachments/assets/a9fd72d0-01bb-4233-aa27-ca95194bbce9&quot; width=&quot;50%&quot;&gt;&lt;/video&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;left&quot;&gt;
        &lt;b&gt;Instruction:&lt;/b&gt; &lt;i&gt;I am in Los Angeles from September 1st to September 6th, with a budget of $5,000. Please help me book a Ritz-Carlton hotel closest to the airport on booking.com and compile a transportation guide for me&lt;/i&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;
        &lt;b&gt;Instruction:&lt;/b&gt; &lt;i&gt;Draw me a chart of Hangzhou&#039;s weather for one month&lt;/i&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

For more use cases, please check out [#842](https://github.com/bytedance/UI-TARS-desktop/issues/842).

### Core Features

- üñ±Ô∏è **One-Click Out-of-the-box CLI** - Supports both **headful** [Web UI](https://agent-tars.com/guide/basic/web-ui.html) and **headless** [server](https://agent-tars.com/guide/advanced/server.html) [execution](https://agent-tars.com/guide/basic/cli.html).
- üåê **Hybrid Browser Agent** - Control browsers using [GUI Agent](https://agent-tars.com/guide/basic/browser.html#visual-grounding), [DOM](https://agent-tars.com/guide/basic/browser.html#dom), or a hybrid strategy.
- üîÑ **Event Stream** - Protocol-driven Event Stream drives [Context Engineering](https://agent-tars.com/beta#context-engineering) and [Agent UI](https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html#easy-to-build-applications).
- üß∞ **MCP Integration** - The kernel is built on MCP and also supports mounting [MCP Servers](https://agent-tars.com/guide/basic/mcp.html) to connect to real-world tools.

### Quick Start

&lt;img alt=&quot;Agent TARS CLI&quot; src=&quot;https://agent-tars.com/agent-tars-cli.png&quot;&gt;

```bash
# Launch with `npx`.
npx @agent-tars/cli@latest

# Install globally, required Node.js &gt;= 22
npm install @agent-tars/cli@latest -g

# Run with your preferred model provider
agent-tars --provider volcengine --model doubao-1-5-thinking-vision-pro-250428 --apiKey your-api-key
agent-tars --provider anthropic --model claude-3-7-sonnet-latest --apiKey your-api-key
```

Visit the comprehensive [Quick Start](https://agent-tars.com/guide/get-started/quick-start.html) guide for detailed setup instructions.

### Documentation

&gt; üåü **Explore Agent TARS Universe** üåü

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th width=&quot;20%&quot; align=&quot;center&quot;&gt;Category&lt;/th&gt;
      &lt;th width=&quot;30%&quot; align=&quot;center&quot;&gt;Resource Link&lt;/th&gt;
      &lt;th width=&quot;50%&quot; align=&quot;left&quot;&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;üè† &lt;strong&gt;Central Hub&lt;/strong&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://agent-tars.com&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/Visit-Website-4F46E5?style=for-the-badge&amp;logo=globe&amp;logoColor=white&quot; alt=&quot;Website&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;Your gateway to Agent TARS ecosystem&lt;/td&gt;
    &lt;/tr&gt;
      &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;üìö &lt;strong&gt;Quick Start&lt;/strong&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://agent-tars.com/guide/get-started/quick-start.html&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/Get-Started-06B6D4?style=for-the-badge&amp;logo=rocket&amp;logoColor=white&quot; alt=&quot;Quick Start&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;Zero to hero in 5 minutes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;üöÄ &lt;strong&gt;What&#039;s New&lt;/strong&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://agent-tars.com/beta&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/Read-Blog-F59E0B?style=for-the-badge&amp;logo=rss&amp;logoColor=white&quot; alt=&quot;Blog&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;Discover cutting-edge features &amp; vision&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;üõ†Ô∏è &lt;strong&gt;Developer Zone&lt;/strong&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://agent-tars.com/guide/get-started/introduction.html&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/View-Docs-10B981?style=for-the-badge&amp;logo=gitbook&amp;logoColor=white&quot; alt=&quot;Docs&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;Master every command &amp; features&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;üéØ &lt;strong&gt;Showcase&lt;/strong&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://github.com/bytedance/UI-TARS-desktop/issues/842&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/View-Examples-8B5CF6?style=for-the-badge&amp;logo=github&amp;logoColor=white&quot; alt=&quot;Examples&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;View use cases built by the official and community&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;üîß &lt;strong&gt;Reference&lt;/strong&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://agent-tars.com/api/&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/API-Reference-EF4444?style=for-the-badge&amp;logo=book&amp;logoColor=white&quot; alt=&quot;API&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;Complete technical reference&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;

## UI-TARS Desktop

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;UI-TARS&quot; width=&quot;260&quot; src=&quot;./apps/ui-tars/resources/icon.png&quot;&gt;
&lt;/p&gt;

UI-TARS Desktop is a native GUI agent for your local computer, driven by [UI-TARS](https://github.com/bytedance/UI-TARS) and Seed-1.5-VL/1.6 series models.

&lt;div align=&quot;center&quot;&gt;
&lt;p&gt;
        &amp;nbsp&amp;nbsp üìë &lt;a href=&quot;https://arxiv.org/abs/2501.12326&quot;&gt;Paper&lt;/a&gt; &amp;nbsp&amp;nbsp
        | ü§ó &lt;a href=&quot;https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B&quot;&gt;Hugging Face Models&lt;/a&gt;&amp;nbsp&amp;nbsp
        | &amp;nbsp&amp;nbspü´® &lt;a href=&quot;https://discord.gg/pTXwYVjfcs&quot;&gt;Discord&lt;/a&gt;&amp;nbsp&amp;nbsp
        | &amp;nbsp&amp;nbspü§ñ &lt;a href=&quot;https://www.modelscope.cn/collections/UI-TARS-bccb56fa1ef640&quot;&gt;ModelScope&lt;/a&gt;&amp;nbsp&amp;nbsp
&lt;br&gt;
üñ•Ô∏è Desktop Application &amp;nbsp&amp;nbsp
| &amp;nbsp&amp;nbsp üëì &lt;a href=&quot;https://github.com/web-infra-dev/midscene&quot;&gt;Midscene (use in browser)&lt;/a&gt; &amp;nbsp&amp;nbsp
&lt;/p&gt;

&lt;/div&gt;

### Showcase

&lt;!-- // FIXME: Choose only two demo, one local computer and one remote computer showcase. --&gt;

|                                                          Instruction                                                           |                                                Local Operator                                                |                                               Remote Operator                                                |
| :----------------------------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------: |
| Please help me open the autosave feature of VS Code and delay AutoSave operations for 500 milliseconds in the VS Code setting. | &lt;video src=&quot;https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27&quot; height=&quot;300&quot; /&gt; | &lt;video src=&quot;https://github.com/user-attachments/assets/01e49b69-7070-46c8-b3e3-2aaaaec71800&quot; height=&quot;300&quot; /&gt; |
|                    Could you help me check the latest open issue of the UI-TARS-Desktop project on GitHub?                     | &lt;video src=&quot;https://github.com/user-attachments/assets/3d159f54-d24a-4268-96c0-e149607e9199&quot; height=&quot;300&quot; /&gt; | &lt;video src=&quot;https://github.com/user-attachments/assets/072fb72d-7394-4bfa-95f5-4736e29f7e58&quot; height=&quot;300&quot; /&gt; |

### Features

- ü§ñ Natural language control powered by Vision-Language Model
- üñ•Ô∏è Screenshot and visual recognition support
- üéØ Precise mouse and keyboard control
- üíª Cross-platform support (Windows/MacOS/Browser)
- üîÑ Real-time feedback and status display
- üîê Private and secure - fully local processing

### Quick Start

See [Quick Start](./docs/quick-start.md)

## Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md).

## License

This project is licensed under the Apache License 2.0.

## Citation

If you find our paper and code useful in your research, please consider giving a star :star: and citation :pencil:

```BibTeX
@article{qin2025ui,
  title={UI-TARS: Pioneering Automated GUI Interaction with Native Agents},
  author={Qin, Yujia and Ye, Yining and Fang, Junjie and Wang, Haoming and Liang, Shihao and Tian, Shizuo and Zhang, Junda and Li, Jiahao and Li, Yunxin and Huang, Shijue and others},
  journal={arXiv preprint arXiv:2501.12326},
  year={2025}
}
```
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[bytebot-ai/bytebot]]></title>
            <link>https://github.com/bytebot-ai/bytebot</link>
            <guid>https://github.com/bytebot-ai/bytebot</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:21 GMT</pubDate>
            <description><![CDATA[Bytebot is a self-hosted AI desktop agent that automates computer tasks through natural language commands, operating within a containerized Linux desktop environment.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytebot-ai/bytebot">bytebot-ai/bytebot</a></h1>
            <p>Bytebot is a self-hosted AI desktop agent that automates computer tasks through natural language commands, operating within a containerized Linux desktop environment.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 10,503</p>
            <p>Forks: 1,367</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;docs/images/bytebot-logo.png&quot; width=&quot;500&quot; alt=&quot;Bytebot Logo&quot;&gt;

# Bytebot: Open-Source AI Desktop Agent

&lt;a href=&quot;https://trendshift.io/repositories/14624&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14624&quot; alt=&quot;bytebot-ai%2Fbytebot | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

**An AI that has its own computer to complete tasks for you**

[![Deploy on Railway](https://railway.com/button.svg)](https://railway.com/deploy/bytebot?referralCode=L9lKXQ)

[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://github.com/bytebot-ai/bytebot/tree/main/docker)
[![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)](LICENSE)
[![Discord](https://img.shields.io/discord/1232768900274585720?color=7289da&amp;label=discord)](https://discord.com/invite/d9ewZkWPTP)

[üåê Website](https://bytebot.ai) ‚Ä¢ [üìö Documentation](https://docs.bytebot.ai) ‚Ä¢ [üí¨ Discord](https://discord.com/invite/d9ewZkWPTP) ‚Ä¢ [ùïè Twitter](https://x.com/bytebot_ai)

&lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
[Deutsch](https://zdoc.app/de/bytebot-ai/bytebot) | 
[Espa√±ol](https://zdoc.app/es/bytebot-ai/bytebot) | 
[fran√ßais](https://zdoc.app/fr/bytebot-ai/bytebot) | 
[Êó•Êú¨Ë™û](https://zdoc.app/ja/bytebot-ai/bytebot) | 
[ÌïúÍµ≠Ïñ¥](https://zdoc.app/ko/bytebot-ai/bytebot) | 
[Portugu√™s](https://zdoc.app/pt/bytebot-ai/bytebot) | 
[–†—É—Å—Å–∫–∏–π](https://zdoc.app/ru/bytebot-ai/bytebot) | 
[‰∏≠Êñá](https://zdoc.app/zh/bytebot-ai/bytebot)
&lt;/div&gt;

---

https://github.com/user-attachments/assets/f271282a-27a3-43f3-9b99-b34007fdd169

https://github.com/user-attachments/assets/72a43cf2-bd87-44c5-a582-e7cbe176f37f

## What is a Desktop Agent?

A desktop agent is an AI that has its own computer. Unlike browser-only agents or traditional RPA tools, Bytebot comes with a full virtual desktop where it can:

- Use any application (browsers, email clients, office tools, IDEs)
- Download and organize files with its own file system
- Log into websites and applications using password managers
- Read and process documents, PDFs, and spreadsheets
- Complete complex multi-step workflows across different programs

Think of it as a virtual employee with their own computer who can see the screen, move the mouse, type on the keyboard, and complete tasks just like a human would.

## Why Give AI Its Own Computer?

When AI has access to a complete desktop environment, it unlocks capabilities that aren&#039;t possible with browser-only agents or API integrations:

### Complete Task Autonomy

Give Bytebot a task like &quot;Download all invoices from our vendor portals and organize them into a folder&quot; and it will:

- Open the browser
- Navigate to each portal
- Handle authentication (including 2FA via password managers)
- Download the files to its local file system
- Organize them into a folder

### Process Documents

Upload files directly to Bytebot&#039;s desktop and it can:

- Read entire PDFs into its context
- Extract data from complex documents
- Cross-reference information across multiple files
- Create new documents based on analysis
- Handle formats that APIs can&#039;t access

### Use Real Applications

Bytebot isn&#039;t limited to web interfaces. It can:

- Use desktop applications like text editors, VS Code, or email clients
- Run scripts and command-line tools
- Install new software as needed
- Configure applications for specific workflows

## Quick Start

### Deploy in 2 Minutes

**Option 1: Railway (Easiest)**
[![Deploy on Railway](https://railway.com/button.svg)](https://railway.com/deploy/bytebot?referralCode=L9lKXQ)

Just click and add your AI provider API key.

**Option 2: Docker Compose**

```bash
git clone https://github.com/bytebot-ai/bytebot.git
cd bytebot

# Add your AI provider key (choose one)
echo &quot;ANTHROPIC_API_KEY=sk-ant-...&quot; &gt; docker/.env
# Or: echo &quot;OPENAI_API_KEY=sk-...&quot; &gt; docker/.env
# Or: echo &quot;GEMINI_API_KEY=...&quot; &gt; docker/.env

docker-compose -f docker/docker-compose.yml up -d

# Open http://localhost:9992
```

[Full deployment guide ‚Üí](https://docs.bytebot.ai/quickstart)

## How It Works

Bytebot consists of four integrated components:

1. **Virtual Desktop**: A complete Ubuntu Linux environment with pre-installed applications
2. **AI Agent**: Understands your tasks and controls the desktop to complete them
3. **Task Interface**: Web UI where you create tasks and watch Bytebot work
4. **APIs**: REST endpoints for programmatic task creation and desktop control

### Key Features

- **Natural Language Tasks**: Just describe what you need done
- **File Uploads**: Drop files onto tasks for Bytebot to process
- **Live Desktop View**: Watch Bytebot work in real-time
- **Takeover Mode**: Take control when you need to help or configure something
- **Password Manager Support**: Install 1Password, Bitwarden, etc. for automatic authentication
- **Persistent Environment**: Install programs and they stay available for future tasks

## Example Tasks

### Basic Examples

```
&quot;Go to Wikipedia and create a summary of quantum computing&quot;
&quot;Research flights from NYC to London and create a comparison document&quot;
&quot;Take screenshots of the top 5 news websites&quot;
```

### Document Processing

```
&quot;Read the uploaded contracts.pdf and extract all payment terms and deadlines&quot;
&quot;Process these 5 invoice PDFs and create a summary report&quot;
&quot;Download and analyze the latest financial report and answer: What were the key risks mentioned?&quot;
```

### Multi-Application Workflows

```
&quot;Download last month&#039;s bank statements from our three banks and consolidate them&quot;
&quot;Check all our vendor portals for new invoices and create a summary report&quot;
&quot;Log into our CRM, export the customer list, and update records in the ERP system&quot;
```

## Programmatic Control

### Create Tasks via API

```python
import requests

# Simple task
response = requests.post(&#039;http://localhost:9991/tasks&#039;, json={
    &#039;description&#039;: &#039;Download the latest sales report and create a summary&#039;
})

# Task with file upload
files = {&#039;files&#039;: open(&#039;contracts.pdf&#039;, &#039;rb&#039;)}
response = requests.post(&#039;http://localhost:9991/tasks&#039;,
    data={&#039;description&#039;: &#039;Review these contracts for important dates&#039;},
    files=files
)
```

### Direct Desktop Control

```bash
# Take a screenshot
curl -X POST http://localhost:9990/computer-use \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{&quot;action&quot;: &quot;screenshot&quot;}&#039;

# Click at specific coordinates
curl -X POST http://localhost:9990/computer-use \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{&quot;action&quot;: &quot;click_mouse&quot;, &quot;coordinate&quot;: [500, 300]}&#039;
```

[Full API documentation ‚Üí](https://docs.bytebot.ai/api-reference/introduction)

## Setting Up Your Desktop Agent

### 1. Deploy Bytebot

Use one of the deployment methods above to get Bytebot running.

### 2. Configure the Desktop

Use the Desktop tab in the UI to:

- Install additional programs you need
- Set up password managers for authentication
- Configure applications with your preferences
- Log into websites you want Bytebot to access

### 3. Start Giving Tasks

Create tasks in natural language and watch Bytebot complete them using the configured desktop.

## Use Cases

### Business Process Automation

- Invoice processing and data extraction
- Multi-system data synchronization
- Report generation from multiple sources
- Compliance checking across platforms

### Development &amp; Testing

- Automated UI testing
- Cross-browser compatibility checks
- Documentation generation with screenshots
- Code deployment verification

### Research &amp; Analysis

- Competitive analysis across websites
- Data gathering from multiple sources
- Document analysis and summarization
- Market research compilation

## Architecture

Bytebot is built with:

- **Desktop**: Ubuntu 22.04 with XFCE, Firefox, VS Code, and other tools
- **Agent**: NestJS service that coordinates AI and desktop actions
- **UI**: Next.js application for task management
- **AI Support**: Works with Anthropic Claude, OpenAI GPT, Google Gemini
- **Deployment**: Docker containers for easy self-hosting

## Why Self-Host?

- **Data Privacy**: Everything runs on your infrastructure
- **Full Control**: Customize the desktop environment as needed
- **No Limits**: Use your own AI API keys without platform restrictions
- **Flexibility**: Install any software, access any systems

## Advanced Features

### Multiple AI Providers

Use any AI provider through our [LiteLLM integration](https://docs.bytebot.ai/deployment/litellm):

- Azure OpenAI
- AWS Bedrock
- Local models via Ollama
- 100+ other providers

### Enterprise Deployment

Deploy on Kubernetes with Helm:

```bash
# Clone the repository
git clone https://github.com/bytebot-ai/bytebot.git
cd bytebot

# Install with Helm
helm install bytebot ./helm \
  --set agent.env.ANTHROPIC_API_KEY=sk-ant-...
```

[Enterprise deployment guide ‚Üí](https://docs.bytebot.ai/deployment/helm)

## Community &amp; Support

- **Discord**: [Join our community](https://discord.com/invite/d9ewZkWPTP) for help and discussions
- **Documentation**: Comprehensive guides at [docs.bytebot.ai](https://docs.bytebot.ai)
- **GitHub Issues**: Report bugs and request features

## Contributing

We welcome contributions! Whether it&#039;s:

- üêõ Bug fixes
- ‚ú® New features
- üìö Documentation improvements
- üåê Translations

Please:

1. Check existing [issues](https://github.com/bytebot-ai/bytebot/issues) first
2. Open an issue to discuss major changes
3. Submit PRs with clear descriptions
4. Join our [Discord](https://discord.com/invite/d9ewZkWPTP) to discuss ideas

## License

Bytebot is open source under the Apache 2.0 license.

---

&lt;div align=&quot;center&quot;&gt;

**Give your AI its own computer. See what it can do.**

[![Deploy on Railway](https://railway.com/button.svg)](https://railway.com/deploy/bytebot?referralCode=L9lKXQ)

&lt;sub&gt;Built by [Tantl Labs](https://tantl.com) and the open source community&lt;/sub&gt;

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[github/docs]]></title>
            <link>https://github.com/github/docs</link>
            <guid>https://github.com/github/docs</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:20 GMT</pubDate>
            <description><![CDATA[The open-source repo for docs.github.com]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/github/docs">github/docs</a></h1>
            <p>The open-source repo for docs.github.com</p>
            <p>Language: TypeScript</p>
            <p>Stars: 19,016</p>
            <p>Forks: 66,182</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># GitHub Docs &lt;!-- omit in toc --&gt;

Welcome to GitHub Docs! GitHub‚Äôs documentation is open source, meaning anyone from inside or outside the company can contribute. For full contributing guidelines, visit our [contributing guide](https://docs.github.com/en/contributing).


## Quick links by contributor type

* **Hubbers (GitHub employees):** See [CONTRIBUTING.md](https://github.com/github/docs-content/blob/main/CONTRIBUTING.md) in the `docs-content` repository for GitHub-specific processes.

* **Open source contributors:** See [CONTRIBUTING.md](https://github.com/github/docs/blob/main/.github/CONTRIBUTING.md) in the `docs` repository for a quick-start summary.

## How we sync changes across Docs repositories

There are two GitHub Docs repositories: 

- **`github/docs`** (public): Open to external contributions

- **`github/docs-internal`** (private): For GitHub employee contributions. 

The two repositories sync frequently. Content changes in one are reflected in the other.  Hubbers might prefer to post in `docs` when working with a customer, but `docs` has limitations on the types of contributions it accepts to safeguard the site and our workflows. Internal contributions should usually go to `docs-internal`.

**Important:** The `docs` repository accepts contributions to content files (`.md` files in `/content` and select `/data` sections like reusables only). Infrastructure files, workflows, and site-building code are not open for external modification.

## New to contributing

Here are some resources to help you get started with open source contributions:

* [Finding ways to contribute to open source on GitHub](https://docs.github.com/en/get-started/exploring-projects-on-github/finding-ways-to-contribute-to-open-source-on-github)
* [Set up Git](https://docs.github.com/en/get-started/git-basics/set-up-git)
* [GitHub flow](https://docs.github.com/en/get-started/using-github/github-flow)
* [Collaborating with pull requests](https://docs.github.com/en/github/collaborating-with-pull-requests)

## License

This project is dual-licensed under:

* **Creative Commons Attribution 4.0** - for documentation and content in the assets, content, and data folders (see [LICENSE](LICENSE))
* **MIT License** - for code (see [LICENSE-CODE](LICENSE-CODE))
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ailyProject/aily-blockly]]></title>
            <link>https://github.com/ailyProject/aily-blockly</link>
            <guid>https://github.com/ailyProject/aily-blockly</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:19 GMT</pubDate>
            <description><![CDATA[AI IDE for hardware development, support Arduino, MicroPython, ESP32, STM32, RP2040, Nrf5x...]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ailyProject/aily-blockly">ailyProject/aily-blockly</a></h1>
            <p>AI IDE for hardware development, support Arduino, MicroPython, ESP32, STM32, RP2040, Nrf5x...</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,150</p>
            <p>Forks: 78</p>
            <p>Stars today: 101 stars today</p>
            <h2>README</h2><pre># aily blockly  

[‰∏≠Êñá](README_ZH.md) | English

## About This Software
Aily Project is a hardware development integrated environment that plans to integrate numerous AI capabilities to help hardware developers develop more smoothly.  
Aily Blockly is a blockly IDE under the aily Project. In the early stage, it provides AI-assisted programming capabilities for non-professional users. The long-term goal is to break the boundary between professional development and non-professional development, and ultimately achieve natural language programming.  

&lt;img src=&quot;./img/home.webp&quot; /&gt;

&gt; We aim to design and develop this project as industrial-grade software, but the project is currently in the alpha stage and is not recommended for mass production device firmware development. However, the current version is perfectly suitable for prototype verification and educational teaching.  

## Current Version Highlights  
1. **Engineering Project Management**
Uses npm for project management, achieving board and library management on a per-project basis. This solves many engineering deficiencies in traditional embedded development environments. For example, using Arduino IDE may result in board package, library, and current project mismatches, causing compilation failures and runtime errors. In this software, the board versions and library versions in each project are independent and do not affect each other.

2. **Library Manager**
Although we have prepared many libraries (covering almost all commonly used modules), these libraries are actually generated by AI and we have not verified them in detail. We need beta testers to verify and improve them together with us.

3. **Powerful and Compact Serial Debug Tool**
Attempts to create an all-purpose serial tool. Welcome everyone to test, provide feedback, and propose new ideas.

4. **AI Project Generation**
According to user requirements, automatically analyzes projects, recommends development boards, modules, and libraries, generates project architecture diagrams and pin connection diagrams, and creates projects for users.

5. **AI Code Generation**
According to user requirements, automatically writes programs.

6. **AI Library Conversion**
Native C/C++ libraries can be easily converted to libraries used by this software. Based on large model configuration generation, during development, if you want to use an Arduino library but don&#039;t have the corresponding blockly library, just provide the Arduino library to AI, and AI will automatically analyze and generate the corresponding blockly library. With this feature, this software can become the blockly platform with the most libraries.

7. **AI Development Board Configuration Generation (Under improvement)**
Based on large model configuration generation, when adding development boards, you no longer need to write new configurations purely by hand. Just provide the development board documentation (md format), and AI will automatically analyze and help you generate development board configuration files. (Only supports development boards with esp32, avr, renesas, rp2040, stm32 as the core, because compilers and core SDKs still need to be prepared by us in advance to the repository)

8. **Lightning Compilation Tool** (Phase 1 online, Phase 2 coming soon!)
Edge-cloud collaboration, lightning compilation. Reduces the original 1-hour compilation work to 1 minute!

## Unofficial Version Notes  
This alpha version for testing only guarantees the minimum usability, and many planned highlight features have not yet been designed and developed.
The current version is not recommended for actual work use, as many adjustments we make later may cause incompatibility between versions.

## Planned Features
¬∑ Hardware simulation  
¬∑ microPython support (mode added, but no library support yet)  

## Documentation
[User Documentation](https://aily.pro/doc)  
[Library Adaptation Documentation](https://github.com/ailyProject/aily-blockly-libraries/blob/main/%E5%BA%93%E8%A7%84%E8%8C%83.md)  
[Software Development Documentation](./develop.md)  

## Related Repositories
[Development Boards](https://github.com/ailyProject/aily-blockly-boards)  
[Block Libraries](https://github.com/ailyProject/aily-blockly-libraries)  
[Compilers](https://github.com/ailyProject/aily-blockly-compilers)  
[Related Tools](https://github.com/ailyProject/aily-project-tools)  

## Project Sponsorship
This project is sponsored by the following companies and individuals

### Corporate Sponsors
&lt;a target=&quot;_blank&quot; href=&quot;https://www.seeedstudio.com/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\seeedstudio\logo_l.webp&quot; alt=&quot;seeedstudio&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;  
&lt;a target=&quot;_blank&quot; href=&quot;https://www.seekfree.cn/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\seekfree\logo_l.webp&quot; alt=&quot;seekfree&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://www.diandeng.tech/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\diandeng\logo_l.webp&quot; alt=&quot;diandeng&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;  
&lt;a target=&quot;_blank&quot; href=&quot;https://www.openjumper.com/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\openjumper\logo.webp&quot; alt=&quot;openjumper&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://www.pdmicro.cn/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\pengde\logo.webp&quot; alt=&quot;pengde&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;  
&lt;a target=&quot;_blank&quot; href=&quot;https://www.titlab.cn/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\titlab\logo_l.webp&quot; alt=&quot;titlab&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;  
&lt;a target=&quot;_blank&quot; href=&quot;https://www.emakefun.com&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\emakefun\logo_l.webp&quot; alt=&quot;emakefun&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;  
&lt;a target=&quot;_blank&quot; href=&quot;http://www.keyes-robot.com/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\keyes\logo_l.webp&quot; alt=&quot;keyes&quot; width=200 /&gt;
&lt;/a&gt;  

### Individual Sponsors   
Tao Dong (Tianwei Electronics)  
Xia Qing (Mushroom Cloud Maker Space)  
Du Zhongzhong Dzz (Community Partner)  
Li Duan (Yixuehui)  
Sun Junjie (Community Partner)  

## Main Open Source Projects Used in This Project
[electron]() This project uses electron to build desktop applications  
[angular]() This project uses angular as the rendering end to build main UI logic  
[node]() This project uses npm and node for package management and executing necessary scripts  
[7z]() This project uses 7z to reduce the size of some packages (such as the huge ESP32 compiler)  
Other content can be found in [package.json](./package.json)  

## The AI features of this project reference the following projects
[Kode](https://github.com/shareAI-lab/Kode-cli)  
[copilot](https://github.com/microsoft/vscode-copilot-chat)  

## Additional Rights Statement  
1. This software is free software under the GPL license. Without authorization, the sale of this software or derivative software based on this software is prohibited.
2. Hardware works developed using this software are not restricted by the GPL, and users may decide on their own release and usage methods.
3. For derivatives based on this software, information about relevant rights holders and sponsors of this project must not be removed, and such information must appear on the software startup page.
4. The online service content attached to this project must not be removed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[Anionex/banana-slides]]></title>
            <link>https://github.com/Anionex/banana-slides</link>
            <guid>https://github.com/Anionex/banana-slides</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:18 GMT</pubDate>
            <description><![CDATA[‰∏Ä‰∏™Âü∫‰∫énano banana proüçåÁöÑÂéüÁîüAI PPTÁîüÊàêÂ∫îÁî®ÔºåËøàÂêëÁúüÊ≠£ÁöÑÔºÇVibe PPTÔºÇ; ÊîØÊåÅ‰∏ä‰º†‰ªªÊÑèÊ®°ÊùøÂõæÁâáÔºõ‰∏ä‰º†‰ªªÊÑèÁ¥†Êùê&Êô∫ËÉΩËß£ÊûêÔºõ‰∏ÄÂè•ËØù/Â§ßÁ∫≤/È°µÈù¢ÊèèËø∞Ëá™Âä®ÁîüÊàêPPTÔºõÂè£Â§¥‰øÆÊîπÊåáÂÆöÂå∫Âüü„ÄÅ‰∏ÄÈîÆÂØºÂá∫ÂèØÁºñËæëppt - An AI-native PPT generator based on nano banana proüçå]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Anionex/banana-slides">Anionex/banana-slides</a></h1>
            <p>‰∏Ä‰∏™Âü∫‰∫énano banana proüçåÁöÑÂéüÁîüAI PPTÁîüÊàêÂ∫îÁî®ÔºåËøàÂêëÁúüÊ≠£ÁöÑÔºÇVibe PPTÔºÇ; ÊîØÊåÅ‰∏ä‰º†‰ªªÊÑèÊ®°ÊùøÂõæÁâáÔºõ‰∏ä‰º†‰ªªÊÑèÁ¥†Êùê&Êô∫ËÉΩËß£ÊûêÔºõ‰∏ÄÂè•ËØù/Â§ßÁ∫≤/È°µÈù¢ÊèèËø∞Ëá™Âä®ÁîüÊàêPPTÔºõÂè£Â§¥‰øÆÊîπÊåáÂÆöÂå∫Âüü„ÄÅ‰∏ÄÈîÆÂØºÂá∫ÂèØÁºñËæëppt - An AI-native PPT generator based on nano banana proüçå</p>
            <p>Language: TypeScript</p>
            <p>Stars: 12,435</p>
            <p>Forks: 1,452</p>
            <p>Stars today: 45 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img width=&quot;256&quot; src=&quot;https://github.com/user-attachments/assets/6f9e4cf9-912d-4faa-9d37-54fb676f547e&quot;&gt;

*Vibe your PPT like vibing code.*

**‰∏≠Êñá | [English](README_EN.md)**

&lt;p&gt;

[![GitHub Stars](https://img.shields.io/github/stars/Anionex/banana-slides?style=square&amp;color=FFD700)](https://github.com/Anionex/banana-slides/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/Anionex/banana-slides?style=square&amp;color=FFD700)](https://github.com/Anionex/banana-slides/network)
[![GitHub Watchers](https://img.shields.io/github/watchers/Anionex/banana-slides?style=square&amp;color=FFD700)](https://github.com/Anionex/banana-slides/watchers)


[![Version](https://img.shields.io/badge/version-v0.4.0-44cc11)](https://github.com/Anionex/banana-slides)
![Docker](https://img.shields.io/badge/Docker-Build-4A90D9?logo=docker&amp;logoColor=white)
[![License](https://img.shields.io/github/license/Anionex/banana-slides?color=0055aa)](https://github.com/Anionex/banana-slides/blob/main/LICENSE)





&lt;/p&gt; 

&lt;b&gt;‰∏Ä‰∏™Âü∫‰∫énano banana proüçåÁöÑÂéüÁîüAI PPTÁîüÊàêÂ∫îÁî®ÔºåÊîØÊåÅÊÉ≥Ê≥ï/Â§ßÁ∫≤/È°µÈù¢ÊèèËø∞ÁîüÊàêÂÆåÊï¥PPTÊºîÁ§∫ÊñáÁ®øÔºå&lt;br&gt;&lt;/b&gt;
&lt;b&gt; Ëá™Âä®ÊèêÂèñÈôÑ‰ª∂ÂõæË°®„ÄÅ‰∏ä‰º†‰ªªÊÑèÁ¥†Êùê„ÄÅÂè£Â§¥ÊèêÂá∫‰øÆÊîπÔºåËøàÂêëÁúüÊ≠£ÁöÑ&quot;Vibe PPT&quot; &lt;/b&gt;

&lt;b&gt;üéØ Èôç‰ΩéPPTÂà∂‰ΩúÈó®ÊßõÔºåËÆ©ÊØè‰∏™‰∫∫ÈÉΩËÉΩÂø´ÈÄüÂàõ‰ΩúÂá∫ÁæéËßÇ‰∏ì‰∏öÁöÑÊºîÁ§∫ÊñáÁ®ø&lt;/b&gt;

&lt;br&gt;

*Â¶ÇÊûúËØ•È°πÁõÆÂØπ‰Ω†ÊúâÁî®, Ê¨¢Ëøéstarüåü &amp;  forküç¥*

&lt;br&gt;

&lt;/p&gt;

&lt;/div&gt;



## ‚ú® È°πÁõÆÁºòËµ∑
‰Ω†ÊòØÂê¶‰πüÊõæÈô∑ÂÖ•ËøôÊ†∑ÁöÑÂõ∞Â¢ÉÔºöÊòéÂ§©Â∞±Ë¶ÅÊ±áÊä•Ôºå‰ΩÜPPTËøòÊòØ‰∏ÄÁâáÁ©∫ÁôΩÔºõËÑë‰∏≠ÊúâÊó†Êï∞Á≤æÂΩ©ÁöÑÊÉ≥Ê≥ïÔºåÂç¥Ë¢´ÁπÅÁêêÁöÑÊéíÁâàÂíåËÆæËÆ°Ê∂àÁ£®ÊéâÊâÄÊúâÁÉ≠ÊÉÖÔºü

Êàë(‰ª¨)Ê∏¥ÊúõËÉΩÂø´ÈÄüÂàõ‰ΩúÂá∫Êó¢‰∏ì‰∏öÂèàÂÖ∑ËÆæËÆ°ÊÑüÁöÑÊºîÁ§∫ÊñáÁ®øÔºå‰º†ÁªüÁöÑAI PPTÁîüÊàêappÔºåËôΩÁÑ∂Â§ß‰ΩìÊª°Ë∂≥‚ÄúÂø´‚ÄùËøô‰∏ÄÈúÄÊ±ÇÔºåÂç¥ËøòÂ≠òÂú®‰ª•‰∏ãÈóÆÈ¢òÔºö

- 1Ô∏è‚É£Âè™ËÉΩÈÄâÊã©È¢ÑËÆæÊ®°ÁâàÔºåÊó†Ê≥ïÁÅµÊ¥ªË∞ÉÊï¥È£éÊ†º
- 2Ô∏è‚É£Ëá™Áî±Â∫¶‰ΩéÔºåÂ§öËΩÆÊîπÂä®Èöæ‰ª•ËøõË°å 
- 3Ô∏è‚É£ÊàêÂìÅËßÇÊÑüÁõ∏‰ººÔºåÂêåË¥®Âåñ‰∏•Èáç
- 4Ô∏è‚É£Á¥†ÊùêË¥®ÈáèËæÉ‰ΩéÔºåÁº∫‰πèÈíàÂØπÊÄß
- 5Ô∏è‚É£ÂõæÊñáÊéíÁâàÂâ≤Ë£ÇÔºåËÆæËÆ°ÊÑüÂ∑Æ

‰ª•‰∏äËøô‰∫õÁº∫Èô∑ÔºåËÆ©‰º†ÁªüÁöÑAI pptÁîüÊàêÂô®Èöæ‰ª•ÂêåÊó∂Êª°Ë∂≥Êàë‰ª¨‚ÄúÂø´‚ÄùÂíå‚ÄúÁæé‚ÄùÁöÑ‰∏§Â§ßPPTÂà∂‰ΩúÈúÄÊ±Ç„ÄÇÂç≥‰ΩøËá™Áß∞Vibe PPTÔºå‰ΩÜÊòØÂú®ÊàëÁöÑÁúº‰∏≠ËøòËøú‰∏çÂ§ü‚ÄúVibe‚Äù„ÄÇ

‰ΩÜÊòØÔºånano bananaüçåÊ®°ÂûãÁöÑÂá∫Áé∞ËÆ©‰∏ÄÂàáÊúâ‰∫ÜËΩ¨Êú∫„ÄÇÊàëÂ∞ùËØï‰ΩøÁî®üçåproËøõË°åpptÈ°µÈù¢ÁîüÊàêÔºåÂèëÁé∞ÁîüÊàêÁöÑÁªìÊûúÊó†ËÆ∫ÊòØË¥®Èáè„ÄÅÁæéÊÑüËøòÊòØ‰∏ÄËá¥ÊÄßÔºåÈÉΩÂÅöÁöÑÈùûÂ∏∏Â•ΩÔºå‰∏îÂá†‰πéËÉΩÁ≤æÁ°ÆÊ∏≤ÊüìpromptË¶ÅÊ±ÇÁöÑÊâÄÊúâÊñáÂ≠ó+ÈÅµÂæ™ÂèÇËÄÉÂõæÁöÑÈ£éÊ†º„ÄÇÈÇ£‰∏∫‰ªÄ‰πà‰∏çÂü∫‰∫éüçåproÔºåÂÅö‰∏Ä‰∏™ÂéüÁîüÁöÑ&quot;Vibe PPT&quot;Â∫îÁî®Âë¢Ôºü

## üë®‚Äçüíª ÈÄÇÁî®Âú∫ÊôØ

1. **Â∞èÁôΩ**ÔºöÈõ∂Èó®ÊßõÂø´ÈÄüÁîüÊàêÁæéËßÇPPTÔºåÊó†ÈúÄËÆæËÆ°ÁªèÈ™åÔºåÂáèÂ∞ëÊ®°ÊùøÈÄâÊã©ÁÉ¶ÊÅº
2. **PPT‰∏ì‰∏ö‰∫∫Â£´**ÔºöÂèÇËÄÉAIÁîüÊàêÁöÑÂ∏ÉÂ±ÄÂíåÂõæÊñáÂÖÉÁ¥†ÁªÑÂêàÔºåÂø´ÈÄüËé∑ÂèñËÆæËÆ°ÁÅµÊÑü
3. **ÊïôËÇ≤Â∑•‰ΩúËÄÖ**ÔºöÂ∞ÜÊïôÂ≠¶ÂÜÖÂÆπÂø´ÈÄüËΩ¨Êç¢‰∏∫ÈÖçÂõæÊïôÊ°àPPTÔºåÊèêÂçáËØæÂ†ÇÊïàÊûú
4. **Â≠¶Áîü**ÔºöÂø´ÈÄüÂÆåÊàê‰Ωú‰∏öPreÔºåÊääÁ≤æÂäõ‰∏ìÊ≥®‰∫éÂÜÖÂÆπËÄåÈùûÊéíÁâàÁæéÂåñ
5. **ËÅåÂú∫‰∫∫Â£´**ÔºöÂïÜ‰∏öÊèêÊ°à„ÄÅ‰∫ßÂìÅ‰ªãÁªçÂø´ÈÄüÂèØËßÜÂåñÔºåÂ§öÂú∫ÊôØÂø´ÈÄüÈÄÇÈÖç


## üé® ÁªìÊûúÊ°à‰æã


&lt;div align=&quot;center&quot;&gt;

| | |
|:---:|:---:|
| &lt;img src=&quot;https://github.com/user-attachments/assets/d58ce3f7-bcec-451d-a3b9-ca3c16223644&quot; width=&quot;500&quot; alt=&quot;Ê°à‰æã3&quot;&gt; | &lt;img src=&quot;https://github.com/user-attachments/assets/c64cd952-2cdf-4a92-8c34-0322cbf3de4e&quot; width=&quot;500&quot; alt=&quot;Ê°à‰æã2&quot;&gt; |
| **ËΩØ‰ª∂ÂºÄÂèëÊúÄ‰Ω≥ÂÆûË∑µ** | **DeepSeek-V3.2ÊäÄÊúØÂ±ïÁ§∫** |
| &lt;img src=&quot;https://github.com/user-attachments/assets/383eb011-a167-4343-99eb-e1d0568830c7&quot; width=&quot;500&quot; alt=&quot;Ê°à‰æã4&quot;&gt; | &lt;img src=&quot;https://github.com/user-attachments/assets/1a63afc9-ad05-4755-8480-fc4aa64987f1&quot; width=&quot;500&quot; alt=&quot;Ê°à‰æã1&quot;&gt; |
| **È¢ÑÂà∂ËèúÊô∫ËÉΩ‰∫ßÁ∫øË£ÖÂ§áÁ†îÂèëÂíå‰∫ß‰∏öÂåñ** | **Èí±ÁöÑÊºîÂèòÔºö‰ªéË¥ùÂ£≥Âà∞Á∫∏Â∏ÅÁöÑÊóÖÁ®ã** |

&lt;/div&gt;

Êõ¥Â§öÂèØËßÅ&lt;a href=&quot;https://github.com/Anionex/banana-slides/issues/2&quot; &gt; ‰ΩøÁî®Ê°à‰æã &lt;/a&gt;


## üéØ ÂäüËÉΩ‰ªãÁªç

### 1. ÁÅµÊ¥ªÂ§öÊ†∑ÁöÑÂàõ‰ΩúË∑ØÂæÑ
ÊîØÊåÅ**ÊÉ≥Ê≥ï**„ÄÅ**Â§ßÁ∫≤**„ÄÅ**È°µÈù¢ÊèèËø∞**‰∏âÁßçËµ∑Ê≠•ÊñπÂºèÔºåÊª°Ë∂≥‰∏çÂêåÂàõ‰Ωú‰π†ÊÉØ„ÄÇ
- **‰∏ÄÂè•ËØùÁîüÊàê**ÔºöËæìÂÖ•‰∏Ä‰∏™‰∏ªÈ¢òÔºåAI Ëá™Âä®ÁîüÊàêÁªìÊûÑÊ∏ÖÊô∞ÁöÑÂ§ßÁ∫≤ÂíåÈÄêÈ°µÂÜÖÂÆπÊèèËø∞„ÄÇ
- **Ëá™ÁÑ∂ËØ≠Ë®ÄÁºñËæë**ÔºöÊîØÊåÅ‰ª• Vibe ÂΩ¢ÂºèÂè£Â§¥‰øÆÊîπÂ§ßÁ∫≤ÊàñÊèèËø∞ÔºàÂ¶Ç&quot;ÊääÁ¨¨‰∏âÈ°µÊîπÊàêÊ°à‰æãÂàÜÊûê&quot;ÔºâÔºåAI ÂÆûÊó∂ÂìçÂ∫îË∞ÉÊï¥„ÄÇ
- **Â§ßÁ∫≤/ÊèèËø∞Ê®°Âºè**ÔºöÊó¢ÂèØ‰∏ÄÈîÆÊâπÈáèÁîüÊàêÔºå‰πüÂèØÊâãÂä®Ë∞ÉÊï¥ÁªÜËäÇ„ÄÇ

&lt;img width=&quot;2000&quot; height=&quot;1125&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/7fc1ecc6-433d-4157-b4ca-95fcebac66ba&quot; /&gt;


### 2. Âº∫Â§ßÁöÑÁ¥†ÊùêËß£ÊûêËÉΩÂäõ
- **Â§öÊ†ºÂºèÊîØÊåÅ**Ôºö‰∏ä‰º† PDF/Docx/MD/Txt Á≠âÊñá‰ª∂ÔºåÂêéÂè∞Ëá™Âä®Ëß£ÊûêÂÜÖÂÆπ„ÄÇ
- **Êô∫ËÉΩÊèêÂèñ**ÔºöËá™Âä®ËØÜÂà´ÊñáÊú¨‰∏≠ÁöÑÂÖ≥ÈîÆÁÇπ„ÄÅÂõæÁâáÈìæÊé•ÂíåÂõæË°®‰ø°ÊÅØÔºå‰∏∫ÁîüÊàêÊèê‰æõ‰∏∞ÂØåÁ¥†Êùê„ÄÇ
- **È£éÊ†ºÂèÇËÄÉ**ÔºöÊîØÊåÅ‰∏ä‰º†ÂèÇËÄÉÂõæÁâáÊàñÊ®°ÊùøÔºåÂÆöÂà∂ PPT È£éÊ†º„ÄÇ

&lt;img width=&quot;1920&quot; height=&quot;1080&quot; alt=&quot;Êñá‰ª∂Ëß£Êûê‰∏éÁ¥†ÊùêÂ§ÑÁêÜ&quot; src=&quot;https://github.com/user-attachments/assets/8cda1fd2-2369-4028-b310-ea6604183936&quot; /&gt;

### 3. &quot;Vibe&quot; ÂºèËá™ÁÑ∂ËØ≠Ë®Ä‰øÆÊîπ
‰∏çÂÜçÂèóÈôê‰∫éÂ§çÊùÇÁöÑËèúÂçïÊåâÈíÆÔºåÁõ¥Êé•ÈÄöËøá**Ëá™ÁÑ∂ËØ≠Ë®Ä**‰∏ãËææ‰øÆÊîπÊåá‰ª§„ÄÇ
- **Â±ÄÈÉ®ÈáçÁªò**ÔºöÂØπ‰∏çÊª°ÊÑèÁöÑÂå∫ÂüüËøõË°åÂè£Â§¥Âºè‰øÆÊîπÔºàÂ¶Ç&quot;ÊääËøô‰∏™ÂõæÊç¢ÊàêÈ•ºÂõæ&quot;Ôºâ„ÄÇ
- **Êï¥È°µ‰ºòÂåñ**ÔºöÂü∫‰∫é nano banana proüçå ÁîüÊàêÈ´òÊ∏Ö„ÄÅÈ£éÊ†ºÁªü‰∏ÄÁöÑÈ°µÈù¢„ÄÇ

&lt;img width=&quot;2000&quot; height=&quot;1125&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/929ba24a-996c-4f6d-9ec6-818be6b08ea3&quot; /&gt;


### 4. ÂºÄÁÆ±Âç≥Áî®ÁöÑÊ†ºÂºèÂØºÂá∫
- **Â§öÊ†ºÂºèÊîØÊåÅ**Ôºö‰∏ÄÈîÆÂØºÂá∫Ê†áÂáÜ **PPTX** Êàñ **PDF** Êñá‰ª∂„ÄÇ
- **ÂÆåÁæéÈÄÇÈÖç**ÔºöÈªòËÆ§ 16:9 ÊØî‰æãÔºåÊéíÁâàÊó†ÈúÄ‰∫åÊ¨°Ë∞ÉÊï¥ÔºåÁõ¥Êé•ÊºîÁ§∫„ÄÇ

&lt;img width=&quot;1000&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/3e54bbba-88be-4f69-90a1-02e875c25420&quot; /&gt;
&lt;img width=&quot;1748&quot; height=&quot;538&quot; alt=&quot;PPT‰∏éPDFÂØºÂá∫&quot; src=&quot;https://github.com/user-attachments/assets/647eb9b1-d0b6-42cb-a898-378ebe06c984&quot; /&gt;

### 5. ÂèØËá™Áî±ÁºñËæëÁöÑpptxÂØºÂá∫ÔºàBetaËø≠‰ª£‰∏≠Ôºâ
- **ÂØºÂá∫ÂõæÂÉè‰∏∫È´òËøòÂéüÂ∫¶„ÄÅËÉåÊôØÂπ≤ÂáÄÁöÑ„ÄÅÂèØËá™Áî±ÁºñËæëÂõæÂÉèÂíåÊñáÂ≠óÁöÑPPTÈ°µÈù¢**
- Áõ∏ÂÖ≥Êõ¥Êñ∞ËßÅ https://github.com/Anionex/banana-slides/issues/121
&lt;img width=&quot;1000&quot;  alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/a85d2d48-1966-4800-a4bf-73d17f914062&quot; /&gt;

&lt;br&gt;

**üåüÂíånotebooklm slide deckÂäüËÉΩÂØπÊØî**
| ÂäüËÉΩ | notebooklm | Êú¨È°πÁõÆ | 
| --- | --- | --- |
| È°µÊï∞‰∏äÈôê | 15È°µ | **Êó†ÈôêÂà∂** | 
| ‰∫åÊ¨°ÁºñËæë | ‰∏çÊîØÊåÅ | **Ê°ÜÈÄâÁºñËæë+Âè£Â§¥ÁºñËæë** |
| Á¥†ÊùêÊ∑ªÂä† | ÁîüÊàêÂêéÊó†Ê≥ïÊ∑ªÂä† | **ÁîüÊàêÂêéËá™Áî±Ê∑ªÂä†** |
| ÂØºÂá∫Ê†ºÂºè | ‰ªÖÊîØÊåÅÂØºÂá∫‰∏∫ PDF | **ÂØºÂá∫‰∏∫PDF„ÄÅ(ÂèØÁºñËæë)pptx** |
| Ê∞¥Âç∞ | ÂÖçË¥πÁâàÊúâÊ∞¥Âç∞ | **Êó†Ê∞¥Âç∞ÔºåËá™Áî±Â¢ûÂà†ÂÖÉÁ¥†** |

&gt; Ê≥®ÔºöÈöèÁùÄÊñ∞ÂäüËÉΩÊ∑ªÂä†,ÂØπÊØîÂèØËÉΩËøáÊó∂



## üî• ËøëÊúüÊõ¥Êñ∞
- „Äê2-9„ÄëÔºö
  * Êñ∞ÂäüËÉΩ
    * ÊîØÊåÅÂú®È¶ñÈ°µ„ÄÅÂ§ßÁ∫≤„ÄÅÊèèËø∞Âç°ÁâáÈáåÈù¢Á≤òË¥¥ÂõæÁâáÂπ∂Á´ãÂç≥ËØÜÂà´ÔºåÂπ∂Êèê‰æõÊõ¥Â•ΩÁöÑ‰∫§‰∫í‰ΩìÈ™å
    * Â§ßÁ∫≤Á´†ËäÇÊâãÂä®ÁºñËæëÔºöÊîØÊåÅÊâãÂä®Ë∞ÉÊï¥È°µÈù¢ÊâÄÂ±ûÁ´†ËäÇÔºàpartÔºâ„ÄÇ
    * Docker Â§öÊû∂ÊûÑÔºöÈïúÂÉèÊîØÊåÅ amd64 / arm64 ÊûÑÂª∫„ÄÇ
    * ÂõΩÈôÖÂåñ + ÊöóÈªëÊ®°ÂºèÔºöÊñ∞Â¢û‰∏≠Ëã±ÊñáÂàáÊç¢ÔºõÊîØÊåÅ‰∫ÆËâ≤/ÊöóËâ≤/Ë∑üÈöèÁ≥ªÁªü‰∏ªÈ¢òÔºõÂÖ®ÁªÑ‰ª∂ÈÄÇÈÖçÊöóÈªëÊ®°Âºè„ÄÇ
  * ‰øÆÂ§ç‰∏é‰ΩìÈ™å‰ºòÂåñ
    * ‰øÆÂ§çÂØºÂá∫Áõ∏ÂÖ≥ 500„ÄÅÂèÇËÄÉÊñá‰ª∂ÂÖ≥ËÅîÊó∂Â∫è„ÄÅoutline/page Êï∞ÊçÆÈîô‰Ωç„ÄÅ‰ªªÂä°ËΩÆËØ¢ÈîôËØØÈ°πÁõÆ„ÄÅÊèèËø∞ÁîüÊàêÊó†ÈôêËΩÆËØ¢„ÄÅÂõæÁâáÈ¢ÑËßàÂÜÖÂ≠òÊ≥ÑÊºè„ÄÅÊâπÈáèÂà†Èô§ÈÉ®ÂàÜÂ§±Ë¥•Â§ÑÁêÜ„ÄÇ
    * ‰ºòÂåñÊ†ºÂºèÁ§∫‰æãÊèêÁ§∫„ÄÅHTTP ÈîôËØØÊèêÁ§∫ÊñáÊ°à„ÄÅModal ÂÖ≥Èó≠‰ΩìÈ™å„ÄÅÊ∏ÖÁêÜÊóßÈ°πÁõÆ localStorage„ÄÅÁßªÈô§È¶ñÊ¨°ÂàõÂª∫È°πÁõÆÂÜó‰ΩôÊèêÁ§∫„ÄÇ
    * Ëã•Âπ≤ÂÖ∂‰ªñ‰ºòÂåñÂíå‰øÆÂ§ç
- „Äê1-4„Äë : v0.4.0ÂèëÂ∏ÉÔºöÂèØÁºñËæëpptxÂØºÂá∫ÂÖ®Èù¢ÂçáÁ∫ßÔºö
  * ÊîØÊåÅÊúÄÂ§ßÁ®ãÂ∫¶ËøòÂéüÂõæÁâá‰∏≠ÊñáÂ≠óÁöÑÂ≠óÂè∑„ÄÅÈ¢úËâ≤„ÄÅÂä†Á≤óÁ≠âÊ†∑ÂºèÔºõ
  * ÊîØÊåÅ‰∫ÜËØÜÂà´Ë°®Ê†º‰∏≠ÁöÑÊñáÂ≠óÂÜÖÂÆπÔºõ
  * Êõ¥Á≤æÁ°ÆÁöÑÊñáÂ≠óÂ§ßÂ∞èÂíåÊñáÂ≠ó‰ΩçÁΩÆËøòÂéüÈÄªËæë
  * ‰ºòÂåñÂØºÂá∫Â∑•‰ΩúÊµÅÔºåÂ§ßÂ§ßÂáèÂ∞ë‰∫ÜÂØºÂá∫ÂêéËÉåÊôØÂõæÊÆãÁïôÊñáÂ≠óÁöÑÁé∞Ë±°Ôºõ
  * ÊîØÊåÅÈ°µÈù¢Â§öÈÄâÈÄªËæëÔºåÁÅµÊ¥ªÈÄâÊã©ÈúÄË¶ÅÁîüÊàêÂíåÂØºÂá∫ÁöÑÂÖ∑‰ΩìÈ°µÈù¢„ÄÇ
  * **ËØ¶ÁªÜÊïàÊûúÂíå‰ΩøÁî®ÊñπÊ≥ïËßÅ https://github.com/Anionex/banana-slides/issues/121**

- „Äê12-27„Äë: Âä†ÂÖ•‰∫ÜÂØπÊó†ÂõæÁâáÊ®°ÊùøÊ®°ÂºèÁöÑÊîØÊåÅÂíåËæÉÈ´òË¥®ÈáèÁöÑÊñáÂ≠óÈ¢ÑËÆæÔºåÁé∞Âú®ÂèØ‰ª•ÈÄöËøáÁ∫ØÊñáÂ≠óÊèèËø∞ÁöÑÊñπÂºèÊù•ÊéßÂà∂pptÈ°µÈù¢È£éÊ†º


## üó∫Ô∏è ÂºÄÂèëËÆ°Âàí

| Áä∂ÊÄÅ | ÈáåÁ®ãÁ¢ë |
| --- | --- |
| ‚úÖ Â∑≤ÂÆåÊàê | ‰ªéÊÉ≥Ê≥ï„ÄÅÂ§ßÁ∫≤„ÄÅÈ°µÈù¢ÊèèËø∞‰∏âÁßçË∑ØÂæÑÂàõÂª∫ PPT |
| ‚úÖ Â∑≤ÂÆåÊàê | Ëß£ÊûêÊñáÊú¨‰∏≠ÁöÑ Markdown Ê†ºÂºèÂõæÁâá |
| ‚úÖ Â∑≤ÂÆåÊàê | PPT ÂçïÈ°µÊ∑ªÂä†Êõ¥Â§öÁ¥†Êùê |
| ‚úÖ Â∑≤ÂÆåÊàê | PPT ÂçïÈ°µÊ°ÜÈÄâÂå∫ÂüüVibeÂè£Â§¥ÁºñËæë |
| ‚úÖ Â∑≤ÂÆåÊàê | Á¥†ÊùêÊ®°Âùó: Á¥†ÊùêÁîüÊàê„ÄÅ‰∏ä‰º†Á≠â |
| ‚úÖ Â∑≤ÂÆåÊàê | ÊîØÊåÅÂ§öÁßçÊñá‰ª∂ÁöÑ‰∏ä‰º†+Ëß£Êûê |
| ‚úÖ Â∑≤ÂÆåÊàê | ÊîØÊåÅVibeÂè£Â§¥Ë∞ÉÊï¥Â§ßÁ∫≤ÂíåÊèèËø∞ |
| ‚úÖ Â∑≤ÂÆåÊàê | ÂàùÊ≠•ÊîØÊåÅÂèØÁºñËæëÁâàÊú¨pptxÊñá‰ª∂ÂØºÂá∫ |
| üîÑ ËøõË°å‰∏≠ | ÊîØÊåÅÂ§öÂ±ÇÊ¨°„ÄÅÁ≤æÁ°ÆÊä†ÂõæÁöÑÂèØÁºñËæëpptxÂØºÂá∫ |
| üîÑ ËøõË°å‰∏≠ | ÁΩëÁªúÊêúÁ¥¢ |
| üîÑ ËøõË°å‰∏≠ | Agent Ê®°Âºè |
| üöç ÈÉ®ÂàÜ | ‰ºòÂåñÂâçÁ´ØÂä†ËΩΩÈÄüÂ∫¶ |
| üß≠ ËßÑÂàí‰∏≠ | Âú®Á∫øÊí≠ÊîæÂäüËÉΩ |
| üß≠ ËßÑÂàí‰∏≠ | ÁÆÄÂçïÁöÑÂä®ÁîªÂíåÈ°µÈù¢ÂàáÊç¢ÊïàÊûú |
| üöç ÈÉ®ÂàÜ | Â§öËØ≠ÁßçÊîØÊåÅ |
| üè¢ÂïÜ‰∏öÁâàÂäüËÉΩ | Áî®Êà∑Á≥ªÁªü |

## üì¶ ‰ΩøÁî®ÊñπÊ≥ï

### ÔºàÊñ∞Ôºâ‰ΩøÁî®Â∫îÁî®Ê®°Êùø‰∏ÄÈîÆÈÉ®ÁΩ≤
ËøôÊòØÊúÄÁÆÄÂçïÁöÑÊñπÂºèÔºåÊó†ÈúÄÂÆâË£ÖdockerÊàñ‰∏ãËΩΩÈ°πÁõÆÔºåÂàõÂª∫ÂêéÂèØÁõ¥Êé•ËøõÂÖ•Â∫îÁî®


1. ÈÄöËøáÈõ®‰∫ë‰∏ÄÈîÆÈÉ®ÁΩ≤ÂíåÂêØÂä®Êú¨Â∫îÁî® (Êñ∞Áî®Êà∑Êúâ15Â§©ÂÖçË¥π‰ΩøÁî®+È¶ñÂÖÖÂèåÂÄçÊîøÁ≠ñ)

[![ÈÄöËøáÈõ®‰∫ë‰∏ÄÈîÆÈÉ®ÁΩ≤](https://rainyun-apps.cn-nb1.rains3.com/materials/deploy-on-rainyun-cn.svg)](https://app.rainyun.com/apps/rca/store/7549/anionex_)

2. Êï¨ËØ∑ÊúüÂæÖ


### ‰ΩøÁî® Docker Composeüê≥
ÈÄöËøádocker composeÂø´ÈÄüÂêØÂä®ÂâçÂêéÁ´ØÊúçÂä°„ÄÇ

&lt;details&gt;
  &lt;summary&gt;üìí Windows/MacÁî®Êà∑ËØ¥Êòé&lt;/summary&gt;

Â¶ÇÊûú‰Ω†‰ΩøÁî® **Windows Êàñ macOS**ÔºåËØ∑ÂÖàÂÆâË£Ö **Docker Desktop**ÔºåÂπ∂Á°Æ‰øù Docker Ê≠£Âú®ËøêË°åÔºàWindows ÂèØÊ£ÄÊü•Á≥ªÁªüÊâòÁõòÂõæÊ†áÔºõmacOS ÂèØÊ£ÄÊü•ËèúÂçïÊ†èÂõæÊ†áÔºâÔºåÁÑ∂ÂêéÊåâÊñáÊ°£‰∏≠ÁöÑÁõ∏ÂêåÊ≠•È™§Êìç‰Ωú„ÄÇ

&gt; **ÊèêÁ§∫**ÔºöÂ¶ÇÊûúÈÅáÂà∞ÈóÆÈ¢òÔºåWindows Áî®Êà∑ËØ∑Âú® Docker Desktop ËÆæÁΩÆ‰∏≠ÂêØÁî® **WSL 2 ÂêéÁ´Ø**ÔºàÊé®ËçêÔºâÔºõÂêåÊó∂Á°Æ‰øùÁ´ØÂè£ **3000** Âíå **5000** Êú™Ë¢´Âç†Áî®„ÄÇ

&lt;/details&gt;

0. **ÂÖãÈöÜ‰ª£Á†Å‰ªìÂ∫ì**
```bash
git clone https://github.com/Anionex/banana-slides
cd banana-slides
```

1. **ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáè**

ÂàõÂª∫ `.env` Êñá‰ª∂ÔºàÂèÇËÄÉ `.env.example`ÔºâÔºö
```bash
cp .env.example .env
```

ÁºñËæë `.env` Êñá‰ª∂ÔºåÈÖçÁΩÆÂøÖË¶ÅÁöÑÁéØÂ¢ÉÂèòÈáèÔºö
&gt; **È°πÁõÆ‰∏≠Â§ßÊ®°ÂûãÊé•Âè£‰ª•AIHubMixÂπ≥Âè∞Ê†ºÂºè‰∏∫Ê†áÂáÜÔºåÊé®Ëçê‰ΩøÁî® [AIHubMix](https://aihubmix.com/?aff=17EC) Ëé∑ÂèñAPIÂØÜÈí•ÔºåÂáèÂ∞èËøÅÁßªÊàêÊú¨**&lt;br&gt;
&gt; **ÂèãÊÉÖÊèêÁ§∫ÔºöË∞∑Ê≠ånano banana proÊ®°ÂûãÊé•Âè£Ë¥πÁî®ËæÉÈ´òÔºåËØ∑Ê≥®ÊÑèË∞ÉÁî®ÊàêÊú¨**
```env
# AI ProviderÊ†ºÂºèÈÖçÁΩÆ (gemini / openai / vertex)
AI_PROVIDER_FORMAT=gemini

# Gemini Ê†ºÂºèÈÖçÁΩÆÔºàÂΩì AI_PROVIDER_FORMAT=gemini Êó∂‰ΩøÁî®Ôºâ
GOOGLE_API_KEY=your-api-key-here
GOOGLE_API_BASE=https://generativelanguage.googleapis.com
# ‰ª£ÁêÜÁ§∫‰æã: https://aihubmix.com/gemini

# OpenAI Ê†ºÂºèÈÖçÁΩÆÔºàÂΩì AI_PROVIDER_FORMAT=openai Êó∂‰ΩøÁî®Ôºâ
OPENAI_API_KEY=your-api-key-here
OPENAI_API_BASE=https://api.openai.com/v1
# ‰ª£ÁêÜÁ§∫‰æã: https://aihubmix.com/v1

# Vertex AI ÈÖçÁΩÆÔºàAI_PROVIDER_FORMAT=vertexÔºâ
# ÈúÄË¶Å GCP È°πÁõÆÂíåÊúçÂä°Ë¥¶Êà∑ÂØÜÈí•
# VERTEX_PROJECT_ID=your-gcp-project-id
# VERTEX_LOCATION=global
# GOOGLE_APPLICATION_CREDENTIALS=./gcp-service-account.json

# Lazyllm Ê†ºÂºèÈÖçÁΩÆÔºàÂΩì AI_PROVIDER_FORMAT=lazyllm Êó∂‰ΩøÁî®Ôºâ
# ÈÄâÊã©ÊñáÊú¨ÁîüÊàêÂíåÂõæÁâáÁîüÊàê‰ΩøÁî®ÁöÑÂéÇÂïÜ
TEXT_MODEL_SOURCE=deepseek        # ÊñáÊú¨ÁîüÊàêÊ®°ÂûãÂéÇÂïÜ
IMAGE_MODEL_SOURCE=doubao         # ÂõæÁâáÁºñËæëÊ®°ÂûãÂéÇÂïÜ
IMAGE_CAPTION_MODEL_SOURCE=qwen   # ÂõæÁâáÊèèËø∞Ê®°ÂûãÂéÇÂïÜ

# ÂêÑÂéÇÂïÜ API KeyÔºàÂè™ÈúÄÈÖçÁΩÆ‰Ω†Ë¶Å‰ΩøÁî®ÁöÑÂéÇÂïÜÔºâ
DOUBAO_API_KEY=your-doubao-api-key            # ÁÅ´Â±±ÂºïÊìé/Ë±ÜÂåÖ
DEEPSEEK_API_KEY=your-deepseek-api-key        # DeepSeek
QWEN_API_KEY=your-qwen-api-key                # ÈòøÈáå‰∫ë/ÈÄö‰πâÂçÉÈóÆ
GLM_API_KEY=your-glm-api-key                  # Êô∫Ë∞± GLM
SILICONFLOW_API_KEY=your-siliconflow-api-key  # Á°ÖÂü∫ÊµÅÂä®
SENSENOVA_API_KEY=your-sensenova-api-key      # ÂïÜÊ±§Êó•Êó•Êñ∞
MINIMAX_API_KEY=your-minimax-api-key          # MiniMax
...
```

**‰ΩøÁî®Êñ∞ÁâàÂèØÁºñËæëÂØºÂá∫ÈÖçÁΩÆÊñπÊ≥ïÔºåËé∑ÂæóÊõ¥Â•ΩÁöÑÂèØÁºñËæëÂØºÂá∫ÊïàÊûú**: ÈúÄÂú®[ÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂπ≥Âè∞](https://console.bce.baidu.com/iam/#/iam/apikey/list)ÔºàÁÇπÂáªÊ≠§Â§ÑËøõÂÖ•Ôºâ‰∏≠Ëé∑ÂèñAPI KEYÔºåÂ°´ÂÜôÂú®.envÊñá‰ª∂‰∏≠ÁöÑBAIDU_API_KEYÂ≠óÊÆµÔºàÊúâÂÖÖË∂≥ÁöÑÂÖçË¥π‰ΩøÁî®È¢ùÂ∫¶Ôºâ„ÄÇËØ¶ËßÅhttps://github.com/Anionex/banana-slides/issues/121 ‰∏≠ÁöÑËØ¥Êòé


&lt;details&gt;
  &lt;summary&gt;üìí Vertex AI ÈÖçÁΩÆÊåáÂçóÔºàÈÄÇÁî®‰∫é GCP Áî®Êà∑Ôºâ&lt;/summary&gt;

Google Cloud Vertex AI ÂÖÅËÆ∏ÈÄöËøá GCP ÊúçÂä°Ë¥¶Êà∑Ë∞ÉÁî® Gemini Ê®°ÂûãÔºåÊñ∞Áî®Êà∑ÂèØ‰ΩøÁî®Ëµ†ÈáëÈ¢ùÂ∫¶„ÄÇÈÖçÁΩÆÊ≠•È™§Ôºö

1. ÂâçÂæÄ [GCP Console](https://console.cloud.google.com/)ÔºåÂàõÂª∫‰∏Ä‰∏™ÊúçÂä°Ë¥¶Êà∑Âπ∂‰∏ãËΩΩ JSON Ê†ºÂºèÁöÑÂØÜÈí•Êñá‰ª∂
2. Â∞ÜÂØÜÈí•Êñá‰ª∂‰øùÂ≠ò‰∏∫È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÁöÑ `gcp-service-account.json`
3. Âú® `.env` ‰∏≠ËÆæÁΩÆÔºö
   ```env
   AI_PROVIDER_FORMAT=vertex
   VERTEX_PROJECT_ID=your-gcp-project-id
   VERTEX_LOCATION=global
   ```
4. Â¶ÇÊûú‰ΩøÁî® Docker ÈÉ®ÁΩ≤ÔºåËøòÈúÄË¶ÅÂú® `docker-compose.yml` ‰∏≠ÂèñÊ∂àÁõ∏ÂÖ≥Ê≥®ÈáäÔºåÂ∞ÜÂØÜÈí•Êñá‰ª∂ÊåÇËΩΩÂà∞ÂÆπÂô®ÂÜÖÂπ∂ËÆæÁΩÆ `GOOGLE_APPLICATION_CREDENTIALS` ÁéØÂ¢ÉÂèòÈáè„ÄÇ

&gt; `gemini-3-*` Á≥ªÂàóÊ®°ÂûãË¶ÅÊ±Ç `VERTEX_LOCATION=global`

&lt;/details&gt;

2. **ÂêØÂä®ÊúçÂä°**

**‚ö° ‰ΩøÁî®È¢ÑÊûÑÂª∫ÈïúÂÉèÔºàÊé®ËçêÔºâ**

È°πÁõÆÂú® Docker Hub Êèê‰æõ‰∫ÜÊûÑÂª∫Â•ΩÁöÑÂâçÁ´ØÂíåÂêéÁ´ØÈïúÂÉèÔºàÂêåÊ≠•‰∏ªÂàÜÊîØÊúÄÊñ∞ÁâàÊú¨ÔºâÔºåÂèØ‰ª•Ë∑≥ËøáÊú¨Âú∞ÊûÑÂª∫Ê≠•È™§ÔºåÂÆûÁé∞Âø´ÈÄüÈÉ®ÁΩ≤Ôºö

```bash
# ‰ΩøÁî®È¢ÑÊûÑÂª∫ÈïúÂÉèÂêØÂä®ÔºàÊó†ÈúÄ‰ªéÂ§¥ÊûÑÂª∫Ôºâ
docker compose -f docker-compose.prod.yml up -d
```

ÈïúÂÉèÂêçÁß∞Ôºö
- `anoinex/banana-slides-frontend:latest`
- `anoinex/banana-slides-backend:latest`

**‰ªéÂ§¥ÊûÑÂª∫ÈïúÂÉè**

```bash
docker compose up -d
```


&gt; [!TIP]
&gt; Â¶ÇÈÅáÁΩëÁªúÈóÆÈ¢òÔºåÂèØÂú® `.env` Êñá‰ª∂‰∏≠ÂèñÊ∂àÈïúÂÉèÊ∫êÈÖçÁΩÆÁöÑÊ≥®Èáä, ÂÜçÈáçÊñ∞ËøêË°åÂêØÂä®ÂëΩ‰ª§Ôºö
&gt; ```env
&gt; # Âú® .env Êñá‰ª∂‰∏≠ÂèñÊ∂à‰ª•‰∏ãÊ≥®ÈáäÂç≥ÂèØ‰ΩøÁî®ÂõΩÂÜÖÈïúÂÉèÊ∫ê
&gt; DOCKER_REGISTRY=docker.1ms.run/
&gt; GHCR_REGISTRY=ghcr.nju.edu.cn/
&gt; APT_MIRROR=mirrors.aliyun.com
&gt; PYPI_INDEX_URL=https://mirrors.cloud.tencent.com/pypi/simple
&gt; NPM_REGISTRY=https://registry.npmmirror.com/
&gt; ```


3. **ËÆøÈóÆÂ∫îÁî®**

- ÂâçÁ´ØÔºöhttp://localhost:3000
- ÂêéÁ´Ø APIÔºöhttp://localhost:5000

4. **Êü•ÁúãÊó•Âøó**

```bash
# Êü•ÁúãÂêéÁ´ØÊó•ÂøóÔºàÊúÄÂêé 200 Ë°åÔºâ
docker logs --tail 200 banana-slides-backend

# ÂÆûÊó∂Êü•ÁúãÂêéÁ´ØÊó•ÂøóÔºàÊúÄÂêé 100 Ë°åÔºâ
docker logs -f --tail 100 banana-slides-backend

# Êü•ÁúãÂâçÁ´ØÊó•ÂøóÔºàÊúÄÂêé 100 Ë°åÔºâ
docker logs --tail 100 banana-slides-frontend
```

5. **ÂÅúÊ≠¢ÊúçÂä°**

```bash
docker compose down
```

6. **Êõ¥Êñ∞È°πÁõÆ**

**‰ΩøÁî®È¢ÑÊûÑÂª∫ÈïúÂÉèÔºàdocker-compose.prod.ymlÔºâ**

```bash
docker compose -f docker-compose.prod.yml pull
docker compose -f docker-compose.prod.yml up -d
```

**‰ΩøÁî®Êú¨Âú∞ÊûÑÂª∫Ôºàdocker-compose.ymlÔºâ**

```bash
git pull
docker compose down
docker compose build --no-cache
docker compose up -d
```

**Ê≥®ÔºöÊÑüË∞¢‰ºòÁßÄÂºÄÂèëËÄÖÊúãÂèã [@ShellMonster](https://github.com/ShellMonster/) Êèê‰æõ‰∫Ü[Êñ∞‰∫∫ÈÉ®ÁΩ≤ÊïôÁ®ã](https://github.com/ShellMonster/banana-slides/blob/docs-deploy-tutorial/docs/NEWBIE_DEPLOYMENT.md)Ôºå‰∏ì‰∏∫Ê≤°Êúâ‰ªª‰ΩïÊúçÂä°Âô®ÈÉ®ÁΩ≤ÁªèÈ™åÁöÑÊñ∞ÊâãËÆæËÆ°ÔºåÂèØ[ÁÇπÂáªÈìæÊé•](https://github.com/ShellMonster/banana-slides/blob/docs-deploy-tutorial/docs/NEWBIE_DEPLOYMENT.md)Êü•Áúã„ÄÇ**

### ‰ªéÊ∫êÁ†ÅÈÉ®ÁΩ≤

#### ÁéØÂ¢ÉË¶ÅÊ±Ç
- Python 3.10 ÊàñÊõ¥È´òÁâàÊú¨
- [uv](https://github.com/astral-sh/uv) - Python ÂåÖÁÆ°ÁêÜÂô®
- Node.js 16+ Âíå npm
- ÊúâÊïàÁöÑ Google Gemini API ÂØÜÈí•
- ÔºàÂèØÈÄâÔºâ[LibreOffice](https://www.libreoffice.org/) - ‰ΩøÁî®„ÄåPPT ÁøªÊñ∞„ÄçÂäüËÉΩ‰∏ä‰º† PPTX Êñá‰ª∂Êó∂ÈúÄË¶ÅÔºåÁî®‰∫éÂ∞Ü PPTX ËΩ¨Êç¢‰∏∫ PDF„ÄÇ**Êé®ËçêÂÖàÂú®Êú¨Âú∞Â∞Ü PPTX ËΩ¨‰∏∫ PDF ÂêéÂÜç‰∏ä‰º†**ÔºåÂéüÂõ†ÔºöLibreOffice Âú®ÊúçÂä°Á´ØÊ∏≤ÊüìÊó∂ÂèØËÉΩÂõ†Áº∫Â∞ëÂ≠ó‰ΩìÔºàÂ¶ÇÂæÆËΩØÈõÖÈªë„ÄÅCalibri Á≠âÔºâÂØºËá¥ÊéíÁâàÈîô‰ΩçÔºå‰∏îÊó†Ê≥ïÂÆåÊï¥ËøòÂéüÈÉ®ÂàÜÁâπÊïà„ÄÇ‰∏ä‰º† PDF Êñá‰ª∂Âàô‰∏çÈúÄË¶Å LibreOffice„ÄÇDocker Áî®Êà∑Â¶Ç‰ªçÈúÄÂú®ÂÆπÂô®ÂÜÖÊîØÊåÅ PPTX ‰∏ä‰º†ÔºåÂèØÊâßË°åÔºö
  ```bash
  docker exec -it banana-slides-backend bash -c &quot;apt-get update &amp;&amp; apt-get install -y libreoffice-impress &amp;&amp; rm -rf /var/lib/apt/lists/*&quot;
  ```
  &gt; Ê≥®ÊÑèÔºöÊ≠§ÊñπÂºèÂÆâË£ÖÁöÑ LibreOffice Âú®ÂÆπÂô®ÈáçÂª∫Âêé‰ºö‰∏¢Â§±ÔºåÈúÄÈáçÊñ∞ÂÆâË£Ö„ÄÇ

#### ÂêéÁ´ØÂÆâË£Ö

0. **ÂÖãÈöÜ‰ª£Á†Å‰ªìÂ∫ì**
```bash
git clone https://github.com/Anionex/banana-slides
cd banana-slides
```

1. **ÂÆâË£Ö uvÔºàÂ¶ÇÊûúÂ∞öÊú™ÂÆâË£ÖÔºâ**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

2. **ÂÆâË£Ö‰æùËµñ**

Âú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãËøêË°åÔºö
```bash
uv sync
```

ËøôÂ∞ÜÊ†πÊçÆ `pyproject.toml` Ëá™Âä®ÂÆâË£ÖÊâÄÊúâ‰æùËµñ„ÄÇ

3. **ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáè**

Â§çÂà∂ÁéØÂ¢ÉÂèòÈáèÊ®°ÊùøÔºö
```bash
cp .env.example .env
```

ÁºñËæë `.env` Êñá‰ª∂ÔºåÈÖçÁΩÆ‰Ω†ÁöÑ API ÂØÜÈí•Ôºö
&gt; **È°πÁõÆ‰∏≠Â§ßÊ®°ÂûãÊé•Âè£‰ª•AIHubMixÂπ≥Âè∞Ê†ºÂºè‰∏∫Ê†áÂáÜÔºåÊé®Ëçê‰ΩøÁî® [AIHubMix](https://aihubmix.com/?aff=17EC) Ëé∑ÂèñAPIÂØÜÈí•ÔºåÂáèÂ∞èËøÅÁßªÊàêÊú¨** 
```env
# AI ProviderÊ†ºÂºèÈÖçÁΩÆ (gemini / openai / vertex)
AI_PROVIDER_FORMAT=gemini

# Gemini Ê†ºÂºèÈÖçÁΩÆÔºàÂΩì AI_PROVIDER_FORMAT=gemini Êó∂‰ΩøÁî®Ôºâ
GOOGLE_API_KEY=your-api-key-here
GOOGLE_API_BASE=https://generativelanguage.googleapis.com
# ‰ª£ÁêÜÁ§∫‰æã: https://aihubmix.com/gemini

# OpenAI Ê†ºÂºèÈÖçÁΩÆÔºàÂΩì AI_PROVIDER_FORMAT=openai Êó∂‰ΩøÁî®Ôºâ
OPENAI_API_KEY=your-api-key-here
OPENAI_API_BASE=https://api.openai.com/v1
# ‰ª£ÁêÜÁ§∫‰æã: https://aihubmix.com/v1

# Vertex AI ÈÖçÁΩÆÔºàAI_PROVIDER_FORMAT=vertexÔºâ
# ÈúÄË¶Å GCP È°πÁõÆÂíåÊúçÂä°Ë¥¶Êà∑ÂØÜÈí•
# VERTEX_PROJECT_ID=your-gcp-project-id
# VERTEX_LOCATION=global
# GOOGLE_APPLICATION_CREDENTIALS=./gcp-service-account.json

# ÂèØ‰øÆÊîπÊ≠§ÂèòÈáèÊù•ÊéßÂà∂ÂêéÁ´ØÊúçÂä°Á´ØÂè£
BACKEND_PORT=5000
...
```

#### ÂâçÁ´ØÂÆâË£Ö

1. **ËøõÂÖ•ÂâçÁ´ØÁõÆÂΩï**
```bash
cd frontend
```

2. **ÂÆâË£Ö‰æùËµñ**
```bash
npm install
```

3. **ÈÖçÁΩÆAPIÂú∞ÂùÄ**

ÂâçÁ´Ø‰ºöËá™Âä®ËøûÊé•Âà∞ `http://localhost:5000` ÁöÑÂêéÁ´ØÊúçÂä°„ÄÇÂ¶ÇÈúÄ‰øÆÊîπÔºåËØ∑ÁºñËæë `src/api/client.ts`„ÄÇ


#### ÂêØÂä®ÂêéÁ´ØÊúçÂä°
&gt; ÔºàÂèØÈÄâÔºâÂ¶ÇÊûúÊú¨Âú∞Â∑≤ÊúâÈáçË¶ÅÊï∞ÊçÆÔºåÂçáÁ∫ßÂâçÂª∫ËÆÆÂÖàÂ§á‰ªΩÊï∞ÊçÆÂ∫ìÔºö  
&gt; `cp backend/instance/database.db backend/instance/database.db.bak`

```bash
cd backend
uv run alembic upgrade head &amp;&amp; uv run python app.py
```

ÂêéÁ´ØÊúçÂä°Â∞ÜÂú® `http://localhost:5000` ÂêØÂä®„ÄÇ

ËÆøÈóÆ `http://localhost:5000/health` È™åËØÅÊúçÂä°ÊòØÂê¶Ê≠£Â∏∏ËøêË°å„ÄÇ

#### ÂêØÂä®ÂâçÁ´ØÂºÄÂèëÊúçÂä°Âô®

```bash
cd frontend
npm run dev
```

ÂâçÁ´ØÂºÄÂèëÊúçÂä°Âô®Â∞ÜÂú® `http://localhost:3000` ÂêØÂä®„ÄÇ

ÊâìÂºÄÊµèËßàÂô®ËÆøÈóÆÂç≥ÂèØ‰ΩøÁî®Â∫îÁî®„ÄÇ


## üõ†Ô∏è ÊäÄÊúØÊû∂ÊûÑ

### ÂâçÁ´ØÊäÄÊúØÊ†à
- **Ê°ÜÊû∂**ÔºöReact 18 + TypeScript
- **ÊûÑÂª∫Â∑•ÂÖ∑**ÔºöVite 5
- **Áä∂ÊÄÅÁÆ°ÁêÜ**ÔºöZustand
- **Ë∑ØÁî±**ÔºöReact Router v6
- **UIÁªÑ‰ª∂**ÔºöTailwind CSS
- **ÊãñÊãΩÂäüËÉΩ**Ôºö@dnd-kit
- **ÂõæÊ†á**ÔºöLucide React
- **HTTPÂÆ¢Êà∑Á´Ø**ÔºöAxios

### ÂêéÁ´ØÊäÄÊúØÊ†à
- **ËØ≠Ë®Ä**ÔºöPython 3.10+
- **Ê°ÜÊû∂**ÔºöFlask 3.0
- **ÂåÖÁÆ°ÁêÜ**Ôºöuv
- **Êï∞ÊçÆÂ∫ì**ÔºöSQLite + Flask-SQLAlchemy
- **AIËÉΩÂäõ**ÔºöGoogle Gemini API
- **PPTÂ§ÑÁêÜ**Ôºöpython-pptx
- **ÂõæÁâáÂ§ÑÁêÜ**ÔºöPillow
- **Âπ∂ÂèëÂ§ÑÁêÜ**ÔºöThreadPoolExecutor
- **Ë∑®ÂüüÊîØÊåÅ**ÔºöFlask-CORS

## üìÅ È°πÁõÆÁªìÊûÑ

```
banana-slides/
‚îú‚îÄ‚îÄ frontend/                    # ReactÂâçÁ´ØÂ∫îÁî®
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/              # È°µÈù¢ÁªÑ‰ª∂
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Home.tsx        # È¶ñÈ°µÔºàÂàõÂª∫È°πÁõÆÔºâ
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OutlineEditor.tsx    # Â§ßÁ∫≤ÁºñËæëÈ°µ
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DetailEditor.tsx     # ËØ¶ÁªÜÊèèËø∞ÁºñËæëÈ°µ
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SlidePreview.tsx     # ÂπªÁÅØÁâáÈ¢ÑËßàÈ°µ
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ History.tsx          # ÂéÜÂè≤ÁâàÊú¨ÁÆ°ÁêÜÈ°µ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/         # UIÁªÑ‰ª∂
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outline/        # Â§ßÁ∫≤Áõ∏ÂÖ≥ÁªÑ‰ª∂
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ OutlineCard.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preview/        # È¢ÑËßàÁõ∏ÂÖ≥ÁªÑ‰ª∂
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SlideCard.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ DescriptionCard.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ shared/         # ÂÖ±‰∫´ÁªÑ‰ª∂
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Button.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Card.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Input.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Textarea.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Modal.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Loading.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Toast.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Markdown.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MaterialSelector.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MaterialGeneratorModal.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TemplateSelector.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ReferenceFileSelector.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout/         # Â∏ÉÂ±ÄÁªÑ‰ª∂
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ history/        # ÂéÜÂè≤ÁâàÊú¨ÁªÑ‰ª∂
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ store/              # ZustandÁä∂ÊÄÅÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useProjectStore.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/                # APIÊé•Âè£
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.ts       # AxiosÂÆ¢Êà∑Á´ØÈÖçÁΩÆ
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ endpoints.ts    # APIÁ´ØÁÇπÂÆö‰πâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ types/              # TypeScriptÁ±ªÂûãÂÆö‰πâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/              # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ constants/          # Â∏∏ÈáèÂÆö‰πâ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ styles/             # Ê†∑ÂºèÊñá‰ª∂
‚îÇ   ‚îú‚îÄ‚îÄ public/                 # ÈùôÊÄÅËµÑÊ∫ê
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ vite.config.ts
‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.js      # Tailwind CSSÈÖçÁΩÆ
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf              # NginxÈÖçÁΩÆ
‚îÇ
‚îú‚îÄ‚îÄ backend/                    # FlaskÂêéÁ´ØÂ∫îÁî®
‚îÇ   ‚îú‚îÄ‚îÄ app.py                  # FlaskÂ∫îÁî®ÂÖ•Âè£
‚îÇ   ‚îú‚îÄ‚îÄ config.py               # ÈÖçÁΩÆÊñá‰ª∂
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Êï∞ÊçÆÂ∫ìÊ®°Âûã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project.py          # ProjectÊ®°Âûã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.py             # PageÊ®°ÂûãÔºàÂπªÁÅØÁâáÈ°µÔºâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task.py             # TaskÊ®°ÂûãÔºàÂºÇÊ≠•‰ªªÂä°Ôºâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ material.py         # MaterialÊ®°ÂûãÔºàÂèÇËÄÉÁ¥†ÊùêÔºâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user_template.py    # UserTemplateÊ®°ÂûãÔºàÁî®Êà∑Ê®°ÊùøÔºâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reference_file.py   # ReferenceFileÊ®°ÂûãÔºàÂèÇËÄÉÊñá‰ª∂Ôºâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page_image_version.py # PageImageVersionÊ®°ÂûãÔºàÈ°µÈù¢ÁâàÊú¨Ôºâ
‚îÇ   ‚îú‚îÄ‚îÄ services/               # ÊúçÂä°Â±Ç
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai_service.py       # AIÁîüÊàêÊúçÂä°ÔºàGeminiÈõÜÊàêÔºâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_service.py     # Êñá‰ª∂ÁÆ°ÁêÜÊúçÂä°
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_parser_service.py # Êñá‰ª∂Ëß£ÊûêÊúçÂä°
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ export_service.py   # PPTX/PDFÂØºÂá∫ÊúçÂä°
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task_manager.py     # ÂºÇÊ≠•‰ªªÂä°ÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts.py          # AIÊèêÁ§∫ËØçÊ®°Êùø
‚îÇ   ‚îú‚îÄ‚îÄ controllers/            # APIÊéßÂà∂Âô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project_controller.py      # È°πÁõÆÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page_controller.py         # È°µÈù¢ÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ material_controller.py     # Á¥†ÊùêÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ template_controller.py     # Ê®°ÊùøÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reference_file_controller.py # ÂèÇËÄÉÊñá‰ª∂ÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ export_controller.py       # ÂØºÂá∫ÂäüËÉΩ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ file_controller.py         # Êñá‰ª∂‰∏ä‰º†
‚îÇ   ‚îú‚îÄ‚îÄ utils/                  # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ response.py         # Áªü‰∏ÄÂìçÂ∫îÊ†ºÂºè
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validators.py       # Êï∞ÊçÆÈ™åËØÅ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ path_utils.py       # Ë∑ØÂæÑÂ§ÑÁêÜ
‚îÇ   ‚îú‚îÄ‚îÄ instance/               # SQLiteÊï∞ÊçÆÂ∫ìÔºàËá™Âä®ÁîüÊàêÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ exports/                # ÂØºÂá∫Êñá‰ª∂ÁõÆÂΩï
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ tests/                      # ÊµãËØïÊñá‰ª∂ÁõÆÂΩï
‚îú‚îÄ‚îÄ v0_demo/                    # Êó©ÊúüÊºîÁ§∫ÁâàÊú¨
‚îú‚îÄ‚îÄ output/                     # ËæìÂá∫Êñá‰ª∂ÁõÆÂΩï
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml              # PythonÈ°πÁõÆÈÖçÁΩÆÔºàuvÁÆ°ÁêÜÔºâ
‚îú‚îÄ‚îÄ uv.lock                     # uv‰æùËµñÈîÅÂÆöÊñá‰ª∂
‚îú‚îÄ‚îÄ docker-compose.yml          # Docker ComposeÈÖçÁΩÆ
‚îú‚îÄ‚îÄ .env.example                 # ÁéØÂ¢ÉÂèòÈáèÁ§∫‰æã
‚îú‚îÄ‚îÄ LICENSE                     # ËÆ∏ÂèØËØÅ
‚îî‚îÄ‚îÄ README.md                   # Êú¨Êñá‰ª∂
```

## ‰∫§ÊµÅÁæ§
‰∏∫‰∫ÜÊñπ‰æøÂ§ßÂÆ∂Ê≤üÈÄö‰∫íÂä©ÔºåÂª∫Ê≠§ÂæÆ‰ø°‰∫§ÊµÅÁæ§.

Ê¨¢ËøéÊèêÂá∫Êñ∞ÂäüËÉΩÂª∫ËÆÆÊàñÂèçÈ¶àÔºåÊú¨‰∫∫‰πü‰ºö~~‰ΩõÁ≥ª~~ÂõûÁ≠îÂ§ßÂÆ∂ÈóÆÈ¢ò

&lt;img width=&quot;312&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/3e0f9fd9-7613-46bc-a37b-17211d40f5fc&quot; /&gt;










## **üîß Â∏∏ËßÅÈóÆÈ¢ò**

1. **ÁîüÊàêÈ°µÈù¢ÊñáÂ≠óÊúâ‰π±Á†ÅÔºåÊñáÂ≠ó‰∏çÊ∏ÖÊô∞**
    - ÂèØÈÄâÊã©Êõ¥È´òÂàÜËæ®ÁéáÁöÑËæìÂá∫Ôºàopenai Ê†ºÂºèÂèØËÉΩ‰∏çÊîØÊåÅË∞ÉÈ´òÂàÜËæ®ÁéáÔºåÂª∫ËÆÆ‰ΩøÁî®geminiÊ†ºÂºèÔºâ„ÄÇÊ†πÊçÆÊµãËØïÔºåÁîüÊàêÈ°µÈù¢ÂâçÂ∞Ü 1k ÂàÜËæ®ÁéáË∞ÉÊï¥Ëá≥ 2k ÂêéÔºåÊñáÂ≠óÊ∏≤ÊüìË¥®Èáè‰ºöÊòæËëóÊèêÂçá„ÄÇ
    - ËØ∑Á°Æ‰øùÂú®È°µÈù¢ÊèèËø∞‰∏≠ÂåÖÂê´ÂÖ∑‰ΩìË¶ÅÊ∏≤ÊüìÁöÑÊñáÂ≠óÂÜÖÂÆπ„ÄÇ

2. **ÂØºÂá∫ÂèØÁºñËæë ppt ÊïàÊûú‰∏ç‰Ω≥ÔºåÂ¶ÇÊñáÂ≠óÈáçÂè†„ÄÅÊó†Ê†∑ÂºèÁ≠â**
    - 90% ÊÉÖÂÜµ‰∏∫ API ÈÖçÁΩÆÂá∫Áé∞ÈóÆÈ¢ò„ÄÇÂèØ‰ª•ÂèÇËÄÉ [issue 121](https://github.com/Anionex/banana-slides/issues/121) ‰∏≠ÁöÑÊéíÊü•‰∏éËß£ÂÜ≥ÊñπÊ°à„ÄÇ

3. **ÊîØÊåÅÂÖçË¥πÂ±ÇÁ∫ßÁöÑ Gemini API Key ÂêóÔºü**
    - ÂÖçË¥πÂ±ÇÁ∫ßÂè™ÊîØÊåÅÊñáÊú¨ÁîüÊàêÔºå‰∏çÊîØÊåÅÂõæÁâáÁîüÊàê„ÄÇ

4. **ÁîüÊàêÂÜÖÂÆπÊó∂ÊèêÁ§∫ 503 ÈîôËØØÊàñ Retry Error**
    - ÂèØ‰ª•Ê†πÊçÆ README ‰∏≠ÁöÑÂëΩ‰ª§Êü•Áúã Docker ÂêéÁ´ØÊó•ÂøóÔºåÂÆö‰Ωç 503 ÈóÆÈ¢òÁöÑËØ¶ÁªÜÊä•ÈîôÔºå‰∏ÄËà¨ÊòØÊ®°ÂûãÈÖçÁΩÆ‰∏çÊ≠£Á°ÆÂØºËá¥„ÄÇ

5. **.env ‰∏≠ËÆæÁΩÆ‰∫Ü API Key ‰πãÂêéÔºå‰∏∫‰ªÄ‰πà‰∏çÁîüÊïàÔºü**
    - ËøêË°åÊó∂ÁºñËæë `.env` ÂêéÈúÄË¶ÅÈáçÂêØ Docker ÂÆπÂô®‰ª•Â∫îÁî®Êõ¥Êîπ„ÄÇ
    - Â¶ÇÊûúÊõæÂú®ÁΩëÈ°µËÆæÁΩÆÈ°µ‰∏≠ÈÖçÁΩÆÂèÇÊï∞Ôºå‰ºöË¶ÜÁõñ `.env` ‰∏≠ÁöÑÂèÇÊï∞ÔºåÂèØÈÄöËøá&quot;ËøòÂéüÈªòËÆ§ËÆæÁΩÆ&quot;ÊÅ¢Â§ç‰∏∫ `.env` ËÆæÁΩÆ„ÄÇ


## ü§ù Ë¥°ÁåÆÊåáÂçó

Ê¨¢ËøéÈÄöËøá
[Issue](https://github.com/Anionex/banana-slides/issues)
Âíå
[Pull Request](https://github.com/Anionex/banana-slides/pulls)
‰∏∫Êú¨È°πÁõÆË¥°ÁåÆÂäõÈáèÔºÅ

&gt; **ÈáçË¶ÅÔºö** Ë¥°ÁåÆÂâçËØ∑ÈòÖËØª [CONTRIBUTING.md](CONTRIBUTING.md)

## üìÑ ËÆ∏ÂèØËØÅ

Êú¨È°πÁõÆÈááÁî® **GNU Affero General Public License v3.0ÔºàAGPL-3.0Ôºâ** ÂºÄÊ∫êÔºå
ÂèØËá™Áî±Áî®‰∫é‰∏™‰∫∫Â≠¶‰π†„ÄÅÁ†îÁ©∂„ÄÅËØïÈ™å„ÄÅÊïôËÇ≤ÊàñÈùûËê•Âà©ÁßëÁ†îÊ¥ªÂä®Á≠âÈùûÂïÜ‰∏öÁî®ÈÄîÔºõ
&lt;details&gt; 
&lt;summary&gt; ËØ¶ÊÉÖ &lt;/summary&gt;
ÈúÄË¶ÅÂïÜ‰∏öËÆ∏ÂèØËØÅÔºàCommercial LicenseÔºâÔºà‰æãÂ¶ÇÔºöÂ∏åÊúõÈó≠Ê∫ê‰ΩøÁî®„ÄÅÁßÅÊúâÂåñÈÉ®ÁΩ≤‰∫§‰ªò„ÄÅÂ∞ÜÊú¨È°πÁõÆÈõÜÊàêËøõÈó≠Ê∫ê‰∫ßÂìÅÔºåÊàñÂú®‰∏çÂÖ¨ÂºÄÂØπÂ∫îÊ∫ê‰ª£Á†ÅÁöÑÂâçÊèê‰∏ãÊèê‰æõÊúçÂä°ÔºâÔºåËØ∑ËÅîÁ≥ª‰ΩúËÄÖÔºöanionex@qq.com
- ËÅîÁ≥ªÊñπÂºèÔºöanionex@qq.com
&lt;/details&gt;



&lt;h2&gt;üöÄ Sponsor / ËµûÂä© &lt;/h2&gt;
&lt;br&gt;
&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://aihubmix.com/?aff=17EC&quot;&gt;
  &lt;img src=&quot;./assets/logo_aihubmix.png&quot; alt=&quot;AIHubMix&quot; style=&quot;height:48px;&quot;&gt;
&lt;/a&gt;
&lt;p&gt;ÊÑüË∞¢AIHubMixÂØπÊú¨È°πÁõÆÁöÑËµûÂä©&lt;/p&gt;
&lt;/div&gt;


&lt;div align=&quot;center&quot;&gt;

 &lt;br&gt;

&lt;a href=&quot;https://api.chatfire.site/login?inviteCode=A15CD6A0&quot;&gt;&lt;img width=&quot;200&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/d6bd255f-ba2c-4ea3-bd90-fef292fc3397&quot; /&gt;
&lt;/a&gt;


&lt;details&gt;
  &lt;summary&gt;ÊÑüË∞¢&lt;a href=&quot;https://api.chatfire.site/login?inviteCode=A15CD6A0&quot;&gt;AIÁÅ´ÂÆù&lt;/a&gt;ÂØπÊú¨È°πÁõÆÁöÑËµûÂä©&lt;/summary&gt;
  ‚ÄúËÅöÂêàÂÖ®ÁêÉÂ§öÊ®°ÂûãAPIÊúçÂä°ÂïÜ„ÄÇÊõ¥‰Ωé‰ª∑Ê†º‰∫´ÂèóÂÆâÂÖ®„ÄÅÁ®≥ÂÆö‰∏î72Â∞èÊó∂ÈìæÊé•ÂÖ®ÁêÉÊúÄÊñ∞Ê®°ÂûãÁöÑÊúçÂä°„ÄÇ‚Äù
&lt;/details&gt;
 
&lt;/div&gt;



## Ëá¥Ë∞¢

- È°πÁõÆË¥°ÁåÆËÄÖ‰ª¨Ôºö

[![Contributors](https://contrib.rocks/image?repo=Anionex/banana-slides)](https://github.com/Anionex/banana-slides/graphs/contributors)

- [Linux.do](https://linux.do/): Êñ∞ÁöÑÁêÜÊÉ≥ÂûãÁ§æÂå∫
  
## ËµûËµè

ÂºÄÊ∫ê‰∏çÊòìüôèÂ¶ÇÊûúÊú¨È°πÁõÆÂØπ‰Ω†Êúâ‰ª∑ÂÄºÔºåÊ¨¢ËøéËØ∑ÂºÄÂèëËÄÖÂñùÊùØÂíñÂï°‚òïÔ∏è

&lt;img width=&quot;240&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/fd7a286d-711b-445e-aecf-43e3fe356473&quot; /&gt;

ÊÑüË∞¢‰ª•‰∏ãÊúãÂèãÂØπÈ°πÁõÆÁöÑÊó†ÂÅøËµûÂä©ÊîØÊåÅÔºö
&gt; @ÈõÖ‰øóÂÖ±Ëµè„ÄÅ@ÊõπÂ≥•„ÄÅ@‰ª•Âπ¥ËßÇÊó•„ÄÅ@John„ÄÅ@ËÉ°yunÊòüEthan, @azazo1„ÄÅ@ÂàòËÅ™NLP„ÄÅ@üçü„ÄÅ@Ëãç‰Ωï„ÄÅ@‰∏áÁëæ„ÄÅ@biubiu„ÄÅ@law„ÄÅ@ÊñπÊ∫ê„ÄÅ@ÂØíÊùæFalcon
&gt; Â¶ÇÂØπËµûÂä©ÂàóË°®ÊúâÁñëÈóÆÔºåÂèØ&lt;a href=&quot;mailto:anionex@qq.com&quot;&gt;ËÅîÁ≥ª‰ΩúËÄÖ&lt;/a&gt;
 
## üìà È°πÁõÆÁªüËÆ°

&lt;a href=&quot;https://www.star-history.com/#Anionex/banana-slides&amp;type=Timeline&amp;legend=top-left&quot;&gt;

 &lt;picture&gt;

   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=Anionex/banana-slides&amp;type=Timeline&amp;theme=dark&amp;legend=top-left&quot; /&gt;

   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=Anionex/banana-slides&amp;type=Timeline&amp;legend=top-left&quot; /&gt;

   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=Anionex/banana-slides&amp;type=Timeline&amp;legend=top-left&quot; /&gt;

 &lt;/picture&gt;

&lt;/a&gt;

&lt;br&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[fastrepl/char]]></title>
            <link>https://github.com/fastrepl/char</link>
            <guid>https://github.com/fastrepl/char</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:17 GMT</pubDate>
            <description><![CDATA[AI notepad for meetings]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fastrepl/char">fastrepl/char</a></h1>
            <p>AI notepad for meetings</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,829</p>
            <p>Forks: 543</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>![twitter-image](https://github.com/user-attachments/assets/b6161cfd-ddfa-4c09-9fbb-ab5a2d6961fc)

&lt;p align=&quot;center&quot;&gt;
  &lt;p align=&quot;center&quot;&gt;Char - The AI notepad for &lt;strong&gt;private&lt;/strong&gt; meetings&lt;/p&gt;
  &lt;p align=&quot;center&quot;&gt;
   &lt;a href=&quot;https://deepwiki.com/fastrepl/char&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://char.com/discord&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Join%20our&amp;message=Discord&amp;color=blue&amp;logo=Discord&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://x.com/getcharnotes&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Follow%20us%20on&amp;message=X&amp;color=black&amp;logo=x&quot; alt=&quot;X&quot;&gt;&lt;/a&gt;
  &lt;/p&gt;
&lt;/p&gt;
   
## What is Char?

Char is an AI notetaking app specifically designed to take meeting notes. With Char, you can transcribe all kinds of meetings whether it be online or offline.

- **Listens** to your meetings so you can only jot down important stuff
- **No bots** joining your meetings - Char listens directly to sounds coming in &amp; out of your computer
- Crafts perfect **summaries** based on your memos, right after the meeting is over
- You can run Char completely **offline** by using LM Studio or Ollama

You can also use it for taking notes for lectures or organizing your thoughts.

## Installation

```bash
brew install --cask fastrepl/fastrepl/char@nightly
```

- [macOS](https://char.com/download) (public beta)
- [Windows](https://github.com/fastrepl/char/issues/66) (q2 2026)
- [Linux](https://github.com/fastrepl/char/issues/67) (q2 2026)

## Highlights

### Notepad

Char is designed to take notes easily during meetings. Just jot down stuff you think are important!

&lt;img width=&quot;732&quot; height=&quot;612&quot; alt=&quot;Screenshot 2025-11-23 at 2 38 20‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/268ab859-a194-484b-b895-bc640df18dd4&quot; /&gt;

### Realtime Transcript

While you stay engaged in the conversation, Char captures every detail so you don&#039;t have to type frantically.

&lt;img width=&quot;688&quot; height=&quot;568&quot; alt=&quot;Screenshot 2025-11-23 at 2 35 47‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/e63ce73f-1a5f-49ce-a14d-dd8ba161e5bc&quot; /&gt;

### From Memos to Summaries

Once the meeting is over, Char will craft a personalized summary based on your memos ‚Äî which is not mandatory. Char will still create great summaries without your notes.

![offline enhancing-1](https://github.com/user-attachments/assets/13af787b-2f6e-4877-b90f-719edc45fb75)

### Truly Local

If you noticed the GIF above, you can see that Char works without any internet connection available. Just set up LM Studio or Ollama to operate Char in air-gapped environments!

&lt;img width=&quot;780&quot; height=&quot;585&quot; alt=&quot;no-wifi&quot; src=&quot;https://github.com/user-attachments/assets/ecf08a9e-3b6c-4fb6-ab38-0bc572f54859&quot; /&gt;

&gt; **Note on accounts:** During onboarding, Char creates an account so you can experience the full product ‚Äî including cloud-powered transcription and summarization ‚Äî at its best quality. All your notes, transcripts, and data are stored locally on your machine in a local SQLite database. If you prefer not to keep an account, you can request deletion anytime at [char.com/app/account](https://char.com/app/account). Char will continue to work fully offline with a local LLM.

### Bring Your Own LLM

Prefer something custom? You can swap in your own language model:

- Run local models via Ollama
- Use approved third-party APIs like Gemini, Claude, or Azure-hosted GPT
- Stay compliant with whatever your org allows

Char plays nice with whatever stack you&#039;re running.

&lt;img width=&quot;912&quot; height=&quot;712&quot; alt=&quot;Screenshot 2025-11-23 at 2 41 03‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/a6552c99-acbc-4d47-9d21-7f1925989344&quot; /&gt;

### Note Templates

Prefer a certain style? Choose from predefined templates like bullet points, agenda-based, or paragraph summary. Or create your own.

Check out our [template gallery](https://char.com/templates) and add your own [here](https://github.com/fastrepl/char/tree/main/apps/web/content/templates).

### AI Chat

Ask follow-ups right inside your notes:

- &quot;What were the action items?&quot;
- &quot;Rewrite this in simpler language&quot;
- &quot;Translate to Spanish&quot;

&lt;img width=&quot;959&quot; height=&quot;712&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/52b7dc14-906f-445f-91f9-b0089d40a495&quot; /&gt;

### Integrations

- Apple Calendar, Contacts
- Obsidian
- Coming soon: Notion, Slack, Hubspot, Salesforce

&lt;img width=&quot;912&quot; height=&quot;712&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/ab559e54-fda5-4c8c-97d7-ba1b9d134cc8&quot; /&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[tldraw/tldraw]]></title>
            <link>https://github.com/tldraw/tldraw</link>
            <guid>https://github.com/tldraw/tldraw</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:16 GMT</pubDate>
            <description><![CDATA[very good whiteboard infinite canvas SDK]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tldraw/tldraw">tldraw/tldraw</a></h1>
            <p>very good whiteboard infinite canvas SDK</p>
            <p>Language: TypeScript</p>
            <p>Stars: 45,541</p>
            <p>Forks: 3,041</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre>&lt;div alt style=&quot;text-align: center; transform: scale(.25);&quot;&gt;
	&lt;picture&gt;
		&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/tldraw/tldraw/raw/main/assets/github-hero-dark.png&quot; /&gt;
		&lt;img alt=&quot;tldraw&quot; src=&quot;https://github.com/tldraw/tldraw/raw/main/assets/github-hero-light.png&quot; /&gt;
	&lt;/picture&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/tldraw&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/tldraw&quot; alt=&quot;npm&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/tldraw&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/tldraw&quot; alt=&quot;npm downloads&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.tldraw.com/?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=sociallink&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/discord-join-5865F2?logo=discord&amp;logoColor=white&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://deepwiki.com/tldraw/tldraw&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
  Build infinite canvas apps in React with the tldraw SDK.
&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://tldraw.dev/quick-start&quot;&gt;Docs&lt;/a&gt; ¬∑ &lt;a href=&quot;https://tldraw.dev/examples&quot;&gt;Examples&lt;/a&gt; ¬∑ &lt;a href=&quot;https://tldraw.dev/starter-kits/overview&quot;&gt;Starter kits&lt;/a&gt;
&lt;/p&gt;

## Feature highlights

tldraw provides a feature-complete infinite canvas engine designed to be the foundation for any canvas app. Create custom shapes, tools, bindings and UI components for a custom experience. Use the default whiteboarding tool set or use the library&#039;s primitives to build entirely new shapes and interactions.

- **Multiplayer** ‚Äî self-hostable real-time collaboration with [`@tldraw/sync`](https://tldraw.dev/docs/sync)
- **Drawing and diagramming** ‚Äî pressure-sensitive drawing, geometric shapes, rich text, arrows, snapping to shapes, edge scrolling, image and video support, image export
- **Runtime API** - drive the canvas at runtime with the Editor API
- **Fully extensible** ‚Äî custom [shapes](https://tldraw.dev/docs/shapes), [tools](https://tldraw.dev/docs/tools), [bindings](https://tldraw.dev/sdk-features/bindings), [UI components](https://tldraw.dev/sdk-features/ui-components), side effects, and event hooks
- **AI integrations** ‚Äî canvas primitives for [building with LLMs](https://tldraw.dev/docs/ai)
- **DOM canvas** ‚Äî web rendering supports anything the browser supports, including embedded websites from YouTube, Figma, GitHub, [and more](https://tldraw.dev/sdk-features/embed-shape)
- **Broad support** ‚Äî works in any browser across desktop, touch screens, tablets, and mobile devices

## Quick start

Install the tldraw package:

```bash
npm i tldraw
```

Then, use the `&lt;Tldraw /&gt;` component in your React app:

```tsx
import { Tldraw } from &#039;tldraw&#039;
import &#039;tldraw/tldraw.css&#039;

export default function App() {
	return (
		&lt;div style={{ position: &#039;fixed&#039;, inset: 0 }}&gt;
			&lt;Tldraw /&gt;
		&lt;/div&gt;
	)
}
```

## Starter kits

Starter kits provide the custom shapes, tools, and user interface needed for common applications. Each kit is MIT-licensed. Hack together a prototype, build out an app on top, or reference the code in a larger project.

Start building with:

```bash
npx create-tldraw@latest
```

- **Multiplayer** ‚Äî self-hosted real-time collaboration powered by `@tldraw/sync` and Cloudflare Durable Objects, the same stack behind [tldraw.com](https://tldraw.com)
- **Agent** ‚Äî AI agents that read, interpret, and modify canvas content
- **Workflow** ‚Äî drag-and-drop node builder for automation pipelines, visual programming, and no-code platforms
- **Chat** ‚Äî canvas-powered AI chat where users sketch, annotate, and mark up images alongside conversations
- **Branching chat** ‚Äî AI chat with visual branching, letting users explore and compare different conversation paths
- **Shader** ‚Äî WebGL shaders that respond to canvas interactions

## Local development

The development server runs the examples app at `localhost:5420`. Clone the repo, then enable [corepack](https://nodejs.org/api/corepack.html) for the correct yarn version:

```bash
npm i -g corepack
```

Install dependencies and start the dev server:

```bash
yarn
yarn dev
```

## Community

- [Discord](https://discord.tldraw.com/?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=sociallink) ‚Äî questions, feedback, and discussion
- [Twitter/X](https://twitter.com/tldraw) ‚Äî news and updates
- [Submit an issue](https://github.com/tldraw/tldraw/issues/new) ‚Äî bug reports and feature requests

## Contributing

See our [contributing guide](https://github.com/tldraw/tldraw/blob/main/CONTRIBUTING.md) to learn about contributing to tldraw.

## License

The tldraw SDK is provided under the [tldraw license](https://github.com/tldraw/tldraw/blob/main/LICENSE.md). You can use the SDK freely in development. Production use requires a [license key](https://tldraw.dev/pricing). Visit [tldraw.dev](https://tldraw.dev) to learn more.

## Trademarks

Copyright (c) 2024-present tldraw Inc. The tldraw name and logo are trademarks of tldraw.

Please see our [trademark guidelines](https://github.com/tldraw/tldraw/blob/main/TRADEMARKS.md) for info on acceptable usage.

## Contributors

&lt;a href=&quot;https://github.com/tldraw/tldraw/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=tldraw/tldraw&amp;max=400&amp;columns=20&quot; width=&quot;100%&quot;/&gt;
&lt;/a&gt;

## Star history

&lt;a href=&quot;https://star-history.com/#tldraw/tldraw&quot;&gt;
	&lt;picture&gt;
	  &lt;source
	    media=&quot;(prefers-color-scheme: dark)&quot;
	    srcset=&quot;https://api.star-history.com/svg?repos=tldraw/tldraw&amp;type=Date&amp;theme=dark&quot;
	  /&gt;
	  &lt;source
	    media=&quot;(prefers-color-scheme: light)&quot;
	    srcset=&quot;https://api.star-history.com/svg?repos=tldraw/tldraw&amp;type=Date&quot;
	  /&gt;
	  &lt;img src=&quot;https://api.star-history.com/svg?repos=tldraw/tldraw&amp;type=Date&quot; alt=&quot;Star History Chart&quot; width=&quot;100%&quot; /&gt;
	&lt;/picture&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[code-yeongyu/oh-my-opencode]]></title>
            <link>https://github.com/code-yeongyu/oh-my-opencode</link>
            <guid>https://github.com/code-yeongyu/oh-my-opencode</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:15 GMT</pubDate>
            <description><![CDATA[the best agent harness]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/code-yeongyu/oh-my-opencode">code-yeongyu/oh-my-opencode</a></h1>
            <p>the best agent harness</p>
            <p>Language: TypeScript</p>
            <p>Stars: 35,551</p>
            <p>Forks: 2,687</p>
            <p>Stars today: 400 stars today</p>
            <h2>README</h2><pre>&gt; [!WARNING]
&gt; **Security warning: impersonation site**
&gt;
&gt; **ohmyopencode.com is NOT affiliated with this project.** We do not operate or endorse that site.
&gt;
&gt; OhMyOpenCode is **free and open-source**. Do **not** download installers or enter payment details on third-party sites that claim to be &quot;official.&quot;
&gt;
&gt; Because the impersonation site is behind a paywall, we **cannot verify what it distributes**. Treat any downloads from it as **potentially unsafe**.
&gt;
&gt; ‚úÖ Official downloads: https://github.com/code-yeongyu/oh-my-opencode/releases

&gt; [!NOTE]
&gt;
&gt; [![Sisyphus Labs ‚Äî Sisyphus is the agent that codes like your team.](./.github/assets/sisyphuslabs.png?v=2)](https://sisyphuslabs.ai)
&gt; &gt; **We&#039;re building a fully productized version of Sisyphus to define the future of frontier agents. &lt;br /&gt;Join the waitlist [here](https://sisyphuslabs.ai).**

&gt; [!TIP]
&gt;
&gt; [![Oh My OpenCode 3.0 is now stable!](./.github/assets/orchestrator-atlas.png?v=3)](https://github.com/code-yeongyu/oh-my-opencode/releases/tag/v3.0.0)
&gt; &gt; **Oh My OpenCode 3.0 is now stable! Use `oh-my-opencode@latest` to install it.**
&gt;
&gt; Be with us!
&gt;
&gt; | [&lt;img alt=&quot;Discord link&quot; src=&quot;https://img.shields.io/discord/1452487457085063218?color=5865F2&amp;label=discord&amp;labelColor=black&amp;logo=discord&amp;logoColor=white&amp;style=flat-square&quot; width=&quot;156px&quot; /&gt;](https://discord.gg/PUwSMR9XNk) | Join our [Discord community](https://discord.gg/PUwSMR9XNk) to connect with contributors and fellow `oh-my-opencode` users. |
&gt; | :-----| :----- |
&gt; | [&lt;img alt=&quot;X link&quot; src=&quot;https://img.shields.io/badge/Follow-%40justsisyphus-00CED1?style=flat-square&amp;logo=x&amp;labelColor=black&quot; width=&quot;156px&quot; /&gt;](https://x.com/justsisyphus) | News and updates for `oh-my-opencode` used to be posted on my X account. &lt;br /&gt; Since it was suspended mistakenly, [@justsisyphus](https://x.com/justsisyphus) now posts updates on my behalf. |
&gt; | [&lt;img alt=&quot;GitHub Follow&quot; src=&quot;https://img.shields.io/github/followers/code-yeongyu?style=flat-square&amp;logo=github&amp;labelColor=black&amp;color=24292f&quot; width=&quot;156px&quot; /&gt;](https://github.com/code-yeongyu) | Follow [@code-yeongyu](https://github.com/code-yeongyu) on GitHub for more projects. |

&lt;!-- &lt;CENTERED SECTION FOR GITHUB DISPLAY&gt; --&gt;

&lt;div align=&quot;center&quot;&gt;

[![Oh My OpenCode](./.github/assets/hero.jpg)](https://github.com/code-yeongyu/oh-my-opencode#oh-my-opencode)

[![Preview](./.github/assets/omo.png)](https://github.com/code-yeongyu/oh-my-opencode#oh-my-opencode)


&lt;/div&gt;

&gt; This is coding on steroids‚Äî`oh-my-opencode` in action. Run background agents, call specialized agents like oracle, librarian, and frontend engineer. Use crafted LSP/AST tools, curated MCPs, and a full Claude Code compatibility layer.

# Claude OAuth Access Notice

## TL;DR

&gt; Q. Can I use oh-my-opencode?

Yes.

&gt; Q. Can I use it with my Claude Code subscription?

Yes, technically possible. But I cannot recommend using it.

## FULL

&gt; As of January 2026, Anthropic has restricted third-party OAuth access citing ToS violations.
&gt;
&gt; [**Anthropic has cited this project, oh-my-opencode as justification for blocking opencode.**](https://x.com/thdxr/status/2010149530486911014)
&gt;
&gt; Indeed, some plugins that spoof Claude Code&#039;s oauth request signatures exist in the community.
&gt;
&gt; These tools may work regardless of technical detectability, but users should be aware of ToS implications, and I personally cannot recommend to use those.
&gt;
&gt; This project is not responsible for any issues arising from the use of unofficial tools, and **we do not have any custom implementations of those oauth systems.**


&lt;div align=&quot;center&quot;&gt;

[![GitHub Release](https://img.shields.io/github/v/release/code-yeongyu/oh-my-opencode?color=369eff&amp;labelColor=black&amp;logo=github&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/releases)
[![npm downloads](https://img.shields.io/npm/dt/oh-my-opencode?color=ff6b35&amp;labelColor=black&amp;style=flat-square)](https://www.npmjs.com/package/oh-my-opencode)
[![GitHub Contributors](https://img.shields.io/github/contributors/code-yeongyu/oh-my-opencode?color=c4f042&amp;labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/graphs/contributors)
[![GitHub Forks](https://img.shields.io/github/forks/code-yeongyu/oh-my-opencode?color=8ae8ff&amp;labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/network/members)
[![GitHub Stars](https://img.shields.io/github/stars/code-yeongyu/oh-my-opencode?color=ffcb47&amp;labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/stargazers)
[![GitHub Issues](https://img.shields.io/github/issues/code-yeongyu/oh-my-opencode?color=ff80eb&amp;labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/issues)
[![License](https://img.shields.io/badge/license-SUL--1.0-white?labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/blob/master/LICENSE.md)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/code-yeongyu/oh-my-opencode)

[English](README.md) | [ÌïúÍµ≠Ïñ¥](README.ko.md) | [Êó•Êú¨Ë™û](README.ja.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](README.zh-cn.md)

&lt;/div&gt;

&lt;!-- &lt;/CENTERED SECTION FOR GITHUB DISPLAY&gt; --&gt;

## Reviews

&gt; &quot;It made me cancel my Cursor subscription. Unbelievable things are happening in the open source community.&quot; - [Arthur Guiot](https://x.com/arthur_guiot/status/2008736347092382053?s=20)

&gt; &quot;If Claude Code does in 7 days what a human does in 3 months, Sisyphus does it in 1 hour. It just works until the task is done. It is a discipline agent.&quot; ‚Äî B, Quant Researcher

&gt; &quot;Knocked out 8000 eslint warnings with Oh My Opencode, just in a day&quot; ‚Äî [Jacob Ferrari](https://x.com/jacobferrari_/status/2003258761952289061)

&gt; &quot;I converted a 45k line tauri app into a SaaS web app overnight using Ohmyopencode and ralph loop. Started with interview me prompt, asked it for ratings and recommendations on the questions. It was amazing to watch it work and to wake up this morning to a mostly working website!&quot; - [James Hargis](https://x.com/hargabyte/status/2007299688261882202)

&gt; &quot;use oh-my-opencode, you will never go back&quot; ‚Äî [d0t3ch](https://x.com/d0t3ch/status/2001685618200580503)

&gt; &quot;I haven&#039;t really been able to articulate exactly what makes it so great yet, but the development experience has reached a completely different dimension.&quot; - [
ËãîÁ°Ø:„Åì„Åë„Åô„Åö„Çä](https://x.com/kokesuzuri/status/2008532913961529372?s=20)

&gt; &quot;Experimenting with open code, oh my opencode and supermemory this weekend to build some minecraft/souls-like abomination.&quot;
&gt; &quot;Asking it to add crouch animations while I go take my post-lunch walk. [Video]&quot; - [MagiMetal](https://x.com/MagiMetal/status/2005374704178373023)

&gt; &quot;You guys should pull this into core and recruit him. Seriously. It&#039;s really, really, really good.&quot; ‚Äî Henning Kilset

&gt; &quot;Hire @yeon_gyu_kim if you can convince him, this dude has revolutionized opencode.&quot; ‚Äî [mysticaltech](https://x.com/mysticaltech/status/2001858758608376079)

&gt; &quot;Oh My OpenCode Is Actually Insane&quot; - [YouTube - Darren Builds AI](https://www.youtube.com/watch?v=G_Snfh2M41M)

---

## Contents

- [Oh My OpenCode](#oh-my-opencode)
  - [Just Skip Reading This Readme](#just-skip-reading-this-readme)
    - [It&#039;s the Age of Agents](#its-the-age-of-agents)
    - [ü™Ñ The Magic Word: `ultrawork`](#-the-magic-word-ultrawork)
    - [For Those Who Want to Read: Meet Sisyphus](#for-those-who-want-to-read-meet-sisyphus)
      - [Just Install It.](#just-install-it)
  - [Installation](#installation)
    - [For Humans](#for-humans)
    - [For LLM Agents](#for-llm-agents)
  - [Uninstallation](#uninstallation)
  - [Features](#features)
   - [Configuration](#configuration)
    - [JSONC Support](#jsonc-support)
    - [Google Auth](#google-auth)
    - [Agents](#agents)
      - [Permission Options](#permission-options)
    - [Built-in Skills](#built-in-skills)
    - [Git Master](#git-master)
    - [Sisyphus Agent](#sisyphus-agent)
    - [Background Tasks](#background-tasks)
    - [Categories](#categories)
    - [Hooks](#hooks)
    - [MCPs](#mcps)
    - [LSP](#lsp)
    - [Experimental](#experimental)
    - [Environment Variables](#environment-variables)
  - [Author&#039;s Note](#authors-note)
  - [Warnings](#warnings)
  - [Loved by professionals at](#loved-by-professionals-at)

# Oh My OpenCode

[Claude Code](https://www.claude.com/product/claude-code) is great.
But if you&#039;re a hacker, you&#039;ll fall head over heels for [OpenCode](https://github.com/sst/opencode).
**START WITH YOUR ChatGPT, Claude, Gemini SUBSCRIPTIONS. OPENCODE COVERS THEM ALL.**

- Endlessly extensible. Endlessly customizable.
- Zero screen flicker.
- [LSP](https://opencode.ai/docs/lsp/), [linters, formatters](https://opencode.ai/docs/formatters/) activate automatically per file‚Äîand you can tweak everything.
- Mix and match models. **Orchestrate them by purpose.**
- Feature-rich. Beautiful. The terminal doesn&#039;t choke. High performance.

Remember the first time you switched from Windows to Linux? That rush of configuring everything exactly how you wanted?
In an age where that magic seems lost, OpenCode brings it back.
If you love coding and computers, OpenCode is that Linux-after-Windows moment.

**But here&#039;s the catch: there&#039;s a lot to learn, it&#039;s complex, and your time is expensive.**

I&#039;ve fixed that.
Even if you&#039;re not a hacker, invest a few minutes. Multiply your skills and productivity.
Hand this doc to an agent and let them set it up.

## Just Skip Reading This Readme

### It&#039;s the Age of Agents
- **Just paste this link into Claude Code / AmpCode / Factory Droid / Cursor and ask it to explain.**
  - Ask why it&#039;s good, why it&#039;s not just another boilerplate setup, what actually gets better.
  - If you&#039;re an LLM agent, explain to the user what becomes possible right now with this project.

As following:

```
Hey please read this readme and tell me why it is different from other agent harness? why is this actually good? https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/refs/heads/dev/README.md
```

### ü™Ñ The Magic Word: `ultrawork`

**Don&#039;t want to read all this? Just include `ultrawork` (or `ulw`) in your prompt.**

That&#039;s it. All the features we provide will work like magic‚Äîparallel agents, background tasks, deep exploration, and relentless execution until completion. The agent figures out the rest automatically.

### For Those Who Want to Read: Meet Sisyphus

![Meet Sisyphus](.github/assets/sisyphus.png)

In greek mythology, Sisyphus was condemned to roll a boulder up a hill for eternity as punishment for deceiving the gods. LLM Agents haven&#039;t really done anything wrong, yet they too roll their &quot;stones&quot;‚Äîtheir thoughts‚Äîevery single day.
My life is no different. Looking back, we are not so different from these agents.
**Yes! LLM Agents are no different from us. They can write code as brilliant as ours and work just as excellently‚Äîif you give them great tools and solid teammates.**

Meet our main agent: Sisyphus (Opus 4.5 High). Below are the tools Sisyphus uses to keep that boulder rolling.

*Everything below is customizable. Take what you want. All features are enabled by default. You don&#039;t have to do anything. Battery Included, works out of the box.*

- Sisyphus&#039;s Teammates (Curated Agents)
  - Oracle: Design, debugging (GPT 5.2 Medium)
  - Frontend UI/UX Engineer: Frontend development (Gemini 3 Pro)
  - Librarian: Official docs, open source implementations, codebase exploration (Claude Sonnet 4.5)
  - Explore: Blazing fast codebase exploration (Contextual Grep) (Grok Code)
- Full LSP / AstGrep Support: Refactor decisively.
- Todo Continuation Enforcer: Forces the agent to continue if it quits halfway. **This is what keeps Sisyphus rolling that boulder.**
- Comment Checker: Prevents AI from adding excessive comments. Code generated by Sisyphus should be indistinguishable from human-written code.
- Claude Code Compatibility: Command, Agent, Skill, MCP, Hook(PreToolUse, PostToolUse, UserPromptSubmit, Stop)
- Curated MCPs:
  - Exa (Web Search)
  - Context7 (Official Documentation)
  - Grep.app (GitHub Code Search)
- Interactive Terminal Supported - Tmux Integration
- Async Agents
- ...

#### Just Install This

You can learn a lot from [overview page](docs/guide/overview.md), but following is like the example workflow.

Just by installing this, you make your agents to work like:

1. Sisyphus doesn&#039;t waste time hunting for files himself; he keeps the main agent&#039;s context lean. Instead, he fires off background tasks to faster, cheaper models in parallel to map the territory for him.
1. Sisyphus leverages LSP for refactoring; it&#039;s more deterministic, safer, and surgical.
1. When the heavy lifting requires a UI touch, Sisyphus delegates frontend tasks directly to Gemini 3 Pro.
1. If Sisyphus gets stuck in a loop or hits a wall, he doesn&#039;t keep banging his head‚Äîhe calls GPT 5.2 for high-IQ strategic backup.
1. Working with a complex open-source framework? Sisyphus spawns subagents to digest the raw source code and documentation in real-time. He operates with total contextual awareness.
1. When Sisyphus touches comments, he either justifies their existence or nukes them. He keeps your codebase clean.
1. Sisyphus is bound by his TODO list. If he doesn&#039;t finish what he started, the system forces him back into &quot;bouldering&quot; mode. Your task gets done, period.
1. Honestly, don&#039;t even bother reading the docs. Just write your prompt. Include the &#039;ultrawork&#039; keyword. Sisyphus will analyze the structure, gather the context, dig through external source code, and just keep bouldering until the job is 100% complete.
1. Actually, typing &#039;ultrawork&#039; is too much effort. Just type &#039;ulw&#039;. Just ulw. Sip your coffee. Your work is done.

Need to look something up? It scours official docs, your entire codebase history, and public GitHub implementations‚Äîusing not just grep but built-in LSP tools and AST-Grep.
3. Stop worrying about context management when delegating to LLMs. I&#039;ve got it covered.
    - OhMyOpenCode aggressively leverages multiple agents to lighten the context load.
    - **Your agent is now the dev team lead. You&#039;re the AI Manager.**
4. It doesn&#039;t stop until the job is done.
5. Don&#039;t want to dive deep into this project? No problem. Just type &#039;ultrathink&#039;.

If you don&#039;t want all this, as mentioned, you can just pick and choose specific features.

## Installation

### For Humans

Copy and paste this prompt to your LLM agent (Claude Code, AmpCode, Cursor, etc.):

```
Install and configure oh-my-opencode by following the instructions here:
https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/refs/heads/master/docs/guide/installation.md
```

Or read the [Installation Guide](docs/guide/installation.md) directly‚Äîbut **we strongly recommend letting an agent handle it. Humans make mistakes.**

### For LLM Agents

Fetch the installation guide and follow it:

```bash
curl -s https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/refs/heads/master/docs/guide/installation.md
```

## Uninstallation

To remove oh-my-opencode:

1. **Remove the plugin from your OpenCode config**

   Edit `~/.config/opencode/opencode.json` (or `opencode.jsonc`) and remove `&quot;oh-my-opencode&quot;` from the `plugin` array:

   ```bash
   # Using jq
   jq &#039;.plugin = [.plugin[] | select(. != &quot;oh-my-opencode&quot;)]&#039; \
       ~/.config/opencode/opencode.json &gt; /tmp/oc.json &amp;&amp; \
       mv /tmp/oc.json ~/.config/opencode/opencode.json
   ```

2. **Remove configuration files (optional)**

   ```bash
   # Remove user config
   rm -f ~/.config/opencode/oh-my-opencode.json

   # Remove project config (if exists)
   rm -f .opencode/oh-my-opencode.json
   ```

3. **Verify removal**

   ```bash
   opencode --version
   # Plugin should no longer be loaded
   ```

## Features

We have lots of features that you&#039;ll think should obviously exist, and once you experience them, you&#039;ll never be able to go back to how things were before.
See the full [Features Documentation](docs/features.md) for detailed information.

**Quick Overview:**
- **Agents**: Sisyphus (the main agent), Prometheus (planner), Oracle (architecture/debugging), Librarian (docs/code search), Explore (fast codebase grep), Multimodal Looker
- **Background Agents**: Run multiple agents in parallel like a real dev team
- **LSP &amp; AST Tools**: Refactoring, rename, diagnostics, AST-aware code search
- **Context Injection**: Auto-inject AGENTS.md, README.md, conditional rules
- **Claude Code Compatibility**: Full hook system, commands, skills, agents, MCPs
- **Built-in MCPs**: websearch (Exa), context7 (docs), grep_app (GitHub search)
- **Session Tools**: List, read, search, and analyze session history
- **Productivity Features**: Ralph Loop, Todo Enforcer, Comment Checker, Think Mode, and more

## Configuration

Highly opinionated, but adjustable to taste.
See the full [Configuration Documentation](docs/configurations.md) for detailed information.

**Quick Overview:**
- **Config Locations**: `.opencode/oh-my-opencode.json` (project) or `~/.config/opencode/oh-my-opencode.json` (user)
- **JSONC Support**: Comments and trailing commas supported
- **Agents**: Override models, temperatures, prompts, and permissions for any agent
- **Built-in Skills**: `playwright` (browser automation), `git-master` (atomic commits)
- **Sisyphus Agent**: Main orchestrator with Prometheus (Planner) and Metis (Plan Consultant)
- **Background Tasks**: Configure concurrency limits per provider/model
- **Categories**: Domain-specific task delegation (`visual`, `business-logic`, custom)
- **Hooks**: 25+ built-in hooks, all configurable via `disabled_hooks`
- **MCPs**: Built-in websearch (Exa), context7 (docs), grep_app (GitHub search)
- **LSP**: Full LSP support with refactoring tools
- **Experimental**: Aggressive truncation, auto-resume, and more


## Author&#039;s Note

**Curious about the philosophy behind this project?** Read the [Ultrawork Manifesto](docs/ultrawork-manifesto.md).

Install Oh My OpenCode.

I&#039;ve used LLMs worth $24,000 tokens purely for personal development.
Tried every tool out there, configured them to death. OpenCode won.

The answers to every problem I hit are baked into this plugin. Just install and go.
If OpenCode is Debian/Arch, Oh My OpenCode is Ubuntu/[Omarchy](https://omarchy.org/).


Heavily influenced by [AmpCode](https://ampcode.com) and [Claude Code](https://code.claude.com/docs/overview)‚ÄîI&#039;ve ported their features here, often improved. And I&#039;m still building.
It&#039;s **Open**Code, after all.

Enjoy multi-model orchestration, stability, and rich features that other harnesses promise but can&#039;t deliver.
I&#039;ll keep testing and updating. I&#039;m this project&#039;s most obsessive user.
- Which model has the sharpest logic?
- Who&#039;s the debugging god?
- Who writes the best prose?
- Who dominates frontend?
- Who owns backend?
- Which model is fastest for daily driving?
- What new features are other harnesses shipping?

This plugin is the distillation of that experience. Just take the best. Got a better idea? PRs are welcome.

**Stop agonizing over agent harness choices.**
**I&#039;ll do the research, borrow from the best, and ship updates here.**

If this sounds arrogant and you have a better answer, please contribute. You&#039;re welcome.

I have no affiliation with any project or model mentioned here. This is purely personal experimentation and preference.

99% of this project was built using OpenCode. I tested for functionality‚ÄîI don&#039;t really know how to write proper TypeScript. **But I personally reviewed and largely rewrote this doc, so read with confidence.**

## Warnings

- Productivity might spike too hard. Don&#039;t let your coworker notice.
  - Actually, I&#039;ll spread the word. Let&#039;s see who wins.
- If you&#039;re on [1.0.132](https://github.com/sst/opencode/releases/tag/v1.0.132) or older, an OpenCode bug may break config.
  - [The fix](https://github.com/sst/opencode/pull/5040) was merged after 1.0.132‚Äîuse a newer version.
    - Fun fact: That PR was discovered and fixed thanks to OhMyOpenCode&#039;s Librarian, Explore, and Oracle setup.

## Loved by professio

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[web-infra-dev/midscene]]></title>
            <link>https://github.com/web-infra-dev/midscene</link>
            <guid>https://github.com/web-infra-dev/midscene</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:14 GMT</pubDate>
            <description><![CDATA[Driving all platforms UI automation with vision-based model]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/web-infra-dev/midscene">web-infra-dev/midscene</a></h1>
            <p>Driving all platforms UI automation with vision-based model</p>
            <p>Language: TypeScript</p>
            <p>Stars: 11,848</p>
            <p>Forks: 858</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Midscene.js&quot;  width=&quot;260&quot; src=&quot;https://github.com/user-attachments/assets/f60de3c1-dd6f-4213-97a1-85bf7c6e79e4&quot;&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Midscene.js&lt;/h1&gt;
&lt;div align=&quot;center&quot;&gt;

English | [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh.md)

&lt;strong&gt;Official Website&lt;/strong&gt;: &lt;a href=&quot;https://midscenejs.com/&quot;&gt;https://midscenejs.com/&lt;/a&gt;

&lt;a href=&quot;https://trendshift.io/repositories/12524&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12524&quot; alt=&quot;web-infra-dev%2Fmidscene | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  Driving all platforms UI automation with vision-based model
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/@midscene/web&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@midscene/web?style=flat-square&amp;color=00a8f0&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/UI%20TARS%20Models-yellow&quot; alt=&quot;hugging face model&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://npm-compare.com/@midscene/web/#timeRange=THREE_YEARS&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/@midscene/web.svg?style=flat-square&amp;color=00a8f0&quot; alt=&quot;downloads&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/web-infra-dev/midscene/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square&amp;color=00a8f0&quot; alt=&quot;License&quot; /&gt;
  &lt;a href=&quot;https://discord.gg/2JyBHxszE4&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1328277792730779648?style=flat-square&amp;color=7289DA&amp;label=Discord&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;discord&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/midscene_ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/midscene_ai?style=flat-square&quot; alt=&quot;twitter&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://deepwiki.com/web-infra-dev/midscene&quot;&gt;
    &lt;img alt=&quot;Ask DeepWiki.com&quot; src=&quot;https://devin.ai/assets/deepwiki-badge.png&quot; style=&quot;height: 18px; vertical-align: middle;&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## üì£ Control Any Platform with Midscene Skills

&gt; Use [Midscene Skills](https://github.com/web-infra-dev/midscene-skills) to control any platform.

## Showcases

autonomously register the GitHub form in a web browser and pass all field validations.

&lt;video src=&quot;https://lf3-static.bytednsdoc.com/obj/eden-cn/nupipfups/Midscene/1.0-showcases/github2.mp4&quot; height=&quot;300&quot; controls&gt;&lt;/video&gt;

Plus these real-world showcases:
* [iOS Automation - Meituan coffee order](https://midscenejs.com/showcases#ios)
* [iOS Automation - Auto-like the first @midscene_ai tweet](https://midscenejs.com/showcases#ios)
* [Android Automation - DCar: Xiaomi SU7 specs](https://midscenejs.com/showcases#android)
* [Android Automation - Booking a hotel for Christmas](https://midscenejs.com/showcases#android)
* [MCP Integration - Midscene MCP UI prepatch release](https://midscenejs.com/showcases#mcp)

See more real-world showcases ‚Äî click to explore: [showcases](https://midscenejs.com/showcases)
Community showcase: [robotic arm + vision + voice for in-vehicle testing](https://midscenejs.com/showcases#community-showcases)

## üí° Features

### Write Automation with Natural Language
- Describe your goals and steps, and Midscene will plan and operate the user interface for you.
- Use Javascript SDK or YAML to write your automation script.

### Web &amp; Mobile App &amp; Any Interface
- **Web Automation**: Either integrate with [Puppeteer](https://midscenejs.com/integrate-with-puppeteer), [Playwright](https://midscenejs.com/integrate-with-playwright) or use [Bridge Mode](https://midscenejs.com/bridge-mode) to control your desktop browser.
- **Android Automation**: Use [Javascript SDK](https://midscenejs.com/android-getting-started) with adb to control your local Android device.
- **iOS Automation**: Use [Javascript SDK](https://midscenejs.com/ios-getting-started) with WebDriverAgent to control your local iOS devices and simulators.
- **Any Interface Automation**: Use [Javascript SDK](https://midscenejs.com/integrate-with-any-interface) to control your own interface.

### For Developers
- **Three kinds of APIs**:
  - [Interaction API](https://midscenejs.com/api#interaction-methods): interact with the user interface.
  - [Data Extraction API](https://midscenejs.com/api#data-extraction): extract data from the user interface and dom.
  - [Utility API](https://midscenejs.com/api#more-apis): utility functions like `aiAssert()`, `aiLocate()`, `aiWaitFor()`.
- **MCP**: Midscene provides MCP services that expose atomic Midscene Agent actions as MCP tools so upper-layer agents can inspect and operate UIs with natural language. [Docs](https://midscenejs.com/mcp)
- [**Caching for Efficiency**](https://midscenejs.com/caching): Replay your script with cache and get the result faster.
- **Debugging Experience**: Midscene.js offers a visualized replay back report file, a built-in playground, and a Chrome Extension to simplify the debugging process. These are the tools most developers truly need.


## üëâ Zero-code Quick Experience

- **[Chrome Extension](https://midscenejs.com/quick-experience)**: Start in-browser experience immediately through [the Chrome Extension](https://midscenejs.com/quick-experience), without writing any code.
- **[Android Playground](https://midscenejs.com/android-getting-started)**: There is also a built-in Android playground to control your local Android device.
- **[iOS Playground](https://midscenejs.com/ios-getting-started)**: There is also a built-in iOS playground to control your local iOS device.

## ‚ú® Driven by Visual Language Model

Midscene.js is all-in on the pure-vision route for UI actions: element localization and interactions are based on screenshots only. It supports visual-language models like `Qwen3-VL`, `Doubao-1.6-vision`, `gemini-3-pro`, and `UI-TARS`. For data extraction and page understanding, you can still opt in to include DOM when needed.

* Pure-vision localization for UI actions; the DOM extraction mode is removed.
* Works across web, mobile, desktop, and even `&lt;canvas&gt;` surfaces.
* Far fewer tokens by skipping DOM for actions, which cuts cost and speeds up runs.
* DOM can still be included for data extraction and page understanding when needed.
* Strong open-source options for self-hosting.

Read more about [Model Strategy](https://midscenejs.com/model-strategy)



## üìÑ Resources 

* Official Website: [https://midscenejs.com](https://midscenejs.com/)
* Documentation: [https://midscenejs.com](https://midscenejs.com/)
* Sample Projects: [https://github.com/web-infra-dev/midscene-example](https://github.com/web-infra-dev/midscene-example)
* API Reference: [https://midscenejs.com/api](https://midscenejs.com/api)
* GitHub: [https://github.com/web-infra-dev/midscene](https://github.com/web-infra-dev/midscene)

## ü§ù Community

* [Discord](https://discord.gg/2JyBHxszE4)
* [Follow us on X](https://x.com/midscene_ai)
* [Lark Group(È£û‰π¶‰∫§ÊµÅÁæ§)](https://applink.larkoffice.com/client/chat/chatter/add_by_link?link_token=693v0991-a6bb-4b44-b2e1-365ca0d199ba)

## üåü Awesome Midscene

Community projects that extend Midscene.js capabilities:

* [midscene-ios](https://github.com/lhuanyu/midscene-ios) - iOS Mirror automation support for Midscene
* [midscene-pc](https://github.com/Mofangbao/midscene-pc) - PC operation device for Windows, macOS, and Linux
* [midscene-pc-docker](https://github.com/Mofangbao/midscene-pc-docker) - Docker image with Midscene-PC server pre-installed
* [Midscene-Python](https://github.com/Python51888/Midscene-Python) - Python SDK for Midscene automation
* [midscene-java](https://github.com/Master-Frank/midscene-java) by @Master-Frank - Java SDK for Midscene automation
* [midscene-java](https://github.com/alstafeev/midscene-java) by @alstafeev - Java SDK for Midscene automation


## üìù Credits

We would like to thank the following projects:

- [Rsbuild](https://github.com/web-infra-dev/rsbuild) and [Rslib](https://github.com/web-infra-dev/rslib) for the build tool.
- [UI-TARS](https://github.com/bytedance/ui-tars) for the open-source agent model UI-TARS.
- [Qwen-VL](https://github.com/QwenLM/Qwen-VL) for the open-source VL model Qwen-VL.
- [scrcpy](https://github.com/Genymobile/scrcpy) and [yume-chan](https://github.com/yume-chan) allow us to control Android devices with browser.
- [appium-adb](https://github.com/appium/appium-adb) for the javascript bridge of adb.
- [appium-webdriveragent](https://github.com/appium/WebDriverAgent) for the javascript operate XCTest„ÄÇ
- [YADB](https://github.com/ysbing/YADB) for the yadb tool which improves the performance of text input.
- [libnut-core](https://github.com/nut-tree/libnut-core) for the cross-platform native keyboard and mouse control.
- [Puppeteer](https://github.com/puppeteer/puppeteer) for browser automation and control.
- [Playwright](https://github.com/microsoft/playwright) for browser automation and control and testing.

## üìñ Citation

If you use Midscene.js in your research or project, please cite:

```bibtex
@software{Midscene.js,
  author = {Xiao Zhou, Tao Yu, YiBing Lin},
  title = {Midscene.js: Your AI Operator for Web, Android, iOS, Automation &amp; Testing.},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/web-infra-dev/midscene}
}
```

## ‚ú® Star History

[![Star History Chart](https://api.star-history.com/svg?repos=web-infra-dev/midscene&amp;type=Date)](https://www.star-history.com/#web-infra-dev/midscene&amp;Date)


## üìù License

Midscene.js is [MIT licensed](https://github.com/web-infra-dev/midscene/blob/main/LICENSE).

---

&lt;div align=&quot;center&quot;&gt;
  If this project helps you or inspires you, please give us a star
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[mnfst/manifest]]></title>
            <link>https://github.com/mnfst/manifest</link>
            <guid>https://github.com/mnfst/manifest</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:13 GMT</pubDate>
            <description><![CDATA[Smart LLM routing for OpenClaw. Cut Costs up to 70%]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mnfst/manifest">mnfst/manifest</a></h1>
            <p>Smart LLM routing for OpenClaw. Cut Costs up to 70%</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,414</p>
            <p>Forks: 160</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;.github/assets/logo-white.svg&quot; /&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;.github/assets/logo-dark.svg&quot; /&gt;
    &lt;img src=&quot;.github/assets/logo-dark.svg&quot; alt=&quot;Manifest&quot; height=&quot;53&quot; title=&quot;Manifest&quot;/&gt;
  &lt;/picture&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    ü¶û Take control of your
OpenClaw costs
&lt;/p&gt;

![manifest-gh](https://github.com/user-attachments/assets/7dd74fc2-f7d6-4558-a95a-014ed754a125)

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/mnfst/manifest/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/mnfst/manifest?style=flat&quot; alt=&quot;GitHub stars&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.npmjs.com/package/manifest&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/manifest?color=cb3837&amp;label=npm&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.npmjs.com/package/manifest&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dw/manifest?color=cb3837&quot; alt=&quot;npm downloads&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://github.com/mnfst/manifest/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/mnfst/manifest/ci.yml?branch=main&amp;label=CI&quot; alt=&quot;CI status&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://app.codecov.io/gh/mnfst/manifest&quot;&gt;&lt;img src=&quot;https://img.shields.io/codecov/c/github/mnfst/manifest?label=coverage&quot; alt=&quot;Codecov&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/mnfst/manifest?color=blue&quot; alt=&quot;license&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://discord.gg/FepAked3W7&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&amp;logoColor=white&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

## What do you get?

- üîÄ **Routes every request to the right model** ‚Äî and cuts costs up to 70%
- üìä **Track your expenses** ‚Äî real-time dashboard that shows tokens and costs per model
- üîî **Set limits** ‚Äî set up alerts (soft or hard) if your consumption exceeds a certain volume

## Why Manifest

OpenClaw sends all your requests to the same model, which is not cost-effective since you summon big models for tiny tasks. Manifest solves it by redirecting queries to the most cost-effective model.

Manifest is an OpenClaw plugin that intercepts your query, passes it through a 23-dimension scoring algorithm in &lt;2ms and sends it to the most suitable model.

Unlike almost all alternatives, everything stays on your machine. No suspicious installer, no black box, no third party, no crypto.

## Quick Start

### Cloud vs Local

Manifest is available in cloud and local versions. While both versions install the same OpenClaw Plugin, the local version stores the telemetry data on your computer and the cloud version uses our secure platform.

#### Use cloud if
- You want a quick install
- You want to access the dashboard from different devices
- You want to connect multiple agents

#### Use local if
- You don&#039;t want the telemetry data to move from your computer
- You don‚Äôt need multi-device access
- You don&#039;t want to subscribe to a cloud service

If you don&#039;t know which version to chose, start with the **cloud version**.

### Cloud (default)

```bash
openclaw plugins install manifest
openclaw config set plugins.entries.manifest.config.apiKey &quot;mnfst_YOUR_KEY&quot;
openclaw gateway restart
```

Sign up at [app.manifest.build](https://app.manifest.build) to get your API key.

### Local

```bash
openclaw plugins install manifest
openclaw config set plugins.entries.manifest.config.mode local
openclaw gateway restart
```

Dashboard opens at **http://127.0.0.1:2099**. Telemetry from your agents flows in automatically.

## Features

- **LLM Router** ‚Äî scores each query and calls the most suitable model
- **Real-time dashboard** ‚Äî tokens, costs, messages, and model usage at a glance
- **No coding required** ‚Äî Simple install as OpenClaw plugin
- **OTLP-native** ‚Äî standard OpenTelemetry ingestion (traces, metrics, logs)

## Privacy by architecture

**In local mode, your data stays on your machine.** All agent messages, token counts, costs, and telemetry are stored locally. In cloud mode, only OpenTelemetry metadata (model, tokens, latency) is sent ‚Äî message content is never collected.

**In cloud mode, the blind proxy physically cannot read your prompts** This is fundamentally different from services saying &quot;trust us.&quot;

The only thing Manifest collects is anonymous product analytics (hashed machine ID, OS platform, package version, event names) to help improve the project. No personally identifiable information or agent data is included.

**Opting out:**

```bash
MANIFEST_TELEMETRY_OPTOUT=1
```

Or add `&quot;telemetryOptOut&quot;: true` to `~/.openclaw/manifest/config.json`.


## Manifest vs OpenRouter

|              | Manifest                                                   | OpenRouter                                                    |
| ------------ | ---------------------------------------------------------- | ------------------------------------------------------------- |
| Architecture | Runs locally ‚Äî data stays on your machine                  | Cloud proxy ‚Äî all traffic routes through their servers        |
| Cost         | Free                                                       | 5% fee on every API call                                      |
| Source code  | MIT licensed, fully open                                   | Proprietary                                                   |
| Data privacy | 100% local routing and logging                    | Your prompts and responses pass through a third party         |
| Transparency | Open scoring algorithm ‚Äî see exactly why a model is chosen | Black box routing, no visibility into how models are selected |

## Supported Providers

Manifest supports **300+ models** across all major LLM providers. Every provider supports smart routing, real-time cost tracking, and OTLP telemetry.

| Provider | Models |
|----------|--------|
| [OpenAI](https://platform.openai.com/) | `gpt-5.3`, `gpt-4.1`, `o3`, `o4-mini` + 54 more |
| [Anthropic](https://www.anthropic.com/) | `claude-opus-4-6`, `claude-sonnet-4.5`, `claude-haiku-4.5` + 14 more |
| [Google Gemini](https://ai.google.dev/) | `gemini-2.5-pro`, `gemini-2.5-flash`, `gemini-3-pro` + 19 more |
| [DeepSeek](https://www.deepseek.com/) | `deepseek-v3`, `deepseek-r1` + 11 more |
| [xAI](https://x.ai/) | `grok-4`, `grok-3`, `grok-3-mini` + 8 more |
| [Mistral AI](https://mistral.ai/) | `mistral-large`, `codestral`, `devstral` + 26 more |
| [Qwen (Alibaba)](https://www.alibabacloud.com/en/solutions/generative-ai/qwen) | `qwen3-235b`, `qwen3-coder`, `qwq-32b` + 42 more |
| [Kimi (Moonshot)](https://kimi.ai/) | `kimi-k2`, `kimi-k2.5` + 3 more |
| [Amazon Nova](https://aws.amazon.com/ai/nova/) | `nova-pro`, `nova-lite`, `nova-micro` + 5 more |
| [Zhipu AI](https://www.zhipuai.cn/) | `glm-5`, `glm-4.6`, `glm-4-plus` + 9 more |
| [OpenRouter](https://openrouter.ai/) | 300+ models from all providers |
| [Ollama](https://ollama.com/) | Run any model locally (Llama, Gemma, Mistral, ‚Ä¶) |

## Contributing

Manifest is open source under the [MIT license](LICENSE). See [CONTRIBUTING.md](CONTRIBUTING.md) for the development setup, architecture notes, and workflow. Join the conversation on [Discord](https://discord.gg/FepAked3W7).

&gt; **Want a hosted version instead?** Check out [app.manifest.build](https://app.manifest.build)

## Quick Links

- [GitHub](https://github.com/mnfst/manifest)
- [Docs](https://manifest.build/docs)
- [Discord](https://discord.com/invite/FepAked3W7)
- [Discussions](https://github.com/mnfst/manifest/discussions)

## License

[MIT](LICENSE)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[openclaw/openclaw]]></title>
            <link>https://github.com/openclaw/openclaw</link>
            <guid>https://github.com/openclaw/openclaw</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:12 GMT</pubDate>
            <description><![CDATA[Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openclaw/openclaw">openclaw/openclaw</a></h1>
            <p>Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û</p>
            <p>Language: TypeScript</p>
            <p>Stars: 240,349</p>
            <p>Forks: 46,396</p>
            <p>Stars today: 3,888 stars today</p>
            <h2>README</h2><pre># ü¶û OpenClaw ‚Äî Personal AI Assistant

&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text-dark.png&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text.png&quot; alt=&quot;OpenClaw&quot; width=&quot;500&quot;&gt;
    &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;EXFOLIATE! EXFOLIATE!&lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/openclaw/openclaw/actions/workflows/ci.yml?branch=main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/openclaw/openclaw/ci.yml?branch=main&amp;style=for-the-badge&quot; alt=&quot;CI status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/openclaw/openclaw/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/openclaw/openclaw?include_prereleases&amp;style=for-the-badge&quot; alt=&quot;GitHub release&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/clawd&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1456350064065904867?label=Discord&amp;logo=discord&amp;logoColor=white&amp;color=5865F2&amp;style=for-the-badge&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge&quot; alt=&quot;MIT License&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

**OpenClaw** is a _personal AI assistant_ you run on your own devices.
It answers you on the channels you already use (WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, WebChat), plus extension channels like BlueBubbles, Matrix, Zalo, and Zalo Personal. It can speak and listen on macOS/iOS/Android, and can render a live Canvas you control. The Gateway is just the control plane ‚Äî the product is the assistant.

If you want a personal, single-user assistant that feels local, fast, and always-on, this is it.

[Website](https://openclaw.ai) ¬∑ [Docs](https://docs.openclaw.ai) ¬∑ [Vision](VISION.md) ¬∑ [DeepWiki](https://deepwiki.com/openclaw/openclaw) ¬∑ [Getting Started](https://docs.openclaw.ai/start/getting-started) ¬∑ [Updating](https://docs.openclaw.ai/install/updating) ¬∑ [Showcase](https://docs.openclaw.ai/start/showcase) ¬∑ [FAQ](https://docs.openclaw.ai/help/faq) ¬∑ [Wizard](https://docs.openclaw.ai/start/wizard) ¬∑ [Nix](https://github.com/openclaw/nix-openclaw) ¬∑ [Docker](https://docs.openclaw.ai/install/docker) ¬∑ [Discord](https://discord.gg/clawd)

Preferred setup: run the onboarding wizard (`openclaw onboard`) in your terminal.
The wizard guides you step by step through setting up the gateway, workspace, channels, and skills. The CLI wizard is the recommended path and works on **macOS, Linux, and Windows (via WSL2; strongly recommended)**.
Works with npm, pnpm, or bun.
New install? Start here: [Getting started](https://docs.openclaw.ai/start/getting-started)

## Sponsors

| OpenAI                                                            | Blacksmith                                                                   | Convex                                                                |
| ----------------------------------------------------------------- | ---------------------------------------------------------------------------- | --------------------------------------------------------------------- |
| [![OpenAI](docs/assets/sponsors/openai.svg)](https://openai.com/) | [![Blacksmith](docs/assets/sponsors/blacksmith.svg)](https://blacksmith.sh/) | [![Convex](docs/assets/sponsors/convex.svg)](https://www.convex.dev/) |

**Subscriptions (OAuth):**

- **[OpenAI](https://openai.com/)** (ChatGPT/Codex)

Model note: while any model is supported, I strongly recommend **Anthropic Pro/Max (100/200) + Opus 4.6** for long‚Äëcontext strength and better prompt‚Äëinjection resistance. See [Onboarding](https://docs.openclaw.ai/start/onboarding).

## Models (selection + auth)

- Models config + CLI: [Models](https://docs.openclaw.ai/concepts/models)
- Auth profile rotation (OAuth vs API keys) + fallbacks: [Model failover](https://docs.openclaw.ai/concepts/model-failover)

## Install (recommended)

Runtime: **Node ‚â•22**.

```bash
npm install -g openclaw@latest
# or: pnpm add -g openclaw@latest

openclaw onboard --install-daemon
```

The wizard installs the Gateway daemon (launchd/systemd user service) so it stays running.

## Quick start (TL;DR)

Runtime: **Node ‚â•22**.

Full beginner guide (auth, pairing, channels): [Getting started](https://docs.openclaw.ai/start/getting-started)

```bash
openclaw onboard --install-daemon

openclaw gateway --port 18789 --verbose

# Send a message
openclaw message send --to +1234567890 --message &quot;Hello from OpenClaw&quot;

# Talk to the assistant (optionally deliver back to any connected channel: WhatsApp/Telegram/Slack/Discord/Google Chat/Signal/iMessage/BlueBubbles/Microsoft Teams/Matrix/Zalo/Zalo Personal/WebChat)
openclaw agent --message &quot;Ship checklist&quot; --thinking high
```

Upgrading? [Updating guide](https://docs.openclaw.ai/install/updating) (and run `openclaw doctor`).

## Development channels

- **stable**: tagged releases (`vYYYY.M.D` or `vYYYY.M.D-&lt;patch&gt;`), npm dist-tag `latest`.
- **beta**: prerelease tags (`vYYYY.M.D-beta.N`), npm dist-tag `beta` (macOS app may be missing).
- **dev**: moving head of `main`, npm dist-tag `dev` (when published).

Switch channels (git + npm): `openclaw update --channel stable|beta|dev`.
Details: [Development channels](https://docs.openclaw.ai/install/development-channels).

## From source (development)

Prefer `pnpm` for builds from source. Bun is optional for running TypeScript directly.

```bash
git clone https://github.com/openclaw/openclaw.git
cd openclaw

pnpm install
pnpm ui:build # auto-installs UI deps on first run
pnpm build

pnpm openclaw onboard --install-daemon

# Dev loop (auto-reload on TS changes)
pnpm gateway:watch
```

Note: `pnpm openclaw ...` runs TypeScript directly (via `tsx`). `pnpm build` produces `dist/` for running via Node / the packaged `openclaw` binary.

## Security defaults (DM access)

OpenClaw connects to real messaging surfaces. Treat inbound DMs as **untrusted input**.

Full security guide: [Security](https://docs.openclaw.ai/gateway/security)

Default behavior on Telegram/WhatsApp/Signal/iMessage/Microsoft Teams/Discord/Google Chat/Slack:

- **DM pairing** (`dmPolicy=&quot;pairing&quot;` / `channels.discord.dmPolicy=&quot;pairing&quot;` / `channels.slack.dmPolicy=&quot;pairing&quot;`; legacy: `channels.discord.dm.policy`, `channels.slack.dm.policy`): unknown senders receive a short pairing code and the bot does not process their message.
- Approve with: `openclaw pairing approve &lt;channel&gt; &lt;code&gt;` (then the sender is added to a local allowlist store).
- Public inbound DMs require an explicit opt-in: set `dmPolicy=&quot;open&quot;` and include `&quot;*&quot;` in the channel allowlist (`allowFrom` / `channels.discord.allowFrom` / `channels.slack.allowFrom`; legacy: `channels.discord.dm.allowFrom`, `channels.slack.dm.allowFrom`).

Run `openclaw doctor` to surface risky/misconfigured DM policies.

## Highlights

- **[Local-first Gateway](https://docs.openclaw.ai/gateway)** ‚Äî single control plane for sessions, channels, tools, and events.
- **[Multi-channel inbox](https://docs.openclaw.ai/channels)** ‚Äî WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, BlueBubbles (iMessage), iMessage (legacy), Microsoft Teams, Matrix, Zalo, Zalo Personal, WebChat, macOS, iOS/Android.
- **[Multi-agent routing](https://docs.openclaw.ai/gateway/configuration)** ‚Äî route inbound channels/accounts/peers to isolated agents (workspaces + per-agent sessions).
- **[Voice Wake](https://docs.openclaw.ai/nodes/voicewake) + [Talk Mode](https://docs.openclaw.ai/nodes/talk)** ‚Äî always-on speech for macOS/iOS/Android with ElevenLabs.
- **[Live Canvas](https://docs.openclaw.ai/platforms/mac/canvas)** ‚Äî agent-driven visual workspace with [A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui).
- **[First-class tools](https://docs.openclaw.ai/tools)** ‚Äî browser, canvas, nodes, cron, sessions, and Discord/Slack actions.
- **[Companion apps](https://docs.openclaw.ai/platforms/macos)** ‚Äî macOS menu bar app + iOS/Android [nodes](https://docs.openclaw.ai/nodes).
- **[Onboarding](https://docs.openclaw.ai/start/wizard) + [skills](https://docs.openclaw.ai/tools/skills)** ‚Äî wizard-driven setup with bundled/managed/workspace skills.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=openclaw/openclaw&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#openclaw/openclaw&amp;type=date&amp;legend=top-left)

## Everything we built so far

### Core platform

- [Gateway WS control plane](https://docs.openclaw.ai/gateway) with sessions, presence, config, cron, webhooks, [Control UI](https://docs.openclaw.ai/web), and [Canvas host](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui).
- [CLI surface](https://docs.openclaw.ai/tools/agent-send): gateway, agent, send, [wizard](https://docs.openclaw.ai/start/wizard), and [doctor](https://docs.openclaw.ai/gateway/doctor).
- [Pi agent runtime](https://docs.openclaw.ai/concepts/agent) in RPC mode with tool streaming and block streaming.
- [Session model](https://docs.openclaw.ai/concepts/session): `main` for direct chats, group isolation, activation modes, queue modes, reply-back. Group rules: [Groups](https://docs.openclaw.ai/channels/groups).
- [Media pipeline](https://docs.openclaw.ai/nodes/images): images/audio/video, transcription hooks, size caps, temp file lifecycle. Audio details: [Audio](https://docs.openclaw.ai/nodes/audio).

### Channels

- [Channels](https://docs.openclaw.ai/channels): [WhatsApp](https://docs.openclaw.ai/channels/whatsapp) (Baileys), [Telegram](https://docs.openclaw.ai/channels/telegram) (grammY), [Slack](https://docs.openclaw.ai/channels/slack) (Bolt), [Discord](https://docs.openclaw.ai/channels/discord) (discord.js), [Google Chat](https://docs.openclaw.ai/channels/googlechat) (Chat API), [Signal](https://docs.openclaw.ai/channels/signal) (signal-cli), [BlueBubbles](https://docs.openclaw.ai/channels/bluebubbles) (iMessage, recommended), [iMessage](https://docs.openclaw.ai/channels/imessage) (legacy imsg), [Microsoft Teams](https://docs.openclaw.ai/channels/msteams) (extension), [Matrix](https://docs.openclaw.ai/channels/matrix) (extension), [Zalo](https://docs.openclaw.ai/channels/zalo) (extension), [Zalo Personal](https://docs.openclaw.ai/channels/zalouser) (extension), [WebChat](https://docs.openclaw.ai/web/webchat).
- [Group routing](https://docs.openclaw.ai/channels/group-messages): mention gating, reply tags, per-channel chunking and routing. Channel rules: [Channels](https://docs.openclaw.ai/channels).

### Apps + nodes

- [macOS app](https://docs.openclaw.ai/platforms/macos): menu bar control plane, [Voice Wake](https://docs.openclaw.ai/nodes/voicewake)/PTT, [Talk Mode](https://docs.openclaw.ai/nodes/talk) overlay, [WebChat](https://docs.openclaw.ai/web/webchat), debug tools, [remote gateway](https://docs.openclaw.ai/gateway/remote) control.
- [iOS node](https://docs.openclaw.ai/platforms/ios): [Canvas](https://docs.openclaw.ai/platforms/mac/canvas), [Voice Wake](https://docs.openclaw.ai/nodes/voicewake), [Talk Mode](https://docs.openclaw.ai/nodes/talk), camera, screen recording, Bonjour pairing.
- [Android node](https://docs.openclaw.ai/platforms/android): [Canvas](https://docs.openclaw.ai/platforms/mac/canvas), [Talk Mode](https://docs.openclaw.ai/nodes/talk), camera, screen recording, optional SMS.
- [macOS node mode](https://docs.openclaw.ai/nodes): system.run/notify + canvas/camera exposure.

### Tools + automation

- [Browser control](https://docs.openclaw.ai/tools/browser): dedicated openclaw Chrome/Chromium, snapshots, actions, uploads, profiles.
- [Canvas](https://docs.openclaw.ai/platforms/mac/canvas): [A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui) push/reset, eval, snapshot.
- [Nodes](https://docs.openclaw.ai/nodes): camera snap/clip, screen record, [location.get](https://docs.openclaw.ai/nodes/location-command), notifications.
- [Cron + wakeups](https://docs.openclaw.ai/automation/cron-jobs); [webhooks](https://docs.openclaw.ai/automation/webhook); [Gmail Pub/Sub](https://docs.openclaw.ai/automation/gmail-pubsub).
- [Skills platform](https://docs.openclaw.ai/tools/skills): bundled, managed, and workspace skills with install gating + UI.

### Runtime + safety

- [Channel routing](https://docs.openclaw.ai/channels/channel-routing), [retry policy](https://docs.openclaw.ai/concepts/retry), and [streaming/chunking](https://docs.openclaw.ai/concepts/streaming).
- [Presence](https://docs.openclaw.ai/concepts/presence), [typing indicators](https://docs.openclaw.ai/concepts/typing-indicators), and [usage tracking](https://docs.openclaw.ai/concepts/usage-tracking).
- [Models](https://docs.openclaw.ai/concepts/models), [model failover](https://docs.openclaw.ai/concepts/model-failover), and [session pruning](https://docs.openclaw.ai/concepts/session-pruning).
- [Security](https://docs.openclaw.ai/gateway/security) and [troubleshooting](https://docs.openclaw.ai/channels/troubleshooting).

### Ops + packaging

- [Control UI](https://docs.openclaw.ai/web) + [WebChat](https://docs.openclaw.ai/web/webchat) served directly from the Gateway.
- [Tailscale Serve/Funnel](https://docs.openclaw.ai/gateway/tailscale) or [SSH tunnels](https://docs.openclaw.ai/gateway/remote) with token/password auth.
- [Nix mode](https://docs.openclaw.ai/install/nix) for declarative config; [Docker](https://docs.openclaw.ai/install/docker)-based installs.
- [Doctor](https://docs.openclaw.ai/gateway/doctor) migrations, [logging](https://docs.openclaw.ai/logging).

## How it works (short)

```
WhatsApp / Telegram / Slack / Discord / Google Chat / Signal / iMessage / BlueBubbles / Microsoft Teams / Matrix / Zalo / Zalo Personal / WebChat
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Gateway            ‚îÇ
‚îÇ       (control plane)         ‚îÇ
‚îÇ     ws://127.0.0.1:18789      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚îú‚îÄ Pi agent (RPC)
               ‚îú‚îÄ CLI (openclaw ‚Ä¶)
               ‚îú‚îÄ WebChat UI
               ‚îú‚îÄ macOS app
               ‚îî‚îÄ iOS / Android nodes
```

## Key subsystems

- **[Gateway WebSocket network](https://docs.openclaw.ai/concepts/architecture)** ‚Äî single WS control plane for clients, tools, and events (plus ops: [Gateway runbook](https://docs.openclaw.ai/gateway)).
- **[Tailscale exposure](https://docs.openclaw.ai/gateway/tailscale)** ‚Äî Serve/Funnel for the Gateway dashboard + WS (remote access: [Remote](https://docs.openclaw.ai/gateway/remote)).
- **[Browser control](https://docs.openclaw.ai/tools/browser)** ‚Äî openclaw‚Äëmanaged Chrome/Chromium with CDP control.
- **[Canvas + A2UI](https://docs.openclaw.ai/platforms/mac/canvas)** ‚Äî agent‚Äëdriven visual workspace (A2UI host: [Canvas/A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui)).
- **[Voice Wake](https://docs.openclaw.ai/nodes/voicewake) + [Talk Mode](https://docs.openclaw.ai/nodes/talk)** ‚Äî always‚Äëon speech and continuous conversation.
- **[Nodes](https://docs.openclaw.ai/nodes)** ‚Äî Canvas, camera snap/clip, screen record, `location.get`, notifications, plus macOS‚Äëonly `system.run`/`system.notify`.

## Tailscale access (Gateway dashboard)

OpenClaw can auto-configure Tailscale **Serve** (tailnet-only) or **Funnel** (public) while the Gateway stays bound to loopback. Configure `gateway.tailscale.mode`:

- `off`: no Tailscale automation (default).
- `serve`: tailnet-only HTTPS via `tailscale serve` (uses Tailscale identity headers by default).
- `funnel`: public HTTPS via `tailscale funnel` (requires shared password auth).

Notes:

- `gateway.bind` must stay `loopback` when Serve/Funnel is enabled (OpenClaw enforces this).
- Serve can be forced to require a password by setting `gateway.auth.mode: &quot;password&quot;` or `gateway.auth.allowTailscale: false`.
- Funnel refuses to start unless `gateway.auth.mode: &quot;password&quot;` is set.
- Optional: `gateway.tailscale.resetOnExit` to undo Serve/Funnel on shutdown.

Details: [Tailscale guide](https://docs.openclaw.ai/gateway/tailscale) ¬∑ [Web surfaces](https://docs.openclaw.ai/web)

## Remote Gateway (Linux is great)

It‚Äôs perfectly fine to run the Gateway on a small Linux instance. Clients (macOS app, CLI, WebChat) can connect over **Tailscale Serve/Funnel** or **SSH tunnels**, and you can still pair device nodes (macOS/iOS/Android) to execute device‚Äëlocal actions when needed.

- **Gateway host** runs the exec tool and channel connections by default.
- **Device nodes** run device‚Äëlocal actions (`system.run`, camera, screen recording, notifications) via `node.invoke`.
  In short: exec runs where the Gateway lives; device actions run where the device lives.

Details: [Remote access](https://docs.openclaw.ai/gateway/remote) ¬∑ [Nodes](https://docs.openclaw.ai/nodes) ¬∑ [Security](https://docs.openclaw.ai/gateway/security)

## macOS permissions via the Gateway protocol

The macOS app can run in **node mode** and advertises its capabilities + permission map over the Gateway WebSocket (`node.list` / `node.describe`). Clients can then execute local actions via `node.invoke`:

- `system.run` runs a local command and returns stdout/stderr/exit code; set `needsScreenRecording: true` to require screen-recording permission (otherwise you‚Äôll get `PERMISSION_MISSING`).
- `system.notify` posts a user notification and fails if notifications are denied.
- `canvas.*`, `camera.*`, `screen.record`, and `location.get` are also routed via `node.invoke` and follow TCC permission status.

Elevated bash (host permissions) is separate from macOS TCC:

- Use `/elevated on|off` to toggle per‚Äësession elevated access when enabled + allowlisted.
- Gateway persists the per‚Äësession toggle via `sessions.patch` (WS method) alongside `thinkingLevel`, `verboseLevel`, `model`, `sendPolicy`, and `groupActivation`.

Details: [Nodes](https://docs.openclaw.ai/nodes) ¬∑ [macOS app](https://docs.openclaw.ai/platforms/macos) ¬∑ [Gateway protocol](https://docs.openclaw.ai/concepts/architecture)

## Agent to Agent (sessions\_\* tools)

- Use these to coordinate work across sessions without jumping between chat surfaces.
- `sessions_list` ‚Äî discover active sessions (agents) and their metadata.
- `sessions_history` ‚Äî fetch transcript logs for a session.
- `sessions_send` ‚Äî message another session; optional reply‚Äëback ping‚Äëpong + announce step (`REPLY_SKIP`, `ANNOUNCE_SKIP`).

Details: [Session tools](https://docs.openclaw.ai/concepts/session-tool)

## Skills registry (ClawHub)

ClawHub is a minimal skill registry. With ClawHub enabled, the agent can search for skills automatically and pull in new ones as needed.

[ClawHub](https://clawhub.com)

## Chat commands

Send these in WhatsApp/Telegram/Slack/Google Chat/Microsoft Teams/WebChat (group commands are owner-only):

- `/status` ‚Äî compact session status (model + tokens, cost when available)
- `/new` or `/reset` ‚Äî reset the session
- `/compact` ‚Äî compact session context (summary)
- `/think &lt;level&gt;` ‚Äî off|minimal|low|medium|high|xhigh (GPT-5.2 + Codex models only)
- `/verbose on|off`
- `/usage off|tokens|full` ‚Äî per-response usage footer
- `/restart` ‚Äî restart the gateway (owner-only in groups)
- `/activation mention|always` ‚Äî group activation toggle (groups only)

## Apps (optional)

The Gateway alone delivers a great experience. All apps are optional and add extra features.

If you plan to build/run companion apps, follow the platform runbooks below.

### macOS (OpenClaw.app) (optional)

- Menu bar control for the Gateway and health.
- Voice Wake + push-to-talk overlay.
- WebChat + debug tools.
- Remote gateway control over SSH.

Note: signed builds required for macOS permissions to stick across rebuilds (see `docs/mac/permissions.md`).

### iOS node (optional)

- Pairs as a node via the Bridge.
- Voice trigger forwarding + Canvas surface.
- Controlled via `openclaw nodes ‚Ä¶`.

Runbook: [iOS connect](https://docs.openclaw.ai/platforms/ios).

### Android node (optional)

- Pairs via the same Bridge + pairing flow as i

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>