<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Sat, 27 Sep 2025 00:04:44 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[ZuodaoTech/everyone-can-use-english]]></title>
            <link>https://github.com/ZuodaoTech/everyone-can-use-english</link>
            <guid>https://github.com/ZuodaoTech/everyone-can-use-english</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[‰∫∫‰∫∫ÈÉΩËÉΩÁî®Ëã±ËØ≠]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ZuodaoTech/everyone-can-use-english">ZuodaoTech/everyone-can-use-english</a></h1>
            <p>‰∫∫‰∫∫ÈÉΩËÉΩÁî®Ëã±ËØ≠</p>
            <p>Language: TypeScript</p>
            <p>Stars: 29,951</p>
            <p>Forks: 4,296</p>
            <p>Stars today: 448 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./enjoy/assets/icon.png&quot; alt=&quot;Clash&quot; width=&quot;128&quot; /&gt;
&lt;/div&gt;

&lt;h3 align=&quot;center&quot;&gt;
AI ÊòØÂΩì‰ªä‰∏ñÁïå‰∏äÊúÄÂ•ΩÁöÑÂ§ñËØ≠ËÄÅÂ∏àÔºåEnjoy ÂÅö AI ÊúÄÂ•ΩÁöÑÂä©Êïô„ÄÇ
&lt;/h3&gt;

[![Deploy 1000h website](https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/deploy-1000h.yml/badge.svg)](https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/deploy-1000h.yml)
[![Test Enjoy App](https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/test-enjoy-app.yml/badge.svg)](https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/test-enjoy-app.yml)
[![Release Enjoy App](https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/release-enjoy-app.yml/badge.svg)](https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/release-enjoy-app.yml)
![Latest Version](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fenjoy.bot%2Fapi%2Fconfig%2Fapp_version&amp;query=%24.version&amp;label=Latest&amp;link=https%3A%2F%2F1000h.org%2Fenjoy-app%2Finstall.html)
![Recording Duration](https://img.shields.io/endpoint?url=https%3A%2F%2Fenjoy.bot%2Fapi%2Fbadges%2Frecordings)

---

## ÁΩëÈ°µÁâà

Enjoy ÁΩëÈ°µÁâàÂ∑≤Áªè‰∏äÁ∫øÔºåÂèØËÆøÈóÆ [https://enjoy.bot](https://enjoy.bot) Áõ¥Êé•‰ΩøÁî®„ÄÇ

&lt;div align=&quot;center&quot; style=&quot;display:flex;overflow:auto;gap:10px;&quot;&gt;
  &lt;img src=&quot;./enjoy/snapshots/web-audios.jpg&quot; alt=&quot;Audios&quot; width=&quot;300&quot; /&gt;
  &lt;img src=&quot;./enjoy/snapshots/web-add-audio.jpg&quot; alt=&quot;Add Audio&quot; width=&quot;300&quot; /&gt;
  &lt;img src=&quot;./enjoy/snapshots/web-audio-shadow.jpg&quot; alt=&quot;Shadow&quot; width=&quot;300&quot; /&gt;
  &lt;img src=&quot;./enjoy/snapshots/web-audio-assessment.jpg&quot; alt=&quot;Assessment&quot; width=&quot;300&quot; /&gt;
  &lt;img src=&quot;./enjoy/snapshots/web-new-chat.jpg&quot; alt=&quot;New Chat&quot; width=&quot;300&quot; /&gt;
  &lt;img src=&quot;./enjoy/snapshots/web-chat.jpg&quot; alt=&quot;Chat&quot; width=&quot;300&quot; /&gt;
&lt;/div&gt;

---

## Ê°åÈù¢ÁâàÂÆâË£ÖÂèä‰ΩøÁî®

‰∏ãËΩΩÂèä‰ΩøÁî®Áõ∏ÂÖ≥ËØ¥ÊòéÔºåËØ∑ÂèÇÈòÖ [ÊñáÊ°£](https://1000h.org/enjoy-app/)„ÄÇ

## È¢ÑËßà

&lt;div align=&quot;center&quot; style=&quot;display:flex;overflow:auto;&quot;&gt;
  &lt;img src=&quot;./enjoy/snapshots/home.png&quot; alt=&quot;Home&quot; width=&quot;800&quot; /&gt;

  &lt;img src=&quot;./enjoy/snapshots/shadow.png&quot; alt=&quot;Home&quot; width=&quot;800&quot; /&gt;

  &lt;img src=&quot;./enjoy/snapshots/assessment.png&quot; alt=&quot;Home&quot; width=&quot;800&quot; /&gt;

  &lt;img src=&quot;./enjoy/snapshots/document.png&quot; alt=&quot;Home&quot; width=&quot;800&quot; /&gt;

  &lt;img src=&quot;./enjoy/snapshots/chat.png&quot; alt=&quot;Home&quot; width=&quot;800&quot; /&gt;
&lt;/div&gt;

## Ê°åÈù¢ÁâàÂºÄÂèë

```bash
yarn install
yarn enjoy:start
```

## Áõ∏ÂÖ≥ÈòÖËØª

### ‰∏ÄÂçÉÂ∞èÊó∂Ôºà2024Ôºâ

- [ÁÆÄË¶ÅËØ¥Êòé](https://1000h.org/intro.html)
- [ËÆ≠ÁªÉ‰ªªÂä°](https://1000h.org/training-tasks/kick-off.html)
- [ËØ≠Èü≥Â°ëÈÄ†](https://1000h.org/sounds-of-american-english/0-intro.html)
- [Â§ßËÑëÂÜÖÈÉ®](https://1000h.org/in-the-brain/01-inifinite.html)
- [Ëá™ÊàëËÆ≠ÁªÉ](https://1000h.org/self-training/00-intro.html)

### ‰∫∫‰∫∫ÈÉΩËÉΩÁî®Ëã±ËØ≠Ôºà2010Ôºâ

- [ÁÆÄ‰ªã](./book/README.md)
- [Á¨¨‰∏ÄÁ´†ÔºöËµ∑ÁÇπ](./book/chapter1.md)
- [Á¨¨‰∫åÁ´†ÔºöÂè£ËØ≠](./book/chapter2.md)
- [Á¨¨‰∏âÁ´†ÔºöËØ≠Èü≥](./book/chapter3.md)
- [Á¨¨ÂõõÁ´†ÔºöÊúóËØª](./book/chapter4.md)
- [Á¨¨‰∫îÁ´†ÔºöËØçÂÖ∏](./book/chapter5.md)
- [Á¨¨ÂÖ≠Á´†ÔºöËØ≠Ê≥ï](./book/chapter6.md)
- [Á¨¨‰∏ÉÁ´†ÔºöÁ≤æËØª](./book/chapter7.md)
- [Á¨¨ÂÖ´Á´†ÔºöÂèÆÂò±](./book/chapter8.md)
- [ÂêéËÆ∞](./book/end.md)

## Â∏∏ËßÅÈóÆÈ¢ò

ËØ∑Êü•ËØ¢ [ÊñáÊ°£ FAQ](https://1000h.org/enjoy-app/faq.html)„ÄÇ
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[humanlayer/humanlayer]]></title>
            <link>https://github.com/humanlayer/humanlayer</link>
            <guid>https://github.com/humanlayer/humanlayer</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[The best way to get AI to solve hard problems in complex codebases.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/humanlayer/humanlayer">humanlayer/humanlayer</a></h1>
            <p>The best way to get AI to solve hard problems in complex codebases.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,235</p>
            <p>Forks: 275</p>
            <p>Stars today: 338 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![Wordmark Logo of HumanLayer](./docs/images/wordmark-light.svg)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

# Close your editor forever.

**CodeLayer is an open source IDE that lets you orchestrate AI coding agents.**

It comes with battle-tested workflows that enable AI to solve hard problems in large, complex codebases.

Built on Claude Code. Open source. Scale from your laptop to your entire team.

[![GitHub Repo stars](https://img.shields.io/github/stars/humanlayer/humanlayer)](https://github.com/humanlayer/humanlayer)
[![License: Apache-2](https://img.shields.io/badge/License-Apache-green.svg)](https://opensource.org/licenses/Apache-2)

&lt;h3&gt;

[Join Waitlist](https://humanlayer.dev/code) | [Discord](https://humanlayer.dev/discord)

&lt;/h3&gt;

&lt;img referrerpolicy=&quot;no-referrer-when-downgrade&quot; src=&quot;https://static.scarf.sh/a.png?x-pxid=fcfc0926-d841-47fb-b8a6-6aba3a6c3228&quot; /&gt;

&lt;/div&gt;

---

&gt; &quot;Our entire company is using CodeLayer now. We&#039;re shipping one banger PR after the other. It is so f-ing good. Unbelievable dude.&quot;
&gt;
&gt; **‚Äì Ren√© Brandel, Founder @ Casco (YC X25)**

---

## Superhuman for Claude Code

Keyboard-first workflows designed for builders who value speed and control.

## Advanced Context Engineering

Scale AI-first dev to your entire team, without devolving into a chaotic slop-fest.

## M U L T I C L A U D E

Run Claude Code sessions in parallel. Worktrees? Done. Remote cloud workers? You got it.

---

&gt; &quot;This has improved my productivity (and token consumption) by at least 50%. Taking a superhuman style approach just makes soo much sense. Also, its so freaking cool to look back at all the work you&#039;ve done in a day.&quot;
&gt;
&gt; **‚Äì Tyler Brown, Founder @ Revlo.ai**

---

## From the team that brought you &quot;Context Engineering&quot;

Leading experts on getting the most out of today&#039;s models.

### üìö Resources

#### [Advanced Context Engineering for Coding Agents](https://github.com/humanlayer/humanlayer)
This talk, given at YC on August 20th, 2025 lays out the groundwork for using AI to solve hard problems in complex codebases.
- [GitHub](https://github.com/humanlayer/humanlayer)
- [YouTube](https://humanlayer.dev/youtube)

#### [12 Factor Agents](https://github.com/humanlayer/humanlayer)
A set of principles for building reliable and scalable LLM applications, inspired by the original 12-Factor App methodology.
- [GitHub](https://github.com/humanlayer/humanlayer)
- [YouTube](https://humanlayer.dev/youtube)

The original repo that coined the term &quot;context engineering&quot; back in April 2025.

#### [ü¶Ñ AI That Works](https://humanlayer.dev/podcast)
A weekly conversation about how we can all get the most juice out of todays models with @hellovai &amp; @dexhorthy
- [GitHub](https://github.com/humanlayer/humanlayer)
- [Podcast](https://humanlayer.dev/podcast)

---

## For Teams

**Invest in outcomes, not tools.**

Want to scale AI-first development to your entire org? Get tailored workflows, custom integrations, and cutting-edge advice.

HumanLayer&#039;s expert engineers will ship in the trenches with you and your team until everyone is a 100x engineer.

üìß Shoot us an email at **contact@humanlayer.dev**, mention your team size and current AI development stack.

---

## Quick Start

```bash
# Coming soon - join the waitlist for early access
```

---

## Legacy Documentation

Looking for the HumanLayer SDK documentation? See [humanlayer.md](./humanlayer.md)

## Contributing

CodeLayer and the HumanLayer SDK are open-source and we welcome contributions in the form of issues, documentation, pull requests, and more. See [CONTRIBUTING.md](./CONTRIBUTING.md) for more details.

## License

The HumanLayer SDK and CodeLayer sources in this repo are licensed under the Apache 2 License.

---

&lt;div align=&quot;center&quot;&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=humanlayer/humanlayer&amp;type=Date)](https://star-history.com/#humanlayer/humanlayer&amp;Date)

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ericciarla/trendFinder]]></title>
            <link>https://github.com/ericciarla/trendFinder</link>
            <guid>https://github.com/ericciarla/trendFinder</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:42 GMT</pubDate>
            <description><![CDATA[Stay on top of trending topics on social media and the web with AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ericciarla/trendFinder">ericciarla/trendFinder</a></h1>
            <p>Stay on top of trending topics on social media and the web with AI</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,646</p>
            <p>Forks: 396</p>
            <p>Stars today: 84 stars today</p>
            <h2>README</h2><pre># Trend Finder üî¶

**Stay on top of trending topics on social media ‚Äî all in one place.**

Trend Finder collects and analyzes posts from key influencers, then sends a Slack or Discord notification when it detects new trends or product launches. This has been a complete game-changer for the Firecrawl marketing team by:

- **Saving time** normally spent manually searching social channels
- **Keeping you informed** of relevant, real-time conversations
- **Enabling rapid response** to new opportunities or emerging industry shifts

_Spend less time hunting for trends and more time creating impactful campaigns._

## Watch the Demo &amp; Tutorial video

[![Thumbnail](https://i.ytimg.com/vi/puimQSun92g/hqdefault.jpg)](https://www.youtube.com/watch?v=puimQSun92g)

Learn how to set up Trend Finder and start monitoring trends in this video!

## How it Works

1. **Data Collection** üì•
   - Monitors selected influencers&#039; posts on Twitter/X using the X API (Warning: the X API free plan is rate limited to only monitor 1 X account every 15 min)
   - Monitors websites for new releases and news with Firecrawl&#039;s /extract
   - Runs on a scheduled basis using cron jobs

2. **AI Analysis** üß†
   - Processes collected content through Together AI
   - Identifies emerging trends, releases, and news.
   - Analyzes sentiment and relevance

3. **Notification System** üì¢
   - When significant trends are detected, sends Slack or Discord notifications based on cron job setup
   - Provides context about the trend and its sources
   - Enables quick response to emerging opportunities

## Features

- ü§ñ AI-powered trend analysis using Together AI
- üì± Social media monitoring (Twitter/X integration)
- üîç Website monitoring with Firecrawl
- üí¨ Instant Slack or Discord notifications
- ‚è±Ô∏è Scheduled monitoring using cron jobs

## Prerequisites

- Node.js (v14 or higher)
- npm or yarn
- Docker
- Docker Compose
- Slack workspace with webhook permissions
- API keys for required services

## Environment Variables

Copy `.env.example` to `.env` and configure the following variables:

```
# Optional: API key from Together AI for trend analysis (https://www.together.ai/)
TOGETHER_API_KEY=your_together_api_key_here

# Optional: API key from DeepSeek for trend analysis (https://deepseek.com/)
DEEPSEEK_API_KEY=

# Optional: API key from OpenAI for trend analysis (https://openai.com/)
OPENAI_API_KEY=

# Required if monitoring web pages (https://www.firecrawl.dev/)
FIRECRAWL_API_KEY=your_firecrawl_api_key_here

# Required if monitoring Twitter/X trends (https://developer.x.com/)
X_API_BEARER_TOKEN=your_twitter_api_bearer_token_here

# Notification driver. Supported drivers: &quot;slack&quot;, &quot;discord&quot;
NOTIFICATION_DRIVER=discord

# Required (if NOTIFICATION_DRIVER is &quot;slack&quot;): Incoming Webhook URL from Slack for notifications
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# Required (if NOTIFICATION_DRIVER is &quot;discord&quot;): Incoming Webhook URL from Discord for notifications
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/WEBHOOK/URL
```

## Getting Started

1. **Clone the repository:**
   ```bash
   git clone [repository-url]
   cd trend-finder
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Configure environment variables:**
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

4. **Run the application:**
   ```bash
   # Development mode with hot reloading
   npm run start

   # Build for production
   npm run build
   ```

## Using Docker

1. **Build the Docker image:**
   ```bash
   docker build -t trend-finder .
   ```

2. **Run the Docker container:**
   ```bash
   docker run -d -p 3000:3000 --env-file .env trend-finder
   ```

## Using Docker Compose

1. **Start the application with Docker Compose:**
   ```bash
   docker-compose up --build -d
   ```

2. **Stop the application with Docker Compose:**
   ```bash
   docker-compose down
   ```

## Project Structure

```
trend-finder/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ controllers/    # Request handlers
‚îÇ   ‚îú‚îÄ‚îÄ services/       # Business logic
‚îÇ   ‚îî‚îÄ‚îÄ index.ts        # Application entry point
‚îú‚îÄ‚îÄ .env.example        # Environment variables template
‚îú‚îÄ‚îÄ package.json        # Dependencies and scripts
‚îî‚îÄ‚îÄ tsconfig.json       # TypeScript configuration
```

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m &#039;Add some amazing feature&#039;`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[google-gemini/gemini-cli]]></title>
            <link>https://github.com/google-gemini/gemini-cli</link>
            <guid>https://github.com/google-gemini/gemini-cli</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:41 GMT</pubDate>
            <description><![CDATA[An open-source AI agent that brings the power of Gemini directly into your terminal.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google-gemini/gemini-cli">google-gemini/gemini-cli</a></h1>
            <p>An open-source AI agent that brings the power of Gemini directly into your terminal.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 76,935</p>
            <p>Forks: 8,258</p>
            <p>Stars today: 195 stars today</p>
            <h2>README</h2><pre># Gemini CLI

[![Gemini CLI CI](https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml/badge.svg)](https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml)
[![Gemini CLI E2E](https://github.com/google-gemini/gemini-cli/actions/workflows/e2e.yml/badge.svg)](https://github.com/google-gemini/gemini-cli/actions/workflows/e2e.yml)
[![Version](https://img.shields.io/npm/v/@google/gemini-cli)](https://www.npmjs.com/package/@google/gemini-cli)
[![License](https://img.shields.io/github/license/google-gemini/gemini-cli)](https://github.com/google-gemini/gemini-cli/blob/main/LICENSE)

![Gemini CLI Screenshot](./docs/assets/gemini-screenshot.png)

Gemini CLI is an open-source AI agent that brings the power of Gemini directly into your terminal. It provides lightweight access to Gemini, giving you the most direct path from your prompt to our model.

## üöÄ Why Gemini CLI?

- **üéØ Free tier**: 60 requests/min and 1,000 requests/day with personal Google account
- **üß† Powerful Gemini 2.5 Pro**: Access to 1M token context window
- **üîß Built-in tools**: Google Search grounding, file operations, shell commands, web fetching
- **üîå Extensible**: MCP (Model Context Protocol) support for custom integrations
- **üíª Terminal-first**: Designed for developers who live in the command line
- **üõ°Ô∏è Open source**: Apache 2.0 licensed

## üì¶ Installation

### Quick Install

#### Run instantly with npx

```bash
# Using npx (no installation required)
npx https://github.com/google-gemini/gemini-cli
```

#### Install globally with npm

```bash
npm install -g @google/gemini-cli
```

#### Install globally with Homebrew (macOS/Linux)

```bash
brew install gemini-cli
```

#### System Requirements

- Node.js version 20 or higher
- macOS, Linux, or Windows

## Release Cadence and Tags

See [Releases](./docs/releases.md) for more details.

### Preview

New preview releases will be published each week at UTC 2359 on Tuesdays. These releases will not have been fully vetted and may contain regressions or other outstanding issues. Please help us test and install with `preview` tag.

```bash
npm install -g @google/gemini-cli@preview
```

### Stable

- New stable releases will be published each week at UTC 2000 on Tuesdays, this will be the full promotion of last week&#039;s `preview` release + any bug fixes and validations. Use `latest` tag.

```bash
npm install -g @google/gemini-cli@latest
```

### Nightly

- New releases will be published each week at UTC 0000 each day, This will be all changes from the main branch as represented at time of release. It should be assumed there are pending validations and issues. Use `nightly` tag.

```bash
npm install -g @google/gemini-cli@nightly
```

## üìã Key Features

### Code Understanding &amp; Generation

- Query and edit large codebases
- Generate new apps from PDFs, images, or sketches using multimodal capabilities
- Debug issues and troubleshoot with natural language

### Automation &amp; Integration

- Automate operational tasks like querying pull requests or handling complex rebases
- Use MCP servers to connect new capabilities, including [media generation with Imagen, Veo or Lyria](https://github.com/GoogleCloudPlatform/vertex-ai-creative-studio/tree/main/experiments/mcp-genmedia)
- Run non-interactively in scripts for workflow automation

### Advanced Capabilities

- Ground your queries with built-in [Google Search](https://ai.google.dev/gemini-api/docs/grounding) for real-time information
- Conversation checkpointing to save and resume complex sessions
- Custom context files (GEMINI.md) to tailor behavior for your projects

### GitHub Integration

Integrate Gemini CLI directly into your GitHub workflows with [**Gemini CLI GitHub Action**](https://github.com/google-github-actions/run-gemini-cli):

- **Pull Request Reviews**: Automated code review with contextual feedback and suggestions
- **Issue Triage**: Automated labeling and prioritization of GitHub issues based on content analysis
- **On-demand Assistance**: Mention `@gemini-cli` in issues and pull requests for help with debugging, explanations, or task delegation
- **Custom Workflows**: Build automated, scheduled and on-demand workflows tailored to your team&#039;s needs

## üîê Authentication Options

Choose the authentication method that best fits your needs:

### Option 1: Login with Google (OAuth login using your Google Account)

**‚ú® Best for:**

- Individual developers.
- Google AI Pro and AI Ultra subscribers.
- Anyone who has a Gemini Code Assist license.

_See [quota limits and terms of service](https://cloud.google.com/gemini/docs/quotas) for details._

**Benefits:**

- **Free tier** with 60 requests/min and 1,000 requests/day
- **Gemini 2.5 Pro and Flash** with 1M token context window
- **No API key management** - just sign in with your Google account
- **Automatic updates** to our latest models

#### Start Gemini CLI, then choose _Login with Google_ and follow the browser authentication flow when prompted

```bash
gemini
```

#### If you are using a paid Code Assist License from your organization, remember to set the Google Cloud Project

```bash
# Set your Google Cloud Project
export GOOGLE_CLOUD_PROJECT=&quot;YOUR_PROJECT_NAME&quot;
gemini
```

### Option 2: Gemini API Key

**‚ú® Best for:** Developers who need specific model control or paid tier access

**Benefits:**

- **Free tier**: 100 requests/day with Gemini 2.5 Pro
- **Model selection**: Choose specific Gemini models
- **Usage-based billing**: Upgrade for higher limits when needed

```bash
# Get your key from https://aistudio.google.com/apikey
export GEMINI_API_KEY=&quot;YOUR_API_KEY&quot;
gemini
```

### Option 3: Vertex AI

**‚ú® Best for:** Enterprise teams and production workloads

**Benefits:**

- **Enterprise features**: Advanced security and compliance
- **Scalable**: Higher rate limits with billing account
- **Integration**: Works with existing Google Cloud infrastructure

```bash
# Get your key from Google Cloud Console
export GOOGLE_API_KEY=&quot;YOUR_API_KEY&quot;
export GOOGLE_GENAI_USE_VERTEXAI=true
gemini
```

For Google Workspace accounts and other authentication methods, see the [authentication guide](./docs/cli/authentication.md).

## üöÄ Getting Started

### Basic Usage

#### Start in current directory

```bash
gemini
```

#### Include multiple directories

```bash
gemini --include-directories ../lib,../docs
```

#### Use specific model

```bash
gemini -m gemini-2.5-flash
```

#### Non-interactive mode for scripts

Get a simple text response:

```bash
gemini -p &quot;Explain the architecture of this codebase&quot;
```

For more advanced scripting, including how to parse JSON and handle errors, use
the `--output-format json` flag to get structured output:

```bash
gemini -p &quot;Explain the architecture of this codebase&quot; --output-format json
```

### Quick Examples

#### Start a new project

```bash
cd new-project/
gemini
&gt; Write me a Discord bot that answers questions using a FAQ.md file I will provide
```

#### Analyze existing code

```bash
git clone https://github.com/google-gemini/gemini-cli
cd gemini-cli
gemini
&gt; Give me a summary of all of the changes that went in yesterday
```

## üìö Documentation

### Getting Started

- [**Quickstart Guide**](./docs/cli/index.md) - Get up and running quickly
- [**Authentication Setup**](./docs/cli/authentication.md) - Detailed auth configuration
- [**Configuration Guide**](./docs/cli/configuration.md) - Settings and customization
- [**Keyboard Shortcuts**](./docs/keyboard-shortcuts.md) - Productivity tips

### Core Features

- [**Commands Reference**](./docs/cli/commands.md) - All slash commands (`/help`, `/chat`, `/mcp`, etc.)
- [**Checkpointing**](./docs/checkpointing.md) - Save and resume conversations
- [**Memory Management**](./docs/tools/memory.md) - Using GEMINI.md context files
- [**Token Caching**](./docs/cli/token-caching.md) - Optimize token usage

### Tools &amp; Extensions

- [**Built-in Tools Overview**](./docs/tools/index.md)
  - [File System Operations](./docs/tools/file-system.md)
  - [Shell Commands](./docs/tools/shell.md)
  - [Web Fetch &amp; Search](./docs/tools/web-fetch.md)
  - [Multi-file Operations](./docs/tools/multi-file.md)
- [**MCP Server Integration**](./docs/tools/mcp-server.md) - Extend with custom tools
- [**Custom Extensions**](./docs/extension.md) - Build your own commands

### Advanced Topics

- [**Architecture Overview**](./docs/architecture.md) - How Gemini CLI works
- [**IDE Integration**](./docs/ide-integration.md) - VS Code companion
- [**Sandboxing &amp; Security**](./docs/sandbox.md) - Safe execution environments
- [**Enterprise Deployment**](./docs/deployment.md) - Docker, system-wide config
- [**Telemetry &amp; Monitoring**](./docs/telemetry.md) - Usage tracking
- [**Tools API Development**](./docs/core/tools-api.md) - Create custom tools

### Configuration &amp; Customization

- [**Settings Reference**](./docs/cli/configuration.md) - All configuration options
- [**Theme Customization**](./docs/cli/themes.md) - Visual customization
- [**.gemini Directory**](./docs/gemini-ignore.md) - Project-specific settings
- [**Environment Variables**](./docs/cli/configuration.md#environment-variables)

### Troubleshooting &amp; Support

- [**Troubleshooting Guide**](./docs/troubleshooting.md) - Common issues and solutions
- [**FAQ**](./docs/troubleshooting.md#frequently-asked-questions) - Quick answers
- Use `/bug` command to report issues directly from the CLI

### Using MCP Servers

Configure MCP servers in `~/.gemini/settings.json` to extend Gemini CLI with custom tools:

```text
&gt; @github List my open pull requests
&gt; @slack Send a summary of today&#039;s commits to #dev channel
&gt; @database Run a query to find inactive users
```

See the [MCP Server Integration guide](./docs/tools/mcp-server.md) for setup instructions.

## ü§ù Contributing

We welcome contributions! Gemini CLI is fully open source (Apache 2.0), and we encourage the community to:

- Report bugs and suggest features
- Improve documentation
- Submit code improvements
- Share your MCP servers and extensions

See our [Contributing Guide](./CONTRIBUTING.md) for development setup, coding standards, and how to submit pull requests.

Check our [Official Roadmap](https://github.com/orgs/google-gemini/projects/11/) for planned features and priorities.

## üìñ Resources

- **[Official Roadmap](./ROADMAP.md)** - See what&#039;s coming next
- **[NPM Package](https://www.npmjs.com/package/@google/gemini-cli)** - Package registry
- **[GitHub Issues](https://github.com/google-gemini/gemini-cli/issues)** - Report bugs or request features
- **[Security Advisories](https://github.com/google-gemini/gemini-cli/security/advisories)** - Security updates

### Uninstall

See the [Uninstall Guide](docs/Uninstall.md) for removal instructions.

## üìÑ Legal

- **License**: [Apache License 2.0](LICENSE)
- **Terms of Service**: [Terms &amp; Privacy](./docs/tos-privacy.md)
- **Security**: [Security Policy](SECURITY.md)

---

&lt;p align=&quot;center&quot;&gt;
  Built with ‚ù§Ô∏è by Google and the open source community
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[langfuse/langfuse]]></title>
            <link>https://github.com/langfuse/langfuse</link>
            <guid>https://github.com/langfuse/langfuse</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:40 GMT</pubDate>
            <description><![CDATA[ü™¢ Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with OpenTelemetry, Langchain, OpenAI SDK, LiteLLM, and more. üçäYC W23]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langfuse/langfuse">langfuse/langfuse</a></h1>
            <p>ü™¢ Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with OpenTelemetry, Langchain, OpenAI SDK, LiteLLM, and more. üçäYC W23</p>
            <p>Language: TypeScript</p>
            <p>Stars: 16,566</p>
            <p>Forks: 1,550</p>
            <p>Stars today: 48 stars today</p>
            <h2>README</h2><pre>&lt;img width=&quot;4856&quot; height=&quot;1000&quot; alt=&quot;github-banner&quot; src=&quot;https://github.com/user-attachments/assets/6f435ef3-1194-4e26-87af-aa13826bbb5f&quot; /&gt;

&lt;div align=&quot;center&quot;&gt;
   &lt;div&gt;
      &lt;h3&gt;
        &lt;a href=&quot;https://langfuse.com/blog/2025-06-04-open-sourcing-langfuse-product&quot;&gt;
            &lt;strong&gt;Langfuse Is Doubling Down On Open Source&lt;/strong&gt;
         &lt;/a&gt; &lt;br&gt; &lt;br&gt;
         &lt;a href=&quot;https://cloud.langfuse.com&quot;&gt;
            &lt;strong&gt;Langfuse Cloud&lt;/strong&gt;
         &lt;/a&gt; ¬∑ 
         &lt;a href=&quot;https://langfuse.com/docs/deployment/self-host&quot;&gt;
            &lt;strong&gt;Self Host&lt;/strong&gt;
         &lt;/a&gt; ¬∑ 
         &lt;a href=&quot;https://langfuse.com/demo&quot;&gt;
            &lt;strong&gt;Demo&lt;/strong&gt;
         &lt;/a&gt;
      &lt;/h3&gt;
   &lt;/div&gt;

   &lt;div&gt;
      &lt;a href=&quot;https://langfuse.com/docs&quot;&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/a&gt; ¬∑
      &lt;a href=&quot;https://langfuse.com/issues&quot;&gt;&lt;strong&gt;Report Bug&lt;/strong&gt;&lt;/a&gt; ¬∑
      &lt;a href=&quot;https://langfuse.com/ideas&quot;&gt;&lt;strong&gt;Feature Request&lt;/strong&gt;&lt;/a&gt; ¬∑
      &lt;a href=&quot;https://langfuse.com/changelog&quot;&gt;&lt;strong&gt;Changelog&lt;/strong&gt;&lt;/a&gt; ¬∑
      &lt;a href=&quot;https://langfuse.com/roadmap&quot;&gt;&lt;strong&gt;Roadmap&lt;/strong&gt;&lt;/a&gt; ¬∑
   &lt;/div&gt;
   &lt;br/&gt;
   &lt;span&gt;Langfuse uses &lt;a href=&quot;https://github.com/orgs/langfuse/discussions&quot;&gt;&lt;strong&gt;GitHub Discussions&lt;/strong&gt;&lt;/a&gt;  for Support and Feature Requests.&lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;&lt;b&gt;We&#039;re hiring.&lt;/b&gt; &lt;a href=&quot;https://langfuse.com/careers&quot;&gt;&lt;strong&gt;Join us&lt;/strong&gt;&lt;/a&gt; in product engineering and technical go-to-market roles.&lt;/span&gt;
   &lt;br/&gt;
   &lt;br/&gt;
   &lt;div&gt;
   &lt;/div&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
   &lt;a href=&quot;https://github.com/langfuse/langfuse/blob/main/LICENSE&quot;&gt;
   &lt;img src=&quot;https://img.shields.io/badge/License-MIT-E11311.svg&quot; alt=&quot;MIT License&quot;&gt;
   &lt;/a&gt;
   &lt;a href=&quot;https://www.ycombinator.com/companies/langfuse&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Y%20Combinator-W23-orange&quot; alt=&quot;Y Combinator W23&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://hub.docker.com/u/langfuse&quot; target=&quot;_blank&quot;&gt;
   &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/langfuse/langfuse?labelColor=%20%23FDB062&amp;logo=Docker&amp;labelColor=%20%23528bff&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://pypi.python.org/pypi/langfuse&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/dm/langfuse?logo=python&amp;logoColor=white&amp;label=pypi%20langfuse&amp;color=blue&quot; alt=&quot;langfuse Python package on PyPi&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://www.npmjs.com/package/langfuse&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/langfuse?logo=npm&amp;logoColor=white&amp;label=npm%20langfuse&amp;color=blue&quot; alt=&quot;langfuse npm package&quot;&gt;&lt;/a&gt;
   &lt;br/&gt;
   &lt;a href=&quot;https://discord.com/invite/7NXusRtqYU&quot; target=&quot;_blank&quot;&gt;
   &lt;img src=&quot;https://img.shields.io/discord/1111061815649124414?logo=discord&amp;labelColor=%20%235462eb&amp;logoColor=%20%23f5f5f5&amp;color=%20%235462eb&quot;
      alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=langfuse&quot; target=&quot;_blank&quot;&gt;
   &lt;img src=&quot;https://img.shields.io/twitter/follow/langfuse?logo=X&amp;color=%20%23f5f5f5&quot;
      alt=&quot;follow on X(Twitter)&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://www.linkedin.com/company/langfuse/&quot; target=&quot;_blank&quot;&gt;
   &lt;img src=&quot;https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;logoColor=fff&quot;
      alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://github.com/langfuse/langfuse/graphs/commit-activity&quot; target=&quot;_blank&quot;&gt;
   &lt;img alt=&quot;Commits last month&quot; src=&quot;https://img.shields.io/github/commit-activity/m/langfuse/langfuse?labelColor=%20%2332b583&amp;color=%20%2312b76a&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://github.com/langfuse/langfuse/&quot; target=&quot;_blank&quot;&gt;
   &lt;img alt=&quot;Issues closed&quot; src=&quot;https://img.shields.io/github/issues-search?query=repo%3Alangfuse%2Flangfuse%20is%3Aclosed&amp;label=issues%20closed&amp;labelColor=%20%237d89b0&amp;color=%20%235d6b98&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://github.com/langfuse/langfuse/discussions/&quot; target=&quot;_blank&quot;&gt;
   &lt;img alt=&quot;Discussion posts&quot; src=&quot;https://img.shields.io/github/discussions/langfuse/langfuse?labelColor=%20%239b8afb&amp;color=%20%237a5af8&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README.cn.md&quot;&gt;&lt;img alt=&quot;ÁÆÄ‰Ωì‰∏≠ÊñáÁâàËá™Ëø∞Êñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README.ja.md&quot;&gt;&lt;img alt=&quot;Êó•Êú¨Ë™û„ÅÆREADME&quot; src=&quot;https://img.shields.io/badge/Êó•Êú¨Ë™û-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README.kr.md&quot;&gt;&lt;img alt=&quot;README in Korean&quot; src=&quot;https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-d9d9d9&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Langfuse is an **open source LLM engineering** platform. It helps teams collaboratively
**develop, monitor, evaluate,** and **debug** AI applications. Langfuse can be **self-hosted in minutes** and is **battle-tested**.

[![Langfuse Overview Video](https://github.com/user-attachments/assets/3926b288-ff61-4b95-8aa1-45d041c70866)](https://langfuse.com/watch-demo)

## ‚ú® Core Features

&lt;img width=&quot;4856&quot; height=&quot;1944&quot; alt=&quot;Langfuse Overview&quot; src=&quot;https://github.com/user-attachments/assets/5dac68ef-d546-49fb-b06f-cfafc19282e3&quot; /&gt;

- [LLM Application Observability](https://langfuse.com/docs/tracing): Instrument your app and start ingesting traces to Langfuse, thereby tracking LLM calls and other relevant logic in your app such as retrieval, embedding, or agent actions. Inspect and debug complex logs and user sessions. Try the interactive [demo](https://langfuse.com/docs/demo) to see this in action.

- [Prompt Management](https://langfuse.com/docs/prompt-management/get-started) helps you centrally manage, version control, and collaboratively iterate on your prompts. Thanks to strong caching on server and client side, you can iterate on prompts without adding latency to your application.

- [Evaluations](https://langfuse.com/docs/evaluation/overview) are key to the LLM application development workflow, and Langfuse adapts to your needs. It supports LLM-as-a-judge, user feedback collection, manual labeling, and custom evaluation pipelines via APIs/SDKs.

- [Datasets](https://langfuse.com/docs/evaluation/dataset-runs/datasets) enable test sets and benchmarks for evaluating your LLM application. They support continuous improvement, pre-deployment testing, structured experiments, flexible evaluation, and seamless integration with frameworks like LangChain and LlamaIndex.

- [LLM Playground](https://langfuse.com/docs/playground) is a tool for testing and iterating on your prompts and model configurations, shortening the feedback loop and accelerating development. When you see a bad result in tracing, you can directly jump to the playground to iterate on it.

- [Comprehensive API](https://langfuse.com/docs/api): Langfuse is frequently used to power bespoke LLMOps workflows while using the building blocks provided by Langfuse via the API. OpenAPI spec, Postman collection, and typed SDKs for Python, JS/TS are available.

## üì¶ Deploy Langfuse

&lt;img width=&quot;4856&quot; height=&quot;1322&quot; alt=&quot;Langfuse Deployment Options&quot; src=&quot;https://github.com/user-attachments/assets/98f020c7-7a20-4264-a201-65c41a52a5d5&quot; /&gt;

### Langfuse Cloud

Managed deployment by the Langfuse team, generous free-tier, no credit card required.

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://cloud.langfuse.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/¬ª%20Sign%20up%20for%20Langfuse%20Cloud-8A2BE2?&amp;color=orange&quot;&gt;
    &lt;/a&gt;
&lt;/div&gt;

### Self-Host Langfuse

Run Langfuse on your own infrastructure:

- [Local (docker compose)](https://langfuse.com/self-hosting/local): Run Langfuse on your own machine in 5 minutes using Docker Compose.

  ```bash
  # Get a copy of the latest Langfuse repository
  git clone https://github.com/langfuse/langfuse.git
  cd langfuse

  # Run the langfuse docker compose
  docker compose up
  ```

- [VM](https://langfuse.com/self-hosting/docker-compose): Run Langfuse on a single Virtual Machine using Docker Compose.
- [Kubernetes (Helm)](https://langfuse.com/self-hosting/kubernetes-helm): Run Langfuse on a Kubernetes cluster using Helm. This is the preferred production deployment.
- Terraform Templates: [AWS](https://langfuse.com/self-hosting/aws), [Azure](https://langfuse.com/self-hosting/azure), [GCP](https://langfuse.com/self-hosting/gcp)

See [self-hosting documentation](https://langfuse.com/self-hosting) to learn more about architecture and configuration options.

## üîå Integrations

&lt;img width=&quot;4856&quot; height=&quot;1322&quot; alt=&quot;github-integrations&quot; src=&quot;https://github.com/user-attachments/assets/e41ea0fb-742d-41ce-bf94-1d4fb95750cd&quot; /&gt;

### Main Integrations:

| Integration                                                                  | Supports                   | Description                                                                                                                                      |
| ---------------------------------------------------------------------------- | -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| [SDK](https://langfuse.com/docs/sdk)                                         | Python, JS/TS              | Manual instrumentation using the SDKs for full flexibility.                                                                                      |
| [OpenAI](https://langfuse.com/integrations/model-providers/openai-py)        | Python, JS/TS              | Automated instrumentation using drop-in replacement of OpenAI SDK.                                                                               |
| [Langchain](https://langfuse.com/docs/integrations/langchain)                | Python, JS/TS              | Automated instrumentation by passing callback handler to Langchain application.                                                                  |
| [LlamaIndex](https://langfuse.com/docs/integrations/llama-index/get-started) | Python                     | Automated instrumentation via LlamaIndex callback system.                                                                                        |
| [Haystack](https://langfuse.com/docs/integrations/haystack)                  | Python                     | Automated instrumentation via Haystack content tracing system.                                                                                   |
| [LiteLLM](https://langfuse.com/docs/integrations/litellm)                    | Python, JS/TS (proxy only) | Use any LLM as a drop in replacement for GPT. Use Azure, OpenAI, Cohere, Anthropic, Ollama, VLLM, Sagemaker, HuggingFace, Replicate (100+ LLMs). |
| [Vercel AI SDK](https://langfuse.com/docs/integrations/vercel-ai-sdk)        | JS/TS                      | TypeScript toolkit designed to help developers build AI-powered applications with React, Next.js, Vue, Svelte, Node.js.                          |
| [API](https://langfuse.com/docs/api)                                         |                            | Directly call the public API. OpenAPI spec available.                                                                                            |

### Packages integrated with Langfuse:

| Name                                                                    | Type               | Description                                                                                                             |
| ----------------------------------------------------------------------- | ------------------ | ----------------------------------------------------------------------------------------------------------------------- |
| [Instructor](https://langfuse.com/docs/integrations/instructor)         | Library            | Library to get structured LLM outputs (JSON, Pydantic)                                                                  |
| [DSPy](https://langfuse.com/docs/integrations/dspy)                     | Library            | Framework that systematically optimizes language model prompts and weights                                              |
| [Mirascope](https://langfuse.com/docs/integrations/mirascope)           | Library            | Python toolkit for building LLM applications.                                                                           |
| [Ollama](https://langfuse.com/docs/integrations/ollama)                 | Model (local)      | Easily run open source LLMs on your own machine.                                                                        |
| [Amazon Bedrock](https://langfuse.com/docs/integrations/amazon-bedrock) | Model              | Run foundation and fine-tuned models on AWS.                                                                            |
| [AutoGen](https://langfuse.com/docs/integrations/autogen)               | Agent Framework    | Open source LLM platform for building distributed agents.                                                               |
| [Flowise](https://langfuse.com/docs/integrations/flowise)               | Chat/Agent&amp;nbsp;UI | JS/TS no-code builder for customized LLM flows.                                                                         |
| [Langflow](https://langfuse.com/docs/integrations/langflow)             | Chat/Agent&amp;nbsp;UI | Python-based UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows. |
| [Dify](https://langfuse.com/docs/integrations/dify)                     | Chat/Agent&amp;nbsp;UI | Open source LLM app development platform with no-code builder.                                                          |
| [OpenWebUI](https://langfuse.com/docs/integrations/openwebui)           | Chat/Agent&amp;nbsp;UI | Self-hosted LLM Chat web ui supporting various LLM runners including self-hosted and local models.                      |
| [Promptfoo](https://langfuse.com/docs/integrations/promptfoo)           | Tool               | Open source LLM testing platform.                                                                                       |
| [LobeChat](https://langfuse.com/docs/integrations/lobechat)             | Chat/Agent&amp;nbsp;UI | Open source chatbot platform.                                                                                           |
| [Vapi](https://langfuse.com/docs/integrations/vapi)                     | Platform           | Open source voice AI platform.                                                                                          |
| [Inferable](https://langfuse.com/docs/integrations/other/inferable)     | Agents             | Open source LLM platform for building distributed agents.                                                               |
| [Gradio](https://langfuse.com/docs/integrations/other/gradio)           | Chat/Agent&amp;nbsp;UI | Open source Python library to build web interfaces like Chat UI.                                                        |
| [Goose](https://langfuse.com/docs/integrations/goose)                   | Agents             | Open source LLM platform for building distributed agents.                                                               |
| [smolagents](https://langfuse.com/docs/integrations/smolagents)         | Agents             | Open source AI agents framework.                                                                                        |
| [CrewAI](https://langfuse.com/docs/integrations/crewai)                 | Agents             | Multi agent framework for agent collaboration and tool use.                                                             |

## üöÄ Quickstart

Instrument your app and start ingesting traces to Langfuse, thereby tracking LLM calls and other relevant logic in your app such as retrieval, embedding, or agent actions. Inspect and debug complex logs and user sessions.

### 1Ô∏è‚É£ Create new project

1.  [Create Langfuse account](https://cloud.langfuse.com/auth/sign-up) or [self-host](https://langfuse.com/self-hosting)
2.  Create a new project
3.  Create new API credentials in the project settings

### 2Ô∏è‚É£ Log your first LLM call

The [`@observe()` decorator](https://langfuse.com/docs/sdk/python/decorators) makes it easy to trace any Python LLM application. In this quickstart we also use the Langfuse [OpenAI integration](https://langfuse.com/integrations/model-providers/openai-py) to automatically capture all model parameters.

&gt; [!TIP]
&gt; Not using OpenAI? Visit [our documentation](https://langfuse.com/docs/get-started#log-your-first-llm-call-to-langfuse) to learn how to log other models and frameworks.

```bash
pip install langfuse openai
```

```bash filename=&quot;.env&quot;
LANGFUSE_SECRET_KEY=&quot;sk-lf-...&quot;
LANGFUSE_PUBLIC_KEY=&quot;pk-lf-...&quot;
LANGFUSE_HOST=&quot;https://cloud.langfuse.com&quot; # üá™üá∫ EU region
# LANGFUSE_HOST=&quot;https://us.cloud.langfuse.com&quot; # üá∫üá∏ US region
```

```python /@observe()/ /from langfuse.openai import openai/ filename=&quot;main.py&quot;
from langfuse import observe
from langfuse.openai import openai # OpenAI integration

@observe()
def story():
    return openai.chat.completions.create(
        model=&quot;gpt-4o&quot;,
        messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is Langfuse?&quot;}],
    ).choices[0].message.content

@observe()
def main():
    return story()

main()
```

### 3Ô∏è‚É£ See traces in Langfuse

See your language model calls and other application logic in Langfuse.

&lt;img width=&quot;1787&quot; height=&quot;674&quot; alt=&quot;Example trace in Langfuse&quot; src=&quot;https://github.com/user-attachments/assets/f796eb78-dfb5-4570-b236-bdb4b67d4d55&quot; /&gt;

_[Public example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/2cec01e3-3dc2-472f-afcf-3b968cf0c1f4?timestamp=2025-02-10T14%3A27%3A30.275Z&amp;observation=cb5ff844-07ef-41e6-b8e2-6c64344bc13b)_

&gt; [!TIP]
&gt;
&gt; [Learn more](https://langfuse.com/docs/tracing) about tracing in Langfuse or play with the [interactive demo](https://langfuse.com/docs/demo).

## ‚≠êÔ∏è Star Us

![star-langfuse-on-github](https://github.com/user-attachments/assets/79a1d816-d229-4526-aecc-097d4a19f1ad)

## üí≠ Support

Finding an answer to your question:

- Our [documentation](https://langfuse.com/docs) is the best place to start looking for answers. It is comprehensive, and we invest significant time into maintaining it. You can also suggest edits to the docs via GitHub.
- [Langfuse FAQs](https://langfuse.com/faq) where the most common questions are answered.
- Use &quot;[Ask AI](https://langfuse.com/docs/ask-ai)&quot; to get instant answers to your questions.

Support Channels:

- **Ask any question in our [public Q&amp;A](https://github.com/orgs/langfuse/discussions/categories/support) on GitHub Discussions.** Please include as much detail as possible (e.g. code snippets, screenshots, background information) to help us understand your question.
- [Request a feature](https://github.com/orgs/langfuse/discussions/categories/ideas) on GitHub Discussions.
- [Report a Bug](https://github.com/langfuse/langfuse/issues) on GitHub Issues.
- For time-sensitive queries, ping us via the in-app chat widget.

## ü§ù Contributing

Your contributions are welcome!

- Vote on [Ideas](https://github.com/orgs/langfuse/discussions/categories/ideas) in GitHub Discussions.
- Raise and comment on [Issues](https://github.com/langfuse/langfuse/issues).
- Open a PR - see [CONTRIBUTING.md](CONTRIBUTING.md) for details on how to setup a development environment.

## ü•á License

This repository is MIT licensed, except for the `ee` folders. See [LICENSE](LICENSE) and [docs](https://langfuse.com/docs/open-source) for more details.

## ‚≠êÔ∏è Star History

&lt;a href=&quot;https://star-history.com/#langfuse/langfuse&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=langfuse/langfuse&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=langfuse/langfuse&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=langfuse/langfuse&amp;type=Date&quot; style=&quot;border-radius: 15px;&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## ‚ù§Ô∏è Open Source Projects Using Langfuse

Top open-source Python projects that use Langfuse, ranked by stars ([Source](https://github.com/langfuse/langfuse-docs/blob/main/components-mdx/dependents)):

| Repository      

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[n8n-io/n8n]]></title>
            <link>https://github.com/n8n-io/n8n</link>
            <guid>https://github.com/n8n-io/n8n</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:39 GMT</pubDate>
            <description><![CDATA[Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/n8n-io/n8n">n8n-io/n8n</a></h1>
            <p>Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 141,027</p>
            <p>Forks: 45,133</p>
            <p>Stars today: 306 stars today</p>
            <h2>README</h2><pre>![Banner image](https://user-images.githubusercontent.com/10284570/173569848-c624317f-42b1-45a6-ab09-f0ea3c247648.png)

# n8n - Secure Workflow Automation for Technical Teams

n8n is a workflow automation platform that gives technical teams the flexibility of code with the speed of no-code. With 400+ integrations, native AI capabilities, and a fair-code license, n8n lets you build powerful automations while maintaining full control over your data and deployments.

![n8n.io - Screenshot](https://raw.githubusercontent.com/n8n-io/n8n/master/assets/n8n-screenshot-readme.png)

## Key Capabilities

- **Code When You Need It**: Write JavaScript/Python, add npm packages, or use the visual interface
- **AI-Native Platform**: Build AI agent workflows based on LangChain with your own data and models
- **Full Control**: Self-host with our fair-code license or use our [cloud offering](https://app.n8n.cloud/login)
- **Enterprise-Ready**: Advanced permissions, SSO, and air-gapped deployments
- **Active Community**: 400+ integrations and 900+ ready-to-use [templates](https://n8n.io/workflows)

## Quick Start

Try n8n instantly with [npx](https://docs.n8n.io/hosting/installation/npm/) (requires [Node.js](https://nodejs.org/en/)):

```
npx n8n
```

Or deploy with [Docker](https://docs.n8n.io/hosting/installation/docker/):

```
docker volume create n8n_data
docker run -it --rm --name n8n -p 5678:5678 -v n8n_data:/home/node/.n8n docker.n8n.io/n8nio/n8n
```

Access the editor at http://localhost:5678

## Resources

- üìö [Documentation](https://docs.n8n.io)
- üîß [400+ Integrations](https://n8n.io/integrations)
- üí° [Example Workflows](https://n8n.io/workflows)
- ü§ñ [AI &amp; LangChain Guide](https://docs.n8n.io/langchain/)
- üë• [Community Forum](https://community.n8n.io)
- üìñ [Community Tutorials](https://community.n8n.io/c/tutorials/28)

## Support

Need help? Our community forum is the place to get support and connect with other users:
[community.n8n.io](https://community.n8n.io)

## License

n8n is [fair-code](https://faircode.io) distributed under the [Sustainable Use License](https://github.com/n8n-io/n8n/blob/master/LICENSE.md) and [n8n Enterprise License](https://github.com/n8n-io/n8n/blob/master/LICENSE_EE.md).

- **Source Available**: Always visible source code
- **Self-Hostable**: Deploy anywhere
- **Extensible**: Add your own nodes and functionality

[Enterprise licenses](mailto:license@n8n.io) available for additional features and support.

Additional information about the license model can be found in the [docs](https://docs.n8n.io/reference/license/).

## Contributing

Found a bug üêõ or have a feature idea ‚ú®? Check our [Contributing Guide](https://github.com/n8n-io/n8n/blob/master/CONTRIBUTING.md) to get started.

## Join the Team

Want to shape the future of automation? Check out our [job posts](https://n8n.io/careers) and join our team!

## What does n8n mean?

**Short answer:** It means &quot;nodemation&quot; and is pronounced as n-eight-n.

**Long answer:** &quot;I get that question quite often (more often than I expected) so I decided it is probably best to answer it here. While looking for a good name for the project with a free domain I realized very quickly that all the good ones I could think of were already taken. So, in the end, I chose nodemation. &#039;node-&#039; in the sense that it uses a Node-View and that it uses Node.js and &#039;-mation&#039; for &#039;automation&#039; which is what the project is supposed to help with. However, I did not like how long the name was and I could not imagine writing something that long every time in the CLI. That is when I then ended up on &#039;n8n&#039;.&quot; - **Jan Oberhauser, Founder and CEO, n8n.io**
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[langgenius/dify]]></title>
            <link>https://github.com/langgenius/dify</link>
            <guid>https://github.com/langgenius/dify</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:38 GMT</pubDate>
            <description><![CDATA[Production-ready platform for agentic workflow development.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langgenius/dify">langgenius/dify</a></h1>
            <p>Production-ready platform for agentic workflow development.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 115,074</p>
            <p>Forks: 17,727</p>
            <p>Stars today: 114 stars today</p>
            <h2>README</h2><pre>![cover-v5-optimized](./images/GitHub_README_if.png)

&lt;p align=&quot;center&quot;&gt;
  üìå &lt;a href=&quot;https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast&quot;&gt;Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cloud.dify.ai&quot;&gt;Dify Cloud&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted&quot;&gt;Self-hosting&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://docs.dify.ai&quot;&gt;Documentation&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://dify.ai/pricing&quot;&gt;Dify edition overview&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://dify.ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Product-F04438&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://dify.ai/pricing&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/free-pricing?logo=free&amp;color=%20%23155EEF&amp;label=pricing&amp;labelColor=%20%23528bff&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/FngNHpbcY7&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1082486657678311454?logo=discord&amp;labelColor=%20%235462eb&amp;logoColor=%20%23f5f5f5&amp;color=%20%235462eb&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://reddit.com/r/difyai&quot; target=&quot;_blank&quot;&gt;  
        &lt;img src=&quot;https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&amp;logo=reddit&amp;label=r%2Fdifyai&amp;labelColor=white&quot;
            alt=&quot;join Reddit&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=dify_ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/dify_ai?logo=X&amp;color=%20%23f5f5f5&quot;
            alt=&quot;follow on X(Twitter)&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/langgenius/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;logoColor=fff&quot;
            alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/u/langgenius&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&amp;color=%20%23f79009&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/graphs/commit-activity&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Commits last month&quot; src=&quot;https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&amp;color=%20%2312b76a&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Issues closed&quot; src=&quot;https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&amp;label=issues%20closed&amp;labelColor=%20%237d89b0&amp;color=%20%235d6b98&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/discussions/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Discussion posts&quot; src=&quot;https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&amp;color=%20%237a5af8&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_TW.md&quot;&gt;&lt;img alt=&quot;ÁπÅÈ´î‰∏≠ÊñáÊñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁπÅÈ´î‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_CN.md&quot;&gt;&lt;img alt=&quot;ÁÆÄ‰Ωì‰∏≠ÊñáÁâàËá™Ëø∞Êñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_JA.md&quot;&gt;&lt;img alt=&quot;Êó•Êú¨Ë™û„ÅÆREADME&quot; src=&quot;https://img.shields.io/badge/Êó•Êú¨Ë™û-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_ES.md&quot;&gt;&lt;img alt=&quot;README en Espa√±ol&quot; src=&quot;https://img.shields.io/badge/Espa√±ol-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_FR.md&quot;&gt;&lt;img alt=&quot;README en Fran√ßais&quot; src=&quot;https://img.shields.io/badge/Fran√ßais-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_KL.md&quot;&gt;&lt;img alt=&quot;README tlhIngan Hol&quot; src=&quot;https://img.shields.io/badge/Klingon-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_KR.md&quot;&gt;&lt;img alt=&quot;README in Korean&quot; src=&quot;https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_AR.md&quot;&gt;&lt;img alt=&quot;README ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&quot; src=&quot;https://img.shields.io/badge/ÿßŸÑÿπÿ±ÿ®Ÿäÿ©-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_TR.md&quot;&gt;&lt;img alt=&quot;T√ºrk√ße README&quot; src=&quot;https://img.shields.io/badge/T√ºrk√ße-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_VI.md&quot;&gt;&lt;img alt=&quot;README Ti·∫øng Vi·ªát&quot; src=&quot;https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_DE.md&quot;&gt;&lt;img alt=&quot;README in Deutsch&quot; src=&quot;https://img.shields.io/badge/German-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_BN.md&quot;&gt;&lt;img alt=&quot;README in ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&quot; src=&quot;https://img.shields.io/badge/‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ-d9d9d9&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Dify is an open-source platform for developing LLM applications. Its intuitive interface combines agentic AI workflows, RAG pipelines, agent capabilities, model management, observability features, and more‚Äîallowing you to quickly move from prototype to production.

## Quick start

&gt; Before installing Dify, make sure your machine meets the following minimum system requirements:
&gt;
&gt; - CPU &gt;= 2 Core
&gt; - RAM &gt;= 4 GiB

&lt;/br&gt;

The easiest way to start the Dify server is through [Docker Compose](docker/docker-compose.yaml). Before running Dify with the following commands, make sure that [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) are installed on your machine:

```bash
cd dify
cd docker
cp .env.example .env
docker compose up -d
```

After running, you can access the Dify dashboard in your browser at [http://localhost/install](http://localhost/install) and start the initialization process.

#### Seeking help

Please refer to our [FAQ](https://docs.dify.ai/getting-started/install-self-hosted/faqs) if you encounter problems setting up Dify. Reach out to [the community and us](#community--contact) if you are still having issues.

&gt; If you&#039;d like to contribute to Dify or do additional development, refer to our [guide to deploying from source code](https://docs.dify.ai/getting-started/install-self-hosted/local-source-code)

## Key features

**1. Workflow**:
Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.

**2. Comprehensive model support**:
Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found [here](https://docs.dify.ai/getting-started/readme/model-providers).

![providers-v5](https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3)

**3. Prompt IDE**:
Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.

**4. RAG Pipeline**:
Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.

**5. Agent capabilities**:
You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALL¬∑E, Stable Diffusion and WolframAlpha.

**6. LLMOps**:
Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.

**7. Backend-as-a-Service**:
All of Dify&#039;s offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.

## Using Dify

- **Cloud &lt;/br&gt;**
  We host a [Dify Cloud](https://dify.ai) service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.

- **Self-hosting Dify Community Edition&lt;/br&gt;**
  Quickly get Dify running in your environment with this [starter guide](#quick-start).
  Use our [documentation](https://docs.dify.ai) for further references and more in-depth instructions.

- **Dify for enterprise / organizations&lt;/br&gt;**
  We provide additional enterprise-centric features. [Log your questions for us through this chatbot](https://udify.app/chat/22L1zSxg6yW1cWQg) or [send us an email](mailto:business@dify.ai?subject=%5BGitHub%5DBusiness%20License%20Inquiry) to discuss enterprise needs. &lt;/br&gt;

  &gt; For startups and small businesses using AWS, check out [Dify Premium on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6) and deploy it to your own AWS VPC with one click. It&#039;s an affordable AMI offering with the option to create apps with custom logo and branding.

## Staying ahead

Star Dify on GitHub and be instantly notified of new releases.

![star-us](https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4)

## Advanced Setup

If you need to customize the configuration, please refer to the comments in our [.env.example](docker/.env.example) file and update the corresponding values in your `.env` file. Additionally, you might need to make adjustments to the `docker-compose.yaml` file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run `docker-compose up -d`. You can find the full list of available environment variables [here](https://docs.dify.ai/getting-started/install-self-hosted/environments).

If you&#039;d like to configure a highly-available setup, there are community-contributed [Helm Charts](https://helm.sh/) and YAML files which allow Dify to be deployed on Kubernetes.

- [Helm Chart by @LeoQuote](https://github.com/douban/charts/tree/master/charts/dify)
- [Helm Chart by @BorisPolonsky](https://github.com/BorisPolonsky/dify-helm)
- [Helm Chart by @magicsong](https://github.com/magicsong/ai-charts)
- [YAML file by @Winson-030](https://github.com/Winson-030/dify-kubernetes)
- [YAML file by @wyy-holding](https://github.com/wyy-holding/dify-k8s)
- [üöÄ NEW! YAML files (Supports Dify v1.6.0) by @Zhoneym](https://github.com/Zhoneym/DifyAI-Kubernetes)

#### Using Terraform for Deployment

Deploy Dify to Cloud Platform with a single click using [terraform](https://www.terraform.io/)

##### Azure Global

- [Azure Terraform by @nikawang](https://github.com/nikawang/dify-azure-terraform)

##### Google Cloud

- [Google Cloud Terraform by @sotazum](https://github.com/DeNA/dify-google-cloud-terraform)

#### Using AWS CDK for Deployment

Deploy Dify to AWS with [CDK](https://aws.amazon.com/cdk/)

##### AWS

- [AWS CDK by @KevinZhao (EKS based)](https://github.com/aws-samples/solution-for-deploying-dify-on-aws)
- [AWS CDK by @tmokmss (ECS based)](https://github.com/aws-samples/dify-self-hosted-on-aws)

#### Using Alibaba Cloud Computing Nest

Quickly deploy Dify to Alibaba cloud with [Alibaba Cloud Computing Nest](https://computenest.console.aliyun.com/service/instance/create/default?type=user&amp;ServiceName=Dify%E7%A4%BE%E5%8C%BA%E7%89%88)

#### Using Alibaba Cloud Data Management

One-Click deploy Dify to Alibaba Cloud with [Alibaba Cloud Data Management](https://www.alibabacloud.com/help/en/dms/dify-in-invitational-preview/)

#### Deploy to AKS with Azure Devops Pipeline

One-Click deploy Dify to AKS with [Azure Devops Pipeline Helm Chart by @LeoZhang](https://github.com/Ruiruiz30/Dify-helm-chart-AKS)

## Contributing

For those who&#039;d like to contribute code, see our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.

&gt; We are looking for contributors to help translate Dify into languages other than Mandarin or English. If you are interested in helping, please see the [i18n README](https://github.com/langgenius/dify/blob/main/web/i18n-config/README.md) for more information, and leave us a comment in the `global-users` channel of our [Discord Community Server](https://discord.gg/8Tpq4AcN9c).

## Community &amp; contact

- [GitHub Discussion](https://github.com/langgenius/dify/discussions). Best for: sharing feedback and asking questions.
- [GitHub Issues](https://github.com/langgenius/dify/issues). Best for: bugs you encounter using Dify.AI, and feature proposals. See our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
- [Discord](https://discord.gg/FngNHpbcY7). Best for: sharing your applications and hanging out with the community.
- [X(Twitter)](https://twitter.com/dify_ai). Best for: sharing your applications and hanging out with the community.

**Contributors**

&lt;a href=&quot;https://github.com/langgenius/dify/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=langgenius/dify&quot; /&gt;
&lt;/a&gt;

## Star history

[![Star History Chart](https://api.star-history.com/svg?repos=langgenius/dify&amp;type=Date)](https://star-history.com/#langgenius/dify&amp;Date)

## Security disclosure

To protect your privacy, please avoid posting security issues on GitHub. Instead, report issues to security@dify.ai, and our team will respond with detailed answer.

## License

This repository is licensed under the [Dify Open Source License](LICENSE), based on Apache 2.0 with additional conditions.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[cloudflare/capnweb]]></title>
            <link>https://github.com/cloudflare/capnweb</link>
            <guid>https://github.com/cloudflare/capnweb</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[JavaScript/TypeScript-native, low-boilerplate, object-capability RPC system]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudflare/capnweb">cloudflare/capnweb</a></h1>
            <p>JavaScript/TypeScript-native, low-boilerplate, object-capability RPC system</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,616</p>
            <p>Forks: 77</p>
            <p>Stars today: 218 stars today</p>
            <h2>README</h2><pre># Cap&#039;n Web: A JavaScript-native RPC system

Cap&#039;n Web is a spiritual sibling to [Cap&#039;n Proto](https://capnproto.org) (and is created by the same author), but designed to play nice in the web stack. That means:
* Like Cap&#039;n Proto, it is an object-capability protocol. (&quot;Cap&#039;n&quot; is short for &quot;capabilities and&quot;.) We&#039;ll get into this more below, but it&#039;s incredibly powerful.
* Unlike Cap&#039;n Proto, Cap&#039;n Web has no schemas. In fact, it has almost no boilerplate whatsoever. This means it works more like the [JavaScript-native RPC system in Cloudflare Workers](https://blog.cloudflare.com/javascript-native-rpc/).
* That said, it integrates nicely with TypeScript.
* Also unlike Cap&#039;n Proto, Cap&#039;n Web&#039;s underlying serialization is human-readable. In fact, it&#039;s just JSON, with a little pre-/post-processing.
* It works over HTTP, WebSocket, and postMessage() out-of-the-box, with the ability to extend it to other transports easily.
* It works in all major browsers, Cloudflare Workers, Node.js, and other modern JavaScript runtimes.
The whole thing compresses (minify+gzip) to under 10kB with no dependencies.

Cap&#039;n Web is more expressive than almost every other RPC system, because it implements an object-capability RPC model. That means it:
* Supports bidirectional calling. The client can call the server, and the server can also call the client.
* Supports passing functions by reference: If you pass a function over RPC, the recipient receives a &quot;stub&quot;. When they call the stub, they actually make an RPC back to you, invoking the function where it was created. This is how bidirectional calling happens: the client passes a callback to the server, and then the server can call it later.
* Similarly, supports passing objects by reference: If a class extends the special marker type `RpcTarget`, then instances of that class are passed by reference, with method calls calling back to the location where the object was created.
* Supports promise pipelining. When you start an RPC, you get back a promise. Instead of awaiting it, you can immediately use the promise in dependent RPCs, thus performing a chain of calls in a single network round trip.
* Supports capability-based security patterns.

## Installation

[Cap&#039;n Web is an npm package.](https://www.npmjs.com/package/capnweb)

```
npm i capnweb
```

## Example

A client looks like this:

```js
import { newWebSocketRpcSession } from &quot;capnweb&quot;;

// One-line setup.
let api = newWebSocketRpcSession(&quot;wss://example.com/api&quot;);

// Call a method on the server!
let result = await api.hello(&quot;World&quot;);

console.log(result);
```

Here&#039;s the server:

```js
import { RpcTarget, newWorkersRpcResponse } from &quot;capnweb&quot;;

// This is the server implementation.
class MyApiServer extends RpcTarget {
  hello(name) {
    return `Hello, ${name}!`
  }
}

// Standard Cloudflare Workers HTTP handler.
//
// (Node and other runtimes are supported too; see below.)
export default {
  fetch(request, env, ctx) {
    // Parse URL for routing.
    let url = new URL(request.url);

    // Serve API at `/api`.
    if (url.pathname === &quot;/api&quot;) {
      return newWorkersRpcResponse(request, new MyApiServer());
    }

    // You could serve other endpoints here...
    return new Response(&quot;Not found&quot;, {status: 404});
  }
}
```

### More complicated example

Here&#039;s an example that:
* Uses TypeScript
* Sends multiple calls, where the second call depends on the result of the first, in one round trip.

We declare our interface in a shared types file:

```ts
interface PublicApi {
  // Authenticate the API token, and returned the authenticated API.
  authenticate(apiToken: string): AuthedApi;

  // Get a given user&#039;s public profile info. (Doesn&#039;t require authentication.)
  getUserProfile(userId: string): Promise&lt;UserProfile&gt;;
}

interface AuthedApi {
  getUserId(): number;

  // Get the user IDs of all the user&#039;s friends.
  getFriendIds(): number[];
}

type UserProfile = {
  name: string;
  photoUrl: string;
}
```

(Note: you don&#039;t _have to_ declare your interface separately. The client could just use `import(&quot;./server&quot;).ApiServer` as the type.)

On the server, we implement the interface as an RpcTarget:

```ts
import { newWorkersRpcResponse, RpcTarget } from &quot;capnweb&quot;;

class ApiServer extends RpcTarget implements PublicApi {
  // ... implement PublicApi ...
}

export default {
  async fetch(req, env, ctx) {
    // ... same as previous example ...
  }
}
```

On the client, we can use it in a batch request:

```ts
import { newHttpBatchRpcSession } from &quot;capnweb&quot;;

let api = newHttpBatchRpcSession&lt;PublicApi&gt;(&quot;https://example.com/api&quot;);

// Call authenticate(), but don&#039;t await it. We can use the returned promise
// to make &quot;pipelined&quot; calls without waiting.
let authedApi: RpcPromise&lt;AuthedApi&gt; = api.authenticate(apiToken);

// Make a pipelined call to get the user&#039;s ID. Again, don&#039;t await it.
let userIdPromise: RpcPromise&lt;number&gt; = authedApi.getUserId();

// Make another pipelined call to fetch the user&#039;s public profile, based on
// the user ID. Notice how we can use `RpcPromise&lt;T&gt;` in the parameters of a
// call anywhere where T is expected. The promise will be replaced with its
// resolution before delivering the call.
let profilePromise = api.getUserProfile(userIdPromise);

// Make another call to get the user&#039;s friends.
let friendsPromise = authedApi.getFriendIds();

// That only returns an array of user IDs, but we want all the profile info
// too, so use the magic .map() function to get them, too! Still one round
// trip.
let friendProfilesPromise = friendsPromise.map((id: RpcPromise&lt;number&gt;) =&gt; {
  return { id, profile: api.getUserProfile(id); };
});

// Now await the promises. The batch is sent at this point. It&#039;s important
// to simultaneously await all promises for which you actually want the
// result. If you don&#039;t actually await a promise before the batch is sent,
// the system detects this and doesn&#039;t actually ask the server to send the
// return value back!
let [profile, friendProfiles] =
    await Promise.all([profilePromise, friendProfilesPromise]);

console.log(`Hello, ${profile.name}!`);

// Note that at this point, the `api` and `authedApi` stubs no longer work,
// because the batch is done. You must start a new batch.
```

Alternatively, for a long-running interactive application, we can set up a persistent WebSocket connection:

```ts
import { newWebSocketRpcSession } from &quot;capnweb&quot;;

// We declare `api` with `using` so that it&#039;ll be disposed at the end of the
// scope, which closes the connection. `using` is a fairly new JavaScript
// feature, part of the &quot;explicit resource management&quot; spec. Alternatively,
// we could declare `api` with `let` or `const` and make sure to call
// `api[Symbol.dispose]()` to dispose it and close the connection later.
using api = newWebSocketRpcSession&lt;PublicApi&gt;(&quot;wss://example.com/api&quot;);

// Usage is exactly the same, except we don&#039;t have to await all the promises
// at once.

// Authenticate and get the user ID in one round trip. Note we use `using`
// again so that `authedApi` will be disposed when we&#039;re done with it. In
// this case, it won&#039;t close the connection (since it&#039;s not the main stub),
// but disposing it does release the `AuthedApi` object on the server side.
using authedApi: RpcPromise&lt;AuthedApi&gt; = api.authenticate(apiToken);
let userId: number = await authedApi.getUserId();

// ... continue calling other methods, now or in the future ...
```

## RPC Basics

### Pass-by-value types

The following types can be passed over RPC (in arguments or return values), and will be passed &quot;by value&quot;, meaning the content is serialized, producing a copy at the receiving end:

* Primitive values: strings, numbers, booleans, null, undefined
* Plain objects (e.g., from object literals)
* Arrays
* `bigint`
* `Date`
* `Uint8Array`
* `Error` and its well-known subclasses

The following types are not supported as of this writing, but may be added in the future:
* `Map` and `Set`
* `ArrayBuffer` and typed arrays other than `Uint8Array`
* `RegExp`
* `ReadableStream` and `WritableStream`, with automatic flow control.
* `Headers`, `Request`, and `Response`

The following are intentionally NOT supported:
* Application-defined classes that do not extend `RpcTarget`.
* Cyclic values. Messages are serialized strictly as trees (like JSON).

### `RpcTarget`

To export an interface over RPC, you must write a class that `extends RpcTarget`. Extending `RpcTarget` tells the RPC system: instances of this class are _pass-by-reference_. When an instance is passed over RPC, the object should NOT be serialized. Instead, the RPC message will contain a &quot;stub&quot; that points back to the original target object. Invoking this stub calls back over RPC.

When you send someone an `RpcTarget` reference, they will be able to call any class method over RPC, including getters. They will not, however, be able to access &quot;own&quot; properties. In precise JavaScript terms, they can access prototype properties but not instance properties. This policy is intended to &quot;do the right thing&quot; for typical JavaScript code, where private members are typically stored as instance properties.

WARNING: If you are using TypeScript, note that declaring a method `private` does not hide it from RPC, because TypeScript annotations are &quot;erased&quot; at runtime, so cannot be enforced. To actually make methods private, you must prefix their names with `#`, which makes them private for JavaScript (not just TypeScript). Names prefixed with `#` are never available over RPC.

### Functions

When a plain function is passed over RPC, it will be treated similarly to an `RpcTarget`. The function will be replaced by a stub which, when invoked, calls back over RPC to the original function object.

If the function has any own properties, those will be available over RPC. Note that this differs from `RpcTarget`: With `RpcTarget`, own properties are not exposed, but with functions, _only_ own properties are exposed. Generally functions don&#039;t have properties anyway, making the point moot.

### `RpcStub&lt;T&gt;`

When a type `T` which extends `RpcTarget` (or is a function) is sent as part of an RPC message (in the arguments to a call, or in the return value), it is replaced with a stub of type `RpcStub&lt;T&gt;`.

Stubs are implemented using JavaScript `Proxy`s. A stub appears to have every possible method and property name. The stub does not know at runtime which properties actually exist on the server side. If you use a property that doesn&#039;t exist, an error will not be produced until you await the results.

TypeScript, however, will know which properties exist from type parameter `T`. Thus, if you are using TypeScript, you will get full compile-time type checking, auto-complete, etc. Hooray!

To read a property from the remote object (as opposed to calling a method), simply `await` the property, like `let foo = await stub.foo;`.

A stub can be passed across RPC again, including over independent connections. If Alice is connected to Bob and Carol, and Alice receives a stub from Bob, Alice can pass the stub in an RPC to Carol, thus allowing Carol to call Bob. (As of this writing, any such calls will be proxied through Alice, but in the future we may support &quot;three-party handoff&quot; such that Carol can make a direct connection to Bob.)

You may construct a stub explicitly without an RPC connection, using `new RpcStub(target)`. This is sometimes useful to be able to perform local calls as if they were remote, or to help manage disposal (see below).

### `RpcPromise&lt;T&gt;`

Calling an RPC method returns an `RpcPromise` rather than a regular `Promise`. You can use an `RpcPromise` in all the ways a regular `Promise` can be used, that is, you can `await` it, call `.then()`, pass it to `Promise.resolve()`, etc. (This is all possible because `RpcPromise` is a [&quot;thenable&quot;](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise#thenables).)

However, you can do more with `RpcPromise`. `RpcPromise` supports _Promise Pipelining_:

1. An `RpcPromise` also acts as a _stub_ for the eventual result of the promise. That means, you can access properties and invoke methods on it, without awaiting the promise first.

```ts
// In a single round trip, authenticate the user, and fetch their notifications.
let user = api.authenticate(cookie);
let notifications = await user.getNotifications();
```

2. An `RpcPromise` (or its properties) can be passed as parameters to other RPC calls.

```ts
// In a single round trip, authenticate the user, and fetch their public profile
// given their ID.
let user = api.authenticate(cookie);
let profile = await api.getUserProfile(user.id);
```

Whenever an `RpcPromise` is passed in the parameters to an RPC, or returned as part of the result, the promise will be replaced with its resolution before delivery to the receiving application. So, you can use an `RpcPromise&lt;T&gt;` anywhere where a `T` is required!

### The magic `map()` method

Every RPC promise has a special method `.map()` which can be used to remotely transform a value, without pulling it back locally. Here&#039;s an example:

```ts
// Get a list of user IDs.
let idsPromise = api.listUserIds();

// Look up the username for each one.
let names = await idsPromise.map(id =&gt; [id, api.getUserName(id)]);
```

This example calls one API method to get a list of user IDs, then, for each user ID in the list, makes another RPC call to look up the user&#039;s name, producing a list of id/name pairs.

**All this happens in a single network round trip!**

`promise.map(func)` transfers a representation of `func` to the server, where it is executed on the promise&#039;s result. Specifically:

* If the promise resolves to an array, the mapper function executes on each element of the array. The overall `.map()` operation returns a promise for an array of the results.
* If the promise resolves to `null` or `undefined`, the map function is not executed at all. The result is the same value.
* If the promise resolves to any other value, the map function executes once on that value, returning the result.

Thus, `map()` can be used both for handling arrays, and for handling nullable values.

There are some restrictions:

* The callback must have no side effects other than calling RPCs.
* The callback must be synchronous. It cannot await anything.
* The input to the callback is an `RpcPromise`, hence the callback cannot actually operate on it, other than to invoke its RPC methods, or to use it in the params of other RPC methods.
* Any stubs which you use in the callback -- and any parameters you pass to them -- will be sent to the peer. Be warned, a malicious peer can use these stubs for anything, not just calling your callback. Typically, it only makes sense to invoke stubs that came from the same peer originally, since this is what saves round-trips.

**How the heck does that work?**

Cap&#039;n Web does NOT send arbitrary code over the wire!

The trick here is record-replay: On the calling side, Cap&#039;n Web will invoke your callback once, in a special &quot;recording&quot; mode, passing in a special placeholder stub which records what you do with it. During the invocation, any RPCs invoked by the callback (on *any* stub) will not actually be executed, but will be recorded as an action the callback performs. Any stubs you use during the recording are &quot;captured&quot; as well. Once the callback returns, the recording and the capture list can then be sent to the peer, where the recording can then be replayed as needed to process individual results.

Since all of the not-yet-determined values seen by the callback are represented as `RpcPromise`s, the callback&#039;s behavior is deterministic. Any actual computation (arithmetic, branching, etc.) can&#039;t possibly use these promises as (meaningful) inputs, so would logically produce the same results for every invocation of the callback. Any such computation will actually end up being performed on the sending side, just once, with the results being imbued into the recording.

### Cloudflare Workers RPC interoperability

Cap&#039;n Web works on any JavaScript platform. But, on Cloudflare Workers specifically, it&#039;s designed to play nicely with the [the built-in RPC system](https://blog.cloudflare.com/javascript-native-rpc/). The two have basically the same semantics, the only difference being that Workers RPC is a built-in API provided by the Workers Runtime, whereas Cap&#039;n Web is implemented in pure JavaScript.

To facilitate interoperability:
* On Workers, the `RpcTarget` class exported by &quot;capnweb&quot; is just an alias of the built-in one, so you can use them interchangeably.
* RPC stubs and promises originating from one RPC system can be passed over the other. This will automatically set up proxying.
* You can also send Workers Service Bindings and Durable Object stubs over Cap&#039;n Web -- again, this sets up proxying.

So basically, it &quot;just works&quot;.

With that said, as of this writing, the feature set is not exactly the same between the two. We aim to fix this over time, by adding missing features to both sides until they match. In particular, as of this writing:
* Workers RPC supports some types that Cap&#039;n Web does not yet, like `Map`, streams, etc.
* Workers RPC supports sending values that contain aliases and cycles. This can actually cause problems, so we actually plan to *remove* this feature from Workers RPC (with a compatibility flag, of course).
* Workers RPC does not yet support placing an `RpcPromise` into the parameters of a request, to be replaced by its resolution.
* Workers RPC does not yet support the magic `.map()` method.

## Resource Management and Disposal

Unfortunately, garbage collection does not work well when remote resources are involved, for two reasons:

1. Many JavaScript runtimes only run the garbage collector when they sense &quot;memory pressure&quot; -- if memory is not running low, then they figure there&#039;s no need to try to reclaim any. However, the runtime has no way to know if the other side of an RPC connection is suffering memory pressure.

2. Garbage collectors need to trace the full object graph in order to detect which objects are unreachable, especially when those objects contain cyclic references. However, the garbage collector can only see local objects; it has no ability to trace through the remote graph to discover cycles that may cross RPC connections.

Both of these problems might be solvable with sufficient work, but the problem seems exceedingly difficult. We make no attempt to solve it in this library.

Instead, you may choose one of two strategies:

1. Explicitly dispose stubs when you are done with them. This notifies the remote end that it can release the associated resources.

2. Use short-lived sessions. When the session ends, all stubs are implicitly disposed. In particular, when using HTTP batch request, there&#039;s generally no need to dispose stubs. When using long-lived WebSocket sessions, however, disposal may be important.

Note: We might extend Cap&#039;n Web to use `FinalizationRegistry` to automatically dispose abandoned stubs in the future, but even if we do, it should not be relied upon, due to problems discussed above.

### How to dispose

Stubs integrate with JavaScript&#039;s [explicit resource management](https://v8.dev/features/explicit-resource-management), which became widely available in mid-2025 (and has been supported via transpilers and polyfills going back a few years earlier). In short:

* Disposable objects (including stubs) have a method `[Symbol.dispose]`. You can call this like `stub[Symbol.dispose]()`.
* You can arrange for a stub to be disposed automatically at the end of a function scope by assigning it to a `using` variable, like `using stub = api.getStub();`. The disposer will automatically be invoked when the variable goes out-of-scope.

### Automatic disposal

This library implements several rules to help make resource management more manageable. These rules may appear a bit complicated, but are intended to implement the behavior you would naturally expect.

The bas

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[mediar-ai/screenpipe]]></title>
            <link>https://github.com/mediar-ai/screenpipe</link>
            <guid>https://github.com/mediar-ai/screenpipe</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[AI app store powered by 24/7 desktop history. open source | 100% local | dev friendly | 24/7 screen, mic recording]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mediar-ai/screenpipe">mediar-ai/screenpipe</a></h1>
            <p>AI app store powered by 24/7 desktop history. open source | 100% local | dev friendly | 24/7 screen, mic recording</p>
            <p>Language: TypeScript</p>
            <p>Stars: 15,699</p>
            <p>Forks: 1,217</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>&lt;img referrerpolicy=&quot;no-referrer-when-downgrade&quot; src=&quot;https://static.scarf.sh/a.png?x-pxid=c3628864-a0cb-47a1-a822-2f936cff50b2&quot; /&gt;
&lt;p align=&quot;center&quot;&gt;
   &lt;a href=&quot;README.md&quot;&gt;English&lt;/a&gt; | &lt;a href=&quot;README-zh_CN.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href=&quot;README-ja.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
   &lt;a href =&quot;https://screenpi.pe&quot;&gt;
      &lt;img src=&quot;https://github.com/user-attachments/assets/d3b1de26-c3c0-4c84-b9c4-b03213b97a30&quot; alt=&quot;logo&quot; width=&quot;200&quot;&gt;
   &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
   &lt;a href=&quot;https://trendshift.io/repositories/11785&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/11785&quot; alt=&quot;mediar-ai%2Fscreenpipe | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;


&lt;!-- ScreenPipe Title and Subtitle --&gt;
&lt;p align=&quot;center&quot; style=&quot;font-family: &#039;Press Start 2P&#039;, monospace;&quot;&gt;
   &lt;h1 align=&quot;center&quot;&gt;[ screenpipe ]&lt;/h1&gt;
   &lt;p align=&quot;center&quot;&gt;AI app store powered by 24/7 desktop history&lt;/p&gt;
   &lt;p align=&quot;center&quot;&gt;open source | 100% local | dev friendly | 24/7 screen, mic recording&lt;/p&gt;
&lt;/p&gt;

&lt;!-- Slogan --&gt;
&lt;p align=&quot;center&quot; style=&quot;font-family: monospace;&quot;&gt;
   &lt;code&gt;[ recording reality, one pixel at a time ]&lt;/code&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://screenpi.pe&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/Download%20The-Desktop%20App-blue?style=for-the-badge&quot; alt=&quot;Download the Desktop App&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.youtube.com/@mediar_ai&quot; target=&quot;_blank&quot;&gt;
       &lt;img alt=&quot;YouTube Channel Subscribers&quot; src=&quot;https://img.shields.io/youtube/channel/subscribers/UCwjkpAsb70_mENKvy7hT5bw&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;


&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://discord.gg/dU9EBuw7Uq&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/823813159592001537?color=5865F2&amp;logo=discord&amp;logoColor=white&amp;style=flat-square&quot; alt=&quot;Join us on Discord&quot;&gt;
    &lt;/a&gt;
   &lt;a href=&quot;https://twitter.com/screen_pipe&quot;&gt;&lt;img alt=&quot;X account&quot; src=&quot;https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&amp;label=Follow%20%40screen_pipe&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://console.algora.io/org/mediar-ai/bounties?status=completed&quot;&gt;
       &lt;img src=&quot;https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2Fmediar-ai%2Fbounties%3Fstatus%3Dcompleted&quot; alt=&quot;Rewarded Bounties&quot;&gt;
   &lt;/a&gt;
   &lt;a href=&quot;https://console.algora.io/org/mediar-ai/bounties?status=open&quot;&gt;
       &lt;img src=&quot;https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2Fmediar-ai%2Fbounties%3Fstatus%3Dopen&quot; alt=&quot;Open Bounties&quot;&gt;
   &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
   

&lt;img width=&quot;1312&quot; alt=&quot;Screenshot 2025-02-15 at 7 51 18‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/5a9f29ce-69ae-463f-b338-186b8cdb2d12&quot; /&gt;

![image](https://github.com/user-attachments/assets/dec2e07c-b3d5-46dd-9f36-c0c26a82c9fb)



https://github.com/user-attachments/assets/628c6c01-a580-4b21-bce9-3e7b186914a4




https://github.com/user-attachments/assets/973ee8e5-5240-4d36-83fe-d38c53efe6a9






---

*news* üî•
- [2025/07] [we raised $2.8m to give AI hands to every desktop](https://x.com/louis030195/status/1948745185178914929)
- [2025/03] introducing [screenpipe terminator](https://github.com/mediar-ai/terminator): playwright but for your desktop. the fastest and most reliable computer use SDK on the internet (100x faster, based on OS APIs instead of vision)
- [2025/02] we&#039;re throwing an [hackathon](https://www.nosu.io/hackathons/screenpipe), $12k in cash prizes, 28 Feb
- [2025/01] we&#039;re partnering with Different AI to bring you [financial automations based on your screen](https://github.com/different-ai/hypr-v0) and [drop-in replacement for granola within obsidian](https://github.com/different-ai/file-organizer-2000)
- [2024/12] pipe store stripe integration: devs build cool shit - few lines of JS and make passive income (available Reddit agent, Timeline ...)
- [2024/11] [screenpipe is number 1 github trending repo (again)](https://x.com/louis030195/status/1859628763425931479)
- [2024/10] screenpipe has been backed by [Founders, Inc](https://f.inc/)
- [2024/09] [screenpipe is number 1 github trending repo &amp; on hackernews!](https://x.com/louis030195/status/1840859691754344483)
- [2024/08] anyone can now [create, share, install pipes](https://docs.screenpi.pe/plugins) (plugins) from the app interface based on a github repo/dir
- [2024/08] we&#039;re running bounties! contribute to screenpipe &amp; make money, [check issues](https://github.com/mediar-ai/screenpipe/issues)
- [2024/08] we released Apple &amp; Windows Native OCR.
- [2024/07] **we just launched the desktop app! [Download now!](https://screenpi.pe)**

---

# how it works?

- we record everything 24/7, 100% locally, uses 10% CPU, 4 GB ram, 15 gb/m
- we index it into an api
- dev build ai apps w user&#039;s full context, desktop native, nextjs, publish, monetize

&lt;img src=&quot;./content/diagram2.png&quot; width=&quot;800&quot; /&gt;

&lt;img src=&quot;https://github.com/user-attachments/assets/da5b8583-550f-4a1f-b211-058e7869bc91&quot; width=&quot;400&quot; /&gt;



# why?

- ai models are commoditized 
- ai is as good as its context
- the most valuable context is all contained in your screen


## get started

macos, linux:

```bash
curl -fsSL get.screenpi.pe/cli | sh
```

or on windows

```bash
iwr get.screenpi.pe/cli.ps1 | iex
```

then

```bash
screenpipe
```

make sure to allow permissions on macos (screen, mic)

- [get the desktop app](https://screenpi.pe/)
- [docs &amp; build from source](https://docs.screenpi.pe/getting-started)

## create plugins

```bash
bunx --bun @screenpipe/dev@latest pipe create
```

screenpipe has a plugin system called &quot;pipe&quot; which lets you create desktop app in nextjs in a sandboxed environment within our Rust code, [read more](https://docs.screenpi.pe/plugins)

you can then publish these to our store and make money:

```bash
cd foo
bunx --bun @screenpipe/dev@latest pipe register --name foo [--paid --price 50] # subscription
bun run build
bunx --bun @screenpipe/dev@latest pipe publish --name foo
```

## community 

- [template to build screenpipe-powered desktop native app using Tauri](https://github.com/LorenzoBloedow/screenpipe-tauri-template-dev)
- [template to build screenpipe-powered desktop native app using Electron](https://github.com/neo773/screenpipe-electron)
- [community projects](https://www.sprint.dev/hackathons/screenpipe)

## star history

![Star History Nov 24 2024](https://github.com/user-attachments/assets/c7e4de14-0771-4bbb-9a4c-7f2102a1a6cd)


## contributing

contributions are welcome! if you&#039;d like to contribute, please read [CONTRIBUTING.md](CONTRIBUTING.md).

   &lt;a href=&quot;https://console.algora.io/org/mediar-ai/bounties?status=completed&quot;&gt;
       &lt;img src=&quot;https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2Fmediar-ai%2Fbounties%3Fstatus%3Dcompleted&quot; alt=&quot;Rewarded Bounties&quot;&gt;
   &lt;/a&gt;
   &lt;a href=&quot;https://console.algora.io/org/mediar-ai/bounties?status=open&quot;&gt;
       &lt;img src=&quot;https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2Fmediar-ai%2Fbounties%3Fstatus%3Dopen&quot; alt=&quot;Open Bounties&quot;&gt;
   &lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[Canner/WrenAI]]></title>
            <link>https://github.com/Canner/WrenAI</link>
            <guid>https://github.com/Canner/WrenAI</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:35 GMT</pubDate>
            <description><![CDATA[‚ö°Ô∏è GenBI (Generative BI) queries any database in natural language, generates accurate SQL (Text-to-SQL), charts (Text-to-Chart), and AI-powered insights in seconds.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Canner/WrenAI">Canner/WrenAI</a></h1>
            <p>‚ö°Ô∏è GenBI (Generative BI) queries any database in natural language, generates accurate SQL (Text-to-SQL), charts (Text-to-Chart), and AI-powered insights in seconds.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 12,095</p>
            <p>Forks: 1,224</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot; id=&quot;top&quot;&gt;
  &lt;a href=&quot;https://getwren.ai/?utm_source=github&amp;utm_medium=title&amp;utm_campaign=readme&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./misc/wrenai_logo.png&quot;&gt;
      &lt;img src=&quot;./misc/wrenai_logo_white.png&quot; width=&quot;300px&quot;&gt;
    &lt;/picture&gt;
    &lt;h1 align=&quot;center&quot;&gt;Wren AI - Open-Source GenBI Agent&lt;/h1&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;Follow us on X&quot; href=&quot;https://x.com/getwrenai&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/badge/-@getwrenai-blue?style=for-the-badge&amp;logo=x&amp;logoColor=white&amp;labelColor=gray&amp;logoWidth=20&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Releases&quot; href=&quot;https://github.com/canner/WrenAI/releases&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/github/v/release/canner/WrenAI?logo=github&amp;label=GitHub%20Release&amp;color=blue&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;License&quot; href=&quot;https://github.com/Canner/WrenAI/blob/main/LICENSE&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/github/license/canner/WrenAI?color=blue&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://docs.getwren.ai&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/docs-online-brightgreen?style=for-the-badge&quot; alt=&quot;Docs&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Join the community on GitHub&quot; href=&quot;https://discord.gg/5DvshJqG8Z&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/badge/-JOIN%20THE%20COMMUNITY-blue?style=for-the-badge&amp;logo=discord&amp;logoColor=white&amp;labelColor=grey&amp;logoWidth=20&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Canner&quot; href=&quot;https://cannerdata.com/?utm_source=github&amp;utm_medium=badge&amp;utm_campaign=readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/%F0%9F%A7%A1-Made%20by%20Canner-blue?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/9263&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/9263&quot; alt=&quot;Canner%2FWrenAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; Wren AI is your GenBI Agent, that you can query any database with natural language ‚Üí get accurate SQL(Text-to-SQL), charts(Text-to-Charts) &amp; AI-generated insights in seconds. ‚ö°Ô∏è

&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;1920&quot; height=&quot;1080&quot; alt=&quot;1&quot; src=&quot;https://github.com/user-attachments/assets/bba9d37a-33e3-49ab-b7cb-32fd6dddc8d1&quot; /&gt;
&lt;/p&gt;
 
## üòç Demos

https://github.com/user-attachments/assets/f9c1cb34-5a95-4580-8890-ec9644da4160

[Watch GenBI Demo](https://github.com/user-attachments/assets/90ad1d35-bb1e-490b-9676-b29863ff090b)

## ü§ñ Features

|                    | What you get | Why it matters |
|--------------------|--------------|----------------|
| **Talk to Your Data** | Ask in any language ‚Üí precise SQL &amp; answers | Slash the SQL learning curveÔªø |
| **GenBI Insights** | AI-written summaries, charts &amp; reports | Decision-ready context in one clickÔªø |
| **Semantic Layer** | MDL models encode schema, metrics, joins | Keeps LLM outputs accurate &amp; governedÔªø |
| **Embed via API**  | Generate queries &amp; charts inside your apps ([API Docs](https://wrenai.readme.io/reference/cloud-getting-started)) | Build custom agents, SaaS features, chatbotsÔªø ([Streamlit Live Demo](https://huggingface.co/spaces/getWrenAI/wrenai-cloud-api-demo)) |

ü§© [Learn more about GenBI](https://getwren.ai/genbi?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme)

## üöÄ Getting Started

Using Wren AI is super simple, you can set it up within 3 minutes, and start to interact with your data!

&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;1920&quot; height=&quot;1080&quot; alt=&quot;2&quot; src=&quot;https://github.com/user-attachments/assets/6555f539-9ef2-485d-9135-0071741fda96&quot; /&gt;
&lt;/p&gt;

- Visit our [Install in your local environment](http://docs.getwren.ai/oss/installation?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme).
- Visit the [Usage Guides](https://docs.getwren.ai/oss/guide/connect/overview?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme) to learn more about how to use Wren AI.
- Or just start with [Wren AI Cloud](https://getwren.ai/?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme) our Managed Cloud Service. ([OSS vs. Commercial Plans](https://docs.getwren.ai/oss/overview/cloud_vs_self_host)).

## üèóÔ∏è Architecture

&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;1011&quot; height=&quot;682&quot; alt=&quot;wrenai-architecture&quot; src=&quot;https://github.com/user-attachments/assets/e99b999f-9912-4fa7-921a-9c86b6b83354&quot; /&gt;
&lt;/p&gt;

üëâ [Learn more about our Design](https://getwren.ai/post/how-we-design-our-semantic-engine-for-llms-the-backbone-of-the-semantic-layer-for-llm-architecture?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme)



## üîå Data Sources

If your data source is not listed here, vote for it in our [GitHub discussion thread](https://github.com/Canner/WrenAI/discussions/327). It will be a valuable input for us to decide on the next supported data sources.
- Athena (Trino)
- Redshift
- BigQuery
- DuckDB
- PostgreSQL
- MySQL
- Microsoft SQL Server
- ClickHouse
- Oracle
- Trino
- Snowflake

## ü§ñ LLM Models

Wren AI supports integration with various Large Language Models (LLMs), including but not limited to:
- OpenAI Models
- Azure OpenAI Models
- DeepSeek Models
- Google AI Studio ‚Äì Gemini Models
- Vertex AI Models (Gemini + Anthropic)
- Bedrock Models
- Anthropic API Models
- Groq Models
- Ollama Models
- Databricks Models

Check [configuration examples here](https://github.com/Canner/WrenAI/tree/main/wren-ai-service/docs/config_examples)!

&gt; [!CAUTION]
&gt; The performance of Wren AI depends significantly on the capabilities of the LLM you choose. We strongly recommend using the most powerful model available for optimal results. Using less capable models may lead to reduced performance, slower response times, or inaccurate outputs.

## üìö Documentation

Visit [Wren AI documentation](https://docs.getwren.ai/oss/overview/introduction?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme) to view the full documentation.

## üì™ Keep Posted?

[Subscribe our blog](https://www.getwren.ai/blog/?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme) and [Follow our LinkedIn](https://www.linkedin.com/company/wrenai)

## üõ†Ô∏è Contribution

1.	Star ‚≠ê the repo to show support (it really helps).
2.	Open an issue for bugs, ideas, or discussions.
3.	Read [Contribution Guidelines](https://github.com/Canner/WrenAI/blob/main/CONTRIBUTING.md) for setup &amp; PR guidelines.

## ‚≠êÔ∏è Community

- Join 1.3k+ developers in our [Discord](https://discord.gg/5DvshJqG8Z) for real-time help and roadmap previews.
- If there are any issues, please visit [GitHub Issues](https://github.com/Canner/WrenAI/issues).
- Explore our [public roadmap](https://wrenai.notion.site/) to stay updated on upcoming features and improvements!

Please note that our [Code of Conduct](./CODE_OF_CONDUCT.md) applies to all Wren AI community channels. Users are **highly encouraged** to read and adhere to them to avoid repercussions.

## üéâ Our Contributors
&lt;a href=&quot;https://github.com/canner/wrenAI/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=Canner/WrenAI&quot; /&gt;
&lt;/a&gt;

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;#top&quot;&gt;‚¨ÜÔ∏è Back to Top&lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[element-hq/element-web]]></title>
            <link>https://github.com/element-hq/element-web</link>
            <guid>https://github.com/element-hq/element-web</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[A glossy Matrix collaboration client for the web.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/element-hq/element-web">element-hq/element-web</a></h1>
            <p>A glossy Matrix collaboration client for the web.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 12,126</p>
            <p>Forks: 2,297</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>[![Chat](https://img.shields.io/matrix/element-web:matrix.org?logo=matrix)](https://matrix.to/#/#element-web:matrix.org)
![Tests](https://github.com/element-hq/element-web/actions/workflows/tests.yaml/badge.svg)
![Static Analysis](https://github.com/element-hq/element-web/actions/workflows/static_analysis.yaml/badge.svg)
[![Localazy](https://img.shields.io/endpoint?url=https%3A%2F%2Fconnect.localazy.com%2Fstatus%2Felement-web%2Fdata%3Fcontent%3Dall%26title%3Dlocalazy%26logo%3Dtrue)](https://localazy.com/p/element-web)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=element-web&amp;metric=alert_status)](https://sonarcloud.io/summary/new_code?id=element-web)
[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=element-web&amp;metric=coverage)](https://sonarcloud.io/summary/new_code?id=element-web)
[![Vulnerabilities](https://sonarcloud.io/api/project_badges/measure?project=element-web&amp;metric=vulnerabilities)](https://sonarcloud.io/summary/new_code?id=element-web)
[![Bugs](https://sonarcloud.io/api/project_badges/measure?project=element-web&amp;metric=bugs)](https://sonarcloud.io/summary/new_code?id=element-web)

# Element

Element (formerly known as Vector and Riot) is a Matrix web client built using the [Matrix
JS SDK](https://github.com/matrix-org/matrix-js-sdk).

# Supported Environments

Element has several tiers of support for different environments:

- Supported
    - Definition:
        - Issues **actively triaged**, regressions **block** the release
    - Last 2 major versions of Chrome, Firefox, and Edge on desktop OSes
    - Last 2 versions of Safari
    - Latest release of official Element Desktop app on desktop OSes
    - Desktop OSes means macOS, Windows, and Linux versions for desktop devices
      that are actively supported by the OS vendor and receive security updates
- Best effort
    - Definition:
        - Issues **accepted**, regressions **do not block** the release
        - The wider Element Products (including Element Call and the Enterprise Server Suite) do still not officially support these browsers.
        - The element web project and its contributors should keep the client functioning and gracefully degrade where other sibling features (E.g. Element Call) may not function.
    - Last major release of Firefox ESR and Chrome/Edge Extended Stable
- Community Supported
    - Definition:
        - Issues **accepted**, regressions **do not block** the release
        - Community contributions are welcome to support these issues
    - Mobile web for current stable version of Chrome, Firefox, and Safari on Android, iOS, and iPadOS
- Not supported
    - Definition: Issues only affecting unsupported environments are **closed**
    - Everything else

The period of support for these tiers should last until the releases specified above, plus 1 app release cycle(2 weeks). In the case of Firefox ESR this is extended further to allow it land in Debian Stable.

For accessing Element on an Android or iOS device, we currently recommend the
native apps [element-android](https://github.com/element-hq/element-android)
and [element-ios](https://github.com/element-hq/element-ios).

# Getting Started

The easiest way to test Element is to just use the hosted copy at &lt;https://app.element.io&gt;.
The `develop` branch is continuously deployed to &lt;https://develop.element.io&gt;
for those who like living dangerously.

To host your own instance of Element see [Installing Element Web](docs/install.md).

To install Element as a desktop application, see [Running as a desktop app](#running-as-a-desktop-app) below.

# Important Security Notes

## Separate domains

We do not recommend running Element from the same domain name as your Matrix
homeserver. The reason is the risk of XSS (cross-site-scripting)
vulnerabilities that could occur if someone caused Element to load and render
malicious user generated content from a Matrix API which then had trusted
access to Element (or other apps) due to sharing the same domain.

We have put some coarse mitigations into place to try to protect against this
situation, but it&#039;s still not good practice to do it in the first place. See
&lt;https://github.com/element-hq/element-web/issues/1977&gt; for more details.

## Configuration best practices

Unless you have special requirements, you will want to add the following to
your web server configuration when hosting Element Web:

- The `X-Frame-Options: SAMEORIGIN` header, to prevent Element Web from being
  framed and protect from [clickjacking][owasp-clickjacking].
- The `frame-ancestors &#039;self&#039;` directive to your `Content-Security-Policy`
  header, as the modern replacement for `X-Frame-Options` (though both should be
  included since not all browsers support it yet, see
  [this][owasp-clickjacking-csp]).
- The `X-Content-Type-Options: nosniff` header, to [disable MIME
  sniffing][mime-sniffing].
- The `X-XSS-Protection: 1; mode=block;` header, for basic XSS protection in
  legacy browsers.

[mime-sniffing]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types#mime_sniffing
[owasp-clickjacking-csp]: https://cheatsheetseries.owasp.org/cheatsheets/Clickjacking_Defense_Cheat_Sheet.html#content-security-policy-frame-ancestors-examples
[owasp-clickjacking]: https://cheatsheetseries.owasp.org/cheatsheets/Clickjacking_Defense_Cheat_Sheet.html

If you are using nginx, this would look something like the following:

```
add_header X-Frame-Options SAMEORIGIN;
add_header X-Content-Type-Options nosniff;
add_header X-XSS-Protection &quot;1; mode=block&quot;;
add_header Content-Security-Policy &quot;frame-ancestors &#039;self&#039;&quot;;
```

For Apache, the configuration looks like:

```
Header set X-Frame-Options SAMEORIGIN
Header set X-Content-Type-Options nosniff
Header set X-XSS-Protection &quot;1; mode=block&quot;
Header set Content-Security-Policy &quot;frame-ancestors &#039;self&#039;&quot;
```

Note: In case you are already setting a `Content-Security-Policy` header
elsewhere, you should modify it to include the `frame-ancestors` directive
instead of adding that last line.

# Building From Source

Element is a modular webapp built with modern ES6 and uses a Node.js build system.
Ensure you have the latest LTS version of Node.js installed.

Using `yarn` instead of `npm` is recommended. Please see the Yarn [install
guide](https://classic.yarnpkg.com/en/docs/install) if you do not have it already.

1. Install or update `node.js` so that your `node` is at least the current recommended LTS.
1. Install `yarn` if not present already.
1. Clone the repo: `git clone https://github.com/element-hq/element-web.git`.
1. Switch to the element-web directory: `cd element-web`.
1. Install the prerequisites: `yarn install`.
    - If you&#039;re using the `develop` branch, then it is recommended to set up a
      proper development environment (see [Setting up a dev
      environment](./developer_guide.md#setting-up-a-dev-environment) below). Alternatively, you
      can use &lt;https://develop.element.io&gt; - the continuous integration release of
      the develop branch.
1. Configure the app by copying `config.sample.json` to `config.json` and
   modifying it. See the [configuration docs](docs/config.md) for details.
1. `yarn dist` to build a tarball to deploy. Untaring this file will give
   a version-specific directory containing all the files that need to go on your
   web server.

Note that `yarn dist` is not supported on Windows, so Windows users can run `yarn build`,
which will build all the necessary files into the `webapp` directory. The version of Element
will not appear in Settings without using the dist script. You can then mount the
`webapp` directory on your web server to actually serve up the app, which is
entirely static content.

# Running as a Desktop app

Element can also be run as a desktop app, wrapped in Electron. You can download a
pre-built version from &lt;https://element.io/get-started&gt; or, if you prefer,
build it yourself.

To build it yourself, follow the instructions at &lt;https://github.com/element-hq/element-desktop&gt;.

Many thanks to @aviraldg for the initial work on the Electron integration.

The [configuration docs](docs/config.md#desktop-app-configuration) show how to override the desktop app&#039;s default settings if desired.

# config.json

Element supports a variety of settings to configure default servers, behaviour, themes, etc.
See the [configuration docs](docs/config.md) for more details.

# Labs Features

Some features of Element may be enabled by flags in the `Labs` section of the settings.
Some of these features are described in [labs.md](https://github.com/element-hq/element-web/blob/develop/docs/labs.md).

# Caching requirements

Element requires the following URLs not to be cached, when/if you are serving Element from your own webserver:

```
/config.*.json
/i18n
/home
/sites
/index.html
```

We also recommend that you force browsers to re-validate any cached copy of Element on page load by configuring your
webserver to return `Cache-Control: no-cache` for `/`. This ensures the browser will fetch a new version of Element on
the next page load after it&#039;s been deployed. Note that this is already configured for you in the nginx config of our
Dockerfile.

# Development

Please read through the following:

1. [Developer guide](./developer_guide.md)
2. [Code style](./code_style.md)
3. [Contribution guide](./CONTRIBUTING.md)

# Translations

To add a new translation, head to the [translating doc](docs/translating.md).

For a developer guide, see the [translating dev doc](docs/translating-dev.md).

# Triaging issues

Issues are triaged by community members and the Web App Team, following the [triage process](https://github.com/element-hq/element-meta/wiki/Triage-process).

We use [issue labels](https://github.com/element-hq/element-meta/wiki/Issue-labelling) to sort all incoming issues.

## Copyright &amp; License

Copyright (c) 2014-2017 OpenMarket Ltd
Copyright (c) 2017 Vector Creations Ltd
Copyright (c) 2017-2025 New Vector Ltd

This software is multi licensed by New Vector Ltd (Element). It can be used either:

(1) for free under the terms of the GNU Affero General Public License (as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version); OR

(2) for free under the terms of the GNU General Public License (as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version); OR

(3) under the terms of a paid-for Element Commercial License agreement between you and Element (the terms of which may vary depending on what you and Element have agreed to).
Unless required by applicable law or agreed to in writing, software distributed under the Licenses is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the Licenses for the specific language governing permissions and limitations under the Licenses.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[OpenCTI-Platform/opencti]]></title>
            <link>https://github.com/OpenCTI-Platform/opencti</link>
            <guid>https://github.com/OpenCTI-Platform/opencti</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[Open Cyber Threat Intelligence Platform]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenCTI-Platform/opencti">OpenCTI-Platform/opencti</a></h1>
            <p>Open Cyber Threat Intelligence Platform</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,780</p>
            <p>Forks: 1,132</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencti.io&quot;&gt;&lt;img src=&quot;./.github/img/logo_opencti.png&quot; alt=&quot;OpenCTI&quot;&gt;&lt;/a&gt;
&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencti.io&quot; alt=&quot;Website&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/website-opencti.io-blue.svg&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://docs.opencti.io&quot; alt=&quot;Documentation&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/documentation-latest-orange.svg&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://community.filigran.io&quot; alt=&quot;Slack&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/slack-3K%2B%20members-4A154B&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://drone.filigran.io/OpenCTI-Platform/opencti&quot;&gt;&lt;img src=&quot;https://drone.filigran.io/api/badges/OpenCTI-Platform/opencti/status.svg&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/OpenCTI-Platform/opencti&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/OpenCTI-Platform/opencti/graph/badge.svg&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://deepscan.io/dashboard#view=project&amp;tid=4926&amp;pid=6716&amp;bid=57311&quot;&gt;&lt;img src=&quot;https://deepscan.io/api/teams/4926/projects/6716/branches/57311/badge/grade.svg&quot; alt=&quot;DeepScan grade&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://renovatebot.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/renovate-enabled-brightgreen.svg&quot; alt=&quot;DeepScan grade&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://hub.docker.com/u/opencti&quot; alt=&quot;Docker pulls&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/opencti/platform&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

## Introduction

OpenCTI is an open source platform allowing organizations to manage their cyber threat intelligence knowledge and observables. It has been created in order to structure, store, organize and visualize technical and non-technical information about cyber threats.

The structuration of the data is performed using a knowledge schema based on the [STIX2 standards](https://oasis-open.github.io/cti-documentation/). It has been designed as a modern web application including a [GraphQL API](https://graphql.org) and an UX oriented frontend. Also, OpenCTI can be integrated with other tools and applications such as [MISP](https://github.com/MISP/MISP), [TheHive](https://github.com/TheHive-Project/TheHive), [MITRE ATT&amp;CK](https://github.com/mitre/cti), etc.

![Screenshot](./.github/img/screenshot.png &quot;Screenshot&quot;)

## Objective

The goal is to create a comprehensive tool allowing users to capitalize technical (such as TTPs and observables) and non-technical information (such as suggested attribution, victimology etc.) while linking each piece of information to its primary source (a report, a MISP event, etc.), with features such as links between each information, first and last seen dates, levels of confidence, etc. The tool is able to use the [MITRE ATT&amp;CK framework](https://attack.mitre.org) (through a [dedicated connector](https://github.com/OpenCTI-Platform/connectors)) to help structure the data. The user can also choose to implement their own datasets.

Once data has been capitalized and processed by the analysts within OpenCTI, new relations may be inferred from existing ones to facilitate the understanding and the representation of this information. This allows the user to extract and leverage meaningful knowledge from the raw data.

OpenCTI not only allows [imports](https://docs.opencti.io/latest/usage/import-automated/) but also [exports of data](https://docs.opencti.io/latest/usage/feeds/) under different formats (CSV, STIX2 bundles, etc.). [Connectors](https://filigran.notion.site/OpenCTI-Ecosystem-868329e9fb734fca89692b2ed6087e76) are currently developed to accelerate interactions between the tool and other platforms.

## Editions of the platform

OpenCTI platform has 2 different editions: Community (CE) and Enterprise (EE). The purpose of the Enterprise Edition is to provide [additional and powerful features](https://filigran.io/offering/subscribe) which require specific investments in research and development. You can enable the Enterprise Edition directly in the settings of the platform.

* OpenCTI Community Edition, licensed under the [Apache 2, Version 2.0 license](LICENSE).
* OpenCTI Enterprise Edition, licensed under the [Enterprise Edition license](LICENSE).

To understand what OpenCTI Enterprise Edition brings in terms of features, just check the [Enterprise Editions page](https://filigran.io/offering/subscribe) on the Filigran website. You can also try this edition by enabling it in the settings of the platform.

## Documentation and demonstration

If you want to know more on OpenCTI, you can read the [documentation on the tool](https://docs.opencti.io). If you wish to discover how the OpenCTI platform is working, a [demonstration instance](https://demo.opencti.io) is available and open to everyone. This instance is reset every night and is based on reference data maintained by the OpenCTI developers.

## Releases download

The releases are available on the [Github releases page](https://github.com/OpenCTI-Platform/opencti/releases). You can also access the [rolling release package](https://releases.opencti.io) generated from the master branch of the repository.

## Installation

All you need to install the OpenCTI platform can be found in the [official documentation](https://docs.opencti.io). For installation, you can:

* [Use Docker](https://docs.opencti.io/latest/deployment/installation/#using-docker)
* [Install manually](https://docs.opencti.io/latest/deployment/installation/#install-manually)
* [Use Terraform (community)](https://docs.opencti.io/latest/deployment/installation/#terraform)
* [Use Helm charts (community)](https://docs.opencti.io/latest/deployment/installation/#helm-charts)

## Contributing

### Code of Conduct

OpenCTI has adopted a [Code of Conduct](CODE_OF_CONDUCT.md) that we expect project participants to adhere to. Please read the [full text](CODE_OF_CONDUCT.md) so that you can understand what actions will and will not be tolerated.

### Contributing Guide

Read our [contributing guide](CONTRIBUTING.md) to learn about our development process, how to propose bugfixes and improvements, and how to build and test your changes to OpenCTI.

### Beginner friendly issues

To help you get you familiar with our contribution process, we have a list of [beginner friendly issues](https://github.com/OpenCTI-Platform/opencti/labels/beginner%20friendly%20issue) which are fairly easy to implement. This is a great place to get started.

### Development

If you want to actively help OpenCTI, we created a [dedicated documentation](https://docs.opencti.io/latest/development/environment_ubuntu/) about the deployment of a development environment and how to start the source code modification.

## Community

### Status &amp; bugs

Currently OpenCTI is under heavy development, if you wish to report bugs or ask for new features, you can directly use the [Github issues module](https://github.com/OpenCTI-Platform/opencti/issues).

### Discussion

If you need support or you wish to engage a discussion about the OpenCTI platform, feel free to join us on our [Slack channel](https://community.filigran.io). You can also send us an email to contact@filigran.io.

## About

### Authors

OpenCTI is a product designed and developed by the company [Filigran](https://filigran.io).

&lt;a href=&quot;https://filigran.io&quot; alt=&quot;Filigran&quot;&gt;&lt;img src=&quot;./.github/img/logo_filigran.png&quot; width=&quot;300&quot; /&gt;&lt;/a&gt;

### Data Collection

#### Usage telemetry

To improve the features and the performances of OpenCTI, the platform collects anonymous statistical data related to its usage and health.

You can find all the details on collected data and associated usage in the [usage telemetry documentation](https://docs.opencti.io/latest/reference/usage-telemetry/).

#### OpenStreetMap server

To provide OpenCTI users with cartography features, the platform uses a dedicated OpenStreetMap server (https://map.opencti.io). To monitor usage and adapt services performances, Filigran collects access log to this server (including IP addresses).

By using this server, you authorize Filigran to collect this information. Otherwise, you are free to deploy your own OpenStreetMap server and modify the platform configuration accordingly.

If you have started using the Filigran server and change your mind, you have the right to access, limit, rectify, erase and receive your data. To exercise your rights, please send your request to privacy@filigran.io.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[TanStack/router]]></title>
            <link>https://github.com/TanStack/router</link>
            <guid>https://github.com/TanStack/router</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[ü§ñ Fully typesafe Router for React (and friends) w/ built-in caching, 1st class search-param APIs, client-side cache integration and isomorphic rendering.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/TanStack/router">TanStack/router</a></h1>
            <p>ü§ñ Fully typesafe Router for React (and friends) w/ built-in caching, 1st class search-param APIs, client-side cache integration and isomorphic rendering.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 11,351</p>
            <p>Forks: 1,228</p>
            <p>Stars today: 133 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://static.scarf.sh/a.png?x-pxid=d988eb79-b0fc-4a2b-8514-6a1ab932d188&quot; /&gt;

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;img
src=&quot;./media/header_router.png&quot;
alt=&quot;TanStack Router&quot;
/&gt;

## TanStack Router

A modern router designed for type safety, data‚Äëdriven navigation, and seamless developer experience.

- End‚Äëto‚Äëend type safety (routes, params, loaders)
- Schema‚Äëdriven search params with validation
- Built‚Äëin caching, prefetching &amp; invalidation
- Nested layouts, transitions &amp; error boundaries

### [Read the Router Docs ‚Üí](https://tanstack.com/router)

&lt;/td&gt;
&lt;td&gt;

&lt;img
src=&quot;./media/header_start.png&quot;
alt=&quot;TanStack Start&quot;
/&gt;

## TanStack Start

A full‚Äëstack framework built on Router, designed for server rendering, streaming, and production‚Äëready deployments.

- Full‚Äëdocument SSR &amp; streaming
- Server functions &amp; end‚Äëto‚Äëend type safety
- Deployment‚Äëready bundling &amp; builds
- All the power of TanStack Router, plus full‚Äëstack features

### [Read the Start Docs ‚Üí](https://tanstack.com/start)

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;br /&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://npmjs.com/package/@tanstack/react-router&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/dm/@tanstack/react-router.svg&quot; alt=&quot;npm downloads&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/tanstack/router&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/tanstack/router.svg?style=social&amp;label=Star&quot; alt=&quot;GitHub stars&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://bundlephobia.com/result?p=@tanstack/react-router&quot;&gt;
    &lt;img src=&quot;https://badgen.net/bundlephobia/minzip/@tanstack/react-router&quot; alt=&quot;Bundle size&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;#badge&quot;&gt;
    &lt;img alt=&quot;semantic-release&quot; src=&quot;https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://bestofjs.org/projects/tanstack-router&quot;&gt;&lt;img alt=&quot;Best of JS&quot; src=&quot;https://img.shields.io/endpoint?url=https://bestofjs-serverless.now.sh/api/project-badge?fullName=TanStack%2Frouter%26since=daily&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/tan_stack&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/tan_stack.svg?style=social&quot; alt=&quot;Follow @TanStack&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

### [Become a Sponsor!](https://github.com/sponsors/tannerlinsley/)

&lt;/div&gt;

## Get Involved

- We welcome issues and pull requests!
- Participate in [GitHub discussions](https://github.com/TanStack/router/discussions)
- Chat with the community on [Discord](https://discord.com/invite/WrRKjPJ)
- See [CONTRIBUTING.md](./CONTRIBUTING.md) for setup instructions

## Partners

&lt;table align=&quot;center&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;
        &lt;a href=&quot;https://www.coderabbit.ai/?via=tanstack&amp;dub_id=aCcEEdAOqqutX6OS&quot;&gt;
			&lt;picture&gt;
			  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://tanstack.com/assets/coderabbit-dark-CMcuvjEy.svg&quot; height=&quot;40&quot; /&gt;
			  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://tanstack.com/assets/coderabbit-light-DVMJ2jHi.svg&quot; height=&quot;40&quot; /&gt;
			  &lt;img src=&quot;https://tanstack.com/assets/coderabbit-dark-CMcuvjEy.svg&quot; height=&quot;40&quot; alt=&quot;CodeRabbit&quot; /&gt;
			&lt;/picture&gt;        
		&lt;/a&gt;
    &lt;/td&gt;
    &lt;td padding=&quot;20&quot;&gt;
      &lt;a href=&quot;https://www.cloudflare.com?utm_source=tanstack&quot;&gt;
         &lt;picture&gt;
    		  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://tanstack.com/assets/cloudflare-white-DQDB7UaL.svg&quot; height=&quot;60&quot; /&gt;
    		  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://tanstack.com/assets/cloudflare-black-CPufaW0B.svg&quot; height=&quot;60&quot; /&gt;
    		  &lt;img src=&quot;https://tanstack.com/assets/cloudflare-black-CPufaW0B.svg&quot; height=&quot;60&quot; alt=&quot;Cloudflare&quot; /&gt;
    		&lt;/picture&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://netlify.com?utm_source=tanstack&quot;&gt;
      &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/netlify-dark.svg&quot; height=&quot;70&quot;/&gt;
        &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/tannerlinsley/files/master/partners/netlify.svg&quot; height=&quot;70&quot;/&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/netlify-dark.svg&quot; height=&quot;70&quot; alt=&quot;Netlify&quot; /&gt;
      &lt;/picture&gt;
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://neon.tech?utm_source=tanstack&quot;&gt;
		  &lt;picture&gt;
	        &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/neon-dark.svg&quot; height=&quot;50&quot;/&gt;
	        &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/tannerlinsley/files/master/partners/neon.svg&quot; height=&quot;50&quot;/&gt;
	        &lt;img src=&quot;https://raw.githubusercontent.com/tannerlinsley/files/master/partners/neon.svg&quot; height=&quot;50&quot; alt=&quot;Neon&quot; /&gt;
		  &lt;/picture&gt;
	  &lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://go.clerk.com/wOwHtuJ&quot;&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://tanstack.com/assets/clerk-logo-dark-CRE22T_2.svg&quot; height=&quot;40&quot;/&gt;
          &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/tannerlinsley/files/master/partners/clerk.svg&quot; height=&quot;40&quot;/&gt;
          &lt;img src=&quot;https://tanstack.com/assets/clerk-logo-dark-CRE22T_2.svg&quot; height=&quot;40&quot; alt=&quot;Clerk&quot; /&gt;
        &lt;/picture&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://convex.dev?utm_source=tanstack&quot;&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/convex-white.svg&quot; height=&quot;30&quot;/&gt;
          &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/tannerlinsley/files/master/partners/convex.svg&quot; height=&quot;30&quot;/&gt;
          &lt;img src=&quot;https://raw.githubusercontent.com/tannerlinsley/files/master/partners/convex.svg&quot; height=&quot;30&quot; alt=&quot;Convex&quot; /&gt;
        &lt;/picture&gt;
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://sentry.io?utm_source=tanstack&quot;&gt;
        &lt;picture&gt;
           &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/tanstack/tanstack.com/main/src/images/sentry-wordmark-light.svg&quot; height=&quot;50&quot;/&gt;
          &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/tannerlinsley/files/master/partners/sentry.svg&quot; height=&quot;50&quot;/&gt;
          &lt;img src=&quot;https://raw.githubusercontent.com/tannerlinsley/files/master/partners/sentry.svg&quot; height=&quot;50&quot; alt=&quot;Sentry&quot; /&gt;
        &lt;/picture&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://www.prisma.io?utm_source=tanstack&amp;via=tanstack&quot;&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://tanstack.com/assets/prisma-dark-DwgDxLwn.svg&quot; height=&quot;50&quot;/&gt;
          &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://tanstack.com/assets/prisma-light-Cloa3Onm.svg&quot; height=&quot;50&quot;/&gt;
          &lt;img src=&quot;https://tanstack.com/assets/prisma-dark-DwgDxLwn.svg&quot; height=&quot;50&quot; alt=&quot;Prisma&quot; /&gt;
        &lt;/picture&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://strapi.link/tanstack-start&quot;&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://tanstack.com/assets/strapi-dark-CQ84tQTk.svg&quot; height=&quot;40&quot;/&gt;
          &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://tanstack.com/assets/strapi-light-6x7linao.svg&quot; height=&quot;40&quot;/&gt;
          &lt;img src=&quot;https://tanstack.com/assets/strapi-dark-CQ84tQTk.svg&quot; height=&quot;40&quot; alt=&quot;Strapi&quot; /&gt;
        &lt;/picture&gt;
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;./media/partner_logo.svg&quot; alt=&quot;Router &amp; you?&quot; height=&quot;65&quot;&gt;
&lt;p&gt;
We&#039;re looking for TanStack Router &amp; Start Partners to join our mission! Partner with us to push the boundaries of TanStack Router &amp; Start and build amazing things together.
&lt;/p&gt;
&lt;a href=&quot;mailto:partners@tanstack.com?subject=TanStack Router &amp; Start Partnership&quot;&gt;&lt;b&gt;LET&#039;S CHAT&lt;/b&gt;&lt;/a&gt;
&lt;/div&gt;

## Explore the TanStack Ecosystem

- &lt;a href=&quot;https://github.com/tanstack/config&quot;&gt;&lt;b&gt;TanStack Config&lt;/b&gt;&lt;/a&gt; ‚Äì Tooling for JS/TS packages
- &lt;a href=&quot;https://github.com/tanstack/db&quot;&gt;&lt;b&gt;TanStack DB&lt;/b&gt;&lt;/a&gt; ‚Äì Reactive sync client store
- &lt;a href=&quot;https://github.com/tanstack/devtools&quot;&gt;&lt;b&gt;TanStack DevTools&lt;/b&gt;&lt;/a&gt; ‚Äì Unified devtools panel
- &lt;a href=&quot;https://github.com/tanstack/form&quot;&gt;&lt;b&gt;TanStack Form&lt;/b&gt;&lt;/a&gt; ‚Äì Type‚Äësafe form state
- &lt;a href=&quot;https://github.com/tanstack/pacer&quot;&gt;&lt;b&gt;TanStack Pacer&lt;/b&gt;&lt;/a&gt; ‚Äì Debouncing, throttling, batching &lt;br/&gt;
- &lt;a href=&quot;https://github.com/tanstack/query&quot;&gt;&lt;b&gt;TanStack Query&lt;/b&gt;&lt;/a&gt; ‚Äì Async state &amp; caching
- &lt;a href=&quot;https://github.com/tanstack/ranger&quot;&gt;&lt;b&gt;TanStack Ranger&lt;/b&gt;&lt;/a&gt; ‚Äì Range &amp; slider primitives
- &lt;a href=&quot;https://github.com/tanstack/store&quot;&gt;&lt;b&gt;TanStack Store&lt;/b&gt;&lt;/a&gt; ‚Äì Reactive data store
- &lt;a href=&quot;https://github.com/tanstack/table&quot;&gt;&lt;b&gt;TanStack Table&lt;/b&gt;&lt;/a&gt; ‚Äì Headless datagrids
- &lt;a href=&quot;https://github.com/tanstack/virtual&quot;&gt;&lt;b&gt;TanStack Virtual&lt;/b&gt;&lt;/a&gt; ‚Äì Virtualized rendering

‚Ä¶ and more at &lt;a href=&quot;https://tanstack.com&quot;&gt;&lt;b&gt;TanStack.com ¬ª&lt;/b&gt;&lt;/a&gt;

&lt;!-- Use the force, Luke --&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[exa-labs/exa-mcp-server]]></title>
            <link>https://github.com/exa-labs/exa-mcp-server</link>
            <guid>https://github.com/exa-labs/exa-mcp-server</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[Exa MCP for web search and web crawling!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/exa-labs/exa-mcp-server">exa-labs/exa-mcp-server</a></h1>
            <p>Exa MCP for web search and web crawling!</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,512</p>
            <p>Forks: 207</p>
            <p>Stars today: 206 stars today</p>
            <h2>README</h2><pre># Exa MCP Server üîç
[![npm version](https://badge.fury.io/js/exa-mcp-server.svg)](https://www.npmjs.com/package/exa-mcp-server)
[![smithery badge](https://smithery.ai/badge/exa)](https://smithery.ai/server/exa)

## üÜï `exa-code`: fast, efficient web context for coding agents

Vibe coding should never have a bad vibe. `exa-code` is a huge step towards coding agents that never hallucinate.

When your coding agent makes a search query, `exa-code` searches over billions
of Github repos, docs pages, Stackoverflow posts, and more, to find the perfect, token-efficient context that the agent needs to code correctly. It&#039;s powered by the Exa search engine.

Examples of queries you can make with `exa-code`:
* use Exa search in python and make sure content is always livecrawled
* use correct syntax for vercel ai sdk to call gpt-5 nano asking it how are you
* how to set up a reproducible Nix Rust development environment

**‚ú® Works with Cursor and Claude Code!** Use the HTTP-based configuration format:

```json
{
  &quot;mcpServers&quot;: {
    &quot;exa&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://mcp.exa.ai/mcp&quot;,
      &quot;headers&quot;: {
        &quot;Remove-Me&quot;: &quot;Disable web_search_exa tool if you&#039;re just coding. To 100% call exa-code, say &#039;use exa-code&#039;.&quot;
      }
    }
  }
}
```

You may include your exa api key in the url like this:
```
https://mcp.exa.ai/mcp?exaApiKey=YOUREXAKEY
```

You may whitelist specific tools in the url with the `enabledTools` parameter which expects a url encoded array strings like this:
```
https://mcp.exa.ai/mcp?exaApiKey=YOUREXAKEY&amp;enabledTools=%5B%22crawling_exa%ss%5D
```

You can also use `exa-code` through [Smithery](https://smithery.ai/server/exa) without an Exa API key.

---

A Model Context Protocol (MCP) server that connects AI assistants like Claude to Exa AI&#039;s search capabilities, including web search, research tools, and our new code search feature.

## Remote Exa MCP üåê

Connect directly to Exa&#039;s hosted MCP server (instead of running it locally).

### Remote Exa MCP URL

```
https://mcp.exa.ai/mcp
```

### Claude Desktop Configuration for Remote MCP

Add this to your Claude Desktop configuration file:

```json
{
  &quot;mcpServers&quot;: {
    &quot;exa&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;-y&quot;,
        &quot;mcp-remote&quot;,
        &quot;https://mcp.exa.ai/mcp&quot;
      ]
    }
  }
}
```

### Cursor and Claude Code Configuration for Remote MCP

For Cursor and Claude Code, use this HTTP-based configuration format:

```json
{
  &quot;mcpServers&quot;: {
    &quot;exa&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://mcp.exa.ai/mcp&quot;,
      &quot;headers&quot;: {}
    }
  }
}
```

### NPM Installation

```bash
npm install -g exa-mcp-server
```

### Using Claude Code

```bash
claude mcp add exa -e EXA_API_KEY=YOUR_API_KEY -- npx -y exa-mcp-server
```

### Using Exa MCP through Smithery

To install the Exa MCP server via [Smithery](https://smithery.ai/server/exa), head over to:

[smithery.ai/server/exa](https://smithery.ai/server/exa)


## Configuration ‚öôÔ∏è

### 1. Configure Claude Desktop to recognize the Exa MCP server

You can find claude_desktop_config.json inside the settings of Claude Desktop app:

Open the Claude Desktop app and enable Developer Mode from the top-left menu bar. 

Once enabled, open Settings (also from the top-left menu bar) and navigate to the Developer Option, where you&#039;ll find the Edit Config button. Clicking it will open the claude_desktop_config.json file, allowing you to make the necessary edits. 

OR (if you want to open claude_desktop_config.json from terminal)

#### For macOS:

1. Open your Claude Desktop configuration:

```bash
code ~/Library/Application\ Support/Claude/claude_desktop_config.json
```

#### For Windows:

1. Open your Claude Desktop configuration:

```powershell
code %APPDATA%\Claude\claude_desktop_config.json
```

### 2. Add the Exa server configuration:

```json
{
  &quot;mcpServers&quot;: {
    &quot;exa&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;exa-mcp-server&quot;],
      &quot;env&quot;: {
        &quot;EXA_API_KEY&quot;: &quot;your-api-key-here&quot;
      }
    }
  }
}
```

Replace `your-api-key-here` with your actual Exa API key from [dashboard.exa.ai/api-keys](https://dashboard.exa.ai/api-keys).

### 3. Available Tools &amp; Tool Selection

The Exa MCP server includes powerful tools for developers and researchers:

#### üî• **Featured: Code Search Tool**
- **get_code_context_exa**: üÜï **NEW!** Search and get relevant code snippets, examples, and documentation from open source libraries, GitHub repositories, and programming frameworks. Perfect for finding up-to-date code documentation, implementation examples, API usage patterns, and best practices from real codebases.

#### üåê **Other Available Tools**
- **web_search_exa**: Performs real-time web searches with optimized results and content extraction.
- **company_research**: Comprehensive company research tool that crawls company websites to gather detailed information about businesses.
- **crawling**: Extracts content from specific URLs, useful for reading articles, PDFs, or any web page when you have the exact URL.
- **linkedin_search**: Search LinkedIn for companies and people using Exa AI. Simply include company names, person names, or specific LinkedIn URLs in your query.
- **deep_researcher_start**: Start a smart AI researcher for complex questions. The AI will search the web, read many sources, and think deeply about your question to create a detailed research report.
- **deep_researcher_check**: Check if your research is ready and get the results. Use this after starting a research task to see if it&#039;s done and get your comprehensive report.

You can choose which tools to enable by adding the `--tools` parameter to your Claude Desktop configuration:

#### üíª **Setup for Code Search Only** (Recommended for Developers)

```json
{
  &quot;mcpServers&quot;: {
    &quot;exa&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;-y&quot;,
        &quot;exa-mcp-server&quot;,
        &quot;--tools=get_code_context_exa,web_search_exa&quot;
      ],
      &quot;env&quot;: {
        &quot;EXA_API_KEY&quot;: &quot;your-api-key-here&quot;
      }
    }
  }
}
```

#### Specify which tools to enable:

```json
{
  &quot;mcpServers&quot;: {
    &quot;exa&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;-y&quot;,
        &quot;exa-mcp-server&quot;,
        &quot;--tools=get_code_context_exa,web_search_exa,company_research,crawling,linkedin_search,deep_researcher_start,deep_researcher_check&quot;
      ],
      &quot;env&quot;: {
        &quot;EXA_API_KEY&quot;: &quot;your-api-key-here&quot;
      }
    }
  }
}
```

For enabling multiple tools, use a comma-separated list:

```json
{
  &quot;mcpServers&quot;: {
    &quot;exa&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;-y&quot;,
        &quot;exa-mcp-server&quot;,
        &quot;--tools=get_code_context_exa,web_search_exa,company_research,crawling,linkedin_search,deep_researcher_start,deep_researcher_check&quot;
      ],
      &quot;env&quot;: {
        &quot;EXA_API_KEY&quot;: &quot;your-api-key-here&quot;
      }
    }
  }
}
```

If you don&#039;t specify any tools, all tools enabled by default will be used.

### 4. Restart Claude Desktop

For the changes to take effect:

1. Completely quit Claude Desktop (not just close the window)
2. Start Claude Desktop again
3. Look for the icon to verify the Exa server is connected

## Using via NPX

If you prefer to run the server directly, you can use npx:

```bash
# Run with all tools enabled by default
npx exa-mcp-server

# Enable specific tools only
npx exa-mcp-server --tools=web_search_exa

# Enable multiple tools
npx exa-mcp-server --tools=web_search_exa,get_code_context_exa

# List all available tools
npx exa-mcp-server --list-tools
```

---

Built with ‚ù§Ô∏è by team Exa
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[siyuan-note/siyuan]]></title>
            <link>https://github.com/siyuan-note/siyuan</link>
            <guid>https://github.com/siyuan-note/siyuan</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[A privacy-first, self-hosted, fully open source personal knowledge management software, written in typescript and golang.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/siyuan-note/siyuan">siyuan-note/siyuan</a></h1>
            <p>A privacy-first, self-hosted, fully open source personal knowledge management software, written in typescript and golang.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 38,072</p>
            <p>Forks: 2,335</p>
            <p>Stars today: 83 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;img alt=&quot;SiYuan&quot; src=&quot;https://b3log.org/images/brand/siyuan-128.png&quot;&gt;
&lt;br&gt;
&lt;em&gt;Refactor your thinking&lt;/em&gt;
&lt;br&gt;&lt;br&gt;
&lt;a title=&quot;Build Status&quot; target=&quot;_blank&quot; href=&quot;https://github.com/siyuan-note/siyuan/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/siyuan-note/siyuan/cd.yml?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;a title=&quot;Releases&quot; target=&quot;_blank&quot; href=&quot;https://github.com/siyuan-note/siyuan/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/siyuan-note/siyuan.svg?style=flat-square&amp;color=9CF&quot;&gt;&lt;/a&gt;
&lt;a title=&quot;Downloads&quot; target=&quot;_blank&quot; href=&quot;https://github.com/siyuan-note/siyuan/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/downloads/siyuan-note/siyuan/total.svg?style=flat-square&amp;color=blueviolet&quot;&gt;&lt;/a&gt;
&lt;br&gt;
&lt;a title=&quot;Docker Pulls&quot; target=&quot;_blank&quot; href=&quot;https://hub.docker.com/r/b3log/siyuan&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/b3log/siyuan.svg?style=flat-square&amp;color=green&quot;&gt;&lt;/a&gt;
&lt;a title=&quot;Docker Image Size&quot; target=&quot;_blank&quot; href=&quot;https://hub.docker.com/r/b3log/siyuan&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/image-size/b3log/siyuan.svg?style=flat-square&amp;color=ff96b4&quot;&gt;&lt;/a&gt;
&lt;a title=&quot;Hits&quot; target=&quot;_blank&quot; href=&quot;https://github.com/siyuan-note/siyuan&quot;&gt;&lt;img src=&quot;https://hits.b3log.org/siyuan-note/siyuan.svg&quot;&gt;&lt;/a&gt;
&lt;br&gt;
&lt;a title=&quot;AGPLv3&quot; target=&quot;_blank&quot; href=&quot;https://www.gnu.org/licenses/agpl-3.0.txt&quot;&gt;&lt;img src=&quot;http://img.shields.io/badge/license-AGPLv3-orange.svg?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;a title=&quot;Code Size&quot; target=&quot;_blank&quot; href=&quot;https://github.com/siyuan-note/siyuan&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/languages/code-size/siyuan-note/siyuan.svg?style=flat-square&amp;color=yellow&quot;&gt;&lt;/a&gt;
&lt;a title=&quot;GitHub Pull Requests&quot; target=&quot;_blank&quot; href=&quot;https://github.com/siyuan-note/siyuan/pulls&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-pr-closed/siyuan-note/siyuan.svg?style=flat-square&amp;color=FF9966&quot;&gt;&lt;/a&gt;
&lt;br&gt;
&lt;a title=&quot;GitHub Commits&quot; target=&quot;_blank&quot; href=&quot;https://github.com/siyuan-note/siyuan/commits/master&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/commit-activity/m/siyuan-note/siyuan.svg?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;a title=&quot;Last Commit&quot; target=&quot;_blank&quot; href=&quot;https://github.com/siyuan-note/siyuan/commits/master&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/last-commit/siyuan-note/siyuan.svg?style=flat-square&amp;color=FF9900&quot;&gt;&lt;/a&gt;
&lt;br&gt;&lt;br&gt;
&lt;a title=&quot;Twitter&quot; target=&quot;_blank&quot; href=&quot;https://twitter.com/b3logos&quot;&gt;&lt;img alt=&quot;Twitter Follow&quot; src=&quot;https://img.shields.io/twitter/follow/b3logos?label=Follow&amp;style=social&quot;&gt;&lt;/a&gt;
&lt;a title=&quot;Discord&quot; target=&quot;_blank&quot; href=&quot;https://discord.gg/dmMbCqVX7G&quot;&gt;&lt;img alt=&quot;Chat on Discord&quot; src=&quot;https://img.shields.io/discord/808152298789666826?label=Discord&amp;logo=Discord&amp;style=social&quot;&gt;&lt;/a&gt;
&lt;br&gt;&lt;br&gt;
&lt;a href=&quot;https://trendshift.io/repositories/3949&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/3949&quot; alt=&quot;siyuan-note%2Fsiyuan | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;README_zh_CN.md&quot;&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href=&quot;README_ja_JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;
&lt;/p&gt;

---

## Table of Contents

* [üí° Introduction](#-introduction)
* [üîÆ Features](#-features)
* [üèóÔ∏è Architecture and Ecosystem](#-architecture-and-ecosystem)
* [üåü Star History](#-star-history)
* [üó∫Ô∏è Roadmap](#Ô∏è-roadmap)
* [üöÄ Download Setup](#-download-setup)
  * [App Market](#app-market)
  * [Installation Package](#installation-package)
  * [Docker Hosting](#docker-hosting)
  * [Unraid Hosting](#unraid-hosting)
  * [Insider Preview](#insider-preview)
* [üèòÔ∏è Community](#Ô∏è-community)
* [üõ†Ô∏è Development Guide](#Ô∏è-development-guide)
* [‚ùì FAQ](#-faq)
  * [How does SiYuan store data?](#how-does-siyuan-store-data)
  * [Does it support data synchronization through a third-party sync disk?](#does-it-support-data-synchronization-through-a-third-party-sync-disk)
  * [Is SiYuan open source?](#is-siyuan-open-source)
  * [How to upgrade to a new version?](#how-to-upgrade-to-a-new-version)
  * [What if some blocks (such as paragraph blocks in list items) cannot find the block icon?](#what-if-some-blocks-such-as-paragraph-blocks-in-list-items-cannot-find-the-block-icon)
  * [What should I do if the data repo key is lost?](#what-should-i-do-if-the-data-repo-key-is-lost)
  * [Do I need to pay for it?](#do-i-need-to-pay-for-it)
* [üôè Acknowledgement](#-acknowledgement)
  * [Contributors](#contributors)

---

## üí° Introduction

SiYuan is a privacy-first personal knowledge management system, support fine-grained block-level reference and Markdown
WYSIWYG.

Welcome to [SiYuan English Discussion Forum](https://liuyun.io) to learn more.

![feature0.png](https://b3logfile.com/file/2024/01/feature0-1orBRlI.png)

![feature51.png](https://b3logfile.com/file/2024/02/feature5-1-uYYjAqy.png)

## üîÆ Features

Most features are free, even for commercial use.

* Content block
  * Block-level reference and two-way links
  * Custom attributes
  * SQL query embed
  * Protocol `siyuan://`
* Editor
  * Block-style
  * Markdown WYSIWYG
  * List outline
  * Block zoom-in
  * Million-word large document editing
  * Mathematical formulas, charts, flowcharts, Gantt charts, timing charts, staffs, etc.
  * Web clipping
  * PDF Annotation link
* Export
  * Block ref and embed
  * Standard Markdown with assets
  * PDF, Word and HTML
  * Copy to WeChat MP, Zhihu and Yuque
* Database
  * Table view
* Flashcard spaced repetition
* AI writing and Q/A chat via OpenAI API
* Tesseract OCR 
* Multi-tab, drag and drop to split screen
* Template snippet
* JavaScript/CSS snippet
* Android/iOS/HarmonyOS App
* Docker deployment
* [API](https://github.com/siyuan-note/siyuan/blob/master/API.md)
* Community marketplace

Some features are only available to paid members, for more details please refer to [Pricing](https://b3log.org/siyuan/en/pricing.html).

## üèóÔ∏è Architecture and Ecosystem

![SiYuan Arch](https://b3logfile.com/file/2023/05/SiYuan_Arch-Sgu8vXT.png &quot;SiYuan Arch&quot;)

| Project                                                  | Description           | Forks                                                                           | Stars                                                                                | 
|----------------------------------------------------------|-----------------------|---------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|
| [lute](https://github.com/88250/lute)                    | Editor engine         | ![GitHub forks](https://img.shields.io/github/forks/88250/lute)                 | ![GitHub Repo stars](https://img.shields.io/github/stars/88250/lute)                 |
| [chrome](https://github.com/siyuan-note/siyuan-chrome)   | Chrome/Edge extension | ![GitHub forks](https://img.shields.io/github/forks/siyuan-note/siyuan-chrome)  | ![GitHub Repo stars](https://img.shields.io/github/stars/siyuan-note/siyuan-chrome)  |
| [bazaar](https://github.com/siyuan-note/bazaar)          | Community marketplace | ![GitHub forks](https://img.shields.io/github/forks/siyuan-note/bazaar)         | ![GitHub Repo stars](https://img.shields.io/github/stars/siyuan-note/bazaar)         |
| [dejavu](https://github.com/siyuan-note/dejavu)          | Data repo             | ![GitHub forks](https://img.shields.io/github/forks/siyuan-note/dejavu)         | ![GitHub Repo stars](https://img.shields.io/github/stars/siyuan-note/dejavu)         |
| [petal](https://github.com/siyuan-note/petal)            | Plugin API            | ![GitHub forks](https://img.shields.io/github/forks/siyuan-note/petal)          | ![GitHub Repo stars](https://img.shields.io/github/stars/siyuan-note/petal)          |
| [android](https://github.com/siyuan-note/siyuan-android) | Android App           | ![GitHub forks](https://img.shields.io/github/forks/siyuan-note/siyuan-android) | ![GitHub Repo stars](https://img.shields.io/github/stars/siyuan-note/siyuan-android) |
| [ios](https://github.com/siyuan-note/siyuan-ios)         | iOS App               | ![GitHub forks](https://img.shields.io/github/forks/siyuan-note/siyuan-ios)     | ![GitHub Repo stars](https://img.shields.io/github/stars/siyuan-note/siyuan-ios)     |
| [harmony](https://github.com/siyuan-note/siyuan-harmony) | HarmonyOS App         | ![GitHub forks](https://img.shields.io/github/forks/siyuan-note/siyuan-harmony) | ![GitHub Repo stars](https://img.shields.io/github/stars/siyuan-note/siyuan-harmony) |
| [riff](https://github.com/siyuan-note/riff)              | Spaced repetition     | ![GitHub forks](https://img.shields.io/github/forks/siyuan-note/riff)           | ![GitHub Repo stars](https://img.shields.io/github/stars/siyuan-note/riff)           |

## üåü Star History

&lt;a href=&quot;https://star-history.com/#siyuan-note/siyuan&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=siyuan-note/siyuan&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=siyuan-note/siyuan&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=siyuan-note/siyuan&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## üó∫Ô∏è Roadmap

* [SiYuan development plan and progress](https://github.com/orgs/siyuan-note/projects/1)
* [SiYuan changelog](CHANGELOG.md)

## üöÄ Download Setup

It is recommended to give priority to installing through the application market on the desktop and mobile, so that you can upgrade the version with one click in the future.

### App Market

Mobile:

* [App Store](https://apps.apple.com/us/app/siyuan/id1583226508)
* [Google Play](https://play.google.com/store/apps/details?id=org.b3log.siyuan)
* [F-Droid](https://f-droid.org/packages/org.b3log.siyuan)

Desktop:

* [Microsoft Store](https://apps.microsoft.com/detail/9p7hpmxp73k4)

### Installation Package

* [B3log](https://b3log.org/siyuan/en/download.html)
* [GitHub](https://github.com/siyuan-note/siyuan/releases)

### Docker Hosting

&lt;details&gt;
&lt;summary&gt;Docker Deployment&lt;/summary&gt;

#### Overview

The easiest way to serve SiYuan on a server is to deploy it through Docker.

* Image name `b3log/siyuan`
* [Image URL](https://hub.docker.com/r/b3log/siyuan)

#### File structure

The overall program is located under `/opt/siyuan/`, which is basically the structure under the resources folder of the Electron installation package:

* appearance: icon, theme, languages
* guide: user guide document
* stage: interface and static resources
* kernel: kernel program

#### Entrypoint

The entry point is set when building the Docker image: `ENTRYPOINT [&quot;/opt/siyuan/entrypoint.sh&quot;]`. This script allows changing the `PUID` and `PGID` of the user that will run inside the container. This is especially relevant to solve permission issues when mounting directories from the host. The `PUID` (User ID) and `PGID` (Group ID) can be passed as environment variables, making it easier to ensure correct permissions when accessing host-mounted directories.

Use the following parameters when running the container with `docker run b3log/siyuan`:

* `--workspace`: Specifies the workspace folder path, mounted to the container via `-v` on the host
* `--accessAuthCode`: Specifies the access authorization code

More parameters can be found using `--help`. Here‚Äôs an example of a startup command with the new environment variables:

```bash
docker run -d \
  -v workspace_dir_host:workspace_dir_container \
  -p 6806:6806 \
  -e PUID=1001 -e PGID=1002 \
  b3log/siyuan \
  --workspace=workspace_dir_container \
  --accessAuthCode=xxx
```

* `PUID`: Custom user ID (optional, defaults to `1000` if not provided)
* `PGID`: Custom group ID (optional, defaults to `1000` if not provided)
* `workspace_dir_host`: The workspace folder path on the host
* `workspace_dir_container`: The path of the workspace folder in the container, as specified in `--workspace`
  * In alternative, it&#039;s possible to set the path via the `SIYUAN_WORKSPACE_PATH` env variable. The commandline will always have the priority, if both are set
* `accessAuthCode`: Access authorization code (please **be sure to modify**, otherwise anyone can access your data)
  * In alternative, it&#039;s possible to set the auth code via the `SIYUAN_ACCESS_AUTH_CODE` env variable. The commandline will always have the priority, if both are set
  * To disable the Access authorization code set the env variable `SIYUAN_ACCESS_AUTH_CODE_BYPASS=true`

To simplify things, it is recommended to configure the workspace folder path to be consistent on the host and container, such as having both `workspace_dir_host` and `workspace_dir_container` configured as `/siyuan/workspace`. The corresponding startup command would be:

```bash
docker run -d \
  -v /siyuan/workspace:/siyuan/workspace \
  -p 6806:6806 \
  -e PUID=1001 -e PGID=1002 \
  b3log/siyuan \
  --workspace=/siyuan/workspace/ \
  --accessAuthCode=xxx
```

#### Docker Compose

For users running Siyuan with Docker Compose, the environment variables `PUID` and `PGID` can be passed to customize the user and group IDs. Here&#039;s an example of a Docker Compose configuration:

```yaml
version: &quot;3.9&quot;
services:
  main:
    image: b3log/siyuan
    command: [&#039;--workspace=/siyuan/workspace/&#039;, &#039;--accessAuthCode=${AuthCode}&#039;]
    ports:
      - 6806:6806
    volumes:
      - /siyuan/workspace:/siyuan/workspace
    restart: unless-stopped
    environment:
      # A list of time zone identifiers can be found at https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
      - TZ=${YOUR_TIME_ZONE}
      - PUID=${YOUR_USER_PUID}  # Customize user ID
      - PGID=${YOUR_USER_PGID}  # Customize group ID
```

In this setup:

* `PUID` and `PGID` are set dynamically and passed to the container
* If these variables are not provided, the default `1000` will be used

By specifying `PUID` and `PGID` in the environment, you avoid the need to explicitly set the `user` directive (`user: &#039;1000:1000&#039;`) in the compose file. The container will dynamically adjust the user and group based on these environment variables at startup.

#### User Permissions

In the image, the `entrypoint.sh` script ensures the creation of the `siyuan` user and group with the specified `PUID` and `PGID`. Therefore, when the host creates a workspace folder, pay attention to setting the user and group ownership of the folder to match the `PUID` and `PGID` you plan to use. For example:

```bash
chown -R 1001:1002 /siyuan/workspace
```

If you use custom `PUID` and `PGID` values, the entrypoint script will ensure that the correct user and group are created inside the container, and ownership of mounted volumes will be adjusted accordingly. There‚Äôs no need to manually pass `-u` in `docker run` or `docker-compose` as the environment variables will handle the customization.

#### Hidden port

Use NGINX reverse proxy to hide port 6806, please note:

* Configure WebSocket reverse proxy `/ws`

#### Note

* Be sure to confirm the correctness of the mounted volume, otherwise the data will be lost after the container is deleted
* Do not use URL rewriting for redirection, otherwise there may be problems with authentication, it is recommended to configure a reverse proxy
* If you encounter permission issues, verify that the `PUID` and `PGID` environment variables match the ownership of the mounted directories on your host system

#### Limitations

* Does not support desktop and mobile application connections, only supports use on browsers
* Export to PDF, HTML and Word formats is not supported
* Import Markdown file is not supported

&lt;/details&gt;

### Unraid Hosting

&lt;details&gt;
&lt;summary&gt;Unraid Deployment&lt;/summary&gt;

Note: First run `chown -R 1000:1000 /mnt/user/appdata/siyuan` in the terminal

Template reference:

```
Web UI: 6806
Container Port: 6806
Container Path: /home/siyuan
Host path: /mnt/user/appdata/siyuan
PUID: 1000
PGID: 1000
Publish parameters: --accessAuthCode=******(Access authorization code)
```

&lt;/details&gt;

### Insider Preview

We release insider preview before major updates, please visit [https://github.com/siyuan-note/insider](https://github.com/siyuan-note/insider).

## üèòÔ∏è Community

* [English Discussion Forum](https://liuyun.io)
* [User community summary](https://liuyun.io/article/1687779743723)
* [Awesome SiYuan](https://github.com/siyuan-note/awesome)

## üõ†Ô∏è Development Guide

See [Development Guide](https://github.com/siyuan-note/siyuan/blob/master/.github/CONTRIBUTING.md).

## ‚ùì FAQ

### How does SiYuan store data?

The data is saved in the workspace folder, in the workspace data folder:

* `assets` is used to save all inserted assets
* `emojis` is used to save emoji images
* `snippets` is used to save code snippets
* `storage` is used to save query conditions, layouts and flashcards, etc.
* `templates` is used to save template snippets
* `widgets` is used to save widgets
* `plugins` is used to save plugins
* `public` is used to save public data
* The rest of the folders are the notebook folders created by the user, files with the suffix of `.sy` in the notebook folder are used to save the document data, and the data format is JSON

### Does it support data synchronization through a third-party sync disk?

Data synchronization through third-party synchronization disks is not supported, otherwise data may be corrupted.

Although it does not support third-party sync disks, it supports connect with third-party cloud storage (Member&#039;s privileges).

In addition, you can also consider manually exporting and importing data to achieve data synchronization:

* Desktop: &lt;kbd&gt;Settings&lt;/kbd&gt; - &lt;kbd&gt;Export&lt;/kbd&gt; - &lt;kbd&gt;Export Data&lt;/kbd&gt; / &lt;kbd&gt;Import Data&lt;/kbd&gt;
* Mobile: &lt;kbd&gt;Right column&lt;/kbd&gt; - &lt;kbd&gt;About&lt;/kbd&gt; - &lt;kbd&gt;Export Data&lt;/kbd&gt; / &lt;kbd&gt;Import Data&lt;/kbd&gt;

### Is SiYuan open source?

SiYuan is completely open source, and contributions are welcome:

* [User Interface and Kernel](https://github.com/siyuan-note/siyuan)
* [Android](https://github.com/siyuan-note/siyuan-android)
* [iOS](https://github.com/siyuan-note/siyuan-ios)
* [HarmonyOS](https://github.com/siyuan-note/siyuan-harmony)
* [Chrome Clipping Extension](https://github.com/siyuan-note/siyuan-chrome)

For more details, please refer to [Development Guide](https://github.com/siyuan-note/siyuan/blob/master/.github/CONTRIBUTING.md).

### How to upgrade to a new version?

* If installed via app store, please update via app store
* If it is installed through the installation package on the desktop, you can open the option of &lt;kbd&gt;Settings&lt;/kbd&gt; - &lt;kbd&gt;About&lt;/kbd&gt; - &lt;kbd&gt;Automatically download update installation package&lt;/kbd&gt;, so that SiYuan will automatically download The latest version of the installation package and prompts to install
* If it is installed by manual installation package, please download the installation package again to install

You can &lt;kbd&gt;Check update&lt;/kbd&gt; in &lt;kbd&gt;Settings&lt;/kbd&gt; - &lt;kbd&gt;About&lt;/kbd&gt; - &lt;kbd&gt;Current Version&lt;/kbd&gt;, or pay attention to [Official Download](https://b3log.org/siyuan/en/download.html) or [GitHub Releases](https://github.com/siyuan-note/siyuan/releases) to get the new version.

### What if some blocks (such as paragraph blocks in list items) cannot find the block icon?

The first sub-block under the list item is the block icon omitted. You can move the cursor into this block and trigger its block menu with &lt;kbd&gt;Ctrl+/&lt;/kbd&gt; .

### What should I do if the data repo key is lost?

* If the data repo key is correctly initialized on multiple devices before, the key is the same on all devices and can be set in &lt;kbd&gt;Settings&lt;/kbd&gt; - &lt;kbd&gt;About&lt;/kbd&gt; - &lt;kbd&gt;Data repo key&lt;/kbd&gt; - &lt;kbd&gt;Copy key string&lt;/kbd&gt; retrieve
* If it has not been configured correctly before (for example, the keys on multiple devices are inconsistent) or all devices are unavailable and the key string cannot be obtained, you can reset the key by following the steps below:

  1. Manually back up the data, you can use &lt;kbd&gt;Export Data&lt;/kbd&gt; or directly copy the &lt;kbd&gt;workspace/data/&lt;/kbd&gt; folder on the fil

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lobehub/lobe-chat]]></title>
            <link>https://github.com/lobehub/lobe-chat</link>
            <guid>https://github.com/lobehub/lobe-chat</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[ü§Ø Lobe Chat - an open-source, modern design AI chat framework. Supports multiple AI providers (OpenAI / Claude 4 / Gemini / DeepSeek / Ollama / Qwen), Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobe-chat">lobehub/lobe-chat</a></h1>
            <p>ü§Ø Lobe Chat - an open-source, modern design AI chat framework. Supports multiple AI providers (OpenAI / Claude 4 / Gemini / DeepSeek / Ollama / Qwen), Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 65,912</p>
            <p>Forks: 13,673</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# Lobe Chat

An open-source, modern design ChatGPT/LLMs UI/framework.&lt;br/&gt;
Supports speech synthesis, multi-modal, and extensible ([function call][docs-function-call]) plugin system.&lt;br/&gt;
One-click **FREE** deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.

**English** ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md) ¬∑ [Official Site][official-site] ¬∑ [Changelog][changelog] ¬∑ [Documents][docs] ¬∑ [Blog][blog] ¬∑ [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeChat Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Pioneering the new age of thinking and creating. Built for you, the Super Individual.&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url] &lt;br /&gt; &lt;br /&gt; &lt;a href=&quot;https://vercel.com/oss&quot;&gt; &lt;img alt=&quot;Vercel OSS Program&quot; src=&quot;https://vercel.com/oss/program-badge.svg&quot; /&gt; &lt;/a&gt;

![][image-overview]

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [üëãüèª Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [‚ú® Features](#-features)
  - [‚ú® MCP Plugin One-Click Installation](#-mcp-plugin-one-click-installation)
  - [üè™ MCP Marketplace](#-mcp-marketplace)
  - [üñ•Ô∏è Desktop App](#Ô∏è-desktop-app)
  - [üåê Smart Internet Search](#-smart-internet-search)
  - [Chain of Thought](#chain-of-thought)
  - [Branching Conversations](#branching-conversations)
  - [Artifacts Support](#artifacts-support)
  - [File Upload /Knowledge Base](#file-upload-knowledge-base)
  - [Multi-Model Service Provider Support](#multi-model-service-provider-support)
  - [Local Large Language Model (LLM) Support](#local-large-language-model-llm-support)
  - [Model Visual Recognition](#model-visual-recognition)
  - [TTS &amp; STT Voice Conversation](#tts--stt-voice-conversation)
  - [Text to Image Generation](#text-to-image-generation)
  - [Plugin System (Function Calling)](#plugin-system-function-calling)
  - [Agent Market (GPTs)](#agent-market-gpts)
  - [Support Local / Remote Database](#support-local--remote-database)
  - [Support Multi-User Management](#support-multi-user-management)
  - [Progressive Web App (PWA)](#progressive-web-app-pwa)
  - [Mobile Device Adaptation](#mobile-device-adaptation)
  - [Custom Themes](#custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [‚ö°Ô∏è Performance](#Ô∏è-performance)
- [üõ≥ Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [üì¶ Ecosystem](#-ecosystem)
- [üß© Plugins](#-plugins)
- [‚å®Ô∏è Local Development](#Ô∏è-local-development)
- [ü§ù Contributing](#-contributing)
- [‚ù§Ô∏è Sponsor](#Ô∏è-sponsor)
- [üîó More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

## üëãüèª Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![][vercel-shield-badge]][vercel-link]   | No installation or registration necessary! Visit our website to experience it firsthand.                           |
| :---------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link] | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub. |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ ‚≠êÔ∏è

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## ‚ú® Features

Transform your AI experience with LobeChat&#039;s powerful features designed for seamless connectivity, enhanced productivity, and unlimited creativity.

![][image-feat-mcp]

### ‚ú® MCP Plugin One-Click Installation

**Seamlessly Connect Your AI to the World**

Unlock the full potential of your AI by enabling smooth, secure, and dynamic interactions with external tools, data sources, and services. LobeChat&#039;s MCP (Model Context Protocol) plugin system breaks down the barriers between your AI and the digital ecosystem, allowing for unprecedented connectivity and functionality.

Transform your conversations into powerful workflows by connecting to databases, APIs, file systems, and more. Experience the freedom of AI that truly understands and interacts with your world.

[![][back-to-top]](#readme-top)

![][image-feat-mcp-market]

### üè™ MCP Marketplace

**Discover, Connect, Extend**

Browse a growing library of MCP plugins to expand your AI&#039;s capabilities and streamline your workflows effortlessly. Visit [lobehub.com/mcp](https://lobehub.com/mcp) to explore the MCP Marketplace, which offers a curated collection of integrations that enhance your AI&#039;s ability to work with various tools and services.

From productivity tools to development environments, discover new ways to extend your AI&#039;s reach and effectiveness. Connect with the community and find the perfect plugins for your specific needs.

[![][back-to-top]](#readme-top)

![][image-feat-desktop]

### üñ•Ô∏è Desktop App

**Peak Performance, Zero Distractions**

Get the full LobeChat experience without browser limitations‚Äîcomprehensive, focused, and always ready to go. Our desktop application provides a dedicated environment for your AI interactions, ensuring optimal performance and minimal distractions.

Experience faster response times, better resource management, and a more stable connection to your AI assistant. The desktop app is designed for users who demand the best performance from their AI tools.

[![][back-to-top]](#readme-top)

![][image-feat-web-search]

### üåê Smart Internet Search

**Online Knowledge On Demand**

With real-time internet access, your AI keeps up with the world‚Äînews, data, trends, and more. Stay informed and get the most current information available, enabling your AI to provide accurate and up-to-date responses.

Access live information, verify facts, and explore current events without leaving your conversation. Your AI becomes a gateway to the world&#039;s knowledge, always current and comprehensive.

[![][back-to-top]](#readme-top)

[![][image-feat-cot]][docs-feat-cot]

### [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeChat. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [üìò LobeChat Knowledge Base Launch ‚Äî From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

- **[OpenAI](https://lobechat.com/discover/provider/openai)**: OpenAI is a global leader in artificial intelligence research, with models like the GPT series pushing the frontiers of natural language processing. OpenAI is committed to transforming multiple industries through innovative and efficient AI solutions. Their products demonstrate significant performance and cost-effectiveness, widely used in research, business, and innovative applications.
- **[Ollama](https://lobechat.com/discover/provider/ollama)**: Ollama provides models that cover a wide range of fields, including code generation, mathematical operations, multilingual processing, and conversational interaction, catering to diverse enterprise-level and localized deployment needs.
- **[Anthropic](https://lobechat.com/discover/provider/anthropic)**: Anthropic is a company focused on AI research and development, offering a range of advanced language models such as Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Opus, and Claude 3 Haiku. These models achieve an ideal balance between intelligence, speed, and cost, suitable for various applications from enterprise workloads to rapid-response scenarios. Claude 3.5 Sonnet, as their latest model, has excelled in multiple evaluations while maintaining a high cost-performance ratio.
- **[Bedrock](https://lobechat.com/discover/provider/bedrock)**: Bedrock is a service provided by Amazon AWS, focusing on delivering advanced AI language and visual models for enterprises. Its model family includes Anthropic&#039;s Claude series, Meta&#039;s Llama 3.1 series, and more, offering a range of options from lightweight to high-performance, supporting tasks such as text generation, conversation, and image processing for businesses of varying scales and needs.
- **[Google](https://lobechat.com/discover/provider/google)**: Google&#039;s Gemini series represents its most advanced, versatile AI models, developed by Google DeepMind, designed for multimodal capabilities, supporting seamless understanding and processing of text, code, images, audio, and video. Suitable for various environments from data centers to mobile devices, it significantly enhances the efficiency and applicability of AI models.
- **[DeepSeek](https://lobechat.com/discover/provider/deepseek)**: DeepSeek is a company focused on AI technology research and application, with its latest model DeepSeek-V2.5 integrating general dialogue and code processing capabilities, achieving significant improvements in human preference alignment, writing tasks, and instruction following.
- **[Moonshot](https://lobechat.com/discover/provider/moonshot)**: Moonshot is an open-source platform launched by Beijing Dark Side Technology Co., Ltd., providing various natural language processing models with a wide range of applications, including but not limited to content creation, academic research, intelligent recommendations, and medical diagnosis, supporting long text processing and complex generation tasks.
- **[OpenRouter](https://lobechat.com/discover/provider/openrouter)**: OpenRouter is a service platform providing access to various cutting-edge large model interfaces, supporting OpenAI, Anthropic, LLaMA, and more, suitable for diverse development and application needs. Users can flexibly choose the optimal model and pricing based on their requirements, enhancing the AI experience.
- **[HuggingFace](https://lobechat.com/discover/provider/huggingface)**: The HuggingFace Inference API provides a fast and free way for you to explore thousands of models for various tasks. Whether you are prototyping for a new application or experimenting with the capabilities of machine learning, this API gives you instant access to high-performance models across multiple domains.
- **[Cloudflare Workers AI](https://lobechat.com/discover/provider/cloudflare)**: Run serverless GPU-powered machine learning models on Cloudflare&#039;s global network.

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+32)&lt;/kbd&gt;&lt;/summary&gt;

- **[GitHub](https://lobechat.com/discover/provider/github)**: With GitHub Models, developers can become AI engineers and leverage the industry&#039;s leading AI models.
- **[Novita](https://lobechat.com/discover/provider/novita)**: Novita AI is a platform providing a variety of large language models and AI image generation API services, flexible, reliable, and cost-effective. It supports the latest open-source models like Llama3 and Mistral, offering a comprehensive, user-friendly, and auto-scaling API solution for generative AI application development, suitable for the rapid growth of AI startups.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[302.AI](https://lobechat.com/discover/provider/ai302)**: 302.AI is an on-demand AI application platform offering the most comprehensive AI APIs and online AI applications available on the market.
- **[Together AI](https://lobechat.com/discover/provider/togetherai)**: Together AI is dedicated to achieving leading performance through innovative AI models, offering extensive customization capabilities, including rapid scaling support and intuitive deployment processes to meet various enterprise needs.
- **[Fireworks AI](https://lobechat.com/discover/provider/fireworksai)**: Fireworks AI is a leading provider of advanced language model services, focusing on functional calling and multimodal processing. Its latest model, Firefunction V2, is based on Llama-3, optimized for function calling, conversation, and instruction following. The visual language model FireLLaVA-13B supports mixed input of images and text. Other notable models include the Llama series and Mixtral series, providing efficient multilingual instruction following and generation support.
- **[Groq](https://lobechat.com/discover/provider/groq)**: Groq&#039;s LPU inference engine has excelled in the latest independent large language model (LLM) benchmarks, redefining the standards for AI solutions with its remarkable speed and efficiency. Groq represents instant inference speed, demonstrating strong performance in cloud-based deployments.
- **[Perplexity](https://lobechat.com/discover/provider/perplexity)**: Perplexity is a leading provider of conversational generation models, offering various advanced Llama 3.1 models that support both online and offline applications, particularly suited for complex natural language processing tasks.
- **[Mistral](https://lobechat.com/discover/provider/mistral)**: Mistral provides advanced general, specialized, and research models widely used in complex reasoning, multilingual tasks, and code generation. Through functional calling interfaces, users can integrate custom functionalities for specific applications.
- **[ModelScope](https://lobechat.com/discover/provider/modelscope)**: ModelScope is a model-as-a-service platform launched by Alibaba Cloud, offering a wide range of AI models and inference services.
- **[Ai21Labs](https://lobechat.com/discover/provider/ai21)**: AI21 Labs builds foundational models and AI systems for enterprises, accelerating the application of generative AI in production.
- **[Upstage](https://lobechat.com/discover/provider/upstage)**: Upstage focuses on developing AI models for various business needs, including Solar LLM and document AI, aiming to achieve artificial general intelligence (AGI) for work. It allows for the creation of simple conversational agents through Chat API and supports functional calling, translation, embedding, and domain-specific applications.
- **[xAI (Grok)](https://lobechat.com/discover/provider/xai)**: xAI is a company dedicated to building artificial intelligence to accelerate human scientific discovery. Our mission is to advance our collective understanding of the universe.
- **[Aliyun Bailian](https://lobechat.com/discover/provider/qwen)**: Tongyi Qianwen is a large-scale language model independently developed by Alibaba Cloud, featuring strong natural language understanding and generation capabilities. It can answer various questions, create written content, express opinions, and write code, playing a role in multiple fields.
- **[Wenxin](https://lobechat.com/discover/provider/wenxin)**: An enterprise-level one-stop platform for large model and AI-native application development and services, providing the most comprehensive and user-friendly toolchain for the entire pr

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ccbikai/hacker-news]]></title>
            <link>https://github.com/ccbikai/hacker-news</link>
            <guid>https://github.com/ccbikai/hacker-news</guid>
            <pubDate>Sat, 27 Sep 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[‰∏Ä‰∏™Âü∫‰∫é AI ÁöÑ Hacker News ‰∏≠ÊñáÊí≠ÂÆ¢È°πÁõÆÔºåÊØèÂ§©Ëá™Âä®ÊäìÂèñ Hacker News ÁÉ≠Èó®ÊñáÁ´†ÔºåÈÄöËøá AI ÁîüÊàê‰∏≠ÊñáÊÄªÁªìÂπ∂ËΩ¨Êç¢‰∏∫Êí≠ÂÆ¢ÂÜÖÂÆπ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ccbikai/hacker-news">ccbikai/hacker-news</a></h1>
            <p>‰∏Ä‰∏™Âü∫‰∫é AI ÁöÑ Hacker News ‰∏≠ÊñáÊí≠ÂÆ¢È°πÁõÆÔºåÊØèÂ§©Ëá™Âä®ÊäìÂèñ Hacker News ÁÉ≠Èó®ÊñáÁ´†ÔºåÈÄöËøá AI ÁîüÊàê‰∏≠ÊñáÊÄªÁªìÂπ∂ËΩ¨Êç¢‰∏∫Êí≠ÂÆ¢ÂÜÖÂÆπ„ÄÇ</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,166</p>
            <p>Forks: 180</p>
            <p>Stars today: 67 stars today</p>
            <h2>README</h2><pre># Hacker News ÊØèÊó•Êí≠Êä•

‰∏Ä‰∏™Âü∫‰∫é AI ÁöÑ Hacker News ‰∏≠ÊñáÊí≠ÂÆ¢È°πÁõÆÔºåÊØèÂ§©Ëá™Âä®ÊäìÂèñ Hacker News ÁÉ≠Èó®ÊñáÁ´†ÔºåÈÄöËøá AI ÁîüÊàê‰∏≠ÊñáÊÄªÁªìÂπ∂ËΩ¨Êç¢‰∏∫Êí≠ÂÆ¢ÂÜÖÂÆπ„ÄÇ

[&lt;img src=&quot;https://devin.ai/assets/deepwiki-badge.png&quot; alt=&quot;DeepWiki&quot; height=&quot;20&quot;/&gt;](https://deepwiki.com/ccbikai/hacker-news)

È¢ÑËßàÂú∞ÂùÄ: &lt;https://hacker-news.agi.li&gt;

ËÆ¢ÈòÖÂú∞ÂùÄ: &lt;https://hacker-news.agi.li/rss.xml&gt;

![hacker-news](https://socialify.git.ci/ccbikai/hacker-news/image?description=1&amp;forks=1&amp;name=1&amp;owner=1&amp;pattern=Circuit+Board&amp;stargazers=1&amp;theme=Auto)

---

## ‰∏ªË¶ÅÁâπÊÄß

- ü§ñ Ëá™Âä®ÊäìÂèñ Hacker News ÊØèÊó•ÁÉ≠Èó®ÊñáÁ´†
- üéØ ‰ΩøÁî® AI Êô∫ËÉΩÊÄªÁªìÊñáÁ´†ÂÜÖÂÆπÂíåËØÑËÆ∫
- üéôÔ∏è ÈÄöËøá Edge TTS ÁîüÊàê‰∏≠ÊñáÊí≠Êä•
- üì± ÊîØÊåÅÁΩëÈ°µÂíåÊí≠ÂÆ¢ App Êî∂Âê¨
- üîÑ ÊØèÊó•Ëá™Âä®Êõ¥Êñ∞
- üìù Êèê‰æõÊñáÁ´†ÊëòË¶ÅÂíåÂÆåÊï¥Êí≠Êä•ÊñáÊú¨

## ÊäÄÊúØÊ†à

- Next.js Â∫îÁî®Ê°ÜÊû∂
- Cloudflare Workers ÈÉ®ÁΩ≤ÂíåËøêË°åÁéØÂ¢É
- Edge TTS ËØ≠Èü≥ÂêàÊàê
- OpenAI API ÂÜÖÂÆπÁîüÊàê
- Tailwind CSS Ê†∑ÂºèÂ§ÑÁêÜ
- shadcn-ui ÁªÑ‰ª∂Â∫ì

## Â∑•‰ΩúÊµÅÁ®ã

1. ÂÆöÊó∂ÊäìÂèñ Hacker News ÁÉ≠Èó®ÊñáÁ´†
2. ‰ΩøÁî® AI ÁîüÊàê‰∏≠ÊñáÊëòË¶ÅÂíåÊí≠Êä•ÊñáÁ®ø
3. ÈÄöËøá TTS ËΩ¨Êç¢‰∏∫Èü≥È¢ë, ÊÑüË∞¢ [Minimax Audio](https://hailuoai.com/audio) ËµûÂä© TTS ÊúçÂä°„ÄÇ
4. Â≠òÂÇ®Âà∞ Cloudflare R2 Âíå KV
5. ÈÄöËøá RSS feed ÂíåÁΩëÈ°µÊèê‰æõËÆøÈóÆ

## Êú¨Âú∞ÂºÄÂèë

&gt; È°πÁõÆÁî±‰∏Ä‰∏™ Worker Âíå Web Á®ãÂ∫èÁªÑÊàêÔºåWorker Ë¥üË¥£ÊäìÂèñÊï∞ÊçÆÔºåÂ§ÑÁêÜÈü≥È¢ë„ÄÇ‰ΩøÁî®‰∫Ü Cloudflare ÁöÑ R2 Â≠òÂÇ®„ÄÅ KV Â≠òÂÇ®„ÄÅÂ∑•‰ΩúÊµÅÂíåÊµèËßàÂô®ÂëàÁé∞„ÄÇ
&gt; Web Á®ãÂ∫èË¥üË¥£Â±ïÁ§∫Êï∞ÊçÆÂíåÊèê‰æõ RSS ËÆ¢ÈòÖ„ÄÇ Web Á®ãÂ∫è‰ΩøÁî® Next.js ÂºÄÂèëÔºåÂèØ‰ª•Áúã‰∏ã OpenNext ÁöÑ Cloudflare ÈÄÇÈÖçÂô®„ÄÇ

1. ÂÆâË£Ö‰æùËµñ:

```bash
pnpm install
```

2. ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáè:

```bash
# .dev.vars
NEXTJS_ENV=development
NEXT_STATIC_HOST=http://localhost:3000/static

# worker/.dev.vars
WORKER_ENV=development
HACKER_NEWS_WORKER_URL=https://you-worker-url
HACKER_NEWS_R2_BUCKET_URL=https://your-bucket-url
OPENAI_API_KEY=your_api_key
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4.1

```

3. ÂêØÂä®ÂºÄÂèëÊúçÂä°Âô®:

```bash
# ÂºÄÂèëÂ∑•‰ΩúÊµÅ
pnpm dev:worker
# curl -X POST http://localhost:8787 # ÊâãÂä®Ëß¶ÂèëÂ∑•‰ΩúÊµÅ

# ÂºÄÂèë Web È°µÈù¢
pnpm dev
```

&gt; Ê≥®ÊÑèÔºö
&gt;
&gt; - Êú¨Âú∞ËøêË°åÂ∑•‰ΩúÊµÅÊó∂ÔºåEdge TTS ËΩ¨Êç¢Èü≥È¢ëÂèØËÉΩ‰ºöÂç°‰Ωè„ÄÇÂª∫ËÆÆÁõ¥Êé•Ê≥®ÈáäËØ•ÈÉ®ÂàÜ‰ª£Á†ÅËøõË°åË∞ÉËØï„ÄÇ
&gt; - Áî±‰∫éÂêàÂπ∂Èü≥È¢ëÈúÄË¶Å‰ΩøÁî® CloudFlare ÁöÑÊµèËßàÂô®Á´ØÂëàÁé∞Ôºå‰∏çÊîØÊåÅÊú¨Âú∞ÂºÄÂèëÔºåÈúÄË¶ÅËøúÁ®ãË∞ÉËØï„ÄÇ ÂèØ‰ª•‰ΩøÁî® `npm run test` ËøõË°åÊµãËØï„ÄÇ

## ÈÉ®ÁΩ≤

È°πÁõÆ‰ΩøÁî® Cloudflare Workers ÈÉ®ÁΩ≤:

1. ÂàõÂª∫ R2 Êñá‰ª∂Â≠òÂÇ®Ê°∂, ÁªëÂÆöÂüüÂêçÂêéÔºå‰øÆÊîπ `NEXT_STATIC_HOST` Âíå `HACKER_NEWS_R2_BUCKET_URL` ÂèòÈáè„ÄÇ
2. ÂàõÂª∫ KV Â≠òÂÇ®Á©∫Èó¥
3. ‰øÆÊîπ `wrangler.json` ‰∏≠ KV Âíå R2 ÁöÑÂÄº
4. ‰ΩøÁî® `wrangler` ËÑöÊâãÊû∂ÈÖçÁΩÆÁ∫ø‰∏äÁéØÂ¢ÉÁöÑÁéØÂ¢ÉÂèòÈáè:

```bash
# Êõ¥Êñ∞ Worker ÁöÑÁßÅÊúâÂèòÈáè
pnpx wrangler secret put --cwd worker HACKER_NEWS_WORKER_URL # ÁªëÂÆöÂüüÂêçÂêéÔºå‰øÆÊîπ‰∏∫ÁªëÂÆöÂüüÂêç
pnpx wrangler secret put --cwd worker HACKER_NEWS_R2_BUCKET_URL
pnpx wrangler secret put --cwd worker OPENAI_API_KEY
pnpx wrangler secret put --cwd worker OPENAI_BASE_URL
pnpx wrangler secret put --cwd worker OPENAI_MODEL

# Êõ¥Êñ∞ Web Á®ãÂ∫èÁöÑÁßÅÊúâÂèòÈáè
pnpx wrangler secret put NEXTJS_ENV # Next.JS ÁéØÂ¢ÉÔºåÂª∫ËÆÆ production
pnpx wrangler secret put NEXT_PUBLIC_BASE_URL # Web ÊúçÂä°Âú∞ÂùÄ
pnpx wrangler secret put NEXT_STATIC_HOST # ÁªëÂÆöÂüüÂêçÂêéÔºå‰øÆÊîπ‰∏∫ÁªëÂÆöÂüüÂêç
```

```bash
# ËÆ∞ÂæóÊÅ¢Â§çÊ≥®ÈáäÔºöwrangler.json ‰∏≠ÁöÑ workflows Áõ∏ÂÖ≥ÈÖçÁΩÆ
pnpm deploy:worker
pnpm deploy
```

## Ë¥°ÁåÆ

Ê¨¢ËøéÊèê‰∫§ Issue Âíå Pull Request!

## ËµûÂä©

- **[Minimax Audio](https://hailuoai.com/audio)**ÔºöËÆ©ÊñáÂ≠óÊ†©Ê†©Â¶Ç‚ÄúÂ£∞‚Äù

1. [Âú® Telegram ÂÖ≥Ê≥®Êàë](https://t.me/miantiao_me)
2. [Âú® ùïè ‰∏äÂÖ≥Ê≥®Êàë](https://404.li/x)
3. [Âú® GitHub ËµûÂä©Êàë](https://github.com/sponsors/ccbikai)

## ÂÖçË¥£Â£∞Êòé

Êú¨È°πÁõÆ‰∏é Hacker News Âíå Y Combinator Ê≤°Êúâ‰ªª‰ΩïÂÖ≥ËÅî„ÄÇ&quot;Hacker News&quot; ÊòØ Y Combinator ÁöÑÊ≥®ÂÜåÂïÜÊ†á„ÄÇ
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>