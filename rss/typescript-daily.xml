<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Wed, 18 Jun 2025 00:04:41 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[menloresearch/jan]]></title>
            <link>https://github.com/menloresearch/jan</link>
            <guid>https://github.com/menloresearch/jan</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:41 GMT</pubDate>
            <description><![CDATA[Jan is an open source alternative to ChatGPT that runs 100% offline on your computer]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/menloresearch/jan">menloresearch/jan</a></h1>
            <p>Jan is an open source alternative to ChatGPT that runs 100% offline on your computer</p>
            <p>Language: TypeScript</p>
            <p>Stars: 30,652</p>
            <p>Forks: 1,812</p>
            <p>Stars today: 196 stars today</p>
            <h2>README</h2><pre># Jan - Local AI Assistant

![Jan banner](./JanBanner.png)

&lt;p align=&quot;center&quot;&gt;
  &lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt;
  &lt;img alt=&quot;GitHub commit activity&quot; src=&quot;https://img.shields.io/github/commit-activity/m/janhq/jan&quot;/&gt;
  &lt;img alt=&quot;Github Last Commit&quot; src=&quot;https://img.shields.io/github/last-commit/janhq/jan&quot;/&gt;
  &lt;img alt=&quot;Github Contributors&quot; src=&quot;https://img.shields.io/github/contributors/janhq/jan&quot;/&gt;
  &lt;img alt=&quot;GitHub closed issues&quot; src=&quot;https://img.shields.io/github/issues-closed/janhq/jan&quot;/&gt;
  &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1107178041848909847?label=discord&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://jan.ai/docs/quickstart&quot;&gt;Getting Started&lt;/a&gt; 
  - &lt;a href=&quot;https://jan.ai/docs&quot;&gt;Docs&lt;/a&gt; 
  - &lt;a href=&quot;https://github.com/janhq/jan/releases&quot;&gt;Changelog&lt;/a&gt; 
  - &lt;a href=&quot;https://github.com/janhq/jan/issues&quot;&gt;Bug reports&lt;/a&gt; 
  - &lt;a href=&quot;https://discord.gg/AsJ8krTT3N&quot;&gt;Discord&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
⚠️ &lt;b&gt; Jan is currently in Development&lt;/b&gt;: Expect breaking changes and bugs!
&lt;/p&gt;


Jan is a ChatGPT-alternative that runs 100% offline on your device. Our goal is to make it easy for a layperson to download and run LLMs and use AI with **full control** and **privacy**.

Jan is powered by [Cortex](https://github.com/janhq/cortex.cpp), our embeddable local AI engine that runs on any hardware.
From PCs to multi-GPU clusters, Jan &amp; Cortex supports universal architectures:

- [x] NVIDIA GPUs (fast)
- [x] Apple M-series (fast)
- [x] Apple Intel
- [x] Linux Debian
- [x] Windows x64

#### Features:
- [Model Library](https://jan.ai/docs/models/manage-models#add-models) with popular LLMs like Llama, Gemma, Mistral, or Qwen 
- Connect to [Remote AI APIs](https://jan.ai/docs/remote-models/openai) like Groq and OpenRouter
- Local API Server with OpenAI-equivalent API
- [Extensions](https://jan.ai/docs/extensions) for customizing Jan

## Download

&lt;table&gt;
  &lt;tr style=&quot;text-align:center&quot;&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;&lt;b&gt;Version Type&lt;/b&gt;&lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;&lt;b&gt;Windows&lt;/b&gt;&lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;&lt;b&gt;MacOS Universal&lt;/b&gt;&lt;/td&gt;
    &lt;td colspan=&quot;2&quot; style=&quot;text-align:center&quot;&gt;&lt;b&gt;Linux&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr style=&quot;text-align:center&quot;&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;&lt;b&gt;Stable (Recommended)&lt;/b&gt;&lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/latest/win-x64&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/windows.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.exe&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/latest/mac-universal&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/mac.png&#039; style=&quot;height:15px; width: 15px&quot; /&gt;
        &lt;b&gt;jan.dmg&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/latest/linux-amd64-deb&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/linux.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.deb&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/latest/linux-amd64-appimage&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/linux.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.AppImage&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr style=&quot;text-align:center&quot;&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;&lt;b&gt;Beta (Preview)&lt;/b&gt;&lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/beta/win-x64&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/windows.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.exe&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/beta/mac-universal&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/mac.png&#039; style=&quot;height:15px; width: 15px&quot; /&gt;
        &lt;b&gt;jan.dmg&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/beta/linux-amd64-deb&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/linux.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.deb&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/beta/linux-amd64-appimage&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/linux.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.AppImage&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr style=&quot;text-align:center&quot;&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;&lt;b&gt;Nightly Build (Experimental)&lt;/b&gt;&lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/nightly/win-x64&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/windows.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.exe&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/nightly/mac-universal&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/mac.png&#039; style=&quot;height:15px; width: 15px&quot; /&gt;
        &lt;b&gt;jan.dmg&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/nightly/linux-amd64-deb&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/linux.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.deb&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/nightly/linux-amd64-appimage&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/linux.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.AppImage&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

Download the latest version of Jan at https://jan.ai/ or visit the [GitHub Releases](https://github.com/janhq/jan/releases) to download any previous release.

## Demo

https://github.com/user-attachments/assets/c3592fa2-c504-4d9d-a885-7e00122a50f3

*Real-time Video: Jan v0.5.7 on a Mac M2, 16GB Sonoma 14.2*

## Quicklinks

### Jan

- [Jan Website](https://jan.ai/)
- [Jan GitHub](https://github.com/janhq/jan)
- [Documentation](https://jan.ai/docs)
- [Jan Changelog](https://jan.ai/changelog)
- [Jan Blog](https://jan.ai/blog)

### Cortex.cpp
Jan is powered by **Cortex.cpp**. It is a C++ command-line interface (CLI) designed as an alternative to [Ollama](https://ollama.com/). By default, it runs on the llama.cpp engine but also supports other engines, including ONNX and TensorRT-LLM, making it a multi-engine platform.


- [Cortex Website](https://cortex.so/)
- [Cortex GitHub](https://github.com/janhq/cortex.cpp)
- [Documentation](https://cortex.so/docs/)
- [Models Library](https://cortex.so/models)
- API Reference: *Under development*
  
## Requirements for running Jan

- **MacOS**: 13 or higher
- **Windows**:
  - Windows 10 or higher
  - To enable GPU support:
    - Nvidia GPU with CUDA Toolkit 11.7 or higher
    - Nvidia driver 470.63.01 or higher
- **Linux**:
  - glibc 2.27 or higher (check with `ldd --version`)
  - gcc 11, g++ 11, cpp 11 or higher, refer to this [link](https://jan.ai/guides/troubleshooting/gpu-not-used/#specific-requirements-for-linux) for more information
  - To enable GPU support:
    - Nvidia GPU with CUDA Toolkit 11.7 or higher
    - Nvidia driver 470.63.01 or higher

## Troubleshooting

As Jan is in development mode, you might get stuck on a some common issues:
- [Troubleshooting a broken build](https://jan.ai/docs/troubleshooting#broken-build)
- [Troubleshooting NVIDIA GPU](https://jan.ai/docs/troubleshooting#troubleshooting-nvidia-gpu)
- [Troubleshooting Something&#039;s Amiss](https://jan.ai/docs/troubleshooting#somethings-amiss)


If you can&#039;t find what you need in our troubleshooting guide, feel free reach out to us for extra help:
1. Copy your [error logs &amp; device specifications](https://jan.ai/docs/troubleshooting#how-to-get-error-logs).
2. Go to our [Discord](https://discord.com/invite/FTk2MvZwJH) &amp; send it to **#🆘|get-help** channel for further support.

*Check the logs to ensure the information is what you intend to send. Note that we retain your logs for only 24 hours, so report any issues promptly.*
  

## Contributing

Contributions are welcome! Please read the [CONTRIBUTING.md](CONTRIBUTING.md) file

### Pre-requisites

- node &gt;= 20.0.0
- yarn &gt;= 1.22.0
- make &gt;= 3.81

### Instructions

1. **Clone the repository and prepare:**

   ```bash
   git clone https://github.com/janhq/jan
   cd jan
   git checkout -b DESIRED_BRANCH
   ```

2. **Run development and use Jan Desktop**

   ```bash
   make dev
   ```

This will start the development server and open the desktop app.



### For production build

```bash
# Do steps 1 and 2 in the previous section
# Build the app
make build
```

This will build the app MacOS m1/m2 for production (with code signing already done) and put the result in `dist` folder.

## Acknowledgements

Jan builds on top of other open-source projects:

- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [LangChain](https://github.com/langchain-ai)
- [TensorRT](https://github.com/NVIDIA/TensorRT)
- [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM)

## Contact

- Bugs &amp; requests: file a GitHub ticket
- For discussion: join our Discord [here](https://discord.gg/FTk2MvZwJH)
- For business inquiries: email hello@jan.ai 
- For jobs: please email hr@jan.ai

## Trust &amp; Safety

Beware of scams!

- We will never request your personal information.
- Our product is completely free; no paid version exists.
- We do not have a token or ICO.
- We are a [bootstrapped company](https://en.wikipedia.org/wiki/Bootstrapping), and don&#039;t have any external investors (*yet*). We&#039;re open to exploring opportunities with strategic partners want to tackle [our mission](https://jan.ai/about#mission) together.

## License

Jan is free and open source, under the **AGPLv3** license.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[continuedev/continue]]></title>
            <link>https://github.com/continuedev/continue</link>
            <guid>https://github.com/continuedev/continue</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:40 GMT</pubDate>
            <description><![CDATA[⏩ Create, share, and use custom AI code assistants with our open-source IDE extensions and hub of models, rules, prompts, docs, and other building blocks]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/continuedev/continue">continuedev/continue</a></h1>
            <p>⏩ Create, share, and use custom AI code assistants with our open-source IDE extensions and hub of models, rules, prompts, docs, and other building blocks</p>
            <p>Language: TypeScript</p>
            <p>Stars: 27,060</p>
            <p>Forks: 2,974</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![Continue logo](media/readme.png)

&lt;/div&gt;

&lt;h1 align=&quot;center&quot;&gt;Continue&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;

**[Continue](https://docs.continue.dev) enables developers to create, share, and use custom AI code assistants with our
open-source [VS Code](https://marketplace.visualstudio.com/items?itemName=Continue.continue)
and [JetBrains](https://plugins.jetbrains.com/plugin/22707-continue-extension) extensions
and [hub of models, rules, prompts, docs, and other building blocks](https://hub.continue.dev)**

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;a target=&quot;_blank&quot; href=&quot;https://opensource.org/licenses/Apache-2.0&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot; style=&quot;height: 22px;&quot; /&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://docs.continue.dev&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/continue_docs-%23BE1B55&quot; style=&quot;height: 22px;&quot; /&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://changelog.continue.dev&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/changelog-%96EFF3&quot; style=&quot;height: 22px;&quot; /&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://discord.gg/vapESyrFmJ&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/discord-join-continue.svg?labelColor=191937&amp;color=6F6FF7&amp;logo=discord&quot; style=&quot;height: 22px;&quot; /&gt;
&lt;/a&gt;

&lt;p&gt;&lt;/p&gt;

## Agent

[Agent](https://continue.dev/docs/agent/how-to-use-it) enables you to make more substantial changes to your codebase

![agent](docs/static/img/agent.gif)

## Chat

[Chat](https://continue.dev/docs/chat/how-to-use-it) makes it easy to ask for help from an LLM without needing to leave
the IDE

![chat](docs/static/img/chat.gif)

## Autocomplete

[Autocomplete](https://continue.dev/docs/autocomplete/how-to-use-it) provides inline code suggestions as you type

![autocomplete](docs/static/img/autocomplete.gif)

## Edit

[Edit](https://continue.dev/docs/edit/how-to-use-it) is a convenient way to modify code without leaving your current
file

![edit](docs/static/img/edit.gif)

&lt;/div&gt;

## Getting Started

Learn about how to install and use Continue in the docs [here](https://continue.dev/docs/getting-started/install)

## Contributing

Read the [contributing guide](https://github.com/continuedev/continue/blob/main/CONTRIBUTING.md), and
join [#contribute on Discord](https://discord.gg/vapESyrFmJ).

## License

[Apache 2.0 © 2023-2024 Continue Dev, Inc.](./LICENSE)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ever-co/ever-gauzy]]></title>
            <link>https://github.com/ever-co/ever-gauzy</link>
            <guid>https://github.com/ever-co/ever-gauzy</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:39 GMT</pubDate>
            <description><![CDATA[Ever® Gauzy™ - Open Business Management Platform (ERP/CRM/HRM/ATS/PM) - https://gauzy.co]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ever-co/ever-gauzy">ever-co/ever-gauzy</a></h1>
            <p>Ever® Gauzy™ - Open Business Management Platform (ERP/CRM/HRM/ATS/PM) - https://gauzy.co</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,757</p>
            <p>Forks: 624</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre># Ever Gauzy Platform

[uri_gauzy]: https://gauzy.co
[uri_license]: https://www.gnu.org/licenses/agpl-3.0.html
[uri_license_image]: https://img.shields.io/badge/License-AGPL%20v3-blue.svg

![visitors](https://visitor-badge.laobi.icu/badge?page_id=ever-co.gauzy-platform)
[![License: AGPL v3][uri_license_image]][uri_license]
[![Gitpod Ready-to-Code](https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod)](https://gitpod.io/#https://github.com/ever-co/ever-gauzy)

## 💡 What&#039;s New

We released [Ever Teams](https://github.com/ever-co/ever-teams) platform for Work &amp; Project Management.
Please check &lt;https://github.com/ever-co/ever-teams&gt; and make it ⭐ on GitHub!
It&#039;s built with a React (NextJs) / ReactNative (Expo) stack and connects to headless [Ever Gauzy Platform APIs](https://api.gauzy.co/docs).

## 🌟 What is it

[Ever® Gauzy™][uri_gauzy] - **Open Business Management Platform** for Collaborative, On-Demand and Sharing Economies.

-   **Enterprise Resource Planning** (ERP)
-   **Customer Relationship Management** (CRM)
-   **Human Resource Management** (HRM)
-   **Applicant Tracking System** (ATS)
-   **Work and Project Management** (PM)
-   **Employee Time-Tracking, Activity &amp; Productivity Tracking**

![overview](https://docs.gauzy.co/overview.png)

Ever® Gauzy™ Platform is a part of our larger Open Platform for **Collaborative, On-Demand and Sharing Economies** - [Ever® Platform™](https://ever.co).

## ✨ Features

Main features:

-   Human Resources Management (HRM) with Time Management / Tracking and Employees Performance Monitoring
-   Customer Relationship Management (CRM)
-   Enterprise Resource Planning (ERP)
-   Projects / Tasks Management
-   Sales Management
-   Financial and Cost Management (including _Accounting_, _Invoicing_, etc)
-   Inventory, Supply Chain Management, and Production Management

A more detailed list of the features available in the platform:

-   [Headless APIs](https://api.gauzy.co/docs)
-   Dashboard (provides an overview of different metrics, such as company income/expenses, employee bonuses, etc.)
-   Time Management / Time Tracking / Activity Tracking / Timesheets
-   Employees Management (register of company employees/contractors, rates of employees, etc.)
-   Employee Onboarding
-   Applicant Tracking System (ATS) / Candidates Interviews
-   Contacts Management (Clients / Customers / Leads / etc.)
-   Schedules / Appointments / Events
-   Project Management / Tasks
-   Goals / KPI / Objectives / Key Results
-   Sales Pipelines
-   Proposals
-   Accounting / Invoicing / Estimates
-   Billing
-   Payments
-   Income / Expenses Management
-   Time Off Management / Holidays / Approvals
-   Inventory
-   Equipment / Sharing
-   Multiple Organizations Management
-   Organization Departments and Teams
-   Organization Clients and Vendors
-   Help Center / Knowledge Base
-   Tags / Labels
-   Reports / Insights / Analytics
-   Organization and Employee Public Pages
-   Integrations (Upwork, HubStaff, etc.)
-   Email History / Email Templates
-   Data Import / Export
-   Roles / Permissions
-   Multi-currency
-   Multi-lingual
-   Dark / Light / Corporate / Material and other Themes

Read more [about Gauzy](https://github.com/ever-co/ever-gauzy/wiki/About-Gauzy) and [how to use it](https://github.com/ever-co/ever-gauzy/wiki/How-to-use-Gauzy) at your company, on-demand business, freelance business, agency, studio or in-house teams.

## 🌼 Screenshots

&lt;details&gt;
&lt;summary&gt;Show / Hide Screenshots&lt;/summary&gt;

### Web UI

![overview](https://docs.gauzy.co/overview.png)

### Desktop Timer UI (Standard)

![timer](https://docs.gauzy.co/desktop/desktop-timer-small.png)

### Desktop Timer UI (Expanded)

![timer](https://docs.gauzy.co/desktop/desktop-timer-expanded.png)

&lt;/details&gt;

## 🔗 Links

-   **&lt;https://gauzy.co&gt;** - check more information about the platform at the official website.
-   **&lt;https://app.gauzy.co&gt;** - SaaS (Important: it&#039;s currently in Alpha version/testing mode, please use it cautiously).
-   **&lt;https://demo.gauzy.co&gt;** - Online Demo (see more info below).
-   **&lt;https://gauzy.co/downloads&gt;** - Download Platform &amp; Apps (see also more info below about available downloads).
-   **&lt;https://docs.gauzy.co&gt;** - Platform Documentation (WIP). See also our [Wiki](https://github.com/ever-co/ever-gauzy/wiki).
-   **&lt;https://ever.co&gt;** - get more information about our company products.

## 📊 Activity

![Alt](https://repobeats.axiom.co/api/embed/7c6f6c3bf56fd91647549cf4ae70af49ed5ee106.svg &#039;Repobeats analytics image&#039;)

## 💻 Demo, Downloads, Testing and Production

### Demo

Ever Gauzy Platform Demo at &lt;https://demo.gauzy.co&gt;.

Notes:

-   Default super-admin user login is `admin@ever.co` and the password is `admin`
-   Content of demo DB resets on each deployment to the demo environment (usually daily)
-   Demo environment deployed using CI/CD from the `develop` branch

### Downloads

You can download Gauzy Platform, Gauzy Server, or Desktop Apps (Windows/Mac/Linux) from the official [Downloads](https://web.gauzy.co/downloads) page.

In addition, all downloads are also available from the following pages:

-   [Platform Releases](https://github.com/ever-co/ever-gauzy/releases)
-   [Server Releases](https://github.com/ever-co/ever-gauzy-server/releases)
-   [Desktop App Releases](https://github.com/ever-co/ever-gauzy-desktop/releases)
-   [Desktop Timer App Releases](https://github.com/ever-co/ever-gauzy-desktop-timer/releases)

### Production (SaaS)

Ever® Gauzy™ Platform SaaS is available at &lt;https://app.gauzy.co&gt;.

Note: it&#039;s currently in Alpha version/testing mode, please use it cautiously!

### Staging

-   Gauzy Platform Staging builds (using CI/CD, from the `stage` branch) are available at &lt;https://stage.gauzy.co&gt;
-   We are using the Staging environment to test releases before they are deployed to the production environment
-   Our pre-releases of desktop/server apps are built from this environment and can be configured manually (in settings) to connect to Stage API: &lt;https://apistage.gauzy.co&gt;

### Server &amp; Desktop Apps

We have Gauzy Server and two Desktop Apps (for Windows/Mac/Linux):

-   Ever® Gauzy™ Server - includes Gauzy API, SQLite DB (or connects to external PostgreSQL) and serves Guazy frontend. It allows to quickly run Gauzy Server for multiple clients (browser-based or Desktop-based). It&#039;s a recommended option if you want to setup the Ever Gauzy Platform in small to medium organizations.

-   Ever® Gauzy™ Desktop App - includes Gauzy frontend (UI), Gauzy API, SQLite DB, etc., all-in-one! It allows to quickly run the whole Gauzy solution locally, both UI and Timer (for time tracking, optionally of course). In addition, it allows you to connect to the external database (e.g. PostgreSQL) or external API (if you have Gauzy Server with API / DB installed on a different computer or if you want to connect to our live API). It&#039;s a recommended option if you want to try Gauzy quickly / for personal use or if you want to connect to Gauzy Server in the &quot;client-server&quot; configuration (and use Desktop App instead of web browser).

-   Ever® Gauzy™ Desktop Timer App - allows running Time and Activity Tracking for employees/contractors with screenshots and activity monitoring. It is recommended to setup by organization employees as long as they are not interested in other Gauzy Platform features (e.g. accounting) and only need to track work time.

More information about our Server &amp; Desktop Apps:

-   Download for your OS from the official [Downloads](https://web.gauzy.co/downloads) page or see the section &quot;Download&quot; above for other links to our releases pages.
-   Setup Gauzy Server with default choices in Setup Wizard and run it.
-   You can also setup Gauzy Desktop App (can run independently or connect to Gauzy Server) or Gauzy Desktop Timer App (should be connected to Gauzy Server)
-   You can login with `admin@ever.co` and password `admin` to check Admin functionality if you installed Gauzy Server or Gauzy Desktop App. Note: such an Admin user is not an employee, so you will not be able to track time.
-   You can login with `employee@ever.co` and password `123456` to check Employee-related functionality in Gauzy UI or to run Desktop Timer from an &quot;Employee&quot; perspective (such a user is an Employee and can track time).
-   If you install Gauzy Server, it is possible to connect to it using a browser (by default on &lt;http://localhost:4200&gt;) or using Gauzy Desktop Apps (make sure to configure Desktop apps to connect to Gauzy API on &lt;http://127.0.0.1:3000/api&gt; because it&#039;s where Gauzy Server API runs by default).
-   You can read more information about our Desktop Apps on the [Desktop Apps Wiki Page](https://github.com/ever-co/ever-gauzy/wiki/Gauzy-Desktop-Apps) and our Server at the [Server Wiki Page](https://github.com/ever-co/ever-gauzy/wiki/Gauzy-Server).

## 🧱 Technology Stack and Requirements

-   [TypeScript](https://www.typescriptlang.org)
-   [NodeJs](https://nodejs.org) / [NestJs](https://github.com/nestjs/nest)
-   [Nx](https://nx.dev) / [Lerna](https://github.com/lerna/lerna)
-   [Angular](https://angular.io) / [RxJS](http://reactivex.io/rxjs) / [Ngx-admin](https://github.com/akveo/ngx-admin)
-   [TypeORM](https://github.com/typeorm/typeorm) / [MikroORM](https://github.com/mikro-orm/mikro-orm) / [Knex](https://github.com/knex/knex)

For Production, we recommend:

-   [PostgreSQL](https://www.postgresql.org) or [MySQL](https://dev.mysql.com)
-   [Kubernetes](https://kubernetes.io), [Docker](https://www.docker.com)

Note: thanks to TypeORM / MikroORM, Gauzy will support lots of DBs: SQLite (default, for demos), PostgreSQL (development/production), MySql (development/production), MariaDb, CockroachDb, MS SQL, Oracle, MongoDb, and others (with minimal changes).

#### See also README.md and CREDITS.md files in relevant folders for lists of libraries and software included in the Platform, information about licenses, and other details

## 📄 Documentation

Please refer to our official [Platform Documentation](https://docs.gauzy.co) and our [Wiki](https://github.com/ever-co/ever-gauzy/wiki) (WIP).

## 🚀 Quick Start

### With Docker Compose

-   Clone repo.
-   Make sure you have the latest Docker Compose [installed locally](https://docs.docker.com/compose/install). Important: you need a minimum [v2.20](https://docs.docker.com/compose/release-notes/#2200).

#### Demo

-   Run `docker-compose -f docker-compose.demo.yml up`, if you want to run the platform in basic configuration (e.g. for Demo / explore functionality / quick run) using our prebuilt Docker images. Check `.env.demo.compose` file for different settings (optionally), e.g. DB type. _(Note: Docker Compose will use latest images pre-build automatically from head of `master` branch using GitHub CI/CD.)_
-   Open &lt;http://localhost:4200&gt; in your browser.
-   Login with email `admin@ever.co` and password: `admin` for Super Admin user.
-   Login with email `employee@ever.co` and password: `123456` for Employee user.
-   Enjoy!

#### Production

-   Edit `.env.compose` (if needed) to use your custom settings, e.g. DB type.
-   Run `docker-compose up -d`, if you want to run the platform in minimal production configuration using our prebuilt Docker images. _(Note: Docker Compose will use latest images pre-build automatically from head of `master` branch using GitHub CI/CD.)_

Note: we recommend using Kubernetes for production workloads instead of Docker Compose!

#### Build

-   Edit `.env.compose` (if needed) to use your custom settings, e.g. DB type.
-   Run `docker-compose -f docker-compose.build.yml up -d `, if you want to build everything (code and Docker images) locally. _(Note: this is extremely long process because it builds whole platform locally. Other options above are much faster!)_
-   :coffee: time... It might take some time for our API to seed fake data in the DB during the first Docker Compose run, even if you used prebuilt Docker images.

Notes:

-   while demo `docker-compose.demo.yml` runs a minimum amount of containers (API, Web UI, and DB), other Docker Compose files run multiple infrastructure dependencies (see full list below).
-   you can also run ONLY infra dependencies (without our API / Web containers) with `docker-compose -f docker-compose.infra.yml up -d` command. We already doing it using `include` in our main docker compose files.
-   you can add something like `--env-file .env.something` to the docker-compose `up` command to instruct Docker Compose to use a specific `.env.something` file with your custom settings

Together with Gauzy, the Docker Compose commands described above for Production (`docker-compose.yml`) and Build (`docker-compose.build.yml`) will run the following infrastructure components:

-   [PostgreSQL](https://www.postgresql.org) - Primary Database.
-   [Pgweb](https://github.com/sosedoff/pgweb) - Cross-platform client for PostgreSQL DBs, available on &lt;http://localhost:8081&gt;.
-   [OpenSearch](https://github.com/opensearch-project) - Search Engine.
-   [OpenSearch Dashboards](https://github.com/opensearch-project) - Search Engine Dashboards, available on &lt;http://localhost:5601&gt;. Default username: `admin` and password: `Gauzy_password_123`
-   [Dejavu](https://github.com/appbaseio/dejavu) - Web UI for OpenSearch, available on &lt;http://localhost:1358&gt;.
-   [MinIO](https://github.com/minio/minio) - Multi-Cloud ☁️ Object Storage (AWS S3 compatible).
-   [Jitsu](https://github.com/jitsucom/jitsu) - Jitsu is an open-source Segment alternative (data ingestion engine).
-   [Redis](https://github.com/redis/redis) - In-memory data store/caching (also used by Jitsu)
-   [Cube](https://github.com/cube-js/cube) - &quot;Semantic Layer&quot; used for Reports, Dashboards, Analytics, and other BI-related features, with UI available on &lt;http://localhost:4000&gt;.
-   [Zipkin](https://github.com/openzipkin/zipkin) - distributed tracing system.

### Manually

#### Required

-   Install [NodeJs](https://nodejs.org/en/download) LTS version or later, e.g. 18.x.
-   Install [Yarn](https://github.com/yarnpkg/yarn) (if you don&#039;t have it) with `npm i -g yarn`.
-   Install NPM packages and Bootstrap solution using the command `yarn bootstrap`.
-   If you will need to make code changes (and push to Git repo), please run `yarn prepare:husky`.
-   Adjust settings in the [`.env.local`](https://github.com/ever-co/ever-gauzy/blob/develop/.env.local) which is used in local runs.
-   Alternatively, you can copy [`.env.sample`](https://github.com/ever-co/ever-gauzy/blob/develop/.env.sample) to `.env` and change default settings there, e.g. database type, name, user, password, etc.
-   Run both API and UI with a single command: `yarn start`.
-   Open Gauzy UI on &lt;http://localhost:4200&gt; in your browser (API runs on &lt;http://localhost:3000/api&gt;).
-   Login with email `admin@ever.co` and password: `admin` for Super Admin user.
-   Login with email `employee@ever.co` and password: `123456` for Employee user.
-   Enjoy!

Notes:

-   during the first API start, DB will be automatically seeded with a minimum set of initial data if no users are found.
-   you can run seed any moment manually (e.g. if you changed entities schemas) with the `yarn seed` command to re-initialize DB (warning: unsafe for production!).
-   it is possible to run generation of extremely large amounts of fake data for demo purposes/testing with `yarn seed:all` (warning: takes ~10 min to complete)

#### Optional / Recommended for Production

-   Optionally (recommended for production) install and run [PostgreSQL](https://www.postgresql.org) version 14 or later (16.x recommended for production). Note: other DB can be configured manually in TypeORM / MikroORM / Knex. The default DB is set to SQLite (recommended for testing/demo purposes only).
-   Optionally (recommended for production) install and run [Redis](https://github.com/redis/redis). Notes: the platform will work without Redis using an in-memory caching strategy instead of a distributed one (recommended for testing/demo purposes only). Please note however that Redis is required for Jitsu.
-   Optionally (recommended for production) install and run [OpenSearch](https://github.com/opensearch-project). Note: the platform will work without OpenSearch using DB build-in search capabilities (recommended for testing/demo purposes only).
-   Optionally install and run [MinIO](https://github.com/minio/minio) or [LocalStack](https://github.com/localstack/localstack). Note: the platform will work without MinIO / LocalStack or other S3-compatible storage using local filesystem-based storage (recommended for testing/demo purposes only). For production, we recommend using Wasabi or AWS S3 storage or another S3-compatible cloud storage.
-   Optionally (recommended for production) install and run [Jitsu](https://github.com/jitsucom/jitsu). Note: the platform will work without Jitsu, however, data ingestion will be disabled for additional analyses / real-time pipelines.
-   Optionally (recommended for production) install and run [Cube](https://github.com/cube-js/cube). Note: the platform will work without Cube, however some advanced (dynamic) reporting and data processing capabilities will be disabled.

### Production

#### General information

-   See [Setup Gauzy for Client Server](https://github.com/ever-co/ever-gauzy/wiki/Setup-Gauzy-for-Client-Server) for more information about production setup on your servers.

#### Kubernetes

-   We recommend deploying to Kubernetes (k8s), either manually (see below) or with our [Terraform Modules](https://github.com/ever-co/ever-gauzy-terraform) or [Ever Helm Charts](https://github.com/ever-co/ever-charts).
-   For more simple deployment scenarios with k8s, please see [Kubernetes configurations](https://github.com/ever-co/ever-gauzy/tree/develop/.deploy/k8s), which we are using to deploy Gauzy into [DigitalOcean k8s cluster](https://www.digitalocean.com/products/kubernetes).

#### DigitalOcean App Platform

-   For the most simple deployment scenarios (e.g. for yourself or your small organization), check our [DigitalOcean App Platform configurations](https://github.com/ever-co/ever-gauzy/tree/develop/.do) and corresponding [GitHub Action](https://github.com/ever-co/ever-gauzy/blob/develop/.github/workflows/deploy-do-app-platform-stage.yml).

#### Virtual Instances / Droplets (via SSH)

-   Another variant to deploy Gauzy is to use DigitalOcean Droplets or any other virtual instance (with Ubuntu OS) and deploy using SCP/SSH, for example, following [GitHub Action](https://github.com/ever-co/ever-gauzy/blob/develop/.github/workflows/deploy-do-droplet-demo.yml)

#### Pulumi

-   In addition, check [Gauzy Pulumi](https://github.com/ever-co/ever-gauzy-pulumi) project (WIP), it makes complex Clouds deployments possible with a single command (`pulumi up`). Note: it currently supports AWS EKS (Kubernetes) for development and production with Application Load Balancers and AWS RDS Serverless PostgreSQL DB deployments. We also implemented deployments to ECS EC2 and Fargate Clusters in the same Pulumi project.

## 💌 Contact Us

-   [Ever.co Website Contact Us page](https://ever.co/contacts)
-   [Slack Community](https://join.slack.com/t/gauzy/shared_invite/enQtNzc5MTA5MDUwODg2LTI0MGEwYTlmNWFlNzQzMzBlOWExNTk0NzAyY2IwYWYwMzZjMTliYjMwNDI3NTJmYmM4MDQ4NDliMDNiNDY1NWU)
-   [Discord Chat](https://discord.gg/hKQfn4j)
-   [![Join the community on Spectrum](https://withspectrum.github.io/badge/badge.svg)](https://spectrum.chat/gauzy)
-   [![Gitter](https://badges.gitter.im/JoinChat.svg)](https://gitter.im/ever-co/ever-gauzy?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge)
-   [![Get help on Codementor](https://cdn.codementor.io/badges/get_help_github.svg)](https://www.codementor.io/evereq?utm_source=github&amp;utm_medium=button&amp;utm_term=evereq&amp;utm_campaign=github)
-   For business inquiries: &lt;mailto:gauzy@ever.co&gt;
-   Please report security vulnerabilities to &lt;mailto:security@

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[musistudio/claude-code-router]]></title>
            <link>https://github.com/musistudio/claude-code-router</link>
            <guid>https://github.com/musistudio/claude-code-router</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:38 GMT</pubDate>
            <description><![CDATA[Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/musistudio/claude-code-router">musistudio/claude-code-router</a></h1>
            <p>Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 599</p>
            <p>Forks: 53</p>
            <p>Stars today: 51 stars today</p>
            <h2>README</h2><pre># Claude Code Router

&gt; This is a tool for routing Claude Code requests to different models, and you can customize any request.


![](screenshoots/claude-code.png)

## Usage

1. Install Claude Code

```shell
npm install -g @anthropic-ai/claude-code
```

2. Install Claude Code Router

```shell
npm install -g @musistudio/claude-code-router
```

3. Start Claude Code by claude-code-router

```shell
ccr code
```

4. Configure routing[optional]    
Set up your `~/.claude-code-router/config.json` file like this:
```json
{
  &quot;OPENAI_API_KEY&quot;: &quot;sk-xxx&quot;,
  &quot;OPENAI_BASE_URL&quot;: &quot;https://api.deepseek.com&quot;,
  &quot;OPENAI_MODEL&quot;: &quot;deepseek-chat&quot;,
  &quot;Providers&quot;: [
    {
      &quot;name&quot;: &quot;openrouter&quot;,
      &quot;api_base_url&quot;: &quot;https://openrouter.ai/api/v1&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [
        &quot;google/gemini-2.5-pro-preview&quot;,
        &quot;anthropic/claude-sonnet-4&quot;,
        &quot;anthropic/claude-3.5-sonnet&quot;,
        &quot;anthropic/claude-3.7-sonnet:thinking&quot;
      ]
    },
    {
      &quot;name&quot;: &quot;deepseek&quot;,
      &quot;api_base_url&quot;: &quot;https://api.deepseek.com&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;deepseek-reasoner&quot;]
    },
    {
      &quot;name&quot;: &quot;ollama&quot;,
      &quot;api_base_url&quot;: &quot;http://localhost:11434/v1&quot;,
      &quot;api_key&quot;: &quot;ollama&quot;,
      &quot;models&quot;: [&quot;qwen2.5-coder:latest&quot;]
    }
  ],
  &quot;Router&quot;: {
    &quot;background&quot;: &quot;ollama,qwen2.5-coder:latest&quot;,
    &quot;think&quot;: &quot;deepseek,deepseek-reasoner&quot;,
    &quot;longContext&quot;: &quot;openrouter,google/gemini-2.5-pro-preview&quot;
  }
}
```
- `background`    
This model will be used to handle some background tasks([background-token-usage](https://docs.anthropic.com/en/docs/claude-code/costs#background-token-usage)). Based on my tests, it doesn’t require high intelligence. I’m using the qwen-coder-2.5:7b model running locally on my MacBook Pro M1 (32GB) via Ollama.
If your computer can’t run Ollama, you can also use some free models, such as qwen-coder-2.5:3b.


- `think`    
This model will be used when enabling Claude Code to perform reasoning. However, reasoning budget control has not yet been implemented (since the DeepSeek-R1 model does not support it), so there is currently no difference between using UltraThink and Think modes.
It is worth noting that Plan Mode also use this model to achieve better planning results.    
Note: The reasoning process via the official DeepSeek API may be very slow, so you may need to wait for an extended period of time.


- `longContext`   
This model will be used when the context length exceeds 32K (this value may be modified in the future). You can route the request to a model that performs well with long contexts (I’ve chosen google/gemini-2.5-pro-preview). This scenario has not been thoroughly tested yet, so if you encounter any issues, please submit an issue.


- model command   
You can also switch models within Claude Code by using the `/model` command. The format is: `provider,model`, like this:     
`/model openrouter,anthropic/claude-3.5-sonnet`    
This will use the anthropic/claude-3.5-sonnet model provided by OpenRouter to handle all subsequent tasks.

## Features
- [x] Plugins
- [x] Support change models
- [ ] Support scheduled tasks


## Some tips:
Now you can use deepseek-v3 models directly without using any plugins.

If you’re using the DeepSeek API provided by the official website, you might encounter an “exceeding context” error after several rounds of conversation (since the official API only supports a 64K context window). In this case, you’ll need to discard the previous context and start fresh. Alternatively, you can use ByteDance’s DeepSeek API, which offers a 128K context window and supports KV cache.

![](screenshoots/contexterror.jpg)

Note: claude code consumes a huge amount of tokens, but thanks to DeepSeek’s low cost, you can use claude code at a fraction of Claude’s price, and you don’t need to subscribe to the Claude Max plan.

Some interesting points: Based on my testing, including a lot of context information can help narrow the performance gap between these LLM models. For instance, when I used Claude-4 in VSCode Copilot to handle a Flutter issue, it messed up the files in three rounds of conversation, and I had to roll everything back. However, when I used claude code with DeepSeek, after three or four rounds of conversation, I finally managed to complete my task—and the cost was less than 1 RMB!

## Some articles:
1. [Project Motivation and Principles](blog/en/project-motivation-and-how-it-works.md)  ([中文版看这里](blog/zh/项目初衷及原理.md))

## Buy me a coffee
If you find this project helpful, you can choose to sponsor the author with a cup of coffee.
[Buy me a coffee](http://paypal.me/musistudio1999)

## Sponsors
Thanks to the following sponsors:

@Simon Leischnig (If you see this, feel free to contact me and I can update it with your GitHub information)</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[clash-verge-rev/clash-verge-rev]]></title>
            <link>https://github.com/clash-verge-rev/clash-verge-rev</link>
            <guid>https://github.com/clash-verge-rev/clash-verge-rev</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[A modern GUI client based on Tauri, designed to run in Windows, macOS and Linux for tailored proxy experience]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/clash-verge-rev/clash-verge-rev">clash-verge-rev/clash-verge-rev</a></h1>
            <p>A modern GUI client based on Tauri, designed to run in Windows, macOS and Linux for tailored proxy experience</p>
            <p>Language: TypeScript</p>
            <p>Stars: 61,870</p>
            <p>Forks: 4,715</p>
            <p>Stars today: 157 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img src=&quot;./src-tauri/icons/icon.png&quot; alt=&quot;Clash&quot; width=&quot;128&quot; /&gt;
  &lt;br&gt;
  Continuation of &lt;a href=&quot;https://github.com/zzzgydi/clash-verge&quot;&gt;Clash Verge&lt;/a&gt;
  &lt;br&gt;
&lt;/h1&gt;

&lt;h3 align=&quot;center&quot;&gt;
A Clash Meta GUI based on &lt;a href=&quot;https://github.com/tauri-apps/tauri&quot;&gt;Tauri&lt;/a&gt;.
&lt;/h3&gt;

## Preview

| Dark                             | Light                             |
| -------------------------------- | --------------------------------- |
| ![预览](./docs/preview_dark.png) | ![预览](./docs/preview_light.png) |

## Install

请到发布页面下载对应的安装包：[Release page](https://github.com/clash-verge-rev/clash-verge-rev/releases)&lt;br&gt;
Go to the [release page](https://github.com/clash-verge-rev/clash-verge-rev/releases) to download the corresponding installation package&lt;br&gt;
Supports Windows (x64/x86), Linux (x64/arm64) and macOS 10.15+ (intel/apple).

### 安装说明和常见问题，请到[文档页](https://clash-verge-rev.github.io/)查看：[Doc](https://clash-verge-rev.github.io/)

---

### TG 频道: [@clash_verge_rev](https://t.me/clash_verge_re)

## Promotion

[狗狗加速 —— 技术流机场 Doggygo VPN](https://verge.dginv.click/#/register?code=oaxsAGo6)

- 高性能海外机场，免费试用，优惠套餐，解锁流媒体，全球首家支持 Hysteria 协议。
- 使用 Clash Verge 专属邀请链接注册送 3 天，每天 1G 流量免费试用：[点此注册](https://verge.dginv.click/#/register?code=oaxsAGo6)
- Clash Verge 专属 8 折优惠码: verge20 (仅有 500 份)
- 优惠套餐每月仅需 15.8 元，160G 流量，年付 8 折
- 海外团队，无跑路风险，高达 50% 返佣
- 集群负载均衡设计，高速专线(兼容老客户端)，极低延迟，无视晚高峰，4K 秒开
- 全球首家 Hysteria 协议机场，现已上线更快的 `Hysteria2` 协议(Clash Verge 客户端最佳搭配)
- 解锁流媒体及 ChatGPT
- 官网：[https://狗狗加速.com](https://verge.dginv.click/#/register?code=oaxsAGo6)

## Features

- 基于性能强劲的 Rust 和 Tauri 2 框架
- 内置[Clash.Meta(mihomo)](https://github.com/MetaCubeX/mihomo)内核，并支持切换 `Alpha` 版本内核。
- 简洁美观的用户界面，支持自定义主题颜色、代理组/托盘图标以及 `CSS Injection`。
- 配置文件管理和增强（Merge 和 Script），配置文件语法提示。
- 系统代理和守卫、`TUN(虚拟网卡)` 模式。
- 可视化节点和规则编辑
- WebDav 配置备份和同步

### FAQ

Refer to [Doc FAQ Page](https://clash-verge-rev.github.io/faq/windows.html)

### Donation

[捐助Clash Verge Rev的开发](https://github.com/sponsors/clash-verge-rev)

## Development

See [CONTRIBUTING.md](./CONTRIBUTING.md) for more details.

To run the development server, execute the following commands after all prerequisites for **Tauri** are installed:

```shell
pnpm i
pnpm run check
pnpm dev
```

## Contributions

Issue and PR welcome!

## Acknowledgement

Clash Verge rev was based on or inspired by these projects and so on:

- [zzzgydi/clash-verge](https://github.com/zzzgydi/clash-verge): A Clash GUI based on tauri. Supports Windows, macOS and Linux.
- [tauri-apps/tauri](https://github.com/tauri-apps/tauri): Build smaller, faster, and more secure desktop applications with a web frontend.
- [Dreamacro/clash](https://github.com/Dreamacro/clash): A rule-based tunnel in Go.
- [MetaCubeX/mihomo](https://github.com/MetaCubeX/mihomo): A rule-based tunnel in Go.
- [Fndroid/clash_for_windows_pkg](https://github.com/Fndroid/clash_for_windows_pkg): A Windows/macOS GUI based on Clash.
- [vitejs/vite](https://github.com/vitejs/vite): Next generation frontend tooling. It&#039;s fast!

## License

GPL-3.0 License. See [License here](./LICENSE) for details.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[firebase/genkit]]></title>
            <link>https://github.com/firebase/genkit</link>
            <guid>https://github.com/firebase/genkit</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[An open source framework for building AI-powered apps with familiar code-centric patterns. Genkit makes it easy to develop, integrate, and test AI features with observability and evaluations. Genkit works with various models and platforms.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/firebase/genkit">firebase/genkit</a></h1>
            <p>An open source framework for building AI-powered apps with familiar code-centric patterns. Genkit makes it easy to develop, integrate, and test AI features with observability and evaluations. Genkit works with various models and platforms.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,069</p>
            <p>Forks: 284</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>![Genkit logo](docs/resources/genkit-logo-dark.png#gh-dark-mode-only &#039;Genkit&#039;)
![Genkit logo](docs/resources/genkit-logo.png#gh-light-mode-only &#039;Genkit&#039;)

Genkit is an open-source framework for building full-stack AI-powered applications, built and used in production by Google&#039;s Firebase. It provides SDKs for multiple programming languages with varying levels of stability:

- **JavaScript/TypeScript (Stable)**: Production-ready with full feature support
- **Go (Beta)**: Feature-complete but may have breaking changes
- **Python (Alpha)**: Early development with core functionality

It offers a unified interface for integrating AI models from providers like [Google](https://genkit.dev/docs/plugins/google-genai), [OpenAI](https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-openai), [Anthropic](https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-anthropic), [Ollama](https://genkit.dev/docs/plugins/ollama/), and more. Rapidly build and deploy production-ready chatbots, automations, and recommendation systems using streamlined APIs for multimodal content, structured outputs, tool calling, and agentic workflows.

Get started with just a few lines of code:

```ts
import { genkit } from &#039;genkit&#039;;
import { googleAI } from &#039;@genkit-ai/googleai&#039;;

const ai = genkit({ plugins: [googleAI()] });

const { text } = await ai.generate({
    model: googleAI.model(&#039;gemini-2.0-flash&#039;),
    prompt: &#039;Why is Firebase awesome?&#039;
});
```

## Explore &amp; build with Genkit

Play with AI sample apps, with visualizations of the Genkit code that powers
them, at no cost to you.

[Explore Genkit by Example](https://examples.genkit.dev)

## Key capabilities

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;strong&gt;Broad AI model support&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;Use a unified interface to integrate with hundreds of models from providers like &lt;a href=&quot;https://genkit.dev/docs/plugins/google-genai&quot;&gt;Google&lt;/a&gt;, &lt;a href=&quot;https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-openai&quot;&gt;
    OpenAI&lt;/a&gt;, &lt;a href=&quot;https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-anthropic&quot;&gt;
    Anthropic&lt;/a&gt;, &lt;a href=&quot;https://genkit.dev/docs/plugins/ollama&quot;&gt;Ollama&lt;/a&gt;, and more. Explore, compare, and use the best models for your needs.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;strong&gt;Simplified AI development&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;Use streamlined APIs to build AI features with &lt;a href=&quot;https://genkit.dev/docs/models#structured-output&quot;&gt;
    structured output&lt;/a&gt;, &lt;a href=&quot;https://genkit.dev/docs/tool-calling&quot;&gt;agentic tool calling&lt;/a&gt;, &lt;a href=&quot;https://genkit.dev/docs/rag&quot;&gt;context-aware generation&lt;/a&gt;, &lt;a href=&quot;https://genkit.dev/docs/models#multimodal&quot;&gt;multi-modal input/output&lt;/a&gt;, and more. Genkit handles the complexity of AI development, so you can build and iterate faster.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;strong&gt;Web and mobile ready&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;Integrate seamlessly with frameworks and platforms including Next.js, React, Angular, iOS, Android, using purpose-built &lt;a href=&quot;https://genkit.dev/docs/firebase&quot;&gt;client SDKs&lt;/a&gt; and helpers.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;strong&gt;Cross-language support&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;Build with the language that best fits your project. Genkit provides SDKs for JavaScript/TypeScript (Stable), Go (Beta), and Python (Alpha) with consistent APIs and capabilities across all supported languages.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;strong&gt;Deploy anywhere&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;Deploy AI logic to any environment that supports your chosen programming language, such as &lt;a href=&quot;https://genkit.dev/docs/firebase&quot;&gt;Cloud Functions for Firebase&lt;/a&gt;,
    &lt;a href=&quot;https://genkit.dev/docs/cloud-run&quot;&gt;Google Cloud Run&lt;/a&gt;, or &lt;a href=&quot;https://genkit.dev/docs/deploy-node&quot;&gt;third-party platforms&lt;/a&gt;,
    with or without Google services.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;strong&gt;Developer tools&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;Accelerate AI development with a purpose-built, local &lt;a href=&quot;https://genkit.dev/docs/devtools&quot;&gt;CLI and Developer UI&lt;/a&gt;. Test prompts and
    flows against individual inputs or datasets, compare outputs from different models, debug with detailed execution traces, and use immediate visual feedback to iterate rapidly on prompts.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;strong&gt;Production monitoring&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt;Ship AI features with confidence using comprehensive production monitoring. Track model performance, and request volumes, latency, and error rates in a &lt;a href=&quot;https://genkit.dev/docs/observability/getting-started&quot;&gt; purpose-built dashboard&lt;/a&gt;. Identify issues quickly with detailed observability metrics, and ensure your AI features meet quality and performance targets in real-world usage.&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## How does it work?

Genkit simplifies AI integration with an open-source SDK and unified APIs that
work across various model providers and programming languages. It abstracts away complexity so you can focus on delivering great user experiences.

Some key features offered by Genkit include:

* [Text and image generation](https://genkit.dev/docs/models)
* [Type-safe, structured data generation](https://genkit.dev/docs/models#structured-output)
* [Tool calling](https://genkit.dev/docs/tool-calling)
* [Prompt templating](https://genkit.dev/docs/dotprompt)
* [Persisted chat interfaces](https://genkit.dev/docs/chat)
* [AI workflows](https://genkit.dev/docs/flows)
* [AI-powered data retrieval (RAG)](https://genkit.dev/docs/rag)

Genkit is designed for server-side deployment in multiple language environments, and also provides seamless client-side integration through dedicated helpers and [client SDKs](https://genkit.dev/docs/firebase).

## Implementation path

&lt;table&gt;
&lt;tr&gt;
  &lt;td&gt;&lt;span&gt;1&lt;/span&gt;&lt;/td&gt;
  &lt;td&gt;Choose your language and model provider&lt;/td&gt;
  &lt;td&gt;Select the Genkit SDK for your preferred language (JavaScript/TypeScript (Stable), Go (Beta), or Python (Alpha)). Choose a model provider like &lt;a href=&quot;https://genkit.dev/docs/plugins/google-genai&quot;&gt;Google Gemini&lt;/a&gt; or Anthropic, and get an API key. Some providers, like &lt;a href=&quot;https://genkit.dev/docs/plugins/vertex-ai&quot;&gt;Vertex AI&lt;/a&gt;, may rely on a different means of authentication.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;&lt;span&gt;2&lt;/span&gt;&lt;/td&gt;
  &lt;td&gt;Install the SDK and initialize&lt;/td&gt;
  &lt;td&gt;Install the Genkit SDK, model-provider package of your choice, and the Genkit CLI. Import the Genkit and provider packages and initialize Genkit with the provider API key.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;&lt;span&gt;3&lt;/span&gt;&lt;/td&gt;
  &lt;td&gt;Write and test AI features&lt;/td&gt;
  &lt;td&gt;Use the Genkit SDK to build AI features for your use case, from basic text generation to complex multi-step workflows and agents. Use the CLI and Developer UI to help you rapidly test and iterate.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;&lt;span&gt;4&lt;/span&gt;&lt;/td&gt;
  &lt;td&gt;Deploy and monitor&lt;/td&gt;
  &lt;td&gt;Deploy your AI features to Firebase, Google Cloud Run, or any environment that supports your chosen programming language. Integrate them into your app, and monitor them in production in the Firebase console.&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

## Get started

- [JavaScript/TypeScript quickstart](https://genkit.dev/docs/get-started) (Stable)
- [Go quickstart](https://genkit.dev/go/docs/get-started-go) (Beta)
- [Python quickstart](https://genkit.dev/python/docs/get-started/) (Alpha)

## Development tools

Genkit provides a CLI and a local UI to streamline your AI development workflow.

### CLI

The Genkit CLI includes commands for running and evaluating your Genkit functions (flows) and collecting telemetry and logs.

- **Install:** `npm install -g genkit-cli`
- **Run a command, wrapped with telemetry, a interactive developer UI, etc:** `genkit start -- &lt;command to run your code&gt;`

### Developer UI

The Genkit developer UI is a local interface for testing, debugging, and iterating on your AI application.

Key features:

- **Run:** Execute and experiment with Genkit flows, prompts, queries, and more in dedicated playgrounds.
- **Inspect:** Analyze detailed traces of past executions, including step-by-step breakdowns of complex flows.
- **Evaluate:** Review the results of evaluations run against your flows, including performance metrics and links to relevant traces.

&lt;img src=&quot;docs/resources/readme-ui-traces-screenshot.png&quot; width=&quot;700&quot; alt=&quot;Screenshot of Genkit Developer UI showing traces&quot;&gt;

## Try Genkit in Firebase Studio

Want to skip the local setup? Click below to try out Genkit using [Firebase Studio](https://firebase.studio), Google&#039;s AI-assisted workspace for full-stack app development in the cloud.

&lt;a href=&quot;https://studio.firebase.google.com/new/genkit&quot;&gt;
  &lt;img
    height=&quot;32&quot;
    alt=&quot;Open in Firebase Studio&quot;
    src=&quot;https://cdn.firebasestudio.dev/btn/open_bright_32.svg&quot;&gt;
&lt;/a&gt;

## Connect with us

- [**Join us on Discord**](https://discord.gg/qXt5zzQKpc) – Get help, share
ideas, and chat with other developers.
- [**Contribute on GitHub**](https://github.com/firebase/genkit/issues) – Report 
bugs, suggest features, or explore the source code.

## Contributing

Contributions to Genkit are welcome and highly appreciated! See our [Contribution Guide](CONTRIBUTING.md) to get started.

## Authors

Genkit is built by [Firebase](https://firebase.google.com/products/genkit) with contributions from the [Open Source Community](https://github.com/firebase/genkit/graphs/contributors).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[linshenkx/prompt-optimizer]]></title>
            <link>https://github.com/linshenkx/prompt-optimizer</link>
            <guid>https://github.com/linshenkx/prompt-optimizer</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:35 GMT</pubDate>
            <description><![CDATA[一款提示词优化器，助力于编写高质量的提示词]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/linshenkx/prompt-optimizer">linshenkx/prompt-optimizer</a></h1>
            <p>一款提示词优化器，助力于编写高质量的提示词</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,477</p>
            <p>Forks: 854</p>
            <p>Stars today: 436 stars today</p>
            <h2>README</h2><pre># Prompt Optimizer (提示词优化器) 🚀

&lt;div align=&quot;center&quot;&gt;

[English](README_EN.md) | [中文](README.md)

[![GitHub stars](https://img.shields.io/github/stars/linshenkx/prompt-optimizer)](https://github.com/linshenkx/prompt-optimizer/stargazers)
![Chrome Web Store Users](https://img.shields.io/chrome-web-store/users/cakkkhboolfnadechdlgdcnjammejlna?style=flat&amp;label=Chrome%20Users&amp;link=https%3A%2F%2Fchromewebstore.google.com%2Fdetail%2F%25E6%258F%2590%25E7%25A4%25BA%25E8%25AF%258D%25E4%25BC%2598%25E5%258C%2596%25E5%2599%25A8%2Fcakkkhboolfnadechdlgdcnjammejlna)

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Docker Pulls](https://img.shields.io/docker/pulls/linshen/prompt-optimizer)](https://hub.docker.com/r/linshen/prompt-optimizer)
![GitHub forks](https://img.shields.io/github/forks/linshenkx/prompt-optimizer?style=flat)
[![Deploy with Vercel](https://img.shields.io/badge/Vercel-indigo?style=flat&amp;logo=vercel)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flinshenkx%2Fprompt-optimizer)

[在线体验](https://prompt.always200.com) | [快速开始](#快速开始) | [常见问题](#常见问题) | [开发文档](dev.md) | [Vercel部署指南](docs/vercel.md) | [Chrome插件](https://chromewebstore.google.com/detail/prompt-optimizer/cakkkhboolfnadechdlgdcnjammejlna)

&lt;/div&gt;

## 📖 项目简介

Prompt Optimizer是一个强大的AI提示词优化工具，帮助你编写更好的AI提示词，提升AI输出质量。支持Web应用和Chrome插件两种使用方式。

### 🎥 功能演示

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/contrast.png&quot; alt=&quot;功能演示&quot; width=&quot;90%&quot;&gt;
&lt;/div&gt;

## ✨ 核心特性

- 🎯 **智能优化**：一键优化提示词，支持多轮迭代改进，提升AI回复准确度
- 🔄 **对比测试**：支持原始提示词和优化后提示词的实时对比，直观展示优化效果
- 🤖 **多模型集成**：支持OpenAI、Gemini、DeepSeek、智谱AI、SiliconFlow等主流AI模型
- ⚙️ **高级参数配置**：支持为每个模型单独配置temperature、max_tokens等LLM参数
- 🔒 **安全架构**：纯客户端处理，数据直接与AI服务商交互，不经过中间服务器
- 💾 **隐私保护**：本地加密存储历史记录和API密钥，支持数据导入导出
- 📱 **多端支持**：同时提供Web应用和Chrome插件两种使用方式
- 🎨 **用户体验**：简洁直观的界面设计，响应式布局和流畅交互动效
- 🌐 **跨域支持**：Vercel部署时支持使用Edge Runtime代理解决跨域问题
- 🔐 **访问控制**：支持密码保护功能，保障部署安全

## 快速开始

### 1. 使用在线版本（推荐）

直接访问：[https://prompt.always200.com](https://prompt.always200.com)

项目是纯前端项目，所有数据只存储在浏览器本地，不会上传至任何服务器，因此直接使用在线版本也是安全可靠的

### 2. Vercel部署
方式1：一键部署到自己的Vercel：
   [![部署到 Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flinshenkx%2Fprompt-optimizer)

方式2: Fork项目后在Vercel中导入（推荐）：
   - 先Fork项目到自己的GitHub
   - 然后在Vercel中导入该项目
   - 可跟踪源项目更新，便于同步最新功能和修复
- 配置环境变量：
  - `ACCESS_PASSWORD`：设置访问密码，启用访问限制
  - `VITE_OPENAI_API_KEY`等：配置各AI服务商的API密钥

更多详细的部署步骤和注意事项，请查看：
- [Vercel部署指南](docs/vercel.md)

### 3. 安装Chrome插件
1. 从Chrome商店安装（由于审批较慢，可能不是最新的）：[Chrome商店地址](https://chromewebstore.google.com/detail/prompt-optimizer/cakkkhboolfnadechdlgdcnjammejlna)
2. 点击图标即可打开提示词优化器

### 4. Docker部署
```bash
# 运行容器（默认配置）
docker run -d -p 80:80 --restart unless-stopped --name prompt-optimizer linshen/prompt-optimizer

# 运行容器（配置API密钥和访问密码）
docker run -d -p 80:80 \
  -e VITE_OPENAI_API_KEY=your_key \
  -e ACCESS_USERNAME=your_username \  # 可选，默认为&quot;admin&quot;
  -e ACCESS_PASSWORD=your_password \  # 设置访问密码
  --restart unless-stopped \
  --name prompt-optimizer \
  linshen/prompt-optimizer
  
```

### 5. Docker Compose部署
```bash
# 1. 克隆仓库
git clone https://github.com/linshenkx/prompt-optimizer.git
cd prompt-optimizer

# 2. 可选：创建.env文件配置API密钥和访问认证
cat &gt; .env &lt;&lt; EOF
# API密钥配置
VITE_OPENAI_API_KEY=your_openai_api_key
VITE_GEMINI_API_KEY=your_gemini_api_key
VITE_DEEPSEEK_API_KEY=your_deepseek_api_key
VITE_ZHIPU_API_KEY=your_zhipu_api_key
VITE_SILICONFLOW_API_KEY=your_siliconflow_api_key

# Basic认证配置（密码保护）
ACCESS_USERNAME=your_username  # 可选，默认为&quot;admin&quot;
ACCESS_PASSWORD=your_password  # 设置访问密码
EOF

# 3. 启动服务
docker compose up -d

# 4. 查看日志
docker compose logs -f
```

你还可以直接编辑docker-compose.yml文件，自定义配置：
```yaml
services:
  prompt-optimizer:
    image: linshen/prompt-optimizer:latest
    container_name: prompt-optimizer
    restart: unless-stopped
    ports:
      - &quot;8081:80&quot;  # 修改端口映射
    environment:
      - VITE_OPENAI_API_KEY=your_key_here  # 直接在配置中设置密钥
```

## ⚙️ API密钥配置

### 方式一：通过界面配置（推荐）
1. 点击界面右上角的&quot;⚙️设置&quot;按钮
2. 选择&quot;模型管理&quot;选项卡
3. 点击需要配置的模型（如OpenAI、Gemini、DeepSeek等）
4. 在弹出的配置框中输入对应的API密钥
5. 点击&quot;保存&quot;即可

支持的模型：
- OpenAI (gpt-3.5-turbo, gpt-4, gpt-4o)
- Gemini (gemini-1.5-pro, gemini-2.0-flash)
- DeepSeek (deepseek-chat, deepseek-coder)
- Zhipu智谱 (glm-4-flash, glm-4, glm-3-turbo)
- SiliconFlow (Pro/deepseek-ai/DeepSeek-V3)
- 自定义API（OpenAI兼容接口）

除了API密钥，您还可以在模型配置界面为每个模型单独设置高级LLM参数。这些参数通过一个名为 `llmParams` 的字段进行配置，它允许您以键值对的形式指定LLM SDK支持的任何参数，从而更精细地控制模型行为。

**高级LLM参数配置示例：**
- **OpenAI/兼容API**: `{&quot;temperature&quot;: 0.7, &quot;max_tokens&quot;: 4096, &quot;timeout&quot;: 60000}`
- **Gemini**: `{&quot;temperature&quot;: 0.8, &quot;maxOutputTokens&quot;: 2048, &quot;topP&quot;: 0.95}`
- **DeepSeek**: `{&quot;temperature&quot;: 0.5, &quot;top_p&quot;: 0.9, &quot;frequency_penalty&quot;: 0.1}`

有关 `llmParams` 的更详细说明和配置指南，请参阅 [LLM参数配置指南](docs/llm-params-guide.md)。

### 方式二：通过环境变量配置
Docker部署时通过 `-e` 参数配置环境变量：
```bash
-e VITE_OPENAI_API_KEY=your_key
-e VITE_GEMINI_API_KEY=your_key
-e VITE_DEEPSEEK_API_KEY=your_key
-e VITE_ZHIPU_API_KEY=your_key
-e VITE_SILICONFLOW_API_KEY=your_key
-e VITE_CUSTOM_API_KEY=your_custom_api_key
-e VITE_CUSTOM_API_BASE_URL=your_custom_api_base_url
-e VITE_CUSTOM_API_MODEL=your_custom_model_name
```

## 本地开发
详细文档可查看 [开发文档](dev.md)

```bash
# 1. 克隆项目
git clone https://github.com/linshenkx/prompt-optimizer.git
cd prompt-optimizer

# 2. 安装依赖
pnpm install

# 3. 启动开发服务
pnpm dev               # 主开发命令：构建core/ui并运行web应用
pnpm dev:web          # 仅运行web应用
pnpm dev:fresh        # 完整重置并重新启动开发环境
```

## 🗺️ 开发路线

- [x] 基础功能开发
- [x] Web应用发布
- [x] Chrome插件发布
- [x] 自定义模型支持
- [x] 多模型支持优化
- [x] 国际化支持

详细的项目状态可查看 [项目状态文档](docs/project-status.md)

## 📖 相关文档

- [文档索引](docs/README.md) - 所有文档的索引
- [技术开发指南](docs/technical-development-guide.md) - 技术栈和开发规范
- [LLM参数配置指南](docs/llm-params-guide.md) - 高级LLM参数配置详细说明
- [项目结构](docs/project-structure.md) - 详细的项目结构说明
- [项目状态](docs/project-status.md) - 当前进度和计划
- [产品需求](docs/prd.md) - 产品需求文档
- [Vercel部署指南](docs/vercel.md) - Vercel部署详细说明


## Star History

&lt;a href=&quot;https://star-history.com/#linshenkx/prompt-optimizer&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## 常见问题

### API连接问题

#### Q1: 为什么配置好API密钥后仍然无法连接到模型服务？
**A**: 大多数连接失败是由**跨域问题**（CORS）导致的。由于本项目是纯前端应用，浏览器出于安全考虑会阻止直接访问不同源的API服务。模型服务如未正确配置CORS策略，会拒绝来自浏览器的直接请求。

#### Q2: 如何解决本地Ollama的连接问题？
**A**: Ollama完全支持OpenAI标准接口，只需配置正确的跨域策略：
1. 设置环境变量 `OLLAMA_ORIGINS=*` 允许任意来源的请求
2. 如仍有问题，设置 `OLLAMA_HOST=0.0.0.0:11434` 监听任意IP地址

#### Q3: 如何解决商业API（如Nvidia的DS API、字节跳动的火山API）的跨域问题？
**A**: 这些平台通常有严格的跨域限制，推荐以下解决方案：

1. **使用Vercel代理**（便捷方案）
   - 使用在线版本：[prompt.always200.com](https://prompt.always200.com)
   - 或自行部署到Vercel平台
   - 在模型设置中勾选&quot;使用Vercel代理&quot;选项
   - 请求流向：浏览器→Vercel→模型服务提供商
   - 详细步骤请参考 [Vercel部署指南](docs/vercel.md)

2. **使用自部署的API中转服务**（可靠方案）
   - 部署如OneAPI等开源API聚合/代理工具
   - 在设置中配置为自定义API端点
   - 请求流向：浏览器→中转服务→模型服务提供商

#### Q4: Vercel代理有什么缺点或风险？
**A**: 使用Vercel代理可能会触发某些模型服务提供商的风控机制。部分厂商可能会将来自Vercel的请求判定为代理行为，从而限制或拒绝服务。如遇此问题，建议使用自部署的中转服务。


## 🤝 参与贡献

1. Fork 本仓库
2. 创建特性分支 (`git checkout -b feature/AmazingFeature`)
3. 提交更改 (`git commit -m &#039;添加某个特性&#039;`)
4. 推送到分支 (`git push origin feature/AmazingFeature`)
5. 提交 Pull Request

提示：使用cursor工具开发时，建议在提交前:
1. 使用&quot;code_review&quot;规则进行代码审查
2. 按照审查报告格式检查:
   - 变更的整体一致性
   - 代码质量和实现方式
   - 测试覆盖情况
   - 文档完善程度
3. 根据审查结果进行优化后再提交

## 👏 贡献者名单

感谢所有为项目做出贡献的开发者！

&lt;a href=&quot;https://github.com/linshenkx/prompt-optimizer/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=linshenkx/prompt-optimizer&quot; alt=&quot;贡献者&quot; /&gt;
&lt;/a&gt;

## 📄 开源协议

本项目采用 [MIT](LICENSE) 协议开源。

---

如果这个项目对你有帮助，请考虑给它一个 Star ⭐️

## 👥 联系我们

- 提交 Issue
- 发起 Pull Request
- 加入讨论组</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[NomicFoundation/hardhat]]></title>
            <link>https://github.com/NomicFoundation/hardhat</link>
            <guid>https://github.com/NomicFoundation/hardhat</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[Hardhat is a development environment to compile, deploy, test, and debug your Ethereum software.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NomicFoundation/hardhat">NomicFoundation/hardhat</a></h1>
            <p>Hardhat is a development environment to compile, deploy, test, and debug your Ethereum software.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,862</p>
            <p>Forks: 1,572</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>packages/hardhat-core/README.md</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[fastapi/full-stack-fastapi-template]]></title>
            <link>https://github.com/fastapi/full-stack-fastapi-template</link>
            <guid>https://github.com/fastapi/full-stack-fastapi-template</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[Full stack, modern web application template. Using FastAPI, React, SQLModel, PostgreSQL, Docker, GitHub Actions, automatic HTTPS and more.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fastapi/full-stack-fastapi-template">fastapi/full-stack-fastapi-template</a></h1>
            <p>Full stack, modern web application template. Using FastAPI, React, SQLModel, PostgreSQL, Docker, GitHub Actions, automatic HTTPS and more.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 33,435</p>
            <p>Forks: 6,371</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre># Full Stack FastAPI Template

&lt;a href=&quot;https://github.com/fastapi/full-stack-fastapi-template/actions?query=workflow%3ATest&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/fastapi/full-stack-fastapi-template/workflows/Test/badge.svg&quot; alt=&quot;Test&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://coverage-badge.samuelcolvin.workers.dev/redirect/fastapi/full-stack-fastapi-template&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://coverage-badge.samuelcolvin.workers.dev/fastapi/full-stack-fastapi-template.svg&quot; alt=&quot;Coverage&quot;&gt;&lt;/a&gt;

## Technology Stack and Features

- ⚡ [**FastAPI**](https://fastapi.tiangolo.com) for the Python backend API.
    - 🧰 [SQLModel](https://sqlmodel.tiangolo.com) for the Python SQL database interactions (ORM).
    - 🔍 [Pydantic](https://docs.pydantic.dev), used by FastAPI, for the data validation and settings management.
    - 💾 [PostgreSQL](https://www.postgresql.org) as the SQL database.
- 🚀 [React](https://react.dev) for the frontend.
    - 💃 Using TypeScript, hooks, Vite, and other parts of a modern frontend stack.
    - 🎨 [Chakra UI](https://chakra-ui.com) for the frontend components.
    - 🤖 An automatically generated frontend client.
    - 🧪 [Playwright](https://playwright.dev) for End-to-End testing.
    - 🦇 Dark mode support.
- 🐋 [Docker Compose](https://www.docker.com) for development and production.
- 🔒 Secure password hashing by default.
- 🔑 JWT (JSON Web Token) authentication.
- 📫 Email based password recovery.
- ✅ Tests with [Pytest](https://pytest.org).
- 📞 [Traefik](https://traefik.io) as a reverse proxy / load balancer.
- 🚢 Deployment instructions using Docker Compose, including how to set up a frontend Traefik proxy to handle automatic HTTPS certificates.
- 🏭 CI (continuous integration) and CD (continuous deployment) based on GitHub Actions.

### Dashboard Login

[![API docs](img/login.png)](https://github.com/fastapi/full-stack-fastapi-template)

### Dashboard - Admin

[![API docs](img/dashboard.png)](https://github.com/fastapi/full-stack-fastapi-template)

### Dashboard - Create User

[![API docs](img/dashboard-create.png)](https://github.com/fastapi/full-stack-fastapi-template)

### Dashboard - Items

[![API docs](img/dashboard-items.png)](https://github.com/fastapi/full-stack-fastapi-template)

### Dashboard - User Settings

[![API docs](img/dashboard-user-settings.png)](https://github.com/fastapi/full-stack-fastapi-template)

### Dashboard - Dark Mode

[![API docs](img/dashboard-dark.png)](https://github.com/fastapi/full-stack-fastapi-template)

### Interactive API Documentation

[![API docs](img/docs.png)](https://github.com/fastapi/full-stack-fastapi-template)

## How To Use It

You can **just fork or clone** this repository and use it as is.

✨ It just works. ✨

### How to Use a Private Repository

If you want to have a private repository, GitHub won&#039;t allow you to simply fork it as it doesn&#039;t allow changing the visibility of forks.

But you can do the following:

- Create a new GitHub repo, for example `my-full-stack`.
- Clone this repository manually, set the name with the name of the project you want to use, for example `my-full-stack`:

```bash
git clone git@github.com:fastapi/full-stack-fastapi-template.git my-full-stack
```

- Enter into the new directory:

```bash
cd my-full-stack
```

- Set the new origin to your new repository, copy it from the GitHub interface, for example:

```bash
git remote set-url origin git@github.com:octocat/my-full-stack.git
```

- Add this repo as another &quot;remote&quot; to allow you to get updates later:

```bash
git remote add upstream git@github.com:fastapi/full-stack-fastapi-template.git
```

- Push the code to your new repository:

```bash
git push -u origin master
```

### Update From the Original Template

After cloning the repository, and after doing changes, you might want to get the latest changes from this original template.

- Make sure you added the original repository as a remote, you can check it with:

```bash
git remote -v

origin    git@github.com:octocat/my-full-stack.git (fetch)
origin    git@github.com:octocat/my-full-stack.git (push)
upstream    git@github.com:fastapi/full-stack-fastapi-template.git (fetch)
upstream    git@github.com:fastapi/full-stack-fastapi-template.git (push)
```

- Pull the latest changes without merging:

```bash
git pull --no-commit upstream master
```

This will download the latest changes from this template without committing them, that way you can check everything is right before committing.

- If there are conflicts, solve them in your editor.

- Once you are done, commit the changes:

```bash
git merge --continue
```

### Configure

You can then update configs in the `.env` files to customize your configurations.

Before deploying it, make sure you change at least the values for:

- `SECRET_KEY`
- `FIRST_SUPERUSER_PASSWORD`
- `POSTGRES_PASSWORD`

You can (and should) pass these as environment variables from secrets.

Read the [deployment.md](./deployment.md) docs for more details.

### Generate Secret Keys

Some environment variables in the `.env` file have a default value of `changethis`.

You have to change them with a secret key, to generate secret keys you can run the following command:

```bash
python -c &quot;import secrets; print(secrets.token_urlsafe(32))&quot;
```

Copy the content and use that as password / secret key. And run that again to generate another secure key.

## How To Use It - Alternative With Copier

This repository also supports generating a new project using [Copier](https://copier.readthedocs.io).

It will copy all the files, ask you configuration questions, and update the `.env` files with your answers.

### Install Copier

You can install Copier with:

```bash
pip install copier
```

Or better, if you have [`pipx`](https://pipx.pypa.io/), you can run it with:

```bash
pipx install copier
```

**Note**: If you have `pipx`, installing copier is optional, you could run it directly.

### Generate a Project With Copier

Decide a name for your new project&#039;s directory, you will use it below. For example, `my-awesome-project`.

Go to the directory that will be the parent of your project, and run the command with your project&#039;s name:

```bash
copier copy https://github.com/fastapi/full-stack-fastapi-template my-awesome-project --trust
```

If you have `pipx` and you didn&#039;t install `copier`, you can run it directly:

```bash
pipx run copier copy https://github.com/fastapi/full-stack-fastapi-template my-awesome-project --trust
```

**Note** the `--trust` option is necessary to be able to execute a [post-creation script](https://github.com/fastapi/full-stack-fastapi-template/blob/master/.copier/update_dotenv.py) that updates your `.env` files.

### Input Variables

Copier will ask you for some data, you might want to have at hand before generating the project.

But don&#039;t worry, you can just update any of that in the `.env` files afterwards.

The input variables, with their default values (some auto generated) are:

- `project_name`: (default: `&quot;FastAPI Project&quot;`) The name of the project, shown to API users (in .env).
- `stack_name`: (default: `&quot;fastapi-project&quot;`) The name of the stack used for Docker Compose labels and project name (no spaces, no periods) (in .env).
- `secret_key`: (default: `&quot;changethis&quot;`) The secret key for the project, used for security, stored in .env, you can generate one with the method above.
- `first_superuser`: (default: `&quot;admin@example.com&quot;`) The email of the first superuser (in .env).
- `first_superuser_password`: (default: `&quot;changethis&quot;`) The password of the first superuser (in .env).
- `smtp_host`: (default: &quot;&quot;) The SMTP server host to send emails, you can set it later in .env.
- `smtp_user`: (default: &quot;&quot;) The SMTP server user to send emails, you can set it later in .env.
- `smtp_password`: (default: &quot;&quot;) The SMTP server password to send emails, you can set it later in .env.
- `emails_from_email`: (default: `&quot;info@example.com&quot;`) The email account to send emails from, you can set it later in .env.
- `postgres_password`: (default: `&quot;changethis&quot;`) The password for the PostgreSQL database, stored in .env, you can generate one with the method above.
- `sentry_dsn`: (default: &quot;&quot;) The DSN for Sentry, if you are using it, you can set it later in .env.

## Backend Development

Backend docs: [backend/README.md](./backend/README.md).

## Frontend Development

Frontend docs: [frontend/README.md](./frontend/README.md).

## Deployment

Deployment docs: [deployment.md](./deployment.md).

## Development

General development docs: [development.md](./development.md).

This includes using Docker Compose, custom local domains, `.env` configurations, etc.

## Release Notes

Check the file [release-notes.md](./release-notes.md).

## License

The Full Stack FastAPI Template is licensed under the terms of the MIT license.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ueberdosis/tiptap]]></title>
            <link>https://github.com/ueberdosis/tiptap</link>
            <guid>https://github.com/ueberdosis/tiptap</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[The headless rich text editor framework for web artisans.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ueberdosis/tiptap">ueberdosis/tiptap</a></h1>
            <p>The headless rich text editor framework for web artisans.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 30,971</p>
            <p>Forks: 2,529</p>
            <p>Stars today: 27 stars today</p>
            <h2>README</h2><pre># Tiptap Editor
The Tiptap Editor is a headless, framework-agnostic rich text editor that&#039;s customizable and extendable through extensions. Its headless nature means it comes without a set user interface, offering full design freedom (for a jumpstart, see linked [UI templates](#examples-codesandbox-and-ui-templates) below). Tiptap is based on the highly reliable [ProseMirror](https://github.com/ProseMirror/prosemirror) library.

Tiptap Editor is complemented by the collaboration open-source backend [Hocuspocus](https://github.com/ueberdosis/hocuspocus). Both the Editor and Hocuspocus form the foundation of the [Tiptap Suite](https://tiptap.dev/).

[![Build Status](https://github.com/ueberdosis/tiptap/actions/workflows/build.yml/badge.svg)](https://github.com/ueberdosis/tiptap/actions/workflows/build.yml)
[![Version](https://img.shields.io/npm/v/@tiptap/core.svg?label=version)](https://www.npmjs.com/package/@tiptap/core)
[![Downloads](https://img.shields.io/npm/dm/@tiptap/core.svg)](https://npmcharts.com/compare/@tiptap/core?minimal=true)
[![License](https://img.shields.io/npm/l/@tiptap/core.svg)](https://www.npmjs.com/package/@tiptap/core)
[![Chat](https://img.shields.io/badge/chat-on%20discord-7289da.svg?sanitize=true)](https://discord.gg/WtJ49jGshW)
[![Sponsor](https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub)](https://github.com/sponsors/ueberdosis)

### How does the Tiptap Editor work?

- **Headless Framework:** Tiptap does not rely on a user interface. So there is no need for class overrides or code hacks. If you do need an example UI feel free to browse our [UI templates](#examples-codesandbox-and-ui-templates) linked below.
- **Framework-agnostic:** The Tiptap Editor is designed to work across different frontend frameworks. This means whether you&#039;re using Vue, React, or plain JavaScript, Tiptap integrates  without compatibility issues.
- **Extension based:** Extensions in Tiptap allow for a tailored editing experience, from simple text styling to advanced features like drag-and-drop block editing. You have the option to choose from over 100 extensions available in the [documentation](https://tiptap.dev/docs/editor/extensions) and [community](https://github.com/ueberdosis/awesome-tiptap/#community-extensions) to enhance your editor&#039;s functionality.
- **Customize your UX:** The editor was built to give you control to define your own [extensions](https://tiptap.dev/docs/editor/guide/custom-extensions) and [nodes](https://tiptap.dev/docs/editor/api/nodes).


### Editor Pro Extensions
The **Pro Extensions** are a set of advanced functionalities that enhance the capabilities of the Tiptap Editor. They are additional features that can be integrated into the base editor to provide more sophisticated editing options.

Key functionalities include collaborative editing, which allows multiple users to edit documents simultaneously, drag-and-drop file management for easier handling of documents and media, and unique node ID assignment. Review the docs right [here](https://tiptap.dev/docs/editor/extensions).

Pro Extensions are free with a [Tiptap account](https://cloud.tiptap.dev/pro-extensions). Once signed up, review the guide in your account.

### Make your editor collaborative
Interested in collaborative editing? Check out our open-source package [Hocuspocus](https://github.com/ueberdosis/hocuspocus) - a collaboration backend built around the CRDT power of [Yjs](https://github.com/yjs/yjs). Hocuspocus serves as the backbone for the [Tiptap Suite](https://tiptap.dev/).

## Documentation
For more detailed information, make sure to check out our [documentation](https://tiptap.dev/docs/editor/installation). If you encounter any problems or have suggestions for our system, please open an issue.

### Examples, CodeSandbox and UI Templates
Have a look at the [examples to see Tiptap in action](https://tiptap.dev/examples) or review and fork our codesandboxes.
- [Basic example of the Tiptap editor.](https://codesandbox.io/p/devbox/editor-9x9dkd?embed=1&amp;file=%2Fsrc%2FApp.js)
- [Collaboration ready Tiptap CodeSandbox](https://codesandbox.io/p/devbox/collaboration-4stk94)
- React notion-like block editor template: [Demo](https://templates.tiptap.dev/)

## About Tiptap
Tiptap is a collection of developer components based on open-source technology, forming the basis of our advanced, paid features. It includes the open-source editor component, collaboration features, Content AI, and Tiptap Cloud. We are developing open-source products that also shape our paid features. We&#039;re committed to improving both, ensuring quality and reliability in every update.

For more details, visit the Tiptap [documentation](https://tiptap.dev/docs/editor/introduction) or [website](https://tiptap.dev/).

### Community
For help, discussion about best practices, or any other conversation that would benefit from being searchable:

[Discuss Tiptap on GitHub](https://github.com/ueberdosis/tiptap/discussions)

### Sponsors 💖
&lt;table&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://www.complish.app/&quot;&gt;
        &lt;img src=&quot;https://uploads-ssl.webflow.com/5fa93d27380666789a1cbbd3/5fae50824b4d2d06f3d2898f_Frame%20374.png&quot; width=&quot;25&quot;&gt;&lt;br&gt;
        &lt;strong&gt;Complish&lt;/strong&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://www.storyblok.com/&quot;&gt;
        &lt;img src=&quot;https://unavatar.io/github/storyblok&quot; width=&quot;25&quot;&gt;&lt;br&gt;
        &lt;strong&gt;Storyblok&lt;/strong&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://posthog.com/&quot;&gt;
        &lt;img src=&quot;https://unavatar.io/github/posthog&quot; width=&quot;25&quot;&gt;&lt;br&gt;
        &lt;strong&gt;PostHog&lt;/strong&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; width=&quot;100&quot;&gt;
      &lt;a href=&quot;https://reflect.app/&quot;&gt;
        &lt;img src=&quot;https://unavatar.io/reflect.app&quot; width=&quot;25&quot;&gt;&lt;br&gt;
        &lt;strong&gt;Reflect&lt;/strong&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; width=&quot;100&quot;&gt;
      &lt;a href=&quot;https://ziffmedia.com/&quot;&gt;
        &lt;img src=&quot;https://unavatar.io/github/ziffmedia&quot; width=&quot;25&quot;&gt;&lt;br&gt;
        &lt;strong&gt;Ziff Media&lt;/strong&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; width=&quot;100&quot;&gt;
      &lt;a href=&quot;https://www.basewell.com/&quot;&gt;
        &lt;img src=&quot;https://unavatar.io/github/Basewell&quot; width=&quot;25&quot;&gt;&lt;br&gt;
        &lt;strong&gt;Basewell&lt;/strong&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; width=&quot;100&quot;&gt;
      &lt;a href=&quot;https://poggio.io&quot;&gt;
        &lt;img src=&quot;https://unavatar.io/github/poggiolabs&quot; width=&quot;25&quot;&gt;&lt;br&gt;
        &lt;strong&gt;Poggio&lt;/strong&gt;
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;table&gt;

&lt;/table&gt;

[iFixit](https://www.ifixit.com/), [ApostropheCMS](https://apostrophecms.com/), [Novadiscovery](http://www.novadiscovery.com/), [Omics Data Automation](https://www.omicsautomation.com), [Flow Mobile](https://www.flowmobile.app/), [DocIQ](https://www.dociq.io/) and [hundreds of awesome individuals](https://github.com/sponsors/ueberdosis).

### Contributing
Feel like adding some magic of your own to Tiptap Editor Core? We welcome contributions! Please see our [CONTRIBUTING](CONTRIBUTING.md) guidelines for how to get started.

### Contributors
[Sam Willis](https://github.com/samwillis),
[Brian Hung](https://github.com/BrianHung),
[Dirk Holtwick](https://github.com/holtwick),
[Sam Duvall](https://github.com/SamDuvall),
[Christoph Flathmann](https://github.com/Chrissi2812),
[Erick Wilder](https://github.com/erickwilder),
[Marius Tolzmann](https://github.com/mariux),
[jjangga0214](https://github.com/jjangga0214),
[Maya Nedeljkovich](https://github.com/mayacoda),
[Ryan Bliss](https://github.com/ryanbliss),
[Gregor](https://github.com/gambolputty) and [many more](../../contributors).

## License
The MIT License (MIT). Please see [License File](LICENSE.md) for more information.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[udecode/plate]]></title>
            <link>https://github.com/udecode/plate</link>
            <guid>https://github.com/udecode/plate</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[Rich-text editor with AI, MCP, and shadcn/ui]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/udecode/plate">udecode/plate</a></h1>
            <p>Rich-text editor with AI, MCP, and shadcn/ui</p>
            <p>Language: TypeScript</p>
            <p>Stars: 14,226</p>
            <p>Forks: 859</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
Plate
&lt;/h1&gt;

&lt;p&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/@platejs/core&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/@platejs/core.svg&quot; alt=&quot;Total Downloads&quot;&gt;&lt;/a&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/udecode/plate/releases/latest&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/udecode/plate&quot; /&gt;&lt;/a&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;tooling/CONTRIBUTING.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg&quot; alt=&quot;PRs Welcome&quot;&gt;&lt;/a&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://discord.gg/mAZRuBzGM3&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/chat-on%20discord-7289da.svg?sanitize=true&quot; /&gt;&lt;/a&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/udecode/plate/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://badgen.now.sh/badge/license/MIT&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

[//]: # &#039;  &lt;a target=&quot;_blank&quot; href=&quot;https://platejs.org/docs/playground&quot; alt=&quot;Live Demo&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Live%20Demo-blue&quot; /&gt;&lt;/a&gt;&#039;
[//]: # &#039;Welcome to Plate, a rich-text editor framework designed for simplicity and efficiency. Plate consists of four main parts:&#039;
[//]: #
[//]: # &quot;1. **Core**: This is the heart of Plate. It&#039;s a special plugin system just for `slate-react`. We&#039;ve made sure everything is neat and tidy, so it&#039;s easier for you to develop your project.&quot;
[//]: # &#039;2. **Plugins**: We give you a big selection of plugin packages. They help make editor behaviors, hooks, serialization, and normalization better, among other things.&#039;
[//]: # &#039;3. **Primitives**: Besides the headless plugins, we also provide primitive hooks and components built on top of [Radix UI](https://www.radix-ui.com/). These are **unstyled** and accessible parts for making great design systems.&#039;
[//]: # &#039;4. **Components**: We know a good-looking start is important. So, we give you components created with Plate CLI and [shadcn/ui](https://ui.shadcn.com/). Use these as a starting point to create your own component library.&#039;

## Templates

You can choose one of the following templates to get started:

| Option                                                                            | Plate | Plugins | AI  | Backend |
| --------------------------------------------------------------------------------- | ----- | ------- | --- | ------- |
| [Notion-like template](https://pro.platejs.org/docs/templates/potion)             | ✅    | ✅      | ✅  | ✅      |
| [Plate playground template](https://github.com/udecode/plate-playground-template) | ✅    | ✅      | ✅  |         |
| [Plate minimal template](https://github.com/udecode/plate-template)               | ✅    |         |     |         |

## Documentation

You can learn more about Plate by checking out our [documentation](https://platejs.org/docs).

## Contributing

To get started, check out our [contributing guide](tooling/CONTRIBUTING.md).

### Contributors

We&#039;d love for you to join us! Whether it&#039;s through giving us a 🌟 star, making a 📥 pull request, or **sharing your plugins**, your help is always appreciated.

[![Star History Chart](https://api.star-history.com/svg?repos=udecode/plate&amp;type=Date)](https://star-history.com/#udecode/plate&amp;Date)

Need more help? Join us on [Discord](https://discord.gg/mAZRuBzGM3). We&#039;re always here to guide you.

## 中文文档

您可以通过查看我们的[中文文档](tooling/cn/README.md)了解更多关于Plate的信息。如果您需要中文支持，欢迎加入我们的[Discord](https://discord.gg/mAZRuBzGM3)中文频道，我们的社区成员将很乐意用中文为您解答问题。

对于贡献者，我们也提供了[中文贡献指南](tooling/cn/CONTRIBUTING.md)，帮助您参与到Plate的开发中。
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[immich-app/immich]]></title>
            <link>https://github.com/immich-app/immich</link>
            <guid>https://github.com/immich-app/immich</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[High performance self-hosted photo and video management solution.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/immich-app/immich">immich-app/immich</a></h1>
            <p>High performance self-hosted photo and video management solution.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 68,499</p>
            <p>Forks: 3,593</p>
            <p>Stars today: 344 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt; 
  &lt;br/&gt;
  &lt;a href=&quot;https://opensource.org/license/agpl-v3&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-AGPL_v3-blue.svg?color=3F51B5&amp;style=for-the-badge&amp;label=License&amp;logoColor=000000&amp;labelColor=ececec&quot; alt=&quot;License: AGPLv3&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.immich.app&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/979116623879368755.svg?label=Discord&amp;logo=Discord&amp;style=for-the-badge&amp;logoColor=000000&amp;labelColor=ececec&quot; alt=&quot;Discord&quot;/&gt;
  &lt;/a&gt;
  &lt;br/&gt;
  &lt;br/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;design/immich-logo-stacked-light.svg&quot; width=&quot;300&quot; title=&quot;Login With Custom URL&quot;&gt;
&lt;/p&gt;
&lt;h3 align=&quot;center&quot;&gt;High performance self-hosted photo and video management solution&lt;/h3&gt;
&lt;br/&gt;
&lt;a href=&quot;https://immich.app&quot;&gt;
&lt;img src=&quot;design/immich-screenshots.png&quot; title=&quot;Main Screenshot&quot;&gt;
&lt;/a&gt;
&lt;br/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;readme_i18n/README_ca_ES.md&quot;&gt;Català&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_es_ES.md&quot;&gt;Español&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_fr_FR.md&quot;&gt;Français&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_it_IT.md&quot;&gt;Italiano&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ja_JP.md&quot;&gt;日本語&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ko_KR.md&quot;&gt;한국어&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_de_DE.md&quot;&gt;Deutsch&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_nl_NL.md&quot;&gt;Nederlands&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_tr_TR.md&quot;&gt;Türkçe&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_zh_CN.md&quot;&gt;中文&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_uk_UA.md&quot;&gt;Українська&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ru_RU.md&quot;&gt;Русский&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_pt_BR.md&quot;&gt;Português Brasileiro&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_sv_SE.md&quot;&gt;Svenska&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ar_JO.md&quot;&gt;العربية&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_vi_VN.md&quot;&gt;Tiếng Việt&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_th_TH.md&quot;&gt;ภาษาไทย&lt;/a&gt;
&lt;/p&gt;

## Disclaimer

- ⚠️ The project is under **very active** development.
- ⚠️ Expect bugs and breaking changes.
- ⚠️ **Do not use the app as the only way to store your photos and videos.**
- ⚠️ Always follow [3-2-1](https://www.backblaze.com/blog/the-3-2-1-backup-strategy/) backup plan for your precious photos and videos!

&gt; [!NOTE]
&gt; You can find the main documentation, including installation guides, at https://immich.app/.

## Links

- [Documentation](https://immich.app/docs)
- [About](https://immich.app/docs/overview/introduction)
- [Installation](https://immich.app/docs/install/requirements)
- [Roadmap](https://immich.app/roadmap)
- [Demo](#demo)
- [Features](#features)
- [Translations](https://immich.app/docs/developer/translations)
- [Contributing](https://immich.app/docs/overview/support-the-project)

## Demo

Access the demo [here](https://demo.immich.app). For the mobile app, you can use `https://demo.immich.app` for the `Server Endpoint URL`.

### Login credentials

| Email           | Password |
| --------------- | -------- |
| demo@immich.app | demo     |

## Features

| Features                                     | Mobile | Web |
| :------------------------------------------- | ------ | --- |
| Upload and view videos and photos            | Yes    | Yes |
| Auto backup when the app is opened           | Yes    | N/A |
| Prevent duplication of assets                | Yes    | Yes |
| Selective album(s) for backup                | Yes    | N/A |
| Download photos and videos to local device   | Yes    | Yes |
| Multi-user support                           | Yes    | Yes |
| Album and Shared albums                      | Yes    | Yes |
| Scrubbable/draggable scrollbar               | Yes    | Yes |
| Support raw formats                          | Yes    | Yes |
| Metadata view (EXIF, map)                    | Yes    | Yes |
| Search by metadata, objects, faces, and CLIP | Yes    | Yes |
| Administrative functions (user management)   | No     | Yes |
| Background backup                            | Yes    | N/A |
| Virtual scroll                               | Yes    | Yes |
| OAuth support                                | Yes    | Yes |
| API Keys                                     | N/A    | Yes |
| LivePhoto/MotionPhoto backup and playback    | Yes    | Yes |
| Support 360 degree image display             | No     | Yes |
| User-defined storage structure               | Yes    | Yes |
| Public Sharing                               | Yes    | Yes |
| Archive and Favorites                        | Yes    | Yes |
| Global Map                                   | Yes    | Yes |
| Partner Sharing                              | Yes    | Yes |
| Facial recognition and clustering            | Yes    | Yes |
| Memories (x years ago)                       | Yes    | Yes |
| Offline support                              | Yes    | No  |
| Read-only gallery                            | Yes    | Yes |
| Stacked Photos                               | Yes    | Yes |
| Tags                                         | No     | Yes |
| Folder View                                  | Yes    | Yes |

## Translations

Read more about translations [here](https://immich.app/docs/developer/translations).

&lt;a href=&quot;https://hosted.weblate.org/engage/immich/&quot;&gt;
&lt;img src=&quot;https://hosted.weblate.org/widget/immich/immich/multi-auto.svg&quot; alt=&quot;Translation status&quot; /&gt;
&lt;/a&gt;

## Repository activity

![Activities](https://repobeats.axiom.co/api/embed/9e86d9dc3ddd137161f2f6d2e758d7863b1789cb.svg &quot;Repobeats analytics image&quot;)

## Star history

&lt;a href=&quot;https://star-history.com/#immich-app/immich&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=immich-app/immich&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=immich-app/immich&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=immich-app/immich&amp;type=Date&quot; width=&quot;100%&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## Contributors

&lt;a href=&quot;https://github.com/alextran1502/immich/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=immich-app/immich&quot; width=&quot;100%&quot;/&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[n8n-io/n8n]]></title>
            <link>https://github.com/n8n-io/n8n</link>
            <guid>https://github.com/n8n-io/n8n</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/n8n-io/n8n">n8n-io/n8n</a></h1>
            <p>Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 108,448</p>
            <p>Forks: 31,083</p>
            <p>Stars today: 393 stars today</p>
            <h2>README</h2><pre>![Banner image](https://user-images.githubusercontent.com/10284570/173569848-c624317f-42b1-45a6-ab09-f0ea3c247648.png)

# n8n - Secure Workflow Automation for Technical Teams

n8n is a workflow automation platform that gives technical teams the flexibility of code with the speed of no-code. With 400+ integrations, native AI capabilities, and a fair-code license, n8n lets you build powerful automations while maintaining full control over your data and deployments.

![n8n.io - Screenshot](https://raw.githubusercontent.com/n8n-io/n8n/master/assets/n8n-screenshot-readme.png)

## Key Capabilities

- **Code When You Need It**: Write JavaScript/Python, add npm packages, or use the visual interface
- **AI-Native Platform**: Build AI agent workflows based on LangChain with your own data and models
- **Full Control**: Self-host with our fair-code license or use our [cloud offering](https://app.n8n.cloud/login)
- **Enterprise-Ready**: Advanced permissions, SSO, and air-gapped deployments
- **Active Community**: 400+ integrations and 900+ ready-to-use [templates](https://n8n.io/workflows)

## Quick Start

Try n8n instantly with [npx](https://docs.n8n.io/hosting/installation/npm/) (requires [Node.js](https://nodejs.org/en/)):

```
npx n8n
```

Or deploy with [Docker](https://docs.n8n.io/hosting/installation/docker/):

```
docker volume create n8n_data
docker run -it --rm --name n8n -p 5678:5678 -v n8n_data:/home/node/.n8n docker.n8n.io/n8nio/n8n
```

Access the editor at http://localhost:5678

## Resources

- 📚 [Documentation](https://docs.n8n.io)
- 🔧 [400+ Integrations](https://n8n.io/integrations)
- 💡 [Example Workflows](https://n8n.io/workflows)
- 🤖 [AI &amp; LangChain Guide](https://docs.n8n.io/langchain/)
- 👥 [Community Forum](https://community.n8n.io)
- 📖 [Community Tutorials](https://community.n8n.io/c/tutorials/28)

## Support

Need help? Our community forum is the place to get support and connect with other users:
[community.n8n.io](https://community.n8n.io)

## License

n8n is [fair-code](https://faircode.io) distributed under the [Sustainable Use License](https://github.com/n8n-io/n8n/blob/master/LICENSE.md) and [n8n Enterprise License](https://github.com/n8n-io/n8n/blob/master/LICENSE_EE.md).

- **Source Available**: Always visible source code
- **Self-Hostable**: Deploy anywhere
- **Extensible**: Add your own nodes and functionality

[Enterprise licenses](mailto:license@n8n.io) available for additional features and support.

Additional information about the license model can be found in the [docs](https://docs.n8n.io/reference/license/).

## Contributing

Found a bug 🐛 or have a feature idea ✨? Check our [Contributing Guide](https://github.com/n8n-io/n8n/blob/master/CONTRIBUTING.md) to get started.

## Join the Team

Want to shape the future of automation? Check out our [job posts](https://n8n.io/careers) and join our team!

## What does n8n mean?

**Short answer:** It means &quot;nodemation&quot; and is pronounced as n-eight-n.

**Long answer:** &quot;I get that question quite often (more often than I expected) so I decided it is probably best to answer it here. While looking for a good name for the project with a free domain I realized very quickly that all the good ones I could think of were already taken. So, in the end, I chose nodemation. &#039;node-&#039; in the sense that it uses a Node-View and that it uses Node.js and &#039;-mation&#039; for &#039;automation&#039; which is what the project is supposed to help with. However, I did not like how long the name was and I could not imagine writing something that long every time in the CLI. That is when I then ended up on &#039;n8n&#039;.&quot; - **Jan Oberhauser, Founder and CEO, n8n.io**
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-demo]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-demo</link>
            <guid>https://github.com/open-telemetry/opentelemetry-demo</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[This repository contains the OpenTelemetry Astronomy Shop, a microservice-based distributed system intended to illustrate the implementation of OpenTelemetry in a near real-world environment.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-demo">open-telemetry/opentelemetry-demo</a></h1>
            <p>This repository contains the OpenTelemetry Astronomy Shop, a microservice-based distributed system intended to illustrate the implementation of OpenTelemetry in a near real-world environment.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,367</p>
            <p>Forks: 3,613</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable-next-line --&gt;
# &lt;img src=&quot;https://opentelemetry.io/img/logos/opentelemetry-logo-nav.png&quot; alt=&quot;OTel logo&quot; width=&quot;45&quot;&gt; OpenTelemetry Demo

[![Slack](https://img.shields.io/badge/slack-@cncf/otel/demo-brightgreen.svg?logo=slack)](https://cloud-native.slack.com/archives/C03B4CWV4DA)
[![Version](https://img.shields.io/github/v/release/open-telemetry/opentelemetry-demo?color=blueviolet)](https://github.com/open-telemetry/opentelemetry-demo/releases)
[![Commits](https://img.shields.io/github/commits-since/open-telemetry/opentelemetry-demo/latest?color=ff69b4&amp;include_prereleases)](https://github.com/open-telemetry/opentelemetry-demo/graphs/commit-activity)
[![Downloads](https://img.shields.io/docker/pulls/otel/demo)](https://hub.docker.com/r/otel/demo)
[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg?color=red)](https://github.com/open-telemetry/opentelemetry-demo/blob/main/LICENSE)
[![Integration Tests](https://github.com/open-telemetry/opentelemetry-demo/actions/workflows/run-integration-tests.yml/badge.svg)](https://github.com/open-telemetry/opentelemetry-demo/actions/workflows/run-integration-tests.yml)
[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/opentelemetry-demo)](https://artifacthub.io/packages/helm/opentelemetry-helm/opentelemetry-demo)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9247/badge)](https://www.bestpractices.dev/en/projects/9247)

## Welcome to the OpenTelemetry Astronomy Shop Demo

This repository contains the OpenTelemetry Astronomy Shop, a microservice-based
distributed system intended to illustrate the implementation of OpenTelemetry in
a near real-world environment.

Our goals are threefold:

- Provide a realistic example of a distributed system that can be used to
  demonstrate OpenTelemetry instrumentation and observability.
- Build a base for vendors, tooling authors, and others to extend and
  demonstrate their OpenTelemetry integrations.
- Create a living example for OpenTelemetry contributors to use for testing new
  versions of the API, SDK, and other components or enhancements.

We&#039;ve already made [huge
progress](https://github.com/open-telemetry/opentelemetry-demo/blob/main/CHANGELOG.md),
and development is ongoing. We hope to represent the full feature set of
OpenTelemetry across its languages in the future.

If you&#039;d like to help (**which we would love**), check out our [contributing
guidance](./CONTRIBUTING.md).

If you&#039;d like to extend this demo or maintain a fork of it, read our
[fork guidance](https://opentelemetry.io/docs/demo/forking/).

## Quick start

You can be up and running with the demo in a few minutes. Check out the docs for
your preferred deployment method:

- [Docker](https://opentelemetry.io/docs/demo/docker_deployment/)
- [Kubernetes](https://opentelemetry.io/docs/demo/kubernetes_deployment/)

## Documentation

For detailed documentation, see [Demo Documentation][docs]. If you&#039;re curious
about a specific feature, the [docs landing page][docs] can point you in the
right direction.

## Demos featuring the Astronomy Shop

We welcome any vendor to fork the project to demonstrate their services and
adding a link below. The community is committed to maintaining the project and
keeping it up to date for you.

|                           |                |                                  |
|---------------------------|----------------|----------------------------------|
| [AlibabaCloud LogService] | [Google Cloud] |  [Oracle]                        |
| [AppDynamics]             | [Grafana Labs] |  [Sentry]                        |
| [Aspecto]                 | [Guance]       |  [ServiceNow Cloud Observability]|
| [Axiom]                   | [Honeycomb.io] |  [SigNoz]                        |
| [Axoflow]                 | [Instana]      |  [Splunk]                        |
| [Azure Data Explorer]     | [Kloudfuse]    |  [Sumo Logic]                    |
| [Coralogix]               | [Last9]        |  [TelemetryHub]                  |
| [Dash0]                   | [Liatrio]      |  [Teletrace]                     |
| [Datadog]                 | [Logz.io]      |  [Tracetest]                     |
| [Dynatrace]               | [New Relic]    |  [Uptrace]                       |
| [Elastic]                 | [OpenSearch]   |                                  |

## Contributing

To get involved with the project see our [CONTRIBUTING](CONTRIBUTING.md)
documentation. Our [SIG Calls](CONTRIBUTING.md#join-a-sig-call) are every other
Wednesday at 8:30 AM PST and anyone is welcome.

## Project leadership

[Maintainers](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#maintainer)
([@open-telemetry/demo-maintainers](https://github.com/orgs/open-telemetry/teams/demo-maintainers)):

- [Juliano Costa](https://github.com/julianocosta89), Datadog
- [Mikko Viitanen](https://github.com/mviitane), Dynatrace
- [Pierre Tessier](https://github.com/puckpuck), Honeycomb

[Approvers](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#approver)
([@open-telemetry/demo-approvers](https://github.com/orgs/open-telemetry/teams/demo-approvers)):

- [Cedric Ziel](https://github.com/cedricziel) Grafana Labs
- [Penghan Wang](https://github.com/wph95), AppDynamics
- [Reiley Yang](https://github.com/reyang), Microsoft
- [Roger Coll](https://github.com/rogercoll), Elastic
- [Ziqi Zhao](https://github.com/fatsheep9146), Alibaba

Emeritus:

- [Austin Parker](https://github.com/austinlparker)
- [Carter Socha](https://github.com/cartersocha)
- [Michael Maxwell](https://github.com/mic-max)
- [Morgan McLean](https://github.com/mtwo)

### Thanks to all the people who have contributed

[![contributors](https://contributors-img.web.app/image?repo=open-telemetry/opentelemetry-demo)](https://github.com/open-telemetry/opentelemetry-demo/graphs/contributors)

[docs]: https://opentelemetry.io/docs/demo/

&lt;!-- Links for Demos featuring the Astronomy Shop section --&gt;

[AlibabaCloud LogService]: https://github.com/aliyun-sls/opentelemetry-demo
[AppDynamics]: https://community.splunk.com/t5/AppDynamics-Knowledge-Base/How-to-observe-Kubernetes-deployment-of-OpenTelemetry-demo-app/ta-p/741454
[Aspecto]: https://github.com/aspecto-io/opentelemetry-demo
[Axiom]: https://play.axiom.co/axiom-play-qf1k/dashboards/otel.traces.otel-demo-traces
[Axoflow]: https://axoflow.com/opentelemetry-support-in-more-detail-in-axosyslog-and-syslog-ng/
[Azure Data Explorer]: https://github.com/Azure/Azure-kusto-opentelemetry-demo
[Coralogix]: https://coralogix.com/blog/configure-otel-demo-send-telemetry-data-coralogix
[Dash0]: https://github.com/dash0hq/opentelemetry-demo
[Datadog]: https://docs.datadoghq.com/opentelemetry/guide/otel_demo_to_datadog
[Dynatrace]: https://www.dynatrace.com/news/blog/opentelemetry-demo-application-with-dynatrace/
[Elastic]: https://github.com/elastic/opentelemetry-demo
[Google Cloud]: https://github.com/GoogleCloudPlatform/opentelemetry-demo
[Grafana Labs]: https://github.com/grafana/opentelemetry-demo
[Guance]: https://github.com/GuanceCloud/opentelemetry-demo
[Honeycomb.io]: https://github.com/honeycombio/opentelemetry-demo
[Instana]: https://github.com/instana/opentelemetry-demo
[Kloudfuse]: https://github.com/kloudfuse/opentelemetry-demo
[Last9]: https://last9.io/docs/integrations-opentelemetry-demo/
[Liatrio]: https://github.com/liatrio/opentelemetry-demo
[Logz.io]: https://logz.io/learn/how-to-run-opentelemetry-demo-with-logz-io/
[New Relic]: https://github.com/newrelic/opentelemetry-demo
[OpenSearch]: https://github.com/opensearch-project/opentelemetry-demo
[Oracle]: https://github.com/oracle-quickstart/oci-o11y-solutions/blob/main/knowledge-content/opentelemetry-demo
[Sentry]: https://github.com/getsentry/opentelemetry-demo
[ServiceNow Cloud Observability]: https://docs.lightstep.com/otel/quick-start-operator#send-data-from-the-opentelemetry-demo
[SigNoz]: https://signoz.io/blog/opentelemetry-demo/
[Splunk]: https://github.com/signalfx/opentelemetry-demo
[Sumo Logic]: https://www.sumologic.com/blog/common-opentelemetry-demo-application/
[TelemetryHub]: https://github.com/TelemetryHub/opentelemetry-demo/tree/telemetryhub-backend
[Teletrace]: https://github.com/teletrace/opentelemetry-demo
[Tracetest]: https://github.com/kubeshop/opentelemetry-demo
[Uptrace]: https://github.com/uptrace/uptrace/tree/master/example/opentelemetry-demo
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[microsoft/data-formulator]]></title>
            <link>https://github.com/microsoft/data-formulator</link>
            <guid>https://github.com/microsoft/data-formulator</guid>
            <pubDate>Wed, 18 Jun 2025 00:04:27 GMT</pubDate>
            <description><![CDATA[🪄 Create rich visualizations with AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/data-formulator">microsoft/data-formulator</a></h1>
            <p>🪄 Create rich visualizations with AI</p>
            <p>Language: TypeScript</p>
            <p>Stars: 12,473</p>
            <p>Forks: 1,007</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;
    &lt;img src=&quot;./public/favicon.ico&quot; alt=&quot;Data Formulator icon&quot; width=&quot;28&quot;&gt; &lt;b&gt;Data Formulator: Create Rich Visualizations with AI&lt;/b&gt;
&lt;/h1&gt;

&lt;div&gt;
    
[![arxiv](https://img.shields.io/badge/Paper-arXiv:2408.16119-b31b1b.svg)](https://arxiv.org/abs/2408.16119)&amp;ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)&amp;ensp;
[![YouTube](https://img.shields.io/badge/YouTube-white?logo=youtube&amp;logoColor=%23FF0000)](https://youtu.be/3ndlwt0Wi3c)&amp;ensp;
[![build](https://github.com/microsoft/data-formulator/actions/workflows/python-build.yml/badge.svg)](https://github.com/microsoft/data-formulator/actions/workflows/python-build.yml)
[![Discord](https://img.shields.io/badge/discord-chat-green?logo=discord)](https://discord.gg/mYCZMQKYZb)

&lt;/div&gt;

Transform data and create rich visualizations iteratively with AI 🪄. Try Data Formulator now!

Any questions? Ask on the Discord channel! [![Discord](https://img.shields.io/badge/discord-chat-green?logo=discord)](https://discord.gg/mYCZMQKYZb)

&lt;!-- [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/data-formulator?quickstart=1) --&gt;

&lt;kbd&gt;
  &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://codespaces.new/microsoft/data-formulator?quickstart=1&quot; title=&quot;open Data Formulator in GitHub Codespaces&quot;&gt;&lt;img src=&quot;public/data-formulator-screenshot.png&quot;&gt;&lt;/a&gt;
&lt;/kbd&gt;



## News 🔥🔥🔥

- [05-13-2025] Data Formulator 0.2.3: External Data Loader 
  - We introduced external data loader class to make import data easier. [Readme](https://github.com/microsoft/data-formulator/tree/main/py-src/data_formulator/data_loader) and [Demo](https://github.com/microsoft/data-formulator/pull/155)
    - Current data loaders: MySQL, Azure Data Explorer (Kusto), Azure Blob and Amazon S3 (json, parquet, csv).
  - Call for action [link](https://github.com/microsoft/data-formulator/issues/156):
    - Users: let us know which data source you&#039;d like to load data from.
    - Developers: let&#039;s build more data loaders.

- [04-23-2025] Data Formulator 0.2: working with *large* data 📦📦📦
  - Explore large data by:
    1. Upload large data file to the local database (powered by [DuckDB](https://github.com/duckdb/duckdb)).
    2. Use drag-and-drop to specify charts, and Data Formulator dynamically fetches data from the database to create visualizations (with ⚡️⚡️⚡️ speeds).
    3. Work with AI agents: they generate SQL queries to transform the data to create rich visualizations!
    4. Anchor the result / follow up / create a new branch / join tables; let&#039;s dive deeper. 
  - Checkout the demos at [[https://github.com/microsoft/data-formulator/releases/tag/0.2]](https://github.com/microsoft/data-formulator/releases/tag/0.2)
  - Improved overall system performance, and enjoy the updated derive concept functionality.

- [03-20-2025] Data Formulator 0.1.7: Anchoring ⚓︎
  - Anchor an intermediate dataset, so that followup data analysis are built on top of the anchored data, not the original one.
  - Clean a data and work with only the cleaned data; create a subset from the original data or join multiple data, and then go from there. AI agents will be less likely to get confused and work faster. ⚡️⚡️
  - Check out the demos at [[https://github.com/microsoft/data-formulator/releases/tag/0.1.7]](https://github.com/microsoft/data-formulator/releases/tag/0.1.7)
  - Don&#039;t forget to update Data Formulator to test it out!

- [02-20-2025] Data Formulator 0.1.6 released! 
  - Now supports working with multiple datasets at once! Tell Data Formulator which data tables you would like to use in the encoding shelf, and it will figure out how to join the tables to create a visualization to answer your question. 🪄
  - Checkout the demo at [[https://github.com/microsoft/data-formulator/releases/tag/0.1.6]](https://github.com/microsoft/data-formulator/releases/tag/0.1.6).
  - Update your Data Formulator to the latest version to play with the new features.

- [02-12-2025] More models supported now!
  - Now supports OpenAI, Azure, Ollama, and Anthropic models (and more powered by [LiteLLM](https://github.com/BerriAI/litellm));
  - Models with strong code generation and instruction following capabilities are recommended (gpt-4o, claude-3-5-sonnet etc.);
  - You can store API keys in `api-keys.env` to avoid typing them every time (see template `api-keys.env.template`).
  - Let us know which models you have good/bad experiences with, and what models you would like to see supported! [[comment here]](https://github.com/microsoft/data-formulator/issues/49)

- [11-07-2024] Minor fun update: data visualization challenges!
  - We added a few visualization challenges with the sample datasets. Can you complete them all? [[try them out!]](https://github.com/microsoft/data-formulator/issues/53#issue-2641841252)
  - Comment in the issue when you did, or share your results/questions with others! [[comment here]](https://github.com/microsoft/data-formulator/issues/53)

- [10-11-2024] Data Formulator python package released! 
  - You can now install Data Formulator using Python and run it locally, easily. [[check it out]](#get-started).
  - Our Codespaces configuration is also updated for fast start up ⚡️. [[try it now!]](https://codespaces.new/microsoft/data-formulator?quickstart=1)
  - New experimental feature: load an image or a messy text, and ask AI to parse and clean it for you(!). [[demo]](https://github.com/microsoft/data-formulator/pull/31#issuecomment-2403652717)
  
- [10-01-2024] Initial release of Data Formulator, check out our [[blog]](https://www.microsoft.com/en-us/research/blog/data-formulator-exploring-how-ai-can-help-analysts-create-rich-data-visualizations/) and [[video]](https://youtu.be/3ndlwt0Wi3c)!

## Overview

**Data Formulator** is an application from Microsoft Research that uses large language models to transform data, expediting the practice of data visualization.

Data Formulator is an AI-powered tool for analysts to iteratively create rich visualizations. Unlike most chat-based AI tools where users need to describe everything in natural language, Data Formulator combines *user interface interactions (UI)* and *natural language (NL) inputs* for easier interaction. This blended approach makes it easier for users to describe their chart designs while delegating data transformation to AI. 

## Get Started

Play with Data Formulator with one of the following options:

- **Option 1: Install via Python PIP**
  
  Use Python PIP for an easy setup experience, running locally (recommend: install it in a virtual environment).
  
  ```bash
  # install data_formulator
  pip install data_formulator

  # start data_formulator
  data_formulator 
  
  # alternatively, you can run data formulator with this command
  python -m data_formulator
  ```

  Data Formulator will be automatically opened in the browser at [http://localhost:5000](http://localhost:5000).

  *Update: you can specify the port number (e.g., 8080) by `python -m data_formulator --port 8080` if the default port is occupied.*

- **Option 2: Codespaces (5 minutes)**
  
  You can also run Data Formulator in Codespaces; we have everything pre-configured. For more details, see [CODESPACES.md](CODESPACES.md).
  
  [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/data-formulator?quickstart=1)

- **Option 3: Working in the developer mode**
  
  You can build Data Formulator locally if you prefer full control over your development environment and the ability to customize the setup to your specific needs. For detailed instructions, refer to [DEVELOPMENT.md](DEVELOPMENT.md).


## Using Data Formulator

Once you&#039;ve completed the setup using either option, follow these steps to start using Data Formulator:

### The basics of data visualization
* Provide OpenAI keys and select a model (GPT-4o suggested) and choose a dataset.
* Choose a chart type, and then drag-and-drop data fields to chart properties (x, y, color, ...) to specify visual encodings.

https://github.com/user-attachments/assets/0fbea012-1d2d-46c3-a923-b1fc5eb5e5b8


### Create visualization beyond the initial dataset (powered by 🤖)
* You can type names of **fields that do not exist in current data** in the encoding shelf:
    - this tells Data Formulator that you want to create visualizations that require computation or transformation from existing data,
    - you can optionally provide a natural language prompt to explain and clarify your intent (not necessary when field names are self-explanatory).
* Click the **Formulate** button.
    - Data Formulator will transform data and instantiate the visualization based on the encoding and prompt.
* Inspect the data, chart and code.
* To create a new chart based on existing ones, follow up in natural language:
    - provide a follow up prompt (e.g., *``show only top 5!&#039;&#039;*),
    - you may also update visual encodings for the new chart.

https://github.com/user-attachments/assets/160c69d2-f42d-435c-9ff3-b1229b5bddba

https://github.com/user-attachments/assets/c93b3e84-8ca8-49ae-80ea-f91ceef34acb

Repeat this process as needed to explore and understand your data. Your explorations are trackable in the **Data Threads** panel. 

## Developers&#039; Guide

Follow the [developers&#039; instructions](DEVELOPMENT.md) to build your new data analysis tools on top of Data Formulator.

## Research Papers
* [Data Formulator 2: Iteratively Creating Rich Visualizations with AI](https://arxiv.org/abs/2408.16119)

```
@article{wang2024dataformulator2iteratively,
      title={Data Formulator 2: Iteratively Creating Rich Visualizations with AI}, 
      author={Chenglong Wang and Bongshin Lee and Steven Drucker and Dan Marshall and Jianfeng Gao},
      year={2024},
      booktitle={ArXiv preprint arXiv:2408.16119},
}
```

* [Data Formulator: AI-powered Concept-driven Visualization Authoring](https://arxiv.org/abs/2309.10094)

```
@article{wang2023data,
  title={Data Formulator: AI-powered Concept-driven Visualization Authoring},
  author={Wang, Chenglong and Thompson, John and Lee, Bongshin},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2023},
  publisher={IEEE}
}
```


## Contributing

This project welcomes contributions and suggestions. Most contributions require you to
agree to a Contributor License Agreement (CLA) declaring that you have the right to,
and actually do, grant us the rights to use your contribution. For details, visit
https://cla.microsoft.com.

When you submit a pull request, a CLA-bot will automatically determine whether you need
to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the
instructions provided by the bot. You will only need to do this once across all repositories using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)
or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft 
trademarks or logos is subject to and must follow 
[Microsoft&#039;s Trademark &amp; Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party&#039;s policies.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>