<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Sun, 11 May 2025 00:05:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[voideditor/void]]></title>
            <link>https://github.com/voideditor/void</link>
            <guid>https://github.com/voideditor/void</guid>
            <pubDate>Sun, 11 May 2025 00:05:02 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/voideditor/void">voideditor/void</a></h1>
            <p></p>
            <p>Language: TypeScript</p>
            <p>Stars: 16,390</p>
            <p>Forks: 951</p>
            <p>Stars today: 1,196 stars today</p>
            <h2>README</h2><pre># Welcome to Void.

&lt;div align=&quot;center&quot;&gt;
	&lt;img
		src=&quot;./src/vs/workbench/browser/parts/editor/media/slice_of_void.png&quot;
	 	alt=&quot;Void Welcome&quot;
		width=&quot;300&quot;
	 	height=&quot;300&quot;
	/&gt;
&lt;/div&gt;

Void is the open-source Cursor alternative.

Use AI agents on your codebase, checkpoint and visualize changes, and bring any model or host locally. Void sends messages directly to providers without retaining your data.

This repo contains the full sourcecode for Void. If you&#039;re new, welcome!

- üß≠ [Website](https://voideditor.com)

- üëã [Discord](https://discord.gg/RSNjgaugJs)

- üöô [Project Board](https://github.com/orgs/voideditor/projects/2)


## Contributing

1. To get started working on Void, check out our Project Board! You can also see [HOW_TO_CONTRIBUTE](https://github.com/voideditor/void/blob/main/HOW_TO_CONTRIBUTE.md).

2. Feel free to attend a casual weekly meeting in our Discord channel!


## Reference

Void is a fork of the [vscode](https://github.com/microsoft/vscode) repository. For a guide to the codebase, see [VOID_CODEBASE_GUIDE](https://github.com/voideditor/void/blob/main/VOID_CODEBASE_GUIDE.md).

## Support
You can always reach us in our Discord server or contact us via email: hello@voideditor.com.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[langgenius/dify]]></title>
            <link>https://github.com/langgenius/dify</link>
            <guid>https://github.com/langgenius/dify</guid>
            <pubDate>Sun, 11 May 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langgenius/dify">langgenius/dify</a></h1>
            <p>Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 96,459</p>
            <p>Forks: 14,444</p>
            <p>Stars today: 104 stars today</p>
            <h2>README</h2><pre>![cover-v5-optimized](https://github.com/langgenius/dify/assets/13230914/f9e19af5-61ba-4119-b926-d10c4c06ebab)

&lt;p align=&quot;center&quot;&gt;
  üìå &lt;a href=&quot;https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast&quot;&gt;Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cloud.dify.ai&quot;&gt;Dify Cloud&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted&quot;&gt;Self-hosting&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://docs.dify.ai&quot;&gt;Documentation&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://dify.ai/pricing&quot;&gt;Dify edition overview&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://dify.ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Product-F04438&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://dify.ai/pricing&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/free-pricing?logo=free&amp;color=%20%23155EEF&amp;label=pricing&amp;labelColor=%20%23528bff&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/FngNHpbcY7&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1082486657678311454?logo=discord&amp;labelColor=%20%235462eb&amp;logoColor=%20%23f5f5f5&amp;color=%20%235462eb&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://reddit.com/r/difyai&quot; target=&quot;_blank&quot;&gt;  
        &lt;img src=&quot;https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&amp;logo=reddit&amp;label=r%2Fdifyai&amp;labelColor=white&quot;
            alt=&quot;join Reddit&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=dify_ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/dify_ai?logo=X&amp;color=%20%23f5f5f5&quot;
            alt=&quot;follow on X(Twitter)&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/langgenius/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;logoColor=fff&quot;
            alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/u/langgenius&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&amp;color=%20%23f79009&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/graphs/commit-activity&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Commits last month&quot; src=&quot;https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&amp;color=%20%2312b76a&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Issues closed&quot; src=&quot;https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&amp;label=issues%20closed&amp;labelColor=%20%237d89b0&amp;color=%20%235d6b98&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/discussions/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Discussion posts&quot; src=&quot;https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&amp;color=%20%237a5af8&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_TW.md&quot;&gt;&lt;img alt=&quot;ÁπÅÈ´î‰∏≠ÊñáÊñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁπÅÈ´î‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_CN.md&quot;&gt;&lt;img alt=&quot;ÁÆÄ‰Ωì‰∏≠ÊñáÁâàËá™Ëø∞Êñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_JA.md&quot;&gt;&lt;img alt=&quot;Êó•Êú¨Ë™û„ÅÆREADME&quot; src=&quot;https://img.shields.io/badge/Êó•Êú¨Ë™û-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_ES.md&quot;&gt;&lt;img alt=&quot;README en Espa√±ol&quot; src=&quot;https://img.shields.io/badge/Espa√±ol-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_FR.md&quot;&gt;&lt;img alt=&quot;README en Fran√ßais&quot; src=&quot;https://img.shields.io/badge/Fran√ßais-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_KL.md&quot;&gt;&lt;img alt=&quot;README tlhIngan Hol&quot; src=&quot;https://img.shields.io/badge/Klingon-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_KR.md&quot;&gt;&lt;img alt=&quot;README in Korean&quot; src=&quot;https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_AR.md&quot;&gt;&lt;img alt=&quot;README ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&quot; src=&quot;https://img.shields.io/badge/ÿßŸÑÿπÿ±ÿ®Ÿäÿ©-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_TR.md&quot;&gt;&lt;img alt=&quot;T√ºrk√ße README&quot; src=&quot;https://img.shields.io/badge/T√ºrk√ße-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_VI.md&quot;&gt;&lt;img alt=&quot;README Ti·∫øng Vi·ªát&quot; src=&quot;https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_DE.md&quot;&gt;&lt;img alt=&quot;README in Deutsch&quot; src=&quot;https://img.shields.io/badge/German-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_BN.md&quot;&gt;&lt;img alt=&quot;README in ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&quot; src=&quot;https://img.shields.io/badge/‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ-d9d9d9&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Dify is an open-source LLM app development platform. Its intuitive interface combines agentic AI workflow, RAG pipeline, agent capabilities, model management, observability features, and more, allowing you to quickly move from prototype to production.

## Quick start

&gt; Before installing Dify, make sure your machine meets the following minimum system requirements:
&gt;
&gt; - CPU &gt;= 2 Core
&gt; - RAM &gt;= 4 GiB

&lt;/br&gt;

The easiest way to start the Dify server is through [docker compose](docker/docker-compose.yaml). Before running Dify with the following commands, make sure that [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) are installed on your machine:

```bash
cd dify
cd docker
cp .env.example .env
docker compose up -d
```

After running, you can access the Dify dashboard in your browser at [http://localhost/install](http://localhost/install) and start the initialization process.

#### Seeking help

Please refer to our [FAQ](https://docs.dify.ai/getting-started/install-self-hosted/faqs) if you encounter problems setting up Dify. Reach out to [the community and us](#community--contact) if you are still having issues.

&gt; If you&#039;d like to contribute to Dify or do additional development, refer to our [guide to deploying from source code](https://docs.dify.ai/getting-started/install-self-hosted/local-source-code)

## Key features

**1. Workflow**:
Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.

https://github.com/langgenius/dify/assets/13230914/356df23e-1604-483d-80a6-9517ece318aa

**2. Comprehensive model support**:
Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found [here](https://docs.dify.ai/getting-started/readme/model-providers).

![providers-v5](https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3)

**3. Prompt IDE**:
Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.

**4. RAG Pipeline**:
Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.

**5. Agent capabilities**:
You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALL¬∑E, Stable Diffusion and WolframAlpha.

**6. LLMOps**:
Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.

**7. Backend-as-a-Service**:
All of Dify&#039;s offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.

## Feature Comparison

&lt;table style=&quot;width: 100%;&quot;&gt;
  &lt;tr&gt;
    &lt;th align=&quot;center&quot;&gt;Feature&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;Dify.AI&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;LangChain&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;Flowise&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;OpenAI Assistants API&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Programming Approach&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;API + App-oriented&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Python Code&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;App-oriented&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;API-oriented&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Supported LLMs&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;OpenAI-only&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;RAG Engine&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Agent&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Workflow&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Observability&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Enterprise Feature (SSO/Access control)&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Local Deployment&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Using Dify

- **Cloud &lt;/br&gt;**
  We host a [Dify Cloud](https://dify.ai) service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.

- **Self-hosting Dify Community Edition&lt;/br&gt;**
  Quickly get Dify running in your environment with this [starter guide](#quick-start).
  Use our [documentation](https://docs.dify.ai) for further references and more in-depth instructions.

- **Dify for enterprise / organizations&lt;/br&gt;**
  We provide additional enterprise-centric features. [Log your questions for us through this chatbot](https://udify.app/chat/22L1zSxg6yW1cWQg) or [send us an email](mailto:business@dify.ai?subject=[GitHub]Business%20License%20Inquiry) to discuss enterprise needs. &lt;/br&gt;
  &gt; For startups and small businesses using AWS, check out [Dify Premium on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6) and deploy it to your own AWS VPC with one click. It&#039;s an affordable AMI offering with the option to create apps with custom logo and branding.

## Staying ahead

Star Dify on GitHub and be instantly notified of new releases.

![star-us](https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4)

## Advanced Setup

If you need to customize the configuration, please refer to the comments in our [.env.example](docker/.env.example) file and update the corresponding values in your `.env` file. Additionally, you might need to make adjustments to the `docker-compose.yaml` file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run `docker-compose up -d`. You can find the full list of available environment variables [here](https://docs.dify.ai/getting-started/install-self-hosted/environments).

If you&#039;d like to configure a highly-available setup, there are community-contributed [Helm Charts](https://helm.sh/) and YAML files which allow Dify to be deployed on Kubernetes.

- [Helm Chart by @LeoQuote](https://github.com/douban/charts/tree/master/charts/dify)
- [Helm Chart by @BorisPolonsky](https://github.com/BorisPolonsky/dify-helm)
- [Helm Chart by @magicsong](https://github.com/magicsong/ai-charts)
- [YAML file by @Winson-030](https://github.com/Winson-030/dify-kubernetes)
- [YAML file by @wyy-holding](https://github.com/wyy-holding/dify-k8s)

#### Using Terraform for Deployment

Deploy Dify to Cloud Platform with a single click using [terraform](https://www.terraform.io/)

##### Azure Global

- [Azure Terraform by @nikawang](https://github.com/nikawang/dify-azure-terraform)

##### Google Cloud

- [Google Cloud Terraform by @sotazum](https://github.com/DeNA/dify-google-cloud-terraform)

#### Using AWS CDK for Deployment

Deploy Dify to AWS with [CDK](https://aws.amazon.com/cdk/)

##### AWS

- [AWS CDK by @KevinZhao](https://github.com/aws-samples/solution-for-deploying-dify-on-aws)

## Contributing

For those who&#039;d like to contribute code, see our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.

&gt; We are looking for contributors to help translate Dify into languages other than Mandarin or English. If you are interested in helping, please see the [i18n README](https://github.com/langgenius/dify/blob/main/web/i18n/README.md) for more information, and leave us a comment in the `global-users` channel of our [Discord Community Server](https://discord.gg/8Tpq4AcN9c).

## Community &amp; contact

- [Github Discussion](https://github.com/langgenius/dify/discussions). Best for: sharing feedback and asking questions.
- [GitHub Issues](https://github.com/langgenius/dify/issues). Best for: bugs you encounter using Dify.AI, and feature proposals. See our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
- [Discord](https://discord.gg/FngNHpbcY7). Best for: sharing your applications and hanging out with the community.
- [X(Twitter)](https://twitter.com/dify_ai). Best for: sharing your applications and hanging out with the community.

**Contributors**

&lt;a href=&quot;https://github.com/langgenius/dify/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=langgenius/dify&quot; /&gt;
&lt;/a&gt;

## Star history

[![Star History Chart](https://api.star-history.com/svg?repos=langgenius/dify&amp;type=Date)](https://star-history.com/#langgenius/dify&amp;Date)

## Security disclosure

To protect your privacy, please avoid posting security issues on GitHub. Instead, send your questions to security@dify.ai and we will provide you with a more detailed answer.

## License

This repository is available under the [Dify Open Source License](LICENSE), which is essentially Apache 2.0 with a few additional restrictions.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[microsoft/vscode]]></title>
            <link>https://github.com/microsoft/vscode</link>
            <guid>https://github.com/microsoft/vscode</guid>
            <pubDate>Sun, 11 May 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[Visual Studio Code]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/vscode">microsoft/vscode</a></h1>
            <p>Visual Studio Code</p>
            <p>Language: TypeScript</p>
            <p>Stars: 170,994</p>
            <p>Forks: 32,166</p>
            <p>Stars today: 53 stars today</p>
            <h2>README</h2><pre># Visual Studio Code - Open Source (&quot;Code - OSS&quot;)

[![Feature Requests](https://img.shields.io/github/issues/microsoft/vscode/feature-request.svg)](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)
[![Bugs](https://img.shields.io/github/issues/microsoft/vscode/bug.svg)](https://github.com/microsoft/vscode/issues?utf8=‚úì&amp;q=is%3Aissue+is%3Aopen+label%3Abug)
[![Gitter](https://img.shields.io/badge/chat-on%20gitter-yellow.svg)](https://gitter.im/Microsoft/vscode)

## The Repository

This repository (&quot;`Code - OSS`&quot;) is where we (Microsoft) develop the [Visual Studio Code](https://code.visualstudio.com) product together with the community. Not only do we work on code and issues here, we also publish our [roadmap](https://github.com/microsoft/vscode/wiki/Roadmap), [monthly iteration plans](https://github.com/microsoft/vscode/wiki/Iteration-Plans), and our [endgame plans](https://github.com/microsoft/vscode/wiki/Running-the-Endgame). This source code is available to everyone under the standard [MIT license](https://github.com/microsoft/vscode/blob/main/LICENSE.txt).

## Visual Studio Code

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;VS Code in action&quot; src=&quot;https://user-images.githubusercontent.com/35271042/118224532-3842c400-b438-11eb-923d-a5f66fa6785a.png&quot;&gt;
&lt;/p&gt;

[Visual Studio Code](https://code.visualstudio.com) is a distribution of the `Code - OSS` repository with Microsoft-specific customizations released under a traditional [Microsoft product license](https://code.visualstudio.com/License/).

[Visual Studio Code](https://code.visualstudio.com) combines the simplicity of a code editor with what developers need for their core edit-build-debug cycle. It provides comprehensive code editing, navigation, and understanding support along with lightweight debugging, a rich extensibility model, and lightweight integration with existing tools.

Visual Studio Code is updated monthly with new features and bug fixes. You can download it for Windows, macOS, and Linux on [Visual Studio Code&#039;s website](https://code.visualstudio.com/Download). To get the latest releases every day, install the [Insiders build](https://code.visualstudio.com/insiders).

## Contributing

There are many ways in which you can participate in this project, for example:

* [Submit bugs and feature requests](https://github.com/microsoft/vscode/issues), and help us verify as they are checked in
* Review [source code changes](https://github.com/microsoft/vscode/pulls)
* Review the [documentation](https://github.com/microsoft/vscode-docs) and make pull requests for anything from typos to additional and new content

If you are interested in fixing issues and contributing directly to the code base,
please see the document [How to Contribute](https://github.com/microsoft/vscode/wiki/How-to-Contribute), which covers the following:

* [How to build and run from source](https://github.com/microsoft/vscode/wiki/How-to-Contribute)
* [The development workflow, including debugging and running tests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#debugging)
* [Coding guidelines](https://github.com/microsoft/vscode/wiki/Coding-Guidelines)
* [Submitting pull requests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests)
* [Finding an issue to work on](https://github.com/microsoft/vscode/wiki/How-to-Contribute#where-to-contribute)
* [Contributing to translations](https://aka.ms/vscodeloc)

## Feedback

* Ask a question on [Stack Overflow](https://stackoverflow.com/questions/tagged/vscode)
* [Request a new feature](CONTRIBUTING.md)
* Upvote [popular feature requests](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)
* [File an issue](https://github.com/microsoft/vscode/issues)
* Connect with the extension author community on [GitHub Discussions](https://github.com/microsoft/vscode-discussions/discussions) or [Slack](https://aka.ms/vscode-dev-community)
* Follow [@code](https://twitter.com/code) and let us know what you think!

See our [wiki](https://github.com/microsoft/vscode/wiki/Feedback-Channels) for a description of each of these channels and information on some other available community-driven channels.

## Related Projects

Many of the core components and extensions to VS Code live in their own repositories on GitHub. For example, the [node debug adapter](https://github.com/microsoft/vscode-node-debug) and the [mono debug adapter](https://github.com/microsoft/vscode-mono-debug) repositories are separate from each other. For a complete list, please visit the [Related Projects](https://github.com/microsoft/vscode/wiki/Related-Projects) page on our [wiki](https://github.com/microsoft/vscode/wiki).

## Bundled Extensions

VS Code includes a set of built-in extensions located in the [extensions](extensions) folder, including grammars and snippets for many languages. Extensions that provide rich language support (code completion, Go to Definition) for a language have the suffix `language-features`. For example, the `json` extension provides coloring for `JSON` and the `json-language-features` extension provides rich language support for `JSON`.

## Development Container

This repository includes a Visual Studio Code Dev Containers / GitHub Codespaces development container.

* For [Dev Containers](https://aka.ms/vscode-remote/download/containers), use the **Dev Containers: Clone Repository in Container Volume...** command which creates a Docker volume for better disk I/O on macOS and Windows.
  * If you already have VS Code and Docker installed, you can also click [here](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/vscode) to get started. This will cause VS Code to automatically install the Dev Containers extension if needed, clone the source code into a container volume, and spin up a dev container for use.

* For Codespaces, install the [GitHub Codespaces](https://marketplace.visualstudio.com/items?itemName=GitHub.codespaces) extension in VS Code, and use the **Codespaces: Create New Codespace** command.

Docker / the Codespace should have at least **4 Cores and 6 GB of RAM (8 GB recommended)** to run full build. See the [development container README](.devcontainer/README.md) for more information.

## Code of Conduct

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## License

Copyright (c) Microsoft Corporation. All rights reserved.

Licensed under the [MIT](LICENSE.txt) license.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[aws-samples/generative-ai-use-cases]]></title>
            <link>https://github.com/aws-samples/generative-ai-use-cases</link>
            <guid>https://github.com/aws-samples/generative-ai-use-cases</guid>
            <pubDate>Sun, 11 May 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[Application implementation with business use cases for safely utilizing generative AI in business operations]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aws-samples/generative-ai-use-cases">aws-samples/generative-ai-use-cases</a></h1>
            <p>Application implementation with business use cases for safely utilizing generative AI in business operations</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,005</p>
            <p>Forks: 241</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;div markdown=&quot;1&quot; align=&quot;center&quot;&gt;
  &lt;h1&gt;Generative AI Use Cases (GenU)&lt;/h1&gt;

[![](https://img.shields.io/badge/Documentation-Latest-blue)](https://aws-samples.github.io/generative-ai-use-cases/index.html) [![](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/aws-samples/generative-ai-use-cases/blob/main/LICENSE) [![](https://github.com/aws-samples/generative-ai-use-cases/actions/workflows/node.js.yml/badge.svg)](https://github.com/aws-samples/generative-ai-use-cases/actions/workflows/node.js.yml) [![](https://github.com/aws-samples/generative-ai-use-cases/actions/workflows/browser-extension.yml/badge.svg)](https://github.com/aws-samples/generative-ai-use-cases/actions/workflows/browser-extension.yml)

English | [Êó•Êú¨Ë™û](./README_ja.md)

Application implementation with business use cases for safely utilizing generative AI in business operations

  &lt;img src=&quot;./docs/assets/images/sc_lp_en.png&quot; alt=&quot;Application implementation with business use cases for safely utilizing generative AI in business operations&quot; width=&quot;68%&quot;&gt;
&lt;/div&gt;

&gt; [!IMPORTANT]
&gt; GenU has supported multiple languages since v4.
&gt;
&gt; GenU „ÅØ v4 „Åã„ÇâÂ§öË®ÄË™ûÂØæÂøú„Åó„Åæ„Åó„Åü„ÄÇÊó•Êú¨Ë™û„Éâ„Ç≠„É•„É°„É≥„Éà„ÅØ[„Åì„Å°„Çâ](./README_ja.md)

## GenU Usage Patterns

Here we introduce GenU&#039;s features and options by usage pattern. For comprehensive deployment options, please refer to [this document](docs/en/DEPLOY_OPTION.md).

&gt; [!TIP]
&gt; Click on a usage pattern to see details

&lt;details markdown=&quot;1&quot;&gt;
  &lt;summary&gt;&lt;strong&gt;&lt;ins&gt;I want to experience generative AI use cases&lt;/ins&gt;&lt;/strong&gt;&lt;/summary&gt;

GenU provides a variety of standard use cases leveraging generative AI. These use cases can serve as seeds for ideas on how to utilize generative AI in business operations, or they can be directly applied to business as-is. We plan to continuously add more refined use cases in the future. If unnecessary, you can also [hide specific use cases](docs/en/DEPLOY_OPTION.md#hiding-specific-use-cases) with an option. Here are the use cases provided by default.

  &lt;br/&gt;
  &lt;br/&gt;
  &lt;table width=&quot;100%&quot;&gt;
    &lt;thead&gt;
      &lt;tr&gt;
        &lt;td width=&quot;20%&quot;&gt;Use Case&lt;/td&gt;
        &lt;td width=&quot;80%&quot;&gt;Description&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;Chat&lt;/td&gt;
        &lt;td&gt;You can interact with large language models (LLMs) in a chat format. The existence of platforms that allow direct dialogue with LLMs enables quick responses to specific and new use cases. It&#039;s also effective as a testing environment for prompt engineering.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Text Generation&lt;/td&gt;
        &lt;td&gt;Generating text in any context is one of the tasks LLMs excel at. It generates all kinds of text including articles, reports, and emails.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Summarization&lt;/td&gt;
        &lt;td&gt;LLMs are good at summarizing large amounts of text. Beyond simple summarization, they can also extract necessary information in a conversational format after being given text as context. For example, after reading a contract, you can ask questions like &quot;What are the conditions for XXX?&quot; or &quot;What is the amount for YYY?&quot;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Writing&lt;/td&gt;
        &lt;td&gt;LLMs can suggest improvements from a more objective perspective, considering not only typos but also the flow and content of the text. You can expect to improve quality by having the LLM objectively check points you might have missed before showing your work to others.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Translation&lt;/td&gt;
        &lt;td&gt;LLMs trained in multiple languages can perform translations. Beyond simple translation, they can incorporate various specified contextual information such as casualness and target audience into the translation.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Web Content Extraction&lt;/td&gt;
        &lt;td&gt;Extracts necessary information from web content such as blogs and documents. The LLM removes unnecessary information and formats it into well-structured text. Extracted content can be used in other use cases such as summarization and translation.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Image Generation&lt;/td&gt;
        &lt;td&gt;Image generation AI can create new images based on text or existing images. It allows for immediate visualization of ideas, potentially improving efficiency in design work. In this feature, LLMs can assist in creating prompts.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Video Generation&lt;/td&gt;
        &lt;td&gt;Video generation AI creates short videos from text. The generated videos can be used as materials in various scenarios.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Video Analysis&lt;/td&gt;
        &lt;td&gt;With multimodal models, it&#039;s now possible to input not only text but also images. In this feature, you can ask the LLM to analyze video frames and text inputs.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Diagram Generation&lt;/td&gt;
        &lt;td&gt;Diagram generation visualizes text and content on any topic using optimal diagrams. It allows for easy text-based diagram creation, enabling efficient creation of flowcharts and other diagrams even for non-programmers and non-designers.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Voice Chat&lt;/td&gt;
        &lt;td&gt;In Voice Chat, you can have a bidirectional voice chat with generative AI. Similar to natural conversation, you can also interrupt and speak while the AI is talking. Also, by setting a system prompt, you can have voice conversations with AI that has specific roles.&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/details&gt;

&lt;details markdown=&quot;1&quot;&gt;
  &lt;summary&gt;&lt;strong&gt;&lt;ins&gt;I want to do RAG&lt;/ins&gt;&lt;/strong&gt;&lt;/summary&gt;

RAG is a technique that allows LLMs to answer questions they normally couldn&#039;t by providing external up-to-date information or domain knowledge that LLMs typically struggle with.
PDF, Word, Excel, and other files accumulated within your organization can serve as information sources.
RAG also has the effect of preventing LLMs from providing &quot;plausible but incorrect information&quot; by only allowing answers based on evidence.

GenU provides a RAG Chat use case.
Two types of information sources are available for RAG Chat: [Amazon Kendra](docs/en/DEPLOY_OPTION.md) and [Knowledge Base](docs/en/DEPLOY_OPTION.md#enabling-rag-chat-knowledge-base-use-case).
When using Amazon Kendra, you can [use manually created S3 Buckets or Kendra Indexes as they are](docs/en/DEPLOY_OPTION.md#using-an-existing-amazon-kendra-index).
When using Knowledge Base, advanced RAG features such as [Advanced Parsing](docs/en/DEPLOY_OPTION.md#enabling-advanced-parsing), [Chunk Strategy Selection](docs/en/DEPLOY_OPTION.md#changing-chunking-strategy), [Query Decomposition](docs/en/DEPLOY_OPTION.md#enabling-rag-chat-knowledge-base-use-case), and [Reranking](docs/en/DEPLOY_OPTION.md#enabling-rag-chat-knowledge-base-use-case) are available.
Knowledge Base also allows for [Metadata Filter Settings](docs/en/DEPLOY_OPTION.md#metadata-filter-configuration).
For example, you can meet requirements such as &quot;switching accessible data sources by organization&quot; or &quot;allowing users to set filters from the UI.&quot;

&lt;/details&gt;

&lt;details markdown=&quot;1&quot;&gt;
  &lt;summary&gt;&lt;strong&gt;&lt;ins&gt;I want to use custom AI agents or Bedrock Flows within my organization&lt;/ins&gt;&lt;/strong&gt;&lt;/summary&gt;

When you [enable agents](docs/en/DEPLOY_OPTION.md#enabling-agent-chat-use-case) in GenU, Web Search Agent and Code Interpreter Agent are created.
The Web Search Agent searches the web for information to answer user questions. For example, it can answer &quot;What is AWS GenU?&quot;
The Code Interpreter Agent can execute code to respond to user requests. For example, it can respond to requests like &quot;Draw a scatter plot with some dummy data.&quot;

While Web Search Agent and Code Interpreter Agent are basic agents, you might want to use more practical agents tailored to your business needs.
GenU provides a feature to [import agents](docs/en/DEPLOY_OPTION.md#adding-manually-created-agents) that you&#039;ve created manually or with other assets.

By using GenU as a platform for agent utilization, you can leverage GenU&#039;s [rich security options](docs/en/DEPLOY_OPTION.md#security-related-settings) and [SAML authentication](docs/en/DEPLOY_OPTION.md#saml-authentication) to spread practical agents within your organization.
Additionally, you can [hide unnecessary standard use cases](docs/en/DEPLOY_OPTION.md#hiding-specific-use-cases) or [display agents inline](docs/en/DEPLOY_OPTION.md#displaying-agents-inline) to use GenU as a more agent-focused platform.

Similarly, there is an [import feature](docs/en/DEPLOY_OPTION.md#enabling-flow-chat-use-case) for Bedrock Flows, so please make use of it.

&lt;/details&gt;

&lt;details markdown=&quot;1&quot;&gt;
  &lt;summary&gt;&lt;strong&gt;&lt;ins&gt;I want to create custom use cases&lt;/ins&gt;&lt;/strong&gt;&lt;/summary&gt;

GenU provides a feature called &quot;Use Case Builder&quot; that allows you to create custom use cases by describing prompt templates in natural language.
Custom use case screens are automatically generated just from prompt templates, so no code changes to GenU itself are required.
Created use cases can be shared with all users who can log into the application, not just for personal use.
Use Case Builder can be [disabled](docs/en/DEPLOY_OPTION.md#use-case-builder-configuration) if not needed.
For more details about Use Case Builder, please check &lt;a href=&quot;https://aws.amazon.com/jp/blogs/news/genu-use-cases-builder/&quot;&gt;this blog&lt;/a&gt;.
&lt;br/&gt;
&lt;br/&gt;
While Use Case Builder can create use cases where you input text into forms or attach files, depending on your requirements, a chat UI might be more suitable.
In such cases, please utilize the system prompt saving feature of the &quot;Chat&quot; use case.
By saving system prompts, you can create business-necessary &quot;bots&quot; with just one click.
For example, you can create &quot;a bot that thoroughly reviews source code when input&quot; or &quot;a bot that extracts email addresses from input content.&quot;
Additionally, chat conversation histories can be shared with logged-in users, and system prompts can be imported from shared conversation histories.
&lt;br/&gt;
&lt;br/&gt;
Since GenU is OSS, you can also customize it to add your own use cases.
In that case, please be careful about conflicts with GenU&#039;s main branch.

&lt;/details&gt;

## Deployment

&gt; [!IMPORTANT]
&gt; Please enable the `modelIds` (text generation), `imageGenerationModelIds` (image generation), and `videoGenerationModelIds` (video generation) in the `modelRegion` region listed in [`/packages/cdk/cdk.json`](/packages/cdk/cdk.json). ([Amazon Bedrock Model access screen](https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/modelaccess))

GenU deployment uses [AWS Cloud Development Kit](https://aws.amazon.com/jp/cdk/) (CDK). If you cannot prepare a CDK execution environment, refer to the following deployment methods:

- [Deployment method using AWS CloudShell (if preparing your own environment is difficult)](docs/en/DEPLOY_ON_CLOUDSHELL.md)
- Workshop ([English](https://catalog.workshops.aws/generative-ai-use-cases) / [Japanese](https://catalog.workshops.aws/generative-ai-use-cases-jp))

First, run the following command. All commands should be executed at the repository root.

```bash
npm ci
```

If you&#039;ve never used CDK before, you need to [Bootstrap](https://docs.aws.amazon.com/ja_jp/cdk/v2/guide/bootstrapping.html) for the first time only. The following command is unnecessary if your environment is already bootstrapped.

```bash
npx -w packages/cdk cdk bootstrap
```

Next, deploy AWS resources with the following command. Please wait for the deployment to complete (it may take about 20 minutes).

```bash
# Normal deployment
npm run cdk:deploy

# Fast deployment (quickly deploy without pre-checking created resources)
npm run cdk:deploy:quick
```

## Architecture

![arch.drawio.png](./docs/assets/images/arch.drawio.png)

## Other Information

- [Deployment Options](docs/en/DEPLOY_OPTION.md)
- [Update Method](docs/en/UPDATE.md)
- [Local Development Environment Setup](docs/en/DEVELOPMENT.md)
- [Resource Deletion Method](docs/en/DESTROY.md)
- [How to Use as a Native App](docs/en/PWA.md)
- [Using Browser Extensions](docs/en/EXTENSION.md)

## Cost Estimation

We have published configuration and cost estimation examples for using GenU. (The service is pay-as-you-go, and actual costs will vary depending on your usage.)

- [Simple Version (without RAG) Estimation](https://aws.amazon.com/jp/cdp/ai-chatbot/)
- [With RAG (Amazon Kendra) Estimation](https://aws.amazon.com/jp/cdp/ai-chatapp/)
- [With RAG (Knowledge Base) Estimation](https://aws.amazon.com/jp/cdp/genai-chat-app/)

## Customer Case Studies

| Customer                                                                                                                          | Quote                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| :-------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| &lt;a href=&quot;https://www.yasashiite.com/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/yasashiite_logo.png&quot;&gt;&lt;/a&gt;              | **Yasashiite Co., Ltd.** &lt;br/&gt; _Thanks to GenU, we were able to provide added value to users and improve employee work efficiency. We continue to evolve from &quot;smooth operation&quot; to &quot;exciting work&quot; as employees&#039; &quot;previous work&quot; transforms into enjoyable work!_ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/yasashiite_case.png) &lt;br/&gt; „Éª[See case page](https://aws.amazon.com/jp/solutions/case-studies/yasashii-te/)                                |
| &lt;a href=&quot;https://www.takihyo.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/TAKIHYO_logo.png&quot;&gt;&lt;/a&gt;                  | **TAKIHYO Co., Ltd.** &lt;br/&gt; _Achieved internal business efficiency and reduced over 450 hours of work by utilizing generative AI. Applied Amazon Bedrock to clothing design, etc., and promoted digital talent development._ &lt;br/&gt; „Éª[See case page](https://aws.amazon.com/jp/solutions/case-studies/takihyo/)                                                                                                                                                     |
| &lt;a href=&quot;https://salsonido.com/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/salsonido_logo.png&quot;&gt;&lt;/a&gt;                    | **Salsonido Inc.** &lt;br/&gt; _By utilizing GenU, which is provided as a solution, we were able to quickly start improving business processes with generative AI._ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/salsonido_case.png) &lt;br/&gt; „Éª[Applied service](https://kirei.ai/)                                                                                                                                                                                |
| &lt;a href=&quot;https://www.tamura-ss.co.jp/jp/index.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/tamura-ss_logo.png&quot;&gt;&lt;/a&gt; | **TAMURA CORPORATION** &lt;br/&gt; _The application samples that AWS publishes on Github have a wealth of immediately testable functions, and by using them as they are, we were able to easily select functions that suited us and shorten the development time of the final system._&lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/tamura-ss_case.png)&lt;br/&gt;                                                                                                      |
| &lt;a href=&quot;https://jdsc.ai/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/jdsc_logo.png&quot;&gt;&lt;/a&gt;                               | **JDSC Inc.** &lt;br/&gt; _Amazon Bedrock allows us to securely use LLMs with our data. Also, we can switch to the optimal model depending on the purpose, allowing us to improve speed and accuracy while keeping costs down._ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/jdsc_case.png)                                                                                                                                                                      |
| &lt;a href=&quot;https://www.iret.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/iret_logo.png&quot;&gt;&lt;/a&gt;                        | **iret, Inc.** &lt;br/&gt; _To accumulate and systematize internal knowledge for BANDAI NAMCO Amusement Inc.&#039;s generative AI utilization, we developed a use case site using Generative AI Use Cases JP provided by AWS. iret, Inc. supported the design, construction, and development of this project._ &lt;br/&gt; „Éª[BANDAI NAMCO Amusement Inc.&#039;s cloud utilization case study](https://cloudpack.jp/casestudy/302.html?_gl=1*17hkazh*_gcl_au*ODA5MDk3NzI0LjE3MTM0MTQ2MDU) |
| &lt;a href=&quot;https://idealog.co.jp&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/idealog_logo.jpg&quot;&gt;&lt;/a&gt;                       | **IDEALOG Inc.** &lt;br/&gt; _I feel that we can achieve even greater work efficiency than with conventional generative AI tools. Using Amazon Bedrock, which doesn&#039;t use input/output data for model training, gives us peace of mind regarding security._ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/idealog_case.png) &lt;br/&gt; „Éª[Applied service](https://kaijosearch.com/)                                                                                   |
| &lt;a href=&quot;https://estyle.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/estyle_logo.png&quot;&gt;&lt;/a&gt;                        | **eStyle Inc.** &lt;br/&gt; _By utilizing GenU, we were able to build a generative AI environment in a short period and promote knowledge sharing within the company._ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/estyle_case.png)                                                                                                                                                                                                                             |
| &lt;a href=&quot;https://meidensha.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/meidensha_logo.svg&quot;&gt;&lt;/a&gt;                  | **Meidensha Corporation** &lt;br/&gt; _By using AWS services such as Amazon Bedrock and Amazon Kendra, we were able to quickly and securely build a generative AI usage environment. It contributes to employee work efficiency through automatic generation of meeting minutes and searching internal information._ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/meidensha_case.png)                                                                            |
| &lt;a href=&quot;https://www.st-grp.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/st-grp_logo.jpg&quot;&gt;&lt;/a&gt;                    | **Sankyo Tateyama, Inc.** &lt;br/&gt; _Information buried within the company became quickly searchable with Amazon Kendra. By referring to GenU, we were able to promptly provide the functions we needed, such as meeting minutes generation._ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/st-grp_case.png)                                                                                                                                                    |
| &lt;a href=&quot;https://www.oisixradaichi.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/oisixradaichi_logo.png&quot;&gt;&lt;/a&gt;      | **Oisix ra daichi Inc.** &lt;br/&gt; _Through the use case development project using GenU, we were able to grasp the necessary resources, project structure, external support, and talent development, which helped us clarify our image for the internal deployment of generative AI._ &lt;br/&gt; „Éª[See case page](https://aws.amazon.com/jp/s

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[portainer/portainer]]></title>
            <link>https://github.com/portainer/portainer</link>
            <guid>https://github.com/portainer/portainer</guid>
            <pubDate>Sun, 11 May 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[Making Docker and Kubernetes management easy.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/portainer/portainer">portainer/portainer</a></h1>
            <p>Making Docker and Kubernetes management easy.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 32,908</p>
            <p>Forks: 2,583</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img title=&quot;portainer&quot; src=&#039;https://github.com/portainer/portainer/blob/develop/app/assets/images/portainer-github-banner.png?raw=true&#039; /&gt;
&lt;/p&gt;

**Portainer Community Edition** is a lightweight service delivery platform for containerized applications that can be used to manage Docker, Swarm, Kubernetes and ACI environments. It is designed to be as simple to deploy as it is to use. The application allows you to manage all your orchestrator resources (containers, images, volumes, networks and more) through a ‚Äòsmart‚Äô GUI and/or an extensive API.

Portainer consists of a single container that can run on any cluster. It can be deployed as a Linux container or a Windows native container.

**Portainer Business Edition** builds on the open-source base and includes a range of advanced features and functions (like RBAC and Support) that are specific to the needs of business users.

- [Compare Portainer CE and Compare Portainer BE](https://portainer.io/products)
- [Take5 ‚Äì get 5 free nodes of Portainer Business for as long as you want them](https://portainer.io/pricing/take5)
- [Portainer BE install guide](https://install.portainer.io)

## Demo

You can try out the public demo instance: http://demo.portainer.io/ (login with the username **admin** and the password **tryportainer**).

Please note that the public demo cluster is **reset every 15min**.

## Latest Version

Portainer CE is updated regularly. We aim to do an update release every couple of months.

**The latest version of Portainer is 2.9.x**. Portainer is on version 2, the second number denotes the month of release.

## Getting started

- [Deploy Portainer](https://docs.portainer.io/v/ce-2.9/start/install)
- [Documentation](https://documentation.portainer.io)
- [Contribute to the project](https://documentation.portainer.io/contributing/instructions/)

## Features &amp; Functions

View [this](https://www.portainer.io/products) table to see all of the Portainer CE functionality and compare to Portainer Business.

- [Portainer CE for Docker / Docker Swarm](https://www.portainer.io/solutions/docker)
- [Portainer CE for Kubernetes](https://www.portainer.io/solutions/kubernetes-ui)
- [Portainer CE for Azure ACI](https://www.portainer.io/solutions/serverless-containers)

## Getting help

Portainer CE is an open source project and is supported by the community. You can buy a supported version of Portainer at portainer.io

Learn more about Portainers community support channels [here.](https://www.portainer.io/community_help)

- Issues: https://github.com/portainer/portainer/issues
- Slack (chat): [https://portainer.slack.com/](https://join.slack.com/t/portainer/shared_invite/zt-txh3ljab-52QHTyjCqbe5RibC2lcjKA)

You can join the Portainer Community by visiting community.portainer.io. This will give you advance notice of events, content and other related Portainer content.

## Reporting bugs and contributing

- Want to report a bug or request a feature? Please open [an issue](https://github.com/portainer/portainer/issues/new).
- Want to help us build **_portainer_**? Follow our [contribution guidelines](https://documentation.portainer.io/contributing/instructions/) to build it locally and make a pull request.

## Security

- Here at Portainer, we believe in [responsible disclosure](https://en.wikipedia.org/wiki/Responsible_disclosure) of security issues. If you have found a security issue, please report it to &lt;security@portainer.io&gt;.

## Work for us

If you are a developer, and our code in this repo makes sense to you, we would love to hear from you. We are always on the hunt for awesome devs, either freelance or employed. Drop us a line to info@portainer.io with your details and/or visit our [careers page](https://portainer.io/careers).

## Privacy

**To make sure we focus our development effort in the right places we need to know which features get used most often. To give us this information we use [Matomo Analytics](https://matomo.org/), which is hosted in Germany and is fully GDPR compliant.**

When Portainer first starts, you are given the option to DISABLE analytics. If you **don&#039;t** choose to disable it, we collect anonymous usage as per [our privacy policy](https://www.portainer.io/documentation/in-app-analytics-and-privacy-policy/). **Please note**, there is no personally identifiable information sent or stored at any time and we only use the data to help us improve Portainer.

## Limitations

Portainer supports &quot;Current - 2 docker versions only. Prior versions may operate, however these are not supported.

## Licensing

Portainer is licensed under the zlib license. See [LICENSE](./LICENSE) for reference.

Portainer also contains code from open source projects. See [ATTRIBUTIONS.md](./ATTRIBUTIONS.md) for a list.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[clash-verge-rev/clash-verge-rev]]></title>
            <link>https://github.com/clash-verge-rev/clash-verge-rev</link>
            <guid>https://github.com/clash-verge-rev/clash-verge-rev</guid>
            <pubDate>Sun, 11 May 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[A modern GUI client based on Tauri, designed to run in Windows, macOS and Linux for tailored proxy experience]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/clash-verge-rev/clash-verge-rev">clash-verge-rev/clash-verge-rev</a></h1>
            <p>A modern GUI client based on Tauri, designed to run in Windows, macOS and Linux for tailored proxy experience</p>
            <p>Language: TypeScript</p>
            <p>Stars: 57,554</p>
            <p>Forks: 4,446</p>
            <p>Stars today: 105 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img src=&quot;./src-tauri/icons/icon.png&quot; alt=&quot;Clash&quot; width=&quot;128&quot; /&gt;
  &lt;br&gt;
  Continuation of &lt;a href=&quot;https://github.com/zzzgydi/clash-verge&quot;&gt;Clash Verge&lt;/a&gt;
  &lt;br&gt;
&lt;/h1&gt;

&lt;h3 align=&quot;center&quot;&gt;
A Clash Meta GUI based on &lt;a href=&quot;https://github.com/tauri-apps/tauri&quot;&gt;Tauri&lt;/a&gt;.
&lt;/h3&gt;

## Preview

| Dark                             | Light                             |
| -------------------------------- | --------------------------------- |
| ![È¢ÑËßà](./docs/preview_dark.png) | ![È¢ÑËßà](./docs/preview_light.png) |

## Install

ËØ∑Âà∞ÂèëÂ∏ÉÈ°µÈù¢‰∏ãËΩΩÂØπÂ∫îÁöÑÂÆâË£ÖÂåÖÔºö[Release page](https://github.com/clash-verge-rev/clash-verge-rev/releases)&lt;br&gt;
Go to the [release page](https://github.com/clash-verge-rev/clash-verge-rev/releases) to download the corresponding installation package&lt;br&gt;
Supports Windows (x64/x86), Linux (x64/arm64) and macOS 10.15+ (intel/apple).

### ÂÆâË£ÖËØ¥ÊòéÂíåÂ∏∏ËßÅÈóÆÈ¢òÔºåËØ∑Âà∞[ÊñáÊ°£È°µ](https://clash-verge-rev.github.io/)Êü•ÁúãÔºö[Doc](https://clash-verge-rev.github.io/)

---

### TG È¢ëÈÅì: [@clash_verge_rev](https://t.me/clash_verge_re)

## Promotion

[ÁãóÁãóÂä†ÈÄü ‚Äî‚Äî ÊäÄÊúØÊµÅÊú∫Âú∫ Doggygo VPN](https://verge.dginv.click/#/register?code=oaxsAGo6)

- È´òÊÄßËÉΩÊµ∑Â§ñÊú∫Âú∫ÔºåÂÖçË¥πËØïÁî®Ôºå‰ºòÊÉ†Â•óÈ§êÔºåËß£ÈîÅÊµÅÂ™í‰ΩìÔºåÂÖ®ÁêÉÈ¶ñÂÆ∂ÊîØÊåÅ Hysteria ÂçèËÆÆ„ÄÇ
- ‰ΩøÁî® Clash Verge ‰∏ìÂ±ûÈÇÄËØ∑ÈìæÊé•Ê≥®ÂÜåÈÄÅ 3 Â§©ÔºåÊØèÂ§© 1G ÊµÅÈáèÂÖçË¥πËØïÁî®Ôºö[ÁÇπÊ≠§Ê≥®ÂÜå](https://verge.dginv.click/#/register?code=oaxsAGo6)
- Clash Verge ‰∏ìÂ±û 8 Êäò‰ºòÊÉ†Á†Å: verge20 (‰ªÖÊúâ 500 ‰ªΩ)
- ‰ºòÊÉ†Â•óÈ§êÊØèÊúà‰ªÖÈúÄ 15.8 ÂÖÉÔºå160G ÊµÅÈáèÔºåÂπ¥‰ªò 8 Êäò
- Êµ∑Â§ñÂõ¢ÈòüÔºåÊó†Ë∑ëË∑ØÈ£éÈô©ÔºåÈ´òËææ 50% Ëøî‰Ω£
- ÈõÜÁæ§Ë¥üËΩΩÂùáË°°ËÆæËÆ°ÔºåÈ´òÈÄü‰∏ìÁ∫ø(ÂÖºÂÆπËÄÅÂÆ¢Êà∑Á´Ø)ÔºåÊûÅ‰ΩéÂª∂ËøüÔºåÊó†ËßÜÊôöÈ´òÂ≥∞Ôºå4K ÁßíÂºÄ
- ÂÖ®ÁêÉÈ¶ñÂÆ∂ Hysteria ÂçèËÆÆÊú∫Âú∫ÔºåÁé∞Â∑≤‰∏äÁ∫øÊõ¥Âø´ÁöÑ `Hysteria2` ÂçèËÆÆ(Clash Verge ÂÆ¢Êà∑Á´ØÊúÄ‰Ω≥Êê≠ÈÖç)
- Ëß£ÈîÅÊµÅÂ™í‰ΩìÂèä ChatGPT
- ÂÆòÁΩëÔºö[https://ÁãóÁãóÂä†ÈÄü.com](https://verge.dginv.click/#/register?code=oaxsAGo6)

## Features

- Âü∫‰∫éÊÄßËÉΩÂº∫Âä≤ÁöÑ Rust Âíå Tauri 2 Ê°ÜÊû∂
- ÂÜÖÁΩÆ[Clash.Meta(mihomo)](https://github.com/MetaCubeX/mihomo)ÂÜÖÊ†∏ÔºåÂπ∂ÊîØÊåÅÂàáÊç¢ `Alpha` ÁâàÊú¨ÂÜÖÊ†∏„ÄÇ
- ÁÆÄÊ¥ÅÁæéËßÇÁöÑÁî®Êà∑ÁïåÈù¢ÔºåÊîØÊåÅËá™ÂÆö‰πâ‰∏ªÈ¢òÈ¢úËâ≤„ÄÅ‰ª£ÁêÜÁªÑ/ÊâòÁõòÂõæÊ†á‰ª•Âèä `CSS Injection`„ÄÇ
- ÈÖçÁΩÆÊñá‰ª∂ÁÆ°ÁêÜÂíåÂ¢ûÂº∫ÔºàMerge Âíå ScriptÔºâÔºåÈÖçÁΩÆÊñá‰ª∂ËØ≠Ê≥ïÊèêÁ§∫„ÄÇ
- Á≥ªÁªü‰ª£ÁêÜÂíåÂÆàÂç´„ÄÅ`TUN(ËôöÊãüÁΩëÂç°)` Ê®°Âºè„ÄÇ
- ÂèØËßÜÂåñËäÇÁÇπÂíåËßÑÂàôÁºñËæë
- WebDav ÈÖçÁΩÆÂ§á‰ªΩÂíåÂêåÊ≠•

### FAQ

Refer to [Doc FAQ Page](https://clash-verge-rev.github.io/faq/windows.html)

### Donation

[ÊçêÂä©Clash Verge RevÁöÑÂºÄÂèë](https://github.com/sponsors/clash-verge-rev)

## Development

See [CONTRIBUTING.md](./CONTRIBUTING.md) for more details.

To run the development server, execute the following commands after all prerequisites for **Tauri** are installed:

```shell
pnpm i
pnpm run check
pnpm dev
```

## Contributions

Issue and PR welcome!

## Acknowledgement

Clash Verge rev was based on or inspired by these projects and so on:

- [zzzgydi/clash-verge](https://github.com/zzzgydi/clash-verge): A Clash GUI based on tauri. Supports Windows, macOS and Linux.
- [tauri-apps/tauri](https://github.com/tauri-apps/tauri): Build smaller, faster, and more secure desktop applications with a web frontend.
- [Dreamacro/clash](https://github.com/Dreamacro/clash): A rule-based tunnel in Go.
- [MetaCubeX/mihomo](https://github.com/MetaCubeX/mihomo): A rule-based tunnel in Go.
- [Fndroid/clash_for_windows_pkg](https://github.com/Fndroid/clash_for_windows_pkg): A Windows/macOS GUI based on Clash.
- [vitejs/vite](https://github.com/vitejs/vite): Next generation frontend tooling. It&#039;s fast!

## License

GPL-3.0 License. See [License here](./LICENSE) for details.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[coder/code-server]]></title>
            <link>https://github.com/coder/code-server</link>
            <guid>https://github.com/coder/code-server</guid>
            <pubDate>Sun, 11 May 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[VS Code in the browser]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/coder/code-server">coder/code-server</a></h1>
            <p>VS Code in the browser</p>
            <p>Language: TypeScript</p>
            <p>Stars: 71,618</p>
            <p>Forks: 5,950</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[web-infra-dev/midscene]]></title>
            <link>https://github.com/web-infra-dev/midscene</link>
            <guid>https://github.com/web-infra-dev/midscene</guid>
            <pubDate>Sun, 11 May 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[Your AI Operator for Web, Android, Automation & Testing.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/web-infra-dev/midscene">web-infra-dev/midscene</a></h1>
            <p>Your AI Operator for Web, Android, Automation & Testing.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 8,717</p>
            <p>Forks: 520</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Midscene.js&quot;  width=&quot;260&quot; src=&quot;https://github.com/user-attachments/assets/f60de3c1-dd6f-4213-97a1-85bf7c6e79e4&quot;&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Midscene.js&lt;/h1&gt;
&lt;div align=&quot;center&quot;&gt;

English | [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh.md)

&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  Your AI Operator for Web, Android, Automation &amp; Testing
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/@midscene/web&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@midscene/web?style=flat-square&amp;color=00a8f0&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%F0%9F%A4%97-UI%20TARS%20Models-yellow&quot; alt=&quot;huagging face model&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://npm-compare.com/@midscene/web/#timeRange=THREE_YEARS&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/@midscene/web.svg?style=flat-square&amp;color=00a8f0&quot; alt=&quot;downloads&quot; /&gt;&lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square&amp;color=00a8f0&quot; alt=&quot;License&quot; /&gt;
  &lt;a href=&quot;https://discord.gg/2JyBHxszE4&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1328277792730779648?style=flat-square&amp;color=7289DA&amp;label=Discord&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;discord&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/midscene_ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/midscene_ai?style=flat-square&quot; alt=&quot;twitter&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

Midscene.js allows AI to serve as your web and Android operator ü§ñ. Simply describe what you want to achieve in natural language, and it will assist you in operating the interface, validating content, and extracting data. Whether you seek a quick experience or in-depth development, you&#039;ll find it easy to get started.

## Showcases

| Instruction  | Video |
| :---:  | :---: |
| Post a Tweet (By UI-TARS model)      |    &lt;video src=&quot;https://github.com/user-attachments/assets/bb3d695a-fbff-4af1-b6cc-5e967c07ccee&quot; height=&quot;300&quot; /&gt;    |
| Use JS code to drive task orchestration, collect information about Jay Chou&#039;s concert, and write it into Google Docs (By UI-TARS model)   | &lt;video src=&quot;https://github.com/user-attachments/assets/75474138-f51f-4c54-b3cf-46d61d059999&quot; height=&quot;300&quot; /&gt;        |
| Control Maps App on Android (By Qwen-2.5-VL model)   | &lt;video src=&quot;https://github.com/user-attachments/assets/1f5bab0e-4c28-44e1-b378-a38809b05a00&quot; height=&quot;300&quot; /&gt;        |
| Using midscene mcp to browse the page (https://www.saucedemo.com/), perform login, add products, place orders, and finally generate test cases based on mcp execution steps and playwright example | &lt;video src=&quot;https://github.com/user-attachments/assets/5cab578d-feb3-4250-8c7e-6793fe38a5be&quot; height=&quot;300&quot; /&gt;        |

## üì¢ 2025 Feb: New open-source model choice - UI-TARS and Qwen2.5-VL

Besides the default model *GPT-4o*, we have added two new recommended open-source models to Midscene.js: *UI-TARS* and *Qwen2.5-VL*. (Yes, Open Source models !) They are dedicated models for image recognition and UI automation, which are known for performing well in UI automation scenarios. Read more about it in [Choose a model](https://midscenejs.com/choose-a-model).

## üí° Features
- **Natural Language Interaction üëÜ**: Just describe your goals and steps, and Midscene will plan and operate the user interface for you.
- **UI Automation ü§ñ**
  - **Web Automation üñ•Ô∏è**: Start in-browser experience immediately through [the Chrome extension](https://midscenejs.com/quick-experience.html), or integrate with [Puppeteer](https://midscenejs.com/integrate-with-puppeteer.html) and [Playwright](https://midscenejs.com/integrate-with-playwright.html).
  - **Android Automation üì±**: Use [the Android playground](https://midscenejs.com/quick-experience-with-android.html) to start experience immediately, or integrate javascript SDK with [adb](https://midscenejs.com/integrate-with-android.html).
- **MCP Integration üîó**: Allows other MCP Clients to directly use Midscene&#039;s capabilities. For more details, please read [MCP Integration](https://midscenejs.com/zh/mcp.html).
- **Visual Reports for Debugging üéûÔ∏è**: Through our test reports and Playground, you can easily understand, replay and debug the entire process.
- **Support Caching üîÑ**: The first time you execute a task through AI, it will be cached, and subsequent executions of the same task will significantly improve execution efficiency.
- **Completely Open Source üî•**: Experience a whole new automation development experience, enjoy!
- **Understand UI, JSON Format Responses üîç**: You can specify data format requirements and receive responses in JSON format.
- **Intuitive Assertions ü§î**: Express your assertions in natural language, and AI will understand and process them.

## ‚ú® Model Choices

You can use multimodal LLMs like `gpt-4o`, or visual-language models like `Qwen2.5-VL`, `gemini-2.5-pro` and `UI-TARS`. In which `UI-TARS` is an open-source model dedicated for UI automation.

Read more about [Choose a model](https://midscenejs.com/choose-a-model)

## üëÄ Comparing to ...

There are so many UI automation tools out there, and each one seems to be all-powerful. What&#039;s special about Midscene.js?

* Debugging Experience: You will soon realize that debugging and maintaining automation scripts is the real challenge. No matter how magical the demo looks, ensuring stability over time requires careful debugging. Midscene.js offers a visualized report file, a built-in playground, and a Chrome Extension to simplify the debugging process. These are the tools most developers truly need, and we&#039;re continually working to improve the debugging experience.

* Open Source, Free, Deploy as you want: Midscene.js is an open-source project. It&#039;s decoupled from any cloud service and model provider, you can choose either public or private deployment. There is always a suitable plan for your business.

* Integrate with Javascript: You can always bet on Javascript üòé

## üìÑ Resources 

* [Home Page: https://midscenejs.com](https://midscenejs.com/)
* Web Browser Automation
  * [Quick Experience By Chrome Extension](https://midscenejs.com/quick-experience.html)
  * [Automate with Scripts in YAML](https://midscenejs.com/automate-with-scripts-in-yaml.html)
  * [Bridge Mode by Chrome Extension](https://midscenejs.com/bridge-mode-by-chrome-extension.html)
  * [Integrate with Puppeteer](https://midscenejs.com/integrate-with-puppeteer.html)
  * [Integrate with Playwright](https://midscenejs.com/integrate-with-playwright.html)
* Android Automation
  * [Quick Experience by Android Playground](https://midscenejs.com/quick-experience-with-android.html)
  * [Integrate with Android(adb)](https://midscenejs.com/integrate-with-android.html)
* [API Reference](https://midscenejs.com/api.html)
* [Choose a model](https://midscenejs.com/choose-a-model.html)
* [Config Model and Provider](https://midscenejs.com/model-provider.html)

## ü§ù Community

* [Discord](https://discord.gg/2JyBHxszE4)
* [Follow us on X](https://x.com/midscene_ai)
* [Lark Group](https://applink.larkoffice.com/client/chat/chatter/add_by_link?link_token=291q2b25-e913-411a-8c51-191e59aab14d)


## üìù Credits

We would like to thank the following projects:

- [Rsbuild](https://github.com/web-infra-dev/rsbuild) for the build tool.
- [UI-TARS](https://github.com/bytedance/ui-tars) for the open-source agent model UI-TARS.
- [Qwen2.5-VL](https://github.com/QwenLM/Qwen2.5-VL) for the open-source VL model Qwen2.5-VL.
- [scrcpy](https://github.com/Genymobile/scrcpy) and [yume-chan](https://github.com/yume-chan) allow us to control Android devices with browser.
- [appium-adb](https://github.com/appium/appium-adb) for the javascript bridge of adb.
- [YADB](https://github.com/ysbing/YADB) for the yadb tool which improves the performance of text input.
- [Puppeteer](https://github.com/puppeteer/puppeteer) for browser automation and control.
- [Playwright](https://github.com/microsoft/playwright) for browser automation and control and testing.

## Citation

If you use Midscene.js in your research or project, please cite:

```bibtex
@software{Midscene.js,
  author = {Xiao Zhou, Tao Yu, YiBing Lin},
  title = {Midscene.js: Your AI Operator for Web, Android, Automation &amp; Testing.},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/web-infra-dev/midscene}
}
```


## üìù License

Midscene.js is [MIT licensed](https://github.com/web-infra-dev/midscene/blob/main/LICENSE).

---

&lt;div align=&quot;center&quot;&gt;
  If this project helps you or inspires you, please give us a ‚≠êÔ∏è
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lobehub/lobe-chat]]></title>
            <link>https://github.com/lobehub/lobe-chat</link>
            <guid>https://github.com/lobehub/lobe-chat</guid>
            <pubDate>Sun, 11 May 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[ü§Ø Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / DeepSeek / Qwen), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Plugins/Artifacts) and Thinking. One-click FREE deployment of your private ChatGPT/ Claude / DeepSeek application.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobe-chat">lobehub/lobe-chat</a></h1>
            <p>ü§Ø Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / DeepSeek / Qwen), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Plugins/Artifacts) and Thinking. One-click FREE deployment of your private ChatGPT/ Claude / DeepSeek application.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 60,316</p>
            <p>Forks: 12,702</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# Lobe Chat

An open-source, modern-design ChatGPT/LLMs UI/Framework.&lt;br/&gt;
Supports speech-synthesis, multi-modal, and extensible ([function call][docs-functionc-call]) plugin system.&lt;br/&gt;
One-click **FREE** deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.

**English** ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md) ¬∑ [Official Site][official-site] ¬∑ [Changelog][changelog] ¬∑ [Documents][docs] ¬∑ [Blog][blog] ¬∑ [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeChat Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Pioneering the new age of thinking and creating. Built for you, the Super Individual.&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url]

![][image-overview]

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [üëãüèª Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [‚ú® Features](#-features)
  - [`1` Chain of Thought](#1-chain-of-thought)
  - [`2` Branching Conversations](#2-branching-conversations)
  - [`3` Artifacts Support](#3-artifacts-support)
  - [`4` File Upload /Knowledge Base](#4-file-upload-knowledge-base)
  - [`5` Multi-Model Service Provider Support](#5-multi-model-service-provider-support)
  - [`6` Local Large Language Model (LLM) Support](#6-local-large-language-model-llm-support)
  - [`7` Model Visual Recognition](#7-model-visual-recognition)
  - [`8` TTS &amp; STT Voice Conversation](#8-tts--stt-voice-conversation)
  - [`9` Text to Image Generation](#9-text-to-image-generation)
  - [`10` Plugin System (Function Calling)](#10-plugin-system-function-calling)
  - [`11` Agent Market (GPTs)](#11-agent-market-gpts)
  - [`12` Support Local / Remote Database](#12-support-local--remote-database)
  - [`13` Support Multi-User Management](#13-support-multi-user-management)
  - [`14` Progressive Web App (PWA)](#14-progressive-web-app-pwa)
  - [`15` Mobile Device Adaptation](#15-mobile-device-adaptation)
  - [`16` Custom Themes](#16-custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [‚ö°Ô∏è Performance](#Ô∏è-performance)
- [üõ≥ Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [üì¶ Ecosystem](#-ecosystem)
- [üß© Plugins](#-plugins)
- [‚å®Ô∏è Local Development](#Ô∏è-local-development)
- [ü§ù Contributing](#-contributing)
- [‚ù§Ô∏è Sponsor](#Ô∏è-sponsor)
- [üîó More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

## üëãüèª Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![][vercel-shield-badge]][vercel-link]   | No installation or registration necessary! Visit our website to experience it firsthand.                           |
| :---------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link] | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub. |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ ‚≠êÔ∏è

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## ‚ú® Features

[![][image-feat-cot]][docs-feat-cot]

### `1` [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### `2` [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### `3` [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeChat. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### `4` [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [üìò LobeChat Knowledge Base Launch ‚Äî From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### `5` [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

- **[OpenAI](https://lobechat.com/discover/provider/openai)**: OpenAI is a global leader in artificial intelligence research, with models like the GPT series pushing the frontiers of natural language processing. OpenAI is committed to transforming multiple industries through innovative and efficient AI solutions. Their products demonstrate significant performance and cost-effectiveness, widely used in research, business, and innovative applications.
- **[Ollama](https://lobechat.com/discover/provider/ollama)**: Ollama provides models that cover a wide range of fields, including code generation, mathematical operations, multilingual processing, and conversational interaction, catering to diverse enterprise-level and localized deployment needs.
- **[Anthropic](https://lobechat.com/discover/provider/anthropic)**: Anthropic is a company focused on AI research and development, offering a range of advanced language models such as Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Opus, and Claude 3 Haiku. These models achieve an ideal balance between intelligence, speed, and cost, suitable for various applications from enterprise workloads to rapid-response scenarios. Claude 3.5 Sonnet, as their latest model, has excelled in multiple evaluations while maintaining a high cost-performance ratio.
- **[Bedrock](https://lobechat.com/discover/provider/bedrock)**: Bedrock is a service provided by Amazon AWS, focusing on delivering advanced AI language and visual models for enterprises. Its model family includes Anthropic&#039;s Claude series, Meta&#039;s Llama 3.1 series, and more, offering a range of options from lightweight to high-performance, supporting tasks such as text generation, conversation, and image processing for businesses of varying scales and needs.
- **[Google](https://lobechat.com/discover/provider/google)**: Google&#039;s Gemini series represents its most advanced, versatile AI models, developed by Google DeepMind, designed for multimodal capabilities, supporting seamless understanding and processing of text, code, images, audio, and video. Suitable for various environments from data centers to mobile devices, it significantly enhances the efficiency and applicability of AI models.
- **[DeepSeek](https://lobechat.com/discover/provider/deepseek)**: DeepSeek is a company focused on AI technology research and application, with its latest model DeepSeek-V2.5 integrating general dialogue and code processing capabilities, achieving significant improvements in human preference alignment, writing tasks, and instruction following.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[HuggingFace](https://lobechat.com/discover/provider/huggingface)**: The HuggingFace Inference API provides a fast and free way for you to explore thousands of models for various tasks. Whether you are prototyping for a new application or experimenting with the capabilities of machine learning, this API gives you instant access to high-performance models across multiple domains.
- **[OpenRouter](https://lobechat.com/discover/provider/openrouter)**: OpenRouter is a service platform providing access to various cutting-edge large model interfaces, supporting OpenAI, Anthropic, LLaMA, and more, suitable for diverse development and application needs. Users can flexibly choose the optimal model and pricing based on their requirements, enhancing the AI experience.
- **[Cloudflare Workers AI](https://lobechat.com/discover/provider/cloudflare)**: Run serverless GPU-powered machine learning models on Cloudflare&#039;s global network.

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+30)&lt;/kbd&gt;&lt;/summary&gt;

- **[GitHub](https://lobechat.com/discover/provider/github)**: With GitHub Models, developers can become AI engineers and leverage the industry&#039;s leading AI models.
- **[Novita](https://lobechat.com/discover/provider/novita)**: Novita AI is a platform providing a variety of large language models and AI image generation API services, flexible, reliable, and cost-effective. It supports the latest open-source models like Llama3 and Mistral, offering a comprehensive, user-friendly, and auto-scaling API solution for generative AI application development, suitable for the rapid growth of AI startups.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[Together AI](https://lobechat.com/discover/provider/togetherai)**: Together AI is dedicated to achieving leading performance through innovative AI models, offering extensive customization capabilities, including rapid scaling support and intuitive deployment processes to meet various enterprise needs.
- **[Fireworks AI](https://lobechat.com/discover/provider/fireworksai)**: Fireworks AI is a leading provider of advanced language model services, focusing on functional calling and multimodal processing. Its latest model, Firefunction V2, is based on Llama-3, optimized for function calling, conversation, and instruction following. The visual language model FireLLaVA-13B supports mixed input of images and text. Other notable models include the Llama series and Mixtral series, providing efficient multilingual instruction following and generation support.
- **[Groq](https://lobechat.com/discover/provider/groq)**: Groq&#039;s LPU inference engine has excelled in the latest independent large language model (LLM) benchmarks, redefining the standards for AI solutions with its remarkable speed and efficiency. Groq represents instant inference speed, demonstrating strong performance in cloud-based deployments.
- **[Perplexity](https://lobechat.com/discover/provider/perplexity)**: Perplexity is a leading provider of conversational generation models, offering various advanced Llama 3.1 models that support both online and offline applications, particularly suited for complex natural language processing tasks.
- **[Mistral](https://lobechat.com/discover/provider/mistral)**: Mistral provides advanced general, specialized, and research models widely used in complex reasoning, multilingual tasks, and code generation. Through functional calling interfaces, users can integrate custom functionalities for specific applications.
- **[Ai21Labs](https://lobechat.com/discover/provider/ai21)**: AI21 Labs builds foundational models and AI systems for enterprises, accelerating the application of generative AI in production.
- **[Upstage](https://lobechat.com/discover/provider/upstage)**: Upstage focuses on developing AI models for various business needs, including Solar LLM and document AI, aiming to achieve artificial general intelligence (AGI) for work. It allows for the creation of simple conversational agents through Chat API and supports functional calling, translation, embedding, and domain-specific applications.
- **[xAI](https://lobechat.com/discover/provider/xai)**: xAI is a company dedicated to building artificial intelligence to accelerate human scientific discovery. Our mission is to advance our collective understanding of the universe.
- **[Qwen](https://lobechat.com/discover/provider/qwen)**: Tongyi Qianwen is a large-scale language model independently developed by Alibaba Cloud, featuring strong natural language understanding and generation capabilities. It can answer various questions, create written content, express opinions, and write code, playing a role in multiple fields.
- **[Wenxin](https://lobechat.com/discover/provider/wenxin)**: An enterprise-level one-stop platform for large model and AI-native application development and services, providing the most comprehensive and user-friendly toolchain for the entire process of generative artificial intelligence model development and application development.
- **[Hunyuan](https://lobechat.com/discover/provider/hunyuan)**: A large language model developed by Tencent, equipped with powerful Chinese creative capabilities, logical reasoning abilities in complex contexts, and reliable task execution skills.
- **[ZhiPu](https://lobechat.com/discover/provider/zhipu)**: Zhipu AI offers an open platform for multimodal and language models, supporting a wide range of AI application scenarios, including text processing, image understanding, and programming assistance.
- **[SiliconCloud](https://lobechat.com/discover/provider/siliconcloud)**: SiliconFlow is dedicated to accelerating AGI for the benefit of humanity, enhancing large-scale AI efficiency through an easy-to-use and cost-effective GenAI stack.
- **[01.AI](https://lobechat.com/discover/provider/zeroone)**: 01.AI focuses on AI 2.0 era technologies, vigorously promoting the innovation and application of &#039;human + artificial intelligence&#039;, using powerful models and advanced AI technologies to enhance human productivity and achieve technological empowerment.
- **[Spark](https://lobechat.com/discover/provider/spark)**: iFlytek&#039;s Spark model provides powerful AI capabilities across multiple domains and languages, utilizing advanced natural language processing technology to build innovative applications suitable for smart hardware, smart healthcare, smart finance, and other vertical scenarios.
- **[SenseNova](https://lobechat.com/discover/provider/sensenova)**: SenseNova, backed by SenseTime&#039;s robust infrastructure, offers efficient and user-friendly full-stack large model services.
- **[Stepfun](https://lobechat.com/discover/provider/stepfun)**: StepFun&#039;s large model possesses industry-leading multimodal and complex reasoning capabilities, supporting ultra-long text understanding and powerful autonomous scheduling search engine functions.
- **[Moonshot](https://lobechat.com/discover/provider/moonshot)**: Moonshot is an open-source platform launched by Beijing Dark Side Technology Co., Ltd., providing various natural language processing models with a wide range of applications, including but not limited to content creation, academic research, intelligent recommendations, and medical diagnosis, supporting long text processing and complex generation tasks.
- **[Baichuan](https://lobechat.com/discover/provider/baichuan)**: Baichuan Intelligence is a company focused on the research and development of large AI models, with its models excelling in domestic knowledge encyclopedias, long text processing, and generative creation tasks in Chinese, surpassing mainstream foreign models. Baichuan Intelligence also possesses industry-leading multimodal capabilities, performing excellently in multiple authoritative evaluations. Its models include Baichuan 4, Baichuan 3 Turbo, and Baichuan 3 Turbo 128k, each optimized for different application scenarios, providing cost-effective solutions.
- **[Minimax](https://lobechat.com/discover/provider/minimax)**: MiniMax is a general artificial intelligence technology company established in 2021, dedicated to co-creating intelligence with users. MiniMax has independently developed general large models of different modalities, including trillion-parameter MoE text models, voice models, and image models, and has launched applications such as Conch AI.
- **[InternLM](https://lobechat.com/di

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[software-mansion/react-native-reanimated]]></title>
            <link>https://github.com/software-mansion/react-native-reanimated</link>
            <guid>https://github.com/software-mansion/react-native-reanimated</guid>
            <pubDate>Sun, 11 May 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[React Native's Animated library reimplemented]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/software-mansion/react-native-reanimated">software-mansion/react-native-reanimated</a></h1>
            <p>React Native's Animated library reimplemented</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,644</p>
            <p>Forks: 1,359</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://user-images.githubusercontent.com/16062886/117443145-ff868480-af37-11eb-8680-648bccf0d0ce.png&quot; alt=&quot;React Native Reanimated by Software Mansion&quot; width=&quot;100%&quot;&gt;

### Create smooth animations with an excellent developer experience.

&gt; Reanimated 4 is here! Check out our [documentation page](https://docs.swmansion.com/react-native-reanimated/) for more information

### Nightly CI state

[![NPM Reanimated publish nightly](https://github.com/software-mansion/react-native-reanimated/actions/workflows/npm-reanimated-publish-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/npm-reanimated-publish-nightly.yml)
[![NPM Worklets publish [Nightly]](https://github.com/software-mansion/react-native-reanimated/actions/workflows/npm-worklets-publish-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/npm-worklets-publish-nightly.yml)
[![Lint clang-tidy [Nightly]](https://github.com/software-mansion/react-native-reanimated/actions/workflows/lint-clang-tidy-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/lint-clang-tidy-nightly.yml)
[![Reanimated compatibility check](https://github.com/software-mansion/react-native-reanimated/actions/workflows/reanimated-compatibility-check-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/reanimated-compatibility-check-nightly.yml)
[![Use frameworks Reanimated build check [Nightly]](https://github.com/software-mansion/react-native-reanimated/actions/workflows/use-frameworks-reanimated-build-check-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/use-frameworks-reanimated-build-check-nightly.yml)
[![React Native nightly Reanimated build check](https://github.com/software-mansion/react-native-reanimated/actions/workflows/react-native-nightly-reanimated-build-check-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/react-native-nightly-reanimated-build-check-nightly.yml)
[![Expo DevClient build check](https://github.com/software-mansion/react-native-reanimated/actions/workflows/expo-devclient-build-check-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/expo-devclient-build-check-nightly.yml)
[![Reanimated TypeScript compatibility test](https://github.com/software-mansion/react-native-reanimated/actions/workflows/reanimated-typescript-compatibility-test-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/reanimated-typescript-compatibility-test-nightly.yml)
[![Windows hosted app Reanimated build check](https://github.com/software-mansion/react-native-reanimated/actions/workflows/windows-hosted-app-reanimated-build-check-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/windows-hosted-app-reanimated-build-check-nightly.yml)
[![URL validation](https://github.com/software-mansion/react-native-reanimated/actions/workflows/url-validation-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/url-validation-nightly.yml)

&lt;!-- TODO: Restore badge once V8 is supported. --&gt;
&lt;!-- [![V8 Reanimated build check](https://github.com/software-mansion/react-native-reanimated/actions/workflows/V8-reanimated-build-check-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/V8-reanimated-build-check-nightly.yml) --&gt;

## Installation

Check out the [installation](https://docs.swmansion.com/react-native-reanimated/docs/fundamentals/getting-started/#installation) section of our docs for the detailed installation instructions.

## Compatibility

React Native Reanimated 4.x supports only the [New React Native architecture](https://reactnative.dev/architecture/landing-page) and three latest React Native versions.

If your app still runs on the old architecture, please consider adopting the New Architecture or stay with latest 3.x release.

## Documentation

Check out our dedicated documentation page for info about this library, API reference and more: [https://docs.swmansion.com/react-native-reanimated/](https://docs.swmansion.com/react-native-reanimated/)

## Examples

The source code for the example (showcase) app is under the [`apps/common-app`](https://github.com/software-mansion/react-native-reanimated/blob/main/apps/common-app/) directory.
If you want to play with the API but don&#039;t feel like trying it on a real app, you can run the example project. Check [Example README](apps/fabric-example/README.md) for installation instructions.

## License

Reanimated library is licensed under [The MIT License](LICENSE).

## Credits

This project has been built and is maintained thanks to the support from [Shopify](https://shopify.com), [Expo.io](https://expo.io) and [Software Mansion](https://swmansion.com)

[![shopify](https://avatars1.githubusercontent.com/u/8085?v=3&amp;s=100 &#039;Shopify.com&#039;)](https://shopify.com)
[![expo](https://avatars2.githubusercontent.com/u/12504344?v=3&amp;s=100 &#039;Expo.io&#039;)](https://expo.io)
[![swm](https://logo.swmansion.com/logo?color=white&amp;variant=desktop&amp;width=150&amp;tag=react-native-reanimated-github &#039;Software Mansion&#039;)](https://swmansion.com)

## Community Discord

[Join the Software Mansion Community Discord](https://discord.swmansion.com) to chat about Reanimated or other Software Mansion libraries.

## Reanimated is created by Software Mansion

Since 2012 [Software Mansion](https://swmansion.com) is a software agency with experience in building web and mobile apps. We are Core React Native Contributors and experts in dealing with all kinds of React Native issues. We can help you build your next dream product ‚Äì [Hire us](https://swmansion.com/contact/projects?utm_source=reanimated&amp;utm_medium=readme).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[honojs/hono]]></title>
            <link>https://github.com/honojs/hono</link>
            <guid>https://github.com/honojs/hono</guid>
            <pubDate>Sun, 11 May 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[Web framework built on Web Standards]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/honojs/hono">honojs/hono</a></h1>
            <p>Web framework built on Web Standards</p>
            <p>Language: TypeScript</p>
            <p>Stars: 24,073</p>
            <p>Forks: 708</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://hono.dev&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/honojs/hono/main/docs/images/hono-title.png&quot; width=&quot;500&quot; height=&quot;auto&quot; alt=&quot;Hono&quot;/&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://hono.dev&quot;&gt;&lt;b&gt;Documentation üëâ hono.dev&lt;/b&gt;&lt;/a&gt;&lt;br /&gt;
&lt;i&gt;Now supports &lt;a href=&quot;https://jsr.io/@hono/hono&quot;&gt;JSR&lt;/a&gt; and &lt;code&gt;deno.land/x&lt;/code&gt; is deprecated! See &lt;a href=&quot;docs/MIGRATION.md&quot;&gt;Migration guide&lt;/a&gt;.&lt;/i&gt;
&lt;/p&gt;

&lt;hr /&gt;

[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/honojs/hono/ci.yml?branch=main)](https://github.com/honojs/hono/actions)
[![GitHub](https://img.shields.io/github/license/honojs/hono)](https://github.com/honojs/hono/blob/main/LICENSE)
[![npm](https://img.shields.io/npm/v/hono)](https://www.npmjs.com/package/hono)
[![npm](https://img.shields.io/npm/dm/hono)](https://www.npmjs.com/package/hono)
[![JSR](https://jsr.io/badges/@hono/hono)](https://jsr.io/@hono/hono)
[![Bundle Size](https://img.shields.io/bundlephobia/min/hono)](https://bundlephobia.com/result?p=hono)
[![Bundle Size](https://img.shields.io/bundlephobia/minzip/hono)](https://bundlephobia.com/result?p=hono)
[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/honojs/hono)](https://github.com/honojs/hono/pulse)
[![GitHub last commit](https://img.shields.io/github/last-commit/honojs/hono)](https://github.com/honojs/hono/commits/main)
[![codecov](https://codecov.io/github/honojs/hono/graph/badge.svg)](https://codecov.io/github/honojs/hono)
[![Discord badge](https://img.shields.io/discord/1011308539819597844?label=Discord&amp;logo=Discord)](https://discord.gg/KMh2eNSdxV)

Hono - _**means flameüî• in Japanese**_ - is a small, simple, and ultrafast web framework built on Web Standards. It works on any JavaScript runtime: Cloudflare Workers, Fastly Compute, Deno, Bun, Vercel, AWS Lambda, Lambda@Edge, and Node.js.

Fast, but not only fast.

```ts
import { Hono } from &#039;hono&#039;
const app = new Hono()

app.get(&#039;/&#039;, (c) =&gt; c.text(&#039;Hono!&#039;))

export default app
```

## Quick Start

```bash
npm create hono@latest
```

## Features

- **Ultrafast** üöÄ - The router `RegExpRouter` is really fast. Not using linear loops. Fast.
- **Lightweight** ü™∂ - The `hono/tiny` preset is under 12kB. Hono has zero dependencies and uses only the Web Standard API.
- **Multi-runtime** üåç - Works on Cloudflare Workers, Fastly Compute, Deno, Bun, AWS Lambda, Lambda@Edge, or Node.js. The same code runs on all platforms.
- **Batteries Included** üîã - Hono has built-in middleware, custom middleware, and third-party middleware. Batteries included.
- **Delightful DX** üòÉ - Super clean APIs. First-class TypeScript support. Now, we&#039;ve got &quot;Types&quot;.

## Documentation

The documentation is available on [hono.dev](https://hono.dev).

## Migration

The migration guide is available on [docs/MIGRATION.md](docs/MIGRATION.md).

## Communication

[X](https://x.com/honojs) and [Discord channel](https://discord.gg/KMh2eNSdxV) are available.

## Contributing

Contributions Welcome! You can contribute in the following ways.

- Create an Issue - Propose a new feature. Report a bug.
- Pull Request - Fix a bug and typo. Refactor the code.
- Create third-party middleware - Instruct below.
- Share - Share your thoughts on the Blog, X, and others.
- Make your application - Please try to use Hono.

For more details, see [docs/CONTRIBUTING.md](docs/CONTRIBUTING.md).

## Contributors

Thanks to [all contributors](https://github.com/honojs/hono/graphs/contributors)!

## Authors

Yusuke Wada &lt;https://github.com/yusukebe&gt;

_RegExpRouter_, _SmartRouter_, _LinearRouter_, and _PatternRouter_ are created by Taku Amano &lt;https://github.com/usualoma&gt;

## License

Distributed under the MIT License. See [LICENSE](LICENSE) for more information.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[infiniflow/ragflow]]></title>
            <link>https://github.com/infiniflow/ragflow</link>
            <guid>https://github.com/infiniflow/ragflow</guid>
            <pubDate>Sun, 11 May 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/infiniflow/ragflow">infiniflow/ragflow</a></h1>
            <p>RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 51,830</p>
            <p>Forks: 4,943</p>
            <p>Stars today: 111 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://demo.ragflow.io/&quot;&gt;
&lt;img src=&quot;web/src/assets/logo-with-text.png&quot; width=&quot;520&quot; alt=&quot;ragflow logo&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;English&lt;/a&gt; |
  &lt;a href=&quot;./README_zh.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; |
  &lt;a href=&quot;./README_tzh.md&quot;&gt;ÁπÅ‰Ωì‰∏≠Êñá&lt;/a&gt; |
  &lt;a href=&quot;./README_ja.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; |
  &lt;a href=&quot;./README_ko.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; |
  &lt;a href=&quot;./README_id.md&quot;&gt;Bahasa Indonesia&lt;/a&gt; |
  &lt;a href=&quot;/README_pt_br.md&quot;&gt;Portugu√™s (Brasil)&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://x.com/intent/follow?screen_name=infiniflowai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/infiniflow?logo=X&amp;color=%20%23f5f5f5&quot; alt=&quot;follow on X(Twitter)&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://demo.ragflow.io&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Online-Demo-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/r/infiniflow/ragflow&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/docker_pull-ragflow:v0.18.0-brightgreen&quot; alt=&quot;docker pull infiniflow/ragflow:v0.18.0&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/releases/latest&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/github/v/release/infiniflow/ragflow?color=blue&amp;label=Latest%20Release&quot; alt=&quot;Latest Release&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/blob/main/LICENSE&quot;&gt;
        &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/License-Apache--2.0-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;license&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://ragflow.io/docs/dev/&quot;&gt;Document&lt;/a&gt; |
  &lt;a href=&quot;https://github.com/infiniflow/ragflow/issues/4214&quot;&gt;Roadmap&lt;/a&gt; |
  &lt;a href=&quot;https://twitter.com/infiniflowai&quot;&gt;Twitter&lt;/a&gt; |
  &lt;a href=&quot;https://discord.gg/NjYzJD3GM3&quot;&gt;Discord&lt;/a&gt; |
  &lt;a href=&quot;https://demo.ragflow.io&quot;&gt;Demo&lt;/a&gt;
&lt;/h4&gt;

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;üìï Table of Contents&lt;/b&gt;&lt;/summary&gt;

- üí° [What is RAGFlow?](#-what-is-ragflow)
- üéÆ [Demo](#-demo)
- üìå [Latest Updates](#-latest-updates)
- üåü [Key Features](#-key-features)
- üîé [System Architecture](#-system-architecture)
- üé¨ [Get Started](#-get-started)
- üîß [Configurations](#-configurations)
- üîß [Build a docker image without embedding models](#-build-a-docker-image-without-embedding-models)
- üîß [Build a docker image including embedding models](#-build-a-docker-image-including-embedding-models)
- üî® [Launch service from source for development](#-launch-service-from-source-for-development)
- üìö [Documentation](#-documentation)
- üìú [Roadmap](#-roadmap)
- üèÑ [Community](#-community)
- üôå [Contributing](#-contributing)

&lt;/details&gt;

## üí° What is RAGFlow?

[RAGFlow](https://ragflow.io/) is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document
understanding. It offers a streamlined RAG workflow for businesses of any scale, combining LLM (Large Language Models)
to provide truthful question-answering capabilities, backed by well-founded citations from various complex formatted
data.

## üéÆ Demo

Try our demo at [https://demo.ragflow.io](https://demo.ragflow.io).

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/infiniflow/ragflow/assets/7248/2f6baa3e-1092-4f11-866d-36f6a9d075e5&quot; width=&quot;1200&quot;/&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/504bbbf1-c9f7-4d83-8cc5-e9cb63c26db6&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## üî• Latest Updates

- 2025-03-19 Supports using a multi-modal model to make sense of images within PDF or DOCX files.
- 2025-02-28 Combined with Internet search (Tavily), supports reasoning like Deep Research for any LLMs.
- 2025-01-26 Optimizes knowledge graph extraction and application, offering various configuration options.
- 2024-12-18 Upgrades Document Layout Analysis model in DeepDoc.
- 2024-11-01 Adds keyword extraction and related question generation to the parsed chunks to improve the accuracy of retrieval.
- 2024-08-22 Support text to SQL statements through RAG.

## üéâ Stay Tuned

‚≠êÔ∏è Star our repository to stay up-to-date with exciting new features and improvements! Get instant notifications for new
releases! üåü

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/18c9707e-b8aa-4caf-a154-037089c105ba&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## üåü Key Features

### üç≠ **&quot;Quality in, quality out&quot;**

- [Deep document understanding](./deepdoc/README.md)-based knowledge extraction from unstructured data with complicated
  formats.
- Finds &quot;needle in a data haystack&quot; of literally unlimited tokens.

### üç± **Template-based chunking**

- Intelligent and explainable.
- Plenty of template options to choose from.

### üå± **Grounded citations with reduced hallucinations**

- Visualization of text chunking to allow human intervention.
- Quick view of the key references and traceable citations to support grounded answers.

### üçî **Compatibility with heterogeneous data sources**

- Supports Word, slides, excel, txt, images, scanned copies, structured data, web pages, and more.

### üõÄ **Automated and effortless RAG workflow**

- Streamlined RAG orchestration catered to both personal and large businesses.
- Configurable LLMs as well as embedding models.
- Multiple recall paired with fused re-ranking.
- Intuitive APIs for seamless integration with business.

## üîé System Architecture

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/infiniflow/ragflow/assets/12318111/d6ac5664-c237-4200-a7c2-a4a00691b485&quot; width=&quot;1000&quot;/&gt;
&lt;/div&gt;

## üé¨ Get Started

### üìù Prerequisites

- CPU &gt;= 4 cores
- RAM &gt;= 16 GB
- Disk &gt;= 50 GB
- Docker &gt;= 24.0.0 &amp; Docker Compose &gt;= v2.26.1
  &gt; If you have not installed Docker on your local machine (Windows, Mac, or Linux),
  &gt; see [Install Docker Engine](https://docs.docker.com/engine/install/).

### üöÄ Start up the server

1. Ensure `vm.max_map_count` &gt;= 262144:

   &gt; To check the value of `vm.max_map_count`:
   &gt;
   &gt; ```bash
   &gt; $ sysctl vm.max_map_count
   &gt; ```
   &gt;
   &gt; Reset `vm.max_map_count` to a value at least 262144 if it is not.
   &gt;
   &gt; ```bash
   &gt; # In this case, we set it to 262144:
   &gt; $ sudo sysctl -w vm.max_map_count=262144
   &gt; ```
   &gt;
   &gt; This change will be reset after a system reboot. To ensure your change remains permanent, add or update the
   &gt; `vm.max_map_count` value in **/etc/sysctl.conf** accordingly:
   &gt;
   &gt; ```bash
   &gt; vm.max_map_count=262144
   &gt; ```

2. Clone the repo:

   ```bash
   $ git clone https://github.com/infiniflow/ragflow.git
   ```

3. Start up the server using the pre-built Docker images:

&gt; [!CAUTION]
&gt; All Docker images are built for x86 platforms. We don&#039;t currently offer Docker images for ARM64.
&gt; If you are on an ARM64 platform, follow [this guide](https://ragflow.io/docs/dev/build_docker_image) to build a Docker image compatible with your system.

   &gt; The command below downloads the `v0.18.0-slim` edition of the RAGFlow Docker image. See the following table for descriptions of different RAGFlow editions. To download a RAGFlow edition different from `v0.18.0-slim`, update the `RAGFLOW_IMAGE` variable accordingly in **docker/.env** before using `docker compose` to start the server. For example: set `RAGFLOW_IMAGE=infiniflow/ragflow:v0.18.0` for the full edition `v0.18.0`.

   ```bash
   $ cd ragflow/docker
   # Use CPU for embedding and DeepDoc tasks:
   $ docker compose -f docker-compose.yml up -d

   # To use GPU to accelerate embedding and DeepDoc tasks:
   # docker compose -f docker-compose-gpu.yml up -d
   ```

   | RAGFlow image tag | Image size (GB) | Has embedding models? | Stable?                  |
   |-------------------|-----------------|-----------------------|--------------------------|
   | v0.18.0           | &amp;approx;9       | :heavy_check_mark:    | Stable release           |
   | v0.18.0-slim      | &amp;approx;2       | ‚ùå                   | Stable release            |
   | nightly           | &amp;approx;9       | :heavy_check_mark:    | _Unstable_ nightly build |
   | nightly-slim      | &amp;approx;2       | ‚ùå                   | _Unstable_ nightly build  |

4. Check the server status after having the server up and running:

   ```bash
   $ docker logs -f ragflow-server
   ```

   _The following output confirms a successful launch of the system:_

   ```bash

         ____   ___    ______ ______ __
        / __ \ /   |  / ____// ____// /____  _      __
       / /_/ // /| | / / __ / /_   / // __ \| | /| / /
      / _, _// ___ |/ /_/ // __/  / // /_/ /| |/ |/ /
     /_/ |_|/_/  |_|\____//_/    /_/ \____/ |__/|__/

    * Running on all addresses (0.0.0.0)
   ```

   &gt; If you skip this confirmation step and directly log in to RAGFlow, your browser may prompt a `network anormal`
   &gt; error because, at that moment, your RAGFlow may not be fully initialized.

5. In your web browser, enter the IP address of your server and log in to RAGFlow.
   &gt; With the default settings, you only need to enter `http://IP_OF_YOUR_MACHINE` (**sans** port number) as the default
   &gt; HTTP serving port `80` can be omitted when using the default configurations.
6. In [service_conf.yaml.template](./docker/service_conf.yaml.template), select the desired LLM factory in `user_default_llm` and update
   the `API_KEY` field with the corresponding API key.

   &gt; See [llm_api_key_setup](https://ragflow.io/docs/dev/llm_api_key_setup) for more information.

   _The show is on!_

## üîß Configurations

When it comes to system configurations, you will need to manage the following files:

- [.env](./docker/.env): Keeps the fundamental setups for the system, such as `SVR_HTTP_PORT`, `MYSQL_PASSWORD`, and
  `MINIO_PASSWORD`.
- [service_conf.yaml.template](./docker/service_conf.yaml.template): Configures the back-end services. The environment variables in this file will be automatically populated when the Docker container starts. Any environment variables set within the Docker container will be available for use, allowing you to customize service behavior based on the deployment environment.
- [docker-compose.yml](./docker/docker-compose.yml): The system relies on [docker-compose.yml](./docker/docker-compose.yml) to start up.

&gt; The [./docker/README](./docker/README.md) file provides a detailed description of the environment settings and service
&gt; configurations which can be used as `${ENV_VARS}` in the [service_conf.yaml.template](./docker/service_conf.yaml.template) file.

To update the default HTTP serving port (80), go to [docker-compose.yml](./docker/docker-compose.yml) and change `80:80`
to `&lt;YOUR_SERVING_PORT&gt;:80`.

Updates to the above configurations require a reboot of all containers to take effect:

&gt; ```bash
&gt; $ docker compose -f docker-compose.yml up -d
&gt; ```

### Switch doc engine from Elasticsearch to Infinity

RAGFlow uses Elasticsearch by default for storing full text and vectors. To switch to [Infinity](https://github.com/infiniflow/infinity/), follow these steps:

1. Stop all running containers:

   ```bash
   $ docker compose -f docker/docker-compose.yml down -v
   ```

&gt; [!WARNING]
&gt; `-v` will delete the docker container volumes, and the existing data will be cleared.

2. Set `DOC_ENGINE` in **docker/.env** to `infinity`.

3. Start the containers:

   ```bash
   $ docker compose -f docker-compose.yml up -d
   ```

&gt; [!WARNING]
&gt; Switching to Infinity on a Linux/arm64 machine is not yet officially supported.

## üîß Build a Docker image without embedding models

This image is approximately 2 GB in size and relies on external LLM and embedding services.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 --build-arg LIGHTEN=1 -f Dockerfile -t infiniflow/ragflow:nightly-slim .
```

## üîß Build a Docker image including embedding models

This image is approximately 9 GB in size. As it includes embedding models, it relies on external LLM services only.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 -f Dockerfile -t infiniflow/ragflow:nightly .
```

## üî® Launch service from source for development

1. Install uv, or skip this step if it is already installed:

   ```bash
   pipx install uv pre-commit
   ```

2. Clone the source code and install Python dependencies:

   ```bash
   git clone https://github.com/infiniflow/ragflow.git
   cd ragflow/
   uv sync --python 3.10 --all-extras # install RAGFlow dependent python modules
   uv run download_deps.py
   pre-commit install
   ```

3. Launch the dependent services (MinIO, Elasticsearch, Redis, and MySQL) using Docker Compose:

   ```bash
   docker compose -f docker/docker-compose-base.yml up -d
   ```

   Add the following line to `/etc/hosts` to resolve all hosts specified in **docker/.env** to `127.0.0.1`:

   ```
   127.0.0.1       es01 infinity mysql minio redis
   ```

4. If you cannot access HuggingFace, set the `HF_ENDPOINT` environment variable to use a mirror site:

   ```bash
   export HF_ENDPOINT=https://hf-mirror.com
   ```

5. Launch backend service:

   ```bash
   source .venv/bin/activate
   export PYTHONPATH=$(pwd)
   bash docker/launch_backend_service.sh
   ```

6. Install frontend dependencies:
   ```bash
   cd web
   npm install
   ```
7. Launch frontend service:

   ```bash
   npm run dev
   ```

   _The following output confirms a successful launch of the system:_

   ![](https://github.com/user-attachments/assets/0daf462c-a24d-4496-a66f-92533534e187)

## üìö Documentation

- [Quickstart](https://ragflow.io/docs/dev/)
- [Configuration](https://ragflow.io/docs/dev/configurations)
- [Release notes](https://ragflow.io/docs/dev/release_notes)
- [User guides](https://ragflow.io/docs/dev/category/guides)
- [Developer guides](https://ragflow.io/docs/dev/category/developers)
- [References](https://ragflow.io/docs/dev/category/references)
- [FAQs](https://ragflow.io/docs/dev/faq)

## üìú Roadmap

See the [RAGFlow Roadmap 2025](https://github.com/infiniflow/ragflow/issues/4214)

## üèÑ Community

- [Discord](https://discord.gg/NjYzJD3GM3)
- [Twitter](https://twitter.com/infiniflowai)
- [GitHub Discussions](https://github.com/orgs/infiniflow/discussions)

## üôå Contributing

RAGFlow flourishes via open-source collaboration. In this spirit, we embrace diverse contributions from the community.
If you would like to be a part, review our [Contribution Guidelines](./CONTRIBUTING.md) first.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[element-plus/element-plus]]></title>
            <link>https://github.com/element-plus/element-plus</link>
            <guid>https://github.com/element-plus/element-plus</guid>
            <pubDate>Sun, 11 May 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[üéâ A Vue.js 3 UI Library made by Element team]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/element-plus/element-plus">element-plus/element-plus</a></h1>
            <p>üéâ A Vue.js 3 UI Library made by Element team</p>
            <p>Language: TypeScript</p>
            <p>Stars: 25,823</p>
            <p>Forks: 18,391</p>
            <p>Stars today: 77 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;300px&quot; src=&quot;https://user-images.githubusercontent.com/10731096/95823103-9ce15780-0d5f-11eb-8010-1bd1b5910d4f.png&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.org/package/element-plus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/element-plus.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/element-plus/element-plus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/node-%20%3E%3D%2016-47c219&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://npmcharts.com/compare/element-plus?minimal=true&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/dm/element-plus.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/element-plus/element-plus&quot;&gt;
    &lt;img src=&quot;https://codecov.io/gh/element-plus/element-plus/branch/dev/graph/badge.svg?token=BKSBO2GLZI&quot;/&gt;
  &lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Element Plus - A Vue.js 3 UI library&lt;/p&gt;

- üí™ Vue 3 Composition API
- üî• Written in TypeScript

## Getting Started

Alright, for you to get started if you are looking for making Element Plus better you should keep reading.
For developers that uses Element Plus to develop your website you should go ahead visit [Getting Started](https://element-plus.org/).

- ‰∏≠ÂõΩÂ§ßÈôÜ[Âä†ÈÄüÈïúÂÉèÁ´ôÁÇπ](https://element-plus.gitee.io/)

## Breaking change list

The first stable release of Element Plus suitable for use in production was released on February 07, 2022. The APIs is stable right now, and here&#039;s also a full list about how to get upgraded from [Element UI](https://element.eleme.io) to Element Plus.

You can find the breaking change list here: [Breaking Change List](https://github.com/element-plus/element-plus/discussions/5658).

### Migration Tool :hammer_and_wrench:

We have made a migration tool for you to migrate your project from [Element UI](https://element.eleme.io) to Element Plus.

You can find the [gogo code migration tool](https://github.com/thx/gogocode/tree/main/packages/gogocode-plugin-element) here.

We have tested this on [Vue Element Admin](https://github.com/PanJiaChen/vue-element-admin). You can find the transpiled code [here](https://github.com/gogocodeio/vue-element-admin).

### Playground

You can also try Element Plus out with the components built-in playground.

#### Try it with our built-in playground

[Playground](https://element-plus.run/)

#### Try it with code sandbox

[![Edit element-plus](https://codesandbox.io/static/img/play-codesandbox.svg)](https://codesandbox.io/s/element-plus-demo-dxtcr)

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Special thanks to the generous sponsorship by:&lt;/b&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Platinum Sponsors&lt;/b&gt;
&lt;/p&gt;
&lt;table align=&quot;center&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://www.vform666.com/&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;150px&quot; src=&quot;https://user-images.githubusercontent.com/17680888/156870588-b25a42d5-888b-4943-8b1b-5239dfd8f4d2.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://js.design?source=element-plus&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;150px&quot; src=&quot;https://user-images.githubusercontent.com/17680888/160634485-df0d00af-8633-4ab8-9a72-aac2b65d1d36.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://www.misboot.com/?from=element-plus&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;150px&quot; src=&quot;https://github-production-user-asset-6210df.s3.amazonaws.com/82012629/250157573-b8ab8d68-ff6b-496f-beb1-9863a545d2af.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Gold Sponsors&lt;/b&gt;
&lt;/p&gt;
&lt;table align=&quot;center&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://wonderful-code.gitee.io/?from=element-plus&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;130px&quot; src=&quot;https://user-images.githubusercontent.com/17680888/173179536-30e35fd1-cd5a-482a-bc41-9d5f0aa66fd4.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://bit.dev/?from=element-ui&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;130px&quot; src=&quot;https://user-images.githubusercontent.com/10095631/41342907-e44e7196-6f2f-11e8-92f2-47702dc8f059.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

---

## Translations

Element Plus is translated to multiple languages, you can click the badge to help up update the translation or apply to become
a proofreader [![Crowdin](https://badges.crowdin.net/element-plus/localized.svg)](https://crowdin.com/project/element-plus)

For now we are only showing English and Chinese for resource reasons, but we are looking forward to translate it into more languages, please go to the link
above and leave a message if you want to help translating Element Plus into your desired language.

### How to help translating

See how to help translating in [Translating Element Plus](https://element-plus.org/en-US/guide/translation.html).

## Stay tuned :eyes:

Join our [Discord](https://discord.com/invite/gXK9XNzW3X) to start communicating with everybody.

## This thing is broken, I should help improve it!

Awesommmmmmee. Everything you need is down below. You can also refer to
[CONTRIBUTING](https://github.com/element-plus/element-plus/blob/dev/CONTRIBUTING.md) and
[Code of Conduct](https://github.com/element-plus/element-plus/blob/dev/CODE_OF_CONDUCT.md)
where you&#039;ll find the same information listed below.

## I would like to become a part of the development team!

Welcome :star_struck:! We are looking for talented developers to join us and making Element Plus better! If you care to join the development team, please
reach out to us, you are more than welcomed to join us! :heart:

We are now lacking of experts of `Testing`, `GitHub Actions`, `PM`, if you do feel like you can and willing to help us, please do reach out to us. :pray:

## Contributors

This project exists thanks to all the people who contribute.

And thank you to all our backers! üôè

&lt;a href=&quot;https://github.com/element-plus/element-plus/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=element-plus/element-plus&quot; /&gt;
&lt;/a&gt;

## License

Element Plus is open source software licensed as
[MIT](https://github.com/element-plus/element-plus/blob/master/LICENSE).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[MODSetter/SurfSense]]></title>
            <link>https://github.com/MODSetter/SurfSense</link>
            <guid>https://github.com/MODSetter/SurfSense</guid>
            <pubDate>Sun, 11 May 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[Open Source Alternative to NotebookLM / Perplexity / Glean, connected to external sources such as search engines (Tavily, Linkup), Slack, Linear, Notion, YouTube, GitHub and more.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/MODSetter/SurfSense">MODSetter/SurfSense</a></h1>
            <p>Open Source Alternative to NotebookLM / Perplexity / Glean, connected to external sources such as search engines (Tavily, Linkup), Slack, Linear, Notion, YouTube, GitHub and more.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,491</p>
            <p>Forks: 247</p>
            <p>Stars today: 110 stars today</p>
            <h2>README</h2><pre>
![new_header](https://github.com/user-attachments/assets/e236b764-0ddc-42ff-a1f1-8fbb3d2e0e65)




# SurfSense
While tools like NotebookLM and Perplexity are impressive and highly effective for conducting research on any topic/query, SurfSense elevates this capability by integrating with your personal knowledge base. It is a highly customizable AI research agent, connected to external sources such as search engines (Tavily, LinkUp), Slack, Linear, Notion, YouTube, GitHub and more to come.

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13606&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13606&quot; alt=&quot;MODSetter%2FSurfSense | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;


# Video

https://github.com/user-attachments/assets/48142909-6391-4084-b7e8-81da388bb1fc

# Podcast&#039;s

https://github.com/user-attachments/assets/d516982f-de00-4c41-9e4c-632a7d942f41

## Podcast Sample

https://github.com/user-attachments/assets/bf64a6ca-934b-47ac-9e1b-edac5fe972ec



## Key Features
### 1. Latest

#### üí° **Idea**: 
Have your own highly customizable private NotebookLM and Perplexity integrated with external sources.
#### üìÅ **Multiple File Format Uploading Support**
Save content from your own personal files *(Documents, images and supports **27 file extensions**)* to your own personal knowledge base .
#### üîç **Powerful Search**
Quickly research or find anything in your saved content .
#### üí¨ **Chat with your Saved Content**
 Interact in Natural Language and get cited answers.
#### üìÑ **Cited Answers**
Get Cited answers just like Perplexity.
#### üîî **Privacy &amp; Local LLM Support**
Works Flawlessly with Ollama local LLMs.
#### üè† **Self Hostable**
Open source and easy to deploy locally.
#### üéôÔ∏è Podcasts 
- Blazingly fast podcast generation agent. (Creates a 3-minute podcast in under 20 seconds.)
- Convert your chat conversations into engaging audio content
- Support for multiple TTS providers (OpenAI, Azure, Google Vertex AI)

#### üìä **Advanced RAG Techniques**
- Supports 150+ LLM&#039;s
- Supports 6000+ Embedding Models.
- Supports all major Rerankers (Pinecode, Cohere, Flashrank etc)
- Uses Hierarchical Indices (2 tiered RAG setup).
- Utilizes Hybrid Search (Semantic + Full Text Search combined with Reciprocal Rank Fusion).
- RAG as a Service API Backend.

#### ‚ÑπÔ∏è **External Sources**
- Search Engines (Tavily, LinkUp)
- Slack
- Linear
- Notion
- Youtube Videos
- GitHub
- and more to come.....

#### üîñ Cross Browser Extension
- The SurfSense extension can be used to save any webpage you like.
- Its main usecase is to save any webpages protected beyond authentication.


## FEATURE REQUESTS AND FUTURE


**SurfSense is actively being developed.** While it&#039;s not yet production-ready, you can help us speed up the process.

Join the [SurfSense Discord](https://discord.gg/ejRNvftDp9) and help shape the future of SurfSense!



## How to get started?

### Installation Options

SurfSense provides two installation methods:

1. **[Docker Installation](https://www.surfsense.net/docs/docker-installation)** - The easiest way to get SurfSense up and running with all dependencies containerized.
   - Includes pgAdmin for database management through a web UI
   - Supports environment variable customization via `.env` file
   - See [Docker Setup Guide](DOCKER_SETUP.md) for detailed instructions

2. **[Manual Installation (Recommended)](https://www.surfsense.net/docs/manual-installation)** - For users who prefer more control over their setup or need to customize their deployment.

Both installation guides include detailed OS-specific instructions for Windows, macOS, and Linux.

Before installation, make sure to complete the [prerequisite setup steps](https://www.surfsense.net/docs/) including:
- PGVector setup
- Google OAuth configuration
- Unstructured.io API key
- Other required API keys

## Screenshots

**Search Spaces** 

![search_spaces](https://github.com/user-attachments/assets/e254c38c-f937-44b6-9e9d-770db583d099)

**Manage Documents** 
![documents](https://github.com/user-attachments/assets/7001e306-eb06-4009-89c6-8fadfdc3fc4d)

**Research Agent** 

![researcher](https://github.com/user-attachments/assets/fda3e61f-f936-4b66-b565-d84edde44a67)

**Podcast Agent** 
![podcasts](https://github.com/user-attachments/assets/6cb82ffd-9e14-4172-bc79-67faf34c4c1c)


**Agent Chat** 

![chat](https://github.com/user-attachments/assets/bb352d52-1c6d-4020-926b-722d0b98b491)

**Browser Extension**

![ext1](https://github.com/user-attachments/assets/1f042b7a-6349-422b-94fb-d40d0df16c40)

![ext2](https://github.com/user-attachments/assets/a9b9f1aa-2677-404d-b0a0-c1b2dddf24a7)


## Tech Stack


 ### **BackEnd** 

-  **FastAPI**: Modern, fast web framework for building APIs with Python
  
-  **PostgreSQL with pgvector**: Database with vector search capabilities for similarity searches

-  **SQLAlchemy**: SQL toolkit and ORM (Object-Relational Mapping) for database interactions

-  **Alembic**: A database migrations tool for SQLAlchemy.

-  **FastAPI Users**: Authentication and user management with JWT and OAuth support

-  **LangGraph**: Framework for developing AI-agents.
  
-  **LangChain**: Framework for developing AI-powered applications.

-  **LLM Integration**: Integration with LLM models through LiteLLM

-  **Rerankers**: Advanced result ranking for improved search relevance

-  **Hybrid Search**: Combines vector similarity and full-text search for optimal results using Reciprocal Rank Fusion (RRF)

-  **Vector Embeddings**: Document and text embeddings for semantic search

-  **pgvector**: PostgreSQL extension for efficient vector similarity operations

-  **Chonkie**: Advanced document chunking and embedding library
 - Uses `AutoEmbeddings` for flexible embedding model selection
 -  `LateChunker` for optimized document chunking based on embedding model&#039;s max sequence length


  
---
 ### **FrontEnd**

-  **Next.js 15.2.3**: React framework featuring App Router, server components, automatic code-splitting, and optimized rendering.

-  **React 19.0.0**: JavaScript library for building user interfaces.

-  **TypeScript**: Static type-checking for JavaScript, enhancing code quality and developer experience.
- **Vercel AI SDK Kit UI Stream Protocol**: To create scalable chat UI.

-  **Tailwind CSS 4.x**: Utility-first CSS framework for building custom UI designs.

-  **Shadcn**: Headless components library.

-  **Lucide React**: Icon set implemented as React components.

-  **Framer Motion**: Animation library for React.

-  **Sonner**: Toast notification library.

-  **Geist**: Font family from Vercel.

-  **React Hook Form**: Form state management and validation.

-  **Zod**: TypeScript-first schema validation with static type inference.

-  **@hookform/resolvers**: Resolvers for using validation libraries with React Hook Form.

-  **@tanstack/react-table**: Headless UI for building powerful tables &amp; datagrids.


 ### **DevOps**

-  **Docker**: Container platform for consistent deployment across environments
  
-  **Docker Compose**: Tool for defining and running multi-container Docker applications

-  **pgAdmin**: Web-based PostgreSQL administration tool included in Docker setup


### **Extension** 
 Manifest v3 on Plasmo

## Future Work
- Add More Connectors.
- Patch minor bugs.
- Implement Canvas. 
- Complete Hybrid Search. **[Done]**
- Add support for file uploads QA. **[Done]**
- Shift to WebSockets for Streaming responses. **[Deprecated in favor of AI SDK Stream Protocol]**
- Based on feedback, I will work on making it compatible with local models. **[Done]**
- Cross Browser Extension **[Done]**
- Critical Notifications **[Done | PAUSED]**
- Saving Chats **[Done]**
- Basic keyword search page for saved sessions **[Done]**
- Multi &amp; Single Document Chat **[Done]**



## Contribute 

Contributions are very welcome! A contribution can be as small as a ‚≠ê or even finding and creating issues.
Fine-tuning the Backend is always desired.

## Star History

&lt;a href=&quot;https://www.star-history.com/#MODSetter/SurfSense&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[browserbase/mcp-server-browserbase]]></title>
            <link>https://github.com/browserbase/mcp-server-browserbase</link>
            <guid>https://github.com/browserbase/mcp-server-browserbase</guid>
            <pubDate>Sun, 11 May 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[Allow LLMs to control a browser with Browserbase and Stagehand]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/browserbase/mcp-server-browserbase">browserbase/mcp-server-browserbase</a></h1>
            <p>Allow LLMs to control a browser with Browserbase and Stagehand</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,597</p>
            <p>Forks: 163</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre># Browserbase MCP Server

![cover](assets/cover-mcp.png)

[The Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you‚Äôre building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.

This server provides cloud browser automation capabilities using [Browserbase](https://www.browserbase.com/) and [Stagehand](https://github.com/browserbase/stagehand). This server enables LLMs to interact with web pages, take screenshots, and execute JavaScript in a cloud browser environment.

To learn to get started with Browserbase, check out [Browserbase MCP](./browserbase/README.md) or [Stagehand MCP](./stagehand/README.md).

## Getting Started with available MCPs

üåê **Browserbase MCP** - Located in [`browserbase/`](./browserbase/)

| Feature            | Description                               |
| ------------------ | ----------------------------------------- |
| Browser Automation | Control and orchestrate cloud browsers    |
| Data Extraction    | Extract structured data from any webpage  |
| Console Monitoring | Track and analyze browser console logs    |
| Screenshots        | Capture full-page and element screenshots |
| Web Interaction    | Navigate, click, and fill forms with ease |

ü§ò **Stagehand MCP** - Located in [`stagehand/`](./stagehand/)

| Feature             | Description                                                                                                                                                    |
| ------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Atomic Instructions | Execute precise actions like `act(&quot;click the login button&quot;)` or `extract(&quot;find the red shoes&quot;)`                                                                |
| Model Flexibility   | Supports multiple models, including OpenAI&#039;s GPT-4 and Anthropic&#039;s Claude-3.7 Sonnet                                                                           |
| Modular Design      | Easily integrate new models with minimal changes                                                                                                               |
| Vision Support      | Use annotated screenshots for complex DOMs                                                                                                                     |
| Open Source         | Contribute to the project and join the [Slack community](https://join.slack.com/t/stagehand-dev/shared_invite/zt-2uvuobu50-~wVSx2Si75CPa3332hwVEw) for support |

### Alternative Installation Methods

[Smithery](https://smithery.ai/server/@browserbasehq/mcp-browserbase)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ant-design/ant-design]]></title>
            <link>https://github.com/ant-design/ant-design</link>
            <guid>https://github.com/ant-design/ant-design</guid>
            <pubDate>Sun, 11 May 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[An enterprise-class UI design language and React UI library]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ant-design/ant-design">ant-design/ant-design</a></h1>
            <p>An enterprise-class UI design language and React UI library</p>
            <p>Language: TypeScript</p>
            <p>Stars: 94,562</p>
            <p>Forks: 52,227</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

&lt;img height=&quot;180&quot; src=&quot;https://gw.alipayobjects.com/zos/rmsportal/KDpgvguMpGfqaHPjicRK.svg&quot;&gt;

&lt;h1&gt;Ant Design&lt;/h1&gt;

An enterprise-class UI design language and React UI library.

[![CI status][github-action-image]][github-action-url] [![codecov][codecov-image]][codecov-url] [![NPM version][npm-image]][npm-url] [![NPM downloads][download-image]][download-url]

[![][bundlephobia-image]][bundlephobia-url] [![][jsdelivr-image]][jsdelivr-url] [![FOSSA Status][fossa-image]][fossa-url] [![DeepWiki][deepwiki-image]][deepwiki-url]

[![Follow Twitter][twitter-image]][twitter-url] [![Renovate status][renovate-image]][renovate-dashboard-url] [![][issues-helper-image]][issues-helper-url] [![dumi][dumi-image]][dumi-url] [![Issues need help][help-wanted-image]][help-wanted-url]

[Changelog](./CHANGELOG.en-US.md) ¬∑ [Report Bug][github-issues-url] ¬∑ [Request Feature][github-issues-url] ¬∑ English ¬∑ [‰∏≠Êñá](./README-zh_CN.md)

## ‚ù§Ô∏è Sponsors and Backers [![](https://opencollective.com/ant-design/tiers/sponsors/badge.svg?label=Sponsors&amp;color=brightgreen)](https://opencollective.com/ant-design#support) [![](https://opencollective.com/ant-design/tiers/backers/badge.svg?label=Backers&amp;color=brightgreen)](https://opencollective.com/ant-design#support)

[![](https://opencollective.com/ant-design/tiers/sponsors.svg?avatarHeight=72)](https://opencollective.com/ant-design/contribute/sponsors-218/checkout) [![](https://opencollective.com/ant-design/tiers/backers.svg?avatarHeight=72)](https://opencollective.com/ant-design/contribute/backers-217/checkout)

[npm-image]: https://img.shields.io/npm/v/antd.svg?style=flat-square
[npm-url]: https://npmjs.org/package/antd
[github-action-image]: https://github.com/ant-design/ant-design/actions/workflows/test.yml/badge.svg
[github-action-url]: https://github.com/ant-design/ant-design/actions/workflows/test.yml
[codecov-image]: https://img.shields.io/codecov/c/github/ant-design/ant-design/master.svg?style=flat-square
[codecov-url]: https://codecov.io/gh/ant-design/ant-design/branch/master
[download-image]: https://img.shields.io/npm/dm/antd.svg?style=flat-square
[download-url]: https://npmjs.org/package/antd
[fossa-image]: https://app.fossa.io/api/projects/git%2Bgithub.com%2Fant-design%2Fant-design.svg?type=shield
[fossa-url]: https://app.fossa.io/projects/git%2Bgithub.com%2Fant-design%2Fant-design?ref=badge_shield
[help-wanted-image]: https://flat.badgen.net/github/label-issues/ant-design/ant-design/help%20wanted/open
[help-wanted-url]: https://github.com/ant-design/ant-design/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22
[twitter-image]: https://img.shields.io/twitter/follow/AntDesignUI.svg?label=Ant%20Design
[twitter-url]: https://twitter.com/AntDesignUI
[jsdelivr-image]: https://data.jsdelivr.com/v1/package/npm/antd/badge
[jsdelivr-url]: https://www.jsdelivr.com/package/npm/antd
[bundlephobia-image]: https://badgen.net/bundlephobia/minzip/antd?style=flat-square
[bundlephobia-url]: https://bundlephobia.com/package/antd
[issues-helper-image]: https://img.shields.io/badge/using-actions--cool-blue?style=flat-square
[issues-helper-url]: https://github.com/actions-cool
[renovate-image]: https://img.shields.io/badge/renovate-enabled-brightgreen.svg?style=flat-square
[renovate-dashboard-url]: https://github.com/ant-design/ant-design/issues/32498
[dumi-image]: https://img.shields.io/badge/docs%20by-dumi-blue?style=flat-square
[dumi-url]: https://github.com/umijs/dumi
[github-issues-url]: https://new-issue.ant.design
[deepwiki-url]: https://deepwiki.com/ant-design/ant-design
[deepwiki-image]: https://img.shields.io/badge/Chat%20with-DeepWiki%20ü§ñ-20B2AA?style=flat-square

&lt;/div&gt;

[![](https://user-images.githubusercontent.com/507615/209472919-6f7e8561-be8c-4b0b-9976-eb3c692aa20a.png)](https://ant.design)

## ‚ú® Features

- üåà Enterprise-class UI designed for web applications.
- üì¶ A set of high-quality React components out of the box.
- üõ° Written in TypeScript with predictable static types.
- ‚öôÔ∏è Whole package of design resources and development tools.
- üåç Internationalization support for dozens of languages.
- üé® Powerful theme customization based on CSS-in-JS.

## üñ• Environment Support

- Modern browsers
- Server-side Rendering
- [Electron](https://www.electronjs.org/)

| [&lt;img src=&quot;https://raw.githubusercontent.com/alrra/browser-logos/master/src/edge/edge_48x48.png&quot; alt=&quot;Edge&quot; width=&quot;24px&quot; height=&quot;24px&quot; /&gt;](https://godban.github.io/browsers-support-badges/)&lt;br&gt;Edge | [&lt;img src=&quot;https://raw.githubusercontent.com/alrra/browser-logos/master/src/firefox/firefox_48x48.png&quot; alt=&quot;Firefox&quot; width=&quot;24px&quot; height=&quot;24px&quot; /&gt;](https://godban.github.io/browsers-support-badges/)&lt;br&gt;Firefox | [&lt;img src=&quot;https://raw.githubusercontent.com/alrra/browser-logos/master/src/chrome/chrome_48x48.png&quot; alt=&quot;Chrome&quot; width=&quot;24px&quot; height=&quot;24px&quot; /&gt;](https://godban.github.io/browsers-support-badges/)&lt;br&gt;Chrome | [&lt;img src=&quot;https://raw.githubusercontent.com/alrra/browser-logos/master/src/safari/safari_48x48.png&quot; alt=&quot;Safari&quot; width=&quot;24px&quot; height=&quot;24px&quot; /&gt;](https://godban.github.io/browsers-support-badges/)&lt;br&gt;Safari | [&lt;img src=&quot;https://raw.githubusercontent.com/alrra/browser-logos/master/src/electron/electron_48x48.png&quot; alt=&quot;Electron&quot; width=&quot;24px&quot; height=&quot;24px&quot; /&gt;](https://godban.github.io/browsers-support-badges/)&lt;br&gt;Electron |
| --- | --- | --- | --- | --- |
| Edge | last 2 versions | last 2 versions | last 2 versions | last 2 versions |

## üì¶ Install

```bash
npm install antd
```

```bash
yarn add antd
```

```bash
pnpm add antd
```

```bash
bun add antd
```

## üî® Usage

```tsx
import { Button, DatePicker } from &#039;antd&#039;;

export default () =&gt; (
  &lt;&gt;
    &lt;Button type=&quot;primary&quot;&gt;PRESS ME&lt;/Button&gt;
    &lt;DatePicker placeholder=&quot;select date&quot; /&gt;
  &lt;/&gt;
);
```

## üîó Links

- [Home page](https://ant.design/)
- [Components Overview](https://ant.design/components/overview)
- [Change Log](CHANGELOG.en-US.md)
- [rc-components](https://react-component.github.io/)
- [üÜï Ant Design X](https://x.ant.design/index-cn)
- [Ant Design Pro](https://pro.ant.design/)
- [Pro Components](https://procomponents.ant.design)
- [Ant Design Mobile](https://mobile.ant.design)
- [Ant Design Mini](https://mini.ant.design)
- [Ant Design Charts](https://charts.ant.design)
- [Ant Design Web3](https://web3.ant.design)
- [Landing Pages](https://landing.ant.design)
- [Ant Motion](https://motion.ant.design)
- [Scaffold Market](https://scaffold.ant.design)
- [Developer Instruction](https://github.com/ant-design/ant-design/wiki/Development)
- [Versioning Release Note](https://github.com/ant-design/ant-design/wiki/%E8%BD%AE%E5%80%BC%E8%A7%84%E5%88%99%E5%92%8C%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83%E6%B5%81%E7%A8%8B)
- [FAQ](https://ant.design/docs/react/faq)
- [Online Playground](https://u.ant.design/reproduce) for bug reports
- [Customize Theme](https://ant.design/docs/react/customize-theme)
- [How to Apply for Being A Collaborator](https://github.com/ant-design/ant-design/wiki/Collaborators#how-to-apply-for-being-a-collaborator)

## ‚å®Ô∏è Development

Use [opensumi.run](https://opensumi.run), a free online pure front-end dev environment.

[![opensumi.run](https://custom-icon-badges.demolab.com/badge/opensumi-run-blue.svg?logo=opensumi)](https://opensumi.run/ide/ant-design/ant-design)

Or clone locally:

```bash
$ git clone git@github.com:ant-design/ant-design.git
$ cd ant-design
$ npm install
$ npm start
```

Open your browser and visit http://127.0.0.1:8001, see more at [Development](https://github.com/ant-design/ant-design/wiki/Development).

## ü§ù Contributing [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](https://makeapullrequest.com)

&lt;table&gt;
&lt;tr&gt;
  &lt;td&gt;
    &lt;a href=&quot;https://next.ossinsight.io/widgets/official/compose-recent-top-contributors?repo_id=34526884&quot; target=&quot;_blank&quot; style=&quot;display: block&quot; align=&quot;center&quot;&gt;
      &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-recent-top-contributors/thumbnail.png?repo_id=34526884&amp;image_size=auto&amp;color_scheme=dark&quot; width=&quot;280&quot;&gt;
        &lt;img alt=&quot;Top Contributors of ant-design/ant-design - Last 28 days&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-recent-top-contributors/thumbnail.png?repo_id=34526884&amp;image_size=auto&amp;color_scheme=light&quot; width=&quot;280&quot;&gt;
      &lt;/picture&gt;
    &lt;/a&gt;
  &lt;/td&gt;
  &lt;td rowspan=&quot;2&quot;&gt;
    &lt;a href=&quot;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats?repo_id=34526884&quot; target=&quot;_blank&quot; style=&quot;display: block&quot; align=&quot;center&quot;&gt;
      &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=34526884&amp;image_size=auto&amp;color_scheme=dark&quot; width=&quot;655&quot; height=&quot;auto&quot;&gt;
        &lt;img alt=&quot;Performance Stats of ant-design/ant-design - Last 28 days&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=34526884&amp;image_size=auto&amp;color_scheme=light&quot; width=&quot;655&quot; height=&quot;auto&quot;&gt;
      &lt;/picture&gt;
    &lt;/a&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;
    &lt;a href=&quot;https://next.ossinsight.io/widgets/official/compose-org-active-contributors?period=past_28_days&amp;activity=new&amp;owner_id=12101536&amp;repo_ids=34526884&quot; target=&quot;_blank&quot; style=&quot;display: block&quot; align=&quot;center&quot;&gt;
      &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?period=past_28_days&amp;activity=new&amp;owner_id=12101536&amp;repo_ids=34526884&amp;image_size=2x3&amp;color_scheme=dark&quot; width=&quot;273&quot; height=&quot;auto&quot;&gt;
        &lt;img alt=&quot;New participants of ant-design - past 28 days&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?period=past_28_days&amp;activity=new&amp;owner_id=12101536&amp;repo_ids=34526884&amp;image_size=2x3&amp;color_scheme=light&quot; width=&quot;273&quot; height=&quot;auto&quot;&gt;
      &lt;/picture&gt;
    &lt;/a&gt;
  &lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;a href=&quot;https://openomy.app/github/ant-design/ant-design&quot; target=&quot;_blank&quot; style=&quot;display: block; width: 100%;&quot; align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openomy.app/svg?repo=ant-design/ant-design&amp;chart=bubble&amp;latestMonth=3&quot; target=&quot;_blank&quot; alt=&quot;Contribution Leaderboard&quot; style=&quot;display: block; width: 100%;&quot; /&gt;
&lt;/a&gt;

Let&#039;s build a better antd together.

We warmly invite contributions from everyone. Before you get started, please take a moment to review our [Contribution Guide](https://ant.design/docs/react/contributing). Feel free to share your ideas through [Pull Requests](https://github.com/ant-design/ant-design/pulls) or [GitHub Issues](https://github.com/ant-design/ant-design/issues). If you&#039;re interested in enhancing our codebase, explore the [Development Instructions](https://github.com/ant-design/ant-design/wiki/Development) and enjoy your coding journey! :)

For collaborators, adhere to our [Pull Request Principle](https://github.com/ant-design/ant-design/wiki/PR-principle) and utilize our [Pull Request Template](https://github.com/ant-design/ant-design/wiki/PR-principle#pull-request-template) when creating a Pull Request.

## Issue funding

We use [Issuehunt](https://issuehunt.io/repos/3452688) to up-vote and promote specific features that you would like to see and implement. Check our backlog and help us:

[![Let&#039;s fund issues in this repository](https://raw.githubusercontent.com/BoostIO/issuehunt-materials/master/v1/issuehunt-button-v1.svg)](https://issuehunt.io/repos/34526884)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[raycast/extensions]]></title>
            <link>https://github.com/raycast/extensions</link>
            <guid>https://github.com/raycast/extensions</guid>
            <pubDate>Sun, 11 May 2025 00:04:46 GMT</pubDate>
            <description><![CDATA[Everything you need to extend Raycast.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/raycast/extensions">raycast/extensions</a></h1>
            <p>Everything you need to extend Raycast.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,207</p>
            <p>Forks: 3,859</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/store-logo.webp&quot; height=&quot;128&quot;&gt;
  &lt;h1 align=&quot;center&quot;&gt;Raycast Extensions&lt;/h1&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;Follow Raycast on X&quot; href=&quot;https://x.com/raycastapp&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/badge/Follow%20@raycastapp-black.svg?style=for-the-badge&amp;logo=X&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Join the community on Slack&quot; href=&quot;https://raycast.com/community&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/badge/Join%20the%20community-black.svg?style=for-the-badge&amp;logo=Slack&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

[Raycast](https://raycast.com/) lets you control your tools with a few keystrokes. This repository contains all extensions that are available in the [Raycast Store](https://raycast.com/store). It also includes documentation and examples of how to extend Raycast using React.

![Header](images/header.webp)

## Getting Started

Visit [https://developers.raycast.com](https://developers.raycast.com) to get started with our API. If you want to discover and install extensions, check out [our Store](https://raycast.com/store).

Be sure to read and follow our [Community](https://manual.raycast.com/community-guidelines) and [Extension](https://manual.raycast.com/extensions) guidelines when submitting your extension and interacting with other folks in this repository.

## Feedback

Raycast wouldn&#039;t be where it is without the feedback from our community, so we would be happy to hear what you think of the API / DevX and how we can improve. Please use [GitHub issues](https://github.com/raycast/extensions/issues/new/choose) for everything API related (bugs, improvements suggestions, developer experience, docs, etc). We have a few [templates](https://developers.raycast.com/examples) that should help you get started.

## Community

Join our [Slack community](https://raycast.com/community) to share your extension, debug nasty bugs or simply get to know like-minded folks.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[alibaba/ChatUI]]></title>
            <link>https://github.com/alibaba/ChatUI</link>
            <guid>https://github.com/alibaba/ChatUI</guid>
            <pubDate>Sun, 11 May 2025 00:04:45 GMT</pubDate>
            <description><![CDATA[The UI design language and React library for Conversational UI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/alibaba/ChatUI">alibaba/ChatUI</a></h1>
            <p>The UI design language and React library for Conversational UI</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,406</p>
            <p>Forks: 328</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://chatui.io/&quot;&gt;
    &lt;img width=&quot;109&quot; height=&quot;28&quot; src=&quot;https://gw.alicdn.com/tfs/TB1uYH4QoY1gK0jSZFMXXaWcVXa-218-56.svg&quot; alt=&quot;ChatUI&quot;&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;The UI design language and React library for Conversational UI&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;WebsiteÔºö&lt;a href=&quot;https://chatui.io/&quot; target=&quot;_blank&quot;&gt;https://chatui.io&lt;/a&gt;&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![LICENSE](https://img.shields.io/npm/l/@chatui/core?style=flat-square)](https://github.com/alibaba/ChatUI/blob/master/LICENSE)
[![NPM version](https://img.shields.io/npm/v/@chatui/core?style=flat-square)](https://www.npmjs.com/package/@chatui/core)
[![NPM downloads](https://img.shields.io/npm/dm/@chatui/core?style=flat-square)](https://www.npmjs.com/package/@chatui/core)
[![Gzip Size](https://img.badgesize.io/https://unpkg.com/@chatui/core@0.1.0/dist/index.js?compression=gzip)](https://unpkg.com/@chatui/core@0.1.0/dist/index.js)
[![Jsdelivr Hits](https://img.shields.io/jsdelivr/npm/hm/@chatui/core?style=flat-square)](https://cdn.jsdelivr.net/npm/@chatui/core)

&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;750&quot; src=&quot;https://gw.alicdn.com/tfs/TB1WTl.lQ9l0K4jSZFKXXXFjpXa-1500-833.jpg&quot;&gt;
&lt;/p&gt;

English | [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md)

## Features

- üòé **Best Practices**: The best practice for chat interaction based on our experience of Alime Chatbot
- üõ° **TypeScript**: Written in TypeScript with predictable static types
- üì± **Responsive**: Responsive design to adapt automatically to whatever device
- ‚ôø **Accessibility**: Accessibility support and get the certification from Accessibility Research Association
- üé® **Theming**: Powerful theme customization in every detail
- üåç **International**: Internationalization support for dozens of languages

## Environment Support

- Modern browsers (support [CSS Variables](https://caniuse.com/css-variables))
- Internet Explorer 11 (with [polyfills](https://stackoverflow.com/questions/57020976/polyfills-in-2019-for-ie11) and [CSS Variables Polyfill](https://github.com/nuxodin/ie11CustomProperties) / [css-vars-ponyfill](https://github.com/jhildenbiddle/css-vars-ponyfill))

| &lt;img src=&quot;https://raw.githubusercontent.com/alrra/browser-logos/master/src/edge/edge_48x48.png&quot; alt=&quot;Edge&quot; width=&quot;24px&quot; height=&quot;24px&quot; /&gt;&lt;br&gt;Edge | &lt;img src=&quot;https://raw.githubusercontent.com/alrra/browser-logos/master/src/firefox/firefox_48x48.png&quot; alt=&quot;Firefox&quot; width=&quot;24px&quot; height=&quot;24px&quot; /&gt;&lt;br&gt;Firefox | &lt;img src=&quot;https://raw.githubusercontent.com/alrra/browser-logos/master/src/chrome/chrome_48x48.png&quot; alt=&quot;Chrome&quot; width=&quot;24px&quot; height=&quot;24px&quot; /&gt;&lt;br&gt;Chrome | &lt;img src=&quot;https://raw.githubusercontent.com/alrra/browser-logos/master/src/safari/safari_48x48.png&quot; alt=&quot;Safari&quot; width=&quot;24px&quot; height=&quot;24px&quot; /&gt;&lt;br&gt;Safari | &lt;img src=&quot;https://raw.githubusercontent.com/alrra/browser-logos/master/src/safari-ios/safari-ios_48x48.png&quot; alt=&quot;iOS Safari&quot; width=&quot;24px&quot; height=&quot;24px&quot; /&gt;&lt;br&gt;iOS Safari | &lt;img src=&quot;https://raw.githubusercontent.com/alrra/browser-logos/master/src/android-webview/android-webview_48x48.png&quot; alt=&quot;Android WebView&quot; width=&quot;24px&quot; height=&quot;24px&quot; /&gt;&lt;br&gt;Android WebView |
| --- | --- | --- | --- | --- | --- |
| 16+ | 31+ | 49+ | 9.1+ | 9.3+ | 6+ |

## Install

```bash
npm install @chatui/core --save
```

```bash
yarn add @chatui/core
```

## Usage

```jsx
import Chat, { Bubble, useMessages } from &#039;@chatui/core&#039;;
import &#039;@chatui/core/dist/index.css&#039;;

const App = () =&gt; {
  const { messages, appendMsg, setTyping } = useMessages([]);

  function handleSend(type, val) {
    if (type === &#039;text&#039; &amp;&amp; val.trim()) {
      appendMsg({
        type: &#039;text&#039;,
        content: { text: val },
        position: &#039;right&#039;,
      });

      setTyping(true);

      setTimeout(() =&gt; {
        appendMsg({
          type: &#039;text&#039;,
          content: { text: &#039;Bala bala&#039; },
        });
      }, 1000);
    }
  }

  function renderMessageContent(msg) {
    const { content } = msg;
    return &lt;Bubble content={content.text} /&gt;;
  }

  return (
    &lt;Chat
      navbar={{ title: &#039;Assistant&#039; }}
      messages={messages}
      renderMessageContent={renderMessageContent}
      onSend={handleSend}
    /&gt;
  );
};
```

[![DEMO](https://codesandbox.io/static/img/play-codesandbox.svg)](https://codesandbox.io/s/chatui-demo-o6n3z?fontsize=14&amp;hidenavigation=1&amp;theme=dark)

### Development

```bash
cd demo
npm i
npm run dev
```

## Theme

Visit [Customize Theme](https://chatui.io/docs/customize-theme) for detail

## Internationalization

Visit [i18n](https://chatui.io/docs/i18n) for detail

## License

MIT
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[frangoteam/FUXA]]></title>
            <link>https://github.com/frangoteam/FUXA</link>
            <guid>https://github.com/frangoteam/FUXA</guid>
            <pubDate>Sun, 11 May 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[Web-based Process Visualization (SCADA/HMI/Dashboard) software]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/frangoteam/FUXA">frangoteam/FUXA</a></h1>
            <p>Web-based Process Visualization (SCADA/HMI/Dashboard) software</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,337</p>
            <p>Forks: 946</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>![fuxa logo](/client/src/favicon.ico)
# FUXA
FUXA is a web-based Process Visualization (SCADA/HMI/Dashboard) software. With FUXA you can create modern process visualizations with individual designs for your machines and real-time data display.

![fuxa editor](/screenshot/fuxa-editor.png)

![fuxa ani](/screenshot/fuxa-thinglinks.gif)

![fuxa action](/screenshot/feature-action-move.gif)

## Features
- Devices connectivity with Modbus RTU/TCP, Siemens S7 Protocol, OPC-UA, BACnet IP, MQTT, Ethernet/IP (Allen Bradley)
- SCADA/HMI Web-Editor - Engineering and Design completely web-based
- Cross-Platform Full-Stack - Backend with NodeJs and Frontend with Web technologies (HTML5, CSS, Javascript, Angular, SVG)

## Live Demo
Here is a [live demo](https://frangoteam.github.io) example of FUXA editor.

## Installing and Running
FUXA is developed with NodeJS (backend) and Angular (frontend).

See the Wiki for more details about installing and getting started

[Wiki](https://github.com/frangoteam/FUXA/wiki)

[Wiki Installing/Building](https://github.com/frangoteam/FUXA/wiki/Installing-and-Running)


### Running from docker
```
docker pull frangoteam/fuxa:latest
docker run -d -p 1881:1881 frangoteam/fuxa:latest

// persistent storage of application data (project), daq (tags history), logs and images (resource)
docker run -d -p 1881:1881 -v fuxa_appdata:/usr/src/app/FUXA/server/_appdata -v fuxa_db:/usr/src/app/FUXA/server/_db -v fuxa_logs:/usr/src/app/FUXA/server/_logs -v fuxa_images:/usr/src/app/FUXA/server/_images frangoteam/fuxa:latest

// with Docker compose
// persistent storage will be at ./appdata ./db ./logs and ./images
wget https://raw.githubusercontent.com/frangoteam/FUXA/master/compose.yml
docker compose up -d
```

### Install from [NPM](https://www.npmjs.com/package/@frangoteam/fuxa)

You need to have installed [Node](https://nodejs.org/en/about/previous-releases) Version 18.

**WARNING** In linux with nodejs Version 18 the installation could be a challenge.
If you don&#039;t intend communicate with Siemens PLCs via S7 (node-snap7 library) you can install from [NPM @frangoteam/fuxa-min](https://www.npmjs.com/package/@frangoteam/fuxa-min)

```
npm install -g --unsafe-perm @frangoteam/fuxa
fuxa
```

### Install from source
[Download the latest release](https://github.com/frangoteam/FUXA/releases) and unpack it

You need to have installed [Node](https://nodejs.org/en/about/previous-releases) Version 18.

**WARNING** In linux with nodejs Version 18 the installation could be a challenge.
If you don&#039;t intend to communicate with Siemens PLCs via S7, you can remove the ```node-snap7``` library from the ```server/package.json```. Similarly, if you don&#039;t intend to use ODBC to communicate with an external database, you can remove the ```odbc``` library from the ```server/package.json```.

```
cd ./server
npm install
npm start
```

Open up a browser (better Chrome) and navigate to http://localhost:1881

**Note** If you intend to use nodejs version 14, please remove odbc from the package.json dependencies. nodejs 14 may have compatibility issues with certain versions of odbc, which could lead to installation errors.

### Creating the Electron Application
Electron is a framework for building cross-platform desktop applications using web technologies. An Electron application is standalone, meaning it can be run independently on your desktop without needing a web browser.

To create the Electron application, you need to have node.js 18 installed. Follow these steps:

Build Server and Client First
```
cd ./server
npm install
cd ../client
npm install
npm run build
```

Packaging
```
cd ./app
npm install
npm run package
```

After following these steps, you will have a standalone Electron application for FUXA. The application can be found in the ./app directory.

## Usage
- Look the guide in [wiki](https://github.com/frangoteam/FUXA/wiki) pages
- Look video from [frangoteam](https://www.youtube.com/@umbertonocelli5301)
- Look video from [Fusion Automate - Urvish Nakum](https://youtube.com/playlist?list=PLxrSjjYyzaaK8uY3kVaFzfGnwhVXiCEAO&amp;si=aU1OxgkUvLQ3bXHq)

## To Debug (Full Stack)
Install and start to serve the frontend
```
cd ./client
npm install
npm start
```

Start the Server and Client (Browser) in Debug Mode
```
In vscode: Debug ‚ÄòServer &amp; Client‚Äô
```

## To Build
Build the frontend for production
```
cd ./client
ng build --configuration=production
```

## Contributing
Any contributions you make are greatly appreciated.
If you identify any errors, or have an idea for an improvement, please open an [issue](/../../issues).
But before filing a new issue, please look through already existing issues. Search open and closed issues first.

Non-code contributions are also highly appreciated, such as improving the documentation or promoting FUXA on social media.

### Pull-Requests
If you want to raise a pull-request with a new feature, or a refactoring of existing code please first open an issue explaining the problem.
```
1. Fork the Project
2. Create your Feature Branch (git checkout -b feature/AmazingFeature)
3. Commit your Changes (git commit -m &#039;Add some AmazingFeature&#039;)
4. Push to the Branch (git push origin feature/AmazingFeature)
5. Open a Pull Request
```

### Coding standards
Please ensure you follow the coding standards used through-out the existing code base. Some basic rules include:
- Indent with 4-spaces, no tabs.
- Opening brace on same line as if/for/function and so on, closing brace on its own line.

## Let us know!
We‚Äôd be really happy if you send us your own shapes in order to collect a library to share it with others. Just send an email to info@frangoteam.org and do let us know if you have any questions or suggestions regarding our work.

## &lt;a href=&quot;https://discord.gg/WZhxz9uHh4&quot; target=&quot;_blank&quot; &gt; &lt;img src=&quot;https://skillicons.dev/icons?i=discord&quot; alt=&quot;&quot;&gt;&lt;/a&gt;

## License
MIT.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[promptfoo/promptfoo]]></title>
            <link>https://github.com/promptfoo/promptfoo</link>
            <guid>https://github.com/promptfoo/promptfoo</guid>
            <pubDate>Sun, 11 May 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[Test your prompts, agents, and RAGs. Red teaming, pentesting, and vulnerability scanning for LLMs. Compare performance of GPT, Claude, Gemini, Llama, and more. Simple declarative configs with command line and CI/CD integration.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/promptfoo/promptfoo">promptfoo/promptfoo</a></h1>
            <p>Test your prompts, agents, and RAGs. Red teaming, pentesting, and vulnerability scanning for LLMs. Compare performance of GPT, Claude, Gemini, Llama, and more. Simple declarative configs with command line and CI/CD integration.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,488</p>
            <p>Forks: 527</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre># Promptfoo: LLM evals &amp; red teaming

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://npmjs.com/package/promptfoo&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/promptfoo&quot; alt=&quot;npm&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://npmjs.com/package/promptfoo&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/promptfoo&quot; alt=&quot;npm&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/promptfoo/promptfoo/actions/workflows/main.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/promptfoo/promptfoo/main.yml&quot; alt=&quot;GitHub Workflow Status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/promptfoo/promptfoo/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/promptfoo/promptfoo&quot; alt=&quot;MIT license&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/promptfoo&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/2092591a-ccc5-42a7-aeb6-24a2808950fd&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;code&gt;promptfoo&lt;/code&gt; is a developer-friendly local tool for testing LLM applications. Stop the trial-and-error approach - start shipping secure, reliable AI apps.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.promptfoo.dev&quot;&gt;Website&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://www.promptfoo.dev/docs/getting-started/&quot;&gt;Getting Started&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://www.promptfoo.dev/docs/red-team/&quot;&gt;Red Teaming&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://www.promptfoo.dev/docs/&quot;&gt;Documentation&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://discord.gg/promptfoo&quot;&gt;Discord&lt;/a&gt;
&lt;/p&gt;

## Quick Start

```sh
# Install and initialize project
npx promptfoo@latest init

# Run your first evaluation
npx promptfoo eval
```

See [Getting Started](https://www.promptfoo.dev/docs/getting-started/) (evals) or [Red Teaming](https://www.promptfoo.dev/docs/red-team/) (vulnerability scanning) for more.

## What can you do with Promptfoo?

- **Test your prompts and models** with [automated evaluations](https://www.promptfoo.dev/docs/getting-started/)
- **Secure your LLM apps** with [red teaming](https://www.promptfoo.dev/docs/red-team/) and vulnerability scanning
- **Compare models** side-by-side (OpenAI, Anthropic, Azure, Bedrock, Ollama, and [more](https://www.promptfoo.dev/docs/providers/))
- **Automate checks** in [CI/CD](https://www.promptfoo.dev/docs/integrations/ci-cd/)
- **Share results** with your team

Here&#039;s what it looks like in action:

![prompt evaluation matrix - web viewer](https://www.promptfoo.dev/img/claude-vs-gpt-example@2x.png)

It works on the command line too:

![prompt evaluation matrix - command line](https://github.com/promptfoo/promptfoo/assets/310310/480e1114-d049-40b9-bd5f-f81c15060284)

It also can generate [security vulnerability reports](https://www.promptfoo.dev/docs/red-team/):

![gen ai red team](https://www.promptfoo.dev/img/riskreport-1@2x.png)

## Why promptfoo?

- üöÄ **Developer-first**: Fast, with features like live reload and caching
- üîí **Private**: Runs 100% locally - your prompts never leave your machine
- üîß **Flexible**: Works with any LLM API or programming language
- üí™ **Battle-tested**: Powers LLM apps serving 10M+ users in production
- üìä **Data-driven**: Make decisions based on metrics, not gut feel
- ü§ù **Open source**: MIT licensed, with an active community

## Star the Project ‚≠ê

If you find promptfoo useful, please star it on GitHub! Stars help the project grow and ensure you stay updated on new releases and features.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;site/static/img/github/star-animation.gif&quot; alt=&quot;Star us on GitHub!&quot; width=&quot;800&quot; /&gt;
&lt;/p&gt;

## Learn More

- üìö [Full Documentation](https://www.promptfoo.dev/docs/intro/)
- üîê [Red Teaming Guide](https://www.promptfoo.dev/docs/red-team/)
- üéØ [Getting Started](https://www.promptfoo.dev/docs/getting-started/)
- üíª [CLI Usage](https://www.promptfoo.dev/docs/usage/command-line/)
- üì¶ [Node.js Package](https://www.promptfoo.dev/docs/usage/node-package/)
- ü§ñ [Supported Models](https://www.promptfoo.dev/docs/providers/)

## Contributing

We welcome contributions! Check out our [contributing guide](https://www.promptfoo.dev/docs/contributing/) to get started.

Join our [Discord community](https://discord.gg/promptfoo) for help and discussion.

&lt;a href=&quot;https://github.com/promptfoo/promptfoo/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=promptfoo/promptfoo&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>