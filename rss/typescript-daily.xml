<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Mon, 13 Oct 2025 00:05:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[anthropics/claude-code]]></title>
            <link>https://github.com/anthropics/claude-code</link>
            <guid>https://github.com/anthropics/claude-code</guid>
            <pubDate>Mon, 13 Oct 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anthropics/claude-code">anthropics/claude-code</a></h1>
            <p>Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 37,874</p>
            <p>Forks: 2,372</p>
            <p>Stars today: 997 stars today</p>
            <h2>README</h2><pre># Claude Code

![](https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square) [![npm]](https://www.npmjs.com/package/@anthropic-ai/claude-code)

[npm]: https://img.shields.io/npm/v/@anthropic-ai/claude-code.svg?style=flat-square

Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows -- all through natural language commands. Use it in your terminal, IDE, or tag @claude on Github.

**Learn more in the [official documentation](https://docs.anthropic.com/en/docs/claude-code/overview)**.

&lt;img src=&quot;./demo.gif&quot; /&gt;

## Get started

1. Install Claude Code:

```sh
npm install -g @anthropic-ai/claude-code
```

2. Navigate to your project directory and run `claude`.

## Reporting Bugs

We welcome your feedback. Use the `/bug` command to report issues directly within Claude Code, or file a [GitHub issue](https://github.com/anthropics/claude-code/issues).

## Connect on Discord

Join the [Claude Developers Discord](https://anthropic.com/discord) to connect with other developers using Claude Code. Get help, share feedback, and discuss your projects with the community.

## Data collection, usage, and retention

When you use Claude Code, we collect feedback, which includes usage data (such as code acceptance or rejections), associated conversation data, and user feedback submitted via the `/bug` command.

### How we use your data

See our [data usage policies](https://docs.anthropic.com/en/docs/claude-code/data-usage).

### Privacy safeguards

We have implemented several safeguards to protect your data, including limited retention periods for sensitive information, restricted access to user session data, and clear policies against using feedback for model training.

For full details, please review our [Commercial Terms of Service](https://www.anthropic.com/legal/commercial-terms) and [Privacy Policy](https://www.anthropic.com/legal/privacy).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[evershopcommerce/evershop]]></title>
            <link>https://github.com/evershopcommerce/evershop</link>
            <guid>https://github.com/evershopcommerce/evershop</guid>
            <pubDate>Mon, 13 Oct 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[üõçÔ∏è Typescript E-commerce Platform]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/evershopcommerce/evershop">evershopcommerce/evershop</a></h1>
            <p>üõçÔ∏è Typescript E-commerce Platform</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,139</p>
            <p>Forks: 1,866</p>
            <p>Stars today: 384 stars today</p>
            <h2>README</h2><pre>&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img width=&quot;60&quot; height=&quot;68&quot; alt=&quot;EverShop Logo&quot; src=&quot;https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/logo-green.png&quot;/&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;h1 align=&quot;center&quot;&gt;EverShop&lt;/h1&gt;
&lt;/p&gt;
&lt;h4 align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://evershop.io/docs/development/getting-started/introduction&quot;&gt;Documentation&lt;/a&gt; |
    &lt;a href=&quot;https://demo.evershop.io/&quot;&gt;Demo&lt;/a&gt;
&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/evershopcommerce/evershop/actions/workflows/build_test.yml/badge.svg&quot; alt=&quot;Github Action&quot;&gt;
  &lt;a href=&quot;https://twitter.com/evershopjs&quot;&gt;
    &lt;img alt=&quot;Twitter Follow&quot; src=&quot;https://img.shields.io/twitter/follow/evershopjs?style=social&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/GSzt7dt7RM&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/757179260417867879?label=discord&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://opensource.org/licenses/GPL-3.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-GPLv3-blue.svg&quot; alt=&quot;License&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img alt=&quot;EverShop&quot; width=&quot;950&quot; src=&quot;https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/banner.png&quot;/&gt;
&lt;/p&gt;

## Introduction

EverShop is a modern, TypeScript-first eCommerce platform built with GraphQL and React. Designed for developers, it offers essential commerce features in a modular, fully customizable architecture‚Äîperfect for building tailored shopping experiences with confidence and speed.

## Installation Using Docker


You can get started with EverShop in minutes by using the Docker image. The Docker image is a great way to get started with EverShop without having to worry about installing dependencies or configuring your environment.

```bash
curl -sSL https://raw.githubusercontent.com/evershopcommerce/evershop/main/docker-compose.yml &gt; docker-compose.yml
docker-compose up -d
```

For the full installation guide, please refer to our [Installation guide](https://evershop.io/docs/development/getting-started/installation-guide).

## Documentation

- [Installation guide](https://evershop.io/docs/development/getting-started/installation-guide).

- [Extension development](https://evershop.io/docs/development/module/create-your-first-extension).

- [Theme development](https://evershop.io/docs/development/theme/theme-overview).


## Demo

Explore our demo store.

&lt;p align=&quot;left&quot;&gt;
  &lt;a href=&quot;https://demo.evershop.io/admin&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;evershop-backend-demo&quot; height=&quot;35&quot; alt=&quot;EverShop Admin Demo&quot; src=&quot;https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/evershop-demo-back.png&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://demo.evershop.io/&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;evershop-store-demo&quot; height=&quot;35&quot; alt=&quot;EverShop Store Demo&quot; src=&quot;https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/evershop-demo-front.png&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;b&gt;Demo user:&lt;/b&gt;

Email: demo@evershop.io&lt;br/&gt;
Password: 123456

## Support

If you like my work, feel free to:

- ‚≠ê this repository. It helps.
- [![Tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)][tweet] about EverShop. Thank you!

[tweet]: https://twitter.com/intent/tweet?url=https%3A%2F%2Fgithub.com%2Fevershopcommerce%2Fevershop&amp;text=Awesome%20React%20Ecommerce%20Project&amp;hashtags=react,ecommerce,expressjs,graphql

## Contributing

EverShop is an open-source project. We are committed to a fully transparent development process and appreciate highly any contributions. Whether you are helping us fix bugs, proposing new features, improving our documentation or spreading the word - we would love to have you as part of the EverShop community.

### Ask a question about EverShop

You can ask questions, and participate in discussions about EverShop-related topics in the EverShop Discord channel.

&lt;a href=&quot;https://discord.gg/GSzt7dt7RM&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/discord_banner_github.svg&quot; /&gt;&lt;/a&gt;

### Create a bug report

If you see an error message or run into an issue, please [create bug report](https://github.com/evershopcommerce/evershop/issues/new). This effort is valued and it will help all EverShop users.


### Submit a feature request

If you have an idea, or you&#039;re missing a capability that would make development easier and more robust, please [Submit feature request](https://github.com/evershopcommerce/evershop/issues/new).

If a similar feature request already exists, don&#039;t forget to leave a &quot;+1&quot;.
If you add some more information such as your thoughts and vision about the feature, your comments will be embraced warmly :)


Please refer to our [Contribution Guidelines](./CONTRIBUTING.md) and [Code of Conduct](./CODE_OF_CONDUCT.md).

## License

[GPL-3.0 License](https://github.com/evershopcommerce/evershop/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[daytonaio/daytona]]></title>
            <link>https://github.com/daytonaio/daytona</link>
            <guid>https://github.com/daytonaio/daytona</guid>
            <pubDate>Mon, 13 Oct 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[Daytona is a Secure and Elastic Infrastructure for Running AI-Generated Code]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/daytonaio/daytona">daytonaio/daytona</a></h1>
            <p>Daytona is a Secure and Elastic Infrastructure for Running AI-Generated Code</p>
            <p>Language: TypeScript</p>
            <p>Stars: 22,931</p>
            <p>Forks: 2,377</p>
            <p>Stars today: 231 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

[![Documentation](https://img.shields.io/github/v/release/daytonaio/docs?label=Docs&amp;color=23cc71)](https://www.daytona.io/docs)
![License](https://img.shields.io/badge/License-AGPL--3-blue)
[![Go Report Card](https://goreportcard.com/badge/github.com/daytonaio/daytona)](https://goreportcard.com/report/github.com/daytonaio/daytona)
[![Issues - daytona](https://img.shields.io/github/issues/daytonaio/daytona)](https://github.com/daytonaio/daytona/issues)
![GitHub Release](https://img.shields.io/github/v/release/daytonaio/daytona)

&lt;/div&gt;

&amp;nbsp;

&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-white.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-black.png&quot;&gt;
    &lt;img alt=&quot;Daytona logo&quot; src=&quot;https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-black.png&quot; width=&quot;50%&quot;&gt;
  &lt;/picture&gt;
&lt;/div&gt;

&lt;h3 align=&quot;center&quot;&gt;
  Run AI Code.
  &lt;br/&gt;
  Secure and Elastic Infrastructure for
  Running Your AI-Generated Code.
&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.daytona.io/docs&quot;&gt; Documentation &lt;/a&gt;¬∑
    &lt;a href=&quot;https://github.com/daytonaio/daytona/issues/new?assignees=&amp;labels=bug&amp;projects=&amp;template=bug_report.md&amp;title=%F0%9F%90%9B+Bug+Report%3A+&quot;&gt; Report Bug &lt;/a&gt;¬∑
    &lt;a href=&quot;https://github.com/daytonaio/daytona/issues/new?assignees=&amp;labels=enhancement&amp;projects=&amp;template=feature_request.md&amp;title=%F0%9F%9A%80+Feature%3A+&quot;&gt; Request Feature &lt;/a&gt;¬∑
    &lt;a href=&quot;https://go.daytona.io/slack&quot;&gt; Join our Slack &lt;/a&gt;¬∑
    &lt;a href=&quot;https://x.com/daytonaio&quot;&gt; Connect on X &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.producthunt.com/posts/daytona-2?embed=true&amp;utm_source=badge-top-post-badge&amp;utm_medium=badge&amp;utm_souce=badge-daytona&amp;#0045;2&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=957617&amp;theme=neutral&amp;period=daily&amp;t=1746176740150&quot; alt=&quot;Daytona&amp;#0032; - Secure&amp;#0032;and&amp;#0032;elastic&amp;#0032;infra&amp;#0032;for&amp;#0032;running&amp;#0032;your&amp;#0032;AI&amp;#0045;generated&amp;#0032;code&amp;#0046; | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.producthunt.com/posts/daytona-2?embed=true&amp;utm_source=badge-top-post-topic-badge&amp;utm_medium=badge&amp;utm_souce=badge-daytona&amp;#0045;2&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=957617&amp;theme=neutral&amp;period=monthly&amp;topic_id=237&amp;t=1746176740150&quot; alt=&quot;Daytona&amp;#0032; - Secure&amp;#0032;and&amp;#0032;elastic&amp;#0032;infra&amp;#0032;for&amp;#0032;running&amp;#0032;your&amp;#0032;AI&amp;#0045;generated&amp;#0032;code&amp;#0046; | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

---

## Installation

### Python SDK

```bash
pip install daytona
```

### TypeScript SDK

```bash
npm install @daytonaio/sdk
```

---

## Features

- **Lightning-Fast Infrastructure**: Sub-90ms Sandbox creation from code to execution.
- **Separated &amp; Isolated Runtime**: Execute AI-generated code with zero risk to your infrastructure.
- **Massive Parallelization for Concurrent AI Workflows**: Fork Sandbox filesystem and memory state (Coming soon!)
- **Programmatic Control**: File, Git, LSP, and Execute API
- **Unlimited Persistence**: Your Sandboxes can live forever
- **OCI/Docker Compatibility**: Use any OCI/Docker image to create a Sandbox

---

## Quick Start

1. Create an account at https://app.daytona.io
1. Generate a [new API key](https://app.daytona.io/dashboard/keys)
1. Follow the [Getting Started docs](https://www.daytona.io/docs/getting-started/) to start using the Daytona SDK

## Creating your first Sandbox

### Python SDK

```py
from daytona import Daytona, DaytonaConfig, CreateSandboxBaseParams

# Initialize the Daytona client
daytona = Daytona(DaytonaConfig(api_key=&quot;YOUR_API_KEY&quot;))

# Create the Sandbox instance
sandbox = daytona.create(CreateSandboxBaseParams(language=&quot;python&quot;))

# Run code securely inside the Sandbox
response = sandbox.process.code_run(&#039;print(&quot;Sum of 3 and 4 is &quot; + str(3 + 4))&#039;)
if response.exit_code != 0:
    print(f&quot;Error running code: {response.exit_code} {response.result}&quot;)
else:
    print(response.result)

# Clean up the Sandbox
daytona.delete(sandbox)
```

### Typescript SDK

```jsx
import { Daytona } from &#039;@daytonaio/sdk&#039;

async function main() {
  // Initialize the Daytona client
  const daytona = new Daytona({
    apiKey: &#039;YOUR_API_KEY&#039;,
  })

  let sandbox
  try {
    // Create the Sandbox instance
    sandbox = await daytona.create({
      language: &#039;typescript&#039;,
    })
    // Run code securely inside the Sandbox
    const response = await sandbox.process.codeRun(&#039;console.log(&quot;Sum of 3 and 4 is &quot; + (3 + 4))&#039;)
    if (response.exitCode !== 0) {
      console.error(&#039;Error running code:&#039;, response.exitCode, response.result)
    } else {
      console.log(response.result)
    }
  } catch (error) {
    console.error(&#039;Sandbox flow error:&#039;, error)
  } finally {
    if (sandbox) await daytona.delete(sandbox)
  }
}

main().catch(console.error)
```

---

## Contributing

Daytona is Open Source under the [GNU AFFERO GENERAL PUBLIC LICENSE](LICENSE), and is the [copyright of its contributors](NOTICE). If you would like to contribute to the software, read the Developer Certificate of Origin Version 1.1 (https://developercertificate.org/). Afterwards, navigate to the [contributing guide](CONTRIBUTING.md) to get started.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[DIYgod/RSSHub]]></title>
            <link>https://github.com/DIYgod/RSSHub</link>
            <guid>https://github.com/DIYgod/RSSHub</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[üß° Everything is RSSible]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DIYgod/RSSHub">DIYgod/RSSHub</a></h1>
            <p>üß° Everything is RSSible</p>
            <p>Language: TypeScript</p>
            <p>Stars: 39,137</p>
            <p>Forks: 8,593</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://docs.rsshub.app/img/logo.png&quot; alt=&quot;RSSHub&quot; width=&quot;100&quot;&gt;
&lt;/p&gt;
&lt;h1 align=&quot;center&quot;&gt;RSSHub&lt;/h1&gt;

&gt; üß° Everything is RSSible

[![](https://img.shields.io/badge/dynamic/json?url=https://rsshub-analytics.diygod.workers.dev/&amp;query=requests&amp;color=F38020&amp;label=requests&amp;logo=cloudflare&amp;style=flat-square&amp;suffix=/month)](https://rsshub.app)
[![docker publish](https://img.shields.io/docker/pulls/diygod/rsshub?label=docker%20pulls&amp;logo=docker&amp;style=flat-square)](https://hub.docker.com/r/diygod/rsshub)
[![npm publish](https://img.shields.io/npm/dt/rsshub?label=npm%20downloads&amp;logo=npm&amp;style=flat-square)](https://www.npmjs.com/package/rsshub)
[![test](https://img.shields.io/github/actions/workflow/status/DIYgod/RSSHub/test.yml?branch=master&amp;label=test&amp;logo=github&amp;style=flat-square)](https://github.com/DIYgod/RSSHub/actions/workflows/test.yml?query=event%3Apush+branch%3Amaster)
[![Test coverage](https://img.shields.io/codecov/c/github/DIYgod/RSSHub.svg?style=flat-square&amp;logo=codecov)](https://app.codecov.io/gh/DIYgod/RSSHub/branch/master)
[![Visitors](https://hitscounter.dev/api/hit?url=https%3A%2F%2Fgithub.com%2FDIYgod%2FRSSHub&amp;label=RSS+lovers&amp;icon=rss-fill&amp;color=%23ff752e)](https://github.com/DIYgod/RSSHub)

[![Telegram group](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.swo.moe%2Fstats%2Ftelegram%2Frsshub&amp;query=count&amp;color=2CA5E0&amp;label=Telegram%20Group&amp;logo=telegram&amp;cacheSeconds=3600&amp;style=flat-square)](https://t.me/rsshub) [![Telegram channel](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.swo.moe%2Fstats%2Ftelegram%2FawesomeRSSHub&amp;query=count&amp;color=2CA5E0&amp;label=Telegram%20Channel&amp;logo=telegram&amp;cacheSeconds=3600&amp;style=flat-square)](https://t.me/awesomeRSSHub) [![X (Twitter)](https://img.shields.io/badge/any_text-Follow-blue?color=2CA5E0&amp;label=Twitter&amp;logo=X&amp;cacheSeconds=3600&amp;style=flat-square)](https://x.com/intent/follow?screen_name=_RSSHub)

## Introduction

RSSHub is the world&#039;s largest RSS network, consisting of over 5,000 global instances.

RSSHub delivers millions of contents aggregated from all kinds of sources, our vibrant open source community is ensuring the deliver of RSSHub&#039;s new routes, new features and bug fixes.

[Documentation](https://docs.rsshub.app) | [Telegram Group](https://t.me/rsshub) | [Telegram Channel](https://t.me/awesomeRSSHub) | [X (Twitter)](https://x.com/intent/follow?screen_name=_RSSHub)

## Related Projects

-   [RSSHub Radar](https://github.com/DIYgod/RSSHub-Radar) | A browser extension that can help you quickly discover and subscribe to the RSS and RSSHub of current websites.
-   [RSSBud](https://github.com/Cay-Zhang/RSSBud) | RSSHub Radar for iOS platform, designed specifically for mobile ecosystem optimization.
-   [RSSAid](https://github.com/LeetaoGoooo/RSSAid) | RSSHub Radar for Android platform built with Flutter.
-   [DocSearch](https://github.com/Fatpandac/DocSearch) | Link RSSHub DocSearch into Raycast

## Contribute

We welcome all pull requests. Suggestions and feedback are also welcomed [here](https://github.com/DIYgod/RSSHub/issues).

Refer to [Quick Start](https://docs.rsshub.app/joinus/)

## Deployment

Refer to [Deployment](https://docs.rsshub.app/deploy/)

## Special Thanks

&lt;div align=&quot;center&quot;&gt;

[![](https://opencollective.com/RSSHub/contributors.svg?width=890)](https://github.com/DIYgod/RSSHub/graphs/contributors)

Logo designer [sheldonrrr](https://dribbble.com/sheldonrrr)

[![](https://raw.githubusercontent.com/DIYgod/sponsors/main/sponsors.simple.svg)](https://github.com/DIYgod/sponsors)

&lt;a href=&quot;https://www.cloudflare.com&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;50px&quot; src=&quot;https://i.imgur.com/7Ph27Fq.png&quot;&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://www.netlify.com&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;40px&quot; src=&quot;https://i.imgur.com/cU01915.png&quot;&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://1password.com&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;40px&quot; src=&quot;https://i.imgur.com/a2XjflO.png&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

## Author

**RSSHub** ¬© [DIYgod](https://github.com/DIYgod), Released under the [MIT](./LICENSE) License.&lt;br&gt;
Authored and maintained by DIYgod with help from contributors ([list](https://github.com/DIYgod/RSSHub/contributors)).

&gt; Blog [@DIYgod](https://diygod.cc) ¬∑ GitHub [@DIYgod](https://github.com/DIYgod) ¬∑ X (Twitter) [@DIYgod](https://x.com/DIYgod) ¬∑ Telegram Channel [@awesomeDIYgod](https://t.me/awesomeDIYgod)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[coze-dev/coze-studio]]></title>
            <link>https://github.com/coze-dev/coze-studio</link>
            <guid>https://github.com/coze-dev/coze-studio</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[An AI agent development platform with all-in-one visual tools, simplifying agent creation, debugging, and deployment like never before. Coze your way to AI Agent creation.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/coze-dev/coze-studio">coze-dev/coze-studio</a></h1>
            <p>An AI agent development platform with all-in-one visual tools, simplifying agent creation, debugging, and deployment like never before. Coze your way to AI Agent creation.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 17,734</p>
            <p>Forks: 2,449</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/943f576df3424fa98580c2ad18946719~tplv-goo7wpa0wc-image.image)

&lt;div align=&quot;center&quot;&gt;&lt;p&gt;
&lt;a href=&quot;#what-is-coze-studio&quot;&gt;Coze Studio&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;#feature-list&quot;&gt;Feature list&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;#quickstart&quot;&gt;Quickstart&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;#developer-guide&quot;&gt;Developer Guide&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
  &lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/license-apache2.0-blue.svg&quot;&gt;
  &lt;img alt=&quot;Go Version&quot; src=&quot;https://img.shields.io/badge/go-%3E%3D%201.23.4-blue&quot;&gt;
&lt;/p&gt;

English | [‰∏≠Êñá](README.zh_CN.md)

&lt;/div&gt;

## What is Coze Studio?

[Coze Studio](https://www.coze.cn/home) is an all-in-one AI agent development tool. Providing the latest large models and tools, various development modes and frameworks, Coze Studio offers the most convenient AI agent development environment, from development to deployment. 

* **Provides all core technologies needed for AI agent development**: prompt, RAG, plugin, workflow, enabling developers to focus on creating the core value of AI.
* **Ready to use for professional AI agent development at the lowest cost**: Coze Studio provides developers with complete app templates and build frameworks, allowing you to quickly construct various AI agents and turn creative ideas into reality.

Coze Studio, derived from the &quot;Coze Development Platform&quot; which has served tens of thousands of enterprises and millions of developers, we have made its core engine completely open. It is a one-stop visual development tool for AI Agents that makes creating, debugging, and deploying AI Agents unprecedentedly simple. Through Coze Studio&#039;s visual design and build tools, developers can quickly create and debug agents, apps, and workflows using no-code or low-code approaches, enabling powerful AI app development and more customized business logic. It&#039;s an ideal choice for building low-code AI products tailored . Coze Studio aims to lower the threshold for AI agent development and application, encouraging community co-construction and sharing for deeper exploration and practice in the AI field.

The backend of Coze Studio is developed using Golang, the frontend uses React + TypeScript, and the overall architecture is based on microservices and built following domain-driven design (DDD) principles. Provide developers with a high-performance, highly scalable, and easy-to-customize underlying framework to help them address complex business needs.
## Feature list
| **Module** | **Feature** |
| --- | --- |
| Model service | Manage the model list, integrate services such as OpenAI and Volcengine |
| Build agent | * Build, publish, and manage agent &lt;br&gt; * Support configuring workflows, knowledge bases, and other resources |
| Build apps | * Create and publish apps &lt;br&gt; * Build business logic through workflows |
| Build a workflow | Create, modify, publish, and delete workflows |
| Develop resources | Support creating and managing the following resources: &lt;br&gt; * Plugins &lt;br&gt; * Knowledge bases &lt;br&gt; * Databases &lt;br&gt; * Prompts |
| API and SDK | * Create conversations, initiate chats, and other OpenAPI &lt;br&gt; * Integrate agents or apps into your own app through Chat SDK |

## Quickstart
Learn how to obtain and deploy the open-source version of Coze Studio, quickly build projects, and experience Coze Studio&#039;s open-source version.

Environment requirements:

* Before installing Coze Studio, please ensure that your machine meets the following minimum system requirements: 2 Core„ÄÅ4 GB
* Pre-install Docker and Docker Compose, and start the Docker service.

Deployment steps:

1. Retrieve the source code.
   ```Bash
   # Clone code
   git clone https://github.com/coze-dev/coze-studio.git
   ```

2. Configure the model.
   1. Copy the template files of the doubao-seed-1.6 model from the template directory and paste them into the configuration file directory.
      ```Bash
      cd coze-studio
      # Copy model configuration template
      cp backend/conf/model/template/model_template_ark_doubao-seed-1.6.yaml backend/conf/model/ark_doubao-seed-1.6.yaml
      ```

   2. Modify the template file in the configuration file directory.
      1. Enter the directory `backend/conf/model`. Open the file `ark_doubao-seed-1.6.yaml`.
      2. Set the fields `id`, `meta.conn_config.api_key`, `meta.conn_config.model`, and save the file.
         * **id**: The model ID in Coze Studio, defined by the developer, must be a non-zero integer and globally unique. Agents or workflows call models based on model IDs. For models that have already been launched, do not modify their IDs; otherwise, it may result in model call failures.
         * **meta.conn_config.api_key**: The API Key for the model service. In this example, it is the API Key for Ark API Key. For more information, see [Get Volcengine Ark API Key](https://www.volcengine.com/docs/82379/1541594) or [Get BytePlus ModelArk API Key](https://docs.byteplus.com/en/docs/ModelArk/1361424?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=coze_open_source).
         * **meta.conn_config.model**: The Model name for the model service. In this example, it refers to the Model ID or Endpoint ID of Ark. For more information, see [Get Volcengine Ark Model ID](https://www.volcengine.com/docs/82379/1513689) / [Get Volcengine Ark Endpoint ID](https://www.volcengine.com/docs/82379/1099522) or  [Get BytePlus ModelArk Model ID](https://docs.byteplus.com/en/docs/ModelArk/model_id?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=coze_open_source) / [Get BytePlus ModelArk Endpoint ID](https://docs.byteplus.com/en/docs/ModelArk/1099522?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=coze_open_source).  
         &gt; For users in China, you may use Volcengine Ark; for users outside China, you may use BytePlus ModelArk instead.
3. Deploy and start the service.
   When deploying and starting Coze Studio for the first time, it may take a while to retrieve images and build local images. Please be patient. During deployment, you will see the following log information. If you see the message &quot;Container coze-server Started,&quot; it means the Coze Studio service has started successfully.
   ```Bash
   # Start the service
   cd docker
   cp .env.example .env
   docker compose up -d
   ```
   For common startup failure issues, **please refer to the [FAQ](https://github.com/coze-dev/coze-studio/wiki/9.-FAQ)**.
4. After starting the service, you can open Coze Studio by accessing `http://localhost:8888/` through your browser.

&gt; [!WARNING]
&gt; If you want to deploy Coze Studio in a public network environment, it is recommended to assess security risks before you begin, and take corresponding protection measures. Possible security risks include account registration functions, Python execution environments in workflow code nodes, Coze Server listening address configurations, SSRF (Server - Side Request Forgery), and some horizontal privilege escalations in APIs.  For more details, refer to [Quickstart](https://github.com/coze-dev/coze-studio/wiki/2.-Quickstart#security-risks-in-public-networks).

## Developer Guide

* **Project Configuration**:
   * [Model Configuration](https://github.com/coze-dev/coze-studio/wiki/3.-Model-configuration): Before deploying the open-source version of Coze Studio, you must configure the model service. Otherwise, you cannot select models when building agents, workflows, and apps.
   * [Plugin Configuration](https://github.com/coze-dev/coze-studio/wiki/4.-Plugin-Configuration): To use official plugins from the plugin store, you must first configure the plugins and add the authentication keys for third-party services.
   * [Basic Component Configuration](https://github.com/coze-dev/coze-studio/wiki/5.-Basic-component-configuration): Learn how to configure components such as image uploaders to use functions like image uploading in Coze Studio .
* [API Reference](https://github.com/coze-dev/coze-studio/wiki/6.-API-Reference): The Coze Studio Community Edition API and Chat SDK are authenticated using Personal Access Token, providing APIs for conversations and workflows.
* [Development Guidelines](https://github.com/coze-dev/coze-studio/wiki/7.-Development-Standards):
   * [Project Architecture](https://github.com/coze-dev/coze-studio/wiki/7.-Development-Standards#project-architecture): Learn about the technical architecture and core components of the open-source version of Coze Studio.
   * [Code Development and Testing](https://github.com/coze-dev/coze-studio/wiki/7.-Development-Standards#code-development-and-testing): Learn how to perform secondary development and testing based on the open-source version of Coze Studio.
   * [Troubleshooting](https://github.com/coze-dev/coze-studio/wiki/7.-Development-Standards#troubleshooting): Learn how to view container states and system logs.

## Using the open-source version of Coze Studio
&gt; Regarding how to use Coze Studio, refer to the [Coze Development Platform Official Documentation Center](https://www.coze.cn/open/docs) for more information. Please note that certain features, such as tone customization, are limited to the commercial version. Differences between the open-source and commercial versions can be found in the **Feature List**.


* [Quick Start](https://www.coze.cn/open/docs/guides/quickstart): Quickly build an AI assistant agent with Coze Studio.
* [Developing Agents](https://www.coze.cn/open/docs/guides/agent_overview): Learn how to create, build, publish, and manage agents. You can use functions such as knowledge, plugins, etc., to resolve model hallucination and lack of expertise in professional fields. In addition, Coze Studio provides rich memory features that enable agents to generate more accurate responses based on a personal user&#039;s historical conversations during interactions.
* [Develop workflows](https://www.coze.cn/open/docs/guides/workflow): A workflow is a set of executable instructions used to implement business logic or complete specific tasks. It structures data flow and task processing for apps or agents. Coze Studio provides a visual canvas where you can quickly build workflows by dragging and dropping nodes.
* [Resources such as plugins](https://www.coze.cn/open/docs/guides/plugin): In Coze Studio, workflows, plugins, databases, knowledge bases, and variables are collectively referred to as resources.
* **API &amp; SDK**: Coze Studio supports [API related to chat and workflows](https://github.com/coze-dev/coze-studio/wiki/6.-API-Reference), and you can also integrate agents or apps with local business systems through [Chat SDK](https://www.coze.cn/open/docs/developer_guides/web_sdk_overview).
* [Tutorials for practice](https://www.coze.cn/open/docs/tutorial/chat_sdk_web_online_customer_service): Learn how to use Coze Studio to implement various AI scenarios, such as building web-based online customer service using Chat SDK.

## License
This project uses the Apache 2.0 license. For details, please refer to the [LICENSE](https://github.com/coze-dev/coze-studio/blob/main/LICENSE-APACHE) file.
## Community contributions
We welcome community contributions. For contribution guidelines, please refer to [CONTRIBUTING](https://github.com/coze-dev/coze-studio/blob/main/CONTRIBUTING.md) and [Code of conduct](https://github.com/coze-dev/coze-studio/blob/main/CODE_OF_CONDUCT.md). We look forward to your contributions!
## Security and privacy
If you discover potential security issues in the project, or believe you may have found a security issue, please notify the ByteDance security team through our [security center](https://security.bytedance.com/src) or [vulnerability reporting email](mailto:sec@bytedance.com).
Please **do not** create public GitHub Issues.
## Join Community

We are committed to building an open and friendly developer community. All developers interested in AI Agent development are welcome to join us!

### üêõ Issue Reports &amp; Feature Requests
To efficiently track and resolve issues while ensuring transparency and collaboration, we recommend participating through:
- **GitHub Issues**: [Submit bug reports or feature requests](https://github.com/coze-dev/coze-studio/issues)
- **Pull Requests**: [Contribute code or documentation improvements](https://github.com/coze-dev/coze-studio/pulls)

### üí¨ Technical Discussion &amp; Communication
Join our technical discussion groups to share experiences with other developers and stay updated with the latest project developments:

**Feishu Group Chat**  
Scan the QR code below with Feishu mobile app to join:

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0a49081e8f3743e8bf3dcdded4bb571a~tplv-goo7wpa0wc-image.image)

**Discord Server**  
Click to join: [Coze Community](https://discord.gg/sTVN9EVS4B)

**Telegram Group**  
Click to join: Telegram Group [Coze](https://t.me/+pP9CkPnomDA0Mjgx)

## Acknowledgments
Thank you to all the developers and community members who have contributed to the Coze Studio project. Special thanks:

* The [Eino](https://github.com/cloudwego/eino) framework team - providing powerful support for Coze Studio&#039;s agent and workflow runtime engines, model abstractions and implementations, and knowledge base indexing and retrieval
* The [FlowGram](https://github.com/bytedance/flowgram.ai) team - providing a high-quality workflow building engine for Coze Studio&#039;s frontend workflow canvas editor
* The [Hertz](https://github.com/cloudwego/hertz) team - Go HTTP framework with high-performance and strong-extensibility for building micro-services
* All users who participated in testing and feedback</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lobehub/lobe-chat]]></title>
            <link>https://github.com/lobehub/lobe-chat</link>
            <guid>https://github.com/lobehub/lobe-chat</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[ü§Ø Lobe Chat - an open-source, modern design AI chat framework. Supports multiple AI providers (OpenAI / Claude 4 / Gemini / DeepSeek / Ollama / Qwen), Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobe-chat">lobehub/lobe-chat</a></h1>
            <p>ü§Ø Lobe Chat - an open-source, modern design AI chat framework. Supports multiple AI providers (OpenAI / Claude 4 / Gemini / DeepSeek / Ollama / Qwen), Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 66,703</p>
            <p>Forks: 13,806</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# Lobe Chat

An open-source, modern design ChatGPT/LLMs UI/framework.&lt;br/&gt;
Supports speech synthesis, multi-modal, and extensible ([function call][docs-function-call]) plugin system.&lt;br/&gt;
One-click **FREE** deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.

**English** ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md) ¬∑ [Official Site][official-site] ¬∑ [Changelog][changelog] ¬∑ [Documents][docs] ¬∑ [Blog][blog] ¬∑ [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeChat Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Pioneering the new age of thinking and creating. Built for you, the Super Individual.&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url] &lt;br /&gt; &lt;br /&gt; &lt;a href=&quot;https://vercel.com/oss&quot;&gt; &lt;img alt=&quot;Vercel OSS Program&quot; src=&quot;https://vercel.com/oss/program-badge.svg&quot; /&gt; &lt;/a&gt;

![][image-overview]

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [üëãüèª Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [‚ú® Features](#-features)
  - [‚ú® MCP Plugin One-Click Installation](#-mcp-plugin-one-click-installation)
  - [üè™ MCP Marketplace](#-mcp-marketplace)
  - [üñ•Ô∏è Desktop App](#Ô∏è-desktop-app)
  - [üåê Smart Internet Search](#-smart-internet-search)
  - [Chain of Thought](#chain-of-thought)
  - [Branching Conversations](#branching-conversations)
  - [Artifacts Support](#artifacts-support)
  - [File Upload /Knowledge Base](#file-upload-knowledge-base)
  - [Multi-Model Service Provider Support](#multi-model-service-provider-support)
  - [Local Large Language Model (LLM) Support](#local-large-language-model-llm-support)
  - [Model Visual Recognition](#model-visual-recognition)
  - [TTS &amp; STT Voice Conversation](#tts--stt-voice-conversation)
  - [Text to Image Generation](#text-to-image-generation)
  - [Plugin System (Function Calling)](#plugin-system-function-calling)
  - [Agent Market (GPTs)](#agent-market-gpts)
  - [Support Local / Remote Database](#support-local--remote-database)
  - [Support Multi-User Management](#support-multi-user-management)
  - [Progressive Web App (PWA)](#progressive-web-app-pwa)
  - [Mobile Device Adaptation](#mobile-device-adaptation)
  - [Custom Themes](#custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [‚ö°Ô∏è Performance](#Ô∏è-performance)
- [üõ≥ Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [üì¶ Ecosystem](#-ecosystem)
- [üß© Plugins](#-plugins)
- [‚å®Ô∏è Local Development](#Ô∏è-local-development)
- [ü§ù Contributing](#-contributing)
- [‚ù§Ô∏è Sponsor](#Ô∏è-sponsor)
- [üîó More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

## üëãüèª Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![][vercel-shield-badge]][vercel-link]   | No installation or registration necessary! Visit our website to experience it firsthand.                           |
| :---------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link] | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub. |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ ‚≠êÔ∏è

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## ‚ú® Features

Transform your AI experience with LobeChat&#039;s powerful features designed for seamless connectivity, enhanced productivity, and unlimited creativity.

![][image-feat-mcp]

### ‚ú® MCP Plugin One-Click Installation

**Seamlessly Connect Your AI to the World**

Unlock the full potential of your AI by enabling smooth, secure, and dynamic interactions with external tools, data sources, and services. LobeChat&#039;s MCP (Model Context Protocol) plugin system breaks down the barriers between your AI and the digital ecosystem, allowing for unprecedented connectivity and functionality.

Transform your conversations into powerful workflows by connecting to databases, APIs, file systems, and more. Experience the freedom of AI that truly understands and interacts with your world.

[![][back-to-top]](#readme-top)

![][image-feat-mcp-market]

### üè™ MCP Marketplace

**Discover, Connect, Extend**

Browse a growing library of MCP plugins to expand your AI&#039;s capabilities and streamline your workflows effortlessly. Visit [lobehub.com/mcp](https://lobehub.com/mcp) to explore the MCP Marketplace, which offers a curated collection of integrations that enhance your AI&#039;s ability to work with various tools and services.

From productivity tools to development environments, discover new ways to extend your AI&#039;s reach and effectiveness. Connect with the community and find the perfect plugins for your specific needs.

[![][back-to-top]](#readme-top)

![][image-feat-desktop]

### üñ•Ô∏è Desktop App

**Peak Performance, Zero Distractions**

Get the full LobeChat experience without browser limitations‚Äîcomprehensive, focused, and always ready to go. Our desktop application provides a dedicated environment for your AI interactions, ensuring optimal performance and minimal distractions.

Experience faster response times, better resource management, and a more stable connection to your AI assistant. The desktop app is designed for users who demand the best performance from their AI tools.

[![][back-to-top]](#readme-top)

![][image-feat-web-search]

### üåê Smart Internet Search

**Online Knowledge On Demand**

With real-time internet access, your AI keeps up with the world‚Äînews, data, trends, and more. Stay informed and get the most current information available, enabling your AI to provide accurate and up-to-date responses.

Access live information, verify facts, and explore current events without leaving your conversation. Your AI becomes a gateway to the world&#039;s knowledge, always current and comprehensive.

[![][back-to-top]](#readme-top)

[![][image-feat-cot]][docs-feat-cot]

### [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeChat. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [üìò LobeChat Knowledge Base Launch ‚Äî From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

- **[OpenAI](https://lobechat.com/discover/provider/openai)**: OpenAI is a global leader in artificial intelligence research, with models like the GPT series pushing the frontiers of natural language processing. OpenAI is committed to transforming multiple industries through innovative and efficient AI solutions. Their products demonstrate significant performance and cost-effectiveness, widely used in research, business, and innovative applications.
- **[Ollama](https://lobechat.com/discover/provider/ollama)**: Ollama provides models that cover a wide range of fields, including code generation, mathematical operations, multilingual processing, and conversational interaction, catering to diverse enterprise-level and localized deployment needs.
- **[Anthropic](https://lobechat.com/discover/provider/anthropic)**: Anthropic is a company focused on AI research and development, offering a range of advanced language models such as Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Opus, and Claude 3 Haiku. These models achieve an ideal balance between intelligence, speed, and cost, suitable for various applications from enterprise workloads to rapid-response scenarios. Claude 3.5 Sonnet, as their latest model, has excelled in multiple evaluations while maintaining a high cost-performance ratio.
- **[Bedrock](https://lobechat.com/discover/provider/bedrock)**: Bedrock is a service provided by Amazon AWS, focusing on delivering advanced AI language and visual models for enterprises. Its model family includes Anthropic&#039;s Claude series, Meta&#039;s Llama 3.1 series, and more, offering a range of options from lightweight to high-performance, supporting tasks such as text generation, conversation, and image processing for businesses of varying scales and needs.
- **[Google](https://lobechat.com/discover/provider/google)**: Google&#039;s Gemini series represents its most advanced, versatile AI models, developed by Google DeepMind, designed for multimodal capabilities, supporting seamless understanding and processing of text, code, images, audio, and video. Suitable for various environments from data centers to mobile devices, it significantly enhances the efficiency and applicability of AI models.
- **[DeepSeek](https://lobechat.com/discover/provider/deepseek)**: DeepSeek is a company focused on AI technology research and application, with its latest model DeepSeek-V2.5 integrating general dialogue and code processing capabilities, achieving significant improvements in human preference alignment, writing tasks, and instruction following.
- **[Moonshot](https://lobechat.com/discover/provider/moonshot)**: Moonshot is an open-source platform launched by Beijing Dark Side Technology Co., Ltd., providing various natural language processing models with a wide range of applications, including but not limited to content creation, academic research, intelligent recommendations, and medical diagnosis, supporting long text processing and complex generation tasks.
- **[OpenRouter](https://lobechat.com/discover/provider/openrouter)**: OpenRouter is a service platform providing access to various cutting-edge large model interfaces, supporting OpenAI, Anthropic, LLaMA, and more, suitable for diverse development and application needs. Users can flexibly choose the optimal model and pricing based on their requirements, enhancing the AI experience.
- **[HuggingFace](https://lobechat.com/discover/provider/huggingface)**: The HuggingFace Inference API provides a fast and free way for you to explore thousands of models for various tasks. Whether you are prototyping for a new application or experimenting with the capabilities of machine learning, this API gives you instant access to high-performance models across multiple domains.
- **[Cloudflare Workers AI](https://lobechat.com/discover/provider/cloudflare)**: Run serverless GPU-powered machine learning models on Cloudflare&#039;s global network.

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+32)&lt;/kbd&gt;&lt;/summary&gt;

- **[GitHub](https://lobechat.com/discover/provider/github)**: With GitHub Models, developers can become AI engineers and leverage the industry&#039;s leading AI models.
- **[Novita](https://lobechat.com/discover/provider/novita)**: Novita AI is a platform providing a variety of large language models and AI image generation API services, flexible, reliable, and cost-effective. It supports the latest open-source models like Llama3 and Mistral, offering a comprehensive, user-friendly, and auto-scaling API solution for generative AI application development, suitable for the rapid growth of AI startups.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[302.AI](https://lobechat.com/discover/provider/ai302)**: 302.AI is an on-demand AI application platform offering the most comprehensive AI APIs and online AI applications available on the market.
- **[Together AI](https://lobechat.com/discover/provider/togetherai)**: Together AI is dedicated to achieving leading performance through innovative AI models, offering extensive customization capabilities, including rapid scaling support and intuitive deployment processes to meet various enterprise needs.
- **[Fireworks AI](https://lobechat.com/discover/provider/fireworksai)**: Fireworks AI is a leading provider of advanced language model services, focusing on functional calling and multimodal processing. Its latest model, Firefunction V2, is based on Llama-3, optimized for function calling, conversation, and instruction following. The visual language model FireLLaVA-13B supports mixed input of images and text. Other notable models include the Llama series and Mixtral series, providing efficient multilingual instruction following and generation support.
- **[Groq](https://lobechat.com/discover/provider/groq)**: Groq&#039;s LPU inference engine has excelled in the latest independent large language model (LLM) benchmarks, redefining the standards for AI solutions with its remarkable speed and efficiency. Groq represents instant inference speed, demonstrating strong performance in cloud-based deployments.
- **[Perplexity](https://lobechat.com/discover/provider/perplexity)**: Perplexity is a leading provider of conversational generation models, offering various advanced Llama 3.1 models that support both online and offline applications, particularly suited for complex natural language processing tasks.
- **[Mistral](https://lobechat.com/discover/provider/mistral)**: Mistral provides advanced general, specialized, and research models widely used in complex reasoning, multilingual tasks, and code generation. Through functional calling interfaces, users can integrate custom functionalities for specific applications.
- **[ModelScope](https://lobechat.com/discover/provider/modelscope)**: ModelScope is a model-as-a-service platform launched by Alibaba Cloud, offering a wide range of AI models and inference services.
- **[Ai21Labs](https://lobechat.com/discover/provider/ai21)**: AI21 Labs builds foundational models and AI systems for enterprises, accelerating the application of generative AI in production.
- **[Upstage](https://lobechat.com/discover/provider/upstage)**: Upstage focuses on developing AI models for various business needs, including Solar LLM and document AI, aiming to achieve artificial general intelligence (AGI) for work. It allows for the creation of simple conversational agents through Chat API and supports functional calling, translation, embedding, and domain-specific applications.
- **[xAI (Grok)](https://lobechat.com/discover/provider/xai)**: xAI is a company dedicated to building artificial intelligence to accelerate human scientific discovery. Our mission is to advance our collective understanding of the universe.
- **[Aliyun Bailian](https://lobechat.com/discover/provider/qwen)**: Tongyi Qianwen is a large-scale language model independently developed by Alibaba Cloud, featuring strong natural language understanding and generation capabilities. It can answer various questions, create written content, express opinions, and write code, playing a role in multiple fields.
- **[Wenxin](https://lobechat.com/discover/provider/wenxin)**: An enterprise-level one-stop platform for large model and AI-native application development and services, providing the most comprehensive and user-friendly toolchain for the entire pr

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[TibixDev/winboat]]></title>
            <link>https://github.com/TibixDev/winboat</link>
            <guid>https://github.com/TibixDev/winboat</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[Run Windows apps on üêß Linux with ‚ú® seamless integration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/TibixDev/winboat">TibixDev/winboat</a></h1>
            <p>Run Windows apps on üêß Linux with ‚ú® seamless integration</p>
            <p>Language: TypeScript</p>
            <p>Stars: 10,556</p>
            <p>Forks: 269</p>
            <p>Stars today: 616 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;left&quot;&gt;
  &lt;table&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;gh-assets/winboat_logo.svg&quot; alt=&quot;WinBoat Logo&quot; width=&quot;150&quot;&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;h1 style=&quot;color: #7C86FF; margin: 0; font-size: 32px;&quot;&gt;WinBoat&lt;/h1&gt;
        &lt;p style=&quot;color: oklch(90% 0 0); font-size: 14px; margin: 5px 0;&quot;&gt;Windows for Penguins.&lt;br&gt;
        Run Windows apps on üêß Linux with ‚ú® seamless integration&lt;/p&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

## Screenshots
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;gh-assets/features/feat_dash.png&quot; alt=&quot;WinBoat Dashboard&quot; width=&quot;45%&quot;&gt;
  &lt;img src=&quot;gh-assets/features/feat_apps.png&quot; alt=&quot;WinBoat Apps&quot; width=&quot;45%&quot;&gt;
  &lt;img src=&quot;gh-assets/features/feat_native.png&quot; alt=&quot;Native Windows&quot; width=&quot;45%&quot;&gt;
&lt;/div&gt;

## ‚ö†Ô∏è Work in Progress ‚ö†Ô∏è
WinBoat is currently in beta, so expect to occasionally run into hiccups and bugs. You should be comfortable with some level of troubleshooting if you decide to try it, however we encourage you to give it a shot anyway.

## Features
- **üé® Elegant Interface**: Sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience
- **üì¶ Automated Installs**: Simple installation process through our interface - pick your preferences &amp; specs and let us handle the rest
- **üöÄ Run Any App**: If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications as native OS-level windows in your Linux environment
- **üñ•Ô∏è Full Windows Desktop**: Access the complete Windows desktop experience when you need it, or run individual apps seamlessly integrated into your Linux workflow
- **üìÅ Filesystem Integration**: Your home directory is mounted in Windows, allowing easy file sharing between the two systems without any hassle
- **‚ú® And many more**: Smartcard passthrough, resource monitoring, and more features being added regularly

## How Does It Work?
WinBoat is an Electron app which allows you to run Windows apps on Linux using a containerized approach. Windows runs as a VM inside a Docker container, we communicate with it using the [WinBoat Guest Server](https://github.com/TibixDev/winboat/tree/main/guest_server) to retrieve data we need from Windows. For compositing applications as native OS-level windows, we use FreeRDP together with Windows&#039;s RemoteApp protocol.

## Prerequisites
Before running WinBoat, ensure your system meets the following requirements:

- **RAM**: At least 4 GB of RAM
- **CPU**: At least 2 CPU threads  
- **Storage**: At least 32 GB free space on the drive your selected install folder corresponds to
- **Virtualization**: KVM enabled in BIOS/UEFI
  - [How to enable virtualization](https://duckduckgo.com/?t=h_&amp;q=how+to+enable+virtualization+in+%3Cmotherboard+brand%3E+bios&amp;ia=web)
- **Docker**: Required for containerization
  - [Installation Guide](https://docs.docker.com/engine/install/)
  - **‚ö†Ô∏è NOTE:** Docker Desktop is **not** supported, you will run into issues if you use it
- **Docker Compose v2**: Required for compatibility with docker-compose.yml files
  - [Installation Guide](https://docs.docker.com/compose/install/#plugin-linux-only)
- **Docker User Group**: Add your user to the `docker` group
  - [Setup Instructions](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user)
- **FreeRDP**: Required for remote desktop connection (Please make sure you have **Version 3.x.x** with sound support included)
  - [Installation Guide](https://github.com/FreeRDP/FreeRDP/wiki/PreBuilds)
- [OPTIONAL] **Kernel Modules**: The `iptables` / `nftables` and `iptable_nat` kernel modules can be loaded for network autodiscovery and better shared filesystem performance, but this is not obligatory in newer versions of WinBoat
  - [Module loading instructions](https://rentry.org/rmfq2e5e)

## Downloading
You can download the latest Linux builds under the [Releases](https://github.com/TibixDev/winboat/releases) tab. We currently offer four variants:
- **AppImage:** A popular &amp; portable app format which should run fine on most distributions
- **Unpacked:** The raw unpacked files, simply run the executable (`linux-unpacked/winboat`)
- **.deb:** The intended format for Debian based distributions
- **.rpm:** The intended format for Fedora based distributions

## Known Issues About Container Runtimes
- Podman is **unsupported** for now
- Docker Desktop is **unsupported** for now
- Distros that emulate Docker through a Podman socket are **unsupported**
- Any rootless containerization solution is currently **unsupported**

## Building WinBoat
- For building you need to have NodeJS and Go installed on your system
- Clone the repo (`git clone https://github.com/TibixDev/WinBoat`)
- Install the dependencies (`npm i`)
- Build the app and the guest server using `npm run build:linux-gs`
- You can now find the built app under `dist` with an AppImage and an Unpacked variant

## Running WinBoat in development mode
- Make sure you meet the [prerequisites](#prerequisites)
- Additionally, for development you need to have NodeJS and Go installed on your system
- Clone the repo (`git clone https://github.com/TibixDev/WinBoat`)
- Install the dependencies (`npm i`)
- Build the guest server (`npm run build-guest-server`)
- Run the app (`npm run dev`)

## Contributing
Contributions are welcome! Whether it&#039;s bug fixes, feature improvements, or documentation updates, we appreciate your help making WinBoat better.

**Please note**: We maintain a focus on technical contributions only. Pull requests containing political/sexual content, or other sensitive/controversial topics will not be accepted. Let&#039;s keep things focused on making great software! üöÄ

Feel free to:
- Report bugs and issues
- Submit feature requests  
- Contribute code improvements
- Help with documentation
- Share feedback and suggestions

Check out our issues page to get started, or feel free to open a new issue if you&#039;ve found something that needs attention.

## License
WinBoat is licensed under the [MIT](https://github.com/TibixDev/winboat/blob/main/LICENSE) license

## Inspiration / Alternatives
These past few years some cool projects have surfaced with similar concepts, some of which we&#039;ve also taken inspirations from.\
They&#039;re awesome and you should check them out:
- [WinApps](https://github.com/winapps-org/winapps)
- [Cassowary](https://github.com/casualsnek/cassowary)
- [dockur/windows](https://github.com/dockur/windows) (üåü Also used in WinBoat)

## Socials &amp; Contact
- [![Website](https://img.shields.io/badge/Website-winboat.app-blue?style=flat&amp;logo=googlechrome&amp;logoColor=white)](https://www.winboat.app/)
- [![Twitter](https://img.shields.io/badge/Twitter-@winboat__app-1DA1F2?style=flat&amp;logo=x&amp;logoColor=white)](https://x.com/winboat_app)
- [![Mastodon](https://img.shields.io/badge/Mastodon-@winboat-6364FF?style=flat&amp;logo=mastodon&amp;logoColor=white)](https://fosstodon.org/@winboat)
- [![Bluesky](https://img.shields.io/badge/Bluesky-winboat.app-00A8E8?style=flat&amp;logo=bluesky&amp;logoColor=white)](http://bsky.app/profile/winboat.app)
- [![Discord](https://img.shields.io/badge/Discord-Join_Community-5865F2?style=flat&amp;logo=discord&amp;logoColor=white)](http://discord.gg/MEwmpWm4tN)
- [![Email](https://img.shields.io/badge/Email-staff@winboat.app-D14836?style=flat&amp;logo=gmail&amp;logoColor=white)](mailto:staff@winboat.app)
- [![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/TibixDev/winboat)

## Star History
&lt;a href=&quot;https://www.star-history.com/#tibixdev/winboat&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=tibixdev/winboat&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=tibixdev/winboat&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=tibixdev/winboat&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[langgenius/dify]]></title>
            <link>https://github.com/langgenius/dify</link>
            <guid>https://github.com/langgenius/dify</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[Production-ready platform for agentic workflow development.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langgenius/dify">langgenius/dify</a></h1>
            <p>Production-ready platform for agentic workflow development.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 116,253</p>
            <p>Forks: 17,934</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>![cover-v5-optimized](./images/GitHub_README_if.png)

&lt;p align=&quot;center&quot;&gt;
  üìå &lt;a href=&quot;https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast&quot;&gt;Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cloud.dify.ai&quot;&gt;Dify Cloud&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted&quot;&gt;Self-hosting&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://docs.dify.ai&quot;&gt;Documentation&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://dify.ai/pricing&quot;&gt;Dify edition overview&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://dify.ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Product-F04438&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://dify.ai/pricing&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/free-pricing?logo=free&amp;color=%20%23155EEF&amp;label=pricing&amp;labelColor=%20%23528bff&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/FngNHpbcY7&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1082486657678311454?logo=discord&amp;labelColor=%20%235462eb&amp;logoColor=%20%23f5f5f5&amp;color=%20%235462eb&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://reddit.com/r/difyai&quot; target=&quot;_blank&quot;&gt;  
        &lt;img src=&quot;https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&amp;logo=reddit&amp;label=r%2Fdifyai&amp;labelColor=white&quot;
            alt=&quot;join Reddit&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=dify_ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/dify_ai?logo=X&amp;color=%20%23f5f5f5&quot;
            alt=&quot;follow on X(Twitter)&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/langgenius/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;logoColor=fff&quot;
            alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/u/langgenius&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&amp;color=%20%23f79009&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/graphs/commit-activity&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Commits last month&quot; src=&quot;https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&amp;color=%20%2312b76a&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Issues closed&quot; src=&quot;https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&amp;label=issues%20closed&amp;labelColor=%20%237d89b0&amp;color=%20%235d6b98&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/discussions/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Discussion posts&quot; src=&quot;https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&amp;color=%20%237a5af8&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/zh-TW/README.md&quot;&gt;&lt;img alt=&quot;ÁπÅÈ´î‰∏≠ÊñáÊñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁπÅÈ´î‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/zh-CN/README.md&quot;&gt;&lt;img alt=&quot;ÁÆÄ‰Ωì‰∏≠ÊñáÊñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/ja-JP/README.md&quot;&gt;&lt;img alt=&quot;Êó•Êú¨Ë™û„ÅÆREADME&quot; src=&quot;https://img.shields.io/badge/Êó•Êú¨Ë™û-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/es-ES/README.md&quot;&gt;&lt;img alt=&quot;README en Espa√±ol&quot; src=&quot;https://img.shields.io/badge/Espa√±ol-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/fr-FR/README.md&quot;&gt;&lt;img alt=&quot;README en Fran√ßais&quot; src=&quot;https://img.shields.io/badge/Fran√ßais-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/tlh/README.md&quot;&gt;&lt;img alt=&quot;README tlhIngan Hol&quot; src=&quot;https://img.shields.io/badge/Klingon-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/ko-KR/README.md&quot;&gt;&lt;img alt=&quot;README in Korean&quot; src=&quot;https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/ar-SA/README.md&quot;&gt;&lt;img alt=&quot;README ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&quot; src=&quot;https://img.shields.io/badge/ÿßŸÑÿπÿ±ÿ®Ÿäÿ©-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/tr-TR/README.md&quot;&gt;&lt;img alt=&quot;T√ºrk√ße README&quot; src=&quot;https://img.shields.io/badge/T√ºrk√ße-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/vi-VN/README.md&quot;&gt;&lt;img alt=&quot;README Ti·∫øng Vi·ªát&quot; src=&quot;https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/de-DE/README.md&quot;&gt;&lt;img alt=&quot;README in Deutsch&quot; src=&quot;https://img.shields.io/badge/German-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/bn-BD/README.md&quot;&gt;&lt;img alt=&quot;README in ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&quot; src=&quot;https://img.shields.io/badge/‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ-d9d9d9&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Dify is an open-source platform for developing LLM applications. Its intuitive interface combines agentic AI workflows, RAG pipelines, agent capabilities, model management, observability features, and more‚Äîallowing you to quickly move from prototype to production.

## Quick start

&gt; Before installing Dify, make sure your machine meets the following minimum system requirements:
&gt;
&gt; - CPU &gt;= 2 Core
&gt; - RAM &gt;= 4 GiB

&lt;/br&gt;

The easiest way to start the Dify server is through [Docker Compose](docker/docker-compose.yaml). Before running Dify with the following commands, make sure that [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) are installed on your machine:

```bash
cd dify
cd docker
cp .env.example .env
docker compose up -d
```

After running, you can access the Dify dashboard in your browser at [http://localhost/install](http://localhost/install) and start the initialization process.

#### Seeking help

Please refer to our [FAQ](https://docs.dify.ai/getting-started/install-self-hosted/faqs) if you encounter problems setting up Dify. Reach out to [the community and us](#community--contact) if you are still having issues.

&gt; If you&#039;d like to contribute to Dify or do additional development, refer to our [guide to deploying from source code](https://docs.dify.ai/getting-started/install-self-hosted/local-source-code)

## Key features

**1. Workflow**:
Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.

**2. Comprehensive model support**:
Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found [here](https://docs.dify.ai/getting-started/readme/model-providers).

![providers-v5](https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3)

**3. Prompt IDE**:
Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.

**4. RAG Pipeline**:
Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.

**5. Agent capabilities**:
You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALL¬∑E, Stable Diffusion and WolframAlpha.

**6. LLMOps**:
Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.

**7. Backend-as-a-Service**:
All of Dify&#039;s offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.

## Using Dify

- **Cloud &lt;/br&gt;**
  We host a [Dify Cloud](https://dify.ai) service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.

- **Self-hosting Dify Community Edition&lt;/br&gt;**
  Quickly get Dify running in your environment with this [starter guide](#quick-start).
  Use our [documentation](https://docs.dify.ai) for further references and more in-depth instructions.

- **Dify for enterprise / organizations&lt;/br&gt;**
  We provide additional enterprise-centric features. [Log your questions for us through this chatbot](https://udify.app/chat/22L1zSxg6yW1cWQg) or [send us an email](mailto:business@dify.ai?subject=%5BGitHub%5DBusiness%20License%20Inquiry) to discuss enterprise needs. &lt;/br&gt;

  &gt; For startups and small businesses using AWS, check out [Dify Premium on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6) and deploy it to your own AWS VPC with one click. It&#039;s an affordable AMI offering with the option to create apps with custom logo and branding.

## Staying ahead

Star Dify on GitHub and be instantly notified of new releases.

![star-us](https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4)

## Advanced Setup

If you need to customize the configuration, please refer to the comments in our [.env.example](docker/.env.example) file and update the corresponding values in your `.env` file. Additionally, you might need to make adjustments to the `docker-compose.yaml` file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run `docker-compose up -d`. You can find the full list of available environment variables [here](https://docs.dify.ai/getting-started/install-self-hosted/environments).

If you&#039;d like to configure a highly-available setup, there are community-contributed [Helm Charts](https://helm.sh/) and YAML files which allow Dify to be deployed on Kubernetes.

- [Helm Chart by @LeoQuote](https://github.com/douban/charts/tree/master/charts/dify)
- [Helm Chart by @BorisPolonsky](https://github.com/BorisPolonsky/dify-helm)
- [Helm Chart by @magicsong](https://github.com/magicsong/ai-charts)
- [YAML file by @Winson-030](https://github.com/Winson-030/dify-kubernetes)
- [YAML file by @wyy-holding](https://github.com/wyy-holding/dify-k8s)
- [üöÄ NEW! YAML files (Supports Dify v1.6.0) by @Zhoneym](https://github.com/Zhoneym/DifyAI-Kubernetes)

#### Using Terraform for Deployment

Deploy Dify to Cloud Platform with a single click using [terraform](https://www.terraform.io/)

##### Azure Global

- [Azure Terraform by @nikawang](https://github.com/nikawang/dify-azure-terraform)

##### Google Cloud

- [Google Cloud Terraform by @sotazum](https://github.com/DeNA/dify-google-cloud-terraform)

#### Using AWS CDK for Deployment

Deploy Dify to AWS with [CDK](https://aws.amazon.com/cdk/)

##### AWS

- [AWS CDK by @KevinZhao (EKS based)](https://github.com/aws-samples/solution-for-deploying-dify-on-aws)
- [AWS CDK by @tmokmss (ECS based)](https://github.com/aws-samples/dify-self-hosted-on-aws)

#### Using Alibaba Cloud Computing Nest

Quickly deploy Dify to Alibaba cloud with [Alibaba Cloud Computing Nest](https://computenest.console.aliyun.com/service/instance/create/default?type=user&amp;ServiceName=Dify%E7%A4%BE%E5%8C%BA%E7%89%88)

#### Using Alibaba Cloud Data Management

One-Click deploy Dify to Alibaba Cloud with [Alibaba Cloud Data Management](https://www.alibabacloud.com/help/en/dms/dify-in-invitational-preview/)

#### Deploy to AKS with Azure Devops Pipeline

One-Click deploy Dify to AKS with [Azure Devops Pipeline Helm Chart by @LeoZhang](https://github.com/Ruiruiz30/Dify-helm-chart-AKS)

## Contributing

For those who&#039;d like to contribute code, see our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.

&gt; We are looking for contributors to help translate Dify into languages other than Mandarin or English. If you are interested in helping, please see the [i18n README](https://github.com/langgenius/dify/blob/main/web/i18n-config/README.md) for more information, and leave us a comment in the `global-users` channel of our [Discord Community Server](https://discord.gg/8Tpq4AcN9c).

## Community &amp; contact

- [GitHub Discussion](https://github.com/langgenius/dify/discussions). Best for: sharing feedback and asking questions.
- [GitHub Issues](https://github.com/langgenius/dify/issues). Best for: bugs you encounter using Dify.AI, and feature proposals. See our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
- [Discord](https://discord.gg/FngNHpbcY7). Best for: sharing your applications and hanging out with the community.
- [X(Twitter)](https://twitter.com/dify_ai). Best for: sharing your applications and hanging out with the community.

**Contributors**

&lt;a href=&quot;https://github.com/langgenius/dify/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=langgenius/dify&quot; /&gt;
&lt;/a&gt;

## Star history

[![Star History Chart](https://api.star-history.com/svg?repos=langgenius/dify&amp;type=Date)](https://star-history.com/#langgenius/dify&amp;Date)

## Security disclosure

To protect your privacy, please avoid posting security issues on GitHub. Instead, report issues to security@dify.ai, and our team will respond with detailed answer.

## License

This repository is licensed under the [Dify Open Source License](LICENSE), based on Apache 2.0 with additional conditions.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[bytedance/flowgram.ai]]></title>
            <link>https://github.com/bytedance/flowgram.ai</link>
            <guid>https://github.com/bytedance/flowgram.ai</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[FlowGram is a node-based flow building engine that helps developers quickly create workflows in either fixed layout or free connection layout modes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytedance/flowgram.ai">bytedance/flowgram.ai</a></h1>
            <p>FlowGram is a node-based flow building engine that helps developers quickly create workflows in either fixed layout or free connection layout modes</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,957</p>
            <p>Forks: 602</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># FlowGram.AI

FlowGram is a node-based flow building engine that helps developers quickly create workflows in either fixed layout or
free connection layout modes. It provides a set of interaction best practices and is particularly suitable for visual
workflows with clear inputs and outputs.

In the current AI boom, we are also focusing on how to empower workflows with AI capabilities, hence the AI suffix in
our name.

&lt;div align=&quot;center&quot;&gt;

[![License](https://img.shields.io/github/license/bytedance/flowgram.ai)](https://github.com/bytedance/flowgram.ai/blob/main/LICENSE)
[![@flowgram.ai/editor](https://img.shields.io/npm/dm/%40flowgram.ai%2Fcore
)](https://www.npmjs.com/package/@flowgram.ai/editor)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/bytedance/flowgram.ai)
[![ÊéòÈáë](https://img.shields.io/badge/ÊéòÈáë-FFFFFF?logo=juejin&amp;logoColor=%23007FFF)](https://juejin.cn/column/7479814468601315362)


[![](https://trendshift.io/api/badge/repositories/13877)](https://trendshift.io/repositories/13877)

&lt;/div&gt;

## üìñ Documentation

- [Official Documentation](https://flowgram.ai/)
- [Contributing Guidelines](https://github.com/bytedance/flowgram.ai/blob/main/CONTRIBUTING.md)

## üì¶ Packages

| Package                                                                   | Description         | Version                                                                                                                                     |
|---------------------------------------------------------------------------|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------|
| [@flowgram.ai/create-app](./apps/create-app)                              | App Creator         | [![npm](https://img.shields.io/npm/v/@flowgram.ai/create-app.svg)](https://www.npmjs.com/package/@flowgram.ai/create-app)                   |
| [@flowgram.ai/fixed-layout-editor](./packages/client/fixed-layout-editor) | Fixed Layout Editor | [![npm](https://img.shields.io/npm/v/@flowgram.ai/fixed-layout-editor.svg)](https://www.npmjs.com/package/@flowgram.ai/fixed-layout-editor) |
| [@flowgram.ai/free-layout-editor](./packages/client/free-layout-editor)   | Free Layout Editor  | [![npm](https://img.shields.io/npm/v/@flowgram.ai/free-layout-editor.svg)](https://www.npmjs.com/package/@flowgram.ai/free-layout-editor)   |

## üéÆ Examples

&lt;div&gt;
  &lt;p&gt;
    &lt;a href=&quot;https://flowgram.ai/examples/fixed-layout/fixed-feature-overview.html&quot;&gt;
        Fixed Layout
    &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
    Fixed layout where nodes can be dragged to specified positions, with support for compound nodes like branches and loops.
  &lt;/p&gt;
  &lt;p&gt;
    &lt;img src=&quot;./apps/docs/src/public/fixed-layout/fixed-layout-demo.gif&quot;/&gt;
  &lt;/p&gt;
  &lt;/div&gt;
  &lt;div&gt;
  &lt;p&gt;
    &lt;a href=&quot;https://flowgram.ai/examples/free-layout/free-feature-overview.html&quot;&gt;
      Free Layout
    &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
      Free layout where nodes can be placed anywhere and connected using free-form lines.
  &lt;/p&gt;
  &lt;p&gt;
    &lt;img src=&quot;./apps/docs/src/public/free-layout/free-layout-demo.gif&quot;/&gt;
  &lt;/p&gt;
&lt;/div&gt;

## üöÄ Getting Started

```sh
# create demo
npx @flowgram.ai/create-app@latest

# in PowerShell
npx &quot;@flowgram.ai/create-app@latest&quot;

# select demo
- fixed-layout # full-feature overview
- free-layout # full-feature overview
- fixed-layout-simple # basic usage
- free-layout-simple # basic usage
```

## üî® Development

1. **Install Node.js 18+**

``` bash
nvm install lts/hydrogen
nvm alias default lts/hydrogen # set default node version
nvm use lts/hydrogen
```

2. **Clone the repository**

``` bash
git clone git@github.com:bytedance/flowgram.ai.git
```

3. **Install required global dependencies**

``` bash
npm i -g pnpm@10.6.5 @microsoft/rush@5.150.0
```

4. **Install project dependencies**

``` bash
rush install
```

5. **Build the project**

``` bash
rush build
```

6. **Run docs or demo**

``` bash
rush dev:docs # docs
rush dev:demo-fixed-layout
rush dev:demo-free-layout
```

After that, you can start to develop projects inside this repository.

Enjoy it!

## üåü Contributors

[![FlowGram.AI Contributors](https://contrib.rocks/image?repo=bytedance/flowgram.ai)](https://github.com/bytedance/flowgram.ai/graphs/contributors)

## üåü Adoption

- [Coze Studio](https://github.com/coze-dev/coze-studio) is an all-in-one AI agent development tool. Providing the latest large models and tools, various development modes and frameworks, Coze Studio offers the most convenient AI agent development environment, from development to deployment.
- [NNDeploy](https://github.com/NNDeploy/nndeploy) is a workflow-based multi-platform ai deployment tool.
- [Certimate](https://github.com/certimate-go/certimate)  is an open-source SSL certificate management tool that helps you automatically apply for and deploy SSL certificates with a visual workflow. It is one of the ACME client options listed in the official documentation of Let&#039;s Encrypt.

## üåü Contact us

- Issues: [Issues](https://github.com/bytedance/flowgram.ai/issues)
- Lark: Scan the QR code below with [Register Feishu](https://www.feishu.cn/en/) to join our FlowGram user group.

&lt;img src=&quot;./apps/docs/src/public/lark-group.png&quot; width=&quot;200&quot;/&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[supermemoryai/supermemory]]></title>
            <link>https://github.com/supermemoryai/supermemory</link>
            <guid>https://github.com/supermemoryai/supermemory</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[Memory engine and app that is extremely fast, scalable. The Memory API for the AI era.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/supermemoryai/supermemory">supermemoryai/supermemory</a></h1>
            <p>Memory engine and app that is extremely fast, scalable. The Memory API for the AI era.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 11,918</p>
            <p>Forks: 1,245</p>
            <p>Stars today: 245 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; style=&quot;padding-bottom:20px;padding-top:20px&quot;&gt;
  &lt;img src=&quot;logo.svg&quot; alt=&quot;supermemory Logo&quot; width=&quot;400&quot; /&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/landing-page.jpeg&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

## Features

### Core Functionality

- **[Add Memories from Any Content](#add-memory)**: Easily add memories from URLs, PDFs, and plain text‚Äîjust paste, upload, or link.
- **[Chat with Your Memories](#chat-memories)**: Converse with your stored content using natural language chat.
- **[Supermemory MCP Integration](#mcp-integration)**: Seamlessly connect with all major AI tools (Claude, Cursor, etc.) via Supermemory MCP.

## How do i use this?

Go to [app.supermemory.ai](https://app.supermemory.ai) and sign into with your account

1. &lt;a id=&quot;add-memory&quot;&gt;&lt;/a&gt;Start Adding Memory with your choice of format (Note, Link, File)
&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/add-memory.png&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

2. You can also Connect to your favourite services (Notion, Google Drive, OneDrive)
&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/add-connections.png&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

3. &lt;a id=&quot;chat-memories&quot;&gt;&lt;/a&gt;Once Memories are added, you can chat with Supermemory by clicking on &quot;Open Chat&quot; and retrieve info from your saved memories
&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/chat.png&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

4. &lt;a id=&quot;mcp-integration&quot;&gt;&lt;/a&gt;Add MCP to your AI Tools (by clicking on &quot;Connect to your AI&quot; and select the AI tool you are trying to integrate)
&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/mcp.png&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

## Support

Have questions or feedback? We&#039;re here to help:

- Email: [dhravya@supermemory.com](mailto:dhravya@supermemory.com)
- Documentation: [docs.supermemory.ai](https://docs.supermemory.ai)

## Contributing

We welcome contributions from developers of all skill levels! Whether you&#039;re fixing bugs, adding features, or improving documentation, your help makes supermemory better for everyone.

### Quick Start for Contributors

1. **Fork and clone** the repository
2. **Install dependencies** with `bun install`
3. **Set up your environment** by copying `.env.example` to `.env.local`
4. **Start developing** with `bun run dev`

For detailed guidelines, development setup, coding standards, and the complete contribution workflow, please see our [**Contributing Guide**](CONTRIBUTING.md).

### Ways to Contribute

- üêõ **Bug fixes** - Help us squash those pesky issues
- ‚ú® **New features** - Add functionality that users will love
- üé® **UI/UX improvements** - Make the interface more intuitive
- ‚ö° **Performance optimizations** - Help us make supermemory faster

Check out our [Issues](https://github.com/supermemoryai/supermemory/issues) page for `good first issue` and `help wanted` labels to get started!

## Updates &amp; Roadmap

Stay up to date with the latest improvements:

- [Changelog](https://docs.supermemory.ai/changelog/overview)
- [X](https://x.com/supermemoryai).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[xyflow/xyflow]]></title>
            <link>https://github.com/xyflow/xyflow</link>
            <guid>https://github.com/xyflow/xyflow</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[React Flow |¬†Svelte Flow - Powerful open source libraries for building node-based UIs with React (https://reactflow.dev) or Svelte (https://svelteflow.dev). Ready out-of-the-box and infinitely customizable.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xyflow/xyflow">xyflow/xyflow</a></h1>
            <p>React Flow |¬†Svelte Flow - Powerful open source libraries for building node-based UIs with React (https://reactflow.dev) or Svelte (https://svelteflow.dev). Ready out-of-the-box and infinitely customizable.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 32,626</p>
            <p>Forks: 2,140</p>
            <p>Stars today: 38 stars today</p>
            <h2>README</h2><pre>![xyflow-header](https://user-images.githubusercontent.com/2857535/279643999-ffda9f91-6b6d-447d-82be-fcbd6103edb6.svg#gh-light-mode-only)
![xyflow-header-dark](https://user-images.githubusercontent.com/2857535/279644026-a01c231c-6c6e-4b41-96e0-a85c75c9acee.svg#gh-dark-mode-only)

&lt;div align=&quot;center&quot;&gt;

![GitHub License MIT](https://img.shields.io/github/license/wbkd/react-flow?color=%23ff0072)
![npm downloads](https://img.shields.io/npm/dt/reactflow?color=%23FF0072&amp;label=React%20Flow%20downloads)
![npm downloads](https://img.shields.io/npm/dt/@xyflow/svelte?color=%23FF3E00&amp;label=Svelte%20Flow%20downloads)

Powerful open source libraries for building node-based UIs with React or Svelte. Ready out-of-the-box and infinitely customizable.

[React Flow](https://reactflow.dev/) ¬∑ [Svelte Flow](https://svelteflow.dev/) ¬∑ [React Flow Pro](https://reactflow.dev/pro) ¬∑ [Discord](https://discord.gg/Bqt6xrs)
&lt;/div&gt;

---

## The xyflow mono repo

The xyflow repository is the home of four packages:
* React Flow 12 `@xyflow/react` [packages/react](./packages/react)
* React Flow 11 `reactflow` [v11 branch](https://github.com/xyflow/xyflow/tree/v11)
* Svelte Flow `@xyflow/svelte` [packages/svelte](./packages/svelte)
* Shared helper library `@xyflow/system` [packages/system](./packages/system)

## Commercial usage

**Are you using React Flow or Svelte Flow for a personal project?** Great! No sponsorship needed, you can support us by reporting any bugs you find, sending us screenshots of your projects, and starring us on Github üåü

**Are you using React Flow or Svelte Flow at your organization and making money from it?** Awesome! We rely on your support to keep our libraries developed and maintained under an MIT License, just how we like it. For React Flow you can do that on the [React Flow Pro website](https://reactflow.dev/pro) and for both of our libraries you can do it through [Github Sponsors](https://github.com/sponsors/xyflow).

## Getting started

The best way to get started is to check out the [React Flow](https://reactflow.dev/learn) or [Svelte Flow](https://svelteflow.dev/learn) learn section. However if you want to get a sneak peek of how to install and use the libraries you can see it here: 

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;React Flow&lt;/strong&gt; basic usage&lt;/summary&gt;

  ### Installation
  
  ```sh
npm install @xyflow/react
  ```

  ### Basic usage
  ```jsx
import { useCallback } from &#039;react&#039;;
import {
  ReactFlow,
  MiniMap,
  Controls,
  Background,
  useNodesState,
  useEdgesState,
  addEdge,
} from &#039;@xyflow/react&#039;;

import &#039;@xyflow/react/dist/style.css&#039;;

const initialNodes = [
  { id: &#039;1&#039;, position: { x: 0, y: 0 }, data: { label: &#039;1&#039; } },
  { id: &#039;2&#039;, position: { x: 0, y: 100 }, data: { label: &#039;2&#039; } },
];

const initialEdges = [{ id: &#039;e1-2&#039;, source: &#039;1&#039;, target: &#039;2&#039; }];

function Flow() {
  const [nodes, setNodes, onNodesChange] = useNodesState(initialNodes);
  const [edges, setEdges, onEdgesChange] = useEdgesState(initialEdges);

  const onConnect = useCallback((params) =&gt; setEdges((eds) =&gt; addEdge(params, eds)), [setEdges]);

  return (
    &lt;ReactFlow
      nodes={nodes}
      edges={edges}
      onNodesChange={onNodesChange}
      onEdgesChange={onEdgesChange}
      onConnect={onConnect}
    &gt;
      &lt;MiniMap /&gt;
      &lt;Controls /&gt;
      &lt;Background /&gt;
    &lt;/ReactFlow&gt;
  );
}

export default Flow;
```
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Svelte Flow&lt;/strong&gt; basic usage&lt;/summary&gt;

  ### Installation
  
  ```sh
npm install @xyflow/svelte
  ```

  ### Basic usage
  ```svelte
&lt;script lang=&quot;ts&quot;&gt;
  import { writable } from &#039;svelte/store&#039;;
  import {
    SvelteFlow,
    Controls,
    Background,
    BackgroundVariant,
    MiniMap,
  } from &#039;@xyflow/svelte&#039;;

  import &#039;@xyflow/svelte/dist/style.css&#039;
  
  const nodes = writable([
    {
      id: &#039;1&#039;,
      type: &#039;input&#039;,
      data: { label: &#039;Input Node&#039; },
      position: { x: 0, y: 0 }
    },
    {
      id: &#039;2&#039;,
      type: &#039;custom&#039;,
      data: { label: &#039;Node&#039; },
      position: { x: 0, y: 150 }
    }
  ]);

  const edges = writable([
    {
      id: &#039;1-2&#039;,
      type: &#039;default&#039;,
      source: &#039;1&#039;,
      target: &#039;2&#039;,
      label: &#039;Edge Text&#039;
    }
  ]);
&lt;/script&gt;

&lt;SvelteFlow
  {nodes}
  {edges}
  fitView
  on:nodeclick={(event) =&gt; console.log(&#039;on node click&#039;, event)}
&gt;
  &lt;Controls /&gt;
  &lt;Background variant={BackgroundVariant.Dots} /&gt;
  &lt;MiniMap /&gt;
&lt;/SvelteFlow&gt;
```
&lt;/details&gt;

## Releases 

For releasing packages we are using [changesets](https://github.com/changesets/changesets) in combination with the [changeset Github action](https://github.com/changesets/action). The rough idea is:

1. create PRs for new features, updates and fixes (with a changeset if relevant for changelog)
2. merge into main 
3. changset creates a PR that bumps all packages based on the changesets 
4. merge changeset PR if you want to release to Github and npm

## Built by [xyflow](https://xyflow.com)

React Flow and Svelte Flow are maintained by the [xyflow team](https://xyflow.com/about). If you need help or want to talk to us about a collaboration, reach out through our¬†[contact form](https://xyflow.com/contact)¬†or by joining our [Discord Server](https://discord.gg/Bqt6xrs).

## License

React Flow and Svelte Flow are [MIT licensed](./LICENSE).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ZuodaoTech/everyone-can-use-english]]></title>
            <link>https://github.com/ZuodaoTech/everyone-can-use-english</link>
            <guid>https://github.com/ZuodaoTech/everyone-can-use-english</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[‰∫∫‰∫∫ÈÉΩËÉΩÁî®Ëã±ËØ≠]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ZuodaoTech/everyone-can-use-english">ZuodaoTech/everyone-can-use-english</a></h1>
            <p>‰∫∫‰∫∫ÈÉΩËÉΩÁî®Ëã±ËØ≠</p>
            <p>Language: TypeScript</p>
            <p>Stars: 31,373</p>
            <p>Forks: 4,467</p>
            <p>Stars today: 45 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./enjoy/assets/icon.png&quot; alt=&quot;Clash&quot; width=&quot;128&quot; /&gt;
&lt;/div&gt;

&lt;h3 align=&quot;center&quot;&gt;
AI ÊòØÂΩì‰ªä‰∏ñÁïå‰∏äÊúÄÂ•ΩÁöÑÂ§ñËØ≠ËÄÅÂ∏àÔºåEnjoy ÂÅö AI ÊúÄÂ•ΩÁöÑÂä©Êïô„ÄÇ
&lt;/h3&gt;

[![Deploy 1000h website](https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/deploy-1000h.yml/badge.svg)](https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/deploy-1000h.yml)
[![Test Enjoy App](https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/test-enjoy-app.yml/badge.svg)](https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/test-enjoy-app.yml)
[![Release Enjoy App](https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/release-enjoy-app.yml/badge.svg)](https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/release-enjoy-app.yml)
![Latest Version](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fenjoy.bot%2Fapi%2Fconfig%2Fapp_version&amp;query=%24.version&amp;label=Latest&amp;link=https%3A%2F%2F1000h.org%2Fenjoy-app%2Finstall.html)
![Recording Duration](https://img.shields.io/endpoint?url=https%3A%2F%2Fenjoy.bot%2Fapi%2Fbadges%2Frecordings)

---

## ÁΩëÈ°µÁâà

Enjoy ÁΩëÈ°µÁâàÂ∑≤Áªè‰∏äÁ∫øÔºåÂèØËÆøÈóÆ [https://enjoy.bot](https://enjoy.bot) Áõ¥Êé•‰ΩøÁî®„ÄÇ

&lt;div align=&quot;center&quot; style=&quot;display:flex;overflow:auto;gap:10px;&quot;&gt;
  &lt;img src=&quot;./enjoy/snapshots/web-audios.jpg&quot; alt=&quot;Audios&quot; width=&quot;300&quot; /&gt;
  &lt;img src=&quot;./enjoy/snapshots/web-add-audio.jpg&quot; alt=&quot;Add Audio&quot; width=&quot;300&quot; /&gt;
  &lt;img src=&quot;./enjoy/snapshots/web-audio-shadow.jpg&quot; alt=&quot;Shadow&quot; width=&quot;300&quot; /&gt;
  &lt;img src=&quot;./enjoy/snapshots/web-audio-assessment.jpg&quot; alt=&quot;Assessment&quot; width=&quot;300&quot; /&gt;
  &lt;img src=&quot;./enjoy/snapshots/web-new-chat.jpg&quot; alt=&quot;New Chat&quot; width=&quot;300&quot; /&gt;
  &lt;img src=&quot;./enjoy/snapshots/web-chat.jpg&quot; alt=&quot;Chat&quot; width=&quot;300&quot; /&gt;
&lt;/div&gt;

---

## Ê°åÈù¢ÁâàÂÆâË£ÖÂèä‰ΩøÁî®

‰∏ãËΩΩÂèä‰ΩøÁî®Áõ∏ÂÖ≥ËØ¥ÊòéÔºåËØ∑ÂèÇÈòÖ [ÊñáÊ°£](https://1000h.org/enjoy-app/)„ÄÇ

## È¢ÑËßà

&lt;div align=&quot;center&quot; style=&quot;display:flex;overflow:auto;&quot;&gt;
  &lt;img src=&quot;./enjoy/snapshots/home.png&quot; alt=&quot;Home&quot; width=&quot;800&quot; /&gt;

  &lt;img src=&quot;./enjoy/snapshots/shadow.png&quot; alt=&quot;Home&quot; width=&quot;800&quot; /&gt;

  &lt;img src=&quot;./enjoy/snapshots/assessment.png&quot; alt=&quot;Home&quot; width=&quot;800&quot; /&gt;

  &lt;img src=&quot;./enjoy/snapshots/document.png&quot; alt=&quot;Home&quot; width=&quot;800&quot; /&gt;

  &lt;img src=&quot;./enjoy/snapshots/chat.png&quot; alt=&quot;Home&quot; width=&quot;800&quot; /&gt;
&lt;/div&gt;

## Ê°åÈù¢ÁâàÂºÄÂèë

```bash
yarn install
yarn enjoy:start
```

## Áõ∏ÂÖ≥ÈòÖËØª

### ‰∏ÄÂçÉÂ∞èÊó∂Ôºà2024Ôºâ

- [ÁÆÄË¶ÅËØ¥Êòé](https://1000h.org/intro.html)
- [ËÆ≠ÁªÉ‰ªªÂä°](https://1000h.org/training-tasks/kick-off.html)
- [ËØ≠Èü≥Â°ëÈÄ†](https://1000h.org/sounds-of-american-english/0-intro.html)
- [Â§ßËÑëÂÜÖÈÉ®](https://1000h.org/in-the-brain/01-inifinite.html)
- [Ëá™ÊàëËÆ≠ÁªÉ](https://1000h.org/self-training/00-intro.html)

### ‰∫∫‰∫∫ÈÉΩËÉΩÁî®Ëã±ËØ≠Ôºà2010Ôºâ

- [ÁÆÄ‰ªã](./book/README.md)
- [Á¨¨‰∏ÄÁ´†ÔºöËµ∑ÁÇπ](./book/chapter1.md)
- [Á¨¨‰∫åÁ´†ÔºöÂè£ËØ≠](./book/chapter2.md)
- [Á¨¨‰∏âÁ´†ÔºöËØ≠Èü≥](./book/chapter3.md)
- [Á¨¨ÂõõÁ´†ÔºöÊúóËØª](./book/chapter4.md)
- [Á¨¨‰∫îÁ´†ÔºöËØçÂÖ∏](./book/chapter5.md)
- [Á¨¨ÂÖ≠Á´†ÔºöËØ≠Ê≥ï](./book/chapter6.md)
- [Á¨¨‰∏ÉÁ´†ÔºöÁ≤æËØª](./book/chapter7.md)
- [Á¨¨ÂÖ´Á´†ÔºöÂèÆÂò±](./book/chapter8.md)
- [ÂêéËÆ∞](./book/end.md)

## Â∏∏ËßÅÈóÆÈ¢ò

ËØ∑Êü•ËØ¢ [ÊñáÊ°£ FAQ](https://1000h.org/enjoy-app/faq.html)„ÄÇ
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[element-plus/element-plus]]></title>
            <link>https://github.com/element-plus/element-plus</link>
            <guid>https://github.com/element-plus/element-plus</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[üéâ A Vue.js 3 UI Library made by Element team]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/element-plus/element-plus">element-plus/element-plus</a></h1>
            <p>üéâ A Vue.js 3 UI Library made by Element team</p>
            <p>Language: TypeScript</p>
            <p>Stars: 26,643</p>
            <p>Forks: 19,337</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;300px&quot; src=&quot;https://user-images.githubusercontent.com/10731096/95823103-9ce15780-0d5f-11eb-8010-1bd1b5910d4f.png&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.org/package/element-plus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/element-plus.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/element-plus/element-plus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/node-%20%3E%3D%2016-47c219&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://npmcharts.com/compare/element-plus?minimal=true&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/dm/element-plus.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/element-plus/element-plus&quot;&gt;
    &lt;img src=&quot;https://codecov.io/gh/element-plus/element-plus/branch/dev/graph/badge.svg?token=BKSBO2GLZI&quot;/&gt;
  &lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Element Plus - A Vue.js 3 UI library&lt;/p&gt;

- üí™ Vue 3 Composition API
- üî• Written in TypeScript

## Getting Started

Alright, for you to get started if you are looking for making Element Plus better you should keep reading.
For developers that uses Element Plus to develop your website you should go ahead visit [Getting Started](https://element-plus.org/).

- ‰∏≠ÂõΩÂ§ßÈôÜ[Âä†ÈÄüÈïúÂÉèÁ´ôÁÇπ](https://element-plus.gitee.io/)

## Breaking change list

The first stable release of Element Plus suitable for use in production was released on February 07, 2022. The APIs is stable right now, and here&#039;s also a full list about how to get upgraded from [Element UI](https://element.eleme.io) to Element Plus.

You can find the breaking change list here: [Breaking Change List](https://github.com/element-plus/element-plus/discussions/5658).

### Migration Tool :hammer_and_wrench:

We have made a migration tool for you to migrate your project from [Element UI](https://element.eleme.io) to Element Plus.

You can find the [gogo code migration tool](https://github.com/thx/gogocode/tree/main/packages/gogocode-plugin-element) here.

We have tested this on [Vue Element Admin](https://github.com/PanJiaChen/vue-element-admin). You can find the transpiled code [here](https://github.com/gogocodeio/vue-element-admin).

### Playground

You can also try Element Plus out with the components built-in playground.

#### Try it with our built-in playground

[Playground](https://element-plus.run/)

#### Try it with code sandbox

[![Edit element-plus](https://codesandbox.io/static/img/play-codesandbox.svg)](https://codesandbox.io/s/element-plus-demo-dxtcr)

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Special thanks to the generous sponsorship by:&lt;/b&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Platinum Sponsors&lt;/b&gt;
&lt;/p&gt;
&lt;table align=&quot;center&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://www.vform666.com/&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;150px&quot; src=&quot;https://user-images.githubusercontent.com/17680888/156870588-b25a42d5-888b-4943-8b1b-5239dfd8f4d2.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://js.design?source=element-plus&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;150px&quot; src=&quot;https://user-images.githubusercontent.com/17680888/160634485-df0d00af-8633-4ab8-9a72-aac2b65d1d36.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://www.misboot.com/?from=element-plus&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;150px&quot; src=&quot;https://github-production-user-asset-6210df.s3.amazonaws.com/82012629/250157573-b8ab8d68-ff6b-496f-beb1-9863a545d2af.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Gold Sponsors&lt;/b&gt;
&lt;/p&gt;
&lt;table align=&quot;center&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://wonderful-code.gitee.io/?from=element-plus&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;130px&quot; src=&quot;https://user-images.githubusercontent.com/17680888/173179536-30e35fd1-cd5a-482a-bc41-9d5f0aa66fd4.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://bit.dev/?from=element-ui&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;130px&quot; src=&quot;https://user-images.githubusercontent.com/10095631/41342907-e44e7196-6f2f-11e8-92f2-47702dc8f059.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

---

## Translations

Element Plus is translated to multiple languages, you can click the badge to help up update the translation or apply to become
a proofreader [![Crowdin](https://badges.crowdin.net/element-plus/localized.svg)](https://crowdin.com/project/element-plus)

For now we are only showing English and Chinese for resource reasons, but we are looking forward to translate it into more languages, please go to the link
above and leave a message if you want to help translating Element Plus into your desired language.

### How to help translating

See how to help translating in [Translating Element Plus](https://element-plus.org/en-US/guide/translation.html).

## Stay tuned :eyes:

Join our [Discord](https://discord.com/invite/gXK9XNzW3X) to start communicating with everybody.

## This thing is broken, I should help improve it!

Awesommmmmmee. Everything you need is down below. You can also refer to
[CONTRIBUTING](https://github.com/element-plus/element-plus/blob/dev/CONTRIBUTING.md) and
[Code of Conduct](https://github.com/element-plus/element-plus/blob/dev/CODE_OF_CONDUCT.md)
where you&#039;ll find the same information listed below.

## I would like to become a part of the development team!

Welcome :star_struck:! We are looking for talented developers to join us and making Element Plus better! If you care to join the development team, please
reach out to us, you are more than welcomed to join us! :heart:

We are now lacking of experts of `Testing`, `GitHub Actions`, `PM`, if you do feel like you can and willing to help us, please do reach out to us. :pray:

## Contributors

This project exists thanks to all the people who contribute.

And thank you to all our backers! üôè

&lt;a href=&quot;https://github.com/element-plus/element-plus/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=element-plus/element-plus&quot; /&gt;
&lt;/a&gt;

## License

Element Plus is open source software licensed as
[MIT](https://github.com/element-plus/element-plus/blob/master/LICENSE).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[infiniflow/ragflow]]></title>
            <link>https://github.com/infiniflow/ragflow</link>
            <guid>https://github.com/infiniflow/ragflow</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/infiniflow/ragflow">infiniflow/ragflow</a></h1>
            <p>RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs</p>
            <p>Language: TypeScript</p>
            <p>Stars: 65,808</p>
            <p>Forks: 6,926</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://demo.ragflow.io/&quot;&gt;
&lt;img src=&quot;web/src/assets/logo-with-text.png&quot; width=&quot;520&quot; alt=&quot;ragflow logo&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-DBEDFA&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_zh.md&quot;&gt;&lt;img alt=&quot;ÁÆÄ‰Ωì‰∏≠ÊñáÁâàËá™Ëø∞Êñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_tzh.md&quot;&gt;&lt;img alt=&quot;ÁπÅÈ´îÁâà‰∏≠ÊñáËá™Ëø∞Êñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁπÅÈ´î‰∏≠Êñá-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_ja.md&quot;&gt;&lt;img alt=&quot;Êó•Êú¨Ë™û„ÅÆREADME&quot; src=&quot;https://img.shields.io/badge/Êó•Êú¨Ë™û-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_ko.md&quot;&gt;&lt;img alt=&quot;ÌïúÍµ≠Ïñ¥&quot; src=&quot;https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_id.md&quot;&gt;&lt;img alt=&quot;Bahasa Indonesia&quot; src=&quot;https://img.shields.io/badge/Bahasa Indonesia-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_pt_br.md&quot;&gt;&lt;img alt=&quot;Portugu√™s(Brasil)&quot; src=&quot;https://img.shields.io/badge/Portugu√™s(Brasil)-DFE0E5&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://x.com/intent/follow?screen_name=infiniflowai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/infiniflow?logo=X&amp;color=%20%23f5f5f5&quot; alt=&quot;follow on X(Twitter)&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://demo.ragflow.io&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Online-Demo-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/r/infiniflow/ragflow&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/docker/pulls/infiniflow/ragflow?label=Docker%20Pulls&amp;color=0db7ed&amp;logo=docker&amp;logoColor=white&amp;style=flat-square&quot; alt=&quot;docker pull infiniflow/ragflow:v0.20.5&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/releases/latest&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/github/v/release/infiniflow/ragflow?color=blue&amp;label=Latest%20Release&quot; alt=&quot;Latest Release&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/blob/main/LICENSE&quot;&gt;
        &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/License-Apache--2.0-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;license&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://deepwiki.com/infiniflow/ragflow&quot;&gt;
        &lt;img alt=&quot;Ask DeepWiki&quot; src=&quot;https://deepwiki.com/badge.svg&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://ragflow.io/docs/dev/&quot;&gt;Document&lt;/a&gt; |
  &lt;a href=&quot;https://github.com/infiniflow/ragflow/issues/4214&quot;&gt;Roadmap&lt;/a&gt; |
  &lt;a href=&quot;https://twitter.com/infiniflowai&quot;&gt;Twitter&lt;/a&gt; |
  &lt;a href=&quot;https://discord.gg/NjYzJD3GM3&quot;&gt;Discord&lt;/a&gt; |
  &lt;a href=&quot;https://demo.ragflow.io&quot;&gt;Demo&lt;/a&gt;
&lt;/h4&gt;

#

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/9064&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/9064&quot; alt=&quot;infiniflow%2Fragflow | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;üìï Table of Contents&lt;/b&gt;&lt;/summary&gt;

- üí° [What is RAGFlow?](#-what-is-ragflow)
- üéÆ [Demo](#-demo)
- üìå [Latest Updates](#-latest-updates)
- üåü [Key Features](#-key-features)
- üîé [System Architecture](#-system-architecture)
- üé¨ [Get Started](#-get-started)
- üîß [Configurations](#-configurations)
- üîß [Build a docker image without embedding models](#-build-a-docker-image-without-embedding-models)
- üîß [Build a docker image including embedding models](#-build-a-docker-image-including-embedding-models)
- üî® [Launch service from source for development](#-launch-service-from-source-for-development)
- üìö [Documentation](#-documentation)
- üìú [Roadmap](#-roadmap)
- üèÑ [Community](#-community)
- üôå [Contributing](#-contributing)

&lt;/details&gt;

## üí° What is RAGFlow?

[RAGFlow](https://ragflow.io/) is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs. It offers a streamlined RAG workflow adaptable to enterprises of any scale. Powered by a converged context engine and pre-built agent templates, RAGFlow enables developers to transform complex data into high-fidelity, production-ready AI systems with exceptional efficiency and precision.

## üéÆ Demo

Try our demo at [https://demo.ragflow.io](https://demo.ragflow.io).

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/chunking.gif&quot; width=&quot;1200&quot;/&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/agentic-dark.gif&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## üî• Latest Updates

- 2025-08-08 Supports OpenAI&#039;s latest GPT-5 series models.
- 2025-08-04 Supports new models, including Kimi K2 and Grok 4.
- 2025-08-01 Supports agentic workflow and MCP.
- 2025-05-23 Adds a Python/JavaScript code executor component to Agent.
- 2025-05-05 Supports cross-language query.
- 2025-03-19 Supports using a multi-modal model to make sense of images within PDF or DOCX files.
- 2025-02-28 Combined with Internet search (Tavily), supports reasoning like Deep Research for any LLMs.
- 2024-12-18 Upgrades Document Layout Analysis model in DeepDoc.
- 2024-08-22 Support text to SQL statements through RAG.

## üéâ Stay Tuned

‚≠êÔ∏è Star our repository to stay up-to-date with exciting new features and improvements! Get instant notifications for new
releases! üåü

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/18c9707e-b8aa-4caf-a154-037089c105ba&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## üåü Key Features

### üç≠ **&quot;Quality in, quality out&quot;**

- [Deep document understanding](./deepdoc/README.md)-based knowledge extraction from unstructured data with complicated
  formats.
- Finds &quot;needle in a data haystack&quot; of literally unlimited tokens.

### üç± **Template-based chunking**

- Intelligent and explainable.
- Plenty of template options to choose from.

### üå± **Grounded citations with reduced hallucinations**

- Visualization of text chunking to allow human intervention.
- Quick view of the key references and traceable citations to support grounded answers.

### üçî **Compatibility with heterogeneous data sources**

- Supports Word, slides, excel, txt, images, scanned copies, structured data, web pages, and more.

### üõÄ **Automated and effortless RAG workflow**

- Streamlined RAG orchestration catered to both personal and large businesses.
- Configurable LLMs as well as embedding models.
- Multiple recall paired with fused re-ranking.
- Intuitive APIs for seamless integration with business.

## üîé System Architecture

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/infiniflow/ragflow/assets/12318111/d6ac5664-c237-4200-a7c2-a4a00691b485&quot; width=&quot;1000&quot;/&gt;
&lt;/div&gt;

## üé¨ Get Started

### üìù Prerequisites

- CPU &gt;= 4 cores
- RAM &gt;= 16 GB
- Disk &gt;= 50 GB
- Docker &gt;= 24.0.0 &amp; Docker Compose &gt;= v2.26.1
- [gVisor](https://gvisor.dev/docs/user_guide/install/): Required only if you intend to use the code executor (sandbox) feature of RAGFlow.

&gt; [!TIP]
&gt; If you have not installed Docker on your local machine (Windows, Mac, or Linux), see [Install Docker Engine](https://docs.docker.com/engine/install/).

### üöÄ Start up the server

1. Ensure `vm.max_map_count` &gt;= 262144:

   &gt; To check the value of `vm.max_map_count`:
   &gt;
   &gt; ```bash
   &gt; $ sysctl vm.max_map_count
   &gt; ```
   &gt;
   &gt; Reset `vm.max_map_count` to a value at least 262144 if it is not.
   &gt;
   &gt; ```bash
   &gt; # In this case, we set it to 262144:
   &gt; $ sudo sysctl -w vm.max_map_count=262144
   &gt; ```
   &gt;
   &gt; This change will be reset after a system reboot. To ensure your change remains permanent, add or update the
   &gt; `vm.max_map_count` value in **/etc/sysctl.conf** accordingly:
   &gt;
   &gt; ```bash
   &gt; vm.max_map_count=262144
   &gt; ```

2. Clone the repo:

   ```bash
   $ git clone https://github.com/infiniflow/ragflow.git
   ```

3. Start up the server using the pre-built Docker images:

&gt; [!CAUTION]
&gt; All Docker images are built for x86 platforms. We don&#039;t currently offer Docker images for ARM64.
&gt; If you are on an ARM64 platform, follow [this guide](https://ragflow.io/docs/dev/build_docker_image) to build a Docker image compatible with your system.

   &gt; The command below downloads the `v0.20.5-slim` edition of the RAGFlow Docker image. See the following table for descriptions of different RAGFlow editions. To download a RAGFlow edition different from `v0.20.5-slim`, update the `RAGFLOW_IMAGE` variable accordingly in **docker/.env** before using `docker compose` to start the server. For example: set `RAGFLOW_IMAGE=infiniflow/ragflow:v0.20.5` for the full edition `v0.20.5`.

   ```bash
   $ cd ragflow/docker
   # Use CPU for embedding and DeepDoc tasks:
   $ docker compose -f docker-compose.yml up -d

   # To use GPU to accelerate embedding and DeepDoc tasks:
   # docker compose -f docker-compose-gpu.yml up -d
   ```

   | RAGFlow image tag | Image size (GB) | Has embedding models? | Stable?                  |
   |-------------------|-----------------|-----------------------|--------------------------|
   | v0.20.5           | &amp;approx;9       | :heavy_check_mark:    | Stable release           |
   | v0.20.5-slim      | &amp;approx;2       | ‚ùå                   | Stable release            |
   | nightly           | &amp;approx;9       | :heavy_check_mark:    | _Unstable_ nightly build |
   | nightly-slim      | &amp;approx;2       | ‚ùå                   | _Unstable_ nightly build  |

4. Check the server status after having the server up and running:

   ```bash
   $ docker logs -f ragflow-server
   ```

   _The following output confirms a successful launch of the system:_

   ```bash

         ____   ___    ______ ______ __
        / __ \ /   |  / ____// ____// /____  _      __
       / /_/ // /| | / / __ / /_   / // __ \| | /| / /
      / _, _// ___ |/ /_/ // __/  / // /_/ /| |/ |/ /
     /_/ |_|/_/  |_|\____//_/    /_/ \____/ |__/|__/

    * Running on all addresses (0.0.0.0)
   ```

   &gt; If you skip this confirmation step and directly log in to RAGFlow, your browser may prompt a `network anormal`
   &gt; error because, at that moment, your RAGFlow may not be fully initialized.

5. In your web browser, enter the IP address of your server and log in to RAGFlow.
   &gt; With the default settings, you only need to enter `http://IP_OF_YOUR_MACHINE` (**sans** port number) as the default
   &gt; HTTP serving port `80` can be omitted when using the default configurations.
6. In [service_conf.yaml.template](./docker/service_conf.yaml.template), select the desired LLM factory in `user_default_llm` and update
   the `API_KEY` field with the corresponding API key.

   &gt; See [llm_api_key_setup](https://ragflow.io/docs/dev/llm_api_key_setup) for more information.

   _The show is on!_

## üîß Configurations

When it comes to system configurations, you will need to manage the following files:

- [.env](./docker/.env): Keeps the fundamental setups for the system, such as `SVR_HTTP_PORT`, `MYSQL_PASSWORD`, and
  `MINIO_PASSWORD`.
- [service_conf.yaml.template](./docker/service_conf.yaml.template): Configures the back-end services. The environment variables in this file will be automatically populated when the Docker container starts. Any environment variables set within the Docker container will be available for use, allowing you to customize service behavior based on the deployment environment.
- [docker-compose.yml](./docker/docker-compose.yml): The system relies on [docker-compose.yml](./docker/docker-compose.yml) to start up.

&gt; The [./docker/README](./docker/README.md) file provides a detailed description of the environment settings and service
&gt; configurations which can be used as `${ENV_VARS}` in the [service_conf.yaml.template](./docker/service_conf.yaml.template) file.

To update the default HTTP serving port (80), go to [docker-compose.yml](./docker/docker-compose.yml) and change `80:80`
to `&lt;YOUR_SERVING_PORT&gt;:80`.

Updates to the above configurations require a reboot of all containers to take effect:

&gt; ```bash
&gt; $ docker compose -f docker-compose.yml up -d
&gt; ```

### Switch doc engine from Elasticsearch to Infinity

RAGFlow uses Elasticsearch by default for storing full text and vectors. To switch to [Infinity](https://github.com/infiniflow/infinity/), follow these steps:

1. Stop all running containers:

   ```bash
   $ docker compose -f docker/docker-compose.yml down -v
   ```

&gt; [!WARNING]
&gt; `-v` will delete the docker container volumes, and the existing data will be cleared.

2. Set `DOC_ENGINE` in **docker/.env** to `infinity`.

3. Start the containers:

   ```bash
   $ docker compose -f docker-compose.yml up -d
   ```

&gt; [!WARNING]
&gt; Switching to Infinity on a Linux/arm64 machine is not yet officially supported.

## üîß Build a Docker image without embedding models

This image is approximately 2 GB in size and relies on external LLM and embedding services.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 --build-arg LIGHTEN=1 -f Dockerfile -t infiniflow/ragflow:nightly-slim .
```

## üîß Build a Docker image including embedding models

This image is approximately 9 GB in size. As it includes embedding models, it relies on external LLM services only.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 -f Dockerfile -t infiniflow/ragflow:nightly .
```

## üî® Launch service from source for development

1. Install `uv` and `pre-commit`, or skip this step if they are already installed:

   ```bash
   pipx install uv pre-commit
   ```

2. Clone the source code and install Python dependencies:

   ```bash
   git clone https://github.com/infiniflow/ragflow.git
   cd ragflow/
   uv sync --python 3.10 --all-extras # install RAGFlow dependent python modules
   uv run download_deps.py
   pre-commit install
   ```

3. Launch the dependent services (MinIO, Elasticsearch, Redis, and MySQL) using Docker Compose:

   ```bash
   docker compose -f docker/docker-compose-base.yml up -d
   ```

   Add the following line to `/etc/hosts` to resolve all hosts specified in **docker/.env** to `127.0.0.1`:

   ```
   127.0.0.1       es01 infinity mysql minio redis sandbox-executor-manager
   ```

4. If you cannot access HuggingFace, set the `HF_ENDPOINT` environment variable to use a mirror site:

   ```bash
   export HF_ENDPOINT=https://hf-mirror.com
   ```

5. If your operating system does not have jemalloc, please install it as follows:

   ```bash
   # Ubuntu
   sudo apt-get install libjemalloc-dev
   # CentOS
   sudo yum install jemalloc
   # OpenSUSE
   sudo zypper install jemalloc
   # macOS
   sudo brew install jemalloc
   ```

6. Launch backend service:

   ```bash
   source .venv/bin/activate
   export PYTHONPATH=$(pwd)
   bash docker/launch_backend_service.sh
   ```

7. Install frontend dependencies:

   ```bash
   cd web
   npm install
   ```

8. Launch frontend service:

   ```bash
   npm run dev
   ```

   _The following output confirms a successful launch of the system:_

   ![](https://github.com/user-attachments/assets/0daf462c-a24d-4496-a66f-92533534e187)

9. Stop RAGFlow front-end and back-end service after development is complete:

   ```bash
   pkill -f &quot;ragflow_server.py|task_executor.py&quot;
   ```


## üìö Documentation

- [Quickstart](https://ragflow.io/docs/dev/)
- [Configuration](https://ragflow.io/docs/dev/configurations)
- [Release notes](https://ragflow.io/docs/dev/release_notes)
- [User guides](https://ragflow.io/docs/dev/category/guides)
- [Developer guides](https://ragflow.io/docs/dev/category/developers)
- [References](https://ragflow.io/docs/dev/category/references)
- [FAQs](https://ragflow.io/docs/dev/faq)

## üìú Roadmap

See the [RAGFlow Roadmap 2025](https://github.com/infiniflow/ragflow/issues/4214)

## üèÑ Community

- [Discord](https://discord.gg/NjYzJD3GM3)
- [Twitter](https://twitter.com/infiniflowai)
- [GitHub Discussions](https://github.com/orgs/infiniflow/discussions)

## üôå Contributing

RAGFlow flourishes via open-source collaboration. In this spirit, we embrace diverse contributions from the community.
If you would like to be a part, review our [Contribution Guidelines](https://ragflow.io/docs/dev/contributing) first.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[RSSNext/Folo]]></title>
            <link>https://github.com/RSSNext/Folo</link>
            <guid>https://github.com/RSSNext/Folo</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[üß° Follow everything in one place]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/RSSNext/Folo">RSSNext/Folo</a></h1>
            <p>üß° Follow everything in one place</p>
            <p>Language: TypeScript</p>
            <p>Stars: 34,916</p>
            <p>Forks: 1,682</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/RSSNext/Folo&quot;&gt;
    &lt;img src=&quot;https://github.com/RSSNext/Folo/raw/refs/heads/dev/apps/desktop/layer/renderer/public/icon.svg&quot; alt=&quot;Logo&quot; width=&quot;80&quot; height=&quot;80&quot;&gt;
  &lt;/a&gt;

  &lt;h3&gt;Folo&lt;/h3&gt;
  &lt;p&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/cbe924f2-d8b0-48b0-814e-7c06ccb1911c&quot; height=&quot;60&quot; /&gt;
    &amp;nbsp;&amp;nbsp;&amp;nbsp;
    &lt;img src=&quot;https://github.com/user-attachments/assets/6997a236-3df3-49d5-98a4-514f6d1a02c4&quot; height=&quot;60&quot; /&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://github.com/RSSNext/Folo/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/RSSNext/Follow?color=ffcb47&amp;labelColor=black&amp;style=flat-square&amp;logo=github&amp;label=Stars&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/RSSNext/Folo/graphs/contributors&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/RSSNext/Folo?style=flat-square&amp;logo=github&amp;label=Contributors&amp;labelColor=black&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://status.follow.is/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://status.follow.is/api/badge/18/uptime?color=%2344CC10&amp;labelColor=black&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/RSSNext/Folo/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/downloads/RSSNext/Folo/total?color=369eff&amp;labelColor=black&amp;logo=github&amp;style=flat-square&amp;label=Downloads&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://x.com/intent/follow?screen_name=folo_is&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Follow-blue?color=1d9bf0&amp;logo=x&amp;labelColor=black&amp;style=flat-square&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/followapp&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Ffollowapp%3Fwith_counts%3Dtrue&amp;query=approximate_member_count&amp;color=5865F2&amp;label=Discord&amp;labelColor=black&amp;logo=discord&amp;logoColor=white&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://github.com/RSSNext/Folo/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/package-json/v/RSSNext/Folo?filename=%2Fapps%2Fmobile%2Fpackage.json&amp;style=flat-square&amp;logo=folo&amp;logoColor=white&amp;label=Mobile&amp;labelColor=black&amp;color=FF5C00&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://apps.apple.com/us/app/folo-follow-everything/id6739802604&quot;&gt;&lt;img src=&quot;https://img.shields.io/itunes/v/6739802604?style=flat-square&amp;logo=apple&amp;label=App%20Store&amp;color=FF5C00&amp;labelColor=black&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://play.google.com/store/apps/details?id=is.follow&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/endpoint?url=https%3A%2F%2Fplay.cuzi.workers.dev%2Fplay%3Fi%3Dis.follow%26gl%3DUS%26hl%3Den%26l%3DAndroid%26m%3D%24version&amp;style=flat-square&amp;logo=google-play&amp;label=Google%20Play&amp;labelColor=black&amp;color=FF5C00&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/RSSNext/Folo/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/package-json/v/RSSNext/Folo?filename=%2Fapps%2Fdesktop%2Fpackage.json&amp;style=flat-square&amp;logo=folo&amp;logoColor=white&amp;label=Desktop&amp;labelColor=black&amp;color=FF5C00&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://apps.apple.com/us/app/folo-follow-everything/id6739802604&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Ffolo-mac-app-store-version.rss3.workers.dev%2F&amp;query=version&amp;prefix=v&amp;style=flat-square&amp;logo=apple&amp;label=Mac%20App%20Store&amp;labelColor=black&amp;color=FF5C00&amp;cacheSeconds=3600&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://apps.microsoft.com/detail/9nvfzpv0v0ht?mode=direct&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Ffolo-microsoft-store-version.rss3.workers.dev%2F&amp;query=version&amp;style=flat-square&amp;logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIj48cGF0aCBmaWxsPSIjZmZmIiBkPSJNMyAzaDguNTN2OC41M0gzek0xMi40NjkgM2g4LjUzdjguNTNoLTguNTN6TTMgMTIuNDdoOC41M1YyMUgzek0xMi40NjkgMTIuNDdoOC41M1YyMWgtOC41M3oiLz48L3N2Zz4%3D&amp;logoColor=white&amp;label=Microsoft%20Store&amp;labelColor=black&amp;color=FF5C00&amp;cacheSeconds=3600&amp;prefix=v&quot; /&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;!-- &lt;a href=&quot;https://github.com/RSSNext/Folo&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/59b957fb-59ed-4ef0-994e-f6a402a6fe2b&quot; alt=&quot;GitHub Trending&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt; --&gt;
    &lt;a href=&quot;https://apps.apple.com/us/app/folo-follow-everything/id6739802604&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/35747716-28bf-413a-822b-aa49d49f1aa0&quot; alt=&quot;Folo Mobile&quot; width=&quot;52%&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://apps.apple.com/us/app/folo-follow-everything/id6739802604&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/198a0165-b8c9-45c1-9116-b473a13a8d0c&quot; alt=&quot;Folo Desktop&quot; width=&quot;46%&quot;/&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
  &lt;/p&gt;
&lt;/div&gt;

As they say, your thoughts are what you read‚Äîand we‚Äôve been consuming noisy feeds for too long! Folo organizes content into one timeline, keeping you updated on what matters, noise-free. Share lists, explore collections, and enjoy distraction-free browsing.

## üëãüèª Getting Started &amp; Join Our Community

Whether for users or professional developers, Folo will be your open information playground. Please be aware that Folo is currently under active development, and feedback is welcome for any [issue](https://github.com/RSSNext/Folo/issues) encountered.

Feel free to try it using the following methods:

| Operating System | Source                                                                                                                                                                                                                                                                                                                                                                                                                                |
| :--------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Any              | &lt;a href=&quot;https://app.folo.is&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/51ef7800-b683-4493-83e8-eb4752366997&quot; alt=&quot;Browser&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;                                                                                                                                                                                                                                                              |
| iOS              | &lt;a href=&quot;https://apps.apple.com/us/app/folo-follow-everything/id6739802604&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/a94d8698-2a11-4f43-9b0a-b756b17b61f7&quot; alt=&quot;App Store&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;                                                                                                                                                                                                              |
| Android          | &lt;a href=&quot;https://play.google.com/store/apps/details?id=is.follow&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/0d178e0b-3ace-4f75-bbde-ab3c0a416ce8&quot; alt=&quot;Google Play&quot; height=&quot;55&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/RSSNext/Folo/releases/latest&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/cf61e197-d756-4606-a8ad-fb591f79fdfc&quot; alt=&quot;App Store&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;               |
| macOS            | &lt;a href=&quot;https://apps.apple.com/us/app/folo-follow-everything/id6739802604&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/0d47f902-7fa3-494e-ad28-9ab11af5e6d4&quot; alt=&quot;Microsoft Store&quot; height=&quot;55&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/RSSNext/Folo/releases/latest&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/cf61e197-d756-4606-a8ad-fb591f79fdfc&quot; alt=&quot;App Store&quot; height=&quot;55&quot;/&gt;&lt;/a&gt; |
| Windows          | &lt;a href=&quot;https://apps.microsoft.com/detail/9nvfzpv0v0ht?mode=direct&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/b3112bab-9dd0-4893-9488-890dcb368f70&quot; alt=&quot;Microsoft Store&quot; height=&quot;55&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/RSSNext/Folo/releases/latest&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/cf61e197-d756-4606-a8ad-fb591f79fdfc&quot; alt=&quot;App Store&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;        |
| Linux            | &lt;a href=&quot;https://github.com/RSSNext/Folo/releases/latest&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/cf61e197-d756-4606-a8ad-fb591f79fdfc&quot; alt=&quot;App Store&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;                                                                                                                                                                                                                                |

You can also install using the following methods maintained by our community:

- If you are using Arch Linux, you can install package [folo-appimage](https://aur.archlinux.org/packages/folo-appimage) that maintained by [timochan](https://github.com/ttimochan) and [grtsinry43](https://github.com/grtsinry43).
- If you are using Nix, you can install package [follow](https://github.com/NixOS/nixpkgs/blob/master/pkgs/by-name/fo/follow/package.nix) that maintained by [iosmanthus](https://github.com/iosmanthus).
- If you are using macOS with [Homebrew](https://brew.sh), you can install cask [folo](https://formulae.brew.sh/cask/folo) that maintained by [realSunyz](https://github.com/realSunyz).
- If you are using Windows with [Scoop](https://scoop.sh), you can install manifest [folo](https://github.com/cscnk52/cetacea/blob/master/bucket/folo.json) that maintained by [cscnk52](https://github.com/cscnk52).

| [![Discord](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Ffollowapp%3Fwith_counts%3Dtrue&amp;query=approximate_member_count&amp;color=5865F2&amp;label=Discord&amp;labelColor=black&amp;logo=discord&amp;logoColor=white&amp;style=flat-square)](https://discord.gg/followapp) | Join our Discord server to connect with developers, request features, and receive support. |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------- |
| [![](https://img.shields.io/badge/any_text-Follow-blue?color=2CA5E0&amp;label=_&amp;logo=x&amp;labelColor=black&amp;style=flat-square)](https://x.com/intent/follow?screen_name=folo_is)                                                                                                                       | Follow us on X/Twitter for product updates and to join in on reward activities.            |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~

![Image](https://github.com/user-attachments/assets/a08f9437-b24c-4388-8f01-2826e09eeaf2)

&lt;a href=&quot;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats?repo_id=783512367&quot; target=&quot;_blank&quot; style=&quot;display: block&quot; align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=783512367&amp;image_size=auto&amp;color_scheme=dark&quot; width=&quot;655&quot; height=&quot;auto&quot;&gt;
    &lt;img alt=&quot;Performance Stats of RSSNext/Folo - Last 28 days&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=783512367&amp;image_size=auto&amp;color_scheme=light&quot; width=&quot;655&quot; height=&quot;auto&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;

## ‚ú® Features

### Customized Information Hub

Subscribe to a vast range of feeds and curated lists. Curate your favorites and keep track of what matters most to you.

![](https://github.com/user-attachments/assets/11dc7d21-f5d8-4e41-9269-24fc352aa02b)

### AI At Your Fingertips

A smarter and more efficient browsing with AI-powered features like translation, summary, and more.

![](https://github.com/user-attachments/assets/37cf4f2f-4c5e-4775-86e8-2fa1a1b2ecf5)

### Dynamic Content Support

Because we know content is more than just text. From articles to videos, images to audio ‚Äî Folo gets it all covered.

![](https://github.com/user-attachments/assets/d1379fd6-8767-476e-b0dc-d61753715e26)

### More Than Just An App

This isn‚Äôt just another app. Folo is a community ‚Äî introducing a new era of openness and community-driven experience.

![](https://github.com/user-attachments/assets/62004a04-eaea-4f5d-bfbf-4e68b6b90286)

## ü§ù Contributing

You are welcome to join the open source community to build together, please check our [Contributing Guide](./CONTRIBUTING.md) for more details.

## üîè Code signing policy

Folo for Windows uses free code signing provided by [SignPath.io](https://about.signpath.io/), certificate by [SignPath Foundation](https://signpath.org/).

Folo for macOS and iOS are signed and notarized by [Apple Developer Program](https://developer.apple.com/programs/).

All released files are verified with [GitHub artifact attestations](https://github.com/RSSNext/Folo/attestations) to ensure their provenance and integrity.

## üìù License

Folo is licensed under the GNU General Public License version 3 with the addition of the following special exception:

All content in the `icons/mgc` directory is copyrighted by https://mgc.mingcute.com/ and cannot be redistributed.

All content in the `lottie` directory is distributed under the [Lottie Simple License](https://lottiefiles.com/page/license).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[kortix-ai/suna]]></title>
            <link>https://github.com/kortix-ai/suna</link>
            <guid>https://github.com/kortix-ai/suna</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[Kortix ‚Äì build, manage and train AI Agents. Fully Open Source.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kortix-ai/suna">kortix-ai/suna</a></h1>
            <p>Kortix ‚Äì build, manage and train AI Agents. Fully Open Source.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 18,302</p>
            <p>Forks: 3,098</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# Kortix ‚Äì Open Source Platform to Build, Manage and Train AI Agents

![Kortix Screenshot](frontend/public/banner.png)

**The complete platform for creating autonomous AI agents that work for you**

Kortix is a comprehensive open source platform that empowers you to build, manage, and train sophisticated AI agents for any use case. Create powerful agents that act autonomously on your behalf, from general-purpose assistants to specialized automation tools.

[![License](https://img.shields.io/badge/License-Apache--2.0-blue)](./license)
[![Discord Follow](https://dcbadge.limes.pink/api/server/Py6pCBUUPw?style=flat)](https://discord.gg/Py6pCBUUPw)
[![Twitter Follow](https://img.shields.io/twitter/follow/kortixai)](https://x.com/kortixai)
[![GitHub Repo stars](https://img.shields.io/github/stars/kortix-ai/suna)](https://github.com/kortix-ai/suna)
[![Issues](https://img.shields.io/github/issues/kortix-ai/suna)](https://github.com/kortix-ai/suna/labels/bug)

&lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
[Deutsch](https://www.readme-i18n.com/kortix-ai/suna?lang=de) | 
[Espa√±ol](https://www.readme-i18n.com/kortix-ai/suna?lang=es) | 
[fran√ßais](https://www.readme-i18n.com/kortix-ai/suna?lang=fr) | 
[Êó•Êú¨Ë™û](https://www.readme-i18n.com/kortix-ai/suna?lang=ja) | 
[ÌïúÍµ≠Ïñ¥](https://www.readme-i18n.com/kortix-ai/suna?lang=ko) | 
[Portugu√™s](https://www.readme-i18n.com/kortix-ai/suna?lang=pt) | 
[–†—É—Å—Å–∫–∏–π](https://www.readme-i18n.com/kortix-ai/suna?lang=ru) | 
[‰∏≠Êñá](https://www.readme-i18n.com/kortix-ai/suna?lang=zh)

&lt;/div&gt;

## üåü What Makes Kortix Special

### ü§ñ Includes Suna ‚Äì Flagship Generalist AI Worker
Meet Suna, our showcase agent that demonstrates the full power of the Kortix platform. Through natural conversation, Suna handles research, data analysis, browser automation, file management, and complex workflows ‚Äì showing you what&#039;s possible when you build with Kortix.

### üîß Build Custom Suna-Type Agents
Create your own specialized agents tailored to specific domains, workflows, or business needs. Whether you need agents for customer service, data processing, content creation, or industry-specific tasks, Kortix provides the infrastructure and tools to build, deploy, and scale them.

### üöÄ Complete Platform Capabilities
- **Browser Automation**: Navigate websites, extract data, fill forms, automate web workflows
- **File Management**: Create, edit, and organize documents, spreadsheets, presentations, code
- **Web Intelligence**: Crawling, search capabilities, data extraction and synthesis
- **System Operations**: Command-line execution, system administration, DevOps tasks
- **API Integrations**: Connect with external services and automate cross-platform workflows
- **Agent Builder**: Visual tools to configure, customize, and deploy agents

## üìã Table of Contents

- [üåü What Makes Kortix Special](#-what-makes-kortix-special)
- [üéØ Agent Examples &amp; Use Cases](#-agent-examples--use-cases)
- [üèóÔ∏è Platform Architecture](#Ô∏è-platform-architecture)
- [üöÄ Quick Start](#-quick-start)
- [üè† Self-Hosting](#-self-hosting)
- [ü§ù Contributing](#-contributing)
- [üìÑ License](#-license)

## üéØ Agent Examples &amp; Use Cases

### Suna - Your Generalist AI Worker

Suna demonstrates the full capabilities of the Kortix platform as a versatile AI worker that can:

**üîç Research &amp; Analysis**
- Conduct comprehensive web research across multiple sources
- Analyze documents, reports, and datasets
- Synthesize information and create detailed summaries
- Market research and competitive intelligence

**üåê Browser Automation**
- Navigate complex websites and web applications
- Extract data from multiple pages automatically
- Fill forms and submit information
- Automate repetitive web-based workflows

**üìÅ File &amp; Document Management**
- Create and edit documents, spreadsheets, presentations
- Organize and structure file systems
- Convert between different file formats
- Generate reports and documentation

**üìä Data Processing &amp; Analysis**
- Clean and transform datasets from various sources
- Perform statistical analysis and create visualizations
- Monitor KPIs and generate insights
- Integrate data from multiple APIs and databases

**‚öôÔ∏è System Administration**
- Execute command-line operations safely
- Manage system configurations and deployments
- Automate DevOps workflows
- Monitor system health and performance

### Build Your Own Specialized Agents

The Kortix platform enables you to create agents tailored to specific needs:

**üéß Customer Service Agents**
- Handle support tickets and FAQ responses
- Manage user onboarding and training
- Escalate complex issues to human agents
- Track customer satisfaction and feedback

**‚úçÔ∏è Content Creation Agents**
- Generate marketing copy and social media posts
- Create technical documentation and tutorials
- Develop educational content and training materials
- Maintain content calendars and publishing schedules

**üìà Sales &amp; Marketing Agents**
- Qualify leads and manage CRM systems
- Schedule meetings and follow up with prospects
- Create personalized outreach campaigns
- Generate sales reports and forecasts

**üî¨ Research &amp; Development Agents**
- Conduct academic and scientific research
- Monitor industry trends and innovations
- Analyze patents and competitive landscapes
- Generate research reports and recommendations

**üè≠ Industry-Specific Agents**
- Healthcare: Patient data analysis, appointment scheduling
- Finance: Risk assessment, compliance monitoring
- Legal: Document review, case research
- Education: Curriculum development, student assessment

Each agent can be configured with custom tools, workflows, knowledge bases, and integrations specific to your requirements.

## üèóÔ∏è Platform Architecture

![Architecture Diagram](docs/images/diagram.png)

Kortix consists of four main components that work together to provide a complete AI agent development platform:

### üîß Backend API
Python/FastAPI service that powers the agent platform with REST endpoints, thread management, agent orchestration, and LLM integration with Anthropic, OpenAI, and others via LiteLLM. Includes agent builder tools, workflow management, and extensible tool system.

### üñ•Ô∏è Frontend Dashboard
Next.js/React application providing a comprehensive agent management interface with chat interfaces, agent configuration dashboards, workflow builders, monitoring tools, and deployment controls.

### üê≥ Agent Runtime
Isolated Docker execution environments for each agent instance featuring browser automation, code interpreter, file system access, tool integration, security sandboxing, and scalable agent deployment.

### üóÑÔ∏è Database &amp; Storage
Supabase-powered data layer handling authentication, user management, agent configurations, conversation history, file storage, workflow state, analytics, and real-time subscriptions for live agent monitoring.

## üöÄ Quick Start

Get your Kortix platform running in minutes with our automated setup wizard:

### 1Ô∏è‚É£ Clone the Repository
```bash
git clone https://github.com/kortix-ai/suna.git
cd suna
```

### 2Ô∏è‚É£ Run the Setup Wizard
```bash
python setup.py
```
The wizard will guide you through 14 steps with progress saving, so you can resume if interrupted.

### 3Ô∏è‚É£ Start the Platform
```bash
python start.py
```

That&#039;s it! Your Kortix platform will be running with Suna ready to assist you.

## üè† Self-Hosting

Kortix can be self-hosted on your own infrastructure using our comprehensive setup wizard, giving you complete control over your AI agent platform. For a complete guide to self-hosting Kortix, please refer to our [Self-Hosting Guide](./docs/SELF-HOSTING.md).

### üîß Setup Process Includes

- **üèóÔ∏è Infrastructure**: Supabase project setup for database and authentication
- **‚ö° Performance**: Redis configuration for caching and session management
- **üõ°Ô∏è Security**: Daytona setup for secure agent execution environments
- **ü§ñ AI Integration**: LLM providers (Anthropic, OpenAI, OpenRouter, etc.)
- **üåê Web Capabilities**: Search and scraping (Tavily, Firecrawl)
- **üìã Workflows**: QStash for background job processing
- **üîó Automation**: Webhook handling for automated tasks
- **üìä Data Sources**: Optional RapidAPI integrations

### üìö Manual Setup

For advanced users who prefer manual configuration, see the [Self-Hosting Guide](./docs/SELF-HOSTING.md) for detailed manual setup instructions.

The wizard will guide you through all necessary steps to get your Kortix platform up and running. For detailed instructions, troubleshooting tips, and advanced configuration options, see the [Self-Hosting Guide](./docs/SELF-HOSTING.md).

## ü§ù Contributing

We welcome contributions from the community! Whether you&#039;re fixing bugs, adding features, or improving documentation, your help makes Kortix better for everyone.

Please see our [Contributing Guide](./CONTRIBUTING.md) for more details on:
- How to set up your development environment
- Code style and standards
- Pull request process
- Community guidelines

## üìÑ License

Kortix is licensed under the Apache License, Version 2.0. See [LICENSE](./LICENSE) for the full license text.

---

&lt;div align=&quot;center&quot;&gt;

**Ready to build your first AI agent?** 

[Get Started](./docs/SELF-HOSTING.md) ‚Ä¢ [Join Discord](https://discord.gg/Py6pCBUUPw) ‚Ä¢ [Follow on Twitter](https://x.com/kortixai)

&lt;/div&gt;</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[wickenico/WailBrew]]></title>
            <link>https://github.com/wickenico/WailBrew</link>
            <guid>https://github.com/wickenico/WailBrew</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:46 GMT</pubDate>
            <description><![CDATA[Minimalistic Homebrew GUI made with Go, Wails and React.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wickenico/WailBrew">wickenico/WailBrew</a></h1>
            <p>Minimalistic Homebrew GUI made with Go, Wails and React.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 687</p>
            <p>Forks: 36</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre># WailBrew - Homebrew GUI Manager

[![Latest Release](https://img.shields.io/github/v/release/wickenico/WailBrew)](https://github.com/wickenico/WailBrew/releases/latest)
[![Downloads](https://img.shields.io/github/downloads/wickenico/WailBrew/total)](https://github.com/wickenico/WailBrew/releases)

## üç∫ About

WailBrew is a modern and intuitive way to manage Homebrew on macOS! It provides a clean graphical interface that makes package management accessible to everyone. From the WailBrew UI, you can:

- View and manage installed formulas and casks
- Search through packages with instant filtering
- Install, uninstall, and upgrade packages
- Check for outdated packages and update them individually or all at once
- View detailed package information including dependencies and conflicts
- Manage Homebrew repositories (tap/untap)

WailBrew was inspired by [Cakebrew](https://www.cakebrew.com/), bringing modern UI design and enhanced functionality to Homebrew package management. Built with [Wails](https://wails.io), Go, and React, it combines native performance with a beautiful, responsive interface.

Requests, Questions, Troubleshooting? =&gt; [r/WailBrew](https://www.reddit.com/r/WailBrew)

## üì• Installation

üì¶ **Installation via Homebrew (recommended):**

```bash
brew tap wickenico/wailbrew
brew install --cask wailbrew
```

**[Download Latest Version](https://github.com/wickenico/WailBrew/releases/latest)** 

## üì∏ Screenshots

![WailBrew Screenshot](images/Screenshot.png)

## üåç Localizations

WailBrew supports multiple languages! As of now, the following languages are supported:

- üá∫üá∏ English
- üá©üá™ German
- üá´üá∑ French
- üáπüá∑ Turkish
- üá®üá≥ Chinese (Simplified)
- üáßüá∑ Portugu√™s do Brasil
- üá∑üá∫ Russian  

If you wish to contribute by translating WailBrew to your language, feel free to [open a Pull Request](https://github.com/wickenico/WailBrew/pulls) or [create an Issue](https://github.com/wickenico/WailBrew/issues).

## üì∞ Mentioned

- &lt;a href=&quot;https://vvmac.com/wordpress_b/wailbrew-pare-homebrew-dune-interface-graphique/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;VVMac&lt;/a&gt;
- &lt;a href=&quot;https://softwareontheweb.com/product/wailbrew&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Software on the web&lt;/a&gt;
- &lt;a href=&quot;https://madewithreactjs.com/wailbrew&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Made with ReactJS&lt;/a&gt;
- &lt;a href=&quot;https://tom-doerr.github.io/repo_posts/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Tom Doerr Repository Showcase&lt;/a&gt;
- &lt;a href=&quot;https://alternativeto.net/software/wailbrew/about/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;AlternativeTo&lt;/a&gt;
- &lt;a href=&quot;https://www.ifun.de/wailbrew-einfache-grafische-oberflaeche-fuer-homebrew-266778/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;iFun&lt;/a&gt;

## üõ†Ô∏è Contributing

Interested in contributing to WailBrew? We welcome contributions of all kinds!

- **Code contributions**: Bug fixes, features, improvements
- **Translations**: Help localize WailBrew to more languages
- **Bug reports**: Found an issue? Let us know
- **Feature requests**: Have an idea? We&#039;d love to hear it

Please see [CONTRIBUTING.md](CONTRIBUTING.md) for detailed development setup and contribution guidelines.

## üìù License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

## üêõ Troubleshooting
### Common Issues
- **Homebrew not found**: Ensure Homebrew is correctly installed
- **Permission errors**: May need to run the app with appropriate permissions
- **Slow performance**: Close other resource-intensive applications

### Support

For issues, feature requests, or questions:
- Visit [r/WailBrew](https://www.reddit.com/r/WailBrew) for community support
- Check [existing issues](https://github.com/wickenico/WailBrew/issues) on GitHub
- Create a [new issue](https://github.com/wickenico/WailBrew/issues/new) if needed
- See [CONTRIBUTING.md](CONTRIBUTING.md) for more details on reporting bugs

## üèÜ Acknowledgments
- Wails community for the framework: https://wails.io
- Cakebrew as inspiration: https://www.cakebrew.com/

**WailBrew** makes Homebrew management simple and accessible for all macOS users. Try it out and streamline your package management workflow!
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ChatGPTNextWeb/NextChat]]></title>
            <link>https://github.com/ChatGPTNextWeb/NextChat</link>
            <guid>https://github.com/ChatGPTNextWeb/NextChat</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:45 GMT</pubDate>
            <description><![CDATA[‚ú® Light and Fast AI Assistant. Support: Web | iOS | MacOS | Android | Linux | Windows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ChatGPTNextWeb/NextChat">ChatGPTNextWeb/NextChat</a></h1>
            <p>‚ú® Light and Fast AI Assistant. Support: Web | iOS | MacOS | Android | Linux | Windows</p>
            <p>Language: TypeScript</p>
            <p>Stars: 86,061</p>
            <p>Forks: 60,937</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;a href=&#039;https://nextchat.club&#039;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/83bdcc07-ae5e-4954-a53a-ac151ba6ccf3&quot; width=&quot;1000&quot; alt=&quot;icon&quot;/&gt;
&lt;/a&gt;

&lt;h1 align=&quot;center&quot;&gt;NextChat&lt;/h1&gt;

English / [ÁÆÄ‰Ωì‰∏≠Êñá](./README_CN.md)

&lt;a href=&quot;https://trendshift.io/repositories/5973&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/5973&quot; alt=&quot;ChatGPTNextWeb%2FChatGPT-Next-Web | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

‚ú® Light and Fast AI Assistant,with Claude, DeepSeek, GPT4 &amp; Gemini Pro support.

[![Saas][Saas-image]][saas-url]
[![Web][Web-image]][web-url]
[![Windows][Windows-image]][download-url]
[![MacOS][MacOS-image]][download-url]
[![Linux][Linux-image]][download-url]

[NextChatAI](https://nextchat.club?utm_source=readme) / [iOS APP](https://apps.apple.com/us/app/nextchat-ai/id6743085599) / [Web App Demo](https://app.nextchat.club) / [Desktop App](https://github.com/Yidadaa/ChatGPT-Next-Web/releases) / [Enterprise Edition](#enterprise-edition)

[saas-url]: https://nextchat.club?utm_source=readme
[saas-image]: https://img.shields.io/badge/NextChat-Saas-green?logo=microsoftedge
[web-url]: https://app.nextchat.club/
[download-url]: https://github.com/Yidadaa/ChatGPT-Next-Web/releases
[Web-image]: https://img.shields.io/badge/Web-PWA-orange?logo=microsoftedge
[Windows-image]: https://img.shields.io/badge/-Windows-blue?logo=windows
[MacOS-image]: https://img.shields.io/badge/-MacOS-black?logo=apple
[Linux-image]: https://img.shields.io/badge/-Linux-333?logo=ubuntu

[&lt;img src=&quot;https://zeabur.com/button.svg&quot; alt=&quot;Deploy on Zeabur&quot; height=&quot;30&quot;&gt;](https://zeabur.com/templates/ZBUEFA) [&lt;img src=&quot;https://vercel.com/button&quot; alt=&quot;Deploy on Vercel&quot; height=&quot;30&quot;&gt;](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FChatGPTNextWeb%2FChatGPT-Next-Web&amp;env=OPENAI_API_KEY&amp;env=CODE&amp;project-name=nextchat&amp;repository-name=NextChat) [&lt;img src=&quot;https://gitpod.io/button/open-in-gitpod.svg&quot; alt=&quot;Open in Gitpod&quot; height=&quot;30&quot;&gt;](https://gitpod.io/#https://github.com/ChatGPTNextWeb/NextChat)

[&lt;img src=&quot;https://github.com/user-attachments/assets/903482d4-3e87-4134-9af1-f2588fa90659&quot; height=&quot;50&quot; width=&quot;&quot; &gt;](https://monica.im/?utm=nxcrp)

&lt;/div&gt;

## ‚ù§Ô∏è Sponsor AI API

&lt;a href=&#039;https://302.ai/&#039;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/a03edf82-2031-4f23-bdb8-bfc0bfd168a4&quot; width=&quot;100%&quot; alt=&quot;icon&quot;/&gt;
&lt;/a&gt;

[302.AI](https://302.ai/) is a pay-as-you-go AI application platform that offers the most comprehensive AI APIs and online applications available.

## ü•≥ Cheer for NextChat iOS Version Online!

&gt; [üëâ Click Here to Install Now](https://apps.apple.com/us/app/nextchat-ai/id6743085599)

&gt; [‚ù§Ô∏è Source Code Coming Soon](https://github.com/ChatGPTNextWeb/NextChat-iOS)

![Github iOS Image](https://github.com/user-attachments/assets/e0aa334f-4c13-4dc9-8310-e3b09fa4b9f3)

## ü´£ NextChat Support MCP !

&gt; Before build, please set env ENABLE_MCP=true

&lt;img src=&quot;https://github.com/user-attachments/assets/d8851f40-4e36-4335-b1a4-ec1e11488c7e&quot;/&gt;

## Enterprise Edition

Meeting Your Company&#039;s Privatization and Customization Deployment Requirements:

- **Brand Customization**: Tailored VI/UI to seamlessly align with your corporate brand image.
- **Resource Integration**: Unified configuration and management of dozens of AI resources by company administrators, ready for use by team members.
- **Permission Control**: Clearly defined member permissions, resource permissions, and knowledge base permissions, all controlled via a corporate-grade Admin Panel.
- **Knowledge Integration**: Combining your internal knowledge base with AI capabilities, making it more relevant to your company&#039;s specific business needs compared to general AI.
- **Security Auditing**: Automatically intercept sensitive inquiries and trace all historical conversation records, ensuring AI adherence to corporate information security standards.
- **Private Deployment**: Enterprise-level private deployment supporting various mainstream private cloud solutions, ensuring data security and privacy protection.
- **Continuous Updates**: Ongoing updates and upgrades in cutting-edge capabilities like multimodal AI, ensuring consistent innovation and advancement.

For enterprise inquiries, please contact: **business@nextchat.dev**

## Screenshots

![Settings](./docs/images/settings.png)

![More](./docs/images/more.png)

## Features

- **Deploy for free with one-click** on Vercel in under 1 minute
- Compact client (~5MB) on Linux/Windows/MacOS, [download it now](https://github.com/Yidadaa/ChatGPT-Next-Web/releases)
- Fully compatible with self-deployed LLMs, recommended for use with [RWKV-Runner](https://github.com/josStorer/RWKV-Runner) or [LocalAI](https://github.com/go-skynet/LocalAI)
- Privacy first, all data is stored locally in the browser
- Markdown support: LaTex, mermaid, code highlight, etc.
- Responsive design, dark mode and PWA
- Fast first screen loading speed (~100kb), support streaming response
- New in v2: create, share and debug your chat tools with prompt templates (mask)
- Awesome prompts powered by [awesome-chatgpt-prompts-zh](https://github.com/PlexPt/awesome-chatgpt-prompts-zh) and [awesome-chatgpt-prompts](https://github.com/f/awesome-chatgpt-prompts)
- Automatically compresses chat history to support long conversations while also saving your tokens
- I18n: English, ÁÆÄ‰Ωì‰∏≠Êñá, ÁπÅ‰Ωì‰∏≠Êñá, Êó•Êú¨Ë™û, Fran√ßais, Espa√±ol, Italiano, T√ºrk√ße, Deutsch, Ti·∫øng Vi·ªát, –†—É—Å—Å–∫–∏–π, ƒåe≈°tina, ÌïúÍµ≠Ïñ¥, Indonesia

&lt;div align=&quot;center&quot;&gt;
   
![‰∏ªÁïåÈù¢](./docs/images/cover.png)

&lt;/div&gt;

## Roadmap

- [x] System Prompt: pin a user defined prompt as system prompt [#138](https://github.com/Yidadaa/ChatGPT-Next-Web/issues/138)
- [x] User Prompt: user can edit and save custom prompts to prompt list
- [x] Prompt Template: create a new chat with pre-defined in-context prompts [#993](https://github.com/Yidadaa/ChatGPT-Next-Web/issues/993)
- [x] Share as image, share to ShareGPT [#1741](https://github.com/Yidadaa/ChatGPT-Next-Web/pull/1741)
- [x] Desktop App with tauri
- [x] Self-host Model: Fully compatible with [RWKV-Runner](https://github.com/josStorer/RWKV-Runner), as well as server deployment of [LocalAI](https://github.com/go-skynet/LocalAI): llama/gpt4all/rwkv/vicuna/koala/gpt4all-j/cerebras/falcon/dolly etc.
- [x] Artifacts: Easily preview, copy and share generated content/webpages through a separate window [#5092](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/pull/5092)
- [x] Plugins: support network search, calculator, any other apis etc. [#165](https://github.com/Yidadaa/ChatGPT-Next-Web/issues/165) [#5353](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/issues/5353)
  - [x] network search, calculator, any other apis etc. [#165](https://github.com/Yidadaa/ChatGPT-Next-Web/issues/165) [#5353](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/issues/5353)
- [x] Supports Realtime Chat [#5672](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/issues/5672)
- [ ] local knowledge base

## What&#039;s New

- üöÄ v2.15.8 Now supports Realtime Chat [#5672](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/issues/5672)
- üöÄ v2.15.4 The Application supports using Tauri fetch LLM API, MORE SECURITY! [#5379](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/issues/5379)
- üöÄ v2.15.0 Now supports Plugins! Read this: [NextChat-Awesome-Plugins](https://github.com/ChatGPTNextWeb/NextChat-Awesome-Plugins)
- üöÄ v2.14.0 Now supports Artifacts &amp; SD
- üöÄ v2.10.1 support Google Gemini Pro model.
- üöÄ v2.9.11 you can use azure endpoint now.
- üöÄ v2.8 now we have a client that runs across all platforms!
- üöÄ v2.7 let&#039;s share conversations as image, or share to ShareGPT!
- üöÄ v2.0 is released, now you can create prompt templates, turn your ideas into reality! Read this: [ChatGPT Prompt Engineering Tips: Zero, One and Few Shot Prompting](https://www.allabtai.com/prompt-engineering-tips-zero-one-and-few-shot-prompting/).

## Get Started

1. Get [OpenAI API Key](https://platform.openai.com/account/api-keys);
2. Click
   [![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FYidadaa%2FChatGPT-Next-Web&amp;env=OPENAI_API_KEY&amp;env=CODE&amp;project-name=chatgpt-next-web&amp;repository-name=ChatGPT-Next-Web), remember that `CODE` is your page password;
3. Enjoy :)

## FAQ

[English &gt; FAQ](./docs/faq-en.md)

## Keep Updated

If you have deployed your own project with just one click following the steps above, you may encounter the issue of &quot;Updates Available&quot; constantly showing up. This is because Vercel will create a new project for you by default instead of forking this project, resulting in the inability to detect updates correctly.

We recommend that you follow the steps below to re-deploy:

- Delete the original repository;
- Use the fork button in the upper right corner of the page to fork this project;
- Choose and deploy in Vercel again, [please see the detailed tutorial](./docs/vercel-cn.md).

### Enable Automatic Updates

&gt; If you encounter a failure of Upstream Sync execution, please [manually update code](./README.md#manually-updating-code).

After forking the project, due to the limitations imposed by GitHub, you need to manually enable Workflows and Upstream Sync Action on the Actions page of the forked project. Once enabled, automatic updates will be scheduled every hour:

![Automatic Updates](./docs/images/enable-actions.jpg)

![Enable Automatic Updates](./docs/images/enable-actions-sync.jpg)

### Manually Updating Code

If you want to update instantly, you can check out the [GitHub documentation](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/syncing-a-fork) to learn how to synchronize a forked project with upstream code.

You can star or watch this project or follow author to get release notifications in time.

## Access Password

This project provides limited access control. Please add an environment variable named `CODE` on the vercel environment variables page. The value should be passwords separated by comma like this:

```
code1,code2,code3
```

After adding or modifying this environment variable, please redeploy the project for the changes to take effect.

## Environment Variables

### `CODE` (optional)

Access password, separated by comma.

### `OPENAI_API_KEY` (required)

Your openai api key, join multiple api keys with comma.

### `BASE_URL` (optional)

&gt; Default: `https://api.openai.com`

&gt; Examples: `http://your-openai-proxy.com`

Override openai api request base url.

### `OPENAI_ORG_ID` (optional)

Specify OpenAI organization ID.

### `AZURE_URL` (optional)

&gt; Example: https://{azure-resource-url}/openai

Azure deploy url.

### `AZURE_API_KEY` (optional)

Azure Api Key.

### `AZURE_API_VERSION` (optional)

Azure Api Version, find it at [Azure Documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#chat-completions).

### `GOOGLE_API_KEY` (optional)

Google Gemini Pro Api Key.

### `GOOGLE_URL` (optional)

Google Gemini Pro Api Url.

### `ANTHROPIC_API_KEY` (optional)

anthropic claude Api Key.

### `ANTHROPIC_API_VERSION` (optional)

anthropic claude Api version.

### `ANTHROPIC_URL` (optional)

anthropic claude Api Url.

### `BAIDU_API_KEY` (optional)

Baidu Api Key.

### `BAIDU_SECRET_KEY` (optional)

Baidu Secret Key.

### `BAIDU_URL` (optional)

Baidu Api Url.

### `BYTEDANCE_API_KEY` (optional)

ByteDance Api Key.

### `BYTEDANCE_URL` (optional)

ByteDance Api Url.

### `ALIBABA_API_KEY` (optional)

Alibaba Cloud Api Key.

### `ALIBABA_URL` (optional)

Alibaba Cloud Api Url.

### `IFLYTEK_URL` (Optional)

iflytek Api Url.

### `IFLYTEK_API_KEY` (Optional)

iflytek Api Key.

### `IFLYTEK_API_SECRET` (Optional)

iflytek Api Secret.

### `CHATGLM_API_KEY` (optional)

ChatGLM Api Key.

### `CHATGLM_URL` (optional)

ChatGLM Api Url.

### `DEEPSEEK_API_KEY` (optional)

DeepSeek Api Key.

### `DEEPSEEK_URL` (optional)

DeepSeek Api Url.

### `HIDE_USER_API_KEY` (optional)

&gt; Default: Empty

If you do not want users to input their own API key, set this value to 1.

### `DISABLE_GPT4` (optional)

&gt; Default: Empty

If you do not want users to use GPT-4, set this value to 1.

### `ENABLE_BALANCE_QUERY` (optional)

&gt; Default: Empty

If you do want users to query balance, set this value to 1.

### `DISABLE_FAST_LINK` (optional)

&gt; Default: Empty

If you want to disable parse settings from url, set this to 1.

### `CUSTOM_MODELS` (optional)

&gt; Default: Empty
&gt; Example: `+llama,+claude-2,-gpt-3.5-turbo,gpt-4-1106-preview=gpt-4-turbo` means add `llama, claude-2` to model list, and remove `gpt-3.5-turbo` from list, and display `gpt-4-1106-preview` as `gpt-4-turbo`.

To control custom models, use `+` to add a custom model, use `-` to hide a model, use `name=displayName` to customize model name, separated by comma.

User `-all` to disable all default models, `+all` to enable all default models.

For Azure: use `modelName@Azure=deploymentName` to customize model name and deployment name.

&gt; Example: `+gpt-3.5-turbo@Azure=gpt35` will show option `gpt35(Azure)` in model list.
&gt; If you only can use Azure model, `-all,+gpt-3.5-turbo@Azure=gpt35` will `gpt35(Azure)` the only option in model list.

For ByteDance: use `modelName@bytedance=deploymentName` to customize model name and deployment name.

&gt; Example: `+Doubao-lite-4k@bytedance=ep-xxxxx-xxx` will show option `Doubao-lite-4k(ByteDance)` in model list.

### `DEFAULT_MODEL` ÔºàoptionalÔºâ

Change default model

### `VISION_MODELS` (optional)

&gt; Default: Empty
&gt; Example: `gpt-4-vision,claude-3-opus,my-custom-model` means add vision capabilities to these models in addition to the default pattern matches (which detect models containing keywords like &quot;vision&quot;, &quot;claude-3&quot;, &quot;gemini-1.5&quot;, etc).

Add additional models to have vision capabilities, beyond the default pattern matching. Multiple models should be separated by commas.

### `WHITE_WEBDAV_ENDPOINTS` (optional)

You can use this option if you want to increase the number of webdav service addresses you are allowed to access, as required by the formatÔºö

- Each address must be a complete endpoint
  &gt; `https://xxxx/yyy`
- Multiple addresses are connected by &#039;, &#039;

### `DEFAULT_INPUT_TEMPLATE` (optional)

Customize the default template used to initialize the User Input Preprocessing configuration item in Settings.

### `STABILITY_API_KEY` (optional)

Stability API key.

### `STABILITY_URL` (optional)

Customize Stability API url.

### `ENABLE_MCP` (optional)

Enable MCPÔºàModel Context ProtocolÔºâFeature

### `SILICONFLOW_API_KEY` (optional)

SiliconFlow API Key.

### `SILICONFLOW_URL` (optional)

SiliconFlow API URL.

### `AI302_API_KEY` (optional)

302.AI API Key.

### `AI302_URL` (optional)

302.AI API URL.

## Requirements

NodeJS &gt;= 18, Docker &gt;= 20

## Development

[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/Yidadaa/ChatGPT-Next-Web)

Before starting development, you must create a new `.env.local` file at project root, and place your api key into it:

```
OPENAI_API_KEY=&lt;your api key here&gt;

# if you are not able to access openai service, use this BASE_URL
BASE_URL=https://chatgpt1.nextweb.fun/api/proxy
```

### Local Development

```shell
# 1. install nodejs and yarn first
# 2. config local env vars in `.env.local`
# 3. run
yarn install
yarn dev
```

## Deployment

### Docker (Recommended)

```shell
docker pull yidadaa/chatgpt-next-web

docker run -d -p 3000:3000 \
   -e OPENAI_API_KEY=sk-xxxx \
   -e CODE=your-password \
   yidadaa/chatgpt-next-web
```

You can start service behind a proxy:

```shell
docker run -d -p 3000:3000 \
   -e OPENAI_API_KEY=sk-xxxx \
   -e CODE=your-password \
   -e PROXY_URL=http://localhost:7890 \
   yidadaa/chatgpt-next-web
```

If your proxy needs password, use:

```shell
-e PROXY_URL=&quot;http://127.0.0.1:7890 user pass&quot;
```

If enable MCP, useÔºö

```
docker run -d -p 3000:3000 \
   -e OPENAI_API_KEY=sk-xxxx \
   -e CODE=your-password \
   -e ENABLE_MCP=true \
   yidadaa/chatgpt-next-web
```

### Shell

```shell
bash &lt;(curl -s https://raw.githubusercontent.com/Yidadaa/ChatGPT-Next-Web/main/scripts/setup.sh)
```

## Synchronizing Chat Records (UpStash)

| [ÁÆÄ‰Ωì‰∏≠Êñá](./docs/synchronise-chat-logs-cn.md) | [English](./docs/synchronise-chat-logs-en.md) | [Italiano](./docs/synchronise-chat-logs-es.md) | [Êó•Êú¨Ë™û](./docs/synchronise-chat-logs-ja.md) | [ÌïúÍµ≠Ïñ¥](./docs/synchronise-chat-logs-ko.md)

## Documentation

&gt; Please go to the [docs][./docs] directory for more documentation instructions.

- [Deploy with cloudflare (Deprecated)](./docs/cloudflare-pages-en.md)
- [Frequent Ask Questions](./docs/faq-en.md)
- [How to add a new translation](./docs/translation.md)
- [How to use Vercel (No English)](./docs/vercel-cn.md)
- [User Manual (Only Chinese, WIP)](./docs/user-manual-cn.md)

## Translation

If you want to add a new translation, read this [document](./docs/translation.md).

## Donation

[Buy Me a Coffee](https://www.buymeacoffee.com/yidadaa)

## Special Thanks

### Contributors

&lt;a href=&quot;https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=ChatGPTNextWeb/ChatGPT-Next-Web&quot; /&gt;
&lt;/a&gt;

## LICENSE

[MIT](https://opensource.org/license/mit/)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[chaitin/PandaWiki]]></title>
            <link>https://github.com/chaitin/PandaWiki</link>
            <guid>https://github.com/chaitin/PandaWiki</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[PandaWiki ÊòØ‰∏ÄÊ¨æ AI Â§ßÊ®°ÂûãÈ©±Âä®ÁöÑÂºÄÊ∫êÁü•ËØÜÂ∫ìÊê≠Âª∫Á≥ªÁªüÔºåÂ∏ÆÂä©‰Ω†Âø´ÈÄüÊûÑÂª∫Êô∫ËÉΩÂåñÁöÑ ‰∫ßÂìÅÊñáÊ°£„ÄÅÊäÄÊúØÊñáÊ°£„ÄÅFAQ„ÄÅÂçöÂÆ¢Á≥ªÁªüÔºåÂÄüÂä©Â§ßÊ®°ÂûãÁöÑÂäõÈáè‰∏∫‰Ω†Êèê‰æõ AI Âàõ‰Ωú„ÄÅAI ÈóÆÁ≠î„ÄÅAI ÊêúÁ¥¢Á≠âËÉΩÂäõ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/chaitin/PandaWiki">chaitin/PandaWiki</a></h1>
            <p>PandaWiki ÊòØ‰∏ÄÊ¨æ AI Â§ßÊ®°ÂûãÈ©±Âä®ÁöÑÂºÄÊ∫êÁü•ËØÜÂ∫ìÊê≠Âª∫Á≥ªÁªüÔºåÂ∏ÆÂä©‰Ω†Âø´ÈÄüÊûÑÂª∫Êô∫ËÉΩÂåñÁöÑ ‰∫ßÂìÅÊñáÊ°£„ÄÅÊäÄÊúØÊñáÊ°£„ÄÅFAQ„ÄÅÂçöÂÆ¢Á≥ªÁªüÔºåÂÄüÂä©Â§ßÊ®°ÂûãÁöÑÂäõÈáè‰∏∫‰Ω†Êèê‰æõ AI Âàõ‰Ωú„ÄÅAI ÈóÆÁ≠î„ÄÅAI ÊêúÁ¥¢Á≠âËÉΩÂäõ„ÄÇ</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,421</p>
            <p>Forks: 581</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/images/banner.png&quot; width=&quot;400&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://ly.safepoint.cloud/Br48PoX&quot;&gt;üìñ ÂÆòÊñπÁΩëÁ´ô&lt;/a&gt; &amp;nbsp; | &amp;nbsp;
  &lt;a target=&quot;_blank&quot; href=&quot;/images/wechat.png&quot;&gt;üôã‚Äç‚ôÇÔ∏è ÂæÆ‰ø°‰∫§ÊµÅÁæ§&lt;/a&gt;
&lt;/p&gt;

## üëã È°πÁõÆ‰ªãÁªç

PandaWiki ÊòØ‰∏ÄÊ¨æ AI Â§ßÊ®°ÂûãÈ©±Âä®ÁöÑ**ÂºÄÊ∫êÁü•ËØÜÂ∫ìÊê≠Âª∫Á≥ªÁªü**ÔºåÂ∏ÆÂä©‰Ω†Âø´ÈÄüÊûÑÂª∫Êô∫ËÉΩÂåñÁöÑ **‰∫ßÂìÅÊñáÊ°£„ÄÅÊäÄÊúØÊñáÊ°£„ÄÅFAQ„ÄÅÂçöÂÆ¢Á≥ªÁªü**ÔºåÂÄüÂä©Â§ßÊ®°ÂûãÁöÑÂäõÈáè‰∏∫‰Ω†Êèê‰æõ **AI Âàõ‰Ωú„ÄÅAI ÈóÆÁ≠î„ÄÅAI ÊêúÁ¥¢** Á≠âËÉΩÂäõ„ÄÇ

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/images/setup.png&quot; width=&quot;800&quot; /&gt;
&lt;/p&gt;

## ‚ö°Ô∏è ÁïåÈù¢Â±ïÁ§∫

| PandaWiki ÊéßÂà∂Âè∞                                 | Wiki ÁΩëÁ´ôÂâçÂè∞                                    |
| ------------------------------------------------ | ------------------------------------------------ |
| &lt;img src=&quot;/images/screenshot-1.png&quot; width=370 /&gt; | &lt;img src=&quot;/images/screenshot-2.png&quot; width=370 /&gt; |
| &lt;img src=&quot;/images/screenshot-3.png&quot; width=370 /&gt; | &lt;img src=&quot;/images/screenshot-4.png&quot; width=370 /&gt; |

## üî• ÂäüËÉΩ‰∏éÁâπËâ≤

- AI È©±Âä®Êô∫ËÉΩÂåñÔºöAI ËæÖÂä©Âàõ‰Ωú„ÄÅAI ËæÖÂä©ÈóÆÁ≠î„ÄÅAI ËæÖÂä©ÊêúÁ¥¢„ÄÇ
- Âº∫Â§ßÁöÑÂØåÊñáÊú¨ÁºñËæëËÉΩÂäõÔºöÂÖºÂÆπ Markdown Âíå HTMLÔºåÊîØÊåÅÂØºÂá∫‰∏∫ word„ÄÅpdf„ÄÅmarkdown Á≠âÂ§öÁßçÊ†ºÂºè„ÄÇ
- ËΩªÊùæ‰∏éÁ¨¨‰∏âÊñπÂ∫îÁî®ËøõË°åÈõÜÊàêÔºöÊîØÊåÅÂÅöÊàêÁΩëÈ°µÊåÇ‰ª∂ÊåÇÂú®ÂÖ∂‰ªñÁΩëÁ´ô‰∏äÔºåÊîØÊåÅÂÅöÊàêÈíâÈíâ„ÄÅÈ£û‰π¶„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°Á≠âËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇ
- ÈÄöËøáÁ¨¨‰∏âÊñπÊù•Ê∫êÂØºÂÖ•ÂÜÖÂÆπÔºöÊ†πÊçÆÁΩëÈ°µ URL ÂØºÂÖ•„ÄÅÈÄöËøáÁΩëÁ´ô Sitemap ÂØºÂÖ•„ÄÅÈÄöËøá RSS ËÆ¢ÈòÖ„ÄÅÈÄöËøáÁ¶ªÁ∫øÊñá‰ª∂ÂØºÂÖ•Á≠â„ÄÇ

## üöÄ ‰∏äÊâãÊåáÂçó

### ÂÆâË£Ö PandaWiki

‰Ω†ÈúÄË¶Å‰∏ÄÂè∞ÊîØÊåÅ Docker 20.x ‰ª•‰∏äÁâàÊú¨ÁöÑ Linux Á≥ªÁªüÊù•ÂÆâË£Ö PandaWiki„ÄÇ

‰ΩøÁî® root ÊùÉÈôêÁôªÂΩï‰Ω†ÁöÑÊúçÂä°Âô®ÔºåÁÑ∂ÂêéÊâßË°å‰ª•‰∏ãÂëΩ‰ª§„ÄÇ

```bash
bash -c &quot;$(curl -fsSLk https://release.baizhi.cloud/panda-wiki/manager.sh)&quot;
```

Ê†πÊçÆÂëΩ‰ª§ÊèêÁ§∫ÁöÑÈÄâÈ°πËøõË°åÂÆâË£ÖÔºåÂëΩ‰ª§ÊâßË°åËøáÁ®ãÂ∞Ü‰ºöÊåÅÁª≠Âá†ÂàÜÈíüÔºåËØ∑ËÄêÂøÉÁ≠âÂæÖ„ÄÇ

&gt; ÂÖ≥‰∫éÂÆâË£Ö‰∏éÈÉ®ÁΩ≤ÁöÑÊõ¥Â§öÁªÜËäÇËØ∑ÂèÇËÄÉ [ÂÆâË£Ö PandaWiki](https://pandawiki.docs.baizhi.cloud/node/01971602-bb4e-7c90-99df-6d3c38cfd6d5)„ÄÇ

### ÁôªÂΩï PandaWiki

Âú®‰∏ä‰∏ÄÊ≠•‰∏≠ÔºåÂÆâË£ÖÂëΩ‰ª§ÊâßË°åÁªìÊùüÂêéÔºå‰Ω†ÁöÑÁªàÁ´Ø‰ºöËæìÂá∫‰ª•‰∏ãÂÜÖÂÆπ„ÄÇ

```
SUCCESS  ÊéßÂà∂Âè∞‰ø°ÊÅØ:
SUCCESS    ËÆøÈóÆÂú∞ÂùÄ(ÂÜÖÁΩë): http://*.*.*.*:2443
SUCCESS    ËÆøÈóÆÂú∞ÂùÄ(Â§ñÁΩë): http://*.*.*.*:2443
SUCCESS    Áî®Êà∑Âêç: admin
SUCCESS    ÂØÜÁ†Å: **********************
```

‰ΩøÁî®ÊµèËßàÂô®ÊâìÂºÄ‰∏äËø∞ÂÜÖÂÆπ‰∏≠ÁöÑ ‚ÄúËÆøÈóÆÂú∞ÂùÄ‚ÄùÔºå‰Ω†Â∞ÜÁúãÂà∞ PandaWiki ÁöÑÊéßÂà∂Âè∞ÁôªÂΩïÂÖ•Âè£Ôºå‰ΩøÁî®‰∏äËø∞ÂÜÖÂÆπ‰∏≠ÁöÑ ‚ÄúÁî®Êà∑Âêç‚Äù Âíå ‚ÄúÂØÜÁ†Å‚Äù ÁôªÂΩïÂç≥ÂèØ„ÄÇ

### ÈÖçÁΩÆ AI Ê®°Âûã

&gt; PandaWiki ÊòØÁî± AI Â§ßÊ®°ÂûãÈ©±Âä®ÁöÑ Wiki Á≥ªÁªüÔºåÂú®Êú™ÈÖçÁΩÆÂ§ßÊ®°ÂûãÁöÑÊÉÖÂÜµ‰∏ã AI Âàõ‰Ωú„ÄÅAI ÈóÆÁ≠î„ÄÅAI ÊêúÁ¥¢ Á≠âÂäüËÉΩÊó†Ê≥ïÊ≠£Â∏∏‰ΩøÁî®„ÄÇ
&gt; 
È¶ñÊ¨°ÁôªÂΩïÊó∂‰ºöÊèêÁ§∫ÈúÄË¶ÅÂÖàÈÖçÁΩÆ AI Ê®°ÂûãÔºåÊ†πÊçÆ‰∏ãÊñπÂõæÁâáÈÖçÁΩÆ ‚ÄúChat Ê®°Âûã‚Äù„ÄÇ

&lt;img src=&quot;/images/modelconfig.png&quot; width=&quot;800&quot; /&gt;

&gt; Êé®Ëçê‰ΩøÁî® [ÁôæÊô∫‰∫ëÊ®°ÂûãÂπøÂú∫](https://baizhi.cloud/) Âø´ÈÄüÊé•ÂÖ• AI Ê®°ÂûãÔºåÊ≥®ÂÜåÂç≥ÂèØËé∑Ëµ† 5 ÂÖÉÁöÑÊ®°Âûã‰ΩøÁî®È¢ùÂ∫¶„ÄÇ
&gt; ÂÖ≥‰∫éÂ§ßÊ®°ÂûãÁöÑÊõ¥Â§öÈÖçÁΩÆÁªÜËäÇËØ∑ÂèÇËÄÉ [Êé•ÂÖ• AI Ê®°Âûã](https://pandawiki.docs.baizhi.cloud/node/01971616-811c-70e1-82d9-706a202b8498)„ÄÇ

### ÂàõÂª∫Áü•ËØÜÂ∫ì

‰∏ÄÂàáÈÖçÁΩÆÂ∞±Áª™ÂêéÔºå‰Ω†ÈúÄË¶ÅÂÖàÂàõÂª∫‰∏Ä‰∏™ ‚ÄúÁü•ËØÜÂ∫ì‚Äù„ÄÇ

‚ÄúÁü•ËØÜÂ∫ì‚Äù ÊòØ‰∏ÄÁªÑÊñáÊ°£ÁöÑÈõÜÂêàÔºåPandaWiki Â∞Ü‰ºöÊ†πÊçÆÁü•ËØÜÂ∫ì‰∏≠ÁöÑÊñáÊ°£Ôºå‰∏∫‰∏çÂêåÁöÑÁü•ËØÜÂ∫ìÂàÜÂà´ÂàõÂª∫ ‚ÄúWiki ÁΩëÁ´ô‚Äù„ÄÇ

&lt;img src=&quot;/images/createkb.png&quot; width=&quot;800&quot; /&gt;

&gt; ÂÖ≥‰∫éÁü•ËØÜÂ∫ìÁöÑÊõ¥Â§öÈÖçÁΩÆÁªÜËäÇËØ∑ÂèÇËÄÉ [Áü•ËØÜÂ∫ìËÆæÁΩÆ](https://pandawiki.docs.baizhi.cloud/node/01971b5e-5bea-76d2-9f89-a95f98347bb0)„ÄÇ

### üí™ ÂºÄÂßã‰ΩøÁî®

Â¶ÇÊûú‰Ω†È°∫Âà©ÂÆåÊàê‰∫Ü‰ª•‰∏äÊ≠•È™§ÔºåÈÇ£‰πàÊÅ≠Âñú‰Ω†ÔºåÂ±û‰∫é‰Ω†ÁöÑ PandaWiki Êê≠Âª∫ÊàêÂäüÔºå‰Ω†ÂèØ‰ª•Ôºö

- ËÆøÈóÆ **ÊéßÂà∂Âè∞** Êù•ÁÆ°ÁêÜ‰Ω†ÁöÑÁü•ËØÜÂ∫ìÂÜÖÂÆπ
- ËÆøÈóÆ **Wiki ÁΩëÁ´ô** ËÆ©‰Ω†ÁöÑÁî®Êà∑‰ΩøÁî®Áü•ËØÜÂ∫ì

## Á§æÂå∫‰∫§ÊµÅ

Ê¨¢ËøéÂä†ÂÖ•Êàë‰ª¨ÁöÑÂæÆ‰ø°Áæ§ËøõË°å‰∫§ÊµÅ„ÄÇ

&lt;img src=&quot;/images/wechat.png&quot; width=&quot;300&quot; /&gt;

## üôã‚Äç‚ôÇÔ∏è Ë¥°ÁåÆ

Ê¨¢ËøéÊèê‰∫§ [Pull Request](https://github.com/chaitin/PandaWiki/pulls) ÊàñÂàõÂª∫ [Issue](https://github.com/chaitin/PandaWiki/issues) Êù•Â∏ÆÂä©ÊîπËøõÈ°πÁõÆ„ÄÇ

## üìù ËÆ∏ÂèØËØÅ

Êú¨È°πÁõÆÈááÁî® GNU Affero General Public License v3.0 (AGPL-3.0) ËÆ∏ÂèØËØÅ„ÄÇËøôÊÑèÂë≥ÁùÄÔºö

- ‰Ω†ÂèØ‰ª•Ëá™Áî±‰ΩøÁî®„ÄÅ‰øÆÊîπÂíåÂàÜÂèëÊú¨ËΩØ‰ª∂
- ‰Ω†ÂøÖÈ°ª‰ª•Áõ∏ÂêåÁöÑËÆ∏ÂèØËØÅÂºÄÊ∫ê‰Ω†ÁöÑ‰øÆÊîπ
- Â¶ÇÊûú‰Ω†ÈÄöËøáÁΩëÁªúÊèê‰æõÊúçÂä°Ôºå‰πüÂøÖÈ°ªÂºÄÊ∫ê‰Ω†ÁöÑ‰ª£Á†Å
- ÂïÜ‰∏ö‰ΩøÁî®ÈúÄË¶ÅÈÅµÂÆàÁõ∏ÂêåÁöÑÂºÄÊ∫êË¶ÅÊ±Ç


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=chaitin/PandaWiki&amp;type=Date)](https://www.star-history.com/#chaitin/PandaWiki&amp;Date)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[bytedance/UI-TARS-desktop]]></title>
            <link>https://github.com/bytedance/UI-TARS-desktop</link>
            <guid>https://github.com/bytedance/UI-TARS-desktop</guid>
            <pubDate>Mon, 13 Oct 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytedance/UI-TARS-desktop">bytedance/UI-TARS-desktop</a></h1>
            <p>The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra</p>
            <p>Language: TypeScript</p>
            <p>Stars: 19,146</p>
            <p>Forks: 1,878</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
  &lt;img alt=&quot;Agent TARS Banner&quot; src=&quot;./images/tars.png&quot;&gt;
&lt;/picture&gt;

&lt;br/&gt;

## Introduction

English | [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md)

[![](https://trendshift.io/api/badge/repositories/13584)](https://trendshift.io/repositories/13584)

&lt;b&gt;TARS&lt;sup&gt;\*&lt;/sup&gt;&lt;/b&gt; is a Multimodal AI Agent stack, currently shipping two projects: [Agent TARS](#agent-tars) and [UI-TARS-desktop](#ui-tars-desktop):

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th width=&quot;50%&quot; align=&quot;center&quot;&gt;&lt;a href=&quot;#agent-tars&quot;&gt;Agent TARS&lt;/a&gt;&lt;/th&gt;
      &lt;th width=&quot;50%&quot; align=&quot;center&quot;&gt;&lt;a href=&quot;#ui-tars-desktop&quot;&gt;UI-TARS-desktop&lt;/a&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;video src=&quot;https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d&quot; width=&quot;50%&quot;&gt;&lt;/video&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;video src=&quot;https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27&quot; width=&quot;50%&quot;&gt;&lt;/video&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;left&quot;&gt;
        &lt;b&gt;Agent TARS&lt;/b&gt; is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product.
        &lt;br&gt;
        &lt;br&gt;
        It primarily ships with a &lt;a href=&quot;https://agent-tars.com/guide/basic/cli.html&quot; target=&quot;_blank&quot;&gt;CLI&lt;/a&gt; and &lt;a href=&quot;https://agent-tars.com/guide/basic/web-ui.html&quot; target=&quot;_blank&quot;&gt;Web UI&lt;/a&gt; for usage.
        It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world &lt;a href=&quot;https://agent-tars.com/guide/basic/mcp.html&quot; target=&quot;_blank&quot;&gt;MCP&lt;/a&gt; tools.
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;
        &lt;b&gt;UI-TARS Desktop&lt;/b&gt; is a desktop application that provides a native GUI Agent based on the &lt;a href=&quot;https://github.com/bytedance/UI-TARS&quot; target=&quot;_blank&quot;&gt;UI-TARS&lt;/a&gt; model.
        &lt;br&gt;
        &lt;br&gt;
        It primarily ships a
        &lt;a href=&quot;https://github.com/bytedance/UI-TARS-desktop/blob/main/docs/quick-start.md#get-model-and-run-local-operator&quot; target=&quot;_blank&quot;&gt;local&lt;/a&gt; and 
        &lt;a href=&quot;https://github.com/bytedance/UI-TARS-desktop/blob/main/docs/quick-start.md#run-remote-operator&quot; target=&quot;_blank&quot;&gt;remote&lt;/a&gt; computer as well as browser operators.
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

## Table of Contents

&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt;
&lt;!-- DON&#039;T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt;

- [News](#news)
- [Agent TARS](#agent-tars)
  - [Showcase](#showcase)
  - [Core Features](#core-features)
  - [Quick Start](#quick-start)
  - [Documentation](#documentation)
- [UI-TARS Desktop](#ui-tars-desktop)
  - [Showcase](#showcase-1)
  - [Features](#features)
  - [Quick Start](#quick-start-1)
- [Contributing](#contributing)
- [License](#license)
- [Citation](#citation)

&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt;

## News

- **\[2025-06-25\]** We released a Agent TARS Beta and Agent TARS CLI - [Introducing Agent TARS Beta](https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html), a multimodal AI agent that aims to explore a work form that is closer to human-like task completion through rich multimodal capabilities (such as GUI Agent, Vision) and seamless integration with various real-world tools.
- **\[2025-06-12\]** - üéÅ We are thrilled to announce the release of UI-TARS Desktop v0.2.0! This update introduces two powerful new features: **Remote Computer Operator** and **Remote Browser Operator**‚Äîboth completely free. No configuration required: simply click to remotely control any computer or browser, and experience a new level of convenience and intelligence.
- **\[2025-04-17\]** - üéâ We&#039;re thrilled to announce the release of new UI-TARS Desktop application v0.1.0, featuring a redesigned Agent UI. The application enhances the computer using experience, introduces new browser operation features, and supports [the advanced UI-TARS-1.5 model](https://seed-tars.com/1.5) for improved performance and precise control.
- **\[2025-02-20\]** - üì¶ Introduced [UI TARS SDK](./docs/sdk.md), is a powerful cross-platform toolkit for building GUI automation agents.
- **\[2025-01-23\]** - üöÄ We updated the **[Cloud Deployment](./docs/deployment.md#cloud-deployment)** section in the ‰∏≠ÊñáÁâà: [GUIÊ®°ÂûãÈÉ®ÁΩ≤ÊïôÁ®ã](https://bytedance.sg.larkoffice.com/docx/TCcudYwyIox5vyxiSDLlgIsTgWf#U94rdCxzBoJMLex38NPlHL21gNb) with new information related to the ModelScope platform. You can now use the ModelScope platform for deployment.

&lt;br&gt;

## Agent TARS

&lt;p&gt;
    &lt;a href=&quot;https://npmjs.com/package/@agent-tars/cli?activeTab=readme&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@agent-tars/cli?style=for-the-badge&amp;colorA=1a1a2e&amp;colorB=3B82F6&amp;logo=npm&amp;logoColor=white&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://npmcharts.com/compare/@agent-tars/cli?minimal=true&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/@agent-tars/cli.svg?style=for-the-badge&amp;colorA=1a1a2e&amp;colorB=0EA5E9&amp;logo=npm&amp;logoColor=white&quot; alt=&quot;downloads&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://nodejs.org/en/about/previous-releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/node/v/@agent-tars/cli.svg?style=for-the-badge&amp;colorA=1a1a2e&amp;colorB=06B6D4&amp;logo=node.js&amp;logoColor=white&quot; alt=&quot;node version&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/HnKcSBgTVx&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20Community-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Discord Community&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/agent_tars&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Twitter-Follow%20%40agent__tars-1DA1F2?style=for-the-badge&amp;logo=twitter&amp;logoColor=white&quot; alt=&quot;Official Twitter&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://applink.larkoffice.com/client/chat/chatter/add_by_link?link_token=deen76f4-ea3c-4964-93a3-78f126f39651&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/È£û‰π¶Áæ§-Âä†ÂÖ•‰∫§ÊµÅÁæ§-00D4AA?style=for-the-badge&amp;logo=lark&amp;logoColor=white&quot; alt=&quot;È£û‰π¶‰∫§ÊµÅÁæ§&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://deepwiki.com/bytedance/UI-TARS-desktop&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/DeepWiki-Ask%20AI-8B5CF6?style=for-the-badge&amp;logo=gitbook&amp;logoColor=white&quot; alt=&quot;Ask DeepWiki&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;b&gt;Agent TARS&lt;/b&gt; is a general multimodal AI Agent stack, it brings the power of GUI Agent and Vision into your terminal, computer, browser and product. &lt;br&gt; &lt;br&gt;
It primarily ships with a &lt;a href=&quot;https://agent-tars.com/guide/basic/cli.html&quot; target=&quot;_blank&quot;&gt;CLI&lt;/a&gt; and &lt;a href=&quot;https://agent-tars.com/guide/basic/web-ui.html&quot; target=&quot;_blank&quot;&gt;Web UI&lt;/a&gt; for usage.
It aims to provide a workflow that is closer to human-like task completion through cutting-edge multimodal LLMs and seamless integration with various real-world &lt;a href=&quot;https://agent-tars.com/guide/basic/mcp.html&quot; target=&quot;_blank&quot;&gt;MCP&lt;/a&gt; tools.


### Showcase

```
Please help me book the earliest flight from San Jose to New York on September 1st and the last return flight on September 6th on Priceline
```

https://github.com/user-attachments/assets/772b0eef-aef7-4ab9-8cb0-9611820539d8

&lt;br&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th width=&quot;50%&quot; align=&quot;center&quot;&gt;Booking Hotel&lt;/th&gt;
      &lt;th width=&quot;50%&quot; align=&quot;center&quot;&gt;Generate Chart with extra MCP Servers&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;video src=&quot;https://github.com/user-attachments/assets/c9489936-afdc-4d12-adda-d4b90d2a869d&quot; width=&quot;50%&quot;&gt;&lt;/video&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;video src=&quot;https://github.com/user-attachments/assets/a9fd72d0-01bb-4233-aa27-ca95194bbce9&quot; width=&quot;50%&quot;&gt;&lt;/video&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;left&quot;&gt;
        &lt;b&gt;Instruction:&lt;/b&gt; &lt;i&gt;I am in Los Angeles from September 1st to September 6th, with a budget of $5,000. Please help me book a Ritz-Carlton hotel closest to the airport on booking.com and compile a transportation guide for me&lt;/i&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;
        &lt;b&gt;Instruction:&lt;/b&gt; &lt;i&gt;Draw me a chart of Hangzhou&#039;s weather for one month&lt;/i&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

For more use cases, please check out [#842](https://github.com/bytedance/UI-TARS-desktop/issues/842).

### Core Features

- üñ±Ô∏è **One-Click Out-of-the-box CLI** - Supports both **headful** [Web UI](https://agent-tars.com/guide/basic/web-ui.html) and **headless** [server](https://agent-tars.com/guide/advanced/server.html)) [execution](https://agent-tars.com/guide/basic/cli.html).
- üåê **Hybrid Browser Agent** - Control browsers using [GUI Agent](https://agent-tars.com/guide/basic/browser.html#visual-grounding), [DOM](https://agent-tars.com/guide/basic/browser.html#dom), or a hybrid strategy.
- üîÑ **Event Stream** - Protocol-driven Event Stream drives [Context Engineering](https://agent-tars.com/beta#context-engineering) and [Agent UI](https://agent-tars.com/blog/2025-06-25-introducing-agent-tars-beta.html#easy-to-build-applications).
- üß∞ **MCP Integration** - The kernel is built on MCP and also supports mounting [MCP Servers](https://agent-tars.com/guide/basic/mcp.html) to connect to real-world tools.

### Quick Start

&lt;img alt=&quot;Agent TARS CLI&quot; src=&quot;https://agent-tars.com/agent-tars-cli.png&quot;&gt;

```bash
# Luanch with `npx`.
npx @agent-tars/cli@latest

# Install globally, required Node.js &gt;= 22
npm install @agent-tars/cli@latest -g

# Run with your preferred model provider
agent-tars --provider volcengine --model doubao-1-5-thinking-vision-pro-250428 --apiKey your-api-key
agent-tars --provider anthropic --model claude-3-7-sonnet-latest --apiKey your-api-key
```

Visit the comprehensive [Quick Start](https://agent-tars.com/guide/get-started/quick-start.html) guide for detailed setup instructions.

### Documentation

&gt; üåü **Explore Agent TARS Universe** üåü

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th width=&quot;20%&quot; align=&quot;center&quot;&gt;Category&lt;/th&gt;
      &lt;th width=&quot;30%&quot; align=&quot;center&quot;&gt;Resource Link&lt;/th&gt;
      &lt;th width=&quot;50%&quot; align=&quot;left&quot;&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;üè† &lt;strong&gt;Central Hub&lt;/strong&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://agent-tars.com&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/Visit-Website-4F46E5?style=for-the-badge&amp;logo=globe&amp;logoColor=white&quot; alt=&quot;Website&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;Your gateway to Agent TARS ecosystem&lt;/td&gt;
    &lt;/tr&gt;
      &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;üìö &lt;strong&gt;Quick Start&lt;/strong&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://agent-tars.com/guide/get-started/quick-start.html&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/Get-Started-06B6D4?style=for-the-badge&amp;logo=rocket&amp;logoColor=white&quot; alt=&quot;Quick Start&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;Zero to hero in 5 minutes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;üöÄ &lt;strong&gt;What&#039;s New&lt;/strong&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://agent-tars.com/beta&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/Read-Blog-F59E0B?style=for-the-badge&amp;logo=rss&amp;logoColor=white&quot; alt=&quot;Blog&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;Discover cutting-edge features &amp; vision&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;üõ†Ô∏è &lt;strong&gt;Developer Zone&lt;/strong&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://agent-tars.com/guide/get-started/introduction.html&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/View-Docs-10B981?style=for-the-badge&amp;logo=gitbook&amp;logoColor=white&quot; alt=&quot;Docs&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;Master every command &amp; features&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;üéØ &lt;strong&gt;Showcase&lt;/strong&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://github.com/bytedance/UI-TARS-desktop/issues/842&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/View-Examples-8B5CF6?style=for-the-badge&amp;logo=github&amp;logoColor=white&quot; alt=&quot;Examples&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;View use cases built by the official and community&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;üîß &lt;strong&gt;Reference&lt;/strong&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://agent-tars.com/api/&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/API-Reference-EF4444?style=for-the-badge&amp;logo=book&amp;logoColor=white&quot; alt=&quot;API&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;left&quot;&gt;Complete technical reference&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;

## UI-TARS Desktop

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;UI-TARS&quot; width=&quot;260&quot; src=&quot;./apps/ui-tars/resources/icon.png&quot;&gt;
&lt;/p&gt;

UI-TARS Desktop is a native GUI agent for your local computer, driven by [UI-TARS](https://github.com/bytedance/UI-TARS) and Seed-1.5-VL/1.6 series models.

&lt;div align=&quot;center&quot;&gt;
&lt;p&gt;
        &amp;nbsp&amp;nbsp üìë &lt;a href=&quot;https://arxiv.org/abs/2501.12326&quot;&gt;Paper&lt;/a&gt; &amp;nbsp&amp;nbsp
        | ü§ó &lt;a href=&quot;https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B&quot;&gt;Hugging Face Models&lt;/a&gt;&amp;nbsp&amp;nbsp
        | &amp;nbsp&amp;nbspü´® &lt;a href=&quot;https://discord.gg/pTXwYVjfcs&quot;&gt;Discord&lt;/a&gt;&amp;nbsp&amp;nbsp
        | &amp;nbsp&amp;nbspü§ñ &lt;a href=&quot;https://www.modelscope.cn/collections/UI-TARS-bccb56fa1ef640&quot;&gt;ModelScope&lt;/a&gt;&amp;nbsp&amp;nbsp
&lt;br&gt;
üñ•Ô∏è Desktop Application &amp;nbsp&amp;nbsp
| &amp;nbsp&amp;nbsp üëì &lt;a href=&quot;https://github.com/web-infra-dev/midscene&quot;&gt;Midscene (use in browser)&lt;/a&gt; &amp;nbsp&amp;nbsp
&lt;/p&gt;

&lt;/div&gt;

### Showcase

&lt;!-- // FIXME: Choose only two demo, one local computer and one remote computer showcase. --&gt;

|                                                          Instruction                                                           |                                                Local Operator                                                |                                               Remote Operator                                                |
| :----------------------------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------: |
| Please help me open the autosave feature of VS Code and delay AutoSave operations for 500 milliseconds in the VS Code setting. | &lt;video src=&quot;https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27&quot; height=&quot;300&quot; /&gt; | &lt;video src=&quot;https://github.com/user-attachments/assets/01e49b69-7070-46c8-b3e3-2aaaaec71800&quot; height=&quot;300&quot; /&gt; |
|                    Could you help me check the latest open issue of the UI-TARS-Desktop project on GitHub?                     | &lt;video src=&quot;https://github.com/user-attachments/assets/3d159f54-d24a-4268-96c0-e149607e9199&quot; height=&quot;300&quot; /&gt; | &lt;video src=&quot;https://github.com/user-attachments/assets/072fb72d-7394-4bfa-95f5-4736e29f7e58&quot; height=&quot;300&quot; /&gt; |

### Features

- ü§ñ Natural language control powered by Vision-Language Model
- üñ•Ô∏è Screenshot and visual recognition support
- üéØ Precise mouse and keyboard control
- üíª Cross-platform support (Windows/MacOS/Browser)
- üîÑ Real-time feedback and status display
- üîê Private and secure - fully local processing

### Quick Start

See [Quick Start](./docs/quick-start.md)

## Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md).

## License

This project is licensed under the Apache License 2.0.

## Citation

If you find our paper and code useful in your research, please consider giving a star :star: and citation :pencil:

```BibTeX
@article{qin2025ui,
  title={UI-TARS: Pioneering Automated GUI Interaction with Native Agents},
  author={Qin, Yujia and Ye, Yining and Fang, Junjie and Wang, Haoming and Liang, Shihao and Tian, Shizuo and Zhang, Junda and Li, Jiahao and Li, Yunxin and Huang, Shijue and others},
  journal={arXiv preprint arXiv:2501.12326},
  year={2025}
}
```</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>