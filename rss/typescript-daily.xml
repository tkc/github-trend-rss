<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Sat, 04 Oct 2025 00:05:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[Infisical/infisical]]></title>
            <link>https://github.com/Infisical/infisical</link>
            <guid>https://github.com/Infisical/infisical</guid>
            <pubDate>Sat, 04 Oct 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[Infisical is the open-source platform for secrets management, PKI, and SSH access.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Infisical/infisical">Infisical/infisical</a></h1>
            <p>Infisical is the open-source platform for secrets management, PKI, and SSH access.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 20,287</p>
            <p>Forks: 1,387</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img width=&quot;300&quot; src=&quot;/img/logoname-white.svg#gh-dark-mode-only&quot; alt=&quot;infisical&quot;&gt;
&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;p align=&quot;center&quot;&gt;&lt;b&gt;The open-source secret management platform&lt;/b&gt;: Sync secrets/configs across your team/infrastructure and prevent secret leaks.&lt;/p&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://infisical.com/slack&quot;&gt;Slack&lt;/a&gt; |
  &lt;a href=&quot;https://infisical.com/&quot;&gt;Infisical Cloud&lt;/a&gt; |
  &lt;a href=&quot;https://infisical.com/docs/self-hosting/overview&quot;&gt;Self-Hosting&lt;/a&gt; |
  &lt;a href=&quot;https://infisical.com/docs/documentation/getting-started/introduction&quot;&gt;Docs&lt;/a&gt; |
  &lt;a href=&quot;https://www.infisical.com&quot;&gt;Website&lt;/a&gt; |
  &lt;a href=&quot;https://infisical.com/careers&quot;&gt;Hiring (Remote/SF)&lt;/a&gt;
&lt;/h4&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/Infisical/infisical/blob/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/license-MIT-blue.svg&quot; alt=&quot;Infisical is released under the MIT license.&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/infisical/infisical/blob/main/CONTRIBUTING.md&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/PRs-Welcome-brightgreen&quot; alt=&quot;PRs welcome!&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/Infisical/infisical/issues&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/commit-activity/m/infisical/infisical&quot; alt=&quot;git commit activity&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://cloudsmith.io/~infisical/repos/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Downloads-6.95M-orange&quot; alt=&quot;Cloudsmith downloads&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://infisical.com/slack&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/chat-on%20Slack-blueviolet&quot; alt=&quot;Slack community channel&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/infisical&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/twitter/follow/infisical?label=Follow&quot; alt=&quot;Infisical Twitter&quot; /&gt;
  &lt;/a&gt;
&lt;/h4&gt;

&lt;img src=&quot;/img/infisical_github_repo2.png&quot; width=&quot;100%&quot; alt=&quot;Dashboard&quot; /&gt;

## Introduction

**[Infisical](https://infisical.com)** is the open source secret management platform that teams use to centralize their application configuration and secrets like API keys and database credentials as well as manage their internal PKI.

We&#039;re on a mission to make security tooling more accessible to everyone, not just security teams, and that means redesigning the entire developer experience from ground up.

## Features

### Secrets Management:

- **[Dashboard](https://infisical.com/docs/documentation/platform/project)**: Manage secrets across projects and environments (e.g. development, production, etc.) through a user-friendly interface.
- **[Native Integrations](https://infisical.com/docs/integrations/overview)**: Sync secrets to platforms like [GitHub](https://infisical.com/docs/integrations/cicd/githubactions), [Vercel](https://infisical.com/docs/integrations/cloud/vercel), [AWS](https://infisical.com/docs/integrations/cloud/aws-secret-manager), and use tools like [Terraform](https://infisical.com/docs/integrations/frameworks/terraform), [Ansible](https://infisical.com/docs/integrations/platforms/ansible), and more.
- **[Secret versioning](https://infisical.com/docs/documentation/platform/secret-versioning)** and **[Point-in-Time Recovery](https://infisical.com/docs/documentation/platform/pit-recovery)**: Keep track of every secret and project state; roll back when needed.
- **[Secret Rotation](https://infisical.com/docs/documentation/platform/secret-rotation/overview)**: Rotate secrets at regular intervals for services like [PostgreSQL](https://infisical.com/docs/documentation/platform/secret-rotation/postgres-credentials), [MySQL](https://infisical.com/docs/documentation/platform/secret-rotation/mysql), [AWS IAM](https://infisical.com/docs/documentation/platform/secret-rotation/aws-iam), and more.
- **[Dynamic Secrets](https://infisical.com/docs/documentation/platform/dynamic-secrets/overview)**: Generate ephemeral secrets on-demand for services like [PostgreSQL](https://infisical.com/docs/documentation/platform/dynamic-secrets/postgresql), [MySQL](https://infisical.com/docs/documentation/platform/dynamic-secrets/mysql), [RabbitMQ](https://infisical.com/docs/documentation/platform/dynamic-secrets/rabbit-mq), and more.
- **[Secret Scanning and Leak Prevention](https://infisical.com/docs/cli/scanning-overview)**: Prevent secrets from leaking to git.
- **[Infisical Kubernetes Operator](https://infisical.com/docs/documentation/getting-started/kubernetes)**: Deliver secrets to your Kubernetes workloads and automatically reload deployments.
- **[Infisical Agent](https://infisical.com/docs/infisical-agent/overview)**: Inject secrets into applications without modifying any code logic.

### Infisical (Internal) PKI:

- **[Private Certificate Authority](https://infisical.com/docs/documentation/platform/pki/private-ca)**: Create CA hierarchies, configure [certificate templates](https://infisical.com/docs/documentation/platform/pki/certificates#guide-to-issuing-certificates) for policy enforcement, and start issuing X.509 certificates.
- **[Certificate Management](https://infisical.com/docs/documentation/platform/pki/certificates)**: Manage the certificate lifecycle from [issuance](https://infisical.com/docs/documentation/platform/pki/certificates#guide-to-issuing-certificates) to [revocation](https://infisical.com/docs/documentation/platform/pki/certificates#guide-to-revoking-certificates) with support for CRL.
- **[Alerting](https://infisical.com/docs/documentation/platform/pki/alerting)**: Configure alerting for expiring CA and end-entity certificates.
- **[Infisical PKI Issuer for Kubernetes](https://infisical.com/docs/documentation/platform/pki/pki-issuer)**: Deliver TLS certificates to your Kubernetes workloads with automatic renewal.
- **[Enrollment over Secure Transport](https://infisical.com/docs/documentation/platform/pki/est)**: Enroll and manage certificates via EST protocol.

### Infisical Key Management System (KMS):

- **[Cryptographic Keys](https://infisical.com/docs/documentation/platform/kms)**: Centrally manage keys across projects through a user-friendly interface or via the API.
- **[Encrypt and Decrypt Data](https://infisical.com/docs/documentation/platform/kms#guide-to-encrypting-data)**: Use symmetric keys to encrypt and decrypt data.

### Infisical SSH

- **[Signed SSH Certificates](https://infisical.com/docs/documentation/platform/ssh)**: Issue ephemeral SSH credentials for secure, short-lived, and centralized access to infrastructure.

### General Platform:

- **Authentication Methods**: Authenticate machine identities with Infisical using a cloud-native or platform agnostic authentication method ([Kubernetes Auth](https://infisical.com/docs/documentation/platform/identities/kubernetes-auth), [GCP Auth](https://infisical.com/docs/documentation/platform/identities/gcp-auth), [Azure Auth](https://infisical.com/docs/documentation/platform/identities/azure-auth), [AWS Auth](https://infisical.com/docs/documentation/platform/identities/aws-auth), [OIDC Auth](https://infisical.com/docs/documentation/platform/identities/oidc-auth/general), [Universal Auth](https://infisical.com/docs/documentation/platform/identities/universal-auth)).
- **[Access Controls](https://infisical.com/docs/documentation/platform/access-controls/overview)**: Define advanced authorization controls for users and machine identities with [RBAC](https://infisical.com/docs/documentation/platform/access-controls/role-based-access-controls), [additional privileges](https://infisical.com/docs/documentation/platform/access-controls/additional-privileges), [temporary access](https://infisical.com/docs/documentation/platform/access-controls/temporary-access), [access requests](https://infisical.com/docs/documentation/platform/access-controls/access-requests), [approval workflows](https://infisical.com/docs/documentation/platform/pr-workflows), and more.
- **[Audit logs](https://infisical.com/docs/documentation/platform/audit-logs)**: Track every action taken on the platform.
- **[Self-hosting](https://infisical.com/docs/self-hosting/overview)**: Deploy Infisical on-prem or cloud with ease; keep data on your own infrastructure.
- **[Infisical SDK](https://infisical.com/docs/sdks/overview)**: Interact with Infisical via client SDKs ([Node](https://infisical.com/docs/sdks/languages/node), [Python](https://github.com/Infisical/python-sdk-official?tab=readme-ov-file#infisical-python-sdk), [Go](https://infisical.com/docs/sdks/languages/go), [Ruby](https://infisical.com/docs/sdks/languages/ruby), [Java](https://infisical.com/docs/sdks/languages/java), [.NET](https://infisical.com/docs/sdks/languages/csharp))
- **[Infisical CLI](https://infisical.com/docs/cli/overview)**: Interact with Infisical via CLI; useful for injecting secrets into local development and CI/CD pipelines.
- **[Infisical API](https://infisical.com/docs/api-reference/overview/introduction)**: Interact with Infisical via API.

## Getting started

Check out the [Quickstart Guides](https://infisical.com/docs/getting-started/introduction)

| Use Infisical Cloud                                                                                                                                     | Deploy Infisical on premise                                                          |
| ------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------ |
| The fastest and most reliable way to &lt;br&gt; get started with Infisical is signing up &lt;br&gt; for free to [Infisical Cloud](https://app.infisical.com/login). | &lt;br&gt; View all [deployment options](https://infisical.com/docs/self-hosting/overview) |

### Run Infisical locally

To set up and run Infisical locally, make sure you have Git and Docker installed on your system. Then run the command for your system:

Linux/macOS:

```console
git clone https://github.com/Infisical/infisical &amp;&amp; cd &quot;$(basename $_ .git)&quot; &amp;&amp; cp .env.example .env &amp;&amp; docker compose -f docker-compose.prod.yml up
```

Windows Command Prompt:

```console
git clone https://github.com/Infisical/infisical &amp;&amp; cd infisical &amp;&amp; copy .env.example .env &amp;&amp; docker compose -f docker-compose.prod.yml up
```

Create an account at `http://localhost:80`

### Scan and prevent secret leaks

On top managing secrets with Infisical, you can also [scan for over 140+ secret types]() in your files, directories and git repositories.

To scan your full git history, run:

```
infisical scan --verbose
```

Install pre commit hook to scan each commit before you push to your repository

```
infisical scan install --pre-commit-hook
```

Learn about Infisical&#039;s code scanning feature [here](https://infisical.com/docs/cli/scanning-overview)

## Open-source vs. paid

This repo available under the [MIT expat license](https://github.com/Infisical/infisical/blob/main/LICENSE), with the exception of the `ee` directory which will contain premium enterprise features requiring a Infisical license.

If you are interested in managed Infisical Cloud of self-hosted Enterprise Offering, take a look at [our website](https://infisical.com/) or [book a meeting with us](https://infisical.cal.com/vlad/infisical-demo).

## Security

Please do not file GitHub issues or post on our public forum for security vulnerabilities, as they are public!

Infisical takes security issues very seriously. If you have any concerns about Infisical or believe you have uncovered a vulnerability, please get in touch via the e-mail address security@infisical.com. In the message, try to provide a description of the issue and ideally a way of reproducing it. The security team will get back to you as soon as possible.

Note that this security address should be used only for undisclosed vulnerabilities. Please report any security problems to us before disclosing it publicly.

## Contributing

Whether it&#039;s big or small, we love contributions. Check out our guide to see how to [get started](https://infisical.com/docs/contributing/getting-started).

Not sure where to get started? You can:

- Join our &lt;a href=&quot;https://infisical.com/slack&quot;&gt;Slack&lt;/a&gt;, and ask us any questions there.

## We are hiring!

If you&#039;re reading this, there is a strong chance you like the products we created.

You might also make a great addition to our team. We&#039;re growing fast and would love for you to [join us](https://infisical.com/careers).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[immich-app/immich]]></title>
            <link>https://github.com/immich-app/immich</link>
            <guid>https://github.com/immich-app/immich</guid>
            <pubDate>Sat, 04 Oct 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[High performance self-hosted photo and video management solution.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/immich-app/immich">immich-app/immich</a></h1>
            <p>High performance self-hosted photo and video management solution.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 79,448</p>
            <p>Forks: 4,172</p>
            <p>Stars today: 767 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt; 
  &lt;br/&gt;
  &lt;a href=&quot;https://opensource.org/license/agpl-v3&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-AGPL_v3-blue.svg?color=3F51B5&amp;style=for-the-badge&amp;label=License&amp;logoColor=000000&amp;labelColor=ececec&quot; alt=&quot;License: AGPLv3&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.immich.app&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/979116623879368755.svg?label=Discord&amp;logo=Discord&amp;style=for-the-badge&amp;logoColor=000000&amp;labelColor=ececec&quot; alt=&quot;Discord&quot;/&gt;
  &lt;/a&gt;
  &lt;br/&gt;
  &lt;br/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;design/immich-logo-stacked-light.svg&quot; width=&quot;300&quot; title=&quot;Login With Custom URL&quot;&gt;
&lt;/p&gt;
&lt;h3 align=&quot;center&quot;&gt;High performance self-hosted photo and video management solution&lt;/h3&gt;
&lt;br/&gt;
&lt;a href=&quot;https://immich.app&quot;&gt;
&lt;img src=&quot;design/immich-screenshots.png&quot; title=&quot;Main Screenshot&quot;&gt;
&lt;/a&gt;
&lt;br/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;readme_i18n/README_ca_ES.md&quot;&gt;Català&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_es_ES.md&quot;&gt;Español&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_fr_FR.md&quot;&gt;Français&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_it_IT.md&quot;&gt;Italiano&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ja_JP.md&quot;&gt;日本語&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ko_KR.md&quot;&gt;한국어&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_de_DE.md&quot;&gt;Deutsch&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_nl_NL.md&quot;&gt;Nederlands&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_tr_TR.md&quot;&gt;Türkçe&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_zh_CN.md&quot;&gt;中文&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_uk_UA.md&quot;&gt;Українська&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ru_RU.md&quot;&gt;Русский&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_pt_BR.md&quot;&gt;Português Brasileiro&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_sv_SE.md&quot;&gt;Svenska&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ar_JO.md&quot;&gt;العربية&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_vi_VN.md&quot;&gt;Tiếng Việt&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_th_TH.md&quot;&gt;ภาษาไทย&lt;/a&gt;
&lt;/p&gt;


&gt; [!WARNING]
&gt; ⚠️ Always follow [3-2-1](https://www.backblaze.com/blog/the-3-2-1-backup-strategy/) backup plan for your precious photos and videos!
&gt; 
 

&gt; [!NOTE]
&gt; You can find the main documentation, including installation guides, at https://immich.app/.

## Links

- [Documentation](https://docs.immich.app/)
- [About](https://docs.immich.app/overview/introduction)
- [Installation](https://docs.immich.app/install/requirements)
- [Roadmap](https://immich.app/roadmap)
- [Demo](#demo)
- [Features](#features)
- [Translations](https://docs.immich.app/developer/translations)
- [Contributing](https://docs.immich.app/overview/support-the-project)

## Demo

Access the demo [here](https://demo.immich.app). For the mobile app, you can use `https://demo.immich.app` for the `Server Endpoint URL`.

### Login credentials

| Email           | Password |
| --------------- | -------- |
| demo@immich.app | demo     |

## Features

| Features                                     | Mobile | Web |
| :------------------------------------------- | ------ | --- |
| Upload and view videos and photos            | Yes    | Yes |
| Auto backup when the app is opened           | Yes    | N/A |
| Prevent duplication of assets                | Yes    | Yes |
| Selective album(s) for backup                | Yes    | N/A |
| Download photos and videos to local device   | Yes    | Yes |
| Multi-user support                           | Yes    | Yes |
| Album and Shared albums                      | Yes    | Yes |
| Scrubbable/draggable scrollbar               | Yes    | Yes |
| Support raw formats                          | Yes    | Yes |
| Metadata view (EXIF, map)                    | Yes    | Yes |
| Search by metadata, objects, faces, and CLIP | Yes    | Yes |
| Administrative functions (user management)   | No     | Yes |
| Background backup                            | Yes    | N/A |
| Virtual scroll                               | Yes    | Yes |
| OAuth support                                | Yes    | Yes |
| API Keys                                     | N/A    | Yes |
| LivePhoto/MotionPhoto backup and playback    | Yes    | Yes |
| Support 360 degree image display             | No     | Yes |
| User-defined storage structure               | Yes    | Yes |
| Public Sharing                               | Yes    | Yes |
| Archive and Favorites                        | Yes    | Yes |
| Global Map                                   | Yes    | Yes |
| Partner Sharing                              | Yes    | Yes |
| Facial recognition and clustering            | Yes    | Yes |
| Memories (x years ago)                       | Yes    | Yes |
| Offline support                              | Yes    | No  |
| Read-only gallery                            | Yes    | Yes |
| Stacked Photos                               | Yes    | Yes |
| Tags                                         | No     | Yes |
| Folder View                                  | Yes    | Yes |

## Translations

Read more about translations [here](https://docs.immich.app/developer/translations).

&lt;a href=&quot;https://hosted.weblate.org/engage/immich/&quot;&gt;
&lt;img src=&quot;https://hosted.weblate.org/widget/immich/immich/multi-auto.svg&quot; alt=&quot;Translation status&quot; /&gt;
&lt;/a&gt;

## Repository activity

![Activities](https://repobeats.axiom.co/api/embed/9e86d9dc3ddd137161f2f6d2e758d7863b1789cb.svg &quot;Repobeats analytics image&quot;)

## Star history

&lt;a href=&quot;https://star-history.com/#immich-app/immich&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=immich-app/immich&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=immich-app/immich&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=immich-app/immich&amp;type=Date&quot; width=&quot;100%&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## Contributors

&lt;a href=&quot;https://github.com/alextran1502/immich/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=immich-app/immich&quot; width=&quot;100%&quot;/&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[cjpais/Handy]]></title>
            <link>https://github.com/cjpais/Handy</link>
            <guid>https://github.com/cjpais/Handy</guid>
            <pubDate>Sat, 04 Oct 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[A free, open source, and extensible speech-to-text application that works completely offline.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cjpais/Handy">cjpais/Handy</a></h1>
            <p>A free, open source, and extensible speech-to-text application that works completely offline.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,780</p>
            <p>Forks: 102</p>
            <p>Stars today: 324 stars today</p>
            <h2>README</h2><pre># Handy

[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.com/invite/WVBeWsNXK4)

**A free, open source, and extensible speech-to-text application that works completely offline.**

Handy is a cross-platform desktop application built with Tauri (Rust + React/TypeScript) that provides simple, privacy-focused speech transcription. Press a shortcut, speak, and have your words appear in any text field—all without sending your voice to the cloud.

## Why Handy?

Handy was created to fill the gap for a truly open source, extensible speech-to-text tool. As stated on [handy.computer](https://handy.computer):

- **Free**: Accessibility tooling belongs in everyone&#039;s hands, not behind a paywall
- **Open Source**: Together we can build further. Extend Handy for yourself and contribute to something bigger
- **Private**: Your voice stays on your computer. Get transcriptions without sending audio to the cloud
- **Simple**: One tool, one job. Transcribe what you say and put it into a text box

Handy isn&#039;t trying to be the best speech-to-text app—it&#039;s trying to be the most forkable one.

## How It Works

1. **Press** a configurable keyboard shortcut to start/stop recording (or use push-to-talk mode)
2. **Speak** your words while the shortcut is active
3. **Release** and Handy processes your speech using Whisper
4. **Get** your transcribed text pasted directly into whatever app you&#039;re using

The process is entirely local:
- Silence is filtered using VAD (Voice Activity Detection) with Silero
- Transcription uses your choice of models:
  - **Whisper models** (Small/Medium/Turbo/Large) with GPU acceleration when available
  - **Parakeet V3** - CPU-optimized model with excellent performance and automatic language detection
- Works on Windows, macOS, and Linux

## Quick Start

### Installation

1. Download the latest release from the [releases page](https://github.com/cjpais/Handy/releases) or the [website](https://handy.computer)
2. Install the application following platform-specific instructions
3. Launch Handy and grant necessary system permissions (microphone, accessibility)
4. Configure your preferred keyboard shortcuts in Settings
5. Start transcribing!

### Development Setup

For detailed build instructions including platform-specific requirements, see [BUILD.md](BUILD.md).

## Architecture

Handy is built as a Tauri application combining:

- **Frontend**: React + TypeScript with Tailwind CSS for the settings UI
- **Backend**: Rust for system integration, audio processing, and ML inference
- **Core Libraries**:
  - `whisper-rs`: Local speech recognition with Whisper models
  - `transcription-rs`: CPU-optimized speech recognition with Parakeet models
  - `cpal`: Cross-platform audio I/O
  - `vad-rs`: Voice Activity Detection
  - `rdev`: Global keyboard shortcuts and system events
  - `rubato`: Audio resampling

## Known Issues &amp; Current Limitations

This project is actively being developed and has some [known issues](https://github.com/cjpais/Handy/issues). We believe in transparency about the current state:

### Platform Support
- **Apple Silicon Macs**
- **x64 Windows**
- **x64 Linux**

### System Requirements/Recommendations

The following are recommendations for running Handy on your own machine. If you don&#039;t meet the system requirements, the performance of the application may be degraded. We are working on improving the performance across all kinds of computers and hardware.

**For Whisper Models:**
- **macOS**: M series Mac
- **Windows**: Intel, AMD, or NVIDIA GPU
- **Linux**: Intel, AMD, or NVIDIA GPU
  * Ubuntu 22.04, 24.04

**For Parakeet V3 Model:**
- **CPU-only operation** - runs on a wide variety of hardware
- **Minimum**: Intel Skylake (6th gen) or equivalent AMD processors
- **Performance**: ~5x real-time speed on mid-range hardware (tested on i5)
- **Automatic language detection** - no manual language selection required

### How to Contribute

1. **Check existing issues** at [github.com/cjpais/Handy/issues](https://github.com/cjpais/Handy/issues)
2. **Fork the repository** and create a feature branch
3. **Test thoroughly** on your target platform
4. **Submit a pull request** with clear description of changes
5. **Join the discussion** - reach out at [contact@handy.computer](mailto:contact@handy.computer)

The goal is to create both a useful tool and a foundation for others to build upon—a well-patterned, simple codebase that serves the community.

## Sponsors

&lt;div align=&quot;center&quot;&gt;
  We&#039;re grateful for the support of our sponsors who help make Handy possible:
  &lt;br&gt;&lt;br&gt;
  &lt;a href=&quot;https://wordcab.com&quot;&gt;
    &lt;img src=&quot;sponsor-images/wordcab.png&quot; alt=&quot;Wordcab&quot; width=&quot;120&quot; height=&quot;120&quot;&gt;
  &lt;/a&gt;
  &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
  &lt;a href=&quot;https://github.com/epicenter-so/epicenter&quot;&gt;
    &lt;img src=&quot;sponsor-images/epicenter.png&quot; alt=&quot;Epicenter&quot; width=&quot;120&quot; height=&quot;120&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

## Related Projects

- **[Handy CLI](https://github.com/cjpais/handy-cli)** - The original Python command-line version
- **[handy.computer](https://handy.computer)** - Project website with demos and documentation

## License

MIT License - see [LICENSE](LICENSE) file for details.

## Acknowledgments

- **Whisper** by OpenAI for the speech recognition model
- **whisper.cpp and ggml** for amazing cross-platform whisper inference/acceleration
- **Silero** for great lightweight VAD
- **Tauri** team for the excellent Rust-based app framework
- **Community contributors** helping make Handy better

---

*&quot;Your search for the right speech-to-text tool can end here—not because Handy is perfect, but because you can make it perfect for you.&quot;*
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[mui/mui-x]]></title>
            <link>https://github.com/mui/mui-x</link>
            <guid>https://github.com/mui/mui-x</guid>
            <pubDate>Sat, 04 Oct 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[MUI X: Build complex and data-rich applications using a growing list of advanced React components, like the Data Grid, Date and Time Pickers, Charts, and more!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mui/mui-x">mui/mui-x</a></h1>
            <p>MUI X: Build complex and data-rich applications using a growing list of advanced React components, like the Data Grid, Date and Time Pickers, Charts, and more!</p>
            <p>Language: TypeScript</p>
            <p>Stars: 5,480</p>
            <p>Forks: 1,629</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable-next-line --&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mui.com/x/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;&lt;img width=&quot;150&quot; height=&quot;133&quot; src=&quot;https://mui.com/static/logo.svg&quot; alt=&quot;MUI X logo&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;MUI X&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/mui/mui-x/blob/HEAD/LICENSE)
[![npm latest package](https://img.shields.io/npm/v/@mui/x-data-grid/latest.svg)](https://www.npmjs.com/package/@mui/x-data-grid)
[![npm downloads](https://img.shields.io/npm/dm/@mui/x-data-grid.svg)](https://www.npmjs.com/package/@mui/x-data-grid)
[![GitHub branch status](https://img.shields.io/github/checks-status/mui/mui-x/HEAD)](https://github.com/mui/mui-x/commits/HEAD/)
[![Coverage status](https://img.shields.io/codecov/c/github/mui/mui-x.svg)](https://codecov.io/gh/mui/mui-x/)
[![Follow on X](https://img.shields.io/twitter/follow/MUI_X_.svg?label=follow+MUI+X)](https://x.com/MUI_X_)
[![Renovate status](https://img.shields.io/badge/renovate-enabled-brightgreen.svg)](https://github.com/mui/mui-x/issues/2081)
[![Average time to resolve an issue](https://isitmaintained.com/badge/resolution/mui/mui-x.svg)](https://isitmaintained.com/project/mui/mui-x &#039;Average time to resolve an issue&#039;)
[![Open Collective backers and sponsors](https://img.shields.io/opencollective/all/mui-org)](https://opencollective.com/mui-org)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/6293/badge)](https://www.bestpractices.dev/projects/6293)

&lt;/div&gt;

[MUI X](https://mui.com/x/) is a suite of advanced React UI components for a wide range of complex use cases.
Each component provides best-in-class UX and DX, with sophisticated UX workflows for data-rich applications.
Components include the Data Grid, Date and Time Pickers, Charts, and Tree View.

MUI X extends the core functionality of [Material UI](https://github.com/mui/material-ui/), but the advanced components also stand on their own and can be fully customized to meet the needs of any design system.

MUI X is **open-core**: [Community](#community-plan) components are MIT-licensed and free forever, while more advanced features and components require a [Pro](#pro-plan) or [Premium](#premium-plan) commercial license.
See [Licensing](#licensing) for more information.

## Documentation

Get started in the [MUI X documentation](https://mui.com/x/introduction/).

- [Data Grid](https://mui.com/x/react-data-grid/)
- [Date and Time Pickers](https://mui.com/x/react-date-pickers/)
- [Charts](https://mui.com/x/react-charts/)
- [Tree View](https://mui.com/x/react-tree-view/)

### Installation

- [Data Grid installation](https://mui.com/x/react-data-grid/quickstart/#installation)
- [Date and Time Pickers installation](https://mui.com/x/react-date-pickers/quickstart/#installation)
- [Charts installation](https://mui.com/x/react-charts/quickstart/#installation)
- [Tree View installation](https://mui.com/x/react-tree-view/quickstart/#installation)

## Licensing

The MUI X team has been building MIT-licensed React components since 2014, starting with Material UI, and we&#039;re committed to the continued advancement of our open-source libraries.
Anything we release under an MIT license will remain MIT-licensed forever.
Learn more about [our stewardship ethos](https://mui-org.notion.site/Stewardship-542a2226043d4f4a96dfb429d16cf5bd).

We offer commercial licenses to developers who need the most advanced components and features that can&#039;t reasonably be maintained by the open-source community alone.
These licenses make it possible for us to support a full-time staff of engineers.

Rest assured that when we release features commercially, it&#039;s only because we believe you won&#039;t find a better MIT-licensed alternative anywhere else.

See the [Licensing page](https://mui.com/x/introduction/licensing/) for complete details.

### Plans

#### Community plan

The free Community version of MUI X contains components and features that we believe are maintainable by contributions from the open-source community.
It&#039;s published under an [MIT license](https://www.tldrlegal.com/license/mit-license) and it&#039;s [free forever](https://mui-org.notion.site/Stewardship-542a2226043d4f4a96dfb429d16cf5bd#20f609acab4441cf9346614119fbbac1).

- [`@mui/x-data-grid`](https://www.npmjs.com/package/@mui/x-data-grid)
- [`@mui/x-date-pickers`](https://www.npmjs.com/package/@mui/x-date-pickers)
- [`@mui/x-charts`](https://www.npmjs.com/package/@mui/x-charts)
- [`@mui/x-tree-view`](https://www.npmjs.com/package/@mui/x-tree-view)

#### Pro plan

MUI X Pro expands on the Community version with more advanced features and functionality.
The Data Grid Pro comes with multi-filtering, multi-sorting, column resizing, and column pinning; you also gain access to the Date and Time Range Picker components, advanced Charts, and drag-and-drop reordering for the Tree View.

The Pro version is available under a commercial license—visit the [Pricing page](https://mui.com/pricing/) for details.

- [`@mui/x-data-grid-pro`](https://www.npmjs.com/package/@mui/x-data-grid-pro)
- [`@mui/x-date-pickers-pro`](https://www.npmjs.com/package/@mui/x-date-pickers-pro)
- [`@mui/x-charts-pro`](https://www.npmjs.com/package/@mui/x-charts-pro)
- [`@mui/x-tree-view-pro`](https://www.npmjs.com/package/@mui/x-tree-view-pro)

#### Premium plan

MUI X Premium unlocks the most advanced features of the Data Grid, including row grouping and Excel exporting, as well as everything offered in the Pro plan.

The Premium version is available under a commercial license—visit the [Pricing page](https://mui.com/pricing/) for details.

- [`@mui/x-data-grid-premium`](https://www.npmjs.com/package/@mui/x-data-grid-premium)
- [`@mui/x-charts-premium`](https://www.npmjs.com/package/@mui/x-charts-premium)

## Support

From community guidance to critical business support, we&#039;re here to help.
Read the [Support guide](https://mui.com/x/introduction/support/) for details.

## Contributing

Read the [Contributing guide](/CONTRIBUTING.md) to learn about our development process, how to propose bug fixes and improvements, and how to build and test your changes.

Contributing to MUI X is about more than just issues and pull requests!
There are many other ways to [support MUI X](https://mui.com/material-ui/getting-started/faq/#mui-is-an-awesome-organization-how-can-i-support-it) beyond contributing to the code base.

## Changelog

The [changelog](https://github.com/mui/mui-x/releases) is regularly updated to reflect what&#039;s changed in each new release.

## Roadmap

Future plans and high-priority features and enhancements can be found in the [roadmap](https://mui.com/x/introduction/roadmap/).

## Security

For details on supported versions and contact information for reporting security issues, please refer to the [security policy](https://github.com/mui/mui-x/security/policy).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[danny-avila/LibreChat]]></title>
            <link>https://github.com/danny-avila/LibreChat</link>
            <guid>https://github.com/danny-avila/LibreChat</guid>
            <pubDate>Sat, 04 Oct 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[Enhanced ChatGPT Clone: Features Agents, MCP, DeepSeek, Anthropic, AWS, OpenAI, Responses API, Azure, Groq, o1, GPT-5, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting. Active.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/danny-avila/LibreChat">danny-avila/LibreChat</a></h1>
            <p>Enhanced ChatGPT Clone: Features Agents, MCP, DeepSeek, Anthropic, AWS, OpenAI, Responses API, Azure, Groq, o1, GPT-5, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting. Active.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 30,550</p>
            <p>Forks: 5,852</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://librechat.ai&quot;&gt;
    &lt;img src=&quot;client/public/assets/logo.svg&quot; height=&quot;256&quot;&gt;
  &lt;/a&gt;
  &lt;h1 align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://librechat.ai&quot;&gt;LibreChat&lt;/a&gt;
  &lt;/h1&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.librechat.ai&quot;&gt; 
    &lt;img
      src=&quot;https://img.shields.io/discord/1086345563026489514?label=&amp;logo=discord&amp;style=for-the-badge&amp;logoWidth=20&amp;logoColor=white&amp;labelColor=000000&amp;color=blueviolet&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.youtube.com/@LibreChat&quot;&gt; 
    &lt;img
      src=&quot;https://img.shields.io/badge/YOUTUBE-red.svg?style=for-the-badge&amp;logo=youtube&amp;logoColor=white&amp;labelColor=000000&amp;logoWidth=20&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://docs.librechat.ai&quot;&gt; 
    &lt;img
      src=&quot;https://img.shields.io/badge/DOCS-blue.svg?style=for-the-badge&amp;logo=read-the-docs&amp;logoColor=white&amp;labelColor=000000&amp;logoWidth=20&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Sponsors&quot; href=&quot;https://github.com/sponsors/danny-avila&quot;&gt;
    &lt;img
      src=&quot;https://img.shields.io/badge/SPONSORS-brightgreen.svg?style=for-the-badge&amp;logo=github-sponsors&amp;logoColor=white&amp;labelColor=000000&amp;logoWidth=20&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://railway.app/template/b5k2mn?referralCode=HI9hWz&quot;&gt;
  &lt;img src=&quot;https://railway.app/button.svg&quot; alt=&quot;Deploy on Railway&quot; height=&quot;30&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://zeabur.com/templates/0X2ZY8&quot;&gt;
  &lt;img src=&quot;https://zeabur.com/button.svg&quot; alt=&quot;Deploy on Zeabur&quot; height=&quot;30&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://template.cloud.sealos.io/deploy?templateName=librechat&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg&quot; alt=&quot;Deploy on Sealos&quot; height=&quot;30&quot;&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.librechat.ai/docs/translation&quot;&gt;
    &lt;img 
      src=&quot;https://img.shields.io/badge/dynamic/json.svg?style=for-the-badge&amp;color=2096F3&amp;label=locize&amp;query=%24.translatedPercentage&amp;url=https://api.locize.app/badgedata/4cb2598b-ed4d-469c-9b04-2ed531a8cb45&amp;suffix=%+translated&quot; 
      alt=&quot;Translation Progress&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;


# ✨ Features

- 🖥️ **UI &amp; Experience** inspired by ChatGPT with enhanced design and features

- 🤖 **AI Model Selection**:  
  - Anthropic (Claude), AWS Bedrock, OpenAI, Azure OpenAI, Google, Vertex AI, OpenAI Responses API (incl. Azure)
  - [Custom Endpoints](https://www.librechat.ai/docs/quick_start/custom_endpoints): Use any OpenAI-compatible API with LibreChat, no proxy required
  - Compatible with [Local &amp; Remote AI Providers](https://www.librechat.ai/docs/configuration/librechat_yaml/ai_endpoints):
    - Ollama, groq, Cohere, Mistral AI, Apple MLX, koboldcpp, together.ai,
    - OpenRouter, Perplexity, ShuttleAI, Deepseek, Qwen, and more

- 🔧 **[Code Interpreter API](https://www.librechat.ai/docs/features/code_interpreter)**: 
  - Secure, Sandboxed Execution in Python, Node.js (JS/TS), Go, C/C++, Java, PHP, Rust, and Fortran
  - Seamless File Handling: Upload, process, and download files directly
  - No Privacy Concerns: Fully isolated and secure execution

- 🔦 **Agents &amp; Tools Integration**:  
  - **[LibreChat Agents](https://www.librechat.ai/docs/features/agents)**:
    - No-Code Custom Assistants: Build specialized, AI-driven helpers
    - Agent Marketplace: Discover and deploy community-built agents
    - Collaborative Sharing: Share agents with specific users and groups
    - Flexible &amp; Extensible: Use MCP Servers, tools, file search, code execution, and more
    - Compatible with Custom Endpoints, OpenAI, Azure, Anthropic, AWS Bedrock, Google, Vertex AI, Responses API, and more
    - [Model Context Protocol (MCP) Support](https://modelcontextprotocol.io/clients#librechat) for Tools

- 🔍 **Web Search**:  
  - Search the internet and retrieve relevant information to enhance your AI context
  - Combines search providers, content scrapers, and result rerankers for optimal results
  - **Customizable Jina Reranking**: Configure custom Jina API URLs for reranking services
  - **[Learn More →](https://www.librechat.ai/docs/features/web_search)**

- 🪄 **Generative UI with Code Artifacts**:  
  - [Code Artifacts](https://youtu.be/GfTj7O4gmd0?si=WJbdnemZpJzBrJo3) allow creation of React, HTML, and Mermaid diagrams directly in chat

- 🎨 **Image Generation &amp; Editing**
  - Text-to-image and image-to-image with [GPT-Image-1](https://www.librechat.ai/docs/features/image_gen#1--openai-image-tools-recommended)
  - Text-to-image with [DALL-E (3/2)](https://www.librechat.ai/docs/features/image_gen#2--dalle-legacy), [Stable Diffusion](https://www.librechat.ai/docs/features/image_gen#3--stable-diffusion-local), [Flux](https://www.librechat.ai/docs/features/image_gen#4--flux), or any [MCP server](https://www.librechat.ai/docs/features/image_gen#5--model-context-protocol-mcp)
  - Produce stunning visuals from prompts or refine existing images with a single instruction

- 💾 **Presets &amp; Context Management**:  
  - Create, Save, &amp; Share Custom Presets  
  - Switch between AI Endpoints and Presets mid-chat
  - Edit, Resubmit, and Continue Messages with Conversation branching  
  - Create and share prompts with specific users and groups
  - [Fork Messages &amp; Conversations](https://www.librechat.ai/docs/features/fork) for Advanced Context control

- 💬 **Multimodal &amp; File Interactions**:  
  - Upload and analyze images with Claude 3, GPT-4.5, GPT-4o, o1, Llama-Vision, and Gemini 📸  
  - Chat with Files using Custom Endpoints, OpenAI, Azure, Anthropic, AWS Bedrock, &amp; Google 🗃️

- 🌎 **Multilingual UI**:
  - English, 中文 (简体), 中文 (繁體), العربية, Deutsch, Español, Français, Italiano
  - Polski, Português (PT), Português (BR), Русский, 日本語, Svenska, 한국어, Tiếng Việt
  - Türkçe, Nederlands, עברית, Català, Čeština, Dansk, Eesti, فارسی
  - Suomi, Magyar, Հայերեն, Bahasa Indonesia, ქართული, Latviešu, ไทย, ئۇيغۇرچە

- 🧠 **Reasoning UI**:  
  - Dynamic Reasoning UI for Chain-of-Thought/Reasoning AI models like DeepSeek-R1

- 🎨 **Customizable Interface**:  
  - Customizable Dropdown &amp; Interface that adapts to both power users and newcomers

- 🗣️ **Speech &amp; Audio**:  
  - Chat hands-free with Speech-to-Text and Text-to-Speech  
  - Automatically send and play Audio  
  - Supports OpenAI, Azure OpenAI, and Elevenlabs

- 📥 **Import &amp; Export Conversations**:  
  - Import Conversations from LibreChat, ChatGPT, Chatbot UI  
  - Export conversations as screenshots, markdown, text, json

- 🔍 **Search &amp; Discovery**:  
  - Search all messages/conversations

- 👥 **Multi-User &amp; Secure Access**:
  - Multi-User, Secure Authentication with OAuth2, LDAP, &amp; Email Login Support
  - Built-in Moderation, and Token spend tools

- ⚙️ **Configuration &amp; Deployment**:  
  - Configure Proxy, Reverse Proxy, Docker, &amp; many Deployment options  
  - Use completely local or deploy on the cloud

- 📖 **Open-Source &amp; Community**:  
  - Completely Open-Source &amp; Built in Public  
  - Community-driven development, support, and feedback

[For a thorough review of our features, see our docs here](https://docs.librechat.ai/) 📚

## 🪶 All-In-One AI Conversations with LibreChat

LibreChat brings together the future of assistant AIs with the revolutionary technology of OpenAI&#039;s ChatGPT. Celebrating the original styling, LibreChat gives you the ability to integrate multiple AI models. It also integrates and enhances original client features such as conversation and message search, prompt templates and plugins.

With LibreChat, you no longer need to opt for ChatGPT Plus and can instead use free or pay-per-call APIs. We welcome contributions, cloning, and forking to enhance the capabilities of this advanced chatbot platform.

[![Watch the video](https://raw.githubusercontent.com/LibreChat-AI/librechat.ai/main/public/images/changelog/v0.7.6.gif)](https://www.youtube.com/watch?v=ilfwGQtJNlI)

Click on the thumbnail to open the video☝️

---

## 🌐 Resources

**GitHub Repo:**
  - **RAG API:** [github.com/danny-avila/rag_api](https://github.com/danny-avila/rag_api)
  - **Website:** [github.com/LibreChat-AI/librechat.ai](https://github.com/LibreChat-AI/librechat.ai)

**Other:**
  - **Website:** [librechat.ai](https://librechat.ai)
  - **Documentation:** [librechat.ai/docs](https://librechat.ai/docs)
  - **Blog:** [librechat.ai/blog](https://librechat.ai/blog)

---

## 📝 Changelog

Keep up with the latest updates by visiting the releases page and notes:
- [Releases](https://github.com/danny-avila/LibreChat/releases)
- [Changelog](https://www.librechat.ai/changelog) 

**⚠️ Please consult the [changelog](https://www.librechat.ai/changelog) for breaking changes before updating.**

---

## ⭐ Star History

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://star-history.com/#danny-avila/LibreChat&amp;Date&quot;&gt;
    &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=danny-avila/LibreChat&amp;type=Date&amp;theme=dark&quot; onerror=&quot;this.src=&#039;https://api.star-history.com/svg?repos=danny-avila/LibreChat&amp;type=Date&#039;&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/4685&quot; target=&quot;_blank&quot; style=&quot;padding: 10px;&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/4685&quot; alt=&quot;danny-avila%2FLibreChat | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://runacap.com/ross-index/q1-24/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; style=&quot;margin-left: 20px;&quot;&gt;
    &lt;img style=&quot;width: 260px; height: 56px&quot; src=&quot;https://runacap.com/wp-content/uploads/2024/04/ROSS_badge_white_Q1_2024.svg&quot; alt=&quot;ROSS Index - Fastest Growing Open-Source Startups in Q1 2024 | Runa Capital&quot; width=&quot;260&quot; height=&quot;56&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

---

## ✨ Contributions

Contributions, suggestions, bug reports and fixes are welcome!

For new features, components, or extensions, please open an issue and discuss before sending a PR.

If you&#039;d like to help translate LibreChat into your language, we&#039;d love your contribution! Improving our translations not only makes LibreChat more accessible to users around the world but also enhances the overall user experience. Please check out our [Translation Guide](https://www.librechat.ai/docs/translation).

---

## 💖 This project exists in its current state thanks to all the people who contribute

&lt;a href=&quot;https://github.com/danny-avila/LibreChat/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=danny-avila/LibreChat&quot; /&gt;
&lt;/a&gt;

---

## 🎉 Special Thanks

We thank [Locize](https://locize.com) for their translation management tools that support multiple languages in LibreChat.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://locize.com&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/d6b70894-6064-475e-bb65-92a9e23e0077&quot; alt=&quot;Locize Logo&quot; height=&quot;50&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[mui/base-ui]]></title>
            <link>https://github.com/mui/base-ui</link>
            <guid>https://github.com/mui/base-ui</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[Unstyled UI components for building accessible web apps and design systems. From the creators of Radix, Floating UI, and Material UI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mui/base-ui">mui/base-ui</a></h1>
            <p>Unstyled UI components for building accessible web apps and design systems. From the creators of Radix, Floating UI, and Material UI.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 5,803</p>
            <p>Forks: 242</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># Base UI

From the creators of Radix, Floating UI, and Material UI, Base UI is an unstyled UI component library for building accessible user interfaces.

---

## Documentation

To get started, check out the [Base UI documentation](https://base-ui.com/react/overview/quick-start).

## Contributing

Read our [contributing guide](/CONTRIBUTING.md) to learn about our development process, how to propose bug fixes and improvements, and how to build and test your changes.

## Releases

To see the latest updates, check out the [releases](https://base-ui.com/react/overview/releases).

## Community

- **Discord** For community support, questions, and tips, join our [Discord](https://discord.gg/g6C3hUtuxz).
- **X** To stay up-to-date on new releases and announcements follow [Base UI on X](https://x.com/base_ui).
- **Bluesky** We&#039;re also on [Bluesky](https://bsky.app/profile/base-ui.com).

## Team

- **Colm Tuite** (Radix) [@colmtuite](https://x.com/colmtuite)
- **Vlad Moroz** (Radix) [@vladyslavmoroz](https://x.com/vladyslavmoroz)
- **James Nelson** (Floating UI) [@atomiksdev](https://x.com/atomiksdev)
- **Michał Dudak** (Material UI) [@michaldudak](https://x.com/michaldudak)
- **Marija Najdova** (Material UI + Fluent UI) [@marijanajdova](https://x.com/marijanajdova)
- **Albert Yu** (Material UI) [@mj12albert](https://github.com/mj12albert)

## License

This project is licensed under the terms of the [MIT license](/LICENSE).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[atuinsh/desktop]]></title>
            <link>https://github.com/atuinsh/desktop</link>
            <guid>https://github.com/atuinsh/desktop</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[📖 Runbooks that run]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/atuinsh/desktop">atuinsh/desktop</a></h1>
            <p>📖 Runbooks that run</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,138</p>
            <p>Forks: 32</p>
            <p>Stars today: 267 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
 &lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/atuinsh/atuin/assets/53315310/13216a1d-1ac0-4c99-b0eb-d88290fe0efd&quot;&gt;
  &lt;img alt=&quot;Atuin Desktop&quot; src=&quot;https://github.com/atuinsh/atuin/assets/53315310/08bc86d4-a781-4aaa-8d7e-478ae6bcd129&quot;&gt;
&lt;/picture&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Atuin Desktop&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;em&gt;Runbooks that Run. A local-first, executable runbook editor for real terminal workflows. Atuin Desktop looks like a doc, but runs like your terminal.&lt;/em&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/atuinsh/desktop/releases&quot;&gt;download&lt;/a&gt; | &lt;a href=&quot;https://man.atuin.sh&quot;&gt;documentation&lt;/a&gt; | &lt;a href=&quot;https://hub.atuin.sh/&quot;&gt;hub&lt;/a&gt; | &lt;a href=&quot;https://discord.gg/Fq8bJSKPHh&quot;&gt;discord&lt;/a&gt;
&lt;/p&gt;


&lt;p align=&quot;center&quot;&gt;
 &lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://man.atuin.sh/images/atuin-desktop-ss-dark.png&quot;&gt;
  &lt;img alt=&quot;Atuin Desktop&quot; src=&quot;https://man.atuin.sh/images/atuin-desktop-ss-light.png&quot;&gt;
&lt;/picture&gt;
&lt;/p&gt;

## 🚀 Open Beta

Atuin Desktop is currently in **open beta**. We&#039;re actively collecting feedback and improving the experience based on real-world usage.

Read the [announcement post](https://blog.atuin.sh/atuin-desktop-open-source/)

## What is Atuin Desktop?

Most infrastructure is held together by five commands someone remembers when things go wrong. Documentation is out of date (if it exists at all), and the real answers are buried in Slack threads, rotting in Notion, or trapped in someone&#039;s shell history.

Atuin Desktop solves this by creating **executable runbooks** that bridge the gap between documentation and automation:

- **Kill context switching**: Chain shell commands, database queries, and HTTP requests in one place
- **Docs that don&#039;t rot**: Execute directly and stay relevant
- **Reusable automation**: Dynamic runbooks with Jinja-style templating  
- **Instant recall**: Autocomplete from your real shell history
- **Local-first, CRDT-powered**: If it runs in your terminal, it runs in a runbook
- **Sync and share**: Keep runbooks up to date across devices and teams with Atuin Hub

## Key Features

### 🔧 Embedded Execution
- Terminal blocks that run directly in the interface
- Database clients for live queries
- Prometheus charts and monitoring integration

### 📚 Living Documentation
- Runbooks that run
- No more copy-pasting from outdated docs
- Real workflows that teams can actually use

### 🔄 Dynamic Templating
- Jinja-style templating for reusable logic
- Variable substitution and conditional logic
- Parameterized workflows for different environments

### 🏛️ Local-First Architecture
- CRDT-powered collaboration
- Works offline, syncs when connected

## Use Cases

Teams are already using Atuin Desktop for:

- **Release Management**: Automated release checklists that actually run
- **Infrastructure Migration**: Safe, repeatable migration workflows
- **Environment Management**: Spinning up staging and production with confidence
- **Database Operations**: Collaborative live query management
- **Incident Response**: Runbooks for when things break

## Getting Started

1. Download a package for your platform [on our releases page](https://github.com/atuinsh/desktop/releases)
2. Sign up for an account [on Atuin Hub](https://hub.atuin.sh/)
3. [Log into Atuin Desktop](https://man.atuin.sh/hub/getting-started/) and create your first runbook

## Feedback &amp; Support

We&#039;re actively seeking feedback during our beta phase! Please use this repository to:

### 🐛 Report Issues

- Found a bug? [Open an issue](../../issues/new?template=bug_report.md)
- Include your OS, Atuin Desktop version, and steps to reproduce

### 💡 Request Features  

- Have an idea? [Submit a feature request](../../issues/new?template=feature_request.md)
- Tell us about your workflow and how Atuin Desktop could better support it

### 💬 General Discussion

Questions about usage? [Start a discussion](https://forum.atuin.sh)

## Roadmap

### Coming Soon

- **Enhanced Integrations**: More database clients, monitoring tools, and APIs
- **History-to-Runbook**: Generate runbooks automatically from your shell history

## Community

- **Blog**: [blog.atuin.sh](https://blog.atuin.sh)
- **Discord**: [Join our community](https://discord.gg/Fq8bJSKPHh)
- **Twitter**: [@atuinsh](https://twitter.com/atuinsh)
- **Bluesky**: [@atuin.sh](https://bsky.app/profile/atuin.sh)
- **Website**: [atuin.sh](https://atuin.sh)

## Related Projects

- **[Atuin CLI](https://github.com/atuinsh/atuin)**: Magical shell history with sync, search, and stats

## License

Copyright 2025 Atuin, Inc

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[simstudioai/sim]]></title>
            <link>https://github.com/simstudioai/sim</link>
            <guid>https://github.com/simstudioai/sim</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[Open-source platform to build and deploy AI agent workflows.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/simstudioai/sim">simstudioai/sim</a></h1>
            <p>Open-source platform to build and deploy AI agent workflows.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 16,173</p>
            <p>Forks: 2,046</p>
            <p>Stars today: 154 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://sim.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
    &lt;img src=&quot;apps/sim/public/logo/reverse/text/large.png&quot; alt=&quot;Sim Logo&quot; width=&quot;500&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Build and deploy AI agent workflows in minutes.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://sim.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/sim.ai-6F3DFA&quot; alt=&quot;Sim.ai&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/Hr4UWYEcTT&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;logoColor=white&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/simdotai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/simstudioai?style=social&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://docs.sim.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Docs-6F3DFA.svg&quot; alt=&quot;Documentation&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;apps/sim/public/static/demo.gif&quot; alt=&quot;Sim Demo&quot; width=&quot;800&quot;/&gt;
&lt;/p&gt;

## Quickstart

### Cloud-hosted: [sim.ai](https://sim.ai)

&lt;a href=&quot;https://sim.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/sim.ai-6F3DFA?logo=data:image/svg%2bxml;base64,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&amp;logoColor=white&quot; alt=&quot;Sim.ai&quot;&gt;&lt;/a&gt;

### Self-hosted: NPM Package

```bash
npx simstudio
```
→ http://localhost:3000

#### Note
Docker must be installed and running on your machine.

#### Options

| Flag | Description |
|------|-------------|
| `-p, --port &lt;port&gt;` | Port to run Sim on (default `3000`) |
| `--no-pull` | Skip pulling latest Docker images |

### Self-hosted: Docker Compose

```bash
# Clone the repository
git clone https://github.com/simstudioai/sim.git

# Navigate to the project directory
cd sim

# Start Sim
docker compose -f docker-compose.prod.yml up -d
```

Access the application at [http://localhost:3000/](http://localhost:3000/)

#### Using Local Models with Ollama

Run Sim with local AI models using [Ollama](https://ollama.ai) - no external APIs required:

```bash
# Start with GPU support (automatically downloads gemma3:4b model)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# For CPU-only systems:
docker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d
```

Wait for the model to download, then visit [http://localhost:3000](http://localhost:3000). Add more models with:
```bash
docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b
```

### Self-hosted: Dev Containers

1. Open VS Code with the [Remote - Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)
2. Open the project and click &quot;Reopen in Container&quot; when prompted
3. Run `bun run dev:full` in the terminal or use the `sim-start` alias
   - This starts both the main application and the realtime socket server

### Self-hosted: Manual Setup

**Requirements:**
- [Bun](https://bun.sh/) runtime
- PostgreSQL 12+ with [pgvector extension](https://github.com/pgvector/pgvector) (required for AI embeddings)

**Note:** Sim uses vector embeddings for AI features like knowledge bases and semantic search, which requires the `pgvector` PostgreSQL extension.

1. Clone and install dependencies:

```bash
git clone https://github.com/simstudioai/sim.git
cd sim
bun install
```

2. Set up PostgreSQL with pgvector:

You need PostgreSQL with the `vector` extension for embedding support. Choose one option:

**Option A: Using Docker (Recommended)**
```bash
# Start PostgreSQL with pgvector extension
docker run --name simstudio-db \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=simstudio \
  -p 5432:5432 -d \
  pgvector/pgvector:pg17
```

**Option B: Manual Installation**
- Install PostgreSQL 12+ and the pgvector extension
- See [pgvector installation guide](https://github.com/pgvector/pgvector#installation)

3. Set up environment:

```bash
cd apps/sim
cp .env.example .env  # Configure with required variables (DATABASE_URL, BETTER_AUTH_SECRET, BETTER_AUTH_URL)
```

Update your `.env` file with the database URL:
```bash
DATABASE_URL=&quot;postgresql://postgres:your_password@localhost:5432/simstudio&quot;
```

4. Set up the database:

First, configure the database package environment:
```bash
cd packages/db
cp .env.example .env 
```

Update your `packages/db/.env` file with the database URL:
```bash
DATABASE_URL=&quot;postgresql://postgres:your_password@localhost:5432/simstudio&quot;
```

Then run the migrations:
```bash
bunx drizzle-kit migrate --config=./drizzle.config.ts
```

5. Start the development servers:

**Recommended approach - run both servers together (from project root):**

```bash
bun run dev:full
```

This starts both the main Next.js application and the realtime socket server required for full functionality.

**Alternative - run servers separately:**

Next.js app (from project root):
```bash
bun run dev
```

Realtime socket server (from `apps/sim` directory in a separate terminal):
```bash
cd apps/sim
bun run dev:sockets
```

## Copilot API Keys

Copilot is a Sim-managed service. To use Copilot on a self-hosted instance:

- Go to https://sim.ai → Settings → Copilot and generate a Copilot API key
- Set `COPILOT_API_KEY` environment variable in your self-hosted apps/sim/.env file to that value

## Tech Stack

- **Framework**: [Next.js](https://nextjs.org/) (App Router)
- **Runtime**: [Bun](https://bun.sh/)
- **Database**: PostgreSQL with [Drizzle ORM](https://orm.drizzle.team)
- **Authentication**: [Better Auth](https://better-auth.com)
- **UI**: [Shadcn](https://ui.shadcn.com/), [Tailwind CSS](https://tailwindcss.com)
- **State Management**: [Zustand](https://zustand-demo.pmnd.rs/)
- **Flow Editor**: [ReactFlow](https://reactflow.dev/)
- **Docs**: [Fumadocs](https://fumadocs.vercel.app/)
- **Monorepo**: [Turborepo](https://turborepo.org/)
- **Realtime**: [Socket.io](https://socket.io/)
- **Background Jobs**: [Trigger.dev](https://trigger.dev/)
- **Remote Code Execution**: [E2B](https://www.e2b.dev/)

## Contributing

We welcome contributions! Please see our [Contributing Guide](.github/CONTRIBUTING.md) for details.

## License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

&lt;p align=&quot;center&quot;&gt;Made with ❤️ by the Sim Team&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[n8n-io/n8n]]></title>
            <link>https://github.com/n8n-io/n8n</link>
            <guid>https://github.com/n8n-io/n8n</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/n8n-io/n8n">n8n-io/n8n</a></h1>
            <p>Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 144,935</p>
            <p>Forks: 46,008</p>
            <p>Stars today: 457 stars today</p>
            <h2>README</h2><pre>![Banner image](https://user-images.githubusercontent.com/10284570/173569848-c624317f-42b1-45a6-ab09-f0ea3c247648.png)

# n8n - Secure Workflow Automation for Technical Teams

n8n is a workflow automation platform that gives technical teams the flexibility of code with the speed of no-code. With 400+ integrations, native AI capabilities, and a fair-code license, n8n lets you build powerful automations while maintaining full control over your data and deployments.

![n8n.io - Screenshot](https://raw.githubusercontent.com/n8n-io/n8n/master/assets/n8n-screenshot-readme.png)

## Key Capabilities

- **Code When You Need It**: Write JavaScript/Python, add npm packages, or use the visual interface
- **AI-Native Platform**: Build AI agent workflows based on LangChain with your own data and models
- **Full Control**: Self-host with our fair-code license or use our [cloud offering](https://app.n8n.cloud/login)
- **Enterprise-Ready**: Advanced permissions, SSO, and air-gapped deployments
- **Active Community**: 400+ integrations and 900+ ready-to-use [templates](https://n8n.io/workflows)

## Quick Start

Try n8n instantly with [npx](https://docs.n8n.io/hosting/installation/npm/) (requires [Node.js](https://nodejs.org/en/)):

```
npx n8n
```

Or deploy with [Docker](https://docs.n8n.io/hosting/installation/docker/):

```
docker volume create n8n_data
docker run -it --rm --name n8n -p 5678:5678 -v n8n_data:/home/node/.n8n docker.n8n.io/n8nio/n8n
```

Access the editor at http://localhost:5678

## Resources

- 📚 [Documentation](https://docs.n8n.io)
- 🔧 [400+ Integrations](https://n8n.io/integrations)
- 💡 [Example Workflows](https://n8n.io/workflows)
- 🤖 [AI &amp; LangChain Guide](https://docs.n8n.io/advanced-ai/)
- 👥 [Community Forum](https://community.n8n.io)
- 📖 [Community Tutorials](https://community.n8n.io/c/tutorials/28)

## Support

Need help? Our community forum is the place to get support and connect with other users:
[community.n8n.io](https://community.n8n.io)

## License

n8n is [fair-code](https://faircode.io) distributed under the [Sustainable Use License](https://github.com/n8n-io/n8n/blob/master/LICENSE.md) and [n8n Enterprise License](https://github.com/n8n-io/n8n/blob/master/LICENSE_EE.md).

- **Source Available**: Always visible source code
- **Self-Hostable**: Deploy anywhere
- **Extensible**: Add your own nodes and functionality

[Enterprise licenses](mailto:license@n8n.io) available for additional features and support.

Additional information about the license model can be found in the [docs](https://docs.n8n.io/sustainable-use-license/).

## Contributing

Found a bug 🐛 or have a feature idea ✨? Check our [Contributing Guide](https://github.com/n8n-io/n8n/blob/master/CONTRIBUTING.md) to get started.

## Join the Team

Want to shape the future of automation? Check out our [job posts](https://n8n.io/careers) and join our team!

## What does n8n mean?

**Short answer:** It means &quot;nodemation&quot; and is pronounced as n-eight-n.

**Long answer:** &quot;I get that question quite often (more often than I expected) so I decided it is probably best to answer it here. While looking for a good name for the project with a free domain I realized very quickly that all the good ones I could think of were already taken. So, in the end, I chose nodemation. &#039;node-&#039; in the sense that it uses a Node-View and that it uses Node.js and &#039;-mation&#039; for &#039;automation&#039; which is what the project is supposed to help with. However, I did not like how long the name was and I could not imagine writing something that long every time in the CLI. That is when I then ended up on &#039;n8n&#039;.&quot; - **Jan Oberhauser, Founder and CEO, n8n.io**
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[AykutSarac/jsoncrack.com]]></title>
            <link>https://github.com/AykutSarac/jsoncrack.com</link>
            <guid>https://github.com/AykutSarac/jsoncrack.com</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[✨ Innovative and open-source visualization application that transforms various data formats, such as JSON, YAML, XML, CSV and more, into interactive graphs.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AykutSarac/jsoncrack.com">AykutSarac/jsoncrack.com</a></h1>
            <p>✨ Innovative and open-source visualization application that transforms various data formats, such as JSON, YAML, XML, CSV and more, into interactive graphs.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 41,658</p>
            <p>Forks: 2,974</p>
            <p>Stars today: 133 stars today</p>
            <h2>README</h2><pre>&lt;!-- PROJECT LOGO --&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/AykutSarac/jsoncrack.com&quot;&gt;
   &lt;img src=&quot;./public/assets/192.png&quot; height=&quot;50&quot; alt=&quot;Logo&quot;&gt;
  &lt;/a&gt;

  &lt;h1 align=&quot;center&quot;&gt;JSON Crack&lt;/h1&gt;

  &lt;p align=&quot;center&quot;&gt;
    The open-source JSON Editor.
    &lt;br /&gt;
    &lt;a href=&quot;https://jsoncrack.com&quot;&gt;&lt;strong&gt;Learn more »&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://todiagram.com&quot;&gt;ToDiagram&lt;/a&gt;
    ·
    &lt;a href=&quot;https://discord.gg/yVyTtCRueq&quot;&gt;Discord&lt;/a&gt;
    ·
    &lt;a href=&quot;https://jsoncrack.com&quot;&gt;Website&lt;/a&gt;
    ·
    &lt;a href=&quot;https://github.com/AykutSarac/jsoncrack.com/issues&quot;&gt;Issues&lt;/a&gt;
    ·
    &lt;a href=&quot;https://marketplace.visualstudio.com/items?itemName=AykutSarac.jsoncrack-vscode&quot;&gt;VS Code&lt;/a&gt;
  &lt;/p&gt;
&lt;/p&gt;

&lt;!-- ABOUT THE PROJECT --&gt;

## About the Project

&lt;img width=&quot;100%&quot; alt=&quot;booking-screen&quot; src=&quot;./public/assets/editor.webp&quot;&gt;

## Visualize JSON into interactive graphs

JSON Crack is a tool for visualizing JSON data in a structured, interactive graphs, making it easier to explore, format, and validate JSON. It offers features like converting JSON to other formats (CSV, YAML), generating JSON Schema, executing queries, and exporting visualizations as images. Designed for both readability and usability.

* **Visualizer**: Instantly convert JSON, YAML, CSV, XML, and TOML into interactive graphs or trees in dark or light mode.
* **Convert**: Seamlessly transform data formats, like JSON to CSV or XML to JSON, for easy sharing.
* **Format &amp; Validate**: Beautify and validate JSON, YAML, and CSV for clear and accurate data.
* **Code Generation**: Generate TypeScript interfaces, Golang structs, and JSON Schema.
* **JSON Schema**: Create JSON Schema, mock data, and validate various data formats.
* **Advanced Tools**: Decode JWT, randomize data, and run jq or JSON path queries.
* **Export Image**: Download your visualization as PNG, JPEG, or SVG.
* **Privacy**: All data processing is local; nothing is stored on our servers.

## Recognition

&lt;a href=&quot;https://news.ycombinator.com/item?id=32626873&quot;&gt;
  &lt;img
    style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot;
    alt=&quot;Featured on Hacker News&quot;
    src=&quot;https://hackernews-badge.vercel.app/api?id=32626873&quot;
  /&gt;
&lt;/a&gt;

&lt;a href=&quot;https://producthunt.com/posts/JSON-Crack?utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-jsoncrack&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=332281&amp;theme=light&quot; alt=&quot;JSON Crack | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;

### Built With

- [Next.js](https://nextjs.org/?ref=jsoncrack.com)
- [React.js](https://reactjs.org/?ref=jsoncrack.com)
- [Reaflow](https://reaflow.dev/?ref=jsoncrack.com)
- [Monaco Editor](https://github.com/suren-atoyan/monaco-react)

## Stay Up-to-Date

JSON Crack officially launched as v1.0 on the 17th of February 2022 and we&#039;ve come a long way so far. Watch **releases** of this repository to be notified of future updates:

&lt;a href=&quot;https://github.com/AykutSarac/jsoncrack.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/AykutSarac/jsoncrack.com&quot; alt=&quot;Star at GitHub&quot; /&gt;&lt;/a&gt;

&lt;!-- GETTING STARTED --&gt;

## Getting Started

To get a local copy up and running, please follow these simple steps.

### Prerequisites

Here is what you need to be able to run JSON Crack.

- Node.js (Version: &gt;=18.x)
- Pnpm _(recommended)_


## Development

### Setup

1. Clone the repo into a public GitHub repository (or fork https://github.com/AykutSarac/jsoncrack.com/fork). If you plan to distribute the code, read the [`LICENSE`](/LICENSE.md) for additional details.

   ```sh
   git clone https://github.com/AykutSarac/jsoncrack.com.git
   ```

2. Go to the project folder

   ```sh
   cd jsoncrack.com
   ```

3. Install packages

   ```sh
   pnpm install
   ```

4. Run the project

   ```sh
   pnpm dev

   # Running on http://localhost:3000/
   ```

### Docker

🐳 A [`Dockerfile`](Dockerfile) is provided in the root of the repository.
If you want to run JSON Crack locally:

```console
# Build a Docker image with:
docker compose build

# Run locally with `docker-compose`
docker compose up

# Go to http://localhost:8888
```

## Configuration

The supported node limit can be changed by editing the `NEXT_PUBLIC_NODE_LIMIT` value in the `.env` file at the project root.

&lt;!-- LICENSE --&gt;

## License

See [`LICENSE`](/LICENSE.md) for more information.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[sst/opencode]]></title>
            <link>https://github.com/sst/opencode</link>
            <guid>https://github.com/sst/opencode</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[The AI coding agent built for the terminal.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sst/opencode">sst/opencode</a></h1>
            <p>The AI coding agent built for the terminal.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 26,440</p>
            <p>Forks: 1,908</p>
            <p>Stars today: 254 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencode.ai&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;packages/console/app/src/asset/logo-ornate-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;packages/console/app/src/asset/logo-ornate-light.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;packages/console/app/src/asset/logo-ornate-light.svg&quot; alt=&quot;OpenCode logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;The AI coding agent built for the terminal.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencode.ai/discord&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;label=discord&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/opencode-ai&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/opencode-ai?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/sst/opencode/actions/workflows/publish.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/sst/opencode/publish.yml?style=flat-square&amp;branch=dev&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

[![OpenCode Terminal UI](packages/web/src/assets/lander/screenshot.png)](https://opencode.ai)

---

### Installation

```bash
# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
brew install sst/tap/opencode      # macOS and Linux
paru -S opencode-bin               # Arch Linux
```

&gt; [!TIP]
&gt; Remove versions older than 0.1.x before installing.

#### Installation Directory

The install script respects the following priority order for the installation path:

1. `$OPENCODE_INSTALL_DIR` - Custom installation directory
2. `$XDG_BIN_DIR` - XDG Base Directory Specification compliant path
3. `$HOME/bin` - Standard user binary directory (if exists or can be created)
4. `$HOME/.opencode/bin` - Default fallback

```bash
# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
```

### Documentation

For more info on how to configure OpenCode [**head over to our docs**](https://opencode.ai/docs).

### Contributing

OpenCode is an opinionated tool so any fundamental feature needs to go through a
design process with the core team.

&gt; [!IMPORTANT]
&gt; We do not accept PRs for core features.

However we still merge a ton of PRs - you can contribute:

- Bug fixes
- Improvements to LLM performance
- Support for new providers
- Fixes for env specific quirks
- Missing standard behavior
- Documentation

Take a look at the git history to see what kind of PRs we end up merging.

&gt; [!NOTE]
&gt; If you do not follow the above guidelines we might close your PR.

To run OpenCode locally you need.

- Bun
- Golang 1.24.x

And run.

```bash
$ bun install
$ bun dev
```

#### Development Notes

**API Client**: After making changes to the TypeScript API endpoints in `packages/opencode/src/server/server.ts`, you will need the OpenCode team to generate a new stainless sdk for the clients.

### FAQ

#### How is this different than Claude Code?

It&#039;s very similar to Claude Code in terms of capability. Here are the key differences:

- 100% open source
- Not coupled to any provider. Although Anthropic is recommended, OpenCode can be used with OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.
- A focus on TUI. OpenCode is built by neovim users and the creators of [terminal.shop](https://terminal.shop); we are going to push the limits of what&#039;s possible in the terminal.
- A client/server architecture. This for example can allow OpenCode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.

#### What&#039;s the other repo?

The other confusingly named repo has no relation to this one. You can [read the story behind it here](https://x.com/thdxr/status/1933561254481666466).

---

**Join our community** [Discord](https://discord.gg/opencode) | [X.com](https://x.com/opencode)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[anthropics/claude-code]]></title>
            <link>https://github.com/anthropics/claude-code</link>
            <guid>https://github.com/anthropics/claude-code</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anthropics/claude-code">anthropics/claude-code</a></h1>
            <p>Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 35,410</p>
            <p>Forks: 2,190</p>
            <p>Stars today: 166 stars today</p>
            <h2>README</h2><pre># Claude Code

![](https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square) [![npm]](https://www.npmjs.com/package/@anthropic-ai/claude-code)

[npm]: https://img.shields.io/npm/v/@anthropic-ai/claude-code.svg?style=flat-square

Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows -- all through natural language commands. Use it in your terminal, IDE, or tag @claude on Github.

**Learn more in the [official documentation](https://docs.anthropic.com/en/docs/claude-code/overview)**.

&lt;img src=&quot;./demo.gif&quot; /&gt;

## Get started

1. Install Claude Code:

```sh
npm install -g @anthropic-ai/claude-code
```

2. Navigate to your project directory and run `claude`.

## Reporting Bugs

We welcome your feedback. Use the `/bug` command to report issues directly within Claude Code, or file a [GitHub issue](https://github.com/anthropics/claude-code/issues).

## Connect on Discord

Join the [Claude Developers Discord](https://anthropic.com/discord) to connect with other developers using Claude Code. Get help, share feedback, and discuss your projects with the community.

## Data collection, usage, and retention

When you use Claude Code, we collect feedback, which includes usage data (such as code acceptance or rejections), associated conversation data, and user feedback submitted via the `/bug` command.

### How we use your data

See our [data usage policies](https://docs.anthropic.com/en/docs/claude-code/data-usage).

### Privacy safeguards

We have implemented several safeguards to protect your data, including limited retention periods for sensitive information, restricted access to user session data, and clear policies against using feedback for model training.

For full details, please review our [Commercial Terms of Service](https://www.anthropic.com/legal/commercial-terms) and [Privacy Policy](https://www.anthropic.com/legal/privacy).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[Koenkk/zigbee2mqtt]]></title>
            <link>https://github.com/Koenkk/zigbee2mqtt</link>
            <guid>https://github.com/Koenkk/zigbee2mqtt</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[Zigbee 🐝 to MQTT bridge 🌉, get rid of your proprietary Zigbee bridges 🔨]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Koenkk/zigbee2mqtt">Koenkk/zigbee2mqtt</a></h1>
            <p>Zigbee 🐝 to MQTT bridge 🌉, get rid of your proprietary Zigbee bridges 🔨</p>
            <p>Language: TypeScript</p>
            <p>Stars: 14,018</p>
            <p>Forks: 1,831</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/koenkk/zigbee2mqtt&quot;&gt;
        &lt;img width=&quot;150&quot; height=&quot;150&quot; src=&quot;images/logo.png&quot;&gt;
    &lt;/a&gt;
    &lt;br&gt;
    &lt;br&gt;
    &lt;div style=&quot;display: flex;&quot;&gt;
        &lt;a href=&quot;https://github.com/Koenkk/zigbee2mqtt/releases&quot;&gt;
            &lt;img src=&quot;https://img.shields.io/github/release/koenkk/zigbee2mqtt.svg&quot;&gt;
        &lt;/a&gt;
        &lt;a href=&quot;https://www.npmjs.com/package/zigbee2mqtt&quot;&gt;
            &lt;img src=&quot;https://img.shields.io/npm/v/zigbee2mqtt&quot;&gt;
        &lt;/a&gt;
        &lt;a href=&quot;https://github.com/Koenkk/zigbee2mqtt/actions/workflows/ci.yml&quot;&gt;
            &lt;img src=&quot;https://github.com/Koenkk/zigbee2mqtt/actions/workflows/ci.yml/badge.svg&quot;&gt;
        &lt;/a&gt;
        &lt;a href=&quot;https://github.com/Koenkk/zigbee2mqtt/actions/workflows/github-code-scanning/codeql&quot;&gt;
            &lt;img src=&quot;https://github.com/Koenkk/zigbee2mqtt/actions/workflows/github-code-scanning/codeql/badge.svg&quot;&gt;
        &lt;/a&gt;
        &lt;a href=&quot;https://discord.gg/dadfWYE&quot;&gt;
            &lt;img src=&quot;https://img.shields.io/discord/556563650429583360.svg&quot;&gt;
        &lt;/a&gt;
        &lt;a href=&quot;https://github.com/Koenkk/zigbee2mqtt/stargazers&quot;&gt;
            &lt;img src=&quot;https://img.shields.io/github/stars/koenkk/zigbee2mqtt.svg&quot;&gt;
        &lt;/a&gt;
        &lt;a href=&quot;https://www.paypal.me/koenkk&quot;&gt;
            &lt;img src=&quot;https://img.shields.io/badge/donate-PayPal-blue.svg&quot;&gt;
        &lt;/a&gt;
    &lt;/div&gt;
    &lt;h1&gt;Zigbee2MQTT  🌉 🐝&lt;/h1&gt;
    &lt;p&gt;
        Allows you to use your Zigbee devices &lt;b&gt;without&lt;/b&gt; the vendor&#039;s bridge or gateway.
    &lt;/p&gt;
    &lt;p&gt;
        It bridges events and allows you to control your Zigbee devices via MQTT. In this way you can integrate your Zigbee devices with whatever smart home infrastructure you are using.
    &lt;/p&gt;
&lt;/div&gt;

## [Getting started](https://www.zigbee2mqtt.io/guide/getting-started)

The [documentation](https://www.zigbee2mqtt.io/) provides you all the information needed to get up and running! Make sure you don&#039;t skip sections if this is your first visit, as there might be important details in there for you.

If you aren&#039;t familiar with **Zigbee** terminology make sure you [read this](https://www.zigbee2mqtt.io/advanced/zigbee/01_zigbee_network.html) to help you out.

## [Integrations](https://www.zigbee2mqtt.io/guide/usage/integrations.html)

Zigbee2MQTT integrates well with (almost) every home automation solution because it uses MQTT. However the following integrations are worth mentioning:

### [Home Assistant](https://www.home-assistant.io/)

&lt;img align=&quot;left&quot; height=&quot;75px&quot; width=&quot;75px&quot; src=&quot;https://user-images.githubusercontent.com/7738048/40914297-49e6e560-6800-11e8-8904-36cce896e5a8.png&quot;&gt;

&lt;br clear=&quot;right&quot;&gt;

[Home Assistant OS](https://www.home-assistant.io/installation/) using [the official addon](https://github.com/zigbee2mqtt/hassio-zigbee2mqtt) ([other installations](https://www.zigbee2mqtt.io/guide/usage/integrations/home_assistant.html))

&lt;br clear=&quot;both&quot;&gt;

### [Homey](https://homey.app/)

&lt;img align=&quot;left&quot; height=&quot;75px&quot; width=&quot;75px&quot; src=&quot;https://etc.athom.com/logo/white/256.png&quot;&gt;

&lt;br clear=&quot;right&quot;&gt;

Integration implemented in the [Homey App](https://homey.app/nl-nl/app/com.gruijter.zigbee2mqtt/) ([documentation &amp; support](https://community.homey.app/t/83214))

&lt;br clear=&quot;both&quot;&gt;

### [Domoticz](https://www.domoticz.com/)

&lt;img align=&quot;left&quot; height=&quot;75px&quot; width=&quot;75px&quot; src=&quot;https://user-images.githubusercontent.com/2734836/47615848-b8dd8700-dabd-11e8-9d77-175002dd8987.png&quot;&gt;

&lt;br clear=&quot;right&quot;&gt;

Integration implemented in Domoticz ([documentation](https://www.domoticz.com/wiki/Zigbee2MQTT)).

&lt;br clear=&quot;both&quot;&gt;

### [Gladys Assistant](https://gladysassistant.com/)

&lt;img align=&quot;left&quot; height=&quot;75px&quot; width=&quot;75px&quot; src=&quot;./images/gladys-assistant-logo.jpg&quot;&gt;

&lt;br clear=&quot;right&quot;&gt;

Integration implemented natively in Gladys Assistant ([documentation](https://gladysassistant.com/docs/integrations/zigbee2mqtt/)).

&lt;br clear=&quot;both&quot;&gt;

### [IoBroker](https://www.iobroker.net/)

&lt;img align=&quot;left&quot; height=&quot;75px&quot; width=&quot;75px&quot; src=&quot;https://forum.iobroker.net/assets/uploads/system/site-logo.png&quot;&gt;

&lt;br clear=&quot;right&quot;&gt;

Integration implemented in IoBroker ([documentation](https://github.com/o0shojo0o/ioBroker.zigbee2mqtt)).

&lt;br clear=&quot;both&quot;&gt;

## Architecture

![Architecture](images/architecture-new.png)

### Internal Architecture

Zigbee2MQTT is made up of three modules, each developed in its own Github project. Starting from the hardware (adapter) and moving up; [zigbee-herdsman](https://github.com/koenkk/zigbee-herdsman) connects to your adapter to handle Zigbee communication and makes an API available to the higher levels of the stack. For e.g. Texas Instruments hardware, zigbee-herdsman uses the [TI zStack monitoring and test API](https://github.com/Koenkk/zigbee-herdsman/wiki/References#texas-instruments-zstack) to communicate with the adapter. The module [zigbee-herdsman-converters](https://github.com/koenkk/zigbee-herdsman-converters) handles the mapping from individual device models to the Zigbee clusters they support. [Zigbee clusters](https://github.com/Koenkk/zigbee-herdsman/wiki/References#csa-zigbee-alliance-spec) are the layers of the Zigbee protocol on top of the base protocol that define things like how lights, sensors and switches talk to each other over the Zigbee network. Finally, the Zigbee2MQTT module drives zigbee-herdsman and maps the zigbee messages to MQTT messages. Zigbee2MQTT also keeps track of the state of the system. It uses a `database.db` file to store this state; a text file with a JSON database of connected devices and their capabilities. Zigbee2MQTT provides several web-based interfaces ([zigbee2mqtt-frontend](https://github.com/nurikk/zigbee2mqtt-frontend), [zigbee2mqtt-windfront](https://github.com/Nerivec/zigbee2mqtt-windfront)) that allows monitoring and configuration.

### Developing

Zigbee2MQTT uses TypeScript. Therefore after making changes to files in the `lib/` directory you need to recompile Zigbee2MQTT. This can be done by executing `pnpm run build`. For faster development instead of running `pnpm run build` you can run `pnpm run build-watch` in another terminal session, this will recompile as you change files.

Before running any of the commands, you&#039;ll first need to run `pnpm install --include=dev`.
Before submitting changes run `pnpm run check:w` then `pnpm run test:coverage`.

## Supported devices

See [Supported devices](https://www.zigbee2mqtt.io/supported-devices) to check whether your device is supported. There is quite an extensive list, including devices from vendors like [Xiaomi](https://www.zigbee2mqtt.io/supported-devices/#v=Xiaomi), [Ikea](https://www.zigbee2mqtt.io/supported-devices/#v=IKEA), [Philips](https://www.zigbee2mqtt.io/supported-devices/#v=Philips), [OSRAM](https://www.zigbee2mqtt.io/supported-devices/#v=OSRAM) and more.

If it&#039;s not listed in [Supported devices](https://www.zigbee2mqtt.io/supported-devices), support can be added (fairly) easily, see [How to support new devices](https://www.zigbee2mqtt.io/advanced/support-new-devices/01_support_new_devices.html).

## Support &amp; help

If you need assistance you can check [opened issues](https://github.com/Koenkk/zigbee2mqtt/issues). Feel free to help with Pull Requests when you were able to fix things or add new devices or just share the love on social media.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[OvidijusParsiunas/deep-chat]]></title>
            <link>https://github.com/OvidijusParsiunas/deep-chat</link>
            <guid>https://github.com/OvidijusParsiunas/deep-chat</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[Fully customizable AI chatbot component for your website]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OvidijusParsiunas/deep-chat">OvidijusParsiunas/deep-chat</a></h1>
            <p>Fully customizable AI chatbot component for your website</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,216</p>
            <p>Forks: 392</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;

![Deep Chat](./assets/readme/banner-2.png)

&lt;b&gt;Deep Chat&lt;/b&gt; is a fully customizable AI chat component that can be injected into your website with just _one line of code_. Whether you want to create a chatbot that leverages popular APIs such as ChatGPT or connect to your own custom service, this component can do it all! Explore [deepchat.dev](https://deepchat.dev/) to view all of the available features, how to use them, examples and more!

### :rocket: Main Features

- Connect to any API
- Avatars
- Names
- Send/Receive files
- Capture photos via webcam
- Record audio via microphone
- Speech To Speech communication
- Speech To Text for message input
- Text To Speech to hear message responses
- Support for MarkDown and custom elements to help structure text and render code
- Introduction panel and dynamic modals to help describe functionality for your users
- Connect to popular AI APIs such as OpenAI, HuggingFace, Cohere directly from the browser
- Communicate with Speech to Speech models
- Support for all major ui frameworks/libraries
- Host a model on the browser
- Focus mode to display only the latest messages
- Everything is customizable!

### :tada: Latest Updates

Deep Chat version `2.2.2` brings a ton of new features into the Deep Chat ecosystem:

- [`browserStorage`](https://deepchat.dev/docs/messages/#browserStorage) allows you store messages locally on your browser without worrying about a backend message integration.
- Button [tooltips](https://deepchat.dev/docs/styles/buttons#Tooltip).
- Place your streamed messages inside custom [`htmlWrappers`](https://deepchat.dev/docs/messages/HTML#htmlWrappers).
- See [release notes](https://github.com/OvidijusParsiunas/deep-chat/releases/tag/2.2.2) for more!

&lt;p align=&quot;center&quot;&gt;
    &lt;img width=&quot;960&quot; src=&quot;https://github.com/user-attachments/assets/51e900ea-43c6-41ca-b255-8b7d59285b26&quot; alt=&quot;version 2.2.2&quot;&gt;
&lt;/p&gt;

`2.2.0` update:

- [OpenAI Realtime API](https://deepchat.dev/docs/directConnection/OpenAI/OpenAIRealtime) for Speech to Speech communication
- [Focus mode](https://deepchat.dev/docs/modes#focusMode) to only display the latest message exchanges and provide a modern AI Chatbot experience
- [Custom buttons](https://deepchat.dev/docs/styles/buttons#customButtons)
- A [Response](https://deepchat.dev/docs/connect#Response) can now have multiple messages
- Ability to connect to [Readable Stream APIs](https://deepchat.dev/docs/connect#Stream)
- See [release notes](https://github.com/OvidijusParsiunas/deep-chat/releases/tag/2.2.0) for more!

&lt;p align=&quot;center&quot;&gt;
    &lt;img width=&quot;1000&quot; src=&quot;https://github.com/user-attachments/assets/6089a0b4-0fe6-43e9-b9ce-840a9cfda885&quot; alt=&quot;version 2.2.0&quot;&gt;
&lt;/p&gt;

`2.1.1` update:

- [Azure OpenAI API](https://deepchat.dev/docs/directConnection/Azure#OpenAI)
- [`loadHistory`](https://deepchat.dev/docs/interceptors#loadHistory) interceptor to asynchronously load history and pagination
- [`updateMessage`](https://deepchat.dev/docs/methods#updateMessage) method to dynamically update messages
- Custom configuration for message text [MarkDown](https://deepchat.dev/docs/messages/styles#remarkable) rendering
- Ability to [group messages](https://deepchat.dev/docs/messages/styles#groupedMessages)
- See [release notes](https://github.com/OvidijusParsiunas/deep-chat/releases/tag/2.1.1) for more!

&lt;p align=&quot;center&quot;&gt;
    &lt;img width=&quot;1000&quot; src=&quot;https://github.com/user-attachments/assets/1e86d151-a7e4-4add-961e-af2c55315a9d&quot; alt=&quot;version 2.1.0&quot;&gt;
&lt;/p&gt;

### :computer: Getting started

```
npm install deep-chat
```

If using React, install the following instead:

```
npm install deep-chat-react
```

Simply add the following to your markup:

```
&lt;deep-chat&gt;&lt;/deep-chat&gt;
```

The exact syntax for the above will vary depending on the framework of your choice ([see here](https://deepchat.dev/examples/frameworks)).

### :zap: Connect

![Connect](./assets/readme/connect.png)

Connecting to a service is simple, all you need to do is define its API details using the [`request`](https://deepchat.dev/docs/connect#request) property:

```
&lt;deep-chat request=&#039;{&quot;url&quot;:&quot;https://service.com/chat&quot;}&#039;/&gt;
```

The service will need to be able to handle request and response formats used in Deep Chat. Please read the [Connect](https://deepchat.dev/docs/connect) section in documentation and check out the [server template](https://deepchat.dev/examples/servers) examples.

Alternatively, if you want to connect without changing the target service, use the [`interceptor`](https://deepchat.dev/docs/interceptors) properties to augment the transferred objects or the [`handler`](https://deepchat.dev/docs/connect#Handler) function to control the request code.

### :electric_plug: Direct connection

![Direct connection](./assets/readme/direct-connect.png)

Connect to popular AI APIs directly from the browser via the use of the [`directConnection`](https://deepchat.dev/docs/directConnection/#directConnection) property:

```
&lt;deep-chat directConnection=&#039;{&quot;openAI&quot;:true}&#039;/&gt;

&lt;deep-chat directConnection=&#039;{&quot;openAI&quot;:{&quot;key&quot;: &quot;optional-key-here&quot;}}&#039;/&gt;
```

Please note that this approach should be used for local/prototyping/demo purposes ONLY as it exposes the API Key to the browser. When ready to go live, please switch to using the [`connect`](https://deepchat.dev/docs/connect#connect-1) property described above along with a [proxy service](https://github.com/OvidijusParsiunas/deep-chat/tree/main/example-servers).

Currently supported direct API connections:
[OpenAI](https://openai.com/blog/openai-api), [HuggingFace](https://huggingface.co/docs/api-inference/index), [Cohere](https://docs.cohere.com/docs), [Stability AI](https://stability.ai/), [Azure](https://learn.microsoft.com/en-gb/azure/cognitive-services/), [AssemblyAI](https://www.assemblyai.com/)

### :robot: Web model

![Web Model](https://github.com/OvidijusParsiunas/deep-chat/assets/18709577/83936e6f-d0c1-42b7-ab61-ac75d7803660)

No servers, no connections, host an LLM model entirely on your browser.

Simply add the [deep-chat-web-llm](https://deepchat.dev/examples/externalModules) module and define the [webModel](https://deepchat.dev/docs/webModel) property:

```
&lt;deep-chat webModel=&quot;true&quot; /&gt;
```

### :camera: :microphone: Camera and Microphone

![Capture](./assets/readme/capture.png)

Use Deep Chat to capture photos with your webcam and record audio with the microphone. You can enable this using the [`camera`](https://deepchat.dev/docs/files#camera) and [`microphone`](https://deepchat.dev/docs/files#microphone) properties:

```
&lt;deep-chat camera=&quot;true&quot; microphone=&quot;true&quot; ...other properties /&gt;
```

### :microphone: :sound: Speech

https://github.com/OvidijusParsiunas/deep-chat/assets/18709577/e103a42e-b3a7-4449-b9db-73fed6d7876e

Input text with your voice using Speech To Text capabilities and have the responses read out to you with Text To Speech. You can enable this functionality via the [`speechToText`](https://deepchat.dev/docs/speech#speechToText) and [`textToSpeech`](https://deepchat.dev/docs/speech#textToSpeech) properties.

```
&lt;deep-chat speechToText=&quot;true&quot; textToSpeech=&quot;true&quot; ...other properties /&gt;
```

### :beginner: Examples

Check out live codepen examples for your [UI framework/library](https://deepchat.dev/examples/frameworks) of choice:

| React                                                                                                                                                   | Vue 2                                                                                                                                                   | Vue 3                                                                                                                                                | Svelte                                                                                                                                                       | SvelteKit                                                                                                                                                                                               | Angular                                                                                                                                                                             | Solid                                                                                                                                                   | Next                                                                                                                                  | Nuxt                                                                                                                                                 | VanillaJS                                                                                                                                                         |
| ------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;a href=&quot;https://stackblitz.com/edit/deep-chat-react?file=src%2FApp.tsx&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/reactLogo.png&quot; width=&quot;60&quot;/&gt;&lt;/a&gt; | &lt;a href=&quot;https://codesandbox.io/s/deep-chat-vue2-cdqpt2?file=/src/App.vue&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/vueLogo.png&quot; width=&quot;60&quot;/&gt;&lt;/a&gt; | &lt;a href=&quot;https://stackblitz.com/edit/deep-chat-vue3?file=src%2FApp.vue&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/vueLogo.png&quot; width=&quot;60&quot;/&gt;&lt;/a&gt; | &lt;a href=&quot;https://stackblitz.com/edit/deep-chat-svelte?file=src%2FApp.svelte&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/svelteLogo.png&quot; width=&quot;45&quot;/&gt;&lt;/a&gt; | &lt;div align=&quot;center&quot;&gt;&lt;a href=&quot;https://stackblitz.com/edit/deep-chat-sveltekit?file=src%2Froutes%2F%2Bpage.svelte&quot; target=&quot;_blank&quot; &gt;&lt;img src=&quot;./website/static/img/svelteLogo.png&quot; width=&quot;45&quot;/&gt;&lt;/a&gt;&lt;/div&gt; | &lt;a href=&quot;https://stackblitz.com/edit/stackblitz-starters-7gygrp?file=src%2Fapp%2Fapp.component.ts&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/angularLogo.png&quot; width=&quot;66&quot;/&gt;&lt;/a&gt; | &lt;a href=&quot;https://stackblitz.com/edit/deep-chat-solid?file=src%2FApp.tsx&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/solidLogo.png&quot; width=&quot;60&quot;/&gt;&lt;/a&gt; | &lt;a href=&quot;https://deepchat.dev/examples/frameworks#next&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/nextLogo.png&quot; width=&quot;60&quot;/&gt;&lt;/a&gt; | &lt;a href=&quot;https://stackblitz.com/edit/nuxt-starter-vwz6pg?file=app.vue&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/nuxtLogo.png&quot; width=&quot;70&quot;/&gt;&lt;/a&gt; | &lt;a href=&quot;https://codesandbox.io/s/deep-chat-vanillajs-v2ywnv?file=/index.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/vanillaJSLogo.png&quot; width=&quot;60&quot;/&gt;&lt;/a&gt; |

Setting up your own server has never been easier with the following [server templates](https://deepchat.dev/examples/servers). From creating your own service to establishing proxies for other APIs such as OpenAI, everything has been documented with clear examples to get you up and running in seconds:

| Express                                                                                                                                                                          | Nest                                                                                                                                                                         | Flask                                                                                                                                                                          | Spring                                                                                                                                                                                 | Go                                                                                                                                                                | SvelteKit                                                                                                                                                                                               | Next                                                                                                                                                                    |
| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| &lt;a href=&quot;https://github.com/OvidijusParsiunas/deep-chat/tree/main/example-servers/node/express&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/expressLogo.png&quot; width=&quot;60&quot;/&gt;&lt;/a&gt; | &lt;a href=&quot;https://github.com/OvidijusParsiunas/deep-chat/tree/main/example-servers/node/nestjs&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/nestLogo.png&quot; width=&quot;60&quot;/&gt;&lt;/a&gt; | &lt;a href=&quot;https://github.com/OvidijusParsiunas/deep-chat/tree/main/example-servers/python/flask&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/flaskLogo.png&quot; width=&quot;60&quot;/&gt;&lt;/a&gt; | &lt;a href=&quot;https://github.com/OvidijusParsiunas/deep-chat/tree/main/example-servers/java/springboot&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/springBootLogo.png&quot; width=&quot;50&quot;/&gt;&lt;/a&gt; | &lt;a href=&quot;https://github.com/OvidijusParsiunas/deep-chat/tree/main/example-servers/go&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/goLogo.png&quot; width=&quot;40&quot;/&gt;&lt;/a&gt; | &lt;div align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/OvidijusParsiunas/deep-chat/tree/main/example-servers/sveltekit&quot; target=&quot;_blank&quot; &gt;&lt;img src=&quot;./website/static/img/svelteLogo.png&quot; width=&quot;45&quot;/&gt;&lt;/a&gt;&lt;/div&gt; | &lt;a href=&quot;https://github.com/OvidijusParsiunas/deep-chat/tree/main/example-servers/nextjs&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./website/static/img/nextLogo.png&quot; width=&quot;55&quot;/&gt;&lt;/a&gt; |

All examples are ready to be deployed on a hosting platform such as [Vercel](https://vercel.com/).

## :tv: Tutorials

Demo videos are available on [YouTube](https://www.youtube.com/@ovi-il4rg/videos):

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.youtube.com/@ovi-il4rg/videos&quot;&gt;
        &lt;img width=&quot;1000&quot; src=&quot;https://github.com/OvidijusParsiunas/deep-chat/assets/18709577/29cc292b-5964-4f06-ba39-6ae3f8585944&quot; alt=&quot;Videos&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

## :joystick: Playground

Create, configure and use Deep Chat components without writing any code in the official [Playground](https://deepchat.dev/playground)!

&lt;p align=&quot;center&quot;&gt;
    &lt;img width=&quot;750&quot; src=&quot;https://github.com/OvidijusParsiunas/deep-chat/assets/18709577/57ab8d3f-defe-40f3-a0af-451f6159bbb2&quot; alt=&quot;Playground&quot;&gt;
&lt;/p&gt;

:tada: &lt;b&gt;Update&lt;/b&gt; - components can now be stretched to full screen dimensions using the new &lt;b&gt;Expanded View&lt;/b&gt;:

&lt;p align=&quot;center&quot;&gt;
    &lt;img width=&quot;750&quot; src=&quot;https://github.com/OvidijusParsiunas/deep-chat/assets/18709577/6b78907c-c4c2-44de-b4c7-d73c1e887fa8&quot; alt=&quot;Expanded View&quot;&gt;
&lt;/p&gt;

## :star2: Sponsors

Thankyou to our generous sponsors!

&lt;p align=&quot;center&quot;&gt;
    &amp;nbsp; &amp;nbsp; &amp;nbsp; 
    &lt;img src=&quot;https://github.com/dorra.png&quot; width=&quot;110px&quot;/&gt;
    &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;  
    &lt;img src=&quot;https://github.com/techpeace.png&quot; width=&quot;110px&quot; /&gt;
    &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;  
    &lt;img src=&quot;https://github.com/ChiaoGeek.png&quot; width=&quot;110px&quot; /&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 
    &lt;a href=&quot;https://github.com/dorra&quot;&gt;dorra&lt;/a&gt;
    &amp;nbsp; &amp;nbsp;  &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp; 
    &lt;a href=&quot;https://github.com/techpeace&quot;&gt;techpeace&lt;/a&gt;
      &amp;nbsp; &amp;nbsp;  &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &amp;nbsp;
    &lt;a href=&quot;https://github.com/ChiaoGeek&quot;&gt;ChiaoGeek&lt;/a&gt;
     &amp;nbsp;
&lt;/p&gt;

## :heart: Contributions

Open source is built by the community for the community. All contributions to this project are welcome!&lt;br&gt;
Additionally, if you have any suggestions for enhancements, ideas on how to take the project further or have discovered a bug, do not hesitate to create a new issue ticket and we will look into it as soon as possible!
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[appwrite/appwrite]]></title>
            <link>https://github.com/appwrite/appwrite</link>
            <guid>https://github.com/appwrite/appwrite</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[Build like a team of hundreds_]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/appwrite/appwrite">appwrite/appwrite</a></h1>
            <p>Build like a team of hundreds_</p>
            <p>Language: TypeScript</p>
            <p>Stars: 52,951</p>
            <p>Forks: 4,712</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>&gt; We just announced API for spatial columns for Appwrite Databases - [Learn more](https://appwrite.io/blog/post/announcing-spatial-columns)

&gt; Appwrite Cloud is now Generally Available - [Learn more](https://appwrite.io/cloud-ga)

&gt; [Get started with Appwrite](https://apwr.dev/appcloud)

&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://appwrite.io&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./public/images/banner.png&quot; alt=&quot;Appwrite banner, with logo and text saying &quot;Build Like a Team of Hundreds&quot;&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;b&gt;Appwrite is an all-in-one development platform for Web, Mobile, and Flutter applications. Use built-in backend infrastructure and web hosting, all from a single place. Built with the open source community and optimized for developer experience in the coding languages you love.&lt;/b&gt;
    &lt;br /&gt;
    &lt;br /&gt;
&lt;/p&gt;

&lt;!-- [![Build Status](https://img.shields.io/travis/com/appwrite/appwrite?style=flat-square)](https://travis-ci.com/appwrite/appwrite) --&gt;

[![We&#039;re Hiring label](https://img.shields.io/static/v1?label=We&#039;re&amp;message=Hiring&amp;color=blue&amp;style=flat-square)](https://appwrite.io/company/careers)
[![Hacktoberfest label](https://img.shields.io/static/v1?label=hacktoberfest&amp;message=ready&amp;color=191120&amp;style=flat-square)](https://hacktoberfest.appwrite.io)
[![Discord label](https://img.shields.io/discord/564160730845151244?label=discord&amp;style=flat-square)](https://appwrite.io/discord?r=Github)
[![Build Status label](https://img.shields.io/github/actions/workflow/status/appwrite/appwrite/tests.yml?branch=master&amp;label=tests&amp;style=flat-square)](https://github.com/appwrite/appwrite/actions)
[![X Account label](https://img.shields.io/twitter/follow/appwrite?color=00acee&amp;label=twitter&amp;style=flat-square)](https://twitter.com/appwrite)

&lt;!-- [![Docker Pulls](https://img.shields.io/docker/pulls/appwrite/appwrite?color=f02e65&amp;style=flat-square)](https://hub.docker.com/r/appwrite/appwrite) --&gt;
&lt;!-- [![Translate](https://img.shields.io/badge/translate-f02e65?style=flat-square)](docs/tutorials/add-translations.md) --&gt;
&lt;!-- [![Swag Store](https://img.shields.io/badge/swag%20store-f02e65?style=flat-square)](https://store.appwrite.io) --&gt;

English | [简体中文](README-CN.md)

Appwrite is an end-to-end platform for building Web, Mobile, Native, or Backend apps, packaged as a set of Docker microservices. It includes both a backend server and a fully integrated hosting solution for deploying static and server-side rendered frontends. Appwrite abstracts the complexity and repetitiveness required to build modern apps from scratch and allows you to build secure, full-stack applications faster.

Using Appwrite, you can easily integrate your app with user authentication and multiple sign-in methods, a database for storing and querying users and team data, storage and file management, image manipulation, Cloud Functions, messaging, and [more services](https://appwrite.io/docs).

&lt;p align=&quot;center&quot;&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://www.producthunt.com/posts/appwrite-2?utm_source=badge-top-post-badge&amp;utm_medium=badge&amp;utm_souce=badge-appwrite-2&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=360315&amp;theme=light&amp;period=daily&quot; alt=&quot;Appwrite - 100&amp;#0037;&amp;#0032;open&amp;#0032;source&amp;#0032;alternative&amp;#0032;for&amp;#0032;Firebase | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
&lt;/p&gt;

![Appwrite project dashboard showing various Appwrite features](public/images/github.png)

Find out more at: [https://appwrite.io](https://appwrite.io).

Table of Contents:

- [Installation \&amp; Setup](#installation--setup)
- [Self-Hosting](#self-hosting)
  - [Unix](#unix)
  - [Windows](#windows)
    - [CMD](#cmd)
    - [PowerShell](#powershell)
  - [Upgrade from an Older Version](#upgrade-from-an-older-version)
- [One-Click Setups](#one-click-setups)
- [Getting Started](#getting-started)
  - [Products](#products)
  - [SDKs](#sdks)
    - [Client](#client)
    - [Server](#server)
    - [Community](#community)
- [Architecture](#architecture)
- [Contributing](#contributing)
- [Security](#security)
- [Follow Us](#follow-us)
- [License](#license)

## Installation &amp; Setup

The easiest way to get started with Appwrite is by [signing up for Appwrite Cloud](https://cloud.appwrite.io/). While Appwrite Cloud is in public beta, you can build with Appwrite completely free, and we won&#039;t collect your credit card information.

## Self-Hosting

Appwrite is designed to run in a containerized environment. Running your server is as easy as running one command from your terminal. You can either run Appwrite on your localhost using docker-compose or on any other container orchestration tool, such as [Kubernetes](https://kubernetes.io/docs/home/), [Docker Swarm](https://docs.docker.com/engine/swarm/), or [Rancher](https://rancher.com/docs/).

Before running the installation command, make sure you have [Docker](https://www.docker.com/products/docker-desktop) installed on your machine:

### Unix

```bash
docker run -it --rm \
    --volume /var/run/docker.sock:/var/run/docker.sock \
    --volume &quot;$(pwd)&quot;/appwrite:/usr/src/code/appwrite:rw \
    --entrypoint=&quot;install&quot; \
    appwrite/appwrite:1.7.4
```

### Windows

#### CMD

```cmd
docker run -it --rm ^
    --volume //var/run/docker.sock:/var/run/docker.sock ^
    --volume &quot;%cd%&quot;/appwrite:/usr/src/code/appwrite:rw ^
    --entrypoint=&quot;install&quot; ^
    appwrite/appwrite:1.7.4
```

#### PowerShell

```powershell
docker run -it --rm `
    --volume /var/run/docker.sock:/var/run/docker.sock `
    --volume ${pwd}/appwrite:/usr/src/code/appwrite:rw `
    --entrypoint=&quot;install&quot; `
    appwrite/appwrite:1.7.4
```

Once the Docker installation is complete, go to http://localhost to access the Appwrite console from your browser. Please note that on non-Linux native hosts, the server might take a few minutes to start after completing the installation.

For advanced production and custom installation, check out our Docker [environment variables](https://appwrite.io/docs/environment-variables) docs. You can also use our public [docker-compose.yml](https://appwrite.io/install/compose) and [.env](https://appwrite.io/install/env) files to manually set up an environment.

### Upgrade from an Older Version

If you are upgrading your Appwrite server from an older version, you should use the Appwrite migration tool once your setup is completed. For more information regarding this, check out the [Installation Docs](https://appwrite.io/docs/self-hosting).

## One-Click Setups

In addition to running Appwrite locally, you can also launch Appwrite using a pre-configured setup. This allows you to get up and running quickly with Appwrite without installing Docker on your local machine.

Choose from one of the providers below:

&lt;table border=&quot;0&quot;&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;
      &lt;a href=&quot;https://marketplace.digitalocean.com/apps/appwrite&quot;&gt;
        &lt;img width=&quot;50&quot; height=&quot;39&quot; src=&quot;public/images/integrations/digitalocean-logo.svg&quot; alt=&quot;DigitalOcean Logo&quot; /&gt;
          &lt;br /&gt;&lt;sub&gt;&lt;b&gt;DigitalOcean&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;
      &lt;a href=&quot;https://gitpod.io/#https://github.com/appwrite/integration-for-gitpod&quot;&gt;
        &lt;img width=&quot;50&quot; height=&quot;39&quot; src=&quot;public/images/integrations/gitpod-logo.svg&quot; alt=&quot;Gitpod Logo&quot; /&gt;
          &lt;br /&gt;&lt;sub&gt;&lt;b&gt;Gitpod&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;
      &lt;a href=&quot;https://www.linode.com/marketplace/apps/appwrite/appwrite/&quot;&gt;
        &lt;img width=&quot;50&quot; height=&quot;39&quot; src=&quot;public/images/integrations/akamai-logo.svg&quot; alt=&quot;Akamai Logo&quot; /&gt;
          &lt;br /&gt;&lt;sub&gt;&lt;b&gt;Akamai Compute&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;
      &lt;a href=&quot;https://aws.amazon.com/marketplace/pp/prodview-2hiaeo2px4md6&quot;&gt;
        &lt;img width=&quot;50&quot; height=&quot;39&quot; src=&quot;public/images/integrations/aws-logo.svg&quot; alt=&quot;AWS Logo&quot; /&gt;
          &lt;br /&gt;&lt;sub&gt;&lt;b&gt;AWS Marketplace&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Getting Started

Getting started with Appwrite is as easy as creating a new project, choosing your platform, and integrating its SDK into your code. You can easily get started with your platform of choice by reading one of our Getting Started tutorials.

| Platform              | Technology                                                                         |
| --------------------- | ---------------------------------------------------------------------------------- |
| **Web app**           | [Quick start for Web](https://appwrite.io/docs/quick-starts/web)                   |
|                       | [Quick start for Next.js](https://appwrite.io/docs/quick-starts/nextjs)            |
|                       | [Quick start for React](https://appwrite.io/docs/quick-starts/react)               |
|                       | [Quick start for Vue.js](https://appwrite.io/docs/quick-starts/vue)                |
|                       | [Quick start for Nuxt](https://appwrite.io/docs/quick-starts/nuxt)                 |
|                       | [Quick start for SvelteKit](https://appwrite.io/docs/quick-starts/sveltekit)       |
|                       | [Quick start for Refine](https://appwrite.io/docs/quick-starts/refine)             |
|                       | [Quick start for Angular](https://appwrite.io/docs/quick-starts/angular)           |
| **Mobile and Native** | [Quick start for React Native](https://appwrite.io/docs/quick-starts/react-native) |
|                       | [Quick start for Flutter](https://appwrite.io/docs/quick-starts/flutter)           |
|                       | [Quick start for Apple](https://appwrite.io/docs/quick-starts/apple)               |
|                       | [Quick start for Android](https://appwrite.io/docs/quick-starts/android)           |
| **Server**            | [Quick start for Node.js](https://appwrite.io/docs/quick-starts/node)              |
|                       | [Quick start for Python](https://appwrite.io/docs/quick-starts/python)             |
|                       | [Quick start for .NET](https://appwrite.io/docs/quick-starts/dotnet)               |
|                       | [Quick start for Dart](https://appwrite.io/docs/quick-starts/dart)                 |
|                       | [Quick start for Ruby](https://appwrite.io/docs/quick-starts/ruby)                 |
|                       | [Quick start for Deno](https://appwrite.io/docs/quick-starts/deno)                 |
|                       | [Quick start for PHP](https://appwrite.io/docs/quick-starts/php)                   |
|                       | [Quick start for Kotlin](https://appwrite.io/docs/quick-starts/kotlin)             |
|                       | [Quick start for Swift](https://appwrite.io/docs/quick-starts/swift)               |

### Products

- [**Account**](https://appwrite.io/docs/references/cloud/client-web/account) - Manage current user authentication and account. Track and manage the user sessions, devices, sign-in methods, and security logs.
- [**Users**](https://appwrite.io/docs/server/users) - Manage and list all project users when building backend integrations with Server SDKs.
- [**Teams**](https://appwrite.io/docs/references/cloud/client-web/teams) - Manage and group users in teams. Manage memberships, invites, and user roles within a team.
- [**Databases**](https://appwrite.io/docs/references/cloud/client-web/databases) - Manage databases, collections, and documents. Read, create, update, and delete documents and filter lists of document collections using advanced filters.
- [**Storage**](https://appwrite.io/docs/references/cloud/client-web/storage) - Manage storage files. Read, create, delete, and preview files. Manipulate the preview of your files to perfectly fit your app. All files are scanned by ClamAV and stored in a secure and encrypted way.
- [**Functions**](https://appwrite.io/docs/references/cloud/server-nodejs/functions) - Customize your Appwrite project by executing your custom code in a secure, isolated environment. You can trigger your code on any Appwrite system event either manually or using a CRON schedule.
- [**Messaging**](https://appwrite.io/docs/references/cloud/client-web/messaging) - Communicate with your users through push notifications, emails, and SMS text messages using Appwrite Messaging.
- [**Realtime**](https://appwrite.io/docs/realtime) - Listen to real-time events for any of your Appwrite services including users, storage, functions, databases, and more.
- [**Locale**](https://appwrite.io/docs/references/cloud/client-web/locale) - Track your user&#039;s location and manage your app locale-based data.
- [**Avatars**](https://appwrite.io/docs/references/cloud/client-web/avatars) - Manage your users&#039; avatars, countries&#039; flags, browser icons, and credit card symbols. Generate QR codes from links or plaintext strings.
- [**MCP**](https://appwrite.io/docs/tooling/mcp) - Use Appwrite&#039;s Model Context Protocol (MCP) server to allow LLMs and AI tools like Claude Desktop, Cursor, and Windsurf Editor to directly interact with your Appwrite project through natural language.
- [**Sites**](https://appwrite.io/docs/products/sites) - Develop, deploy, and scale your web applications directly from Appwrite, alongside your backend.

For the complete API documentation, visit [https://appwrite.io/docs](https://appwrite.io/docs). For more tutorials, news and announcements check out our [blog](https://medium.com/appwrite-io) and [Discord Server](https://discord.gg/GSeTUeA).

### SDKs

Below is a list of currently supported platforms and languages. If you would like to help us add support to your platform of choice, you can go over to our [SDK Generator](https://github.com/appwrite/sdk-generator) project and view our [contribution guide](https://github.com/appwrite/sdk-generator/blob/master/CONTRIBUTING.md).

#### Client

- :white_check_mark: &amp;nbsp; [Web](https://github.com/appwrite/sdk-for-web) (Maintained by the Appwrite Team)
- :white_check_mark: &amp;nbsp; [Flutter](https://github.com/appwrite/sdk-for-flutter) (Maintained by the Appwrite Team)
- :white_check_mark: &amp;nbsp; [Apple](https://github.com/appwrite/sdk-for-apple) (Maintained by the Appwrite Team)
- :white_check_mark: &amp;nbsp; [Android](https://github.com/appwrite/sdk-for-android) (Maintained by the Appwrite Team)
- :white_check_mark: &amp;nbsp; [React Native](https://github.com/appwrite/sdk-for-react-native) - **Beta** (Maintained by the Appwrite Team)

#### Server

- :white_check_mark: &amp;nbsp; [NodeJS](https://github.com/appwrite/sdk-for-node) (Maintained by the Appwrite Team)
- :white_check_mark: &amp;nbsp; [PHP](https://github.com/appwrite/sdk-for-php) (Maintained by the Appwrite Team)
- :white_check_mark: &amp;nbsp; [Dart](https://github.com/appwrite/sdk-for-dart) (Maintained by the Appwrite Team)
- :white_check_mark: &amp;nbsp; [Deno](https://github.com/appwrite/sdk-for-deno) (Maintained by the Appwrite Team)
- :white_check_mark: &amp;nbsp; [Ruby](https://github.com/appwrite/sdk-for-ruby) (Maintained by the Appwrite Team)
- :white_check_mark: &amp;nbsp; [Python](https://github.com/appwrite/sdk-for-python) (Maintained by the Appwrite Team)
- :white_check_mark: &amp;nbsp; [Kotlin](https://github.com/appwrite/sdk-for-kotlin) (Maintained by the Appwrite Team)
- :white_check_mark: &amp;nbsp; [Swift](https://github.com/appwrite/sdk-for-swift) (Maintained by the Appwrite Team)
- :white_check_mark: &amp;nbsp; [.NET](https://github.com/appwrite/sdk-for-dotnet) - **Beta** (Maintained by the Appwrite Team)

#### Community

- :white_check_mark: &amp;nbsp; [Appcelerator Titanium](https://github.com/m1ga/ti.appwrite) (Maintained by [Michael Gangolf](https://github.com/m1ga/))
- :white_check_mark: &amp;nbsp; [Godot Engine](https://github.com/GodotNuts/appwrite-sdk) (Maintained by [fenix-hub @GodotNuts](https://github.com/fenix-hub))

Looking for more SDKs? - Help us by contributing a pull request to our [SDK Generator](https://github.com/appwrite/sdk-generator)!

## Architecture

![Appwrite Architecture showing how Appwrite is built and the services and tools it uses](docs/specs/overview.drawio.svg)

Appwrite uses a microservices architecture that was designed for easy scaling and delegation of responsibilities. In addition, Appwrite supports multiple APIs, such as REST, WebSocket, and GraphQL to allow you to interact with your resources by leveraging your existing knowledge and protocols of choice.

The Appwrite API layer was designed to be extremely fast by leveraging in-memory caching and delegating any heavy-lifting tasks to the Appwrite background workers. The background workers also allow you to precisely control your compute capacity and costs using a message queue to handle the load. You can learn more about our architecture in the [contribution guide](CONTRIBUTING.md#architecture-1).

## Contributing

All code contributions, including those of people having commit access, must go through a pull request and be approved by a core developer before being merged. This is to ensure a proper review of all the code.

We truly :heart: pull requests! If you wish to help, you can learn more about how you can contribute to this project in the [contribution guide](CONTRIBUTING.md).

## Security

For security issues, kindly email us at [security@appwrite.io](mailto:security@appwrite.io) instead of posting a public issue on GitHub.

## Follow Us

Join our growing community around the world! Check out our official [Blog](https://appwrite.io/blog). Follow us on [X](https://twitter.com/appwrite), [LinkedIn](https://www.linkedin.com/company/appwrite/), [Dev Community](https://dev.to/appwrite) or join our live [Discord server](https://appwrite.io/discord) for more help, ideas, and discussions.

## License

This repository is available under the [BSD 3-Clause License](./LICENSE).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[expo/expo]]></title>
            <link>https://github.com/expo/expo</link>
            <guid>https://github.com/expo/expo</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[An open-source framework for making universal native apps with React. Expo runs on Android, iOS, and the web.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/expo/expo">expo/expo</a></h1>
            <p>An open-source framework for making universal native apps with React. Expo runs on Android, iOS, and the web.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 43,817</p>
            <p>Forks: 8,961</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre>&lt;!-- Banner Image --&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://expo.dev/&quot;&gt;
    &lt;img alt=&quot;Expo logo&quot; height=&quot;128&quot; src=&quot;./.github/resources/banner.png&quot;&gt;
    &lt;h1 align=&quot;center&quot;&gt;Expo&lt;/h1&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
   &lt;a aria-label=&quot;SDK version&quot; href=&quot;https://www.npmjs.com/package/expo&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo SDK version&quot; src=&quot;https://img.shields.io/npm/v/expo.svg?style=flat-square&amp;label=SDK&amp;labelColor=000000&amp;color=4630EB&quot; /&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Chat or ask a question&quot; href=&quot;https://chat.expo.dev&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Chat or ask a question&quot; src=&quot;https://img.shields.io/discord/695411232856997968.svg?style=flat-square&amp;labelColor=000000&amp;color=4630EB&amp;logo=discord&amp;logoColor=FFFFFF&amp;label=Chat%20with%20us&quot; /&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Expo is free to use&quot; href=&quot;https://github.com/expo/expo/blob/main/LICENSE&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;License: MIT&quot; src=&quot;https://img.shields.io/badge/License-MIT-success.svg?style=flat-square&amp;color=33CC12&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;expo downloads&quot; href=&quot;http://www.npmtrends.com/expo&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Downloads&quot; src=&quot;https://img.shields.io/npm/dm/expo.svg?style=flat-square&amp;labelColor=gray&amp;color=33CC12&amp;label=Downloads&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;try expo with snack&quot; href=&quot;https://snack.expo.dev&quot;&gt;&lt;b&gt;Try Expo in the Browser&lt;/b&gt;&lt;/a&gt;
&amp;ensp;•&amp;ensp;
  &lt;a aria-label=&quot;expo documentation&quot; href=&quot;https://docs.expo.dev&quot;&gt;Read the Documentation&lt;/a&gt;
&amp;ensp;•&amp;ensp;
  &lt;a aria-label=&quot;expo documentation&quot; href=&quot;https://expo.dev/blog&quot;&gt;Learn more on our blog&lt;/a&gt;
&amp;ensp;•&amp;ensp;
  &lt;a aria-label=&quot;expo documentation&quot; href=&quot;https://expo.canny.io/feature-requests&quot;&gt;Request a feature&lt;/a&gt;
&lt;/p&gt;

&lt;h6 align=&quot;center&quot;&gt;Follow us on&lt;/h6&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;Follow @expo on X&quot; href=&quot;https://x.com/intent/follow?screen_name=expo&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on X&quot; src=&quot;https://img.shields.io/badge/X-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;&amp;nbsp;
  &lt;a aria-label=&quot;Follow @expo on GitHub&quot; href=&quot;https://github.com/expo&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on GitHub&quot; src=&quot;https://img.shields.io/badge/GitHub-222222?style=for-the-badge&amp;logo=github&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;&amp;nbsp;
  &lt;a aria-label=&quot;Follow @expo on Reddit&quot; href=&quot;https://www.reddit.com/r/expo/&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on Reddit&quot; src=&quot;https://img.shields.io/badge/Reddit-FF4500?style=for-the-badge&amp;logo=reddit&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;&amp;nbsp;
  &lt;a aria-label=&quot;Follow @expo on Bluesky&quot; href=&quot;https://bsky.app/profile/expo.dev&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on Bluesky&quot; src=&quot;https://img.shields.io/badge/Bluesky-1DA1F2?style=for-the-badge&amp;logo=bluesky&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;&amp;nbsp;
  &lt;a aria-label=&quot;Follow @expo on LinkedIn&quot; href=&quot;https://www.linkedin.com/company/expo-dev&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on LinkedIn&quot; src=&quot;https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## Introduction

Expo is an open-source platform for making universal native apps that run on Android, iOS, and the web. It includes a universal runtime and libraries that let you build native apps by writing React and JavaScript.

This repository includes the Expo SDK, Modules API, Go app, CLI, Router, documentation, and various other supporting tools. [Expo Application Services (EAS)](https://expo.dev/eas) is a platform of hosted services that are deeply integrated with Expo open source tools. EAS helps you build, ship, and iterate on your app as an individual or a team.

Read the [Expo Community Guidelines](https://expo.dev/guidelines) before interacting in the repository. Thank you for helping keep the Expo community open and welcoming!

## Table of contents

- [📚 Documentation](#-documentation)
- [🗺 Project Layout](#-project-layout)
- [🏅 Badges](#-badges)
- [👏 Contributing](#-contributing)
- [❓ FAQ](#-faq)
- [💙 The Team](#-the-team)
- [License](#license)

## 📚 Documentation

&lt;p&gt;Learn about building and deploying universal apps &lt;a aria-label=&quot;expo documentation&quot; href=&quot;https://docs.expo.dev&quot;&gt;in our official docs!&lt;/a&gt;&lt;/p&gt;

- [Getting Started](https://docs.expo.dev/)
- [API Reference](https://docs.expo.dev/versions/latest/)
- [Using Custom Native Modules](https://docs.expo.dev/workflow/customizing/)

## 🗺 Project Layout

- [`packages`](/packages) All the source code for Expo modules, if you want to edit a library or just see how it works this is where you&#039;ll find it.
- [`apps`](/apps) This is where you can find Expo projects which are linked to the development modules. You&#039;ll do most of your testing in here.
- [`apps/expo-go`](/apps/expo-go) This is where you can find the source code for Expo Go.
- [`apps/expo-go/ios/Exponent.xcworkspace`](/apps/expo-go/ios) is the Xcode workspace. When developing iOS, always open this instead of `Exponent.xcodeproj` because the workspace also loads the CocoaPods dependencies.
- [`docs`](/docs) The source code for **https://docs.expo.dev**
- [`templates`](/templates) The template projects you get when you run `npx create-expo-app`
- [`react-native-lab`](/react-native-lab) This is our fork of `react-native` used to build Expo Go.
- [`guides`](/guides) In-depth tutorials for advanced topics like contributing to the client.
- [`tools`](/tools) contain build and configuration tools.
- [`template-files`](/template-files) contains templates for files that require private keys. They are populated using the keys in `template-files/keys.json`.
- [`template-files/ios/dependencies.json`](/template-files/ios/dependencies.json) specifies the CocoaPods dependencies of the app.

## 🏅 Badges

Let everyone know your app can be run instantly in the _Expo Go_ app!
&lt;br/&gt;

[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-000.svg?style=flat-square&amp;logo=EXPO&amp;labelColor=f3f3f3&amp;logoColor=000)](https://expo.dev/client)

[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-4630EB.svg?style=flat-square&amp;logo=EXPO&amp;labelColor=f3f3f3&amp;logoColor=000)](https://expo.dev/client)

```md
[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-000.svg?style=flat-square&amp;logo=EXPO&amp;labelColor=f3f3f3&amp;logoColor=000)](https://expo.dev/client)

[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-4630EB.svg?style=flat-square&amp;logo=EXPO&amp;labelColor=f3f3f3&amp;logoColor=000)](https://expo.dev/client)
```

## 👏 Contributing

If you like Expo and want to help make it better then check out our [contributing guide](/CONTRIBUTING.md)! Check out the [CLI package](https://github.com/expo/expo/tree/main/packages/%40expo/cli) to work on the Expo CLI.

## ❓ FAQ

If you have questions about Expo and want answers, then check out our [Frequently Asked Questions](https://docs.expo.dev/faq/)!

If you still have questions you can ask them on our [Discord and Forums](https://chat.expo.dev) or X [@expo](https://x.com/expo).

## 💙 The Team

Curious about who makes Expo? Here are our [team members](https://expo.dev/about)!

## License

The Expo source code is made available under the [MIT license](LICENSE). Some of the dependencies are licensed differently, with the BSD license, for example.

&lt;img alt=&quot;Star the Expo repo on GitHub to support the project&quot; src=&quot;https://user-images.githubusercontent.com/9664363/185428788-d762fd5d-97b3-4f59-8db7-f72405be9677.gif&quot; width=&quot;50%&quot;&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[openai/openai-node]]></title>
            <link>https://github.com/openai/openai-node</link>
            <guid>https://github.com/openai/openai-node</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[Official JavaScript / TypeScript library for the OpenAI API]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/openai-node">openai/openai-node</a></h1>
            <p>Official JavaScript / TypeScript library for the OpenAI API</p>
            <p>Language: TypeScript</p>
            <p>Stars: 10,149</p>
            <p>Forks: 1,256</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># OpenAI TypeScript and JavaScript API Library

[![NPM version](&lt;https://img.shields.io/npm/v/openai.svg?label=npm%20(stable)&gt;)](https://npmjs.org/package/openai) ![npm bundle size](https://img.shields.io/bundlephobia/minzip/openai) [![JSR Version](https://jsr.io/badges/@openai/openai)](https://jsr.io/@openai/openai)

This library provides convenient access to the OpenAI REST API from TypeScript or JavaScript.

It is generated from our [OpenAPI specification](https://github.com/openai/openai-openapi) with [Stainless](https://stainlessapi.com/).

To learn how to use the OpenAI API, check out our [API Reference](https://platform.openai.com/docs/api-reference) and [Documentation](https://platform.openai.com/docs).

## Installation

```sh
npm install openai
```

### Installation from JSR

```sh
deno add jsr:@openai/openai
npx jsr add @openai/openai
```

These commands will make the module importable from the `@openai/openai` scope. You can also [import directly from JSR](https://jsr.io/docs/using-packages#importing-with-jsr-specifiers) without an install step if you&#039;re using the Deno JavaScript runtime:

```ts
import OpenAI from &#039;jsr:@openai/openai&#039;;
```

## Usage

The full API of this library can be found in [api.md file](api.md) along with many [code examples](https://github.com/openai/openai-node/tree/master/examples).

The primary API for interacting with OpenAI models is the [Responses API](https://platform.openai.com/docs/api-reference/responses). You can generate text from the model with the code below.

```ts
import OpenAI from &#039;openai&#039;;

const client = new OpenAI({
  apiKey: process.env[&#039;OPENAI_API_KEY&#039;], // This is the default and can be omitted
});

const response = await client.responses.create({
  model: &#039;gpt-4o&#039;,
  instructions: &#039;You are a coding assistant that talks like a pirate&#039;,
  input: &#039;Are semicolons optional in JavaScript?&#039;,
});

console.log(response.output_text);
```

The previous standard (supported indefinitely) for generating text is the [Chat Completions API](https://platform.openai.com/docs/api-reference/chat). You can use that API to generate text from the model with the code below.

```ts
import OpenAI from &#039;openai&#039;;

const client = new OpenAI({
  apiKey: process.env[&#039;OPENAI_API_KEY&#039;], // This is the default and can be omitted
});

const completion = await client.chat.completions.create({
  model: &#039;gpt-4o&#039;,
  messages: [
    { role: &#039;developer&#039;, content: &#039;Talk like a pirate.&#039; },
    { role: &#039;user&#039;, content: &#039;Are semicolons optional in JavaScript?&#039; },
  ],
});

console.log(completion.choices[0].message.content);
```

## Streaming responses

We provide support for streaming responses using Server Sent Events (SSE).

```ts
import OpenAI from &#039;openai&#039;;

const client = new OpenAI();

const stream = await client.responses.create({
  model: &#039;gpt-4o&#039;,
  input: &#039;Say &quot;Sheep sleep deep&quot; ten times fast!&#039;,
  stream: true,
});

for await (const event of stream) {
  console.log(event);
}
```

## File uploads

Request parameters that correspond to file uploads can be passed in many different forms:

- `File` (or an object with the same structure)
- a `fetch` `Response` (or an object with the same structure)
- an `fs.ReadStream`
- the return value of our `toFile` helper

```ts
import fs from &#039;fs&#039;;
import OpenAI, { toFile } from &#039;openai&#039;;

const client = new OpenAI();

// If you have access to Node `fs` we recommend using `fs.createReadStream()`:
await client.files.create({ file: fs.createReadStream(&#039;input.jsonl&#039;), purpose: &#039;fine-tune&#039; });

// Or if you have the web `File` API you can pass a `File` instance:
await client.files.create({ file: new File([&#039;my bytes&#039;], &#039;input.jsonl&#039;), purpose: &#039;fine-tune&#039; });

// You can also pass a `fetch` `Response`:
await client.files.create({ file: await fetch(&#039;https://somesite/input.jsonl&#039;), purpose: &#039;fine-tune&#039; });

// Finally, if none of the above are convenient, you can use our `toFile` helper:
await client.files.create({
  file: await toFile(Buffer.from(&#039;my bytes&#039;), &#039;input.jsonl&#039;),
  purpose: &#039;fine-tune&#039;,
});
await client.files.create({
  file: await toFile(new Uint8Array([0, 1, 2]), &#039;input.jsonl&#039;),
  purpose: &#039;fine-tune&#039;,
});
```

## Webhook Verification

Verifying webhook signatures is _optional but encouraged_.

For more information about webhooks, see [the API docs](https://platform.openai.com/docs/guides/webhooks).

### Parsing webhook payloads

For most use cases, you will likely want to verify the webhook and parse the payload at the same time. To achieve this, we provide the method `client.webhooks.unwrap()`, which parses a webhook request and verifies that it was sent by OpenAI. This method will throw an error if the signature is invalid.

Note that the `body` parameter must be the raw JSON string sent from the server (do not parse it first). The `.unwrap()` method will parse this JSON for you into an event object after verifying the webhook was sent from OpenAI.

```ts
import { headers } from &#039;next/headers&#039;;
import OpenAI from &#039;openai&#039;;

const client = new OpenAI({
  webhookSecret: process.env.OPENAI_WEBHOOK_SECRET, // env var used by default; explicit here.
});

export async function webhook(request: Request) {
  const headersList = headers();
  const body = await request.text();

  try {
    const event = client.webhooks.unwrap(body, headersList);

    switch (event.type) {
      case &#039;response.completed&#039;:
        console.log(&#039;Response completed:&#039;, event.data);
        break;
      case &#039;response.failed&#039;:
        console.log(&#039;Response failed:&#039;, event.data);
        break;
      default:
        console.log(&#039;Unhandled event type:&#039;, event.type);
    }

    return Response.json({ message: &#039;ok&#039; });
  } catch (error) {
    console.error(&#039;Invalid webhook signature:&#039;, error);
    return new Response(&#039;Invalid signature&#039;, { status: 400 });
  }
}
```

### Verifying webhook payloads directly

In some cases, you may want to verify the webhook separately from parsing the payload. If you prefer to handle these steps separately, we provide the method `client.webhooks.verifySignature()` to _only verify_ the signature of a webhook request. Like `.unwrap()`, this method will throw an error if the signature is invalid.

Note that the `body` parameter must be the raw JSON string sent from the server (do not parse it first). You will then need to parse the body after verifying the signature.

```ts
import { headers } from &#039;next/headers&#039;;
import OpenAI from &#039;openai&#039;;

const client = new OpenAI({
  webhookSecret: process.env.OPENAI_WEBHOOK_SECRET, // env var used by default; explicit here.
});

export async function webhook(request: Request) {
  const headersList = headers();
  const body = await request.text();

  try {
    client.webhooks.verifySignature(body, headersList);

    // Parse the body after verification
    const event = JSON.parse(body);
    console.log(&#039;Verified event:&#039;, event);

    return Response.json({ message: &#039;ok&#039; });
  } catch (error) {
    console.error(&#039;Invalid webhook signature:&#039;, error);
    return new Response(&#039;Invalid signature&#039;, { status: 400 });
  }
}
```

## Handling errors

When the library is unable to connect to the API,
or if the API returns a non-success status code (i.e., 4xx or 5xx response),
a subclass of `APIError` will be thrown:

&lt;!-- prettier-ignore --&gt;
```ts
const job = await client.fineTuning.jobs
  .create({ model: &#039;gpt-4o&#039;, training_file: &#039;file-abc123&#039; })
  .catch(async (err) =&gt; {
    if (err instanceof OpenAI.APIError) {
      console.log(err.request_id);
      console.log(err.status); // 400
      console.log(err.name); // BadRequestError
      console.log(err.headers); // {server: &#039;nginx&#039;, ...}
    } else {
      throw err;
    }
  });
```

Error codes are as follows:

| Status Code | Error Type                 |
| ----------- | -------------------------- |
| 400         | `BadRequestError`          |
| 401         | `AuthenticationError`      |
| 403         | `PermissionDeniedError`    |
| 404         | `NotFoundError`            |
| 422         | `UnprocessableEntityError` |
| 429         | `RateLimitError`           |
| &gt;=500       | `InternalServerError`      |
| N/A         | `APIConnectionError`       |

## Request IDs

&gt; For more information on debugging requests, see [these docs](https://platform.openai.com/docs/api-reference/debugging-requests)

All object responses in the SDK provide a `_request_id` property which is added from the `x-request-id` response header so that you can quickly log failing requests and report them back to OpenAI.

```ts
const completion = await client.chat.completions.create({
  messages: [{ role: &#039;user&#039;, content: &#039;Say this is a test&#039; }],
  model: &#039;gpt-4o&#039;,
});
console.log(completion._request_id); // req_123
```

You can also access the Request ID using the `.withResponse()` method:

```ts
const { data: stream, request_id } = await openai.chat.completions
  .create({
    model: &#039;gpt-4&#039;,
    messages: [{ role: &#039;user&#039;, content: &#039;Say this is a test&#039; }],
    stream: true,
  })
  .withResponse();
```

## Realtime API

The Realtime API enables you to build low-latency, multi-modal conversational experiences. It currently supports text and audio as both input and output, as well as [function calling](https://platform.openai.com/docs/guides/function-calling) through a `WebSocket` connection.

```ts
import { OpenAIRealtimeWebSocket } from &#039;openai/realtime/websocket&#039;;

const rt = new OpenAIRealtimeWebSocket({ model: &#039;gpt-realtime&#039; });

rt.on(&#039;response.text.delta&#039;, (event) =&gt; process.stdout.write(event.delta));
```

For more information see [realtime.md](realtime.md).

## Microsoft Azure OpenAI

To use this library with [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/overview), use the `AzureOpenAI`
class instead of the `OpenAI` class.

&gt; [!IMPORTANT]
&gt; The Azure API shape slightly differs from the core API shape which means that the static types for responses / params
&gt; won&#039;t always be correct.

```ts
import { AzureOpenAI } from &#039;openai&#039;;
import { getBearerTokenProvider, DefaultAzureCredential } from &#039;@azure/identity&#039;;

const credential = new DefaultAzureCredential();
const scope = &#039;https://cognitiveservices.azure.com/.default&#039;;
const azureADTokenProvider = getBearerTokenProvider(credential, scope);

const openai = new AzureOpenAI({ azureADTokenProvider });

const result = await openai.chat.completions.create({
  model: &#039;gpt-4o&#039;,
  messages: [{ role: &#039;user&#039;, content: &#039;Say hello!&#039; }],
});

console.log(result.choices[0]!.message?.content);
```

### Retries

Certain errors will be automatically retried 2 times by default, with a short exponential backoff.
Connection errors (for example, due to a network connectivity problem), 408 Request Timeout, 409 Conflict,
429 Rate Limit, and &gt;=500 Internal errors will all be retried by default.

You can use the `maxRetries` option to configure or disable this:

&lt;!-- prettier-ignore --&gt;
```js
// Configure the default for all requests:
const client = new OpenAI({
  maxRetries: 0, // default is 2
});

// Or, configure per-request:
await client.chat.completions.create({ messages: [{ role: &#039;user&#039;, content: &#039;How can I get the name of the current day in JavaScript?&#039; }], model: &#039;gpt-4o&#039; }, {
  maxRetries: 5,
});
```

### Timeouts

Requests time out after 10 minutes by default. You can configure this with a `timeout` option:

&lt;!-- prettier-ignore --&gt;
```ts
// Configure the default for all requests:
const client = new OpenAI({
  timeout: 20 * 1000, // 20 seconds (default is 10 minutes)
});

// Override per-request:
await client.chat.completions.create({ messages: [{ role: &#039;user&#039;, content: &#039;How can I list all files in a directory using Python?&#039; }], model: &#039;gpt-4o&#039; }, {
  timeout: 5 * 1000,
});
```

On timeout, an `APIConnectionTimeoutError` is thrown.

Note that requests which time out will be [retried twice by default](#retries).

## Request IDs

&gt; For more information on debugging requests, see [these docs](https://platform.openai.com/docs/api-reference/debugging-requests)

All object responses in the SDK provide a `_request_id` property which is added from the `x-request-id` response header so that you can quickly log failing requests and report them back to OpenAI.

```ts
const response = await client.responses.create({ model: &#039;gpt-4o&#039;, input: &#039;testing 123&#039; });
console.log(response._request_id); // req_123
```

You can also access the Request ID using the `.withResponse()` method:

```ts
const { data: stream, request_id } = await openai.responses
  .create({
    model: &#039;gpt-4o&#039;,
    input: &#039;Say this is a test&#039;,
    stream: true,
  })
  .withResponse();
```

## Auto-pagination

List methods in the OpenAI API are paginated.
You can use the `for await … of` syntax to iterate through items across all pages:

```ts
async function fetchAllFineTuningJobs(params) {
  const allFineTuningJobs = [];
  // Automatically fetches more pages as needed.
  for await (const fineTuningJob of client.fineTuning.jobs.list({ limit: 20 })) {
    allFineTuningJobs.push(fineTuningJob);
  }
  return allFineTuningJobs;
}
```

Alternatively, you can request a single page at a time:

```ts
let page = await client.fineTuning.jobs.list({ limit: 20 });
for (const fineTuningJob of page.data) {
  console.log(fineTuningJob);
}

// Convenience methods are provided for manually paginating:
while (page.hasNextPage()) {
  page = await page.getNextPage();
  // ...
}
```

## Realtime API

The Realtime API enables you to build low-latency, multi-modal conversational experiences. It currently supports text and audio as both input and output, as well as [function calling](https://platform.openai.com/docs/guides/function-calling) through a `WebSocket` connection.

```ts
import { OpenAIRealtimeWebSocket } from &#039;openai/realtime/websocket&#039;;

const rt = new OpenAIRealtimeWebSocket({ model: &#039;gpt-realtime&#039; });

rt.on(&#039;response.text.delta&#039;, (event) =&gt; process.stdout.write(event.delta));
```

For more information see [realtime.md](realtime.md).

## Microsoft Azure OpenAI

To use this library with [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/overview), use the `AzureOpenAI`
class instead of the `OpenAI` class.

&gt; [!IMPORTANT]
&gt; The Azure API shape slightly differs from the core API shape which means that the static types for responses / params
&gt; won&#039;t always be correct.

```ts
import { AzureOpenAI } from &#039;openai&#039;;
import { getBearerTokenProvider, DefaultAzureCredential } from &#039;@azure/identity&#039;;

const credential = new DefaultAzureCredential();
const scope = &#039;https://cognitiveservices.azure.com/.default&#039;;
const azureADTokenProvider = getBearerTokenProvider(credential, scope);

const openai = new AzureOpenAI({
  azureADTokenProvider,
  apiVersion: &#039;&lt;The API version, e.g. 2024-10-01-preview&gt;&#039;,
});

const result = await openai.chat.completions.create({
  model: &#039;gpt-4o&#039;,
  messages: [{ role: &#039;user&#039;, content: &#039;Say hello!&#039; }],
});

console.log(result.choices[0]!.message?.content);
```

For more information on support for the Azure API, see [azure.md](azure.md).

## Advanced Usage

### Accessing raw Response data (e.g., headers)

The &quot;raw&quot; `Response` returned by `fetch()` can be accessed through the `.asResponse()` method on the `APIPromise` type that all methods return.
This method returns as soon as the headers for a successful response are received and does not consume the response body, so you are free to write custom parsing or streaming logic.

You can also use the `.withResponse()` method to get the raw `Response` along with the parsed data.
Unlike `.asResponse()` this method consumes the body, returning once it is parsed.

&lt;!-- prettier-ignore --&gt;
```ts
const client = new OpenAI();

const httpResponse = await client.responses
  .create({ model: &#039;gpt-4o&#039;, input: &#039;say this is a test.&#039; })
  .asResponse();

// access the underlying web standard Response object
console.log(httpResponse.headers.get(&#039;X-My-Header&#039;));
console.log(httpResponse.statusText);

const { data: modelResponse, response: raw } = await client.responses
  .create({ model: &#039;gpt-4o&#039;, input: &#039;say this is a test.&#039; })
  .withResponse();
console.log(raw.headers.get(&#039;X-My-Header&#039;));
console.log(modelResponse);
```

### Logging

&gt; [!IMPORTANT]
&gt; All log messages are intended for debugging only. The format and content of log messages
&gt; may change between releases.

#### Log levels

The log level can be configured in two ways:

1. Via the `OPENAI_LOG` environment variable
2. Using the `logLevel` client option (overrides the environment variable if set)

```ts
import OpenAI from &#039;openai&#039;;

const client = new OpenAI({
  logLevel: &#039;debug&#039;, // Show all log messages
});
```

Available log levels, from most to least verbose:

- `&#039;debug&#039;` - Show debug messages, info, warnings, and errors
- `&#039;info&#039;` - Show info messages, warnings, and errors
- `&#039;warn&#039;` - Show warnings and errors (default)
- `&#039;error&#039;` - Show only errors
- `&#039;off&#039;` - Disable all logging

At the `&#039;debug&#039;` level, all HTTP requests and responses are logged, including headers and bodies.
Some authentication-related headers are redacted, but sensitive data in request and response bodies
may still be visible.

#### Custom logger

By default, this library logs to `globalThis.console`. You can also provide a custom logger.
Most logging libraries are supported, including [pino](https://www.npmjs.com/package/pino), [winston](https://www.npmjs.com/package/winston), [bunyan](https://www.npmjs.com/package/bunyan), [consola](https://www.npmjs.com/package/consola), [signale](https://www.npmjs.com/package/signale), and [@std/log](https://jsr.io/@std/log). If your logger doesn&#039;t work, please open an issue.

When providing a custom logger, the `logLevel` option still controls which messages are emitted, messages
below the configured level will not be sent to your logger.

```ts
import OpenAI from &#039;openai&#039;;
import pino from &#039;pino&#039;;

const logger = pino();

const client = new OpenAI({
  logger: logger.child({ name: &#039;OpenAI&#039; }),
  logLevel: &#039;debug&#039;, // Send all messages to pino, allowing it to filter
});
```

### Making custom/undocumented requests

This library is typed for convenient access to the documented API. If you need to access undocumented
endpoints, params, or response properties, the library can still be used.

#### Undocumented endpoints

To make requests to undocumented endpoints, you can use `client.get`, `client.post`, and other HTTP verbs.
Options on the client, such as retries, will be respected when making these requests.

```ts
await client.post(&#039;/some/path&#039;, {
  body: { some_prop: &#039;foo&#039; },
  query: { some_query_arg: &#039;bar&#039; },
});
```

#### Undocumented request params

To make requests using undocumented parameters, you may use `// @ts-expect-error` on the undocumented
parameter. This library doesn&#039;t validate at runtime that the request matches the type, so any extra values you
send will be sent as-is.

```ts
client.chat.completions.create({
  // ...
  // @ts-expect-error baz is not yet public
  baz: &#039;undocumented option&#039;,
});
```

For requests with the `GET` verb, any extra params will be in the query, all other requests will send the
extra param in the body.

If you want to explicitly send an extra argument, you can do so with the `query`, `body`, and `headers` request
options.

#### Undocumented response properties

To access undocumented response properties, you may access the response object with `// @ts-expect-error` on
the response object, or cast the response object to the requisite type. Like the request params, we do not
validate or strip extra properties from the response from the API.

### Customizing the fetch client

If you want to use a different `fetch` function, you can either polyfill the global:

```ts
import fetch from &#039;my-fetch&#039;;

globalThis.fetch = fetch;
```

Or pass it to the client:

```ts
import OpenAI from &#039;openai&#039;;
import fetch from &#039;my-fetch&#039;;

const client = new OpenAI({ fetch });
```

### Fetch options

If you want to set custom `fetch` options without overriding the `fetch` function, you can provide a `fetchOptions` object when instantiating the cl

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[payloadcms/payload]]></title>
            <link>https://github.com/payloadcms/payload</link>
            <guid>https://github.com/payloadcms/payload</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[Payload is the open-source, fullstack Next.js framework, giving you instant backend superpowers. Get a full TypeScript backend and admin panel instantly. Use Payload as a headless CMS or for building powerful applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/payloadcms/payload">payloadcms/payload</a></h1>
            <p>Payload is the open-source, fullstack Next.js framework, giving you instant backend superpowers. Get a full TypeScript backend and admin panel instantly. Use Payload as a headless CMS or for building powerful applications.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 37,897</p>
            <p>Forks: 2,968</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://payloadcms.com&quot;&gt;&lt;img width=&quot;100%&quot; src=&quot;https://l4wlsi8vxy8hre4v.public.blob.vercel-storage.com/github-banner-new-logo.jpg&quot; alt=&quot;Payload headless CMS Admin panel built with React&quot; /&gt;&lt;/a&gt;
&lt;br /&gt;
&lt;br /&gt;

&lt;p align=&quot;left&quot;&gt;
  &lt;a href=&quot;https://github.com/payloadcms/payload/actions&quot;&gt;&lt;img alt=&quot;GitHub Workflow Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/payloadcms/payload/main.yml?style=flat-square&quot;&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://discord.gg/payload&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/967097582721572934?label=Discord&amp;color=7289da&amp;style=flat-square&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.npmjs.com/package/payload&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/dw/payload?style=flat-square&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://github.com/payloadcms/payload/graphs/contributors&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/github/contributors-anon/payloadcms/payload?color=yellow&amp;style=flat-square&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.npmjs.com/package/payload&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/payload?style=flat-square&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://twitter.com/payloadcms&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/follow-payloadcms-1DA1F2?logo=twitter&amp;style=flat-square&quot; alt=&quot;Payload Twitter&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;hr/&gt;
&lt;h4&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://payloadcms.com/docs/getting-started/what-is-payload&quot; rel=&quot;dofollow&quot;&gt;&lt;strong&gt;Explore the Docs&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;·&amp;nbsp;&lt;a target=&quot;_blank&quot; href=&quot;https://payloadcms.com/community-help&quot; rel=&quot;dofollow&quot;&gt;&lt;strong&gt;Community Help&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;·&amp;nbsp;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/payloadcms/payload/discussions/1539&quot; rel=&quot;dofollow&quot;&gt;&lt;strong&gt;Roadmap&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;·&amp;nbsp;&lt;a target=&quot;_blank&quot; href=&quot;https://www.g2.com/products/payload-cms/reviews#reviews&quot; rel=&quot;dofollow&quot;&gt;&lt;strong&gt;View G2 Reviews&lt;/strong&gt;&lt;/a&gt;
&lt;/h4&gt;
&lt;hr/&gt;

&gt; [!IMPORTANT]
&gt; 🎉 &lt;strong&gt;We&#039;ve released 3.0!&lt;/strong&gt; Star this repo or keep an eye on it to follow along.

Payload is the first-ever Next.js native CMS that can install directly in your existing `/app` folder. It&#039;s the start of a new era for headless CMS.

&lt;h3&gt;Benefits over a regular CMS&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Deploy anywhere, including serverless on Vercel for free&lt;/li&gt;
  &lt;li&gt;Combine your front+backend in the same &lt;code&gt;/app&lt;/code&gt; folder if you want&lt;/li&gt;
  &lt;li&gt;Don&#039;t sign up for yet another SaaS - Payload is open source&lt;/li&gt;
  &lt;li&gt;Query your database in React Server Components&lt;/li&gt;
  &lt;li&gt;Both admin and backend are 100% extensible&lt;/li&gt;
  &lt;li&gt;No vendor lock-in&lt;/li&gt;
  &lt;li&gt;Never touch ancient WP code again&lt;/li&gt;
  &lt;li&gt;Build faster, never hit a roadblock&lt;/li&gt;
&lt;/ul&gt;

## Quickstart

Before beginning to work with Payload, make sure you have all of the [required software](https://payloadcms.com/docs/getting-started/installation).

```text
pnpx create-payload-app@latest
```

**If you&#039;re new to Payload, you should start with the website template** (`pnpx create-payload-app@latest -t website`). It shows how to do _everything_ - including custom Rich Text blocks, on-demand revalidation, live preview, and more. It comes with a frontend built with Tailwind all in one `/app` folder.

## One-click templates

Jumpstart your next project by starting with a pre-made template. These are production-ready, end-to-end solutions designed to get you to market as fast as possible.

### [🌐 Website](https://github.com/payloadcms/payload/tree/main/templates/website)

Build any kind of website, blog, or portfolio from small to enterprise. Comes with a fully functional front-end built with RSCs and Tailwind.

We&#039;re constantly adding more templates to our [Templates Directory](https://github.com/payloadcms/payload/tree/main/templates). If you maintain your own template, consider adding the `payload-template` topic to your GitHub repository for others to find.

- [Official Templates](https://github.com/payloadcms/payload/tree/main/templates)
- [Community Templates](https://github.com/topics/payload-template)

## ✨ Features

- Completely free and open-source
- Next.js native, built to run inside _your_ `/app` folder
- Use server components to extend Payload UI
- Query your database directly in server components, no need for REST / GraphQL
- Fully TypeScript with automatic types for your data
- [Auth out of the box](https://payloadcms.com/docs/authentication/overview)
- [Versions and drafts](https://payloadcms.com/docs/versions/overview)
- [Localization](https://payloadcms.com/docs/configuration/localization)
- [Block-based layout builder](https://payloadcms.com/docs/fields/blocks)
- [Customizable React admin](https://payloadcms.com/docs/admin/overview)
- [Lexical rich text editor](https://payloadcms.com/docs/fields/rich-text)
- [Conditional field logic](https://payloadcms.com/docs/fields/overview#conditional-logic)
- Extremely granular [Access Control](https://payloadcms.com/docs/access-control/overview)
- [Document and field-level hooks](https://payloadcms.com/docs/hooks/overview) for every action Payload provides
- Intensely fast API
- Highly secure thanks to HTTP-only cookies, CSRF protection, and more

&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/payloadcms/payload/discussions&quot;&gt;&lt;strong&gt;Request Feature&lt;/strong&gt;&lt;/a&gt;

## 🗒️ Documentation

Check out the [Payload website](https://payloadcms.com/docs/getting-started/what-is-payload) to find in-depth documentation for everything that Payload offers.

Migrating from v2 to v3? Check out the [3.0 Migration Guide](https://github.com/payloadcms/payload/blob/main/docs/migration-guide/overview.mdx) on how to do it.

## 🙋 Contributing

If you want to add contributions to this repository, please follow the instructions in [contributing.md](./CONTRIBUTING.md).

## 📚 Examples

The [Examples Directory](./examples) is a great resource for learning how to setup Payload in a variety of different ways, but you can also find great examples in our blog and throughout our social media.

If you&#039;d like to run the examples, you can use `create-payload-app` to create a project from one:

```sh
npx create-payload-app --example example_name
```

You can see more examples at:

- [Examples Directory](./examples)
- [Payload Blog](https://payloadcms.com/blog)
- [Payload YouTube](https://www.youtube.com/@payloadcms)

## 🔌 Plugins

Payload is highly extensible and allows you to install or distribute plugins that add or remove functionality. There are both officially-supported and community-supported plugins available. If you maintain your own plugin, consider adding the `payload-plugin` topic to your GitHub repository for others to find.

- [Official Plugins](https://github.com/orgs/payloadcms/repositories?q=topic%3Apayload-plugin)
- [Community Plugins](https://github.com/topics/payload-plugin)

## 🚨 Need help?

There are lots of good conversations and resources in our Github Discussions board and our Discord Server. If you&#039;re struggling with something, chances are, someone&#039;s already solved what you&#039;re up against. :point_down:

- [GitHub Discussions](https://github.com/payloadcms/payload/discussions)
- [GitHub Issues](https://github.com/payloadcms/payload/issues)
- [Discord](https://t.co/30APlsQUPB)
- [Community Help](https://payloadcms.com/community-help)

## ⭐ Like what we&#039;re doing? Give us a star

![payload-github-star](https://cms.payloadcms.com/media/payload-github-star.gif)

## 👏 Thanks to all our contributors

&lt;img align=&quot;left&quot; src=&quot;https://contributors-img.web.app/image?repo=payloadcms/payload&quot;/&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[MotiaDev/motia]]></title>
            <link>https://github.com/MotiaDev/motia</link>
            <guid>https://github.com/MotiaDev/motia</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:46 GMT</pubDate>
            <description><![CDATA[Multi-Language Backend Framework that unifies APIs, background jobs, workflows, and AI Agents into a single core primitive with built-in observability and state management.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/MotiaDev/motia">MotiaDev/motia</a></h1>
            <p>Multi-Language Backend Framework that unifies APIs, background jobs, workflows, and AI Agents into a single core primitive with built-in observability and state management.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,012</p>
            <p>Forks: 685</p>
            <p>Stars today: 197 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://motia.dev&quot;&gt;
  &lt;img src=&quot;assets/github-readme-banner.png&quot; alt=&quot;Motia Banner&quot; width=&quot;100%&quot;&gt;
&lt;/a&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/14032&quot; style=&quot;margin-right:8px;&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/14032&quot; alt=&quot;Motia&quot; style=&quot;width: 250px; height: 55px; margin-right:8px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://vercel.com/blog/summer-2025-oss-program#motia&quot; target=&quot;_blank&quot; style=&quot;margin-left:8px;&quot;&gt;
    &lt;img alt=&quot;Vercel OSS Program&quot; src=&quot;https://vercel.com/oss/program-badge.svg&quot; style=&quot;width: 250px; height: 55px; margin-left:8px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;🔥 The Unified Backend Framework That Eliminates Runtime Fragmentation 🔥&lt;/strong&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;em&gt;APIs, background jobs, workflows, and AI agents in one system. JavaScript, TypeScript, Python, and more in one codebase.&lt;/em&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/motia&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/motia?style=flat&amp;logo=npm&amp;logoColor=white&amp;color=CB3837&amp;labelColor=000000&quot; alt=&quot;npm version&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/MotiaDev/motia/blob/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/license-MIT-green?style=flat&amp;logo=opensourceinitiative&amp;logoColor=white&amp;labelColor=000000&quot; alt=&quot;license&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/MotiaDev/motia&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/MotiaDev/motia?style=flat&amp;logo=github&amp;logoColor=white&amp;color=yellow&amp;labelColor=000000&quot; alt=&quot;GitHub stars&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/motiadev&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Follow-@motiadev-1DA1F2?style=flat&amp;logo=twitter&amp;logoColor=white&amp;labelColor=000000&quot; alt=&quot;Twitter Follow&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/motia&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1322278831184281721?style=flat&amp;logo=discord&amp;logoColor=white&amp;color=5865F2&amp;label=Discord&amp;labelColor=000000&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.motia.dev/manifesto&quot;&gt;💡 Motia Manifesto&lt;/a&gt; •
  &lt;a href=&quot;https://www.motia.dev/docs/getting-started/quick-start&quot;&gt;🚀 Quick Start&lt;/a&gt; •
  &lt;a href=&quot;https://www.motia.dev/docs/concepts/steps/steps&quot;&gt;📋 Defining Steps&lt;/a&gt; •
  &lt;a href=&quot;https://www.motia.dev/docs&quot;&gt;📚 Docs&lt;/a&gt;
&lt;/p&gt;

---

## 🎯 What is Motia?

Backend development today is fragmented.

APIs live in one framework, background jobs in another, queues and schedulers elsewhere, and now AI agents and streaming systems have their own runtimes. Add observability and state management on top, and you&#039;re stitching together half a dozen tools before writing your first feature.

**Motia unifies all of these concerns around one core primitive: the Step.**

Just as React made frontend development simple by introducing components, Motia redefines backend development with Steps.

Every backend pattern, API endpoints, background jobs, queues, workflows, AI agents, streaming, observability, and state, is expressed with the same primitive.

To read more about this, check out our **[manifesto](https://motia.dev/manifesto)**.

---

## The Core Primitive: the Step

A Step is just a file with a `config` and a `handler`. Motia auto-discovers these files and connects them automatically.

Here&#039;s a simple example of two Steps working together: an API Step that emits an event, and an Event Step that processes it.

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;TypeScript&lt;/b&gt;&lt;/summary&gt;

```ts
// steps/send-message.step.ts
export const config = {
  name: &#039;SendMessage&#039;,
  type: &#039;api&#039;,
  path: &#039;/messages&#039;,
  method: &#039;POST&#039;,
  emits: [&#039;message.sent&#039;]
};

export const handler = async (req, { emit }) =&gt; {
  await emit({
    topic: &#039;message.sent&#039;,
    data: { text: req.body.text }
  });
  return { status: 200, body: { ok: true } };
};
```

```ts
// steps/process-message.step.ts
export const config = {
  name: &#039;ProcessMessage&#039;,
  type: &#039;event&#039;,
  subscribes: [&#039;message.sent&#039;]
};

export const handler = async (input, { logger }) =&gt; {
  logger.info(&#039;Processing message&#039;, input);
};
```

&lt;/details&gt;

&lt;details close&gt;
&lt;summary&gt;&lt;b&gt;Python&lt;/b&gt;&lt;/summary&gt;

```python
# send_message_step.py
config = {
    &quot;name&quot;: &quot;SendMessage&quot;,
    &quot;type&quot;: &quot;api&quot;,
    &quot;path&quot;: &quot;/messages&quot;,
    &quot;method&quot;: &quot;POST&quot;,
    &quot;emits&quot;: [&quot;message.sent&quot;]
}

async def handler(req, context):
    await context.emit({
        &quot;topic&quot;: &quot;message.sent&quot;,
        &quot;data&quot;: {&quot;text&quot;: req.body[&quot;text&quot;]}
    })
    return {&quot;status&quot;: 200, &quot;body&quot;: {&quot;ok&quot;: True}}
```

```python
# process_message_step.py
config = {
    &quot;name&quot;: &quot;ProcessMessage&quot;,
    &quot;type&quot;: &quot;event&quot;,
    &quot;subscribes&quot;: [&quot;message.sent&quot;]
}

async def handler(input, context):
    context.logger.info(&quot;Processing message&quot;, input)
```

&lt;/details close&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;JavaScript&lt;/b&gt;&lt;/summary&gt;

```js
// steps/send-message.step.js
const config = {
  name: &#039;SendMessage&#039;,
  type: &#039;api&#039;,
  path: &#039;/messages&#039;,
  method: &#039;POST&#039;,
  emits: [&#039;message.sent&#039;]
};

const handler = async (req, { emit }) =&gt; {
  await emit({
    topic: &#039;message.sent&#039;,
    data: { text: req.body.text }
  });
  return { status: 200, body: { ok: true } };
};

module.exports = { config, handler };
```

```js
// steps/process-message.step.js
const config = {
  name: &#039;ProcessMessage&#039;,
  type: &#039;event&#039;,
  subscribes: [&#039;message.sent&#039;]
};

const handler = async (input, { logger }) =&gt; {
  logger.info(&#039;Processing message&#039;, input);
};

module.exports = { config, handler };
```

&lt;/details&gt;

👉 With just two files, you&#039;ve built an **API endpoint**, a **queue**, and a **worker**. No extra frameworks required.

**[Learn more about Steps →](https://motia.dev/docs/concepts/steps/steps)**

[![Motia combines APIs, background queues, and AI agents into one system](assets/github-readme-banner.gif)](https://motia.dev)

## 💻 Remix your own Motia App in Replit
[![Open in Replit](https://img.shields.io/badge/Open%20in-Replit-blue?logo=replit&amp;style=for-the-badge)](https://replit.com/@motiadev/motia)

## 🚀 Quickstart

Get Motia project up and running in **under 60 seconds**:

### 1. Bootstrap a New Motia Project

```bash
npx motia@latest create   # runs the interactive terminal
```

Follow the prompts to pick a template, project name, and language.
![motia-terminal](assets/motia-terminal.gif)

### 2. Start the Workbench

Inside your new project folder, launch the dev server:

```bash
npx motia dev # ➜ http://localhost:3000
```

**That&#039;s it!** You have:
- ✅ REST APIs with validation
- ✅ Visual debugger &amp; tracing  
- ✅ Multi-language support
- ✅ Event-driven architecture
- ✅ Zero configuration

![new-workbench](assets/new-workbench.png)

&gt; 📖 **[Full tutorial in our docs →](https://motia.dev/docs/getting-started/quick-start)**

## 🎯 Step Types

| Type | Trigger | Use Case |
|------|---------|----------|
| **`api`** | HTTP Request | REST endpoints |
| **`event`** | Topic subscription | Background processing |  
| **`cron`** | Schedule | Recurring jobs |
| **`noop`** | Manual | External processes |

&gt; 📖 **[Learn more about Steps →](https://motia.dev/docs/concepts/steps)**

---

## 🎯 Examples

### 🏆 **[ChessArena.ai](https://chessarena.ai)** - Full-Featured Production App

A complete chess platform benchmarking LLM performance with real-time evaluation.

**[Live Website →](https://chessarena.ai)** | **[Source Code →](https://github.com/MotiaDev/chessarena-ai)**

&gt; ![ChessArena.ai in action (raw GIF)](https://github.com/MotiaDev/chessarena-ai/blob/main/public/images/chessarena.gif?raw=true)

**Built from scratch to production deployment, featuring:**
- 🔐 **Authentication &amp; user management**
- 🤖 **Multi-agent LLM evaluation** (OpenAI, Claude, Gemini, Grok)
- 🐍 **Python engine integration** (Stockfish chess evaluation)
- 📊 **Real-time streaming** with live move updates and scoring
- 🎨 **Modern React UI** with interactive chess boards
- 🔄 **Event-driven workflows** connecting TypeScript APIs to Python processors
- 📈 **Live leaderboards** with move-by-move quality scoring
- 🚀 **Production deployment** on Motia Cloud

### 📚 **More Examples**

**[View all 20+ examples →](https://github.com/MotiaDev/motia-examples)**

| Example | Description |
|---------|-------------|
| **[AI Research Agent](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-deep-research-agent)** | Web research with iterative analysis |
| **[Streaming Chatbot](https://github.com/MotiaDev/motia-examples/tree/main/examples/streaming-ai-chatbot)** | Real-time AI responses |
| **[Gmail Automation](https://github.com/MotiaDev/motia-examples/tree/main/examples/gmail-workflow)** | Smart email processing |
| **[GitHub PR Manager](https://github.com/MotiaDev/motia-examples/tree/main/examples/github-integration-workflow)** | Automated PR workflows |
| **[Finance Agent](https://github.com/MotiaDev/motia-examples/tree/main/examples/finance-agent)** | Real-time market analysis |

**Features demonstrated:** Multi-language workflows • Real-time streaming • AI integration • Production deployment

---

## 🌐 Language Support

| Language | Status | 
|----------|--------|
| **JavaScript** | ✅ Stable |
| **TypeScript** | ✅ Stable |
| **Python** | ✅ Stable |
| **Ruby** | 🚧 Beta |
| **Go** | 🔄 Soon |

## 📚 Resources

- **[📖 Documentation](https://motia.dev/docs)** - Complete guides and API reference
- **[💬 Discord](https://discord.gg/motia)** - Community support and discussions
- **[🐛 GitHub Issues](https://github.com/MotiaDev/motia/issues)** - Bug reports and feature requests
- **[🗺️ Roadmap](https://github.com/orgs/MotiaDev/projects/2)** - Upcoming features and progress

## 🚧 Roadmap

We have a public roadmap for Motia, you can view it [here](https://github.com/orgs/MotiaDev/projects/2/views/4).

Feel free to add comments to the issues, or create a new issue if you have a feature request.

| Feature | Status | Link | Description |
| ------- | ------ | ---- | ----------- |
| Python Types | Planned | [#485](https://github.com/MotiaDev/motia/issues/485) | Add support for Python types |
| Streams: RBAC | Planned | [#495](https://github.com/MotiaDev/motia/issues/495) | Add support for RBAC |
| Streams: Workbench UI | Planned | [#497](https://github.com/MotiaDev/motia/issues/497) | Add support for Workbench UI |
| Queue Strategies | Planned | [#476](https://github.com/MotiaDev/motia/issues/476) | Add support for Queue Strategies |
| Reactive Steps | Planned | [#477](https://github.com/MotiaDev/motia/issues/477) | Add support for Reactive Steps |
| Point in time triggers | Planned | [#480](https://github.com/MotiaDev/motia/issues/480) | Add support for Point in time triggers |
| Workbench plugins | Planned | [#481](https://github.com/MotiaDev/motia/issues/481) | Add support for Workbench plugins |
| Rewrite our Core in either Go or Rust | Planned | [#482](https://github.com/MotiaDev/motia/issues/482) | Rewrite our Core in either Go or Rust |
| Decrease deployment time | Planned | [#483](https://github.com/MotiaDev/motia/issues/483) | Decrease deployment time |
| Built-in database support | Planned | [#484](https://github.com/MotiaDev/motia/issues/484) | Add support for built-in database |

## 🤝 Contributing

We welcome contributions! Check our **[Contributing Guide](https://github.com/MotiaDev/motia/blob/main/CONTRIBUTING.md)** to get started.

---

&lt;div align=&quot;center&quot;&gt;

**[🚀 Get Started](https://motia.dev)** • **[📖 Docs](https://motia.dev/docs)** • **[💬 Discord](https://discord.gg/motia)**

[![Star History Chart](https://api.star-history.com/svg?repos=motiadev/motia&amp;type=Date)](https://www.star-history.com/#motiadev/motia&amp;Date)

&lt;sub&gt;⭐ **Star us if you find Motia useful!**&lt;/sub&gt;

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lobehub/lobe-chat]]></title>
            <link>https://github.com/lobehub/lobe-chat</link>
            <guid>https://github.com/lobehub/lobe-chat</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:45 GMT</pubDate>
            <description><![CDATA[🤯 Lobe Chat - an open-source, modern design AI chat framework. Supports multiple AI providers (OpenAI / Claude 4 / Gemini / DeepSeek / Ollama / Qwen), Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobe-chat">lobehub/lobe-chat</a></h1>
            <p>🤯 Lobe Chat - an open-source, modern design AI chat framework. Supports multiple AI providers (OpenAI / Claude 4 / Gemini / DeepSeek / Ollama / Qwen), Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 66,427</p>
            <p>Forks: 13,759</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# Lobe Chat

An open-source, modern design ChatGPT/LLMs UI/framework.&lt;br/&gt;
Supports speech synthesis, multi-modal, and extensible ([function call][docs-function-call]) plugin system.&lt;br/&gt;
One-click **FREE** deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.

**English** · [简体中文](./README.zh-CN.md) · [Official Site][official-site] · [Changelog][changelog] · [Documents][docs] · [Blog][blog] · [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeChat Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Pioneering the new age of thinking and creating. Built for you, the Super Individual.&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url] &lt;br /&gt; &lt;br /&gt; &lt;a href=&quot;https://vercel.com/oss&quot;&gt; &lt;img alt=&quot;Vercel OSS Program&quot; src=&quot;https://vercel.com/oss/program-badge.svg&quot; /&gt; &lt;/a&gt;

![][image-overview]

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [👋🏻 Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [✨ Features](#-features)
  - [✨ MCP Plugin One-Click Installation](#-mcp-plugin-one-click-installation)
  - [🏪 MCP Marketplace](#-mcp-marketplace)
  - [🖥️ Desktop App](#️-desktop-app)
  - [🌐 Smart Internet Search](#-smart-internet-search)
  - [Chain of Thought](#chain-of-thought)
  - [Branching Conversations](#branching-conversations)
  - [Artifacts Support](#artifacts-support)
  - [File Upload /Knowledge Base](#file-upload-knowledge-base)
  - [Multi-Model Service Provider Support](#multi-model-service-provider-support)
  - [Local Large Language Model (LLM) Support](#local-large-language-model-llm-support)
  - [Model Visual Recognition](#model-visual-recognition)
  - [TTS &amp; STT Voice Conversation](#tts--stt-voice-conversation)
  - [Text to Image Generation](#text-to-image-generation)
  - [Plugin System (Function Calling)](#plugin-system-function-calling)
  - [Agent Market (GPTs)](#agent-market-gpts)
  - [Support Local / Remote Database](#support-local--remote-database)
  - [Support Multi-User Management](#support-multi-user-management)
  - [Progressive Web App (PWA)](#progressive-web-app-pwa)
  - [Mobile Device Adaptation](#mobile-device-adaptation)
  - [Custom Themes](#custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [⚡️ Performance](#️-performance)
- [🛳 Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [📦 Ecosystem](#-ecosystem)
- [🧩 Plugins](#-plugins)
- [⌨️ Local Development](#️-local-development)
- [🤝 Contributing](#-contributing)
- [❤️ Sponsor](#️-sponsor)
- [🔗 More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

## 👋🏻 Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![][vercel-shield-badge]][vercel-link]   | No installation or registration necessary! Visit our website to experience it firsthand.                           |
| :---------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link] | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub. |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ ⭐️

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## ✨ Features

Transform your AI experience with LobeChat&#039;s powerful features designed for seamless connectivity, enhanced productivity, and unlimited creativity.

![][image-feat-mcp]

### ✨ MCP Plugin One-Click Installation

**Seamlessly Connect Your AI to the World**

Unlock the full potential of your AI by enabling smooth, secure, and dynamic interactions with external tools, data sources, and services. LobeChat&#039;s MCP (Model Context Protocol) plugin system breaks down the barriers between your AI and the digital ecosystem, allowing for unprecedented connectivity and functionality.

Transform your conversations into powerful workflows by connecting to databases, APIs, file systems, and more. Experience the freedom of AI that truly understands and interacts with your world.

[![][back-to-top]](#readme-top)

![][image-feat-mcp-market]

### 🏪 MCP Marketplace

**Discover, Connect, Extend**

Browse a growing library of MCP plugins to expand your AI&#039;s capabilities and streamline your workflows effortlessly. Visit [lobehub.com/mcp](https://lobehub.com/mcp) to explore the MCP Marketplace, which offers a curated collection of integrations that enhance your AI&#039;s ability to work with various tools and services.

From productivity tools to development environments, discover new ways to extend your AI&#039;s reach and effectiveness. Connect with the community and find the perfect plugins for your specific needs.

[![][back-to-top]](#readme-top)

![][image-feat-desktop]

### 🖥️ Desktop App

**Peak Performance, Zero Distractions**

Get the full LobeChat experience without browser limitations—comprehensive, focused, and always ready to go. Our desktop application provides a dedicated environment for your AI interactions, ensuring optimal performance and minimal distractions.

Experience faster response times, better resource management, and a more stable connection to your AI assistant. The desktop app is designed for users who demand the best performance from their AI tools.

[![][back-to-top]](#readme-top)

![][image-feat-web-search]

### 🌐 Smart Internet Search

**Online Knowledge On Demand**

With real-time internet access, your AI keeps up with the world—news, data, trends, and more. Stay informed and get the most current information available, enabling your AI to provide accurate and up-to-date responses.

Access live information, verify facts, and explore current events without leaving your conversation. Your AI becomes a gateway to the world&#039;s knowledge, always current and comprehensive.

[![][back-to-top]](#readme-top)

[![][image-feat-cot]][docs-feat-cot]

### [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeChat. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [📘 LobeChat Knowledge Base Launch — From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

- **[OpenAI](https://lobechat.com/discover/provider/openai)**: OpenAI is a global leader in artificial intelligence research, with models like the GPT series pushing the frontiers of natural language processing. OpenAI is committed to transforming multiple industries through innovative and efficient AI solutions. Their products demonstrate significant performance and cost-effectiveness, widely used in research, business, and innovative applications.
- **[Ollama](https://lobechat.com/discover/provider/ollama)**: Ollama provides models that cover a wide range of fields, including code generation, mathematical operations, multilingual processing, and conversational interaction, catering to diverse enterprise-level and localized deployment needs.
- **[Anthropic](https://lobechat.com/discover/provider/anthropic)**: Anthropic is a company focused on AI research and development, offering a range of advanced language models such as Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Opus, and Claude 3 Haiku. These models achieve an ideal balance between intelligence, speed, and cost, suitable for various applications from enterprise workloads to rapid-response scenarios. Claude 3.5 Sonnet, as their latest model, has excelled in multiple evaluations while maintaining a high cost-performance ratio.
- **[Bedrock](https://lobechat.com/discover/provider/bedrock)**: Bedrock is a service provided by Amazon AWS, focusing on delivering advanced AI language and visual models for enterprises. Its model family includes Anthropic&#039;s Claude series, Meta&#039;s Llama 3.1 series, and more, offering a range of options from lightweight to high-performance, supporting tasks such as text generation, conversation, and image processing for businesses of varying scales and needs.
- **[Google](https://lobechat.com/discover/provider/google)**: Google&#039;s Gemini series represents its most advanced, versatile AI models, developed by Google DeepMind, designed for multimodal capabilities, supporting seamless understanding and processing of text, code, images, audio, and video. Suitable for various environments from data centers to mobile devices, it significantly enhances the efficiency and applicability of AI models.
- **[DeepSeek](https://lobechat.com/discover/provider/deepseek)**: DeepSeek is a company focused on AI technology research and application, with its latest model DeepSeek-V2.5 integrating general dialogue and code processing capabilities, achieving significant improvements in human preference alignment, writing tasks, and instruction following.
- **[Moonshot](https://lobechat.com/discover/provider/moonshot)**: Moonshot is an open-source platform launched by Beijing Dark Side Technology Co., Ltd., providing various natural language processing models with a wide range of applications, including but not limited to content creation, academic research, intelligent recommendations, and medical diagnosis, supporting long text processing and complex generation tasks.
- **[OpenRouter](https://lobechat.com/discover/provider/openrouter)**: OpenRouter is a service platform providing access to various cutting-edge large model interfaces, supporting OpenAI, Anthropic, LLaMA, and more, suitable for diverse development and application needs. Users can flexibly choose the optimal model and pricing based on their requirements, enhancing the AI experience.
- **[HuggingFace](https://lobechat.com/discover/provider/huggingface)**: The HuggingFace Inference API provides a fast and free way for you to explore thousands of models for various tasks. Whether you are prototyping for a new application or experimenting with the capabilities of machine learning, this API gives you instant access to high-performance models across multiple domains.
- **[Cloudflare Workers AI](https://lobechat.com/discover/provider/cloudflare)**: Run serverless GPU-powered machine learning models on Cloudflare&#039;s global network.

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+32)&lt;/kbd&gt;&lt;/summary&gt;

- **[GitHub](https://lobechat.com/discover/provider/github)**: With GitHub Models, developers can become AI engineers and leverage the industry&#039;s leading AI models.
- **[Novita](https://lobechat.com/discover/provider/novita)**: Novita AI is a platform providing a variety of large language models and AI image generation API services, flexible, reliable, and cost-effective. It supports the latest open-source models like Llama3 and Mistral, offering a comprehensive, user-friendly, and auto-scaling API solution for generative AI application development, suitable for the rapid growth of AI startups.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[302.AI](https://lobechat.com/discover/provider/ai302)**: 302.AI is an on-demand AI application platform offering the most comprehensive AI APIs and online AI applications available on the market.
- **[Together AI](https://lobechat.com/discover/provider/togetherai)**: Together AI is dedicated to achieving leading performance through innovative AI models, offering extensive customization capabilities, including rapid scaling support and intuitive deployment processes to meet various enterprise needs.
- **[Fireworks AI](https://lobechat.com/discover/provider/fireworksai)**: Fireworks AI is a leading provider of advanced language model services, focusing on functional calling and multimodal processing. Its latest model, Firefunction V2, is based on Llama-3, optimized for function calling, conversation, and instruction following. The visual language model FireLLaVA-13B supports mixed input of images and text. Other notable models include the Llama series and Mixtral series, providing efficient multilingual instruction following and generation support.
- **[Groq](https://lobechat.com/discover/provider/groq)**: Groq&#039;s LPU inference engine has excelled in the latest independent large language model (LLM) benchmarks, redefining the standards for AI solutions with its remarkable speed and efficiency. Groq represents instant inference speed, demonstrating strong performance in cloud-based deployments.
- **[Perplexity](https://lobechat.com/discover/provider/perplexity)**: Perplexity is a leading provider of conversational generation models, offering various advanced Llama 3.1 models that support both online and offline applications, particularly suited for complex natural language processing tasks.
- **[Mistral](https://lobechat.com/discover/provider/mistral)**: Mistral provides advanced general, specialized, and research models widely used in complex reasoning, multilingual tasks, and code generation. Through functional calling interfaces, users can integrate custom functionalities for specific applications.
- **[ModelScope](https://lobechat.com/discover/provider/modelscope)**: ModelScope is a model-as-a-service platform launched by Alibaba Cloud, offering a wide range of AI models and inference services.
- **[Ai21Labs](https://lobechat.com/discover/provider/ai21)**: AI21 Labs builds foundational models and AI systems for enterprises, accelerating the application of generative AI in production.
- **[Upstage](https://lobechat.com/discover/provider/upstage)**: Upstage focuses on developing AI models for various business needs, including Solar LLM and document AI, aiming to achieve artificial general intelligence (AGI) for work. It allows for the creation of simple conversational agents through Chat API and supports functional calling, translation, embedding, and domain-specific applications.
- **[xAI (Grok)](https://lobechat.com/discover/provider/xai)**: xAI is a company dedicated to building artificial intelligence to accelerate human scientific discovery. Our mission is to advance our collective understanding of the universe.
- **[Aliyun Bailian](https://lobechat.com/discover/provider/qwen)**: Tongyi Qianwen is a large-scale language model independently developed by Alibaba Cloud, featuring strong natural language understanding and generation capabilities. It can answer various questions, create written content, express opinions, and write code, playing a role in multiple fields.
- **[Wenxin](https://lobechat.com/discover/provider/wenxin)**: An enterprise-level one-stop platform for large model and AI-native application development and services, providing the most comprehensive and user-friendly toolchain for the entire pr

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[twentyhq/twenty]]></title>
            <link>https://github.com/twentyhq/twenty</link>
            <guid>https://github.com/twentyhq/twenty</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[Building a modern alternative to Salesforce, powered by the community.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/twentyhq/twenty">twentyhq/twenty</a></h1>
            <p>Building a modern alternative to Salesforce, powered by the community.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 35,705</p>
            <p>Forks: 4,238</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>[![Hacktoberfest 2025](packages/twenty-website/public/images/readme/hacktoberfest2025.png)](https://twentycrm.notion.site/)

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.twenty.com&quot;&gt;
    &lt;img src=&quot;./packages/twenty-website/public/images/core/logo.svg&quot; width=&quot;100px&quot; alt=&quot;Twenty logo&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h2 align=&quot;center&quot; &gt;The #1 Open-Source CRM &lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://twenty.com&quot;&gt;🌐 Website&lt;/a&gt; · &lt;a href=&quot;https://twenty.com/developers&quot;&gt;📚 Documentation&lt;/a&gt; · &lt;a href=&quot;https://github.com/orgs/twentyhq/projects/1&quot;&gt;&lt;img src=&quot;./packages/twenty-website/public/images/readme/planner-icon.svg&quot; width=&quot;12&quot; height=&quot;12&quot;/&gt; Roadmap &lt;/a&gt; · &lt;a href=&quot;https://discord.gg/cx5n4Jzs57&quot;&gt;&lt;img src=&quot;./packages/twenty-website/public/images/readme/discord-icon.svg&quot; width=&quot;12&quot; height=&quot;12&quot;/&gt; Discord&lt;/a&gt; · &lt;a href=&quot;https://www.figma.com/file/xt8O9mFeLl46C5InWwoMrN/Twenty&quot;&gt;&lt;img src=&quot;./packages/twenty-website/public/images/readme/figma-icon.png&quot;  width=&quot;12&quot; height=&quot;12&quot;/&gt;  Figma&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt;


&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.twenty.com&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/github-cover-dark.png&quot; /&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/github-cover-light.png&quot; /&gt;
      &lt;img src=&quot;./packages/twenty-website/public/images/readme/github-cover-light.png&quot; alt=&quot;Cover&quot; /&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;br /&gt;

# Installation 

See:  
🚀 [Self-hosting](https://twenty.com/developers/section/self-hosting)  
🖥️ [Local Setup](https://twenty.com/developers/local-setup)  

# Does the world need another CRM?

We built Twenty for three reasons:

**CRMs are too expensive, and users are trapped.** Companies use locked-in customer data to hike prices. It shouldn&#039;t be that way.

**A fresh start is required to build a better experience.** We can learn from past mistakes and craft a cohesive experience inspired by new UX patterns from tools like Notion, Airtable or Linear.

**We believe in Open-source and community.** Hundreds of developers are already building Twenty together. Once we have plugin capabilities, a whole ecosystem will grow around it.

&lt;br /&gt;

# What You Can Do With Twenty

Please feel free to flag any specific needs you have by creating an issue.   

Below are a few features we have implemented to date:

+ [Personalize layouts with filters, sort, group by, kanban and table views](#personalize-layouts-with-filters-sort-group-by-kanban-and-table-views)
+ [Customize your objects and fields](#customize-your-objects-and-fields)
+ [Create and manage permissions with custom roles](#create-and-manage-permissions-with-custom-roles)
+ [Automate workflow with triggers and actions](#automate-workflow-with-triggers-and-actions)
+ [Emails, calendar events, files, and more](#emails-calendar-events-files-and-more)


## Personalize layouts with filters, sort, group by, kanban and table views

&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/views-dark.png&quot; /&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/views-light.png&quot; /&gt;
      &lt;img src=&quot;./packages/twenty-website/public/images/readme/views-light.png&quot; alt=&quot;Companies Kanban Views&quot; /&gt;
    &lt;/picture&gt;
&lt;/p&gt;

## Customize your objects and fields

&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/data-model-dark.png&quot; /&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/data-model-light.png&quot; /&gt;
      &lt;img src=&quot;./packages/twenty-website/public/images/readme/data-model-light.png&quot; alt=&quot;Setting Custom Objects&quot; /&gt;
    &lt;/picture&gt;
&lt;/p&gt;

## Create and manage permissions with custom roles

&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/permissions-dark.png&quot; /&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/permissions-light.png&quot; /&gt;
      &lt;img src=&quot;./packages/twenty-website/public/images/readme/permissions-light.png&quot; alt=&quot;Permissions&quot; /&gt;
    &lt;/picture&gt;
&lt;/p&gt;

## Automate workflow with triggers and actions

&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/workflows-dark.png&quot; /&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/workflows-light.png&quot; /&gt;
      &lt;img src=&quot;./packages/twenty-website/public/images/readme/workflows-light.png&quot; alt=&quot;Workflows&quot; /&gt;
    &lt;/picture&gt;
&lt;/p&gt;

## Emails, calendar events, files, and more

&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/plus-other-features-dark.png&quot; /&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/twentyhq/twenty/refs/heads/main/packages/twenty-website/public/images/readme/plus-other-features-light.png&quot; /&gt;
      &lt;img src=&quot;./packages/twenty-website/public/images/readme/plus-other-features-light.png&quot; alt=&quot;Other Features&quot; /&gt;
    &lt;/picture&gt;
&lt;/p&gt;

&lt;br /&gt;

# Stack
- [TypeScript](https://www.typescriptlang.org/)
- [Nx](https://nx.dev/)
- [NestJS](https://nestjs.com/), with [BullMQ](https://bullmq.io/), [PostgreSQL](https://www.postgresql.org/), [Redis](https://redis.io/)
- [React](https://reactjs.org/), with [Recoil](https://recoiljs.org/), [Emotion](https://emotion.sh/) and [Lingui](https://lingui.dev/)



# Thanks

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.chromatic.com/&quot;&gt;&lt;img src=&quot;./packages/twenty-website/public/images/readme/chromatic.png&quot; height=&quot;30&quot; alt=&quot;Chromatic&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://greptile.com&quot;&gt;&lt;img src=&quot;./packages/twenty-website/public/images/readme/greptile.png&quot; height=&quot;30&quot; alt=&quot;Greptile&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://sentry.io/&quot;&gt;&lt;img src=&quot;./packages/twenty-website/public/images/readme/sentry.png&quot; height=&quot;30&quot; alt=&quot;Sentry&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://crowdin.com/&quot;&gt;&lt;img src=&quot;./packages/twenty-website/public/images/readme/crowdin.png&quot; height=&quot;30&quot; alt=&quot;Crowdin&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

  Thanks to these amazing services that we use and recommend for UI testing (Chromatic), code review (Greptile), catching bugs (Sentry) and translating (Crowdin).


# Join the Community

- Star the repo
- Subscribe to releases (watch -&gt; custom -&gt; releases)
- Follow us on [Twitter](https://twitter.com/twentycrm) or [LinkedIn](https://www.linkedin.com/company/twenty/) 
- Join our [Discord](https://discord.gg/cx5n4Jzs57)
- Improve translations on [Crowdin](https://twenty.crowdin.com/twenty) 
- [Contributions](https://github.com/twentyhq/twenty/contribute) are, of course, most welcome! 
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[bitwarden/clients]]></title>
            <link>https://github.com/bitwarden/clients</link>
            <guid>https://github.com/bitwarden/clients</guid>
            <pubDate>Sat, 04 Oct 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[Bitwarden client apps (web, browser extension, desktop, and cli).]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bitwarden/clients">bitwarden/clients</a></h1>
            <p>Bitwarden client apps (web, browser extension, desktop, and cli).</p>
            <p>Language: TypeScript</p>
            <p>Stars: 11,335</p>
            <p>Forks: 1,503</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/bitwarden/brand/main/screenshots/apps-combo-logo.png&quot; alt=&quot;Bitwarden&quot; /&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/bitwarden/clients/actions/workflows/build-browser.yml?query=branch:main&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/bitwarden/clients/actions/workflows/build-browser.yml/badge.svg?branch=main&quot; alt=&quot;GitHub Workflow browser build on main&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/bitwarden/clients/actions/workflows/build-cli.yml?query=branch:main&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/bitwarden/clients/actions/workflows/build-cli.yml/badge.svg?branch=main&quot; alt=&quot;GitHub Workflow CLI build on main&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/bitwarden/clients/actions/workflows/build-desktop.yml?query=branch:main&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/bitwarden/clients/actions/workflows/build-desktop.yml/badge.svg?branch=main&quot; alt=&quot;GitHub Workflow desktop build on main&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/bitwarden/clients/actions/workflows/build-web.yml?query=branch:main&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/bitwarden/clients/actions/workflows/build-web.yml/badge.svg?branch=main&quot; alt=&quot;GitHub Workflow web build on main&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://gitter.im/bitwarden/Lobby&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://badges.gitter.im/bitwarden/Lobby.svg&quot; alt=&quot;gitter chat&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

---

# Bitwarden Client Applications

This repository houses all Bitwarden client applications except the mobile applications ([iOS](https://github.com/bitwarden/ios) | [android](https://github.com/bitwarden/android)).

Please refer to the [Clients section](https://contributing.bitwarden.com/getting-started/clients/) of the [Contributing Documentation](https://contributing.bitwarden.com/) for build instructions, recommended tooling, code style tips, and lots of other great information to get you started.

## Related projects:

- [bitwarden/server](https://github.com/bitwarden/server): The core infrastructure backend (API, database, Docker, etc).
- [bitwarden/ios](https://github.com/bitwarden/ios): Bitwarden iOS Password Manager &amp; Authenticator apps.
- [bitwarden/android](https://github.com/bitwarden/android): Bitwarden Android Password Manager &amp; Authenticator apps.
- [bitwarden/directory-connector](https://github.com/bitwarden/directory-connector): A tool for syncing a directory (AD, LDAP, Azure, G Suite, Okta) to an organization.

# We&#039;re Hiring!

Interested in contributing in a big way? Consider joining our team! We&#039;re hiring for many positions. Please take a look at our [Careers page](https://bitwarden.com/careers/) to see what opportunities are [currently open](https://bitwarden.com/careers/#open-positions) as well as what it&#039;s like to work at Bitwarden.

# Contribute

Code contributions are welcome! Please commit any pull requests against the `main` branch. Learn more about how to contribute by reading the [Contributing Guidelines](https://contributing.bitwarden.com/contributing/). Check out the [Contributing Documentation](https://contributing.bitwarden.com/) for how to get started with your first contribution.

Security audits and feedback are welcome. Please open an issue or email us privately if the report is sensitive in nature. You can read our security policy in the [`SECURITY.md`](SECURITY.md) file.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>