<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Sat, 28 Feb 2026 00:05:33 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[bytedance/deer-flow]]></title>
            <link>https://github.com/bytedance/deer-flow</link>
            <guid>https://github.com/bytedance/deer-flow</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:33 GMT</pubDate>
            <description><![CDATA[An open-source SuperAgent harness that researches, codes, and creates. With the help of sandboxes, memories, tools, skills and subagents, it handles different levels of tasks that could take minutes to hours.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytedance/deer-flow">bytedance/deer-flow</a></h1>
            <p>An open-source SuperAgent harness that researches, codes, and creates. With the help of sandboxes, memories, tools, skills and subagents, it handles different levels of tasks that could take minutes to hours.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,819</p>
            <p>Forks: 2,666</p>
            <p>Stars today: 696 stars today</p>
            <h2>README</h2><pre># ü¶å DeerFlow - 2.0

DeerFlow (**D**eep **E**xploration and **E**fficient **R**esearch **Flow**) is an open-source **super agent harness** that orchestrates **sub-agents**, **memory**, and **sandboxes** to do almost anything ‚Äî powered by **extensible skills**.

https://github.com/user-attachments/assets/a8bcadc4-e040-4cf2-8fda-dd768b999c18

&gt; [!NOTE]
&gt; **DeerFlow 2.0 is a ground-up rewrite.** It shares no code with v1. If you&#039;re looking for the original Deep Research framework, it&#039;s maintained on the [`1.x` branch](https://github.com/bytedance/deer-flow/tree/main-1.x) ‚Äî contributions there are still welcome. Active development has moved to 2.0.

## Offiical Website

Learn more and see **real demos** on our official website.

**[deerflow.tech](https://deerflow.tech/)**

---

## Table of Contents

- [Quick Start](#quick-start)
- [Sandbox Mode](#sandbox-mode)
- [From Deep Research to Super Agent Harness](#from-deep-research-to-super-agent-harness)
- [Core Features](#core-features)
  - [Skills &amp; Tools](#skills--tools)
  - [Sub-Agents](#sub-agents)
  - [Sandbox &amp; File System](#sandbox--file-system)
  - [Context Engineering](#context-engineering)
  - [Long-Term Memory](#long-term-memory)
- [Recommended Models](#recommended-models)
- [Documentation](#documentation)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgments](#acknowledgments)
- [Star History](#star-history)

## Quick Start

### Configuration

1. **Clone the DeerFlow repository**

   ```bash
   git clone https://github.com/bytedance/deer-flow.git
   cd deer-flow
   ```

2. **Generate local configuration files**

   From the project root directory (`deer-flow/`), run:

   ```bash
   make config
   ```

   This command creates local configuration files based on the provided example templates.

3. **Configure your preferred model(s)**

   Edit `config.yaml` and define at least one model:

   ```yaml
   models:
     - name: gpt-4                       # Internal identifier
       display_name: GPT-4               # Human-readable name
       use: langchain_openai:ChatOpenAI  # LangChain class path
       model: gpt-4                      # Model identifier for API
       api_key: $OPENAI_API_KEY          # API key (recommended: use env var)
       max_tokens: 4096                  # Maximum tokens per request
       temperature: 0.7                  # Sampling temperature
   ```

  
4. **Set API keys for your configured model(s)**

   Choose one of the following methods:

- Option A: Edit the `.env` file in the project root (Recommended)


   ```bash
   TAVILY_API_KEY=your-tavily-api-key
   OPENAI_API_KEY=your-openai-api-key
   # Add other provider keys as needed
   ```

- Option B: Export environment variables in your shell

   ```bash
   export OPENAI_API_KEY=your-openai-api-key
   ```

- Option C: Edit `config.yaml` directly (Not recommended for production)

   ```yaml
   models:
     - name: gpt-4
       api_key: your-actual-api-key-here  # Replace placeholder
   ```

### Running the Application

#### Option 1: Docker (Recommended)

The fastest way to get started with a consistent environment:

1. **Initialize and start**:
   ```bash
   make docker-init    # Pull sandbox image (Only once or when image updates)
   make docker-start   # Start services (auto-detects sandbox mode from config.yaml)
   ```

   `make docker-start` now starts `provisioner` only when `config.yaml` uses provisioner mode (`sandbox.use: src.community.aio_sandbox:AioSandboxProvider` with `provisioner_url`).

2. **Access**: http://localhost:2026

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed Docker development guide.

#### Option 2: Local Development

If you prefer running services locally:

1. **Check prerequisites**:
   ```bash
   make check  # Verifies Node.js 22+, pnpm, uv, nginx
   ```

2. **(Optional) Pre-pull sandbox image**:
   ```bash
   # Recommended if using Docker/Container-based sandbox
   make setup-sandbox
   ```

3. **Start services**:
   ```bash
   make dev
   ```

4. **Access**: http://localhost:2026

### Advanced
#### Sandbox Mode

DeerFlow supports multiple sandbox execution modes:
- **Local Execution** (runs sandbox code directly on the host machine)
- **Docker Execution** (runs sandbox code in isolated Docker containers)
- **Docker Execution with Kubernetes** (runs sandbox code in Kubernetes pods via provisioner service)

For Docker development, service startup follows `config.yaml` sandbox mode. In Local/Docker modes, `provisioner` is not started.

See the [Sandbox Configuration Guide](backend/docs/CONFIGURATION.md#sandbox) to configure your preferred mode.

#### MCP Server

DeerFlow supports configurable MCP servers and skills to extend its capabilities.
See the [MCP Server Guide](backend/docs/MCP_SERVER.md) for detailed instructions.

## From Deep Research to Super Agent Harness

DeerFlow started as a Deep Research framework ‚Äî and the community ran with it. Since launch, developers have pushed it far beyond research: building data pipelines, generating slide decks, spinning up dashboards, automating content workflows. Things we never anticipated.

That told us something important: DeerFlow wasn&#039;t just a research tool. It was a **harness** ‚Äî a runtime that gives agents the infrastructure to actually get work done.

So we rebuilt it from scratch.

DeerFlow 2.0 is no longer a framework you wire together. It&#039;s a super agent harness ‚Äî batteries included, fully extensible. Built on LangGraph and LangChain, it ships with everything an agent needs out of the box: a filesystem, memory, skills, sandboxed execution, and the ability to plan and spawn sub-agents for complex, multi-step tasks.

Use it as-is. Or tear it apart and make it yours.

## Core Features

### Skills &amp; Tools

Skills are what make DeerFlow do *almost anything*.

A standard Agent Skill is a structured capability module ‚Äî a Markdown file that defines a workflow, best practices, and references to supporting resources. DeerFlow ships with built-in skills for research, report generation, slide creation, web pages, image and video generation, and more. But the real power is extensibility: add your own skills, replace the built-in ones, or combine them into compound workflows.

Skills are loaded progressively ‚Äî only when the task needs them, not all at once. This keeps the context window lean and makes DeerFlow work well even with token-sensitive models.

Tools follow the same philosophy. DeerFlow comes with a core toolset ‚Äî web search, web fetch, file operations, bash execution ‚Äî and supports custom tools via MCP servers and Python functions. Swap anything. Add anything.

```
# Paths inside the sandbox container
/mnt/skills/public
‚îú‚îÄ‚îÄ research/SKILL.md
‚îú‚îÄ‚îÄ report-generation/SKILL.md
‚îú‚îÄ‚îÄ slide-creation/SKILL.md
‚îú‚îÄ‚îÄ web-page/SKILL.md
‚îî‚îÄ‚îÄ image-generation/SKILL.md

/mnt/skills/custom
‚îî‚îÄ‚îÄ your-custom-skill/SKILL.md      ‚Üê yours
```

### Sub-Agents

Complex tasks rarely fit in a single pass. DeerFlow decomposes them.

The lead agent can spawn sub-agents on the fly ‚Äî each with its own scoped context, tools, and termination conditions. Sub-agents run in parallel when possible, report back structured results, and the lead agent synthesizes everything into a coherent output.

This is how DeerFlow handles tasks that take minutes to hours: a research task might fan out into a dozen sub-agents, each exploring a different angle, then converge into a single report ‚Äî or a website ‚Äî or a slide deck with generated visuals. One harness, many hands.

### Sandbox &amp; File System

DeerFlow doesn&#039;t just *talk* about doing things. It has its own computer.

Each task runs inside an isolated Docker container with a full filesystem ‚Äî skills, workspace, uploads, outputs. The agent reads, writes, and edits files. It executes bash commands and codes. It views images. All sandboxed, all auditable, zero contamination between sessions.

This is the difference between a chatbot with tool access and an agent with an actual execution environment.

```
# Paths inside the sandbox container
/mnt/user-data/
‚îú‚îÄ‚îÄ uploads/          ‚Üê your files
‚îú‚îÄ‚îÄ workspace/        ‚Üê agents&#039; working directory
‚îî‚îÄ‚îÄ outputs/          ‚Üê final deliverables
```

### Context Engineering

**Isolated Sub-Agent Context**: Each sub-agent runs in its own isolated context. This means that the sub-agent will not be able to see the context of the main agent or other sub-agents. This is important to ensure that the sub-agent is able to focus on the task at hand and not be distracted by the context of the main agent or other sub-agents.

**Summarization**: Within a session, DeerFlow manages context aggressively ‚Äî summarizing completed sub-tasks, offloading intermediate results to the filesystem, compressing what&#039;s no longer immediately relevant. This lets it stay sharp across long, multi-step tasks without blowing the context window.

### Long-Term Memory

Most agents forget everything the moment a conversation ends. DeerFlow remembers.

Across sessions, DeerFlow builds a persistent memory of your profile, preferences, and accumulated knowledge. The more you use it, the better it knows you ‚Äî your writing style, your technical stack, your recurring workflows. Memory is stored locally and stays under your control.

## Recommended Models

DeerFlow is model-agnostic ‚Äî it works with any LLM that implements the OpenAI-compatible API. That said, it performs best with models that support:

- **Long context windows** (100k+ tokens) for deep research and multi-step tasks
- **Reasoning capabilities** for adaptive planning and complex decomposition
- **Multimodal inputs** for image understanding and video comprehension
- **Strong tool-use** for reliable function calling and structured outputs

## Documentation

- [Contributing Guide](CONTRIBUTING.md) - Development environment setup and workflow
- [Configuration Guide](backend/docs/CONFIGURATION.md) - Setup and configuration instructions
- [Architecture Overview](backend/CLAUDE.md) - Technical architecture details
- [Backend Architecture](backend/README.md) - Backend architecture and API reference

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for development setup, workflow, and guidelines.

Regression coverage includes Docker sandbox mode detection and provisioner kubeconfig-path handling tests in `backend/tests/`.

## License

This project is open source and available under the [MIT License](./LICENSE).

## Acknowledgments

DeerFlow is built upon the incredible work of the open-source community. We are deeply grateful to all the projects and contributors whose efforts have made DeerFlow possible. Truly, we stand on the shoulders of giants.

We would like to extend our sincere appreciation to the following projects for their invaluable contributions:

- **[LangChain](https://github.com/langchain-ai/langchain)**: Their exceptional framework powers our LLM interactions and chains, enabling seamless integration and functionality.
- **[LangGraph](https://github.com/langchain-ai/langgraph)**: Their innovative approach to multi-agent orchestration has been instrumental in enabling DeerFlow&#039;s sophisticated workflows.

These projects exemplify the transformative power of open-source collaboration, and we are proud to build upon their foundations.

### Key Contributors

A heartfelt thank you goes out to the core authors of `DeerFlow`, whose vision, passion, and dedication have brought this project to life:

- **[Daniel Walnut](https://github.com/hetaoBackend/)**
- **[Henry Li](https://github.com/magiccube/)**

Your unwavering commitment and expertise have been the driving force behind DeerFlow&#039;s success. We are honored to have you at the helm of this journey.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=bytedance/deer-flow&amp;type=Date)](https://star-history.com/#bytedance/deer-flow&amp;Date)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ruvnet/ruflo]]></title>
            <link>https://github.com/ruvnet/ruflo</link>
            <guid>https://github.com/ruvnet/ruflo</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:32 GMT</pubDate>
            <description><![CDATA[üåä The leading agent orchestration platform for Claude. Deploy intelligent multi-agent swarms, coordinate autonomous workflows, and build conversational AI systems. Features enterprise-grade architecture, distributed swarm intelligence, RAG integration, and native Claude Code / Codex Integration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ruvnet/ruflo">ruvnet/ruflo</a></h1>
            <p>üåä The leading agent orchestration platform for Claude. Deploy intelligent multi-agent swarms, coordinate autonomous workflows, and build conversational AI systems. Features enterprise-grade architecture, distributed swarm intelligence, RAG integration, and native Claude Code / Codex Integration</p>
            <p>Language: TypeScript</p>
            <p>Stars: 15,593</p>
            <p>Forks: 1,801</p>
            <p>Stars today: 531 stars today</p>
            <h2>README</h2><pre># üåä Ruflo v3: Enterprise AI Orchestration Platform

&lt;div align=&quot;center&quot;&gt;

![Ruflo Banner](ruflo/assets/ruFlo.png)



[![GitHub Project of the Day](https://img.shields.io/badge/GitHub-Project%20of%20the%20Day-ff6600?style=for-the-badge&amp;logo=github&amp;logoColor=white)](https://github.com/ruvnet/claude-flow)

[![Star on GitHub](https://img.shields.io/github/stars/ruvnet/claude-flow?style=for-the-badge&amp;logo=github&amp;color=gold)](https://github.com/ruvnet/claude-flow)
[![Monthly Downloads](https://img.shields.io/npm/dm/claude-flow?style=for-the-badge&amp;logo=npm&amp;color=blue&amp;label=Monthly%20Downloads)](https://www.npmjs.com/package/claude-flow)
[![Total Downloads](https://img.shields.io/npm/dt/claude-flow?style=for-the-badge&amp;logo=npm&amp;color=cyan&amp;label=Total%20Downloads)](https://www.npmjs.com/package/claude-flow)
[![ruv.io](https://img.shields.io/badge/ruv.io-AI%20Platform-green?style=for-the-badge&amp;logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCI+PHBhdGggZmlsbD0id2hpdGUiIGQ9Ik0xMiAyQzYuNDggMiAyIDYuNDggMiAxMnM0LjQ4IDEwIDEwIDEwIDEwLTQuNDggMTAtMTBTMTcuNTIgMiAxMiAyem0wIDE4Yy00LjQyIDAtOC0zLjU4LTgtOHMzLjU4LTggOC04IDggMy41OCA4IDgtMy41OCA4LTggOHoiLz48L3N2Zz4=)](https://ruv.io)
[![Agentics Foundation](https://img.shields.io/badge/Agentics-Foundation-crimson?style=for-the-badge&amp;logo=openai)](https://discord.com/invite/dfxmpwkG2D)
[![Claude Code](https://img.shields.io/badge/Claude%20Code-SDK%20Integrated-green?style=for-the-badge&amp;logo=anthropic)](https://github.com/ruvnet/claude-flow)
[![MIT License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge&amp;logo=opensourceinitiative)](https://opensource.org/licenses/MIT)
---
[![Follow @ruv](https://img.shields.io/badge/Follow%20%40ruv-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white)](https://x.com/ruv)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&amp;logo=linkedin)](https://www.linkedin.com/in/reuvencohen/)
[![YouTube](https://img.shields.io/badge/YouTube-Subscribe-FF0000?style=for-the-badge&amp;logo=youtube&amp;logoColor=white)](https://www.youtube.com/@ReuvenCohen)

# **Production-ready multi-agent AI orchestration for Claude Code**
*Deploy 60+ specialized agents in coordinated swarms with self-learning capabilities, fault-tolerant consensus, and enterprise-grade security.*

&lt;/div&gt;

&gt; **Why Ruflo?** Claude Flow is now Ruflo ‚Äî named by Ruv, who loves Rust, flow states, and building things that feel inevitable. The &quot;Ru&quot; is the Ruv. The &quot;flo&quot; is the flow. Underneath, WASM kernels written in Rust power the policy engine, embeddings, and proof system. 5,800 commits later, the alpha is over. This is v3.5.

## Getting into the Flow

Ruflo is a comprehensive AI agent orchestration framework that transforms Claude Code into a powerful multi-agent development platform. It enables teams to deploy, coordinate, and optimize specialized AI agents working together on complex software engineering tasks.

### Self-Learning/Self-Optimizing Agent Architecture

```
User ‚Üí Ruflo (CLI/MCP) ‚Üí Router ‚Üí Swarm ‚Üí Agents ‚Üí Memory ‚Üí LLM Providers
                       ‚Üë                          ‚Üì
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ Learning Loop ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

&lt;details&gt;
&lt;summary&gt;üìê &lt;strong&gt;Expanded Architecture&lt;/strong&gt; ‚Äî Full system diagram with RuVector intelligence&lt;/summary&gt;

```mermaid
flowchart TB
    subgraph USER[&quot;üë§ User Layer&quot;]
        U[User]
    end

    subgraph ENTRY[&quot;üö™ Entry Layer&quot;]
        CLI[CLI / MCP Server]
        AID[AIDefence Security]
    end

    subgraph ROUTING[&quot;üß≠ Routing Layer&quot;]
        QL[Q-Learning Router]
        MOE[MoE - 8 Experts]
        SK[Skills - 42+]
        HK[Hooks - 17]
    end

    subgraph SWARM[&quot;üêù Swarm Coordination&quot;]
        TOPO[Topologies&lt;br/&gt;mesh/hier/ring/star]
        CONS[Consensus&lt;br/&gt;Raft/BFT/Gossip/CRDT]
        CLM[Claims&lt;br/&gt;Human-Agent Coord]
    end

    subgraph AGENTS[&quot;ü§ñ 60+ Agents&quot;]
        AG1[coder]
        AG2[tester]
        AG3[reviewer]
        AG4[architect]
        AG5[security]
        AG6[...]
    end

    subgraph RESOURCES[&quot;üì¶ Resources&quot;]
        MEM[(Memory&lt;br/&gt;AgentDB)]
        PROV[Providers&lt;br/&gt;Claude/GPT/Gemini/Ollama]
        WORK[Workers - 12&lt;br/&gt;ultralearn/audit/optimize]
    end

    subgraph RUVECTOR[&quot;üß† RuVector Intelligence Layer&quot;]
        direction TB
        subgraph ROW1[&quot; &quot;]
            SONA[SONA&lt;br/&gt;Self-Optimize&lt;br/&gt;&amp;lt;0.05ms]
            EWC[EWC++&lt;br/&gt;No Forgetting]
            FLASH[Flash Attention&lt;br/&gt;2.49-7.47x]
        end
        subgraph ROW2[&quot; &quot;]
            HNSW[HNSW&lt;br/&gt;150x-12,500x faster]
            RB[ReasoningBank&lt;br/&gt;Pattern Store]
            HYP[Hyperbolic&lt;br/&gt;Poincar√©]
        end
        subgraph ROW3[&quot; &quot;]
            LORA[LoRA/Micro&lt;br/&gt;128x compress]
            QUANT[Int8 Quant&lt;br/&gt;3.92x memory]
            RL[9 RL Algos&lt;br/&gt;Q/SARSA/PPO/DQN]
        end
    end

    subgraph LEARNING[&quot;üîÑ Learning Loop&quot;]
        L1[RETRIEVE] --&gt; L2[JUDGE] --&gt; L3[DISTILL] --&gt; L4[CONSOLIDATE] --&gt; L5[ROUTE]
    end

    U --&gt; CLI
    CLI --&gt; AID
    AID --&gt; QL &amp; MOE &amp; SK &amp; HK
    QL &amp; MOE &amp; SK &amp; HK --&gt; TOPO &amp; CONS &amp; CLM
    TOPO &amp; CONS &amp; CLM --&gt; AG1 &amp; AG2 &amp; AG3 &amp; AG4 &amp; AG5 &amp; AG6
    AG1 &amp; AG2 &amp; AG3 &amp; AG4 &amp; AG5 &amp; AG6 --&gt; MEM &amp; PROV &amp; WORK
    MEM --&gt; SONA &amp; EWC &amp; FLASH
    SONA &amp; EWC &amp; FLASH --&gt; HNSW &amp; RB &amp; HYP
    HNSW &amp; RB &amp; HYP --&gt; LORA &amp; QUANT &amp; RL
    LORA &amp; QUANT &amp; RL --&gt; L1
    L5 -.-&gt;|loops back| QL

    style RUVECTOR fill:#1a1a2e,stroke:#e94560,stroke-width:2px
    style LEARNING fill:#0f3460,stroke:#e94560,stroke-width:2px
    style USER fill:#16213e,stroke:#0f3460
    style ENTRY fill:#1a1a2e,stroke:#0f3460
    style ROUTING fill:#1a1a2e,stroke:#0f3460
    style SWARM fill:#1a1a2e,stroke:#0f3460
    style AGENTS fill:#1a1a2e,stroke:#0f3460
    style RESOURCES fill:#1a1a2e,stroke:#0f3460
```

**RuVector Components** (included with Ruflo):

| Component | Purpose | Performance |
|-----------|---------|-------------|
| **SONA** | Self-Optimizing Neural Architecture - learns optimal routing | Fast adaptation |
| **EWC++** | Elastic Weight Consolidation - prevents catastrophic forgetting | Preserves learned patterns |
| **Flash Attention** | Optimized attention computation | 2-7x speedup |
| **HNSW** | Hierarchical Navigable Small World vector search | Sub-millisecond retrieval |
| **ReasoningBank** | Pattern storage with trajectory learning | RETRIEVE‚ÜíJUDGE‚ÜíDISTILL |
| **Hyperbolic** | Poincare ball embeddings for hierarchical data | Better code relationships |
| **LoRA/MicroLoRA** | Low-Rank Adaptation for efficient fine-tuning | Lightweight adaptation |
| **Int8 Quantization** | Memory-efficient weight storage | ~4x memory reduction |
| **SemanticRouter** | Semantic task routing with cosine similarity | Fast intent routing |
| **9 RL Algorithms** | Q-Learning, SARSA, A2C, PPO, DQN, Decision Transformer, etc. | Task-specific learning |

```bash
# Use RuVector via Ruflo
npx ruflo@alpha hooks intelligence --status
```

&lt;/details&gt;

### Get Started Fast

```bash
# One-line install (recommended)
curl -fsSL https://cdn.jsdelivr.net/gh/ruvnet/claude-flow@main/scripts/install.sh | bash

# Or full setup with MCP + diagnostics
curl -fsSL https://cdn.jsdelivr.net/gh/ruvnet/claude-flow@main/scripts/install.sh | bash -s -- --full

# Or via npx
npx ruflo@alpha init --wizard
```

---
### Key Capabilities

ü§ñ **60+ Specialized Agents** - Ready-to-use AI agents for coding, code review, testing, security audits, documentation, and DevOps. Each agent is optimized for its specific role.

üêù **Coordinated Agent Teams** - Run unlimited agents simultaneously in organized swarms. Agents spawn sub-workers, communicate, share context, and divide work automatically using hierarchical (queen/workers) or mesh (peer-to-peer) patterns.

üß† **Learns From Your Workflow** - The system remembers what works. Successful patterns are stored and reused, routing similar tasks to the best-performing agents. Gets smarter over time.

üîå **Works With Any LLM** - Switch between Claude, GPT, Gemini, Cohere, or local models like Llama. Automatic failover if one provider is unavailable. Smart routing picks the cheapest option that meets quality requirements.

‚ö° **Plugs Into Claude Code** - Native integration via MCP (Model Context Protocol). Use ruflo commands directly in your Claude Code sessions with full tool access.

üîí **Production-Ready Security** - Built-in protection against prompt injection, input validation, path traversal prevention, command injection blocking, and safe credential handling.

üß© **Extensible Plugin System** - Add custom capabilities with the plugin SDK. Create workers, hooks, providers, and security modules. Share plugins via the decentralized IPFS marketplace.

---

### A multi-purpose Agent Tool Kit 

&lt;details&gt;
&lt;summary&gt;üîÑ &lt;strong&gt;Core Flow&lt;/strong&gt; ‚Äî How requests move through the system&lt;/summary&gt;

Every request flows through four layers: from your CLI or Claude Code interface, through intelligent routing, to specialized agents, and finally to LLM providers for reasoning.

| Layer | Components | What It Does |
|-------|------------|--------------|
| User | Claude Code, CLI | Your interface to control and run commands |
| Orchestration | MCP Server, Router, Hooks | Routes requests to the right agents |
| Agents | 60+ types | Specialized workers (coder, tester, reviewer...) |
| Providers | Anthropic, OpenAI, Google, Ollama | AI models that power reasoning |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üêù &lt;strong&gt;Swarm Coordination&lt;/strong&gt; ‚Äî How agents work together&lt;/summary&gt;

Agents organize into swarms led by queens that coordinate work, prevent drift, and reach consensus on decisions‚Äîeven when some agents fail.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Coordination | Queen, Swarm, Consensus | Manages agent teams (Raft, Byzantine, Gossip) |
| Drift Control | Hierarchical topology, Checkpoints | Prevents agents from going off-task |
| Hive Mind | Queen-led hierarchy, Collective memory | Strategic/tactical/adaptive queens coordinate workers |
| Consensus | Byzantine, Weighted, Majority | Fault-tolerant decisions (2/3 majority for BFT) |

**Hive Mind Capabilities:**
- üêù **Queen Types**: Strategic (planning), Tactical (execution), Adaptive (optimization)
- üë∑ **8 Worker Types**: Researcher, Coder, Analyst, Tester, Architect, Reviewer, Optimizer, Documenter
- üó≥Ô∏è **3 Consensus Algorithms**: Majority, Weighted (Queen 3x), Byzantine (f &lt; n/3)
- üß† **Collective Memory**: Shared knowledge, LRU cache, SQLite persistence with WAL
- ‚ö° **Performance**: Fast batch spawning with parallel agent coordination

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üß† &lt;strong&gt;Intelligence &amp; Memory&lt;/strong&gt; ‚Äî How the system learns and remembers&lt;/summary&gt;

The system stores successful patterns in vector memory, builds a knowledge graph for structural understanding, learns from outcomes via neural networks, and adapts routing based on what works best.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Memory | HNSW, AgentDB, Cache | Stores and retrieves patterns with fast HNSW search |
| Knowledge Graph | MemoryGraph, PageRank, Communities | Identifies influential insights, detects clusters (ADR-049) |
| Self-Learning | LearningBridge, SONA, ReasoningBank | Triggers learning from insights, confidence lifecycle (ADR-049) |
| Agent Scopes | AgentMemoryScope, 3-scope dirs | Per-agent isolation + cross-agent knowledge transfer (ADR-049) |
| Embeddings | ONNX Runtime, MiniLM | Local vectors without API calls (75x faster) |
| Learning | SONA, MoE, ReasoningBank | Self-improves from results (&lt;0.05ms adaptation) |
| Fine-tuning | MicroLoRA, EWC++ | Lightweight adaptation without full retraining |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;‚ö° &lt;strong&gt;Optimization&lt;/strong&gt; ‚Äî How to reduce cost and latency&lt;/summary&gt;

Skip expensive LLM calls for simple tasks using WebAssembly transforms, and compress tokens to reduce API costs by 30-50%.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Agent Booster | WASM, AST analysis | Skips LLM for simple edits (&lt;1ms) |
| Token Optimizer | Compression, Caching | Reduces token usage 30-50% |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üîß &lt;strong&gt;Operations&lt;/strong&gt; ‚Äî Background services and integrations&lt;/summary&gt;

Background daemons handle security audits, performance optimization, and session persistence automatically while you work.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Background | Daemon, 12 Workers | Auto-runs audits, optimization, learning |
| Security | AIDefence, Validation | Blocks injection, detects threats |
| Sessions | Persist, Restore, Export | Saves context across conversations |
| GitHub | PR, Issues, Workflows | Manages repos and code reviews |
| Analytics | Metrics, Benchmarks | Monitors performance, finds bottlenecks |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üéØ &lt;strong&gt;Task Routing&lt;/strong&gt; ‚Äî Extend your Claude Code subscription by 250%&lt;/summary&gt;

Smart routing skips expensive LLM calls when possible. Simple edits use WASM (free), medium tasks use cheaper models. This can extend your Claude Code usage by 250% or save significantly on direct API costs.

| Complexity | Handler | Speed |
|------------|---------|-------|
| Simple | Agent Booster (WASM) | &lt;1ms |
| Medium | Haiku/Sonnet | ~500ms |
| Complex | Opus + Swarm | 2-5s |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;‚ö° &lt;strong&gt;Agent Booster (WASM)&lt;/strong&gt; ‚Äî Skip LLM for simple code transforms&lt;/summary&gt;

Agent Booster uses WebAssembly to handle simple code transformations without calling the LLM at all. When the hooks system detects a simple task, it routes directly to Agent Booster for instant results.

**Supported Transform Intents:**

| Intent | What It Does | Example |
|--------|--------------|---------|
| `var-to-const` | Convert var/let to const | `var x = 1` ‚Üí `const x = 1` |
| `add-types` | Add TypeScript type annotations | `function foo(x)` ‚Üí `function foo(x: string)` |
| `add-error-handling` | Wrap in try/catch | Adds proper error handling |
| `async-await` | Convert promises to async/await | `.then()` chains ‚Üí `await` |
| `add-logging` | Add console.log statements | Adds debug logging |
| `remove-console` | Strip console.* calls | Removes all console statements |

**Hook Signals:**

When you see these in hook output, the system is telling you how to optimize:

```bash
# Agent Booster available - skip LLM entirely
[AGENT_BOOSTER_AVAILABLE] Intent: var-to-const
‚Üí Use Edit tool directly, 352x faster than LLM

# Model recommendation for Task tool
[TASK_MODEL_RECOMMENDATION] Use model=&quot;haiku&quot;
‚Üí Pass model=&quot;haiku&quot; to Task tool for cost savings
```

**Performance:**

| Metric | Agent Booster | LLM Call |
|--------|---------------|----------|
| Latency | &lt;1ms | 2-5s |
| Cost | $0 | $0.0002-$0.015 |
| Speedup | **352x faster** | baseline |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üí∞ &lt;strong&gt;Token Optimizer&lt;/strong&gt; ‚Äî 30-50% token reduction&lt;/summary&gt;

The Token Optimizer integrates agentic-flow optimizations to reduce API costs by compressing context and caching results.

**Savings Breakdown:**

| Optimization | Token Savings | How It Works |
|--------------|---------------|--------------|
| ReasoningBank retrieval | -32% | Fetches relevant patterns instead of full context |
| Agent Booster edits | -15% | Simple edits skip LLM entirely |
| Cache (95% hit rate) | -10% | Reuses embeddings and patterns |
| Optimal batch size | -20% | Groups related operations |
| **Combined** | **30-50%** | Stacks multiplicatively |

**Usage:**

```typescript
import { getTokenOptimizer } from &#039;@claude-flow/integration&#039;;
const optimizer = await getTokenOptimizer();

// Get compact context (32% fewer tokens)
const ctx = await optimizer.getCompactContext(&quot;auth patterns&quot;);

// Optimized edit (352x faster for simple transforms)
await optimizer.optimizedEdit(file, oldStr, newStr, &quot;typescript&quot;);

// Optimal config for swarm (100% success rate)
const config = optimizer.getOptimalConfig(agentCount);
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üõ°Ô∏è &lt;strong&gt;Anti-Drift Swarm Configuration&lt;/strong&gt; ‚Äî Prevent goal drift in multi-agent work&lt;/summary&gt;

Complex swarms can drift from their original goals. Ruflo V3 includes anti-drift defaults that prevent agents from going off-task.

**Recommended Configuration:**

```javascript
// Anti-drift defaults (ALWAYS use for coding tasks)
swarm_init({
  topology: &quot;hierarchical&quot;,  // Single coordinator enforces alignment
  maxAgents: 8,              // Smaller team = less drift surface
  strategy: &quot;specialized&quot;    // Clear roles reduce ambiguity
})
```

**Why This Prevents Drift:**

| Setting | Anti-Drift Benefit |
|---------|-------------------|
| `hierarchical` | Coordinator validates each output against goal, catches divergence early |
| `maxAgents: 6-8` | Fewer agents = less coordination overhead, easier alignment |
| `specialized` | Clear boundaries - each agent knows exactly what to do, no overlap |
| `raft` consensus | Leader maintains authoritative state, no conflicting decisions |

**Additional Anti-Drift Measures:**

- Frequent checkpoints via `post-task` hooks
- Shared memory namespace for all agents
- Short task cycles with verification gates
- Hierarchical coordinator reviews all outputs

**Task ‚Üí Agent Routing (Anti-Drift):**

| Code | Task Type | Recommended Agents |
|------|-----------|-------------------|
| 1 | Bug Fix | coordinator, researcher, coder, tester |
| 3 | Feature | coordinator, architect, coder, tester, reviewer |
| 5 | Refactor | coordinator, architect, coder, reviewer |
| 7 | Performance | coordinator, perf-engineer, coder |
| 9 | Security | coordinator, security-architect, auditor |
| 11 | Memory | coordinator, memory-specialist, perf-engineer |

&lt;/details&gt;

### Claude Code: With vs Without Ruflo

| Capability | Claude Code Alone | Claude Code + Ruflo |
|------------|-------------------|---------------------------|
| **Agent Collaboration** | Agents work in isolation, no shared context | Agents collaborate via swarms with shared memory and consensus |
| **Coordination** | Manual orchestration between tasks | Queen-led hierarchy with 5 consensus algorithms (Raft, Byzantine, Gossip) |
| **Hive Mind** | ‚õî Not available | üêù Queen-led swarms with collective intelligence, 3 queen types, 8 worker types |
| **Consensus** | ‚õî No multi-agent decisions | Byzantine fault-tolerant voting (f &lt; n/3), weighted, majority |
| **Memory** | Session-only, no persistence | HNSW vector memory with sub-ms retrieval + knowledge graph |
| **Vector Database** | ‚õî No native support | üêò RuVector PostgreSQL with 77+ SQL functions, ~61¬µs search, 16,400 QPS |
| **Knowledge Graph** | ‚õî Flat insight lists | PageRank + community detection identifies influential insights (ADR-049) |
| **Collective Memory** | ‚õî No shared knowledge | Shared knowledge base with LRU cache, SQLite persistence, 8 memory types |
| **Learning** | Static behavior, no adaptation | SONA self-learning with &lt;0.05ms adaptation, LearningBridge for insights |
| **Agent Scoping** | Single project scope | 3-scope agent memory (project/local/user) with cross-agent transfer |
| **Task Routing** | You decide which agent to use | Intelligent routing based on learned patterns (89% accuracy) |
| **Complex Tasks** | Manual breakdown required | Automatic decomposition across 5 domains (Security, Core, Integration, Support) |
| **Background Workers** | Nothing runs automatically | 12 context-triggered workers auto-dispatch on file changes, patterns, sessions |
| **LLM Provider** | Anthropic only | 6 providers with automatic failover and cost-based routing (85% savings) |
| **Security** | Standard protections | CVE-hardened with bcrypt, input validation, path traversal prevention |
| **Performance** | Baseline | Faster tasks via parallel swarm spawning and intelligent routing |

## Quick Start

### Prerequisites

- **Node.js 20+** (required)
- **npm 9+** / **pnpm** / **bun** package manager

**IMPORTANT**: Claude Code must be installed first:

```bash
# 1. Install C

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[abhigyanpatwari/GitNexus]]></title>
            <link>https://github.com/abhigyanpatwari/GitNexus</link>
            <guid>https://github.com/abhigyanpatwari/GitNexus</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:31 GMT</pubDate>
            <description><![CDATA[GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/abhigyanpatwari/GitNexus">abhigyanpatwari/GitNexus</a></h1>
            <p>GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,177</p>
            <p>Forks: 553</p>
            <p>Stars today: 1,385 stars today</p>
            <h2>README</h2><pre># GitNexus

&lt;a href=&quot;https://trendshift.io/repositories/19809&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/19809&quot; alt=&quot;abhigyanpatwari%2FGitNexus | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

**Building git for agent context.**

Indexes any codebase into a knowledge graph ‚Äî every dependency, call chain, cluster, and execution flow ‚Äî then exposes it through smart tools so AI agents never miss code.

[![npm version](https://img.shields.io/npm/v/gitnexus.svg)](https://www.npmjs.com/package/gitnexus)
[![License: PolyForm Noncommercial](https://img.shields.io/badge/License-PolyForm%20Noncommercial-blue.svg)](https://polyformproject.org/licenses/noncommercial/1.0.0/)



https://github.com/user-attachments/assets/172685ba-8e54-4ea7-9ad1-e31a3398da72



&gt; *Like DeepWiki, but deeper.* DeepWiki helps you *understand* code. GitNexus lets you *analyze* it ‚Äî because a knowledge graph tracks every relationship, not just descriptions.

**TL;DR:** The **Web UI** is a quick way to chat with any repo. The **CLI + MCP** is how you make your AI agent actually reliable ‚Äî it gives Cursor, Claude Code, and friends a deep architectural view of your codebase so they stop missing dependencies, breaking call chains, and shipping blind edits. Even smaller models get full architectural clarity, making it compete with goliath models.

---

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=abhigyanpatwari/GitNexus&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#abhigyanpatwari/GitNexus&amp;type=date&amp;legend=top-left)


## Two Ways to Use GitNexus

|                   | **CLI + MCP**                                            | **Web UI**                                             |
| ----------------- | -------------------------------------------------------------- | ------------------------------------------------------------ |
| **What**    | Index repos locally, connect AI agents via MCP                 | Visual graph explorer + AI chat in browser                   |
| **For**     | Daily development with Cursor, Claude Code, Windsurf, OpenCode | Quick exploration, demos, one-off analysis                   |
| **Scale**   | Full repos, any size                                           | Limited by browser memory (~5k files), or unlimited via backend mode |
| **Install** | `npm install -g gitnexus`                                    | No install ‚Äî[gitnexus.vercel.app](https://gitnexus.vercel.app) |
| **Storage** | KuzuDB native (fast, persistent)                               | KuzuDB WASM (in-memory, per session)                         |
| **Parsing** | Tree-sitter native bindings                                    | Tree-sitter WASM                                             |
| **Privacy** | Everything local, no network                                   | Everything in-browser, no server                             |

&gt; **Bridge mode:** `gitnexus serve` connects the two ‚Äî the web UI auto-detects the local server and can browse all your CLI-indexed repos without re-uploading or re-indexing.

---

## CLI + MCP (recommended)

The CLI indexes your repository and runs an MCP server that gives AI agents deep codebase awareness.

### Quick Start

```bash
# Index your repo (run from repo root)
npx gitnexus analyze
```

That&#039;s it. This indexes the codebase, installs agent skills, registers Claude Code hooks, and creates `AGENTS.md` / `CLAUDE.md` context files ‚Äî all in one command.

To configure MCP for your editor, run `npx gitnexus setup` once ‚Äî or set it up manually below.

### MCP Setup

`gitnexus setup` auto-detects your editors and writes the correct global MCP config. You only need to run it once.

### Editor Support

| Editor                | MCP | Skills | Hooks (auto-augment) | Support        |
| --------------------- | --- | ------ | -------------------- | -------------- |
| **Claude Code** | Yes | Yes    | Yes (PreToolUse)     | **Full** |
| **Cursor**      | Yes | Yes    | ‚Äî                   | MCP + Skills   |
| **Windsurf**    | Yes | ‚Äî     | ‚Äî                   | MCP            |
| **OpenCode**    | Yes | Yes    | ‚Äî                   | MCP + Skills   |

&gt; **Claude Code** gets the deepest integration: MCP tools + agent skills + PreToolUse hooks that automatically enrich grep/glob/bash calls with knowledge graph context.

### Community Integrations

| Agent | Install | Source |
|-------|---------|--------|
| [pi](https://pi.dev) | `pi install npm:pi-gitnexus` | [pi-gitnexus](https://github.com/tintinweb/pi-gitnexus) |

If you prefer manual configuration:

**Claude Code** (full support ‚Äî MCP + skills + hooks):

```bash
claude mcp add gitnexus -- npx -y gitnexus@latest mcp
```

**Cursor** (`~/.cursor/mcp.json` ‚Äî global, works for all projects):

```json
{
  &quot;mcpServers&quot;: {
    &quot;gitnexus&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;gitnexus@latest&quot;, &quot;mcp&quot;]
    }
  }
}
```

**OpenCode** (`~/.config/opencode/config.json`):

```json
{
  &quot;mcp&quot;: {
    &quot;gitnexus&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;gitnexus@latest&quot;, &quot;mcp&quot;]
    }
  }
}
```

### CLI Commands

```bash
gitnexus setup                    # Configure MCP for your editors (one-time)
gitnexus analyze [path]           # Index a repository (or update stale index)
gitnexus analyze --force          # Force full re-index
gitnexus analyze --skip-embeddings  # Skip embedding generation (faster)
gitnexus mcp                     # Start MCP server (stdio) ‚Äî serves all indexed repos
gitnexus serve                   # Start local HTTP server (multi-repo) for web UI connection
gitnexus list                    # List all indexed repositories
gitnexus status                  # Show index status for current repo
gitnexus clean                   # Delete index for current repo
gitnexus clean --all --force     # Delete all indexes
gitnexus wiki [path]             # Generate repository wiki from knowledge graph
gitnexus wiki --model &lt;model&gt;    # Wiki with custom LLM model (default: gpt-4o-mini)
gitnexus wiki --base-url &lt;url&gt;   # Wiki with custom LLM API base URL
```

### What Your AI Agent Gets

**7 tools** exposed via MCP:

| Tool               | What It Does                                                      | `repo` Param |
| ------------------ | ----------------------------------------------------------------- | -------------- |
| `list_repos`     | Discover all indexed repositories                                 | ‚Äî             |
| `query`          | Process-grouped hybrid search (BM25 + semantic + RRF)             | Optional       |
| `context`        | 360-degree symbol view ‚Äî categorized refs, process participation | Optional       |
| `impact`         | Blast radius analysis with depth grouping and confidence          | Optional       |
| `detect_changes` | Git-diff impact ‚Äî maps changed lines to affected processes       | Optional       |
| `rename`         | Multi-file coordinated rename with graph + text search            | Optional       |
| `cypher`         | Raw Cypher graph queries                                          | Optional       |

&gt; When only one repo is indexed, the `repo` parameter is optional. With multiple repos, specify which one: `query({query: &quot;auth&quot;, repo: &quot;my-app&quot;})`.

**Resources** for instant context:

| Resource                                  | Purpose                                              |
| ----------------------------------------- | ---------------------------------------------------- |
| `gitnexus://repos`                      | List all indexed repositories (read this first)      |
| `gitnexus://repo/{name}/context`        | Codebase stats, staleness check, and available tools |
| `gitnexus://repo/{name}/clusters`       | All functional clusters with cohesion scores         |
| `gitnexus://repo/{name}/cluster/{name}` | Cluster members and details                          |
| `gitnexus://repo/{name}/processes`      | All execution flows                                  |
| `gitnexus://repo/{name}/process/{name}` | Full process trace with steps                        |
| `gitnexus://repo/{name}/schema`         | Graph schema for Cypher queries                      |

**2 MCP prompts** for guided workflows:

| Prompt            | What It Does                                                              |
| ----------------- | ------------------------------------------------------------------------- |
| `detect_impact` | Pre-commit change analysis ‚Äî scope, affected processes, risk level       |
| `generate_map`  | Architecture documentation from the knowledge graph with mermaid diagrams |

**4 agent skills** installed to `.claude/skills/` automatically:

- **Exploring** ‚Äî Navigate unfamiliar code using the knowledge graph
- **Debugging** ‚Äî Trace bugs through call chains
- **Impact Analysis** ‚Äî Analyze blast radius before changes
- **Refactoring** ‚Äî Plan safe refactors using dependency mapping

---

## Multi-Repo MCP Architecture

GitNexus uses a **global registry** so one MCP server can serve multiple indexed repos. No per-project MCP config needed ‚Äî set it up once and it works everywhere.

```mermaid
flowchart TD
    subgraph CLI [CLI Commands]
        Setup[&quot;gitnexus setup&quot;]
        Analyze[&quot;gitnexus analyze&quot;]
        Clean[&quot;gitnexus clean&quot;]
        List[&quot;gitnexus list&quot;]
    end

    subgraph Registry [&quot;~/.gitnexus/&quot;]
        RegFile[&quot;registry.json&quot;]
    end

    subgraph Repos [Project Repos]
        RepoA[&quot;.gitnexus/ in repo A&quot;]
        RepoB[&quot;.gitnexus/ in repo B&quot;]
    end

    subgraph MCP [MCP Server]
        Server[&quot;server.ts&quot;]
        Backend[&quot;LocalBackend&quot;]
        Pool[&quot;Connection Pool&quot;]
        ConnA[&quot;KuzuDB conn A&quot;]
        ConnB[&quot;KuzuDB conn B&quot;]
    end

    Setup --&gt;|&quot;writes global MCP config&quot;| CursorConfig[&quot;~/.cursor/mcp.json&quot;]
    Analyze --&gt;|&quot;registers repo&quot;| RegFile
    Analyze --&gt;|&quot;stores index&quot;| RepoA
    Clean --&gt;|&quot;unregisters repo&quot;| RegFile
    List --&gt;|&quot;reads&quot;| RegFile
    Server --&gt;|&quot;reads registry&quot;| RegFile
    Server --&gt; Backend
    Backend --&gt; Pool
    Pool --&gt;|&quot;lazy open&quot;| ConnA
    Pool --&gt;|&quot;lazy open&quot;| ConnB
    ConnA --&gt;|&quot;queries&quot;| RepoA
    ConnB --&gt;|&quot;queries&quot;| RepoB
```

**How it works:** Each `gitnexus analyze` stores the index in `.gitnexus/` inside the repo (portable, gitignored) and registers a pointer in `~/.gitnexus/registry.json`. When an AI agent starts, the MCP server reads the registry and can serve any indexed repo. KuzuDB connections are opened lazily on first query and evicted after 5 minutes of inactivity (max 5 concurrent). If only one repo is indexed, the `repo` parameter is optional on all tools ‚Äî agents don&#039;t need to change anything.

---

## Web UI (browser-based)

A fully client-side graph explorer and AI chat. No server, no install ‚Äî your code never leaves the browser.

**Try it now:** [gitnexus.vercel.app](https://gitnexus.vercel.app) ‚Äî drag &amp; drop a ZIP and start exploring.

&lt;img width=&quot;2550&quot; height=&quot;1343&quot; alt=&quot;gitnexus_img&quot; src=&quot;https://github.com/user-attachments/assets/cc5d637d-e0e5-48e6-93ff-5bcfdb929285&quot; /&gt;

Or run locally:

```bash
git clone https://github.com/abhigyanpatwari/gitnexus.git
cd gitnexus/gitnexus-web
npm install
npm run dev
```

The web UI uses the same indexing pipeline as the CLI but runs entirely in WebAssembly (Tree-sitter WASM, KuzuDB WASM, in-browser embeddings). It&#039;s great for quick exploration but limited by browser memory for larger repos.

**Local Backend Mode:** Run `gitnexus serve` and open the web UI locally ‚Äî it auto-detects the server and shows all your indexed repos, with full AI chat support. No need to re-upload or re-index. The agent&#039;s tools (Cypher queries, search, code navigation) route through the backend HTTP API automatically.

---

## The Problem GitNexus Solves

Tools like **Cursor**, **Claude Code**, **Cline**, **Roo Code**, and **Windsurf** are powerful ‚Äî but they don&#039;t truly know your codebase structure.

**What happens:**

1. AI edits `UserService.validate()`
2. Doesn&#039;t know 47 functions depend on its return type
3. **Breaking changes ship**

### Traditional Graph RAG vs GitNexus

Traditional approaches give the LLM raw graph edges and hope it explores enough. GitNexus **precomputes structure at index time** ‚Äî clustering, tracing, scoring ‚Äî so tools return complete context in one call:

```mermaid
flowchart TB
    subgraph Traditional[&quot;Traditional Graph RAG&quot;]
        direction TB
        U1[&quot;User: What depends on UserService?&quot;]
        U1 --&gt; LLM1[&quot;LLM receives raw graph&quot;]
        LLM1 --&gt; Q1[&quot;Query 1: Find callers&quot;]
        Q1 --&gt; Q2[&quot;Query 2: What files?&quot;]
        Q2 --&gt; Q3[&quot;Query 3: Filter tests?&quot;]
        Q3 --&gt; Q4[&quot;Query 4: High-risk?&quot;]
        Q4 --&gt; OUT1[&quot;Answer after 4+ queries&quot;]
    end

    subgraph GN[&quot;GitNexus Smart Tools&quot;]
        direction TB
        U2[&quot;User: What depends on UserService?&quot;]
        U2 --&gt; TOOL[&quot;impact UserService upstream&quot;]
        TOOL --&gt; PRECOMP[&quot;Pre-structured response:
        8 callers, 3 clusters, all 90%+ confidence&quot;]
        PRECOMP --&gt; OUT2[&quot;Complete answer, 1 query&quot;]
    end
```

**Core innovation: Precomputed Relational Intelligence**

- **Reliability** ‚Äî LLM can&#039;t miss context, it&#039;s already in the tool response
- **Token efficiency** ‚Äî No 10-query chains to understand one function
- **Model democratization** ‚Äî Smaller LLMs work because tools do the heavy lifting

---

## How It Works

GitNexus builds a complete knowledge graph of your codebase through a multi-phase indexing pipeline:

1. **Structure** ‚Äî Walks the file tree and maps folder/file relationships
2. **Parsing** ‚Äî Extracts functions, classes, methods, and interfaces using Tree-sitter ASTs
3. **Resolution** ‚Äî Resolves imports and function calls across files with language-aware logic
4. **Clustering** ‚Äî Groups related symbols into functional communities
5. **Processes** ‚Äî Traces execution flows from entry points through call chains
6. **Search** ‚Äî Builds hybrid search indexes for fast retrieval

### Supported Languages

TypeScript, JavaScript, Python, Java, C, C++, C#, Go, Rust

---

## Tool Examples

### Impact Analysis

```
impact({target: &quot;UserService&quot;, direction: &quot;upstream&quot;, minConfidence: 0.8})

TARGET: Class UserService (src/services/user.ts)

UPSTREAM (what depends on this):
  Depth 1 (WILL BREAK):
    handleLogin [CALLS 90%] -&gt; src/api/auth.ts:45
    handleRegister [CALLS 90%] -&gt; src/api/auth.ts:78
    UserController [CALLS 85%] -&gt; src/controllers/user.ts:12
  Depth 2 (LIKELY AFFECTED):
    authRouter [IMPORTS] -&gt; src/routes/auth.ts
```

Options: `maxDepth`, `minConfidence`, `relationTypes` (`CALLS`, `IMPORTS`, `EXTENDS`, `IMPLEMENTS`), `includeTests`

### Process-Grouped Search

```
query({query: &quot;authentication middleware&quot;})

processes:
  - summary: &quot;LoginFlow&quot;
    priority: 0.042
    symbol_count: 4
    process_type: cross_community
    step_count: 7

process_symbols:
  - name: validateUser
    type: Function
    filePath: src/auth/validate.ts
    process_id: proc_login
    step_index: 2

definitions:
  - name: AuthConfig
    type: Interface
    filePath: src/types/auth.ts
```

### Context (360-degree Symbol View)

```
context({name: &quot;validateUser&quot;})

symbol:
  uid: &quot;Function:validateUser&quot;
  kind: Function
  filePath: src/auth/validate.ts
  startLine: 15

incoming:
  calls: [handleLogin, handleRegister, UserController]
  imports: [authRouter]

outgoing:
  calls: [checkPassword, createSession]

processes:
  - name: LoginFlow (step 2/7)
  - name: RegistrationFlow (step 3/5)
```

### Detect Changes (Pre-Commit)

```
detect_changes({scope: &quot;all&quot;})

summary:
  changed_count: 12
  affected_count: 3
  changed_files: 4
  risk_level: medium

changed_symbols: [validateUser, AuthService, ...]
affected_processes: [LoginFlow, RegistrationFlow, ...]
```

### Rename (Multi-File)

```
rename({symbol_name: &quot;validateUser&quot;, new_name: &quot;verifyUser&quot;, dry_run: true})

status: success
files_affected: 5
total_edits: 8
graph_edits: 6     (high confidence)
text_search_edits: 2  (review carefully)
changes: [...]
```

### Cypher Queries

```cypher
-- Find what calls auth functions with high confidence
MATCH (c:Community {heuristicLabel: &#039;Authentication&#039;})&lt;-[:CodeRelation {type: &#039;MEMBER_OF&#039;}]-(fn)
MATCH (caller)-[r:CodeRelation {type: &#039;CALLS&#039;}]-&gt;(fn)
WHERE r.confidence &gt; 0.8
RETURN caller.name, fn.name, r.confidence
ORDER BY r.confidence DESC
```

---

## Wiki Generation

Generate LLM-powered documentation from your knowledge graph:

```bash
# Requires an LLM API key (OPENAI_API_KEY, etc.)
gitnexus wiki

# Use a custom model or provider
gitnexus wiki --model gpt-4o
gitnexus wiki --base-url https://api.anthropic.com/v1

# Force full regeneration
gitnexus wiki --force
```

The wiki generator reads the indexed graph structure, groups files into modules via LLM, generates per-module documentation pages, and creates an overview page ‚Äî all with cross-references to the knowledge graph.

---

## Tech Stack

| Layer                     | CLI                                   | Web                                     |
| ------------------------- | ------------------------------------- | --------------------------------------- |
| **Runtime**         | Node.js (native)                      | Browser (WASM)                          |
| **Parsing**         | Tree-sitter native bindings           | Tree-sitter WASM                        |
| **Database**        | KuzuDB native                         | KuzuDB WASM                             |
| **Embeddings**      | HuggingFace transformers.js (GPU/CPU) | transformers.js (WebGPU/WASM)           |
| **Search**          | BM25 + semantic + RRF                 | BM25 + semantic + RRF                   |
| **Agent Interface** | MCP (stdio)                           | LangChain ReAct agent                   |
| **Visualization**   | ‚Äî                                    | Sigma.js + Graphology (WebGL)           |
| **Frontend**        | ‚Äî                                    | React 18, TypeScript, Vite, Tailwind v4 |
| **Clustering**      | Graphology                            | Graphology                              |
| **Concurrency**     | Worker threads + async                | Web Workers + Comlink                   |

---

## Roadmap

### Actively Building

- [ ] **LLM Cluster Enrichment** ‚Äî Semantic cluster names via LLM API
- [ ] **AST Decorator Detection** ‚Äî Parse @Controller, @Get, etc.
- [ ] **Incremental Indexing** ‚Äî Only re-index changed files

### Recently Completed

- [X] Wiki Generation, Multi-File Rename, Git-Diff Impact Analysis
- [X] Process-Grouped Search, 360-Degree Context, Claude Code Hooks
- [X] Multi-Repo MCP, Zero-Config Setup, 9 Language Support
- [X] Community Detection, Process Detection, Confidence Scoring
- [X] Hybrid Search, Vector Index

---

## Security &amp; Privacy

- **CLI**: Everything runs locally on your machine. No network calls. Index stored in `.gitnexus/` (gitignored). Global registry at `~/.gitnexus/` stores only paths and metadata.
- **Web**: Everything runs in your browser. No code uploaded to any server. API keys stored in localStorage only.
- Open source ‚Äî audit the code yourself.

---

## Acknowledgments

- [Tree-sitter](https://tree-sitter.github.io/) ‚Äî AST parsing
- [KuzuDB](https://kuzudb.com/) ‚Äî Embedded graph database with vector support
- [Sigma.js](https://www.sigmajs.org/) ‚Äî WebGL graph rendering
- [transformers.js](https://huggingface.co/docs/transformers.js) ‚Äî Browser ML
- [Graphology](https://graphology.github.io/) ‚Äî Graph data structures
- [MCP](https://modelcontextprotocol.io/) ‚Äî Model Context Protocol
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[moeru-ai/airi]]></title>
            <link>https://github.com/moeru-ai/airi</link>
            <guid>https://github.com/moeru-ai/airi</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:30 GMT</pubDate>
            <description><![CDATA[üíñüß∏ Self hosted, you-owned Grok Companion, a container of souls of waifu, cyber livings to bring them into our worlds, wishing to achieve Neuro-sama's altitude. Capable of realtime voice chat, Minecraft, Factorio playing. Web / macOS / Windows supported.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/moeru-ai/airi">moeru-ai/airi</a></h1>
            <p>üíñüß∏ Self hosted, you-owned Grok Companion, a container of souls of waifu, cyber livings to bring them into our worlds, wishing to achieve Neuro-sama's altitude. Capable of realtime voice chat, Minecraft, Factorio playing. Web / macOS / Windows supported.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 18,234</p>
            <p>Forks: 1,750</p>
            <p>Stars today: 199 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
  &lt;source
    width=&quot;100%&quot;
    srcset=&quot;./docs/content/public/banner-dark-1280x640.avif&quot;
    media=&quot;(prefers-color-scheme: dark)&quot;
  /&gt;
  &lt;source
    width=&quot;100%&quot;
    srcset=&quot;./docs/content/public/banner-light-1280x640.avif&quot;
    media=&quot;(prefers-color-scheme: light), (prefers-color-scheme: no-preference)&quot;
  /&gt;
  &lt;img width=&quot;250&quot; src=&quot;./docs/content/public/banner-light-1280x640.avif&quot; /&gt;
&lt;/picture&gt;

&lt;h1 align=&quot;center&quot;&gt;Project AIRI&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;Re-creating Neuro-sama, a soul container of AI waifu / virtual characters to bring them into our world.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  [&lt;a href=&quot;https://discord.gg/TgQ3Cu2F7A&quot;&gt;Join Discord Server&lt;/a&gt;] [&lt;a href=&quot;https://airi.moeru.ai&quot;&gt;Try it&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.zh-CN.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.ja-JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.ru-RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.vi.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.fr.md&quot;&gt;Fran√ßais&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.ko-KR.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;]
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://deepwiki.com/moeru-ai/airi&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/moeru-ai/airi.svg?style=flat&amp;colorA=080f12&amp;colorB=1fa669&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/TgQ3Cu2F7A&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2FTgQ3Cu2F7A%3Fwith_counts%3Dtrue&amp;query=%24.approximate_member_count&amp;suffix=%20members&amp;logo=discord&amp;logoColor=white&amp;label=%20&amp;color=7389D8&amp;labelColor=6A7EC2&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/proj_airi&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%40proj__airi-black?style=flat&amp;logo=x&amp;labelColor=%23101419&amp;color=%232d2e30&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://t.me/+7M_ZKO3zUHFlOThh&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Telegram-%235AA9E6?logo=telegram&amp;labelColor=FFFFFF&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/wechat.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/WeChat-%2307C160?logo=wechat&amp;logoColor=%2307C160&amp;labelColor=FFFFFF&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://qun.qq.com/universal-share/share?ac=1&amp;authKey=9g00d%2BZS7nORzcJugNNddJ7rCghZTIR7fhXabGwch2S%2BG%2BKGIKwlN1N2nIqkh2jg&amp;busi_data=eyJncm91cENvZGUiOiIxMDU4MTU2Njk3IiwidG9rZW4iOiJmcnkra1hWNFIxNytEcG0zcHRUdVJIaldlRDFxN0dzK080QWtvTEdOQjJkNEY2eUFta1g1clNpbkxSMS9FQWFYIiwidWluIjoiMTI2MDkwNzMzNSJ9&amp;data=b1eJrwn3GVOUh7YIxZ7l9vHQo99HPmRxKPpMKlDCmfzx8Y57IXb2EZCMaOC9rVTd2U558qpNjwUYUWlPHxVHvg&amp;svctype=4&amp;tempid=h5_group_info&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/QQ-%2312B7F5?logo=qq&amp;labelColor=FFFFFF&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.producthunt.com/products/airi?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_source=badge-airi&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=993524&amp;theme=neutral&amp;t=1752696535380&quot; alt=&quot;AIRI - A&amp;#0032;container&amp;#0032;of&amp;#0032;cyber&amp;#0032;living&amp;#0032;souls&amp;#0044;&amp;#0032;re&amp;#0045;creation&amp;#0032;of&amp;#0032;Neuro&amp;#0045;sama | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/14636&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14636&quot; alt=&quot;moeru-ai%2Fairi | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; Heavily inspired by [Neuro-sama](https://www.youtube.com/@Neurosama)

&gt; [!WARNING]
&gt; **Attention:** We **do not** have any officially minted cryptocurrency or token associated with this project. Please check the information and proceed with caution.

&gt; [!NOTE]
&gt;
&gt; We&#039;ve got a whole dedicated organization [@proj-airi](https://github.com/proj-airi) for all the sub-projects born from Project AIRI. Check it out!
&gt;
&gt; RAG, memory system, embedded database, icons, Live2D utilities, and more!

&gt; [!TIP]
&gt; We have a translation project on [Crowdin](https://crowdin.com/project/proj-airi). If you find any inaccurate translations, feel free to contribute improvements there.
&gt; &lt;a href=&quot;https://crowdin.com/project/proj-airi&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img style=&quot;width: 140px; height: 40px;&quot; src=&quot;https://badges.crowdin.net/badge/light/crowdin-on-dark.png&quot; srcset=&quot;https://badges.crowdin.net/badge/light/crowdin-on-dark.png 1x, https://badges.crowdin.net/badge/light/crowdin-on-dark@2x.png 2x&quot; alt=&quot;Crowdin | Agile localization for tech companies&quot; width=&quot;140&quot; height=&quot;40&quot; /&gt;&lt;/a&gt;

Have you dreamed about having a cyber living being (cyber waifu, digital pet) or digital companion that could play with and talk to you?

With the power of modern large language models like [ChatGPT](https://chatgpt.com) and famous [Claude](https://claude.ai), asking a virtual being to roleplay and chat with us is already easy enough for everyone. Platforms like [Character.ai (a.k.a. c.ai)](https://character.ai) and [JanitorAI](https://janitorai.com/) as well as local playgrounds like [SillyTavern](https://github.com/SillyTavern/SillyTavern) are already good-enough solutions for a chat based or visual adventure game like experience.

&gt; But, what about the abilities to play games? And see what you are coding at? Chatting while playing games, watching videos, and is capable of doing many other things.

Perhaps you know [Neuro-sama](https://www.youtube.com/@Neurosama) already. She is currently the best virtual streamer capable of playing games, chatting, and interacting with you and the participants. Some also call this kind of being &quot;digital human.&quot; **Sadly, as it&#039;s not open sourced, you cannot interact with her after her live streams go offline**.

Therefore, this project, AIRI, offers another possibility here: **let you own your digital life, cyber living, easily, anywhere, anytime**.

## DevLogs We Posted &amp; Recent Updates

- [DevLog @ 2026.01.01](https://airi.moeru.ai/docs/en/blog/DevLog-2026.01.01/) on January 1, 2026
- [DevLog @ 2025.10.20](https://airi.moeru.ai/docs/en/blog/DevLog-2025.10.20/) on October 20, 2025
- [DevLog @ 2025.08.05](https://airi.moeru.ai/docs/en/blog/DevLog-2025.08.05/) on August 5, 2025
- [DevLog @ 2025.08.01](https://airi.moeru.ai/docs/en/blog/DevLog-2025.08.01/) on August 1, 2025
- [DevLog @ 2025.07.18](https://airi.moeru.ai/docs/en/blog/DevLog-2025.07.18/) on July 18, 2025
- [DreamLog 0x1](https://airi.moeru.ai/docs/en/blog/dreamlog-0x1/) on June 16, 2025
- ...more on [documentation site](https://airi.moeru.ai/docs/en/)

## What&#039;s So Special About This Project?

Unlike the other AI driven VTuber open source projects, „Ç¢„Ç§„É™ was built with support of many Web technologies such as [WebGPU](https://www.w3.org/TR/webgpu/), [WebAudio](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API), [Web Workers](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers), [WebAssembly](https://webassembly.org/), [WebSocket](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket), etc. from the first day.

&gt; [!TIP]
&gt; Worrying about the performance drop since we are using Web related technologies?
&gt;
&gt; Don&#039;t worry, while Web browser version is meant to give an insight about how much we can push and do inside browsers, and webviews, we will never fully rely on this, the desktop version of AIRI is capable of using native [NVIDIA CUDA](https://developer.nvidia.com/cuda-toolkit) and [Apple Metal](https://developer.apple.com/metal/) by default (thanks to HuggingFace &amp; beloved [candle](https://github.com/huggingface/candle) project), without any complex dependency managements, considering the tradeoff, it was partially powered by Web technologies for graphics, layouts, animations, and the WIP plugin systems for everyone to integrate things.

This means that **„Ç¢„Ç§„É™ is capable of running on modern browsers and devices** and even on mobile devices (already done with PWA support). This brings a lot of possibilities for us (the developers) to build and extend the power of „Ç¢„Ç§„É™ VTuber to the next level, while still leaving the flexibilities for users to enable features that requires TCP connections or other non-Web technologies such as connecting to a Discord voice channel or playing Minecraft and Factorio with friends.

&gt; [!NOTE]
&gt;
&gt; We are still in the early stage of development where we are seeking out talented developers to join us and help us to make „Ç¢„Ç§„É™ a reality.
&gt;
&gt; It&#039;s ok if you are not familiar with Vue.js, TypeScript, and devtools required for this project, you can join us as an artist, designer, or even help us to launch our first live stream.
&gt;
&gt; Even if you are a big fan of React, Svelte or even Solid, we welcome you. You can open a sub-directory to add features that you want to see in „Ç¢„Ç§„É™, or would like to experiment with.
&gt;
&gt; Fields (and related projects) that we are looking for:
&gt;
&gt; - Live2D modeller
&gt; - VRM modeller
&gt; - VRChat avatar designer
&gt; - Computer Vision
&gt; - Reinforcement Learning
&gt; - Speech Recognition
&gt; - Speech Synthesis
&gt; - ONNX Runtime
&gt; - Transformers.js
&gt; - vLLM
&gt; - WebGPU
&gt; - Three.js
&gt; - WebXR ([checkout the another project](https://github.com/moeru-ai/chat) we have under the @moeru-ai organization)
&gt;
&gt; **If you are interested, why not introduce yourself here? [Would like to join part of us to build AIRI?](https://github.com/moeru-ai/airi/discussions/33)**

## Current Progress

Capable of

- [x] Brain
  - [x] Play [Minecraft](https://www.minecraft.net)
  - [x] Play [Factorio](https://www.factorio.com) (WIP, but [PoC and demo available](https://github.com/moeru-ai/airi-factorio))
  - [x] Chat in [Telegram](https://telegram.org)
  - [x] Chat in [Discord](https://discord.com)
  - [ ] Memory
    - [x] Pure in-browser database support (DuckDB WASM | `pglite`)
    - [ ] Memory Alaya (WIP)
  - [ ] Pure in-browser local (WebGPU) inference
- [x] Ears
  - [x] Audio input from browser
  - [x] Audio input from [Discord](https://discord.com)
  - [x] Client side speech recognition
  - [x] Client side talking detection
- [x] Mouth
  - [x] [ElevenLabs](https://elevenlabs.io/) voice synthesis
- [x] Body
  - [x] VRM support
    - [x] Control VRM model
  - [x] VRM model animations
    - [x] Auto blink
    - [x] Auto look at
    - [x] Idle eye movement
  - [x] Live2D support
    - [x] Control Live2D model
  - [x] Live2D model animations
    - [x] Auto blink
    - [x] Auto look at
    - [x] Idle eye movement

## Development

&gt; For detailed instructions to develop this project, follow [CONTRIBUTING.md](./.github/CONTRIBUTING.md)

&gt; [!NOTE]
&gt; By default, `pnpm dev` will start the development server for the Stage Web (browser version). If you would
&gt; like to try developing the desktop version, please make sure you read [CONTRIBUTING.md](./.github/CONTRIBUTING.md)
&gt; to setup the environment correctly.

```shell
pnpm i
pnpm dev
```

### Stage Web (Browser Version at [airi.moeru.ai](https://airi.moeru.ai))

```shell
pnpm dev
```

### Stage Tamagotchi (Desktop Version)

```shell
pnpm dev:tamagotchi
```

A Nix package for Tamagotchi is included. To run airi with Nix, first make sure to enable flakes, then run:

```shell
nix run github:moeru-ai/airi
```

### Stage Pocket (Mobile Version)

Start the development server for the capacitor web version:

```shell
pnpm dev:pocket
```

Check your IP address in the output of the command above:

```shell
  ROLLDOWN-VITE v7.3.0  ready in 1073 ms

  ‚ûú  Local:   https://localhost:5273/
  ‚ûú  Network: https://&lt;ip-will-be-here&gt;:5273/
  ‚ûú  Vue DevTools: Open https://localhost:5273/__devtools__/ as a separate window
  ‚ûú  Vue DevTools: Press Option(‚å•)+Shift(‚áß)+D in App to toggle the Vue DevTools
  ‚ûú  UnoCSS Inspector: https://localhost:5273/__unocss/
```

Open the Xcode project:

```shell
CAPACITOR_DEV_SERVER_URL=https://&lt;your-ip-address&gt;:5273 pnpm open:ios
```

Then Xcode will open and you can click the &quot;Run&quot; button to run the app on your iPhone.

If you need to connect server channel on pocket in wireless mode, you need to start tamagotchi as root:

```shell
sudo pnpm dev:tamagotchi
```

Then enable secure websocket in tamagotchi `settings/system/general`.

### Documentation Site

```shell
pnpm dev:docs
```

### Publish

Please update the version in `Cargo.toml` after running `bumpp`:

```shell
npx bumpp --no-commit --no-tag
```

## Support of LLM API Providers (powered by [xsai](https://github.com/moeru-ai/xsai))

- [x] [302.AI (sponsored)](https://share.302.ai/514k2v)
- [x] [OpenRouter](https://openrouter.ai/)
- [x] [vLLM](https://github.com/vllm-project/vllm)
- [x] [SGLang](https://github.com/sgl-project/sglang)
- [x] [Ollama](https://github.com/ollama/ollama)
- [x] [Google Gemini](https://developers.generativeai.google)
- [x] [OpenAI](https://platform.openai.com/docs/guides/gpt/chat-completions-api)
  - [ ] [Azure OpenAI API](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference) (PR welcome)
- [x] [Anthropic Claude](https://anthropic.com)
  - [ ] [AWS Claude](https://docs.anthropic.com/en/api/claude-on-amazon-bedrock) (PR welcome)
- [x] [DeepSeek](https://www.deepseek.com/)
- [x] [Qwen](https://help.aliyun.com/document_detail/2400395.html)
- [x] [xAI](https://x.ai/)
- [x] [Groq](https://wow.groq.com/)
- [x] [Mistral](https://mistral.ai/)
- [x] [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/)
- [x] [Together.ai](https://www.together.ai/)
- [x] [Fireworks.ai](https://www.together.ai/)
- [x] [Novita](https://www.novita.ai/)
- [x] [Zhipu](https://bigmodel.cn)
- [x] [SiliconFlow](https://cloud.siliconflow.cn/i/rKXmRobW)
- [x] [Stepfun](https://platform.stepfun.com/)
- [x] [Baichuan](https://platform.baichuan-ai.com)
- [x] [Minimax](https://api.minimax.chat/)
- [x] [Moonshot AI](https://platform.moonshot.cn/)
- [x] [ModelScope](https://modelscope.cn/docs/model-service/API-Inference/intro)
- [x] [Player2](https://player2.game/)
- [x] [Tencent Cloud](https://cloud.tencent.com/document/product/1729)
- [ ] [Sparks](https://www.xfyun.cn/doc/spark/Web.html) (PR welcome)
- [ ] [Volcano Engine](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;ac=DSASUQY5&amp;rc=2QXCA1VI) (PR welcome)

## Sub-projects Born from This Project

- [Awesome AI VTuber](https://github.com/proj-airi/awesome-ai-vtuber): A curated list of AI VTubers and related projects
- [`unspeech`](https://github.com/moeru-ai/unspeech): Universal endpoint proxy server for `/audio/transcriptions` and `/audio/speech`, like LiteLLM but for any ASR and TTS
- [`hfup`](https://github.com/moeru-ai/hfup): tools to help on deploying, bundling to HuggingFace Spaces
- [`xsai-transformers`](https://github.com/moeru-ai/xsai-transformers): Experimental [ü§ó Transformers.js](https://github.com/huggingface/transformers.js) provider for [xsAI](https://github.com/moeru-ai/xsai).
- [WebAI: Realtime Voice Chat](https://github.com/proj-airi/webai-realtime-voice-chat): Full example of implementing ChatGPT&#039;s realtime voice from scratch with VAD + STT + LLM + TTS.
- [`@proj-airi/drizzle-duckdb-wasm`](https://github.com/moeru-ai/airi/tree/main/packages/drizzle-duckdb-wasm/README.md): Drizzle ORM driver for DuckDB WASM
- [`@proj-airi/duckdb-wasm`](https://github.com/moeru-ai/airi/tree/main/packages/duckdb-wasm/README.md): Easy to use wrapper for `@duckdb/duckdb-wasm`
- [`tauri-plugin-mcp`](https://github.com/moeru-ai/airi/blob/main/crates/tauri-plugin-mcp/README.md): A Tauri plugin for interacting with MCP servers.
- [AIRI Factorio](https://github.com/moeru-ai/airi-factorio): Allow AIRI to play Factorio
- [Factorio RCON API](https://github.com/nekomeowww/factorio-rcon-api): RESTful API wrapper for Factorio headless server console
- [`autorio`](https://github.com/moeru-ai/airi-factorio/tree/main/packages/autorio): Factorio automation library
- [`tstl-plugin-reload-factorio-mod`](https://github.com/moeru-ai/airi-factorio/tree/main/packages/tstl-plugin-reload-factorio-mod): Reload Factorio mod when developing
- [Velin](https://github.com/luoling8192/velin): Use Vue SFC and Markdown to write easy to manage stateful prompts for LLM
- [`demodel`](https://github.com/moeru-ai/demodel): Easily boost the speed of pulling your models and datasets from various of inference runtimes.
- [`inventory`](https://github.com/moeru-ai/inventory): Centralized model catalog and default provider configurations backend service
- [MCP Launcher](https://github.com/moeru-ai/mcp-launcher): Easy to use MCP builder &amp; launcher for all possible MCP servers, just like Ollama for models!
- [ü•∫ SAD](https://github.com/moeru-ai/sad): Documentation and notes for self-host and browser running LLMs.

```mermaid
%%{ init: { &#039;flowchart&#039;: { &#039;curve&#039;: &#039;catmullRom&#039; } } }%%

flowchart TD
  Core(&quot;Core&quot;)
  Unspeech(&quot;unspeech&quot;)
  DBDriver(&quot;@proj-airi/drizzle-duckdb-wasm&quot;)
  MemoryDriver(&quot;[WIP] Memory Alaya&quot;)
  DB1(&quot;@proj-airi/duckdb-wasm&quot;)
  SVRT(&quot;@proj-airi/server-runtime&quot;)
  Memory(&quot;Memory&quot;)
  STT(&quot;STT&quot;)
  Stage(&quot;Stage&quot;)
  StageUI(&quot;@proj-airi/stage-ui&quot;)
  UI(&quot;@proj-airi/ui&quot;)

  subgraph AIRI
    DB1 --&gt; DBDriver --&gt; MemoryDriver --&gt; Memory --&gt; Core
    UI --&gt; StageUI --&gt; Stage --&gt; Core
    Core --&gt; STT
    Core --&gt; SVRT
  end

  subgraph UI_Components
    UI --&gt; StageUI
    UITransitions(&quot;@proj-airi/ui-transitions&quot;) --&gt; StageUI
    UILoadingScreens(&quot;@proj-airi/ui-loading-screens&quot;) --&gt; StageUI
    FontCJK(&quot;@proj-airi/font-cjkfonts-allseto&quot;) --&gt; StageUI
    FontXiaolai(&quot;@proj-airi/font-xiaolai&quot;) --&gt; StageUI
  end

  subgraph Apps
    Stage --&gt; StageWeb(&quot;@proj-airi/stage-web&quot;)
    Stage --&gt; StageTamagotchi(&quot;@proj-airi/stage-tamagotchi&quot;)
    Core --&gt; RealtimeAudio(&quot;@proj-airi/realtime-audio&quot;)
    Core --&gt; PromptEngineering(&quot;@proj-airi/playground-prompt-engineering&quot;)
  end

  subgraph Server_Components
    Core --&gt; ServerSDK(&quot;@proj-airi/server-sdk&quot;)
    ServerShared(&quot;@proj-airi/server-shared&quot;) --&gt; SVRT
    ServerShared --&gt; ServerSDK
  end

  STT --&gt;|Speaking| Unspeech
  SVRT --&gt;|Playing Factorio| F_AGENT
  SVRT --&gt;|Playing Minecraft| MC_AGENT

  subgraph Factorio_Agent
    F_AGENT(&quot;Factorio Agent&quot;)
    F_API(&quot;Factorio RCON API&quot;)
    factorio-server(&quot;factorio-server&quot;)
    F_MOD1(&quot;autorio&quot;)

    F_AGENT --&gt; F_API -.-&gt; factorio-server
    F_MOD1 -.-&gt; factorio-server
  end

  subgraph Minecraft_Agent
    MC_AGENT(&quot;Minecraft Agent&quot;)
    Mineflayer(&quot;Mineflayer&quot;)
    minecraft-server(&quot;minecraft-server&quot;)

    MC_AGENT --&gt; Mineflayer -.-&gt; minecraft-server
  end

  XSAI(&quot;xsAI&quot;) --&gt; Core
  XSAI --&gt; F_AGENT
  XSAI --&gt; MC_AGENT

  Core --&gt; TauriMCP(&quot;@proj-airi/tauri-plugin-mcp&quot;)
  Memory_PGVector(&quot;@proj-airi/memory-pgvector&quot;) --&gt; Memory

  style Core fill:#f9d4d4,stroke:#333,stroke-width:1px
  style AIRI fill:#fcf7f7,stroke:#333,stroke-width:1px
  style UI fill:#d4f9d4,stroke:#333,stroke-width:1px
  style Stage fill:#d4f9d4,stroke:#333,stroke-width:1px
  style UI_Components fill:#d4f9d4,stroke:#333,stroke-width:1px
  style Server_Components fill:#d4e6f9,stroke:#333,stroke-width:1px
  style Apps fill:#d4d4f9,stroke:#333,stroke-width:1px
  style Factorio_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px
  style Minecraft_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px

  style DBDriver fill:#f9f9d4,stroke:#333,stroke-width:1px
  style MemoryDriver fill:#f9f9d4,stroke:#333,stroke-width:1px
  style DB1 fill:#f9f9d4,stroke:#333,stroke-width:1px
  style Memory fill:#f9f9d4,stroke:#333,stroke-width:1px
  style Memory_PGVector fill:#f9f9d4,stroke:#333,stroke-width:1px
```

## Similar Projects

### Open sourced ones

- [kimjammer/Neuro: A recreation of Neuro-Sama originally created in 7 days.](https://github.com/kimjammer/Neuro): very well completed implementation.
- [SugarcaneDefender/z-waif](https://github.com/SugarcaneDefender/z-waif): Great at gaming, autonomous, and prompt engineering
- [semperai/amica](https://github.com/semperai/amica/): Great at VRM, WebXR
- [elizaOS/eliza](https://github.com/elizaOS/eliza): Great examples and software engineering on how to integrate agent into various of systems and APIs
- [ardha27/AI-Waifu-Vt

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lak7/devildev]]></title>
            <link>https://github.com/lak7/devildev</link>
            <guid>https://github.com/lak7/devildev</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:29 GMT</pubDate>
            <description><![CDATA[DevilDev aims to be spec driven lovable which is better and open src]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lak7/devildev">lak7/devildev</a></h1>
            <p>DevilDev aims to be spec driven lovable which is better and open src</p>
            <p>Language: TypeScript</p>
            <p>Stars: 401</p>
            <p>Forks: 52</p>
            <p>Stars today: 75 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/lak7/devildev&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;public/full-logo-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;public/full-logo-light.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;public/full-logo-light.svg&quot; alt=&quot;DevilDev logo&quot; height=&quot;125&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/version-0.4.0-blue&quot; alt=&quot;Version 0.4.0&quot; /&gt;
   &lt;img src=&quot;https://img.shields.io/badge/status-experimental-orange&quot; alt=&quot;Status: Experimental&quot; /&gt;
   &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-blue.svg&quot; alt=&quot;License: Apache 2.0&quot; /&gt;
  &lt;/a&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;Vision:&lt;/strong&gt; A spec-driven, lovable alternative that turns explicit specifications into reliable, scalable code.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;public/devildev-architecture.png&quot; alt=&quot;DevilDev Architecture Preview&quot; width=&quot;125%&quot;&gt;
&lt;/p&gt;

## Table of Contents
- [DevilDev](#devildev)
- [Why DevilDev](#why-devildev)
- [Vision &amp; Future](#vision--future)
- [Getting Started](#getting-started)
  - [Tech Stack](#tech-stack)
  - [Installation Guide](#installation-guide)
- [License](#license)

## DevilDev

DevilDev is a **spec-driven architecture workspace** that helps developers generate, inspect, and iterate on software architecture using natural-language specifications and existing repositories.

Instead of jumping straight to code, DevilDev focuses on **making architecture explicit**-breaking systems into clear phases, components, and relationships that can be reasoned about, evolved, and reviewed before implementation.


## Why DevilDev

Modern AI coding tools jump straight to code. DevilDev does the opposite.

DevilDev is built for developers who want to **think clearly about systems before writing code**. It helps you:

- **Turn vague ideas into explicit architecture** using structured, spec-driven generation
- **Understand existing codebases** by reverse-engineering architecture from repositories
- **Iterate safely** by evolving architecture in phases instead of rewriting everything
- **Create a shared mental model** that humans and AI can reason about together

DevilDev is intentionally focused on architecture today‚Äî**not code generation**‚Äîbecause clear architecture is the hardest part to fix later.

## Vision &amp; Future

DevilDev‚Äôs vision is to build **any piece of software** not just websites - using **explicit, spec-driven workflows** instead of opaque, one-shot code generation.

Today, DevilDev generates architecture and documentation from specifications. In the future, those same specifications will drive the creation of the **entire software system**, built **phase by phase** with human review at every step.

The goal is not to generate code quickly, but to generate **correct, maintainable, non-garbage software** by treating specifications as the source of truth:

**spec ‚Üí architecture ‚Üí modules ‚Üí implementation**

DevilDev is designed to work across all kinds of software:
- backend services
- distributed systems
- developer tools
- internal platforms
- libraries and infrastructure

By keeping every phase explicit and reviewable, DevilDev aims to make AI-assisted software development **trustworthy, predictable, and genuinely useful**, while remaining simple and enjoyable to work with.


## Getting Started
Use the Local Setup instructions below to configure your environment, webhooks, and required third-party keys before running the app locally.

## Tech Stack
- Next.js (App Router), React, TypeScript
- PostgreSQL + Prisma
- Clerk for auth and webhooks
- GitHub App integration
- Supabase for vector store
- LangChain for agent orchestration
- Inngest for background jobs
- Dodo Payments for subscriptions

## Installation Guide

### Prerequisites

Before you begin, ensure you have the following installed:
- **Node.js** (v18 or higher recommended)
- **npm**, **yarn**, **pnpm**, or **bun** package manager
- **PostgreSQL** database (local or cloud-hosted)
- **Git** for version control

---


### Step 1: Clone and Install Dependencies

```bash
# Clone the repository
git clone https://github.com/lak7/devildev.git
cd devildev

# Install dependencies
npm install
# or
yarn install
# or
pnpm install
# or
bun install
```

### Step 2: Set Up Public URL for Webhooks (CRITICAL)

**‚ö†Ô∏è IMPORTANT**: Webhooks are **required** for core functionality. Services need to send HTTP requests to your local server, which requires a public URL.

#### Option A: Using ngrok (Recommended)

1. Sign up for a free account at [ngrok](https://ngrok.com/)
2. Install ngrok:
   ```bash
   # macOS
   brew install ngrok
   
   # Or download from https://ngrok.com/download
   ```
3. Authenticate ngrok:
   ```bash
   ngrok config add-authtoken YOUR_AUTH_TOKEN
   ```
4. Start ngrok tunnel (in a separate terminal, keep it running):
   ```bash
   ngrok http 3000
   ```
5. Copy the HTTPS URL (e.g., `https://abc123.ngrok.io`) - you&#039;ll use this for webhook endpoints

#### Option B: Using Other Tunneling Services

- [Cloudflare Tunnel](https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/)
- [localtunnel](https://localtunnel.github.io/www/)
- [serveo](https://serveo.net/)

**Note**: The public URL will change each time you restart ngrok unless you use an ngrok static URL. Choose a static URL when possible to avoid updating webhook URLs in your service dashboards after every restart.

### Step 3: Set Up Services

#### Clerk Authentication

**‚ö†Ô∏è CRITICAL**: Clerk webhooks are required to create users in your database when they sign up. Without a working webhook, user accounts won&#039;t be created in the database.

1. Go to [Clerk Dashboard](https://dashboard.clerk.com/)
2. Create a new application (use **Development** mode)
3. Copy your **Publishable Key** and **Secret Key** (they start with `pk_test_` and `sk_test_`)
4. Set up webhook endpoint:
   - Go to **Webhooks** in Clerk Dashboard
   - Click **Add Endpoint**
   - Enter your ngrok URL: `https://your-ngrok-url.ngrok.io/api/webhook/clerk`
   - Select events: `user.created`, `user.updated`, `user.deleted`
   - Copy the **Signing Secret** to `CLERK_WEBHOOK_SECRET` in `.env.local`
   - **Important**: Update this URL whenever your ngrok URL changes

#### GitHub Webhook (Using GitHub App)

**‚ö†Ô∏è CRITICAL**: If you&#039;re using GitHub App features, webhooks are required to receive installation events.

1. Create a GitHub App: go to GitHub **Settings** ‚Üí **Developer settings** ‚Üí **GitHub Apps** ‚Üí **New GitHub App**. Use your ngrok URL for the homepage and callback (e.g., `https://your-ngrok-url.ngrok.io` and `https://your-ngrok-url.ngrok.io/api/github/callback`).
2. In your GitHub App settings, go to **Webhooks**
3. Set webhook URL: `https://your-ngrok-url.ngrok.io/api/webhook/github`
4. Set webhook secret to `GITHUB_WEBHOOK_SECRET` in `.env.local`
5. Select events: `installation`, `installation_repositories`

#### Supabase Setup

1. Create a project at [Supabase](https://supabase.com/)
2. Go to **Settings** ‚Üí **API**
3. Copy **Project URL** to `SUPABASE_URL`
4. Copy **anon/public key** to `SUPABASE_KEY`
5. Set up the vector store table (see Supabase Vector documentation)

#### Database Setup

1. Set up a PostgreSQL database:
   - **Option A**: Local PostgreSQL installation
   - **Option B**: Cloud service like [Neon](https://neon.tech/), [Supabase](https://supabase.com/), or [Railway](https://railway.app/)
2. Update `DATABASE_URL` in `.env.local` with your connection string

#### Dodo Payments Webhook

**CRITICAL**: Dodo webhooks are required to update subscription status when payments are processed.

1. In your Dodo Payments dashboard, go to **Webhooks**
2. Add webhook endpoint: `https://your-ngrok-url.ngrok.io/api/webhook/dodo`
3. Copy the webhook secret to `DODO_WEBHOOK_KEY` in `.env.local`
4. **Important**: Update this URL whenever your ngrok URL changes

#### Inngest Setup (Required)

Inngest is **required** for core functionality including architecture generation and reverse architecture generation.

1. Sign up for a free account at [Inngest](https://www.inngest.com/)
2. Create a new app in the Inngest dashboard
3. For local development, set the app URL to your ngrok URL: `https://your-ngrok-url.ngrok.io/api/inngest`
4. Copy your **Event Key** and **Signing Key** from the dashboard
5. Add them to `.env.local` as `INNGEST_EVENT_KEY` and `INNGEST_SIGNING_KEY`
6. Start Inngest Dev Server in a separate terminal:
   ```bash
   npx inngest-cli@latest dev
   ```
   This handles function execution locally. Keep this running while developing.

### Step 4: Set Up Environment Variables

Create a `.env.local` file in the root directory:

```bash
# Database Configuration (Required)
DATABASE_URL=&quot;postgresql://user:password@localhost:5432/devildev?schema=public&quot;

# Clerk Authentication (Required)
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_...
CLERK_SECRET_KEY=sk_test_...
CLERK_WEBHOOK_SECRET=whsec_...

# OpenAI API (Required)
OPENAI_API_KEY=sk-...

# Parallel API (Required)
PARALLEL_API_KEY=your_parallel_api_key

# Base URL (Required for local - use your ngrok URL)
NEXT_PUBLIC_BASE_URL=https://your-ngrok-url.ngrok.io


# Supabase Vector Store (Required for document retrieval)
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your_supabase_anon_key

# Dodo Payments (Required for subscription features)
NEXT_PUBLIC_DODO_PAYMENT_LINK=https://pay.dodopayments.com/...
DODO_WEBHOOK_KEY=your_dodo_webhook_secret
NEXT_PUBLIC_DODO_PAYMENT_CANCEL_LINK=https://your-ngrok-url.ngrok.io/cancel

# Inngest (Required - for background job processing)
INNGEST_EVENT_KEY=your_inngest_event_key
INNGEST_SIGNING_KEY=your_inngest_signing_key

# GitHub App Integration (Optional - for GitHub App migration)
GITHUB_APP_ID=your_github_app_id
GITHUB_PRIVATE_KEY=&quot;-----BEGIN RSA PRIVATE KEY-----\n...\n-----END RSA PRIVATE KEY-----&quot;
GITHUB_WEBHOOK_SECRET=your_github_webhook_secret
GITHUB_APP_SLUG=your_app_slug
GITHUB_APP_FLOW_ENABLED=false
GITHUB_APP_NEW_USERS=false


# Optional: GitHub App Logging
GITHUB_APP_LOGGING=false
```

### Step 4: Database Migration

Generate Prisma Client and run migrations:

```bash
# Generate Prisma Client
npx prisma generate

# Run database migrations
npx prisma migrate dev

# (Optional) View database in Prisma Studio
npx prisma studio
```

### Step 5: Run the Development Server

**Important**: Make sure you have these running:

1. **ngrok** (Terminal 1) - provides public URL for webhooks
2. **Inngest Dev Server** (Terminal 2) - handles background jobs
3. **Next.js dev server** (Terminal 3) - your application

```bash
# Terminal 1: Start ngrok (keep running)
ngrok http 3000

# Terminal 2: Start Inngest Dev Server (keep running)
npx inngest-cli@latest dev

# Terminal 3: Start Next.js dev server
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

---

## Contributing

We welcome contributions. See our [Contributing Guide](CONTRIBUTING.md) for details.

---

## License
This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ailyProject/aily-blockly]]></title>
            <link>https://github.com/ailyProject/aily-blockly</link>
            <guid>https://github.com/ailyProject/aily-blockly</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:28 GMT</pubDate>
            <description><![CDATA[AI IDE for hardware development, support Arduino, MicroPython, ESP32, STM32, RP2040, Nrf5x...]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ailyProject/aily-blockly">ailyProject/aily-blockly</a></h1>
            <p>AI IDE for hardware development, support Arduino, MicroPython, ESP32, STM32, RP2040, Nrf5x...</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,047</p>
            <p>Forks: 62</p>
            <p>Stars today: 158 stars today</p>
            <h2>README</h2><pre># aily blockly  

[‰∏≠Êñá](README_ZH.md) | English

## About This Software
Aily Project is a hardware development integrated environment that plans to integrate numerous AI capabilities to help hardware developers develop more smoothly.  
Aily Blockly is a blockly IDE under the aily Project. In the early stage, it provides AI-assisted programming capabilities for non-professional users. The long-term goal is to break the boundary between professional development and non-professional development, and ultimately achieve natural language programming.  

&lt;img src=&quot;./img/home.webp&quot; /&gt;

&gt; We aim to design and develop this project as industrial-grade software, but the project is currently in the alpha stage and is not recommended for mass production device firmware development. However, the current version is perfectly suitable for prototype verification and educational teaching.  

## Current Version Highlights  
1. **Engineering Project Management**
Uses npm for project management, achieving board and library management on a per-project basis. This solves many engineering deficiencies in traditional embedded development environments. For example, using Arduino IDE may result in board package, library, and current project mismatches, causing compilation failures and runtime errors. In this software, the board versions and library versions in each project are independent and do not affect each other.

2. **Library Manager**
Although we have prepared many libraries (covering almost all commonly used modules), these libraries are actually generated by AI and we have not verified them in detail. We need beta testers to verify and improve them together with us.

3. **Powerful and Compact Serial Debug Tool**
Attempts to create an all-purpose serial tool. Welcome everyone to test, provide feedback, and propose new ideas.

4. **AI Project Generation**
According to user requirements, automatically analyzes projects, recommends development boards, modules, and libraries, generates project architecture diagrams and pin connection diagrams, and creates projects for users.

5. **AI Code Generation**
According to user requirements, automatically writes programs.

6. **AI Library Conversion**
Native C/C++ libraries can be easily converted to libraries used by this software. Based on large model configuration generation, during development, if you want to use an Arduino library but don&#039;t have the corresponding blockly library, just provide the Arduino library to AI, and AI will automatically analyze and generate the corresponding blockly library. With this feature, this software can become the blockly platform with the most libraries.

7. **AI Development Board Configuration Generation (Under improvement)**
Based on large model configuration generation, when adding development boards, you no longer need to write new configurations purely by hand. Just provide the development board documentation (md format), and AI will automatically analyze and help you generate development board configuration files. (Only supports development boards with esp32, avr, renesas, rp2040, stm32 as the core, because compilers and core SDKs still need to be prepared by us in advance to the repository)

8. **Lightning Compilation Tool** (Phase 1 online, Phase 2 coming soon!)
Edge-cloud collaboration, lightning compilation. Reduces the original 1-hour compilation work to 1 minute!

## Unofficial Version Notes  
This alpha version for testing only guarantees the minimum usability, and many planned highlight features have not yet been designed and developed.
The current version is not recommended for actual work use, as many adjustments we make later may cause incompatibility between versions.

## Planned Features
¬∑ Hardware simulation  
¬∑ microPython support (mode added, but no library support yet)  

## Documentation
[User Documentation](https://aily.pro/doc)  
[Library Adaptation Documentation](https://github.com/ailyProject/aily-blockly-libraries/blob/main/%E5%BA%93%E8%A7%84%E8%8C%83.md)  
[Software Development Documentation](./develop.md)  

## Related Repositories
[Development Boards](https://github.com/ailyProject/aily-blockly-boards)  
[Block Libraries](https://github.com/ailyProject/aily-blockly-libraries)  
[Compilers](https://github.com/ailyProject/aily-blockly-compilers)  
[Related Tools](https://github.com/ailyProject/aily-project-tools)  

## Project Sponsorship
This project is sponsored by the following companies and individuals

### Corporate Sponsors
&lt;a target=&quot;_blank&quot; href=&quot;https://www.seeedstudio.com/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\seeedstudio\logo_l.webp&quot; alt=&quot;seeedstudio&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;  
&lt;a target=&quot;_blank&quot; href=&quot;https://www.seekfree.cn/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\seekfree\logo_l.webp&quot; alt=&quot;seekfree&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://www.diandeng.tech/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\diandeng\logo_l.webp&quot; alt=&quot;diandeng&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;  
&lt;a target=&quot;_blank&quot; href=&quot;https://www.openjumper.com/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\openjumper\logo.webp&quot; alt=&quot;openjumper&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://www.pdmicro.cn/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\pengde\logo.webp&quot; alt=&quot;pengde&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;  
&lt;a target=&quot;_blank&quot; href=&quot;https://www.titlab.cn/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\titlab\logo_l.webp&quot; alt=&quot;titlab&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;  
&lt;a target=&quot;_blank&quot; href=&quot;https://www.emakefun.com&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\emakefun\logo_l.webp&quot; alt=&quot;emakefun&quot; width=200 /&gt;
&lt;/a&gt;&lt;br&gt;  
&lt;a target=&quot;_blank&quot; href=&quot;http://www.keyes-robot.com/&quot; &gt;
    &lt;img src=&quot;.\public\sponsor\keyes\logo_l.webp&quot; alt=&quot;keyes&quot; width=200 /&gt;
&lt;/a&gt;  

### Individual Sponsors   
Tao Dong (Tianwei Electronics)  
Xia Qing (Mushroom Cloud Maker Space)  
Du Zhongzhong Dzz (Community Partner)  
Li Duan (Yixuehui)  
Sun Junjie (Community Partner)  

## Main Open Source Projects Used in This Project
[electron]() This project uses electron to build desktop applications  
[angular]() This project uses angular as the rendering end to build main UI logic  
[node]() This project uses npm and node for package management and executing necessary scripts  
[7z]() This project uses 7z to reduce the size of some packages (such as the huge ESP32 compiler)  
Other content can be found in [package.json](./package.json)  

## The AI features of this project reference the following projects
[Kode](https://github.com/shareAI-lab/Kode-cli)  
[copilot](https://github.com/microsoft/vscode-copilot-chat)  

## Additional Rights Statement  
1. This software is free software under the GPL license. Without authorization, the sale of this software or derivative software based on this software is prohibited.
2. Hardware works developed using this software are not restricted by the GPL, and users may decide on their own release and usage methods.
3. For derivatives based on this software, information about relevant rights holders and sponsors of this project must not be removed, and such information must appear on the software startup page.
4. The online service content attached to this project must not be removed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[vercel-labs/just-bash]]></title>
            <link>https://github.com/vercel-labs/just-bash</link>
            <guid>https://github.com/vercel-labs/just-bash</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:27 GMT</pubDate>
            <description><![CDATA[Bash for Agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vercel-labs/just-bash">vercel-labs/just-bash</a></h1>
            <p>Bash for Agents</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,451</p>
            <p>Forks: 77</p>
            <p>Stars today: 258 stars today</p>
            <h2>README</h2><pre># just-bash

A simulated bash environment with an in-memory virtual filesystem, written in TypeScript.

Designed for AI agents that need a secure, sandboxed bash environment.

Supports optional network access via `curl` with secure-by-default URL filtering.

**Note**: This is beta software. Use at your own risk and please provide feedback.

## Table of Contents

- [Security model](#security-model)
- [Installation](#installation)
- [Usage](#usage)
  - [Basic API](#basic-api)
  - [Configuration](#configuration)
  - [Custom Commands](#custom-commands)
  - [Filesystem Options](#filesystem-options)
  - [AI SDK Tool](#ai-sdk-tool)
  - [Vercel Sandbox Compatible API](#vercel-sandbox-compatible-api)
  - [CLI Binary](#cli-binary)
  - [Interactive Shell](#interactive-shell)
- [Supported Commands](#supported-commands)
- [Shell Features](#shell-features)
- [Default Layout](#default-layout)
- [Network Access](#network-access)
- [Execution Protection](#execution-protection)
- [AST Transform Plugins](#ast-transform-plugins)
- [Development](#development)

## Security model

- The shell only has access to the provided file system.
- Execution is protected against infinite loops or recursion. However, Bash is not fully robust against DOS from input. If you need to be robust against this, use process isolation at the OS level.
- Binaries or even WASM are inherently unsupported (Use [Vercel Sandbox](https://vercel.com/docs/vercel-sandbox) or a similar product if a full VM is needed).
- There is no network access by default.
- Network access can be enabled, but requests are checked against URL prefix allow-lists and HTTP-method allow-lists. See [network access](#network-access) for details

## Installation

```bash
npm install just-bash
```

## Usage

### Basic API

```typescript
import { Bash } from &quot;just-bash&quot;;

const env = new Bash();
await env.exec(&#039;echo &quot;Hello&quot; &gt; greeting.txt&#039;);
const result = await env.exec(&quot;cat greeting.txt&quot;);
console.log(result.stdout); // &quot;Hello\n&quot;
console.log(result.exitCode); // 0
console.log(result.env); // Final environment after execution
```

Each `exec()` is isolated‚Äîenv vars, functions, and cwd don&#039;t persist across calls (filesystem does).

### Configuration

```typescript
const env = new Bash({
  files: { &quot;/data/file.txt&quot;: &quot;content&quot; }, // Initial files
  env: { MY_VAR: &quot;value&quot; }, // Initial environment
  cwd: &quot;/app&quot;, // Starting directory (default: /home/user)
  executionLimits: { maxCallDepth: 50 }, // See &quot;Execution Protection&quot;
});

// Per-exec overrides
await env.exec(&quot;echo $TEMP&quot;, { env: { TEMP: &quot;value&quot; }, cwd: &quot;/tmp&quot; });
```

#### Lazy Files

File values can be functions (sync or async). The function is called on first read and the result is cached ‚Äî if the file is written to before being read, the function is never called:

```typescript
const env = new Bash({
  files: {
    &quot;/data/config.json&quot;: () =&gt; JSON.stringify({ key: &quot;value&quot; }),
    &quot;/data/remote.txt&quot;: async () =&gt; (await fetch(&quot;https://example.com&quot;)).text(),
    &quot;/data/static.txt&quot;: &quot;always loaded&quot;,
  },
});
```

This is useful for large or expensive-to-compute content that may not be needed.

### Custom Commands

Extend just-bash with your own TypeScript commands using `defineCommand`:

```typescript
import { Bash, defineCommand } from &quot;just-bash&quot;;

const hello = defineCommand(&quot;hello&quot;, async (args, ctx) =&gt; {
  const name = args[0] || &quot;world&quot;;
  return { stdout: `Hello, ${name}!\n`, stderr: &quot;&quot;, exitCode: 0 };
});

const upper = defineCommand(&quot;upper&quot;, async (args, ctx) =&gt; {
  return { stdout: ctx.stdin.toUpperCase(), stderr: &quot;&quot;, exitCode: 0 };
});

const bash = new Bash({ customCommands: [hello, upper] });

await bash.exec(&quot;hello Alice&quot;); // &quot;Hello, Alice!\n&quot;
await bash.exec(&quot;echo &#039;test&#039; | upper&quot;); // &quot;TEST\n&quot;
```

Custom commands receive the full `CommandContext` with access to `fs`, `cwd`, `env`, `stdin`, and `exec` for running subcommands.

### Filesystem Options

Four filesystem implementations are available:

**InMemoryFs** (default) - Pure in-memory filesystem, no disk access:

```typescript
import { Bash } from &quot;just-bash&quot;;
const env = new Bash(); // Uses InMemoryFs by default
```

**OverlayFs** - Copy-on-write over a real directory. Reads come from disk, writes stay in memory:

```typescript
import { Bash } from &quot;just-bash&quot;;
import { OverlayFs } from &quot;just-bash/fs/overlay-fs&quot;;

const overlay = new OverlayFs({ root: &quot;/path/to/project&quot; });
const env = new Bash({ fs: overlay, cwd: overlay.getMountPoint() });

await env.exec(&quot;cat package.json&quot;); // reads from disk
await env.exec(&#039;echo &quot;modified&quot; &gt; package.json&#039;); // stays in memory
```

**ReadWriteFs** - Direct read-write access to a real directory. Use this if you want the agent to be agle to write to your disk:

```typescript
import { Bash } from &quot;just-bash&quot;;
import { ReadWriteFs } from &quot;just-bash/fs/read-write-fs&quot;;

const rwfs = new ReadWriteFs({ root: &quot;/path/to/sandbox&quot; });
const env = new Bash({ fs: rwfs });

await env.exec(&#039;echo &quot;hello&quot; &gt; file.txt&#039;); // writes to real filesystem
```

**MountableFs** - Mount multiple filesystems at different paths. Combines read-only and read-write filesystems into a unified namespace:

```typescript
import { Bash, MountableFs, InMemoryFs } from &quot;just-bash&quot;;
import { OverlayFs } from &quot;just-bash/fs/overlay-fs&quot;;
import { ReadWriteFs } from &quot;just-bash/fs/read-write-fs&quot;;

const fs = new MountableFs({ base: new InMemoryFs() });

// Mount read-only knowledge base
fs.mount(&quot;/mnt/knowledge&quot;, new OverlayFs({ root: &quot;/path/to/knowledge&quot;, readOnly: true }));

// Mount read-write workspace
fs.mount(&quot;/home/agent&quot;, new ReadWriteFs({ root: &quot;/path/to/workspace&quot; }));

const bash = new Bash({ fs, cwd: &quot;/home/agent&quot; });

await bash.exec(&quot;ls /mnt/knowledge&quot;); // reads from knowledge base
await bash.exec(&quot;cp /mnt/knowledge/doc.txt ./&quot;); // cross-mount copy
await bash.exec(&#039;echo &quot;notes&quot; &gt; notes.txt&#039;); // writes to workspace
```

You can also configure mounts in the constructor:

```typescript
import { MountableFs, InMemoryFs } from &quot;just-bash&quot;;
import { OverlayFs } from &quot;just-bash/fs/overlay-fs&quot;;
import { ReadWriteFs } from &quot;just-bash/fs/read-write-fs&quot;;

const fs = new MountableFs({
  base: new InMemoryFs(),
  mounts: [
    { mountPoint: &quot;/data&quot;, filesystem: new OverlayFs({ root: &quot;/shared/data&quot; }) },
    { mountPoint: &quot;/workspace&quot;, filesystem: new ReadWriteFs({ root: &quot;/tmp/work&quot; }) },
  ],
});
```

### AI SDK Tool

For AI agents, use [`bash-tool`](https://github.com/vercel-labs/bash-tool) which is optimized for just-bash and provides a ready-to-use [AI SDK](https://ai-sdk.dev/) tool:

```bash
npm install bash-tool
```

```typescript
import { createBashTool } from &quot;bash-tool&quot;;
import { generateText } from &quot;ai&quot;;

const bashTool = createBashTool({
  files: { &quot;/data/users.json&quot;: &#039;[{&quot;name&quot;: &quot;Alice&quot;}, {&quot;name&quot;: &quot;Bob&quot;}]&#039; },
});

const result = await generateText({
  model: &quot;anthropic/claude-sonnet-4&quot;,
  tools: { bash: bashTool },
  prompt: &quot;Count the users in /data/users.json&quot;,
});
```

See the [bash-tool documentation](https://github.com/vercel-labs/bash-tool) for more details and examples.

### Vercel Sandbox Compatible API

Bash provides a `Sandbox` class that&#039;s API-compatible with [`@vercel/sandbox`](https://vercel.com/docs/vercel-sandbox), making it easy to swap implementations. You can start with Bash and switch to a real sandbox when you need the power of a full VM (e.g. to run node, python, or custom binaries).

```typescript
import { Sandbox } from &quot;just-bash&quot;;

// Create a sandbox instance
const sandbox = await Sandbox.create({ cwd: &quot;/app&quot; });

// Write files to the virtual filesystem
await sandbox.writeFiles({
  &quot;/app/script.sh&quot;: &#039;echo &quot;Hello World&quot;&#039;,
  &quot;/app/data.json&quot;: &#039;{&quot;key&quot;: &quot;value&quot;}&#039;,
});

// Run commands and get results
const cmd = await sandbox.runCommand(&quot;bash /app/script.sh&quot;);
const output = await cmd.stdout(); // &quot;Hello World\n&quot;
const exitCode = (await cmd.wait()).exitCode; // 0

// Read files back
const content = await sandbox.readFile(&quot;/app/data.json&quot;);

// Create directories
await sandbox.mkDir(&quot;/app/logs&quot;, { recursive: true });

// Clean up (no-op for Bash, but API-compatible)
await sandbox.stop();
```

### CLI Binary

After installing globally (`npm install -g just-bash`), use the `just-bash` command as a secure alternative to `bash` for AI agents:

```bash
# Execute inline script
just-bash -c &#039;ls -la &amp;&amp; cat package.json | head -5&#039;

# Execute with specific project root
just-bash -c &#039;grep -r &quot;TODO&quot; src/&#039; --root /path/to/project

# Pipe script from stdin
echo &#039;find . -name &quot;*.ts&quot; | wc -l&#039; | just-bash

# Execute a script file
just-bash ./scripts/deploy.sh

# Get JSON output for programmatic use
just-bash -c &#039;echo hello&#039; --json
# Output: {&quot;stdout&quot;:&quot;hello\n&quot;,&quot;stderr&quot;:&quot;&quot;,&quot;exitCode&quot;:0}
```

The CLI uses OverlayFS - reads come from the real filesystem, but all writes stay in memory and are discarded after execution. The project root is mounted at `/home/user/project`.

Options:

- `-c &lt;script&gt;` - Execute script from argument
- `--root &lt;path&gt;` - Root directory (default: current directory)
- `--cwd &lt;path&gt;` - Working directory in sandbox
- `-e, --errexit` - Exit on first error
- `--json` - Output as JSON

### Interactive Shell

```bash
pnpm shell
```

The interactive shell has full internet access enabled by default, allowing you to use `curl` to fetch data from any URL. Use `--no-network` to disable this:

```bash
pnpm shell --no-network
```

## Supported Commands

### File Operations

`cat`, `cp`, `file`, `ln`, `ls`, `mkdir`, `mv`, `readlink`, `rm`, `rmdir`, `split`, `stat`, `touch`, `tree`

### Text Processing

`awk`, `base64`, `column`, `comm`, `cut`, `diff`, `expand`, `fold`, `grep` (+ `egrep`, `fgrep`), `head`, `join`, `md5sum`, `nl`, `od`, `paste`, `printf`, `rev`, `rg`, `sed`, `sha1sum`, `sha256sum`, `sort`, `strings`, `tac`, `tail`, `tr`, `unexpand`, `uniq`, `wc`, `xargs`

### Data Processing

`jq` (JSON), `python3`/`python` (Python via Pyodide; required opt-in), `sqlite3` (SQLite), `xan` (CSV), `yq` (YAML/XML/TOML/CSV)

### Compression &amp; Archives

`gzip` (+ `gunzip`, `zcat`), `tar`

### Navigation &amp; Environment

`basename`, `cd`, `dirname`, `du`, `echo`, `env`, `export`, `find`, `hostname`, `printenv`, `pwd`, `tee`

### Shell Utilities

`alias`, `bash`, `chmod`, `clear`, `date`, `expr`, `false`, `help`, `history`, `seq`, `sh`, `sleep`, `time`, `timeout`, `true`, `unalias`, `which`, `whoami`

### Network Commands

`curl`, `html-to-markdown`

All commands support `--help` for usage information.

## Shell Features

- **Pipes**: `cmd1 | cmd2`
- **Redirections**: `&gt;`, `&gt;&gt;`, `2&gt;`, `2&gt;&amp;1`, `&lt;`
- **Command chaining**: `&amp;&amp;`, `||`, `;`
- **Variables**: `$VAR`, `${VAR}`, `${VAR:-default}`
- **Positional parameters**: `$1`, `$2`, `$@`, `$#`
- **Glob patterns**: `*`, `?`, `[...]`
- **If statements**: `if COND; then CMD; elif COND; then CMD; else CMD; fi`
- **Functions**: `function name { ... }` or `name() { ... }`
- **Local variables**: `local VAR=value`
- **Loops**: `for`, `while`, `until`
- **Symbolic links**: `ln -s target link`
- **Hard links**: `ln target link`

## Default Layout

When created without options, Bash provides a Unix-like directory structure:

- `/home/user` - Default working directory (and `$HOME`)
- `/bin` - Contains stubs for all built-in commands
- `/usr/bin` - Additional binary directory
- `/tmp` - Temporary files directory

Commands can be invoked by path (e.g., `/bin/ls`) or by name.

## Network Access

Network access (and the `curl` command) is disabled by default for security. To enable it, configure the `network` option:

```typescript
// Allow specific URLs with GET/HEAD only (safest)
const env = new Bash({
  network: {
    allowedUrlPrefixes: [
      &quot;https://api.github.com/repos/myorg/&quot;,
      &quot;https://api.example.com&quot;,
    ],
  },
});

// Allow specific URLs with additional methods
const env = new Bash({
  network: {
    allowedUrlPrefixes: [&quot;https://api.example.com&quot;],
    allowedMethods: [&quot;GET&quot;, &quot;HEAD&quot;, &quot;POST&quot;], // Default: [&quot;GET&quot;, &quot;HEAD&quot;]
  },
});

// Allow all URLs and methods (use with caution)
const env = new Bash({
  network: { dangerouslyAllowFullInternetAccess: true },
});
```

**Note:** The `curl` command only exists when network is configured. Without network configuration, `curl` returns &quot;command not found&quot;.

## Python Support

Python support via Pyodide is opt-in due to additional security surface. Enable it explicitly, but be aware of the risk:

```typescript
const env = new Bash({
  python: true,
});

// Execute Python code
await env.exec(&#039;python3 -c &quot;print(1 + 2)&quot;&#039;);

// Run Python scripts
await env.exec(&#039;python3 script.py&#039;);
```

**Note:** The `python3` and `python` commands only exist when `python: true` is configured. Python is not available in browser environments.

## SQLite Support

The `sqlite3` command uses sql.js (WASM-based SQLite) which is fully sandboxed and cannot access the real filesystem:

```typescript
const env = new Bash();

// Query in-memory database
await env.exec(&#039;sqlite3 :memory: &quot;SELECT 1 + 1&quot;&#039;);

// Query file-based database
await env.exec(&#039;sqlite3 data.db &quot;SELECT * FROM users&quot;&#039;);
```

**Note:** SQLite is not available in browser environments. Queries run in a worker thread with a configurable timeout (default: 5 seconds) to prevent runaway queries from blocking execution.

### Allow-List Security

The allow-list enforces:

- **Origin matching**: URLs must match the exact origin (scheme + host + port)
- **Path prefix**: Only paths starting with the specified prefix are allowed
- **HTTP method restrictions**: Only GET and HEAD by default (configure `allowedMethods` for more)
- **Redirect protection**: Redirects to non-allowed URLs are blocked

### Using curl

```bash
# Fetch and process data
curl -s https://api.example.com/data | grep pattern

# Download and convert HTML to Markdown
curl -s https://example.com | html-to-markdown

# POST JSON data
curl -X POST -H &quot;Content-Type: application/json&quot; \
  -d &#039;{&quot;key&quot;:&quot;value&quot;}&#039; https://api.example.com/endpoint
```

## Execution Protection

Bash protects against infinite loops and deep recursion with configurable limits:

```typescript
const env = new Bash({
  executionLimits: {
    maxCallDepth: 100, // Max function recursion depth
    maxCommandCount: 10000, // Max total commands executed
    maxLoopIterations: 10000, // Max iterations per loop
    maxAwkIterations: 10000, // Max iterations in awk programs
    maxSedIterations: 10000, // Max iterations in sed scripts
  },
});
```

All limits have sensible defaults. Error messages include hints on which limit to increase. Feel free to increase if your scripts intentionally go beyond them.

## AST Transform Plugins

Parse bash scripts into an AST, run transform plugins, and serialize back to executable bash. Useful for instrumenting scripts (e.g., capturing per-command stdout/stderr) or analyzing them (e.g., extracting command names) before execution.

```typescript
import { Bash, BashTransformPipeline, TeePlugin, CommandCollectorPlugin } from &quot;just-bash&quot;;

// Standalone pipeline ‚Äî output can be run by any shell
const pipeline = new BashTransformPipeline()
  .use(new TeePlugin({ outputDir: &quot;/tmp/logs&quot; }))
  .use(new CommandCollectorPlugin());
const result = pipeline.transform(&quot;echo hello | grep hello&quot;);
result.script;             // transformed bash string
result.metadata.commands;  // [&quot;echo&quot;, &quot;grep&quot;, &quot;tee&quot;]

// Integrated API ‚Äî exec() auto-applies transforms and returns metadata
const bash = new Bash();
bash.registerTransformPlugin(new CommandCollectorPlugin());
const execResult = await bash.exec(&quot;echo hello | grep hello&quot;);
execResult.metadata?.commands; // [&quot;echo&quot;, &quot;grep&quot;]
```

See [src/transform/README.md](src/transform/README.md) for the full API, built-in plugins, and how to write custom plugins.

## Development

```bash
pnpm test        # Run tests in watch mode
pnpm test:run    # Run tests once
pnpm typecheck   # Type check without emitting
pnpm build       # Build TypeScript
pnpm shell       # Run interactive shell
```

## AI Agent Instructions

For AI agents, we recommend using [`bash-tool`](https://github.com/vercel-labs/bash-tool) which is optimized for just-bash and provides additional guidance in its `AGENTS.md`:

```bash
cat node_modules/bash-tool/dist/AGENTS.md
```

## License

Apache-2.0
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[vercel/chat]]></title>
            <link>https://github.com/vercel/chat</link>
            <guid>https://github.com/vercel/chat</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:26 GMT</pubDate>
            <description><![CDATA[A unified TypeScript SDK for building chat bots across Slack, Microsoft Teams, Google Chat, Discord, and more.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vercel/chat">vercel/chat</a></h1>
            <p>A unified TypeScript SDK for building chat bots across Slack, Microsoft Teams, Google Chat, Discord, and more.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 910</p>
            <p>Forks: 54</p>
            <p>Stars today: 96 stars today</p>
            <h2>README</h2><pre># Chat SDK

[![npm version](https://img.shields.io/npm/v/chat)](https://www.npmjs.com/package/chat)
[![npm downloads](https://img.shields.io/npm/dm/chat)](https://www.npmjs.com/package/chat)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

A unified TypeScript SDK for building chat bots across Slack, Microsoft Teams, Google Chat, Discord, Telegram, GitHub, and Linear. Write your bot logic once, deploy everywhere.

## Installation

```bash
npm install chat
```

Install adapters for your platforms:

```bash
npm install @chat-adapter/slack @chat-adapter/teams @chat-adapter/gchat @chat-adapter/discord @chat-adapter/telegram
```

## Usage

```typescript
import { Chat } from &quot;chat&quot;;
import { createSlackAdapter } from &quot;@chat-adapter/slack&quot;;
import { createRedisState } from &quot;@chat-adapter/state-redis&quot;;

const bot = new Chat({
  userName: &quot;mybot&quot;,
  adapters: {
    slack: createSlackAdapter(),
  },
  state: createRedisState(),
});

bot.onNewMention(async (thread) =&gt; {
  await thread.subscribe();
  await thread.post(&quot;Hello! I&#039;m listening to this thread.&quot;);
});

bot.onSubscribedMessage(async (thread, message) =&gt; {
  await thread.post(`You said: ${message.text}`);
});
```

See the [Getting Started guide](https://chat-sdk.dev/docs/getting-started) for a full walkthrough.

## Supported platforms

| Platform | Package | Mentions | Reactions | Cards | Modals | Streaming | DMs |
|----------|---------|----------|-----------|-------|--------|-----------|-----|
| Slack | `@chat-adapter/slack` | Yes | Yes | Yes | Yes | Native | Yes |
| Microsoft Teams | `@chat-adapter/teams` | Yes | Read-only | Yes | No | Post+Edit | Yes |
| Google Chat | `@chat-adapter/gchat` | Yes | Yes | Yes | No | Post+Edit | Yes |
| Discord | `@chat-adapter/discord` | Yes | Yes | Yes | No | Post+Edit | Yes |
| Telegram | `@chat-adapter/telegram` | Yes | Yes | Partial | No | Post+Edit | Yes |
| GitHub | `@chat-adapter/github` | Yes | Yes | No | No | No | No |
| Linear | `@chat-adapter/linear` | Yes | Yes | No | No | No | No |

## Features

- [**Event handlers**](https://chat-sdk.dev/docs/usage) ‚Äî mentions, messages, reactions, button clicks, slash commands, modals
- [**AI streaming**](https://chat-sdk.dev/docs/streaming) ‚Äî stream LLM responses with native Slack streaming and post+edit fallback
- [**Cards**](https://chat-sdk.dev/docs/cards) ‚Äî JSX-based interactive cards (Block Kit, Adaptive Cards, Google Chat Cards)
- [**Actions**](https://chat-sdk.dev/docs/actions) ‚Äî handle button clicks and dropdown selections
- [**Modals**](https://chat-sdk.dev/docs/modals) ‚Äî form dialogs with text inputs, dropdowns, and validation
- [**Slash commands**](https://chat-sdk.dev/docs/slash-commands) ‚Äî handle `/command` invocations
- [**Emoji**](https://chat-sdk.dev/docs/emoji) ‚Äî type-safe, cross-platform emoji with custom emoji support
- [**File uploads**](https://chat-sdk.dev/docs/files) ‚Äî send and receive file attachments
- [**Direct messages**](https://chat-sdk.dev/docs/direct-messages) ‚Äî initiate DMs programmatically
- [**Ephemeral messages**](https://chat-sdk.dev/docs/ephemeral-messages) ‚Äî user-only visible messages with DM fallback

## Packages

| Package | Description |
|---------|-------------|
| `chat` | Core SDK with `Chat` class, types, JSX runtime, and utilities |
| `@chat-adapter/slack` | [Slack adapter](https://chat-sdk.dev/docs/adapters/slack) |
| `@chat-adapter/teams` | [Teams adapter](https://chat-sdk.dev/docs/adapters/teams) |
| `@chat-adapter/gchat` | [Google Chat adapter](https://chat-sdk.dev/docs/adapters/gchat) |
| `@chat-adapter/discord` | [Discord adapter](https://chat-sdk.dev/docs/adapters/discord) |
| `@chat-adapter/telegram` | [Telegram adapter](https://chat-sdk.dev/docs/adapters/telegram) |
| `@chat-adapter/github` | [GitHub adapter](https://chat-sdk.dev/docs/adapters/github) |
| `@chat-adapter/linear` | [Linear adapter](https://chat-sdk.dev/docs/adapters/linear) |
| `@chat-adapter/state-redis` | [Redis state adapter](https://chat-sdk.dev/docs/state/redis) (production) |
| `@chat-adapter/state-ioredis` | [ioredis state adapter](https://chat-sdk.dev/docs/state/ioredis) (alternative) |
| `@chat-adapter/state-memory` | [In-memory state adapter](https://chat-sdk.dev/docs/state/memory) (development) |

## AI coding agent support

If you use an AI coding agent like [Claude Code](https://docs.anthropic.com/en/docs/claude-code), you can teach it about Chat SDK:

```bash
npx skills add vercel/chat
```

## Documentation

Full documentation is available at [chat-sdk.dev/docs](https://chat-sdk.dev/docs).

## Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for development setup and the release process.

## License

MIT
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[simstudioai/sim]]></title>
            <link>https://github.com/simstudioai/sim</link>
            <guid>https://github.com/simstudioai/sim</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:25 GMT</pubDate>
            <description><![CDATA[Build, deploy, and orchestrate AI agents. Sim is the central intelligence layer for your AI workforce.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/simstudioai/sim">simstudioai/sim</a></h1>
            <p>Build, deploy, and orchestrate AI agents. Sim is the central intelligence layer for your AI workforce.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 26,739</p>
            <p>Forks: 3,369</p>
            <p>Stars today: 116 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://sim.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
    &lt;img src=&quot;apps/sim/public/logo/reverse/text/large.png&quot; alt=&quot;Sim Logo&quot; width=&quot;500&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Build and deploy AI agent workflows in minutes.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://sim.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/sim.ai-6F3DFA&quot; alt=&quot;Sim.ai&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/Hr4UWYEcTT&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;logoColor=white&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/simdotai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/simdotai?style=social&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://docs.sim.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Docs-6F3DFA.svg&quot; alt=&quot;Documentation&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://deepwiki.com/simstudioai/sim&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;&lt;/a&gt;  &lt;a href=&quot;https://cursor.com/link/prompt?text=Help%20me%20set%20up%20Sim%20locally.%20Follow%20these%20steps%3A%0A%0A1.%20First%2C%20verify%20Docker%20is%20installed%20and%20running%3A%0A%20%20%20docker%20--version%0A%20%20%20docker%20info%0A%0A2.%20Clone%20the%20repository%3A%0A%20%20%20git%20clone%20https%3A%2F%2Fgithub.com%2Fsimstudioai%2Fsim.git%0A%20%20%20cd%20sim%0A%0A3.%20Start%20the%20services%20with%20Docker%20Compose%3A%0A%20%20%20docker%20compose%20-f%20docker-compose.prod.yml%20up%20-d%0A%0A4.%20Wait%20for%20all%20containers%20to%20be%20healthy%20(this%20may%20take%201-2%20minutes)%3A%0A%20%20%20docker%20compose%20-f%20docker-compose.prod.yml%20ps%0A%0A5.%20Verify%20the%20app%20is%20accessible%20at%20http%3A%2F%2Flocalhost%3A3000%0A%0AIf%20there%20are%20any%20errors%2C%20help%20me%20troubleshoot%20them.%20Common%20issues%3A%0A-%20Port%203000%2C%203002%2C%20or%205432%20already%20in%20use%0A-%20Docker%20not%20running%0A-%20Insufficient%20memory%20(needs%2012GB%2B%20RAM)%0A%0AFor%20local%20AI%20models%20with%20Ollama%2C%20use%20this%20instead%20of%20step%203%3A%0A%20%20%20docker%20compose%20-f%20docker-compose.ollama.yml%20--profile%20setup%20up%20-d&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Set%20Up%20with-Cursor-000000?logo=cursor&amp;logoColor=white&quot; alt=&quot;Set Up with Cursor&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

### Build Workflows with Ease
Design agent workflows visually on a canvas‚Äîconnect agents, tools, and blocks, then run them instantly.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;apps/sim/public/static/workflow.gif&quot; alt=&quot;Workflow Builder Demo&quot; width=&quot;800&quot;/&gt;
&lt;/p&gt;

### Supercharge with Copilot
Leverage Copilot to generate nodes, fix errors, and iterate on flows directly from natural language.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;apps/sim/public/static/copilot.gif&quot; alt=&quot;Copilot Demo&quot; width=&quot;800&quot;/&gt;
&lt;/p&gt;

### Integrate Vector Databases
Upload documents to a vector store and let agents answer questions grounded in your specific content.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;apps/sim/public/static/knowledge.gif&quot; alt=&quot;Knowledge Uploads and Retrieval Demo&quot; width=&quot;800&quot;/&gt;
&lt;/p&gt;

## Quickstart

### Cloud-hosted: [sim.ai](https://sim.ai)

&lt;a href=&quot;https://sim.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/sim.ai-6F3DFA?logo=data:image/svg%2bxml;base64,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&amp;logoColor=white&quot; alt=&quot;Sim.ai&quot;&gt;&lt;/a&gt;

### Self-hosted: NPM Package

```bash
npx simstudio
```
‚Üí http://localhost:3000

#### Note
Docker must be installed and running on your machine.

#### Options

| Flag | Description |
|------|-------------|
| `-p, --port &lt;port&gt;` | Port to run Sim on (default `3000`) |
| `--no-pull` | Skip pulling latest Docker images |

### Self-hosted: Docker Compose

```bash
git clone https://github.com/simstudioai/sim.git &amp;&amp; cd sim
docker compose -f docker-compose.prod.yml up -d
```

Open [http://localhost:3000](http://localhost:3000)

#### Using Local Models with Ollama

Run Sim with local AI models using [Ollama](https://ollama.ai) - no external APIs required:

```bash
# Start with GPU support (automatically downloads gemma3:4b model)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# For CPU-only systems:
docker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d
```

Wait for the model to download, then visit [http://localhost:3000](http://localhost:3000). Add more models with:
```bash
docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b
```

#### Using an External Ollama Instance

If Ollama is running on your host machine, use `host.docker.internal` instead of `localhost`:

```bash
OLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d
```

On Linux, use your host&#039;s IP address or add `extra_hosts: [&quot;host.docker.internal:host-gateway&quot;]` to the compose file.

#### Using vLLM

Sim supports [vLLM](https://docs.vllm.ai/) for self-hosted models. Set `VLLM_BASE_URL` and optionally `VLLM_API_KEY` in your environment.

### Self-hosted: Dev Containers

1. Open VS Code with the [Remote - Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)
2. Open the project and click &quot;Reopen in Container&quot; when prompted
3. Run `bun run dev:full` in the terminal or use the `sim-start` alias
   - This starts both the main application and the realtime socket server

### Self-hosted: Manual Setup

**Requirements:** [Bun](https://bun.sh/), [Node.js](https://nodejs.org/) v20+, PostgreSQL 12+ with [pgvector](https://github.com/pgvector/pgvector)

1. Clone and install:

```bash
git clone https://github.com/simstudioai/sim.git
cd sim
bun install
```

2. Set up PostgreSQL with pgvector:

```bash
docker run --name simstudio-db -e POSTGRES_PASSWORD=your_password -e POSTGRES_DB=simstudio -p 5432:5432 -d pgvector/pgvector:pg17
```

Or install manually via the [pgvector guide](https://github.com/pgvector/pgvector#installation).

3. Configure environment:

```bash
cp apps/sim/.env.example apps/sim/.env
cp packages/db/.env.example packages/db/.env
# Edit both .env files to set DATABASE_URL=&quot;postgresql://postgres:your_password@localhost:5432/simstudio&quot;
```

4. Run migrations:

```bash
cd packages/db &amp;&amp; bunx drizzle-kit migrate --config=./drizzle.config.ts
```

5. Start development servers:

```bash
bun run dev:full  # Starts both Next.js app and realtime socket server
```

Or run separately: `bun run dev` (Next.js) and `cd apps/sim &amp;&amp; bun run dev:sockets` (realtime).

## Copilot API Keys

Copilot is a Sim-managed service. To use Copilot on a self-hosted instance:

- Go to https://sim.ai ‚Üí Settings ‚Üí Copilot and generate a Copilot API key
- Set `COPILOT_API_KEY` environment variable in your self-hosted apps/sim/.env file to that value

## Environment Variables

Key environment variables for self-hosted deployments. See [`.env.example`](apps/sim/.env.example) for defaults or [`env.ts`](apps/sim/lib/core/config/env.ts) for the full list.

| Variable | Required | Description |
|----------|----------|-------------|
| `DATABASE_URL` | Yes | PostgreSQL connection string with pgvector |
| `BETTER_AUTH_SECRET` | Yes | Auth secret (`openssl rand -hex 32`) |
| `BETTER_AUTH_URL` | Yes | Your app URL (e.g., `http://localhost:3000`) |
| `NEXT_PUBLIC_APP_URL` | Yes | Public app URL (same as above) |
| `ENCRYPTION_KEY` | Yes | Encrypts environment variables (`openssl rand -hex 32`) |
| `INTERNAL_API_SECRET` | Yes | Encrypts internal API routes (`openssl rand -hex 32`) |
| `API_ENCRYPTION_KEY` | Yes | Encrypts API keys (`openssl rand -hex 32`) |
| `COPILOT_API_KEY` | No | API key from sim.ai for Copilot features |

## Tech Stack

- **Framework**: [Next.js](https://nextjs.org/) (App Router)
- **Runtime**: [Bun](https://bun.sh/)
- **Database**: PostgreSQL with [Drizzle ORM](https://orm.drizzle.team)
- **Authentication**: [Better Auth](https://better-auth.com)
- **UI**: [Shadcn](https://ui.shadcn.com/), [Tailwind CSS](https://tailwindcss.com)
- **State Management**: [Zustand](https://zustand-demo.pmnd.rs/)
- **Flow Editor**: [ReactFlow](https://reactflow.dev/)
- **Docs**: [Fumadocs](https://fumadocs.vercel.app/)
- **Monorepo**: [Turborepo](https://turborepo.org/)
- **Realtime**: [Socket.io](https://socket.io/)
- **Background Jobs**: [Trigger.dev](https://trigger.dev/)
- **Remote Code Execution**: [E2B](https://www.e2b.dev/)

## Contributing

We welcome contributions! Please see our [Contributing Guide](.github/CONTRIBUTING.md) for details.

## License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

&lt;p align=&quot;center&quot;&gt;Made with ‚ù§Ô∏è by the Sim Team&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[whyour/qinglong]]></title>
            <link>https://github.com/whyour/qinglong</link>
            <guid>https://github.com/whyour/qinglong</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:24 GMT</pubDate>
            <description><![CDATA[ÊîØÊåÅ Python3„ÄÅJavaScript„ÄÅShell„ÄÅTypescript ÁöÑÂÆöÊó∂‰ªªÂä°ÁÆ°ÁêÜÂπ≥Âè∞ÔºàTimed task management platform supporting Python3, JavaScript, Shell, TypescriptÔºâ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/whyour/qinglong">whyour/qinglong</a></h1>
            <p>ÊîØÊåÅ Python3„ÄÅJavaScript„ÄÅShell„ÄÅTypescript ÁöÑÂÆöÊó∂‰ªªÂä°ÁÆ°ÁêÜÂπ≥Âè∞ÔºàTimed task management platform supporting Python3, JavaScript, Shell, TypescriptÔºâ</p>
            <p>Language: TypeScript</p>
            <p>Stars: 19,278</p>
            <p>Forks: 3,233</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img width=&quot;100&quot; src=&quot;https://user-images.githubusercontent.com/22700758/191449379-f9f56204-0e31-4a16-be5a-331f52696a73.png&quot;&gt;

&lt;h1 align=&quot;center&quot;&gt;ÈùíÈæô&lt;/h1&gt;

ÁÆÄ‰Ωì‰∏≠Êñá | [English](./README-en.md)

ÊîØÊåÅ Python3„ÄÅJavaScript„ÄÅShell„ÄÅTypescript ÁöÑÂÆöÊó∂‰ªªÂä°ÁÆ°ÁêÜÂπ≥Âè∞

Timed task management platform supporting Python3, JavaScript, Shell, Typescript

[![npm version][npm-version-image]][npm-version-url] [![docker pulls][docker-pulls-image]][docker-pulls-url] [![docker stars][docker-stars-image]][docker-stars-url] [![docker image size][docker-image-size-image]][docker-image-size-url]

[npm-version-image]: https://img.shields.io/npm/v/@whyour/qinglong?style=flat
[npm-version-url]: https://www.npmjs.com/package/@whyour/qinglong?activeTab=readme
[docker-pulls-image]: https://img.shields.io/docker/pulls/whyour/qinglong?style=flat
[docker-pulls-url]: https://hub.docker.com/r/whyour/qinglong
[docker-stars-image]: https://img.shields.io/docker/stars/whyour/qinglong?style=flat
[docker-stars-url]: https://hub.docker.com/r/whyour/qinglong
[docker-image-size-image]: https://img.shields.io/docker/image-size/whyour/qinglong?style=flat
[docker-image-size-url]: https://hub.docker.com/r/whyour/qinglong

[Demo](http://demo.qinglong.online:4433/) / [Issues](https://github.com/whyour/qinglong/issues) / [Telegram Channel](https://t.me/jiao_long) / [Buy Me a Coffee](https://www.buymeacoffee.com/qinglong)

[ÊºîÁ§∫](http://demo.qinglong.online:4433/) / [ÂèçÈ¶à](https://github.com/whyour/qinglong/issues) / [Telegram È¢ëÈÅì](https://t.me/jiao_long) / [ÊâìËµèÂºÄÂèëËÄÖ](https://user-images.githubusercontent.com/22700758/244744295-29cd0cd1-c8bb-4ea1-adf6-29bd390ad4dd.jpg)
&lt;/div&gt;

![cover](https://user-images.githubusercontent.com/22700758/244847235-8dc1ca21-e03f-4606-9458-0541fab60413.png)

## ÂäüËÉΩ

- ÊîØÊåÅÂ§öÁßçËÑöÊú¨ËØ≠Ë®ÄÔºàpython3„ÄÅjavaScript„ÄÅshell„ÄÅtypescriptÔºâ
- ÊîØÊåÅÂú®Á∫øÁÆ°ÁêÜËÑöÊú¨„ÄÅÁéØÂ¢ÉÂèòÈáè„ÄÅÈÖçÁΩÆÊñá‰ª∂
- ÊîØÊåÅÂú®Á∫øÊü•Áúã‰ªªÂä°Êó•Âøó
- ÊîØÊåÅÁßíÁ∫ß‰ªªÂä°ËÆæÁΩÆ
- ÊîØÊåÅÁ≥ªÁªüÁ∫ßÈÄöÁü•
- ÊîØÊåÅÊöóÈªëÊ®°Âºè
- ÊîØÊåÅÊâãÊú∫Á´ØÊìç‰Ωú

## ÁâàÊú¨

### docker

`latest` ÈïúÂÉèÊòØÂü∫‰∫é `alpine` ÊûÑÂª∫Ôºå`debian` ÈïúÂÉèÊòØÂü∫‰∫é `debian-slim` ÊûÑÂª∫„ÄÇÂ¶ÇÊûúÈúÄË¶Å‰ΩøÁî® `alpine` ‰∏çÊîØÊåÅÁöÑ‰æùËµñÔºåÂª∫ËÆÆ‰ΩøÁî® `debian` ÈïúÂÉè

**‚ö†Ô∏è ÈáçË¶ÅÊèêÁ§∫**: Â¶ÇÊûúÊÇ®ÈúÄË¶Å‰ª•**Èùû root Áî®Êà∑**ËøêË°å DockerÔºåËØ∑‰ΩøÁî® `debian` ÈïúÂÉè„ÄÇAlpine ÁöÑ `crond` ÈúÄË¶Å root ÊùÉÈôê„ÄÇ

```bash
docker pull whyour/qinglong:latest
docker pull whyour/qinglong:debian
```

### npm

npm ÁâàÊú¨ÊîØÊåÅ `debian/ubuntu/alpine` Á≥ªÁªüÔºåÈúÄË¶ÅËá™Ë°åÂÆâË£Ö `node/npm/python3/pip3/pnpm`

```bash
npm i @whyour/qinglong
```

## ÈÉ®ÁΩ≤

[Êü•ÁúãÊñáÊ°£](https://qinglong.online/guide/getting-started/installation-guide)

## ÂÜÖÁΩÆ API

[Êü•ÁúãÊñáÊ°£](https://qinglong.online/guide/user-guide/built-in-api)

## ÂÜÖÁΩÆÂëΩ‰ª§

[Êü•ÁúãÊñáÊ°£](https://qinglong.online/guide/user-guide/basic-explanation)

## ÂºÄÂèë

```bash
git clone https://github.com/whyour/qinglong.git
cd qinglong
cp .env.example .env
# Êé®Ëçê‰ΩøÁî® pnpm https://pnpm.io/zh/installation
npm install -g pnpm@8.3.1
pnpm install
pnpm start
```

ÊâìÂºÄ‰Ω†ÁöÑÊµèËßàÂô®ÔºåËÆøÈóÆ &lt;http://127.0.0.1:5700&gt;

## ÈìæÊé•

- [nevinee](https://gitee.com/evine)
- [crontab-ui](https://github.com/alseambusher/crontab-ui)
- [Ant Design](https://ant.design)
- [Ant Design Pro](https://pro.ant.design/)
- [Umijs](https://umijs.org)
- [darkreader](https://github.com/darkreader/darkreader)
- [admin-server](https://github.com/sunpu007/admin-server)

## ÂêçÁß∞Êù•Ê∫ê

ÈùíÈæôÔºåÂèàÂêçËãçÈæôÔºåÂú®‰∏≠ÂõΩ‰º†ÁªüÊñáÂåñ‰∏≠ÊòØÂõõË±°‰πã‰∏Ä„ÄÅ[Â§©‰πãÂõõÁÅµ](https://zh.wikipedia.org/wiki/%E5%A4%A9%E4%B9%8B%E5%9B%9B%E7%81%B5)‰πã‰∏ÄÔºåÊ†πÊçÆ‰∫îË°åÂ≠¶ËØ¥ÔºåÂÆÉÊòØ‰ª£Ë°®‰∏úÊñπÁöÑÁÅµÂÖΩÔºå‰∏∫ÈùíËâ≤ÁöÑÈæôÔºå‰∫îË°åÂ±ûÊú®Ôºå‰ª£Ë°®ÁöÑÂ≠£ËäÇÊòØÊò•Â≠£ÔºåÂÖ´Âç¶‰∏ªÈúá„ÄÇËãçÈæô‰∏éÂ∫îÈæô‰∏ÄÊ†∑ÔºåÈÉΩÊòØË∫´ÂÖ∑ÁæΩÁøº„ÄÇ„ÄäÂº†ÊûúÊòüÂÆó„ÄãÁß∞‚ÄúÂèàÊúâËæÖÁøºÔºåÊñπ‰∏∫ÁúüÈæô‚Äù„ÄÇ

„ÄäÂêéÊ±â‰π¶¬∑ÂæãÂéÜÂøó‰∏ã„ÄãËÆ∞ËΩΩÔºöÊó•Âë®‰∫éÂ§©Ôºå‰∏ÄÂØí‰∏ÄÊöëÔºåÂõõÊó∂Â§áÊàêÔºå‰∏áÁâ©ÊØïÊîπÔºåÊëÑÊèêËøÅÊ¨°ÔºåÈùíÈæôÁßªËæ∞ÔºåË∞ì‰πãÂ≤Å„ÄÇ

Âú®‰∏≠ÂõΩ[‰∫åÂçÅÂÖ´ÂÆø](https://zh.wikipedia.org/wiki/%E4%BA%8C%E5%8D%81%E5%85%AB%E5%AE%BF)‰∏≠ÔºåÈùíÈæôÊòØ‰∏úÊñπ‰∏ÉÂÆøÔºàËßí„ÄÅ‰∫¢„ÄÅÊ∞ê„ÄÅÊàø„ÄÅÂøÉ„ÄÅÂ∞æ„ÄÅÁÆïÔºâÁöÑÊÄªÁß∞„ÄÇ Âú®Êó©ÊúüÊòüÂÆø‰ø°‰ª∞‰∏≠ÔºåÁ•ÇÊòØÊúÄÂ∞äË¥µÁöÑÂ§©Á•û„ÄÇ ‰ΩÜË¢´ÈÅìÊïô‰ø°‰ª∞Âê∏Á∫≥ÂÖ•ÂÖ∂Á•ûÁ≥ªÂêéÔºåÁ•ûÊ†ºÂ§ßË∑åÔºåÈÅìÊïôÂ∞ÜÂÖ∂Áß∞‰∏∫‚ÄúÂ≠üÁ´†‚ÄùÔºåÂú®‰∏çÂêåÁöÑÈÅìÁªè‰∏≠Êúâ‚ÄúÂ∏ùÂêõ‚Äù„ÄÅ‚ÄúÂú£Â∞Ü‚Äù„ÄÅ‚ÄúÁ•ûÂ∞Ü‚ÄùÂíå‚ÄúÊçïÈ¨ºÂ∞Ü‚ÄùÁ≠âÁß∞ÂëºÔºå‰∏éÁôΩËôéÁõëÂÖµÁ•ûÂêõ‰∏ÄËµ∑ÔºåÊòØÈÅìÊïôÁöÑÊä§Âç´Â§©Á•û„ÄÇ
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[anomalyco/opencode]]></title>
            <link>https://github.com/anomalyco/opencode</link>
            <guid>https://github.com/anomalyco/opencode</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:23 GMT</pubDate>
            <description><![CDATA[The open source coding agent.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anomalyco/opencode">anomalyco/opencode</a></h1>
            <p>The open source coding agent.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 112,461</p>
            <p>Forks: 11,262</p>
            <p>Stars today: 819 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencode.ai&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;packages/console/app/src/asset/logo-ornate-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;packages/console/app/src/asset/logo-ornate-light.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;packages/console/app/src/asset/logo-ornate-light.svg&quot; alt=&quot;OpenCode logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;The open source AI coding agent.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencode.ai/discord&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;label=discord&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/opencode-ai&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/opencode-ai?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/anomalyco/opencode/actions/workflows/publish.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/anomalyco/opencode/publish.yml?style=flat-square&amp;branch=dev&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;README.md&quot;&gt;English&lt;/a&gt; |
  &lt;a href=&quot;README.zh.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; |
  &lt;a href=&quot;README.zht.md&quot;&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; |
  &lt;a href=&quot;README.ko.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; |
  &lt;a href=&quot;README.de.md&quot;&gt;Deutsch&lt;/a&gt; |
  &lt;a href=&quot;README.es.md&quot;&gt;Espa√±ol&lt;/a&gt; |
  &lt;a href=&quot;README.fr.md&quot;&gt;Fran√ßais&lt;/a&gt; |
  &lt;a href=&quot;README.it.md&quot;&gt;Italiano&lt;/a&gt; |
  &lt;a href=&quot;README.da.md&quot;&gt;Dansk&lt;/a&gt; |
  &lt;a href=&quot;README.ja.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; |
  &lt;a href=&quot;README.pl.md&quot;&gt;Polski&lt;/a&gt; |
  &lt;a href=&quot;README.ru.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; |
  &lt;a href=&quot;README.bs.md&quot;&gt;Bosanski&lt;/a&gt; |
  &lt;a href=&quot;README.ar.md&quot;&gt;ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt; |
  &lt;a href=&quot;README.no.md&quot;&gt;Norsk&lt;/a&gt; |
  &lt;a href=&quot;README.br.md&quot;&gt;Portugu√™s (Brasil)&lt;/a&gt; |
  &lt;a href=&quot;README.th.md&quot;&gt;‡πÑ‡∏ó‡∏¢&lt;/a&gt; |
  &lt;a href=&quot;README.tr.md&quot;&gt;T√ºrk√ße&lt;/a&gt; |
  &lt;a href=&quot;README.uk.md&quot;&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt; |
  &lt;a href=&quot;README.bn.md&quot;&gt;‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt; |
  &lt;a href=&quot;README.gr.md&quot;&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;
&lt;/p&gt;

[![OpenCode Terminal UI](packages/web/src/assets/lander/screenshot.png)](https://opencode.ai)

---

### Installation

```bash
# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
scoop install opencode             # Windows
choco install opencode             # Windows
brew install anomalyco/tap/opencode # macOS and Linux (recommended, always up to date)
brew install opencode              # macOS and Linux (official brew formula, updated less)
sudo pacman -S opencode            # Arch Linux (Stable)
paru -S opencode-bin               # Arch Linux (Latest from AUR)
mise use -g opencode               # Any OS
nix run nixpkgs#opencode           # or github:anomalyco/opencode for latest dev branch
```

&gt; [!TIP]
&gt; Remove versions older than 0.1.x before installing.

### Desktop App (BETA)

OpenCode is also available as a desktop application. Download directly from the [releases page](https://github.com/anomalyco/opencode/releases) or [opencode.ai/download](https://opencode.ai/download).

| Platform              | Download                              |
| --------------------- | ------------------------------------- |
| macOS (Apple Silicon) | `opencode-desktop-darwin-aarch64.dmg` |
| macOS (Intel)         | `opencode-desktop-darwin-x64.dmg`     |
| Windows               | `opencode-desktop-windows-x64.exe`    |
| Linux                 | `.deb`, `.rpm`, or AppImage           |

```bash
# macOS (Homebrew)
brew install --cask opencode-desktop
# Windows (Scoop)
scoop bucket add extras; scoop install extras/opencode-desktop
```

#### Installation Directory

The install script respects the following priority order for the installation path:

1. `$OPENCODE_INSTALL_DIR` - Custom installation directory
2. `$XDG_BIN_DIR` - XDG Base Directory Specification compliant path
3. `$HOME/bin` - Standard user binary directory (if it exists or can be created)
4. `$HOME/.opencode/bin` - Default fallback

```bash
# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
```

### Agents

OpenCode includes two built-in agents you can switch between with the `Tab` key.

- **build** - Default, full-access agent for development work
- **plan** - Read-only agent for analysis and code exploration
  - Denies file edits by default
  - Asks permission before running bash commands
  - Ideal for exploring unfamiliar codebases or planning changes

Also included is a **general** subagent for complex searches and multistep tasks.
This is used internally and can be invoked using `@general` in messages.

Learn more about [agents](https://opencode.ai/docs/agents).

### Documentation

For more info on how to configure OpenCode, [**head over to our docs**](https://opencode.ai/docs).

### Contributing

If you&#039;re interested in contributing to OpenCode, please read our [contributing docs](./CONTRIBUTING.md) before submitting a pull request.

### Building on OpenCode

If you are working on a project that&#039;s related to OpenCode and is using &quot;opencode&quot; as part of its name, for example &quot;opencode-dashboard&quot; or &quot;opencode-mobile&quot;, please add a note to your README to clarify that it is not built by the OpenCode team and is not affiliated with us in any way.

### FAQ

#### How is this different from Claude Code?

It&#039;s very similar to Claude Code in terms of capability. Here are the key differences:

- 100% open source
- Not coupled to any provider. Although we recommend the models we provide through [OpenCode Zen](https://opencode.ai/zen), OpenCode can be used with Claude, OpenAI, Google, or even local models. As models evolve, the gaps between them will close and pricing will drop, so being provider-agnostic is important.
- Out-of-the-box LSP support
- A focus on TUI. OpenCode is built by neovim users and the creators of [terminal.shop](https://terminal.shop); we are going to push the limits of what&#039;s possible in the terminal.
- A client/server architecture. This, for example, can allow OpenCode to run on your computer while you drive it remotely from a mobile app, meaning that the TUI frontend is just one of the possible clients.

---

**Join our community** [Discord](https://discord.gg/opencode) | [X.com](https://x.com/opencode)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[tldraw/tldraw]]></title>
            <link>https://github.com/tldraw/tldraw</link>
            <guid>https://github.com/tldraw/tldraw</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:22 GMT</pubDate>
            <description><![CDATA[very good whiteboard infinite canvas SDK]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tldraw/tldraw">tldraw/tldraw</a></h1>
            <p>very good whiteboard infinite canvas SDK</p>
            <p>Language: TypeScript</p>
            <p>Stars: 45,515</p>
            <p>Forks: 3,038</p>
            <p>Stars today: 54 stars today</p>
            <h2>README</h2><pre>&lt;div alt style=&quot;text-align: center; transform: scale(.25);&quot;&gt;
	&lt;picture&gt;
		&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/tldraw/tldraw/raw/main/assets/github-hero-dark.png&quot; /&gt;
		&lt;img alt=&quot;tldraw&quot; src=&quot;https://github.com/tldraw/tldraw/raw/main/assets/github-hero-light.png&quot; /&gt;
	&lt;/picture&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/tldraw&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/tldraw&quot; alt=&quot;npm&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/tldraw&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/tldraw&quot; alt=&quot;npm downloads&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.tldraw.com/?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=sociallink&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/discord-join-5865F2?logo=discord&amp;logoColor=white&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://deepwiki.com/tldraw/tldraw&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
  Build infinite canvas apps in React with the tldraw SDK.
&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://tldraw.dev/quick-start&quot;&gt;Docs&lt;/a&gt; ¬∑ &lt;a href=&quot;https://tldraw.dev/examples&quot;&gt;Examples&lt;/a&gt; ¬∑ &lt;a href=&quot;https://tldraw.dev/starter-kits/overview&quot;&gt;Starter kits&lt;/a&gt;
&lt;/p&gt;

## Feature highlights

tldraw provides a feature-complete infinite canvas engine designed to be the foundation for any canvas app. Create custom shapes, tools, bindings and UI components for a custom experience. Use the default whiteboarding tool set or use the library&#039;s primitives to build entirely new shapes and interactions.

- **Multiplayer** ‚Äî self-hostable real-time collaboration with [`@tldraw/sync`](https://tldraw.dev/docs/sync)
- **Drawing and diagramming** ‚Äî pressure-sensitive drawing, geometric shapes, rich text, arrows, snapping to shapes, edge scrolling, image and video support, image export
- **Runtime API** - drive the canvas at runtime with the Editor API
- **Fully extensible** ‚Äî custom [shapes](https://tldraw.dev/docs/shapes), [tools](https://tldraw.dev/docs/tools), [bindings](https://tldraw.dev/sdk-features/bindings), [UI components](https://tldraw.dev/sdk-features/ui-components), side effects, and event hooks
- **AI integrations** ‚Äî canvas primitives for [building with LLMs](https://tldraw.dev/docs/ai)
- **DOM canvas** ‚Äî web rendering supports anything the browser supports, including embedded websites from YouTube, Figma, GitHub, [and more](https://tldraw.dev/sdk-features/embed-shape)
- **Broad support** ‚Äî works in any browser across desktop, touch screens, tablets, and mobile devices

## Quick start

Install the tldraw package:

```bash
npm i tldraw
```

Then, use the `&lt;Tldraw /&gt;` component in your React app:

```tsx
import { Tldraw } from &#039;tldraw&#039;
import &#039;tldraw/tldraw.css&#039;

export default function App() {
	return (
		&lt;div style={{ position: &#039;fixed&#039;, inset: 0 }}&gt;
			&lt;Tldraw /&gt;
		&lt;/div&gt;
	)
}
```

## Starter kits

Starter kits provide the custom shapes, tools, and user interface needed for common applications. Each kit is MIT-licensed. Hack together a prototype, build out an app on top, or reference the code in a larger project.

Start building with:

```bash
npx create-tldraw@latest
```

- **Multiplayer** ‚Äî self-hosted real-time collaboration powered by `@tldraw/sync` and Cloudflare Durable Objects, the same stack behind [tldraw.com](https://tldraw.com)
- **Agent** ‚Äî AI agents that read, interpret, and modify canvas content
- **Workflow** ‚Äî drag-and-drop node builder for automation pipelines, visual programming, and no-code platforms
- **Chat** ‚Äî canvas-powered AI chat where users sketch, annotate, and mark up images alongside conversations
- **Branching chat** ‚Äî AI chat with visual branching, letting users explore and compare different conversation paths
- **Shader** ‚Äî WebGL shaders that respond to canvas interactions

## Local development

The development server runs the examples app at `localhost:5420`. Clone the repo, then enable [corepack](https://nodejs.org/api/corepack.html) for the correct yarn version:

```bash
npm i -g corepack
```

Install dependencies and start the dev server:

```bash
yarn
yarn dev
```

## Community

- [Discord](https://discord.tldraw.com/?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=sociallink) ‚Äî questions, feedback, and discussion
- [Twitter/X](https://twitter.com/tldraw) ‚Äî news and updates
- [Submit an issue](https://github.com/tldraw/tldraw/issues/new) ‚Äî bug reports and feature requests

## Contributing

See our [contributing guide](https://github.com/tldraw/tldraw/blob/main/CONTRIBUTING.md) to learn about contributing to tldraw.

## License

The tldraw SDK is provided under the [tldraw license](https://github.com/tldraw/tldraw/blob/main/LICENSE.md). You can use the SDK freely in development. Production use requires a [license key](https://tldraw.dev/pricing). Visit [tldraw.dev](https://tldraw.dev) to learn more.

## Trademarks

Copyright (c) 2024-present tldraw Inc. The tldraw name and logo are trademarks of tldraw.

Please see our [trademark guidelines](https://github.com/tldraw/tldraw/blob/main/TRADEMARKS.md) for info on acceptable usage.

## Contributors

&lt;a href=&quot;https://github.com/tldraw/tldraw/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=tldraw/tldraw&amp;max=400&amp;columns=20&quot; width=&quot;100%&quot;/&gt;
&lt;/a&gt;

## Star history

&lt;a href=&quot;https://star-history.com/#tldraw/tldraw&quot;&gt;
	&lt;picture&gt;
	  &lt;source
	    media=&quot;(prefers-color-scheme: dark)&quot;
	    srcset=&quot;https://api.star-history.com/svg?repos=tldraw/tldraw&amp;type=Date&amp;theme=dark&quot;
	  /&gt;
	  &lt;source
	    media=&quot;(prefers-color-scheme: light)&quot;
	    srcset=&quot;https://api.star-history.com/svg?repos=tldraw/tldraw&amp;type=Date&quot;
	  /&gt;
	  &lt;img src=&quot;https://api.star-history.com/svg?repos=tldraw/tldraw&amp;type=Date&quot; alt=&quot;Star History Chart&quot; width=&quot;100%&quot; /&gt;
	&lt;/picture&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[nocobase/nocobase]]></title>
            <link>https://github.com/nocobase/nocobase</link>
            <guid>https://github.com/nocobase/nocobase</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:21 GMT</pubDate>
            <description><![CDATA[NocoBase is the most extensible AI-powered no-code/low-code platform for building business applications and enterprise solutions.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nocobase/nocobase">nocobase/nocobase</a></h1>
            <p>NocoBase is the most extensible AI-powered no-code/low-code platform for building business applications and enterprise solutions.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,632</p>
            <p>Forks: 2,462</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>English | [‰∏≠Êñá](./README.zh-CN.md) | [Êó•Êú¨Ë™û](./README.ja-JP.md)

https://github.com/user-attachments/assets/4d11a87b-00e2-48f3-9bf7-389d21072d13

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/4112&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/4112&quot; alt=&quot;nocobase%2Fnocobase | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://www.producthunt.com/posts/nocobase?embed=true&amp;utm_source=badge-top-post-topic-badge&amp;utm_medium=badge&amp;utm_souce=badge-nocobase&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=456520&amp;theme=light&amp;period=weekly&amp;topic_id=267&quot; alt=&quot;NocoBase - Scalability&amp;#0045;first&amp;#0044;&amp;#0032;open&amp;#0045;source&amp;#0032;no&amp;#0045;code&amp;#0032;platform | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

## What is NocoBase

NocoBase is the most extensible AI-powered no-code platform.   
Total control. Infinite extensibility. AI collaboration.  
Enable your team to adapt quickly and cut costs dramatically.  
No years of development. No millions wasted.  
Deploy NocoBase in minutes ‚Äî and take control of everything.

Homepage:  
https://www.nocobase.com/  

Online Demo:  
https://demo.nocobase.com/new

Documents:  
https://docs.nocobase.com/

Forum:  
https://forum.nocobase.com/

Use Cases:  
https://www.nocobase.com/en/blog/tags/customer-stories

## Release Notes

Our [blog](https://www.nocobase.com/en/blog/timeline) is regularly updated with release notes and provides a weekly summary.

## Distinctive features

### 1. Data model-driven, not form/table‚Äìdriven

Instead of being constrained by forms or tables, NocoBase adopts a data model‚Äìdriven approach, separating data structure from user interface to unlock unlimited possibilities.

- UI and data structure are fully decoupled
- Multiple blocks and actions can be created for the same table or record in any quantity or form
- Supports the main database, external databases, and third-party APIs as data sources

![model](https://static-docs.nocobase.com/model.png)

### 2. AI employees, integrated into your business systems
Unlike standalone AI demos, NocoBase allows you to embed AI capabilities seamlessly into your interfaces, workflows, and data context, making AI truly useful in real business scenarios.

- Define AI employees for roles such as translator, analyst, researcher, or assistant
- Seamless AI‚Äìhuman collaboration in interfaces and workflows
- Ensure AI usage is secure, transparent, and customizable for your business needs

![AI-employee](https://static-docs.nocobase.com/ai-employee-home.png)

### 3. What you see is what you get, incredibly easy to use

While enabling the development of complex business systems, NocoBase keeps the experience simple and intuitive.

- One-click switch between usage mode and configuration mode
- Pages serve as a canvas to arrange blocks and actions, similar to Notion
- Configuration mode is designed for ordinary users, not just programmers

![wysiwyg](https://static-docs.nocobase.com/wysiwyg.gif)

### 4. Everything is a plugin, designed for extension
Adding more no-code features will never cover every business case. NocoBase is built for extension through its plugin-based microkernel architecture.

- All functionalities are plugins, similar to WordPress
- Plugins are ready to use upon installation
- Pages, blocks, actions, APIs, and data sources can all be extended through custom plugins

![plugins](https://static-docs.nocobase.com/plugins.png)

## Installation

NocoBase supports three installation methods:

- &lt;a target=&quot;_blank&quot; href=&quot;https://docs.nocobase.com/welcome/getting-started/installation/docker-compose&quot;&gt;Installing With Docker (üëçRecommended)&lt;/a&gt;

  Suitable for no-code scenarios, no code to write. When upgrading, just download the latest image and reboot.

- &lt;a target=&quot;_blank&quot; href=&quot;https://docs.nocobase.com/welcome/getting-started/installation/create-nocobase-app&quot;&gt;Installing from create-nocobase-app CLI&lt;/a&gt;

  The business code of the project is completely independent and supports low-code development.

- &lt;a target=&quot;_blank&quot; href=&quot;https://docs.nocobase.com/welcome/getting-started/installation/git-clone&quot;&gt;Installing from Git source code&lt;/a&gt;

  If you want to experience the latest unreleased version, or want to participate in the contribution, you need to make changes and debug on the source code, it is recommended to choose this installation method, which requires a high level of development skills, and if the code has been updated, you can git pull the latest code.

## How NocoBase works

https://github.com/user-attachments/assets/8d183b44-9bb5-4792-b08f-bc08fe8dfaaf
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[siteboon/claudecodeui]]></title>
            <link>https://github.com/siteboon/claudecodeui</link>
            <guid>https://github.com/siteboon/claudecodeui</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:20 GMT</pubDate>
            <description><![CDATA[Use Claude Code, Cursor CLI or Codex on mobile and web with CloudCLI (aka Claude Code UI). CloudCLI is a free open source webui/GUI that helps you manage your Claude Code session and projects remotely]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/siteboon/claudecodeui">siteboon/claudecodeui</a></h1>
            <p>Use Claude Code, Cursor CLI or Codex on mobile and web with CloudCLI (aka Claude Code UI). CloudCLI is a free open source webui/GUI that helps you manage your Claude Code session and projects remotely</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,300</p>
            <p>Forks: 921</p>
            <p>Stars today: 70 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;public/logo.svg&quot; alt=&quot;Claude Code UI&quot; width=&quot;64&quot; height=&quot;64&quot;&gt;
  &lt;h1&gt;Cloud CLI (aka Claude Code UI)&lt;/h1&gt;
&lt;/div&gt;


A desktop and mobile UI for [Claude Code](https://docs.anthropic.com/en/docs/claude-code), [Cursor CLI](https://docs.cursor.com/en/cli/overview) and [Codex](https://developers.openai.com/codex). You can use it locally or remotely to view your active projects and sessions in Claude Code, Cursor, or Codex and make changes to them from everywhere (mobile or desktop). This gives you a proper interface that works everywhere. 

&lt;a href=&quot;https://trendshift.io/repositories/15586&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15586&quot; alt=&quot;siteboon%2Fclaudecodeui | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;div align=&quot;right&quot;&gt;&lt;i&gt;&lt;b&gt;English&lt;/b&gt; ¬∑ &lt;a href=&quot;./README.ko.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; ¬∑ &lt;a href=&quot;./README.zh-CN.md&quot;&gt;‰∏≠Êñá&lt;/a&gt; ¬∑ &lt;a href=&quot;./README.ja.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;&lt;/i&gt;&lt;/div&gt;

## Screenshots

&lt;div align=&quot;center&quot;&gt;
  
&lt;table&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;h3&gt;Desktop View&lt;/h3&gt;
&lt;img src=&quot;public/screenshots/desktop-main.png&quot; alt=&quot;Desktop Interface&quot; width=&quot;400&quot;&gt;
&lt;br&gt;
&lt;em&gt;Main interface showing project overview and chat&lt;/em&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;h3&gt;Mobile Experience&lt;/h3&gt;
&lt;img src=&quot;public/screenshots/mobile-chat.png&quot; alt=&quot;Mobile Interface&quot; width=&quot;250&quot;&gt;
&lt;br&gt;
&lt;em&gt;Responsive mobile design with touch navigation&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot; colspan=&quot;2&quot;&gt;
&lt;h3&gt;CLI Selection&lt;/h3&gt;
&lt;img src=&quot;public/screenshots/cli-selection.png&quot; alt=&quot;CLI Selection&quot; width=&quot;400&quot;&gt;
&lt;br&gt;
&lt;em&gt;Select between Claude Code, Cursor CLI and Codex&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;



&lt;/div&gt;

## Features

- **Responsive Design** - Works seamlessly across desktop, tablet, and mobile so you can also use Claude Code, Cursor, or Codex from mobile 
- **Interactive Chat Interface** - Built-in chat interface for seamless communication with Claude Code, Cursor, or Codex
- **Integrated Shell Terminal** - Direct access to Claude Code, Cursor CLI, or Codex through built-in shell functionality
- **File Explorer** - Interactive file tree with syntax highlighting and live editing
- **Git Explorer** - View, stage and commit your changes. You can also switch branches 
- **Session Management** - Resume conversations, manage multiple sessions, and track history
- **TaskMaster AI Integration** *(Optional)* - Advanced project management with AI-powered task planning, PRD parsing, and workflow automation
- **Model Compatibility** - Works with Claude Sonnet 4.5, Opus 4.5, and GPT-5.2 


## Quick Start

### Prerequisites

- [Node.js](https://nodejs.org/) v22 or higher
- [Claude Code CLI](https://docs.anthropic.com/en/docs/claude-code) installed and configured, and/or
- [Cursor CLI](https://docs.cursor.com/en/cli/overview) installed and configured, and/or
- [Codex](https://developers.openai.com/codex) installed and configured

### One-click Operation (Recommended)

No installation required, direct operation:

```bash
npx @siteboon/claude-code-ui
```

The server will start and be accessible at `http://localhost:3001` (or your configured PORT).

**To restart**: Simply run the same `npx` command again after stopping the server
### Global Installation (For Regular Use)

For frequent use, install globally once:

```bash
npm install -g @siteboon/claude-code-ui
```

Then start with a simple command:

```bash
claude-code-ui
```


**To restart**: Stop with Ctrl+C and run `claude-code-ui` again.

**To update**:
```bash
cloudcli update
```

### CLI Usage

After global installation, you have access to both `claude-code-ui` and `cloudcli` commands:

| Command / Option | Short | Description |
|------------------|-------|-------------|
| `cloudcli` or `claude-code-ui` | | Start the server (default) |
| `cloudcli start` | | Start the server explicitly |
| `cloudcli status` | | Show configuration and data locations |
| `cloudcli update` | | Update to the latest version |
| `cloudcli help` | | Show help information |
| `cloudcli version` | | Show version information |
| `--port &lt;port&gt;` | `-p` | Set server port (default: 3001) |
| `--database-path &lt;path&gt;` | | Set custom database location |

**Examples:**
```bash
cloudcli                          # Start with defaults
cloudcli -p 8080              # Start on custom port
cloudcli status                   # Show current configuration
```

### Run as Background Service (Recommended for Production)

For production use, run Claude Code UI as a background service using PM2 (Process Manager 2):

#### Install PM2

```bash
npm install -g pm2
```

#### Start as Background Service

```bash
# Start the server in background
pm2 start claude-code-ui --name &quot;claude-code-ui&quot;

# Or using the shorter alias
pm2 start cloudcli --name &quot;claude-code-ui&quot;

# Start on a custom port
pm2 start cloudcli --name &quot;claude-code-ui&quot; -- --port 8080
```


#### Auto-Start on System Boot

To make Claude Code UI start automatically when your system boots:

```bash
# Generate startup script for your platform
pm2 startup

# Save current process list
pm2 save
```


### Local Development Installation

1. **Clone the repository:**
```bash
git clone https://github.com/siteboon/claudecodeui.git
cd claudecodeui
```

2. **Install dependencies:**
```bash
npm install
```

3. **Configure environment:**
```bash
cp .env.example .env
# Edit .env with your preferred settings
```

4. **Start the application:**
```bash
# Development mode (with hot reload)
npm run dev

```
The application will start at the port you specified in your .env

5. **Open your browser:**
   - Development: `http://localhost:3001`

## Security &amp; Tools Configuration

**üîí Important Notice**: All Claude Code tools are **disabled by default**. This prevents potentially harmful operations from running automatically.

### Enabling Tools

To use Claude Code&#039;s full functionality, you&#039;ll need to manually enable tools:

1. **Open Tools Settings** - Click the gear icon in the sidebar
3. **Enable Selectively** - Turn on only the tools you need
4. **Apply Settings** - Your preferences are saved locally

&lt;div align=&quot;center&quot;&gt;

![Tools Settings Modal](public/screenshots/tools-modal.png)
*Tools Settings interface - enable only what you need*

&lt;/div&gt;

**Recommended approach**: Start with basic tools enabled and add more as needed. You can always adjust these settings later.

## TaskMaster AI Integration *(Optional)*

Claude Code UI supports **[TaskMaster AI](https://github.com/eyaltoledano/claude-task-master)** (aka claude-task-master) integration for advanced project management and AI-powered task planning.

It provides
- AI-powered task generation from PRDs (Product Requirements Documents)
- Smart task breakdown and dependency management  
- Visual task boards and progress tracking

**Setup &amp; Documentation**: Visit the [TaskMaster AI GitHub repository](https://github.com/eyaltoledano/claude-task-master) for installation instructions, configuration guides, and usage examples.
After installing it you should be able to enable it from the Settings


## Usage Guide

### Core Features

#### Project Management
It automatically discovers Claude Code, Cursor or Codex sessions when available and groups them together into projects
session counts
- **Project Actions** - Rename, delete, and organize projects
- **Smart Navigation** - Quick access to recent projects and sessions
- **MCP support** - Add your own MCP servers through the UI 

#### Chat Interface
- **Use responsive chat or Claude Code/Cursor CLI/Codex CLI** - You can either use the adapted chat interface or use the shell button to connect to your selected CLI. 
- **Real-time Communication** - Stream responses from your selected CLI (Claude Code/Cursor/Codex) with WebSocket connection
- **Session Management** - Resume previous conversations or start fresh sessions
- **Message History** - Complete conversation history with timestamps and metadata
- **Multi-format Support** - Text, code blocks, and file references

#### File Explorer &amp; Editor
- **Interactive File Tree** - Browse project structure with expand/collapse navigation
- **Live File Editing** - Read, modify, and save files directly in the interface
- **Syntax Highlighting** - Support for multiple programming languages
- **File Operations** - Create, rename, delete files and directories

#### Git Explorer


#### TaskMaster AI Integration *(Optional)*
- **Visual Task Board** - Kanban-style interface for managing development tasks
- **PRD Parser** - Create Product Requirements Documents and parse them into structured tasks
- **Progress Tracking** - Real-time status updates and completion tracking

#### Session Management
- **Session Persistence** - All conversations automatically saved
- **Session Organization** - Group sessions by project and timestamp
- **Session Actions** - Rename, delete, and export conversation history
- **Cross-device Sync** - Access sessions from any device

### Mobile App
- **Responsive Design** - Optimized for all screen sizes
- **Touch-friendly Interface** - Swipe gestures and touch navigation
- **Mobile Navigation** - Bottom tab bar for easy thumb navigation
- **Adaptive Layout** - Collapsible sidebar and smart content prioritization
- **Add shortcut to Home Screen** - Add a shortcut to your home screen and the app will behave like a PWA

## Architecture

### System Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ    ‚îÇ   Backend       ‚îÇ    ‚îÇ  Agent     ‚îÇ
‚îÇ   (React/Vite)  ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ (Express/WS)    ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ  Integration    ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Backend (Node.js + Express)
- **Express Server** - RESTful API with static file serving
- **WebSocket Server** - Communication for chats and project refresh
- **Agent Integration (Claude Code / Cursor CLI / Codex)** - Process spawning and management
- **File System API** - Exposing file browser for projects

### Frontend (React + Vite)
- **React 18** - Modern component architecture with hooks
- **CodeMirror** - Advanced code editor with syntax highlighting





### Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details on commit conventions, development workflow, and release process.

## Troubleshooting

### Common Issues &amp; Solutions


#### &quot;No Claude projects found&quot;
**Problem**: The UI shows no projects or empty project list
**Solutions**:
- Ensure [Claude Code](https://docs.anthropic.com/en/docs/claude-code) is properly installed
- Run `claude` command in at least one project directory to initialize
- Verify `~/.claude/projects/` directory exists and has proper permissions

#### File Explorer Issues
**Problem**: Files not loading, permission errors, empty directories
**Solutions**:
- Check project directory permissions (`ls -la` in terminal)
- Verify the project path exists and is accessible
- Review server console logs for detailed error messages
- Ensure you&#039;re not trying to access system directories outside project scope


## License

GNU General Public License v3.0 - see [LICENSE](LICENSE) file for details.

This project is open source and free to use, modify, and distribute under the GPL v3 license.

## Acknowledgments

### Built With
- **[Claude Code](https://docs.anthropic.com/en/docs/claude-code)** - Anthropic&#039;s official CLI
- **[Cursor CLI](https://docs.cursor.com/en/cli/overview)** - Cursor&#039;s official CLI
- **[Codex](https://developers.openai.com/codex)** - OpenAI Codex
- **[React](https://react.dev/)** - User interface library
- **[Vite](https://vitejs.dev/)** - Fast build tool and dev server
- **[Tailwind CSS](https://tailwindcss.com/)** - Utility-first CSS framework
- **[CodeMirror](https://codemirror.net/)** - Advanced code editor
- **[TaskMaster AI](https://github.com/eyaltoledano/claude-task-master)** *(Optional)* - AI-powered project management and task planning

## Support &amp; Community

### Stay Updated
- **Star** this repository to show support
- **Watch** for updates and new releases
- **Follow** the project for announcements

### Sponsors
- [Siteboon - AI powered website builder](https://siteboon.ai)
---

&lt;div align=&quot;center&quot;&gt;
  &lt;strong&gt;Made with care for the Claude Code, Cursor and Codex community.&lt;/strong&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[openclaw/openclaw]]></title>
            <link>https://github.com/openclaw/openclaw</link>
            <guid>https://github.com/openclaw/openclaw</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:19 GMT</pubDate>
            <description><![CDATA[Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openclaw/openclaw">openclaw/openclaw</a></h1>
            <p>Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û</p>
            <p>Language: TypeScript</p>
            <p>Stars: 236,591</p>
            <p>Forks: 45,627</p>
            <p>Stars today: 4,005 stars today</p>
            <h2>README</h2><pre># ü¶û OpenClaw ‚Äî Personal AI Assistant

&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text-dark.png&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text.png&quot; alt=&quot;OpenClaw&quot; width=&quot;500&quot;&gt;
    &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;EXFOLIATE! EXFOLIATE!&lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/openclaw/openclaw/actions/workflows/ci.yml?branch=main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/openclaw/openclaw/ci.yml?branch=main&amp;style=for-the-badge&quot; alt=&quot;CI status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/openclaw/openclaw/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/openclaw/openclaw?include_prereleases&amp;style=for-the-badge&quot; alt=&quot;GitHub release&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/clawd&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1456350064065904867?label=Discord&amp;logo=discord&amp;logoColor=white&amp;color=5865F2&amp;style=for-the-badge&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge&quot; alt=&quot;MIT License&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

**OpenClaw** is a _personal AI assistant_ you run on your own devices.
It answers you on the channels you already use (WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, WebChat), plus extension channels like BlueBubbles, Matrix, Zalo, and Zalo Personal. It can speak and listen on macOS/iOS/Android, and can render a live Canvas you control. The Gateway is just the control plane ‚Äî the product is the assistant.

If you want a personal, single-user assistant that feels local, fast, and always-on, this is it.

[Website](https://openclaw.ai) ¬∑ [Docs](https://docs.openclaw.ai) ¬∑ [Vision](VISION.md) ¬∑ [DeepWiki](https://deepwiki.com/openclaw/openclaw) ¬∑ [Getting Started](https://docs.openclaw.ai/start/getting-started) ¬∑ [Updating](https://docs.openclaw.ai/install/updating) ¬∑ [Showcase](https://docs.openclaw.ai/start/showcase) ¬∑ [FAQ](https://docs.openclaw.ai/help/faq) ¬∑ [Wizard](https://docs.openclaw.ai/start/wizard) ¬∑ [Nix](https://github.com/openclaw/nix-openclaw) ¬∑ [Docker](https://docs.openclaw.ai/install/docker) ¬∑ [Discord](https://discord.gg/clawd)

Preferred setup: run the onboarding wizard (`openclaw onboard`) in your terminal.
The wizard guides you step by step through setting up the gateway, workspace, channels, and skills. The CLI wizard is the recommended path and works on **macOS, Linux, and Windows (via WSL2; strongly recommended)**.
Works with npm, pnpm, or bun.
New install? Start here: [Getting started](https://docs.openclaw.ai/start/getting-started)

## Sponsors

| OpenAI                                                            | Blacksmith                                                                   | Convex                                                                |
| ----------------------------------------------------------------- | ---------------------------------------------------------------------------- | --------------------------------------------------------------------- |
| [![OpenAI](docs/assets/sponsors/openai.svg)](https://openai.com/) | [![Blacksmith](docs/assets/sponsors/blacksmith.svg)](https://blacksmith.sh/) | [![Convex](docs/assets/sponsors/convex.svg)](https://www.convex.dev/) |

**Subscriptions (OAuth):**

- **[OpenAI](https://openai.com/)** (ChatGPT/Codex)

Model note: while any model is supported, I strongly recommend **Anthropic Pro/Max (100/200) + Opus 4.6** for long‚Äëcontext strength and better prompt‚Äëinjection resistance. See [Onboarding](https://docs.openclaw.ai/start/onboarding).

## Models (selection + auth)

- Models config + CLI: [Models](https://docs.openclaw.ai/concepts/models)
- Auth profile rotation (OAuth vs API keys) + fallbacks: [Model failover](https://docs.openclaw.ai/concepts/model-failover)

## Install (recommended)

Runtime: **Node ‚â•22**.

```bash
npm install -g openclaw@latest
# or: pnpm add -g openclaw@latest

openclaw onboard --install-daemon
```

The wizard installs the Gateway daemon (launchd/systemd user service) so it stays running.

## Quick start (TL;DR)

Runtime: **Node ‚â•22**.

Full beginner guide (auth, pairing, channels): [Getting started](https://docs.openclaw.ai/start/getting-started)

```bash
openclaw onboard --install-daemon

openclaw gateway --port 18789 --verbose

# Send a message
openclaw message send --to +1234567890 --message &quot;Hello from OpenClaw&quot;

# Talk to the assistant (optionally deliver back to any connected channel: WhatsApp/Telegram/Slack/Discord/Google Chat/Signal/iMessage/BlueBubbles/Microsoft Teams/Matrix/Zalo/Zalo Personal/WebChat)
openclaw agent --message &quot;Ship checklist&quot; --thinking high
```

Upgrading? [Updating guide](https://docs.openclaw.ai/install/updating) (and run `openclaw doctor`).

## Development channels

- **stable**: tagged releases (`vYYYY.M.D` or `vYYYY.M.D-&lt;patch&gt;`), npm dist-tag `latest`.
- **beta**: prerelease tags (`vYYYY.M.D-beta.N`), npm dist-tag `beta` (macOS app may be missing).
- **dev**: moving head of `main`, npm dist-tag `dev` (when published).

Switch channels (git + npm): `openclaw update --channel stable|beta|dev`.
Details: [Development channels](https://docs.openclaw.ai/install/development-channels).

## From source (development)

Prefer `pnpm` for builds from source. Bun is optional for running TypeScript directly.

```bash
git clone https://github.com/openclaw/openclaw.git
cd openclaw

pnpm install
pnpm ui:build # auto-installs UI deps on first run
pnpm build

pnpm openclaw onboard --install-daemon

# Dev loop (auto-reload on TS changes)
pnpm gateway:watch
```

Note: `pnpm openclaw ...` runs TypeScript directly (via `tsx`). `pnpm build` produces `dist/` for running via Node / the packaged `openclaw` binary.

## Security defaults (DM access)

OpenClaw connects to real messaging surfaces. Treat inbound DMs as **untrusted input**.

Full security guide: [Security](https://docs.openclaw.ai/gateway/security)

Default behavior on Telegram/WhatsApp/Signal/iMessage/Microsoft Teams/Discord/Google Chat/Slack:

- **DM pairing** (`dmPolicy=&quot;pairing&quot;` / `channels.discord.dmPolicy=&quot;pairing&quot;` / `channels.slack.dmPolicy=&quot;pairing&quot;`; legacy: `channels.discord.dm.policy`, `channels.slack.dm.policy`): unknown senders receive a short pairing code and the bot does not process their message.
- Approve with: `openclaw pairing approve &lt;channel&gt; &lt;code&gt;` (then the sender is added to a local allowlist store).
- Public inbound DMs require an explicit opt-in: set `dmPolicy=&quot;open&quot;` and include `&quot;*&quot;` in the channel allowlist (`allowFrom` / `channels.discord.allowFrom` / `channels.slack.allowFrom`; legacy: `channels.discord.dm.allowFrom`, `channels.slack.dm.allowFrom`).

Run `openclaw doctor` to surface risky/misconfigured DM policies.

## Highlights

- **[Local-first Gateway](https://docs.openclaw.ai/gateway)** ‚Äî single control plane for sessions, channels, tools, and events.
- **[Multi-channel inbox](https://docs.openclaw.ai/channels)** ‚Äî WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, BlueBubbles (iMessage), iMessage (legacy), Microsoft Teams, Matrix, Zalo, Zalo Personal, WebChat, macOS, iOS/Android.
- **[Multi-agent routing](https://docs.openclaw.ai/gateway/configuration)** ‚Äî route inbound channels/accounts/peers to isolated agents (workspaces + per-agent sessions).
- **[Voice Wake](https://docs.openclaw.ai/nodes/voicewake) + [Talk Mode](https://docs.openclaw.ai/nodes/talk)** ‚Äî always-on speech for macOS/iOS/Android with ElevenLabs.
- **[Live Canvas](https://docs.openclaw.ai/platforms/mac/canvas)** ‚Äî agent-driven visual workspace with [A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui).
- **[First-class tools](https://docs.openclaw.ai/tools)** ‚Äî browser, canvas, nodes, cron, sessions, and Discord/Slack actions.
- **[Companion apps](https://docs.openclaw.ai/platforms/macos)** ‚Äî macOS menu bar app + iOS/Android [nodes](https://docs.openclaw.ai/nodes).
- **[Onboarding](https://docs.openclaw.ai/start/wizard) + [skills](https://docs.openclaw.ai/tools/skills)** ‚Äî wizard-driven setup with bundled/managed/workspace skills.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=openclaw/openclaw&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#openclaw/openclaw&amp;type=date&amp;legend=top-left)

## Everything we built so far

### Core platform

- [Gateway WS control plane](https://docs.openclaw.ai/gateway) with sessions, presence, config, cron, webhooks, [Control UI](https://docs.openclaw.ai/web), and [Canvas host](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui).
- [CLI surface](https://docs.openclaw.ai/tools/agent-send): gateway, agent, send, [wizard](https://docs.openclaw.ai/start/wizard), and [doctor](https://docs.openclaw.ai/gateway/doctor).
- [Pi agent runtime](https://docs.openclaw.ai/concepts/agent) in RPC mode with tool streaming and block streaming.
- [Session model](https://docs.openclaw.ai/concepts/session): `main` for direct chats, group isolation, activation modes, queue modes, reply-back. Group rules: [Groups](https://docs.openclaw.ai/channels/groups).
- [Media pipeline](https://docs.openclaw.ai/nodes/images): images/audio/video, transcription hooks, size caps, temp file lifecycle. Audio details: [Audio](https://docs.openclaw.ai/nodes/audio).

### Channels

- [Channels](https://docs.openclaw.ai/channels): [WhatsApp](https://docs.openclaw.ai/channels/whatsapp) (Baileys), [Telegram](https://docs.openclaw.ai/channels/telegram) (grammY), [Slack](https://docs.openclaw.ai/channels/slack) (Bolt), [Discord](https://docs.openclaw.ai/channels/discord) (discord.js), [Google Chat](https://docs.openclaw.ai/channels/googlechat) (Chat API), [Signal](https://docs.openclaw.ai/channels/signal) (signal-cli), [BlueBubbles](https://docs.openclaw.ai/channels/bluebubbles) (iMessage, recommended), [iMessage](https://docs.openclaw.ai/channels/imessage) (legacy imsg), [Microsoft Teams](https://docs.openclaw.ai/channels/msteams) (extension), [Matrix](https://docs.openclaw.ai/channels/matrix) (extension), [Zalo](https://docs.openclaw.ai/channels/zalo) (extension), [Zalo Personal](https://docs.openclaw.ai/channels/zalouser) (extension), [WebChat](https://docs.openclaw.ai/web/webchat).
- [Group routing](https://docs.openclaw.ai/channels/group-messages): mention gating, reply tags, per-channel chunking and routing. Channel rules: [Channels](https://docs.openclaw.ai/channels).

### Apps + nodes

- [macOS app](https://docs.openclaw.ai/platforms/macos): menu bar control plane, [Voice Wake](https://docs.openclaw.ai/nodes/voicewake)/PTT, [Talk Mode](https://docs.openclaw.ai/nodes/talk) overlay, [WebChat](https://docs.openclaw.ai/web/webchat), debug tools, [remote gateway](https://docs.openclaw.ai/gateway/remote) control.
- [iOS node](https://docs.openclaw.ai/platforms/ios): [Canvas](https://docs.openclaw.ai/platforms/mac/canvas), [Voice Wake](https://docs.openclaw.ai/nodes/voicewake), [Talk Mode](https://docs.openclaw.ai/nodes/talk), camera, screen recording, Bonjour pairing.
- [Android node](https://docs.openclaw.ai/platforms/android): [Canvas](https://docs.openclaw.ai/platforms/mac/canvas), [Talk Mode](https://docs.openclaw.ai/nodes/talk), camera, screen recording, optional SMS.
- [macOS node mode](https://docs.openclaw.ai/nodes): system.run/notify + canvas/camera exposure.

### Tools + automation

- [Browser control](https://docs.openclaw.ai/tools/browser): dedicated openclaw Chrome/Chromium, snapshots, actions, uploads, profiles.
- [Canvas](https://docs.openclaw.ai/platforms/mac/canvas): [A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui) push/reset, eval, snapshot.
- [Nodes](https://docs.openclaw.ai/nodes): camera snap/clip, screen record, [location.get](https://docs.openclaw.ai/nodes/location-command), notifications.
- [Cron + wakeups](https://docs.openclaw.ai/automation/cron-jobs); [webhooks](https://docs.openclaw.ai/automation/webhook); [Gmail Pub/Sub](https://docs.openclaw.ai/automation/gmail-pubsub).
- [Skills platform](https://docs.openclaw.ai/tools/skills): bundled, managed, and workspace skills with install gating + UI.

### Runtime + safety

- [Channel routing](https://docs.openclaw.ai/channels/channel-routing), [retry policy](https://docs.openclaw.ai/concepts/retry), and [streaming/chunking](https://docs.openclaw.ai/concepts/streaming).
- [Presence](https://docs.openclaw.ai/concepts/presence), [typing indicators](https://docs.openclaw.ai/concepts/typing-indicators), and [usage tracking](https://docs.openclaw.ai/concepts/usage-tracking).
- [Models](https://docs.openclaw.ai/concepts/models), [model failover](https://docs.openclaw.ai/concepts/model-failover), and [session pruning](https://docs.openclaw.ai/concepts/session-pruning).
- [Security](https://docs.openclaw.ai/gateway/security) and [troubleshooting](https://docs.openclaw.ai/channels/troubleshooting).

### Ops + packaging

- [Control UI](https://docs.openclaw.ai/web) + [WebChat](https://docs.openclaw.ai/web/webchat) served directly from the Gateway.
- [Tailscale Serve/Funnel](https://docs.openclaw.ai/gateway/tailscale) or [SSH tunnels](https://docs.openclaw.ai/gateway/remote) with token/password auth.
- [Nix mode](https://docs.openclaw.ai/install/nix) for declarative config; [Docker](https://docs.openclaw.ai/install/docker)-based installs.
- [Doctor](https://docs.openclaw.ai/gateway/doctor) migrations, [logging](https://docs.openclaw.ai/logging).

## How it works (short)

```
WhatsApp / Telegram / Slack / Discord / Google Chat / Signal / iMessage / BlueBubbles / Microsoft Teams / Matrix / Zalo / Zalo Personal / WebChat
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Gateway            ‚îÇ
‚îÇ       (control plane)         ‚îÇ
‚îÇ     ws://127.0.0.1:18789      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚îú‚îÄ Pi agent (RPC)
               ‚îú‚îÄ CLI (openclaw ‚Ä¶)
               ‚îú‚îÄ WebChat UI
               ‚îú‚îÄ macOS app
               ‚îî‚îÄ iOS / Android nodes
```

## Key subsystems

- **[Gateway WebSocket network](https://docs.openclaw.ai/concepts/architecture)** ‚Äî single WS control plane for clients, tools, and events (plus ops: [Gateway runbook](https://docs.openclaw.ai/gateway)).
- **[Tailscale exposure](https://docs.openclaw.ai/gateway/tailscale)** ‚Äî Serve/Funnel for the Gateway dashboard + WS (remote access: [Remote](https://docs.openclaw.ai/gateway/remote)).
- **[Browser control](https://docs.openclaw.ai/tools/browser)** ‚Äî openclaw‚Äëmanaged Chrome/Chromium with CDP control.
- **[Canvas + A2UI](https://docs.openclaw.ai/platforms/mac/canvas)** ‚Äî agent‚Äëdriven visual workspace (A2UI host: [Canvas/A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui)).
- **[Voice Wake](https://docs.openclaw.ai/nodes/voicewake) + [Talk Mode](https://docs.openclaw.ai/nodes/talk)** ‚Äî always‚Äëon speech and continuous conversation.
- **[Nodes](https://docs.openclaw.ai/nodes)** ‚Äî Canvas, camera snap/clip, screen record, `location.get`, notifications, plus macOS‚Äëonly `system.run`/`system.notify`.

## Tailscale access (Gateway dashboard)

OpenClaw can auto-configure Tailscale **Serve** (tailnet-only) or **Funnel** (public) while the Gateway stays bound to loopback. Configure `gateway.tailscale.mode`:

- `off`: no Tailscale automation (default).
- `serve`: tailnet-only HTTPS via `tailscale serve` (uses Tailscale identity headers by default).
- `funnel`: public HTTPS via `tailscale funnel` (requires shared password auth).

Notes:

- `gateway.bind` must stay `loopback` when Serve/Funnel is enabled (OpenClaw enforces this).
- Serve can be forced to require a password by setting `gateway.auth.mode: &quot;password&quot;` or `gateway.auth.allowTailscale: false`.
- Funnel refuses to start unless `gateway.auth.mode: &quot;password&quot;` is set.
- Optional: `gateway.tailscale.resetOnExit` to undo Serve/Funnel on shutdown.

Details: [Tailscale guide](https://docs.openclaw.ai/gateway/tailscale) ¬∑ [Web surfaces](https://docs.openclaw.ai/web)

## Remote Gateway (Linux is great)

It‚Äôs perfectly fine to run the Gateway on a small Linux instance. Clients (macOS app, CLI, WebChat) can connect over **Tailscale Serve/Funnel** or **SSH tunnels**, and you can still pair device nodes (macOS/iOS/Android) to execute device‚Äëlocal actions when needed.

- **Gateway host** runs the exec tool and channel connections by default.
- **Device nodes** run device‚Äëlocal actions (`system.run`, camera, screen recording, notifications) via `node.invoke`.
  In short: exec runs where the Gateway lives; device actions run where the device lives.

Details: [Remote access](https://docs.openclaw.ai/gateway/remote) ¬∑ [Nodes](https://docs.openclaw.ai/nodes) ¬∑ [Security](https://docs.openclaw.ai/gateway/security)

## macOS permissions via the Gateway protocol

The macOS app can run in **node mode** and advertises its capabilities + permission map over the Gateway WebSocket (`node.list` / `node.describe`). Clients can then execute local actions via `node.invoke`:

- `system.run` runs a local command and returns stdout/stderr/exit code; set `needsScreenRecording: true` to require screen-recording permission (otherwise you‚Äôll get `PERMISSION_MISSING`).
- `system.notify` posts a user notification and fails if notifications are denied.
- `canvas.*`, `camera.*`, `screen.record`, and `location.get` are also routed via `node.invoke` and follow TCC permission status.

Elevated bash (host permissions) is separate from macOS TCC:

- Use `/elevated on|off` to toggle per‚Äësession elevated access when enabled + allowlisted.
- Gateway persists the per‚Äësession toggle via `sessions.patch` (WS method) alongside `thinkingLevel`, `verboseLevel`, `model`, `sendPolicy`, and `groupActivation`.

Details: [Nodes](https://docs.openclaw.ai/nodes) ¬∑ [macOS app](https://docs.openclaw.ai/platforms/macos) ¬∑ [Gateway protocol](https://docs.openclaw.ai/concepts/architecture)

## Agent to Agent (sessions\_\* tools)

- Use these to coordinate work across sessions without jumping between chat surfaces.
- `sessions_list` ‚Äî discover active sessions (agents) and their metadata.
- `sessions_history` ‚Äî fetch transcript logs for a session.
- `sessions_send` ‚Äî message another session; optional reply‚Äëback ping‚Äëpong + announce step (`REPLY_SKIP`, `ANNOUNCE_SKIP`).

Details: [Session tools](https://docs.openclaw.ai/concepts/session-tool)

## Skills registry (ClawHub)

ClawHub is a minimal skill registry. With ClawHub enabled, the agent can search for skills automatically and pull in new ones as needed.

[ClawHub](https://clawhub.com)

## Chat commands

Send these in WhatsApp/Telegram/Slack/Google Chat/Microsoft Teams/WebChat (group commands are owner-only):

- `/status` ‚Äî compact session status (model + tokens, cost when available)
- `/new` or `/reset` ‚Äî reset the session
- `/compact` ‚Äî compact session context (summary)
- `/think &lt;level&gt;` ‚Äî off|minimal|low|medium|high|xhigh (GPT-5.2 + Codex models only)
- `/verbose on|off`
- `/usage off|tokens|full` ‚Äî per-response usage footer
- `/restart` ‚Äî restart the gateway (owner-only in groups)
- `/activation mention|always` ‚Äî group activation toggle (groups only)

## Apps (optional)

The Gateway alone delivers a great experience. All apps are optional and add extra features.

If you plan to build/run companion apps, follow the platform runbooks below.

### macOS (OpenClaw.app) (optional)

- Menu bar control for the Gateway and health.
- Voice Wake + push-to-talk overlay.
- WebChat + debug tools.
- Remote gateway control over SSH.

Note: signed builds required for macOS permissions to stick across rebuilds (see `docs/mac/permissions.md`).

### iOS node (optional)

- Pairs as a node via the Bridge.
- Voice trigger forwarding + Canvas surface.
- Controlled via `openclaw nodes ‚Ä¶`.

Runbook: [iOS connect](https://docs.openclaw.ai/platforms/ios).

### Android node (optional)

- Pairs via the same Bridge + pairing flow as i

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ourongxing/newsnow]]></title>
            <link>https://github.com/ourongxing/newsnow</link>
            <guid>https://github.com/ourongxing/newsnow</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:18 GMT</pubDate>
            <description><![CDATA[Elegant reading of real-time and hottest news]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ourongxing/newsnow">ourongxing/newsnow</a></h1>
            <p>Elegant reading of real-time and hottest news</p>
            <p>Language: TypeScript</p>
            <p>Stars: 18,237</p>
            <p>Forks: 5,224</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>![](/public/og-image.png)

English | [ÁÆÄ‰Ωì‰∏≠Êñá](README.zh-CN.md) | [Êó•Êú¨Ë™û](README.ja-JP.md)

&gt; [!NOTE]
&gt; This is a demo version currently supporting Chinese only. A full-featured version with better customization and English content support will be released later.

**_Elegant reading of real-time and hottest news_**

## Features

- Clean and elegant UI design for optimal reading experience
- Real-time updates on trending news
- GitHub OAuth login with data synchronization
- 30-minute default cache duration (logged-in users can force refresh)
- Adaptive scraping interval (minimum 2 minutes) based on source update frequency to optimize resource usage and prevent IP bans
- support MCP server

```json
{
  &quot;mcpServers&quot;: {
    &quot;newsnow&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;-y&quot;,
        &quot;newsnow-mcp-server&quot;
      ],
      &quot;env&quot;: {
        &quot;BASE_URL&quot;: &quot;https://newsnow.busiyi.world&quot;
      }
    }
  }
}
```
You can change the `BASE_URL` to your own domain.

## Deployment

### Basic Deployment

For deployments without login and caching:

1. Fork this repository
2. Import to platforms like Cloudflare Page or Vercel

### Cloudflare Page Configuration

- Build command: `pnpm run build`
- Output directory: `dist/output/public`

### GitHub OAuth Setup

1. [Create a GitHub App](https://github.com/settings/applications/new)
2. No special permissions required
3. Set callback URL to: `https://your-domain.com/api/oauth/github` (replace `your-domain` with your actual domain)
4. Obtain Client ID and Client Secret

### Environment Variables

Refer to `example.env.server`. For local development, rename it to `.env.server` and configure:

```env
# Github Client ID
G_CLIENT_ID=
# Github Client Secret
G_CLIENT_SECRET=
# JWT Secret, usually the same as Client Secret
JWT_SECRET=
# Initialize database, must be set to true on first run, can be turned off afterward
INIT_TABLE=true
# Whether to enable cache
ENABLE_CACHE=true
```

### Database Support

Supported database connectors: https://db0.unjs.io/connectors
**Cloudflare D1 Database** is recommended.

1. Create D1 database in Cloudflare Worker dashboard
2. Configure database_id and database_name in wrangler.toml
3. If wrangler.toml doesn&#039;t exist, rename example.wrangler.toml and modify configurations
4. Changes will take effect on next deployment

### Docker Deployment

In project root directory:

```sh
docker compose up
```

You can also set Environment Variables in `docker-compose.yml`.

## Development

&gt; [!Note]
&gt; Requires Node.js &gt;= 20

```sh
corepack enable
pnpm i
pnpm dev
```

### Adding Data Sources

Refer to `shared/sources` and `server/sources` directories. The project provides complete type definitions and a clean architecture.

For detailed instructions on how to add new sources, see [CONTRIBUTING.md](CONTRIBUTING.md).

## Roadmap

- Add **multi-language support** (English, Chinese, more to come).
- Improve **personalization options** (category-based news, saved preferences).
- Expand **data sources** to cover global news in multiple languages.

**_release when ready_**
![](https://testmnbbs.oss-cn-zhangjiakou.aliyuncs.com/pic/20250328172146_rec_.gif?x-oss-process=base_webp)

## Contributing

Contributions are welcome! Feel free to submit pull requests or create issues for feature requests and bug reports.

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines on how to contribute, especially for adding new data sources.

## License

[MIT](./LICENSE) ¬© ourongxing
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>