<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Thu, 26 Feb 2026 00:07:34 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[abhigyanpatwari/GitNexus]]></title>
            <link>https://github.com/abhigyanpatwari/GitNexus</link>
            <guid>https://github.com/abhigyanpatwari/GitNexus</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:34 GMT</pubDate>
            <description><![CDATA[GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/abhigyanpatwari/GitNexus">abhigyanpatwari/GitNexus</a></h1>
            <p>GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,672</p>
            <p>Forks: 305</p>
            <p>Stars today: 894 stars today</p>
            <h2>README</h2><pre># GitNexus

&lt;a href=&quot;https://trendshift.io/repositories/19809&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/19809&quot; alt=&quot;abhigyanpatwari%2FGitNexus | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

**Building git for agent context.**

Indexes any codebase into a knowledge graph ‚Äî every dependency, call chain, cluster, and execution flow ‚Äî then exposes it through smart tools so AI agents never miss code.

[![npm version](https://img.shields.io/npm/v/gitnexus.svg)](https://www.npmjs.com/package/gitnexus)
[![License: PolyForm Noncommercial](https://img.shields.io/badge/License-PolyForm%20Noncommercial-blue.svg)](https://polyformproject.org/licenses/noncommercial/1.0.0/)



https://github.com/user-attachments/assets/172685ba-8e54-4ea7-9ad1-e31a3398da72



&gt; *Like DeepWiki, but deeper.* DeepWiki helps you *understand* code. GitNexus lets you *analyze* it ‚Äî because a knowledge graph tracks every relationship, not just descriptions.

**TL;DR:** The **Web UI** is a quick way to chat with any repo. The **CLI + MCP** is how you make your AI agent actually reliable ‚Äî it gives Cursor, Claude Code, and friends a deep architectural view of your codebase so they stop missing dependencies, breaking call chains, and shipping blind edits. Even smaller models get full architectural clarity, making it compete with goliath models.

---

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=abhigyanpatwari/GitNexus&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#abhigyanpatwari/GitNexus&amp;type=date&amp;legend=top-left)


## Two Ways to Use GitNexus

|                   | **CLI + MCP**                                            | **Web UI**                                             |
| ----------------- | -------------------------------------------------------------- | ------------------------------------------------------------ |
| **What**    | Index repos locally, connect AI agents via MCP                 | Visual graph explorer + AI chat in browser                   |
| **For**     | Daily development with Cursor, Claude Code, Windsurf, OpenCode | Quick exploration, demos, one-off analysis                   |
| **Scale**   | Full repos, any size                                           | Limited by browser memory (~5k files), or unlimited via backend mode |
| **Install** | `npm install -g gitnexus`                                    | No install ‚Äî[gitnexus.vercel.app](https://gitnexus.vercel.app) |
| **Storage** | KuzuDB native (fast, persistent)                               | KuzuDB WASM (in-memory, per session)                         |
| **Parsing** | Tree-sitter native bindings                                    | Tree-sitter WASM                                             |
| **Privacy** | Everything local, no network                                   | Everything in-browser, no server                             |

&gt; **Bridge mode:** `gitnexus serve` connects the two ‚Äî the web UI auto-detects the local server and can browse all your CLI-indexed repos without re-uploading or re-indexing.

---

## CLI + MCP (recommended)

The CLI indexes your repository and runs an MCP server that gives AI agents deep codebase awareness.

### Quick Start

```bash
# Index your repo (run from repo root)
npx gitnexus analyze
```

That&#039;s it. This indexes the codebase, installs agent skills, registers Claude Code hooks, and creates `AGENTS.md` / `CLAUDE.md` context files ‚Äî all in one command.

To configure MCP for your editor, run `npx gitnexus setup` once ‚Äî or set it up manually below.

### MCP Setup

`gitnexus setup` auto-detects your editors and writes the correct global MCP config. You only need to run it once.

### Editor Support

| Editor                | MCP | Skills | Hooks (auto-augment) | Support        |
| --------------------- | --- | ------ | -------------------- | -------------- |
| **Claude Code** | Yes | Yes    | Yes (PreToolUse)     | **Full** |
| **Cursor**      | Yes | Yes    | ‚Äî                   | MCP + Skills   |
| **Windsurf**    | Yes | ‚Äî     | ‚Äî                   | MCP            |
| **OpenCode**    | Yes | Yes    | ‚Äî                   | MCP + Skills   |

&gt; **Claude Code** gets the deepest integration: MCP tools + agent skills + PreToolUse hooks that automatically enrich grep/glob/bash calls with knowledge graph context.

### Community Integrations

| Agent | Install | Source |
|-------|---------|--------|
| [pi](https://pi.dev) | `pi install npm:pi-gitnexus` | [pi-gitnexus](https://github.com/tintinweb/pi-gitnexus) |

If you prefer manual configuration:

**Claude Code** (full support ‚Äî MCP + skills + hooks):

```bash
claude mcp add gitnexus -- npx -y gitnexus@latest mcp
```

**Cursor** (`~/.cursor/mcp.json` ‚Äî global, works for all projects):

```json
{
  &quot;mcpServers&quot;: {
    &quot;gitnexus&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;gitnexus@latest&quot;, &quot;mcp&quot;]
    }
  }
}
```

**OpenCode** (`~/.config/opencode/config.json`):

```json
{
  &quot;mcp&quot;: {
    &quot;gitnexus&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;gitnexus@latest&quot;, &quot;mcp&quot;]
    }
  }
}
```

### CLI Commands

```bash
gitnexus setup                    # Configure MCP for your editors (one-time)
gitnexus analyze [path]           # Index a repository (or update stale index)
gitnexus analyze --force          # Force full re-index
gitnexus analyze --skip-embeddings  # Skip embedding generation (faster)
gitnexus mcp                     # Start MCP server (stdio) ‚Äî serves all indexed repos
gitnexus serve                   # Start local HTTP server (multi-repo) for web UI connection
gitnexus list                    # List all indexed repositories
gitnexus status                  # Show index status for current repo
gitnexus clean                   # Delete index for current repo
gitnexus clean --all --force     # Delete all indexes
gitnexus wiki [path]             # Generate repository wiki from knowledge graph
gitnexus wiki --model &lt;model&gt;    # Wiki with custom LLM model (default: gpt-4o-mini)
gitnexus wiki --base-url &lt;url&gt;   # Wiki with custom LLM API base URL
```

### What Your AI Agent Gets

**7 tools** exposed via MCP:

| Tool               | What It Does                                                      | `repo` Param |
| ------------------ | ----------------------------------------------------------------- | -------------- |
| `list_repos`     | Discover all indexed repositories                                 | ‚Äî             |
| `query`          | Process-grouped hybrid search (BM25 + semantic + RRF)             | Optional       |
| `context`        | 360-degree symbol view ‚Äî categorized refs, process participation | Optional       |
| `impact`         | Blast radius analysis with depth grouping and confidence          | Optional       |
| `detect_changes` | Git-diff impact ‚Äî maps changed lines to affected processes       | Optional       |
| `rename`         | Multi-file coordinated rename with graph + text search            | Optional       |
| `cypher`         | Raw Cypher graph queries                                          | Optional       |

&gt; When only one repo is indexed, the `repo` parameter is optional. With multiple repos, specify which one: `query({query: &quot;auth&quot;, repo: &quot;my-app&quot;})`.

**Resources** for instant context:

| Resource                                  | Purpose                                              |
| ----------------------------------------- | ---------------------------------------------------- |
| `gitnexus://repos`                      | List all indexed repositories (read this first)      |
| `gitnexus://repo/{name}/context`        | Codebase stats, staleness check, and available tools |
| `gitnexus://repo/{name}/clusters`       | All functional clusters with cohesion scores         |
| `gitnexus://repo/{name}/cluster/{name}` | Cluster members and details                          |
| `gitnexus://repo/{name}/processes`      | All execution flows                                  |
| `gitnexus://repo/{name}/process/{name}` | Full process trace with steps                        |
| `gitnexus://repo/{name}/schema`         | Graph schema for Cypher queries                      |

**2 MCP prompts** for guided workflows:

| Prompt            | What It Does                                                              |
| ----------------- | ------------------------------------------------------------------------- |
| `detect_impact` | Pre-commit change analysis ‚Äî scope, affected processes, risk level       |
| `generate_map`  | Architecture documentation from the knowledge graph with mermaid diagrams |

**4 agent skills** installed to `.claude/skills/` automatically:

- **Exploring** ‚Äî Navigate unfamiliar code using the knowledge graph
- **Debugging** ‚Äî Trace bugs through call chains
- **Impact Analysis** ‚Äî Analyze blast radius before changes
- **Refactoring** ‚Äî Plan safe refactors using dependency mapping

---

## Multi-Repo MCP Architecture

GitNexus uses a **global registry** so one MCP server can serve multiple indexed repos. No per-project MCP config needed ‚Äî set it up once and it works everywhere.

```mermaid
flowchart TD
    subgraph CLI [CLI Commands]
        Setup[&quot;gitnexus setup&quot;]
        Analyze[&quot;gitnexus analyze&quot;]
        Clean[&quot;gitnexus clean&quot;]
        List[&quot;gitnexus list&quot;]
    end

    subgraph Registry [&quot;~/.gitnexus/&quot;]
        RegFile[&quot;registry.json&quot;]
    end

    subgraph Repos [Project Repos]
        RepoA[&quot;.gitnexus/ in repo A&quot;]
        RepoB[&quot;.gitnexus/ in repo B&quot;]
    end

    subgraph MCP [MCP Server]
        Server[&quot;server.ts&quot;]
        Backend[&quot;LocalBackend&quot;]
        Pool[&quot;Connection Pool&quot;]
        ConnA[&quot;KuzuDB conn A&quot;]
        ConnB[&quot;KuzuDB conn B&quot;]
    end

    Setup --&gt;|&quot;writes global MCP config&quot;| CursorConfig[&quot;~/.cursor/mcp.json&quot;]
    Analyze --&gt;|&quot;registers repo&quot;| RegFile
    Analyze --&gt;|&quot;stores index&quot;| RepoA
    Clean --&gt;|&quot;unregisters repo&quot;| RegFile
    List --&gt;|&quot;reads&quot;| RegFile
    Server --&gt;|&quot;reads registry&quot;| RegFile
    Server --&gt; Backend
    Backend --&gt; Pool
    Pool --&gt;|&quot;lazy open&quot;| ConnA
    Pool --&gt;|&quot;lazy open&quot;| ConnB
    ConnA --&gt;|&quot;queries&quot;| RepoA
    ConnB --&gt;|&quot;queries&quot;| RepoB
```

**How it works:** Each `gitnexus analyze` stores the index in `.gitnexus/` inside the repo (portable, gitignored) and registers a pointer in `~/.gitnexus/registry.json`. When an AI agent starts, the MCP server reads the registry and can serve any indexed repo. KuzuDB connections are opened lazily on first query and evicted after 5 minutes of inactivity (max 5 concurrent). If only one repo is indexed, the `repo` parameter is optional on all tools ‚Äî agents don&#039;t need to change anything.

---

## Web UI (browser-based)

A fully client-side graph explorer and AI chat. No server, no install ‚Äî your code never leaves the browser.

**Try it now:** [gitnexus.vercel.app](https://gitnexus.vercel.app) ‚Äî drag &amp; drop a ZIP and start exploring.

&lt;img width=&quot;2550&quot; height=&quot;1343&quot; alt=&quot;gitnexus_img&quot; src=&quot;https://github.com/user-attachments/assets/cc5d637d-e0e5-48e6-93ff-5bcfdb929285&quot; /&gt;

Or run locally:

```bash
git clone https://github.com/abhigyanpatwari/gitnexus.git
cd gitnexus/gitnexus-web
npm install
npm run dev
```

The web UI uses the same indexing pipeline as the CLI but runs entirely in WebAssembly (Tree-sitter WASM, KuzuDB WASM, in-browser embeddings). It&#039;s great for quick exploration but limited by browser memory for larger repos.

**Local Backend Mode:** Run `gitnexus serve` and open the web UI locally ‚Äî it auto-detects the server and shows all your indexed repos, with full AI chat support. No need to re-upload or re-index. The agent&#039;s tools (Cypher queries, search, code navigation) route through the backend HTTP API automatically.

---

## The Problem GitNexus Solves

Tools like **Cursor**, **Claude Code**, **Cline**, **Roo Code**, and **Windsurf** are powerful ‚Äî but they don&#039;t truly know your codebase structure.

**What happens:**

1. AI edits `UserService.validate()`
2. Doesn&#039;t know 47 functions depend on its return type
3. **Breaking changes ship**

### Traditional Graph RAG vs GitNexus

Traditional approaches give the LLM raw graph edges and hope it explores enough. GitNexus **precomputes structure at index time** ‚Äî clustering, tracing, scoring ‚Äî so tools return complete context in one call:

```mermaid
flowchart TB
    subgraph Traditional[&quot;Traditional Graph RAG&quot;]
        direction TB
        U1[&quot;User: What depends on UserService?&quot;]
        U1 --&gt; LLM1[&quot;LLM receives raw graph&quot;]
        LLM1 --&gt; Q1[&quot;Query 1: Find callers&quot;]
        Q1 --&gt; Q2[&quot;Query 2: What files?&quot;]
        Q2 --&gt; Q3[&quot;Query 3: Filter tests?&quot;]
        Q3 --&gt; Q4[&quot;Query 4: High-risk?&quot;]
        Q4 --&gt; OUT1[&quot;Answer after 4+ queries&quot;]
    end

    subgraph GN[&quot;GitNexus Smart Tools&quot;]
        direction TB
        U2[&quot;User: What depends on UserService?&quot;]
        U2 --&gt; TOOL[&quot;impact UserService upstream&quot;]
        TOOL --&gt; PRECOMP[&quot;Pre-structured response:
        8 callers, 3 clusters, all 90%+ confidence&quot;]
        PRECOMP --&gt; OUT2[&quot;Complete answer, 1 query&quot;]
    end
```

**Core innovation: Precomputed Relational Intelligence**

- **Reliability** ‚Äî LLM can&#039;t miss context, it&#039;s already in the tool response
- **Token efficiency** ‚Äî No 10-query chains to understand one function
- **Model democratization** ‚Äî Smaller LLMs work because tools do the heavy lifting

---

## How It Works

GitNexus builds a complete knowledge graph of your codebase through a multi-phase indexing pipeline:

1. **Structure** ‚Äî Walks the file tree and maps folder/file relationships
2. **Parsing** ‚Äî Extracts functions, classes, methods, and interfaces using Tree-sitter ASTs
3. **Resolution** ‚Äî Resolves imports and function calls across files with language-aware logic
4. **Clustering** ‚Äî Groups related symbols into functional communities
5. **Processes** ‚Äî Traces execution flows from entry points through call chains
6. **Search** ‚Äî Builds hybrid search indexes for fast retrieval

### Supported Languages

TypeScript, JavaScript, Python, Java, C, C++, C#, Go, Rust

---

## Tool Examples

### Impact Analysis

```
impact({target: &quot;UserService&quot;, direction: &quot;upstream&quot;, minConfidence: 0.8})

TARGET: Class UserService (src/services/user.ts)

UPSTREAM (what depends on this):
  Depth 1 (WILL BREAK):
    handleLogin [CALLS 90%] -&gt; src/api/auth.ts:45
    handleRegister [CALLS 90%] -&gt; src/api/auth.ts:78
    UserController [CALLS 85%] -&gt; src/controllers/user.ts:12
  Depth 2 (LIKELY AFFECTED):
    authRouter [IMPORTS] -&gt; src/routes/auth.ts
```

Options: `maxDepth`, `minConfidence`, `relationTypes` (`CALLS`, `IMPORTS`, `EXTENDS`, `IMPLEMENTS`), `includeTests`

### Process-Grouped Search

```
query({query: &quot;authentication middleware&quot;})

processes:
  - summary: &quot;LoginFlow&quot;
    priority: 0.042
    symbol_count: 4
    process_type: cross_community
    step_count: 7

process_symbols:
  - name: validateUser
    type: Function
    filePath: src/auth/validate.ts
    process_id: proc_login
    step_index: 2

definitions:
  - name: AuthConfig
    type: Interface
    filePath: src/types/auth.ts
```

### Context (360-degree Symbol View)

```
context({name: &quot;validateUser&quot;})

symbol:
  uid: &quot;Function:validateUser&quot;
  kind: Function
  filePath: src/auth/validate.ts
  startLine: 15

incoming:
  calls: [handleLogin, handleRegister, UserController]
  imports: [authRouter]

outgoing:
  calls: [checkPassword, createSession]

processes:
  - name: LoginFlow (step 2/7)
  - name: RegistrationFlow (step 3/5)
```

### Detect Changes (Pre-Commit)

```
detect_changes({scope: &quot;all&quot;})

summary:
  changed_count: 12
  affected_count: 3
  changed_files: 4
  risk_level: medium

changed_symbols: [validateUser, AuthService, ...]
affected_processes: [LoginFlow, RegistrationFlow, ...]
```

### Rename (Multi-File)

```
rename({symbol_name: &quot;validateUser&quot;, new_name: &quot;verifyUser&quot;, dry_run: true})

status: success
files_affected: 5
total_edits: 8
graph_edits: 6     (high confidence)
text_search_edits: 2  (review carefully)
changes: [...]
```

### Cypher Queries

```cypher
-- Find what calls auth functions with high confidence
MATCH (c:Community {heuristicLabel: &#039;Authentication&#039;})&lt;-[:CodeRelation {type: &#039;MEMBER_OF&#039;}]-(fn)
MATCH (caller)-[r:CodeRelation {type: &#039;CALLS&#039;}]-&gt;(fn)
WHERE r.confidence &gt; 0.8
RETURN caller.name, fn.name, r.confidence
ORDER BY r.confidence DESC
```

---

## Wiki Generation

Generate LLM-powered documentation from your knowledge graph:

```bash
# Requires an LLM API key (OPENAI_API_KEY, etc.)
gitnexus wiki

# Use a custom model or provider
gitnexus wiki --model gpt-4o
gitnexus wiki --base-url https://api.anthropic.com/v1

# Force full regeneration
gitnexus wiki --force
```

The wiki generator reads the indexed graph structure, groups files into modules via LLM, generates per-module documentation pages, and creates an overview page ‚Äî all with cross-references to the knowledge graph.

---

## Tech Stack

| Layer                     | CLI                                   | Web                                     |
| ------------------------- | ------------------------------------- | --------------------------------------- |
| **Runtime**         | Node.js (native)                      | Browser (WASM)                          |
| **Parsing**         | Tree-sitter native bindings           | Tree-sitter WASM                        |
| **Database**        | KuzuDB native                         | KuzuDB WASM                             |
| **Embeddings**      | HuggingFace transformers.js (GPU/CPU) | transformers.js (WebGPU/WASM)           |
| **Search**          | BM25 + semantic + RRF                 | BM25 + semantic + RRF                   |
| **Agent Interface** | MCP (stdio)                           | LangChain ReAct agent                   |
| **Visualization**   | ‚Äî                                    | Sigma.js + Graphology (WebGL)           |
| **Frontend**        | ‚Äî                                    | React 18, TypeScript, Vite, Tailwind v4 |
| **Clustering**      | Graphology                            | Graphology                              |
| **Concurrency**     | Worker threads + async                | Web Workers + Comlink                   |

---

## Roadmap

### Actively Building

- [ ] **LLM Cluster Enrichment** ‚Äî Semantic cluster names via LLM API
- [ ] **AST Decorator Detection** ‚Äî Parse @Controller, @Get, etc.
- [ ] **Incremental Indexing** ‚Äî Only re-index changed files

### Recently Completed

- [X] Wiki Generation, Multi-File Rename, Git-Diff Impact Analysis
- [X] Process-Grouped Search, 360-Degree Context, Claude Code Hooks
- [X] Multi-Repo MCP, Zero-Config Setup, 9 Language Support
- [X] Community Detection, Process Detection, Confidence Scoring
- [X] Hybrid Search, Vector Index

---

## Security &amp; Privacy

- **CLI**: Everything runs locally on your machine. No network calls. Index stored in `.gitnexus/` (gitignored). Global registry at `~/.gitnexus/` stores only paths and metadata.
- **Web**: Everything runs in your browser. No code uploaded to any server. API keys stored in localStorage only.
- Open source ‚Äî audit the code yourself.

---

## Acknowledgments

- [Tree-sitter](https://tree-sitter.github.io/) ‚Äî AST parsing
- [KuzuDB](https://kuzudb.com/) ‚Äî Embedded graph database with vector support
- [Sigma.js](https://www.sigmajs.org/) ‚Äî WebGL graph rendering
- [transformers.js](https://huggingface.co/docs/transformers.js) ‚Äî Browser ML
- [Graphology](https://graphology.github.io/) ‚Äî Graph data structures
- [MCP](https://modelcontextprotocol.io/) ‚Äî Model Context Protocol
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[bytedance/deer-flow]]></title>
            <link>https://github.com/bytedance/deer-flow</link>
            <guid>https://github.com/bytedance/deer-flow</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:33 GMT</pubDate>
            <description><![CDATA[An open-source SuperAgent harness that researches, codes, and creates. With the help of sandboxes, memories, tools, skills and subagents, it handles different levels of tasks that could take minutes to hours.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytedance/deer-flow">bytedance/deer-flow</a></h1>
            <p>An open-source SuperAgent harness that researches, codes, and creates. With the help of sandboxes, memories, tools, skills and subagents, it handles different levels of tasks that could take minutes to hours.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 20,435</p>
            <p>Forks: 2,557</p>
            <p>Stars today: 59 stars today</p>
            <h2>README</h2><pre># ü¶å DeerFlow - 2.0

DeerFlow (**D**eep **E**xploration and **E**fficient **R**esearch **Flow**) is an open-source **super agent harness** that orchestrates **sub-agents**, **memory**, and **sandboxes** to do almost anything ‚Äî powered by **extensible skills**.

https://github.com/user-attachments/assets/a8bcadc4-e040-4cf2-8fda-dd768b999c18

&gt; [!NOTE]
&gt; **DeerFlow 2.0 is a ground-up rewrite.** It shares no code with v1. If you&#039;re looking for the original Deep Research framework, it&#039;s maintained on the [`1.x` branch](https://github.com/bytedance/deer-flow/tree/main-1.x) ‚Äî contributions there are still welcome. Active development has moved to 2.0.

## Offiical Website

Learn more and see **real demos** on our official website.

**[deerflow.tech](https://deerflow.tech/)**

---

## Table of Contents

- [Quick Start](#quick-start)
- [Sandbox Mode](#sandbox-mode)
- [From Deep Research to Super Agent Harness](#from-deep-research-to-super-agent-harness)
- [Core Features](#core-features)
  - [Skills &amp; Tools](#skills--tools)
  - [Sub-Agents](#sub-agents)
  - [Sandbox &amp; File System](#sandbox--file-system)
  - [Context Engineering](#context-engineering)
  - [Long-Term Memory](#long-term-memory)
- [Recommended Models](#recommended-models)
- [Documentation](#documentation)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgments](#acknowledgments)
- [Star History](#star-history)

## Quick Start

### Configuration

1. **Clone the DeerFlow repository**

   ```bash
   git clone https://github.com/bytedance/deer-flow.git
   cd deer-flow
   ```

2. **Generate local configuration files**

   From the project root directory (`deer-flow/`), run:

   ```bash
   make config
   ```

   This command creates local configuration files based on the provided example templates.

3. **Configure your preferred model(s)**

   Edit `config.yaml` and define at least one model:

   ```yaml
   models:
     - name: gpt-4                       # Internal identifier
       display_name: GPT-4               # Human-readable name
       use: langchain_openai:ChatOpenAI  # LangChain class path
       model: gpt-4                      # Model identifier for API
       api_key: $OPENAI_API_KEY          # API key (recommended: use env var)
       max_tokens: 4096                  # Maximum tokens per request
       temperature: 0.7                  # Sampling temperature
   ```

4. **Set API keys for your configured model(s)**

   Choose one of the following methods:

- Option A: Edit the `.env` file in the project root (Recommended)


   ```bash
   TAVILY_API_KEY=your-tavily-api-key
   OPENAI_API_KEY=your-openai-api-key
   # Add other provider keys as needed
   ```

- Option B: Export environment variables in your shell

   ```bash
   export OPENAI_API_KEY=your-openai-api-key
   ```

- Option C: Edit `config.yaml` directly (Not recommended for production)

   ```yaml
   models:
     - name: gpt-4
       api_key: your-actual-api-key-here  # Replace placeholder
   ```

### Running the Application

#### Option 1: Docker (Recommended)

The fastest way to get started with a consistent environment:

1. **Initialize and start**:
   ```bash
   make docker-init    # Pull sandbox image (Only once or when image updates)
   make docker-start   # Start services (auto-detects sandbox mode from config.yaml)
   ```

   `make docker-start` now starts `provisioner` only when `config.yaml` uses provisioner mode (`sandbox.use: src.community.aio_sandbox:AioSandboxProvider` with `provisioner_url`).

2. **Access**: http://localhost:2026

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed Docker development guide.

#### Option 2: Local Development

If you prefer running services locally:

1. **Check prerequisites**:
   ```bash
   make check  # Verifies Node.js 22+, pnpm, uv, nginx
   ```

2. **(Optional) Pre-pull sandbox image**:
   ```bash
   # Recommended if using Docker/Container-based sandbox
   make setup-sandbox
   ```

3. **Start services**:
   ```bash
   make dev
   ```

4. **Access**: http://localhost:2026

### Advanced
#### Sandbox Mode

DeerFlow supports multiple sandbox execution modes:
- **Local Execution** (runs sandbox code directly on the host machine)
- **Docker Execution** (runs sandbox code in isolated Docker containers)
- **Docker Execution with Kubernetes** (runs sandbox code in Kubernetes pods via provisioner service)

For Docker development, service startup follows `config.yaml` sandbox mode. In Local/Docker modes, `provisioner` is not started.

See the [Sandbox Configuration Guide](backend/docs/CONFIGURATION.md#sandbox) to configure your preferred mode.

#### MCP Server

DeerFlow supports configurable MCP servers and skills to extend its capabilities.
See the [MCP Server Guide](backend/docs/MCP_SERVER.md) for detailed instructions.

## From Deep Research to Super Agent Harness

DeerFlow started as a Deep Research framework ‚Äî and the community ran with it. Since launch, developers have pushed it far beyond research: building data pipelines, generating slide decks, spinning up dashboards, automating content workflows. Things we never anticipated.

That told us something important: DeerFlow wasn&#039;t just a research tool. It was a **harness** ‚Äî a runtime that gives agents the infrastructure to actually get work done.

So we rebuilt it from scratch.

DeerFlow 2.0 is no longer a framework you wire together. It&#039;s a super agent harness ‚Äî batteries included, fully extensible. Built on LangGraph and LangChain, it ships with everything an agent needs out of the box: a filesystem, memory, skills, sandboxed execution, and the ability to plan and spawn sub-agents for complex, multi-step tasks.

Use it as-is. Or tear it apart and make it yours.

## Core Features

### Skills &amp; Tools

Skills are what make DeerFlow do *almost anything*.

A standard Agent Skill is a structured capability module ‚Äî a Markdown file that defines a workflow, best practices, and references to supporting resources. DeerFlow ships with built-in skills for research, report generation, slide creation, web pages, image and video generation, and more. But the real power is extensibility: add your own skills, replace the built-in ones, or combine them into compound workflows.

Skills are loaded progressively ‚Äî only when the task needs them, not all at once. This keeps the context window lean and makes DeerFlow work well even with token-sensitive models.

Tools follow the same philosophy. DeerFlow comes with a core toolset ‚Äî web search, web fetch, file operations, bash execution ‚Äî and supports custom tools via MCP servers and Python functions. Swap anything. Add anything.

```
# Paths inside the sandbox container
/mnt/skills/public
‚îú‚îÄ‚îÄ research/SKILL.md
‚îú‚îÄ‚îÄ report-generation/SKILL.md
‚îú‚îÄ‚îÄ slide-creation/SKILL.md
‚îú‚îÄ‚îÄ web-page/SKILL.md
‚îî‚îÄ‚îÄ image-generation/SKILL.md

/mnt/skills/custom
‚îî‚îÄ‚îÄ your-custom-skill/SKILL.md      ‚Üê yours
```

### Sub-Agents

Complex tasks rarely fit in a single pass. DeerFlow decomposes them.

The lead agent can spawn sub-agents on the fly ‚Äî each with its own scoped context, tools, and termination conditions. Sub-agents run in parallel when possible, report back structured results, and the lead agent synthesizes everything into a coherent output.

This is how DeerFlow handles tasks that take minutes to hours: a research task might fan out into a dozen sub-agents, each exploring a different angle, then converge into a single report ‚Äî or a website ‚Äî or a slide deck with generated visuals. One harness, many hands.

### Sandbox &amp; File System

DeerFlow doesn&#039;t just *talk* about doing things. It has its own computer.

Each task runs inside an isolated Docker container with a full filesystem ‚Äî skills, workspace, uploads, outputs. The agent reads, writes, and edits files. It executes bash commands and codes. It views images. All sandboxed, all auditable, zero contamination between sessions.

This is the difference between a chatbot with tool access and an agent with an actual execution environment.

```
# Paths inside the sandbox container
/mnt/user-data/
‚îú‚îÄ‚îÄ uploads/          ‚Üê your files
‚îú‚îÄ‚îÄ workspace/        ‚Üê agents&#039; working directory
‚îî‚îÄ‚îÄ outputs/          ‚Üê final deliverables
```

### Context Engineering

**Isolated Sub-Agent Context**: Each sub-agent runs in its own isolated context. This means that the sub-agent will not be able to see the context of the main agent or other sub-agents. This is important to ensure that the sub-agent is able to focus on the task at hand and not be distracted by the context of the main agent or other sub-agents.

**Summarization**: Within a session, DeerFlow manages context aggressively ‚Äî summarizing completed sub-tasks, offloading intermediate results to the filesystem, compressing what&#039;s no longer immediately relevant. This lets it stay sharp across long, multi-step tasks without blowing the context window.

### Long-Term Memory

Most agents forget everything the moment a conversation ends. DeerFlow remembers.

Across sessions, DeerFlow builds a persistent memory of your profile, preferences, and accumulated knowledge. The more you use it, the better it knows you ‚Äî your writing style, your technical stack, your recurring workflows. Memory is stored locally and stays under your control.

## Recommended Models

DeerFlow is model-agnostic ‚Äî it works with any LLM that implements the OpenAI-compatible API. That said, it performs best with models that support:

- **Long context windows** (100k+ tokens) for deep research and multi-step tasks
- **Reasoning capabilities** for adaptive planning and complex decomposition
- **Multimodal inputs** for image understanding and video comprehension
- **Strong tool-use** for reliable function calling and structured outputs

## Documentation

- [Contributing Guide](CONTRIBUTING.md) - Development environment setup and workflow
- [Configuration Guide](backend/docs/CONFIGURATION.md) - Setup and configuration instructions
- [Architecture Overview](backend/CLAUDE.md) - Technical architecture details
- [Backend Architecture](backend/README.md) - Backend architecture and API reference

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for development setup, workflow, and guidelines.

Regression coverage includes Docker sandbox mode detection and provisioner kubeconfig-path handling tests in `backend/tests/`.

## License

This project is open source and available under the [MIT License](./LICENSE).

## Acknowledgments

DeerFlow is built upon the incredible work of the open-source community. We are deeply grateful to all the projects and contributors whose efforts have made DeerFlow possible. Truly, we stand on the shoulders of giants.

We would like to extend our sincere appreciation to the following projects for their invaluable contributions:

- **[LangChain](https://github.com/langchain-ai/langchain)**: Their exceptional framework powers our LLM interactions and chains, enabling seamless integration and functionality.
- **[LangGraph](https://github.com/langchain-ai/langgraph)**: Their innovative approach to multi-agent orchestration has been instrumental in enabling DeerFlow&#039;s sophisticated workflows.

These projects exemplify the transformative power of open-source collaboration, and we are proud to build upon their foundations.

### Key Contributors

A heartfelt thank you goes out to the core authors of `DeerFlow`, whose vision, passion, and dedication have brought this project to life:

- **[Daniel Walnut](https://github.com/hetaoBackend/)**
- **[Henry Li](https://github.com/magiccube/)**

Your unwavering commitment and expertise have been the driving force behind DeerFlow&#039;s success. We are honored to have you at the helm of this journey.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=bytedance/deer-flow&amp;type=Date)](https://star-history.com/#bytedance/deer-flow&amp;Date)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[shareAI-lab/learn-claude-code]]></title>
            <link>https://github.com/shareAI-lab/learn-claude-code</link>
            <guid>https://github.com/shareAI-lab/learn-claude-code</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:32 GMT</pubDate>
            <description><![CDATA[Bash is all you need - A nano Claude Code‚Äìlike agent, built from 0 to 1]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/shareAI-lab/learn-claude-code">shareAI-lab/learn-claude-code</a></h1>
            <p>Bash is all you need - A nano Claude Code‚Äìlike agent, built from 0 to 1</p>
            <p>Language: TypeScript</p>
            <p>Stars: 17,952</p>
            <p>Forks: 3,766</p>
            <p>Stars today: 175 stars today</p>
            <h2>README</h2><pre># Learn Claude Code -- A nano Claude Code-like agent, built from 0 to 1

[English](./README.md) | [‰∏≠Êñá](./README-zh.md) | [Êó•Êú¨Ë™û](./README-ja.md)

```
                    THE AGENT PATTERN
                    =================

    User --&gt; messages[] --&gt; LLM --&gt; response
                                      |
                            stop_reason == &quot;tool_use&quot;?
                           /                          \
                         yes                           no
                          |                             |
                    execute tools                    return text
                    append results
                    loop back -----------------&gt; messages[]


    That&#039;s the minimal loop. Every AI coding agent needs this loop.
    Production agents add policy, permissions, and lifecycle layers.
```

**12 progressive sessions, from a simple loop to isolated autonomous execution.**
**Each session adds one mechanism. Each mechanism has one motto.**

&gt; **s01** &amp;nbsp; *&quot;Bash is all you need&quot;* &amp;mdash; one tool + one loop = an agent
&gt;
&gt; **s02** &amp;nbsp; *&quot;The loop didn&#039;t change&quot;* &amp;mdash; adding tools means adding handlers, not rewriting the loop
&gt;
&gt; **s03** &amp;nbsp; *&quot;Plan before you act&quot;* &amp;mdash; visible plans improve task completion
&gt;
&gt; **s04** &amp;nbsp; *&quot;Process isolation = context isolation&quot;* &amp;mdash; fresh messages[] per subagent
&gt;
&gt; **s05** &amp;nbsp; *&quot;Load on demand, not upfront&quot;* &amp;mdash; inject knowledge via tool_result, not system prompt
&gt;
&gt; **s06** &amp;nbsp; *&quot;Strategic forgetting&quot;* &amp;mdash; forget old context to enable infinite sessions
&gt;
&gt; **s07** &amp;nbsp; *&quot;State survives /compact&quot;* &amp;mdash; file-based state outlives context compression
&gt;
&gt; **s08** &amp;nbsp; *&quot;Fire and forget&quot;* &amp;mdash; non-blocking threads + notification queue
&gt;
&gt; **s09** &amp;nbsp; *&quot;Append to send, drain to read&quot;* &amp;mdash; async mailboxes for persistent teammates
&gt;
&gt; **s10** &amp;nbsp; *&quot;Same request_id, two protocols&quot;* &amp;mdash; one FSM pattern powers shutdown + plan approval
&gt;
&gt; **s11** &amp;nbsp; *&quot;Poll, claim, work, repeat&quot;* &amp;mdash; no coordinator needed, agents self-organize
&gt;
&gt; **s12** &amp;nbsp; *&quot;Isolate by directory, coordinate by task ID&quot;* &amp;mdash; task board + optional worktree lanes

---

## The Core Pattern

```python
def agent_loop(messages):
    while True:
        response = client.messages.create(
            model=MODEL, system=SYSTEM,
            messages=messages, tools=TOOLS,
        )
        messages.append({&quot;role&quot;: &quot;assistant&quot;,
                         &quot;content&quot;: response.content})

        if response.stop_reason != &quot;tool_use&quot;:
            return

        results = []
        for block in response.content:
            if block.type == &quot;tool_use&quot;:
                output = TOOL_HANDLERS[block.name](**block.input)
                results.append({
                    &quot;type&quot;: &quot;tool_result&quot;,
                    &quot;tool_use_id&quot;: block.id,
                    &quot;content&quot;: output,
                })
        messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: results})
```

Every session layers one mechanism on top of this loop -- without changing the loop itself.

## Scope (Important)

This repository is a 0-&gt;1 learning project for building a nano Claude Code-like agent.
It intentionally simplifies or omits several production mechanisms:

- Full event/hook buses (for example PreToolUse, SessionStart/End, ConfigChange).  
  s12 includes only a minimal append-only lifecycle event stream for teaching.
- Rule-based permission governance and trust workflows
- Session lifecycle controls (resume/fork) and advanced worktree lifecycle controls
- Full MCP runtime details (transport/OAuth/resource subscribe/polling)

Treat the team JSONL mailbox protocol in this repo as a teaching implementation, not a claim about any specific production internals.

## Quick Start

```sh
git clone https://github.com/shareAI-lab/learn-claude-code
cd learn-claude-code
pip install -r requirements.txt
cp .env.example .env   # Edit .env with your ANTHROPIC_API_KEY

python agents/s01_agent_loop.py       # Start here
python agents/s11_autonomous_agents.py  # Full autonomous team
python agents/s12_worktree_task_isolation.py  # Task-aware worktree isolation
```

### Web Platform

Interactive visualizations, step-through diagrams, source viewer, and documentation.

```sh
cd web &amp;&amp; npm install &amp;&amp; npm run dev   # http://localhost:3000
```

## Learning Path

```
Phase 1: THE LOOP                    Phase 2: PLANNING &amp; KNOWLEDGE
==================                   ==============================
s01  The Agent Loop          [1]     s03  TodoWrite               [5]
     while + stop_reason                  TodoManager + nag reminder
     |                                    |
     +-&gt; s02  Tools              [4]     s04  Subagents            [5]
              dispatch map: name-&gt;handler     fresh messages[] per child
                                              |
                                         s05  Skills               [5]
                                              SKILL.md via tool_result
                                              |
                                         s06  Compact              [5]
                                              3-layer compression

Phase 3: PERSISTENCE                 Phase 4: TEAMS
==================                   =====================
s07  Tasks                   [8]     s09  Agent Teams             [9]
     file-based CRUD + deps graph         teammates + JSONL mailboxes
     |                                    |
s08  Background Tasks        [6]     s10  Team Protocols          [12]
     daemon threads + notify queue        shutdown + plan approval FSM
                                          |
                                     s11  Autonomous Agents       [14]
                                          idle cycle + auto-claim
                                     |
                                     s12  Worktree Isolation      [16]
                                          task coordination + optional isolated execution lanes

                                     [N] = number of tools
```

## Architecture

```
learn-claude-code/
|
|-- agents/                        # Python reference implementations (s01-s12 + full)
|-- docs/{en,zh,ja}/               # Mental-model-first documentation (3 languages)
|-- web/                           # Interactive learning platform (Next.js)
|-- skills/                        # Skill files for s05
+-- .github/workflows/ci.yml      # CI: typecheck + build
```

## Documentation

Mental-model-first: problem, solution, ASCII diagram, minimal code.
Available in [English](./docs/en/) | [‰∏≠Êñá](./docs/zh/) | [Êó•Êú¨Ë™û](./docs/ja/).

| Session | Topic | Motto |
|---------|-------|-------|
| [s01](./docs/en/s01-the-agent-loop.md) | The Agent Loop | *Bash is all you need* |
| [s02](./docs/en/s02-tool-use.md) | Tools | *The loop didn&#039;t change* |
| [s03](./docs/en/s03-todo-write.md) | TodoWrite | *Plan before you act* |
| [s04](./docs/en/s04-subagent.md) | Subagents | *Process isolation = context isolation* |
| [s05](./docs/en/s05-skill-loading.md) | Skills | *Load on demand, not upfront* |
| [s06](./docs/en/s06-context-compact.md) | Compact | *Strategic forgetting* |
| [s07](./docs/en/s07-task-system.md) | Tasks | *State survives /compact* |
| [s08](./docs/en/s08-background-tasks.md) | Background Tasks | *Fire and forget* |
| [s09](./docs/en/s09-agent-teams.md) | Agent Teams | *Append to send, drain to read* |
| [s10](./docs/en/s10-team-protocols.md) | Team Protocols | *Same request_id, two protocols* |
| [s11](./docs/en/s11-autonomous-agents.md) | Autonomous Agents | *Poll, claim, work, repeat* |
| [s12](./docs/en/s12-worktree-task-isolation.md) | Worktree + Task Isolation | *Isolate by directory, coordinate by task ID* |

## License

MIT

---

**The model is the agent. Our job is to give it tools and stay out of the way.**
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[badlogic/pi-mono]]></title>
            <link>https://github.com/badlogic/pi-mono</link>
            <guid>https://github.com/badlogic/pi-mono</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:31 GMT</pubDate>
            <description><![CDATA[AI agent toolkit: coding agent CLI, unified LLM API, TUI & web UI libraries, Slack bot, vLLM pods]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/badlogic/pi-mono">badlogic/pi-mono</a></h1>
            <p>AI agent toolkit: coding agent CLI, unified LLM API, TUI & web UI libraries, Slack bot, vLLM pods</p>
            <p>Language: TypeScript</p>
            <p>Stars: 16,598</p>
            <p>Forks: 1,743</p>
            <p>Stars today: 759 stars today</p>
            <h2>README</h2><pre># üèñÔ∏è OSS Vacation

**Issue tracker and PRs reopen March 2, 2026.**

All PRs will be auto-closed until then. Approved contributors can submit PRs after vacation without reapproval. For support, join [Discord](https://discord.com/invite/3cU7Bz4UPx).

---

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://shittycodingagent.ai&quot;&gt;
    &lt;img src=&quot;https://shittycodingagent.ai/logo.svg&quot; alt=&quot;pi logo&quot; width=&quot;128&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.com/invite/3cU7Bz4UPx&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/badge/discord-community-5865F2?style=flat-square&amp;logo=discord&amp;logoColor=white&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/badlogic/pi-mono/actions/workflows/ci.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/badlogic/pi-mono/ci.yml?style=flat-square&amp;branch=main&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pi.dev&quot;&gt;pi.dev&lt;/a&gt; domain graciously donated by
  &lt;br /&gt;&lt;br /&gt;
  &lt;a href=&quot;https://exe.dev&quot;&gt;&lt;img src=&quot;packages/coding-agent/docs/images/exy.png&quot; alt=&quot;Exy mascot&quot; width=&quot;48&quot; /&gt;&lt;br /&gt;exe.dev&lt;/a&gt;
&lt;/p&gt;

# Pi Monorepo

&gt; **Looking for the pi coding agent?** See **[packages/coding-agent](packages/coding-agent)** for installation and usage.

Tools for building AI agents and managing LLM deployments.

## Packages

| Package | Description |
|---------|-------------|
| **[@mariozechner/pi-ai](packages/ai)** | Unified multi-provider LLM API (OpenAI, Anthropic, Google, etc.) |
| **[@mariozechner/pi-agent-core](packages/agent)** | Agent runtime with tool calling and state management |
| **[@mariozechner/pi-coding-agent](packages/coding-agent)** | Interactive coding agent CLI |
| **[@mariozechner/pi-mom](packages/mom)** | Slack bot that delegates messages to the pi coding agent |
| **[@mariozechner/pi-tui](packages/tui)** | Terminal UI library with differential rendering |
| **[@mariozechner/pi-web-ui](packages/web-ui)** | Web components for AI chat interfaces |
| **[@mariozechner/pi-pods](packages/pods)** | CLI for managing vLLM deployments on GPU pods |

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for contribution guidelines and [AGENTS.md](AGENTS.md) for project-specific rules (for both humans and agents).

## Development

```bash
npm install          # Install all dependencies
npm run build        # Build all packages
npm run check        # Lint, format, and type check
./test.sh            # Run tests (skips LLM-dependent tests without API keys)
./pi-test.sh         # Run pi from sources (must be run from repo root)
```

&gt; **Note:** `npm run check` requires `npm run build` to be run first. The web-ui package uses `tsc` which needs compiled `.d.ts` files from dependencies.

## License

MIT</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[langgenius/dify]]></title>
            <link>https://github.com/langgenius/dify</link>
            <guid>https://github.com/langgenius/dify</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:30 GMT</pubDate>
            <description><![CDATA[Production-ready platform for agentic workflow development.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langgenius/dify">langgenius/dify</a></h1>
            <p>Production-ready platform for agentic workflow development.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 130,342</p>
            <p>Forks: 20,305</p>
            <p>Stars today: 165 stars today</p>
            <h2>README</h2><pre>![cover-v5-optimized](./images/GitHub_README_if.png)

&lt;p align=&quot;center&quot;&gt;
  üìå &lt;a href=&quot;https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast&quot;&gt;Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cloud.dify.ai&quot;&gt;Dify Cloud&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted&quot;&gt;Self-hosting&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://docs.dify.ai&quot;&gt;Documentation&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://dify.ai/pricing&quot;&gt;Dify edition overview&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://dify.ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Product-F04438&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://dify.ai/pricing&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/free-pricing?logo=free&amp;color=%20%23155EEF&amp;label=pricing&amp;labelColor=%20%23528bff&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/FngNHpbcY7&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1082486657678311454?logo=discord&amp;labelColor=%20%235462eb&amp;logoColor=%20%23f5f5f5&amp;color=%20%235462eb&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://reddit.com/r/difyai&quot; target=&quot;_blank&quot;&gt;  
        &lt;img src=&quot;https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&amp;logo=reddit&amp;label=r%2Fdifyai&amp;labelColor=white&quot;
            alt=&quot;join Reddit&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=dify_ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/dify_ai?logo=X&amp;color=%20%23f5f5f5&quot;
            alt=&quot;follow on X(Twitter)&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/langgenius/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;logoColor=fff&quot;
            alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/u/langgenius&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&amp;color=%20%23f79009&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/graphs/commit-activity&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Commits last month&quot; src=&quot;https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&amp;color=%20%2312b76a&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Issues closed&quot; src=&quot;https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&amp;label=issues%20closed&amp;labelColor=%20%237d89b0&amp;color=%20%235d6b98&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/discussions/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Discussion posts&quot; src=&quot;https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&amp;color=%20%237a5af8&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://insights.linuxfoundation.org/project/langgenius-dify&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;LFX Health Score&quot; src=&quot;https://insights.linuxfoundation.org/api/badge/health-score?project=langgenius-dify&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://insights.linuxfoundation.org/project/langgenius-dify&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;LFX Contributors&quot; src=&quot;https://insights.linuxfoundation.org/api/badge/contributors?project=langgenius-dify&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://insights.linuxfoundation.org/project/langgenius-dify&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;LFX Active Contributors&quot; src=&quot;https://insights.linuxfoundation.org/api/badge/active-contributors?project=langgenius-dify&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/zh-TW/README.md&quot;&gt;&lt;img alt=&quot;ÁπÅÈ´î‰∏≠ÊñáÊñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁπÅÈ´î‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/zh-CN/README.md&quot;&gt;&lt;img alt=&quot;ÁÆÄ‰Ωì‰∏≠ÊñáÊñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/ja-JP/README.md&quot;&gt;&lt;img alt=&quot;Êó•Êú¨Ë™û„ÅÆREADME&quot; src=&quot;https://img.shields.io/badge/Êó•Êú¨Ë™û-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/es-ES/README.md&quot;&gt;&lt;img alt=&quot;README en Espa√±ol&quot; src=&quot;https://img.shields.io/badge/Espa√±ol-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/fr-FR/README.md&quot;&gt;&lt;img alt=&quot;README en Fran√ßais&quot; src=&quot;https://img.shields.io/badge/Fran√ßais-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/tlh/README.md&quot;&gt;&lt;img alt=&quot;README tlhIngan Hol&quot; src=&quot;https://img.shields.io/badge/Klingon-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/ko-KR/README.md&quot;&gt;&lt;img alt=&quot;README in Korean&quot; src=&quot;https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/ar-SA/README.md&quot;&gt;&lt;img alt=&quot;README ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&quot; src=&quot;https://img.shields.io/badge/ÿßŸÑÿπÿ±ÿ®Ÿäÿ©-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/tr-TR/README.md&quot;&gt;&lt;img alt=&quot;T√ºrk√ße README&quot; src=&quot;https://img.shields.io/badge/T√ºrk√ße-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/vi-VN/README.md&quot;&gt;&lt;img alt=&quot;README Ti·∫øng Vi·ªát&quot; src=&quot;https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/de-DE/README.md&quot;&gt;&lt;img alt=&quot;README in Deutsch&quot; src=&quot;https://img.shields.io/badge/German-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/bn-BD/README.md&quot;&gt;&lt;img alt=&quot;README in ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&quot; src=&quot;https://img.shields.io/badge/‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ-d9d9d9&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Dify is an open-source platform for developing LLM applications. Its intuitive interface combines agentic AI workflows, RAG pipelines, agent capabilities, model management, observability features, and more‚Äîallowing you to quickly move from prototype to production.

## Quick start

&gt; Before installing Dify, make sure your machine meets the following minimum system requirements:
&gt;
&gt; - CPU &gt;= 2 Core
&gt; - RAM &gt;= 4 GiB

&lt;br/&gt;

The easiest way to start the Dify server is through [Docker Compose](docker/docker-compose.yaml). Before running Dify with the following commands, make sure that [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) are installed on your machine:

```bash
cd dify
cd docker
cp .env.example .env
docker compose up -d
```

After running, you can access the Dify dashboard in your browser at [http://localhost/install](http://localhost/install) and start the initialization process.

#### Seeking help

Please refer to our [FAQ](https://docs.dify.ai/getting-started/install-self-hosted/faqs) if you encounter problems setting up Dify. Reach out to [the community and us](#community--contact) if you are still having issues.

&gt; If you&#039;d like to contribute to Dify or do additional development, refer to our [guide to deploying from source code](https://docs.dify.ai/getting-started/install-self-hosted/local-source-code)

## Key features

**1. Workflow**:
Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.

**2. Comprehensive model support**:
Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found [here](https://docs.dify.ai/getting-started/readme/model-providers).

![providers-v5](https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3)

**3. Prompt IDE**:
Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.

**4. RAG Pipeline**:
Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.

**5. Agent capabilities**:
You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALL¬∑E, Stable Diffusion and WolframAlpha.

**6. LLMOps**:
Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.

**7. Backend-as-a-Service**:
All of Dify&#039;s offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.

## Using Dify

- **Cloud &lt;br/&gt;**
  We host a [Dify Cloud](https://dify.ai) service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.

- **Self-hosting Dify Community Edition&lt;br/&gt;**
  Quickly get Dify running in your environment with this [starter guide](#quick-start).
  Use our [documentation](https://docs.dify.ai) for further references and more in-depth instructions.

- **Dify for enterprise / organizations&lt;br/&gt;**
  We provide additional enterprise-centric features. [Send us an email](mailto:business@dify.ai?subject=%5BGitHub%5DBusiness%20License%20Inquiry) to discuss your enterprise needs. &lt;br/&gt;

  &gt; For startups and small businesses using AWS, check out [Dify Premium on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6) and deploy it to your own AWS VPC with one click. It&#039;s an affordable AMI offering with the option to create apps with custom logo and branding.

## Staying ahead

Star Dify on GitHub and be instantly notified of new releases.

![star-us](https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4)

## Advanced Setup

### Custom configurations

If you need to customize the configuration, please refer to the comments in our [.env.example](docker/.env.example) file and update the corresponding values in your `.env` file. Additionally, you might need to make adjustments to the `docker-compose.yaml` file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run `docker-compose up -d`. You can find the full list of available environment variables [here](https://docs.dify.ai/getting-started/install-self-hosted/environments).

#### Customizing Suggested Questions

You can now customize the &quot;Suggested Questions After Answer&quot; feature to better fit your use case. For example, to generate longer, more technical questions:

```bash
# In your .env file
SUGGESTED_QUESTIONS_PROMPT=&#039;Please help me predict the five most likely technical follow-up questions a developer would ask. Focus on implementation details, best practices, and architecture considerations. Keep each question between 40-60 characters. Output must be JSON array: [&quot;question1&quot;,&quot;question2&quot;,&quot;question3&quot;,&quot;question4&quot;,&quot;question5&quot;]&#039;
SUGGESTED_QUESTIONS_MAX_TOKENS=512
SUGGESTED_QUESTIONS_TEMPERATURE=0.3
```

See the [Suggested Questions Configuration Guide](docs/suggested-questions-configuration.md) for detailed examples and usage instructions.

### Metrics Monitoring with Grafana

Import the dashboard to Grafana, using Dify&#039;s PostgreSQL database as data source, to monitor metrics in granularity of apps, tenants, messages, and more.

- [Grafana Dashboard by @bowenliang123](https://github.com/bowenliang123/dify-grafana-dashboard)

### Deployment with Kubernetes

If you&#039;d like to configure a highly-available setup, there are community-contributed [Helm Charts](https://helm.sh/) and YAML files which allow Dify to be deployed on Kubernetes.

- [Helm Chart by @LeoQuote](https://github.com/douban/charts/tree/master/charts/dify)
- [Helm Chart by @BorisPolonsky](https://github.com/BorisPolonsky/dify-helm)
- [Helm Chart by @magicsong](https://github.com/magicsong/ai-charts)
- [YAML file by @Winson-030](https://github.com/Winson-030/dify-kubernetes)
- [YAML file by @wyy-holding](https://github.com/wyy-holding/dify-k8s)
- [üöÄ NEW! YAML files (Supports Dify v1.6.0) by @Zhoneym](https://github.com/Zhoneym/DifyAI-Kubernetes)

#### Using Terraform for Deployment

Deploy Dify to Cloud Platform with a single click using [terraform](https://www.terraform.io/)

##### Azure Global

- [Azure Terraform by @nikawang](https://github.com/nikawang/dify-azure-terraform)

##### Google Cloud

- [Google Cloud Terraform by @sotazum](https://github.com/DeNA/dify-google-cloud-terraform)

#### Using AWS CDK for Deployment

Deploy Dify to AWS with [CDK](https://aws.amazon.com/cdk/)

##### AWS

- [AWS CDK by @KevinZhao (EKS based)](https://github.com/aws-samples/solution-for-deploying-dify-on-aws)
- [AWS CDK by @tmokmss (ECS based)](https://github.com/aws-samples/dify-self-hosted-on-aws)

#### Using Alibaba Cloud Computing Nest

Quickly deploy Dify to Alibaba cloud with [Alibaba Cloud Computing Nest](https://computenest.console.aliyun.com/service/instance/create/default?type=user&amp;ServiceName=Dify%E7%A4%BE%E5%8C%BA%E7%89%88)

#### Using Alibaba Cloud Data Management

One-Click deploy Dify to Alibaba Cloud with [Alibaba Cloud Data Management](https://www.alibabacloud.com/help/en/dms/dify-in-invitational-preview/)

#### Deploy to AKS with Azure Devops Pipeline

One-Click deploy Dify to AKS with [Azure Devops Pipeline Helm Chart by @LeoZhang](https://github.com/Ruiruiz30/Dify-helm-chart-AKS)

## Contributing

For those who&#039;d like to contribute code, see our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.

&gt; We are looking for contributors to help translate Dify into languages other than Mandarin or English. If you are interested in helping, please see the [i18n README](https://github.com/langgenius/dify/blob/main/web/i18n-config/README.md) for more information, and leave us a comment in the `global-users` channel of our [Discord Community Server](https://discord.gg/8Tpq4AcN9c).

## Community &amp; contact

- [GitHub Discussion](https://github.com/langgenius/dify/discussions). Best for: sharing feedback and asking questions.
- [GitHub Issues](https://github.com/langgenius/dify/issues). Best for: bugs you encounter using Dify.AI, and feature proposals. See our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
- [Discord](https://discord.gg/FngNHpbcY7). Best for: sharing your applications and hanging out with the community.
- [X(Twitter)](https://twitter.com/dify_ai). Best for: sharing your applications and hanging out with the community.

**Contributors**

&lt;a href=&quot;https://github.com/langgenius/dify/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=langgenius/dify&quot; /&gt;
&lt;/a&gt;

## Star history

[![Star History Chart](https://api.star-history.com/svg?repos=langgenius/dify&amp;type=Date)](https://star-history.com/#langgenius/dify&amp;Date)

## Security disclosure

To protect your privacy, please avoid posting security issues on GitHub. Instead, report issues to security@dify.ai, and our team will respond with detailed answer.

## License

This repository is licensed under the [Dify Open Source License](LICENSE), based on Apache 2.0 with additional conditions.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[tiann/hapi]]></title>
            <link>https://github.com/tiann/hapi</link>
            <guid>https://github.com/tiann/hapi</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:29 GMT</pubDate>
            <description><![CDATA[App for Claude Code / Codex / Gemini / OpenCode, vibe coding anytime, anywhere]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tiann/hapi">tiann/hapi</a></h1>
            <p>App for Claude Code / Codex / Gemini / OpenCode, vibe coding anytime, anywhere</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,785</p>
            <p>Forks: 180</p>
            <p>Stars today: 114 stars today</p>
            <h2>README</h2><pre># HAPI

Run official Claude Code / Codex / Gemini / OpenCode sessions locally and control them remotely through a Web / PWA / Telegram Mini App.

&gt; **Why HAPI?** HAPI is a local-first alternative to Happy. See [Why Not Happy?](docs/guide/why-hapi.md) for the key differences.

## Features

- **Seamless Handoff** - Work locally, switch to remote when needed, switch back anytime. No context loss, no session restart.
- **Native First** - HAPI wraps your AI agent instead of replacing it. Same terminal, same experience, same muscle memory.
- **AFK Without Stopping** - Step away from your desk? Approve AI requests from your phone with one tap.
- **Your AI, Your Choice** - Claude Code, Codex, Gemini, OpenCode‚Äîdifferent models, one unified workflow.
- **Terminal Anywhere** - Run commands from your phone or browser, directly connected to the working machine.
- **Voice Control** - Talk to your AI agent hands-free using the built-in voice assistant.

## Demo

https://github.com/user-attachments/assets/38230353-94c6-4dbe-9c29-b2a2cc457546

## Getting Started

```bash
npx @twsxtd/hapi hub --relay     # start hub with E2E encrypted relay
npx @twsxtd/hapi                 # run claude code
```

`hapi server` remains supported as an alias.

The terminal will display a URL and QR code. Scan the QR code with your phone or open the URL to access.

&gt; The relay uses WireGuard + TLS for end-to-end encryption. Your data is encrypted from your device to your machine.

For self-hosted options (Cloudflare Tunnel, Tailscale), see [Installation](docs/guide/installation.md)

## Docs

- [App](docs/guide/pwa.md)
- [How it Works](docs/guide/how-it-works.md)
- [Voice Assistant](docs/guide/voice-assistant.md)
- [Why HAPI](docs/guide/why-hapi.md)
- [FAQ](docs/guide/faq.md)

## Build from source

```bash
bun install
bun run build:single-exe
```

## Credits

HAPI means &quot;ÂìàÁöÆ&quot; a Chinese transliteration of [Happy](https://github.com/slopus/happy). Great credit to the original project.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[refly-ai/refly]]></title>
            <link>https://github.com/refly-ai/refly</link>
            <guid>https://github.com/refly-ai/refly</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:28 GMT</pubDate>
            <description><![CDATA[The first open-source agent skills builder. Define skills by vibe workflow, run on Claude Code, Cursor, Codex & more. Build Clawdbot ü¶û¬∑ APIs for Lovable ¬∑ Bots for Slack & Lark/Feishu ¬∑ Skills are infrastructure, not prompts.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/refly-ai/refly">refly-ai/refly</a></h1>
            <p>The first open-source agent skills builder. Define skills by vibe workflow, run on Claude Code, Cursor, Codex & more. Build Clawdbot ü¶û¬∑ APIs for Lovable ¬∑ Bots for Slack & Lark/Feishu ¬∑ Skills are infrastructure, not prompts.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,794</p>
            <p>Forks: 679</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>
&lt;img width=&quot;2880&quot; height=&quot;1620&quot; alt=&quot;the first open-source agent skills builder&quot; src=&quot;https://github.com/user-attachments/assets/2609adbb-c8db-4ca4-8404-12eb32d19cf1&quot; /&gt;


# Refly ‚Äî Agent Skills Builder Powered by Vibe Workflow
&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;README.md&quot;&gt;&lt;u&gt;English&lt;/u&gt;&lt;/a&gt; ¬∑ &lt;a href=&quot;README_CN.md&quot;&gt;&lt;u&gt;‰∏≠Êñá&lt;/u&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/refly-ai/refly&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/refly-ai/refly?style=flat&amp;colorA=080f12&amp;colorB=1fa669&amp;logo=github&quot; alt=&quot;GitHub stars&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://refly.ai/workspace&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/refly.ai-007bff?style=flat&amp;colorA=080f12&amp;colorB=007bff&amp;logo=google-chrome&amp;logoColor=white&quot; alt=&quot;Website&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.youtube.com/@refly-ai&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/YouTube-Refly%20AI-FF0000?style=flat&amp;colorA=080f12&amp;colorB=FF0000&amp;logo=youtube&amp;logoColor=white&quot; alt=&quot;YouTube&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.com/invite/YVuYFjFvRC&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2FYVuYFjFvRC%3Fwith_counts%3Dtrue&amp;query=%24.approximate_member_count&amp;suffix=%20members&amp;logo=discord&amp;logoColor=white&amp;label=%20&amp;color=7389D8&amp;labelColor=6A7EC2&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/refly-ai/refly-skills&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/refly--skills-Repo-2ea043?style=flat&amp;colorA=080f12&amp;logo=github&quot; alt=&quot;Refly Skills&quot;&gt;
  &lt;/a&gt;&lt;br&gt;
  &lt;a href=&quot;https://docs.refly.ai/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/docs.refly.ai-Docs-2ea043?style=flat&amp;colorA=080f12&amp;logo=readthedocs&quot; alt=&quot;Docs&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://deepwiki.com/refly-ai/refly&quot;&gt;
    &lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/license-ReflyAI%20License-2ea043?style=flat&amp;colorA=080f12&quot; alt=&quot;License&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://x.com/reflyai&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/%40reflyai-black?style=flat&amp;logo=x&amp;labelColor=%23101419&amp;color=%232d2e30&quot; alt=&quot;X (formerly Twitter) Follow&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;


[APIs for Lovable](#use-case-1-api-integration) ¬∑ [Webhooks for Lark/Feishu](#use-case-2-webhook-for-lark-feishu) ¬∑ [Skills for Claude Code](#use-case-3-skills-for-claude-code) ¬∑ [Build Clawdbot](#use-case-4-build-clawdbot)

Skills are not prompts. They are durable infrastructure.

Refly is the first open-source platform for building stable, atomic, and versioned agent skills. 

&lt;a href=&quot;https://refly.ai/workspace&quot;&gt;&lt;u&gt;Try it Now&lt;/u&gt;&lt;/a&gt; 

---
## Refly Skills

Refly Skills is the official executable skill registry for Refly.

- ‚ö° **Run instantly**: Execute skills in Refly with one click
- üß© **Reusable infrastructure**: Versioned skills, not one-off prompts
- üîå **Export anywhere**: Ship skills to Claude Code or deploy as APIs
- üåç **Community-powered**: Import, fork, and publish your own skills

Explore the registry: &lt;a href=&quot;https://github.com/refly-ai/refly-skills&quot;&gt;&lt;u&gt;Refly Skills Repo&lt;/u&gt;&lt;/a&gt; 

Skills are deterministic agent capabilities‚Äîreusable across workflows, teams, and runtimes.

**TL;DR**: Refly compiles your enterprise SOPs into executable agent skills. Built in 3 minutes. Shipped anywhere.

---
## Quick Start

### Deploy Refly

- üìò **[Self-Deployment Guide](https://docs.refly.ai/community-version/self-deploy/)**  
  *(Recommended for Developers)* Step-by-step guide to deploying Refly on your own server using Docker.

- üîå **[API Reference](https://github.com/refly-ai/refly/tree/main/docs/en/guide/api)**  
  Complete API documentation for integrating Refly into your applications.

&gt; [!TIP]
&gt; Want to explore instantly? Open the hosted workspace: &lt;a href=&quot;https://refly.ai/workspace&quot;&gt;&lt;u&gt;Refly Workspace&lt;/u&gt;&lt;/a&gt; 

### What&#039;s Next?

After deployment, choose your path based on your use case:

| I want to... | Start here | Time |
|-------------|-----------|------|
| üîß **Build my first workflow** | [Create a Workflow](#create-your-first-workflow) | 5 mins |
| üîå **Call workflows via API** | [API Integration](#use-case-1-api-integration) | 10 mins |
| üí¨ **Connect to Lark/Feishu** | [Webhook Setup](#use-case-2-webhook-for-lark-feishu) | 15 mins |
| ü§ñ **Export for Claude Code** | [Export Skills](#use-case-3-skills-for-claude-code) | 15 mins |
| ü¶û  **Build a Clawdbot** | [Build Clawdbot](#use-case-4-build-clawdbot) | 20 mins |
---


## Why Refly?

Most AI Agents fail in production because they rely on &quot;Vibe-coded&quot; scripts and fragile, black-box logic. As the ecosystem moves toward agentic frameworks like Claude Code, AutoGen, and MCP, the bottleneck is no longer the LLM‚Äîit&#039;s the lack of standardized, reliable actions.

Refly bridges the gap between raw APIs and intelligent agents. We allow you to codify messy business logic into structured, version-controlled Agent skills that any agent can invoke with 100% reliability.

**Stop hard-coding tools.** Build modular skills once in Refly&#039;s visual IDE and deploy them as MCP servers, standard APIs, or portable SDKs to any agent framework. &lt;a href=&quot;https://refly.ai/workspace&quot;&gt;&lt;u&gt;Try it Now&lt;/u&gt;&lt;/a&gt; 

---

## Core Capabilities

### üéØ Construct with Vibe (Copilot-led Builder)

Describe your business logic in natural language, and Refly&#039;s Model-Native DSL compiles your intent into a high-performance skill.

- **Intent-Driven Construction**: Describe the work once; Refly turns intent into deterministic, reusable, and composable skills.
- **Efficiency at Scale**: Streamlined DSL optimized for LLMs, ensuring fast execution and significantly lower token costs.
- **3-Minute Deployment**: Transition from a static enterprise SOP to a production-ready agent skill in under 3 minutes.

### ‚ö° Execute with Control (Intervenable Runtime)

Break the &quot;black box&quot; of AI execution with a stateful runtime designed for deterministic reliability.

- **Intervenable Runtime**: Pause, audit, and re-steer agent logic mid-run to ensure 100% operational compliance.
- **Deterministic Guarantees**: Enforce strict business rules that minimize hallucinations and handle failure recovery.

### üöÄ Ship to Production (Unified Agent Stack)

Unify MCP integrations, tools, models, and reusable skills into a single execution layer.

- **Universal Delivery**: Export as APIs for Lovable, webhooks for Slack or Lark/Feishu, or native tools for Claude Code and Cursor.
- **Stable Scheduling**: Run workflows reliably on schedule with managed execution.

### üèõÔ∏è Govern as Assets (Skill Registry)

Transform fragile scripts into governed, shared infrastructure across your organization.

- **Central Skill Registry**: Securely manage, version, and share agent capabilities.
- **Team Workspace Collaboration**: Build together with native version control and audit logs.

---

## Ecosystem

Refly is designed to be the universal bridge between your existing enterprise toolchain and the next generation of agentic runtimes.

### Tooling &amp; Protocols (Inputs)

Bring your own data and logic into Refly with zero friction.

- **3,000+ Native Tools**: Seamlessly integrate with Stripe, Slack, Salesforce, GitHub, etc.

A full list of supported model and tools providers can be found in [provider-catalog.json](./config/provider-catalog.json).

&lt;img width=&quot;3840&quot; height=&quot;1254&quot; alt=&quot;part supported tools integrations in refly&quot; src=&quot;https://github.com/user-attachments/assets/954f43bd-356d-48c4-a3b9-1c0f2e781a43&quot; /&gt;


- **MCP Support**: Full compatibility with Model Context Protocol servers
- **Private Skill Connectors**: Connect to your databases, scripts, and internal systems

### Agent Runtimes &amp; Platforms (Outputs)

Export your deterministic skills to any environment where work happens.

&lt;img width=&quot;2688&quot; height=&quot;1512&quot; alt=&quot;deterministic skills can be exported to cursor, claude code and etc.&quot; src=&quot;https://github.com/user-attachments/assets/23e7a204-4dce-432f-b8bc-65839061d086&quot; /&gt;



- **AI Coding Tools**: Native export for Claude Code and Cursor (coming soon)
- **App Builders**: Power Lovable or custom frontends via stateful APIs
- **Automation Hubs**: Deploy as webhooks for Slack, Lark/Feishu, or Microsoft Teams
- **Agent Frameworks**: Compatible with AutoGen, Manus, LangChain, and custom Python stacks

---
## Why Teams Choose Refly

### For Builders: From Vibe to Production

Most agent tooling today falls into two categories:

- Workflow builders (n8n, Dify): Great for orchestration, but workflows are fragile, trigger-only &quot;black boxes,&quot; and hard to reuse.
- Agent frameworks (LangChain): Powerful primitives, but require heavy engineering, manual boilerplate, and high maintenance to keep running.
Refly eliminates the friction of manual configuration, giving you the fastest path from a &quot;vibe&quot; to a usable agent tool. By using our Streamlined DSL, you get the speed of a GUI with the precision of code.

| Dimension | Legacy Automation &lt;br&gt;&lt;sub&gt;(n8n, Dify)&lt;/sub&gt; | Code-First SDKs &lt;br&gt;&lt;sub&gt;(LangChain)&lt;/sub&gt; | **Refly Skills** |
| :--- | :--- | :--- | :--- |
| **Interaction Depth** | Trigger-only &lt;br&gt;&lt;sub&gt;Black box&lt;/sub&gt; | Programmatic &lt;br&gt;&lt;sub&gt;Code changes&lt;/sub&gt; | **Intervenable runtime**&lt;br&gt;&lt;sub&gt;Steer logic mid-run&lt;/sub&gt; |
| **Construction** | Manual API wiring &amp; JSON | Manual Python/TS boilerplate | **Copilot-led**&lt;br&gt;&lt;sub&gt;Describe intent ‚Üí skills generated&lt;/sub&gt; |
| **Recovery** | Fail = restart from scratch | Debug ‚Üí redeploy ‚Üí rerun | **Hot-fix**&lt;br&gt;&lt;sub&gt;Repair workflows during execution&lt;/sub&gt; |
| **Portability** | Hard to reuse across environments | Framework-specific | **Export everywhere**&lt;br&gt;&lt;sub&gt;To Claude Code, Cursor, Manus&lt;/sub&gt; |
| **Deployment** | Limited function tools | Custom microservices | **Production Ready**&lt;br&gt;&lt;sub&gt;Stateful, validated APIs&lt;/sub&gt; |
### For Enterprise: Scalable Skills Governance

Workflow tools like n8n are great for basic connectivity, and frameworks like LangChain offer powerful primitives ‚Äî but neither provides the governed, production-ready capability layer required for enterprise agent infrastructure.

Refly acts as the Agent skills builder, providing the governance and reliability infrastructure required to deploy AI across the entire organization.

| Enterprise Requirement | Legacy Tools &lt;br&gt;&lt;sub&gt;(Workflow-first)&lt;/sub&gt; | SDKs &lt;br&gt;&lt;sub&gt;(Code-first)&lt;/sub&gt; | **Refly (Skill OS)** |
| :--- | :--- | :--- | :--- |
| **Governance &amp; Reuse** | Templates are copied and&lt;br&gt;&lt;sub&gt;reconfigured per instance&lt;/sub&gt; | No native registry&lt;br&gt;&lt;sub&gt;for sharing logic&lt;/sub&gt; | **Central skill registry**&lt;br&gt;&lt;sub&gt;Versioned, shareable capability assets&lt;/sub&gt; |
| **Operational Reliability** | Trigger-based&lt;br&gt;&lt;sub&gt;limited recovery&lt;/sub&gt; | Custom handling required | **Stateful runtime**&lt;br&gt;&lt;sub&gt;With validation + failure recovery&lt;/sub&gt; |
| **SOP Enforcement** | Workflows drift&lt;br&gt;&lt;sub&gt;across copies&lt;/sub&gt; | Depends on manual&lt;br&gt;&lt;sub&gt;engineering discipline&lt;/sub&gt; | **SOP-grade deterministic skills**&lt;br&gt;&lt;sub&gt;With controlled execution&lt;/sub&gt; |
| **Deployment** | Instance-bound workflows | Code maintained manually&lt;br&gt;&lt;sub&gt;per team&lt;/sub&gt; | **Local-first, on-prem ready**&lt;br&gt;&lt;sub&gt;Open-source infrastructure&lt;/sub&gt; |
| **Total Cost (TCO)** | Overhead grows with&lt;br&gt;&lt;sub&gt;workflow complexity&lt;/sub&gt; | High engineering&lt;br&gt;&lt;sub&gt;maintenance costs&lt;/sub&gt; | **Minimal DSL**&lt;br&gt;&lt;sub&gt;Reduces token spend&lt;/sub&gt; |

---
## Create Your First Workflow

&gt; [!NOTE]
&gt; This section assumes you have completed [self-deployment](https://docs.refly.ai/community-version/self-deploy/) and can access Refly at `http://localhost:5700`

**Step 1: Register and Log In**

1. Open `http://localhost:5700` in your browser
2. Register with your email and password
3. Configure your first model provider:
   - Click the account icon (top right) ‚Üí Settings
   - Add a provider (e.g., OpenAI, Anthropic)
   - Add your first chat model
   - Set it as default

&gt; üìñ Detailed setup with screenshots: [Self-Deployment Guide](https://docs.refly.ai/community-version/self-deploy/#start-using-refly)

**Step 2: Create a Workflow**

1. Click **&quot;New Workflow&quot;** on the home page
2. Choose a template or start from scratch:
   - **Blank Canvas**: Build with visual nodes
   - **Vibe Mode**: Describe your workflow in natural language

**Example - Product Research Workflow**:
```text
1. Add &quot;Web Search&quot; node - searches for product information
2. Add &quot;LLM&quot; node - analyzes search results
3. Add &quot;Output&quot; node - formats the report
4. Connect the nodes
5. Click &quot;Save&quot;
```

&gt; [!TIP]
&gt; If you want the fastest path, start with Vibe Mode and iterate from a template.

**Step 3: Test Your Workflow**

1. Click &quot;Run&quot; button
2. Enter test input (e.g., a product URL)
3. View execution results in real-time
4. Check logs if something fails

---

## Use Cases

### Use Case 1: API Integration

**Goal**: Call your workflow from your application via REST API

**Get Your API Credentials**

1. Go to Settings ‚Üí API Keys
2. Click &quot;Generate New Key&quot;
3. Copy your API key (keep it secure!)

**Make Your First API Call**
```bash
curl -X POST https://your-refly-instance.com/api/v1/workflows/{WORKFLOW_ID}/execute \
  -H &quot;Authorization: Bearer YOUR_API_KEY&quot; \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{
    &quot;input&quot;: {
      &quot;product_url&quot;: &quot;https://example.com/product&quot;
    }
  }&#039;
```

**Response**:
```json
{
  &quot;execution_id&quot;: &quot;exec_abc123&quot;,
  &quot;status&quot;: &quot;running&quot;
}
```

**Check Execution Status**
```bash
curl https://your-refly-instance.com/api/v1/executions/{execution_id} \
  -H &quot;Authorization: Bearer YOUR_API_KEY&quot;
```

üìñ **Full API Documentation**: [API Reference](https://github.com/refly-ai/refly/tree/main/docs/en/guide/api)




### Use Case 2: Webhook for Lark (Feishu)

**Goal**: Trigger your workflow when someone sends a message in Lark

**Prerequisites**

- A Lark workspace with admin access
- A workflow created in Refly

**Setup Steps**

1. **In Refly**:
   - Open your workflow
   - Click &quot;Settings&quot; ‚Üí &quot;Triggers&quot;
   - Enable &quot;Webhook Trigger&quot;
   - Copy the Webhook URL

2. **In Lark/Feishu**:
   - Go to [api.feishu.com/apps](https://open.feishu.cn/app)
   - Create a &quot;Custom App&quot;
   - Navigate to &quot;Event Subscriptions&quot;
   - Paste the Refly Webhook URL into &quot;Request URL&quot;
   - Click &quot;Add Event&quot; and select &quot;Receive Message&quot;
   - Go to &quot;Version Management&quot; and publish the app
     

3. **Test**:
   - In Feishu, find your bot in the search bar and send a message (e.g., `analyze report.pdf`)
   - Your workflow executes and returns results via the webhook


&gt; ‚ö†Ô∏è **Note**: Detailed Lark/Feishu integration guide coming soon. For now, see [API Reference](https://github.com/refly-ai/refly/tree/main/docs/en/guide/api) for webhook configuration.


### Use Case 3: Skills for Claude Code

**Goal**: Publish your Refly workflows as Claude Code skills

**Quick Start**

1. **Install Refly CLI**
```bash
npm install -g @powerformer/refly-cli
```

2. **Install a Skill**
```bash
# Via Refly CLI
refly skill install &lt;skill-id&gt;

#Via npx
npx skills add refly-ai/&lt;skill-name&gt;
```

3. **Publish a Skill**
```bash
refly skill publish &lt;skill-id&gt;
```

The skill is now available in Claude Code, Cursor, and MCP-powered workflows. Agent can invoke your workflow as a tool!


üìñ **Documentation**: &lt;a href=&quot;https://github.com/refly-ai/refly-skills&quot;&gt;&lt;u&gt;Refly Skills&lt;/u&gt;&lt;/a&gt; 

### Use Case 4: Build Clawdbot

üìñ **Tutorial**: &lt;a href=&quot;https://powerformer.feishu.cn/wiki/Gz4swMzn0izknZki3g4coSgvnNe&quot;&gt;&lt;u&gt;Build Clawdbot Tutorial&lt;/u&gt;&lt;/a&gt; 

***

## Community &amp; Support

- üåü **[Star us on GitHub](https://github.com/refly-ai/refly)**: It helps us keep building!
- üí¨ **[Discord](https://discord.com/invite/YVuYFjFvRC)**: Join our community
- üê¶ **[Twitter](https://x.com/reflyai)**: Follow us for updates
- üìñ **[Documentation](https://docs.refly.ai)**: Full guides and tutorials
- üêõ **[Issues](https://github.com/refly-ai/refly/issues)**: Report bugs or request features

---

## Join Us

Join our community to get help, share your experience, and connect with other Refly users: &lt;a href=&quot;https://docs.refly.ai/community/contact-us&quot;&gt;&lt;u&gt;Refly Community&lt;/u&gt;&lt;/a&gt;

---

## Contributing

For those who&#039;d like to contribute code, see our [Contribution Guide](CONTRIBUTING.md). At the same time, please consider supporting Refly by sharing it on social media and at events and conferences.

&gt; We are looking for contributors to help translate Refly into languages other than Mandarin or English. If you are interested in helping, please see the [Contribution Guide](CONTRIBUTING.md) for more information.

---

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=refly-ai/refly&amp;type=Date)](https://star-history.com/#refly-ai/refly&amp;Date)

## License

This repository is licensed under the [ReflyAI Open Source License](LICENSE), which is essentially the Apache 2.0 License with some additional restrictions.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[makenotion/notion-mcp-server]]></title>
            <link>https://github.com/makenotion/notion-mcp-server</link>
            <guid>https://github.com/makenotion/notion-mcp-server</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:27 GMT</pubDate>
            <description><![CDATA[Official Notion MCP Server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/makenotion/notion-mcp-server">makenotion/notion-mcp-server</a></h1>
            <p>Official Notion MCP Server</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,937</p>
            <p>Forks: 488</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># Notion MCP Server

&gt; [!NOTE]
&gt;
&gt; We‚Äôve introduced **Notion MCP**, a remote MCP server with the following improvements:
&gt;
&gt; - Easy installation via standard OAuth. No need to fiddle with JSON or API tokens anymore.
&gt; - Powerful tools tailored to AI agents, including editing pages in Markdown. These tools are designed with optimized token consumption in mind.
&gt;
&gt; Learn more and get started at [Notion MCP documentation](https://developers.notion.com/docs/mcp).
&gt;
&gt; We are prioritizing, and only providing active support for, **Notion MCP** (remote). As a result:
&gt;
&gt; - We may sunset this local MCP server repository in the future.
&gt; - Issues and pull requests here are not actively monitored.
&gt; - Please do not file issues relating to the remote MCP here; instead, contact Notion support.

![notion-mcp-sm](https://github.com/user-attachments/assets/6c07003c-8455-4636-b298-d60ffdf46cd8)

This project implements an [MCP server](https://spec.modelcontextprotocol.io/) for the [Notion API](https://developers.notion.com/reference/intro).

![mcp-demo](https://github.com/user-attachments/assets/e3ff90a7-7801-48a9-b807-f7dd47f0d3d6)

---

## ‚ö†Ô∏è Version 2.0.0 breaking changes

**Version 2.0.0 migrates to the Notion API 2025-09-03** which introduces data sources as the primary abstraction for databases.

### What changed

**Removed tools (3):**

- `post-database-query` - replaced by `query-data-source`
- `update-a-database` - replaced by `update-a-data-source`
- `create-a-database` - replaced by `create-a-data-source`

**New tools (7):**

- `query-data-source` - Query a data source (database) with filters and sorts
- `retrieve-a-data-source` - Get metadata and schema for a data source
- `update-a-data-source` - Update data source properties
- `create-a-data-source` - Create a new data source
- `list-data-source-templates` - List available templates in a data source
- `move-page` - Move a page to a different parent location
- `retrieve-a-database` - Get database metadata including its data source IDs

**Parameter changes:**

- All database operations now use `data_source_id` instead of `database_id`
- Search filter values changed from `[&quot;page&quot;, &quot;database&quot;]` to `[&quot;page&quot;, &quot;data_source&quot;]`
- Page creation now supports both `page_id` and `database_id` parents (for data sources)

### Do I need to migrate?

**No code changes required.** MCP tools are discovered automatically when the server starts. When you upgrade to v2.0.0, AI clients will automatically see the new tool names and parameters. The old database tools are no longer available.

If you have hardcoded tool names or prompts that reference the old database tools, update them to use the new data source tools:

| Old Tool (v1.x) | New Tool (v2.0) | Parameter Change |
| -------------- | --------------- | ---------------- |
| `post-database-query` | `query-data-source` | `database_id` ‚Üí `data_source_id` |
| `update-a-database` | `update-a-data-source` | `database_id` ‚Üí `data_source_id` |
| `create-a-database` | `create-a-data-source` | No change (uses `parent.page_id`) |

&gt; **Note:** `retrieve-a-database` is still available and returns database metadata including the list of data source IDs. Use `retrieve-a-data-source` to get the schema and properties of a specific data source.

**Total tools now: 22** (was 19 in v1.x)

---

### Installation

#### 1. Setting up integration in Notion

Go to [https://www.notion.so/profile/integrations](https://www.notion.so/profile/integrations) and create a new **internal** integration or select an existing one.

![Creating a Notion Integration token](docs/images/integrations-creation.png)

While we limit the scope of Notion API&#039;s exposed (for example, you will not be able to delete databases via MCP), there is a non-zero risk to workspace data by exposing it to LLMs. Security-conscious users may want to further configure the Integration&#039;s _Capabilities_.

For example, you can create a read-only integration token by giving only &quot;Read content&quot; access from the &quot;Configuration&quot; tab:

![Notion Integration Token Capabilities showing Read content checked](docs/images/integrations-capabilities.png)

#### 2. Connecting content to integration

Ensure relevant pages and databases are connected to your integration.

To do this, visit the **Access** tab in your internal integration settings. Edit access and select the pages you&#039;d like to use.

![Integration Access tab](docs/images/integration-access.png)

![Edit integration access](docs/images/page-access-edit.png)

Alternatively, you can grant page access individually. You&#039;ll need to visit the target page, and click on the 3 dots, and select &quot;Connect to integration&quot;.

![Adding Integration Token to Notion Connections](docs/images/connections.png)

#### 3. Adding MCP config to your client

##### Using npm

###### Cursor &amp; Claude

Add the following to your `.cursor/mcp.json` or `claude_desktop_config.json` (MacOS: `~/Library/Application\ Support/Claude/claude_desktop_config.json`)

###### Option 1: Using NOTION_TOKEN (recommended)

```json
{
  &quot;mcpServers&quot;: {
    &quot;notionApi&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;@notionhq/notion-mcp-server&quot;],
      &quot;env&quot;: {
        &quot;NOTION_TOKEN&quot;: &quot;ntn_****&quot;
      }
    }
  }
}
```

###### Option 2: Using OPENAPI_MCP_HEADERS (for advanced use cases)

```json
{
  &quot;mcpServers&quot;: {
    &quot;notionApi&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;@notionhq/notion-mcp-server&quot;],
      &quot;env&quot;: {
        &quot;OPENAPI_MCP_HEADERS&quot;: &quot;{\&quot;Authorization\&quot;: \&quot;Bearer ntn_****\&quot;, \&quot;Notion-Version\&quot;: \&quot;2025-09-03\&quot; }&quot;
      }
    }
  }
}
```

###### Zed

Add the following to your `settings.json`

```json
{
  &quot;context_servers&quot;: {
    &quot;some-context-server&quot;: {
      &quot;command&quot;: {
        &quot;path&quot;: &quot;npx&quot;,
        &quot;args&quot;: [&quot;-y&quot;, &quot;@notionhq/notion-mcp-server&quot;],
        &quot;env&quot;: {
          &quot;OPENAPI_MCP_HEADERS&quot;: &quot;{\&quot;Authorization\&quot;: \&quot;Bearer ntn_****\&quot;, \&quot;Notion-Version\&quot;: \&quot;2025-09-03\&quot; }&quot;
        }
      },
      &quot;settings&quot;: {}
    }
  }
}
```

###### GitHub Copilot CLI

Use the Copilot CLI to interactively add the MCP server:

```bash
/mcp add
```

Alternatively, create or edit the configuration file `~/.copilot/mcp-config.json` and add:

```json
{
  &quot;mcpServers&quot;: {
    &quot;notionApi&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;@notionhq/notion-mcp-server&quot;],
      &quot;env&quot;: {
        &quot;NOTION_TOKEN&quot;: &quot;ntn_****&quot;
      }
    }
  }
}
```

For more information, see the [Copilot CLI documentation](https://docs.github.com/en/copilot/concepts/agents/about-copilot-cli).

##### Using Docker

There are two options for running the MCP server with Docker:

###### Option 1: Using the official Docker Hub image

Add the following to your `.cursor/mcp.json` or `claude_desktop_config.json`

Using NOTION_TOKEN (recommended):

```json
{
  &quot;mcpServers&quot;: {
    &quot;notionApi&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;--rm&quot;,
        &quot;-i&quot;,
        &quot;-e&quot;, &quot;NOTION_TOKEN&quot;,
        &quot;mcp/notion&quot;
      ],
      &quot;env&quot;: {
        &quot;NOTION_TOKEN&quot;: &quot;ntn_****&quot;
      }
    }
  }
}
```

Using OPENAPI_MCP_HEADERS (for advanced use cases):

```json
{
  &quot;mcpServers&quot;: {
    &quot;notionApi&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;--rm&quot;,
        &quot;-i&quot;,
        &quot;-e&quot;, &quot;OPENAPI_MCP_HEADERS&quot;,
        &quot;mcp/notion&quot;
      ],
      &quot;env&quot;: {
        &quot;OPENAPI_MCP_HEADERS&quot;: &quot;{\&quot;Authorization\&quot;:\&quot;Bearer ntn_****\&quot;,\&quot;Notion-Version\&quot;:\&quot;2025-09-03\&quot;}&quot;
      }
    }
  }
}
```

This approach:

- Uses the official Docker Hub image
- Properly handles JSON escaping via environment variables
- Provides a more reliable configuration method

###### Option 2: Building the Docker image locally

You can also build and run the Docker image locally. First, build the Docker image:

```bash
docker compose build
```

Then, add the following to your `.cursor/mcp.json` or `claude_desktop_config.json`

Using NOTION_TOKEN (recommended):

```json
{
  &quot;mcpServers&quot;: {
    &quot;notionApi&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;--rm&quot;,
        &quot;-i&quot;,
        &quot;-e&quot;,
        &quot;NOTION_TOKEN=ntn_****&quot;,
        &quot;notion-mcp-server&quot;
      ]
    }
  }
}
```

Using OPENAPI_MCP_HEADERS (for advanced use cases):

```json
{
  &quot;mcpServers&quot;: {
    &quot;notionApi&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;--rm&quot;,
        &quot;-i&quot;,
        &quot;-e&quot;,
        &quot;OPENAPI_MCP_HEADERS={\&quot;Authorization\&quot;: \&quot;Bearer ntn_****\&quot;, \&quot;Notion-Version\&quot;: \&quot;2025-09-03\&quot;}&quot;,
        &quot;notion-mcp-server&quot;
      ]
    }
  }
}
```

Don&#039;t forget to replace `ntn_****` with your integration secret. Find it from your integration configuration tab:

![Copying your Integration token from the Configuration tab in the developer portal](https://github.com/user-attachments/assets/67b44536-5333-49fa-809c-59581bf5370a)

### Transport options

The Notion MCP Server supports two transport modes:

#### STDIO transport (default)

The default transport mode uses standard input/output for communication. This is the standard MCP transport used by most clients like Claude Desktop.

```bash
# Run with default stdio transport
npx @notionhq/notion-mcp-server

# Or explicitly specify stdio
npx @notionhq/notion-mcp-server --transport stdio
```

#### Streamable HTTP transport

For web-based applications or clients that prefer HTTP communication, you can use the Streamable HTTP transport:

```bash
# Run with Streamable HTTP transport on port 3000 (default)
npx @notionhq/notion-mcp-server --transport http

# Run on a custom port
npx @notionhq/notion-mcp-server --transport http --port 8080

# Run with a custom authentication token
npx @notionhq/notion-mcp-server --transport http --auth-token &quot;your-secret-token&quot;
```

When using Streamable HTTP transport, the server will be available at `http://0.0.0.0:&lt;port&gt;/mcp`.

##### Authentication

The Streamable HTTP transport requires bearer token authentication for security. You have three options:

###### Option 1: Auto-generated token (recommended for development)

```bash
npx @notionhq/notion-mcp-server --transport http
```

The server will generate a secure random token and display it in the console:

```text
Generated auth token: a1b2c3d4e5f6789abcdef0123456789abcdef0123456789abcdef0123456789ab
Use this token in the Authorization header: Bearer a1b2c3d4e5f6789abcdef0123456789abcdef0123456789abcdef0123456789ab
```

###### Option 2: Custom token via command line (recommended for production)

```bash
npx @notionhq/notion-mcp-server --transport http --auth-token &quot;your-secret-token&quot;
```

###### Option 3: Custom token via environment variable (recommended for production)

```bash
AUTH_TOKEN=&quot;your-secret-token&quot; npx @notionhq/notion-mcp-server --transport http
```

The command line argument `--auth-token` takes precedence over the `AUTH_TOKEN` environment variable if both are provided.

##### Making HTTP requests

All requests to the Streamable HTTP transport must include the bearer token in the Authorization header:

```bash
# Example request
curl -H &quot;Authorization: Bearer your-token-here&quot; \
     -H &quot;Content-Type: application/json&quot; \
     -H &quot;mcp-session-id: your-session-id&quot; \
     -d &#039;{&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;initialize&quot;, &quot;params&quot;: {}, &quot;id&quot;: 1}&#039; \
     http://localhost:3000/mcp
```

**Note:** Make sure to set either the `NOTION_TOKEN` environment variable (recommended) or the `OPENAPI_MCP_HEADERS` environment variable with your Notion integration token when using either transport mode.

### Examples

1. Using the following instruction

```text
Comment &quot;Hello MCP&quot; on page &quot;Getting started&quot;
```

   AI will correctly plan two API calls, `v1/search` and `v1/comments`, to achieve the task

1. Similarly, the following instruction will result in a new page named &quot;Notion MCP&quot; added to parent page &quot;Development&quot;

```text
Add a page titled &quot;Notion MCP&quot; to page &quot;Development&quot;
```

1. You may also reference content ID directly

```text
Get the content of page 1a6b35e6e67f802fa7e1d27686f017f2
```

### Development

#### Build &amp; test

```bash
npm run build
npm test
```

#### Execute

```bash
npx -y --prefix /path/to/local/notion-mcp-server @notionhq/notion-mcp-server
```

Testing changes locally in Cursor:

1. Run `npm link` command from repository root to create a machine-global symlink to the `notion-mcp-server` package.
2. Merge the configuration snippet below into Cursor&#039;s `mcp.json` (or other MCP client you want to test with).
3. (Cleanup) run `npm unlink` from repository root.

```json
{
  &quot;mcpServers&quot;: {
    &quot;notion-local-package&quot;: {
      &quot;command&quot;: &quot;notion-mcp-server&quot;,
      &quot;env&quot;: {
        &quot;NOTION_TOKEN&quot;: &quot;ntn_...&quot;
      }
    }
  }
}
```

#### Publish

```bash
npm login
npm publish --access public
```
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ourongxing/newsnow]]></title>
            <link>https://github.com/ourongxing/newsnow</link>
            <guid>https://github.com/ourongxing/newsnow</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:26 GMT</pubDate>
            <description><![CDATA[Elegant reading of real-time and hottest news]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ourongxing/newsnow">ourongxing/newsnow</a></h1>
            <p>Elegant reading of real-time and hottest news</p>
            <p>Language: TypeScript</p>
            <p>Stars: 18,190</p>
            <p>Forks: 5,219</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre>![](/public/og-image.png)

English | [ÁÆÄ‰Ωì‰∏≠Êñá](README.zh-CN.md) | [Êó•Êú¨Ë™û](README.ja-JP.md)

&gt; [!NOTE]
&gt; This is a demo version currently supporting Chinese only. A full-featured version with better customization and English content support will be released later.

**_Elegant reading of real-time and hottest news_**

## Features

- Clean and elegant UI design for optimal reading experience
- Real-time updates on trending news
- GitHub OAuth login with data synchronization
- 30-minute default cache duration (logged-in users can force refresh)
- Adaptive scraping interval (minimum 2 minutes) based on source update frequency to optimize resource usage and prevent IP bans
- support MCP server

```json
{
  &quot;mcpServers&quot;: {
    &quot;newsnow&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;-y&quot;,
        &quot;newsnow-mcp-server&quot;
      ],
      &quot;env&quot;: {
        &quot;BASE_URL&quot;: &quot;https://newsnow.busiyi.world&quot;
      }
    }
  }
}
```
You can change the `BASE_URL` to your own domain.

## Deployment

### Basic Deployment

For deployments without login and caching:

1. Fork this repository
2. Import to platforms like Cloudflare Page or Vercel

### Cloudflare Page Configuration

- Build command: `pnpm run build`
- Output directory: `dist/output/public`

### GitHub OAuth Setup

1. [Create a GitHub App](https://github.com/settings/applications/new)
2. No special permissions required
3. Set callback URL to: `https://your-domain.com/api/oauth/github` (replace `your-domain` with your actual domain)
4. Obtain Client ID and Client Secret

### Environment Variables

Refer to `example.env.server`. For local development, rename it to `.env.server` and configure:

```env
# Github Client ID
G_CLIENT_ID=
# Github Client Secret
G_CLIENT_SECRET=
# JWT Secret, usually the same as Client Secret
JWT_SECRET=
# Initialize database, must be set to true on first run, can be turned off afterward
INIT_TABLE=true
# Whether to enable cache
ENABLE_CACHE=true
```

### Database Support

Supported database connectors: https://db0.unjs.io/connectors
**Cloudflare D1 Database** is recommended.

1. Create D1 database in Cloudflare Worker dashboard
2. Configure database_id and database_name in wrangler.toml
3. If wrangler.toml doesn&#039;t exist, rename example.wrangler.toml and modify configurations
4. Changes will take effect on next deployment

### Docker Deployment

In project root directory:

```sh
docker compose up
```

You can also set Environment Variables in `docker-compose.yml`.

## Development

&gt; [!Note]
&gt; Requires Node.js &gt;= 20

```sh
corepack enable
pnpm i
pnpm dev
```

### Adding Data Sources

Refer to `shared/sources` and `server/sources` directories. The project provides complete type definitions and a clean architecture.

For detailed instructions on how to add new sources, see [CONTRIBUTING.md](CONTRIBUTING.md).

## Roadmap

- Add **multi-language support** (English, Chinese, more to come).
- Improve **personalization options** (category-based news, saved preferences).
- Expand **data sources** to cover global news in multiple languages.

**_release when ready_**
![](https://testmnbbs.oss-cn-zhangjiakou.aliyuncs.com/pic/20250328172146_rec_.gif?x-oss-process=base_webp)

## Contributing

Contributions are welcome! Feel free to submit pull requests or create issues for feature requests and bug reports.

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines on how to contribute, especially for adding new data sources.

## License

[MIT](./LICENSE) ¬© ourongxing
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[CodebuffAI/codebuff]]></title>
            <link>https://github.com/CodebuffAI/codebuff</link>
            <guid>https://github.com/CodebuffAI/codebuff</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:25 GMT</pubDate>
            <description><![CDATA[Generate code from the terminal!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/CodebuffAI/codebuff">CodebuffAI/codebuff</a></h1>
            <p>Generate code from the terminal!</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,908</p>
            <p>Forks: 385</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre># Codebuff

Codebuff is an **open-source AI coding assistant** that edits your codebase through natural language instructions. Instead of using one model for everything, it coordinates specialized agents that work together to understand your project and make precise changes.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./assets/codebuff-vs-claude-code.png&quot; alt=&quot;Codebuff vs Claude Code&quot; width=&quot;400&quot;&gt;
&lt;/div&gt;

Codebuff beats Claude Code at 61% vs 53% on [our evals](evals/README.md) across 175+ coding tasks over multiple open-source repos that simulate real-world tasks.


## How it works

When you ask Codebuff to &quot;add authentication to my API,&quot; it might invoke:

1. A **File Picker Agent** to scan your codebase to understand the architecture and find relevant files
2. A **Planner Agent** to plan which files need changes and in what order
3. An **Editor Agent** to make precise edits
4. A **Reviewer Agent** to validate changes

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./assets/multi-agents.png&quot; alt=&quot;Codebuff Multi-Agents&quot; width=&quot;250&quot;&gt;
&lt;/div&gt;

This multi-agent approach gives you better context understanding, more accurate edits, and fewer errors compared to single-model tools.

## CLI: Install and start coding

Install:

```bash
npm install -g codebuff
```

Run:

```bash
cd your-project
codebuff
```

Then just tell Codebuff what you want and it handles the rest:

- &quot;Fix the SQL injection vulnerability in user registration&quot;
- &quot;Add rate limiting to all API endpoints&quot;
- &quot;Refactor the database connection code for better performance&quot;

Codebuff will find the right files, makes changes across your codebase, and runs tests to make sure nothing breaks.

## Create custom agents

To get started building your own agents, start Codebuff and run the `/init` command:

```bash
codebuff
```

Then inside the CLI:

```
/init
```

This creates:
```
knowledge.md               # Project context for Codebuff
.agents/
‚îî‚îÄ‚îÄ types/                 # TypeScript type definitions
    ‚îú‚îÄ‚îÄ agent-definition.ts
    ‚îú‚îÄ‚îÄ tools.ts
    ‚îî‚îÄ‚îÄ util-types.ts
```

You can write agent definition files that give you maximum control over agent behavior.

Implement your workflows by specifying tools, which agents can be spawned, and prompts. We even have TypeScript generators for more programmatic control.

For example, here&#039;s a `git-committer` agent that creates git commits based on the current git state. Notice that it runs `git diff` and `git log` to analyze changes, but then hands control over to the LLM to craft a meaningful commit message and perform the actual commit.

```typescript
export default {
  id: &#039;git-committer&#039;,
  displayName: &#039;Git Committer&#039;,
  model: &#039;openai/gpt-5-nano&#039;,
  toolNames: [&#039;read_files&#039;, &#039;run_terminal_command&#039;, &#039;end_turn&#039;],

  instructionsPrompt:
    &#039;You create meaningful git commits by analyzing changes, reading relevant files for context, and crafting clear commit messages that explain the &quot;why&quot; behind changes.&#039;,

  async *handleSteps() {
    // Analyze what changed
    yield { tool: &#039;run_terminal_command&#039;, command: &#039;git diff&#039; }
    yield { tool: &#039;run_terminal_command&#039;, command: &#039;git log --oneline -5&#039; }

    // Stage files and create commit with good message
    yield &#039;STEP_ALL&#039;
  },
}
```

## SDK: Run agents in production

Install the [SDK package](https://www.npmjs.com/package/@codebuff/sdk) -- note this is different than the CLI codebuff package.

```bash
npm install @codebuff/sdk
```

Import the client and run agents!

```typescript
import { CodebuffClient } from &#039;@codebuff/sdk&#039;

// 1. Initialize the client
const client = new CodebuffClient({
  apiKey: &#039;your-api-key&#039;,
  cwd: &#039;/path/to/your/project&#039;,
  onError: (error) =&gt; console.error(&#039;Codebuff error:&#039;, error.message),
})

// 2. Do a coding task...
const result = await client.run({
  agent: &#039;base&#039;, // Codebuff&#039;s base coding agent
  prompt: &#039;Add error handling to all API endpoints&#039;,
  handleEvent: (event) =&gt; {
    console.log(&#039;Progress&#039;, event)
  },
})

// 3. Or, run a custom agent!
const myCustomAgent: AgentDefinition = {
  id: &#039;greeter&#039;,
  displayName: &#039;Greeter&#039;,
  model: &#039;openai/gpt-5.1&#039;,
  instructionsPrompt: &#039;Say hello!&#039;,
}
await client.run({
  agent: &#039;greeter&#039;,
  agentDefinitions: [myCustomAgent],
  prompt: &#039;My name is Bob.&#039;,
  customToolDefinitions: [], // Add custom tools too!
  handleEvent: (event) =&gt; {
    console.log(&#039;Progress&#039;, event)
  },
})
```

Learn more about the SDK [here](https://www.npmjs.com/package/@codebuff/sdk).

## Why choose Codebuff

**Custom workflows**: TypeScript generators let you mix AI generation with programmatic control. Agents can spawn subagents, branch on conditions, and run multi-step processes.

**Any model on OpenRouter**: Unlike Claude Code which locks you into Anthropic&#039;s models, Codebuff supports any model available on [OpenRouter](https://openrouter.ai/models) - from Claude and GPT to specialized models like Qwen, DeepSeek, and others. Switch models for different tasks or use the latest releases without waiting for platform updates.

**Reuse any published agent**: Compose existing [published agents](https://www.codebuff.com/store) to get a leg up. Codebuff agents are the new MCP!

**SDK**: Build Codebuff into your applications. Create custom tools, integrate with CI/CD, or embed coding assistance into your products.

## Contributing to Codebuff

We ‚ù§Ô∏è contributions from the community - whether you&#039;re fixing bugs, tweaking our agents, or improving documentation.

**Want to contribute?** Check out our [Contributing Guide](./CONTRIBUTING.md) to get started.

### Running Tests

To run the test suite:

```bash
cd cli
bun test
```

**For interactive E2E testing**, install tmux:

```bash
# macOS
brew install tmux

# Ubuntu/Debian
sudo apt-get install tmux

# Windows (via WSL)
wsl --install
sudo apt-get install tmux
```

See [cli/src/__tests__/README.md](cli/src/__tests__/README.md) for comprehensive testing documentation.

Some ways you can help:

- üêõ **Fix bugs** or add features
- ü§ñ **Create specialized agents** and publish them to the Agent Store
- üìö **Improve documentation** or write tutorials
- üí° **Share ideas** in our [GitHub Issues](https://github.com/CodebuffAI/codebuff/issues)

## Get started

### Install

**CLI**: `npm install -g codebuff`

**SDK**: `npm install @codebuff/sdk`

### Resources

**Documentation**: [codebuff.com/docs](https://codebuff.com/docs)

**Community**: [Discord](https://codebuff.com/discord)

**Issues &amp; Ideas**: [GitHub Issues](https://github.com/CodebuffAI/codebuff/issues)

**Contributing**: [CONTRIBUTING.md](./CONTRIBUTING.md) - Start here to contribute!

**Support**: [support@codebuff.com](mailto:support@codebuff.com)

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=CodebuffAI/codebuff&amp;type=Date)](https://www.star-history.com/#CodebuffAI/codebuff&amp;Date)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[wonderwhy-er/DesktopCommanderMCP]]></title>
            <link>https://github.com/wonderwhy-er/DesktopCommanderMCP</link>
            <guid>https://github.com/wonderwhy-er/DesktopCommanderMCP</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:24 GMT</pubDate>
            <description><![CDATA[This is MCP server for Claude that gives it terminal control, file system search and diff file editing capabilities]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wonderwhy-er/DesktopCommanderMCP">wonderwhy-er/DesktopCommanderMCP</a></h1>
            <p>This is MCP server for Claude that gives it terminal control, file system search and diff file editing capabilities</p>
            <p>Language: TypeScript</p>
            <p>Stars: 5,537</p>
            <p>Forks: 625</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># Desktop Commander MCP
### Search, update, manage files and run terminal commands with AI

[![npm downloads](https://img.shields.io/npm/dw/@wonderwhy-er/desktop-commander)](https://www.npmjs.com/package/@wonderwhy-er/desktop-commander)
[![AgentAudit Verified](https://agentaudit.dev/api/badge/desktop-commander)](https://agentaudit.dev/skills/desktop-commander)
[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/wonderwhy-er/DesktopCommanderMCP)](https://archestra.ai/mcp-catalog/wonderwhy-er__desktopcommandermcp)
[![smithery badge](https://smithery.ai/badge/@wonderwhy-er/desktop-commander)](https://smithery.ai/server/@wonderwhy-er/desktop-commander)
[![Buy Me A Coffee](https://img.shields.io/badge/Buy%20Me%20A%20Coffee-support-yellow.svg)](https://www.buymeacoffee.com/wonderwhyer)


[![Discord](https://img.shields.io/badge/Join%20Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.gg/kQ27sNnZr7)


Work with code and text, run processes, and automate tasks, going far beyond other AI editors - while using host client subscriptions instead of API token costs.

&lt;a href=&quot;https://glama.ai/mcp/servers/zempur9oh4&quot;&gt;
  &lt;img width=&quot;380&quot; height=&quot;200&quot; src=&quot;https://glama.ai/mcp/servers/zempur9oh4/badge&quot; alt=&quot;Desktop Commander MCP&quot; /&gt;
&lt;/a&gt;

## üëã We‚Äôre hiring ‚Äî come build with us: https://desktopcommander.app/careers/

## Table of Contents
- [Features](#features)
- [How to install](#how-to-install)
- [Remote MCP (ChatGPT, Claude Web)](#remote-mcp-chatgpt-claude-web)
- [Getting Started](#getting-started)
- [Usage](#usage)
- [Handling Long-Running Commands](#handling-long-running-commands)
- [Work in Progress and TODOs](#roadmap)
- [Sponsors and Supporters](#support-desktop-commander)
- [Website](#website)
- [Media](#media)
- [Testimonials](#testimonials)
- [Frequently Asked Questions](#frequently-asked-questions)
- [Contributing](#contributing)
- [License](#license)

All of your AI development tools in one place.
Desktop Commander puts all dev tools in one chat.
Execute long-running terminal commands on your computer and manage processes through Model Context Protocol (MCP). Built on top of [MCP Filesystem Server](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem) to provide additional search and replace file editing capabilities.

## Features

- **Remote AI Control** - Use Desktop Commander from ChatGPT, Claude web, and other AI services via [Remote MCP](https://mcp.desktopcommander.app)
- **Enhanced terminal commands with interactive process control**
- **Execute code in memory (Python, Node.js, R) without saving files**
- **Instant data analysis - just ask to analyze CSV/JSON/Excel files**
- **Native Excel file support** - Read, write, edit, and search Excel files (.xlsx, .xls, .xlsm) without external tools
- **PDF support** - Read PDFs with text extraction, create new PDFs from markdown, modify existing PDFs
- **Interact with running processes (SSH, databases, development servers)**
- Execute terminal commands with output streaming
- Command timeout and background execution support
- Process management (list and kill processes)
- Session management for long-running commands
- Server configuration management:
  - Get/set configuration values
  - Update multiple settings at once
  - Dynamic configuration changes without server restart
- Full filesystem operations:
  - Read/write files (text, Excel, PDF)
  - Create/list directories
  - Move files/directories
  - Search files and content (including Excel content)
  - Get file metadata
  - **Negative offset file reading**: Read from end of files using negative offset values (like Unix tail)
- Code editing capabilities:
  - Surgical text replacements for small changes
  - Full file rewrites for major changes
  - Multiple file support
  - Pattern-based replacements
  - vscode-ripgrep based recursive code or text search in folders
- Comprehensive audit logging:
  - All tool calls are automatically logged
  - Log rotation with 10MB size limit
  - Detailed timestamps and arguments

## How to install

Desktop Commander offers multiple installation methods to fit different user needs and technical requirements.

&gt; **üìã Update &amp; Uninstall Information:** Before choosing an installation option, note that **only Options 1, 2, 3, and 6 have automatic updates**. Options 4 and 5 require manual updates. See the sections below for update and uninstall instructions for each option.

### Option 1: Install through npx ‚≠ê **Auto-Updates** **Requires Node.js**
Just run this in terminal:
```
npx @wonderwhy-er/desktop-commander@latest setup
```

For debugging mode (allows Node.js inspector connection):
```
npx @wonderwhy-er/desktop-commander@latest setup --debug
```

**Command line options during setup:**
- `--debug`: Enable debugging mode for Node.js inspector
- `--no-onboarding`: Disable onboarding prompts for new users

Restart Claude if running.

**‚úÖ Auto-Updates:** Yes - automatically updates when you restart Claude  
**üîÑ Manual Update:** Run the setup command again  
**üóëÔ∏è Uninstall:** Run `npx @wonderwhy-er/desktop-commander@latest remove`

### Option 2: Using bash script installer (macOS) ‚≠ê **Auto-Updates** **Installs Node.js if needed**
For macOS users, you can use our automated bash installer which will check your Node.js version, install it if needed, and automatically configure Desktop Commander:
```
curl -fsSL https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install.sh | bash
```
This script handles all dependencies and configuration automatically for a seamless setup experience.

**‚úÖ Auto-Updates:** Yes - requires manual updates  
**üîÑ Manual Update:** Re-run the bash installer command above  
**üóëÔ∏è Uninstall:** Run `npx @wonderwhy-er/desktop-commander@latest remove`

### Option 3: Installing via Smithery ‚≠ê **Auto-Updates** **Requires Node.js**

To install Desktop Commander for Claude Desktop via [Smithery](https://smithery.ai/server/@wonderwhy-er/desktop-commander):

1. **Visit the Smithery page:** https://smithery.ai/server/@wonderwhy-er/desktop-commander
2. **Login to Smithery** if you haven&#039;t already
3. **Select your client** (Claude Desktop) on the right side
4. **Install with the provided key** that appears after selecting your client
5. **Restart Claude Desktop**

The old command-line installation method is no longer supported. Please use the web interface above for the most reliable installation experience.

**‚úÖ Auto-Updates:** Yes - automatically updates when you restart Claude  
**üîÑ Manual Update:** Visit the Smithery page and reinstall  

### Option 4: Add to claude_desktop_config manually ‚≠ê **Auto-Updates** **Requires Node.js**
Add this entry to your claude_desktop_config.json:

- On Mac: `~/Library/Application\ Support/Claude/claude_desktop_config.json`
- On Windows: `%APPDATA%\Claude\claude_desktop_config.json`
- On Linux: `~/.config/Claude/claude_desktop_config.json`

```json
{
  &quot;mcpServers&quot;: {
    &quot;desktop-commander&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;-y&quot;,
        &quot;@wonderwhy-er/desktop-commander@latest&quot;
      ]
    }
  }
}
```
Restart Claude if running.

**‚úÖ Auto-Updates:** Yes - automatically updates when you restart Claude  
**üîÑ Manual Update:** Run the setup command again  
**üóëÔ∏è Uninstall:** Run `npx @wonderwhy-er/desktop-commander@latest remove` or  remove the &quot;desktop-commander&quot; entry from your claude_desktop_config.json file

### ### Option 5: Checkout locally ‚ùå **Manual Updates** **Requires Node.js** ‚ùå **Manual Updates** **Requires Node.js**
1. Clone and build:
```bash
git clone https://github.com/wonderwhy-er/DesktopCommanderMCP.git
cd DesktopCommanderMCP
npm run setup
```
Restart Claude if running.

The setup command will:
- Install dependencies
- Build the server
- Configure Claude&#039;s desktop app
- Add MCP servers to Claude&#039;s config if needed

**‚ùå Auto-Updates:** No - requires manual git updates  
**üîÑ Manual Update:** `cd DesktopCommanderMCP &amp;&amp; git pull &amp;&amp; npm run setup`  
**üóëÔ∏è Uninstall:** Run `npx @wonderwhy-er/desktop-commander@latest remove` or remove the cloned directory and remove MCP server entry from Claude config

### Option 6: Docker Installation üê≥ ‚≠ê **Auto-Updates** **No Node.js Required**

Perfect for users who want complete or partial isolation or don&#039;t have Node.js installed. Desktop Commander runs in a sandboxed Docker container with a persistent work environment.

#### Prerequisites
- [Docker Desktop](https://www.docker.com/products/docker-desktop/) installed **and running**
- Claude Desktop app installed

**Important:** Make sure Docker Desktop is fully started before running the installer.

#### Automated Installation (Recommended)

**macOS/Linux:**
```bash
bash &lt;(curl -fsSL https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.sh)
```

**Windows PowerShell:**
```powershell
# Download and run the installer (one-liner)
iex ((New-Object System.Net.WebClient).DownloadString(&#039;https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.ps1&#039;))
```

The automated installer will:
- Check Docker installation
- Pull the latest Docker image 
- Prompt you to select folders for mounting
- Configure Claude Desktop automatically
- Restart Claude if possible

#### How Docker Persistence Works
Desktop Commander creates a persistent work environment that remembers everything between sessions:
- **Your development tools**: Any software you install (Node.js, Python, databases, etc.) stays installed
- **Your configurations**: Git settings, SSH keys, shell preferences, and other personal configs are preserved  
- **Your work files**: Projects and files in the workspace area persist across restarts
- **Package caches**: Downloaded packages and dependencies are cached for faster future installs

Think of it like having your own dedicated development computer that never loses your setup, but runs safely isolated from your main system.

#### Manual Docker Configuration

If you prefer manual setup, add this to your claude_desktop_config.json:

**Basic setup (no file access):**
```json
{
  &quot;mcpServers&quot;: {
    &quot;desktop-commander-in-docker&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;-i&quot;,
        &quot;--rm&quot;,
        &quot;mcp/desktop-commander:latest&quot;
      ]
    }
  }
}
```

**With folder mounting:**
```json
{
  &quot;mcpServers&quot;: {
    &quot;desktop-commander-in-docker&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;-i&quot;,
        &quot;--rm&quot;,
        &quot;-v&quot;, &quot;/Users/username/Desktop:/mnt/desktop&quot;,
        &quot;-v&quot;, &quot;/Users/username/Documents:/mnt/documents&quot;,
        &quot;mcp/desktop-commander:latest&quot;
      ]
    }
  }
}
```

**Advanced folder mounting:**
```json
{
  &quot;mcpServers&quot;: {
    &quot;desktop-commander-in-docker&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;, &quot;-i&quot;, &quot;--rm&quot;,
        &quot;-v&quot;, &quot;dc-system:/usr&quot;,
        &quot;-v&quot;, &quot;dc-home:/root&quot;, 
        &quot;-v&quot;, &quot;dc-workspace:/workspace&quot;,
        &quot;-v&quot;, &quot;dc-packages:/var&quot;,
        &quot;-v&quot;, &quot;/Users/username/Projects:/mnt/Projects&quot;,
        &quot;-v&quot;, &quot;/Users/username/Downloads:/mnt/Downloads&quot;,
        &quot;mcp/desktop-commander:latest&quot;
      ]
    }
  }
}
```

#### Docker Benefits
‚úÖ **Controlled Isolation:** Runs in sandboxed environment with persistent development state
‚úÖ **No Node.js Required:** Everything included in the container
‚úÖ **Cross-Platform:** Same experience on all operating systems
‚úÖ **Persistent Environment:** Your tools, files, configs, and work survives restarts

**‚úÖ Auto-Updates:** Yes - `latest` tag automatically gets newer versions  
**üîÑ Manual Update:** `docker pull mcp/desktop-commander:latest` then restart Claude  

#### Docker Management Commands

**macOS/Linux:**

Check installation status:
```bash
bash &lt;(curl -fsSL https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.sh) --status
```

Reset all persistent data (removes all installed tools and configs):
```bash
bash &lt;(curl -fsSL https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.sh) --reset
```

**Windows PowerShell:**

Check status:
```powershell
$script = (New-Object System.Net.WebClient).DownloadString(&#039;https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.ps1&#039;); &amp; ([ScriptBlock]::Create(&quot;$script&quot;)) -Status
```

Reset all data:
```powershell
$script = (New-Object System.Net.WebClient).DownloadString(&#039;https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.ps1&#039;); &amp; ([ScriptBlock]::Create(&quot;$script&quot;)) -Reset
```

Show help:
```powershell
$script = (New-Object System.Net.WebClient).DownloadString(&#039;https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.ps1&#039;); &amp; ([ScriptBlock]::Create(&quot;$script&quot;)) -Help
```

Verbose output:
```powershell
$script = (New-Object System.Net.WebClient).DownloadString(&#039;https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.ps1&#039;); &amp; ([ScriptBlock]::Create(&quot;$script&quot;)) -VerboseOutput
```  

#### Troubleshooting Docker Installation
If you broke the Docker container or need a fresh start:
```bash
# Reset and reinstall from scratch
bash &lt;(curl -fsSL https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.sh) --reset &amp;&amp; bash &lt;(curl -fsSL https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.sh)
```
This will completely reset your persistent environment and reinstall everything fresh with exception of not touching mounted folders

## Remote MCP (ChatGPT, Claude Web) üåê

Use Desktop Commander from **ChatGPT**, **Claude web**, and other AI services through their MCP/Connector integrations - no Claude Desktop app required.

**üëâ Get started at [mcp.desktopcommander.app](https://mcp.desktopcommander.app)**

The website provides complete instructions for:
- Installing and running the Remote Device on your computer
- Connecting your AI service (ChatGPT, Claude, etc.)
- Managing your devices and sessions

### How It Works

1. You run a lightweight **Remote Device** on your computer
2. It connects securely to the cloud Remote MCP service
3. Your AI sends commands through the cloud to your device
4. Commands execute locally, results return to your AI
5. **You stay in control** - stop anytime with `Ctrl+C`

### Security

- ‚úÖ Device only runs when you start it
- ‚úÖ Commands execute under your user permissions
- ‚úÖ Secure OAuth authentication and encrypted communication channel

## Updating &amp; Uninstalling Desktop Commander

### Automatic Updates (Options 1, 2, 3, 4 &amp; 6)
**Options 1 (npx), Option 2 (bash installer), 3 (Smithery), 4 (manual config), and 6 (Docker)** automatically update to the latest version whenever you restart Claude. No manual intervention needed.

### Manual Updates (Option 5)
- **Option 5 (local checkout):** `cd DesktopCommanderMCP &amp;&amp; git pull &amp;&amp; npm run setup`

### Uninstalling Desktop Commander
#### ü§ñ Automatic Uninstallation (Recommended)

The easiest way to completely remove Desktop Commander:

```bash
npx @wonderwhy-er/desktop-commander@latest remove
```

This automatic uninstaller will:
- ‚úÖ Remove Desktop Commander from Claude&#039;s MCP server configuration
- ‚úÖ Create a backup of your Claude config before making changes
- ‚úÖ Provide guidance for complete package removal
- ‚úÖ Restore from backup if anything goes wrong

#### üîß Manual Uninstallation

If the automatic uninstaller doesn&#039;t work or you prefer manual removal:

##### Remove from Claude Configuration

1. **Locate your Claude Desktop config file:**
  - **macOS:** `~/Library/Application Support/Claude/claude_desktop_config.json`
  - **Windows:** `%APPDATA%\Claude\claude_desktop_config.json`
  - **Linux:** `~/.config/Claude/claude_desktop_config.json`

2. **Edit the config file:**
  - Open the file in a text editor
  - Find and remove the `&quot;desktop-commander&quot;` entry from the `&quot;mcpServers&quot;` section
  - Save the file

  **Example - Remove this section:**
  ```json
  {
      &quot;desktop-commander&quot;: {
        &quot;command&quot;: &quot;npx&quot;,
        &quot;args&quot;: [&quot;@wonderwhy-er/desktop-commander@latest&quot;]
      }
  }
  ```

Close and restart Claude Desktop to complete the removal.

#### üÜò Troubleshooting

**If automatic uninstallation fails:**
- Use manual uninstallation as a fallback

**If Claude won&#039;t start after uninstalling:**
- Restore the backup config file created by the uninstaller
- Or manually fix the JSON syntax in your claude_desktop_config.json

**Need help?**
- Join our Discord community: https://discord.com/invite/kQ27sNnZr7

## Getting Started

Once Desktop Commander is installed and Claude Desktop is restarted, you&#039;re ready to supercharge your Claude experience!

### üöÄ New User Onboarding

Desktop Commander includes intelligent onboarding to help you discover what&#039;s possible:

**For New Users:** When you&#039;re just getting started (fewer than 10 successful commands), Claude will automatically offer helpful getting-started guidance and practical tutorials after you use Desktop Commander successfully.

**Request Help Anytime:** You can ask for onboarding assistance at any time by simply saying:
- *&quot;Help me get started with Desktop Commander&quot;*
- *&quot;Show me Desktop Commander examples&quot;* 
- *&quot;What can I do with Desktop Commander?&quot;*

Claude will then show you beginner-friendly tutorials and examples, including:
- üìÅ Organizing your Downloads folder automatically
- üìä Analyzing CSV/Excel files with Python
- ‚öôÔ∏è Setting up GitHub Actions CI/CD
- üîç Exploring and understanding codebases
- ü§ñ Running interactive development environments

## Usage

The server provides a comprehensive set of tools organized into several categories:

### Available Tools

| Category | Tool | Description |
|----------|------|-------------|
| **Configuration** | `get_config` | Get the complete server configuration as JSON (includes blockedCommands, defaultShell, allowedDirectories, fileReadLineLimit, fileWriteLineLimit, telemetryEnabled) |
| | `set_config_value` | Set a specific configuration value by key. Available settings: &lt;br&gt;‚Ä¢ `blockedCommands`: Array of shell commands that cannot be executed&lt;br&gt;‚Ä¢ `defaultShell`: Shell to use for commands (e.g., bash, zsh, powershell)&lt;br&gt;‚Ä¢ `allowedDirectories`: Array of filesystem paths the server can access for file operations (‚ö†Ô∏è terminal commands can still access files outside these directories)&lt;br&gt;‚Ä¢ `fileReadLineLimit`: Maximum lines to read at once (default: 1000)&lt;br&gt;‚Ä¢ `fileWriteLineLimit`: Maximum lines to write at once (default: 50)&lt;br&gt;‚Ä¢ `telemetryEnabled`: Enable/disable telemetry (boolean) |
| **Terminal** | `start_process` | Start programs with smart detection of when they&#039;re ready for input |
| | `interact_with_process` | Send commands to running programs and get responses |
| | `read_process_output` | Read output from running processes |
| | `force_terminate` | Force terminate a running terminal session |
| | `list_sessions` | List all active terminal sessions |
| | `list_processes` | List all running processes with detailed information |
| | `kill_process` | Terminate a running process by PID |
| **Filesystem** | `read_file` | Read contents from local filesystem, URLs, Excel files (.xlsx, .xls, .xlsm), and PDFs with line/page-based pagination |
| | `read_multiple_files` | Read multiple files simultaneously |
| | `write_file` | Write file contents with options for rewrite or append mode. Supports Excel files (JSON 2D array format). For PDFs, use `write_pdf` |
| | `write_pdf` | Create new PDF files from markdown or modify existing PDFs (insert/delete pages). Supports HTML/CSS styling and SVG graphics |
| | `create_directory` | Create a new directory or ensure it exists |
| | `list_directory` | Get detailed recursive listing of files and directories (supports depth parameter, default depth=2) |
| | `move_file` | Move or rename files and directories |
| | `start_search` | Start streaming search for files by name or conte

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[DayuanJiang/next-ai-draw-io]]></title>
            <link>https://github.com/DayuanJiang/next-ai-draw-io</link>
            <guid>https://github.com/DayuanJiang/next-ai-draw-io</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:23 GMT</pubDate>
            <description><![CDATA[A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DayuanJiang/next-ai-draw-io">DayuanJiang/next-ai-draw-io</a></h1>
            <p>A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,837</p>
            <p>Forks: 2,313</p>
            <p>Stars today: 184 stars today</p>
            <h2>README</h2><pre># Next AI Draw.io

&lt;div align=&quot;center&quot;&gt;

**AI-Powered Diagram Creation Tool - Chat, Draw, Visualize**

English | [‰∏≠Êñá](./docs/cn/README_CN.md) | [Êó•Êú¨Ë™û](./docs/ja/README_JA.md)

[![TrendShift](https://trendshift.io/api/badge/repositories/15449)](https://next-ai-drawio.jiang.jp/)

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Next.js](https://img.shields.io/badge/Next.js-16.x-black)](https://nextjs.org/)
[![React](https://img.shields.io/badge/React-19.x-61dafb)](https://react.dev/)
[![Sponsor](https://img.shields.io/badge/Sponsor-‚ù§-ea4aaa)](https://github.com/sponsors/DayuanJiang)

[![Live Demo](./public/live-demo-button.svg)](https://next-ai-drawio.jiang.jp/)

&lt;/div&gt;

A Next.js web application that integrates AI capabilities with draw.io diagrams. Create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.

&gt; Note: Thanks to &lt;img src=&quot;https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/doubao-color.png&quot; alt=&quot;&quot; height=&quot;20&quot; /&gt; [ByteDance Doubao](https://www.volcengine.com/activity/newyear-referral?utm_campaign=doubao&amp;utm_content=aidrawio&amp;utm_medium=github&amp;utm_source=coopensrc&amp;utm_term=project) sponsorship, the demo site now uses the powerful K2-thinking model!


https://github.com/user-attachments/assets/9d60a3e8-4a1c-4b5e-acbb-26af2d3eabd1



## Table of Contents
- [Next AI Draw.io](#next-ai-drawio)
  - [Table of Contents](#table-of-contents)
  - [Examples](#examples)
  - [Features](#features)
  - [MCP Server (Preview)](#mcp-server-preview)
    - [Claude Code CLI](#claude-code-cli)
  - [Getting Started](#getting-started)
    - [Try it Online](#try-it-online)
    - [Desktop Application](#desktop-application)
    - [Run with Docker](#run-with-docker)
    - [Installation](#installation)
  - [Deployment](#deployment)
    - [Deploy to EdgeOne Pages](#deploy-to-edgeone-pages)
    - [Deploy on Vercel](#deploy-on-vercel)
    - [Deploy on Cloudflare Workers](#deploy-on-cloudflare-workers)
  - [Multi-Provider Support](#multi-provider-support)
  - [How It Works](#how-it-works)
  - [Support \&amp; Contact](#support--contact)
  - [FAQ](#faq)
  - [Star History](#star-history)

## Examples

Here are some example prompts and their generated diagrams:

&lt;div align=&quot;center&quot;&gt;
&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td colspan=&quot;2&quot; valign=&quot;top&quot; align=&quot;center&quot;&gt;
      &lt;strong&gt;Animated transformer connectors&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Give me a **animated connector** diagram of transformer&#039;s architecture.&lt;/p&gt;
      &lt;img src=&quot;./public/animated_connectors.svg&quot; alt=&quot;Transformer Architecture with Animated Connectors&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;GCP architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a GCP architecture diagram with **GCP icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/gcp_demo.svg&quot; alt=&quot;GCP Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;AWS architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a AWS architecture diagram with **AWS icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/aws_demo.svg&quot; alt=&quot;AWS Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;Azure architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a Azure architecture diagram with **Azure icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/azure_demo.svg&quot; alt=&quot;Azure Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;Cat sketch prompt&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Draw a cute cat for me.&lt;/p&gt;
      &lt;img src=&quot;./public/cat_demo.svg&quot; alt=&quot;Cat Drawing&quot; width=&quot;240&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;

## Features

-   **LLM-Powered Diagram Creation**: Leverage Large Language Models to create and manipulate draw.io diagrams directly through natural language commands
-   **Image-Based Diagram Replication**: Upload existing diagrams or images and have the AI replicate and enhance them automatically
-   **PDF &amp; Text File Upload**: Upload PDF documents and text files to extract content and generate diagrams from existing documents
-   **AI Reasoning Display**: View the AI&#039;s thinking process for supported models (OpenAI o1/o3, Gemini, Claude, etc.)
-   **Diagram History**: Comprehensive version control that tracks all changes, allowing you to view and restore previous versions of your diagrams before the AI editing.
-   **Interactive Chat Interface**: Communicate with AI to refine your diagrams in real-time
-   **Cloud Architecture Diagram Support**: Specialized support for generating cloud architecture diagrams (AWS, GCP, Azure)
-   **Animated Connectors**: Create dynamic and animated connectors between diagram elements for better visualization

## MCP Server (Preview)

&gt; **Preview Feature**: This feature is experimental and may not be stable.

Use Next AI Draw.io with AI agents like Claude Desktop, Cursor, and VS Code via MCP (Model Context Protocol).

```json
{
  &quot;mcpServers&quot;: {
    &quot;drawio&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;@next-ai-drawio/mcp-server@latest&quot;]
    }
  }
}
```

### Claude Code CLI

```bash
claude mcp add drawio -- npx @next-ai-drawio/mcp-server@latest
```

Then ask Claude to create diagrams:
&gt; &quot;Create a flowchart showing user authentication with login, MFA, and session management&quot;

The diagram appears in your browser in real-time!

See the [MCP Server README](./packages/mcp-server/README.md) for VS Code, Cursor, and other client configurations.

## Getting Started

### Try it Online

No installation needed! Try the app directly on our demo site:

[![Live Demo](./public/live-demo-button.svg)](https://next-ai-drawio.jiang.jp/)



&gt; **Bring Your Own API Key**: You can use your own API key to bypass usage limits on the demo site. Click the Settings icon in the chat panel to configure your provider and API key. Your key is stored locally in your browser and is never stored on the server.

### Desktop Application

Download the native desktop app for your platform from the [Releases page](https://github.com/DayuanJiang/next-ai-draw-io/releases):

Supported platforms: Windows, macOS, Linux.

### Run with Docker

[Go to Docker Guide](./docs/en/docker.md)

### Installation

1. Clone the repository:

```bash
git clone https://github.com/DayuanJiang/next-ai-draw-io
cd next-ai-draw-io
npm install
cp env.example .env.local
```

See the [Provider Configuration Guide](./docs/en/ai-providers.md) for detailed setup instructions for each provider.

2. Run the development server:

```bash
npm run dev
```

3. Open [http://localhost:6002](http://localhost:6002) in your browser to see the application.

## Deployment

### Deploy to EdgeOne Pages

You can deploy with one click using [Tencent EdgeOne Pages](https://pages.edgeone.ai/).

Deploy by this button: 

[![Deploy to EdgeOne Pages](https://cdnstatic.tencentcs.com/edgeone/pages/deploy.svg)](https://edgeone.ai/pages/new?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io)

Check out the [Tencent EdgeOne Pages documentation](https://pages.edgeone.ai/document/deployment-overview) for more details.

Additionally, deploying through Tencent EdgeOne Pages will also grant you a [daily free quota for DeepSeek models](https://pages.edgeone.ai/document/edge-ai).

### Deploy on Vercel 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io)

The easiest way to deploy is using [Vercel](https://vercel.com/new), the creators of Next.js. Be sure to **set the environment variables** in the Vercel dashboard as you did in your local `.env.local` file.

See the [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.

### Deploy on Cloudflare Workers

[Go to Cloudflare Deploy Guide](./docs/en/cloudflare-deploy.md)



## Multi-Provider Support

-   [ByteDance Doubao](https://www.volcengine.com/activity/newyear-referral?utm_campaign=doubao&amp;utm_content=aidrawio&amp;utm_medium=github&amp;utm_source=coopensrc&amp;utm_term=project)
-   AWS Bedrock (default)
-   OpenAI
-   Anthropic
-   Google AI
-   Google Vertex AI
-   Azure OpenAI
-   Ollama
-   OpenRouter
-   DeepSeek
-   SiliconFlow
-   ModelScope
-   SGLang
-   Vercel AI Gateway


All providers except AWS Bedrock and OpenRouter support custom endpoints.

üìñ **[Detailed Provider Configuration Guide](./docs/en/ai-providers.md)** - See setup instructions for each provider.

### Server-Side Multi-Model Configuration

Administrators can configure multiple server-side models that are available to all users without requiring personal API keys. Configure via `AI_MODELS_CONFIG` environment variable (JSON string) or `ai-models.json` file.

**Model Requirements**: This task requires strong model capabilities for generating long-form text with strict formatting constraints (draw.io XML). Recommended models include Claude Sonnet 4.5, GPT-5.1, Gemini 3 Pro, and DeepSeek V3.2/R1.

Note that the `claude` series has been trained on draw.io diagrams with cloud architecture logos like AWS, Azure, GCP. So if you want to create cloud architecture diagrams, this is the best choice.


## How It Works

The application uses the following technologies:

-   **Next.js**: For the frontend framework and routing
-   **Vercel AI SDK** (`ai` + `@ai-sdk/*`): For streaming AI responses and multi-provider support
-   **react-drawio**: For diagram representation and manipulation

Diagrams are represented as XML that can be rendered in draw.io. The AI processes your commands and generates or modifies this XML accordingly.


## Support &amp; Contact

**Special thanks to [ByteDance Doubao](https://www.volcengine.com/activity/newyear-referral?utm_campaign=doubao&amp;utm_content=aidrawio&amp;utm_medium=github&amp;utm_source=coopensrc&amp;utm_term=project) for sponsoring the API token usage of the demo site!** Register on the ARK platform to get 500K free tokens for all models!

If you find this project useful, please consider [sponsoring](https://github.com/sponsors/DayuanJiang) to help me host the live demo site!

For support or inquiries, please open an issue on the GitHub repository or contact the maintainer at:

-   Email: me[at]jiang.jp

## FAQ

See [FAQ](./docs/en/FAQ.md) for common issues and solutions.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=DayuanJiang/next-ai-draw-io&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#DayuanJiang/next-ai-draw-io&amp;type=date&amp;legend=top-left)

---
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>