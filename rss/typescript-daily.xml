<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Tue, 12 Aug 2025 00:04:52 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[menloresearch/jan]]></title>
            <link>https://github.com/menloresearch/jan</link>
            <guid>https://github.com/menloresearch/jan</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[Jan is an open source alternative to ChatGPT that runs 100% offline on your computer]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/menloresearch/jan">menloresearch/jan</a></h1>
            <p>Jan is an open source alternative to ChatGPT that runs 100% offline on your computer</p>
            <p>Language: TypeScript</p>
            <p>Stars: 36,178</p>
            <p>Forks: 2,111</p>
            <p>Stars today: 333 stars today</p>
            <h2>README</h2><pre># Jan - Local AI Assistant

![Jan banner](./JanBanner.png)

&lt;p align=&quot;center&quot;&gt;
  &lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt;
  &lt;img alt=&quot;GitHub commit activity&quot; src=&quot;https://img.shields.io/github/commit-activity/m/janhq/jan&quot;/&gt;
  &lt;img alt=&quot;Github Last Commit&quot; src=&quot;https://img.shields.io/github/last-commit/janhq/jan&quot;/&gt;
  &lt;img alt=&quot;Github Contributors&quot; src=&quot;https://img.shields.io/github/contributors/janhq/jan&quot;/&gt;
  &lt;img alt=&quot;GitHub closed issues&quot; src=&quot;https://img.shields.io/github/issues-closed/janhq/jan&quot;/&gt;
  &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1107178041848909847?label=discord&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://jan.ai/docs/quickstart&quot;&gt;Getting Started&lt;/a&gt; 
  - &lt;a href=&quot;https://jan.ai/docs&quot;&gt;Docs&lt;/a&gt; 
  - &lt;a href=&quot;https://github.com/janhq/jan/releases&quot;&gt;Changelog&lt;/a&gt; 
  - &lt;a href=&quot;https://github.com/janhq/jan/issues&quot;&gt;Bug reports&lt;/a&gt; 
  - &lt;a href=&quot;https://discord.gg/AsJ8krTT3N&quot;&gt;Discord&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
‚ö†Ô∏è &lt;b&gt; Jan is currently in Development&lt;/b&gt;: Expect breaking changes and bugs!
&lt;/p&gt;


Jan is a ChatGPT-alternative that runs 100% offline on your device. Our goal is to make it easy for a layperson to download and run LLMs and use AI with **full control** and **privacy**.

Jan is powered by [Cortex](https://github.com/janhq/cortex.cpp), our embeddable local AI engine that runs on any hardware.
From PCs to multi-GPU clusters, Jan &amp; Cortex supports universal architectures:

- [x] NVIDIA GPUs (fast)
- [x] Apple M-series (fast)
- [x] Apple Intel
- [x] Linux Debian
- [x] Windows x64

#### Features:
- [Model Library](https://jan.ai/docs/models/manage-models#add-models) with popular LLMs like Llama, Gemma, Mistral, or Qwen 
- Connect to [Remote AI APIs](https://jan.ai/docs/remote-models/openai) like Groq and OpenRouter
- Local API Server with OpenAI-equivalent API
- [Extensions](https://jan.ai/docs/extensions) for customizing Jan

## Download

&lt;table&gt;
  &lt;tr style=&quot;text-align:center&quot;&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;&lt;b&gt;Version Type&lt;/b&gt;&lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;&lt;b&gt;Windows&lt;/b&gt;&lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;&lt;b&gt;MacOS Universal&lt;/b&gt;&lt;/td&gt;
    &lt;td colspan=&quot;2&quot; style=&quot;text-align:center&quot;&gt;&lt;b&gt;Linux&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr style=&quot;text-align:center&quot;&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;&lt;b&gt;Stable (Recommended)&lt;/b&gt;&lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/latest/win-x64&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/windows.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.exe&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/latest/mac-universal&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/mac.png&#039; style=&quot;height:15px; width: 15px&quot; /&gt;
        &lt;b&gt;jan.dmg&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/latest/linux-amd64-deb&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/linux.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.deb&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/latest/linux-amd64-appimage&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/linux.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.AppImage&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr style=&quot;text-align:center&quot;&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;&lt;b&gt;Beta (Preview)&lt;/b&gt;&lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/beta/win-x64&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/windows.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.exe&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/beta/mac-universal&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/mac.png&#039; style=&quot;height:15px; width: 15px&quot; /&gt;
        &lt;b&gt;jan.dmg&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/beta/linux-amd64-deb&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/linux.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.deb&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/beta/linux-amd64-appimage&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/linux.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.AppImage&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr style=&quot;text-align:center&quot;&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;&lt;b&gt;Nightly Build (Experimental)&lt;/b&gt;&lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/nightly/win-x64&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/windows.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.exe&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/nightly/mac-universal&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/mac.png&#039; style=&quot;height:15px; width: 15px&quot; /&gt;
        &lt;b&gt;jan.dmg&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/nightly/linux-amd64-deb&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/linux.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.deb&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td style=&quot;text-align:center&quot;&gt;
      &lt;a href=&#039;https://app.jan.ai/download/nightly/linux-amd64-appimage&#039;&gt;
        &lt;img src=&#039;https://github.com/janhq/jan/blob/dev/docs/static/img/linux.png&#039; style=&quot;height:14px; width: 14px&quot; /&gt;
        &lt;b&gt;jan.AppImage&lt;/b&gt;
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

Download the latest version of Jan at https://jan.ai/ or visit the [GitHub Releases](https://github.com/janhq/jan/releases) to download any previous release.

## Demo

https://github.com/user-attachments/assets/c3592fa2-c504-4d9d-a885-7e00122a50f3

*Real-time Video: Jan v0.5.7 on a Mac M2, 16GB Sonoma 14.2*

## Quicklinks

### Jan

- [Jan Website](https://jan.ai/)
- [Jan GitHub](https://github.com/janhq/jan)
- [Documentation](https://jan.ai/docs)
- [Jan Changelog](https://jan.ai/changelog)
- [Jan Blog](https://jan.ai/blog)

### Cortex.cpp
Jan is powered by **Cortex.cpp**. It is a C++ command-line interface (CLI) designed as an alternative to [Ollama](https://ollama.com/). By default, it runs on the llama.cpp engine but also supports other engines, including ONNX and TensorRT-LLM, making it a multi-engine platform.


- [Cortex Website](https://cortex.so/)
- [Cortex GitHub](https://github.com/janhq/cortex.cpp)
- [Documentation](https://cortex.so/docs/)
- [Models Library](https://cortex.so/models)
- API Reference: *Under development*
  
## Requirements for running Jan

- **MacOS**: 13 or higher
- **Windows**:
  - Windows 10 or higher
  - To enable GPU support:
    - Nvidia GPU with CUDA Toolkit 11.7 or higher
    - Nvidia driver 470.63.01 or higher
- **Linux**:
  - glibc 2.27 or higher (check with `ldd --version`)
  - gcc 11, g++ 11, cpp 11 or higher, refer to this [link](https://jan.ai/guides/troubleshooting/gpu-not-used/#specific-requirements-for-linux) for more information
  - To enable GPU support:
    - Nvidia GPU with CUDA Toolkit 11.7 or higher
    - Nvidia driver 470.63.01 or higher

## Troubleshooting

As Jan is in development mode, you might get stuck on a some common issues:
- [Troubleshooting a broken build](https://jan.ai/docs/troubleshooting#broken-build)
- [Troubleshooting NVIDIA GPU](https://jan.ai/docs/troubleshooting#troubleshooting-nvidia-gpu)
- [Troubleshooting Something&#039;s Amiss](https://jan.ai/docs/troubleshooting#somethings-amiss)


If you can&#039;t find what you need in our troubleshooting guide, feel free reach out to us for extra help:
1. Copy your [error logs &amp; device specifications](https://jan.ai/docs/troubleshooting#how-to-get-error-logs).
2. Go to our [Discord](https://discord.com/invite/FTk2MvZwJH) &amp; send it to **#üÜò|get-help** channel for further support.

*Check the logs to ensure the information is what you intend to send. Note that we retain your logs for only 24 hours, so report any issues promptly.*
  

## Contributing

Contributions are welcome! Please read the [CONTRIBUTING.md](CONTRIBUTING.md) file

### Pre-requisites

- node &gt;= 20.0.0
- yarn &gt;= 1.22.0
- make &gt;= 3.81

### Instructions

1. **Clone the repository and prepare:**

   ```bash
   git clone https://github.com/janhq/jan
   cd jan
   git checkout -b DESIRED_BRANCH
   ```

2. **Run development and use Jan Desktop**

   ```bash
   make dev
   ```

This will start the development server and open the desktop app.



### For production build

```bash
# Do steps 1 and 2 in the previous section
# Build the app
make build
```

This will build the app MacOS m1/m2 for production (with code signing already done) and put the result in `dist` folder.

## Acknowledgements

Jan builds on top of other open-source projects:

- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [LangChain](https://github.com/langchain-ai)
- [TensorRT](https://github.com/NVIDIA/TensorRT)
- [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM)

## Contact

- Bugs &amp; requests: file a GitHub ticket
- For discussion: join our Discord [here](https://discord.gg/FTk2MvZwJH)
- For business inquiries: email hello@jan.ai 
- For jobs: please email hr@jan.ai

## Trust &amp; Safety

Beware of scams!

- We will never request your personal information.
- Our product is completely free; no paid version exists.
- We do not have a token or ICO.
- We are a [bootstrapped company](https://en.wikipedia.org/wiki/Bootstrapping), and don&#039;t have any external investors (*yet*). We&#039;re open to exploring opportunities with strategic partners want to tackle [our mission](https://jan.ai/about#mission) together.

## License

Jan is free and open source, under the **AGPLv3** license.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[midday-ai/midday]]></title>
            <link>https://github.com/midday-ai/midday</link>
            <guid>https://github.com/midday-ai/midday</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[Invoicing, Time tracking, File reconciliation, Storage, Financial Overview & your own Assistant made for Freelancers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/midday-ai/midday">midday-ai/midday</a></h1>
            <p>Invoicing, Time tracking, File reconciliation, Storage, Financial Overview & your own Assistant made for Freelancers</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,837</p>
            <p>Forks: 914</p>
            <p>Stars today: 130 stars today</p>
            <h2>README</h2><pre>![hero](github.png)

&lt;p align=&quot;center&quot;&gt;
	&lt;h1 align=&quot;center&quot;&gt;&lt;b&gt;Midday&lt;/b&gt;&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;
    Run your business smarter
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://go.midday.ai/anPiuRx&quot;&gt;Discord&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://midday.ai&quot;&gt;Website&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/midday-ai/midday/issues&quot;&gt;Issues&lt;/a&gt;
  &lt;/p&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://go.midday.ai/K7GwMoQ&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Supabase-3ECF8E?style=for-the-badge&amp;logo=supabase&amp;logoColor=white&quot; alt=&quot;Supabase&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## About Midday

Midday is an all-in-one tool designed to help freelancers, contractors, consultants, and solo entrepreneurs manage their business operations more efficiently. It integrates various functions typically scattered across multiple platforms into a single, cohesive system.


## Features

**Time Tracking**: Allows for live time tracking of projects to boost productivity and collaboration, providing insightful project overviews.&lt;br/&gt;
**Invoicing**: An upcoming feature that will enable users to create web-based invoices, collaborate in real-time, and synchronize projects seamlessly.&lt;br/&gt;
**Magic Inbox**: Automatically matches incoming invoices or receipts to the correct transactions, simplifying financial tracking and organization.&lt;br/&gt;
**Vault**: Secure storage for important files like contracts and agreements, keeping everything in one place for easy access‚Äã.&lt;br/&gt;
**Seamless Export**: Facilitates easy export of financial data, packaged neatly in CSV files for accountants.&lt;br/&gt;
**Assistant**: Provides tailored insights into financial situations, helping users understand spending patterns, cut costs, and find documents.&lt;br/&gt;




## Get started

We are working on the documentation to get started with Midday for local development: https://docs.midday.ai

## App Architecture

- Monorepo
- Bun
- React
- TypeScript
- Nextjs
- Supabase
- Shadcn
- Tauri
- Expo
- TailwindCSS

### Hosting

- Supabase (database, storage, realtime, auth)
- Vercel (Website, Dashboard)
- Fly.io (API/tRPC)

### Services

- Trigger.dev (background jobs)
- Resend (Transactional &amp; Marketing)
- Novu (notifications)
- Github Actions (CI/CD)
- GoCardLess (Bank connection EU)
- Plaid (Bank connection in Canada and US)
- Teller (Bank connection in the US)
- OpenPanel (Events and Analytics)
- Polar (Payment processing)
- Typesense (Search)
- Mistral
- OpenAI

## Repo Activity

![Alt](https://repobeats.axiom.co/api/embed/96aae855e5dd87c30d53c1d154b37cf7aa5a89b3.svg &quot;Repobeats analytics image&quot;)

## License

This project is licensed under the **[AGPL-3.0](https://opensource.org/licenses/AGPL-3.0)** for non-commercial use. 

### Commercial Use

For commercial use or deployments requiring a setup fee, please contact us
for a commercial license at [engineer@midday.ai](mailto:engineer@midday.ai).

By using this software, you agree to the terms of the license.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[fastapi/full-stack-fastapi-template]]></title>
            <link>https://github.com/fastapi/full-stack-fastapi-template</link>
            <guid>https://github.com/fastapi/full-stack-fastapi-template</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[Full stack, modern web application template. Using FastAPI, React, SQLModel, PostgreSQL, Docker, GitHub Actions, automatic HTTPS and more.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fastapi/full-stack-fastapi-template">fastapi/full-stack-fastapi-template</a></h1>
            <p>Full stack, modern web application template. Using FastAPI, React, SQLModel, PostgreSQL, Docker, GitHub Actions, automatic HTTPS and more.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 35,871</p>
            <p>Forks: 6,842</p>
            <p>Stars today: 419 stars today</p>
            <h2>README</h2><pre># Full Stack FastAPI Template

&lt;a href=&quot;https://github.com/fastapi/full-stack-fastapi-template/actions?query=workflow%3ATest&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/fastapi/full-stack-fastapi-template/workflows/Test/badge.svg&quot; alt=&quot;Test&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://coverage-badge.samuelcolvin.workers.dev/redirect/fastapi/full-stack-fastapi-template&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://coverage-badge.samuelcolvin.workers.dev/fastapi/full-stack-fastapi-template.svg&quot; alt=&quot;Coverage&quot;&gt;&lt;/a&gt;

## Technology Stack and Features

- ‚ö° [**FastAPI**](https://fastapi.tiangolo.com) for the Python backend API.
    - üß∞ [SQLModel](https://sqlmodel.tiangolo.com) for the Python SQL database interactions (ORM).
    - üîç [Pydantic](https://docs.pydantic.dev), used by FastAPI, for the data validation and settings management.
    - üíæ [PostgreSQL](https://www.postgresql.org) as the SQL database.
- üöÄ [React](https://react.dev) for the frontend.
    - üíÉ Using TypeScript, hooks, Vite, and other parts of a modern frontend stack.
    - üé® [Chakra UI](https://chakra-ui.com) for the frontend components.
    - ü§ñ An automatically generated frontend client.
    - üß™ [Playwright](https://playwright.dev) for End-to-End testing.
    - ü¶á Dark mode support.
- üêã [Docker Compose](https://www.docker.com) for development and production.
- üîí Secure password hashing by default.
- üîë JWT (JSON Web Token) authentication.
- üì´ Email based password recovery.
- ‚úÖ Tests with [Pytest](https://pytest.org).
- üìû [Traefik](https://traefik.io) as a reverse proxy / load balancer.
- üö¢ Deployment instructions using Docker Compose, including how to set up a frontend Traefik proxy to handle automatic HTTPS certificates.
- üè≠ CI (continuous integration) and CD (continuous deployment) based on GitHub Actions.

### Dashboard Login

[![API docs](img/login.png)](https://github.com/fastapi/full-stack-fastapi-template)

### Dashboard - Admin

[![API docs](img/dashboard.png)](https://github.com/fastapi/full-stack-fastapi-template)

### Dashboard - Create User

[![API docs](img/dashboard-create.png)](https://github.com/fastapi/full-stack-fastapi-template)

### Dashboard - Items

[![API docs](img/dashboard-items.png)](https://github.com/fastapi/full-stack-fastapi-template)

### Dashboard - User Settings

[![API docs](img/dashboard-user-settings.png)](https://github.com/fastapi/full-stack-fastapi-template)

### Dashboard - Dark Mode

[![API docs](img/dashboard-dark.png)](https://github.com/fastapi/full-stack-fastapi-template)

### Interactive API Documentation

[![API docs](img/docs.png)](https://github.com/fastapi/full-stack-fastapi-template)

## How To Use It

You can **just fork or clone** this repository and use it as is.

‚ú® It just works. ‚ú®

### How to Use a Private Repository

If you want to have a private repository, GitHub won&#039;t allow you to simply fork it as it doesn&#039;t allow changing the visibility of forks.

But you can do the following:

- Create a new GitHub repo, for example `my-full-stack`.
- Clone this repository manually, set the name with the name of the project you want to use, for example `my-full-stack`:

```bash
git clone git@github.com:fastapi/full-stack-fastapi-template.git my-full-stack
```

- Enter into the new directory:

```bash
cd my-full-stack
```

- Set the new origin to your new repository, copy it from the GitHub interface, for example:

```bash
git remote set-url origin git@github.com:octocat/my-full-stack.git
```

- Add this repo as another &quot;remote&quot; to allow you to get updates later:

```bash
git remote add upstream git@github.com:fastapi/full-stack-fastapi-template.git
```

- Push the code to your new repository:

```bash
git push -u origin master
```

### Update From the Original Template

After cloning the repository, and after doing changes, you might want to get the latest changes from this original template.

- Make sure you added the original repository as a remote, you can check it with:

```bash
git remote -v

origin    git@github.com:octocat/my-full-stack.git (fetch)
origin    git@github.com:octocat/my-full-stack.git (push)
upstream    git@github.com:fastapi/full-stack-fastapi-template.git (fetch)
upstream    git@github.com:fastapi/full-stack-fastapi-template.git (push)
```

- Pull the latest changes without merging:

```bash
git pull --no-commit upstream master
```

This will download the latest changes from this template without committing them, that way you can check everything is right before committing.

- If there are conflicts, solve them in your editor.

- Once you are done, commit the changes:

```bash
git merge --continue
```

### Configure

You can then update configs in the `.env` files to customize your configurations.

Before deploying it, make sure you change at least the values for:

- `SECRET_KEY`
- `FIRST_SUPERUSER_PASSWORD`
- `POSTGRES_PASSWORD`

You can (and should) pass these as environment variables from secrets.

Read the [deployment.md](./deployment.md) docs for more details.

### Generate Secret Keys

Some environment variables in the `.env` file have a default value of `changethis`.

You have to change them with a secret key, to generate secret keys you can run the following command:

```bash
python -c &quot;import secrets; print(secrets.token_urlsafe(32))&quot;
```

Copy the content and use that as password / secret key. And run that again to generate another secure key.

## How To Use It - Alternative With Copier

This repository also supports generating a new project using [Copier](https://copier.readthedocs.io).

It will copy all the files, ask you configuration questions, and update the `.env` files with your answers.

### Install Copier

You can install Copier with:

```bash
pip install copier
```

Or better, if you have [`pipx`](https://pipx.pypa.io/), you can run it with:

```bash
pipx install copier
```

**Note**: If you have `pipx`, installing copier is optional, you could run it directly.

### Generate a Project With Copier

Decide a name for your new project&#039;s directory, you will use it below. For example, `my-awesome-project`.

Go to the directory that will be the parent of your project, and run the command with your project&#039;s name:

```bash
copier copy https://github.com/fastapi/full-stack-fastapi-template my-awesome-project --trust
```

If you have `pipx` and you didn&#039;t install `copier`, you can run it directly:

```bash
pipx run copier copy https://github.com/fastapi/full-stack-fastapi-template my-awesome-project --trust
```

**Note** the `--trust` option is necessary to be able to execute a [post-creation script](https://github.com/fastapi/full-stack-fastapi-template/blob/master/.copier/update_dotenv.py) that updates your `.env` files.

### Input Variables

Copier will ask you for some data, you might want to have at hand before generating the project.

But don&#039;t worry, you can just update any of that in the `.env` files afterwards.

The input variables, with their default values (some auto generated) are:

- `project_name`: (default: `&quot;FastAPI Project&quot;`) The name of the project, shown to API users (in .env).
- `stack_name`: (default: `&quot;fastapi-project&quot;`) The name of the stack used for Docker Compose labels and project name (no spaces, no periods) (in .env).
- `secret_key`: (default: `&quot;changethis&quot;`) The secret key for the project, used for security, stored in .env, you can generate one with the method above.
- `first_superuser`: (default: `&quot;admin@example.com&quot;`) The email of the first superuser (in .env).
- `first_superuser_password`: (default: `&quot;changethis&quot;`) The password of the first superuser (in .env).
- `smtp_host`: (default: &quot;&quot;) The SMTP server host to send emails, you can set it later in .env.
- `smtp_user`: (default: &quot;&quot;) The SMTP server user to send emails, you can set it later in .env.
- `smtp_password`: (default: &quot;&quot;) The SMTP server password to send emails, you can set it later in .env.
- `emails_from_email`: (default: `&quot;info@example.com&quot;`) The email account to send emails from, you can set it later in .env.
- `postgres_password`: (default: `&quot;changethis&quot;`) The password for the PostgreSQL database, stored in .env, you can generate one with the method above.
- `sentry_dsn`: (default: &quot;&quot;) The DSN for Sentry, if you are using it, you can set it later in .env.

## Backend Development

Backend docs: [backend/README.md](./backend/README.md).

## Frontend Development

Frontend docs: [frontend/README.md](./frontend/README.md).

## Deployment

Deployment docs: [deployment.md](./deployment.md).

## Development

General development docs: [development.md](./development.md).

This includes using Docker Compose, custom local domains, `.env` configurations, etc.

## Release Notes

Check the file [release-notes.md](./release-notes.md).

## License

The Full Stack FastAPI Template is licensed under the terms of the MIT license.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[mendableai/firecrawl]]></title>
            <link>https://github.com/mendableai/firecrawl</link>
            <guid>https://github.com/mendableai/firecrawl</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[üî• Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl and extract with a single API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mendableai/firecrawl">mendableai/firecrawl</a></h1>
            <p>üî• Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl and extract with a single API.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 46,646</p>
            <p>Forks: 4,248</p>
            <p>Stars today: 323 stars today</p>
            <h2>README</h2><pre>&lt;h3 align=&quot;center&quot;&gt;
  &lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;
  &lt;img
    src=&quot;https://raw.githubusercontent.com/mendableai/firecrawl/main/img/firecrawl_logo.png&quot;
    height=&quot;200&quot;
  &gt;
&lt;/h3&gt;
&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/mendableai/firecrawl/blob/main/LICENSE&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/github/license/mendableai/firecrawl&quot; alt=&quot;License&quot;&gt;
&lt;/a&gt;
    &lt;a href=&quot;https://pepy.tech/project/firecrawl-py&quot;&gt;
  &lt;img src=&quot;https://static.pepy.tech/badge/firecrawl-py&quot; alt=&quot;Downloads&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://GitHub.com/mendableai/firecrawl/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/github/contributors/mendableai/firecrawl.svg&quot; alt=&quot;GitHub Contributors&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://firecrawl.dev&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Visit-firecrawl.dev-orange&quot; alt=&quot;Visit firecrawl.dev&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div&gt;
  &lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://twitter.com/firecrawl_dev&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Follow%20on%20X-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white&quot; alt=&quot;Follow on X&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/104100957&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Follow%20on%20LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white&quot; alt=&quot;Follow on LinkedIn&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://discord.com/invite/gSmWdAkdwd&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Join%20our%20Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Join our Discord&quot; /&gt;
    &lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

# üî• Firecrawl

Empower your AI apps with clean data from any website. Featuring advanced scraping, crawling, and data extraction capabilities.

_This repository is in development, and we‚Äôre still integrating custom modules into the mono repo. It&#039;s not fully ready for self-hosted deployment yet, but you can run it locally._

## What is Firecrawl?

[Firecrawl](https://firecrawl.dev?ref=github) is an API service that takes a URL, crawls it, and converts it into clean markdown or structured data. We crawl all accessible subpages and give you clean data for each. No sitemap required. Check out our [documentation](https://docs.firecrawl.dev).

_Pst. hey, you, join our stargazers :)_

&lt;a href=&quot;https://github.com/mendableai/firecrawl&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/github/stars/mendableai/firecrawl.svg?style=social&amp;label=Star&amp;maxAge=2592000&quot; alt=&quot;GitHub stars&quot;&gt;
&lt;/a&gt;

## How to use it?

We provide an easy to use API with our hosted version. You can find the playground and documentation [here](https://firecrawl.dev/playground). You can also self host the backend if you&#039;d like.

Check out the following resources to get started:
- [x] **API**: [Documentation](https://docs.firecrawl.dev/api-reference/introduction)
- [x] **SDKs**: [Python](https://docs.firecrawl.dev/sdks/python), [Node](https://docs.firecrawl.dev/sdks/node), [Go](https://docs.firecrawl.dev/sdks/go), [Rust](https://docs.firecrawl.dev/sdks/rust)
- [x] **LLM Frameworks**: [Langchain (python)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/), [Langchain (js)](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl), [Llama Index](https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader), [Crew.ai](https://docs.crewai.com/), [Composio](https://composio.dev/tools/firecrawl/all), [PraisonAI](https://docs.praison.ai/firecrawl/), [Superinterface](https://superinterface.ai/docs/assistants/functions/firecrawl), [Vectorize](https://docs.vectorize.io/integrations/source-connectors/firecrawl)
- [x] **Low-code Frameworks**: [Dify](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl), [Langflow](https://docs.langflow.org/), [Flowise AI](https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl), [Cargo](https://docs.getcargo.io/integration/firecrawl), [Pipedream](https://pipedream.com/apps/firecrawl/)
- [x] **Others**: [Zapier](https://zapier.com/apps/firecrawl/integrations), [Pabbly Connect](https://www.pabbly.com/connect/integrations/firecrawl/)
- [ ] Want an SDK or Integration? Let us know by opening an issue.

To run locally, refer to guide [here](https://github.com/mendableai/firecrawl/blob/main/CONTRIBUTING.md).

### API Key

To use the API, you need to sign up on [Firecrawl](https://firecrawl.dev) and get an API key.

### Features

- [**Scrape**](#scraping): scrapes a URL and get its content in LLM-ready format (markdown, structured data via [LLM Extract](#llm-extraction-beta), screenshot, html)
- [**Crawl**](#crawling): scrapes all the URLs of a web page and return content in LLM-ready format
- [**Map**](#map): input a website and get all the website urls - extremely fast
- [**Search**](#search): search the web and get full content from results
- [**Extract**](#extract): get structured data from single page, multiple pages or entire websites with AI.

### Powerful Capabilities
- **LLM-ready formats**: markdown, structured data, screenshot, HTML, links, metadata
- **The hard stuff**: proxies, anti-bot mechanisms, dynamic content (js-rendered), output parsing, orchestration
- **Customizability**: exclude tags, crawl behind auth walls with custom headers, max crawl depth, etc...
- **Media parsing**: pdfs, docx, images
- **Reliability first**: designed to get the data you need - no matter how hard it is
- **Actions**: click, scroll, input, wait and more before extracting data
- **Batching (New)**: scrape thousands of URLs at the same time with a new async endpoint.

You can find all of Firecrawl&#039;s capabilities and how to use them in our [documentation](https://docs.firecrawl.dev)

### Crawling

Used to crawl a URL and all accessible subpages. This submits a crawl job and returns a job ID to check the status of the crawl.

```bash
curl -X POST https://api.firecrawl.dev/v1/crawl \
    -H &#039;Content-Type: application/json&#039; \
    -H &#039;Authorization: Bearer fc-YOUR_API_KEY&#039; \
    -d &#039;{
      &quot;url&quot;: &quot;https://docs.firecrawl.dev&quot;,
      &quot;limit&quot;: 10,
      &quot;scrapeOptions&quot;: {
        &quot;formats&quot;: [&quot;markdown&quot;, &quot;html&quot;]
      }
    }&#039;
```

Returns a crawl job id and the url to check the status of the crawl.

```json
{
  &quot;success&quot;: true,
  &quot;id&quot;: &quot;123-456-789&quot;,
  &quot;url&quot;: &quot;https://api.firecrawl.dev/v1/crawl/123-456-789&quot;
}
```

### Check Crawl Job

Used to check the status of a crawl job and get its result.

```bash
curl -X GET https://api.firecrawl.dev/v1/crawl/123-456-789 \
  -H &#039;Content-Type: application/json&#039; \
  -H &#039;Authorization: Bearer YOUR_API_KEY&#039;
```

```json
{
  &quot;status&quot;: &quot;completed&quot;,
  &quot;total&quot;: 36,
  &quot;creditsUsed&quot;: 36,
  &quot;expiresAt&quot;: &quot;2024-00-00T00:00:00.000Z&quot;,
  &quot;data&quot;: [
    {
      &quot;markdown&quot;: &quot;[Firecrawl Docs home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/firecrawl/logo/light.svg)!...&quot;,
      &quot;html&quot;: &quot;&lt;!DOCTYPE html&gt;&lt;html lang=\&quot;en\&quot; class=\&quot;js-focus-visible lg:[--scroll-mt:9.5rem]\&quot; data-js-focus-visible=\&quot;\&quot;&gt;...&quot;,
      &quot;metadata&quot;: {
        &quot;title&quot;: &quot;Build a &#039;Chat with website&#039; using Groq Llama 3 | Firecrawl&quot;,
        &quot;language&quot;: &quot;en&quot;,
        &quot;sourceURL&quot;: &quot;https://docs.firecrawl.dev/learn/rag-llama3&quot;,
        &quot;description&quot;: &quot;Learn how to use Firecrawl, Groq Llama 3, and Langchain to build a &#039;Chat with your website&#039; bot.&quot;,
        &quot;ogLocaleAlternate&quot;: [],
        &quot;statusCode&quot;: 200
      }
    }
  ]
}
```

### Scraping

Used to scrape a URL and get its content in the specified formats.

```bash
curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H &#039;Content-Type: application/json&#039; \
    -H &#039;Authorization: Bearer YOUR_API_KEY&#039; \
    -d &#039;{
      &quot;url&quot;: &quot;https://docs.firecrawl.dev&quot;,
      &quot;formats&quot; : [&quot;markdown&quot;, &quot;html&quot;]
    }&#039;
```

Response:

```json
{
  &quot;success&quot;: true,
  &quot;data&quot;: {
    &quot;markdown&quot;: &quot;Launch Week I is here! [See our Day 2 Release üöÄ](https://www.firecrawl.dev/blog/launch-week-i-day-2-doubled-rate-limits)[üí• Get 2 months free...&quot;,
    &quot;html&quot;: &quot;&lt;!DOCTYPE html&gt;&lt;html lang=\&quot;en\&quot; class=\&quot;light\&quot; style=\&quot;color-scheme: light;\&quot;&gt;&lt;body class=\&quot;__variable_36bd41 __variable_d7dc5d font-inter ...&quot;,
    &quot;metadata&quot;: {
      &quot;title&quot;: &quot;Home - Firecrawl&quot;,
      &quot;description&quot;: &quot;Firecrawl crawls and converts any website into clean markdown.&quot;,
      &quot;language&quot;: &quot;en&quot;,
      &quot;keywords&quot;: &quot;Firecrawl,Markdown,Data,Mendable,Langchain&quot;,
      &quot;robots&quot;: &quot;follow, index&quot;,
      &quot;ogTitle&quot;: &quot;Firecrawl&quot;,
      &quot;ogDescription&quot;: &quot;Turn any website into LLM-ready data.&quot;,
      &quot;ogUrl&quot;: &quot;https://www.firecrawl.dev/&quot;,
      &quot;ogImage&quot;: &quot;https://www.firecrawl.dev/og.png?123&quot;,
      &quot;ogLocaleAlternate&quot;: [],
      &quot;ogSiteName&quot;: &quot;Firecrawl&quot;,
      &quot;sourceURL&quot;: &quot;https://firecrawl.dev&quot;,
      &quot;statusCode&quot;: 200
    }
  }
}
```

### Map

Used to map a URL and get urls of the website. This returns most links present on the website.

```bash cURL
curl -X POST https://api.firecrawl.dev/v1/map \
    -H &#039;Content-Type: application/json&#039; \
    -H &#039;Authorization: Bearer YOUR_API_KEY&#039; \
    -d &#039;{
      &quot;url&quot;: &quot;https://firecrawl.dev&quot;
    }&#039;
```

Response:

```json
{
  &quot;status&quot;: &quot;success&quot;,
  &quot;links&quot;: [
    &quot;https://firecrawl.dev&quot;,
    &quot;https://www.firecrawl.dev/pricing&quot;,
    &quot;https://www.firecrawl.dev/blog&quot;,
    &quot;https://www.firecrawl.dev/playground&quot;,
    &quot;https://www.firecrawl.dev/smart-crawl&quot;,
  ]
}
```

#### Map with search

Map with `search` param allows you to search for specific urls inside a website.

```bash cURL
curl -X POST https://api.firecrawl.dev/v1/map \
    -H &#039;Content-Type: application/json&#039; \
    -H &#039;Authorization: Bearer YOUR_API_KEY&#039; \
    -d &#039;{
      &quot;url&quot;: &quot;https://firecrawl.dev&quot;,
      &quot;search&quot;: &quot;docs&quot;
    }&#039;
```

Response will be an ordered list from the most relevant to the least relevant.

```json
{
  &quot;status&quot;: &quot;success&quot;,
  &quot;links&quot;: [
    &quot;https://docs.firecrawl.dev&quot;,
    &quot;https://docs.firecrawl.dev/sdks/python&quot;,
    &quot;https://docs.firecrawl.dev/learn/rag-llama3&quot;,
  ]
}
```

### Search

Search the web and get full content from results

Firecrawl‚Äôs search API allows you to perform web searches and optionally scrape the search results in one operation.

- Choose specific output formats (markdown, HTML, links, screenshots)
- Search the web with customizable parameters (language, country, etc.)
- Optionally retrieve content from search results in various formats
- Control the number of results and set timeouts

```bash
curl -X POST https://api.firecrawl.dev/v1/search \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;Authorization: Bearer fc-YOUR_API_KEY&quot; \
  -d &#039;{
    &quot;query&quot;: &quot;what is firecrawl?&quot;,
    &quot;limit&quot;: 5
  }&#039;
```

#### Response

```json
{
  &quot;success&quot;: true,
  &quot;data&quot;: [
    {
      &quot;url&quot;: &quot;https://firecrawl.dev&quot;,
      &quot;title&quot;: &quot;Firecrawl | Home Page&quot;,
      &quot;description&quot;: &quot;Turn websites into LLM-ready data with Firecrawl&quot;
    },
    {
      &quot;url&quot;: &quot;https://docs.firecrawl.dev&quot;,
      &quot;title&quot;: &quot;Documentation | Firecrawl&quot;,
      &quot;description&quot;: &quot;Learn how to use Firecrawl in your own applications&quot;
    }
  ]
}
```

#### With content scraping

```bash
curl -X POST https://api.firecrawl.dev/v1/search \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;Authorization: Bearer fc-YOUR_API_KEY&quot; \
  -d &#039;{
    &quot;query&quot;: &quot;what is firecrawl?&quot;,
    &quot;limit&quot;: 5,
    &quot;scrapeOptions&quot;: {
      &quot;formats&quot;: [&quot;markdown&quot;, &quot;links&quot;]
    }
  }&#039;
```

### Extract (Beta)

Get structured data from entire websites with a prompt and/or a schema.

You can extract structured data from one or multiple URLs, including wildcards:

Single Page:
Example: https://firecrawl.dev/some-page

Multiple Pages / Full Domain
Example: https://firecrawl.dev/*

When you use /*, Firecrawl will automatically crawl and parse all URLs it can discover in that domain, then extract the requested data.

```bash
curl -X POST https://api.firecrawl.dev/v1/extract \
    -H &#039;Content-Type: application/json&#039; \
    -H &#039;Authorization: Bearer YOUR_API_KEY&#039; \
    -d &#039;{
      &quot;urls&quot;: [
        &quot;https://firecrawl.dev/*&quot;, 
        &quot;https://docs.firecrawl.dev/&quot;, 
        &quot;https://www.ycombinator.com/companies&quot;
      ],
      &quot;prompt&quot;: &quot;Extract the company mission, whether it is open source, and whether it is in Y Combinator from the page.&quot;,
      &quot;schema&quot;: {
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
          &quot;company_mission&quot;: {
            &quot;type&quot;: &quot;string&quot;
          },
          &quot;is_open_source&quot;: {
            &quot;type&quot;: &quot;boolean&quot;
          },
          &quot;is_in_yc&quot;: {
            &quot;type&quot;: &quot;boolean&quot;
          }
        },
        &quot;required&quot;: [
          &quot;company_mission&quot;,
          &quot;is_open_source&quot;,
          &quot;is_in_yc&quot;
        ]
      }
    }&#039;
```

```json
{
  &quot;success&quot;: true,
  &quot;id&quot;: &quot;44aa536d-f1cb-4706-ab87-ed0386685740&quot;,
  &quot;urlTrace&quot;: []
}
```

If you are using the sdks, it will auto pull the response for you:

```json
{
  &quot;success&quot;: true,
  &quot;data&quot;: {
    &quot;company_mission&quot;: &quot;Firecrawl is the easiest way to extract data from the web. Developers use us to reliably convert URLs into LLM-ready markdown or structured data with a single API call.&quot;,
    &quot;supports_sso&quot;: false,
    &quot;is_open_source&quot;: true,
    &quot;is_in_yc&quot;: true
  }
}
```

### LLM Extraction (Beta)

Used to extract structured data from scraped pages.

```bash
curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H &#039;Content-Type: application/json&#039; \
    -H &#039;Authorization: Bearer YOUR_API_KEY&#039; \
    -d &#039;{
      &quot;url&quot;: &quot;https://www.mendable.ai/&quot;,
      &quot;formats&quot;: [&quot;json&quot;],
      &quot;jsonOptions&quot;: {
        &quot;schema&quot;: {
          &quot;type&quot;: &quot;object&quot;,
          &quot;properties&quot;: {
            &quot;company_mission&quot;: {
                      &quot;type&quot;: &quot;string&quot;
            },
            &quot;supports_sso&quot;: {
                      &quot;type&quot;: &quot;boolean&quot;
            },
            &quot;is_open_source&quot;: {
                      &quot;type&quot;: &quot;boolean&quot;
            },
            &quot;is_in_yc&quot;: {
                      &quot;type&quot;: &quot;boolean&quot;
            }
          },
          &quot;required&quot;: [
            &quot;company_mission&quot;,
            &quot;supports_sso&quot;,
            &quot;is_open_source&quot;,
            &quot;is_in_yc&quot;
          ]
        }
      }
    }&#039;
```

```json
{
  &quot;success&quot;: true,
  &quot;data&quot;: {
    &quot;content&quot;: &quot;Raw Content&quot;,
    &quot;metadata&quot;: {
      &quot;title&quot;: &quot;Mendable&quot;,
      &quot;description&quot;: &quot;Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide&quot;,
      &quot;robots&quot;: &quot;follow, index&quot;,
      &quot;ogTitle&quot;: &quot;Mendable&quot;,
      &quot;ogDescription&quot;: &quot;Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide&quot;,
      &quot;ogUrl&quot;: &quot;https://mendable.ai/&quot;,
      &quot;ogImage&quot;: &quot;https://mendable.ai/mendable_new_og1.png&quot;,
      &quot;ogLocaleAlternate&quot;: [],
      &quot;ogSiteName&quot;: &quot;Mendable&quot;,
      &quot;sourceURL&quot;: &quot;https://mendable.ai/&quot;
    },
    &quot;json&quot;: {
      &quot;company_mission&quot;: &quot;Train a secure AI on your technical resources that answers customer and employee questions so your team doesn&#039;t have to&quot;,
      &quot;supports_sso&quot;: true,
      &quot;is_open_source&quot;: false,
      &quot;is_in_yc&quot;: true
    }
  }
}
```

### Extracting without a schema (New)

You can now extract without a schema by just passing a `prompt` to the endpoint. The llm chooses the structure of the data.

```bash
curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H &#039;Content-Type: application/json&#039; \
    -H &#039;Authorization: Bearer YOUR_API_KEY&#039; \
    -d &#039;{
      &quot;url&quot;: &quot;https://docs.firecrawl.dev/&quot;,
      &quot;formats&quot;: [&quot;json&quot;],
      &quot;jsonOptions&quot;: {
        &quot;prompt&quot;: &quot;Extract the company mission from the page.&quot;
      }
    }&#039;
```

### Interacting with the page with Actions (Cloud-only)

Firecrawl allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction.

Here is an example of how to use actions to navigate to google.com, search for Firecrawl, click on the first result, and take a screenshot.

```bash
curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H &#039;Content-Type: application/json&#039; \
    -H &#039;Authorization: Bearer YOUR_API_KEY&#039; \
    -d &#039;{
        &quot;url&quot;: &quot;google.com&quot;,
        &quot;formats&quot;: [&quot;markdown&quot;],
        &quot;actions&quot;: [
            {&quot;type&quot;: &quot;wait&quot;, &quot;milliseconds&quot;: 2000},
            {&quot;type&quot;: &quot;click&quot;, &quot;selector&quot;: &quot;textarea[title=\&quot;Search\&quot;]&quot;},
            {&quot;type&quot;: &quot;wait&quot;, &quot;milliseconds&quot;: 2000},
            {&quot;type&quot;: &quot;write&quot;, &quot;text&quot;: &quot;firecrawl&quot;},
            {&quot;type&quot;: &quot;wait&quot;, &quot;milliseconds&quot;: 2000},
            {&quot;type&quot;: &quot;press&quot;, &quot;key&quot;: &quot;ENTER&quot;},
            {&quot;type&quot;: &quot;wait&quot;, &quot;milliseconds&quot;: 3000},
            {&quot;type&quot;: &quot;click&quot;, &quot;selector&quot;: &quot;h3&quot;},
            {&quot;type&quot;: &quot;wait&quot;, &quot;milliseconds&quot;: 3000},
            {&quot;type&quot;: &quot;screenshot&quot;}
        ]
    }&#039;
```

### Batch Scraping Multiple URLs (New)

You can now batch scrape multiple URLs at the same time. It is very similar to how the /crawl endpoint works. It submits a batch scrape job and returns a job ID to check the status of the batch scrape.

```bash
curl -X POST https://api.firecrawl.dev/v1/batch/scrape \
    -H &#039;Content-Type: application/json&#039; \
    -H &#039;Authorization: Bearer YOUR_API_KEY&#039; \
    -d &#039;{
      &quot;urls&quot;: [&quot;https://docs.firecrawl.dev&quot;, &quot;https://docs.firecrawl.dev/sdks/overview&quot;],
      &quot;formats&quot; : [&quot;markdown&quot;, &quot;html&quot;]
    }&#039;
```



## Using Python SDK

### Installing Python SDK

```bash
pip install firecrawl-py
```

### Crawl a website

```python
from firecrawl.firecrawl import FirecrawlApp
from firecrawl.firecrawl import ScrapeOptions

app = FirecrawlApp(api_key=&quot;fc-YOUR_API_KEY&quot;)

# Scrape a website:
scrape_status = app.scrape_url(
  &#039;https://firecrawl.dev&#039;, 
  formats=[&quot;markdown&quot;, &quot;html&quot;]
)
print(scrape_status)

# Crawl a website:
crawl_status = app.crawl_url(
  &#039;https://firecrawl.dev&#039;,
  limit=100,
  scrape_options=ScrapeOptions(
    formats=[&quot;markdown&quot;, &quot;html&quot;],),
  poll_interval=30
)
print(crawl_status)
```

### Extracting structured data from a URL

With LLM extraction, you can easily extract structured data from any URL. We support pydantic schemas to make it easier for you too. Here is how you to use it:

```python
class ArticleSchema(BaseModel):
    title: str
    points: int 
    by: str
    commentsURL: str

class TopArticlesSchema(BaseModel):
    top: List[ArticleSchema] = Field(..., description=&quot;Top 5 stories&quot;)

json_config = JsonConfig(schema=TopArticlesSchema.model_json_schema())

llm_extraction_result = app.scrape_url(&#039;https://news.ycombinator.com&#039;, formats=[&quot;json&quot;], json=json_config)

print(llm_extraction_result.json)
```

## Using the Node SDK

### Installation

To install the Firecrawl Node SDK, you can use npm:

```bash
npm install @mendable/firecrawl-js
```

### Usage

1. Get an API key from [firecrawl.dev](https://firecrawl.dev)
2. Set the API key as an environment variable named `FIRECRAWL_API_KEY` or pass it as a parameter to the `FirecrawlApp` class.

```js
import FirecrawlApp, { CrawlParams, CrawlStatusResponse } from &#039;@mendable/firecrawl-js&#039;;

const app = new FirecrawlApp({apiKey: &quot;fc-YOUR_API_KEY&quot;});

// Scrape a website
const scrapeResponse = await app.scrapeUrl(&#039;https://firecrawl.dev&#039;, {
  formats: [&#039;markdown&#039;, &#039;html&#039;],
});

if (scrapeResponse) {
  console.log(scrapeResponse)
}

// Crawl a website
const crawlResponse = await app.crawlUrl(&#039;https://firecrawl.dev&#039;, {
  limit: 100,
  scrapeOptions: {
    formats: [&#039;markdown&#039;, &#039;html&#039;],
  }
} satisfies CrawlParams, true, 30) satisfies CrawlStatusResponse;

if (crawlResponse) {
  console.log(crawlResponse)
}
```


### Extracting structured data from a URL

With LLM extraction, you can easily extract structured data from any URL. We support zod schema to make it easier for you too. Here is how to use it:

```js
import FirecrawlApp from &quot;@mendable/firecrawl-js&quot;;
import { z } from &quot;zod&quot;;

const app = new FirecrawlApp({
  apiKey: &quot;fc-YOUR_API_KEY&quot;
});

// Define schema to extract contents into
const schema = z.object({
  top: z
    .array(
      z.object({
        title: z.string(),
        points: z.number(),
        by: z.string(),
        commentsURL: z.string(),
      })
    )
    .length(5)
    .describe(&quot;Top 5 stories on Hacker News&quot;),
});

const scrapeResult = await app

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[umami-software/umami]]></title>
            <link>https://github.com/umami-software/umami</link>
            <guid>https://github.com/umami-software/umami</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[Umami is a modern, privacy-focused alternative to Google Analytics.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/umami-software/umami">umami-software/umami</a></h1>
            <p>Umami is a modern, privacy-focused alternative to Google Analytics.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 29,262</p>
            <p>Forks: 5,350</p>
            <p>Stars today: 1,147 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://content.umami.is/website/images/umami-logo.png&quot; alt=&quot;Umami Logo&quot; width=&quot;100&quot;&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Umami&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Umami is a simple, fast, privacy-focused alternative to Google Analytics.&lt;/i&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/umami-software/umami/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/release/umami-software/umami.svg&quot; alt=&quot;GitHub Release&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/umami-software/umami/blob/master/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/umami-software/umami.svg&quot; alt=&quot;MIT License&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/umami-software/umami/actions&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/umami-software/umami/ci.yml&quot; alt=&quot;Build Status&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://analytics.umami.is/share/LGazGOecbDtaIwDr/umami.is&quot; style=&quot;text-decoration: none;&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Try%20Demo%20Now-Click%20Here-brightgreen&quot; alt=&quot;Umami Demo&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

---

## üöÄ Getting Started

A detailed getting started guide can be found at [umami.is/docs](https://umami.is/docs/).

---

## üõ† Installing from Source

### Requirements

- A server with Node.js version 18.18 or newer
- A database. Umami supports [MariaDB](https://www.mariadb.org/) (minimum v10.5), [MySQL](https://www.mysql.com/) (minimum v8.0) and [PostgreSQL](https://www.postgresql.org/) (minimum v12.14) databases.

### Get the Source Code and Install Packages

```bash
git clone https://github.com/umami-software/umami.git
cd umami
npm install
```

### Configure Umami

Create an `.env` file with the following:

```bash
DATABASE_URL=connection-url
```

The connection URL format:

```bash
postgresql://username:mypassword@localhost:5432/mydb
mysql://username:mypassword@localhost:3306/mydb
```

### Build the Application

```bash
npm run build
```

_The build step will create tables in your database if you are installing for the first time. It will also create a login user with username **admin** and password **umami**._

### Start the Application

```bash
npm run start
```

_By default, this will launch the application on `http://localhost:3000`. You will need to either [proxy](https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/) requests from your web server or change the [port](https://nextjs.org/docs/api-reference/cli#production) to serve the application directly._

---

## üê≥ Installing with Docker

To build the Umami container and start up a Postgres database, run:

```bash
docker compose up -d
```

Alternatively, to pull just the Umami Docker image with PostgreSQL support:

```bash
docker pull docker.umami.is/umami-software/umami:postgresql-latest
```

Or with MySQL support:

```bash
docker pull docker.umami.is/umami-software/umami:mysql-latest
```

---

## üîÑ Getting Updates

To get the latest features, simply do a pull, install any new dependencies, and rebuild:

```bash
git pull
npm install
npm run build
```

To update the Docker image, simply pull the new images and rebuild:

```bash
docker compose pull
docker compose up --force-recreate -d
```

---

## üõü Support

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/umami-software/umami&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/GitHub--blue?style=social&amp;logo=github&quot; alt=&quot;GitHub&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/umami_software&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Twitter--blue?style=social&amp;logo=twitter&quot; alt=&quot;Twitter&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://linkedin.com/company/umami-software&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/LinkedIn--blue?style=social&amp;logo=linkedin&quot; alt=&quot;LinkedIn&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://umami.is/discord&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Discord--blue?style=social&amp;logo=discord&quot; alt=&quot;Discord&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

[release-shield]: https://img.shields.io/github/release/umami-software/umami.svg
[releases-url]: https://github.com/umami-software/umami/releases
[license-shield]: https://img.shields.io/github/license/umami-software/umami.svg
[license-url]: https://github.com/umami-software/umami/blob/master/LICENSE
[build-shield]: https://img.shields.io/github/actions/workflow/status/umami-software/umami/ci.yml
[build-url]: https://github.com/umami-software/umami/actions
[github-shield]: https://img.shields.io/badge/GitHub--blue?style=social&amp;logo=github
[github-url]: https://github.com/umami-software/umami
[twitter-shield]: https://img.shields.io/badge/Twitter--blue?style=social&amp;logo=twitter
[twitter-url]: https://twitter.com/umami_software
[linkedin-shield]: https://img.shields.io/badge/LinkedIn--blue?style=social&amp;logo=linkedin
[linkedin-url]: https://linkedin.com/company/umami-software
[discord-shield]: https://img.shields.io/badge/Discord--blue?style=social&amp;logo=discord
[discord-url]: https://discord.com/invite/4dz4zcXYrQ
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[idosal/git-mcp]]></title>
            <link>https://github.com/idosal/git-mcp</link>
            <guid>https://github.com/idosal/git-mcp</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[Put an end to code hallucinations! GitMCP is a free, open-source, remote MCP server for any GitHub project]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/idosal/git-mcp">idosal/git-mcp</a></h1>
            <p>Put an end to code hallucinations! GitMCP is a free, open-source, remote MCP server for any GitHub project</p>
            <p>Language: TypeScript</p>
            <p>Stars: 4,711</p>
            <p>Forks: 336</p>
            <p>Stars today: 348 stars today</p>
            <h2>README</h2><pre># GitMCP

&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;884&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/2bf3e3df-556c-49c6-ab7b-36c279d53bba&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#-what-is-gitmcp&quot;&gt;What is GitMCP&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#-features&quot;&gt;Features&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#-getting-started&quot;&gt;Getting Started&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#-how-it-works&quot;&gt;How It Works&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#-badge&quot;&gt;Badge&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#-examples&quot;&gt;Examples&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#-faq&quot;&gt;FAQ&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#-privacy&quot;&gt;Privacy&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#-contributing&quot;&gt;Contributing&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#-license&quot;&gt;License&lt;/a&gt;
&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;

[![GitMCP](https://img.shields.io/endpoint?url=https://gitmcp.io/badge/idosal/git-mcp)](https://gitmcp.io/idosal/git-mcp)
[![Twitter Follow](https://img.shields.io/twitter/follow/idosal1?style=social)](https://twitter.com/idosal1)
[![Twitter Follow](https://img.shields.io/twitter/follow/liadyosef?style=social)](https://twitter.com/liadyosef)
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.pulsemcp.com/servers/idosal-git-mcp&quot;&gt;&lt;img src=&quot;https://www.pulsemcp.com/badge/top-pick/idosal-git-mcp&quot; width=&quot;400&quot; alt=&quot;Pulse MCP Badge&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

## ü§î What is GitMCP?
**Stop vibe-hallucinating and start vibe-coding!**

[GitMCP](https://gitmcp.io) is a free, open-source, remote [Model Context Protocol (MCP)](https://docs.anthropic.com/en/docs/agents-and-tools/mcp) server that transforms **any** GitHub project (repositories or GitHub pages) into a documentation hub. It enables AI tools like Cursor to access up-to-date documentation and code, even if the LLM has never encountered them, thereby eliminating code hallucinations seamlessly.

GitMCP supports **two flavors** -

*   **Specific Repository (`gitmcp.io/{owner}/{repo}` or `{owner}.gitmcp.io/{repo}`):** Use these when you primarily work with a select number of libraries. This ensures your AI assistant always targets the correct project, enhancing security and relevance by preventing access to unintended repositories.
*   **Generic Server (`gitmcp.io/docs`):** Use this for maximum flexibility when you need to switch between different repositories frequently. The AI assistant will prompt you (or decide based on context) which repository to access for each request. Be mindful that this relies on correctly identifying the target repository each time.

**With GitMCP:**

*   AI assistants access the *latest* documentation and code directly from the source.
*   Get accurate API usage and reliable code examples.
*   Work effectively even with niche, new, or rapidly changing libraries.
*   Significantly reduced hallucinations and improved code correctness.

For example, this side-by-side comparison shows the result for the same one-shot prompt in Cursor when creating a [three.js](https://github.com/mrdoob/three.js) scene -

https://github.com/user-attachments/assets/fbf1b4a7-f9f0-4c0e-831c-4d64faae2c45

## ‚ú® Features

- üòé **Latest Documentation on ANY GitHub Project**: Grant your AI assistant seamless access to the GitHub project&#039;s documentation and code. The built-in smart search capabilities help find exactly what the AI needs without using too many tokens!
- üß† **No More Hallucinations**: With GitMCP, your AI assistant can provide accurate and relevant answers to your questions.
- ‚òÅÔ∏è **Zero Setup**: GitMCP runs in the cloud. Simply add the chosen GitMCP URL as an MCP server in your IDE ‚Äî no downloads, installations, signups, or changes are required.
- üí¨ **Embedded Chat**: Start quickly by chatting directly with the repository&#039;s documentation through our in-browser chat!
- ‚úÖ **Open, Free, and Private**: GitMCP is open-source and completely free to use. It doesn&#039;t collect personal information or store queries. You can even self-host it!

&lt;video src=&quot;https://github.com/user-attachments/assets/2c3afaf9-6c08-436e-9efd-db8710554430&quot;&gt;&lt;/video&gt;

## üöÄ Getting Started

Using GitMCP is easy! Simply follow these steps:

### Step 1: Choose the type of server you want

Choose one of these URL formats depending on what you want to connect to:

- For GitHub repositories: `gitmcp.io/{owner}/{repo}`
- For GitHub Pages sites: `{owner}.gitmcp.io/{repo}`
- For a generic tool that supports any repository (dynamic): `gitmcp.io/docs`

Replace `{owner}` with the GitHub username or organization name, and `{repo}` with the repository name.

For your convenience, you can also use the conversion tool on the landing page to format the GitHub URL into an MCP URL!

### Step 2: Connect your AI assistant

Select your AI assistant from the options below and follow the configuration instructions:

#### Connecting Cursor

Update your Cursor configuration file at `~/.cursor/mcp.json`:
   ```json
   {
     &quot;mcpServers&quot;: {
       &quot;gitmcp&quot;: {
         &quot;url&quot;: &quot;https://gitmcp.io/{owner}/{repo}&quot;
       }
     }
   }
   ```

#### Connecting Claude Desktop

1. In Claude Desktop, go to Settings &gt; Developer &gt; Edit Config
2. Replace the configuration with:
   ```json
   {
     &quot;mcpServers&quot;: {
       &quot;gitmcp&quot;: {
         &quot;command&quot;: &quot;npx&quot;,
         &quot;args&quot;: [
           &quot;mcp-remote&quot;,
           &quot;https://gitmcp.io/{owner}/{repo}&quot;
         ]
       }
     }
   }
   ```

#### Connecting Windsurf

Update your Windsurf configuration file at `~/.codeium/windsurf/mcp_config.json`:
   ```json
   {
     &quot;mcpServers&quot;: {
       &quot;gitmcp&quot;: {
         &quot;serverUrl&quot;: &quot;https://gitmcp.io/{owner}/{repo}&quot;
       }
     }
   }
   ```

#### Connecting VSCode

Update your VSCode configuration file at `.vscode/mcp.json`:
   ```json
   {
     &quot;servers&quot;: {
       &quot;gitmcp&quot;: {
         &quot;type&quot;: &quot;sse&quot;,
         &quot;url&quot;: &quot;https://gitmcp.io/{owner}/{repo}&quot;
       }
     }
   }
   ```

#### Connecting Cline

Update your Cline configuration file at `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`:
   ```json
   {
     &quot;mcpServers&quot;: {
       &quot;gitmcp&quot;: {
         &quot;url&quot;: &quot;https://gitmcp.io/{owner}/{repo}&quot;,
         &quot;disabled&quot;: false,
         &quot;autoApprove&quot;: []
       }
     }
   }
   ```

#### Connecting Highlight AI

1. Open Highlight AI and click the plugins icon (@ symbol) in the sidebar
2. Click **Installed Plugins** at the top of the sidebar
3. Select **Custom Plugin**
4. Click **Add a plugin using a custom SSE URL**

Plugin name: `gitmcp`
SSE URL: `https://gitmcp.io/{owner}/{repo}`

For more details on adding custom MCP servers to HighlightAI, refer to [the documentation](https://docs.highlightai.com/learn/developers/plugins/custom-plugins-setup).

#### Connecting Augment Code

1. Open Augment Code settings
2. Navigate to the MCP section
3. Add a new MCP server with the following details:

Name the MCP server: `git-mcp Docs`

Use this command:
```bash
npx mcp-remote https://gitmcp.io/{owner}/{repo}
```

Or use the following configuration:
```json
{
  &quot;mcpServers&quot;: {
    &quot;git-mcp Docs&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;mcp-remote&quot;,
        &quot;https://gitmcp.io/{owner}/{repo}&quot;
      ]
    }
  }
}
```

#### Connecting Msty AI
1. Open Msty Studio
2. Go to Tools &gt; Import Tools from JSON Clipboard
3. Paste the following configuration:

```json
{
  &quot;mcpServers&quot;: {
    &quot;git-mcp Docs&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;mcp-remote&quot;,
        &quot;https://gitmcp.io/{owner}/{repo}&quot;
      ]
    }
  }
}
```

For more details on configuring MCP servers in Augment Code, visit [the Augment Code documentation](https://docs.augmentcode.com/setup-augment/mcp).

&gt; **Note:** Remember to replace `{owner}` and `{repo}` with the actual GitHub username/organization and repository name. You can also use the dynamic endpoint `https://gitmcp.io/docs` to allow your AI to access any repository on demand.

## ‚öô How It Works

GitMCP connects your AI assistant to GitHub repositories using the Model Context Protocol (MCP), a standard that lets AI tools request additional information from external sources.

What happens when you use GitMCP:

1. **You provide the GitMCP URL** to your AI assistant (e.g., `gitmcp.io/microsoft/typescript`). GitMCP exposes tools like documentation fetching, smart search, code search, etc.
2. **Prompt the AI assistant** on documentation/code-related questions.
3. **Your AI sends requests** to GitMCP to use its tools (with your approval).
4. **GitMCP executes the AI&#039;s request** and returns the requested data.
5. **Your AI receives the information** and generates a more accurate, grounded response without hallucinations.

### Supported Documentation

GitMCP currently supports the following documents (in order of priority):
1. [llms.txt](https://llmstxt.org)
2. AI-optimized version of the project&#039;s documentation
3. `README.md`/root

## üí° Examples

Here are some examples of how to use GitMCP with different AI assistants and repositories:

### Example 1: Using Windsurf with a specific repository

For the GitHub repository `https://github.com/microsoft/playwright-mcp`, add `https://gitmcp.io/microsoft/playwright-mcp` as an MCP server to Windsurf.

**Prompt to Claude:**
&gt; &quot;How do I use the Playwright MCP&quot;

Windsurf will pull the relevant documentation from GitMCP to implement the memory feature correctly.

### Example 2: Using Cursor with a GitHub Pages site

For the GitHub Pages site `langchain-ai.github.io/langgraph`, add `https://langchain-ai.gitmcp.io/langgraph` as an MCP server to Cursor.

**Prompt to Cursor:**
&gt; &quot;Add memory to my LangGraph agent&quot;

Cursor will pull the relevant documentation and code from GitMCP to correctly implement the memory feature.

### Example 3: Using Claude Desktop with the dynamic endpoint

You don&#039;t have to pick specific repositories. The generic `gitmcp.io/docs` endpoint allows AI to pick the GitHub project on the fly!

**Prompt to any AI assistant:**
&gt; &quot;I want to learn about the OpenAI Whisper speech recognition model. Explain how it works.

Claude will pull the data from GitMCP and answer the question.

## üõ†Ô∏è Tools

GitMCP provides AI assistants with several valuable tools to help them access, understand, and query GitHub repositories.

### `fetch_&lt;repo-name&gt;_documentation`

This tool gets the primary documentation from a GitHub repository. It works by retrieving relevant documentation (e.g., `llms.txt`). This gives the AI a good overview of what the project is about

**When it&#039;s useful:** For general questions about a project&#039;s purpose, features, or how to get started

### `search_&lt;repo-name&gt;_documentation`

This tool lets the AI search through a repository&#039;s documentation by providing a specific search query. Instead of loading all the documentation (which could be very large), it uses intelligent search to find just the relevant parts.

**When it&#039;s useful:** For specific questions about particular features, functions, or concepts within a project

### `fetch_url_content`

This tool helps the AI get information from links mentioned in the documentation. It retrieves the content from those links and converts it to a format the AI can easily read.

**When it&#039;s useful:** When documentation references external information that would help answer your question

### `search_&lt;repo-name&gt;_code`

This tool searches through the actual code in the repository using GitHub&#039;s code search. It helps AI find specific code examples or implementation details.

**When it&#039;s useful:** When you want examples of how something is implemented or need technical details not covered in documentation

&gt; **Note:** When using the dynamic endpoint (`gitmcp.io/docs`), these tools are named slightly differently (`fetch_generic_documentation`, `search_generic_code`, and `search_generic_documentation`) and need additional information about which repository to access.

## üìä Badge

GitMCP has a badge to your repository&#039;s README. It allows users to quickly access your documentation through their IDE or browser (using the embedded chat). It also showcases how many times your documentation has been accessed through GitMCP.

Example (`idosal/git-mcp`): [![GitMCP](https://img.shields.io/endpoint?url=https://gitmcp.io/badge/idosal/git-mcp)](https://gitmcp.io/idosal/git-mcp)

### Adding the Badge to Your Repository

Add the following to your `README.md`:

```markdown
[![GitMCP](https://img.shields.io/endpoint?url=https://gitmcp.io/badge/OWNER/REPO)](https://gitmcp.io/OWNER/REPO)
```

Replace `OWNER` with your GitHub username or organization, and `REPO` with your repository name.

### How We Count Views

Increment for each tool call on the specific repository.

### Customizing the Badge

You can customize the badge&#039;s appearance with parameters:

| Parameter | Description | Default | Example |
|-----------|-------------|---------|---------|
| `color` | Color for the badge value | `aquamarine` | `?color=green` |
| `label` | Badge label | `GitMCP` | `Documentation`

Please reach out!

## ‚ùì FAQ

### What is the Model Context Protocol?

The [Model Context Protocol](https://modelcontextprotocol.io/introduction) is a standard that allows AI assistants to request and receive additional context from external sources in a structured manner, enhancing their understanding and performance.

### Does GitMCP work with any AI assistant?

Yes, GitMCP is compatible with any AI assistant supporting the Model Context Protocol, including tools like Cursor, VSCode, Claude, etc.

### Is GitMCP compatible with all GitHub projects?

Absolutely! GitMCP works with any public GitHub repository without requiring any modifications. It prioritizes the `llms.txt` file and falls back to `README.md` or other pages if the former is unavailable. Future updates aim to support additional documentation methods and even generate content dynamically.

### Does GitMCP cost money?

No, GitMCP is a free service to the community with no associated costs.

## üîí Privacy

GitMCP is deeply committed to its users&#039; privacy. The service doesn&#039;t have access to or store any personally identifiable information as it doesn&#039;t require authentication. In addition, it doesn&#039;t store any queries sent by the agents. Moreover, as GitMCP is an open-source project, it can be deployed independently in your environment.

GitMCP only accesses content that is already publicly available and only when queried by a user. GitMCP does not automatically scrape repositories. Before accessing any GitHub Pages site, the code checks for `robots.txt` rules and follows the directives set by site owners, allowing them to opt out. Please note that GitMCP doesn&#039;t permanently store data regarding the GitHub projects or their content.

## üë• Contributing

We welcome contributions, feedback, and ideas! Please review our [contribution](https://github.com/idosal/git-mcp/blob/main/.github/CONTRIBUTING.md) guidelines.

### Local Development Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/idosal/git-mcp.git
   cd git-mcp
   ```

2. **Install dependencies**
   ```bash
   pnpm install
   ```

3. **Run locally for development**
   ```bash
   npm run dev
   # or
   pnpm dev
   ```

#### Using MCP Inspector for Testing

1. Install the MCP Inspector tool:
   ```bash
   npx @modelcontextprotocol/inspector
   ```

2. In the inspector interface:
   - Set Transport Type to `SSE`
   - Enter your GitMCP URL (e.g., `http://localhost:5173/docs`)
   - Click &quot;Connect&quot;

## üìÑ License

This project is licensed under the [Apache License 2.0](LICENSE).

## Disclaimer

GitMCP is provided &quot;as is&quot; without warranty of any kind. While we strive to ensure the reliability and security of our service, we are not responsible for any damages or issues that may arise from its use. GitHub projects accessed through GitMCP are subject to their respective owners&#039; terms and conditions. GitMCP is not affiliated with GitHub or any of the mentioned AI tools.


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=idosal/git-mcp&amp;type=Timeline)](https://www.star-history.com/#idosal/git-mcp&amp;Timeline)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[CapSoftware/Cap]]></title>
            <link>https://github.com/CapSoftware/Cap</link>
            <guid>https://github.com/CapSoftware/Cap</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:46 GMT</pubDate>
            <description><![CDATA[Open source Loom alternative. Beautiful, shareable screen recordings.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/CapSoftware/Cap">CapSoftware/Cap</a></h1>
            <p>Open source Loom alternative. Beautiful, shareable screen recordings.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 10,895</p>
            <p>Forks: 691</p>
            <p>Stars today: 121 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;p align=&quot;center&quot;&gt;
   &lt;img width=&quot;150&quot; height=&quot;150&quot; src=&quot;https://github.com/CapSoftware/Cap/blob/main/apps/desktop/src-tauri/icons/Square310x310Logo.png&quot; alt=&quot;Logo&quot;&gt;
  &lt;/p&gt;
	&lt;h1 align=&quot;center&quot;&gt;&lt;b&gt;Cap&lt;/b&gt;&lt;/h1&gt;
	&lt;p align=&quot;center&quot;&gt;
		The open source Loom alternative.
    &lt;br /&gt;
    &lt;a href=&quot;https://cap.so&quot;&gt;&lt;strong&gt;Cap.so ¬ª&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;b&gt;Downloads for &lt;/b&gt;
		&lt;a href=&quot;https://cap.so/download&quot;&gt;macOS &amp; Windows&lt;/a&gt;
    &lt;br /&gt;
  &lt;/p&gt;
&lt;/p&gt;
&lt;br/&gt;

[![Open Bounties](https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2FCapSoftware%2Fbounties%3Fstatus%3Dopen)](https://console.algora.io/org/CapSoftware/bounties?status=open)

Cap is the open source alternative to Loom. It&#039;s a video messaging tool that allows you to record, edit and share videos in seconds.

&lt;img src=&quot;https://raw.githubusercontent.com/CapSoftware/Cap/refs/heads/main/apps/web/public/landing-cover.png&quot;/&gt;

# Self Hosting

Cap Web is available to self-host using Docker or Railway, see our [self-hosting docs](https://cap.so/docs/self-hosting) to learn more.
You can also use the button below to deploy Cap Web to Railway:

[![Deploy on Railway](https://railway.com/button.svg)](https://railway.com/new/template/PwpGcf)

Cap Desktop can connect to your self-hosted Cap Web instance regardless of if you build it yourself or [download from our website](https://cap.so/download).

# Monorepo App Architecture

We use a combination of Rust, React (Next.js), TypeScript, Tauri, Drizzle (ORM), MySQL, TailwindCSS throughout this Turborepo powered monorepo.

&gt; A note about database: The codebase is currently designed to work with MySQL only. MariaDB or other compatible databases might partially work but are not officially supported.

### Apps:

- `desktop`: A [Tauri](https://tauri.app) (Rust) app, using [SolidStart](https://start.solidjs.com) on the frontend.
- `web`: A [Next.js](https://nextjs.org) web app.

### Packages:

- `ui`: A [React](https://reactjs.org) Shared component library.
- `utils`: A [React](https://reactjs.org) Shared utility library.
- `tsconfig`: Shared `tsconfig` configurations used throughout the monorepo.
- `database`: A [React](https://reactjs.org) and [Drizzle ORM](https://orm.drizzle.team/) Shared database library.
- `config`: `eslint` configurations (includes `eslint-config-next`, `eslint-config-prettier` other configs used throughout the monorepo).

# Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for more information. This guide is a work in progress, and is updated regularly as the app matures.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[babel/babel]]></title>
            <link>https://github.com/babel/babel</link>
            <guid>https://github.com/babel/babel</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:45 GMT</pubDate>
            <description><![CDATA[üê† Babel is a compiler for writing next generation JavaScript.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/babel/babel">babel/babel</a></h1>
            <p>üê† Babel is a compiler for writing next generation JavaScript.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 43,686</p>
            <p>Forks: 5,739</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://babeljs.io/&quot;&gt;
    &lt;img alt=&quot;babel&quot; src=&quot;https://raw.githubusercontent.com/babel/logo/master/babel.png&quot; width=&quot;546&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  The compiler for writing next generation JavaScript.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://gitpod.io/#https://github.com/babel/babel&quot;&gt;&lt;img alt=&quot;Gitpod ready-to-code&quot; src=&quot;https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://pkg.pr.new/~/babel/babel&quot;&gt;&lt;img alt=&quot;pkg.pr.new&quot; src=&quot;https://pkg.pr.new/badge/babel/babel?style=flat&amp;color=000&amp;logoSize=auto&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.npmjs.com/package/@babel/core&quot;&gt;&lt;img alt=&quot;v7 npm Downloads&quot; src=&quot;https://img.shields.io/npm/dm/@babel/core.svg?maxAge=43200&amp;label=v7%20downloads&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/babel-core&quot;&gt;&lt;img alt=&quot;v6 npm Downloads&quot; src=&quot;https://img.shields.io/npm/dm/babel-core.svg?maxAge=43200&amp;label=v6%20downloads&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/babel/babel/actions/workflows/ci.yml&quot;&gt;&lt;img alt=&quot;GitHub CI Status&quot; src=&quot;https://github.com/babel/babel/actions/workflows/ci.yml/badge.svg?branch=main&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/github/babel/babel&quot;&gt;&lt;img alt=&quot;Coverage Status&quot; src=&quot;https://img.shields.io/codecov/c/github/babel/babel/main.svg?maxAge=43200&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://slack.babeljs.io/&quot;&gt;&lt;img alt=&quot;Slack Status&quot; src=&quot;https://slack.babeljs.io/badge.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=babeljs&quot;&gt;&lt;img alt=&quot;Follow on Twitter&quot; src=&quot;https://img.shields.io/twitter/follow/babeljs.svg?style=social&amp;label=Follow&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h2 align=&quot;center&quot;&gt;Supporting Babel&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#backers&quot;&gt;&lt;img alt=&quot;Backers on Open Collective&quot; src=&quot;https://opencollective.com/babel/backers/badge.svg&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;#sponsors&quot;&gt;&lt;img alt=&quot;Sponsors on Open Collective&quot; src=&quot;https://opencollective.com/babel/sponsors/badge.svg&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://medium.com/friendship-dot-js/i-peeked-into-my-node-modules-directory-and-you-wont-believe-what-happened-next-b89f63d21558&quot;&gt;&lt;img alt=&quot;Business Strategy Status&quot; src=&quot;https://img.shields.io/badge/business%20model-flavortown-green.svg&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Babel (pronounced [&quot;babble&quot;](https://soundcloud.com/sebmck/how-to-pronounce-babel))  is a community-driven project used by many companies and projects, and is maintained by a group of [volunteers](https://babeljs.io/team). If you&#039;d like to help support the future of the project, please consider:

- Giving developer time on the project. (Message us on [Twitter](https://twitter.com/babeljs) or [Slack](https://slack.babeljs.io/) for guidance!)
- Giving funds by becoming a sponsor on [Open Collective](https://opencollective.com/babel) or [GitHub](https://github.com/sponsors/babel/) (which goes to our Open Collective account)!

## Sponsors

Our top sponsors are shown below! [[Become a sponsor](https://opencollective.com/babel#sponsor)]

&lt;a href=&quot;https://opencollective.com/babel/sponsor/0/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/0/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/1/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/1/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/2/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/2/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/3/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/3/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/4/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/4/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/5/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/5/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/6/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/6/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/7/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/7/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/8/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/8/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/9/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/9/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/10/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/10/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/11/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/11/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/12/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/12/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/13/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/13/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/babel/sponsor/14/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/babel/sponsor/14/avatar.svg&quot;&gt;&lt;/a&gt;

## Intro

Babel is a tool that helps you write code in the latest version of JavaScript. When your supported environments don&#039;t support certain features natively, Babel will help you compile those features down to a supported version.

**In**

```js
// ES2020 nullish coalescing
function greet(input) {
  return input ?? &quot;Hello world&quot;;
}
```

**Out**

```js
function greet(input) {
  return input != null ? input : &quot;Hello world&quot;;
}
```

Try it out at our [REPL](https://babel.dev/repl#?browsers=defaults&amp;loose=true&amp;code_lz=GYVwdgxgLglg9mABAcwE4FN1QBQzABxCgEpEBvAKEUQyhFST0KkQH5XEAiACXQBs-cRAHc4qPgBNOAbgoBfIA&amp;shippedProposals=true&amp;sourceType=script&amp;lineWrap=true&amp;presets=env%2Cenv&amp;prettier=true&amp;forceAllTransforms=true).

## FAQ

### Who maintains Babel?

Mostly a handful of volunteers, funded by you! Please check out our [team page](https://babeljs.io/team)!

### Is there a Babel song?

I&#039;m so glad you asked: [Hallelujah ‚Äî‚Äî In Praise of Babel](SONG.md) by [@angus-c](https://github.com/angus-c), [audio version](https://youtu.be/40abpedBKK8) by [@swyx](https://twitter.com/@swyx). Tweet us your recordings!

### Looking for support?

For questions and support please [join or open a GitHub Discussion](https://github.com/babel/babel/discussions), join our [Slack Community](https://slack.babeljs.io/) (you can [sign up here](https://slack.babeljs.io/) for an invite), ask a question on [Stack Overflow](https://stackoverflow.com/questions/tagged/babeljs), or ping us on [Bluesky](https://bsky.app/profile/babel.dev).

### Where are the docs?

Check out our website: [babeljs.io](https://babeljs.io/), and report issues/features at [babel/website](https://github.com/babel/website/issues).

### Want to report a bug or request a feature?

Please read through our [CONTRIBUTING.md](CONTRIBUTING.md) and fill out the issue template at [babel/issues](https://github.com/babel/babel/issues)!

### Want to contribute to Babel?

Check out:

- Our [#development](https://babeljs.slack.com/messages/development) Slack channel and say hi! ([sign-up](https://slack.babeljs.io))
- Issues with the [good first issue](https://github.com/babel/babel/labels/good%20first%20issue) and [help wanted](https://github.com/babel/babel/labels/help%20wanted) label. We suggest also looking at the [closed ones](https://github.com/babel/babel/issues?utf8=%E2%9C%93&amp;q=is%3Aclosed+label%3A%22good+first+issue%22) to get a sense of the kinds of issues you can tackle.

Some resources:

- Our [CONTRIBUTING.md](CONTRIBUTING.md) to get started with setting up the repo.
- Our discussions/notes/roadmap: [babel/notes](https://github.com/babel/notes)
- Our progress on TC39 proposals: [babel/proposals](https://github.com/babel/proposals)
- Our blog which contains release posts and explanations: [/blog](https://babeljs.io/blog)
- Our videos page with talks about open source and Babel: [/videos](https://babeljs.io/videos)
- Our [podcast](https://podcast.babeljs.io)

### How is the repo structured?

The Babel repo is managed as a [monorepo](doc/design/monorepo.md) that is composed of many [npm packages](packages/README.md).

## License

[MIT](LICENSE)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[openai/openai-node]]></title>
            <link>https://github.com/openai/openai-node</link>
            <guid>https://github.com/openai/openai-node</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[Official JavaScript / TypeScript library for the OpenAI API]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/openai-node">openai/openai-node</a></h1>
            <p>Official JavaScript / TypeScript library for the OpenAI API</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,946</p>
            <p>Forks: 1,185</p>
            <p>Stars today: 280 stars today</p>
            <h2>README</h2><pre># OpenAI TypeScript and JavaScript API Library

[![NPM version](&lt;https://img.shields.io/npm/v/openai.svg?label=npm%20(stable)&gt;)](https://npmjs.org/package/openai) ![npm bundle size](https://img.shields.io/bundlephobia/minzip/openai) [![JSR Version](https://jsr.io/badges/@openai/openai)](https://jsr.io/@openai/openai)

This library provides convenient access to the OpenAI REST API from TypeScript or JavaScript.

It is generated from our [OpenAPI specification](https://github.com/openai/openai-openapi) with [Stainless](https://stainlessapi.com/).

To learn how to use the OpenAI API, check out our [API Reference](https://platform.openai.com/docs/api-reference) and [Documentation](https://platform.openai.com/docs).

## Installation

```sh
npm install openai
```

### Installation from JSR

```sh
deno add jsr:@openai/openai
npx jsr add @openai/openai
```

These commands will make the module importable from the `@openai/openai` scope. You can also [import directly from JSR](https://jsr.io/docs/using-packages#importing-with-jsr-specifiers) without an install step if you&#039;re using the Deno JavaScript runtime:

```ts
import OpenAI from &#039;jsr:@openai/openai&#039;;
```

## Usage

The full API of this library can be found in [api.md file](api.md) along with many [code examples](https://github.com/openai/openai-node/tree/master/examples).

The primary API for interacting with OpenAI models is the [Responses API](https://platform.openai.com/docs/api-reference/responses). You can generate text from the model with the code below.

```ts
import OpenAI from &#039;openai&#039;;

const client = new OpenAI({
  apiKey: process.env[&#039;OPENAI_API_KEY&#039;], // This is the default and can be omitted
});

const response = await client.responses.create({
  model: &#039;gpt-4o&#039;,
  instructions: &#039;You are a coding assistant that talks like a pirate&#039;,
  input: &#039;Are semicolons optional in JavaScript?&#039;,
});

console.log(response.output_text);
```

The previous standard (supported indefinitely) for generating text is the [Chat Completions API](https://platform.openai.com/docs/api-reference/chat). You can use that API to generate text from the model with the code below.

```ts
import OpenAI from &#039;openai&#039;;

const client = new OpenAI({
  apiKey: process.env[&#039;OPENAI_API_KEY&#039;], // This is the default and can be omitted
});

const completion = await client.chat.completions.create({
  model: &#039;gpt-4o&#039;,
  messages: [
    { role: &#039;developer&#039;, content: &#039;Talk like a pirate.&#039; },
    { role: &#039;user&#039;, content: &#039;Are semicolons optional in JavaScript?&#039; },
  ],
});

console.log(completion.choices[0].message.content);
```

## Streaming responses

We provide support for streaming responses using Server Sent Events (SSE).

```ts
import OpenAI from &#039;openai&#039;;

const client = new OpenAI();

const stream = await client.responses.create({
  model: &#039;gpt-4o&#039;,
  input: &#039;Say &quot;Sheep sleep deep&quot; ten times fast!&#039;,
  stream: true,
});

for await (const event of stream) {
  console.log(event);
}
```

## File uploads

Request parameters that correspond to file uploads can be passed in many different forms:

- `File` (or an object with the same structure)
- a `fetch` `Response` (or an object with the same structure)
- an `fs.ReadStream`
- the return value of our `toFile` helper

```ts
import fs from &#039;fs&#039;;
import OpenAI, { toFile } from &#039;openai&#039;;

const client = new OpenAI();

// If you have access to Node `fs` we recommend using `fs.createReadStream()`:
await client.files.create({ file: fs.createReadStream(&#039;input.jsonl&#039;), purpose: &#039;fine-tune&#039; });

// Or if you have the web `File` API you can pass a `File` instance:
await client.files.create({ file: new File([&#039;my bytes&#039;], &#039;input.jsonl&#039;), purpose: &#039;fine-tune&#039; });

// You can also pass a `fetch` `Response`:
await client.files.create({ file: await fetch(&#039;https://somesite/input.jsonl&#039;), purpose: &#039;fine-tune&#039; });

// Finally, if none of the above are convenient, you can use our `toFile` helper:
await client.files.create({
  file: await toFile(Buffer.from(&#039;my bytes&#039;), &#039;input.jsonl&#039;),
  purpose: &#039;fine-tune&#039;,
});
await client.files.create({
  file: await toFile(new Uint8Array([0, 1, 2]), &#039;input.jsonl&#039;),
  purpose: &#039;fine-tune&#039;,
});
```

## Webhook Verification

Verifying webhook signatures is _optional but encouraged_.

For more information about webhooks, see [the API docs](https://platform.openai.com/docs/guides/webhooks).

### Parsing webhook payloads

For most use cases, you will likely want to verify the webhook and parse the payload at the same time. To achieve this, we provide the method `client.webhooks.unwrap()`, which parses a webhook request and verifies that it was sent by OpenAI. This method will throw an error if the signature is invalid.

Note that the `body` parameter must be the raw JSON string sent from the server (do not parse it first). The `.unwrap()` method will parse this JSON for you into an event object after verifying the webhook was sent from OpenAI.

```ts
import { headers } from &#039;next/headers&#039;;
import OpenAI from &#039;openai&#039;;

const client = new OpenAI({
  webhookSecret: process.env.OPENAI_WEBHOOK_SECRET, // env var used by default; explicit here.
});

export async function webhook(request: Request) {
  const headersList = headers();
  const body = await request.text();

  try {
    const event = client.webhooks.unwrap(body, headersList);

    switch (event.type) {
      case &#039;response.completed&#039;:
        console.log(&#039;Response completed:&#039;, event.data);
        break;
      case &#039;response.failed&#039;:
        console.log(&#039;Response failed:&#039;, event.data);
        break;
      default:
        console.log(&#039;Unhandled event type:&#039;, event.type);
    }

    return Response.json({ message: &#039;ok&#039; });
  } catch (error) {
    console.error(&#039;Invalid webhook signature:&#039;, error);
    return new Response(&#039;Invalid signature&#039;, { status: 400 });
  }
}
```

### Verifying webhook payloads directly

In some cases, you may want to verify the webhook separately from parsing the payload. If you prefer to handle these steps separately, we provide the method `client.webhooks.verifySignature()` to _only verify_ the signature of a webhook request. Like `.unwrap()`, this method will throw an error if the signature is invalid.

Note that the `body` parameter must be the raw JSON string sent from the server (do not parse it first). You will then need to parse the body after verifying the signature.

```ts
import { headers } from &#039;next/headers&#039;;
import OpenAI from &#039;openai&#039;;

const client = new OpenAI({
  webhookSecret: process.env.OPENAI_WEBHOOK_SECRET, // env var used by default; explicit here.
});

export async function webhook(request: Request) {
  const headersList = headers();
  const body = await request.text();

  try {
    client.webhooks.verifySignature(body, headersList);

    // Parse the body after verification
    const event = JSON.parse(body);
    console.log(&#039;Verified event:&#039;, event);

    return Response.json({ message: &#039;ok&#039; });
  } catch (error) {
    console.error(&#039;Invalid webhook signature:&#039;, error);
    return new Response(&#039;Invalid signature&#039;, { status: 400 });
  }
}
```

## Handling errors

When the library is unable to connect to the API,
or if the API returns a non-success status code (i.e., 4xx or 5xx response),
a subclass of `APIError` will be thrown:

&lt;!-- prettier-ignore --&gt;
```ts
const job = await client.fineTuning.jobs
  .create({ model: &#039;gpt-4o&#039;, training_file: &#039;file-abc123&#039; })
  .catch(async (err) =&gt; {
    if (err instanceof OpenAI.APIError) {
      console.log(err.request_id);
      console.log(err.status); // 400
      console.log(err.name); // BadRequestError
      console.log(err.headers); // {server: &#039;nginx&#039;, ...}
    } else {
      throw err;
    }
  });
```

Error codes are as follows:

| Status Code | Error Type                 |
| ----------- | -------------------------- |
| 400         | `BadRequestError`          |
| 401         | `AuthenticationError`      |
| 403         | `PermissionDeniedError`    |
| 404         | `NotFoundError`            |
| 422         | `UnprocessableEntityError` |
| 429         | `RateLimitError`           |
| &gt;=500       | `InternalServerError`      |
| N/A         | `APIConnectionError`       |

## Request IDs

&gt; For more information on debugging requests, see [these docs](https://platform.openai.com/docs/api-reference/debugging-requests)

All object responses in the SDK provide a `_request_id` property which is added from the `x-request-id` response header so that you can quickly log failing requests and report them back to OpenAI.

```ts
const completion = await client.chat.completions.create({
  messages: [{ role: &#039;user&#039;, content: &#039;Say this is a test&#039; }],
  model: &#039;gpt-4o&#039;,
});
console.log(completion._request_id); // req_123
```

You can also access the Request ID using the `.withResponse()` method:

```ts
const { data: stream, request_id } = await openai.chat.completions
  .create({
    model: &#039;gpt-4&#039;,
    messages: [{ role: &#039;user&#039;, content: &#039;Say this is a test&#039; }],
    stream: true,
  })
  .withResponse();
```

## Realtime API Beta

The Realtime API enables you to build low-latency, multi-modal conversational experiences. It currently supports text and audio as both input and output, as well as [function calling](https://platform.openai.com/docs/guides/function-calling) through a `WebSocket` connection.

```ts
import { OpenAIRealtimeWebSocket } from &#039;openai/beta/realtime/websocket&#039;;

const rt = new OpenAIRealtimeWebSocket({ model: &#039;gpt-4o-realtime-preview-2024-12-17&#039; });

rt.on(&#039;response.text.delta&#039;, (event) =&gt; process.stdout.write(event.delta));
```

For more information see [realtime.md](realtime.md).

## Microsoft Azure OpenAI

To use this library with [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/overview), use the `AzureOpenAI`
class instead of the `OpenAI` class.

&gt; [!IMPORTANT]
&gt; The Azure API shape slightly differs from the core API shape which means that the static types for responses / params
&gt; won&#039;t always be correct.

```ts
import { AzureOpenAI } from &#039;openai&#039;;
import { getBearerTokenProvider, DefaultAzureCredential } from &#039;@azure/identity&#039;;

const credential = new DefaultAzureCredential();
const scope = &#039;https://cognitiveservices.azure.com/.default&#039;;
const azureADTokenProvider = getBearerTokenProvider(credential, scope);

const openai = new AzureOpenAI({ azureADTokenProvider });

const result = await openai.chat.completions.create({
  model: &#039;gpt-4o&#039;,
  messages: [{ role: &#039;user&#039;, content: &#039;Say hello!&#039; }],
});

console.log(result.choices[0]!.message?.content);
```

### Retries

Certain errors will be automatically retried 2 times by default, with a short exponential backoff.
Connection errors (for example, due to a network connectivity problem), 408 Request Timeout, 409 Conflict,
429 Rate Limit, and &gt;=500 Internal errors will all be retried by default.

You can use the `maxRetries` option to configure or disable this:

&lt;!-- prettier-ignore --&gt;
```js
// Configure the default for all requests:
const client = new OpenAI({
  maxRetries: 0, // default is 2
});

// Or, configure per-request:
await client.chat.completions.create({ messages: [{ role: &#039;user&#039;, content: &#039;How can I get the name of the current day in JavaScript?&#039; }], model: &#039;gpt-4o&#039; }, {
  maxRetries: 5,
});
```

### Timeouts

Requests time out after 10 minutes by default. You can configure this with a `timeout` option:

&lt;!-- prettier-ignore --&gt;
```ts
// Configure the default for all requests:
const client = new OpenAI({
  timeout: 20 * 1000, // 20 seconds (default is 10 minutes)
});

// Override per-request:
await client.chat.completions.create({ messages: [{ role: &#039;user&#039;, content: &#039;How can I list all files in a directory using Python?&#039; }], model: &#039;gpt-4o&#039; }, {
  timeout: 5 * 1000,
});
```

On timeout, an `APIConnectionTimeoutError` is thrown.

Note that requests which time out will be [retried twice by default](#retries).

## Request IDs

&gt; For more information on debugging requests, see [these docs](https://platform.openai.com/docs/api-reference/debugging-requests)

All object responses in the SDK provide a `_request_id` property which is added from the `x-request-id` response header so that you can quickly log failing requests and report them back to OpenAI.

```ts
const response = await client.responses.create({ model: &#039;gpt-4o&#039;, input: &#039;testing 123&#039; });
console.log(response._request_id); // req_123
```

You can also access the Request ID using the `.withResponse()` method:

```ts
const { data: stream, request_id } = await openai.responses
  .create({
    model: &#039;gpt-4o&#039;,
    input: &#039;Say this is a test&#039;,
    stream: true,
  })
  .withResponse();
```

## Auto-pagination

List methods in the OpenAI API are paginated.
You can use the `for await ‚Ä¶ of` syntax to iterate through items across all pages:

```ts
async function fetchAllFineTuningJobs(params) {
  const allFineTuningJobs = [];
  // Automatically fetches more pages as needed.
  for await (const fineTuningJob of client.fineTuning.jobs.list({ limit: 20 })) {
    allFineTuningJobs.push(fineTuningJob);
  }
  return allFineTuningJobs;
}
```

Alternatively, you can request a single page at a time:

```ts
let page = await client.fineTuning.jobs.list({ limit: 20 });
for (const fineTuningJob of page.data) {
  console.log(fineTuningJob);
}

// Convenience methods are provided for manually paginating:
while (page.hasNextPage()) {
  page = await page.getNextPage();
  // ...
}
```

## Realtime API Beta

The Realtime API enables you to build low-latency, multi-modal conversational experiences. It currently supports text and audio as both input and output, as well as [function calling](https://platform.openai.com/docs/guides/function-calling) through a `WebSocket` connection.

```ts
import { OpenAIRealtimeWebSocket } from &#039;openai/beta/realtime/websocket&#039;;

const rt = new OpenAIRealtimeWebSocket({ model: &#039;gpt-4o-realtime-preview-2024-12-17&#039; });

rt.on(&#039;response.text.delta&#039;, (event) =&gt; process.stdout.write(event.delta));
```

For more information see [realtime.md](realtime.md).

## Microsoft Azure OpenAI

To use this library with [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/overview), use the `AzureOpenAI`
class instead of the `OpenAI` class.

&gt; [!IMPORTANT]
&gt; The Azure API shape slightly differs from the core API shape which means that the static types for responses / params
&gt; won&#039;t always be correct.

```ts
import { AzureOpenAI } from &#039;openai&#039;;
import { getBearerTokenProvider, DefaultAzureCredential } from &#039;@azure/identity&#039;;

const credential = new DefaultAzureCredential();
const scope = &#039;https://cognitiveservices.azure.com/.default&#039;;
const azureADTokenProvider = getBearerTokenProvider(credential, scope);

const openai = new AzureOpenAI({
  azureADTokenProvider,
  apiVersion: &#039;&lt;The API version, e.g. 2024-10-01-preview&gt;&#039;,
});

const result = await openai.chat.completions.create({
  model: &#039;gpt-4o&#039;,
  messages: [{ role: &#039;user&#039;, content: &#039;Say hello!&#039; }],
});

console.log(result.choices[0]!.message?.content);
```

For more information on support for the Azure API, see [azure.md](azure.md).

## Advanced Usage

### Accessing raw Response data (e.g., headers)

The &quot;raw&quot; `Response` returned by `fetch()` can be accessed through the `.asResponse()` method on the `APIPromise` type that all methods return.
This method returns as soon as the headers for a successful response are received and does not consume the response body, so you are free to write custom parsing or streaming logic.

You can also use the `.withResponse()` method to get the raw `Response` along with the parsed data.
Unlike `.asResponse()` this method consumes the body, returning once it is parsed.

&lt;!-- prettier-ignore --&gt;
```ts
const client = new OpenAI();

const httpResponse = await client.responses
  .create({ model: &#039;gpt-4o&#039;, input: &#039;say this is a test.&#039; })
  .asResponse();

// access the underlying web standard Response object
console.log(httpResponse.headers.get(&#039;X-My-Header&#039;));
console.log(httpResponse.statusText);

const { data: modelResponse, response: raw } = await client.responses
  .create({ model: &#039;gpt-4o&#039;, input: &#039;say this is a test.&#039; })
  .withResponse();
console.log(raw.headers.get(&#039;X-My-Header&#039;));
console.log(modelResponse);
```

### Logging

&gt; [!IMPORTANT]
&gt; All log messages are intended for debugging only. The format and content of log messages
&gt; may change between releases.

#### Log levels

The log level can be configured in two ways:

1. Via the `OPENAI_LOG` environment variable
2. Using the `logLevel` client option (overrides the environment variable if set)

```ts
import OpenAI from &#039;openai&#039;;

const client = new OpenAI({
  logLevel: &#039;debug&#039;, // Show all log messages
});
```

Available log levels, from most to least verbose:

- `&#039;debug&#039;` - Show debug messages, info, warnings, and errors
- `&#039;info&#039;` - Show info messages, warnings, and errors
- `&#039;warn&#039;` - Show warnings and errors (default)
- `&#039;error&#039;` - Show only errors
- `&#039;off&#039;` - Disable all logging

At the `&#039;debug&#039;` level, all HTTP requests and responses are logged, including headers and bodies.
Some authentication-related headers are redacted, but sensitive data in request and response bodies
may still be visible.

#### Custom logger

By default, this library logs to `globalThis.console`. You can also provide a custom logger.
Most logging libraries are supported, including [pino](https://www.npmjs.com/package/pino), [winston](https://www.npmjs.com/package/winston), [bunyan](https://www.npmjs.com/package/bunyan), [consola](https://www.npmjs.com/package/consola), [signale](https://www.npmjs.com/package/signale), and [@std/log](https://jsr.io/@std/log). If your logger doesn&#039;t work, please open an issue.

When providing a custom logger, the `logLevel` option still controls which messages are emitted, messages
below the configured level will not be sent to your logger.

```ts
import OpenAI from &#039;openai&#039;;
import pino from &#039;pino&#039;;

const logger = pino();

const client = new OpenAI({
  logger: logger.child({ name: &#039;OpenAI&#039; }),
  logLevel: &#039;debug&#039;, // Send all messages to pino, allowing it to filter
});
```

### Making custom/undocumented requests

This library is typed for convenient access to the documented API. If you need to access undocumented
endpoints, params, or response properties, the library can still be used.

#### Undocumented endpoints

To make requests to undocumented endpoints, you can use `client.get`, `client.post`, and other HTTP verbs.
Options on the client, such as retries, will be respected when making these requests.

```ts
await client.post(&#039;/some/path&#039;, {
  body: { some_prop: &#039;foo&#039; },
  query: { some_query_arg: &#039;bar&#039; },
});
```

#### Undocumented request params

To make requests using undocumented parameters, you may use `// @ts-expect-error` on the undocumented
parameter. This library doesn&#039;t validate at runtime that the request matches the type, so any extra values you
send will be sent as-is.

```ts
client.chat.completions.create({
  // ...
  // @ts-expect-error baz is not yet public
  baz: &#039;undocumented option&#039;,
});
```

For requests with the `GET` verb, any extra params will be in the query, all other requests will send the
extra param in the body.

If you want to explicitly send an extra argument, you can do so with the `query`, `body`, and `headers` request
options.

#### Undocumented response properties

To access undocumented response properties, you may access the response object with `// @ts-expect-error` on
the response object, or cast the response object to the requisite type. Like the request params, we do not
validate or strip extra properties from the response from the API.

### Customizing the fetch client

If you want to use a different `fetch` function, you can either polyfill the global:

```ts
import fetch from &#039;my-fetch&#039;;

globalThis.fetch = fetch;
```

Or pass it to the client:

```ts
import OpenAI from &#039;openai&#039;;
import fetch from &#039;my-fetch&#039;;

const client = new OpenAI({ fetch });
```

### Fetch options

If you want to set custom `fetch` options without overriding the `fetch` function, y

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[Mail-0/Zero]]></title>
            <link>https://github.com/Mail-0/Zero</link>
            <guid>https://github.com/Mail-0/Zero</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[Experience email the way you want with Mail0 ‚Äì the first open source email app that puts your privacy and safety first. Join the discord: https://mail0.link/discord]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Mail-0/Zero">Mail-0/Zero</a></h1>
            <p>Experience email the way you want with Mail0 ‚Äì the first open source email app that puts your privacy and safety first. Join the discord: https://mail0.link/discord</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,322</p>
            <p>Forks: 1,094</p>
            <p>Stars today: 36 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source srcset=&quot;apps/mail/public/white-icon.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
    &lt;img src=&quot;apps/mail/public/black-icon.svg&quot; alt=&quot;Zero Logo&quot; width=&quot;64&quot; style=&quot;background-color: #000; padding: 10px;&quot;/&gt;
  &lt;/picture&gt;
&lt;/p&gt;

# Zero

An Open-Source Gmail Alternative for the Future of Email

## What is Zero?

Zero is an open-source AI email solution that gives users the power to **self-host** their own email app while also integrating external services like Gmail and other email providers. Our goal is to modernize and improve emails through AI agents to truly modernize emails.

## Why Zero?

Most email services today are either **closed-source**, **data-hungry**, or **too complex to self-host**.
0.email is different:

- ‚úÖ **Open-Source** ‚Äì No hidden agendas, fully transparent.
- ü¶æ **AI Driven** - Enhance your emails with Agents &amp; LLMs.
- üîí **Data Privacy First** ‚Äì Your emails, your data. Zero does not track, collect, or sell your data in any way. Please note: while we integrate with external services, the data passed through them is not under our control and falls under their respective privacy policies and terms of service.
- ‚öôÔ∏è **Self-Hosting Freedom** ‚Äì Run your own email app with ease.
- üì¨ **Unified Inbox** ‚Äì Connect multiple email providers like Gmail, Outlook, and more.
- üé® **Customizable UI &amp; Features** ‚Äì Tailor your email experience the way you want it.
- üöÄ **Developer-Friendly** ‚Äì Built with extensibility and integrations in mind.

## Tech Stack

Zero is built with modern and reliable technologies:

- **Frontend**: Next.js, React, TypeScript, TailwindCSS, Shadcn UI
- **Backend**: Node.js, Drizzle ORM
- **Database**: PostgreSQL
- **Authentication**: Better Auth, Google OAuth
&lt;!-- - **Testing**: Jest, React Testing Library --&gt;

## Getting Started

### Video Tutorial

Watch this helpful video tutorial on how to set up Zero locally:

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=yIXLQcjbeEM&quot;&gt;
    &lt;img src=&quot;https://img.youtube.com/vi/yIXLQcjbeEM/0.jpg&quot; alt=&quot;Zero Setup Tutorial&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

### Prerequisites

**Required Versions:**

- [Node.js](https://nodejs.org/en/download) (v18 or higher)
- [pnpm](https://pnpm.io) (v10 or higher)
- [Docker](https://docs.docker.com/engine/install/) (v20 or higher)

Before running the application, you&#039;ll need to set up services and configure environment variables. For more details on environment variables, see the [Environment Variables](#environment-variables) section.

### Setup Options

You can set up Zero in two ways:

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;Standard Setup (Recommended)&lt;/b&gt;&lt;/summary&gt;

#### Quick Start Guide

1. **Clone and Install**

   ```bash
   # Clone the repository
   git clone https://github.com/Mail-0/Zero.git
   cd Zero

   # Install dependencies
   pnpm install

   # Start database locally
   pnpm docker:db:up
   ```

2. **Set Up Environment**

   - Run `pnpm nizzy env` to setup your environment variables
   - Run `pnpm nizzy sync` to sync your environment variables and types
   - Start the database with the provided docker compose setup: `pnpm docker:db:up`
   - Initialize the database: `pnpm db:push`

3. **Start the App**

   ```bash
   pnpm dev
   ```

4. **Open in Browser**

   Visit [http://localhost:3000](http://localhost:3000)
   &lt;/details&gt;

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;Devcontainer Setup&lt;/b&gt;&lt;/summary&gt;

#### Quick Start guide

1. **Clone and Install**

   ```bash
   # Clone the repository
   git clone https://github.com/Mail-0/Zero.git
   cd Zero
   ```

   Then open the code in devcontainer and install the dependencies:

   ```
   pnpm install

   # Start the database locally
   pnpm docker:db:up
   ```

2. **Set Up Environment**

   - Run `pnpm nizzy env` to setup your environment variables
   - Run `pnpm nizzy sync` to sync your environment variables and types
   - Start the database with the provided docker compose setup: `pnpm docker:db:up`
   - Initialize the database: `pnpm db:push`

3. **Start The App**
   ```bash
   pnpm dev
   ```
   Visit [http://localhost:3000](http://localhost:3000)
     &lt;/details&gt;

### Environment Setup

1. **Better Auth Setup**

   - Open the `.env` file and change the BETTER_AUTH_SECRET to a random string. (Use `openssl rand -hex 32` to generate a 32 character string)

     ```env
     BETTER_AUTH_SECRET=your_secret_key
     ```

2. **Google OAuth Setup** (Required for Gmail integration)

   - Go to [Google Cloud Console](https://console.cloud.google.com)
   - Create a new project
   - Add the following APIs in your Google Cloud Project: [People API](https://console.cloud.google.com/apis/library/people.googleapis.com), [Gmail API](https://console.cloud.google.com/apis/library/gmail.googleapis.com)
     - Use the links above and click &#039;Enable&#039; or
     - Go to &#039;APIs and Services&#039; &gt; &#039;Enable APIs and Services&#039; &gt; Search for &#039;Google People API&#039; and click &#039;Enable&#039;
     - Go to &#039;APIs and Services&#039; &gt; &#039;Enable APIs and Services&#039; &gt; Search for &#039;Gmail API&#039; and click &#039;Enable&#039;
   - Enable the Google OAuth2 API
   - Create OAuth 2.0 credentials (Web application type)
   - Add authorized redirect URIs:
     - Development:
       - `http://localhost:8787/api/auth/callback/google`
     - Production:
       - `https://your-production-url/api/auth/callback/google`
   - Add to `.env`:

     ```env
     GOOGLE_CLIENT_ID=your_client_id
     GOOGLE_CLIENT_SECRET=your_client_secret
     ```

   - Add yourself as a test user:

     - Go to [`Audience`](https://console.cloud.google.com/auth/audience)
     - Under &#039;Test users&#039; click &#039;Add Users&#039;
     - Add your email and click &#039;Save&#039;

&gt; [!WARNING]
&gt; The authorized redirect URIs in Google Cloud Console must match **exactly** what you configure in the `.env`, including the protocol (http/https), domain, and path - these are provided above.

3. **Autumn Setup** (Required for some encryption)

   - Go to [Autumn](https://useautumn.com/)
   - For Local Use, click [onboarding](https://app.useautumn.com/sandbox/onboarding) button and generate an Autumn Secret Key
   - For production, select the production mode from upper left corner and generate and fill the other fields. After that, generate an Autumn Secret Key

   - Add to `.env`:

   ```env
   AUTUMN_SECRET_KEY=your_autumn_secret
   ```

4. **Twilio Setup** (Required for SMS Integration)

   - Go to the [Twilio](https://www.twilio.com/)
   - Create a Twilio account if you don‚Äôt already have one
   - From the dashboard, locate your:

     - Account SID
     - Auth Token
     - Phone Number

   - Add to your `.env` file:

   ```env
   TWILIO_ACCOUNT_SID=your_account_sid
   TWILIO_AUTH_TOKEN=your_auth_token
   TWILIO_PHONE_NUMBER=your_twilio_phone_number
   ```

### Environment Variables

Run `pnpm nizzy env` to setup your environment variables. It will copy the `.env.example` file to `.env` and fill in the variables for you.
For local development a connection string example is provided in the `.env.example` file located in the same folder as the database.

### Database Setup

Zero uses PostgreSQL for storing data. Here&#039;s how to set it up:

1. **Start the Database**

   Run this command to start a local PostgreSQL instance:

   ```bash
   pnpm docker:db:up
   ```

   This creates a database with:

   - Name: `zerodotemail`
   - Username: `postgres`
   - Password: `postgres`
   - Port: `5432`

2. **Set Up Database Connection**

   Make sure your database connection string is in `.env` file. And you have ran `pnpm nizzy sync` to sync the latest env.

   For local development use:

   ```
   DATABASE_URL=&quot;postgresql://postgres:postgres@localhost:5432/zerodotemail&quot;
   ```

3. **Database Commands**

   - **Set up database tables**:

     ```bash
     pnpm db:push
     ```

   - **Create migration files** (after schema changes):

     ```bash
     pnpm db:generate
     ```

   - **Apply migrations**:

     ```bash
     pnpm db:migrate
     ```

   - **View database content**:
     ```bash
     pnpm db:studio
     ```
     &gt; If you run `pnpm dev` in your terminal, the studio command should be automatically running with the app.

### Sync

Background: https://x.com/cmdhaus/status/1940886269950902362
We&#039;re now storing the user&#039;s emails in their Durable Object &amp; an R2 bucket. This allow us to speed things up, a lot.
This also introduces 3 environment variables, `DROP_AGENT_TABLES`,`THREAD_SYNC_MAX_COUNT`, `THREAD_SYNC_LOOP`.
`DROP_AGENT_TABLES`: should the durable object drop the threads table before starting a sync
`THREAD_SYNC_MAX_COUNT`: how many threads should we sync? max `500` because it&#039;s using the same number for the maxResults number from the driver. i.e 500 results per page.
`THREAD_SYNC_LOOP`: should make sure to sync all of the items inside a folder? i.e if THREAD_SYNC_MAX_COUNT=500 it will sync 500 threads per request until the folder is fully synced. (should be true in production)

## Contribute

Please refer to the [contributing guide](.github/CONTRIBUTING.md).

If you&#039;d like to help with translating Zero to other languages, check out our [translation guide](.github/TRANSLATION.md).

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Mail-0/Zero&amp;type=Timeline)](https://www.star-history.com/#Mail-0/Zero&amp;Timeline)

## This project wouldn&#039;t be possible without these awesome companies

&lt;div style=&quot;display: flex; justify-content: center;&quot;&gt;
  &lt;a href=&quot;https://vercel.com&quot; style=&quot;text-decoration: none;&quot;&gt;
    &lt;img src=&quot;public/vercel.png&quot; alt=&quot;Vercel&quot; width=&quot;96&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://better-auth.com&quot; style=&quot;text-decoration: none;&quot;&gt;
    &lt;img src=&quot;public/better-auth.png&quot; alt=&quot;Better Auth&quot; width=&quot;96&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://orm.drizzle.team&quot; style=&quot;text-decoration: none;&quot;&gt;
    &lt;img src=&quot;public/drizzle-orm.png&quot; alt=&quot;Drizzle ORM&quot; width=&quot;96&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://coderabbit.com&quot; style=&quot;text-decoration: none;&quot;&gt;
    &lt;img src=&quot;public/coderabbit.png&quot; alt=&quot;Coderabbit AI&quot; width=&quot;96&quot;/&gt;
  &lt;/a&gt;
&lt;/div&gt;

## ü§ç The team

Curious who makes Zero? Here are our [contributors and maintainers](https://0.email/contributors)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[adrianhajdin/react-native-movie-app]]></title>
            <link>https://github.com/adrianhajdin/react-native-movie-app</link>
            <guid>https://github.com/adrianhajdin/react-native-movie-app</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:42 GMT</pubDate>
            <description><![CDATA[Get hands-on with React Native and Expo in this crash course! Build a mobile movie app from scratch, and learn essential skills for mobile development along the way.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/adrianhajdin/react-native-movie-app">adrianhajdin/react-native-movie-app</a></h1>
            <p>Get hands-on with React Native and Expo in this crash course! Build a mobile movie app from scratch, and learn essential skills for mobile development along the way.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 496</p>
            <p>Forks: 145</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;br /&gt;
    &lt;a href=&quot;https://www.youtube.com/watch?v=f8Z9JyB2EIE&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;assets/readme/hero.webp&quot; alt=&quot;Project Banner&quot;&gt;
    &lt;/a&gt;
  &lt;br /&gt;

  &lt;div&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-React_Native-black?style=for-the-badge&amp;logoColor=white&amp;logo=react&amp;color=61DAFB&quot; alt=&quot;React Native&quot; /&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-Expo-black?style=for-the-badge&amp;logoColor=white&amp;logo=expo&amp;color=000020&quot; alt=&quot;Expo&quot; /&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-TypeScript-black?style=for-the-badge&amp;logoColor=white&amp;logo=typescript&amp;color=3178C6&quot; alt=&quot;TypeScript&quot; /&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-Tailwind_CSS-black?style=for-the-badge&amp;logoColor=white&amp;logo=tailwindcss&amp;color=06B6D4&quot; alt=&quot;Tailwind CSS&quot; /&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-Appwrite-black?style=for-the-badge&amp;logoColor=white&amp;logo=appwrite&amp;color=F02E65&quot; alt=&quot;Appwrite&quot; /&gt;
  &lt;/div&gt;

  &lt;h3 align=&quot;center&quot;&gt;A Movie Finding App with Extensive Search&lt;/h3&gt;

   &lt;div align=&quot;center&quot;&gt;
     Build this project step by step with our detailed tutorial on &lt;a href=&quot;https://www.youtube.com/@javascriptmastery/videos&quot; target=&quot;_blank&quot;&gt;&lt;b&gt;JavaScript Mastery&lt;/b&gt;&lt;/a&gt; YouTube. Join the JSM family!
    &lt;/div&gt;
&lt;/div&gt;

## üìã &lt;a name=&quot;table&quot;&gt;Table of Contents&lt;/a&gt;

1. ü§ñ [Introduction](#introduction)

2. ‚öôÔ∏è [Tech Stack](#tech-stack)

3. üîã [Features](#features)

4. ü§∏ [Quick Start](#quick-start)

5. üï∏Ô∏è [Snippets (Code to Copy)](#snippets)

6. üîó [Assets](#links)

7. üöÄ [More](#more)

## üö® Tutorial

This repository contains the code corresponding to an in-depth tutorial available on our YouTube channel, &lt;a href=&quot;https://www.youtube.com/@javascriptmastery/videos&quot; target=&quot;_blank&quot;&gt;&lt;b&gt;JavaScript Mastery&lt;/b&gt;&lt;/a&gt;.

If you prefer visual learning, this is the perfect resource for you. Follow our tutorial to learn how to build projects like these step-by-step in a beginner-friendly manner!

&lt;a href=&quot;https://www.youtube.com/watch?v=f8Z9JyB2EIE&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/sujatagunale/EasyRead/assets/151519281/1736fca5-a031-4854-8c09-bc110e3bc16d&quot; /&gt;&lt;/a&gt;

## &lt;a name=&quot;introduction&quot;&gt;ü§ñ Introduction&lt;/a&gt;

Built with Expo, TypeScript, and Tailwind CSS, this app fetches movies and creates a popularity algorithm using Appwrite. It provides users with a seamless browsing experience, ranking movies based on various engagement metrics. The app leverages modern UI/UX principles for a responsive and visually appealing interface, ensuring real-world scalability and performance.

If you&#039;re getting started and need assistance or face any bugs, join our active Discord community with over **50k+** members. It&#039;s a place where people help each other out.

&lt;a href=&quot;https://discord.com/invite/n6EdbFJ&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/sujatagunale/EasyRead/assets/151519281/618f4872-1e10-42da-8213-1d69e486d02e&quot; /&gt;&lt;/a&gt;

## &lt;a name=&quot;tech-stack&quot;&gt;‚öôÔ∏è Tech Stack&lt;/a&gt;

- **[Expo](https://expo.dev/)** is an open-source platform for building universal native apps (Android, iOS, web) using JavaScript/TypeScript and React Native. It features file-based routing via Expo Router, fast refresh, native modules for camera/maps/notifications, over-the-air updates (EAS), and streamlined app deployment.

- **[React Native](https://reactnative.dev/)** is a framework for building mobile UIs with React. It enables component‚Äëbased, cross-platform development with declarative UI, deep native API support, and is tightly integrated with Expo for navigation and native capabilities.

- **[Appwrite](https://jsm.dev/rn25-appwrite)** is an open-source backend-as-a-service platform offering secure authentication (email/password, OAuth, SMS, magic links), databases, file storage with compression/encryption, real-time messaging, serverless functions, and static site hosting via Appwrite Sites‚Äîall managed through a unified console and microservices architecture.

- **[TypeScript](https://www.typescriptlang.org/)** is a statically-typed superset of JavaScript providing type annotations, interfaces, enums, generics, and enhanced tooling. It improves error detection, code quality, and scalability‚Äîideal for robust, maintainable projects.

- **[Tailwind CSS](https://tailwindcss.com/)** is a utility-first CSS framework enabling rapid UI design via low-level classes. In React Native/Expo, it‚Äôs commonly used with NativeWind to apply Tailwind-style utilities to mobile components.

- **[NativeWind](https://www.nativewind.dev/)** brings Tailwind CSS to React Native and Expo, allowing you to style mobile components using utility-first classes for fast, consistent, and responsive UI design.

## &lt;a name=&quot;features&quot;&gt;üîã Features&lt;/a&gt;

### Features of the Mobile Movie AppProject

üëâ **Real-time data**: Fetching and displaying real-time movie data

üëâ **Home Page**: Featured and discover movies

üëâ **Search Page**: Search for your favorite movies

üëâ **Popularity algorithm**: Track user searches to display the most popular movies

and many more, including code architecture and reusability.

## &lt;a name=&quot;quick-start&quot;&gt;ü§∏ Quick Start&lt;/a&gt;

Follow these steps to set up the project locally on your machine.

**Prerequisites**

Make sure you have the following installed on your machine:

- [Git](https://git-scm.com/)

- [Node.js](https://nodejs.org/en)

- [npm](https://www.npmjs.com/) (Node Package Manager)

**Cloning the Repository**

```bash
git clone https://github.com/adrianhajdin/rn-movie-app.git

cd rn-movie-app
```

**Installation**

Install the project dependencies using npm:

```bash
npm install
```

**Set Up Environment Variables**

Create a new file named `.env` in the root of your project and add the following content:

```env

EXPO_PUBLIC_MOVIE_API_KEY=

EXPO_PUBLIC_APPWRITE_PROJECT_ID=

EXPO_PUBLIC_APPWRITE_DATABASE_ID=

EXPO_PUBLIC_APPWRITE_COLLECTION_ID=
```

Replace the placeholder values with your actual TMDB API key, Appwrite project ID, Database ID, and Collection ID. You can obtain these credentials by signing up on the [Appwrite](https://jsm.dev/rn25-appwrite), [TMDB](https://www.themoviedb.org/login).

**Running the Project**

```bash

npx expo start

```

Open your ExpoGO app on your phone and scan the QR code to view the project.

## &lt;a name=&quot;snippets&quot;&gt;üï∏Ô∏è Snippets&lt;/a&gt;

&lt;details&gt;

&lt;summary&gt;&lt;code&gt;tailwind.config.js&lt;/code&gt;&lt;/summary&gt;

```typescript
/** @type {import(&#039;tailwindcss&#039;).Config} */
module.exports = {
  content: [&quot;./app/**/*.{js,jsx,ts,tsx}&quot;, &quot;./components/**/*.{js,jsx,ts,tsx}&quot;],
  presets: [require(&quot;nativewind/preset&quot;)],
  theme: {
    extend: {
      colors: {
        primary: &quot;#030014&quot;,
        secondary: &quot;#151312&quot;,
        ratingBox: &quot;#221F3D&quot;,
        searchBar: &quot;#0F0D23&quot;,
        text: &quot;#9CA4AB&quot;,
        darkAccent: &quot;#AB8BFF&quot;,
        accentText: &quot;#A8B5DB&quot;,
        secondaryText: &quot;#D6C7FF&quot;,
      },
    },
  },
  plugins: [],
};
```

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;&lt;code&gt;app/globals.css&lt;/code&gt;&lt;/summary&gt;

```css
@tailwind base;
@tailwind components;
@tailwind utilities;
```

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;&lt;code&gt;interfaces/interfaces.d.ts&lt;/code&gt;&lt;/summary&gt;

```typescript
interface Movie {
  id: number;
  title: string;
  adult: boolean;
  backdrop_path: string;
  genre_ids: number[];
  original_language: string;
  original_title: string;
  overview: string;
  popularity: number;
  poster_path: string;
  release_date: string;
  video: boolean;
  vote_average: number;
  vote_count: number;
}

interface TrendingMovie {
  searchTerm: string;
  movie_id: number;
  title: string;
  count: number;
  poster_url: string;
}

interface MovieDetails {
  adult: boolean;
  backdrop_path: string | null;
  belongs_to_collection: {
    id: number;
    name: string;
    poster_path: string;
    backdrop_path: string;
  } | null;
  budget: number;
  genres: {
    id: number;
    name: string;
  }[];
  homepage: string | null;
  id: number;
  imdb_id: string | null;
  original_language: string;
  original_title: string;
  overview: string | null;
  popularity: number;
  poster_path: string | null;
  production_companies: {
    id: number;
    logo_path: string | null;
    name: string;
    origin_country: string;
  }[];
  production_countries: {
    iso_3166_1: string;
    name: string;
  }[];
  release_date: string;
  revenue: number;
  runtime: number | null;
  spoken_languages: {
    english_name: string;
    iso_639_1: string;
    name: string;
  }[];
  status: string;
  tagline: string | null;
  title: string;
  video: boolean;
  vote_average: number;
  vote_count: number;
}

interface TrendingCardProps {
  movie: TrendingMovie;
  index: number;
}
```

&lt;/details&gt;

## &lt;a name=&quot;links&quot;&gt;üîó Assets&lt;/a&gt;

Assets and snippets used in the project can be found in the **[video kit](https://jsm.dev/rn25-movie)**.

&lt;a href=&quot;https://jsm.dev/rn25-movie&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;assets/readme/videokit.webp&quot; alt=&quot;Video Kit Banner&quot;&gt;
&lt;/a&gt;

## &lt;a name=&quot;more&quot;&gt;üöÄ More&lt;/a&gt;

**Advance your skills with Next.js Pro Course**

Enjoyed creating this project? Dive deeper into our PRO courses for a richer learning adventure. They&#039;re packed with

detailed explanations, cool features, and exercises to boost your skills. Give it a go!

&lt;a href=&quot;https://jsm.dev/rn25-jsm&quot; target=&quot;_blank&quot;&gt;
   &lt;img src=&quot;assets/readme/jsmpro.webp&quot; alt=&quot;Project Banner&quot;&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[xyTom/snippai]]></title>
            <link>https://github.com/xyTom/snippai</link>
            <guid>https://github.com/xyTom/snippai</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:41 GMT</pubDate>
            <description><![CDATA[Snip Anything Solve Everything‚Äã]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xyTom/snippai">xyTom/snippai</a></h1>
            <p>Snip Anything Solve Everything‚Äã</p>
            <p>Language: TypeScript</p>
            <p>Stars: 775</p>
            <p>Forks: 42</p>
            <p>Stars today: 140 stars today</p>
            <h2>README</h2><pre># Getting Started with Create React App

This project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app).

## Available Scripts

In the project directory, you can run:

### `npm start`

Runs the app in the development mode.\
Open [http://localhost:3000](http://localhost:3000) to view it in your browser.

The page will reload when you make changes.\
You may also see any lint errors in the console.

### `npm test`

Launches the test runner in the interactive watch mode.\
See the section about [running tests](https://facebook.github.io/create-react-app/docs/running-tests) for more information.

### `npm run build`

Builds the app for production to the `build` folder.\
It correctly bundles React in production mode and optimizes the build for the best performance.

The build is minified and the filenames include the hashes.\
Your app is ready to be deployed!

See the section about [deployment](https://facebook.github.io/create-react-app/docs/deployment) for more information.

### `npm run eject`

**Note: this is a one-way operation. Once you `eject`, you can&#039;t go back!**

If you aren&#039;t satisfied with the build tool and configuration choices, you can `eject` at any time. This command will remove the single build dependency from your project.

Instead, it will copy all the configuration files and the transitive dependencies (webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except `eject` will still work, but they will point to the copied scripts so you can tweak them. At this point you&#039;re on your own.

You don&#039;t have to ever use `eject`. The curated feature set is suitable for small and middle deployments, and you shouldn&#039;t feel obligated to use this feature. However we understand that this tool wouldn&#039;t be useful if you couldn&#039;t customize it when you are ready for it.

## Learn More

You can learn more in the [Create React App documentation](https://facebook.github.io/create-react-app/docs/getting-started).

To learn React, check out the [React documentation](https://reactjs.org/).

### Code Splitting

This section has moved here: [https://facebook.github.io/create-react-app/docs/code-splitting](https://facebook.github.io/create-react-app/docs/code-splitting)

### Analyzing the Bundle Size

This section has moved here: [https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size](https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size)

### Making a Progressive Web App

This section has moved here: [https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app](https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app)

### Advanced Configuration

This section has moved here: [https://facebook.github.io/create-react-app/docs/advanced-configuration](https://facebook.github.io/create-react-app/docs/advanced-configuration)

### Deployment

This section has moved here: [https://facebook.github.io/create-react-app/docs/deployment](https://facebook.github.io/create-react-app/docs/deployment)

### `npm run build` fails to minify

This section has moved here: [https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify](https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[butlerx/wetty]]></title>
            <link>https://github.com/butlerx/wetty</link>
            <guid>https://github.com/butlerx/wetty</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:40 GMT</pubDate>
            <description><![CDATA[Terminal in browser over http/https. (Ajaxterm/Anyterm alternative, but much better)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/butlerx/wetty">butlerx/wetty</a></h1>
            <p>Terminal in browser over http/https. (Ajaxterm/Anyterm alternative, but much better)</p>
            <p>Language: TypeScript</p>
            <p>Stars: 4,856</p>
            <p>Forks: 722</p>
            <p>Stars today: 54 stars today</p>
            <h2>README</h2><pre># WeTTY = Web + TTY.

&lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt;

[![All Contributors](https://img.shields.io/badge/all_contributors-41-orange.svg?style=flat-square)](#contributors-)

&lt;!-- ALL-CONTRIBUTORS-BADGE:END --&gt;

[![Documentation](https://img.shields.io/badge/documentation-yes-brightgreen.svg)](https://github.com/butlerx/wetty/tree/main/docs)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/butlerx/wetty/blob/main/LICENSE)

&gt; Terminal access in browser over http/https

![WeTTY](./docs/terminal.png?raw=true)

Terminal over HTTP and https. WeTTY is an alternative to ajaxterm and anyterm
but much better than them because WeTTY uses xterm.js which is a full fledged
implementation of terminal emulation written entirely in JavaScript. WeTTY uses
websockets rather than Ajax and hence better response time.

## Prerequisites

- node &gt;=18
- make
- python
- build-essential

## Install

```sh
npm -g i wetty
```

## Usage

```sh
$ wetty --help
Options:
  --help, -h      Print help message                                   [boolean]
  --version       Show version number                                  [boolean]
  --conf          config file to load config from                       [string]
  --ssl-key       path to SSL key                                       [string]
  --ssl-cert      path to SSL certificate                               [string]
  --ssh-host      ssh server host                                       [string]
  --ssh-port      ssh server port                                       [number]
  --ssh-user      ssh user                                              [string]
  --title         window title                                          [string]
  --ssh-auth      defaults to &quot;password&quot;, you can use &quot;publickey,password&quot;
                  instead                                               [string]
  --ssh-pass      ssh password                                          [string]
  --ssh-key       path to an optional client private key (connection will be
                  password-less and insecure!)                          [string]
  --ssh-config    Specifies an alternative ssh configuration file. For further
                  details see &quot;-F&quot; option in ssh(1)                     [string]
  --force-ssh     Connecting through ssh even if running as root       [boolean]
  --known-hosts   path to known hosts file                              [string]
  --base, -b      base path to wetty                                    [string]
  --port, -p      wetty listen port                                     [number]
  --host          wetty listen host                                     [string]
  --command, -c   command to run in shell                               [string]
  --allow-iframe  Allow wetty to be embedded in an iframe, defaults to allowing
                  same origin                                          [boolean]
```

Open your browser on `http://yourserver:3000/wetty` and you will prompted to
login. Or go to `http://yourserver:3000/wetty/ssh/&lt;username&gt;` to specify the
user beforehand.

If you run it as root it will launch `/bin/login` (where you can specify the
user name), else it will launch `ssh` and connect by default to `localhost`. The
SSH connection can be forced using the `--force-ssh` option.

If instead you wish to connect to a remote host you can specify the `--ssh-host`
option, the SSH port using the `--ssh-port` option and the SSH user using the
`--ssh-user` option.

Check out the [Flags docs](https://butlerx.github.io/wetty/flags) for a full
list of flags

### Docker container

To use WeTTY as a docker container, a docker image is available on
[docker hub](https://hub.docker.com/r/wettyoss/wetty). To run this image, use

```sh
docker run --rm -p 3000:3000 wettyoss/wetty --ssh-host=&lt;YOUR-IP&gt;
```

and you will be able to open a ssh session to the host given by `YOUR-IP` under
the URL [http://localhost:3000/wetty](http://localhost:3000/wetty).

It is recommended to drive WeTTY behind a reverse proxy to have HTTPS security
and possibly Let‚Äôs Encrypt support. Popular containers to achieve this are
[nginx-proxy](https://github.com/nginx-proxy/nginx-proxy) and
[traefik](https://traefik.io/traefik/). For traefik there is an example
docker-compose file in the containers directory.

## FAQ

Check out the [docs](https://github.com/butlerx/wetty/tree/main/docs)

- [Running as daemon](https://butlerx.github.io/wetty/service)
- [HTTPS Support](https://butlerx.github.io/wetty/https)
  - [Using NGINX](https://butlerx.github.io/wetty/nginx)
  - [Using Apache](https://butlerx.github.io/wetty/apache)
- [Automatic Login](https://butlerx.github.io/wetty/auto-login)
- [Downloading Files](https://butlerx.github.io/wetty/downloading-files)

### What browsers are supported?

WeTTY supports all browsers that
[xterm.js supports](https://github.com/xtermjs/xterm.js#browser-support).

## Author

üë§ **Cian Butler &lt;butlerx@notthe.cloud&gt;**

- Mastodon: [@butlerx@mastodon.ie](https://mastodon.ie/@butlerx)
- Github: [@butlerx](https://github.com/butlerx)

## Contributing ‚ú®

Contributions, issues and feature requests are welcome!&lt;br /&gt;Feel free to check
[issues page](https://github.com/butlerx/wetty/issues).

Please read the [development docs](https://butlerx.github.io/wetty/development)
for installing from source and running is dev node

Thanks goes to these wonderful people
([emoji key](https://allcontributors.org/docs/en/emoji-key)):

&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://cianbutler.ie&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/867930?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Cian Butler&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Cian Butler&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=butlerx&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=butlerx&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://about.me/krishnasrinivas&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/634494?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Krishna Srinivas&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Krishna Srinivas&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=krishnasrinivas&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/acalatrava&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/8502129?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;acalatrava&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;acalatrava&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=acalatrava&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Strubbl&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/97055?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Strubbl&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Strubbl&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=Strubbl&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/2sheds&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/16163?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Oleg Kurapov&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Oleg Kurapov&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=2sheds&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://www.rabchev.com&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/1876061?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Boyan Rabchev&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Boyan Rabchev&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=rabchev&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/nosemeocurrenada&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/3845708?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Jimmy&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jimmy&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=nosemeocurrenada&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://www.gerritforge.com&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/182893?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Luca Milanesio&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Luca Milanesio&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=lucamilanesio&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://anthonyjund.com&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/39376331?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Anthony Jund&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Anthony Jund&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=antonyjim&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.mirtouf.fr&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/5165058?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;mirtouf&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;mirtouf&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=mirtouf&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://cor-net.org&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/556693?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Bertrand Roussel&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Bertrand Roussel&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=CoRfr&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.benl.com.au/&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/6703966?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Ben Letchford&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ben Letchford&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=benletchford&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/SouraDutta&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/33066261?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;SouraDutta&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;SouraDutta&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=SouraDutta&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/koushikmln&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/8670988?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Koushik M.L.N&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Koushik M.L.N&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=koushikmln&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://imu.li/&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/4085046?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Imuli&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Imuli&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=imuli&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/perpen&quot;&gt;&lt;img src=&quot;https://avatars2.githubusercontent.com/u/9963805?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;perpen&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;perpen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=perpen&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://nathanleclaire.com&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/1476820?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Nathan LeClaire&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Nathan LeClaire&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=nathanleclaire&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/MiKr13&quot;&gt;&lt;img src=&quot;https://avatars2.githubusercontent.com/u/34394719?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Mihir Kumar&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mihir Kumar&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=MiKr13&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://redhat.com&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/540893?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Chris Suszynski&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Chris Suszynski&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=cardil&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://9wd.de&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/1257835?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Felix Bartels&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Felix Bartels&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=fbartels&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/jarrettgilliam&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/5099690?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Jarrett Gilliam&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jarrett Gilliam&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=jarrettgilliam&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://harrylee.me&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/7056279?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Harry Lee&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Harry Lee&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=harryleesan&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://andreask.cs.illinois.edu&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/352067?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Andreas Kl√∂ckner&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Andreas Kl√∂ckner&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=inducer&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/DenisKramer&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/23534092?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;DenisKramer&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;DenisKramer&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=DenisKramer&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/vamship&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/7143376?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Vamshi K Ponnapalli&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Vamshi K Ponnapalli&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=vamship&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://tridnguyen.com&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/1652595?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Tri Nguyen&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Tri Nguyen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=tnguyen14&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://felix.pojtinger.com/&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/28832235?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Felix Pojtinger&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Felix Pojtinger&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=pojntfx&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://nealey.github.io/&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/423780?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Neale Pickett&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Neale Pickett&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=nealey&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.matthewpiercey.ml&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/22581026?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Matthew Piercey&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Matthew Piercey&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=mtpiercey&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/kholbekj&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/2786571?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Kasper Holbek Jensen&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kasper Holbek Jensen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=kholbekj&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://mastodon.technology/@farhan&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/10103765?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Farhan Khan&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Farhan Khan&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=khanzf&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.jurrevriesen.nl&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/7419259?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Jurre Vriesen&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jurre Vriesen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=jurruh&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.kartar.net/&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/4365?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;James Turnbull&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;James Turnbull&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=jamtur01&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/deanshub&quot;&gt;&lt;img src=&quot;https://avatars2.githubusercontent.com/u/2688676?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Dean Shub&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Dean Shub&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=deanshub&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/lozbrown&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/9961593?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;lozbrown &quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;lozbrown &lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=lozbrown&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;#example-lozbrown&quot; title=&quot;Examples&quot;&gt;üí°&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/sergeir82&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/5081149?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;sergeir82&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;sergeir82&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=sergeir82&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/kmlucy&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/13952475?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Kyle Lucy&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kyle Lucy&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=kmlucy&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/userdocs&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/16525024?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;userdocs&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;userdocs&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=userdocs&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://logmein.com/&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/1554533?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Janos Kasza&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Janos Kasza&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=janoskk&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://grantshandy.xyz/&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/45475651?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Grant Handy&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Grant Handy&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=DefunctLizard&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/LeszekBlazewski&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/34927142?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Leszek B≈Ça≈ºewski&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Leszek B≈Ça≈ºewski&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/butlerx/WeTTy/commits?author=LeszekBlazewski&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;#platform-LeszekBlazewski&quot; title=&quot;Packaging/porting to new platform&quot;&gt;üì¶&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- markdownlint-restore --&gt;
&lt;!-- prettier-ignore-end --&gt;

&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt;

This project follows the
[all-contributors](https://github.com/all-contributors/all-contributors)
specification. Contributions of any kind welcome!

## 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[David-patrick-chuks/Riona-AI-Agent]]></title>
            <link>https://github.com/David-patrick-chuks/Riona-AI-Agent</link>
            <guid>https://github.com/David-patrick-chuks/Riona-AI-Agent</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:39 GMT</pubDate>
            <description><![CDATA[Riona Ai Agent üå∏ is built using Node.js and TypeScript üõ†Ô∏è, designed for seamless job execution üì∏. It's lightweight, efficient, and still evolving üöß‚Äîexciting new features coming soon! üåü]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/David-patrick-chuks/Riona-AI-Agent">David-patrick-chuks/Riona-AI-Agent</a></h1>
            <p>Riona Ai Agent üå∏ is built using Node.js and TypeScript üõ†Ô∏è, designed for seamless job execution üì∏. It's lightweight, efficient, and still evolving üöß‚Äîexciting new features coming soon! üåü</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,596</p>
            <p>Forks: 679</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>## Support the Project üôå

If you&#039;d like to support the development of Instagram-AI-Agent, please consider contributing to the following wallet addresses:

- **Bitcoin (BTC)**: 1GkWY6pjn7KoAkCnUab2MxnxeEQihknfUi
- **Ethereum (ETH-erc20)**: 0xabb45f4d85e7d9db5de684c35ccde7239a167cbb
- **Solana (SOL)**: EQV7fQ57zKNMFXy53WBfo2sCxtkRQVQLqj8sqWGnoyR

Your support helps keep this project running and growing! üöÄ

## Instagram-AI-Agent üå∏

Instagram-AI-Agent is an AI-powered automation tool designed for **Instagram** to automate social media interactions such as posting, liking, and commenting. It leverages advanced AI models to generate engaging content, automate interactions, and manage Instagram accounts efficiently.

Before using the automation features, you can personalize the agent by training with the following, including:
https://www.instagram.com/dreamlandofficial_1?igsh=NTZvcHRkNjlhYzhp
- **YouTube Video URL** üé•
- **Audio File** üéôÔ∏è
- **Portfolio or Website Link** üåê
- **File Formats Supported**: PDF, DOC, DOCX, TXT üìÑ

## Features

- **Instagram Automation**: Automatically log in, post photos, like posts, and leave thoughtful comments.
- **AI-Powered Content Generation**: Use Google Generative AI to create engaging captions and comments.
- **Proxy Support**: Use proxies to manage multiple accounts and avoid rate limits.
- **Cookie Management**: Save and load cookies to maintain sessions across restarts.

**Upcoming Features:**

- **Twitter Automation**: (Coming soon) Automatically tweet, retweet, and like tweets.
- **GitHub Automation**: (Coming soon) Automatically manage repositories, issues, and pull requests.

## Installation

1. **Clone the repository**:

   ```sh
   git clone https://github.com/david-patrick-chuks/Instagram-AI-Agent.git
   cd Instagram-AI-Agent
   ```

2. **Install dependencies**:

   ```sh
   npm install
   ```

3. **Set up environment variables**:
   Rename the [.env.example](http://_vscodecontentref_/1) file to [.env](http://_vscodecontentref_/1) in the root directory and add your Instagram credentials. Refer to the [.env.example](http://_vscodecontentref_/2) file for the required variables.
   ```dotenv # Instagram credentials
   IGusername=your_instagram_username
   IGpassword=your_instagram_password 
   
   Xusername= #Twitter username
   Xpassword= #Twitter password

   MONGODB_URI= #MongoDB URI
   ```

## MongoDB Setup (Using Docker)

1. **Install Docker**:
   If you don&#039;t have Docker installed, download and install it from the [official website](https://www.docker.com/products/docker-desktop/)
2. **Run MongoDB using Docker Container**:

    **Option 1:**
      ```sh
      docker run -d -p 27017:27017 --name instagram-ai-mongodb mongodb/mongodb-community-server:latest
      ```
    **Option 2:**
      ```sh
      docker run -d -p 27017:27017 --name instagram-ai-mongodb -v mongodb_data:/data/db mongodb/mongodb-community-server:latest
      ```   
      (Option 2: use this if you want to have like a permanent storage in you so your data won&#039;t be lost or remove if you stop or remove your Docker container)
3. **Modify the MONGODB_URI in the .env file**:
   ```dotenv
   MONGODB_URI=mongodb://localhost:27017/instagram-ai-agent
   ```
4. **Verify the connection**:
   Open a new terminal and run the following command:
   ```sh
   docker ps
   ```
   You should see the MongoDB container running.

   Docker Commands (Additional Info):
   - To stop the MongoDB container:
     ```sh
     docker stop instagram-ai-mongodb
     ```
   - To start the MongoDB container:
       ```sh
       docker start instagram-ai-mongodb
       ```
   - To remove the MongoDB container:
      ```sh
      docker rm instagram-ai-mongodb
      ```
   - To remove the MongoDB container and its data:
      ```sh
      docker rm -v instagram-ai-mongodb
      ```

## Usage

1. **Run the Instagram agent**:
   ```sh
   npm start
   ```

**Upcoming Features:**

- **Run the Twitter agent** (Coming soon):

  ```sh
  npm run start:twitter
  ```

- **Run the GitHub agent** (Coming soon):
  ```sh
  npm run start:github
  ```

## Project Structure

- **src/client**: Contains the main logic for interacting with social media platforms like Instagram.
- **src/config**: Configuration files, including the logger setup.
- **src/utils**: Utility functions for handling errors, cookies, data saving, etc.
- **src/Agent**: Contains the AI agent logic and training scripts.
- **src/Agent/training**: Training scripts for the AI agent.
- **src/schema**: Schema definitions for AI-generated content and database models.
- **src/test**: Contains test data and scripts, such as example tweets.

## Logging

The project uses a custom logger to log information, warnings, and errors. Logs are saved in the [logs](http://_vscodecontentref_/3) directory.

## Error Handling

Process-level error handlers are set up to catch unhandled promise rejections, uncaught exceptions, and process warnings. Errors are logged using the custom logger.

## Contributing

Contributions are welcome! Please fork the repository and submit a pull request with your changes.

## License

This project is licensed under the MIT License. See the LICENSE file for details.

## Acknowledgements

- [Google Generative AI](https://ai.google/tools/) for providing the AI models.
- [Puppeteer](https://github.com/puppeteer/puppeteer) for browser automation.
- [puppeteer-extra](https://github.com/berstend/puppeteer-extra) for additional plugins and enhancements.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[huggingface/aisheets]]></title>
            <link>https://github.com/huggingface/aisheets</link>
            <guid>https://github.com/huggingface/aisheets</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:38 GMT</pubDate>
            <description><![CDATA[Build, enrich, and transform datasets using AI models with no code]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/aisheets">huggingface/aisheets</a></h1>
            <p>Build, enrich, and transform datasets using AI models with no code</p>
            <p>Language: TypeScript</p>
            <p>Stars: 261</p>
            <p>Forks: 19</p>
            <p>Stars today: 110 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# ü§ó Hugging Face AI Sheets

*Build, enrich, and transform datasets using AI models with no code. Deploy locally or on the Hub with access to thousands of open models.*

[Introduction](https://huggingface.co/blog/aisheets) ‚Ä¢ [Try it out](https://huggingface.co/spaces/aisheets/sheets)

&lt;video width=&quot;400&quot; src=&quot;https://github.com/user-attachments/assets/a284e4d4-3c11-4885-96cc-2f6f0314f2a1&quot;&gt;&lt;/video&gt;

&lt;/div&gt;

## What&#039;s AI Sheets?

Hugging Face AI Sheets is an open-source tool for building, enriching, and transforming datasets using AI models with no code. The tool can be deployed locally or on the Hub. It lets you use thousands of open models from the Hugging Face Hub via Inference Providers or local models, including `gpt-oss` from OpenAI!


## Quick Start

### Using the AI Sheets Space

Try it instantly at &lt;https://huggingface.co/spaces/aisheets/sheets&gt;

### Using Docker

First, get your Hugging Face token from &lt;https://huggingface.co/settings/tokens&gt;

```bash
export HF_TOKEN=your_token_here
docker run -p 3000:3000 \
-e HF_TOKEN=HF_TOKEN \
AI Sheets/sheets
```

Open `http://localhost:3000` in your browser.

### Using pnpm

First, [install pnpm](https://pnpm.io/installation) if you haven&#039;t already.

```bash
git clone https://github.com/huggingface/sheets.git
cd sheets
export HF_TOKEN=your_token_here
pnpm install
pnpm dev
```

Open `http://localhost:5173` in your browser.

#### Building for production

To build the production application, run:

```bash
pnpm build
```

This will create a production build in the `dist` directory.

Then, you can launch the built-in Express server to serve the production build:

```bash
export HF_TOKEN=your_token_here
pnpm serve
```

## Running AI Sheets with custom (and local) LLMs

By default, AI Sheets is configured to use the Huggingface Inference Providers API to run inference on the latest open-source models. However, you can also run Sheets with own custom LLMs, such as those hosted on your own infrastructure or other cloud providers. The only requirement is that your LLMs must support the [OpenAI API specification](https://platform.openai.com/docs/api-reference/introduction).

## Steps

When running AI Sheets with custom LLMs, you need to set some environment variables to point the inference calls to your custom LLMs. Here are the steps:

1. **Set the `MODEL_ENDPOINT_URL` environment variable**: This variable should point to the base URL of your custom LLM&#039;s API endpoint. For example, if you are using Ollama to run your LLM locally, you would set it like this:

```sh
export MODEL_ENDPOINT_URL=http://localhost:11434
```

Since Ollama starts a local server on port `11434` by default, this URL will point to your local Ollama instance.

2. **Set the `MODEL_ENDPOINT_NAME` environment variable**: This variable should specify the name of the model you want to use. For example, if you are using the `llama3` model, you would set it like this:

```sh
export MODEL_ENDPOINT_NAME=llama3
```

This is a crucial step to conform to the OpenAI API specification. The model name is a required parameter in the [OpenAI API](https://platform.openai.com/docs/api-reference/responses/create#responses-create-model), and it is used to identify which model to use for inference.

3. **Run the AI Sheets app**: After setting the environment variables, you can run the Sheets app as usual. The app will now use your custom LLM for inference instead of the default Huggingface Inference Providers API as the default behavior. Anyway, all the models provided by the Huggingface Inference Providers API will still be available when selecting a model in the column settings.

* Note: The text-to-image generation feature cannot be customized yet. It will always utilize the Hugging Face Inference Providers API to generate images. Take this into account when running AI Sheets with custom LLMs.

## Example of running AI Sheets with Ollama

To run AI Sheets with Ollama, you can follow these steps:

1. Start the Ollama server, and run the model of your choice
```sh
export OLLAMA_NOHISTORY=1
ollama serve
```

```sh
ollama run llama3
```

(Visit the Ollama [FAQ](https://github.com/ollama/ollama/blob/main/docs/faq.md#how-can-i-specify-the-context-window-size) page to know more about Ollama server configuration)

2. Set the environment variables:

```sh
export MODEL_ENDPOINT_URL=http://localhost:11434
export MODEL_ENDPOINT_NAME=llama3
```

3. Run the AI Sheets app:

```sh
pnpm serve
```

This will start the AI Sheets app and use the `llama3` model running on your local Ollama instance for inference.

## Advanced configuration

AI Sheets defines some environment variables that can be used to customize the behavior of the application. In the following sections, we will describe the available environment variables and their usage.

### ¬†Authentication

- `OAUTH_CLIENT_ID`: The Hugging Face OAuth client ID for the application. This is used to authenticate users via the Hugging Face OAuth. If this variable is defined, it will be used to authenticate users. (See how to setup the Hugging Face OAuth [here](https://huggingface.co/blog/frascuchon/running-sheets-locally#oauth-authentication)).

- `HF_TOKEN`: A Hugging Face token to use for authentication. If this variable is defined, it will be used for authenticated inference calls, instead of the OAuth token.

- `OAUTH_SCOPES`: The scopes to request during the OAuth authentication. The default value is `openid profile inference-api manage-repos`. This variable is used to request the necessary permissions for the application to function correctly, and normally does not need to be changed.

### ¬†Inference

- `DEFAULT_MODEL`: The default model id to use when calling the inference API for text generation. The default value is `meta-llama/Llama-3.3-70B-Instruct`. This variable can be used to change the default model used for text generation and must be a valid model id from the [Hugging Face Hub](https://huggingface.co/models?pipeline_tag=text-generation&amp;inference_provider=all&amp;sort=trending),

- `DEFAULT_MODEL_PROVIDER`: The default model provider to use when calling the inference API for text generation. The default value is `nebius`. This variable can be used to change the default model provider used for text generation and must be a valid provider from the [Hugging Face Inference Providers](https://huggingface.co/docs/inference-providers/en/index).

- `ORG_BILLING`: The organization billing to use for inference calls. If this variable is defined, the inference calls will be billed to the specified organization. This is useful for organizations that want to manage their inference costs and usage. Remember that users must be part of the organization to use this feature, or an `HF_TOKEN` of a user that is part of the organization must be defined.

- `MODEL_ENDPOINT_URL`:  The URL of a custom inference endpoint to use for text generation. If this variable is defined, it will be used instead of the default Hugging Face Inference API. This is useful for using custom inference endpoints that are not hosted on the Hugging Face Hub, such as Ollama or LLM Studio. The URL must be a valid endpoint that supports the [OpenAI API format](https://platform.openai.com/docs/api-reference/chat/create).

- `MODEL_ENDPOINT_NAME`: The model id to use when calling the custom inference endpoint defined by `MODEL_ENDPOINT_URL`. This variable is required if `MODEL_ENDPOINT_URL` is defined for custom inference endpoints that require a model id, such as Ollama or LLM Studio. The model id must correspond to the model deployed on the custom inference endpoint.

- `NUM_CONCURRENT_REQUESTS`: The number of concurrent requests to allow when calling the inference API in the column cells generation process. The default value is `5`, and the maximum value is `10`. This is useful to control the number of concurrent requests made to the inference API and avoid hitting rate limits defined by the provider.

### Miscellaneous

- `DATA_DIR`: The directory where the application will store all its data. The default value is `./data`. This variable can be used to change the data directory used by the application. The directory must be writable by the application.

- `SERPER_API_KEY`: The API key to use for the Serper web search API. If this variable is defined, it will be used to authenticate web search requests. If this variable is not defined, web search will be disabled. The Serper API key can be obtained from the [Serper website](https://serper.dev/).

- `TELEMETRY_ENABLED`: A boolean value that indicates whether telemetry is enabled or not. The default value is `1`. This variable can be used to disable telemetry if desired. Telemetry is used to collect anonymous usage data to help improve the application.

- `EXAMPLES_PROMPT_MAX_CONTEXT_SIZE`: The maximum context size (in characters) for the examples section in the prompt for text generation. The default value is `8192`. If the examples section exceeds this size, it will be truncated. This variable can be used when the examples section is too large and needs to be reduced to fit within the context size limits of the model.

- `SOURCES_PROMPT_MAX_CONTEXT_SIZE`: The maximum context size (in characters) for the sources section in the prompt for text generation. The default value is `61440`. If the sources section exceeds this size, it will be truncated. This variable can be used when the sources section is too large and needs to be reduced to fit within the context size limits of the model.


## Developer docs

### Dev dependencies on your vscode

#### vitest runner

&lt;https://marketplace.visualstudio.com/items?itemName=rluvaton.vscode-vitest&gt;

#### biome

&lt;https://marketplace.visualstudio.com/items?itemName=biomejs.biome&gt;

### Project Structure

This project is using Qwik with [QwikCity](https://qwik.dev/qwikcity/overview/). QwikCity is just an extra set of tools on top of Qwik to make it easier to build a full site, including directory-based routing, layouts, and more.

Inside your project, you&#039;ll see the following directory structure:

```
‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ components/ --&gt; Stateless components
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îú‚îÄ‚îÄ features/ --&gt; Components with business logic
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ routes/
        ‚îî‚îÄ‚îÄ ...
```

- `src/routes`: Provides the directory-based routing, which can include a hierarchy of `layout.tsx` layout files, and an `index.tsx` file as the page. Additionally, `index.ts` files are endpoints. Please see the [routing docs](https://qwik.dev/qwikcity/routing/overview/) for more info.

- `src/components`: Recommended directory for components.

- `public`: Any static assets, like images, can be placed in the public directory. Please see the [Vite public directory](https://vitejs.dev/guide/assets.html#the-public-directory) for more info.

### Development

Run this on your root folder

```sh
touch .env
```

Add in your `.env` file the following variable:

```
HF_TOKEN=your_hugging_face_token
```

Development mode uses [Vite&#039;s development server](https://vitejs.dev/). The `dev` command will server-side render (SSR) the output during development.

```shell
pnpm dev
```

&gt; Note: during dev mode, Vite may request a significant number of `.js` files. This does not represent a Qwik production build.

### Preview

The preview command will create a production build of the client modules, a production build of `src/entry.preview.tsx`, and run a local server. The preview server is only for convenience to preview a production build locally and should not be used as a production server.

```shell
pnpm preview
```

### Production

The production build will generate client and server modules by running both client and server build commands. The build command will use Typescript to run a type check on the source code.

```shell
pnpm build
```

### Express Server

This app has a minimal [Express server](https://expressjs.com/) implementation. After running a full build, you can preview the build using the command:

```
pnpm serve
```

Then visit [http://localhost:3000/](http://localhost:3000/)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ericc-ch/copilot-api]]></title>
            <link>https://github.com/ericc-ch/copilot-api</link>
            <guid>https://github.com/ericc-ch/copilot-api</guid>
            <pubDate>Tue, 12 Aug 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[Turn GitHub Copilot into OpenAI/Anthropic API compatible server. Usable with Claude Code!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ericc-ch/copilot-api">ericc-ch/copilot-api</a></h1>
            <p>Turn GitHub Copilot into OpenAI/Anthropic API compatible server. Usable with Claude Code!</p>
            <p>Language: TypeScript</p>
            <p>Stars: 661</p>
            <p>Forks: 136</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre># Copilot API Proxy

&gt; [!WARNING]
&gt; This is a reverse-engineered proxy of GitHub Copilot API. It is not supported by GitHub, and may break unexpectedly. Use at your own risk.

[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/E1E519XS7W)

---

**Note:** If you are using [opencode](https://github.com/sst/opencode), you do not need this project. Opencode supports GitHub Copilot provider out of the box.

---

## Project Overview

A reverse-engineered proxy for the GitHub Copilot API that exposes it as an OpenAI and Anthropic compatible service. This allows you to use GitHub Copilot with any tool that supports the OpenAI Chat Completions API or the Anthropic Messages API, including to power [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview).

## Features

- **OpenAI &amp; Anthropic Compatibility**: Exposes GitHub Copilot as an OpenAI-compatible (`/v1/chat/completions`, `/v1/models`, `/v1/embeddings`) and Anthropic-compatible (`/v1/messages`) API.
- **Claude Code Integration**: Easily configure and launch [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview) to use Copilot as its backend with a simple command-line flag (`--claude-code`).
- **Usage Dashboard**: A web-based dashboard to monitor your Copilot API usage, view quotas, and see detailed statistics.
- **Rate Limit Control**: Manage API usage with rate-limiting options (`--rate-limit`) and a waiting mechanism (`--wait`) to prevent errors from rapid requests.
- **Manual Request Approval**: Manually approve or deny each API request for fine-grained control over usage (`--manual`).
- **Token Visibility**: Option to display GitHub and Copilot tokens during authentication and refresh for debugging (`--show-token`).
- **Flexible Authentication**: Authenticate interactively or provide a GitHub token directly, suitable for CI/CD environments.
- **Support for Different Account Types**: Works with individual, business, and enterprise GitHub Copilot plans.

## Demo

https://github.com/user-attachments/assets/7654b383-669d-4eb9-b23c-06d7aefee8c5

## Prerequisites

- Bun (&gt;= 1.2.x)
- GitHub account with Copilot subscription (individual, business, or enterprise)

## Installation

To install dependencies, run:

```sh
bun install
```

## Using with Docker

Build image

```sh
docker build -t copilot-api .
```

Run the container

```sh
# Create a directory on your host to persist the GitHub token and related data
mkdir -p ./copilot-data

# Run the container with a bind mount to persist the token
# This ensures your authentication survives container restarts

docker run -p 4141:4141 -v $(pwd)/copilot-data:/root/.local/share/copilot-api copilot-api
```

&gt; **Note:**
&gt; The GitHub token and related data will be stored in `copilot-data` on your host. This is mapped to `/root/.local/share/copilot-api` inside the container, ensuring persistence across restarts.

### Docker with Environment Variables

You can pass the GitHub token directly to the container using environment variables:

```sh
# Build with GitHub token
docker build --build-arg GH_TOKEN=your_github_token_here -t copilot-api .

# Run with GitHub token
docker run -p 4141:4141 -e GH_TOKEN=your_github_token_here copilot-api

# Run with additional options
docker run -p 4141:4141 -e GH_TOKEN=your_token copilot-api start --verbose --port 4141
```

### Docker Compose Example

```yaml
version: &#039;3.8&#039;
services:
  copilot-api:
    build: .
    ports:
      - &quot;4141:4141&quot;
    environment:
      - GH_TOKEN=your_github_token_here
    restart: unless-stopped
```

The Docker image includes:
- Multi-stage build for optimized image size
- Non-root user for enhanced security
- Health check for container monitoring
- Pinned base image version for reproducible builds

## Using with npx

You can run the project directly using npx:

```sh
npx copilot-api@latest start
```

With options:

```sh
npx copilot-api@latest start --port 8080
```

For authentication only:

```sh
npx copilot-api@latest auth
```

## Command Structure

Copilot API now uses a subcommand structure with these main commands:

- `start`: Start the Copilot API server. This command will also handle authentication if needed.
- `auth`: Run GitHub authentication flow without starting the server. This is typically used if you need to generate a token for use with the `--github-token` option, especially in non-interactive environments.
- `check-usage`: Show your current GitHub Copilot usage and quota information directly in the terminal (no server required).
- `debug`: Display diagnostic information including version, runtime details, file paths, and authentication status. Useful for troubleshooting and support.

## Command Line Options

### Start Command Options

The following command line options are available for the `start` command:

| Option         | Description                                                                   | Default    | Alias |
| -------------- | ----------------------------------------------------------------------------- | ---------- | ----- |
| --port         | Port to listen on                                                             | 4141       | -p    |
| --verbose      | Enable verbose logging                                                        | false      | -v    |
| --account-type | Account type to use (individual, business, enterprise)                        | individual | -a    |
| --manual       | Enable manual request approval                                                | false      | none  |
| --rate-limit   | Rate limit in seconds between requests                                        | none       | -r    |
| --wait         | Wait instead of error when rate limit is hit                                  | false      | -w    |
| --github-token | Provide GitHub token directly (must be generated using the `auth` subcommand) | none       | -g    |
| --claude-code  | Generate a command to launch Claude Code with Copilot API config              | false      | -c    |
| --show-token   | Show GitHub and Copilot tokens on fetch and refresh                           | false      | none  |

### Auth Command Options

| Option       | Description               | Default | Alias |
| ------------ | ------------------------- | ------- | ----- |
| --verbose    | Enable verbose logging    | false   | -v    |
| --show-token | Show GitHub token on auth | false   | none  |

### Debug Command Options

| Option | Description                    | Default | Alias |
| ------ | ------------------------------ | ------- | ----- |
| --json | Output debug info as JSON      | false   | none  |

## API Endpoints

The server exposes several endpoints to interact with the Copilot API. It provides OpenAI-compatible endpoints and now also includes support for Anthropic-compatible endpoints, allowing for greater flexibility with different tools and services.

### OpenAI Compatible Endpoints

These endpoints mimic the OpenAI API structure.

| Endpoint                    | Method | Description                                               |
| --------------------------- | ------ | --------------------------------------------------------- |
| `POST /v1/chat/completions` | `POST` | Creates a model response for the given chat conversation. |
| `GET /v1/models`            | `GET`  | Lists the currently available models.                     |
| `POST /v1/embeddings`       | `POST` | Creates an embedding vector representing the input text.  |

### Anthropic Compatible Endpoints

These endpoints are designed to be compatible with the Anthropic Messages API.

| Endpoint                         | Method | Description                                                  |
| -------------------------------- | ------ | ------------------------------------------------------------ |
| `POST /v1/messages`              | `POST` | Creates a model response for a given conversation.           |
| `POST /v1/messages/count_tokens` | `POST` | Calculates the number of tokens for a given set of messages. |

### Usage Monitoring Endpoints

New endpoints for monitoring your Copilot usage and quotas.

| Endpoint     | Method | Description                                                  |
| ------------ | ------ | ------------------------------------------------------------ |
| `GET /usage` | `GET`  | Get detailed Copilot usage statistics and quota information. |
| `GET /token` | `GET`  | Get the current Copilot token being used by the API.         |

## Example Usage

Using with npx:

```sh
# Basic usage with start command
npx copilot-api@latest start

# Run on custom port with verbose logging
npx copilot-api@latest start --port 8080 --verbose

# Use with a business plan GitHub account
npx copilot-api@latest start --account-type business

# Use with an enterprise plan GitHub account
npx copilot-api@latest start --account-type enterprise

# Enable manual approval for each request
npx copilot-api@latest start --manual

# Set rate limit to 30 seconds between requests
npx copilot-api@latest start --rate-limit 30

# Wait instead of error when rate limit is hit
npx copilot-api@latest start --rate-limit 30 --wait

# Provide GitHub token directly
npx copilot-api@latest start --github-token ghp_YOUR_TOKEN_HERE

# Run only the auth flow
npx copilot-api@latest auth

# Run auth flow with verbose logging
npx copilot-api@latest auth --verbose

# Show your Copilot usage/quota in the terminal (no server needed)
npx copilot-api@latest check-usage

# Display debug information for troubleshooting
npx copilot-api@latest debug

# Display debug information in JSON format
npx copilot-api@latest debug --json
```

## Using the Usage Viewer

After starting the server, a URL to the Copilot Usage Dashboard will be displayed in your console. This dashboard is a web interface for monitoring your API usage.

1.  Start the server. For example, using npx:
    ```sh
    npx copilot-api@latest start
    ```
2.  The server will output a URL to the usage viewer. Copy and paste this URL into your browser. It will look something like this:
    `https://ericc-ch.github.io/copilot-api?endpoint=http://localhost:4141/usage`
    - If you use the `start.bat` script on Windows, this page will open automatically.

The dashboard provides a user-friendly interface to view your Copilot usage data:

- **API Endpoint URL**: The dashboard is pre-configured to fetch data from your local server endpoint via the URL query parameter. You can change this URL to point to any other compatible API endpoint.
- **Fetch Data**: Click the &quot;Fetch&quot; button to load or refresh the usage data. The dashboard will automatically fetch data on load.
- **Usage Quotas**: View a summary of your usage quotas for different services like Chat and Completions, displayed with progress bars for a quick overview.
- **Detailed Information**: See the full JSON response from the API for a detailed breakdown of all available usage statistics.
- **URL-based Configuration**: You can also specify the API endpoint directly in the URL using a query parameter. This is useful for bookmarks or sharing links. For example:
  `https://ericc-ch.github.io/copilot-api?endpoint=http://your-api-server/usage`

## Using with Claude Code

This proxy can be used to power [Claude Code](https://docs.anthropic.com/en/claude-code), an experimental conversational AI assistant for developers from Anthropic.

There are two ways to configure Claude Code to use this proxy:

### Interactive Setup with `--claude-code` flag

To get started, run the `start` command with the `--claude-code` flag:

```sh
npx copilot-api@latest start --claude-code
```

You will be prompted to select a primary model and a &quot;small, fast&quot; model for background tasks. After selecting the models, a command will be copied to your clipboard. This command sets the necessary environment variables for Claude Code to use the proxy.

Paste and run this command in a new terminal to launch Claude Code.

### Manual Configuration with `settings.json`

Alternatively, you can configure Claude Code by creating a `.claude/settings.json` file in your project&#039;s root directory. This file should contain the environment variables needed by Claude Code. This way you don&#039;t need to run the interactive setup every time.

Here is an example `.claude/settings.json` file:

```json
{
  &quot;env&quot;: {
    &quot;ANTHROPIC_BASE_URL&quot;: &quot;http://localhost:4141&quot;,
    &quot;ANTHROPIC_AUTH_TOKEN&quot;: &quot;dummy&quot;,
    &quot;ANTHROPIC_MODEL&quot;: &quot;gpt-4.1&quot;,
    &quot;ANTHROPIC_SMALL_FAST_MODEL&quot;: &quot;gpt-4.1&quot;
  }
}
```

You can find more options here: [Claude Code settings](https://docs.anthropic.com/en/docs/claude-code/settings#environment-variables)

You can also read more about IDE integration here: [Add Claude Code to your IDE](https://docs.anthropic.com/en/docs/claude-code/ide-integrations)

## Running from Source

The project can be run from source in several ways:

### Development Mode

```sh
bun run dev
```

### Production Mode

```sh
bun run start
```

## Usage Tips

- To avoid hitting GitHub Copilot&#039;s rate limits, you can use the following flags:
  - `--manual`: Enables manual approval for each request, giving you full control over when requests are sent.
  - `--rate-limit &lt;seconds&gt;`: Enforces a minimum time interval between requests. For example, `copilot-api start --rate-limit 30` will ensure there&#039;s at least a 30-second gap between requests.
  - `--wait`: Use this with `--rate-limit`. It makes the server wait for the cooldown period to end instead of rejecting the request with an error. This is useful for clients that don&#039;t automatically retry on rate limit errors.
- If you have a GitHub business or enterprise plan account with Copilot, use the `--account-type` flag (e.g., `--account-type business`). See the [official documentation](https://docs.github.com/en/enterprise-cloud@latest/copilot/managing-copilot/managing-github-copilot-in-your-organization/managing-access-to-github-copilot-in-your-organization/managing-github-copilot-access-to-your-organizations-network#configuring-copilot-subscription-based-network-routing-for-your-enterprise-or-organization) for more details.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>