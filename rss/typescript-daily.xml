<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Mon, 02 Mar 2026 00:06:44 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[moeru-ai/airi]]></title>
            <link>https://github.com/moeru-ai/airi</link>
            <guid>https://github.com/moeru-ai/airi</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:44 GMT</pubDate>
            <description><![CDATA[üíñüß∏ Self hosted, you-owned Grok Companion, a container of souls of waifu, cyber livings to bring them into our worlds, wishing to achieve Neuro-sama's altitude. Capable of realtime voice chat, Minecraft, Factorio playing. Web / macOS / Windows supported.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/moeru-ai/airi">moeru-ai/airi</a></h1>
            <p>üíñüß∏ Self hosted, you-owned Grok Companion, a container of souls of waifu, cyber livings to bring them into our worlds, wishing to achieve Neuro-sama's altitude. Capable of realtime voice chat, Minecraft, Factorio playing. Web / macOS / Windows supported.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 20,189</p>
            <p>Forks: 1,908</p>
            <p>Stars today: 736 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
  &lt;source
    width=&quot;100%&quot;
    srcset=&quot;./docs/content/public/banner-dark-1280x640.avif&quot;
    media=&quot;(prefers-color-scheme: dark)&quot;
  /&gt;
  &lt;source
    width=&quot;100%&quot;
    srcset=&quot;./docs/content/public/banner-light-1280x640.avif&quot;
    media=&quot;(prefers-color-scheme: light), (prefers-color-scheme: no-preference)&quot;
  /&gt;
  &lt;img width=&quot;250&quot; src=&quot;./docs/content/public/banner-light-1280x640.avif&quot; /&gt;
&lt;/picture&gt;

&lt;h1 align=&quot;center&quot;&gt;Project AIRI&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;Re-creating Neuro-sama, a soul container of AI waifu / virtual characters to bring them into our world.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  [&lt;a href=&quot;https://discord.gg/TgQ3Cu2F7A&quot;&gt;Join Discord Server&lt;/a&gt;] [&lt;a href=&quot;https://airi.moeru.ai&quot;&gt;Try it&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.zh-CN.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.ja-JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.ru-RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.vi.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.fr.md&quot;&gt;Fran√ßais&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.ko-KR.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;]
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://deepwiki.com/moeru-ai/airi&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/moeru-ai/airi.svg?style=flat&amp;colorA=080f12&amp;colorB=1fa669&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/TgQ3Cu2F7A&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2FTgQ3Cu2F7A%3Fwith_counts%3Dtrue&amp;query=%24.approximate_member_count&amp;suffix=%20members&amp;logo=discord&amp;logoColor=white&amp;label=%20&amp;color=7389D8&amp;labelColor=6A7EC2&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/proj_airi&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%40proj__airi-black?style=flat&amp;logo=x&amp;labelColor=%23101419&amp;color=%232d2e30&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://t.me/+7M_ZKO3zUHFlOThh&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Telegram-%235AA9E6?logo=telegram&amp;labelColor=FFFFFF&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/wechat.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/WeChat-%2307C160?logo=wechat&amp;logoColor=%2307C160&amp;labelColor=FFFFFF&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://qun.qq.com/universal-share/share?ac=1&amp;authKey=9g00d%2BZS7nORzcJugNNddJ7rCghZTIR7fhXabGwch2S%2BG%2BKGIKwlN1N2nIqkh2jg&amp;busi_data=eyJncm91cENvZGUiOiIxMDU4MTU2Njk3IiwidG9rZW4iOiJmcnkra1hWNFIxNytEcG0zcHRUdVJIaldlRDFxN0dzK080QWtvTEdOQjJkNEY2eUFta1g1clNpbkxSMS9FQWFYIiwidWluIjoiMTI2MDkwNzMzNSJ9&amp;data=b1eJrwn3GVOUh7YIxZ7l9vHQo99HPmRxKPpMKlDCmfzx8Y57IXb2EZCMaOC9rVTd2U558qpNjwUYUWlPHxVHvg&amp;svctype=4&amp;tempid=h5_group_info&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/QQ-%2312B7F5?logo=qq&amp;labelColor=FFFFFF&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.producthunt.com/products/airi?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_source=badge-airi&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=993524&amp;theme=neutral&amp;t=1752696535380&quot; alt=&quot;AIRI - A&amp;#0032;container&amp;#0032;of&amp;#0032;cyber&amp;#0032;living&amp;#0032;souls&amp;#0044;&amp;#0032;re&amp;#0045;creation&amp;#0032;of&amp;#0032;Neuro&amp;#0045;sama | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/14636&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14636&quot; alt=&quot;moeru-ai%2Fairi | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; Heavily inspired by [Neuro-sama](https://www.youtube.com/@Neurosama)

&gt; [!WARNING]
&gt; **Attention:** We **do not** have any officially minted cryptocurrency or token associated with this project. Please check the information and proceed with caution.

&gt; [!NOTE]
&gt;
&gt; We&#039;ve got a whole dedicated organization [@proj-airi](https://github.com/proj-airi) for all the sub-projects born from Project AIRI. Check it out!
&gt;
&gt; RAG, memory system, embedded database, icons, Live2D utilities, and more!

&gt; [!TIP]
&gt; We have a translation project on [Crowdin](https://crowdin.com/project/proj-airi). If you find any inaccurate translations, feel free to contribute improvements there.
&gt; &lt;a href=&quot;https://crowdin.com/project/proj-airi&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img style=&quot;width: 140px; height: 40px;&quot; src=&quot;https://badges.crowdin.net/badge/light/crowdin-on-dark.png&quot; srcset=&quot;https://badges.crowdin.net/badge/light/crowdin-on-dark.png 1x, https://badges.crowdin.net/badge/light/crowdin-on-dark@2x.png 2x&quot; alt=&quot;Crowdin | Agile localization for tech companies&quot; width=&quot;140&quot; height=&quot;40&quot; /&gt;&lt;/a&gt;

Have you dreamed about having a cyber living being (cyber waifu, digital pet) or digital companion that could play with and talk to you?

With the power of modern large language models like [ChatGPT](https://chatgpt.com) and famous [Claude](https://claude.ai), asking a virtual being to roleplay and chat with us is already easy enough for everyone. Platforms like [Character.ai (a.k.a. c.ai)](https://character.ai) and [JanitorAI](https://janitorai.com/) as well as local playgrounds like [SillyTavern](https://github.com/SillyTavern/SillyTavern) are already good-enough solutions for a chat based or visual adventure game like experience.

&gt; But, what about the abilities to play games? And see what you are coding at? Chatting while playing games, watching videos, and is capable of doing many other things.

Perhaps you know [Neuro-sama](https://www.youtube.com/@Neurosama) already. She is currently the best virtual streamer capable of playing games, chatting, and interacting with you and the participants. Some also call this kind of being &quot;digital human.&quot; **Sadly, as it&#039;s not open sourced, you cannot interact with her after her live streams go offline**.

Therefore, this project, AIRI, offers another possibility here: **let you own your digital life, cyber living, easily, anywhere, anytime**.

## DevLogs We Posted &amp; Recent Updates

- [DevLog @ 2026.02.16](https://airi.moeru.ai/docs/en/blog/DevLog-2026.02.16/) on February 16, 2026
- [DevLog @ 2026.01.01](https://airi.moeru.ai/docs/en/blog/DevLog-2026.01.01/) on January 1, 2026
- [DevLog @ 2025.10.20](https://airi.moeru.ai/docs/en/blog/DevLog-2025.10.20/) on October 20, 2025
- [DevLog @ 2025.08.05](https://airi.moeru.ai/docs/en/blog/DevLog-2025.08.05/) on August 5, 2025
- [DevLog @ 2025.08.01](https://airi.moeru.ai/docs/en/blog/DevLog-2025.08.01/) on August 1, 2025
- [DreamLog 0x1](https://airi.moeru.ai/docs/en/blog/dreamlog-0x1/) on June 16, 2025
- ...more on [documentation site](https://airi.moeru.ai/docs/en/)

## What&#039;s So Special About This Project?

Unlike the other AI driven VTuber open source projects, „Ç¢„Ç§„É™ was built with support of many Web technologies such as [WebGPU](https://www.w3.org/TR/webgpu/), [WebAudio](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API), [Web Workers](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers), [WebAssembly](https://webassembly.org/), [WebSocket](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket), etc. from the first day.

&gt; [!TIP]
&gt; Worrying about the performance drop since we are using Web related technologies?
&gt;
&gt; Don&#039;t worry, while Web browser version is meant to give an insight about how much we can push and do inside browsers, and webviews, we will never fully rely on this, the desktop version of AIRI is capable of using native [NVIDIA CUDA](https://developer.nvidia.com/cuda-toolkit) and [Apple Metal](https://developer.apple.com/metal/) by default (thanks to HuggingFace &amp; beloved [candle](https://github.com/huggingface/candle) project), without any complex dependency managements, considering the tradeoff, it was partially powered by Web technologies for graphics, layouts, animations, and the WIP plugin systems for everyone to integrate things.

This means that **„Ç¢„Ç§„É™ is capable of running on modern browsers and devices** and even on mobile devices (already done with PWA support). This brings a lot of possibilities for us (the developers) to build and extend the power of „Ç¢„Ç§„É™ VTuber to the next level, while still leaving the flexibilities for users to enable features that requires TCP connections or other non-Web technologies such as connecting to a Discord voice channel or playing Minecraft and Factorio with friends.

&gt; [!NOTE]
&gt;
&gt; We are still in the early stage of development where we are seeking out talented developers to join us and help us to make „Ç¢„Ç§„É™ a reality.
&gt;
&gt; It&#039;s ok if you are not familiar with Vue.js, TypeScript, and devtools required for this project, you can join us as an artist, designer, or even help us to launch our first live stream.
&gt;
&gt; Even if you are a big fan of React, Svelte or even Solid, we welcome you. You can open a sub-directory to add features that you want to see in „Ç¢„Ç§„É™, or would like to experiment with.
&gt;
&gt; Fields (and related projects) that we are looking for:
&gt;
&gt; - Live2D modeller
&gt; - VRM modeller
&gt; - VRChat avatar designer
&gt; - Computer Vision
&gt; - Reinforcement Learning
&gt; - Speech Recognition
&gt; - Speech Synthesis
&gt; - ONNX Runtime
&gt; - Transformers.js
&gt; - vLLM
&gt; - WebGPU
&gt; - Three.js
&gt; - WebXR ([checkout the another project](https://github.com/moeru-ai/chat) we have under the @moeru-ai organization)
&gt;
&gt; **If you are interested, why not introduce yourself here? [Would like to join part of us to build AIRI?](https://github.com/moeru-ai/airi/discussions/33)**

## Current Progress

Capable of

- [x] Brain
  - [x] Play [Minecraft](https://www.minecraft.net)
  - [x] Play [Factorio](https://www.factorio.com) (WIP, but [PoC and demo available](https://github.com/moeru-ai/airi-factorio))
  - [x] Chat in [Telegram](https://telegram.org)
  - [x] Chat in [Discord](https://discord.com)
  - [ ] Memory
    - [x] Pure in-browser database support (DuckDB WASM | `pglite`)
    - [ ] Memory Alaya (WIP)
  - [ ] Pure in-browser local (WebGPU) inference
- [x] Ears
  - [x] Audio input from browser
  - [x] Audio input from [Discord](https://discord.com)
  - [x] Client side speech recognition
  - [x] Client side talking detection
- [x] Mouth
  - [x] [ElevenLabs](https://elevenlabs.io/) voice synthesis
- [x] Body
  - [x] VRM support
    - [x] Control VRM model
  - [x] VRM model animations
    - [x] Auto blink
    - [x] Auto look at
    - [x] Idle eye movement
  - [x] Live2D support
    - [x] Control Live2D model
  - [x] Live2D model animations
    - [x] Auto blink
    - [x] Auto look at
    - [x] Idle eye movement

## Development

&gt; For detailed instructions to develop this project, follow [CONTRIBUTING.md](./.github/CONTRIBUTING.md)

&gt; [!NOTE]
&gt; By default, `pnpm dev` will start the development server for the Stage Web (browser version). If you would
&gt; like to try developing the desktop version, please make sure you read [CONTRIBUTING.md](./.github/CONTRIBUTING.md)
&gt; to setup the environment correctly.

```shell
pnpm i
pnpm dev
```

### Stage Web (Browser Version at [airi.moeru.ai](https://airi.moeru.ai))

```shell
pnpm dev
```

### Stage Tamagotchi (Desktop Version)

```shell
pnpm dev:tamagotchi
```

A Nix package for Tamagotchi is included. To run airi with Nix, first make sure to enable flakes, then run:

```shell
nix run github:moeru-ai/airi
```

### Stage Pocket (Mobile Version)

Start the development server for the capacitor web version:

```shell
pnpm dev:pocket
```

Check your IP address in the output of the command above:

```shell
  ROLLDOWN-VITE v7.3.0  ready in 1073 ms

  ‚ûú  Local:   https://localhost:5273/
  ‚ûú  Network: https://&lt;ip-will-be-here&gt;:5273/
  ‚ûú  Vue DevTools: Open https://localhost:5273/__devtools__/ as a separate window
  ‚ûú  Vue DevTools: Press Option(‚å•)+Shift(‚áß)+D in App to toggle the Vue DevTools
  ‚ûú  UnoCSS Inspector: https://localhost:5273/__unocss/
```

Open the Xcode project:

```shell
CAPACITOR_DEV_SERVER_URL=https://&lt;your-ip-address&gt;:5273 pnpm open:ios
```

Then Xcode will open and you can click the &quot;Run&quot; button to run the app on your iPhone.

If you need to connect server channel on pocket in wireless mode, you need to start tamagotchi as root:

```shell
sudo pnpm dev:tamagotchi
```

Then enable secure websocket in tamagotchi `settings/system/general`.

### Documentation Site

```shell
pnpm dev:docs
```

### Publish

Please update the version in `Cargo.toml` after running `bumpp`:

```shell
npx bumpp --no-commit --no-tag
```

## Support of LLM API Providers (powered by [xsai](https://github.com/moeru-ai/xsai))

- [x] [302.AI (sponsored)](https://share.302.ai/514k2v)
- [x] [OpenRouter](https://openrouter.ai/)
- [x] [vLLM](https://github.com/vllm-project/vllm)
- [x] [SGLang](https://github.com/sgl-project/sglang)
- [x] [Ollama](https://github.com/ollama/ollama)
- [x] [Google Gemini](https://developers.generativeai.google)
- [x] [OpenAI](https://platform.openai.com/docs/guides/gpt/chat-completions-api)
  - [ ] [Azure OpenAI API](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference) (PR welcome)
- [x] [Anthropic Claude](https://anthropic.com)
  - [ ] [AWS Claude](https://docs.anthropic.com/en/api/claude-on-amazon-bedrock) (PR welcome)
- [x] [DeepSeek](https://www.deepseek.com/)
- [x] [Qwen](https://help.aliyun.com/document_detail/2400395.html)
- [x] [xAI](https://x.ai/)
- [x] [Groq](https://wow.groq.com/)
- [x] [Mistral](https://mistral.ai/)
- [x] [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/)
- [x] [Together.ai](https://www.together.ai/)
- [x] [Fireworks.ai](https://www.together.ai/)
- [x] [Novita](https://www.novita.ai/)
- [x] [Zhipu](https://bigmodel.cn)
- [x] [SiliconFlow](https://cloud.siliconflow.cn/i/rKXmRobW)
- [x] [Stepfun](https://platform.stepfun.com/)
- [x] [Baichuan](https://platform.baichuan-ai.com)
- [x] [Minimax](https://api.minimax.chat/)
- [x] [Moonshot AI](https://platform.moonshot.cn/)
- [x] [ModelScope](https://modelscope.cn/docs/model-service/API-Inference/intro)
- [x] [Player2](https://player2.game/)
- [x] [Tencent Cloud](https://cloud.tencent.com/document/product/1729)
- [ ] [Sparks](https://www.xfyun.cn/doc/spark/Web.html) (PR welcome)
- [ ] [Volcano Engine](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;ac=DSASUQY5&amp;rc=2QXCA1VI) (PR welcome)

## Sub-projects Born from This Project

- [Awesome AI VTuber](https://github.com/proj-airi/awesome-ai-vtuber): A curated list of AI VTubers and related projects
- [`unspeech`](https://github.com/moeru-ai/unspeech): Universal endpoint proxy server for `/audio/transcriptions` and `/audio/speech`, like LiteLLM but for any ASR and TTS
- [`hfup`](https://github.com/moeru-ai/hfup): tools to help on deploying, bundling to HuggingFace Spaces
- [`xsai-transformers`](https://github.com/moeru-ai/xsai-transformers): Experimental [ü§ó Transformers.js](https://github.com/huggingface/transformers.js) provider for [xsAI](https://github.com/moeru-ai/xsai).
- [WebAI: Realtime Voice Chat](https://github.com/proj-airi/webai-realtime-voice-chat): Full example of implementing ChatGPT&#039;s realtime voice from scratch with VAD + STT + LLM + TTS.
- [`@proj-airi/drizzle-duckdb-wasm`](https://github.com/moeru-ai/airi/tree/main/packages/drizzle-duckdb-wasm/README.md): Drizzle ORM driver for DuckDB WASM
- [`@proj-airi/duckdb-wasm`](https://github.com/moeru-ai/airi/tree/main/packages/duckdb-wasm/README.md): Easy to use wrapper for `@duckdb/duckdb-wasm`
- [`tauri-plugin-mcp`](https://github.com/moeru-ai/airi/blob/main/crates/tauri-plugin-mcp/README.md): A Tauri plugin for interacting with MCP servers.
- [AIRI Factorio](https://github.com/moeru-ai/airi-factorio): Allow AIRI to play Factorio
- [Factorio RCON API](https://github.com/nekomeowww/factorio-rcon-api): RESTful API wrapper for Factorio headless server console
- [`autorio`](https://github.com/moeru-ai/airi-factorio/tree/main/packages/autorio): Factorio automation library
- [`tstl-plugin-reload-factorio-mod`](https://github.com/moeru-ai/airi-factorio/tree/main/packages/tstl-plugin-reload-factorio-mod): Reload Factorio mod when developing
- [Velin](https://github.com/luoling8192/velin): Use Vue SFC and Markdown to write easy to manage stateful prompts for LLM
- [`demodel`](https://github.com/moeru-ai/demodel): Easily boost the speed of pulling your models and datasets from various of inference runtimes.
- [`inventory`](https://github.com/moeru-ai/inventory): Centralized model catalog and default provider configurations backend service
- [MCP Launcher](https://github.com/moeru-ai/mcp-launcher): Easy to use MCP builder &amp; launcher for all possible MCP servers, just like Ollama for models!
- [ü•∫ SAD](https://github.com/moeru-ai/sad): Documentation and notes for self-host and browser running LLMs.

```mermaid
%%{ init: { &#039;flowchart&#039;: { &#039;curve&#039;: &#039;catmullRom&#039; } } }%%

flowchart TD
  Core(&quot;Core&quot;)
  Unspeech(&quot;unspeech&quot;)
  DBDriver(&quot;@proj-airi/drizzle-duckdb-wasm&quot;)
  MemoryDriver(&quot;[WIP] Memory Alaya&quot;)
  DB1(&quot;@proj-airi/duckdb-wasm&quot;)
  SVRT(&quot;@proj-airi/server-runtime&quot;)
  Memory(&quot;Memory&quot;)
  STT(&quot;STT&quot;)
  Stage(&quot;Stage&quot;)
  StageUI(&quot;@proj-airi/stage-ui&quot;)
  UI(&quot;@proj-airi/ui&quot;)

  subgraph AIRI
    DB1 --&gt; DBDriver --&gt; MemoryDriver --&gt; Memory --&gt; Core
    UI --&gt; StageUI --&gt; Stage --&gt; Core
    Core --&gt; STT
    Core --&gt; SVRT
  end

  subgraph UI_Components
    UI --&gt; StageUI
    UITransitions(&quot;@proj-airi/ui-transitions&quot;) --&gt; StageUI
    UILoadingScreens(&quot;@proj-airi/ui-loading-screens&quot;) --&gt; StageUI
    FontCJK(&quot;@proj-airi/font-cjkfonts-allseto&quot;) --&gt; StageUI
    FontXiaolai(&quot;@proj-airi/font-xiaolai&quot;) --&gt; StageUI
  end

  subgraph Apps
    Stage --&gt; StageWeb(&quot;@proj-airi/stage-web&quot;)
    Stage --&gt; StageTamagotchi(&quot;@proj-airi/stage-tamagotchi&quot;)
    Core --&gt; RealtimeAudio(&quot;@proj-airi/realtime-audio&quot;)
    Core --&gt; PromptEngineering(&quot;@proj-airi/playground-prompt-engineering&quot;)
  end

  subgraph Server_Components
    Core --&gt; ServerSDK(&quot;@proj-airi/server-sdk&quot;)
    ServerShared(&quot;@proj-airi/server-shared&quot;) --&gt; SVRT
    ServerShared --&gt; ServerSDK
  end

  STT --&gt;|Speaking| Unspeech
  SVRT --&gt;|Playing Factorio| F_AGENT
  SVRT --&gt;|Playing Minecraft| MC_AGENT

  subgraph Factorio_Agent
    F_AGENT(&quot;Factorio Agent&quot;)
    F_API(&quot;Factorio RCON API&quot;)
    factorio-server(&quot;factorio-server&quot;)
    F_MOD1(&quot;autorio&quot;)

    F_AGENT --&gt; F_API -.-&gt; factorio-server
    F_MOD1 -.-&gt; factorio-server
  end

  subgraph Minecraft_Agent
    MC_AGENT(&quot;Minecraft Agent&quot;)
    Mineflayer(&quot;Mineflayer&quot;)
    minecraft-server(&quot;minecraft-server&quot;)

    MC_AGENT --&gt; Mineflayer -.-&gt; minecraft-server
  end

  XSAI(&quot;xsAI&quot;) --&gt; Core
  XSAI --&gt; F_AGENT
  XSAI --&gt; MC_AGENT

  Core --&gt; TauriMCP(&quot;@proj-airi/tauri-plugin-mcp&quot;)
  Memory_PGVector(&quot;@proj-airi/memory-pgvector&quot;) --&gt; Memory

  style Core fill:#f9d4d4,stroke:#333,stroke-width:1px
  style AIRI fill:#fcf7f7,stroke:#333,stroke-width:1px
  style UI fill:#d4f9d4,stroke:#333,stroke-width:1px
  style Stage fill:#d4f9d4,stroke:#333,stroke-width:1px
  style UI_Components fill:#d4f9d4,stroke:#333,stroke-width:1px
  style Server_Components fill:#d4e6f9,stroke:#333,stroke-width:1px
  style Apps fill:#d4d4f9,stroke:#333,stroke-width:1px
  style Factorio_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px
  style Minecraft_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px

  style DBDriver fill:#f9f9d4,stroke:#333,stroke-width:1px
  style MemoryDriver fill:#f9f9d4,stroke:#333,stroke-width:1px
  style DB1 fill:#f9f9d4,stroke:#333,stroke-width:1px
  style Memory fill:#f9f9d4,stroke:#333,stroke-width:1px
  style Memory_PGVector fill:#f9f9d4,stroke:#333,stroke-width:1px
```

## Similar Projects

### Open sourced ones

- [kimjammer/Neuro: A recreation of Neuro-Sama originally created in 7 days.](https://github.com/kimjammer/Neuro): very well completed implementation.
- [SugarcaneDefender/z-waif](https://github.com/SugarcaneDefender/z-waif): Great at gaming, autonomous, and prompt engineering
- [semperai/amica](https://github.com/semperai/amica/): Great at VRM, WebXR
- [elizaOS/eliza](https://github.com/elizaOS/eliza): Great examples and software engineering on how to integrate agent into various of systems and APIs
- [ardha27/AI-Waif

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ruvnet/ruflo]]></title>
            <link>https://github.com/ruvnet/ruflo</link>
            <guid>https://github.com/ruvnet/ruflo</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:43 GMT</pubDate>
            <description><![CDATA[üåä The leading agent orchestration platform for Claude. Deploy intelligent multi-agent swarms, coordinate autonomous workflows, and build conversational AI systems. Features enterprise-grade architecture, distributed swarm intelligence, RAG integration, and native Claude Code / Codex Integration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ruvnet/ruflo">ruvnet/ruflo</a></h1>
            <p>üåä The leading agent orchestration platform for Claude. Deploy intelligent multi-agent swarms, coordinate autonomous workflows, and build conversational AI systems. Features enterprise-grade architecture, distributed swarm intelligence, RAG integration, and native Claude Code / Codex Integration</p>
            <p>Language: TypeScript</p>
            <p>Stars: 17,286</p>
            <p>Forks: 1,942</p>
            <p>Stars today: 766 stars today</p>
            <h2>README</h2><pre># üåä Ruflo v3: Enterprise AI Orchestration Platform

&lt;div align=&quot;center&quot;&gt;

![Ruflo Banner](ruflo/assets/ruFlo.png)



[![GitHub Project of the Day](https://img.shields.io/badge/GitHub-Project%20of%20the%20Day-ff6600?style=for-the-badge&amp;logo=github&amp;logoColor=white)](https://github.com/ruvnet/claude-flow)

[![Star on GitHub](https://img.shields.io/github/stars/ruvnet/claude-flow?style=for-the-badge&amp;logo=github&amp;color=gold)](https://github.com/ruvnet/claude-flow)
[![Monthly Downloads](https://img.shields.io/npm/dm/claude-flow?style=for-the-badge&amp;logo=npm&amp;color=blue&amp;label=Monthly%20Downloads)](https://www.npmjs.com/package/claude-flow)
[![Total Downloads](https://img.shields.io/npm/dt/claude-flow?style=for-the-badge&amp;logo=npm&amp;color=cyan&amp;label=Total%20Downloads)](https://www.npmjs.com/package/claude-flow)
[![ruv.io](https://img.shields.io/badge/ruv.io-AI%20Platform-green?style=for-the-badge&amp;logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCI+PHBhdGggZmlsbD0id2hpdGUiIGQ9Ik0xMiAyQzYuNDggMiAyIDYuNDggMiAxMnM0LjQ4IDEwIDEwIDEwIDEwLTQuNDggMTAtMTBTMTcuNTIgMiAxMiAyem0wIDE4Yy00LjQyIDAtOC0zLjU4LTgtOHMzLjU4LTggOC04IDggMy41OCA4IDgtMy41OCA4LTggOHoiLz48L3N2Zz4=)](https://ruv.io)
[![Agentics Foundation](https://img.shields.io/badge/Agentics-Foundation-crimson?style=for-the-badge&amp;logo=openai)](https://discord.com/invite/dfxmpwkG2D)
[![Claude Code](https://img.shields.io/badge/Claude%20Code-SDK%20Integrated-green?style=for-the-badge&amp;logo=anthropic)](https://github.com/ruvnet/claude-flow)
[![MIT License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge&amp;logo=opensourceinitiative)](https://opensource.org/licenses/MIT)
---
[![Follow @ruv](https://img.shields.io/badge/Follow%20%40ruv-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white)](https://x.com/ruv)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&amp;logo=linkedin)](https://www.linkedin.com/in/reuvencohen/)
[![YouTube](https://img.shields.io/badge/YouTube-Subscribe-FF0000?style=for-the-badge&amp;logo=youtube&amp;logoColor=white)](https://www.youtube.com/@ReuvenCohen)

# **Production-ready multi-agent AI orchestration for Claude Code**
*Deploy 60+ specialized agents in coordinated swarms with self-learning capabilities, fault-tolerant consensus, and enterprise-grade security.*

&lt;/div&gt;

&gt; **Why Ruflo?** Claude Flow is now Ruflo ‚Äî named by Ruv, who loves Rust, flow states, and building things that feel inevitable. The &quot;Ru&quot; is the Ruv. The &quot;flo&quot; is the flow. Underneath, WASM kernels written in Rust power the policy engine, embeddings, and proof system. 5,800 commits later, the alpha is over. This is v3.5.

## Getting into the Flow

Ruflo is a comprehensive AI agent orchestration framework that transforms Claude Code into a powerful multi-agent development platform. It enables teams to deploy, coordinate, and optimize specialized AI agents working together on complex software engineering tasks.

### Self-Learning/Self-Optimizing Agent Architecture

```
User ‚Üí Ruflo (CLI/MCP) ‚Üí Router ‚Üí Swarm ‚Üí Agents ‚Üí Memory ‚Üí LLM Providers
                       ‚Üë                          ‚Üì
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ Learning Loop ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

&lt;details&gt;
&lt;summary&gt;üìê &lt;strong&gt;Expanded Architecture&lt;/strong&gt; ‚Äî Full system diagram with RuVector intelligence&lt;/summary&gt;

```mermaid
flowchart TB
    subgraph USER[&quot;üë§ User Layer&quot;]
        U[User]
    end

    subgraph ENTRY[&quot;üö™ Entry Layer&quot;]
        CLI[CLI / MCP Server]
        AID[AIDefence Security]
    end

    subgraph ROUTING[&quot;üß≠ Routing Layer&quot;]
        QL[Q-Learning Router]
        MOE[MoE - 8 Experts]
        SK[Skills - 42+]
        HK[Hooks - 17]
    end

    subgraph SWARM[&quot;üêù Swarm Coordination&quot;]
        TOPO[Topologies&lt;br/&gt;mesh/hier/ring/star]
        CONS[Consensus&lt;br/&gt;Raft/BFT/Gossip/CRDT]
        CLM[Claims&lt;br/&gt;Human-Agent Coord]
    end

    subgraph AGENTS[&quot;ü§ñ 60+ Agents&quot;]
        AG1[coder]
        AG2[tester]
        AG3[reviewer]
        AG4[architect]
        AG5[security]
        AG6[...]
    end

    subgraph RESOURCES[&quot;üì¶ Resources&quot;]
        MEM[(Memory&lt;br/&gt;AgentDB)]
        PROV[Providers&lt;br/&gt;Claude/GPT/Gemini/Ollama]
        WORK[Workers - 12&lt;br/&gt;ultralearn/audit/optimize]
    end

    subgraph RUVECTOR[&quot;üß† RuVector Intelligence Layer&quot;]
        direction TB
        subgraph ROW1[&quot; &quot;]
            SONA[SONA&lt;br/&gt;Self-Optimize&lt;br/&gt;&amp;lt;0.05ms]
            EWC[EWC++&lt;br/&gt;No Forgetting]
            FLASH[Flash Attention&lt;br/&gt;2.49-7.47x]
        end
        subgraph ROW2[&quot; &quot;]
            HNSW[HNSW&lt;br/&gt;150x-12,500x faster]
            RB[ReasoningBank&lt;br/&gt;Pattern Store]
            HYP[Hyperbolic&lt;br/&gt;Poincar√©]
        end
        subgraph ROW3[&quot; &quot;]
            LORA[LoRA/Micro&lt;br/&gt;128x compress]
            QUANT[Int8 Quant&lt;br/&gt;3.92x memory]
            RL[9 RL Algos&lt;br/&gt;Q/SARSA/PPO/DQN]
        end
    end

    subgraph LEARNING[&quot;üîÑ Learning Loop&quot;]
        L1[RETRIEVE] --&gt; L2[JUDGE] --&gt; L3[DISTILL] --&gt; L4[CONSOLIDATE] --&gt; L5[ROUTE]
    end

    U --&gt; CLI
    CLI --&gt; AID
    AID --&gt; QL &amp; MOE &amp; SK &amp; HK
    QL &amp; MOE &amp; SK &amp; HK --&gt; TOPO &amp; CONS &amp; CLM
    TOPO &amp; CONS &amp; CLM --&gt; AG1 &amp; AG2 &amp; AG3 &amp; AG4 &amp; AG5 &amp; AG6
    AG1 &amp; AG2 &amp; AG3 &amp; AG4 &amp; AG5 &amp; AG6 --&gt; MEM &amp; PROV &amp; WORK
    MEM --&gt; SONA &amp; EWC &amp; FLASH
    SONA &amp; EWC &amp; FLASH --&gt; HNSW &amp; RB &amp; HYP
    HNSW &amp; RB &amp; HYP --&gt; LORA &amp; QUANT &amp; RL
    LORA &amp; QUANT &amp; RL --&gt; L1
    L5 -.-&gt;|loops back| QL

    style RUVECTOR fill:#1a1a2e,stroke:#e94560,stroke-width:2px
    style LEARNING fill:#0f3460,stroke:#e94560,stroke-width:2px
    style USER fill:#16213e,stroke:#0f3460
    style ENTRY fill:#1a1a2e,stroke:#0f3460
    style ROUTING fill:#1a1a2e,stroke:#0f3460
    style SWARM fill:#1a1a2e,stroke:#0f3460
    style AGENTS fill:#1a1a2e,stroke:#0f3460
    style RESOURCES fill:#1a1a2e,stroke:#0f3460
```

**RuVector Components** (included with Ruflo):

| Component | Purpose | Performance |
|-----------|---------|-------------|
| **SONA** | Self-Optimizing Neural Architecture - learns optimal routing | Fast adaptation |
| **EWC++** | Elastic Weight Consolidation - prevents catastrophic forgetting | Preserves learned patterns |
| **Flash Attention** | Optimized attention computation | 2-7x speedup |
| **HNSW** | Hierarchical Navigable Small World vector search | Sub-millisecond retrieval |
| **ReasoningBank** | Pattern storage with trajectory learning | RETRIEVE‚ÜíJUDGE‚ÜíDISTILL |
| **Hyperbolic** | Poincare ball embeddings for hierarchical data | Better code relationships |
| **LoRA/MicroLoRA** | Low-Rank Adaptation for efficient fine-tuning | Lightweight adaptation |
| **Int8 Quantization** | Memory-efficient weight storage | ~4x memory reduction |
| **SemanticRouter** | Semantic task routing with cosine similarity | Fast intent routing |
| **9 RL Algorithms** | Q-Learning, SARSA, A2C, PPO, DQN, Decision Transformer, etc. | Task-specific learning |

```bash
# Use RuVector via Ruflo
npx ruflo@latest hooks intelligence --status
```

&lt;/details&gt;

### Get Started Fast

```bash
# One-line install (recommended)
curl -fsSL https://cdn.jsdelivr.net/gh/ruvnet/claude-flow@main/scripts/install.sh | bash

# Or full setup with MCP + diagnostics
curl -fsSL https://cdn.jsdelivr.net/gh/ruvnet/claude-flow@main/scripts/install.sh | bash -s -- --full

# Or via npx
npx ruflo@latest init --wizard
```

---
### Key Capabilities

ü§ñ **60+ Specialized Agents** - Ready-to-use AI agents for coding, code review, testing, security audits, documentation, and DevOps. Each agent is optimized for its specific role.

üêù **Coordinated Agent Teams** - Run unlimited agents simultaneously in organized swarms. Agents spawn sub-workers, communicate, share context, and divide work automatically using hierarchical (queen/workers) or mesh (peer-to-peer) patterns.

üß† **Learns From Your Workflow** - The system remembers what works. Successful patterns are stored and reused, routing similar tasks to the best-performing agents. Gets smarter over time.

üîå **Works With Any LLM** - Switch between Claude, GPT, Gemini, Cohere, or local models like Llama. Automatic failover if one provider is unavailable. Smart routing picks the cheapest option that meets quality requirements.

‚ö° **Plugs Into Claude Code** - Native integration via MCP (Model Context Protocol). Use ruflo commands directly in your Claude Code sessions with full tool access.

üîí **Production-Ready Security** - Built-in protection against prompt injection, input validation, path traversal prevention, command injection blocking, and safe credential handling.

üß© **Extensible Plugin System** - Add custom capabilities with the plugin SDK. Create workers, hooks, providers, and security modules. Share plugins via the decentralized IPFS marketplace.

---

### A multi-purpose Agent Tool Kit 

&lt;details&gt;
&lt;summary&gt;üîÑ &lt;strong&gt;Core Flow&lt;/strong&gt; ‚Äî How requests move through the system&lt;/summary&gt;

Every request flows through four layers: from your CLI or Claude Code interface, through intelligent routing, to specialized agents, and finally to LLM providers for reasoning.

| Layer | Components | What It Does |
|-------|------------|--------------|
| User | Claude Code, CLI | Your interface to control and run commands |
| Orchestration | MCP Server, Router, Hooks | Routes requests to the right agents |
| Agents | 60+ types | Specialized workers (coder, tester, reviewer...) |
| Providers | Anthropic, OpenAI, Google, Ollama | AI models that power reasoning |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üêù &lt;strong&gt;Swarm Coordination&lt;/strong&gt; ‚Äî How agents work together&lt;/summary&gt;

Agents organize into swarms led by queens that coordinate work, prevent drift, and reach consensus on decisions‚Äîeven when some agents fail.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Coordination | Queen, Swarm, Consensus | Manages agent teams (Raft, Byzantine, Gossip) |
| Drift Control | Hierarchical topology, Checkpoints | Prevents agents from going off-task |
| Hive Mind | Queen-led hierarchy, Collective memory | Strategic/tactical/adaptive queens coordinate workers |
| Consensus | Byzantine, Weighted, Majority | Fault-tolerant decisions (2/3 majority for BFT) |

**Hive Mind Capabilities:**
- üêù **Queen Types**: Strategic (planning), Tactical (execution), Adaptive (optimization)
- üë∑ **8 Worker Types**: Researcher, Coder, Analyst, Tester, Architect, Reviewer, Optimizer, Documenter
- üó≥Ô∏è **3 Consensus Algorithms**: Majority, Weighted (Queen 3x), Byzantine (f &lt; n/3)
- üß† **Collective Memory**: Shared knowledge, LRU cache, SQLite persistence with WAL
- ‚ö° **Performance**: Fast batch spawning with parallel agent coordination

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üß† &lt;strong&gt;Intelligence &amp; Memory&lt;/strong&gt; ‚Äî How the system learns and remembers&lt;/summary&gt;

The system stores successful patterns in vector memory, builds a knowledge graph for structural understanding, learns from outcomes via neural networks, and adapts routing based on what works best.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Memory | HNSW, AgentDB, Cache | Stores and retrieves patterns with fast HNSW search |
| Knowledge Graph | MemoryGraph, PageRank, Communities | Identifies influential insights, detects clusters (ADR-049) |
| Self-Learning | LearningBridge, SONA, ReasoningBank | Triggers learning from insights, confidence lifecycle (ADR-049) |
| Agent Scopes | AgentMemoryScope, 3-scope dirs | Per-agent isolation + cross-agent knowledge transfer (ADR-049) |
| Embeddings | ONNX Runtime, MiniLM | Local vectors without API calls (75x faster) |
| Learning | SONA, MoE, ReasoningBank | Self-improves from results (&lt;0.05ms adaptation) |
| Fine-tuning | MicroLoRA, EWC++ | Lightweight adaptation without full retraining |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;‚ö° &lt;strong&gt;Optimization&lt;/strong&gt; ‚Äî How to reduce cost and latency&lt;/summary&gt;

Skip expensive LLM calls for simple tasks using WebAssembly transforms, and compress tokens to reduce API costs by 30-50%.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Agent Booster | WASM, AST analysis | Skips LLM for simple edits (&lt;1ms) |
| Token Optimizer | Compression, Caching | Reduces token usage 30-50% |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üîß &lt;strong&gt;Operations&lt;/strong&gt; ‚Äî Background services and integrations&lt;/summary&gt;

Background daemons handle security audits, performance optimization, and session persistence automatically while you work.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Background | Daemon, 12 Workers | Auto-runs audits, optimization, learning |
| Security | AIDefence, Validation | Blocks injection, detects threats |
| Sessions | Persist, Restore, Export | Saves context across conversations |
| GitHub | PR, Issues, Workflows | Manages repos and code reviews |
| Analytics | Metrics, Benchmarks | Monitors performance, finds bottlenecks |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üéØ &lt;strong&gt;Task Routing&lt;/strong&gt; ‚Äî Extend your Claude Code subscription by 250%&lt;/summary&gt;

Smart routing skips expensive LLM calls when possible. Simple edits use WASM (free), medium tasks use cheaper models. This can extend your Claude Code usage by 250% or save significantly on direct API costs.

| Complexity | Handler | Speed |
|------------|---------|-------|
| Simple | Agent Booster (WASM) | &lt;1ms |
| Medium | Haiku/Sonnet | ~500ms |
| Complex | Opus + Swarm | 2-5s |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;‚ö° &lt;strong&gt;Agent Booster (WASM)&lt;/strong&gt; ‚Äî Skip LLM for simple code transforms&lt;/summary&gt;

Agent Booster uses WebAssembly to handle simple code transformations without calling the LLM at all. When the hooks system detects a simple task, it routes directly to Agent Booster for instant results.

**Supported Transform Intents:**

| Intent | What It Does | Example |
|--------|--------------|---------|
| `var-to-const` | Convert var/let to const | `var x = 1` ‚Üí `const x = 1` |
| `add-types` | Add TypeScript type annotations | `function foo(x)` ‚Üí `function foo(x: string)` |
| `add-error-handling` | Wrap in try/catch | Adds proper error handling |
| `async-await` | Convert promises to async/await | `.then()` chains ‚Üí `await` |
| `add-logging` | Add console.log statements | Adds debug logging |
| `remove-console` | Strip console.* calls | Removes all console statements |

**Hook Signals:**

When you see these in hook output, the system is telling you how to optimize:

```bash
# Agent Booster available - skip LLM entirely
[AGENT_BOOSTER_AVAILABLE] Intent: var-to-const
‚Üí Use Edit tool directly, 352x faster than LLM

# Model recommendation for Task tool
[TASK_MODEL_RECOMMENDATION] Use model=&quot;haiku&quot;
‚Üí Pass model=&quot;haiku&quot; to Task tool for cost savings
```

**Performance:**

| Metric | Agent Booster | LLM Call |
|--------|---------------|----------|
| Latency | &lt;1ms | 2-5s |
| Cost | $0 | $0.0002-$0.015 |
| Speedup | **352x faster** | baseline |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üí∞ &lt;strong&gt;Token Optimizer&lt;/strong&gt; ‚Äî 30-50% token reduction&lt;/summary&gt;

The Token Optimizer integrates agentic-flow optimizations to reduce API costs by compressing context and caching results.

**Savings Breakdown:**

| Optimization | Token Savings | How It Works |
|--------------|---------------|--------------|
| ReasoningBank retrieval | -32% | Fetches relevant patterns instead of full context |
| Agent Booster edits | -15% | Simple edits skip LLM entirely |
| Cache (95% hit rate) | -10% | Reuses embeddings and patterns |
| Optimal batch size | -20% | Groups related operations |
| **Combined** | **30-50%** | Stacks multiplicatively |

**Usage:**

```typescript
import { getTokenOptimizer } from &#039;@claude-flow/integration&#039;;
const optimizer = await getTokenOptimizer();

// Get compact context (32% fewer tokens)
const ctx = await optimizer.getCompactContext(&quot;auth patterns&quot;);

// Optimized edit (352x faster for simple transforms)
await optimizer.optimizedEdit(file, oldStr, newStr, &quot;typescript&quot;);

// Optimal config for swarm (100% success rate)
const config = optimizer.getOptimalConfig(agentCount);
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üõ°Ô∏è &lt;strong&gt;Anti-Drift Swarm Configuration&lt;/strong&gt; ‚Äî Prevent goal drift in multi-agent work&lt;/summary&gt;

Complex swarms can drift from their original goals. Ruflo V3 includes anti-drift defaults that prevent agents from going off-task.

**Recommended Configuration:**

```javascript
// Anti-drift defaults (ALWAYS use for coding tasks)
swarm_init({
  topology: &quot;hierarchical&quot;,  // Single coordinator enforces alignment
  maxAgents: 8,              // Smaller team = less drift surface
  strategy: &quot;specialized&quot;    // Clear roles reduce ambiguity
})
```

**Why This Prevents Drift:**

| Setting | Anti-Drift Benefit |
|---------|-------------------|
| `hierarchical` | Coordinator validates each output against goal, catches divergence early |
| `maxAgents: 6-8` | Fewer agents = less coordination overhead, easier alignment |
| `specialized` | Clear boundaries - each agent knows exactly what to do, no overlap |
| `raft` consensus | Leader maintains authoritative state, no conflicting decisions |

**Additional Anti-Drift Measures:**

- Frequent checkpoints via `post-task` hooks
- Shared memory namespace for all agents
- Short task cycles with verification gates
- Hierarchical coordinator reviews all outputs

**Task ‚Üí Agent Routing (Anti-Drift):**

| Code | Task Type | Recommended Agents |
|------|-----------|-------------------|
| 1 | Bug Fix | coordinator, researcher, coder, tester |
| 3 | Feature | coordinator, architect, coder, tester, reviewer |
| 5 | Refactor | coordinator, architect, coder, reviewer |
| 7 | Performance | coordinator, perf-engineer, coder |
| 9 | Security | coordinator, security-architect, auditor |
| 11 | Memory | coordinator, memory-specialist, perf-engineer |

&lt;/details&gt;

### Claude Code: With vs Without Ruflo

| Capability | Claude Code Alone | Claude Code + Ruflo |
|------------|-------------------|---------------------------|
| **Agent Collaboration** | Agents work in isolation, no shared context | Agents collaborate via swarms with shared memory and consensus |
| **Coordination** | Manual orchestration between tasks | Queen-led hierarchy with 5 consensus algorithms (Raft, Byzantine, Gossip) |
| **Hive Mind** | ‚õî Not available | üêù Queen-led swarms with collective intelligence, 3 queen types, 8 worker types |
| **Consensus** | ‚õî No multi-agent decisions | Byzantine fault-tolerant voting (f &lt; n/3), weighted, majority |
| **Memory** | Session-only, no persistence | HNSW vector memory with sub-ms retrieval + knowledge graph |
| **Vector Database** | ‚õî No native support | üêò RuVector PostgreSQL with 77+ SQL functions, ~61¬µs search, 16,400 QPS |
| **Knowledge Graph** | ‚õî Flat insight lists | PageRank + community detection identifies influential insights (ADR-049) |
| **Collective Memory** | ‚õî No shared knowledge | Shared knowledge base with LRU cache, SQLite persistence, 8 memory types |
| **Learning** | Static behavior, no adaptation | SONA self-learning with &lt;0.05ms adaptation, LearningBridge for insights |
| **Agent Scoping** | Single project scope | 3-scope agent memory (project/local/user) with cross-agent transfer |
| **Task Routing** | You decide which agent to use | Intelligent routing based on learned patterns (89% accuracy) |
| **Complex Tasks** | Manual breakdown required | Automatic decomposition across 5 domains (Security, Core, Integration, Support) |
| **Background Workers** | Nothing runs automatically | 12 context-triggered workers auto-dispatch on file changes, patterns, sessions |
| **LLM Provider** | Anthropic only | 6 providers with automatic failover and cost-based routing (85% savings) |
| **Security** | Standard protections | CVE-hardened with bcrypt, input validation, path traversal prevention |
| **Performance** | Baseline | Faster tasks via parallel swarm spawning and intelligent routing |

## Quick Start

### Prerequisites

- **Node.js 20+** (required)
- **npm 9+** / **pnpm** / **bun** package manager

**IMPORTANT**: Claude Code must be installed first:

```bash
# 1. Install

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[superset-sh/superset]]></title>
            <link>https://github.com/superset-sh/superset</link>
            <guid>https://github.com/superset-sh/superset</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:42 GMT</pubDate>
            <description><![CDATA[IDE for the AI Agents Era - Run an army of Claude Code, Codex, etc. on your machine]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/superset-sh/superset">superset-sh/superset</a></h1>
            <p>IDE for the AI Agents Era - Run an army of Claude Code, Codex, etc. on your machine</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,857</p>
            <p>Forks: 205</p>
            <p>Stars today: 389 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img width=&quot;full&quot; alt=&quot;Superset&quot; src=&quot;apps/marketing/public/images/readme-hero.png&quot; /&gt;

### The Terminal for Coding Agents

[![GitHub stars](https://img.shields.io/github/stars/superset-sh/superset?style=flat&amp;logo=github)](https://github.com/superset-sh/superset/stargazers)
[![GitHub release](https://img.shields.io/github/v/release/superset-sh/superset?style=flat&amp;logo=github)](https://github.com/superset-sh/superset/releases)
[![License](https://img.shields.io/github/license/superset-sh/superset?style=flat)](LICENSE.md)
[![Twitter](https://img.shields.io/badge/@superset__sh-555?logo=x)](https://x.com/superset_sh)
[![Discord](https://img.shields.io/badge/Discord-555?logo=discord)](https://discord.gg/cZeD9WYcV7)

&lt;br /&gt;

[**Download for macOS**](https://github.com/superset-sh/superset/releases/latest) &amp;nbsp;&amp;bull;&amp;nbsp; [Documentation](https://docs.superset.sh) &amp;nbsp;&amp;bull;&amp;nbsp; [Changelog](https://github.com/superset-sh/superset/releases) &amp;nbsp;&amp;bull;&amp;nbsp; [Discord](https://discord.gg/cZeD9WYcV7)

&lt;br /&gt;


&lt;/div&gt;

## Why Superset?

Superset is a turbocharged terminal that allows you to run any CLI coding agents along with the tools to 10x your development workflow. 

- **Run multiple agents simultaneously** without context switching overhead
- **Isolate each task** in its own git worktree so agents don&#039;t interfere with each other
- **Monitor all your agents** from one place and get notified when they need attention
- **Review changes quickly** with built-in diff viewer and editor

Wait less, ship more.

## Features

| Feature | Description |
|:--------|:------------|
| **Parallel Execution** | Run 10+ coding agents simultaneously on your machine |
| **Worktree Isolation** | Each task gets its own branch and working directory |
| **Agent Monitoring** | Track agent status and get notified when changes are ready |
| **Built-in Diff Viewer** | Inspect and edit agent changes without leaving the app |
| **Workspace Presets** | Automate env setup, dependency installation, and more |
| **Universal Compatibility** | Works with any CLI agent that runs in a terminal |
| **Quick Context Switching** | Jump between tasks as they need your attention |
| **IDE Integration** | Open any workspace in your favorite editor with one click |

## Supported Agents

Superset works with any CLI-based coding agent, including:

| Agent | Status |
|:------|:-------|
| [Claude Code](https://github.com/anthropics/claude-code) | Fully supported |
| [OpenAI Codex CLI](https://github.com/openai/codex) | Fully supported |
| [Cursor Agent](https://docs.cursor.com/agent) | Fully supported |
| [Gemini CLI](https://github.com/google-gemini/gemini-cli) | Fully supported |
| [GitHub Copilot](https://github.com/features/copilot) | Fully supported |
| [OpenCode](https://github.com/opencode-ai/opencode) | Fully supported |
| Any CLI agent | Will work |

If it runs in a terminal, it runs on Superset

## Requirements

| Requirement | Details |
|:------------|:--------|
| **OS** | macOS (Windows/Linux untested) |
| **Runtime** | [Bun](https://bun.sh/) v1.0+ |
| **Version Control** | Git 2.20+ |
| **GitHub CLI** | [gh](https://cli.github.com/) |
| **Caddy** | [caddy](https://caddyserver.com/docs/install) (for dev server) |

## Getting Started

### Quick Start (Pre-built)

**[Download Superset for macOS](https://github.com/superset-sh/superset/releases/latest)**

### Build from Source

&lt;details&gt;
&lt;summary&gt;Click to expand build instructions&lt;/summary&gt;

**1. Clone the repository**

```bash
git clone https://github.com/superset-sh/superset.git
cd superset
```

**2. Set up environment variables** (choose one):

Option A: Full setup
```bash
cp .env.example .env
# Edit .env and fill in the values
```

Option B: Skip env validation (for quick local testing)
```bash
cp .env.example .env
echo &#039;SKIP_ENV_VALIDATION=1&#039; &gt;&gt; .env
```

**3. Set up Caddy** (reverse proxy for Electric SQL streams):

```bash
# Install caddy: brew install caddy (macOS) or see https://caddyserver.com/docs/install
cp Caddyfile.example Caddyfile
```

**4. Install dependencies and run**

```bash
bun install
bun run dev
```

**5. Build the desktop app**

```bash
bun run build
open apps/desktop/release
```

&lt;/details&gt;

## Keyboard Shortcuts

All shortcuts are customizable via **Settings &gt; Keyboard Shortcuts** (`‚åò/`). See [full documentation](https://docs.superset.sh/keyboard-shortcuts).

### Workspace Navigation

| Shortcut | Action |
|:---------|:-------|
| `‚åò1-9` | Switch to workspace 1-9 |
| `‚åò‚å•‚Üë/‚Üì` | Previous/next workspace |
| `‚åòN` | New workspace |
| `‚åò‚áßN` | Quick create workspace |
| `‚åò‚áßO` | Open project |

### Terminal

| Shortcut | Action |
|:---------|:-------|
| `‚åòT` | New tab |
| `‚åòW` | Close pane/terminal |
| `‚åòD` | Split right |
| `‚åò‚áßD` | Split down |
| `‚åòK` | Clear terminal |
| `‚åòF` | Find in terminal |
| `‚åò‚å•‚Üê/‚Üí` | Previous/next tab |
| `Ctrl+1-9` | Open preset 1-9 |

### Layout

| Shortcut | Action |
|:---------|:-------|
| `‚åòB` | Toggle workspaces sidebar |
| `‚åòL` | Toggle changes panel |
| `‚åòO` | Open in external app |
| `‚åò‚áßC` | Copy path |

## Configuration

Configure workspace setup and teardown in `.superset/config.json`. See [full documentation](https://docs.superset.sh/setup-teardown-scripts).

```json
{
  &quot;setup&quot;: [&quot;./.superset/setup.sh&quot;],
  &quot;teardown&quot;: [&quot;./.superset/teardown.sh&quot;]
}
```

| Option | Type | Description |
|:-------|:-----|:------------|
| `setup` | `string[]` | Commands to run when creating a workspace |
| `teardown` | `string[]` | Commands to run when deleting a workspace |

### Example setup script

```bash
#!/bin/bash
# .superset/setup.sh

# Copy environment variables
cp ../.env .env

# Install dependencies
bun install

# Run any other setup tasks
echo &quot;Workspace ready!&quot;
```

Scripts have access to environment variables:
- `SUPERSET_WORKSPACE_NAME` ‚Äî Name of the workspace
- `SUPERSET_ROOT_PATH` ‚Äî Path to the main repository

## Internal Dependency Overrides

For the internal `mastracode` fork/bundle workflow used by this repo, see [docs/mastracode-fork-workflow.md](docs/mastracode-fork-workflow.md).

## Tech Stack

&lt;p&gt;
  &lt;a href=&quot;https://www.electronjs.org/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Electron-191970?logo=Electron&amp;logoColor=white&quot; alt=&quot;Electron&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://reactjs.org/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/React-%2320232a.svg?logo=react&amp;logoColor=%2361DAFB&quot; alt=&quot;React&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://tailwindcss.com/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Tailwindcss-%2338B2AC.svg?logo=tailwind-css&amp;logoColor=white&quot; alt=&quot;TailwindCSS&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://bun.sh/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Bun-000000?logo=bun&amp;logoColor=white&quot; alt=&quot;Bun&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://turbo.build/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Turborepo-EF4444?logo=turborepo&amp;logoColor=white&quot; alt=&quot;Turborepo&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://vitejs.dev/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Vite-%23646CFF.svg?logo=vite&amp;logoColor=white&quot; alt=&quot;Vite&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://biomejs.dev/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Biome-339AF0?logo=biome&amp;logoColor=white&quot; alt=&quot;Biome&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://orm.drizzle.team/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Drizzle%20ORM-FFE873?logo=drizzle&amp;logoColor=black&quot; alt=&quot;Drizzle ORM&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://neon.tech/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Neon-00E9CA?logo=neon&amp;logoColor=white&quot; alt=&quot;Neon&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://trpc.io/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/tRPC-2596BE?logo=trpc&amp;logoColor=white&quot; alt=&quot;tRPC&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

## Contributing

We welcome contributions! If you have a suggestion that would make Superset better:

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m &#039;Add amazing feature&#039;`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

You can also [open issues](https://github.com/superset-sh/superset/issues) for bugs or feature requests.

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed instructions and code of conduct.

&lt;a href=&quot;https://github.com/superset-sh/superset/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=superset-sh/superset&quot; /&gt;
&lt;/a&gt;

## Community

Join the Superset community to get help, share feedback, and connect with other users:

- **[Discord](https://discord.gg/cZeD9WYcV7)** ‚Äî Chat with the team and community
- **[Twitter](https://x.com/superset_sh)** ‚Äî Follow for updates and announcements
- **[GitHub Issues](https://github.com/superset-sh/superset/issues)** ‚Äî Report bugs and request features
- **[GitHub Discussions](https://github.com/superset-sh/superset/discussions)** ‚Äî Ask questions and share ideas

### Team

[![Avi Twitter](https://img.shields.io/badge/Avi-@avimakesrobots-555?logo=x)](https://x.com/avimakesrobots)
[![Kiet Twitter](https://img.shields.io/badge/Kiet-@flyakiet-555?logo=x)](https://x.com/flyakiet)
[![Satya Twitter](https://img.shields.io/badge/Satya-@saddle__paddle-555?logo=x)](https://x.com/saddle_paddle)

## License

Distributed under the Apache 2.0 License. See [LICENSE.md](LICENSE.md) for more information.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[openclaw/openclaw]]></title>
            <link>https://github.com/openclaw/openclaw</link>
            <guid>https://github.com/openclaw/openclaw</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:41 GMT</pubDate>
            <description><![CDATA[Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openclaw/openclaw">openclaw/openclaw</a></h1>
            <p>Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û</p>
            <p>Language: TypeScript</p>
            <p>Stars: 242,949</p>
            <p>Forks: 47,001</p>
            <p>Stars today: 2,734 stars today</p>
            <h2>README</h2><pre># ü¶û OpenClaw ‚Äî Personal AI Assistant

&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text-dark.png&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text.png&quot; alt=&quot;OpenClaw&quot; width=&quot;500&quot;&gt;
    &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;EXFOLIATE! EXFOLIATE!&lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/openclaw/openclaw/actions/workflows/ci.yml?branch=main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/openclaw/openclaw/ci.yml?branch=main&amp;style=for-the-badge&quot; alt=&quot;CI status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/openclaw/openclaw/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/openclaw/openclaw?include_prereleases&amp;style=for-the-badge&quot; alt=&quot;GitHub release&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/clawd&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1456350064065904867?label=Discord&amp;logo=discord&amp;logoColor=white&amp;color=5865F2&amp;style=for-the-badge&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge&quot; alt=&quot;MIT License&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

**OpenClaw** is a _personal AI assistant_ you run on your own devices.
It answers you on the channels you already use (WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, WebChat), plus extension channels like BlueBubbles, Matrix, Zalo, and Zalo Personal. It can speak and listen on macOS/iOS/Android, and can render a live Canvas you control. The Gateway is just the control plane ‚Äî the product is the assistant.

If you want a personal, single-user assistant that feels local, fast, and always-on, this is it.

[Website](https://openclaw.ai) ¬∑ [Docs](https://docs.openclaw.ai) ¬∑ [Vision](VISION.md) ¬∑ [DeepWiki](https://deepwiki.com/openclaw/openclaw) ¬∑ [Getting Started](https://docs.openclaw.ai/start/getting-started) ¬∑ [Updating](https://docs.openclaw.ai/install/updating) ¬∑ [Showcase](https://docs.openclaw.ai/start/showcase) ¬∑ [FAQ](https://docs.openclaw.ai/help/faq) ¬∑ [Wizard](https://docs.openclaw.ai/start/wizard) ¬∑ [Nix](https://github.com/openclaw/nix-openclaw) ¬∑ [Docker](https://docs.openclaw.ai/install/docker) ¬∑ [Discord](https://discord.gg/clawd)

Preferred setup: run the onboarding wizard (`openclaw onboard`) in your terminal.
The wizard guides you step by step through setting up the gateway, workspace, channels, and skills. The CLI wizard is the recommended path and works on **macOS, Linux, and Windows (via WSL2; strongly recommended)**.
Works with npm, pnpm, or bun.
New install? Start here: [Getting started](https://docs.openclaw.ai/start/getting-started)

## Sponsors

| OpenAI                                                            | Blacksmith                                                                   | Convex                                                                |
| ----------------------------------------------------------------- | ---------------------------------------------------------------------------- | --------------------------------------------------------------------- |
| [![OpenAI](docs/assets/sponsors/openai.svg)](https://openai.com/) | [![Blacksmith](docs/assets/sponsors/blacksmith.svg)](https://blacksmith.sh/) | [![Convex](docs/assets/sponsors/convex.svg)](https://www.convex.dev/) |

**Subscriptions (OAuth):**

- **[OpenAI](https://openai.com/)** (ChatGPT/Codex)

Model note: while any model is supported, I strongly recommend **Anthropic Pro/Max (100/200) + Opus 4.6** for long‚Äëcontext strength and better prompt‚Äëinjection resistance. See [Onboarding](https://docs.openclaw.ai/start/onboarding).

## Models (selection + auth)

- Models config + CLI: [Models](https://docs.openclaw.ai/concepts/models)
- Auth profile rotation (OAuth vs API keys) + fallbacks: [Model failover](https://docs.openclaw.ai/concepts/model-failover)

## Install (recommended)

Runtime: **Node ‚â•22**.

```bash
npm install -g openclaw@latest
# or: pnpm add -g openclaw@latest

openclaw onboard --install-daemon
```

The wizard installs the Gateway daemon (launchd/systemd user service) so it stays running.

## Quick start (TL;DR)

Runtime: **Node ‚â•22**.

Full beginner guide (auth, pairing, channels): [Getting started](https://docs.openclaw.ai/start/getting-started)

```bash
openclaw onboard --install-daemon

openclaw gateway --port 18789 --verbose

# Send a message
openclaw message send --to +1234567890 --message &quot;Hello from OpenClaw&quot;

# Talk to the assistant (optionally deliver back to any connected channel: WhatsApp/Telegram/Slack/Discord/Google Chat/Signal/iMessage/BlueBubbles/Microsoft Teams/Matrix/Zalo/Zalo Personal/WebChat)
openclaw agent --message &quot;Ship checklist&quot; --thinking high
```

Upgrading? [Updating guide](https://docs.openclaw.ai/install/updating) (and run `openclaw doctor`).

## Development channels

- **stable**: tagged releases (`vYYYY.M.D` or `vYYYY.M.D-&lt;patch&gt;`), npm dist-tag `latest`.
- **beta**: prerelease tags (`vYYYY.M.D-beta.N`), npm dist-tag `beta` (macOS app may be missing).
- **dev**: moving head of `main`, npm dist-tag `dev` (when published).

Switch channels (git + npm): `openclaw update --channel stable|beta|dev`.
Details: [Development channels](https://docs.openclaw.ai/install/development-channels).

## From source (development)

Prefer `pnpm` for builds from source. Bun is optional for running TypeScript directly.

```bash
git clone https://github.com/openclaw/openclaw.git
cd openclaw

pnpm install
pnpm ui:build # auto-installs UI deps on first run
pnpm build

pnpm openclaw onboard --install-daemon

# Dev loop (auto-reload on TS changes)
pnpm gateway:watch
```

Note: `pnpm openclaw ...` runs TypeScript directly (via `tsx`). `pnpm build` produces `dist/` for running via Node / the packaged `openclaw` binary.

## Security defaults (DM access)

OpenClaw connects to real messaging surfaces. Treat inbound DMs as **untrusted input**.

Full security guide: [Security](https://docs.openclaw.ai/gateway/security)

Default behavior on Telegram/WhatsApp/Signal/iMessage/Microsoft Teams/Discord/Google Chat/Slack:

- **DM pairing** (`dmPolicy=&quot;pairing&quot;` / `channels.discord.dmPolicy=&quot;pairing&quot;` / `channels.slack.dmPolicy=&quot;pairing&quot;`; legacy: `channels.discord.dm.policy`, `channels.slack.dm.policy`): unknown senders receive a short pairing code and the bot does not process their message.
- Approve with: `openclaw pairing approve &lt;channel&gt; &lt;code&gt;` (then the sender is added to a local allowlist store).
- Public inbound DMs require an explicit opt-in: set `dmPolicy=&quot;open&quot;` and include `&quot;*&quot;` in the channel allowlist (`allowFrom` / `channels.discord.allowFrom` / `channels.slack.allowFrom`; legacy: `channels.discord.dm.allowFrom`, `channels.slack.dm.allowFrom`).

Run `openclaw doctor` to surface risky/misconfigured DM policies.

## Highlights

- **[Local-first Gateway](https://docs.openclaw.ai/gateway)** ‚Äî single control plane for sessions, channels, tools, and events.
- **[Multi-channel inbox](https://docs.openclaw.ai/channels)** ‚Äî WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, BlueBubbles (iMessage), iMessage (legacy), Microsoft Teams, Matrix, Zalo, Zalo Personal, WebChat, macOS, iOS/Android.
- **[Multi-agent routing](https://docs.openclaw.ai/gateway/configuration)** ‚Äî route inbound channels/accounts/peers to isolated agents (workspaces + per-agent sessions).
- **[Voice Wake](https://docs.openclaw.ai/nodes/voicewake) + [Talk Mode](https://docs.openclaw.ai/nodes/talk)** ‚Äî always-on speech for macOS/iOS/Android with ElevenLabs.
- **[Live Canvas](https://docs.openclaw.ai/platforms/mac/canvas)** ‚Äî agent-driven visual workspace with [A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui).
- **[First-class tools](https://docs.openclaw.ai/tools)** ‚Äî browser, canvas, nodes, cron, sessions, and Discord/Slack actions.
- **[Companion apps](https://docs.openclaw.ai/platforms/macos)** ‚Äî macOS menu bar app + iOS/Android [nodes](https://docs.openclaw.ai/nodes).
- **[Onboarding](https://docs.openclaw.ai/start/wizard) + [skills](https://docs.openclaw.ai/tools/skills)** ‚Äî wizard-driven setup with bundled/managed/workspace skills.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=openclaw/openclaw&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#openclaw/openclaw&amp;type=date&amp;legend=top-left)

## Everything we built so far

### Core platform

- [Gateway WS control plane](https://docs.openclaw.ai/gateway) with sessions, presence, config, cron, webhooks, [Control UI](https://docs.openclaw.ai/web), and [Canvas host](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui).
- [CLI surface](https://docs.openclaw.ai/tools/agent-send): gateway, agent, send, [wizard](https://docs.openclaw.ai/start/wizard), and [doctor](https://docs.openclaw.ai/gateway/doctor).
- [Pi agent runtime](https://docs.openclaw.ai/concepts/agent) in RPC mode with tool streaming and block streaming.
- [Session model](https://docs.openclaw.ai/concepts/session): `main` for direct chats, group isolation, activation modes, queue modes, reply-back. Group rules: [Groups](https://docs.openclaw.ai/channels/groups).
- [Media pipeline](https://docs.openclaw.ai/nodes/images): images/audio/video, transcription hooks, size caps, temp file lifecycle. Audio details: [Audio](https://docs.openclaw.ai/nodes/audio).

### Channels

- [Channels](https://docs.openclaw.ai/channels): [WhatsApp](https://docs.openclaw.ai/channels/whatsapp) (Baileys), [Telegram](https://docs.openclaw.ai/channels/telegram) (grammY), [Slack](https://docs.openclaw.ai/channels/slack) (Bolt), [Discord](https://docs.openclaw.ai/channels/discord) (discord.js), [Google Chat](https://docs.openclaw.ai/channels/googlechat) (Chat API), [Signal](https://docs.openclaw.ai/channels/signal) (signal-cli), [BlueBubbles](https://docs.openclaw.ai/channels/bluebubbles) (iMessage, recommended), [iMessage](https://docs.openclaw.ai/channels/imessage) (legacy imsg), [Microsoft Teams](https://docs.openclaw.ai/channels/msteams) (extension), [Matrix](https://docs.openclaw.ai/channels/matrix) (extension), [Zalo](https://docs.openclaw.ai/channels/zalo) (extension), [Zalo Personal](https://docs.openclaw.ai/channels/zalouser) (extension), [WebChat](https://docs.openclaw.ai/web/webchat).
- [Group routing](https://docs.openclaw.ai/channels/group-messages): mention gating, reply tags, per-channel chunking and routing. Channel rules: [Channels](https://docs.openclaw.ai/channels).

### Apps + nodes

- [macOS app](https://docs.openclaw.ai/platforms/macos): menu bar control plane, [Voice Wake](https://docs.openclaw.ai/nodes/voicewake)/PTT, [Talk Mode](https://docs.openclaw.ai/nodes/talk) overlay, [WebChat](https://docs.openclaw.ai/web/webchat), debug tools, [remote gateway](https://docs.openclaw.ai/gateway/remote) control.
- [iOS node](https://docs.openclaw.ai/platforms/ios): [Canvas](https://docs.openclaw.ai/platforms/mac/canvas), [Voice Wake](https://docs.openclaw.ai/nodes/voicewake), [Talk Mode](https://docs.openclaw.ai/nodes/talk), camera, screen recording, Bonjour pairing.
- [Android node](https://docs.openclaw.ai/platforms/android): [Canvas](https://docs.openclaw.ai/platforms/mac/canvas), [Talk Mode](https://docs.openclaw.ai/nodes/talk), camera, screen recording, optional SMS.
- [macOS node mode](https://docs.openclaw.ai/nodes): system.run/notify + canvas/camera exposure.

### Tools + automation

- [Browser control](https://docs.openclaw.ai/tools/browser): dedicated openclaw Chrome/Chromium, snapshots, actions, uploads, profiles.
- [Canvas](https://docs.openclaw.ai/platforms/mac/canvas): [A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui) push/reset, eval, snapshot.
- [Nodes](https://docs.openclaw.ai/nodes): camera snap/clip, screen record, [location.get](https://docs.openclaw.ai/nodes/location-command), notifications.
- [Cron + wakeups](https://docs.openclaw.ai/automation/cron-jobs); [webhooks](https://docs.openclaw.ai/automation/webhook); [Gmail Pub/Sub](https://docs.openclaw.ai/automation/gmail-pubsub).
- [Skills platform](https://docs.openclaw.ai/tools/skills): bundled, managed, and workspace skills with install gating + UI.

### Runtime + safety

- [Channel routing](https://docs.openclaw.ai/channels/channel-routing), [retry policy](https://docs.openclaw.ai/concepts/retry), and [streaming/chunking](https://docs.openclaw.ai/concepts/streaming).
- [Presence](https://docs.openclaw.ai/concepts/presence), [typing indicators](https://docs.openclaw.ai/concepts/typing-indicators), and [usage tracking](https://docs.openclaw.ai/concepts/usage-tracking).
- [Models](https://docs.openclaw.ai/concepts/models), [model failover](https://docs.openclaw.ai/concepts/model-failover), and [session pruning](https://docs.openclaw.ai/concepts/session-pruning).
- [Security](https://docs.openclaw.ai/gateway/security) and [troubleshooting](https://docs.openclaw.ai/channels/troubleshooting).

### Ops + packaging

- [Control UI](https://docs.openclaw.ai/web) + [WebChat](https://docs.openclaw.ai/web/webchat) served directly from the Gateway.
- [Tailscale Serve/Funnel](https://docs.openclaw.ai/gateway/tailscale) or [SSH tunnels](https://docs.openclaw.ai/gateway/remote) with token/password auth.
- [Nix mode](https://docs.openclaw.ai/install/nix) for declarative config; [Docker](https://docs.openclaw.ai/install/docker)-based installs.
- [Doctor](https://docs.openclaw.ai/gateway/doctor) migrations, [logging](https://docs.openclaw.ai/logging).

## How it works (short)

```
WhatsApp / Telegram / Slack / Discord / Google Chat / Signal / iMessage / BlueBubbles / Microsoft Teams / Matrix / Zalo / Zalo Personal / WebChat
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Gateway            ‚îÇ
‚îÇ       (control plane)         ‚îÇ
‚îÇ     ws://127.0.0.1:18789      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚îú‚îÄ Pi agent (RPC)
               ‚îú‚îÄ CLI (openclaw ‚Ä¶)
               ‚îú‚îÄ WebChat UI
               ‚îú‚îÄ macOS app
               ‚îî‚îÄ iOS / Android nodes
```

## Key subsystems

- **[Gateway WebSocket network](https://docs.openclaw.ai/concepts/architecture)** ‚Äî single WS control plane for clients, tools, and events (plus ops: [Gateway runbook](https://docs.openclaw.ai/gateway)).
- **[Tailscale exposure](https://docs.openclaw.ai/gateway/tailscale)** ‚Äî Serve/Funnel for the Gateway dashboard + WS (remote access: [Remote](https://docs.openclaw.ai/gateway/remote)).
- **[Browser control](https://docs.openclaw.ai/tools/browser)** ‚Äî openclaw‚Äëmanaged Chrome/Chromium with CDP control.
- **[Canvas + A2UI](https://docs.openclaw.ai/platforms/mac/canvas)** ‚Äî agent‚Äëdriven visual workspace (A2UI host: [Canvas/A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui)).
- **[Voice Wake](https://docs.openclaw.ai/nodes/voicewake) + [Talk Mode](https://docs.openclaw.ai/nodes/talk)** ‚Äî always‚Äëon speech and continuous conversation.
- **[Nodes](https://docs.openclaw.ai/nodes)** ‚Äî Canvas, camera snap/clip, screen record, `location.get`, notifications, plus macOS‚Äëonly `system.run`/`system.notify`.

## Tailscale access (Gateway dashboard)

OpenClaw can auto-configure Tailscale **Serve** (tailnet-only) or **Funnel** (public) while the Gateway stays bound to loopback. Configure `gateway.tailscale.mode`:

- `off`: no Tailscale automation (default).
- `serve`: tailnet-only HTTPS via `tailscale serve` (uses Tailscale identity headers by default).
- `funnel`: public HTTPS via `tailscale funnel` (requires shared password auth).

Notes:

- `gateway.bind` must stay `loopback` when Serve/Funnel is enabled (OpenClaw enforces this).
- Serve can be forced to require a password by setting `gateway.auth.mode: &quot;password&quot;` or `gateway.auth.allowTailscale: false`.
- Funnel refuses to start unless `gateway.auth.mode: &quot;password&quot;` is set.
- Optional: `gateway.tailscale.resetOnExit` to undo Serve/Funnel on shutdown.

Details: [Tailscale guide](https://docs.openclaw.ai/gateway/tailscale) ¬∑ [Web surfaces](https://docs.openclaw.ai/web)

## Remote Gateway (Linux is great)

It‚Äôs perfectly fine to run the Gateway on a small Linux instance. Clients (macOS app, CLI, WebChat) can connect over **Tailscale Serve/Funnel** or **SSH tunnels**, and you can still pair device nodes (macOS/iOS/Android) to execute device‚Äëlocal actions when needed.

- **Gateway host** runs the exec tool and channel connections by default.
- **Device nodes** run device‚Äëlocal actions (`system.run`, camera, screen recording, notifications) via `node.invoke`.
  In short: exec runs where the Gateway lives; device actions run where the device lives.

Details: [Remote access](https://docs.openclaw.ai/gateway/remote) ¬∑ [Nodes](https://docs.openclaw.ai/nodes) ¬∑ [Security](https://docs.openclaw.ai/gateway/security)

## macOS permissions via the Gateway protocol

The macOS app can run in **node mode** and advertises its capabilities + permission map over the Gateway WebSocket (`node.list` / `node.describe`). Clients can then execute local actions via `node.invoke`:

- `system.run` runs a local command and returns stdout/stderr/exit code; set `needsScreenRecording: true` to require screen-recording permission (otherwise you‚Äôll get `PERMISSION_MISSING`).
- `system.notify` posts a user notification and fails if notifications are denied.
- `canvas.*`, `camera.*`, `screen.record`, and `location.get` are also routed via `node.invoke` and follow TCC permission status.

Elevated bash (host permissions) is separate from macOS TCC:

- Use `/elevated on|off` to toggle per‚Äësession elevated access when enabled + allowlisted.
- Gateway persists the per‚Äësession toggle via `sessions.patch` (WS method) alongside `thinkingLevel`, `verboseLevel`, `model`, `sendPolicy`, and `groupActivation`.

Details: [Nodes](https://docs.openclaw.ai/nodes) ¬∑ [macOS app](https://docs.openclaw.ai/platforms/macos) ¬∑ [Gateway protocol](https://docs.openclaw.ai/concepts/architecture)

## Agent to Agent (sessions\_\* tools)

- Use these to coordinate work across sessions without jumping between chat surfaces.
- `sessions_list` ‚Äî discover active sessions (agents) and their metadata.
- `sessions_history` ‚Äî fetch transcript logs for a session.
- `sessions_send` ‚Äî message another session; optional reply‚Äëback ping‚Äëpong + announce step (`REPLY_SKIP`, `ANNOUNCE_SKIP`).

Details: [Session tools](https://docs.openclaw.ai/concepts/session-tool)

## Skills registry (ClawHub)

ClawHub is a minimal skill registry. With ClawHub enabled, the agent can search for skills automatically and pull in new ones as needed.

[ClawHub](https://clawhub.com)

## Chat commands

Send these in WhatsApp/Telegram/Slack/Google Chat/Microsoft Teams/WebChat (group commands are owner-only):

- `/status` ‚Äî compact session status (model + tokens, cost when available)
- `/new` or `/reset` ‚Äî reset the session
- `/compact` ‚Äî compact session context (summary)
- `/think &lt;level&gt;` ‚Äî off|minimal|low|medium|high|xhigh (GPT-5.2 + Codex models only)
- `/verbose on|off`
- `/usage off|tokens|full` ‚Äî per-response usage footer
- `/restart` ‚Äî restart the gateway (owner-only in groups)
- `/activation mention|always` ‚Äî group activation toggle (groups only)

## Apps (optional)

The Gateway alone delivers a great experience. All apps are optional and add extra features.

If you plan to build/run companion apps, follow the platform runbooks below.

### macOS (OpenClaw.app) (optional)

- Menu bar control for the Gateway and health.
- Voice Wake + push-to-talk overlay.
- WebChat + debug tools.
- Remote gateway control over SSH.

Note: signed builds required for macOS permissions to stick across rebuilds (see `docs/mac/permissions.md`).

### iOS node (optional)

- Pairs as a node via the Bridge.
- Voice trigger forwarding + Canvas surface.
- Controlled via `openclaw nodes ‚Ä¶`.

Runbook: [iOS connect](https://docs.openclaw.ai/platforms/ios).

### Android node (optional)

- Pairs via the same Bridge + pairing flow as i

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[farion1231/cc-switch]]></title>
            <link>https://github.com/farion1231/cc-switch</link>
            <guid>https://github.com/farion1231/cc-switch</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:40 GMT</pubDate>
            <description><![CDATA[A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode & Gemini CLI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/farion1231/cc-switch">farion1231/cc-switch</a></h1>
            <p>A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode & Gemini CLI.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 22,163</p>
            <p>Forks: 1,360</p>
            <p>Stars today: 396 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# All-in-One Assistant for Claude Code, Codex &amp; Gemini CLI

[![Version](https://img.shields.io/badge/version-3.11.1-blue.svg)](https://github.com/farion1231/cc-switch/releases)
[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/farion1231/cc-switch/releases)
[![Built with Tauri](https://img.shields.io/badge/built%20with-Tauri%202-orange.svg)](https://tauri.app/)
[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/farion1231/cc-switch/total)](https://github.com/farion1231/cc-switch/releases/latest)

&lt;a href=&quot;https://trendshift.io/repositories/15372&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15372&quot; alt=&quot;farion1231%2Fcc-switch | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

English | [‰∏≠Êñá](README_ZH.md) | [Êó•Êú¨Ë™û](README_JA.md) | [Changelog](CHANGELOG.md)

&lt;/div&gt;

## ‚ù§Ô∏èSponsor

[![MiniMax](assets/partners/banners/minimax-en.jpeg)](https://platform.minimax.io/subscribe/coding-plan?code=ClLhgxr2je&amp;source=link)

MiniMax-M2.5 is a SOTA large language model designed for real-world productivity. Trained in a diverse range of complex real-world digital working environments, M2.5 builds upon the coding expertise of M2.1 to extend into general office work, reaching fluency in generating and operating Word, Excel, and Powerpoint files, context switching between diverse software environments, and working across different agent and human teams. Scoring 80.2% on SWE-Bench Verified, 51.3% on Multi-SWE-Bench, and 76.3% on BrowseComp, M2.5 is also more token efficient than previous generations, having been trained to optimize its actions and output through planning.

[Click](https://platform.minimax.io/subscribe/coding-plan?code=ClLhgxr2je&amp;source=link) to get an exclusive 12% off the MiniMax Coding Plan!

---

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.packyapi.com/register?aff=cc-switch&quot;&gt;&lt;img src=&quot;assets/partners/logos/packycode.png&quot; alt=&quot;PackyCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to PackyCode for sponsoring this project! PackyCode is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more. PackyCode provides special discounts for our software users: register using &lt;a href=&quot;https://www.packyapi.com/register?aff=cc-switch&quot;&gt;this link&lt;/a&gt; and enter the &quot;cc-switch&quot; promo code during first recharge to get 10% off.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://aigocode.com/invite/CC-SWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/aigocode.png&quot; alt=&quot;AIGoCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AIGoCode for sponsoring this project! AIGoCode is an all-in-one platform that integrates Claude Code, Codex, and the latest Gemini models, providing you with stable, efficient, and highly cost-effective AI coding services. The platform offers flexible subscription plans, zero risk of account suspension, direct access with no VPN required, and lightning-fast responses. AIGoCode has prepared a special benefit for CC Switch users: if you register via &lt;a href=&quot;https://aigocode.com/invite/CC-SWITCH&quot;&gt;this link&lt;/a&gt;, you&#039;ll receive an extra 10% bonus credit on your first top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.aicodemirror.com/register?invitecode=9915W3&quot;&gt;&lt;img src=&quot;assets/partners/logos/aicodemirror.jpg&quot; alt=&quot;AICodeMirror&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AICodeMirror for sponsoring this project! AICodeMirror provides official high-stability relay services for Claude Code / Codex / Gemini CLI, with enterprise-grade concurrency, fast invoicing, and 24/7 dedicated technical support.
Claude Code / Codex / Gemini official channels at 38% / 2% / 9% of original price, with extra discounts on top-ups! AICodeMirror offers special benefits for CC Switch users: register via &lt;a href=&quot;https://www.aicodemirror.com/register?invitecode=9915W3&quot;&gt;this link&lt;/a&gt; to enjoy 20% off your first top-up, and enterprise customers can get up to 25% off!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://cubence.com/signup?code=CCSWITCH&amp;source=ccs&quot;&gt;&lt;img src=&quot;assets/partners/logos/cubence.png&quot; alt=&quot;Cubence&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to Cubence for sponsoring this project! Cubence is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more with flexible billing options including pay-as-you-go and monthly plans. Cubence provides special discounts for CC Switch users: register using &lt;a href=&quot;https://cubence.com/signup?code=CCSWITCH&amp;source=ccs&quot;&gt;this link&lt;/a&gt; and enter the &quot;CCSWITCH&quot; promo code during recharge to get 10% off every top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.dmxapi.cn/register?aff=bUHu&quot;&gt;&lt;img src=&quot;assets/partners/logos/dmx-en.jpg&quot; alt=&quot;DMXAPI&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to DMXAPI for sponsoring this project! DMXAPI provides global large model API services to 200+ enterprise users. One API key for all global models. Features include: instant invoicing, unlimited concurrency, starting from $0.15, 24/7 technical support. GPT/Claude/Gemini all at 32% off, domestic models 20-50% off, Claude Code exclusive models at 66% off! &lt;a href=&quot;https://www.dmxapi.cn/register?aff=bUHu&quot;&gt;Register here&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.right.codes/register?aff=CCSWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/rightcode.jpg&quot; alt=&quot;RightCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thank you to Right Code for sponsoring this project! Right Code reliably provides routing services for models such as Claude Code, Codex, and Gemini. It features a highly cost-effective Codex monthly subscription plan and &lt;strong&gt;supports quota rollovers‚Äîunused quota from one day can be carried over and used the next day.&lt;/strong&gt; Invoices are available upon top-up. Enterprise and team users can receive dedicated one-on-one support. Right Code also offers an exclusive discount for CC Switch users: register via &lt;a href=&quot;https://www.right.codes/register?aff=CCSWITCH&quot;&gt;this link&lt;/a&gt;, and with every top-up you will receive pay-as-you-go credit equivalent to 25% of the amount paid.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://aicoding.sh/i/CCSWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/aicoding.jpg&quot; alt=&quot;AICoding&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AICoding.sh for sponsoring this project! AICoding.sh ‚Äî Global AI Model API Relay Service at Unbeatable Prices! Claude Code at 19% of original price, GPT at just 1%! Trusted by hundreds of enterprises for cost-effective AI services. Supports Claude Code, GPT, Gemini and major domestic models, with enterprise-grade high concurrency, fast invoicing, and 24/7 dedicated technical support. CC Switch users who register via &lt;a href=&quot;https://aicoding.sh/i/CCSWITCH&quot;&gt;this link&lt;/a&gt; get 10% off their first top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://crazyrouter.com/register?aff=OZcm&amp;ref=cc-switch&quot;&gt;&lt;img src=&quot;assets/partners/logos/crazyrouter.jpg&quot; alt=&quot;AICoding&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to Crazyrouter for sponsoring this project! Crazyrouter is a high-performance AI API aggregation platform ‚Äî one API key for 300+ models including Claude Code, Codex, Gemini CLI, and more. All models at 55% of official pricing with auto-failover, smart routing, and unlimited concurrency. Crazyrouter offers an exclusive deal for CC Switch users: register via &lt;a href=&quot;https://crazyrouter.com/register?aff=OZcm&amp;ref=cc-switch&quot;&gt;this link&lt;/a&gt;  to get &lt;strong&gt;$2 free credit&lt;/strong&gt; instantly, plus enter promo code `CCSWITCH` on your first top-up for an extra &lt;strong&gt;30% bonus credit&lt;/strong&gt;! &lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.sssaicode.com/register?ref=DCP0SM&quot;&gt;&lt;img src=&quot;assets/partners/logos/sssaicode.png&quot; alt=&quot;SSSAiCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to SSSAiCode for sponsoring this project! SSSAiCode is a stable and reliable API relay service, dedicated to providing stable, reliable, and affordable Claude and Codex model services, &lt;strong&gt;offering high cost-effective official Claude service at just ¬•0.5/$ equivalent&lt;/strong&gt;, supporting monthly and pay-as-you-go billing plans with same-day fast invoicing. SSSAiCode offers a special deal for CC Switch users: register via &lt;a href=&quot;https://www.sssaicode.com/register?ref=DCP0SM&quot;&gt;this link&lt;/a&gt; to enjoy $10 extra credit on every top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

## Screenshots

|                  Main Interface                   |                  Add Provider                  |
| :-----------------------------------------------: | :--------------------------------------------: |
| ![Main Interface](assets/screenshots/main-en.png) | ![Add Provider](assets/screenshots/add-en.png) |

## Features

### Current Version: v3.11.1 | [Full Changelog](CHANGELOG.md) | [Release Notes](docs/release-note-v3.11.1-en.md)

**v3.8.0 Major Update (2025-11-28)**

**Persistence Architecture Upgrade &amp; Brand New UI**

- **SQLite + JSON Dual-layer Architecture**
  - Migrated from JSON file storage to SQLite + JSON dual-layer structure
  - Syncable data (providers, MCP, Prompts, Skills) stored in SQLite
  - Device-level data (window state, local paths) stored in JSON
  - Lays the foundation for future cloud sync functionality
  - Schema version management for database migrations

- **Brand New User Interface**
  - Completely redesigned interface layout
  - Unified component styles and smoother animations
  - Optimized visual hierarchy
  - Tailwind CSS downgraded from v4 to v3.4 for better browser compatibility

- **Japanese Language Support**
  - Added Japanese interface support (now supports Chinese/English/Japanese)

- **Auto Launch on Startup**
  - One-click enable/disable in settings
  - Platform-native APIs (Registry/LaunchAgent/XDG autostart)

- **Skills Recursive Scanning**
  - Support for multi-level directory structures
  - Allow same-named skills from different repositories

- **Critical Bug Fixes**
  - Fixed custom endpoints lost when updating providers
  - Fixed Gemini configuration write issues
  - Fixed Linux WebKitGTK rendering issues

**v3.7.0 Highlights**

**Six Core Features, 18,000+ Lines of New Code**

- **Gemini CLI Integration**
  - Third supported AI CLI (Claude Code / Codex / Gemini)
  - Dual-file configuration support (`.env` + `settings.json`)
  - Complete MCP server management
  - Presets: Google Official (OAuth) / PackyCode / Custom

- **Claude Skills Management System**
  - Auto-scan skills from GitHub repositories (3 pre-configured curated repos)
  - One-click install/uninstall to `~/.claude/skills/`
  - Custom repository support + subdirectory scanning
  - Complete lifecycle management (discover/install/update)

- **Prompts Management System**
  - Multi-preset system prompt management (unlimited presets, quick switching)
  - Cross-app support (Claude: `CLAUDE.md` / Codex: `AGENTS.md` / Gemini: `GEMINI.md`)
  - Markdown editor (CodeMirror 6 + real-time preview)
  - Smart backfill protection, preserves manual modifications

- **MCP v3.7.0 Unified Architecture**
  - Single panel manages MCP servers across three applications
  - New SSE (Server-Sent Events) transport type
  - Smart JSON parser + Codex TOML format auto-correction
  - Unified import/export + bidirectional sync

- **Deep Link Protocol**
  - `ccswitch://` protocol registration (all platforms)
  - One-click import provider configs via shared links
  - Security validation + lifecycle integration

- **Environment Variable Conflict Detection**
  - Auto-detect cross-app configuration conflicts (Claude/Codex/Gemini/MCP)
  - Visual conflict indicators + resolution suggestions
  - Override warnings + backup before changes

**Core Capabilities**

- **Provider Management**: One-click switching between Claude Code, Codex, and Gemini API configurations
- **AWS Bedrock Support**: Built-in AWS Bedrock provider presets with AKSK and API Key authentication, cross-region inference support (global/us/eu/apac), covering Claude Code and OpenCode
- **Speed Testing**: Measure API endpoint latency with visual quality indicators
- **Import/Export**: Backup and restore configs with auto-rotation (keep 10 most recent)
- **i18n Support**: Complete Chinese/English localization (UI, errors, tray)
- **Claude Plugin Sync**: One-click apply/restore Claude plugin configurations

**v3.6 Highlights**

- Provider duplication &amp; drag-and-drop sorting
- Multi-endpoint management &amp; custom config directory (cloud sync ready)
- Granular model configuration (4-tier: Haiku/Sonnet/Opus/Custom)
- WSL environment support with auto-sync on directory change
- 100% hooks test coverage &amp; complete architecture refactoring

**System Features**

- System tray with quick switching
- Single instance daemon
- Built-in auto-updater
- Atomic writes with rollback protection

## Download &amp; Installation

### System Requirements

- **Windows**: Windows 10 and above
- **macOS**: macOS 10.15 (Catalina) and above
- **Linux**: Ubuntu 22.04+ / Debian 11+ / Fedora 34+ and other mainstream distributions

### Windows Users

Download the latest `CC-Switch-v{version}-Windows.msi` installer or `CC-Switch-v{version}-Windows-Portable.zip` portable version from the [Releases](../../releases) page.

### macOS Users

**Method 1: Install via Homebrew (Recommended)**

```bash
brew tap farion1231/ccswitch
brew install --cask cc-switch
```

Update:

```bash
brew upgrade --cask cc-switch
```

**Method 2: Manual Download**

Download `CC-Switch-v{version}-macOS.zip` from the [Releases](../../releases) page and extract to use.

&gt; **Note**: Since the author doesn&#039;t have an Apple Developer account, you may see an &quot;unidentified developer&quot; warning on first launch. Please close it first, then go to &quot;System Settings&quot; ‚Üí &quot;Privacy &amp; Security&quot; ‚Üí click &quot;Open Anyway&quot;, and you&#039;ll be able to open it normally afterwards.

### Arch Linux Users

**Install via paru (Recommended)**

```bash
paru -S cc-switch-bin
```

### Linux Users

Download the latest Linux build from the [Releases](../../releases) page:

- `CC-Switch-v{version}-Linux.deb` (Debian/Ubuntu)
- `CC-Switch-v{version}-Linux.rpm` (Fedora/RHEL/openSUSE)
- `CC-Switch-v{version}-Linux.AppImage` (Universal)
- `CC-Switch-v{version}-Linux.flatpak` (Flatpak)

Flatpak install &amp; run:

```bash
flatpak install --user ./CC-Switch-v{version}-Linux.flatpak
flatpak run com.ccswitch.desktop
```

## Quick Start

### Basic Usage

1. **Add Provider**: Click &quot;Add Provider&quot; ‚Üí Choose preset or create custom configuration
2. **Switch Provider**:
   - Main UI: Select provider ‚Üí Click &quot;Enable&quot;
   - System Tray: Click provider name directly (instant effect)
3. **Takes Effect**: Restart your terminal or Claude Code / Codex / Gemini clients to apply changes
4. **Back to Official**: Select the &quot;Official Login&quot; preset (Claude/Codex) or &quot;Google Official&quot; preset (Gemini), restart the corresponding client, then follow its login/OAuth flow

### MCP Management

- **Location**: Click &quot;MCP&quot; button in top-right corner
- **Add Server**:
  - Use built-in templates (mcp-fetch, mcp-filesystem, etc.)
  - Support stdio / http / sse transport types
  - Configure independent MCP servers for different apps
- **Enable/Disable**: Toggle switches to control which servers sync to live config
- **Sync**: Enabled servers auto-sync to each app&#039;s live files
- **Import/Export**: Import existing MCP servers from Claude/Codex/Gemini config files

### Skills Management (v3.7.0 New)

- **Location**: Click &quot;Skills&quot; button in top-right corner
- **Discover Skills**:
  - Auto-scan pre-configured GitHub repositories (Anthropic official, ComposioHQ, community, etc.)
  - Add custom repositories (supports subdirectory scanning)
- **Install Skills**: Click &quot;Install&quot; to one-click install to `~/.claude/skills/`
- **Uninstall Skills**: Click &quot;Uninstall&quot; to safely remove and clean up state
- **Manage Repositories**: Add/remove custom GitHub repositories

### Prompts Management (v3.7.0 New)

- **Location**: Click &quot;Prompts&quot; button in top-right corner
- **Create Presets**:
  - Create unlimited system prompt presets
  - Use Markdown editor to write prompts (syntax highlighting + real-time preview)
- **Switch Presets**: Select preset ‚Üí Click &quot;Activate&quot; to apply immediately
- **Sync Mechanism**:
  - Claude: `~/.claude/CLAUDE.md`
  - Codex: `~/.codex/AGENTS.md`
  - Gemini: `~/.gemini/GEMINI.md`
- **Protection Mechanism**: Auto-save current prompt content before switching, preserves manual modifications

### Configuration Files

**Claude Code**

- Live config: `~/.claude/settings.json` (or `claude.json`)
- API key field: `env.ANTHROPIC_AUTH_TOKEN` or `env.ANTHROPIC_API_KEY`
- MCP servers: `~/.claude.json` ‚Üí `mcpServers`

**Codex**

- Live config: `~/.codex/auth.json` (required) + `config.toml` (optional)
- API key field: `OPENAI_API_KEY` in `auth.json`
- MCP servers: `~/.codex/config.toml` ‚Üí `[mcp_servers]` tables

**Gemini**

- Live config: `~/.gemini/.env` (API key) + `~/.gemini/settings.json` (auth mode)
- API key field: `GEMINI_API_KEY` or `GOOGLE_GEMINI_API_KEY` in `.env`
- Environment variables: Support `GOOGLE_GEMINI_BASE_URL`, `GEMINI_MODEL`, etc.
- MCP servers: `~/.gemini/settings.json` ‚Üí `mcpServers`
- Tray quick switch: Each provider switch rewrites `~/.gemini/.env`, no need to restart Gemini CLI

**CC Switch Storage (v3.8.0 New Architecture)**

- Database (SSOT): `~/.cc-switch/cc-switch.db` (SQLite, stores providers, MCP, Prompts, Skills)
- Local settings: `~/.cc-switch/settings.json` (device-level settings)
- Backups: `~/.cc-switch/backups/` (auto-rotate, keep 10)

### Cloud Sync Setup

1. Go to Settings ‚Üí &quot;Custom Configuration Directory&quot;
2. Choose your cloud sync folder (Dropbox, OneDrive, iCloud, etc.)
3. Restart app to apply
4. Repeat on other devices to enable cross-device sync

&gt; **Note**: First launch auto-imports existing Claude/Codex configs as default provider.

## Architecture Overview

### Design Principles

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (React + TS)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Components  ‚îÇ  ‚îÇ    Hooks     ‚îÇ  ‚îÇ  TanStack Query  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   (UI)      ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Logic) ‚îÇ‚îÄ‚îÄ‚îÇ   (Cache/Sync)   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ Tauri IPC
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Backend (Tauri + Rust)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Commands   ‚îÇ  ‚îÇ   Services   ‚îÇ  ‚îÇ  Models/Config   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ (API Layer) ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Layer) ‚îÇ‚îÄ‚îÄ‚îÇ     (Data)       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Core Design Patterns**

- **SSOT** (Single Source of Truth): All data stored in `~/.cc-switch/cc-switch.db` (SQLite)
- **Dual-layer Storage**: SQLite for syncable data, JSON for device-level settings
- **Dual-way Sync**: Write to live files on switch, backfill from live when editing active provider
- **Atomic Writes**: Temp file + rename pattern prevents config corruption
- **Concurrency Safe**: Mutex-protected database connection avoids race conditions
- **Layered Architecture**: Clear separation (Commands ‚Üí Services ‚Üí DAO ‚Üí Database)

**Key Components**

- **ProviderService**: Provider CRUD, switching, backfill, sorting
- **McpService**: MCP server management, import/export, live file sync
- **ConfigService**: Config import/export, backup rotation
- **SpeedtestService**: API endpoint latency measurement

**v3.6 Refactoring**

- Backend: 5-phase refactoring (error handling ‚Üí command split ‚Üí tests ‚Üí services ‚Üí concurrency)
- Frontend: 4-stage refactoring (test infra ‚Üí hooks ‚Üí components ‚Üí cleanup)
- Testing: 100% hooks coverage + integration tests (vitest + MSW)

## Development

### Environment Requirements

- Node.js 18+
- pnpm 8+
- Rust 1.85+
- Tauri CLI 2.8+

### 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[hcengineering/platform]]></title>
            <link>https://github.com/hcengineering/platform</link>
            <guid>https://github.com/hcengineering/platform</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:39 GMT</pubDate>
            <description><![CDATA[Huly ‚Äî All-in-One Project Management Platform (alternative to Linear, Jira, Slack, Notion, Motion)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hcengineering/platform">hcengineering/platform</a></h1>
            <p>Huly ‚Äî All-in-One Project Management Platform (alternative to Linear, Jira, Slack, Notion, Motion)</p>
            <p>Language: TypeScript</p>
            <p>Stars: 24,742</p>
            <p>Forks: 1,731</p>
            <p>Stars today: 184 stars today</p>
            <h2>README</h2><pre># Huly Platform

[![X (formerly Twitter) Follow](https://img.shields.io/twitter/follow/huly_io?style=for-the-badge)](https://x.com/huly_io)
![GitHub License](https://img.shields.io/github/license/hcengineering/platform?style=for-the-badge)

‚≠êÔ∏è Your star shines on us. Star us on GitHub!

## About

The Huly Platform is a robust framework designed to accelerate the development of business applications, such as CRM systems.
This repository includes several applications, such as Chat, Project Management, CRM, HRM, and ATS.
Various teams are building products on top of the Platform, including [Huly](https://huly.io) and [TraceX](https://tracex.co).

![Huly](https://repository-images.githubusercontent.com/392073243/6d27d5cc-38cd-4d88-affe-bb88b393180c)

## Self-Hosting

If you&#039;re primarily interested in self-hosting Huly without the intention to modify or contribute to its development, please use [huly-selfhost](https://github.com/hcengineering/huly-selfhost).
This project offers a convenient method to host Huly using `docker`, designed for ease of use and quick setup. Explore this option to effortlessly enjoy Huly on your own server.

## Activity

![Alt](https://repobeats.axiom.co/api/embed/c42c99e21691fa60ea61b5cdf11c2e0647621534.svg &#039;Repobeats analytics image&#039;)

## API Client

If you want to interact with Huly programmatically, check out our [API Client](https://github.com/hcengineering/huly.core/tree/main/packages/api-client) documentation. The API client provides a typed interface for all Huly operations and can be used to build integrations and custom applications.

You can find API usage examples in the [Huly examples](https://github.com/hcengineering/huly-examples) repository.

## Changelog

For detailed information about changes, improvements, and bug fixes in each version, see our [Changelog](./changelog.md).

## Versions

The Huly Platform uses two types of version tags to distinguish between production-ready and development releases:

- **Production Versions (`v*`)** - Stable releases for end users
  - Example: `v0.7.310`, `v0.7.307`, `v0.6.501`
  - These versions are recommended for production deployments
  - Suitable for self-hosted installations
  - Published with release notes on [GitHub Releases](https://github.com/hcengineering/platform/releases)

- **Development Versions (`s*`)** - Pre-release builds for developers
  - Example: `s0.7.313`, `s0.7.292`, `s0.7.288`
  - Used for development and testing purposes
  - May contain experimental features or bug fixes
  - Not recommended for production use

## Architecture

For detailed information about the platform architecture, services, and their interactions, see our [Architecture Overview](./ARCHITECTURE_OVERVIEW.md).

## Table of Contents

- [Huly Platform](#huly-platform)
  - [About](#about)
  - [Self-Hosting](#self-hosting)
  - [Activity](#activity)
  - [API Client](#api-client)
  - [Changelog](#changelog)
  - [Versions](#versions)
  - [Architecture](#architecture)
  - [Table of Contents](#table-of-contents)
  - [Pre-requisites](#pre-requisites)
  - [Verification](#verification)
  - [Branches \&amp; Contributing](#branches--contributing)
  - [Setup dev environment](#setup-dev-environment)
  - [Fast start](#fast-start)
  - [Installation](#installation)
  - [Build and run](#build-and-run)
  - [Run in development mode](#run-in-development-mode)
  - [Update project structure and database](#update-project-structure-and-database)
  - [Troubleshooting](#troubleshooting)
  - [Build \&amp; Watch](#build--watch)
  - [Tests](#tests)
    - [Unit tests](#unit-tests)
    - [UI tests](#ui-tests)
  - [Package publishing](#package-publishing)
  - [Additional testing](#additional-testing)
  - [WSL build guide](#wsl-build-guide)

## Pre-requisites

- Before proceeding, ensure that your system meets the following requirements:
  - [Node.js](https://nodejs.org/en/download/) (v22 is required)
  - [Docker](https://docs.docker.com/get-docker/)
  - [Docker Compose](https://docs.docker.com/compose/install/)

## Verification

To verify the installation, perform the following checks in your terminal:

- Ensure that the `docker` commands are available:

```bash
docker --version
docker compose version
```

## Branches &amp; Contributing

- The `main` branch is the default branch used for production deployments.
  Changes to this branch are made from the `staging` branch once a version is ready for community use.

- The `staging` branch is used for pre-release testing.
  It is stable enough for testing but not yet ready for production deployment.

- The `develop` branch is used for development and is the default branch for contributions.

We periodically merge `develop` into `staging` to perform testing builds. Once we are satisfied with the build quality in our pre-release deployment, we merge changes into `main` and release a new version to the community.

## Setup dev environment

### To initialise the communication submodule

```bash
git submodule init
git submodule update
```

### To update the communication submodule

```bash
git submodule update
```

### Authentication

This project uses GitHub Packages for dependency management. To successfully download dependencies, you need to generate a GitHub personal access token and log in to npm using that token.

Follow these steps:

1. Generate a GitHub Token:
- Log in to your GitHub account
- Go to **Settings** &gt; **Developer settings** &gt; **Personal access tokens** (https://github.com/settings/personal-access-tokens)
- Click **Generate new token**
- Select the required scopes (at least `read:packages`)
- Generate the token and copy it

2. Authenticate with npm:
```bash
npm login --registry=https://npm.pkg.github.com
```

When prompted, enter your GitHub username, use the generated token as your password


## Fast start

```bash
sh ./scripts/fast-start.sh
```

## Installation

You need Microsoft&#039;s [rush](https://rushjs.io) to install the application.

1. Install Rush globally using the command:

```bash
npm install -g @microsoft/rush
```

2. Navigate to the repository root and run the following commands:

```bash
rush install
rush build
```

Alternatively, you can just execute:

```bash
sh ./scripts/presetup-rush.sh
```

## Build and run

Development environment setup requires Docker to be installed on system.

Support is available for both amd64 and arm64 containers on Linux and macOS.

```bash
cd ./dev/
rush build    # Will build all the required packages.
# rush rebuild  # could be used to omit build cache.
rush bundle   # Will prepare bundles.
rush package  # Will build all webpack packages.
rush validate # Will validate all sources with typescript and generate d.ts files required for ts-node execution.
rush svelte-check # Optional. svelte files validation using svelte-check.
rush docker:build   # Will build Docker containers for all applications in the local Docker environment.
rush docker:up # Will set up all the containers
```

Be aware `rush docker:build` will automatically execute all required phases like build, bundle, package.

&gt; **Note:** For resource-constrained machines, you can use the minified variants `rush docker:min` and `rush docker:up:min` to build and run only the required services (excludes hulypulse, redis, process, backup, rating, preview, link-preview, elastic, fulltext, payment, stats, print, sign, hulygun, hulykvs).

Alternatively, you can just execute:

```bash
sh ./scripts/build.sh
```

By default, Docker volumes named dev_db, dev_elastic, and dev_files will be created for the MongoDB, Elasticsearch, and MinIO instances.

Add the following lines to your hosts file:

- **macOS / Linux:** `/etc/hosts`
- **Windows:** `C:\Windows\System32\drivers\etc\hosts`

```plain
127.0.0.1 huly.local
::1 huly.local
```

Accessing the URL &lt;http://huly.local:8087&gt; will lead you to the app in development mode.

Limitations:

- Local installation does not support sending emails, thus disabling functionalities such as password recovery and email notifications.

## Run in development mode

Development mode allows for live reloading and a smoother development process.

```bash
cd dev/prod
rush validate
rushx dev-server
```

Then go to &lt;http://localhost:8080&gt;

Select &quot;Sign up&quot; on the right panel and click the &quot;Sign up with password&quot; link at the bottom. Enter the new user&#039;s credentials, then proceed to create a workspace for them.

## Update project structure and database

If the project&#039;s structure is updated, it may be necessary to relink and rebuild the projects.

```bash
rush update
rush build
```

## Troubleshooting

If a build fails, but the code is correct, try to delete the [build cache](https://rushjs.io/pages/maintainer/build_cache/) and retry.

```bash
# from the project root
rm -rf common/temp/build-cache
```

## Build &amp; Watch

For development purpose `rush build:watch` action could be used.

It includes build and validate phases in watch mode.

## Tests

### Unit tests

```bash
rush test # To execute all tests

rushx test # For individual test execution inside a package directory
```

### UI tests

```bash
cd ./tests
rush build
rush bundle
rush docker:build
## creates test Docker containers and sets up test database
./prepare.sh
## runs UI tests
rushx uitest
```

To execute tests in the development environment, please follow these steps:

```bash
cd ./tests
./create-local.sh ## use ./restore-local.sh if you only want to restore the workspace to a predefined initial state for sanity.
cd ./sanity
rushx dev-uitest # To execute all tests against the development environment.
rushx dev-debug -g &#039;pattern&#039; # To execute tests in debug mode with only the matching test pattern.
```

## Package publishing

```bash
node ./common/scripts/bump.js -p projectName
```

## Additional testing

This project is tested with BrowserStack.

## WSL build guide

This guide describes the nuances of building and running the application from source code located on your NTFS drive, which is accessible from both Windows and WSL.

### Prerequisites

#### Disk Space Requirements

Ensure you have sufficient disk space available:
- A fully deployed local application in clean Docker will consume slightly more than **35 GB** of WSL virtual disk space
- The application folder after build (sources + artifacts) will occupy **4.5 GB**

If there&#039;s insufficient space on your system drive (usually `C:\`), you can change the virtual disk location in Docker Settings ‚Üí Resources ‚Üí Advanced.

#### Docker WSL Integration

Make sure Docker is accessible from WSL:

1. Go to Docker Settings ‚Üí Resources ‚Üí Advanced ‚Üí WSL Integration
2. Select the distribution where you&#039;ll be building and running the application
3. Verify integration works by running this command in WSL:
   ```bash
   docker run hello-world
   ```

### Common Issues and Solutions

#### Git Line Endings on Windows

Windows Git often automatically replaces line endings. Since most build scripts are `.sh` files, ensure your Windows checkout doesn&#039;t break them.

**Solution options:**
- Checkout from WSL instead of Windows
- Configure Git on Windows to disable auto-replacement:
  ```bash
  git config --global core.autocrlf false
  ```
  This disables auto-replacement for all repositories on your machine.

#### Elevated Privileges in WSL

Some commands in the instructions require elevated privileges when working in WSL. If you&#039;re using Ubuntu distribution, prefix commands with `sudo`:

```bash
sudo npm install -g @microsoft/rush
```

#### WSL Configuration

If the source code is located on a Windows NTFS drive, then edit the `/etc/wsl.conf` file in WSL (e.g., `sudo nano /etc/wsl.conf`) and add the following content if it doesn&#039;t exist:

```ini
[automount]
enabled = true
root = /mnt/
options = &quot;metadata,umask=22,fmask=11&quot;

[interop]
appendWindowsPath = false
```

However, we recommend storing the repository on a WSL disk, as this dramatically improves build and maintenance operations.

### Running the Application

After these preparations, the build instructions should work without issues.

#### Port Conflicts

When starting the application (`rush docker:up`), some network ports in Windows might be occupied. You can fix port mapping in the `\dev\docker-compose.yaml` file.

**Important:** Depending on which port you change, you&#039;ll need to:
1. Find what&#039;s using that port
2. Update the new address in the corresponding service configuration

&lt;sub&gt;&lt;sup&gt;&amp;copy; 2025 &lt;a href=&quot;https://hardcoreeng.com&quot;&gt;Hardcore Engineering Inc&lt;/a&gt;.&lt;/sup&gt;&lt;/sub&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[YishenTu/claudian]]></title>
            <link>https://github.com/YishenTu/claudian</link>
            <guid>https://github.com/YishenTu/claudian</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:38 GMT</pubDate>
            <description><![CDATA[An Obsidian plugin that embeds Claude Code as an AI collaborator in your vault]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/YishenTu/claudian">YishenTu/claudian</a></h1>
            <p>An Obsidian plugin that embeds Claude Code as an AI collaborator in your vault</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,024</p>
            <p>Forks: 196</p>
            <p>Stars today: 64 stars today</p>
            <h2>README</h2><pre># Claudian

![GitHub stars](https://img.shields.io/github/stars/YishenTu/claudian?style=social)
![GitHub release](https://img.shields.io/github/v/release/YishenTu/claudian)
![License](https://img.shields.io/github/license/YishenTu/claudian)

![Preview](Preview.png)

An Obsidian plugin that embeds Claude Code as an AI collaborator in your vault. Your vault becomes Claude&#039;s working directory, giving it full agentic capabilities: file read/write, search, bash commands, and multi-step workflows.

## Features

- **Full Agentic Capabilities**: Leverage Claude Code&#039;s power to read, write, and edit files, search, and execute bash commands, all within your Obsidian vault.
- **Context-Aware**: Automatically attach the focused note, mention files with `@`, exclude notes by tag, include editor selection (Highlight), and access external directories for additional context.
- **Vision Support**: Analyze images by sending them via drag-and-drop, paste, or file path.
- **Inline Edit**: Edit selected text or insert content at cursor position directly in notes with word-level diff preview and read-only tool access for context.
- **Instruction Mode (`#`)**: Add refined custom instructions to your system prompt directly from the chat input, with review/edit in a modal.
- **Slash Commands**: Create reusable prompt templates triggered by `/command`, with argument placeholders, `@file` references, and optional inline bash substitutions.
- **Skills**: Extend Claudian with reusable capability modules that are automatically invoked based on context, compatible with Claude Code&#039;s skill format.
- **Custom Agents**: Define custom subagents that Claude can invoke, with support for tool restrictions and model overrides.
- **Claude Code Plugins**: Enable Claude Code plugins installed via the CLI, with automatic discovery from `~/.claude/plugins` and per-vault configuration. Plugin skills, agents, and slash commands integrate seamlessly.
- **MCP Support**: Connect external tools and data sources via Model Context Protocol servers (stdio, SSE, HTTP) with context-saving mode and `@`-mention activation.
- **Advanced Model Control**: Select between Haiku, Sonnet, and Opus, configure custom models via environment variables, fine-tune thinking budget, and enable Sonnet with 1M context window (requires Max subscription).
- **Plan Mode**: Toggle plan mode via Shift+Tab in the chat input. Claudian explores and designs before implementing, presenting a plan for approval with options to approve in a new session, continue in the current session, or provide feedback.
- **Security**: Permission modes (YOLO/Safe/Plan), safety blocklist, and vault confinement with symlink-safe checks.
- **Claude in Chrome**: Allow Claude to interact with Chrome through the `claude-in-chrome` extension.

## Requirements

- [Claude Code CLI](https://code.claude.com/docs/en/overview) installed (strongly recommend install Claude Code via Native Install)
- Obsidian v1.8.9+
- Claude subscription/API or Custom model provider that supports Anthropic API format ([Openrouter](https://openrouter.ai/docs/guides/guides/claude-code-integration), [Kimi](https://platform.moonshot.ai/docs/guide/agent-support), [GLM](https://docs.z.ai/devpack/tool/claude), [DeepSeek](https://api-docs.deepseek.com/guides/anthropic_api), etc.)
- Desktop only (macOS, Linux, Windows)

## Installation

### From GitHub Release (recommended)

1. Download `main.js`, `manifest.json`, and `styles.css` from the [latest release](https://github.com/YishenTu/claudian/releases/latest)
2. Create a folder called `claudian` in your vault&#039;s plugins folder:
   ```
   /path/to/vault/.obsidian/plugins/claudian/
   ```
3. Copy the downloaded files into the `claudian` folder
4. Enable the plugin in Obsidian:
   - Settings ‚Üí Community plugins ‚Üí Enable &quot;Claudian&quot;

### Using BRAT

[BRAT](https://github.com/TfTHacker/obsidian42-brat) (Beta Reviewers Auto-update Tester) allows you to install and automatically update plugins directly from GitHub.

1. Install the BRAT plugin from Obsidian Community Plugins
2. Enable BRAT in Settings ‚Üí Community plugins
3. Open BRAT settings and click &quot;Add Beta plugin&quot;
4. Enter the repository URL: `https://github.com/YishenTu/claudian`
5. Click &quot;Add Plugin&quot; and BRAT will install Claudian automatically
6. Enable Claudian in Settings ‚Üí Community plugins

&gt; **Tip**: BRAT will automatically check for updates and notify you when a new version is available.

### From source (development)

1. Clone this repository into your vault&#039;s plugins folder:
   ```bash
   cd /path/to/vault/.obsidian/plugins
   git clone https://github.com/YishenTu/claudian.git
   cd claudian
   ```

2. Install dependencies and build:
   ```bash
   npm install
   npm run build
   ```

3. Enable the plugin in Obsidian:
   - Settings ‚Üí Community plugins ‚Üí Enable &quot;Claudian&quot;

### Development

```bash
# Watch mode
npm run dev

# Production build
npm run build
```

&gt; **Tip**: Copy `.env.local.example` to `.env.local` or `npm install` and setup your vault path to auto-copy files during development.

## Usage

**Two modes:**
1. Click the bot icon in ribbon or use command palette to open chat
2. Select text + hotkey for inline edit

Use it like Claude Code‚Äîread, write, edit, search files in your vault.

### Context

- **File**: Auto-attaches focused note; type `@` to attach other files
- **@-mention dropdown**: Type `@` to see MCP servers, agents, external contexts, and vault files
  - `@Agents/` shows custom agents for selection
  - `@mcp-server` enables context-saving MCP servers
  - `@folder/` filters to files from that external context (e.g., `@workspace/`)
  - Vault files shown by default
- **Selection**: Select text in editor, then chat‚Äîselection included automatically
- **Images**: Drag-drop, paste, or type path; configure media folder for `![[image]]` embeds
- **External contexts**: Click folder icon in toolbar for access to directories outside vault

### Features

- **Inline Edit**: Select text + hotkey to edit directly in notes with word-level diff preview
- **Instruction Mode**: Type `#` to add refined instructions to system prompt
- **Slash Commands**: Type `/` for custom prompt templates or skills
- **Skills**: Add `skill/SKILL.md` files to `~/.claude/skills/` or `{vault}/.claude/skills/`, recommended to use Claude Code to manage skills
- **Custom Agents**: Add `agent.md` files to `~/.claude/agents/` (global) or `{vault}/.claude/agents/` (vault-specific); select via `@Agents/` in chat, or prompt Claudian to invoke agents
- **Claude Code Plugins**: Enable plugins via Settings ‚Üí Claude Code Plugins, recommended to use Claude Code to manage plugins
- **MCP**: Add external tools via Settings ‚Üí MCP Servers; use `@mcp-server` in chat to activate

## Configuration

### Settings

**Customization**
- **User name**: Your name for personalized greetings
- **Excluded tags**: Tags that prevent notes from auto-loading (e.g., `sensitive`, `private`)
- **Media folder**: Configure where vault stores attachments for embedded image support (e.g., `attachments`)
- **Custom system prompt**: Additional instructions appended to the default system prompt (Instruction Mode `#` saves here)
- **Enable auto-scroll**: Toggle automatic scrolling to bottom during streaming (default: on)
- **Auto-generate conversation titles**: Toggle AI-powered title generation after the first user message is sent
- **Title generation model**: Model used for auto-generating conversation titles (default: Auto/Haiku)
- **Vim-style navigation mappings**: Configure key bindings with lines like `map w scrollUp`, `map s scrollDown`, `map i focusInput`

**Hotkeys**
- **Inline edit hotkey**: Hotkey to trigger inline edit on selected text
- **Open chat hotkey**: Hotkey to open the chat sidebar

**Slash Commands**
- Create/edit/import/export custom `/commands` (optionally override model and allowed tools)

**MCP Servers**
- Add/edit/verify/delete MCP server configurations with context-saving mode

**Claude Code Plugins**
- Enable/disable Claude Code plugins discovered from `~/.claude/plugins`
- User-scoped plugins available in all vaults; project-scoped plugins only in matching vault

**Safety**
- **Load user Claude settings**: Load `~/.claude/settings.json` (user&#039;s Claude Code permission rules may bypass Safe mode)
- **Enable command blocklist**: Block dangerous bash commands (default: on)
- **Blocked commands**: Patterns to block (supports regex, platform-specific)
- **Allowed export paths**: Paths outside the vault where files can be exported (default: `~/Desktop`, `~/Downloads`). Supports `~`, `$VAR`, `${VAR}`, and `%VAR%` (Windows).

**Environment**
- **Custom variables**: Environment variables for Claude SDK (KEY=VALUE format, supports `export ` prefix)
- **Environment snippets**: Save and restore environment variable configurations

**Advanced**
- **Claude CLI path**: Custom path to Claude Code CLI (leave empty for auto-detection)

## Safety and Permissions

| Scope | Access |
|-------|--------|
| **Vault** | Full read/write (symlink-safe via `realpath`) |
| **Export paths** | Write-only (e.g., `~/Desktop`, `~/Downloads`) |
| **External contexts** | Full read/write (session-only, added via folder icon) |

- **YOLO mode**: No approval prompts; all tool calls execute automatically (default)
- **Safe mode**: Approval prompt per tool call; Bash requires exact match, file tools allow prefix match
- **Plan mode**: Explores and designs a plan before implementing. Toggle via Shift+Tab in the chat input

## Privacy &amp; Data Use

- **Sent to API**: Your input, attached files, images, and tool call outputs. Default: Anthropic; custom endpoint via `ANTHROPIC_BASE_URL`.
- **Local storage**: Settings, session metadata, and commands stored in `vault/.claude/`; session messages in `~/.claude/projects/` (SDK-native); legacy sessions in `vault/.claude/sessions/`.
- **No telemetry**: No tracking beyond your configured API provider.

## Troubleshooting

### Claude CLI not found

If you encounter `spawn claude ENOENT` or `Claude CLI not found`, the plugin can&#039;t auto-detect your Claude installation. Common with Node version managers (nvm, fnm, volta).

**Solution**: Find your CLI path and set it in Settings ‚Üí Advanced ‚Üí Claude CLI path.

| Platform | Command | Example Path |
|----------|---------|--------------|
| macOS/Linux | `which claude` | `/Users/you/.volta/bin/claude` |
| Windows (native) | `where.exe claude` | `C:\Users\you\AppData\Local\Claude\claude.exe` |
| Windows (npm) | `npm root -g` | `{root}\@anthropic-ai\claude-code\cli.js` |

&gt; **Note**: On Windows, avoid `.cmd` wrappers. Use `claude.exe` or `cli.js`.

**Alternative**: Add your Node.js bin directory to PATH in Settings ‚Üí Environment ‚Üí Custom variables.

### npm CLI and Node.js not in same directory

If using npm-installed CLI, check if `claude` and `node` are in the same directory:
```bash
dirname $(which claude)
dirname $(which node)
```

If different, GUI apps like Obsidian may not find Node.js.

**Solutions**:
1. Install native binary (recommended)
2. Add Node.js path to Settings ‚Üí Environment: `PATH=/path/to/node/bin`

**Still having issues?** [Open a GitHub issue](https://github.com/YishenTu/claudian/issues) with your platform, CLI path, and error message.

## Architecture

```
src/
‚îú‚îÄ‚îÄ main.ts                      # Plugin entry point
‚îú‚îÄ‚îÄ core/                        # Core infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ agent/                   # Claude Agent SDK wrapper (ClaudianService)
‚îÇ   ‚îú‚îÄ‚îÄ agents/                  # Custom agent management (AgentManager)
‚îÇ   ‚îú‚îÄ‚îÄ commands/                # Slash command management (SlashCommandManager)
‚îÇ   ‚îú‚îÄ‚îÄ hooks/                   # PreToolUse/PostToolUse hooks
‚îÇ   ‚îú‚îÄ‚îÄ images/                  # Image caching and loading
‚îÇ   ‚îú‚îÄ‚îÄ mcp/                     # MCP server config, service, and testing
‚îÇ   ‚îú‚îÄ‚îÄ plugins/                 # Claude Code plugin discovery and management
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                 # System prompts for agents
‚îÇ   ‚îú‚îÄ‚îÄ sdk/                     # SDK message transformation
‚îÇ   ‚îú‚îÄ‚îÄ security/                # Approval, blocklist, path validation
‚îÇ   ‚îú‚îÄ‚îÄ storage/                 # Distributed storage system
‚îÇ   ‚îú‚îÄ‚îÄ tools/                   # Tool constants and utilities
‚îÇ   ‚îî‚îÄ‚îÄ types/                   # Type definitions
‚îú‚îÄ‚îÄ features/                    # Feature modules
‚îÇ   ‚îú‚îÄ‚îÄ chat/                    # Main chat view + UI, rendering, controllers, tabs
‚îÇ   ‚îú‚îÄ‚îÄ inline-edit/             # Inline edit service + UI
‚îÇ   ‚îî‚îÄ‚îÄ settings/                # Settings tab UI
‚îú‚îÄ‚îÄ shared/                      # Shared UI components and modals
‚îÇ   ‚îú‚îÄ‚îÄ components/              # Input toolbar bits, dropdowns, selection highlight
‚îÇ   ‚îú‚îÄ‚îÄ mention/                 # @-mention dropdown controller
‚îÇ   ‚îú‚îÄ‚îÄ modals/                  # Instruction modal
‚îÇ   ‚îî‚îÄ‚îÄ icons.ts                 # Shared SVG icons
‚îú‚îÄ‚îÄ i18n/                        # Internationalization (10 locales)
‚îú‚îÄ‚îÄ utils/                       # Modular utility functions
‚îî‚îÄ‚îÄ style/                       # Modular CSS (‚Üí styles.css)
```

## Roadmap

- [x] Claude Code Plugin support
- [x] Custom agent (subagent) support
- [x] Claude in Chrome support
- [x] `/compact` command
- [x] Plan mode
- [x] `rewind` and `fork` support (including `/fork` command)
- [x] `!command` support
- [ ] Tool renderers refinement
- [ ] Hooks and other advanced features
- [ ] More to come!

## License

Licensed under the [MIT License](LICENSE).

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=YishenTu/claudian&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#YishenTu/claudian&amp;type=date&amp;legend=top-left)

## Acknowledgments

- [Obsidian](https://obsidian.md) for the plugin API
- [Anthropic](https://anthropic.com) for Claude and the [Claude Agent SDK](https://platform.claude.com/docs/en/agent-sdk/overview)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[iOfficeAI/AionUi]]></title>
            <link>https://github.com/iOfficeAI/AionUi</link>
            <guid>https://github.com/iOfficeAI/AionUi</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:37 GMT</pubDate>
            <description><![CDATA[Free, local, open-source 24/7 Cowork app and OpenClaw for Gemini CLI, Claude Code, Codex, OpenCode, Qwen Code, Goose CLI, Auggie, and more | üåü Star if you like it!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/iOfficeAI/AionUi">iOfficeAI/AionUi</a></h1>
            <p>Free, local, open-source 24/7 Cowork app and OpenClaw for Gemini CLI, Claude Code, Codex, OpenCode, Qwen Code, Goose CLI, Auggie, and more | üåü Star if you like it!</p>
            <p>Language: TypeScript</p>
            <p>Stars: 17,523</p>
            <p>Forks: 1,342</p>
            <p>Stars today: 132 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[CherryHQ/cherry-studio]]></title>
            <link>https://github.com/CherryHQ/cherry-studio</link>
            <guid>https://github.com/CherryHQ/cherry-studio</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:36 GMT</pubDate>
            <description><![CDATA[AI productivity studio with smart chat, autonomous agents, and 300+ assistants. Unified access to frontier LLMs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/CherryHQ/cherry-studio">CherryHQ/cherry-studio</a></h1>
            <p>AI productivity studio with smart chat, autonomous agents, and 300+ assistants. Unified access to frontier LLMs</p>
            <p>Language: TypeScript</p>
            <p>Stars: 40,463</p>
            <p>Forks: 3,734</p>
            <p>Stars today: 51 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;right&quot; &gt;
  &lt;details&gt;
    &lt;summary &gt;üåê Language&lt;/summary&gt;
    &lt;div&gt;
      &lt;div align=&quot;right&quot;&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=en&quot;&gt;English&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=zh-CN&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=zh-TW&quot;&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=ja&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=ko&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=hi&quot;&gt;‡§π‡§ø‡§®‡•ç‡§¶‡•Ä&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=th&quot;&gt;‡πÑ‡∏ó‡∏¢&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=fr&quot;&gt;Fran√ßais&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=de&quot;&gt;Deutsch&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=es&quot;&gt;Espa√±ol&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=it&quot;&gt;Italiano&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=ru&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=pt&quot;&gt;Portugu√™s&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=nl&quot;&gt;Nederlands&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=pl&quot;&gt;Polski&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=ar&quot;&gt;ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=fa&quot;&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=tr&quot;&gt;T√ºrk√ße&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=vi&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=id&quot;&gt;Bahasa Indonesia&lt;/a&gt;&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/details&gt;
&lt;/div&gt;

&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/CherryHQ/cherry-studio/releases&quot;&gt;
    &lt;img src=&quot;https://github.com/CherryHQ/cherry-studio/blob/main/build/icon.png?raw=true&quot; width=&quot;150&quot; height=&quot;150&quot; alt=&quot;banner&quot; /&gt;&lt;br&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;English | &lt;a href=&quot;./docs/zh/README.md&quot;&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href=&quot;https://cherry-ai.com&quot;&gt;Official Site&lt;/a&gt; | &lt;a href=&quot;https://docs.cherry-ai.com/docs/en-us&quot;&gt;Documents&lt;/a&gt; | &lt;a href=&quot;./docs/en/guides/development.md&quot;&gt;Development&lt;/a&gt; | &lt;a href=&quot;https://github.com/CherryHQ/cherry-studio/issues&quot;&gt;Feedback&lt;/a&gt;&lt;br&gt;&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![][deepwiki-shield]][deepwiki-link]
[![][twitter-shield]][twitter-link]
[![][discord-shield]][discord-link]
[![][telegram-shield]][telegram-link]

&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;

[![][github-release-shield]][github-release-link]
[![][github-nightly-shield]][github-nightly-link]
[![][github-contributors-shield]][github-contributors-link]
[![][license-shield]][license-link]
[![][commercial-shield]][commercial-link]
[![][sponsor-shield]][sponsor-link]

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
 &lt;a href=&quot;https://hellogithub.com/repository/1605492e1e2a4df3be07abfa4578dd37&quot; target=&quot;_blank&quot; style=&quot;text-decoration: none&quot;&gt;&lt;img src=&quot;https://api.hellogithub.com/v1/widgets/recommend.svg?rid=1605492e1e2a4df3be07abfa4578dd37&quot; alt=&quot;FeaturedÔΩúHelloGitHub&quot;  width=&quot;220&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;
 &lt;a href=&quot;https://trendshift.io/repositories/14318&quot; target=&quot;_blank&quot; style=&quot;text-decoration: none&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14318&quot; alt=&quot;CherryHQ%2Fcherry-studio | Trendshift&quot; width=&quot;220&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;
 &lt;a href=&quot;https://www.producthunt.com/posts/cherry-studio?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-cherry&amp;#0045;studio&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=496640&amp;theme=light&quot; alt=&quot;Cherry&amp;#0032;Studio - AI&amp;#0032;Chatbots&amp;#0044;&amp;#0032;AI&amp;#0032;Desktop&amp;#0032;Client | Product Hunt&quot; width=&quot;220&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

# üçí Cherry Studio

Cherry Studio is a desktop client that supports multiple LLM providers, available on Windows, Mac and Linux.

üëè Join [Telegram Group](https://t.me/CherryStudioAI)ÔΩú[Discord](https://discord.gg/wez8HtpxqQ) | [QQ Group(575014769)](https://qm.qq.com/q/lo0D4qVZKi)

‚ù§Ô∏è Like Cherry Studio? Give it a star üåü or [Sponsor](docs/zh/guides/sponsor.md) to support the development!

# üå† Screenshot

![](https://github.com/user-attachments/assets/36dddb2c-e0fb-4a5f-9411-91447bab6e18)

![](https://github.com/user-attachments/assets/f549e8a0-2385-40b4-b52b-2039e39f2930)

![](https://github.com/user-attachments/assets/58e0237c-4d36-40de-b428-53051d982026)

# üåü Key Features

1. **Diverse LLM Provider Support**:

- ‚òÅÔ∏è Major LLM Cloud Services: OpenAI, Gemini, Anthropic, and more
- üîó AI Web Service Integration: Claude, Perplexity, [Poe](https://poe.com/), and others
- üíª Local Model Support with Ollama, LM Studio

2. **AI Assistants &amp; Conversations**:

- üìö 300+ Pre-configured AI Assistants
- ü§ñ Custom Assistant Creation
- üí¨ Multi-model Simultaneous Conversations

3. **Document &amp; Data Processing**:

- üìÑ Supports Text, Images, Office, PDF, and more
- ‚òÅÔ∏è WebDAV File Management and Backup
- üìä Mermaid Chart Visualization
- üíª Code Syntax Highlighting

4. **Practical Tools Integration**:

- üîç Global Search Functionality
- üìù Topic Management System
- üî§ AI-powered Translation
- üéØ Drag-and-drop Sorting
- üîå Mini Program Support
- ‚öôÔ∏è MCP(Model Context Protocol) Server

5. **Enhanced User Experience**:

- üñ•Ô∏è Cross-platform Support for Windows, Mac, and Linux
- üì¶ Ready to Use - No Environment Setup Required
- üé® Light/Dark Themes and Transparent Window
- üìù Complete Markdown Rendering
- ü§≤ Easy Content Sharing

# üìù Roadmap

We&#039;re actively working on the following features and improvements:

1. üéØ **Core Features**

- Selection Assistant with smart content selection enhancement
- Deep Research with advanced research capabilities
- Memory System with global context awareness
- Document Preprocessing with improved document handling
- MCP Marketplace for Model Context Protocol ecosystem

2. üóÇ **Knowledge Management**

- Notes and Collections
- Dynamic Canvas visualization
- OCR capabilities
- TTS (Text-to-Speech) support

3. üì± **Platform Support**

- HarmonyOS Edition (PC)
- Android App (Phase 1)
- iOS App (Phase 1)
- Multi-Window support
- Window Pinning functionality
- Intel AI PC (Core Ultra) Support

4. üîå **Advanced Features**

- Plugin System
- ASR (Automatic Speech Recognition)
- Assistant and Topic Interaction Refactoring

Track our progress and contribute on our [project board](https://github.com/orgs/CherryHQ/projects/7).

Want to influence our roadmap? Join our [GitHub Discussions](https://github.com/CherryHQ/cherry-studio/discussions) to share your ideas and feedback!

# üåà Theme

- Theme Gallery: &lt;https://cherrycss.com&gt;
- Aero Theme: &lt;https://github.com/hakadao/CherryStudio-Aero&gt;
- PaperMaterial Theme: &lt;https://github.com/rainoffallingstar/CherryStudio-PaperMaterial&gt;
- Claude dynamic-style: &lt;https://github.com/bjl101501/CherryStudio-Claudestyle-dynamic&gt;
- Maple Neon Theme: &lt;https://github.com/BoningtonChen/CherryStudio_themes&gt;

Welcome PR for more themes

# ü§ù Contributing

We welcome contributions to Cherry Studio! Here are some ways you can contribute:

1. **Contribute Code**: Develop new features or optimize existing code.
2. **Fix Bugs**: Submit fixes for any bugs you find.
3. **Maintain Issues**: Help manage GitHub issues.
4. **Product Design**: Participate in design discussions.
5. **Write Documentation**: Improve user manuals and guides.
6. **Community Engagement**: Join discussions and help users.
7. **Promote Usage**: Spread the word about Cherry Studio.

Refer to the [Branching Strategy](docs/en/guides/branching-strategy.md) for contribution guidelines

## Getting Started

1. **Fork the Repository**: Fork and clone it to your local machine.
2. **Create a Branch**: For your changes.
3. **Submit Changes**: Commit and push your changes.
4. **Open a Pull Request**: Describe your changes and reasons.

For more detailed guidelines, please refer to our [Contributing Guide](CONTRIBUTING.md).

Thank you for your support and contributions!

# üîß Developer Co-creation Program

We are launching the Cherry Studio Developer Co-creation Program to foster a healthy and positive-feedback loop within the open-source ecosystem. We believe that great software is built collaboratively, and every merged pull request breathes new life into the project.

We sincerely invite you to join our ranks of contributors and shape the future of Cherry Studio with us.

## Contributor Rewards Program

To give back to our core contributors and create a virtuous cycle, we have established the following long-term incentive plan.

**The inaugural tracking period for this program will be Q3 2025 (July, August, September). Rewards for this cycle will be distributed on October 1st.**

Within any tracking period (e.g., July 1st to September 30th for the first cycle), any developer who contributes more than **30 meaningful commits** to any of Cherry Studio&#039;s open-source projects on GitHub will be eligible for the following benefits:

- **Cursor Subscription Sponsorship**: Receive a **$70 USD** credit or reimbursement for your [Cursor](https://cursor.sh/) subscription, making AI your most efficient coding partner.
- **Unlimited Model Access**: Get **unlimited** API calls for the **DeepSeek** and **Qwen** models.
- **Cutting-Edge Tech Access**: Enjoy occasional perks, including API access to models like **Claude**, **Gemini**, and **OpenAI**, keeping you at the forefront of technology.

## Growing Together &amp; Future Plans

A vibrant community is the driving force behind any sustainable open-source project. As Cherry Studio grows, so will our rewards program. We are committed to continuously aligning our benefits with the best-in-class tools and resources in the industry. This ensures our core contributors receive meaningful support, creating a positive cycle where developers, the community, and the project grow together.

**Moving forward, the project will also embrace an increasingly open stance to give back to the entire open-source community.**

## How to Get Started?

We look forward to your first Pull Request!

You can start by exploring our repositories, picking up a `good first issue`, or proposing your own enhancements. Every commit is a testament to the spirit of open source.

Thank you for your interest and contributions.

Let&#039;s build together.

# üè¢ Enterprise Edition

Building on the Community Edition, we are proud to introduce **Cherry Studio Enterprise Edition**‚Äîa privately-deployable AI productivity and management platform designed for modern teams and enterprises.

The Enterprise Edition addresses core challenges in team collaboration by centralizing the management of AI resources, knowledge, and data. It empowers organizations to enhance efficiency, foster innovation, and ensure compliance, all while maintaining 100% control over their data in a secure environment.

## Core Advantages

- **Unified Model Management**: Centrally integrate and manage various cloud-based LLMs (e.g., OpenAI, Anthropic, Google Gemini) and locally deployed private models. Employees can use them out-of-the-box without individual configuration.
- **Enterprise-Grade Knowledge Base**: Build, manage, and share team-wide knowledge bases. Ensures knowledge retention and consistency, enabling team members to interact with AI based on unified and accurate information.
- **Fine-Grained Access Control**: Easily manage employee accounts and assign role-based permissions for different models, knowledge bases, and features through a unified admin backend.
- **Fully Private Deployment**: Deploy the entire backend service on your on-premises servers or private cloud, ensuring your data remains 100% private and under your control to meet the strictest security and compliance standards.
- **Reliable Backend Services**: Provides stable API services and enterprise-grade data backup and recovery mechanisms to ensure business continuity.

## ‚ú® Online Demo

**üîó [Cherry Studio Enterprise](https://enterprise.cherry-ai.com)**

## Version Comparison

| Feature           | Community Edition                                                                    | Enterprise Edition                                                                                                                      |
| :---------------- | :----------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------- |
| **Open Source**   | ‚úÖ Yes                                                                               | ‚≠ïÔ∏è Partially released to customers                                                                                                      |
| **Cost**          | [AGPL-3.0 License](https://github.com/CherryHQ/cherry-studio?tab=AGPL-3.0-1-ov-file) | Buyout / Subscription Fee                                                                                                               |
| **Admin Backend** | ‚Äî                                                                                    | ‚óè Centralized **Model** Access&lt;br&gt;‚óè **Employee** Management&lt;br&gt;‚óè Shared **Knowledge Base**&lt;br&gt;‚óè **Access** Control&lt;br&gt;‚óè **Data** Backup |
| **Server**        | ‚Äî                                                                                    | ‚úÖ Dedicated Private Deployment                                                                                                         |

## Get the Enterprise Edition

We believe the Enterprise Edition will become your team&#039;s AI productivity engine. If you are interested in Cherry Studio Enterprise Edition and would like to learn more, request a quote, or schedule a demo, please feel free to contact us.

- **For Business Inquiries &amp; Purchasing**:
  **üìß [bd@cherry-ai.com](mailto:bd@cherry-ai.com)**

# üîó Related Projects

- [new-api](https://github.com/QuantumNous/new-api): The next-generation LLM gateway and AI asset management system supports multiple languages.

- [one-api](https://github.com/songquanpeng/one-api): LLM API management and distribution system supporting mainstream models like OpenAI, Azure, and Anthropic. Features a unified API interface, suitable for key management and secondary distribution.

- [Poe](https://poe.com/): Poe gives you access to the best AI, all in one place. Explore GPT-5, Claude Opus 4.1, DeepSeek-R1, Veo 3, ElevenLabs, and millions of others.

- [ublacklist](https://github.com/iorate/ublacklist): Blocks specific sites from appearing in Google search results

# üöÄ Contributors

&lt;a href=&quot;https://github.com/CherryHQ/cherry-studio/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=CherryHQ/cherry-studio&quot; /&gt;
&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;

# üìä GitHub Stats

![Stats](https://repobeats.axiom.co/api/embed/a693f2e5f773eed620f70031e974552156c7f397.svg &quot;Repobeats analytics image&quot;)

# ‚≠êÔ∏è Star History

&lt;a href=&quot;https://www.star-history.com/#CherryHQ/cherry-studio&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=CherryHQ/cherry-studio&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=CherryHQ/cherry-studio&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=CherryHQ/cherry-studio&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

# üìú License

The Cherry Studio Community Edition is governed by the standard GNU Affero General Public License v3.0 (AGPL-3.0), available at https://www.gnu.org/licenses/agpl-3.0.html.

Use of the Cherry Studio Community Edition for commercial purposes is permitted, subject to full compliance with the terms and conditions of the AGPL-3.0 license.

Should you require a commercial license that provides an exemption from the AGPL-3.0 requirements, please contact us at bd@cherry-ai.com.

&lt;!-- Links &amp; Images --&gt;

[deepwiki-shield]: https://img.shields.io/badge/Deepwiki-CherryHQ-0088CC?logo=data:image/svg+xml;base64,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

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[mnfst/manifest]]></title>
            <link>https://github.com/mnfst/manifest</link>
            <guid>https://github.com/mnfst/manifest</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:35 GMT</pubDate>
            <description><![CDATA[Smart LLM routing for OpenClaw. Cut Costs up to 70%]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mnfst/manifest">mnfst/manifest</a></h1>
            <p>Smart LLM routing for OpenClaw. Cut Costs up to 70%</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,453</p>
            <p>Forks: 165</p>
            <p>Stars today: 46 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;.github/assets/logo-white.svg&quot; /&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;.github/assets/logo-dark.svg&quot; /&gt;
    &lt;img src=&quot;.github/assets/logo-dark.svg&quot; alt=&quot;Manifest&quot; height=&quot;53&quot; title=&quot;Manifest&quot;/&gt;
  &lt;/picture&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    ü¶û Take control of your
OpenClaw costs
&lt;/p&gt;

![manifest-gh](https://github.com/user-attachments/assets/7dd74fc2-f7d6-4558-a95a-014ed754a125)

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/mnfst/manifest/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/mnfst/manifest?style=flat&quot; alt=&quot;GitHub stars&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.npmjs.com/package/manifest&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/manifest?color=cb3837&amp;label=npm&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.npmjs.com/package/manifest&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dw/manifest?color=cb3837&quot; alt=&quot;npm downloads&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://github.com/mnfst/manifest/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/mnfst/manifest/ci.yml?branch=main&amp;label=CI&quot; alt=&quot;CI status&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://app.codecov.io/gh/mnfst/manifest&quot;&gt;&lt;img src=&quot;https://img.shields.io/codecov/c/github/mnfst/manifest?label=coverage&quot; alt=&quot;Codecov&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/mnfst/manifest?color=blue&quot; alt=&quot;license&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://discord.gg/FepAked3W7&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&amp;logoColor=white&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

## What do you get?

- üîÄ **Routes every request to the right model** ‚Äî and cuts costs up to 70%
- üìä **Track your expenses** ‚Äî real-time dashboard that shows tokens and costs per model
- üîî **Set limits** ‚Äî set up alerts (soft or hard) if your consumption exceeds a certain volume

## Why Manifest

OpenClaw sends all your requests to the same model, which is not cost-effective since you summon big models for tiny tasks. Manifest solves it by redirecting queries to the most cost-effective model.

Manifest is an OpenClaw plugin that intercepts your query, passes it through a 23-dimension scoring algorithm in &lt;2ms and sends it to the most suitable model.

Unlike almost all alternatives, everything stays on your machine. No suspicious installer, no black box, no third party, no crypto.

## Quick Start

### Cloud vs Local

Manifest is available in cloud and local versions. While both versions install the same OpenClaw Plugin, the local version stores the telemetry data on your computer and the cloud version uses our secure platform.

#### Use cloud if
- You want a quick install
- You want to access the dashboard from different devices
- You want to connect multiple agents

#### Use local if
- You don&#039;t want the telemetry data to move from your computer
- You don‚Äôt need multi-device access
- You don&#039;t want to subscribe to a cloud service

If you don&#039;t know which version to chose, start with the **cloud version**.

### Cloud (default)

```bash
openclaw plugins install manifest
openclaw config set plugins.entries.manifest.config.apiKey &quot;mnfst_YOUR_KEY&quot;
openclaw gateway restart
```

Sign up at [app.manifest.build](https://app.manifest.build) to get your API key.

### Local

```bash
openclaw plugins install manifest
openclaw config set plugins.entries.manifest.config.mode local
openclaw gateway restart
```

Dashboard opens at **http://127.0.0.1:2099**. Telemetry from your agents flows in automatically.

## Features

- **LLM Router** ‚Äî scores each query and calls the most suitable model
- **Real-time dashboard** ‚Äî tokens, costs, messages, and model usage at a glance
- **No coding required** ‚Äî Simple install as OpenClaw plugin
- **OTLP-native** ‚Äî standard OpenTelemetry ingestion (traces, metrics, logs)

## Privacy by architecture

**In local mode, your data stays on your machine.** All agent messages, token counts, costs, and telemetry are stored locally. In cloud mode, only OpenTelemetry metadata (model, tokens, latency) is sent ‚Äî message content is never collected.

**In cloud mode, the blind proxy physically cannot read your prompts** This is fundamentally different from services saying &quot;trust us.&quot;

The only thing Manifest collects is anonymous product analytics (hashed machine ID, OS platform, package version, event names) to help improve the project. No personally identifiable information or agent data is included.

**Opting out:**

```bash
MANIFEST_TELEMETRY_OPTOUT=1
```

Or add `&quot;telemetryOptOut&quot;: true` to `~/.openclaw/manifest/config.json`.


## Manifest vs OpenRouter

|              | Manifest                                                   | OpenRouter                                                    |
| ------------ | ---------------------------------------------------------- | ------------------------------------------------------------- |
| Architecture | Runs locally ‚Äî data stays on your machine                  | Cloud proxy ‚Äî all traffic routes through their servers        |
| Cost         | Free                                                       | 5% fee on every API call                                      |
| Source code  | MIT licensed, fully open                                   | Proprietary                                                   |
| Data privacy | 100% local routing and logging                    | Your prompts and responses pass through a third party         |
| Transparency | Open scoring algorithm ‚Äî see exactly why a model is chosen | Black box routing, no visibility into how models are selected |

## Supported Providers

Manifest supports **300+ models** across all major LLM providers. Every provider supports smart routing, real-time cost tracking, and OTLP telemetry.

| Provider | Models |
|----------|--------|
| [OpenAI](https://platform.openai.com/) | `gpt-5.3`, `gpt-4.1`, `o3`, `o4-mini` + 54 more |
| [Anthropic](https://www.anthropic.com/) | `claude-opus-4-6`, `claude-sonnet-4.5`, `claude-haiku-4.5` + 14 more |
| [Google Gemini](https://ai.google.dev/) | `gemini-2.5-pro`, `gemini-2.5-flash`, `gemini-3-pro` + 19 more |
| [DeepSeek](https://www.deepseek.com/) | `deepseek-v3`, `deepseek-r1` + 11 more |
| [xAI](https://x.ai/) | `grok-4`, `grok-3`, `grok-3-mini` + 8 more |
| [Mistral AI](https://mistral.ai/) | `mistral-large`, `codestral`, `devstral` + 26 more |
| [Qwen (Alibaba)](https://www.alibabacloud.com/en/solutions/generative-ai/qwen) | `qwen3-235b`, `qwen3-coder`, `qwq-32b` + 42 more |
| [Kimi (Moonshot)](https://kimi.ai/) | `kimi-k2`, `kimi-k2.5` + 3 more |
| [Amazon Nova](https://aws.amazon.com/ai/nova/) | `nova-pro`, `nova-lite`, `nova-micro` + 5 more |
| [Zhipu AI](https://www.zhipuai.cn/) | `glm-5`, `glm-4.6`, `glm-4-plus` + 9 more |
| [OpenRouter](https://openrouter.ai/) | 300+ models from all providers |
| [Ollama](https://ollama.com/) | Run any model locally (Llama, Gemma, Mistral, ‚Ä¶) |

## Contributing

Manifest is open source under the [MIT license](LICENSE). See [CONTRIBUTING.md](CONTRIBUTING.md) for the development setup, architecture notes, and workflow. Join the conversation on [Discord](https://discord.gg/FepAked3W7).

&gt; **Want a hosted version instead?** Check out [app.manifest.build](https://app.manifest.build)

## Quick Links

- [GitHub](https://github.com/mnfst/manifest)
- [Docs](https://manifest.build/docs)
- [Discord](https://discord.com/invite/FepAked3W7)
- [Discussions](https://github.com/mnfst/manifest/discussions)

## License

[MIT](LICENSE)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lobehub/lobehub]]></title>
            <link>https://github.com/lobehub/lobehub</link>
            <guid>https://github.com/lobehub/lobehub</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:34 GMT</pubDate>
            <description><![CDATA[The ultimate space for work and life ‚Äî to find, build, and collaborate with agent teammates that grow with you. We are taking agent harness to the next level ‚Äî enabling multi-agent collaboration, effortless agent team design, and introducing agents as the unit of work interaction.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobehub">lobehub/lobehub</a></h1>
            <p>The ultimate space for work and life ‚Äî to find, build, and collaborate with agent teammates that grow with you. We are taking agent harness to the next level ‚Äî enabling multi-agent collaboration, effortless agent team design, and introducing agents as the unit of work interaction.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 72,841</p>
            <p>Forks: 14,695</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# LobeHub

LobeHub is the ultimate space for work and life: &lt;br/&gt;
to find, build, and collaborate with agent teammates that grow with you.&lt;br/&gt;
We‚Äôre building the world‚Äôs largest human‚Äìagent co-evolving network.

**English** ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md) ¬∑ [Official Site][official-site] ¬∑ [Changelog][changelog] ¬∑ [Documents][docs] ¬∑ [Blog][blog] ¬∑ [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeHub Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Agent teammates that grow with you&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url]

[![](https://vercel.com/oss/program-badge.svg)](https://vercel.com/oss)

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [üëãüèª Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [‚ú® Features](#-features)
  - [Create: Agents as the Unit of Work](#create-agents-as-the-unit-of-work)
  - [Collaborate: Scale New Forms of Collaboration Networks](#collaborate-scale-new-forms-of-collaboration-networks)
  - [Evolve: Co-evolution of Humans and Agents](#evolve-co-evolution-of-humans-and-agents)
  - [MCP Plugin One-Click Installation](#mcp-plugin-one-click-installation)
  - [MCP Marketplace](#mcp-marketplace)
  - [Desktop App](#desktop-app)
  - [Smart Internet Search](#smart-internet-search)
  - [Chain of Thought](#chain-of-thought)
  - [Branching Conversations](#branching-conversations)
  - [Artifacts Support](#artifacts-support)
  - [File Upload /Knowledge Base](#file-upload-knowledge-base)
  - [Multi-Model Service Provider Support](#multi-model-service-provider-support)
  - [Local Large Language Model (LLM) Support](#local-large-language-model-llm-support)
  - [Model Visual Recognition](#model-visual-recognition)
  - [TTS &amp; STT Voice Conversation](#tts--stt-voice-conversation)
  - [Text to Image Generation](#text-to-image-generation)
  - [Plugin System (Function Calling)](#plugin-system-function-calling)
  - [Agent Market (GPTs)](#agent-market-gpts)
  - [Support Local / Remote Database](#support-local--remote-database)
  - [Support Multi-User Management](#support-multi-user-management)
  - [Progressive Web App (PWA)](#progressive-web-app-pwa)
  - [Mobile Device Adaptation](#mobile-device-adaptation)
  - [Custom Themes](#custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [üõ≥ Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [üì¶ Ecosystem](#-ecosystem)
- [üß© Plugins](#-plugins)
- [‚å®Ô∏è Local Development](#Ô∏è-local-development)
- [ü§ù Contributing](#-contributing)
- [‚ù§Ô∏è Sponsor](#Ô∏è-sponsor)
- [üîó More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

&lt;br/&gt;

&lt;https://github.com/user-attachments/assets/6710ad97-03d0-4175-bd75-adff9b55eca2&gt;

## üëãüèª Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeHub is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![](https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=1065874&amp;theme=light&amp;t=1769347414733)](https://www.producthunt.com/products/lobehub?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_campaign=badge-lobehub) | We are live on Product Hunt! We are thrilled to bring LobeHub to the world. If you believe in a future where humans and agents co-evolve, please support our journey. |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link]                                                                                                                                                                                                         | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub.                                                    |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ ‚≠êÔ∏è

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## ‚ú® Features

Today‚Äôs agents are one-off, task-driven tools. They lack context, live in isolation, and require manual hand-offs between different windows and models. While some maintain memory, it is often global, shallow, and impersonal. In this mode, users are forced to toggle between fragmented conversations, making it difficult to form structured productivity.

**LobeHub changes everything.**

LobeHub is a work-and-lifestyle space to find, build, and collaborate with agent teammates that grow with you. In LobeHub, we treat **Agents as the unit of work**, providing an infrastructure where humans and agents co-evolve.

![](https://hub-apac-1.lobeobjects.space/blog/assets/2204cde2228fb3f583f3f2c090bc49fb.webp)

### Create: Agents as the Unit of Work

Building a personalized AI team starts with the **Agent Builder**. You can describe what you need once, and the agent setup starts right away, applying auto-configurations so you can use it instantly.

- **Unified Intelligence**: Seamlessly access any model and any modality‚Äîall under your control.
- **10,000+ Skills**: Connect your agents to the skills you use every day with a library of over 10,000 tools and MCP-compatible plugins.

[![][back-to-top]](#readme-top)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

![](https://hub-apac-1.lobeobjects.space/blog/assets/771ff3d30b9ef93e65e55021cc43d356.webp)

### Collaborate: Scale New Forms of Collaboration Networks

LobeHub introduces **Agent Groups**, allowing you to work with agents like real teammates. The system assembles the right agents for the task, enabling parallel collaboration and iterative improvement.

- **Pages**: Write and refine content with multiple agents in one place with a shared context.
- **Schedule**: Schedule runs and let agents do the work at the right time, even while you are away.
- **Project**: Organize work by project to keep everything structured and easy to track.
- **Workspace**: A shared space for teams to collaborate with agents, ensuring clear ownership and visibility across the organization.

[![][back-to-top]](#readme-top)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

![](https://hub-apac-1.lobeobjects.space/blog/assets/fe98eae9fcb6acc47c8e1fb69bdb4b50.webp)

### Evolve: Co-evolution of Humans and Agents

The best AI is one that understands you deeply. LobeHub features **Personal Memory** that builds a clear understanding of your needs.

- **Continual Learning**: Your agents learn from how you work, adapting their behavior to act at the right moment.
- **White-Box Memory**: We believe in transparency. Your agents use structured, editable memory, giving you full control over what they remember.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;More Features&lt;/summary&gt;

![][image-feat-mcp]

### MCP Plugin One-Click Installation

**Seamlessly Connect Your AI to the World**

Unlock the full potential of your AI by enabling smooth, secure, and dynamic interactions with external tools, data sources, and services. LobeHub&#039;s MCP (Model Context Protocol) plugin system breaks down the barriers between your AI and the digital ecosystem, allowing for unprecedented connectivity and functionality.

Transform your conversations into powerful workflows by connecting to databases, APIs, file systems, and more. Experience the freedom of AI that truly understands and interacts with your world.

[![][back-to-top]](#readme-top)

![][image-feat-mcp-market]

### MCP Marketplace

**Discover, Connect, Extend**

Browse a growing library of MCP plugins to expand your AI&#039;s capabilities and streamline your workflows effortlessly. Visit [lobehub.com/mcp](https://lobehub.com/mcp) to explore the MCP Marketplace, which offers a curated collection of integrations that enhance your AI&#039;s ability to work with various tools and services.

From productivity tools to development environments, discover new ways to extend your AI&#039;s reach and effectiveness. Connect with the community and find the perfect plugins for your specific needs.

[![][back-to-top]](#readme-top)

![][image-feat-desktop]

### Desktop App

**Peak Performance, Zero Distractions**

Get the full LobeHub experience without browser limitations‚Äîcomprehensive, focused, and always ready to go. Our desktop application provides a dedicated environment for your AI interactions, ensuring optimal performance and minimal distractions.

Experience faster response times, better resource management, and a more stable connection to your AI assistant. The desktop app is designed for users who demand the best performance from their AI tools.

[![][back-to-top]](#readme-top)

![][image-feat-web-search]

### Smart Internet Search

**Online Knowledge On Demand**

With real-time internet access, your AI keeps up with the world‚Äînews, data, trends, and more. Stay informed and get the most current information available, enabling your AI to provide accurate and up-to-date responses.

Access live information, verify facts, and explore current events without leaving your conversation. Your AI becomes a gateway to the world&#039;s knowledge, always current and comprehensive.

[![][back-to-top]](#readme-top)

[![][image-feat-cot]][docs-feat-cot]

### [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeHub. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeHub supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [üìò LobeHub Knowledge Base Launch ‚Äî From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeHub, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeHub can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+-10)&lt;/kbd&gt;&lt;/summary&gt;

&lt;/details&gt;

&gt; üìä Total providers: [&lt;kbd&gt;**0**&lt;/kbd&gt;](https://lobechat.com/discover/providers)

 &lt;!-- PROVIDER LIST --&gt;

At the same time, we are also planning to support more model service providers. If you would like LobeHub to support your favorite service provider, feel free to join our [üí¨ community discussion](https://github.com/lobehub/lobe-chat/discussions/1284).

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-local]][docs-feat-local]

### [Local Large Language Model (LLM) Support][docs-feat-local]

To meet the specific needs of users, LobeHub also supports the use of local models based on [Ollama](https://ollama.ai), allowing users to flexibly use their own or third-party models.

&gt; \[!TIP]
&gt;
&gt; Learn more about [üìò Using Ollama in LobeHub][docs-usage-ollama] by checking it out.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-vision]][docs-feat-vision]

### [Model Visual Recognition][docs-feat-vision]

LobeHub now supports OpenAI&#039;s latest [`gpt-4-vision`](https://platform.openai.com/docs/guides/vision) model with visual recognition capabilities,
a multimodal intelligence that can perceive visuals. Users can easily upload or drag and drop images into the dialogue box,
and the agent will be able to recognize the content of the images and engage in intelligent conversation based on this,
creating smarter and more diversified chat scenarios.

This feature opens up new interactive methods, allowing communication to transcend text and include a wealth of visual elements.
Whether it&#039;s sharing images in daily use or interpreting images within specific industries, the agent provides an outstanding conversational experience.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-tts]][docs-feat-tts]

### [TTS &amp; STT Voice Conversation][docs-feat-tts]

LobeHub supports Text-to-Speech (TTS) and Speech-to-Text (STT) technologies, enabling our application to convert text messages into clear voice outputs,
allowing users to interact with our conversational agent as if they were talking to a real person. Users can choose from a variety of voices to pair with the agent.

Moreover, TTS offers an excellent solution for those who prefer auditory learning or desire to receive information while busy.
In LobeHub, we have meticulously selected a range of high-quality voice options (OpenAI Audio, Microsoft Edge Speech) to meet the needs of users from different regions and cultural backgrounds.
Users can choose the voice that suits their personal preferences or specific scenarios, resulting in a personalized communication experience.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-t2i]][docs-feat-t2i]

### [Text to Image Generation][docs-feat-t2i]

With support for the latest text-to-image generation technology, LobeHub now allows users to invoke image creation tools directly within conversations with the agent. By leveraging the capabilities of AI tools such as [`DALL-E 3`](https://openai.com/dall-e-3), [`MidJourney`](https://www.midjourney.com/), and [`Pollinations`](https://pollinations.ai/), the agents are now equipped to transform your ideas into images.

This enables a more private and immersive creative process, allowing for the seamless integration of visual storytelling into your personal dialogue with the agent.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-plugin]][docs-feat-plugin]

### [Plugin System (Function Calling)][docs-feat-plugin]

The plugin ecosystem of LobeHub is an important extension of its core functionality, greatly enhancing the practicality and flexibility of the LobeHub assistant.

&lt;video controls src=&quot;https://github.com/lobehub/lobe-chat/assets/28616219/f29475a3-f346-4196-a435-41a6373ab9e2&quot; muted=&quot;false&quot;&gt;&lt;/video&gt;

By utilizing plugins, LobeHub assistants can obtain and process real-time information, such as searching for web information and providing users with instant and relevant news.

In addition, these plugins are not limited to news aggregation, but can also extend to other practical functions, such as quickly searching documents, generating images, obtaining data from various platforms like Bilibili, Steam, and interacting with various third-party services.

&gt; \[!TIP]
&gt;
&gt; Learn more about [üìò Plugin Usage][docs-usage-plugin] by checking it out.

&lt;!-- PLUGIN LIST --&gt;

| Recent Submits                                                                                                             | Description                                                                                                                                     |
| -------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>