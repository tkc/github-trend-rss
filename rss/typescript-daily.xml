<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Fri, 29 Aug 2025 00:04:56 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[Canner/WrenAI]]></title>
            <link>https://github.com/Canner/WrenAI</link>
            <guid>https://github.com/Canner/WrenAI</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[‚ö°Ô∏è GenBI (Generative BI) queries any database in natural language, generates accurate SQL (Text-to-SQL), charts (Text-to-Chart), and AI-powered insights in seconds.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Canner/WrenAI">Canner/WrenAI</a></h1>
            <p>‚ö°Ô∏è GenBI (Generative BI) queries any database in natural language, generates accurate SQL (Text-to-SQL), charts (Text-to-Chart), and AI-powered insights in seconds.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 10,286</p>
            <p>Forks: 1,054</p>
            <p>Stars today: 120 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot; id=&quot;top&quot;&gt;
  &lt;a href=&quot;https://getwren.ai/?utm_source=github&amp;utm_medium=title&amp;utm_campaign=readme&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./misc/wrenai_logo.png&quot;&gt;
      &lt;img src=&quot;./misc/wrenai_logo_white.png&quot; width=&quot;300px&quot;&gt;
    &lt;/picture&gt;
    &lt;h1 align=&quot;center&quot;&gt;Wren AI - Open-Source GenBI Agent&lt;/h1&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;Follow us on X&quot; href=&quot;https://x.com/getwrenai&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/badge/-@getwrenai-blue?style=for-the-badge&amp;logo=x&amp;logoColor=white&amp;labelColor=gray&amp;logoWidth=20&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Releases&quot; href=&quot;https://github.com/canner/WrenAI/releases&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/github/v/release/canner/WrenAI?logo=github&amp;label=GitHub%20Release&amp;color=blue&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;License&quot; href=&quot;https://github.com/Canner/WrenAI/blob/main/LICENSE&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/github/license/canner/WrenAI?color=blue&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://docs.getwren.ai&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/docs-online-brightgreen?style=for-the-badge&quot; alt=&quot;Docs&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Join the community on GitHub&quot; href=&quot;https://discord.gg/5DvshJqG8Z&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/badge/-JOIN%20THE%20COMMUNITY-blue?style=for-the-badge&amp;logo=discord&amp;logoColor=white&amp;labelColor=grey&amp;logoWidth=20&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Canner&quot; href=&quot;https://cannerdata.com/?utm_source=github&amp;utm_medium=badge&amp;utm_campaign=readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/%F0%9F%A7%A1-Made%20by%20Canner-blue?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/9263&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/9263&quot; alt=&quot;Canner%2FWrenAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; Wren AI is your GenBI Agent, that you can query any database with natural language ‚Üí get accurate SQL(Text-to-SQL), charts(Text-to-Charts) &amp; AI-generated insights in seconds. ‚ö°Ô∏è

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./misc/workflow.png&quot;&gt;
&lt;/p&gt;

## üòç Demos

https://github.com/user-attachments/assets/f9c1cb34-5a95-4580-8890-ec9644da4160

[Watch GenBI Demo](https://github.com/user-attachments/assets/90ad1d35-bb1e-490b-9676-b29863ff090b)

## ü§ñ Features

|                    | What you get | Why it matters |
|--------------------|--------------|----------------|
| **Talk to Your Data** | Ask in any language ‚Üí precise SQL &amp; answers | Slash the SQL learning curveÔªø |
| **GenBI Insights** | AI-written summaries, charts &amp; reports | Decision-ready context in one clickÔªø |
| **Semantic Layer** | MDL models encode schema, metrics, joins | Keeps LLM outputs accurate &amp; governedÔªø |
| **Embed via API**  | Generate queries &amp; charts inside your apps ([API Docs](https://wrenai.readme.io/reference/cloud-getting-started)) | Build custom agents, SaaS features, chatbotsÔªø ([Streamlit Live Demo](https://huggingface.co/spaces/getWrenAI/wrenai-cloud-api-demo)) |

ü§© [Learn more about GenBI](https://getwren.ai/genbi?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme)

## üöÄ Getting Started

Using Wren AI is super simple, you can set it up within 3 minutes, and start to interact with your data!

- Visit our [Install in your local environment](http://docs.getwren.ai/oss/installation?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme).
- Visit the [Usage Guides](https://docs.getwren.ai/oss/guide/connect/overview?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme) to learn more about how to use Wren AI.
- Or just start with [Wren AI Cloud](https://getwren.ai/?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme) our Managed Cloud Service. ([OSS vs. Commercial Plans](https://docs.getwren.ai/oss/overview/cloud_vs_self_host)).

## üèóÔ∏è Architecture

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./misc/how_wrenai_works.png&quot;&gt;
&lt;/p&gt;

üëâ [Learn more about our Design](https://getwren.ai/post/how-we-design-our-semantic-engine-for-llms-the-backbone-of-the-semantic-layer-for-llm-architecture?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme)


## üîå Data Sources

If your data source is not listed here, vote for it in our [GitHub discussion thread](https://github.com/Canner/WrenAI/discussions/327). It will be a valuable input for us to decide on the next supported data sources.
- Athena (Trino)
- Redshift
- BigQuery
- DuckDB
- PostgreSQL
- MySQL
- Microsoft SQL Server
- ClickHouse
- Oracle
- Trino
- Snowflake

## ü§ñ LLM Models

Wren AI supports integration with various Large Language Models (LLMs), including but not limited to:
- OpenAI Models
- Azure OpenAI Models
- DeepSeek Models
- Google AI Studio ‚Äì Gemini Models
- Vertex AI Models (Gemini + Anthropic)
- Bedrock Models
- Anthropic API Models
- Groq Models
- Ollama Models
- Databricks Models

Check [configuration examples here](https://github.com/Canner/WrenAI/tree/main/wren-ai-service/docs/config_examples)!

&gt; [!CAUTION]
&gt; The performance of Wren AI depends significantly on the capabilities of the LLM you choose. We strongly recommend using the most powerful model available for optimal results. Using less capable models may lead to reduced performance, slower response times, or inaccurate outputs.

## üìö Documentation

Visit [Wren AI documentation](https://docs.getwren.ai/oss/overview/introduction?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme) to view the full documentation.

## üì™ Keep Posted?

[Subscribe our blog](https://www.getwren.ai/blog/?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme) and [Follow our LinkedIn](https://www.linkedin.com/company/wrenai)

## üõ†Ô∏è Contribution

1.	Star ‚≠ê the repo to show support (it really helps).
2.	Open an issue for bugs, ideas, or discussions.
3.	Read [Contribution Guidelines](https://github.com/Canner/WrenAI/blob/main/CONTRIBUTING.md) for setup &amp; PR guidelines.

## ‚≠êÔ∏è Community

- Join 1.3k+ developers in our [Discord](https://discord.gg/5DvshJqG8Z) for real-time help and roadmap previews.
- If there are any issues, please visit [GitHub Issues](https://github.com/Canner/WrenAI/issues).
- Explore our [public roadmap](https://wrenai.notion.site/) to stay updated on upcoming features and improvements!

Please note that our [Code of Conduct](./CODE_OF_CONDUCT.md) applies to all Wren AI community channels. Users are **highly encouraged** to read and adhere to them to avoid repercussions.

## üéâ Our Contributors
&lt;a href=&quot;https://github.com/canner/wrenAI/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=Canner/WrenAI&quot; /&gt;
&lt;/a&gt;

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;#top&quot;&gt;‚¨ÜÔ∏è Back to Top&lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[miurla/morphic]]></title>
            <link>https://github.com/miurla/morphic</link>
            <guid>https://github.com/miurla/morphic</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[An AI-powered search engine with a generative UI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/miurla/morphic">miurla/morphic</a></h1>
            <p>An AI-powered search engine with a generative UI</p>
            <p>Language: TypeScript</p>
            <p>Stars: 8,004</p>
            <p>Forks: 2,192</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre># Morphic

An AI-powered search engine with a generative UI.

![capture](/public/screenshot-2025-05-04.png)

## üóÇÔ∏è Overview

- üõ† [Features](#-features)
- üß± [Stack](#-stack)
- üöÄ [Quickstart](#-quickstart)
- üåê [Deploy](#-deploy)
- üîé [Search Engine](#-search-engine)
- üíô [Sponsors](#-sponsors)
- üë• [Contributing](#-contributing)
- üìÑ [License](#-license)

üìù Explore AI-generated documentation on [DeepWiki](https://deepwiki.com/miurla/morphic)

## üõ† Features

### Core Features

- AI-powered search with GenerativeUI
- Natural language question understanding
- Multiple search providers support (Tavily, SearXNG, Exa)
- Model selection from UI (switch between available AI models)
  - Reasoning models with visible thought process

### Authentication

- User authentication powered by [Supabase Auth](https://supabase.com/docs/guides/auth)
- Supports Email/Password sign-up and sign-in
- Supports Social Login with Google

### Chat &amp; History

- Chat history functionality (Optional)
- Share search results (Optional)
- Redis support (Local/Upstash)

### AI Providers

The following AI providers are supported:

- OpenAI (Default)
- Google Generative AI
- Azure OpenAI
- Anthropic
- Ollama
- Groq
- DeepSeek
- Fireworks
- xAI (Grok)
- OpenAI Compatible

Models are configured in `public/config/models.json`. Each model requires its corresponding API key to be set in the environment variables. See [Configuration Guide](docs/CONFIGURATION.md) for details.

### Search Capabilities

- URL-specific search
- Video search support (Optional)
- SearXNG integration with:
  - Customizable search depth (basic/advanced)
  - Configurable engines
  - Adjustable results limit
  - Safe search options
  - Custom time range filtering

### Additional Features

- Docker deployment ready
- Browser search engine integration

## üß± Stack

### Core Framework

- [Next.js](https://nextjs.org/) - App Router, React Server Components
- [TypeScript](https://www.typescriptlang.org/) - Type safety
- [Vercel AI SDK](https://sdk.vercel.ai/docs) - Text streaming / Generative UI

### Authentication &amp; Authorization (Updated Category)

- [Supabase](https://supabase.com/) - User authentication and backend services

### AI &amp; Search

- [OpenAI](https://openai.com/) - Default AI provider (Optional: Google AI, Anthropic, Groq, Ollama, Azure OpenAI, DeepSeek, Fireworks)
- [Tavily AI](https://tavily.com/) - Default search provider
- Alternative providers:
  - [SearXNG](https://docs.searxng.org/) - Self-hosted search
  - [Exa](https://exa.ai/) - Neural search

### Data Storage

- [Upstash](https://upstash.com/) - Serverless Redis
- [Redis](https://redis.io/) - Local Redis option

### UI &amp; Styling

- [Tailwind CSS](https://tailwindcss.com/) - Utility-first CSS framework
- [shadcn/ui](https://ui.shadcn.com/) - Re-usable components
- [Radix UI](https://www.radix-ui.com/) - Unstyled, accessible components
- [Lucide Icons](https://lucide.dev/) - Beautiful &amp; consistent icons

## üöÄ Quickstart

### 1. Fork and Clone repo

Fork the repo to your Github account, then run the following command to clone the repo:

```bash
git clone git@github.com:[YOUR_GITHUB_ACCOUNT]/morphic.git
```

### 2. Install dependencies

```bash
cd morphic
bun install
```

### 3. Configure environment variables

```bash
cp .env.local.example .env.local
```

Fill in the required environment variables in `.env.local`:

```bash
# Required for Core Functionality
OPENAI_API_KEY=     # Get from https://platform.openai.com/api-keys
TAVILY_API_KEY=     # Get from https://app.tavily.com/home
```

For optional features configuration (Redis, SearXNG, etc.), see [CONFIGURATION.md](./docs/CONFIGURATION.md)

### 4. Run app locally

#### Using Bun

```bash
bun dev
```

#### Using Docker

```bash
docker compose up -d
```

Visit http://localhost:3000 in your browser.

## üåê Deploy

Host your own live version of Morphic with Vercel, Cloudflare Pages, or Docker.

### Vercel

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fmiurla%2Fmorphic&amp;env=OPENAI_API_KEY,TAVILY_API_KEY,UPSTASH_REDIS_REST_URL,UPSTASH_REDIS_REST_TOKEN)

### Docker Prebuilt Image

Prebuilt Docker images are available on GitHub Container Registry:

```bash
docker pull ghcr.io/miurla/morphic:latest
```

You can use it with docker-compose:

```yaml
services:
  morphic:
    image: ghcr.io/miurla/morphic:latest
    env_file: .env.local
    ports:
      - &#039;3000:3000&#039;
    volumes:
      - ./models.json:/app/public/config/models.json # Optional: Override default model configuration
```

The default model configuration is located at `public/config/models.json`. For Docker deployment, you can create `models.json` alongside `.env.local` to override the default configuration.

## üîé Search Engine

### Setting up the Search Engine in Your Browser

If you want to use Morphic as a search engine in your browser, follow these steps:

1. Open your browser settings.
2. Navigate to the search engine settings section.
3. Select &quot;Manage search engines and site search&quot;.
4. Under &quot;Site search&quot;, click on &quot;Add&quot;.
5. Fill in the fields as follows:
   - **Search engine**: Morphic
   - **Shortcut**: morphic
   - **URL with %s in place of query**: `https://morphic.sh/search?q=%s`
6. Click &quot;Add&quot; to save the new search engine.
7. Find &quot;Morphic&quot; in the list of site search, click on the three dots next to it, and select &quot;Make default&quot;.

This will allow you to use Morphic as your default search engine in the browser.

## üíô Sponsors

This project is proudly supported by:

&lt;a href=&quot;https://vercel.com/oss&quot;&gt;
  &lt;img alt=&quot;Vercel OSS Program&quot; src=&quot;https://vercel.com/oss/program-badge.svg&quot; /&gt;
&lt;/a&gt;

## üë• Contributing

We welcome contributions to Morphic! Whether it&#039;s bug reports, feature requests, or pull requests, all contributions are appreciated.

Please see our [Contributing Guide](CONTRIBUTING.md) for details on:

- How to submit issues
- How to submit pull requests
- Commit message conventions
- Development setup

## üìÑ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[onlook-dev/onlook]]></title>
            <link>https://github.com/onlook-dev/onlook</link>
            <guid>https://github.com/onlook-dev/onlook</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[The Cursor for Designers ‚Ä¢ An Open-Source AI-First Design tool ‚Ä¢ Visually build, style, and edit your React App with AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/onlook-dev/onlook">onlook-dev/onlook</a></h1>
            <p>The Cursor for Designers ‚Ä¢ An Open-Source AI-First Design tool ‚Ä¢ Visually build, style, and edit your React App with AI</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,964</p>
            <p>Forks: 1,519</p>
            <p>Stars today: 29 stars today</p>
            <h2>README</h2><pre>&lt;!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 --&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img width=&quot;800&quot; alt=&quot;header image&quot; src=&quot;assets/web-preview.png&quot;&gt;
&lt;h3 align=&quot;center&quot;&gt;Onlook&lt;/h3&gt;
  &lt;p align=&quot;center&quot;&gt;
    Cursor for Designers
    &lt;br /&gt;
    &lt;a href=&quot;https://docs.onlook.com&quot;&gt;&lt;strong&gt;Explore the docs ¬ª&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
  &lt;/p&gt;
  &lt;p align=&quot;center&quot;&gt;
    üë®‚Äçüíªüë©‚Äçüíªüë®‚Äçüíª
    &lt;a href=&quot;https://www.ycombinator.com/companies/onlook/jobs/e4gHv1n-founding-engineer-fullstack&quot;&gt;We&#039;re hiring engineers in SF!&lt;/a&gt;
    üë©‚Äçüíªüë®‚Äçüíªüë©‚Äçüíª
  &lt;/p&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://youtu.be/RSX_3EaO5eU?feature=shared&quot;&gt;View Demo&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/onlook-dev/onlook/issues/new?labels=bug&amp;template=bug-report---.md&quot;&gt;Report Bug&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/onlook-dev/onlook/issues/new?labels=enhancement&amp;template=feature-request---.md&quot;&gt;Request Feature&lt;/a&gt;
  &lt;/p&gt;
  &lt;!-- PROJECT SHIELDS --&gt;
&lt;!--
*** I&#039;m using markdown &quot;reference style&quot; links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
--&gt;
&lt;!-- [![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![Apache License][license-shield]][license-url] --&gt;

[![Discord][discord-shield]][discord-url]
[![LinkedIn][linkedin-shield]][linkedin-url]
[![Twitter][twitter-shield]][twitter-url]

[‰∏≠Êñá](https://www.readme-i18n.com/onlook-dev/onlook?lang=zh) |
[Espa√±ol](https://www.readme-i18n.com/onlook-dev/onlook?lang=es) |
[Deutsch](https://www.readme-i18n.com/onlook-dev/onlook?lang=de) |
[fran√ßais](https://www.readme-i18n.com/onlook-dev/onlook?lang=fr) |
[Portugu√™s](https://www.readme-i18n.com/onlook-dev/onlook?lang=pt) |
[–†—É—Å—Å–∫–∏–π](https://www.readme-i18n.com/onlook-dev/onlook?lang=ru) |
[Êó•Êú¨Ë™û](https://www.readme-i18n.com/onlook-dev/onlook?lang=ja) |
[ÌïúÍµ≠Ïñ¥](https://www.readme-i18n.com/onlook-dev/onlook?lang=ko)

&lt;/div&gt;

# An Open-Source, Visual-First Code Editor

Craft websites, prototypes, and designs with AI in Next.js + TailwindCSS. Make
edits directly in the browser DOM with a visual editor. Design in realtime with
code. An open-source alternative to Bolt.new, Lovable, V0, Replit Agent, Figma
Make, Webflow, etc.

### üöß üöß üöß Onlook is still under development üöß üöß üöß

We&#039;re actively looking for contributors to help make Onlook for Web an
incredible prompt-to-build experience. Check the
[open issues](https://github.com/onlook-dev/onlook/issues) for a full list of
proposed features (and known issues), and join our
[Discord](https://discord.gg/hERDfFZCsH) to collaborate with hundreds of other
builders.

## What you can do with Onlook:

- [x] Create Next.js app in seconds
  - [x] Start from text or image
  - [ ] Use prebuilt templates
  - [ ] Import from Figma
  - [ ] Start from GitHub repo
- [x] Visually edit your app
  - [x] Use Figma-like UI
  - [x] Preview your app in real-time
  - [x] Manage brand assets and tokens
  - [x] Create and navigate to Pages
  - [x] Browse layers
  - [x] Manage project Images
  - [ ] Detect and use Components ‚Äì _Previously in
        [Onlook Desktop](https://github.com/onlook-dev/desktop)_
- [x] Development Tools
  - [x] Real-time code editor
  - [x] Save and restore from checkpoints
  - [x] Run commands via CLI
  - [x] Connect with app marketplace

- [x] Deploy your app in seconds
  - [x] Generate sharable links
  - [x] Link your custom domain
- [ ] Collaborate with your team
  - [ ] Real-time editing
  - [ ] Leave comments

![Onlook-GitHub-Example](https://github.com/user-attachments/assets/642de37a-72cc-4056-8eb7-8eb42714cdc4)

## Getting Started

Available soon with a [hosted app](https://onlook.com) or
[run locally](https://docs.onlook.com/developers/running-locally).

### Usage

Onlook will run on any Next.js + TailwindCSS project, import your project into
Onlook or start from scratch within the editor.

Use the AI chat to create or edit a project you&#039;re working on. At any time, you
can always right-click an element to open up the exact location of the element
in code.

&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/4ad9f411-b172-4430-81ef-650f4f314666&quot; /&gt;

&lt;br&gt;

Draw-in new divs and re-arrange them within their parent containers by
dragging-and-dropping.

&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;assets/insert-div.png&quot;&gt;

&lt;br&gt;

Preview the code side-by-side with your site design.

&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;assets/code-connect.png&quot;&gt;

&lt;br&gt;

Use Onlook&#039;s editor toolbar to adjust Tailwind styles, directly manipulate
objects, and experiment with layouts.

&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;assets/text-styling.png&quot; /&gt;

## Documentation

For full documentation, visit [docs.onlook.com](https://docs.onlook.com)

To see how to Contribute, visit
[Contributing to Onlook](https://docs.onlook.com/developers) in our docs.

## How it works

&lt;img width=&quot;676&quot; alt=&quot;architecture&quot; src=&quot;assets/architecture.png&quot;&gt;

1. When you create an app, we load the code into a web container
2. The container runs and serves the code
3. Our editor receives the preview link and displays it in an iFrame
4. Our editor reads and indexes the code from the container
5. We instrument the code in order to map elements to their place in code
6. When the element is edited, we edit the element in our iFrame, then in code
7. Our AI chat also has code access and tools to understand and edit the code

This architecture can theoretically scale to any language or framework that
displays DOM elements declaratively (e.g. jsx/tsx/html). We are focused on
making it work well with Next.js and TailwindCSS for now.

For a full walkthrough, check out our
[Architecture Docs](https://docs.onlook.com/developers/architecture).

### Our Tech Stack

#### Front-end

- [Next.js](https://nextjs.org/) - Full stack
- [TailwindCSS](https://tailwindcss.com/) - Styling
- [tRPC](https://trpc.io/) - Server interface

#### Database

- [Supabase](https://supabase.com/) - Auth, Database, Storage
- [Drizzle](https://orm.drizzle.team/) - ORM

#### AI

- [AI SDK](https://ai-sdk.dev/) - LLM client
- [OpenRouter](https://openrouter.ai/) - LLM model provider
- [Morph Fast Apply](https://morphllm.com) - Fast apply model provider
- [Relace](https://relace.ai) - Fast apply model provider

#### Sandbox and hosting

- [CodeSandboxSDK](https://codesandbox.io/docs/sdk) - Dev sandbox
- [Freestyle](https://www.freestyle.sh/) - Hosting

#### Runtime

- [Bun](https://bun.sh/) - Monorepo, runtime, bundler
- [Docker](https://www.docker.com/) - Container management

## Contributing

![image](https://github.com/user-attachments/assets/ecc94303-df23-46ae-87dc-66b040396e0b)

If you have a suggestion that would make this better, please fork the repo and
create a pull request. You can also
[open issues](https://github.com/onlook-dev/onlook/issues).

See the [CONTRIBUTING.md](CONTRIBUTING.md) for instructions and code of conduct.

#### Contributors

&lt;a href=&quot;https://github.com/onlook-dev/onlook/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=onlook-dev/onlook&quot; /&gt;
&lt;/a&gt;

## Contact

![image](https://github.com/user-attachments/assets/60684b68-1925-4550-8efd-51a1509fc953)

- Team: [Discord](https://discord.gg/hERDfFZCsH) -
  [Twitter](https://twitter.com/onlookdev) -
  [LinkedIn](https://www.linkedin.com/company/onlook-dev/) -
  [Email](mailto:contact@onlook.com)
- Project:
  [https://github.com/onlook-dev/onlook](https://github.com/onlook-dev/onlook)
- Website: [https://onlook.com](https://onlook.com)

## License

Distributed under the Apache 2.0 License. See [LICENSE.md](LICENSE.md) for more
information.

&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/onlook-dev/studio.svg?style=for-the-badge
[contributors-url]: https://github.com/onlook-dev/onlook/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/onlook-dev/studio.svg?style=for-the-badge
[forks-url]: https://github.com/onlook-dev/onlook/network/members
[stars-shield]: https://img.shields.io/github/stars/onlook-dev/studio.svg?style=for-the-badge
[stars-url]: https://github.com/onlook-dev/onlook/stargazers
[issues-shield]: https://img.shields.io/github/issues/onlook-dev/studio.svg?style=for-the-badge
[issues-url]: https://github.com/onlook-dev/onlook/issues
[license-shield]: https://img.shields.io/github/license/onlook-dev/studio.svg?style=for-the-badge
[license-url]: https://github.com/onlook-dev/onlook/blob/master/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?logo=linkedin&amp;colorB=555
[linkedin-url]: https://www.linkedin.com/company/onlook-dev
[twitter-shield]: https://img.shields.io/badge/-Twitter-black?logo=x&amp;colorB=555
[twitter-url]: https://x.com/onlookdev
[discord-shield]: https://img.shields.io/badge/-Discord-black?logo=discord&amp;colorB=555
[discord-url]: https://discord.gg/hERDfFZCsH
[React.js]: https://img.shields.io/badge/react-%2320232a.svg?logo=react&amp;logoColor=%2361DAFB
[React-url]: https://reactjs.org/
[TailwindCSS]: https://img.shields.io/badge/tailwindcss-%2338B2AC.svg?logo=tailwind-css&amp;logoColor=white
[Tailwind-url]: https://tailwindcss.com/
[Electron.js]: https://img.shields.io/badge/Electron-191970?logo=Electron&amp;logoColor=white
[Electron-url]: https://www.electronjs.org/
[Vite.js]: https://img.shields.io/badge/vite-%23646CFF.svg?logo=vite&amp;logoColor=white
[Vite-url]: https://vitejs.dev/
[product-screenshot]: assets/brand.png
[weave-shield]: https://img.shields.io/endpoint?url=https%3A%2F%2Fapp.workweave.ai%2Fapi%2Frepository%2Fbadge%2Forg_pWcXBHJo3Li2Te2Y4WkCPA33%2F820087727&amp;cacheSeconds=3600&amp;labelColor=#131313
[weave-url]: https://app.workweave.ai/reports/repository/org_pWcXBHJo3Li2Te2Y4WkCPA33/820087727
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[google-gemini/gemini-cli]]></title>
            <link>https://github.com/google-gemini/gemini-cli</link>
            <guid>https://github.com/google-gemini/gemini-cli</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[An open-source AI agent that brings the power of Gemini directly into your terminal.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google-gemini/gemini-cli">google-gemini/gemini-cli</a></h1>
            <p>An open-source AI agent that brings the power of Gemini directly into your terminal.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 72,478</p>
            <p>Forks: 7,489</p>
            <p>Stars today: 244 stars today</p>
            <h2>README</h2><pre># Gemini CLI

[![Gemini CLI CI](https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml/badge.svg)](https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml)
[![Version](https://img.shields.io/npm/v/@google/gemini-cli)](https://www.npmjs.com/package/@google/gemini-cli)
[![License](https://img.shields.io/github/license/google-gemini/gemini-cli)](https://github.com/google-gemini/gemini-cli/blob/main/LICENSE)

![Gemini CLI Screenshot](./docs/assets/gemini-screenshot.png)

Gemini CLI is an open-source AI agent that brings the power of Gemini directly into your terminal. It provides lightweight access to Gemini, giving you the most direct path from your prompt to our model.

## üöÄ Why Gemini CLI?

- **üéØ Free tier**: 60 requests/min and 1,000 requests/day with personal Google account
- **üß† Powerful Gemini 2.5 Pro**: Access to 1M token context window
- **üîß Built-in tools**: Google Search grounding, file operations, shell commands, web fetching
- **üîå Extensible**: MCP (Model Context Protocol) support for custom integrations
- **üíª Terminal-first**: Designed for developers who live in the command line
- **üõ°Ô∏è Open source**: Apache 2.0 licensed

## üì¶ Installation

### Quick Install

#### Run instantly with npx

```bash
# Using npx (no installation required)
npx https://github.com/google-gemini/gemini-cli
```

#### Install globally with npm

```bash
npm install -g @google/gemini-cli
```

#### Install globally with Homebrew (macOS/Linux)

```bash
brew install gemini-cli
```

#### System Requirements

- Node.js version 20 or higher
- macOS, Linux, or Windows

## Release Cadence and Tags

See [Releases](./docs/releases.md) for more details.

### Preview

New preview releases will be published each week at UTC 2359 on Tuesdays. These releases will not have been fully vetted and may contain regressions or other outstanding issues. Please help us test and install with `preview` tag.

```bash
npm install -g @google/gemini-cli@preview
```

### Stable

- New stable releases will be published each week at UTC 2000 on Tuesdays, this will be the full promotion of last week&#039;s `preview` release + any bug fixes and validations. Use `latest` tag.

```bash
npm install -g @google/gemini-cli@latest
```

### Nightly

- New releases will be published each week at UTC 0000 each day, This will be all changes from the main branch as represented at time of release. It should be assumed there are pending validations and issues. Use `nightly` tag.

```bash
npm install -g @google/gemini-cli@nightly
```

## üìã Key Features

### Code Understanding &amp; Generation

- Query and edit large codebases
- Generate new apps from PDFs, images, or sketches using multimodal capabilities
- Debug issues and troubleshoot with natural language

### Automation &amp; Integration

- Automate operational tasks like querying pull requests or handling complex rebases
- Use MCP servers to connect new capabilities, including [media generation with Imagen, Veo or Lyria](https://github.com/GoogleCloudPlatform/vertex-ai-creative-studio/tree/main/experiments/mcp-genmedia)
- Run non-interactively in scripts for workflow automation

### Advanced Capabilities

- Ground your queries with built-in [Google Search](https://ai.google.dev/gemini-api/docs/grounding) for real-time information
- Conversation checkpointing to save and resume complex sessions
- Custom context files (GEMINI.md) to tailor behavior for your projects

### GitHub Integration

Integrate Gemini CLI directly into your GitHub workflows with [**Gemini CLI GitHub Action**](https://github.com/google-github-actions/run-gemini-cli):

- **Pull Request Reviews**: Automated code review with contextual feedback and suggestions
- **Issue Triage**: Automated labeling and prioritization of GitHub issues based on content analysis
- **On-demand Assistance**: Mention `@gemini-cli` in issues and pull requests for help with debugging, explanations, or task delegation
- **Custom Workflows**: Build automated, scheduled and on-demand workflows tailored to your team&#039;s needs

## üîê Authentication Options

Choose the authentication method that best fits your needs:

### Option 1: OAuth login (Using your Google Account)

**‚ú® Best for:** Individual developers as well as anyone who has a Gemini Code Assist License. (see [quota limits and terms of service](https://cloud.google.com/gemini/docs/quotas) for details)

**Benefits:**

- **Free tier**: 60 requests/min and 1,000 requests/day
- **Gemini 2.5 Pro** with 1M token context window
- **No API key management** - just sign in with your Google account
- **Automatic updates** to latest models

#### Start Gemini CLI, then choose OAuth and follow the browser authentication flow when prompted

```bash
gemini
```

#### If you are using a paid Code Assist License from your organization, remember to set the Google Cloud Project

```bash
# Set your Google Cloud Project
export GOOGLE_CLOUD_PROJECT=&quot;YOUR_PROJECT_NAME&quot;
gemini
```

### Option 2: Gemini API Key

**‚ú® Best for:** Developers who need specific model control or paid tier access

**Benefits:**

- **Free tier**: 100 requests/day with Gemini 2.5 Pro
- **Model selection**: Choose specific Gemini models
- **Usage-based billing**: Upgrade for higher limits when needed

```bash
# Get your key from https://aistudio.google.com/apikey
export GEMINI_API_KEY=&quot;YOUR_API_KEY&quot;
gemini
```

### Option 3: Vertex AI

**‚ú® Best for:** Enterprise teams and production workloads

**Benefits:**

- **Enterprise features**: Advanced security and compliance
- **Scalable**: Higher rate limits with billing account
- **Integration**: Works with existing Google Cloud infrastructure

```bash
# Get your key from Google Cloud Console
export GOOGLE_API_KEY=&quot;YOUR_API_KEY&quot;
export GOOGLE_GENAI_USE_VERTEXAI=true
gemini
```

For Google Workspace accounts and other authentication methods, see the [authentication guide](./docs/cli/authentication.md).

## üöÄ Getting Started

### Basic Usage

#### Start in current directory

```bash
gemini
```

#### Include multiple directories

```bash
gemini --include-directories ../lib,../docs
```

#### Use specific model

```bash
gemini -m gemini-2.5-flash
```

#### Non-interactive mode for scripts

```bash
gemini -p &quot;Explain the architecture of this codebase&quot;
```

### Quick Examples

#### Start a new project

```bash
cd new-project/
gemini
&gt; Write me a Discord bot that answers questions using a FAQ.md file I will provide
```

#### Analyze existing code

```bash
git clone https://github.com/google-gemini/gemini-cli
cd gemini-cli
gemini
&gt; Give me a summary of all of the changes that went in yesterday
```

## üìö Documentation

### Getting Started

- [**Quickstart Guide**](./docs/cli/index.md) - Get up and running quickly
- [**Authentication Setup**](./docs/cli/authentication.md) - Detailed auth configuration
- [**Configuration Guide**](./docs/cli/configuration.md) - Settings and customization
- [**Keyboard Shortcuts**](./docs/keyboard-shortcuts.md) - Productivity tips

### Core Features

- [**Commands Reference**](./docs/cli/commands.md) - All slash commands (`/help`, `/chat`, `/mcp`, etc.)
- [**Checkpointing**](./docs/checkpointing.md) - Save and resume conversations
- [**Memory Management**](./docs/tools/memory.md) - Using GEMINI.md context files
- [**Token Caching**](./docs/cli/token-caching.md) - Optimize token usage

### Tools &amp; Extensions

- [**Built-in Tools Overview**](./docs/tools/index.md)
  - [File System Operations](./docs/tools/file-system.md)
  - [Shell Commands](./docs/tools/shell.md)
  - [Web Fetch &amp; Search](./docs/tools/web-fetch.md)
  - [Multi-file Operations](./docs/tools/multi-file.md)
- [**MCP Server Integration**](./docs/tools/mcp-server.md) - Extend with custom tools
- [**Custom Extensions**](./docs/extension.md) - Build your own commands

### Advanced Topics

- [**Architecture Overview**](./docs/architecture.md) - How Gemini CLI works
- [**IDE Integration**](./docs/ide-integration.md) - VS Code companion
- [**Sandboxing &amp; Security**](./docs/sandbox.md) - Safe execution environments
- [**Enterprise Deployment**](./docs/deployment.md) - Docker, system-wide config
- [**Telemetry &amp; Monitoring**](./docs/telemetry.md) - Usage tracking
- [**Tools API Development**](./docs/core/tools-api.md) - Create custom tools

### Configuration &amp; Customization

- [**Settings Reference**](./docs/cli/configuration.md) - All configuration options
- [**Theme Customization**](./docs/cli/themes.md) - Visual customization
- [**.gemini Directory**](./docs/gemini-ignore.md) - Project-specific settings
- [**Environment Variables**](./docs/cli/configuration.md#environment-variables)

### Troubleshooting &amp; Support

- [**Troubleshooting Guide**](./docs/troubleshooting.md) - Common issues and solutions
- [**FAQ**](./docs/troubleshooting.md#frequently-asked-questions) - Quick answers
- Use `/bug` command to report issues directly from the CLI

### Using MCP Servers

Configure MCP servers in `~/.gemini/settings.json` to extend Gemini CLI with custom tools:

```text
&gt; @github List my open pull requests
&gt; @slack Send a summary of today&#039;s commits to #dev channel
&gt; @database Run a query to find inactive users
```

See the [MCP Server Integration guide](./docs/tools/mcp-server.md) for setup instructions.

## ü§ù Contributing

We welcome contributions! Gemini CLI is fully open source (Apache 2.0), and we encourage the community to:

- Report bugs and suggest features
- Improve documentation
- Submit code improvements
- Share your MCP servers and extensions

See our [Contributing Guide](./CONTRIBUTING.md) for development setup, coding standards, and how to submit pull requests.

Check our [Official Roadmap](https://github.com/orgs/google-gemini/projects/11/) for planned features and priorities.

## üìñ Resources

- **[Official Roadmap](./ROADMAP.md)** - See what&#039;s coming next
- **[NPM Package](https://www.npmjs.com/package/@google/gemini-cli)** - Package registry
- **[GitHub Issues](https://github.com/google-gemini/gemini-cli/issues)** - Report bugs or request features
- **[Security Advisories](https://github.com/google-gemini/gemini-cli/security/advisories)** - Security updates

### Uninstall

See the [Uninstall Guide](docs/Uninstall.md) for removal instructions.

## üìÑ Legal

- **License**: [Apache License 2.0](LICENSE)
- **Terms of Service**: [Terms &amp; Privacy](./docs/tos-privacy.md)
- **Security**: [Security Policy](SECURITY.md)

---

&lt;p align=&quot;center&quot;&gt;
  Built with ‚ù§Ô∏è by Google and the open source community
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[kamranahmedse/developer-roadmap]]></title>
            <link>https://github.com/kamranahmedse/developer-roadmap</link>
            <guid>https://github.com/kamranahmedse/developer-roadmap</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[Interactive roadmaps, guides and other educational content to help developers grow in their careers.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kamranahmedse/developer-roadmap">kamranahmedse/developer-roadmap</a></h1>
            <p>Interactive roadmaps, guides and other educational content to help developers grow in their careers.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 334,866</p>
            <p>Forks: 42,651</p>
            <p>Stars today: 94 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[linshenkx/prompt-optimizer]]></title>
            <link>https://github.com/linshenkx/prompt-optimizer</link>
            <guid>https://github.com/linshenkx/prompt-optimizer</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[‰∏ÄÊ¨æÊèêÁ§∫ËØç‰ºòÂåñÂô®ÔºåÂä©Âäõ‰∫éÁºñÂÜôÈ´òË¥®ÈáèÁöÑÊèêÁ§∫ËØç]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/linshenkx/prompt-optimizer">linshenkx/prompt-optimizer</a></h1>
            <p>‰∏ÄÊ¨æÊèêÁ§∫ËØç‰ºòÂåñÂô®ÔºåÂä©Âäõ‰∫éÁºñÂÜôÈ´òË¥®ÈáèÁöÑÊèêÁ§∫ËØç</p>
            <p>Language: TypeScript</p>
            <p>Stars: 13,742</p>
            <p>Forks: 1,679</p>
            <p>Stars today: 135 stars today</p>
            <h2>README</h2><pre># Prompt Optimizer (ÊèêÁ§∫ËØç‰ºòÂåñÂô®) üöÄ

&lt;div align=&quot;center&quot;&gt;

[English](README_EN.md) | [‰∏≠Êñá](README.md)

[![GitHub stars](https://img.shields.io/github/stars/linshenkx/prompt-optimizer)](https://github.com/linshenkx/prompt-optimizer/stargazers)
![Chrome Web Store Users](https://img.shields.io/chrome-web-store/users/cakkkhboolfnadechdlgdcnjammejlna?style=flat&amp;label=Chrome%20Users&amp;link=https%3A%2F%2Fchromewebstore.google.com%2Fdetail%2F%25E6%258F%2590%25E7%25A4%25BA%25E8%25AF%258D%25E4%25BC%2598%25E5%258C%2596%25E5%2599%25A8%2Fcakkkhboolfnadechdlgdcnjammejlna)

&lt;a href=&quot;https://trendshift.io/repositories/13813&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13813&quot; alt=&quot;linshenkx%2Fprompt-optimizer | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Docker Pulls](https://img.shields.io/docker/pulls/linshen/prompt-optimizer)](https://hub.docker.com/r/linshen/prompt-optimizer)
![GitHub forks](https://img.shields.io/github/forks/linshenkx/prompt-optimizer?style=flat)
[![Deploy with Vercel](https://img.shields.io/badge/Vercel-indigo?style=flat&amp;logo=vercel)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flinshenkx%2Fprompt-optimizer)

[Âú®Á∫ø‰ΩìÈ™å](https://prompt.always200.com) | [Âø´ÈÄüÂºÄÂßã](#Âø´ÈÄüÂºÄÂßã) | [Â∏∏ËßÅÈóÆÈ¢ò](#Â∏∏ËßÅÈóÆÈ¢ò) | [ChromeÊèí‰ª∂](https://chromewebstore.google.com/detail/prompt-optimizer/cakkkhboolfnadechdlgdcnjammejlna)

[ÂºÄÂèëÊñáÊ°£](dev.md) | [VercelÈÉ®ÁΩ≤ÊåáÂçó](docs/user/deployment/vercel.md) | [MCPÈÉ®ÁΩ≤‰ΩøÁî®ËØ¥Êòé](docs/user/mcp-server.md) | [DeepWikiÊñáÊ°£](https://deepwiki.com/linshenkx/prompt-optimizer) | [ZReadÊñáÊ°£](https://zread.ai/linshenkx/prompt-optimizer)

&lt;/div&gt;

## üìñ È°πÁõÆÁÆÄ‰ªã

Prompt OptimizerÊòØ‰∏Ä‰∏™Âº∫Â§ßÁöÑAIÊèêÁ§∫ËØç‰ºòÂåñÂ∑•ÂÖ∑ÔºåÂ∏ÆÂä©‰Ω†ÁºñÂÜôÊõ¥Â•ΩÁöÑAIÊèêÁ§∫ËØçÔºåÊèêÂçáAIËæìÂá∫Ë¥®Èáè„ÄÇÊîØÊåÅWebÂ∫îÁî®„ÄÅÊ°åÈù¢Â∫îÁî®„ÄÅChromeÊèí‰ª∂ÂíåDockerÈÉ®ÁΩ≤ÂõõÁßç‰ΩøÁî®ÊñπÂºè„ÄÇ

### üé• ÂäüËÉΩÊºîÁ§∫

&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;&lt;b&gt;1. ËßíËâ≤ÊâÆÊºîÂØπËØùÔºöÊøÄÂèëÂ∞èÊ®°ÂûãÊΩúÂäõ&lt;/b&gt;&lt;/p&gt;
  &lt;p&gt;Âú®ËøΩÊ±ÇÊàêÊú¨ÊïàÁõäÁöÑÁîü‰∫ßÊàñÊ≥®ÈáçÈöêÁßÅÁöÑÊú¨Âú∞ÂåñÂú∫ÊôØ‰∏≠ÔºåÁªìÊûÑÂåñÁöÑÊèêÁ§∫ËØçËÉΩËÆ©Â∞èÊ®°ÂûãÁ®≥ÂÆöÂú∞ËøõÂÖ•ËßíËâ≤ÔºåÊèê‰æõÊ≤âÊµ∏Âºè„ÄÅÈ´ò‰∏ÄËá¥ÊÄßÁöÑËßíËâ≤ÊâÆÊºî‰ΩìÈ™åÔºåÊúâÊïàÊøÄÂèëÂÖ∂ÊΩúÂäõ„ÄÇ&lt;/p&gt;
  &lt;img src=&quot;images/demo/cat-maid-roleplay.png&quot; alt=&quot;Áå´Â•≥‰ªÜËßíËâ≤ÊâÆÊºîÊºîÁ§∫&quot; width=&quot;85%&quot;&gt;
  &lt;br&gt;
  &lt;p&gt;&lt;b&gt;2. Áü•ËØÜÂõæË∞±ÊèêÂèñÔºö‰øùÈöúÁîü‰∫ßÁéØÂ¢ÉÁöÑÁ®≥ÂÆöÊÄß&lt;/b&gt;&lt;/p&gt;
  &lt;p&gt;Âú®ÈúÄË¶ÅÁ®ãÂ∫èÂåñÂ§ÑÁêÜÁöÑÁîü‰∫ßÁéØÂ¢É‰∏≠ÔºåÈ´òË¥®ÈáèÁöÑÊèêÁ§∫ËØçËÉΩÊòæËëóÈôç‰ΩéÂØπÊ®°ÂûãÊô∫ËÉΩÁ®ãÂ∫¶ÁöÑË¶ÅÊ±ÇÔºå‰ΩøÂæóÊõ¥ÁªèÊµéÁöÑÂ∞èÊ®°Âûã‰πüËÉΩÁ®≥ÂÆöËæìÂá∫ÂèØÈù†ÁöÑÊåáÂÆöÊ†ºÂºè„ÄÇÊú¨Â∑•ÂÖ∑Êó®Âú®ËæÖÂä©ÂºÄÂèëËÄÖÂø´ÈÄüËææÂà∞Ê≠§ÁõÆÁöÑÔºå‰ªéËÄåÂä†ÈÄüÂºÄÂèë„ÄÅ‰øùÈöúÁ®≥ÂÆöÔºåÂÆûÁé∞ÈôçÊú¨Â¢ûÊïà„ÄÇ&lt;/p&gt;
  &lt;img src=&quot;images/demo/knowledge-graph-extractor.png&quot; alt=&quot;Áü•ËØÜÂõæË∞±ÊèêÂèñÊºîÁ§∫&quot; width=&quot;85%&quot;&gt;
  &lt;br&gt;
  &lt;p&gt;&lt;b&gt;3. ËØóÊ≠åÂÜô‰ΩúÔºöËæÖÂä©ÂàõÊÑèÊé¢Á¥¢‰∏éÈúÄÊ±ÇÂÆöÂà∂&lt;/b&gt;&lt;/p&gt;
  &lt;p&gt;ÂΩìÈù¢ÂØπ‰∏Ä‰∏™Âº∫Â§ßÁöÑAIÔºåÊàë‰ª¨ÁöÑÁõÆÊ†á‰∏çÂè™ÊòØÂæóÂà∞‰∏Ä‰∏™‚ÄúÂ•Ω‚ÄùÁ≠îÊ°àÔºåËÄåÊòØÂæóÂà∞‰∏Ä‰∏™‚ÄúÊàë‰ª¨ÊÉ≥Ë¶ÅÁöÑ‚ÄùÁã¨ÁâπÁ≠îÊ°à„ÄÇÊú¨Â∑•ÂÖ∑ËÉΩÂ∏ÆÂä©Áî®Êà∑Â∞Ü‰∏Ä‰∏™Ê®°Á≥äÁöÑÁÅµÊÑüÔºàÂ¶Ç‚ÄúÂÜôÈ¶ñËØó‚ÄùÔºâÁªÜÂåñ‰∏∫ÂÖ∑‰ΩìÁöÑÈúÄÊ±ÇÔºàÂÖ≥‰∫é‰ªÄ‰πà‰∏ªÈ¢ò„ÄÅ‰ΩïÁßçÊÑèË±°„ÄÅ‰ΩïÁßçÊÉÖÊÑüÔºâÔºåËæÖÂä©ÊÇ®Êé¢Á¥¢„ÄÅÂèëÊéòÂπ∂Á≤æÁ°ÆË°®ËææËá™Â∑±ÁöÑÂàõÊÑèÔºå‰∏éAIÂÖ±ÂàõÁã¨‰∏ÄÊó†‰∫åÁöÑ‰ΩúÂìÅ„ÄÇ&lt;/p&gt;
  &lt;img src=&quot;images/demo/poetry-writing.png&quot; alt=&quot;ËØóÊ≠åÂàõ‰ΩúÊºîÁ§∫&quot; width=&quot;85%&quot;&gt;
&lt;/div&gt;

## ‚ú® Ê†∏ÂøÉÁâπÊÄß

- üéØ **Êô∫ËÉΩ‰ºòÂåñ**Ôºö‰∏ÄÈîÆ‰ºòÂåñÊèêÁ§∫ËØçÔºåÊîØÊåÅÂ§öËΩÆËø≠‰ª£ÊîπËøõÔºåÊèêÂçáAIÂõûÂ§çÂáÜÁ°ÆÂ∫¶
- üìù **ÂèåÊ®°Âºè‰ºòÂåñ**ÔºöÊîØÊåÅÁ≥ªÁªüÊèêÁ§∫ËØç‰ºòÂåñÂíåÁî®Êà∑ÊèêÁ§∫ËØç‰ºòÂåñÔºåÊª°Ë∂≥‰∏çÂêå‰ΩøÁî®Âú∫ÊôØ
- üîÑ **ÂØπÊØîÊµãËØï**ÔºöÊîØÊåÅÂéüÂßãÊèêÁ§∫ËØçÂíå‰ºòÂåñÂêéÊèêÁ§∫ËØçÁöÑÂÆûÊó∂ÂØπÊØîÔºåÁõ¥ËßÇÂ±ïÁ§∫‰ºòÂåñÊïàÊûú
- ü§ñ **Â§öÊ®°ÂûãÈõÜÊàê**ÔºöÊîØÊåÅOpenAI„ÄÅGemini„ÄÅDeepSeek„ÄÅÊô∫Ë∞±AI„ÄÅSiliconFlowÁ≠â‰∏ªÊµÅAIÊ®°Âûã
- üîí **ÂÆâÂÖ®Êû∂ÊûÑ**ÔºöÁ∫ØÂÆ¢Êà∑Á´ØÂ§ÑÁêÜÔºåÊï∞ÊçÆÁõ¥Êé•‰∏éAIÊúçÂä°ÂïÜ‰∫§‰∫íÔºå‰∏çÁªèËøá‰∏≠Èó¥ÊúçÂä°Âô®
- üì± **Â§öÁ´ØÊîØÊåÅ**ÔºöÂêåÊó∂Êèê‰æõWebÂ∫îÁî®„ÄÅÊ°åÈù¢Â∫îÁî®„ÄÅChromeÊèí‰ª∂ÂíåDockerÈÉ®ÁΩ≤ÂõõÁßç‰ΩøÁî®ÊñπÂºè
- üîê **ËÆøÈóÆÊéßÂà∂**ÔºöÊîØÊåÅÂØÜÁ†Å‰øùÊä§ÂäüËÉΩÔºå‰øùÈöúÈÉ®ÁΩ≤ÂÆâÂÖ®
- üß© **MCPÂçèËÆÆÊîØÊåÅ**ÔºöÊîØÊåÅModel Context Protocol (MCP) ÂçèËÆÆÔºåÂèØ‰∏éClaude DesktopÁ≠âMCPÂÖºÂÆπÂ∫îÁî®ÈõÜÊàê

## Âø´ÈÄüÂºÄÂßã

### 1. ‰ΩøÁî®Âú®Á∫øÁâàÊú¨ÔºàÊé®ËçêÔºâ

Áõ¥Êé•ËÆøÈóÆÔºö[https://prompt.always200.com](https://prompt.always200.com)

È°πÁõÆÊòØÁ∫ØÂâçÁ´ØÈ°πÁõÆÔºåÊâÄÊúâÊï∞ÊçÆÂè™Â≠òÂÇ®Âú®ÊµèËßàÂô®Êú¨Âú∞Ôºå‰∏ç‰ºö‰∏ä‰º†Ëá≥‰ªª‰ΩïÊúçÂä°Âô®ÔºåÂõ†Ê≠§Áõ¥Êé•‰ΩøÁî®Âú®Á∫øÁâàÊú¨‰πüÊòØÂÆâÂÖ®ÂèØÈù†ÁöÑ

### 2. VercelÈÉ®ÁΩ≤
ÊñπÂºè1Ôºö‰∏ÄÈîÆÈÉ®ÁΩ≤Âà∞Ëá™Â∑±ÁöÑVercel(Êñπ‰æøÔºå‰ΩÜÂêéÁª≠Êó†Ê≥ïËá™Âä®Êõ¥Êñ∞)Ôºö
   [![ÈÉ®ÁΩ≤Âà∞ Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flinshenkx%2Fprompt-optimizer)

ÊñπÂºè2: ForkÈ°πÁõÆÂêéÂú®Vercel‰∏≠ÂØºÂÖ•ÔºàÊé®ËçêÔºå‰ΩÜÈúÄÂèÇËÄÉÈÉ®ÁΩ≤ÊñáÊ°£ËøõË°åÊâãÂä®ËÆæÁΩÆÔºâÔºö
   - ÂÖàForkÈ°πÁõÆÂà∞Ëá™Â∑±ÁöÑGitHub
   - ÁÑ∂ÂêéÂú®Vercel‰∏≠ÂØºÂÖ•ËØ•È°πÁõÆ
   - ÂèØË∑üË∏™Ê∫êÈ°πÁõÆÊõ¥Êñ∞Ôºå‰æø‰∫éÂêåÊ≠•ÊúÄÊñ∞ÂäüËÉΩÂíå‰øÆÂ§ç
- ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáèÔºö
  - `ACCESS_PASSWORD`ÔºöËÆæÁΩÆËÆøÈóÆÂØÜÁ†ÅÔºåÂêØÁî®ËÆøÈóÆÈôêÂà∂
  - `VITE_OPENAI_API_KEY`Á≠âÔºöÈÖçÁΩÆÂêÑAIÊúçÂä°ÂïÜÁöÑAPIÂØÜÈí•

Êõ¥Â§öËØ¶ÁªÜÁöÑÈÉ®ÁΩ≤Ê≠•È™§ÂíåÊ≥®ÊÑè‰∫ãÈ°πÔºåËØ∑Êü•ÁúãÔºö
- [VercelÈÉ®ÁΩ≤ÊåáÂçó](docs/user/deployment/vercel.md)

### 3. ‰∏ãËΩΩÊ°åÈù¢Â∫îÁî®
‰ªé [GitHub Releases](https://github.com/linshenkx/prompt-optimizer/releases) ‰∏ãËΩΩÊúÄÊñ∞ÁâàÊú¨„ÄÇÊàë‰ª¨‰∏∫ÂêÑÂπ≥Âè∞Êèê‰æõ**ÂÆâË£ÖÁ®ãÂ∫è**Âíå**ÂéãÁº©ÂåÖ**‰∏§ÁßçÊ†ºÂºè„ÄÇ

- **ÂÆâË£ÖÁ®ãÂ∫è (Êé®Ëçê)**: Â¶Ç `*.exe`, `*.dmg`, `*.AppImage` Á≠â„ÄÇ**Âº∫ÁÉàÊé®Ëçê‰ΩøÁî®Ê≠§ÊñπÂºèÔºåÂõ†‰∏∫ÂÆÉÊîØÊåÅËá™Âä®Êõ¥Êñ∞**„ÄÇ
- **ÂéãÁº©ÂåÖ**: Â¶Ç `*.zip`„ÄÇËß£ÂéãÂç≥Áî®Ôºå‰ΩÜÊó†Ê≥ïËá™Âä®Êõ¥Êñ∞„ÄÇ

**Ê°åÈù¢Â∫îÁî®Ê†∏ÂøÉ‰ºòÂäø**:
- ‚úÖ **Êó†Ë∑®ÂüüÈôêÂà∂**Ôºö‰Ωú‰∏∫ÂéüÁîüÊ°åÈù¢Â∫îÁî®ÔºåÂÆÉËÉΩÂΩªÂ∫ïÊëÜËÑ±ÊµèËßàÂô®Ë∑®ÂüüÔºàCORSÔºâÈóÆÈ¢òÁöÑÂõ∞Êâ∞„ÄÇËøôÊÑèÂë≥ÁùÄÊÇ®ÂèØ‰ª•Áõ¥Êé•ËøûÊé•‰ªª‰ΩïAIÊúçÂä°Êèê‰æõÂïÜÁöÑAPIÔºåÂåÖÊã¨Êú¨Âú∞ÈÉ®ÁΩ≤ÁöÑOllamaÊàñÊúâ‰∏•Ê†ºÂÆâÂÖ®Á≠ñÁï•ÁöÑÂïÜ‰∏öAPIÔºåËé∑ÂæóÊúÄÂÆåÊï¥„ÄÅÊúÄÁ®≥ÂÆöÁöÑÂäüËÉΩ‰ΩìÈ™å„ÄÇ
- ‚úÖ **Ëá™Âä®Êõ¥Êñ∞**ÔºöÈÄöËøáÂÆâË£ÖÁ®ãÂ∫èÔºàÂ¶Ç `.exe`, `.dmg`ÔºâÂÆâË£ÖÁöÑÁâàÊú¨ÔºåËÉΩÂ§üËá™Âä®Ê£ÄÊü•Âπ∂Êõ¥Êñ∞Âà∞ÊúÄÊñ∞Áâà„ÄÇ
- ‚úÖ **Áã¨Á´ãËøêË°å**ÔºöÊó†ÈúÄ‰æùËµñÊµèËßàÂô®ÔºåÊèê‰æõÊõ¥Âø´ÁöÑÂìçÂ∫îÂíåÊõ¥‰Ω≥ÁöÑÊÄßËÉΩ„ÄÇ

### 4. ÂÆâË£ÖChromeÊèí‰ª∂
1. ‰ªéChromeÂïÜÂ∫óÂÆâË£ÖÔºàÁî±‰∫éÂÆ°ÊâπËæÉÊÖ¢ÔºåÂèØËÉΩ‰∏çÊòØÊúÄÊñ∞ÁöÑÔºâÔºö[ChromeÂïÜÂ∫óÂú∞ÂùÄ](https://chromewebstore.google.com/detail/prompt-optimizer/cakkkhboolfnadechdlgdcnjammejlna)
2. ÁÇπÂáªÂõæÊ†áÂç≥ÂèØÊâìÂºÄÊèêÁ§∫ËØç‰ºòÂåñÂô®

### 5. DockerÈÉ®ÁΩ≤
&lt;details&gt;
&lt;summary&gt;ÁÇπÂáªÊü•Áúã Docker ÈÉ®ÁΩ≤ÂëΩ‰ª§&lt;/summary&gt;

```bash
# ËøêË°åÂÆπÂô®ÔºàÈªòËÆ§ÈÖçÁΩÆÔºâ
docker run -d -p 8081:80 --restart unless-stopped --name prompt-optimizer linshen/prompt-optimizer

# ËøêË°åÂÆπÂô®ÔºàÈÖçÁΩÆAPIÂØÜÈí•ÂíåËÆøÈóÆÂØÜÁ†ÅÔºâ
docker run -d -p 8081:80 \
  -e VITE_OPENAI_API_KEY=your_key \
  -e ACCESS_USERNAME=your_username \  # ÂèØÈÄâÔºåÈªòËÆ§‰∏∫&quot;admin&quot;
  -e ACCESS_PASSWORD=your_password \  # ËÆæÁΩÆËÆøÈóÆÂØÜÁ†Å
  --restart unless-stopped \
  --name prompt-optimizer \
  linshen/prompt-optimizer
```
&lt;/details&gt;

&gt; **ÂõΩÂÜÖÈïúÂÉè**: Â¶ÇÊûúDocker HubËÆøÈóÆËæÉÊÖ¢ÔºåÂèØ‰ª•Â∞Ü‰∏äËø∞ÂëΩ‰ª§‰∏≠ÁöÑ `linshen/prompt-optimizer` ÊõøÊç¢‰∏∫ `registry.cn-guangzhou.aliyuncs.com/prompt-optimizer/prompt-optimizer`

### 6. Docker ComposeÈÉ®ÁΩ≤
&lt;details&gt;
&lt;summary&gt;ÁÇπÂáªÊü•Áúã Docker Compose ÈÉ®ÁΩ≤Ê≠•È™§&lt;/summary&gt;

```bash
# 1. ÂÖãÈöÜ‰ªìÂ∫ì
git clone https://github.com/linshenkx/prompt-optimizer.git
cd prompt-optimizer

# 2. ÂèØÈÄâÔºöÂàõÂª∫.envÊñá‰ª∂ÈÖçÁΩÆAPIÂØÜÈí•ÂíåËÆøÈóÆËÆ§ËØÅ
cp env.local.example .env
# ÁºñËæë .env Êñá‰ª∂ÔºåÂ°´ÂÖ•ÂÆûÈôÖÁöÑ API ÂØÜÈí•ÂíåÈÖçÁΩÆ

# 3. ÂêØÂä®ÊúçÂä°
docker compose up -d

# 4. Êü•ÁúãÊó•Âøó
docker compose logs -f

# 5. ËÆøÈóÆÊúçÂä°
Web ÁïåÈù¢Ôºöhttp://localhost:8081
MCP ÊúçÂä°Âô®Ôºöhttp://localhost:8081/mcp
```
&lt;/details&gt;

‰Ω†ËøòÂèØ‰ª•Áõ¥Êé•ÁºñËæëdocker-compose.ymlÊñá‰ª∂ÔºåËá™ÂÆö‰πâÈÖçÁΩÆÔºö
&lt;details&gt;
&lt;summary&gt;ÁÇπÂáªÊü•Áúã docker-compose.yml Á§∫‰æã&lt;/summary&gt;

```yaml
services:
  prompt-optimizer:
    # ‰ΩøÁî®Docker HubÈïúÂÉè
    image: linshen/prompt-optimizer:latest
    # Êàñ‰ΩøÁî®ÈòøÈáå‰∫ëÈïúÂÉèÔºàÂõΩÂÜÖÁî®Êà∑Êé®ËçêÔºâ
    # image: registry.cn-guangzhou.aliyuncs.com/prompt-optimizer/prompt-optimizer:latest
    container_name: prompt-optimizer
    restart: unless-stopped
    ports:
      - &quot;8081:80&quot;  # WebÂ∫îÁî®Á´ØÂè£ÔºàÂåÖÂê´MCPÊúçÂä°Âô®ÔºåÈÄöËøá/mcpË∑ØÂæÑËÆøÈóÆÔºâ
    environment:
      # APIÂØÜÈí•ÈÖçÁΩÆ
      - VITE_OPENAI_API_KEY=your_openai_key
      - VITE_GEMINI_API_KEY=your_gemini_key
      # ËÆøÈóÆÊéßÂà∂ÔºàÂèØÈÄâÔºâ
      - ACCESS_USERNAME=admin
      - ACCESS_PASSWORD=your_password
```
&lt;/details&gt;

### 7. MCP Server ‰ΩøÁî®ËØ¥Êòé
&lt;details&gt;
&lt;summary&gt;ÁÇπÂáªÊü•Áúã MCP Server ‰ΩøÁî®ËØ¥Êòé&lt;/summary&gt;

Prompt Optimizer Áé∞Âú®ÊîØÊåÅ Model Context Protocol (MCP) ÂçèËÆÆÔºåÂèØ‰ª•‰∏é Claude Desktop Á≠âÊîØÊåÅ MCP ÁöÑ AI Â∫îÁî®ÈõÜÊàê„ÄÇ

ÂΩìÈÄöËøá Docker ËøêË°åÊó∂ÔºåMCP Server ‰ºöËá™Âä®ÂêØÂä®ÔºåÂπ∂ÂèØÈÄöËøá `http://ip:port/mcp` ËÆøÈóÆ„ÄÇ

#### ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ

MCP Server ÈúÄË¶ÅÈÖçÁΩÆ API ÂØÜÈí•ÊâçËÉΩÊ≠£Â∏∏Â∑•‰Ωú„ÄÇ‰∏ªË¶ÅÁöÑ MCP ‰∏ìÂ±ûÈÖçÁΩÆÔºö

```bash
# MCP ÊúçÂä°Âô®ÈÖçÁΩÆ
MCP_DEFAULT_MODEL_PROVIDER=openai  # ÂèØÈÄâÂÄºÔºöopenai, gemini, deepseek, siliconflow, zhipu, custom
MCP_LOG_LEVEL=info                 # Êó•ÂøóÁ∫ßÂà´
```

#### Docker ÁéØÂ¢É‰∏ã‰ΩøÁî® MCP

Âú® Docker ÁéØÂ¢É‰∏≠ÔºåMCP Server ‰ºö‰∏é Web Â∫îÁî®‰∏ÄËµ∑ËøêË°åÔºåÊÇ®ÂèØ‰ª•ÈÄöËøá Web Â∫îÁî®ÁöÑÁõ∏ÂêåÁ´ØÂè£ËÆøÈóÆ MCP ÊúçÂä°ÔºåË∑ØÂæÑ‰∏∫ `/mcp`„ÄÇ

‰æãÂ¶ÇÔºåÂ¶ÇÊûúÊÇ®Â∞ÜÂÆπÂô®ÁöÑ 80 Á´ØÂè£Êò†Â∞ÑÂà∞‰∏ªÊú∫ÁöÑ 8081 Á´ØÂè£Ôºö
```bash
docker run -d -p 8081:80 \
  -e VITE_OPENAI_API_KEY=your-openai-key \
  -e MCP_DEFAULT_MODEL_PROVIDER=openai \
  --name prompt-optimizer \
  linshen/prompt-optimizer
```

ÈÇ£‰πà MCP Server Â∞ÜÂèØ‰ª•ÈÄöËøá `http://localhost:8081/mcp` ËÆøÈóÆ„ÄÇ

#### Claude Desktop ÈõÜÊàêÁ§∫‰æã

Ë¶ÅÂú® Claude Desktop ‰∏≠‰ΩøÁî® Prompt OptimizerÔºåÊÇ®ÈúÄË¶ÅÂú® Claude Desktop ÁöÑÈÖçÁΩÆÊñá‰ª∂‰∏≠Ê∑ªÂä†ÊúçÂä°ÈÖçÁΩÆ„ÄÇ

1. ÊâæÂà∞ Claude Desktop ÁöÑÈÖçÁΩÆÁõÆÂΩïÔºö
   - Windows: `%APPDATA%\Claude\services`
   - macOS: `~/Library/Application Support/Claude/services`
   - Linux: `~/.config/Claude/services`

2. ÁºñËæëÊàñÂàõÂª∫ `services.json` Êñá‰ª∂ÔºåÊ∑ªÂä†‰ª•‰∏ãÂÜÖÂÆπÔºö

```json
{
  &quot;services&quot;: [
    {
      &quot;name&quot;: &quot;Prompt Optimizer&quot;,
      &quot;url&quot;: &quot;http://localhost:8081/mcp&quot;
    }
  ]
}
```

ËØ∑Á°Æ‰øùÂ∞Ü `localhost:8081` ÊõøÊç¢‰∏∫ÊÇ®ÂÆûÈôÖÈÉ®ÁΩ≤ Prompt Optimizer ÁöÑÂú∞ÂùÄÂíåÁ´ØÂè£„ÄÇ

#### ÂèØÁî®Â∑•ÂÖ∑

- **optimize-user-prompt**: ‰ºòÂåñÁî®Êà∑ÊèêÁ§∫ËØç‰ª•ÊèêÈ´ò LLM ÊÄßËÉΩ
- **optimize-system-prompt**: ‰ºòÂåñÁ≥ªÁªüÊèêÁ§∫ËØç‰ª•ÊèêÈ´ò LLM ÊÄßËÉΩ
- **iterate-prompt**: ÂØπÂ∑≤ÁªèÊàêÁÜü/ÂÆåÂñÑÁöÑÊèêÁ§∫ËØçËøõË°åÂÆöÂêëËø≠‰ª£‰ºòÂåñ

Êõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑Êü•Áúã [MCP ÊúçÂä°Âô®Áî®Êà∑ÊåáÂçó](docs/user/mcp-server.md)„ÄÇ
&lt;/details&gt;

## ‚öôÔ∏è APIÂØÜÈí•ÈÖçÁΩÆ

&lt;details&gt;
&lt;summary&gt;ÁÇπÂáªÊü•ÁúãAPIÂØÜÈí•ÈÖçÁΩÆÊñπÊ≥ï&lt;/summary&gt;

### ÊñπÂºè‰∏ÄÔºöÈÄöËøáÁïåÈù¢ÈÖçÁΩÆÔºàÊé®ËçêÔºâ
1. ÁÇπÂáªÁïåÈù¢Âè≥‰∏äËßíÁöÑ&quot;‚öôÔ∏èËÆæÁΩÆ&quot;ÊåâÈíÆ
2. ÈÄâÊã©&quot;Ê®°ÂûãÁÆ°ÁêÜ&quot;ÈÄâÈ°πÂç°
3. ÁÇπÂáªÈúÄË¶ÅÈÖçÁΩÆÁöÑÊ®°ÂûãÔºàÂ¶ÇOpenAI„ÄÅGemini„ÄÅDeepSeekÁ≠âÔºâ
4. Âú®ÂºπÂá∫ÁöÑÈÖçÁΩÆÊ°Ü‰∏≠ËæìÂÖ•ÂØπÂ∫îÁöÑAPIÂØÜÈí•
5. ÁÇπÂáª&quot;‰øùÂ≠ò&quot;Âç≥ÂèØ

ÊîØÊåÅÁöÑÊ®°ÂûãÔºöOpenAI„ÄÅGemini„ÄÅDeepSeek„ÄÅZhipuÊô∫Ë∞±„ÄÅSiliconFlow„ÄÅËá™ÂÆö‰πâAPIÔºàOpenAIÂÖºÂÆπÊé•Âè£Ôºâ

Èô§‰∫ÜAPIÂØÜÈí•ÔºåÊÇ®ËøòÂèØ‰ª•Âú®Ê®°ÂûãÈÖçÁΩÆÁïåÈù¢‰∏∫ÊØè‰∏™Ê®°ÂûãÂçïÁã¨ËÆæÁΩÆÈ´òÁ∫ßLLMÂèÇÊï∞„ÄÇËøô‰∫õÂèÇÊï∞ÈÄöËøá‰∏Ä‰∏™Âêç‰∏∫ `llmParams` ÁöÑÂ≠óÊÆµËøõË°åÈÖçÁΩÆÔºåÂÆÉÂÖÅËÆ∏ÊÇ®‰ª•ÈîÆÂÄºÂØπÁöÑÂΩ¢ÂºèÊåáÂÆöLLM SDKÊîØÊåÅÁöÑ‰ªª‰ΩïÂèÇÊï∞Ôºå‰ªéËÄåÊõ¥Á≤æÁªÜÂú∞ÊéßÂà∂Ê®°ÂûãË°å‰∏∫„ÄÇ

**È´òÁ∫ßLLMÂèÇÊï∞ÈÖçÁΩÆÁ§∫‰æãÔºö**
- **OpenAI/ÂÖºÂÆπAPI**: `{&quot;temperature&quot;: 0.7, &quot;max_tokens&quot;: 4096, &quot;timeout&quot;: 60000}`
- **Gemini**: `{&quot;temperature&quot;: 0.8, &quot;maxOutputTokens&quot;: 2048, &quot;topP&quot;: 0.95}`
- **DeepSeek**: `{&quot;temperature&quot;: 0.5, &quot;top_p&quot;: 0.9, &quot;frequency_penalty&quot;: 0.1}`

ÊúâÂÖ≥ `llmParams` ÁöÑÊõ¥ËØ¶ÁªÜËØ¥ÊòéÂíåÈÖçÁΩÆÊåáÂçóÔºåËØ∑ÂèÇÈòÖ [LLMÂèÇÊï∞ÈÖçÁΩÆÊåáÂçó](docs/developer/llm-params-guide.md)„ÄÇ

### ÊñπÂºè‰∫åÔºöÈÄöËøáÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ
DockerÈÉ®ÁΩ≤Êó∂ÈÄöËøá `-e` ÂèÇÊï∞ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáèÔºö

```bash
-e VITE_OPENAI_API_KEY=your_key
-e VITE_GEMINI_API_KEY=your_key
-e VITE_DEEPSEEK_API_KEY=your_key
-e VITE_ZHIPU_API_KEY=your_key
-e VITE_SILICONFLOW_API_KEY=your_key

# Â§öËá™ÂÆö‰πâÊ®°ÂûãÈÖçÁΩÆÔºàÊîØÊåÅÊó†ÈôêÊï∞ÈáèÔºâ
-e VITE_CUSTOM_API_KEY_ollama=dummy_key
-e VITE_CUSTOM_API_BASE_URL_ollama=http://localhost:11434/v1
-e VITE_CUSTOM_API_MODEL_ollama=qwen2.5:7b
```

&gt; üìñ **ËØ¶ÁªÜÈÖçÁΩÆÊåáÂçó**: Êü•Áúã [Â§öËá™ÂÆö‰πâÊ®°ÂûãÈÖçÁΩÆÊñáÊ°£](./docs/user/multi-custom-models.md) ‰∫ÜËß£ÂÆåÊï¥ÁöÑÈÖçÁΩÆÊñπÊ≥ïÂíåÈ´òÁ∫ßÁî®Ê≥ï

&lt;/details&gt;

## Êú¨Âú∞ÂºÄÂèë
ËØ¶ÁªÜÊñáÊ°£ÂèØÊü•Áúã [ÂºÄÂèëÊñáÊ°£](dev.md)

&lt;details&gt;
&lt;summary&gt;ÁÇπÂáªÊü•ÁúãÊú¨Âú∞ÂºÄÂèëÂëΩ‰ª§&lt;/summary&gt;

```bash
# 1. ÂÖãÈöÜÈ°πÁõÆ
git clone https://github.com/linshenkx/prompt-optimizer.git
cd prompt-optimizer

# 2. ÂÆâË£Ö‰æùËµñ
pnpm install

# 3. ÂêØÂä®ÂºÄÂèëÊúçÂä°
pnpm dev               # ‰∏ªÂºÄÂèëÂëΩ‰ª§ÔºöÊûÑÂª∫core/uiÂπ∂ËøêË°åwebÂ∫îÁî®
pnpm dev:web          # ‰ªÖËøêË°åwebÂ∫îÁî®
pnpm dev:fresh        # ÂÆåÊï¥ÈáçÁΩÆÂπ∂ÈáçÊñ∞ÂêØÂä®ÂºÄÂèëÁéØÂ¢É
```
&lt;/details&gt;

## üó∫Ô∏è ÂºÄÂèëË∑ØÁ∫ø

- [x] Âü∫Á°ÄÂäüËÉΩÂºÄÂèë
- [x] WebÂ∫îÁî®ÂèëÂ∏É
- [x] ChromeÊèí‰ª∂ÂèëÂ∏É
- [x] ÂõΩÈôÖÂåñÊîØÊåÅ
- [x] ÊîØÊåÅÁ≥ªÁªüÊèêÁ§∫ËØç‰ºòÂåñÂíåÁî®Êà∑ÊèêÁ§∫ËØç‰ºòÂåñ
- [x] Ê°åÈù¢Â∫îÁî®ÂèëÂ∏É
- [x] mcpÊúçÂä°ÂèëÂ∏É

ËØ¶ÁªÜÁöÑÈ°πÁõÆÁä∂ÊÄÅÂèØÊü•Áúã [È°πÁõÆÁä∂ÊÄÅÊñáÊ°£](docs/project-status.md)

## üìñ Áõ∏ÂÖ≥ÊñáÊ°£

- [ÊñáÊ°£Á¥¢Âºï](docs/README.md) - ÊâÄÊúâÊñáÊ°£ÁöÑÁ¥¢Âºï
- [ÊäÄÊúØÂºÄÂèëÊåáÂçó](docs/developer/technical-development-guide.md) - ÊäÄÊúØÊ†àÂíåÂºÄÂèëËßÑËåÉ
- [LLMÂèÇÊï∞ÈÖçÁΩÆÊåáÂçó](docs/developer/llm-params-guide.md) - È´òÁ∫ßLLMÂèÇÊï∞ÈÖçÁΩÆËØ¶ÁªÜËØ¥Êòé
- [È°πÁõÆÁªìÊûÑ](docs/developer/project-structure.md) - ËØ¶ÁªÜÁöÑÈ°πÁõÆÁªìÊûÑËØ¥Êòé
- [È°πÁõÆÁä∂ÊÄÅ](docs/project/project-status.md) - ÂΩìÂâçËøõÂ∫¶ÂíåËÆ°Âàí
- [‰∫ßÂìÅÈúÄÊ±Ç](docs/project/prd.md) - ‰∫ßÂìÅÈúÄÊ±ÇÊñáÊ°£
- [VercelÈÉ®ÁΩ≤ÊåáÂçó](docs/user/deployment/vercel.md) - VercelÈÉ®ÁΩ≤ËØ¶ÁªÜËØ¥Êòé


## Star History

&lt;a href=&quot;https://star-history.com/#linshenkx/prompt-optimizer&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## Â∏∏ËßÅÈóÆÈ¢ò

&lt;details&gt;
&lt;summary&gt;ÁÇπÂáªÊü•ÁúãÂ∏∏ËßÅÈóÆÈ¢òËß£Á≠î&lt;/summary&gt;

### APIËøûÊé•ÈóÆÈ¢ò

#### Q1: ‰∏∫‰ªÄ‰πàÈÖçÁΩÆÂ•ΩAPIÂØÜÈí•Âêé‰ªçÁÑ∂Êó†Ê≥ïËøûÊé•Âà∞Ê®°ÂûãÊúçÂä°Ôºü
**A**: Â§ßÂ§öÊï∞ËøûÊé•Â§±Ë¥•ÊòØÁî±**Ë∑®ÂüüÈóÆÈ¢ò**ÔºàCORSÔºâÂØºËá¥ÁöÑ„ÄÇÁî±‰∫éÊú¨È°πÁõÆÊòØÁ∫ØÂâçÁ´ØÂ∫îÁî®ÔºåÊµèËßàÂô®Âá∫‰∫éÂÆâÂÖ®ËÄÉËôë‰ºöÈòªÊ≠¢Áõ¥Êé•ËÆøÈóÆ‰∏çÂêåÊ∫êÁöÑAPIÊúçÂä°„ÄÇÊ®°ÂûãÊúçÂä°Â¶ÇÊú™Ê≠£Á°ÆÈÖçÁΩÆCORSÁ≠ñÁï•Ôºå‰ºöÊãíÁªùÊù•Ëá™ÊµèËßàÂô®ÁöÑÁõ¥Êé•ËØ∑Ê±Ç„ÄÇ

#### Q2: Â¶Ç‰ΩïËß£ÂÜ≥Êú¨Âú∞OllamaÁöÑËøûÊé•ÈóÆÈ¢òÔºü
**A**: OllamaÂÆåÂÖ®ÊîØÊåÅOpenAIÊ†áÂáÜÊé•Âè£ÔºåÂè™ÈúÄÈÖçÁΩÆÊ≠£Á°ÆÁöÑË∑®ÂüüÁ≠ñÁï•Ôºö
1. ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè `OLLAMA_ORIGINS=*` ÂÖÅËÆ∏‰ªªÊÑèÊù•Ê∫êÁöÑËØ∑Ê±Ç
2. Â¶Ç‰ªçÊúâÈóÆÈ¢òÔºåËÆæÁΩÆ `OLLAMA_HOST=0.0.0.0:11434` ÁõëÂê¨‰ªªÊÑèIPÂú∞ÂùÄ

#### Q3: Â¶Ç‰ΩïËß£ÂÜ≥ÂïÜ‰∏öAPIÔºàÂ¶ÇNvidiaÁöÑDS API„ÄÅÂ≠óËäÇË∑≥Âä®ÁöÑÁÅ´Â±±APIÔºâÁöÑË∑®ÂüüÈóÆÈ¢òÔºü
**A**: Ëøô‰∫õÂπ≥Âè∞ÈÄöÂ∏∏Êúâ‰∏•Ê†ºÁöÑË∑®ÂüüÈôêÂà∂ÔºåÊé®Ëçê‰ª•‰∏ãËß£ÂÜ≥ÊñπÊ°àÔºö

1. **‰ΩøÁî®Vercel‰ª£ÁêÜ**Ôºà‰æøÊç∑ÊñπÊ°àÔºâ
   - ‰ΩøÁî®Âú®Á∫øÁâàÊú¨Ôºö[prompt.always200.com](https://prompt.always200.com)
   - ÊàñËá™Ë°åÈÉ®ÁΩ≤Âà∞VercelÂπ≥Âè∞
   - Âú®Ê®°ÂûãËÆæÁΩÆ‰∏≠ÂãæÈÄâ&quot;‰ΩøÁî®Vercel‰ª£ÁêÜ&quot;ÈÄâÈ°π
   - ËØ∑Ê±ÇÊµÅÂêëÔºöÊµèËßàÂô®‚ÜíVercel‚ÜíÊ®°ÂûãÊúçÂä°Êèê‰æõÂïÜ
   - ËØ¶ÁªÜÊ≠•È™§ËØ∑ÂèÇËÄÉ [VercelÈÉ®ÁΩ≤ÊåáÂçó](docs/user/deployment/vercel.md)

2. **‰ΩøÁî®Ëá™ÈÉ®ÁΩ≤ÁöÑAPI‰∏≠ËΩ¨ÊúçÂä°**ÔºàÂèØÈù†ÊñπÊ°àÔºâ
   - ÈÉ®ÁΩ≤Â¶ÇOneAPIÁ≠âÂºÄÊ∫êAPIËÅöÂêà/‰ª£ÁêÜÂ∑•ÂÖ∑
   - Âú®ËÆæÁΩÆ‰∏≠ÈÖçÁΩÆ‰∏∫Ëá™ÂÆö‰πâAPIÁ´ØÁÇπ
   - ËØ∑Ê±ÇÊµÅÂêëÔºöÊµèËßàÂô®‚Üí‰∏≠ËΩ¨ÊúçÂä°‚ÜíÊ®°ÂûãÊúçÂä°Êèê‰æõÂïÜ

#### Q4: Vercel‰ª£ÁêÜÊúâ‰ªÄ‰πàÁº∫ÁÇπÊàñÈ£éÈô©Ôºü
**A**: ‰ΩøÁî®Vercel‰ª£ÁêÜÂèØËÉΩ‰ºöËß¶ÂèëÊüê‰∫õÊ®°ÂûãÊúçÂä°Êèê‰æõÂïÜÁöÑÈ£éÊéßÊú∫Âà∂„ÄÇÈÉ®ÂàÜÂéÇÂïÜÂèØËÉΩ‰ºöÂ∞ÜÊù•Ëá™VercelÁöÑËØ∑Ê±ÇÂà§ÂÆö‰∏∫‰ª£ÁêÜË°å‰∏∫Ôºå‰ªéËÄåÈôêÂà∂ÊàñÊãíÁªùÊúçÂä°„ÄÇÂ¶ÇÈÅáÊ≠§ÈóÆÈ¢òÔºåÂª∫ËÆÆ‰ΩøÁî®Ëá™ÈÉ®ÁΩ≤ÁöÑ‰∏≠ËΩ¨ÊúçÂä°„ÄÇ

#### Q5: ÊàëÂ∑≤Ê≠£Á°ÆÈÖçÁΩÆÊú¨Âú∞Ê®°ÂûãÔºàÂ¶ÇOllamaÔºâÁöÑË∑®ÂüüÁ≠ñÁï•Ôºå‰∏∫‰ªÄ‰πà‰ΩøÁî®Âú®Á∫øÁâà‰æùÁÑ∂Êó†Ê≥ïËøûÊé•Ôºü
**A**: ËøôÊòØÁî±ÊµèËßàÂô®ÁöÑ**Ê∑∑ÂêàÂÜÖÂÆπÔºàMixed ContentÔºâÂÆâÂÖ®Á≠ñÁï•**ÂØºËá¥ÁöÑ„ÄÇÂá∫‰∫éÂÆâÂÖ®ËÄÉËôëÔºåÊµèËßàÂô®‰ºöÈòªÊ≠¢ÂÆâÂÖ®ÁöÑHTTPSÈ°µÈù¢ÔºàÂ¶ÇÂú®Á∫øÁâàÔºâÂêë‰∏çÂÆâÂÖ®ÁöÑHTTPÂú∞ÂùÄÔºàÂ¶ÇÊÇ®ÁöÑÊú¨Âú∞OllamaÊúçÂä°ÔºâÂèëÈÄÅËØ∑Ê±Ç„ÄÇ

**Ëß£ÂÜ≥ÊñπÊ°à**Ôºö
‰∏∫‰∫ÜÁªïËøáÊ≠§ÈôêÂà∂ÔºåÊÇ®ÈúÄË¶ÅËÆ©Â∫îÁî®ÂíåAPIÂ§Ñ‰∫éÂêå‰∏ÄÁßçÂçèËÆÆ‰∏ãÔºà‰æãÂ¶ÇÔºåÈÉΩÊòØHTTPÔºâ„ÄÇÊé®Ëçê‰ª•‰∏ãÂá†ÁßçÊñπÂºèÔºö
1. **‰ΩøÁî®Ê°åÈù¢Áâà**ÔºöÊ°åÈù¢Â∫îÁî®Ê≤°ÊúâÊµèËßàÂô®ÈôêÂà∂ÔºåÊòØËøûÊé•Êú¨Âú∞Ê®°ÂûãÊúÄÁ®≥ÂÆöÂèØÈù†ÁöÑÊñπÂºè„ÄÇ
2. **dockerÈÉ®ÁΩ≤**ÔºödockerÈÉ®ÁΩ≤‰πüÊòØhttp
3. **‰ΩøÁî®ChromeÊèí‰ª∂**ÔºöÊèí‰ª∂Âú®Êüê‰∫õÊÉÖÂÜµ‰∏ã‰πüÂèØ‰ª•ÁªïËøáÈÉ®ÂàÜÂÆâÂÖ®ÈôêÂà∂„ÄÇ

&lt;/details&gt;


## ü§ù ÂèÇ‰∏éË¥°ÁåÆ

&lt;details&gt;
&lt;summary&gt;ÁÇπÂáªÊü•ÁúãË¥°ÁåÆÊåáÂçó&lt;/summary&gt;

1. Fork Êú¨‰ªìÂ∫ì
2. ÂàõÂª∫ÁâπÊÄßÂàÜÊîØ (`git checkout -b feature/AmazingFeature`)
3. Êèê‰∫§Êõ¥Êîπ (`git commit -m &#039;Ê∑ªÂä†Êüê‰∏™ÁâπÊÄß&#039;`)
4. Êé®ÈÄÅÂà∞ÂàÜÊîØ (`git push origin feature/AmazingFeature`)
5. Êèê‰∫§ Pull Request

ÊèêÁ§∫Ôºö‰ΩøÁî®cursorÂ∑•ÂÖ∑ÂºÄÂèëÊó∂ÔºåÂª∫ËÆÆÂú®Êèê‰∫§Ââç:
1. ‰ΩøÁî®&quot;code_review&quot;ËßÑÂàôËøõË°å‰ª£Á†ÅÂÆ°Êü•
2. ÊåâÁÖßÂÆ°Êü•Êä•ÂëäÊ†ºÂºèÊ£ÄÊü•:
   - ÂèòÊõ¥ÁöÑÊï¥‰Ωì‰∏ÄËá¥ÊÄß
   - ‰ª£Á†ÅË¥®ÈáèÂíåÂÆûÁé∞ÊñπÂºè
   - ÊµãËØïË¶ÜÁõñÊÉÖÂÜµ
   - ÊñáÊ°£ÂÆåÂñÑÁ®ãÂ∫¶
3. Ê†πÊçÆÂÆ°Êü•ÁªìÊûúËøõË°å‰ºòÂåñÂêéÂÜçÊèê‰∫§

&lt;/details&gt;

## üëè Ë¥°ÁåÆËÄÖÂêçÂçï

ÊÑüË∞¢ÊâÄÊúâ‰∏∫È°πÁõÆÂÅöÂá∫Ë¥°ÁåÆÁöÑÂºÄÂèëËÄÖÔºÅ

&lt;a href=&quot;https://github.com/linshenkx/prompt-optimizer/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=linshenkx/prompt-optimizer&quot; alt=&quot;Ë¥°ÁåÆËÄÖ&quot; /&gt;
&lt;/a&gt;

## üìÑ ÂºÄÊ∫êÂçèËÆÆ

Êú¨È°πÁõÆÈááÁî® [MIT](LICENSE) ÂçèËÆÆÂºÄÊ∫ê„ÄÇ

---

Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåËØ∑ËÄÉËôëÁªôÂÆÉ‰∏Ä‰∏™ Star ‚≠êÔ∏è

## üë• ËÅîÁ≥ªÊàë‰ª¨

- Êèê‰∫§ Issue
- ÂèëËµ∑ Pull Request
- Âä†ÂÖ•ËÆ®ËÆ∫ÁªÑ</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[humanlayer/12-factor-agents]]></title>
            <link>https://github.com/humanlayer/12-factor-agents</link>
            <guid>https://github.com/humanlayer/12-factor-agents</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[What are the principles we can use to build LLM-powered software that is actually good enough to put in the hands of production customers?]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/humanlayer/12-factor-agents">humanlayer/12-factor-agents</a></h1>
            <p>What are the principles we can use to build LLM-powered software that is actually good enough to put in the hands of production customers?</p>
            <p>Language: TypeScript</p>
            <p>Stars: 13,277</p>
            <p>Forks: 939</p>
            <p>Stars today: 106 stars today</p>
            <h2>README</h2><pre># 12-Factor Agents - Principles for building reliable LLM applications

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.apache.org/licenses/LICENSE-2.0&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/Code-Apache%202.0-blue.svg&quot; alt=&quot;Code License: Apache 2.0&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/Content-CC%20BY--SA%204.0-lightgrey.svg&quot; alt=&quot;Content License: CC BY-SA 4.0&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://humanlayer.dev/discord&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/chat-discord-5865F2&quot; alt=&quot;Discord Server&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://www.youtube.com/watch?v=8kMaTybvDUw&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/aidotengineer-conf_talk_(17m)-white&quot; alt=&quot;YouTube
Deep Dive&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://www.youtube.com/watch?v=yxJDyQ8v6P0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/youtube-deep_dive-crimson&quot; alt=&quot;YouTube
Deep Dive&quot;&gt;&lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;&lt;/p&gt;

*In the spirit of [12 Factor Apps](https://12factor.net/)*.  *The source for this project is public at https://github.com/humanlayer/12-factor-agents, and I welcome your feedback and contributions. Let&#039;s figure this out together!*

&gt; [!TIP]
&gt; Missed the AI Engineer World&#039;s Fair? [Catch the talk here](https://www.youtube.com/watch?v=8kMaTybvDUw)
&gt;
&gt; Looking for Context Engineering? [Jump straight to factor 3](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-03-own-your-context-window.md)
&gt;
&gt; Want to contribute to `npx/uvx create-12-factor-agent` - check out [the discussion thread](https://github.com/humanlayer/12-factor-agents/discussions/61)


&lt;img referrerpolicy=&quot;no-referrer-when-downgrade&quot; src=&quot;https://static.scarf.sh/a.png?x-pxid=2acad99a-c2d9-48df-86f5-9ca8061b7bf9&quot; /&gt;

&lt;a href=&quot;#visual-nav&quot;&gt;&lt;img width=&quot;907&quot; alt=&quot;Screenshot 2025-04-03 at 2 49 07‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/23286ad8-7bef-4902-b371-88ff6a22e998&quot; /&gt;&lt;/a&gt;


Hi, I&#039;m Dex. I&#039;ve been [hacking](https://youtu.be/8bIHcttkOTE) on [AI agents](https://theouterloop.substack.com) for [a while](https://humanlayer.dev). 


**I&#039;ve tried every agent framework out there**, from the plug-and-play crew/langchains to the &quot;minimalist&quot; smolagents of the world to the &quot;production grade&quot; langraph, griptape, etc. 

**I&#039;ve talked to a lot of really strong founders**, in and out of YC, who are all building really impressive things with AI. Most of them are rolling the stack themselves. I don&#039;t see a lot of frameworks in production customer-facing agents.

**I&#039;ve been surprised to find** that most of the products out there billing themselves as &quot;AI Agents&quot; are not all that agentic. A lot of them are mostly deterministic code, with LLM steps sprinkled in at just the right points to make the experience truly magical.

Agents, at least the good ones, don&#039;t follow the [&quot;here&#039;s your prompt, here&#039;s a bag of tools, loop until you hit the goal&quot;](https://www.anthropic.com/engineering/building-effective-agents#agents) pattern. Rather, they are comprised of mostly just software. 

So, I set out to answer:

&gt; ### **What are the principles we can use to build LLM-powered software that is actually good enough to put in the hands of production customers?**

Welcome to 12-factor agents. As every Chicago mayor since Daley has consistently plastered all over the city&#039;s major airports, we&#039;re glad you&#039;re here.

*Special thanks to [@iantbutler01](https://github.com/iantbutler01), [@tnm](https://github.com/tnm), [@hellovai](https://www.github.com/hellovai), [@stantonk](https://www.github.com/stantonk), [@balanceiskey](https://www.github.com/balanceiskey), [@AdjectiveAllison](https://www.github.com/AdjectiveAllison), [@pfbyjy](https://www.github.com/pfbyjy), [@a-churchill](https://www.github.com/a-churchill), and the SF MLOps community for early feedback on this guide.*

## The Short Version: The 12 Factors

Even if LLMs [continue to get exponentially more powerful](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-10-small-focused-agents.md#what-if-llms-get-smarter), there will be core engineering techniques that make LLM-powered software more reliable, more scalable, and easier to maintain.

- [How We Got Here: A Brief History of Software](https://github.com/humanlayer/12-factor-agents/blob/main/content/brief-history-of-software.md)
- [Factor 1: Natural Language to Tool Calls](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-01-natural-language-to-tool-calls.md)
- [Factor 2: Own your prompts](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-02-own-your-prompts.md)
- [Factor 3: Own your context window](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-03-own-your-context-window.md)
- [Factor 4: Tools are just structured outputs](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-04-tools-are-structured-outputs.md)
- [Factor 5: Unify execution state and business state](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-05-unify-execution-state.md)
- [Factor 6: Launch/Pause/Resume with simple APIs](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-06-launch-pause-resume.md)
- [Factor 7: Contact humans with tool calls](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-07-contact-humans-with-tools.md)
- [Factor 8: Own your control flow](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-08-own-your-control-flow.md)
- [Factor 9: Compact Errors into Context Window](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-09-compact-errors.md)
- [Factor 10: Small, Focused Agents](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-10-small-focused-agents.md)
- [Factor 11: Trigger from anywhere, meet users where they are](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-11-trigger-from-anywhere.md)
- [Factor 12: Make your agent a stateless reducer](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-12-stateless-reducer.md)

### Visual Nav

|    |    |    |
|----|----|-----|
|[![factor 1](https://github.com/humanlayer/12-factor-agents/blob/main/img/110-natural-language-tool-calls.png)](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-01-natural-language-to-tool-calls.md) | [![factor 2](https://github.com/humanlayer/12-factor-agents/blob/main/img/120-own-your-prompts.png)](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-02-own-your-prompts.md) | [![factor 3](https://github.com/humanlayer/12-factor-agents/blob/main/img/130-own-your-context-building.png)](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-03-own-your-context-window.md) |
|[![factor 4](https://github.com/humanlayer/12-factor-agents/blob/main/img/140-tools-are-just-structured-outputs.png)](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-04-tools-are-structured-outputs.md) | [![factor 5](https://github.com/humanlayer/12-factor-agents/blob/main/img/150-unify-state.png)](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-05-unify-execution-state.md) | [![factor 6](https://github.com/humanlayer/12-factor-agents/blob/main/img/160-pause-resume-with-simple-apis.png)](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-06-launch-pause-resume.md) |
| [![factor 7](https://github.com/humanlayer/12-factor-agents/blob/main/img/170-contact-humans-with-tools.png)](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-07-contact-humans-with-tools.md) | [![factor 8](https://github.com/humanlayer/12-factor-agents/blob/main/img/180-control-flow.png)](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-08-own-your-control-flow.md) | [![factor 9](https://github.com/humanlayer/12-factor-agents/blob/main/img/190-factor-9-errors-static.png)](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-09-compact-errors.md) |
| [![factor 10](https://github.com/humanlayer/12-factor-agents/blob/main/img/1a0-small-focused-agents.png)](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-10-small-focused-agents.md) | [![factor 11](https://github.com/humanlayer/12-factor-agents/blob/main/img/1b0-trigger-from-anywhere.png)](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-11-trigger-from-anywhere.md) | [![factor 12](https://github.com/humanlayer/12-factor-agents/blob/main/img/1c0-stateless-reducer.png)](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-12-stateless-reducer.md) |

## How we got here

For a deeper dive on my agent journey and what led us here, check out [A Brief History of Software](https://github.com/humanlayer/12-factor-agents/blob/main/content/brief-history-of-software.md) - a quick summary here:

### The promise of agents

We&#039;re gonna talk a lot about Directed Graphs (DGs) and their Acyclic friends, DAGs. I&#039;ll start by pointing out that...well...software is a directed graph. There&#039;s a reason we used to represent programs as flow charts.

![010-software-dag](https://github.com/humanlayer/12-factor-agents/blob/main/img/010-software-dag.png)

### From code to DAGs

Around 20 years ago, we started to see DAG orchestrators become popular. We&#039;re talking classics like [Airflow](https://airflow.apache.org/), [Prefect](https://www.prefect.io/), some predecessors, and some newer ones like ([dagster](https://dagster.io/), [inggest](https://www.inngest.com/), [windmill](https://www.windmill.dev/)). These followed the same graph pattern, with the added benefit of observability, modularity, retries, administration, etc.

![015-dag-orchestrators](https://github.com/humanlayer/12-factor-agents/blob/main/img/015-dag-orchestrators.png)

### The promise of agents

I&#039;m not the first [person to say this](https://youtu.be/Dc99-zTMyMg?si=bcT0hIwWij2mR-40&amp;t=73), but my biggest takeaway when I started learning about agents, was that you get to throw the DAG away. Instead of software engineers coding each step and edge case, you can give the agent a goal and a set of transitions:

![025-agent-dag](https://github.com/humanlayer/12-factor-agents/blob/main/img/025-agent-dag.png)

And let the LLM make decisions in real time to figure out the path

![026-agent-dag-lines](https://github.com/humanlayer/12-factor-agents/blob/main/img/026-agent-dag-lines.png)

The promise here is that you write less software, you just give the LLM the &quot;edges&quot; of the graph and let it figure out the nodes. You can recover from errors, you can write less code, and you may find that LLMs find novel solutions to problems.


### Agents as loops

As we&#039;ll see later, it turns out this doesn&#039;t quite work.

Let&#039;s dive one step deeper - with agents you&#039;ve got this loop consisting of 3 steps:

1. LLM determines the next step in the workflow, outputting structured json (&quot;tool calling&quot;)
2. Deterministic code executes the tool call
3. The result is appended to the context window 
4. Repeat until the next step is determined to be &quot;done&quot;

```python
initial_event = {&quot;message&quot;: &quot;...&quot;}
context = [initial_event]
while True:
  next_step = await llm.determine_next_step(context)
  context.append(next_step)

  if (next_step.intent === &quot;done&quot;):
    return next_step.final_answer

  result = await execute_step(next_step)
  context.append(result)
```

Our initial context is just the starting event (maybe a user message, maybe a cron fired, maybe a webhook, etc), and we ask the llm to choose the next step (tool) or to determine that we&#039;re done.

Here&#039;s a multi-step example:

[![027-agent-loop-animation](https://github.com/humanlayer/12-factor-agents/blob/main/img/027-agent-loop-animation.gif)](https://github.com/user-attachments/assets/3beb0966-fdb1-4c12-a47f-ed4e8240f8fd)

&lt;details&gt;
&lt;summary&gt;&lt;a href=&quot;https://github.com/humanlayer/12-factor-agents/blob/main/img/027-agent-loop-animation.gif&quot;&gt;GIF Version&lt;/a&gt;&lt;/summary&gt;

![027-agent-loop-animation](https://github.com/humanlayer/12-factor-agents/blob/main/img/027-agent-loop-animation.gif)]

&lt;/details&gt;

## Why 12-factor agents?

At the end of the day, this approach just doesn&#039;t work as well as we want it to.

In building HumanLayer, I&#039;ve talked to at least 100 SaaS builders (mostly technical founders) looking to make their existing product more agentic. The journey usually goes something like:

1. Decide you want to build an agent
2. Product design, UX mapping, what problems to solve
3. Want to move fast, so grab $FRAMEWORK and *get to building*
4. Get to 70-80% quality bar 
5. Realize that 80% isn&#039;t good enough for most customer-facing features
6. Realize that getting past 80% requires reverse-engineering the framework, prompts, flow, etc.
7. Start over from scratch

&lt;details&gt;
&lt;summary&gt;Random Disclaimers&lt;/summary&gt;

**DISCLAIMER**: I&#039;m not sure the exact right place to say this, but here seems as good as any: **this in BY NO MEANS meant to be a dig on either the many frameworks out there, or the pretty dang smart people who work on them**. They enable incredible things and have accelerated the AI ecosystem. 

I hope that one outcome of this post is that agent framework builders can learn from the journeys of myself and others, and make frameworks even better. 

Especially for builders who want to move fast but need deep control.

**DISCLAIMER 2**: I&#039;m not going to talk about MCP. I&#039;m sure you can see where it fits in.

**DISCLAIMER 3**: I&#039;m using mostly typescript, for [reasons](https://www.linkedin.com/posts/dexterihorthy_llms-typescript-aiagents-activity-7290858296679313408-Lh9e?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAA4oHTkByAiD-wZjnGsMBUL_JT6nyyhOh30) but all this stuff works in python or any other language you prefer. 


Anyways back to the thing...

&lt;/details&gt;

### Design Patterns for great LLM applications

After digging through hundreds of AI libriaries and working with dozens of founders, my instinct is this:

1. There are some core things that make agents great
2. Going all in on a framework and building what is essentially a greenfield rewrite may be counter-productive
3. There are some core principles that make agents great, and you will get most/all of them if you pull in a framework
4. BUT, the fastest way I&#039;ve seen for builders to get high-quality AI software in the hands of customers is to take small, modular concepts from agent building, and incorporate them into their existing product
5. These modular concepts from agents can be defined and applied by most skilled software engineers, even if they don&#039;t have an AI background

&gt; #### The fastest way I&#039;ve seen for builders to get good AI software in the hands of customers is to take small, modular concepts from agent building, and incorporate them into their existing product


## The 12 Factors (again)


- [How We Got Here: A Brief History of Software](https://github.com/humanlayer/12-factor-agents/blob/main/content/brief-history-of-software.md)
- [Factor 1: Natural Language to Tool Calls](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-01-natural-language-to-tool-calls.md)
- [Factor 2: Own your prompts](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-02-own-your-prompts.md)
- [Factor 3: Own your context window](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-03-own-your-context-window.md)
- [Factor 4: Tools are just structured outputs](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-04-tools-are-structured-outputs.md)
- [Factor 5: Unify execution state and business state](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-05-unify-execution-state.md)
- [Factor 6: Launch/Pause/Resume with simple APIs](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-06-launch-pause-resume.md)
- [Factor 7: Contact humans with tool calls](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-07-contact-humans-with-tools.md)
- [Factor 8: Own your control flow](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-08-own-your-control-flow.md)
- [Factor 9: Compact Errors into Context Window](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-09-compact-errors.md)
- [Factor 10: Small, Focused Agents](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-10-small-focused-agents.md)
- [Factor 11: Trigger from anywhere, meet users where they are](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-11-trigger-from-anywhere.md)
- [Factor 12: Make your agent a stateless reducer](https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-12-stateless-reducer.md)

## Honorable Mentions / other advice

- [Factor 13: Pre-fetch all the context you might need](https://github.com/humanlayer/12-factor-agents/blob/main/content/appendix-13-pre-fetch.md)

## Related Resources

- Contribute to this guide [here](https://github.com/humanlayer/12-factor-agents)
- [I talked about a lot of this on an episode of the Tool Use podcast](https://youtu.be/8bIHcttkOTE) in March 2025
- I write about some of this stuff at [The Outer Loop](https://theouterloop.substack.com)
- I do [webinars about Maximizing LLM Performance](https://github.com/hellovai/ai-that-works/tree/main) with [@hellovai](https://github.com/hellovai)
- We build OSS agents with this methodology under [got-agents/agents](https://github.com/got-agents/agents)
- We ignored all our own advice and built a [framework for running distributed agents in kubernetes](https://github.com/humanlayer/kubechain)
- Other links from this guide:
  - [12 Factor Apps](https://12factor.net)
  - [Building Effective Agents (Anthropic)](https://www.anthropic.com/engineering/building-effective-agents#agents)
  - [Prompts are Functions](https://thedataexchange.media/baml-revolution-in-ai-engineering/ )
  - [Library patterns: Why frameworks are evil](https://tomasp.net/blog/2015/library-frameworks/)
  - [The Wrong Abstraction](https://sandimetz.com/blog/2016/1/20/the-wrong-abstraction)
  - [Mailcrew Agent](https://github.com/dexhorthy/mailcrew)
  - [Mailcrew Demo Video](https://www.youtube.com/watch?v=f_cKnoPC_Oo)
  - [Chainlit Demo](https://x.com/chainlit_io/status/1858613325921480922)
  - [TypeScript for LLMs](https://www.linkedin.com/posts/dexterihorthy_llms-typescript-aiagents-activity-7290858296679313408-Lh9e)
  - [Schema Aligned Parsing](https://www.boundaryml.com/blog/schema-aligned-parsing)
  - [Function Calling vs Structured Outputs vs JSON Mode](https://www.vellum.ai/blog/when-should-i-use-function-calling-structured-outputs-or-json-mode)
  - [BAML on GitHub](https://github.com/boundaryml/baml)
  - [OpenAI JSON vs Function Calling](https://docs.llamaindex.ai/en/stable/examples/llm/openai_json_vs_function_calling/)
  - [Outer Loop Agents](https://theouterloop.substack.com/p/openais-realtime-api-is-a-step-towards)
  - [Airflow](https://airflow.apache.org/)
  - [Prefect](https://www.prefect.io/)
  - [Dagster](https://dagster.io/)
  - [Inngest](https://www.inngest.com/)
  - [Windmill](https://www.windmill.dev/)
  - [The AI Agent Index (MIT)](https://aiagentindex.mit.edu/)
  - [NotebookLM on Finding Model Capability Boundaries](https://open.substack.com/pub/swyx/p/notebooklm?selection=08e1187c-cfee-4c63-93c9-71216640a5f8)

## Contributors

Thanks to everyone who has contributed to 12-factor agents!

[&lt;img src=&quot;https://avatars.githubusercontent.com/u/3730605?v=4&amp;s=80&quot; width=&quot;80px&quot; alt=&quot;dexhorthy&quot; /&gt;](https://github.com/dexhorthy) [&lt;img src=&quot;https://avatars.githubusercontent.com/u/50557586?v=4&amp;s=80&quot; width=&quot;80px&quot; alt=&quot;Sypherd&quot; /&gt;](https://github.com/Sypherd) [&lt;img src=&quot;https://avatars.githubusercontent.com/u/66259401?v=4&amp;s=80&quot; width=&quot;80px&quot; alt=&quot;tofaramususa&quot; /&gt;](https://github.com/tofaramususa) [&lt;img src=&quot;https://avatars.githubusercontent.com/u/18105223?v=4&amp;s=80&quot; width=&quot;80px&quot; alt=&quot;a-churchill&quot; /&gt;](https://github.com/a-church

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[mayneyao/eidos]]></title>
            <link>https://github.com/mayneyao/eidos</link>
            <guid>https://github.com/mayneyao/eidos</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[An extensible framework for Personal Data Management.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mayneyao/eidos">mayneyao/eidos</a></h1>
            <p>An extensible framework for Personal Data Management.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,795</p>
            <p>Forks: 116</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>![eidos](/public/show/table-and-doc.webp)

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://eidos.space?home=1&quot;&gt;Home Page&lt;/a&gt; |
    &lt;a href=&quot;https://discord.gg/bsGMPDR23b&quot;&gt;Discord&lt;/a&gt; |
    &lt;a href=&quot;https://eidos.space/download&quot;&gt;Download&lt;/a&gt;
    &lt;p&gt;
    Eidos is an extensible framework for managing your personal data throughout your lifetime in one place.
    &lt;/p&gt;
&lt;/div&gt;

&gt; [!IMPORTANT]
&gt; Eidos sets a big goal in mind, but it is still in its early stages, and there is a lot of work to be done. You can give it a try, but I do not recommend using it for production purposes. If you&#039;re interested in this project, I recommend staying updated on its development. If you have an Early Access key, you&#039;ll receive an email notification when Eidos is officially released.

## Features

- Out-of-the-box Notion-like documents and databases
- Offline Support: Everything runs inside your local machine. Access your data without an internet connection. Data is stored locally for blazing-fast performance.
- AI Features: Deeply integrated with LLM for AI-powered capabilities. Translate, summarize, and interact with your data within Eidos.
- Extensible: Customize Eidos to suit your needs. Write extension code manually or use AI to generate extension code

  - Micro block: UI components for customized data display and interaction. Can be referenced in documents, covers, and right panels
  - Doc Plugin: Customize document editor behavior
  - Script: Create powerful data processing logic with TypeScript/JavaScript/Python.
  - UDF: Use JavaScript to create custom calculation functions for use in table Formula fields.

- Developer Friendly:

  - API &amp; SDK
  - Sqlite Standardization: Every table in Eidos is a SQLite table.

## How to use

There are two versions of Eidos:

- Web app[tech preview]: Accessible via browser, it&#039;s a pure PWA with no web server. But it has some limitations, see [web-vs-desktop](./docs/web-vs-desktop.md)
- Desktop app[recommended]: Offline support, full features.

Get the app from: https://eidos.space/download

## How to develop

### web app

1. Clone the repository `git clone git@github.com:mayneyao/eidos.git`
2. Run `pnpm install` to install dependencies
3. Run `pnpm dev`
4. You can now access the app in your browser at http://localhost:5173

### desktop app

1. Clone the repository `git clone git@github.com:mayneyao/eidos.git`
2. Run `pnpm install` to install dependencies
3. Run `pnpm download-libsimple` to download libsimple
4. Run `pnpm dev:desktop`

## How to deploy your own

For most users, you don&#039;t need to deploy your own. You can use the desktop app version of Eidos with full offline support and features.

If you want to deploy your own, see more details at [self-hosting](./docs/self-hosting.md)

## Roadmap &amp; changelogs

| Version                                                        | Features                          | Domain          | Range   | Status |
| -------------------------------------------------------------- | --------------------------------- | --------------- | ------- | ------ |
| 0.14                                                           | Table core refactor               | Table,Base      |         | Plan   |
| 0.13                                                           | Support writing Scripts in Python | Extension       |         | üöß     |
| [0.12](https://github.com/mayneyao/eidos/releases/tag/v0.12.0) | Document core refactor            | Document,Base   | 2024-12 | ‚úÖ‚¨ÜÔ∏è   |
| 0.11                                                           | Extension generation via chat     | AI,Extension    | 2024-11 | ‚úÖ     |
| 0.10                                                           | Micro blocks editing via Cursor   | AI,Extension    | 2024-11 | ‚úÖ     |
| 0.9                                                            | Micro block components            | AI,Extension    | 2024-11 | ‚úÖ     |
| 0.8                                                            | i18n support                      | General         | 2024-10 | ‚úÖ     |
| 0.7                                                            | Desktop app support               | Desktop         | 2024-09 | ‚úÖ     |
| 0.6                                                            | Bug fixes &amp; Publish service       | General,Publish | 2024-08 | ‚úÖ     |
| 0.5                                                            | Feature improvements              | General         | 2024-07 | ‚úÖ     |
| 0.4                                                            | Open source                       | Project         | 2024-06 | ‚úÖ     |
| 0.3                                                            | AI &amp; Extension                    | AI,Extension    |         | ‚úÖ     |
| 0.2                                                            | Document functionality            | Document        |         | ‚úÖ     |
| 0.1                                                            | Table functionality               | Table           |         | ‚úÖ     |

You can see the latest status of the project in the [project board](https://github.com/users/mayneyao/projects/5), but it may not be up to date.

- [x] Desktop App
- [x] I18n
- [ ] Publish Service: Publish your data to the web.
- [ ] P2p sync based on CRDT: local-first, not local-only. Sync your data across devices.

## Credits

Eidos based on the following open-source projects:

### web app

- [sqlite-wasm](https://github.com/sqlite/sqlite-wasm) - Run SQLite in the browser
- [shadcn-ui](https://github.com/shadcn-ui/ui) - UI components
- [glide-data-grid](https://github.com/glideapps/glide-data-grid) - High performance table
- [lexical](https://github.com/facebook/lexical) - Document editor
- [web-llm](https://github.com/mlc-ai/web-llm) - Run LLM in the browser
- [teable](https://github.com/teableio/teable) &amp; [apitable](https://github.com/apitable/apitable) - Teach me how to build an Airtable-like table.

### desktop app

- [electron](https://github.com/electron/electron) - Build cross-platform desktop apps
- [libsimple](https://github.com/wangfenjin/simple) - a sqlite extension for full-text search for CJK languages

## License

This project is licensed under the terms of the AGPL license.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[medplum/medplum]]></title>
            <link>https://github.com/medplum/medplum</link>
            <guid>https://github.com/medplum/medplum</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[Medplum is a healthcare platform that helps you quickly develop high-quality compliant applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/medplum/medplum">medplum/medplum</a></h1>
            <p>Medplum is a healthcare platform that helps you quickly develop high-quality compliant applications.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,847</p>
            <p>Forks: 557</p>
            <p>Stars today: 71 stars today</p>
            <h2>README</h2><pre># [Medplum](https://www.medplum.com) &amp;middot; [![GitHub license](https://img.shields.io/badge/license-Apache-blue.svg)](https://github.com/medplum/medplum/blob/main/LICENSE.txt) [![npm version](https://img.shields.io/npm/v/@medplum/core.svg?color=blue)](https://www.npmjs.com/package/@medplum/core) [![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=medplum_medplum&amp;metric=alert_status&amp;token=207c95a43e7519809d6d336d8cc7837d3e057acf)](https://sonarcloud.io/dashboard?id=medplum_medplum) [![Coverage Status](https://coveralls.io/repos/github/medplum/medplum/badge.svg?branch=main)](https://coveralls.io/github/medplum/medplum?branch=main) [![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10900/badge?gold)](https://www.bestpractices.dev/projects/10900)

![Medplum](packages/docs/static/img/cover.webp)

Medplum is a developer platform that enables flexible and rapid development of healthcare apps.

- **Medplum Auth** - End-to-end identity solution for easy user authentication, sign-in, and permissions using OAuth, OpenID, and SMART-on-FHIR.
- **Medplum Clinical Data Repository (CDR)** - Backend server that hosts your healthcare data in a secure, compliant, and standards-based repository.
- **Medplum API** - FHIR-based API for sending, receiving, and manipulating data.
- **Medplum SDK** - Client libraries that simplify the process of interacting with the **Medplum API**.
- **Medplum App** - Web application where you can view your data and perform basic editing tasks. You can also use the Medplum App to manage basic workflows.
- **Medplum Bots** - Write and run application logic server-side without needing to set up your own server.
- **UI Component Library** - React components designed to help you quickly develop custom healthcare applications.

## Docs

- [Contributing](#contributing)
  - [Ground Rules](#ground-rules)
  - [Codebase](#codebase)
    - [Technologies](#technologies)
    - [Folder Structure](#folder-structure)

## Contributing

**We heartily welcome any and all contributions that match our engineering standards!**

That being said, this codebase isn&#039;t your typical open-source project because it&#039;s not a library or package with a
limited scope -- it&#039;s our entire product. Our [Contributing documentation](https://medplum.com/docs/contributing) has
all the information you need to get started.

### Ground Rules

#### Contributions and discussion guidelines

By making a contribution to this project, you are deemed to have accepted the [Developer Certificate of Origin](https://developercertificate.org/) (DCO).

All conversations and communities on Medplum are expected to follow GitHub&#039;s [Community Guidelines](https://help.github.com/en/github/site-policy/github-community-guidelines)
and [Acceptable Use Policies](https://help.github.com/en/github/site-policy/github-acceptable-use-policies). We expect
discussions on issues and pull requests to stay positive, productive, and respectful. Remember: there are real people on
the other side of the screen!

#### Reporting a bug or proposing a new feature

If you found a technical bug on Medplum or have ideas for features we should implement, the issue tracker is the best
place to share with us. ([click here to open a new issue](https://github.com/medplum/medplum/issues/new))

### Writing documentation or blog content

Did you learn how to do something using Medplum that wasn&#039;t obvious on your first try? By contributing your new knowledge
to our documentation, you can help others who might have a similar use case!

Our documentation is hosted on [medplum.com/docs](https://www.medplum.com/docs), but it is built from [Markdown](https://www.markdownguide.org/)
files in our [`docs` package](https://github.com/medplum/medplum/tree/main/packages/docs/docs).

For relatively small changes, you can edit files directly from your web browser on [Github.dev](https://github.dev/medplum/medplum/blob/main/packages/docs/docs/home.md)
without needing to clone the repository.

#### Fixing a bug or implementing a new feature

If you find a bug and open a Pull Request that fixes it, we&#039;ll review it as soon as possible to ensure it meets our engineering standards.

If you want to implement a new feature, open an issue first to discuss with us how the feature might work, and to ensure
it fits into our roadmap and plans for the app.

If you want to contribute but are unsure how to start, we have [a &quot;good first issue&quot; label](https://github.com/medplum/medplum/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) which is applied to newcomer-friendly issues. Take a look at [the full list of good first issues](https://github.com/medplum/medplum/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) and pick something you like!

**Ready to get started writing code?** Follow the [local setup instructions](https://www.medplum.com/docs/contributing/local-dev-setup) and jump in!

### Codebase

#### Technologies

With the ground rules out of the way, let&#039;s talk about the coarse architecture of this mono repo:

- **Full-stack TypeScript**: We use Node.js to power our servers, and React to power our frontend apps. Almost all of the code you&#039;ll touch in this codebase will be TypeScript.

Here is a list of all the big technologies we use:

- **PostgreSQL**: Data storage
- **Redis**: Background jobs and caching
- **Express**: API server
- **TypeScript**: Type-safe JavaScript
- **React**: Frontend React app

#### Folder structure

```sh
medplum/
‚îú‚îÄ‚îÄ packages
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ agent           # On-premise agent
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ app             # Frontend web app
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ bot-layer       # AWS Lambda Layer for Bots
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ cdk             # AWS CDK infra as code
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ cli             # Command line interface
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ core            # Core shared library
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ definitions     # Data definitions
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ docs            # Documentation
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ examples        # Example code used in documentation
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ fhir-router     # FHIR URL router
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ fhirtypes       # FHIR TypeScript definitions
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ generator       # Code generator utilities
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ graphiql        # Preconfigured GraphiQL
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ hl7             # HL7 client and server
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ mock            # Mock FHIR data for testing
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ react           # React component library
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ react-hooks     # React hooks library
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ server          # Backend API server
‚îî‚îÄ‚îÄ scripts             # Helper bash scripts
```

## Thanks

&lt;a href=&quot;https://www.chromatic.com/&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/321738/84662277-e3db4f80-af1b-11ea-88f5-91d67a5e59f6.png&quot; width=&quot;153&quot; height=&quot;30&quot; alt=&quot;Chromatic&quot; /&gt;&lt;/a&gt;

Thanks to [Chromatic](https://www.chromatic.com/) for providing the visual testing platform that helps us review UI changes and catch visual regressions.

## License

[Apache 2.0](LICENSE.txt)

Copyright &amp;copy; Medplum 2025

FHIR&amp;reg; is a registered trademark of HL7.

SNOMED&amp;reg; is a registered trademark of the International Health Terminology Standards Development Organisation.

LOINC&amp;reg; is a registered trademark of Regenstrief Institute, Inc.

DICOM&amp;reg; is the registered trademark of the National Electrical Manufacturers Association (NEMA).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[humanlayer/humanlayer]]></title>
            <link>https://github.com/humanlayer/humanlayer</link>
            <guid>https://github.com/humanlayer/humanlayer</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[HumanLayer enables AI agents to communicate with humans in tool-based and async workflows. Guarantee human oversight of high-stakes function calls with approval workflows across slack, email and more. Bring your LLM and Framework of choice and start giving your AI agents safe access to the world. Agentic Workflows, human in the loop, tool calling]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/humanlayer/humanlayer">humanlayer/humanlayer</a></h1>
            <p>HumanLayer enables AI agents to communicate with humans in tool-based and async workflows. Guarantee human oversight of high-stakes function calls with approval workflows across slack, email and more. Bring your LLM and Framework of choice and start giving your AI agents safe access to the world. Agentic Workflows, human in the loop, tool calling</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,306</p>
            <p>Forks: 134</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![Wordmark Logo of HumanLayer](./docs/images/wordmark-light.svg)

&lt;/div&gt;

üöß **HumanLayer** is undergoing some changes...stay tuned! üöß

&lt;div align=&quot;center&quot;&gt;

&lt;h3&gt;

[HumanLayer Code](https://humanlayer.dev/code) | [Discord](https://humanlayer.dev/discord) | [Release](https://github.com/humanlayer/humanlayer/releases)


&lt;/h3&gt;

[![GitHub Repo stars](https://img.shields.io/github/stars/humanlayer/humanlayer)](https://github.com/humanlayer/humanlayer)
[![License: Apache-2](https://img.shields.io/badge/License-Apache-green.svg)](https://opensource.org/licenses/Apache-2)

&lt;img referrerpolicy=&quot;no-referrer-when-downgrade&quot; src=&quot;https://static.scarf.sh/a.png?x-pxid=fcfc0926-d841-47fb-b8a6-6aba3a6c3228&quot; /&gt;

&lt;/div&gt;

## Table of contents

- [Getting Started](#getting-started)
- [Why HumanLayer?](#why-humanlayer)
- [Key Features](#key-features)
- [Examples](#examples)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License](#license)

## Why HumanLayer?

Functions and tools are a key part of [Agentic Workflows](https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance). They enable LLMs to interact meaningfully with the outside world and automate broad scopes of impactful work. Correct and accurate function calling is essential for AI agents that do meaningful things like book appointments, interact with customers, manage billing information, write+execute code, and more.

[![Tool Calling Loop from Louis Dupont](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r8rEqjGZs_e6dibWeaqaQg.png)](https://louis-dupont.medium.com/transforming-software-interactions-with-tool-calling-and-llms-dc39185247e9)
_From https://louis-dupont.medium.com/transforming-software-interactions-with-tool-calling-and-llms-dc39185247e9_

**However**, the most useful functions we can give to an LLM are also the most risky. We can all imagine the value of an AI Database Administrator that constantly tunes and refactors our SQL database, but most teams wouldn&#039;t give an LLM access to run arbitrary SQL statements against a production database (heck, we mostly don&#039;t even let humans do that). That is:

&lt;div align=&quot;center&quot;&gt;
&lt;h3&gt;&lt;blockquote&gt;Even with state-of-the-art agentic reasoning and prompt routing, LLMs are not sufficiently reliable to be given access to high-stakes functions without human oversight&lt;/blockquote&gt;&lt;/h3&gt;
&lt;/div&gt;

To better define what is meant by &quot;high stakes&quot;, some examples:

- **Low Stakes**: Read Access to public data (e.g. search wikipedia, access public APIs and DataSets)
- **Low Stakes**: Communicate with agent author (e.g. an engineer might empower an agent to send them a private Slack message with updates on progress)
- **Medium Stakes**: Read Access to Private Data (e.g. read emails, access calendars, query a CRM)
- **Medium Stakes**: Communicate with strict rules (e.g. sending based on a specific sequence of hard-coded email templates)
- **High Stakes**: Communicate on my Behalf or on behalf of my Company (e.g. send emails, post to slack, publish social/blog content)
- **High Stakes**: Write Access to Private Data (e.g. update CRM records, modify feature toggles, update billing information)

&lt;div align=&quot;center&quot;&gt;&lt;img style=&quot;width: 600px&quot; alt=&quot;Image showing the levels of function stakes stacked on top of one another&quot; src=&quot;./docs/images/function_stakes.png&quot;&gt;&lt;/div&gt;

The high stakes functions are the ones that are the most valuable and promise the most impact in automating away human workflows. But they are also the ones where &quot;90% accuracy&quot; is not acceptable. Reliability is further impacted by today&#039;s LLMs&#039; tendency to hallucinate or craft low-quality text that is clearly AI generated. The sooner teams can get Agents reliably and safely calling these tools with high-quality inputs, the sooner they can reap massive benefits.

HumanLayer provides a set of tools to _deterministically_ guarantee human oversight of high stakes function calls. Even if the LLM makes a mistake or hallucinates, HumanLayer is baked into the tool/function itself, guaranteeing a human in the loop.

&lt;div align=&quot;center&quot;&gt;&lt;img style=&quot;width: 400px&quot; alt=&quot;HumanLayer @require_approval decorator wrapping the Commnicate on my behalf function&quot; src=&quot;./docs/images/humanlayer_require_approval.png&quot;&gt;&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;h3&gt;&lt;blockquote&gt;
HumanLayer provides a set of tools to *deterministically* guarantee human oversight of high stakes function calls
&lt;/blockquote&gt;&lt;/h3&gt;
&lt;/div&gt;

### The Future: Autonomous Agents and the &quot;Outer Loop&quot;

_Read More: [OpenAI&#039;s RealTime API is a step towards outer-loop agents](https://theouterloop.substack.com/p/openais-realtime-api-is-a-step-towards)_

Between `require_approval` and `human_as_tool`, HumanLayer is built to empower the next generation of AI agents - Autonomous Agents, but it&#039;s just a piece of the puzzle. To clarify &quot;next generation&quot;, we can summarize briefly the history of LLM applications.

- **Gen 1**: Chat - human-initiated question / response interface
- **Gen 2**: Agentic Assistants - frameworks drive prompt routing, tool calling, chain of thought, and context window management to get much more reliability and functionality. Most workflows are initiated by humans in single-shot &quot;here&#039;s a task, go do it&quot; or rolling chat interfaces.
- **Gen 3**: Autonomous Agents - no longer human initiated, agents will live in the &quot;outer loop&quot; driving toward their goals using various tools and functions. Human/Agent communication is Agent-initiated rather than human-initiated.

![gen2 vs gen 3 agents](./docs/images/gen-2-gen-3-agents.png)

Gen 3 autonomous agents will need ways to consult humans for input on various tasks. In order for these agents to perform actual useful work, they&#039;ll need human oversight for sensitive operations.

These agents will require ways to contact one or more humans across various channels including chat, email, sms, and more.

While early versions of these agents may technically be &quot;human initiated&quot; in that they get kicked off on a regular schedule by e.g. a cron or similar, the best ones will be managing their own scheduling and costs. This will require toolkits for inspecting costs and something akin to `sleep_until`. They&#039;ll need to run in orchestration frameworks that can durably serialize and resume agent workflows across tool calls that might not return for hours or days. These frameworks will need to support context window management by a &quot;manager LLM&quot; and enable agents to fork sub-chains to handle specialized tasks and roles.

Example use cases for these outer loop agents include [the linkedin inbox assistant](./examples/langchain/04-human_as_tool_linkedin.py) and [the customer onboarding assistant](./examples/langchain/05-approvals_and_humans_composite.py), but that&#039;s really just scratching the surface.

## Contributing

The HumanLayer SDK and docs are open-source and we welcome contributions in the form of issues, documentation, pull requests, and more. See [CONTRIBUTING.md](./CONTRIBUTING.md) for more details.

## Fun Stuff

[![Star History Chart](https://api.star-history.com/svg?repos=humanlayer/humanlayer&amp;type=Date)](https://star-history.com/#humanlayer/humanlayer&amp;Date)


## Development Conventions

### TODO Annotations

We use a priority-based TODO annotation system throughout the codebase:

- `TODO(0)`: Critical - never merge
- `TODO(1)`: High - architectural flaws, major bugs
- `TODO(2)`: Medium - minor bugs, missing features
- `TODO(3)`: Low - polish, tests, documentation
- `TODO(4)`: Questions/investigations needed
- `PERF`: Performance optimization opportunities

## License

The HumanLayer SDK and CodeLayer sources in this repo are licensed under the Apache 2 License.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[jnsahaj/tweakcn]]></title>
            <link>https://github.com/jnsahaj/tweakcn</link>
            <guid>https://github.com/jnsahaj/tweakcn</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:46 GMT</pubDate>
            <description><![CDATA[A visual no-code theme editor for shadcn/ui components]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jnsahaj/tweakcn">jnsahaj/tweakcn</a></h1>
            <p>A visual no-code theme editor for shadcn/ui components</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,848</p>
            <p>Forks: 384</p>
            <p>Stars today: 77 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;h1&gt;tweakcn.com&lt;/h1&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://vercel.com/oss&quot;&gt;
    &lt;img alt=&quot;Vercel OSS Program&quot; src=&quot;https://vercel.com/oss/program-badge.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;br /&gt;
  &lt;br /&gt;
  &lt;a href=&quot;https://discord.gg/Phs4u2NM3n&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1353416868769173576?style=for-the-badge&amp;logo=discord&amp;logoColor=%23ffffff&quot;&gt;
  &lt;/a&gt;
  &lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/jnsahaj/tweakcn?style=for-the-badge&amp;logo=github&quot;&gt;
  &lt;a href=&quot;https://x.com/iamsahaj_xyz&quot;&gt;
    &lt;img alt=&quot;X (formerly Twitter) URL&quot; src=&quot;https://img.shields.io/twitter/url?url=https%3A%2F%2Fx.com%2Fiamsahaj_xyz&amp;style=for-the-badge&amp;logo=x&amp;label=%40iamsahaj_xyz&amp;color=%2300000000&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;br /&gt;

**[tweakcn](https://tweakcn.com)** is a powerful Visual Theme Editor for tailwind CSS &amp; shadcn/ui components. It comes with Beautiful theme presets to get started, while aiming to offer advanced customisation for each aspect of your UI

![tweakcn.com](public/og-image.v050725.png)

## Motivation

Websites made with shadcn/ui famously look the same. tweakcn is a tool that helps you customize shadcn/ui components visually, to make your components stand-out. The goal is to build a platform where a user can discover endless customization options and then have the ability to put their own twist on it. Check our roadmap for more information

## Current Features

You can find the full feature list here: https://tweakcn.com/#features

## Roadmap

You can find the updated roadmap here: https://tweakcn.com/#roadmap

## Run Locally

**IMPORTANT: For contributions, please see [CONTRIBUTING.md](CONTRIBUTING.md).**

### Prerequisites

- Node.js 18+
- npm / yarn / pnpm

### Installation

1. Clone the repository:

```bash
git clone https://github.com/jnsahaj/tweakcn.git
cd tweakcn
```

2. Install dependencies:

```bash
npm install
```

3. Start the development server:

```bash
npm run dev
```

4. Open [http://localhost:3000](http://localhost:3000) in your browser.

## Contributors

&lt;a href=&quot;https://github.com/jnsahaj/tweakcn/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=jnsahaj/tweakcn&quot; /&gt;
&lt;/a&gt;

Made with [contrib.rocks](https://contrib.rocks).

### Interested in Contributing?

Contributions are welcome! Please feel free to submit a Pull Request.

# Star History

&lt;p align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://star-history.com/#jnsahaj/tweakcn&amp;Date&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=jnsahaj/tweakcn&amp;type=Date&amp;theme=dark&quot;&gt;
      &lt;img alt=&quot;GitHub Star History for jnsahaj/tweakcn&quot; src=&quot;https://api.star-history.com/svg?repos=jnsahaj/tweakcn&amp;type=Date&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;!-- GitAds-Verify: HX84XPI5OQ816367AROGJ9SROARUHQER --&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[codexu/note-gen]]></title>
            <link>https://github.com/codexu/note-gen</link>
            <guid>https://github.com/codexu/note-gen</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:45 GMT</pubDate>
            <description><![CDATA[A cross-platform Markdown AI note-taking software.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/codexu/note-gen">codexu/note-gen</a></h1>
            <p>A cross-platform Markdown AI note-taking software.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 8,121</p>
            <p>Forks: 541</p>
            <p>Stars today: 77 stars today</p>
            <h2>README</h2><pre># NoteGen

![](https://img.shields.io/badge/free-pricing?logo=free&amp;color=%20%23155EEF&amp;label=pricing&amp;labelColor=%20%23528bff)
[![GitHub Repo stars](https://img.shields.io/github/stars/codexu/note-gen)](https://github.com/codexu/note-gen)
[![](https://gitcode.com/codexu/note-gen/star/badge.svg)](https://gitcode.com/codexu/note-gen)
![](https://github.com/codexu/note-gen/actions/workflows/release.yml/badge.svg?branch=release)
[![Netlify Status](https://api.netlify.com/api/v1/badges/8f7518c3-b627-4277-bc2f-e477960f5dc4/deploy-status)](https://app.netlify.com/projects/note-gen-docs/deploys)
![](https://img.shields.io/github/downloads/codexu/note-gen/total)
![](https://img.shields.io/github/issues-closed/codexu/note-gen)

&lt;div&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/12784&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12784&quot; alt=&quot;codexu%2Fnote-gen | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://hellogithub.com/repository/0163cb946dca44cc8905dbe34c2c987b&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=0163cb946dca44cc8905dbe34c2c987b&amp;claim_uid=YJ39kIMBz1TGAvc&quot; alt=&quot;FeaturedÔΩúHelloGitHub&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.producthunt.com/products/notegen-2?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_source=badge-notegen&amp;#0045;2&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=956348&amp;theme=light&amp;t=1749194675492&quot; alt=&quot;NoteGen - A&amp;#0032;cross&amp;#0045;platform&amp;#0032;Markdown&amp;#0032;note&amp;#0045;taking&amp;#0032;application | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

## Guide

üñ•Ô∏è Official Document: [English](https://notegen.top/en/) | [ÁÆÄ‰Ωì‰∏≠Êñá](https://notegen.top/cn/)

üí¨ Join [WeChat/QQ Group](https://github.com/codexu/note-gen/discussions/110), [Discord](https://discord.gg/SXyVZGpbpk), [Telegram](https://t.me/notegen)

NoteGen is a cross-platform `Markdown` note-taking application dedicated to using AI to bridge recording and writing, organizing fragmented knowledge into a readable note.

![](https://s2.loli.net/2025/06/13/UbVGPrhFl3etnQz.png)

## Why Choose NoteGen?

- Lightweight: [Installation package](https://github.com/codexu/note-gen/releases) is **only 20MB**, free with no ads or bundled software.
- Cross-platform capabilities of `Tauri2`, it supports Windows, MacOS, Linux, iOS, and Android, and it supports free multi-device data synchronization.
- Supports multiple recording methods including `screenshots`, `text`, `illustrations`, `files`, `links`, etc., meeting fragmented recording needs across various scenarios.
- Native `Markdown(.md)` as storage format, no modifications, easy to migrate.
- Native offline usage, supporting real-time synchronization to `GitHub, Gitee private repositories` with history rollback, and WebDAV synchronization.
- AI-enhanced: Configurable with ChatGPT, Gemini, Ollama, LM Studio, Grok, and other models, with support for custom third-party model configuration.
- RAG: Your notes are your knowledge base. Support embedding models and reranking models.

## How to Use?

### Download

Currently supports Mac, Windows, and Linux. Thanks to Tauri2&#039;s cross-platform capabilities, it will support iOS and Android in the future.

| Windows | MacOS | Linux | Android | iOS |
| --- | --- | --- | --- | --- |
| ‚úÖ beta | ‚úÖ beta | ‚úÖ beta | üõ†Ô∏è alpha | üõ†Ô∏è alpha |
| [Download](https://notegen.top/en/docs/download#desktop-beta) | [Download](https://notegen.top/en/docs/download#desktop-beta) | [Download](https://notegen.top/en/docs/download#desktop-beta) | [Download](https://notegen.top/en/docs/download#android) | Self-compiled |

&gt; [UpgradeLink offers application upgrade and download services](http://upgrade.toolsetlink.com/upgrade/example/tauri-example.html)

### Enhancement

The note-taking application can be used directly without configuration. If you want a better experience, please open the settings page to configure AI and synchronization.

[Read settings guide](https://notegen.top/en/settings/sync.html)

## From Recording to Writing

Conventional note-taking applications typically don&#039;t provide recording functionality. Users need to manually copy and paste content for recording, which greatly reduces efficiency. When faced with scattered recorded content, it requires significant effort to organize.

NoteGen is divided into `Recording` and `Writing` pages, with the following relationship:

- Recordings can be organized into notes and transferred to the writing page for in-depth composition.
- During writing, you can insert recordings at any time.

### Recording

The recording function is similar to an **AI chatbot**, but when conversing with it, you can associate it with previously recorded content, switching from conversation mode to organization mode to arrange recordings into a readable note.

The following auxiliary features can help you record more effectively:

- **Tags** to distinguish different recording scenarios.
- **Personas** with support for custom prompts to precisely control your AI assistant.
- **Clipboard Assistant** that automatically recognizes text or images in your clipboard and records them to your list.

### Writing

The writing section is divided into two parts: **File Manager** and **Markdown Editor**.

**File Manager**

- Supports management of local Markdown files and GitHub synchronized files.
- Supports unlimited directory hierarchy.
- Supports multiple sorting methods.

**Markdown Editor**

- Supports WYSIWYG, instant rendering, and split-screen preview modes.
- Supports version control with history rollback.
- Supports AI assistance for conversation, continuation, polishing, and translation functions.
- Supports image hosting, uploading images and converting them to Markdown image links.
- Supports HTML to Markdown conversion, automatically converting copied browser content to Markdown format.
- Supports outlines, math formulas, mind maps, charts, flowcharts, Gantt charts, sequence diagrams, staves, multimedia, voice reading, title anchors, code highlighting and copying, graphviz rendering, and plantuml UML diagrams.
- Supports real-time local content saving, delayed (10s without editing) automatic synchronization, and history rollback.

## Other Features

- Global search for quickly finding and jumping to specific content.
- Image hosting management for convenient management of image repository content.
- Themes and appearance with support for dark themes and appearance settings for Markdown, code, etc.
- Internationalization support, currently available in Chinese and English.

## Contribute

- [Read contribution guide](https://notegen.top/en/docs/contributing)
- [Update plans](https://github.com/codexu/note-gen/issues/46)
- [Submit bugs or improvement suggestions](https://github.com/codexu/note-gen/issues)
- [Discussions](https://github.com/codexu/note-gen/discussions)

## Contributors

&lt;a href=&quot;https://github.com/codexu/note-gen/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=codexu/note-gen&quot; /&gt;
&lt;/a&gt;

## Sponsors

&lt;div&gt;
  &lt;a href=&quot;https://cloud.siliconflow.cn/i/O2ciJeZw&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://s2.loli.net/2025/06/11/65TLRh813e2YFzr.png&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.qiniu.com/products/ai-token-api?utm_source=NoteGen&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://s2.loli.net/2025/06/11/OKJq542lTs7U9xg.png&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;http://upgrade.toolsetlink.com/upgrade/example/tauri-example.html&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://s2.loli.net/2025/06/11/r2dqNIWVXp4RaFe.png&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://share.302.ai/jfFrIP&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://s2.loli.net/2025/07/01/dPlkU1tejnDyV4S.png&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=codexu/note-gen&amp;type=Date)](https://www.star-history.com/#codexu/note-gen&amp;Date)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[microsoft/playwright-mcp]]></title>
            <link>https://github.com/microsoft/playwright-mcp</link>
            <guid>https://github.com/microsoft/playwright-mcp</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[Playwright MCP server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/playwright-mcp">microsoft/playwright-mcp</a></h1>
            <p>Playwright MCP server</p>
            <p>Language: TypeScript</p>
            <p>Stars: 18,438</p>
            <p>Forks: 1,425</p>
            <p>Stars today: 130 stars today</p>
            <h2>README</h2><pre>## Playwright MCP

A Model Context Protocol (MCP) server that provides browser automation capabilities using [Playwright](https://playwright.dev). This server enables LLMs to interact with web pages through structured accessibility snapshots, bypassing the need for screenshots or visually-tuned models.

### Key Features

- **Fast and lightweight**. Uses Playwright&#039;s accessibility tree, not pixel-based input.
- **LLM-friendly**. No vision models needed, operates purely on structured data.
- **Deterministic tool application**. Avoids ambiguity common with screenshot-based approaches.

### Requirements
- Node.js 18 or newer
- VS Code, Cursor, Windsurf, Claude Desktop, Goose or any other MCP client

&lt;!--
// Generate using:
node utils/generate-links.js
--&gt;

### Getting started

First, install the Playwright MCP server with your client.

**Standard config** works in most of the tools:

```js
{
  &quot;mcpServers&quot;: {
    &quot;playwright&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;@playwright/mcp@latest&quot;
      ]
    }
  }
}
```

[&lt;img src=&quot;https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&amp;label=Install%20Server&amp;color=0098FF&quot; alt=&quot;Install in VS Code&quot;&gt;](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522playwright%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522%2540playwright%252Fmcp%2540latest%2522%255D%257D) [&lt;img alt=&quot;Install in VS Code Insiders&quot; src=&quot;https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&amp;label=Install%20Server&amp;color=24bfa5&quot;&gt;](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522playwright%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522%2540playwright%252Fmcp%2540latest%2522%255D%257D)


&lt;details&gt;
&lt;summary&gt;Claude Code&lt;/summary&gt;

Use the Claude Code CLI to add the Playwright MCP server:

```bash
claude mcp add playwright npx @playwright/mcp@latest
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Claude Desktop&lt;/summary&gt;

Follow the MCP install [guide](https://modelcontextprotocol.io/quickstart/user), use the standard config above.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Codex&lt;/summary&gt;

Create or edit the configuration file `~/.codex/config.toml` and add:

```toml
[mcp_servers.playwright]
command = &quot;npx&quot;
args = [&quot;@playwright/mcp@latest&quot;]
```

For more information, see the [Codex MCP documentation](https://github.com/openai/codex/blob/main/codex-rs/config.md#mcp_servers).

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Cursor&lt;/summary&gt;

#### Click the button to install:

[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](cursor://anysphere.cursor-deeplink/mcp/install?name=Playwright&amp;config=eyJjb21tYW5kIjoibnB4IEBwbGF5d3JpZ2h0L21jcEBsYXRlc3QifQ%3D%3D)

#### Or install manually:

Go to `Cursor Settings` -&gt; `MCP` -&gt; `Add new MCP Server`. Name to your liking, use `command` type with the command `npx @playwright/mcp@latest`. You can also verify config or add command like arguments via clicking `Edit`.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Gemini CLI&lt;/summary&gt;

Follow the MCP install [guide](https://github.com/google-gemini/gemini-cli/blob/main/docs/tools/mcp-server.md#configure-the-mcp-server-in-settingsjson), use the standard config above.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Goose&lt;/summary&gt;

#### Click the button to install:

[![Install in Goose](https://block.github.io/goose/img/extension-install-dark.svg)](https://block.github.io/goose/extension?cmd=npx&amp;arg=%40playwright%2Fmcp%40latest&amp;id=playwright&amp;name=Playwright&amp;description=Interact%20with%20web%20pages%20through%20structured%20accessibility%20snapshots%20using%20Playwright)

#### Or install manually:

Go to `Advanced settings` -&gt; `Extensions` -&gt; `Add custom extension`. Name to your liking, use type `STDIO`, and set the `command` to `npx @playwright/mcp`. Click &quot;Add Extension&quot;.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;LM Studio&lt;/summary&gt;

#### Click the button to install:

[![Add MCP Server playwright to LM Studio](https://files.lmstudio.ai/deeplink/mcp-install-light.svg)](https://lmstudio.ai/install-mcp?name=playwright&amp;config=eyJjb21tYW5kIjoibnB4IiwiYXJncyI6WyJAcGxheXdyaWdodC9tY3BAbGF0ZXN0Il19)

#### Or install manually:

Go to `Program` in the right sidebar -&gt; `Install` -&gt; `Edit mcp.json`. Use the standard config above.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;opencode&lt;/summary&gt;

Follow the MCP Servers [documentation](https://opencode.ai/docs/mcp-servers/). For example in `~/.config/opencode/opencode.json`:

```json
{
  &quot;$schema&quot;: &quot;https://opencode.ai/config.json&quot;,
  &quot;mcp&quot;: {
    &quot;playwright&quot;: {
      &quot;type&quot;: &quot;local&quot;,
      &quot;command&quot;: [
        &quot;npx&quot;,
        &quot;@playwright/mcp@latest&quot;
      ],
      &quot;enabled&quot;: true
    }
  }
}

```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Qodo Gen&lt;/summary&gt;

Open [Qodo Gen](https://docs.qodo.ai/qodo-documentation/qodo-gen) chat panel in VSCode or IntelliJ ‚Üí Connect more tools ‚Üí + Add new MCP ‚Üí Paste the standard config above.

Click &lt;code&gt;Save&lt;/code&gt;.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;VS Code&lt;/summary&gt;

#### Click the button to install:

[&lt;img src=&quot;https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&amp;label=Install%20Server&amp;color=0098FF&quot; alt=&quot;Install in VS Code&quot;&gt;](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522playwright%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522%2540playwright%252Fmcp%2540latest%2522%255D%257D) [&lt;img alt=&quot;Install in VS Code Insiders&quot; src=&quot;https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&amp;label=Install%20Server&amp;color=24bfa5&quot;&gt;](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522playwright%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522%2540playwright%252Fmcp%2540latest%2522%255D%257D)

#### Or install manually:

Follow the MCP install [guide](https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_add-an-mcp-server), use the standard config above. You can also install the Playwright MCP server using the VS Code CLI:

```bash
# For VS Code
code --add-mcp &#039;{&quot;name&quot;:&quot;playwright&quot;,&quot;command&quot;:&quot;npx&quot;,&quot;args&quot;:[&quot;@playwright/mcp@latest&quot;]}&#039;
```

After installation, the Playwright MCP server will be available for use with your GitHub Copilot agent in VS Code.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Windsurf&lt;/summary&gt;

Follow Windsurf MCP [documentation](https://docs.windsurf.com/windsurf/cascade/mcp). Use the standard config above.

&lt;/details&gt;

### Configuration

Playwright MCP server supports following arguments. They can be provided in the JSON configuration above, as a part of the `&quot;args&quot;` list:

&lt;!--- Options generated by update-readme.js --&gt;

```
&gt; npx @playwright/mcp@latest --help
  --allowed-origins &lt;origins&gt;  semicolon-separated list of origins to allow the
                               browser to request. Default is to allow all.
  --blocked-origins &lt;origins&gt;  semicolon-separated list of origins to block the
                               browser from requesting. Blocklist is evaluated
                               before allowlist. If used without the allowlist,
                               requests not matching the blocklist are still
                               allowed.
  --block-service-workers      block service workers
  --browser &lt;browser&gt;          browser or chrome channel to use, possible
                               values: chrome, firefox, webkit, msedge.
  --caps &lt;caps&gt;                comma-separated list of additional capabilities
                               to enable, possible values: vision, pdf.
  --cdp-endpoint &lt;endpoint&gt;    CDP endpoint to connect to.
  --config &lt;path&gt;              path to the configuration file.
  --device &lt;device&gt;            device to emulate, for example: &quot;iPhone 15&quot;
  --executable-path &lt;path&gt;     path to the browser executable.
  --extension                  Connect to a running browser instance
                               (Edge/Chrome only). Requires the &quot;Playwright MCP
                               Bridge&quot; browser extension to be installed.
  --headless                   run browser in headless mode, headed by default
  --host &lt;host&gt;                host to bind server to. Default is localhost. Use
                               0.0.0.0 to bind to all interfaces.
  --ignore-https-errors        ignore https errors
  --isolated                   keep the browser profile in memory, do not save
                               it to disk.
  --image-responses &lt;mode&gt;     whether to send image responses to the client.
                               Can be &quot;allow&quot; or &quot;omit&quot;, Defaults to &quot;allow&quot;.
  --no-sandbox                 disable the sandbox for all process types that
                               are normally sandboxed.
  --output-dir &lt;path&gt;          path to the directory for output files.
  --port &lt;port&gt;                port to listen on for SSE transport.
  --proxy-bypass &lt;bypass&gt;      comma-separated domains to bypass proxy, for
                               example &quot;.com,chromium.org,.domain.com&quot;
  --proxy-server &lt;proxy&gt;       specify proxy server, for example
                               &quot;http://myproxy:3128&quot; or &quot;socks5://myproxy:8080&quot;
  --save-session               Whether to save the Playwright MCP session into
                               the output directory.
  --save-trace                 Whether to save the Playwright Trace of the
                               session into the output directory.
  --storage-state &lt;path&gt;       path to the storage state file for isolated
                               sessions.
  --user-agent &lt;ua string&gt;     specify user agent string
  --user-data-dir &lt;path&gt;       path to the user data directory. If not
                               specified, a temporary directory will be created.
  --viewport-size &lt;size&gt;       specify browser viewport size in pixels, for
                               example &quot;1280, 720&quot;
```

&lt;!--- End of options generated section --&gt;

### User profile

You can run Playwright MCP with persistent profile like a regular browser (default), in isolated contexts for testing sessions, or connect to your existing browser using the browser extension.

**Persistent profile**

All the logged in information will be stored in the persistent profile, you can delete it between sessions if you&#039;d like to clear the offline state.
Persistent profile is located at the following locations and you can override it with the `--user-data-dir` argument.

```bash
# Windows
%USERPROFILE%\AppData\Local\ms-playwright\mcp-{channel}-profile

# macOS
- ~/Library/Caches/ms-playwright/mcp-{channel}-profile

# Linux
- ~/.cache/ms-playwright/mcp-{channel}-profile
```

**Isolated**

In the isolated mode, each session is started in the isolated profile. Every time you ask MCP to close the browser,
the session is closed and all the storage state for this session is lost. You can provide initial storage state
to the browser via the config&#039;s `contextOptions` or via the `--storage-state` argument. Learn more about the storage
state [here](https://playwright.dev/docs/auth).

```js
{
  &quot;mcpServers&quot;: {
    &quot;playwright&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;@playwright/mcp@latest&quot;,
        &quot;--isolated&quot;,
        &quot;--storage-state={path/to/storage.json}&quot;
      ]
    }
  }
}
```

**Browser Extension**

The Playwright MCP Chrome Extension allows you to connect to existing browser tabs and leverage your logged-in sessions and browser state. See [extension/README.md](extension/README.md) for installation and setup instructions.

### Configuration file

The Playwright MCP server can be configured using a JSON configuration file. You can specify the configuration file
using the `--config` command line option:

```bash
npx @playwright/mcp@latest --config path/to/config.json
```

&lt;details&gt;
&lt;summary&gt;Configuration file schema&lt;/summary&gt;

```typescript
{
  // Browser configuration
  browser?: {
    // Browser type to use (chromium, firefox, or webkit)
    browserName?: &#039;chromium&#039; | &#039;firefox&#039; | &#039;webkit&#039;;

    // Keep the browser profile in memory, do not save it to disk.
    isolated?: boolean;

    // Path to user data directory for browser profile persistence
    userDataDir?: string;

    // Browser launch options (see Playwright docs)
    // @see https://playwright.dev/docs/api/class-browsertype#browser-type-launch
    launchOptions?: {
      channel?: string;        // Browser channel (e.g. &#039;chrome&#039;)
      headless?: boolean;      // Run in headless mode
      executablePath?: string; // Path to browser executable
      // ... other Playwright launch options
    };

    // Browser context options
    // @see https://playwright.dev/docs/api/class-browser#browser-new-context
    contextOptions?: {
      viewport?: { width: number, height: number };
      // ... other Playwright context options
    };

    // CDP endpoint for connecting to existing browser
    cdpEndpoint?: string;

    // Remote Playwright server endpoint
    remoteEndpoint?: string;
  },

  // Server configuration
  server?: {
    port?: number;  // Port to listen on
    host?: string;  // Host to bind to (default: localhost)
  },

  // List of additional capabilities
  capabilities?: Array&lt;
    &#039;tabs&#039; |    // Tab management
    &#039;install&#039; | // Browser installation
    &#039;pdf&#039; |     // PDF generation
    &#039;vision&#039; |  // Coordinate-based interactions
  &gt;;

  // Directory for output files
  outputDir?: string;

  // Network configuration
  network?: {
    // List of origins to allow the browser to request. Default is to allow all. Origins matching both `allowedOrigins` and `blockedOrigins` will be blocked.
    allowedOrigins?: string[];

    // List of origins to block the browser to request. Origins matching both `allowedOrigins` and `blockedOrigins` will be blocked.
    blockedOrigins?: string[];
  };
 
  /**
   * Whether to send image responses to the client. Can be &quot;allow&quot; or &quot;omit&quot;. 
   * Defaults to &quot;allow&quot;.
   */
  imageResponses?: &#039;allow&#039; | &#039;omit&#039;;
}
```
&lt;/details&gt;

### Standalone MCP server

When running headed browser on system w/o display or from worker processes of the IDEs,
run the MCP server from environment with the DISPLAY and pass the `--port` flag to enable HTTP transport.

```bash
npx @playwright/mcp@latest --port 8931
```

And then in MCP client config, set the `url` to the HTTP endpoint:

```js
{
  &quot;mcpServers&quot;: {
    &quot;playwright&quot;: {
      &quot;url&quot;: &quot;http://localhost:8931/mcp&quot;
    }
  }
}
```

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Docker&lt;/b&gt;&lt;/summary&gt;

**NOTE:** The Docker implementation only supports headless chromium at the moment.

```js
{
  &quot;mcpServers&quot;: {
    &quot;playwright&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [&quot;run&quot;, &quot;-i&quot;, &quot;--rm&quot;, &quot;--init&quot;, &quot;--pull=always&quot;, &quot;mcr.microsoft.com/playwright/mcp&quot;]
    }
  }
}
```

You can build the Docker image yourself.

```
docker build -t mcr.microsoft.com/playwright/mcp .
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Programmatic usage&lt;/b&gt;&lt;/summary&gt;

```js
import http from &#039;http&#039;;

import { createConnection } from &#039;@playwright/mcp&#039;;
import { SSEServerTransport } from &#039;@modelcontextprotocol/sdk/server/sse.js&#039;;

http.createServer(async (req, res) =&gt; {
  // ...

  // Creates a headless Playwright MCP server with SSE transport
  const connection = await createConnection({ browser: { launchOptions: { headless: true } } });
  const transport = new SSEServerTransport(&#039;/messages&#039;, res);
  await connection.sever.connect(transport);

  // ...
});
```
&lt;/details&gt;

### Tools

&lt;!--- Tools generated by update-readme.js --&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Core automation&lt;/b&gt;&lt;/summary&gt;

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_click**
  - Title: Click
  - Description: Perform click on a web page
  - Parameters:
    - `element` (string): Human-readable element description used to obtain permission to interact with the element
    - `ref` (string): Exact target element reference from the page snapshot
    - `doubleClick` (boolean, optional): Whether to perform a double click instead of a single click
    - `button` (string, optional): Button to click, defaults to left
  - Read-only: **false**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_close**
  - Title: Close browser
  - Description: Close the page
  - Parameters: None
  - Read-only: **true**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_console_messages**
  - Title: Get console messages
  - Description: Returns all console messages
  - Parameters: None
  - Read-only: **true**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_drag**
  - Title: Drag mouse
  - Description: Perform drag and drop between two elements
  - Parameters:
    - `startElement` (string): Human-readable source element description used to obtain the permission to interact with the element
    - `startRef` (string): Exact source element reference from the page snapshot
    - `endElement` (string): Human-readable target element description used to obtain the permission to interact with the element
    - `endRef` (string): Exact target element reference from the page snapshot
  - Read-only: **false**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_evaluate**
  - Title: Evaluate JavaScript
  - Description: Evaluate JavaScript expression on page or element
  - Parameters:
    - `function` (string): () =&gt; { /* code */ } or (element) =&gt; { /* code */ } when element is provided
    - `element` (string, optional): Human-readable element description used to obtain permission to interact with the element
    - `ref` (string, optional): Exact target element reference from the page snapshot
  - Read-only: **false**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_file_upload**
  - Title: Upload files
  - Description: Upload one or multiple files
  - Parameters:
    - `paths` (array): The absolute paths to the files to upload. Can be a single file or multiple files.
  - Read-only: **false**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_fill_form**
  - Title: Fill form
  - Description: Fill multiple form fields
  - Parameters:
    - `fields` (array): Fields to fill in
  - Read-only: **false**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_handle_dialog**
  - Title: Handle a dialog
  - Description: Handle a dialog
  - Parameters:
    - `accept` (boolean): Whether to accept the dialog.
    - `promptText` (string, optional): The text of the prompt in case of a prompt dialog.
  - Read-only: **false**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_hover**
  - Title: Hover mouse
  - Description: Hover over element on page
  - Parameters:
    - `element` (string): Human-readable element description used to obtain permission to interact with the element
    - `ref` (string): Exact target element reference from the page snapshot
  - Read-only: **true**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_navigate**
  - Title: Navigate to a URL
  - Description: Navigate to a URL
  - Parameters:
    - `url` (string): The URL to navigate to
  - Read-only: **false**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_navigate_back**
  - Title: Go back
  - Description: Go back to the previous page
  - Parameters: None
  - Read-only: **true**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_network_requests**
  - Title: List network requests
  - Description: Returns all network requests since loading the page
  - Parameters: None
  - Read-only: **true**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_press_key**
  - Title: Press a key
  - Description: Press a key on the keyboard
  - Parameters:
    - `key` (string): Name of the key to press or a character to generate, such as `ArrowLeft` or `a`
  - Read-only: **false**

&lt;!-- NOTE: This has been generated via update-readme.js --&gt;

- **browser_resize**
  - Ti

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[gyoridavid/short-video-maker]]></title>
            <link>https://github.com/gyoridavid/short-video-maker</link>
            <guid>https://github.com/gyoridavid/short-video-maker</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[Creates short videos for TikTok, Instagram Reels, and YouTube Shorts using the Model Context Protocol (MCP) and a REST API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gyoridavid/short-video-maker">gyoridavid/short-video-maker</a></h1>
            <p>Creates short videos for TikTok, Instagram Reels, and YouTube Shorts using the Model Context Protocol (MCP) and a REST API.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 646</p>
            <p>Forks: 236</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>## [üìö Join our Skool community for support, premium content and more!](https://www.skool.com/ai-agents-az/about?s1m)

### Be part of a growing community and help us create more content like this

# Description

An open source automated video creation tool for generating short-form video content. Short Video Maker combines text-to-speech, automatic captions, background videos, and music to create engaging short videos from simple text inputs.

This project is meant to provide a free alternative to heavy GPU-power hungry video generation (and a free alternative to expensive, third-party API calls). It doesn&#039;t generate a video from scratch based on an image or an image prompt.

The repository was open-sourced by the¬†[AI Agents A-Z Youtube Channel](https://www.youtube.com/channel/UCloXqLhp_KGhHBe1kwaL2Tg). We encourage you to check out the channel for more AI-related content and tutorials.

The server exposes an [MCP](https://github.com/modelcontextprotocol) and a REST server.

While the MCP server can be used with an AI Agent (like n8n) the REST endpoints provide more flexibility for video generation.

You can find example n8n workflows created with the REST/MCP server [in this repository](https://github.com/gyoridavid/ai_agents_az/tree/main/episode_7).

# TOC

## Getting started

- [Requirements](#general-requirements)
- [How to run the server](#getting-started-1)
- [Web UI](#web-ui)
- [Tutorial](#tutorial-with-n8n)
- [Examples](#examples)

## Usage

- [Environment variables](#environment-variables)
- [REST API](#rest-api)
- [Configuration options](#configuration-options)
- [MCP](#mcp-server)

## Info

- [Features](#features)
- [How it works](#how-it-works)
- [Limitations](#limitations)
- [Concepts](#concepts)
- [Troubleshooting](#troubleshooting)
- [Deploying in the cloud](#deploying-to-the-cloud)
- [FAQ](#faq)
- [Dependencies](#dependencies-for-the-video-generation)
- [Contributing](#how-to-contribute)
- [License](#license)
- [Acknowledgements](#acknowledgments)

# Tutorial with n8n

[![Automated faceless video generation (n8n + MCP) with captions, background music, local and 100% free](https://img.youtube.com/vi/jzsQpn-AciM/0.jpg)](https://www.youtube.com/watch?v=jzsQpn-AciM)

# Examples

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/1b488e7d-1b40-439d-8767-6ab51dbc0922&quot; width=&quot;480&quot; height=&quot;270&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/bb7ce80f-e6e1-44e5-ba4e-9b13d917f55b&quot; width=&quot;270&quot; height=&quot;480&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
&lt;td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

# Features

- Generate complete short videos from text prompts
- Text-to-speech conversion
- Automatic caption generation and styling
- Background video search and selection via Pexels
- Background music with genre/mood selection
- Serve as both REST API and Model Context Protocol (MCP) server

# How It Works

Shorts Creator takes simple text inputs and search terms, then:

1. Converts text to speech using Kokoro TTS
2. Generates accurate captions via Whisper
3. Finds relevant background videos from Pexels
4. Composes all elements with Remotion
5. Renders a professional-looking short video with perfectly timed captions

# Limitations

- The project only capable generating videos with English voiceover (kokoro-js doesn‚Äôt support other languages at the moment)
- The background videos are sourced from Pexels

# General Requirements

- internet
- free pexels api key
- ‚â• 3 gb free RAM, my recommendation is 4gb RAM
- ‚â• 2 vCPU
- ‚â• 5gb disc space


# Concepts

## Scene

Each video is assembled from multiple scenes. These scenes consists of

1. Text: Narration, the text the TTS will read and create captions from.
2. Search terms: The keywords the server should use to find videos from Pexels API. If none can be found, joker terms are being used (`nature`, `globe`, `space`, `ocean`)

# Getting started

## Docker (recommended)

There are three docker images, for three different use cases. Generally speaking, most of the time you want to spin up the `tiny` one.

### Tiny

- Uses the `tiny.en` whisper.cpp model
- Uses the `q4` quantized kokoro model
- `CONCURRENCY=1` to overcome OOM errors coming from Remotion with limited resources
- `VIDEO_CACHE_SIZE_IN_BYTES=2097152000` (2gb) to overcome OOM errors coming from Remotion with limited resources

```jsx
docker run -it --rm --name short-video-maker -p 3123:3123 -e LOG_LEVEL=debug -e PEXELS_API_KEY= gyoridavid/short-video-maker:latest-tiny
```

### Normal

- Uses the `base.en` whisper.cpp model
- Uses the `fp32` kokoro model
- `CONCURRENCY=1` to overcome OOM errors coming from Remotion with limited resources
- `VIDEO_CACHE_SIZE_IN_BYTES=2097152000` (2gb) to overcome OOM errors coming from Remotion with limited resources

```jsx
docker run -it --rm --name short-video-maker -p 3123:3123 -e LOG_LEVEL=debug -e PEXELS_API_KEY= gyoridavid/short-video-maker:latest
```

### Cuda

If you own an Nvidia GPU and you want use a larger whisper model with GPU acceleration, you can use the CUDA optimised Docker image.

- Uses the `medium.en` whisper.cpp model (with GPU acceleration)
- Uses `fp32` kokoro model
- `CONCURRENCY=1` to overcome OOM errors coming from Remotion with limited resources
- `VIDEO_CACHE_SIZE_IN_BYTES=2097152000` (2gb) to overcome OOM errors coming from Remotion with limited resources

```jsx
docker run -it --rm --name short-video-maker -p 3123:3123 -e LOG_LEVEL=debug -e PEXELS_API_KEY= --gpus=all gyoridavid/short-video-maker:latest-cuda
```

## Docker compose

You might use Docker Compose to run n8n or other services, and you want to combine them. Make sure you add the shared network to the service configuration.

```bash
version: &quot;3&quot;

services:
  short-video-maker:
    image: gyoridavid/short-video-maker:latest-tiny
    environment:
      - LOG_LEVEL=debug
      - PEXELS_API_KEY=
    ports:
      - &quot;3123:3123&quot;
    volumes:
	    - ./videos:/app/data/videos # expose the generated videos

```

If you are using the [Self-hosted AI starter kit](https://github.com/n8n-io/self-hosted-ai-starter-kit) you want to add `networks: [&#039;demo&#039;]` to the\*\* `short-video-maker` service so you can reach it with http://short-video-maker:3123 in n8n.

# NPM

While Docker is the recommended way to run the project, you can run it with npm or npx.
On top of the general requirements, the following are necessary to run the server.

## Supported platforms

- Ubuntu ‚â• 22.04 (libc 2.5 for Whisper.cpp)
  - Required packages: `git wget cmake ffmpeg curl make libsdl2-dev libnss3 libdbus-1-3 libatk1.0-0 libgbm-dev libasound2 libxrandr2 libxkbcommon-dev libxfixes3 libxcomposite1 libxdamage1 libatk-bridge2.0-0 libpango-1.0-0 libcairo2 libcups2`
- Mac OS
  - ffmpeg (`brew install ffmpeg`)
  - node.js (tested on 22+)

Windows is **NOT** supported at the moment (whisper.cpp installation fails occasionally).

# Web UI

@mushitori made a Web UI to generate the videos from your browser.

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      &lt;img width=&quot;1088&quot; alt=&quot;Screenshot 2025-05-12 at 1 45 11‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/2ab64aea-f639-41b0-bd19-2fcf73bb1a3d&quot; /&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;img width=&quot;1075&quot; alt=&quot;Screenshot 2025-05-12 at 1 45 44‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/0ff568fe-ddcb-4dad-ae62-2640290aef1e&quot; /&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;img width=&quot;1083&quot; alt=&quot;Screenshot 2025-05-12 at 1 45 51‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/d3c1c826-3cb3-4313-b17c-605ff612fb63&quot; /&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;img width=&quot;1070&quot; alt=&quot;Screenshot 2025-05-12 at 1 46 42‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/18edb1a0-9fc2-48b3-8896-e919e7dc57ff&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

You can load it on http://localhost:3123

# Environment variables

## üü¢¬†Configuration

| key             | description                                                     | default |
| --------------- | --------------------------------------------------------------- | ------- |
| PEXELS_API_KEY  | [your (free) Pexels API key](https://www.pexels.com/api/)       |         |
| LOG_LEVEL       | pino log level                                                  | info    |
| WHISPER_VERBOSE | whether the output of whisper.cpp should be forwarded to stdout | false   |
| PORT            | the port the server will listen on                              | 3123    |

## ‚öôÔ∏è¬†System configuration

| key                       | description                                                                                                                                                                                                                                                                           | default                                                     |
| ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------- |
| KOKORO_MODEL_PRECISION    | The size of the Kokoro model to use. Valid options are `fp32`, `fp16`, `q8`, `q4`, `q4f16`                                                                                                                                                                                            | depends, see the descriptions of the docker images above ^^ |
| CONCURRENCY               | [concurrency refers to how many browser tabs are opened in parallel during a render. Each Chrome tab renders web content and then screenshots it.](https://www.remotion.dev/docs/terminology/concurrency). Tweaking this value helps with running the project with limited resources. | depends, see the descriptions of the docker images above ^^ |
| VIDEO_CACHE_SIZE_IN_BYTES | Cache for¬†[&lt;OffthreadVideo&gt;](https://remotion.dev/docs/offthreadvideo) frames in Remotion. Tweaking this value helps with running the project with limited resources.                                                                                                                 | depends, see the descriptions of the docker images above ^^ |

## ‚ö†Ô∏è¬†Danger zone

| key           | description                                                                                                                                                                              | default                                                                                              |
| ------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |
| WHISPER_MODEL | Which whisper.cpp model to use. Valid options are `tiny`, `tiny.en`, `base`, `base.en`, `small`, `small.en`, `medium`, `medium.en`, `large-v1`, `large-v2`, `large-v3`, `large-v3-turbo` | Depends, see the descriptions of the docker images above. For npm, the default option is `medium.en` |
| DATA_DIR_PATH | the data directory of the project                                                                                                                                                        | `~/.ai-agents-az-video-generator` with npm, `/app/data` in the Docker images                         |
| DOCKER        | whether the project is running in a Docker container                                                                                                                                     | `true` for the docker images, otherwise `false`                                                      |
| DEV           | guess! :)                                                                                                                                                                                | `false`                                                                                              |

# Configuration options

| key                    | description                                                                                                    | default    |
| ---------------------- | -------------------------------------------------------------------------------------------------------------- | ---------- |
| paddingBack            | The end screen, for how long the video should keep playing after the narration has finished (in milliseconds). | 0          |
| music                  | The mood of the background music. Get the available options from the GET `/api/music-tags` endpoint.           | random     |
| captionPosition        | The position where the captions should be rendered. Possible options: `top`, `center`, `bottom`. Default value | `bottom`   |
| captionBackgroundColor | The background color of the active caption item.                                                               | `blue`     |
| voice                  | The Kokoro voice.                                                                                              | `af_heart` |
| orientation            | The video orientation. Possible options are `portrait` and `landscape`                                         | `portrait` |
| musicVolume            | Set the volume of the background music. Possible options are `low` `medium` `high` and `muted`                 | `high`     |

# Usage

## MCP server

## Server URLs

`/mcp/sse`

`/mcp/messages`

## Available tools

- `create-short-video` Creates a short video - the LLM will figure out the right configuration. If you want to use specific configuration, you need to specify those in you prompt.
- `get-video-status` Somewhat useless, it‚Äôs meant for checking the status of the video, but since the AI agents aren‚Äôt really good with the concept of time, you‚Äôll probably will end up using the REST API for that anyway.

# REST API

### GET `/health`

Healthcheck endpoint

```bash
curl --location &#039;localhost:3123/health&#039;
```

```bash
{
    &quot;status&quot;: &quot;ok&quot;
}
```

### POST `/api/short-video`

```bash
curl --location &#039;localhost:3123/api/short-video&#039; \
--header &#039;Content-Type: application/json&#039; \
--data &#039;{
    &quot;scenes&quot;: [
      {
        &quot;text&quot;: &quot;Hello world!&quot;,
        &quot;searchTerms&quot;: [&quot;river&quot;]
      }
    ],
    &quot;config&quot;: {
      &quot;paddingBack&quot;: 1500,
      &quot;music&quot;: &quot;chill&quot;
    }
}&#039;
```

```bash
{
    &quot;videoId&quot;: &quot;cma9sjly700020jo25vwzfnv9&quot;
}
```

### GET `/api/short-video/{id}/status`

```bash
curl --location &#039;localhost:3123/api/short-video/cm9ekme790000hysi5h4odlt1/status&#039;
```

```bash
{
    &quot;status&quot;: &quot;ready&quot;
}
```

### GET `/api/short-video/{id}`

```bash
curl --location &#039;localhost:3123/api/short-video/cm9ekme790000hysi5h4odlt1&#039;
```

Response: the binary data of the video.

### GET `/api/short-videos`

```bash
curl --location &#039;localhost:3123/api/short-videos&#039;
```

```bash
{
    &quot;videos&quot;: [
        {
            &quot;id&quot;: &quot;cma9wcwfc0000brsi60ur4lib&quot;,
            &quot;status&quot;: &quot;processing&quot;
        }
    ]
}
```

### DELETE `/api/short-video/{id}`

```bash
curl --location --request DELETE &#039;localhost:3123/api/short-video/cma9wcwfc0000brsi60ur4lib&#039;
```

```bash
{
    &quot;success&quot;: true
}
```

### GET `/api/voices`

```bash
curl --location &#039;localhost:3123/api/voices&#039;
```

```bash
[
    &quot;af_heart&quot;,
    &quot;af_alloy&quot;,
    &quot;af_aoede&quot;,
    &quot;af_bella&quot;,
    &quot;af_jessica&quot;,
    &quot;af_kore&quot;,
    &quot;af_nicole&quot;,
    &quot;af_nova&quot;,
    &quot;af_river&quot;,
    &quot;af_sarah&quot;,
    &quot;af_sky&quot;,
    &quot;am_adam&quot;,
    &quot;am_echo&quot;,
    &quot;am_eric&quot;,
    &quot;am_fenrir&quot;,
    &quot;am_liam&quot;,
    &quot;am_michael&quot;,
    &quot;am_onyx&quot;,
    &quot;am_puck&quot;,
    &quot;am_santa&quot;,
    &quot;bf_emma&quot;,
    &quot;bf_isabella&quot;,
    &quot;bm_george&quot;,
    &quot;bm_lewis&quot;,
    &quot;bf_alice&quot;,
    &quot;bf_lily&quot;,
    &quot;bm_daniel&quot;,
    &quot;bm_fable&quot;
]
```

### GET `/api/music-tags`

```bash
curl --location &#039;localhost:3123/api/music-tags&#039;
```

```bash
[
    &quot;sad&quot;,
    &quot;melancholic&quot;,
    &quot;happy&quot;,
    &quot;euphoric/high&quot;,
    &quot;excited&quot;,
    &quot;chill&quot;,
    &quot;uneasy&quot;,
    &quot;angry&quot;,
    &quot;dark&quot;,
    &quot;hopeful&quot;,
    &quot;contemplative&quot;,
    &quot;funny/quirky&quot;
]
```

# Troubleshooting

## Docker

The server needs at least 3gb free memory. Make sure to allocate enough RAM to Docker.

If you are running the server from Windows and via wsl2, you need to set the resource limits from the [wsl utility 2](https://learn.microsoft.com/en-us/windows/wsl/wsl-config#configure-global-options-with-wslconfig) - otherwise set it from Docker Desktop. (Ubuntu is not restricting the resources unless specified with the run command).

## NPM

Make sure all the necessary packages are installed.

# n8n

Setting up the MCP (or REST) server depends on how you run n8n and the server. Please follow the examples from the matrix below.

|                                                   | n8n is running locally, using `n8n start`              | n8n is running locally using Docker                                                                                                                                                                                           | n8n is running in the cloud                            |
| ------------------------------------------------- | ------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------ |
| `short-video-maker` is running in Docker, locally | `http://localhost:3123`                                | It depends. You can technically use `http://host.docker.internal:3123` as it points to the host, but you could configure to use the same network and use the service name to communicate like `http://short-video-maker:3123` | won‚Äôt work - deploy `short-video-maker` to the cloud   |
| `short-video-maker` is running with npm/npx       | `http://localhost:3123`                                | `http://host.docker.internal:3123`                                                                                                                                                                                            | won‚Äôt work - deploy `short-video-maker` to the cloud   |
| `short-video-maker` is running in the cloud       | You should use your IP address `http://{YOUR_IP}:3123` | You should use your IP address `http://{YOUR_IP}:3123`                                                                                                                                                                        | You should use your IP address `http://{YOUR_IP}:3123` |

# Deploying to the cloud

While each VPS provider is different, and it‚Äôs impossible to provide configuration to all of them, here are some tips.

- Use Ubuntu ‚â• 22.04
- Have ‚â• 4gb RAM, ‚â• 2vCPUs and ‚â•5gb storage
- Use [pm2](https://pm2.keymetrics.io/) to run/manage the server
- Put the environment variables to the `.bashrc` file (or similar)

# FAQ

## Can I use other languages? (French, German etc.)

Unfortunately, it‚Äôs not possible at the moment. Kokoro-js only supports English.

## Can I pass in images and videos and can it stitch it together

No

## Should I run the project with `npm` or `docker`?

Docker is the recommended way to run the project.

## How much GPU is being used for the video generation?

Honestly, not a lot - only whisper.cpp can be accelerated.

Remotion is CPU-heavy, and [Kokoro-js](https://gi

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[sst/opencode]]></title>
            <link>https://github.com/sst/opencode</link>
            <guid>https://github.com/sst/opencode</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:42 GMT</pubDate>
            <description><![CDATA[AI coding agent, built for the terminal.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sst/opencode">sst/opencode</a></h1>
            <p>AI coding agent, built for the terminal.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,352</p>
            <p>Forks: 1,444</p>
            <p>Stars today: 131 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencode.ai&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;packages/web/src/assets/logo-ornate-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;packages/web/src/assets/logo-ornate-light.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;packages/web/src/assets/logo-ornate-light.svg&quot; alt=&quot;opencode logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;AI coding agent, built for the terminal.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencode.ai/discord&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;label=discord&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/opencode-ai&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/opencode-ai?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/sst/opencode/actions/workflows/publish.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/sst/opencode/publish.yml?style=flat-square&amp;branch=dev&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

[![opencode Terminal UI](packages/web/src/assets/lander/screenshot.png)](https://opencode.ai)

---

### Installation

```bash
# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
brew install sst/tap/opencode      # macOS and Linux
paru -S opencode-bin               # Arch Linux
```

&gt; [!TIP]
&gt; Remove versions older than 0.1.x before installing.

#### Installation Directory

The install script respects the following priority order for the installation path:

1. `$OPENCODE_INSTALL_DIR` - Custom installation directory
2. `$XDG_BIN_DIR` - XDG Base Directory Specification compliant path
3. `$HOME/bin` - Standard user binary directory (if exists or can be created)
4. `$HOME/.opencode/bin` - Default fallback

```bash
# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
```

### Documentation

For more info on how to configure opencode [**head over to our docs**](https://opencode.ai/docs).

### Contributing

opencode is an opinionated tool so any fundamental feature needs to go through a
design process with the core team.

&gt; [!IMPORTANT]
&gt; We do not accept PRs for core features.

However we still merge a ton of PRs - you can contribute:

- Bug fixes
- Improvements to LLM performance
- Support for new providers
- Fixes for env specific quirks
- Missing standard behavior
- Documentation

Take a look at the git history to see what kind of PRs we end up merging.

&gt; [!NOTE]
&gt; If you do not follow the above guidelines we might close your PR.

To run opencode locally you need.

- Bun
- Golang 1.24.x

And run.

```bash
$ bun install
$ bun dev
```

#### Development Notes

**API Client**: After making changes to the TypeScript API endpoints in `packages/opencode/src/server/server.ts`, you will need the opencode team to generate a new stainless sdk for the clients.

### FAQ

#### How is this different than Claude Code?

It&#039;s very similar to Claude Code in terms of capability. Here are the key differences:

- 100% open source
- Not coupled to any provider. Although Anthropic is recommended, opencode can be used with OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.
- A focus on TUI. opencode is built by neovim users and the creators of [terminal.shop](https://terminal.shop); we are going to push the limits of what&#039;s possible in the terminal.
- A client/server architecture. This for example can allow opencode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.

#### What&#039;s the other repo?

The other confusingly named repo has no relation to this one. You can [read the story behind it here](https://x.com/thdxr/status/1933561254481666466).

---

**Join our community** [Discord](https://discord.gg/opencode) | [YouTube](https://www.youtube.com/c/sst-dev) | [X.com](https://x.com/anomaly_inv)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[shadcn-ui/ui]]></title>
            <link>https://github.com/shadcn-ui/ui</link>
            <guid>https://github.com/shadcn-ui/ui</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:41 GMT</pubDate>
            <description><![CDATA[A set of beautifully-designed, accessible components and a code distribution platform. Works with your favorite frameworks. Open Source. Open Code.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/shadcn-ui/ui">shadcn-ui/ui</a></h1>
            <p>A set of beautifully-designed, accessible components and a code distribution platform. Works with your favorite frameworks. Open Source. Open Code.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 93,824</p>
            <p>Forks: 6,582</p>
            <p>Stars today: 76 stars today</p>
            <h2>README</h2><pre># shadcn/ui

Accessible and customizable components that you can copy and paste into your apps. Free. Open Source. **Use this to build your own component library**.

![hero](apps/www/public/og.jpg)

## Documentation

Visit http://ui.shadcn.com/docs to view the documentation.

## Contributing

Please read the [contributing guide](/CONTRIBUTING.md).

## License

Licensed under the [MIT license](https://github.com/shadcn/ui/blob/main/LICENSE.md).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[n8n-io/n8n]]></title>
            <link>https://github.com/n8n-io/n8n</link>
            <guid>https://github.com/n8n-io/n8n</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:40 GMT</pubDate>
            <description><![CDATA[Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/n8n-io/n8n">n8n-io/n8n</a></h1>
            <p>Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 133,444</p>
            <p>Forks: 41,637</p>
            <p>Stars today: 306 stars today</p>
            <h2>README</h2><pre>![Banner image](https://user-images.githubusercontent.com/10284570/173569848-c624317f-42b1-45a6-ab09-f0ea3c247648.png)

# n8n - Secure Workflow Automation for Technical Teams

n8n is a workflow automation platform that gives technical teams the flexibility of code with the speed of no-code. With 400+ integrations, native AI capabilities, and a fair-code license, n8n lets you build powerful automations while maintaining full control over your data and deployments.

![n8n.io - Screenshot](https://raw.githubusercontent.com/n8n-io/n8n/master/assets/n8n-screenshot-readme.png)

## Key Capabilities

- **Code When You Need It**: Write JavaScript/Python, add npm packages, or use the visual interface
- **AI-Native Platform**: Build AI agent workflows based on LangChain with your own data and models
- **Full Control**: Self-host with our fair-code license or use our [cloud offering](https://app.n8n.cloud/login)
- **Enterprise-Ready**: Advanced permissions, SSO, and air-gapped deployments
- **Active Community**: 400+ integrations and 900+ ready-to-use [templates](https://n8n.io/workflows)

## Quick Start

Try n8n instantly with [npx](https://docs.n8n.io/hosting/installation/npm/) (requires [Node.js](https://nodejs.org/en/)):

```
npx n8n
```

Or deploy with [Docker](https://docs.n8n.io/hosting/installation/docker/):

```
docker volume create n8n_data
docker run -it --rm --name n8n -p 5678:5678 -v n8n_data:/home/node/.n8n docker.n8n.io/n8nio/n8n
```

Access the editor at http://localhost:5678

## Resources

- üìö [Documentation](https://docs.n8n.io)
- üîß [400+ Integrations](https://n8n.io/integrations)
- üí° [Example Workflows](https://n8n.io/workflows)
- ü§ñ [AI &amp; LangChain Guide](https://docs.n8n.io/langchain/)
- üë• [Community Forum](https://community.n8n.io)
- üìñ [Community Tutorials](https://community.n8n.io/c/tutorials/28)

## Support

Need help? Our community forum is the place to get support and connect with other users:
[community.n8n.io](https://community.n8n.io)

## License

n8n is [fair-code](https://faircode.io) distributed under the [Sustainable Use License](https://github.com/n8n-io/n8n/blob/master/LICENSE.md) and [n8n Enterprise License](https://github.com/n8n-io/n8n/blob/master/LICENSE_EE.md).

- **Source Available**: Always visible source code
- **Self-Hostable**: Deploy anywhere
- **Extensible**: Add your own nodes and functionality

[Enterprise licenses](mailto:license@n8n.io) available for additional features and support.

Additional information about the license model can be found in the [docs](https://docs.n8n.io/reference/license/).

## Contributing

Found a bug üêõ or have a feature idea ‚ú®? Check our [Contributing Guide](https://github.com/n8n-io/n8n/blob/master/CONTRIBUTING.md) to get started.

## Join the Team

Want to shape the future of automation? Check out our [job posts](https://n8n.io/careers) and join our team!

## What does n8n mean?

**Short answer:** It means &quot;nodemation&quot; and is pronounced as n-eight-n.

**Long answer:** &quot;I get that question quite often (more often than I expected) so I decided it is probably best to answer it here. While looking for a good name for the project with a free domain I realized very quickly that all the good ones I could think of were already taken. So, in the end, I chose nodemation. &#039;node-&#039; in the sense that it uses a Node-View and that it uses Node.js and &#039;-mation&#039; for &#039;automation&#039; which is what the project is supposed to help with. However, I did not like how long the name was and I could not imagine writing something that long every time in the CLI. That is when I then ended up on &#039;n8n&#039;.&quot; - **Jan Oberhauser, Founder and CEO, n8n.io**
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[modelcontextprotocol/servers]]></title>
            <link>https://github.com/modelcontextprotocol/servers</link>
            <guid>https://github.com/modelcontextprotocol/servers</guid>
            <pubDate>Fri, 29 Aug 2025 00:04:39 GMT</pubDate>
            <description><![CDATA[Model Context Protocol Servers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/modelcontextprotocol/servers">modelcontextprotocol/servers</a></h1>
            <p>Model Context Protocol Servers</p>
            <p>Language: TypeScript</p>
            <p>Stars: 66,090</p>
            <p>Forks: 7,735</p>
            <p>Stars today: 143 stars today</p>
            <h2>README</h2><pre># Model Context Protocol servers

This repository is a collection of *reference implementations* for the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), as well as references to community-built servers and additional resources.

The servers in this repository showcase the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources.
Typically, each MCP server is implemented with an MCP SDK:

- [C# MCP SDK](https://github.com/modelcontextprotocol/csharp-sdk)
- [Go MCP SDK](https://github.com/modelcontextprotocol/go-sdk)
- [Java MCP SDK](https://github.com/modelcontextprotocol/java-sdk)
- [Kotlin MCP SDK](https://github.com/modelcontextprotocol/kotlin-sdk)
- [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk)
- [Ruby MCP SDK](https://github.com/modelcontextprotocol/ruby-sdk)
- [Rust MCP SDK](https://github.com/modelcontextprotocol/rust-sdk)
- [Swift MCP SDK](https://github.com/modelcontextprotocol/swift-sdk)
- [TypeScript MCP SDK](https://github.com/modelcontextprotocol/typescript-sdk)

&gt; [!NOTE]
&gt; Lists in this README are maintained in alphabetical order to minimize merge conflicts when adding new items.

## üåü Reference Servers

These servers aim to demonstrate MCP features and the official SDKs.

- **[Everything](src/everything)** - Reference / test server with prompts, resources, and tools.
- **[Fetch](src/fetch)** - Web content fetching and conversion for efficient LLM usage.
- **[Filesystem](src/filesystem)** - Secure file operations with configurable access controls.
- **[Git](src/git)** - Tools to read, search, and manipulate Git repositories.
- **[Memory](src/memory)** - Knowledge graph-based persistent memory system.
- **[Sequential Thinking](src/sequentialthinking)** - Dynamic and reflective problem-solving through thought sequences.
- **[Time](src/time)** - Time and timezone conversion capabilities.

### Archived

The following reference servers are now archived and can be found at [servers-archived](https://github.com/modelcontextprotocol/servers-archived).

- **[AWS KB Retrieval](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/aws-kb-retrieval-server)** - Retrieval from AWS Knowledge Base using Bedrock Agent Runtime.
- **[Brave Search](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/brave-search)** - Web and local search using Brave&#039;s Search API.  Has been replaced by the [official server](https://github.com/brave/brave-search-mcp-server).
- **[EverArt](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/everart)** - AI image generation using various models.
- **[GitHub](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/github)** - Repository management, file operations, and GitHub API integration.
- **[GitLab](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gitlab)** - GitLab API, enabling project management.
- **[Google Drive](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/gdrive)** - File access and search capabilities for Google Drive.
- **[Google Maps](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/google-maps)** - Location services, directions, and place details.
- **[PostgreSQL](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/postgres)** - Read-only database access with schema inspection.
- **[Puppeteer](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/puppeteer)** - Browser automation and web scraping.
- **[Redis](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/redis)** - Interact with Redis key-value stores.
- **[Sentry](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sentry)** - Retrieving and analyzing issues from Sentry.io.
- **[Slack](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/slack)** - Channel management and messaging capabilities. Now maintained by [Zencoder](https://github.com/zencoderai/slack-mcp-server)
- **[SQLite](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sqlite)** - Database interaction and business intelligence capabilities.

## ü§ù Third-Party Servers

### üéñÔ∏è Official Integrations

Official integrations are maintained by companies building production ready MCP servers for their platforms.

- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://www.21st.dev/favicon.ico&quot; alt=&quot;21st.dev Logo&quot; /&gt; **[21st.dev Magic](https://github.com/21st-dev/magic-mcp)** - Create crafted UI components inspired by the best 21st.dev design engineers.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://framerusercontent.com/images/LpSK1tSZweomrAHOMAj9Gea96lA.svg&quot; alt=&quot;Paragon Logo&quot; /&gt; **[ActionKit by Paragon](https://github.com/useparagon/paragon-mcp)** - Connect to 130+ SaaS integrations (e.g. Slack, Salesforce, Gmail) with Paragon‚Äôs [ActionKit](https://www.useparagon.com/actionkit) API.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://invoxx-public-bucket.s3.eu-central-1.amazonaws.com/frontend-resources/adfin-logo-small.svg&quot; alt=&quot;Adfin Logo&quot; /&gt; **[Adfin](https://github.com/Adfin-Engineering/mcp-server-adfin)** - The only platform you need to get paid - all payments in one place, invoicing and accounting reconciliations with [Adfin](https://www.adfin.com/).
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://github.com/AgentOps-AI/agentops/blob/main/docs/favicon.png&quot; alt=&quot;AgentOps Logo&quot; /&gt; **[AgentOps](https://github.com/AgentOps-AI/agentops-mcp)** - Provide observability and tracing for debugging AI agents with [AgentOps](https://www.agentops.ai/) API.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://www.agentql.com/favicon/favicon.png&quot; alt=&quot;AgentQL Logo&quot; /&gt; **[AgentQL](https://github.com/tinyfish-io/agentql-mcp)** - Enable AI agents to get structured data from unstructured web with [AgentQL](https://www.agentql.com/).
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://agentrpc.com/favicon.ico&quot; alt=&quot;AgentRPC Logo&quot; /&gt; **[AgentRPC](https://github.com/agentrpc/agentrpc)** - Connect to any function, any language, across network boundaries using [AgentRPC](https://www.agentrpc.com/).
- **[Agentset](https://github.com/agentset-ai/mcp-server)** - RAG for your knowledge base connected to [Agentset](https://agentset.ai).
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://aiven.io/favicon.ico&quot; alt=&quot;Aiven Logo&quot; /&gt; **[Aiven](https://github.com/Aiven-Open/mcp-aiven)** - Navigate your [Aiven projects](https://go.aiven.io/mcp-server) and interact with the PostgreSQL¬Æ, Apache Kafka¬Æ, ClickHouse¬Æ and OpenSearch¬Æ services
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://www.alation.com/resource-center/download/7p3vnbbznfiw/34FMtBTex5ppvs2hNYa9Fc/c877c37e88e5339878658697c46d2d58/Alation-Logo-Bug-Primary.svg&quot; alt=&quot;Alation Logo&quot; /&gt; **[Alation](https://github.com/Alation/alation-ai-agent-sdk)** - Unlock the power of the enterprise Data Catalog by harnessing tools provided by the Alation MCP server.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://i.postimg.cc/5NYw9qjS/alby-icon-head-yellow-500x500.png&quot; alt=&quot;Alby Logo&quot; /&gt; **[Alby Bitcoin Payments](https://github.com/getAlby/mcp)** - Connect any bitcoin lightning wallet to your agent to send and receive instant payments globally with your agent.
- **[Algolia](https://github.com/algolia/mcp)** - Use AI agents to provision, configure, and query your [Algolia](https://algolia.com) search indices.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://img.alicdn.com/imgextra/i4/O1CN01epkXwH1WLAXkZfV6N_!!6000000002771-2-tps-200-200.png&quot; alt=&quot;Alibaba Cloud AnalyticDB for MySQL Logo&quot; /&gt; **[Alibaba Cloud AnalyticDB for MySQL](https://github.com/aliyun/alibabacloud-adb-mysql-mcp-server)** - Connect to an [AnalyticDB for MySQL](https://www.alibabacloud.com/en/product/analyticdb-for-mysql) cluster for getting database or table metadata, querying and analyzing data. It will be supported to add the OpenAPI for cluster operation in the future.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://github.com/aliyun/alibabacloud-adbpg-mcp-server/blob/master/images/AnalyticDB.png&quot; alt=&quot;Alibaba Cloud AnalyticDB for PostgreSQL Logo&quot; /&gt; **[Alibaba Cloud AnalyticDB for PostgreSQL](https://github.com/aliyun/alibabacloud-adbpg-mcp-server)** - An MCP server to connect to [AnalyticDB for PostgreSQL](https://github.com/aliyun/alibabacloud-adbpg-mcp-server) instances, query and analyze data.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://img.alicdn.com/imgextra/i3/O1CN0101UWWF1UYn3rAe3HU_!!6000000002530-2-tps-32-32.png&quot; alt=&quot;DataWorks Logo&quot; /&gt; **[Alibaba Cloud DataWorks](https://github.com/aliyun/alibabacloud-dataworks-mcp-server)** - A Model Context Protocol (MCP) server that provides tools for AI, allowing it to interact with the [DataWorks](https://www.alibabacloud.com/help/en/dataworks/) Open API through a standardized interface. This implementation is based on the Alibaba Cloud Open API and enables AI agents to perform cloud resources operations seamlessly.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://opensearch-shanghai.oss-cn-shanghai.aliyuncs.com/ouhuang/aliyun-icon.png&quot; alt=&quot;Alibaba Cloud OpenSearch Logo&quot; /&gt; **[Alibaba Cloud OpenSearch](https://github.com/aliyun/alibabacloud-opensearch-mcp-server)** - This MCP server equips AI Agents with tools to interact with [OpenSearch](https://help.aliyun.com/zh/open-search/?spm=5176.7946605.J_5253785160.6.28098651AaYZXC) through a standardized and extensible interface.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://github.com/aliyun/alibaba-cloud-ops-mcp-server/blob/master/image/alibaba-cloud.png&quot; alt=&quot;Alibaba Cloud OPS Logo&quot; /&gt; **[Alibaba Cloud OPS](https://github.com/aliyun/alibaba-cloud-ops-mcp-server)** - Manage the lifecycle of your Alibaba Cloud resources with [CloudOps Orchestration Service](https://www.alibabacloud.com/en/product/oos) and Alibaba Cloud OpenAPI.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server/blob/main/assets/alibabacloudrds.png&quot; alt=&quot;Alibaba Cloud RDS MySQL Logo&quot; /&gt; **[Alibaba Cloud RDS](https://github.com/aliyun/alibabacloud-rds-openapi-mcp-server)** - An MCP server designed to interact with the Alibaba Cloud RDS OpenAPI, enabling programmatic management of RDS resources via an LLM.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://www.alipayplus.com/favicon.ico&quot; alt=&quot;AlipayPlus Logo&quot; /&gt; **[AlipayPlus](https://github.com/alipay/global-alipayplus-mcp)** - Connect your AI Agents to AlipayPlus Checkout Payment.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://cdn.allvoicelab.com/resources/workbench/dist/icon-dark.ico&quot; alt=&quot;AllVoiceLab Logo&quot; /&gt; **[AllVoiceLab](https://www.allvoicelab.com/mcp)** - An AI voice toolkit with TTS, voice cloning, and video translation, now available as an MCP server for smarter agent integration.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://files.alpaca.markets/webassets/favicon-32x32.png&quot; alt=&quot;Alpaca Logo&quot; /&gt; **[Alpaca](https://github.com/alpacahq/alpaca-mcp-server)** ‚Äì Alpaca&#039;s MCP server lets you trade stocks and options, analyze market data, and build strategies through [Alpaca&#039;s Trading API](https://alpaca.markets/)
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://www.alphavantage.co/logo.png/&quot; alt=&quot;AlphaVantage Logo&quot; /&gt; **[AlphaVantage](https://mcp.alphavantage.co/)** - Connect to 100+ APIs for financial market data, including stock prices, fundamentals, and more from [AlphaVantage](https://www.alphavantage.co)
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://www.antom.com/favicon.ico&quot; alt=&quot;Antom Logo&quot; /&gt; **[Antom](https://github.com/alipay/global-antom-mcp)** - Connect your AI Agents to Antom Checkout Payment.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://developers.anytype.io/img/favicon.ico&quot; alt=&quot;Anytype Logo&quot; /&gt; **[Anytype](https://github.com/anyproto/anytype-mcp)** - An MCP server enabling AI assistants to interact with [Anytype](https://anytype.io) - a local and collaborative wiki - to organize objects, lists, and more through natural language.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://doris.apache.org/images/favicon.ico&quot; alt=&quot;Apache Doris Logo&quot; /&gt; **[Apache Doris](https://github.com/apache/doris-mcp-server)** - MCP Server For [Apache Doris](https://doris.apache.org/), an MPP-based real-time data warehouse.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://iotdb.apache.org/img/logo.svg&quot; alt=&quot;Apache IoTDB Logo&quot; /&gt; **[Apache IoTDB](https://github.com/apache/iotdb-mcp-server)** - MCP Server for [Apache IoTDB](https://github.com/apache/iotdb) database and its tools
- **[Apache Pinot](https://github.com/startreedata/mcp-pinot)** ‚Äì MCP server for running real - time analytics queries on Apache Pinot, an open-source OLAP database built for high-throughput, low-latency powering real-time applications.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://apify.com/favicon.ico&quot; alt=&quot;Apify Logo&quot; /&gt; **[Apify](https://github.com/apify/actors-mcp-server)** - [Actors MCP Server](https://apify.com/apify/actors-mcp-server): Use 3,000+ pre-built cloud tools to extract data from websites, e-commerce, social media, search engines, maps, and more
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://2052727.fs1.hubspotusercontent-na1.net/hubfs/2052727/cropped-cropped-apimaticio-favicon-1-32x32.png&quot; alt=&quot;APIMatic Logo&quot; /&gt; **[APIMatic MCP](https://github.com/apimatic/apimatic-validator-mcp)** - APIMatic MCP Server is used to validate OpenAPI specifications using [APIMatic](https://www.apimatic.io/). The server processes OpenAPI files and returns validation summaries by leveraging APIMatic&#039;s API.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://apollo-server-landing-page.cdn.apollographql.com/_latest/assets/favicon.png&quot; alt=&quot;Apollo Graph Logo&quot; /&gt; **[Apollo MCP Server](https://github.com/apollographql/apollo-mcp-server/)** - Connect your GraphQL APIs to AI agents
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://developer.aqara.com/favicon.ico&quot; alt=&quot;Aqara Logo&quot; /&gt; **[Aqara MCP Server](https://github.com/aqara/aqara-mcp-server/)** - Control  [Aqara](https://www.aqara.com/) smart home devices, query status, execute scenes, and much more using natural language.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://media.licdn.com/dms/image/v2/C4D0BAQEeD7Dxbpadkw/company-logo_200_200/company-logo_200_200/0/1644692667545/archbee_logo?e=2147483647&amp;v=beta&amp;t=lTi9GRIoqzG6jN3kJC26uZWh0q3uiQelsH6mGoq_Wfw&quot; alt=&quot;Archbee Logo&quot; /&gt; **[Archbee](https://www.npmjs.com/package/@archbee/mcp)** - Write and publish documentation that becomes the trusted source for instant answers with AI. Stop cobbling tools and use [Archbee](https://www.archbee.com/) ‚Äî the first complete documentation platform.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://phoenix.arize.com/wp-content/uploads/2023/04/cropped-Favicon-32x32.png&quot; alt=&quot;Arize-Phoenix Logo&quot; /&gt; **[Arize Phoenix](https://github.com/Arize-ai/phoenix/tree/main/js/packages/phoenix-mcp)** - Inspect traces, manage prompts, curate datasets, and run experiments using [Arize Phoenix](https://github.com/Arize-ai/phoenix), an open-source AI and LLM observability tool.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://731523176-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FaVUBXRZbpAgtjYf5HsvO%2Fuploads%2FaRRrVVocXCTr6GkepfCx%2Flogo_color.svg?alt=media&amp;token=3ba24089-0ab2-421f-a9d9-41f2f94f954a&quot; alt=&quot;Armor Logo&quot; /&gt; **[Armor Crypto MCP](https://github.com/armorwallet/armor-crypto-mcp)** - MCP to interface with multiple blockchains, staking, DeFi, swap, bridging, wallet management, DCA, Limit Orders, Coin Lookup, Tracking and more.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://console.asgardeo.io/app/libs/themes/wso2is/assets/images/branding/favicon.ico&quot; alt=&quot;Asgardeo Logo&quot; /&gt; **[Asgardeo](https://github.com/asgardeo/asgardeo-mcp-server)** - MCP server to interact with your [Asgardeo](https://wso2.com/asgardeo) organization through LLM tools.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://www.datastax.com/favicon-32x32.png&quot; alt=&quot;DataStax logo&quot; /&gt; **[Astra DB](https://github.com/datastax/astra-db-mcp)** - Comprehensive tools for managing collections and documents in a [DataStax Astra DB](https://www.datastax.com/products/datastax-astra) NoSQL database with a full range of operations such as create, update, delete, find, and associated bulk actions.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://cdn.prod.website-files.com/66598898fd13d51606c3215d/66ccbfef13bd8bc19d587578_favicon-32x32.png&quot; alt=&quot;Atla Logo&quot; /&gt; **[Atla](https://github.com/atla-ai/atla-mcp-server)** - Enable AI agents to interact with the [Atla API](https://docs.atla-ai.com/) for state-of-the-art LLMJ evaluation.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://assets.atlan.com/assets/atlan-a-logo-blue-background.png&quot; alt=&quot;Atlan Logo&quot; /&gt; **[Atlan](https://github.com/atlanhq/agent-toolkit/tree/main/modelcontextprotocol)** - The Atlan Model Context Protocol server allows you to interact with the [Atlan](https://www.atlan.com/) services through multiple tools.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://www.atlassian.com/favicon.ico&quot; alt=&quot;Atlassian Logo&quot; /&gt; **[Atlassian](https://www.atlassian.com/platform/remote-mcp-server)** - Securely interact with Jira work items and Confluence pages, and search across both.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://res.oafimg.cn/-/737b3b3ffed9b19e/logo.png&quot; alt=&quot;AtomGit Logo&quot; /&gt; **[AtomGit](https://atomgit.com/atomgit-open-source-ecosystem/atomgit-mcp-server)** - Official AtomGit server for integration with repository management, PRs, issues, branches, labels, and more.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://resources.audiense.com/hubfs/favicon-1.png&quot; alt=&quot;Audiense Logo&quot; /&gt; **[Audiense Insights](https://github.com/AudienseCo/mcp-audiense-insights)** - Marketing insights and audience analysis from [Audiense](https://www.audiense.com/products/audiense-insights) reports, covering demographic, cultural, influencer, and content engagement analysis.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://cdn.auth0.com/website/website/favicons/auth0-favicon.svg&quot; alt=&quot;Auth0 Logo&quot; /&gt; **[Auth0](https://github.com/auth0/auth0-mcp-server)** - MCP server for interacting with your Auth0 tenant, supporting creating and modifying actions, applications, forms, logs, resource servers, and more.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://firstorder.ai/favicon_auth.ico&quot; alt=&quot;Authenticator App Logo&quot; /&gt; **[Authenticator App ¬∑ 2FA](https://github.com/firstorderai/authenticator_mcp)** - A secure MCP (Model Context Protocol) server that enables AI agents to interact with the Authenticator App.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico&quot; alt=&quot;AWS Logo&quot; /&gt; **[AWS](https://github.com/awslabs/mcp)** -  Specialized MCP servers that bring AWS best practices directly to your development workflow.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://axiom.co/favicon.ico&quot; alt=&quot;Axiom Logo&quot; /&gt; **[Axiom](https://github.com/axiomhq/mcp-server-axiom)** - Query and analyze your Axiom logs, traces, and all other event data in natural language
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/acom_social_icon_azure&quot; alt=&quot;Microsoft Azure Logo&quot; /&gt; **[Azure](https://github.com/Azure/azure-mcp)** - The Azure MCP Server gives MCP Clients access to key Azure services and tools like Azure Storage, Cosmos DB, the Azure CLI, and more.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/1062064-Products-1.2-24x24&quot; alt=&quot;Microsoft Azure DevOps Logo&quot; /&gt; **[Azure DevOps](https://github.com/microsoft/azure-devops-mcp)** - Interact with Azure DevOps services like repositories, work items, builds, releases, test plans, and code search.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://mapopen-website-wiki.cdn.bcebos.com/LOGO/lbsyunlogo_icon.ico&quot; alt=&quot;Baidu Map Logo&quot; /&gt; **[Baidu Map](https://github.com/baidu-maps/mcp)** - [Baidu Map MCP Server](https://lbsyun.baidu.com/faq/api?title=mcpserver/base) provides tools for AI agents to interact with Baidu Maps APIs, enabling location-based services and geospatial data analysis.
- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;ht

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>