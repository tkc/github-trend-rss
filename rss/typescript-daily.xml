<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Tue, 24 Feb 2026 00:07:38 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[abhigyanpatwari/GitNexus]]></title>
            <link>https://github.com/abhigyanpatwari/GitNexus</link>
            <guid>https://github.com/abhigyanpatwari/GitNexus</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:38 GMT</pubDate>
            <description><![CDATA[GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/abhigyanpatwari/GitNexus">abhigyanpatwari/GitNexus</a></h1>
            <p>GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,907</p>
            <p>Forks: 135</p>
            <p>Stars today: 467 stars today</p>
            <h2>README</h2><pre># GitNexus

&lt;a href=&quot;https://trendshift.io/repositories/19809&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/19809&quot; alt=&quot;abhigyanpatwari%2FGitNexus | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

**Building git for agent context.**

Indexes any codebase into a knowledge graph â€” every dependency, call chain, cluster, and execution flow â€” then exposes it through smart tools so AI agents never miss code.

[![npm version](https://img.shields.io/npm/v/gitnexus.svg)](https://www.npmjs.com/package/gitnexus)
[![License: PolyForm Noncommercial](https://img.shields.io/badge/License-PolyForm%20Noncommercial-blue.svg)](https://polyformproject.org/licenses/noncommercial/1.0.0/)



https://github.com/user-attachments/assets/172685ba-8e54-4ea7-9ad1-e31a3398da72



&gt; *Like DeepWiki, but deeper.* DeepWiki helps you *understand* code. GitNexus lets you *analyze* it â€” because a knowledge graph tracks every relationship, not just descriptions.

**TL;DR:** The **Web UI** is a quick way to chat with any repo. The **CLI + MCP** is how you make your AI agent actually reliable â€” it gives Cursor, Claude Code, and friends a deep architectural view of your codebase so they stop missing dependencies, breaking call chains, and shipping blind edits. Even smaller models get full architectural clarity, making it compete with goliath models.

---

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=abhigyanpatwari/GitNexus&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#abhigyanpatwari/GitNexus&amp;type=date&amp;legend=top-left)


## Two Ways to Use GitNexus

|                   | **CLI + MCP**                                            | **Web UI**                                             |
| ----------------- | -------------------------------------------------------------- | ------------------------------------------------------------ |
| **What**    | Index repos locally, connect AI agents via MCP                 | Visual graph explorer + AI chat in browser                   |
| **For**     | Daily development with Cursor, Claude Code, Windsurf, OpenCode | Quick exploration, demos, one-off analysis                   |
| **Scale**   | Full repos, any size                                           | Limited by browser memory (~5k files), or unlimited via backend mode |
| **Install** | `npm install -g gitnexus`                                    | No install â€”[gitnexus.vercel.app](https://gitnexus.vercel.app) |
| **Storage** | KuzuDB native (fast, persistent)                               | KuzuDB WASM (in-memory, per session)                         |
| **Parsing** | Tree-sitter native bindings                                    | Tree-sitter WASM                                             |
| **Privacy** | Everything local, no network                                   | Everything in-browser, no server                             |

&gt; **Bridge mode:** `gitnexus serve` connects the two â€” the web UI auto-detects the local server and can browse all your CLI-indexed repos without re-uploading or re-indexing.

---

## CLI + MCP (recommended)

The CLI indexes your repository and runs an MCP server that gives AI agents deep codebase awareness.

### Quick Start

```bash
# Index your repo (run from repo root)
npx gitnexus analyze
```

That&#039;s it. This indexes the codebase, installs agent skills, registers Claude Code hooks, and creates `AGENTS.md` / `CLAUDE.md` context files â€” all in one command.

To configure MCP for your editor, run `npx gitnexus setup` once â€” or set it up manually below.

### MCP Setup

`gitnexus setup` auto-detects your editors and writes the correct global MCP config. You only need to run it once.

### Editor Support

| Editor                | MCP | Skills | Hooks (auto-augment) | Support        |
| --------------------- | --- | ------ | -------------------- | -------------- |
| **Claude Code** | Yes | Yes    | Yes (PreToolUse)     | **Full** |
| **Cursor**      | Yes | Yes    | â€”                   | MCP + Skills   |
| **Windsurf**    | Yes | â€”     | â€”                   | MCP            |
| **OpenCode**    | Yes | Yes    | â€”                   | MCP + Skills   |

&gt; **Claude Code** gets the deepest integration: MCP tools + agent skills + PreToolUse hooks that automatically enrich grep/glob/bash calls with knowledge graph context.

If you prefer manual configuration:

**Claude Code** (full support â€” MCP + skills + hooks):

```bash
claude mcp add gitnexus -- npx -y gitnexus@latest mcp
```

**Cursor** (`~/.cursor/mcp.json` â€” global, works for all projects):

```json
{
  &quot;mcpServers&quot;: {
    &quot;gitnexus&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;gitnexus@latest&quot;, &quot;mcp&quot;]
    }
  }
}
```

**OpenCode** (`~/.config/opencode/config.json`):

```json
{
  &quot;mcp&quot;: {
    &quot;gitnexus&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;gitnexus@latest&quot;, &quot;mcp&quot;]
    }
  }
}
```

### CLI Commands

```bash
gitnexus setup                    # Configure MCP for your editors (one-time)
gitnexus analyze [path]           # Index a repository (or update stale index)
gitnexus analyze --force          # Force full re-index
gitnexus analyze --skip-embeddings  # Skip embedding generation (faster)
gitnexus mcp                     # Start MCP server (stdio) â€” serves all indexed repos
gitnexus serve                   # Start local HTTP server (multi-repo) for web UI connection
gitnexus list                    # List all indexed repositories
gitnexus status                  # Show index status for current repo
gitnexus clean                   # Delete index for current repo
gitnexus clean --all --force     # Delete all indexes
gitnexus wiki [path]             # Generate repository wiki from knowledge graph
gitnexus wiki --model &lt;model&gt;    # Wiki with custom LLM model (default: gpt-4o-mini)
gitnexus wiki --base-url &lt;url&gt;   # Wiki with custom LLM API base URL
```

### What Your AI Agent Gets

**7 tools** exposed via MCP:

| Tool               | What It Does                                                      | `repo` Param |
| ------------------ | ----------------------------------------------------------------- | -------------- |
| `list_repos`     | Discover all indexed repositories                                 | â€”             |
| `query`          | Process-grouped hybrid search (BM25 + semantic + RRF)             | Optional       |
| `context`        | 360-degree symbol view â€” categorized refs, process participation | Optional       |
| `impact`         | Blast radius analysis with depth grouping and confidence          | Optional       |
| `detect_changes` | Git-diff impact â€” maps changed lines to affected processes       | Optional       |
| `rename`         | Multi-file coordinated rename with graph + text search            | Optional       |
| `cypher`         | Raw Cypher graph queries                                          | Optional       |

&gt; When only one repo is indexed, the `repo` parameter is optional. With multiple repos, specify which one: `query({query: &quot;auth&quot;, repo: &quot;my-app&quot;})`.

**Resources** for instant context:

| Resource                                  | Purpose                                              |
| ----------------------------------------- | ---------------------------------------------------- |
| `gitnexus://repos`                      | List all indexed repositories (read this first)      |
| `gitnexus://repo/{name}/context`        | Codebase stats, staleness check, and available tools |
| `gitnexus://repo/{name}/clusters`       | All functional clusters with cohesion scores         |
| `gitnexus://repo/{name}/cluster/{name}` | Cluster members and details                          |
| `gitnexus://repo/{name}/processes`      | All execution flows                                  |
| `gitnexus://repo/{name}/process/{name}` | Full process trace with steps                        |
| `gitnexus://repo/{name}/schema`         | Graph schema for Cypher queries                      |

**2 MCP prompts** for guided workflows:

| Prompt            | What It Does                                                              |
| ----------------- | ------------------------------------------------------------------------- |
| `detect_impact` | Pre-commit change analysis â€” scope, affected processes, risk level       |
| `generate_map`  | Architecture documentation from the knowledge graph with mermaid diagrams |

**4 agent skills** installed to `.claude/skills/` automatically:

- **Exploring** â€” Navigate unfamiliar code using the knowledge graph
- **Debugging** â€” Trace bugs through call chains
- **Impact Analysis** â€” Analyze blast radius before changes
- **Refactoring** â€” Plan safe refactors using dependency mapping

---

## Multi-Repo MCP Architecture

GitNexus uses a **global registry** so one MCP server can serve multiple indexed repos. No per-project MCP config needed â€” set it up once and it works everywhere.

```mermaid
flowchart TD
    subgraph CLI [CLI Commands]
        Setup[&quot;gitnexus setup&quot;]
        Analyze[&quot;gitnexus analyze&quot;]
        Clean[&quot;gitnexus clean&quot;]
        List[&quot;gitnexus list&quot;]
    end

    subgraph Registry [&quot;~/.gitnexus/&quot;]
        RegFile[&quot;registry.json&quot;]
    end

    subgraph Repos [Project Repos]
        RepoA[&quot;.gitnexus/ in repo A&quot;]
        RepoB[&quot;.gitnexus/ in repo B&quot;]
    end

    subgraph MCP [MCP Server]
        Server[&quot;server.ts&quot;]
        Backend[&quot;LocalBackend&quot;]
        Pool[&quot;Connection Pool&quot;]
        ConnA[&quot;KuzuDB conn A&quot;]
        ConnB[&quot;KuzuDB conn B&quot;]
    end

    Setup --&gt;|&quot;writes global MCP config&quot;| CursorConfig[&quot;~/.cursor/mcp.json&quot;]
    Analyze --&gt;|&quot;registers repo&quot;| RegFile
    Analyze --&gt;|&quot;stores index&quot;| RepoA
    Clean --&gt;|&quot;unregisters repo&quot;| RegFile
    List --&gt;|&quot;reads&quot;| RegFile
    Server --&gt;|&quot;reads registry&quot;| RegFile
    Server --&gt; Backend
    Backend --&gt; Pool
    Pool --&gt;|&quot;lazy open&quot;| ConnA
    Pool --&gt;|&quot;lazy open&quot;| ConnB
    ConnA --&gt;|&quot;queries&quot;| RepoA
    ConnB --&gt;|&quot;queries&quot;| RepoB
```

**How it works:** Each `gitnexus analyze` stores the index in `.gitnexus/` inside the repo (portable, gitignored) and registers a pointer in `~/.gitnexus/registry.json`. When an AI agent starts, the MCP server reads the registry and can serve any indexed repo. KuzuDB connections are opened lazily on first query and evicted after 5 minutes of inactivity (max 5 concurrent). If only one repo is indexed, the `repo` parameter is optional on all tools â€” agents don&#039;t need to change anything.

---

## Web UI (browser-based)

A fully client-side graph explorer and AI chat. No server, no install â€” your code never leaves the browser.

**Try it now:** [gitnexus.vercel.app](https://gitnexus.vercel.app) â€” drag &amp; drop a ZIP and start exploring.

&lt;img width=&quot;2550&quot; height=&quot;1343&quot; alt=&quot;gitnexus_img&quot; src=&quot;https://github.com/user-attachments/assets/cc5d637d-e0e5-48e6-93ff-5bcfdb929285&quot; /&gt;

Or run locally:

```bash
git clone https://github.com/abhigyanpatwari/gitnexus.git
cd gitnexus/gitnexus-web
npm install
npm run dev
```

The web UI uses the same indexing pipeline as the CLI but runs entirely in WebAssembly (Tree-sitter WASM, KuzuDB WASM, in-browser embeddings). It&#039;s great for quick exploration but limited by browser memory for larger repos.

**Local Backend Mode:** Run `gitnexus serve` and open the web UI locally â€” it auto-detects the server and shows all your indexed repos, with full AI chat support. No need to re-upload or re-index. The agent&#039;s tools (Cypher queries, search, code navigation) route through the backend HTTP API automatically.

---

## The Problem GitNexus Solves

Tools like **Cursor**, **Claude Code**, **Cline**, **Roo Code**, and **Windsurf** are powerful â€” but they don&#039;t truly know your codebase structure.

**What happens:**

1. AI edits `UserService.validate()`
2. Doesn&#039;t know 47 functions depend on its return type
3. **Breaking changes ship**

### Traditional Graph RAG vs GitNexus

Traditional approaches give the LLM raw graph edges and hope it explores enough. GitNexus **precomputes structure at index time** â€” clustering, tracing, scoring â€” so tools return complete context in one call:

```mermaid
flowchart TB
    subgraph Traditional[&quot;Traditional Graph RAG&quot;]
        direction TB
        U1[&quot;User: What depends on UserService?&quot;]
        U1 --&gt; LLM1[&quot;LLM receives raw graph&quot;]
        LLM1 --&gt; Q1[&quot;Query 1: Find callers&quot;]
        Q1 --&gt; Q2[&quot;Query 2: What files?&quot;]
        Q2 --&gt; Q3[&quot;Query 3: Filter tests?&quot;]
        Q3 --&gt; Q4[&quot;Query 4: High-risk?&quot;]
        Q4 --&gt; OUT1[&quot;Answer after 4+ queries&quot;]
    end

    subgraph GN[&quot;GitNexus Smart Tools&quot;]
        direction TB
        U2[&quot;User: What depends on UserService?&quot;]
        U2 --&gt; TOOL[&quot;impact UserService upstream&quot;]
        TOOL --&gt; PRECOMP[&quot;Pre-structured response:
        8 callers, 3 clusters, all 90%+ confidence&quot;]
        PRECOMP --&gt; OUT2[&quot;Complete answer, 1 query&quot;]
    end
```

**Core innovation: Precomputed Relational Intelligence**

- **Reliability** â€” LLM can&#039;t miss context, it&#039;s already in the tool response
- **Token efficiency** â€” No 10-query chains to understand one function
- **Model democratization** â€” Smaller LLMs work because tools do the heavy lifting

---

## How It Works

GitNexus builds a complete knowledge graph of your codebase through a multi-phase indexing pipeline:

1. **Structure** â€” Walks the file tree and maps folder/file relationships
2. **Parsing** â€” Extracts functions, classes, methods, and interfaces using Tree-sitter ASTs
3. **Resolution** â€” Resolves imports and function calls across files with language-aware logic
4. **Clustering** â€” Groups related symbols into functional communities
5. **Processes** â€” Traces execution flows from entry points through call chains
6. **Search** â€” Builds hybrid search indexes for fast retrieval

### Supported Languages

TypeScript, JavaScript, Python, Java, C, C++, C#, Go, Rust

---

## Tool Examples

### Impact Analysis

```
impact({target: &quot;UserService&quot;, direction: &quot;upstream&quot;, minConfidence: 0.8})

TARGET: Class UserService (src/services/user.ts)

UPSTREAM (what depends on this):
  Depth 1 (WILL BREAK):
    handleLogin [CALLS 90%] -&gt; src/api/auth.ts:45
    handleRegister [CALLS 90%] -&gt; src/api/auth.ts:78
    UserController [CALLS 85%] -&gt; src/controllers/user.ts:12
  Depth 2 (LIKELY AFFECTED):
    authRouter [IMPORTS] -&gt; src/routes/auth.ts
```

Options: `maxDepth`, `minConfidence`, `relationTypes` (`CALLS`, `IMPORTS`, `EXTENDS`, `IMPLEMENTS`), `includeTests`

### Process-Grouped Search

```
query({query: &quot;authentication middleware&quot;})

processes:
  - summary: &quot;LoginFlow&quot;
    priority: 0.042
    symbol_count: 4
    process_type: cross_community
    step_count: 7

process_symbols:
  - name: validateUser
    type: Function
    filePath: src/auth/validate.ts
    process_id: proc_login
    step_index: 2

definitions:
  - name: AuthConfig
    type: Interface
    filePath: src/types/auth.ts
```

### Context (360-degree Symbol View)

```
context({name: &quot;validateUser&quot;})

symbol:
  uid: &quot;Function:validateUser&quot;
  kind: Function
  filePath: src/auth/validate.ts
  startLine: 15

incoming:
  calls: [handleLogin, handleRegister, UserController]
  imports: [authRouter]

outgoing:
  calls: [checkPassword, createSession]

processes:
  - name: LoginFlow (step 2/7)
  - name: RegistrationFlow (step 3/5)
```

### Detect Changes (Pre-Commit)

```
detect_changes({scope: &quot;all&quot;})

summary:
  changed_count: 12
  affected_count: 3
  changed_files: 4
  risk_level: medium

changed_symbols: [validateUser, AuthService, ...]
affected_processes: [LoginFlow, RegistrationFlow, ...]
```

### Rename (Multi-File)

```
rename({symbol_name: &quot;validateUser&quot;, new_name: &quot;verifyUser&quot;, dry_run: true})

status: success
files_affected: 5
total_edits: 8
graph_edits: 6     (high confidence)
text_search_edits: 2  (review carefully)
changes: [...]
```

### Cypher Queries

```cypher
-- Find what calls auth functions with high confidence
MATCH (c:Community {heuristicLabel: &#039;Authentication&#039;})&lt;-[:CodeRelation {type: &#039;MEMBER_OF&#039;}]-(fn)
MATCH (caller)-[r:CodeRelation {type: &#039;CALLS&#039;}]-&gt;(fn)
WHERE r.confidence &gt; 0.8
RETURN caller.name, fn.name, r.confidence
ORDER BY r.confidence DESC
```

---

## Wiki Generation

Generate LLM-powered documentation from your knowledge graph:

```bash
# Requires an LLM API key (OPENAI_API_KEY, etc.)
gitnexus wiki

# Use a custom model or provider
gitnexus wiki --model gpt-4o
gitnexus wiki --base-url https://api.anthropic.com/v1

# Force full regeneration
gitnexus wiki --force
```

The wiki generator reads the indexed graph structure, groups files into modules via LLM, generates per-module documentation pages, and creates an overview page â€” all with cross-references to the knowledge graph.

---

## Tech Stack

| Layer                     | CLI                                   | Web                                     |
| ------------------------- | ------------------------------------- | --------------------------------------- |
| **Runtime**         | Node.js (native)                      | Browser (WASM)                          |
| **Parsing**         | Tree-sitter native bindings           | Tree-sitter WASM                        |
| **Database**        | KuzuDB native                         | KuzuDB WASM                             |
| **Embeddings**      | HuggingFace transformers.js (GPU/CPU) | transformers.js (WebGPU/WASM)           |
| **Search**          | BM25 + semantic + RRF                 | BM25 + semantic + RRF                   |
| **Agent Interface** | MCP (stdio)                           | LangChain ReAct agent                   |
| **Visualization**   | â€”                                    | Sigma.js + Graphology (WebGL)           |
| **Frontend**        | â€”                                    | React 18, TypeScript, Vite, Tailwind v4 |
| **Clustering**      | Graphology                            | Graphology                              |
| **Concurrency**     | Worker threads + async                | Web Workers + Comlink                   |

---

## Roadmap

### Actively Building

- [ ] **LLM Cluster Enrichment** â€” Semantic cluster names via LLM API
- [ ] **AST Decorator Detection** â€” Parse @Controller, @Get, etc.
- [ ] **Incremental Indexing** â€” Only re-index changed files

### Recently Completed

- [X] Wiki Generation, Multi-File Rename, Git-Diff Impact Analysis
- [X] Process-Grouped Search, 360-Degree Context, Claude Code Hooks
- [X] Multi-Repo MCP, Zero-Config Setup, 9 Language Support
- [X] Community Detection, Process Detection, Confidence Scoring
- [X] Hybrid Search, Vector Index

---

## Security &amp; Privacy

- **CLI**: Everything runs locally on your machine. No network calls. Index stored in `.gitnexus/` (gitignored). Global registry at `~/.gitnexus/` stores only paths and metadata.
- **Web**: Everything runs in your browser. No code uploaded to any server. API keys stored in localStorage only.
- Open source â€” audit the code yourself.

---

## Acknowledgments

- [Tree-sitter](https://tree-sitter.github.io/) â€” AST parsing
- [KuzuDB](https://kuzudb.com/) â€” Embedded graph database with vector support
- [Sigma.js](https://www.sigmajs.org/) â€” WebGL graph rendering
- [transformers.js](https://huggingface.co/docs/transformers.js) â€” Browser ML
- [Graphology](https://graphology.github.io/) â€” Graph data structures
- [MCP](https://modelcontextprotocol.io/) â€” Model Context Protocol
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[stan-smith/FossFLOW]]></title>
            <link>https://github.com/stan-smith/FossFLOW</link>
            <guid>https://github.com/stan-smith/FossFLOW</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:37 GMT</pubDate>
            <description><![CDATA[Make beautiful isometric infrastructure diagrams]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stan-smith/FossFLOW">stan-smith/FossFLOW</a></h1>
            <p>Make beautiful isometric infrastructure diagrams</p>
            <p>Language: TypeScript</p>
            <p>Stars: 18,545</p>
            <p>Forks: 1,198</p>
            <p>Stars today: 430 stars today</p>
            <h2>README</h2><pre># FossFLOW - Isometric Diagramming Tool &lt;img width=&quot;30&quot; height=&quot;30&quot; alt=&quot;fossflow&quot; src=&quot;https://github.com/user-attachments/assets/56d78887-601c-4336-ab87-76f8ee4cde96&quot; /&gt;

&lt;p align=&quot;center&quot;&gt;
 &lt;a href=&quot;README.md&quot;&gt;English&lt;/a&gt; | &lt;a href=&quot;docs/README.cn.md&quot;&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; | &lt;a href=&quot;docs/README.es.md&quot;&gt;EspaÃ±ol&lt;/a&gt; | &lt;a href=&quot;docs/README.pt.md&quot;&gt;PortuguÃªs&lt;/a&gt; | &lt;a href=&quot;docs/README.fr.md&quot;&gt;FranÃ§ais&lt;/a&gt; | &lt;a href=&quot;docs/README.hi.md&quot;&gt;à¤¹à¤¿à¤¨à¥à¤¦à¥€&lt;/a&gt; | &lt;a href=&quot;docs/README.bn.md&quot;&gt;à¦¬à¦¾à¦‚à¦²à¦¾&lt;/a&gt; | &lt;a href=&quot;docs/README.ru.md&quot;&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; | &lt;a href=&quot;docs/README.id.md&quot;&gt;Bahasa Indonesia&lt;/a&gt; | &lt;a href=&quot;docs/README.de.md&quot;&gt;Deutsch&lt;/a&gt;
&lt;/p&gt;


&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/15118&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15118&quot; alt=&quot;stan-smith%2FFossFLOW | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;b&gt;Hey!&lt;/b&gt; Stan here, if you&#039;ve used FossFLOW and it&#039;s helped you, &lt;b&gt;I&#039;d really appreciate if you could donate something small :)&lt;/b&gt; I work full time, and finding the time to work on this project is challenging enough.
If you&#039;ve had a feature that I&#039;ve implemented for you, or fixed a bug it&#039;d be great if you could :) if not, that&#039;s not a problem, this software will always remain free!


&lt;b&gt;Also!&lt;/b&gt; If you haven&#039;t yet, please check out the underlying library this is built on by &lt;a href=&quot;https://github.com/markmanx/isoflow&quot;&gt;@markmanx&lt;/a&gt; I truly stand on the shoulders of a giant here ğŸ«¡

[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/P5P61KBXA3)

&lt;a href=&quot;https://www.buymeacoffee.com/stan.smith&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://cdn.buymeacoffee.com/buttons/default-orange.png&quot; alt=&quot;Buy Me A Coffee&quot; height=&quot;41&quot; width=&quot;174&quot;&gt;&lt;/a&gt;

Thanks,

-Stan

## Try it online
&lt;p align=&quot;center&quot;&gt;
Go to  &lt;b&gt; --&gt; https://stan-smith.github.io/FossFLOW/ &lt;-- &lt;/b&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;

 &lt;a href=&quot;https://github.com/stan-smith/SlingShot&quot;&gt;
  Check out my latest project: &lt;b&gt;SlingShot&lt;/b&gt; - Dead easy video streaming over QUIC
 &lt;/a&gt;
&lt;/p&gt;

------------------------------------------------------------------------------------------------------------------------------
FossFLOW is a powerful, open-source Progressive Web App (PWA) for creating beautiful isometric diagrams. Built with React and the &lt;a href=&quot;https://github.com/markmanx/isoflow&quot;&gt;Isoflow&lt;/a&gt; (Now forked and published to NPM as fossflow) library, it runs entirely in your browser with offline support.

![Screenshot_20250630_160954](https://github.com/user-attachments/assets/e7f254ad-625f-4b8a-8efc-5293b5be9d55)

- **ğŸ¤ [CONTRIBUTING.md](https://github.com/stan-smith/FossFLOW/blob/master/CONTRIBUTING.md)** - How to contribute to the project.

## ğŸ³ Quick Deploy with Docker

```bash
# Using Docker Compose (recommended - includes persistent storage)
docker compose up

# Or run directly from Docker Hub with persistent storage
docker run -p 80:80 -v $(pwd)/diagrams:/data/diagrams stnsmith/fossflow:latest
```

Server storage is enabled by default in Docker. Your diagrams will be saved to `./diagrams` on the host.

To disable server storage, set `ENABLE_SERVER_STORAGE=false`:
```bash
docker run -p 80:80 -e ENABLE_SERVER_STORAGE=false stnsmith/fossflow:latest
```

## Quick Start (Local Development)

```bash
# Clone the repository
git clone https://github.com/stan-smith/FossFLOW
cd FossFLOW

# Install dependencies
npm install

# Build the library (required first time)
npm run build:lib

# Start development server
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

## Monorepo Structure

This is a monorepo containing two packages:

- `packages/fossflow-lib` - React component library for drawing network diagrams (built with Webpack)
- `packages/fossflow-app` - Progressive Web App which wraps the lib and presents it (built with RSBuild)

### Development Commands

```bash
# Development
npm run dev          # Start app development server
npm run dev:lib      # Watch mode for library development

# Building
npm run build        # Build both library and app
npm run build:lib    # Build library only
npm run build:app    # Build app only

# Testing &amp; Linting
npm test             # Run unit tests
npm run lint         # Check for linting errors

# E2E Tests (Selenium)
cd e2e-tests
./run-tests.sh       # Run end-to-end tests (requires Docker &amp; Python)

# Publishing
npm run publish:lib  # Publish library to npm
```

## How to Use

### Creating Diagrams

1. **Add Items**:
   - Press the &quot;+&quot; button on the top right menu, the library of components will appear on the left
   - Drag and drop components from the library onto the canvas
   - Or right-click on the grid and select &quot;Add node&quot;

2. **Connect Items**: 
   - Select the Connector tool (press &#039;C&#039; or click connector icon)
   - **Click mode** (default): Click first node, then click second node
   - **Drag mode** (optional): Click and drag from first to second node
   - Switch modes in Settings â†’ Connectors tab

3. **Save Your Work**:
   - **Quick Save** - Saves to browser session
   - **Export** - Download as JSON file
   - **Import** - Load from JSON file

### Storage Options

- **Session Storage**: Temporary saves cleared when browser closes
- **Export/Import**: Permanent storage as JSON files
- **Auto-Save**: Automatically saves changes every 5 seconds to session

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## Documentation

- [FOSSFLOW_ENCYCLOPEDIA.md](FOSSFLOW_ENCYCLOPEDIA.md) - Comprehensive guide to the codebase
- [CONTRIBUTING.md](CONTRIBUTING.md) - Contributing guidelines

## License

MIT
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[cloudflare/agents]]></title>
            <link>https://github.com/cloudflare/agents</link>
            <guid>https://github.com/cloudflare/agents</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:36 GMT</pubDate>
            <description><![CDATA[Build and deploy AI Agents on Cloudflare]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudflare/agents">cloudflare/agents</a></h1>
            <p>Build and deploy AI Agents on Cloudflare</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,998</p>
            <p>Forks: 416</p>
            <p>Stars today: 318 stars today</p>
            <h2>README</h2><pre># Cloudflare Agents

[![npm version](https://img.shields.io/npm/v/agents)](https://www.npmjs.com/package/agents)
[![npm downloads](https://img.shields.io/npm/dw/agents)](https://www.npmjs.com/package/agents)

![npm install agents](assets/npm-install-agents.svg)

Agents are persistent, stateful execution environments for agentic workloads, powered by Cloudflare [Durable Objects](https://developers.cloudflare.com/durable-objects/). Each agent has its own state, storage, and lifecycle â€” with built-in support for real-time communication, scheduling, AI model calls, MCP, workflows, and more.

Agents hibernate when idle and wake on demand. You can run millions of them â€” one per user, per session, per game room â€” each costs nothing when inactive.

```sh
npm create cloudflare@latest -- --template cloudflare/agents-starter
```

Or add to an existing project:

```sh
npm install agents
```

**[Read the docs](https://developers.cloudflare.com/agents/)** â€” getting started, API reference, guides, and more.

## Quick Example

A counter agent with persistent state, callable methods, and real-time sync to a React frontend:

```typescript
// server.ts
import { Agent, routeAgentRequest, callable } from &quot;agents&quot;;

export type CounterState = { count: number };

export class CounterAgent extends Agent&lt;Env, CounterState&gt; {
  initialState = { count: 0 };

  @callable()
  increment() {
    this.setState({ count: this.state.count + 1 });
    return this.state.count;
  }

  @callable()
  decrement() {
    this.setState({ count: this.state.count - 1 });
    return this.state.count;
  }
}

export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext) {
    return (
      (await routeAgentRequest(request, env)) ??
      new Response(&quot;Not found&quot;, { status: 404 })
    );
  }
};
```

```tsx
// client.tsx
import { useAgent } from &quot;agents/react&quot;;
import { useState } from &quot;react&quot;;
import type { CounterAgent, CounterState } from &quot;./server&quot;;

function Counter() {
  const [count, setCount] = useState(0);

  const agent = useAgent&lt;CounterAgent, CounterState&gt;({
    agent: &quot;CounterAgent&quot;,
    onStateUpdate: (state) =&gt; setCount(state.count)
  });

  return (
    &lt;div&gt;
      &lt;span&gt;{count}&lt;/span&gt;
      &lt;button onClick={() =&gt; agent.stub.increment()}&gt;+&lt;/button&gt;
      &lt;button onClick={() =&gt; agent.stub.decrement()}&gt;-&lt;/button&gt;
    &lt;/div&gt;
  );
}
```

State changes sync to all connected clients automatically. Call methods like they&#039;re local functions.

## Features

| Feature               | Description                                                            |
| --------------------- | ---------------------------------------------------------------------- |
| **Persistent State**  | Syncs to all connected clients, survives restarts                      |
| **Callable Methods**  | Type-safe RPC via the `@callable()` decorator                          |
| **Scheduling**        | One-time, recurring, and cron-based tasks                              |
| **WebSockets**        | Real-time bidirectional communication with lifecycle hooks             |
| **AI Chat**           | Message persistence, resumable streaming, server/client tool execution |
| **MCP**               | Act as MCP servers or connect as MCP clients                           |
| **Workflows**         | Durable multi-step tasks with human-in-the-loop approval               |
| **Email**             | Receive and respond via Cloudflare Email Routing                       |
| **Code Mode**         | LLMs generate executable TypeScript instead of individual tool calls   |
| **SQL**               | Direct SQLite queries via Durable Objects                              |
| **React Hooks**       | `useAgent` and `useAgentChat` for frontend integration                 |
| **Vanilla JS Client** | `AgentClient` for non-React environments                               |

**Coming soon:** Realtime voice agents, web browsing (headless browser), sandboxed code execution, and multi-channel communication (SMS, messengers).

## Packages

| Package                                     | Description                                                                     |
| ------------------------------------------- | ------------------------------------------------------------------------------- |
| [`agents`](packages/agents)                 | Core SDK â€” Agent class, routing, state, scheduling, MCP, email, workflows       |
| [`@cloudflare/ai-chat`](packages/ai-chat)   | Higher-level AI chat â€” persistent messages, resumable streaming, tool execution |
| [`hono-agents`](packages/hono-agents)       | Hono middleware for adding agents to Hono apps                                  |
| [`@cloudflare/codemode`](packages/codemode) | Experimental â€” LLMs write executable code to orchestrate tools                  |

## Examples

The [`examples/`](examples) directory has self-contained demos covering most SDK features â€” MCP servers/clients, workflows, email agents, webhooks, tic-tac-toe, resumable streaming, and more. The [`playground`](examples/playground) is the kitchen-sink showcase with everything in one UI.

There are also examples using the [OpenAI Agents SDK](https://openai.github.io/openai-agents-js/) in [`openai-sdk/`](openai-sdk).

Run any example locally:

```sh
cd examples/playground
npm run dev
```

## Documentation

- [Full docs](https://developers.cloudflare.com/agents/) on developers.cloudflare.com
- [`docs/`](docs) directory in this repo (synced upstream)
- [Anthropic Patterns guide](guides/anthropic-patterns) â€” sequential, routing, parallel, orchestrator, evaluator
- [Human-in-the-Loop guide](guides/human-in-the-loop) â€” approval workflows with pause/resume

## Repository Structure

| Directory                                       | Description                                              |
| ----------------------------------------------- | -------------------------------------------------------- |
| [`packages/agents/`](packages/agents)           | Core SDK                                                 |
| [`packages/ai-chat/`](packages/ai-chat)         | AI chat layer                                            |
| [`packages/hono-agents/`](packages/hono-agents) | Hono integration                                         |
| [`packages/codemode/`](packages/codemode)       | Code Mode (experimental)                                 |
| [`examples/`](examples)                         | Self-contained demo apps                                 |
| [`openai-sdk/`](openai-sdk)                     | Examples using the OpenAI Agents SDK                     |
| [`guides/`](guides)                             | In-depth pattern tutorials                               |
| [`docs/`](docs)                                 | Markdown docs synced to developers.cloudflare.com        |
| [`site/`](site)                                 | Deployed websites (agents.cloudflare.com, AI playground) |
| [`design/`](design)                             | Architecture and design decision records                 |
| [`scripts/`](scripts)                           | Repo-wide tooling                                        |

## Development

Node 24+ required. Uses npm workspaces.

```sh
npm install          # install all workspaces
npm run build        # build all packages
npm run check        # full CI check (format, lint, typecheck, exports)
CI=true npm test     # run tests (vitest + vitest-pool-workers)
```

Changes to `packages/` need a changeset:

```sh
npx changeset
```

See [`AGENTS.md`](AGENTS.md) for deeper contributor guidance.

## Contributing

We are not accepting external pull requests at this time â€” the SDK is evolving quickly and we want to keep the surface area manageable. That said, we&#039;d love to hear from you:

- **Bug reports &amp; feature requests** â€” [open an issue](https://github.com/cloudflare/agents/issues)
- **Questions &amp; ideas** â€” [start a discussion](https://github.com/cloudflare/agents/discussions)

## License

[MIT](LICENSE)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[clash-verge-rev/clash-verge-rev]]></title>
            <link>https://github.com/clash-verge-rev/clash-verge-rev</link>
            <guid>https://github.com/clash-verge-rev/clash-verge-rev</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:35 GMT</pubDate>
            <description><![CDATA[A modern GUI client based on Tauri, designed to run in Windows, macOS and Linux for tailored proxy experience]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/clash-verge-rev/clash-verge-rev">clash-verge-rev/clash-verge-rev</a></h1>
            <p>A modern GUI client based on Tauri, designed to run in Windows, macOS and Linux for tailored proxy experience</p>
            <p>Language: TypeScript</p>
            <p>Stars: 98,215</p>
            <p>Forks: 7,169</p>
            <p>Stars today: 142 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img src=&quot;./src-tauri/icons/icon.png&quot; alt=&quot;Clash&quot; width=&quot;128&quot; /&gt;
  &lt;br&gt;
  Continuation of &lt;a href=&quot;https://github.com/zzzgydi/clash-verge&quot;&gt;Clash Verge&lt;/a&gt;
  &lt;br&gt;
&lt;/h1&gt;

&lt;h3 align=&quot;center&quot;&gt;
A Clash Meta GUI based on &lt;a href=&quot;https://github.com/tauri-apps/tauri&quot;&gt;Tauri&lt;/a&gt;.
&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
  Languages:
  &lt;a href=&quot;./README.md&quot;&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; Â·
  &lt;a href=&quot;./docs/README_en.md&quot;&gt;English&lt;/a&gt; Â·
  &lt;a href=&quot;./docs/README_es.md&quot;&gt;EspaÃ±ol&lt;/a&gt; Â·
  &lt;a href=&quot;./docs/README_ru.md&quot;&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; Â·
  &lt;a href=&quot;./docs/README_ja.md&quot;&gt;æ—¥æœ¬èª&lt;/a&gt; Â·
  &lt;a href=&quot;./docs/README_ko.md&quot;&gt;í•œêµ­ì–´&lt;/a&gt; Â·
  &lt;a href=&quot;./docs/README_fa.md&quot;&gt;ÙØ§Ø±Ø³ÛŒ&lt;/a&gt;
&lt;/p&gt;

## Preview

| Dark                             | Light                             |
| -------------------------------- | --------------------------------- |
| ![é¢„è§ˆ](./docs/preview_dark.png) | ![é¢„è§ˆ](./docs/preview_light.png) |

## Install

è¯·åˆ°å‘å¸ƒé¡µé¢ä¸‹è½½å¯¹åº”çš„å®‰è£…åŒ…ï¼š[Release page](https://github.com/clash-verge-rev/clash-verge-rev/releases)&lt;br&gt;
Go to the [Release page](https://github.com/clash-verge-rev/clash-verge-rev/releases) to download the corresponding installation package&lt;br&gt;
Supports Windows (x64/x86), Linux (x64/arm64) and macOS 10.15+ (intel/apple).

#### æˆ‘åº”å½“æ€æ ·é€‰æ‹©å‘è¡Œç‰ˆ

| ç‰ˆæœ¬        | ç‰¹å¾                                     | é“¾æ¥                                                                                   |
| :---------- | :--------------------------------------- | :------------------------------------------------------------------------------------- |
| Stable      | æ­£å¼ç‰ˆï¼Œé«˜å¯é æ€§ï¼Œé€‚åˆæ—¥å¸¸ä½¿ç”¨ã€‚         | [Release](https://github.com/clash-verge-rev/clash-verge-rev/releases)                 |
| Alpha(åºŸå¼ƒ) | æµ‹è¯•å‘å¸ƒæµç¨‹ã€‚                           | [Alpha](https://github.com/clash-verge-rev/clash-verge-rev/releases/tag/alpha)         |
| AutoBuild   | æ»šåŠ¨æ›´æ–°ç‰ˆï¼Œé€‚åˆæµ‹è¯•åé¦ˆï¼Œå¯èƒ½å­˜åœ¨ç¼ºé™·ã€‚ | [AutoBuild](https://github.com/clash-verge-rev/clash-verge-rev/releases/tag/autobuild) |

#### å®‰è£…è¯´æ˜å’Œå¸¸è§é—®é¢˜ï¼Œè¯·åˆ° [æ–‡æ¡£é¡µ](https://clash-verge-rev.github.io/) æŸ¥çœ‹

---

### TG é¢‘é“: [@clash_verge_rev](https://t.me/clash_verge_re)

## Promotion

### âœˆï¸ [ç‹—ç‹—åŠ é€Ÿ â€”â€” æŠ€æœ¯æµæœºåœº Doggygo VPN](https://verge.dginv.click/#/register?code=oaxsAGo6)

ğŸš€ é«˜æ€§èƒ½æµ·å¤–æŠ€æœ¯æµæœºåœºï¼Œæ”¯æŒå…è´¹è¯•ç”¨ä¸ä¼˜æƒ å¥—é¤ï¼Œå…¨é¢è§£é”æµåª’ä½“åŠ AI æœåŠ¡ï¼Œå…¨çƒé¦–å®¶é‡‡ç”¨ **QUIC åè®®**ã€‚

ğŸ ä½¿ç”¨ **Clash Verge ä¸“å±é‚€è¯·é“¾æ¥** æ³¨å†Œå³é€ **3 å¤©å…è´¹è¯•ç”¨**ï¼Œæ¯æ—¥ **1GB æµé‡**ï¼šğŸ‘‰ [ç‚¹æ­¤æ³¨å†Œ](https://verge.dginv.click/#/register?code=oaxsAGo6)

#### **æ ¸å¿ƒä¼˜åŠ¿ï¼š**

- ğŸ“± è‡ªç ” iOS å®¢æˆ·ç«¯ï¼ˆä¸šå†…&quot;å”¯ä¸€&quot;ï¼‰æŠ€æœ¯ç»å¾—èµ·è€ƒéªŒï¼Œæå¤§**æŒç»­ç ”å‘**æŠ•å…¥
- ğŸ§‘â€ğŸ’» **12å°æ—¶çœŸäººå®¢æœ**(é¡ºå¸¦è§£å†³ Clash Verge ä½¿ç”¨é—®é¢˜)
- ğŸ’° ä¼˜æƒ å¥—é¤æ¯æœˆ**ä»…éœ€ 21 å…ƒï¼Œ160G æµé‡ï¼Œå¹´ä»˜ 8 æŠ˜**
- ğŸŒ æµ·å¤–å›¢é˜Ÿï¼Œæ— è·‘è·¯é£é™©ï¼Œé«˜è¾¾ 50% è¿”ä½£
- âš™ï¸ **é›†ç¾¤è´Ÿè½½å‡è¡¡**è®¾è®¡ï¼Œ**è´Ÿè½½ç›‘æ§å’Œéšæ—¶æ‰©å®¹**ï¼Œé«˜é€Ÿä¸“çº¿(å…¼å®¹è€å®¢æˆ·ç«¯)ï¼Œæä½å»¶è¿Ÿï¼Œæ— è§†æ™šé«˜å³°ï¼Œ4K ç§’å¼€
- âš¡ å…¨çƒé¦–å®¶**Quic åè®®æœºåœº**ï¼Œç°å·²ä¸Šçº¿æ›´å¿«çš„ Tuic åè®®(Clash Verge å®¢æˆ·ç«¯æœ€ä½³æ­é…)
- ğŸ¬ è§£é”**æµåª’ä½“åŠ ä¸»æµ AI**

ğŸŒ å®˜ç½‘ï¼šğŸ‘‰ [https://ç‹—ç‹—åŠ é€Ÿ.com](https://verge.dginv.click/#/register?code=oaxsAGo6)

## Features

- åŸºäºæ€§èƒ½å¼ºåŠ²çš„ Rust å’Œ Tauri 2 æ¡†æ¶
- å†…ç½®[Clash.Meta(mihomo)](https://github.com/MetaCubeX/mihomo)å†…æ ¸ï¼Œå¹¶æ”¯æŒåˆ‡æ¢ `Alpha` ç‰ˆæœ¬å†…æ ¸ã€‚
- ç®€æ´ç¾è§‚çš„ç”¨æˆ·ç•Œé¢ï¼Œæ”¯æŒè‡ªå®šä¹‰ä¸»é¢˜é¢œè‰²ã€ä»£ç†ç»„/æ‰˜ç›˜å›¾æ ‡ä»¥åŠ `CSS Injection`ã€‚
- é…ç½®æ–‡ä»¶ç®¡ç†å’Œå¢å¼ºï¼ˆMerge å’Œ Scriptï¼‰ï¼Œé…ç½®æ–‡ä»¶è¯­æ³•æç¤ºã€‚
- ç³»ç»Ÿä»£ç†å’Œå®ˆå«ã€`TUN(è™šæ‹Ÿç½‘å¡)` æ¨¡å¼ã€‚
- å¯è§†åŒ–èŠ‚ç‚¹å’Œè§„åˆ™ç¼–è¾‘
- WebDav é…ç½®å¤‡ä»½å’ŒåŒæ­¥

### FAQ

Refer to [Doc FAQ Page](https://clash-verge-rev.github.io/faq/windows.html)

### Donation

[æåŠ©Clash Verge Revçš„å¼€å‘](https://github.com/sponsors/clash-verge-rev)

## Development

See [CONTRIBUTING.md](./CONTRIBUTING.md) for more details.

To run the development server, execute the following commands after all prerequisites for **Tauri** are installed:

```shell
pnpm i
pnpm run prebuild
pnpm dev
```

## Contributions

Issue and PR welcome!

## Acknowledgement

Clash Verge rev was based on or inspired by these projects and so on:

- [zzzgydi/clash-verge](https://github.com/zzzgydi/clash-verge): A Clash GUI based on tauri. Supports Windows, macOS and Linux.
- [tauri-apps/tauri](https://github.com/tauri-apps/tauri): Build smaller, faster, and more secure desktop applications with a web frontend.
- [Dreamacro/clash](https://github.com/Dreamacro/clash): A rule-based tunnel in Go.
- [MetaCubeX/mihomo](https://github.com/MetaCubeX/mihomo): A rule-based tunnel in Go.
- [Fndroid/clash_for_windows_pkg](https://github.com/Fndroid/clash_for_windows_pkg): A Windows/macOS GUI based on Clash.
- [vitejs/vite](https://github.com/vitejs/vite): Next generation frontend tooling. It&#039;s fast!

## License

GPL-3.0 License. See [License here](./LICENSE) for details.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[laurent22/joplin]]></title>
            <link>https://github.com/laurent22/joplin</link>
            <guid>https://github.com/laurent22/joplin</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:34 GMT</pubDate>
            <description><![CDATA[Joplin - the privacy-focused note taking app with sync capabilities for Windows, macOS, Linux, Android and iOS.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/laurent22/joplin">laurent22/joplin</a></h1>
            <p>Joplin - the privacy-focused note taking app with sync capabilities for Windows, macOS, Linux, Android and iOS.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 53,585</p>
            <p>Forks: 5,804</p>
            <p>Stars today: 36 stars today</p>
            <h2>README</h2><pre>[![Donate](https://joplinapp.org/images/badges/Donate-PayPal-green.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_donations&amp;business=E8JMYD2LQ8MMA&amp;lc=GB&amp;item_name=Joplin+Development&amp;currency_code=EUR&amp;bn=PP%2dDonationsBF%3abtn_donateCC_LG%2egif%3aNonHosted) [![Sponsor on GitHub](https://joplinapp.org/images/badges/GitHub-Badge.svg)](https://github.com/sponsors/laurent22/) [![Become a patron](https://joplinapp.org/images/badges/Patreon-Badge.svg)](https://www.patreon.com/joplin)

* * *

&lt;img width=&quot;64&quot; src=&quot;https://raw.githubusercontent.com/laurent22/joplin/master/Assets/LinuxIcons/256x256.png&quot; align=&quot;left&quot; /&gt; **Joplin** is a free, open source note taking and to-do application, which can handle a large number of notes organised into notebooks. The notes are searchable, can be copied, tagged and modified either from the applications directly or from your own text editor. The notes are in [Markdown format](#markdown).

Notes exported from Evernote via .enex files [can be imported](#importing) into Joplin, including the formatted content (which is converted to Markdown), resources (images, attachments, etc.) and complete metadata (geolocation, updated time, created time, etc.). Plain Markdown files can also be imported.

The notes can be [synchronised](#synchronisation) with various cloud services including [Nextcloud](https://nextcloud.com/), Dropbox, OneDrive, WebDAV or the file system (for example with a network directory). When synchronising the notes, notebooks, tags and other metadata are saved to plain text files which can be easily inspected, backed up and moved around.

The application is available for Windows, Linux, macOS, Android and iOS (the terminal app also works on FreeBSD). A [Web Clipper](https://github.com/laurent22/joplin/blob/master/readme/clipper.md), to save web pages and screenshots from your browser, is also available for [Firefox](https://addons.mozilla.org/firefox/addon/joplin-web-clipper/) and [Chrome](https://chrome.google.com/webstore/detail/joplin-web-clipper/alofnhikmmkdbbbgpnglcpdollgjjfek?hl=en-GB).

&lt;div class=&quot;top-screenshot&quot;&gt;&lt;img src=&quot;https://joplinapp.org/images/AllClients.jpg&quot; style=&quot;max-width: 100%; max-height: 35em;&quot;&gt;&lt;/div&gt;

# Installation

Three types of applications are available: for the **desktop** (Windows, macOS and Linux), for **mobile** (Android and iOS) and for **terminal** (Windows, macOS, Linux and FreeBSD). All applications have similar user interfaces and can synchronise with each other.

## Desktop applications

Operating System | Download | Alternative
-----------------|--------|-------------------
Windows (32 and 64-bit)         | &lt;a href=&#039;https://github.com/laurent22/joplin/releases/download/v1.0.241/Joplin-Setup-1.0.241.exe&#039;&gt;&lt;img alt=&#039;Get it on Windows&#039; width=&quot;134px&quot; src=&#039;https://joplinapp.org/images/BadgeWindows.png&#039;/&gt;&lt;/a&gt; | Or get the &lt;a href=&#039;https://github.com/laurent22/joplin/releases/download/v1.0.241/JoplinPortable.exe&#039;&gt;Portable version&lt;/a&gt;&lt;br&gt;&lt;br&gt;The [portable application](https://en.wikipedia.org/wiki/Portable_application) allows installing the software on a portable device such as a USB key. Simply copy the file JoplinPortable.exe in any directory on that USB key ; the application will then create a directory called &quot;JoplinProfile&quot; next to the executable file.
macOS          | &lt;a href=&#039;https://github.com/laurent22/joplin/releases/download/v1.0.241/Joplin-1.0.241.dmg&#039;&gt;&lt;img alt=&#039;Get it on macOS&#039; width=&quot;134px&quot; src=&#039;https://joplinapp.org/images/BadgeMacOS.png&#039;/&gt;&lt;/a&gt; | You can also use Homebrew (unsupported): `brew cask install joplin`
Linux          | &lt;a href=&#039;https://github.com/laurent22/joplin/releases/download/v1.0.241/Joplin-1.0.241.AppImage&#039;&gt;&lt;img alt=&#039;Get it on Linux&#039; width=&quot;134px&quot; src=&#039;https://joplinapp.org/images/BadgeLinux.png&#039;/&gt;&lt;/a&gt; | An Arch Linux package (unsupported) [is also available](#terminal-application).&lt;br&gt;&lt;br&gt;If it works with your distribution (it has been tested on Ubuntu, Fedora, and Mint; the desktop environments supported are GNOME, KDE, Xfce, MATE, LXQT, LXDE, Unity, Cinnamon, Deepin and Pantheon), the recommended way is to use this script as it will handle the desktop icon too:&lt;br&gt;&lt;br&gt; `wget -O - https://raw.githubusercontent.com/laurent22/joplin/master/Joplin_install_and_update.sh \| bash`

## Mobile applications

Operating System | Download | Alt. Download
-----------------|:--------:|----------------
Android          | &lt;a href=&#039;https://play.google.com/store/apps/details?id=net.cozic.joplin&amp;utm_source=GitHub&amp;utm_campaign=README&amp;pcampaignid=MKT-Other-global-all-co-prtnr-py-PartBadge-Mar2515-1&#039;&gt;&lt;img alt=&#039;Get it on Google Play&#039; height=&quot;40px&quot; src=&#039;https://joplinapp.org/images/BadgeAndroid.png&#039;/&gt;&lt;/a&gt; | or &lt;a href=&quot;https://f-droid.org/packages/net.cozic.joplin&quot;&gt;Get it on F-Droid&lt;/a&gt;&lt;br/&gt; or directly download the APK file: [64-bit](https://github.com/laurent22/joplin-android/releases/download/android-v1.0.340/joplin-v1.0.340.apk) [32-bit](https://github.com/laurent22/joplin-android/releases/download/android-v1.0.340/joplin-v1.0.340-32bit.apk)
iOS              | &lt;a href=&#039;https://itunes.apple.com/us/app/joplin/id1315599797&#039;&gt;&lt;img alt=&#039;Get it on the App Store&#039; height=&quot;40px&quot; src=&#039;https://joplinapp.org/images/BadgeIOS.png&#039;/&gt;&lt;/a&gt; | -

## Terminal application

Operating system | Method
-----------------|----------------
macOS, Linux, or Windows (via [WSL](https://msdn.microsoft.com/en-us/commandline/wsl/faq?f=255&amp;MSPPError=-2147217396)) | **Important:** First, [install Node 10+](https://nodejs.org/en/download/package-manager/).&lt;br/&gt;&lt;br/&gt;`NPM_CONFIG_PREFIX=~/.joplin-bin npm install -g joplin`&lt;br/&gt;`sudo ln -s ~/.joplin-bin/bin/joplin /usr/bin/joplin`&lt;br&gt;&lt;br&gt;By default, the application binary will be installed under `~/.joplin-bin`. You may change this directory if needed. Alternatively, if your npm permissions are setup as described [here](https://docs.npmjs.com/getting-started/fixing-npm-permissions#option-2-change-npms-default-directory-to-another-directory) (Option 2) then simply running `npm -g install joplin` would work.

To start it, type `joplin`.

For usage information, please refer to the full [Joplin Terminal Application Documentation](https://joplinapp.org/terminal/).

### Unsupported methods

There are other ways to install the terminal application. However, they are not supported and problems must be reported to the upstream projects.

Operating system | Method
-----------------|----------------
macOS            | `brew install joplin`
Arch Linux       | An Arch Linux package is available [here](https://aur.archlinux.org/packages/joplin/). To install it, use an AUR wrapper such as yay: `yay -S joplin`. Both the CLI tool (type `joplin`) and desktop app (type `joplin-desktop`) are packaged. You can also install a compiled version with the [chaotic-aur](https://wiki.archlinux.org/index.php/Unofficial_user_repositories#chaotic-aur) repository. For support, please go to the [GitHub repo](https://github.com/masterkorp/joplin-pkgbuild).

## Web Clipper

The Web Clipper is a browser extension that allows you to save web pages and screenshots from your browser. For more information on how to install and use it, see the [Web Clipper Help Page](https://github.com/laurent22/joplin/blob/master/readme/clipper.md).

# Sponsors

&lt;a href=&quot;https://seirei.ne.jp&quot;&gt;&lt;img title=&quot;Serei Network&quot; width=&quot;256&quot; src=&quot;https://joplinapp.org/images/sponsors/SeireiNetwork.png&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://usrigging.com/&quot;&gt;&lt;img title=&quot;U.S. Ringing Supply&quot; width=&quot;256&quot; src=&quot;https://joplinapp.org/images/sponsors/RingingSupply.svg&quot;/&gt;&lt;/a&gt;

* * *

|     |     |     |
| :---: | :---: | :---: |
| &lt;img width=&quot;50&quot; src=&quot;https://avatars0.githubusercontent.com/u/6979755?s=96&amp;v=4&quot;/&gt;&lt;/br&gt;[Devon Zuegel](https://github.com/devonzuegel) | &lt;img width=&quot;50&quot; src=&quot;https://avatars2.githubusercontent.com/u/24908652?s=96&amp;v=4&quot;/&gt;&lt;/br&gt;[å°è¥¿ã€€å­å®—](https://github.com/konishi-t) | &lt;img width=&quot;50&quot; src=&quot;https://avatars2.githubusercontent.com/u/215668?s=96&amp;v=4&quot;/&gt;&lt;/br&gt;[Alexander van der Berg](https://github.com/avanderberg)
| &lt;img width=&quot;50&quot; src=&quot;https://avatars0.githubusercontent.com/u/1168659?s=96&amp;v=4&quot;/&gt;&lt;/br&gt;[Nicholas Head](https://github.com/nicholashead) | &lt;img width=&quot;50&quot; src=&quot;https://avatars2.githubusercontent.com/u/1439535?s=96&amp;v=4&quot;/&gt;&lt;/br&gt;[Frank Bloise](https://github.com/fbloise) | &lt;img width=&quot;50&quot; src=&quot;https://avatars2.githubusercontent.com/u/15859362?s=96&amp;v=4&quot;/&gt;&lt;/br&gt;[Thomas Broussard](https://github.com/thomasbroussard)
| &lt;img width=&quot;50&quot; src=&quot;https://avatars2.githubusercontent.com/u/1307332?s=96&amp;v=4&quot;/&gt;&lt;/br&gt;[Brandon Johnson](https://github.com/dbrandonjohnson) |   |

&lt;!-- TOC --&gt;
# Table of contents

- Applications

	- [Desktop application](https://github.com/laurent22/joplin/blob/master/readme/desktop.md)
	- [Mobile applications](https://github.com/laurent22/joplin/blob/master/readme/mobile.md)
	- [Terminal application](https://github.com/laurent22/joplin/blob/master/readme/terminal.md)
	- [Web Clipper](https://github.com/laurent22/joplin/blob/master/readme/clipper.md)

- Support

	- [Joplin Forum](https://discourse.joplinapp.org)
	- [Markdown Guide](https://github.com/laurent22/joplin/blob/master/readme/markdown.md)
	- [How to enable end-to-end encryption](https://github.com/laurent22/joplin/blob/master/readme/e2ee.md)
	- [What is a conflict?](https://github.com/laurent22/joplin/blob/master/readme/conflict.md)
	- [How to enable debug mode](https://github.com/laurent22/joplin/blob/master/readme/debugging.md)
	- [API documentation](https://github.com/laurent22/joplin/blob/master/readme/api.md)
	- [FAQ](https://github.com/laurent22/joplin/blob/master/readme/faq.md)

- Development

	- [End-to-end encryption spec](https://github.com/laurent22/joplin/blob/master/readme/spec.md)
	- [Note History spec](https://github.com/laurent22/joplin/blob/master/readme/spec/history.md)
	- [Sync Lock spec](https://github.com/laurent22/joplin/blob/master/readme/spec/sync_lock.md)

- Google Summer of Code 2020

	- [Google Summer of Code 2020](https://github.com/laurent22/joplin/blob/master/readme/gsoc2020/index.md)
	- [Project Ideas](https://github.com/laurent22/joplin/blob/master/readme/gsoc2020/ideas.md)

- About

	- [Changelog (Desktop App)](https://github.com/laurent22/joplin/blob/master/readme/changelog.md)
	- [Changelog (CLI App)](https://github.com/laurent22/joplin/blob/master/readme/changelog_cli.md)
	- [Stats](https://github.com/laurent22/joplin/blob/master/readme/stats.md)
	- [Donate](https://github.com/laurent22/joplin/blob/master/readme/donate.md)
&lt;!-- TOC --&gt;

# Features

- Desktop, mobile and terminal applications.
- [Web Clipper](https://github.com/laurent22/joplin/blob/master/readme/clipper.md) for Firefox and Chrome.
- End To End Encryption (E2EE)
- Note history (revisions)
- Synchronisation with various services, including Nextcloud, Dropbox, WebDAV and OneDrive.
- Import Enex files (Evernote export format) and Markdown files.
- Export JEX files (Joplin Export format) and raw files.
- Support notes, to-dos, tags and notebooks.
- Goto Anything feature.
- Sort notes by multiple criteria - title, updated time, etc.
- Support for alarms (notifications) in mobile and desktop applications.
- Offline first, so the entire data is always available on the device even without an internet connection.
- Markdown notes, which are rendered with images and formatting in the desktop and mobile applications. Support for extra features such as math notation and checkboxes.
- File attachment support - images are displayed, and other files are linked and can be opened in the relevant application.
- Search functionality.
- Geo-location support.
- Supports multiple languages
- External editor support - open notes in your favorite external editor with one click in Joplin.

# Importing

## Importing from Evernote

Joplin was designed as a replacement for Evernote and so can import complete Evernote notebooks, as well as notes, tags, resources (attached files) and note metadata (such as author, geo-location, etc.) via ENEX files. In terms of data, the only two things that might slightly differ are:

- Recognition data - Evernote images, in particular scanned (or photographed) documents have [recognition data](https://en.wikipedia.org/wiki/Optical_character_recognition) associated with them. It is the text that Evernote has been able to recognise in the document. This data is not preserved when the note are imported into Joplin. However, should it become supported in the search tool or other parts of Joplin, it should be possible to regenerate this recognition data since the actual image would still be available.

- Colour, font sizes and faces - Evernote text is stored as HTML and this is converted to Markdown during the import process. For notes that are mostly plain text or with basic formatting (bold, italic, bullet points, links, etc.) this is a lossless conversion, and the note, once rendered back to HTML should be very similar. Tables are also imported and converted to Markdown tables. For very complex notes, some formatting data might be lost - in particular colours, font sizes and font faces will not be imported. The text itself however is always imported in full regardless of formatting.

To import Evernote data, first export your Evernote notebooks to ENEX files as described [here](https://help.evernote.com/hc/en-us/articles/209005557-How-to-back-up-export-and-restore-import-notes-and-notebooks). Then follow these steps:

In the **desktop application**, open File &gt; Import &gt; ENEX and select your file. The notes will be imported into a new separate notebook. If needed they can then be moved to a different notebook, or the notebook can be renamed, etc.

In the **terminal application**, in [command-line mode](https://github.com/laurent22/joplin/blob/master/readme/terminal.md#command-line-mode), type `import /path/to/file.enex`. This will import the notes into a new notebook named after the filename.

## Importing from Markdown files

Joplin can import notes from plain Markdown file. You can either import a complete directory of Markdown files or individual files.

In the **desktop application**, open File &gt; Import &gt; MD and select your Markdown file or directory.

In the **terminal application**, in [command-line mode](https://github.com/laurent22/joplin/blob/master/readme/terminal.md#command-line-mode), type `import --format md /path/to/file.md` or `import --format md /path/to/directory/`.

## Importing from other applications

In general the way to import notes from any application into Joplin is to convert the notes to ENEX files (Evernote format) and to import these ENEX files into Joplin using the method above. Most note-taking applications support ENEX files so it should be relatively straightforward. For help about specific applications, see below:

* Standard Notes: Please see [this tutorial](https://programadorwebvalencia.com/migrate-notes-from-standard-notes-to-joplin/)
* Tomboy Notes: Export the notes to ENEX files [as described here](https://askubuntu.com/questions/243691/how-can-i-export-my-tomboy-notes-into-evernote/608551) for example, and import these ENEX files into Joplin.
* OneNote: First [import the notes from OneNote into Evernote](https://discussion.evernote.com/topic/107736-is-there-a-way-to-import-from-onenote-into-evernote-on-the-mac/). Then export the ENEX file from Evernote and import it into Joplin.
* NixNote: Synchronise with Evernote, then export the ENEX files and import them into Joplin. More info [in this thread](https://discourse.joplinapp.org/t/import-from-nixnote/183/3).

# Exporting

Joplin can export to the JEX format (Joplin Export file), which is a tar file that can contain multiple notes, notebooks, etc. This is a lossless format in that all the notes, but also metadata such as geo-location, updated time, tags, etc. are preserved. This format is convenient for backup purposes and can be re-imported into Joplin. A &quot;raw&quot; format is also available. This is the same as the JEX format except that the data is saved to a directory and each item represented by a single file.

# Synchronisation

One of the goals of Joplin was to avoid being tied to any particular company or service, whether it is Evernote, Google or Microsoft. As such the synchronisation is designed without any hard dependency to any particular service. Most of the synchronisation process is done at an abstract level and access to external services, such as Nextcloud or Dropbox, is done via lightweight drivers. It is easy to support new services by creating simple drivers that provide a filesystem-like interface, i.e. the ability to read, write, delete and list items. It is also simple to switch from one service to another or to even sync to multiple services at once. Each note, notebook, tags, as well as the relation between items is transmitted as plain text files during synchronisation, which means the data can also be moved to a different application, can be easily backed up, inspected, etc.

Currently, synchronisation is possible with Nextcloud, Dropbox, OneDrive or the local filesystem. To enable synchronisation please follow the instructions below. After that, the application will synchronise in the background whenever it is running, or you can click on &quot;Synchronise&quot; to start a synchronisation manually.

## Nextcloud synchronisation

&lt;img src=&quot;https://joplinapp.org/images/nextcloud-logo-background.png&quot; width=&quot;100&quot; align=&quot;left&quot;&gt; &lt;a href=&quot;https://nextcloud.com/&quot;&gt;Nextcloud&lt;/a&gt; is a self-hosted, private cloud solution. It can store documents, images and videos but also calendars, passwords and countless other things and can sync them to your laptop or phone. As you can host your own Nextcloud server, you own both the data on your device and infrastructure used for synchronisation. As such it is a good fit for Joplin. The platform is also well supported and with a strong community, so it is likely to be around for a while - since it&#039;s open source anyway, it is not a service that can be closed, it can exist on a server for as long as one chooses.

In the **desktop application** or **mobile application**, go to the config screen and select Nextcloud as the synchronisation target. Then input the WebDAV URL (to get it, click on Settings in the bottom left corner of the page, in Nextcloud), this is normally `https://example.com/nextcloud/remote.php/webdav/Joplin` (**make sure to create the &quot;Joplin&quot; directory in Nextcloud**), and set the username and password. If it does not work, please [see this explanation](https://github.com/laurent22/joplin/issues/61#issuecomment-373282608) for more details.

In the **terminal application**, you will need to set the `sync.target` config variable and all the `sync.5.path`, `sync.5.username` and `sync.5.password` config variables to, respectively the Nextcloud WebDAV URL, your username and your password. This can be done from the command line mode using:

	:config sync.5.path https://example.com/nextcloud/remote.php/webdav/Joplin
	:config sync.5.username YOUR_USERNAME
	:config sync.5.password YOUR_PASSWORD
	:config sync.target 5

If synchronisation does not work, please consult the logs in the app profile directory - it is often due to a misconfigured URL or password. The log should indicate what the exact issue is.

## Dropbox synchronisation

When syncing with Dropbox, Joplin creates a sub-directory in Dropbox, in `/Apps/Joplin` and read/write the notes and notebooks from it. The application does not have access to anything outside this directory.

In the **desktop application** or **mobile application**, select &quot;Dropbox&quot; as the synchronisation target in the config screen (it is selected by default). Then, to initiate the synchronisation process, click on the &quot;Synchronise&quot; button in the sidebar and follow the instructions.

In the **terminal application**, to initiate the synchronisation process, type `:sync`. You will be asked to follow a link to authorise the application. It is possible to also synchronise outside of the user interface by typing `j

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[code-yeongyu/oh-my-opencode]]></title>
            <link>https://github.com/code-yeongyu/oh-my-opencode</link>
            <guid>https://github.com/code-yeongyu/oh-my-opencode</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:33 GMT</pubDate>
            <description><![CDATA[the best agent harness]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/code-yeongyu/oh-my-opencode">code-yeongyu/oh-my-opencode</a></h1>
            <p>the best agent harness</p>
            <p>Language: TypeScript</p>
            <p>Stars: 33,478</p>
            <p>Forks: 2,524</p>
            <p>Stars today: 351 stars today</p>
            <h2>README</h2><pre>&gt; [!WARNING]
&gt; **Security warning: impersonation site**
&gt;
&gt; **ohmyopencode.com is NOT affiliated with this project.** We do not operate or endorse that site.
&gt;
&gt; OhMyOpenCode is **free and open-source**. Do **not** download installers or enter payment details on third-party sites that claim to be &quot;official.&quot;
&gt;
&gt; Because the impersonation site is behind a paywall, we **cannot verify what it distributes**. Treat any downloads from it as **potentially unsafe**.
&gt;
&gt; âœ… Official downloads: https://github.com/code-yeongyu/oh-my-opencode/releases

&gt; [!NOTE]
&gt;
&gt; [![Sisyphus Labs â€” Sisyphus is the agent that codes like your team.](./.github/assets/sisyphuslabs.png?v=2)](https://sisyphuslabs.ai)
&gt; &gt; **We&#039;re building a fully productized version of Sisyphus to define the future of frontier agents. &lt;br /&gt;Join the waitlist [here](https://sisyphuslabs.ai).**

&gt; [!TIP]
&gt;
&gt; [![Oh My OpenCode 3.0 is now stable!](./.github/assets/orchestrator-atlas.png?v=3)](https://github.com/code-yeongyu/oh-my-opencode/releases/tag/v3.0.0)
&gt; &gt; **Oh My OpenCode 3.0 is now stable! Use `oh-my-opencode@latest` to install it.**
&gt;
&gt; Be with us!
&gt;
&gt; | [&lt;img alt=&quot;Discord link&quot; src=&quot;https://img.shields.io/discord/1452487457085063218?color=5865F2&amp;label=discord&amp;labelColor=black&amp;logo=discord&amp;logoColor=white&amp;style=flat-square&quot; width=&quot;156px&quot; /&gt;](https://discord.gg/PUwSMR9XNk) | Join our [Discord community](https://discord.gg/PUwSMR9XNk) to connect with contributors and fellow `oh-my-opencode` users. |
&gt; | :-----| :----- |
&gt; | [&lt;img alt=&quot;X link&quot; src=&quot;https://img.shields.io/badge/Follow-%40justsisyphus-00CED1?style=flat-square&amp;logo=x&amp;labelColor=black&quot; width=&quot;156px&quot; /&gt;](https://x.com/justsisyphus) | News and updates for `oh-my-opencode` used to be posted on my X account. &lt;br /&gt; Since it was suspended mistakenly, [@justsisyphus](https://x.com/justsisyphus) now posts updates on my behalf. |
&gt; | [&lt;img alt=&quot;GitHub Follow&quot; src=&quot;https://img.shields.io/github/followers/code-yeongyu?style=flat-square&amp;logo=github&amp;labelColor=black&amp;color=24292f&quot; width=&quot;156px&quot; /&gt;](https://github.com/code-yeongyu) | Follow [@code-yeongyu](https://github.com/code-yeongyu) on GitHub for more projects. |

&lt;!-- &lt;CENTERED SECTION FOR GITHUB DISPLAY&gt; --&gt;

&lt;div align=&quot;center&quot;&gt;

[![Oh My OpenCode](./.github/assets/hero.jpg)](https://github.com/code-yeongyu/oh-my-opencode#oh-my-opencode)

[![Preview](./.github/assets/omo.png)](https://github.com/code-yeongyu/oh-my-opencode#oh-my-opencode)


&lt;/div&gt;

&gt; This is coding on steroidsâ€”`oh-my-opencode` in action. Run background agents, call specialized agents like oracle, librarian, and frontend engineer. Use crafted LSP/AST tools, curated MCPs, and a full Claude Code compatibility layer.

# Claude OAuth Access Notice

## TL;DR

&gt; Q. Can I use oh-my-opencode?

Yes.

&gt; Q. Can I use it with my Claude Code subscription?

Yes, technically possible. But I cannot recommend using it.

## FULL

&gt; As of January 2026, Anthropic has restricted third-party OAuth access citing ToS violations.
&gt;
&gt; [**Anthropic has cited this project, oh-my-opencode as justification for blocking opencode.**](https://x.com/thdxr/status/2010149530486911014)
&gt;
&gt; Indeed, some plugins that spoof Claude Code&#039;s oauth request signatures exist in the community.
&gt;
&gt; These tools may work regardless of technical detectability, but users should be aware of ToS implications, and I personally cannot recommend to use those.
&gt;
&gt; This project is not responsible for any issues arising from the use of unofficial tools, and **we do not have any custom implementations of those oauth systems.**


&lt;div align=&quot;center&quot;&gt;

[![GitHub Release](https://img.shields.io/github/v/release/code-yeongyu/oh-my-opencode?color=369eff&amp;labelColor=black&amp;logo=github&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/releases)
[![npm downloads](https://img.shields.io/npm/dt/oh-my-opencode?color=ff6b35&amp;labelColor=black&amp;style=flat-square)](https://www.npmjs.com/package/oh-my-opencode)
[![GitHub Contributors](https://img.shields.io/github/contributors/code-yeongyu/oh-my-opencode?color=c4f042&amp;labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/graphs/contributors)
[![GitHub Forks](https://img.shields.io/github/forks/code-yeongyu/oh-my-opencode?color=8ae8ff&amp;labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/network/members)
[![GitHub Stars](https://img.shields.io/github/stars/code-yeongyu/oh-my-opencode?color=ffcb47&amp;labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/stargazers)
[![GitHub Issues](https://img.shields.io/github/issues/code-yeongyu/oh-my-opencode?color=ff80eb&amp;labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/issues)
[![License](https://img.shields.io/badge/license-SUL--1.0-white?labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/blob/master/LICENSE.md)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/code-yeongyu/oh-my-opencode)

[English](README.md) | [í•œêµ­ì–´](README.ko.md) | [æ—¥æœ¬èª](README.ja.md) | [ç®€ä½“ä¸­æ–‡](README.zh-cn.md)

&lt;/div&gt;

&lt;!-- &lt;/CENTERED SECTION FOR GITHUB DISPLAY&gt; --&gt;

## Reviews

&gt; &quot;It made me cancel my Cursor subscription. Unbelievable things are happening in the open source community.&quot; - [Arthur Guiot](https://x.com/arthur_guiot/status/2008736347092382053?s=20)

&gt; &quot;If Claude Code does in 7 days what a human does in 3 months, Sisyphus does it in 1 hour. It just works until the task is done. It is a discipline agent.&quot; â€” B, Quant Researcher

&gt; &quot;Knocked out 8000 eslint warnings with Oh My Opencode, just in a day&quot; â€” [Jacob Ferrari](https://x.com/jacobferrari_/status/2003258761952289061)

&gt; &quot;I converted a 45k line tauri app into a SaaS web app overnight using Ohmyopencode and ralph loop. Started with interview me prompt, asked it for ratings and recommendations on the questions. It was amazing to watch it work and to wake up this morning to a mostly working website!&quot; - [James Hargis](https://x.com/hargabyte/status/2007299688261882202)

&gt; &quot;use oh-my-opencode, you will never go back&quot; â€” [d0t3ch](https://x.com/d0t3ch/status/2001685618200580503)

&gt; &quot;I haven&#039;t really been able to articulate exactly what makes it so great yet, but the development experience has reached a completely different dimension.&quot; - [
è‹”ç¡¯:ã“ã‘ã™ãšã‚Š](https://x.com/kokesuzuri/status/2008532913961529372?s=20)

&gt; &quot;Experimenting with open code, oh my opencode and supermemory this weekend to build some minecraft/souls-like abomination.&quot;
&gt; &quot;Asking it to add crouch animations while I go take my post-lunch walk. [Video]&quot; - [MagiMetal](https://x.com/MagiMetal/status/2005374704178373023)

&gt; &quot;You guys should pull this into core and recruit him. Seriously. It&#039;s really, really, really good.&quot; â€” Henning Kilset

&gt; &quot;Hire @yeon_gyu_kim if you can convince him, this dude has revolutionized opencode.&quot; â€” [mysticaltech](https://x.com/mysticaltech/status/2001858758608376079)

&gt; &quot;Oh My OpenCode Is Actually Insane&quot; - [YouTube - Darren Builds AI](https://www.youtube.com/watch?v=G_Snfh2M41M)

---

## Contents

- [Oh My OpenCode](#oh-my-opencode)
  - [Just Skip Reading This Readme](#just-skip-reading-this-readme)
    - [It&#039;s the Age of Agents](#its-the-age-of-agents)
    - [ğŸª„ The Magic Word: `ultrawork`](#-the-magic-word-ultrawork)
    - [For Those Who Want to Read: Meet Sisyphus](#for-those-who-want-to-read-meet-sisyphus)
      - [Just Install It.](#just-install-it)
  - [Installation](#installation)
    - [For Humans](#for-humans)
    - [For LLM Agents](#for-llm-agents)
  - [Uninstallation](#uninstallation)
  - [Features](#features)
   - [Configuration](#configuration)
    - [JSONC Support](#jsonc-support)
    - [Google Auth](#google-auth)
    - [Agents](#agents)
      - [Permission Options](#permission-options)
    - [Built-in Skills](#built-in-skills)
    - [Git Master](#git-master)
    - [Sisyphus Agent](#sisyphus-agent)
    - [Background Tasks](#background-tasks)
    - [Categories](#categories)
    - [Hooks](#hooks)
    - [MCPs](#mcps)
    - [LSP](#lsp)
    - [Experimental](#experimental)
    - [Environment Variables](#environment-variables)
  - [Author&#039;s Note](#authors-note)
  - [Warnings](#warnings)
  - [Loved by professionals at](#loved-by-professionals-at)

# Oh My OpenCode

[Claude Code](https://www.claude.com/product/claude-code) is great.
But if you&#039;re a hacker, you&#039;ll fall head over heels for [OpenCode](https://github.com/sst/opencode).
**START WITH YOUR ChatGPT, Claude, Gemini SUBSCRIPTIONS. OPENCODE COVERS THEM ALL.**

- Endlessly extensible. Endlessly customizable.
- Zero screen flicker.
- [LSP](https://opencode.ai/docs/lsp/), [linters, formatters](https://opencode.ai/docs/formatters/) activate automatically per fileâ€”and you can tweak everything.
- Mix and match models. **Orchestrate them by purpose.**
- Feature-rich. Beautiful. The terminal doesn&#039;t choke. High performance.

Remember the first time you switched from Windows to Linux? That rush of configuring everything exactly how you wanted?
In an age where that magic seems lost, OpenCode brings it back.
If you love coding and computers, OpenCode is that Linux-after-Windows moment.

**But here&#039;s the catch: there&#039;s a lot to learn, it&#039;s complex, and your time is expensive.**

I&#039;ve fixed that.
Even if you&#039;re not a hacker, invest a few minutes. Multiply your skills and productivity.
Hand this doc to an agent and let them set it up.

## Just Skip Reading This Readme

### It&#039;s the Age of Agents
- **Just paste this link into Claude Code / AmpCode / Factory Droid / Cursor and ask it to explain.**
  - Ask why it&#039;s good, why it&#039;s not just another boilerplate setup, what actually gets better.
  - If you&#039;re an LLM agent, explain to the user what becomes possible right now with this project.

As following:

```
Hey please read this readme and tell me why it is different from other agent harness? why is this actually good? https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/refs/heads/dev/README.md
```

### ğŸª„ The Magic Word: `ultrawork`

**Don&#039;t want to read all this? Just include `ultrawork` (or `ulw`) in your prompt.**

That&#039;s it. All the features we provide will work like magicâ€”parallel agents, background tasks, deep exploration, and relentless execution until completion. The agent figures out the rest automatically.

### For Those Who Want to Read: Meet Sisyphus

![Meet Sisyphus](.github/assets/sisyphus.png)

In greek mythology, Sisyphus was condemned to roll a boulder up a hill for eternity as punishment for deceiving the gods. LLM Agents haven&#039;t really done anything wrong, yet they too roll their &quot;stones&quot;â€”their thoughtsâ€”every single day.
My life is no different. Looking back, we are not so different from these agents.
**Yes! LLM Agents are no different from us. They can write code as brilliant as ours and work just as excellentlyâ€”if you give them great tools and solid teammates.**

Meet our main agent: Sisyphus (Opus 4.5 High). Below are the tools Sisyphus uses to keep that boulder rolling.

*Everything below is customizable. Take what you want. All features are enabled by default. You don&#039;t have to do anything. Battery Included, works out of the box.*

- Sisyphus&#039;s Teammates (Curated Agents)
  - Oracle: Design, debugging (GPT 5.2 Medium)
  - Frontend UI/UX Engineer: Frontend development (Gemini 3 Pro)
  - Librarian: Official docs, open source implementations, codebase exploration (Claude Sonnet 4.5)
  - Explore: Blazing fast codebase exploration (Contextual Grep) (Grok Code)
- Full LSP / AstGrep Support: Refactor decisively.
- Todo Continuation Enforcer: Forces the agent to continue if it quits halfway. **This is what keeps Sisyphus rolling that boulder.**
- Comment Checker: Prevents AI from adding excessive comments. Code generated by Sisyphus should be indistinguishable from human-written code.
- Claude Code Compatibility: Command, Agent, Skill, MCP, Hook(PreToolUse, PostToolUse, UserPromptSubmit, Stop)
- Curated MCPs:
  - Exa (Web Search)
  - Context7 (Official Documentation)
  - Grep.app (GitHub Code Search)
- Interactive Terminal Supported - Tmux Integration
- Async Agents
- ...

#### Just Install This

You can learn a lot from [overview page](docs/guide/overview.md), but following is like the example workflow.

Just by installing this, you make your agents to work like:

1. Sisyphus doesn&#039;t waste time hunting for files himself; he keeps the main agent&#039;s context lean. Instead, he fires off background tasks to faster, cheaper models in parallel to map the territory for him.
1. Sisyphus leverages LSP for refactoring; it&#039;s more deterministic, safer, and surgical.
1. When the heavy lifting requires a UI touch, Sisyphus delegates frontend tasks directly to Gemini 3 Pro.
1. If Sisyphus gets stuck in a loop or hits a wall, he doesn&#039;t keep banging his headâ€”he calls GPT 5.2 for high-IQ strategic backup.
1. Working with a complex open-source framework? Sisyphus spawns subagents to digest the raw source code and documentation in real-time. He operates with total contextual awareness.
1. When Sisyphus touches comments, he either justifies their existence or nukes them. He keeps your codebase clean.
1. Sisyphus is bound by his TODO list. If he doesn&#039;t finish what he started, the system forces him back into &quot;bouldering&quot; mode. Your task gets done, period.
1. Honestly, don&#039;t even bother reading the docs. Just write your prompt. Include the &#039;ultrawork&#039; keyword. Sisyphus will analyze the structure, gather the context, dig through external source code, and just keep bouldering until the job is 100% complete.
1. Actually, typing &#039;ultrawork&#039; is too much effort. Just type &#039;ulw&#039;. Just ulw. Sip your coffee. Your work is done.

Need to look something up? It scours official docs, your entire codebase history, and public GitHub implementationsâ€”using not just grep but built-in LSP tools and AST-Grep.
3. Stop worrying about context management when delegating to LLMs. I&#039;ve got it covered.
    - OhMyOpenCode aggressively leverages multiple agents to lighten the context load.
    - **Your agent is now the dev team lead. You&#039;re the AI Manager.**
4. It doesn&#039;t stop until the job is done.
5. Don&#039;t want to dive deep into this project? No problem. Just type &#039;ultrathink&#039;.

If you don&#039;t want all this, as mentioned, you can just pick and choose specific features.

## Installation

### For Humans

Copy and paste this prompt to your LLM agent (Claude Code, AmpCode, Cursor, etc.):

```
Install and configure oh-my-opencode by following the instructions here:
https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/refs/heads/master/docs/guide/installation.md
```

Or read the [Installation Guide](docs/guide/installation.md) directlyâ€”but **we strongly recommend letting an agent handle it. Humans make mistakes.**

### For LLM Agents

Fetch the installation guide and follow it:

```bash
curl -s https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/refs/heads/master/docs/guide/installation.md
```

## Uninstallation

To remove oh-my-opencode:

1. **Remove the plugin from your OpenCode config**

   Edit `~/.config/opencode/opencode.json` (or `opencode.jsonc`) and remove `&quot;oh-my-opencode&quot;` from the `plugin` array:

   ```bash
   # Using jq
   jq &#039;.plugin = [.plugin[] | select(. != &quot;oh-my-opencode&quot;)]&#039; \
       ~/.config/opencode/opencode.json &gt; /tmp/oc.json &amp;&amp; \
       mv /tmp/oc.json ~/.config/opencode/opencode.json
   ```

2. **Remove configuration files (optional)**

   ```bash
   # Remove user config
   rm -f ~/.config/opencode/oh-my-opencode.json

   # Remove project config (if exists)
   rm -f .opencode/oh-my-opencode.json
   ```

3. **Verify removal**

   ```bash
   opencode --version
   # Plugin should no longer be loaded
   ```

## Features

We have lots of features that you&#039;ll think should obviously exist, and once you experience them, you&#039;ll never be able to go back to how things were before.
See the full [Features Documentation](docs/features.md) for detailed information.

**Quick Overview:**
- **Agents**: Sisyphus (the main agent), Prometheus (planner), Oracle (architecture/debugging), Librarian (docs/code search), Explore (fast codebase grep), Multimodal Looker
- **Background Agents**: Run multiple agents in parallel like a real dev team
- **LSP &amp; AST Tools**: Refactoring, rename, diagnostics, AST-aware code search
- **Context Injection**: Auto-inject AGENTS.md, README.md, conditional rules
- **Claude Code Compatibility**: Full hook system, commands, skills, agents, MCPs
- **Built-in MCPs**: websearch (Exa), context7 (docs), grep_app (GitHub search)
- **Session Tools**: List, read, search, and analyze session history
- **Productivity Features**: Ralph Loop, Todo Enforcer, Comment Checker, Think Mode, and more

## Configuration

Highly opinionated, but adjustable to taste.
See the full [Configuration Documentation](docs/configurations.md) for detailed information.

**Quick Overview:**
- **Config Locations**: `.opencode/oh-my-opencode.json` (project) or `~/.config/opencode/oh-my-opencode.json` (user)
- **JSONC Support**: Comments and trailing commas supported
- **Agents**: Override models, temperatures, prompts, and permissions for any agent
- **Built-in Skills**: `playwright` (browser automation), `git-master` (atomic commits)
- **Sisyphus Agent**: Main orchestrator with Prometheus (Planner) and Metis (Plan Consultant)
- **Background Tasks**: Configure concurrency limits per provider/model
- **Categories**: Domain-specific task delegation (`visual`, `business-logic`, custom)
- **Hooks**: 25+ built-in hooks, all configurable via `disabled_hooks`
- **MCPs**: Built-in websearch (Exa), context7 (docs), grep_app (GitHub search)
- **LSP**: Full LSP support with refactoring tools
- **Experimental**: Aggressive truncation, auto-resume, and more


## Author&#039;s Note

**Curious about the philosophy behind this project?** Read the [Ultrawork Manifesto](docs/ultrawork-manifesto.md).

Install Oh My OpenCode.

I&#039;ve used LLMs worth $24,000 tokens purely for personal development.
Tried every tool out there, configured them to death. OpenCode won.

The answers to every problem I hit are baked into this plugin. Just install and go.
If OpenCode is Debian/Arch, Oh My OpenCode is Ubuntu/[Omarchy](https://omarchy.org/).


Heavily influenced by [AmpCode](https://ampcode.com) and [Claude Code](https://code.claude.com/docs/overview)â€”I&#039;ve ported their features here, often improved. And I&#039;m still building.
It&#039;s **Open**Code, after all.

Enjoy multi-model orchestration, stability, and rich features that other harnesses promise but can&#039;t deliver.
I&#039;ll keep testing and updating. I&#039;m this project&#039;s most obsessive user.
- Which model has the sharpest logic?
- Who&#039;s the debugging god?
- Who writes the best prose?
- Who dominates frontend?
- Who owns backend?
- Which model is fastest for daily driving?
- What new features are other harnesses shipping?

This plugin is the distillation of that experience. Just take the best. Got a better idea? PRs are welcome.

**Stop agonizing over agent harness choices.**
**I&#039;ll do the research, borrow from the best, and ship updates here.**

If this sounds arrogant and you have a better answer, please contribute. You&#039;re welcome.

I have no affiliation with any project or model mentioned here. This is purely personal experimentation and preference.

99% of this project was built using OpenCode. I tested for functionalityâ€”I don&#039;t really know how to write proper TypeScript. **But I personally reviewed and largely rewrote this doc, so read with confidence.**

## Warnings

- Productivity might spike too hard. Don&#039;t let your coworker notice.
  - Actually, I&#039;ll spread the word. Let&#039;s see who wins.
- If you&#039;re on [1.0.132](https://github.com/sst/opencode/releases/tag/v1.0.132) or older, an OpenCode bug may break config.
  - [The fix](https://github.com/sst/opencode/pull/5040) was merged after 1.0.132â€”use a newer version.
    - Fun fact: That PR was discovered and fixed thanks to OhMyOpenCode&#039;s Librarian, Explore, and Oracle setup.

## Loved by professio

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[DayuanJiang/next-ai-draw-io]]></title>
            <link>https://github.com/DayuanJiang/next-ai-draw-io</link>
            <guid>https://github.com/DayuanJiang/next-ai-draw-io</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:32 GMT</pubDate>
            <description><![CDATA[A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DayuanJiang/next-ai-draw-io">DayuanJiang/next-ai-draw-io</a></h1>
            <p>A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,529</p>
            <p>Forks: 2,282</p>
            <p>Stars today: 68 stars today</p>
            <h2>README</h2><pre># Next AI Draw.io

&lt;div align=&quot;center&quot;&gt;

**AI-Powered Diagram Creation Tool - Chat, Draw, Visualize**

English | [ä¸­æ–‡](./docs/cn/README_CN.md) | [æ—¥æœ¬èª](./docs/ja/README_JA.md)

[![TrendShift](https://trendshift.io/api/badge/repositories/15449)](https://next-ai-drawio.jiang.jp/)

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Next.js](https://img.shields.io/badge/Next.js-16.x-black)](https://nextjs.org/)
[![React](https://img.shields.io/badge/React-19.x-61dafb)](https://react.dev/)
[![Sponsor](https://img.shields.io/badge/Sponsor-â¤-ea4aaa)](https://github.com/sponsors/DayuanJiang)

[![Live Demo](./public/live-demo-button.svg)](https://next-ai-drawio.jiang.jp/)

&lt;/div&gt;

A Next.js web application that integrates AI capabilities with draw.io diagrams. Create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.

&gt; Note: Thanks to &lt;img src=&quot;https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/doubao-color.png&quot; alt=&quot;&quot; height=&quot;20&quot; /&gt; [ByteDance Doubao](https://www.volcengine.com/activity/newyear-referral?utm_campaign=doubao&amp;utm_content=aidrawio&amp;utm_medium=github&amp;utm_source=coopensrc&amp;utm_term=project) sponsorship, the demo site now uses the powerful K2-thinking model!


https://github.com/user-attachments/assets/9d60a3e8-4a1c-4b5e-acbb-26af2d3eabd1



## Table of Contents
- [Next AI Draw.io](#next-ai-drawio)
  - [Table of Contents](#table-of-contents)
  - [Examples](#examples)
  - [Features](#features)
  - [MCP Server (Preview)](#mcp-server-preview)
    - [Claude Code CLI](#claude-code-cli)
  - [Getting Started](#getting-started)
    - [Try it Online](#try-it-online)
    - [Desktop Application](#desktop-application)
    - [Run with Docker](#run-with-docker)
    - [Installation](#installation)
  - [Deployment](#deployment)
    - [Deploy to EdgeOne Pages](#deploy-to-edgeone-pages)
    - [Deploy on Vercel](#deploy-on-vercel)
    - [Deploy on Cloudflare Workers](#deploy-on-cloudflare-workers)
  - [Multi-Provider Support](#multi-provider-support)
  - [How It Works](#how-it-works)
  - [Support \&amp; Contact](#support--contact)
  - [FAQ](#faq)
  - [Star History](#star-history)

## Examples

Here are some example prompts and their generated diagrams:

&lt;div align=&quot;center&quot;&gt;
&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td colspan=&quot;2&quot; valign=&quot;top&quot; align=&quot;center&quot;&gt;
      &lt;strong&gt;Animated transformer connectors&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Give me a **animated connector** diagram of transformer&#039;s architecture.&lt;/p&gt;
      &lt;img src=&quot;./public/animated_connectors.svg&quot; alt=&quot;Transformer Architecture with Animated Connectors&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;GCP architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a GCP architecture diagram with **GCP icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/gcp_demo.svg&quot; alt=&quot;GCP Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;AWS architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a AWS architecture diagram with **AWS icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/aws_demo.svg&quot; alt=&quot;AWS Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;Azure architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a Azure architecture diagram with **Azure icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/azure_demo.svg&quot; alt=&quot;Azure Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;Cat sketch prompt&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Draw a cute cat for me.&lt;/p&gt;
      &lt;img src=&quot;./public/cat_demo.svg&quot; alt=&quot;Cat Drawing&quot; width=&quot;240&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;

## Features

-   **LLM-Powered Diagram Creation**: Leverage Large Language Models to create and manipulate draw.io diagrams directly through natural language commands
-   **Image-Based Diagram Replication**: Upload existing diagrams or images and have the AI replicate and enhance them automatically
-   **PDF &amp; Text File Upload**: Upload PDF documents and text files to extract content and generate diagrams from existing documents
-   **AI Reasoning Display**: View the AI&#039;s thinking process for supported models (OpenAI o1/o3, Gemini, Claude, etc.)
-   **Diagram History**: Comprehensive version control that tracks all changes, allowing you to view and restore previous versions of your diagrams before the AI editing.
-   **Interactive Chat Interface**: Communicate with AI to refine your diagrams in real-time
-   **Cloud Architecture Diagram Support**: Specialized support for generating cloud architecture diagrams (AWS, GCP, Azure)
-   **Animated Connectors**: Create dynamic and animated connectors between diagram elements for better visualization

## MCP Server (Preview)

&gt; **Preview Feature**: This feature is experimental and may not be stable.

Use Next AI Draw.io with AI agents like Claude Desktop, Cursor, and VS Code via MCP (Model Context Protocol).

```json
{
  &quot;mcpServers&quot;: {
    &quot;drawio&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;@next-ai-drawio/mcp-server@latest&quot;]
    }
  }
}
```

### Claude Code CLI

```bash
claude mcp add drawio -- npx @next-ai-drawio/mcp-server@latest
```

Then ask Claude to create diagrams:
&gt; &quot;Create a flowchart showing user authentication with login, MFA, and session management&quot;

The diagram appears in your browser in real-time!

See the [MCP Server README](./packages/mcp-server/README.md) for VS Code, Cursor, and other client configurations.

## Getting Started

### Try it Online

No installation needed! Try the app directly on our demo site:

[![Live Demo](./public/live-demo-button.svg)](https://next-ai-drawio.jiang.jp/)



&gt; **Bring Your Own API Key**: You can use your own API key to bypass usage limits on the demo site. Click the Settings icon in the chat panel to configure your provider and API key. Your key is stored locally in your browser and is never stored on the server.

### Desktop Application

Download the native desktop app for your platform from the [Releases page](https://github.com/DayuanJiang/next-ai-draw-io/releases):

Supported platforms: Windows, macOS, Linux.

### Run with Docker

[Go to Docker Guide](./docs/en/docker.md)

### Installation

1. Clone the repository:

```bash
git clone https://github.com/DayuanJiang/next-ai-draw-io
cd next-ai-draw-io
npm install
cp env.example .env.local
```

See the [Provider Configuration Guide](./docs/en/ai-providers.md) for detailed setup instructions for each provider.

2. Run the development server:

```bash
npm run dev
```

3. Open [http://localhost:6002](http://localhost:6002) in your browser to see the application.

## Deployment

### Deploy to EdgeOne Pages

You can deploy with one click using [Tencent EdgeOne Pages](https://pages.edgeone.ai/).

Deploy by this button: 

[![Deploy to EdgeOne Pages](https://cdnstatic.tencentcs.com/edgeone/pages/deploy.svg)](https://edgeone.ai/pages/new?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io)

Check out the [Tencent EdgeOne Pages documentation](https://pages.edgeone.ai/document/deployment-overview) for more details.

Additionally, deploying through Tencent EdgeOne Pages will also grant you a [daily free quota for DeepSeek models](https://pages.edgeone.ai/document/edge-ai).

### Deploy on Vercel 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io)

The easiest way to deploy is using [Vercel](https://vercel.com/new), the creators of Next.js. Be sure to **set the environment variables** in the Vercel dashboard as you did in your local `.env.local` file.

See the [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.

### Deploy on Cloudflare Workers

[Go to Cloudflare Deploy Guide](./docs/en/cloudflare-deploy.md)



## Multi-Provider Support

-   [ByteDance Doubao](https://www.volcengine.com/activity/newyear-referral?utm_campaign=doubao&amp;utm_content=aidrawio&amp;utm_medium=github&amp;utm_source=coopensrc&amp;utm_term=project)
-   AWS Bedrock (default)
-   OpenAI
-   Anthropic
-   Google AI
-   Google Vertex AI
-   Azure OpenAI
-   Ollama
-   OpenRouter
-   DeepSeek
-   SiliconFlow
-   ModelScope
-   SGLang
-   Vercel AI Gateway


All providers except AWS Bedrock and OpenRouter support custom endpoints.

ğŸ“– **[Detailed Provider Configuration Guide](./docs/en/ai-providers.md)** - See setup instructions for each provider.

### Server-Side Multi-Model Configuration

Administrators can configure multiple server-side models that are available to all users without requiring personal API keys. Configure via `AI_MODELS_CONFIG` environment variable (JSON string) or `ai-models.json` file.

**Model Requirements**: This task requires strong model capabilities for generating long-form text with strict formatting constraints (draw.io XML). Recommended models include Claude Sonnet 4.5, GPT-5.1, Gemini 3 Pro, and DeepSeek V3.2/R1.

Note that the `claude` series has been trained on draw.io diagrams with cloud architecture logos like AWS, Azure, GCP. So if you want to create cloud architecture diagrams, this is the best choice.


## How It Works

The application uses the following technologies:

-   **Next.js**: For the frontend framework and routing
-   **Vercel AI SDK** (`ai` + `@ai-sdk/*`): For streaming AI responses and multi-provider support
-   **react-drawio**: For diagram representation and manipulation

Diagrams are represented as XML that can be rendered in draw.io. The AI processes your commands and generates or modifies this XML accordingly.


## Support &amp; Contact

**Special thanks to [ByteDance Doubao](https://www.volcengine.com/activity/newyear-referral?utm_campaign=doubao&amp;utm_content=aidrawio&amp;utm_medium=github&amp;utm_source=coopensrc&amp;utm_term=project) for sponsoring the API token usage of the demo site!** Register on the ARK platform to get 500K free tokens for all models!

If you find this project useful, please consider [sponsoring](https://github.com/sponsors/DayuanJiang) to help me host the live demo site!

For support or inquiries, please open an issue on the GitHub repository or contact the maintainer at:

-   Email: me[at]jiang.jp

## FAQ

See [FAQ](./docs/en/FAQ.md) for common issues and solutions.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=DayuanJiang/next-ai-draw-io&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#DayuanJiang/next-ai-draw-io&amp;type=date&amp;legend=top-left)

---
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[shareAI-lab/learn-claude-code]]></title>
            <link>https://github.com/shareAI-lab/learn-claude-code</link>
            <guid>https://github.com/shareAI-lab/learn-claude-code</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:31 GMT</pubDate>
            <description><![CDATA[Bash is all you need - A nano Claude Codeâ€“like agent, built from 0 to 1]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/shareAI-lab/learn-claude-code">shareAI-lab/learn-claude-code</a></h1>
            <p>Bash is all you need - A nano Claude Codeâ€“like agent, built from 0 to 1</p>
            <p>Language: TypeScript</p>
            <p>Stars: 17,502</p>
            <p>Forks: 3,701</p>
            <p>Stars today: 106 stars today</p>
            <h2>README</h2><pre># Learn Claude Code -- A nano Claude Code-like agent, built from 0 to 1

[English](./README.md) | [ä¸­æ–‡](./README-zh.md) | [æ—¥æœ¬èª](./README-ja.md)

```
                    THE AGENT PATTERN
                    =================

    User --&gt; messages[] --&gt; LLM --&gt; response
                                      |
                            stop_reason == &quot;tool_use&quot;?
                           /                          \
                         yes                           no
                          |                             |
                    execute tools                    return text
                    append results
                    loop back -----------------&gt; messages[]


    That&#039;s the minimal loop. Every AI coding agent needs this loop.
    Production agents add policy, permissions, and lifecycle layers.
```

**12 progressive sessions, from a simple loop to isolated autonomous execution.**
**Each session adds one mechanism. Each mechanism has one motto.**

&gt; **s01** &amp;nbsp; *&quot;Bash is all you need&quot;* &amp;mdash; one tool + one loop = an agent
&gt;
&gt; **s02** &amp;nbsp; *&quot;The loop didn&#039;t change&quot;* &amp;mdash; adding tools means adding handlers, not rewriting the loop
&gt;
&gt; **s03** &amp;nbsp; *&quot;Plan before you act&quot;* &amp;mdash; visible plans improve task completion
&gt;
&gt; **s04** &amp;nbsp; *&quot;Process isolation = context isolation&quot;* &amp;mdash; fresh messages[] per subagent
&gt;
&gt; **s05** &amp;nbsp; *&quot;Load on demand, not upfront&quot;* &amp;mdash; inject knowledge via tool_result, not system prompt
&gt;
&gt; **s06** &amp;nbsp; *&quot;Strategic forgetting&quot;* &amp;mdash; forget old context to enable infinite sessions
&gt;
&gt; **s07** &amp;nbsp; *&quot;State survives /compact&quot;* &amp;mdash; file-based state outlives context compression
&gt;
&gt; **s08** &amp;nbsp; *&quot;Fire and forget&quot;* &amp;mdash; non-blocking threads + notification queue
&gt;
&gt; **s09** &amp;nbsp; *&quot;Append to send, drain to read&quot;* &amp;mdash; async mailboxes for persistent teammates
&gt;
&gt; **s10** &amp;nbsp; *&quot;Same request_id, two protocols&quot;* &amp;mdash; one FSM pattern powers shutdown + plan approval
&gt;
&gt; **s11** &amp;nbsp; *&quot;Poll, claim, work, repeat&quot;* &amp;mdash; no coordinator needed, agents self-organize
&gt;
&gt; **s12** &amp;nbsp; *&quot;Isolate by directory, coordinate by task ID&quot;* &amp;mdash; task board + optional worktree lanes

---

## The Core Pattern

```python
def agent_loop(messages):
    while True:
        response = client.messages.create(
            model=MODEL, system=SYSTEM,
            messages=messages, tools=TOOLS,
        )
        messages.append({&quot;role&quot;: &quot;assistant&quot;,
                         &quot;content&quot;: response.content})

        if response.stop_reason != &quot;tool_use&quot;:
            return

        results = []
        for block in response.content:
            if block.type == &quot;tool_use&quot;:
                output = TOOL_HANDLERS[block.name](**block.input)
                results.append({
                    &quot;type&quot;: &quot;tool_result&quot;,
                    &quot;tool_use_id&quot;: block.id,
                    &quot;content&quot;: output,
                })
        messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: results})
```

Every session layers one mechanism on top of this loop -- without changing the loop itself.

## Scope (Important)

This repository is a 0-&gt;1 learning project for building a nano Claude Code-like agent.
It intentionally simplifies or omits several production mechanisms:

- Full event/hook buses (for example PreToolUse, SessionStart/End, ConfigChange).  
  s12 includes only a minimal append-only lifecycle event stream for teaching.
- Rule-based permission governance and trust workflows
- Session lifecycle controls (resume/fork) and advanced worktree lifecycle controls
- Full MCP runtime details (transport/OAuth/resource subscribe/polling)

Treat the team JSONL mailbox protocol in this repo as a teaching implementation, not a claim about any specific production internals.

## Quick Start

```sh
git clone https://github.com/shareAI-lab/learn-claude-code
cd learn-claude-code
pip install -r requirements.txt
cp .env.example .env   # Edit .env with your ANTHROPIC_API_KEY

python agents/s01_agent_loop.py       # Start here
python agents/s11_autonomous_agents.py  # Full autonomous team
python agents/s12_worktree_task_isolation.py  # Task-aware worktree isolation
```

### Web Platform

Interactive visualizations, step-through diagrams, source viewer, and documentation.

```sh
cd web &amp;&amp; npm install &amp;&amp; npm run dev   # http://localhost:3000
```

## Learning Path

```
Phase 1: THE LOOP                    Phase 2: PLANNING &amp; KNOWLEDGE
==================                   ==============================
s01  The Agent Loop          [1]     s03  TodoWrite               [5]
     while + stop_reason                  TodoManager + nag reminder
     |                                    |
     +-&gt; s02  Tools              [4]     s04  Subagents            [5]
              dispatch map: name-&gt;handler     fresh messages[] per child
                                              |
                                         s05  Skills               [5]
                                              SKILL.md via tool_result
                                              |
                                         s06  Compact              [5]
                                              3-layer compression

Phase 3: PERSISTENCE                 Phase 4: TEAMS
==================                   =====================
s07  Tasks                   [8]     s09  Agent Teams             [9]
     file-based CRUD + deps graph         teammates + JSONL mailboxes
     |                                    |
s08  Background Tasks        [6]     s10  Team Protocols          [12]
     daemon threads + notify queue        shutdown + plan approval FSM
                                          |
                                     s11  Autonomous Agents       [14]
                                          idle cycle + auto-claim
                                     |
                                     s12  Worktree Isolation      [16]
                                          task coordination + optional isolated execution lanes

                                     [N] = number of tools
```

## Architecture

```
learn-claude-code/
|
|-- agents/                        # Python reference implementations (s01-s12 + full)
|-- docs/{en,zh,ja}/               # Mental-model-first documentation (3 languages)
|-- web/                           # Interactive learning platform (Next.js)
|-- skills/                        # Skill files for s05
+-- .github/workflows/ci.yml      # CI: typecheck + build
```

## Documentation

Mental-model-first: problem, solution, ASCII diagram, minimal code.
Available in [English](./docs/en/) | [ä¸­æ–‡](./docs/zh/) | [æ—¥æœ¬èª](./docs/ja/).

| Session | Topic | Motto |
|---------|-------|-------|
| [s01](./docs/en/s01-the-agent-loop.md) | The Agent Loop | *Bash is all you need* |
| [s02](./docs/en/s02-tool-use.md) | Tools | *The loop didn&#039;t change* |
| [s03](./docs/en/s03-todo-write.md) | TodoWrite | *Plan before you act* |
| [s04](./docs/en/s04-subagent.md) | Subagents | *Process isolation = context isolation* |
| [s05](./docs/en/s05-skill-loading.md) | Skills | *Load on demand, not upfront* |
| [s06](./docs/en/s06-context-compact.md) | Compact | *Strategic forgetting* |
| [s07](./docs/en/s07-task-system.md) | Tasks | *State survives /compact* |
| [s08](./docs/en/s08-background-tasks.md) | Background Tasks | *Fire and forget* |
| [s09](./docs/en/s09-agent-teams.md) | Agent Teams | *Append to send, drain to read* |
| [s10](./docs/en/s10-team-protocols.md) | Team Protocols | *Same request_id, two protocols* |
| [s11](./docs/en/s11-autonomous-agents.md) | Autonomous Agents | *Poll, claim, work, repeat* |
| [s12](./docs/en/s12-worktree-task-isolation.md) | Worktree + Task Isolation | *Isolate by directory, coordinate by task ID* |

## License

MIT

---

**The model is the agent. Our job is to give it tools and stay out of the way.**
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[microsoft/data-formulator]]></title>
            <link>https://github.com/microsoft/data-formulator</link>
            <guid>https://github.com/microsoft/data-formulator</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:30 GMT</pubDate>
            <description><![CDATA[ğŸª„ Create rich visualizations with AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/data-formulator">microsoft/data-formulator</a></h1>
            <p>ğŸª„ Create rich visualizations with AI</p>
            <p>Language: TypeScript</p>
            <p>Stars: 15,039</p>
            <p>Forks: 1,368</p>
            <p>Stars today: 89 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img src=&quot;./public/favicon.ico&quot; alt=&quot;Data Formulator icon&quot; width=&quot;28&quot;&gt;&amp;nbsp;
  Data Formulator: AI-powered Data Visualization
&lt;/h1&gt;


&lt;p align=&quot;center&quot;&gt;
  ğŸª„ Explore data with visualizations, powered by AI agents.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://data-formulator.ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/ğŸš€_Try_Online_Demo-data--formulator.ai-F59E0B?style=for-the-badge&quot; alt=&quot;Try Online Demo&quot;&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;#get-started&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/ğŸ’»_Install_Locally-pip_install-3776AB?style=for-the-badge&quot; alt=&quot;Install Locally&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://arxiv.org/abs/2408.16119&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Paper-arXiv:2408.16119-b31b1b.svg&quot; alt=&quot;arXiv&quot;&gt;&lt;/a&gt;&amp;ensp;
  &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-yellow.svg&quot; alt=&quot;License: MIT&quot;&gt;&lt;/a&gt;&amp;ensp;
  &lt;a href=&quot;https://www.youtube.com/watch?v=GfTE2FLyMrs&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/YouTube-white?logo=youtube&amp;logoColor=%23FF0000&quot; alt=&quot;YouTube&quot;&gt;&lt;/a&gt;&amp;ensp;
  &lt;a href=&quot;https://github.com/microsoft/data-formulator/actions/workflows/python-build.yml&quot;&gt;&lt;img src=&quot;https://github.com/microsoft/data-formulator/actions/workflows/python-build.yml/badge.svg&quot; alt=&quot;build&quot;&gt;&lt;/a&gt;&amp;ensp;
  &lt;a href=&quot;https://discord.gg/mYCZMQKYZb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/discord-chat-green?logo=discord&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;!-- [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/data-formulator?quickstart=1) --&gt;
&lt;!-- 
https://github.com/user-attachments/assets/8ca57b68-4d7a-42cb-bcce-43f8b1681ce2 --&gt;

&lt;kbd&gt;
  &lt;img src=&quot;public/data-formulator-screenshot-v0.5.png&quot;&gt;
&lt;/kbd&gt;


## News ğŸ”¥ğŸ”¥ğŸ”¥
[01-25-2025] **Data Formulator 0.6** â€” Real-time insights from live data
-  âš¡ **Connect to live data**: Connect to URLs and databases with automatic refresh intervals. Visualizations update automatically as your data changes to provide you live insights. [Demo: track international space station position speed live](https://github.com/microsoft/data-formulator/releases/tag/0.6)
-  ğŸ¨ **UI Updates**: Unified UI for data loading; direct drag-and-drop fields from the data table to update visualization designs.

[12-08-2025] **Data Formulator 0.5.1** â€” Connect more, visualize more, move faster
- ğŸ”Œ **Community data loaders**: Google BigQuery, MySQL, Postgres, MongoDB
- ğŸ“Š **New chart types**: US Map &amp; Pie Chart (more to be added soon)
- âœï¸ **Editable reports**: Refine generated reports with [Chartifact](https://github.com/microsoft/chartifact) in markdown style. [demo](https://github.com/microsoft/data-formulator/pull/200#issue-3635408217)
- âš¡ **Snappier UI**: Noticeably faster interactions across the board

[11-07-2025] Data Formulator 0.5: Vibe with your data, in control

- ğŸ“Š **Load (almost) any data**: load structured data, extract data from screenshots, from messy text blocks, or connect to databases.
- ğŸ¤– **Explore data with AI agents**: Use agent mode for hands-off exploration, or stay in control in interactive mode.
- âœ… **Verify AI generated results**: interact with charts and inspect data, formulas, explanations, and code.
- ğŸ“ **Create reports to share insights**: choose charts you want to share, and ask agents to create reports grounded in data formulated throughout exploration.

## Previous Updates

Here are milestones that lead to the current design:
- **v0.2.2** ([Demo](https://github.com/microsoft/data-formulator/pull/176)): Goal-driven exploration with agent recommendations and performance improvements
- **v0.2.1.3/4** ([Readme](https://github.com/microsoft/data-formulator/tree/main/py-src/data_formulator/data_loader) | [Demo](https://github.com/microsoft/data-formulator/pull/155)): External data loaders (MySQL, PostgreSQL, MSSQL, Azure Data Explorer, S3, Azure Blob)
- **v0.2** ([Demos](https://github.com/microsoft/data-formulator/releases/tag/0.2)): Large data support with DuckDB integration
- **v0.1.7** ([Demos](https://github.com/microsoft/data-formulator/releases/tag/0.1.7)): Dataset anchoring for cleaner workflows
- **v0.1.6** ([Demo](https://github.com/microsoft/data-formulator/releases/tag/0.1.6)): Multi-table support with automatic joins
- **Model Support**: OpenAI, Azure, Ollama, Anthropic via [LiteLLM](https://github.com/BerriAI/litellm) ([feedback](https://github.com/microsoft/data-formulator/issues/49))
- **Python Package**: Easy local installation ([try it](#get-started))
- **Visualization Challenges**: Test your skills ([challenges](https://github.com/microsoft/data-formulator/issues/53))
- **Data Extraction**: Parse data from images and text ([demo](https://github.com/microsoft/data-formulator/pull/31#issuecomment-2403652717))
- **Initial Release**: [Blog](https://www.microsoft.com/en-us/research/blog/data-formulator-exploring-how-ai-can-help-analysts-create-rich-data-visualizations/) | [Video](https://youtu.be/3ndlwt0Wi3c)

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;View detailed update history&lt;/b&gt;&lt;/summary&gt;

- [07-10-2025] Data Formulator 0.2.2: Start with an analysis goal
  - Some key frontend performance updates. 
  - You can start your exploration with a goal, or, tab and see if the agent can recommend some good exploration ideas for you. [Demo](https://github.com/microsoft/data-formulator/pull/176)

- [05-13-2025] Data Formulator 0.2.1.3/4: External Data Loader 
  - We introduced external data loader class to make import data easier. [Readme](https://github.com/microsoft/data-formulator/tree/main/py-src/data_formulator/data_loader) and [Demo](https://github.com/microsoft/data-formulator/pull/155)
    - Current data loaders: MySQL, Azure Data Explorer (Kusto), Azure Blob and Amazon S3 (json, parquet, csv).
    - [07-01-2025] Updated with: Postgresql, mssql.
  - Call for action [link](https://github.com/microsoft/data-formulator/issues/156):
    - Users: let us know which data source you&#039;d like to load data from.
    - Developers: let&#039;s build more data loaders.

- [04-23-2025] Data Formulator 0.2: working with *large* data ğŸ“¦ğŸ“¦ğŸ“¦
  - Explore large data by:
    1. Upload large data file to the local database (powered by [DuckDB](https://github.com/duckdb/duckdb)).
    2. Use drag-and-drop to specify charts, and Data Formulator dynamically fetches data from the database to create visualizations (with âš¡ï¸âš¡ï¸âš¡ï¸ speeds).
    3. Work with AI agents: they generate SQL queries to transform the data to create rich visualizations!
    4. Anchor the result / follow up / create a new branch / join tables; let&#039;s dive deeper. 
  - Checkout the demos at [[https://github.com/microsoft/data-formulator/releases/tag/0.2]](https://github.com/microsoft/data-formulator/releases/tag/0.2)
  - Improved overall system performance, and enjoy the updated derive concept functionality.

- [03-20-2025] Data Formulator 0.1.7: Anchoring âš“ï¸
  - Anchor an intermediate dataset, so that followup data analysis are built on top of the anchored data, not the original one.
  - Clean a data and work with only the cleaned data; create a subset from the original data or join multiple data, and then go from there. AI agents will be less likely to get confused and work faster. âš¡ï¸âš¡ï¸
  - Check out the demos at [[https://github.com/microsoft/data-formulator/releases/tag/0.1.7]](https://github.com/microsoft/data-formulator/releases/tag/0.1.7)
  - Don&#039;t forget to update Data Formulator to test it out!

- [02-20-2025] Data Formulator 0.1.6 released! 
  - Now supports working with multiple datasets at once! Tell Data Formulator which data tables you would like to use in the encoding shelf, and it will figure out how to join the tables to create a visualization to answer your question. ğŸª„
  - Checkout the demo at [[https://github.com/microsoft/data-formulator/releases/tag/0.1.6]](https://github.com/microsoft/data-formulator/releases/tag/0.1.6).
  - Update your Data Formulator to the latest version to play with the new features.

- [02-12-2025] More models supported now!
  - Now supports OpenAI, Azure, Ollama, and Anthropic models (and more powered by [LiteLLM](https://github.com/BerriAI/litellm));
  - Models with strong code generation and instruction following capabilities are recommended (gpt-4o, claude-3-5-sonnet etc.);
  - You can store API keys in `api-keys.env` to avoid typing them every time (see template `api-keys.env.template`).
  - Let us know which models you have good/bad experiences with, and what models you would like to see supported! [[comment here]](https://github.com/microsoft/data-formulator/issues/49)

- [11-07-2024] Minor fun update: data visualization challenges!
  - We added a few visualization challenges with the sample datasets. Can you complete them all? [[try them out!]](https://github.com/microsoft/data-formulator/issues/53#issue-2641841252)
  - Comment in the issue when you did, or share your results/questions with others! [[comment here]](https://github.com/microsoft/data-formulator/issues/53)

- [10-11-2024] Data Formulator python package released! 
  - You can now install Data Formulator using Python and run it locally, easily. [[check it out]](#get-started).
  - Our Codespaces configuration is also updated for fast start up âš¡ï¸. [[try it now!]](https://codespaces.new/microsoft/data-formulator?quickstart=1)
  - New experimental feature: load an image or a messy text, and ask AI to parse and clean it for you(!). [[demo]](https://github.com/microsoft/data-formulator/pull/31#issuecomment-2403652717)
  
- [10-01-2024] Initial release of Data Formulator, check out our [[blog]](https://www.microsoft.com/en-us/research/blog/data-formulator-exploring-how-ai-can-help-analysts-create-rich-data-visualizations/) and [[video]](https://youtu.be/3ndlwt0Wi3c)!

&lt;/details&gt;

## Overview

**Data Formulator** is a Microsoft Research prototype for data exploration with visualizations powered by AI agents.

Data Formulator enables analysts to iteratively explore and visualize data. Started with data in any format (screenshot, text, csv, or database), users can work with AI agents with a novel blended interface that combines *user interface interactions (UI)* and *natural language (NL) inputs* to communicate their intents, control branching exploration directions, and create reports to share their insights. 

## Get Started

Play with Data Formulator with one of the following options:

- **Option 1: Install via Python PIP**
  
  Use Python PIP for an easy setup experience, running locally (recommend: install it in a virtual environment).
  
  ```bash
  # install data_formulator
  pip install data_formulator

  # Run data formulator with this command
  python -m data_formulator
  ```

  Data Formulator will be automatically opened in the browser at [http://localhost:5000](http://localhost:5000).

  *you can specify the port number (e.g., 8080) by `python -m data_formulator --port 8080` if the default port is occupied.*

- **Option 2: Codespaces (5 minutes)**
  
  You can also run Data Formulator in Codespaces; we have everything pre-configured. For more details, see [CODESPACES.md](CODESPACES.md).
  
  [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/data-formulator?quickstart=1)

- **Option 3: Working in the developer mode**
  
  You can build Data Formulator locally if you prefer full control over your development environment and develop your own version on top. For detailed instructions, refer to [DEVELOPMENT.md](DEVELOPMENT.md).


## Using Data Formulator

### Load Data

Besides uploading csv, tsv or xlsx files that contain structured data, you can ask Data Formulator to extract data from screenshots, text blocks or websites, or load data from databases use connectors. Then you are ready to explore.

&lt;img width=&quot;1920&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/e23cdb47-984c-4ce4-a014-8f36e025e393&quot; /&gt;

### Explore Data

There are four levels to explore data based depending on whether you want more vibe or more control:

- Level 1 (most control): Create charts with UI via drag-and-drop, if all fields to be visualized are already in the data.
- Level 2: Specify chart designs with natural language + NL. Describe how new fields should be visualized in your chart, AI will automatically transform data to realize the design.
- Level 3: Get recommendations: Ask AI agents to recommend charts directly from NL descriptions, or even directly ask for exploration ideas.
- Level 4 (most vibe): In agent mode, provide a high-level goal and let AI agents automatically plan and explore data in multiple turns. Exploration threads will be created automatically.

https://github.com/user-attachments/assets/164aff58-9f93-4792-b8ed-9944578fbb72

- Level 5: In practice, leverage all of them to keep up with both vibe and control!

### Create Reports

Use the report builder to compose a report of the style you like, based on selected charts. Then share the reports to others!

&lt;!-- 
### The basics of data visualization
* Set up model provider, for agentic experience, model with reasoning and strong code generation ablity is recommended.
* Describe the exploration 

https://github.com/user-attachments/assets/0fbea012-1d2d-46c3-a923-b1fc5eb5e5b8


### Create visualization beyond the initial dataset (powered by ğŸ¤–)
* You can type names of **fields that do not exist in current data** in the encoding shelf:
    - this tells Data Formulator that you want to create visualizations that require computation or transformation from existing data,
    - you can optionally provide a natural language prompt to explain and clarify your intent (not necessary when field names are self-explanatory).
* Click the **Formulate** button.
    - Data Formulator will transform data and instantiate the visualization based on the encoding and prompt.
* Inspect the data, chart and code.
* To create a new chart based on existing ones, follow up in natural language:
    - provide a follow up prompt (e.g., *``show only top 5!&#039;&#039;*),
    - you may also update visual encodings for the new chart.

https://github.com/user-attachments/assets/160c69d2-f42d-435c-9ff3-b1229b5bddba

https://github.com/user-attachments/assets/c93b3e84-8ca8-49ae-80ea-f91ceef34acb

Repeat this process as needed to explore and understand your data. Your explorations are trackable in the **Data Threads** panel.  --&gt;

## Developers&#039; Guide

Follow the [developers&#039; instructions](DEVELOPMENT.md) to build your new data analysis tools on top of Data Formulator.

Help wanted:

* Add more database connectors (https://github.com/microsoft/data-formulator/issues/156)
* Scaling up messy data extractor: more document types and larger files.
* Adding more chart templates (e.g., maps).
* other ideas?

## Research Papers
* [Data Formulator 2: Iteratively Creating Rich Visualizations with AI](https://arxiv.org/abs/2408.16119)

```
@article{wang2024dataformulator2iteratively,
      title={Data Formulator 2: Iteratively Creating Rich Visualizations with AI}, 
      author={Chenglong Wang and Bongshin Lee and Steven Drucker and Dan Marshall and Jianfeng Gao},
      year={2024},
      booktitle={ArXiv preprint arXiv:2408.16119},
}
```

* [Data Formulator: AI-powered Concept-driven Visualization Authoring](https://arxiv.org/abs/2309.10094)

```
@article{wang2023data,
  title={Data Formulator: AI-powered Concept-driven Visualization Authoring},
  author={Wang, Chenglong and Thompson, John and Lee, Bongshin},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2023},
  publisher={IEEE}
}
```


## Contributing

This project welcomes contributions and suggestions. Most contributions require you to
agree to a Contributor License Agreement (CLA) declaring that you have the right to,
and actually do, grant us the rights to use your contribution. For details, visit
https://cla.microsoft.com.

When you submit a pull request, a CLA-bot will automatically determine whether you need
to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the
instructions provided by the bot. You will only need to do this once across all repositories using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)
or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft 
trademarks or logos is subject to and must follow 
[Microsoft&#039;s Trademark &amp; Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party&#039;s policies.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[InsForge/InsForge]]></title>
            <link>https://github.com/InsForge/InsForge</link>
            <guid>https://github.com/InsForge/InsForge</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:29 GMT</pubDate>
            <description><![CDATA[AI-native backend platforms, turn coding agents into fullstack builders.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/InsForge/InsForge">InsForge/InsForge</a></h1>
            <p>AI-native backend platforms, turn coding agents into fullstack builders.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,510</p>
            <p>Forks: 215</p>
            <p>Stars today: 65 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://insforge.dev&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/logo-dark.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/logo-light.svg&quot;&gt;
      &lt;img src=&quot;assets/logo-dark.svg&quot; alt=&quot;InsForge&quot; width=&quot;500&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;

  &lt;p&gt;
    The backend built for agentic coding.&lt;br /&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-orange.svg&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.npmjs.com/package/@insforge/sdk&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dt/@insforge/sdk?color=blue&amp;label=downloads&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/InsForge/insforge/graphs/contributors&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/InsForge/insforge?color=green&quot; alt=&quot;Contributors&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://cursor.com/link/prompt?text=Help+me+set+up+InsForge+locally.+Follow+these+steps%3A%0A%0A1.+First%2C+verify+Docker+is+installed+and+running%3A%0A+++docker+--version%0A+++docker+info%0A%0A2.+Clone+the+repository%3A%0A+++git+clone+https%3A%2F%2Fgithub.com%2Finsforge%2Finsforge.git%0A+++cd+insforge%0A%0A3.+Copy+the+example+env+config+and+start+services%3A%0A+++cp+env.example+to+env+file%0A+++docker+compose+up+-d%0A%0A4.+Wait+for+all+containers+to+be+healthy+(this+may+take+1-2+minutes)%3A%0A+++docker+compose+ps%0A%0A5.+Verify+the+app+is+accessible+at+http%3A%2F%2Flocalhost%3A7131%0A%0A6.+Follow+the+steps+in+the+dashboard+to+connect+InsForge+MCP+Server+to+your+agent.%0A%0AIf+there+are+any+errors%2C+help+me+troubleshoot+them.+Common+issues%3A%0A-+Docker+not+running%0A-+Ports+already+in+use%0A-+Insufficient+memory&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Set%20Up%20with-Cursor-181818?logo=cursor&amp;logoColor=white&amp;labelColor=555555&quot; alt=&quot;Set Up With Cursor&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://insforge.dev&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Visit-InsForge.dev-181818?logoColor=white&amp;labelColor=555555&amp;logo=data:image/svg%2bxml;base64,PHN2ZyB3aWR0aD0iMjQwIiBoZWlnaHQ9IjI0MCIgdmlld0JveD0iMCAwIDI0MCAyNDAiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PHBhdGggZD0iTTI2LjExODQgMTAxLjZDMjMuMjkzOSA5OC43ODMzIDIzLjI5MzkgOTQuMjE2NiAyNi4xMTg0IDkxLjRMOTcuNzE2NyAyMEwyMDAgMjBMNzcuMjYgMTQyLjRDNzQuNDM1NSAxNDUuMjE3IDY5Ljg1NjIgMTQ1LjIxNyA2Ny4wMzE3IDE0Mi40TDI2LjExODQgMTAxLjZaIiBmaWxsPSJ3aGl0ZSIvPjxwYXRoIGQ9Ik0xNTUuMjUxIDc3LjM3NUwyMDAgMTIyVjIyNEwxMDQuMTA5IDEyOC4zNzVMMTU1LjI1MSA3Ny4zNzVaIiBmaWxsPSJ3aGl0ZSIvPjwvc3ZnPgo=&quot; alt=&quot;Visit InsForge.dev&quot;&gt;&lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
    &lt;a href=&quot;https://x.com/InsForge_dev&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Follow%20on%20X-000000?logo=x&amp;logoColor=white&amp;style=for-the-badge&quot; alt=&quot;Follow on X&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/insforge&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Follow%20on%20LinkedIn-0A66C2?logo=linkedin&amp;logoColor=white&amp;style=for-the-badge&quot; alt=&quot;Follow on LinkedIn&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.com/invite/MPxwj5xVvW&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Join%20our%20Discord-5865F2?logo=discord&amp;logoColor=white&amp;style=for-the-badge&quot; alt=&quot;Join our Discord&quot;&gt;&lt;/a&gt;
  &lt;/p&gt;
  &lt;a href=&quot;https://vercel.com/oss&quot;&gt;
    &lt;img alt=&quot;Vercel OSS Program&quot; src=&quot;https://vercel.com/oss/program-badge.svg&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

## InsForge
InsForge is a backend development platform built for AI coding agents and AI code editors. It exposes backend primitives like databases, auth, storage, and functions through a semantic layer that agents can understand, reason about, and operate end to end.

&lt;p align=&quot;center&quot;&gt;
  &lt;video width=&quot;100%&quot; src=&quot;https://github.com/user-attachments/assets/e4362de8-ab46-4792-8499-4f1eec42a097&quot; controls&gt;&lt;/video&gt;
&lt;/p&gt;

### How it works
InsForge acts as a semantic layer between AI coding agents and backend primitives. It performs backend context engineering so agents can understand, operate, and inspect backend systems.

- **Fetch backend context**: Agents can fetch documentation and available operations for the backend primitives they use.
- **Configure primitives**: Agents can configure backend primitives directly.
- **Inspect backend state**: Backend state and logs are exposed through structured schemas.

```mermaid
graph TB

    subgraph TOP[&quot; &quot;]
        AG[AI Coding Agents]
    end

    subgraph MID[&quot; &quot;]
        SL[InsForge Semantic Layer]
    end

    AG --&gt; SL

    SL --&gt; AUTH[Authentication]
    SL --&gt; DB[Database]
    SL --&gt; ST[Storage]
    SL --&gt; EF[Edge Functions]
    SL --&gt; MG[Model Gateway]
    SL --&gt; DEP[Deployment]

    classDef bar fill:#0b0f14,stroke:#30363d,stroke-width:1px,color:#ffffff
    classDef card fill:#161b22,stroke:#30363d,stroke-width:1px,color:#ffffff

    class AG,SL bar
    class AUTH,DB,ST,EF,MG,DEP card

    style TOP fill:transparent,stroke:transparent
    style MID fill:transparent,stroke:transparent

    linkStyle default stroke:#30363d,stroke-width:1px
```

### Core Products:
- **Authentication**: User management, authentication, and sessions
- **Database**: Postgres relational database
- **Storage**: S3 compatible file storage
- **Model Gateway**: OpenAI compatible API across multiple LLM providers
- **Edge Functions**: Serverless code running on the edge
- **Site Deployment**: Site build and deployment


## â­ï¸ Star the Repository

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/insforge-star.gif&quot; alt=&quot;Star InsForge&quot; width=&quot;100%&quot;&gt;
&lt;/p&gt;

If you find InsForge useful or interesting, a GitHub Star â­ï¸ would be greatly appreciated.

## Quickstart

### Cloud-hosted: [insforge.dev](https://insforge.dev)

&lt;a href=&quot;https://insforge.dev&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/insforge.dev-181818?logo=data:image/svg%2bxml;base64,PHN2ZyB3aWR0aD0iMjQwIiBoZWlnaHQ9IjI0MCIgdmlld0JveD0iMCAwIDI0MCAyNDAiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PHBhdGggZD0iTTI2LjExODQgMTAxLjZDMjMuMjkzOSA5OC43ODMzIDIzLjI5MzkgOTQuMjE2NiAyNi4xMTg0IDkxLjRMOTcuNzE2NyAyMEwyMDAgMjBMNzcuMjYgMTQyLjRDNzQuNDM1NSAxNDUuMjE3IDY5Ljg1NjIgMTQ1LjIxNyA2Ny4wMzE3IDE0Mi40TDI2LjExODQgMTAxLjZaIiBmaWxsPSJ3aGl0ZSIvPjxwYXRoIGQ9Ik0xNTUuMjUxIDc3LjM3NUwyMDAgMTIyVjIyNEwxMDQuMTA5IDEyOC4zNzVMMTU1LjI1MSA3Ny4zNzVaIiBmaWxsPSJ3aGl0ZSIvPjwvc3ZnPgo=&amp;logoColor=white&quot; alt=&quot;InsForge.dev&quot;&gt;&lt;/a&gt;

### Self-hosted: Docker Compose

Prerequisites: [Docker](https://www.docker.com/) + [Node.js](https://nodejs.org/)

#### 1. Setup

You can run InsForge locally using Docker Compose. This will start a local InsForge instance on your machine.

[![Deploy on Docker][docker-btn]][docker-deploy]

Or run from source:
```bash
# Run with Docker
git clone https://github.com/insforge/insforge.git
cd insforge
cp .env.example .env
docker compose -f docker-compose.prod.yml up
```

#### 2. Connect InsForge MCP

Open [http://localhost:7130](http://localhost:7130)

Follow the steps to connect InsForge MCP Server

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/connect.png&quot; alt=&quot;Connect InsForge MCP&quot; width=&quot;600&quot;&gt;
&lt;/div&gt;

#### 3. Verify installation

To verify the connection, send the following prompt to your agent:
```
I&#039;m using InsForge as my backend platform, call InsForge MCP&#039;s fetch-docs tool to learn about InsForge instructions.
```

### One-click Deployment

In addition to running InsForge locally, you can also launch InsForge using a pre-configured setup. This allows you to get up and running quickly with InsForge without installing Docker on your local machine.

| Railway | Zeabur | Sealos (coming soon) |
| --- | --- | --- |
| [![Deploy on Railway](https://railway.com/button.svg)](https://railway.com/deploy/insforge) | [![Deploy on Zeabur](https://zeabur.com/button.svg)](https://zeabur.com/templates/Q82M3Y) | [![Deploy on Sealos](https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg)](https://template.hzh.sealos.run/deploy?templateName=insforge) |


## Contributing

**Contributing**: If you&#039;re interested in contributing, you can check our guide here [CONTRIBUTING.md](CONTRIBUTING.md). We truly appreciate pull requests, all types of help are appreciated!

**Support**: If you need any help or support, we&#039;re responsive on our [Discord channel](https://discord.com/invite/MPxwj5xVvW), and also feel free to email us [info@insforge.dev](mailto:info@insforge.dev) too!


## Documentation &amp; Support

### Documentation
- **[Official Docs](https://docs.insforge.dev/introduction)** - Comprehensive guides and API references

### Community
- **[Discord](https://discord.com/invite/MPxwj5xVvW)** - Join our vibrant community
- **[Twitter](https://x.com/InsForge_dev)** - Follow for updates and tips

### Contact
- **Email**: info@insforge.dev

## License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

---

[![Star History Chart](https://api.star-history.com/svg?repos=InsForge/insforge&amp;type=Date)](https://www.star-history.com/#InsForge/insforge&amp;Date)

## Badges

Show your project is built with InsForge.

### Made with InsForge

&lt;a href=&quot;https://insforge.dev&quot;&gt;
  &lt;img
    width=&quot;168&quot;
    height=&quot;30&quot;
    src=&quot;https://insforge.dev/badge-made-with-insforge.svg&quot;
    alt=&quot;Made with InsForge&quot;
  /&gt;
&lt;/a&gt;

**Markdown:**
```md
[![Made with InsForge](https://insforge.dev/badge-made-with-insforge.svg)](https://insforge.dev)
```

**HTML:**
```html
&lt;a href=&quot;https://insforge.dev&quot;&gt;
  &lt;img
    width=&quot;168&quot;
    height=&quot;30&quot;
    src=&quot;https://insforge.dev/badge-made-with-insforge.svg&quot;
    alt=&quot;Made with InsForge&quot;
  /&gt;
&lt;/a&gt;
```

### Made with InsForge (dark)

&lt;a href=&quot;https://insforge.dev&quot;&gt;
  &lt;img
    width=&quot;168&quot;
    height=&quot;30&quot;
    src=&quot;https://insforge.dev/badge-made-with-insforge-dark.svg&quot;
    alt=&quot;Made with InsForge&quot;
  /&gt;
&lt;/a&gt;

**Markdown:**
```md
[![Made with InsForge](https://insforge.dev/badge-made-with-insforge-dark.svg)](https://insforge.dev)
```

**HTML:**
```html
&lt;a href=&quot;https://insforge.dev&quot;&gt;
  &lt;img
    width=&quot;168&quot;
    height=&quot;30&quot;
    src=&quot;https://insforge.dev/badge-made-with-insforge-dark.svg&quot;
    alt=&quot;Made with InsForge&quot;
  /&gt;
&lt;/a&gt;
```

## Translations

- [Arabic | Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](/i18n/README.ar.md)
- [Spanish | EspaÃ±ol](/i18n/README.es.md)
- [French | FranÃ§ais](/i18n/README.fr.md)
- [Hindi | à¤¹à¤¿à¤‚à¤¦à¥€](/i18n/README.hi.md)
- [Japanese | æ—¥æœ¬èª](/i18n/README.ja.md)
- [Korean | í•œêµ­ì–´](/i18n/README.ko.md)
- [Portuguese (Brazilian) / PortuguÃªs Brasileiro](/i18n/README.pt-BR.md)
- [Russian | Ğ ÑƒÑÑĞºĞ¸Ğ¹](/i18n/README.ru.md)
- [Chinese (Simplified) | ç®€ä½“ä¸­æ–‡](/i18n/README.zh-CN.md)

---

&lt;p align=&quot;center&quot;&gt;â­ &lt;b&gt;Star us on GitHub&lt;/b&gt; to get notified about new releases!&lt;/p&gt;

&lt;!-- LINK GROUPS --&gt;

[docker-btn]: ./deploy/buttons/docker.png
[docker-deploy]: ./deploy/docker-deploy.md</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[immich-app/immich]]></title>
            <link>https://github.com/immich-app/immich</link>
            <guid>https://github.com/immich-app/immich</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:28 GMT</pubDate>
            <description><![CDATA[High performance self-hosted photo and video management solution.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/immich-app/immich">immich-app/immich</a></h1>
            <p>High performance self-hosted photo and video management solution.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 93,339</p>
            <p>Forks: 4,957</p>
            <p>Stars today: 126 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt; 
  &lt;br/&gt;
  &lt;a href=&quot;https://opensource.org/license/agpl-v3&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-AGPL_v3-blue.svg?color=3F51B5&amp;style=for-the-badge&amp;label=License&amp;logoColor=000000&amp;labelColor=ececec&quot; alt=&quot;License: AGPLv3&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.immich.app&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/979116623879368755.svg?label=Discord&amp;logo=Discord&amp;style=for-the-badge&amp;logoColor=000000&amp;labelColor=ececec&quot; alt=&quot;Discord&quot;/&gt;
  &lt;/a&gt;
  &lt;br/&gt;
  &lt;br/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;design/immich-logo-stacked-light.svg&quot; width=&quot;300&quot; title=&quot;Login With Custom URL&quot;&gt;
&lt;/p&gt;
&lt;h3 align=&quot;center&quot;&gt;High performance self-hosted photo and video management solution&lt;/h3&gt;
&lt;br/&gt;
&lt;a href=&quot;https://immich.app&quot;&gt;
&lt;img src=&quot;design/immich-screenshots.png&quot; title=&quot;Main Screenshot&quot;&gt;
&lt;/a&gt;
&lt;br/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;readme_i18n/README_ca_ES.md&quot;&gt;CatalÃ &lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_es_ES.md&quot;&gt;EspaÃ±ol&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_fr_FR.md&quot;&gt;FranÃ§ais&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_it_IT.md&quot;&gt;Italiano&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ja_JP.md&quot;&gt;æ—¥æœ¬èª&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ko_KR.md&quot;&gt;í•œêµ­ì–´&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_de_DE.md&quot;&gt;Deutsch&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_nl_NL.md&quot;&gt;Nederlands&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_tr_TR.md&quot;&gt;TÃ¼rkÃ§e&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_zh_CN.md&quot;&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_zh_TW.md&quot;&gt;æ­£é«”ä¸­æ–‡&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_uk_UA.md&quot;&gt;Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ru_RU.md&quot;&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_pt_BR.md&quot;&gt;PortuguÃªs Brasileiro&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_sv_SE.md&quot;&gt;Svenska&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ar_JO.md&quot;&gt;Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_vi_VN.md&quot;&gt;Tiáº¿ng Viá»‡t&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_th_TH.md&quot;&gt;à¸ à¸²à¸©à¸²à¹„à¸—à¸¢&lt;/a&gt;
&lt;/p&gt;


&gt; [!WARNING]
&gt; âš ï¸ Always follow [3-2-1](https://www.backblaze.com/blog/the-3-2-1-backup-strategy/) backup plan for your precious photos and videos!
&gt; 
 

&gt; [!NOTE]
&gt; You can find the main documentation, including installation guides, at https://immich.app/.

## Links

- [Documentation](https://docs.immich.app/)
- [About](https://docs.immich.app/overview/introduction)
- [Installation](https://docs.immich.app/install/requirements)
- [Roadmap](https://immich.app/roadmap)
- [Demo](#demo)
- [Features](#features)
- [Translations](https://docs.immich.app/developer/translations)
- [Contributing](https://docs.immich.app/overview/support-the-project)

## Demo

Access the demo [here](https://demo.immich.app). For the mobile app, you can use `https://demo.immich.app` for the `Server Endpoint URL`.

### Login credentials

| Email           | Password |
| --------------- | -------- |
| demo@immich.app | demo     |

## Features

| Features                                     | Mobile | Web |
| :------------------------------------------- | ------ | --- |
| Upload and view videos and photos            | Yes    | Yes |
| Auto backup when the app is opened           | Yes    | N/A |
| Prevent duplication of assets                | Yes    | Yes |
| Selective album(s) for backup                | Yes    | N/A |
| Download photos and videos to local device   | Yes    | Yes |
| Multi-user support                           | Yes    | Yes |
| Album and Shared albums                      | Yes    | Yes |
| Scrubbable/draggable scrollbar               | Yes    | Yes |
| Support raw formats                          | Yes    | Yes |
| Metadata view (EXIF, map)                    | Yes    | Yes |
| Search by metadata, objects, faces, and CLIP | Yes    | Yes |
| Administrative functions (user management)   | No     | Yes |
| Background backup                            | Yes    | N/A |
| Virtual scroll                               | Yes    | Yes |
| OAuth support                                | Yes    | Yes |
| API Keys                                     | N/A    | Yes |
| LivePhoto/MotionPhoto backup and playback    | Yes    | Yes |
| Support 360 degree image display             | No     | Yes |
| User-defined storage structure               | Yes    | Yes |
| Public Sharing                               | Yes    | Yes |
| Archive and Favorites                        | Yes    | Yes |
| Global Map                                   | Yes    | Yes |
| Partner Sharing                              | Yes    | Yes |
| Facial recognition and clustering            | Yes    | Yes |
| Memories (x years ago)                       | Yes    | Yes |
| Offline support                              | Yes    | No  |
| Read-only gallery                            | Yes    | Yes |
| Stacked Photos                               | Yes    | Yes |
| Tags                                         | No     | Yes |
| Folder View                                  | Yes    | Yes |

## Translations

Read more about translations [here](https://docs.immich.app/developer/translations).

&lt;a href=&quot;https://hosted.weblate.org/engage/immich/&quot;&gt;
&lt;img src=&quot;https://hosted.weblate.org/widget/immich/immich/multi-auto.svg&quot; alt=&quot;Translation status&quot; /&gt;
&lt;/a&gt;

## Repository activity

![Activities](https://repobeats.axiom.co/api/embed/9e86d9dc3ddd137161f2f6d2e758d7863b1789cb.svg &quot;Repobeats analytics image&quot;)

## Star history

&lt;a href=&quot;https://star-history.com/#immich-app/immich&amp;type=date&amp;legend=top-left&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=immich-app/immich&amp;type=date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=immich-app/immich&amp;type=date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=immich-app/immich&amp;type=date&quot; width=&quot;100%&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## Contributors

&lt;a href=&quot;https://github.com/immich-app/immich/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=immich-app/immich&quot; width=&quot;100%&quot;/&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[honojs/hono]]></title>
            <link>https://github.com/honojs/hono</link>
            <guid>https://github.com/honojs/hono</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:27 GMT</pubDate>
            <description><![CDATA[Web framework built on Web Standards]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/honojs/hono">honojs/hono</a></h1>
            <p>Web framework built on Web Standards</p>
            <p>Language: TypeScript</p>
            <p>Stars: 28,976</p>
            <p>Forks: 945</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://hono.dev&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/honojs/hono/main/docs/images/hono-title.png&quot; width=&quot;500&quot; height=&quot;auto&quot; alt=&quot;Hono&quot;/&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;hr /&gt;

[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/honojs/hono/ci.yml?branch=main)](https://github.com/honojs/hono/actions)
[![GitHub](https://img.shields.io/github/license/honojs/hono)](https://github.com/honojs/hono/blob/main/LICENSE)
[![npm](https://img.shields.io/npm/v/hono)](https://www.npmjs.com/package/hono)
[![npm](https://img.shields.io/npm/dm/hono)](https://www.npmjs.com/package/hono)
[![JSR](https://jsr.io/badges/@hono/hono)](https://jsr.io/@hono/hono)
[![Bundle Size](https://img.shields.io/bundlephobia/min/hono)](https://bundlephobia.com/result?p=hono)
[![Bundle Size](https://img.shields.io/bundlephobia/minzip/hono)](https://bundlephobia.com/result?p=hono)
[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/honojs/hono)](https://github.com/honojs/hono/pulse)
[![GitHub last commit](https://img.shields.io/github/last-commit/honojs/hono)](https://github.com/honojs/hono/commits/main)
[![codecov](https://codecov.io/github/honojs/hono/graph/badge.svg)](https://codecov.io/github/honojs/hono)
[![Discord badge](https://img.shields.io/discord/1011308539819597844?label=Discord&amp;logo=Discord)](https://discord.gg/KMh2eNSdxV)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/honojs/hono)

Hono - _**means flameğŸ”¥ in Japanese**_ - is a small, simple, and ultrafast web framework built on Web Standards. It works on any JavaScript runtime: Cloudflare Workers, Fastly Compute, Deno, Bun, Vercel, AWS Lambda, Lambda@Edge, and Node.js.

Fast, but not only fast.

```ts
import { Hono } from &#039;hono&#039;
const app = new Hono()

app.get(&#039;/&#039;, (c) =&gt; c.text(&#039;Hono!&#039;))

export default app
```

## Quick Start

```bash
npm create hono@latest
```

## Features

- **Ultrafast** ğŸš€ - The router `RegExpRouter` is really fast. Not using linear loops. Fast.
- **Lightweight** ğŸª¶ - The `hono/tiny` preset is under 12kB. Hono has zero dependencies and uses only the Web Standard API.
- **Multi-runtime** ğŸŒ - Works on Cloudflare Workers, Fastly Compute, Deno, Bun, AWS Lambda, Lambda@Edge, or Node.js. The same code runs on all platforms.
- **Batteries Included** ğŸ”‹ - Hono has built-in middleware, custom middleware, and third-party middleware. Batteries included.
- **Delightful DX** ğŸ˜ƒ - Super clean APIs. First-class TypeScript support. Now, we&#039;ve got &quot;Types&quot;.

## Documentation

The documentation is available on [hono.dev](https://hono.dev).

## Migration

The migration guide is available on [docs/MIGRATION.md](docs/MIGRATION.md).

## Communication

[X](https://x.com/honojs) and [Discord channel](https://discord.gg/KMh2eNSdxV) are available.

## Contributing

Contributions Welcome! You can contribute in the following ways.

- Create an Issue - Propose a new feature. Report a bug.
- Pull Request - Fix a bug or typo. Refactor the code.
- Create third-party middleware - See instructions below.
- Share - Share your thoughts on the Blog, X, and others.
- Make your application - Please try to use Hono.

For more details, see [docs/CONTRIBUTING.md](docs/CONTRIBUTING.md).

## Contributors

Thanks to [all contributors](https://github.com/honojs/hono/graphs/contributors)!

## Authors

Yusuke Wada &lt;https://github.com/yusukebe&gt;

_RegExpRouter_, _SmartRouter_, _LinearRouter_, and _PatternRouter_ are created by Taku Amano &lt;https://github.com/usualoma&gt;

## License

Distributed under the MIT License. See [LICENSE](LICENSE) for more information.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lobehub/lobehub]]></title>
            <link>https://github.com/lobehub/lobehub</link>
            <guid>https://github.com/lobehub/lobehub</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:26 GMT</pubDate>
            <description><![CDATA[The ultimate space for work and life â€” to find, build, and collaborate with agent teammates that grow with you. We are taking agent harness to the next level â€” enabling multi-agent collaboration, effortless agent team design, and introducing agents as the unit of work interaction.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobehub">lobehub/lobehub</a></h1>
            <p>The ultimate space for work and life â€” to find, build, and collaborate with agent teammates that grow with you. We are taking agent harness to the next level â€” enabling multi-agent collaboration, effortless agent team design, and introducing agents as the unit of work interaction.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 72,546</p>
            <p>Forks: 14,665</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# LobeHub

LobeHub is the ultimate space for work and life: &lt;br/&gt;
to find, build, and collaborate with agent teammates that grow with you.&lt;br/&gt;
Weâ€™re building the worldâ€™s largest humanâ€“agent co-evolving network.

**English** Â· [ç®€ä½“ä¸­æ–‡](./README.zh-CN.md) Â· [Official Site][official-site] Â· [Changelog][changelog] Â· [Documents][docs] Â· [Blog][blog] Â· [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeHub Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Agent teammates that grow with you&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url]

[![](https://vercel.com/oss/program-badge.svg)](https://vercel.com/oss)

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [ğŸ‘‹ğŸ» Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [âœ¨ Features](#-features)
  - [Create: Agents as the Unit of Work](#create-agents-as-the-unit-of-work)
  - [Collaborate: Scale New Forms of Collaboration Networks](#collaborate-scale-new-forms-of-collaboration-networks)
  - [Evolve: Co-evolution of Humans and Agents](#evolve-co-evolution-of-humans-and-agents)
  - [MCP Plugin One-Click Installation](#mcp-plugin-one-click-installation)
  - [MCP Marketplace](#mcp-marketplace)
  - [Desktop App](#desktop-app)
  - [Smart Internet Search](#smart-internet-search)
  - [Chain of Thought](#chain-of-thought)
  - [Branching Conversations](#branching-conversations)
  - [Artifacts Support](#artifacts-support)
  - [File Upload /Knowledge Base](#file-upload-knowledge-base)
  - [Multi-Model Service Provider Support](#multi-model-service-provider-support)
  - [Local Large Language Model (LLM) Support](#local-large-language-model-llm-support)
  - [Model Visual Recognition](#model-visual-recognition)
  - [TTS &amp; STT Voice Conversation](#tts--stt-voice-conversation)
  - [Text to Image Generation](#text-to-image-generation)
  - [Plugin System (Function Calling)](#plugin-system-function-calling)
  - [Agent Market (GPTs)](#agent-market-gpts)
  - [Support Local / Remote Database](#support-local--remote-database)
  - [Support Multi-User Management](#support-multi-user-management)
  - [Progressive Web App (PWA)](#progressive-web-app-pwa)
  - [Mobile Device Adaptation](#mobile-device-adaptation)
  - [Custom Themes](#custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [ğŸ›³ Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [ğŸ“¦ Ecosystem](#-ecosystem)
- [ğŸ§© Plugins](#-plugins)
- [âŒ¨ï¸ Local Development](#ï¸-local-development)
- [ğŸ¤ Contributing](#-contributing)
- [â¤ï¸ Sponsor](#ï¸-sponsor)
- [ğŸ”— More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

&lt;br/&gt;

&lt;https://github.com/user-attachments/assets/6710ad97-03d0-4175-bd75-adff9b55eca2&gt;

## ğŸ‘‹ğŸ» Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeHub is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![](https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=1065874&amp;theme=light&amp;t=1769347414733)](https://www.producthunt.com/products/lobehub?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_campaign=badge-lobehub) | We are live on Product Hunt! We are thrilled to bring LobeHub to the world. If you believe in a future where humans and agents co-evolve, please support our journey. |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link]                                                                                                                                                                                                         | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub.                                                    |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ â­ï¸

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## âœ¨ Features

Todayâ€™s agents are one-off, task-driven tools. They lack context, live in isolation, and require manual hand-offs between different windows and models. While some maintain memory, it is often global, shallow, and impersonal. In this mode, users are forced to toggle between fragmented conversations, making it difficult to form structured productivity.

**LobeHub changes everything.**

LobeHub is a work-and-lifestyle space to find, build, and collaborate with agent teammates that grow with you. In LobeHub, we treat **Agents as the unit of work**, providing an infrastructure where humans and agents co-evolve.

![](https://hub-apac-1.lobeobjects.space/blog/assets/2204cde2228fb3f583f3f2c090bc49fb.webp)

### Create: Agents as the Unit of Work

Building a personalized AI team starts with the **Agent Builder**. You can describe what you need once, and the agent setup starts right away, applying auto-configurations so you can use it instantly.

- **Unified Intelligence**: Seamlessly access any model and any modalityâ€”all under your control.
- **10,000+ Skills**: Connect your agents to the skills you use every day with a library of over 10,000 tools and MCP-compatible plugins.

[![][back-to-top]](#readme-top)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

![](https://hub-apac-1.lobeobjects.space/blog/assets/771ff3d30b9ef93e65e55021cc43d356.webp)

### Collaborate: Scale New Forms of Collaboration Networks

LobeHub introduces **Agent Groups**, allowing you to work with agents like real teammates. The system assembles the right agents for the task, enabling parallel collaboration and iterative improvement.

- **Pages**: Write and refine content with multiple agents in one place with a shared context.
- **Schedule**: Schedule runs and let agents do the work at the right time, even while you are away.
- **Project**: Organize work by project to keep everything structured and easy to track.
- **Workspace**: A shared space for teams to collaborate with agents, ensuring clear ownership and visibility across the organization.

[![][back-to-top]](#readme-top)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

![](https://hub-apac-1.lobeobjects.space/blog/assets/fe98eae9fcb6acc47c8e1fb69bdb4b50.webp)

### Evolve: Co-evolution of Humans and Agents

The best AI is one that understands you deeply. LobeHub features **Personal Memory** that builds a clear understanding of your needs.

- **Continual Learning**: Your agents learn from how you work, adapting their behavior to act at the right moment.
- **White-Box Memory**: We believe in transparency. Your agents use structured, editable memory, giving you full control over what they remember.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;More Features&lt;/summary&gt;

![][image-feat-mcp]

### MCP Plugin One-Click Installation

**Seamlessly Connect Your AI to the World**

Unlock the full potential of your AI by enabling smooth, secure, and dynamic interactions with external tools, data sources, and services. LobeHub&#039;s MCP (Model Context Protocol) plugin system breaks down the barriers between your AI and the digital ecosystem, allowing for unprecedented connectivity and functionality.

Transform your conversations into powerful workflows by connecting to databases, APIs, file systems, and more. Experience the freedom of AI that truly understands and interacts with your world.

[![][back-to-top]](#readme-top)

![][image-feat-mcp-market]

### MCP Marketplace

**Discover, Connect, Extend**

Browse a growing library of MCP plugins to expand your AI&#039;s capabilities and streamline your workflows effortlessly. Visit [lobehub.com/mcp](https://lobehub.com/mcp) to explore the MCP Marketplace, which offers a curated collection of integrations that enhance your AI&#039;s ability to work with various tools and services.

From productivity tools to development environments, discover new ways to extend your AI&#039;s reach and effectiveness. Connect with the community and find the perfect plugins for your specific needs.

[![][back-to-top]](#readme-top)

![][image-feat-desktop]

### Desktop App

**Peak Performance, Zero Distractions**

Get the full LobeHub experience without browser limitationsâ€”comprehensive, focused, and always ready to go. Our desktop application provides a dedicated environment for your AI interactions, ensuring optimal performance and minimal distractions.

Experience faster response times, better resource management, and a more stable connection to your AI assistant. The desktop app is designed for users who demand the best performance from their AI tools.

[![][back-to-top]](#readme-top)

![][image-feat-web-search]

### Smart Internet Search

**Online Knowledge On Demand**

With real-time internet access, your AI keeps up with the worldâ€”news, data, trends, and more. Stay informed and get the most current information available, enabling your AI to provide accurate and up-to-date responses.

Access live information, verify facts, and explore current events without leaving your conversation. Your AI becomes a gateway to the world&#039;s knowledge, always current and comprehensive.

[![][back-to-top]](#readme-top)

[![][image-feat-cot]][docs-feat-cot]

### [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeHub. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeHub supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [ğŸ“˜ LobeHub Knowledge Base Launch â€” From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeHub, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeHub can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+-10)&lt;/kbd&gt;&lt;/summary&gt;

&lt;/details&gt;

&gt; ğŸ“Š Total providers: [&lt;kbd&gt;**0**&lt;/kbd&gt;](https://lobechat.com/discover/providers)

 &lt;!-- PROVIDER LIST --&gt;

At the same time, we are also planning to support more model service providers. If you would like LobeHub to support your favorite service provider, feel free to join our [ğŸ’¬ community discussion](https://github.com/lobehub/lobe-chat/discussions/1284).

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-local]][docs-feat-local]

### [Local Large Language Model (LLM) Support][docs-feat-local]

To meet the specific needs of users, LobeHub also supports the use of local models based on [Ollama](https://ollama.ai), allowing users to flexibly use their own or third-party models.

&gt; \[!TIP]
&gt;
&gt; Learn more about [ğŸ“˜ Using Ollama in LobeHub][docs-usage-ollama] by checking it out.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-vision]][docs-feat-vision]

### [Model Visual Recognition][docs-feat-vision]

LobeHub now supports OpenAI&#039;s latest [`gpt-4-vision`](https://platform.openai.com/docs/guides/vision) model with visual recognition capabilities,
a multimodal intelligence that can perceive visuals. Users can easily upload or drag and drop images into the dialogue box,
and the agent will be able to recognize the content of the images and engage in intelligent conversation based on this,
creating smarter and more diversified chat scenarios.

This feature opens up new interactive methods, allowing communication to transcend text and include a wealth of visual elements.
Whether it&#039;s sharing images in daily use or interpreting images within specific industries, the agent provides an outstanding conversational experience.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-tts]][docs-feat-tts]

### [TTS &amp; STT Voice Conversation][docs-feat-tts]

LobeHub supports Text-to-Speech (TTS) and Speech-to-Text (STT) technologies, enabling our application to convert text messages into clear voice outputs,
allowing users to interact with our conversational agent as if they were talking to a real person. Users can choose from a variety of voices to pair with the agent.

Moreover, TTS offers an excellent solution for those who prefer auditory learning or desire to receive information while busy.
In LobeHub, we have meticulously selected a range of high-quality voice options (OpenAI Audio, Microsoft Edge Speech) to meet the needs of users from different regions and cultural backgrounds.
Users can choose the voice that suits their personal preferences or specific scenarios, resulting in a personalized communication experience.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-t2i]][docs-feat-t2i]

### [Text to Image Generation][docs-feat-t2i]

With support for the latest text-to-image generation technology, LobeHub now allows users to invoke image creation tools directly within conversations with the agent. By leveraging the capabilities of AI tools such as [`DALL-E 3`](https://openai.com/dall-e-3), [`MidJourney`](https://www.midjourney.com/), and [`Pollinations`](https://pollinations.ai/), the agents are now equipped to transform your ideas into images.

This enables a more private and immersive creative process, allowing for the seamless integration of visual storytelling into your personal dialogue with the agent.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-plugin]][docs-feat-plugin]

### [Plugin System (Function Calling)][docs-feat-plugin]

The plugin ecosystem of LobeHub is an important extension of its core functionality, greatly enhancing the practicality and flexibility of the LobeHub assistant.

&lt;video controls src=&quot;https://github.com/lobehub/lobe-chat/assets/28616219/f29475a3-f346-4196-a435-41a6373ab9e2&quot; muted=&quot;false&quot;&gt;&lt;/video&gt;

By utilizing plugins, LobeHub assistants can obtain and process real-time information, such as searching for web information and providing users with instant and relevant news.

In addition, these plugins are not limited to news aggregation, but can also extend to other practical functions, such as quickly searching documents, generating images, obtaining data from various platforms like Bilibili, Steam, and interacting with various third-party services.

&gt; \[!TIP]
&gt;
&gt; Learn more about [ğŸ“˜ Plugin Usage][docs-usage-plugin] by checking it out.

&lt;!-- PLUGIN LIST --&gt;

| Recent Submits                                                                                                             | Description                                                                                                                                     |
| -------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[triggerdotdev/trigger.dev]]></title>
            <link>https://github.com/triggerdotdev/trigger.dev</link>
            <guid>https://github.com/triggerdotdev/trigger.dev</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:25 GMT</pubDate>
            <description><![CDATA[Trigger.dev â€“ build and deploy fullyâ€‘managed AI agents and workflows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/triggerdotdev/trigger.dev">triggerdotdev/trigger.dev</a></h1>
            <p>Trigger.dev â€“ build and deploy fullyâ€‘managed AI agents and workflows</p>
            <p>Language: TypeScript</p>
            <p>Stars: 13,833</p>
            <p>Forks: 1,046</p>
            <p>Stars today: 29 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![Trigger.dev logo](https://content.trigger.dev/github-header-banner.jpg)

### Build and deploy fullyâ€‘managed AI agents and workflows

[Website](https://trigger.dev) | [Docs](https://trigger.dev/docs) | [Issues](https://github.com/triggerdotdev/trigger.dev/issues) | [Example projects](https://github.com/triggerdotdev/examples) | [Feature requests](https://triggerdev.featurebase.app/) | [Public roadmap](https://triggerdev.featurebase.app/roadmap) | [Self-hosting](https://trigger.dev/docs/self-hosting/overview) 

[![Open Source](https://img.shields.io/badge/Open%20Source-%E2%9D%A4-red.svg)](https://github.com/triggerdotdev/trigger.dev)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/triggerdotdev/trigger.dev/blob/main/LICENSE)
[![npm](https://img.shields.io/npm/v/@trigger.dev/sdk.svg?label=npm)](https://www.npmjs.com/package/@trigger.dev/sdk)
[![SDK downloads](https://img.shields.io/npm/dm/@trigger.dev/sdk.svg?label=SDK%20downloads)](https://www.npmjs.com/package/@trigger.dev/sdk)

[![Twitter Follow](https://img.shields.io/twitter/follow/triggerdotdev?style=social)](https://twitter.com/triggerdotdev)
[![Discord](https://img.shields.io/discord/1066956501299777596?logo=discord&amp;logoColor=white&amp;color=7289da)](https://discord.gg/nkqV9xBYWy)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/triggerdotdev/trigger.dev)
[![GitHub stars](https://img.shields.io/github/stars/triggerdotdev/trigger.dev?style=social)](https://github.com/triggerdotdev/trigger.dev)

&lt;/div&gt;

## About Trigger.dev

Trigger.dev is the open-source platform for building AI workflows in TypeScript. Long-running tasks with retries, queues, observability, and elastic scaling.

## The platform designed for building AI agents

Build [AI agents](https://trigger.dev/product/ai-agents) using all the frameworks, services and LLMs you&#039;re used to, deploy them to Trigger.dev and get durable, long-running tasks with retries, queues, observability, and elastic scaling out of the box.

- **Long-running without timeouts**: Execute your tasks with absolutely no timeouts, unlike AWS Lambda, Vercel, and other serverless platforms.

- **Durability, retries &amp; queues**: Build rock solid agents and AI applications using our durable tasks, retries, queues and idempotency.

- **True runtime freedom**: Customize your deployed tasks with system packages â€“ run browsers, Python scripts, FFmpeg and more.

- **Human-in-the-loop**: Programmatically pause your tasks until a human can approve, reject or give feedback.

- **Realtime apps &amp; streaming**: Move your background jobs to the foreground by subscribing to runs or streaming AI responses to your app.

- **Observability &amp; monitoring**: Each run has full tracing and logs. Configure error alerts to catch bugs fast.

## Key features:

- **[JavaScript and TypeScript SDK](https://trigger.dev/docs/tasks/overview)** - Build background tasks using familiar programming models
- **[Long-running tasks](https://trigger.dev/docs/runs/max-duration)** - Handle resource-heavy tasks without timeouts
- **[Durable cron schedules](https://trigger.dev/docs/tasks/scheduled#scheduled-tasks-cron)** - Create and attach recurring schedules of up to a year
- **[Trigger.dev Realtime](https://trigger.dev/docs/realtime/overview)** - Trigger, subscribe to, and get real-time updates for runs, with LLM streaming support
- **[Build extensions](https://trigger.dev/docs/config/extensions/overview#build-extensions)** - Hook directly into the build system and customize the build process. Run Python scripts, FFmpeg, browsers, and more.
- **[React hooks](https://trigger.dev/docs/frontend/react-hooks#react-hooks)** - Interact with the Trigger.dev API on your frontend using our React hooks package
- **[Batch triggering](https://trigger.dev/docs/triggering#tasks-batchtrigger)** - Use batchTrigger() to initiate multiple runs of a task with custom payloads and options
- **[Structured inputs / outputs](https://trigger.dev/docs/tasks/schemaTask#schematask)** - Define precise data schemas for your tasks with runtime payload validation
- **[Waits](https://trigger.dev/docs/wait)** - Add waits to your tasks to pause execution for a specified duration
- **[Preview branches](https://trigger.dev/docs/deployment/preview-branches)** - Create isolated environments for testing and development. Integrates with Vercel and git workflows
- **[Waitpoints](https://trigger.dev/docs/wait-for-token#wait-for-token)** - Add human-in-the-loop judgment at critical decision points without disrupting workflow
- **[Concurrency &amp; queues](https://trigger.dev/docs/queue-concurrency#concurrency-and-queues)** - Set concurrency rules to manage how multiple tasks execute
- **[Multiple environments](https://trigger.dev/docs/how-it-works#dev-mode)** - Support for DEV, PREVIEW, STAGING, and PROD environments
- **[No infrastructure to manage](https://trigger.dev/docs/how-it-works#trigger-dev-architecture)** - Auto-scaling infrastructure that eliminates timeouts and server management
- **[Automatic retries](https://trigger.dev/docs/errors-retrying)** - If your task encounters an uncaught error, we automatically attempt to run it again
- **[Checkpointing](https://trigger.dev/docs/how-it-works#the-checkpoint-resume-system)** - Tasks are inherently durable, thanks to our checkpointing feature
- **[Versioning](https://trigger.dev/docs/versioning)** - Atomic versioning allows you to deploy new versions without affecting running tasks
- **[Machines](https://trigger.dev/docs/machines)** - Configure the number of vCPUs and GBs of RAM you want the task to use
- **[Observability &amp; monitoring](https://trigger.dev/product/observability-and-monitoring)** - Monitor every aspect of your tasks&#039; performance with comprehensive logging and visualization tools
- **[Logging &amp; tracing](https://trigger.dev/docs/logging)** - Comprehensive logging and tracing for all your tasks
- **[Tags](https://trigger.dev/docs/tags#tags)** - Attach up to ten tags to each run, allowing you to filter via the dashboard, realtime, and the SDK
- **[Run metadata](https://trigger.dev/docs/runs/metadata#run-metadata)** - Attach metadata to runs which updates as the run progresses and is available to use in your frontend for live updates
- **[Bulk actions](https://trigger.dev/docs/bulk-actions)** - Perform actions on multiple runs simultaneously, including replaying and cancelling
- **[Real-time alerts](https://trigger.dev/docs/troubleshooting-alerts#alerts)** - Choose your preferred notification method for run failures and deployments

## Write tasks in your codebase

Create tasks where they belong: in your codebase. Version control, localhost, test and review like you&#039;re already used to.

```ts
import { task } from &quot;@trigger.dev/sdk&quot;;

//1. You need to export each task
export const helloWorld = task({
  //2. Use a unique id for each task
  id: &quot;hello-world&quot;,
  //3. The run function is the main function of the task
  run: async (payload: { message: string }) =&gt; {
    //4. You can write code that runs for a long time here, there are no timeouts
    console.log(payload.message);
  },
});
```

## Deployment

Use our SDK to write tasks in your codebase. There&#039;s no infrastructure to manage, your tasks automatically scale and connect to our cloud. Or you can always self-host.

## Environments

We support `Development`, `Staging`, `Preview`, and `Production` environments, allowing you to test your tasks before deploying them to production.

## Full visibility of every job run

View every task in every run so you can tell exactly what happened. We provide a full trace view of every task run so you can see what happened at every step.

![Trace view image](https://content.trigger.dev/trace-view.png)

# Getting started

The quickest way to get started is to create an account and project in our [web app](https://cloud.trigger.dev), and follow the instructions in the onboarding. Build and deploy your first task in minutes.

### Useful links:

- [Quick start](https://trigger.dev/docs/quick-start) - get up and running in minutes
- [How it works](https://trigger.dev/docs/how-it-works) - understand how Trigger.dev works under the hood
- [Guides and examples](https://trigger.dev/docs/guides/introduction) - walk-through guides and code examples for popular frameworks and use cases

## Self-hosting

If you prefer to self-host Trigger.dev, you can follow our [self-hosting guides](https://trigger.dev/docs/self-hosting/overview):

- [Docker self-hosting guide](https://trigger.dev/docs/self-hosting/docker) - use Docker Compose to spin up a Trigger.dev instance
- [Kubernetes self-hosting guide](https://trigger.dev/docs/self-hosting/kubernetes) - use our official Helm chart to deploy Trigger.dev to your Kubernetes cluster

## Support and community

We have a large active community in our official [Discord server](https://trigger.dev/discord) for support, including a dedicated channel for self-hosting.

## Development

To setup and develop locally or contribute to the open source project, follow our [development guide](./CONTRIBUTING.md).

## Meet the Amazing People Behind This Project:

&lt;a href=&quot;https://github.com/triggerdotdev/trigger.dev/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=triggerdotdev/trigger.dev&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[google-gemini/gemini-cli]]></title>
            <link>https://github.com/google-gemini/gemini-cli</link>
            <guid>https://github.com/google-gemini/gemini-cli</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:24 GMT</pubDate>
            <description><![CDATA[An open-source AI agent that brings the power of Gemini directly into your terminal.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google-gemini/gemini-cli">google-gemini/gemini-cli</a></h1>
            <p>An open-source AI agent that brings the power of Gemini directly into your terminal.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 95,432</p>
            <p>Forks: 11,553</p>
            <p>Stars today: 129 stars today</p>
            <h2>README</h2><pre># Gemini CLI

[![Gemini CLI CI](https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml/badge.svg)](https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml)
[![Gemini CLI E2E (Chained)](https://github.com/google-gemini/gemini-cli/actions/workflows/chained_e2e.yml/badge.svg)](https://github.com/google-gemini/gemini-cli/actions/workflows/chained_e2e.yml)
[![Version](https://img.shields.io/npm/v/@google/gemini-cli)](https://www.npmjs.com/package/@google/gemini-cli)
[![License](https://img.shields.io/github/license/google-gemini/gemini-cli)](https://github.com/google-gemini/gemini-cli/blob/main/LICENSE)
[![View Code Wiki](https://assets.codewiki.google/readme-badge/static.svg)](https://codewiki.google/github.com/google-gemini/gemini-cli?utm_source=badge&amp;utm_medium=github&amp;utm_campaign=github.com/google-gemini/gemini-cli)

![Gemini CLI Screenshot](./docs/assets/gemini-screenshot.png)

Gemini CLI is an open-source AI agent that brings the power of Gemini directly
into your terminal. It provides lightweight access to Gemini, giving you the
most direct path from your prompt to our model.

Learn all about Gemini CLI in our [documentation](https://geminicli.com/docs/).

## ğŸš€ Why Gemini CLI?

- **ğŸ¯ Free tier**: 60 requests/min and 1,000 requests/day with personal Google
  account.
- **ğŸ§  Powerful Gemini 3 models**: Access to improved reasoning and 1M token
  context window.
- **ğŸ”§ Built-in tools**: Google Search grounding, file operations, shell
  commands, web fetching.
- **ğŸ”Œ Extensible**: MCP (Model Context Protocol) support for custom
  integrations.
- **ğŸ’» Terminal-first**: Designed for developers who live in the command line.
- **ğŸ›¡ï¸ Open source**: Apache 2.0 licensed.

## ğŸ“¦ Installation

See
[Gemini CLI installation, execution, and releases](./docs/get-started/installation.md)
for recommended system specifications and a detailed installation guide.

### Quick Install

#### Run instantly with npx

```bash
# Using npx (no installation required)
npx @google/gemini-cli
```

#### Install globally with npm

```bash
npm install -g @google/gemini-cli
```

#### Install globally with Homebrew (macOS/Linux)

```bash
brew install gemini-cli
```

#### Install globally with MacPorts (macOS)

```bash
sudo port install gemini-cli
```

#### Install with Anaconda (for restricted environments)

```bash
# Create and activate a new environment
conda create -y -n gemini_env -c conda-forge nodejs
conda activate gemini_env

# Install Gemini CLI globally via npm (inside the environment)
npm install -g @google/gemini-cli
```

## Release Cadence and Tags

See [Releases](./docs/releases.md) for more details.

### Preview

New preview releases will be published each week at UTC 2359 on Tuesdays. These
releases will not have been fully vetted and may contain regressions or other
outstanding issues. Please help us test and install with `preview` tag.

```bash
npm install -g @google/gemini-cli@preview
```

### Stable

- New stable releases will be published each week at UTC 2000 on Tuesdays, this
  will be the full promotion of last week&#039;s `preview` release + any bug fixes
  and validations. Use `latest` tag.

```bash
npm install -g @google/gemini-cli@latest
```

### Nightly

- New releases will be published each day at UTC 0000. This will be all changes
  from the main branch as represented at time of release. It should be assumed
  there are pending validations and issues. Use `nightly` tag.

```bash
npm install -g @google/gemini-cli@nightly
```

## ğŸ“‹ Key Features

### Code Understanding &amp; Generation

- Query and edit large codebases
- Generate new apps from PDFs, images, or sketches using multimodal capabilities
- Debug issues and troubleshoot with natural language

### Automation &amp; Integration

- Automate operational tasks like querying pull requests or handling complex
  rebases
- Use MCP servers to connect new capabilities, including
  [media generation with Imagen, Veo or Lyria](https://github.com/GoogleCloudPlatform/vertex-ai-creative-studio/tree/main/experiments/mcp-genmedia)
- Run non-interactively in scripts for workflow automation

### Advanced Capabilities

- Ground your queries with built-in
  [Google Search](https://ai.google.dev/gemini-api/docs/grounding) for real-time
  information
- Conversation checkpointing to save and resume complex sessions
- Custom context files (GEMINI.md) to tailor behavior for your projects

### GitHub Integration

Integrate Gemini CLI directly into your GitHub workflows with
[**Gemini CLI GitHub Action**](https://github.com/google-github-actions/run-gemini-cli):

- **Pull Request Reviews**: Automated code review with contextual feedback and
  suggestions
- **Issue Triage**: Automated labeling and prioritization of GitHub issues based
  on content analysis
- **On-demand Assistance**: Mention `@gemini-cli` in issues and pull requests
  for help with debugging, explanations, or task delegation
- **Custom Workflows**: Build automated, scheduled and on-demand workflows
  tailored to your team&#039;s needs

## ğŸ” Authentication Options

Choose the authentication method that best fits your needs:

### Option 1: Login with Google (OAuth login using your Google Account)

**âœ¨ Best for:** Individual developers as well as anyone who has a Gemini Code
Assist License. (see
[quota limits and terms of service](https://cloud.google.com/gemini/docs/quotas)
for details)

**Benefits:**

- **Free tier**: 60 requests/min and 1,000 requests/day
- **Gemini 3 models** with 1M token context window
- **No API key management** - just sign in with your Google account
- **Automatic updates** to latest models

#### Start Gemini CLI, then choose _Login with Google_ and follow the browser authentication flow when prompted

```bash
gemini
```

#### If you are using a paid Code Assist License from your organization, remember to set the Google Cloud Project

```bash
# Set your Google Cloud Project
export GOOGLE_CLOUD_PROJECT=&quot;YOUR_PROJECT_ID&quot;
gemini
```

### Option 2: Gemini API Key

**âœ¨ Best for:** Developers who need specific model control or paid tier access

**Benefits:**

- **Free tier**: 1000 requests/day with Gemini 3 (mix of flash and pro)
- **Model selection**: Choose specific Gemini models
- **Usage-based billing**: Upgrade for higher limits when needed

```bash
# Get your key from https://aistudio.google.com/apikey
export GEMINI_API_KEY=&quot;YOUR_API_KEY&quot;
gemini
```

### Option 3: Vertex AI

**âœ¨ Best for:** Enterprise teams and production workloads

**Benefits:**

- **Enterprise features**: Advanced security and compliance
- **Scalable**: Higher rate limits with billing account
- **Integration**: Works with existing Google Cloud infrastructure

```bash
# Get your key from Google Cloud Console
export GOOGLE_API_KEY=&quot;YOUR_API_KEY&quot;
export GOOGLE_GENAI_USE_VERTEXAI=true
gemini
```

For Google Workspace accounts and other authentication methods, see the
[authentication guide](./docs/get-started/authentication.md).

## ğŸš€ Getting Started

### Basic Usage

#### Start in current directory

```bash
gemini
```

#### Include multiple directories

```bash
gemini --include-directories ../lib,../docs
```

#### Use specific model

```bash
gemini -m gemini-2.5-flash
```

#### Non-interactive mode for scripts

Get a simple text response:

```bash
gemini -p &quot;Explain the architecture of this codebase&quot;
```

For more advanced scripting, including how to parse JSON and handle errors, use
the `--output-format json` flag to get structured output:

```bash
gemini -p &quot;Explain the architecture of this codebase&quot; --output-format json
```

For real-time event streaming (useful for monitoring long-running operations),
use `--output-format stream-json` to get newline-delimited JSON events:

```bash
gemini -p &quot;Run tests and deploy&quot; --output-format stream-json
```

### Quick Examples

#### Start a new project

```bash
cd new-project/
gemini
&gt; Write me a Discord bot that answers questions using a FAQ.md file I will provide
```

#### Analyze existing code

```bash
git clone https://github.com/google-gemini/gemini-cli
cd gemini-cli
gemini
&gt; Give me a summary of all of the changes that went in yesterday
```

## ğŸ“š Documentation

### Getting Started

- [**Quickstart Guide**](./docs/get-started/index.md) - Get up and running
  quickly.
- [**Authentication Setup**](./docs/get-started/authentication.md) - Detailed
  auth configuration.
- [**Configuration Guide**](./docs/get-started/configuration.md) - Settings and
  customization.
- [**Keyboard Shortcuts**](./docs/cli/keyboard-shortcuts.md) - Productivity
  tips.

### Core Features

- [**Commands Reference**](./docs/cli/commands.md) - All slash commands
  (`/help`, `/chat`, etc).
- [**Custom Commands**](./docs/cli/custom-commands.md) - Create your own
  reusable commands.
- [**Context Files (GEMINI.md)**](./docs/cli/gemini-md.md) - Provide persistent
  context to Gemini CLI.
- [**Checkpointing**](./docs/cli/checkpointing.md) - Save and resume
  conversations.
- [**Token Caching**](./docs/cli/token-caching.md) - Optimize token usage.

### Tools &amp; Extensions

- [**Built-in Tools Overview**](./docs/tools/index.md)
  - [File System Operations](./docs/tools/file-system.md)
  - [Shell Commands](./docs/tools/shell.md)
  - [Web Fetch &amp; Search](./docs/tools/web-fetch.md)
- [**MCP Server Integration**](./docs/tools/mcp-server.md) - Extend with custom
  tools.
- [**Custom Extensions**](./docs/extensions/index.md) - Build and share your own
  commands.

### Advanced Topics

- [**Headless Mode (Scripting)**](./docs/cli/headless.md) - Use Gemini CLI in
  automated workflows.
- [**Architecture Overview**](./docs/architecture.md) - How Gemini CLI works.
- [**IDE Integration**](./docs/ide-integration/index.md) - VS Code companion.
- [**Sandboxing &amp; Security**](./docs/cli/sandbox.md) - Safe execution
  environments.
- [**Trusted Folders**](./docs/cli/trusted-folders.md) - Control execution
  policies by folder.
- [**Enterprise Guide**](./docs/cli/enterprise.md) - Deploy and manage in a
  corporate environment.
- [**Telemetry &amp; Monitoring**](./docs/cli/telemetry.md) - Usage tracking.
- [**Tools API Development**](./docs/core/tools-api.md) - Create custom tools.
- [**Local development**](./docs/local-development.md) - Local development
  tooling.

### Troubleshooting &amp; Support

- [**Troubleshooting Guide**](./docs/troubleshooting.md) - Common issues and
  solutions.
- [**FAQ**](./docs/faq.md) - Frequently asked questions.
- Use `/bug` command to report issues directly from the CLI.

### Using MCP Servers

Configure MCP servers in `~/.gemini/settings.json` to extend Gemini CLI with
custom tools:

```text
&gt; @github List my open pull requests
&gt; @slack Send a summary of today&#039;s commits to #dev channel
&gt; @database Run a query to find inactive users
```

See the [MCP Server Integration guide](./docs/tools/mcp-server.md) for setup
instructions.

## ğŸ¤ Contributing

We welcome contributions! Gemini CLI is fully open source (Apache 2.0), and we
encourage the community to:

- Report bugs and suggest features.
- Improve documentation.
- Submit code improvements.
- Share your MCP servers and extensions.

See our [Contributing Guide](./CONTRIBUTING.md) for development setup, coding
standards, and how to submit pull requests.

Check our [Official Roadmap](https://github.com/orgs/google-gemini/projects/11)
for planned features and priorities.

## ğŸ“– Resources

- **[Official Roadmap](./ROADMAP.md)** - See what&#039;s coming next.
- **[Changelog](./docs/changelogs/index.md)** - See recent notable updates.
- **[NPM Package](https://www.npmjs.com/package/@google/gemini-cli)** - Package
  registry.
- **[GitHub Issues](https://github.com/google-gemini/gemini-cli/issues)** -
  Report bugs or request features.
- **[Security Advisories](https://github.com/google-gemini/gemini-cli/security/advisories)** -
  Security updates.

### Uninstall

See the [Uninstall Guide](docs/cli/uninstall.md) for removal instructions.

## ğŸ“„ Legal

- **License**: [Apache License 2.0](LICENSE)
- **Terms of Service**: [Terms &amp; Privacy](./docs/tos-privacy.md)
- **Security**: [Security Policy](SECURITY.md)

---

&lt;p align=&quot;center&quot;&gt;
  Built with â¤ï¸ by Google and the open source community
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[readest/readest]]></title>
            <link>https://github.com/readest/readest</link>
            <guid>https://github.com/readest/readest</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:23 GMT</pubDate>
            <description><![CDATA[Readest is a modern, feature-rich ebook reader designed for avid readers offering seamless cross-platform access, powerful tools, and an intuitive interface to elevate your reading experience.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/readest/readest">readest/readest</a></h1>
            <p>Readest is a modern, feature-rich ebook reader designed for avid readers offering seamless cross-platform access, powerful tools, and an intuitive interface to elevate your reading experience.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 18,093</p>
            <p>Forks: 976</p>
            <p>Stars today: 124 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://readest.com?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://github.com/readest/readest/blob/main/apps/readest-app/src-tauri/icons/icon.png?raw=true&quot; alt=&quot;Readest Logo&quot; width=&quot;20%&quot; /&gt;
  &lt;/a&gt;
  &lt;h1&gt;Readest&lt;/h1&gt;
  &lt;br&gt;

[Readest][link-website] is an open-source ebook reader designed for immersive and deep reading experiences. Built as a modern rewrite of [Foliate](https://github.com/johnfactotum/foliate), it leverages [Next.js 16](https://github.com/vercel/next.js) and [Tauri v2](https://github.com/tauri-apps/tauri) to deliver a smooth, cross-platform experience across macOS, Windows, Linux, Android, iOS, and the Web.

[![Website][badge-website]][link-website]
[![Web App][badge-web-app]][link-web-readest]
[![OS][badge-platforms]][link-website]
&lt;br&gt;
[![Discord][badge-discord]][link-discord]
[![Reddit][badge-reddit]][link-reddit]
[![AGPL Licence][badge-license]](LICENSE)
[![Language Coverage][badge-language-coverage]][link-locales]
[![Donate][badge-donate]][link-donate]
[![Latest release][badge-release]][link-gh-releases]
[![Last commit][badge-last-commit]][link-gh-commits]
[![Commits][badge-commit-activity]][link-gh-pulse]
[![][badge-hellogithub]][link-hellogithub]
[![Ask DeepWiki][badge-deepwiki]][link-deepwiki]

&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#features&quot;&gt;Features&lt;/a&gt; â€¢
  &lt;a href=&quot;#planned-features&quot;&gt;Planned Features&lt;/a&gt; â€¢
  &lt;a href=&quot;#screenshots&quot;&gt;Screenshots&lt;/a&gt; â€¢
  &lt;a href=&quot;#downloads&quot;&gt;Downloads&lt;/a&gt; â€¢
  &lt;a href=&quot;#getting-started&quot;&gt;Getting Started&lt;/a&gt; â€¢
  &lt;a href=&quot;#troubleshooting&quot;&gt;Troubleshooting&lt;/a&gt; â€¢
  &lt;a href=&quot;#support&quot;&gt;Support&lt;/a&gt; â€¢
  &lt;a href=&quot;#license&quot;&gt;License&lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://readest.com&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;./data/screenshots/landing_all_platforms.png&quot; alt=&quot;Readest Banner&quot; width=&quot;100%&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

## Features

&lt;div align=&quot;left&quot;&gt;âœ… Implemented&lt;/div&gt;

| **Feature**                             | **Description**                                                                                                        | **Status** |
| --------------------------------------- | ---------------------------------------------------------------------------------------------------------------------- | ---------- |
| **Multi-Format Support**                | Support EPUB, MOBI, KF8 (AZW3), FB2, CBZ, TXT, PDF (experimental)                                                      | âœ…         |
| **Scroll/Page View Modes**              | Switch between scrolling or paginated reading modes.                                                                   | âœ…         |
| **Full-Text Search**                    | Search across the entire book to find relevant sections.                                                               | âœ…         |
| **Annotations and Highlighting**        | Add highlights, bookmarks, and notes to enhance your reading experience and use instant mode for quicker interactions. | âœ…         |
| **Dictionary/Wikipedia Lookup**         | Instantly look up words and terms when reading.                                                                        | âœ…         |
| **[Parallel Read][link-parallel-read]** | Read two books or documents simultaneously in a split-screen view.                                                     | âœ…         |
| **Customize Font and Layout**           | Adjust font, layout, theme mode, and theme colors for a personalized experience.                                       | âœ…         |
| **Code Syntax Highlighting**            | Read software manuals with rich coloring of code examples.                                                             | âœ…         |
| **File Association and Open With**      | Quickly open files in Readest in your file browser with one-click.                                                     | âœ…         |
| **Library Management**                  | Organize, sort, and manage your entire ebook library.                                                                  | âœ…         |
| **OPDS/Calibre Integration**            | Integrate OPDS/Calibre to access online libraries and catalogs.                                                        | âœ…         |
| **Translate with DeepL and Yandex**     | From a single sentence to the entire bookâ€”translate instantly.                                                         | âœ…         |
| **Text-to-Speech (TTS) Support**        | Enjoy smooth, multilingual narrationâ€”even within a single book.                                                        | âœ…         |
| **Sync across Platforms**               | Synchronize book files, reading progress, notes, and bookmarks across all supported platforms.                         | âœ…         |
| **Accessibility**                       | Provides full keyboard navigation and supports for screen readers such as VoiceOver, TalkBack, NVDA, and Orca.         | âœ…         |
| **Visual &amp; Focus Aids**                 | Reading ruler, paragraph-by-paragraph reading mode, and speed reading features.                                        | âœ…         |

## Planned Features

&lt;div align=&quot;left&quot;&gt;ğŸ›  Building&lt;/div&gt;
&lt;div align=&quot;left&quot;&gt;ğŸ”„ Planned&lt;/div&gt;

| **Feature**                                | **Description**                                                                            | **Priority** |
| ------------------------------------------ | ------------------------------------------------------------------------------------------ | ------------ |
| [**Sync with Koreader**][link-kosync-wiki] | Synchronize reading progress, notes, and bookmarks with [Koreader][link-koreader] devices. | ğŸ›            |
| **AI-Powered Summarization**               | Generate summaries of books or chapters using AI for quick insights.                       | ğŸ›            |
| **Advanced Reading Stats**                 | Track reading time, pages read, and more for detailed insights.                            | ğŸ›            |
| **Audiobook Support**                      | Extend functionality to play and manage audiobooks.                                        | ğŸ”„           |
| **Handwriting Annotations**                | Add support for handwriting annotations using a pen on compatible devices.                 | ğŸ”„           |
| **In-Library Full-Text Search**            | Search across your entire ebook library to find topics and quotes.                         | ğŸ”„           |

Stay tuned for continuous improvements and updates! Contributions and suggestions are always welcomeâ€”let&#039;s build the ultimate reading experience together. ğŸ˜Š

## Screenshots

![Annotations](./data/screenshots/annotations.png)

![TTS](./data/screenshots/tts_speak_aloud.png)

![DeepL](./data/screenshots/deepl.png)

![Footnote](./data/screenshots/footnote_popover.png)

![Wikipedia](./data/screenshots/wikipedia_vertical.png)

![Theming Dark Mode](./data/screenshots/theming_dark_mode.png)

---

## Downloads

### Mobile Apps

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://apps.apple.com/app/id6738622779&quot;&gt;
    &lt;img alt=&quot;Download on the App Store&quot; src=&quot;https://developer.apple.com/assets/elements/badges/download-on-the-app-store.svg&quot; style=&quot;height: 50px;&quot; /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
  &lt;a href=&quot;https://play.google.com/store/apps/details?id=com.bilingify.readest&quot;&gt;
    &lt;img alt=&quot;Get it on Google Play&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/7/78/Google_Play_Store_badge_EN.svg&quot; style=&quot;height: 50px;&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

### Platform-Specific Downloads

- macOS / iOS / iPadOS : Search and install **Readest** on the [App Store][link-appstore], _also_ available on TestFlight for beta test (send your Apple ID to &lt;readestapp@gmail.com&gt; to request access).
- Windows / Linux / Android: Visit and download **Readest** at [https://readest.com][link-website] or the [Releases on GitHub][link-gh-releases].
- Linux users can also install [Readest on Flathub][link-flathub].
- Web: Visit and use **Readest for Web** at [https://web.readest.com][link-web-readest].

## Requirements

- **Node.js** and **pnpm** for Next.js development
- **Rust** and **Cargo** for Tauri development

For the best experience to build Readest for yourself, use a recent version of Node.js and Rust. Refer to the [Tauri documentation](https://v2.tauri.app/start/prerequisites/) for details on setting up the development environment prerequisites on different platforms.

```bash
nvm install v22
nvm use v22
npm install -g pnpm
rustup update
```

## Getting Started

To get started with Readest, follow these steps to clone and build the project.

### 1. Clone the Repository

```bash
git clone https://github.com/readest/readest.git
cd readest
```

### 2. Install Dependencies

```bash
# might need to rerun this when code is updated
git submodule update --init --recursive
pnpm install
# copy vendors dist libs to public directory
pnpm --filter @readest/readest-app setup-vendors
```

### 3. Verify Dependencies Installation

To confirm that all dependencies are correctly installed, run the following command:

```bash
pnpm tauri info
```

This command will display information about the installed Tauri dependencies and configuration on your platform. Note that the output may vary depending on the operating system and environment setup. Please review the output specific to your platform for any potential issues.

For Windows targets, â€œBuild Tools for Visual Studio 2022â€ (or a higher edition of Visual Studio) and the â€œDesktop development with C++â€ workflow must be installed. For Windows ARM64 targets, the â€œVS 2022 C++ ARM64 build toolsâ€ and &quot;C++ Clang Compiler for Windows&quot; components must be installed. And make sure `clang` can be found in the path by adding `C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\Llvm\x64\bin` for example in the environment variable `Path`.

### 4. Build for Development

```bash
# Start development for the Tauri app
pnpm tauri dev
# or start development for the Web app
pnpm dev-web
# preview with OpenNext build for the Web app
pnpm preview
```

For Android:

```bash
# Initialize the Android environment (run once)
rm apps/readest-app/src-tauri/gen/android
pnpm tauri android init
git checkout apps/readest-app/src-tauri/gen/android

pnpm tauri android dev
# or if you want to dev on a real device
pnpm tauri android dev --host
```

For iOS:

```bash
# Set up the iOS environment (run once)
pnpm tauri ios init

pnpm tauri ios dev
# or if you want to dev on a real device
pnpm tauri ios dev --host
```

### 5. Build for Production

```bash
pnpm tauri build
pnpm tauri android build
pnpm tauri ios build
```

Please refer to our release script if you experience any issues:
https://github.com/readest/readest/blob/main/.github/workflows/release.yml

### 6. Setup dev environment with Nix

If you have Nix installed, you can leverage flake to enter a development shell
with all the necessary dependencies:

```bash
nix develop ./ops  # enter a dev shell for the web app
nix develop ./ops#ios # enter a dev shell for the ios app
nix develop ./ops#android # enter a dev shell for the android app
```

### 7. More information

Please check the [wiki][link-gh-wiki] of this project for more information on development.

## Troubleshooting

### 1. Readest Wonâ€™t Launch on Windows (Missing Edge WebView2 Runtime)

**Symptom**

- When you double-click readest.exe, nothing happens. No window appears, and Task Manager does not show the process.
- This can affect both the standard installer and the portable version.

**Cause**

- Microsoft Edge WebView2 Runtime is either missing, outdated, or improperly installed on your system. Readest depends on WebView2 to render the interface on Windows.

**How to Fix**

1. Check if WebView2 is installed
   - Open â€œAdd or Remove Programsâ€ (a.k.a. Apps &amp; features) on Windows. Look for â€œMicrosoft Edge WebView2 Runtime.â€
2. Install or Update WebView2
   - Download the WebView2 Runtime directly from Microsoft: [link](https://developer.microsoft.com/en-us/microsoft-edge/webview2?form=MA13LH).
   - If you prefer an offline installer, download the offline package and run it as an Administrator.
3. Re-run Readest
   - After installing/updating WebView2, launch readest.exe again.
   - If you still encounter problems, reboot your PC and try again.

**Additional Tips**

- If reinstalling once doesnâ€™t work, uninstall Edge WebView2 completely, then reinstall it with Administrator privileges.
- Verify your Windows installation has the latest updates from Microsoft.

**Still Stuck?**

- See Issue [readest/readest#358](https://github.com/readest/readest/issues/358) for further details, or head over to our [Discord][link-discord] server and open a support discussion with detailed logs of your environment and the steps youâ€™ve taken.

### 2. AppImage Launches but Only Shows a Taskbar Icon

On some Arch Linux systemsâ€”especially those using Waylandâ€”the Readest AppImage may briefly show an icon in the taskbar and then exit without opening a window.

You might see logs such as:

```
Could not create default EGL display: EGL_BAD_PARAMETER. Aborting...
```

This behavior is usually caused by compatibility issues between the bundled AppImage libraries and the systemâ€™s EGL / Wayland environment.

**Workaround 1: Launch with LD_PRELOAD (recommended)**

You can preload the system Wayland client library before launching the AppImage:

```
LD_PRELOAD=/usr/lib/libwayland-client.so /path/to/Readest.AppImage
```

This workaround has been confirmed to resolve the issue on affected systems.

**Workaround 2: Use the Flatpak Version**

If you prefer a more reliable out-of-the-box experience on Arch Linux, consider using the [Flatpak build on Flathub][link-flathub] instead. The Flatpak runtime helps avoid system library mismatches and tends to behave more consistently across different Wayland and X11 setups.

## Contributors

Readest is open-source, and contributions are welcome! Feel free to open issues, suggest features, or submit pull requests. Please **review our [contributing guidelines](CONTRIBUTING.md) before you start**. We also welcome you to join our [Discord][link-discord] community for either support or contributing guidance.

&lt;a href=&quot;https://github.com/readest/readest/graphs/contributors&quot;&gt;
  &lt;p align=&quot;left&quot;&gt;
    &lt;img width=&quot;500&quot; src=&quot;https://contrib.rocks/image?repo=readest/readest&quot; alt=&quot;A table of avatars from the project&#039;s contributors&quot; /&gt;
  &lt;/p&gt;
&lt;/a&gt;

## Support

If Readest has been useful to you, consider supporting its development. You can [become a sponsor on GitHub](https://github.com/sponsors/readest), [donate via Stripe](https://donate.stripe.com/4gMcN5aZdcE52kW3TFgjC01), or [donate with crypto](https://donate.readest.com). Your contribution helps us squash bugs faster, improve performance, and keep building great features.

### Sponsors

&lt;p align=&quot;center&quot;&gt;
  &lt;a title=&quot;Browser testing via TestMu AI&quot; href=&quot;https://www.testmuai.com/?utm_medium=sponsor&amp;utm_source=readest&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/readest/readest/refs/heads/main/data/sponsors/testmu-ai-logo.png&quot; style=&quot;vertical-align: middle;&quot; width=&quot;250&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## License

Readest is free software: you can redistribute it and/or modify it under the terms of the [GNU Affero General Public License](https://www.gnu.org/licenses/agpl-3.0.html) as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. See the [LICENSE](LICENSE) file for details.

The following libraries and frameworks are used in this software:

- [foliate-js](https://github.com/johnfactotum/foliate-js), which is MIT licensed.
- [zip.js](https://github.com/gildas-lormeau/zip.js), which is licensed under the BSD-3-Clause license.
- [fflate](https://github.com/101arrowz/fflate), which is MIT licensed.
- [PDF.js](https://github.com/mozilla/pdf.js), which is licensed under Apache License 2.0.
- [daisyUI](https://github.com/saadeghi/daisyui), which is MIT licensed.
- [marked](https://github.com/markedjs/marked), which is MIT licensed.
- [next.js](https://github.com/vercel/next.js), which is MIT licensed.
- [react-icons](https://github.com/react-icons/react-icons), which has various open-source licenses.
- [react](https://github.com/facebook/react), which is MIT licensed.
- [tauri](https://github.com/tauri-apps/tauri), which is MIT licensed.

The following fonts are utilized in this software, either bundled within the application or provided through web fonts:

[Bitter](https://fonts.google.com/specimen/Bitter), [Fira Code](https://fonts.google.com/specimen/Fira+Code), [Inter](https://fonts.google.com/specimen/Inter), [Literata](https://fonts.google.com/specimen/Literata), [Merriweather](https://fonts.google.com/specimen/Merriweather), [Noto Sans](https://fonts.google.com/specimen/Noto+Sans), [Roboto](https://fonts.google.com/specimen/Roboto), [LXGW WenKai](https://github.com/lxgw/LxgwWenKai), [MiSans](https://hyperos.mi.com/font/en/), [Source Han](https://github.com/adobe-fonts/source-han-sans/), [WenQuanYi Micro Hei](http://wenq.org/wqy2/)

We would also like to thank the [Web Chinese Fonts Plan](https://chinese-font.netlify.app) for offering open-source tools that enable the use of Chinese fonts on the web.

---

&lt;div align=&quot;center&quot; style=&quot;color: gray;&quot;&gt;Happy reading with Readest!&lt;/div&gt;

[badge-website]: https://img.shields.io/badge/website-readest.com-orange
[badge-web-app]: https://img.shields.io/badge/read%20online-web.readest.com-orange
[badge-license]: https://img.shields.io/github/license/readest/readest?color=teal
[badge-release]: https://img.shields.io/github/release/readest/readest?color=green
[badge-platforms]: https://img.shields.io/badge/platforms-macOS%2C%20Windows%2C%20Linux%2C%20Android%2C%20iOS%2C%20Web%2C%20PWA-green
[badge-last-commit]: https://img.shields.io/github/last-commit/readest/readest?color=blue
[badge-commit-activity]: https://img.shields.io/github/commit-activity/m/readest/readest?color=blue
[badge-discord]: https://img.shields.io/discord/1314226120886976544?color=5865F2&amp;label=discord&amp;labelColor=black&amp;logo=discord&amp;logoColor=white&amp;style=flat-square
[badge-hellogithub]: https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=8a5b6ade2aee461a8bd94e59200682a7&amp;claim_uid=eRLUbPOy2qZtDgw&amp;theme=small
[badge-donate]: https://donate.readest.com/badge.svg
[badge-deepwiki]: https://deepwiki.com/badge.svg
[badge-reddit]: https://img.shields.io/reddit/subreddit-subscribers/readest?style=flat&amp;logo=reddit&amp;color=F37E41
[badge-language-coverage]: https://img.shields.io/badge/coverage-53%25%20population%20ğŸŒ-green
[link-donate]: https://donate.readest.com/?tickers=btc%2Ceth%2Csol%2Cusdc
[link-appstore]: https://apps.apple.com/app/apple-store/id6738622779?pt=127463130&amp;ct=github&amp;mt=8
[link-website]: https://readest.com?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=readme
[link-flathub]: https://flathub.org/en/apps/com.bilingify.readest
[link-web-readest]: https://web.readest.com
[link-gh-releases]: https://github.com/readest/readest/releases
[link-gh-commits]: https://github.com/readest/readest/commits/main
[link-gh-pulse]: https://github.com/readest/readest/pulse
[link-gh-wiki]: https://github.com/readest/readest/wiki
[link-discord]: https://discord.gg/gntyVNk3BJ
[link-parallel-read]: https://readest.com/#parallel-read
[link-koreader]: https://github.com/koreader/koreader
[link-hellogithub]: https://hellogithub.com/repository/8a5b6ade2aee461a8bd94e59200682a7
[link-deepwiki]: https://deepwiki.com/readest/readest
[link-locales]: https://github.com/readest/readest/tree/main/apps/readest-app/public/locales
[link-kosync-wiki]: https://github.com/readest/readest/wiki/Sync-with-Koreader-devices
[link-reddit]: https://reddit.com/r/readest/
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>