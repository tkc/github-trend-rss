<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Sun, 07 Dec 2025 00:05:31 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[electric-sql/pglite]]></title>
            <link>https://github.com/electric-sql/pglite</link>
            <guid>https://github.com/electric-sql/pglite</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[Embeddable Postgres with real-time, reactive bindings.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/electric-sql/pglite">electric-sql/pglite</a></h1>
            <p>Embeddable Postgres with real-time, reactive bindings.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 13,920</p>
            <p>Forks: 325</p>
            <p>Stars today: 58 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pglite.dev&quot; target=&quot;_blank&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot;
          srcset=&quot;https://raw.githubusercontent.com/electric-sql/pglite/main/docs/public/img/brand/logo.svg&quot;
      /&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot;
          srcset=&quot;https://raw.githubusercontent.com/electric-sql/pglite/main/docs/public/img/brand/logo-light.svg&quot;
      /&gt;
      &lt;img alt=&quot;ElectricSQL logo&quot;
          src=&quot;https://raw.githubusercontent.com/electric-sql/pglite/main/docs/public/img/brand/logo-light.svg&quot;
      /&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pglite.dev&quot;&gt;PGlite&lt;/a&gt; - the WASM build of Postgres from &lt;a href=&quot;https://electric-sql.com&quot; target=&quot;_blank&quot;&gt;ElectricSQL&lt;/a&gt;.&lt;br&gt;
  Build reactive, realtime, local-first apps directly on Postgres.
&lt;p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/electric-sql/pglite/stargazers/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/electric-sql/pglite?style=social&amp;label=Star&quot; /&gt;&lt;/a&gt;
  &lt;!-- &lt;a href=&quot;https://github.com/electric-sql/pglite/actions&quot;&gt;&lt;img src=&quot;https://github.com/electric-sql/pglite/workflows/CI/badge.svg&quot; alt=&quot;CI&quot;&gt;&lt;/a&gt; --&gt;
  &lt;a href=&quot;https://github.com/electric-sql/pglite/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-Apache_2.0-green&quot; alt=&quot;License - Apache 2.0&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;#roadmap&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/status-alpha-orange&quot; alt=&quot;Status - Alpha&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.electric-sql.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/933657521581858818?color=5969EA&amp;label=discord&quot; alt=&quot;Chat - Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/ElectricSQL&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/nestframework.svg?style=social&amp;label=Follow%20@ElectricSQL&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://fosstodon.org/@electric&quot;&gt;&lt;img src=&quot;https://img.shields.io/mastodon/follow/109599644322136925.svg?domain=https%3A%2F%2Ffosstodon.org&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

# PGlite - Postgres in WASM

![PGlite](https://raw.githubusercontent.com/electric-sql/pglite/main/screenshot.png)

PGlite is a WASM Postgres build packaged into a TypeScript client library that enables you to run Postgres in the browser, Node.js, Bun and Deno, with no need to install any other dependencies. It is only 3mb gzipped and has support for many Postgres extensions, including [pgvector](https://github.com/pgvector/pgvector).

```javascript
import { PGlite } from &quot;@electric-sql/pglite&quot;;

const db = new PGlite();
await db.query(&quot;select &#039;Hello world&#039; as message;&quot;);
// -&gt; { rows: [ { message: &quot;Hello world&quot; } ] }
```

It can be used as an ephemeral in-memory database, or with persistence either to the file system (Node/Bun/Deno) or indexedDB (Browser).

Unlike previous &quot;Postgres in the browser&quot; projects, PGlite does not use a Linux virtual machine - it is simply Postgres in WASM.

For full documentation and user guides see [pglite.dev](https://pglite.dev).

## Browser

It can be installed and imported using your usual package manager:

```js
import { PGlite } from &quot;@electric-sql/pglite&quot;;
```
or using a CDN such as JSDeliver:

```js
import { PGlite } from &quot;https://cdn.jsdelivr.net/npm/@electric-sql/pglite/dist/index.js&quot;;
```

Then for an in-memory Postgres:

```js
const db = new PGlite()
await db.query(&quot;select &#039;Hello world&#039; as message;&quot;)
// -&gt; { rows: [ { message: &quot;Hello world&quot; } ] }
```

or to persist the database to indexedDB:

```js
const db = new PGlite(&quot;idb://my-pgdata&quot;);
```

## Node/Bun/Deno

Install into your project:

**NodeJS**

```bash
npm install @electric-sql/pglite
```

**Bun**

```bash
bun install @electric-sql/pglite
```

**Deno**

```bash
deno add npm:@electric-sql/pglite
```

To use the in-memory Postgres:

```javascript
import { PGlite } from &quot;@electric-sql/pglite&quot;;

const db = new PGlite();
await db.query(&quot;select &#039;Hello world&#039; as message;&quot;);
// -&gt; { rows: [ { message: &quot;Hello world&quot; } ] }
```

or to persist to the filesystem:

```javascript
const db = new PGlite(&quot;./path/to/pgdata&quot;);
```

## How it works

PostgreSQL typically operates using a process forking model; whenever a client initiates a connection, a new process is forked to manage that connection. However, programs compiled with Emscripten - a C to WebAssembly (WASM) compiler - cannot fork new processes, and operates strictly in a single-process mode. As a result, PostgreSQL cannot be directly compiled to WASM for conventional operation.

Fortunately, PostgreSQL includes a &quot;single user mode&quot; primarily intended for command-line usage during bootstrapping and recovery procedures. Building upon this capability, PGlite introduces an input/output pathway that facilitates interaction with PostgreSQL when it is compiled to WASM within a JavaScript environment.

## Limitations

- PGlite is single user/connection.

## How to build PGlite and contribute

The build process of PGlite is split into two parts:

1. Building the Postgres WASM module.
2. Building the PGlite client library and other TypeScript packages.

Docker is required to build the WASM module, along with Node (v20 or above) and [pnpm](https://pnpm.io/) for package management and building the TypeScript packages.

To start checkout the repository and install dependencies:

```bash
git clone --recurse-submodules https://github.com/electric-sql/pglite
cd pglite
pnpm install
```

To build everything, we have the convenient `pnpm build:all` command in the root of the repository. This command will:

1. Use Docker to build the Postgres WASM module. The artifacts produced by this step are then copied to `/packages/pglite/release`.
2. Build the PGlite client library and other TypeScript packages.

To _only_ build the Postgres WASM module (i.e. point 1 above), run

```bash
pnpm wasm:build
```

If you don&#039;t want to build the WASM module and assorted WASM binaries from scratch, they are generated automatically on Github after each successful PR merge. You can download the latest binaries by going to the last successfully merged PR and clicking the link after the comment _Interim build files:_. Extract the files and place them under `packages/pglite/release` in your local repo copy.

To build all TypeScript packages (i.e. point 2 of the above), run:

```bash
pnpm ts:build
```

This will build all packages in the correct order based on their dependency relationships. You can now develop any individual package using the `build` and `test` scripts, as well as the `stylecheck` and `typecheck` scripts to ensure style and type validity.

Or alternatively to build a single package, move into the package directory and run:

```bash
cd packages/pglite
pnpm build
```

When ready to open a PR, run the following command at the root of the repository:
```bash
pnpm changeset
```
And follow the instructions to create an appropriate changeset. Please ensure any contributions that touch code are accompanied by a changeset.

## Acknowledgments

PGlite builds on the work of [Stas Kelvich](https://github.com/kelvich) of [Neon](https://neon.tech) in this [Postgres fork](https://github.com/electric-sql/postgres-wasm).

## Sponsors

Big shoutout to everybody supporting us!

### Blacksmith

&lt;a href=&quot;https://blacksmith.sh&quot;&gt;
  &lt;img src=&quot;./docs/img/blacksmith-logo-white-on-black.svg&quot; width=&quot;350px&quot;/&gt;
&lt;/a&gt;

## License

PGlite is dual-licensed under the terms of the¬†[Apache License 2.0](https://github.com/electric-sql/pglite/blob/main/LICENSE)¬†and the¬†[PostgreSQL License](https://github.com/electric-sql/pglite/blob/main/POSTGRES-LICENSE), you can choose which you prefer.

Changes to the¬†[Postgres source](https://github.com/electric-sql/postgres-wasm)¬†are licensed under the PostgreSQL License.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[actions/starter-workflows]]></title>
            <link>https://github.com/actions/starter-workflows</link>
            <guid>https://github.com/actions/starter-workflows</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[Accelerating new GitHub Actions workflows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/actions/starter-workflows">actions/starter-workflows</a></h1>
            <p>Accelerating new GitHub Actions workflows</p>
            <p>Language: TypeScript</p>
            <p>Stars: 10,971</p>
            <p>Forks: 6,617</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://avatars0.githubusercontent.com/u/44036562?s=100&amp;v=4&quot;/&gt; 
&lt;/p&gt;

## Starter Workflows

These are the workflow files for helping people get started with GitHub Actions.  They&#039;re presented whenever you start to create a new GitHub Actions workflow.

**If you want to get started with GitHub Actions, you can use these starter workflows by clicking the &quot;Actions&quot; tab in the repository where you want to create a workflow.**

&lt;img src=&quot;https://d3vv6lp55qjaqc.cloudfront.net/items/353A3p3Y2x3c2t2N0c01/Image%202019-08-27%20at%203.25.07%20PM.png&quot; max-width=&quot;75%&quot;/&gt;

### Note

Thank you for your interest in this GitHub repo, however, right now we are not taking contributions. 

We continue to focus our resources on strategic areas that help our customers be successful while making developers&#039; lives easier. While GitHub Actions remains a key part of this vision, we are allocating resources towards other areas of Actions and are not taking contributions to this repository at this time. The GitHub public roadmap is the best place to follow along for any updates on features we‚Äôre working on and what stage they‚Äôre in.

We are taking the following steps to better direct requests related to GitHub Actions, including:

1. We will be directing questions and support requests to our [Community Discussions area](https://github.com/orgs/community/discussions/categories/actions)

2. High Priority bugs can be reported through Community Discussions or you can report these to our support team https://support.github.com/contact/bug-report.

3. Security Issues should be handled as per our [security.md](security.md)

We will still provide security updates for this project and fix major breaking changes during this time.

You are welcome to still raise bugs in this repo.

### Directory structure

* [ci](ci): solutions for Continuous Integration workflows
* [deployments](deployments): solutions for Deployment workflows
* [automation](automation): solutions for automating workflows
* [code-scanning](code-scanning): solutions for [Code Scanning](https://github.com/features/security)
* [pages](pages): solutions for Pages workflows
* [icons](icons): svg icons for the relevant template

Each workflow must be written in YAML and have a `.yml` extension. They also need a corresponding `.properties.json` file that contains extra metadata about the workflow (this is displayed in the GitHub.com UI).

For example: `ci/django.yml` and `ci/properties/django.properties.json`.

### Valid properties

* `name`: the name shown in onboarding. This property is unique within the repository.
* `description`: the description shown in onboarding
* `iconName`: the icon name in the relevant folder, for example, `django` should have an icon `icons/django.svg`. Only SVG is supported at this time. Another option is to use [octicon](https://primer.style/octicons/). The format to use an octicon is `octicon &lt;&lt;icon name&gt;&gt;`. Example: `octicon person`
* `creator`: creator of the template shown in onboarding. All the workflow templates from an author will have the same `creator` field.
* `categories`: the categories that it will be shown under. Choose at least one category from the list [here](#categories). Further, choose the categories from the list of languages available [here](https://github.com/github/linguist/blob/master/lib/linguist/languages.yml) and the list of tech stacks available [here](https://github.com/github-starter-workflows/repo-analysis-partner/blob/main/tech_stacks.yml). When a user views the available templates, those templates that match the language and tech stacks will feature more prominently.

### Categories
* continuous-integration
* deployment
* testing
* code-quality
* code-review
* dependency-management
* monitoring
* Automation
* utilities
* Pages
* Hugo

### Variables
These variables can be placed in the starter workflow and will be substituted as detailed below:

* `$default-branch`: will substitute the branch from the repository, for example `main` and `master`
* `$protected-branches`: will substitute any protected branches from the repository
* `$cron-daily`: will substitute a valid but random time within the day

## How to test templates before publishing

### Disable template for public
The template author adds a `labels` array in the template&#039;s `properties.json` file with a label `preview`. This will hide the template from users, unless user uses query parameter `preview=true` in the URL.
Example `properties.json` file:
```json
{
    &quot;name&quot;: &quot;Node.js&quot;,
    &quot;description&quot;: &quot;Build and test a Node.js project with npm.&quot;,
    &quot;iconName&quot;: &quot;nodejs&quot;,
    &quot;categories&quot;: [&quot;Continuous integration&quot;, &quot;JavaScript&quot;, &quot;npm&quot;, &quot;React&quot;, &quot;Angular&quot;, &quot;Vue&quot;],
    &quot;labels&quot;: [&quot;preview&quot;]
}
```

For viewing the templates with `preview` label, provide query parameter `preview=true` to the  `new workflow` page URL. Eg. `https://github.com/&lt;owner&gt;/&lt;repo_name&gt;/actions/new?preview=true`.

### Enable template for public
Remove the `labels` array from `properties.json` file to publish the template to public
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[badlogic/pi-mono]]></title>
            <link>https://github.com/badlogic/pi-mono</link>
            <guid>https://github.com/badlogic/pi-mono</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[Monorepo for pi packages: TUI library, agent framework, and pod management CLI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/badlogic/pi-mono">badlogic/pi-mono</a></h1>
            <p>Monorepo for pi packages: TUI library, agent framework, and pod management CLI</p>
            <p>Language: TypeScript</p>
            <p>Stars: 402</p>
            <p>Forks: 45</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># Pi Monorepo

Tools for building AI agents and managing LLM deployments.

## Packages

| Package | Description |
|---------|-------------|
| **[@mariozechner/pi-ai](packages/ai)** | Unified multi-provider LLM API (OpenAI, Anthropic, Google, etc.) |
| **[@mariozechner/pi-agent](packages/agent)** | Agent runtime with tool calling and state management |
| **[@mariozechner/pi-coding-agent](packages/coding-agent)** | Interactive coding agent CLI |
| **[@mariozechner/pi-mom](packages/mom)** | Slack bot that delegates messages to the pi coding agent |
| **[@mariozechner/pi-tui](packages/tui)** | Terminal UI library with differential rendering |
| **[@mariozechner/pi-web-ui](packages/web-ui)** | Web components for AI chat interfaces |
| **[@mariozechner/pi-proxy](packages/proxy)** | CORS proxy for browser-based LLM API calls |
| **[@mariozechner/pi](packages/pods)** | CLI for managing vLLM deployments on GPU pods |

## Development

### Setup

```bash
npm install          # Install all dependencies
npm run build        # Build all packages
npm run check        # Lint, format, and type check
```

### CI

GitHub Actions runs on push to `main` and on pull requests. The workflow runs `npm run check` and `npm run test` for each package in parallel.

**Do not add LLM API keys as secrets to this repository.** Tests that require LLM access use `describe.skipIf()` to skip when API keys are missing. This is intentional:

- PRs from external contributors would have access to secrets in the CI environment
- Malicious PR code could exfiltrate API keys
- Tests that need LLM calls are skipped on CI and run locally by developers who have keys configured

If you need to run LLM-dependent tests, run them locally with your own API keys.

### Development

Start watch builds for all packages:
```bash
npm run dev
```

Then run with tsx:
```bash
cd packages/coding-agent &amp;&amp; npx tsx src/cli.ts
cd packages/pods &amp;&amp; npx tsx src/cli.ts
```

### Versioning (Lockstep)

**All packages MUST always have the same version number.** Use these commands to bump versions:

```bash
npm run version:patch    # 0.7.5 -&gt; 0.7.6
npm run version:minor    # 0.7.5 -&gt; 0.8.0
npm run version:major    # 0.7.5 -&gt; 1.0.0
```

These commands:
1. Update all package versions to the same number
2. Update inter-package dependency versions (e.g., `pi-agent` depends on `pi-ai@^0.7.7`)
3. Update `package-lock.json`

**Never manually edit version numbers.** The lockstep system ensures consistency across the monorepo.

### Publishing

Complete release process:

1. **Add changes to CHANGELOG.md** (if changes affect coding-agent):
   ```bash
   # Add your changes to the [Unreleased] section in packages/coding-agent/CHANGELOG.md
   # Always add new entries under [Unreleased], never under already-released versions
   ```

2. **Bump version** (all packages):
   ```bash
   npm run version:patch    # For bug fixes
   npm run version:minor    # For new features
   npm run version:major    # For breaking changes
   ```

3. **Finalize CHANGELOG.md for release** (if changes affect coding-agent):
   ```bash
   # Change [Unreleased] to the new version number with today&#039;s date
   # e.g., ## [0.7.16] - 2025-11-17
   # NEVER add entries to already-released version sections
   # Each version section is immutable once released
   ```

4. **Commit and tag**:
   ```bash
   git add .
   git commit -m &quot;Release v0.7.16&quot;
   git tag v0.7.16
   git push origin main
   git push origin v0.7.16
   ```

5. **Publish to npm**:
   ```bash
   npm run publish        # Publish all packages to npm
   ```

6. **Add new [Unreleased] section** (for next development cycle):
   ```bash
   # Add a new [Unreleased] section at the top of CHANGELOG.md
   # Commit: git commit -am &quot;Add [Unreleased] section&quot;
   ```

## License

MIT</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[sst/opencode]]></title>
            <link>https://github.com/sst/opencode</link>
            <guid>https://github.com/sst/opencode</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[The open source coding agent.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sst/opencode">sst/opencode</a></h1>
            <p>The open source coding agent.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 36,262</p>
            <p>Forks: 3,030</p>
            <p>Stars today: 397 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencode.ai&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;packages/console/app/src/asset/logo-ornate-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;packages/console/app/src/asset/logo-ornate-light.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;packages/console/app/src/asset/logo-ornate-light.svg&quot; alt=&quot;OpenCode logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;The AI coding agent built for the terminal.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencode.ai/discord&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;label=discord&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/opencode-ai&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/opencode-ai?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/sst/opencode/actions/workflows/publish.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/sst/opencode/publish.yml?style=flat-square&amp;branch=dev&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

[![OpenCode Terminal UI](packages/web/src/assets/lander/screenshot.png)](https://opencode.ai)

---

### Installation

```bash
# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
scoop bucket add extras; scoop install extras/opencode  # Windows
choco install opencode             # Windows
brew install opencode              # macOS and Linux
paru -S opencode-bin               # Arch Linux
mise use --pin -g ubi:sst/opencode # Any OS
nix run nixpkgs#opencode           # or github:sst/opencode for latest dev branch
```

&gt; [!TIP]
&gt; Remove versions older than 0.1.x before installing.

#### Installation Directory

The install script respects the following priority order for the installation path:

1. `$OPENCODE_INSTALL_DIR` - Custom installation directory
2. `$XDG_BIN_DIR` - XDG Base Directory Specification compliant path
3. `$HOME/bin` - Standard user binary directory (if exists or can be created)
4. `$HOME/.opencode/bin` - Default fallback

```bash
# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
```

### Agents

OpenCode includes two built-in agents you can switch between,
you can switch between these using the `Tab` key.

- **build** - Default, full access agent for development work
- **plan** - Read-only agent for analysis and code exploration
  - Denies file edits by default
  - Asks permission before running bash commands
  - Ideal for exploring unfamiliar codebases or planning changes

Also, included is a **general** subagent for complex searches and multi-step tasks.
This is used internally and can be invoked using `@general` in messages.

Learn more about [agents](https://opencode.ai/docs/agents).

### Documentation

For more info on how to configure OpenCode [**head over to our docs**](https://opencode.ai/docs).

### Contributing

If you&#039;re interested in contributing to OpenCode, please read our [contributing docs](./CONTRIBUTING.md) before submitting a pull request.

### Building on OpenCode

If you are working on a project that&#039;s related to OpenCode and is using &quot;opencode&quot; as a part of its name; for example, &quot;opencode-dashboard&quot; or &quot;opencode-mobile&quot;, please add a note to your README to clarify that it is not built by the OpenCode team and is not affiliated with us in anyway.

### FAQ

#### How is this different than Claude Code?

It&#039;s very similar to Claude Code in terms of capability. Here are the key differences:

- 100% open source
- Not coupled to any provider. Although we recommend the models we provide through [OpenCode Zen](https://opencode.ai/zen); OpenCode can be used with Claude, OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.
- Out of the box LSP support
- A focus on TUI. OpenCode is built by neovim users and the creators of [terminal.shop](https://terminal.shop); we are going to push the limits of what&#039;s possible in the terminal.
- A client/server architecture. This for example can allow OpenCode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.

#### What&#039;s the other repo?

The other confusingly named repo has no relation to this one. You can [read the story behind it here](https://x.com/thdxr/status/1933561254481666466).

---

**Join our community** [Discord](https://discord.gg/opencode) | [X.com](https://x.com/opencode)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[DayuanJiang/next-ai-draw-io]]></title>
            <link>https://github.com/DayuanJiang/next-ai-draw-io</link>
            <guid>https://github.com/DayuanJiang/next-ai-draw-io</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DayuanJiang/next-ai-draw-io">DayuanJiang/next-ai-draw-io</a></h1>
            <p>A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 4,256</p>
            <p>Forks: 480</p>
            <p>Stars today: 402 stars today</p>
            <h2>README</h2><pre># Next AI Draw.io

&lt;div align=&quot;center&quot;&gt;

**AI-Powered Diagram Creation Tool - Chat, Draw, Visualize**

English | [‰∏≠Êñá](./README_CN.md) | [Êó•Êú¨Ë™û](./README_JA.md)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Next.js](https://img.shields.io/badge/Next.js-15.x-black)](https://nextjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.x-blue)](https://www.typescriptlang.org/)
[![Sponsor](https://img.shields.io/badge/Sponsor-‚ù§-ea4aaa)](https://github.com/sponsors/DayuanJiang)

[üöÄ Live Demo](https://next-ai-drawio.jiang.jp/)

&lt;/div&gt;

A Next.js web application that integrates AI capabilities with draw.io diagrams. Create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.

https://github.com/user-attachments/assets/b2eef5f3-b335-4e71-a755-dc2e80931979

## Features

-   **LLM-Powered Diagram Creation**: Leverage Large Language Models to create and manipulate draw.io diagrams directly through natural language commands
-   **Image-Based Diagram Replication**: Upload existing diagrams or images and have the AI replicate and enhance them automatically
-   **Diagram History**: Comprehensive version control that tracks all changes, allowing you to view and restore previous versions of your diagrams before the AI editing.
-   **Interactive Chat Interface**: Communicate with AI to refine your diagrams in real-time
-   **AWS Architecture Diagram Support**: Specialized support for generating AWS architecture diagrams
-   **Animated Connectors**: Create dynamic and animated connectors between diagram elements for better visualization

## **Examples**

Here are some example prompts and their generated diagrams:

&lt;div align=&quot;center&quot;&gt;
&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td colspan=&quot;2&quot; valign=&quot;top&quot; align=&quot;center&quot;&gt;
      &lt;strong&gt;Animated transformer connectors&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Give me a **animated connector** diagram of transformer&#039;s architecture.&lt;/p&gt;
      &lt;img src=&quot;./public/animated_connectors.svg&quot; alt=&quot;Transformer Architecture with Animated Connectors&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;GCP architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a GCP architecture diagram with **GCP icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/gcp_demo.svg&quot; alt=&quot;GCP Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;AWS architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a AWS architecture diagram with **AWS icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/aws_demo.svg&quot; alt=&quot;AWS Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;Azure architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a Azure architecture diagram with **Azure icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/azure_demo.svg&quot; alt=&quot;Azure Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;Cat sketch prompt&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Draw a cute cat for me.&lt;/p&gt;
      &lt;img src=&quot;./public/cat_demo.svg&quot; alt=&quot;Cat Drawing&quot; width=&quot;240&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;

## How It Works

The application uses the following technologies:

-   **Next.js**: For the frontend framework and routing
-   **Vercel AI SDK** (`ai` + `@ai-sdk/*`): For streaming AI responses and multi-provider support
-   **react-drawio**: For diagram representation and manipulation

Diagrams are represented as XML that can be rendered in draw.io. The AI processes your commands and generates or modifies this XML accordingly.

## Multi-Provider Support

-   AWS Bedrock (default)
-   OpenAI
-   Anthropic
-   Google AI
-   Azure OpenAI
-   Ollama
-   OpenRouter
-   DeepSeek

All providers except AWS Bedrock and OpenRouter support custom endpoints.

üìñ **[Detailed Provider Configuration Guide](./docs/ai-providers.md)** - See setup instructions for each provider.

**Model Requirements**: This task requires strong model capabilities for generating long-form text with strict formatting constraints (draw.io XML). Recommended models include Claude Sonnet 4.5, GPT-4o, Gemini 2.0, and DeepSeek V3/R1.

Note that `claude-sonnet-4-5` has trained on draw.io diagrams with AWS logos, so if you want to create AWS architecture diagrams, this is the best choice.

## Getting Started

### Run with Docker (Recommended)

If you just want to run it locally, the best way is to use Docker.

First, install Docker if you haven&#039;t already: [Get Docker](https://docs.docker.com/get-docker/)

Then run:

```bash
docker run -d -p 3000:3000 \
  -e AI_PROVIDER=openai \
  -e AI_MODEL=gpt-4o \
  -e OPENAI_API_KEY=your_api_key \
  ghcr.io/dayuanjiang/next-ai-draw-io:latest
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

Replace the environment variables with your preferred AI provider configuration. See [Multi-Provider Support](#multi-provider-support) for available options.

### Installation

1. Clone the repository:

```bash
git clone https://github.com/DayuanJiang/next-ai-draw-io
cd next-ai-draw-io
```

2. Install dependencies:

```bash
npm install
# or
yarn install
```

3. Configure your AI provider:

Create a `.env.local` file in the root directory:

```bash
cp env.example .env.local
```

Edit `.env.local` and configure your chosen provider:

-   Set `AI_PROVIDER` to your chosen provider (bedrock, openai, anthropic, google, azure, ollama, openrouter, deepseek)
-   Set `AI_MODEL` to the specific model you want to use
-   Add the required API keys for your provider
-   `TEMPERATURE`: Optional temperature setting (e.g., `0` for deterministic output). Leave unset for models that don&#039;t support it (e.g., reasoning models).
-   `ACCESS_CODE_LIST`: Optional access password(s), can be comma-separated for multiple passwords.

&gt; Warning: If you do not set `ACCESS_CODE_LIST`, anyone can access your deployed site directly, which may lead to rapid depletion of your token. It is recommended to set this option.

See the [Provider Configuration Guide](./docs/ai-providers.md) for detailed setup instructions for each provider.

4. Run the development server:

```bash
npm run dev
```

5. Open [http://localhost:3000](http://localhost:3000) in your browser to see the application.

## Deployment

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new) from the creators of Next.js.

Check out the [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.

Or you can deploy by this button.
[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io)

Be sure to **set the environment variables** in the Vercel dashboard as you did in your local `.env.local` file.

## Project Structure

```
app/                  # Next.js App Router
  api/chat/           # Chat API endpoint with AI tools
  page.tsx            # Main page with DrawIO embed
components/           # React components
  chat-panel.tsx      # Chat interface with diagram control
  chat-input.tsx      # User input component with file upload
  history-dialog.tsx  # Diagram version history viewer
  ui/                 # UI components (buttons, cards, etc.)
contexts/             # React context providers
  diagram-context.tsx # Global diagram state management
lib/                  # Utility functions and helpers
  ai-providers.ts     # Multi-provider AI configuration
  utils.ts            # XML processing and conversion utilities
public/               # Static assets including example images
```

## TODOs

-   [x] Allow the LLM to modify the XML instead of generating it from scratch everytime.
-   [x] Improve the smoothness of shape streaming updates.
-   [x] Add multiple AI provider support (OpenAI, Anthropic, Google, Azure, Ollama)
-   [x] Solve the bug that generation will fail for session that longer than 60s.
-   [ ] Add API config on the UI.

## Support &amp; Contact

If you find this project useful, please consider [sponsoring](https://github.com/sponsors/DayuanJiang) to help me host the live demo site!

For support or inquiries, please open an issue on the GitHub repository or contact the maintainer at:

-   Email: me[at]jiang.jp

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=DayuanJiang/next-ai-draw-io&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#DayuanJiang/next-ai-draw-io&amp;type=date&amp;legend=top-left)

---
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[software-mansion/react-native-reanimated]]></title>
            <link>https://github.com/software-mansion/react-native-reanimated</link>
            <guid>https://github.com/software-mansion/react-native-reanimated</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[React Native's Animated library reimplemented]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/software-mansion/react-native-reanimated">software-mansion/react-native-reanimated</a></h1>
            <p>React Native's Animated library reimplemented</p>
            <p>Language: TypeScript</p>
            <p>Stars: 10,489</p>
            <p>Forks: 1,420</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://user-images.githubusercontent.com/16062886/117443145-ff868480-af37-11eb-8680-648bccf0d0ce.png&quot; alt=&quot;React Native Reanimated by Software Mansion&quot; width=&quot;100%&quot;&gt;

### Create smooth animations with an excellent developer experience.

&gt; Reanimated 4 is here! Check out our [documentation page](https://docs.swmansion.com/react-native-reanimated/) for more information

### Nightly CI state

[![NPM Reanimated publish nightly](https://github.com/software-mansion/react-native-reanimated/actions/workflows/npm-reanimated-publish-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/npm-reanimated-publish-nightly.yml)
[![NPM Worklets publish [Nightly]](https://github.com/software-mansion/react-native-reanimated/actions/workflows/npm-worklets-publish-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/npm-worklets-publish-nightly.yml)
[![Lint clang-tidy [Nightly]](https://github.com/software-mansion/react-native-reanimated/actions/workflows/lint-clang-tidy-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/lint-clang-tidy-nightly.yml)
[![Reanimated compatibility check](https://github.com/software-mansion/react-native-reanimated/actions/workflows/reanimated-compatibility-check-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/reanimated-compatibility-check-nightly.yml)
[![Use frameworks Reanimated build check [Nightly]](https://github.com/software-mansion/react-native-reanimated/actions/workflows/use-frameworks-reanimated-build-check-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/use-frameworks-reanimated-build-check-nightly.yml)
[![React Native nightly Reanimated build check](https://github.com/software-mansion/react-native-reanimated/actions/workflows/react-native-nightly-reanimated-build-check-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/react-native-nightly-reanimated-build-check-nightly.yml)
[![Expo DevClient build check](https://github.com/software-mansion/react-native-reanimated/actions/workflows/expo-devclient-build-check-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/expo-devclient-build-check-nightly.yml)
[![Reanimated TypeScript compatibility test](https://github.com/software-mansion/react-native-reanimated/actions/workflows/reanimated-typescript-compatibility-test-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/reanimated-typescript-compatibility-test-nightly.yml)
[![Windows hosted app Reanimated build check](https://github.com/software-mansion/react-native-reanimated/actions/workflows/windows-hosted-app-reanimated-build-check-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/windows-hosted-app-reanimated-build-check-nightly.yml)
[![Worklets Bundle Mode build check [Nightly]](https://github.com/software-mansion/react-native-reanimated/actions/workflows/worklets-bundle-mode-build-check-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/worklets-bundle-mode-build-check-nightly.yml)
[![URL validation](https://github.com/software-mansion/react-native-reanimated/actions/workflows/url-validation-nightly.yml/badge.svg)](https://github.com/software-mansion/react-native-reanimated/actions/workflows/url-validation-nightly.yml)

## Installation

Check out the [installation](https://docs.swmansion.com/react-native-reanimated/docs/fundamentals/getting-started/#installation) section of our docs for the detailed installation instructions.

## Compatibility

React Native Reanimated 4.x supports only the [New React Native architecture](https://reactnative.dev/architecture/landing-page) and three latest React Native versions.

If your app still runs on the old architecture, please consider adopting the New Architecture or stay with latest 3.x release.

## Documentation

Check out our dedicated documentation page for info about this library, API reference and more: [https://docs.swmansion.com/react-native-reanimated/](https://docs.swmansion.com/react-native-reanimated/)

## Examples

The source code for the example (showcase) app is under the [`apps/common-app`](https://github.com/software-mansion/react-native-reanimated/blob/main/apps/common-app/) directory.
If you want to play with the API but don&#039;t feel like trying it on a real app, you can run the example project. Check [Example README](apps/fabric-example/README.md) for installation instructions.

## License

Reanimated library is licensed under [The MIT License](LICENSE).

## Credits

This project has been built and is maintained thanks to the support from [Shopify](https://shopify.com), [Expo.io](https://expo.io) and [Software Mansion](https://swmansion.com)

[![shopify](https://avatars1.githubusercontent.com/u/8085?v=3&amp;s=100 &#039;Shopify.com&#039;)](https://shopify.com)
[![expo](https://avatars2.githubusercontent.com/u/12504344?v=3&amp;s=100 &#039;Expo.io&#039;)](https://expo.io)
[![swm](https://logo.swmansion.com/logo?color=white&amp;variant=desktop&amp;width=150&amp;tag=react-native-reanimated-github &#039;Software Mansion&#039;)](https://swmansion.com)

## Community Discord

[Join the Software Mansion Community Discord](https://discord.swmansion.com) to chat about Reanimated or other Software Mansion libraries.

## Reanimated is created by Software Mansion

Since 2012 [Software Mansion](https://swmansion.com) is a software agency with experience in building web and mobile apps. We are Core React Native Contributors and experts in dealing with all kinds of React Native issues. We can help you build your next dream product ‚Äì [Hire us](https://swmansion.com/contact/projects?utm_source=reanimated&amp;utm_medium=readme).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[actualbudget/actual]]></title>
            <link>https://github.com/actualbudget/actual</link>
            <guid>https://github.com/actualbudget/actual</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[A local-first personal finance app]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/actualbudget/actual">actualbudget/actual</a></h1>
            <p>A local-first personal finance app</p>
            <p>Language: TypeScript</p>
            <p>Stars: 23,580</p>
            <p>Forks: 1,986</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/demo.png&quot; alt=&quot;Actualbudget&quot; /&gt;
&lt;/p&gt;

## Getting Started

Actual is a local-first personal finance tool. It is 100% free and open-source, written in NodeJS, it has a synchronization element so that all your changes can move between devices without any heavy lifting.

If you are interested in contributing, or want to know how development works, see our [contributing](https://actualbudget.org/docs/contributing/) document we would love to have you.

Want to say thanks? Click the ‚≠ê at the top of the page.

## Key Links

- Actual [discord](https://discord.gg/pRYNYr4W5A) community.
- Actual [Community Documentation](https://actualbudget.org/docs)
- [Frequently asked questions](https://actualbudget.org/docs/faq)

## Installation

There are four ways to deploy Actual:

1. One-click deployment [via PikaPods](https://www.pikapods.com/pods?run=actual) (~1.40 $/month) - recommended for non-technical users
1. Managed hosting [via Fly.io](https://actualbudget.org/docs/install/fly) (~1.50 $/month)
1. Self-hosted by using [a Docker image](https://actualbudget.org/docs/install/docker)
1. Local-only apps - [downloadable Windows, Mac and Linux apps](https://actualbudget.org/download/) you can run on your device

Learn more in the [installation instructions docs](https://actualbudget.org/docs/install/).

## Ready to Start Budgeting?

Read about [Envelope budgeting](https://actualbudget.org/docs/getting-started/envelope-budgeting) to know more about the idea behind Actual Budget.

### Are you new to budgeting or want to start fresh?

Check out the community&#039;s [Starting Fresh](https://actualbudget.org/docs/getting-started/starting-fresh) guide so you can quickly get up and running!

### Are you migrating from other budgeting apps?

Check out the community&#039;s [Migration](https://actualbudget.org/docs/migration/) guide to start jumping on the Actual Budget train!

## Documentation

We have a wide range of documentation on how to use Actual, this is all available in our [Community Documentation](https://actualbudget.org/docs), this includes topics on Budgeting, Account Management, Tips &amp; Tricks and some documentation for developers.

## Contributing

Actual is a community driven product. Learn more about [contributing to Actual](https://actualbudget.org/docs/contributing/).

### Code structure

The Actual app is split up into a few packages:

- loot-core - The core application that runs on any platform
- desktop-client - The desktop UI
- desktop-electron - The desktop app

More information on the project structure is available in our [community documentation](https://actualbudget.org/docs/contributing/project-details).

### Feature Requests

Current feature requests can be seen [here](https://github.com/actualbudget/actual/issues?q=is%3Aissue+label%3A%22needs+votes%22+sort%3Areactions-%2B1-desc).
Vote for your favorite requests by reacting :+1: to the top comment of the request.

To add new feature requests, open a new Issue of the &quot;Feature Request&quot; type.

### Translation

Make Actual Budget accessible to more people by helping with the [Internationalization](https://actualbudget.org/docs/contributing/i18n/) of Actual. We are using a crowd sourcing tool to manage the translations, see our [Weblate Project](https://hosted.weblate.org/projects/actualbudget/). Weblate proudly supports open-source software projects through their [Libre plan](https://weblate.org/en/hosting/#libre).

&lt;a href=&quot;https://hosted.weblate.org/engage/actualbudget/&quot;&gt;
&lt;img src=&quot;https://hosted.weblate.org/widget/actualbudget/actual/287x66-grey.png&quot; alt=&quot;Translation status&quot; /&gt;
&lt;/a&gt;

## Repo Activity

![Alt](https://repobeats.axiom.co/api/embed/e20537dd8b74956f86736726ccfbc6f0565bec22.svg &#039;Repobeats analytics image&#039;)

## Sponsors

Thanks to our wonderful sponsors who make Actual Budget possible!

&lt;a href=&quot;https://www.netlify.com&quot;&gt; &lt;img src=&quot;https://www.netlify.com/v3/img/components/netlify-color-accent.svg&quot; alt=&quot;Deploys by Netlify&quot; /&gt; &lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[farion1231/cc-switch]]></title>
            <link>https://github.com/farion1231/cc-switch</link>
            <guid>https://github.com/farion1231/cc-switch</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[A cross-platform desktop All-in-One assistant tool for Claude Code, Codex & Gemini CLI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/farion1231/cc-switch">farion1231/cc-switch</a></h1>
            <p>A cross-platform desktop All-in-One assistant tool for Claude Code, Codex & Gemini CLI.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 5,908</p>
            <p>Forks: 387</p>
            <p>Stars today: 64 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# All-in-One Assistant for Claude Code, Codex &amp; Gemini CLI

[![Version](https://img.shields.io/badge/version-3.8.2-blue.svg)](https://github.com/farion1231/cc-switch/releases)
[![Trending](https://img.shields.io/badge/üî•_TypeScript_Trending-Daily%20%7C%20Weekly%20%7C%20Monthly-ff6b6b.svg)](https://github.com/trending/typescript)
[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/farion1231/cc-switch/releases)
[![Built with Tauri](https://img.shields.io/badge/built%20with-Tauri%202-orange.svg)](https://tauri.app/)
[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/farion1231/cc-switch/total)](https://github.com/farion1231/cc-switch/releases/latest)

&lt;a href=&quot;https://trendshift.io/repositories/15372&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15372&quot; alt=&quot;farion1231%2Fcc-switch | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

English | [‰∏≠Êñá](README_ZH.md) | [Êó•Êú¨Ë™û](README_JA.md) | [Changelog](CHANGELOG.md)

**From Provider Switcher to All-in-One AI CLI Management Platform**

Unified management for Claude Code, Codex &amp; Gemini CLI provider configurations, MCP servers, Skills extensions, and system prompts.

&lt;/div&gt;

## ‚ù§Ô∏èSponsor

![Zhipu GLM](assets/partners/banners/glm-en.jpg)

This project is sponsored by Z.ai, supporting us with their GLM CODING PLAN.

GLM CODING PLAN is a subscription service designed for AI coding, starting at just $3/month. It provides access to their flagship GLM-4.6 model across 10+ popular AI coding tools (Claude Code, Cline, Roo Code, etc.), offering developers top-tier, fast, and stable coding experiences.

Get 10% OFF the GLM CODING PLAN with [this link](https://z.ai/subscribe?ic=8JVLJQFSKB)!

---

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;img src=&quot;assets/partners/logos/packycode.png&quot; alt=&quot;PackyCode&quot; width=&quot;150&quot;&gt;&lt;/td&gt;
&lt;td&gt;Thanks to PackyCode for sponsoring this project! PackyCode is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more. PackyCode provides special discounts for our software users: register using &lt;a href=&quot;https://www.packyapi.com/register?aff=cc-switch&quot;&gt;this link&lt;/a&gt; and enter the &quot;cc-switch&quot; promo code during recharge to get 10% off.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;img src=&quot;assets/partners/logos/sds-en.png&quot; alt=&quot;ShanDianShuo&quot; width=&quot;150&quot;&gt;&lt;/td&gt;
&lt;td&gt;Thanks to ShanDianShuo for sponsoring this project! ShanDianShuo is a local-first AI voice input: Millisecond latency, data stays on device, 4x faster than typing, AI-powered correction, Privacy-first, completely free. Doubles your coding efficiency with Claude Code! &lt;a href=&quot;https://www.shandianshuo.cn&quot;&gt;Free download&lt;/a&gt; for Mac/Win&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

## Screenshots

|                  Main Interface                   |                  Add Provider                  |
| :-----------------------------------------------: | :--------------------------------------------: |
| ![Main Interface](assets/screenshots/main-en.png) | ![Add Provider](assets/screenshots/add-en.png) |

## Features

### Current Version: v3.8.2 | [Full Changelog](CHANGELOG.md) | [Release Notes](docs/release-note-v3.8.0-en.md)

**v3.8.0 Major Update (2025-11-28)**

**Persistence Architecture Upgrade &amp; Brand New UI**

- **SQLite + JSON Dual-layer Architecture**
  - Migrated from JSON file storage to SQLite + JSON dual-layer structure
  - Syncable data (providers, MCP, Prompts, Skills) stored in SQLite
  - Device-level data (window state, local paths) stored in JSON
  - Lays the foundation for future cloud sync functionality
  - Schema version management for database migrations

- **Brand New User Interface**
  - Completely redesigned interface layout
  - Unified component styles and smoother animations
  - Optimized visual hierarchy
  - Tailwind CSS downgraded from v4 to v3.4 for better browser compatibility

- **Japanese Language Support**
  - Added Japanese interface support (now supports Chinese/English/Japanese)

- **Auto Launch on Startup**
  - One-click enable/disable in settings
  - Platform-native APIs (Registry/LaunchAgent/XDG autostart)

- **Skills Recursive Scanning**
  - Support for multi-level directory structures
  - Allow same-named skills from different repositories

- **Critical Bug Fixes**
  - Fixed custom endpoints lost when updating providers
  - Fixed Gemini configuration write issues
  - Fixed Linux WebKitGTK rendering issues

**v3.7.0 Highlights**

**Six Core Features, 18,000+ Lines of New Code**

- **Gemini CLI Integration**
  - Third supported AI CLI (Claude Code / Codex / Gemini)
  - Dual-file configuration support (`.env` + `settings.json`)
  - Complete MCP server management
  - Presets: Google Official (OAuth) / PackyCode / Custom

- **Claude Skills Management System**
  - Auto-scan skills from GitHub repositories (3 pre-configured curated repos)
  - One-click install/uninstall to `~/.claude/skills/`
  - Custom repository support + subdirectory scanning
  - Complete lifecycle management (discover/install/update)

- **Prompts Management System**
  - Multi-preset system prompt management (unlimited presets, quick switching)
  - Cross-app support (Claude: `CLAUDE.md` / Codex: `AGENTS.md` / Gemini: `GEMINI.md`)
  - Markdown editor (CodeMirror 6 + real-time preview)
  - Smart backfill protection, preserves manual modifications

- **MCP v3.7.0 Unified Architecture**
  - Single panel manages MCP servers across three applications
  - New SSE (Server-Sent Events) transport type
  - Smart JSON parser + Codex TOML format auto-correction
  - Unified import/export + bidirectional sync

- **Deep Link Protocol**
  - `ccswitch://` protocol registration (all platforms)
  - One-click import provider configs via shared links
  - Security validation + lifecycle integration

- **Environment Variable Conflict Detection**
  - Auto-detect cross-app configuration conflicts (Claude/Codex/Gemini/MCP)
  - Visual conflict indicators + resolution suggestions
  - Override warnings + backup before changes

**Core Capabilities**

- **Provider Management**: One-click switching between Claude Code, Codex, and Gemini API configurations
- **Speed Testing**: Measure API endpoint latency with visual quality indicators
- **Import/Export**: Backup and restore configs with auto-rotation (keep 10 most recent)
- **i18n Support**: Complete Chinese/English localization (UI, errors, tray)
- **Claude Plugin Sync**: One-click apply/restore Claude plugin configurations

**v3.6 Highlights**

- Provider duplication &amp; drag-and-drop sorting
- Multi-endpoint management &amp; custom config directory (cloud sync ready)
- Granular model configuration (4-tier: Haiku/Sonnet/Opus/Custom)
- WSL environment support with auto-sync on directory change
- 100% hooks test coverage &amp; complete architecture refactoring

**System Features**

- System tray with quick switching
- Single instance daemon
- Built-in auto-updater
- Atomic writes with rollback protection

## Download &amp; Installation

### System Requirements

- **Windows**: Windows 10 and above
- **macOS**: macOS 10.15 (Catalina) and above
- **Linux**: Ubuntu 22.04+ / Debian 11+ / Fedora 34+ and other mainstream distributions

### Windows Users

Download the latest `CC-Switch-v{version}-Windows.msi` installer or `CC-Switch-v{version}-Windows-Portable.zip` portable version from the [Releases](../../releases) page.

### macOS Users

**Method 1: Install via Homebrew (Recommended)**

```bash
brew tap farion1231/ccswitch
brew install --cask cc-switch
```

Update:

```bash
brew upgrade --cask cc-switch
```

**Method 2: Manual Download**

Download `CC-Switch-v{version}-macOS.zip` from the [Releases](../../releases) page and extract to use.

&gt; **Note**: Since the author doesn&#039;t have an Apple Developer account, you may see an &quot;unidentified developer&quot; warning on first launch. Please close it first, then go to &quot;System Settings&quot; ‚Üí &quot;Privacy &amp; Security&quot; ‚Üí click &quot;Open Anyway&quot;, and you&#039;ll be able to open it normally afterwards.

### ArchLinux Áî®Êà∑

**Install via paru (Recommended)**

```bash
paru -S cc-switch-bin
```

### Linux Users

Download the latest `CC-Switch-v{version}-Linux.deb` package or `CC-Switch-v{version}-Linux.AppImage` from the [Releases](../../releases) page.

## Quick Start

### Basic Usage

1. **Add Provider**: Click &quot;Add Provider&quot; ‚Üí Choose preset or create custom configuration
2. **Switch Provider**:
   - Main UI: Select provider ‚Üí Click &quot;Enable&quot;
   - System Tray: Click provider name directly (instant effect)
3. **Takes Effect**: Restart your terminal or Claude Code / Codex / Gemini clients to apply changes
4. **Back to Official**: Select the &quot;Official Login&quot; preset (Claude/Codex) or &quot;Google Official&quot; preset (Gemini), restart the corresponding client, then follow its login/OAuth flow

### MCP Management

- **Location**: Click &quot;MCP&quot; button in top-right corner
- **Add Server**:
  - Use built-in templates (mcp-fetch, mcp-filesystem, etc.)
  - Support stdio / http / sse transport types
  - Configure independent MCP servers for different apps
- **Enable/Disable**: Toggle switches to control which servers sync to live config
- **Sync**: Enabled servers auto-sync to each app&#039;s live files
- **Import/Export**: Import existing MCP servers from Claude/Codex/Gemini config files

### Skills Management (v3.7.0 New)

- **Location**: Click &quot;Skills&quot; button in top-right corner
- **Discover Skills**:
  - Auto-scan pre-configured GitHub repositories (Anthropic official, ComposioHQ, community, etc.)
  - Add custom repositories (supports subdirectory scanning)
- **Install Skills**: Click &quot;Install&quot; to one-click install to `~/.claude/skills/`
- **Uninstall Skills**: Click &quot;Uninstall&quot; to safely remove and clean up state
- **Manage Repositories**: Add/remove custom GitHub repositories

### Prompts Management (v3.7.0 New)

- **Location**: Click &quot;Prompts&quot; button in top-right corner
- **Create Presets**:
  - Create unlimited system prompt presets
  - Use Markdown editor to write prompts (syntax highlighting + real-time preview)
- **Switch Presets**: Select preset ‚Üí Click &quot;Activate&quot; to apply immediately
- **Sync Mechanism**:
  - Claude: `~/.claude/CLAUDE.md`
  - Codex: `~/.codex/AGENTS.md`
  - Gemini: `~/.gemini/GEMINI.md`
- **Protection Mechanism**: Auto-save current prompt content before switching, preserves manual modifications

### Configuration Files

**Claude Code**

- Live config: `~/.claude/settings.json` (or `claude.json`)
- API key field: `env.ANTHROPIC_AUTH_TOKEN` or `env.ANTHROPIC_API_KEY`
- MCP servers: `~/.claude.json` ‚Üí `mcpServers`

**Codex**

- Live config: `~/.codex/auth.json` (required) + `config.toml` (optional)
- API key field: `OPENAI_API_KEY` in `auth.json`
- MCP servers: `~/.codex/config.toml` ‚Üí `[mcp_servers]` tables

**Gemini**

- Live config: `~/.gemini/.env` (API key) + `~/.gemini/settings.json` (auth mode)
- API key field: `GEMINI_API_KEY` or `GOOGLE_GEMINI_API_KEY` in `.env`
- Environment variables: Support `GOOGLE_GEMINI_BASE_URL`, `GEMINI_MODEL`, etc.
- MCP servers: `~/.gemini/settings.json` ‚Üí `mcpServers`
- Tray quick switch: Each provider switch rewrites `~/.gemini/.env`, no need to restart Gemini CLI

**CC Switch Storage (v3.8.0 New Architecture)**

- Database (SSOT): `~/.cc-switch/cc-switch.db` (SQLite, stores providers, MCP, Prompts, Skills)
- Local settings: `~/.cc-switch/settings.json` (device-level settings)
- Backups: `~/.cc-switch/backups/` (auto-rotate, keep 10)

### Cloud Sync Setup

1. Go to Settings ‚Üí &quot;Custom Configuration Directory&quot;
2. Choose your cloud sync folder (Dropbox, OneDrive, iCloud, etc.)
3. Restart app to apply
4. Repeat on other devices to enable cross-device sync

&gt; **Note**: First launch auto-imports existing Claude/Codex configs as default provider.

## Architecture Overview

### Design Principles

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (React + TS)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Components  ‚îÇ  ‚îÇ    Hooks     ‚îÇ  ‚îÇ  TanStack Query  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   (UI)      ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Logic) ‚îÇ‚îÄ‚îÄ‚îÇ   (Cache/Sync)   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ Tauri IPC
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Backend (Tauri + Rust)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Commands   ‚îÇ  ‚îÇ   Services   ‚îÇ  ‚îÇ  Models/Config   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ (API Layer) ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Layer) ‚îÇ‚îÄ‚îÄ‚îÇ     (Data)       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Core Design Patterns**

- **SSOT** (Single Source of Truth): All data stored in `~/.cc-switch/cc-switch.db` (SQLite)
- **Dual-layer Storage**: SQLite for syncable data, JSON for device-level settings
- **Dual-way Sync**: Write to live files on switch, backfill from live when editing active provider
- **Atomic Writes**: Temp file + rename pattern prevents config corruption
- **Concurrency Safe**: Mutex-protected database connection avoids race conditions
- **Layered Architecture**: Clear separation (Commands ‚Üí Services ‚Üí DAO ‚Üí Database)

**Key Components**

- **ProviderService**: Provider CRUD, switching, backfill, sorting
- **McpService**: MCP server management, import/export, live file sync
- **ConfigService**: Config import/export, backup rotation
- **SpeedtestService**: API endpoint latency measurement

**v3.6 Refactoring**

- Backend: 5-phase refactoring (error handling ‚Üí command split ‚Üí tests ‚Üí services ‚Üí concurrency)
- Frontend: 4-stage refactoring (test infra ‚Üí hooks ‚Üí components ‚Üí cleanup)
- Testing: 100% hooks coverage + integration tests (vitest + MSW)

## Development

### Environment Requirements

- Node.js 18+
- pnpm 8+
- Rust 1.85+
- Tauri CLI 2.8+

### Development Commands

```bash
# Install dependencies
pnpm install

# Dev mode (hot reload)
pnpm dev

# Type check
pnpm typecheck

# Format code
pnpm format

# Check code format
pnpm format:check

# Run frontend unit tests
pnpm test:unit

# Run tests in watch mode (recommended for development)
pnpm test:unit:watch

# Build application
pnpm build

# Build debug version
pnpm tauri build --debug
```

### Rust Backend Development

```bash
cd src-tauri

# Format Rust code
cargo fmt

# Run clippy checks
cargo clippy

# Run backend tests
cargo test

# Run specific tests
cargo test test_name

# Run tests with test-hooks feature
cargo test --features test-hooks
```

### Testing Guide (v3.6 New)

**Frontend Testing**:

- Uses **vitest** as test framework
- Uses **MSW (Mock Service Worker)** to mock Tauri API calls
- Uses **@testing-library/react** for component testing

**Test Coverage**:

- Hooks unit tests (100% coverage)
  - `useProviderActions` - Provider operations
  - `useMcpActions` - MCP management
  - `useSettings` series - Settings management
  - `useImportExport` - Import/export
- Integration tests
  - App main application flow
  - SettingsDialog complete interaction
  - MCP panel functionality

**Running Tests**:

```bash
# Run all tests
pnpm test:unit

# Watch mode (auto re-run)
pnpm test:unit:watch

# With coverage report
pnpm test:unit --coverage
```

## Tech Stack

**Frontend**: React 18 ¬∑ TypeScript ¬∑ Vite ¬∑ TailwindCSS 4 ¬∑ TanStack Query v5 ¬∑ react-i18next ¬∑ react-hook-form ¬∑ zod ¬∑ shadcn/ui ¬∑ @dnd-kit

**Backend**: Tauri 2.8 ¬∑ Rust ¬∑ serde ¬∑ tokio ¬∑ thiserror ¬∑ tauri-plugin-updater/process/dialog/store/log

**Testing**: vitest ¬∑ MSW ¬∑ @testing-library/react

## Project Structure

```
‚îú‚îÄ‚îÄ src/                      # Frontend (React + TypeScript)
‚îÇ   ‚îú‚îÄ‚îÄ components/           # UI components (providers/settings/mcp/ui)
‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Custom hooks (business logic)
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/              # Tauri API wrapper (type-safe)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query/            # TanStack Query config
‚îÇ   ‚îú‚îÄ‚îÄ i18n/locales/         # Translations (zh/en)
‚îÇ   ‚îú‚îÄ‚îÄ config/               # Presets (providers/mcp)
‚îÇ   ‚îî‚îÄ‚îÄ types/                # TypeScript definitions
‚îú‚îÄ‚îÄ src-tauri/                # Backend (Rust)
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ commands/         # Tauri command layer (by domain)
‚îÇ       ‚îú‚îÄ‚îÄ services/         # Business logic layer
‚îÇ       ‚îú‚îÄ‚îÄ app_config.rs     # Config data models
‚îÇ       ‚îú‚îÄ‚îÄ provider.rs       # Provider domain models
‚îÇ       ‚îú‚îÄ‚îÄ mcp.rs            # MCP sync &amp; validation
‚îÇ       ‚îî‚îÄ‚îÄ lib.rs            # App entry &amp; tray menu
‚îú‚îÄ‚îÄ tests/                    # Frontend tests
‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Unit tests
‚îÇ   ‚îî‚îÄ‚îÄ components/           # Integration tests
‚îî‚îÄ‚îÄ assets/                   # Screenshots &amp; partner resources
```

## Changelog

See [CHANGELOG.md](CHANGELOG.md) for version update details.

## Legacy Electron Version

[Releases](../../releases) retains v2.0.3 legacy Electron version

If you need legacy Electron code, you can pull the electron-legacy branch

## Contributing

Issues and suggestions are welcome!

Before submitting PRs, please ensure:

- Pass type check: `pnpm typecheck`
- Pass format check: `pnpm format:check`
- Pass unit tests: `pnpm test:unit`
- üí° For new features, please open an issue for discussion before submitting a PR

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=farion1231/cc-switch&amp;type=Date)](https://www.star-history.com/#farion1231/cc-switch&amp;Date)

## License

MIT ¬© Jason Young
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[plait-board/drawnix]]></title>
            <link>https://github.com/plait-board/drawnix</link>
            <guid>https://github.com/plait-board/drawnix</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[ÂºÄÊ∫êÁôΩÊùøÂ∑•ÂÖ∑ÔºàSaaSÔºâÔºå‰∏Ä‰ΩìÂåñÁôΩÊùøÔºåÂåÖÂê´ÊÄùÁª¥ÂØºÂõæ„ÄÅÊµÅÁ®ãÂõæ„ÄÅËá™Áî±ÁîªÁ≠â„ÄÇAll in one open-source whiteboard tool with mind, flowchart, freehand and etc.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/plait-board/drawnix">plait-board/drawnix</a></h1>
            <p>ÂºÄÊ∫êÁôΩÊùøÂ∑•ÂÖ∑ÔºàSaaSÔºâÔºå‰∏Ä‰ΩìÂåñÁôΩÊùøÔºåÂåÖÂê´ÊÄùÁª¥ÂØºÂõæ„ÄÅÊµÅÁ®ãÂõæ„ÄÅËá™Áî±ÁîªÁ≠â„ÄÇAll in one open-source whiteboard tool with mind, flowchart, freehand and etc.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 12,753</p>
            <p>Forks: 1,032</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture style=&quot;width: 320px&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/plait-board/drawnix/blob/develop/apps/web/public/logo/logo_drawnix_h.svg?raw=true&quot; /&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/plait-board/drawnix/blob/develop/apps/web/public/logo/logo_drawnix_h_dark.svg?raw=true&quot; /&gt;
    &lt;img src=&quot;https://github.com/plait-board/drawnix/blob/develop/apps/web/public/logo/logo_drawnix_h.svg?raw=true&quot; width=&quot;360&quot; alt=&quot;Drawnix logo and name&quot; /&gt;
  &lt;/picture&gt;
&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;h2&gt;
    ÂºÄÊ∫êÁôΩÊùøÂ∑•ÂÖ∑ÔºàSaaSÔºâÔºå‰∏Ä‰ΩìÂåñÁôΩÊùøÔºåÂåÖÂê´ÊÄùÁª¥ÂØºÂõæ„ÄÅÊµÅÁ®ãÂõæ„ÄÅËá™Áî±ÁîªÁ≠â
  &lt;br /&gt;
  &lt;/h2&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;figure&gt;
    &lt;a target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
      &lt;img src=&quot;https://github.com/plait-board/drawnix/blob/develop/apps/web/public/product_showcase/case-2.png&quot; alt=&quot;Product showcase&quot; width=&quot;80%&quot; /&gt;
    &lt;/a&gt;
    &lt;figcaption&gt;
      &lt;p align=&quot;center&quot;&gt;
        All in one ÁôΩÊùøÔºåÊÄùÁª¥ÂØºÂõæ„ÄÅÊµÅÁ®ãÂõæ„ÄÅËá™Áî±ÁîªÁ≠â
      &lt;/p&gt;
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  &lt;a href=&quot;https://hellogithub.com/repository/plait-board/drawnix&quot; target=&quot;_blank&quot;&gt;
    &lt;picture style=&quot;width: 250&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=4dcea807fab7468a962c153b07ae4e4e&amp;claim_uid=zmFSY5k8EuZri43&amp;theme=neutral&quot; /&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=4dcea807fab7468a962c153b07ae4e4e&amp;claim_uid=zmFSY5k8EuZri43&amp;theme=dark&quot; /&gt;
      &lt;img src=&quot;https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=4dcea807fab7468a962c153b07ae4e4e&amp;claim_uid=zmFSY5k8EuZri43&amp;theme=neutral&quot; alt=&quot;FeaturedÔΩúHelloGitHub&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot;/&gt;
    &lt;/picture&gt;
  &lt;/a&gt;

  &lt;br /&gt;

  &lt;a href=&quot;https://trendshift.io/repositories/13979&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13979&quot; alt=&quot;plait-board%2Fdrawnix | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

[*English README*](https://github.com/plait-board/drawnix/blob/develop/README_en.md)

## ÁâπÊÄß

- üíØ¬†ÂÖçË¥π + ÂºÄÊ∫ê
- ‚öíÔ∏è¬†ÊÄùÁª¥ÂØºÂõæ„ÄÅÊµÅÁ®ãÂõæ
- üñå ÁîªÁ¨î
- üòÄ ÊèíÂÖ•ÂõæÁâá
- üöÄ Âü∫‰∫éÊèí‰ª∂Êú∫Âà∂
- üñºÔ∏è üìÉ ÂØºÂá∫‰∏∫ PNG, JSON(`.drawnix`)
- üíæ Ëá™Âä®‰øùÂ≠òÔºàÊµèËßàÂô®ÁºìÂ≠òÔºâ
- ‚ö° ÁºñËæëÁâπÊÄßÔºöÊí§ÈîÄ„ÄÅÈáçÂÅö„ÄÅÂ§çÂà∂„ÄÅÁ≤òË¥¥Á≠â
- üåå Êó†ÈôêÁîªÂ∏ÉÔºöÁº©Êîæ„ÄÅÊªöÂä®
- üé® ‰∏ªÈ¢òÊ®°Âºè
- üì± ÁßªÂä®ËÆæÂ§áÈÄÇÈÖç
- üìà ÊîØÊåÅ mermaid ËØ≠Ê≥ïËΩ¨ÊµÅÁ®ãÂõæ
- ‚ú® ÊîØÊåÅ markdown ÊñáÊú¨ËΩ¨ÊÄùÁª¥ÂØºÂõæÔºàÊñ∞ÊîØÊåÅ üî•üî•üî•Ôºâ


## ÂÖ≥‰∫éÂêçÁß∞

***Drawnix***  ÔºåÊ∫ê‰∫éÁªòÁîª(  ***Draw***  )‰∏éÂá§Âá∞(  ***Phoenix***  )ÁöÑÁÅµÊÑü‰∫§Áªá„ÄÇ

Âá§Âá∞Ë±°ÂæÅÁùÄÁîüÁîü‰∏çÊÅØÁöÑÂàõÈÄ†ÂäõÔºåËÄå *Draw* ‰ª£Ë°®ÁùÄ‰∫∫Á±ªÊúÄÂéüÂßãÁöÑË°®ËææÊñπÂºè„ÄÇÂú®ËøôÈáåÔºåÊØè‰∏ÄÊ¨°Âàõ‰ΩúÈÉΩÊòØ‰∏ÄÊ¨°Ëâ∫ÊúØÁöÑÊ∂ÖÊßÉÔºåÊØè‰∏ÄÁ¨îÁªòÁîªÈÉΩÊòØÁÅµÊÑüÁöÑÈáçÁîü„ÄÇ

ÂàõÊÑèÂ¶ÇÂêåÂá§Âá∞ÔºåÊµ¥ÁÅ´ÊñπËÉΩÈáçÁîüÔºåËÄå  ***Drawnix***  Ë¶ÅÂÅöÊäÄÊúØ‰∏éÂàõÊÑè‰πãÁÅ´ÁöÑÂÆàÊä§ËÄÖ„ÄÇ

*Draw Beyond, Rise Above.*


## ‰∏é Plait ÁîªÂõæÊ°ÜÊû∂

*Drawnix* ÁöÑÂÆö‰ΩçÊòØ‰∏Ä‰∏™ÂºÄÁÆ±Âç≥Áî®„ÄÅÂºÄÊ∫ê„ÄÅÂÖçË¥πÁöÑÂ∑•ÂÖ∑‰∫ßÂìÅÔºåÂÆÉÁöÑÂ∫ïÂ±ÇÊòØ *Plait* Ê°ÜÊû∂Ôºå*Plait* ÊòØÊàëÂè∏ÂºÄÊ∫êÁöÑ‰∏ÄÊ¨æÁîªÂõæÊ°ÜÊû∂Ôºå‰ª£Ë°®ÁùÄÂÖ¨Âè∏Âú®Áü•ËØÜÂ∫ì‰∫ßÂìÅ([PingCode Wiki](https://pingcode.com/product/wiki?utm_source=drawnix))‰∏äÁöÑÈáçË¶ÅÊäÄÊúØÊ≤âÊ∑Ä„ÄÇ


Drawnix ÊòØÊèí‰ª∂Êû∂ÊûÑÔºå‰∏éÂâçÈù¢ËØ¥Âà∞ÂºÄÊ∫êÂ∑•ÂÖ∑ÊØîÊäÄÊúØÊû∂ÊûÑÊõ¥Â§çÊùÇ‰∏Ä‰∫õÔºå‰ΩÜÊòØÊèí‰ª∂Êû∂ÊûÑ‰πüÊúâ‰ºòÂäøÔºåÊØîÂ¶ÇËÉΩÂ§üÊîØÊåÅÂ§öÁßç UI Ê°ÜÊû∂Ôºà*Angular„ÄÅReact*ÔºâÔºåËÉΩÂ§üÈõÜÊàê‰∏çÂêåÂØåÊñáÊú¨Ê°ÜÊû∂ÔºàÂΩìÂâç‰ªÖÊîØÊåÅ *Slate* Ê°ÜÊû∂ÔºâÔºåÂú®ÂºÄÂèë‰∏äÂèØ‰ª•ÂæàÂ•ΩÁöÑÂÆûÁé∞‰∏öÂä°ÁöÑÂàÜÂ±ÇÔºåÂºÄÂèëÂêÑÁßçÁªÜÁ≤íÂ∫¶ÁöÑÂèØÂ§çÁî®Êèí‰ª∂ÔºåÂèØ‰ª•Êâ©Â±ïÊõ¥Â§öÁöÑÁîªÊùøÁöÑÂ∫îÁî®Âú∫ÊôØ„ÄÇ


## ‰ªìÂÇ®ÁªìÊûÑ

```
drawnix/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ web                   # drawnix.com
‚îÇ   ‚îÇ    ‚îî‚îÄ‚îÄ index.html       # HTML
‚îú‚îÄ‚îÄ dist/                     # ÊûÑÂª∫‰∫ßÁâ©
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îî‚îÄ‚îÄ drawnix/              # ÁôΩÊùøÂ∫îÁî®
‚îÇ   ‚îî‚îÄ‚îÄ react-board/          # ÁôΩÊùø React ËßÜÂõæÂ±Ç
‚îÇ   ‚îî‚îÄ‚îÄ react-text/           # ÊñáÊú¨Ê∏≤ÊüìÊ®°Âùó
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ README_en.md

```

## Â∫îÁî®

[*https://drawnix.com*](https://drawnix.com) ÊòØ *drawnix* ÁöÑÊúÄÂ∞èÂåñÂ∫îÁî®„ÄÇ

ËøëÊúü‰ºöÈ´òÈ¢ëËø≠‰ª£ drawnix.comÔºåÁõ¥Âà∞ÂèëÂ∏É *DawnÔºàÁ†¥ÊôìÔºâ* ÁâàÊú¨„ÄÇ


## ÂºÄÂèë

```
npm install

npm run start
```

## Docker

```
docker pull pubuzhixing/drawnix:latest
```

## ‰æùËµñ

- [plait](https://github.com/worktile/plait) - ÂºÄÊ∫êÁîªÂõæÊ°ÜÊû∂
- [slate](https://github.com/ianstormtaylor/slate)  - ÂØåÊñáÊú¨ÁºñËæëÂô®Ê°ÜÊû∂
- [floating-ui](https://github.com/floating-ui/floating-ui)  - ‰∏Ä‰∏™Ë∂ÖÁ∫ßÂ•ΩÁî®ÁöÑÂàõÂª∫ÂºπÂá∫Â±ÇÂü∫Á°ÄÂ∫ì



## Ë¥°ÁåÆ

Ê¨¢Ëøé‰ªª‰ΩïÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºö

- Êèê Bug

- Ë¥°ÁåÆ‰ª£Á†Å

## ÊÑüË∞¢ÊîØÊåÅ

ÁâπÂà´ÊÑüË∞¢ÂÖ¨Âè∏ÂØπÂºÄÊ∫êÈ°πÁõÆÁöÑÂ§ßÂäõÊîØÊåÅÔºå‰πüÊÑüË∞¢‰∏∫Êú¨È°πÁõÆË¥°ÁåÆ‰ª£Á†Å„ÄÅÊèê‰æõÂª∫ËÆÆÁöÑÊúãÂèã„ÄÇ

&lt;p align=&quot;left&quot;&gt;
  &lt;a href=&quot;https://pingcode.com?utm_source=drawnix&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://cdn-aliyun.pingcode.com/static/site/img/pingcode-logo.4267e7b.svg&quot; width=&quot;120&quot; alt=&quot;PingCode&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## License

[MIT License](https://github.com/plait-board/drawnix/blob/master/LICENSE)  </pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lobehub/lobe-chat]]></title>
            <link>https://github.com/lobehub/lobe-chat</link>
            <guid>https://github.com/lobehub/lobe-chat</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[ü§Ø LobeHub - an open-source, modern design AI Agent Workspace. Supports multiple AI providers, Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobe-chat">lobehub/lobe-chat</a></h1>
            <p>ü§Ø LobeHub - an open-source, modern design AI Agent Workspace. Supports multiple AI providers, Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 68,674</p>
            <p>Forks: 14,170</p>
            <p>Stars today: 64 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# Lobe Chat

An open-source, modern design ChatGPT/LLMs UI/framework.&lt;br/&gt;
Supports speech synthesis, multi-modal, and extensible ([function call][docs-function-call]) plugin system.&lt;br/&gt;
One-click **FREE** deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.

**English** ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md) ¬∑ [Official Site][official-site] ¬∑ [Changelog][changelog] ¬∑ [Documents][docs] ¬∑ [Blog][blog] ¬∑ [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeChat Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Pioneering the new age of thinking and creating. Built for you, the Super Individual.&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url] &lt;br /&gt; &lt;br /&gt; &lt;a href=&quot;https://vercel.com/oss&quot;&gt; &lt;img alt=&quot;Vercel OSS Program&quot; src=&quot;https://vercel.com/oss/program-badge.svg&quot; /&gt; &lt;/a&gt;

![][image-overview]

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [üëãüèª Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [‚ú® Features](#-features)
  - [‚ú® MCP Plugin One-Click Installation](#-mcp-plugin-one-click-installation)
  - [üè™ MCP Marketplace](#-mcp-marketplace)
  - [üñ•Ô∏è Desktop App](#Ô∏è-desktop-app)
  - [üåê Smart Internet Search](#-smart-internet-search)
  - [Chain of Thought](#chain-of-thought)
  - [Branching Conversations](#branching-conversations)
  - [Artifacts Support](#artifacts-support)
  - [File Upload /Knowledge Base](#file-upload-knowledge-base)
  - [Multi-Model Service Provider Support](#multi-model-service-provider-support)
  - [Local Large Language Model (LLM) Support](#local-large-language-model-llm-support)
  - [Model Visual Recognition](#model-visual-recognition)
  - [TTS &amp; STT Voice Conversation](#tts--stt-voice-conversation)
  - [Text to Image Generation](#text-to-image-generation)
  - [Plugin System (Function Calling)](#plugin-system-function-calling)
  - [Agent Market (GPTs)](#agent-market-gpts)
  - [Support Local / Remote Database](#support-local--remote-database)
  - [Support Multi-User Management](#support-multi-user-management)
  - [Progressive Web App (PWA)](#progressive-web-app-pwa)
  - [Mobile Device Adaptation](#mobile-device-adaptation)
  - [Custom Themes](#custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [‚ö°Ô∏è Performance](#Ô∏è-performance)
- [üõ≥ Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [üì¶ Ecosystem](#-ecosystem)
- [üß© Plugins](#-plugins)
- [‚å®Ô∏è Local Development](#Ô∏è-local-development)
- [ü§ù Contributing](#-contributing)
- [‚ù§Ô∏è Sponsor](#Ô∏è-sponsor)
- [üîó More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

## üëãüèª Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![][vercel-shield-badge]][vercel-link]   | No installation or registration necessary! Visit our website to experience it firsthand.                           |
| :---------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link] | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub. |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ ‚≠êÔ∏è

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## ‚ú® Features

Transform your AI experience with LobeChat&#039;s powerful features designed for seamless connectivity, enhanced productivity, and unlimited creativity.

![][image-feat-mcp]

### ‚ú® MCP Plugin One-Click Installation

**Seamlessly Connect Your AI to the World**

Unlock the full potential of your AI by enabling smooth, secure, and dynamic interactions with external tools, data sources, and services. LobeChat&#039;s MCP (Model Context Protocol) plugin system breaks down the barriers between your AI and the digital ecosystem, allowing for unprecedented connectivity and functionality.

Transform your conversations into powerful workflows by connecting to databases, APIs, file systems, and more. Experience the freedom of AI that truly understands and interacts with your world.

[![][back-to-top]](#readme-top)

![][image-feat-mcp-market]

### üè™ MCP Marketplace

**Discover, Connect, Extend**

Browse a growing library of MCP plugins to expand your AI&#039;s capabilities and streamline your workflows effortlessly. Visit [lobehub.com/mcp](https://lobehub.com/mcp) to explore the MCP Marketplace, which offers a curated collection of integrations that enhance your AI&#039;s ability to work with various tools and services.

From productivity tools to development environments, discover new ways to extend your AI&#039;s reach and effectiveness. Connect with the community and find the perfect plugins for your specific needs.

[![][back-to-top]](#readme-top)

![][image-feat-desktop]

### üñ•Ô∏è Desktop App

**Peak Performance, Zero Distractions**

Get the full LobeChat experience without browser limitations‚Äîcomprehensive, focused, and always ready to go. Our desktop application provides a dedicated environment for your AI interactions, ensuring optimal performance and minimal distractions.

Experience faster response times, better resource management, and a more stable connection to your AI assistant. The desktop app is designed for users who demand the best performance from their AI tools.

[![][back-to-top]](#readme-top)

![][image-feat-web-search]

### üåê Smart Internet Search

**Online Knowledge On Demand**

With real-time internet access, your AI keeps up with the world‚Äînews, data, trends, and more. Stay informed and get the most current information available, enabling your AI to provide accurate and up-to-date responses.

Access live information, verify facts, and explore current events without leaving your conversation. Your AI becomes a gateway to the world&#039;s knowledge, always current and comprehensive.

[![][back-to-top]](#readme-top)

[![][image-feat-cot]][docs-feat-cot]

### [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeChat. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [üìò LobeChat Knowledge Base Launch ‚Äî From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

- **[OpenAI](https://lobechat.com/discover/provider/openai)**: OpenAI is a global leader in artificial intelligence research, with models like the GPT series pushing the frontiers of natural language processing. OpenAI is committed to transforming multiple industries through innovative and efficient AI solutions. Their products demonstrate significant performance and cost-effectiveness, widely used in research, business, and innovative applications.
- **[Ollama](https://lobechat.com/discover/provider/ollama)**: Ollama provides models that cover a wide range of fields, including code generation, mathematical operations, multilingual processing, and conversational interaction, catering to diverse enterprise-level and localized deployment needs.
- **[Anthropic](https://lobechat.com/discover/provider/anthropic)**: Anthropic is a company focused on AI research and development, offering a range of advanced language models such as Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Opus, and Claude 3 Haiku. These models achieve an ideal balance between intelligence, speed, and cost, suitable for various applications from enterprise workloads to rapid-response scenarios. Claude 3.5 Sonnet, as their latest model, has excelled in multiple evaluations while maintaining a high cost-performance ratio.
- **[Bedrock](https://lobechat.com/discover/provider/bedrock)**: Bedrock is a service provided by Amazon AWS, focusing on delivering advanced AI language and visual models for enterprises. Its model family includes Anthropic&#039;s Claude series, Meta&#039;s Llama 3.1 series, and more, offering a range of options from lightweight to high-performance, supporting tasks such as text generation, conversation, and image processing for businesses of varying scales and needs.
- **[Google](https://lobechat.com/discover/provider/google)**: Google&#039;s Gemini series represents its most advanced, versatile AI models, developed by Google DeepMind, designed for multimodal capabilities, supporting seamless understanding and processing of text, code, images, audio, and video. Suitable for various environments from data centers to mobile devices, it significantly enhances the efficiency and applicability of AI models.
- **[DeepSeek](https://lobechat.com/discover/provider/deepseek)**: DeepSeek is a company focused on AI technology research and application, with its latest model DeepSeek-V2.5 integrating general dialogue and code processing capabilities, achieving significant improvements in human preference alignment, writing tasks, and instruction following.
- **[Moonshot](https://lobechat.com/discover/provider/moonshot)**: Moonshot is an open-source platform launched by Beijing Dark Side Technology Co., Ltd., providing various natural language processing models with a wide range of applications, including but not limited to content creation, academic research, intelligent recommendations, and medical diagnosis, supporting long text processing and complex generation tasks.
- **[OpenRouter](https://lobechat.com/discover/provider/openrouter)**: OpenRouter is a service platform providing access to various cutting-edge large model interfaces, supporting OpenAI, Anthropic, LLaMA, and more, suitable for diverse development and application needs. Users can flexibly choose the optimal model and pricing based on their requirements, enhancing the AI experience.
- **[HuggingFace](https://lobechat.com/discover/provider/huggingface)**: The HuggingFace Inference API provides a fast and free way for you to explore thousands of models for various tasks. Whether you are prototyping for a new application or experimenting with the capabilities of machine learning, this API gives you instant access to high-performance models across multiple domains.
- **[Cloudflare Workers AI](https://lobechat.com/discover/provider/cloudflare)**: Run serverless GPU-powered machine learning models on Cloudflare&#039;s global network.

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+31)&lt;/kbd&gt;&lt;/summary&gt;

- **[GitHub](https://lobechat.com/discover/provider/github)**: With GitHub Models, developers can become AI engineers and leverage the industry&#039;s leading AI models.
- **[Novita](https://lobechat.com/discover/provider/novita)**: Novita AI is a platform providing a variety of large language models and AI image generation API services, flexible, reliable, and cost-effective. It supports the latest open-source models like Llama3 and Mistral, offering a comprehensive, user-friendly, and auto-scaling API solution for generative AI application development, suitable for the rapid growth of AI startups.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[302.AI](https://lobechat.com/discover/provider/ai302)**: 302.AI is an on-demand AI application platform offering the most comprehensive AI APIs and online AI applications available on the market.
- **[Together AI](https://lobechat.com/discover/provider/togetherai)**: Together AI is dedicated to achieving leading performance through innovative AI models, offering extensive customization capabilities, including rapid scaling support and intuitive deployment processes to meet various enterprise needs.
- **[Fireworks AI](https://lobechat.com/discover/provider/fireworksai)**: Fireworks AI is a leading provider of advanced language model services, focusing on functional calling and multimodal processing. Its latest model, Firefunction V2, is based on Llama-3, optimized for function calling, conversation, and instruction following. The visual language model FireLLaVA-13B supports mixed input of images and text. Other notable models include the Llama series and Mixtral series, providing efficient multilingual instruction following and generation support.
- **[Groq](https://lobechat.com/discover/provider/groq)**: Groq&#039;s LPU inference engine has excelled in the latest independent large language model (LLM) benchmarks, redefining the standards for AI solutions with its remarkable speed and efficiency. Groq represents instant inference speed, demonstrating strong performance in cloud-based deployments.
- **[Perplexity](https://lobechat.com/discover/provider/perplexity)**: Perplexity is a leading provider of conversational generation models, offering various advanced Llama 3.1 models that support both online and offline applications, particularly suited for complex natural language processing tasks.
- **[Mistral](https://lobechat.com/discover/provider/mistral)**: Mistral provides advanced general, specialized, and research models widely used in complex reasoning, multilingual tasks, and code generation. Through functional calling interfaces, users can integrate custom functionalities for specific applications.
- **[ModelScope](https://lobechat.com/discover/provider/modelscope)**: ModelScope is a model-as-a-service platform launched by Alibaba Cloud, offering a wide range of AI models and inference services.
- **[Ai21Labs](https://lobechat.com/discover/provider/ai21)**: AI21 Labs builds foundational models and AI systems for enterprises, accelerating the application of generative AI in production.
- **[Upstage](https://lobechat.com/discover/provider/upstage)**: Upstage focuses on developing AI models for various business needs, including Solar LLM and document AI, aiming to achieve artificial general intelligence (AGI) for work. It allows for the creation of simple conversational agents through Chat API and supports functional calling, translation, embedding, and domain-specific applications.
- **[xAI (Grok)](https://lobechat.com/discover/provider/xai)**: xAI is a company dedicated to building artificial intelligence to accelerate human scientific discovery. Our mission is to advance our collective understanding of the universe.
- **[Aliyun Bailian](https://lobechat.com/discover/provider/qwen)**: Tongyi Qianwen is a large-scale language model independently developed by Alibaba Cloud, featuring strong natural language understanding and generation capabilities. It can answer various questions, create written content, express opinions, and write code, playing a role in multiple fields.
- **[Wenxin](https://lobechat.com/discover/provider/wenxin)**: An enterprise-level one-stop platform for large model and AI-native application development and services, providing the most comprehensive and user-friendly toolchain for the entire pr

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[wybert/earth-agent-chrome-ext]]></title>
            <link>https://github.com/wybert/earth-agent-chrome-ext</link>
            <guid>https://github.com/wybert/earth-agent-chrome-ext</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:21 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wybert/earth-agent-chrome-ext">wybert/earth-agent-chrome-ext</a></h1>
            <p></p>
            <p>Language: TypeScript</p>
            <p>Stars: 55</p>
            <p>Forks: 7</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># Earth Agent Chrome Extension

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;src/assets/mydesign/Robot-earth-transparent-cut-edge.png&quot; alt=&quot;Earth Agent Robot&quot; width=&quot;200&quot;/&gt;
&lt;/div&gt;

Cursor like AI-agent for Google Earth Engine right in your browser as a Chrome extension. It helps you do anything related to Google Earth Engine automatically through chatting. Hatched from [sundai.club](https://www.sundai.club/projects/ad38a4e9-5cd5-4a90-b66c-c3f811cc5e8a).

## Features

- Chat interface for Earth Engine assistance
- Knows Earth Engine Data Catalog as well as community dataset
- Help you write code, and run the code
- Help debug the code
- Help you explian the map
- Planning and reasoning
- Environment management tools (reset map/console, clear code)
- Comprehensive agent testing framework with automated testing capabilities

## Installation

### Option 1: Install from Chrome Web Store (Easiest &amp; Recommended)

1.  Visit the [Earth Agent page on the Chrome Web Store](https://chromewebstore.google.com/detail/earth-agent/hmpjiipbhhnppfdahieaafhdgdmhaple).
2.  Click &quot;Add to Chrome&quot;.
3.  The extension will be added to your browser and will appear in your Chrome toolbar.

### Option 2: Download from GitHub Releases

1. Go to the [Releases page](https://github.com/wybert/earth-agent-chrome-ext/releases)
2. Download the latest `earth-agent-extension.zip`
3. Extract the zip file to a folder on your computer
4. Open Chrome and navigate to `chrome://extensions/`
5. Enable &quot;Developer mode&quot; (toggle in the top right)
6. Click &quot;Load unpacked&quot; and select the extracted folder
7. The extension will appear in your Chrome toolbar

### Option 3: Install from Source

1. Clone the repository
2. Install dependencies with `npm install`
3. Build the extension with `npm run build`
4. Load the unpacked extension from the `dist` directory in Chrome

## Configuration

After installation, you&#039;ll need to configure your AI provider:

1. Click the Earth Agent extension icon in Chrome
2. Go to Settings
3. Choose your AI provider:
   - **OpenAI**: Add your OpenAI API key (supports GPT-4o, GPT-4.1, GPT-o3, etc.)
   - **Anthropic**: Add your Anthropic API key (supports Claude models)
   - **Google**: Add your Google API key (supports Gemini models)
   - **Qwen**: Add your DashScope API key (supports Qwen models)
   - **Ollama**: Configure local Ollama server (requires local installation)
4. Select your preferred model
5. Start chatting with Earth Engine!

### Ollama Setup (Local AI Models)

For Ollama local models:

1. [Install Ollama](https://ollama.com/) on your machine
2. Pull your desired models: `ollama pull gemma3` or `ollama pull llama3`
3. **Important**: Start Ollama with CORS enabled: `OLLAMA_ORIGINS=&quot;*&quot; ollama serve`
4. In the extension settings, select &quot;Ollama&quot; as provider
5. Enter your model name (e.g., &quot;gemma3:1b&quot;, &quot;llama3:latest&quot;)
6. **Tool Support**: Not all models support tools - check [Ollama model search](https://ollama.com/search) for models with &quot;tools&quot; tag for full Earth Engine integration

## Environment Management

The agent includes powerful environment management capabilities:

- **Reset Map/Inspector/Console**: Ask the agent to &quot;reset the map&quot; or &quot;clear the console&quot; to clean up your Google Earth Engine workspace
- **Clear Script**: Request &quot;clear the code&quot; or &quot;start fresh&quot; to remove all code from the Earth Engine editor
- **Natural Language Control**: Simply describe what you want to clean up, and the agent will handle it automatically

These tools help maintain a clean workspace during development and are particularly useful when switching between different Earth Engine tasks.

## AI Model Tool Support

The extension provides powerful Earth Engine integration tools, but tool support varies by AI provider and model:

- **‚úÖ Full Tool Support**: OpenAI GPT models, Anthropic Claude models, Google Gemini models, Qwen models
- **‚ö†Ô∏è Variable Tool Support**: Ollama models - tool support depends on the specific model
  - **Tool-Compatible Ollama Models**: Check [Ollama model search](https://ollama.com/search) for models with &quot;tools&quot; tag
  - **Examples with tools**: `qwen3`, `llama3.1`, `mistral`, `codellama`, `firefunction-v2`
  - **Basic Chat Only**: Models without tool support can still provide Earth Engine guidance and code suggestions
- **üìñ Documentation**: For other providers, refer to their respective documentation for tool/function calling capabilities

**Tip**: For the best Earth Engine integration experience with automated code execution, use tool-compatible models from any provider.

## How to Use the Extension

### Getting Started

1. **Open Google Earth Engine Code Editor** in a Chrome tab: https://code.earthengine.google.com/
2. **Click the Earth Agent extension icon** in your Chrome toolbar
3. **Start chatting!** The agent can see your Earth Engine environment and help with any GEE-related tasks

### Basic Usage Flow

The Earth Agent works as your intelligent assistant for Google Earth Engine development:

- **Ask questions** about Earth Engine concepts, datasets, or code
- **Request code generation** for specific Earth Engine tasks
- **Get help debugging** existing code in your editor
- **Analyze and explain** maps, data, and results
- **Manage your workspace** with automatic cleanup tools

## Example Prompts to Try

### üåç **Getting Started with Earth Engine**
```
&quot;Help me create a simple map showing NDVI for California using Landsat data&quot;

&quot;Show me how to filter satellite imagery by date and cloud cover&quot;

&quot;What datasets are available for precipitation data?&quot;

&quot;Create a time series chart of vegetation indices for a specific location&quot;
```

### üõ∞Ô∏è **Satellite Data Analysis**
```
&quot;Find and display the latest Sentinel-2 image over New York City with less than 10% cloud cover&quot;

&quot;Calculate NDVI for cropland areas in Iowa and create a visualization&quot;

&quot;Compare deforestation between 2010 and 2020 in the Amazon rainforest&quot;

&quot;Detect urban expansion using night lights data over the past 5 years&quot;
```

### üìä **Data Processing and Analysis**
```
&quot;Create a reducer to calculate mean temperature by administrative boundaries&quot;

&quot;Help me export this image to Google Drive with specific projection and scale&quot;

&quot;Set up a batch processing workflow for multiple images&quot;

&quot;Calculate zonal statistics for land use categories within protected areas&quot;
```

### üó∫Ô∏è **Visualization and Mapping**
```
&quot;Add a legend to this map showing the color scale for elevation data&quot;

&quot;Create an interactive map with multiple layers that users can toggle&quot;

&quot;Style this land cover classification with appropriate colors&quot;

&quot;Add geometry drawing tools and export the drawn polygons&quot;
```

### üîß **Debugging and Optimization**
```
&quot;This code is running slowly, can you optimize it?&quot;

&quot;I&#039;m getting a memory error, help me fix this computation&quot;

&quot;Explain what this error message means and how to fix it&quot;

&quot;Check my code for best practices and suggest improvements&quot;
```

### üßπ **Workspace Management**
```
&quot;Clear my console and reset the map view&quot;

&quot;Remove all code from the editor so I can start fresh&quot;

&quot;Reset my workspace to a clean state&quot;

&quot;Take a screenshot of my current results&quot;
```

## Available Tools &amp; Functions

The Earth Agent includes powerful tools that enable it to interact directly with your Google Earth Engine environment:

### üåç **Earth Engine Integration Tools**

#### **Code Editor Integration**
- **Insert Code**: Automatically write code directly into your GEE Code Editor
- **Execute Code**: Run the code in your editor and monitor execution
- **Code Analysis**: Analyze existing code and suggest improvements
- **Error Debugging**: Identify and fix errors in your Earth Engine scripts

#### **Dataset Discovery**
- **Dataset Search**: Find relevant Earth Engine datasets based on your needs
- **Dataset Documentation**: Get detailed information about specific datasets
- **Data Catalog Access**: Browse and explore the complete Earth Engine Data Catalog
- **Community Datasets**: Access community-contributed datasets and collections

#### **Map and Visualization Tools**
- **Map Inspection**: Analyze what&#039;s currently displayed on your map
- **Layer Management**: Add, remove, and modify map layers
- **Visualization Parameters**: Automatically configure visualization settings
- **Legend Creation**: Generate appropriate legends for your data

#### **Environment Management**
- **Reset Map/Inspector/Console**: Clean up your workspace with a single command
- **Clear Script**: Remove all code from the editor to start fresh
- **Screenshot Capture**: Take snapshots of your work for documentation
- **Console Monitoring**: Check console output and error messages

### üåê **Browser Automation Tools**

#### **Web Page Interaction**
- **Element Clicking**: Click buttons, links, and interface elements
- **Text Input**: Fill forms and input fields automatically
- **Page Navigation**: Navigate through web interfaces
- **Element Inspection**: Analyze web page structure and content

#### **Visual Analysis**
- **Screenshot Capture**: Take full-page or selective screenshots
- **Element Detection**: Find and identify specific page elements
- **Content Extraction**: Extract text and data from web pages
- **Accessibility Analysis**: Generate accessibility reports for web content

### üîç **Information and Research Tools**

#### **Weather Integration**
- **Current Weather**: Get real-time weather information for any location
- **Weather Data**: Access meteorological data for analysis
- **Climate Information**: Historical and current climate data

#### **Documentation Access**
- **Context7 Integration**: Access comprehensive Earth Engine documentation
- **API Reference**: Get detailed API documentation and examples
- **Best Practices**: Learn recommended approaches and patterns
- **Code Examples**: Access curated code examples and tutorials

### ü§ñ **AI Agent Capabilities**

#### **Multi-Step Workflows**
- **Plan and Execute**: Break down complex tasks into manageable steps
- **Error Recovery**: Automatically retry and fix failed operations
- **Progress Tracking**: Monitor long-running processes and operations
- **Adaptive Learning**: Adjust approach based on results and feedback

#### **Code Generation**
- **Custom Scripts**: Generate Earth Engine scripts for specific tasks
- **Function Creation**: Create reusable functions and modules
- **Workflow Automation**: Build complete analysis pipelines
- **Batch Processing**: Set up automated processing for multiple datasets

#### **Analysis and Insights**
- **Data Interpretation**: Explain results and findings from your analysis
- **Trend Detection**: Identify patterns and trends in your data
- **Anomaly Detection**: Find unusual patterns or outliers
- **Comparative Analysis**: Compare different datasets or time periods

## Tool Compatibility by Provider

### ‚úÖ **Full Tool Support**
**OpenAI, Anthropic, Google, Qwen**: All tools and functions available
- Complete Earth Engine integration
- Full browser automation
- Advanced multi-step workflows
- Error recovery and debugging

### ‚ö†Ô∏è **Variable Tool Support**
**Ollama**: Tool availability depends on the specific model
- **With Tools**: Models tagged with &quot;tools&quot; on [Ollama search](https://ollama.com/search)
  - Examples: `qwen3`, `llama3.1`, `mistral`, `codellama`, `firefunction-v2`
  - Full Earth Engine integration available
  - Complete browser automation support
- **Chat Only**: Models without tool support
  - Provides expert guidance and code suggestions
  - Can explain concepts and help with debugging
  - Limited to conversational assistance (no direct code execution)

### üí° **Usage Tips**

#### **For Maximum Productivity**
1. **Use tool-compatible models** when you need automated code execution
2. **Be specific** in your requests for better results
3. **Ask for explanations** to learn Earth Engine concepts
4. **Use workspace management** tools to keep your environment clean
5. **Take screenshots** to document your work and results

#### **Common Workflows**
1. **Exploratory Analysis**: Ask questions ‚Üí Get code ‚Üí Run and iterate
2. **Data Processing**: Define requirements ‚Üí Generate pipeline ‚Üí Execute and export
3. **Visualization**: Create map ‚Üí Style layers ‚Üí Add legends ‚Üí Capture results
4. **Debugging**: Describe problem ‚Üí Analyze code ‚Üí Apply fixes ‚Üí Test solution

## Agent Testing Panel

The extension includes a comprehensive testing framework for evaluating AI agent performance:

- **Multi-Provider Support**: Test with OpenAI GPT models, Anthropic Claude models, Google Gemini, Qwen models, or Ollama local models
- **Batch Testing**: Run multiple prompts automatically with configurable intervals
- **Environment Controls**: Configure reset and clear functions, including optional GEE editor reload
- **Results Analysis**: Export detailed test results with screenshots and metadata
- **Screenshot Storage**: Multiple storage options (local, downloads folder, Google Drive)
- **Tool Compatibility**: Automatically adapts testing based on model tool support capabilities

Access the testing panel by clicking the flask icon (üß™) in the main chat interface.

## Advanced Usage Examples

### üöÄ **Complex Multi-Step Workflows**

**Example: Creating a Complete Deforestation Analysis**
```
&quot;I want to analyze deforestation in the Brazilian Amazon from 2000 to 2023. 
Please create a complete workflow that:
1. Loads appropriate satellite imagery
2. Calculates forest loss over time
3. Creates visualizations showing the changes
4. Generates statistics by state/region
5. Exports the results for further analysis&quot;
```

**Example: Agricultural Monitoring Pipeline**
```
&quot;Set up an agricultural monitoring system for corn fields in Iowa that:
- Uses Sentinel-2 and Landsat data
- Calculates NDVI, EVI, and SAVI indices
- Creates time series analysis for growing seasons
- Identifies areas of crop stress
- Generates automated reports with charts and maps&quot;
```

### üìà **Data Science Integration**

**Example: Climate Change Analysis**
```
&quot;Help me create a climate change impact study that:
1. Uses ERA5 temperature and precipitation data
2. Calculates 30-year climate normals
3. Identifies significant trends and anomalies
4. Creates publication-ready visualizations
5. Exports data in formats suitable for statistical analysis&quot;
```

**Example: Urban Heat Island Study**
```
&quot;Design an urban heat island analysis for major cities that:
- Uses Landsat thermal bands and MODIS LST
- Compares urban vs rural temperatures
- Analyzes the relationship with land cover
- Creates before/after comparisons over 20 years
- Generates interactive maps for public outreach&quot;
```

### üîÑ **Automated Processing**

**Example: Batch Processing Multiple Regions**
```
&quot;I have a list of 50 protected areas. Please create a batch processing workflow that:
1. Processes each area separately
2. Calculates vegetation indices for each season
3. Detects any significant changes or disturbances
4. Creates standardized reports for each area
5. Compiles results into a summary dashboard&quot;
```

## Troubleshooting

### Common Issues and Solutions

#### **üîß Extension Not Working**
- **Refresh the Earth Engine tab** and try again
- **Check your API keys** in the extension settings
- **Verify internet connection** for cloud-based providers
- **For Ollama**: Ensure it&#039;s running with `OLLAMA_ORIGINS=&quot;*&quot; ollama serve`

#### **üö´ Tools Not Working**
- **Check model compatibility**: Ensure your selected model supports tools
- **For Ollama**: Use models with &quot;tools&quot; tag from [Ollama search](https://ollama.com/search)
- **Try a different provider**: Switch to OpenAI, Anthropic, Google, or Qwen for guaranteed tool support

#### **‚ö° Performance Issues**
- **Use more specific prompts** to reduce processing time
- **Break complex tasks** into smaller steps
- **Check Earth Engine quotas** if operations fail
- **For local models**: Ensure sufficient system resources

#### **üêõ Code Errors**
- **Ask the agent to debug**: &quot;This code has an error, please fix it&quot;
- **Check console output**: &quot;What errors are showing in the console?&quot;
- **Reset workspace**: &quot;Clear everything and start fresh&quot;

#### **üì° Connectivity Issues**
- **Verify API keys** are correctly entered
- **Check provider status** (OpenAI, Anthropic, Google, Qwen status pages)
- **For Ollama**: Confirm local server is accessible at `http://localhost:11434`

### Getting Help

1. **Use the agent itself**: Ask &quot;How do I...&quot; or &quot;Help me troubleshoot...&quot;
2. **Check the console**: Look for error messages in browser developer tools
3. **Try different models**: Some models may work better for specific tasks
4. **Reset your workspace**: Use environment management tools to start fresh

## Privacy and Security

### Data Handling
- **API Keys**: Stored securely in Chrome extension storage, never shared
- **Chat History**: Kept locally in your browser, not sent to external servers
- **Code and Data**: Only shared with your selected AI provider during active conversations
- **Screenshots**: Stored locally or in your chosen location (Downloads, Google Drive)

### Best Practices
- **Keep API keys secure**: Don&#039;t share your extension settings or API keys
- **Review generated code**: Always review code before running important analyses
- **Use appropriate models**: Choose models based on your data sensitivity requirements
- **Regular updates**: Keep the extension updated for latest security features

## Creating a New Release

For developers who want to create releases:

```bash
# Create and push a version tag
git tag v1.0.0
git push origin v1.0.0

# GitHub Actions will automatically:
# - Build the extension
# - Run tests
# - Create a release with installation files
```

## Development

You need nodejs and npm,

1. Clone the repository
2. Install dependencies with `npm install`
3. Build the extension with `npm run build`
4. Load the unpacked extension from the `dist` directory in Chrome
5. Create branches and make changes
6. Build the project and refresh the chrome extension to see updates
7. push changes if all works good


## CORS Handling

The extension handles Cross-Origin Resource Sharing (CORS) issues by proxying API requests through the background script. This setup works because:

1. Chrome extension background scripts have permission to make cross-origin requests if the URL is included in the `host_permissions` in `manifest.json`
2. Content scripts and the sidepanel are subject to CORS restrictions
3. The tools are designed to automatically detect the current environment and:
   - Make direct API calls when running in the background script or Node.js
   - Proxy requests via the background script when running in a content script or sidepanel

If you encounter CORS issues:
- Check that `https://context7.com/*` is included in the `host_permissions` in `manifest.json`
- Verify that the background script is properly handling the message types
- Check the background script console for detailed error messages

## License

MIT

## Thanks

- [Sundai Club](https://www.sundai.club/)
- React
- Vercel AI SDK
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[PaperDebugger/paperdebugger]]></title>
            <link>https://github.com/PaperDebugger/paperdebugger</link>
            <guid>https://github.com/PaperDebugger/paperdebugger</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[Paper Debugger is the best overleaf companion]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/PaperDebugger/paperdebugger">PaperDebugger/paperdebugger</a></h1>
            <p>Paper Debugger is the best overleaf companion</p>
            <p>Language: TypeScript</p>
            <p>Stars: 361</p>
            <p>Forks: 23</p>
            <p>Stars today: 139 stars today</p>
            <h2>README</h2><pre>![branding](docs/imgs/branding.png)

**Explore the demo paper‚Äôs supporting assets in the [/demo](/demo/) folder.**

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://chromewebstore.google.com/detail/paperdebugger/dfkedikhakpapbfcnbpmfhpklndgiaog&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/chrome-web-store/users/dfkedikhakpapbfcnbpmfhpklndgiaog?label=Users&quot; alt=&quot;Chrome Web Store Users&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://chromewebstore.google.com/detail/paperdebugger/dfkedikhakpapbfcnbpmfhpklndgiaog&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/chrome-web-store/v/dfkedikhakpapbfcnbpmfhpklndgiaog?label=Chrome%20Web%20Store&amp;logo=google-chrome&amp;logoColor=white&quot; alt=&quot;Chrome Web Store Version&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/PaperDebugger/paperdebugger/releases&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/PaperDebugger/paperdebugger?label=Latest%20Release&quot; alt=&quot;GitHub Release&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/PaperDebugger/paperdebugger/actions/workflows/release.yml&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/PaperDebugger/paperdebugger/build.yml?branch=main&quot; alt=&quot;Build Status&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/PaperDebugger/PaperDebugger?tab=AGPL-3.0-1-ov-file&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/PaperDebugger/paperdebugger&quot; alt=&quot;License&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

**PaperDebugger** is an AI-powered academic writing assistant that helps researchers debug and improve their LaTeX papers with intelligent suggestions and seamless Overleaf integration. It is powered by a custom MCP-based orchestration engine that simulates the full academic workflow **Research ‚Üí Critique ‚Üí Revision**. &lt;br&gt;
This enables multi-step reasoning, reviewer-style critique, and structured revision passes beyond standard chat-based assistance.


&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://chromewebstore.google.com/detail/paperdebugger/dfkedikhakpapbfcnbpmfhpklndgiaog&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;üöÄ Install from Chrome Web Store&lt;/strong&gt;&lt;/a&gt; ‚Ä¢ &lt;a href=&quot;https://github.com/PaperDebugger/paperdebugger/releases/latest&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;üì¶ Download Latest Release&lt;/strong&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/imgs/preview2.png&quot; width=&quot;46%&quot; style=&quot;margin: 0 1.5%;&quot;/&gt;
  &lt;img src=&quot;docs/imgs/preview3.png&quot; width=&quot;46%&quot; style=&quot;margin: 0 1.5%;&quot;/&gt;
  &lt;img src=&quot;docs/imgs/preview1.png&quot; width=&quot;100%&quot; style=&quot;margin: 0 1.5%; border-radius: 0.5rem;&quot;/&gt;
&lt;/div&gt;

## üìã Table of Contents

- [üìã Table of Contents](#-table-of-contents)
- [‚ú® Features](#-features)
- [üéØ Quick Start](#-quick-start)
  - [For Users](#for-users)
  - [Custom Endpoint Configuration](#custom-endpoint-configuration)
- [üèóÔ∏è Architecture Overview](#Ô∏è-architecture-overview)
- [üõ†Ô∏è Development Setup](#Ô∏è-development-setup)
  - [Prerequisites](#prerequisites)
    - [System Requirements](#system-requirements)
    - [Development Tools](#development-tools)
    - [Quick Installation (macOS/Linux with Homebrew)](#quick-installation-macoslinux-with-homebrew)
  - [Backend Build](#backend-build)
    - [1. Clone the Repository](#1-clone-the-repository)
    - [2. Start MongoDB](#2-start-mongodb)
    - [3. Environment Configuration](#3-environment-configuration)
    - [4. Custom MCP Backend Orchestration](#4-custom-mcp-backend-orchestration)
    - [5. Build and Run](#4-build-and-run)
  - [Frontend Extension Build](#frontend-extension-build)
    - [Chrome Extension Development](#chrome-extension-development)
    - [Installing the Development Extension](#installing-the-development-extension)

## ‚ú® Features

PaperDebugger never modifies your project, it only reads and provides suggestions.

- **ü§ñ AI-Powered Chat**: Intelligent conversations about your Overleaf project
- **‚ö° Instant Insert**: One-click insertion of AI responses into your project
- **üí¨ Comment System**: Automatically generate and insert comments into your project
- **üìö Prompt Library**: Custom prompt templates for different use cases
- **üîí Privacy First**: Your content stays secure - we only read, never modify
- **üß† Multi-Agent Orchestration** ‚Äì [XtraMCP](https://github.com/4ndrelim/academic-paper-mcp-server) support for literature-grounded research, AI-Conference review, and domain-specific revision

https://github.com/user-attachments/assets/6c20924d-1eb6-44d5-95b0-207bd08b718b

## üéØ Quick Start

### For Users

1. **Install the Extension**
   - [Chrome Web Store](https://chromewebstore.google.com/detail/paperdebugger/dfkedikhakpapbfcnbpmfhpklndgiaog) (Recommended)
   - [Latest Release](https://github.com/PaperDebugger/paperdebugger/releases/latest) (Manual Install)

2. **Manual Installation**
   - Download the latest release
   - Open Chrome and go to `chrome://extensions/`
   - Enable &quot;Developer mode&quot;
   - Click &quot;Load unpacked&quot; or drag the extension file

3. **Start Using**
   - Open any Overleaf project
   - Click the PaperDebugger icon
   - Begin chatting with your LaTeX assistant!

### Custom Endpoint Configuration

If you want to use a **self-hosted** PaperDebugger backend, you can configure a custom endpoint. **Note**: You need to handle HTTPS serving yourself, as Chrome blocks HTTP requests from HTTPS websites for security reasons.

**Steps:**
1. Open the PaperDebugger extension
2. Go to Settings, click the version number 5 times to enable &quot;Developer Tools&quot; (a.)
3. Enter your backend URL in the &quot;Backend Endpoint&quot; field (b.)
4. Refresh the page

If you encounter endpoint errors after refresh, use the &quot;Advanced Options&quot; at the bottom of the login page to reconfigure.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/imgs/custom endpoint.png&quot; alt=&quot;Custom Endpoint Configuration&quot; style=&quot;max-width: 600px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);&quot;/&gt;
&lt;/div&gt;

## üèóÔ∏è Architecture Overview

The PaperDebugger backend is built with modern technologies:

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/imgs/stacks.png&quot; style=&quot;max-height: 200px;&quot; /&gt;
&lt;/div&gt;

- **Language**: Go 1.24+
- **Framework**: Gin (HTTP) + gRPC (API)
- **Database**: MongoDB
- **AI Integration**: OpenAI API
- **Architecture**: Microservices with Protocol Buffers
- **Authentication**: JWT-based with OAuth support


## üõ†Ô∏è Development Setup

### Prerequisites

#### System Requirements
- **Go**: 1.24 or higher
- **Node.js**: LTS version (for frontend build)
- **MongoDB**: 4.4 or higher
- **Git**: For cloning the repository

#### Development Tools
- **Buf**: Protocol Buffer compiler
- **Wire**: Dependency injection code generator
- **Make**: Build automation

#### Quick Installation (macOS/Linux with Homebrew)
```bash
# Install Go
brew install go

# Install Buf (required for Protocol Buffers)
brew install bufbuild/buf/buf

# Install Node.js
brew install node
```

### Backend Build

#### 1. Clone the Repository
```bash
git clone https://github.com/PaperDebugger/paperdebugger.git
cd paperdebugger
```

#### 2. Start MongoDB
```bash
# Using Docker (recommended)
docker run -d --name mongodb -p 27017:27017 mongo:latest
```

#### 3. Environment Configuration
```bash
cp .env.example .env
# Edit the .env file based on your configuration
```

#### 4. Custom MCP Backend Orchestration [OPTIONAL FOR LOCAL DEV]
Our enhanced orchestration backend, [**XtraMCP**](https://github.com/4ndrelim/academic-paper-mcp-server), is currently closed-source while under active development. &lt;br&gt;
You can run PaperDebugger without it; all core features (chat, formatting, edits, comments) work normally.

Connecting to XtraMCP unlocks:
- research-mode agents,  
- structured reviewer-style critique,  
- domain-specific revisions tailored to academic writing powered by [XtraGPT](https://huggingface.co/Xtra-Computing/XtraGPT-14B) models

We plan to **open-source XtraMCP** once the API stabilizes for community use.


#### 5. Build and Run
```bash
# Build the backend
make build

# Run the backend server
./dist/pd.exe
```

The server will start on `http://localhost:6060`.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/imgs/run.png&quot; alt=&quot;Backend Server Running&quot; style=&quot;max-width: 600px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);&quot;/&gt;
&lt;/div&gt;

### Frontend Extension Build

#### Chrome Extension Development
```bash
cd webapp/_webapp

# Install frontend dependencies
npm install

# Build for production (connects to production server)
npm run build:prd:chrome

# Package the extension
cd dist
zip -r paperdebugger-extension.zip *
```

#### Installing the Development Extension
1. Open Chrome and navigate to `chrome://extensions/`
2. Enable &quot;Developer mode&quot; (toggle in top-right)
3. Click &quot;Load unpacked&quot; and select the `webapp/_webapp/dist` directory
   - Or drag the `paperdebugger-extension.zip` file into the extensions page

## Citation
```
@misc{hou2025paperdebugger,
      title={PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing}, 
      author={Junyi Hou and Andre Lin Huikai and Nuo Chen and Yiwei Gong and Bingsheng He},
      year={2025},
      eprint={2512.02589},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2512.02589}, 
}
```
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[expo/expo]]></title>
            <link>https://github.com/expo/expo</link>
            <guid>https://github.com/expo/expo</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[An open-source framework for making universal native apps with React. Expo runs on Android, iOS, and the web.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/expo/expo">expo/expo</a></h1>
            <p>An open-source framework for making universal native apps with React. Expo runs on Android, iOS, and the web.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 45,393</p>
            <p>Forks: 10,171</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;!-- Banner Image --&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://expo.dev/&quot;&gt;
    &lt;img alt=&quot;Expo logo&quot; height=&quot;128&quot; src=&quot;./.github/resources/banner.png&quot;&gt;
    &lt;h1 align=&quot;center&quot;&gt;Expo&lt;/h1&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
   &lt;a aria-label=&quot;SDK version&quot; href=&quot;https://www.npmjs.com/package/expo&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo SDK version&quot; src=&quot;https://img.shields.io/npm/v/expo.svg?style=flat-square&amp;label=SDK&amp;labelColor=000000&amp;color=4630EB&quot; /&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Chat or ask a question&quot; href=&quot;https://chat.expo.dev&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Chat or ask a question&quot; src=&quot;https://img.shields.io/discord/695411232856997968.svg?style=flat-square&amp;labelColor=000000&amp;color=4630EB&amp;logo=discord&amp;logoColor=FFFFFF&amp;label=Chat%20with%20us&quot; /&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Expo is free to use&quot; href=&quot;https://github.com/expo/expo/blob/main/LICENSE&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;License: MIT&quot; src=&quot;https://img.shields.io/badge/License-MIT-success.svg?style=flat-square&amp;color=33CC12&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;expo downloads&quot; href=&quot;http://www.npmtrends.com/expo&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Downloads&quot; src=&quot;https://img.shields.io/npm/dm/expo.svg?style=flat-square&amp;labelColor=gray&amp;color=33CC12&amp;label=Downloads&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;try expo with snack&quot; href=&quot;https://snack.expo.dev&quot;&gt;&lt;b&gt;Try Expo in the Browser&lt;/b&gt;&lt;/a&gt;
&amp;ensp;‚Ä¢&amp;ensp;
  &lt;a aria-label=&quot;expo documentation&quot; href=&quot;https://docs.expo.dev&quot;&gt;Read the Documentation&lt;/a&gt;
&amp;ensp;‚Ä¢&amp;ensp;
  &lt;a aria-label=&quot;expo documentation&quot; href=&quot;https://expo.dev/blog&quot;&gt;Learn more on our blog&lt;/a&gt;
&amp;ensp;‚Ä¢&amp;ensp;
  &lt;a aria-label=&quot;expo documentation&quot; href=&quot;https://expo.canny.io/feature-requests&quot;&gt;Request a feature&lt;/a&gt;
&lt;/p&gt;

&lt;h6 align=&quot;center&quot;&gt;Follow us on&lt;/h6&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;Follow @expo on X&quot; href=&quot;https://x.com/intent/follow?screen_name=expo&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on X&quot; src=&quot;https://img.shields.io/badge/X-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;&amp;nbsp;
  &lt;a aria-label=&quot;Follow @expo on GitHub&quot; href=&quot;https://github.com/expo&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on GitHub&quot; src=&quot;https://img.shields.io/badge/GitHub-222222?style=for-the-badge&amp;logo=github&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;&amp;nbsp;
  &lt;a aria-label=&quot;Follow @expo on Reddit&quot; href=&quot;https://www.reddit.com/r/expo/&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on Reddit&quot; src=&quot;https://img.shields.io/badge/Reddit-FF4500?style=for-the-badge&amp;logo=reddit&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;&amp;nbsp;
  &lt;a aria-label=&quot;Follow @expo on Bluesky&quot; href=&quot;https://bsky.app/profile/expo.dev&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on Bluesky&quot; src=&quot;https://img.shields.io/badge/Bluesky-1DA1F2?style=for-the-badge&amp;logo=bluesky&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;&amp;nbsp;
  &lt;a aria-label=&quot;Follow @expo on LinkedIn&quot; href=&quot;https://www.linkedin.com/company/expo-dev&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on LinkedIn&quot; src=&quot;https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## Introduction

Expo is an open-source platform for making universal native apps that run on Android, iOS, and the web. It includes a universal runtime and libraries that let you build native apps by writing React and JavaScript.

This repository includes the Expo SDK, Modules API, Go app, CLI, Router, documentation, and various other supporting tools. [Expo Application Services (EAS)](https://expo.dev/eas) is a platform of hosted services that are deeply integrated with Expo open source tools. EAS helps you build, ship, and iterate on your app as an individual or a team.

Read the [Expo Community Guidelines](https://expo.dev/guidelines) before interacting in the repository. Thank you for helping keep the Expo community open and welcoming!

## Table of contents

- [üìö Documentation](#-documentation)
- [üó∫ Project Layout](#-project-layout)
- [üèÖ Badges](#-badges)
- [üëè Contributing](#-contributing)
- [‚ùì FAQ](#-faq)
- [üíô The Team](#-the-team)
- [License](#license)

## üìö Documentation

&lt;p&gt;Learn about building and deploying universal apps &lt;a aria-label=&quot;expo documentation&quot; href=&quot;https://docs.expo.dev&quot;&gt;in our official docs!&lt;/a&gt;&lt;/p&gt;

- [Getting Started](https://docs.expo.dev/)
- [API Reference](https://docs.expo.dev/versions/latest/)
- [Using Custom Native Modules](https://docs.expo.dev/workflow/customizing/)

## üó∫ Project Layout

- [`packages`](/packages) All the source code for Expo modules, if you want to edit a library or just see how it works this is where you&#039;ll find it.
- [`apps`](/apps) This is where you can find Expo projects which are linked to the development modules. You&#039;ll do most of your testing in here.
- [`apps/expo-go`](/apps/expo-go) This is where you can find the source code for Expo Go.
- [`apps/expo-go/ios/Exponent.xcworkspace`](/apps/expo-go/ios) is the Xcode workspace. When developing iOS, always open this instead of `Exponent.xcodeproj` because the workspace also loads the CocoaPods dependencies.
- [`docs`](/docs) The source code for **https://docs.expo.dev**
- [`templates`](/templates) The template projects you get when you run `npx create-expo-app`
- [`react-native-lab`](/react-native-lab) This is our fork of `react-native` used to build Expo Go.
- [`guides`](/guides) In-depth tutorials for advanced topics like contributing to the client.
- [`tools`](/tools) contain build and configuration tools.
- [`template-files`](/template-files) contains templates for files that require private keys. They are populated using the keys in `template-files/keys.json`.
- [`template-files/ios/dependencies.json`](/template-files/ios/dependencies.json) specifies the CocoaPods dependencies of the app.

## üèÖ Badges

Let everyone know your app can be run instantly in the _Expo Go_ app!
&lt;br/&gt;

[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-000.svg?style=flat-square&amp;logo=EXPO&amp;labelColor=f3f3f3&amp;logoColor=000)](https://expo.dev/client)

[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-4630EB.svg?style=flat-square&amp;logo=EXPO&amp;labelColor=f3f3f3&amp;logoColor=000)](https://expo.dev/client)

```md
[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-000.svg?style=flat-square&amp;logo=EXPO&amp;labelColor=f3f3f3&amp;logoColor=000)](https://expo.dev/client)

[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-4630EB.svg?style=flat-square&amp;logo=EXPO&amp;labelColor=f3f3f3&amp;logoColor=000)](https://expo.dev/client)
```

## üëè Contributing

If you like Expo and want to help make it better then check out our [contributing guide](/CONTRIBUTING.md)! Check out the [CLI package](https://github.com/expo/expo/tree/main/packages/%40expo/cli) to work on the Expo CLI.

## ‚ùì FAQ

If you have questions about Expo and want answers, then check out our [Frequently Asked Questions](https://docs.expo.dev/faq/)!

If you still have questions you can ask them on our [Discord and Forums](https://chat.expo.dev) or X [@expo](https://x.com/expo).

## üíô The Team

Curious about who makes Expo? Here are our [team members](https://expo.dev/about)!

## License

The Expo source code is made available under the [MIT license](LICENSE). Some of the dependencies are licensed differently, with the BSD license, for example.

&lt;img alt=&quot;Star the Expo repo on GitHub to support the project&quot; src=&quot;https://user-images.githubusercontent.com/9664363/185428788-d762fd5d-97b3-4f59-8db7-f72405be9677.gif&quot; width=&quot;50%&quot;&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[musistudio/claude-code-router]]></title>
            <link>https://github.com/musistudio/claude-code-router</link>
            <guid>https://github.com/musistudio/claude-code-router</guid>
            <pubDate>Sun, 07 Dec 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/musistudio/claude-code-router">musistudio/claude-code-router</a></h1>
            <p>Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 22,956</p>
            <p>Forks: 1,796</p>
            <p>Stars today: 47 stars today</p>
            <h2>README</h2><pre>![](blog/images/claude-code-router-img.png)

[![](https://img.shields.io/badge/%F0%9F%87%A8%F0%9F%87%B3-%E4%B8%AD%E6%96%87%E7%89%88-ff0000?style=flat)](README_zh.md)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?&amp;logo=discord&amp;logoColor=white)](https://discord.gg/rdftVMaUcS)
[![](https://img.shields.io/github/license/musistudio/claude-code-router)](https://github.com/musistudio/claude-code-router/blob/main/LICENSE)

&lt;hr&gt;

![](blog/images/sponsors/glm-en.jpg)
&gt; This project is sponsored by Z.ai, supporting us with their GLM CODING PLAN.    
&gt; GLM CODING PLAN is a subscription service designed for AI coding, starting at just $3/month. It provides access to their flagship GLM-4.6 model across 10+ popular AI coding tools (Claude Code, Cline, Roo Code, etc.), offering developers top-tier, fast, and stable coding experiences.     
&gt; Get 10% OFF GLM CODING PLANÔºöhttps://z.ai/subscribe?ic=8JVLJQFSKB     

&gt; A powerful tool to route Claude Code requests to different models and customize any request.

&gt; [GLM-4.6 Supports Reasoning and Interleaved Thinking](blog/en/glm-4.6-supports-reasoning.md)

![](blog/images/claude-code.png)

## ‚ú® Features

- **Model Routing**: Route requests to different models based on your needs (e.g., background tasks, thinking, long context).
- **Multi-Provider Support**: Supports various model providers like OpenRouter, DeepSeek, Ollama, Gemini, Volcengine, and SiliconFlow.
- **Request/Response Transformation**: Customize requests and responses for different providers using transformers.
- **Dynamic Model Switching**: Switch models on-the-fly within Claude Code using the `/model` command.
- **CLI Model Management**: Manage models and providers directly from the terminal with `ccr model`.
- **GitHub Actions Integration**: Trigger Claude Code tasks in your GitHub workflows.
- **Plugin System**: Extend functionality with custom transformers.

## üöÄ Getting Started

### 1. Installation

First, ensure you have [Claude Code](https://docs.anthropic.com/en/docs/claude-code/quickstart) installed:

```shell
npm install -g @anthropic-ai/claude-code
```

Then, install Claude Code Router:

```shell
npm install -g @musistudio/claude-code-router
```

### 2. Configuration

Create and configure your `~/.claude-code-router/config.json` file. For more details, you can refer to `config.example.json`.

The `config.json` file has several key sections:

- **`PROXY_URL`** (optional): You can set a proxy for API requests, for example: `&quot;PROXY_URL&quot;: &quot;http://127.0.0.1:7890&quot;`.
- **`LOG`** (optional): You can enable logging by setting it to `true`. When set to `false`, no log files will be created. Default is `true`.
- **`LOG_LEVEL`** (optional): Set the logging level. Available options are: `&quot;fatal&quot;`, `&quot;error&quot;`, `&quot;warn&quot;`, `&quot;info&quot;`, `&quot;debug&quot;`, `&quot;trace&quot;`. Default is `&quot;debug&quot;`.
- **Logging Systems**: The Claude Code Router uses two separate logging systems:
  - **Server-level logs**: HTTP requests, API calls, and server events are logged using pino in the `~/.claude-code-router/logs/` directory with filenames like `ccr-*.log`
  - **Application-level logs**: Routing decisions and business logic events are logged in `~/.claude-code-router/claude-code-router.log`
- **`APIKEY`** (optional): You can set a secret key to authenticate requests. When set, clients must provide this key in the `Authorization` header (e.g., `Bearer your-secret-key`) or the `x-api-key` header. Example: `&quot;APIKEY&quot;: &quot;your-secret-key&quot;`.
- **`HOST`** (optional): You can set the host address for the server. If `APIKEY` is not set, the host will be forced to `127.0.0.1` for security reasons to prevent unauthorized access. Example: `&quot;HOST&quot;: &quot;0.0.0.0&quot;`.
- **`NON_INTERACTIVE_MODE`** (optional): When set to `true`, enables compatibility with non-interactive environments like GitHub Actions, Docker containers, or other CI/CD systems. This sets appropriate environment variables (`CI=true`, `FORCE_COLOR=0`, etc.) and configures stdin handling to prevent the process from hanging in automated environments. Example: `&quot;NON_INTERACTIVE_MODE&quot;: true`.

- **`Providers`**: Used to configure different model providers.
- **`Router`**: Used to set up routing rules. `default` specifies the default model, which will be used for all requests if no other route is configured.
- **`API_TIMEOUT_MS`**: Specifies the timeout for API calls in milliseconds.

#### Environment Variable Interpolation

Claude Code Router supports environment variable interpolation for secure API key management. You can reference environment variables in your `config.json` using either `$VAR_NAME` or `${VAR_NAME}` syntax:

```json
{
  &quot;OPENAI_API_KEY&quot;: &quot;$OPENAI_API_KEY&quot;,
  &quot;GEMINI_API_KEY&quot;: &quot;${GEMINI_API_KEY}&quot;,
  &quot;Providers&quot;: [
    {
      &quot;name&quot;: &quot;openai&quot;,
      &quot;api_base_url&quot;: &quot;https://api.openai.com/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;$OPENAI_API_KEY&quot;,
      &quot;models&quot;: [&quot;gpt-5&quot;, &quot;gpt-5-mini&quot;]
    }
  ]
}
```

This allows you to keep sensitive API keys in environment variables instead of hardcoding them in configuration files. The interpolation works recursively through nested objects and arrays.

Here is a comprehensive example:

```json
{
  &quot;APIKEY&quot;: &quot;your-secret-key&quot;,
  &quot;PROXY_URL&quot;: &quot;http://127.0.0.1:7890&quot;,
  &quot;LOG&quot;: true,
  &quot;API_TIMEOUT_MS&quot;: 600000,
  &quot;NON_INTERACTIVE_MODE&quot;: false,
  &quot;Providers&quot;: [
    {
      &quot;name&quot;: &quot;openrouter&quot;,
      &quot;api_base_url&quot;: &quot;https://openrouter.ai/api/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [
        &quot;google/gemini-2.5-pro-preview&quot;,
        &quot;anthropic/claude-sonnet-4&quot;,
        &quot;anthropic/claude-3.5-sonnet&quot;,
        &quot;anthropic/claude-3.7-sonnet:thinking&quot;
      ],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;openrouter&quot;]
      }
    },
    {
      &quot;name&quot;: &quot;deepseek&quot;,
      &quot;api_base_url&quot;: &quot;https://api.deepseek.com/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;deepseek-chat&quot;, &quot;deepseek-reasoner&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;deepseek&quot;],
        &quot;deepseek-chat&quot;: {
          &quot;use&quot;: [&quot;tooluse&quot;]
        }
      }
    },
    {
      &quot;name&quot;: &quot;ollama&quot;,
      &quot;api_base_url&quot;: &quot;http://localhost:11434/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;ollama&quot;,
      &quot;models&quot;: [&quot;qwen2.5-coder:latest&quot;]
    },
    {
      &quot;name&quot;: &quot;gemini&quot;,
      &quot;api_base_url&quot;: &quot;https://generativelanguage.googleapis.com/v1beta/models/&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;gemini-2.5-flash&quot;, &quot;gemini-2.5-pro&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;gemini&quot;]
      }
    },
    {
      &quot;name&quot;: &quot;volcengine&quot;,
      &quot;api_base_url&quot;: &quot;https://ark.cn-beijing.volces.com/api/v3/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;deepseek-v3-250324&quot;, &quot;deepseek-r1-250528&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;deepseek&quot;]
      }
    },
    {
      &quot;name&quot;: &quot;modelscope&quot;,
      &quot;api_base_url&quot;: &quot;https://api-inference.modelscope.cn/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;&quot;,
      &quot;models&quot;: [&quot;Qwen/Qwen3-Coder-480B-A35B-Instruct&quot;, &quot;Qwen/Qwen3-235B-A22B-Thinking-2507&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [
          [
            &quot;maxtoken&quot;,
            {
              &quot;max_tokens&quot;: 65536
            }
          ],
          &quot;enhancetool&quot;
        ],
        &quot;Qwen/Qwen3-235B-A22B-Thinking-2507&quot;: {
          &quot;use&quot;: [&quot;reasoning&quot;]
        }
      }
    },
    {
      &quot;name&quot;: &quot;dashscope&quot;,
      &quot;api_base_url&quot;: &quot;https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;&quot;,
      &quot;models&quot;: [&quot;qwen3-coder-plus&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [
          [
            &quot;maxtoken&quot;,
            {
              &quot;max_tokens&quot;: 65536
            }
          ],
          &quot;enhancetool&quot;
        ]
      }
    },
    {
      &quot;name&quot;: &quot;aihubmix&quot;,
      &quot;api_base_url&quot;: &quot;https://aihubmix.com/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-&quot;,
      &quot;models&quot;: [
        &quot;Z/glm-4.5&quot;,
        &quot;claude-opus-4-20250514&quot;,
        &quot;gemini-2.5-pro&quot;
      ]
    }
  ],
  &quot;Router&quot;: {
    &quot;default&quot;: &quot;deepseek,deepseek-chat&quot;,
    &quot;background&quot;: &quot;ollama,qwen2.5-coder:latest&quot;,
    &quot;think&quot;: &quot;deepseek,deepseek-reasoner&quot;,
    &quot;longContext&quot;: &quot;openrouter,google/gemini-2.5-pro-preview&quot;,
    &quot;longContextThreshold&quot;: 60000,
    &quot;webSearch&quot;: &quot;gemini,gemini-2.5-flash&quot;
  }
}
```

### 3. Running Claude Code with the Router

Start Claude Code using the router:

```shell
ccr code
```

&gt; **Note**: After modifying the configuration file, you need to restart the service for the changes to take effect:
&gt;
&gt; ```shell
&gt; ccr restart
&gt; ```

### 4. UI Mode

For a more intuitive experience, you can use the UI mode to manage your configuration:

```shell
ccr ui
```

This will open a web-based interface where you can easily view and edit your `config.json` file.

![UI](/blog/images/ui.png)

### 5. CLI Model Management

For users who prefer terminal-based workflows, you can use the interactive CLI model selector:

```shell
ccr model
```
![](blog/images/models.gif)

This command provides an interactive interface to:

- View current configuration:
- See all configured models (default, background, think, longContext, webSearch, image)
- Switch models: Quickly change which model is used for each router type
- Add new models: Add models to existing providers
- Create new providers: Set up complete provider configurations including:
   - Provider name and API endpoint
   - API key
   - Available models
   - Transformer configuration with support for:
     - Multiple transformers (openrouter, deepseek, gemini, etc.)
     - Transformer options (e.g., maxtoken with custom limits)
     - Provider-specific routing (e.g., OpenRouter provider preferences)

The CLI tool validates all inputs and provides helpful prompts to guide you through the configuration process, making it easy to manage complex setups without editing JSON files manually.

### 6. Activate Command (Environment Variables Setup)

The `activate` command allows you to set up environment variables globally in your shell, enabling you to use the `claude` command directly or integrate Claude Code Router with applications built using the Agent SDK.

To activate the environment variables, run:

```shell
eval &quot;$(ccr activate)&quot;
```

This command outputs the necessary environment variables in shell-friendly format, which are then set in your current shell session. After activation, you can:

- **Use `claude` command directly**: Run `claude` commands without needing to use `ccr code`. The `claude` command will automatically route requests through Claude Code Router.
- **Integrate with Agent SDK applications**: Applications built with the Anthropic Agent SDK will automatically use the configured router and models.

The `activate` command sets the following environment variables:

- `ANTHROPIC_AUTH_TOKEN`: API key from your configuration
- `ANTHROPIC_BASE_URL`: The local router endpoint (default: `http://127.0.0.1:3456`)
- `NO_PROXY`: Set to `127.0.0.1` to prevent proxy interference
- `DISABLE_TELEMETRY`: Disables telemetry
- `DISABLE_COST_WARNINGS`: Disables cost warnings
- `API_TIMEOUT_MS`: API timeout from your configuration

&gt; **Note**: Make sure the Claude Code Router service is running (`ccr start`) before using the activated environment variables. The environment variables are only valid for the current shell session. To make them persistent, you can add `eval &quot;$(ccr activate)&quot;` to your shell configuration file (e.g., `~/.zshrc` or `~/.bashrc`).

#### Providers

The `Providers` array is where you define the different model providers you want to use. Each provider object requires:

- `name`: A unique name for the provider.
- `api_base_url`: The full API endpoint for chat completions.
- `api_key`: Your API key for the provider.
- `models`: A list of model names available from this provider.
- `transformer` (optional): Specifies transformers to process requests and responses.

#### Transformers

Transformers allow you to modify the request and response payloads to ensure compatibility with different provider APIs.

- **Global Transformer**: Apply a transformer to all models from a provider. In this example, the `openrouter` transformer is applied to all models under the `openrouter` provider.
  ```json
  {
    &quot;name&quot;: &quot;openrouter&quot;,
    &quot;api_base_url&quot;: &quot;https://openrouter.ai/api/v1/chat/completions&quot;,
    &quot;api_key&quot;: &quot;sk-xxx&quot;,
    &quot;models&quot;: [
      &quot;google/gemini-2.5-pro-preview&quot;,
      &quot;anthropic/claude-sonnet-4&quot;,
      &quot;anthropic/claude-3.5-sonnet&quot;
    ],
    &quot;transformer&quot;: { &quot;use&quot;: [&quot;openrouter&quot;] }
  }
  ```
- **Model-Specific Transformer**: Apply a transformer to a specific model. In this example, the `deepseek` transformer is applied to all models, and an additional `tooluse` transformer is applied only to the `deepseek-chat` model.

  ```json
  {
    &quot;name&quot;: &quot;deepseek&quot;,
    &quot;api_base_url&quot;: &quot;https://api.deepseek.com/chat/completions&quot;,
    &quot;api_key&quot;: &quot;sk-xxx&quot;,
    &quot;models&quot;: [&quot;deepseek-chat&quot;, &quot;deepseek-reasoner&quot;],
    &quot;transformer&quot;: {
      &quot;use&quot;: [&quot;deepseek&quot;],
      &quot;deepseek-chat&quot;: { &quot;use&quot;: [&quot;tooluse&quot;] }
    }
  }
  ```

- **Passing Options to a Transformer**: Some transformers, like `maxtoken`, accept options. To pass options, use a nested array where the first element is the transformer name and the second is an options object.
  ```json
  {
    &quot;name&quot;: &quot;siliconflow&quot;,
    &quot;api_base_url&quot;: &quot;https://api.siliconflow.cn/v1/chat/completions&quot;,
    &quot;api_key&quot;: &quot;sk-xxx&quot;,
    &quot;models&quot;: [&quot;moonshotai/Kimi-K2-Instruct&quot;],
    &quot;transformer&quot;: {
      &quot;use&quot;: [
        [
          &quot;maxtoken&quot;,
          {
            &quot;max_tokens&quot;: 16384
          }
        ]
      ]
    }
  }
  ```

**Available Built-in Transformers:**

- `Anthropic`:If you use only the `Anthropic` transformer, it will preserve the original request and response parameters(you can use it to connect directly to an Anthropic endpoint).
- `deepseek`: Adapts requests/responses for DeepSeek API.
- `gemini`: Adapts requests/responses for Gemini API.
- `openrouter`: Adapts requests/responses for OpenRouter API. It can also accept a `provider` routing parameter to specify which underlying providers OpenRouter should use. For more details, refer to the [OpenRouter documentation](https://openrouter.ai/docs/features/provider-routing). See an example below:
  ```json
    &quot;transformer&quot;: {
      &quot;use&quot;: [&quot;openrouter&quot;],
      &quot;moonshotai/kimi-k2&quot;: {
        &quot;use&quot;: [
          [
            &quot;openrouter&quot;,
            {
              &quot;provider&quot;: {
                &quot;only&quot;: [&quot;moonshotai/fp8&quot;]
              }
            }
          ]
        ]
      }
    }
  ```
- `groq`: Adapts requests/responses for groq API.
- `maxtoken`: Sets a specific `max_tokens` value.
- `tooluse`: Optimizes tool usage for certain models via `tool_choice`.
- `gemini-cli` (experimental): Unofficial support for Gemini via Gemini CLI [gemini-cli.js](https://gist.github.com/musistudio/1c13a65f35916a7ab690649d3df8d1cd).
- `reasoning`: Used to process the `reasoning_content` field.
- `sampling`: Used to process sampling information fields such as `temperature`, `top_p`, `top_k`, and `repetition_penalty`.
- `enhancetool`: Adds a layer of error tolerance to the tool call parameters returned by the LLM (this will cause the tool call information to no longer be streamed).
- `cleancache`: Clears the `cache_control` field from requests.
- `vertex-gemini`: Handles the Gemini API using Vertex authentication.
- `chutes-glm` Unofficial support for GLM 4.5 model via Chutes [chutes-glm-transformer.js](https://gist.github.com/vitobotta/2be3f33722e05e8d4f9d2b0138b8c863).
- `qwen-cli` (experimental): Unofficial support for qwen3-coder-plus model via Qwen CLI [qwen-cli.js](https://gist.github.com/musistudio/f5a67841ced39912fd99e42200d5ca8b).
- `rovo-cli` (experimental): Unofficial support for gpt-5 via Atlassian Rovo Dev CLI [rovo-cli.js](https://gist.github.com/SaseQ/c2a20a38b11276537ec5332d1f7a5e53).

**Custom Transformers:**

You can also create your own transformers and load them via the `transformers` field in `config.json`.

```json
{
  &quot;transformers&quot;: [
    {
      &quot;path&quot;: &quot;/User/xxx/.claude-code-router/plugins/gemini-cli.js&quot;,
      &quot;options&quot;: {
        &quot;project&quot;: &quot;xxx&quot;
      }
    }
  ]
}
```

#### Router

The `Router` object defines which model to use for different scenarios:

- `default`: The default model for general tasks.
- `background`: A model for background tasks. This can be a smaller, local model to save costs.
- `think`: A model for reasoning-heavy tasks, like Plan Mode.
- `longContext`: A model for handling long contexts (e.g., &gt; 60K tokens).
- `longContextThreshold` (optional): The token count threshold for triggering the long context model. Defaults to 60000 if not specified.
- `webSearch`: Used for handling web search tasks and this requires the model itself to support the feature. If you&#039;re using openrouter, you need to add the `:online` suffix after the model name.
- `image` (beta): Used for handling image-related tasks (supported by CCR‚Äôs built-in agent). If the model does not support tool calling, you need to set the `config.forceUseImageAgent` property to `true`.

- You can also switch models dynamically in Claude Code with the `/model` command:
`/model provider_name,model_name`
Example: `/model openrouter,anthropic/claude-3.5-sonnet`

#### Custom Router

For more advanced routing logic, you can specify a custom router script via the `CUSTOM_ROUTER_PATH` in your `config.json`. This allows you to implement complex routing rules beyond the default scenarios.

In your `config.json`:

```json
{
  &quot;CUSTOM_ROUTER_PATH&quot;: &quot;/User/xxx/.claude-code-router/custom-router.js&quot;
}
```

The custom router file must be a JavaScript module that exports an `async` function. This function receives the request object and the config object as arguments and should return the provider and model name as a string (e.g., `&quot;provider_name,model_name&quot;`), or `null` to fall back to the default router.

Here is an example of a `custom-router.js` based on `custom-router.example.js`:

```javascript
// /User/xxx/.claude-code-router/custom-router.js

/**
 * A custom router function to determine which model to use based on the request.
 *
 * @param {object} req - The request object from Claude Code, containing the request body.
 * @param {object} config - The application&#039;s config object.
 * @returns {Promise&lt;string|null&gt;} - A promise that resolves to the &quot;provider,model_name&quot; string, or null to use the default router.
 */
module.exports = async function router(req, config) {
  const userMessage = req.body.messages.find((m) =&gt; m.role === &quot;user&quot;)?.content;

  if (userMessage &amp;&amp; userMessage.includes(&quot;explain this code&quot;)) {
    // Use a powerful model for code explanation
    return &quot;openrouter,anthropic/claude-3.5-sonnet&quot;;
  }

  // Fallback to the default router configuration
  return null;
};
```

##### Subagent Routing

For routing within subagents, you must specify a particular provider and model by including `&lt;CCR-SUBAGENT-MODEL&gt;provider,model&lt;/CCR-SUBAGENT-MODEL&gt;` at the **beginning** of the subagent&#039;s prompt. This allows you to direct specific subagent tasks to designated models.

**Example:**

```
&lt;CCR-SUBAGENT-MODEL&gt;openrouter,anthropic/claude-3.5-sonnet&lt;/CCR-SUBAGENT-MODEL&gt;
Please help me analyze this code snippet for potential optimizations...
```

## Status Line (Beta)
To better monitor the status of claude-code-router at runtime, version v1.0.40 includes a built-in statusline tool, which you can enable in the UI.
![statusline-config.png](/blog/images/statusline-config.png)

The effect is as follows:
![statusline](/blog/images/statusline.png)

## ü§ñ GitHub Actions

Integrate Claude Code Router into your CI/CD pipeline. After setting up [Claude Code Actions](https://docs.anthropic.com/en/docs/claude-code/github-actions), modify your `.github/workflows/claude.yaml` to use the router:

```yaml
name: Claude Code

on:
  issue_comment:
    types: [created]
  # ... other triggers

jobs:
  claude:
    if: |
      (github.event_name == &#039;issue_comment&#039; &amp;&amp; contains(github.event.comment.body, &#039;@claude&#039;)) ||
      # ... other conditions
    runs-on: ubuntu-latest
    permissions:
   

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>