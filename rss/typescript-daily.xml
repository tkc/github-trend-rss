<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Sat, 11 Oct 2025 00:04:34 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[browserbase/stagehand]]></title>
            <link>https://github.com/browserbase/stagehand</link>
            <guid>https://github.com/browserbase/stagehand</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[The AI Browser Automation Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/browserbase/stagehand">browserbase/stagehand</a></h1>
            <p>The AI Browser Automation Framework</p>
            <p>Language: TypeScript</p>
            <p>Stars: 18,105</p>
            <p>Forks: 1,143</p>
            <p>Stars today: 248 stars today</p>
            <h2>README</h2><pre>&lt;div id=&quot;toc&quot; align=&quot;center&quot; style=&quot;margin-bottom: 0;&quot;&gt;
  &lt;ul style=&quot;list-style: none; margin: 0; padding: 0;&quot;&gt;
    &lt;a href=&quot;https://stagehand.dev&quot;&gt;
      &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;media/dark_logo.png&quot; /&gt;
        &lt;img alt=&quot;Stagehand&quot; src=&quot;media/light_logo.png&quot; width=&quot;200&quot; style=&quot;margin-right: 30px;&quot; /&gt;
      &lt;/picture&gt;
    &lt;/a&gt;
  &lt;/ul&gt;
&lt;/div&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;The AI Browser Automation Framework&lt;/strong&gt;&lt;br&gt;
  &lt;a href=&quot;https://docs.stagehand.dev&quot;&gt;Read the Docs&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/browserbase/stagehand/tree/main?tab=MIT-1-ov-file#MIT-1-ov-file&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;media/dark_license.svg&quot; /&gt;
      &lt;img alt=&quot;MIT License&quot; src=&quot;media/light_license.svg&quot; /&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;media/dark_slack.svg&quot; /&gt;
      &lt;img alt=&quot;Slack Community&quot; src=&quot;media/light_slack.svg&quot; /&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://trendshift.io/repositories/12122&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12122&quot; alt=&quot;browserbase%2Fstagehand | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
If you&#039;re looking for the Python implementation, you can find it 
&lt;a href=&quot;https://github.com/browserbase/stagehand-python&quot;&gt; here&lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot; style=&quot;display: flex; align-items: center; justify-content: center; gap: 4px; margin-bottom: 0;&quot;&gt;
  &lt;b&gt;Vibe code&lt;/b&gt;
  &lt;span style=&quot;font-size: 1.05em;&quot;&gt; Stagehand with &lt;/span&gt;
  &lt;a href=&quot;https://director.ai&quot; style=&quot;display: flex; align-items: center;&quot;&gt;
    &lt;span&gt;Director&lt;/span&gt;
  &lt;/a&gt;
  &lt;span&gt; &lt;/span&gt;
  &lt;picture&gt;
    &lt;img alt=&quot;Director&quot; src=&quot;media/director_icon.svg&quot; width=&quot;25&quot; /&gt;
  &lt;/picture&gt;
&lt;/div&gt;

## Why Stagehand?

Most existing browser automation tools either require you to write low-level code in a framework like Selenium, Playwright, or Puppeteer, or use high-level agents that can be unpredictable in production. By letting developers choose what to write in code vs. natural language, Stagehand is the natural choice for browser automations in production.

1. **Choose when to write code vs. natural language**: use AI when you want to navigate unfamiliar pages, and use code ([Playwright](https://playwright.dev/)) when you know exactly what you want to do.

2. **Preview and cache actions**: Stagehand lets you preview AI actions before running them, and also helps you easily cache repeatable actions to save time and tokens.

3. **Computer use models with one line of code**: Stagehand lets you integrate SOTA computer use models from OpenAI and Anthropic into the browser with one line of code.

## Example

Here&#039;s how to build a sample browser automation with Stagehand:

&lt;div align=&quot;center&quot;&gt;
  &lt;div style=&quot;max-width:300px;&quot;&gt;
    &lt;img src=&quot;/media/github_demo.gif&quot; alt=&quot;See Stagehand in Action&quot;&gt;
  &lt;/div&gt;
&lt;/div&gt;

```typescript
// Use Playwright functions on the page object
const page = stagehand.page;
await page.goto(&quot;https://github.com/browserbase&quot;);

// Use act() to execute individual actions
await page.act(&quot;click on the stagehand repo&quot;);

// Use Computer Use agents for larger actions
const agent = stagehand.agent({
    provider: &quot;openai&quot;,
    model: &quot;computer-use-preview&quot;,
});
await agent.execute(&quot;Get to the latest PR&quot;);

// Use extract() to read data from the page
const { author, title } = await page.extract({
  instruction: &quot;extract the author and title of the PR&quot;,
  schema: z.object({
    author: z.string().describe(&quot;The username of the PR author&quot;),
    title: z.string().describe(&quot;The title of the PR&quot;),
  }),
});
```

## Documentation

Visit [docs.stagehand.dev](https://docs.stagehand.dev) to view the full documentation.

## Getting Started

Start with Stagehand with one line of code, or check out our [Quickstart Guide](https://docs.stagehand.dev/first-steps/quickstart) for more information:

```bash
npx create-browser-app
```

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.loom.com/share/f5107f86d8c94fa0a8b4b1e89740f7a7&quot;&gt;
      &lt;p&gt;Watch Anirudh demo create-browser-app to create a Stagehand project!&lt;/p&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://www.loom.com/share/f5107f86d8c94fa0a8b4b1e89740f7a7&quot;&gt;
      &lt;img style=&quot;max-width:300px;&quot; src=&quot;https://cdn.loom.com/sessions/thumbnails/f5107f86d8c94fa0a8b4b1e89740f7a7-ec3f428b6775ceeb-full-play.gif&quot;&gt;
    &lt;/a&gt;
  &lt;/div&gt;

### Build and Run from Source

```bash
git clone https://github.com/browserbase/stagehand.git
cd stagehand
pnpm install
pnpm playwright install
pnpm run build
pnpm run example # run the blank script at ./examples/example.ts
pnpm run example 2048 # run the 2048 example at ./examples/2048.ts
pnpm run evals -man # see evaluation suite options
```

Stagehand is best when you have an API key for an LLM provider and Browserbase credentials. To add these to your project, run:

```bash
cp .env.example .env
nano .env # Edit the .env file to add API keys
```

## Contributing

&gt; [!NOTE]  
&gt; We highly value contributions to Stagehand! For questions or support, please join our [Slack community](https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg).

At a high level, we&#039;re focused on improving reliability, speed, and cost in that order of priority. If you&#039;re interested in contributing, we strongly recommend reaching out to [Miguel Gonzalez](https://x.com/miguel_gonzf) or [Paul Klein](https://x.com/pk_iv) in our [Slack community](https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg) before starting to ensure that your contribution aligns with our goals.

For more information, please see our [Contributing Guide](https://docs.stagehand.dev/examples/contributing).

## Acknowledgements

This project heavily relies on [Playwright](https://playwright.dev/) as a resilient backbone to automate the web. It also would not be possible without the awesome techniques and discoveries made by [tarsier](https://github.com/reworkd/tarsier), [gemini-zod](https://github.com/jbeoris/gemini-zod), and [fuji-web](https://github.com/normal-computing/fuji-web).

We&#039;d like to thank the following people for their major contributions to Stagehand:
- [Paul Klein](https://github.com/pkiv)
- [Anirudh Kamath](https://github.com/kamath)
- [Sean McGuire](https://github.com/seanmcguire12)
- [Miguel Gonzalez](https://github.com/miguelg719)
- [Sameel Arif](https://github.com/sameelarif)
- [Filip Michalsky](https://github.com/filip-michalsky)
- [Jeremy Press](https://x.com/jeremypress)
- [Navid Pour](https://github.com/navidpour)

## License

Licensed under the MIT License.

Copyright 2025 Browserbase, Inc.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[anthropics/claude-code]]></title>
            <link>https://github.com/anthropics/claude-code</link>
            <guid>https://github.com/anthropics/claude-code</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anthropics/claude-code">anthropics/claude-code</a></h1>
            <p>Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 36,154</p>
            <p>Forks: 2,275</p>
            <p>Stars today: 177 stars today</p>
            <h2>README</h2><pre># Claude Code

![](https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square) [![npm]](https://www.npmjs.com/package/@anthropic-ai/claude-code)

[npm]: https://img.shields.io/npm/v/@anthropic-ai/claude-code.svg?style=flat-square

Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows -- all through natural language commands. Use it in your terminal, IDE, or tag @claude on Github.

**Learn more in the [official documentation](https://docs.anthropic.com/en/docs/claude-code/overview)**.

&lt;img src=&quot;./demo.gif&quot; /&gt;

## Get started

1. Install Claude Code:

```sh
npm install -g @anthropic-ai/claude-code
```

2. Navigate to your project directory and run `claude`.

## Reporting Bugs

We welcome your feedback. Use the `/bug` command to report issues directly within Claude Code, or file a [GitHub issue](https://github.com/anthropics/claude-code/issues).

## Connect on Discord

Join the [Claude Developers Discord](https://anthropic.com/discord) to connect with other developers using Claude Code. Get help, share feedback, and discuss your projects with the community.

## Data collection, usage, and retention

When you use Claude Code, we collect feedback, which includes usage data (such as code acceptance or rejections), associated conversation data, and user feedback submitted via the `/bug` command.

### How we use your data

See our [data usage policies](https://docs.anthropic.com/en/docs/claude-code/data-usage).

### Privacy safeguards

We have implemented several safeguards to protect your data, including limited retention periods for sensitive information, restricted access to user session data, and clear policies against using feedback for model training.

For full details, please review our [Commercial Terms of Service](https://www.anthropic.com/legal/commercial-terms) and [Privacy Policy](https://www.anthropic.com/legal/privacy).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[TibixDev/winboat]]></title>
            <link>https://github.com/TibixDev/winboat</link>
            <guid>https://github.com/TibixDev/winboat</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[Run Windows apps on 🐧 Linux with ✨ seamless integration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/TibixDev/winboat">TibixDev/winboat</a></h1>
            <p>Run Windows apps on 🐧 Linux with ✨ seamless integration</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,230</p>
            <p>Forks: 239</p>
            <p>Stars today: 1,263 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;left&quot;&gt;
  &lt;table&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;img src=&quot;gh-assets/winboat_logo.svg&quot; alt=&quot;WinBoat Logo&quot; width=&quot;150&quot;&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;h1 style=&quot;color: #7C86FF; margin: 0; font-size: 32px;&quot;&gt;WinBoat&lt;/h1&gt;
        &lt;p style=&quot;color: oklch(90% 0 0); font-size: 14px; margin: 5px 0;&quot;&gt;Windows for Penguins.&lt;br&gt;
        Run Windows apps on 🐧 Linux with ✨ seamless integration&lt;/p&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

## Screenshots
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;gh-assets/features/feat_dash.png&quot; alt=&quot;WinBoat Dashboard&quot; width=&quot;45%&quot;&gt;
  &lt;img src=&quot;gh-assets/features/feat_apps.png&quot; alt=&quot;WinBoat Apps&quot; width=&quot;45%&quot;&gt;
  &lt;img src=&quot;gh-assets/features/feat_native.png&quot; alt=&quot;Native Windows&quot; width=&quot;45%&quot;&gt;
&lt;/div&gt;

## ⚠️ Work in Progress ⚠️
WinBoat is currently in beta, so expect to occasionally run into hiccups and bugs. You should be comfortable with some level of troubleshooting if you decide to try it, however we encourage you to give it a shot anyway.

## Features
- **🎨 Elegant Interface**: Sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience
- **📦 Automated Installs**: Simple installation process through our interface - pick your preferences &amp; specs and let us handle the rest
- **🚀 Run Any App**: If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications as native OS-level windows in your Linux environment
- **🖥️ Full Windows Desktop**: Access the complete Windows desktop experience when you need it, or run individual apps seamlessly integrated into your Linux workflow
- **📁 Filesystem Integration**: Your home directory is mounted in Windows, allowing easy file sharing between the two systems without any hassle
- **✨ And many more**: Smartcard passthrough, resource monitoring, and more features being added regularly

## How Does It Work?
WinBoat is an Electron app which allows you to run Windows apps on Linux using a containerized approach. Windows runs as a VM inside a Docker container, we communicate with it using the [WinBoat Guest Server](https://github.com/TibixDev/winboat/tree/main/guest_server) to retrieve data we need from Windows. For compositing applications as native OS-level windows, we use FreeRDP together with Windows&#039;s RemoteApp protocol.

## Prerequisites
Before running WinBoat, ensure your system meets the following requirements:

- **RAM**: At least 4 GB of RAM
- **CPU**: At least 2 CPU threads  
- **Storage**: At least 32 GB free space in `/var`
- **Virtualization**: KVM enabled in BIOS/UEFI
  - [How to enable virtualization](https://duckduckgo.com/?t=h_&amp;q=how+to+enable+virtualization+in+%3Cmotherboard+brand%3E+bios&amp;ia=web)
- **Docker**: Required for containerization
  - [Installation Guide](https://docs.docker.com/engine/install/)
  - **⚠️ NOTE:** Docker Desktop is **not** supported, you will run into issues if you use it
- **Docker Compose v2**: Required for compatibility with docker-compose.yml files
  - [Installation Guide](https://docs.docker.com/compose/install/#plugin-linux-only)
- **Docker User Group**: Add your user to the `docker` group
  - [Setup Instructions](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user)
- **FreeRDP**: Required for remote desktop connection (Please make sure you have **Version 3.x.x** with sound support included)
  - [Installation Guide](https://github.com/FreeRDP/FreeRDP/wiki/PreBuilds)
- [OPTIONAL] **Kernel Modules**: The `iptables` / `nftables` and `iptable_nat` kernel modules can be loaded for network autodiscovery and better shared filesystem performance, but this is not obligatory in newer versions of WinBoat
  - [Module loading instructions](https://rentry.org/rmfq2e5e)

## Downloading
You can download the latest Linux builds under the [Releases](https://github.com/TibixDev/winboat/releases) tab. We currently offer four variants:
- **AppImage:** A popular &amp; portable app format which should run fine on most distributions
- **Unpacked:** The raw unpacked files, simply run the executable (`linux-unpacked/winboat`)
- **.deb:** The intended format for Debian based distributions
- **.rpm:** The intended format for Fedora based distributions

## Known Issues About Container Runtimes
- Podman is **unsupported** for now
- Docker Desktop is **unsupported** for now
- Distros that emulate Docker through a Podman socket are **unsupported**
- Any rootless containerization solution is currently **unsupported**

## Building WinBoat
- For building you need to have NodeJS and Go installed on your system
- Clone the repo (`git clone https://github.com/TibixDev/WinBoat`)
- Install the dependencies (`npm i`)
- Build the app and the guest server using `npm run build:linux-gs`
- You can now find the built app under `dist` with an AppImage and an Unpacked variant

## Running WinBoat in development mode
- Make sure you meet the [prerequisites](#prerequisites)
- Additionally, for development you need to have NodeJS and Go installed on your system
- Clone the repo (`git clone https://github.com/TibixDev/WinBoat`)
- Install the dependencies (`npm i`)
- Build the guest server (`npm run build-guest-server`)
- Run the app (`npm run dev`)

## Contributing
Contributions are welcome! Whether it&#039;s bug fixes, feature improvements, or documentation updates, we appreciate your help making WinBoat better.

**Please note**: We maintain a focus on technical contributions only. Pull requests containing political/sexual content, or other sensitive/controversial topics will not be accepted. Let&#039;s keep things focused on making great software! 🚀

Feel free to:
- Report bugs and issues
- Submit feature requests  
- Contribute code improvements
- Help with documentation
- Share feedback and suggestions

Check out our issues page to get started, or feel free to open a new issue if you&#039;ve found something that needs attention.

## License
WinBoat is licensed under the [MIT](https://github.com/TibixDev/winboat/blob/main/LICENSE) license

## Inspiration / Alternatives
These past few years some cool projects have surfaced with similar concepts, some of which we&#039;ve also taken inspirations from.\
They&#039;re awesome and you should check them out:
- [WinApps](https://github.com/winapps-org/winapps)
- [Cassowary](https://github.com/casualsnek/cassowary)
- [dockur/windows](https://github.com/dockur/windows) (🌟 Also used in WinBoat)

## Socials &amp; Contact
- [![Website](https://img.shields.io/badge/Website-winboat.app-blue?style=flat&amp;logo=googlechrome&amp;logoColor=white)](https://www.winboat.app/)
- [![Twitter](https://img.shields.io/badge/Twitter-@winboat__app-1DA1F2?style=flat&amp;logo=x&amp;logoColor=white)](https://x.com/winboat_app)
- [![Mastodon](https://img.shields.io/badge/Mastodon-@winboat-6364FF?style=flat&amp;logo=mastodon&amp;logoColor=white)](https://fosstodon.org/@winboat)
- [![Bluesky](https://img.shields.io/badge/Bluesky-winboat.app-00A8E8?style=flat&amp;logo=bluesky&amp;logoColor=white)](http://bsky.app/profile/winboat.app)
- [![Discord](https://img.shields.io/badge/Discord-Join_Community-5865F2?style=flat&amp;logo=discord&amp;logoColor=white)](http://discord.gg/MEwmpWm4tN)
- [![Email](https://img.shields.io/badge/Email-staff@winboat.app-D14836?style=flat&amp;logo=gmail&amp;logoColor=white)](mailto:staff@winboat.app)
- [![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/TibixDev/winboat)

## Star History
&lt;a href=&quot;https://www.star-history.com/#tibixdev/winboat&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=tibixdev/winboat&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=tibixdev/winboat&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=tibixdev/winboat&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[CapSoftware/Cap]]></title>
            <link>https://github.com/CapSoftware/Cap</link>
            <guid>https://github.com/CapSoftware/Cap</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[Open source Loom alternative. Beautiful, shareable screen recordings.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/CapSoftware/Cap">CapSoftware/Cap</a></h1>
            <p>Open source Loom alternative. Beautiful, shareable screen recordings.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 12,367</p>
            <p>Forks: 845</p>
            <p>Stars today: 136 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;p align=&quot;center&quot;&gt;
   &lt;img width=&quot;150&quot; height=&quot;150&quot; src=&quot;https://github.com/CapSoftware/Cap/blob/main/apps/desktop/src-tauri/icons/Square310x310Logo.png&quot; alt=&quot;Logo&quot;&gt;
  &lt;/p&gt;
	&lt;h1 align=&quot;center&quot;&gt;&lt;b&gt;Cap&lt;/b&gt;&lt;/h1&gt;
	&lt;p align=&quot;center&quot;&gt;
		The open source Loom alternative.
    &lt;br /&gt;
    &lt;a href=&quot;https://cap.so&quot;&gt;&lt;strong&gt;Cap.so »&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;b&gt;Downloads for &lt;/b&gt;
		&lt;a href=&quot;https://cap.so/download&quot;&gt;macOS &amp; Windows&lt;/a&gt;
    &lt;br /&gt;
  &lt;/p&gt;
&lt;/p&gt;
&lt;br/&gt;

[![Open Bounties](https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2FCapSoftware%2Fbounties%3Fstatus%3Dopen)](https://console.algora.io/org/CapSoftware/bounties?status=open)

Cap is the open source alternative to Loom. It&#039;s a video messaging tool that allows you to record, edit and share videos in seconds.

&lt;img src=&quot;https://raw.githubusercontent.com/CapSoftware/Cap/refs/heads/main/apps/web/public/landing-cover.png&quot;/&gt;

# Self Hosting

Cap Web is available to self-host using Docker or Railway, see our [self-hosting docs](https://cap.so/docs/self-hosting) to learn more.
You can also use the button below to deploy Cap Web to Railway:

[![Deploy on Railway](https://railway.com/button.svg)](https://railway.com/new/template/PwpGcf)

Cap Desktop can connect to your self-hosted Cap Web instance regardless of if you build it yourself or [download from our website](https://cap.so/download).

# Monorepo App Architecture

We use a combination of Rust, React (Next.js), TypeScript, Tauri, Drizzle (ORM), MySQL, TailwindCSS throughout this Turborepo powered monorepo.

&gt; A note about database: The codebase is currently designed to work with MySQL only. MariaDB or other compatible databases might partially work but are not officially supported.

### Apps:

- `desktop`: A [Tauri](https://tauri.app) (Rust) app, using [SolidStart](https://start.solidjs.com) on the frontend.
- `web`: A [Next.js](https://nextjs.org) web app.

### Packages:

- `ui`: A [React](https://reactjs.org) Shared component library.
- `utils`: A [React](https://reactjs.org) Shared utility library.
- `tsconfig`: Shared `tsconfig` configurations used throughout the monorepo.
- `database`: A [React](https://reactjs.org) and [Drizzle ORM](https://orm.drizzle.team/) Shared database library.
- `config`: `eslint` configurations (includes `eslint-config-next`, `eslint-config-prettier` other configs used throughout the monorepo).

### License:
Portions of this software are licensed as follows:

- All code residing in the `cap-camera*` and `scap-*` families of crates is licensed under the MIT License (see [licenses/LICENSE-MIT](https://github.com/CapSoftware/Cap/blob/main/licenses/LICENSE-MIT)).
- All third party components are licensed under the original license provided by the owner of the applicable component
- All other content not mentioned above is available under the AGPLv3 license as defined in [LICENSE](https://github.com/CapSoftware/Cap/blob/main/LICENSE)
  
# Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for more information. This guide is a work in progress, and is updated regularly as the app matures.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[xyflow/xyflow]]></title>
            <link>https://github.com/xyflow/xyflow</link>
            <guid>https://github.com/xyflow/xyflow</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[React Flow | Svelte Flow - Powerful open source libraries for building node-based UIs with React (https://reactflow.dev) or Svelte (https://svelteflow.dev). Ready out-of-the-box and infinitely customizable.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xyflow/xyflow">xyflow/xyflow</a></h1>
            <p>React Flow | Svelte Flow - Powerful open source libraries for building node-based UIs with React (https://reactflow.dev) or Svelte (https://svelteflow.dev). Ready out-of-the-box and infinitely customizable.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 32,421</p>
            <p>Forks: 2,132</p>
            <p>Stars today: 92 stars today</p>
            <h2>README</h2><pre>![xyflow-header](https://user-images.githubusercontent.com/2857535/279643999-ffda9f91-6b6d-447d-82be-fcbd6103edb6.svg#gh-light-mode-only)
![xyflow-header-dark](https://user-images.githubusercontent.com/2857535/279644026-a01c231c-6c6e-4b41-96e0-a85c75c9acee.svg#gh-dark-mode-only)

&lt;div align=&quot;center&quot;&gt;

![GitHub License MIT](https://img.shields.io/github/license/wbkd/react-flow?color=%23ff0072)
![npm downloads](https://img.shields.io/npm/dt/reactflow?color=%23FF0072&amp;label=React%20Flow%20downloads)
![npm downloads](https://img.shields.io/npm/dt/@xyflow/svelte?color=%23FF3E00&amp;label=Svelte%20Flow%20downloads)

Powerful open source libraries for building node-based UIs with React or Svelte. Ready out-of-the-box and infinitely customizable.

[React Flow](https://reactflow.dev/) · [Svelte Flow](https://svelteflow.dev/) · [React Flow Pro](https://reactflow.dev/pro) · [Discord](https://discord.gg/Bqt6xrs)
&lt;/div&gt;

---

## The xyflow mono repo

The xyflow repository is the home of four packages:
* React Flow 12 `@xyflow/react` [packages/react](./packages/react)
* React Flow 11 `reactflow` [v11 branch](https://github.com/xyflow/xyflow/tree/v11)
* Svelte Flow `@xyflow/svelte` [packages/svelte](./packages/svelte)
* Shared helper library `@xyflow/system` [packages/system](./packages/system)

## Commercial usage

**Are you using React Flow or Svelte Flow for a personal project?** Great! No sponsorship needed, you can support us by reporting any bugs you find, sending us screenshots of your projects, and starring us on Github 🌟

**Are you using React Flow or Svelte Flow at your organization and making money from it?** Awesome! We rely on your support to keep our libraries developed and maintained under an MIT License, just how we like it. For React Flow you can do that on the [React Flow Pro website](https://reactflow.dev/pro) and for both of our libraries you can do it through [Github Sponsors](https://github.com/sponsors/xyflow).

## Getting started

The best way to get started is to check out the [React Flow](https://reactflow.dev/learn) or [Svelte Flow](https://svelteflow.dev/learn) learn section. However if you want to get a sneak peek of how to install and use the libraries you can see it here: 

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;React Flow&lt;/strong&gt; basic usage&lt;/summary&gt;

  ### Installation
  
  ```sh
npm install @xyflow/react
  ```

  ### Basic usage
  ```jsx
import { useCallback } from &#039;react&#039;;
import {
  ReactFlow,
  MiniMap,
  Controls,
  Background,
  useNodesState,
  useEdgesState,
  addEdge,
} from &#039;@xyflow/react&#039;;

import &#039;@xyflow/react/dist/style.css&#039;;

const initialNodes = [
  { id: &#039;1&#039;, position: { x: 0, y: 0 }, data: { label: &#039;1&#039; } },
  { id: &#039;2&#039;, position: { x: 0, y: 100 }, data: { label: &#039;2&#039; } },
];

const initialEdges = [{ id: &#039;e1-2&#039;, source: &#039;1&#039;, target: &#039;2&#039; }];

function Flow() {
  const [nodes, setNodes, onNodesChange] = useNodesState(initialNodes);
  const [edges, setEdges, onEdgesChange] = useEdgesState(initialEdges);

  const onConnect = useCallback((params) =&gt; setEdges((eds) =&gt; addEdge(params, eds)), [setEdges]);

  return (
    &lt;ReactFlow
      nodes={nodes}
      edges={edges}
      onNodesChange={onNodesChange}
      onEdgesChange={onEdgesChange}
      onConnect={onConnect}
    &gt;
      &lt;MiniMap /&gt;
      &lt;Controls /&gt;
      &lt;Background /&gt;
    &lt;/ReactFlow&gt;
  );
}

export default Flow;
```
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Svelte Flow&lt;/strong&gt; basic usage&lt;/summary&gt;

  ### Installation
  
  ```sh
npm install @xyflow/svelte
  ```

  ### Basic usage
  ```svelte
&lt;script lang=&quot;ts&quot;&gt;
  import { writable } from &#039;svelte/store&#039;;
  import {
    SvelteFlow,
    Controls,
    Background,
    BackgroundVariant,
    MiniMap,
  } from &#039;@xyflow/svelte&#039;;

  import &#039;@xyflow/svelte/dist/style.css&#039;
  
  const nodes = writable([
    {
      id: &#039;1&#039;,
      type: &#039;input&#039;,
      data: { label: &#039;Input Node&#039; },
      position: { x: 0, y: 0 }
    },
    {
      id: &#039;2&#039;,
      type: &#039;custom&#039;,
      data: { label: &#039;Node&#039; },
      position: { x: 0, y: 150 }
    }
  ]);

  const edges = writable([
    {
      id: &#039;1-2&#039;,
      type: &#039;default&#039;,
      source: &#039;1&#039;,
      target: &#039;2&#039;,
      label: &#039;Edge Text&#039;
    }
  ]);
&lt;/script&gt;

&lt;SvelteFlow
  {nodes}
  {edges}
  fitView
  on:nodeclick={(event) =&gt; console.log(&#039;on node click&#039;, event)}
&gt;
  &lt;Controls /&gt;
  &lt;Background variant={BackgroundVariant.Dots} /&gt;
  &lt;MiniMap /&gt;
&lt;/SvelteFlow&gt;
```
&lt;/details&gt;

## Releases 

For releasing packages we are using [changesets](https://github.com/changesets/changesets) in combination with the [changeset Github action](https://github.com/changesets/action). The rough idea is:

1. create PRs for new features, updates and fixes (with a changeset if relevant for changelog)
2. merge into main 
3. changset creates a PR that bumps all packages based on the changesets 
4. merge changeset PR if you want to release to Github and npm

## Built by [xyflow](https://xyflow.com)

React Flow and Svelte Flow are maintained by the [xyflow team](https://xyflow.com/about). If you need help or want to talk to us about a collaboration, reach out through our [contact form](https://xyflow.com/contact) or by joining our [Discord Server](https://discord.gg/Bqt6xrs).

## License

React Flow and Svelte Flow are [MIT licensed](./LICENSE).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[supermemoryai/supermemory]]></title>
            <link>https://github.com/supermemoryai/supermemory</link>
            <guid>https://github.com/supermemoryai/supermemory</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[Memory engine and app that is extremely fast, scalable. The Memory API for the AI era.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/supermemoryai/supermemory">supermemoryai/supermemory</a></h1>
            <p>Memory engine and app that is extremely fast, scalable. The Memory API for the AI era.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 11,429</p>
            <p>Forks: 1,196</p>
            <p>Stars today: 62 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; style=&quot;padding-bottom:20px;padding-top:20px&quot;&gt;
  &lt;img src=&quot;logo.svg&quot; alt=&quot;supermemory Logo&quot; width=&quot;400&quot; /&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/landing-page.jpeg&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

## Features

### Core Functionality

- **[Add Memories from Any Content](#add-memory)**: Easily add memories from URLs, PDFs, and plain text—just paste, upload, or link.
- **[Chat with Your Memories](#chat-memories)**: Converse with your stored content using natural language chat.
- **[Supermemory MCP Integration](#mcp-integration)**: Seamlessly connect with all major AI tools (Claude, Cursor, etc.) via Supermemory MCP.

## How do i use this?

Go to [app.supermemory.ai](https://app.supermemory.ai) and sign into with your account

1. &lt;a id=&quot;add-memory&quot;&gt;&lt;/a&gt;Start Adding Memory with your choice of format (Note, Link, File)
&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/add-memory.png&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

2. You can also Connect to your favourite services (Notion, Google Drive, OneDrive)
&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/add-connections.png&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

3. &lt;a id=&quot;chat-memories&quot;&gt;&lt;/a&gt;Once Memories are added, you can chat with Supermemory by clicking on &quot;Open Chat&quot; and retrieve info from your saved memories
&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/chat.png&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

4. &lt;a id=&quot;mcp-integration&quot;&gt;&lt;/a&gt;Add MCP to your AI Tools (by clicking on &quot;Connect to your AI&quot; and select the AI tool you are trying to integrate)
&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/mcp.png&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

## Support

Have questions or feedback? We&#039;re here to help:

- Email: [dhravya@supermemory.com](mailto:dhravya@supermemory.com)
- Documentation: [docs.supermemory.ai](https://docs.supermemory.ai)

## Contributing

We welcome contributions from developers of all skill levels! Whether you&#039;re fixing bugs, adding features, or improving documentation, your help makes supermemory better for everyone.

### Quick Start for Contributors

1. **Fork and clone** the repository
2. **Install dependencies** with `bun install`
3. **Set up your environment** by copying `.env.example` to `.env.local`
4. **Start developing** with `bun run dev`

For detailed guidelines, development setup, coding standards, and the complete contribution workflow, please see our [**Contributing Guide**](CONTRIBUTING.md).

### Ways to Contribute

- 🐛 **Bug fixes** - Help us squash those pesky issues
- ✨ **New features** - Add functionality that users will love
- 🎨 **UI/UX improvements** - Make the interface more intuitive
- ⚡ **Performance optimizations** - Help us make supermemory faster

Check out our [Issues](https://github.com/supermemoryai/supermemory/issues) page for `good first issue` and `help wanted` labels to get started!

## Updates &amp; Roadmap

Stay up to date with the latest improvements:

- [Changelog](https://docs.supermemory.ai/changelog/overview)
- [X](https://x.com/supermemoryai).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[evershopcommerce/evershop]]></title>
            <link>https://github.com/evershopcommerce/evershop</link>
            <guid>https://github.com/evershopcommerce/evershop</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[🛍️ Typescript E-commerce Platform]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/evershopcommerce/evershop">evershopcommerce/evershop</a></h1>
            <p>🛍️ Typescript E-commerce Platform</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,326</p>
            <p>Forks: 1,785</p>
            <p>Stars today: 99 stars today</p>
            <h2>README</h2><pre>&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;img width=&quot;60&quot; height=&quot;68&quot; alt=&quot;EverShop Logo&quot; src=&quot;https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/logo-green.png&quot;/&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;h1 align=&quot;center&quot;&gt;EverShop&lt;/h1&gt;
&lt;/p&gt;
&lt;h4 align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://evershop.io/docs/development/getting-started/introduction&quot;&gt;Documentation&lt;/a&gt; |
    &lt;a href=&quot;https://demo.evershop.io/&quot;&gt;Demo&lt;/a&gt;
&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/evershopcommerce/evershop/actions/workflows/build_test.yml/badge.svg&quot; alt=&quot;Github Action&quot;&gt;
  &lt;a href=&quot;https://twitter.com/evershopjs&quot;&gt;
    &lt;img alt=&quot;Twitter Follow&quot; src=&quot;https://img.shields.io/twitter/follow/evershopjs?style=social&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/GSzt7dt7RM&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/757179260417867879?label=discord&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://opensource.org/licenses/GPL-3.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-GPLv3-blue.svg&quot; alt=&quot;License&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img alt=&quot;EverShop&quot; width=&quot;950&quot; src=&quot;https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/banner.png&quot;/&gt;
&lt;/p&gt;

## Introduction

EverShop is a modern, TypeScript-first eCommerce platform built with GraphQL and React. Designed for developers, it offers essential commerce features in a modular, fully customizable architecture—perfect for building tailored shopping experiences with confidence and speed.

## Installation Using Docker


You can get started with EverShop in minutes by using the Docker image. The Docker image is a great way to get started with EverShop without having to worry about installing dependencies or configuring your environment.

```bash
curl -sSL https://raw.githubusercontent.com/evershopcommerce/evershop/main/docker-compose.yml &gt; docker-compose.yml
docker-compose up -d
```

For the full installation guide, please refer to our [Installation guide](https://evershop.io/docs/development/getting-started/installation-guide).

## Documentation

- [Installation guide](https://evershop.io/docs/development/getting-started/installation-guide).

- [Extension development](https://evershop.io/docs/development/module/create-your-first-extension).

- [Theme development](https://evershop.io/docs/development/theme/theme-overview).


## Demo

Explore our demo store.

&lt;p align=&quot;left&quot;&gt;
  &lt;a href=&quot;https://demo.evershop.io/admin&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;evershop-backend-demo&quot; height=&quot;35&quot; alt=&quot;EverShop Admin Demo&quot; src=&quot;https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/evershop-demo-back.png&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://demo.evershop.io/&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;evershop-store-demo&quot; height=&quot;35&quot; alt=&quot;EverShop Store Demo&quot; src=&quot;https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/evershop-demo-front.png&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;b&gt;Demo user:&lt;/b&gt;

Email: demo@evershop.io&lt;br/&gt;
Password: 123456

## Support

If you like my work, feel free to:

- ⭐ this repository. It helps.
- [![Tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)][tweet] about EverShop. Thank you!

[tweet]: https://twitter.com/intent/tweet?url=https%3A%2F%2Fgithub.com%2Fevershopcommerce%2Fevershop&amp;text=Awesome%20React%20Ecommerce%20Project&amp;hashtags=react,ecommerce,expressjs,graphql

## Contributing

EverShop is an open-source project. We are committed to a fully transparent development process and appreciate highly any contributions. Whether you are helping us fix bugs, proposing new features, improving our documentation or spreading the word - we would love to have you as part of the EverShop community.

### Ask a question about EverShop

You can ask questions, and participate in discussions about EverShop-related topics in the EverShop Discord channel.

&lt;a href=&quot;https://discord.gg/GSzt7dt7RM&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/discord_banner_github.svg&quot; /&gt;&lt;/a&gt;

### Create a bug report

If you see an error message or run into an issue, please [create bug report](https://github.com/evershopcommerce/evershop/issues/new). This effort is valued and it will help all EverShop users.


### Submit a feature request

If you have an idea, or you&#039;re missing a capability that would make development easier and more robust, please [Submit feature request](https://github.com/evershopcommerce/evershop/issues/new).

If a similar feature request already exists, don&#039;t forget to leave a &quot;+1&quot;.
If you add some more information such as your thoughts and vision about the feature, your comments will be embraced warmly :)


Please refer to our [Contribution Guidelines](./CONTRIBUTING.md) and [Code of Conduct](./CODE_OF_CONDUCT.md).

## License

[GPL-3.0 License](https://github.com/evershopcommerce/evershop/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[coze-dev/coze-studio]]></title>
            <link>https://github.com/coze-dev/coze-studio</link>
            <guid>https://github.com/coze-dev/coze-studio</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:27 GMT</pubDate>
            <description><![CDATA[An AI agent development platform with all-in-one visual tools, simplifying agent creation, debugging, and deployment like never before. Coze your way to AI Agent creation.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/coze-dev/coze-studio">coze-dev/coze-studio</a></h1>
            <p>An AI agent development platform with all-in-one visual tools, simplifying agent creation, debugging, and deployment like never before. Coze your way to AI Agent creation.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 17,512</p>
            <p>Forks: 2,432</p>
            <p>Stars today: 44 stars today</p>
            <h2>README</h2><pre>![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/943f576df3424fa98580c2ad18946719~tplv-goo7wpa0wc-image.image)

&lt;div align=&quot;center&quot;&gt;&lt;p&gt;
&lt;a href=&quot;#what-is-coze-studio&quot;&gt;Coze Studio&lt;/a&gt; •
&lt;a href=&quot;#feature-list&quot;&gt;Feature list&lt;/a&gt; •
&lt;a href=&quot;#quickstart&quot;&gt;Quickstart&lt;/a&gt; •
&lt;a href=&quot;#developer-guide&quot;&gt;Developer Guide&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
  &lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/license-apache2.0-blue.svg&quot;&gt;
  &lt;img alt=&quot;Go Version&quot; src=&quot;https://img.shields.io/badge/go-%3E%3D%201.23.4-blue&quot;&gt;
&lt;/p&gt;

English | [中文](README.zh_CN.md)

&lt;/div&gt;

## What is Coze Studio?

[Coze Studio](https://www.coze.cn/home) is an all-in-one AI agent development tool. Providing the latest large models and tools, various development modes and frameworks, Coze Studio offers the most convenient AI agent development environment, from development to deployment. 

* **Provides all core technologies needed for AI agent development**: prompt, RAG, plugin, workflow, enabling developers to focus on creating the core value of AI.
* **Ready to use for professional AI agent development at the lowest cost**: Coze Studio provides developers with complete app templates and build frameworks, allowing you to quickly construct various AI agents and turn creative ideas into reality.

Coze Studio, derived from the &quot;Coze Development Platform&quot; which has served tens of thousands of enterprises and millions of developers, we have made its core engine completely open. It is a one-stop visual development tool for AI Agents that makes creating, debugging, and deploying AI Agents unprecedentedly simple. Through Coze Studio&#039;s visual design and build tools, developers can quickly create and debug agents, apps, and workflows using no-code or low-code approaches, enabling powerful AI app development and more customized business logic. It&#039;s an ideal choice for building low-code AI products tailored . Coze Studio aims to lower the threshold for AI agent development and application, encouraging community co-construction and sharing for deeper exploration and practice in the AI field.

The backend of Coze Studio is developed using Golang, the frontend uses React + TypeScript, and the overall architecture is based on microservices and built following domain-driven design (DDD) principles. Provide developers with a high-performance, highly scalable, and easy-to-customize underlying framework to help them address complex business needs.
## Feature list
| **Module** | **Feature** |
| --- | --- |
| Model service | Manage the model list, integrate services such as OpenAI and Volcengine |
| Build agent | * Build, publish, and manage agent &lt;br&gt; * Support configuring workflows, knowledge bases, and other resources |
| Build apps | * Create and publish apps &lt;br&gt; * Build business logic through workflows |
| Build a workflow | Create, modify, publish, and delete workflows |
| Develop resources | Support creating and managing the following resources: &lt;br&gt; * Plugins &lt;br&gt; * Knowledge bases &lt;br&gt; * Databases &lt;br&gt; * Prompts |
| API and SDK | * Create conversations, initiate chats, and other OpenAPI &lt;br&gt; * Integrate agents or apps into your own app through Chat SDK |

## Quickstart
Learn how to obtain and deploy the open-source version of Coze Studio, quickly build projects, and experience Coze Studio&#039;s open-source version.

Environment requirements:

* Before installing Coze Studio, please ensure that your machine meets the following minimum system requirements: 2 Core、4 GB
* Pre-install Docker and Docker Compose, and start the Docker service.

Deployment steps:

1. Retrieve the source code.
   ```Bash
   # Clone code
   git clone https://github.com/coze-dev/coze-studio.git
   ```

2. Configure the model.
   1. Copy the template files of the doubao-seed-1.6 model from the template directory and paste them into the configuration file directory.
      ```Bash
      cd coze-studio
      # Copy model configuration template
      cp backend/conf/model/template/model_template_ark_doubao-seed-1.6.yaml backend/conf/model/ark_doubao-seed-1.6.yaml
      ```

   2. Modify the template file in the configuration file directory.
      1. Enter the directory `backend/conf/model`. Open the file `ark_doubao-seed-1.6.yaml`.
      2. Set the fields `id`, `meta.conn_config.api_key`, `meta.conn_config.model`, and save the file.
         * **id**: The model ID in Coze Studio, defined by the developer, must be a non-zero integer and globally unique. Agents or workflows call models based on model IDs. For models that have already been launched, do not modify their IDs; otherwise, it may result in model call failures.
         * **meta.conn_config.api_key**: The API Key for the model service. In this example, it is the API Key for Ark API Key. For more information, see [Get Volcengine Ark API Key](https://www.volcengine.com/docs/82379/1541594) or [Get BytePlus ModelArk API Key](https://docs.byteplus.com/en/docs/ModelArk/1361424?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=coze_open_source).
         * **meta.conn_config.model**: The Model name for the model service. In this example, it refers to the Model ID or Endpoint ID of Ark. For more information, see [Get Volcengine Ark Model ID](https://www.volcengine.com/docs/82379/1513689) / [Get Volcengine Ark Endpoint ID](https://www.volcengine.com/docs/82379/1099522) or  [Get BytePlus ModelArk Model ID](https://docs.byteplus.com/en/docs/ModelArk/model_id?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=coze_open_source) / [Get BytePlus ModelArk Endpoint ID](https://docs.byteplus.com/en/docs/ModelArk/1099522?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=coze_open_source).  
         &gt; For users in China, you may use Volcengine Ark; for users outside China, you may use BytePlus ModelArk instead.
3. Deploy and start the service.
   When deploying and starting Coze Studio for the first time, it may take a while to retrieve images and build local images. Please be patient. During deployment, you will see the following log information. If you see the message &quot;Container coze-server Started,&quot; it means the Coze Studio service has started successfully.
   ```Bash
   # Start the service
   cd docker
   cp .env.example .env
   docker compose up -d
   ```
   For common startup failure issues, **please refer to the [FAQ](https://github.com/coze-dev/coze-studio/wiki/9.-FAQ)**.
4. After starting the service, you can open Coze Studio by accessing `http://localhost:8888/` through your browser.

&gt; [!WARNING]
&gt; If you want to deploy Coze Studio in a public network environment, it is recommended to assess security risks before you begin, and take corresponding protection measures. Possible security risks include account registration functions, Python execution environments in workflow code nodes, Coze Server listening address configurations, SSRF (Server - Side Request Forgery), and some horizontal privilege escalations in APIs.  For more details, refer to [Quickstart](https://github.com/coze-dev/coze-studio/wiki/2.-Quickstart#security-risks-in-public-networks).

## Developer Guide

* **Project Configuration**:
   * [Model Configuration](https://github.com/coze-dev/coze-studio/wiki/3.-Model-configuration): Before deploying the open-source version of Coze Studio, you must configure the model service. Otherwise, you cannot select models when building agents, workflows, and apps.
   * [Plugin Configuration](https://github.com/coze-dev/coze-studio/wiki/4.-Plugin-Configuration): To use official plugins from the plugin store, you must first configure the plugins and add the authentication keys for third-party services.
   * [Basic Component Configuration](https://github.com/coze-dev/coze-studio/wiki/5.-Basic-component-configuration): Learn how to configure components such as image uploaders to use functions like image uploading in Coze Studio .
* [API Reference](https://github.com/coze-dev/coze-studio/wiki/6.-API-Reference): The Coze Studio Community Edition API and Chat SDK are authenticated using Personal Access Token, providing APIs for conversations and workflows.
* [Development Guidelines](https://github.com/coze-dev/coze-studio/wiki/7.-Development-Standards):
   * [Project Architecture](https://github.com/coze-dev/coze-studio/wiki/7.-Development-Standards#project-architecture): Learn about the technical architecture and core components of the open-source version of Coze Studio.
   * [Code Development and Testing](https://github.com/coze-dev/coze-studio/wiki/7.-Development-Standards#code-development-and-testing): Learn how to perform secondary development and testing based on the open-source version of Coze Studio.
   * [Troubleshooting](https://github.com/coze-dev/coze-studio/wiki/7.-Development-Standards#troubleshooting): Learn how to view container states and system logs.

## Using the open-source version of Coze Studio
&gt; Regarding how to use Coze Studio, refer to the [Coze Development Platform Official Documentation Center](https://www.coze.cn/open/docs) for more information. Please note that certain features, such as tone customization, are limited to the commercial version. Differences between the open-source and commercial versions can be found in the **Feature List**.


* [Quick Start](https://www.coze.cn/open/docs/guides/quickstart): Quickly build an AI assistant agent with Coze Studio.
* [Developing Agents](https://www.coze.cn/open/docs/guides/agent_overview): Learn how to create, build, publish, and manage agents. You can use functions such as knowledge, plugins, etc., to resolve model hallucination and lack of expertise in professional fields. In addition, Coze Studio provides rich memory features that enable agents to generate more accurate responses based on a personal user&#039;s historical conversations during interactions.
* [Develop workflows](https://www.coze.cn/open/docs/guides/workflow): A workflow is a set of executable instructions used to implement business logic or complete specific tasks. It structures data flow and task processing for apps or agents. Coze Studio provides a visual canvas where you can quickly build workflows by dragging and dropping nodes.
* [Resources such as plugins](https://www.coze.cn/open/docs/guides/plugin): In Coze Studio, workflows, plugins, databases, knowledge bases, and variables are collectively referred to as resources.
* **API &amp; SDK**: Coze Studio supports [API related to chat and workflows](https://github.com/coze-dev/coze-studio/wiki/6.-API-Reference), and you can also integrate agents or apps with local business systems through [Chat SDK](https://www.coze.cn/open/docs/developer_guides/web_sdk_overview).
* [Tutorials for practice](https://www.coze.cn/open/docs/tutorial/chat_sdk_web_online_customer_service): Learn how to use Coze Studio to implement various AI scenarios, such as building web-based online customer service using Chat SDK.

## License
This project uses the Apache 2.0 license. For details, please refer to the [LICENSE](https://github.com/coze-dev/coze-studio/blob/main/LICENSE-APACHE) file.
## Community contributions
We welcome community contributions. For contribution guidelines, please refer to [CONTRIBUTING](https://github.com/coze-dev/coze-studio/blob/main/CONTRIBUTING.md) and [Code of conduct](https://github.com/coze-dev/coze-studio/blob/main/CODE_OF_CONDUCT.md). We look forward to your contributions!
## Security and privacy
If you discover potential security issues in the project, or believe you may have found a security issue, please notify the ByteDance security team through our [security center](https://security.bytedance.com/src) or [vulnerability reporting email](mailto:sec@bytedance.com).
Please **do not** create public GitHub Issues.
## Join Community

We are committed to building an open and friendly developer community. All developers interested in AI Agent development are welcome to join us!

### 🐛 Issue Reports &amp; Feature Requests
To efficiently track and resolve issues while ensuring transparency and collaboration, we recommend participating through:
- **GitHub Issues**: [Submit bug reports or feature requests](https://github.com/coze-dev/coze-studio/issues)
- **Pull Requests**: [Contribute code or documentation improvements](https://github.com/coze-dev/coze-studio/pulls)

### 💬 Technical Discussion &amp; Communication
Join our technical discussion groups to share experiences with other developers and stay updated with the latest project developments:

**Feishu Group Chat**  
Scan the QR code below with Feishu mobile app to join:

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0a49081e8f3743e8bf3dcdded4bb571a~tplv-goo7wpa0wc-image.image)

**Discord Server**  
Click to join: [Coze Community](https://discord.gg/sTVN9EVS4B)

**Telegram Group**  
Click to join: Telegram Group [Coze](https://t.me/+pP9CkPnomDA0Mjgx)

## Acknowledgments
Thank you to all the developers and community members who have contributed to the Coze Studio project. Special thanks:

* The [Eino](https://github.com/cloudwego/eino) framework team - providing powerful support for Coze Studio&#039;s agent and workflow runtime engines, model abstractions and implementations, and knowledge base indexing and retrieval
* The [FlowGram](https://github.com/bytedance/flowgram.ai) team - providing a high-quality workflow building engine for Coze Studio&#039;s frontend workflow canvas editor
* The [Hertz](https://github.com/cloudwego/hertz) team - Go HTTP framework with high-performance and strong-extensibility for building micro-services
* All users who participated in testing and feedback</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[shadcn-ui/ui]]></title>
            <link>https://github.com/shadcn-ui/ui</link>
            <guid>https://github.com/shadcn-ui/ui</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[A set of beautifully-designed, accessible components and a code distribution platform. Works with your favorite frameworks. Open Source. Open Code.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/shadcn-ui/ui">shadcn-ui/ui</a></h1>
            <p>A set of beautifully-designed, accessible components and a code distribution platform. Works with your favorite frameworks. Open Source. Open Code.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 97,328</p>
            <p>Forks: 6,928</p>
            <p>Stars today: 231 stars today</p>
            <h2>README</h2><pre># shadcn/ui

Accessible and customizable components that you can copy and paste into your apps. Free. Open Source. **Use this to build your own component library**.

![hero](apps/www/public/og.jpg)

## Documentation

Visit http://ui.shadcn.com/docs to view the documentation.

## Contributing

Please read the [contributing guide](/CONTRIBUTING.md).

## License

Licensed under the [MIT license](https://github.com/shadcn/ui/blob/main/LICENSE.md).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[chaitin/PandaWiki]]></title>
            <link>https://github.com/chaitin/PandaWiki</link>
            <guid>https://github.com/chaitin/PandaWiki</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:25 GMT</pubDate>
            <description><![CDATA[PandaWiki 是一款 AI 大模型驱动的开源知识库搭建系统，帮助你快速构建智能化的 产品文档、技术文档、FAQ、博客系统，借助大模型的力量为你提供 AI 创作、AI 问答、AI 搜索等能力。]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/chaitin/PandaWiki">chaitin/PandaWiki</a></h1>
            <p>PandaWiki 是一款 AI 大模型驱动的开源知识库搭建系统，帮助你快速构建智能化的 产品文档、技术文档、FAQ、博客系统，借助大模型的力量为你提供 AI 创作、AI 问答、AI 搜索等能力。</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,370</p>
            <p>Forks: 572</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/images/banner.png&quot; width=&quot;400&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://ly.safepoint.cloud/Br48PoX&quot;&gt;📖 官方网站&lt;/a&gt; &amp;nbsp; | &amp;nbsp;
  &lt;a target=&quot;_blank&quot; href=&quot;/images/wechat.png&quot;&gt;🙋‍♂️ 微信交流群&lt;/a&gt;
&lt;/p&gt;

## 👋 项目介绍

PandaWiki 是一款 AI 大模型驱动的**开源知识库搭建系统**，帮助你快速构建智能化的 **产品文档、技术文档、FAQ、博客系统**，借助大模型的力量为你提供 **AI 创作、AI 问答、AI 搜索** 等能力。

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/images/setup.png&quot; width=&quot;800&quot; /&gt;
&lt;/p&gt;

## ⚡️ 界面展示

| PandaWiki 控制台                                 | Wiki 网站前台                                    |
| ------------------------------------------------ | ------------------------------------------------ |
| &lt;img src=&quot;/images/screenshot-1.png&quot; width=370 /&gt; | &lt;img src=&quot;/images/screenshot-2.png&quot; width=370 /&gt; |
| &lt;img src=&quot;/images/screenshot-3.png&quot; width=370 /&gt; | &lt;img src=&quot;/images/screenshot-4.png&quot; width=370 /&gt; |

## 🔥 功能与特色

- AI 驱动智能化：AI 辅助创作、AI 辅助问答、AI 辅助搜索。
- 强大的富文本编辑能力：兼容 Markdown 和 HTML，支持导出为 word、pdf、markdown 等多种格式。
- 轻松与第三方应用进行集成：支持做成网页挂件挂在其他网站上，支持做成钉钉、飞书、企业微信等聊天机器人。
- 通过第三方来源导入内容：根据网页 URL 导入、通过网站 Sitemap 导入、通过 RSS 订阅、通过离线文件导入等。

## 🚀 上手指南

### 安装 PandaWiki

你需要一台支持 Docker 20.x 以上版本的 Linux 系统来安装 PandaWiki。

使用 root 权限登录你的服务器，然后执行以下命令。

```bash
bash -c &quot;$(curl -fsSLk https://release.baizhi.cloud/panda-wiki/manager.sh)&quot;
```

根据命令提示的选项进行安装，命令执行过程将会持续几分钟，请耐心等待。

&gt; 关于安装与部署的更多细节请参考 [安装 PandaWiki](https://pandawiki.docs.baizhi.cloud/node/01971602-bb4e-7c90-99df-6d3c38cfd6d5)。

### 登录 PandaWiki

在上一步中，安装命令执行结束后，你的终端会输出以下内容。

```
SUCCESS  控制台信息:
SUCCESS    访问地址(内网): http://*.*.*.*:2443
SUCCESS    访问地址(外网): http://*.*.*.*:2443
SUCCESS    用户名: admin
SUCCESS    密码: **********************
```

使用浏览器打开上述内容中的 “访问地址”，你将看到 PandaWiki 的控制台登录入口，使用上述内容中的 “用户名” 和 “密码” 登录即可。

### 配置 AI 模型

&gt; PandaWiki 是由 AI 大模型驱动的 Wiki 系统，在未配置大模型的情况下 AI 创作、AI 问答、AI 搜索 等功能无法正常使用。
&gt; 
首次登录时会提示需要先配置 AI 模型，根据下方图片配置 “Chat 模型”。

&lt;img src=&quot;/images/modelconfig.png&quot; width=&quot;800&quot; /&gt;

&gt; 推荐使用 [百智云模型广场](https://baizhi.cloud/) 快速接入 AI 模型，注册即可获赠 5 元的模型使用额度。
&gt; 关于大模型的更多配置细节请参考 [接入 AI 模型](https://pandawiki.docs.baizhi.cloud/node/01971616-811c-70e1-82d9-706a202b8498)。

### 创建知识库

一切配置就绪后，你需要先创建一个 “知识库”。

“知识库” 是一组文档的集合，PandaWiki 将会根据知识库中的文档，为不同的知识库分别创建 “Wiki 网站”。

&lt;img src=&quot;/images/createkb.png&quot; width=&quot;800&quot; /&gt;

&gt; 关于知识库的更多配置细节请参考 [知识库设置](https://pandawiki.docs.baizhi.cloud/node/01971b5e-5bea-76d2-9f89-a95f98347bb0)。

### 💪 开始使用

如果你顺利完成了以上步骤，那么恭喜你，属于你的 PandaWiki 搭建成功，你可以：

- 访问 **控制台** 来管理你的知识库内容
- 访问 **Wiki 网站** 让你的用户使用知识库

## 社区交流

欢迎加入我们的微信群进行交流。

&lt;img src=&quot;/images/wechat.png&quot; width=&quot;300&quot; /&gt;

## 🙋‍♂️ 贡献

欢迎提交 [Pull Request](https://github.com/chaitin/PandaWiki/pulls) 或创建 [Issue](https://github.com/chaitin/PandaWiki/issues) 来帮助改进项目。

## 📝 许可证

本项目采用 GNU Affero General Public License v3.0 (AGPL-3.0) 许可证。这意味着：

- 你可以自由使用、修改和分发本软件
- 你必须以相同的许可证开源你的修改
- 如果你通过网络提供服务，也必须开源你的代码
- 商业使用需要遵守相同的开源要求


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=chaitin/PandaWiki&amp;type=Date)](https://www.star-history.com/#chaitin/PandaWiki&amp;Date)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[stravu/crystal]]></title>
            <link>https://github.com/stravu/crystal</link>
            <guid>https://github.com/stravu/crystal</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[Run multiple Codex and Claude Code AI sessions in parallel git worktrees. Test, compare approaches & manage AI-assisted development workflows in one desktop app.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stravu/crystal">stravu/crystal</a></h1>
            <p>Run multiple Codex and Claude Code AI sessions in parallel git worktrees. Test, compare approaches & manage AI-assisted development workflows in one desktop app.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,154</p>
            <p>Forks: 128</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre># Crystal - Multi-Session AI Code Assistant Manager

&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;&lt;a href=&quot;https://github.com/stravu/crystal/releases/latest&quot;&gt;**Get the Latest Release Here**&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![Build](https://github.com/stravu/crystal/actions/workflows/build.yml/badge.svg)](https://github.com/stravu/crystal/actions/workflows/build.yml)
[![Quality](https://github.com/stravu/crystal/actions/workflows/quality.yml/badge.svg)](https://github.com/stravu/crystal/actions/workflows/quality.yml)
[![Join our Discord](https://img.shields.io/badge/Join%20our-Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.gg/XrVa6q7DPY)

&lt;/div&gt;

Crystal is an Electron desktop application that lets you run, inspect, and test multiple AI coding assistant instances simultaneously using git worktrees. Crystal supports both **Claude Code** (Anthropic) and **Codex** (OpenAI) assistants. Crystal is an independent project created by [Stravu](https://stravu.com/?utm_source=Crystal&amp;utm_medium=OS&amp;utm_campaign=Crystal&amp;utm_id=1). Stravu provides editable, collaborate AI notebooks with text, tables, diagrams.







https://github.com/user-attachments/assets/5ca66e5b-8d05-4570-8417-5e8dcd7726ef







## The Crystal Workflow

1. Create sessions from prompts, each in an isolated git worktree
2. Iterate with your AI assistant (Claude Code or Codex) inside your sessions. Each iteration will make a commit so you can always go back.
3. Review the diff changes and make manual edits as needed
4. Squash your commits together with a new message and rebase to your main branch.

## ✨ Key Features

- **🤖 Multiple AI Assistants** - Support for Claude Code (Anthropic) and Codex (OpenAI)
- **🚀 Parallel Sessions** - Run multiple AI assistant instances at once
- **🌳 Git Worktree Isolation** - Each session gets its own branch
- **💾 Session Persistence** - Resume conversations anytime
- **🔧 Git Integration** - Built-in rebase and squash operations
- **📊 Change Tracking** - View diffs and track modifications
- **🔔 Notifications** - Desktop alerts when sessions need input
- **🏗️ Run Scripts** - Test changes instantly without leaving Crystal

## 🚀 Quick Start

### Prerequisites
- **For Claude Code**: Claude Code installed and logged in or API key provided
- **For Codex**: Codex installed (via npm: `@openai/codex` or Homebrew) with ChatGPT account or API key
- Git installed
- Git repository (Crystal will initialize one if needed)

### 1. Create a Project
Create a new project if you haven&#039;t already. This can be an empty folder or an existing git repository. Crystal will initialize git if needed.

### 2. Create Sessions from a Prompt
For any feature you&#039;re working on, create one or multiple new sessions:
- Each session will be an isolated git worktree

### 3. Monitor and Test Your Changes
As sessions complete:
- **Configure run scripts** in project settings to test your application without leaving Crystal
- **Use the diff viewer** to review all changes and make manual edits as needed
- **Continue conversations** with your AI assistant if you need additional changes

### 4. Finalize Your Changes
When everything looks good:
- Click **&quot;Rebase to main&quot;** to squash all commits with a new message and rebase them to your main branch
- This creates a clean commit history on your main branch

### Git Operations
- **Rebase from main**: Pull latest changes from main into your worktree
- **Squash and rebase to main**: Combine all commits and rebase onto main
- Always preview commands with tooltips before executing



## Installation

### Download Pre-built Binaries

- **macOS**: Download `Crystal-{version}.dmg` from the [latest release](https://github.com/stravu/crystal/releases/latest)
  - Open the DMG file and drag Crystal to your Applications folder
  - On first launch, you may need to right-click and select &quot;Open&quot; due to macOS security settings

- **Windows** (Unofficial - Build from source): Windows is currently supported through local builds only. An installer will be provided in future releases.
  - Follow the &quot;Building from Source&quot; instructions below

### Homebrew 
```bash
brew install --cask stravu-crystal
```

## Building from Source

```bash
# Clone the repository
git clone https://github.com/stravu/crystal.git
cd crystal

# One-time setup
pnpm run setup

# Run in development
pnpm run electron-dev
```

## Building for Production

```bash
# Build for macOS
pnpm build:mac
```



## 🤝 Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Developing Crystal with Crystal

If you&#039;re using Crystal to develop Crystal itself, you need to use a separate data directory to avoid conflicts with your main Crystal instance:

```bash
# Set the run script in your Crystal project settings to:
pnpm run setup &amp;&amp; pnpm run build:main &amp;&amp; CRYSTAL_DIR=~/.crystal_test pnpm electron-dev
```

This ensures:
- Your development Crystal instance uses `~/.crystal_test` for its data
- Your main Crystal instance continues using `~/.crystal` 
- Worktrees won&#039;t conflict between the two instances
- You can safely test changes without affecting your primary Crystal setup

## Using with Third-Party Deployments

To use Crystal with cloud providers or via corporate infrastructure, you should create a [settings](https://docs.anthropic.com/en/docs/claude-code/settings) file with `ENV` values to correctly connect to the provider.

For example, here is a minimal configuration to use Amazon Bedrock via an AWS Profile:

```json5
{
  &quot;env&quot;: {
    &quot;CLAUDE_CODE_USE_BEDROCK&quot;: &quot;1&quot;,
    &quot;AWS_REGION&quot;: &quot;us-east-2&quot;, // Replace with your AWS region
    &quot;AWS_PROFILE&quot;: &quot;my-aws-profile&quot; // Replace with your profile
  },
}
```

Check the [deployment documentation](https://docs.anthropic.com/en/docs/claude-code/third-party-integrations) for more information on getting setup with your particular deployment.

## Additional Documentation

For a full project overview, see [CLAUDE.md](CLAUDE.md). Additional diagrams, database schema details, release instructions, and license notes can be found in the [docs](./docs) directory.

## 📄 License

Crystal is open source software licensed under the [MIT License](LICENSE).

### Third-Party Licenses

Crystal includes third-party software components. All third-party licenses are documented in the [NOTICES](NOTICES) file. This file is automatically generated and kept up-to-date with our dependencies.

To regenerate the NOTICES file after updating dependencies:
```bash
pnpm run generate-notices
```

## Disclaimer

Crystal is an independent project created by [Stravu](https://stravu.com/?utm_source=Crystal&amp;utm_medium=OS&amp;utm_campaign=Crystal&amp;utm_id=1). Claude™ is a trademark of Anthropic, PBC. Codex™ is a trademark of OpenAI, Inc. Crystal is not affiliated with, endorsed by, or sponsored by Anthropic or OpenAI. This tool is designed to work with Claude Code and Codex, which must be installed separately.

---

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;frontend/public/stravu-logo.png&quot; alt=&quot;Stravu Logo&quot; width=&quot;80&quot; height=&quot;80&quot;&gt;
  &lt;br&gt;
  Made with ❤️ by &lt;a href=&quot;https://stravu.com/?utm_source=Crystal&amp;utm_medium=OS&amp;utm_campaign=Crystal&amp;utm_id=1&quot;&gt;Stravu&lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[open-metadata/OpenMetadata]]></title>
            <link>https://github.com/open-metadata/OpenMetadata</link>
            <guid>https://github.com/open-metadata/OpenMetadata</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[OpenMetadata is a unified metadata platform for data discovery, data observability, and data governance powered by a central metadata repository, in-depth column level lineage, and seamless team collaboration.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-metadata/OpenMetadata">open-metadata/OpenMetadata</a></h1>
            <p>OpenMetadata is a unified metadata platform for data discovery, data observability, and data governance powered by a central metadata repository, in-depth column level lineage, and seamless team collaboration.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,705</p>
            <p>Forks: 1,459</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://open-metadata.org&quot;&gt;
        &lt;img alt=&quot;Logo&quot; src=&quot;https://github.com/open-metadata/OpenMetadata/assets/40225091/e794ced8-7220-4393-8efc-3faf93bfb503&quot; width=&quot;49%&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Empower your Data Journey with OpenMetadata&lt;/b&gt;&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    
![Commit Activity](https://img.shields.io/github/commit-activity/m/open-metadata/OpenMetadata?style=for-the-badge)
[![Release](https://img.shields.io/github/release/open-metadata/OpenMetadata/all.svg?style=for-the-badge)](https://github.com/open-metadata/OpenMetadata/releases)

&lt;/div&gt;

## What is OpenMetadata?
[OpenMetadata](https://open-metadata.org/)  is a unified metadata platform for data discovery, data observability, and data governance powered by a central metadata repository, in-depth column level lineage, and seamless team collaboration. It is one of the fastest-growing open-source projects with a vibrant community and adoption by a diverse set of companies in a variety of industry verticals. Based on Open Metadata Standards and APIs, supporting connectors to a wide range of data services, OpenMetadata enables end-to-end metadata management, giving you the freedom to unlock the value of your data assets.
&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/open-metadata/OpenMetadata/assets/40225091/ebfb4ec5-f0a2-4d58-8ce5-a082b5cf0f76&quot; width=800&gt;
&lt;/div&gt;

&lt;br /&gt;
Contents:

- [Features](#key-features-of-openmetadata)
- [Try our Sandbox](#try-our-sandbox)
- [Install &amp; Run](#install-and-run-openmetadata)
- [Roadmap](https://docs.open-metadata.org/latest/roadmap)
- [Documentation and Support](#documentation-and-support)
- [Contributors](#contributors)

OpenMetadata Consists of Four Main Components:
- **Metadata Schemas**: These are the core definitions and vocabulary for metadata based on common abstractions and types. They also allow for custom extensions and properties to suit different use cases and domains.
- **Metadata Store**: This is the central repository for storing and managing the metadata graph, which connects data assets, users, and tool-generated metadata in a unified way.
- **Metadata APIs**: These are the interfaces for producing and consuming metadata, built on top of the metadata schemas. They enable seamless integration of user interfaces and tools, systems, and services with the metadata store.
- **Ingestion Framework**: This is a pluggable framework for ingesting metadata from various sources and tools to the metadata store. It supports about 84+ connectors for data warehouses, databases, dashboard services, messaging services, pipeline services, and more.

## Key Features of OpenMetadata
**Data Discovery**: Find and explore all your data assets in a single place using various strategies, such as keyword search, data associations, and advanced queries. You can search across tables, topics, dashboards, pipelines, and services.

![12](https://github.com/open-metadata/OpenMetadata/assets/40225091/0dbd2746-c93d-4a47-8d3e-ceb3ae01436f)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Collaboration**: Communicate, converse, and cooperate with other users and teams on data assets. You can get event notifications, send alerts, add announcements, create tasks, and use conversation threads.

![11](https://github.com/open-metadata/OpenMetadata/assets/40225091/7df29e12-8a29-44b7-9466-42474823783f)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Quality and Profiler**: Measure and monitor the quality with **no-code** to build trust in your data. You can define and run data quality tests, group them into test suites, and view the results in an interactive dashboard. With powerful collaboration, make data quality a shared responsibility in your organization.

![8](https://github.com/open-metadata/OpenMetadata/assets/40225091/6b330827-cc2d-4d06-abf0-a4d42ce532ba)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Governance**: Enforce data policies and standards across your organization. You can define data domains and data products, assign owners and stakeholders, and classify data assets using tags and terms. Use powerful automation features to auto-classify your data.

![10](https://github.com/open-metadata/OpenMetadata/assets/40225091/f7384a71-6b58-44ad-983f-e302718ee3f1)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Insights and KPIs**: Use reports and platform analytics to understand how your organization&#039;s data is doing. Data Insights provides a single-pane view of all the key metrics to reflect the state of your data best. Define the Key Performance Indicators (KPIs) and set goals within OpenMetadata to work towards better documentation, ownership, and tiering. Alerts can be set against the KPIs to be received on a specified schedule.

![9](https://github.com/open-metadata/OpenMetadata/assets/40225091/61fc2f65-2436-4fc9-9434-c27ee9b25183)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Lineage**: Track and visualize the origin and transformation of your data assets end-to-end. You can view column-level lineage, filter queries, and edit lineage manually using a no-code editor.
  
**Data Documentation**: Document your data assets and metadata entities using rich text, images, and links. You can also add comments and annotations and generate data dictionaries and data catalogs.
  
**Data Observability**: Monitor the health and performance of your data assets and pipelines. You can view metrics such as data freshness, data volume, data quality, and data latency. You can also set up alerts and notifications for any anomalies or failures.
  
**Data Security**: Secure your data and metadata using various authentication and authorization mechanisms. You can integrate with different identity providers for single sign-on and define roles and policies for access control.
  
**Webhooks**: Integrate with external applications and services using webhooks. You can register URLs to receive metadata event notifications and integrate with Slack, Microsoft Teams, and Google Chat.
  
**Connectors**: Ingest metadata from various sources and tools using connectors. OpenMetadata supports about 84+ connectors for data warehouses, databases, dashboard services, messaging services, pipeline services, and more.

## Try our Sandbox

Take a look and play with sample data at [http://sandbox.open-metadata.org](http://sandbox.open-metadata.org)

## Install and Run OpenMetadata
Get up and running in a few minutes. See the OpenMetadata documentation for [installation instructions](https://docs.open-metadata.org/quick-start/local-docker-deployment).

## Documentation and Support

We&#039;re here to help and make OpenMetadata even better! Check out [OpenMetadata documentation](https://docs.open-metadata.org/) for a complete description of OpenMetadata&#039;s features. Join our [Slack Community](https://slack.open-metadata.org/) to get in touch with us if you want to chat, need help, or discuss new feature requirements.


## Contributors

We ❤️ all contributions, big and small! Check out our [CONTRIBUTING](./CONTRIBUTING.md) guide to get started, and let us know how we can help.

Don&#039;t want to miss anything? Give the project a ⭐ 🚀 

A HUGE THANK YOU to all our supporters!

&lt;a href=&quot;https://github.com/open-metadata/OpenMetadata/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=open-metadata/OpenMetadata&amp;max=4000&amp;columns=30&quot; /&gt;
&lt;/a&gt;

## Stargazers

[![Stargazers of @open-metadata/OpenMetadata repo](http://reporoster.com/stars/open-metadata/OpenMetadata)](https://github.com/open-metadata/OpenMetadata/stargazers)

## License
OpenMetadata is released under [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[google-gemini/gemini-cli]]></title>
            <link>https://github.com/google-gemini/gemini-cli</link>
            <guid>https://github.com/google-gemini/gemini-cli</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:22 GMT</pubDate>
            <description><![CDATA[An open-source AI agent that brings the power of Gemini directly into your terminal.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google-gemini/gemini-cli">google-gemini/gemini-cli</a></h1>
            <p>An open-source AI agent that brings the power of Gemini directly into your terminal.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 78,639</p>
            <p>Forks: 8,541</p>
            <p>Stars today: 194 stars today</p>
            <h2>README</h2><pre># Gemini CLI

[![Gemini CLI CI](https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml/badge.svg)](https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml)
[![Gemini CLI E2E](https://github.com/google-gemini/gemini-cli/actions/workflows/e2e.yml/badge.svg)](https://github.com/google-gemini/gemini-cli/actions/workflows/e2e.yml)
[![Version](https://img.shields.io/npm/v/@google/gemini-cli)](https://www.npmjs.com/package/@google/gemini-cli)
[![License](https://img.shields.io/github/license/google-gemini/gemini-cli)](https://github.com/google-gemini/gemini-cli/blob/main/LICENSE)

![Gemini CLI Screenshot](./docs/assets/gemini-screenshot.png)

Gemini CLI is an open-source AI agent that brings the power of Gemini directly
into your terminal. It provides lightweight access to Gemini, giving you the
most direct path from your prompt to our model.

## 🚀 Why Gemini CLI?

- **🎯 Free tier**: 60 requests/min and 1,000 requests/day with personal Google
  account.
- **🧠 Powerful Gemini 2.5 Pro**: Access to 1M token context window.
- **🔧 Built-in tools**: Google Search grounding, file operations, shell
  commands, web fetching.
- **🔌 Extensible**: MCP (Model Context Protocol) support for custom
  integrations.
- **💻 Terminal-first**: Designed for developers who live in the command line.
- **🛡️ Open source**: Apache 2.0 licensed.

## 📦 Installation

### Quick Install

#### Run instantly with npx

```bash
# Using npx (no installation required)
npx https://github.com/google-gemini/gemini-cli
```

#### Install globally with npm

```bash
npm install -g @google/gemini-cli
```

#### Install globally with Homebrew (macOS/Linux)

```bash
brew install gemini-cli
```

#### System Requirements

- Node.js version 20 or higher
- macOS, Linux, or Windows

## Release Cadence and Tags

See [Releases](./docs/releases.md) for more details.

### Preview

New preview releases will be published each week at UTC 2359 on Tuesdays. These
releases will not have been fully vetted and may contain regressions or other
outstanding issues. Please help us test and install with `preview` tag.

```bash
npm install -g @google/gemini-cli@preview
```

### Stable

- New stable releases will be published each week at UTC 2000 on Tuesdays, this
  will be the full promotion of last week&#039;s `preview` release + any bug fixes
  and validations. Use `latest` tag.

```bash
npm install -g @google/gemini-cli@latest
```

### Nightly

- New releases will be published each week at UTC 0000 each day, This will be
  all changes from the main branch as represented at time of release. It should
  be assumed there are pending validations and issues. Use `nightly` tag.

```bash
npm install -g @google/gemini-cli@nightly
```

## 📋 Key Features

### Code Understanding &amp; Generation

- Query and edit large codebases
- Generate new apps from PDFs, images, or sketches using multimodal capabilities
- Debug issues and troubleshoot with natural language

### Automation &amp; Integration

- Automate operational tasks like querying pull requests or handling complex
  rebases
- Use MCP servers to connect new capabilities, including
  [media generation with Imagen, Veo or Lyria](https://github.com/GoogleCloudPlatform/vertex-ai-creative-studio/tree/main/experiments/mcp-genmedia)
- Run non-interactively in scripts for workflow automation

### Advanced Capabilities

- Ground your queries with built-in
  [Google Search](https://ai.google.dev/gemini-api/docs/grounding) for real-time
  information
- Conversation checkpointing to save and resume complex sessions
- Custom context files (GEMINI.md) to tailor behavior for your projects

### GitHub Integration

Integrate Gemini CLI directly into your GitHub workflows with
[**Gemini CLI GitHub Action**](https://github.com/google-github-actions/run-gemini-cli):

- **Pull Request Reviews**: Automated code review with contextual feedback and
  suggestions
- **Issue Triage**: Automated labeling and prioritization of GitHub issues based
  on content analysis
- **On-demand Assistance**: Mention `@gemini-cli` in issues and pull requests
  for help with debugging, explanations, or task delegation
- **Custom Workflows**: Build automated, scheduled and on-demand workflows
  tailored to your team&#039;s needs

## 🔐 Authentication Options

Choose the authentication method that best fits your needs:

### Option 1: Login with Google (OAuth login using your Google Account)

**✨ Best for:** Individual developers as well as anyone who has a Gemini Code
Assist License. (see
[quota limits and terms of service](https://cloud.google.com/gemini/docs/quotas)
for details)

**Benefits:**

- **Free tier**: 60 requests/min and 1,000 requests/day
- **Gemini 2.5 Pro** with 1M token context window
- **No API key management** - just sign in with your Google account
- **Automatic updates** to latest models

#### Start Gemini CLI, then choose _Login with Google_ and follow the browser authentication flow when prompted

```bash
gemini
```

#### If you are using a paid Code Assist License from your organization, remember to set the Google Cloud Project

```bash
# Set your Google Cloud Project
export GOOGLE_CLOUD_PROJECT=&quot;YOUR_PROJECT_ID&quot;
gemini
```

### Option 2: Gemini API Key

**✨ Best for:** Developers who need specific model control or paid tier access

**Benefits:**

- **Free tier**: 100 requests/day with Gemini 2.5 Pro
- **Model selection**: Choose specific Gemini models
- **Usage-based billing**: Upgrade for higher limits when needed

```bash
# Get your key from https://aistudio.google.com/apikey
export GEMINI_API_KEY=&quot;YOUR_API_KEY&quot;
gemini
```

### Option 3: Vertex AI

**✨ Best for:** Enterprise teams and production workloads

**Benefits:**

- **Enterprise features**: Advanced security and compliance
- **Scalable**: Higher rate limits with billing account
- **Integration**: Works with existing Google Cloud infrastructure

```bash
# Get your key from Google Cloud Console
export GOOGLE_API_KEY=&quot;YOUR_API_KEY&quot;
export GOOGLE_GENAI_USE_VERTEXAI=true
gemini
```

For Google Workspace accounts and other authentication methods, see the
[authentication guide](./docs/get-started/authentication.md).

## 🚀 Getting Started

### Basic Usage

#### Start in current directory

```bash
gemini
```

#### Include multiple directories

```bash
gemini --include-directories ../lib,../docs
```

#### Use specific model

```bash
gemini -m gemini-2.5-flash
```

#### Non-interactive mode for scripts

Get a simple text response:

```bash
gemini -p &quot;Explain the architecture of this codebase&quot;
```

For more advanced scripting, including how to parse JSON and handle errors, use
the `--output-format json` flag to get structured output:

```bash
gemini -p &quot;Explain the architecture of this codebase&quot; --output-format json
```

### Quick Examples

#### Start a new project

```bash
cd new-project/
gemini
&gt; Write me a Discord bot that answers questions using a FAQ.md file I will provide
```

#### Analyze existing code

```bash
git clone https://github.com/google-gemini/gemini-cli
cd gemini-cli
gemini
&gt; Give me a summary of all of the changes that went in yesterday
```

## 📚 Documentation

### Getting Started

- [**Quickstart Guide**](./docs/get-started/index.md) - Get up and running
  quickly.
- [**Authentication Setup**](./docs/get-started/authentication.md) - Detailed
  auth configuration.
- [**Configuration Guide**](./docs/get-started/configuration.md) - Settings and
  customization.
- [**Keyboard Shortcuts**](./docs/cli/keyboard-shortcuts.md) - Productivity
  tips.

### Core Features

- [**Commands Reference**](./docs/cli/commands.md) - All slash commands
  (`/help`, `/chat`, etc).
- [**Custom Commands**](./docs/cli/custom-commands.md) - Create your own
  reusable commands.
- [**Context Files (GEMINI.md)**](./docs/cli/gemini-md.md) - Provide persistent
  context to Gemini CLI.
- [**Checkpointing**](./docs/cli/checkpointing.md) - Save and resume
  conversations.
- [**Token Caching**](./docs/cli/token-caching.md) - Optimize token usage.

### Tools &amp; Extensions

- [**Built-in Tools Overview**](./docs/tools/index.md)
  - [File System Operations](./docs/tools/file-system.md)
  - [Shell Commands](./docs/tools/shell.md)
  - [Web Fetch &amp; Search](./docs/tools/web-fetch.md)
- [**MCP Server Integration**](./docs/tools/mcp-server.md) - Extend with custom
  tools.
- [**Custom Extensions**](./docs/extensions/index.md) - Build and share your own
  commands.

### Advanced Topics

- [**Headless Mode (Scripting)**](./docs/cli/headless.md) - Use Gemini CLI in
  automated workflows.
- [**Architecture Overview**](./docs/architecture.md) - How Gemini CLI works.
- [**IDE Integration**](./docs/ide-integration/index.md) - VS Code companion.
- [**Sandboxing &amp; Security**](./docs/cli/sandbox.md) - Safe execution
  environments.
- [**Trusted Folders**](./docs/cli/trusted-folders.md) - Control execution
  policies by folder.
- [**Enterprise Guide**](./docs/cli/enterprise.md) - Deploy and manage in a
  corporate environment.
- [**Telemetry &amp; Monitoring**](./docs/cli/telemetry.md) - Usage tracking.
- [**Tools API Development**](./docs/core/tools-api.md) - Create custom tools.

### Troubleshooting &amp; Support

- [**Troubleshooting Guide**](./docs/troubleshooting.md) - Common issues and
  solutions.
- [**FAQ**](./docs/faq.md) - Frequently asked questions.
- Use `/bug` command to report issues directly from the CLI.

### Using MCP Servers

Configure MCP servers in `~/.gemini/settings.json` to extend Gemini CLI with
custom tools:

```text
&gt; @github List my open pull requests
&gt; @slack Send a summary of today&#039;s commits to #dev channel
&gt; @database Run a query to find inactive users
```

See the [MCP Server Integration guide](./docs/tools/mcp-server.md) for setup
instructions.

## 🤝 Contributing

We welcome contributions! Gemini CLI is fully open source (Apache 2.0), and we
encourage the community to:

- Report bugs and suggest features.
- Improve documentation.
- Submit code improvements.
- Share your MCP servers and extensions.

See our [Contributing Guide](./CONTRIBUTING.md) for development setup, coding
standards, and how to submit pull requests.

Check our [Official Roadmap](https://github.com/orgs/google-gemini/projects/11)
for planned features and priorities.

## 📖 Resources

- **[Official Roadmap](./ROADMAP.md)** - See what&#039;s coming next.
- **[Changelog](./docs/changelogs/index.md)** - See recent notable updates.
- **[NPM Package](https://www.npmjs.com/package/@google/gemini-cli)** - Package
  registry.
- **[GitHub Issues](https://github.com/google-gemini/gemini-cli/issues)** -
  Report bugs or request features.
- **[Security Advisories](https://github.com/google-gemini/gemini-cli/security/advisories)** -
  Security updates.

### Uninstall

See the [Uninstall Guide](docs/cli/uninstall.md) for removal instructions.

## 📄 Legal

- **License**: [Apache License 2.0](LICENSE)
- **Terms of Service**: [Terms &amp; Privacy](./docs/tos-privacy.md)
- **Security**: [Security Policy](SECURITY.md)

---

&lt;p align=&quot;center&quot;&gt;
  Built with ❤️ by Google and the open source community
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[chatchat-space/Langchain-Chatchat]]></title>
            <link>https://github.com/chatchat-space/Langchain-Chatchat</link>
            <guid>https://github.com/chatchat-space/Langchain-Chatchat</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[Langchain-Chatchat（原Langchain-ChatGLM）基于 Langchain 与 ChatGLM, Qwen 与 Llama 等语言模型的 RAG 与 Agent 应用 | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM, Qwen and Llama) RAG and Agent app with langchain]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/chatchat-space/Langchain-Chatchat">chatchat-space/Langchain-Chatchat</a></h1>
            <p>Langchain-Chatchat（原Langchain-ChatGLM）基于 Langchain 与 ChatGLM, Qwen 与 Llama 等语言模型的 RAG 与 Agent 应用 | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM, Qwen and Llama) RAG and Agent app with langchain</p>
            <p>Language: TypeScript</p>
            <p>Stars: 36,218</p>
            <p>Forks: 6,039</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>![](docs/img/logo-long-chatchat-trans-v2.png)
&lt;a href=&quot;https://trendshift.io/repositories/329&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/329&quot; alt=&quot;chatchat-space%2FLangchain-Chatchat | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

[![pypi badge](https://img.shields.io/pypi/v/langchain-chatchat.svg)](https://shields.io/)
[![Generic badge](https://img.shields.io/badge/python-3.8%7C3.9%7C3.10%7C3.11-blue.svg)](https://pypi.org/project/pypiserver/)
[![zread](https://img.shields.io/badge/Ask_Zread-_.svg?style=flat&amp;color=00b0aa&amp;labelColor=000000&amp;logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQuOTYxNTYgMS42MDAxSDIuMjQxNTZDMS44ODgxIDEuNjAwMSAxLjYwMTU2IDEuODg2NjQgMS42MDE1NiAyLjI0MDFWNC45NjAxQzEuNjAxNTYgNS4zMTM1NiAxLjg4ODEgNS42MDAxIDIuMjQxNTYgNS42MDAxSDQuOTYxNTZDNS4zMTUwMiA1LjYwMDEgNS42MDE1NiA1LjMxMzU2IDUuNjAxNTYgNC45NjAxVjIuMjQwMUM1LjYwMTU2IDEuODg2NjQgNS4zMTUwMiAxLjYwMDEgNC45NjE1NiAxLjYwMDFaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00Ljk2MTU2IDEwLjM5OTlIMi4yNDE1NkMxLjg4ODEgMTAuMzk5OSAxLjYwMTU2IDEwLjY4NjQgMS42MDE1NiAxMS4wMzk5VjEzLjc1OTlDMS42MDE1NiAxNC4xMTM0IDEuODg4MSAxNC4zOTk5IDIuMjQxNTYgMTQuMzk5OUg0Ljk2MTU2QzUuMzE1MDIgMTQuMzk5OSA1LjYwMTU2IDE0LjExMzQgNS42MDE1NiAxMy43NTk5VjExLjAzOTlDNS42MDE1NiAxMC42ODY0IDUuMzE1MDIgMTAuMzk5OSA0Ljk2MTU2IDEwLjM5OTlaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik0xMy43NTg0IDEuNjAwMUgxMS4wMzg0QzEwLjY4NSAxLjYwMDEgMTAuMzk4NCAxLjg4NjY0IDEwLjM5ODQgMi4yNDAxVjQuOTYwMUMxMC4zOTg0IDUuMzEzNTYgMTAuNjg1IDUuNjAwMSAxMS4wMzg0IDUuNjAwMUgxMy43NTg0QzE0LjExMTkgNS42MDAxIDE0LjM5ODQgNS4zMTM1NiAxNC4zOTg0IDQuOTYwMVYyLjI0MDFDMTQuMzk4NCAxLjg4NjY0IDE0LjExMTkgMS42MDAxIDEzLjc1ODQgMS42MDAxWiIgZmlsbD0iI2ZmZiIvPgo8cGF0aCBkPSJNNCAxMkwxMiA0TDQgMTJaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00IDEyTDEyIDQiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIvPgo8L3N2Zz4K&amp;logoColor=ffffff)](https://zread.ai/chatchat-space/Langchain-Chatchat)

🌍 [READ THIS IN ENGLISH](README_en.md)

📃 **LangChain-Chatchat** (原 Langchain-ChatGLM)

基于 ChatGLM 等大语言模型与 Langchain 等应用框架实现，开源、可离线部署的 RAG 与 Agent 应用项目。

---

## 目录

* [概述](README.md#概述)
* [功能介绍](README.md#功能介绍)
    * [0.3.x 功能一览](README.md#03x-版本功能一览)
    * [已支持的模型推理框架与模型](README.md#已支持的模型部署框架与模型)
* [快速上手](README.md#快速上手)
    * [pip 安装部署](README.md#pip-安装部署)
    * [源码安装部署/开发部署](README.md#源码安装部署开发部署)
    * [Docker 部署](README.md#docker-部署)
* [项目里程碑](README.md#项目里程碑)
* [联系我们](README.md#联系我们)

## 概述

🤖️ 一种利用 [langchain](https://github.com/langchain-ai/langchain)
思想实现的基于本地知识库的问答应用，目标期望建立一套对中文场景与开源模型支持友好、可离线运行的知识库问答解决方案。

💡 受 [GanymedeNil](https://github.com/GanymedeNil) 的项目 [document.ai](https://github.com/GanymedeNil/document.ai)
和 [AlexZhangji](https://github.com/AlexZhangji)
创建的 [ChatGLM-6B Pull Request](https://github.com/THUDM/ChatGLM-6B/pull/216)
启发，建立了全流程可使用开源模型实现的本地知识库问答应用。本项目的最新版本中可使用 [Xinference](https://github.com/xorbitsai/inference)、[Ollama](https://github.com/ollama/ollama)
等框架接入 [GLM-4-Chat](https://github.com/THUDM/GLM-4)、 [Qwen2-Instruct](https://github.com/QwenLM/Qwen2)、 [Llama3](https://github.com/meta-llama/llama3)
等模型，依托于 [langchain](https://github.com/langchain-ai/langchain)
框架支持通过基于 [FastAPI](https://github.com/tiangolo/fastapi) 提供的 API
调用服务，或使用基于 [Streamlit](https://github.com/streamlit/streamlit) 的 WebUI 进行操作。

![](docs/img/langchain_chatchat_0.3.0.png)

✅ 本项目支持市面上主流的开源 LLM、 Embedding 模型与向量数据库，可实现全部使用**开源**模型**离线私有部署**。与此同时，本项目也支持
OpenAI GPT API 的调用，并将在后续持续扩充对各类模型及模型 API 的接入。

⛓️ 本项目实现原理如下图所示，过程包括加载文件 -&gt; 读取文本 -&gt; 文本分割 -&gt; 文本向量化 -&gt; 问句向量化 -&gt;
在文本向量中匹配出与问句向量最相似的 `top k`个 -&gt; 匹配出的文本作为上下文和问题一起添加到 `prompt`中 -&gt; 提交给 `LLM`生成回答。

📺 [原理介绍视频](https://www.bilibili.com/video/BV13M4y1e7cN/?share_source=copy_web&amp;vd_source=e6c5aafe684f30fbe41925d61ca6d514)

![实现原理图](docs/img/langchain+chatglm.png)

从文档处理角度来看，实现流程如下：

![实现原理图2](docs/img/langchain+chatglm2.png)

🚩 本项目未涉及微调、训练过程，但可利用微调或训练对本项目效果进行优化。

🌐 [AutoDL 镜像](https://www.codewithgpu.com/i/chatchat-space/Langchain-Chatchat/Langchain-Chatchat) 中 `0.3.0`
版本所使用代码已更新至本项目 `v0.3.0` 版本。

🐳 Docker 镜像将会在近期更新。

🧑‍💻 如果你想对本项目做出贡献，欢迎移步[开发指南](docs/contributing/README_dev.md) 获取更多开发部署相关信息。

## 功能介绍

### 0.3.x 版本功能一览

| 功能        | 0.2.x                            | 0.3.x                                                               |
|-----------|----------------------------------|---------------------------------------------------------------------|
| 模型接入      | 本地：fastchat&lt;br&gt;在线：XXXModelWorker | 本地：model_provider,支持大部分主流模型加载框架&lt;br&gt;在线：oneapi&lt;br&gt;所有模型接入均兼容openai sdk |
| Agent     | ❌不稳定                             | ✅针对ChatGLM3和Qwen进行优化,Agent能力显著提升                                    ||
| LLM对话     | ✅                                | ✅                                                                   ||
| 知识库对话     | ✅                                | ✅                                                                   ||
| 搜索引擎对话    | ✅                                | ✅                                                                   ||
| 文件对话      | ✅仅向量检索                           | ✅统一为File RAG功能,支持BM25+KNN等多种检索方式                                    ||
| 数据库对话     | ❌                                | ✅                                                                   ||
| 多模态图片对话     | ❌                                | ✅  推荐使用 qwen-vl-chat                   ||
| ARXIV文献对话 | ❌                                | ✅                                                                   ||
| Wolfram对话 | ❌                                | ✅                                                                   ||
| 文生图       | ❌                                | ✅                                                                   ||
| 本地知识库管理   | ✅                                | ✅                                                                   ||
| WEBUI     | ✅                                | ✅更好的多会话支持,自定义系统提示词...                                               |

0.3.x 版本的核心功能由 Agent 实现,但用户也可以手动实现工具调用:

|操作方式|实现的功能|适用场景|
|-------|---------|-------|
|选中&quot;启用Agent&quot;,选择多个工具|由LLM自动进行工具调用|使用ChatGLM3/Qwen或在线API等具备Agent能力的模型|
|选中&quot;启用Agent&quot;,选择单个工具|LLM仅解析工具参数|使用的模型Agent能力一般,不能很好的选择工具&lt;br&gt;想手动选择功能|
|不选中&quot;启用Agent&quot;,选择单个工具|不使用Agent功能的情况下,手动填入参数进行工具调用|使用的模型不具备Agent能力|
|不选中任何工具，上传一个图片|图片对话|使用 qwen-vl-chat 等多模态模型|

更多功能和更新请实际部署体验.

### 已支持的模型部署框架与模型

本项目中已经支持市面上主流的如 [GLM-4-Chat](https://github.com/THUDM/GLM-4)
与 [Qwen2-Instruct](https://github.com/QwenLM/Qwen2) 等新近开源大语言模型和 Embedding
模型，这些模型需要用户自行启动模型部署框架后，通过修改配置信息接入项目，本项目已支持的本地模型部署框架如下：

| 模型部署框架             | Xinference                                                                               | LocalAI                                                    | Ollama                                                                         | FastChat                                                                             |
|--------------------|------------------------------------------------------------------------------------------|------------------------------------------------------------|--------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|
| OpenAI API 接口对齐    | ✅                                                                                        | ✅                                                          | ✅                                                                              | ✅                                                                                    |
| 加速推理引擎             | GPTQ, GGML, vLLM, TensorRT, mlx                                                          | GPTQ, GGML, vLLM, TensorRT                                 | GGUF, GGML                                                                     | vLLM                                                                                 |
| 接入模型类型             | LLM, Embedding, Rerank, Text-to-Image, Vision, Audio                                     | LLM, Embedding, Rerank, Text-to-Image, Vision, Audio       | LLM, Text-to-Image, Vision                                                     | LLM, Vision                                                                          |
| Function Call      | ✅                                                                                        | ✅                                                          | ✅                                                                              | /                                                                                    |
| 更多平台支持(CPU, Metal) | ✅                                                                                        | ✅                                                          | ✅                                                                              | ✅                                                                                    |
| 异构                 | ✅                                                                                        | ✅                                                          | /                                                                              | /                                                                                    |
| 集群                 | ✅                                                                                        | ✅                                                          | /                                                                              | /                                                                                    |
| 操作文档链接             | [Xinference 文档](https://inference.readthedocs.io/zh-cn/latest/models/builtin/index.html) | [LocalAI 文档](https://localai.io/model-compatibility/)      | [Ollama 文档](https://github.com/ollama/ollama?tab=readme-ov-file#model-library) | [FastChat 文档](https://github.com/lm-sys/FastChat#install)                            |
| 可用模型               | [Xinference 已支持模型](https://inference.readthedocs.io/en/latest/models/builtin/index.html) | [LocalAI 已支持模型](https://localai.io/model-compatibility/#/) | [Ollama 已支持模型](https://ollama.com/library#/)                                   | [FastChat 已支持模型](https://github.com/lm-sys/FastChat/blob/main/docs/model_support.md) |

除上述本地模型加载框架外，项目中也为可接入在线 API 的 [One API](https://github.com/songquanpeng/one-api)
框架接入提供了支持，支持包括 [OpenAI ChatGPT](https://platform.openai.com/docs/guides/gpt/chat-completions-api)、[Azure OpenAI API](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference)、[Anthropic Claude](https://anthropic.com/)、[智谱清言](https://bigmodel.cn/)、[百川](https://platform.baichuan-ai.com/)
等常用在线 API 的接入使用。

&gt; [!Note]
&gt; 关于 Xinference 加载本地模型:
&gt; Xinference 内置模型会自动下载,如果想让它加载本机下载好的模型,可以在启动 Xinference 服务后,到项目 tools/model_loaders
&gt; 目录下执行 `streamlit run xinference_manager.py`,按照页面提示为指定模型设置本地路径即可.

## 快速上手

### pip 安装部署

#### 0. 软硬件要求

💡 软件方面，本项目已支持在 Python 3.8-3.11 环境中进行使用，并已在 Windows、macOS、Linux 操作系统中进行测试。

💻 硬件方面，因 0.3.0 版本已修改为支持不同模型部署框架接入，因此可在 CPU、GPU、NPU、MPS 等不同硬件条件下使用。

#### 1. 安装 Langchain-Chatchat

从 0.3.0 版本起，Langchain-Chatchat 提供以 Python 库形式的安装方式，具体安装请执行：

```shell
pip install langchain-chatchat -U
```

&gt; [!important]
&gt; 为确保所使用的 Python 库为最新版，建议使用官方 Pypi 源或清华源。

&gt; [!Note]
&gt; 因模型部署框架 Xinference 接入 Langchain-Chatchat 时需要额外安装对应的 Python 依赖库，因此如需搭配 Xinference
&gt; 框架使用时，建议使用如下安装方式：
&gt; ```shell
&gt; pip install &quot;langchain-chatchat[xinference]&quot; -U
&gt; ```

#### 2. 模型推理框架并加载模型

从 0.3.0 版本起，Langchain-Chatchat 不再根据用户输入的本地模型路径直接进行模型加载，涉及到的模型种类包括
LLM、Embedding、Reranker
及后续会提供支持的多模态模型等，均改为支持市面常见的各大模型推理框架接入，如 [Xinference](https://github.com/xorbitsai/inference)、[Ollama](https://github.com/ollama/ollama)、[LocalAI](https://github.com/mudler/LocalAI)、[FastChat](https://github.com/lm-sys/FastChat)、[One API](https://github.com/songquanpeng/one-api)
等。

因此，请确认在启动 Langchain-Chatchat 项目前，首先进行模型推理框架的运行，并加载所需使用的模型。

这里以 Xinference 举例,
请参考 [Xinference文档](https://inference.readthedocs.io/zh-cn/latest/getting_started/installation.html) 进行框架部署与模型加载。

&gt; [!WARNING]  
&gt; 为避免依赖冲突，请将 Langchain-Chatchat 和模型部署框架如 Xinference 等放在不同的 Python 虚拟环境中, 比如 conda, venv,
&gt; virtualenv 等。

#### 3. 初始化项目配置与数据目录

从 0.3.1 版本起，Langchain-Chatchat 使用本地 `yaml` 文件的方式进行配置，用户可以直接查看并修改其中的内容，服务器会自动更新无需重启。

1. 设置 Chatchat 存储配置文件和数据文件的根目录（可选）

```shell
# on linux or macos
export CHATCHAT_ROOT=/path/to/chatchat_data

# on windows
set CHATCHAT_ROOT=/path/to/chatchat_data
```

若不设置该环境变量，则自动使用当前目录。

2. 执行初始化

```shell
chatchat init
```

该命令会执行以下操作：

- 创建所有需要的数据目录
- 复制 samples 知识库内容
- 生成默认 `yaml` 配置文件

3. 修改配置文件

- 配置模型（model_settings.yaml）  
  需要根据步骤 **2. 模型推理框架并加载模型**
  中选用的模型推理框架与加载的模型进行模型接入配置，具体参考 `model_settings.yaml` 中的注释。主要修改以下内容：
  ```yaml
  # 默认选用的 LLM 名称
   DEFAULT_LLM_MODEL: qwen1.5-chat

   # 默认选用的 Embedding 名称
   DEFAULT_EMBEDDING_MODEL: bge-large-zh-v1.5

  # 将 `LLM_MODEL_CONFIG` 中 `llm_model, action_model` 的键改成对应的 LLM 模型
  # 在 `MODEL_PLATFORMS` 中修改对应模型平台信息
  ```
- 配置知识库路径（basic_settings.yaml）（可选）  
  默认知识库位于 `CHATCHAT_ROOT/data/knowledge_base`，如果你想把知识库放在不同的位置，或者想连接现有的知识库，可以在这里修改对应目录即可。
  ```yaml
  # 知识库默认存储路径
   KB_ROOT_PATH: D:\chatchat-test\data\knowledge_base

   # 数据库默认存储路径。如果使用sqlite，可以直接修改DB_ROOT_PATH；如果使用其它数据库，请直接修改SQLALCHEMY_DATABASE_URI。
   DB_ROOT_PATH: D:\chatchat-test\data\knowledge_base\info.db

   # 知识库信息数据库连接URI
   SQLALCHEMY_DATABASE_URI: sqlite:///D:\chatchat-test\data\knowledge_base\info.db
  ```
- 配置知识库（kb_settings.yaml）（可选）

  默认使用 `FAISS` 知识库，如果想连接其它类型的知识库，可以修改 `DEFAULT_VS_TYPE` 和 `kbs_config`。

#### 4. 初始化知识库

&gt; [!WARNING]  
&gt; 进行知识库初始化前，请确保已经启动模型推理框架及对应 `embedding` 模型，且已按照上述**步骤3**完成模型接入配置。

```shell
chatchat kb -r
```

更多功能可以查看 `chatchat kb --help`

出现以下日志即为成功:

```text 

----------------------------------------------------------------------------------------------------
知识库名称      ：samples
知识库类型      ：faiss
向量模型：      ：bge-large-zh-v1.5
知识库路径      ：/root/anaconda3/envs/chatchat/lib/python3.11/site-packages/chatchat/data/knowledge_base/samples
文件总数量      ：47
入库文件数      ：42
知识条目数      ：740
用时            ：0:02:29.701002
----------------------------------------------------------------------------------------------------

总计用时        ：0:02:33.414425

```

&gt; [!Note]
&gt; 知识库初始化的常见问题
&gt;
&gt; &lt;details&gt;
&gt;
&gt; ##### 1. Windows 下重建知识库或添加知识文件时卡住不动
&gt; 此问题常出现于新建虚拟环境中，可以通过以下方式确认：
&gt;
&gt; `from unstructured.partition.auto import partition`
&gt;
&gt; 如果该语句卡住无法执行，可以执行以下命令：
&gt; ```shell
&gt; pip uninstall python-magic-bin
&gt; # check the version of the uninstalled package
&gt; pip install &#039;python-magic-bin=={version}&#039;
&gt; ```
&gt; 然后按照本节指引重新创建知识库即可。
&gt;
&gt; &lt;/details&gt;

#### 5. 启动项目

```shell
chatchat start -a
```

出现以下界面即为启动成功:

![WebUI界面](docs/img/langchain_chatchat_webui.png)

&gt; [!WARNING]  
&gt; 由于 chatchat 配置默认监听地址 `DEFAULT_BIND_HOST` 为 127.0.0.1, 所以无法通过其他 ip 进行访问。
&gt;
&gt; 如需通过机器ip 进行访问(如 Linux 系统), 需要到 `basic_settings.yaml` 中将监听地址修改为 0.0.0.0。
&gt; &lt;/details&gt;

### 其它配置

1. 数据库对话配置请移步这里 [数据库对话配置说明](docs/install/README_text2sql.md)


### 源码安装部署/开发部署

源码安装部署请参考 [开发指南](docs/contributing/README_dev.md)

### Docker 部署

```shell
docker pull chatimage/chatchat:0.3.1.3-93e2c87-20240829

docker pull ccr.ccs.tencentyun.com/langchain-chatchat/chatchat:0.3.1.3-93e2c87-20240829 # 国内镜像
```

&gt; [!important]
&gt; 强烈建议: 使用 docker-compose 部署, 具体参考 [README_docker](docs/install/README_docker.md)

### 旧版本迁移

* 0.3.x 结构改变很大,强烈建议您按照文档重新部署. 以下指南不保证100%兼容和成功. 记得提前备份重要数据!

- 首先按照 `安装部署` 中的步骤配置运行环境，修改配置文件
- 将 0.2.x 项目的 knowledge_base 目录拷贝到配置的 `DATA` 目录下

---

## 项目里程碑

+ `2023年4月`: `Langchain-ChatGLM 0.1.0` 发布，支持基于 ChatGLM-6B 模型的本地知识库问答。
+ `2023年8月`: `Langchain-ChatGLM` 改名为 `Langchain-Chatchat`，发布 `0.2.0` 版本，使用 `fastchat` 作为模型加载方案，支持更多的模型和数据库。
+ `2023年10月`: `Langchain-Chatchat 0.2.5` 发布，推出 Agent 内容，开源项目在`Founder Park &amp; Zhipu AI &amp; Zilliz`
  举办的黑客马拉松获得三等奖。
+ `2023年12月`: `Langchain-Chatchat` 开源项目获得超过 **20K** stars.
+ `2024年6月`: `Langchain-Chatchat 0.3.0` 发布，带来全新项目架构。

+ 🔥 让我们一起期待未来 Chatchat 的故事 ···

---

## 协议

本项目代码遵循 [Apache-2.0](LICENSE) 协议。

## 联系我们

### Telegram

[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;logo=telegram&amp;logoColor=white &quot;langchain-chatchat&quot;)](https://t.me/+RjliQ3jnJ1YyN2E9)

### 项目交流群

&lt;img src=&quot;docs/img/qr_code_117_2.jpg&quot; alt=&quot;二维码&quot; width=&quot;300&quot; /&gt;

🎉 Langchain-Chatchat 项目微信交流群，如果你也对本项目感兴趣，欢迎加入群聊参与讨论交流。

### 公众号

&lt;img src=&quot;docs/img/official_wechat_mp_account.png&quot; alt=&quot;二维码&quot; width=&quot;300&quot; /&gt;

🎉 Langchain-Chatchat 项目官方公众号，欢迎扫码关注。

## 引用

如果本项目有帮助到您的研究，请引用我们：

```
@software{langchain_chatchat,
    title        = {{langchain-chatchat}},
    author       = {Liu, Qian and Song, Jinke, and Huang, Zhiguo, and Zhang, Yuxuan, and glide-the, and liunux4odoo},
    year         = 2024,
    journal      = {GitHub repository},
    publisher    = {GitHub},
    howpublished = {\url{https://github.com/chatchat-space/Langchain-Chatchat}}
}
```
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[dream-num/univer]]></title>
            <link>https://github.com/dream-num/univer</link>
            <guid>https://github.com/dream-num/univer</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[Build AI-native spreadsheets. Univer is a full-stack framework for creating and editing spreadsheets on both web and server. With Univer MCP, Univer Spreadsheets is driven directly through natural language.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dream-num/univer">dream-num/univer</a></h1>
            <p>Build AI-native spreadsheets. Univer is a full-stack framework for creating and editing spreadsheets on both web and server. With Univer MCP, Univer Spreadsheets is driven directly through natural language.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 11,273</p>
            <p>Forks: 977</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./docs/img/banner-light.png&quot;&gt;
    &lt;img src=&quot;./docs/img/banner-dark.png&quot; alt=&quot;Univer&quot; width=&quot;400&quot; /&gt;
&lt;/picture&gt;

An Isomorphic Full-Stack Framework for Creating and Editing Spreadsheets, Docs, and Slides Across Web and Server.&lt;br /&gt;
**Extensible. High-performance. Embedded to your application.**

**English** | [简体中文][readme-zh-link] | [日本語][readme-ja-link] | [Español][readme-es-link] &lt;br /&gt;
[Official Site][official-site-link] | [Documentation][documentation-link] | [Online Playground][playground-link] | [Blog][blog-link]

[![][github-license-shield]][github-license-link]
[![][github-actions-shield]][github-actions-link]
[![][github-stars-shield]][github-stars-link]
[![][github-contributors-shield]][github-contributors-link] &lt;br /&gt;
[![][github-forks-shield]][github-forks-link]
[![][github-issues-shield]][github-issues-link]
[![][codecov-shield]][codecov-link]
[![][codefactor-shield]][codefactor-link]
[![][discord-shield]][discord-link]

[![Trendshift][github-trending-shield]][github-trending-url]

&lt;/div&gt;

## Use [Univer MCP](https://github.com/dream-num/univer-mcp) to drive Univer Spreadsheets with natural language and build AI-native spreadsheets.

https://github.com/user-attachments/assets/7429bd5f-d769-4057-9e67-353337531024

&lt;details open&gt;
&lt;summary&gt;
&lt;strong&gt;Table of contents&lt;/strong&gt;
&lt;/summary&gt;

- [🌈 Highlights](#-highlights)
- [✨ Features](#-features)
    - [📊 Univer Sheet](#-univer-sheet)
    - [📝 Univer Doc](#-univer-doc-under-development)
    - [📽️ Univer Slide](#%EF%B8%8F-univer-slide-under-development)
- [🌐 Internationalization](#-internationalization)
- [👾 Showcase](#-showcase)&lt;!-- - [📦 Ecosystem](#-ecosystem) --&gt;
- [💬 Community](#-community)
- [🤝 Contribution](#-contribution)
- [❤️ Sponsor](#%EF%B8%8F-sponsors)
- [📄 License](#-license)

&lt;/details&gt;

## 🌈 Highlights

- 📈 Univer is designed to support **spreadsheets**, **documents** and **presentation**.
- 🧙‍♀️ Univer is **isomorphic**. It can run both on browsers and Node.js (in the future, mobile devices as well), with the same API.
- ⚙️ Univer is easily **embeddable**, allowing seamless integration into your applications.
- 🎇 Univer is **powerful**, offering a wide range of features including **formulas**, **conditional formatting**, **data validation**, **filtering**, **collaborative editing**, **printing**, **import &amp; export** and more features on the horizon.
- 🔌 Univer is **highly extensible**, thanks to its *plug-in architecture* that makes it a delight for developers to implement their unique requirements on the top of Univer.
- 💄 Univer is **highly customizable**, allowing you to personalize its appearance using *themes*. It also provides support for internationalization (i18n).
- 🥤 Univer is **easy to work with**. The *Presets* &amp; *Facade API* make it easy to hands on.
- ⚡ Univer in **performant**.
  - ✏️ Univer boasts an efficient *rendering engine* based on canvas, capable of rendering various document types flawlessly. The rendering engines supports advanced typesetting features such as *punctuation squeezing*, *text and image layout* and *scroll buffering*.
  - 🧮 Univer incorporates a lightning-fast *formula engine* that can operate in Web Workers or even on the server side.
- 🌌 Univer is a **highly integrated** system. Documents, spreadsheets and slides can interoperate with each others and even rendered on the same canvas, allowing information and data flow within Univer.

## ✨ Features

Univer provides a wide range of features for spreadsheets, documents and presentations. Here are some of the key features:

### 📊 Univer Sheets

- **Core Features**: Univer supports core spreadsheet functionality, including cells, rows, columns, worksheets, and workbooks.
- **Formulas**: Extensive support for various formulas, including mathematical, statistical, logical, text, date and time, lookup and reference, engineering, financial, and information formulas.
- **Permissions**: Allows restricting access to specific elements.
- **Number Formatting**: Supports formatting numbers based on specific criteria.
- **Hyperlinks**: Enables linking to external websites, email addresses, and other locations within a spreadsheet.
- **Floating Images**: Allows inserting images into a spreadsheet and positioning them anywhere on the sheet.
- **Find &amp; Replace**: Provides the ability to search for specific text within a spreadsheet and replace it with other text.
- **Filtering**: Allows filtering data based on specific criteria.
- **Sorting**: Allows sorting data based on specific criteria.
- **Data Validation**: Supports restricting the type of data that can be entered into a cell.
- **Conditional Formatting**: Supports applying formatting to cells based on specific criteria.
- **Comments**: Enables adding comments to cells to provide additional information.
- **Cross-highlighting**: Supports displaying cross-highlighting in spreadsheets to help users quickly locate selected cells.
- **Zen Editor**: Provides a distraction-free editing experience with a clean interface and minimal distractions.
- **Pivot Tables**[^1]: Supports pivot tables, allowing users to summarize and analyze data.
- **Sparklines**[^1]: Supports sparklines, which are small charts that fit within a cell to provide a visual representation of data.
- **Printing**[^1]: Allows printing a spreadsheet or exporting it to PDF.
- **Import &amp; Export**[^1]: Support for importing and exporting data in XLSX.
- **Charts**[^1]: Supports various types of charts, including bar charts, line charts, pie charts, scatter plots, and more.
- **Collaborative Editing**[^1]: Supports multiple users editing a spreadsheet simultaneously. File history and recovering are also provided.
- **Editing History**[^1]: Allows users to view and restore previous versions of a spreadsheet.

### 📝 Univer Docs (rc)

- **Core Features**: Univer supports core document features, including paragraphs, headings, lists, superscript, subscript, and more.
- **Lists**: Supports ordered lists, unordered lists, and task lists.
- **Hyperlinks**: Supports inserting links to external websites, email addresses, and other locations within a document.
- **Floating Images**: Allows inserting images into a document and supporting text and image layout.
- **Headers &amp; Footers**: Allows adding headers and footers to a document.
- **Comments**: Enables adding comments to a document to provide additional information.
- **Printing**[^1]: Allows printing a document or exporting it to PDF.
- **Import &amp; Export**[^1]: Supports importing and exporting data in DOCX format.
- **Collaborative Editing**[^1]: Supports multiple users editing a document simultaneously.

### 📽️ Univer Slides (Under Development)

- **Core Features**: Univer will support core presentation features, including slides, shapes, text, images, and more.

## 🌐 Internationalization

Univer supports multiple languages, including:

- `zh-CN`
- `zh-TW`
- `en-US`
- `ru-RU`
- `vi-VN`
- `fa-IR`
- `ko-KR`
- `es-ES`
- `ca-ES`

`zh-CN` and `en-US` are officially supported, while the others are contributed and maintained by the community.

You can add the language you want by [Using Custom Locales](https://docs.univer.ai/guides/sheets/getting-started/i18n#custom-language-packs). You can also help us add new language support by referring to the [contribution guide](./CONTRIBUTING.md).

## 👾 Showcase

Embed Univer in AI products as a data presentation tool.

[![][examples-preview-capalyze]][examples-link-capalyze]

You can find all the examples in the [Univer Examples](https://docs.univer.ai/showcase).

| **📊 Spreadsheets** | **📊 Multi-instance** | **📊 Uniscript** |
| :---: | :---: | :---: |
| [![][examples-preview-0]][examples-link-0] | [![][examples-preview-1]][examples-link-1] | [![][examples-preview-2]][examples-link-2] |
| **📊 Big data** | **📊 Collaboration** | **📊 Collaboration Playground** |
| [![][examples-preview-3]][examples-link-3] | [![][examples-preview-4]][examples-link-4] | [![][examples-preview-5]][examples-link-5] |
| **📊 Import &amp; Export** | **📊 Printing** | **📝 Documents** |
| [![][examples-preview-6]][examples-link-6] | [![][examples-preview-7]][examples-link-7] | [![][examples-preview-8]][examples-link-8] |
| **📝 Multi-instance** | **📝 Uniscript** | **📝 Big data** |
| [![][examples-preview-9]][examples-link-9] | [![][examples-preview-10]][examples-link-10] | [![][examples-preview-11]][examples-link-11] |
| **📝 Collaboration** | **📝 Collaboration Playground** | **📽️ Presentations** |
| [![][examples-preview-12]][examples-link-12] | [![][examples-preview-13]][examples-link-13] | [![][examples-preview-14]][examples-link-14] |
| **📊 Zen Editor** | **Univer Workspace (SaaS version)** | &amp;nbsp; |
| [![][examples-preview-15]][examples-link-15] | [![][examples-preview-16]][examples-link-16] | &amp;nbsp; |

&lt;!-- ## 📦 Ecosystem

Univer has a rich ecosystem that includes a wide range of tools and resources to help you get started with Univer: --&gt;

## 🔗 Links

- [Latest Preview of the `dev` Branch](https://univer-preview.vercel.app/)
- [Official Site](https://univer.ai)
- [Presets Repository](https://github.com/dream-num/univer-presets)

## 🔒 Security

Univer is committed to maintaining a secure codebase. We follow best practices for security and regularly update our dependencies. For more information, please refer to our [Security Policy](./SECURITY.md).

## 💬 Community

[![][github-community-badge]][github-community-link] [![][discord-community-badge]][discord-community-link] [![][stackoverflow-community-badge]][stackoverflow-community-link]

Univer is an inclusive and welcoming project. Please read our [Code of Conduct](./CODE_OF_CONDUCT.md) before participating in the community.

Join the Univer community:

- Chat with us and other developers on [Discord][discord-community-link].
- Start a discussion on [GitHub Discussions][github-community-link].
- Open a topic on [Stack Overflow][stackoverflow-community-link] and tag it with `univer`.

You can also find Univer on:

[Twitter][twitter-community-link] | [YouTube][youtube-community-link]

## 🤝 Contribution

We appreciate any kinds of contributing. You can submit [issues or feature requests](https://github.com/dream-num/univer/issues) to us. Please read our [contributing guide](./CONTRIBUTING.md) first.

If you would like to contribute code to Univer, please refer to the contributing guide as well. It would guide you through the process of setting up the development environment and submitting a pull request.

## ❤️ Sponsors

The growth and development of the Univer project rely on the support of its backers and sponsors. If you are interested in supporting our project, we kindly invite you to consider becoming a sponsor. You can sponsor us through [Open Collective](https://opencollective.com/univer).

Thanks to our sponsors, just part of them are listed here because of the space limit, ranking is no particular order:

[![][sponsor-badge-0]][sponsor-link-0]
[![][sponsor-badge-1]][sponsor-link-1]
[![][sponsor-badge-2]][sponsor-link-2]
[![][sponsor-badge-3]][sponsor-link-3]
[![][sponsor-badge-4]][sponsor-link-4]
[![][sponsor-badge-5]][sponsor-link-5]
[![][sponsor-badge-6]][sponsor-link-6]

[![][backer-badge-0]][backer-link-0]
[![][backer-badge-1]][backer-link-1]
[![][backer-badge-2]][backer-link-2]
[![][backer-badge-3]][backer-link-3]
[![][backer-badge-4]][backer-link-4]
[![][backer-badge-5]][backer-link-5]
[![][backer-badge-6]][backer-link-6]

## 📄 License

Copyright © 2021-2025 DreamNum Co,Ltd. All Rights Reserved.

Licensed under the [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) license.

&lt;!-- Footnotes --&gt;
[^1]: These features are provided by the non-OSS version of Univer, which is free for commercial use and also includes paid upgrade plans.

&lt;!-- Links --&gt;
[github-license-shield]: https://img.shields.io/github/license/dream-num/univer?style=flat-square
[github-license-link]: ./LICENSE
[github-actions-shield]: https://img.shields.io/github/actions/workflow/status/dream-num/univer/build.yml?style=flat-square
[github-actions-link]: https://github.com/dream-num/univer/actions/workflows/build.yml
[github-stars-link]: https://github.com/dream-num/univer/stargazers
[github-stars-shield]: https://img.shields.io/github/stars/dream-num/univer?style=flat-square
[github-trending-shield]: https://trendshift.io/api/badge/repositories/4376
[github-trending-url]: https://trendshift.io/repositories/4376
[github-contributors-link]: https://github.com/dream-num/univer/graphs/contributors
[github-contributors-shield]: https://img.shields.io/github/contributors/dream-num/univer?style=flat-square
[github-forks-link]: https://github.com/dream-num/univer/network/members
[github-forks-shield]: https://img.shields.io/github/forks/dream-num/univer?style=flat-square
[github-issues-link]: https://github.com/dream-num/univer/issues
[github-issues-shield]: https://img.shields.io/github/issues/dream-num/univer?style=flat-square
[codecov-shield]: https://img.shields.io/codecov/c/gh/dream-num/univer?token=aPfyW2pIMN&amp;style=flat-square
[codecov-link]: https://codecov.io/gh/dream-num/univer
[codefactor-shield]: https://www.codefactor.io/repository/github/dream-num/univer/badge/dev?style=flat-square
[codefactor-link]: https://www.codefactor.io/repository/github/dream-num/univer/overview/dev
[discord-shield]: https://img.shields.io/discord/1136129819961217077?logo=discord&amp;logoColor=FFFFFF&amp;label=discord&amp;color=5865F2&amp;style=flat-square
[discord-link]: https://discord.gg/z3NKNT6D2f

[readme-en-link]: ./README.md
[readme-zh-link]: ./README-zh.md
[readme-ja-link]: ./README-ja.md
[readme-es-link]: ./README-es.md

[official-site-link]: https://univer.ai
[documentation-link]: https://docs.univer.ai/en-US
[playground-link]: https://docs.univer.ai/en-US/showcase
[blog-link]: https://docs.univer.ai/en-US/blog

[stackoverflow-community-link]: https://stackoverflow.com/questions/tagged/univer
[stackoverflow-community-badge]: https://img.shields.io/badge/stackoverflow-univer-ef8236?labelColor=black&amp;logo=stackoverflow&amp;logoColor=white&amp;style=for-the-badge
[github-community-link]: https://github.com/dream-num/univer/discussions
[github-community-badge]: https://img.shields.io/badge/github-univer-24292e?labelColor=black&amp;logo=github&amp;logoColor=white&amp;style=for-the-badge
[discord-community-link]: https://discord.gg/z3NKNT6D2f
[discord-community-badge]: https://img.shields.io/discord/1136129819961217077?color=5865F2&amp;label=discord&amp;labelColor=black&amp;logo=discord&amp;logoColor=white&amp;style=for-the-badge
[twitter-community-link]: https://twitter.com/univerhq
[youtube-community-link]: https://www.youtube.com/@dreamNum
[zhihu-community-link]: https://www.zhihu.com/org/meng-shu-ke-ji
[segmentfault-community-link]: https://segmentfault.com/u/congrongdehongjinyu
[juejin-community-link]: https://juejin.cn/user/4312146127850733

[sponsor-link-0]: https://opencollective.com/univer/sponsor/0/website
[sponsor-link-1]: https://opencollective.com/univer/sponsor/1/website
[sponsor-link-2]: https://opencollective.com/univer/sponsor/2/website
[sponsor-link-3]: https://opencollective.com/univer/sponsor/3/website
[sponsor-link-4]: https://opencollective.com/univer/sponsor/4/website
[sponsor-link-5]: https://opencollective.com/univer/sponsor/5/website
[sponsor-link-6]: https://opencollective.com/univer/sponsor/6/website
[sponsor-badge-0]: https://opencollective.com/univer/sponsor/0/avatar.svg
[sponsor-badge-1]: https://opencollective.com/univer/sponsor/1/avatar.svg
[sponsor-badge-2]: https://opencollective.com/univer/sponsor/2/avatar.svg
[sponsor-badge-3]: https://opencollective.com/univer/sponsor/3/avatar.svg
[sponsor-badge-4]: https://opencollective.com/univer/sponsor/4/avatar.svg
[sponsor-badge-5]: https://opencollective.com/univer/sponsor/5/avatar.svg
[sponsor-badge-6]: https://opencollective.com/univer/sponsor/6/avatar.svg
[backer-link-0]: https://opencollective.com/univer/backer/0/website
[backer-link-1]: https://opencollective.com/univer/backer/1/website
[backer-link-2]: https://opencollective.com/univer/backer/2/website
[backer-link-3]: https://opencollective.com/univer/backer/3/website
[backer-link-4]: https://opencollective.com/univer/backer/4/website
[backer-link-5]: https://opencollective.com/univer/backer/5/website
[backer-link-6]: https://opencollective.com/univer/backer/6/website
[backer-badge-0]: https://opencollective.com/univer/backer/0/avatar.svg
[backer-badge-1]: https://opencollective.com/univer/backer/1/avatar.svg
[backer-badge-2]: https://opencollective.com/univer/backer/2/avatar.svg
[backer-badge-3]: https://opencollective.com/univer/backer/3/avatar.svg
[backer-badge-4]: https://opencollective.com/univer/backer/4/avatar.svg
[backer-badge-5]: https://opencollective.com/univer/backer/5/avatar.svg
[backer-badge-6]: https://opencollective.com/univer/backer/6/avatar.svg

[examples-preview-capalyze]: ./docs/img/examples-sheets-capalyze.gif
[examples-preview-0]: ./docs/img/examples-sheets.gif
[examples-preview-1]: ./docs/img/examples-sheets-multi.gif
[examples-preview-2]: ./docs/img/examples-sheets-uniscript.gif
[examples-preview-3]: ./docs/img/examples-sheets-big-data.gif
[examples-preview-4]: ./docs/img/pro-examples-sheets-collaboration.gif
[examples-preview-5]: ./docs/img/pro-examples-sheets-collaboration-playground.gif
[examples-preview-6]: ./docs/img/pro-examples-sheets-exchange.gif
[examples-preview-7]: ./docs/img/pro-examples-sheets-print.gif
[examples-preview-8]: ./docs/img/examples-docs.gif
[examples-preview-9]: ./docs/img/examples-docs-multi.gif
[examples-preview-10]: ./docs/img/examples-docs-uniscript.gif
[examples-preview-11]: ./docs/img/examples-docs-big-data.gif
[examples-preview-12]: ./docs/img/pro-examples-docs-collaboration.gif
[examples-preview-13]: ./docs/img/pro-examples-docs-collaboration-playground.gif
[examples-preview-14]: ./docs/img/examples-slides.gif
[examples-preview-15]: ./docs/img/zen-mode.gif
[examples-preview-16]: ./docs/img/univer-workspace-drag-chart.gif
[examples-link-capalyze]: https://capalyze.ai/
[examples-link-0]: https://docs.univer.ai/showcase
[examples-link-1]: https://docs.univer.ai/showcase
[examples-link-2]: https://docs.univer.ai/showcase
[examples-link-3]: https://docs.univer.ai/showcase
[examples-link-4]: https://docs.univer.ai/showcase
[examples-link-5]: https://docs.univer.ai/showcase
[examples-link-6]: https://docs.univer.ai/showcase
[examples-link-7]: https://docs.univer.ai/showcase
[examples-link-8]: https://docs.univer.ai/showcase
[examples-link-9]: https://docs.univer.ai/showcase
[examples-link-10]: https://docs.univer.ai/showcase
[examples-link-11]: https://docs.univer.ai/showcase
[examples-link-12]: https://docs.univer.ai/showcase
[examples-link-13]: https://docs.univer.ai/showcase
[examples-link-14]: https://docs.univer.ai/showcase
[examples-link-15]: https://univer.ai/guides/sheet/features/zen-editor
[examples-link-16]: https://youtu.be/kpV0MvQuFZA
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[infiniflow/ragflow]]></title>
            <link>https://github.com/infiniflow/ragflow</link>
            <guid>https://github.com/infiniflow/ragflow</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:19 GMT</pubDate>
            <description><![CDATA[RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/infiniflow/ragflow">infiniflow/ragflow</a></h1>
            <p>RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs</p>
            <p>Language: TypeScript</p>
            <p>Stars: 65,713</p>
            <p>Forks: 6,912</p>
            <p>Stars today: 61 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://demo.ragflow.io/&quot;&gt;
&lt;img src=&quot;web/src/assets/logo-with-text.png&quot; width=&quot;520&quot; alt=&quot;ragflow logo&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-DBEDFA&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_zh.md&quot;&gt;&lt;img alt=&quot;简体中文版自述文件&quot; src=&quot;https://img.shields.io/badge/简体中文-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_tzh.md&quot;&gt;&lt;img alt=&quot;繁體版中文自述文件&quot; src=&quot;https://img.shields.io/badge/繁體中文-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_ja.md&quot;&gt;&lt;img alt=&quot;日本語のREADME&quot; src=&quot;https://img.shields.io/badge/日本語-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_ko.md&quot;&gt;&lt;img alt=&quot;한국어&quot; src=&quot;https://img.shields.io/badge/한국어-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_id.md&quot;&gt;&lt;img alt=&quot;Bahasa Indonesia&quot; src=&quot;https://img.shields.io/badge/Bahasa Indonesia-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_pt_br.md&quot;&gt;&lt;img alt=&quot;Português(Brasil)&quot; src=&quot;https://img.shields.io/badge/Português(Brasil)-DFE0E5&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://x.com/intent/follow?screen_name=infiniflowai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/infiniflow?logo=X&amp;color=%20%23f5f5f5&quot; alt=&quot;follow on X(Twitter)&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://demo.ragflow.io&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Online-Demo-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/r/infiniflow/ragflow&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/docker/pulls/infiniflow/ragflow?label=Docker%20Pulls&amp;color=0db7ed&amp;logo=docker&amp;logoColor=white&amp;style=flat-square&quot; alt=&quot;docker pull infiniflow/ragflow:v0.20.5&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/releases/latest&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/github/v/release/infiniflow/ragflow?color=blue&amp;label=Latest%20Release&quot; alt=&quot;Latest Release&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/blob/main/LICENSE&quot;&gt;
        &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/License-Apache--2.0-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;license&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://deepwiki.com/infiniflow/ragflow&quot;&gt;
        &lt;img alt=&quot;Ask DeepWiki&quot; src=&quot;https://deepwiki.com/badge.svg&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://ragflow.io/docs/dev/&quot;&gt;Document&lt;/a&gt; |
  &lt;a href=&quot;https://github.com/infiniflow/ragflow/issues/4214&quot;&gt;Roadmap&lt;/a&gt; |
  &lt;a href=&quot;https://twitter.com/infiniflowai&quot;&gt;Twitter&lt;/a&gt; |
  &lt;a href=&quot;https://discord.gg/NjYzJD3GM3&quot;&gt;Discord&lt;/a&gt; |
  &lt;a href=&quot;https://demo.ragflow.io&quot;&gt;Demo&lt;/a&gt;
&lt;/h4&gt;

#

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/9064&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/9064&quot; alt=&quot;infiniflow%2Fragflow | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;📕 Table of Contents&lt;/b&gt;&lt;/summary&gt;

- 💡 [What is RAGFlow?](#-what-is-ragflow)
- 🎮 [Demo](#-demo)
- 📌 [Latest Updates](#-latest-updates)
- 🌟 [Key Features](#-key-features)
- 🔎 [System Architecture](#-system-architecture)
- 🎬 [Get Started](#-get-started)
- 🔧 [Configurations](#-configurations)
- 🔧 [Build a docker image without embedding models](#-build-a-docker-image-without-embedding-models)
- 🔧 [Build a docker image including embedding models](#-build-a-docker-image-including-embedding-models)
- 🔨 [Launch service from source for development](#-launch-service-from-source-for-development)
- 📚 [Documentation](#-documentation)
- 📜 [Roadmap](#-roadmap)
- 🏄 [Community](#-community)
- 🙌 [Contributing](#-contributing)

&lt;/details&gt;

## 💡 What is RAGFlow?

[RAGFlow](https://ragflow.io/) is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs. It offers a streamlined RAG workflow adaptable to enterprises of any scale. Powered by a converged context engine and pre-built agent templates, RAGFlow enables developers to transform complex data into high-fidelity, production-ready AI systems with exceptional efficiency and precision.

## 🎮 Demo

Try our demo at [https://demo.ragflow.io](https://demo.ragflow.io).

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/chunking.gif&quot; width=&quot;1200&quot;/&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/agentic-dark.gif&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## 🔥 Latest Updates

- 2025-08-08 Supports OpenAI&#039;s latest GPT-5 series models.
- 2025-08-04 Supports new models, including Kimi K2 and Grok 4.
- 2025-08-01 Supports agentic workflow and MCP.
- 2025-05-23 Adds a Python/JavaScript code executor component to Agent.
- 2025-05-05 Supports cross-language query.
- 2025-03-19 Supports using a multi-modal model to make sense of images within PDF or DOCX files.
- 2025-02-28 Combined with Internet search (Tavily), supports reasoning like Deep Research for any LLMs.
- 2024-12-18 Upgrades Document Layout Analysis model in DeepDoc.
- 2024-08-22 Support text to SQL statements through RAG.

## 🎉 Stay Tuned

⭐️ Star our repository to stay up-to-date with exciting new features and improvements! Get instant notifications for new
releases! 🌟

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/18c9707e-b8aa-4caf-a154-037089c105ba&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## 🌟 Key Features

### 🍭 **&quot;Quality in, quality out&quot;**

- [Deep document understanding](./deepdoc/README.md)-based knowledge extraction from unstructured data with complicated
  formats.
- Finds &quot;needle in a data haystack&quot; of literally unlimited tokens.

### 🍱 **Template-based chunking**

- Intelligent and explainable.
- Plenty of template options to choose from.

### 🌱 **Grounded citations with reduced hallucinations**

- Visualization of text chunking to allow human intervention.
- Quick view of the key references and traceable citations to support grounded answers.

### 🍔 **Compatibility with heterogeneous data sources**

- Supports Word, slides, excel, txt, images, scanned copies, structured data, web pages, and more.

### 🛀 **Automated and effortless RAG workflow**

- Streamlined RAG orchestration catered to both personal and large businesses.
- Configurable LLMs as well as embedding models.
- Multiple recall paired with fused re-ranking.
- Intuitive APIs for seamless integration with business.

## 🔎 System Architecture

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/infiniflow/ragflow/assets/12318111/d6ac5664-c237-4200-a7c2-a4a00691b485&quot; width=&quot;1000&quot;/&gt;
&lt;/div&gt;

## 🎬 Get Started

### 📝 Prerequisites

- CPU &gt;= 4 cores
- RAM &gt;= 16 GB
- Disk &gt;= 50 GB
- Docker &gt;= 24.0.0 &amp; Docker Compose &gt;= v2.26.1
- [gVisor](https://gvisor.dev/docs/user_guide/install/): Required only if you intend to use the code executor (sandbox) feature of RAGFlow.

&gt; [!TIP]
&gt; If you have not installed Docker on your local machine (Windows, Mac, or Linux), see [Install Docker Engine](https://docs.docker.com/engine/install/).

### 🚀 Start up the server

1. Ensure `vm.max_map_count` &gt;= 262144:

   &gt; To check the value of `vm.max_map_count`:
   &gt;
   &gt; ```bash
   &gt; $ sysctl vm.max_map_count
   &gt; ```
   &gt;
   &gt; Reset `vm.max_map_count` to a value at least 262144 if it is not.
   &gt;
   &gt; ```bash
   &gt; # In this case, we set it to 262144:
   &gt; $ sudo sysctl -w vm.max_map_count=262144
   &gt; ```
   &gt;
   &gt; This change will be reset after a system reboot. To ensure your change remains permanent, add or update the
   &gt; `vm.max_map_count` value in **/etc/sysctl.conf** accordingly:
   &gt;
   &gt; ```bash
   &gt; vm.max_map_count=262144
   &gt; ```

2. Clone the repo:

   ```bash
   $ git clone https://github.com/infiniflow/ragflow.git
   ```

3. Start up the server using the pre-built Docker images:

&gt; [!CAUTION]
&gt; All Docker images are built for x86 platforms. We don&#039;t currently offer Docker images for ARM64.
&gt; If you are on an ARM64 platform, follow [this guide](https://ragflow.io/docs/dev/build_docker_image) to build a Docker image compatible with your system.

   &gt; The command below downloads the `v0.20.5-slim` edition of the RAGFlow Docker image. See the following table for descriptions of different RAGFlow editions. To download a RAGFlow edition different from `v0.20.5-slim`, update the `RAGFLOW_IMAGE` variable accordingly in **docker/.env** before using `docker compose` to start the server. For example: set `RAGFLOW_IMAGE=infiniflow/ragflow:v0.20.5` for the full edition `v0.20.5`.

   ```bash
   $ cd ragflow/docker
   # Use CPU for embedding and DeepDoc tasks:
   $ docker compose -f docker-compose.yml up -d

   # To use GPU to accelerate embedding and DeepDoc tasks:
   # docker compose -f docker-compose-gpu.yml up -d
   ```

   | RAGFlow image tag | Image size (GB) | Has embedding models? | Stable?                  |
   |-------------------|-----------------|-----------------------|--------------------------|
   | v0.20.5           | &amp;approx;9       | :heavy_check_mark:    | Stable release           |
   | v0.20.5-slim      | &amp;approx;2       | ❌                   | Stable release            |
   | nightly           | &amp;approx;9       | :heavy_check_mark:    | _Unstable_ nightly build |
   | nightly-slim      | &amp;approx;2       | ❌                   | _Unstable_ nightly build  |

4. Check the server status after having the server up and running:

   ```bash
   $ docker logs -f ragflow-server
   ```

   _The following output confirms a successful launch of the system:_

   ```bash

         ____   ___    ______ ______ __
        / __ \ /   |  / ____// ____// /____  _      __
       / /_/ // /| | / / __ / /_   / // __ \| | /| / /
      / _, _// ___ |/ /_/ // __/  / // /_/ /| |/ |/ /
     /_/ |_|/_/  |_|\____//_/    /_/ \____/ |__/|__/

    * Running on all addresses (0.0.0.0)
   ```

   &gt; If you skip this confirmation step and directly log in to RAGFlow, your browser may prompt a `network anormal`
   &gt; error because, at that moment, your RAGFlow may not be fully initialized.

5. In your web browser, enter the IP address of your server and log in to RAGFlow.
   &gt; With the default settings, you only need to enter `http://IP_OF_YOUR_MACHINE` (**sans** port number) as the default
   &gt; HTTP serving port `80` can be omitted when using the default configurations.
6. In [service_conf.yaml.template](./docker/service_conf.yaml.template), select the desired LLM factory in `user_default_llm` and update
   the `API_KEY` field with the corresponding API key.

   &gt; See [llm_api_key_setup](https://ragflow.io/docs/dev/llm_api_key_setup) for more information.

   _The show is on!_

## 🔧 Configurations

When it comes to system configurations, you will need to manage the following files:

- [.env](./docker/.env): Keeps the fundamental setups for the system, such as `SVR_HTTP_PORT`, `MYSQL_PASSWORD`, and
  `MINIO_PASSWORD`.
- [service_conf.yaml.template](./docker/service_conf.yaml.template): Configures the back-end services. The environment variables in this file will be automatically populated when the Docker container starts. Any environment variables set within the Docker container will be available for use, allowing you to customize service behavior based on the deployment environment.
- [docker-compose.yml](./docker/docker-compose.yml): The system relies on [docker-compose.yml](./docker/docker-compose.yml) to start up.

&gt; The [./docker/README](./docker/README.md) file provides a detailed description of the environment settings and service
&gt; configurations which can be used as `${ENV_VARS}` in the [service_conf.yaml.template](./docker/service_conf.yaml.template) file.

To update the default HTTP serving port (80), go to [docker-compose.yml](./docker/docker-compose.yml) and change `80:80`
to `&lt;YOUR_SERVING_PORT&gt;:80`.

Updates to the above configurations require a reboot of all containers to take effect:

&gt; ```bash
&gt; $ docker compose -f docker-compose.yml up -d
&gt; ```

### Switch doc engine from Elasticsearch to Infinity

RAGFlow uses Elasticsearch by default for storing full text and vectors. To switch to [Infinity](https://github.com/infiniflow/infinity/), follow these steps:

1. Stop all running containers:

   ```bash
   $ docker compose -f docker/docker-compose.yml down -v
   ```

&gt; [!WARNING]
&gt; `-v` will delete the docker container volumes, and the existing data will be cleared.

2. Set `DOC_ENGINE` in **docker/.env** to `infinity`.

3. Start the containers:

   ```bash
   $ docker compose -f docker-compose.yml up -d
   ```

&gt; [!WARNING]
&gt; Switching to Infinity on a Linux/arm64 machine is not yet officially supported.

## 🔧 Build a Docker image without embedding models

This image is approximately 2 GB in size and relies on external LLM and embedding services.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 --build-arg LIGHTEN=1 -f Dockerfile -t infiniflow/ragflow:nightly-slim .
```

## 🔧 Build a Docker image including embedding models

This image is approximately 9 GB in size. As it includes embedding models, it relies on external LLM services only.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 -f Dockerfile -t infiniflow/ragflow:nightly .
```

## 🔨 Launch service from source for development

1. Install `uv` and `pre-commit`, or skip this step if they are already installed:

   ```bash
   pipx install uv pre-commit
   ```

2. Clone the source code and install Python dependencies:

   ```bash
   git clone https://github.com/infiniflow/ragflow.git
   cd ragflow/
   uv sync --python 3.10 --all-extras # install RAGFlow dependent python modules
   uv run download_deps.py
   pre-commit install
   ```

3. Launch the dependent services (MinIO, Elasticsearch, Redis, and MySQL) using Docker Compose:

   ```bash
   docker compose -f docker/docker-compose-base.yml up -d
   ```

   Add the following line to `/etc/hosts` to resolve all hosts specified in **docker/.env** to `127.0.0.1`:

   ```
   127.0.0.1       es01 infinity mysql minio redis sandbox-executor-manager
   ```

4. If you cannot access HuggingFace, set the `HF_ENDPOINT` environment variable to use a mirror site:

   ```bash
   export HF_ENDPOINT=https://hf-mirror.com
   ```

5. If your operating system does not have jemalloc, please install it as follows:

   ```bash
   # Ubuntu
   sudo apt-get install libjemalloc-dev
   # CentOS
   sudo yum install jemalloc
   # OpenSUSE
   sudo zypper install jemalloc
   # macOS
   sudo brew install jemalloc
   ```

6. Launch backend service:

   ```bash
   source .venv/bin/activate
   export PYTHONPATH=$(pwd)
   bash docker/launch_backend_service.sh
   ```

7. Install frontend dependencies:

   ```bash
   cd web
   npm install
   ```

8. Launch frontend service:

   ```bash
   npm run dev
   ```

   _The following output confirms a successful launch of the system:_

   ![](https://github.com/user-attachments/assets/0daf462c-a24d-4496-a66f-92533534e187)

9. Stop RAGFlow front-end and back-end service after development is complete:

   ```bash
   pkill -f &quot;ragflow_server.py|task_executor.py&quot;
   ```


## 📚 Documentation

- [Quickstart](https://ragflow.io/docs/dev/)
- [Configuration](https://ragflow.io/docs/dev/configurations)
- [Release notes](https://ragflow.io/docs/dev/release_notes)
- [User guides](https://ragflow.io/docs/dev/category/guides)
- [Developer guides](https://ragflow.io/docs/dev/category/developers)
- [References](https://ragflow.io/docs/dev/category/references)
- [FAQs](https://ragflow.io/docs/dev/faq)

## 📜 Roadmap

See the [RAGFlow Roadmap 2025](https://github.com/infiniflow/ragflow/issues/4214)

## 🏄 Community

- [Discord](https://discord.gg/NjYzJD3GM3)
- [Twitter](https://twitter.com/infiniflowai)
- [GitHub Discussions](https://github.com/orgs/infiniflow/discussions)

## 🙌 Contributing

RAGFlow flourishes via open-source collaboration. In this spirit, we embrace diverse contributions from the community.
If you would like to be a part, review our [Contribution Guidelines](https://ragflow.io/docs/dev/contributing) first.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[Budibase/budibase]]></title>
            <link>https://github.com/Budibase/budibase</link>
            <guid>https://github.com/Budibase/budibase</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:18 GMT</pubDate>
            <description><![CDATA[Create business apps and automate workflows in minutes. Supports PostgreSQL, MySQL, MariaDB, MSSQL, MongoDB, Rest API, Docker, K8s, and more 🚀 No code / Low code platform..]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Budibase/budibase">Budibase/budibase</a></h1>
            <p>Create business apps and automate workflows in minutes. Supports PostgreSQL, MySQL, MariaDB, MSSQL, MongoDB, Rest API, Docker, K8s, and more 🚀 No code / Low code platform..</p>
            <p>Language: TypeScript</p>
            <p>Stars: 27,083</p>
            <p>Forks: 2,007</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.budibase.com&quot;&gt;
    &lt;img alt=&quot;Budibase&quot; src=&quot;https://res.cloudinary.com/daog6scxm/image/upload/v1696515725/Branding/Assets/Symbol/RGB/Full%20Colour/Budibase_Symbol_RGB_FullColour_cbqvha_1_z5cwq2.svg&quot; width=&quot;60&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;h1 align=&quot;center&quot;&gt;
  Budibase
&lt;/h1&gt;

&lt;h3 align=&quot;center&quot;&gt;
  The low code platform you&#039;ll enjoy using
&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;
  Budibase is an open-source low-code platform that saves engineers 100s of hours building forms, portals, and approval apps, securely.
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
 🤖 🎨 🚀
&lt;/h3&gt;
&lt;br&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Budibase design ui&quot; src=&quot;https://res.cloudinary.com/daog6scxm/image/upload/v1680181644/ui/homepage-design-ui_sizp7b.png&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/Budibase/budibase/releases&quot;&gt;
    &lt;img alt=&quot;GitHub all releases&quot; src=&quot;https://img.shields.io/github/downloads/Budibase/budibase/total&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/Budibase/budibase/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest by date)&quot; src=&quot;https://img.shields.io/github/v/release/Budibase/budibase&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=budibase&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/twitter/follow/budibase?style=social&quot; alt=&quot;Follow @budibase&quot; /&gt;
  &lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg&quot; alt=&quot;Code of conduct&quot; /&gt;
  &lt;a href=&quot;https://codecov.io/gh/Budibase/budibase&quot;&gt;
    &lt;img src=&quot;https://codecov.io/gh/Budibase/budibase/graph/badge.svg?token=E8W2ZFXQOH&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://account.budibase.app/register&quot;&gt;Get started - we host (Budibase Cloud)&lt;/a&gt;
  &lt;span&gt; · &lt;/span&gt;
  &lt;a href=&quot;https://docs.budibase.com/docs/hosting-methods&quot;&gt;Get started - you host (Docker, K8s, DO)&lt;/a&gt;
  &lt;span&gt; · &lt;/span&gt;
  &lt;a href=&quot;https://docs.budibase.com/docs&quot;&gt;Docs&lt;/a&gt;
  &lt;span&gt; · &lt;/span&gt;
  &lt;a href=&quot;https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas&quot;&gt;Feature request&lt;/a&gt;
  &lt;span&gt; · &lt;/span&gt;
  &lt;a href=&quot;https://github.com/Budibase/budibase/issues&quot;&gt;Report a bug&lt;/a&gt;
  &lt;span&gt; · &lt;/span&gt;
  Support: &lt;a href=&quot;https://github.com/Budibase/budibase/discussions&quot;&gt;Discussions&lt;/a&gt;
&lt;/h3&gt;

&lt;br /&gt;&lt;br /&gt;

## ✨ Features

### Build and ship real software

Unlike other platforms, with Budibase you build and ship single page applications. Budibase applications have performance baked in and can be designed responsively, providing users with a great experience.
&lt;br /&gt;&lt;br /&gt;

### Open source and extensible

Budibase is open-source - licensed as GPL v3. This should fill you with confidence that Budibase will always be around. You can also code against Budibase or fork it and make changes as you please, providing a developer-friendly experience.
&lt;br /&gt;&lt;br /&gt;

### Load data or start from scratch

Budibase pulls data from multiple sources, including MongoDB, CouchDB, PostgreSQL, MariaDB, MySQL, Airtable, S3, DynamoDB, or a REST API. And unlike other platforms, with Budibase you can start from scratch and create business apps with no data sources. [Request new datasources](https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas).

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Budibase data&quot; src=&quot;https://res.cloudinary.com/daog6scxm/image/upload/v1680281798/ui/data_klbuna.png&quot;&gt;
&lt;/p&gt;
&lt;br /&gt;&lt;br /&gt;

### Design and build apps with powerful pre-made components

Budibase comes out of the box with beautifully designed, powerful components which you can use like building blocks to build your UI. We also expose many of your favourite CSS styling options so you can go that extra creative mile. [Request new component](https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas).

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Budibase design&quot; src=&quot;https://res.cloudinary.com/daog6scxm/image/upload/v1675437167/ui/form_2x_mbli8y.png&quot;&gt;
&lt;/p&gt;
&lt;br /&gt;&lt;br /&gt;

### Automate processes, integrate with other tools and connect to webhooks

Save time by automating manual processes and workflows. From connecting to webhooks to automating emails, simply tell Budibase what to do and let it work for you. You can easily [create new automations for Budibase here](https://github.com/Budibase/automations) or [Request new automation](https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas).
&lt;br /&gt;&lt;br /&gt;

### Integrate with your favorite tools

Budibase integrates with a number of popular tools allowing you to build apps that perfectly fit your stack.

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Budibase integrations&quot; src=&quot;https://res.cloudinary.com/daog6scxm/image/upload/v1680195228/ui/automate_fg9z07.png&quot;&gt;
&lt;/p&gt;
&lt;br /&gt;&lt;br /&gt;

### Deploy with confidence and security

Budibase is made to scale. With Budibase, you can self-host on your own infrastructure and globally manage users, onboarding, SMTP, apps, groups, theming and more. You can also provide users/groups with an app portal and disseminate user management to the group manager.

- Checkout the promo video: https://youtu.be/xoljVpty_Kw

&lt;br /&gt;

---

&lt;br /&gt;

## Budibase Public API

As with anything that we build in Budibase, our new public API is simple to use, flexible, and introduces new extensibility. To summarize, the Budibase API enables:

- Budibase as a backend
- Interoperability

#### Docs

You can learn more about the Budibase API at the following places:

- [General documentation](https://docs.budibase.com/docs/public-api): Learn how to get your API key, how to use spec, and how to use Postman
- [Interactive API documentation](https://docs.budibase.com/reference/appcreate) : Learn how to interact with the API

&lt;br /&gt;&lt;br /&gt;

## 🏁 Get started

Deploy Budibase using Docker, Kubernetes, and Digital Ocean on your existing infrastructure. Or use Budibase Cloud if you don&#039;t need to self-host and would like to get started quickly.

### [Get started with self-hosting Budibase](https://docs.budibase.com/docs/hosting-methods)

- [Docker - single ARM compatible image](https://docs.budibase.com/docs/docker)
- [Docker Compose](https://docs.budibase.com/docs/docker-compose)
- [Kubernetes](https://docs.budibase.com/docs/kubernetes-k8s)
- [Digital Ocean](https://docs.budibase.com/docs/digitalocean)
- [Portainer](https://docs.budibase.com/docs/portainer)

### [Get started with Budibase Cloud](https://budibase.com)

&lt;br /&gt;&lt;br /&gt;

## 🎓 Learning Budibase

The Budibase documentation [lives here](https://docs.budibase.com/docs).
&lt;br /&gt;

&lt;br /&gt;&lt;br /&gt;

## 💬 Community

If you have a question or would like to talk with other Budibase users and join our community, please hop over to [Github discussions](https://github.com/Budibase/budibase/discussions)

&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;

## ❗ Code of conduct

Budibase is dedicated to providing everyone a welcoming, diverse, and harassment-free experience. We expect everyone in the Budibase community to abide by our [**Code of Conduct**](https://github.com/Budibase/budibase/blob/HEAD/docs/CODE_OF_CONDUCT.md). Please read it.
&lt;br /&gt;

&lt;br /&gt;&lt;br /&gt;

## 🙌 Contributing to Budibase

From opening a bug report to creating a pull request: every contribution is appreciated and welcomed. If you&#039;re planning to implement a new feature or change the API, please create an issue first. This way, we can ensure your work is not in vain.
Environment setup instructions are available [here](https://github.com/Budibase/budibase/tree/HEAD/docs/CONTRIBUTING.md).

### Not Sure Where to Start?

A good place to start contributing is by looking for the [good first issue](https://github.com/Budibase/budibase/labels/good%20first%20issue) tag.

### How the repository is organized

Budibase is a monorepo managed by lerna. Lerna manages the building and publishing of the budibase packages. At a high level, here are the packages that make up Budibase.

- [packages/builder](https://github.com/Budibase/budibase/tree/HEAD/packages/builder) - contains code for the budibase builder client-side svelte application.

- [packages/client](https://github.com/Budibase/budibase/tree/HEAD/packages/client) - A module that runs in the browser responsible for reading JSON definition and creating living, breathing web apps from it.

- [packages/server](https://github.com/Budibase/budibase/tree/HEAD/packages/server) - The budibase server. This Koa app is responsible for serving the JS for the builder and budibase apps, as well as providing the API for interaction with the database and file system.

For more information, see [CONTRIBUTING.md](https://github.com/Budibase/budibase/blob/HEAD/docs/CONTRIBUTING.md)

&lt;br /&gt;&lt;br /&gt;

## 📝 License

Budibase is open-source, licensed as [GPL v3](https://www.gnu.org/licenses/gpl-3.0.en.html). The client and component libraries are licensed as [MPL](https://directory.fsf.org/wiki/License:MPL-2.0) - so the apps you build can be licensed however you like.

&lt;br /&gt;&lt;br /&gt;

## ⭐ Stargazers over time

[![Stargazers over time](https://starchart.cc/Budibase/budibase.svg)](https://starchart.cc/Budibase/budibase)

If you are having issues between updates of the builder, please use the guide [here](https://github.com/Budibase/budibase/blob/HEAD/docs/CONTRIBUTING.md#troubleshooting) to clear down your environment.

&lt;br /&gt;&lt;br /&gt;

## Contributors ✨

Thanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):

&lt;a href=&quot;https://github.com/Budibase/budibase/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=Budibase/budibase&quot; /&gt;
&lt;/a&gt;

Made with [contrib.rocks](https://contrib.rocks).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[waifu-project/movie]]></title>
            <link>https://github.com/waifu-project/movie</link>
            <guid>https://github.com/waifu-project/movie</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:17 GMT</pubDate>
            <description><![CDATA[小猫影视是一款全平台的影视播放器, 支持 VOD/JS 扩展源]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/waifu-project/movie">waifu-project/movie</a></h1>
            <p>小猫影视是一款全平台的影视播放器, 支持 VOD/JS 扩展源</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,254</p>
            <p>Forks: 148</p>
            <p>Stars today: 139 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;logo.png&quot; width=&quot;108&quot; /&gt;

## 小猫影视

&gt; [!WARNING]
&gt; **小猫影视在 [2.5.9](https://github.com/waifu-project/movie/releases/tag/release-v2.5.9) 之后已转向闭源**
&gt;
&gt; 反馈和建议同样可以在 [issue](https://github.com/waifu-project/movie/issues) 中提出
&gt; 或者也可以在 [Telegram](https://t.me/catmovie1145) 群组里反馈

全平台支持, 支持 `Android` | `Windows` | `Macos` | `iOS` | `Linux`

![](https://img.shields.io/badge/macOS-000000?style=flat&amp;logo=apple&amp;logoColor=white)
![](https://img.shields.io/badge/iOS-000000?style=flat&amp;logoColor=white)
![](https://img.shields.io/badge/Linux-FCC624?style=flat&amp;logo=linux&amp;logoColor=black)
![](https://img.shields.io/badge/Windows-0078D6?style=flat&amp;logo=windows&amp;logoColor=white)
![](https://img.shields.io/badge/Android-3DDC84?style=flat&amp;logo=android&amp;logoColor=white)

&lt;details&gt;
&lt;summary&gt;查看截图 🖼️&lt;/summary&gt;

![首页](https://s2.loli.net/2025/09/14/QJmYod9K7G6cRkE.png)
![搜索](https://s2.loli.net/2025/09/14/8eEsAtpcM3dIX5C.png)
![TV](https://s2.loli.net/2025/09/14/trgyicKe47mf5I2.png)
![播放.jpg](https://s2.loli.net/2025/09/14/oO6iKgFPEth9M43.png)

&lt;/details&gt;

## 下载 📦


| 系统     | 文件后缀 | 架构          | 下载链接 |
|---------|------|-------------|------|
| macOS   | .zip | 通用(universal)   |  [全球加速](https://gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie-mac.zip) \| [香港加速](https://hk.gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie-mac.zip) \| [加速3](https://ghfast.top/https://github.com/waifu-project/movie/releases/latest/download/catmovie-mac.zip) \| [原始](https://github.com/waifu-project/movie/releases/latest/download/catmovie-mac.zip)  |
| iOS     | .ipa | -           |  [全球加速](https://gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie.ipa) \| [香港加速](https://hk.gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie.ipa) \| [加速3](https://ghfast.top/https://github.com/waifu-project/movie/releases/latest/download/catmovie.ipa) \| [原始](https://github.com/waifu-project/movie/releases/latest/download/catmovie.ipa)    |   |   |
| Android | .apk | 常用(arm64-v8a)   |  [全球加速](https://gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie.apk) \| [香港加速](https://hk.gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie.apk) \| [加速3](https://ghfast.top/https://github.com/waifu-project/movie/releases/latest/download/catmovie.apk) \| [原始](https://github.com/waifu-project/movie/releases/latest/download/catmovie.apk)    |   |
| Android | .apk | 旧手机(armeabi-v7a) |  [全球加速](https://gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie-legacy.apk) \| [香港加速](https://hk.gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie-legacy.apk) \| [加速3](https://ghfast.top/https://github.com/waifu-project/movie/releases/latest/download/catmovie-legacy.apk) \| [原始](https://github.com/waifu-project/movie/releases/latest/download/catmovie-legacy.apk)   |
| Android | .apk | 通用(universal)   |  [全球加速](https://gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie-universal.apk) \| [香港加速](https://hk.gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie-universal.apk) \| [加速3](https://ghfast.top/https://github.com/waifu-project/movie/releases/latest/download/catmovie-universal.apk) \| [原始](https://github.com/waifu-project/movie/releases/latest/download/catmovie-universal.apk)    |
| Windows | .zip | -            |  [全球加速](https://gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie-windows.zip) \| [香港加速](https://hk.gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie-windows.zip) \| [加速3](https://ghfast.top/https://github.com/waifu-project/movie/releases/latest/download/catmovie-windows.zip) \| [原始](https://github.com/waifu-project/movie/releases/latest/download/catmovie-windows.zip)    |   |
| Linux   | .zip | -            | [全球加速](https://gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie-linux-x86_64.tar.gz) \| [香港加速](https://hk.gh-proxy.com/https://github.com/waifu-project/movie/releases/latest/download/catmovie-linux-x86_64.tar.gz) \| [加速3](https://ghfast.top/https://github.com/waifu-project/movie/releases/latest/download/catmovie-linux-x86_64.tar.gz) \| [原始](https://github.com/waifu-project/movie/releases/latest/download/catmovie-linux-x86_64.tar.gz)     |


&lt;!-- &gt; 更新的话可直接使用 `brew reinstall -f yoyo`

```bash
brew tap waifu-project/brew
brew install yoyo
``` --&gt;

&lt;!-- 在 `Archlinux` 需要安装两个包

```sh
yay -S webkit2gtk-4.1
yay -S xdg-user-dir xdg-utils
``` --&gt;

&lt;!-- 在 `Win10` 下, 如果使用 `Webview` 播放器内核, 需要额外安装 [WebView2 Runtime](https://developer.microsoft.com/en-us/microsoft-edge/webview2)

&gt; https://docs.microsoft.com/en-us/microsoft-edge/webview2/concepts/distribution --&gt;

&lt;!-- 自签的话建议使用:

- [Sideloadly](https://sideloadly.io)
- [TrollStore](https://github.com/opa334/TrollStore)
- [NB助手](https://nbtool8.com)

&gt; [!NOTE]
&gt; apple-magnifier://install?url=https://github.com/waifu-project/movie/releases/latest/download/catmovie.ipa --&gt;

### 文档 📜

- [制作源](./docs/create_source.md)
- [键盘快捷键](./docs/keyboard.md) 
&lt;!-- - [解析VIP视频](./docs/parse_vip.md) --&gt;
&lt;!-- - [URL Scheme](./docs/protocol.md) --&gt;

### 赞助 🌠

开发不易, 感谢您的支持, 这将让小猫可以继续走下去 🤗

&lt;img src=&quot;https://s2.loli.net/2025/09/24/ByRvOsQhWzKLXNo.jpg&quot; width=&quot;300&quot; /&gt;</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[better-auth/better-auth]]></title>
            <link>https://github.com/better-auth/better-auth</link>
            <guid>https://github.com/better-auth/better-auth</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:16 GMT</pubDate>
            <description><![CDATA[The most comprehensive authentication framework for TypeScript]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/better-auth/better-auth">better-auth/better-auth</a></h1>
            <p>The most comprehensive authentication framework for TypeScript</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,700</p>
            <p>Forks: 1,700</p>
            <p>Stars today: 63 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source srcset=&quot;./banner-dark.png&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
    &lt;source srcset=&quot;./banner.png&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
    &lt;img src=&quot;./banner.png&quot; alt=&quot;Better Auth Logo&quot;&gt;
  &lt;/picture&gt;
  &lt;h2 align=&quot;center&quot;&gt;
    Better Auth
  &lt;/h2&gt;

  &lt;p align=&quot;center&quot;&gt;
    The most comprehensive authentication library for TypeScript
    &lt;br /&gt;
    &lt;a href=&quot;https://better-auth.com&quot;&gt;&lt;strong&gt;Learn more »&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://discord.gg/better-auth&quot;&gt;Discord&lt;/a&gt;
    ·
    &lt;a href=&quot;https://better-auth.com&quot;&gt;Website&lt;/a&gt;
    ·
    &lt;a href=&quot;https://github.com/better-auth/better-auth/issues&quot;&gt;Issues&lt;/a&gt;
  &lt;/p&gt;

[![npm](https://img.shields.io/npm/dm/better-auth?style=flat&amp;colorA=000000&amp;colorB=000000)](https://npm.chart.dev/better-auth?primary=neutral&amp;gray=neutral&amp;theme=dark)
[![npm version](https://img.shields.io/npm/v/better-auth.svg?style=flat&amp;colorA=000000&amp;colorB=000000)](https://www.npmjs.com/package/better-auth)
[![GitHub stars](https://img.shields.io/github/stars/better-auth/better-auth?style=flat&amp;colorA=000000&amp;colorB=000000)](https://github.com/better-auth/better-auth/stargazers)
&lt;/p&gt;

## About the Project

Better Auth is framework-agnostic authentication (and authorization) library for TypeScript. It provides a comprehensive set of features out of the box and includes a plugin ecosystem that simplifies adding advanced functionalities with minimal code in short amount of time. Whether you need 2FA, multi-tenant support, or other complex features. It lets you focus on building your actual application instead of reinventing the wheel. 

### Why Better Auth

Authentication in the TypeScript ecosystem is a half-solved problem. Other open-source libraries often require a lot of additional code for anything beyond basic authentication. Rather than just pushing third-party services as the solution, I believe we can do better as a community—hence, Better Auth.

## Contribution

Better Auth is free and open source project licensed under the [MIT License](./LICENSE.md). You are free to do whatever you want with it.

You could help continuing its development by:

- [Contribute to the source code](./CONTRIBUTING.md)
- [Suggest new features and report issues](https://github.com/better-auth/better-auth/issues)

## Security
If you discover a security vulnerability within Better Auth, please send an e-mail to security@better-auth.com.

All reports will be promptly addressed, and you&#039;ll be credited accordingly.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[langgenius/dify]]></title>
            <link>https://github.com/langgenius/dify</link>
            <guid>https://github.com/langgenius/dify</guid>
            <pubDate>Sat, 11 Oct 2025 00:04:15 GMT</pubDate>
            <description><![CDATA[Production-ready platform for agentic workflow development.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langgenius/dify">langgenius/dify</a></h1>
            <p>Production-ready platform for agentic workflow development.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 116,142</p>
            <p>Forks: 17,915</p>
            <p>Stars today: 121 stars today</p>
            <h2>README</h2><pre>![cover-v5-optimized](./images/GitHub_README_if.png)

&lt;p align=&quot;center&quot;&gt;
  📌 &lt;a href=&quot;https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast&quot;&gt;Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cloud.dify.ai&quot;&gt;Dify Cloud&lt;/a&gt; ·
  &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted&quot;&gt;Self-hosting&lt;/a&gt; ·
  &lt;a href=&quot;https://docs.dify.ai&quot;&gt;Documentation&lt;/a&gt; ·
  &lt;a href=&quot;https://dify.ai/pricing&quot;&gt;Dify edition overview&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://dify.ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Product-F04438&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://dify.ai/pricing&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/free-pricing?logo=free&amp;color=%20%23155EEF&amp;label=pricing&amp;labelColor=%20%23528bff&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/FngNHpbcY7&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1082486657678311454?logo=discord&amp;labelColor=%20%235462eb&amp;logoColor=%20%23f5f5f5&amp;color=%20%235462eb&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://reddit.com/r/difyai&quot; target=&quot;_blank&quot;&gt;  
        &lt;img src=&quot;https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&amp;logo=reddit&amp;label=r%2Fdifyai&amp;labelColor=white&quot;
            alt=&quot;join Reddit&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=dify_ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/dify_ai?logo=X&amp;color=%20%23f5f5f5&quot;
            alt=&quot;follow on X(Twitter)&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/langgenius/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;logoColor=fff&quot;
            alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/u/langgenius&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&amp;color=%20%23f79009&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/graphs/commit-activity&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Commits last month&quot; src=&quot;https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&amp;color=%20%2312b76a&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Issues closed&quot; src=&quot;https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&amp;label=issues%20closed&amp;labelColor=%20%237d89b0&amp;color=%20%235d6b98&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/discussions/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Discussion posts&quot; src=&quot;https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&amp;color=%20%237a5af8&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/zh-TW/README.md&quot;&gt;&lt;img alt=&quot;繁體中文文件&quot; src=&quot;https://img.shields.io/badge/繁體中文-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/zh-CN/README.md&quot;&gt;&lt;img alt=&quot;简体中文文件&quot; src=&quot;https://img.shields.io/badge/简体中文-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/ja-JP/README.md&quot;&gt;&lt;img alt=&quot;日本語のREADME&quot; src=&quot;https://img.shields.io/badge/日本語-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/es-ES/README.md&quot;&gt;&lt;img alt=&quot;README en Español&quot; src=&quot;https://img.shields.io/badge/Español-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/fr-FR/README.md&quot;&gt;&lt;img alt=&quot;README en Français&quot; src=&quot;https://img.shields.io/badge/Français-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/tlh/README.md&quot;&gt;&lt;img alt=&quot;README tlhIngan Hol&quot; src=&quot;https://img.shields.io/badge/Klingon-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/ko-KR/README.md&quot;&gt;&lt;img alt=&quot;README in Korean&quot; src=&quot;https://img.shields.io/badge/한국어-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/ar-SA/README.md&quot;&gt;&lt;img alt=&quot;README بالعربية&quot; src=&quot;https://img.shields.io/badge/العربية-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/tr-TR/README.md&quot;&gt;&lt;img alt=&quot;Türkçe README&quot; src=&quot;https://img.shields.io/badge/Türkçe-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/vi-VN/README.md&quot;&gt;&lt;img alt=&quot;README Tiếng Việt&quot; src=&quot;https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/de-DE/README.md&quot;&gt;&lt;img alt=&quot;README in Deutsch&quot; src=&quot;https://img.shields.io/badge/German-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/bn-BD/README.md&quot;&gt;&lt;img alt=&quot;README in বাংলা&quot; src=&quot;https://img.shields.io/badge/বাংলা-d9d9d9&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Dify is an open-source platform for developing LLM applications. Its intuitive interface combines agentic AI workflows, RAG pipelines, agent capabilities, model management, observability features, and more—allowing you to quickly move from prototype to production.

## Quick start

&gt; Before installing Dify, make sure your machine meets the following minimum system requirements:
&gt;
&gt; - CPU &gt;= 2 Core
&gt; - RAM &gt;= 4 GiB

&lt;/br&gt;

The easiest way to start the Dify server is through [Docker Compose](docker/docker-compose.yaml). Before running Dify with the following commands, make sure that [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) are installed on your machine:

```bash
cd dify
cd docker
cp .env.example .env
docker compose up -d
```

After running, you can access the Dify dashboard in your browser at [http://localhost/install](http://localhost/install) and start the initialization process.

#### Seeking help

Please refer to our [FAQ](https://docs.dify.ai/getting-started/install-self-hosted/faqs) if you encounter problems setting up Dify. Reach out to [the community and us](#community--contact) if you are still having issues.

&gt; If you&#039;d like to contribute to Dify or do additional development, refer to our [guide to deploying from source code](https://docs.dify.ai/getting-started/install-self-hosted/local-source-code)

## Key features

**1. Workflow**:
Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.

**2. Comprehensive model support**:
Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found [here](https://docs.dify.ai/getting-started/readme/model-providers).

![providers-v5](https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3)

**3. Prompt IDE**:
Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.

**4. RAG Pipeline**:
Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.

**5. Agent capabilities**:
You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALL·E, Stable Diffusion and WolframAlpha.

**6. LLMOps**:
Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.

**7. Backend-as-a-Service**:
All of Dify&#039;s offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.

## Using Dify

- **Cloud &lt;/br&gt;**
  We host a [Dify Cloud](https://dify.ai) service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.

- **Self-hosting Dify Community Edition&lt;/br&gt;**
  Quickly get Dify running in your environment with this [starter guide](#quick-start).
  Use our [documentation](https://docs.dify.ai) for further references and more in-depth instructions.

- **Dify for enterprise / organizations&lt;/br&gt;**
  We provide additional enterprise-centric features. [Log your questions for us through this chatbot](https://udify.app/chat/22L1zSxg6yW1cWQg) or [send us an email](mailto:business@dify.ai?subject=%5BGitHub%5DBusiness%20License%20Inquiry) to discuss enterprise needs. &lt;/br&gt;

  &gt; For startups and small businesses using AWS, check out [Dify Premium on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6) and deploy it to your own AWS VPC with one click. It&#039;s an affordable AMI offering with the option to create apps with custom logo and branding.

## Staying ahead

Star Dify on GitHub and be instantly notified of new releases.

![star-us](https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4)

## Advanced Setup

If you need to customize the configuration, please refer to the comments in our [.env.example](docker/.env.example) file and update the corresponding values in your `.env` file. Additionally, you might need to make adjustments to the `docker-compose.yaml` file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run `docker-compose up -d`. You can find the full list of available environment variables [here](https://docs.dify.ai/getting-started/install-self-hosted/environments).

If you&#039;d like to configure a highly-available setup, there are community-contributed [Helm Charts](https://helm.sh/) and YAML files which allow Dify to be deployed on Kubernetes.

- [Helm Chart by @LeoQuote](https://github.com/douban/charts/tree/master/charts/dify)
- [Helm Chart by @BorisPolonsky](https://github.com/BorisPolonsky/dify-helm)
- [Helm Chart by @magicsong](https://github.com/magicsong/ai-charts)
- [YAML file by @Winson-030](https://github.com/Winson-030/dify-kubernetes)
- [YAML file by @wyy-holding](https://github.com/wyy-holding/dify-k8s)
- [🚀 NEW! YAML files (Supports Dify v1.6.0) by @Zhoneym](https://github.com/Zhoneym/DifyAI-Kubernetes)

#### Using Terraform for Deployment

Deploy Dify to Cloud Platform with a single click using [terraform](https://www.terraform.io/)

##### Azure Global

- [Azure Terraform by @nikawang](https://github.com/nikawang/dify-azure-terraform)

##### Google Cloud

- [Google Cloud Terraform by @sotazum](https://github.com/DeNA/dify-google-cloud-terraform)

#### Using AWS CDK for Deployment

Deploy Dify to AWS with [CDK](https://aws.amazon.com/cdk/)

##### AWS

- [AWS CDK by @KevinZhao (EKS based)](https://github.com/aws-samples/solution-for-deploying-dify-on-aws)
- [AWS CDK by @tmokmss (ECS based)](https://github.com/aws-samples/dify-self-hosted-on-aws)

#### Using Alibaba Cloud Computing Nest

Quickly deploy Dify to Alibaba cloud with [Alibaba Cloud Computing Nest](https://computenest.console.aliyun.com/service/instance/create/default?type=user&amp;ServiceName=Dify%E7%A4%BE%E5%8C%BA%E7%89%88)

#### Using Alibaba Cloud Data Management

One-Click deploy Dify to Alibaba Cloud with [Alibaba Cloud Data Management](https://www.alibabacloud.com/help/en/dms/dify-in-invitational-preview/)

#### Deploy to AKS with Azure Devops Pipeline

One-Click deploy Dify to AKS with [Azure Devops Pipeline Helm Chart by @LeoZhang](https://github.com/Ruiruiz30/Dify-helm-chart-AKS)

## Contributing

For those who&#039;d like to contribute code, see our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.

&gt; We are looking for contributors to help translate Dify into languages other than Mandarin or English. If you are interested in helping, please see the [i18n README](https://github.com/langgenius/dify/blob/main/web/i18n-config/README.md) for more information, and leave us a comment in the `global-users` channel of our [Discord Community Server](https://discord.gg/8Tpq4AcN9c).

## Community &amp; contact

- [GitHub Discussion](https://github.com/langgenius/dify/discussions). Best for: sharing feedback and asking questions.
- [GitHub Issues](https://github.com/langgenius/dify/issues). Best for: bugs you encounter using Dify.AI, and feature proposals. See our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
- [Discord](https://discord.gg/FngNHpbcY7). Best for: sharing your applications and hanging out with the community.
- [X(Twitter)](https://twitter.com/dify_ai). Best for: sharing your applications and hanging out with the community.

**Contributors**

&lt;a href=&quot;https://github.com/langgenius/dify/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=langgenius/dify&quot; /&gt;
&lt;/a&gt;

## Star history

[![Star History Chart](https://api.star-history.com/svg?repos=langgenius/dify&amp;type=Date)](https://star-history.com/#langgenius/dify&amp;Date)

## Security disclosure

To protect your privacy, please avoid posting security issues on GitHub. Instead, report issues to security@dify.ai, and our team will respond with detailed answer.

## License

This repository is licensed under the [Dify Open Source License](LICENSE), based on Apache 2.0 with additional conditions.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>