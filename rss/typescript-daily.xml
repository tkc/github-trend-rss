<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Thu, 15 May 2025 00:05:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[i-am-alice/3rd-devs]]></title>
            <link>https://github.com/i-am-alice/3rd-devs</link>
            <guid>https://github.com/i-am-alice/3rd-devs</guid>
            <pubDate>Thu, 15 May 2025 00:05:05 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/i-am-alice/3rd-devs">i-am-alice/3rd-devs</a></h1>
            <p></p>
            <p>Language: TypeScript</p>
            <p>Stars: 391</p>
            <p>Forks: 267</p>
            <p>Stars today: 44 stars today</p>
            <h2>README</h2><pre># AI_devs 3

Repozytorium zawiera przykłady z lekcji kursu AI_devs 3.
Więcej informacji znajdziesz na [aidevs.pl](https://aidevs.pl).

## Wymagania

Wszystkie przykłady zostały napisane w JavaScript / TypeScript i większość z nich zawiera kod backendowy do którego uruchomienia potrzebny jest Node.js oraz Bun.

- [Node.js](https://nodejs.org)
- [Bun](https://bun.sh)

Upewnij się, że posiadasz najnowsze wersje Node.js oraz Bun zainstalowane na swoim komputerze.

## Instalacja

1. Pobierz repozytorium:

   ```bash
   git clone git@github.com:i-am-alice/3rd-devs.git
   cd 3rd-devs
   ```

2. Zainstaluj zależności:
   ```bash
   bun install
   ```
3. Skopiuj plik `.env.example` do `.env` i wypełnij go kluczami API (na początek wystarczy klucz OpenAI).

4. Uruchom dostępne przykłady z pliku `package.json`, według poniższej instrukcji.

## Instalacja — DOCKER

Jeśli posiadasz w swoim systemie możliwość uruchamiania kontenerów Dockera (na Windows użyj np. WSL/WSL2), możesz wykorzystać skrypt, który zbuduje i uruchomi dla Ciebie kontener ze środowiskiem gotowym do pracy.

1. Wejdź do katalogu, w którym chcesz przetrzymywać pliki środowiska i wydaj następujące polecenia:

   ```bash
   curl -fsSL https://env.ag3nts.org -o setup.sh
   bash setup.sh
   ```
   
2. Powyższy skrypt NIE zmienia niczego w systemie. Wykonuje on następujące czynności:
   - klonowanie repozytorium do katalogu &quot;3rd-devs&quot; (poza kontenerem, w aktualnym katalogu)
   - przygotowanie pliku Dockerfile
   - usunięcie starego obrazu Dockera o nazwie &quot;aidevs&quot; (jeśli istnieje)
   - uruchomienie procesu budowy obrazu Dockera
   - instalacja wymaganych paczek wewnątrz zdokeryzowanego środowiska
  
3. Po pomyślnym zbudowaniu obrazu możesz uruchomić go poleceniem (jeśli port 3000 masz zajęty, wybierz inny):
   ```bash
   docker run --rm -it -p 3000:3000 --name aidevs -v ${PWD}/3rd-devs:/app aidevs3
   ```

4. Pliki w katalogu &quot;3rd-devs&quot; możesz modyfikować w dowolnym IDE. Będą one bezpośrednio widoczne wewnątrz kontenera

5. Będąc już wewnątrz kontenera, skopiuj plik `.env.example` do `.env` i wypełnij go wymaganymi kluczami API (na początek wystarczy klucz OpenAI).

6. Twoje środowisko jest gotowe do pracy.


## S01E01

### Thread

Przykład przedstawia konwersację między użytkownikiem i asystentem, w której działa mechanizm podsumowania konwersacji.

- Uruchomienie serwera: `bun run thread`
- Interakcja demo: `curl -X POST http://localhost:3000/api/demo`
- Interakcja chat: `curl -X POST http://localhost:3000/api/chat -H &quot;Content-Type: application/json&quot; -d &#039;{&quot;message&quot;: { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hi&quot;}}&#039;`

Wywołanie powyższego endpointu uruchomi trzy niezależne zapytania do OpenAI, jednak w wiadomości systemowej zostanie przekazane podsumowanie poprzedniej interakcji, dzięki czemu model będzie miał możliwość odwołać się do ich treści.

W przykładzie uwzględniony jest także endpoint `/api/chat` na który można przesłać obiekt { &quot;message&quot;: &quot;...&quot; } zawierający treść wiadomości do modelu. Wątek zostanie zresetowany **dopiero po ponownym uruchomieniu serwera** (wciśnij CMD + C / Control + C i ponownie `bun run thread`).

### Use Search

UWAGA: przykład wymaga zainstalowania `promptfoo` w przypadku którego prawdopodobnie musisz to zrobić poleceniem `npm install promptfoo` ponieważ `bun install promptfoo` nie działa poprawnie w każdej sytuacji.

- Uruchomienie skryptu: `bun use_search`

Rezultatem działania skryptu jest tablica zawierająca kilkanaście przykładowych testów dla promptu decydującego o tym, czy skorzystanie z wyszukiwarki jest potrzebne.

### Pick domains

- Uruchomienie skryptu: `bun pick_domains`

Rezultatem działania skryptu jest tablica zawierająca kilkanaście przykładowych testów dla promptu generującego zapytania do wyszukiwarki Internetowej, wskazując także odpowiednie domeny.

### Rate

- Uruchomienie skryptu: `bun rate`

Rezultatem działania skryptu jest tablica zawierająca kilkanaście przykładowych testów dla promptu oceniającego, czy odpowiedź modelu zawiera odpowiednie informacje.

### Websearch

Przykład ten korzysta z [Firecrawl](https://www.firecrawl.dev) do przeszukiwania Internetu oraz pobierania treści stron www. Konieczne jest więc uzupełnienie pliku `.env` wartości FIRECRAWL_API_KEY ustawionej na klucz API.
(Firecrawl oferuje bezpłatny plan).

- Uruchomienie serwera: `bun websearch`
- Interakcja:
  ```bash
  curl -X POST http://localhost:3000/api/chat \
    -H &quot;Content-Type: application/json&quot; \
    -d &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Search wiki for &#039;John Wick&#039;&quot;}]}&#039;
  ```

Ważne: w pliku `websearch/app.ts` można zmienić listę domen, które są dopuszczalne do przeszukiwania i pobierania treści.

## S01E02

### Linear

Uruchomienie tego przykładu wymaga uzupełnienia pliku `.env` i wartości `LINEAR_API_KEY` oraz `LINEAR_WEBHOOK_SECRET`.
Obie wartości można znaleźć w [ustawieniach API](https://linear.app/overment/settings/api). Dodatkowo Twój localhost musi być dostępny z poza Twojej sieci lokalnej, np. za pomocą [ngrok](https://ngrok.com/). Publiczny adres URL należy także wskazać w panelu Linear w sekcji Webhooks, np.: `https://&lt;ngrok-url&gt;/api/linear/watch-issue` (pamiętaj o dodaniu właściwego endpointu do adresu).

WAŻNE: w pliku `linear/prompts.ts` znajduje się prompt w którym zostały opisane **moje projekty** w Linear.
Aby skrypt działał poprawnie, musisz zmodyfikować ten prompt, tak aby zawierał identyfikatory oraz opisy Twoich projektów.

Listę projektów i ich identyfikatory możesz pobrać korzystając z endpointu `/api/linear/projects`.

- Uruchomienie serwera: `bun linear`
- Pobranie listy projektów: `curl http://localhost:3000/api/linear/projects`
- Po dodaniu nowego wpisu w Twoim linearze, zostanie on automatycznie przypisany do projektu zgodnie z zasadami w promptach, o ile nie został przypisany przez Ciebie ręcznie.

### Files

- Uruchomienie serwera: `bun files`
- Interakcja:
  ```bash
  curl -X POST http://localhost:3000/api/chat \
    -H &quot;Content-Type: application/json&quot; \
    -d &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hey there, what\&#039;s up?&quot;}], &quot;conversation_id&quot;: &quot;d7582176-bc52-4ef3-980a-047b868f9f49&quot;}&#039;
  ```

Przykład ten pokazuje mechanizm podejmowania decyzji o zapamiętywaniu informacji na podstawie kontekstu rozmowy.
Dodatkowo w przypadku podania `conversation_id` w obiekcie żądania, do rozmowy zostaną wczytane wszystkie wiadomości dotyczące konkretnej rozmowy.

Wszystkie pliki zapisywane są w folderze `files/context`, a sam katalog można otworzyć w aplikacji [Obsidian](https://obsidian.md/) aby zobaczyć powiązania pomiędzy wspomnieniami.

## S01E03

### Langfuse

Ten przykład wymaga uzupełnienia pliku `.env` o wartości `LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY` oraz `LANGFUSE_HOST`. Można je uzyskać zakładając bezpłatne konto na [Langfuse](https://langfuse.com/).

UWAGA: Aby uruchomić ten przykład, musisz w panelu Langfuse utworzyć nowy prompt o nazwie `Answer`, którego wartość możesz ustawić na np. &#039;Odpowiadaj pisząc wyłącznie wielkimi literami&#039;.

- Uruchomienie serwera: `bun langfuse`
- Interakcja:
  ```bash
  curl -X POST http://localhost:3000/api/chat \
    -H &quot;Content-Type: application/json&quot; \
    -d &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hey there, what\&#039;s up?&quot;}]}&#039;
  ```

Po wykonaniu zapytania, zostanie ono automatycznie zalogowane do Langfuse, a wynik wyświetlony w panelu.

### Tiktokenizer

- Uruchomienie serwera: `bun tiktokenizer`
- Interakcja:
  ```bash
  curl -X POST http://localhost:3000/api/chat \
    -H &quot;Content-Type: application/json&quot; \
    -d &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hey there, what\&#039;s up?&quot;}], &quot;model&quot;: &quot;gpt-4o&quot;}&#039;
  ```

Przykład ten pokazuje mechanizm liczenia tokenów w zapytaniach do modeli OpenAI (np. gpt-4o).

### Max tokens

Przykład ten pokazuje jeden mechanizm pozwalający na kontynuowanie wypowiedzi modelu, pomimo osiągnięcia maksymalnej liczby tokenów wyjściowych (output tokens).

- Uruchomienie serwera: `bun max_tokens`
- Interakcja:
  ```bash
  curl -X POST http://localhost:3000/api/chat \
    -H &quot;Content-Type: application/json&quot; \
    -d &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Write ten sentences about apples and put them in order.&quot;}]}&#039;
  ```

### Constitution

Przykład ten przedstawia mechanizm blokowania zapytań, które nie spełniają warunków określonych w prompcie `/constitution/prompts.ts`.

- Uruchomienie serwera: `bun constitution`
- Interakcja:
  ```bash
  curl -X POST http://localhost:3000/api/chat \
    -H &quot;Content-Type: application/json&quot; \
    -d &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]}&#039;
  ```

## S01E04

### Memory

Ten przykład po uruchomieniu tworzy katalog memories w którym zapisywane są pliki markdown, pełniące rolę pamięci modelu.
Nie jest to przykład nadający się na produkcję, lecz przedstawia ogólne mechaniki pamięci długoterminowej, które będziemy rozwijać w dalszych lekcjach.

- Uruchomienie serwera: `bun memory`
- Interakcja:

```bash
 curl -X POST http://localhost:3000/api/chat \
   -H &quot;Content-Type: application/json&quot; \
   -d &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]}&#039;
```

## S01E05

### External

Ten przykład zawiera standardową logikę interakcji z modelem, ale wymaga podania klucza API w nagłówku `Authorization` w formacie `Bearer &lt;klucz&gt;`. Wartość klucza zostaje wczytana z pliku `.env` jako `PERSONAL_API_KEY`. Dodatkowo zostały dodane mechanizmy ograniczania liczby zapytań, więc po kilku próbach ponowne wywołanie zapytania zwróci błąd 429.

- Uruchomienie serwera: `bun external`
- Interakcja:
  ```bash
  curl -X POST http://localhost:3000/api/chat \
    -H &quot;Content-Type: application/json&quot; \
    -d &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]}&#039;
  ```

### Prompts

**UWAGA**: Aby uruchomić ten przykład konieczne jest nawiązanie połączenie z Langfuse poprzez uzupełnienie pliku `.env` o wartości `LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY` oraz `LANGFUSE_HOST`. Dodatkowo na Twoim koncie musisz utworzyć nowy prompt o nazwie `Answer`, którego wartość możesz ustawić na np. &#039;Odpowiadaj pisząc wyłącznie wielkimi literami&#039;, aby tylko sprawdzić działanie mechanizmu. Dodatkowo prompt &quot;Answer&quot; należy dodać w ustawieniu &quot;Chat&quot;, a nie &quot;Text&quot; (tryb można zmienić z pomocą zakładek w Langfuse)

- Uruchomienie serwera: `bun prompts`
- Interakcja:
  ```bash
  curl -X POST http://localhost:3000/api/chat \
    -H &quot;Content-Type: application/json&quot; \
    -d &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]}&#039;
  ```

### Database

Ten przykład nie dotyczy bezpośrednio działania LLM, lecz przedstawia sposób organizacji informacji w bazie danych, takich jak konwersacje czy historia wiadomości.

- Uruchomienie serwera: `bun database`
- Interakcja:
  ```bash
  curl -X POST http://localhost:3000/api/chat \
    -H &quot;Content-Type: application/json&quot; \
    -d &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]}&#039;
  ```

### Qdrant

Przykład ten przedstawia **absolutnie podstawowe** połączenie z bazą wektorową Qdrant. Jego zadaniem jest zapisywanie historii wiadomości, a następnie wyszukiwanie i wczytywanie do kontekstu rozmowy najbardziej podobnych wiadomości. Przykład ten będziemy rozbudowywać w dalszych lekcjach, łącząc się z Qdrant w bardziej złożonych konfiguracjach.

UWAGA: Aby uruchomić ten przykład, musisz w panelu Langfuse utworzyć nowy prompt o nazwie `Answer`, którego wartość możesz ustawić na np. &#039;Odpowiadaj pisząc wyłącznie wielkimi literami&#039;. Powodem jest fakt, że w ten przykład został powiązany z przykładem `langfuse`.

- Uruchomienie serwera: `bun qdrant`
- Interakcja:
  ```bash
  curl -X POST http://localhost:3000/api/chat \
    -H &quot;Content-Type: application/json&quot; \
    -d &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]}&#039;
  ```

## S02E01

### Audio

UWAGA: Ten przykład wymaga uruchomienia frontendu w folderze `audio-frontend` oraz backendu w folderze `audio-backend`. W związku z tym przykład **trzeba** uruchomić na własnym komputerze.

- Uruchomienie frontendu: `bun audio:dev`
- Uruchomienie backendu: `bun audio`
- Interakcja: Otwórz w przeglądarce stronę http://localhost:5173

WAŻNE: Jakość działania tego przykładu zależy głównie od jakości mikrofonu oraz dźwięków otoczenia. Upewnij się więc, że jakość nagrania jest dobra i że nie ma zakłóceń uniemożliwiających wykrywanie końca wypowiedzi.

## S02E02

### Vision

- Uruchomienie kodu: `bun vision`

### Recognize

- Uruchomienie kodu: `bun recognize`

### Recognize-Pixtral

Do uruchomienia tego przykładu należy uzupełnić plik `.env` o wartość `MISTRAL_API_KEY`. Można go pobrać tutaj na [Mistral.ai](https://auth.mistral.ai/ui/login?flow=d2707d87-5325-4ff5-a7cd-25a2e21323d5)

- Uruchomienie kodu: `bun recognize_pixtral`

## S02E02

### Vision

- Uruchomienie kodu: `bun vision`
- Interakcja: przykład wykonuje się automatycznie na pliku `vision/lessons.png`

### Recognize

- Uruchomienie kodu: `bun recognize`
- Interakcja: przykład wykonuje się automatycznie na plikach z katalogu `recognize/avatars`

### Recognize-Pixtral

- Uruchomienie kodu: `bun recognize_pixtral`
- Interakcja: przykład wykonuje się automatycznie na plikach z katalogu `recognize_pixtral/avatars`

## S02E03

--- brak przykładów ---

## S02E04

### Captions

- Uruchomienie kodu: `bun captions`
- Interakcja: przykład wykonuje się automatycznie na pliku `captions/article.md`

### Summary

- Uruchomienie kodu: `bun summary`
- Interakcja: skrypt wykonuje się automatycznie na pliku `summary/article.md`

### Video

Do uruchomienia tego przykładu należy uzupełnić plik `.env` o wartość `GOOGLE_AI_STUDIO_API_KEY`, który można pobrać z [Google AI Studio](https://aistudio.google.com/).

- Uruchomienie kodu: `bun video`
- Interakcja: przykład wykonuje się automatycznie na pliku `video/test.mp3`

### Narration

UWAGA: Ten przykład może zużywać duże ilości kredytów na ElevenLabs, więc jeśli chcesz zobaczyć rezultat jego działania, to w katalogu `narration` znajdują się dwa przykładowe pliki audio, które możesz odtworzyć bez uruchamiania kodu.

Do uruchomienia tego przykładu należy uzupełnić plik `.env` o wartość `GOOGLE_AI_STUDIO_API_KEY`, który można pobrać z [Google AI Studio](https://aistudio.google.com/) oraz `ELEVEN_LABS_API_KEY`, który można pobrać z [ElevenLabs](https://elevenlabs.io/).

- Uruchomienie kodu: `bun narration`
- Interakcja: przykład wykonuje się automatycznie na treści wiadomości użytkownika przekazanej w funkcji `generateNarration` w pliku `narration/app.ts`

## S02E05

### Read

- Uruchomienie kodu: `bun read`
- Interakcja: przykład wykonuje się automatycznie na pliku `read/article.md` i generuje plik audio w folderze read/summary.wav

### Mindmap

Ten przykład wymaga uruchomienia frontendu w folderze `audio-map-frontend` oraz backendu w folderze `audio-map`. W związku z tym przykład **trzeba** uruchomić na własnym komputerze.

- Uruchomienie frontendu: `bun map:dev`
- Uruchomienie backendu: `bun audio-map`
- Interakcja: Otwórz w przeglądarce stronę http://localhost:5173

### Notes

- Uruchomienie kodu: `bun notes`
- Interakcja: przykład wykonuje się automatycznie na wiadomości wpisanej w treść pliku `notes/app.ts` (jest tam kilka przykładów innych wiadomości, które można podmienić).

## S03E01

### Text Splitter

- Uruchomienie kodu: `bun text-splitter`
- Interakcja: przykład wykonuje się automatycznie na plikach markdown z katalogu &quot;text-splitter&quot;

### Unstructured

- Uruchomienie kodu: `bun unstructured`
- Interakcja: przykład wykonuje się automatycznie na pliku source.md z katalogu &quot;unstructured&quot;

## S03E02

### Embedding

Uruchomienie tego przykładu wymaga uzupełnienia pliku `.env` o wartości &quot;QDRANT_URL&quot; oraz &quot;QDRANT_API_KEY&quot;.
Wartości te można znaleźć w panelu Qdrant po zalogowaniu na bezpłatne konto na stronie [Qdrant Cloud](https://cloud.qdrant.io/).

![Qdrant Cloud](https://cloud.overment.com/aidevs3_cluster-1732010353.png)

Natomiast klucz API można pobrać w zakładce &quot;Data Access Control&quot;.

- Uruchomienie kodu: `bun embedding`
- Interakcja: przykład wykonuje się automatycznie na danych osadzonych w pliku embedding/app.ts

### Rerank

- Uruchomienie kodu: `bun rerank`
- Interakcja: przykład wykonuje się automatycznie na danych osadzonych w pliku rerank/app.ts

### Naive RAG

- Uruchomienie kodu: `bun naive-rag`
- Interakcja: przykład wykonuje się automatycznie na danych osadzonych w pliku naive-rag/app.ts

### Better RAG

- Uruchomienie kodu: `bun better-rag`
- Interakcja: przykład wykonuje się automatycznie na danych osadzonych w pliku better-rag/app.ts

### Semantic

- Uruchomienie kodu: `bun semantic`
- Interakcja: przykład wykonuje się automatycznie na danych osadzonych w pliku semantic/app.ts

## S03E03

### Algolia

Do uruchomienia tego przykładu konieczne jest uzupełnienie `ALGOLIA_APP_ID` oraz `ALGOLIA_API_KEY` w pliku `.env`.
**UWAGA**: przy pierwszym uruchomieniu przykładu pojawi się błąd ale spowoduje to utworzenie indeksu w Algolia. Wówczas należy przejść do panelu Algolia i w zakładce &quot;Facets&quot; dodać nowy facet o nazwie `author`.

![](https://cloud.overment.com/2024-11-20/aidevs3_algolia-09eeb970-2.png)

- Uruchomienie kodu: `bun algolia`
- Interakcja: przykład wykonuje się automatycznie na danych osadzonych w pliku algolia/app.ts

### Sync

**UWAGA**: Do uruchomienia tego przykładu konieczne jest uzupełnienie `ALGOLIA_APP_ID` oraz `ALGOLIA_API_KEY` w pliku `.env`.
Wymagane jest bezpłatne konto na [Algolia](https://www.algolia.com/).

Dodatkowo jeśli wyniki wyszukiwania nie są poprawnie zwracane, należy sprawdzić czy pole `text` zostało poprawnie ustawione w panelu Algolia jako `searchableAttributes`.

![Algolia](https://cloud.overment.com/2024-11-19/aidevs3_cleanshot-3e7fd444-c.png)

- Uruchomienie kodu: `bun sync`
- Interakcja: przykład wykonuje się automatycznie na danych osadzonych w pliku sync/app.ts

### Hybrid

**UWAGA**: Do uruchomienia tego przykładu konieczne jest uzupełnienie `QDRANT_URL` oraz `QDRANT_API_KEY` w pliku `.env`.
Konieczne jest także połączenie z Algolia podobnie jak w przypadku przykładu `sync`.

- Uruchomienie kodu: `bun hybrid`
- Interakcja: przykład wykonuje się automatycznie na danych osadzonych w pliku hybrid/app.ts

## S03E05

Do uruchomienia tego przykładu konieczne jest połączenie z bazą Neo4j. Można ją zainstalować lokalnie, a następnie uzupełnić plik `.env` o wartości `NEO4J_URI`, `NEO4J_USER` oraz `NEO4J_PASSWORD`.

### Neo4j-101

- Uruchomienie kodu: `bun neo4j-101`
- Interakcja: przykład wykonuje się automatycznie na danych osadzonych w pliku neo4j-101/app.ts

### Neo4j

- Uruchomienie kodu: `bun neo4j`
- Interakcja: przykład wykonuje się automatycznie na danych osadzonych w pliku neo4j/app.ts
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ahmedkhaleel2004/gitdiagram]]></title>
            <link>https://github.com/ahmedkhaleel2004/gitdiagram</link>
            <guid>https://github.com/ahmedkhaleel2004/gitdiagram</guid>
            <pubDate>Thu, 15 May 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[Free, simple, fast interactive diagrams for any GitHub repository]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ahmedkhaleel2004/gitdiagram">ahmedkhaleel2004/gitdiagram</a></h1>
            <p>Free, simple, fast interactive diagrams for any GitHub repository</p>
            <p>Language: TypeScript</p>
            <p>Stars: 12,140</p>
            <p>Forks: 848</p>
            <p>Stars today: 157 stars today</p>
            <h2>README</h2><pre>[![Image](./docs/readme_img.png &quot;GitDiagram Front Page&quot;)](https://gitdiagram.com/)

![License](https://img.shields.io/badge/license-MIT-blue.svg)
[![Kofi](https://img.shields.io/badge/Kofi-F16061.svg?logo=ko-fi&amp;logoColor=white)](https://ko-fi.com/ahmedkhaleel2004)

# GitDiagram

Turn any GitHub repository into an interactive diagram for visualization in seconds.

You can also replace `hub` with `diagram` in any Github URL to access its diagram.

## 🚀 Features

- 👀 **Instant Visualization**: Convert any GitHub repository structure into a system design / architecture diagram
- 🎨 **Interactivity**: Click on components to navigate directly to source files and relevant directories
- ⚡ **Fast Generation**: Powered by OpenAI o4-mini for quick and accurate diagrams
- 🔄 **Customization**: Modify and regenerate diagrams with custom instructions
- 🌐 **API Access**: Public API available for integration (WIP)

## ⚙️ Tech Stack

- **Frontend**: Next.js, TypeScript, Tailwind CSS, ShadCN
- **Backend**: FastAPI, Python, Server Actions
- **Database**: PostgreSQL (with Drizzle ORM)
- **AI**: OpenAI o4-mini
- **Deployment**: Vercel (Frontend), EC2 (Backend)
- **CI/CD**: GitHub Actions
- **Analytics**: PostHog, Api-Analytics

## 🤔 About

I created this because I wanted to contribute to open-source projects but quickly realized their codebases are too massive for me to dig through manually, so this helps me get started - but it&#039;s definitely got many more use cases!

Given any public (or private!) GitHub repository it generates diagrams in Mermaid.js with OpenAI&#039;s o4-mini! (Previously Claude 3.5 Sonnet)

I extract information from the file tree and README for details and interactivity (you can click components to be taken to relevant files and directories)

Most of what you might call the &quot;processing&quot; of this app is done with prompt engineering - see `/backend/app/prompts.py`. This basically extracts and pipelines data and analysis for a larger action workflow, ending in the diagram code.

## 🔒 How to diagram private repositories

You can simply click on &quot;Private Repos&quot; in the header and follow the instructions by providing a GitHub personal access token with the `repo` scope.

You can also self-host this app locally (backend separated as well!) with the steps below.

## 🛠️ Self-hosting / Local Development

1. Clone the repository

```bash
git clone https://github.com/ahmedkhaleel2004/gitdiagram.git
cd gitdiagram
```

2. Install dependencies

```bash
pnpm i
```

3. Set up environment variables (create .env)

```bash
cp .env.example .env
```

Then edit the `.env` file with your Anthropic API key and optional GitHub personal access token.

4. Run backend

```bash
docker-compose up --build -d
```

Logs available at `docker-compose logs -f`
The FastAPI server will be available at `localhost:8000`

5. Start local database

```bash
chmod +x start-database.sh
./start-database.sh
```

When prompted to generate a random password, input yes.
The Postgres database will start in a container at `localhost:5432`

6. Initialize the database schema

```bash
pnpm db:push
```

You can view and interact with the database using `pnpm db:studio`

7. Run Frontend

```bash
pnpm dev
```

You can now access the website at `localhost:3000` and edit the rate limits defined in `backend/app/routers/generate.py` in the generate function decorator.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Acknowledgements

Shoutout to [Romain Courtois](https://github.com/cyclotruc)&#039;s [Gitingest](https://gitingest.com/) for inspiration and styling

## 📈 Rate Limits

I am currently hosting it for free with no rate limits though this is somewhat likely to change in the future.

&lt;!-- If you would like to bypass these, self-hosting instructions are provided. I also plan on adding an input for your own Anthropic API key.

Diagram generation:

- 1 request per minute
- 5 requests per day --&gt;

## 🤔 Future Steps

- Implement font-awesome icons in diagram
- Implement an embedded feature like star-history.com but for diagrams. The diagram could also be updated progressively as commits are made.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[kamranahmedse/developer-roadmap]]></title>
            <link>https://github.com/kamranahmedse/developer-roadmap</link>
            <guid>https://github.com/kamranahmedse/developer-roadmap</guid>
            <pubDate>Thu, 15 May 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[Interactive roadmaps, guides and other educational content to help developers grow in their careers.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kamranahmedse/developer-roadmap">kamranahmedse/developer-roadmap</a></h1>
            <p>Interactive roadmaps, guides and other educational content to help developers grow in their careers.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 320,646</p>
            <p>Forks: 41,445</p>
            <p>Stars today: 446 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lobehub/lobe-chat]]></title>
            <link>https://github.com/lobehub/lobe-chat</link>
            <guid>https://github.com/lobehub/lobe-chat</guid>
            <pubDate>Thu, 15 May 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[🤯 Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / DeepSeek / Qwen), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Plugins/Artifacts) and Thinking. One-click FREE deployment of your private ChatGPT/ Claude / DeepSeek application.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobe-chat">lobehub/lobe-chat</a></h1>
            <p>🤯 Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / DeepSeek / Qwen), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Plugins/Artifacts) and Thinking. One-click FREE deployment of your private ChatGPT/ Claude / DeepSeek application.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 60,749</p>
            <p>Forks: 12,746</p>
            <p>Stars today: 61 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# Lobe Chat

An open-source, modern-design ChatGPT/LLMs UI/Framework.&lt;br/&gt;
Supports speech-synthesis, multi-modal, and extensible ([function call][docs-functionc-call]) plugin system.&lt;br/&gt;
One-click **FREE** deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.

**English** · [简体中文](./README.zh-CN.md) · [Official Site][official-site] · [Changelog][changelog] · [Documents][docs] · [Blog][blog] · [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeChat Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Pioneering the new age of thinking and creating. Built for you, the Super Individual.&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url]

![][image-overview]

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [👋🏻 Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [✨ Features](#-features)
  - [`1` Chain of Thought](#1-chain-of-thought)
  - [`2` Branching Conversations](#2-branching-conversations)
  - [`3` Artifacts Support](#3-artifacts-support)
  - [`4` File Upload /Knowledge Base](#4-file-upload-knowledge-base)
  - [`5` Multi-Model Service Provider Support](#5-multi-model-service-provider-support)
  - [`6` Local Large Language Model (LLM) Support](#6-local-large-language-model-llm-support)
  - [`7` Model Visual Recognition](#7-model-visual-recognition)
  - [`8` TTS &amp; STT Voice Conversation](#8-tts--stt-voice-conversation)
  - [`9` Text to Image Generation](#9-text-to-image-generation)
  - [`10` Plugin System (Function Calling)](#10-plugin-system-function-calling)
  - [`11` Agent Market (GPTs)](#11-agent-market-gpts)
  - [`12` Support Local / Remote Database](#12-support-local--remote-database)
  - [`13` Support Multi-User Management](#13-support-multi-user-management)
  - [`14` Progressive Web App (PWA)](#14-progressive-web-app-pwa)
  - [`15` Mobile Device Adaptation](#15-mobile-device-adaptation)
  - [`16` Custom Themes](#16-custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [⚡️ Performance](#️-performance)
- [🛳 Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [📦 Ecosystem](#-ecosystem)
- [🧩 Plugins](#-plugins)
- [⌨️ Local Development](#️-local-development)
- [🤝 Contributing](#-contributing)
- [❤️ Sponsor](#️-sponsor)
- [🔗 More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

## 👋🏻 Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![][vercel-shield-badge]][vercel-link]   | No installation or registration necessary! Visit our website to experience it firsthand.                           |
| :---------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link] | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub. |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ ⭐️

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## ✨ Features

[![][image-feat-cot]][docs-feat-cot]

### `1` [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### `2` [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### `3` [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeChat. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### `4` [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [📘 LobeChat Knowledge Base Launch — From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### `5` [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

- **[OpenAI](https://lobechat.com/discover/provider/openai)**: OpenAI is a global leader in artificial intelligence research, with models like the GPT series pushing the frontiers of natural language processing. OpenAI is committed to transforming multiple industries through innovative and efficient AI solutions. Their products demonstrate significant performance and cost-effectiveness, widely used in research, business, and innovative applications.
- **[Ollama](https://lobechat.com/discover/provider/ollama)**: Ollama provides models that cover a wide range of fields, including code generation, mathematical operations, multilingual processing, and conversational interaction, catering to diverse enterprise-level and localized deployment needs.
- **[Anthropic](https://lobechat.com/discover/provider/anthropic)**: Anthropic is a company focused on AI research and development, offering a range of advanced language models such as Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Opus, and Claude 3 Haiku. These models achieve an ideal balance between intelligence, speed, and cost, suitable for various applications from enterprise workloads to rapid-response scenarios. Claude 3.5 Sonnet, as their latest model, has excelled in multiple evaluations while maintaining a high cost-performance ratio.
- **[Bedrock](https://lobechat.com/discover/provider/bedrock)**: Bedrock is a service provided by Amazon AWS, focusing on delivering advanced AI language and visual models for enterprises. Its model family includes Anthropic&#039;s Claude series, Meta&#039;s Llama 3.1 series, and more, offering a range of options from lightweight to high-performance, supporting tasks such as text generation, conversation, and image processing for businesses of varying scales and needs.
- **[Google](https://lobechat.com/discover/provider/google)**: Google&#039;s Gemini series represents its most advanced, versatile AI models, developed by Google DeepMind, designed for multimodal capabilities, supporting seamless understanding and processing of text, code, images, audio, and video. Suitable for various environments from data centers to mobile devices, it significantly enhances the efficiency and applicability of AI models.
- **[DeepSeek](https://lobechat.com/discover/provider/deepseek)**: DeepSeek is a company focused on AI technology research and application, with its latest model DeepSeek-V2.5 integrating general dialogue and code processing capabilities, achieving significant improvements in human preference alignment, writing tasks, and instruction following.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[HuggingFace](https://lobechat.com/discover/provider/huggingface)**: The HuggingFace Inference API provides a fast and free way for you to explore thousands of models for various tasks. Whether you are prototyping for a new application or experimenting with the capabilities of machine learning, this API gives you instant access to high-performance models across multiple domains.
- **[OpenRouter](https://lobechat.com/discover/provider/openrouter)**: OpenRouter is a service platform providing access to various cutting-edge large model interfaces, supporting OpenAI, Anthropic, LLaMA, and more, suitable for diverse development and application needs. Users can flexibly choose the optimal model and pricing based on their requirements, enhancing the AI experience.
- **[Cloudflare Workers AI](https://lobechat.com/discover/provider/cloudflare)**: Run serverless GPU-powered machine learning models on Cloudflare&#039;s global network.

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+30)&lt;/kbd&gt;&lt;/summary&gt;

- **[GitHub](https://lobechat.com/discover/provider/github)**: With GitHub Models, developers can become AI engineers and leverage the industry&#039;s leading AI models.
- **[Novita](https://lobechat.com/discover/provider/novita)**: Novita AI is a platform providing a variety of large language models and AI image generation API services, flexible, reliable, and cost-effective. It supports the latest open-source models like Llama3 and Mistral, offering a comprehensive, user-friendly, and auto-scaling API solution for generative AI application development, suitable for the rapid growth of AI startups.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[Together AI](https://lobechat.com/discover/provider/togetherai)**: Together AI is dedicated to achieving leading performance through innovative AI models, offering extensive customization capabilities, including rapid scaling support and intuitive deployment processes to meet various enterprise needs.
- **[Fireworks AI](https://lobechat.com/discover/provider/fireworksai)**: Fireworks AI is a leading provider of advanced language model services, focusing on functional calling and multimodal processing. Its latest model, Firefunction V2, is based on Llama-3, optimized for function calling, conversation, and instruction following. The visual language model FireLLaVA-13B supports mixed input of images and text. Other notable models include the Llama series and Mixtral series, providing efficient multilingual instruction following and generation support.
- **[Groq](https://lobechat.com/discover/provider/groq)**: Groq&#039;s LPU inference engine has excelled in the latest independent large language model (LLM) benchmarks, redefining the standards for AI solutions with its remarkable speed and efficiency. Groq represents instant inference speed, demonstrating strong performance in cloud-based deployments.
- **[Perplexity](https://lobechat.com/discover/provider/perplexity)**: Perplexity is a leading provider of conversational generation models, offering various advanced Llama 3.1 models that support both online and offline applications, particularly suited for complex natural language processing tasks.
- **[Mistral](https://lobechat.com/discover/provider/mistral)**: Mistral provides advanced general, specialized, and research models widely used in complex reasoning, multilingual tasks, and code generation. Through functional calling interfaces, users can integrate custom functionalities for specific applications.
- **[Ai21Labs](https://lobechat.com/discover/provider/ai21)**: AI21 Labs builds foundational models and AI systems for enterprises, accelerating the application of generative AI in production.
- **[Upstage](https://lobechat.com/discover/provider/upstage)**: Upstage focuses on developing AI models for various business needs, including Solar LLM and document AI, aiming to achieve artificial general intelligence (AGI) for work. It allows for the creation of simple conversational agents through Chat API and supports functional calling, translation, embedding, and domain-specific applications.
- **[xAI](https://lobechat.com/discover/provider/xai)**: xAI is a company dedicated to building artificial intelligence to accelerate human scientific discovery. Our mission is to advance our collective understanding of the universe.
- **[Qwen](https://lobechat.com/discover/provider/qwen)**: Tongyi Qianwen is a large-scale language model independently developed by Alibaba Cloud, featuring strong natural language understanding and generation capabilities. It can answer various questions, create written content, express opinions, and write code, playing a role in multiple fields.
- **[Wenxin](https://lobechat.com/discover/provider/wenxin)**: An enterprise-level one-stop platform for large model and AI-native application development and services, providing the most comprehensive and user-friendly toolchain for the entire process of generative artificial intelligence model development and application development.
- **[Hunyuan](https://lobechat.com/discover/provider/hunyuan)**: A large language model developed by Tencent, equipped with powerful Chinese creative capabilities, logical reasoning abilities in complex contexts, and reliable task execution skills.
- **[ZhiPu](https://lobechat.com/discover/provider/zhipu)**: Zhipu AI offers an open platform for multimodal and language models, supporting a wide range of AI application scenarios, including text processing, image understanding, and programming assistance.
- **[SiliconCloud](https://lobechat.com/discover/provider/siliconcloud)**: SiliconFlow is dedicated to accelerating AGI for the benefit of humanity, enhancing large-scale AI efficiency through an easy-to-use and cost-effective GenAI stack.
- **[01.AI](https://lobechat.com/discover/provider/zeroone)**: 01.AI focuses on AI 2.0 era technologies, vigorously promoting the innovation and application of &#039;human + artificial intelligence&#039;, using powerful models and advanced AI technologies to enhance human productivity and achieve technological empowerment.
- **[Spark](https://lobechat.com/discover/provider/spark)**: iFlytek&#039;s Spark model provides powerful AI capabilities across multiple domains and languages, utilizing advanced natural language processing technology to build innovative applications suitable for smart hardware, smart healthcare, smart finance, and other vertical scenarios.
- **[SenseNova](https://lobechat.com/discover/provider/sensenova)**: SenseNova, backed by SenseTime&#039;s robust infrastructure, offers efficient and user-friendly full-stack large model services.
- **[Stepfun](https://lobechat.com/discover/provider/stepfun)**: StepFun&#039;s large model possesses industry-leading multimodal and complex reasoning capabilities, supporting ultra-long text understanding and powerful autonomous scheduling search engine functions.
- **[Moonshot](https://lobechat.com/discover/provider/moonshot)**: Moonshot is an open-source platform launched by Beijing Dark Side Technology Co., Ltd., providing various natural language processing models with a wide range of applications, including but not limited to content creation, academic research, intelligent recommendations, and medical diagnosis, supporting long text processing and complex generation tasks.
- **[Baichuan](https://lobechat.com/discover/provider/baichuan)**: Baichuan Intelligence is a company focused on the research and development of large AI models, with its models excelling in domestic knowledge encyclopedias, long text processing, and generative creation tasks in Chinese, surpassing mainstream foreign models. Baichuan Intelligence also possesses industry-leading multimodal capabilities, performing excellently in multiple authoritative evaluations. Its models include Baichuan 4, Baichuan 3 Turbo, and Baichuan 3 Turbo 128k, each optimized for different application scenarios, providing cost-effective solutions.
- **[Minimax](https://lobechat.com/discover/provider/minimax)**: MiniMax is a general artificial intelligence technology company established in 2021, dedicated to co-creating intelligence with users. MiniMax has independently developed general large models of different modalities, including trillion-parameter MoE text models, voice models, and image models, and has launched applications such as Conch AI.
- **[InternLM](https://lobechat.com/di

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[n8n-io/n8n]]></title>
            <link>https://github.com/n8n-io/n8n</link>
            <guid>https://github.com/n8n-io/n8n</guid>
            <pubDate>Thu, 15 May 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/n8n-io/n8n">n8n-io/n8n</a></h1>
            <p>Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 93,334</p>
            <p>Forks: 25,590</p>
            <p>Stars today: 825 stars today</p>
            <h2>README</h2><pre>![Banner image](https://user-images.githubusercontent.com/10284570/173569848-c624317f-42b1-45a6-ab09-f0ea3c247648.png)

# n8n - Secure Workflow Automation for Technical Teams

n8n is a workflow automation platform that gives technical teams the flexibility of code with the speed of no-code. With 400+ integrations, native AI capabilities, and a fair-code license, n8n lets you build powerful automations while maintaining full control over your data and deployments.

![n8n.io - Screenshot](https://raw.githubusercontent.com/n8n-io/n8n/master/assets/n8n-screenshot-readme.png)

## Key Capabilities

- **Code When You Need It**: Write JavaScript/Python, add npm packages, or use the visual interface
- **AI-Native Platform**: Build AI agent workflows based on LangChain with your own data and models
- **Full Control**: Self-host with our fair-code license or use our [cloud offering](https://app.n8n.cloud/login)
- **Enterprise-Ready**: Advanced permissions, SSO, and air-gapped deployments
- **Active Community**: 400+ integrations and 900+ ready-to-use [templates](https://n8n.io/workflows)

## Quick Start

Try n8n instantly with [npx](https://docs.n8n.io/hosting/installation/npm/) (requires [Node.js](https://nodejs.org/en/)):

```
npx n8n
```

Or deploy with [Docker](https://docs.n8n.io/hosting/installation/docker/):

```
docker volume create n8n_data
docker run -it --rm --name n8n -p 5678:5678 -v n8n_data:/home/node/.n8n docker.n8n.io/n8nio/n8n
```

Access the editor at http://localhost:5678

## Resources

- 📚 [Documentation](https://docs.n8n.io)
- 🔧 [400+ Integrations](https://n8n.io/integrations)
- 💡 [Example Workflows](https://n8n.io/workflows)
- 🤖 [AI &amp; LangChain Guide](https://docs.n8n.io/langchain/)
- 👥 [Community Forum](https://community.n8n.io)
- 📖 [Community Tutorials](https://community.n8n.io/c/tutorials/28)

## Support

Need help? Our community forum is the place to get support and connect with other users:
[community.n8n.io](https://community.n8n.io)

## License

n8n is [fair-code](https://faircode.io) distributed under the [Sustainable Use License](https://github.com/n8n-io/n8n/blob/master/LICENSE.md) and [n8n Enterprise License](https://github.com/n8n-io/n8n/blob/master/LICENSE_EE.md).

- **Source Available**: Always visible source code
- **Self-Hostable**: Deploy anywhere
- **Extensible**: Add your own nodes and functionality

[Enterprise licenses](mailto:license@n8n.io) available for additional features and support.

Additional information about the license model can be found in the [docs](https://docs.n8n.io/reference/license/).

## Contributing

Found a bug 🐛 or have a feature idea ✨? Check our [Contributing Guide](https://github.com/n8n-io/n8n/blob/master/CONTRIBUTING.md) to get started.

## Join the Team

Want to shape the future of automation? Check out our [job posts](https://n8n.io/careers) and join our team!

## What does n8n mean?

**Short answer:** It means &quot;nodemation&quot; and is pronounced as n-eight-n.

**Long answer:** &quot;I get that question quite often (more often than I expected) so I decided it is probably best to answer it here. While looking for a good name for the project with a free domain I realized very quickly that all the good ones I could think of were already taken. So, in the end, I chose nodemation. &#039;node-&#039; in the sense that it uses a Node-View and that it uses Node.js and &#039;-mation&#039; for &#039;automation&#039; which is what the project is supposed to help with. However, I did not like how long the name was and I could not imagine writing something that long every time in the CLI. That is when I then ended up on &#039;n8n&#039;.&quot; - **Jan Oberhauser, Founder and CEO, n8n.io**
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[open-metadata/OpenMetadata]]></title>
            <link>https://github.com/open-metadata/OpenMetadata</link>
            <guid>https://github.com/open-metadata/OpenMetadata</guid>
            <pubDate>Thu, 15 May 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[OpenMetadata is a unified metadata platform for data discovery, data observability, and data governance powered by a central metadata repository, in-depth column level lineage, and seamless team collaboration.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-metadata/OpenMetadata">open-metadata/OpenMetadata</a></h1>
            <p>OpenMetadata is a unified metadata platform for data discovery, data observability, and data governance powered by a central metadata repository, in-depth column level lineage, and seamless team collaboration.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,646</p>
            <p>Forks: 1,221</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://open-metadata.org&quot;&gt;
        &lt;img alt=&quot;Logo&quot; src=&quot;https://github.com/open-metadata/OpenMetadata/assets/40225091/e794ced8-7220-4393-8efc-3faf93bfb503&quot; width=&quot;49%&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Empower your Data Journey with OpenMetadata&lt;/b&gt;&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    
![Commit Activity](https://img.shields.io/github/commit-activity/m/open-metadata/OpenMetadata?style=for-the-badge)
[![Release](https://img.shields.io/github/release/open-metadata/OpenMetadata/all.svg?style=for-the-badge)](https://github.com/open-metadata/OpenMetadata/releases)

&lt;/div&gt;

## What is OpenMetadata?
[OpenMetadata](https://open-metadata.org/)  is a unified metadata platform for data discovery, data observability, and data governance powered by a central metadata repository, in-depth column level lineage, and seamless team collaboration. It is one of the fastest-growing open-source projects with a vibrant community and adoption by a diverse set of companies in a variety of industry verticals. Based on Open Metadata Standards and APIs, supporting connectors to a wide range of data services, OpenMetadata enables end-to-end metadata management, giving you the freedom to unlock the value of your data assets.
&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/open-metadata/OpenMetadata/assets/40225091/ebfb4ec5-f0a2-4d58-8ce5-a082b5cf0f76&quot; width=800&gt;
&lt;/div&gt;

&lt;br /&gt;
Contents:

- [Features](#key-features-of-openmetadata)
- [Try our Sandbox](#try-our-sandbox)
- [Install &amp; Run](#install-and-run-openmetadata)
- [Roadmap](https://docs.open-metadata.org/latest/roadmap)
- [Documentation and Support](#documentation-and-support)
- [Contributors](#contributors)

OpenMetadata Consists of Four Main Components:
- **Metadata Schemas**: These are the core definitions and vocabulary for metadata based on common abstractions and types. They also allow for custom extensions and properties to suit different use cases and domains.
- **Metadata Store**: This is the central repository for storing and managing the metadata graph, which connects data assets, users, and tool-generated metadata in a unified way.
- **Metadata APIs**: These are the interfaces for producing and consuming metadata, built on top of the metadata schemas. They enable seamless integration of user interfaces and tools, systems, and services with the metadata store.
- **Ingestion Framework**: This is a pluggable framework for ingesting metadata from various sources and tools to the metadata store. It supports about 75+ connectors for data warehouses, databases, dashboard services, messaging services, pipeline services, and more.

## Key Features of OpenMetadata
**Data Discovery**: Find and explore all your data assets in a single place using various strategies, such as keyword search, data associations, and advanced queries. You can search across tables, topics, dashboards, pipelines, and services.

![12](https://github.com/open-metadata/OpenMetadata/assets/40225091/0dbd2746-c93d-4a47-8d3e-ceb3ae01436f)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Collaboration**: Communicate, converse, and cooperate with other users and teams on data assets. You can get event notifications, send alerts, add announcements, create tasks, and use conversation threads.

![11](https://github.com/open-metadata/OpenMetadata/assets/40225091/7df29e12-8a29-44b7-9466-42474823783f)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Quality and Profiler**: Measure and monitor the quality with **no-code** to build trust in your data. You can define and run data quality tests, group them into test suites, and view the results in an interactive dashboard. With powerful collaboration, make data quality a shared responsibility in your organization.

![8](https://github.com/open-metadata/OpenMetadata/assets/40225091/6b330827-cc2d-4d06-abf0-a4d42ce532ba)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Governance**: Enforce data policies and standards across your organization. You can define data domains and data products, assign owners and stakeholders, and classify data assets using tags and terms. Use powerful automation features to auto-classify your data.

![10](https://github.com/open-metadata/OpenMetadata/assets/40225091/f7384a71-6b58-44ad-983f-e302718ee3f1)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Insights and KPIs**: Use reports and platform analytics to understand how your organization&#039;s data is doing. Data Insights provides a single-pane view of all the key metrics to reflect the state of your data best. Define the Key Performance Indicators (KPIs) and set goals within OpenMetadata to work towards better documentation, ownership, and tiering. Alerts can be set against the KPIs to be received on a specified schedule.

![9](https://github.com/open-metadata/OpenMetadata/assets/40225091/61fc2f65-2436-4fc9-9434-c27ee9b25183)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Lineage**: Track and visualize the origin and transformation of your data assets end-to-end. You can view column-level lineage, filter queries, and edit lineage manually using a no-code editor.
  
**Data Documentation**: Document your data assets and metadata entities using rich text, images, and links. You can also add comments and annotations and generate data dictionaries and data catalogs.
  
**Data Observability**: Monitor the health and performance of your data assets and pipelines. You can view metrics such as data freshness, data volume, data quality, and data latency. You can also set up alerts and notifications for any anomalies or failures.
  
**Data Security**: Secure your data and metadata using various authentication and authorization mechanisms. You can integrate with different identity providers for single sign-on and define roles and policies for access control.
  
**Webhooks**: Integrate with external applications and services using webhooks. You can register URLs to receive metadata event notifications and integrate with Slack, Microsoft Teams, and Google Chat.
  
**Connectors**: Ingest metadata from various sources and tools using connectors. OpenMetadata supports about 75+ connectors for data warehouses, databases, dashboard services, messaging services, pipeline services, and more.

## Try our Sandbox

Take a look and play with sample data at [http://sandbox.open-metadata.org](http://sandbox.open-metadata.org)

## Install and Run OpenMetadata
Get up and running in a few minutes. See the OpenMetadata documentation for [installation instructions](https://docs.open-metadata.org/quick-start/local-docker-deployment).

## Documentation and Support

We&#039;re here to help and make OpenMetadata even better! Check out [OpenMetadata documentation](https://docs.open-metadata.org/) for a complete description of OpenMetadata&#039;s features. Join our [Slack Community](https://slack.open-metadata.org/) to get in touch with us if you want to chat, need help, or discuss new feature requirements.


## Contributors

We ❤️ all contributions, big and small! Check out our [CONTRIBUTING](./CONTRIBUTING.md) guide to get started, and let us know how we can help.

Don&#039;t want to miss anything? Give the project a ⭐ 🚀 

A HUGE THANK YOU to all our supporters!

&lt;a href=&quot;https://github.com/open-metadata/OpenMetadata/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=open-metadata/OpenMetadata&amp;max=4000&amp;columns=30&quot; /&gt;
&lt;/a&gt;

## Stargazers

[![Stargazers of @open-metadata/OpenMetadata repo](http://reporoster.com/stars/open-metadata/OpenMetadata)](https://github.com/open-metadata/OpenMetadata/stargazers)

## License
OpenMetadata is released under [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[bytedance/UI-TARS-desktop]]></title>
            <link>https://github.com/bytedance/UI-TARS-desktop</link>
            <guid>https://github.com/bytedance/UI-TARS-desktop</guid>
            <pubDate>Thu, 15 May 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[A GUI Agent application based on UI-TARS(Vision-Language Model) that allows you to control your computer using natural language.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytedance/UI-TARS-desktop">bytedance/UI-TARS-desktop</a></h1>
            <p>A GUI Agent application based on UI-TARS(Vision-Language Model) that allows you to control your computer using natural language.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 13,807</p>
            <p>Forks: 1,114</p>
            <p>Stars today: 61 stars today</p>
            <h2>README</h2><pre>

&gt; [!IMPORTANT]
&gt; &lt;a href=&quot;./apps/agent-tars/README.md&quot;&gt;
&gt;   &lt;img src=&quot;./apps/agent-tars/static/hero.png&quot;&gt;
&gt; &lt;/a&gt;
&gt;
&gt; **\[2025-03-18\]** We released a **technical preview** version of a new desktop app - [Agent TARS](./apps/agent-tars/README.md), a multimodal AI agent that leverages browser operations by visually interpreting web pages and seamlessly integrating with command lines and file systems.


&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;UI-TARS&quot; width=&quot;260&quot; src=&quot;./apps/ui-tars/resources/icon.png&quot;&gt;
&lt;/p&gt;

# UI-TARS Desktop

UI-TARS Desktop is a GUI Agent application based on [UI-TARS (Vision-Language Model)](https://github.com/bytedance/UI-TARS) that allows you to control your computer using natural language.


&lt;div align=&quot;center&quot;&gt;
&lt;p&gt;
        &amp;nbsp&amp;nbsp 📑 &lt;a href=&quot;https://arxiv.org/abs/2501.12326&quot;&gt;Paper&lt;/a&gt; &amp;nbsp&amp;nbsp
        | 🤗 &lt;a href=&quot;https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B&quot;&gt;Hugging Face Models&lt;/a&gt;&amp;nbsp&amp;nbsp
        | &amp;nbsp&amp;nbsp🫨 &lt;a href=&quot;https://discord.gg/pTXwYVjfcs&quot;&gt;Discord&lt;/a&gt;&amp;nbsp&amp;nbsp
        | &amp;nbsp&amp;nbsp🤖 &lt;a href=&quot;https://www.modelscope.cn/collections/UI-TARS-bccb56fa1ef640&quot;&gt;ModelScope&lt;/a&gt;&amp;nbsp&amp;nbsp
&lt;br&gt;
🖥️ Desktop Application &amp;nbsp&amp;nbsp
| &amp;nbsp&amp;nbsp 👓 &lt;a href=&quot;https://github.com/web-infra-dev/midscene&quot;&gt;Midscene (use in browser)&lt;/a&gt; &amp;nbsp&amp;nbsp
| &amp;nbsp&amp;nbsp &lt;a href=&quot;https://deepwiki.com/bytedance/UI-TARS-desktop&quot;&gt;
    &lt;img alt=&quot;Ask DeepWiki.com&quot; src=&quot;https://devin.ai/assets/deepwiki-badge.png&quot; style=&quot;height: 18px; vertical-align: middle;&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

[![](https://trendshift.io/api/badge/repositories/13584)](https://trendshift.io/repositories/13584)

&lt;/div&gt;

## Showcases

| Instruction  | Video |
| :---:  | :---: |
| Please help me open the autosave feature of VS Code and delay AutoSave operations for 500 milliseconds in the VS Code setting.      |    &lt;video src=&quot;https://github.com/user-attachments/assets/e0914ce9-ad33-494b-bdec-0c25c1b01a27&quot; height=&quot;300&quot; /&gt;    |
| Could you help me check the latest open issue of the UI-TARS-Desktop project on GitHub?   | &lt;video src=&quot;https://github.com/user-attachments/assets/3d159f54-d24a-4268-96c0-e149607e9199&quot; height=&quot;300&quot; /&gt;        |


## News

- **\[2025-04-17\]** - 🎉 We&#039;re thrilled to announce the release of new UI-TARS Desktop application v0.1.0, featuring a redesigned Agent UI. The application enhances the computer using experience, introduces new browser operation features, and supports [the advanced UI-TARS-1.5 model](https://seed-tars.com/1.5) for improved performance and precise control.
- **\[2025-02-20\]** - 📦 Introduced [UI TARS SDK](./docs/sdk.md), is a powerful cross-platform toolkit for building GUI automation agents.
- **\[2025-01-23\]** - 🚀 We updated the **[Cloud Deployment](./docs/deployment.md#cloud-deployment)** section in the 中文版: [GUI模型部署教程](https://bytedance.sg.larkoffice.com/docx/TCcudYwyIox5vyxiSDLlgIsTgWf#U94rdCxzBoJMLex38NPlHL21gNb) with new information related to the ModelScope platform. You can now use the ModelScope platform for deployment.


## Features

- 🤖 Natural language control powered by Vision-Language Model
- 🖥️ Screenshot and visual recognition support
- 🎯 Precise mouse and keyboard control
- 💻 Cross-platform support (Windows/MacOS/Browser)
- 🔄 Real-time feedback and status display
- 🔐 Private and secure - fully local processing

## Quick Start

See [Quick Start](./docs/quick-start.md).

## Deployment

See [Deployment](https://github.com/bytedance/UI-TARS/blob/main/README_deploy.md).

## Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md).

## SDK (Experimental)

See [@ui-tars/sdk](./docs/sdk.md)

## License

UI-TARS Desktop is licensed under the Apache License 2.0.

## Citation
If you find our paper and code useful in your research, please consider giving a star :star: and citation :pencil:

```BibTeX
@article{qin2025ui,
  title={UI-TARS: Pioneering Automated GUI Interaction with Native Agents},
  author={Qin, Yujia and Ye, Yining and Fang, Junjie and Wang, Haoming and Liang, Shihao and Tian, Shizuo and Zhang, Junda and Li, Jiahao and Li, Yunxin and Huang, Shijue and others},
  journal={arXiv preprint arXiv:2501.12326},
  year={2025}
}
```
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[adobe/react-spectrum]]></title>
            <link>https://github.com/adobe/react-spectrum</link>
            <guid>https://github.com/adobe/react-spectrum</guid>
            <pubDate>Thu, 15 May 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[A collection of libraries and tools that help you build adaptive, accessible, and robust user experiences.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/adobe/react-spectrum">adobe/react-spectrum</a></h1>
            <p>A collection of libraries and tools that help you build adaptive, accessible, and robust user experiences.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 13,889</p>
            <p>Forks: 1,245</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>#  [React Spectrum Libraries](https://react-spectrum.adobe.com/)

A collection of libraries and tools that help you build adaptive, accessible, and robust user experiences.

### React Spectrum

A React implementation of Spectrum, Adobe’s design system. Spectrum provides adaptive, accessible, and cohesive experiences for all Adobe applications.

[Explore React Spectrum](https://react-spectrum.adobe.com/react-spectrum/index.html)

### React Aria

A library of unstyled React components and hooks that helps you build accessible, high quality UI components for your application or design system.

[Learn more about React Aria](https://react-spectrum.adobe.com/react-aria/index.html)

### React Stately

A library of React Hooks that provides cross-platform state management for your design system.

[More information about React Stately](https://react-spectrum.adobe.com/react-stately/index.html)

### Internationalized

A collection of framework-agnostic internationalization libraries for the web.

[Internationalized Packages](https://react-spectrum.adobe.com/internationalized/index.html)

## Features

* ♿️ **[Accessible](https://react-spectrum.adobe.com/react-aria/accessibility.html)** – Accessibility and behavior is implemented according to [WAI-ARIA Authoring Practices](https://www.w3.org/TR/wai-aria-practices-1.2/), including full screen reader and keyboard navigation support. All components have been tested across a wide variety of screen readers and devices to ensure the best experience possible for all users.
* 📱 **[Adaptive](https://react-spectrum.adobe.com/react-aria/interactions.html)** – All components are designed to work with mouse, touch, and keyboard interactions. They’re built with responsive design principles to deliver a great experience, no matter the device.
* 🌍 **[International](https://react-spectrum.adobe.com/react-aria/internationalization.html)** – Support over 30 languages is included out of the box, including support for right-to-left languages, date and number formatting, and more.
* 🎨 **[Customizable](https://react-spectrum.adobe.com/react-spectrum/theming.html)** – React Spectrum components support custom themes, and automatically adapt for dark mode. For even more customizability, you can build your own components with your own DOM structure and styling using the [React Aria](https://react-spectrum.adobe.com/react-aria/index.html) and [React Stately](https://react-spectrum.adobe.com/react-stately/index.html) hooks to provide behavior, accessibility, and interactions.

## Getting started

React Spectrum includes several libraries, which you can choose depending on your usecase.

* [React Spectrum](https://react-spectrum.adobe.com/react-spectrum/getting-started.html) is an implementation of Adobe&#039;s design system. If you’re integrating with Adobe software or would like a complete component library to use in your project, look no further!
* [React Aria](https://react-spectrum.adobe.com/react-aria/getting-started.html) is a collection of unstyled React components and hooks that helps you build accessible, high quality UI components for your own application or design system. If you&#039;re building a component library for the web from scratch with your own styling, start here.
* [React Stately](https://react-spectrum.adobe.com/react-stately/getting-started.html) is a library of state management hooks for use in your component library. If you&#039;re using React Aria, you&#039;ll likely also use React Stately, but it can also be used independently (e.g. on other platforms like React Native).

[Read more about our architecture](https://react-spectrum.adobe.com/architecture.html).

## Contributing

One of the goals of the React Spectrum project is to make building design systems and component libraries as easy as possible, while maintaining high quality interactions and accessibility support. We aim to raise the bar for web applications. The best way to achieve that goal is **together**. We would love contributions from the community no matter how big or small. 😍

Read our [contributing guide](https://react-spectrum.adobe.com/contribute.html) to learn about how to propose bugfixes and improvements, and how the development process works. For detailed information about our architecture, and how all of the pieces fit together, read our [architecture docs](https://react-spectrum.adobe.com/architecture.html).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[zaidmukaddam/scira]]></title>
            <link>https://github.com/zaidmukaddam/scira</link>
            <guid>https://github.com/zaidmukaddam/scira</guid>
            <pubDate>Thu, 15 May 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[Scira (Formerly MiniPerplx) is a minimalistic AI-powered search engine that helps you find information on the internet and cites it too. Powered by Vercel AI SDK! Search with models like xAI's Grok 3.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zaidmukaddam/scira">zaidmukaddam/scira</a></h1>
            <p>Scira (Formerly MiniPerplx) is a minimalistic AI-powered search engine that helps you find information on the internet and cites it too. Powered by Vercel AI SDK! Search with models like xAI's Grok 3.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,962</p>
            <p>Forks: 938</p>
            <p>Stars today: 45 stars today</p>
            <h2>README</h2><pre># Scira

![Scira](/app/opengraph-image.png)

A minimalistic AI-powered search engine that helps you find information on the internet.

## Powered By

&lt;div align=&quot;center&quot;&gt;
  &lt;div style=&quot;display: flex; justify-content: center; align-items: center; gap: 80px; margin: 20px 0;&quot;&gt;
    &lt;a href=&quot;https://sdk.vercel.ai/docs&quot;&gt;
      &lt;img src=&quot;/public/one.svg&quot; alt=&quot;Vercel AI SDK&quot; height=&quot;40&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://tavily.com&quot;&gt;
      &lt;img src=&quot;/public/four.svg&quot; alt=&quot;Tavily AI&quot; height=&quot;40&quot; /&gt;
    &lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;

- [Vercel AI SDK](https://sdk.vercel.ai/docs) - For AI model integration and streaming
- [Tavily AI](https://tavily.com) - For search grounding and web search capabilities

## Special Thanks

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

  [![Warp](https://github.com/user-attachments/assets/2bda420d-4211-4900-a37e-e3c7056d799c)](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=scira)&lt;br&gt;
  ### **[Warp, the intelligent terminal](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=scira)**&lt;br&gt;
  [Available for MacOS, Linux, &amp; Windows](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=scira)&lt;br&gt;
  [Visit warp.dev to learn more](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=scira)

  [![NinjaTools](https://bakrqvdfyriopfzffskk.supabase.co/storage/v1/object/sign/ads/Ninja%20Tools%20AD.png?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJhZHMvTmluamEgVG9vbHMgQUQucG5nIiwiaWF0IjoxNzQyNzExMTMwLCJleHAiOjEwMzgyNzExMTMwfQ.eTY4DXSEXe61I7-Jk0nK8rimSLAETqfp5mEO5MpsH00)](https://ninjatools.ai/?ref=scria)&lt;br&gt;
  ### **[NinjaTools, the All in one AI assistant and workspace](https://ninjatools.ai/?ref=scria)**&lt;br&gt;
  [Visit Ninjatools.ai to learn more](https://ninjatools.ai/?ref=scria)
  
&lt;/div&gt;

## Features

- **AI-powered search**: Get answers to your questions using Anthropic&#039;s Models.
- **Web search**: Search the web using Tavily&#039;s API.
- **URL Specific search**: Get information from a specific URL.
- **Weather**: Get the current weather for any location using OpenWeather&#039;s API.
- **Programming**: Run code snippets in multiple languages using E2B&#039;s API.
- **Maps**: Get the location of any place using Google Maps API, Mapbox API, and TripAdvisor API.
- **YouTube Search**: Search for videos on YouTube and get timestamps and transcripts [powered by Exa.AI - the Web Search API](https://exa.ai/).
- **Academic Search**: Search for academic papers [powered by Exa.AI - the Web Search API](https://exa.ai/). 
- **X Posts Search**: Search for posts on X.com [powered by Exa.AI - the Web Search API](https://exa.ai/).
- **Flight Tracker**: Track flights using AviationStack&#039;s API.
- **Trending Movies and TV Shows**: Get information about trending movies and TV shows.
- **Movie or TV Show Search**: Get information about any movie or TV show.

## LLM used
- [xAI&#039;s Grok](https://x.ai/grok)
- [Anthropic&#039;s Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet)
- [Meta&#039;s Llama 3.3 70B by Cerebras](https://inference-docs.cerebras.ai/introduction)
- [Deepseek R1 Distill by Groq Inc](https://console.groq.com/docs/model/deepseek-r1-distill-llama-70b)

## Built with
- [Next.js](https://nextjs.org/)
- [Tailwind CSS](https://tailwindcss.com/)
- [Vercel AI SDK](https://sdk.vercel.ai/docs)
- [Shadcn/UI](https://ui.shadcn.com/)
- [Exa.AI](https://exa.ai/)
- [Tavily](https://tavily.com/)
- [OpenWeather](https://openweathermap.org/)
- [E2B](https://e2b.dev/)
- [Google Maps](https://developers.google.com/maps)
- [Mapbox](https://www.mapbox.com/)
- [TripAdvisor](https://www.tripadvisor.com/)
- [AviationStack](https://aviationstack.com/)

### Deploy your own

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fzaidmukaddam%2Fscira&amp;env=XAI_API_KEY,OPENAI_API_KEY,GROQ_API_KEY,E2B_API_KEY,ELEVENLABS_API_KEY,TAVILY_API_KEY,EXA_API_KEY,TMDB_API_KEY,YT_ENDPOINT,FIRECRAWL_API_KEY,OPENWEATHER_API_KEY,SANDBOX_TEMPLATE_ID,GOOGLE_MAPS_API_KEY,MAPBOX_ACCESS_TOKEN,TRIPADVISOR_API_KEY,AVIATION_STACK_API_KEY,CRON_SECRET,BLOB_READ_WRITE_TOKEN,NEXT_PUBLIC_MAPBOX_TOKEN,NEXT_PUBLIC_POSTHOG_KEY,NEXT_PUBLIC_POSTHOG_HOST,NEXT_PUBLIC_GOOGLE_MAPS_API_KEY,MEM0_API_KEY,MEM0_ORG_ID,MEM0_PROJECT_ID,SMITHERY_API_KEY&amp;envDescription=API%20keys%20and%20configuration%20required%20for%20Scira%20to%20function%20(including%20SMITHERY_API_KEY))

## Set Scira as your default search engine

1. **Open the Chrome browser settings**:
   - Click on the three vertical dots in the upper right corner of the browser.
   - Select &quot;Settings&quot; from the dropdown menu.

2. **Go to the search engine settings**:
   - In the left sidebar, click on &quot;Search engine.&quot;
   - Then select &quot;Manage search engines and site search.&quot;

3. **Add a new search engine**:
   - Click on &quot;Add&quot; next to &quot;Site search.&quot;

4. **Set the search engine name**:
   - Enter `Scira` in the &quot;Search engine&quot; field.

5. **Set the search engine URL**:
   - Enter `https://scira.ai?q=%s` in the &quot;URL with %s in place of query&quot; field.

6. **Set the search engine shortcut**:
   - Enter `sh` in the &quot;Shortcut&quot; field.

7. **Set Default**:
   - Click on the three dots next to the search engine you just added.
   - Select &quot;Make default&quot; from the dropdown menu.

After completing these steps, you should be able to use Scira as your default search engine in Chrome.

### Local development

#### Run via Docker

The application can be run using Docker in two ways:

##### Using Docker Compose (Recommended)

1. Make sure you have Docker and Docker Compose installed on your system
2. Create a `.env` file based on `.env.example` with your API keys
3. Run the following command in the project root:
   ```bash
   docker compose up
   ```
4. The application will be available at `http://localhost:3000`

##### Using Docker Directly

1. Create a `.env` file based on `.env.example` with your API keys
2. Build the Docker image:
   ```bash
   docker build -t scira.app .
   ```
3. Run the container:
   ```bash
   docker run --env-file .env -p 3000:3000 scira.app
   ```

The application uses a multi-stage build process to minimize the final image size and implements security best practices. The production image runs on Node.js LTS with Alpine Linux for a minimal footprint.

#### Run with Node.js

To run the application locally without Docker:

1. Sign up for accounts with the required AI providers:
   - OpenAI (required)
   - Anthropic (required)
   - Tavily (required for web search feature)
2. Copy `.env.example` to `.env.local` and fill in your API keys
3. Install dependencies:
   ```bash
   pnpm install
   ```
4. Start the development server:
   ```bash
   pnpm dev
   ```
5. Open `http://localhost:3000` in your browser

# License

This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[dataelement/bisheng]]></title>
            <link>https://github.com/dataelement/bisheng</link>
            <guid>https://github.com/dataelement/bisheng</guid>
            <pubDate>Thu, 15 May 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[BISHENG is an open LLM devops platform for next generation Enterprise AI applications. Powerful and comprehensive features include: GenAI workflow, RAG, Agent, Unified model management, Evaluation, SFT, Dataset Management, Enterprise-level System Management, Observability and more.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dataelement/bisheng">dataelement/bisheng</a></h1>
            <p>BISHENG is an open LLM devops platform for next generation Enterprise AI applications. Powerful and comprehensive features include: GenAI workflow, RAG, Agent, Unified model management, Evaluation, SFT, Dataset Management, Enterprise-level System Management, Observability and more.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 8,440</p>
            <p>Forks: 1,392</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>**Proudly made by Chinese，May we, like the creators of Deepseek and Black Myth: Wukong, bring more wonder and greatness to the world.**

&gt; 源自中国匠心，希望我们能像 [Deepseek]、[黑神话：悟空] 团队一样，给世界带来更多美好。

&lt;img src=&quot;https://dataelem.com/bs/face.png&quot; alt=&quot;Bisheng banner&quot;&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://dataelem.feishu.cn/wiki/ZxW6wZyAJicX4WkG0NqcWsbynde&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/docs-Wiki-brightgreen&quot;&gt;&lt;/a&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/dataelement/bisheng&quot; alt=&quot;license&quot;/&gt;
    &lt;a href=&quot;&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/last-commit/dataelement/bisheng&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://star-history.com/#dataelement/bisheng&amp;Timeline&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/dataelement/bisheng?color=yellow&quot;&gt;&lt;/a&gt; 
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README_CN.md&quot;&gt;简体中文&lt;/a&gt; |
  &lt;a href=&quot;./README.md&quot;&gt;English&lt;/a&gt; |
  &lt;a href=&quot;./README_JPN.md&quot;&gt;日本語&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/717&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/717&quot; alt=&quot;dataelement%2Fbisheng | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;div class=&quot;column&quot; align=&quot;middle&quot;&gt;
  &lt;!-- &lt;a href=&quot;https://bisheng.slack.com/join/shared_invite/&quot;&gt; --&gt;
    &lt;!-- &lt;img src=&quot;https://img.shields.io/badge/Join-Slack-orange&quot; alt=&quot;join-slack&quot;/&gt; --&gt;
  &lt;/a&gt;
  &lt;!-- &lt;img src=&quot;https://img.shields.io/github/license/bisheng-io/bisheng&quot; alt=&quot;license&quot;/&gt; --&gt;
  &lt;!-- &lt;img src=&quot;https://img.shields.io/docker/pulls/bisheng-io/bisheng&quot; alt=&quot;docker-pull-count&quot; /&gt; --&gt;
&lt;/div&gt;


BISHENG is an open LLM application devops platform, focusing on enterprise scenarios. It has been used by a large number of industry leading organizations and Fortune 500 companies.

&quot;Bi Sheng&quot; was the inventor of movable type printing, which played a vital role in promoting the transmission of human knowledge. We hope that BISHENG can also provide strong support for the widespread implementation of intelligent applications. Everyone is welcome to participate.


## Features 
1. Unique [BISHENG Workflow](https://dataelem.feishu.cn/wiki/R7HZwH5ZGiJUDrkHZXicA9pInif)
   - 🧩 **Independent and comprehensive application orchestration framework**: Enables the execution of various tasks within a single framework (while similar products rely on bot invocation or separate chatflow and workflow modules for different tasks).
   - 🔄 **Human in the loop**: Allows users to intervene and provide feedback during the execution of workflows (including multi-turn conversations), whereas similar products can only execute workflows from start to finish without intervention.
   - 💥 **Powerful**: Supports loops, parallelism, batch processing, conditional logic, and free combination of all logic components. It also handles complex scenarios such as multi-type input/output, report generation, content review, and more.
   - 🖐️ **User-friendly and intuitive**: Operations like loops, parallelism, and batch processing, which require specialized components in similar products, can be easily visualized in BISHENG as a &quot;flowchart&quot; (drawing a loop forms a loop, aligning elements creates parallelism, and selecting multiple items enables batch processing).
   &lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://dataelem.com/bs/bisheng_workflow.png&quot; alt=&quot;sence0&quot;&gt;&lt;/p&gt;

2. &lt;b&gt;Designed for Enterprise Applications&lt;/b&gt;: Document review, fixed-layout report generation, multi-agent collaboration, policy update comparison, support ticket assistance, customer service assistance, meeting minutes generation, resume screening, call record analysis, unstructured data governance, knowledge mining, data analysis, and more. 

​	The platform supports the construction of &lt;b&gt;highly complex enterprise application scenarios&lt;/b&gt; and offers &lt;b&gt;deep optimization&lt;/b&gt; 	with hundreds of components and thousands of parameters.
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://dataelem.com/bs/chat.png&quot; alt=&quot;sence1&quot;&gt;&lt;/p&gt;

3. &lt;b&gt;Enterprise-grade&lt;/b&gt; features are the fundamental guarantee for application implementation: security review, RBAC, user group management, traffic control by group, SSO/LDAP, vulnerability scanning and patching, high availability deployment solutions, monitoring, statistics, and more.
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://dataelem.com/bs/pro.png&quot; alt=&quot;sence2&quot;&gt;&lt;/p&gt;

4. &lt;b&gt;High-Precision Document Parsing&lt;/b&gt;: Our high-precision document parsing model is trained on a vast amount of high-quality data accumulated over past 5 years. It includes high-precision printed text, handwritten text, and rare character recognition models, table recognition models, layout analysis models, and seal models., table recognition models, layout analysis models, and seal models. You can deploy it privately for free.
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://dataelem.com/bs/ocr.png&quot; alt=&quot;sence3&quot;&gt;&lt;/p&gt;

5. A community for sharing best practices across various enterprise scenarios: An open repository of application cases and best practices.
## Quick start 

Please ensure the following conditions are met before installing BISHENG:
- CPU &gt;= 4 Virtual Cores
- RAM &gt;= 16 GB
- Docker 19.03.9+
- Docker Compose 1.25.1+
&gt; Recommended hardware condition: 18 virtual cores, 48G. In addition to installing BISHENG, we will also install the following third-party components by default: ES, Milvus, and Onlyoffice.

Download BISHENG
```bash
git clone https://github.com/dataelement/bisheng.git
# Enter the installation directory
cd bisheng/docker

# If the system does not have the git command, you can download the BISHENG code as a zip file.
wget https://github.com/dataelement/bisheng/archive/refs/heads/main.zip
# Unzip and enter the installation directory
unzip main.zip &amp;&amp; cd bisheng-main/docker
```
Start BISHENG
```bash
docker-compose up -d
```
After the startup is complete, access http://IP:3001 in the browser. The login page will appear, proceed with user registration. 

By default, the first registered user will become the system admin. 

For more installation and deployment issues, refer to:：[Self-hosting](https://dataelem.feishu.cn/wiki/BSCcwKd4Yiot3IkOEC8cxGW7nPc)

## Acknowledgement 
This repo benefits from [langchain](https://github.com/langchain-ai/langchain) [langflow](https://github.com/logspace-ai/langflow) [unstructured](https://github.com/Unstructured-IO/unstructured) and [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) . Thanks for their wonderful works.

&lt;b&gt;Thank you to our contributors：&lt;/b&gt;

&lt;a href=&quot;https://github.com/dataelement/bisheng/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=dataelement/bisheng&quot; /&gt;
&lt;/a&gt;



## Community &amp; contact 
Welcome to join our discussion group

&lt;img src=&quot;https://www.dataelem.com/nstatic/qrcode.png&quot; alt=&quot;Wechat QR Code&quot;&gt;


&lt;!--
## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=dataelement/bisheng&amp;type=Date)](https://star-history.com/#dataelement/bisheng&amp;Date)
--&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[GrapesJS/grapesjs]]></title>
            <link>https://github.com/GrapesJS/grapesjs</link>
            <guid>https://github.com/GrapesJS/grapesjs</guid>
            <pubDate>Thu, 15 May 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[Free and Open source Web Builder Framework. Next generation tool for building templates without coding]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GrapesJS/grapesjs">GrapesJS/grapesjs</a></h1>
            <p>Free and Open source Web Builder Framework. Next generation tool for building templates without coding</p>
            <p>Language: TypeScript</p>
            <p>Stars: 24,161</p>
            <p>Forks: 4,323</p>
            <p>Stars today: 31 stars today</p>
            <h2>README</h2><pre># [GrapesJS](http://grapesjs.com)

[![Build Status](https://github.com/GrapesJS/grapesjs/actions/workflows/build.yml/badge.svg)](https://github.com/GrapesJS/grapesjs/actions)
[![Chat](https://img.shields.io/badge/chat-discord-7289da.svg)](https://discord.gg/QAbgGXq)
[![CDNJS](https://img.shields.io/cdnjs/v/grapesjs.svg)](https://cdnjs.com/libraries/grapesjs)
[![npm](https://img.shields.io/npm/v/grapesjs.svg)](https://www.npmjs.com/package/grapesjs)


&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://grapesjs.com/assets/images/grapesjs-front-page-m.jpg&quot; alt=&quot;GrapesJS&quot; width=&quot;500&quot; align=&quot;center&quot;/&gt;&lt;/p&gt;


GrapesJS is a free and open source Web Builder Framework which helps building HTML templates, faster and easily, to be delivered in sites, newsletters or mobile apps. Mainly, GrapesJS was designed to be used inside a [CMS] to speed up the creation of dynamic templates. To better understand this concept check the image below

&lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://grapesjs.com/assets/images/gjs-concept.png&quot; alt=&quot;GrapesJS - Style Manager&quot; height=&quot;400&quot; align=&quot;center&quot;/&gt;&lt;/p&gt;
&lt;br/&gt;

Generally any &#039;template system&#039;, that you&#039;d find in various applications like CMS, is composed by the **structure** (HTML), **style** (CSS) and **variables**, which are then replaced with other templates and contents on server-side and rendered on client.

This demos show examples of what is possible to achieve:&lt;br/&gt;
Webpage Demo - http://grapesjs.com/demo.html&lt;br/&gt;
Newsletter Demo - http://grapesjs.com/demo-newsletter-editor.html&lt;br/&gt;





## Table of contents

* [Features](#features)
* [Download](#download)
* [Usage](#usage)
* [Development](#development)
* [Documentation](#documentation)
* [API](#api)
* [Testing](#testing)
* [Plugins](#plugins)
* [Support](#support)
* [Changelog](https://github.com/GrapesJS/grapesjs/releases)
* [Contributing](https://github.com/GrapesJS/grapesjs/blob/master/CONTRIBUTING.md)
* [License](#license)




## Features

| Blocks | Style Manager | Layer Manager |
|--|--|--|
|&lt;img  src=&quot;http://grapesjs.com/assets/images/sc-grapesjs-blocks-prp.jpg&quot;  alt=&quot;GrapesJS - Block Manager&quot;  height=&quot;400&quot;  align=&quot;center&quot;/&gt;|&lt;img  src=&quot;http://grapesjs.com/assets/images/sc-grapesjs-style-2.jpg&quot;  alt=&quot;GrapesJS - Style Manager&quot;  height=&quot;400&quot;  align=&quot;center&quot;/&gt;|&lt;img  src=&quot;http://grapesjs.com/assets/images/sc-grapesjs-layers-2.jpg&quot;  alt=&quot;GrapesJS - Layer Manager&quot;  height=&quot;400&quot;  align=&quot;center&quot;/&gt;|

| Code Viewer | Asset Manager |
|--|--|
|&lt;img  src=&quot;http://grapesjs.com/assets/images/sc-grapesjs-code.jpg&quot;  alt=&quot;GrapesJS - Code Viewer&quot;  height=&quot;300&quot;  align=&quot;center&quot;/&gt;|&lt;img  src=&quot;http://grapesjs.com/assets/images/sc-grapesjs-assets-1.jpg&quot;  alt=&quot;GrapesJS - Asset Manager&quot;  height=&quot;250&quot;  align=&quot;center&quot;/&gt;|

* Local and remote storage

* Default built-in commands (basically for creating and managing different components)





## Download

* CDNs
  * UNPKG (resolves to the latest version)
    * `https://unpkg.com/grapesjs`
    * `https://unpkg.com/grapesjs/dist/css/grapes.min.css`
  * CDNJS (replace `X.X.X` with the current version)
    * `https://cdnjs.cloudflare.com/ajax/libs/grapesjs/X.X.X/grapes.min.js`
    * `https://cdnjs.cloudflare.com/ajax/libs/grapesjs/X.X.X/css/grapes.min.css`
* NPM
  * `npm i grapesjs`
* GIT
  * `git clone https://github.com/GrapesJS/grapesjs.git`

For the development purpose you should follow instructions below.





## Usage

```html
&lt;link rel=&quot;stylesheet&quot; href=&quot;path/to/grapes.min.css&quot;&gt;
&lt;script src=&quot;path/to/grapes.min.js&quot;&gt;&lt;/script&gt;

&lt;div id=&quot;gjs&quot;&gt;&lt;/div&gt;

&lt;script type=&quot;text/javascript&quot;&gt;
  var editor = grapesjs.init({
      container : &#039;#gjs&#039;,
      components: &#039;&lt;div class=&quot;txt-red&quot;&gt;Hello world!&lt;/div&gt;&#039;,
      style: &#039;.txt-red{color: red}&#039;,
  });
&lt;/script&gt;
```

For a more practical example I&#039;d suggest looking up the code inside this demo: http://grapesjs.com/demo.html


## Development

Clone the repository and install all the necessary dependencies (`yarn` is highly recommended)

```sh
$ git clone https://github.com/GrapesJS/grapesjs.git
$ cd grapesjs
$ yarn
```

Start the dev server

```sh
$ yarn start
```

Once the development server is started you should be able to reach the demo page (eg. `http://localhost:8080`)





## Documentation

Check the getting started guide here: [Documentation]





## API

API References could be found here: [API-Reference]





## Testing

```sh
$ yarn test
```





## Plugins

[Official Plugins](https://github.com/orgs/GrapesJS/repositories?q=-repo%3Agrapesjs%2Fgrapesjs&amp;type=source) | [Community Plugins](https://github.com/topics/grapesjs-plugin)

### Wrappers

* [@grapesjs/react](https://github.com/GrapesJS/react) - GrapesJS wrapper for React that allows you to build custom and declarative UI for your editor.



### Extensions
* [grapesjs-plugin-export](https://github.com/GrapesJS/export) - Export GrapesJS templates in a zip archive
* [grapesjs-plugin-filestack](https://github.com/GrapesJS/filestack) - Add Filestack uploader in Asset Manager
* [grapesjs-plugin-ckeditor](https://github.com/GrapesJS/ckeditor) - Replaces the built-in RTE with CKEditor
* [grapesjs-tui-image-editor](https://github.com/GrapesJS/tui-image-editor) - GrapesJS TOAST UI Image Editor
* [grapesjs-blocks-basic](https://github.com/GrapesJS/blocks-basic) - Basic set of blocks
* [grapesjs-plugin-forms](https://github.com/GrapesJS/components-forms) - Set of form components and blocks
* [grapesjs-navbar](https://github.com/GrapesJS/components-navbar) - Simple navbar component
* [grapesjs-component-countdown](https://github.com/GrapesJS/components-countdown) - Simple countdown component
* [grapesjs-style-gradient](https://github.com/GrapesJS/style-gradient) - Add `gradient` type input to the Style Manager
* [grapesjs-style-filter](https://github.com/GrapesJS/style-filter) - Add `filter` type input to the Style Manager
* [grapesjs-style-bg](https://github.com/GrapesJS/style-bg) - Full-stack background style property type, with the possibility to add images, colors, and gradients
* [grapesjs-blocks-flexbox](https://github.com/GrapesJS/blocks-flexbox) - Add the flexbox block
* [grapesjs-lory-slider](https://github.com/GrapesJS/components-lory) - Slider component by using [lory](https://github.com/meandmax/lory)
* [grapesjs-tabs](https://github.com/GrapesJS/components-tabs) - Simple tabs component
* [grapesjs-tooltip](https://github.com/GrapesJS/components-tooltip) - Simple, CSS only, tooltip component for GrapesJS
* [grapesjs-custom-code](https://github.com/GrapesJS/components-custom-code) - Embed custom code
* [grapesjs-touch](https://github.com/GrapesJS/touch) - Enable touch support
* [grapesjs-indexeddb](https://github.com/GrapesJS/storage-indexeddb) - Storage wrapper for IndexedDB
* [grapesjs-firestore](https://github.com/GrapesJS/storage-firestore) - Storage wrapper for [Cloud Firestore](https://firebase.google.com/docs/firestore)
* [grapesjs-parser-postcss](https://github.com/GrapesJS/parser-postcss) - Custom CSS parser for GrapesJS by using [PostCSS](https://github.com/postcss/postcss)
* [grapesjs-typed](https://github.com/GrapesJS/components-typed) - Typed component made by wrapping Typed.js library
* [grapesjs-ui-suggest-classes](https://github.com/silexlabs/grapesjs-ui-suggest-classes) - Enable auto-complete of classes in the SelectorManager UI
* [grapesjs-fonts](https://github.com/silexlabs/grapesjs-fonts) - Custom Fonts plugin, adds a UI to manage fonts in websites
* [grapesjs-symbols](https://github.com/silexlabs/grapesjs-symbols) - Symbols plugin to reuse elements in a website and accross pages
* [grapesjs-click](https://github.com/bgrand-ch/grapesjs-click) - Grab and drop blocks and components with click (no more drag-and-drop)
* [grapesjs-float](https://github.com/bgrand-ch/grapesjs-float) - Anchor a floating element next to another element (selected component, ...)

### Presets
* [grapesjs-preset-webpage](https://github.com/GrapesJS/preset-webpage) - Webpage Builder
* [grapesjs-preset-newsletter](https://github.com/GrapesJS/preset-newsletter) - Newsletter Builder
* [grapesjs-mjml](https://github.com/GrapesJS/mjml) - Newsletter Builder with MJML components


Find out more about plugins here: [Creating plugins](https://grapesjs.com/docs/modules/Plugins.html)





## Support

If you like the project and you wish to see it grow, please consider supporting us with a donation of your choice or become a backer/sponsor via [Open Collective](https://opencollective.com/grapesjs)

[![PayPalMe](http://grapesjs.com/assets/images/ppme.png)](https://paypal.me/grapesjs)
[![Bitcoin](https://user-images.githubusercontent.com/11614725/52977952-87235f80-33cf-11e9-9607-7a9a354e1155.png)](https://commerce.coinbase.com/checkout/fc90b940-558d-408b-a166-28a823c98173)

&lt;a href=&quot;https://opencollective.com/grapesjs&quot;&gt;&lt;img src=&quot;https://opencollective.com/grapesjs/tiers/sponsors.svg?avatarHeight=64&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/grapesjs&quot;&gt;&lt;img src=&quot;https://opencollective.com/grapesjs/tiers/backers.svg?avatarHeight=64&quot;&gt;&lt;/a&gt;

&lt;br&gt;

[![BrowserStack](https://user-images.githubusercontent.com/11614725/39406324-4ef89c40-4bb5-11e8-809a-113d9432e5a5.png)](https://www.browserstack.com)&lt;br/&gt;
Thanks to [BrowserStack](https://www.browserstack.com) for providing us browser testing services


## License

BSD 3-clause


[Documentation]: &lt;https://grapesjs.com/docs/&gt;
[API-Reference]: &lt;https://grapesjs.com/docs/api/&gt;
[CMS]: &lt;https://en.wikipedia.org/wiki/Content_management_system&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[oslook/cursor-ai-downloads]]></title>
            <link>https://github.com/oslook/cursor-ai-downloads</link>
            <guid>https://github.com/oslook/cursor-ai-downloads</guid>
            <pubDate>Thu, 15 May 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[All Cursor AI's official download links for both the latest and older versions, making it easy for you to update, downgrade, and choose any version. 🚀]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oslook/cursor-ai-downloads">oslook/cursor-ai-downloads</a></h1>
            <p>All Cursor AI's official download links for both the latest and older versions, making it easy for you to update, downgrade, and choose any version. 🚀</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,267</p>
            <p>Forks: 114</p>
            <p>Stars today: 57 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;right&quot;&gt;
   &lt;a href=&quot;https://www.buymeacoffee.com/oslook&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.buymeacoffee.com/button-api/?text=buy me a coffee&amp;emoji=☕&amp;slug=oslook&amp;button_colour=ffda33&amp;font_colour=000000&amp;font_family=Bree&amp;outline_colour=000000&amp;coffee_colour=FFDD00&amp;latest=2&quot; width=&quot;160&quot; alt=&quot;Buy Me a Coffee&quot;/&gt;
   &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://mintlify.s3-us-west-1.amazonaws.com/cursor/images/logo/app-logo.svg&quot; alt=&quot;Cursor Icon&quot; width=&quot;100&quot;/&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Cursor AI&#039;s Official Download Links&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;The most comprehensive official download link for Cursor AI versions on GitHub, making it easy for you to update and choose any version. 🚀&lt;/strong&gt;&lt;/p&gt;


&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://buymeacoffee.com/oslook&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Buy Me a Coffee&quot; src=&quot;https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Support%20Me-FFDA33&quot;&gt;&lt;/a&gt;
  &lt;img alt=&quot;Linux-Installer&quot; src=&quot;https://img.shields.io/badge/Linux-Installer-E95620&quot;&gt;
  &lt;img alt=&quot;MacOS-Installer&quot; src=&quot;https://img.shields.io/badge/MacOS-Installer-E95620&quot;&gt;
  &lt;img alt=&quot;Windows-Installer&quot; src=&quot;https://img.shields.io/badge/Windows-Installer-E95620&quot;&gt;
  &lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/License-MIT-blueviolet&quot;&gt;
&lt;/p&gt;

⭐️ Your star shines on us. Star us on GitHub!

🔍 head over to [&gt;&gt; Cursor Download Hub &lt;&lt;](https://cursor.uuid.site) perform a quick search version history.

&lt;a href=&quot;https://cursor.uuid.site&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Cursor Download Hub&quot; src=&quot;https://img.shields.io/badge/Cursor%20Download%20Hub-FFDA33?logo=searxng&amp;style=for-the-badge&amp;logoColor=red&quot;&gt;&lt;/a&gt;
---

## 📖 Table of Contents

- [❓ What is Cursor?](#what-is-cursor)
- [🔮 Why list the download links?](#why-list-the-download-links)
- [🚀 Cursor AI&#039;s Changelog](#cursor-changelog)
- [⏬ Download Links for All Versions](#all-version-download-links)
- [📜 License](#-license)
- [☕ Support This Project](#support-this-project)

---

## What is Cursor?

Cursor is **[The AI Code Editor](https://cursor.com)**, Built to make you extraordinarily productive, Cursor is the best way to code with AI.

## Why list the download links?

The reason for maintaining a list of versions is that some older versions offer a better user experience, allowing users the freedom to choose. Since Cursor AI automatically upgrades to the latest version, we provide official download links for the older versions.

To meet different user needs, we offer:

1. Who Want the Latest or Preview Features
   
Access the newest preview version to try out upcoming features before they&#039;re officially released to website.
  
2. Who Prefer Stable Versions
   
Use the official download links to access any older, stable version you prefer.

## Cursor Changelog

Please refer to the [Official Link](https://www.cursor.com/changelog)

### Key Features

List some key features and the versions they were introduced in for reference when considering rollback or downgrade.

1. Deepseek R1 and Deepseek v3 models supported (0.44.x ~)
&gt; You can enable them in Settings &gt; Models. Cursor team self-host these models in the US.

2. Integrate Claude 3.7 Sonnet (0.46.0 ~)
&gt; try to add `claude-3.7-sonnet-thinking` and `claude-3-7-sonnet-20250219` should work now.

## All Version Download Links

&gt; ⚠️ Security Notice
&gt;  - ✅ All links published by the Cursor team. no changes have been made.
&gt;  - ❗ Verify the domain before downloading. All downloads are hosted at: `https://downloads.cursor.com`
&gt;  - 💾 Backup your work before upgrade/downgrade if you’re concerned about changes.
&gt;  - Free &amp; free trial accounts can no longer use chat with premium models on Cursor Version 0.45 or less. Please upgrade to Pro or use Cursor Version 0.46 or later.

| Version | Date | Mac Installer | Windows Installer | Linux Installer |
| --- | --- | --- | --- | --- |
| 0.50.4 | 2025-05-14 | [darwin-universal](https://downloads.cursor.com/production/8ea935e79a50a02da912a034bbeda84a6d3d355d/darwin/universal/Cursor-darwin-universal.dmg) &lt;br&gt;[darwin-x64](https://downloads.cursor.com/production/8ea935e79a50a02da912a034bbeda84a6d3d355d/darwin/x64/Cursor-darwin-x64.dmg) &lt;br&gt;[darwin-arm64](https://downloads.cursor.com/production/8ea935e79a50a02da912a034bbeda84a6d3d355d/darwin/arm64/Cursor-darwin-arm64.dmg) | [win32-x64-user](https://downloads.cursor.com/production/8ea935e79a50a02da912a034bbeda84a6d3d355d/win32/x64/user-setup/CursorUserSetup-x64-0.50.4.exe)&lt;br&gt;[win32-arm64-user](https://downloads.cursor.com/production/8ea935e79a50a02da912a034bbeda84a6d3d355d/win32/arm64/user-setup/CursorUserSetup-arm64-0.50.4.exe)&lt;br&gt;[win32-x64-system](https://downloads.cursor.com/production/8ea935e79a50a02da912a034bbeda84a6d3d355d/win32/x64/system-setup/CursorSetup-x64-0.50.4.exe)&lt;br&gt;[win32-arm64-system](https://downloads.cursor.com/production/8ea935e79a50a02da912a034bbeda84a6d3d355d/win32/arm64/system-setup/CursorSetup-arm64-0.50.4.exe) | [linux-x64](https://downloads.cursor.com/production/8ea935e79a50a02da912a034bbeda84a6d3d355d/linux/x64/Cursor-0.50.4-x86_64.AppImage)&lt;br&gt;[linux-arm64](https://downloads.cursor.com/production/8ea935e79a50a02da912a034bbeda84a6d3d355d/linux/arm64/Cursor-0.50.4-aarch64.AppImage) |
| 0.50.3 | 2025-05-13 | [darwin-universal](https://downloads.cursor.com/production/7ae22cf8cd5af9e08b62585dd03d10f5f610acf9/darwin/universal/Cursor-darwin-universal.dmg) &lt;br&gt;[darwin-x64](https://downloads.cursor.com/production/7ae22cf8cd5af9e08b62585dd03d10f5f610acf9/darwin/x64/Cursor-darwin-x64.dmg) &lt;br&gt;[darwin-arm64](https://downloads.cursor.com/production/7ae22cf8cd5af9e08b62585dd03d10f5f610acf9/darwin/arm64/Cursor-darwin-arm64.dmg) | [win32-x64-user](https://downloads.cursor.com/production/7ae22cf8cd5af9e08b62585dd03d10f5f610acf9/win32/x64/user-setup/CursorUserSetup-x64-0.50.3.exe)&lt;br&gt;[win32-arm64-user](https://downloads.cursor.com/production/7ae22cf8cd5af9e08b62585dd03d10f5f610acf9/win32/arm64/user-setup/CursorUserSetup-arm64-0.50.3.exe)&lt;br&gt;[win32-x64-system](https://downloads.cursor.com/production/7ae22cf8cd5af9e08b62585dd03d10f5f610acf9/win32/x64/system-setup/CursorSetup-x64-0.50.3.exe)&lt;br&gt;[win32-arm64-system](https://downloads.cursor.com/production/7ae22cf8cd5af9e08b62585dd03d10f5f610acf9/win32/arm64/system-setup/CursorSetup-arm64-0.50.3.exe) | [linux-x64](https://downloads.cursor.com/production/7ae22cf8cd5af9e08b62585dd03d10f5f610acf9/linux/x64/Cursor-0.50.3-x86_64.AppImage)&lt;br&gt;[linux-arm64](https://downloads.cursor.com/production/7ae22cf8cd5af9e08b62585dd03d10f5f610acf9/linux/arm64/Cursor-0.50.3-aarch64.AppImage) |
| 0.50.2 | 2025-05-13 | [darwin-universal](https://downloads.cursor.com/production/fc3e38722d374aeba23729a31220a4f0662e3c9b/darwin/universal/Cursor-darwin-universal.dmg) &lt;br&gt;[darwin-x64](https://downloads.cursor.com/production/fc3e38722d374aeba23729a31220a4f0662e3c9b/darwin/x64/Cursor-darwin-x64.dmg) &lt;br&gt;[darwin-arm64](https://downloads.cursor.com/production/fc3e38722d374aeba23729a31220a4f0662e3c9b/darwin/arm64/Cursor-darwin-arm64.dmg) | [win32-x64-user](https://downloads.cursor.com/production/fc3e38722d374aeba23729a31220a4f0662e3c9b/win32/x64/user-setup/CursorUserSetup-x64-0.50.2.exe)&lt;br&gt;[win32-arm64-user](https://downloads.cursor.com/production/fc3e38722d374aeba23729a31220a4f0662e3c9b/win32/arm64/user-setup/CursorUserSetup-arm64-0.50.2.exe)&lt;br&gt;[win32-x64-system](https://downloads.cursor.com/production/fc3e38722d374aeba23729a31220a4f0662e3c9b/win32/x64/system-setup/CursorSetup-x64-0.50.2.exe)&lt;br&gt;[win32-arm64-system](https://downloads.cursor.com/production/fc3e38722d374aeba23729a31220a4f0662e3c9b/win32/arm64/system-setup/CursorSetup-arm64-0.50.2.exe) | [linux-x64](https://downloads.cursor.com/production/fc3e38722d374aeba23729a31220a4f0662e3c9b/linux/x64/Cursor-0.50.2-x86_64.AppImage)&lt;br&gt;[linux-arm64](https://downloads.cursor.com/production/fc3e38722d374aeba23729a31220a4f0662e3c9b/linux/arm64/Cursor-0.50.2-aarch64.AppImage) |
| 0.50.1 | 2025-05-11 | [darwin-universal](https://downloads.cursor.com/production/81bf18c2ba01d6e7e886875bdb6d1d04ac31c1f7/darwin/universal/Cursor-darwin-universal.dmg) &lt;br&gt;[darwin-x64](https://downloads.cursor.com/production/81bf18c2ba01d6e7e886875bdb6d1d04ac31c1f7/darwin/x64/Cursor-darwin-x64.dmg) &lt;br&gt;[darwin-arm64](https://downloads.cursor.com/production/81bf18c2ba01d6e7e886875bdb6d1d04ac31c1f7/darwin/arm64/Cursor-darwin-arm64.dmg) | [win32-x64-user](https://downloads.cursor.com/production/81bf18c2ba01d6e7e886875bdb6d1d04ac31c1f7/win32/x64/user-setup/CursorUserSetup-x64-0.50.1.exe)&lt;br&gt;[win32-arm64-user](https://downloads.cursor.com/production/81bf18c2ba01d6e7e886875bdb6d1d04ac31c1f7/win32/arm64/user-setup/CursorUserSetup-arm64-0.50.1.exe)&lt;br&gt;[win32-x64-system](https://downloads.cursor.com/production/81bf18c2ba01d6e7e886875bdb6d1d04ac31c1f7/win32/x64/system-setup/CursorSetup-x64-0.50.1.exe)&lt;br&gt;[win32-arm64-system](https://downloads.cursor.com/production/81bf18c2ba01d6e7e886875bdb6d1d04ac31c1f7/win32/arm64/system-setup/CursorSetup-arm64-0.50.1.exe) | [linux-x64](https://downloads.cursor.com/production/81bf18c2ba01d6e7e886875bdb6d1d04ac31c1f7/linux/x64/Cursor-0.50.1-x86_64.AppImage)&lt;br&gt;[linux-arm64](https://downloads.cursor.com/production/81bf18c2ba01d6e7e886875bdb6d1d04ac31c1f7/linux/arm64/Cursor-0.50.1-aarch64.AppImage) |
| 0.50.0 | 2025-05-09 | [darwin-universal](https://downloads.cursor.com/production/bbfa51c1211255cbbde8b558e014a593f44051f4/darwin/universal/Cursor-darwin-universal.dmg) &lt;br&gt;[darwin-x64](https://downloads.cursor.com/production/bbfa51c1211255cbbde8b558e014a593f44051f4/darwin/x64/Cursor-darwin-x64.dmg) &lt;br&gt;[darwin-arm64](https://downloads.cursor.com/production/bbfa51c1211255cbbde8b558e014a593f44051f4/darwin/arm64/Cursor-darwin-arm64.dmg) | [win32-x64-user](https://downloads.cursor.com/production/bbfa51c1211255cbbde8b558e014a593f44051f4/win32/x64/user-setup/CursorUserSetup-x64-0.50.0.exe)&lt;br&gt;[win32-arm64-user](https://downloads.cursor.com/production/bbfa51c1211255cbbde8b558e014a593f44051f4/win32/arm64/user-setup/CursorUserSetup-arm64-0.50.0.exe)&lt;br&gt;[win32-x64-system](https://downloads.cursor.com/production/bbfa51c1211255cbbde8b558e014a593f44051f4/win32/x64/system-setup/CursorSetup-x64-0.50.0.exe)&lt;br&gt;[win32-arm64-system](https://downloads.cursor.com/production/bbfa51c1211255cbbde8b558e014a593f44051f4/win32/arm64/system-setup/CursorSetup-arm64-0.50.0.exe) | [linux-x64](https://downloads.cursor.com/production/bbfa51c1211255cbbde8b558e014a593f44051f4/linux/x64/Cursor-0.50.0-x86_64.AppImage)&lt;br&gt;[linux-arm64](https://downloads.cursor.com/production/bbfa51c1211255cbbde8b558e014a593f44051f4/linux/arm64/Cursor-0.50.0-aarch64.AppImage) |
| 0.49.6 | 2025-04-25 | [darwin-universal](https://downloads.cursor.com/production/0781e811de386a0c5bcb07ceb259df8ff8246a52/darwin/universal/Cursor-darwin-universal.dmg) &lt;br&gt;[darwin-x64](https://downloads.cursor.com/production/0781e811de386a0c5bcb07ceb259df8ff8246a52/darwin/x64/Cursor-darwin-x64.dmg) &lt;br&gt;[darwin-arm64](https://downloads.cursor.com/production/0781e811de386a0c5bcb07ceb259df8ff8246a52/darwin/arm64/Cursor-darwin-arm64.dmg) | [win32-x64-user](https://downloads.cursor.com/production/0781e811de386a0c5bcb07ceb259df8ff8246a52/win32/x64/user-setup/CursorUserSetup-x64-0.49.6.exe)&lt;br&gt;[win32-arm64-user](https://downloads.cursor.com/production/0781e811de386a0c5bcb07ceb259df8ff8246a52/win32/arm64/user-setup/CursorUserSetup-arm64-0.49.6.exe)&lt;br&gt;[win32-x64-system](https://downloads.cursor.com/production/0781e811de386a0c5bcb07ceb259df8ff8246a52/win32/x64/system-setup/CursorSetup-x64-0.49.6.exe)&lt;br&gt;[win32-arm64-system](https://downloads.cursor.com/production/0781e811de386a0c5bcb07ceb259df8ff8246a52/win32/arm64/system-setup/CursorSetup-arm64-0.49.6.exe) | [linux-x64](https://downloads.cursor.com/production/0781e811de386a0c5bcb07ceb259df8ff8246a52/linux/x64/Cursor-0.49.6-x86_64.AppImage)&lt;br&gt;[linux-arm64](https://downloads.cursor.com/production/0781e811de386a0c5bcb07ceb259df8ff8246a52/linux/arm64/Cursor-0.49.6-aarch64.AppImage) |
| 0.49.5 | 2025-04-24 | [darwin-universal](https://downloads.cursor.com/production/fd861c8a80c0f9e4e35294b1915ee8a7b29ae858/darwin/universal/Cursor-darwin-universal.dmg) &lt;br&gt;[darwin-x64](https://downloads.cursor.com/production/fd861c8a80c0f9e4e35294b1915ee8a7b29ae858/darwin/x64/Cursor-darwin-x64.dmg) &lt;br&gt;[darwin-arm64](https://downloads.cursor.com/production/fd861c8a80c0f9e4e35294b1915ee8a7b29ae858/darwin/arm64/Cursor-darwin-arm64.dmg) | [win32-x64-user](https://downloads.cursor.com/production/fd861c8a80c0f9e4e35294b1915ee8a7b29ae858/win32/x64/user-setup/CursorUserSetup-x64-0.49.5.exe)&lt;br&gt;[win32-arm64-user](https://downloads.cursor.com/production/fd861c8a80c0f9e4e35294b1915ee8a7b29ae858/win32/arm64/user-setup/CursorUserSetup-arm64-0.49.5.exe)&lt;br&gt;[win32-x64-system](https://downloads.cursor.com/production/fd861c8a80c0f9e4e35294b1915ee8a7b29ae858/win32/x64/system-setup/CursorSetup-x64-0.49.5.exe)&lt;br&gt;[win32-arm64-system](https://downloads.cursor.com/production/fd861c8a80c0f9e4e35294b1915ee8a7b29ae858/win32/arm64/system-setup/CursorSetup-arm64-0.49.5.exe) | [linux-x64](https://downloads.cursor.com/production/fd861c8a80c0f9e4e35294b1915ee8a7b29ae858/linux/x64/Cursor-0.49.5-x86_64.AppImage)&lt;br&gt;[linux-arm64](https://downloads.cursor.com/production/fd861c8a80c0f9e4e35294b1915ee8a7b29ae858/linux/arm64/Cursor-0.49.5-aarch64.AppImage) |
| 0.49.4 | 2025-04-22 | [darwin-universal](https://downloads.cursor.com/production/ec408037b24566b11e6132c58bbe6ad27046eb91/darwin/universal/Cursor-darwin-universal.dmg) &lt;br&gt;[darwin-x64](https://downloads.cursor.com/production/ec408037b24566b11e6132c58bbe6ad27046eb91/darwin/x64/Cursor-darwin-x64.dmg) &lt;br&gt;[darwin-arm64](https://downloads.cursor.com/production/ec408037b24566b11e6132c58bbe6ad27046eb91/darwin/arm64/Cursor-darwin-arm64.dmg) | [win32-x64-user](https://downloads.cursor.com/production/ec408037b24566b11e6132c58bbe6ad27046eb91/win32/x64/user-setup/CursorUserSetup-x64-0.49.4.exe)&lt;br&gt;[win32-arm64-user](https://downloads.cursor.com/production/ec408037b24566b11e6132c58bbe6ad27046eb91/win32/arm64/user-setup/CursorUserSetup-arm64-0.49.4.exe)&lt;br&gt;[win32-x64-system](https://downloads.cursor.com/production/ec408037b24566b11e6132c58bbe6ad27046eb91/win32/x64/system-setup/CursorSetup-x64-0.49.4.exe)&lt;br&gt;[win32-arm64-system](https://downloads.cursor.com/production/ec408037b24566b11e6132c58bbe6ad27046eb91/win32/arm64/system-setup/CursorSetup-arm64-0.49.4.exe) | [linux-x64](https://downloads.cursor.com/production/ec408037b24566b11e6132c58bbe6ad27046eb91/linux/x64/Cursor-0.49.4-x86_64.AppImage)&lt;br&gt;[linux-arm64](https://downloads.cursor.com/production/ec408037b24566b11e6132c58bbe6ad27046eb91/linux/arm64/Cursor-0.49.4-aarch64.AppImage) |
| 0.49.3 | 2025-04-21 | [darwin-universal](https://downloads.cursor.com/production/224bc1da1a36703c583d62e407d4bccbb8c6a641/darwin/universal/Cursor-darwin-universal.dmg) &lt;br&gt;[darwin-x64](https://downloads.cursor.com/production/224bc1da1a36703c583d62e407d4bccbb8c6a641/darwin/x64/Cursor-darwin-x64.dmg) &lt;br&gt;[darwin-arm64](https://downloads.cursor.com/production/224bc1da1a36703c583d62e407d4bccbb8c6a641/darwin/arm64/Cursor-darwin-arm64.dmg) | [win32-x64-user](https://downloads.cursor.com/production/224bc1da1a36703c583d62e407d4bccbb8c6a641/win32/x64/user-setup/CursorUserSetup-x64-0.49.3.exe)&lt;br&gt;[win32-arm64-user](https://downloads.cursor.com/production/224bc1da1a36703c583d62e407d4bccbb8c6a641/win32/arm64/user-setup/CursorUserSetup-arm64-0.49.3.exe)&lt;br&gt;[win32-x64-system](https://downloads.cursor.com/production/224bc1da1a36703c583d62e407d4bccbb8c6a641/win32/x64/system-setup/CursorSetup-x64-0.49.3.exe)&lt;br&gt;[win32-arm64-system](https://downloads.cursor.com/production/224bc1da1a36703c583d62e407d4bccbb8c6a641/win32/arm64/system-setup/CursorSetup-arm64-0.49.3.exe) | [linux-x64](https://downloads.cursor.com/production/224bc1da1a36703c583d62e407d4bccbb8c6a641/linux/x64/Cursor-0.49.3-x86_64.AppImage)&lt;br&gt;[linux-arm64](https://downloads.cursor.com/production/224bc1da1a36703c583d62e407d4bccbb8c6a641/linux/arm64/Cursor-0.49.3-aarch64.AppImage) |
| 0.49.2 | 2025-04-19 | [darwin-universal](https://downloads.cursor.com/production/1d0a7a3b734be5aea27e30d0c56d2a6e2c79da74/darwin/universal/Cursor-darwin-universal.dmg) &lt;br&gt;[darwin-x64](https://downloads.cursor.com/production/1d0a7a3b734be5aea27e30d0c56d2a6e2c79da74/darwin/x64/Cursor-darwin-x64.dmg) &lt;br&gt;[darwin-arm64](https://downloads.cursor.com/production/1d0a7a3b734be5aea27e30d0c56d2a6e2c79da74/darwin/arm64/Cursor-darwin-arm64.dmg) | [win32-x64-user](https://downloads.cursor.com/production/1d0a7a3b734be5aea27e30d0c56d2a6e2c79da74/win32/x64/user-setup/CursorUserSetup-x64-0.49.2.exe)&lt;br&gt;[win32-arm64-user](https://downloads.cursor.com/production/1d0a7a3b734be5aea27e30d0c56d2a6e2c79da74/win32/arm64/user-setup/CursorUserSetup-arm64-0.49.2.exe)&lt;br&gt;[win32-x64-system](https://downloads.cursor.com/production/1d0a7a3b734be5aea27e30d0c56d2a6e2c79da74/win32/x64/system-setup/CursorSetup-x64-0.49.2.exe)&lt;br&gt;[win32-arm64-system](https://downloads.cursor.com/production/1d0a7a3b734be5aea27e30d0c56d2a6e2c79da74/win32/arm64/system-setup/CursorSetup-arm64-0.49.2.exe) | [linux-x64](https://downloads.cursor.com/production/1d0a7a3b734be5aea27e30d0c56d2a6e2c79da74/linux/x64/Cursor-0.49.2-x86_64.AppImage)&lt;br&gt;[linux-arm64](https://downloads.cursor.com/production/1d0a7a3b734be5aea27e30d0c56d2a6e2c79da74/linux/arm64/Cursor-0.49.2-aarch64.AppImage) |
| 0.49.1 | 2025-04-17 | [darwin-universal](https://downloads.cursor.com/production/600e5c827c07c5818474c1056eeec61d478b407a/darwin/universal/Cursor-darwin-universal.dmg) &lt;br&gt;[darwin-x64](https://downloads.cursor.com/production/600e5c827c07c5818474c1056eeec61d478b407a/darwin/x64/Cursor-darwin-x64.dmg) &lt;br&gt;[darwin-arm64](https://downloads.cursor.com/production/600e5c827c07c5818474c1056eeec61d478b407a/darwin/arm64/Cursor-darwin-arm64.dmg) | [win32-x64-user](https://downloads.cursor.com/production/600e5c827c07c5818474c1056eeec61d478b407a/win32/x64/user-setup/CursorUserSetup-x64-0.49.1.exe)&lt;br&gt;[win32-arm64-user](https://downloads.cursor.com/production/600e5c827c07c5818474c1056eeec61d478b407a/win32/arm64/user-setup/CursorUserSetup-arm64-0.49.1.exe)&lt;br&gt;[win32-x64-system](https://downloads.cursor.com/production/600e5c827c07c5818474c1056eeec61d478b407a/win32/x64/system-setup/CursorSetup-x64-0.49.1.exe)&lt;br&gt;[win32-arm64-system](https://downloads.cursor.com/production/600e5c827c07c5818474c1056eeec61d478b407a/win32/arm64/system-setup/CursorSetup-arm64-0.49.1.exe) | [linux-x64](https://downloads.cursor.com/production/600e5c827c07c5818474c1056eeec61d478b407a/linux/x64/Cursor-0.49.1-x86_64.AppImage)&lt;br&gt;[linux-arm64](https://downloads.cursor.com/production/600e5c827c07c5818474c1056eeec61d478b407a/linux/arm64/Cursor-0.49.1-aarch64.AppImage) |
| 0.49.0 | 2025-04-16 | [darwin-universal](https://downloads.cursor.com/production/88a47f0edd42a2ba73afb018ada9fe9eda7df75f/darwin/universal/Cursor-darwin-universal.dmg) &lt;br&gt;[darwin-x64](https://downloads.cursor.com/production/88a47f0edd42a2ba73afb018ada9fe9eda7df75f/darwin/x64/Cursor-darwin-x64.dmg) &lt;br&gt;[darwin-arm64](https://downloads.cursor.com/production/88a47f0edd42a2ba73afb018ada9fe9eda7df75f/darwin/arm64/Cursor-darwin-arm64.dmg) | [win32-x64-user](https://downloads.cursor.com/production/88a47f0edd42a2ba73afb018ada9fe9eda7df75f/win32/x64/user-setup/CursorUserSetup-x64-0.49.0.exe)&lt;br&gt;[win32-arm64-user](https://downloads.cursor.com/production/88a47f0edd42a2ba73afb018ada9fe9eda7df75f/win32/arm64/user-setup/CursorUserSetup-arm64-0.49.0.exe)&lt;br&gt;[win32-x64-system](https://downloads.cursor.com/production/88a47f0edd42a2ba73afb018ada9fe9eda7df75f/win32/x64/system-setup/CursorSetup-x64-0.49.0.exe)&lt;br&gt;[win32-arm64-system](https://downloads.cursor.com/production/88a47f0edd42a2ba73afb018ada9fe9eda7df75f/win32/arm64/system-setup/CursorSetup-arm64-0.49.0.exe) | [linux-x64](https://downloads.cursor.com/production/88a47f0edd42a2ba73afb018ada9fe9eda7df75f/linux/x64/Cursor-0.49.0-x86_64.AppImage)&lt;br&gt;[linux-arm64](https://downloads.cursor.com/production/88a47f0edd42a2ba73afb018ada9fe9eda7df75f/linux/arm64/Cursor-0.49.0-aarch64.AppIma

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[infiniflow/ragflow]]></title>
            <link>https://github.com/infiniflow/ragflow</link>
            <guid>https://github.com/infiniflow/ragflow</guid>
            <pubDate>Thu, 15 May 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/infiniflow/ragflow">infiniflow/ragflow</a></h1>
            <p>RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 52,350</p>
            <p>Forks: 5,003</p>
            <p>Stars today: 159 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://demo.ragflow.io/&quot;&gt;
&lt;img src=&quot;web/src/assets/logo-with-text.png&quot; width=&quot;520&quot; alt=&quot;ragflow logo&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;English&lt;/a&gt; |
  &lt;a href=&quot;./README_zh.md&quot;&gt;简体中文&lt;/a&gt; |
  &lt;a href=&quot;./README_tzh.md&quot;&gt;繁体中文&lt;/a&gt; |
  &lt;a href=&quot;./README_ja.md&quot;&gt;日本語&lt;/a&gt; |
  &lt;a href=&quot;./README_ko.md&quot;&gt;한국어&lt;/a&gt; |
  &lt;a href=&quot;./README_id.md&quot;&gt;Bahasa Indonesia&lt;/a&gt; |
  &lt;a href=&quot;/README_pt_br.md&quot;&gt;Português (Brasil)&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://x.com/intent/follow?screen_name=infiniflowai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/infiniflow?logo=X&amp;color=%20%23f5f5f5&quot; alt=&quot;follow on X(Twitter)&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://demo.ragflow.io&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Online-Demo-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/r/infiniflow/ragflow&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/docker_pull-ragflow:v0.18.0-brightgreen&quot; alt=&quot;docker pull infiniflow/ragflow:v0.18.0&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/releases/latest&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/github/v/release/infiniflow/ragflow?color=blue&amp;label=Latest%20Release&quot; alt=&quot;Latest Release&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/blob/main/LICENSE&quot;&gt;
        &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/License-Apache--2.0-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;license&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://ragflow.io/docs/dev/&quot;&gt;Document&lt;/a&gt; |
  &lt;a href=&quot;https://github.com/infiniflow/ragflow/issues/4214&quot;&gt;Roadmap&lt;/a&gt; |
  &lt;a href=&quot;https://twitter.com/infiniflowai&quot;&gt;Twitter&lt;/a&gt; |
  &lt;a href=&quot;https://discord.gg/NjYzJD3GM3&quot;&gt;Discord&lt;/a&gt; |
  &lt;a href=&quot;https://demo.ragflow.io&quot;&gt;Demo&lt;/a&gt;
&lt;/h4&gt;

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;📕 Table of Contents&lt;/b&gt;&lt;/summary&gt;

- 💡 [What is RAGFlow?](#-what-is-ragflow)
- 🎮 [Demo](#-demo)
- 📌 [Latest Updates](#-latest-updates)
- 🌟 [Key Features](#-key-features)
- 🔎 [System Architecture](#-system-architecture)
- 🎬 [Get Started](#-get-started)
- 🔧 [Configurations](#-configurations)
- 🔧 [Build a docker image without embedding models](#-build-a-docker-image-without-embedding-models)
- 🔧 [Build a docker image including embedding models](#-build-a-docker-image-including-embedding-models)
- 🔨 [Launch service from source for development](#-launch-service-from-source-for-development)
- 📚 [Documentation](#-documentation)
- 📜 [Roadmap](#-roadmap)
- 🏄 [Community](#-community)
- 🙌 [Contributing](#-contributing)

&lt;/details&gt;

## 💡 What is RAGFlow?

[RAGFlow](https://ragflow.io/) is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document
understanding. It offers a streamlined RAG workflow for businesses of any scale, combining LLM (Large Language Models)
to provide truthful question-answering capabilities, backed by well-founded citations from various complex formatted
data.

## 🎮 Demo

Try our demo at [https://demo.ragflow.io](https://demo.ragflow.io).

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/infiniflow/ragflow/assets/7248/2f6baa3e-1092-4f11-866d-36f6a9d075e5&quot; width=&quot;1200&quot;/&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/504bbbf1-c9f7-4d83-8cc5-e9cb63c26db6&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## 🔥 Latest Updates

- 2025-03-19 Supports using a multi-modal model to make sense of images within PDF or DOCX files.
- 2025-02-28 Combined with Internet search (Tavily), supports reasoning like Deep Research for any LLMs.
- 2025-01-26 Optimizes knowledge graph extraction and application, offering various configuration options.
- 2024-12-18 Upgrades Document Layout Analysis model in DeepDoc.
- 2024-11-01 Adds keyword extraction and related question generation to the parsed chunks to improve the accuracy of retrieval.
- 2024-08-22 Support text to SQL statements through RAG.

## 🎉 Stay Tuned

⭐️ Star our repository to stay up-to-date with exciting new features and improvements! Get instant notifications for new
releases! 🌟

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/18c9707e-b8aa-4caf-a154-037089c105ba&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## 🌟 Key Features

### 🍭 **&quot;Quality in, quality out&quot;**

- [Deep document understanding](./deepdoc/README.md)-based knowledge extraction from unstructured data with complicated
  formats.
- Finds &quot;needle in a data haystack&quot; of literally unlimited tokens.

### 🍱 **Template-based chunking**

- Intelligent and explainable.
- Plenty of template options to choose from.

### 🌱 **Grounded citations with reduced hallucinations**

- Visualization of text chunking to allow human intervention.
- Quick view of the key references and traceable citations to support grounded answers.

### 🍔 **Compatibility with heterogeneous data sources**

- Supports Word, slides, excel, txt, images, scanned copies, structured data, web pages, and more.

### 🛀 **Automated and effortless RAG workflow**

- Streamlined RAG orchestration catered to both personal and large businesses.
- Configurable LLMs as well as embedding models.
- Multiple recall paired with fused re-ranking.
- Intuitive APIs for seamless integration with business.

## 🔎 System Architecture

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/infiniflow/ragflow/assets/12318111/d6ac5664-c237-4200-a7c2-a4a00691b485&quot; width=&quot;1000&quot;/&gt;
&lt;/div&gt;

## 🎬 Get Started

### 📝 Prerequisites

- CPU &gt;= 4 cores
- RAM &gt;= 16 GB
- Disk &gt;= 50 GB
- Docker &gt;= 24.0.0 &amp; Docker Compose &gt;= v2.26.1
  &gt; If you have not installed Docker on your local machine (Windows, Mac, or Linux),
  &gt; see [Install Docker Engine](https://docs.docker.com/engine/install/).

### 🚀 Start up the server

1. Ensure `vm.max_map_count` &gt;= 262144:

   &gt; To check the value of `vm.max_map_count`:
   &gt;
   &gt; ```bash
   &gt; $ sysctl vm.max_map_count
   &gt; ```
   &gt;
   &gt; Reset `vm.max_map_count` to a value at least 262144 if it is not.
   &gt;
   &gt; ```bash
   &gt; # In this case, we set it to 262144:
   &gt; $ sudo sysctl -w vm.max_map_count=262144
   &gt; ```
   &gt;
   &gt; This change will be reset after a system reboot. To ensure your change remains permanent, add or update the
   &gt; `vm.max_map_count` value in **/etc/sysctl.conf** accordingly:
   &gt;
   &gt; ```bash
   &gt; vm.max_map_count=262144
   &gt; ```

2. Clone the repo:

   ```bash
   $ git clone https://github.com/infiniflow/ragflow.git
   ```

3. Start up the server using the pre-built Docker images:

&gt; [!CAUTION]
&gt; All Docker images are built for x86 platforms. We don&#039;t currently offer Docker images for ARM64.
&gt; If you are on an ARM64 platform, follow [this guide](https://ragflow.io/docs/dev/build_docker_image) to build a Docker image compatible with your system.

   &gt; The command below downloads the `v0.18.0-slim` edition of the RAGFlow Docker image. See the following table for descriptions of different RAGFlow editions. To download a RAGFlow edition different from `v0.18.0-slim`, update the `RAGFLOW_IMAGE` variable accordingly in **docker/.env** before using `docker compose` to start the server. For example: set `RAGFLOW_IMAGE=infiniflow/ragflow:v0.18.0` for the full edition `v0.18.0`.

   ```bash
   $ cd ragflow/docker
   # Use CPU for embedding and DeepDoc tasks:
   $ docker compose -f docker-compose.yml up -d

   # To use GPU to accelerate embedding and DeepDoc tasks:
   # docker compose -f docker-compose-gpu.yml up -d
   ```

   | RAGFlow image tag | Image size (GB) | Has embedding models? | Stable?                  |
   |-------------------|-----------------|-----------------------|--------------------------|
   | v0.18.0           | &amp;approx;9       | :heavy_check_mark:    | Stable release           |
   | v0.18.0-slim      | &amp;approx;2       | ❌                   | Stable release            |
   | nightly           | &amp;approx;9       | :heavy_check_mark:    | _Unstable_ nightly build |
   | nightly-slim      | &amp;approx;2       | ❌                   | _Unstable_ nightly build  |

4. Check the server status after having the server up and running:

   ```bash
   $ docker logs -f ragflow-server
   ```

   _The following output confirms a successful launch of the system:_

   ```bash

         ____   ___    ______ ______ __
        / __ \ /   |  / ____// ____// /____  _      __
       / /_/ // /| | / / __ / /_   / // __ \| | /| / /
      / _, _// ___ |/ /_/ // __/  / // /_/ /| |/ |/ /
     /_/ |_|/_/  |_|\____//_/    /_/ \____/ |__/|__/

    * Running on all addresses (0.0.0.0)
   ```

   &gt; If you skip this confirmation step and directly log in to RAGFlow, your browser may prompt a `network anormal`
   &gt; error because, at that moment, your RAGFlow may not be fully initialized.

5. In your web browser, enter the IP address of your server and log in to RAGFlow.
   &gt; With the default settings, you only need to enter `http://IP_OF_YOUR_MACHINE` (**sans** port number) as the default
   &gt; HTTP serving port `80` can be omitted when using the default configurations.
6. In [service_conf.yaml.template](./docker/service_conf.yaml.template), select the desired LLM factory in `user_default_llm` and update
   the `API_KEY` field with the corresponding API key.

   &gt; See [llm_api_key_setup](https://ragflow.io/docs/dev/llm_api_key_setup) for more information.

   _The show is on!_

## 🔧 Configurations

When it comes to system configurations, you will need to manage the following files:

- [.env](./docker/.env): Keeps the fundamental setups for the system, such as `SVR_HTTP_PORT`, `MYSQL_PASSWORD`, and
  `MINIO_PASSWORD`.
- [service_conf.yaml.template](./docker/service_conf.yaml.template): Configures the back-end services. The environment variables in this file will be automatically populated when the Docker container starts. Any environment variables set within the Docker container will be available for use, allowing you to customize service behavior based on the deployment environment.
- [docker-compose.yml](./docker/docker-compose.yml): The system relies on [docker-compose.yml](./docker/docker-compose.yml) to start up.

&gt; The [./docker/README](./docker/README.md) file provides a detailed description of the environment settings and service
&gt; configurations which can be used as `${ENV_VARS}` in the [service_conf.yaml.template](./docker/service_conf.yaml.template) file.

To update the default HTTP serving port (80), go to [docker-compose.yml](./docker/docker-compose.yml) and change `80:80`
to `&lt;YOUR_SERVING_PORT&gt;:80`.

Updates to the above configurations require a reboot of all containers to take effect:

&gt; ```bash
&gt; $ docker compose -f docker-compose.yml up -d
&gt; ```

### Switch doc engine from Elasticsearch to Infinity

RAGFlow uses Elasticsearch by default for storing full text and vectors. To switch to [Infinity](https://github.com/infiniflow/infinity/), follow these steps:

1. Stop all running containers:

   ```bash
   $ docker compose -f docker/docker-compose.yml down -v
   ```

&gt; [!WARNING]
&gt; `-v` will delete the docker container volumes, and the existing data will be cleared.

2. Set `DOC_ENGINE` in **docker/.env** to `infinity`.

3. Start the containers:

   ```bash
   $ docker compose -f docker-compose.yml up -d
   ```

&gt; [!WARNING]
&gt; Switching to Infinity on a Linux/arm64 machine is not yet officially supported.

## 🔧 Build a Docker image without embedding models

This image is approximately 2 GB in size and relies on external LLM and embedding services.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 --build-arg LIGHTEN=1 -f Dockerfile -t infiniflow/ragflow:nightly-slim .
```

## 🔧 Build a Docker image including embedding models

This image is approximately 9 GB in size. As it includes embedding models, it relies on external LLM services only.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 -f Dockerfile -t infiniflow/ragflow:nightly .
```

## 🔨 Launch service from source for development

1. Install uv, or skip this step if it is already installed:

   ```bash
   pipx install uv pre-commit
   ```

2. Clone the source code and install Python dependencies:

   ```bash
   git clone https://github.com/infiniflow/ragflow.git
   cd ragflow/
   uv sync --python 3.10 --all-extras # install RAGFlow dependent python modules
   uv run download_deps.py
   pre-commit install
   ```

3. Launch the dependent services (MinIO, Elasticsearch, Redis, and MySQL) using Docker Compose:

   ```bash
   docker compose -f docker/docker-compose-base.yml up -d
   ```

   Add the following line to `/etc/hosts` to resolve all hosts specified in **docker/.env** to `127.0.0.1`:

   ```
   127.0.0.1       es01 infinity mysql minio redis
   ```

4. If you cannot access HuggingFace, set the `HF_ENDPOINT` environment variable to use a mirror site:

   ```bash
   export HF_ENDPOINT=https://hf-mirror.com
   ```

5. If your operating system does not have jemalloc, please install it as follows:

   ```bash
   # ubuntu
   sudo apt-get install libjemalloc-dev
   # centos
   sudo yum install jemalloc
   ```
   
6. Launch backend service:

   ```bash
   source .venv/bin/activate
   export PYTHONPATH=$(pwd)
   bash docker/launch_backend_service.sh
   ```

7. Install frontend dependencies:

   ```bash
   cd web
   npm install
   ```

8. Launch frontend service:

   ```bash
   npm run dev
   ```

   _The following output confirms a successful launch of the system:_

   ![](https://github.com/user-attachments/assets/0daf462c-a24d-4496-a66f-92533534e187)

9. Stop RAGFlow front-end and back-end service after development is complete:

   ```bash
   pkill -f &quot;ragflow_server.py|task_executor.py&quot;
   ```


## 📚 Documentation

- [Quickstart](https://ragflow.io/docs/dev/)
- [Configuration](https://ragflow.io/docs/dev/configurations)
- [Release notes](https://ragflow.io/docs/dev/release_notes)
- [User guides](https://ragflow.io/docs/dev/category/guides)
- [Developer guides](https://ragflow.io/docs/dev/category/developers)
- [References](https://ragflow.io/docs/dev/category/references)
- [FAQs](https://ragflow.io/docs/dev/faq)

## 📜 Roadmap

See the [RAGFlow Roadmap 2025](https://github.com/infiniflow/ragflow/issues/4214)

## 🏄 Community

- [Discord](https://discord.gg/NjYzJD3GM3)
- [Twitter](https://twitter.com/infiniflowai)
- [GitHub Discussions](https://github.com/orgs/infiniflow/discussions)

## 🙌 Contributing

RAGFlow flourishes via open-source collaboration. In this spirit, we embrace diverse contributions from the community.
If you would like to be a part, review our [Contribution Guidelines](./CONTRIBUTING.md) first.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[aws-amplify/amplify-js]]></title>
            <link>https://github.com/aws-amplify/amplify-js</link>
            <guid>https://github.com/aws-amplify/amplify-js</guid>
            <pubDate>Thu, 15 May 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[A declarative JavaScript library for application development using cloud services.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aws-amplify/amplify-js">aws-amplify/amplify-js</a></h1>
            <p>A declarative JavaScript library for application development using cloud services.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,516</p>
            <p>Forks: 2,157</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://s3.amazonaws.com/aws-mobile-hub-images/aws-amplify-logo.png&quot; alt=&quot;AWS Amplify&quot; width=&quot;550&quot; &gt;

[![current aws-amplify package version](https://img.shields.io/npm/v/aws-amplify?color=brightgreen&amp;label=npm%20package)](https://www.npmjs.com/package/aws-amplify)
[![weekly downloads](https://img.shields.io/npm/dw/aws-amplify)](https://www.npmjs.com/package/aws-amplify)
[![GitHub Workflow Status (with event)](https://img.shields.io/github/actions/workflow/status/aws-amplify/amplify-js/push-main-release.yml)
](https://github.com/aws-amplify/amplify-js/blob/main/.github/workflows/push-main-release.yml)
[![code coverage](https://codecov.io/gh/aws-amplify/amplify-js/branch/main/graph/badge.svg)](https://codecov.io/gh/aws-amplify/amplify-js)
[![join discord](https://img.shields.io/discord/308323056592486420?logo=discord)](https://discord.gg/jWVbPfC)

### Reporting Bugs / Feature Requests

[![Open Bugs](https://img.shields.io/github/issues/aws-amplify/amplify-js/bug?color=d73a4a&amp;label=bugs)](https://github.com/aws-amplify/amplify-js/issues?q=is%3Aissue+is%3Aopen+label%3Abug)
[![Feature Requests](https://img.shields.io/github/issues/aws-amplify/amplify-js/feature-request?color=ff9001&amp;label=feature%20requests)](https://github.com/aws-amplify/amplify-js/issues?q=is%3Aissue+label%3Afeature-request+is%3Aopen)
[![Closed Issues](https://img.shields.io/github/issues-closed/aws-amplify/amplify-js?color=%2325CC00&amp;label=issues%20closed)](https://github.com/aws-amplify/amplify-js/issues?q=is%3Aissue+is%3Aclosed+)

&gt; **Note**
&gt; aws-amplify 6 has been released. If you are looking for upgrade guidance [click here](#notice)

### AWS Amplify is a JavaScript library for frontend and mobile developers building cloud-enabled applications

AWS Amplify provides a declarative and easy-to-use interface across different categories of cloud operations. AWS Amplify goes well with any JavaScript based frontend workflow and React Native for mobile developers.

Our default implementation works with Amazon Web Services (AWS), but AWS Amplify is designed to be open and pluggable for any custom backend or service.

#### Visit our [documentation site](https://docs.amplify.aws/) to learn more about AWS Amplify. Please see the [Amplify JavaScript](https://docs.amplify.aws/lib/q/platform/js/) page for information around the full list of features we support.

- [Contributing](https://github.com/aws-amplify/amplify-js/blob/main/CONTRIBUTING.md)

### Features

| Category                                                                                                          | AWS Provider                                                | Description                                                                                                            |
| ----------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------- |
| [**Authentication**](https://docs.amplify.aws/lib/auth/getting-started/q/platform/js)                             | [Amazon Cognito](https://aws.amazon.com/cognito/)           | APIs and Building blocks to create Authentication experiences.                                                         |
| [**Analytics**](https://docs.amplify.aws/lib/analytics/getting-started/q/platform/js)                             | [Amazon Pinpoint](https://aws.amazon.com/pinpoint/)         | Collect Analytics data for your application including tracking user sessions.                                          |
| [**REST API**](https://docs.amplify.aws/lib/restapi/getting-started/q/platform/js)                                | [Amazon API Gateway](https://aws.amazon.com/api-gateway/)   | Sigv4 signing and AWS auth for API Gateway and other REST endpoints.                                                   |
| [**GraphQL API**](https://docs.amplify.aws/lib/graphqlapi/getting-started/q/platform/js)                          | [AWS AppSync](https://aws.amazon.com/appsync/)              | Interact with your GraphQL or AWS AppSync endpoint(s).                                                                 |
| [**DataStore**](https://docs.amplify.aws/lib/datastore/getting-started/q/platform/js)                             | [AWS AppSync](https://aws.amazon.com/appsync/)              | Programming model for shared and distributed data, with simple online/offline synchronization.                         |
| [**Storage**](https://docs.amplify.aws/lib/storage/getting-started/q/platform/js)                                 | [Amazon S3](https://aws.amazon.com/s3/)                     | Manages content in public, protected, private storage buckets.                                                         |
| [**Geo (Developer preview)**](https://docs.amplify.aws/lib/geo/getting-started/q/platform/js)                     | [Amazon Location Service](https://aws.amazon.com/location/) | Provides APIs and UI components for maps and location search for JavaScript-based web apps.                            |
| [**Push Notifications**](https://docs.amplify.aws/lib/push-notifications/getting-started/q/platform/js)           | [Amazon Pinpoint](https://aws.amazon.com/pinpoint/)         | Allows you to integrate push notifications in your app with Amazon Pinpoint targeting and campaign management support. |
| [**Interactions**](https://docs.amplify.aws/lib/interactions/getting-started/q/platform/js#interactions-with-aws) | [Amazon Lex](https://aws.amazon.com/lex/)                   | Create conversational bots powered by deep learning technologies.                                                      |
| [**PubSub**](https://docs.amplify.aws/lib/pubsub/getting-started/q/platform/js)                                   | [AWS IoT](https://aws.amazon.com/iot/)                      | Provides connectivity with cloud-based message-oriented middleware.                                                    |
| [**Internationalization**](https://docs.amplify.aws/lib/utilities/i18n/q/platform/js)                             | ---                                                         | A lightweight internationalization solution.                                                                           |
| [**Cache**](https://docs.amplify.aws/lib/utilities/cache/q/platform/js)                                           | ---                                                         | Provides a generic LRU cache for JavaScript developers to store data with priority and expiration settings.            |
| [**Predictions**](https://docs.amplify.aws/lib/predictions/getting-started/q/platform/js)                         | Various\*                                                   | Connect your app with machine learning services like NLP, computer vision, TTS, and more.                              |

- Predictions utilizes a range of Amazon&#039;s Machine Learning services, including: Amazon Comprehend, Amazon Polly, Amazon Rekognition, Amazon Textract, and Amazon Translate.

## Getting Started

AWS Amplify is available as `aws-amplify` on [npm](https://www.npmjs.com/package/aws-amplify).

To get started pick your platform from our [**Getting Started** home page](https://docs.amplify.aws/javascript/)

## Notice:

### Amplify 6.x.x has breaking changes. Please see the breaking changes on our [migration guide](https://docs.amplify.aws/javascript/build-a-backend/troubleshooting/migrate-from-javascript-v5-to-v6/)

### Amplify 5.x.x has breaking changes. Please see the breaking changes below:

- If you are using **default exports** from any Amplify package, then you will need to migrate to using named exports. For example:

  ```diff
  - import Amplify from &#039;aws-amplify&#039;;
  + import { Amplify } from &#039;aws-amplify&#039;

  - import Analytics from &#039;@aws-amplify/analytics&#039;;
  + import { Analytics } from &#039;@aws-amplify/analytics&#039;;
  // or better
  + import { Analytics } from &#039;aws-amplify&#039;;

  - import Storage from &#039;@aws-amplify/storage&#039;;
  + import { Storage } from &#039;@aws-amplify/storage&#039;;
  // or better
  + import { Storage } from &#039;aws-amplify&#039;;
  ```

- Datastore predicate syntax has changed, impacting the `DataStore.query`, `DataStore.save`, `DataStore.delete`, and `DataStore.observe` interfaces. For example:

  ```diff
  - await DataStore.delete(Post, (post) =&gt; post.status(&#039;eq&#039;, PostStatus.INACTIVE));
  + await DataStore.delete(Post, (post) =&gt; post.status.eq(PostStatus.INACTIVE));

  - await DataStore.query(Post, p =&gt; p.and( p =&gt; [p.title(&#039;eq&#039;, &#039;Amplify Getting Started Guide&#039;), p.score(&#039;gt&#039;, 8)]));
  + await DataStore.query(Post, p =&gt; p.and( p =&gt; [p.title.eq(&#039;Amplify Getting Started Guide&#039;), p.score.gt(8)]));
  ```

  - To use the new syntax with 5.x.x you may need to rebuild your Datastore models with the latest version of Amplify codegen. To do this:
    - [Upgrade the Amplify CLI](https://docs.amplify.aws/cli/start/workflows/#upgrade-amplify-cli)
      - `npm install -g @aws-amplify/cli`
    - [Re-generate your models with Amplify codegen](https://docs.amplify.aws/lib/datastore/getting-started/q/platform/js/#code-generation-amplify-cli)
      - `amplify codegen models`

- `Storage.list` has changed the name of the `maxKeys` parameter to `pageSize` and has a new return type that contains the results list. For example:

  ```diff
  - const photos = await Storage.list(&#039;photos/&#039;, { maxKeys: 100 });
  - const { key } = photos[0];

  + const photos = await Storage.list(&#039;photos/&#039;, { pageSize: 100 });
  + const { key } = photos.results[0];
  ```

- `Storage.put` with resumable turned on has changed the key to no longer include the bucket name. For example:

  ```diff
  - let uploadedObjectKey;
  - Storage.put(file.name, file, {
  -   resumable: true,
  -   // Necessary to parse the bucket name out to work with the key
  -   completeCallback: (obj) =&gt; uploadedObjectKey = obj.key.substring( obj.key.indexOf(&quot;/&quot;) + 1 )
  - }

  + let uploadedObjectKey;
  + Storage.put(file.name, file, {
  +   resumable: true,
  +   completeCallback: (obj) =&gt; uploadedObjectKey = obj.key
  + }
  ```

- `Analytics.record` no longer accepts string as input. For example:

  ```diff
  - Analytics.record(&#039;my example event&#039;);
  + Analytics.record({ name: &#039;my example event&#039; });
  ```

- The `JS` export has been removed from `@aws-amplify/core` in favor of exporting the functions it contained.
- Any calls to `Amplify.Auth`, `Amplify.Cache`, and `Amplify.ServiceWorker` are no longer supported. Instead, your code should use the named exports. For example:

  ```diff
  - import { Amplify } from &#039;aws-amplify&#039;;
  - Amplify.configure(...);
  - // ...
  - Amplify.Auth.signIn(...);

  + import { Amplify, Auth } from &#039;aws-amplify&#039;;
  + Amplify.configure(...);
  + // ...
  + Auth.signIn(...);
  ```

### Amplify 4.x.x has breaking changes for React Native. Please see the breaking changes below:

- If you are using React Native (vanilla or Expo), you will need to add the following React Native community dependencies:
  - `@react-native-community/netinfo`
  - `@react-native-async-storage/async-storage`

```
// React Native
yarn add aws-amplify amazon-cognito-identity-js @react-native-community/netinfo @react-native-async-storage/async-storage
npx pod-install

// Expo
yarn add aws-amplify @react-native-community/netinfo @react-native-async-storage/async-storage
```

### Amplify 3.x.x has breaking changes. Please see the breaking changes below:

- `AWS.credentials` and `AWS.config` don’t exist anymore in Amplify JavaScript.
  - Both options will not be available to use in version 3. You will not be able to use and set your own credentials.
  - For more information on this change, please see the [AWS SDK for JavaScript v3](https://github.com/aws/aws-sdk-js-v3/#configuration)
- `aws-sdk@2.x` has been removed from `Amplify@3.x.x` in favor of [version 3 of aws-sdk-js](https://github.com/aws/aws-sdk-js-v3). We recommend to migrate to [aws-sdk-js-v3](https://github.com/aws/aws-sdk-js-v3) if you rely on AWS services that are not supported by Amplify, since [aws-sdk-js-v3](https://github.com/aws/aws-sdk-js-v3) is imported modularly.

If you can&#039;t migrate to [aws-sdk-js-v3](https://github.com/aws/aws-sdk-js-v3) or rely on aws-sdk@2.x, you will need to import it separately.

- If you are using exported paths within your Amplify JS application, (e.g. `import from &quot;@aws-amplify/analytics/lib/Analytics&quot;`) this will now break and no longer will be supported. You will need to change to named imports:

  ```js
  import { Analytics } from &#039;aws-amplify&#039;;
  ```

- If you are using categories as `Amplify.&lt;Category&gt;`, this will no longer work and we recommend to import the category you are needing to use:

  ```js
  import { Auth } from &#039;aws-amplify&#039;;
  ```

### DataStore Docs

For more information on contributing to DataStore / how DataStore works, see the [DataStore Docs](packages/datastore/README.md)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[FlowiseAI/Flowise]]></title>
            <link>https://github.com/FlowiseAI/Flowise</link>
            <guid>https://github.com/FlowiseAI/Flowise</guid>
            <pubDate>Thu, 15 May 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[Drag & drop UI to build your customized LLM flow]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/FlowiseAI/Flowise">FlowiseAI/Flowise</a></h1>
            <p>Drag & drop UI to build your customized LLM flow</p>
            <p>Language: TypeScript</p>
            <p>Stars: 38,134</p>
            <p>Forks: 19,877</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable MD030 --&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://github.com/FlowiseAI/Flowise/blob/main/images/flowise_white.svg#gh-light-mode-only&quot;&gt;
&lt;img src=&quot;https://github.com/FlowiseAI/Flowise/blob/main/images/flowise_dark.svg#gh-dark-mode-only&quot;&gt;
&lt;/p&gt;

[![Release Notes](https://img.shields.io/github/release/FlowiseAI/Flowise)](https://github.com/FlowiseAI/Flowise/releases)
[![Discord](https://img.shields.io/discord/1087698854775881778?label=Discord&amp;logo=discord)](https://discord.gg/jbaHfsRVBW)
[![Twitter Follow](https://img.shields.io/twitter/follow/FlowiseAI?style=social)](https://twitter.com/FlowiseAI)
[![GitHub star chart](https://img.shields.io/github/stars/FlowiseAI/Flowise?style=social)](https://star-history.com/#FlowiseAI/Flowise)
[![GitHub fork](https://img.shields.io/github/forks/FlowiseAI/Flowise?style=social)](https://github.com/FlowiseAI/Flowise/fork)

English | [繁體中文](./i18n/README-TW.md) | [简体中文](./i18n/README-ZH.md) | [日本語](./i18n/README-JA.md) | [한국어](./i18n/README-KR.md)

&lt;h3&gt;Build AI Agents, Visually&lt;/h3&gt;
&lt;a href=&quot;https://github.com/FlowiseAI/Flowise&quot;&gt;
&lt;img width=&quot;100%&quot; src=&quot;https://github.com/FlowiseAI/Flowise/blob/main/images/flowise_agentflow.gif?raw=true&quot;&gt;&lt;/a&gt;

## ⚡Quick Start

Download and Install [NodeJS](https://nodejs.org/en/download) &gt;= 18.15.0

1. Install Flowise
    ```bash
    npm install -g flowise
    ```
2. Start Flowise

    ```bash
    npx flowise start
    ```

    With username &amp; password

    ```bash
    npx flowise start --FLOWISE_USERNAME=user --FLOWISE_PASSWORD=1234
    ```

3. Open [http://localhost:3000](http://localhost:3000)

## 🐳 Docker

### Docker Compose

1. Clone the Flowise project
2. Go to `docker` folder at the root of the project
3. Copy `.env.example` file, paste it into the same location, and rename to `.env` file
4. `docker compose up -d`
5. Open [http://localhost:3000](http://localhost:3000)
6. You can bring the containers down by `docker compose stop`

### Docker Image

1. Build the image locally:
    ```bash
    docker build --no-cache -t flowise .
    ```
2. Run image:

    ```bash
    docker run -d --name flowise -p 3000:3000 flowise
    ```

3. Stop image:
    ```bash
    docker stop flowise
    ```

## 👨‍💻 Developers

Flowise has 3 different modules in a single mono repository.

-   `server`: Node backend to serve API logics
-   `ui`: React frontend
-   `components`: Third-party nodes integrations
-   `api-documentation`: Auto-generated swagger-ui API docs from express

### Prerequisite

-   Install [PNPM](https://pnpm.io/installation)
    ```bash
    npm i -g pnpm
    ```

### Setup

1.  Clone the repository

    ```bash
    git clone https://github.com/FlowiseAI/Flowise.git
    ```

2.  Go into repository folder

    ```bash
    cd Flowise
    ```

3.  Install all dependencies of all modules:

    ```bash
    pnpm install
    ```

4.  Build all the code:

    ```bash
    pnpm build
    ```

    &lt;details&gt;
    &lt;summary&gt;Exit code 134 (JavaScript heap out of memory)&lt;/summary&gt;  
      If you get this error when running the above `build` script, try increasing the Node.js heap size and run the script again:

        export NODE_OPTIONS=&quot;--max-old-space-size=4096&quot;
        pnpm build

    &lt;/details&gt;

5.  Start the app:

    ```bash
    pnpm start
    ```

    You can now access the app on [http://localhost:3000](http://localhost:3000)

6.  For development build:

    -   Create `.env` file and specify the `VITE_PORT` (refer to `.env.example`) in `packages/ui`
    -   Create `.env` file and specify the `PORT` (refer to `.env.example`) in `packages/server`
    -   Run

        ```bash
        pnpm dev
        ```

    Any code changes will reload the app automatically on [http://localhost:8080](http://localhost:8080)

## 🔒 Authentication

To enable app level authentication, add `FLOWISE_USERNAME` and `FLOWISE_PASSWORD` to the `.env` file in `packages/server`:

```
FLOWISE_USERNAME=user
FLOWISE_PASSWORD=1234
```

## 🌱 Env Variables

Flowise support different environment variables to configure your instance. You can specify the following variables in the `.env` file inside `packages/server` folder. Read [more](https://github.com/FlowiseAI/Flowise/blob/main/CONTRIBUTING.md#-env-variables)

## 📖 Documentation

[Flowise Docs](https://docs.flowiseai.com/)

## 🌐 Self Host

Deploy Flowise self-hosted in your existing infrastructure, we support various [deployments](https://docs.flowiseai.com/configuration/deployment)

-   [AWS](https://docs.flowiseai.com/configuration/deployment/aws)
-   [Azure](https://docs.flowiseai.com/configuration/deployment/azure)
-   [Digital Ocean](https://docs.flowiseai.com/configuration/deployment/digital-ocean)
-   [GCP](https://docs.flowiseai.com/configuration/deployment/gcp)
-   [Alibaba Cloud](https://computenest.console.aliyun.com/service/instance/create/default?type=user&amp;ServiceName=Flowise社区版)
-   &lt;details&gt;
      &lt;summary&gt;Others&lt;/summary&gt;

    -   [Railway](https://docs.flowiseai.com/configuration/deployment/railway)

        [![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template/pn4G8S?referralCode=WVNPD9)

    -   [Render](https://docs.flowiseai.com/configuration/deployment/render)

        [![Deploy to Render](https://render.com/images/deploy-to-render-button.svg)](https://docs.flowiseai.com/configuration/deployment/render)

    -   [HuggingFace Spaces](https://docs.flowiseai.com/deployment/hugging-face)

        &lt;a href=&quot;https://huggingface.co/spaces/FlowiseAI/Flowise&quot;&gt;&lt;img src=&quot;https://huggingface.co/datasets/huggingface/badges/raw/main/open-in-hf-spaces-sm.svg&quot; alt=&quot;HuggingFace Spaces&quot;&gt;&lt;/a&gt;

    -   [Elestio](https://elest.io/open-source/flowiseai)

        [![Deploy on Elestio](https://elest.io/images/logos/deploy-to-elestio-btn.png)](https://elest.io/open-source/flowiseai)

    -   [Sealos](https://template.sealos.io/deploy?templateName=flowise)

        [![Deploy on Sealos](https://sealos.io/Deploy-on-Sealos.svg)](https://template.sealos.io/deploy?templateName=flowise)

    -   [RepoCloud](https://repocloud.io/details/?app_id=29)

        [![Deploy on RepoCloud](https://d16t0pc4846x52.cloudfront.net/deploy.png)](https://repocloud.io/details/?app_id=29)

      &lt;/details&gt;

## ☁️ Flowise Cloud

[Get Started with Flowise Cloud](https://flowiseai.com/)

## 🙋 Support

Feel free to ask any questions, raise problems, and request new features in [discussion](https://github.com/FlowiseAI/Flowise/discussions)

## 🙌 Contributing

Thanks go to these awesome contributors

&lt;a href=&quot;https://github.com/FlowiseAI/Flowise/graphs/contributors&quot;&gt;
&lt;img src=&quot;https://contrib.rocks/image?repo=FlowiseAI/Flowise&quot; /&gt;
&lt;/a&gt;

See [contributing guide](CONTRIBUTING.md). Reach out to us at [Discord](https://discord.gg/jbaHfsRVBW) if you have any questions or issues.
[![Star History Chart](https://api.star-history.com/svg?repos=FlowiseAI/Flowise&amp;type=Timeline)](https://star-history.com/#FlowiseAI/Flowise&amp;Date)

## 📄 License

Source code in this repository is made available under the [Apache License Version 2.0](LICENSE.md).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[langgenius/dify]]></title>
            <link>https://github.com/langgenius/dify</link>
            <guid>https://github.com/langgenius/dify</guid>
            <pubDate>Thu, 15 May 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langgenius/dify">langgenius/dify</a></h1>
            <p>Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 97,059</p>
            <p>Forks: 14,548</p>
            <p>Stars today: 196 stars today</p>
            <h2>README</h2><pre>![cover-v5-optimized](https://github.com/langgenius/dify/assets/13230914/f9e19af5-61ba-4119-b926-d10c4c06ebab)

&lt;p align=&quot;center&quot;&gt;
  📌 &lt;a href=&quot;https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast&quot;&gt;Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cloud.dify.ai&quot;&gt;Dify Cloud&lt;/a&gt; ·
  &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted&quot;&gt;Self-hosting&lt;/a&gt; ·
  &lt;a href=&quot;https://docs.dify.ai&quot;&gt;Documentation&lt;/a&gt; ·
  &lt;a href=&quot;https://dify.ai/pricing&quot;&gt;Dify edition overview&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://dify.ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Product-F04438&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://dify.ai/pricing&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/free-pricing?logo=free&amp;color=%20%23155EEF&amp;label=pricing&amp;labelColor=%20%23528bff&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/FngNHpbcY7&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1082486657678311454?logo=discord&amp;labelColor=%20%235462eb&amp;logoColor=%20%23f5f5f5&amp;color=%20%235462eb&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://reddit.com/r/difyai&quot; target=&quot;_blank&quot;&gt;  
        &lt;img src=&quot;https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&amp;logo=reddit&amp;label=r%2Fdifyai&amp;labelColor=white&quot;
            alt=&quot;join Reddit&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=dify_ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/dify_ai?logo=X&amp;color=%20%23f5f5f5&quot;
            alt=&quot;follow on X(Twitter)&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/langgenius/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;logoColor=fff&quot;
            alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/u/langgenius&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&amp;color=%20%23f79009&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/graphs/commit-activity&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Commits last month&quot; src=&quot;https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&amp;color=%20%2312b76a&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Issues closed&quot; src=&quot;https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&amp;label=issues%20closed&amp;labelColor=%20%237d89b0&amp;color=%20%235d6b98&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/discussions/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Discussion posts&quot; src=&quot;https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&amp;color=%20%237a5af8&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_TW.md&quot;&gt;&lt;img alt=&quot;繁體中文文件&quot; src=&quot;https://img.shields.io/badge/繁體中文-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_CN.md&quot;&gt;&lt;img alt=&quot;简体中文版自述文件&quot; src=&quot;https://img.shields.io/badge/简体中文-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_JA.md&quot;&gt;&lt;img alt=&quot;日本語のREADME&quot; src=&quot;https://img.shields.io/badge/日本語-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_ES.md&quot;&gt;&lt;img alt=&quot;README en Español&quot; src=&quot;https://img.shields.io/badge/Español-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_FR.md&quot;&gt;&lt;img alt=&quot;README en Français&quot; src=&quot;https://img.shields.io/badge/Français-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_KL.md&quot;&gt;&lt;img alt=&quot;README tlhIngan Hol&quot; src=&quot;https://img.shields.io/badge/Klingon-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_KR.md&quot;&gt;&lt;img alt=&quot;README in Korean&quot; src=&quot;https://img.shields.io/badge/한국어-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_AR.md&quot;&gt;&lt;img alt=&quot;README بالعربية&quot; src=&quot;https://img.shields.io/badge/العربية-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_TR.md&quot;&gt;&lt;img alt=&quot;Türkçe README&quot; src=&quot;https://img.shields.io/badge/Türkçe-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_VI.md&quot;&gt;&lt;img alt=&quot;README Tiếng Việt&quot; src=&quot;https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_DE.md&quot;&gt;&lt;img alt=&quot;README in Deutsch&quot; src=&quot;https://img.shields.io/badge/German-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_BN.md&quot;&gt;&lt;img alt=&quot;README in বাংলা&quot; src=&quot;https://img.shields.io/badge/বাংলা-d9d9d9&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Dify is an open-source LLM app development platform. Its intuitive interface combines agentic AI workflow, RAG pipeline, agent capabilities, model management, observability features, and more, allowing you to quickly move from prototype to production.

## Quick start

&gt; Before installing Dify, make sure your machine meets the following minimum system requirements:
&gt;
&gt; - CPU &gt;= 2 Core
&gt; - RAM &gt;= 4 GiB

&lt;/br&gt;

The easiest way to start the Dify server is through [docker compose](docker/docker-compose.yaml). Before running Dify with the following commands, make sure that [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) are installed on your machine:

```bash
cd dify
cd docker
cp .env.example .env
docker compose up -d
```

After running, you can access the Dify dashboard in your browser at [http://localhost/install](http://localhost/install) and start the initialization process.

#### Seeking help

Please refer to our [FAQ](https://docs.dify.ai/getting-started/install-self-hosted/faqs) if you encounter problems setting up Dify. Reach out to [the community and us](#community--contact) if you are still having issues.

&gt; If you&#039;d like to contribute to Dify or do additional development, refer to our [guide to deploying from source code](https://docs.dify.ai/getting-started/install-self-hosted/local-source-code)

## Key features

**1. Workflow**:
Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.

https://github.com/langgenius/dify/assets/13230914/356df23e-1604-483d-80a6-9517ece318aa

**2. Comprehensive model support**:
Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found [here](https://docs.dify.ai/getting-started/readme/model-providers).

![providers-v5](https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3)

**3. Prompt IDE**:
Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.

**4. RAG Pipeline**:
Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.

**5. Agent capabilities**:
You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALL·E, Stable Diffusion and WolframAlpha.

**6. LLMOps**:
Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.

**7. Backend-as-a-Service**:
All of Dify&#039;s offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.

## Feature Comparison

&lt;table style=&quot;width: 100%;&quot;&gt;
  &lt;tr&gt;
    &lt;th align=&quot;center&quot;&gt;Feature&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;Dify.AI&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;LangChain&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;Flowise&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;OpenAI Assistants API&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Programming Approach&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;API + App-oriented&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Python Code&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;App-oriented&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;API-oriented&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Supported LLMs&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;OpenAI-only&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;RAG Engine&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Agent&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Workflow&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Observability&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Enterprise Feature (SSO/Access control)&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Local Deployment&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Using Dify

- **Cloud &lt;/br&gt;**
  We host a [Dify Cloud](https://dify.ai) service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.

- **Self-hosting Dify Community Edition&lt;/br&gt;**
  Quickly get Dify running in your environment with this [starter guide](#quick-start).
  Use our [documentation](https://docs.dify.ai) for further references and more in-depth instructions.

- **Dify for enterprise / organizations&lt;/br&gt;**
  We provide additional enterprise-centric features. [Log your questions for us through this chatbot](https://udify.app/chat/22L1zSxg6yW1cWQg) or [send us an email](mailto:business@dify.ai?subject=[GitHub]Business%20License%20Inquiry) to discuss enterprise needs. &lt;/br&gt;
  &gt; For startups and small businesses using AWS, check out [Dify Premium on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6) and deploy it to your own AWS VPC with one click. It&#039;s an affordable AMI offering with the option to create apps with custom logo and branding.

## Staying ahead

Star Dify on GitHub and be instantly notified of new releases.

![star-us](https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4)

## Advanced Setup

If you need to customize the configuration, please refer to the comments in our [.env.example](docker/.env.example) file and update the corresponding values in your `.env` file. Additionally, you might need to make adjustments to the `docker-compose.yaml` file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run `docker-compose up -d`. You can find the full list of available environment variables [here](https://docs.dify.ai/getting-started/install-self-hosted/environments).

If you&#039;d like to configure a highly-available setup, there are community-contributed [Helm Charts](https://helm.sh/) and YAML files which allow Dify to be deployed on Kubernetes.

- [Helm Chart by @LeoQuote](https://github.com/douban/charts/tree/master/charts/dify)
- [Helm Chart by @BorisPolonsky](https://github.com/BorisPolonsky/dify-helm)
- [Helm Chart by @magicsong](https://github.com/magicsong/ai-charts)
- [YAML file by @Winson-030](https://github.com/Winson-030/dify-kubernetes)
- [YAML file by @wyy-holding](https://github.com/wyy-holding/dify-k8s)

#### Using Terraform for Deployment

Deploy Dify to Cloud Platform with a single click using [terraform](https://www.terraform.io/)

##### Azure Global

- [Azure Terraform by @nikawang](https://github.com/nikawang/dify-azure-terraform)

##### Google Cloud

- [Google Cloud Terraform by @sotazum](https://github.com/DeNA/dify-google-cloud-terraform)

#### Using AWS CDK for Deployment

Deploy Dify to AWS with [CDK](https://aws.amazon.com/cdk/)

##### AWS

- [AWS CDK by @KevinZhao](https://github.com/aws-samples/solution-for-deploying-dify-on-aws)

## Contributing

For those who&#039;d like to contribute code, see our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.

&gt; We are looking for contributors to help translate Dify into languages other than Mandarin or English. If you are interested in helping, please see the [i18n README](https://github.com/langgenius/dify/blob/main/web/i18n/README.md) for more information, and leave us a comment in the `global-users` channel of our [Discord Community Server](https://discord.gg/8Tpq4AcN9c).

## Community &amp; contact

- [Github Discussion](https://github.com/langgenius/dify/discussions). Best for: sharing feedback and asking questions.
- [GitHub Issues](https://github.com/langgenius/dify/issues). Best for: bugs you encounter using Dify.AI, and feature proposals. See our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
- [Discord](https://discord.gg/FngNHpbcY7). Best for: sharing your applications and hanging out with the community.
- [X(Twitter)](https://twitter.com/dify_ai). Best for: sharing your applications and hanging out with the community.

**Contributors**

&lt;a href=&quot;https://github.com/langgenius/dify/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=langgenius/dify&quot; /&gt;
&lt;/a&gt;

## Star history

[![Star History Chart](https://api.star-history.com/svg?repos=langgenius/dify&amp;type=Date)](https://star-history.com/#langgenius/dify&amp;Date)

## Security disclosure

To protect your privacy, please avoid posting security issues on GitHub. Instead, send your questions to security@dify.ai and we will provide you with a more detailed answer.

## License

This repository is available under the [Dify Open Source License](LICENSE), which is essentially Apache 2.0 with a few additional restrictions.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[prisma/prisma]]></title>
            <link>https://github.com/prisma/prisma</link>
            <guid>https://github.com/prisma/prisma</guid>
            <pubDate>Thu, 15 May 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[Next-generation ORM for Node.js & TypeScript | PostgreSQL, MySQL, MariaDB, SQL Server, SQLite, MongoDB and CockroachDB]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prisma/prisma">prisma/prisma</a></h1>
            <p>Next-generation ORM for Node.js & TypeScript | PostgreSQL, MySQL, MariaDB, SQL Server, SQLite, MongoDB and CockroachDB</p>
            <p>Language: TypeScript</p>
            <p>Stars: 42,259</p>
            <p>Forks: 1,747</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>![Prisma](https://i.imgur.com/h6UIYTu.png)

&lt;div align=&quot;center&quot;&gt;
  &lt;h1&gt;Prisma&lt;/h1&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/prisma&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/prisma.svg?style=flat&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/prisma/prisma/blob/main/CONTRIBUTING.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/prisma/prisma/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-Apache%202-blue&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://pris.ly/discord&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/937751382725886062?label=Discord&quot;&gt;&lt;/a&gt;
  &lt;br /&gt;
  &lt;br /&gt;
  &lt;a href=&quot;https://www.prisma.io/docs/getting-started/quickstart&quot;&gt;Quickstart&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://www.prisma.io/&quot;&gt;Website&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://www.prisma.io/docs/&quot;&gt;Docs&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://github.com/prisma/prisma-examples/&quot;&gt;Examples&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://www.prisma.io/blog&quot;&gt;Blog&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://pris.ly/discord?utm_source=github&amp;utm_medium=prisma&amp;utm_content=repo_readme&quot;&gt;Discord&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://pris.ly/x?utm_source=github&amp;utm_medium=prisma&amp;utm_content=repo_readme&quot;&gt;Twitter&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://pris.ly/youtube?utm_source=github&amp;utm_medium=prisma&amp;utm_content=repo_readme&quot;&gt;Youtube&lt;/a&gt;
  &lt;br /&gt;
  &lt;hr /&gt;
&lt;/div&gt;

## What is Prisma?

Prisma ORM is a **next-generation ORM** that consists of these tools:

- [**Prisma Client**](https://www.prisma.io/docs/concepts/components/prisma-client): Auto-generated and type-safe query builder for Node.js &amp; TypeScript
- [**Prisma Migrate**](https://www.prisma.io/docs/concepts/components/prisma-migrate): Declarative data modeling &amp; migration system
- [**Prisma Studio**](https://github.com/prisma/studio): GUI to view and edit data in your database

Prisma Client can be used in _any_ Node.js or TypeScript backend application (including serverless applications and microservices). This can be a [REST API](https://www.prisma.io/docs/concepts/overview/prisma-in-your-stack/rest), a [GraphQL API](https://www.prisma.io/docs/concepts/overview/prisma-in-your-stack/graphql), a gRPC API, or anything else that needs a database.

**If you need a database to use with Prisma ORM, check out [Prisma Postgres](https://www.prisma.io/docs/getting-started/quickstart-prismaPostgres?utm_source=github&amp;utm_medium=prisma-readme).**

## Getting started

### Quickstart (5min)

The fastest way to get started with Prisma is by following the quickstart guides. You can choose either of two databases:

- [Prisma Postgres](https://www.prisma.io/docs/getting-started/quickstart-prismaPostgres)
- [SQLite](https://www.prisma.io/docs/getting-started/quickstart-sqlite)

### Bring your own database

If you already have your own database, you can follows these guides:

- [Add Prisma to an existing project](https://www.prisma.io/docs/getting-started/setup-prisma/add-to-existing-project/relational-databases-typescript-postgresql)
- [Set up a new project with Prisma from scratch](https://www.prisma.io/docs/getting-started/setup-prisma/start-from-scratch/relational-databases-typescript-postgresql)

## How Prisma ORM works

This section provides a high-level overview of how Prisma ORM works and its most important technical components. For a more thorough introduction, visit the [Prisma documentation](https://www.prisma.io/docs/).

### The Prisma schema

Every project that uses a tool from the Prisma toolkit starts with a [Prisma schema file](https://www.prisma.io/docs/concepts/components/prisma-schema). The Prisma schema allows developers to define their _application models_ in an intuitive data modeling language. It also contains the connection to a database and defines a _generator_:

```prisma
// Data source
datasource db {
  provider = &quot;postgresql&quot;
  url      = env(&quot;DATABASE_URL&quot;)
}

// Generator
generator client {
  provider = &quot;prisma-client-js&quot;
}

// Data model
model Post {
  id        Int     @id @default(autoincrement())
  title     String
  content   String?
  published Boolean @default(false)
  author    User?   @relation(fields:  [authorId], references: [id])
  authorId  Int?
}

model User {
  id    Int     @id @default(autoincrement())
  email String  @unique
  name  String?
  posts Post[]
}
```

In this schema, you configure three things:

- **Data source**: Specifies your database connection (via an environment variable)
- **Generator**: Indicates that you want to generate Prisma Client
- **Data model**: Defines your application models

---

### The Prisma data model

On this page, the focus is on the data model. You can learn more about [Data sources](https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema/data-sources) and [Generators](https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema/generators) on the respective docs pages.

#### Functions of Prisma models

The data model is a collection of [models](https://www.prisma.io/docs/concepts/components/prisma-schema/data-model#defining-models). A model has two major functions:

- Represent a table in the underlying database
- Provide the foundation for the queries in the Prisma Client API

#### Getting a data model

There are two major workflows for &quot;getting&quot; a data model into your Prisma schema:

- Generate the data model from [introspecting](https://www.prisma.io/docs/concepts/components/introspection) a database
- Manually writing the data model and mapping it to the database with [Prisma Migrate](https://www.prisma.io/docs/concepts/components/prisma-migrate)

Once the data model is defined, you can [generate Prisma Client](https://www.prisma.io/docs/concepts/components/prisma-client/generating-prisma-client) which will expose CRUD and more queries for the defined models. If you&#039;re using TypeScript, you&#039;ll get full type-safety for all queries (even when only retrieving the subsets of a model&#039;s fields).

---

### Accessing your database with Prisma Client

#### Generating Prisma Client

The first step when using Prisma Client is installing its npm package:

```
npm install @prisma/client
```

Note that the installation of this package invokes the `prisma generate` command which reads your Prisma schema and _generates_ the Prisma Client code. The code will be located in `node_modules/.prisma/client`, which is exported by `node_modules/@prisma/client/index.d.ts`.

After you change your data model, you&#039;ll need to manually re-generate Prisma Client to ensure the code inside `node_modules/.prisma/client` gets updated:

```
npx prisma generate
```

Refer to the documentation for more information about [&quot;generating the Prisma client&quot;](https://www.prisma.io/docs/concepts/components/prisma-client/generating-prisma-client).

#### Using Prisma Client to send queries to your database

Once the Prisma Client is generated, you can import it in your code and send queries to your database. This is what the setup code looks like.

##### Import and instantiate Prisma Client

You can import and instantiate Prisma Client as follows:

```ts
import { PrismaClient } from &#039;@prisma/client&#039;

const prisma = new PrismaClient()
```

or

```js
const { PrismaClient } = require(&#039;@prisma/client&#039;)

const prisma = new PrismaClient()
```

Now you can start sending queries via the generated Prisma Client API, here are a few sample queries. Note that all Prisma Client queries return _plain old JavaScript objects_.

Learn more about the available operations in the [Prisma Client docs](https://www.prisma.io/docs/concepts/components/prisma-client) or watch this [demo video](https://www.youtube.com/watch?v=LggrE5kJ75I&amp;list=PLn2e1F9Rfr6k9PnR_figWOcSHgc_erDr5&amp;index=4) (2 min).

##### Retrieve all `User` records from the database

```ts
const allUsers = await prisma.user.findMany()
```

##### Include the `posts` relation on each returned `User` object

```ts
const allUsers = await prisma.user.findMany({
  include: { posts: true },
})
```

##### Filter all `Post` records that contain `&quot;prisma&quot;`

```ts
const filteredPosts = await prisma.post.findMany({
  where: {
    OR: [{ title: { contains: &#039;prisma&#039; } }, { content: { contains: &#039;prisma&#039; } }],
  },
})
```

##### Create a new `User` and a new `Post` record in the same query

```ts
const user = await prisma.user.create({
  data: {
    name: &#039;Alice&#039;,
    email: &#039;alice@prisma.io&#039;,
    posts: {
      create: { title: &#039;Join us for Prisma Day 2021&#039; },
    },
  },
})
```

##### Update an existing `Post` record

```ts
const post = await prisma.post.update({
  where: { id: 42 },
  data: { published: true },
})
```

#### Usage with TypeScript

Note that when using TypeScript, the result of this query will be _statically typed_ so that you can&#039;t accidentally access a property that doesn&#039;t exist (and any typos are caught at compile-time). Learn more about leveraging Prisma Client&#039;s generated types on the [Advanced usage of generated types](https://www.prisma.io/docs/concepts/components/prisma-client/advanced-usage-of-generated-types) page in the docs.

## Community

Prisma has a large and supportive [community](https://www.prisma.io/community) of enthusiastic application developers. You can join us on [Discord](https://pris.ly/discord) and here on [GitHub](https://github.com/prisma/prisma/discussions).

## Badges

[![Made with Prisma](http://made-with.prisma.io/dark.svg)](https://prisma.io) [![Made with Prisma](http://made-with.prisma.io/indigo.svg)](https://prisma.io)

Built something awesome with Prisma? 🌟 Show it off with these [badges](https://github.com/prisma/presskit?tab=readme-ov-file#badges), perfect for your readme or website.

```
[![Made with Prisma](http://made-with.prisma.io/dark.svg)](https://prisma.io)
```

```
[![Made with Prisma](http://made-with.prisma.io/indigo.svg)](https://prisma.io)
```

## MCP server

The Prisma CLI includes a [Prisma MCP server](https://www.prisma.io/docs/postgres/mcp-server). It&#039;s started via this CLI command:

```
npx prisma mcp
```

Most AI tools support a JSON-based configuration for MCP servers looking like this:

```json
{
  &quot;mcpServers&quot;: {
    &quot;Prisma&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;prisma&quot;, &quot;mcp&quot;]
    }
  }
}
```

Prisma&#039;s MCP server gives AI agents the ability to manage [Prisma Postgres](https://www.prisma.io/postgres) databases (e.g. spin up new database instances or run schema migrations).

## Security

If you have a security issue to report, please contact us at [security@prisma.io](mailto:security@prisma.io?subject=[GitHub]%20Prisma%202%20Security%20Report%20).

## Support

### Ask a question about Prisma

You can ask questions and initiate [discussions](https://github.com/prisma/prisma/discussions/) about Prisma-related topics in the `prisma` repository on GitHub.

👉 [**Ask a question**](https://github.com/prisma/prisma/discussions/new)

### Create a bug report for Prisma

If you see an error message or run into an issue, please make sure to create a bug report! You can find [best practices for creating bug reports](https://www.prisma.io/docs/guides/other/troubleshooting-orm/creating-bug-reports) (like including additional debugging output) in the docs.

👉 [**Create bug report**](https://pris.ly/prisma-prisma-bug-report)

### Submit a feature request

If Prisma currently doesn&#039;t have a certain feature, be sure to check out the [roadmap](https://www.prisma.io/docs/more/roadmap) to see if this is already planned for the future.

If the feature on the roadmap is linked to a GitHub issue, please make sure to leave a 👍 reaction on the issue and ideally a comment with your thoughts about the feature!

👉 [**Submit feature request**](https://github.com/prisma/prisma/issues/new?assignees=&amp;labels=&amp;template=feature_request.md&amp;title=)

## Contributing

Refer to our [contribution guidelines](https://github.com/prisma/prisma/blob/main/CONTRIBUTING.md) and [Code of Conduct for contributors](https://github.com/prisma/prisma/blob/main/CODE_OF_CONDUCT.md).

## Tests Status

- Prisma Tests Status:
  [![Prisma Tests Status](https://github.com/prisma/prisma/workflows/CI/badge.svg)](https://github.com/prisma/prisma/actions/workflows/test.yml?query=branch%3Amain)
- Ecosystem Tests Status:
  [![Ecosystem Tests Status](https://github.com/prisma/ecosystem-tests/workflows/test/badge.svg)](https://github.com/prisma/ecosystem-tests/actions/workflows/test.yaml?query=branch%3Adev)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[material-components/material-web]]></title>
            <link>https://github.com/material-components/material-web</link>
            <guid>https://github.com/material-components/material-web</guid>
            <pubDate>Thu, 15 May 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[Material Design Web Components]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/material-components/material-web">material-components/material-web</a></h1>
            <p>Material Design Web Components</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,903</p>
            <p>Forks: 951</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre># Material Web

&lt;img src=&quot;./docs/images/material-web.gif&quot;
  title=&quot;Material web components&quot;
  alt=&quot;A collection of Material web components&quot;
  style=&quot;border-radius: 32px&quot;&gt;

[![Published on npm](https://img.shields.io/npm/v/%40material%2Fweb)](https://www.npmjs.com/package/@material/web)
[![Join our Discord](https://img.shields.io/badge/discord-join%20chat-5865F2.svg?logo=discord&amp;logoColor=fff&amp;label=%23material)](https://lit.dev/discord/)
[![Test status](https://github.com/material-components/material-web/actions/workflows/test.yml/badge.svg)](https://github.com/material-components/material-web/actions/workflows/test.yml)
[![npm Downloads](https://img.shields.io/npm/dm/%40material%2Fweb?label=npm%20downloads)](https://npm-stat.com/charts.html?package=%40material%2Fweb)
[![jsDelivr hits (npm)](https://img.shields.io/jsdelivr/npm/hm/%40material%2Fweb)](https://www.jsdelivr.com/package/npm/@material/web?tab=stats)

`@material/web` is a library of
[web components](https://developer.mozilla.org/en-US/docs/Web/Web_Components)&lt;!-- {.external} --&gt;
that helps build beautiful and accessible web applications. It uses
[Material 3](https://m3.material.io/)&lt;!-- {.external} --&gt;, the latest version of Google&#039;s
open-source design system.

**Note:
[MWC is in maintenance mode pending new maintainers](https://github.com/material-components/material-web/discussions/5642).**

## Resources

-   [Introduction](./docs/intro.md)
-   [Roadmap](./docs/roadmap.md)
-   [Component docs](./docs/components/)
-   [Bundle size](./docs/size.md)
-   [Browser support and FAQ](./docs/support.md)

## Quick start

&gt; Tip: Using Angular? We recommend using
&gt; [Angular Material](https://material.angular.io/)&lt;!-- {.external} --&gt; components
&gt; instead.

This code snippet is a buildless example that loads `@material/web` from a CDN.
Check out the [quick start](./docs/quick-start.md) guide to install and build
for production.

&lt;!-- LINT.IfChange --&gt;

```html
&lt;head&gt;
  &lt;link href=&quot;https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&amp;display=swap&quot; rel=&quot;stylesheet&quot;&gt;
  &lt;script type=&quot;importmap&quot;&gt;
    {
      &quot;imports&quot;: {
        &quot;@material/web/&quot;: &quot;https://esm.run/@material/web/&quot;
      }
    }
  &lt;/script&gt;
  &lt;script type=&quot;module&quot;&gt;
    import &#039;@material/web/all.js&#039;;
    import {styles as typescaleStyles} from &#039;@material/web/typography/md-typescale-styles.js&#039;;

    document.adoptedStyleSheets.push(typescaleStyles.styleSheet);
  &lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;h1 class=&quot;md-typescale-display-medium&quot;&gt;Hello Material!&lt;/h1&gt;
  &lt;form&gt;
    &lt;p class=&quot;md-typescale-body-medium&quot;&gt;Check out these controls in a form!&lt;/p&gt;
    &lt;md-checkbox&gt;&lt;/md-checkbox&gt;
    &lt;div&gt;
      &lt;md-radio name=&quot;group&quot;&gt;&lt;/md-radio&gt;
      &lt;md-radio name=&quot;group&quot;&gt;&lt;/md-radio&gt;
      &lt;md-radio name=&quot;group&quot;&gt;&lt;/md-radio&gt;
    &lt;/div&gt;

    &lt;md-outlined-text-field label=&quot;Favorite color&quot; value=&quot;Purple&quot;&gt;&lt;/md-outlined-text-field&gt;

    &lt;md-outlined-button type=&quot;reset&quot;&gt;Reset&lt;/md-outlined-button&gt;
  &lt;/form&gt;
  &lt;style&gt;
    form {
      display: flex;
      flex-direction: column;
      align-items: flex-start;
      gap: 16px;
    }
  &lt;/style&gt;
&lt;/body&gt;
```

&lt;!-- LINT.ThenChange(./g3doc/docs/quick-start.md) --&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>