<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Sat, 14 Feb 2026 00:08:21 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[ChromeDevTools/chrome-devtools-mcp]]></title>
            <link>https://github.com/ChromeDevTools/chrome-devtools-mcp</link>
            <guid>https://github.com/ChromeDevTools/chrome-devtools-mcp</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:21 GMT</pubDate>
            <description><![CDATA[Chrome DevTools for coding agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ChromeDevTools/chrome-devtools-mcp">ChromeDevTools/chrome-devtools-mcp</a></h1>
            <p>Chrome DevTools for coding agents</p>
            <p>Language: TypeScript</p>
            <p>Stars: 24,710</p>
            <p>Forks: 1,461</p>
            <p>Stars today: 363 stars today</p>
            <h2>README</h2><pre># Chrome DevTools MCP

[![npm chrome-devtools-mcp package](https://img.shields.io/npm/v/chrome-devtools-mcp.svg)](https://npmjs.org/package/chrome-devtools-mcp)

`chrome-devtools-mcp` lets your coding agent (such as Gemini, Claude, Cursor or Copilot)
control and inspect a live Chrome browser. It acts as a Model-Context-Protocol
(MCP) server, giving your AI coding assistant access to the full power of
Chrome DevTools for reliable automation, in-depth debugging, and performance analysis.

## [Tool reference](./docs/tool-reference.md) | [Changelog](./CHANGELOG.md) | [Contributing](./CONTRIBUTING.md) | [Troubleshooting](./docs/troubleshooting.md) | [Design Principles](./docs/design-principles.md)

## Key features

- **Get performance insights**: Uses [Chrome
  DevTools](https://github.com/ChromeDevTools/devtools-frontend) to record
  traces and extract actionable performance insights.
- **Advanced browser debugging**: Analyze network requests, take screenshots and
  check browser console messages (with source-mapped stack traces).
- **Reliable automation**. Uses
  [puppeteer](https://github.com/puppeteer/puppeteer) to automate actions in
  Chrome and automatically wait for action results.

## Disclaimers

`chrome-devtools-mcp` exposes content of the browser instance to the MCP clients
allowing them to inspect, debug, and modify any data in the browser or DevTools.
Avoid sharing sensitive or personal information that you don&#039;t want to share with
MCP clients.

Performance tools may send trace URLs to the Google CrUX API to fetch real-user
experience data. This helps provide a holistic performance picture by
presenting field data alongside lab data. This data is collected by the [Chrome
User Experience Report (CrUX)](https://developer.chrome.com/docs/crux). To disable
this, run with the `--no-performance-crux` flag.

## **Usage statistics**

Google collects usage statistics (such as tool invocation success rates, latency, and environment information) to improve the reliability and performance of Chrome DevTools MCP.

Data collection is **enabled by default**. You can opt-out by passing the `--no-usage-statistics` flag when starting the server:

```json
&quot;args&quot;: [&quot;-y&quot;, &quot;chrome-devtools-mcp@latest&quot;, &quot;--no-usage-statistics&quot;]
```

Google handles this data in accordance with the [Google Privacy Policy](https://policies.google.com/privacy).

Google&#039;s collection of usage statistics for Chrome DevTools MCP is independent from the Chrome browser&#039;s usage statistics. Opting out of Chrome metrics does not automatically opt you out of this tool, and vice-versa.

Collection is disabled if CHROME_DEVTOOLS_MCP_NO_USAGE_STATISTICS or CI env variables are set.

## Requirements

- [Node.js](https://nodejs.org/) v20.19 or a newer [latest maintenance LTS](https://github.com/nodejs/Release#release-schedule) version.
- [Chrome](https://www.google.com/chrome/) current stable version or newer.
- [npm](https://www.npmjs.com/).

## Getting started

Add the following config to your MCP client:

```json
{
  &quot;mcpServers&quot;: {
    &quot;chrome-devtools&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;chrome-devtools-mcp@latest&quot;]
    }
  }
}
```

&gt; [!NOTE]  
&gt; Using `chrome-devtools-mcp@latest` ensures that your MCP client will always use the latest version of the Chrome DevTools MCP server.

### MCP Client configuration

&lt;details&gt;
  &lt;summary&gt;Amp&lt;/summary&gt;
  Follow https://ampcode.com/manual#mcp and use the config provided above. You can also install the Chrome DevTools MCP server using the CLI:

```bash
amp mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
```

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Antigravity&lt;/summary&gt;

To use the Chrome DevTools MCP server follow the instructions from &lt;a href=&quot;https://antigravity.google/docs/mcp&quot;&gt;Antigravity&#039;s docs&lt;/a&gt; to install a custom MCP server. Add the following config to the MCP servers config:

```bash
{
  &quot;mcpServers&quot;: {
    &quot;chrome-devtools&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;chrome-devtools-mcp@latest&quot;,
        &quot;--browser-url=http://127.0.0.1:9222&quot;,
        &quot;-y&quot;
      ]
    }
  }
}
```

This will make the Chrome DevTools MCP server automatically connect to the browser that Antigravity is using. If you are not using port 9222, make sure to adjust accordingly.

Chrome DevTools MCP will not start the browser instance automatically using this approach as as the Chrome DevTools MCP server runs in Antigravity&#039;s built-in browser. If the browser is not already running, you have to start it first by clicking the Chrome icon at the top right corner.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Claude Code&lt;/summary&gt;

**Install via CLI (MCP only)**

Use the Claude Code CLI to add the Chrome DevTools MCP server (&lt;a href=&quot;https://code.claude.com/docs/en/mcp&quot;&gt;guide&lt;/a&gt;):

```bash
claude mcp add chrome-devtools --scope user npx chrome-devtools-mcp@latest
```

**Install as a Plugin (MCP + Skills)**

To install Chrome DevTools MCP with skills, add the marketplace registry in Claude Code:

```sh
/plugin marketplace add ChromeDevTools/chrome-devtools-mcp
```

Then, install the plugin:

```sh
/plugin install chrome-devtools-mcp
```

Restart Claude Code to have the MCP server and skills load (check with `/skills`).

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Cline&lt;/summary&gt;
  Follow https://docs.cline.bot/mcp/configuring-mcp-servers and use the config provided above.
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Codex&lt;/summary&gt;
  Follow the &lt;a href=&quot;https://github.com/openai/codex/blob/main/docs/advanced.md#model-context-protocol-mcp&quot;&gt;configure MCP guide&lt;/a&gt;
  using the standard config from above. You can also install the Chrome DevTools MCP server using the Codex CLI:

```bash
codex mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
```

**On Windows 11**

Configure the Chrome install location and increase the startup timeout by updating `.codex/config.toml` and adding the following `env` and `startup_timeout_ms` parameters:

```
[mcp_servers.chrome-devtools]
command = &quot;cmd&quot;
args = [
    &quot;/c&quot;,
    &quot;npx&quot;,
    &quot;-y&quot;,
    &quot;chrome-devtools-mcp@latest&quot;,
]
env = { SystemRoot=&quot;C:\\Windows&quot;, PROGRAMFILES=&quot;C:\\Program Files&quot; }
startup_timeout_ms = 20_000
```

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Copilot CLI&lt;/summary&gt;

Start Copilot CLI:

```
copilot
```

Start the dialog to add a new MCP server by running:

```
/mcp add
```

Configure the following fields and press `CTRL+S` to save the configuration:

- **Server name:** `chrome-devtools`
- **Server Type:** `[1] Local`
- **Command:** `npx -y chrome-devtools-mcp@latest`

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Copilot / VS Code&lt;/summary&gt;

**Click the button to install:**

[&lt;img src=&quot;https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&amp;label=Install%20Server&amp;color=0098FF&quot; alt=&quot;Install in VS Code&quot;&gt;](https://vscode.dev/redirect/mcp/install?name=io.github.ChromeDevTools%2Fchrome-devtools-mcp&amp;config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22chrome-devtools-mcp%22%5D%2C%22env%22%3A%7B%7D%7D)

[&lt;img src=&quot;https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&amp;label=Install%20Server&amp;color=24bfa5&quot; alt=&quot;Install in VS Code Insiders&quot;&gt;](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522io.github.ChromeDevTools%252Fchrome-devtools-mcp%2522%252C%2522config%2522%253A%257B%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522chrome-devtools-mcp%2522%255D%252C%2522env%2522%253A%257B%257D%257D%257D)

**Or install manually:**

Follow the MCP install &lt;a href=&quot;https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_add-an-mcp-server&quot;&gt;guide&lt;/a&gt;,
with the standard config from above. You can also install the Chrome DevTools MCP server using the VS Code CLI:

```bash
code --add-mcp &#039;{&quot;name&quot;:&quot;io.github.ChromeDevTools/chrome-devtools-mcp&quot;,&quot;command&quot;:&quot;npx&quot;,&quot;args&quot;:[&quot;-y&quot;,&quot;chrome-devtools-mcp&quot;],&quot;env&quot;:{}}&#039;
```

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Cursor&lt;/summary&gt;

**Click the button to install:**

[&lt;img src=&quot;https://cursor.com/deeplink/mcp-install-dark.svg&quot; alt=&quot;Install in Cursor&quot;&gt;](https://cursor.com/en/install-mcp?name=chrome-devtools&amp;config=eyJjb21tYW5kIjoibnB4IC15IGNocm9tZS1kZXZ0b29scy1tY3BAbGF0ZXN0In0%3D)

**Or install manually:**

Go to `Cursor Settings` -&gt; `MCP` -&gt; `New MCP Server`. Use the config provided above.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Factory CLI&lt;/summary&gt;
Use the Factory CLI to add the Chrome DevTools MCP server (&lt;a href=&quot;https://docs.factory.ai/cli/configuration/mcp&quot;&gt;guide&lt;/a&gt;):

```bash
droid mcp add chrome-devtools &quot;npx -y chrome-devtools-mcp@latest&quot;
```

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Gemini CLI&lt;/summary&gt;
Install the Chrome DevTools MCP server using the Gemini CLI.

**Project wide:**

```bash
# Either MCP only:
gemini mcp add chrome-devtools npx chrome-devtools-mcp@latest
# Or as a Gemini extension (MCP+Skills):
gemini extensions install --auto-update https://github.com/ChromeDevTools/chrome-devtools-mcp
```

**Globally:**

```bash
gemini mcp add -s user chrome-devtools npx chrome-devtools-mcp@latest
```

Alternatively, follow the &lt;a href=&quot;https://github.com/google-gemini/gemini-cli/blob/main/docs/tools/mcp-server.md#how-to-set-up-your-mcp-server&quot;&gt;MCP guide&lt;/a&gt; and use the standard config from above.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Gemini Code Assist&lt;/summary&gt;
  Follow the &lt;a href=&quot;https://cloud.google.com/gemini/docs/codeassist/use-agentic-chat-pair-programmer#configure-mcp-servers&quot;&gt;configure MCP guide&lt;/a&gt;
  using the standard config from above.
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;JetBrains AI Assistant &amp; Junie&lt;/summary&gt;

Go to `Settings | Tools | AI Assistant | Model Context Protocol (MCP)` -&gt; `Add`. Use the config provided above.
The same way chrome-devtools-mcp can be configured for JetBrains Junie in `Settings | Tools | Junie | MCP Settings` -&gt; `Add`. Use the config provided above.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Kiro&lt;/summary&gt;

In **Kiro Settings**, go to `Configure MCP` &gt; `Open Workspace or User MCP Config` &gt; Use the configuration snippet provided above.

Or, from the IDE **Activity Bar** &gt; `Kiro` &gt; `MCP Servers` &gt; `Click Open MCP Config`. Use the configuration snippet provided above.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Katalon Studio&lt;/summary&gt;

The Chrome DevTools MCP server can be used with &lt;a href=&quot;https://docs.katalon.com/katalon-studio/studioassist/mcp-servers/setting-up-chrome-devtools-mcp-server-for-studioassist&quot;&gt;Katalon StudioAssist&lt;/a&gt; via an MCP proxy.

**Step 1:** Install the MCP proxy by following the &lt;a href=&quot;https://docs.katalon.com/katalon-studio/studioassist/mcp-servers/setting-up-mcp-proxy-for-stdio-mcp-servers&quot;&gt;MCP proxy setup guide&lt;/a&gt;.

**Step 2:** Start the Chrome DevTools MCP server with the proxy:

```bash
mcp-proxy --transport streamablehttp --port 8080 -- npx -y chrome-devtools-mcp@latest
```

**Note:** You may need to pick another port if 8080 is already in use.

**Step 3:** In Katalon Studio, add the server to StudioAssist with the following settings:

- **Connection URL:** `http://127.0.0.1:8080/mcp`
- **Transport type:** `HTTP`

Once connected, the Chrome DevTools MCP tools will be available in StudioAssist.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;OpenCode&lt;/summary&gt;

Add the following configuration to your `opencode.json` file. If you don&#039;t have one, create it at `~/.config/opencode/opencode.json` (&lt;a href=&quot;https://opencode.ai/docs/mcp-servers&quot;&gt;guide&lt;/a&gt;):

```json
{
  &quot;$schema&quot;: &quot;https://opencode.ai/config.json&quot;,
  &quot;mcp&quot;: {
    &quot;chrome-devtools&quot;: {
      &quot;type&quot;: &quot;local&quot;,
      &quot;command&quot;: [&quot;npx&quot;, &quot;-y&quot;, &quot;chrome-devtools-mcp@latest&quot;]
    }
  }
}
```

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Qoder&lt;/summary&gt;

In **Qoder Settings**, go to `MCP Server` &gt; `+ Add` &gt; Use the configuration snippet provided above.

Alternatively, follow the &lt;a href=&quot;https://docs.qoder.com/user-guide/chat/model-context-protocol&quot;&gt;MCP guide&lt;/a&gt; and use the standard config from above.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Qoder CLI&lt;/summary&gt;

Install the Chrome DevTools MCP server using the Qoder CLI (&lt;a href=&quot;https://docs.qoder.com/cli/using-cli#mcp-servsers&quot;&gt;guide&lt;/a&gt;):

**Project wide:**

```bash
qodercli mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
```

**Globally:**

```bash
qodercli mcp add -s user chrome-devtools -- npx chrome-devtools-mcp@latest
```

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Visual Studio&lt;/summary&gt;
  
  **Click the button to install:**
  
  [&lt;img src=&quot;https://img.shields.io/badge/Visual_Studio-Install-C16FDE?logo=visualstudio&amp;logoColor=white&quot; alt=&quot;Install in Visual Studio&quot;&gt;](https://vs-open.link/mcp-install?%7B%22name%22%3A%22chrome-devtools%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22chrome-devtools-mcp%40latest%22%5D%7D)
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Warp&lt;/summary&gt;

Go to `Settings | AI | Manage MCP Servers` -&gt; `+ Add` to [add an MCP Server](https://docs.warp.dev/knowledge-and-collaboration/mcp#adding-an-mcp-server). Use the config provided above.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Windsurf&lt;/summary&gt;
  Follow the &lt;a href=&quot;https://docs.windsurf.com/windsurf/cascade/mcp#mcp-config-json&quot;&gt;configure MCP guide&lt;/a&gt;
  using the standard config from above.
&lt;/details&gt;

### Your first prompt

Enter the following prompt in your MCP Client to check if everything is working:

```
Check the performance of https://developers.chrome.com
```

Your MCP client should open the browser and record a performance trace.

&gt; [!NOTE]  
&gt; The MCP server will start the browser automatically once the MCP client uses a tool that requires a running browser instance. Connecting to the Chrome DevTools MCP server on its own will not automatically start the browser.

## Tools

If you run into any issues, checkout our [troubleshooting guide](./docs/troubleshooting.md).

&lt;!-- BEGIN AUTO GENERATED TOOLS --&gt;

- **Input automation** (8 tools)
  - [`click`](docs/tool-reference.md#click)
  - [`drag`](docs/tool-reference.md#drag)
  - [`fill`](docs/tool-reference.md#fill)
  - [`fill_form`](docs/tool-reference.md#fill_form)
  - [`handle_dialog`](docs/tool-reference.md#handle_dialog)
  - [`hover`](docs/tool-reference.md#hover)
  - [`press_key`](docs/tool-reference.md#press_key)
  - [`upload_file`](docs/tool-reference.md#upload_file)
- **Navigation automation** (6 tools)
  - [`close_page`](docs/tool-reference.md#close_page)
  - [`list_pages`](docs/tool-reference.md#list_pages)
  - [`navigate_page`](docs/tool-reference.md#navigate_page)
  - [`new_page`](docs/tool-reference.md#new_page)
  - [`select_page`](docs/tool-reference.md#select_page)
  - [`wait_for`](docs/tool-reference.md#wait_for)
- **Emulation** (2 tools)
  - [`emulate`](docs/tool-reference.md#emulate)
  - [`resize_page`](docs/tool-reference.md#resize_page)
- **Performance** (3 tools)
  - [`performance_analyze_insight`](docs/tool-reference.md#performance_analyze_insight)
  - [`performance_start_trace`](docs/tool-reference.md#performance_start_trace)
  - [`performance_stop_trace`](docs/tool-reference.md#performance_stop_trace)
- **Network** (2 tools)
  - [`get_network_request`](docs/tool-reference.md#get_network_request)
  - [`list_network_requests`](docs/tool-reference.md#list_network_requests)
- **Debugging** (5 tools)
  - [`evaluate_script`](docs/tool-reference.md#evaluate_script)
  - [`get_console_message`](docs/tool-reference.md#get_console_message)
  - [`list_console_messages`](docs/tool-reference.md#list_console_messages)
  - [`take_screenshot`](docs/tool-reference.md#take_screenshot)
  - [`take_snapshot`](docs/tool-reference.md#take_snapshot)

&lt;!-- END AUTO GENERATED TOOLS --&gt;

## Configuration

The Chrome DevTools MCP server supports the following configuration option:

&lt;!-- BEGIN AUTO GENERATED OPTIONS --&gt;

- **`--autoConnect`/ `--auto-connect`**
  If specified, automatically connects to a browser (Chrome 144+) running in the user data directory identified by the channel param. Requires the remoted debugging server to be started in the Chrome instance via chrome://inspect/#remote-debugging.
  - **Type:** boolean
  - **Default:** `false`

- **`--browserUrl`/ `--browser-url`, `-u`**
  Connect to a running, debuggable Chrome instance (e.g. `http://127.0.0.1:9222`). For more details see: https://github.com/ChromeDevTools/chrome-devtools-mcp#connecting-to-a-running-chrome-instance.
  - **Type:** string

- **`--wsEndpoint`/ `--ws-endpoint`, `-w`**
  WebSocket endpoint to connect to a running Chrome instance (e.g., ws://127.0.0.1:9222/devtools/browser/&lt;id&gt;). Alternative to --browserUrl.
  - **Type:** string

- **`--wsHeaders`/ `--ws-headers`**
  Custom headers for WebSocket connection in JSON format (e.g., &#039;{&quot;Authorization&quot;:&quot;Bearer token&quot;}&#039;). Only works with --wsEndpoint.
  - **Type:** string

- **`--headless`**
  Whether to run in headless (no UI) mode.
  - **Type:** boolean
  - **Default:** `false`

- **`--executablePath`/ `--executable-path`, `-e`**
  Path to custom Chrome executable.
  - **Type:** string

- **`--isolated`**
  If specified, creates a temporary user-data-dir that is automatically cleaned up after the browser is closed. Defaults to false.
  - **Type:** boolean

- **`--userDataDir`/ `--user-data-dir`**
  Path to the user data directory for Chrome. Default is $HOME/.cache/chrome-devtools-mcp/chrome-profile$CHANNEL_SUFFIX_IF_NON_STABLE
  - **Type:** string

- **`--channel`**
  Specify a different Chrome channel that should be used. The default is the stable channel version.
  - **Type:** string
  - **Choices:** `stable`, `canary`, `beta`, `dev`

- **`--logFile`/ `--log-file`**
  Path to a file to write debug logs to. Set the env variable `DEBUG` to `*` to enable verbose logs. Useful for submitting bug reports.
  - **Type:** string

- **`--viewport`**
  Initial viewport size for the Chrome instances started by the server. For example, `1280x720`. In headless mode, max size is 3840x2160px.
  - **Type:** string

- **`--proxyServer`/ `--proxy-server`**
  Proxy server configuration for Chrome passed as --proxy-server when launching the browser. See https://www.chromium.org/developers/design-documents/network-settings/ for details.
  - **Type:** string

- **`--acceptInsecureCerts`/ `--accept-insecure-certs`**
  If enabled, ignores errors relative to self-signed and expired certificates. Use with caution.
  - **Type:** boolean

- **`--chromeArg`/ `--chrome-arg`**
  Additional arguments for Chrome. Only applies when Chrome is launched by chrome-devtools-mcp.
  - **Type:** array

- **`--ignoreDefaultChromeArg`/ `--ignore-default-chrome-arg`**
  Explicitly disable default arguments for Chrome. Only applies when Chrome is launched by chrome-devtools-mcp.
  - **Type:** array

- **`--categoryEmulation`/ `--category-emulation`**
  Set to false to exclude tools related to emulation.
  - **Type:** boolean
  - **Default:** `true`

- **`--categoryPerformance`/ `--category-performance`**
  Set to false to exclude tools related to performance.
  - **Type:** boolean
  - **Default:** `true`

- **`--categoryNetwork`/ `--category-network`**
  Set to false to exclude tools related to network.
  - **Type:** boolean
  - **Default:** `true`

- **`--performanceCrux`/ `--performance-crux`**
  Set to false to disable sending URLs from performance traces to CrUX API to get field performance data.
  - **Type:** boolean
  - **Default:** `true`

- **`--usageStatistics`/ `--usage-statistics`**
  Set to false to opt-out of usage statistics collection. Google collects usage data to improve the tool, handled under the Google Privacy Policy (https://policies.google.com/privacy). This is independent from Chrome browser metrics. Disabled if CHROME_DEVTOOLS_MCP_NO_USAGE_STATISTICS or CI env variables are set.
  - **Type:** boolean
  - **Default:** `true`

&lt;!-- END AUTO GENERATED OPTIONS --&gt;

Pass them via the `args` property in the JSON configuration. For example:

```json
{
  &quot;mcpServers&quot;: {
    &quot;chrome-devtools&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;chrome-devtools-mcp@latest&quot;,
        &quot;--channel=canary&quot;,
        &quot;--headless=true&quot;,
        &quot;--isolated=true&quot;
      ]
    }
  }
}
```

### Connecting via WebSocket with custom headers

You can connect direct

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[danielmiessler/Personal_AI_Infrastructure]]></title>
            <link>https://github.com/danielmiessler/Personal_AI_Infrastructure</link>
            <guid>https://github.com/danielmiessler/Personal_AI_Infrastructure</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:20 GMT</pubDate>
            <description><![CDATA[Agentic AI Infrastructure for magnifying HUMAN capabilities.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/danielmiessler/Personal_AI_Infrastructure">danielmiessler/Personal_AI_Infrastructure</a></h1>
            <p>Agentic AI Infrastructure for magnifying HUMAN capabilities.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 8,023</p>
            <p>Forks: 1,132</p>
            <p>Stars today: 595 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./images/pai-logo-v7.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./images/pai-logo-v7.png&quot;&gt;
  &lt;img alt=&quot;PAI Logo&quot; src=&quot;./images/pai-logo-v7.png&quot; width=&quot;300&quot;&gt;
&lt;/picture&gt;

&lt;br/&gt;
&lt;br/&gt;

# Personal AI Infrastructure

[![Typing SVG](https://readme-typing-svg.demolab.com?font=Fira+Code&amp;weight=500&amp;size=24&amp;pause=1000&amp;color=60A5FA&amp;center=true&amp;vCenter=true&amp;width=600&amp;lines=Everyone+needs+access+to+the+best+AI.;AI+should+magnify+everyone.;Your+personal+AI+stack.)](https://github.com/danielmiessler/PAI)

&lt;br/&gt;

&lt;!-- Social Proof --&gt;
![Stars](https://img.shields.io/github/stars/danielmiessler/PAI?style=social)
![Forks](https://img.shields.io/github/forks/danielmiessler/PAI?style=social)
![Watchers](https://img.shields.io/github/watchers/danielmiessler/PAI?style=social)

&lt;!-- Project Health --&gt;
![Release](https://img.shields.io/github/v/release/danielmiessler/PAI?style=flat&amp;logo=github&amp;color=8B5CF6)
![Last Commit](https://img.shields.io/github/last-commit/danielmiessler/PAI?style=flat&amp;logo=git&amp;color=22C55E)
![Open Issues](https://img.shields.io/github/issues/danielmiessler/PAI?style=flat&amp;logo=github&amp;color=F97316)
![Open PRs](https://img.shields.io/github/issues-pr/danielmiessler/PAI?style=flat&amp;logo=github&amp;color=EC4899)
![License](https://img.shields.io/github/license/danielmiessler/PAI?style=flat&amp;color=60A5FA)

&lt;!-- Metrics --&gt;
![Discussions](https://img.shields.io/github/discussions/danielmiessler/PAI?style=flat&amp;logo=github&amp;label=Discussions&amp;color=EAB308)
![Commit Activity](https://img.shields.io/github/commit-activity/m/danielmiessler/PAI?style=flat&amp;logo=git&amp;label=Commits%2Fmo&amp;color=F59E0B)
![Repo Size](https://img.shields.io/github/repo-size/danielmiessler/PAI?style=flat&amp;logo=database&amp;label=Repo%20Size&amp;color=D97706)

&lt;!-- Content --&gt;
[![Get Started](https://img.shields.io/badge/üöÄ_Get_Started-Install-22C55E?style=flat)](#-installation)
[![Release v2.5](https://img.shields.io/badge/üì¶_Release-v2.5-8B5CF6?style=flat)](Releases/v2.5/)
[![Packs](https://img.shields.io/badge/üì¶_Packs-23-8B5CF6?style=flat)](Packs/)
[![Bundles](https://img.shields.io/badge/üéÅ_Bundles-1-F97316?style=flat)](Bundles/)
[![Contributors](https://img.shields.io/github/contributors/danielmiessler/PAI?style=flat&amp;logo=githubsponsors&amp;logoColor=white&amp;label=Contributors&amp;color=EC4899)](https://github.com/danielmiessler/PAI/graphs/contributors)

&lt;!-- Tech Stack --&gt;
[![Built with Claude](https://img.shields.io/badge/Built_with-Claude-D4A574?style=flat&amp;logo=anthropic&amp;logoColor=white)](https://claude.ai)
[![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=flat&amp;logo=typescript&amp;logoColor=white)](https://www.typescriptlang.org/)
[![Bun](https://img.shields.io/badge/Bun-000000?style=flat&amp;logo=bun&amp;logoColor=white)](https://bun.sh)
[![UL Community](https://img.shields.io/badge/UL_Community-5865F2?style=flat&amp;logo=discord&amp;logoColor=white)](https://danielmiessler.com/upgrade)

&lt;br/&gt;

**Overview:** [Purpose](#the-purpose-of-this-project) ¬∑ [What is PAI?](#what-is-pai) ¬∑ [New to AI?](#new-to-this-start-here) ¬∑ [Principles](#the-pai-principles) ¬∑ [Primitives](#pai-primitives)

**Get Started:** [Installation](#-installation) ¬∑ [Releases](Releases/) ¬∑ [Packs](#-packs) ¬∑ [Bundles](#-bundles)

**Resources:** [FAQ](#-faq) ¬∑ [Roadmap](#-roadmap) ¬∑ [Community](#-community) ¬∑ [Contributing](#-contributing)

&lt;br/&gt;

[![PAI Overview Video](https://img.youtube.com/vi/Le0DLrn7ta0/maxresdefault.jpg)](https://youtu.be/Le0DLrn7ta0)

**[Watch the full PAI walkthrough](https://youtu.be/Le0DLrn7ta0)** | **[Read: The Real Internet of Things](https://danielmiessler.com/blog/real-internet-of-things)**

---

&lt;/div&gt;

&gt; [!IMPORTANT]
&gt; **PAI v2.5.0 Released** ‚Äî Think Deeper, Execute Faster: Two-Pass Capability Selection, Thinking Tools with Justify-Exclusion, and Parallel-by-Default Execution.
&gt;
&gt; **[Release notes ‚Üí](Releases/v2.5/README.md)** | **[GitHub Release ‚Üí](https://github.com/danielmiessler/PAI/releases/tag/v2.5.0)**

&lt;div align=&quot;center&quot;&gt;

# AI should magnify everyone‚Äînot just the top 1%.

&lt;/div&gt;

## The Purpose of This Project

**PAI exists to solve what I believe is the [P0 problem](https://danielmiessler.com/telos) in the world:**

### Only a tiny fraction of humanity&#039;s creative potential is activated on Earth.

Most people don&#039;t believe they have valuable contributions to make. They think there are &quot;special&quot; people‚Äîand they aren&#039;t one of them. They&#039;ve never asked who they are, what they&#039;re about, and have never articulated or written it down. This makes them catastrophically vulnerable to AI displacement. Without activation, there is no high-agency.

So our goal with PAI is to activate people.

**PAI&#039;s mission is twofold:**

1. **Activate as many people as possible** ‚Äî Help people identify, articulate, and pursue their own purpose in life through AI-augmented self-discovery
2. **Make the best AI available in the world accessible to everyone** ‚Äî Ensure this quality of AI infrastructure isn&#039;t reserved for just the rich or technical elite.

That&#039;s why this is an open-source project instead of private.

---

## New to This? Start Here

You&#039;ve probably used ChatGPT or Claude. Type a question, get an answer. Simple.

You can think of AI systems as **three levels**:

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-eli5-diagram.png&quot; alt=&quot;The AI Evolution - From chatbots to your personal AI system&quot; width=&quot;800&quot;&gt;
&lt;/p&gt;

### Chatbots

ChatGPT, Claude, Gemini‚Äîyou ask something, it answers, and then it forgets everything. Next conversation starts fresh. No memory of you, your preferences, or what you talked about yesterday.

**The pattern:** Ask ‚Üí Answer ‚Üí Forget

### Agentic Platforms

Tools like Claude Code, Cursor, and Windsurf. The AI can actually *do* things‚Äîwrite code, browse the web, edit files, run commands.

**The pattern:** Ask ‚Üí Use tools ‚Üí Get result

More capable, but it still doesn&#039;t know *you*‚Äîyour goals, your preferences, your history.

### PAI (Personal AI Infrastructure)

Now your DA **learns and improves**:
- **Captures every signal** ‚Äî Ratings, sentiment, verification outcomes
- **Learns from mistakes** ‚Äî Failures get analyzed and fixed
- **Gets better over time** ‚Äî Success patterns get reinforced
- **Upgrades itself** ‚Äî Skills, workflows, even the core behavior evolves

Plus it knows:
- **Your goals** ‚Äî What you&#039;re working toward
- **Your preferences** ‚Äî How you like things done
- **Your history** ‚Äî Past decisions and learnings

**The pattern:** Observe ‚Üí Think ‚Üí Plan ‚Üí Execute ‚Üí Verify ‚Üí **Learn** ‚Üí Improve

The key difference: **PAI learns from feedback**. Every interaction makes it better at helping *you* specifically.

---

## What is PAI?

PAI is a Personalized AI Platform designed to magnify your capabilities.

It&#039;s designed for humans most of all, but can be used by teams, companies, or Federations of Planets desiring to be better versions of themselves.

The scale of the entity doesn&#039;t matter: It&#039;s a system for understanding, articulating, and realizing its principal&#039;s goals using a full-featured Agentic AI Platform.

### Who is PAI for?

**Everyone, full stop.** It&#039;s the anti-gatekeeping AI project.

- **Small business owners** who aren&#039;t technical but want AI to handle invoicing, scheduling, customer follow-ups, and marketing
- **Companies** who want to understand their data, optimize operations, and make better decisions
- **Managers** who want to run their teams more effectively‚Äîtracking projects, preparing for reviews, and communicating clearly
- **Artists and creatives** who want to find local events, galleries, and opportunities to showcase their work
- **Everyday people** who want to improve their lives‚Äîbetter fitness routines, stronger social connections, personal finance, or just getting organized
- **Developers** using AI coding assistants who want persistent memory and custom workflows
- **Power users** who want their AI to know their goals, preferences, and context
- **Teams** building shared AI infrastructure with consistent capabilities
- **Experimenters** interested in AI system design and personal AI patterns

### What makes PAI different?

The first thing people ask is:

&gt; How is this different from Claude Code, or any of the other agentic systems?

Most agentic systems are built around tools with the user being an afterthought. They are also mostly task-based instead of being goal-based using all the context available to them. PAI is the opposite.

**Three core differentiators:**

1. **Goal Orientation** ‚Äî PAI&#039;s primary focus is on the human running it and what they&#039;re trying to do in the world, not the tech. This is built into how the system executes all tasks.

2. **Pursuit of Optimal Output** ‚Äî The system&#039;s outer loop and everything it does is trying to produce the exact right output given the current situation and all the contexts around it.

3. **Continuous Learning** ‚Äî The system constantly captures signals about what was done, what changes were made, what outputs were produced for each request, and then how you liked or disliked the results.

---

## The PAI Principles

These principles guide how PAI systems are designed and built. **[Full breakdown ‚Üí](https://danielmiessler.com/blog/personal-ai-infrastructure)**

| # | Principle | Summary |
|---|-----------|---------|
| 1 | **User Centricity** | PAI is built around you, not tooling. Your goals, preferences, and context come first‚Äîthe infrastructure exists to serve them. |
| 2 | **The Foundational Algorithm** | The scientific method as a universal problem-solving loop: Observe ‚Üí Think ‚Üí Plan ‚Üí Build ‚Üí Execute ‚Üí Verify ‚Üí Learn. Define the ideal state, iterate until you reach it. |
| 3 | **Clear Thinking First** | Good prompts come from clear thinking. Clarify the problem before writing the prompt. |
| 4 | **Scaffolding &gt; Model** | System architecture matters more than which model you use. |
| 5 | **Deterministic Infrastructure** | AI is probabilistic; your infrastructure shouldn&#039;t be. Use templates and patterns. |
| 6 | **Code Before Prompts** | If you can solve it with a bash script, don&#039;t use AI. |
| 7 | **Spec / Test / Evals First** | Write specifications and tests before building. Measure if the system works. |
| 8 | **UNIX Philosophy** | Do one thing well. Make tools composable. Use text interfaces. |
| 9 | **ENG / SRE Principles** | Treat AI infrastructure like production software: version control, automation, monitoring. |
| 10 | **CLI as Interface** | Command-line interfaces are faster, more scriptable, and more reliable than GUIs. |
| 11 | **Goal ‚Üí Code ‚Üí CLI ‚Üí Prompts ‚Üí Agents** | The decision hierarchy: clarify goal, then code, then CLI, then prompts, then agents. |
| 12 | **Skill Management** | Modular capabilities that route intelligently based on context. |
| 13 | **Memory System** | Everything worth knowing gets captured. History feeds future context. |
| 14 | **Agent Personalities** | Different work needs different approaches. Specialized agents with unique voices. |
| 15 | **Science as Meta-Loop** | Hypothesis ‚Üí Experiment ‚Üí Measure ‚Üí Iterate. |
| 16 | **Permission to Fail** | Explicit permission to say &quot;I don&#039;t know&quot; prevents hallucinations. |

---

## PAI Primitives

While the Principles describe the *philosophy* of PAI, the Primitives are the *architecture*‚Äîthe core systems that make everything work.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-unique-components-diagram.png&quot; alt=&quot;PAI Primitives - A system that knows you, not a tool harness&quot; width=&quot;800&quot;&gt;
&lt;/p&gt;

These primitives work together to create the experience of working with a system that understands and knows you‚Äîas opposed to a tool harness that just executes commands.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-1-assistant-vs-agent.png&quot; alt=&quot;Assistant vs Agent-Based Interaction&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Assistant vs. Agent-Based AI Interaction

PAI treats AI as a [persistent assistant, friend, coach, and mentor](https://danielmiessler.com/blog/personal-ai-maturity-model) rather than a stateless agent that runs tasks. An assistant knows your goals, remembers your preferences, and improves over time. An agent executes commands and forgets.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-primitive-telos.png&quot; alt=&quot;TELOS - Deep Goal Understanding&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### TELOS (Deep Goal Understanding)

10 files that capture who you are: MISSION.md, GOALS.md, PROJECTS.md, BELIEFS.md, MODELS.md, STRATEGIES.md, NARRATIVES.md, LEARNED.md, CHALLENGES.md, IDEAS.md. Your DA knows what you&#039;re working toward because it&#039;s all documented.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-primitive-user-system-separation.png&quot; alt=&quot;User/System Separation&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### User/System Separation

Your customizations live in USER/. PAI infrastructure lives in SYSTEM/. When PAI upgrades, your files are untouched. Portable identity, upgrade-safe.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-primitive-customization.png&quot; alt=&quot;Granular Customization&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Granular Customization

Six layers of customization: Identity (name, voice, personality), Preferences (tech stack, tools), Workflows (how skills execute), Skills (what capabilities exist), Hooks (how events are handled), and Memory (what gets captured). Start with defaults, customize when needed.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-2-skill-system.png&quot; alt=&quot;Skill System&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Skill System

Highly focused on consistent results. It has a structure that puts *deterministic outcomes first* by going from CODE -&gt; CLI-BASED-TOOL -&gt; PROMPT -&gt; SKILL instead of a haphazard structure.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-3-memory-system.png&quot; alt=&quot;Memory System&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Memory System

Focused on continuous learning. Every interaction generates signals‚Äîratings, sentiment, successes, failures‚Äîthat feed back into improving the system. Three-tier architecture (hot/warm/cold) with phase-based learning directories.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-6-hook-system.png&quot; alt=&quot;Hook System&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Hook System

Responds to lifecycle events‚Äîsession start, tool use, task completion, and more. 8 event types enable voice notifications, automatic context loading, session capture, security validation, and observability.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-5-security-system.png&quot; alt=&quot;Security System&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Security System

Defines system and user-level security policies by default. You don&#039;t have to run with `--dangerously-skip-permissions` to have an uninterrupted experience. PAI&#039;s security hooks validate commands before execution, blocking dangerous operations while allowing normal workflows to proceed smoothly.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-4-ai-installation.png&quot; alt=&quot;AI-Based Installation&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### AI-Based Installation

Your AI assistant reads the packs, understands your system, and installs everything for you. No manual configuration, no guessing‚Äîthe AI handles it.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-8-notification-system.png&quot; alt=&quot;Notification System&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Notification System

Keeps you informed without being intrusive. Push notifications via ntfy for mobile alerts, Discord integration for team updates, and duration-aware routing that escalates for long-running tasks. Fire-and-forget design means notifications never block your workflow.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-9-voice-system.png&quot; alt=&quot;Voice System&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Voice System

Powered by ElevenLabs TTS. Hear task completions, session summaries, and important updates spoken aloud. Prosody enhancement makes speech sound natural. Your AI has a voice.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-7-terminal-ui.png&quot; alt=&quot;Terminal-Based UI&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Terminal-Based UI

Rich tab titles and pane management. Dynamic status lines show learning signals, context usage, and current task state. Your terminal is a command center.

---

## üöÄ Installation

&gt; [!CAUTION]
&gt; **Project in Active Development** ‚Äî PAI is evolving rapidly. Expect breaking changes, restructuring, and frequent updates. We are working on stable and development branches, but currently it&#039;s all combined.

### Which Install Path Should I Use?

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Do you want a complete, working PAI system right now?          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ     YES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Option 1: Full Release Install              ‚îÇ
‚îÇ                     (Complete .claude/ directory, ~5 min)       ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ     NO, I want to customize or learn the system                 ‚îÇ
‚îÇ         ‚îÇ                                                       ‚îÇ
‚îÇ         ‚îú‚îÄ‚îÄ‚ñ∫ Option 2: Bundle + Packs (Build it yourself)       ‚îÇ
‚îÇ         ‚îÇ    (Skeleton structure, then install packs manually)  ‚îÇ
‚îÇ         ‚îÇ                                                       ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚ñ∫ Option 3: Individual Packs (Cherry-pick)           ‚îÇ
‚îÇ              (Install only specific capabilities you need)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Option 1: Full Release Install (Recommended)

&gt; **This is the fastest path to a working PAI system.** You get a complete, pre-configured `.claude/` directory with all infrastructure packs already installed.

```bash
# Clone the repo
git clone https://github.com/danielmiessler/PAI.git
cd PAI/Releases/v2.5

# Back up your existing Claude Code configuration (if any)
[ -d ~/.claude ] &amp;&amp; mv ~/.claude ~/.claude-backup-$(date +%Y%m%d)

# Copy the complete PAI installation
cp -r .claude ~/

# Run the configuration wizard
cd ~/.claude &amp;&amp; bun run INSTALL.ts
```

**The wizard will:**
- Ask for your name, DA name, and timezone
- Configure environment variables (works with both bash and zsh)
- Set up voice preferences (optional)
- Verify the installation

**After installation:** Restart Claude Code to activate hooks.

[**Full Release documentation ‚Üí**](Releases/v2.5/README.md)

---

### Option 2: Bundle + Manual Pack Installation

&gt; **For users who want to understand the system** as they build it, or need a customized setup.

&gt; [!WARNING]
&gt; The Bundle wizard creates a **skeleton directory structure only**. You must then install each pack manually in the correct order for a working system.

```bash
# Clone the repo
git clone https://github.com/danielmiessler/PAI.git
cd PAI/Bundles/Official

# Run the interactive wizard (creates skeleton structure)
bun run install.ts
```

**After the wizard completes, you MUST install packs in this order:**

| Order | Pack | Command |
|-------|------|---------|
| 1 | pai-hook-system | &quot;Install the pack at PAI/Packs/pai-hook-system/&quot; |
| 2 | pai-core-install | &quot;Install the pack at PAI/Packs/pai-core-install/&quot; |
| 3 | pai-statusline | &quot;Install the pack at PAI/Packs/pai-statusline/&quot; |
| 4+ | Any skill packs | Install as needed |

[**Bundle documentation ‚Üí**](Bundles/Official/README.md)

---

### Option 3: Individual Pack Installation

Install individual packs by giving them to your DA:

1. **Browse packs** - Find a pack you want in [Packs/](Packs/)
2. **Give it to your DA** - Provide the pack directory path
3. **Ask your DA to install it:**

```
Install this pack into my system. Use PAI_DIR=&quot;~/.claude&quot;
and DA=&quot;MyAI&quot;. Set up the hooks, save the code, and verify it works.
```

### Option 4: Browse and Cherry-Pick

Packs are self-contained. You can:
- Read the code directly in the pack
- Copy specific functions or workflows
- Adapt the approach to your own system
- Use it as reference documentation

**No forced structure. No mandatory setup. Take what&#039;s useful, leave the rest.**

---

## üì¶ Packs

PAI capabilities are distributed as **Packs**‚Äîse

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[CyberTimon/RapidRAW]]></title>
            <link>https://github.com/CyberTimon/RapidRAW</link>
            <guid>https://github.com/CyberTimon/RapidRAW</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:19 GMT</pubDate>
            <description><![CDATA[A beautiful, non-destructive, and GPU-accelerated RAW image editor built with performance in mind.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/CyberTimon/RapidRAW">CyberTimon/RapidRAW</a></h1>
            <p>A beautiful, non-destructive, and GPU-accelerated RAW image editor built with performance in mind.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 4,980</p>
            <p>Forks: 164</p>
            <p>Stars today: 86 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/editor.png&quot; alt=&quot;RapidRAW Editor&quot;&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![Rust](https://img.shields.io/badge/rust-%23000000.svg?style=for-the-badge&amp;logo=rust&amp;logoColor=white)](https://www.rust-lang.org/)
[![wgpu](https://img.shields.io/badge/wgpu-%23282C34.svg?style=for-the-badge&amp;logo=webgpu&amp;logoColor=white)](https://wgpu.rs/)
[![React](https://img.shields.io/badge/react-%2320232a.svg?style=for-the-badge&amp;logo=react&amp;logoColor=%2361DAFB)](https://react.dev/)
[![Tauri](https://img.shields.io/badge/Tauri-24C8DB?style=for-the-badge&amp;logo=tauri&amp;logoColor=white)](https://tauri.app/)
[![AGPL-3.0](https://img.shields.io/badge/License-AGPL_v3-blue.svg?style=for-the-badge)](https://opensource.org/licenses/AGPL-3.0)
[![GitHub stars](https://img.shields.io/github/stars/CyberTimon/RapidRAW?style=for-the-badge&amp;logo=github&amp;label=Stars)](https://github.com/CyberTimon/RapidRAW/stargazers)
&lt;br&gt;
[![www.getrapidraw.com](https://img.shields.io/badge/getrapidraw.com-%232ea44f?style=for-the-badge&amp;logo=safari&amp;logoColor=white)](https://www.getrapidraw.com)
[![Instagram](https://img.shields.io/badge/Instagram-%23E4405F.svg?style=for-the-badge&amp;logo=Instagram&amp;logoColor=white)](https://www.instagram.com/getrapidraw/)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.gg/cvFugZ2Hw8)

&lt;/div&gt;

# RapidRAW

&gt; A beautiful, non-destructive, and GPU-accelerated RAW image editor built with performance in mind.

RapidRAW is a modern, high-performance alternative to Adobe Lightroom¬Æ. It delivers a simple, beautiful editing experience in a lightweight package (under 20MB) for Windows, macOS, and Linux.

I started developing this project as a personal challenge when I was 18. My goal was to create a high-performance tool for my own photography workflow while deepening my understanding of React, WGSL and Rust, with the support from Google Gemini.

&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot; align=&quot;center&quot;&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://github.com/CyberTimon/RapidRAW/releases/latest&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/CyberTimon/RapidRAW/main/src-tauri/icons/full_res_original.png&quot; alt=&quot;Download RapidRAW&quot; height=&quot;96&quot;&gt;
      &lt;/a&gt;
      &lt;h3&gt;Download RapidRAW&lt;/h3&gt;
      &lt;p&gt;Get the latest release for Windows, macOS, and Linux. Packaged and ready to run.&lt;/p&gt;
      &lt;strong&gt;&lt;a href=&quot;https://github.com/CyberTimon/RapidRAW/releases/latest&quot;&gt;Download Latest Version ‚Üí&lt;/a&gt;&lt;/strong&gt;
      &lt;br&gt;&lt;br&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot; align=&quot;center&quot;&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://github.com/CyberTimon/RapidRAW-Docs&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/CyberTimon/RapidRAW/main/src-tauri/icons/docs.png&quot; alt=&quot;Read the Docs&quot; height=&quot;96&quot;&gt;
      &lt;/a&gt;
      &lt;h3&gt;Read the Docs&lt;/h3&gt;
      &lt;p&gt;Learn how to use RapidRAW with step-by-step tutorials, from adjustments to masking.&lt;/p&gt;
      &lt;strong&gt;&lt;a href=&quot;https://github.com/CyberTimon/RapidRAW-Docs&quot;&gt;View Tutorials &amp; Examples ‚Üí&lt;/a&gt;&lt;/strong&gt;
      &lt;br&gt;&lt;br&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;For Who Is This?&lt;/strong&gt;&lt;/summary&gt;
RapidRAW is for photographers who love to edit their photos in a &lt;strong&gt;clean, fast, and simple workflow&lt;/strong&gt;. It prioritizes speed, a beautiful user interface, and powerful tools that let you achieve your creative color vision quickly.
&lt;br&gt;&lt;br&gt;
It is &lt;strong&gt;not&lt;/strong&gt; for users who seek absolute, perfect color accuracy. While the results are great for most purposes, the focus is on a fluid, creative process rather than perfect color precision.
&lt;br&gt;&lt;br&gt;
RapidRAW is still in active development and isn&#039;t yet as polished as mature tools like Darktable, RawTherapee, or Adobe Lightroom¬Æ. Right now, the focus is on building a fast, enjoyable core editing experience. You may encounter bugs - if you do, please report them so I can fix them :) Your feedback really helps!
&lt;br&gt;&lt;br&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Recent Changes&lt;/strong&gt;&lt;/summary&gt;

*   **2026-02-12:** Straight brush mask lines using shift click and enhanced Lensfun DB parsing
*   **2026-02-10:** Improved image loading performance
*   **2026-02-06:** Refactored negative conversion logic using characteristic curves.
*   **2026-02-04:** Global tooltips &amp; major UI polish
*   **2026-02-03:** New creative effects: Glow, Halation &amp; Lens Flares
*   **2026-01-31:** Accurate color noise reduction for RAW images &amp; improved image loading
*   **2026-01-30:** Enhanced Lensfun DB parsing and improved lens matching logic
*   **2026-01-29:** Add cross-channel copy/paste &amp; flat-line clipping logic for curves
*   **2026-01-26:** Favorite lens saving, improved rotation controls (finer grid), better local contrast adjustments
*   **2026-01-25:** Filmstrip performance boost, improved sorting, lens distortion fixes for AI masks &amp; crop

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Expand further&lt;/strong&gt;&lt;/summary&gt;

*   **2026-01-24:** Added automatic lens, TCA &amp; vignette correction using lensfun
*   **2026-01-22:** Improved and centralized EXIF data handling for greater accuracy and support
*   **2026-01-21:** Inpainting now works correctly on images with geometry transformations
*   **2026-01-20:** Export preset management for saving export settings 
*   **2026-01-19:** Preload library for faster startup &amp; automatic geometry transformation helper lines
*   **2026-01-18:** Implement image geometry transformation utils
*   **2026-01-17:** Refactor AI panel to correctly work with the new masking system
*   **2026-01-16:** Major masking system overhaul with drag &amp; drop, per-mask opacity/invert &amp; UI improvements
*   **2026-01-13:** New python middleware client for external generative AI integration (ComfyUI)
*   **2026-01-12:** Created a RapidRAW community discord server
*   **2026-01-11:** Separate preview worker, optional high-quality live previews &amp; mask/ai patch caching
*   **2026-01-10:** Enhanced EXIF UI, optimized color wheels/curves &amp; rawler update
*   **2026-01-09:** Live previews for all adjustments &amp; masks with optimized GPU processing
*   **2026-01-05:** Collage maker upgrade (drag &amp; drop, zoom, ratio options)
*   **2026-01-05:** &#039;Prefer RAW&#039; filter option added to library
*   **2026-01-05:** Support for uppercase file extensions
*   **2026-01-05:** Flush thumbnail cache on folder switch
*   **2025-12-27:** Fix LUT banding issues with improved sampling
*   **2025-12-26:** AI masking stability improvements under load
*   **2025-12-23:** Metadata card in toolbar &amp; context menu export
*   **2025-12-23:** Monochromatic grain &amp; white balance picker improvements
*   **2025-12-22:** BM3D Denoising with comparison slider
*   **2025-12-20:** Batch export stability improvements &amp; RAM optimization
*   **2025-12-14:** Exposure slider added to masking tools
*   **2025-12-14:** Improved delete workflow
*   **2025-12-08:** Improved mask eraser tool behavior &amp; ORT v2 migration
*   **2025-12-07:** Write EXIF metadata to file
*   **2025-12-07:** Color picker for white balance
*   **2025-11-30:** HSL luminance artifacts fix
*   **2025-11-29:** Improved mask stacking &amp; many bug fixes
*   **2025-11-28:** QOI support
*   **2025-11-25:** Update rawler
*   **2025-11-23:** Recursive library view to display images from all subfolders
*   **2025-11-22:** DNG loader improvements
*   **2025-11-18:** Improved vibrancy adjustment
*   **2025-11-15:** Virtual copies &amp; library improvements
*   **2025-11-14:** Open-with-file cross plattform compatibilty &amp; single instance lock
*   **2025-11-13:** Rewritten tagging system to support pill-like image tagging
*   **2025-11-10:** Improved folder tree with search functionality
*   **2025-11-08:** Added EXR file format support
*   **2025-11-XX:** Improving AgX
*   **2025-11-02:** Optimize image loading &amp; add processing engine settings
*   **2025-10-31:** Expose highlights compression point to user &amp; improve keybinds detection
*   **2025-10-28:** Copy paste settings &amp; brightness adjustment
*   **2025-10-XX:** Working on tonemapping - ongoing...
*   **2025-10-24:** Getting AgX right isn&#039;t as easy as it seems :=)
*   **2025-10-22:** AgX tone mapping
*   **2025-10-19:** Whole image mask component &amp; organize mask components better
*   **2025-10-19:** You can now apply presets to masks &amp; improved auto adjustments
*   **2025-10-17:** New centr√© adjustment, rawler now as a submodule &amp; improved logger
*   **2025-10-15:** Ability to pin folders, improved session handling &amp; smooth library thumbnail updating
*   **2025-10-11:** Realistic, complex &amp; non-dulling exposure &amp; highlights slider
*   **2025-10-11:** Smooth filmstrip thumbnail updates
*   **2025-10-07:** New watermarking support
*   **2025-10-06:** Improve crop quality by transforming before scaling
*   **2025-10-XX:** Many small improvements - ongoing...
*   **2025-09-27:** Sort library by exif metadata &amp; release cleanup / bug fixes
*   **2025-09-26:** Collage maker to create unique collages with many different layouts, spacing &amp; border radius
*   **2025-09-23:** Color calibration tool to adjust RGB primaries &amp; adjustments visibility settings
*   **2025-09-22:** Issue template &amp; CI/CD improvements
*   **2025-09-20:** Universal presets importer, prioritize dGPU &amp; improved local contrast tools (sharpness, clarity etc.)
*   **2025-09-17:** Automatic image culling (duplicate &amp; blur detection)
*   **2025-09-14:** Grid previews in community panel &amp; improved ComfyUi workflow
*   **2025-09-12:** New community presets panel to share &amp; showcase presets
*   **2025-09-10:** Extended generative AI roadmap &amp; started building RapidRAW website
*   **2025-09-09:** Many shader improvements &amp; bug fixes, invert tint slider
*   **2025-09-06:** New update notifier that alerts users when a new version becomes available
*   **2025-09-04:** Added toggleable clipping warnings (blue = shadows, red = highlights)
*   **2025-09-02:** Transition to Rust 2024 &amp; Cache image on GPU
*   **2025-08-31:** Cancel thumbnail generation on folder change &amp; optimized ai patch saving  
*   **2025-08-30:** Optimize ComfyUI image transfer &amp; speed
*   **2025-08-28:** Chromatic aberration correction &amp; Shader improvements
*   **2025-08-26:** User customisable ComfyUI workflow selection
*   **2025-08-25:** Make LUTs parser more robust (support more advanced formats)
*   **2025-08-24:** Improved keyboard shortcuts
*   **2025-08-23:** Estimate file size before exporting
*   **2025-08-21:** Added LUTs (.cube, .3dl, .png, .jpg, .jpeg, .tiff) support
*   **2025-08-16:** Fast AI sky masks
*   **2025-08-15:** Show full resolution image when zooming in
*   **2025-08-15:** Implement Tauri&#039;s IPC as a replacement for the slow Base64 image transfer
*   **2025-08-12:** Relative zoom indicator
*   **2025-08-11:** TypeScript cleanup &amp; many bug fixes
*   **2025-08-09:** Local inpainting without the need for ComfyUI, ability to change thumbnail aspect ratio
*   **2025-08-09:** Frontend refactored to TypeScript thanks to @varjolintu
*   **2025-08-08:** New onnxruntime download strategy &amp; the base for local inpainting
*   **2025-08-05:** Improved HSL cascading, UI &amp; animation improvements, ability to grow &amp; shrink / feather AI masks
*   **2025-08-03:** New high performance, seamless image panorama stitcher (without any dependencies on OpenCV)
*   **2025-08-02:** Added an image straightening tool and improved crop &amp; rotation functionality (especially on portrait images)
*   **2025-08-02:** A new dedicated image importer, ability to rename and batch rename files, improved dark theme, and other fixes
*   **2025-07-31:** Ability to tag &amp; filter images by color labels, refactored image right clicking
*   **2025-07-31:** Reimplemented the functionality of GPU processing (GPU cropping, etc.) -&gt; No longer dependent on TEXTURE_BINDING_ARRAY
*   **2025-07-29:** Refactored generative AI foundation, many small fixes
*   **2025-07-27:** Automatic AI image tagging, overall mask transparency setting per mask
*   **2025-07-25:** Fuji RAF X-Trans sensor support (new x-trans demosaicing algo)
*   **2025-07-24:** Auto crop when cropping an image (to prevent black borders), added drag &amp; drop sort abilty to presets panel
*   **2025-07-22:** Significant improvements to the shader: More accurate exposure slider, better tone mapper (simplified ACES)
*   **2025-07-21:** Remember scroll position when going into the editing section
*   **2025-07-20:** Ability to add presets to folders, export preset folders etc, preset _animations_
*   **2025-07-20:** Tutorials on how to use RapidRAW
*   **2025-07-19:** Initial color negative conversion implementation, shader improvements
*   **2025-07-19:** New color wheels, persistent collapsed / expanded state for UI elements
*   **2025-07-19:** Fixed banding &amp; purple artefacts on RAW images, better color noise reduction, show exposure in stops
*   **2025-07-18:** Smooth zoom slider, new adaptive editor theme setting
*   **2025-07-18:** New export functionality: Export with metadata, GPS metadata remover, batch export file naming scheme using tags
*   **2025-07-18:** Ability to delete the associated RAW/JPEG in right click delete operations
*   **2025-07-17:** Small bug fixes
*   **2025-07-13:** Native looking titlebar and ability to input precise number into sliders
*   **2025-07-13:** Huge update to masks: You can now add multiple masks to a mask containers, subtract / add / combine masks etc.
*   **2025-07-12:** Improved curves tool, more shader improvements, improved handling of very large files
*   **2025-07-11:** More accurate shader, reorganized main library preferences dropdown, smoother histogram, more realistic film grain
*   **2025-07-11:** Added a HUD-like waveform overlay toggle to display specific channel waveforms (w-key)
*   **2025-07-10:** Rewritten batch export system and async thumbnail generation (makes the loading of large folders a lot more fluid)
*   **2025-07-10:** Window transparency can now be toggled in the settings, thanks to @andrewazores
*   **2025-07-08:** Ability to toggle the visibility of individual adjustments sections
*   **2025-07-08:** Fixed top-left zoom bug, corrected scale behavior in crop panel, keep default original aspect ratio
*   **2025-07-08:** Added image rating filter and redesigned the metadata panel with improved layout, clearer sections, and an embedded GPS map
*   **2025-07-07:** Improved generative AI features and updated [AI Roadmap](#ai-roadmap)
*   **2025-07-06:** Initial generative AI integration with [ComfyUI](https://github.com/comfyanonymous/ComfyUI) - for more details, checkout the [AI Roadmap](#ai-roadmap)
*   **2025-07-05:** Ability to overwrite preset with current settings
*   **2025-07-04:** High speed and precise cache to significantly accelerate large image editing
*   **2025-07-04:** Greatly improved shader with better dehaze, more accurate curves etc
*   **2025-07-04:** Predefined 90¬∞ clockwise rotation and ability to flip images
*   **2025-07-03:** Switched from [rawloader](https://github.com/pedrocr/rawloader) to [rawler](https://github.com/dnglab/dnglab/tree/main/rawler) to support a wider range of RAW formats
*   **2025-07-02:** AI-powered foreground / background masking
*   **2025-06-30:** AI-powered subject masking
*   **2025-06-30:** Precompiled Linux builds
*   **2025-06-29:** New 5:4 aspect ratio, new low contrast grey theme and more cameras support (DJI Mavic lineup)
*   **2025-06-28:** Release cleanup, CI/CD improvements and minor fixes
*   **2025-06-27:** Initial release. For more information about the earlier progress, look at the [Initial Development Log](#initial-development-log)

&lt;/details&gt;
&lt;/details&gt;
&lt;br&gt;

**Table of Contents**
- [Key Features](#key-features)
- [Demo &amp; Screenshots](#demo--screenshots)
- [The Idea](#the-idea)
- [Current Priorities](#current-priorities)
- [AI Roadmap](#ai-roadmap)
- [Initial Development Log](#initial-development-log)
- [Getting Started](#getting-started)
- [System Requirements](#system-requirements)
- [Contributing](#contributing)
- [Special Thanks](#special-thanks)
- [Support the Project](#support-the-project)
- [License &amp; Philosophy](#license--philosophy)

---

## Key Features

&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td valign=&quot;top&quot; width=&quot;50%&quot;&gt;
      &lt;h4&gt;Core Editing Engine&lt;/h4&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;GPU-Accelerated:&lt;/strong&gt; Full 32-bit image processing pipeline written in WGSL for instant feedback.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Masking:&lt;/strong&gt; Layer-based masking with AI subject, sky and foreground detection. Combine with traditional masks for great control.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Generative Edits:&lt;/strong&gt; Remove or add elements using text prompts, powered by an optional AI backend.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Full RAW Support:&lt;/strong&gt; Supports a wide range of RAW camera formats through rawler, with JPEG support included.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Non-Destructive Workflow:&lt;/strong&gt; All edits are stored in a &lt;code&gt;.rrdata&lt;/code&gt; sidecar file, leaving your original images untouched.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Lens Correction:&lt;/strong&gt; Automatic distortion, TCA, and vignette correction powered by Lensfun.&lt;/li&gt;
      &lt;/ul&gt;
      &lt;h4&gt;Professional Grade Adjustments&lt;/h4&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Tonal Controls:&lt;/strong&gt; Exposure, Tone Mapping (including AgX!), Contrast, Highlights, Shadows, Whites, and Blacks.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Tone Curves:&lt;/strong&gt; Full control over Luma/RGB channels.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Color Grading:&lt;/strong&gt; Temperature, Tint, Vibrance, Saturation, color wheels and a full HSL color mixer.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Detail Enhancement:&lt;/strong&gt; Sharpening, Clarity, Structure, and Noise Reduction.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Effects:&lt;/strong&gt; LUTs, Dehaze, Vignette, Glow, Halation, Flares and Film Grain.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Transform Tools:&lt;/strong&gt; Perspective correction, rotation, straightening, crop, and warping tools.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
    &lt;td valign=&quot;top&quot; width=&quot;50%&quot;&gt;
      &lt;h4&gt;Library &amp; Workflow&lt;/h4&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Image Library:&lt;/strong&gt; Effortlessly manage and cull your entire photo collection for a streamlined and efficient workflow.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Organization:&lt;/strong&gt; Recursive folder view, virtual copies, color labels, star ratings, tags and more.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;File Operations:&lt;/strong&gt; Import, copy, move, rename, and duplicate images/folders.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Filmstrip View:&lt;/strong&gt; Quickly navigate between all the images in your current folder while editing.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Batch Operations:&lt;/strong&gt; Save significant time by applying a consistent set of adjustments or exporting entire batches of images simultaneously.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;EXIF Data Viewer:&lt;/strong&gt; Gain insights by inspecting the complete metadata from your camera.&lt;/li&gt;
      &lt;/ul&gt;
      &lt;h4&gt;Productivity &amp; UI&lt;/h4&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Preset System:&lt;/strong&gt; Create, save, import, and share your favorite looks.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Copy &amp; Paste Settings:&lt;/strong&gt; Quickly transfer adjustments between images.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Undo/Redo History:&lt;/strong&gt; A robust history system for every edit.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Customizable UI:&lt;/strong&gt; Resizable panels and multiple beautiful UI themes with smooth animations.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Compositions:&lt;/strong&gt; Built-in seamless Panorama Stitcher, flexible Collage Maker, and Film Negative Converter.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Exporting:&lt;/strong&gt; Control file format, watermarking, naming scheme, metadata, resizing options on export.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Demo &amp; Screenshots

Here&#039;s RapidRAW in action.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/editor.gif&quot; alt=&quot;The main editor interface in action&quot;&gt;&lt;/img&gt;&lt;br&gt;
  &lt;em&gt;The main editor interface in action.&lt;/em&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot;&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/C

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[rowboatlabs/rowboat]]></title>
            <link>https://github.com/rowboatlabs/rowboat</link>
            <guid>https://github.com/rowboatlabs/rowboat</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:18 GMT</pubDate>
            <description><![CDATA[Open-source AI coworker, with memory]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rowboatlabs/rowboat">rowboatlabs/rowboat</a></h1>
            <p>Open-source AI coworker, with memory</p>
            <p>Language: TypeScript</p>
            <p>Stars: 5,496</p>
            <p>Forks: 436</p>
            <p>Stars today: 467 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://www.youtube.com/watch?v=5AWoGo-L16I&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
  &lt;img width=&quot;1339&quot; height=&quot;607&quot; alt=&quot;rowboat-github-2&quot; src=&quot;https://github.com/user-attachments/assets/fc463b99-01b3-401c-b4a4-044dad480901&quot; /&gt;
&lt;/a&gt;

&lt;h5 align=&quot;center&quot;&gt;

&lt;p align=&quot;center&quot; style=&quot;display: flex; justify-content: center; gap: 20px; align-items: center;&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/13609&quot; target=&quot;blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/13609&quot; alt=&quot;rowboatlabs/rowboat | Trendshift&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.rowboatlabs.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img alt=&quot;Website&quot; src=&quot;https://img.shields.io/badge/Website-10b981?labelColor=10b981&amp;logo=window&amp;logoColor=white&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/wajrgmJQ6b&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/badge/Discord-5865F2?logo=discord&amp;logoColor=white&amp;labelColor=5865F2&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://x.com/intent/user?screen_name=rowboatlabshq&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img alt=&quot;Twitter&quot; src=&quot;https://img.shields.io/twitter/follow/rowboatlabshq?style=social&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.ycombinator.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img alt=&quot;Y Combinator&quot; src=&quot;https://img.shields.io/badge/Y%20Combinator-S24-orange&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

# Rowboat  
**Open-source AI coworker that turns work into a knowledge graph and acts on it**

&lt;/h5&gt;

Rowboat connects to your email and meeting notes, builds a long-lived knowledge graph, and uses that context to help you get work done - privately, on your machine.

You can do things like:
- `Build me a deck about our next quarter roadmap` ‚Üí generates a PDF using context from your knowledge graph
- `Prep me for my meeting with Alex` ‚Üí pulls past decisions, open questions, and relevant threads into a crisp brief (or a voice note)
- Visualize, edit, and update your knowledge graph anytime (it‚Äôs just Markdown)
- Record voice memos that automatically capture and update key takeaways in the graph

Download latest for Mac/Windows/Linux: [Download](https://www.rowboatlabs.com/downloads)


## Demo


[![Demo](https://github.com/user-attachments/assets/3f560bcf-d93c-4064-81eb-75a9fae31742)](https://www.youtube.com/watch?v=5AWoGo-L16I)

[Watch the full video](https://www.youtube.com/watch?v=5AWoGo-L16I)

---

## Installation

**Download latest for Mac/Windows/Linux:** [Download](https://www.rowboatlabs.com/downloads)

**All release files:**   https://github.com/rowboatlabs/rowboat/releases/latest

### Google setup
To connect Google services (Gmail, Calendar, and Drive), follow [Google setup](https://github.com/rowboatlabs/rowboat/blob/main/google-setup.md).

### Voice notes
To enable voice notes (optional), add a Deepgram API key in ~/.rowboat/config/deepgram.json:
```
{
  &quot;apiKey&quot;: &quot;&lt;key&gt;&quot;
}
```


## What it does

Rowboat is a **local-first AI coworker** that can:
- **Remember** the important context you don‚Äôt want to re-explain (people, projects, decisions, commitments)
- **Understand** what‚Äôs relevant right now (before a meeting, while replying to an email, when writing a doc)
- **Help you act** by drafting, summarizing, planning, and producing real artifacts (briefs, emails, docs, PDF slides)

Under the hood, Rowboat maintains an **Obsidian-compatible vault** of plain Markdown notes with backlinks ‚Äî a transparent ‚Äúworking memory‚Äù you can inspect and edit.

## Integrations

Rowboat builds memory from the work you already do, including:
- **Gmail** (email)
- **Granola** (meeting notes)
- **Fireflies** (meeting notes)

## How it‚Äôs different

Most AI tools reconstruct context on demand by searching transcripts or documents.

Rowboat maintains **long-lived knowledge** instead:
- context accumulates over time
- relationships are explicit and inspectable
- notes are editable by you, not hidden inside a model
- everything lives on your machine as plain Markdown

The result is memory that compounds, rather than retrieval that starts cold every time.

## What you can do with it

- **Meeting prep** from prior decisions, threads, and open questions
- **Email drafting** grounded in history and commitments
- **Docs &amp; decks** generated from your ongoing context (including PDF slides)
- **Follow-ups**: capture decisions, action items, and owners so nothing gets dropped
- **On-your-machine help**: create files, summarize into notes, and run workflows using local tools (with explicit, reviewable actions)

## Background agents

Rowboat can spin up **background agents** to do repeatable work automatically - so routine tasks happen without you having to ask every time.

Examples:
- Draft email replies in the background (grounded in your past context and commitments)
- Generate a daily voice note each morning (agenda, priorities, upcoming meetings)
- Create recurring project updates from the latest emails/notes
- Keep your knowledge graph up to date as new information comes in

You control what runs, when it runs, and what gets written back into your local Markdown vault.

## Bring your own model

Rowboat works with the model setup you prefer:
- **Local models** via Ollama or LM Studio
- **Hosted models** (bring your own API key/provider)
- Swap models anytime ‚Äî your data stays in your local Markdown vault

## Extend Rowboat with tools (MCP)

Rowboat can connect to external tools and services via **Model Context Protocol (MCP)**.
That means you can plug in (for example) search, databases, CRMs, support tools, and automations - or your own internal tools.

Examples: Exa (web search), Twitter/X, ElevenLabs (voice), Slack, Linear/Jira, GitHub, and more.

## Local-first by design

- All data is stored locally as plain Markdown
- No proprietary formats or hosted lock-in
- You can inspect, edit, back up, or delete everything at any time


## Looking for Rowboat Web Studio?

If you‚Äôre looking for Rowboat web Studio, start [here](https://docs.rowboatlabs.com/). 

---
&lt;div align=&quot;center&quot;&gt;

[Discord](https://discord.gg/wajrgmJQ6b) ¬∑ [Twitter](https://x.com/intent/user?screen_name=rowboatlabshq)
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[EveryInc/compound-engineering-plugin]]></title>
            <link>https://github.com/EveryInc/compound-engineering-plugin</link>
            <guid>https://github.com/EveryInc/compound-engineering-plugin</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:17 GMT</pubDate>
            <description><![CDATA[Official Claude Code compound engineering plugin]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EveryInc/compound-engineering-plugin">EveryInc/compound-engineering-plugin</a></h1>
            <p>Official Claude Code compound engineering plugin</p>
            <p>Language: TypeScript</p>
            <p>Stars: 8,790</p>
            <p>Forks: 682</p>
            <p>Stars today: 128 stars today</p>
            <h2>README</h2><pre># Compound Marketplace

[![Build Status](https://github.com/EveryInc/compound-engineering-plugin/actions/workflows/ci.yml/badge.svg)](https://github.com/EveryInc/compound-engineering-plugin/actions/workflows/ci.yml)
[![npm](https://img.shields.io/npm/v/@every-env/compound-plugin)](https://www.npmjs.com/package/@every-env/compound-plugin)

A Claude Code plugin marketplace featuring the **Compound Engineering Plugin** ‚Äî tools that make each unit of engineering work easier than the last.

## Claude Code Install

```bash
/plugin marketplace add https://github.com/EveryInc/compound-engineering-plugin
/plugin install compound-engineering
```

## OpenCode, Codex, Droid, Cursor &amp; Pi (experimental) Install

This repo includes a Bun/TypeScript CLI that converts Claude Code plugins to OpenCode, Codex, Factory Droid, Cursor, and Pi.

```bash
# convert the compound-engineering plugin into OpenCode format
bunx @every-env/compound-plugin install compound-engineering --to opencode

# convert to Codex format
bunx @every-env/compound-plugin install compound-engineering --to codex

# convert to Factory Droid format
bunx @every-env/compound-plugin install compound-engineering --to droid

# convert to Cursor format
bunx @every-env/compound-plugin install compound-engineering --to cursor

# convert to Pi format
bunx @every-env/compound-plugin install compound-engineering --to pi
```

Local dev:

```bash
bun run src/index.ts install ./plugins/compound-engineering --to opencode
```

OpenCode output is written to `~/.config/opencode` by default, with `opencode.json` at the root and `agents/`, `skills/`, and `plugins/` alongside it.
Codex output is written to `~/.codex/prompts` and `~/.codex/skills`, with each Claude command converted into both a prompt and a skill (the prompt instructs Codex to load the corresponding skill). Generated Codex skill descriptions are truncated to 1024 characters (Codex limit).
Droid output is written to `~/.factory/` with commands, droids (agents), and skills. Claude tool names are mapped to Factory equivalents (`Bash` ‚Üí `Execute`, `Write` ‚Üí `Create`, etc.) and namespace prefixes are stripped from commands.
Cursor output is written to `.cursor/` with rules (`.mdc`), commands, skills, and `mcp.json`. Agents become &quot;Agent Requested&quot; rules (`alwaysApply: false`) so Cursor&#039;s AI activates them on demand. Works with both the Cursor IDE and Cursor CLI (`cursor-agent`) ‚Äî they share the same `.cursor/` config directory.
Pi output is written to `~/.pi/agent/` by default with prompts, skills, extensions, and `compound-engineering/mcporter.json` for MCPorter interoperability.

All provider targets are experimental and may change as the formats evolve.

## Sync Personal Config

Sync your personal Claude Code config (`~/.claude/`) to other AI coding tools:

```bash
# Sync skills and MCP servers to OpenCode
bunx @every-env/compound-plugin sync --target opencode

# Sync to Codex
bunx @every-env/compound-plugin sync --target codex

# Sync to Pi
bunx @every-env/compound-plugin sync --target pi

# Sync to Droid (skills only)
bunx @every-env/compound-plugin sync --target droid

# Sync to Cursor (skills + MCP servers)
bunx @every-env/compound-plugin sync --target cursor
```

This syncs:
- Personal skills from `~/.claude/skills/` (as symlinks)
- MCP servers from `~/.claude/settings.json`

Skills are symlinked (not copied) so changes in Claude Code are reflected immediately.

## Workflow

```
Plan ‚Üí Work ‚Üí Review ‚Üí Compound ‚Üí Repeat
```

| Command | Purpose |
|---------|---------|
| `/workflows:plan` | Turn feature ideas into detailed implementation plans |
| `/workflows:work` | Execute plans with worktrees and task tracking |
| `/workflows:review` | Multi-agent code review before merging |
| `/workflows:compound` | Document learnings to make future work easier |

Each cycle compounds: plans inform future plans, reviews catch more issues, patterns get documented.

## Philosophy

**Each unit of engineering work should make subsequent units easier‚Äînot harder.**

Traditional development accumulates technical debt. Every feature adds complexity. The codebase becomes harder to work with over time.

Compound engineering inverts this. 80% is in planning and review, 20% is in execution:
- Plan thoroughly before writing code
- Review to catch issues and capture learnings
- Codify knowledge so it&#039;s reusable
- Keep quality high so future changes are easy

## Learn More

- [Full component reference](plugins/compound-engineering/README.md) - all agents, commands, skills
- [Compound engineering: how Every codes with agents](https://every.to/chain-of-thought/compound-engineering-how-every-codes-with-agents)
- [The story behind compounding engineering](https://every.to/source-code/my-ai-had-already-fixed-the-code-before-i-saw-it)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[actions/setup-node]]></title>
            <link>https://github.com/actions/setup-node</link>
            <guid>https://github.com/actions/setup-node</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:16 GMT</pubDate>
            <description><![CDATA[Set up your GitHub Actions workflow with a specific version of node.js]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/actions/setup-node">actions/setup-node</a></h1>
            <p>Set up your GitHub Actions workflow with a specific version of node.js</p>
            <p>Language: TypeScript</p>
            <p>Stars: 4,636</p>
            <p>Forks: 1,627</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># setup-node

[![basic-validation](https://github.com/actions/setup-node/actions/workflows/basic-validation.yml/badge.svg)](https://github.com/actions/setup-node/actions/workflows/basic-validation.yml)
[![versions](https://github.com/actions/setup-node/actions/workflows/versions.yml/badge.svg)](https://github.com/actions/setup-node/actions/workflows/versions.yml)
[![e2e-cache](https://github.com/actions/setup-node/actions/workflows/e2e-cache.yml/badge.svg?branch=main)](https://github.com/actions/setup-node/actions/workflows/e2e-cache.yml)
[![proxy](https://github.com/actions/setup-node/actions/workflows/proxy.yml/badge.svg)](https://github.com/actions/setup-node/actions/workflows/proxy.yml)

This action provides the following functionality for GitHub Actions users:

- Optionally downloading and caching distribution of the requested Node.js version, and adding it to the PATH
- Optionally caching npm/yarn/pnpm dependencies
- Registering problem matchers for error output
- Configuring authentication for GPR or npm

## Breaking changes in V6

- Caching is now automatically enabled for npm projects when either the `devEngines.packageManager` field or the top-level `packageManager` field in `package.json` is set to `npm`. For other package managers, such as Yarn and pnpm, caching is disabled by default and must be configured manually using the `cache` input.

- The `always-auth` input has been removed, as it is deprecated and will no longer be supported in future npm releases. To ensure your workflows continue to run without warnings or errors, please remove any references to `always-auth` from your configuration.

## Breaking changes in V5

- Enabled caching by default with package manager detection if no cache input is provided.
  &gt; For workflows with elevated privileges or access to sensitive information, we recommend disabling automatic caching by setting `package-manager-cache: false` when caching is not needed for secure operation.

- Upgraded action from node20 to node24.
  &gt; Make sure your runner is on version v2.327.1 or later to ensure compatibility with this release. [See Release Notes](https://github.com/actions/runner/releases/tag/v2.327.1)

For more details, see the full release notes on the [releases page](https://github.com/actions/setup-node/releases/v5.0.0)

## Usage

See [action.yml](action.yml)

&lt;!-- start usage --&gt;
```yaml
- uses: actions/setup-node@v6
  with:
    # Version Spec of the version to use in SemVer notation.
    # It also admits such aliases as lts/*, latest, nightly and canary builds
    # Examples: 12.x, 10.15.1, &gt;=10.15.0, lts/Hydrogen, 16-nightly, latest, node
    node-version: &#039;&#039;

    # File containing the version Spec of the version to use.  Examples: package.json, .nvmrc, .node-version, .tool-versions.
    # If node-version and node-version-file are both provided the action will use version from node-version.
    node-version-file: &#039;&#039;

    # Set this option if you want the action to check for the latest available version
    # that satisfies the version spec.
    # It will only get affect for lts Nodejs versions (12.x, &gt;=10.15.0, lts/Hydrogen).
    # Default: false
    check-latest: false

    # Target architecture for Node to use. Examples: x86, x64. Will use system architecture by default.
    # Default: &#039;&#039;. The action use system architecture by default
    architecture: &#039;&#039;

    # Used to pull node distributions from https://github.com/actions/node-versions.
    # Since there&#039;s a default, this is typically not supplied by the user.
    # When running this action on github.com, the default value is sufficient.
    # When running on GHES, you can pass a personal access token for github.com if you are experiencing rate limiting.
    #
    # We recommend using a service account with the least permissions necessary. Also
    # when generating a new PAT, select the least scopes necessary.
    #
    # [Learn more about creating and using encrypted secrets](https://help.github.com/en/actions/automating-your-workflow-with-github-actions/creating-and-using-encrypted-secrets)
    #
    # Default: ${{ github.server_url == &#039;https://github.com&#039; &amp;&amp; github.token || &#039;&#039; }}
    token: &#039;&#039;

    # Used to specify a package manager for caching in the default directory. Supported values: npm, yarn, pnpm.
    # Package manager should be pre-installed
    # Default: &#039;&#039;
    cache: &#039;&#039;

    # Controls automatic caching for npm. By default, caching for npm is enabled if either the devEngines.packageManager field or the top-level packageManager field in package.json specifies npm and no explicit cache input is provided.
    # To disable automatic caching for npm, set package-manager-cache to false.
    # default: true
    package-manager-cache: true

    # Used to specify the path to a dependency file: package-lock.json, yarn.lock, etc.
    # It will generate hash from the target file for primary key. It works only If cache is specified.
    # Supports wildcards or a list of file names for caching multiple dependencies.
    # Default: &#039;&#039;
    cache-dependency-path: &#039;&#039;

    # Optional registry to set up for auth. Will set the registry in a project level .npmrc and .yarnrc file,
    # and set up auth to read in from env.NODE_AUTH_TOKEN.
    # Default: &#039;&#039;
    registry-url: &#039;&#039;

    # Optional scope for authenticating against scoped registries.
    # Will fall back to the repository owner when using the GitHub Packages registry (https://npm.pkg.github.com/).
    # Default: &#039;&#039;
    scope: &#039;&#039;

    # Optional mirror to download binaries from.
    # Artifacts need to match the official Node.js
    # Example:
    # V8 Canary Build: &lt;mirror_url&gt;/download/v8-canary
    # RC Build: &lt;mirror_url&gt;/download/rc
    # Official: Build &lt;mirror_url&gt;/dist
    # Nightly build: &lt;mirror_url&gt;/download/nightly
    # Default: &#039;&#039;
    mirror: &#039;&#039;

    # Optional mirror token.
    # The token will be used as a bearer token in the Authorization header
    # Default: &#039;&#039;
    mirror-token: &#039;&#039;
```
&lt;!-- end usage --&gt;

**Basic:**

```yaml
steps:
- uses: actions/checkout@v6
- uses: actions/setup-node@v6
  with:
    node-version: 24
- run: npm ci
- run: npm test
```

The `node-version` input is optional. If not supplied, the node version from PATH will be used. However, it is recommended to always specify Node.js version and not rely on the system one.

The action will first check the local cache for a semver match. If unable to find a specific version in the cache, the action will attempt to download a version of Node.js. It will pull LTS versions from [node-versions releases](https://github.com/actions/node-versions/releases) and on miss or failure will fall back to the previous behavior of downloading directly from [node dist](https://nodejs.org/dist/).

For information regarding locally cached versions of Node.js on GitHub hosted runners, check out [GitHub Actions Runner Images](https://github.com/actions/runner-images).

### Supported version syntax

The `node-version` input supports the Semantic Versioning Specification, for more detailed examples please refer to [the semver package documentation](https://github.com/npm/node-semver).

Examples:

 - Major versions: `22`, `24`
 - More specific versions: `20.19`, `22.17.1` , `24.8.0`
 - NVM LTS syntax: `lts/iron`, `lts/jod`, `lts/*`, `lts/-n`
 - Latest release: `*` or `latest`/`current`/`node`

**Note:** Like the other values, `*` will get the latest [locally-cached Node.js version](https://github.com/actions/runner-images/blob/main/images/ubuntu/Ubuntu2204-Readme.md#nodejs), or the latest version from [actions/node-versions](https://github.com/actions/node-versions/blob/main/versions-manifest.json), depending on the [`check-latest`](docs/advanced-usage.md#check-latest-version) input.

`current`/`latest`/`node` always resolve to the latest [dist version](https://nodejs.org/dist/index.json).
That version is then downloaded from actions/node-versions if possible, or directly from Node.js if not.
Since it will not be cached always, there is possibility of hitting rate limit when downloading from dist

### Checking in lockfiles

It&#039;s **strongly recommended** to commit the lockfile of your package manager for security and performance reasons. For more information consult the &quot;Working with lockfiles&quot; section of the [Advanced usage](docs/advanced-usage.md#working-with-lockfiles) guide.

## Caching global packages data

The action has a built-in functionality for caching and restoring dependencies. It uses [actions/cache](https://github.com/actions/cache) under the hood for caching global packages data but requires less configuration settings. Supported package managers are `npm`, `yarn`, `pnpm` (v6.10+). The `cache` input is optional.

The action defaults to search for the dependency file (`package-lock.json`, `npm-shrinkwrap.json` or `yarn.lock`) in the repository root, and uses its hash as a part of the cache key. Use `cache-dependency-path` for cases when multiple dependency files are used, or they are located in different subdirectories.

**Note:** The action does not cache `node_modules`

See the examples of using cache for `yarn`/`pnpm` and `cache-dependency-path` input in the [Advanced usage](docs/advanced-usage.md#caching-packages-data) guide.

**Caching npm dependencies:**

```yaml
steps:
- uses: actions/checkout@v6
- uses: actions/setup-node@v6
  with:
    node-version: 24
    cache: &#039;npm&#039;
- run: npm ci
- run: npm test
```

**Caching npm dependencies in monorepos:**

```yaml
steps:
- uses: actions/checkout@v6
- uses: actions/setup-node@v6
  with:
    node-version: 24
    cache: &#039;npm&#039;
    cache-dependency-path: subdir/package-lock.json
- run: npm ci
- run: npm test
```

Caching for npm dependencies is automatically enabled when your `package.json` contains either `devEngines.packageManager` field or top-level `packageManager` field set to `npm`, and no explicit cache input is provided.

This behavior is controlled by the `package-manager-cache` input, which defaults to `true`. To turn off automatic caching, set `package-manager-cache` to `false`.

```yaml
steps:
- uses: actions/checkout@v6
- uses: actions/setup-node@v6
  with:
    package-manager-cache: false
- run: npm ci
```
&gt; If your `package.json` file does not include a `packageManager` field set to `npm`, caching will be disabled unless you explicitly enable it. For workflows with elevated privileges or access to sensitive information, we recommend disabling automatic caching for npm by setting `package-manager-cache: false` when caching is not required for secure operation.

## Matrix Testing

```yaml
jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node: [ 20, 22, 24 ]
    name: Node ${{ matrix.node }} sample
    steps:
      - uses: actions/checkout@v6
      - name: Setup node
        uses: actions/setup-node@v6
        with:
          node-version: ${{ matrix.node }}
      - run: npm ci
      - run: npm test
```

## Using `setup-node` on GHES

`setup-node` comes pre-installed on the appliance with GHES if Actions is enabled. When dynamically downloading Nodejs distributions, `setup-node` downloads distributions from [`actions/node-versions`](https://github.com/actions/node-versions) on github.com (outside of the appliance). These calls to `actions/node-versions` are made via unauthenticated requests, which are limited to [60 requests per hour per IP](https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting). If more requests are made within the time frame, then you will start to see rate-limit errors during downloading that looks like: `##[error]API rate limit exceeded for...`. After that error the action will try to download versions directly from the official site, but it also can have rate limit so it&#039;s better to put token.

To get a higher rate limit, you can [generate a personal access token on github.com](https://github.com/settings/tokens/new) and pass it as the `token` input for the action:

```yaml
uses: actions/setup-node@v6
with:
  token: ${{ secrets.GH_DOTCOM_TOKEN }}
  node-version: 24
```

If the runner is not able to access github.com, any Nodejs versions requested during a workflow run must come from the runner&#039;s tool cache. See &quot;[Setting up the tool cache on self-hosted runners without internet access](https://docs.github.com/en/enterprise-server@3.2/admin/github-actions/managing-access-to-actions-from-githubcom/setting-up-the-tool-cache-on-self-hosted-runners-without-internet-access)&quot; for more information.

## Advanced usage

 - [Check latest version](docs/advanced-usage.md#check-latest-version)
 - [Using a node version file](docs/advanced-usage.md#node-version-file)
 - [Using different architectures](docs/advanced-usage.md#architecture)
 - [Using v8 canary versions](docs/advanced-usage.md#v8-canary-versions)
 - [Using nightly versions](docs/advanced-usage.md#nightly-versions)
 - [Using rc versions](docs/advanced-usage.md#rc-versions)
 - [Caching packages data](docs/advanced-usage.md#caching-packages-data)
 - [Using multiple operating systems and architectures](docs/advanced-usage.md#multiple-operating-systems-and-architectures)
 - [Publishing to npmjs and GPR with npm](docs/advanced-usage.md#publish-to-npmjs-and-gpr-with-npm)
 - [Publishing to npmjs and GPR with yarn](docs/advanced-usage.md#publish-to-npmjs-and-gpr-with-yarn)
 - [Using private packages](docs/advanced-usage.md#use-private-packages)
 - [Using private mirror](docs/advanced-usage.md#use-private-mirror)

## Recommended permissions

When using the `setup-node` action in your GitHub Actions workflow, it is recommended to set the following permissions to ensure proper functionality:

```yaml
permissions:
  contents: read # access to check out code and install dependencies
```

## License

The scripts and documentation in this project are released under the [MIT License](LICENSE)

## Contributions

Contributions are welcome! See [Contributor&#039;s Guide](docs/contributors.md)

## Code of Conduct

:wave: Be nice. See [our code of conduct](CODE_OF_CONDUCT.md)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[musistudio/claude-code-router]]></title>
            <link>https://github.com/musistudio/claude-code-router</link>
            <guid>https://github.com/musistudio/claude-code-router</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:15 GMT</pubDate>
            <description><![CDATA[Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/musistudio/claude-code-router">musistudio/claude-code-router</a></h1>
            <p>Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 27,802</p>
            <p>Forks: 2,152</p>
            <p>Stars today: 75 stars today</p>
            <h2>README</h2><pre>![](blog/images/claude-code-router-img.png)

[![](https://img.shields.io/badge/%F0%9F%87%A8%F0%9F%87%B3-%E4%B8%AD%E6%96%87%E7%89%88-ff0000?style=flat)](README_zh.md)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?&amp;logo=discord&amp;logoColor=white)](https://discord.gg/rdftVMaUcS)
[![](https://img.shields.io/github/license/musistudio/claude-code-router)](https://github.com/musistudio/claude-code-router/blob/main/LICENSE)

&lt;hr&gt;

![](blog/images/sponsors/glm-en.jpg)
&gt; This project is sponsored by Z.ai, supporting us with their GLM CODING PLAN.    
&gt; GLM CODING PLAN is a subscription service designed for AI coding, starting at just $3/month. It provides access to their flagship GLM-4.7 model across 10+ popular AI coding tools (Claude Code, Cline, Roo Code, etc.), offering developers top-tier, fast, and stable coding experiences.     
&gt; Get 10% OFF GLM CODING PLANÔºöhttps://z.ai/subscribe?ic=8JVLJQFSKB     

&gt; [Progressive Disclosure of Agent Tools from the Perspective of CLI Tool Style](/blog/en/progressive-disclosure-of-agent-tools-from-the-perspective-of-cli-tool-style.md)

&gt; A powerful tool to route Claude Code requests to different models and customize any request.

![](blog/images/claude-code.png)

## ‚ú® Features

- **Model Routing**: Route requests to different models based on your needs (e.g., background tasks, thinking, long context).
- **Multi-Provider Support**: Supports various model providers like OpenRouter, DeepSeek, Ollama, Gemini, Volcengine, and SiliconFlow.
- **Request/Response Transformation**: Customize requests and responses for different providers using transformers.
- **Dynamic Model Switching**: Switch models on-the-fly within Claude Code using the `/model` command.
- **CLI Model Management**: Manage models and providers directly from the terminal with `ccr model`.
- **GitHub Actions Integration**: Trigger Claude Code tasks in your GitHub workflows.
- **Plugin System**: Extend functionality with custom transformers.

## üöÄ Getting Started

### 1. Installation

First, ensure you have [Claude Code](https://docs.anthropic.com/en/docs/claude-code/quickstart) installed:

```shell
npm install -g @anthropic-ai/claude-code
```

Then, install Claude Code Router:

```shell
npm install -g @musistudio/claude-code-router
```

### 2. Configuration

Create and configure your `~/.claude-code-router/config.json` file. For more details, you can refer to `config.example.json`.

The `config.json` file has several key sections:

- **`PROXY_URL`** (optional): You can set a proxy for API requests, for example: `&quot;PROXY_URL&quot;: &quot;http://127.0.0.1:7890&quot;`.
- **`LOG`** (optional): You can enable logging by setting it to `true`. When set to `false`, no log files will be created. Default is `true`.
- **`LOG_LEVEL`** (optional): Set the logging level. Available options are: `&quot;fatal&quot;`, `&quot;error&quot;`, `&quot;warn&quot;`, `&quot;info&quot;`, `&quot;debug&quot;`, `&quot;trace&quot;`. Default is `&quot;debug&quot;`.
- **Logging Systems**: The Claude Code Router uses two separate logging systems:
  - **Server-level logs**: HTTP requests, API calls, and server events are logged using pino in the `~/.claude-code-router/logs/` directory with filenames like `ccr-*.log`
  - **Application-level logs**: Routing decisions and business logic events are logged in `~/.claude-code-router/claude-code-router.log`
- **`APIKEY`** (optional): You can set a secret key to authenticate requests. When set, clients must provide this key in the `Authorization` header (e.g., `Bearer your-secret-key`) or the `x-api-key` header. Example: `&quot;APIKEY&quot;: &quot;your-secret-key&quot;`.
- **`HOST`** (optional): You can set the host address for the server. If `APIKEY` is not set, the host will be forced to `127.0.0.1` for security reasons to prevent unauthorized access. Example: `&quot;HOST&quot;: &quot;0.0.0.0&quot;`.
- **`NON_INTERACTIVE_MODE`** (optional): When set to `true`, enables compatibility with non-interactive environments like GitHub Actions, Docker containers, or other CI/CD systems. This sets appropriate environment variables (`CI=true`, `FORCE_COLOR=0`, etc.) and configures stdin handling to prevent the process from hanging in automated environments. Example: `&quot;NON_INTERACTIVE_MODE&quot;: true`.

- **`Providers`**: Used to configure different model providers.
- **`Router`**: Used to set up routing rules. `default` specifies the default model, which will be used for all requests if no other route is configured.
- **`API_TIMEOUT_MS`**: Specifies the timeout for API calls in milliseconds.

#### Environment Variable Interpolation

Claude Code Router supports environment variable interpolation for secure API key management. You can reference environment variables in your `config.json` using either `$VAR_NAME` or `${VAR_NAME}` syntax:

```json
{
  &quot;OPENAI_API_KEY&quot;: &quot;$OPENAI_API_KEY&quot;,
  &quot;GEMINI_API_KEY&quot;: &quot;${GEMINI_API_KEY}&quot;,
  &quot;Providers&quot;: [
    {
      &quot;name&quot;: &quot;openai&quot;,
      &quot;api_base_url&quot;: &quot;https://api.openai.com/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;$OPENAI_API_KEY&quot;,
      &quot;models&quot;: [&quot;gpt-5&quot;, &quot;gpt-5-mini&quot;]
    }
  ]
}
```

This allows you to keep sensitive API keys in environment variables instead of hardcoding them in configuration files. The interpolation works recursively through nested objects and arrays.

Here is a comprehensive example:

```json
{
  &quot;APIKEY&quot;: &quot;your-secret-key&quot;,
  &quot;PROXY_URL&quot;: &quot;http://127.0.0.1:7890&quot;,
  &quot;LOG&quot;: true,
  &quot;API_TIMEOUT_MS&quot;: 600000,
  &quot;NON_INTERACTIVE_MODE&quot;: false,
  &quot;Providers&quot;: [
    {
      &quot;name&quot;: &quot;openrouter&quot;,
      &quot;api_base_url&quot;: &quot;https://openrouter.ai/api/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [
        &quot;google/gemini-2.5-pro-preview&quot;,
        &quot;anthropic/claude-sonnet-4&quot;,
        &quot;anthropic/claude-3.5-sonnet&quot;,
        &quot;anthropic/claude-3.7-sonnet:thinking&quot;
      ],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;openrouter&quot;]
      }
    },
    {
      &quot;name&quot;: &quot;deepseek&quot;,
      &quot;api_base_url&quot;: &quot;https://api.deepseek.com/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;deepseek-chat&quot;, &quot;deepseek-reasoner&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;deepseek&quot;],
        &quot;deepseek-chat&quot;: {
          &quot;use&quot;: [&quot;tooluse&quot;]
        }
      }
    },
    {
      &quot;name&quot;: &quot;ollama&quot;,
      &quot;api_base_url&quot;: &quot;http://localhost:11434/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;ollama&quot;,
      &quot;models&quot;: [&quot;qwen2.5-coder:latest&quot;]
    },
    {
      &quot;name&quot;: &quot;gemini&quot;,
      &quot;api_base_url&quot;: &quot;https://generativelanguage.googleapis.com/v1beta/models/&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;gemini-2.5-flash&quot;, &quot;gemini-2.5-pro&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;gemini&quot;]
      }
    },
    {
      &quot;name&quot;: &quot;volcengine&quot;,
      &quot;api_base_url&quot;: &quot;https://ark.cn-beijing.volces.com/api/v3/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;deepseek-v3-250324&quot;, &quot;deepseek-r1-250528&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;deepseek&quot;]
      }
    },
    {
      &quot;name&quot;: &quot;modelscope&quot;,
      &quot;api_base_url&quot;: &quot;https://api-inference.modelscope.cn/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;&quot;,
      &quot;models&quot;: [&quot;Qwen/Qwen3-Coder-480B-A35B-Instruct&quot;, &quot;Qwen/Qwen3-235B-A22B-Thinking-2507&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [
          [
            &quot;maxtoken&quot;,
            {
              &quot;max_tokens&quot;: 65536
            }
          ],
          &quot;enhancetool&quot;
        ],
        &quot;Qwen/Qwen3-235B-A22B-Thinking-2507&quot;: {
          &quot;use&quot;: [&quot;reasoning&quot;]
        }
      }
    },
    {
      &quot;name&quot;: &quot;dashscope&quot;,
      &quot;api_base_url&quot;: &quot;https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;&quot;,
      &quot;models&quot;: [&quot;qwen3-coder-plus&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [
          [
            &quot;maxtoken&quot;,
            {
              &quot;max_tokens&quot;: 65536
            }
          ],
          &quot;enhancetool&quot;
        ]
      }
    },
    {
      &quot;name&quot;: &quot;aihubmix&quot;,
      &quot;api_base_url&quot;: &quot;https://aihubmix.com/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-&quot;,
      &quot;models&quot;: [
        &quot;Z/glm-4.5&quot;,
        &quot;claude-opus-4-20250514&quot;,
        &quot;gemini-2.5-pro&quot;
      ]
    }
  ],
  &quot;Router&quot;: {
    &quot;default&quot;: &quot;deepseek,deepseek-chat&quot;,
    &quot;background&quot;: &quot;ollama,qwen2.5-coder:latest&quot;,
    &quot;think&quot;: &quot;deepseek,deepseek-reasoner&quot;,
    &quot;longContext&quot;: &quot;openrouter,google/gemini-2.5-pro-preview&quot;,
    &quot;longContextThreshold&quot;: 60000,
    &quot;webSearch&quot;: &quot;gemini,gemini-2.5-flash&quot;
  }
}
```

### 3. Running Claude Code with the Router

Start Claude Code using the router:

```shell
ccr code
```

&gt; **Note**: After modifying the configuration file, you need to restart the service for the changes to take effect:
&gt;
&gt; ```shell
&gt; ccr restart
&gt; ```

### 4. UI Mode

For a more intuitive experience, you can use the UI mode to manage your configuration:

```shell
ccr ui
```

This will open a web-based interface where you can easily view and edit your `config.json` file.

![UI](/blog/images/ui.png)

### 5. CLI Model Management

For users who prefer terminal-based workflows, you can use the interactive CLI model selector:

```shell
ccr model
```
![](blog/images/models.gif)

This command provides an interactive interface to:

- View current configuration:
- See all configured models (default, background, think, longContext, webSearch, image)
- Switch models: Quickly change which model is used for each router type
- Add new models: Add models to existing providers
- Create new providers: Set up complete provider configurations including:
   - Provider name and API endpoint
   - API key
   - Available models
   - Transformer configuration with support for:
     - Multiple transformers (openrouter, deepseek, gemini, etc.)
     - Transformer options (e.g., maxtoken with custom limits)
     - Provider-specific routing (e.g., OpenRouter provider preferences)

The CLI tool validates all inputs and provides helpful prompts to guide you through the configuration process, making it easy to manage complex setups without editing JSON files manually.

### 6. Presets Management

Presets allow you to save, share, and reuse configurations easily. You can export your current configuration as a preset and install presets from files or URLs.

```shell
# Export current configuration as a preset
ccr preset export my-preset

# Export with metadata
ccr preset export my-preset --description &quot;My OpenAI config&quot; --author &quot;Your Name&quot; --tags &quot;openai,production&quot;

# Install a preset from local directory
ccr preset install /path/to/preset

# List all installed presets
ccr preset list

# Show preset information
ccr preset info my-preset

# Delete a preset
ccr preset delete my-preset
```

**Preset Features:**
- **Export**: Save your current configuration as a preset directory (with manifest.json)
- **Install**: Install presets from local directories
- **Sensitive Data Handling**: API keys and other sensitive data are automatically sanitized during export (marked as `{{field}}` placeholders)
- **Dynamic Configuration**: Presets can include input schemas for collecting required information during installation
- **Version Control**: Each preset includes version metadata for tracking updates

**Preset File Structure:**
```
~/.claude-code-router/presets/
‚îú‚îÄ‚îÄ my-preset/
‚îÇ   ‚îî‚îÄ‚îÄ manifest.json    # Contains configuration and metadata
```

### 7. Activate Command (Environment Variables Setup)

The `activate` command allows you to set up environment variables globally in your shell, enabling you to use the `claude` command directly or integrate Claude Code Router with applications built using the Agent SDK.

To activate the environment variables, run:

```shell
eval &quot;$(ccr activate)&quot;
```

This command outputs the necessary environment variables in shell-friendly format, which are then set in your current shell session. After activation, you can:

- **Use `claude` command directly**: Run `claude` commands without needing to use `ccr code`. The `claude` command will automatically route requests through Claude Code Router.
- **Integrate with Agent SDK applications**: Applications built with the Anthropic Agent SDK will automatically use the configured router and models.

The `activate` command sets the following environment variables:

- `ANTHROPIC_AUTH_TOKEN`: API key from your configuration
- `ANTHROPIC_BASE_URL`: The local router endpoint (default: `http://127.0.0.1:3456`)
- `NO_PROXY`: Set to `127.0.0.1` to prevent proxy interference
- `DISABLE_TELEMETRY`: Disables telemetry
- `DISABLE_COST_WARNINGS`: Disables cost warnings
- `API_TIMEOUT_MS`: API timeout from your configuration

&gt; **Note**: Make sure the Claude Code Router service is running (`ccr start`) before using the activated environment variables. The environment variables are only valid for the current shell session. To make them persistent, you can add `eval &quot;$(ccr activate)&quot;` to your shell configuration file (e.g., `~/.zshrc` or `~/.bashrc`).

#### Providers

The `Providers` array is where you define the different model providers you want to use. Each provider object requires:

- `name`: A unique name for the provider.
- `api_base_url`: The full API endpoint for chat completions.
- `api_key`: Your API key for the provider.
- `models`: A list of model names available from this provider.
- `transformer` (optional): Specifies transformers to process requests and responses.

#### Transformers

Transformers allow you to modify the request and response payloads to ensure compatibility with different provider APIs.

- **Global Transformer**: Apply a transformer to all models from a provider. In this example, the `openrouter` transformer is applied to all models under the `openrouter` provider.
  ```json
  {
    &quot;name&quot;: &quot;openrouter&quot;,
    &quot;api_base_url&quot;: &quot;https://openrouter.ai/api/v1/chat/completions&quot;,
    &quot;api_key&quot;: &quot;sk-xxx&quot;,
    &quot;models&quot;: [
      &quot;google/gemini-2.5-pro-preview&quot;,
      &quot;anthropic/claude-sonnet-4&quot;,
      &quot;anthropic/claude-3.5-sonnet&quot;
    ],
    &quot;transformer&quot;: { &quot;use&quot;: [&quot;openrouter&quot;] }
  }
  ```
- **Model-Specific Transformer**: Apply a transformer to a specific model. In this example, the `deepseek` transformer is applied to all models, and an additional `tooluse` transformer is applied only to the `deepseek-chat` model.

  ```json
  {
    &quot;name&quot;: &quot;deepseek&quot;,
    &quot;api_base_url&quot;: &quot;https://api.deepseek.com/chat/completions&quot;,
    &quot;api_key&quot;: &quot;sk-xxx&quot;,
    &quot;models&quot;: [&quot;deepseek-chat&quot;, &quot;deepseek-reasoner&quot;],
    &quot;transformer&quot;: {
      &quot;use&quot;: [&quot;deepseek&quot;],
      &quot;deepseek-chat&quot;: { &quot;use&quot;: [&quot;tooluse&quot;] }
    }
  }
  ```

- **Passing Options to a Transformer**: Some transformers, like `maxtoken`, accept options. To pass options, use a nested array where the first element is the transformer name and the second is an options object.
  ```json
  {
    &quot;name&quot;: &quot;siliconflow&quot;,
    &quot;api_base_url&quot;: &quot;https://api.siliconflow.cn/v1/chat/completions&quot;,
    &quot;api_key&quot;: &quot;sk-xxx&quot;,
    &quot;models&quot;: [&quot;moonshotai/Kimi-K2-Instruct&quot;],
    &quot;transformer&quot;: {
      &quot;use&quot;: [
        [
          &quot;maxtoken&quot;,
          {
            &quot;max_tokens&quot;: 16384
          }
        ]
      ]
    }
  }
  ```

**Available Built-in Transformers:**

- `Anthropic`:If you use only the `Anthropic` transformer, it will preserve the original request and response parameters(you can use it to connect directly to an Anthropic endpoint).
- `deepseek`: Adapts requests/responses for DeepSeek API.
- `gemini`: Adapts requests/responses for Gemini API.
- `openrouter`: Adapts requests/responses for OpenRouter API. It can also accept a `provider` routing parameter to specify which underlying providers OpenRouter should use. For more details, refer to the [OpenRouter documentation](https://openrouter.ai/docs/features/provider-routing). See an example below:
  ```json
    &quot;transformer&quot;: {
      &quot;use&quot;: [&quot;openrouter&quot;],
      &quot;moonshotai/kimi-k2&quot;: {
        &quot;use&quot;: [
          [
            &quot;openrouter&quot;,
            {
              &quot;provider&quot;: {
                &quot;only&quot;: [&quot;moonshotai/fp8&quot;]
              }
            }
          ]
        ]
      }
    }
  ```
- `groq`: Adapts requests/responses for groq API.
- `maxtoken`: Sets a specific `max_tokens` value.
- `tooluse`: Optimizes tool usage for certain models via `tool_choice`.
- `gemini-cli` (experimental): Unofficial support for Gemini via Gemini CLI [gemini-cli.js](https://gist.github.com/musistudio/1c13a65f35916a7ab690649d3df8d1cd).
- `reasoning`: Used to process the `reasoning_content` field.
- `sampling`: Used to process sampling information fields such as `temperature`, `top_p`, `top_k`, and `repetition_penalty`.
- `enhancetool`: Adds a layer of error tolerance to the tool call parameters returned by the LLM (this will cause the tool call information to no longer be streamed).
- `cleancache`: Clears the `cache_control` field from requests.
- `vertex-gemini`: Handles the Gemini API using Vertex authentication.
- `chutes-glm` Unofficial support for GLM 4.5 model via Chutes [chutes-glm-transformer.js](https://gist.github.com/vitobotta/2be3f33722e05e8d4f9d2b0138b8c863).
- `qwen-cli` (experimental): Unofficial support for qwen3-coder-plus model via Qwen CLI [qwen-cli.js](https://gist.github.com/musistudio/f5a67841ced39912fd99e42200d5ca8b).
- `rovo-cli` (experimental): Unofficial support for gpt-5 via Atlassian Rovo Dev CLI [rovo-cli.js](https://gist.github.com/SaseQ/c2a20a38b11276537ec5332d1f7a5e53).

**Custom Transformers:**

You can also create your own transformers and load them via the `transformers` field in `config.json`.

```json
{
  &quot;transformers&quot;: [
    {
      &quot;path&quot;: &quot;/User/xxx/.claude-code-router/plugins/gemini-cli.js&quot;,
      &quot;options&quot;: {
        &quot;project&quot;: &quot;xxx&quot;
      }
    }
  ]
}
```

#### Router

The `Router` object defines which model to use for different scenarios:

- `default`: The default model for general tasks.
- `background`: A model for background tasks. This can be a smaller, local model to save costs.
- `think`: A model for reasoning-heavy tasks, like Plan Mode.
- `longContext`: A model for handling long contexts (e.g., &gt; 60K tokens).
- `longContextThreshold` (optional): The token count threshold for triggering the long context model. Defaults to 60000 if not specified.
- `webSearch`: Used for handling web search tasks and this requires the model itself to support the feature. If you&#039;re using openrouter, you need to add the `:online` suffix after the model name.
- `image` (beta): Used for handling image-related tasks (supported by CCR‚Äôs built-in agent). If the model does not support tool calling, you need to set the `config.forceUseImageAgent` property to `true`.

- You can also switch models dynamically in Claude Code with the `/model` command:
`/model provider_name,model_name`
Example: `/model openrouter,anthropic/claude-3.5-sonnet`

#### Custom Router

For more advanced routing logic, you can specify a custom router script via the `CUSTOM_ROUTER_PATH` in your `config.json`. This allows you to implement complex routing rules beyond the default scenarios.

In your `config.json`:

```json
{
  &quot;CUSTOM_ROUTER_PATH&quot;: &quot;/User/xxx/.claude-code-router/custom-router.js&quot;
}
```

The custom router file must be a JavaScript module that exports an `async` function. This function receives the request object and the config object as arguments and should return the provider and model name as a string (e.g., `&quot;provider_name,model_name&quot;`), or `null` to fall back to the default router.

Here is an example of a `custom-router.js` based on `custom-router.example.js`:

```javascript
// /User/xxx/.claude-code-router/custom-router.js

/**
 * A custom router function to determine which model to use based on the request.
 *
 * @param {object} req - The request object from Claude Code, containing the request body.
 * @param {object} config - The application&#039;s config object.
 * @returns {Promise&lt;string|null&gt;} - A promise that resolves to the &quot;provider,model_name&quot; string, or null to use the default router.
 */
module.exports = async function router(req, config) {
  const userMessage = req.body.messages.find((m) =&gt; m.role === &quot;user&quot;)?.content;

  if (userMessage &amp;&amp; userMessage.includes(&quot;explain this code&quot;)) {
    // Use a powerful model for code explanation
    return &quot;openrouter,anthropic/claude-3.5-sonnet&quot;;
  }

  // Fallback to the 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[angular/angular]]></title>
            <link>https://github.com/angular/angular</link>
            <guid>https://github.com/angular/angular</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:14 GMT</pubDate>
            <description><![CDATA[Deliver web apps with confidence üöÄ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/angular/angular">angular/angular</a></h1>
            <p>Deliver web apps with confidence üöÄ</p>
            <p>Language: TypeScript</p>
            <p>Stars: 99,824</p>
            <p>Forks: 27,058</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;Angular - The modern web developer&#039;s platform&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;adev/src/assets/images/press-kit/angular_icon_gradient.gif&quot; alt=&quot;angular-logo&quot; width=&quot;120px&quot; height=&quot;120px&quot;/&gt;
  &lt;br&gt;
  &lt;em&gt;Angular is a development platform for building mobile and desktop web applications
    &lt;br&gt; using TypeScript/JavaScript and other languages.&lt;/em&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://angular.dev/&quot;&gt;&lt;strong&gt;angular.dev&lt;/strong&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;Contributing Guidelines&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://github.com/angular/angular/issues&quot;&gt;Submit an Issue&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://blog.angular.dev/&quot;&gt;Blog&lt;/a&gt;
  &lt;br&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/@angular/core&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/@angular/core.svg?logo=npm&amp;logoColor=fff&amp;label=NPM+package&amp;color=limegreen&quot; alt=&quot;Angular on npm&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;hr&gt;

## Documentation

Get started with Angular, learn the fundamentals and explore advanced topics on our documentation website.

- [Getting Started][quickstart]
- [Architecture][architecture]
- [Components and Templates][componentstemplates]
- [Forms][forms]
- [API][api]

### Advanced

- [Angular Elements][angularelements]
- [Server Side Rendering][ssr]
- [Schematics][schematics]
- [Lazy Loading][lazyloading]
- [Animations][animations]

### Local Development

To contribute to the Angular Docs, check out the [Angular.dev README](adev/README.md)

## Development Setup

### Prerequisites

- Install [Node.js] which includes [Node Package Manager][npm]

### Setting Up a Project

Install the Angular CLI globally:

```
npm install -g @angular/cli
```

Create workspace:

```
ng new [PROJECT NAME]
```

Run the application:

```
cd [PROJECT NAME]
ng serve
```

Angular is cross-platform, fast, scalable, has incredible tooling, and is loved by millions.

## Quickstart

[Get started in 5 minutes][quickstart].

## Ecosystem

&lt;p&gt;
  &lt;img src=&quot;/contributing-docs/images/angular-ecosystem-logos.png&quot; alt=&quot;angular ecosystem logos&quot; width=&quot;500px&quot; height=&quot;auto&quot;&gt;
&lt;/p&gt;

- [Angular Command Line (CLI)][cli]
- [Angular Material][angularmaterial]

## Changelog

[Learn about the latest improvements][changelog].

## Upgrading

Check out our [upgrade guide](https://angular.dev/update-guide/) to find out the best way to upgrade your project.

## Contributing

### Contributing Guidelines

Read through our [contributing guidelines][contributing] to learn about our submission process, coding rules, and more.

### Want to Help?

Want to report a bug, contribute some code, or improve the documentation? Excellent! Read up on our guidelines for [contributing][contributing] and then check out one of our issues labeled as &lt;kbd&gt;[help wanted](https://github.com/angular/angular/labels/help%20wanted)&lt;/kbd&gt; or &lt;kbd&gt;[good first issue](https://github.com/angular/angular/labels/good%20first%20issue)&lt;/kbd&gt;.

### Code of Conduct

Help us keep Angular open and inclusive. Please read and follow our [Code of Conduct][codeofconduct].

## Community

Join the conversation and help the community.

- [X (formerly Twitter)][X (formerly Twitter)]
- [Bluesky][bluesky]
- [Discord][discord]
- [YouTube][youtube]
- [StackOverflow][stackoverflow]
- Find a Local [Meetup][meetup]

[![Love Angular badge](https://img.shields.io/badge/angular-love-blue?logo=angular&amp;angular=love)](https://www.github.com/angular/angular)

**Love Angular? Give our repo a star :star: :arrow_up:.**

[contributing]: CONTRIBUTING.md
[quickstart]: https://angular.dev/tutorials/learn-angular
[changelog]: CHANGELOG.md
[ng]: https://angular.dev
[documentation]: https://angular.dev/overview
[angularmaterial]: https://material.angular.dev/
[cli]: https://angular.dev/tools/cli
[architecture]: https://angular.dev/essentials
[componentstemplates]: https://angular.dev/tutorials/learn-angular/1-components-in-angular
[forms]: https://angular.dev/tutorials/learn-angular/15-forms
[api]: https://angular.dev/api
[angularelements]: https://angular.dev/guide/elements
[ssr]: https://angular.dev/guide/ssr
[schematics]: https://angular.dev/tools/cli/schematics
[lazyloading]: https://angular.dev/guide/routing/define-routes#lazily-loaded-components
[node.js]: https://nodejs.org/
[npm]: https://www.npmjs.com/get-npm
[codeofconduct]: CODE_OF_CONDUCT.md
[X (formerly Twitter)]: https://www.x.com/angular
[bluesky]: https://bsky.app/profile/angular.dev
[discord]: https://discord.gg/angular
[stackoverflow]: https://stackoverflow.com/questions/tagged/angular
[youtube]: https://youtube.com/angular
[meetup]: https://www.meetup.com/find/?keywords=angular
[animations]: https://angular.dev/guide/animations
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[microsoft/azure-devops-mcp]]></title>
            <link>https://github.com/microsoft/azure-devops-mcp</link>
            <guid>https://github.com/microsoft/azure-devops-mcp</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:13 GMT</pubDate>
            <description><![CDATA[The MCP server for Azure DevOps, bringing the power of Azure DevOps directly to your agents.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/azure-devops-mcp">microsoft/azure-devops-mcp</a></h1>
            <p>The MCP server for Azure DevOps, bringing the power of Azure DevOps directly to your agents.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,266</p>
            <p>Forks: 405</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># ‚≠ê Azure DevOps MCP Server

Easily install the Azure DevOps MCP Server for VS Code or VS Code Insiders:

[![Install with NPX in VS Code](https://img.shields.io/badge/VS_Code-Install_AzureDevops_MCP_Server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=ado&amp;config=%7B%20%22type%22%3A%20%22stdio%22%2C%20%22command%22%3A%20%22npx%22%2C%20%22args%22%3A%20%5B%22-y%22%2C%20%22%40azure-devops%2Fmcp%22%2C%20%22%24%7Binput%3Aado_org%7D%22%5D%7D&amp;inputs=%5B%7B%22id%22%3A%20%22ado_org%22%2C%20%22type%22%3A%20%22promptString%22%2C%20%22description%22%3A%20%22Azure%20DevOps%20organization%20name%20%20%28e.g.%20%27contoso%27%29%22%7D%5D)
[![Install with NPX in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_AzureDevops_MCP_Server-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=ado&amp;quality=insiders&amp;config=%7B%20%22type%22%3A%20%22stdio%22%2C%20%22command%22%3A%20%22npx%22%2C%20%22args%22%3A%20%5B%22-y%22%2C%20%22%40azure-devops%2Fmcp%22%2C%20%22%24%7Binput%3Aado_org%7D%22%5D%7D&amp;inputs=%5B%7B%22id%22%3A%20%22ado_org%22%2C%20%22type%22%3A%20%22promptString%22%2C%20%22description%22%3A%20%22Azure%20DevOps%20organization%20name%20%20%28e.g.%20%27contoso%27%29%22%7D%5D)

This TypeScript project provides a **local** MCP server for Azure DevOps, enabling you to perform a wide range of Azure DevOps tasks directly from your code editor.

## üìÑ Table of Contents

1. [üì∫ Overview](#-overview)
2. [üèÜ Expectations](#-expectations)
3. [‚öôÔ∏è Supported Tools](#Ô∏è-supported-tools)
4. [üîå Installation &amp; Getting Started](#-installation--getting-started)
5. [üåè Using Domains](#-using-domains)
6. [üìù Troubleshooting](#-troubleshooting)
7. [üé© Examples &amp; Best Practices](#-examples--best-practices)
8. [üôã‚Äç‚ôÄÔ∏è Frequently Asked Questions](#Ô∏è-frequently-asked-questions)
9. [üìå Contributing](#-contributing)

## üì∫ Overview

The Azure DevOps MCP Server brings Azure DevOps context to your agents. Try prompts like:

- &quot;List my ADO projects&quot;
- &quot;List ADO Builds for &#039;Contoso&#039;&quot;
- &quot;List ADO Repos for &#039;Contoso&#039;&quot;
- &quot;List test plans for &#039;Contoso&#039;&quot;
- &quot;List teams for project &#039;Contoso&#039;&quot;
- &quot;List iterations for project &#039;Contoso&#039;&quot;
- &quot;List my work items for project &#039;Contoso&#039;&quot;
- &quot;List work items in current iteration for &#039;Contoso&#039; project and &#039;Contoso Team&#039;&quot;
- &quot;List all wikis in the &#039;Contoso&#039; project&quot;
- &quot;Create a wiki page &#039;/Architecture/Overview&#039; with content about system design&quot;
- &quot;Update the wiki page &#039;/Getting Started&#039; with new onboarding instructions&quot;
- &quot;Get the content of the wiki page &#039;/API/Authentication&#039; from the Documentation wiki&quot;

## üèÜ Expectations

The Azure DevOps MCP Server is built from tools that are concise, simple, focused, and easy to use‚Äîeach designed for a specific scenario. We intentionally avoid complex tools that try to do too much. The goal is to provide a thin abstraction layer over the REST APIs, making data access straightforward and letting the language model handle complex reasoning.

## ‚öôÔ∏è Supported Tools

See [TOOLSET.md](./docs/TOOLSET.md) for a comprehensive list.

## üîå Installation &amp; Getting Started

For the best experience, use Visual Studio Code and GitHub Copilot. See the [getting started documentation](./docs/GETTINGSTARTED.md) to use our MCP Server with other tools such as Visual Studio 2022, Claude Code, and Cursor.

### Prerequisites

1. Install [VS Code](https://code.visualstudio.com/download) or [VS Code Insiders](https://code.visualstudio.com/insiders)
2. Install [Node.js](https://nodejs.org/en/download) 20+
3. Open VS Code in an empty folder

### Installation

#### ‚ú® One-Click Install

[![Install with NPX in VS Code](https://img.shields.io/badge/VS_Code-Install_AzureDevops_MCP_Server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=ado&amp;config=%7B%20%22type%22%3A%20%22stdio%22%2C%20%22command%22%3A%20%22npx%22%2C%20%22args%22%3A%20%5B%22-y%22%2C%20%22%40azure-devops%2Fmcp%22%2C%20%22%24%7Binput%3Aado_org%7D%22%5D%7D&amp;inputs=%5B%7B%22id%22%3A%20%22ado_org%22%2C%20%22type%22%3A%20%22promptString%22%2C%20%22description%22%3A%20%22Azure%20DevOps%20organization%20name%20%20%28e.g.%20%27contoso%27%29%22%7D%5D)
[![Install with NPX in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_AzureDevops_MCP_Server-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=ado&amp;quality=insiders&amp;config=%7B%20%22type%22%3A%20%22stdio%22%2C%20%22command%22%3A%20%22npx%22%2C%20%22args%22%3A%20%5B%22-y%22%2C%20%22%40azure-devops%2Fmcp%22%2C%20%22%24%7Binput%3Aado_org%7D%22%5D%7D&amp;inputs=%5B%7B%22id%22%3A%20%22ado_org%22%2C%20%22type%22%3A%20%22promptString%22%2C%20%22description%22%3A%20%22Azure%20DevOps%20organization%20name%20%20%28e.g.%20%27contoso%27%29%22%7D%5D)

After installation, select GitHub Copilot Agent Mode and refresh the tools list. Learn more about Agent Mode in the [VS Code Documentation](https://code.visualstudio.com/docs/copilot/chat/chat-agent-mode).

#### üß® Install from Public Feed (Recommended)

This installation method is the easiest for all users of Visual Studio Code.

üé• [Watch this quick start video to get up and running in under two minutes!](https://youtu.be/EUmFM6qXoYk)

##### Steps

In your project, add a `.vscode\mcp.json` file with the following content:

```json
{
  &quot;inputs&quot;: [
    {
      &quot;id&quot;: &quot;ado_org&quot;,
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;description&quot;: &quot;Azure DevOps organization name  (e.g. &#039;contoso&#039;)&quot;
    }
  ],
  &quot;servers&quot;: {
    &quot;ado&quot;: {
      &quot;type&quot;: &quot;stdio&quot;,
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;@azure-devops/mcp&quot;, &quot;${input:ado_org}&quot;]
    }
  }
}
```

üî• To stay up to date with the latest features, you can use our nightly builds. Simply update your `mcp.json` configuration to use `@azure-devops/mcp@next`. Here is an updated example:

```json
{
  &quot;inputs&quot;: [
    {
      &quot;id&quot;: &quot;ado_org&quot;,
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;description&quot;: &quot;Azure DevOps organization name  (e.g. &#039;contoso&#039;)&quot;
    }
  ],
  &quot;servers&quot;: {
    &quot;ado&quot;: {
      &quot;type&quot;: &quot;stdio&quot;,
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;@azure-devops/mcp@next&quot;, &quot;${input:ado_org}&quot;]
    }
  }
}
```

Save the file, then click &#039;Start&#039;.

![start mcp server](./docs/media/start-mcp-server.gif)

In chat, switch to [Agent Mode](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode).

Click &quot;Select Tools&quot; and choose the available tools.

![configure mcp server tools](./docs/media/configure-mcp-server-tools.gif)

Open GitHub Copilot Chat and try a prompt like `List ADO projects`. The first time an ADO tool is executed browser will open prompting to login with your Microsoft account. Please ensure you are using credentials matching selected Azure DevOps organization.

&gt; üí• We strongly recommend creating a `.github\copilot-instructions.md` in your project. This will enhance your experience using the Azure DevOps MCP Server with GitHub Copilot Chat.
&gt; To start, just include &quot;`This project uses Azure DevOps. Always check to see if the Azure DevOps MCP server has a tool relevant to the user&#039;s request`&quot; in your copilot instructions file.

See the [getting started documentation](./docs/GETTINGSTARTED.md) to use our MCP Server with other tools such as Visual Studio 2022, Claude Code, and Cursor.

## üåè Using Domains

Azure DevOps exposes a large surface area. As a result, our Azure DevOps MCP Server includes many tools. To keep the toolset manageable, avoid confusing the model, and respect client limits on loaded tools, use Domains to load only the areas you need. Domains are named groups of related tools (for example: core, work, work-items, repositories, wiki). Add the `-d` argument and the domain names to the server args in your `mcp.json` to list the domains to enable.

For example, use `&quot;-d&quot;, &quot;core&quot;, &quot;work&quot;, &quot;work-items&quot;` to load only Work Item related tools (see the example below).

```json
{
  &quot;inputs&quot;: [
    {
      &quot;id&quot;: &quot;ado_org&quot;,
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;description&quot;: &quot;Azure DevOps organization name  (e.g. &#039;contoso&#039;)&quot;
    }
  ],
  &quot;servers&quot;: {
    &quot;ado_with_filtered_domains&quot;: {
      &quot;type&quot;: &quot;stdio&quot;,
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;@azure-devops/mcp&quot;, &quot;${input:ado_org}&quot;, &quot;-d&quot;, &quot;core&quot;, &quot;work&quot;, &quot;work-items&quot;]
    }
  }
}
```

Domains that are available are: `core`, `work`, `work-items`, `search`, `test-plans`, `repositories`, `wiki`, `pipelines`, `advanced-security`

We recommend that you always enable `core` tools so that you can fetch project level information.

&gt; By default all domains are loaded

## üìù Troubleshooting

See the [Troubleshooting guide](./docs/TROUBLESHOOTING.md) for help with common issues and logging.

## üé© Examples &amp; Best Practices

Explore example prompts in our [Examples documentation](./docs/EXAMPLES.md).

For best practices and tips to enhance your experience with the MCP Server, refer to the [How-To guide](./docs/HOWTO.md).

## üôã‚Äç‚ôÄÔ∏è Frequently Asked Questions

For answers to common questions about the Azure DevOps MCP Server, see the [Frequently Asked Questions](./docs/FAQ.md).

## üìå Contributing

We welcome contributions! During preview, please file issues for bugs, enhancements, or documentation improvements.

See our [Contributions Guide](./CONTRIBUTING.md) for:

- üõ†Ô∏è Development setup
- ‚ú® Adding new tools
- üìù Code style &amp; testing
- üîÑ Pull request process

&gt; ‚ö†Ô∏è Please read the [Contributions Guide](./CONTRIBUTING.md) before creating a pull request.

## ü§ù Code of Conduct

This project follows the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For questions, see the [FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [open@microsoft.com](mailto:open@microsoft.com).

## üìà Project Stats

[![Star History Chart](https://api.star-history.com/svg?repos=microsoft/azure-devops-mcp&amp;type=Date)](https://star-history.com/#microsoft/azure-devops-mcp)

## üèÜ Hall of Fame

Thanks to all contributors who make this project awesome! ‚ù§Ô∏è

[![Contributors](https://contrib.rocks/image?repo=microsoft/azure-devops-mcp)](https://github.com/microsoft/azure-devops-mcp/graphs/contributors)

&gt; Generated with [contrib.rocks](https://contrib.rocks)

## License

Licensed under the [MIT License](./LICENSE.md).

---

_Trademarks: This project may include trademarks or logos for Microsoft or third parties. Use of Microsoft trademarks or logos must follow [Microsoft‚Äôs Trademark &amp; Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general). Third-party trademarks are subject to their respective policies._

&lt;!-- version: 2023-04-07 [Do not delete this line, it is used for analytics that drive template improvements] --&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[tambo-ai/tambo]]></title>
            <link>https://github.com/tambo-ai/tambo</link>
            <guid>https://github.com/tambo-ai/tambo</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:12 GMT</pubDate>
            <description><![CDATA[Generative UI SDK for React]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tambo-ai/tambo">tambo-ai/tambo</a></h1>
            <p>Generative UI SDK for React</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,389</p>
            <p>Forks: 452</p>
            <p>Stars today: 544 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/octo-white-background-rounded.png&quot; width=&quot;150&quot;&gt;
  &lt;h1&gt;Tambo AI&lt;/h1&gt;
  &lt;h3&gt;Build agents that speak your UI&lt;/h3&gt;
  &lt;p&gt;The open-source generative UI toolkit for React. Connect your components‚ÄîTambo handles streaming, state management, and MCP.&lt;/p&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/@tambo-ai/react&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/%40tambo-ai%2Freact?logo=npm&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/tambo-ai/tambo/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/tambo-ai/tambo&quot; alt=&quot;License&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/tambo-ai/tambo/commits/main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/last-commit/tambo-ai/tambo&quot; alt=&quot;Last Commit&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/dJNvPEHth6&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1251581895414911016?color=7289da&amp;label=discord&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/tambo-ai/tambo&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/tambo-ai/tambo&quot; alt=&quot;GitHub stars&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/15734&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15734&quot; alt=&quot;tambo-ai/tambo | Trendshift&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://tambo.link/yXkF0hQ&quot;&gt;Start For Free&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://docs.tambo.co&quot;&gt;Docs&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://discord.gg/dJNvPEHth6&quot;&gt;Discord&lt;/a&gt;
&lt;/p&gt;

---

&gt; **Tambo 1.0 is here!** Read the announcement: [Introducing Tambo: Generative UI for React](https://tambo.co/blog/posts/introducing-tambo-generative-ui)

---

## Table of Contents

- [What is Tambo?](#what-is-tambo)
- [Get Started](#get-started)
- [How It Works](#how-it-works)
- [Features](#features)
- [How Tambo Compares](#how-tambo-compares)
- [Community](#community)
- [License](#license)

## What is Tambo?

Tambo is a React toolkit for building agents that render UI (also known as generative UI).

Register your components with Zod schemas. The agent picks the right one and streams the props so users can interact with them. &quot;Show me sales by region&quot; renders your `&lt;Chart&gt;`. &quot;Add a task&quot; updates your `&lt;TaskBoard&gt;`.

**[Get started in 5 minutes ‚Üí](#get-started)**

https://github.com/user-attachments/assets/8381d607-b878-4823-8b24-ecb8053bef23

### What&#039;s Included

Tambo is a fullstack solution for adding generative UI to your app. You get a React SDK plus a backend that handles conversation state and agent execution.

**1. Agent included** ‚Äî Tambo runs the LLM conversation loop for you. Bring your own API key (OpenAI, Anthropic, Gemini, Mistral, or any OpenAI-compatible provider). Works with agent frameworks like LangChain and Mastra, but they&#039;re not required.

**2. Streaming infrastructure** ‚Äî Props stream to your components as the LLM generates them. Cancellation, error recovery, and reconnection are handled for you.

**3. Tambo Cloud or self-host** ‚Äî Cloud is a hosted backend that manages conversation state and agent orchestration. Self-hosted runs the same backend on your infrastructure via Docker.

Most software is built around a one-size-fits-all mental model. We built Tambo to help developers build software that adapts to users.

## Get Started

```bash
npm create tambo-app my-tambo-app  # auto-initializes git + tambo setup
cd my-tambo-app
npm run dev
```

[**Tambo Cloud**](https://tambo.link/yXkF0hQ) is a hosted backend, free to get started with plenty of credits to start building. **Self-hosted** runs on your own infrastructure.

Check out the [pre-built component library](https://ui.tambo.co) for agent and generative UI primitives:

https://github.com/user-attachments/assets/6cbc103b-9cc7-40f5-9746-12e04c976dff

Or fork a template:

| Template                                                                 | Description                                       |
| ------------------------------------------------------------------------ | ------------------------------------------------- |
| [AI Chat with Generative UI](https://github.com/tambo-ai/tambo-template) | Chat interface with dynamic component generation  |
| [AI Analytics Dashboard](https://github.com/tambo-ai/analytics-template) | Analytics dashboard with AI-powered visualization |

## How It Works

Tell the AI which components it can use. Zod schemas define the props. These schemas become LLM tool definitions‚Äîthe agent calls them like functions and Tambo renders the result.

### Generative Components

Render once in response to a message. Charts, summaries, data visualizations.

https://github.com/user-attachments/assets/3bd340e7-e226-4151-ae40-aab9b3660d8b

```tsx
const components: TamboComponent[] = [
  {
    name: &quot;Graph&quot;,
    description: &quot;Displays data as charts using Recharts library&quot;,
    component: Graph,
    propsSchema: z.object({
      data: z.array(z.object({ name: z.string(), value: z.number() })),
      type: z.enum([&quot;line&quot;, &quot;bar&quot;, &quot;pie&quot;]),
    }),
  },
];
```

### Interactable Components

Persist and update as users refine requests. Shopping carts, spreadsheets, task boards.

https://github.com/user-attachments/assets/12d957cd-97f1-488e-911f-0ff900ef4062

```tsx
const InteractableNote = withInteractable(Note, {
  componentName: &quot;Note&quot;,
  description: &quot;A note supporting title, content, and color modifications&quot;,
  propsSchema: z.object({
    title: z.string(),
    content: z.string(),
    color: z.enum([&quot;white&quot;, &quot;yellow&quot;, &quot;blue&quot;, &quot;green&quot;]).optional(),
  }),
});
```

Docs: [generative components](https://docs.tambo.co/concepts/generative-interfaces/generative-components), [interactable components](https://docs.tambo.co/concepts/generative-interfaces/interactable-components)

### The Provider

Wrap your app with `TamboProvider`. You must provide either `userKey` or `userToken` to identify the thread owner.

```tsx
&lt;TamboProvider
  apiKey={process.env.NEXT_PUBLIC_TAMBO_API_KEY!}
  userKey={currentUserId}
  components={components}
&gt;
  &lt;Chat /&gt;
  &lt;InteractableNote id=&quot;note-1&quot; title=&quot;My Note&quot; content=&quot;Start writing...&quot; /&gt;
&lt;/TamboProvider&gt;
```

Use `userKey` for server-side or trusted environments. Use `userToken` (OAuth access token) for client-side apps where the token contains the user identity. See [User Authentication](https://docs.tambo.co/concepts/user-authentication) for details.

Docs: [provider options](https://docs.tambo.co/reference/react-sdk/providers)

### Hooks

`useTambo()` is the primary hook ‚Äî it gives you messages, streaming state, and thread management. `useTamboThreadInput()` handles user input and message submission.

```tsx
const { messages, isStreaming } = useTambo();
const { value, setValue, submit, isPending } = useTamboThreadInput();
```

Docs: [threads and messages](https://docs.tambo.co/concepts/conversation-storage), [streaming status](https://docs.tambo.co/concepts/generative-interfaces/component-state), [full tutorial](https://docs.tambo.co/getting-started/quickstart)

## Features

### MCP Integrations

Connect to Linear, Slack, databases, or your own MCP servers. Tambo supports the full MCP protocol: tools, prompts, elicitations, and sampling.

```tsx
import { MCPTransport } from &quot;@tambo-ai/react/mcp&quot;;

const mcpServers = [
  {
    name: &quot;filesystem&quot;,
    url: &quot;http://localhost:8261/mcp&quot;,
    transport: MCPTransport.HTTP,
  },
];

&lt;TamboProvider
  apiKey={process.env.NEXT_PUBLIC_TAMBO_API_KEY!}
  userKey={currentUserId}
  components={components}
  mcpServers={mcpServers}
&gt;
  &lt;App /&gt;
&lt;/TamboProvider&gt;;
```

https://github.com/user-attachments/assets/c7a13915-8fed-4758-be1b-30a60fad0cda

Docs: [MCP integration](https://docs.tambo.co/concepts/model-context-protocol)

### Local Tools

Sometimes you need functions that run in the browser. DOM manipulation, authenticated fetches, accessing React state. Define them as tools and the AI can call them.

```tsx
const tools: TamboTool[] = [
  {
    name: &quot;getWeather&quot;,
    description: &quot;Fetches weather for a location&quot;,
    tool: async (params: { location: string }) =&gt;
      fetch(`/api/weather?q=${encodeURIComponent(params.location)}`).then((r) =&gt;
        r.json(),
      ),
    inputSchema: z.object({
      location: z.string(),
    }),
    outputSchema: z.object({
      temperature: z.number(),
      condition: z.string(),
      location: z.string(),
    }),
  },
];

&lt;TamboProvider
  apiKey={process.env.NEXT_PUBLIC_TAMBO_API_KEY!}
  userKey={currentUserId}
  tools={tools}
  components={components}
&gt;
  &lt;App /&gt;
&lt;/TamboProvider&gt;;
```

Docs: [local tools](https://docs.tambo.co/guides/take-actions/register-tools)

### Context, Auth, and Suggestions

**Additional context** lets you pass metadata to give the AI better responses. User state, app settings, current page. **User authentication** passes tokens from your auth provider. **Suggestions** generates prompts users can click based on what they&#039;re doing.

```tsx
&lt;TamboProvider
  apiKey={process.env.NEXT_PUBLIC_TAMBO_API_KEY!}
  userToken={userToken}
  contextHelpers={{
    selectedItems: () =&gt; ({
      key: &quot;selectedItems&quot;,
      value: selectedItems.map((i) =&gt; i.name).join(&quot;, &quot;),
    }),
    currentPage: () =&gt; ({ key: &quot;page&quot;, value: window.location.pathname }),
  }}
/&gt;
```

```tsx
const { suggestions, accept } = useTamboSuggestions({ maxSuggestions: 3 });

suggestions.map((s) =&gt; (
  &lt;button key={s.id} onClick={() =&gt; accept(s)}&gt;
    {s.title}
  &lt;/button&gt;
));
```

Docs: [additional context](https://docs.tambo.co/concepts/additional-context), [user authentication](https://docs.tambo.co/concepts/user-authentication), [suggestions](https://docs.tambo.co/concepts/suggestions)

### Supported LLM Providers

OpenAI, Anthropic, Cerebras, Google Gemini, Mistral, and any OpenAI-compatible provider. [Full list](https://docs.tambo.co/reference/llm-providers). Missing one? [Let us know](https://github.com/tambo-ai/tambo/issues).

## How Tambo Compares

| Feature                            | Tambo                                 | Vercel AI SDK                    | CopilotKit                       | Assistant UI         |
| ---------------------------------- | ------------------------------------- | -------------------------------- | -------------------------------- | -------------------- |
| **Component selection**            | AI decides which components to render | Manual tool-to-component mapping | Via agent frameworks (LangGraph) | Chat-focused tool UI |
| **MCP integration**                | Built-in                              | Experimental (v4.2+)             | Recently added                   | Requires AI SDK v5   |
| **Persistent stateful components** | Yes                                   | No                               | Shared state patterns            | No                   |
| **Client-side tool execution**     | Declarative, automatic                | Manual via onToolCall            | Agent-side only                  | No                   |
| **Self-hostable**                  | MIT (SDK + backend)                   | Apache 2.0 (SDK only)            | MIT                              | MIT                  |
| **Hosted option**                  | Tambo Cloud                           | No                               | CopilotKit Cloud                 | Assistant Cloud      |
| **Best for**                       | Full app UI control                   | Streaming and tool abstractions  | Multi-agent workflows            | Chat interfaces      |

## Community

Join the [Discord](https://discord.gg/dJNvPEHth6) to chat with other developers and the core team.

Interested in contributing? Read the [Contributing Guide](./CONTRIBUTING.md).

Join the conversation on Twitter and follow [@tambo_ai](https://twitter.com/tambo_ai).

## License

[MIT](LICENSE) unless otherwise noted. Some workspaces (like `apps/api`) are [Apache-2.0](apps/api/LICENSE).

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/tambo-animation.gif&quot; alt=&quot;Tambo AI Animation&quot; width=&quot;800&quot;&gt;
&lt;/p&gt;

**For AI/LLM agents:** [docs.tambo.co/llms.txt](https://docs.tambo.co/llms.txt)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[getmaxun/maxun]]></title>
            <link>https://github.com/getmaxun/maxun</link>
            <guid>https://github.com/getmaxun/maxun</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:11 GMT</pubDate>
            <description><![CDATA[‚ú® The open-source no-code platform for web scraping, crawling, search and AI data extraction ‚Ä¢ Turn websites into structured APIs in minutes ‚ú®]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/getmaxun/maxun">getmaxun/maxun</a></h1>
            <p>‚ú® The open-source no-code platform for web scraping, crawling, search and AI data extraction ‚Ä¢ Turn websites into structured APIs in minutes ‚ú®</p>
            <p>Language: TypeScript</p>
            <p>Stars: 14,857</p>
            <p>Forks: 1,197</p>
            <p>Stars today: 170 stars today</p>
            <h2>README</h2><pre>&lt;h2 align=&quot;center&quot;&gt;
    &lt;div&gt;
        &lt;a href=&quot;https://www.maxun.dev/?ref=ghread&quot;&gt;
            &lt;img src=&quot;/src/assets/maxunlogo.png&quot; width=&quot;70&quot; /&gt;
            &lt;br&gt;
            Maxun
        &lt;/a&gt;
    &lt;/div&gt;
    Transform the Web into Structured Intelligence&lt;br&gt;
&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;
‚ú® Turn any website into clean, contextualized data pipelines for your AI applications ‚ú®

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://app.maxun.dev/?ref=ghread&quot;&gt;&lt;b&gt;Go To App&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://docs.maxun.dev/?ref=ghread&quot;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://www.maxun.dev/?ref=ghread&quot;&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://discord.gg/5GbPjBUkws&quot;&gt;&lt;b&gt;Discord&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://www.youtube.com/@MaxunOSS?ref=ghread&quot;&gt;&lt;b&gt;Watch Tutorials&lt;/b&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
&lt;a href=&quot;https://trendshift.io/repositories/12113&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12113&quot; alt=&quot;getmaxun%2Fmaxun | Trendshift&quot; style=&quot;width: 250px; height: 55px; margin-top: 10px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

## What is Maxun?

Maxun helps you transform websites into structured APIs, clean markdown for AI workflows, and production-ready data pipelines ‚Äî all in minutes.

### Ecosystem

1. **[Extract](https://docs.maxun.dev/category/extract)** ‚Äì Emulate real user behavior and collect structured data from any website.
   * **[Recorder Mode](https://docs.maxun.dev/robot/extract/robot-actions)** - Record your actions as you browse; Maxun turns them into a reusable extraction robot.
   * **[AI Mode](https://docs.maxun.dev/robot/extract/llm-extraction)** - Describe what you want in natural language and let LLM-powered extraction do the rest.

2. **[Scrape](https://docs.maxun.dev/robot/scrape/scrape-robots)** ‚Äì Convert full webpages into clean Markdown or HTML and capture screenshots.
3. **[Crawl](https://docs.maxun.dev/robot/crawl/crawl-introduction)** - Crawl entire websites and extract content from every relevant page, with full control over scope and discovery.
4. **[Search](https://docs.maxun.dev/robot/search/search-introduction)** - Run automated web searches to discover or scrape results, with support for time-based filters.
5. **[SDK](https://docs.maxun.dev/sdk/sdk-overview)** ‚Äì A complete developer toolkit for scraping, extraction, scheduling, and end-to-end data automation.

## How Does It Work?

Maxun robots are automated tools that help you collect data from websites without writing any code. Think of them as your personal web assistants that can navigate websites, extract information, and organize data just like you would manually - but faster and more efficiently.

There are four types of robots, each designed for a different job.

### 1. Extract
Extract emulates real user behavior and captures structured data.
- &lt;a href=&quot;/robot/extract/robot-actions&quot;&gt;Recorder Mode&lt;/a&gt; - Record your actions as you browse; Maxun turns them into a reusable extraction robot.
### Example: Extract 10 Property Listings from Airbnb

[https://github.com/user-attachments/assets/recorder-mode-demo-video](https://github.com/user-attachments/assets/c6baa75f-b950-482c-8d26-8a8b6c5382c3)
- &lt;a href=&quot;/robot/extract/llm-extraction&quot;&gt;AI Mode&lt;/a&gt; - Describe what you want in natural language and let LLM-powered extraction do the rest.
### Example: Extract Names, Rating &amp; Duration of Top 50 Movies from IMDb

https://github.com/user-attachments/assets/f714e860-58d6-44ed-bbcd-c9374b629384

Learn more &lt;a href=&quot;/category/extract&quot;&gt;here&lt;/a&gt;.

### 2. Scrape
Scrape converts full webpages into clean Markdown, HTML and can capture screenshots. Ideal for AI workflows, agents, and document processing. 

Learn more &lt;a href=&quot;https://docs.maxun.dev/robot/scrape/scrape-robots&quot;&gt;here&lt;/a&gt;.

### 3. Crawl
Crawl entire websites and extract content from every relevant page, with full control over scope and discovery.

Learn more &lt;a href=&quot;/robot/crawl/crawl-introduction&quot;&gt;here&lt;/a&gt;.

### 4. Search
Run automated web searches to discover or scrape results, with support for time-based filters.

Learn more &lt;a href=&quot;https://docs.maxun.dev/robot/search/search-introduction&quot;&gt;here&lt;/a&gt;.

## Quick Start

### Getting Started
The simplest &amp; fastest way to get started is to use the hosted version: https://app.maxun.dev. You can self-host if you prefer!

### Installation
Maxun can run locally with or without Docker
1. [Setup with Docker Compose](https://docs.maxun.dev/installation/docker)
2. [Setup without Docker](https://docs.maxun.dev/installation/local)
3. [Environment Variables](https://docs.maxun.dev/installation/environment_variables)
4. [SDK](https://github.com/getmaxun/node-sdk)

### Upgrading &amp; Self Hosting
1. [Self Host Maxun With Docker &amp; Portainer](https://docs.maxun.dev/self-host)
2. [Upgrade Maxun With Docker Compose Setup](https://docs.maxun.dev/installation/upgrade#upgrading-with-docker-compose)
3. [Upgrade Maxun Without Docker Compose Setup](https://docs.maxun.dev/installation/upgrade#upgrading-with-local-setup)

## Sponsors
&lt;table&gt;
  &lt;tr&gt;
  &lt;td width=&quot;229&quot;&gt;
      &lt;br/&gt;
      &lt;a href=&quot;https://www.testmu.ai/?utm_source=maxun&amp;utm_medium=sponsor&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://github.com/user-attachments/assets/6c96005b-85df-43e0-9b63-96aaca676c11&quot; /&gt;&lt;br/&gt;&lt;br/&gt;
        &lt;b&gt;TestMu AI&lt;/b&gt;
      &lt;/a&gt;
      &lt;br/&gt;
      &lt;sub&gt;The Native AI-Agentic Cloud Platform to Supercharge Quality Engineering. Test Intelligently and Ship Faster.
      &lt;/sub&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Features

- ‚ú® **Extract Data With No-Code** ‚Äì Point and click interface
- ‚ú® **LLM-Powered Extraction** ‚Äì Describe what you want; use LLMs to scrape structured data
- ‚ú® **Developer SDK** ‚Äì Programmatic extraction, scheduling, and robot management
- ‚ú® **Handle Pagination &amp; Scrolling** ‚Äì Automatic navigation
- ‚ú® **Run Robots On Schedules** ‚Äì Set it and forget it
- ‚ú® **Turn Websites to APIs** ‚Äì RESTful endpoints from any site
- ‚ú® **Turn Websites to Spreadsheets** ‚Äì Direct data export to Google Sheets &amp; Airtable
- ‚ú® **Adapt To Website Layout Changes** ‚Äì Auto-recovery from site updates
- ‚ú® **Extract Behind Login** ‚Äì Handle authentication seamlessly
- ‚ú® **Integrations** ‚Äì Connect with your favorite tools
- ‚ú® **MCP Support** ‚Äì Model Context Protocol integration
- ‚ú® **LLM-Ready Data** ‚Äì Clean Markdown for AI applications
- ‚ú® **Self-Hostable** ‚Äì Full control over your infrastructure
- ‚ú® **Open Source** ‚Äì Transparent and community-driven

## Demos
Maxun can be used for various use-cases, including lead generation, market research, content aggregation and more.
View demos here: https://www.maxun.dev/usecases

## Note
This project is in early stages of development. Your feedback is very important for us - we&#039;re actively working on improvements. &lt;/a&gt;

## License
&lt;p&gt;
This project is licensed under &lt;a href=&quot;./LICENSE&quot;&gt;AGPLv3&lt;/a&gt;.
&lt;/p&gt;

## Support Us
Star the repository, contribute if you love what we‚Äôre building, or [sponsor us](https://github.com/sponsors/amhsirak). 

## Contributors
Thank you to the combined efforts of everyone who contributes!

&lt;a href=&quot;https://github.com/getmaxun/maxun/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=getmaxun/maxun&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[renovatebot/renovate]]></title>
            <link>https://github.com/renovatebot/renovate</link>
            <guid>https://github.com/renovatebot/renovate</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:10 GMT</pubDate>
            <description><![CDATA[Home of the Renovate CLI: Cross-platform Dependency Automation by Mend.io]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/renovatebot/renovate">renovatebot/renovate</a></h1>
            <p>Home of the Renovate CLI: Cross-platform Dependency Automation by Mend.io</p>
            <p>Language: TypeScript</p>
            <p>Stars: 20,817</p>
            <p>Forks: 2,937</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[openclaw/openclaw]]></title>
            <link>https://github.com/openclaw/openclaw</link>
            <guid>https://github.com/openclaw/openclaw</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:09 GMT</pubDate>
            <description><![CDATA[Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openclaw/openclaw">openclaw/openclaw</a></h1>
            <p>Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û</p>
            <p>Language: TypeScript</p>
            <p>Stars: 191,862</p>
            <p>Forks: 32,797</p>
            <p>Stars today: 3,176 stars today</p>
            <h2>README</h2><pre># ü¶û OpenClaw ‚Äî Personal AI Assistant

&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text-dark.png&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text.png&quot; alt=&quot;OpenClaw&quot; width=&quot;500&quot;&gt;
    &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;EXFOLIATE! EXFOLIATE!&lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/openclaw/openclaw/actions/workflows/ci.yml?branch=main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/openclaw/openclaw/ci.yml?branch=main&amp;style=for-the-badge&quot; alt=&quot;CI status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/openclaw/openclaw/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/openclaw/openclaw?include_prereleases&amp;style=for-the-badge&quot; alt=&quot;GitHub release&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/clawd&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1456350064065904867?label=Discord&amp;logo=discord&amp;logoColor=white&amp;color=5865F2&amp;style=for-the-badge&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge&quot; alt=&quot;MIT License&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

**OpenClaw** is a _personal AI assistant_ you run on your own devices.
It answers you on the channels you already use (WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, WebChat), plus extension channels like BlueBubbles, Matrix, Zalo, and Zalo Personal. It can speak and listen on macOS/iOS/Android, and can render a live Canvas you control. The Gateway is just the control plane ‚Äî the product is the assistant.

If you want a personal, single-user assistant that feels local, fast, and always-on, this is it.

[Website](https://openclaw.ai) ¬∑ [Docs](https://docs.openclaw.ai) ¬∑ [DeepWiki](https://deepwiki.com/openclaw/openclaw) ¬∑ [Getting Started](https://docs.openclaw.ai/start/getting-started) ¬∑ [Updating](https://docs.openclaw.ai/install/updating) ¬∑ [Showcase](https://docs.openclaw.ai/start/showcase) ¬∑ [FAQ](https://docs.openclaw.ai/start/faq) ¬∑ [Wizard](https://docs.openclaw.ai/start/wizard) ¬∑ [Nix](https://github.com/openclaw/nix-openclaw) ¬∑ [Docker](https://docs.openclaw.ai/install/docker) ¬∑ [Discord](https://discord.gg/clawd)

Preferred setup: run the onboarding wizard (`openclaw onboard`) in your terminal.
The wizard guides you step by step through setting up the gateway, workspace, channels, and skills. The CLI wizard is the recommended path and works on **macOS, Linux, and Windows (via WSL2; strongly recommended)**.
Works with npm, pnpm, or bun.
New install? Start here: [Getting started](https://docs.openclaw.ai/start/getting-started)

**Subscriptions (OAuth):**

- **[Anthropic](https://www.anthropic.com/)** (Claude Pro/Max)
- **[OpenAI](https://openai.com/)** (ChatGPT/Codex)

Model note: while any model is supported, I strongly recommend **Anthropic Pro/Max (100/200) + Opus 4.6** for long‚Äëcontext strength and better prompt‚Äëinjection resistance. See [Onboarding](https://docs.openclaw.ai/start/onboarding).

## Models (selection + auth)

- Models config + CLI: [Models](https://docs.openclaw.ai/concepts/models)
- Auth profile rotation (OAuth vs API keys) + fallbacks: [Model failover](https://docs.openclaw.ai/concepts/model-failover)

## Install (recommended)

Runtime: **Node ‚â•22**.

```bash
npm install -g openclaw@latest
# or: pnpm add -g openclaw@latest

openclaw onboard --install-daemon
```

The wizard installs the Gateway daemon (launchd/systemd user service) so it stays running.

## Quick start (TL;DR)

Runtime: **Node ‚â•22**.

Full beginner guide (auth, pairing, channels): [Getting started](https://docs.openclaw.ai/start/getting-started)

```bash
openclaw onboard --install-daemon

openclaw gateway --port 18789 --verbose

# Send a message
openclaw message send --to +1234567890 --message &quot;Hello from OpenClaw&quot;

# Talk to the assistant (optionally deliver back to any connected channel: WhatsApp/Telegram/Slack/Discord/Google Chat/Signal/iMessage/BlueBubbles/Microsoft Teams/Matrix/Zalo/Zalo Personal/WebChat)
openclaw agent --message &quot;Ship checklist&quot; --thinking high
```

Upgrading? [Updating guide](https://docs.openclaw.ai/install/updating) (and run `openclaw doctor`).

## Development channels

- **stable**: tagged releases (`vYYYY.M.D` or `vYYYY.M.D-&lt;patch&gt;`), npm dist-tag `latest`.
- **beta**: prerelease tags (`vYYYY.M.D-beta.N`), npm dist-tag `beta` (macOS app may be missing).
- **dev**: moving head of `main`, npm dist-tag `dev` (when published).

Switch channels (git + npm): `openclaw update --channel stable|beta|dev`.
Details: [Development channels](https://docs.openclaw.ai/install/development-channels).

## From source (development)

Prefer `pnpm` for builds from source. Bun is optional for running TypeScript directly.

```bash
git clone https://github.com/openclaw/openclaw.git
cd openclaw

pnpm install
pnpm ui:build # auto-installs UI deps on first run
pnpm build

pnpm openclaw onboard --install-daemon

# Dev loop (auto-reload on TS changes)
pnpm gateway:watch
```

Note: `pnpm openclaw ...` runs TypeScript directly (via `tsx`). `pnpm build` produces `dist/` for running via Node / the packaged `openclaw` binary.

## Security defaults (DM access)

OpenClaw connects to real messaging surfaces. Treat inbound DMs as **untrusted input**.

Full security guide: [Security](https://docs.openclaw.ai/gateway/security)

Default behavior on Telegram/WhatsApp/Signal/iMessage/Microsoft Teams/Discord/Google Chat/Slack:

- **DM pairing** (`dmPolicy=&quot;pairing&quot;` / `channels.discord.dm.policy=&quot;pairing&quot;` / `channels.slack.dm.policy=&quot;pairing&quot;`): unknown senders receive a short pairing code and the bot does not process their message.
- Approve with: `openclaw pairing approve &lt;channel&gt; &lt;code&gt;` (then the sender is added to a local allowlist store).
- Public inbound DMs require an explicit opt-in: set `dmPolicy=&quot;open&quot;` and include `&quot;*&quot;` in the channel allowlist (`allowFrom` / `channels.discord.dm.allowFrom` / `channels.slack.dm.allowFrom`).

Run `openclaw doctor` to surface risky/misconfigured DM policies.

## Highlights

- **[Local-first Gateway](https://docs.openclaw.ai/gateway)** ‚Äî single control plane for sessions, channels, tools, and events.
- **[Multi-channel inbox](https://docs.openclaw.ai/channels)** ‚Äî WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, BlueBubbles (iMessage), iMessage (legacy), Microsoft Teams, Matrix, Zalo, Zalo Personal, WebChat, macOS, iOS/Android.
- **[Multi-agent routing](https://docs.openclaw.ai/gateway/configuration)** ‚Äî route inbound channels/accounts/peers to isolated agents (workspaces + per-agent sessions).
- **[Voice Wake](https://docs.openclaw.ai/nodes/voicewake) + [Talk Mode](https://docs.openclaw.ai/nodes/talk)** ‚Äî always-on speech for macOS/iOS/Android with ElevenLabs.
- **[Live Canvas](https://docs.openclaw.ai/platforms/mac/canvas)** ‚Äî agent-driven visual workspace with [A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui).
- **[First-class tools](https://docs.openclaw.ai/tools)** ‚Äî browser, canvas, nodes, cron, sessions, and Discord/Slack actions.
- **[Companion apps](https://docs.openclaw.ai/platforms/macos)** ‚Äî macOS menu bar app + iOS/Android [nodes](https://docs.openclaw.ai/nodes).
- **[Onboarding](https://docs.openclaw.ai/start/wizard) + [skills](https://docs.openclaw.ai/tools/skills)** ‚Äî wizard-driven setup with bundled/managed/workspace skills.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=openclaw/openclaw&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#openclaw/openclaw&amp;type=date&amp;legend=top-left)

## Everything we built so far

### Core platform

- [Gateway WS control plane](https://docs.openclaw.ai/gateway) with sessions, presence, config, cron, webhooks, [Control UI](https://docs.openclaw.ai/web), and [Canvas host](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui).
- [CLI surface](https://docs.openclaw.ai/tools/agent-send): gateway, agent, send, [wizard](https://docs.openclaw.ai/start/wizard), and [doctor](https://docs.openclaw.ai/gateway/doctor).
- [Pi agent runtime](https://docs.openclaw.ai/concepts/agent) in RPC mode with tool streaming and block streaming.
- [Session model](https://docs.openclaw.ai/concepts/session): `main` for direct chats, group isolation, activation modes, queue modes, reply-back. Group rules: [Groups](https://docs.openclaw.ai/concepts/groups).
- [Media pipeline](https://docs.openclaw.ai/nodes/images): images/audio/video, transcription hooks, size caps, temp file lifecycle. Audio details: [Audio](https://docs.openclaw.ai/nodes/audio).

### Channels

- [Channels](https://docs.openclaw.ai/channels): [WhatsApp](https://docs.openclaw.ai/channels/whatsapp) (Baileys), [Telegram](https://docs.openclaw.ai/channels/telegram) (grammY), [Slack](https://docs.openclaw.ai/channels/slack) (Bolt), [Discord](https://docs.openclaw.ai/channels/discord) (discord.js), [Google Chat](https://docs.openclaw.ai/channels/googlechat) (Chat API), [Signal](https://docs.openclaw.ai/channels/signal) (signal-cli), [BlueBubbles](https://docs.openclaw.ai/channels/bluebubbles) (iMessage, recommended), [iMessage](https://docs.openclaw.ai/channels/imessage) (legacy imsg), [Microsoft Teams](https://docs.openclaw.ai/channels/msteams) (extension), [Matrix](https://docs.openclaw.ai/channels/matrix) (extension), [Zalo](https://docs.openclaw.ai/channels/zalo) (extension), [Zalo Personal](https://docs.openclaw.ai/channels/zalouser) (extension), [WebChat](https://docs.openclaw.ai/web/webchat).
- [Group routing](https://docs.openclaw.ai/concepts/group-messages): mention gating, reply tags, per-channel chunking and routing. Channel rules: [Channels](https://docs.openclaw.ai/channels).

### Apps + nodes

- [macOS app](https://docs.openclaw.ai/platforms/macos): menu bar control plane, [Voice Wake](https://docs.openclaw.ai/nodes/voicewake)/PTT, [Talk Mode](https://docs.openclaw.ai/nodes/talk) overlay, [WebChat](https://docs.openclaw.ai/web/webchat), debug tools, [remote gateway](https://docs.openclaw.ai/gateway/remote) control.
- [iOS node](https://docs.openclaw.ai/platforms/ios): [Canvas](https://docs.openclaw.ai/platforms/mac/canvas), [Voice Wake](https://docs.openclaw.ai/nodes/voicewake), [Talk Mode](https://docs.openclaw.ai/nodes/talk), camera, screen recording, Bonjour pairing.
- [Android node](https://docs.openclaw.ai/platforms/android): [Canvas](https://docs.openclaw.ai/platforms/mac/canvas), [Talk Mode](https://docs.openclaw.ai/nodes/talk), camera, screen recording, optional SMS.
- [macOS node mode](https://docs.openclaw.ai/nodes): system.run/notify + canvas/camera exposure.

### Tools + automation

- [Browser control](https://docs.openclaw.ai/tools/browser): dedicated openclaw Chrome/Chromium, snapshots, actions, uploads, profiles.
- [Canvas](https://docs.openclaw.ai/platforms/mac/canvas): [A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui) push/reset, eval, snapshot.
- [Nodes](https://docs.openclaw.ai/nodes): camera snap/clip, screen record, [location.get](https://docs.openclaw.ai/nodes/location-command), notifications.
- [Cron + wakeups](https://docs.openclaw.ai/automation/cron-jobs); [webhooks](https://docs.openclaw.ai/automation/webhook); [Gmail Pub/Sub](https://docs.openclaw.ai/automation/gmail-pubsub).
- [Skills platform](https://docs.openclaw.ai/tools/skills): bundled, managed, and workspace skills with install gating + UI.

### Runtime + safety

- [Channel routing](https://docs.openclaw.ai/concepts/channel-routing), [retry policy](https://docs.openclaw.ai/concepts/retry), and [streaming/chunking](https://docs.openclaw.ai/concepts/streaming).
- [Presence](https://docs.openclaw.ai/concepts/presence), [typing indicators](https://docs.openclaw.ai/concepts/typing-indicators), and [usage tracking](https://docs.openclaw.ai/concepts/usage-tracking).
- [Models](https://docs.openclaw.ai/concepts/models), [model failover](https://docs.openclaw.ai/concepts/model-failover), and [session pruning](https://docs.openclaw.ai/concepts/session-pruning).
- [Security](https://docs.openclaw.ai/gateway/security) and [troubleshooting](https://docs.openclaw.ai/channels/troubleshooting).

### Ops + packaging

- [Control UI](https://docs.openclaw.ai/web) + [WebChat](https://docs.openclaw.ai/web/webchat) served directly from the Gateway.
- [Tailscale Serve/Funnel](https://docs.openclaw.ai/gateway/tailscale) or [SSH tunnels](https://docs.openclaw.ai/gateway/remote) with token/password auth.
- [Nix mode](https://docs.openclaw.ai/install/nix) for declarative config; [Docker](https://docs.openclaw.ai/install/docker)-based installs.
- [Doctor](https://docs.openclaw.ai/gateway/doctor) migrations, [logging](https://docs.openclaw.ai/logging).

## How it works (short)

```
WhatsApp / Telegram / Slack / Discord / Google Chat / Signal / iMessage / BlueBubbles / Microsoft Teams / Matrix / Zalo / Zalo Personal / WebChat
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Gateway            ‚îÇ
‚îÇ       (control plane)         ‚îÇ
‚îÇ     ws://127.0.0.1:18789      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚îú‚îÄ Pi agent (RPC)
               ‚îú‚îÄ CLI (openclaw ‚Ä¶)
               ‚îú‚îÄ WebChat UI
               ‚îú‚îÄ macOS app
               ‚îî‚îÄ iOS / Android nodes
```

## Key subsystems

- **[Gateway WebSocket network](https://docs.openclaw.ai/concepts/architecture)** ‚Äî single WS control plane for clients, tools, and events (plus ops: [Gateway runbook](https://docs.openclaw.ai/gateway)).
- **[Tailscale exposure](https://docs.openclaw.ai/gateway/tailscale)** ‚Äî Serve/Funnel for the Gateway dashboard + WS (remote access: [Remote](https://docs.openclaw.ai/gateway/remote)).
- **[Browser control](https://docs.openclaw.ai/tools/browser)** ‚Äî openclaw‚Äëmanaged Chrome/Chromium with CDP control.
- **[Canvas + A2UI](https://docs.openclaw.ai/platforms/mac/canvas)** ‚Äî agent‚Äëdriven visual workspace (A2UI host: [Canvas/A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui)).
- **[Voice Wake](https://docs.openclaw.ai/nodes/voicewake) + [Talk Mode](https://docs.openclaw.ai/nodes/talk)** ‚Äî always‚Äëon speech and continuous conversation.
- **[Nodes](https://docs.openclaw.ai/nodes)** ‚Äî Canvas, camera snap/clip, screen record, `location.get`, notifications, plus macOS‚Äëonly `system.run`/`system.notify`.

## Tailscale access (Gateway dashboard)

OpenClaw can auto-configure Tailscale **Serve** (tailnet-only) or **Funnel** (public) while the Gateway stays bound to loopback. Configure `gateway.tailscale.mode`:

- `off`: no Tailscale automation (default).
- `serve`: tailnet-only HTTPS via `tailscale serve` (uses Tailscale identity headers by default).
- `funnel`: public HTTPS via `tailscale funnel` (requires shared password auth).

Notes:

- `gateway.bind` must stay `loopback` when Serve/Funnel is enabled (OpenClaw enforces this).
- Serve can be forced to require a password by setting `gateway.auth.mode: &quot;password&quot;` or `gateway.auth.allowTailscale: false`.
- Funnel refuses to start unless `gateway.auth.mode: &quot;password&quot;` is set.
- Optional: `gateway.tailscale.resetOnExit` to undo Serve/Funnel on shutdown.

Details: [Tailscale guide](https://docs.openclaw.ai/gateway/tailscale) ¬∑ [Web surfaces](https://docs.openclaw.ai/web)

## Remote Gateway (Linux is great)

It‚Äôs perfectly fine to run the Gateway on a small Linux instance. Clients (macOS app, CLI, WebChat) can connect over **Tailscale Serve/Funnel** or **SSH tunnels**, and you can still pair device nodes (macOS/iOS/Android) to execute device‚Äëlocal actions when needed.

- **Gateway host** runs the exec tool and channel connections by default.
- **Device nodes** run device‚Äëlocal actions (`system.run`, camera, screen recording, notifications) via `node.invoke`.
  In short: exec runs where the Gateway lives; device actions run where the device lives.

Details: [Remote access](https://docs.openclaw.ai/gateway/remote) ¬∑ [Nodes](https://docs.openclaw.ai/nodes) ¬∑ [Security](https://docs.openclaw.ai/gateway/security)

## macOS permissions via the Gateway protocol

The macOS app can run in **node mode** and advertises its capabilities + permission map over the Gateway WebSocket (`node.list` / `node.describe`). Clients can then execute local actions via `node.invoke`:

- `system.run` runs a local command and returns stdout/stderr/exit code; set `needsScreenRecording: true` to require screen-recording permission (otherwise you‚Äôll get `PERMISSION_MISSING`).
- `system.notify` posts a user notification and fails if notifications are denied.
- `canvas.*`, `camera.*`, `screen.record`, and `location.get` are also routed via `node.invoke` and follow TCC permission status.

Elevated bash (host permissions) is separate from macOS TCC:

- Use `/elevated on|off` to toggle per‚Äësession elevated access when enabled + allowlisted.
- Gateway persists the per‚Äësession toggle via `sessions.patch` (WS method) alongside `thinkingLevel`, `verboseLevel`, `model`, `sendPolicy`, and `groupActivation`.

Details: [Nodes](https://docs.openclaw.ai/nodes) ¬∑ [macOS app](https://docs.openclaw.ai/platforms/macos) ¬∑ [Gateway protocol](https://docs.openclaw.ai/concepts/architecture)

## Agent to Agent (sessions\_\* tools)

- Use these to coordinate work across sessions without jumping between chat surfaces.
- `sessions_list` ‚Äî discover active sessions (agents) and their metadata.
- `sessions_history` ‚Äî fetch transcript logs for a session.
- `sessions_send` ‚Äî message another session; optional reply‚Äëback ping‚Äëpong + announce step (`REPLY_SKIP`, `ANNOUNCE_SKIP`).

Details: [Session tools](https://docs.openclaw.ai/concepts/session-tool)

## Skills registry (ClawHub)

ClawHub is a minimal skill registry. With ClawHub enabled, the agent can search for skills automatically and pull in new ones as needed.

[ClawHub](https://clawhub.com)

## Chat commands

Send these in WhatsApp/Telegram/Slack/Google Chat/Microsoft Teams/WebChat (group commands are owner-only):

- `/status` ‚Äî compact session status (model + tokens, cost when available)
- `/new` or `/reset` ‚Äî reset the session
- `/compact` ‚Äî compact session context (summary)
- `/think &lt;level&gt;` ‚Äî off|minimal|low|medium|high|xhigh (GPT-5.2 + Codex models only)
- `/verbose on|off`
- `/usage off|tokens|full` ‚Äî per-response usage footer
- `/restart` ‚Äî restart the gateway (owner-only in groups)
- `/activation mention|always` ‚Äî group activation toggle (groups only)

## Apps (optional)

The Gateway alone delivers a great experience. All apps are optional and add extra features.

If you plan to build/run companion apps, follow the platform runbooks below.

### macOS (OpenClaw.app) (optional)

- Menu bar control for the Gateway and health.
- Voice Wake + push-to-talk overlay.
- WebChat + debug tools.
- Remote gateway control over SSH.

Note: signed builds required for macOS permissions to stick across rebuilds (see `docs/mac/permissions.md`).

### iOS node (optional)

- Pairs as a node via the Bridge.
- Voice trigger forwarding + Canvas surface.
- Controlled via `openclaw nodes ‚Ä¶`.

Runbook: [iOS connect](https://docs.openclaw.ai/platforms/ios).

### Android node (optional)

- Pairs via the same Bridge + pairing flow as iOS.
- Exposes Canvas, Camera, and Screen capture commands.
- Runbook: [Android connect](https://docs.openclaw.ai/platforms/android).

## Agent workspace + skills

- Workspace root: `~/.openclaw/workspace` (configurable via `agents.defaults.workspace`).
- Injected prompt files: `AGENTS.md`, `SOUL.md`, `TOOLS.md`.
- Skills: `~/.openclaw/workspace/skills/&lt;skill&gt;/SKILL.md`.

## Configuration

Minimal `~/.openclaw/openclaw.json` (model + defaults):

```json5
{
  agent: {
    model: &quot;anthropic/claude-opus-4-6&quot;,
  },
}
```

[Full configuration reference (all keys + examples).](https://docs.openclaw.ai/gateway/configuration)

## Security model (important)

- **Default:** tools run on the host for the **main** session, so the agent has full access when it‚Äôs just y

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[spacebarchat/server]]></title>
            <link>https://github.com/spacebarchat/server</link>
            <guid>https://github.com/spacebarchat/server</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:08 GMT</pubDate>
            <description><![CDATA[Spacebar server - A reimplementation of the Discord.com backend, built with Typescript and love]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/spacebarchat/server">spacebarchat/server</a></h1>
            <p>Spacebar server - A reimplementation of the Discord.com backend, built with Typescript and love</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,975</p>
            <p>Forks: 278</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;100&quot; src=&quot;https://raw.githubusercontent.com/spacebarchat/spacebarchat/master/branding/png/Spacebar__Icon-Rounded-Subtract.png&quot; /&gt;
&lt;/p&gt;
&lt;h1 align=&quot;center&quot;&gt;Spacebar Server&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://matrix.to/#/#spacebar:rory.gay&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/matrix/spacebar%3Arory.gay?server_fqdn=matrix.rory.gay&amp;fetchMode=summary&amp;logo=matrix&amp;logoColor=fffffff&amp;label=Matrix&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://fermi.chat/invite/NAa7zJ?instance=https%3A%2F%2Fspacebar.chat&quot;&gt;
    &lt;img src=&quot;https://api.old.server.spacebar.chat/api/guilds/1006649183970562092/shield.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/ZrnGQP6p3d&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/806142446094385153?color=7489d5&amp;logo=discord&amp;logoColor=ffffff&amp;label=Discord&quot; /&gt;
  &lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/static/v1?label=Status&amp;message=Development&amp;color=blue&quot;&gt;
  &lt;a title=&quot;Crowdin&quot; target=&quot;_blank&quot; href=&quot;https://translate.spacebar.chat/&quot;&gt;&lt;img src=&quot;https://badges.crowdin.net/fosscord/localized.svg&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://opencollective.com/spacebar&quot;&gt;
    &lt;img src=&quot;https://opencollective.com/spacebar/tiers/badge.svg&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

## [About](https://spacebar.chat)

Spacebar/server is a Discord backend re-implementation and extension.
We aim to reverse engineer and add additional features to the Discord backend, while remaining completely backwards compatible with existing bots, applications, and clients.

This repository contains:

- [API Request/Response Types](/src/schemas)
- [Spacebar HTTP API Server](/src/api)
- [WebSocket Gateway Server](/src/gateway)
- [HTTP CDN Server](/src/cdn)
- [WebRTC Server](/src/webrtc)
- [Utility and Database Models](/src/util)
- [Spacebar Admin API (C#)](/extra/admin-api) (Emma [it/its]@Rory&amp; was here)

## [Documentation](https://docs.spacebar.chat)

And with documentation on how to set up your own server [here](https://docs.spacebar.chat/setup/server), docs to set up either client [here](https://docs.spacebar.chat/setup/clients/), and docs about bots [here](https://docs.spacebar.chat/setup/bots/)

## [Contributing](https://docs.spacebar.chat/contributing/)

## Clients

You _should_ be able to use any client designed for Discord.com to connect to a Spacebar instance.
However, some incompatibilities still exist between Spacebar and Discord. For this reason, not every client will connect.  
We recommend using [Fermi](https://fermi.chat/login?instance=https%3A%2F%2Fspacebar.chat) as a solid starting point on your adventure in the SpaceBar!
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[cinnyapp/cinny]]></title>
            <link>https://github.com/cinnyapp/cinny</link>
            <guid>https://github.com/cinnyapp/cinny</guid>
            <pubDate>Sat, 14 Feb 2026 00:08:07 GMT</pubDate>
            <description><![CDATA[Yet another matrix client]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cinnyapp/cinny">cinnyapp/cinny</a></h1>
            <p>Yet another matrix client</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,963</p>
            <p>Forks: 404</p>
            <p>Stars today: 153 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>