<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Wed, 30 Apr 2025 00:05:17 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[lobehub/lobe-chat]]></title>
            <link>https://github.com/lobehub/lobe-chat</link>
            <guid>https://github.com/lobehub/lobe-chat</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[ü§Ø Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / DeepSeek / Qwen), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Plugins/Artifacts) and Thinking. One-click FREE deployment of your private ChatGPT/ Claude / DeepSeek application.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobe-chat">lobehub/lobe-chat</a></h1>
            <p>ü§Ø Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / DeepSeek / Qwen), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Plugins/Artifacts) and Thinking. One-click FREE deployment of your private ChatGPT/ Claude / DeepSeek application.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 59,843</p>
            <p>Forks: 12,640</p>
            <p>Stars today: 298 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# Lobe Chat

An open-source, modern-design ChatGPT/LLMs UI/Framework.&lt;br/&gt;
Supports speech-synthesis, multi-modal, and extensible ([function call][docs-functionc-call]) plugin system.&lt;br/&gt;
One-click **FREE** deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.

**English** ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md) ¬∑ [Official Site][official-site] ¬∑ [Changelog][changelog] ¬∑ [Documents][docs] ¬∑ [Blog][blog] ¬∑ [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeChat Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Pioneering the new age of thinking and creating. Built for you, the Super Individual.&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url]

![][image-overview]

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [üëãüèª Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [‚ú® Features](#-features)
  - [`1` Chain of Thought](#1-chain-of-thought)
  - [`2` Branching Conversations](#2-branching-conversations)
  - [`3` Artifacts Support](#3-artifacts-support)
  - [`4` File Upload /Knowledge Base](#4-file-upload-knowledge-base)
  - [`5` Multi-Model Service Provider Support](#5-multi-model-service-provider-support)
  - [`6` Local Large Language Model (LLM) Support](#6-local-large-language-model-llm-support)
  - [`7` Model Visual Recognition](#7-model-visual-recognition)
  - [`8` TTS &amp; STT Voice Conversation](#8-tts--stt-voice-conversation)
  - [`9` Text to Image Generation](#9-text-to-image-generation)
  - [`10` Plugin System (Function Calling)](#10-plugin-system-function-calling)
  - [`11` Agent Market (GPTs)](#11-agent-market-gpts)
  - [`12` Support Local / Remote Database](#12-support-local--remote-database)
  - [`13` Support Multi-User Management](#13-support-multi-user-management)
  - [`14` Progressive Web App (PWA)](#14-progressive-web-app-pwa)
  - [`15` Mobile Device Adaptation](#15-mobile-device-adaptation)
  - [`16` Custom Themes](#16-custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [‚ö°Ô∏è Performance](#Ô∏è-performance)
- [üõ≥ Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [üì¶ Ecosystem](#-ecosystem)
- [üß© Plugins](#-plugins)
- [‚å®Ô∏è Local Development](#Ô∏è-local-development)
- [ü§ù Contributing](#-contributing)
- [‚ù§Ô∏è Sponsor](#Ô∏è-sponsor)
- [üîó More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

## üëãüèª Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![][vercel-shield-badge]][vercel-link]   | No installation or registration necessary! Visit our website to experience it firsthand.                           |
| :---------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link] | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub. |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ ‚≠êÔ∏è

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## ‚ú® Features

[![][image-feat-cot]][docs-feat-cot]

### `1` [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### `2` [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### `3` [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeChat. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### `4` [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [üìò LobeChat Knowledge Base Launch ‚Äî From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### `5` [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

- **[OpenAI](https://lobechat.com/discover/provider/openai)**: OpenAI is a global leader in artificial intelligence research, with models like the GPT series pushing the frontiers of natural language processing. OpenAI is committed to transforming multiple industries through innovative and efficient AI solutions. Their products demonstrate significant performance and cost-effectiveness, widely used in research, business, and innovative applications.
- **[Ollama](https://lobechat.com/discover/provider/ollama)**: Ollama provides models that cover a wide range of fields, including code generation, mathematical operations, multilingual processing, and conversational interaction, catering to diverse enterprise-level and localized deployment needs.
- **[Anthropic](https://lobechat.com/discover/provider/anthropic)**: Anthropic is a company focused on AI research and development, offering a range of advanced language models such as Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Opus, and Claude 3 Haiku. These models achieve an ideal balance between intelligence, speed, and cost, suitable for various applications from enterprise workloads to rapid-response scenarios. Claude 3.5 Sonnet, as their latest model, has excelled in multiple evaluations while maintaining a high cost-performance ratio.
- **[Bedrock](https://lobechat.com/discover/provider/bedrock)**: Bedrock is a service provided by Amazon AWS, focusing on delivering advanced AI language and visual models for enterprises. Its model family includes Anthropic&#039;s Claude series, Meta&#039;s Llama 3.1 series, and more, offering a range of options from lightweight to high-performance, supporting tasks such as text generation, conversation, and image processing for businesses of varying scales and needs.
- **[Google](https://lobechat.com/discover/provider/google)**: Google&#039;s Gemini series represents its most advanced, versatile AI models, developed by Google DeepMind, designed for multimodal capabilities, supporting seamless understanding and processing of text, code, images, audio, and video. Suitable for various environments from data centers to mobile devices, it significantly enhances the efficiency and applicability of AI models.
- **[DeepSeek](https://lobechat.com/discover/provider/deepseek)**: DeepSeek is a company focused on AI technology research and application, with its latest model DeepSeek-V2.5 integrating general dialogue and code processing capabilities, achieving significant improvements in human preference alignment, writing tasks, and instruction following.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[HuggingFace](https://lobechat.com/discover/provider/huggingface)**: The HuggingFace Inference API provides a fast and free way for you to explore thousands of models for various tasks. Whether you are prototyping for a new application or experimenting with the capabilities of machine learning, this API gives you instant access to high-performance models across multiple domains.
- **[OpenRouter](https://lobechat.com/discover/provider/openrouter)**: OpenRouter is a service platform providing access to various cutting-edge large model interfaces, supporting OpenAI, Anthropic, LLaMA, and more, suitable for diverse development and application needs. Users can flexibly choose the optimal model and pricing based on their requirements, enhancing the AI experience.
- **[Cloudflare Workers AI](https://lobechat.com/discover/provider/cloudflare)**: Run serverless GPU-powered machine learning models on Cloudflare&#039;s global network.

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+30)&lt;/kbd&gt;&lt;/summary&gt;

- **[GitHub](https://lobechat.com/discover/provider/github)**: With GitHub Models, developers can become AI engineers and leverage the industry&#039;s leading AI models.
- **[Novita](https://lobechat.com/discover/provider/novita)**: Novita AI is a platform providing a variety of large language models and AI image generation API services, flexible, reliable, and cost-effective. It supports the latest open-source models like Llama3 and Mistral, offering a comprehensive, user-friendly, and auto-scaling API solution for generative AI application development, suitable for the rapid growth of AI startups.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[Together AI](https://lobechat.com/discover/provider/togetherai)**: Together AI is dedicated to achieving leading performance through innovative AI models, offering extensive customization capabilities, including rapid scaling support and intuitive deployment processes to meet various enterprise needs.
- **[Fireworks AI](https://lobechat.com/discover/provider/fireworksai)**: Fireworks AI is a leading provider of advanced language model services, focusing on functional calling and multimodal processing. Its latest model, Firefunction V2, is based on Llama-3, optimized for function calling, conversation, and instruction following. The visual language model FireLLaVA-13B supports mixed input of images and text. Other notable models include the Llama series and Mixtral series, providing efficient multilingual instruction following and generation support.
- **[Groq](https://lobechat.com/discover/provider/groq)**: Groq&#039;s LPU inference engine has excelled in the latest independent large language model (LLM) benchmarks, redefining the standards for AI solutions with its remarkable speed and efficiency. Groq represents instant inference speed, demonstrating strong performance in cloud-based deployments.
- **[Perplexity](https://lobechat.com/discover/provider/perplexity)**: Perplexity is a leading provider of conversational generation models, offering various advanced Llama 3.1 models that support both online and offline applications, particularly suited for complex natural language processing tasks.
- **[Mistral](https://lobechat.com/discover/provider/mistral)**: Mistral provides advanced general, specialized, and research models widely used in complex reasoning, multilingual tasks, and code generation. Through functional calling interfaces, users can integrate custom functionalities for specific applications.
- **[Ai21Labs](https://lobechat.com/discover/provider/ai21)**: AI21 Labs builds foundational models and AI systems for enterprises, accelerating the application of generative AI in production.
- **[Upstage](https://lobechat.com/discover/provider/upstage)**: Upstage focuses on developing AI models for various business needs, including Solar LLM and document AI, aiming to achieve artificial general intelligence (AGI) for work. It allows for the creation of simple conversational agents through Chat API and supports functional calling, translation, embedding, and domain-specific applications.
- **[xAI](https://lobechat.com/discover/provider/xai)**: xAI is a company dedicated to building artificial intelligence to accelerate human scientific discovery. Our mission is to advance our collective understanding of the universe.
- **[Qwen](https://lobechat.com/discover/provider/qwen)**: Tongyi Qianwen is a large-scale language model independently developed by Alibaba Cloud, featuring strong natural language understanding and generation capabilities. It can answer various questions, create written content, express opinions, and write code, playing a role in multiple fields.
- **[Wenxin](https://lobechat.com/discover/provider/wenxin)**: An enterprise-level one-stop platform for large model and AI-native application development and services, providing the most comprehensive and user-friendly toolchain for the entire process of generative artificial intelligence model development and application development.
- **[Hunyuan](https://lobechat.com/discover/provider/hunyuan)**: A large language model developed by Tencent, equipped with powerful Chinese creative capabilities, logical reasoning abilities in complex contexts, and reliable task execution skills.
- **[ZhiPu](https://lobechat.com/discover/provider/zhipu)**: Zhipu AI offers an open platform for multimodal and language models, supporting a wide range of AI application scenarios, including text processing, image understanding, and programming assistance.
- **[SiliconCloud](https://lobechat.com/discover/provider/siliconcloud)**: SiliconFlow is dedicated to accelerating AGI for the benefit of humanity, enhancing large-scale AI efficiency through an easy-to-use and cost-effective GenAI stack.
- **[01.AI](https://lobechat.com/discover/provider/zeroone)**: 01.AI focuses on AI 2.0 era technologies, vigorously promoting the innovation and application of &#039;human + artificial intelligence&#039;, using powerful models and advanced AI technologies to enhance human productivity and achieve technological empowerment.
- **[Spark](https://lobechat.com/discover/provider/spark)**: iFlytek&#039;s Spark model provides powerful AI capabilities across multiple domains and languages, utilizing advanced natural language processing technology to build innovative applications suitable for smart hardware, smart healthcare, smart finance, and other vertical scenarios.
- **[SenseNova](https://lobechat.com/discover/provider/sensenova)**: SenseNova, backed by SenseTime&#039;s robust infrastructure, offers efficient and user-friendly full-stack large model services.
- **[Stepfun](https://lobechat.com/discover/provider/stepfun)**: StepFun&#039;s large model possesses industry-leading multimodal and complex reasoning capabilities, supporting ultra-long text understanding and powerful autonomous scheduling search engine functions.
- **[Moonshot](https://lobechat.com/discover/provider/moonshot)**: Moonshot is an open-source platform launched by Beijing Dark Side Technology Co., Ltd., providing various natural language processing models with a wide range of applications, including but not limited to content creation, academic research, intelligent recommendations, and medical diagnosis, supporting long text processing and complex generation tasks.
- **[Baichuan](https://lobechat.com/discover/provider/baichuan)**: Baichuan Intelligence is a company focused on the research and development of large AI models, with its models excelling in domestic knowledge encyclopedias, long text processing, and generative creation tasks in Chinese, surpassing mainstream foreign models. Baichuan Intelligence also possesses industry-leading multimodal capabilities, performing excellently in multiple authoritative evaluations. Its models include Baichuan 4, Baichuan 3 Turbo, and Baichuan 3 Turbo 128k, each optimized for different application scenarios, providing cost-effective solutions.
- **[Minimax](https://lobechat.com/discover/provider/minimax)**: MiniMax is a general artificial intelligence technology company established in 2021, dedicated to co-creating intelligence with users. MiniMax has independently developed general large models of different modalities, including trillion-parameter MoE text models, voice models, and image models, and has launched applications such as Conch AI.
- **[InternLM](https://lobechat.com/di

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[transformerlab/transformerlab-app]]></title>
            <link>https://github.com/transformerlab/transformerlab-app</link>
            <guid>https://github.com/transformerlab/transformerlab-app</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[Open Source Application for Advanced LLM Engineering: interact, train, fine-tune, and evaluate large language models on your own computer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/transformerlab/transformerlab-app">transformerlab/transformerlab-app</a></h1>
            <p>Open Source Application for Advanced LLM Engineering: interact, train, fine-tune, and evaluate large language models on your own computer.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,491</p>
            <p>Forks: 179</p>
            <p>Stars today: 64 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://transformerlab.ai&quot;&gt;&lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/transformerlab/transformerlab-app/refs/heads/main/assets/Transformer-Lab_Logo_Reverse.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/transformerlab/transformerlab-app/refs/heads/main/assets/Transformer-Lab_Logo.svg&quot;&gt;
    &lt;img alt=&quot;transformer lab logo&quot; src=&quot;https://raw.githubusercontent.com/transformerlab/transformerlab-app/refs/heads/main/assets/Transformer-Lab_Logo.svg&quot; style=&quot;max-width: 650px&quot;&gt;
  &lt;/picture&gt;&lt;/a&gt;

  &lt;p align=&quot;center&quot;&gt;
    100% Open Source Toolkit for Large Language Models: Train, Tune, Chat on your own Machine
    &lt;br /&gt;
    &lt;a href=&quot;https://transformerlab.ai/docs/download/&quot;&gt;&lt;strong&gt;Download&lt;/strong&gt;&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://transformerlab.ai/docs/intro&quot;&gt;&lt;strong&gt;Explore the docs ¬ª&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://youtu.be/tY5TAvKviLo&quot;&gt;View Demo&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/transformerlab/transformerlab-app/issues&quot;&gt;Report Bugs&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/transformerlab/transformerlab-app/issues/new&quot;&gt;Suggest Features&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://discord.gg/transformerlab&quot;&gt;Join Discord&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://twitter.com/transformerlab&quot;&gt;Follow on Twitter&lt;/a&gt;
  &lt;/p&gt;
  &lt;p align=&quot;center&quot;&gt;
   Note: Transformer Lab is actively being developed. Please join our Discord or follow us on Twitter for updates. Questions, feedback and contributions are highly valued!&lt;/p&gt;
&lt;/div&gt;

&lt;!-- ABOUT THE PROJECT --&gt;

## Download Now

[![Download Icon]][Download URL]

## About The Project

![Product Screen Shot](assets/transformerlab-demo-jan2025.gif)

Transformer Lab is an app that allows anyone to experiment with Large Language Models.

## Backed by Mozilla

Transformer Lab is proud to be supported by Mozilla through the &lt;a href=&quot;https://future.mozilla.org/builders/&quot;&gt;Mozilla Builders Program&lt;/a&gt;

&lt;a href=&quot;https://future.mozilla.org/builders/&quot;&gt;
    &lt;img src=&quot;https://transformerlab.ai/img/mozilla-builders-2024.png&quot; alt=&quot;Mozilla Builders Logo&quot; width=300&gt;
&lt;/a&gt;

## Features

Transformer Lab allows you to:

- üíï **One-click Download Hundreds of Popular Models**:
  - DeepSeek, Llama3, Qwen, Phi4, Gemma, Mistral, Mixtral, Command-R, and dozens more
- ‚¨á **Download any LLM from Huggingface**
- üé∂ **Finetune / Train Across Different Hardware**
  - Finetune using MLX on Apple Silicon
  - Finetune using Huggingface on GPU
- ‚öñÔ∏è **RLHF and Preference Optimization**
  - DPO
  - ORPO
  - SIMPO
  - Reward Modeling
- üíª **Work with LLMs Across Operating Systems**:
  - Windows App
  - MacOS App
  - Linux
- üí¨ **Chat with Models**
  - Chat
  - Completions
  - Preset (Templated) Prompts
  - Chat History
  - Tweak generation parameters
  - Batched Inference
  - Tool Use / Function Calling (in alpha)
- üöÇ **Use Different Inference Engines**
  - MLX on Apple Silicon
  - Huggingface Transformers
  - vLLM
  - Llama CPP
- üßë‚Äçüéì **Evaluate models**
- üìñ **RAG (Retreival Augmented Generation)**
  - Drag and Drop File UI
  - Works on Apple MLX, Transformers, and other engines
- üìì **Build Datasets for Training**
  - Pull from hundreds of common datasets available on HuggingFace
  - Provide your own dataset using drag and drop
- üî¢ **Calculate Embeddings**
- üíÅ **Full REST API**
- üå© **Run in the Cloud**
  - You can run the user interface on your desktop/laptop while the engine runs on a remote or cloud machine
  - Or you can run everything locally on a single machine
- üîÄ **Convert Models Across Platforms**
  - Convert from/to Huggingface, MLX, GGUF
- üîå **Plugin Support**
  - Easily pull from a library of existing plugins
  - Write your own plugins to extend functionality
- üßë‚Äçüíª **Embedded Monaco Code Editor**
  - Edit plugins and view what&#039;s happening behind the scenes
- üìù **Prompt Editing**
  - Easily edit System Messages or Prompt Templates
- üìú **Inference Logs**
  - While doing inference or RAG, view a log of the raw queries sent to the LLM

And you can do the above, all through a simple cross-platform GUI.

&lt;!-- GETTING STARTED --&gt;

## Getting Started

&lt;a href=&quot;https://transformerlab.ai/docs/download&quot;&gt;Click here&lt;/a&gt; to download Transformer Lab.

&lt;a href=&quot;https://transformerlab.ai/docs/intro&quot;&gt;Read this page&lt;/a&gt; to learn how to install and use.

### Built With

- [![Electron][Electron]][Electron-url]
- [![React][React.js]][React-url]
- [![HuggingFace][HuggingFace]][HuggingFace-url]

## Developers

### Building from Scratch

To build the app yourself, pull this repo, and follow the steps below:

(Please note that the current build doesn&#039;t work on Node v23 but it works on v22)

```bash
npm install
```

```bash
npm start
```

## Packaging for Production

To package apps for the local platform:

```bash
npm run package
```

&lt;!-- LICENSE --&gt;

## License

Distributed under the AGPL V3 License. See `LICENSE.txt` for more information.

## Reference

If you found Transformer Lab useful in your research or applications, please cite using the following BibTeX:

```
@software{transformerlab,
  author = {Asaria, Ali},
  title = {Transformer Lab: Experiment with Large Language Models},
  month = December,
  year = 2023,
  url = {https://github.com/transformerlab/transformerlab-app}
}
```

&lt;!-- CONTACT --&gt;

## Contact

- [@aliasaria](https://twitter.com/aliasaria) - Ali Asasria
- [@dadmobile](https://github.com/dadmobile) - Tony Salomone

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;

[product-screenshot]: https://transformerlab.ai/assets/images/screenshot01-53ecb8c52338db3c9246cf2ebbbdc40d.png
[React.js]: https://img.shields.io/badge/React-20232A?style=for-the-badge&amp;logo=react&amp;logoColor=61DAFB
[React-url]: https://reactjs.org/
[Electron]: https://img.shields.io/badge/Electron-20232A?style=for-the-badge&amp;logo=electron&amp;logoColor=61DAFB
[Electron-url]: https://www.electronjs.org/
[HuggingFace]: https://img.shields.io/badge/ü§ó_HuggingFace-20232A?style=for-the-badge
[HuggingFace-url]: https://huggingface.co/
[Download Icon]: https://img.shields.io/badge/Download-EF2D5E?style=for-the-badge&amp;logoColor=white&amp;logo=DocuSign
[Download URL]: https://transformerlab.ai/docs/download
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[daytonaio/daytona]]></title>
            <link>https://github.com/daytonaio/daytona</link>
            <guid>https://github.com/daytonaio/daytona</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Daytona is a Secure and Elastic Infrastructure for Running AI-Generated Code]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/daytonaio/daytona">daytonaio/daytona</a></h1>
            <p>Daytona is a Secure and Elastic Infrastructure for Running AI-Generated Code</p>
            <p>Language: TypeScript</p>
            <p>Stars: 16,636</p>
            <p>Forks: 1,623</p>
            <p>Stars today: 741 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

[![Documentation](https://img.shields.io/github/v/release/daytonaio/docs?label=Docs&amp;color=23cc71)](https://www.daytona.io/docs)
![License](https://img.shields.io/badge/License-AGPL--3-blue)
[![Go Report Card](https://goreportcard.com/badge/github.com/daytonaio/daytona)](https://goreportcard.com/report/github.com/daytonaio/daytona)
[![Issues - daytona](https://img.shields.io/github/issues/daytonaio/daytona)](https://github.com/daytonaio/daytona/issues)
![GitHub Release](https://img.shields.io/github/v/release/daytonaio/daytona)

&lt;/div&gt;

&amp;nbsp;

&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-white.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-black.png&quot;&gt;
    &lt;img alt=&quot;Daytona logo&quot; src=&quot;https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-black.png&quot; width=&quot;50%&quot;&gt;
  &lt;/picture&gt;
&lt;/div&gt;

&lt;h3 align=&quot;center&quot;&gt;
  Run AI Code.
  &lt;br/&gt;
  Secure and Elastic Infrastructure for
  Running Your AI-Generated Code.
&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.daytona.io/docs&quot;&gt; Documentation &lt;/a&gt;¬∑
    &lt;a href=&quot;https://github.com/daytonaio/daytona/issues/new?assignees=&amp;labels=bug&amp;projects=&amp;template=bug_report.md&amp;title=%F0%9F%90%9B+Bug+Report%3A+&quot;&gt; Report Bug &lt;/a&gt;¬∑
    &lt;a href=&quot;https://github.com/daytonaio/daytona/issues/new?assignees=&amp;labels=enhancement&amp;projects=&amp;template=feature_request.md&amp;title=%F0%9F%9A%80+Feature%3A+&quot;&gt; Request Feature &lt;/a&gt;¬∑
    &lt;a href=&quot;https://go.daytona.io/slack&quot;&gt; Join our Slack &lt;/a&gt;¬∑
    &lt;a href=&quot;https://x.com/daytonaio&quot;&gt; Connect on X &lt;/a&gt;
&lt;/p&gt;

---

## Installation

### Python SDK

```bash
pip install daytona-sdk
```

### TypeScript SDK

```bash
npm install @daytonaio/sdk
```

---

## Features

- **Lightning-Fast Infrastructure**: Sub-90ms Sandbox creation from code to execution.
- **Separated &amp; Isolated Runtime**: Execute AI-generated code with zero risk to your infrastructure.
- **Massive Parallelization for Concurrent AI Workflows**: Fork Sandbox filesystem and memory state (Coming soon!)
- **Programmatic Control**: File, Git, LSP, and Execute API
- **Unlimited Persistence**: Your Sandboxes can live forever
- **OCI/Docker Compatibility**: Use any OCI/Docker image to create a Sandbox

---

## Quick Start

1. Create an account at https://app.daytona.io
1. Generate a [new API key](https://app.daytona.io/dashboard/keys)
1. Follow the [Getting Started docs](https://www.daytona.io/docs/getting-started/) to start using the Daytona SDK

## Creating your first Sandbox

### Python SDK

```py
from daytona_sdk import Daytona, DaytonaConfig, CreateSandboxParams

# Initialize the Daytona client
daytona = Daytona(DaytonaConfig(api_key=&quot;YOUR_API_KEY&quot;))

# Create the Sandbox instance
sandbox = daytona.create(CreateSandboxParams(language=&quot;python&quot;))

# Run code securely inside the Sandbox
response = sandbox.process.code_run(&#039;print(&quot;Sum of 3 and 4 is &quot; + str(3 + 4))&#039;)
if response.exit_code != 0:
    print(f&quot;Error running code: {response.exit_code} {response.result}&quot;)
else:
    print(response.result)

# Clean up the Sandbox
daytona.remove(sandbox)
```

### Typescript SDK

```jsx
import { Daytona } from &#039;@daytonaio/sdk&#039;

async function main() {
  // Initialize the Daytona client
  const daytona = new Daytona({
    apiKey: &#039;YOUR_API_KEY&#039;,
  })

  let sandbox
  try {
    // Create the Sandbox instance
    sandbox = await daytona.create({
      language: &#039;python&#039;,
    })
    // Run code securely inside the Sandbox
    const response = await sandbox.process.codeRun(&#039;print(&quot;Sum of 3 and 4 is &quot; + str(3 + 4))&#039;)
    if (response.exitCode !== 0) {
      console.error(&#039;Error running code:&#039;, response.exitCode, response.result)
    } else {
      console.log(response.result)
    }
  } catch (error) {
    console.error(&#039;Sandbox flow error:&#039;, error)
  } finally {
    if (sandbox) await daytona.remove(sandbox)
  }
}

main().catch(console.error)
```

---

## Contributing

Daytona is Open Source under the [GNU GENERAL PUBLIC LICENSE](LICENSE), and is the [copyright of its contributors](NOTICE). If you would like to contribute to the software, read the Developer Certificate of Origin Version 1.1 (https://developercertificate.org/). Afterwards, navigate to the [contributing guide](CONTRIBUTING.md) to get started.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[langgenius/dify]]></title>
            <link>https://github.com/langgenius/dify</link>
            <guid>https://github.com/langgenius/dify</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langgenius/dify">langgenius/dify</a></h1>
            <p>Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 95,111</p>
            <p>Forks: 14,207</p>
            <p>Stars today: 327 stars today</p>
            <h2>README</h2><pre>![cover-v5-optimized](https://github.com/langgenius/dify/assets/13230914/f9e19af5-61ba-4119-b926-d10c4c06ebab)

&lt;p align=&quot;center&quot;&gt;
  üìå &lt;a href=&quot;https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast&quot;&gt;Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cloud.dify.ai&quot;&gt;Dify Cloud&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted&quot;&gt;Self-hosting&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://docs.dify.ai&quot;&gt;Documentation&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://dify.ai/pricing&quot;&gt;Dify edition overview&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://dify.ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Product-F04438&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://dify.ai/pricing&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/free-pricing?logo=free&amp;color=%20%23155EEF&amp;label=pricing&amp;labelColor=%20%23528bff&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/FngNHpbcY7&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1082486657678311454?logo=discord&amp;labelColor=%20%235462eb&amp;logoColor=%20%23f5f5f5&amp;color=%20%235462eb&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://reddit.com/r/difyai&quot; target=&quot;_blank&quot;&gt;  
        &lt;img src=&quot;https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&amp;logo=reddit&amp;label=r%2Fdifyai&amp;labelColor=white&quot;
            alt=&quot;join Reddit&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=dify_ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/dify_ai?logo=X&amp;color=%20%23f5f5f5&quot;
            alt=&quot;follow on X(Twitter)&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/langgenius/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;logoColor=fff&quot;
            alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/u/langgenius&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&amp;color=%20%23f79009&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/graphs/commit-activity&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Commits last month&quot; src=&quot;https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&amp;color=%20%2312b76a&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Issues closed&quot; src=&quot;https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&amp;label=issues%20closed&amp;labelColor=%20%237d89b0&amp;color=%20%235d6b98&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/discussions/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Discussion posts&quot; src=&quot;https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&amp;color=%20%237a5af8&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_TW.md&quot;&gt;&lt;img alt=&quot;ÁπÅÈ´î‰∏≠ÊñáÊñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁπÅÈ´î‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_CN.md&quot;&gt;&lt;img alt=&quot;ÁÆÄ‰Ωì‰∏≠ÊñáÁâàËá™Ëø∞Êñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_JA.md&quot;&gt;&lt;img alt=&quot;Êó•Êú¨Ë™û„ÅÆREADME&quot; src=&quot;https://img.shields.io/badge/Êó•Êú¨Ë™û-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_ES.md&quot;&gt;&lt;img alt=&quot;README en Espa√±ol&quot; src=&quot;https://img.shields.io/badge/Espa√±ol-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_FR.md&quot;&gt;&lt;img alt=&quot;README en Fran√ßais&quot; src=&quot;https://img.shields.io/badge/Fran√ßais-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_KL.md&quot;&gt;&lt;img alt=&quot;README tlhIngan Hol&quot; src=&quot;https://img.shields.io/badge/Klingon-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_KR.md&quot;&gt;&lt;img alt=&quot;README in Korean&quot; src=&quot;https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_AR.md&quot;&gt;&lt;img alt=&quot;README ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&quot; src=&quot;https://img.shields.io/badge/ÿßŸÑÿπÿ±ÿ®Ÿäÿ©-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_TR.md&quot;&gt;&lt;img alt=&quot;T√ºrk√ße README&quot; src=&quot;https://img.shields.io/badge/T√ºrk√ße-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_VI.md&quot;&gt;&lt;img alt=&quot;README Ti·∫øng Vi·ªát&quot; src=&quot;https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_DE.md&quot;&gt;&lt;img alt=&quot;README in Deutsch&quot; src=&quot;https://img.shields.io/badge/German-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_BN.md&quot;&gt;&lt;img alt=&quot;README in ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&quot; src=&quot;https://img.shields.io/badge/‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ-d9d9d9&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Dify is an open-source LLM app development platform. Its intuitive interface combines agentic AI workflow, RAG pipeline, agent capabilities, model management, observability features, and more, allowing you to quickly move from prototype to production.

## Quick start

&gt; Before installing Dify, make sure your machine meets the following minimum system requirements:
&gt;
&gt; - CPU &gt;= 2 Core
&gt; - RAM &gt;= 4 GiB

&lt;/br&gt;

The easiest way to start the Dify server is through [docker compose](docker/docker-compose.yaml). Before running Dify with the following commands, make sure that [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) are installed on your machine:

```bash
cd dify
cd docker
cp .env.example .env
docker compose up -d
```

After running, you can access the Dify dashboard in your browser at [http://localhost/install](http://localhost/install) and start the initialization process.

#### Seeking help

Please refer to our [FAQ](https://docs.dify.ai/getting-started/install-self-hosted/faqs) if you encounter problems setting up Dify. Reach out to [the community and us](#community--contact) if you are still having issues.

&gt; If you&#039;d like to contribute to Dify or do additional development, refer to our [guide to deploying from source code](https://docs.dify.ai/getting-started/install-self-hosted/local-source-code)

## Key features

**1. Workflow**:
Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.

https://github.com/langgenius/dify/assets/13230914/356df23e-1604-483d-80a6-9517ece318aa

**2. Comprehensive model support**:
Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found [here](https://docs.dify.ai/getting-started/readme/model-providers).

![providers-v5](https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3)

**3. Prompt IDE**:
Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.

**4. RAG Pipeline**:
Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.

**5. Agent capabilities**:
You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALL¬∑E, Stable Diffusion and WolframAlpha.

**6. LLMOps**:
Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.

**7. Backend-as-a-Service**:
All of Dify&#039;s offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.

## Feature Comparison

&lt;table style=&quot;width: 100%;&quot;&gt;
  &lt;tr&gt;
    &lt;th align=&quot;center&quot;&gt;Feature&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;Dify.AI&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;LangChain&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;Flowise&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;OpenAI Assistants API&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Programming Approach&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;API + App-oriented&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Python Code&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;App-oriented&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;API-oriented&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Supported LLMs&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;OpenAI-only&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;RAG Engine&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Agent&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Workflow&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Observability&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Enterprise Feature (SSO/Access control)&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Local Deployment&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚úÖ&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;‚ùå&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Using Dify

- **Cloud &lt;/br&gt;**
  We host a [Dify Cloud](https://dify.ai) service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.

- **Self-hosting Dify Community Edition&lt;/br&gt;**
  Quickly get Dify running in your environment with this [starter guide](#quick-start).
  Use our [documentation](https://docs.dify.ai) for further references and more in-depth instructions.

- **Dify for enterprise / organizations&lt;/br&gt;**
  We provide additional enterprise-centric features. [Log your questions for us through this chatbot](https://udify.app/chat/22L1zSxg6yW1cWQg) or [send us an email](mailto:business@dify.ai?subject=[GitHub]Business%20License%20Inquiry) to discuss enterprise needs. &lt;/br&gt;
  &gt; For startups and small businesses using AWS, check out [Dify Premium on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6) and deploy it to your own AWS VPC with one click. It&#039;s an affordable AMI offering with the option to create apps with custom logo and branding.

## Staying ahead

Star Dify on GitHub and be instantly notified of new releases.

![star-us](https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4)

## Advanced Setup

If you need to customize the configuration, please refer to the comments in our [.env.example](docker/.env.example) file and update the corresponding values in your `.env` file. Additionally, you might need to make adjustments to the `docker-compose.yaml` file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run `docker-compose up -d`. You can find the full list of available environment variables [here](https://docs.dify.ai/getting-started/install-self-hosted/environments).

If you&#039;d like to configure a highly-available setup, there are community-contributed [Helm Charts](https://helm.sh/) and YAML files which allow Dify to be deployed on Kubernetes.

- [Helm Chart by @LeoQuote](https://github.com/douban/charts/tree/master/charts/dify)
- [Helm Chart by @BorisPolonsky](https://github.com/BorisPolonsky/dify-helm)
- [Helm Chart by @magicsong](https://github.com/magicsong/ai-charts)
- [YAML file by @Winson-030](https://github.com/Winson-030/dify-kubernetes)
- [YAML file by @wyy-holding](https://github.com/wyy-holding/dify-k8s)

#### Using Terraform for Deployment

Deploy Dify to Cloud Platform with a single click using [terraform](https://www.terraform.io/)

##### Azure Global

- [Azure Terraform by @nikawang](https://github.com/nikawang/dify-azure-terraform)

##### Google Cloud

- [Google Cloud Terraform by @sotazum](https://github.com/DeNA/dify-google-cloud-terraform)

#### Using AWS CDK for Deployment

Deploy Dify to AWS with [CDK](https://aws.amazon.com/cdk/)

##### AWS

- [AWS CDK by @KevinZhao](https://github.com/aws-samples/solution-for-deploying-dify-on-aws)

## Contributing

For those who&#039;d like to contribute code, see our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.

&gt; We are looking for contributors to help translate Dify into languages other than Mandarin or English. If you are interested in helping, please see the [i18n README](https://github.com/langgenius/dify/blob/main/web/i18n/README.md) for more information, and leave us a comment in the `global-users` channel of our [Discord Community Server](https://discord.gg/8Tpq4AcN9c).

## Community &amp; contact

- [Github Discussion](https://github.com/langgenius/dify/discussions). Best for: sharing feedback and asking questions.
- [GitHub Issues](https://github.com/langgenius/dify/issues). Best for: bugs you encounter using Dify.AI, and feature proposals. See our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
- [Discord](https://discord.gg/FngNHpbcY7). Best for: sharing your applications and hanging out with the community.
- [X(Twitter)](https://twitter.com/dify_ai). Best for: sharing your applications and hanging out with the community.

**Contributors**

&lt;a href=&quot;https://github.com/langgenius/dify/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=langgenius/dify&quot; /&gt;
&lt;/a&gt;

## Star history

[![Star History Chart](https://api.star-history.com/svg?repos=langgenius/dify&amp;type=Date)](https://star-history.com/#langgenius/dify&amp;Date)

## Security disclosure

To protect your privacy, please avoid posting security issues on GitHub. Instead, send your questions to security@dify.ai and we will provide you with a more detailed answer.

## License

This repository is available under the [Dify Open Source License](LICENSE), which is essentially Apache 2.0 with a few additional restrictions.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[refined-github/refined-github]]></title>
            <link>https://github.com/refined-github/refined-github</link>
            <guid>https://github.com/refined-github/refined-github</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[Browser extension that simplifies the GitHub interface and adds useful features]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/refined-github/refined-github">refined-github/refined-github</a></h1>
            <p>Browser extension that simplifies the GitHub interface and adds useful features</p>
            <p>Language: TypeScript</p>
            <p>Stars: 27,413</p>
            <p>Forks: 1,559</p>
            <p>Stars today: 175 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[mountain-loop/yaak]]></title>
            <link>https://github.com/mountain-loop/yaak</link>
            <guid>https://github.com/mountain-loop/yaak</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[The most intuitive desktop API client. Organize and execute REST, GraphQL, WebSockets, Server Sent Events, and gRPC ü¶¨]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mountain-loop/yaak">mountain-loop/yaak</a></h1>
            <p>The most intuitive desktop API client. Organize and execute REST, GraphQL, WebSockets, Server Sent Events, and gRPC ü¶¨</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,174</p>
            <p>Forks: 194</p>
            <p>Stars today: 46 stars today</p>
            <h2>README</h2><pre># Yaak API Client

Yaak is a desktop API client for interacting with REST, GraphQL, Server Sent Events (SSE), WebSocket, and gRPC
APIs. It&#039;s built using [Tauri](https://tauri.app), Rust, and ReactJS.

![screenshot](https://github.com/user-attachments/assets/f18e963f-0b68-4ecb-b8b8-cb71aa9aec02)

## Feature Overview

- ü™Ç Import data from Postman, Insomnia, OpenAPI, Swagger, or Curl.&lt;br/&gt;
- üì§ Send requests via REST, GraphQL, Server Sent Events (SSE), WebSockets, or gRPC.&lt;br/&gt;
- üîê Automatically authorize requests with OAuth 2.0, JWT tokens, Basic Auth, and more.&lt;br/&gt;
- üîé Filter response bodies using JSONPath or XPath queries.&lt;br/&gt;
- ‚õìÔ∏è Chain together multiple requests to dynamically reference values.&lt;br/&gt;
- üìÇ Organize requests into workspaces and nested folders.&lt;br/&gt;
- üßÆ Use environment variables to easily switch between Prod and Dev.&lt;br/&gt;
- üè∑Ô∏è Send dynamic values like UUIDs or timestamps using template tags.&lt;br/&gt;
- üé® Choose from many of the included themes, or make your own.&lt;br/&gt;
- üíΩ Mirror workspace data to a directory for integration with Git or Dropbox.&lt;br/&gt;
- üìú View response history for each request.&lt;br/&gt;
- üîå Create your own plugins for authentication, template tags, and more!&lt;br/&gt;
- üõú Configure a proxy to access firewall-blocked APIs

## Feedback and Bug Reports

All feedback, bug reports, questions, and feature requests should be reported to
[feedback.yaak.app](https://feedback.yaak.app).

## Community Projects

- [`yaak2postman`](https://github.com/BiteCraft/yaak2postman) CLI for converting Yaak data
  exports to Postman-compatible collections

## Contribution Policy

Yaak is open source, but only accepting contributions for bug fixes. To get started, 
visit [`DEVELOPMENT.md`](DEVELOPMENT.md) for tips on setting up your environment.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[immich-app/immich]]></title>
            <link>https://github.com/immich-app/immich</link>
            <guid>https://github.com/immich-app/immich</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[High performance self-hosted photo and video management solution.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/immich-app/immich">immich-app/immich</a></h1>
            <p>High performance self-hosted photo and video management solution.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 64,775</p>
            <p>Forks: 3,405</p>
            <p>Stars today: 103 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt; 
  &lt;br/&gt;
  &lt;a href=&quot;https://opensource.org/license/agpl-v3&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-AGPL_v3-blue.svg?color=3F51B5&amp;style=for-the-badge&amp;label=License&amp;logoColor=000000&amp;labelColor=ececec&quot; alt=&quot;License: AGPLv3&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.immich.app&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/979116623879368755.svg?label=Discord&amp;logo=Discord&amp;style=for-the-badge&amp;logoColor=000000&amp;labelColor=ececec&quot; alt=&quot;Discord&quot;/&gt;
  &lt;/a&gt;
  &lt;br/&gt;
  &lt;br/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;design/immich-logo-stacked-light.svg&quot; width=&quot;300&quot; title=&quot;Login With Custom URL&quot;&gt;
&lt;/p&gt;
&lt;h3 align=&quot;center&quot;&gt;High performance self-hosted photo and video management solution&lt;/h3&gt;
&lt;br/&gt;
&lt;a href=&quot;https://immich.app&quot;&gt;
&lt;img src=&quot;design/immich-screenshots.png&quot; title=&quot;Main Screenshot&quot;&gt;
&lt;/a&gt;
&lt;br/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;readme_i18n/README_ca_ES.md&quot;&gt;Catal√†&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_es_ES.md&quot;&gt;Espa√±ol&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_fr_FR.md&quot;&gt;Fran√ßais&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_it_IT.md&quot;&gt;Italiano&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ja_JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ko_KR.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_de_DE.md&quot;&gt;Deutsch&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_nl_NL.md&quot;&gt;Nederlands&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_tr_TR.md&quot;&gt;T√ºrk√ße&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_zh_CN.md&quot;&gt;‰∏≠Êñá&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_uk_UA.md&quot;&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ru_RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_pt_BR.md&quot;&gt;Portugu√™s Brasileiro&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_sv_SE.md&quot;&gt;Svenska&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_ar_JO.md&quot;&gt;ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_vi_VN.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;
  &lt;a href=&quot;readme_i18n/README_th_TH.md&quot;&gt;‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢&lt;/a&gt;
&lt;/p&gt;

## Disclaimer

- ‚ö†Ô∏è The project is under **very active** development.
- ‚ö†Ô∏è Expect bugs and breaking changes.
- ‚ö†Ô∏è **Do not use the app as the only way to store your photos and videos.**
- ‚ö†Ô∏è Always follow [3-2-1](https://www.backblaze.com/blog/the-3-2-1-backup-strategy/) backup plan for your precious photos and videos!

&gt; [!NOTE]
&gt; You can find the main documentation, including installation guides, at https://immich.app/.

## Links

- [Documentation](https://immich.app/docs)
- [About](https://immich.app/docs/overview/introduction)
- [Installation](https://immich.app/docs/install/requirements)
- [Roadmap](https://immich.app/roadmap)
- [Demo](#demo)
- [Features](#features)
- [Translations](https://immich.app/docs/developer/translations)
- [Contributing](https://immich.app/docs/overview/support-the-project)

## Demo

Access the demo [here](https://demo.immich.app). For the mobile app, you can use `https://demo.immich.app` for the `Server Endpoint URL`.

### Login credentials

| Email           | Password |
| --------------- | -------- |
| demo@immich.app | demo     |

## Features

| Features                                     | Mobile | Web |
| :------------------------------------------- | ------ | --- |
| Upload and view videos and photos            | Yes    | Yes |
| Auto backup when the app is opened           | Yes    | N/A |
| Prevent duplication of assets                | Yes    | Yes |
| Selective album(s) for backup                | Yes    | N/A |
| Download photos and videos to local device   | Yes    | Yes |
| Multi-user support                           | Yes    | Yes |
| Album and Shared albums                      | Yes    | Yes |
| Scrubbable/draggable scrollbar               | Yes    | Yes |
| Support raw formats                          | Yes    | Yes |
| Metadata view (EXIF, map)                    | Yes    | Yes |
| Search by metadata, objects, faces, and CLIP | Yes    | Yes |
| Administrative functions (user management)   | No     | Yes |
| Background backup                            | Yes    | N/A |
| Virtual scroll                               | Yes    | Yes |
| OAuth support                                | Yes    | Yes |
| API Keys                                     | N/A    | Yes |
| LivePhoto/MotionPhoto backup and playback    | Yes    | Yes |
| Support 360 degree image display             | No     | Yes |
| User-defined storage structure               | Yes    | Yes |
| Public Sharing                               | Yes    | Yes |
| Archive and Favorites                        | Yes    | Yes |
| Global Map                                   | Yes    | Yes |
| Partner Sharing                              | Yes    | Yes |
| Facial recognition and clustering            | Yes    | Yes |
| Memories (x years ago)                       | Yes    | Yes |
| Offline support                              | Yes    | No  |
| Read-only gallery                            | Yes    | Yes |
| Stacked Photos                               | Yes    | Yes |
| Tags                                         | No     | Yes |
| Folder View                                  | Yes    | Yes |

## Translations

Read more about translations [here](https://immich.app/docs/developer/translations).

&lt;a href=&quot;https://hosted.weblate.org/engage/immich/&quot;&gt;
&lt;img src=&quot;https://hosted.weblate.org/widget/immich/immich/multi-auto.svg&quot; alt=&quot;Translation status&quot; /&gt;
&lt;/a&gt;

## Repository activity

![Activities](https://repobeats.axiom.co/api/embed/9e86d9dc3ddd137161f2f6d2e758d7863b1789cb.svg &quot;Repobeats analytics image&quot;)

## Star history

&lt;a href=&quot;https://star-history.com/#immich-app/immich&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=immich-app/immich&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=immich-app/immich&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=immich-app/immich&amp;type=Date&quot; width=&quot;100%&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## Contributors

&lt;a href=&quot;https://github.com/alextran1502/immich/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=immich-app/immich&quot; width=&quot;100%&quot;/&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[dubinc/dub]]></title>
            <link>https://github.com/dubinc/dub</link>
            <guid>https://github.com/dubinc/dub</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[The modern link attribution platform. Loved by modern marketing teams like Twilio, Buffer, Framer, Perplexity, Vercel, and more.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dubinc/dub">dubinc/dub</a></h1>
            <p>The modern link attribution platform. Loved by modern marketing teams like Twilio, Buffer, Framer, Perplexity, Vercel, and more.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,274</p>
            <p>Forks: 2,399</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://dub.co&quot;&gt;
  &lt;img alt=&quot;Dub is the modern, open-source link attribution platform for short links, conversion tracking, and affiliate programs.&quot; src=&quot;https://github.com/dubinc/dub/assets/28986134/3815d859-afaa-48f9-a9b3-c09964e4d404&quot;&gt;
&lt;/a&gt;

&lt;h3 align=&quot;center&quot;&gt;Dub&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
    The open-source link attribution platform.
    &lt;br /&gt;
    &lt;a href=&quot;https://dub.co&quot;&gt;&lt;strong&gt;Learn more ¬ª&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;#introduction&quot;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/a&gt; ¬∑
    &lt;a href=&quot;#features&quot;&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/a&gt; ¬∑
    &lt;a href=&quot;#tech-stack&quot;&gt;&lt;strong&gt;Tech Stack&lt;/strong&gt;&lt;/a&gt; ¬∑
    &lt;a href=&quot;#self-hosting&quot;&gt;&lt;strong&gt;Self-hosting&lt;/strong&gt;&lt;/a&gt; ¬∑
    &lt;a href=&quot;#contributing&quot;&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://twitter.com/dubdotco&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/twitter/follow/dubdotco?style=flat&amp;label=%40dubdotco&amp;logo=twitter&amp;color=0bf&amp;logoColor=fff&quot; alt=&quot;Twitter&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://news.ycombinator.com/item?id=32939407&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Hacker%20News-255-%23FF6600&quot; alt=&quot;Hacker News&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/dubinc/dub/blob/main/LICENSE.md&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/dubinc/dub?label=license&amp;logo=github&amp;color=f80&amp;logoColor=fff&quot; alt=&quot;License&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;br/&gt;

## Introduction

Dub is the open-source link attribution platform for modern marketing teams.

## Features

- **Free custom domains**: Create branded short links [with your own domain](https://dub.co/help/article/how-to-add-custom-domain) and [improve click-through rates by 30%](https://dub.co/blog/custom-domains). Paid plans also include a [complimentary custom domain](https://dub.co/help/article/free-dot-link-domain).
- **Advanced link features**: Supercharge your links with [custom link previews](https://dub.co/help/article/custom-link-previews), [device targeting](https://dub.co/help/article/device-targeting), [geo targeting](https://dub.co/help/article/geo-targeting), [link cloaking](https://dub.co/help/article/link-cloaking), [password protection](https://dub.co/help/article/password-protected-links), and more.
- **Advanced Analytics**: Dub provides [powerful analytics](https://dub.co/analytics) for your links, including geolocation, device, browser, and referrer information.
- **QR Codes**: QR codes and short links are like peas in a pod. Dub offers [free QR codes](https://dub.co/tools/qr-code) for every short link you create. Feeling artsy? [Customize them with your own logo](https://dub.co/help/article/custom-qr-codes).
- **Team collaboration**: [Invite your teammates](https://dub.co/help/article/how-to-invite-teammates) to collaborate on your links. For [enterprises](https://dub.co/enterprise), Dub offers [SAML SSO](https://dub.co/help/category/saml-sso) with Okta, Google, and Azure AD for higher security.

## Tech Stack

- [Next.js](https://nextjs.org/) ‚Äì framework
- [TypeScript](https://www.typescriptlang.org/) ‚Äì¬†language
- [Tailwind](https://tailwindcss.com/) ‚Äì¬†CSS
- [Upstash](https://upstash.com/) ‚Äì¬†redis
- [Tinybird](https://tinybird.com/) ‚Äì¬†analytics
- [PlanetScale](https://planetscale.com/) ‚Äì¬†database
- [NextAuth.js](https://next-auth.js.org/) ‚Äì auth
- [BoxyHQ](https://boxyhq.com/enterprise-sso) ‚Äì SSO/SAML
- [Turborepo](https://turbo.build/repo) ‚Äì monorepo
- [Stripe](https://stripe.com/) ‚Äì¬†payments
- [Resend](https://resend.com/) ‚Äì emails
- [Vercel](https://vercel.com/) ‚Äì deployments
- [Pangea](https://pangea.cloud/services/domain-intel/reputation) - link scanning

## Self-Hosting

You can self-host Dub for greater control over your data and design. [Read this guide](https://dub.co/docs/self-hosting/guide) to learn more.

## Contributing

We love our contributors! Here&#039;s how you can contribute:

- [Open an issue](https://github.com/dubinc/dub/issues) if you believe you&#039;ve encountered a bug.
- Follow the [local development guide](https://dub.co/docs/local-development) to get your local dev environment set up.
- Make a [pull request](https://github.com/dubinc/dub/pull) to add new features/make quality-of-life improvements/fix bugs.

&lt;a href=&quot;https://github.com/dubinc/dub/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=dubinc/dub&quot; /&gt;
&lt;/a&gt;

## Repo Activity

![Dub repo activity ‚Äì¬†generated by Axiom](https://repobeats.axiom.co/api/embed/6ac4c94a89ea20e2e10032b932a128b6d8442e66.svg &quot;Repobeats analytics image&quot;)

## License

Inspired by [Plausible](https://plausible.io/), Dub is open-source under the GNU Affero General Public License Version 3 (AGPLv3) or any later version. You can [find it here](https://github.com/dubinc/dub/blob/main/LICENSE.md).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[jetkvm/kvm]]></title>
            <link>https://github.com/jetkvm/kvm</link>
            <guid>https://github.com/jetkvm/kvm</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[JetKVM - Control any computer remotely]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jetkvm/kvm">jetkvm/kvm</a></h1>
            <p>JetKVM - Control any computer remotely</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,369</p>
            <p>Forks: 130</p>
            <p>Stars today: 75 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;img alt=&quot;JetKVM logo&quot; src=&quot;https://jetkvm.com/logo-blue.png&quot; height=&quot;28&quot;&gt;

### KVM

[Discord](https://jetkvm.com/discord) | [Website](https://jetkvm.com) | [Issues](https://github.com/jetkvm/cloud-api/issues) | [Docs](https://jetkvm.com/docs)

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/jetkvm.svg?style=social&amp;label=Follow%20%40JetKVM)](https://twitter.com/jetkvm)

&lt;/div&gt;

JetKVM is a high-performance, open-source KVM over IP (Keyboard, Video, Mouse) solution designed for efficient remote management of computers, servers, and workstations. Whether you&#039;re dealing with boot failures, installing a new operating system, adjusting BIOS settings, or simply taking control of a machine from afar, JetKVM provides the tools to get it done effectively.

## Features

- **Ultra-low Latency** - 1080p@60FPS video with 30-60ms latency using H.264 encoding. Smooth mouse and keyboard interaction for responsive remote control.
- **Free &amp; Optional Remote Access** - Remote management via JetKVM Cloud using WebRTC.
- **Open-source software** - Written in Golang on Linux. Easily customizable through SSH access to the JetKVM device.

## Contributing

We welcome contributions from the community! Whether it&#039;s improving the firmware, adding new features, or enhancing documentation, your input is valuable. We also have some rules and taboos here, so please read this page and our [Code of Conduct](/CODE_OF_CONDUCT.md) carefully.

## I need help

The best place to search for answers is our [Documentation](https://jetkvm.com/docs). If you can&#039;t find the answer there, check our [Discord Server](https://jetkvm.com/discord).

## I want to report an issue

If you&#039;ve found an issue and want to report it, please check our [Issues](https://github.com/jetkvm/kvm/issues) page. Make sure the description contains information about the firmware version you&#039;re using, your platform, and a clear explanation of the steps to reproduce the issue.

# Development

JetKVM is written in Go &amp; TypeScript. with some bits and pieces written in C. An intermediate level of Go &amp; TypeScript knowledge is recommended for comfortable programming.

The project contains two main parts, the backend software that runs on the KVM device and the frontend software that is served by the KVM device, and also the cloud.

For most of local device development, all you need is to use the `./dev_deploy.sh` script. It will build the frontend and backend and deploy them to the local KVM device. Run `./dev_deploy.sh --help` for more information.

## Backend

The backend is written in Go and is responsible for the KVM device management, the cloud API and the cloud web.

## Frontend

The frontend is written in React and TypeScript and is served by the KVM device. It has three build targets: `device`, `development` and `production`. Development is used for development of the cloud version on your local machine, device is used for building the frontend for the KVM device and production is used for building the frontend for the cloud.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[xyflow/xyflow]]></title>
            <link>https://github.com/xyflow/xyflow</link>
            <guid>https://github.com/xyflow/xyflow</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[React Flow |¬†Svelte Flow - Powerful open source libraries for building node-based UIs with React (https://reactflow.dev) or Svelte (https://svelteflow.dev). Ready out-of-the-box and infinitely customizable.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xyflow/xyflow">xyflow/xyflow</a></h1>
            <p>React Flow |¬†Svelte Flow - Powerful open source libraries for building node-based UIs with React (https://reactflow.dev) or Svelte (https://svelteflow.dev). Ready out-of-the-box and infinitely customizable.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 29,178</p>
            <p>Forks: 1,900</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre>![xyflow-header](https://user-images.githubusercontent.com/2857535/279643999-ffda9f91-6b6d-447d-82be-fcbd6103edb6.svg#gh-light-mode-only)
![xyflow-header-dark](https://user-images.githubusercontent.com/2857535/279644026-a01c231c-6c6e-4b41-96e0-a85c75c9acee.svg#gh-dark-mode-only)

&lt;div align=&quot;center&quot;&gt;

![GitHub License MIT](https://img.shields.io/github/license/wbkd/react-flow?color=%23ff0072)
![npm downloads](https://img.shields.io/npm/dt/reactflow?color=%23FF0072&amp;label=React%20Flow%20downloads)
![npm downloads](https://img.shields.io/npm/dt/@xyflow/svelte?color=%23FF3E00&amp;label=Svelte%20Flow%20downloads)

Powerful open source libraries for building node-based UIs with React or Svelte. Ready out-of-the-box and infinitely customizable.

[React Flow](https://reactflow.dev/) ¬∑ [Svelte Flow](https://svelteflow.dev/) ¬∑ [React Flow Pro](https://reactflow.dev/pro) ¬∑ [Discord](https://discord.gg/Bqt6xrs)
&lt;/div&gt;

---

## The xyflow mono repo

The xyflow repository is the home of four packages:
* React Flow 12 `@xyflow/react` [packages/react](./packages/react)
* React Flow 11 `reactflow` [v11 branch](https://github.com/xyflow/xyflow/tree/v11)
* Svelte Flow `@xyflow/svelte` [packages/svelte](./packages/svelte)
* Shared helper library `@xyflow/system` [packages/system](./packages/system)

## Commercial usage

**Are you using React Flow or Svelte Flow for a personal project?** Great! No sponsorship needed, you can support us by reporting any bugs you find, sending us screenshots of your projects, and starring us on Github üåü

**Are you using React Flow or Svelte Flow at your organization and making money from it?** Awesome! We rely on your support to keep our libraries developed and maintained under an MIT License, just how we like it. For React Flow you can do that on the [React Flow Pro website](https://reactflow.dev/pro) and for both of our libraries you can do it through [Github Sponsors](https://github.com/sponsors/xyflow).

## Getting started

The best way to get started is to check out the [React Flow](https://reactflow.dev/learn) or [Svelte Flow](https://svelteflow.dev/learn) learn section. However if you want to get a sneak peek of how to install and use the libraries you can see it here: 

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;React Flow&lt;/strong&gt; basic usage&lt;/summary&gt;

  ### Installation
  
  ```sh
npm install @xyflow/react
  ```

  ### Basic usage
  ```jsx
import { useCallback } from &#039;react&#039;;
import {
  ReactFlow,
  MiniMap,
  Controls,
  Background,
  useNodesState,
  useEdgesState,
  addEdge,
} from &#039;@xyflow/react&#039;;

import &#039;@xyflow/react/dist/style.css&#039;;

const initialNodes = [
  { id: &#039;1&#039;, position: { x: 0, y: 0 }, data: { label: &#039;1&#039; } },
  { id: &#039;2&#039;, position: { x: 0, y: 100 }, data: { label: &#039;2&#039; } },
];

const initialEdges = [{ id: &#039;e1-2&#039;, source: &#039;1&#039;, target: &#039;2&#039; }];

function Flow() {
  const [nodes, setNodes, onNodesChange] = useNodesState(initialNodes);
  const [edges, setEdges, onEdgesChange] = useEdgesState(initialEdges);

  const onConnect = useCallback((params) =&gt; setEdges((eds) =&gt; addEdge(params, eds)), [setEdges]);

  return (
    &lt;ReactFlow
      nodes={nodes}
      edges={edges}
      onNodesChange={onNodesChange}
      onEdgesChange={onEdgesChange}
      onConnect={onConnect}
    &gt;
      &lt;MiniMap /&gt;
      &lt;Controls /&gt;
      &lt;Background /&gt;
    &lt;/ReactFlow&gt;
  );
}

export default Flow;
```
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Svelte Flow&lt;/strong&gt; basic usage&lt;/summary&gt;

  ### Installation
  
  ```sh
npm install @xyflow/svelte
  ```

  ### Basic usage
  ```svelte
&lt;script lang=&quot;ts&quot;&gt;
  import { writable } from &#039;svelte/store&#039;;
  import {
    SvelteFlow,
    Controls,
    Background,
    BackgroundVariant,
    MiniMap,
  } from &#039;@xyflow/svelte&#039;;

  import &#039;@xyflow/svelte/dist/style.css&#039;
  
  const nodes = writable([
    {
      id: &#039;1&#039;,
      type: &#039;input&#039;,
      data: { label: &#039;Input Node&#039; },
      position: { x: 0, y: 0 }
    },
    {
      id: &#039;2&#039;,
      type: &#039;custom&#039;,
      data: { label: &#039;Node&#039; },
      position: { x: 0, y: 150 }
    }
  ]);

  const edges = writable([
    {
      id: &#039;1-2&#039;,
      type: &#039;default&#039;,
      source: &#039;1&#039;,
      target: &#039;2&#039;,
      label: &#039;Edge Text&#039;
    }
  ]);
&lt;/script&gt;

&lt;SvelteFlow
  {nodes}
  {edges}
  fitView
  on:nodeclick={(event) =&gt; console.log(&#039;on node click&#039;, event)}
&gt;
  &lt;Controls /&gt;
  &lt;Background variant={BackgroundVariant.Dots} /&gt;
  &lt;MiniMap /&gt;
&lt;/SvelteFlow&gt;
```
&lt;/details&gt;

## Releases 

For releasing packages we are using [changesets](https://github.com/changesets/changesets) in combination with the [changeset Github action](https://github.com/changesets/action). The rough idea is:

1. create PRs for new features, updates and fixes (with a changeset if relevant for changelog)
2. merge into main 
3. changset creates a PR that bumps all packages based on the changesets 
4. merge changeset PR if you want to release to Github and npm

## The xyflow team

React Flow and Svelte Flow are maintained by the team behind [xyflow](https://xyflow.com). If you need help or want to talk to us about a collaboration, reach out through our¬†[contact form](https://xyflow.com/contact)¬†or by joining our [Discord Server](https://discord.gg/Bqt6xrs).

- Christopher ‚Ä¢¬†[Twitter](https://twitter.com/chrtze)¬†‚Ä¢¬†[Github](https://github.com/chrtze)
- Hayleigh ‚Ä¢¬†[Twitter](https://twitter.com/hayleighdotdev)¬†‚Ä¢¬†[Github](https://github.com/hayleigh-dot-dev)
- Abbey ‚Ä¢¬†[Github](https://github.com/printerscanner)
- Moritz ‚Ä¢¬†[Twitter](https://twitter.com/moklick)¬†‚Ä¢¬†[Github](https://github.com/moklick)
- Peter ‚Ä¢¬†[Github](https://github.com/peterkogo)


## License

React Flow and Svelte Flow are [MIT licensed](./LICENSE).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[jestjs/jest]]></title>
            <link>https://github.com/jestjs/jest</link>
            <guid>https://github.com/jestjs/jest</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[Delightful JavaScript Testing.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jestjs/jest">jestjs/jest</a></h1>
            <p>Delightful JavaScript Testing.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 44,726</p>
            <p>Forks: 6,534</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/jest&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/jest&quot; alt=&quot;npm version&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/jestjs/jest/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-MIT-blue.svg&quot; alt=&quot;Jest is released under the MIT license.&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=jestjs_&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/jestjs_.svg?style=social&amp;label=Follow%20@jestjs_&quot; alt=&quot;Follow on Twitter&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/jestjs/jest/actions/workflows/nodejs.yml&quot;&gt;&lt;img alt=&quot;GitHub CI Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/jestjs/jest/nodejs.yml?label=CI&amp;logo=GitHub&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/github/jestjs/jest&quot;&gt;&lt;img alt=&quot;Coverage Status&quot; src=&quot;https://img.shields.io/codecov/c/github/jestjs/jest/main.svg?maxAge=43200&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://gitpod.io/#https://github.com/jestjs/jest&quot;&gt;&lt;img alt=&quot;Gitpod ready-to-code&quot; src=&quot;https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;!-- A spacer --&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;website/static/img/jest-readme-headline.png&quot; width=&quot;80%&quot;/&gt;&lt;/p&gt;

&lt;h2 align=&quot;center&quot;&gt;üÉè Delightful JavaScript Testing&lt;/h2&gt;

**üë©üèª‚Äçüíª Developer Ready**: A comprehensive JavaScript testing solution. Works out of the box for most JavaScript projects.

**üèÉüèΩ Instant Feedback**: Fast, interactive watch mode only runs test files related to changed files.

**üì∏ Snapshot Testing**: Capture snapshots of large objects to simplify testing and to analyze how they change over time.

&lt;p align=&quot;right&quot;&gt;&lt;em&gt;See more on &lt;a href=&quot;https://jestjs.io&quot;&gt;jestjs.io&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

## Table of Contents

- [Getting Started](#getting-started)
- [Running from command line](#running-from-command-line)
- [Additional Configuration](#additional-configuration)
  - [Generate a basic configuration file](#generate-a-basic-configuration-file)
  - [Using Babel](#using-babel)
  - [Using webpack](#using-webpack)
  - [Using Vite](#using-vite)
  - [Using Parcel](#using-parcel)
  - [Using Typescript](#using-typescript)
- [Documentation](#documentation)
- [Badge](#badge)
- [Contributing](#contributing)
  - [Code of Conduct](#code-of-conduct)
  - [Contributing Guide](#contributing-guide)
  - [Good First Issues](#good-first-issues)
- [Credits](#credits)
  - [Backers](#backers)
  - [Sponsors](#sponsors)
- [License](#license)
- [Copyright](#copyright)

## Getting Started

&lt;!-- copied from Getting Started docs, links updated to point to Jest website --&gt;

Install Jest using [`yarn`](https://yarnpkg.com/en/package/jest):

```bash
yarn add --dev jest
```

Or [`npm`](https://www.npmjs.com/package/jest):

```bash
npm install --save-dev jest
```

Note: Jest documentation uses `yarn` commands, but `npm` will also work. You can compare `yarn` and `npm` commands in the [yarn docs, here](https://yarnpkg.com/en/docs/migrating-from-npm#toc-cli-commands-comparison).

Let&#039;s get started by writing a test for a hypothetical function that adds two numbers. First, create a `sum.js` file:

```javascript
function sum(a, b) {
  return a + b;
}
module.exports = sum;
```

Then, create a file named `sum.test.js`. This will contain our actual test:

```javascript
const sum = require(&#039;./sum&#039;);

test(&#039;adds 1 + 2 to equal 3&#039;, () =&gt; {
  expect(sum(1, 2)).toBe(3);
});
```

Add the following section to your `package.json`:

```json
{
  &quot;scripts&quot;: {
    &quot;test&quot;: &quot;jest&quot;
  }
}
```

Finally, run `yarn test` or `npm test` and Jest will print this message:

```bash
PASS  ./sum.test.js
‚úì adds 1 + 2 to equal 3 (5ms)
```

**You just successfully wrote your first test using Jest!**

This test used `expect` and `toBe` to test that two values were exactly identical. To learn about the other things that Jest can test, see [Using Matchers](https://jestjs.io/docs/using-matchers).

## Running from command line

You can run Jest directly from the CLI (if it&#039;s globally available in your `PATH`, e.g. by `yarn global add jest` or `npm install jest --global`) with a variety of useful options.

Here&#039;s how to run Jest on files matching `my-test`, using `config.json` as a configuration file and display a native OS notification after the run:

```bash
jest my-test --notify --config=config.json
```

If you&#039;d like to learn more about running `jest` through the command line, take a look at the [Jest CLI Options](https://jestjs.io/docs/cli) page.

## Additional Configuration

### Generate a basic configuration file

Based on your project, Jest will ask you a few questions and will create a basic configuration file with a short description for each option:

```bash
yarn create jest
```

### Using Babel

To use [Babel](https://babeljs.io/), install required dependencies via `yarn`:

```bash
yarn add --dev babel-jest @babel/core @babel/preset-env
```

Configure Babel to target your current version of Node by creating a `babel.config.js` file in the root of your project:

```javascript
// babel.config.js
module.exports = {
  presets: [[&#039;@babel/preset-env&#039;, {targets: {node: &#039;current&#039;}}]],
};
```

The ideal configuration for Babel will depend on your project. See [Babel&#039;s docs](https://babeljs.io/docs/en/) for more details.

&lt;details&gt;
  &lt;summary markdown=&quot;span&quot;&gt;&lt;strong&gt;Making your Babel config jest-aware&lt;/strong&gt;&lt;/summary&gt;

Jest will set `process.env.NODE_ENV` to `&#039;test&#039;` if it&#039;s not set to something else. You can use that in your configuration to conditionally setup only the compilation needed for Jest, e.g.

```javascript
// babel.config.js
module.exports = api =&gt; {
  const isTest = api.env(&#039;test&#039;);
  // You can use isTest to determine what presets and plugins to use.

  return {
    // ...
  };
};
```

&gt; Note: `babel-jest` is automatically installed when installing Jest and will automatically transform files if a babel configuration exists in your project. To avoid this behavior, you can explicitly reset the `transform` configuration option:

```javascript
// jest.config.js
module.exports = {
  transform: {},
};
```

&lt;/details&gt;

&lt;!-- Note that the Babel 6 section in the Getting Started was removed --&gt;

### Using webpack

Jest can be used in projects that use [webpack](https://webpack.js.org/) to manage assets, styles, and compilation. webpack does offer some unique challenges over other tools. Refer to the [webpack guide](https://jestjs.io/docs/webpack) to get started.

### Using Vite

Jest can be used in projects that use [vite](https://vitejs.dev/) to serves source code over native ESM to provide some frontend tooling, vite is an opinionated tool and does offer some out-of-the box workflows. Jest is not fully supported by vite due to how the [plugin system](https://github.com/vitejs/vite/issues/1955#issuecomment-776009094) from vite works, but there is some working examples for first-class jest integration using the `vite-jest`, since this is not fully supported, you might as well read the [limitation of the `vite-jest`](https://github.com/sodatea/vite-jest/tree/main/packages/vite-jest#limitations-and-differences-with-commonjs-tests). Refer to the [vite guide](https://vitejs.dev/guide/) to get started.

### Using Parcel

Jest can be used in projects that use [parcel-bundler](https://parceljs.org/) to manage assets, styles, and compilation similar to webpack. Parcel requires zero configuration. Refer to the official [docs](https://parceljs.org/docs/) to get started.

### Using TypeScript

Jest supports TypeScript, via Babel. First, make sure you followed the instructions on [using Babel](#using-babel) above. Next, install the `@babel/preset-typescript` via `yarn`:

```bash
yarn add --dev @babel/preset-typescript
```

Then add `@babel/preset-typescript` to the list of presets in your `babel.config.js`.

```diff
// babel.config.js
module.exports = {
  presets: [
    [&#039;@babel/preset-env&#039;, {targets: {node: &#039;current&#039;}}],
+    &#039;@babel/preset-typescript&#039;,
  ],
};
```

However, there are some [caveats](https://babeljs.io/docs/en/babel-plugin-transform-typescript#caveats) to using TypeScript with Babel. Because TypeScript support in Babel is purely transpilation, Jest will not type-check your tests as they are run. If you want that, you can use [ts-jest](https://github.com/kulshekhar/ts-jest) instead, or just run the TypeScript compiler [tsc](https://www.typescriptlang.org/docs/handbook/compiler-options.html) separately (or as part of your build process).

&lt;!-- end copied --&gt;

## Documentation

Learn more about using [Jest on the official site!](https://jestjs.io)

- [Getting Started](https://jestjs.io/docs/getting-started)
- [Guides](https://jestjs.io/docs/snapshot-testing)
- [API Reference](https://jestjs.io/docs/api)
- [Configuring Jest](https://jestjs.io/docs/configuration)

## Badge

Show the world you&#039;re using _Jest_ `‚Üí` [![tested with jest](https://img.shields.io/badge/tested_with-jest-99424f.svg)](https://github.com/jestjs/jest) [![jest tested](https://img.shields.io/badge/Jest-tested-eee.svg?logo=jest&amp;labelColor=99424f)](https://github.com/jestjs/jest) [![jest](https://jestjs.io/img/jest-badge.svg)](https://github.com/jestjs/jest)

&lt;!-- prettier-ignore --&gt;
```md
[![tested with jest](https://img.shields.io/badge/tested_with-jest-99424f.svg?logo=jest)](https://github.com/jestjs/jest)
[![jest tested](https://img.shields.io/badge/Jest-tested-eee.svg?logo=jest&amp;labelColor=99424f)](https://github.com/jestjs/jest)
[![jest](https://jestjs.io/img/jest-badge.svg)](https://github.com/jestjs/jest)
```

## Contributing

Development of Jest happens in the open on GitHub, and we are grateful to the community for contributing bugfixes and improvements. Read below to learn how you can take part in improving Jest.

### [Code of Conduct](https://code.facebook.com/codeofconduct)

Facebook has adopted a Code of Conduct that we expect project participants to adhere to. Please read [the full text](https://code.facebook.com/codeofconduct) so that you can understand what actions will and will not be tolerated.

### [Contributing Guide](CONTRIBUTING.md)

Read our [contributing guide](CONTRIBUTING.md) to learn about our development process, how to propose bugfixes and improvements, and how to build and test your changes to Jest.

### [Good First Issues](https://github.com/jestjs/jest/labels/good%20first%20issue)

To help you get your feet wet and get you familiar with our contribution process, we have a list of [good first issues](https://github.com/jestjs/jest/labels/good%20first%20issue) that contain bugs which have a relatively limited scope. This is a great place to get started.

## Credits

This project exists thanks to all the people who [contribute](CONTRIBUTING.md).

&lt;a href=&quot;https://github.com/jestjs/jest/graphs/contributors&quot;&gt;&lt;img src=&quot;https://opencollective.com/jest/contributors.svg?width=890&amp;button=false&quot; /&gt;&lt;/a&gt;

### [Backers](https://opencollective.com/jest#backer)

Thank you to all our backers! üôè

&lt;a href=&quot;https://opencollective.com/jest#backers&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/jest/backers.svg?width=890&quot;&gt;&lt;/a&gt;

### [Sponsors](https://opencollective.com/jest#sponsor)

Support this project by becoming a sponsor. Your logo will show up here with a link to your website.

&lt;a href=&quot;https://opencollective.com/jest/sponsor/0/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/jest/sponsor/0/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/jest/sponsor/1/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/jest/sponsor/1/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/jest/sponsor/2/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/jest/sponsor/2/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/jest/sponsor/3/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/jest/sponsor/3/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/jest/sponsor/4/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/jest/sponsor/4/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/jest/sponsor/5/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/jest/sponsor/5/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/jest/sponsor/6/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/jest/sponsor/6/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/jest/sponsor/7/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/jest/sponsor/7/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/jest/sponsor/8/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/jest/sponsor/8/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/jest/sponsor/9/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/jest/sponsor/9/avatar.svg&quot;&gt;&lt;/a&gt;

## License

Jest is [MIT licensed](./LICENSE).

## Copyright

Copyright Contributors to the Jest project.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[renovatebot/renovate]]></title>
            <link>https://github.com/renovatebot/renovate</link>
            <guid>https://github.com/renovatebot/renovate</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[Home of the Renovate CLI: Cross-platform Dependency Automation by Mend.io]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/renovatebot/renovate">renovatebot/renovate</a></h1>
            <p>Home of the Renovate CLI: Cross-platform Dependency Automation by Mend.io</p>
            <p>Language: TypeScript</p>
            <p>Stars: 18,851</p>
            <p>Forks: 2,536</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[infiniflow/ragflow]]></title>
            <link>https://github.com/infiniflow/ragflow</link>
            <guid>https://github.com/infiniflow/ragflow</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/infiniflow/ragflow">infiniflow/ragflow</a></h1>
            <p>RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 50,824</p>
            <p>Forks: 4,816</p>
            <p>Stars today: 126 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://demo.ragflow.io/&quot;&gt;
&lt;img src=&quot;web/src/assets/logo-with-text.png&quot; width=&quot;520&quot; alt=&quot;ragflow logo&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;English&lt;/a&gt; |
  &lt;a href=&quot;./README_zh.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; |
  &lt;a href=&quot;./README_tzh.md&quot;&gt;ÁπÅ‰Ωì‰∏≠Êñá&lt;/a&gt; |
  &lt;a href=&quot;./README_ja.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; |
  &lt;a href=&quot;./README_ko.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; |
  &lt;a href=&quot;./README_id.md&quot;&gt;Bahasa Indonesia&lt;/a&gt; |
  &lt;a href=&quot;/README_pt_br.md&quot;&gt;Portugu√™s (Brasil)&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://x.com/intent/follow?screen_name=infiniflowai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/infiniflow?logo=X&amp;color=%20%23f5f5f5&quot; alt=&quot;follow on X(Twitter)&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://demo.ragflow.io&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Online-Demo-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/r/infiniflow/ragflow&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/docker_pull-ragflow:v0.18.0-brightgreen&quot; alt=&quot;docker pull infiniflow/ragflow:v0.18.0&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/releases/latest&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/github/v/release/infiniflow/ragflow?color=blue&amp;label=Latest%20Release&quot; alt=&quot;Latest Release&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/blob/main/LICENSE&quot;&gt;
        &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/License-Apache--2.0-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;license&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://ragflow.io/docs/dev/&quot;&gt;Document&lt;/a&gt; |
  &lt;a href=&quot;https://github.com/infiniflow/ragflow/issues/4214&quot;&gt;Roadmap&lt;/a&gt; |
  &lt;a href=&quot;https://twitter.com/infiniflowai&quot;&gt;Twitter&lt;/a&gt; |
  &lt;a href=&quot;https://discord.gg/NjYzJD3GM3&quot;&gt;Discord&lt;/a&gt; |
  &lt;a href=&quot;https://demo.ragflow.io&quot;&gt;Demo&lt;/a&gt;
&lt;/h4&gt;

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;üìï Table of Contents&lt;/b&gt;&lt;/summary&gt;

- üí° [What is RAGFlow?](#-what-is-ragflow)
- üéÆ [Demo](#-demo)
- üìå [Latest Updates](#-latest-updates)
- üåü [Key Features](#-key-features)
- üîé [System Architecture](#-system-architecture)
- üé¨ [Get Started](#-get-started)
- üîß [Configurations](#-configurations)
- üîß [Build a docker image without embedding models](#-build-a-docker-image-without-embedding-models)
- üîß [Build a docker image including embedding models](#-build-a-docker-image-including-embedding-models)
- üî® [Launch service from source for development](#-launch-service-from-source-for-development)
- üìö [Documentation](#-documentation)
- üìú [Roadmap](#-roadmap)
- üèÑ [Community](#-community)
- üôå [Contributing](#-contributing)

&lt;/details&gt;

## üí° What is RAGFlow?

[RAGFlow](https://ragflow.io/) is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document
understanding. It offers a streamlined RAG workflow for businesses of any scale, combining LLM (Large Language Models)
to provide truthful question-answering capabilities, backed by well-founded citations from various complex formatted
data.

## üéÆ Demo

Try our demo at [https://demo.ragflow.io](https://demo.ragflow.io).

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/infiniflow/ragflow/assets/7248/2f6baa3e-1092-4f11-866d-36f6a9d075e5&quot; width=&quot;1200&quot;/&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/504bbbf1-c9f7-4d83-8cc5-e9cb63c26db6&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## üî• Latest Updates

- 2025-03-19 Supports using a multi-modal model to make sense of images within PDF or DOCX files.
- 2025-02-28 Combined with Internet search (Tavily), supports reasoning like Deep Research for any LLMs.
- 2025-01-26 Optimizes knowledge graph extraction and application, offering various configuration options.
- 2024-12-18 Upgrades Document Layout Analysis model in DeepDoc.
- 2024-11-01 Adds keyword extraction and related question generation to the parsed chunks to improve the accuracy of retrieval.
- 2024-08-22 Support text to SQL statements through RAG.

## üéâ Stay Tuned

‚≠êÔ∏è Star our repository to stay up-to-date with exciting new features and improvements! Get instant notifications for new
releases! üåü

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/18c9707e-b8aa-4caf-a154-037089c105ba&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## üåü Key Features

### üç≠ **&quot;Quality in, quality out&quot;**

- [Deep document understanding](./deepdoc/README.md)-based knowledge extraction from unstructured data with complicated
  formats.
- Finds &quot;needle in a data haystack&quot; of literally unlimited tokens.

### üç± **Template-based chunking**

- Intelligent and explainable.
- Plenty of template options to choose from.

### üå± **Grounded citations with reduced hallucinations**

- Visualization of text chunking to allow human intervention.
- Quick view of the key references and traceable citations to support grounded answers.

### üçî **Compatibility with heterogeneous data sources**

- Supports Word, slides, excel, txt, images, scanned copies, structured data, web pages, and more.

### üõÄ **Automated and effortless RAG workflow**

- Streamlined RAG orchestration catered to both personal and large businesses.
- Configurable LLMs as well as embedding models.
- Multiple recall paired with fused re-ranking.
- Intuitive APIs for seamless integration with business.

## üîé System Architecture

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/infiniflow/ragflow/assets/12318111/d6ac5664-c237-4200-a7c2-a4a00691b485&quot; width=&quot;1000&quot;/&gt;
&lt;/div&gt;

## üé¨ Get Started

### üìù Prerequisites

- CPU &gt;= 4 cores
- RAM &gt;= 16 GB
- Disk &gt;= 50 GB
- Docker &gt;= 24.0.0 &amp; Docker Compose &gt;= v2.26.1
  &gt; If you have not installed Docker on your local machine (Windows, Mac, or Linux),
  &gt; see [Install Docker Engine](https://docs.docker.com/engine/install/).

### üöÄ Start up the server

1. Ensure `vm.max_map_count` &gt;= 262144:

   &gt; To check the value of `vm.max_map_count`:
   &gt;
   &gt; ```bash
   &gt; $ sysctl vm.max_map_count
   &gt; ```
   &gt;
   &gt; Reset `vm.max_map_count` to a value at least 262144 if it is not.
   &gt;
   &gt; ```bash
   &gt; # In this case, we set it to 262144:
   &gt; $ sudo sysctl -w vm.max_map_count=262144
   &gt; ```
   &gt;
   &gt; This change will be reset after a system reboot. To ensure your change remains permanent, add or update the
   &gt; `vm.max_map_count` value in **/etc/sysctl.conf** accordingly:
   &gt;
   &gt; ```bash
   &gt; vm.max_map_count=262144
   &gt; ```

2. Clone the repo:

   ```bash
   $ git clone https://github.com/infiniflow/ragflow.git
   ```

3. Start up the server using the pre-built Docker images:

&gt; [!CAUTION]
&gt; All Docker images are built for x86 platforms. We don&#039;t currently offer Docker images for ARM64.
&gt; If you are on an ARM64 platform, follow [this guide](https://ragflow.io/docs/dev/build_docker_image) to build a Docker image compatible with your system.

   &gt; The command below downloads the `v0.18.0-slim` edition of the RAGFlow Docker image. See the following table for descriptions of different RAGFlow editions. To download a RAGFlow edition different from `v0.18.0-slim`, update the `RAGFLOW_IMAGE` variable accordingly in **docker/.env** before using `docker compose` to start the server. For example: set `RAGFLOW_IMAGE=infiniflow/ragflow:v0.18.0` for the full edition `v0.18.0`.

   ```bash
   $ cd ragflow/docker
   # Use CPU for embedding and DeepDoc tasks:
   $ docker compose -f docker-compose.yml up -d

   # To use GPU to accelerate embedding and DeepDoc tasks:
   # docker compose -f docker-compose-gpu.yml up -d
   ```

   | RAGFlow image tag | Image size (GB) | Has embedding models? | Stable?                  |
   |-------------------|-----------------|-----------------------|--------------------------|
   | v0.18.0           | &amp;approx;9       | :heavy_check_mark:    | Stable release           |
   | v0.18.0-slim      | &amp;approx;2       | ‚ùå                   | Stable release            |
   | nightly           | &amp;approx;9       | :heavy_check_mark:    | _Unstable_ nightly build |
   | nightly-slim      | &amp;approx;2       | ‚ùå                   | _Unstable_ nightly build  |

4. Check the server status after having the server up and running:

   ```bash
   $ docker logs -f ragflow-server
   ```

   _The following output confirms a successful launch of the system:_

   ```bash

         ____   ___    ______ ______ __
        / __ \ /   |  / ____// ____// /____  _      __
       / /_/ // /| | / / __ / /_   / // __ \| | /| / /
      / _, _// ___ |/ /_/ // __/  / // /_/ /| |/ |/ /
     /_/ |_|/_/  |_|\____//_/    /_/ \____/ |__/|__/

    * Running on all addresses (0.0.0.0)
   ```

   &gt; If you skip this confirmation step and directly log in to RAGFlow, your browser may prompt a `network anormal`
   &gt; error because, at that moment, your RAGFlow may not be fully initialized.

5. In your web browser, enter the IP address of your server and log in to RAGFlow.
   &gt; With the default settings, you only need to enter `http://IP_OF_YOUR_MACHINE` (**sans** port number) as the default
   &gt; HTTP serving port `80` can be omitted when using the default configurations.
6. In [service_conf.yaml.template](./docker/service_conf.yaml.template), select the desired LLM factory in `user_default_llm` and update
   the `API_KEY` field with the corresponding API key.

   &gt; See [llm_api_key_setup](https://ragflow.io/docs/dev/llm_api_key_setup) for more information.

   _The show is on!_

## üîß Configurations

When it comes to system configurations, you will need to manage the following files:

- [.env](./docker/.env): Keeps the fundamental setups for the system, such as `SVR_HTTP_PORT`, `MYSQL_PASSWORD`, and
  `MINIO_PASSWORD`.
- [service_conf.yaml.template](./docker/service_conf.yaml.template): Configures the back-end services. The environment variables in this file will be automatically populated when the Docker container starts. Any environment variables set within the Docker container will be available for use, allowing you to customize service behavior based on the deployment environment.
- [docker-compose.yml](./docker/docker-compose.yml): The system relies on [docker-compose.yml](./docker/docker-compose.yml) to start up.

&gt; The [./docker/README](./docker/README.md) file provides a detailed description of the environment settings and service
&gt; configurations which can be used as `${ENV_VARS}` in the [service_conf.yaml.template](./docker/service_conf.yaml.template) file.

To update the default HTTP serving port (80), go to [docker-compose.yml](./docker/docker-compose.yml) and change `80:80`
to `&lt;YOUR_SERVING_PORT&gt;:80`.

Updates to the above configurations require a reboot of all containers to take effect:

&gt; ```bash
&gt; $ docker compose -f docker-compose.yml up -d
&gt; ```

### Switch doc engine from Elasticsearch to Infinity

RAGFlow uses Elasticsearch by default for storing full text and vectors. To switch to [Infinity](https://github.com/infiniflow/infinity/), follow these steps:

1. Stop all running containers:

   ```bash
   $ docker compose -f docker/docker-compose.yml down -v
   ```

&gt; [!WARNING]
&gt; `-v` will delete the docker container volumes, and the existing data will be cleared.

2. Set `DOC_ENGINE` in **docker/.env** to `infinity`.

3. Start the containers:

   ```bash
   $ docker compose -f docker-compose.yml up -d
   ```

&gt; [!WARNING]
&gt; Switching to Infinity on a Linux/arm64 machine is not yet officially supported.

## üîß Build a Docker image without embedding models

This image is approximately 2 GB in size and relies on external LLM and embedding services.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 --build-arg LIGHTEN=1 -f Dockerfile -t infiniflow/ragflow:nightly-slim .
```

## üîß Build a Docker image including embedding models

This image is approximately 9 GB in size. As it includes embedding models, it relies on external LLM services only.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 -f Dockerfile -t infiniflow/ragflow:nightly .
```

## üî® Launch service from source for development

1. Install uv, or skip this step if it is already installed:

   ```bash
   pipx install uv pre-commit
   ```

2. Clone the source code and install Python dependencies:

   ```bash
   git clone https://github.com/infiniflow/ragflow.git
   cd ragflow/
   uv sync --python 3.10 --all-extras # install RAGFlow dependent python modules
   pre-commit install
   ```

3. Launch the dependent services (MinIO, Elasticsearch, Redis, and MySQL) using Docker Compose:

   ```bash
   docker compose -f docker/docker-compose-base.yml up -d
   ```

   Add the following line to `/etc/hosts` to resolve all hosts specified in **docker/.env** to `127.0.0.1`:

   ```
   127.0.0.1       es01 infinity mysql minio redis
   ```

4. If you cannot access HuggingFace, set the `HF_ENDPOINT` environment variable to use a mirror site:

   ```bash
   export HF_ENDPOINT=https://hf-mirror.com
   ```

5. Launch backend service:

   ```bash
   source .venv/bin/activate
   export PYTHONPATH=$(pwd)
   bash docker/launch_backend_service.sh
   ```

6. Install frontend dependencies:
   ```bash
   cd web
   npm install
   ```
7. Launch frontend service:

   ```bash
   npm run dev
   ```

   _The following output confirms a successful launch of the system:_

   ![](https://github.com/user-attachments/assets/0daf462c-a24d-4496-a66f-92533534e187)

## üìö Documentation

- [Quickstart](https://ragflow.io/docs/dev/)
- [Configuration](https://ragflow.io/docs/dev/configurations)
- [Release notes](https://ragflow.io/docs/dev/release_notes)
- [User guides](https://ragflow.io/docs/dev/category/guides)
- [Developer guides](https://ragflow.io/docs/dev/category/developers)
- [References](https://ragflow.io/docs/dev/category/references)
- [FAQs](https://ragflow.io/docs/dev/faq)

## üìú Roadmap

See the [RAGFlow Roadmap 2025](https://github.com/infiniflow/ragflow/issues/4214)

## üèÑ Community

- [Discord](https://discord.gg/NjYzJD3GM3)
- [Twitter](https://twitter.com/infiniflowai)
- [GitHub Discussions](https://github.com/orgs/infiniflow/discussions)

## üôå Contributing

RAGFlow flourishes via open-source collaboration. In this spirit, we embrace diverse contributions from the community.
If you would like to be a part, review our [Contribution Guidelines](./CONTRIBUTING.md) first.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[element-plus/element-plus]]></title>
            <link>https://github.com/element-plus/element-plus</link>
            <guid>https://github.com/element-plus/element-plus</guid>
            <pubDate>Wed, 30 Apr 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[üéâ A Vue.js 3 UI Library made by Element team]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/element-plus/element-plus">element-plus/element-plus</a></h1>
            <p>üéâ A Vue.js 3 UI Library made by Element team</p>
            <p>Language: TypeScript</p>
            <p>Stars: 25,673</p>
            <p>Forks: 18,326</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;300px&quot; src=&quot;https://user-images.githubusercontent.com/10731096/95823103-9ce15780-0d5f-11eb-8010-1bd1b5910d4f.png&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.org/package/element-plus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/element-plus.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/element-plus/element-plus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/node-%20%3E%3D%2016-47c219&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://npmcharts.com/compare/element-plus?minimal=true&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/dm/element-plus.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/element-plus/element-plus&quot;&gt;
    &lt;img src=&quot;https://codecov.io/gh/element-plus/element-plus/branch/dev/graph/badge.svg?token=BKSBO2GLZI&quot;/&gt;
  &lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Element Plus - A Vue.js 3 UI library&lt;/p&gt;

- üí™ Vue 3 Composition API
- üî• Written in TypeScript

## Getting Started

Alright, for you to get started if you are looking for making Element Plus better you should keep reading.
For developers that uses Element Plus to develop your website you should go ahead visit [Getting Started](https://element-plus.org/).

- ‰∏≠ÂõΩÂ§ßÈôÜ[Âä†ÈÄüÈïúÂÉèÁ´ôÁÇπ](https://element-plus.gitee.io/)

## Breaking change list

The first stable release of Element Plus suitable for use in production was released on February 07, 2022. The APIs is stable right now, and here&#039;s also a full list about how to get upgraded from [Element UI](https://element.eleme.io) to Element Plus.

You can find the breaking change list here: [Breaking Change List](https://github.com/element-plus/element-plus/discussions/5658).

### Migration Tool :hammer_and_wrench:

We have made a migration tool for you to migrate your project from [Element UI](https://element.eleme.io) to Element Plus.

You can find the [gogo code migration tool](https://github.com/thx/gogocode/tree/main/packages/gogocode-plugin-element) here.

We have tested this on [Vue Element Admin](https://github.com/PanJiaChen/vue-element-admin). You can find the transpiled code [here](https://github.com/gogocodeio/vue-element-admin).

### Playground

You can also try Element Plus out with the components built-in playground.

#### Try it with our built-in playground

[Playground](https://element-plus.run/)

#### Try it with code sandbox

[![Edit element-plus](https://codesandbox.io/static/img/play-codesandbox.svg)](https://codesandbox.io/s/element-plus-demo-dxtcr)

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Special thanks to the generous sponsorship by:&lt;/b&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Platinum Sponsors&lt;/b&gt;
&lt;/p&gt;
&lt;table align=&quot;center&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://www.vform666.com/&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;150px&quot; src=&quot;https://user-images.githubusercontent.com/17680888/156870588-b25a42d5-888b-4943-8b1b-5239dfd8f4d2.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://js.design?source=element-plus&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;150px&quot; src=&quot;https://user-images.githubusercontent.com/17680888/160634485-df0d00af-8633-4ab8-9a72-aac2b65d1d36.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://www.misboot.com/?from=element-plus&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;150px&quot; src=&quot;https://github-production-user-asset-6210df.s3.amazonaws.com/82012629/250157573-b8ab8d68-ff6b-496f-beb1-9863a545d2af.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Gold Sponsors&lt;/b&gt;
&lt;/p&gt;
&lt;table align=&quot;center&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://wonderful-code.gitee.io/?from=element-plus&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;130px&quot; src=&quot;https://user-images.githubusercontent.com/17680888/173179536-30e35fd1-cd5a-482a-bc41-9d5f0aa66fd4.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://bit.dev/?from=element-ui&quot; target=&quot;_blank&quot;&gt;
          &lt;img width=&quot;130px&quot; src=&quot;https://user-images.githubusercontent.com/10095631/41342907-e44e7196-6f2f-11e8-92f2-47702dc8f059.png&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

---

## Translations

Element Plus is translated to multiple languages, you can click the badge to help up update the translation or apply to become
a proofreader [![Crowdin](https://badges.crowdin.net/element-plus/localized.svg)](https://crowdin.com/project/element-plus)

For now we are only showing English and Chinese for resource reasons, but we are looking forward to translate it into more languages, please go to the link
above and leave a message if you want to help translating Element Plus into your desired language.

### How to help translating

See how to help translating in [Translating Element Plus](https://element-plus.org/en-US/guide/translation.html).

## Stay tuned :eyes:

Join our [Discord](https://discord.com/invite/gXK9XNzW3X) to start communicating with everybody.

## This thing is broken, I should help improve it!

Awesommmmmmee. Everything you need is down below. You can also refer to
[CONTRIBUTING](https://github.com/element-plus/element-plus/blob/dev/CONTRIBUTING.md) and
[Code of Conduct](https://github.com/element-plus/element-plus/blob/dev/CODE_OF_CONDUCT.md)
where you&#039;ll find the same information listed below.

## I would like to become a part of the development team!

Welcome :star_struck:! We are looking for talented developers to join us and making Element Plus better! If you care to join the development team, please
reach out to us, you are more than welcomed to join us! :heart:

We are now lacking of experts of `Testing`, `GitHub Actions`, `PM`, if you do feel like you can and willing to help us, please do reach out to us. :pray:

## Contributors

This project exists thanks to all the people who contribute.

And thank you to all our backers! üôè

&lt;a href=&quot;https://github.com/element-plus/element-plus/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=element-plus/element-plus&quot; /&gt;
&lt;/a&gt;

## License

Element Plus is open source software licensed as
[MIT](https://github.com/element-plus/element-plus/blob/master/LICENSE).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>