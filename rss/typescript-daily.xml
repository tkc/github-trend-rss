<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Sun, 15 Feb 2026 00:06:58 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[tambo-ai/tambo]]></title>
            <link>https://github.com/tambo-ai/tambo</link>
            <guid>https://github.com/tambo-ai/tambo</guid>
            <pubDate>Sun, 15 Feb 2026 00:06:58 GMT</pubDate>
            <description><![CDATA[Generative UI SDK for React]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tambo-ai/tambo">tambo-ai/tambo</a></h1>
            <p>Generative UI SDK for React</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,601</p>
            <p>Forks: 464</p>
            <p>Stars today: 127 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/octo-white-background-rounded.png&quot; width=&quot;150&quot;&gt;
  &lt;h1&gt;Tambo AI&lt;/h1&gt;
  &lt;h3&gt;Build agents that speak your UI&lt;/h3&gt;
  &lt;p&gt;The open-source generative UI toolkit for React. Connect your components‚ÄîTambo handles streaming, state management, and MCP.&lt;/p&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/@tambo-ai/react&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/%40tambo-ai%2Freact?logo=npm&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/tambo-ai/tambo/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/tambo-ai/tambo&quot; alt=&quot;License&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/tambo-ai/tambo/commits/main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/last-commit/tambo-ai/tambo&quot; alt=&quot;Last Commit&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/dJNvPEHth6&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1251581895414911016?color=7289da&amp;label=discord&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/tambo-ai/tambo&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/tambo-ai/tambo&quot; alt=&quot;GitHub stars&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/15734&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15734&quot; alt=&quot;tambo-ai/tambo | Trendshift&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://tambo.link/yXkF0hQ&quot;&gt;Start For Free&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://docs.tambo.co&quot;&gt;Docs&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://discord.gg/dJNvPEHth6&quot;&gt;Discord&lt;/a&gt;
&lt;/p&gt;

---

&gt; **Tambo 1.0 is here!** Read the announcement: [Introducing Tambo: Generative UI for React](https://tambo.co/blog/posts/introducing-tambo-generative-ui)

---

## Table of Contents

- [What is Tambo?](#what-is-tambo)
- [Get Started](#get-started)
- [How It Works](#how-it-works)
- [Features](#features)
- [How Tambo Compares](#how-tambo-compares)
- [Community](#community)
- [License](#license)

## What is Tambo?

Tambo is a React toolkit for building agents that render UI (also known as generative UI).

Register your components with Zod schemas. The agent picks the right one and streams the props so users can interact with them. &quot;Show me sales by region&quot; renders your `&lt;Chart&gt;`. &quot;Add a task&quot; updates your `&lt;TaskBoard&gt;`.

**[Get started in 5 minutes ‚Üí](#get-started)**

https://github.com/user-attachments/assets/8381d607-b878-4823-8b24-ecb8053bef23

### What&#039;s Included

Tambo is a fullstack solution for adding generative UI to your app. You get a React SDK plus a backend that handles conversation state and agent execution.

**1. Agent included** ‚Äî Tambo runs the LLM conversation loop for you. Bring your own API key (OpenAI, Anthropic, Gemini, Mistral, or any OpenAI-compatible provider). Works with agent frameworks like LangChain and Mastra, but they&#039;re not required.

**2. Streaming infrastructure** ‚Äî Props stream to your components as the LLM generates them. Cancellation, error recovery, and reconnection are handled for you.

**3. Tambo Cloud or self-host** ‚Äî Cloud is a hosted backend that manages conversation state and agent orchestration. Self-hosted runs the same backend on your infrastructure via Docker.

Most software is built around a one-size-fits-all mental model. We built Tambo to help developers build software that adapts to users.

## Get Started

```bash
npm create tambo-app my-tambo-app  # auto-initializes git + tambo setup
cd my-tambo-app
npm run dev
```

[**Tambo Cloud**](https://tambo.link/yXkF0hQ) is a hosted backend, free to get started with plenty of credits to start building. **Self-hosted** runs on your own infrastructure.

Check out the [pre-built component library](https://ui.tambo.co) for agent and generative UI primitives:

https://github.com/user-attachments/assets/6cbc103b-9cc7-40f5-9746-12e04c976dff

Or fork a template:

| Template                                                                 | Description                                       |
| ------------------------------------------------------------------------ | ------------------------------------------------- |
| [AI Chat with Generative UI](https://github.com/tambo-ai/tambo-template) | Chat interface with dynamic component generation  |
| [AI Analytics Dashboard](https://github.com/tambo-ai/analytics-template) | Analytics dashboard with AI-powered visualization |

## How It Works

Tell the AI which components it can use. Zod schemas define the props. These schemas become LLM tool definitions‚Äîthe agent calls them like functions and Tambo renders the result.

### Generative Components

Render once in response to a message. Charts, summaries, data visualizations.

https://github.com/user-attachments/assets/3bd340e7-e226-4151-ae40-aab9b3660d8b

```tsx
const components: TamboComponent[] = [
  {
    name: &quot;Graph&quot;,
    description: &quot;Displays data as charts using Recharts library&quot;,
    component: Graph,
    propsSchema: z.object({
      data: z.array(z.object({ name: z.string(), value: z.number() })),
      type: z.enum([&quot;line&quot;, &quot;bar&quot;, &quot;pie&quot;]),
    }),
  },
];
```

### Interactable Components

Persist and update as users refine requests. Shopping carts, spreadsheets, task boards.

https://github.com/user-attachments/assets/12d957cd-97f1-488e-911f-0ff900ef4062

```tsx
const InteractableNote = withInteractable(Note, {
  componentName: &quot;Note&quot;,
  description: &quot;A note supporting title, content, and color modifications&quot;,
  propsSchema: z.object({
    title: z.string(),
    content: z.string(),
    color: z.enum([&quot;white&quot;, &quot;yellow&quot;, &quot;blue&quot;, &quot;green&quot;]).optional(),
  }),
});
```

Docs: [generative components](https://docs.tambo.co/concepts/generative-interfaces/generative-components), [interactable components](https://docs.tambo.co/concepts/generative-interfaces/interactable-components)

### The Provider

Wrap your app with `TamboProvider`. You must provide either `userKey` or `userToken` to identify the thread owner.

```tsx
&lt;TamboProvider
  apiKey={process.env.NEXT_PUBLIC_TAMBO_API_KEY!}
  userKey={currentUserId}
  components={components}
&gt;
  &lt;Chat /&gt;
  &lt;InteractableNote id=&quot;note-1&quot; title=&quot;My Note&quot; content=&quot;Start writing...&quot; /&gt;
&lt;/TamboProvider&gt;
```

Use `userKey` for server-side or trusted environments. Use `userToken` (OAuth access token) for client-side apps where the token contains the user identity. See [User Authentication](https://docs.tambo.co/concepts/user-authentication) for details.

Docs: [provider options](https://docs.tambo.co/reference/react-sdk/providers)

### Hooks

`useTambo()` is the primary hook ‚Äî it gives you messages, streaming state, and thread management. `useTamboThreadInput()` handles user input and message submission.

```tsx
const { messages, isStreaming } = useTambo();
const { value, setValue, submit, isPending } = useTamboThreadInput();
```

Docs: [threads and messages](https://docs.tambo.co/concepts/conversation-storage), [streaming status](https://docs.tambo.co/concepts/generative-interfaces/component-state), [full tutorial](https://docs.tambo.co/getting-started/quickstart)

## Features

### MCP Integrations

Connect to Linear, Slack, databases, or your own MCP servers. Tambo supports the full MCP protocol: tools, prompts, elicitations, and sampling.

```tsx
import { MCPTransport } from &quot;@tambo-ai/react/mcp&quot;;

const mcpServers = [
  {
    name: &quot;filesystem&quot;,
    url: &quot;http://localhost:8261/mcp&quot;,
    transport: MCPTransport.HTTP,
  },
];

&lt;TamboProvider
  apiKey={process.env.NEXT_PUBLIC_TAMBO_API_KEY!}
  userKey={currentUserId}
  components={components}
  mcpServers={mcpServers}
&gt;
  &lt;App /&gt;
&lt;/TamboProvider&gt;;
```

https://github.com/user-attachments/assets/c7a13915-8fed-4758-be1b-30a60fad0cda

Docs: [MCP integration](https://docs.tambo.co/concepts/model-context-protocol)

### Local Tools

Sometimes you need functions that run in the browser. DOM manipulation, authenticated fetches, accessing React state. Define them as tools and the AI can call them.

```tsx
const tools: TamboTool[] = [
  {
    name: &quot;getWeather&quot;,
    description: &quot;Fetches weather for a location&quot;,
    tool: async (params: { location: string }) =&gt;
      fetch(`/api/weather?q=${encodeURIComponent(params.location)}`).then((r) =&gt;
        r.json(),
      ),
    inputSchema: z.object({
      location: z.string(),
    }),
    outputSchema: z.object({
      temperature: z.number(),
      condition: z.string(),
      location: z.string(),
    }),
  },
];

&lt;TamboProvider
  apiKey={process.env.NEXT_PUBLIC_TAMBO_API_KEY!}
  userKey={currentUserId}
  tools={tools}
  components={components}
&gt;
  &lt;App /&gt;
&lt;/TamboProvider&gt;;
```

Docs: [local tools](https://docs.tambo.co/guides/take-actions/register-tools)

### Context, Auth, and Suggestions

**Additional context** lets you pass metadata to give the AI better responses. User state, app settings, current page. **User authentication** passes tokens from your auth provider. **Suggestions** generates prompts users can click based on what they&#039;re doing.

```tsx
&lt;TamboProvider
  apiKey={process.env.NEXT_PUBLIC_TAMBO_API_KEY!}
  userToken={userToken}
  contextHelpers={{
    selectedItems: () =&gt; ({
      key: &quot;selectedItems&quot;,
      value: selectedItems.map((i) =&gt; i.name).join(&quot;, &quot;),
    }),
    currentPage: () =&gt; ({ key: &quot;page&quot;, value: window.location.pathname }),
  }}
/&gt;
```

```tsx
const { suggestions, accept } = useTamboSuggestions({ maxSuggestions: 3 });

suggestions.map((s) =&gt; (
  &lt;button key={s.id} onClick={() =&gt; accept(s)}&gt;
    {s.title}
  &lt;/button&gt;
));
```

Docs: [additional context](https://docs.tambo.co/concepts/additional-context), [user authentication](https://docs.tambo.co/concepts/user-authentication), [suggestions](https://docs.tambo.co/concepts/suggestions)

### Supported LLM Providers

OpenAI, Anthropic, Cerebras, Google Gemini, Mistral, and any OpenAI-compatible provider. [Full list](https://docs.tambo.co/reference/llm-providers). Missing one? [Let us know](https://github.com/tambo-ai/tambo/issues).

## How Tambo Compares

| Feature                            | Tambo                                 | Vercel AI SDK                    | CopilotKit                       | Assistant UI         |
| ---------------------------------- | ------------------------------------- | -------------------------------- | -------------------------------- | -------------------- |
| **Component selection**            | AI decides which components to render | Manual tool-to-component mapping | Via agent frameworks (LangGraph) | Chat-focused tool UI |
| **MCP integration**                | Built-in                              | Experimental (v4.2+)             | Recently added                   | Requires AI SDK v5   |
| **Persistent stateful components** | Yes                                   | No                               | Shared state patterns            | No                   |
| **Client-side tool execution**     | Declarative, automatic                | Manual via onToolCall            | Agent-side only                  | No                   |
| **Self-hostable**                  | MIT (SDK + backend)                   | Apache 2.0 (SDK only)            | MIT                              | MIT                  |
| **Hosted option**                  | Tambo Cloud                           | No                               | CopilotKit Cloud                 | Assistant Cloud      |
| **Best for**                       | Full app UI control                   | Streaming and tool abstractions  | Multi-agent workflows            | Chat interfaces      |

## Community

Join the [Discord](https://discord.gg/dJNvPEHth6) to chat with other developers and the core team.

Interested in contributing? Read the [Contributing Guide](./CONTRIBUTING.md).

Join the conversation on Twitter and follow [@tambo_ai](https://twitter.com/tambo_ai).

## License

[MIT](LICENSE) unless otherwise noted. Some workspaces (like `apps/api`) are [Apache-2.0](apps/api/LICENSE).

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/tambo-animation.gif&quot; alt=&quot;Tambo AI Animation&quot; width=&quot;800&quot;&gt;
&lt;/p&gt;

**For AI/LLM agents:** [docs.tambo.co/llms.txt](https://docs.tambo.co/llms.txt)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[rowboatlabs/rowboat]]></title>
            <link>https://github.com/rowboatlabs/rowboat</link>
            <guid>https://github.com/rowboatlabs/rowboat</guid>
            <pubDate>Sun, 15 Feb 2026 00:06:57 GMT</pubDate>
            <description><![CDATA[Open-source AI coworker, with memory]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rowboatlabs/rowboat">rowboatlabs/rowboat</a></h1>
            <p>Open-source AI coworker, with memory</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,014</p>
            <p>Forks: 491</p>
            <p>Stars today: 217 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://www.youtube.com/watch?v=5AWoGo-L16I&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
  &lt;img width=&quot;1339&quot; height=&quot;607&quot; alt=&quot;rowboat-github-2&quot; src=&quot;https://github.com/user-attachments/assets/fc463b99-01b3-401c-b4a4-044dad480901&quot; /&gt;
&lt;/a&gt;

&lt;h5 align=&quot;center&quot;&gt;

&lt;p align=&quot;center&quot; style=&quot;display: flex; justify-content: center; gap: 20px; align-items: center;&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/13609&quot; target=&quot;blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/13609&quot; alt=&quot;rowboatlabs/rowboat | Trendshift&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.rowboatlabs.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img alt=&quot;Website&quot; src=&quot;https://img.shields.io/badge/Website-10b981?labelColor=10b981&amp;logo=window&amp;logoColor=white&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/wajrgmJQ6b&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/badge/Discord-5865F2?logo=discord&amp;logoColor=white&amp;labelColor=5865F2&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://x.com/intent/user?screen_name=rowboatlabshq&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img alt=&quot;Twitter&quot; src=&quot;https://img.shields.io/twitter/follow/rowboatlabshq?style=social&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.ycombinator.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img alt=&quot;Y Combinator&quot; src=&quot;https://img.shields.io/badge/Y%20Combinator-S24-orange&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

# Rowboat  
**Open-source AI coworker that turns work into a knowledge graph and acts on it**

&lt;/h5&gt;

Rowboat connects to your email and meeting notes, builds a long-lived knowledge graph, and uses that context to help you get work done - privately, on your machine.

You can do things like:
- `Build me a deck about our next quarter roadmap` ‚Üí generates a PDF using context from your knowledge graph
- `Prep me for my meeting with Alex` ‚Üí pulls past decisions, open questions, and relevant threads into a crisp brief (or a voice note)
- Visualize, edit, and update your knowledge graph anytime (it‚Äôs just Markdown)
- Record voice memos that automatically capture and update key takeaways in the graph

Download latest for Mac/Windows/Linux: [Download](https://www.rowboatlabs.com/downloads)


## Demo


[![Demo](https://github.com/user-attachments/assets/3f560bcf-d93c-4064-81eb-75a9fae31742)](https://www.youtube.com/watch?v=5AWoGo-L16I)

[Watch the full video](https://www.youtube.com/watch?v=5AWoGo-L16I)

---

## Installation

**Download latest for Mac/Windows/Linux:** [Download](https://www.rowboatlabs.com/downloads)

**All release files:**   https://github.com/rowboatlabs/rowboat/releases/latest

### Google setup
To connect Google services (Gmail, Calendar, and Drive), follow [Google setup](https://github.com/rowboatlabs/rowboat/blob/main/google-setup.md).

### Voice notes
To enable voice notes (optional), add a Deepgram API key in ~/.rowboat/config/deepgram.json:
```
{
  &quot;apiKey&quot;: &quot;&lt;key&gt;&quot;
}
```


## What it does

Rowboat is a **local-first AI coworker** that can:
- **Remember** the important context you don‚Äôt want to re-explain (people, projects, decisions, commitments)
- **Understand** what‚Äôs relevant right now (before a meeting, while replying to an email, when writing a doc)
- **Help you act** by drafting, summarizing, planning, and producing real artifacts (briefs, emails, docs, PDF slides)

Under the hood, Rowboat maintains an **Obsidian-compatible vault** of plain Markdown notes with backlinks ‚Äî a transparent ‚Äúworking memory‚Äù you can inspect and edit.

## Integrations

Rowboat builds memory from the work you already do, including:
- **Gmail** (email)
- **Granola** (meeting notes)
- **Fireflies** (meeting notes)

## How it‚Äôs different

Most AI tools reconstruct context on demand by searching transcripts or documents.

Rowboat maintains **long-lived knowledge** instead:
- context accumulates over time
- relationships are explicit and inspectable
- notes are editable by you, not hidden inside a model
- everything lives on your machine as plain Markdown

The result is memory that compounds, rather than retrieval that starts cold every time.

## What you can do with it

- **Meeting prep** from prior decisions, threads, and open questions
- **Email drafting** grounded in history and commitments
- **Docs &amp; decks** generated from your ongoing context (including PDF slides)
- **Follow-ups**: capture decisions, action items, and owners so nothing gets dropped
- **On-your-machine help**: create files, summarize into notes, and run workflows using local tools (with explicit, reviewable actions)

## Background agents

Rowboat can spin up **background agents** to do repeatable work automatically - so routine tasks happen without you having to ask every time.

Examples:
- Draft email replies in the background (grounded in your past context and commitments)
- Generate a daily voice note each morning (agenda, priorities, upcoming meetings)
- Create recurring project updates from the latest emails/notes
- Keep your knowledge graph up to date as new information comes in

You control what runs, when it runs, and what gets written back into your local Markdown vault.

## Bring your own model

Rowboat works with the model setup you prefer:
- **Local models** via Ollama or LM Studio
- **Hosted models** (bring your own API key/provider)
- Swap models anytime ‚Äî your data stays in your local Markdown vault

## Extend Rowboat with tools (MCP)

Rowboat can connect to external tools and services via **Model Context Protocol (MCP)**.
That means you can plug in (for example) search, databases, CRMs, support tools, and automations - or your own internal tools.

Examples: Exa (web search), Twitter/X, ElevenLabs (voice), Slack, Linear/Jira, GitHub, and more.

## Local-first by design

- All data is stored locally as plain Markdown
- No proprietary formats or hosted lock-in
- You can inspect, edit, back up, or delete everything at any time


## Looking for Rowboat Web Studio?

If you‚Äôre looking for Rowboat web Studio, start [here](https://docs.rowboatlabs.com/). 

---
&lt;div align=&quot;center&quot;&gt;

[Discord](https://discord.gg/wajrgmJQ6b) ¬∑ [Twitter](https://x.com/intent/user?screen_name=rowboatlabshq)
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ChromeDevTools/chrome-devtools-mcp]]></title>
            <link>https://github.com/ChromeDevTools/chrome-devtools-mcp</link>
            <guid>https://github.com/ChromeDevTools/chrome-devtools-mcp</guid>
            <pubDate>Sun, 15 Feb 2026 00:06:56 GMT</pubDate>
            <description><![CDATA[Chrome DevTools for coding agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ChromeDevTools/chrome-devtools-mcp">ChromeDevTools/chrome-devtools-mcp</a></h1>
            <p>Chrome DevTools for coding agents</p>
            <p>Language: TypeScript</p>
            <p>Stars: 25,081</p>
            <p>Forks: 1,479</p>
            <p>Stars today: 331 stars today</p>
            <h2>README</h2><pre># Chrome DevTools MCP

[![npm chrome-devtools-mcp package](https://img.shields.io/npm/v/chrome-devtools-mcp.svg)](https://npmjs.org/package/chrome-devtools-mcp)

`chrome-devtools-mcp` lets your coding agent (such as Gemini, Claude, Cursor or Copilot)
control and inspect a live Chrome browser. It acts as a Model-Context-Protocol
(MCP) server, giving your AI coding assistant access to the full power of
Chrome DevTools for reliable automation, in-depth debugging, and performance analysis.

## [Tool reference](./docs/tool-reference.md) | [Changelog](./CHANGELOG.md) | [Contributing](./CONTRIBUTING.md) | [Troubleshooting](./docs/troubleshooting.md) | [Design Principles](./docs/design-principles.md)

## Key features

- **Get performance insights**: Uses [Chrome
  DevTools](https://github.com/ChromeDevTools/devtools-frontend) to record
  traces and extract actionable performance insights.
- **Advanced browser debugging**: Analyze network requests, take screenshots and
  check browser console messages (with source-mapped stack traces).
- **Reliable automation**. Uses
  [puppeteer](https://github.com/puppeteer/puppeteer) to automate actions in
  Chrome and automatically wait for action results.

## Disclaimers

`chrome-devtools-mcp` exposes content of the browser instance to the MCP clients
allowing them to inspect, debug, and modify any data in the browser or DevTools.
Avoid sharing sensitive or personal information that you don&#039;t want to share with
MCP clients.

Performance tools may send trace URLs to the Google CrUX API to fetch real-user
experience data. This helps provide a holistic performance picture by
presenting field data alongside lab data. This data is collected by the [Chrome
User Experience Report (CrUX)](https://developer.chrome.com/docs/crux). To disable
this, run with the `--no-performance-crux` flag.

## **Usage statistics**

Google collects usage statistics (such as tool invocation success rates, latency, and environment information) to improve the reliability and performance of Chrome DevTools MCP.

Data collection is **enabled by default**. You can opt-out by passing the `--no-usage-statistics` flag when starting the server:

```json
&quot;args&quot;: [&quot;-y&quot;, &quot;chrome-devtools-mcp@latest&quot;, &quot;--no-usage-statistics&quot;]
```

Google handles this data in accordance with the [Google Privacy Policy](https://policies.google.com/privacy).

Google&#039;s collection of usage statistics for Chrome DevTools MCP is independent from the Chrome browser&#039;s usage statistics. Opting out of Chrome metrics does not automatically opt you out of this tool, and vice-versa.

Collection is disabled if CHROME_DEVTOOLS_MCP_NO_USAGE_STATISTICS or CI env variables are set.

## Requirements

- [Node.js](https://nodejs.org/) v20.19 or a newer [latest maintenance LTS](https://github.com/nodejs/Release#release-schedule) version.
- [Chrome](https://www.google.com/chrome/) current stable version or newer.
- [npm](https://www.npmjs.com/).

## Getting started

Add the following config to your MCP client:

```json
{
  &quot;mcpServers&quot;: {
    &quot;chrome-devtools&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;chrome-devtools-mcp@latest&quot;]
    }
  }
}
```

&gt; [!NOTE]  
&gt; Using `chrome-devtools-mcp@latest` ensures that your MCP client will always use the latest version of the Chrome DevTools MCP server.

### MCP Client configuration

&lt;details&gt;
  &lt;summary&gt;Amp&lt;/summary&gt;
  Follow https://ampcode.com/manual#mcp and use the config provided above. You can also install the Chrome DevTools MCP server using the CLI:

```bash
amp mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
```

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Antigravity&lt;/summary&gt;

To use the Chrome DevTools MCP server follow the instructions from &lt;a href=&quot;https://antigravity.google/docs/mcp&quot;&gt;Antigravity&#039;s docs&lt;/a&gt; to install a custom MCP server. Add the following config to the MCP servers config:

```bash
{
  &quot;mcpServers&quot;: {
    &quot;chrome-devtools&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;chrome-devtools-mcp@latest&quot;,
        &quot;--browser-url=http://127.0.0.1:9222&quot;,
        &quot;-y&quot;
      ]
    }
  }
}
```

This will make the Chrome DevTools MCP server automatically connect to the browser that Antigravity is using. If you are not using port 9222, make sure to adjust accordingly.

Chrome DevTools MCP will not start the browser instance automatically using this approach as as the Chrome DevTools MCP server runs in Antigravity&#039;s built-in browser. If the browser is not already running, you have to start it first by clicking the Chrome icon at the top right corner.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Claude Code&lt;/summary&gt;

**Install via CLI (MCP only)**

Use the Claude Code CLI to add the Chrome DevTools MCP server (&lt;a href=&quot;https://code.claude.com/docs/en/mcp&quot;&gt;guide&lt;/a&gt;):

```bash
claude mcp add chrome-devtools --scope user npx chrome-devtools-mcp@latest
```

**Install as a Plugin (MCP + Skills)**

To install Chrome DevTools MCP with skills, add the marketplace registry in Claude Code:

```sh
/plugin marketplace add ChromeDevTools/chrome-devtools-mcp
```

Then, install the plugin:

```sh
/plugin install chrome-devtools-mcp
```

Restart Claude Code to have the MCP server and skills load (check with `/skills`).

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Cline&lt;/summary&gt;
  Follow https://docs.cline.bot/mcp/configuring-mcp-servers and use the config provided above.
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Codex&lt;/summary&gt;
  Follow the &lt;a href=&quot;https://github.com/openai/codex/blob/main/docs/advanced.md#model-context-protocol-mcp&quot;&gt;configure MCP guide&lt;/a&gt;
  using the standard config from above. You can also install the Chrome DevTools MCP server using the Codex CLI:

```bash
codex mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
```

**On Windows 11**

Configure the Chrome install location and increase the startup timeout by updating `.codex/config.toml` and adding the following `env` and `startup_timeout_ms` parameters:

```
[mcp_servers.chrome-devtools]
command = &quot;cmd&quot;
args = [
    &quot;/c&quot;,
    &quot;npx&quot;,
    &quot;-y&quot;,
    &quot;chrome-devtools-mcp@latest&quot;,
]
env = { SystemRoot=&quot;C:\\Windows&quot;, PROGRAMFILES=&quot;C:\\Program Files&quot; }
startup_timeout_ms = 20_000
```

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Copilot CLI&lt;/summary&gt;

Start Copilot CLI:

```
copilot
```

Start the dialog to add a new MCP server by running:

```
/mcp add
```

Configure the following fields and press `CTRL+S` to save the configuration:

- **Server name:** `chrome-devtools`
- **Server Type:** `[1] Local`
- **Command:** `npx -y chrome-devtools-mcp@latest`

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Copilot / VS Code&lt;/summary&gt;

**Click the button to install:**

[&lt;img src=&quot;https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&amp;label=Install%20Server&amp;color=0098FF&quot; alt=&quot;Install in VS Code&quot;&gt;](https://vscode.dev/redirect/mcp/install?name=io.github.ChromeDevTools%2Fchrome-devtools-mcp&amp;config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22chrome-devtools-mcp%22%5D%2C%22env%22%3A%7B%7D%7D)

[&lt;img src=&quot;https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&amp;label=Install%20Server&amp;color=24bfa5&quot; alt=&quot;Install in VS Code Insiders&quot;&gt;](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522io.github.ChromeDevTools%252Fchrome-devtools-mcp%2522%252C%2522config%2522%253A%257B%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522chrome-devtools-mcp%2522%255D%252C%2522env%2522%253A%257B%257D%257D%257D)

**Or install manually:**

Follow the MCP install &lt;a href=&quot;https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_add-an-mcp-server&quot;&gt;guide&lt;/a&gt;,
with the standard config from above. You can also install the Chrome DevTools MCP server using the VS Code CLI:

```bash
code --add-mcp &#039;{&quot;name&quot;:&quot;io.github.ChromeDevTools/chrome-devtools-mcp&quot;,&quot;command&quot;:&quot;npx&quot;,&quot;args&quot;:[&quot;-y&quot;,&quot;chrome-devtools-mcp&quot;],&quot;env&quot;:{}}&#039;
```

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Cursor&lt;/summary&gt;

**Click the button to install:**

[&lt;img src=&quot;https://cursor.com/deeplink/mcp-install-dark.svg&quot; alt=&quot;Install in Cursor&quot;&gt;](https://cursor.com/en/install-mcp?name=chrome-devtools&amp;config=eyJjb21tYW5kIjoibnB4IC15IGNocm9tZS1kZXZ0b29scy1tY3BAbGF0ZXN0In0%3D)

**Or install manually:**

Go to `Cursor Settings` -&gt; `MCP` -&gt; `New MCP Server`. Use the config provided above.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Factory CLI&lt;/summary&gt;
Use the Factory CLI to add the Chrome DevTools MCP server (&lt;a href=&quot;https://docs.factory.ai/cli/configuration/mcp&quot;&gt;guide&lt;/a&gt;):

```bash
droid mcp add chrome-devtools &quot;npx -y chrome-devtools-mcp@latest&quot;
```

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Gemini CLI&lt;/summary&gt;
Install the Chrome DevTools MCP server using the Gemini CLI.

**Project wide:**

```bash
# Either MCP only:
gemini mcp add chrome-devtools npx chrome-devtools-mcp@latest
# Or as a Gemini extension (MCP+Skills):
gemini extensions install --auto-update https://github.com/ChromeDevTools/chrome-devtools-mcp
```

**Globally:**

```bash
gemini mcp add -s user chrome-devtools npx chrome-devtools-mcp@latest
```

Alternatively, follow the &lt;a href=&quot;https://github.com/google-gemini/gemini-cli/blob/main/docs/tools/mcp-server.md#how-to-set-up-your-mcp-server&quot;&gt;MCP guide&lt;/a&gt; and use the standard config from above.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Gemini Code Assist&lt;/summary&gt;
  Follow the &lt;a href=&quot;https://cloud.google.com/gemini/docs/codeassist/use-agentic-chat-pair-programmer#configure-mcp-servers&quot;&gt;configure MCP guide&lt;/a&gt;
  using the standard config from above.
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;JetBrains AI Assistant &amp; Junie&lt;/summary&gt;

Go to `Settings | Tools | AI Assistant | Model Context Protocol (MCP)` -&gt; `Add`. Use the config provided above.
The same way chrome-devtools-mcp can be configured for JetBrains Junie in `Settings | Tools | Junie | MCP Settings` -&gt; `Add`. Use the config provided above.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Kiro&lt;/summary&gt;

In **Kiro Settings**, go to `Configure MCP` &gt; `Open Workspace or User MCP Config` &gt; Use the configuration snippet provided above.

Or, from the IDE **Activity Bar** &gt; `Kiro` &gt; `MCP Servers` &gt; `Click Open MCP Config`. Use the configuration snippet provided above.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Katalon Studio&lt;/summary&gt;

The Chrome DevTools MCP server can be used with &lt;a href=&quot;https://docs.katalon.com/katalon-studio/studioassist/mcp-servers/setting-up-chrome-devtools-mcp-server-for-studioassist&quot;&gt;Katalon StudioAssist&lt;/a&gt; via an MCP proxy.

**Step 1:** Install the MCP proxy by following the &lt;a href=&quot;https://docs.katalon.com/katalon-studio/studioassist/mcp-servers/setting-up-mcp-proxy-for-stdio-mcp-servers&quot;&gt;MCP proxy setup guide&lt;/a&gt;.

**Step 2:** Start the Chrome DevTools MCP server with the proxy:

```bash
mcp-proxy --transport streamablehttp --port 8080 -- npx -y chrome-devtools-mcp@latest
```

**Note:** You may need to pick another port if 8080 is already in use.

**Step 3:** In Katalon Studio, add the server to StudioAssist with the following settings:

- **Connection URL:** `http://127.0.0.1:8080/mcp`
- **Transport type:** `HTTP`

Once connected, the Chrome DevTools MCP tools will be available in StudioAssist.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;OpenCode&lt;/summary&gt;

Add the following configuration to your `opencode.json` file. If you don&#039;t have one, create it at `~/.config/opencode/opencode.json` (&lt;a href=&quot;https://opencode.ai/docs/mcp-servers&quot;&gt;guide&lt;/a&gt;):

```json
{
  &quot;$schema&quot;: &quot;https://opencode.ai/config.json&quot;,
  &quot;mcp&quot;: {
    &quot;chrome-devtools&quot;: {
      &quot;type&quot;: &quot;local&quot;,
      &quot;command&quot;: [&quot;npx&quot;, &quot;-y&quot;, &quot;chrome-devtools-mcp@latest&quot;]
    }
  }
}
```

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Qoder&lt;/summary&gt;

In **Qoder Settings**, go to `MCP Server` &gt; `+ Add` &gt; Use the configuration snippet provided above.

Alternatively, follow the &lt;a href=&quot;https://docs.qoder.com/user-guide/chat/model-context-protocol&quot;&gt;MCP guide&lt;/a&gt; and use the standard config from above.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Qoder CLI&lt;/summary&gt;

Install the Chrome DevTools MCP server using the Qoder CLI (&lt;a href=&quot;https://docs.qoder.com/cli/using-cli#mcp-servsers&quot;&gt;guide&lt;/a&gt;):

**Project wide:**

```bash
qodercli mcp add chrome-devtools -- npx chrome-devtools-mcp@latest
```

**Globally:**

```bash
qodercli mcp add -s user chrome-devtools -- npx chrome-devtools-mcp@latest
```

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Visual Studio&lt;/summary&gt;
  
  **Click the button to install:**
  
  [&lt;img src=&quot;https://img.shields.io/badge/Visual_Studio-Install-C16FDE?logo=visualstudio&amp;logoColor=white&quot; alt=&quot;Install in Visual Studio&quot;&gt;](https://vs-open.link/mcp-install?%7B%22name%22%3A%22chrome-devtools%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22chrome-devtools-mcp%40latest%22%5D%7D)
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Warp&lt;/summary&gt;

Go to `Settings | AI | Manage MCP Servers` -&gt; `+ Add` to [add an MCP Server](https://docs.warp.dev/knowledge-and-collaboration/mcp#adding-an-mcp-server). Use the config provided above.

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Windsurf&lt;/summary&gt;
  Follow the &lt;a href=&quot;https://docs.windsurf.com/windsurf/cascade/mcp#mcp-config-json&quot;&gt;configure MCP guide&lt;/a&gt;
  using the standard config from above.
&lt;/details&gt;

### Your first prompt

Enter the following prompt in your MCP Client to check if everything is working:

```
Check the performance of https://developers.chrome.com
```

Your MCP client should open the browser and record a performance trace.

&gt; [!NOTE]  
&gt; The MCP server will start the browser automatically once the MCP client uses a tool that requires a running browser instance. Connecting to the Chrome DevTools MCP server on its own will not automatically start the browser.

## Tools

If you run into any issues, checkout our [troubleshooting guide](./docs/troubleshooting.md).

&lt;!-- BEGIN AUTO GENERATED TOOLS --&gt;

- **Input automation** (8 tools)
  - [`click`](docs/tool-reference.md#click)
  - [`drag`](docs/tool-reference.md#drag)
  - [`fill`](docs/tool-reference.md#fill)
  - [`fill_form`](docs/tool-reference.md#fill_form)
  - [`handle_dialog`](docs/tool-reference.md#handle_dialog)
  - [`hover`](docs/tool-reference.md#hover)
  - [`press_key`](docs/tool-reference.md#press_key)
  - [`upload_file`](docs/tool-reference.md#upload_file)
- **Navigation automation** (6 tools)
  - [`close_page`](docs/tool-reference.md#close_page)
  - [`list_pages`](docs/tool-reference.md#list_pages)
  - [`navigate_page`](docs/tool-reference.md#navigate_page)
  - [`new_page`](docs/tool-reference.md#new_page)
  - [`select_page`](docs/tool-reference.md#select_page)
  - [`wait_for`](docs/tool-reference.md#wait_for)
- **Emulation** (2 tools)
  - [`emulate`](docs/tool-reference.md#emulate)
  - [`resize_page`](docs/tool-reference.md#resize_page)
- **Performance** (3 tools)
  - [`performance_analyze_insight`](docs/tool-reference.md#performance_analyze_insight)
  - [`performance_start_trace`](docs/tool-reference.md#performance_start_trace)
  - [`performance_stop_trace`](docs/tool-reference.md#performance_stop_trace)
- **Network** (2 tools)
  - [`get_network_request`](docs/tool-reference.md#get_network_request)
  - [`list_network_requests`](docs/tool-reference.md#list_network_requests)
- **Debugging** (5 tools)
  - [`evaluate_script`](docs/tool-reference.md#evaluate_script)
  - [`get_console_message`](docs/tool-reference.md#get_console_message)
  - [`list_console_messages`](docs/tool-reference.md#list_console_messages)
  - [`take_screenshot`](docs/tool-reference.md#take_screenshot)
  - [`take_snapshot`](docs/tool-reference.md#take_snapshot)

&lt;!-- END AUTO GENERATED TOOLS --&gt;

## Configuration

The Chrome DevTools MCP server supports the following configuration option:

&lt;!-- BEGIN AUTO GENERATED OPTIONS --&gt;

- **`--autoConnect`/ `--auto-connect`**
  If specified, automatically connects to a browser (Chrome 144+) running in the user data directory identified by the channel param. Requires the remoted debugging server to be started in the Chrome instance via chrome://inspect/#remote-debugging.
  - **Type:** boolean
  - **Default:** `false`

- **`--browserUrl`/ `--browser-url`, `-u`**
  Connect to a running, debuggable Chrome instance (e.g. `http://127.0.0.1:9222`). For more details see: https://github.com/ChromeDevTools/chrome-devtools-mcp#connecting-to-a-running-chrome-instance.
  - **Type:** string

- **`--wsEndpoint`/ `--ws-endpoint`, `-w`**
  WebSocket endpoint to connect to a running Chrome instance (e.g., ws://127.0.0.1:9222/devtools/browser/&lt;id&gt;). Alternative to --browserUrl.
  - **Type:** string

- **`--wsHeaders`/ `--ws-headers`**
  Custom headers for WebSocket connection in JSON format (e.g., &#039;{&quot;Authorization&quot;:&quot;Bearer token&quot;}&#039;). Only works with --wsEndpoint.
  - **Type:** string

- **`--headless`**
  Whether to run in headless (no UI) mode.
  - **Type:** boolean
  - **Default:** `false`

- **`--executablePath`/ `--executable-path`, `-e`**
  Path to custom Chrome executable.
  - **Type:** string

- **`--isolated`**
  If specified, creates a temporary user-data-dir that is automatically cleaned up after the browser is closed. Defaults to false.
  - **Type:** boolean

- **`--userDataDir`/ `--user-data-dir`**
  Path to the user data directory for Chrome. Default is $HOME/.cache/chrome-devtools-mcp/chrome-profile$CHANNEL_SUFFIX_IF_NON_STABLE
  - **Type:** string

- **`--channel`**
  Specify a different Chrome channel that should be used. The default is the stable channel version.
  - **Type:** string
  - **Choices:** `stable`, `canary`, `beta`, `dev`

- **`--logFile`/ `--log-file`**
  Path to a file to write debug logs to. Set the env variable `DEBUG` to `*` to enable verbose logs. Useful for submitting bug reports.
  - **Type:** string

- **`--viewport`**
  Initial viewport size for the Chrome instances started by the server. For example, `1280x720`. In headless mode, max size is 3840x2160px.
  - **Type:** string

- **`--proxyServer`/ `--proxy-server`**
  Proxy server configuration for Chrome passed as --proxy-server when launching the browser. See https://www.chromium.org/developers/design-documents/network-settings/ for details.
  - **Type:** string

- **`--acceptInsecureCerts`/ `--accept-insecure-certs`**
  If enabled, ignores errors relative to self-signed and expired certificates. Use with caution.
  - **Type:** boolean

- **`--chromeArg`/ `--chrome-arg`**
  Additional arguments for Chrome. Only applies when Chrome is launched by chrome-devtools-mcp.
  - **Type:** array

- **`--ignoreDefaultChromeArg`/ `--ignore-default-chrome-arg`**
  Explicitly disable default arguments for Chrome. Only applies when Chrome is launched by chrome-devtools-mcp.
  - **Type:** array

- **`--categoryEmulation`/ `--category-emulation`**
  Set to false to exclude tools related to emulation.
  - **Type:** boolean
  - **Default:** `true`

- **`--categoryPerformance`/ `--category-performance`**
  Set to false to exclude tools related to performance.
  - **Type:** boolean
  - **Default:** `true`

- **`--categoryNetwork`/ `--category-network`**
  Set to false to exclude tools related to network.
  - **Type:** boolean
  - **Default:** `true`

- **`--performanceCrux`/ `--performance-crux`**
  Set to false to disable sending URLs from performance traces to CrUX API to get field performance data.
  - **Type:** boolean
  - **Default:** `true`

- **`--usageStatistics`/ `--usage-statistics`**
  Set to false to opt-out of usage statistics collection. Google collects usage data to improve the tool, handled under the Google Privacy Policy (https://policies.google.com/privacy). This is independent from Chrome browser metrics. Disabled if CHROME_DEVTOOLS_MCP_NO_USAGE_STATISTICS or CI env variables are set.
  - **Type:** boolean
  - **Default:** `true`

&lt;!-- END AUTO GENERATED OPTIONS --&gt;

Pass them via the `args` property in the JSON configuration. For example:

```json
{
  &quot;mcpServers&quot;: {
    &quot;chrome-devtools&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;chrome-devtools-mcp@latest&quot;,
        &quot;--channel=canary&quot;,
        &quot;--headless=true&quot;,
        &quot;--isolated=true&quot;
      ]
    }
  }
}
```

### Connecting via WebSocket with custom headers

You can connect direct

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[letta-ai/letta-code]]></title>
            <link>https://github.com/letta-ai/letta-code</link>
            <guid>https://github.com/letta-ai/letta-code</guid>
            <pubDate>Sun, 15 Feb 2026 00:06:55 GMT</pubDate>
            <description><![CDATA[The memory-first coding agent]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/letta-ai/letta-code">letta-ai/letta-code</a></h1>
            <p>The memory-first coding agent</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,202</p>
            <p>Forks: 135</p>
            <p>Stars today: 55 stars today</p>
            <h2>README</h2><pre># Letta Code

[![npm](https://img.shields.io/npm/v/@letta-ai/letta-code.svg?style=flat-square)](https://www.npmjs.com/package/@letta-ai/letta-code) [![Discord](https://img.shields.io/badge/discord-join-blue?style=flat-square&amp;logo=discord)](https://discord.gg/letta)

Letta Code is a memory-first coding harness, built on top of the Letta API. Instead of working in independent sessions, you work with a persisted agent that learns over time and is portable across models (Claude Sonnet/Opus 4.5, GPT-5.2-Codex, Gemini 3 Pro, GLM-4.7, and more).

**Read more about how to use Letta Code on the [official docs page](https://docs.letta.com/letta-code).**

![](https://github.com/letta-ai/letta-code/blob/main/assets/letta-code-demo.gif)

## Get started
Install the package via [npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm):
```bash
npm install -g @letta-ai/letta-code
```
Navigate to your project directory and run `letta` (see various command-line options [on the docs](https://docs.letta.com/letta-code/commands)). 

Run `/connect` to configure your own LLM API keys (OpenAI, Anthropic, etc.), and use `/model` to swap models.

&gt; [!NOTE]
&gt;  By default, Letta Code will to connect to the [Letta API](https://app.letta.com/). Use `/connect` to use your own LLM API keys and coding plans (Codex, zAI, Minimax) for free. Set `LETTA_BASE_URL` to connect to an external [Docker server](https://docs.letta.com/letta-code/docker).

## Philosophy 
Letta Code is built around long-lived agents that persist across sessions and improve with use. Rather than working in independent sessions, each session is tied to a persisted agent that learns.

**Claude Code / Codex / Gemini CLI** (Session-Based)
- Sessions are independent
- No learning between sessions
- Context = messages in the current session + `AGENTS.md`
- Relationship: Every conversation is like meeting a new contractor

**Letta Code** (Agent-Based)
- Same agent across sessions
- Persistent memory and learning over time
- `/clear` starts a new conversation (aka &quot;thread&quot; or &quot;session&quot;), but memory persists
- Relationship: Like having a coworker or mentee that learns and remembers

## Agent Memory &amp; Learning
If you‚Äôre using Letta Code for the first time, you will likely want to run the `/init` command to initialize the agent‚Äôs memory system:
```bash
&gt; /init
```

Over time, the agent will update its memory as it learns. To actively guide your agents memory, you can use the `/remember` command:
```bash
&gt; /remember [optional instructions on what to remember]
```
Letta Code works with skills (reusable modules that teach your agent new capabilities in a `.skills` directory), but additionally supports [skill learning](https://www.letta.com/blog/skill-learning). You can ask your agent to learn a skill from it&#039;s current trajectory with the command: 
```bash
&gt; /skill [optional instructions on what skill to learn]
```

Read the docs to learn more about [skills and skill learning](https://docs.letta.com/letta-code/skills).

Community maintained packages are available for Arch Linux users on the [AUR](https://aur.archlinux.org/packages/letta-code):
```bash
yay -S letta-code # release
yay -S letta-code-git # nightly
```

---

Made with üíú in San Francisco
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[cinnyapp/cinny]]></title>
            <link>https://github.com/cinnyapp/cinny</link>
            <guid>https://github.com/cinnyapp/cinny</guid>
            <pubDate>Sun, 15 Feb 2026 00:06:54 GMT</pubDate>
            <description><![CDATA[Yet another matrix client]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cinnyapp/cinny">cinnyapp/cinny</a></h1>
            <p>Yet another matrix client</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,044</p>
            <p>Forks: 410</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[danielmiessler/Personal_AI_Infrastructure]]></title>
            <link>https://github.com/danielmiessler/Personal_AI_Infrastructure</link>
            <guid>https://github.com/danielmiessler/Personal_AI_Infrastructure</guid>
            <pubDate>Sun, 15 Feb 2026 00:06:53 GMT</pubDate>
            <description><![CDATA[Agentic AI Infrastructure for magnifying HUMAN capabilities.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/danielmiessler/Personal_AI_Infrastructure">danielmiessler/Personal_AI_Infrastructure</a></h1>
            <p>Agentic AI Infrastructure for magnifying HUMAN capabilities.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 8,332</p>
            <p>Forks: 1,155</p>
            <p>Stars today: 406 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./images/pai-logo-v7.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./images/pai-logo-v7.png&quot;&gt;
  &lt;img alt=&quot;PAI Logo&quot; src=&quot;./images/pai-logo-v7.png&quot; width=&quot;300&quot;&gt;
&lt;/picture&gt;

&lt;br/&gt;
&lt;br/&gt;

# Personal AI Infrastructure

[![Typing SVG](https://readme-typing-svg.demolab.com?font=Fira+Code&amp;weight=500&amp;size=24&amp;pause=1000&amp;color=60A5FA&amp;center=true&amp;vCenter=true&amp;width=600&amp;lines=Everyone+needs+access+to+the+best+AI.;AI+should+magnify+everyone.;Your+personal+AI+stack.)](https://github.com/danielmiessler/PAI)

&lt;br/&gt;

&lt;!-- Social Proof --&gt;
![Stars](https://img.shields.io/github/stars/danielmiessler/PAI?style=social)
![Forks](https://img.shields.io/github/forks/danielmiessler/PAI?style=social)
![Watchers](https://img.shields.io/github/watchers/danielmiessler/PAI?style=social)

&lt;!-- Project Health --&gt;
![Release](https://img.shields.io/github/v/release/danielmiessler/PAI?style=flat&amp;logo=github&amp;color=8B5CF6)
![Last Commit](https://img.shields.io/github/last-commit/danielmiessler/PAI?style=flat&amp;logo=git&amp;color=22C55E)
![Open Issues](https://img.shields.io/github/issues/danielmiessler/PAI?style=flat&amp;logo=github&amp;color=F97316)
![Open PRs](https://img.shields.io/github/issues-pr/danielmiessler/PAI?style=flat&amp;logo=github&amp;color=EC4899)
![License](https://img.shields.io/github/license/danielmiessler/PAI?style=flat&amp;color=60A5FA)

&lt;!-- Metrics --&gt;
![Discussions](https://img.shields.io/github/discussions/danielmiessler/PAI?style=flat&amp;logo=github&amp;label=Discussions&amp;color=EAB308)
![Commit Activity](https://img.shields.io/github/commit-activity/m/danielmiessler/PAI?style=flat&amp;logo=git&amp;label=Commits%2Fmo&amp;color=F59E0B)
![Repo Size](https://img.shields.io/github/repo-size/danielmiessler/PAI?style=flat&amp;logo=database&amp;label=Repo%20Size&amp;color=D97706)

&lt;!-- Content --&gt;
[![Get Started](https://img.shields.io/badge/üöÄ_Get_Started-Install-22C55E?style=flat)](#-installation)
[![Release v2.5](https://img.shields.io/badge/üì¶_Release-v2.5-8B5CF6?style=flat)](Releases/v2.5/)
[![Packs](https://img.shields.io/badge/üì¶_Packs-23-8B5CF6?style=flat)](Packs/)
[![Bundles](https://img.shields.io/badge/üéÅ_Bundles-1-F97316?style=flat)](Bundles/)
[![Contributors](https://img.shields.io/github/contributors/danielmiessler/PAI?style=flat&amp;logo=githubsponsors&amp;logoColor=white&amp;label=Contributors&amp;color=EC4899)](https://github.com/danielmiessler/PAI/graphs/contributors)

&lt;!-- Tech Stack --&gt;
[![Built with Claude](https://img.shields.io/badge/Built_with-Claude-D4A574?style=flat&amp;logo=anthropic&amp;logoColor=white)](https://claude.ai)
[![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=flat&amp;logo=typescript&amp;logoColor=white)](https://www.typescriptlang.org/)
[![Bun](https://img.shields.io/badge/Bun-000000?style=flat&amp;logo=bun&amp;logoColor=white)](https://bun.sh)
[![UL Community](https://img.shields.io/badge/UL_Community-5865F2?style=flat&amp;logo=discord&amp;logoColor=white)](https://danielmiessler.com/upgrade)

&lt;br/&gt;

**Overview:** [Purpose](#the-purpose-of-this-project) ¬∑ [What is PAI?](#what-is-pai) ¬∑ [New to AI?](#new-to-this-start-here) ¬∑ [Principles](#the-pai-principles) ¬∑ [Primitives](#pai-primitives)

**Get Started:** [Installation](#-installation) ¬∑ [Releases](Releases/) ¬∑ [Packs](#-packs) ¬∑ [Bundles](#-bundles)

**Resources:** [FAQ](#-faq) ¬∑ [Roadmap](#-roadmap) ¬∑ [Community](#-community) ¬∑ [Contributing](#-contributing)

&lt;br/&gt;

[![PAI Overview Video](https://img.youtube.com/vi/Le0DLrn7ta0/maxresdefault.jpg)](https://youtu.be/Le0DLrn7ta0)

**[Watch the full PAI walkthrough](https://youtu.be/Le0DLrn7ta0)** | **[Read: The Real Internet of Things](https://danielmiessler.com/blog/real-internet-of-things)**

---

&lt;/div&gt;

&gt; [!IMPORTANT]
&gt; **PAI v2.5.0 Released** ‚Äî Think Deeper, Execute Faster: Two-Pass Capability Selection, Thinking Tools with Justify-Exclusion, and Parallel-by-Default Execution.
&gt;
&gt; **[Release notes ‚Üí](Releases/v2.5/README.md)** | **[GitHub Release ‚Üí](https://github.com/danielmiessler/PAI/releases/tag/v2.5.0)**

&lt;div align=&quot;center&quot;&gt;

# AI should magnify everyone‚Äînot just the top 1%.

&lt;/div&gt;

## The Purpose of This Project

**PAI exists to solve what I believe is the [P0 problem](https://danielmiessler.com/telos) in the world:**

### Only a tiny fraction of humanity&#039;s creative potential is activated on Earth.

Most people don&#039;t believe they have valuable contributions to make. They think there are &quot;special&quot; people‚Äîand they aren&#039;t one of them. They&#039;ve never asked who they are, what they&#039;re about, and have never articulated or written it down. This makes them catastrophically vulnerable to AI displacement. Without activation, there is no high-agency.

So our goal with PAI is to activate people.

**PAI&#039;s mission is twofold:**

1. **Activate as many people as possible** ‚Äî Help people identify, articulate, and pursue their own purpose in life through AI-augmented self-discovery
2. **Make the best AI available in the world accessible to everyone** ‚Äî Ensure this quality of AI infrastructure isn&#039;t reserved for just the rich or technical elite.

That&#039;s why this is an open-source project instead of private.

---

## New to This? Start Here

You&#039;ve probably used ChatGPT or Claude. Type a question, get an answer. Simple.

You can think of AI systems as **three levels**:

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-eli5-diagram.png&quot; alt=&quot;The AI Evolution - From chatbots to your personal AI system&quot; width=&quot;800&quot;&gt;
&lt;/p&gt;

### Chatbots

ChatGPT, Claude, Gemini‚Äîyou ask something, it answers, and then it forgets everything. Next conversation starts fresh. No memory of you, your preferences, or what you talked about yesterday.

**The pattern:** Ask ‚Üí Answer ‚Üí Forget

### Agentic Platforms

Tools like Claude Code, Cursor, and Windsurf. The AI can actually *do* things‚Äîwrite code, browse the web, edit files, run commands.

**The pattern:** Ask ‚Üí Use tools ‚Üí Get result

More capable, but it still doesn&#039;t know *you*‚Äîyour goals, your preferences, your history.

### PAI (Personal AI Infrastructure)

Now your DA **learns and improves**:
- **Captures every signal** ‚Äî Ratings, sentiment, verification outcomes
- **Learns from mistakes** ‚Äî Failures get analyzed and fixed
- **Gets better over time** ‚Äî Success patterns get reinforced
- **Upgrades itself** ‚Äî Skills, workflows, even the core behavior evolves

Plus it knows:
- **Your goals** ‚Äî What you&#039;re working toward
- **Your preferences** ‚Äî How you like things done
- **Your history** ‚Äî Past decisions and learnings

**The pattern:** Observe ‚Üí Think ‚Üí Plan ‚Üí Execute ‚Üí Verify ‚Üí **Learn** ‚Üí Improve

The key difference: **PAI learns from feedback**. Every interaction makes it better at helping *you* specifically.

---

## What is PAI?

PAI is a Personalized AI Platform designed to magnify your capabilities.

It&#039;s designed for humans most of all, but can be used by teams, companies, or Federations of Planets desiring to be better versions of themselves.

The scale of the entity doesn&#039;t matter: It&#039;s a system for understanding, articulating, and realizing its principal&#039;s goals using a full-featured Agentic AI Platform.

### Who is PAI for?

**Everyone, full stop.** It&#039;s the anti-gatekeeping AI project.

- **Small business owners** who aren&#039;t technical but want AI to handle invoicing, scheduling, customer follow-ups, and marketing
- **Companies** who want to understand their data, optimize operations, and make better decisions
- **Managers** who want to run their teams more effectively‚Äîtracking projects, preparing for reviews, and communicating clearly
- **Artists and creatives** who want to find local events, galleries, and opportunities to showcase their work
- **Everyday people** who want to improve their lives‚Äîbetter fitness routines, stronger social connections, personal finance, or just getting organized
- **Developers** using AI coding assistants who want persistent memory and custom workflows
- **Power users** who want their AI to know their goals, preferences, and context
- **Teams** building shared AI infrastructure with consistent capabilities
- **Experimenters** interested in AI system design and personal AI patterns

### What makes PAI different?

The first thing people ask is:

&gt; How is this different from Claude Code, or any of the other agentic systems?

Most agentic systems are built around tools with the user being an afterthought. They are also mostly task-based instead of being goal-based using all the context available to them. PAI is the opposite.

**Three core differentiators:**

1. **Goal Orientation** ‚Äî PAI&#039;s primary focus is on the human running it and what they&#039;re trying to do in the world, not the tech. This is built into how the system executes all tasks.

2. **Pursuit of Optimal Output** ‚Äî The system&#039;s outer loop and everything it does is trying to produce the exact right output given the current situation and all the contexts around it.

3. **Continuous Learning** ‚Äî The system constantly captures signals about what was done, what changes were made, what outputs were produced for each request, and then how you liked or disliked the results.

---

## The PAI Principles

These principles guide how PAI systems are designed and built. **[Full breakdown ‚Üí](https://danielmiessler.com/blog/personal-ai-infrastructure)**

| # | Principle | Summary |
|---|-----------|---------|
| 1 | **User Centricity** | PAI is built around you, not tooling. Your goals, preferences, and context come first‚Äîthe infrastructure exists to serve them. |
| 2 | **The Foundational Algorithm** | The scientific method as a universal problem-solving loop: Observe ‚Üí Think ‚Üí Plan ‚Üí Build ‚Üí Execute ‚Üí Verify ‚Üí Learn. Define the ideal state, iterate until you reach it. |
| 3 | **Clear Thinking First** | Good prompts come from clear thinking. Clarify the problem before writing the prompt. |
| 4 | **Scaffolding &gt; Model** | System architecture matters more than which model you use. |
| 5 | **Deterministic Infrastructure** | AI is probabilistic; your infrastructure shouldn&#039;t be. Use templates and patterns. |
| 6 | **Code Before Prompts** | If you can solve it with a bash script, don&#039;t use AI. |
| 7 | **Spec / Test / Evals First** | Write specifications and tests before building. Measure if the system works. |
| 8 | **UNIX Philosophy** | Do one thing well. Make tools composable. Use text interfaces. |
| 9 | **ENG / SRE Principles** | Treat AI infrastructure like production software: version control, automation, monitoring. |
| 10 | **CLI as Interface** | Command-line interfaces are faster, more scriptable, and more reliable than GUIs. |
| 11 | **Goal ‚Üí Code ‚Üí CLI ‚Üí Prompts ‚Üí Agents** | The decision hierarchy: clarify goal, then code, then CLI, then prompts, then agents. |
| 12 | **Skill Management** | Modular capabilities that route intelligently based on context. |
| 13 | **Memory System** | Everything worth knowing gets captured. History feeds future context. |
| 14 | **Agent Personalities** | Different work needs different approaches. Specialized agents with unique voices. |
| 15 | **Science as Meta-Loop** | Hypothesis ‚Üí Experiment ‚Üí Measure ‚Üí Iterate. |
| 16 | **Permission to Fail** | Explicit permission to say &quot;I don&#039;t know&quot; prevents hallucinations. |

---

## PAI Primitives

While the Principles describe the *philosophy* of PAI, the Primitives are the *architecture*‚Äîthe core systems that make everything work.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-unique-components-diagram.png&quot; alt=&quot;PAI Primitives - A system that knows you, not a tool harness&quot; width=&quot;800&quot;&gt;
&lt;/p&gt;

These primitives work together to create the experience of working with a system that understands and knows you‚Äîas opposed to a tool harness that just executes commands.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-1-assistant-vs-agent.png&quot; alt=&quot;Assistant vs Agent-Based Interaction&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Assistant vs. Agent-Based AI Interaction

PAI treats AI as a [persistent assistant, friend, coach, and mentor](https://danielmiessler.com/blog/personal-ai-maturity-model) rather than a stateless agent that runs tasks. An assistant knows your goals, remembers your preferences, and improves over time. An agent executes commands and forgets.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-primitive-telos.png&quot; alt=&quot;TELOS - Deep Goal Understanding&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### TELOS (Deep Goal Understanding)

10 files that capture who you are: MISSION.md, GOALS.md, PROJECTS.md, BELIEFS.md, MODELS.md, STRATEGIES.md, NARRATIVES.md, LEARNED.md, CHALLENGES.md, IDEAS.md. Your DA knows what you&#039;re working toward because it&#039;s all documented.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-primitive-user-system-separation.png&quot; alt=&quot;User/System Separation&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### User/System Separation

Your customizations live in USER/. PAI infrastructure lives in SYSTEM/. When PAI upgrades, your files are untouched. Portable identity, upgrade-safe.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-primitive-customization.png&quot; alt=&quot;Granular Customization&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Granular Customization

Six layers of customization: Identity (name, voice, personality), Preferences (tech stack, tools), Workflows (how skills execute), Skills (what capabilities exist), Hooks (how events are handled), and Memory (what gets captured). Start with defaults, customize when needed.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-2-skill-system.png&quot; alt=&quot;Skill System&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Skill System

Highly focused on consistent results. It has a structure that puts *deterministic outcomes first* by going from CODE -&gt; CLI-BASED-TOOL -&gt; PROMPT -&gt; SKILL instead of a haphazard structure.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-3-memory-system.png&quot; alt=&quot;Memory System&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Memory System

Focused on continuous learning. Every interaction generates signals‚Äîratings, sentiment, successes, failures‚Äîthat feed back into improving the system. Three-tier architecture (hot/warm/cold) with phase-based learning directories.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-6-hook-system.png&quot; alt=&quot;Hook System&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Hook System

Responds to lifecycle events‚Äîsession start, tool use, task completion, and more. 8 event types enable voice notifications, automatic context loading, session capture, security validation, and observability.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-5-security-system.png&quot; alt=&quot;Security System&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Security System

Defines system and user-level security policies by default. You don&#039;t have to run with `--dangerously-skip-permissions` to have an uninterrupted experience. PAI&#039;s security hooks validate commands before execution, blocking dangerous operations while allowing normal workflows to proceed smoothly.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-4-ai-installation.png&quot; alt=&quot;AI-Based Installation&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### AI-Based Installation

Your AI assistant reads the packs, understands your system, and installs everything for you. No manual configuration, no guessing‚Äîthe AI handles it.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-8-notification-system.png&quot; alt=&quot;Notification System&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Notification System

Keeps you informed without being intrusive. Push notifications via ntfy for mobile alerts, Discord integration for team updates, and duration-aware routing that escalates for long-running tasks. Fire-and-forget design means notifications never block your workflow.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-9-voice-system.png&quot; alt=&quot;Voice System&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Voice System

Powered by ElevenLabs TTS. Hear task completions, session summaries, and important updates spoken aloud. Prosody enhancement makes speech sound natural. Your AI has a voice.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./images/pai-component-7-terminal-ui.png&quot; alt=&quot;Terminal-Based UI&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

### Terminal-Based UI

Rich tab titles and pane management. Dynamic status lines show learning signals, context usage, and current task state. Your terminal is a command center.

---

## üöÄ Installation

&gt; [!CAUTION]
&gt; **Project in Active Development** ‚Äî PAI is evolving rapidly. Expect breaking changes, restructuring, and frequent updates. We are working on stable and development branches, but currently it&#039;s all combined.

### Which Install Path Should I Use?

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Do you want a complete, working PAI system right now?          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ     YES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Option 1: Full Release Install              ‚îÇ
‚îÇ                     (Complete .claude/ directory, ~5 min)       ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ     NO, I want to customize or learn the system                 ‚îÇ
‚îÇ         ‚îÇ                                                       ‚îÇ
‚îÇ         ‚îú‚îÄ‚îÄ‚ñ∫ Option 2: Bundle + Packs (Build it yourself)       ‚îÇ
‚îÇ         ‚îÇ    (Skeleton structure, then install packs manually)  ‚îÇ
‚îÇ         ‚îÇ                                                       ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚ñ∫ Option 3: Individual Packs (Cherry-pick)           ‚îÇ
‚îÇ              (Install only specific capabilities you need)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Option 1: Full Release Install (Recommended)

&gt; **This is the fastest path to a working PAI system.** You get a complete, pre-configured `.claude/` directory with all infrastructure packs already installed.

```bash
# Clone the repo
git clone https://github.com/danielmiessler/PAI.git
cd PAI/Releases/v2.5

# Back up your existing Claude Code configuration (if any)
[ -d ~/.claude ] &amp;&amp; mv ~/.claude ~/.claude-backup-$(date +%Y%m%d)

# Copy the complete PAI installation
cp -r .claude ~/

# Run the configuration wizard
cd ~/.claude &amp;&amp; bun run INSTALL.ts
```

**The wizard will:**
- Ask for your name, DA name, and timezone
- Configure environment variables (works with both bash and zsh)
- Set up voice preferences (optional)
- Verify the installation

**After installation:** Restart Claude Code to activate hooks.

[**Full Release documentation ‚Üí**](Releases/v2.5/README.md)

---

### Option 2: Bundle + Manual Pack Installation

&gt; **For users who want to understand the system** as they build it, or need a customized setup.

&gt; [!WARNING]
&gt; The Bundle wizard creates a **skeleton directory structure only**. You must then install each pack manually in the correct order for a working system.

```bash
# Clone the repo
git clone https://github.com/danielmiessler/PAI.git
cd PAI/Bundles/Official

# Run the interactive wizard (creates skeleton structure)
bun run install.ts
```

**After the wizard completes, you MUST install packs in this order:**

| Order | Pack | Command |
|-------|------|---------|
| 1 | pai-hook-system | &quot;Install the pack at PAI/Packs/pai-hook-system/&quot; |
| 2 | pai-core-install | &quot;Install the pack at PAI/Packs/pai-core-install/&quot; |
| 3 | pai-statusline | &quot;Install the pack at PAI/Packs/pai-statusline/&quot; |
| 4+ | Any skill packs | Install as needed |

[**Bundle documentation ‚Üí**](Bundles/Official/README.md)

---

### Option 3: Individual Pack Installation

Install individual packs by giving them to your DA:

1. **Browse packs** - Find a pack you want in [Packs/](Packs/)
2. **Give it to your DA** - Provide the pack directory path
3. **Ask your DA to install it:**

```
Install this pack into my system. Use PAI_DIR=&quot;~/.claude&quot;
and DA=&quot;MyAI&quot;. Set up the hooks, save the code, and verify it works.
```

### Option 4: Browse and Cherry-Pick

Packs are self-contained. You can:
- Read the code directly in the pack
- Copy specific functions or workflows
- Adapt the approach to your own system
- Use it as reference documentation

**No forced structure. No mandatory setup. Take what&#039;s useful, leave the rest.**

---

## üì¶ Packs

PAI capabilities are distributed as **Packs**‚Äîse

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[chartdb/chartdb]]></title>
            <link>https://github.com/chartdb/chartdb</link>
            <guid>https://github.com/chartdb/chartdb</guid>
            <pubDate>Sun, 15 Feb 2026 00:06:52 GMT</pubDate>
            <description><![CDATA[Database diagrams editor that allows you to visualize and design your DB with a single query.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/chartdb/chartdb">chartdb/chartdb</a></h1>
            <p>Database diagrams editor that allows you to visualize and design your DB with a single query.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,224</p>
            <p>Forks: 1,258</p>
            <p>Stars today: 61 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://chartdb.io#gh-light-mode-only&quot;&gt;
    &lt;img src=&quot;https://github.com/chartdb/chartdb/blob/main/src/assets/logo-light.png&quot; width=&quot;400&quot; height=&quot;70&quot; alt=&quot;ChartDB&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://chartdb.io##gh-dark-mode-only&quot;&gt;
    &lt;img src=&quot;https://github.com/chartdb/chartdb/blob/main/src/assets/logo-dark.png&quot; width=&quot;400&quot; height=&quot;70&quot; alt=&quot;ChartDB&quot;&gt;
  &lt;/a&gt;
  &lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Open-source database diagrams editor&lt;/b&gt; &lt;br /&gt;
  &lt;b&gt;No installations ‚Ä¢ No Database password required.&lt;/b&gt; &lt;br /&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.gg/QeFwyWSKwC&quot;&gt;Community&lt;/a&gt;  &amp;bull;
  &lt;a href=&quot;https://www.chartdb.io?ref=github_readme&quot;&gt;Website&lt;/a&gt;  &amp;bull;
  &lt;a href=&quot;https://chartdb.io/templates?ref=github_readme&quot;&gt;Examples&lt;/a&gt;  &amp;bull;
  &lt;a href=&quot;https://app.chartdb.io?ref=github_readme&quot;&gt;Demo&lt;/a&gt;
&lt;/h3&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/chartdb/chartdb?tab=AGPL-3.0-1-ov-file#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/chartdb/chartdb?color=blue&quot; alt=&quot;ChartDB is released under the AGPL license.&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/chartdb/chartdb/blob/main/CONTRIBUTING.md&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/PRs-Welcome-brightgreen&quot; alt=&quot;PRs welcome!&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/QeFwyWSKwC&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1277047413705670678?color=5865F2&amp;label=Discord&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Discord community channel&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://x.com/intent/follow?screen_name=jonathanfishner&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/twitter/follow/jonathanfishner?style=social&quot;/&gt;
  &lt;/a&gt;

&lt;/h4&gt;

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&#039;700px&#039; src=&quot;./public/chartdb.png&quot;&gt;
&lt;/p&gt;

### üéâ ChartDB

ChartDB is a powerful, web-based database diagramming editor.
Instantly visualize your database schema with a single **&quot;Smart Query.&quot;** Customize diagrams, export SQL scripts, and access all features‚Äîno account required. Experience seamless database design here.

**What it does**:

- **Instant Schema Import**
  Run a single query to instantly retrieve your database schema as JSON. This makes it incredibly fast to visualize your database schema, whether for documentation, team discussions, or simply understanding your data better.

- **AI-Powered Export for Easy Migration**
  Our AI-driven export feature allows you to generate the DDL script in the dialect of your choice. Whether you&#039;re migrating from MySQL to PostgreSQL or from SQLite to MariaDB, ChartDB simplifies the process by providing the necessary scripts tailored to your target database.
- **Interactive Editing**
  Fine-tune your database schema using our intuitive editor. Easily make adjustments or annotations to better visualize complex structures.

### Status

ChartDB is currently in Public Beta. Star and watch this repository to get notified of updates.

### Supported Databases

- ‚úÖ PostgreSQL (&lt;img src=&quot;./src/assets/postgresql_logo_2.png&quot; width=&quot;15&quot;/&gt; + &lt;img src=&quot;./src/assets/supabase.png&quot; alt=&quot;Supabase&quot; width=&quot;15&quot;/&gt; + &lt;img src=&quot;./src/assets/timescale.png&quot; alt=&quot;Timescale&quot; width=&quot;15&quot;/&gt; )
- ‚úÖ MySQL
- ‚úÖ SQL Server
- ‚úÖ MariaDB
- ‚úÖ SQLite (&lt;img src=&quot;./src/assets/sqlite_logo_2.png&quot; width=&quot;15&quot;/&gt; + &lt;img src=&quot;./src/assets/cloudflare_d1.png&quot; alt=&quot;Cloudflare D1&quot; width=&quot;15&quot;/&gt; Cloudflare D1)
- ‚úÖ CockroachDB
- ‚úÖ ClickHouse

## Getting Started

Use the [cloud version](https://app.chartdb.io?ref=github_readme_2) or deploy locally:

### How To Use

```bash
npm install
npm run dev
```

### Build

```bash
npm install
npm run build
```

Or like this if you want to have AI capabilities:

```bash
npm install
VITE_OPENAI_API_KEY=&lt;YOUR_OPEN_AI_KEY&gt; npm run build
```

### Run the Docker Container

```bash
docker run -e OPENAI_API_KEY=&lt;YOUR_OPEN_AI_KEY&gt; -p 8080:80 ghcr.io/chartdb/chartdb:latest
```

#### Build and Run locally

```bash
docker build -t chartdb .
docker run -e OPENAI_API_KEY=&lt;YOUR_OPEN_AI_KEY&gt; -p 8080:80 chartdb
```

#### Using Custom Inference Server

```bash
# Build
docker build \
  --build-arg VITE_OPENAI_API_ENDPOINT=&lt;YOUR_ENDPOINT&gt; \
  --build-arg VITE_LLM_MODEL_NAME=&lt;YOUR_MODEL_NAME&gt; \
  -t chartdb .

# Run
docker run \
  -e OPENAI_API_ENDPOINT=&lt;YOUR_ENDPOINT&gt; \
  -e LLM_MODEL_NAME=&lt;YOUR_MODEL_NAME&gt; \
  -p 8080:80 chartdb
```

&gt; **Privacy Note:** ChartDB includes privacy-focused analytics via Fathom Analytics. You can disable this by adding `-e DISABLE_ANALYTICS=true` to the run command or `--build-arg VITE_DISABLE_ANALYTICS=true` when building.

&gt; **Note:** You must configure either Option 1 (OpenAI API key) OR Option 2 (Custom endpoint and model name) for AI capabilities to work. Do not mix the two options.

Open your browser and navigate to `http://localhost:8080`.

Example configuration for a local vLLM server:

```bash
VITE_OPENAI_API_ENDPOINT=http://localhost:8000/v1
VITE_LLM_MODEL_NAME=Qwen/Qwen2.5-32B-Instruct-AWQ
```

## Try it on our website

1. Go to [ChartDB.io](https://chartdb.io?ref=github_readme_2)
2. Click &quot;Go to app&quot;
3. Choose the database that you are using.
4. Take the magic query and run it in your database.
5. Copy and paste the resulting JSON set into ChartDB.
6. Enjoy Viewing &amp; Editing!

## üíö Community &amp; Support

- [Discord](https://discord.gg/QeFwyWSKwC) (For live discussion with the community and the ChartDB team)
- [GitHub Issues](https://github.com/chartdb/chartdb/issues) (For any bugs and errors you encounter using ChartDB)
- [Twitter](https://x.com/intent/follow?screen_name=jonathanfishner) (Get news fast)

## Contributing

We welcome community contributions, big or small, and are here to guide you along
the way. Message us in the [ChartDB Community Discord](https://discord.gg/QeFwyWSKwC).

For more information on how to contribute, please see our
[Contributing Guide](/CONTRIBUTING.md).

This project is released with a [Contributor Code of Conduct](/CODE_OF_CONDUCT.md).
By participating in this project, you agree to follow its terms.

Thank you for helping us make ChartDB better for everyone :heart:.

## License

ChartDB is licensed under the [GNU Affero General Public License v3.0](LICENSE)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[openclaw/openclaw]]></title>
            <link>https://github.com/openclaw/openclaw</link>
            <guid>https://github.com/openclaw/openclaw</guid>
            <pubDate>Sun, 15 Feb 2026 00:06:51 GMT</pubDate>
            <description><![CDATA[Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openclaw/openclaw">openclaw/openclaw</a></h1>
            <p>Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û</p>
            <p>Language: TypeScript</p>
            <p>Stars: 194,370</p>
            <p>Forks: 33,507</p>
            <p>Stars today: 2,758 stars today</p>
            <h2>README</h2><pre># ü¶û OpenClaw ‚Äî Personal AI Assistant

&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text-dark.png&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text.png&quot; alt=&quot;OpenClaw&quot; width=&quot;500&quot;&gt;
    &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;EXFOLIATE! EXFOLIATE!&lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/openclaw/openclaw/actions/workflows/ci.yml?branch=main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/openclaw/openclaw/ci.yml?branch=main&amp;style=for-the-badge&quot; alt=&quot;CI status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/openclaw/openclaw/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/openclaw/openclaw?include_prereleases&amp;style=for-the-badge&quot; alt=&quot;GitHub release&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/clawd&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1456350064065904867?label=Discord&amp;logo=discord&amp;logoColor=white&amp;color=5865F2&amp;style=for-the-badge&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge&quot; alt=&quot;MIT License&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

**OpenClaw** is a _personal AI assistant_ you run on your own devices.
It answers you on the channels you already use (WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, WebChat), plus extension channels like BlueBubbles, Matrix, Zalo, and Zalo Personal. It can speak and listen on macOS/iOS/Android, and can render a live Canvas you control. The Gateway is just the control plane ‚Äî the product is the assistant.

If you want a personal, single-user assistant that feels local, fast, and always-on, this is it.

[Website](https://openclaw.ai) ¬∑ [Docs](https://docs.openclaw.ai) ¬∑ [DeepWiki](https://deepwiki.com/openclaw/openclaw) ¬∑ [Getting Started](https://docs.openclaw.ai/start/getting-started) ¬∑ [Updating](https://docs.openclaw.ai/install/updating) ¬∑ [Showcase](https://docs.openclaw.ai/start/showcase) ¬∑ [FAQ](https://docs.openclaw.ai/start/faq) ¬∑ [Wizard](https://docs.openclaw.ai/start/wizard) ¬∑ [Nix](https://github.com/openclaw/nix-openclaw) ¬∑ [Docker](https://docs.openclaw.ai/install/docker) ¬∑ [Discord](https://discord.gg/clawd)

Preferred setup: run the onboarding wizard (`openclaw onboard`) in your terminal.
The wizard guides you step by step through setting up the gateway, workspace, channels, and skills. The CLI wizard is the recommended path and works on **macOS, Linux, and Windows (via WSL2; strongly recommended)**.
Works with npm, pnpm, or bun.
New install? Start here: [Getting started](https://docs.openclaw.ai/start/getting-started)

**Subscriptions (OAuth):**

- **[Anthropic](https://www.anthropic.com/)** (Claude Pro/Max)
- **[OpenAI](https://openai.com/)** (ChatGPT/Codex)

Model note: while any model is supported, I strongly recommend **Anthropic Pro/Max (100/200) + Opus 4.6** for long‚Äëcontext strength and better prompt‚Äëinjection resistance. See [Onboarding](https://docs.openclaw.ai/start/onboarding).

## Models (selection + auth)

- Models config + CLI: [Models](https://docs.openclaw.ai/concepts/models)
- Auth profile rotation (OAuth vs API keys) + fallbacks: [Model failover](https://docs.openclaw.ai/concepts/model-failover)

## Install (recommended)

Runtime: **Node ‚â•22**.

```bash
npm install -g openclaw@latest
# or: pnpm add -g openclaw@latest

openclaw onboard --install-daemon
```

The wizard installs the Gateway daemon (launchd/systemd user service) so it stays running.

## Quick start (TL;DR)

Runtime: **Node ‚â•22**.

Full beginner guide (auth, pairing, channels): [Getting started](https://docs.openclaw.ai/start/getting-started)

```bash
openclaw onboard --install-daemon

openclaw gateway --port 18789 --verbose

# Send a message
openclaw message send --to +1234567890 --message &quot;Hello from OpenClaw&quot;

# Talk to the assistant (optionally deliver back to any connected channel: WhatsApp/Telegram/Slack/Discord/Google Chat/Signal/iMessage/BlueBubbles/Microsoft Teams/Matrix/Zalo/Zalo Personal/WebChat)
openclaw agent --message &quot;Ship checklist&quot; --thinking high
```

Upgrading? [Updating guide](https://docs.openclaw.ai/install/updating) (and run `openclaw doctor`).

## Development channels

- **stable**: tagged releases (`vYYYY.M.D` or `vYYYY.M.D-&lt;patch&gt;`), npm dist-tag `latest`.
- **beta**: prerelease tags (`vYYYY.M.D-beta.N`), npm dist-tag `beta` (macOS app may be missing).
- **dev**: moving head of `main`, npm dist-tag `dev` (when published).

Switch channels (git + npm): `openclaw update --channel stable|beta|dev`.
Details: [Development channels](https://docs.openclaw.ai/install/development-channels).

## From source (development)

Prefer `pnpm` for builds from source. Bun is optional for running TypeScript directly.

```bash
git clone https://github.com/openclaw/openclaw.git
cd openclaw

pnpm install
pnpm ui:build # auto-installs UI deps on first run
pnpm build

pnpm openclaw onboard --install-daemon

# Dev loop (auto-reload on TS changes)
pnpm gateway:watch
```

Note: `pnpm openclaw ...` runs TypeScript directly (via `tsx`). `pnpm build` produces `dist/` for running via Node / the packaged `openclaw` binary.

## Security defaults (DM access)

OpenClaw connects to real messaging surfaces. Treat inbound DMs as **untrusted input**.

Full security guide: [Security](https://docs.openclaw.ai/gateway/security)

Default behavior on Telegram/WhatsApp/Signal/iMessage/Microsoft Teams/Discord/Google Chat/Slack:

- **DM pairing** (`dmPolicy=&quot;pairing&quot;` / `channels.discord.dm.policy=&quot;pairing&quot;` / `channels.slack.dm.policy=&quot;pairing&quot;`): unknown senders receive a short pairing code and the bot does not process their message.
- Approve with: `openclaw pairing approve &lt;channel&gt; &lt;code&gt;` (then the sender is added to a local allowlist store).
- Public inbound DMs require an explicit opt-in: set `dmPolicy=&quot;open&quot;` and include `&quot;*&quot;` in the channel allowlist (`allowFrom` / `channels.discord.dm.allowFrom` / `channels.slack.dm.allowFrom`).

Run `openclaw doctor` to surface risky/misconfigured DM policies.

## Highlights

- **[Local-first Gateway](https://docs.openclaw.ai/gateway)** ‚Äî single control plane for sessions, channels, tools, and events.
- **[Multi-channel inbox](https://docs.openclaw.ai/channels)** ‚Äî WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, BlueBubbles (iMessage), iMessage (legacy), Microsoft Teams, Matrix, Zalo, Zalo Personal, WebChat, macOS, iOS/Android.
- **[Multi-agent routing](https://docs.openclaw.ai/gateway/configuration)** ‚Äî route inbound channels/accounts/peers to isolated agents (workspaces + per-agent sessions).
- **[Voice Wake](https://docs.openclaw.ai/nodes/voicewake) + [Talk Mode](https://docs.openclaw.ai/nodes/talk)** ‚Äî always-on speech for macOS/iOS/Android with ElevenLabs.
- **[Live Canvas](https://docs.openclaw.ai/platforms/mac/canvas)** ‚Äî agent-driven visual workspace with [A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui).
- **[First-class tools](https://docs.openclaw.ai/tools)** ‚Äî browser, canvas, nodes, cron, sessions, and Discord/Slack actions.
- **[Companion apps](https://docs.openclaw.ai/platforms/macos)** ‚Äî macOS menu bar app + iOS/Android [nodes](https://docs.openclaw.ai/nodes).
- **[Onboarding](https://docs.openclaw.ai/start/wizard) + [skills](https://docs.openclaw.ai/tools/skills)** ‚Äî wizard-driven setup with bundled/managed/workspace skills.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=openclaw/openclaw&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#openclaw/openclaw&amp;type=date&amp;legend=top-left)

## Everything we built so far

### Core platform

- [Gateway WS control plane](https://docs.openclaw.ai/gateway) with sessions, presence, config, cron, webhooks, [Control UI](https://docs.openclaw.ai/web), and [Canvas host](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui).
- [CLI surface](https://docs.openclaw.ai/tools/agent-send): gateway, agent, send, [wizard](https://docs.openclaw.ai/start/wizard), and [doctor](https://docs.openclaw.ai/gateway/doctor).
- [Pi agent runtime](https://docs.openclaw.ai/concepts/agent) in RPC mode with tool streaming and block streaming.
- [Session model](https://docs.openclaw.ai/concepts/session): `main` for direct chats, group isolation, activation modes, queue modes, reply-back. Group rules: [Groups](https://docs.openclaw.ai/concepts/groups).
- [Media pipeline](https://docs.openclaw.ai/nodes/images): images/audio/video, transcription hooks, size caps, temp file lifecycle. Audio details: [Audio](https://docs.openclaw.ai/nodes/audio).

### Channels

- [Channels](https://docs.openclaw.ai/channels): [WhatsApp](https://docs.openclaw.ai/channels/whatsapp) (Baileys), [Telegram](https://docs.openclaw.ai/channels/telegram) (grammY), [Slack](https://docs.openclaw.ai/channels/slack) (Bolt), [Discord](https://docs.openclaw.ai/channels/discord) (discord.js), [Google Chat](https://docs.openclaw.ai/channels/googlechat) (Chat API), [Signal](https://docs.openclaw.ai/channels/signal) (signal-cli), [BlueBubbles](https://docs.openclaw.ai/channels/bluebubbles) (iMessage, recommended), [iMessage](https://docs.openclaw.ai/channels/imessage) (legacy imsg), [Microsoft Teams](https://docs.openclaw.ai/channels/msteams) (extension), [Matrix](https://docs.openclaw.ai/channels/matrix) (extension), [Zalo](https://docs.openclaw.ai/channels/zalo) (extension), [Zalo Personal](https://docs.openclaw.ai/channels/zalouser) (extension), [WebChat](https://docs.openclaw.ai/web/webchat).
- [Group routing](https://docs.openclaw.ai/concepts/group-messages): mention gating, reply tags, per-channel chunking and routing. Channel rules: [Channels](https://docs.openclaw.ai/channels).

### Apps + nodes

- [macOS app](https://docs.openclaw.ai/platforms/macos): menu bar control plane, [Voice Wake](https://docs.openclaw.ai/nodes/voicewake)/PTT, [Talk Mode](https://docs.openclaw.ai/nodes/talk) overlay, [WebChat](https://docs.openclaw.ai/web/webchat), debug tools, [remote gateway](https://docs.openclaw.ai/gateway/remote) control.
- [iOS node](https://docs.openclaw.ai/platforms/ios): [Canvas](https://docs.openclaw.ai/platforms/mac/canvas), [Voice Wake](https://docs.openclaw.ai/nodes/voicewake), [Talk Mode](https://docs.openclaw.ai/nodes/talk), camera, screen recording, Bonjour pairing.
- [Android node](https://docs.openclaw.ai/platforms/android): [Canvas](https://docs.openclaw.ai/platforms/mac/canvas), [Talk Mode](https://docs.openclaw.ai/nodes/talk), camera, screen recording, optional SMS.
- [macOS node mode](https://docs.openclaw.ai/nodes): system.run/notify + canvas/camera exposure.

### Tools + automation

- [Browser control](https://docs.openclaw.ai/tools/browser): dedicated openclaw Chrome/Chromium, snapshots, actions, uploads, profiles.
- [Canvas](https://docs.openclaw.ai/platforms/mac/canvas): [A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui) push/reset, eval, snapshot.
- [Nodes](https://docs.openclaw.ai/nodes): camera snap/clip, screen record, [location.get](https://docs.openclaw.ai/nodes/location-command), notifications.
- [Cron + wakeups](https://docs.openclaw.ai/automation/cron-jobs); [webhooks](https://docs.openclaw.ai/automation/webhook); [Gmail Pub/Sub](https://docs.openclaw.ai/automation/gmail-pubsub).
- [Skills platform](https://docs.openclaw.ai/tools/skills): bundled, managed, and workspace skills with install gating + UI.

### Runtime + safety

- [Channel routing](https://docs.openclaw.ai/concepts/channel-routing), [retry policy](https://docs.openclaw.ai/concepts/retry), and [streaming/chunking](https://docs.openclaw.ai/concepts/streaming).
- [Presence](https://docs.openclaw.ai/concepts/presence), [typing indicators](https://docs.openclaw.ai/concepts/typing-indicators), and [usage tracking](https://docs.openclaw.ai/concepts/usage-tracking).
- [Models](https://docs.openclaw.ai/concepts/models), [model failover](https://docs.openclaw.ai/concepts/model-failover), and [session pruning](https://docs.openclaw.ai/concepts/session-pruning).
- [Security](https://docs.openclaw.ai/gateway/security) and [troubleshooting](https://docs.openclaw.ai/channels/troubleshooting).

### Ops + packaging

- [Control UI](https://docs.openclaw.ai/web) + [WebChat](https://docs.openclaw.ai/web/webchat) served directly from the Gateway.
- [Tailscale Serve/Funnel](https://docs.openclaw.ai/gateway/tailscale) or [SSH tunnels](https://docs.openclaw.ai/gateway/remote) with token/password auth.
- [Nix mode](https://docs.openclaw.ai/install/nix) for declarative config; [Docker](https://docs.openclaw.ai/install/docker)-based installs.
- [Doctor](https://docs.openclaw.ai/gateway/doctor) migrations, [logging](https://docs.openclaw.ai/logging).

## How it works (short)

```
WhatsApp / Telegram / Slack / Discord / Google Chat / Signal / iMessage / BlueBubbles / Microsoft Teams / Matrix / Zalo / Zalo Personal / WebChat
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Gateway            ‚îÇ
‚îÇ       (control plane)         ‚îÇ
‚îÇ     ws://127.0.0.1:18789      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚îú‚îÄ Pi agent (RPC)
               ‚îú‚îÄ CLI (openclaw ‚Ä¶)
               ‚îú‚îÄ WebChat UI
               ‚îú‚îÄ macOS app
               ‚îî‚îÄ iOS / Android nodes
```

## Key subsystems

- **[Gateway WebSocket network](https://docs.openclaw.ai/concepts/architecture)** ‚Äî single WS control plane for clients, tools, and events (plus ops: [Gateway runbook](https://docs.openclaw.ai/gateway)).
- **[Tailscale exposure](https://docs.openclaw.ai/gateway/tailscale)** ‚Äî Serve/Funnel for the Gateway dashboard + WS (remote access: [Remote](https://docs.openclaw.ai/gateway/remote)).
- **[Browser control](https://docs.openclaw.ai/tools/browser)** ‚Äî openclaw‚Äëmanaged Chrome/Chromium with CDP control.
- **[Canvas + A2UI](https://docs.openclaw.ai/platforms/mac/canvas)** ‚Äî agent‚Äëdriven visual workspace (A2UI host: [Canvas/A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui)).
- **[Voice Wake](https://docs.openclaw.ai/nodes/voicewake) + [Talk Mode](https://docs.openclaw.ai/nodes/talk)** ‚Äî always‚Äëon speech and continuous conversation.
- **[Nodes](https://docs.openclaw.ai/nodes)** ‚Äî Canvas, camera snap/clip, screen record, `location.get`, notifications, plus macOS‚Äëonly `system.run`/`system.notify`.

## Tailscale access (Gateway dashboard)

OpenClaw can auto-configure Tailscale **Serve** (tailnet-only) or **Funnel** (public) while the Gateway stays bound to loopback. Configure `gateway.tailscale.mode`:

- `off`: no Tailscale automation (default).
- `serve`: tailnet-only HTTPS via `tailscale serve` (uses Tailscale identity headers by default).
- `funnel`: public HTTPS via `tailscale funnel` (requires shared password auth).

Notes:

- `gateway.bind` must stay `loopback` when Serve/Funnel is enabled (OpenClaw enforces this).
- Serve can be forced to require a password by setting `gateway.auth.mode: &quot;password&quot;` or `gateway.auth.allowTailscale: false`.
- Funnel refuses to start unless `gateway.auth.mode: &quot;password&quot;` is set.
- Optional: `gateway.tailscale.resetOnExit` to undo Serve/Funnel on shutdown.

Details: [Tailscale guide](https://docs.openclaw.ai/gateway/tailscale) ¬∑ [Web surfaces](https://docs.openclaw.ai/web)

## Remote Gateway (Linux is great)

It‚Äôs perfectly fine to run the Gateway on a small Linux instance. Clients (macOS app, CLI, WebChat) can connect over **Tailscale Serve/Funnel** or **SSH tunnels**, and you can still pair device nodes (macOS/iOS/Android) to execute device‚Äëlocal actions when needed.

- **Gateway host** runs the exec tool and channel connections by default.
- **Device nodes** run device‚Äëlocal actions (`system.run`, camera, screen recording, notifications) via `node.invoke`.
  In short: exec runs where the Gateway lives; device actions run where the device lives.

Details: [Remote access](https://docs.openclaw.ai/gateway/remote) ¬∑ [Nodes](https://docs.openclaw.ai/nodes) ¬∑ [Security](https://docs.openclaw.ai/gateway/security)

## macOS permissions via the Gateway protocol

The macOS app can run in **node mode** and advertises its capabilities + permission map over the Gateway WebSocket (`node.list` / `node.describe`). Clients can then execute local actions via `node.invoke`:

- `system.run` runs a local command and returns stdout/stderr/exit code; set `needsScreenRecording: true` to require screen-recording permission (otherwise you‚Äôll get `PERMISSION_MISSING`).
- `system.notify` posts a user notification and fails if notifications are denied.
- `canvas.*`, `camera.*`, `screen.record`, and `location.get` are also routed via `node.invoke` and follow TCC permission status.

Elevated bash (host permissions) is separate from macOS TCC:

- Use `/elevated on|off` to toggle per‚Äësession elevated access when enabled + allowlisted.
- Gateway persists the per‚Äësession toggle via `sessions.patch` (WS method) alongside `thinkingLevel`, `verboseLevel`, `model`, `sendPolicy`, and `groupActivation`.

Details: [Nodes](https://docs.openclaw.ai/nodes) ¬∑ [macOS app](https://docs.openclaw.ai/platforms/macos) ¬∑ [Gateway protocol](https://docs.openclaw.ai/concepts/architecture)

## Agent to Agent (sessions\_\* tools)

- Use these to coordinate work across sessions without jumping between chat surfaces.
- `sessions_list` ‚Äî discover active sessions (agents) and their metadata.
- `sessions_history` ‚Äî fetch transcript logs for a session.
- `sessions_send` ‚Äî message another session; optional reply‚Äëback ping‚Äëpong + announce step (`REPLY_SKIP`, `ANNOUNCE_SKIP`).

Details: [Session tools](https://docs.openclaw.ai/concepts/session-tool)

## Skills registry (ClawHub)

ClawHub is a minimal skill registry. With ClawHub enabled, the agent can search for skills automatically and pull in new ones as needed.

[ClawHub](https://clawhub.com)

## Chat commands

Send these in WhatsApp/Telegram/Slack/Google Chat/Microsoft Teams/WebChat (group commands are owner-only):

- `/status` ‚Äî compact session status (model + tokens, cost when available)
- `/new` or `/reset` ‚Äî reset the session
- `/compact` ‚Äî compact session context (summary)
- `/think &lt;level&gt;` ‚Äî off|minimal|low|medium|high|xhigh (GPT-5.2 + Codex models only)
- `/verbose on|off`
- `/usage off|tokens|full` ‚Äî per-response usage footer
- `/restart` ‚Äî restart the gateway (owner-only in groups)
- `/activation mention|always` ‚Äî group activation toggle (groups only)

## Apps (optional)

The Gateway alone delivers a great experience. All apps are optional and add extra features.

If you plan to build/run companion apps, follow the platform runbooks below.

### macOS (OpenClaw.app) (optional)

- Menu bar control for the Gateway and health.
- Voice Wake + push-to-talk overlay.
- WebChat + debug tools.
- Remote gateway control over SSH.

Note: signed builds required for macOS permissions to stick across rebuilds (see `docs/mac/permissions.md`).

### iOS node (optional)

- Pairs as a node via the Bridge.
- Voice trigger forwarding + Canvas surface.
- Controlled via `openclaw nodes ‚Ä¶`.

Runbook: [iOS connect](https://docs.openclaw.ai/platforms/ios).

### Android node (optional)

- Pairs via the same Bridge + pairing flow as iOS.
- Exposes Canvas, Camera, and Screen capture commands.
- Runbook: [Android connect](https://docs.openclaw.ai/platforms/android).

## Agent workspace + skills

- Workspace root: `~/.openclaw/workspace` (configurable via `agents.defaults.workspace`).
- Injected prompt files: `AGENTS.md`, `SOUL.md`, `TOOLS.md`.
- Skills: `~/.openclaw/workspace/skills/&lt;skill&gt;/SKILL.md`.

## Configuration

Minimal `~/.openclaw/openclaw.json` (model + defaults):

```json5
{
  agent: {
    model: &quot;anthropic/claude-opus-4-6&quot;,
  },
}
```

[Full configuration reference (all keys + examples).](https://docs.openclaw.ai/gateway/configuration)

## Security model (important)

- **Default:** tools run on the host for the **main** session, so the agent has full access when it‚Äôs just y

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[getmaxun/maxun]]></title>
            <link>https://github.com/getmaxun/maxun</link>
            <guid>https://github.com/getmaxun/maxun</guid>
            <pubDate>Sun, 15 Feb 2026 00:06:50 GMT</pubDate>
            <description><![CDATA[‚ú® The open-source no-code platform for web scraping, crawling, search and AI data extraction ‚Ä¢ Turn websites into structured APIs in minutes ‚ú®]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/getmaxun/maxun">getmaxun/maxun</a></h1>
            <p>‚ú® The open-source no-code platform for web scraping, crawling, search and AI data extraction ‚Ä¢ Turn websites into structured APIs in minutes ‚ú®</p>
            <p>Language: TypeScript</p>
            <p>Stars: 14,889</p>
            <p>Forks: 1,197</p>
            <p>Stars today: 51 stars today</p>
            <h2>README</h2><pre>&lt;h2 align=&quot;center&quot;&gt;
    &lt;div&gt;
        &lt;a href=&quot;https://www.maxun.dev/?ref=ghread&quot;&gt;
            &lt;img src=&quot;/src/assets/maxunlogo.png&quot; width=&quot;70&quot; /&gt;
            &lt;br&gt;
            Maxun
        &lt;/a&gt;
    &lt;/div&gt;
    Transform the Web into Structured Intelligence&lt;br&gt;
&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;
‚ú® Turn any website into clean, contextualized data pipelines for your AI applications ‚ú®

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://app.maxun.dev/?ref=ghread&quot;&gt;&lt;b&gt;Go To App&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://docs.maxun.dev/?ref=ghread&quot;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://www.maxun.dev/?ref=ghread&quot;&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://discord.gg/5GbPjBUkws&quot;&gt;&lt;b&gt;Discord&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://www.youtube.com/@MaxunOSS?ref=ghread&quot;&gt;&lt;b&gt;Watch Tutorials&lt;/b&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
&lt;a href=&quot;https://trendshift.io/repositories/12113&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12113&quot; alt=&quot;getmaxun%2Fmaxun | Trendshift&quot; style=&quot;width: 250px; height: 55px; margin-top: 10px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

## What is Maxun?

Maxun helps you transform websites into structured APIs, clean markdown for AI workflows, and production-ready data pipelines ‚Äî all in minutes.

### Ecosystem

1. **[Extract](https://docs.maxun.dev/category/extract)** ‚Äì Emulate real user behavior and collect structured data from any website.
   * **[Recorder Mode](https://docs.maxun.dev/robot/extract/robot-actions)** - Record your actions as you browse; Maxun turns them into a reusable extraction robot.
   * **[AI Mode](https://docs.maxun.dev/robot/extract/llm-extraction)** - Describe what you want in natural language and let LLM-powered extraction do the rest.

2. **[Scrape](https://docs.maxun.dev/robot/scrape/scrape-robots)** ‚Äì Convert full webpages into clean Markdown or HTML and capture screenshots.
3. **[Crawl](https://docs.maxun.dev/robot/crawl/crawl-introduction)** - Crawl entire websites and extract content from every relevant page, with full control over scope and discovery.
4. **[Search](https://docs.maxun.dev/robot/search/search-introduction)** - Run automated web searches to discover or scrape results, with support for time-based filters.
5. **[SDK](https://docs.maxun.dev/sdk/sdk-overview)** ‚Äì A complete developer toolkit for scraping, extraction, scheduling, and end-to-end data automation.

## How Does It Work?

Maxun robots are automated tools that help you collect data from websites without writing any code. Think of them as your personal web assistants that can navigate websites, extract information, and organize data just like you would manually - but faster and more efficiently.

There are four types of robots, each designed for a different job.

### 1. Extract
Extract emulates real user behavior and captures structured data.
- &lt;a href=&quot;/robot/extract/robot-actions&quot;&gt;Recorder Mode&lt;/a&gt; - Record your actions as you browse; Maxun turns them into a reusable extraction robot.
### Example: Extract 10 Property Listings from Airbnb

[https://github.com/user-attachments/assets/recorder-mode-demo-video](https://github.com/user-attachments/assets/c6baa75f-b950-482c-8d26-8a8b6c5382c3)
- &lt;a href=&quot;/robot/extract/llm-extraction&quot;&gt;AI Mode&lt;/a&gt; - Describe what you want in natural language and let LLM-powered extraction do the rest.
### Example: Extract Names, Rating &amp; Duration of Top 50 Movies from IMDb

https://github.com/user-attachments/assets/f714e860-58d6-44ed-bbcd-c9374b629384

Learn more &lt;a href=&quot;/category/extract&quot;&gt;here&lt;/a&gt;.

### 2. Scrape
Scrape converts full webpages into clean Markdown, HTML and can capture screenshots. Ideal for AI workflows, agents, and document processing. 

Learn more &lt;a href=&quot;https://docs.maxun.dev/robot/scrape/scrape-robots&quot;&gt;here&lt;/a&gt;.

### 3. Crawl
Crawl entire websites and extract content from every relevant page, with full control over scope and discovery.

Learn more &lt;a href=&quot;/robot/crawl/crawl-introduction&quot;&gt;here&lt;/a&gt;.

### 4. Search
Run automated web searches to discover or scrape results, with support for time-based filters.

Learn more &lt;a href=&quot;https://docs.maxun.dev/robot/search/search-introduction&quot;&gt;here&lt;/a&gt;.

## Quick Start

### Getting Started
The simplest &amp; fastest way to get started is to use the hosted version: https://app.maxun.dev. You can self-host if you prefer!

### Installation
Maxun can run locally with or without Docker
1. [Setup with Docker Compose](https://docs.maxun.dev/installation/docker)
2. [Setup without Docker](https://docs.maxun.dev/installation/local)
3. [Environment Variables](https://docs.maxun.dev/installation/environment_variables)
4. [SDK](https://github.com/getmaxun/node-sdk)

### Upgrading &amp; Self Hosting
1. [Self Host Maxun With Docker &amp; Portainer](https://docs.maxun.dev/self-host)
2. [Upgrade Maxun With Docker Compose Setup](https://docs.maxun.dev/installation/upgrade#upgrading-with-docker-compose)
3. [Upgrade Maxun Without Docker Compose Setup](https://docs.maxun.dev/installation/upgrade#upgrading-with-local-setup)

## Sponsors
&lt;table&gt;
  &lt;tr&gt;
  &lt;td width=&quot;229&quot;&gt;
      &lt;br/&gt;
      &lt;a href=&quot;https://www.testmu.ai/?utm_source=maxun&amp;utm_medium=sponsor&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://github.com/user-attachments/assets/6c96005b-85df-43e0-9b63-96aaca676c11&quot; /&gt;&lt;br/&gt;&lt;br/&gt;
        &lt;b&gt;TestMu AI&lt;/b&gt;
      &lt;/a&gt;
      &lt;br/&gt;
      &lt;sub&gt;The Native AI-Agentic Cloud Platform to Supercharge Quality Engineering. Test Intelligently and Ship Faster.
      &lt;/sub&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Features

- ‚ú® **Extract Data With No-Code** ‚Äì Point and click interface
- ‚ú® **LLM-Powered Extraction** ‚Äì Describe what you want; use LLMs to scrape structured data
- ‚ú® **Developer SDK** ‚Äì Programmatic extraction, scheduling, and robot management
- ‚ú® **Handle Pagination &amp; Scrolling** ‚Äì Automatic navigation
- ‚ú® **Run Robots On Schedules** ‚Äì Set it and forget it
- ‚ú® **Turn Websites to APIs** ‚Äì RESTful endpoints from any site
- ‚ú® **Turn Websites to Spreadsheets** ‚Äì Direct data export to Google Sheets &amp; Airtable
- ‚ú® **Adapt To Website Layout Changes** ‚Äì Auto-recovery from site updates
- ‚ú® **Extract Behind Login** ‚Äì Handle authentication seamlessly
- ‚ú® **Integrations** ‚Äì Connect with your favorite tools
- ‚ú® **MCP Support** ‚Äì Model Context Protocol integration
- ‚ú® **LLM-Ready Data** ‚Äì Clean Markdown for AI applications
- ‚ú® **Self-Hostable** ‚Äì Full control over your infrastructure
- ‚ú® **Open Source** ‚Äì Transparent and community-driven

## Demos
Maxun can be used for various use-cases, including lead generation, market research, content aggregation and more.
View demos here: https://www.maxun.dev/usecases

## Note
This project is in early stages of development. Your feedback is very important for us - we&#039;re actively working on improvements. &lt;/a&gt;

## License
&lt;p&gt;
This project is licensed under &lt;a href=&quot;./LICENSE&quot;&gt;AGPLv3&lt;/a&gt;.
&lt;/p&gt;

## Support Us
Star the repository, contribute if you love what we‚Äôre building, or [sponsor us](https://github.com/sponsors/amhsirak). 

## Contributors
Thank you to the combined efforts of everyone who contributes!

&lt;a href=&quot;https://github.com/getmaxun/maxun/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=getmaxun/maxun&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[backstage/backstage]]></title>
            <link>https://github.com/backstage/backstage</link>
            <guid>https://github.com/backstage/backstage</guid>
            <pubDate>Sun, 15 Feb 2026 00:06:49 GMT</pubDate>
            <description><![CDATA[Backstage is an open framework for building developer portals]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/backstage/backstage">backstage/backstage</a></h1>
            <p>Backstage is an open framework for building developer portals</p>
            <p>Language: TypeScript</p>
            <p>Stars: 32,599</p>
            <p>Forks: 7,090</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>[![headline](docs/assets/headline.png)](https://backstage.io/)

# [Backstage](https://backstage.io)

English \| [ÌïúÍµ≠Ïñ¥](README-ko_kr.md) \| [‰∏≠ÊñáÁâà](README-zh_Hans.md) \| [Fran√ßais](README-fr_FR.md)

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![CNCF Status](https://img.shields.io/badge/cncf%20status-incubation-blue.svg)](https://www.cncf.io/projects)
[![Discord](https://img.shields.io/discord/687207715902193673?logo=discord&amp;label=Discord&amp;color=5865F2&amp;logoColor=white)](https://discord.gg/backstage-687207715902193673)
![Code style](https://img.shields.io/badge/code_style-prettier-ff69b4.svg)
[![Codecov](https://img.shields.io/codecov/c/github/backstage/backstage)](https://codecov.io/gh/backstage/backstage)
[![](https://img.shields.io/github/v/release/backstage/backstage)](https://github.com/backstage/backstage/releases)
[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/7678/badge)](https://bestpractices.coreinfrastructure.org/projects/7678)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/backstage/backstage/badge)](https://securityscorecards.dev/viewer/?uri=github.com/backstage/backstage)

## What is Backstage?

[Backstage](https://backstage.io/) is an open source framework for building developer portals. Powered by a centralized software catalog, Backstage restores order to your microservices and infrastructure and enables your product teams to ship high-quality code quickly without compromising autonomy.

Backstage unifies all your infrastructure tooling, services, and documentation to create a streamlined development environment from end to end.

![software-catalog](docs/assets/header.png)

Out of the box, Backstage includes:

- [Backstage Software Catalog](https://backstage.io/docs/features/software-catalog/) for managing all your software such as microservices, libraries, data pipelines, websites, and ML models
- [Backstage Software Templates](https://backstage.io/docs/features/software-templates/) for quickly spinning up new projects and standardizing your tooling with your organization‚Äôs best practices
- [Backstage TechDocs](https://backstage.io/docs/features/techdocs/) for making it easy to create, maintain, find, and use technical documentation, using a &quot;docs like code&quot; approach
- Plus, a growing ecosystem of [open source plugins](https://github.com/backstage/backstage/tree/master/plugins) that further expand Backstage‚Äôs customizability and functionality

Backstage was created by Spotify but is now hosted by the [Cloud Native Computing Foundation (CNCF)](https://www.cncf.io) as an Incubation level project. For more information, see the [announcement](https://backstage.io/blog/2022/03/16/backstage-turns-two#out-of-the-sandbox-and-into-incubation).

## Project roadmap

For information about the detailed project roadmap including delivered milestones, see [the Roadmap](https://backstage.io/docs/overview/roadmap).

## Getting Started

To start using Backstage, see the [Getting Started documentation](https://backstage.io/docs/getting-started).

## Documentation

The documentation of Backstage includes:

- [Main documentation](https://backstage.io/docs)
- [Software Catalog](https://backstage.io/docs/features/software-catalog/)
- [Architecture](https://backstage.io/docs/overview/architecture-overview) ([Decisions](https://backstage.io/docs/architecture-decisions/))
- [Designing for Backstage](https://backstage.io/docs/dls/design)
- [Storybook - UI components](https://backstage.io/storybook)

## Community

To engage with our community, you can use the following resources:

- [Discord chatroom](https://discord.gg/backstage-687207715902193673) - Get support or discuss the project
- [Contributing to Backstage](https://github.com/backstage/backstage/blob/master/CONTRIBUTING.md) - Start here if you want to contribute
- [RFCs](https://github.com/backstage/backstage/labels/rfc) - Help shape the technical direction
- [FAQ](https://backstage.io/docs/faq) - Frequently Asked Questions
- [Code of Conduct](CODE_OF_CONDUCT.md) - This is how we roll
- [Adopters](ADOPTERS.md) - Companies already using Backstage
- [Blog](https://backstage.io/blog/) - Announcements and updates
- [Newsletter](https://spoti.fi/backstagenewsletter) - Subscribe to our email newsletter
- [Backstage Community Sessions](https://github.com/backstage/community) - Join monthly meetups and explore Backstage community
- Give us a star ‚≠êÔ∏è - If you are using Backstage or think it is an interesting project, we would love a star ‚ù§Ô∏è

## Governance

See the [GOVERNANCE.md](https://github.com/backstage/community/blob/main/GOVERNANCE.md) document in the [backstage/community](https://github.com/backstage/community) repository.

## License

Copyright 2020-2026 ¬© The Backstage Authors. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our Trademark Usage page: https://www.linuxfoundation.org/trademark-usage

Licensed under the Apache License, Version 2.0: http://www.apache.org/licenses/LICENSE-2.0

## Security

Please report sensitive security issues using Spotify&#039;s [bug-bounty program](https://hackerone.com/spotify) rather than GitHub.

For further details, see our complete [security release process](SECURITY.md).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[rybbit-io/rybbit]]></title>
            <link>https://github.com/rybbit-io/rybbit</link>
            <guid>https://github.com/rybbit-io/rybbit</guid>
            <pubDate>Sun, 15 Feb 2026 00:06:48 GMT</pubDate>
            <description><![CDATA[üê∏ Rybbit - open-source and privacy-friendly alternative to Google Analytics that is 10x more intuitive.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rybbit-io/rybbit">rybbit-io/rybbit</a></h1>
            <p>üê∏ Rybbit - open-source and privacy-friendly alternative to Google Analytics that is 10x more intuitive.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 11,343</p>
            <p>Forks: 580</p>
            <p>Stars today: 57 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/be982e50-8d59-471c-9fb7-e8982658a608&quot; height=&quot;100&quot;&gt;
    &lt;p align=&quot;center&quot;&gt;Open Source Web &amp; Product Analytics&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://rybbit.com&quot; target=&quot;_blank&quot;&gt;Website&lt;/a&gt; |
    &lt;a href=&quot;https://demo.rybbit.com/1&quot; target=&quot;_blank&quot;&gt;Demo&lt;/a&gt; |
    &lt;a href=&quot;https://rybbit.com/docs&quot; target=&quot;_blank&quot;&gt;Documentation&lt;/a&gt; |
    &lt;a href=&quot;https://discord.gg/DEhGb4hYBj&quot; target=&quot;_blank&quot;&gt;Discord&lt;/a&gt; |
    &lt;a href=&quot;https://github.com/rybbit-io/rybbit?tab=AGPL-3.0-1-ov-file&quot; target=&quot;_blank&quot;&gt;License (AGPL-3)&lt;/a&gt; |
    &lt;a href=&quot;https://github.com/rybbit-io/rybbit/blob/master/CONTRIBUTE.md&quot; target=&quot;_blank&quot;&gt;Contribute&lt;/a&gt;
&lt;/p&gt;

&lt;a href=&quot;https://rybbit.com/&quot; target=&quot;_blank&quot;&gt;Rybbit&lt;/a&gt; is the modern open source and privacy friendly alternative to Google Analytics. It takes only a couple minutes to setup and is super intuitive to use.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.producthunt.com/products/rybbit?embed=true&amp;utm_source=badge-top-post-badge&amp;utm_medium=badge&amp;utm_source=badge-rybbit&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=1028220&amp;theme=standard&amp;period=daily&quot; alt=&quot;Rybbit - Open Source Google Analytics Replacement | Product Hunt&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;&lt;a href=&quot;https://demo.rybbit.com/81&quot;&gt;üîç View Live Demo&lt;/a&gt;&lt;/strong&gt; - See Rybbit running on a real-life production site.
&lt;/p&gt;

&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 25 20‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/7988ba04-64ee-4410-9972-847d278efa2f&quot; /&gt;

&lt;hr&gt;

## üöÄ Getting Started

There are two ways to start using Rybbit:

| Option                                                   | Description                                                   |
| -------------------------------------------------------- | ------------------------------------------------------------- |
| **[Hosted Service](https://rybbit.com)**                 | Free tier available - the fastest way to get started          |
| **[Self-Hosting](https://rybbit.com/docs/self-hosting)** | Deploy and manage Rybbit on your own VPS for complete control |

üìö Explore our [documentation](https://rybbit.com/docs) to learn more about installation, configuration, and usage.

&lt;hr&gt;

## ‚ú® Key Features

- All key web analytics metrics including sessions, unique users, pageviews, bounce rate, session duration
- Session replays
- No cookies &amp; privacy friendly
- Customizable goals. retention, user journeys, and funnels dashboards
- Advanced filtering across 15+ dimensions
- Custom events with JSON properties
- 3 level location tracking (country -&gt; region -&gt; city) + advanced map visualizations
- Real time dashboard
- Support for organizations and unlimited number of sites

&lt;hr&gt;

## üìä Comparison

See how Rybbit compares to other analytics solutions:

| Feature                           | Rybbit | GA4        | Plausible  | Cloudflare |
| --------------------------------- | ------ | ---------- | ---------- | ---------- |
| **Open Source**                   | ‚úÖ     | ‚ùå         | ‚úÖ         | ‚ùå         |
| **Self-Hosting**                  | ‚úÖ     | ‚ùå         | ‚úÖ\*       | ‚ùå         |
| **Cookieless &amp; Privacy friendly** | ‚úÖ     | ‚ùå         | ‚úÖ         | ‚úÖ         |
| **Advanced Maps**                 | ‚úÖ     | ‚ùå         | ‚ùå         | ‚ùå         |
| **Advanced Filters**              | ‚úÖ     | ‚ö†Ô∏è Limited | ‚ö†Ô∏è Limited | ‚ùå         |
| **Web Vitals**                    | ‚úÖ\*\* | ‚ùå         | ‚ùå         | ‚ùå         |
| **Session Details**               | ‚úÖ     | ‚ùå         | ‚ùå         | ‚ùå         |
| **User Profiles**                 | ‚úÖ     | ‚ùå         | ‚ùå         | ‚ùå         |
| **Session Replays**               | ‚úÖ     | ‚ùå         | ‚ùå         | ‚ùå         |
| **Funnels**                       | ‚úÖ     | ‚úÖ         | ‚úÖ\*\*     | ‚ùå         |
| **User Journeys**                 | ‚úÖ     | ‚úÖ         | ‚ùå         | ‚ùå         |
| **Retention Analysis**            | ‚úÖ     | ‚úÖ         | ‚ùå         | ‚ùå         |
| **Goals &amp; Events**                | ‚úÖ     | ‚úÖ         | ‚úÖ         | ‚ùå         |
| **Real-time Dashboard**           | ‚úÖ     | ‚úÖ         | ‚úÖ         | ‚úÖ         |
| **Custom Events (JSON)**          | ‚úÖ     | ‚úÖ         | ‚ö†Ô∏è Limited | ‚ùå         |
| **Error Tracking**                | ‚úÖ     | ‚ùå         | ‚ùå         | ‚ùå         |
| **Public Dashboards**             | ‚úÖ     | ‚ùå         | ‚úÖ         | ‚ùå         |
| **Organizations**                 | ‚úÖ     | ‚úÖ         | ‚úÖ         | ‚úÖ         |
| **Free Tier**                     | ‚úÖ     | ‚úÖ         | ‚ùå         | ‚úÖ         |
| **Frog üê∏**                       | ‚úÖ     | ‚ùå         | ‚ùå         | ‚ùå         |

\* Plausible&#039;s Community Edition has very limited features compared to their cloud version

\*\* Only available on paid tiers

&lt;hr&gt;

## üìä Dashboard Preview

### Map

&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 27 12‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/52643121-4f4d-4bbe-9910-2516226bf421&quot; /&gt;
&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 30 39‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/153585d5-7ff6-43bb-8bf6-fecfbe240ef8&quot; /&gt;
&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 30 00‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/3873bc6b-9f79-4e9a-b083-0676a7d52b1d&quot; /&gt;
&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 30 23‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/04ceca1d-a4af-4f52-856c-f054deeb1023&quot; /&gt;

## Session Replay

&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 29 18‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/6906aef0-8ce0-41f9-9bbb-b175ef158df3&quot; /&gt;

### Journeys

&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 34 13‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/4cd465df-8f91-43bf-a121-647ae2c9e8e1&quot; /&gt;

### Funnels

&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 34 05‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/e3b083c2-4f18-4c8c-bc97-9491a6402439&quot; /&gt;

### Goals

&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 28 26‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/d34c5c00-1dec-4864-9115-bfa9e9811d60&quot; /&gt;

### Users

&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 28 54‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/f10c1bba-6658-4b6a-94a6-dcba351e4eea&quot; /&gt;

### Errors

&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 40 56‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/efd60f04-c203-45ea-981d-14f34ec2b1e1&quot; /&gt;

### Retention

&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 34 20‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/c56a31ac-7af5-419b-82a5-d3aedb68debc&quot; /&gt;

### Web Vitals (Cloud only)

&lt;img width=&quot;1299&quot; height=&quot;797&quot; alt=&quot;Screenshot 2025-10-16 at 7 28 01‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/d88b8be0-cd30-4dd6-a0e5-5446c890c0f9&quot; /&gt;

&lt;hr&gt;

## ‚≠ê Star History

[![Star History Chart](https://api.star-history.com/svg?repos=rybbit-io/rybbit&amp;type=Date)](https://www.star-history.com/#rybbit-io/rybbit&amp;Date)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>