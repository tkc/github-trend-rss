<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Thu, 17 Apr 2025 00:04:49 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[fuma-nama/fumadocs]]></title>
            <link>https://github.com/fuma-nama/fumadocs</link>
            <guid>https://github.com/fuma-nama/fumadocs</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[The beautiful docs framework with Next.js.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fuma-nama/fumadocs">fuma-nama/fumadocs</a></h1>
            <p>The beautiful docs framework with Next.js.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 4,883</p>
            <p>Forks: 268</p>
            <p>Stars today: 574 stars today</p>
            <h2>README</h2><pre>![banner](./apps/docs/public/banner.png)

The framework for building documentation websites in Next.js.

üìò Learn More: [Documentation](https://fumadocs.vercel.app).

## Compatibility

All packages are **ESM only**.

## Sticker

![logo](./documents/logo.png)

Welcome to print it out :D

## Contributions

Make sure to read the [Contributing Guide](/.github/contributing.md) before submitting a pull request.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[CapSoftware/Cap]]></title>
            <link>https://github.com/CapSoftware/Cap</link>
            <guid>https://github.com/CapSoftware/Cap</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[Open source Loom alternative. Beautiful, shareable screen recordings.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/CapSoftware/Cap">CapSoftware/Cap</a></h1>
            <p>Open source Loom alternative. Beautiful, shareable screen recordings.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,583</p>
            <p>Forks: 434</p>
            <p>Stars today: 74 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;p align=&quot;center&quot;&gt;
   &lt;img width=&quot;150&quot; height=&quot;150&quot; src=&quot;https://github.com/CapSoftware/Cap/blob/main/apps/desktop/src-tauri/icons/Square310x310Logo.png&quot; alt=&quot;Logo&quot;&gt;
  &lt;/p&gt;
	&lt;h1 align=&quot;center&quot;&gt;&lt;b&gt;Cap&lt;/b&gt;&lt;/h1&gt;
	&lt;p align=&quot;center&quot;&gt;
		The open source Loom alternative.
    &lt;br /&gt;
    &lt;a href=&quot;https://cap.so&quot;&gt;&lt;strong&gt;Cap.so ¬ª&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;b&gt;Downloads for &lt;/b&gt;
		&lt;a href=&quot;https://cap.so/download&quot;&gt;macOS &amp; Windows&lt;/a&gt;
    &lt;br /&gt;
  &lt;/p&gt;
&lt;/p&gt;
&lt;br/&gt;

[![Open Bounties](https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2FCapSoftware%2Fbounties%3Fstatus%3Dopen)](https://console.algora.io/org/CapSoftware/bounties?status=open)

Cap is the open source alternative to Loom. It&#039;s a video messaging tool that allows you to record, edit and share videos in seconds.

&lt;img src=&quot;https://raw.githubusercontent.com/CapSoftware/Cap/refs/heads/main/apps/web/public/landing-cover.png&quot;/&gt;

# Cap Self Hosting

We&#039;re working on a self-hosting guide for Cap. This will include one-click deployment buttons for Vercel and Render, as well as an option to self host with Docker. Join the &lt;a href=&quot;https://discord.gg/y8gdQ3WRN3&quot;&gt;Cap Discord&lt;/a&gt; if you want to help contribute to this particular project.

# Monorepo App Architecture

We use a combination of Rust, React (Next.js), TypeScript, Tauri, Drizzle (ORM), MySQL, TailwindCSS throughout this Turborepo powered monorepo.

### Apps:

- `desktop`: A [Tauri](https://tauri.app) (Rust) app, using [SolidStart](https://start.solidjs.com) on the frontend.
- `web`: A [Next.js](https://nextjs.org) web app.

### Packages:

- `ui`: A [React](https://reactjs.org) Shared component library.
- `utils`: A [React](https://reactjs.org) Shared utility library.
- `tsconfig`: Shared `tsconfig` configurations used throughout the monorepo.
- `database`: A [React](https://reactjs.org) and [Drizzle ORM](https://orm.drizzle.team/) Shared database library.
- `config`: `eslint` configurations (includes `eslint-config-next`, `eslint-config-prettier` other configs used throughout the monorepo).

# Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for more information. This guide is a work in progress, and is updated regularly as the app matures.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[aws-samples/generative-ai-use-cases]]></title>
            <link>https://github.com/aws-samples/generative-ai-use-cases</link>
            <guid>https://github.com/aws-samples/generative-ai-use-cases</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[Application implementation with business use cases for safely utilizing generative AI in business operations]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aws-samples/generative-ai-use-cases">aws-samples/generative-ai-use-cases</a></h1>
            <p>Application implementation with business use cases for safely utilizing generative AI in business operations</p>
            <p>Language: TypeScript</p>
            <p>Stars: 954</p>
            <p>Forks: 224</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;div markdown=&quot;1&quot; align=&quot;center&quot;&gt;
  &lt;h1&gt;Generative AI Use Cases (GenU)&lt;/h1&gt;

[![](https://img.shields.io/badge/Documentation-Latest-blue)](https://aws-samples.github.io/generative-ai-use-cases/index.html) [![](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/aws-samples/generative-ai-use-cases/blob/main/LICENSE) [![](https://github.com/aws-samples/generative-ai-use-cases/actions/workflows/node.js.yml/badge.svg)](https://github.com/aws-samples/generative-ai-use-cases/actions/workflows/node.js.yml) [![](https://github.com/aws-samples/generative-ai-use-cases/actions/workflows/browser-extension.yml/badge.svg)](https://github.com/aws-samples/generative-ai-use-cases/actions/workflows/browser-extension.yml)

English | [Êó•Êú¨Ë™û](./README_ja.md)

Application implementation with business use cases for safely utilizing generative AI in business operations

  &lt;img src=&quot;./docs/assets/images/sc_lp_en.png&quot; alt=&quot;Application implementation with business use cases for safely utilizing generative AI in business operations&quot; width=&quot;68%&quot;&gt;
&lt;/div&gt;

&gt; [!IMPORTANT]
&gt; GenU has supported multiple languages since v4.
&gt;
&gt; GenU „ÅØ v4 „Åã„ÇâÂ§öË®ÄË™ûÂØæÂøú„Åó„Åæ„Åó„Åü„ÄÇÊó•Êú¨Ë™û„Éâ„Ç≠„É•„É°„É≥„Éà„ÅØ[„Åì„Å°„Çâ](./README_ja.md)

## GenU Usage Patterns

Here we introduce GenU&#039;s features and options by usage pattern. For comprehensive deployment options, please refer to [this document](docs/en/DEPLOY_OPTION.md).

&gt; [!TIP]
&gt; Click on a usage pattern to see details

&lt;details markdown=&quot;1&quot;&gt;
  &lt;summary&gt;&lt;strong&gt;&lt;ins&gt;I want to experience generative AI use cases&lt;/ins&gt;&lt;/strong&gt;&lt;/summary&gt;

GenU provides a variety of standard use cases leveraging generative AI. These use cases can serve as seeds for ideas on how to utilize generative AI in business operations, or they can be directly applied to business as-is. We plan to continuously add more refined use cases in the future. If unnecessary, you can also [hide specific use cases](docs/en/DEPLOY_OPTION.md#hiding-specific-use-cases) with an option. Here are the use cases provided by default.

  &lt;br/&gt;
  &lt;br/&gt;
  &lt;table width=&quot;100%&quot;&gt;
    &lt;thead&gt;
      &lt;tr&gt;
        &lt;td width=&quot;20%&quot;&gt;Use Case&lt;/td&gt;
        &lt;td width=&quot;80%&quot;&gt;Description&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;Chat&lt;/td&gt;
        &lt;td&gt;You can interact with large language models (LLMs) in a chat format. The existence of platforms that allow direct dialogue with LLMs enables quick responses to specific and new use cases. It&#039;s also effective as a testing environment for prompt engineering.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Text Generation&lt;/td&gt;
        &lt;td&gt;Generating text in any context is one of the tasks LLMs excel at. It generates all kinds of text including articles, reports, and emails.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Summarization&lt;/td&gt;
        &lt;td&gt;LLMs are good at summarizing large amounts of text. Beyond simple summarization, they can also extract necessary information in a conversational format after being given text as context. For example, after reading a contract, you can ask questions like &quot;What are the conditions for XXX?&quot; or &quot;What is the amount for YYY?&quot;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Writing&lt;/td&gt;
        &lt;td&gt;LLMs can suggest improvements from a more objective perspective, considering not only typos but also the flow and content of the text. You can expect to improve quality by having the LLM objectively check points you might have missed before showing your work to others.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Translation&lt;/td&gt;
        &lt;td&gt;LLMs trained in multiple languages can perform translations. Beyond simple translation, they can incorporate various specified contextual information such as casualness and target audience into the translation.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Web Content Extraction&lt;/td&gt;
        &lt;td&gt;Extracts necessary information from web content such as blogs and documents. The LLM removes unnecessary information and formats it into well-structured text. Extracted content can be used in other use cases such as summarization and translation.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Image Generation&lt;/td&gt;
        &lt;td&gt;Image generation AI can create new images based on text or existing images. It allows for immediate visualization of ideas, potentially improving efficiency in design work. In this feature, LLMs can assist in creating prompts.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Video Generation&lt;/td&gt;
        &lt;td&gt;Video generation AI creates short videos from text. The generated videos can be used as materials in various scenarios.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Video Analysis&lt;/td&gt;
        &lt;td&gt;With multimodal models, it&#039;s now possible to input not only text but also images. In this feature, you can ask the LLM to analyze video frames and text inputs.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Diagram Generation&lt;/td&gt;
        &lt;td&gt;Diagram generation visualizes text and content on any topic using optimal diagrams. It allows for easy text-based diagram creation, enabling efficient creation of flowcharts and other diagrams even for non-programmers and non-designers.&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/details&gt;

&lt;details markdown=&quot;1&quot;&gt;
  &lt;summary&gt;&lt;strong&gt;&lt;ins&gt;I want to do RAG&lt;/ins&gt;&lt;/strong&gt;&lt;/summary&gt;

RAG is a technique that allows LLMs to answer questions they normally couldn&#039;t by providing external up-to-date information or domain knowledge that LLMs typically struggle with.
PDF, Word, Excel, and other files accumulated within your organization can serve as information sources.
RAG also has the effect of preventing LLMs from providing &quot;plausible but incorrect information&quot; by only allowing answers based on evidence.

GenU provides a RAG Chat use case.
Two types of information sources are available for RAG Chat: [Amazon Kendra](docs/en/DEPLOY_OPTION.md) and [Knowledge Base](docs/en/DEPLOY_OPTION.md#enabling-rag-chat-knowledge-base-use-case).
When using Amazon Kendra, you can [use manually created S3 Buckets or Kendra Indexes as they are](docs/en/DEPLOY_OPTION.md#using-an-existing-amazon-kendra-index).
When using Knowledge Base, advanced RAG features such as [Advanced Parsing](docs/en/DEPLOY_OPTION.md#enabling-advanced-parsing), [Chunk Strategy Selection](docs/en/DEPLOY_OPTION.md#changing-chunking-strategy), [Query Decomposition](docs/en/DEPLOY_OPTION.md#enabling-rag-chat-knowledge-base-use-case), and [Reranking](docs/en/DEPLOY_OPTION.md#enabling-rag-chat-knowledge-base-use-case) are available.
Knowledge Base also allows for [Metadata Filter Settings](docs/en/DEPLOY_OPTION.md#metadata-filter-configuration).
For example, you can meet requirements such as &quot;switching accessible data sources by organization&quot; or &quot;allowing users to set filters from the UI.&quot;

&lt;/details&gt;

&lt;details markdown=&quot;1&quot;&gt;
  &lt;summary&gt;&lt;strong&gt;&lt;ins&gt;I want to use custom AI agents or Bedrock Flows within my organization&lt;/ins&gt;&lt;/strong&gt;&lt;/summary&gt;

When you [enable agents](docs/en/DEPLOY_OPTION.md#enabling-agent-chat-use-case) in GenU, Web Search Agent and Code Interpreter Agent are created.
The Web Search Agent searches the web for information to answer user questions. For example, it can answer &quot;What is AWS GenU?&quot;
The Code Interpreter Agent can execute code to respond to user requests. For example, it can respond to requests like &quot;Draw a scatter plot with some dummy data.&quot;

While Web Search Agent and Code Interpreter Agent are basic agents, you might want to use more practical agents tailored to your business needs.
GenU provides a feature to [import agents](docs/en/DEPLOY_OPTION.md#adding-manually-created-agents) that you&#039;ve created manually or with other assets.

By using GenU as a platform for agent utilization, you can leverage GenU&#039;s [rich security options](docs/en/DEPLOY_OPTION.md#security-related-settings) and [SAML authentication](docs/en/DEPLOY_OPTION.md#saml-authentication) to spread practical agents within your organization.
Additionally, you can [hide unnecessary standard use cases](docs/en/DEPLOY_OPTION.md#hiding-specific-use-cases) or [display agents inline](docs/en/DEPLOY_OPTION.md#displaying-agents-inline) to use GenU as a more agent-focused platform.

Similarly, there is an [import feature](docs/en/DEPLOY_OPTION.md#enabling-flow-chat-use-case) for Bedrock Flows, so please make use of it.

&lt;/details&gt;

&lt;details markdown=&quot;1&quot;&gt;
  &lt;summary&gt;&lt;strong&gt;&lt;ins&gt;I want to create custom use cases&lt;/ins&gt;&lt;/strong&gt;&lt;/summary&gt;

GenU provides a feature called &quot;Use Case Builder&quot; that allows you to create custom use cases by describing prompt templates in natural language.
Custom use case screens are automatically generated just from prompt templates, so no code changes to GenU itself are required.
Created use cases can be shared with all users who can log into the application, not just for personal use.
Use Case Builder can be [disabled](docs/en/DEPLOY_OPTION.md#use-case-builder-configuration) if not needed.
For more details about Use Case Builder, please check &lt;a href=&quot;https://aws.amazon.com/jp/blogs/news/genu-use-cases-builder/&quot;&gt;this blog&lt;/a&gt;.
&lt;br/&gt;
&lt;br/&gt;
While Use Case Builder can create use cases where you input text into forms or attach files, depending on your requirements, a chat UI might be more suitable.
In such cases, please utilize the system prompt saving feature of the &quot;Chat&quot; use case.
By saving system prompts, you can create business-necessary &quot;bots&quot; with just one click.
For example, you can create &quot;a bot that thoroughly reviews source code when input&quot; or &quot;a bot that extracts email addresses from input content.&quot;
Additionally, chat conversation histories can be shared with logged-in users, and system prompts can be imported from shared conversation histories.
&lt;br/&gt;
&lt;br/&gt;
Since GenU is OSS, you can also customize it to add your own use cases.
In that case, please be careful about conflicts with GenU&#039;s main branch.

&lt;/details&gt;

## Deployment

&gt; [!IMPORTANT]
&gt; Please enable the `modelIds` (text generation), `imageGenerationModelIds` (image generation), and `videoGenerationModelIds` (video generation) in the `modelRegion` region listed in [`/packages/cdk/cdk.json`](/packages/cdk/cdk.json). ([Amazon Bedrock Model access screen](https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/modelaccess))

GenU deployment uses [AWS Cloud Development Kit](https://aws.amazon.com/jp/cdk/) (CDK). If you cannot prepare a CDK execution environment, refer to the following deployment methods:

- [Deployment method using AWS CloudShell (if preparing your own environment is difficult)](docs/en/DEPLOY_ON_CLOUDSHELL.md)
- [Workshop](https://catalog.workshops.aws/generative-ai-use-cases-jp)

First, run the following command. All commands should be executed at the repository root.

```bash
npm ci
```

If you&#039;ve never used CDK before, you need to [Bootstrap](https://docs.aws.amazon.com/ja_jp/cdk/v2/guide/bootstrapping.html) for the first time only. The following command is unnecessary if your environment is already bootstrapped.

```bash
npx -w packages/cdk cdk bootstrap
```

Next, deploy AWS resources with the following command. Please wait for the deployment to complete (it may take about 20 minutes).

```bash
# Normal deployment
npm run cdk:deploy

# Fast deployment (quickly deploy without pre-checking created resources)
npm run cdk:deploy:quick
```

## Architecture

![arch.drawio.png](./docs/assets/images/arch.drawio.png)

## Other Information

- [Deployment Options](docs/en/DEPLOY_OPTION.md)
- [Update Method](docs/en/UPDATE.md)
- [Local Development Environment Setup](docs/en/DEVELOPMENT.md)
- [Resource Deletion Method](docs/en/DESTROY.md)
- [How to Use as a Native App](docs/en/PWA.md)
- [Using Browser Extensions](docs/en/EXTENSION.md)

## Cost Estimation

We have published configuration and cost estimation examples for using GenU. (The service is pay-as-you-go, and actual costs will vary depending on your usage.)

- [Simple Version (without RAG) Estimation](https://aws.amazon.com/jp/cdp/ai-chatbot/)
- [With RAG (Amazon Kendra) Estimation](https://aws.amazon.com/jp/cdp/ai-chatapp/)
- [With RAG (Knowledge Base) Estimation](https://aws.amazon.com/jp/cdp/genai-chat-app/)

## Customer Case Studies

| Customer                                                                                                                          | Quote                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| :-------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| &lt;a href=&quot;https://www.yasashiite.com/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/yasashiite_logo.png&quot;&gt;&lt;/a&gt;              | **Yasashiite Co., Ltd.** &lt;br/&gt; _Thanks to GenU, we were able to provide added value to users and improve employee work efficiency. We continue to evolve from &quot;smooth operation&quot; to &quot;exciting work&quot; as employees&#039; &quot;previous work&quot; transforms into enjoyable work!_ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/yasashiite_case.png) &lt;br/&gt; „Éª[See case page](https://aws.amazon.com/jp/solutions/case-studies/yasashii-te/)                                |
| &lt;a href=&quot;https://www.takihyo.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/TAKIHYO_logo.png&quot;&gt;&lt;/a&gt;                  | **TAKIHYO Co., Ltd.** &lt;br/&gt; _Achieved internal business efficiency and reduced over 450 hours of work by utilizing generative AI. Applied Amazon Bedrock to clothing design, etc., and promoted digital talent development._ &lt;br/&gt; „Éª[See case page](https://aws.amazon.com/jp/solutions/case-studies/takihyo/)                                                                                                                                                     |
| &lt;a href=&quot;https://salsonido.com/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/salsonido_logo.png&quot;&gt;&lt;/a&gt;                    | **Salsonido Inc.** &lt;br/&gt; _By utilizing GenU, which is provided as a solution, we were able to quickly start improving business processes with generative AI._ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/salsonido_case.png) &lt;br/&gt; „Éª[Applied service](https://kirei.ai/)                                                                                                                                                                                |
| &lt;a href=&quot;https://www.tamura-ss.co.jp/jp/index.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/tamura-ss_logo.png&quot;&gt;&lt;/a&gt; | **TAMURA CORPORATION** &lt;br/&gt; _The application samples that AWS publishes on Github have a wealth of immediately testable functions, and by using them as they are, we were able to easily select functions that suited us and shorten the development time of the final system._&lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/tamura-ss_case.png)&lt;br/&gt;                                                                                                      |
| &lt;a href=&quot;https://jdsc.ai/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/jdsc_logo.png&quot;&gt;&lt;/a&gt;                               | **JDSC Inc.** &lt;br/&gt; _Amazon Bedrock allows us to securely use LLMs with our data. Also, we can switch to the optimal model depending on the purpose, allowing us to improve speed and accuracy while keeping costs down._ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/jdsc_case.png)                                                                                                                                                                      |
| &lt;a href=&quot;https://www.iret.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/iret_logo.png&quot;&gt;&lt;/a&gt;                        | **iret, Inc.** &lt;br/&gt; _To accumulate and systematize internal knowledge for BANDAI NAMCO Amusement Inc.&#039;s generative AI utilization, we developed a use case site using Generative AI Use Cases JP provided by AWS. iret, Inc. supported the design, construction, and development of this project._ &lt;br/&gt; „Éª[BANDAI NAMCO Amusement Inc.&#039;s cloud utilization case study](https://cloudpack.jp/casestudy/302.html?_gl=1*17hkazh*_gcl_au*ODA5MDk3NzI0LjE3MTM0MTQ2MDU) |
| &lt;a href=&quot;https://idealog.co.jp&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/idealog_logo.jpg&quot;&gt;&lt;/a&gt;                       | **IDEALOG Inc.** &lt;br/&gt; _I feel that we can achieve even greater work efficiency than with conventional generative AI tools. Using Amazon Bedrock, which doesn&#039;t use input/output data for model training, gives us peace of mind regarding security._ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/idealog_case.png) &lt;br/&gt; „Éª[Applied service](https://kaijosearch.com/)                                                                                   |
| &lt;a href=&quot;https://estyle.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/estyle_logo.png&quot;&gt;&lt;/a&gt;                        | **eStyle Inc.** &lt;br/&gt; _By utilizing GenU, we were able to build a generative AI environment in a short period and promote knowledge sharing within the company._ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/estyle_case.png)                                                                                                                                                                                                                             |
| &lt;a href=&quot;https://meidensha.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/meidensha_logo.svg&quot;&gt;&lt;/a&gt;                  | **Meidensha Corporation** &lt;br/&gt; _By using AWS services such as Amazon Bedrock and Amazon Kendra, we were able to quickly and securely build a generative AI usage environment. It contributes to employee work efficiency through automatic generation of meeting minutes and searching internal information._ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/meidensha_case.png)                                                                            |
| &lt;a href=&quot;https://www.st-grp.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/st-grp_logo.jpg&quot;&gt;&lt;/a&gt;                    | **Sankyo Tateyama, Inc.** &lt;br/&gt; _Information buried within the company became quickly searchable with Amazon Kendra. By referring to GenU, we were able to promptly provide the functions we needed, such as meeting minutes generation._ &lt;br/&gt; „Éª[See case details](./docs/assets/images/cases/st-grp_case.png)                                                                                                                                                    |
| &lt;a href=&quot;https://www.oisixradaichi.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/oisixradaichi_logo.png&quot;&gt;&lt;/a&gt;      | **Oisix ra daichi Inc.** &lt;br/&gt; _Through the use case development project using GenU, we were able to grasp the necessary resources, project structure, external support, and talent development, which helped us clarify our image for the internal deployment of generative AI._ &lt;br/&gt; „Éª[See case page](https://aws.amazon.com/jp/solutions/case-studies/oisix/)                                                                                                  |
| &lt;a href=&quot;https://www.san-a.co.jp/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;./docs/assets/images/cases/san-a_logo.png&quot;&gt;&lt;/a&gt;                      | **SAN-A CO., LTD.** &lt;br/&gt; _By utilizing Amazon Bedrock, our engineers&#039; productivity has dramatically improved, accelerating the migration of our comp

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[expo/expo]]></title>
            <link>https://github.com/expo/expo</link>
            <guid>https://github.com/expo/expo</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:46 GMT</pubDate>
            <description><![CDATA[An open-source framework for making universal native apps with React. Expo runs on Android, iOS, and the web.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/expo/expo">expo/expo</a></h1>
            <p>An open-source framework for making universal native apps with React. Expo runs on Android, iOS, and the web.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 39,118</p>
            <p>Forks: 6,594</p>
            <p>Stars today: 48 stars today</p>
            <h2>README</h2><pre>&lt;!-- Banner Image --&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://expo.dev/&quot;&gt;
    &lt;img alt=&quot;expo sdk&quot; height=&quot;128&quot; src=&quot;./.github/resources/banner.png&quot;&gt;
    &lt;h1 align=&quot;center&quot;&gt;Expo&lt;/h1&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
   &lt;a aria-label=&quot;SDK version&quot; href=&quot;https://www.npmjs.com/package/expo&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo SDK version&quot; src=&quot;https://img.shields.io/npm/v/expo.svg?style=flat-square&amp;label=SDK&amp;labelColor=000000&amp;color=4630EB&quot; /&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Chat or ask a question&quot; href=&quot;https://chat.expo.dev&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Chat or ask a question&quot; src=&quot;https://img.shields.io/discord/695411232856997968.svg?style=flat-square&amp;labelColor=000000&amp;color=4630EB&amp;logo=discord&amp;logoColor=FFFFFF&amp;label=Chat%20with%20us&quot; /&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Expo is free to use&quot; href=&quot;https://github.com/expo/expo/blob/main/LICENSE&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;License: MIT&quot; src=&quot;https://img.shields.io/badge/License-MIT-success.svg?style=flat-square&amp;color=33CC12&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;expo downloads&quot; href=&quot;http://www.npmtrends.com/expo&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Downloads&quot; src=&quot;https://img.shields.io/npm/dm/expo.svg?style=flat-square&amp;labelColor=gray&amp;color=33CC12&amp;label=Downloads&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;try expo with snack&quot; href=&quot;https://snack.expo.dev&quot;&gt;&lt;b&gt;Try Expo in the Browser&lt;/b&gt;&lt;/a&gt;
&amp;ensp;‚Ä¢&amp;ensp;
  &lt;a aria-label=&quot;expo documentation&quot; href=&quot;https://docs.expo.dev&quot;&gt;Read the Documentation&lt;/a&gt;
&amp;ensp;‚Ä¢&amp;ensp;
  &lt;a aria-label=&quot;expo documentation&quot; href=&quot;https://expo.dev/blog&quot;&gt;Learn more on our blog&lt;/a&gt;
&amp;ensp;‚Ä¢&amp;ensp;
  &lt;a aria-label=&quot;expo documentation&quot; href=&quot;https://expo.canny.io/feature-requests&quot;&gt;Request a feature&lt;/a&gt;
&lt;/p&gt;

&lt;h6 align=&quot;center&quot;&gt;Follow us on&lt;/h6&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;Follow @expo on X&quot; href=&quot;https://x.com/intent/follow?screen_name=expo&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on X&quot; src=&quot;https://img.shields.io/badge/X-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;&amp;nbsp;
  &lt;a aria-label=&quot;Follow @expo on GitHub&quot; href=&quot;https://github.com/expo&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on GitHub&quot; src=&quot;https://img.shields.io/badge/GitHub-222222?style=for-the-badge&amp;logo=github&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;&amp;nbsp;
  &lt;a aria-label=&quot;Follow @expo on Reddit&quot; href=&quot;https://www.reddit.com/r/expo/&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on Reddit&quot; src=&quot;https://img.shields.io/badge/Reddit-FF4500?style=for-the-badge&amp;logo=reddit&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;&amp;nbsp;
  &lt;a aria-label=&quot;Follow @expo on Bluesky&quot; href=&quot;https://bsky.app/profile/expo.dev&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on LinkedIn&quot; src=&quot;https://img.shields.io/badge/Bluesky-1DA1F2?style=for-the-badge&amp;logo=bluesky&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;&amp;nbsp;
  &lt;a aria-label=&quot;Follow @expo on LinkedIn&quot; href=&quot;https://www.linkedin.com/company/expo-dev&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Expo on LinkedIn&quot; src=&quot;https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white&quot; target=&quot;_blank&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## Introduction

Expo is an open-source platform for making universal native apps that run on Android, iOS, and the web. It includes a universal runtime and libraries that let you build native apps by writing React and JavaScript.

This repository includes the Expo SDK, Modules API, Go app, CLI, Router, documentation, and various other supporting tools. [Expo Application Services (EAS)](https://expo.dev/eas) is a platform of hosted services that are deeply integrated with Expo open source tools. EAS helps you build, ship, and iterate on your app as an individual or a team.

Read the [Expo Community Guidelines](https://expo.dev/guidelines) before interacting in the repository. Thank you for helping keep the Expo community open and welcoming!

## Table of contents

- [üìö Documentation](#-documentation)
- [üó∫ Project Layout](#-project-layout)
- [üèÖ Badges](#-badges)
- [üëè Contributing](#-contributing)
- [‚ùì FAQ](#-faq)
- [üíô The Team](#-the-team)
- [License](#license)

## üìö Documentation

&lt;p&gt;Learn about building and deploying universal apps &lt;a aria-label=&quot;expo documentation&quot; href=&quot;https://docs.expo.dev&quot;&gt;in our official docs!&lt;/a&gt;&lt;/p&gt;

- [Getting Started](https://docs.expo.dev/)
- [API Reference](https://docs.expo.dev/versions/latest/)
- [Using Custom Native Modules](https://docs.expo.dev/workflow/customizing/)

## üó∫ Project Layout

- [`packages`](/packages) All the source code for Expo modules, if you want to edit a library or just see how it works this is where you&#039;ll find it.
- [`apps`](/apps) This is where you can find Expo projects which are linked to the development modules. You&#039;ll do most of your testing in here.
- [`apps/expo-go`](/apps/expo-go) This is where you can find the source code for Expo Go.
- [`apps/expo-go/ios/Exponent.xcworkspace`](/apps/expo-go/ios) is the Xcode workspace. When developing iOS, always open this instead of `Exponent.xcodeproj` because the workspace also loads the CocoaPods dependencies.
- [`docs`](/docs) The source code for **https://docs.expo.dev**
- [`templates`](/templates) The template projects you get when you run `npx create-expo-app`
- [`react-native-lab`](/react-native-lab) This is our fork of `react-native` used to build Expo Go.
- [`guides`](/guides) In-depth tutorials for advanced topics like contributing to the client.
- [`tools`](/tools) contain build and configuration tools.
- [`template-files`](/template-files) contains templates for files that require private keys. They are populated using the keys in `template-files/keys.json`.
- [`template-files/ios/dependencies.json`](/template-files/ios/dependencies.json) specifies the CocoaPods dependencies of the app.

## üèÖ Badges

Let everyone know your app can be run instantly in the _Expo Go_ app!
&lt;br/&gt;

[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-000.svg?style=flat-square&amp;logo=EXPO&amp;labelColor=f3f3f3&amp;logoColor=000)](https://expo.dev/client)

[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-4630EB.svg?style=flat-square&amp;logo=EXPO&amp;labelColor=f3f3f3&amp;logoColor=000)](https://expo.dev/client)

```md
[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-000.svg?style=flat-square&amp;logo=EXPO&amp;labelColor=f3f3f3&amp;logoColor=000)](https://expo.dev/client)

[![runs with Expo Go](https://img.shields.io/badge/Runs%20with%20Expo%20Go-4630EB.svg?style=flat-square&amp;logo=EXPO&amp;labelColor=f3f3f3&amp;logoColor=000)](https://expo.dev/client)
```

## üëè Contributing

If you like Expo and want to help make it better then check out our [contributing guide](/CONTRIBUTING.md)! Check out the [CLI package](https://github.com/expo/expo/tree/main/packages/%40expo/cli) to work on the Expo CLI.

## ‚ùì FAQ

If you have questions about Expo and want answers, then check out our [Frequently Asked Questions](https://docs.expo.dev/faq/)!

If you still have questions you can ask them on our [Discord and Forums](https://chat.expo.dev) or X [@expo](https://x.com/expo).

## üíô The Team

Curious about who makes Expo? Here are our [team members](https://expo.dev/about)!

## License

The Expo source code is made available under the [MIT license](LICENSE). Some of the dependencies are licensed differently, with the BSD license, for example.

&lt;img alt=&quot;Star the Expo repo on GitHub to support the project&quot; src=&quot;https://user-images.githubusercontent.com/9664363/185428788-d762fd5d-97b3-4f59-8db7-f72405be9677.gif&quot; width=&quot;50%&quot;&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[browserbase/stagehand]]></title>
            <link>https://github.com/browserbase/stagehand</link>
            <guid>https://github.com/browserbase/stagehand</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:45 GMT</pubDate>
            <description><![CDATA[An AI web browsing framework focused on simplicity and extensibility.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/browserbase/stagehand">browserbase/stagehand</a></h1>
            <p>An AI web browsing framework focused on simplicity and extensibility.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,937</p>
            <p>Forks: 547</p>
            <p>Stars today: 252 stars today</p>
            <h2>README</h2><pre>&lt;div id=&quot;toc&quot; align=&quot;center&quot;&gt;
  &lt;ul style=&quot;list-style: none&quot;&gt;
    &lt;a href=&quot;https://stagehand.dev&quot;&gt;
      &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://stagehand.dev/logo-dark.svg&quot; /&gt;
        &lt;img alt=&quot;Stagehand&quot; src=&quot;https://stagehand.dev/logo-light.svg&quot; /&gt;
      &lt;/picture&gt;
    &lt;/a&gt;
  &lt;/ul&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  The production-ready framework for AI browser automations.&lt;br&gt;
  &lt;a href=&quot;https://docs.stagehand.dev&quot;&gt;Read the Docs&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/browserbase/stagehand/tree/main?tab=MIT-1-ov-file#MIT-1-ov-file&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://stagehand.dev/api/assets/license?mode=dark&quot; /&gt;
      &lt;img alt=&quot;MIT License&quot; src=&quot;https://stagehand.dev/api/assets/license?mode=light&quot; /&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://stagehand.dev/slack&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://stagehand.dev/api/assets/slack?mode=dark&quot; /&gt;
      &lt;img alt=&quot;Slack Community&quot; src=&quot;https://stagehand.dev/api/assets/slack?mode=light&quot; /&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://trendshift.io/repositories/12122&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12122&quot; alt=&quot;browserbase%2Fstagehand | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

## Why Stagehand?

Most existing browser automation tools either require you to write low-level code in a framework like Selenium, Playwright, or Puppeteer, or use high-level agents that can be unpredictable in production. By letting developers choose what to write in code vs. natural language, Stagehand is the natural choice for browser automations in production.

1. **Choose when to write code vs. natural language**: use AI when you want to navigate unfamiliar pages, and use code ([Playwright](https://playwright.dev/)) when you know exactly what you want to do.

2. **Preview and cache actions**: Stagehand lets you preview AI actions before running them, and also helps you easily cache repeatable actions to save time and tokens.

3. **Computer use models with one line of code**: Stagehand lets you integrate SOTA computer use models from OpenAI and Anthropic into the browser with one line of code.

## Example

Here&#039;s how to build a sample browser automation with Stagehand:

&lt;div align=&quot;center&quot;&gt;
  &lt;div style=&quot;max-width:300px;&quot;&gt;
    &lt;img src=&quot;/media/github_demo.gif&quot; alt=&quot;See Stagehand in Action&quot;&gt;
  &lt;/div&gt;
&lt;/div&gt;

```typescript
// Use Playwright functions on the page object
const page = stagehand.page;
await page.goto(&quot;https://github.com/browserbase&quot;);

// Use act() to execute individual actions
await page.act(&quot;click on the stagehand repo&quot;);

// Use Computer Use agents for larger actions
const agent = stagehand.agent({
    provider: &quot;openai&quot;,
    model: &quot;computer-use-preview&quot;,
});
await agent.execute(&quot;Get to the latest PR&quot;);

// Use extract() to read data from the page
const { author, title } = await page.extract({
  instruction: &quot;extract the author and title of the PR&quot;,
  schema: z.object({
    author: z.string().describe(&quot;The username of the PR author&quot;),
    title: z.string().describe(&quot;The title of the PR&quot;),
  }),
});
```

## Documentation

Visit [docs.stagehand.dev](https://docs.stagehand.dev) to view the full documentation.

## Getting Started

Start with Stagehand with one line of code, or check out our [Quickstart Guide](https://docs.stagehand.dev/get_started/quickstart) for more information:

```bash
npx create-browser-app
```

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.loom.com/share/f5107f86d8c94fa0a8b4b1e89740f7a7&quot;&gt;
      &lt;p&gt;Watch Anirudh demo create-browser-app to create a Stagehand project!&lt;/p&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://www.loom.com/share/f5107f86d8c94fa0a8b4b1e89740f7a7&quot;&gt;
      &lt;img style=&quot;max-width:300px;&quot; src=&quot;https://cdn.loom.com/sessions/thumbnails/f5107f86d8c94fa0a8b4b1e89740f7a7-ec3f428b6775ceeb-full-play.gif&quot;&gt;
    &lt;/a&gt;
  &lt;/div&gt;

### Build and Run from Source

```bash
git clone https://github.com/browserbase/stagehand.git
cd stagehand
npm install
npx playwright install
npm run build
npm run example # run the blank script at ./examples/example.ts
```

Stagehand is best when you have an API key for an LLM provider and Browserbase credentials. To add these to your project, run:

```bash
cp .env.example .env
nano .env # Edit the .env file to add API keys
```

## Contributing

&gt; [!NOTE]  
&gt; We highly value contributions to Stagehand! For questions or support, please join our [Slack community](https://stagehand.dev/slack).

At a high level, we&#039;re focused on improving reliability, speed, and cost in that order of priority. If you&#039;re interested in contributing, we strongly recommend reaching out to [Anirudh Kamath](https://x.com/kamathematic) or [Paul Klein](https://x.com/pk_iv) in our [Slack community](https://stagehand.dev/slack) before starting to ensure that your contribution aligns with our goals.

For more information, please see our [Contributing Guide](https://docs.stagehand.dev/contributions/contributing).

## Acknowledgements

This project heavily relies on [Playwright](https://playwright.dev/) as a resilient backbone to automate the web. It also would not be possible without the awesome techniques and discoveries made by [tarsier](https://github.com/reworkd/tarsier), and [fuji-web](https://github.com/normal-computing/fuji-web).

We&#039;d like to thank the following people for their major contributions to Stagehand:
- [Paul Klein](https://github.com/pkiv)
- [Anirudh Kamath](https://github.com/kamath)
- [Sean McGuire](https://github.com/seanmcguire12)
- [Miguel Gonzalez](https://github.com/miguelg719)
- [Sameel Arif](https://github.com/sameelarif)
- [Filip Michalsky](https://github.com/filip-michalsky)
- [Jeremy Press](https://x.com/jeremypress)
- [Navid Pour](https://github.com/navidpour)

## License

Licensed under the MIT License.

Copyright 2025 Browserbase, Inc.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[getsentry/sentry-javascript]]></title>
            <link>https://github.com/getsentry/sentry-javascript</link>
            <guid>https://github.com/getsentry/sentry-javascript</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[Official Sentry SDKs for JavaScript]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/getsentry/sentry-javascript">getsentry/sentry-javascript</a></h1>
            <p>Official Sentry SDKs for JavaScript</p>
            <p>Language: TypeScript</p>
            <p>Stars: 8,216</p>
            <p>Forks: 1,665</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://sentry.io/?utm_source=github&amp;utm_medium=logo&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://sentry-brand.storage.googleapis.com/sentry-wordmark-dark-280x84.png&quot; alt=&quot;Sentry&quot; width=&quot;280&quot; height=&quot;84&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

_Bad software is everywhere, and we&#039;re tired of it. Sentry is on a mission to help developers write better software
faster, so we can get back to enjoying technology. If you want to join us
[&lt;kbd&gt;**Check out our open positions**&lt;/kbd&gt;](https://sentry.io/careers/)_

![Build &amp; Test](https://github.com/getsentry/sentry-javascript/workflows/CI:%20Build%20&amp;%20Test/badge.svg)
[![codecov](https://codecov.io/gh/getsentry/sentry-javascript/branch/develop/graph/badge.svg)](https://codecov.io/gh/getsentry/sentry-javascript)
[![npm version](https://img.shields.io/npm/v/@sentry/core.svg)](https://www.npmjs.com/package/@sentry/core)
[![Discord](https://img.shields.io/discord/621778831602221064)](https://discord.gg/Ww9hbqr)

# Official Sentry SDKs for JavaScript

&lt;a href=&quot;https://docs.sentry.io/platforms/javascript/&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/aedc2b46-9959-4b9e-8a23-6240062cefc5&quot; alt=&quot;Sentry for JavaScript&quot;&gt;
&lt;/a&gt;

This is the next line of Sentry JavaScript SDKs, comprised in the `@sentry/` namespace. It will provide a more
convenient interface and improved consistency between various JavaScript environments.

## Links

- [![Documentation](https://img.shields.io/badge/documentation-sentry.io-green.svg)](https://docs.sentry.io/quickstart/)
- [![Forum](https://img.shields.io/badge/forum-sentry-green.svg)](https://forum.sentry.io/c/sdks)
- [![Discord](https://img.shields.io/discord/621778831602221064)](https://discord.gg/Ww9hbqr)
- [![Stack Overflow](https://img.shields.io/badge/stack%20overflow-sentry-green.svg)](http://stackoverflow.com/questions/tagged/sentry)
- [![Twitter Follow](https://img.shields.io/twitter/follow/getsentry?label=getsentry&amp;style=social)](https://twitter.com/intent/follow?screen_name=getsentry)

## Contents

- [Contributing](https://github.com/getsentry/sentry-javascript/blob/develop/CONTRIBUTING.md)
- [Supported Platforms](#supported-platforms)
- [Installation and Usage](#installation-and-usage)
- [Other Packages](#other-packages)
- [Bug Bounty Program](#bug-bounty-program)

## Supported Platforms

For each major JavaScript platform, there is a specific high-level SDK that provides all the tools you need in a single
package. Please refer to the README and instructions of those SDKs for more detailed information:

- [`@sentry/browser`](https://github.com/getsentry/sentry-javascript/tree/master/packages/browser): SDK for Browsers
- [`@sentry/node`](https://github.com/getsentry/sentry-javascript/tree/master/packages/node): SDK for Node including
  integrations for Express
- [`@sentry/angular`](https://github.com/getsentry/sentry-javascript/tree/master/packages/angular): Browser SDK for
  Angular
- [`@sentry/astro`](https://github.com/getsentry/sentry-javascript/tree/master/packages/astro): SDK for Astro
- [`@sentry/ember`](https://github.com/getsentry/sentry-javascript/tree/master/packages/ember): Browser SDK for Ember
- [`@sentry/react`](https://github.com/getsentry/sentry-javascript/tree/master/packages/react): Browser SDK for React
- [`@sentry/svelte`](https://github.com/getsentry/sentry-javascript/tree/master/packages/svelte): Browser SDK for Svelte
- [`@sentry/sveltekit`](https://github.com/getsentry/sentry-javascript/tree/master/packages/sveltekit): SDK for
  SvelteKit
- [`@sentry/vue`](https://github.com/getsentry/sentry-javascript/tree/master/packages/vue): Browser SDK for Vue
- [`@sentry/solid`](https://github.com/getsentry/sentry-javascript/tree/master/packages/solid): Browser SDK for Solid
- [`@sentry/gatsby`](https://github.com/getsentry/sentry-javascript/tree/master/packages/gatsby): SDK for Gatsby
- [`@sentry/nestjs`](https://github.com/getsentry/sentry-javascript/tree/master/packages/nestjs): SDK for NestJS
- [`@sentry/nextjs`](https://github.com/getsentry/sentry-javascript/tree/master/packages/nextjs): SDK for Next.js
- [`@sentry/remix`](https://github.com/getsentry/sentry-javascript/tree/master/packages/remix): SDK for Remix
- [`@sentry/tanstackstart-react`](https://github.com/getsentry/sentry-javascript/tree/master/packages/tanstackstart-react): SDK for TanStack Start React
- [`@sentry/aws-serverless`](https://github.com/getsentry/sentry-javascript/tree/master/packages/aws-serverless): SDK
  for AWS Lambda Functions
- [`@sentry/google-cloud-serverless`](https://github.com/getsentry/sentry-javascript/tree/master/packages/google-cloud-serverless):
  SDK for Google Cloud Functions
- [`@sentry/electron`](https://github.com/getsentry/sentry-electron): SDK for Electron with support for native crashes
- [`@sentry/react-native`](https://github.com/getsentry/sentry-react-native): SDK for React Native with support for
  native crashes
- [`@sentry/capacitor`](https://github.com/getsentry/sentry-capacitor): SDK for Capacitor Apps and Ionic with support
  for native crashes
- [`@sentry/bun`](https://github.com/getsentry/sentry-javascript/tree/master/packages/bun): SDK for Bun
- [`@sentry/deno`](https://github.com/getsentry/sentry-javascript/tree/master/packages/deno): SDK for Deno
- [`@sentry/cloudflare`](https://github.com/getsentry/sentry-javascript/tree/master/packages/cloudflare): SDK for
  Cloudflare

## Version Support Policy

We recognize the importance of continued support for our SDK across different versions.
Our commitment is to provide bug fixes and feature updates for older versions based on community demand and usage.

## Installation and Usage

To install a SDK, simply add the high-level package, for example:

```sh
npm install --save @sentry/browser
yarn add @sentry/browser
```

Setup and usage of these SDKs always follows the same principle.

```javascript
import * as Sentry from &#039;@sentry/browser&#039;;

Sentry.init({
  dsn: &#039;__DSN__&#039;,
  // ...
});

Sentry.captureMessage(&#039;Hello, world!&#039;);
```

## Other Packages

Besides the high-level SDKs, this repository contains shared packages, helpers and configuration used for SDK
development. If you&#039;re thinking about contributing to or creating a JavaScript-based SDK, have a look at the resources
below:

- [`@sentry-internal/replay`](https://github.com/getsentry/sentry-javascript/tree/master/packages/replay-internal):
  Provides the integration for Session Replay.
- [`@sentry/core`](https://github.com/getsentry/sentry-javascript/tree/master/packages/core): The base for all
  JavaScript SDKs with interfaces, type definitions and base classes.

## Bug Bounty Program

Our bug bounty program aims to improve the security of our open source projects by encouraging the community to identify
and report potential security vulnerabilities. Your reward will depend on the severity of the identified vulnerability.

Our program is currently running on an invitation basis. If you&#039;re interested in participating, please send us an email
to security@sentry.io and tell us, that you are interested in auditing this repository.

For more details, please have a look at https://sentry.io/security/#vulnerability-disclosure.

## Contributors

Thanks to everyone who contributed to the Sentry JavaScript SDK!

&lt;a href=&quot;https://github.com/getsentry/sentry-javascript/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=getsentry/sentry-javascript&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lobehub/lobe-chat]]></title>
            <link>https://github.com/lobehub/lobe-chat</link>
            <guid>https://github.com/lobehub/lobe-chat</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[ü§Ø Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / DeepSeek / Qwen), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Plugins/Artifacts) and Thinking. One-click FREE deployment of your private ChatGPT/ Claude / DeepSeek application.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobe-chat">lobehub/lobe-chat</a></h1>
            <p>ü§Ø Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / DeepSeek / Qwen), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Plugins/Artifacts) and Thinking. One-click FREE deployment of your private ChatGPT/ Claude / DeepSeek application.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 58,914</p>
            <p>Forks: 12,487</p>
            <p>Stars today: 42 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# Lobe Chat

An open-source, modern-design ChatGPT/LLMs UI/Framework.&lt;br/&gt;
Supports speech-synthesis, multi-modal, and extensible ([function call][docs-functionc-call]) plugin system.&lt;br/&gt;
One-click **FREE** deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.

**English** ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md) ¬∑ [Official Site][official-site] ¬∑ [Changelog][changelog] ¬∑ [Documents][docs] ¬∑ [Blog][blog] ¬∑ [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeChat Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Pioneering the new age of thinking and creating. Built for you, the Super Individual.&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url]

![][image-overview]

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [üëãüèª Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [‚ú® Features](#-features)
  - [`1` Chain of Thought](#1-chain-of-thought)
  - [`2` Branching Conversations](#2-branching-conversations)
  - [`3` Artifacts Support](#3-artifacts-support)
  - [`4` File Upload /Knowledge Base](#4-file-upload-knowledge-base)
  - [`5` Multi-Model Service Provider Support](#5-multi-model-service-provider-support)
  - [`6` Local Large Language Model (LLM) Support](#6-local-large-language-model-llm-support)
  - [`7` Model Visual Recognition](#7-model-visual-recognition)
  - [`8` TTS &amp; STT Voice Conversation](#8-tts--stt-voice-conversation)
  - [`9` Text to Image Generation](#9-text-to-image-generation)
  - [`10` Plugin System (Function Calling)](#10-plugin-system-function-calling)
  - [`11` Agent Market (GPTs)](#11-agent-market-gpts)
  - [`12` Support Local / Remote Database](#12-support-local--remote-database)
  - [`13` Support Multi-User Management](#13-support-multi-user-management)
  - [`14` Progressive Web App (PWA)](#14-progressive-web-app-pwa)
  - [`15` Mobile Device Adaptation](#15-mobile-device-adaptation)
  - [`16` Custom Themes](#16-custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [‚ö°Ô∏è Performance](#Ô∏è-performance)
- [üõ≥ Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [üì¶ Ecosystem](#-ecosystem)
- [üß© Plugins](#-plugins)
- [‚å®Ô∏è Local Development](#Ô∏è-local-development)
- [ü§ù Contributing](#-contributing)
- [‚ù§Ô∏è Sponsor](#Ô∏è-sponsor)
- [üîó More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

## üëãüèª Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![][vercel-shield-badge]][vercel-link]   | No installation or registration necessary! Visit our website to experience it firsthand.                           |
| :---------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link] | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub. |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ ‚≠êÔ∏è

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## ‚ú® Features

[![][image-feat-cot]][docs-feat-cot]

### `1` [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### `2` [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### `3` [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeChat. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### `4` [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [üìò LobeChat Knowledge Base Launch ‚Äî From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### `5` [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

- **[OpenAI](https://lobechat.com/discover/provider/openai)**: OpenAI is a global leader in artificial intelligence research, with models like the GPT series pushing the frontiers of natural language processing. OpenAI is committed to transforming multiple industries through innovative and efficient AI solutions. Their products demonstrate significant performance and cost-effectiveness, widely used in research, business, and innovative applications.
- **[Ollama](https://lobechat.com/discover/provider/ollama)**: Ollama provides models that cover a wide range of fields, including code generation, mathematical operations, multilingual processing, and conversational interaction, catering to diverse enterprise-level and localized deployment needs.
- **[Anthropic](https://lobechat.com/discover/provider/anthropic)**: Anthropic is a company focused on AI research and development, offering a range of advanced language models such as Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Opus, and Claude 3 Haiku. These models achieve an ideal balance between intelligence, speed, and cost, suitable for various applications from enterprise workloads to rapid-response scenarios. Claude 3.5 Sonnet, as their latest model, has excelled in multiple evaluations while maintaining a high cost-performance ratio.
- **[Bedrock](https://lobechat.com/discover/provider/bedrock)**: Bedrock is a service provided by Amazon AWS, focusing on delivering advanced AI language and visual models for enterprises. Its model family includes Anthropic&#039;s Claude series, Meta&#039;s Llama 3.1 series, and more, offering a range of options from lightweight to high-performance, supporting tasks such as text generation, conversation, and image processing for businesses of varying scales and needs.
- **[Google](https://lobechat.com/discover/provider/google)**: Google&#039;s Gemini series represents its most advanced, versatile AI models, developed by Google DeepMind, designed for multimodal capabilities, supporting seamless understanding and processing of text, code, images, audio, and video. Suitable for various environments from data centers to mobile devices, it significantly enhances the efficiency and applicability of AI models.
- **[DeepSeek](https://lobechat.com/discover/provider/deepseek)**: DeepSeek is a company focused on AI technology research and application, with its latest model DeepSeek-V2.5 integrating general dialogue and code processing capabilities, achieving significant improvements in human preference alignment, writing tasks, and instruction following.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[HuggingFace](https://lobechat.com/discover/provider/huggingface)**: The HuggingFace Inference API provides a fast and free way for you to explore thousands of models for various tasks. Whether you are prototyping for a new application or experimenting with the capabilities of machine learning, this API gives you instant access to high-performance models across multiple domains.
- **[OpenRouter](https://lobechat.com/discover/provider/openrouter)**: OpenRouter is a service platform providing access to various cutting-edge large model interfaces, supporting OpenAI, Anthropic, LLaMA, and more, suitable for diverse development and application needs. Users can flexibly choose the optimal model and pricing based on their requirements, enhancing the AI experience.
- **[Cloudflare Workers AI](https://lobechat.com/discover/provider/cloudflare)**: Run serverless GPU-powered machine learning models on Cloudflare&#039;s global network.

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+30)&lt;/kbd&gt;&lt;/summary&gt;

- **[GitHub](https://lobechat.com/discover/provider/github)**: With GitHub Models, developers can become AI engineers and leverage the industry&#039;s leading AI models.
- **[Novita](https://lobechat.com/discover/provider/novita)**: Novita AI is a platform providing a variety of large language models and AI image generation API services, flexible, reliable, and cost-effective. It supports the latest open-source models like Llama3 and Mistral, offering a comprehensive, user-friendly, and auto-scaling API solution for generative AI application development, suitable for the rapid growth of AI startups.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[Together AI](https://lobechat.com/discover/provider/togetherai)**: Together AI is dedicated to achieving leading performance through innovative AI models, offering extensive customization capabilities, including rapid scaling support and intuitive deployment processes to meet various enterprise needs.
- **[Fireworks AI](https://lobechat.com/discover/provider/fireworksai)**: Fireworks AI is a leading provider of advanced language model services, focusing on functional calling and multimodal processing. Its latest model, Firefunction V2, is based on Llama-3, optimized for function calling, conversation, and instruction following. The visual language model FireLLaVA-13B supports mixed input of images and text. Other notable models include the Llama series and Mixtral series, providing efficient multilingual instruction following and generation support.
- **[Groq](https://lobechat.com/discover/provider/groq)**: Groq&#039;s LPU inference engine has excelled in the latest independent large language model (LLM) benchmarks, redefining the standards for AI solutions with its remarkable speed and efficiency. Groq represents instant inference speed, demonstrating strong performance in cloud-based deployments.
- **[Perplexity](https://lobechat.com/discover/provider/perplexity)**: Perplexity is a leading provider of conversational generation models, offering various advanced Llama 3.1 models that support both online and offline applications, particularly suited for complex natural language processing tasks.
- **[Mistral](https://lobechat.com/discover/provider/mistral)**: Mistral provides advanced general, specialized, and research models widely used in complex reasoning, multilingual tasks, and code generation. Through functional calling interfaces, users can integrate custom functionalities for specific applications.
- **[Ai21Labs](https://lobechat.com/discover/provider/ai21)**: AI21 Labs builds foundational models and AI systems for enterprises, accelerating the application of generative AI in production.
- **[Upstage](https://lobechat.com/discover/provider/upstage)**: Upstage focuses on developing AI models for various business needs, including Solar LLM and document AI, aiming to achieve artificial general intelligence (AGI) for work. It allows for the creation of simple conversational agents through Chat API and supports functional calling, translation, embedding, and domain-specific applications.
- **[xAI](https://lobechat.com/discover/provider/xai)**: xAI is a company dedicated to building artificial intelligence to accelerate human scientific discovery. Our mission is to advance our collective understanding of the universe.
- **[Qwen](https://lobechat.com/discover/provider/qwen)**: Tongyi Qianwen is a large-scale language model independently developed by Alibaba Cloud, featuring strong natural language understanding and generation capabilities. It can answer various questions, create written content, express opinions, and write code, playing a role in multiple fields.
- **[Wenxin](https://lobechat.com/discover/provider/wenxin)**: An enterprise-level one-stop platform for large model and AI-native application development and services, providing the most comprehensive and user-friendly toolchain for the entire process of generative artificial intelligence model development and application development.
- **[Hunyuan](https://lobechat.com/discover/provider/hunyuan)**: A large language model developed by Tencent, equipped with powerful Chinese creative capabilities, logical reasoning abilities in complex contexts, and reliable task execution skills.
- **[ZhiPu](https://lobechat.com/discover/provider/zhipu)**: Zhipu AI offers an open platform for multimodal and language models, supporting a wide range of AI application scenarios, including text processing, image understanding, and programming assistance.
- **[SiliconCloud](https://lobechat.com/discover/provider/siliconcloud)**: SiliconFlow is dedicated to accelerating AGI for the benefit of humanity, enhancing large-scale AI efficiency through an easy-to-use and cost-effective GenAI stack.
- **[01.AI](https://lobechat.com/discover/provider/zeroone)**: 01.AI focuses on AI 2.0 era technologies, vigorously promoting the innovation and application of &#039;human + artificial intelligence&#039;, using powerful models and advanced AI technologies to enhance human productivity and achieve technological empowerment.
- **[Spark](https://lobechat.com/discover/provider/spark)**: iFlytek&#039;s Spark model provides powerful AI capabilities across multiple domains and languages, utilizing advanced natural language processing technology to build innovative applications suitable for smart hardware, smart healthcare, smart finance, and other vertical scenarios.
- **[SenseNova](https://lobechat.com/discover/provider/sensenova)**: SenseNova, backed by SenseTime&#039;s robust infrastructure, offers efficient and user-friendly full-stack large model services.
- **[Stepfun](https://lobechat.com/discover/provider/stepfun)**: StepFun&#039;s large model possesses industry-leading multimodal and complex reasoning capabilities, supporting ultra-long text understanding and powerful autonomous scheduling search engine functions.
- **[Moonshot](https://lobechat.com/discover/provider/moonshot)**: Moonshot is an open-source platform launched by Beijing Dark Side Technology Co., Ltd., providing various natural language processing models with a wide range of applications, including but not limited to content creation, academic research, intelligent recommendations, and medical diagnosis, supporting long text processing and complex generation tasks.
- **[Baichuan](https://lobechat.com/discover/provider/baichuan)**: Baichuan Intelligence is a company focused on the research and development of large AI models, with its models excelling in domestic knowledge encyclopedias, long text processing, and generative creation tasks in Chinese, surpassing mainstream foreign models. Baichuan Intelligence also possesses industry-leading multimodal capabilities, performing excellently in multiple authoritative evaluations. Its models include Baichuan 4, Baichuan 3 Turbo, and Baichuan 3 Turbo 128k, each optimized for different application scenarios, providing cost-effective solutions.
- **[Minimax](https://lobechat.com/discover/provider/minimax)**: MiniMax is a general artificial intelligence technology company established in 2021, dedicated to co-creating intelligence with users. MiniMax has independently developed general large models of different modalities, including trillion-parameter MoE text models, voice models, and image models, and has launched applications such as Conch AI.
- **[InternLM](https://lobechat.com/di

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[gitroomhq/postiz-app]]></title>
            <link>https://github.com/gitroomhq/postiz-app</link>
            <guid>https://github.com/gitroomhq/postiz-app</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:42 GMT</pubDate>
            <description><![CDATA[üì® The ultimate social media scheduling tool, with a bunch of AI ü§ñ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gitroomhq/postiz-app">gitroomhq/postiz-app</a></h1>
            <p>üì® The ultimate social media scheduling tool, with a bunch of AI ü§ñ</p>
            <p>Language: TypeScript</p>
            <p>Stars: 19,537</p>
            <p>Forks: 3,112</p>
            <p>Stars today: 31 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://affiliate.postiz.com&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/af9f47b3-e20c-402b-bd11-02f39248d738&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://postiz.com/&quot; target=&quot;_blank&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/765e9d72-3ee7-4a56-9d59-a2c9befe2311&quot;&gt;
    &lt;img alt=&quot;Postiz Logo&quot; src=&quot;https://github.com/user-attachments/assets/f0d30d70-dddb-4142-8876-e9aa6ed1cb99&quot; width=&quot;280&quot;/&gt;
  &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;


&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-blue.svg&quot; alt=&quot;License&quot;&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;strong&gt;
  &lt;h2&gt;Your ultimate AI social media scheduling tool&lt;/h2&gt;&lt;br /&gt;
  &lt;a href=&quot;https://postiz.com&quot;&gt;Postiz&lt;/a&gt;: An alternative to: Buffer.com, Hypefury, Twitter Hunter, Etc...&lt;br /&gt;&lt;br /&gt;
  &lt;/strong&gt;
  Postiz offers everything you need to manage your social media posts,&lt;br /&gt;build an audience, capture leads, and grow your business.
&lt;/div&gt;


&lt;div class=&quot;flex&quot; align=&quot;center&quot;&gt;
  &lt;br /&gt;
  &lt;img alt=&quot;Instagram&quot; src=&quot;https://postiz.com/svgs/socials/Instagram.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Youtube&quot; src=&quot;https://postiz.com/svgs/socials/Youtube.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Dribbble&quot; src=&quot;https://postiz.com/svgs/socials/Dribbble.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Linkedin&quot; src=&quot;https://postiz.com/svgs/socials/Linkedin.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Reddit&quot; src=&quot;https://postiz.com/svgs/socials/Reddit.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;TikTok&quot; src=&quot;https://postiz.com/svgs/socials/TikTok.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Facebook&quot; src=&quot;https://postiz.com/svgs/socials/Facebook.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Pinterest&quot; src=&quot;https://postiz.com/svgs/socials/Pinterest.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;Threads&quot; src=&quot;https://postiz.com/svgs/socials/Threads.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;X&quot; src=&quot;https://postiz.com/svgs/socials/X.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;X&quot; src=&quot;https://postiz.com/svgs/socials/Slack.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;X&quot; src=&quot;https://postiz.com/svgs/socials/Discord.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;X&quot; src=&quot;https://postiz.com/svgs/socials/Mastodon.svg&quot; width=&quot;32&quot;&gt;
  &lt;img alt=&quot;X&quot; src=&quot;https://postiz.com/svgs/socials/Bluesky.svg&quot; width=&quot;32&quot;&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;br /&gt;
  &lt;a href=&quot;https://docs.postiz.com&quot; rel=&quot;dofollow&quot;&gt;&lt;strong&gt;Explore the docs ¬ª&lt;/strong&gt;&lt;/a&gt;
  &lt;br /&gt;

  &lt;br/&gt;
    &lt;a href=&quot;https://platform.postiz.com&quot;&gt;Register&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://discord.postiz.com&quot;&gt;Join Our Discord (devs only)&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://twitter.com/getpostiz&quot;&gt;X&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://gitroom.com&quot;&gt;Gitroom&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://git.sn/telegram&quot;&gt;Telegram (Crypto)&lt;/a&gt;
  &lt;/p&gt;

&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;video src=&quot;https://github.com/user-attachments/assets/05436a01-19c8-4827-b57f-05a5e7637a67&quot; width=&quot;100%&quot; /&gt;
&lt;/p&gt;

## ‚ú® Features

| ![Image 1](https://github.com/user-attachments/assets/a27ee220-beb7-4c7e-8c1b-2c44301f82ef) | ![Image 2](https://github.com/user-attachments/assets/eb5f5f15-ed90-47fc-811c-03ccba6fa8a2) |
|--------------------------------|--------------------------------|
| ![Image 3](https://github.com/user-attachments/assets/d51786ee-ddd8-4ef8-8138-5192e9cfe7c3) | ![Image 4](https://github.com/user-attachments/assets/91f83c89-22f6-43d6-b7aa-d2d3378289fb) |

# Intro

- Schedule all your social media posts (many AI features)
- Measure your work with analytics.
- Collaborate with other team members to exchange or buy posts.
- Invite your team members to collaborate, comment, and schedule posts.
- At the moment there is no difference between the hosted version to the self-hosted version

## Tech Stack

- NX (Monorepo)
- NextJS (React)
- NestJS
- Prisma (Default to PostgreSQL)
- Redis (BullMQ)
- Resend (email notifications)

## Quick Start
To have the project up and running, please follow the [Quick Start Guide](https://docs.postiz.com/quickstart)

## Invest in the Postiz Coin :)
DMsTbeCfX1crgAse5tver98KAMarPWeP3d6U3Gmmpump

# License

This repository&#039;s source code is available under the [AGPL-3.0 license](LICENSE).

&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.g2.com/products/postiz/take_survey&quot; target=&quot;blank&quot;&gt;&lt;img alt=&quot;g2&quot; src=&quot;https://github.com/user-attachments/assets/892cb74c-0b49-4589-b2f5-fbdbf7a98f66&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;


</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[Budibase/budibase]]></title>
            <link>https://github.com/Budibase/budibase</link>
            <guid>https://github.com/Budibase/budibase</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:41 GMT</pubDate>
            <description><![CDATA[Create business apps and automate workflows in minutes. Supports PostgreSQL, MySQL, MariaDB, MSSQL, MongoDB, Rest API, Docker, K8s, and more üöÄ No code / Low code platform..]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Budibase/budibase">Budibase/budibase</a></h1>
            <p>Create business apps and automate workflows in minutes. Supports PostgreSQL, MySQL, MariaDB, MSSQL, MongoDB, Rest API, Docker, K8s, and more üöÄ No code / Low code platform..</p>
            <p>Language: TypeScript</p>
            <p>Stars: 24,297</p>
            <p>Forks: 1,702</p>
            <p>Stars today: 253 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.budibase.com&quot;&gt;
    &lt;img alt=&quot;Budibase&quot; src=&quot;https://res.cloudinary.com/daog6scxm/image/upload/v1696515725/Branding/Assets/Symbol/RGB/Full%20Colour/Budibase_Symbol_RGB_FullColour_cbqvha_1_z5cwq2.svg&quot; width=&quot;60&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;h1 align=&quot;center&quot;&gt;
  Budibase
&lt;/h1&gt;

&lt;h3 align=&quot;center&quot;&gt;
  The low code platform you&#039;ll enjoy using
&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;
  Budibase is an open-source low-code platform that saves engineers 100s of hours building forms, portals, and approval apps, securely.
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
 ü§ñ üé® üöÄ
&lt;/h3&gt;
&lt;br&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Budibase design ui&quot; src=&quot;https://res.cloudinary.com/daog6scxm/image/upload/v1680181644/ui/homepage-design-ui_sizp7b.png&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/Budibase/budibase/releases&quot;&gt;
    &lt;img alt=&quot;GitHub all releases&quot; src=&quot;https://img.shields.io/github/downloads/Budibase/budibase/total&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/Budibase/budibase/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest by date)&quot; src=&quot;https://img.shields.io/github/v/release/Budibase/budibase&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=budibase&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/twitter/follow/budibase?style=social&quot; alt=&quot;Follow @budibase&quot; /&gt;
  &lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg&quot; alt=&quot;Code of conduct&quot; /&gt;
  &lt;a href=&quot;https://codecov.io/gh/Budibase/budibase&quot;&gt;
    &lt;img src=&quot;https://codecov.io/gh/Budibase/budibase/graph/badge.svg?token=E8W2ZFXQOH&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://account.budibase.app/register&quot;&gt;Get started - we host (Budibase Cloud)&lt;/a&gt;
  &lt;span&gt; ¬∑ &lt;/span&gt;
  &lt;a href=&quot;https://docs.budibase.com/docs/hosting-methods&quot;&gt;Get started - you host (Docker, K8s, DO)&lt;/a&gt;
  &lt;span&gt; ¬∑ &lt;/span&gt;
  &lt;a href=&quot;https://docs.budibase.com/docs&quot;&gt;Docs&lt;/a&gt;
  &lt;span&gt; ¬∑ &lt;/span&gt;
  &lt;a href=&quot;https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas&quot;&gt;Feature request&lt;/a&gt;
  &lt;span&gt; ¬∑ &lt;/span&gt;
  &lt;a href=&quot;https://github.com/Budibase/budibase/issues&quot;&gt;Report a bug&lt;/a&gt;
  &lt;span&gt; ¬∑ &lt;/span&gt;
  Support: &lt;a href=&quot;https://github.com/Budibase/budibase/discussions&quot;&gt;Discussions&lt;/a&gt;
&lt;/h3&gt;

&lt;br /&gt;&lt;br /&gt;

## ‚ú® Features

### Build and ship real software

Unlike other platforms, with Budibase you build and ship single page applications. Budibase applications have performance baked in and can be designed responsively, providing users with a great experience.
&lt;br /&gt;&lt;br /&gt;

### Open source and extensible

Budibase is open-source - licensed as GPL v3. This should fill you with confidence that Budibase will always be around. You can also code against Budibase or fork it and make changes as you please, providing a developer-friendly experience.
&lt;br /&gt;&lt;br /&gt;

### Load data or start from scratch

Budibase pulls data from multiple sources, including MongoDB, CouchDB, PostgreSQL, MariaDB, MySQL, Airtable, S3, DynamoDB, or a REST API. And unlike other platforms, with Budibase you can start from scratch and create business apps with no data sources. [Request new datasources](https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas).

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Budibase data&quot; src=&quot;https://res.cloudinary.com/daog6scxm/image/upload/v1680281798/ui/data_klbuna.png&quot;&gt;
&lt;/p&gt;
&lt;br /&gt;&lt;br /&gt;

### Design and build apps with powerful pre-made components

Budibase comes out of the box with beautifully designed, powerful components which you can use like building blocks to build your UI. We also expose many of your favourite CSS styling options so you can go that extra creative mile. [Request new component](https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas).

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Budibase design&quot; src=&quot;https://res.cloudinary.com/daog6scxm/image/upload/v1675437167/ui/form_2x_mbli8y.png&quot;&gt;
&lt;/p&gt;
&lt;br /&gt;&lt;br /&gt;

### Automate processes, integrate with other tools and connect to webhooks

Save time by automating manual processes and workflows. From connecting to webhooks to automating emails, simply tell Budibase what to do and let it work for you. You can easily [create new automations for Budibase here](https://github.com/Budibase/automations) or [Request new automation](https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas).
&lt;br /&gt;&lt;br /&gt;

### Integrate with your favorite tools

Budibase integrates with a number of popular tools allowing you to build apps that perfectly fit your stack.

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Budibase integrations&quot; src=&quot;https://res.cloudinary.com/daog6scxm/image/upload/v1680195228/ui/automate_fg9z07.png&quot;&gt;
&lt;/p&gt;
&lt;br /&gt;&lt;br /&gt;

### Deploy with confidence and security

Budibase is made to scale. With Budibase, you can self-host on your own infrastructure and globally manage users, onboarding, SMTP, apps, groups, theming and more. You can also provide users/groups with an app portal and disseminate user management to the group manager.

- Checkout the promo video: https://youtu.be/xoljVpty_Kw

&lt;br /&gt;

---

&lt;br /&gt;

## Budibase Public API

As with anything that we build in Budibase, our new public API is simple to use, flexible, and introduces new extensibility. To summarize, the Budibase API enables:

- Budibase as a backend
- Interoperability

#### Docs

You can learn more about the Budibase API at the following places:

- [General documentation](https://docs.budibase.com/docs/public-api): Learn how to get your API key, how to use spec, and how to use Postman
- [Interactive API documentation](https://docs.budibase.com/reference/appcreate) : Learn how to interact with the API

&lt;br /&gt;&lt;br /&gt;

## üèÅ Get started

Deploy Budibase using Docker, Kubernetes, and Digital Ocean on your existing infrastructure. Or use Budibase Cloud if you don&#039;t need to self-host and would like to get started quickly.

### [Get started with self-hosting Budibase](https://docs.budibase.com/docs/hosting-methods)

- [Docker - single ARM compatible image](https://docs.budibase.com/docs/docker)
- [Docker Compose](https://docs.budibase.com/docs/docker-compose)
- [Kubernetes](https://docs.budibase.com/docs/kubernetes-k8s)
- [Digital Ocean](https://docs.budibase.com/docs/digitalocean)
- [Portainer](https://docs.budibase.com/docs/portainer)

### [Get started with Budibase Cloud](https://budibase.com)

&lt;br /&gt;&lt;br /&gt;

## üéì Learning Budibase

The Budibase documentation [lives here](https://docs.budibase.com/docs).
&lt;br /&gt;

&lt;br /&gt;&lt;br /&gt;

## üí¨ Community

If you have a question or would like to talk with other Budibase users and join our community, please hop over to [Github discussions](https://github.com/Budibase/budibase/discussions)

&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;

## ‚ùó Code of conduct

Budibase is dedicated to providing everyone a welcoming, diverse, and harassment-free experience. We expect everyone in the Budibase community to abide by our [**Code of Conduct**](https://github.com/Budibase/budibase/blob/HEAD/docs/CODE_OF_CONDUCT.md). Please read it.
&lt;br /&gt;

&lt;br /&gt;&lt;br /&gt;

## üôå Contributing to Budibase

From opening a bug report to creating a pull request: every contribution is appreciated and welcomed. If you&#039;re planning to implement a new feature or change the API, please create an issue first. This way, we can ensure your work is not in vain.
Environment setup instructions are available [here](https://github.com/Budibase/budibase/tree/HEAD/docs/CONTRIBUTING.md).

### Not Sure Where to Start?

A good place to start contributing is by looking for the [good first issue](https://github.com/Budibase/budibase/labels/good%20first%20issue) tag.

### How the repository is organized

Budibase is a monorepo managed by lerna. Lerna manages the building and publishing of the budibase packages. At a high level, here are the packages that make up Budibase.

- [packages/builder](https://github.com/Budibase/budibase/tree/HEAD/packages/builder) - contains code for the budibase builder client-side svelte application.

- [packages/client](https://github.com/Budibase/budibase/tree/HEAD/packages/client) - A module that runs in the browser responsible for reading JSON definition and creating living, breathing web apps from it.

- [packages/server](https://github.com/Budibase/budibase/tree/HEAD/packages/server) - The budibase server. This Koa app is responsible for serving the JS for the builder and budibase apps, as well as providing the API for interaction with the database and file system.

For more information, see [CONTRIBUTING.md](https://github.com/Budibase/budibase/blob/HEAD/docs/CONTRIBUTING.md)

&lt;br /&gt;&lt;br /&gt;

## üìù License

Budibase is open-source, licensed as [GPL v3](https://www.gnu.org/licenses/gpl-3.0.en.html). The client and component libraries are licensed as [MPL](https://directory.fsf.org/wiki/License:MPL-2.0) - so the apps you build can be licensed however you like.

&lt;br /&gt;&lt;br /&gt;

## ‚≠ê Stargazers over time

[![Stargazers over time](https://starchart.cc/Budibase/budibase.svg)](https://starchart.cc/Budibase/budibase)

If you are having issues between updates of the builder, please use the guide [here](https://github.com/Budibase/budibase/blob/HEAD/docs/CONTRIBUTING.md#troubleshooting) to clear down your environment.

&lt;br /&gt;&lt;br /&gt;

## Contributors ‚ú®

Thanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):

&lt;a href=&quot;https://github.com/Budibase/budibase/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=Budibase/budibase&quot; /&gt;
&lt;/a&gt;

Made with [contrib.rocks](https://contrib.rocks).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[react-native-maps/react-native-maps]]></title>
            <link>https://github.com/react-native-maps/react-native-maps</link>
            <guid>https://github.com/react-native-maps/react-native-maps</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:40 GMT</pubDate>
            <description><![CDATA[React Native Mapview component for iOS + Android]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/react-native-maps/react-native-maps">react-native-maps/react-native-maps</a></h1>
            <p>React Native Mapview component for iOS + Android</p>
            <p>Language: TypeScript</p>
            <p>Stars: 15,413</p>
            <p>Forks: 4,872</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># react-native-maps [![npm version](https://img.shields.io/npm/v/react-native-maps.svg?style=flat)](https://www.npmjs.com/package/react-native-maps)

React Native Map components for iOS + Android

## Contributing

This project is being maintained by a small group of people, and any help with issues and pull requests are always appreciated. If you are able and willing to contribute, please read the [guidelines](./CONTRIBUTING.md).

## Installation

See [Installation Instructions](docs/installation.md).

See [Setup Instructions for the Included Example Project](docs/examples-setup.md).

## Compatibility

## React Native Compatibility

### Important Notes:

- **Fabric is now supported**:  
  Fabric is now supported for the latest version of the library, if you don&#039;t have Fabric (New Arch) enabled, please use v1.21.0 or earlier

### Version Requirements:

#### Fabric Only

- **Version `1.22.0` and below**: Requires **React Native `&gt;= 0.76`**.

#### Old Arch

- **Version `1.21.0` and below**: Requires **React Native `&gt;= 0.74`**.
- **Version `1.14.0` and above**: Requires **React Native `&gt;= 0.74`**.
- **Versions below `1.14.0`**: Require **React Native `&gt;= 0.64.3`**.

## Component API

[`&lt;MapView /&gt;` Component API](docs/mapview.md)

[`&lt;Marker /&gt;` Component API](docs/marker.md)

[`&lt;Callout /&gt;` Component API](docs/callout.md)

[`&lt;Polygon /&gt;` Component API](docs/polygon.md)

[`&lt;Polyline /&gt;` Component API](docs/polyline.md)

[`&lt;Circle /&gt;` Component API](docs/circle.md)

[`&lt;Overlay /&gt;` Component API](docs/overlay.md)

[`&lt;Heatmap /&gt;` Component API](docs/heatmap.md)

[`&lt;Geojson /&gt;` Component API](docs/geojson.md)

## General Usage

```js
import MapView from &#039;react-native-maps&#039;;
```

or

```js
var MapView = require(&#039;react-native-maps&#039;);
```

This MapView component is built so that features on the map (such as Markers, Polygons, etc.) are
specified as children of the MapView itself. This provides an intuitive and react-like API for
declaratively controlling features on the map.

### Rendering a Map with an initial region

## MapView

```jsx
&lt;MapView
  initialRegion={{
    latitude: 37.78825,
    longitude: -122.4324,
    latitudeDelta: 0.0922,
    longitudeDelta: 0.0421,
  }}
/&gt;
```

### Using a MapView while controlling the region as state

```jsx
getInitialState() {
  return {
    region: {
      latitude: 37.78825,
      longitude: -122.4324,
      latitudeDelta: 0.0922,
      longitudeDelta: 0.0421,
    },
  };
}

onRegionChange(region) {
  this.setState({ region });
}

render() {
  return (
    &lt;MapView
      region={this.state.region}
      onRegionChange={this.onRegionChange}
    /&gt;
  );
}
```

### Rendering a list of markers on a map

```jsx
import {Marker} from &#039;react-native-maps&#039;;

&lt;MapView region={this.state.region} onRegionChange={this.onRegionChange}&gt;
  {this.state.markers.map((marker, index) =&gt; (
    &lt;Marker
      key={index}
      coordinate={marker.latlng}
      title={marker.title}
      description={marker.description}
    /&gt;
  ))}
&lt;/MapView&gt;;
```

### Rendering a Marker with a custom image

1. You need to generate an `png` image with various resolution (lets call them `custom_pin`) - for more information go to [Android](https://developer.android.com/studio/write/resource-manager#import), [iOS](https://developer.apple.com/documentation/xcode/adding-images-to-your-xcode-project)
2. put all images in Android drawables and iOS assets dir
3. Now you can use the following code:

```jsx
&lt;Marker
  coordinate={{latitude: latitude, longitude: longitude}}
  image={{uri: &#039;custom_pin&#039;}}
/&gt;
```

Note: You can also pass the image binary data like `image={require(&#039;custom_pin.png&#039;)}`, but this will not scale good with the different screen sizes.

### Rendering a Marker with a custom view

Note: This has performance implications, if you wish for a simpler solution go with a custom image (save your self the headache)

```jsx
&lt;Marker coordinate={{latitude: latitude, longitude: longitude}}&gt;
  &lt;MyCustomMarkerView {...marker} /&gt;
&lt;/Marker&gt;
```

### Rendering a custom Marker with a custom Callout

```jsx
import {Callout} from &#039;react-native-maps&#039;;

&lt;Marker coordinate={marker.latlng}&gt;
  &lt;MyCustomMarkerView {...marker} /&gt;
  &lt;Callout&gt;
    &lt;MyCustomCalloutView {...marker} /&gt;
  &lt;/Callout&gt;
&lt;/Marker&gt;;
```

### Draggable Markers

```jsx
&lt;MapView initialRegion={...}&gt;
  &lt;Marker draggable
    coordinate={this.state.x}
    onDragEnd={(e) =&gt; this.setState({ x: e.nativeEvent.coordinate })}
  /&gt;
&lt;/MapView&gt;
```

### Using a custom Tile Overlay

#### Tile Overlay using tile server

```jsx
import {UrlTile} from &#039;react-native-maps&#039;;

&lt;MapView region={this.state.region} onRegionChange={this.onRegionChange}&gt;
  &lt;UrlTile
    /**
     * The url template of the tile server. The patterns {x} {y} {z} will be replaced at runtime
     * For example, http://c.tile.openstreetmap.org/{z}/{x}/{y}.png
     */
    urlTemplate={this.state.urlTemplate}
    /**
     * The maximum zoom level for this tile overlay. Corresponds to the maximumZ setting in
     * MKTileOverlay. iOS only.
     */
    maximumZ={19}
    /**
     * flipY allows tiles with inverted y coordinates (origin at bottom left of map)
     * to be used. Its default value is false.
     */
    flipY={false}
  /&gt;
&lt;/MapView&gt;;
```

For Android: add the following line in your AndroidManifest.xml

```xml
&lt;uses-permission android:name=&quot;android.permission.INTERNET&quot; /&gt;
```

For IOS: configure [App Transport Security](https://developer.apple.com/library/content/documentation/General/Reference/InfoPlistKeyReference/Articles/CocoaKeys.html#//apple_ref/doc/uid/TP40009251-SW33) in your app

## React Native Configuration for Fabric / New Architecture

This library doesn&#039;t support the new arch yet due to issues with inserting subviews / interoplayer. we&#039;re working on it.

### Configuration Steps

1. **Open your configuration file**: Locate the `react-native-config` file in your project directory.

2. **Add the following configuration**: Include the `unstable_reactLegacyComponentNames` array for both Android and iOS platforms as shown below:

```javascript
module.exports = {
  project: {
    android: {
      unstable_reactLegacyComponentNames: [
        &#039;AIRMap&#039;,
        &#039;AIRMapCallout&#039;,
        &#039;AIRMapCalloutSubview&#039;,
        &#039;AIRMapCircle&#039;,
        &#039;AIRMapHeatmap&#039;,
        &#039;AIRMapLocalTile&#039;,
        &#039;AIRMapMarker&#039;,
        &#039;AIRMapOverlay&#039;,
        &#039;AIRMapPolygon&#039;,
        &#039;AIRMapPolyline&#039;,
        &#039;AIRMapUrlTile&#039;,
        &#039;AIRMapWMSTile&#039;,
      ],
    },
    ios: {
      unstable_reactLegacyComponentNames: [
        &#039;AIRMap&#039;,
        &#039;AIRMapCallout&#039;,
        &#039;AIRMapCalloutSubview&#039;,
        &#039;AIRMapCircle&#039;,
        &#039;AIRMapHeatmap&#039;,
        &#039;AIRMapLocalTile&#039;,
        &#039;AIRMapMarker&#039;,
        &#039;AIRMapOverlay&#039;,
        &#039;AIRMapPolygon&#039;,
        &#039;AIRMapPolyline&#039;,
        &#039;AIRMapUrlTile&#039;,
        &#039;AIRMapWMSTile&#039;,
      ],
    },
  },
};
```

checkout the example project to see it in action.

#### Tile Overlay using local tiles

Tiles can be stored locally within device using xyz tiling scheme and displayed as tile overlay as well. This is usefull especially for offline map usage when tiles are available for selected map region within device storage.

```jsx
import {LocalTile} from &#039;react-native-maps&#039;;

&lt;MapView region={this.state.region} onRegionChange={this.onRegionChange}&gt;
  &lt;LocalTile
    /**
     * The path template of the locally stored tiles. The patterns {x} {y} {z} will be replaced at runtime
     * For example, /storage/emulated/0/mytiles/{z}/{x}/{y}.png
     */
    pathTemplate={this.state.pathTemplate}
    /**
     * The size of provided local tiles (usually 256 or 512).
     */
    tileSize={256}
  /&gt;
&lt;/MapView&gt;;
```

For Android: LocalTile is still just overlay over original map tiles. It means that if device is online, underlying tiles will be still downloaded. If original tiles download/display is not desirable set mapType to &#039;none&#039;. For example:

```
&lt;MapView
  mapType={Platform.OS == &quot;android&quot; ? &quot;none&quot; : &quot;standard&quot;}
&gt;
```

See [OSM Wiki](https://wiki.openstreetmap.org/wiki/Category:Tile_downloading) for how to download tiles for offline usage.

### Overlaying other components on the map

Place components that you wish to overlay `MapView` underneath the `MapView` closing tag. Absolutely position these elements.

```jsx
render() {
  return (
    &lt;MapView
      region={this.state.region}
    /&gt;
    &lt;OverlayComponent
      style={{position: &quot;absolute&quot;, bottom: 50}}
    /&gt;
  );
}
```

### Customizing the map style (Google Maps Only)

The `&lt;MapView provider=&quot;google&quot; googleMapId=&quot;yourStyledMapId&quot; /&gt;` Google Maps on iOS and Android supports styling via google cloud platform, the styled maps are published under a googleMapId, by simply setting the property googleMapId to the MapView you can use that styled map
more info here: [google map id](https://developers.google.com/maps/documentation/get-map-id)

### MapView Events

The `&lt;MapView /&gt;` component and its child components have several events that you can subscribe to.
This example displays some of them in a log as a demonstration.

![](http://i.giphy.com/3o6UBpncYQASu2WTW8.gif) ![](http://i.giphy.com/xT77YdviLqtjaecRYA.gif)

### Tracking Region / Location

![](http://i.giphy.com/3o6UBoPSLlIKQ2dv7q.gif) ![](http://i.giphy.com/xT77XWjqECvdgjx9oA.gif)

### Programmatically Changing Region

One can change the mapview&#039;s position using refs and component methods, or by passing in an updated
`region` prop. The component methods will allow one to animate to a given position like the native
API could.

![](http://i.giphy.com/3o6UB7poyB6YJ0KPWU.gif) ![](http://i.giphy.com/xT77Yc4wK3pzZusEbm.gif)

### Changing the style of the map

![](http://i.imgur.com/a9WqCL6.png)

### Arbitrary React Views as Markers

![](http://i.giphy.com/3o6UBcsCLoLQtksJxe.gif) ![](http://i.giphy.com/3o6UB1qGEM9jYni3KM.gif)

### Using the MapView with the Animated API

The `&lt;MapView /&gt;` component can be made to work with the Animated API, having the entire `region` prop
be declared as an animated value. This allows one to animate the zoom and position of the MapView along
with other gestures, giving a nice feel.

Further, Marker views can use the animated API to enhance the effect.

![](http://i.giphy.com/xT77XMw9IwS6QAv0nC.gif) ![](http://i.giphy.com/3o6UBdGQdM1GmVoIdq.gif)

Issue: Since android needs to render its marker views as a bitmap, the animations APIs may not be
compatible with the Marker views. Not sure if this can be worked around yet or not.

Markers&#039; coordinates can also be animated, as shown in this example:

![](http://i.giphy.com/xTcnTelp1OwGPu1Wh2.gif) ![](http://i.giphy.com/xTcnT6WVpwlCiQnFW8.gif)

### Polygon Creator

![](http://i.giphy.com/3o6UAZWqQBkOzs8HE4.gif) ![](http://i.giphy.com/xT77XVBRErNZl3zyWQ.gif)

### Other Overlays

So far, `&lt;Circle /&gt;`, `&lt;Polygon /&gt;`, and `&lt;Polyline /&gt;` are available to pass in as children to the
`&lt;MapView /&gt;` component.

![](http://i.giphy.com/xT77XZCH8JpEhzVcNG.gif) ![](http://i.giphy.com/xT77XZyA0aYeOX5jsA.gif)

### Gradient Polylines (iOS MapKit only)

Gradient polylines can be created using the `strokeColors` prop of the `&lt;Polyline&gt;` component.

![](https://i.imgur.com/P7UeqAm.png?1)

### Default Markers

Default markers will be rendered unless a custom marker is specified. One can optionally adjust the
color of the default marker by using the `pinColor` prop.

![](http://i.giphy.com/xT77Y0pWKmUUnguHK0.gif) ![](http://i.giphy.com/3o6UBfk3I58VIwZjVe.gif)

### Custom Callouts

Callouts to markers can be completely arbitrary react views, similar to markers. As a result, they
can be interacted with like any other view.

Additionally, you can fall back to the standard behavior of just having a title/description through
the `&lt;Marker /&gt;`&#039;s `title` and `description` props.

Custom callout views can be the entire tooltip bubble, or just the content inside of the system
default bubble.

To handle press on specific subview of callout use `&lt;CalloutSubview /&gt;` with `onPress`.
See `Callouts.js` example.

![](http://i.giphy.com/xT77XNePGnMIIDpbnq.gif) ![](http://i.giphy.com/xT77YdU0HXryvoRqaQ.gif)

### Image-based Markers

Markers can be customized by just using images, and specified using the `image` prop.

![](http://i.imgur.com/mzrOjTR.png)

### Draggable Markers

Markers are draggable, and emit continuous drag events to update other UI during drags.

![](http://i.giphy.com/l2JImnZxdv1WbpQfC.gif) ![](http://i.giphy.com/l2JIhv4Jx6Ugx1EGI.gif)

### Lite Mode ( Android )

Enable lite mode on Android with `liteMode` prop. Ideal when having multiple maps in a View or ScrollView.

![](http://i.giphy.com/qZ2lAf18s89na.gif)

### On Poi Click (Google Maps Only)

Poi are clickable, you can catch the event to get its information (usually to get the full detail from Google Place using the placeId).

![](https://media.giphy.com/media/3480VsCKnHr31uCLU3/giphy.gif)

### Animated Region

The MapView can accept an `AnimatedRegion` value as its `region` prop. This allows you to utilize the Animated API to control the map&#039;s center and zoom.

```jsx
import MapView, { AnimatedRegion, Animated } from &#039;react-native-maps&#039;;

getInitialState() {
  return {
    region: new AnimatedRegion({
      latitude: LATITUDE,
      longitude: LONGITUDE,
      latitudeDelta: LATITUDE_DELTA,
      longitudeDelta: LONGITUDE_DELTA,
    }),
  };
}

onRegionChange(region) {
  this.state.region.setValue(region);
}

render() {
  return (
    &lt;Animated
      region={this.state.region}
      onRegionChange={this.onRegionChange}
    /&gt;
  );
}
```

### Animated Marker Position

Markers can also accept an `AnimatedRegion` value as a coordinate.

```jsx
import MapView, { AnimatedRegion, MarkerAnimated } from &#039;react-native-maps&#039;;

getInitialState() {
  return {
    coordinate: new AnimatedRegion({
      latitude: LATITUDE,
      longitude: LONGITUDE,
    }),
  };
}

componentWillReceiveProps(nextProps) {
  const duration = 500

  if (this.props.coordinate !== nextProps.coordinate) {
    if (Platform.OS === &#039;android&#039;) {
      if (this.marker) {
        this.marker.animateMarkerToCoordinate(
          nextProps.coordinate,
          duration
        );
      }
    } else {
      this.state.coordinate.timing({
        ...nextProps.coordinate,
        useNativeDriver: true, // defaults to false if not passed explicitly
        duration
      }).start();
    }
  }
}

render() {
  return (
    &lt;MapView initialRegion={...}&gt;
      &lt;MarkerAnimated
        ref={marker =&gt; { this.marker = marker }}
        coordinate={this.state.coordinate}
      /&gt;
    &lt;/MapView&gt;
  );
}
```

### Take Snapshot of map

```jsx
import MapView, { Marker } from &#039;react-native-maps&#039;;

getInitialState() {
  return {
    coordinate: {
      latitude: LATITUDE,
      longitude: LONGITUDE,
    },
  };
}

takeSnapshot () {
  // &#039;takeSnapshot&#039; takes a config object with the
  // following options
  const snapshot = this.map.takeSnapshot({
    width: 300,      // optional, when omitted the view-width is used
    height: 300,     // optional, when omitted the view-height is used
    region: {..},    // iOS only, optional region to render
    format: &#039;png&#039;,   // image formats: &#039;png&#039;, &#039;jpg&#039; (default: &#039;png&#039;)
    quality: 0.8,    // image quality: 0..1 (only relevant for jpg, default: 1)
    result: &#039;file&#039;   // result types: &#039;file&#039;, &#039;base64&#039; (default: &#039;file&#039;)
  });
  snapshot.then((uri) =&gt; {
    this.setState({ mapSnapshot: uri });
  });
}

render() {
  return (
    &lt;View&gt;
      &lt;MapView initialRegion={...} ref={map =&gt; { this.map = map }}&gt;
        &lt;Marker coordinate={this.state.coordinate} /&gt;
      &lt;/MapView&gt;
      &lt;Image source={{ uri: this.state.mapSnapshot.uri }} /&gt;
      &lt;TouchableOpacity onPress={this.takeSnapshot}&gt;
        Take Snapshot
      &lt;/TouchableOpacity&gt;
    &lt;/View&gt;
  );
}
```

### Zoom to Specified Markers

Pass an array of marker identifiers to have the map re-focus.

![](http://i.giphy.com/3o7qEbOQnO0yoXqKJ2.gif) ![](http://i.giphy.com/l41YdrQZ7m6Dz4h0c.gif)

### Zoom to Specified Coordinates

Pass an array of coordinates to focus a map region on said coordinates.

![](https://cloud.githubusercontent.com/assets/1627824/18609960/da5d9e06-7cdc-11e6-811e-34e255093df9.gif)

### Troubleshooting

#### My map is blank

- Make sure that you have [properly installed](docs/installation.md) react-native-maps.
- Check in the logs if there is more informations about the issue.
- Try setting the style of the MapView to an absolute position with top, left, right and bottom values set.
- Make sure you have enabled Google Maps API in [Google developer console](https://console.developers.google.com/apis/library)

```javascript
const styles = StyleSheet.create({
  map: {
    ...StyleSheet.absoluteFillObject,
  },
});
```

```jsx
&lt;MapView
  style={styles.map}
  // other props
/&gt;
```

#### Inputs don&#039;t focus

- When inputs don&#039;t focus or elements don&#039;t respond to tap, look at the order of the view hierarchy, sometimes the issue could be due to ordering of rendered components, prefer putting MapView as the first component.

Bad:

```jsx
&lt;View&gt;
  &lt;TextInput /&gt;
  &lt;MapView /&gt;
&lt;/View&gt;
```

Good:

```jsx
&lt;View&gt;
  &lt;MapView /&gt;
  &lt;TextInput /&gt;
&lt;/View&gt;
```

#### Children Components Not Re-Rendering

Components that aren&#039;t declared by this library (Ex: Markers, Polyline) must not be children of the MapView component due to MapView&#039;s unique rendering methodology. Have your custom components / views outside the MapView component and position absolute to ensure they only re-render as needed.
Example:
Bad:

```jsx
&lt;View style={StyleSheet.absoluteFillObject}&gt;
  &lt;MapView style={StyleSheet.absoluteFillObject}&gt;
    &lt;View style={{position: &#039;absolute&#039;, top: 100, left: 50}} /&gt;
  &lt;/MapView&gt;
&lt;/View&gt;
```

Good:

```jsx
&lt;View style={StyleSheet.absoluteFillObject}&gt;
  &lt;MapView style={StyleSheet.absoluteFillObject} /&gt;
  &lt;View style={{position: &#039;absolute&#039;, top: 100, left: 50}} /&gt;
&lt;/View&gt;
```

Source: https://github.com/react-native-maps/react-native-maps/issues/1901

#### Crashing with EXC_BAD_ACCESS on iOS when switching apps

`&lt;MapView&gt;` using Apple Maps in `mapType: &quot;standard&quot;` will sometimes crash when you background the app or switch into another app. This is only an issue in XCode using Metal API Validation, and won&#039;t happen in production. To eliminate this problem even while debugging in XCode, go to `Edit Scheme... -&gt; Run (Debug) -&gt; Diagnostics` and uncheck `Metal -&gt; API Validation`. (h/t [@Simon-TechForm](https://github.com/Simon-TechForm)).

Source: https://github.com/react-native-maps/react-native-maps/issues/3957#issuecomment-924161121

#### onRegionChangeComplete() callback is called infinitely

If changing the state in `onRegionChangeComplete` is called infinitely, add a condition to limit these calls to occur only when the region change was done as a result of a user&#039;s action.

```javascript
onRegionChangeComplete={ (region, gesture) =&gt; {
	// This fix only works on Google Maps because isGesture is NOT available on Apple Maps
	if (!gesture.isGesture) {
    return;
  }

  // You can use
  dispatch({ type: &quot;map_region&quot;, payload: { mapRegion: region }}); // if using useReducer
	// setMapRegionState(region); // if using useState
}}
```

Source: https://github.com/react-native-maps/react-native-maps/issues/846#issuecomment-1210079461

## License

     Copyright (c) 2017 Airbnb

     Licensed under the The MIT License (MIT) (the &quot;License&quot;);
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at

        https://raw.githubusercontent.com/airbnb/react-native-maps/master/LICENSE

     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[infiniflow/ragflow]]></title>
            <link>https://github.com/infiniflow/ragflow</link>
            <guid>https://github.com/infiniflow/ragflow</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:39 GMT</pubDate>
            <description><![CDATA[RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/infiniflow/ragflow">infiniflow/ragflow</a></h1>
            <p>RAGFlow is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 49,191</p>
            <p>Forks: 4,642</p>
            <p>Stars today: 179 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://demo.ragflow.io/&quot;&gt;
&lt;img src=&quot;web/src/assets/logo-with-text.png&quot; width=&quot;520&quot; alt=&quot;ragflow logo&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;English&lt;/a&gt; |
  &lt;a href=&quot;./README_zh.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; |
  &lt;a href=&quot;./README_tzh.md&quot;&gt;ÁπÅ‰Ωì‰∏≠Êñá&lt;/a&gt; |
  &lt;a href=&quot;./README_ja.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; |
  &lt;a href=&quot;./README_ko.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; |
  &lt;a href=&quot;./README_id.md&quot;&gt;Bahasa Indonesia&lt;/a&gt; |
  &lt;a href=&quot;/README_pt_br.md&quot;&gt;Portugu√™s (Brasil)&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://x.com/intent/follow?screen_name=infiniflowai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/infiniflow?logo=X&amp;color=%20%23f5f5f5&quot; alt=&quot;follow on X(Twitter)&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://demo.ragflow.io&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Online-Demo-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/r/infiniflow/ragflow&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/docker_pull-ragflow:v0.17.2-brightgreen&quot; alt=&quot;docker pull infiniflow/ragflow:v0.17.2&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/releases/latest&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/github/v/release/infiniflow/ragflow?color=blue&amp;label=Latest%20Release&quot; alt=&quot;Latest Release&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/blob/main/LICENSE&quot;&gt;
        &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/License-Apache--2.0-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;license&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://ragflow.io/docs/dev/&quot;&gt;Document&lt;/a&gt; |
  &lt;a href=&quot;https://github.com/infiniflow/ragflow/issues/4214&quot;&gt;Roadmap&lt;/a&gt; |
  &lt;a href=&quot;https://twitter.com/infiniflowai&quot;&gt;Twitter&lt;/a&gt; |
  &lt;a href=&quot;https://discord.gg/NjYzJD3GM3&quot;&gt;Discord&lt;/a&gt; |
  &lt;a href=&quot;https://demo.ragflow.io&quot;&gt;Demo&lt;/a&gt;
&lt;/h4&gt;

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;üìï Table of Contents&lt;/b&gt;&lt;/summary&gt;

- üí° [What is RAGFlow?](#-what-is-ragflow)
- üéÆ [Demo](#-demo)
- üìå [Latest Updates](#-latest-updates)
- üåü [Key Features](#-key-features)
- üîé [System Architecture](#-system-architecture)
- üé¨ [Get Started](#-get-started)
- üîß [Configurations](#-configurations)
- üîß [Build a docker image without embedding models](#-build-a-docker-image-without-embedding-models)
- üîß [Build a docker image including embedding models](#-build-a-docker-image-including-embedding-models)
- üî® [Launch service from source for development](#-launch-service-from-source-for-development)
- üìö [Documentation](#-documentation)
- üìú [Roadmap](#-roadmap)
- üèÑ [Community](#-community)
- üôå [Contributing](#-contributing)

&lt;/details&gt;

## üí° What is RAGFlow?

[RAGFlow](https://ragflow.io/) is an open-source RAG (Retrieval-Augmented Generation) engine based on deep document
understanding. It offers a streamlined RAG workflow for businesses of any scale, combining LLM (Large Language Models)
to provide truthful question-answering capabilities, backed by well-founded citations from various complex formatted
data.

## üéÆ Demo

Try our demo at [https://demo.ragflow.io](https://demo.ragflow.io).

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/infiniflow/ragflow/assets/7248/2f6baa3e-1092-4f11-866d-36f6a9d075e5&quot; width=&quot;1200&quot;/&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/504bbbf1-c9f7-4d83-8cc5-e9cb63c26db6&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## üî• Latest Updates

- 2025-03-19 Supports using a multi-modal model to make sense of images within PDF or DOCX files.
- 2025-02-28 Combined with Internet search (Tavily), supports reasoning like Deep Research for any LLMs.
- 2025-01-26 Optimizes knowledge graph extraction and application, offering various configuration options.
- 2024-12-18 Upgrades Document Layout Analysis model in DeepDoc.
- 2024-11-01 Adds keyword extraction and related question generation to the parsed chunks to improve the accuracy of retrieval.
- 2024-08-22 Support text to SQL statements through RAG.

## üéâ Stay Tuned

‚≠êÔ∏è Star our repository to stay up-to-date with exciting new features and improvements! Get instant notifications for new
releases! üåü

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/18c9707e-b8aa-4caf-a154-037089c105ba&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## üåü Key Features

### üç≠ **&quot;Quality in, quality out&quot;**

- [Deep document understanding](./deepdoc/README.md)-based knowledge extraction from unstructured data with complicated
  formats.
- Finds &quot;needle in a data haystack&quot; of literally unlimited tokens.

### üç± **Template-based chunking**

- Intelligent and explainable.
- Plenty of template options to choose from.

### üå± **Grounded citations with reduced hallucinations**

- Visualization of text chunking to allow human intervention.
- Quick view of the key references and traceable citations to support grounded answers.

### üçî **Compatibility with heterogeneous data sources**

- Supports Word, slides, excel, txt, images, scanned copies, structured data, web pages, and more.

### üõÄ **Automated and effortless RAG workflow**

- Streamlined RAG orchestration catered to both personal and large businesses.
- Configurable LLMs as well as embedding models.
- Multiple recall paired with fused re-ranking.
- Intuitive APIs for seamless integration with business.

## üîé System Architecture

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/infiniflow/ragflow/assets/12318111/d6ac5664-c237-4200-a7c2-a4a00691b485&quot; width=&quot;1000&quot;/&gt;
&lt;/div&gt;

## üé¨ Get Started

### üìù Prerequisites

- CPU &gt;= 4 cores
- RAM &gt;= 16 GB
- Disk &gt;= 50 GB
- Docker &gt;= 24.0.0 &amp; Docker Compose &gt;= v2.26.1
  &gt; If you have not installed Docker on your local machine (Windows, Mac, or Linux),
  &gt; see [Install Docker Engine](https://docs.docker.com/engine/install/).

### üöÄ Start up the server

1. Ensure `vm.max_map_count` &gt;= 262144:

   &gt; To check the value of `vm.max_map_count`:
   &gt;
   &gt; ```bash
   &gt; $ sysctl vm.max_map_count
   &gt; ```
   &gt;
   &gt; Reset `vm.max_map_count` to a value at least 262144 if it is not.
   &gt;
   &gt; ```bash
   &gt; # In this case, we set it to 262144:
   &gt; $ sudo sysctl -w vm.max_map_count=262144
   &gt; ```
   &gt;
   &gt; This change will be reset after a system reboot. To ensure your change remains permanent, add or update the
   &gt; `vm.max_map_count` value in **/etc/sysctl.conf** accordingly:
   &gt;
   &gt; ```bash
   &gt; vm.max_map_count=262144
   &gt; ```

2. Clone the repo:

   ```bash
   $ git clone https://github.com/infiniflow/ragflow.git
   ```

3. Start up the server using the pre-built Docker images:

&gt; [!CAUTION]
&gt; All Docker images are built for x86 platforms. We don&#039;t currently offer Docker images for ARM64.
&gt; If you are on an ARM64 platform, follow [this guide](https://ragflow.io/docs/dev/build_docker_image) to build a Docker image compatible with your system.

   &gt; The command below downloads the `v0.17.2-slim` edition of the RAGFlow Docker image. See the following table for descriptions of different RAGFlow editions. To download a RAGFlow edition different from `v0.17.2-slim`, update the `RAGFLOW_IMAGE` variable accordingly in **docker/.env** before using `docker compose` to start the server. For example: set `RAGFLOW_IMAGE=infiniflow/ragflow:v0.17.2` for the full edition `v0.17.2`.

   ```bash
   $ cd ragflow/docker
   # Use CPU for embedding and DeepDoc tasks:
   $ docker compose -f docker-compose.yml up -d

   # To use GPU to accelerate embedding and DeepDoc tasks:
   # docker compose -f docker-compose-gpu.yml up -d
   ```

   | RAGFlow image tag | Image size (GB) | Has embedding models? | Stable?                  |
   |-------------------|-----------------|-----------------------|--------------------------|
   | v0.17.2           | &amp;approx;9       | :heavy_check_mark:    | Stable release           |
   | v0.17.2-slim      | &amp;approx;2       | ‚ùå                   | Stable release            |
   | nightly           | &amp;approx;9       | :heavy_check_mark:    | _Unstable_ nightly build |
   | nightly-slim      | &amp;approx;2       | ‚ùå                   | _Unstable_ nightly build  |

4. Check the server status after having the server up and running:

   ```bash
   $ docker logs -f ragflow-server
   ```

   _The following output confirms a successful launch of the system:_

   ```bash

         ____   ___    ______ ______ __
        / __ \ /   |  / ____// ____// /____  _      __
       / /_/ // /| | / / __ / /_   / // __ \| | /| / /
      / _, _// ___ |/ /_/ // __/  / // /_/ /| |/ |/ /
     /_/ |_|/_/  |_|\____//_/    /_/ \____/ |__/|__/

    * Running on all addresses (0.0.0.0)
   ```

   &gt; If you skip this confirmation step and directly log in to RAGFlow, your browser may prompt a `network anormal`
   &gt; error because, at that moment, your RAGFlow may not be fully initialized.

5. In your web browser, enter the IP address of your server and log in to RAGFlow.
   &gt; With the default settings, you only need to enter `http://IP_OF_YOUR_MACHINE` (**sans** port number) as the default
   &gt; HTTP serving port `80` can be omitted when using the default configurations.
6. In [service_conf.yaml.template](./docker/service_conf.yaml.template), select the desired LLM factory in `user_default_llm` and update
   the `API_KEY` field with the corresponding API key.

   &gt; See [llm_api_key_setup](https://ragflow.io/docs/dev/llm_api_key_setup) for more information.

   _The show is on!_

## üîß Configurations

When it comes to system configurations, you will need to manage the following files:

- [.env](./docker/.env): Keeps the fundamental setups for the system, such as `SVR_HTTP_PORT`, `MYSQL_PASSWORD`, and
  `MINIO_PASSWORD`.
- [service_conf.yaml.template](./docker/service_conf.yaml.template): Configures the back-end services. The environment variables in this file will be automatically populated when the Docker container starts. Any environment variables set within the Docker container will be available for use, allowing you to customize service behavior based on the deployment environment.
- [docker-compose.yml](./docker/docker-compose.yml): The system relies on [docker-compose.yml](./docker/docker-compose.yml) to start up.

&gt; The [./docker/README](./docker/README.md) file provides a detailed description of the environment settings and service
&gt; configurations which can be used as `${ENV_VARS}` in the [service_conf.yaml.template](./docker/service_conf.yaml.template) file.

To update the default HTTP serving port (80), go to [docker-compose.yml](./docker/docker-compose.yml) and change `80:80`
to `&lt;YOUR_SERVING_PORT&gt;:80`.

Updates to the above configurations require a reboot of all containers to take effect:

&gt; ```bash
&gt; $ docker compose -f docker-compose.yml up -d
&gt; ```

### Switch doc engine from Elasticsearch to Infinity

RAGFlow uses Elasticsearch by default for storing full text and vectors. To switch to [Infinity](https://github.com/infiniflow/infinity/), follow these steps:

1. Stop all running containers:

   ```bash
   $ docker compose -f docker/docker-compose.yml down -v
   ```

&gt; [!WARNING]
&gt; `-v` will delete the docker container volumes, and the existing data will be cleared.

2. Set `DOC_ENGINE` in **docker/.env** to `infinity`.

3. Start the containers:

   ```bash
   $ docker compose -f docker-compose.yml up -d
   ```

&gt; [!WARNING]
&gt; Switching to Infinity on a Linux/arm64 machine is not yet officially supported.

## üîß Build a Docker image without embedding models

This image is approximately 2 GB in size and relies on external LLM and embedding services.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 --build-arg LIGHTEN=1 -f Dockerfile -t infiniflow/ragflow:nightly-slim .
```

## üîß Build a Docker image including embedding models

This image is approximately 9 GB in size. As it includes embedding models, it relies on external LLM services only.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 -f Dockerfile -t infiniflow/ragflow:nightly .
```

## üî® Launch service from source for development

1. Install uv, or skip this step if it is already installed:

   ```bash
   pipx install uv
   ```

2. Clone the source code and install Python dependencies:

   ```bash
   git clone https://github.com/infiniflow/ragflow.git
   cd ragflow/
   uv sync --python 3.10 --all-extras # install RAGFlow dependent python modules
   ```

3. Launch the dependent services (MinIO, Elasticsearch, Redis, and MySQL) using Docker Compose:

   ```bash
   docker compose -f docker/docker-compose-base.yml up -d
   ```

   Add the following line to `/etc/hosts` to resolve all hosts specified in **docker/.env** to `127.0.0.1`:

   ```
   127.0.0.1       es01 infinity mysql minio redis
   ```

4. If you cannot access HuggingFace, set the `HF_ENDPOINT` environment variable to use a mirror site:

   ```bash
   export HF_ENDPOINT=https://hf-mirror.com
   ```

5. Launch backend service:

   ```bash
   source .venv/bin/activate
   export PYTHONPATH=$(pwd)
   bash docker/launch_backend_service.sh
   ```

6. Install frontend dependencies:
   ```bash
   cd web
   npm install
   ```
7. Launch frontend service:

   ```bash
   npm run dev
   ```

   _The following output confirms a successful launch of the system:_

   ![](https://github.com/user-attachments/assets/0daf462c-a24d-4496-a66f-92533534e187)

## üìö Documentation

- [Quickstart](https://ragflow.io/docs/dev/)
- [Configuration](https://ragflow.io/docs/dev/configurations)
- [Release notes](https://ragflow.io/docs/dev/release_notes)
- [User guides](https://ragflow.io/docs/dev/category/guides)
- [Developer guides](https://ragflow.io/docs/dev/category/developers)
- [References](https://ragflow.io/docs/dev/category/references)
- [FAQs](https://ragflow.io/docs/dev/faq)

## üìú Roadmap

See the [RAGFlow Roadmap 2025](https://github.com/infiniflow/ragflow/issues/4214)

## üèÑ Community

- [Discord](https://discord.gg/NjYzJD3GM3)
- [Twitter](https://twitter.com/infiniflowai)
- [GitHub Discussions](https://github.com/orgs/infiniflow/discussions)

## üôå Contributing

RAGFlow flourishes via open-source collaboration. In this spirit, we embrace diverse contributions from the community.
If you would like to be a part, review our [Contribution Guidelines](./CONTRIBUTING.md) first.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[desktop/desktop]]></title>
            <link>https://github.com/desktop/desktop</link>
            <guid>https://github.com/desktop/desktop</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:38 GMT</pubDate>
            <description><![CDATA[Focus on what matters instead of fighting with Git.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/desktop/desktop">desktop/desktop</a></h1>
            <p>Focus on what matters instead of fighting with Git.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 20,412</p>
            <p>Forks: 9,615</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># [GitHub Desktop](https://desktop.github.com)

[GitHub Desktop](https://desktop.github.com/) is an open-source [Electron](https://www.electronjs.org/)-based
GitHub app. It is written in [TypeScript](https://www.typescriptlang.org) and
uses [React](https://reactjs.org/).

&lt;picture&gt;
  &lt;source
    srcset=&quot;https://user-images.githubusercontent.com/634063/202742848-63fa1488-6254-49b5-af7c-96a6b50ea8af.png&quot;
    media=&quot;(prefers-color-scheme: dark)&quot;
  /&gt;
  &lt;img
    width=&quot;1072&quot;
    src=&quot;https://user-images.githubusercontent.com/634063/202742985-bb3b3b94-8aca-404a-8d8a-fd6a6f030672.png&quot;
    alt=&quot;A screenshot of the GitHub Desktop application showing changes being viewed and committed with two attributed co-authors&quot;
  /&gt;
&lt;/picture&gt;

## Where can I get it?

Download the official installer for your operating system:

 - [macOS](https://central.github.com/deployments/desktop/desktop/latest/darwin)
 - [macOS (Apple silicon)](https://central.github.com/deployments/desktop/desktop/latest/darwin-arm64)
 - [Windows](https://central.github.com/deployments/desktop/desktop/latest/win32)
 - [Windows machine-wide install](https://central.github.com/deployments/desktop/desktop/latest/win32?format=msi)

Linux is not officially supported; however, you can find installers created for Linux from a fork of GitHub Desktop in the [Community Releases](https://github.com/desktop/desktop#community-releases) section.

### Beta Channel

Want to test out new features and get fixes before everyone else? Install the
beta channel to get access to early builds of Desktop:

 - [macOS](https://central.github.com/deployments/desktop/desktop/latest/darwin?env=beta)
 - [macOS (Apple silicon)](https://central.github.com/deployments/desktop/desktop/latest/darwin-arm64?env=beta)
 - [Windows](https://central.github.com/deployments/desktop/desktop/latest/win32?env=beta)
 - [Windows (ARM64)](https://central.github.com/deployments/desktop/desktop/latest/win32-arm64?env=beta)

The release notes for the latest beta versions are available [here](https://desktop.github.com/release-notes/?env=beta).

### Past Releases
You can find past releases at https://desktop.githubusercontent.com. After installation of a past version, the auto update functionality will attempt to download the latest version. 

### Community Releases

There are several community-supported package managers that can be used to
install GitHub Desktop:
 - Windows users can install using [winget](https://docs.microsoft.com/en-us/windows/package-manager/winget/) `c:\&gt; winget install github-desktop` or [Chocolatey](https://chocolatey.org/) `c:\&gt; choco install github-desktop`
 - macOS users can install using [Homebrew](https://brew.sh/) package manager:
      `$ brew install --cask github`

Installers for various Linux distributions can be found on the
[`shiftkey/desktop`](https://github.com/shiftkey/desktop) fork.

## Is GitHub Desktop right for me? What are the primary areas of focus?

[This document](https://github.com/desktop/desktop/blob/development/docs/process/what-is-desktop.md) describes the focus of GitHub Desktop and who the product is most useful for.

## I have a problem with GitHub Desktop

Note: The [GitHub Desktop Code of Conduct](https://github.com/desktop/desktop/blob/development/CODE_OF_CONDUCT.md) applies in all interactions relating to the GitHub Desktop project.

First, please search the [open issues](https://github.com/desktop/desktop/issues?q=is%3Aopen)
and [closed issues](https://github.com/desktop/desktop/issues?q=is%3Aclosed)
to see if your issue hasn&#039;t already been reported (it may also be fixed).

There is also a list of [known issues](https://github.com/desktop/desktop/blob/development/docs/known-issues.md)
that are being tracked against Desktop, and some of these issues have workarounds.

If you can&#039;t find an issue that matches what you&#039;re seeing, open a [new issue](https://github.com/desktop/desktop/issues/new/choose),
choose the right template and provide us with enough information to investigate
further.

## The issue I reported isn&#039;t fixed yet. What can I do?

If nobody has responded to your issue in a few days, you&#039;re welcome to respond to it with a friendly ping in the issue. Please do not respond more than a second time if nobody has responded. The GitHub Desktop maintainers are constrained in time and resources, and diagnosing individual configurations can be difficult and time consuming. While we&#039;ll try to at least get you pointed in the right direction, we can&#039;t guarantee we&#039;ll be able to dig too deeply into any one person&#039;s issue.

## How can I contribute to GitHub Desktop?

The [CONTRIBUTING.md](./.github/CONTRIBUTING.md) document will help you get setup and
familiar with the source. The [documentation](docs/) folder also contains more
resources relevant to the project.

If you&#039;re looking for something to work on, check out the [help wanted](https://github.com/desktop/desktop/issues?q=is%3Aissue+is%3Aopen+label%3A%22help%20wanted%22) label.

## Building Desktop

To setup your development environment for building Desktop, check out: [`setup.md`](./docs/contributing/setup.md).

## More Resources

See [desktop.github.com](https://desktop.github.com) for more product-oriented
information about GitHub Desktop.

See our [getting started documentation](https://docs.github.com/en/desktop/overview/getting-started-with-github-desktop) for more information on how to set up, authenticate, and configure GitHub Desktop.

## License

**[MIT](LICENSE)**

The MIT license grant is not for GitHub&#039;s trademarks, which include the logo
designs. GitHub reserves all trademark and copyright rights in and to all
GitHub trademarks. GitHub&#039;s logos include, for instance, the stylized
Invertocat designs that include &quot;logo&quot; in the file title in the following
folder: [logos](app/static/logos).

GitHub¬Æ and its stylized versions and the Invertocat mark are GitHub&#039;s
Trademarks or registered Trademarks. When using GitHub&#039;s logos, be sure to
follow the GitHub [logo guidelines](https://github.com/logos).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[cypress-io/cypress]]></title>
            <link>https://github.com/cypress-io/cypress</link>
            <guid>https://github.com/cypress-io/cypress</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[Fast, easy and reliable testing for anything that runs in a browser.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cypress-io/cypress">cypress-io/cypress</a></h1>
            <p>Fast, easy and reliable testing for anything that runs in a browser.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 48,521</p>
            <p>Forks: 3,280</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.cypress.io&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot;  srcset=&quot;./assets/cypress-logo-dark.png&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./assets/cypress-logo-light.png&quot;&gt;
      &lt;img alt=&quot;Cypress Logo&quot; src=&quot;./assets/cypress-logo-light.png&quot;&gt;
    &lt;/picture&gt;    
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://on.cypress.io&quot;&gt;Documentation&lt;/a&gt; |
  &lt;a href=&quot;https://on.cypress.io/changelog&quot;&gt;Changelog&lt;/a&gt; |
  &lt;a href=&quot;https://on.cypress.io/roadmap&quot;&gt;Roadmap&lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
  The web has evolved. Finally, testing has too.
&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
  Fast, easy and reliable testing for anything that runs in a browser.
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  Join us, we&#039;re &lt;a href=&quot;https://cypress.io/jobs&quot;&gt;hiring&lt;/a&gt;.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/cypress&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/dm/cypress.svg&quot; alt=&quot;npm&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://gitter.im/cypress-io/cypress&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/gitter/room/cypress-io/cypress.svg&quot; alt=&quot;Gitter chat&quot;/&gt;
  &lt;/a&gt;
    &lt;a href=&quot;https://stackshare.io/cypress&quot;&gt;
    &lt;img src=&quot;https://img.stackshare.io/misc/follow-on-stackshare-badge.svg&quot; alt=&quot;StackShare&quot;/&gt;
  &lt;/a&gt;&lt;br /&gt;
&lt;/p&gt;

## What is Cypress?

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://player.vimeo.com/video/237527670&quot;&gt;
    &lt;img alt=&quot;Why Cypress Video&quot; src=&quot;https://user-images.githubusercontent.com/1271364/31739717-dbdff0ee-b41c-11e7-9b16-bfa1b6ac1814.png&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## Installing

[![npm version](https://badge.fury.io/js/cypress.svg)](https://badge.fury.io/js/cypress)

Install Cypress for Mac, Linux, or Windows, then [get started](https://on.cypress.io/install).

```bash
npm install cypress --save-dev
```
or
```bash
yarn add cypress --dev
```

![installing-cli e1693232](https://user-images.githubusercontent.com/1271364/31740846-7bf607f0-b420-11e7-855f-41c996040d31.gif)


## Contributing

- [![CircleCI](https://circleci.com/gh/cypress-io/cypress/tree/develop.svg?style=svg)](https://circleci.com/gh/cypress-io/cypress/tree/develop) - `develop` branch
- [![CircleCI](https://circleci.com/gh/cypress-io/cypress/tree/master.svg?style=svg)](https://circleci.com/gh/cypress-io/cypress/tree/master) - `master` branch

Please see our [Contributing Guideline](./CONTRIBUTING.md) which explains repo organization, linting, testing, and other steps.

## License

[![license](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/cypress-io/cypress/blob/master/LICENSE)

This project is licensed under the terms of the [MIT license](/LICENSE).

## Badges

Let the world know your project is using Cypress.io to test with this cool badge

[![Cypress.io](https://img.shields.io/badge/tested%20with-Cypress-04C38E.svg)](https://www.cypress.io/)

```
[![Cypress.io](https://img.shields.io/badge/tested%20with-Cypress-04C38E.svg)](https://www.cypress.io/)
```
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[transformerlab/transformerlab-app]]></title>
            <link>https://github.com/transformerlab/transformerlab-app</link>
            <guid>https://github.com/transformerlab/transformerlab-app</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[Open Source Application for Advanced LLM Engineering: interact, train, fine-tune, and evaluate large language models on your own computer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/transformerlab/transformerlab-app">transformerlab/transformerlab-app</a></h1>
            <p>Open Source Application for Advanced LLM Engineering: interact, train, fine-tune, and evaluate large language models on your own computer.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,957</p>
            <p>Forks: 106</p>
            <p>Stars today: 50 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://transformerlab.ai&quot;&gt;&lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/transformerlab/transformerlab-app/refs/heads/main/assets/Transformer-Lab_Logo_Reverse.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/transformerlab/transformerlab-app/refs/heads/main/assets/Transformer-Lab_Logo.svg&quot;&gt;
    &lt;img alt=&quot;transformer lab logo&quot; src=&quot;https://raw.githubusercontent.com/transformerlab/transformerlab-app/refs/heads/main/assets/Transformer-Lab_Logo.svg&quot; style=&quot;max-width: 650px&quot;&gt;
  &lt;/picture&gt;&lt;/a&gt;

  &lt;p align=&quot;center&quot;&gt;
    100% Open Source Toolkit for Large Language Models: Train, Tune, Chat on your own Machine
    &lt;br /&gt;
    &lt;a href=&quot;https://transformerlab.ai/docs/download/&quot;&gt;&lt;strong&gt;Download&lt;/strong&gt;&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://transformerlab.ai/docs/intro&quot;&gt;&lt;strong&gt;Explore the docs ¬ª&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://youtu.be/tY5TAvKviLo&quot;&gt;View Demo&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/transformerlab/transformerlab-app/issues&quot;&gt;Report Bugs&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/transformerlab/transformerlab-app/issues/new&quot;&gt;Suggest Features&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://discord.gg/transformerlab&quot;&gt;Join Discord&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://twitter.com/transformerlab&quot;&gt;Follow on Twitter&lt;/a&gt;
  &lt;/p&gt;
  &lt;p align=&quot;center&quot;&gt;
   Note: Transformer Lab is actively being developed. Please join our Discord or follow us on Twitter for updates. Questions, feedback and contributions are highly valued!&lt;/p&gt;
&lt;/div&gt;

&lt;!-- ABOUT THE PROJECT --&gt;

## Download Now

[![Download Icon]][Download URL]

## About The Project

![Product Screen Shot](assets/transformerlab-demo-jan2025.gif)

Transformer Lab is an app that allows anyone to experiment with Large Language Models.

## Backed by Mozilla

Transformer Lab is proud to be supported by Mozilla through the &lt;a href=&quot;https://future.mozilla.org/builders/&quot;&gt;Mozilla Builders Program&lt;/a&gt;

&lt;a href=&quot;https://future.mozilla.org/builders/&quot;&gt;
    &lt;img src=&quot;https://transformerlab.ai/img/mozilla-builders-2024.png&quot; alt=&quot;Mozilla Builders Logo&quot; width=300&gt;
&lt;/a&gt;

## Features

Transformer Lab allows you to:

- üíï **One-click Download Hundreds of Popular Models**:
  - DeepSeek, Llama3, Qwen, Phi4, Gemma, Mistral, Mixtral, Command-R, and dozens more
- ‚¨á **Download any LLM from Huggingface**
- üé∂ **Finetune / Train Across Different Hardware**
  - Finetune using MLX on Apple Silicon
  - Finetune using Huggingface on GPU
- ‚öñÔ∏è **RLHF and Preference Optimization**
  - DPO
  - ORPO
  - SIMPO
  - Reward Modeling
- üíª **Work with LLMs Across Operating Systems**:
  - Windows App
  - MacOS App
  - Linux
- üí¨ **Chat with Models**
  - Chat
  - Completions
  - Preset (Templated) Prompts
  - Chat History
  - Tweak generation parameters
  - Batched Inference
  - Tool Use / Function Calling (in alpha)
- üöÇ **Use Different Inference Engines**
  - MLX on Apple Silicon
  - Huggingface Transformers
  - vLLM
  - Llama CPP
- üßë‚Äçüéì **Evaluate models**
- üìñ **RAG (Retreival Augmented Generation)**
  - Drag and Drop File UI
  - Works on Apple MLX, Transformers, and other engines
- üìì **Build Datasets for Training**
  - Pull from hundreds of common datasets available on HuggingFace
  - Provide your own dataset using drag and drop
- üî¢ **Calculate Embeddings**
- üíÅ **Full REST API**
- üå© **Run in the Cloud**
  - You can run the user interface on your desktop/laptop while the engine runs on a remote or cloud machine
  - Or you can run everything locally on a single machine
- üîÄ **Convert Models Across Platforms**
  - Convert from/to Huggingface, MLX, GGUF
- üîå **Plugin Support**
  - Easily pull from a library of existing plugins
  - Write your own plugins to extend functionality
- üßë‚Äçüíª **Embedded Monaco Code Editor**
  - Edit plugins and view what&#039;s happening behind the scenes
- üìù **Prompt Editing**
  - Easily edit System Messages or Prompt Templates
- üìú **Inference Logs**
  - While doing inference or RAG, view a log of the raw queries sent to the LLM

And you can do the above, all through a simple cross-platform GUI.

&lt;!-- GETTING STARTED --&gt;

## Getting Started

&lt;a href=&quot;https://transformerlab.ai/docs/download&quot;&gt;Click here&lt;/a&gt; to download Transformer Lab.

&lt;a href=&quot;https://transformerlab.ai/docs/intro&quot;&gt;Read this page&lt;/a&gt; to learn how to install and use.

### Built With

- [![Electron][Electron]][Electron-url]
- [![React][React.js]][React-url]
- [![HuggingFace][HuggingFace]][HuggingFace-url]

## Developers

### Building from Scratch

To build the app yourself, pull this repo, and follow the steps below:

(Please note that the current build doesn&#039;t work on Node v23 but it works on v22)

```bash
npm install
```

```bash
npm start
```

## Packaging for Production

To package apps for the local platform:

```bash
npm run package
```

&lt;!-- LICENSE --&gt;

## License

Distributed under the AGPL V3 License. See `LICENSE.txt` for more information.

## Reference

If you found Transformer Lab useful in your research or applications, please cite using the following BibTeX:

```
@software{transformerlab,
  author = {Asaria, Ali},
  title = {Transformer Lab: Experiment with Large Language Models},
  month = December,
  year = 2023,
  url = {https://github.com/transformerlab/transformerlab-app}
}
```

&lt;!-- CONTACT --&gt;

## Contact

- [@aliasaria](https://twitter.com/aliasaria) - Ali Asasria
- [@dadmobile](https://github.com/dadmobile) - Tony Salomone

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;

[product-screenshot]: https://transformerlab.ai/assets/images/screenshot01-53ecb8c52338db3c9246cf2ebbbdc40d.png
[React.js]: https://img.shields.io/badge/React-20232A?style=for-the-badge&amp;logo=react&amp;logoColor=61DAFB
[React-url]: https://reactjs.org/
[Electron]: https://img.shields.io/badge/Electron-20232A?style=for-the-badge&amp;logo=electron&amp;logoColor=61DAFB
[Electron-url]: https://www.electronjs.org/
[HuggingFace]: https://img.shields.io/badge/ü§ó_HuggingFace-20232A?style=for-the-badge
[HuggingFace-url]: https://huggingface.co/
[Download Icon]: https://img.shields.io/badge/Download-EF2D5E?style=for-the-badge&amp;logoColor=white&amp;logo=DocuSign
[Download URL]: https://transformerlab.ai/docs/download
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[adobe/react-spectrum]]></title>
            <link>https://github.com/adobe/react-spectrum</link>
            <guid>https://github.com/adobe/react-spectrum</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:35 GMT</pubDate>
            <description><![CDATA[A collection of libraries and tools that help you build adaptive, accessible, and robust user experiences.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/adobe/react-spectrum">adobe/react-spectrum</a></h1>
            <p>A collection of libraries and tools that help you build adaptive, accessible, and robust user experiences.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 13,768</p>
            <p>Forks: 1,228</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>#  [React Spectrum Libraries](https://react-spectrum.adobe.com/)

A collection of libraries and tools that help you build adaptive, accessible, and robust user experiences.

### React Spectrum

A React implementation of Spectrum, Adobe‚Äôs design system. Spectrum provides adaptive, accessible, and cohesive experiences for all Adobe applications.

[Explore React Spectrum](https://react-spectrum.adobe.com/react-spectrum/index.html)

### React Aria

A library of unstyled React components and hooks that helps you build accessible, high quality UI components for your application or design system.

[Learn more about React Aria](https://react-spectrum.adobe.com/react-aria/index.html)

### React Stately

A library of React Hooks that provides cross-platform state management for your design system.

[More information about React Stately](https://react-spectrum.adobe.com/react-stately/index.html)

### Internationalized

A collection of framework-agnostic internationalization libraries for the web.

[Internationalized Packages](https://react-spectrum.adobe.com/internationalized/index.html)

## Features

* ‚ôøÔ∏è **[Accessible](https://react-spectrum.adobe.com/react-aria/accessibility.html)** ‚Äì Accessibility and behavior is implemented according to [WAI-ARIA Authoring Practices](https://www.w3.org/TR/wai-aria-practices-1.2/), including full screen reader and keyboard navigation support. All components have been tested across a wide variety of screen readers and devices to ensure the best experience possible for all users.
* üì± **[Adaptive](https://react-spectrum.adobe.com/react-aria/interactions.html)** ‚Äì All components are designed to work with mouse, touch, and keyboard interactions. They‚Äôre built with responsive design principles to deliver a great experience, no matter the device.
* üåç **[International](https://react-spectrum.adobe.com/react-aria/internationalization.html)** ‚Äì Support over 30 languages is included out of the box, including support for right-to-left languages, date and number formatting, and more.
* üé® **[Customizable](https://react-spectrum.adobe.com/react-spectrum/theming.html)** ‚Äì React Spectrum components support custom themes, and automatically adapt for dark mode. For even more customizability, you can build your own components with your own DOM structure and styling using the [React Aria](https://react-spectrum.adobe.com/react-aria/index.html) and [React Stately](https://react-spectrum.adobe.com/react-stately/index.html) hooks to provide behavior, accessibility, and interactions.

## Getting started

React Spectrum includes several libraries, which you can choose depending on your usecase.

* [React Spectrum](https://react-spectrum.adobe.com/react-spectrum/getting-started.html) is an implementation of Adobe&#039;s design system. If you‚Äôre integrating with Adobe software or would like a complete component library to use in your project, look no further!
* [React Aria](https://react-spectrum.adobe.com/react-aria/getting-started.html) is a collection of unstyled React components and hooks that helps you build accessible, high quality UI components for your own application or design system. If you&#039;re building a component library for the web from scratch with your own styling, start here.
* [React Stately](https://react-spectrum.adobe.com/react-stately/getting-started.html) is a library of state management hooks for use in your component library. If you&#039;re using React Aria, you&#039;ll likely also use React Stately, but it can also be used independently (e.g. on other platforms like React Native).

[Read more about our architecture](https://react-spectrum.adobe.com/architecture.html).

## Contributing

One of the goals of the React Spectrum project is to make building design systems and component libraries as easy as possible, while maintaining high quality interactions and accessibility support. We aim to raise the bar for web applications. The best way to achieve that goal is **together**. We would love contributions from the community no matter how big or small. üòç

Read our [contributing guide](https://react-spectrum.adobe.com/contribute.html) to learn about how to propose bugfixes and improvements, and how the development process works. For detailed information about our architecture, and how all of the pieces fit together, read our [architecture docs](https://react-spectrum.adobe.com/architecture.html).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[cline/cline]]></title>
            <link>https://github.com/cline/cline</link>
            <guid>https://github.com/cline/cline</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[Autonomous coding agent right in your IDE, capable of creating/editing files, executing commands, using the browser, and more with your permission every step of the way.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cline/cline">cline/cline</a></h1>
            <p>Autonomous coding agent right in your IDE, capable of creating/editing files, executing commands, using the browser, and more with your permission every step of the way.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 40,356</p>
            <p>Forks: 4,441</p>
            <p>Stars today: 207 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;sub&gt;
English | &lt;a href=&quot;https://github.com/cline/cline/blob/main/locales/es/README.md&quot; target=&quot;_blank&quot;&gt;Espa√±ol&lt;/a&gt; | &lt;a href=&quot;https://github.com/cline/cline/blob/main/locales/de/README.md&quot; target=&quot;_blank&quot;&gt;Deutsch&lt;/a&gt; | &lt;a href=&quot;https://github.com/cline/cline/blob/main/locales/ja/README.md&quot; target=&quot;_blank&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href=&quot;https://github.com/cline/cline/blob/main/locales/zh-cn/README.md&quot; target=&quot;_blank&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href=&quot;https://github.com/cline/cline/blob/main/locales/zh-tw/README.md&quot; target=&quot;_blank&quot;&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href=&quot;https://github.com/cline/cline/blob/main/locales/ko/README.md&quot; target=&quot;_blank&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;
&lt;/sub&gt;&lt;/div&gt;

# Cline ‚Äì \#1 on OpenRouter

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://media.githubusercontent.com/media/cline/cline/main/assets/docs/demo.gif&quot; width=&quot;100%&quot; /&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Download on VS Marketplace&lt;/strong&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;https://discord.gg/cline&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Discord&lt;/strong&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.reddit.com/r/cline/&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;r/cline&lt;/strong&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/cline/cline/discussions/categories/feature-requests?discussions_q=is%3Aopen+category%3A%22Feature+Requests%22+sort%3Atop&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Feature Requests&lt;/strong&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;https://docs.cline.bot/getting-started/for-new-coders&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Getting Started&lt;/strong&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

Meet Cline, an AI assistant that can use your **CLI** a**N**d **E**ditor.

Thanks to¬†[Claude 3.7 Sonnet&#039;s agentic coding capabilities](https://www.anthropic.com/claude/sonnet),¬†Cline can handle complex software development tasks step-by-step. With tools that let him create &amp; edit files, explore large projects, use the browser, and execute terminal commands (after you grant permission), he can assist you in ways that go beyond code completion or tech support. Cline can even use the Model Context Protocol (MCP) to create new tools and extend his own capabilities. While autonomous AI scripts traditionally run in sandboxed environments, this extension provides a human-in-the-loop GUI to approve every file change and terminal command, providing a safe and accessible way to explore the potential of agentic AI.

1. Enter your task and add images to convert mockups into functional apps or fix bugs with screenshots.
2. Cline starts by analyzing your file structure &amp; source code ASTs, running regex searches, and reading relevant files to get up to speed in existing projects. By carefully managing what information is added to context, Cline can provide valuable assistance even for large, complex projects without overwhelming the context window.
3. Once Cline has the information he needs, he can:
    - Create and edit files + monitor linter/compiler errors along the way, letting him proactively fix issues like missing imports and syntax errors on his own.
    - Execute commands directly in your terminal and monitor their output as he works, letting him e.g., react to dev server issues after editing a file.
    - For web development tasks, Cline can launch the site in a headless browser, click, type, scroll, and capture screenshots + console logs, allowing him to fix runtime errors and visual bugs.
4. When a task is completed, Cline will present the result to you with a terminal command like¬†`open -a &quot;Google Chrome&quot; index.html`, which you run with a click of a button.

&gt; [!TIP]
&gt; Use the¬†`CMD/CTRL + Shift + P`¬†shortcut to open the command palette and type¬†&quot;Cline: Open In New Tab&quot;¬†to open the extension as a tab in your editor. This lets you use Cline side-by-side with your file explorer, and see how he changes your workspace more clearly.

---

&lt;img align=&quot;right&quot; width=&quot;340&quot; src=&quot;https://github.com/user-attachments/assets/3cf21e04-7ce9-4d22-a7b9-ba2c595e88a4&quot;&gt;

### Use any API and Model

Cline supports API providers like OpenRouter, Anthropic, OpenAI, Google Gemini, AWS Bedrock, Azure, and GCP Vertex. You can also configure any OpenAI compatible API, or use a local model through LM Studio/Ollama. If you&#039;re using OpenRouter, the extension fetches their latest model list, allowing you to use the newest models as soon as they&#039;re available.

The extension also keeps track of total tokens and API usage cost for the entire task loop and individual requests, keeping you informed of spend every step of the way.

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

&lt;img align=&quot;left&quot; width=&quot;370&quot; src=&quot;https://github.com/user-attachments/assets/81be79a8-1fdb-4028-9129-5fe055e01e76&quot;&gt;

### Run Commands in Terminal

Thanks to the new [shell integration updates in VSCode v1.93](https://code.visualstudio.com/updates/v1_93#_terminal-shell-integration-api), Cline can execute commands directly in your terminal and receive the output. This allows him to perform a wide range of tasks, from installing packages and running build scripts to deploying applications, managing databases, and executing tests, all while adapting to your dev environment &amp; toolchain to get the job done right.

For long running processes like dev servers, use the &quot;Proceed While Running&quot; button to let Cline continue in the task while the command runs in the background. As Cline works he‚Äôll be notified of any new terminal output along the way, letting him react to issues that may come up, such as compile-time errors when editing files.

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

&lt;img align=&quot;right&quot; width=&quot;400&quot; src=&quot;https://github.com/user-attachments/assets/c5977833-d9b8-491e-90f9-05f9cd38c588&quot;&gt;

### Create and Edit Files

Cline can create and edit files directly in your editor, presenting you a diff view of the changes. You can edit or revert Cline&#039;s changes directly in the diff view editor, or provide feedback in chat until you&#039;re satisfied with the result. Cline also monitors linter/compiler errors (missing imports, syntax errors, etc.) so he can fix issues that come up along the way on his own.

All changes made by Cline are recorded in your file&#039;s Timeline, providing an easy way to track and revert modifications if needed.

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

&lt;img align=&quot;left&quot; width=&quot;370&quot; src=&quot;https://github.com/user-attachments/assets/bc2e85ba-dfeb-4fe6-9942-7cfc4703cbe5&quot;&gt;

### Use the Browser

With Claude 3.5 Sonnet&#039;s new [Computer Use](https://www.anthropic.com/news/3-5-models-and-computer-use) capability, Cline can launch a browser, click elements, type text, and scroll, capturing screenshots and console logs at each step. This allows for interactive debugging, end-to-end testing, and even general web use! This gives him autonomy to fixing visual bugs and runtime issues without you needing to handhold and copy-pasting error logs yourself.

Try asking Cline to &quot;test the app&quot;, and watch as he runs a command like `npm run dev`, launches your locally running dev server in a browser, and performs a series of tests to confirm that everything works. [See a demo here.](https://x.com/sdrzn/status/1850880547825823989)

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

&lt;img align=&quot;right&quot; width=&quot;350&quot; src=&quot;https://github.com/user-attachments/assets/ac0efa14-5c1f-4c26-a42d-9d7c56f5fadd&quot;&gt;

### &quot;add a tool that...&quot;

Thanks to the [Model Context Protocol](https://github.com/modelcontextprotocol), Cline can extend his capabilities through custom tools. While you can use [community-made servers](https://github.com/modelcontextprotocol/servers), Cline can instead create and install tools tailored to your specific workflow. Just ask Cline to &quot;add a tool&quot; and he will handle everything, from creating a new MCP server to installing it into the extension. These custom tools then become part of Cline&#039;s toolkit, ready to use in future tasks.

-   &quot;add a tool that fetches Jira tickets&quot;: Retrieve ticket ACs and put Cline to work
-   &quot;add a tool that manages AWS EC2s&quot;: Check server metrics and scale instances up or down
-   &quot;add a tool that pulls the latest PagerDuty incidents&quot;: Fetch details and ask Cline to fix bugs

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

&lt;img align=&quot;left&quot; width=&quot;360&quot; src=&quot;https://github.com/user-attachments/assets/7fdf41e6-281a-4b4b-ac19-020b838b6970&quot;&gt;

### Add Context

**`@url`:**¬†Paste in a URL for the extension to fetch and convert to markdown, useful when you want to give Cline the latest docs

**`@problems`:**¬†Add workspace errors and warnings (&#039;Problems&#039; panel) for Cline to fix

**`@file`:**¬†Adds a file&#039;s contents so you don&#039;t have to waste API requests approving read file (+ type to search files)

**`@folder`:**¬†Adds folder&#039;s files all at once to speed up your workflow even more

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

&lt;img align=&quot;right&quot; width=&quot;350&quot; src=&quot;https://github.com/user-attachments/assets/140c8606-d3bf-41b9-9a1f-4dbf0d4c90cb&quot;&gt;

### Checkpoints: Compare and Restore

As Cline works through a task, the extension takes a snapshot of your workspace at each step. You can use the &#039;Compare&#039; button to see a diff between the snapshot and your current workspace, and the &#039;Restore&#039; button to roll back to that point.

For example, when working with a local web server, you can use &#039;Restore Workspace Only&#039; to quickly test different versions of your app, then use &#039;Restore Task and Workspace&#039; when you find the version you want to continue building from. This lets you safely explore different approaches without losing progress.

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

## Contributing

To contribute to the project, start with our [Contributing Guide](CONTRIBUTING.md) to learn the basics. You can also join our [Discord](https://discord.gg/cline) to chat with other contributors in the `#contributors` channel. If you&#039;re looking for full-time work, check out our open positions on our [careers page](https://cline.bot/join-us)!

&lt;details&gt;
&lt;summary&gt;Local Development Instructions&lt;/summary&gt;

1. Clone the repository _(Requires [git-lfs](https://git-lfs.com/))_:
    ```bash
    git clone https://github.com/cline/cline.git
    ```
2. Open the project in VSCode:
    ```bash
    code cline
    ```
3. Install the necessary dependencies for the extension and webview-gui:
    ```bash
    npm run install:all
    ```
4. Launch by pressing `F5` (or `Run`-&gt;`Start Debugging`) to open a new VSCode window with the extension loaded. (You may need to install the [esbuild problem matchers extension](https://marketplace.visualstudio.com/items?itemName=connor4312.esbuild-problem-matchers) if you run into issues building the project.)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Creating a Pull Request&lt;/summary&gt;

1. Before creating a PR, generate a changeset entry:
    ```bash
    npm run changeset
    ```
   This will prompt you for:
   - Type of change (major, minor, patch)
     - `major` ‚Üí breaking changes (1.0.0 ‚Üí 2.0.0)
     - `minor` ‚Üí new features (1.0.0 ‚Üí 1.1.0)
     - `patch` ‚Üí bug fixes (1.0.0 ‚Üí 1.0.1)
   - Description of your changes

2. Commit your changes and the generated `.changeset` file

3. Push your branch and create a PR on GitHub. Our CI will:
   - Run tests and checks
   - Changesetbot will create a comment showing the version impact
   - When merged to main, changesetbot will create a Version Packages PR
   - When the Version Packages PR is merged, a new release will be published

&lt;/details&gt;


## License

[Apache 2.0 ¬© 2025 Cline Bot Inc.](./LICENSE)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[maplibre/maplibre-gl-js]]></title>
            <link>https://github.com/maplibre/maplibre-gl-js</link>
            <guid>https://github.com/maplibre/maplibre-gl-js</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[MapLibre GL JS - Interactive vector tile maps in the browser]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/maplibre/maplibre-gl-js">maplibre/maplibre-gl-js</a></h1>
            <p>MapLibre GL JS - Interactive vector tile maps in the browser</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,469</p>
            <p>Forks: 820</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://maplibre.org/img/maplibre-logo-big.svg&quot; alt=&quot;MapLibre Logo&quot;&gt;
&lt;/p&gt;

# MapLibre GL JS

[![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg?style=flat)](LICENSE.txt) [![Version](https://img.shields.io/npm/v/maplibre-gl?style=flat)](https://www.npmjs.com/package/maplibre-gl) [![CI](https://github.com/maplibre/maplibre-gl-js/actions/workflows/test-all.yml/badge.svg)](https://github.com/maplibre/maplibre-gl-js/actions/workflows/test-all.yml) [![PRs](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat)](https://opensource.org/licenses/BSD-3-Clause) [![codecov](https://codecov.io/gh/maplibre/maplibre-gl-js/branch/main/graph/badge.svg)](https://codecov.io/gh/maplibre/maplibre-gl-js)

**[MapLibre GL JS](https://maplibre.org/maplibre-gl-js/docs/API/)** is an open-source library for publishing maps on your websites or webview based apps. Fast displaying of maps is possible thanks to GPU-accelerated vector tile rendering.

It originated as an open-source fork of [mapbox-gl-js](https://github.com/mapbox/mapbox-gl-js), before their switch to a non-OSS license in December 2020. The library&#039;s initial versions (1.x) were intended to be a drop-in replacement for the Mapbox‚Äôs OSS version (1.x) with additional functionality, but have evolved a lot since then.

## Getting Started

Include the JavaScript and CSS files in the `&lt;head&gt;` of your HTML file.

```html
&lt;script src=&#039;https://unpkg.com/maplibre-gl@latest/dist/maplibre-gl.js&#039;&gt;&lt;/script&gt;
&lt;link href=&#039;https://unpkg.com/maplibre-gl@latest/dist/maplibre-gl.css&#039; rel=&#039;stylesheet&#039; /&gt;
```

Include the following code in the `&lt;body&gt;` of your HTML file.

```html
&lt;div id=&#039;map&#039; style=&#039;width: 400px; height: 300px;&#039;&gt;&lt;/div&gt;
&lt;script&gt;
var map = new maplibregl.Map({
  container: &#039;map&#039;,
  style: &#039;https://demotiles.maplibre.org/style.json&#039;, // stylesheet location
  center: [-74.5, 40], // starting position [lng, lat]
  zoom: 9 // starting zoom
});
&lt;/script&gt;
```

Enjoy the map!

&lt;br /&gt;

## Documentation

Full documentation for this library [is available here](https://maplibre.org/maplibre-gl-js/docs/API/).

Check out the features through [examples](https://maplibre.org/maplibre-gl-js/docs/examples/).

| Showcases |      |
| ---- | ---- |
|![Display a map](https://maplibre.org/maplibre-gl-js/docs/assets/examples/simple-map.png)	|![Third party vector tile source](https://maplibre.org/maplibre-gl-js/docs/assets/examples/3d-terrain.png)	|
|![Animate a series of images](https://maplibre.org/maplibre-gl-js/docs/assets/examples/animate-images.png)	|![Create a heatmap layer](https://maplibre.org/maplibre-gl-js/docs/assets/examples/heatmap-layer.png)	|
|![3D buildings](https://maplibre.org/maplibre-gl-js/docs/assets/examples/3d-buildings.png)	|![Visualize population density](https://maplibre.org/maplibre-gl-js/docs/assets/examples/visualize-population-density.png)	|

&lt;br /&gt;

Want an example? Have a look at the official [MapLibre GL JS Documentation](https://maplibre.org/maplibre-gl-js/docs/examples/).

Use MapLibre GL JS bindings for [React](https://visgl.github.io/react-map-gl/docs/get-started) and [Angular](https://github.com/maplibre/ngx-maplibre-gl). Find more at [awesome-maplibre](https://github.com/maplibre/awesome-maplibre).

&lt;br /&gt;

## Contribution

### Getting Involved

Join the #maplibre slack channel at OSMUS: get an invite at https://slack.openstreetmap.us/
Read the [CONTRIBUTING.md](CONTRIBUTING.md) guide in order to get familiar with how we do things around here.

### Avoid Fragmentation

If you depend on a free software alternative to `mapbox-gl-js`, please consider joining our effort! Anyone with a stake in a healthy community-led fork is welcome to help us figure out our next steps. We welcome contributors and leaders! MapLibre GL JS already represents the combined efforts of a few early fork efforts, and we all benefit from &quot;one project&quot; rather than &quot;our way&quot;. If you know of other forks, please reach out to them and direct them here.

&gt; **MapLibre GL JS** is developed following¬†[Semantic Versioning (2.0.0)](https://semver.org/spec/v2.0.0.html).

### Bounties

We offer Bounties for some tasks in the MapLibre GL JS repo. Read more about the Bounties in our step-by-step guide:

https://maplibre.org/roadmap/step-by-step-bounties-guide/

And find all currently published Bounties in MapLibre GL JS [here](https://github.com/maplibre/maplibre-gl-js/issues?q=is%3Aissue+is%3Aopen+label%3A%22%F0%9F%92%B0+bounty+L%22%2C%22%F0%9F%92%B0+bounty+S%22%2C%22%F0%9F%92%B0+bounty+M%22%2C%22%F0%9F%92%B0+bounty+XL%22%2C%22%F0%9F%92%B0+bounty+XXL%22+).

&lt;br /&gt;

## Sponsors

We thank everyone who supported us financially in the past and special thanks to the people and organizations who support us with recurring donations!

Read more about the MapLibre Sponsorship Program at [https://maplibre.org/sponsors/](https://maplibre.org/sponsors/).

Gold:

&lt;a href=&quot;https://aws.amazon.com/location&quot;&gt;&lt;img src=&quot;https://maplibre.org/img/aws-logo.svg&quot; alt=&quot;Logo AWS&quot; width=&quot;25%&quot;/&gt;&lt;/a&gt;

&lt;a href=&quot;https://meta.com&quot;&gt;&lt;img src=&quot;https://maplibre.org/img/meta-logo.svg&quot; alt=&quot;Logo Meta&quot; width=&quot;25%&quot;/&gt;&lt;/a&gt;

Silver:

&lt;a href=&quot;https://www.mierune.co.jp/?lang=en&quot;&gt;&lt;img src=&quot;https://maplibre.org/img/mierune-logo.svg&quot; alt=&quot;Logo MIERUNE&quot; width=&quot;25%&quot;/&gt;&lt;/a&gt;

&lt;a href=&quot;https://komoot.com/&quot;&gt;&lt;img src=&quot;https://maplibre.org/img/komoot-logo.svg&quot; alt=&quot;Logo komoot&quot; width=&quot;25%&quot;/&gt;&lt;/a&gt;

&lt;a href=&quot;https://www.jawg.io/&quot;&gt;&lt;img src=&quot;https://maplibre.org/img/jawgmaps-logo.svg&quot; alt=&quot;Logo JawgMaps&quot; width=&quot;25%&quot;/&gt;&lt;/a&gt;

&lt;a href=&quot;https://www.radar.com/&quot;&gt;&lt;img src=&quot;https://maplibre.org/img/radar-logo.svg&quot; alt=&quot;Logo Radar&quot; width=&quot;25%&quot;/&gt;&lt;/a&gt;

&lt;a href=&quot;https://www.microsoft.com/&quot;&gt;&lt;img src=&quot;https://maplibre.org/img/msft-logo.svg&quot; alt=&quot;Logo MSFT&quot; width=&quot;25%&quot;/&gt;&lt;/a&gt;

&lt;a href=&quot;https://www.mappedin.com/&quot;&gt;&lt;img src=&quot;https://maplibre.org/img/mappedin-logo.svg&quot; alt=&quot;Logo mappedin&quot; width=&quot;25%&quot;/&gt;&lt;/a&gt;

&lt;a href=&quot;https://www.mapme.com/&quot;&gt;&lt;img src=&quot;https://maplibre.org/img/mapme-logo.svg&quot; alt=&quot;Logo mapme&quot; width=&quot;25%&quot;/&gt;&lt;/a&gt;

&lt;a href=&quot;https://www.maptiler.com/&quot;&gt;&lt;img src=&quot;https://maplibre.org/img/maptiler-logo.svg&quot; alt=&quot;Logo maptiler&quot; width=&quot;25%&quot;/&gt;&lt;/a&gt;

Backers and Supporters:

&lt;a href=&quot;https://opencollective.com/maplibre/backer/0/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/0/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/1/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/1/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/2/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/2/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/3/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/3/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/4/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/4/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/5/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/5/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/6/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/6/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/7/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/7/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/8/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/8/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/9/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/9/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/10/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/10/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/11/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/11/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/12/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/12/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/13/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/13/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/14/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/14/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/15/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/15/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/16/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/16/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/17/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/17/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/18/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/18/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/19/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/19/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/20/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/20/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/21/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/21/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/22/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/22/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/23/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/23/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/24/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/24/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/25/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/25/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/26/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/26/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/27/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/27/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/28/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/28/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/29/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/29/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/maplibre/backer/30/website?requireActive=false&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/maplibre/backer/30/avatar.svg?requireActive=false&quot;&gt;&lt;/a&gt;

&lt;br /&gt;

## Thank you Mapbox üôèüèΩ

We&#039;d like to acknowledge the amazing work Mapbox has contributed to open source. The open source community is sad to part ways with them, but we simultaneously feel grateful for everything they already contributed. `mapbox-gl-js` 1.x is an open source achievement that now lives on as `maplibre-gl`. We&#039;re proud to develop on the shoulders of giants, thank you Mapbox üôáüèΩ‚Äç‚ôÄÔ∏è.

Please keep in mind: Unauthorized backports are the biggest threat to the MapLibre project. It is unacceptable to backport code from mapbox-gl-js, which is not covered by the former BSD-3 license. If you are unsure about this issue, [please ask](https://github.com/maplibre/maplibre-gl-js/discussions)!

&lt;br /&gt;

## License

**MapLibre GL JS** is licensed under the [3-Clause BSD license](./LICENSE.txt).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[miurla/morphic]]></title>
            <link>https://github.com/miurla/morphic</link>
            <guid>https://github.com/miurla/morphic</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[An AI-powered search engine with a generative UI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/miurla/morphic">miurla/morphic</a></h1>
            <p>An AI-powered search engine with a generative UI</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,332</p>
            <p>Forks: 1,976</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># Morphic

An AI-powered search engine with a generative UI.

![capture](/public/screenshot-2025-01-31.png)

## üóÇÔ∏è Overview

- üõ† [Features](#-features)
- üß± [Stack](#-stack)
- üöÄ [Quickstart](#-quickstart)
- üåê [Deploy](#-deploy)
- üîé [Search Engine](#-search-engine)
- ‚úÖ [Verified models](#-verified-models)
- ‚ö° [AI SDK Implementation](#-ai-sdk-implementation)
- üì¶ [Open Source vs Cloud Offering](#-open-source-vs-cloud-offering)
- üë• [Contributing](#-contributing)

## üõ† Features

### Core Features

- AI-powered search with GenerativeUI
- Natural language question understanding
- Multiple search providers support (Tavily, SearXNG, Exa)
- Model selection from UI (switch between available AI models)
  - Reasoning models with visible thought process

### Chat &amp; History

- Chat history functionality (Optional)
- Share search results (Optional)
- Redis support (Local/Upstash)

### AI Providers

The following AI providers are supported:

- OpenAI (Default)
- Google Generative AI
- Azure OpenAI
- Anthropic
- Ollama
- Groq
- DeepSeek
- Fireworks
- xAI (Grok)
- OpenAI Compatible

Models are configured in `public/config/models.json`. Each model requires its corresponding API key to be set in the environment variables. See [Configuration Guide](docs/CONFIGURATION.md) for details.

### Search Capabilities

- URL-specific search
- Video search support (Optional)
- SearXNG integration with:
  - Customizable search depth (basic/advanced)
  - Configurable engines
  - Adjustable results limit
  - Safe search options
  - Custom time range filtering

### Additional Features

- Docker deployment ready
- Browser search engine integration

## üß± Stack

### Core Framework

- [Next.js](https://nextjs.org/) - App Router, React Server Components
- [TypeScript](https://www.typescriptlang.org/) - Type safety
- [Vercel AI SDK](https://sdk.vercel.ai/docs) - Text streaming / Generative UI

### AI &amp; Search

- [OpenAI](https://openai.com/) - Default AI provider (Optional: Google AI, Anthropic, Groq, Ollama, Azure OpenAI, DeepSeek, Fireworks)
- [Tavily AI](https://tavily.com/) - Default search provider
- Alternative providers:
  - [SearXNG](https://docs.searxng.org/) - Self-hosted search
  - [Exa](https://exa.ai/) - Neural search

### Data Storage

- [Upstash](https://upstash.com/) - Serverless Redis
- [Redis](https://redis.io/) - Local Redis option

### UI &amp; Styling

- [Tailwind CSS](https://tailwindcss.com/) - Utility-first CSS framework
- [shadcn/ui](https://ui.shadcn.com/) - Re-usable components
- [Radix UI](https://www.radix-ui.com/) - Unstyled, accessible components
- [Lucide Icons](https://lucide.dev/) - Beautiful &amp; consistent icons

## üöÄ Quickstart

### 1. Fork and Clone repo

Fork the repo to your Github account, then run the following command to clone the repo:

```bash
git clone git@github.com:[YOUR_GITHUB_ACCOUNT]/morphic.git
```

### 2. Install dependencies

```bash
cd morphic
bun install
```

### 3. Configure environment variables

```bash
cp .env.local.example .env.local
```

Fill in the required environment variables in `.env.local`:

```bash
# Required
OPENAI_API_KEY=     # Get from https://platform.openai.com/api-keys
TAVILY_API_KEY=     # Get from https://app.tavily.com/home
```

For optional features configuration (Redis, SearXNG, etc.), see [CONFIGURATION.md](./docs/CONFIGURATION.md)

### 4. Run app locally

#### Using Bun

```bash
bun dev
```

#### Using Docker

```bash
docker compose up -d
```

Visit http://localhost:3000 in your browser.

## üåê Deploy

Host your own live version of Morphic with Vercel, Cloudflare Pages, or Docker.

### Vercel

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fmiurla%2Fmorphic&amp;env=OPENAI_API_KEY,TAVILY_API_KEY,UPSTASH_REDIS_REST_URL,UPSTASH_REDIS_REST_TOKEN)

### Docker Prebuilt Image

Prebuilt Docker images are available on GitHub Container Registry:

```bash
docker pull ghcr.io/miurla/morphic:latest
```

You can use it with docker-compose:

```yaml
services:
  morphic:
    image: ghcr.io/miurla/morphic:latest
    env_file: .env.local
    ports:
      - &#039;3000:3000&#039;
    volumes:
      - ./models.json:/app/public/config/models.json # Optional: Override default model configuration
```

The default model configuration is located at `public/config/models.json`. For Docker deployment, you can create `models.json` alongside `.env.local` to override the default configuration.

## üîé Search Engine

### Setting up the Search Engine in Your Browser

If you want to use Morphic as a search engine in your browser, follow these steps:

1. Open your browser settings.
2. Navigate to the search engine settings section.
3. Select &quot;Manage search engines and site search&quot;.
4. Under &quot;Site search&quot;, click on &quot;Add&quot;.
5. Fill in the fields as follows:
   - **Search engine**: Morphic
   - **Shortcut**: morphic
   - **URL with %s in place of query**: `https://morphic.sh/search?q=%s`
6. Click &quot;Add&quot; to save the new search engine.
7. Find &quot;Morphic&quot; in the list of site search, click on the three dots next to it, and select &quot;Make default&quot;.

This will allow you to use Morphic as your default search engine in the browser.

## ‚úÖ Verified models

### List of models applicable to all

- OpenAI
  - gpt-4.1
  - gpt-4.1-mini
  - gpt-4.1-nano
  - o3-mini
  - gpt-4o
  - gpt-4o-mini
  - gpt-4-turbo
  - gpt-3.5-turbo
- Google
  - Gemini 2.5 Pro (Experimental)
  - Gemini 2.0 Flash Thinking (Experimental)
  - Gemini 2.0 Flash
- Anthropic
  - Claude 3.5 Sonnet
  - Claude 3.5 Hike
- Ollama
  - qwen2.5
  - deepseek-r1
- Groq
  - deepseek-r1-distill-llama-70b
  - Llama 4 Maverick 17B
- Fireworks
  - DeepSeek R1
  - Llama 4 Maverick
- DeepSeek
  - DeepSeek V3
  - DeepSeek R1
- xAI
  - grok-2
  - grok-2-vision
  - grok-3-beta

## ‚ö° AI SDK Implementation

### Current Version: AI SDK UI

This version of Morphic uses the AI SDK UI implementation, which is recommended for production use. It provides better streaming performance and more reliable client-side UI updates.

### Previous Version: AI SDK RSC (v0.2.34 and earlier)

The React Server Components (RSC) implementation of AI SDK was used in versions up to [v0.2.34](https://github.com/miurla/morphic/releases/tag/v0.2.34) but is now considered experimental and not recommended for production. If you need to reference the RSC implementation, please check the v0.2.34 release tag.

&gt; Note: v0.2.34 was the final version using RSC implementation before migrating to AI SDK UI.

For more information about choosing between AI SDK UI and RSC, see the [official documentation](https://sdk.vercel.ai/docs/getting-started/navigating-the-library#when-to-use-ai-sdk-rsc).

## üì¶ Open Source vs Cloud Offering

Morphic is open source software available under the Apache-2.0 license.

To maintain sustainable development and provide cloud-ready features, we offer a hosted version of Morphic alongside our open-source offering. The cloud solution makes Morphic accessible to non-technical users and provides additional features while keeping the core functionality open and available for developers.

For our cloud service, visit [morphic.sh](https://morphic.sh).

## üë• Contributing

We welcome contributions to Morphic! Whether it&#039;s bug reports, feature requests, or pull requests, all contributions are appreciated.

Please see our [Contributing Guide](CONTRIBUTING.md) for details on:

- How to submit issues
- How to submit pull requests
- Commit message conventions
- Development setup
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[web-infra-dev/midscene]]></title>
            <link>https://github.com/web-infra-dev/midscene</link>
            <guid>https://github.com/web-infra-dev/midscene</guid>
            <pubDate>Thu, 17 Apr 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[Let AI be your browser operator.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/web-infra-dev/midscene">web-infra-dev/midscene</a></h1>
            <p>Let AI be your browser operator.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,980</p>
            <p>Forks: 453</p>
            <p>Stars today: 46 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Midscene.js&quot;  width=&quot;260&quot; src=&quot;https://github.com/user-attachments/assets/f60de3c1-dd6f-4213-97a1-85bf7c6e79e4&quot;&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Midscene.js&lt;/h1&gt;
&lt;div align=&quot;center&quot;&gt;

English | [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh.md)

&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  Let AI be your browser operator.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/@midscene/web&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@midscene/web?style=flat-square&amp;color=00a8f0&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://huggingface.co/bytedance-research/UI-TARS-7B-SFT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%F0%9F%A4%97-UI%20TARS%20Models-yellow&quot; alt=&quot;huagging face model&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://npm-compare.com/@midscene/web/#timeRange=THREE_YEARS&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/@midscene/web.svg?style=flat-square&amp;color=00a8f0&quot; alt=&quot;downloads&quot; /&gt;&lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square&amp;color=00a8f0&quot; alt=&quot;License&quot; /&gt;
  &lt;a href=&quot;https://discord.gg/2JyBHxszE4&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1328277792730779648?style=flat-square&amp;color=7289DA&amp;label=Discord&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;discord&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/midscene_ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/midscene_ai?style=flat-square&quot; alt=&quot;twitter&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

Midscene.js lets AI be your browser operator ü§ñ.Just describe what you want to do in natural language, and it will help you operate web pages, validate content, and extract data. Whether you want a quick experience or deep development, you can get started easily.


## Showcases

The following recorded example video is based on the [UI-TARS 7B SFT](https://huggingface.co/bytedance-research/UI-TARS-7B-SFT) model, and the video has not been sped up at all~

| Instruction  | Video |
| :---:  | :---: |
| Post a Tweet      |    &lt;video src=&quot;https://github.com/user-attachments/assets/bb3d695a-fbff-4af1-b6cc-5e967c07ccee&quot; height=&quot;300&quot; /&gt;    |
| Use JS code to drive task orchestration, collect information about Jay Chou&#039;s concert, and write it into Google Docs   | &lt;video src=&quot;https://github.com/user-attachments/assets/75474138-f51f-4c54-b3cf-46d61d059999&quot; height=&quot;300&quot; /&gt;        |


## üì¢ New open-source model choice - UI-TARS and Qwen2.5-VL

Besides the default model *GPT-4o*, we have added two new recommended open-source models to Midscene.js: *UI-TARS* and *Qwen2.5-VL*. (Yes, Open Source !) They are dedicated models for image recognition and UI automation, which are known for performing well in UI automation scenarios. Read more about it in [Choose a model](https://midscenejs.com/choose-a-model).

## üí° Features
- **Natural Language Interaction üëÜ**: Just describe your goals and steps, and Midscene will plan and operate the user interface for you.
- **Chrome Extension Experience üñ•Ô∏è**: Start experiencing immediately through the Chrome extension, no coding required.
- **Puppeteer/Playwright Integration üîß**: Supports Puppeteer and Playwright integration, allowing you to combine AI capabilities with these powerful automation tools for easy automation.
- **Support Open-Source Models ü§ñ**: Supports private deployment of [`UI-TARS`](https://github.com/bytedance/ui-tars) and [`Qwen2.5-VL`](https://github.com/QwenLM/Qwen2.5-VL), which outperforms closed-source models like GPT-4o and Claude in UI automation scenarios while better protecting data security.
- **Support General Models üåü**: Supports general large models like GPT-4o and Claude, adapting to various scenario needs.
- **Visual Reports for Debugging üéûÔ∏è**: Through our test reports and Playground, you can easily understand, replay and debug the entire process.
- **Support Caching üîÑ**: The first time you execute a task through AI, it will be cached, and subsequent executions of the same task will significantly improve execution efficiency.
- **Completely Open Source üî•**: Experience a whole new automation development experience, enjoy!
- **Understand UI, JSON Format Responses üîç**: You can specify data format requirements and receive responses in JSON format.
- **Intuitive Assertions ü§î**: Express your assertions in natural language, and AI will understand and process them.

## ‚ú® Model Choices

- You can use general-purpose LLMs like `gpt-4o`, it works well for most cases. And also, `gemini-1.5-pro`, `qwen-vl-max-latest` are supported.
- You can also use [`UI-TARS`](https://github.com/bytedance/ui-tars) model, which is an **open-source model** dedicated for UI automation. You can deploy it on your own server, and it will dramatically improve the performance and data privacy. 
- Read more about [Choose a model](https://midscenejs.com/choose-a-model)

## üëÄ Comparing to ...

There are so many UI automation tools out there, and each one seems to be all-powerful. What&#039;s special about Midscene.js?

* Debugging Experience: You will soon find that debugging and maintaining automation scripts is the real challenge point. No matter how magic the demo is, you still need to debug the process to make it stable over time. Midscene.js offers a visualized report file, a built-in playground, and a Chrome Extension to debug the entire process. This is what most developers really need. And we&#039;re continuing to work on improving the debugging experience.

* Open Source, Free, Deploy as you want: Midscene.js is an open-source project. It&#039;s decoupled from any cloud service and model provider, you can choose either public or private deployment. There is always a suitable plan for your business.

* Integrate with Javascript: You can always bet on Javascript üòé

## üìÑ Resources 

* [Home Page: https://midscenejs.com](https://midscenejs.com/)
* [Quick Experience By Chrome Extension](https://midscenejs.com/quick-experience.html), this is where you should get started 
* Integration
  * [Automate with Scripts in YAML](https://midscenejs.com/automate-with-scripts-in-yaml.html), use this if you prefer to write YAML file instead of code
  * [Bridge Mode by Chrome Extension](https://midscenejs.com/bridge-mode-by-chrome-extension.html), use this to control the desktop Chrome by scripts
  * [Integrate with Puppeteer](https://midscenejs.com/integrate-with-puppeteer.html)
  * [Integrate with Playwright](https://midscenejs.com/integrate-with-playwright.html)
* [API Reference](https://midscenejs.com/api.html)
* [Choose a model](https://midscenejs.com/choose-a-model.html)
* [Config Model and Provider](https://midscenejs.com/model-provider.html)

## ü§ù Community

* [Discord](https://discord.gg/2JyBHxszE4)
* [Follow us on X](https://x.com/midscene_ai)
* [Lark Group](https://applink.larkoffice.com/client/chat/chatter/add_by_link?link_token=291q2b25-e913-411a-8c51-191e59aab14d)


## Citation

If you use Midscene.js in your research or project, please cite:

```bibtex
@software{Midscene.js,
  author = {Zhou, Xiao and Yu, Tao},
  title = {Midscene.js: Let AI be your browser operator.},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/web-infra-dev/midscene}
}
```


## üìù License

Midscene.js is [MIT licensed](https://github.com/web-infra-dev/midscene/blob/main/LICENSE).

---

&lt;div align=&quot;center&quot;&gt;
  If this project helps you or inspires you, please give us a ‚≠êÔ∏è
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>