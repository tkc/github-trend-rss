<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Fri, 27 Feb 2026 00:08:29 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[bytedance/deer-flow]]></title>
            <link>https://github.com/bytedance/deer-flow</link>
            <guid>https://github.com/bytedance/deer-flow</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:29 GMT</pubDate>
            <description><![CDATA[An open-source SuperAgent harness that researches, codes, and creates. With the help of sandboxes, memories, tools, skills and subagents, it handles different levels of tasks that could take minutes to hours.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytedance/deer-flow">bytedance/deer-flow</a></h1>
            <p>An open-source SuperAgent harness that researches, codes, and creates. With the help of sandboxes, memories, tools, skills and subagents, it handles different levels of tasks that could take minutes to hours.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,085</p>
            <p>Forks: 2,599</p>
            <p>Stars today: 617 stars today</p>
            <h2>README</h2><pre># ğŸ¦Œ DeerFlow - 2.0

DeerFlow (**D**eep **E**xploration and **E**fficient **R**esearch **Flow**) is an open-source **super agent harness** that orchestrates **sub-agents**, **memory**, and **sandboxes** to do almost anything â€” powered by **extensible skills**.

https://github.com/user-attachments/assets/a8bcadc4-e040-4cf2-8fda-dd768b999c18

&gt; [!NOTE]
&gt; **DeerFlow 2.0 is a ground-up rewrite.** It shares no code with v1. If you&#039;re looking for the original Deep Research framework, it&#039;s maintained on the [`1.x` branch](https://github.com/bytedance/deer-flow/tree/main-1.x) â€” contributions there are still welcome. Active development has moved to 2.0.

## Offiical Website

Learn more and see **real demos** on our official website.

**[deerflow.tech](https://deerflow.tech/)**

---

## Table of Contents

- [Quick Start](#quick-start)
- [Sandbox Mode](#sandbox-mode)
- [From Deep Research to Super Agent Harness](#from-deep-research-to-super-agent-harness)
- [Core Features](#core-features)
  - [Skills &amp; Tools](#skills--tools)
  - [Sub-Agents](#sub-agents)
  - [Sandbox &amp; File System](#sandbox--file-system)
  - [Context Engineering](#context-engineering)
  - [Long-Term Memory](#long-term-memory)
- [Recommended Models](#recommended-models)
- [Documentation](#documentation)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgments](#acknowledgments)
- [Star History](#star-history)

## Quick Start

### Configuration

1. **Clone the DeerFlow repository**

   ```bash
   git clone https://github.com/bytedance/deer-flow.git
   cd deer-flow
   ```

2. **Generate local configuration files**

   From the project root directory (`deer-flow/`), run:

   ```bash
   make config
   ```

   This command creates local configuration files based on the provided example templates.

3. **Configure your preferred model(s)**

   Edit `config.yaml` and define at least one model:

   ```yaml
   models:
     - name: gpt-4                       # Internal identifier
       display_name: GPT-4               # Human-readable name
       use: langchain_openai:ChatOpenAI  # LangChain class path
       model: gpt-4                      # Model identifier for API
       api_key: $OPENAI_API_KEY          # API key (recommended: use env var)
       max_tokens: 4096                  # Maximum tokens per request
       temperature: 0.7                  # Sampling temperature
   ```

4. **Set API keys for your configured model(s)**

   Choose one of the following methods:

- Option A: Edit the `.env` file in the project root (Recommended)


   ```bash
   TAVILY_API_KEY=your-tavily-api-key
   OPENAI_API_KEY=your-openai-api-key
   # Add other provider keys as needed
   ```

- Option B: Export environment variables in your shell

   ```bash
   export OPENAI_API_KEY=your-openai-api-key
   ```

- Option C: Edit `config.yaml` directly (Not recommended for production)

   ```yaml
   models:
     - name: gpt-4
       api_key: your-actual-api-key-here  # Replace placeholder
   ```

### Running the Application

#### Option 1: Docker (Recommended)

The fastest way to get started with a consistent environment:

1. **Initialize and start**:
   ```bash
   make docker-init    # Pull sandbox image (Only once or when image updates)
   make docker-start   # Start services (auto-detects sandbox mode from config.yaml)
   ```

   `make docker-start` now starts `provisioner` only when `config.yaml` uses provisioner mode (`sandbox.use: src.community.aio_sandbox:AioSandboxProvider` with `provisioner_url`).

2. **Access**: http://localhost:2026

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed Docker development guide.

#### Option 2: Local Development

If you prefer running services locally:

1. **Check prerequisites**:
   ```bash
   make check  # Verifies Node.js 22+, pnpm, uv, nginx
   ```

2. **(Optional) Pre-pull sandbox image**:
   ```bash
   # Recommended if using Docker/Container-based sandbox
   make setup-sandbox
   ```

3. **Start services**:
   ```bash
   make dev
   ```

4. **Access**: http://localhost:2026

### Advanced
#### Sandbox Mode

DeerFlow supports multiple sandbox execution modes:
- **Local Execution** (runs sandbox code directly on the host machine)
- **Docker Execution** (runs sandbox code in isolated Docker containers)
- **Docker Execution with Kubernetes** (runs sandbox code in Kubernetes pods via provisioner service)

For Docker development, service startup follows `config.yaml` sandbox mode. In Local/Docker modes, `provisioner` is not started.

See the [Sandbox Configuration Guide](backend/docs/CONFIGURATION.md#sandbox) to configure your preferred mode.

#### MCP Server

DeerFlow supports configurable MCP servers and skills to extend its capabilities.
See the [MCP Server Guide](backend/docs/MCP_SERVER.md) for detailed instructions.

## From Deep Research to Super Agent Harness

DeerFlow started as a Deep Research framework â€” and the community ran with it. Since launch, developers have pushed it far beyond research: building data pipelines, generating slide decks, spinning up dashboards, automating content workflows. Things we never anticipated.

That told us something important: DeerFlow wasn&#039;t just a research tool. It was a **harness** â€” a runtime that gives agents the infrastructure to actually get work done.

So we rebuilt it from scratch.

DeerFlow 2.0 is no longer a framework you wire together. It&#039;s a super agent harness â€” batteries included, fully extensible. Built on LangGraph and LangChain, it ships with everything an agent needs out of the box: a filesystem, memory, skills, sandboxed execution, and the ability to plan and spawn sub-agents for complex, multi-step tasks.

Use it as-is. Or tear it apart and make it yours.

## Core Features

### Skills &amp; Tools

Skills are what make DeerFlow do *almost anything*.

A standard Agent Skill is a structured capability module â€” a Markdown file that defines a workflow, best practices, and references to supporting resources. DeerFlow ships with built-in skills for research, report generation, slide creation, web pages, image and video generation, and more. But the real power is extensibility: add your own skills, replace the built-in ones, or combine them into compound workflows.

Skills are loaded progressively â€” only when the task needs them, not all at once. This keeps the context window lean and makes DeerFlow work well even with token-sensitive models.

Tools follow the same philosophy. DeerFlow comes with a core toolset â€” web search, web fetch, file operations, bash execution â€” and supports custom tools via MCP servers and Python functions. Swap anything. Add anything.

```
# Paths inside the sandbox container
/mnt/skills/public
â”œâ”€â”€ research/SKILL.md
â”œâ”€â”€ report-generation/SKILL.md
â”œâ”€â”€ slide-creation/SKILL.md
â”œâ”€â”€ web-page/SKILL.md
â””â”€â”€ image-generation/SKILL.md

/mnt/skills/custom
â””â”€â”€ your-custom-skill/SKILL.md      â† yours
```

### Sub-Agents

Complex tasks rarely fit in a single pass. DeerFlow decomposes them.

The lead agent can spawn sub-agents on the fly â€” each with its own scoped context, tools, and termination conditions. Sub-agents run in parallel when possible, report back structured results, and the lead agent synthesizes everything into a coherent output.

This is how DeerFlow handles tasks that take minutes to hours: a research task might fan out into a dozen sub-agents, each exploring a different angle, then converge into a single report â€” or a website â€” or a slide deck with generated visuals. One harness, many hands.

### Sandbox &amp; File System

DeerFlow doesn&#039;t just *talk* about doing things. It has its own computer.

Each task runs inside an isolated Docker container with a full filesystem â€” skills, workspace, uploads, outputs. The agent reads, writes, and edits files. It executes bash commands and codes. It views images. All sandboxed, all auditable, zero contamination between sessions.

This is the difference between a chatbot with tool access and an agent with an actual execution environment.

```
# Paths inside the sandbox container
/mnt/user-data/
â”œâ”€â”€ uploads/          â† your files
â”œâ”€â”€ workspace/        â† agents&#039; working directory
â””â”€â”€ outputs/          â† final deliverables
```

### Context Engineering

**Isolated Sub-Agent Context**: Each sub-agent runs in its own isolated context. This means that the sub-agent will not be able to see the context of the main agent or other sub-agents. This is important to ensure that the sub-agent is able to focus on the task at hand and not be distracted by the context of the main agent or other sub-agents.

**Summarization**: Within a session, DeerFlow manages context aggressively â€” summarizing completed sub-tasks, offloading intermediate results to the filesystem, compressing what&#039;s no longer immediately relevant. This lets it stay sharp across long, multi-step tasks without blowing the context window.

### Long-Term Memory

Most agents forget everything the moment a conversation ends. DeerFlow remembers.

Across sessions, DeerFlow builds a persistent memory of your profile, preferences, and accumulated knowledge. The more you use it, the better it knows you â€” your writing style, your technical stack, your recurring workflows. Memory is stored locally and stays under your control.

## Recommended Models

DeerFlow is model-agnostic â€” it works with any LLM that implements the OpenAI-compatible API. That said, it performs best with models that support:

- **Long context windows** (100k+ tokens) for deep research and multi-step tasks
- **Reasoning capabilities** for adaptive planning and complex decomposition
- **Multimodal inputs** for image understanding and video comprehension
- **Strong tool-use** for reliable function calling and structured outputs

## Documentation

- [Contributing Guide](CONTRIBUTING.md) - Development environment setup and workflow
- [Configuration Guide](backend/docs/CONFIGURATION.md) - Setup and configuration instructions
- [Architecture Overview](backend/CLAUDE.md) - Technical architecture details
- [Backend Architecture](backend/README.md) - Backend architecture and API reference

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for development setup, workflow, and guidelines.

Regression coverage includes Docker sandbox mode detection and provisioner kubeconfig-path handling tests in `backend/tests/`.

## License

This project is open source and available under the [MIT License](./LICENSE).

## Acknowledgments

DeerFlow is built upon the incredible work of the open-source community. We are deeply grateful to all the projects and contributors whose efforts have made DeerFlow possible. Truly, we stand on the shoulders of giants.

We would like to extend our sincere appreciation to the following projects for their invaluable contributions:

- **[LangChain](https://github.com/langchain-ai/langchain)**: Their exceptional framework powers our LLM interactions and chains, enabling seamless integration and functionality.
- **[LangGraph](https://github.com/langchain-ai/langgraph)**: Their innovative approach to multi-agent orchestration has been instrumental in enabling DeerFlow&#039;s sophisticated workflows.

These projects exemplify the transformative power of open-source collaboration, and we are proud to build upon their foundations.

### Key Contributors

A heartfelt thank you goes out to the core authors of `DeerFlow`, whose vision, passion, and dedication have brought this project to life:

- **[Daniel Walnut](https://github.com/hetaoBackend/)**
- **[Henry Li](https://github.com/magiccube/)**

Your unwavering commitment and expertise have been the driving force behind DeerFlow&#039;s success. We are honored to have you at the helm of this journey.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=bytedance/deer-flow&amp;type=Date)](https://star-history.com/#bytedance/deer-flow&amp;Date)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[farion1231/cc-switch]]></title>
            <link>https://github.com/farion1231/cc-switch</link>
            <guid>https://github.com/farion1231/cc-switch</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:28 GMT</pubDate>
            <description><![CDATA[A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode & Gemini CLI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/farion1231/cc-switch">farion1231/cc-switch</a></h1>
            <p>A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode & Gemini CLI.</p>
            <p>Language: Rust</p>
            <p>Stars: 20,633</p>
            <p>Forks: 1,281</p>
            <p>Stars today: 418 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# All-in-One Assistant for Claude Code, Codex &amp; Gemini CLI

[![Version](https://img.shields.io/badge/version-3.10.2-blue.svg)](https://github.com/farion1231/cc-switch/releases)
[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/farion1231/cc-switch/releases)
[![Built with Tauri](https://img.shields.io/badge/built%20with-Tauri%202-orange.svg)](https://tauri.app/)
[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/farion1231/cc-switch/total)](https://github.com/farion1231/cc-switch/releases/latest)

&lt;a href=&quot;https://trendshift.io/repositories/15372&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15372&quot; alt=&quot;farion1231%2Fcc-switch | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

English | [ä¸­æ–‡](README_ZH.md) | [æ—¥æœ¬èª](README_JA.md) | [Changelog](CHANGELOG.md)

&lt;/div&gt;

## â¤ï¸Sponsor

[![MiniMax](assets/partners/banners/minimax-en.jpeg)](https://platform.minimax.io/subscribe/coding-plan?code=ClLhgxr2je&amp;source=link)

MiniMax-M2.5 is a SOTA large language model designed for real-world productivity. Trained in a diverse range of complex real-world digital working environments, M2.5 builds upon the coding expertise of M2.1 to extend into general office work, reaching fluency in generating and operating Word, Excel, and Powerpoint files, context switching between diverse software environments, and working across different agent and human teams. Scoring 80.2% on SWE-Bench Verified, 51.3% on Multi-SWE-Bench, and 76.3% on BrowseComp, M2.5 is also more token efficient than previous generations, having been trained to optimize its actions and output through planning.

[Click](https://platform.minimax.io/subscribe/coding-plan?code=ClLhgxr2je&amp;source=link) to get an exclusive 12% off the MiniMax Coding Plan!

---

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.packyapi.com/register?aff=cc-switch&quot;&gt;&lt;img src=&quot;assets/partners/logos/packycode.png&quot; alt=&quot;PackyCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to PackyCode for sponsoring this project! PackyCode is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more. PackyCode provides special discounts for our software users: register using &lt;a href=&quot;https://www.packyapi.com/register?aff=cc-switch&quot;&gt;this link&lt;/a&gt; and enter the &quot;cc-switch&quot; promo code during first recharge to get 10% off.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://aigocode.com/invite/CC-SWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/aigocode.png&quot; alt=&quot;AIGoCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AIGoCode for sponsoring this project! AIGoCode is an all-in-one platform that integrates Claude Code, Codex, and the latest Gemini models, providing you with stable, efficient, and highly cost-effective AI coding services. The platform offers flexible subscription plans, zero risk of account suspension, direct access with no VPN required, and lightning-fast responses. AIGoCode has prepared a special benefit for CC Switch users: if you register via &lt;a href=&quot;https://aigocode.com/invite/CC-SWITCH&quot;&gt;this link&lt;/a&gt;, you&#039;ll receive an extra 10% bonus credit on your first top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.aicodemirror.com/register?invitecode=9915W3&quot;&gt;&lt;img src=&quot;assets/partners/logos/aicodemirror.jpg&quot; alt=&quot;AICodeMirror&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AICodeMirror for sponsoring this project! AICodeMirror provides official high-stability relay services for Claude Code / Codex / Gemini CLI, with enterprise-grade concurrency, fast invoicing, and 24/7 dedicated technical support.
Claude Code / Codex / Gemini official channels at 38% / 2% / 9% of original price, with extra discounts on top-ups! AICodeMirror offers special benefits for CC Switch users: register via &lt;a href=&quot;https://www.aicodemirror.com/register?invitecode=9915W3&quot;&gt;this link&lt;/a&gt; to enjoy 20% off your first top-up, and enterprise customers can get up to 25% off!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://cubence.com/signup?code=CCSWITCH&amp;source=ccs&quot;&gt;&lt;img src=&quot;assets/partners/logos/cubence.png&quot; alt=&quot;Cubence&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to Cubence for sponsoring this project! Cubence is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more with flexible billing options including pay-as-you-go and monthly plans. Cubence provides special discounts for CC Switch users: register using &lt;a href=&quot;https://cubence.com/signup?code=CCSWITCH&amp;source=ccs&quot;&gt;this link&lt;/a&gt; and enter the &quot;CCSWITCH&quot; promo code during recharge to get 10% off every top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.dmxapi.cn/register?aff=bUHu&quot;&gt;&lt;img src=&quot;assets/partners/logos/dmx-en.jpg&quot; alt=&quot;DMXAPI&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to DMXAPI for sponsoring this project! DMXAPI provides global large model API services to 200+ enterprise users. One API key for all global models. Features include: instant invoicing, unlimited concurrency, starting from $0.15, 24/7 technical support. GPT/Claude/Gemini all at 32% off, domestic models 20-50% off, Claude Code exclusive models at 66% off! &lt;a href=&quot;https://www.dmxapi.cn/register?aff=bUHu&quot;&gt;Register here&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.right.codes/register?aff=CCSWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/rightcode.jpg&quot; alt=&quot;RightCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thank you to Right Code for sponsoring this project! Right Code reliably provides routing services for models such as Claude Code, Codex, and Gemini. It features a highly cost-effective Codex monthly subscription plan and &lt;strong&gt;supports quota rolloversâ€”unused quota from one day can be carried over and used the next day.&lt;/strong&gt; Invoices are available upon top-up. Enterprise and team users can receive dedicated one-on-one support. Right Code also offers an exclusive discount for CC Switch users: register via &lt;a href=&quot;https://www.right.codes/register?aff=CCSWITCH&quot;&gt;this link&lt;/a&gt;, and with every top-up you will receive pay-as-you-go credit equivalent to 25% of the amount paid.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://aicoding.sh/i/CCSWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/aicoding.jpg&quot; alt=&quot;AICoding&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AICoding.sh for sponsoring this project! AICoding.sh â€” Global AI Model API Relay Service at Unbeatable Prices! Claude Code at 19% of original price, GPT at just 1%! Trusted by hundreds of enterprises for cost-effective AI services. Supports Claude Code, GPT, Gemini and major domestic models, with enterprise-grade high concurrency, fast invoicing, and 24/7 dedicated technical support. CC Switch users who register via &lt;a href=&quot;https://aicoding.sh/i/CCSWITCH&quot;&gt;this link&lt;/a&gt; get 10% off their first top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://crazyrouter.com/register?aff=OZcm&amp;ref=cc-switch&quot;&gt;&lt;img src=&quot;assets/partners/logos/crazyrouter.jpg&quot; alt=&quot;AICoding&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to Crazyrouter for sponsoring this project! Crazyrouter is a high-performance AI API aggregation platform â€” one API key for 300+ models including Claude Code, Codex, Gemini CLI, and more. All models at 55% of official pricing with auto-failover, smart routing, and unlimited concurrency. Crazyrouter offers an exclusive deal for CC Switch users: register via &lt;a href=&quot;https://crazyrouter.com/register?aff=OZcm&amp;ref=cc-switch&quot;&gt;this link&lt;/a&gt;  to get &lt;strong&gt;$2 free credit&lt;/strong&gt; instantly, plus enter promo code `CCSWITCH` on your first top-up for an extra &lt;strong&gt;30% bonus credit&lt;/strong&gt;! &lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.sssaicode.com/register?ref=DCP0SM&quot;&gt;&lt;img src=&quot;assets/partners/logos/sssaicode.png&quot; alt=&quot;SSSAiCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to SSSAiCode for sponsoring this project! SSSAiCode is a stable and reliable API relay service, dedicated to providing stable, reliable, and affordable Claude and Codex model services, &lt;strong&gt;offering high cost-effective official Claude service at just Â¥0.5/$ equivalent&lt;/strong&gt;, supporting monthly and pay-as-you-go billing plans with same-day fast invoicing. SSSAiCode offers a special deal for CC Switch users: register via &lt;a href=&quot;https://www.sssaicode.com/register?ref=DCP0SM&quot;&gt;this link&lt;/a&gt; to enjoy $10 extra credit on every top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

## Screenshots

|                  Main Interface                   |                  Add Provider                  |
| :-----------------------------------------------: | :--------------------------------------------: |
| ![Main Interface](assets/screenshots/main-en.png) | ![Add Provider](assets/screenshots/add-en.png) |

## Features

### Current Version: v3.10.2 | [Full Changelog](CHANGELOG.md) | [Release Notes](docs/release-note-v3.9.0-en.md)

**v3.8.0 Major Update (2025-11-28)**

**Persistence Architecture Upgrade &amp; Brand New UI**

- **SQLite + JSON Dual-layer Architecture**
  - Migrated from JSON file storage to SQLite + JSON dual-layer structure
  - Syncable data (providers, MCP, Prompts, Skills) stored in SQLite
  - Device-level data (window state, local paths) stored in JSON
  - Lays the foundation for future cloud sync functionality
  - Schema version management for database migrations

- **Brand New User Interface**
  - Completely redesigned interface layout
  - Unified component styles and smoother animations
  - Optimized visual hierarchy
  - Tailwind CSS downgraded from v4 to v3.4 for better browser compatibility

- **Japanese Language Support**
  - Added Japanese interface support (now supports Chinese/English/Japanese)

- **Auto Launch on Startup**
  - One-click enable/disable in settings
  - Platform-native APIs (Registry/LaunchAgent/XDG autostart)

- **Skills Recursive Scanning**
  - Support for multi-level directory structures
  - Allow same-named skills from different repositories

- **Critical Bug Fixes**
  - Fixed custom endpoints lost when updating providers
  - Fixed Gemini configuration write issues
  - Fixed Linux WebKitGTK rendering issues

**v3.7.0 Highlights**

**Six Core Features, 18,000+ Lines of New Code**

- **Gemini CLI Integration**
  - Third supported AI CLI (Claude Code / Codex / Gemini)
  - Dual-file configuration support (`.env` + `settings.json`)
  - Complete MCP server management
  - Presets: Google Official (OAuth) / PackyCode / Custom

- **Claude Skills Management System**
  - Auto-scan skills from GitHub repositories (3 pre-configured curated repos)
  - One-click install/uninstall to `~/.claude/skills/`
  - Custom repository support + subdirectory scanning
  - Complete lifecycle management (discover/install/update)

- **Prompts Management System**
  - Multi-preset system prompt management (unlimited presets, quick switching)
  - Cross-app support (Claude: `CLAUDE.md` / Codex: `AGENTS.md` / Gemini: `GEMINI.md`)
  - Markdown editor (CodeMirror 6 + real-time preview)
  - Smart backfill protection, preserves manual modifications

- **MCP v3.7.0 Unified Architecture**
  - Single panel manages MCP servers across three applications
  - New SSE (Server-Sent Events) transport type
  - Smart JSON parser + Codex TOML format auto-correction
  - Unified import/export + bidirectional sync

- **Deep Link Protocol**
  - `ccswitch://` protocol registration (all platforms)
  - One-click import provider configs via shared links
  - Security validation + lifecycle integration

- **Environment Variable Conflict Detection**
  - Auto-detect cross-app configuration conflicts (Claude/Codex/Gemini/MCP)
  - Visual conflict indicators + resolution suggestions
  - Override warnings + backup before changes

**Core Capabilities**

- **Provider Management**: One-click switching between Claude Code, Codex, and Gemini API configurations
- **AWS Bedrock Support**: Built-in AWS Bedrock provider presets with AKSK and API Key authentication, cross-region inference support (global/us/eu/apac), covering Claude Code and OpenCode
- **Speed Testing**: Measure API endpoint latency with visual quality indicators
- **Import/Export**: Backup and restore configs with auto-rotation (keep 10 most recent)
- **i18n Support**: Complete Chinese/English localization (UI, errors, tray)
- **Claude Plugin Sync**: One-click apply/restore Claude plugin configurations

**v3.6 Highlights**

- Provider duplication &amp; drag-and-drop sorting
- Multi-endpoint management &amp; custom config directory (cloud sync ready)
- Granular model configuration (4-tier: Haiku/Sonnet/Opus/Custom)
- WSL environment support with auto-sync on directory change
- 100% hooks test coverage &amp; complete architecture refactoring

**System Features**

- System tray with quick switching
- Single instance daemon
- Built-in auto-updater
- Atomic writes with rollback protection

## Download &amp; Installation

### System Requirements

- **Windows**: Windows 10 and above
- **macOS**: macOS 10.15 (Catalina) and above
- **Linux**: Ubuntu 22.04+ / Debian 11+ / Fedora 34+ and other mainstream distributions

### Windows Users

Download the latest `CC-Switch-v{version}-Windows.msi` installer or `CC-Switch-v{version}-Windows-Portable.zip` portable version from the [Releases](../../releases) page.

### macOS Users

**Method 1: Install via Homebrew (Recommended)**

```bash
brew tap farion1231/ccswitch
brew install --cask cc-switch
```

Update:

```bash
brew upgrade --cask cc-switch
```

**Method 2: Manual Download**

Download `CC-Switch-v{version}-macOS.zip` from the [Releases](../../releases) page and extract to use.

&gt; **Note**: Since the author doesn&#039;t have an Apple Developer account, you may see an &quot;unidentified developer&quot; warning on first launch. Please close it first, then go to &quot;System Settings&quot; â†’ &quot;Privacy &amp; Security&quot; â†’ click &quot;Open Anyway&quot;, and you&#039;ll be able to open it normally afterwards.

### Arch Linux Users

**Install via paru (Recommended)**

```bash
paru -S cc-switch-bin
```

### Linux Users

Download the latest Linux build from the [Releases](../../releases) page:

- `CC-Switch-v{version}-Linux.deb` (Debian/Ubuntu)
- `CC-Switch-v{version}-Linux.rpm` (Fedora/RHEL/openSUSE)
- `CC-Switch-v{version}-Linux.AppImage` (Universal)
- `CC-Switch-v{version}-Linux.flatpak` (Flatpak)

Flatpak install &amp; run:

```bash
flatpak install --user ./CC-Switch-v{version}-Linux.flatpak
flatpak run com.ccswitch.desktop
```

## Quick Start

### Basic Usage

1. **Add Provider**: Click &quot;Add Provider&quot; â†’ Choose preset or create custom configuration
2. **Switch Provider**:
   - Main UI: Select provider â†’ Click &quot;Enable&quot;
   - System Tray: Click provider name directly (instant effect)
3. **Takes Effect**: Restart your terminal or Claude Code / Codex / Gemini clients to apply changes
4. **Back to Official**: Select the &quot;Official Login&quot; preset (Claude/Codex) or &quot;Google Official&quot; preset (Gemini), restart the corresponding client, then follow its login/OAuth flow

### MCP Management

- **Location**: Click &quot;MCP&quot; button in top-right corner
- **Add Server**:
  - Use built-in templates (mcp-fetch, mcp-filesystem, etc.)
  - Support stdio / http / sse transport types
  - Configure independent MCP servers for different apps
- **Enable/Disable**: Toggle switches to control which servers sync to live config
- **Sync**: Enabled servers auto-sync to each app&#039;s live files
- **Import/Export**: Import existing MCP servers from Claude/Codex/Gemini config files

### Skills Management (v3.7.0 New)

- **Location**: Click &quot;Skills&quot; button in top-right corner
- **Discover Skills**:
  - Auto-scan pre-configured GitHub repositories (Anthropic official, ComposioHQ, community, etc.)
  - Add custom repositories (supports subdirectory scanning)
- **Install Skills**: Click &quot;Install&quot; to one-click install to `~/.claude/skills/`
- **Uninstall Skills**: Click &quot;Uninstall&quot; to safely remove and clean up state
- **Manage Repositories**: Add/remove custom GitHub repositories

### Prompts Management (v3.7.0 New)

- **Location**: Click &quot;Prompts&quot; button in top-right corner
- **Create Presets**:
  - Create unlimited system prompt presets
  - Use Markdown editor to write prompts (syntax highlighting + real-time preview)
- **Switch Presets**: Select preset â†’ Click &quot;Activate&quot; to apply immediately
- **Sync Mechanism**:
  - Claude: `~/.claude/CLAUDE.md`
  - Codex: `~/.codex/AGENTS.md`
  - Gemini: `~/.gemini/GEMINI.md`
- **Protection Mechanism**: Auto-save current prompt content before switching, preserves manual modifications

### Configuration Files

**Claude Code**

- Live config: `~/.claude/settings.json` (or `claude.json`)
- API key field: `env.ANTHROPIC_AUTH_TOKEN` or `env.ANTHROPIC_API_KEY`
- MCP servers: `~/.claude.json` â†’ `mcpServers`

**Codex**

- Live config: `~/.codex/auth.json` (required) + `config.toml` (optional)
- API key field: `OPENAI_API_KEY` in `auth.json`
- MCP servers: `~/.codex/config.toml` â†’ `[mcp_servers]` tables

**Gemini**

- Live config: `~/.gemini/.env` (API key) + `~/.gemini/settings.json` (auth mode)
- API key field: `GEMINI_API_KEY` or `GOOGLE_GEMINI_API_KEY` in `.env`
- Environment variables: Support `GOOGLE_GEMINI_BASE_URL`, `GEMINI_MODEL`, etc.
- MCP servers: `~/.gemini/settings.json` â†’ `mcpServers`
- Tray quick switch: Each provider switch rewrites `~/.gemini/.env`, no need to restart Gemini CLI

**CC Switch Storage (v3.8.0 New Architecture)**

- Database (SSOT): `~/.cc-switch/cc-switch.db` (SQLite, stores providers, MCP, Prompts, Skills)
- Local settings: `~/.cc-switch/settings.json` (device-level settings)
- Backups: `~/.cc-switch/backups/` (auto-rotate, keep 10)

### Cloud Sync Setup

1. Go to Settings â†’ &quot;Custom Configuration Directory&quot;
2. Choose your cloud sync folder (Dropbox, OneDrive, iCloud, etc.)
3. Restart app to apply
4. Repeat on other devices to enable cross-device sync

&gt; **Note**: First launch auto-imports existing Claude/Codex configs as default provider.

## Architecture Overview

### Design Principles

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React + TS)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Components  â”‚  â”‚    Hooks     â”‚  â”‚  TanStack Query  â”‚    â”‚
â”‚  â”‚   (UI)      â”‚â”€â”€â”‚ (Bus. Logic) â”‚â”€â”€â”‚   (Cache/Sync)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Tauri IPC
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Backend (Tauri + Rust)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Commands   â”‚  â”‚   Services   â”‚  â”‚  Models/Config   â”‚    â”‚
â”‚  â”‚ (API Layer) â”‚â”€â”€â”‚ (Bus. Layer) â”‚â”€â”€â”‚     (Data)       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Core Design Patterns**

- **SSOT** (Single Source of Truth): All data stored in `~/.cc-switch/cc-switch.db` (SQLite)
- **Dual-layer Storage**: SQLite for syncable data, JSON for device-level settings
- **Dual-way Sync**: Write to live files on switch, backfill from live when editing active provider
- **Atomic Writes**: Temp file + rename pattern prevents config corruption
- **Concurrency Safe**: Mutex-protected database connection avoids race conditions
- **Layered Architecture**: Clear separation (Commands â†’ Services â†’ DAO â†’ Database)

**Key Components**

- **ProviderService**: Provider CRUD, switching, backfill, sorting
- **McpService**: MCP server management, import/export, live file sync
- **ConfigService**: Config import/export, backup rotation
- **SpeedtestService**: API endpoint latency measurement

**v3.6 Refactoring**

- Backend: 5-phase refactoring (error handling â†’ command split â†’ tests â†’ services â†’ concurrency)
- Frontend: 4-stage refactoring (test infra â†’ hooks â†’ components â†’ cleanup)
- Testing: 100% hooks coverage + integration tests (vitest + MSW)

## Development

### Environment Requirements

- Node.js 18+
- pnpm 8+
- Rust 1.85+
- Tauri CLI 2.8+

### D

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ruvnet/claude-flow]]></title>
            <link>https://github.com/ruvnet/claude-flow</link>
            <guid>https://github.com/ruvnet/claude-flow</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:27 GMT</pubDate>
            <description><![CDATA[ğŸŒŠ The leading agent orchestration platform for Claude. Deploy intelligent multi-agent swarms, coordinate autonomous workflows, and build conversational AI systems. Features enterprise-grade architecture, distributed swarm intelligence, RAG integration, and native Claude Code / Codex Integration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ruvnet/claude-flow">ruvnet/claude-flow</a></h1>
            <p>ğŸŒŠ The leading agent orchestration platform for Claude. Deploy intelligent multi-agent swarms, coordinate autonomous workflows, and build conversational AI systems. Features enterprise-grade architecture, distributed swarm intelligence, RAG integration, and native Claude Code / Codex Integration</p>
            <p>Language: TypeScript</p>
            <p>Stars: 14,948</p>
            <p>Forks: 1,741</p>
            <p>Stars today: 215 stars today</p>
            <h2>README</h2><pre># ğŸŒŠ Ruflo v3: Enterprise AI Orchestration Platform

&lt;div align=&quot;center&quot;&gt;

![Ruflo Banner](https://repository-images.githubusercontent.com/995029641/b9acbe16-0f49-420d-804f-468ba2a73ace)



[![GitHub Project of the Day](https://img.shields.io/badge/GitHub-Project%20of%20the%20Day-ff6600?style=for-the-badge&amp;logo=github&amp;logoColor=white)](https://github.com/ruvnet/claude-flow)

[![Star on GitHub](https://img.shields.io/github/stars/ruvnet/claude-flow?style=for-the-badge&amp;logo=github&amp;color=gold)](https://github.com/ruvnet/claude-flow)
[![Monthly Downloads](https://img.shields.io/npm/dm/claude-flow?style=for-the-badge&amp;logo=npm&amp;color=blue&amp;label=Monthly%20Downloads)](https://www.npmjs.com/package/claude-flow)
[![Total Downloads](https://img.shields.io/npm/dt/claude-flow?style=for-the-badge&amp;logo=npm&amp;color=cyan&amp;label=Total%20Downloads)](https://www.npmjs.com/package/claude-flow)
[![ruv.io](https://img.shields.io/badge/ruv.io-AI%20Platform-green?style=for-the-badge&amp;logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCI+PHBhdGggZmlsbD0id2hpdGUiIGQ9Ik0xMiAyQzYuNDggMiAyIDYuNDggMiAxMnM0LjQ4IDEwIDEwIDEwIDEwLTQuNDggMTAtMTBTMTcuNTIgMiAxMiAyem0wIDE4Yy00LjQyIDAtOC0zLjU4LTgtOHMzLjU4LTggOC04IDggMy41OCA4IDgtMy41OCA4LTggOHoiLz48L3N2Zz4=)](https://ruv.io)
[![Agentics Foundation](https://img.shields.io/badge/Agentics-Foundation-crimson?style=for-the-badge&amp;logo=openai)](https://discord.com/invite/dfxmpwkG2D)
[![Claude Code](https://img.shields.io/badge/Claude%20Code-SDK%20Integrated-green?style=for-the-badge&amp;logo=anthropic)](https://github.com/ruvnet/claude-flow)
[![MIT License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge&amp;logo=opensourceinitiative)](https://opensource.org/licenses/MIT)
---
[![Follow @ruv](https://img.shields.io/badge/Follow%20%40ruv-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white)](https://x.com/ruv)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&amp;logo=linkedin)](https://www.linkedin.com/in/reuvencohen/)
[![YouTube](https://img.shields.io/badge/YouTube-Subscribe-FF0000?style=for-the-badge&amp;logo=youtube&amp;logoColor=white)](https://www.youtube.com/@ReuvenCohen)

# **Production-ready multi-agent AI orchestration for Claude Code**
*Deploy 60+ specialized agents in coordinated swarms with self-learning capabilities, fault-tolerant consensus, and enterprise-grade security.*

&lt;/div&gt;

## Getting into the Flow

Ruflo is a comprehensive AI agent orchestration framework that transforms Claude Code into a powerful multi-agent development platform. It enables teams to deploy, coordinate, and optimize specialized AI agents working together on complex software engineering tasks.

### Self-Learning/Self-Optimizing Agent Architecture

```
User â†’ Ruflo (CLI/MCP) â†’ Router â†’ Swarm â†’ Agents â†’ Memory â†’ LLM Providers
                       â†‘                          â†“
                       â””â”€â”€â”€â”€ Learning Loop â†â”€â”€â”€â”€â”€â”€â”˜
```

&lt;details&gt;
&lt;summary&gt;ğŸ“ &lt;strong&gt;Expanded Architecture&lt;/strong&gt; â€” Full system diagram with RuVector intelligence&lt;/summary&gt;

```mermaid
flowchart TB
    subgraph USER[&quot;ğŸ‘¤ User Layer&quot;]
        U[User]
    end

    subgraph ENTRY[&quot;ğŸšª Entry Layer&quot;]
        CLI[CLI / MCP Server]
        AID[AIDefence Security]
    end

    subgraph ROUTING[&quot;ğŸ§­ Routing Layer&quot;]
        QL[Q-Learning Router]
        MOE[MoE - 8 Experts]
        SK[Skills - 42+]
        HK[Hooks - 17]
    end

    subgraph SWARM[&quot;ğŸ Swarm Coordination&quot;]
        TOPO[Topologies&lt;br/&gt;mesh/hier/ring/star]
        CONS[Consensus&lt;br/&gt;Raft/BFT/Gossip/CRDT]
        CLM[Claims&lt;br/&gt;Human-Agent Coord]
    end

    subgraph AGENTS[&quot;ğŸ¤– 60+ Agents&quot;]
        AG1[coder]
        AG2[tester]
        AG3[reviewer]
        AG4[architect]
        AG5[security]
        AG6[...]
    end

    subgraph RESOURCES[&quot;ğŸ“¦ Resources&quot;]
        MEM[(Memory&lt;br/&gt;AgentDB)]
        PROV[Providers&lt;br/&gt;Claude/GPT/Gemini/Ollama]
        WORK[Workers - 12&lt;br/&gt;ultralearn/audit/optimize]
    end

    subgraph RUVECTOR[&quot;ğŸ§  RuVector Intelligence Layer&quot;]
        direction TB
        subgraph ROW1[&quot; &quot;]
            SONA[SONA&lt;br/&gt;Self-Optimize&lt;br/&gt;&amp;lt;0.05ms]
            EWC[EWC++&lt;br/&gt;No Forgetting]
            FLASH[Flash Attention&lt;br/&gt;2.49-7.47x]
        end
        subgraph ROW2[&quot; &quot;]
            HNSW[HNSW&lt;br/&gt;150x-12,500x faster]
            RB[ReasoningBank&lt;br/&gt;Pattern Store]
            HYP[Hyperbolic&lt;br/&gt;PoincarÃ©]
        end
        subgraph ROW3[&quot; &quot;]
            LORA[LoRA/Micro&lt;br/&gt;128x compress]
            QUANT[Int8 Quant&lt;br/&gt;3.92x memory]
            RL[9 RL Algos&lt;br/&gt;Q/SARSA/PPO/DQN]
        end
    end

    subgraph LEARNING[&quot;ğŸ”„ Learning Loop&quot;]
        L1[RETRIEVE] --&gt; L2[JUDGE] --&gt; L3[DISTILL] --&gt; L4[CONSOLIDATE] --&gt; L5[ROUTE]
    end

    U --&gt; CLI
    CLI --&gt; AID
    AID --&gt; QL &amp; MOE &amp; SK &amp; HK
    QL &amp; MOE &amp; SK &amp; HK --&gt; TOPO &amp; CONS &amp; CLM
    TOPO &amp; CONS &amp; CLM --&gt; AG1 &amp; AG2 &amp; AG3 &amp; AG4 &amp; AG5 &amp; AG6
    AG1 &amp; AG2 &amp; AG3 &amp; AG4 &amp; AG5 &amp; AG6 --&gt; MEM &amp; PROV &amp; WORK
    MEM --&gt; SONA &amp; EWC &amp; FLASH
    SONA &amp; EWC &amp; FLASH --&gt; HNSW &amp; RB &amp; HYP
    HNSW &amp; RB &amp; HYP --&gt; LORA &amp; QUANT &amp; RL
    LORA &amp; QUANT &amp; RL --&gt; L1
    L5 -.-&gt;|loops back| QL

    style RUVECTOR fill:#1a1a2e,stroke:#e94560,stroke-width:2px
    style LEARNING fill:#0f3460,stroke:#e94560,stroke-width:2px
    style USER fill:#16213e,stroke:#0f3460
    style ENTRY fill:#1a1a2e,stroke:#0f3460
    style ROUTING fill:#1a1a2e,stroke:#0f3460
    style SWARM fill:#1a1a2e,stroke:#0f3460
    style AGENTS fill:#1a1a2e,stroke:#0f3460
    style RESOURCES fill:#1a1a2e,stroke:#0f3460
```

**RuVector Components** (`npx ruvector`):

| Component | Purpose | Performance |
|-----------|---------|-------------|
| **SONA** | Self-Optimizing Neural Architecture - learns optimal routing | &lt;0.05ms adaptation |
| **EWC++** | Elastic Weight Consolidation - prevents catastrophic forgetting | Preserves 95%+ knowledge |
| **Flash Attention** | Optimized attention computation | 2.49x-7.47x speedup |
| **HNSW** | Hierarchical Navigable Small World vector search | 150x-12,500x faster |
| **ReasoningBank** | Pattern storage with trajectory learning | RETRIEVEâ†’JUDGEâ†’DISTILL |
| **Hyperbolic** | PoincarÃ© ball embeddings for hierarchical data | Better code relationships |
| **LoRA/MicroLoRA** | Low-Rank Adaptation for efficient fine-tuning | **&lt;3Î¼s** adaptation, 383k ops/sec |
| **Int8 Quantization** | Memory-efficient weight storage | 3.92x memory reduction |
| **SemanticRouter** | Semantic task routing with cosine similarity | **34,798 routes/s**, 0.029ms |
| **9 RL Algorithms** | Q-Learning, SARSA, A2C, PPO, DQN, Decision Transformer, etc. | Task-specific learning |

```bash
# Install RuVector standalone
npx ruvector

# Or use via Ruflo
npx ruflo@v3alpha hooks intelligence --status
```

&lt;/details&gt;

### Get Started Fast

```bash
# One-line install (recommended)
curl -fsSL https://cdn.jsdelivr.net/gh/ruvnet/claude-flow@main/scripts/install.sh | bash

# Or full setup with MCP + diagnostics
curl -fsSL https://cdn.jsdelivr.net/gh/ruvnet/claude-flow@main/scripts/install.sh | bash -s -- --full

# Or via npx
npx ruflo@alpha init --wizard
```

---
### Key Capabilities

ğŸ¤– **60+ Specialized Agents** - Ready-to-use AI agents for coding, code review, testing, security audits, documentation, and DevOps. Each agent is optimized for its specific role.

ğŸ **Coordinated Agent Teams** - Run unlimited agents simultaneously in organized swarms. Agents spawn sub-workers, communicate, share context, and divide work automatically using hierarchical (queen/workers) or mesh (peer-to-peer) patterns.

ğŸ§  **Learns From Your Workflow** - The system remembers what works. Successful patterns are stored and reused, routing similar tasks to the best-performing agents. Gets smarter over time.

ğŸ”Œ **Works With Any LLM** - Switch between Claude, GPT, Gemini, Cohere, or local models like Llama. Automatic failover if one provider is unavailable. Smart routing picks the cheapest option that meets quality requirements.

âš¡ **Plugs Into Claude Code** - Native integration via MCP (Model Context Protocol). Use ruflo commands directly in your Claude Code sessions with full tool access.

ğŸ”’ **Production-Ready Security** - Built-in protection against prompt injection, input validation, path traversal prevention, command injection blocking, and safe credential handling.

ğŸ§© **Extensible Plugin System** - Add custom capabilities with the plugin SDK. Create workers, hooks, providers, and security modules. Share plugins via the decentralized IPFS marketplace.

---

### A multi-purpose Agent Tool Kit 

&lt;details&gt;
&lt;summary&gt;ğŸ”„ &lt;strong&gt;Core Flow&lt;/strong&gt; â€” How requests move through the system&lt;/summary&gt;

Every request flows through four layers: from your CLI or Claude Code interface, through intelligent routing, to specialized agents, and finally to LLM providers for reasoning.

| Layer | Components | What It Does |
|-------|------------|--------------|
| User | Claude Code, CLI | Your interface to control and run commands |
| Orchestration | MCP Server, Router, Hooks | Routes requests to the right agents |
| Agents | 60+ types | Specialized workers (coder, tester, reviewer...) |
| Providers | Anthropic, OpenAI, Google, Ollama | AI models that power reasoning |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ &lt;strong&gt;Swarm Coordination&lt;/strong&gt; â€” How agents work together&lt;/summary&gt;

Agents organize into swarms led by queens that coordinate work, prevent drift, and reach consensus on decisionsâ€”even when some agents fail.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Coordination | Queen, Swarm, Consensus | Manages agent teams (Raft, Byzantine, Gossip) |
| Drift Control | Hierarchical topology, Checkpoints | Prevents agents from going off-task |
| Hive Mind | Queen-led hierarchy, Collective memory | Strategic/tactical/adaptive queens coordinate workers |
| Consensus | Byzantine, Weighted, Majority | Fault-tolerant decisions (2/3 majority for BFT) |

**Hive Mind Capabilities:**
- ğŸ **Queen Types**: Strategic (planning), Tactical (execution), Adaptive (optimization)
- ğŸ‘· **8 Worker Types**: Researcher, Coder, Analyst, Tester, Architect, Reviewer, Optimizer, Documenter
- ğŸ—³ï¸ **3 Consensus Algorithms**: Majority, Weighted (Queen 3x), Byzantine (f &lt; n/3)
- ğŸ§  **Collective Memory**: Shared knowledge, LRU cache, SQLite persistence with WAL
- âš¡ **Performance**: 10-20x faster batch spawning, 84.8% SWE-Bench solve rate

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ§  &lt;strong&gt;Intelligence &amp; Memory&lt;/strong&gt; â€” How the system learns and remembers&lt;/summary&gt;

The system stores successful patterns in vector memory, builds a knowledge graph for structural understanding, learns from outcomes via neural networks, and adapts routing based on what works best.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Memory | HNSW, AgentDB, Cache | Stores and retrieves patterns 150x faster |
| Knowledge Graph | MemoryGraph, PageRank, Communities | Identifies influential insights, detects clusters (ADR-049) |
| Self-Learning | LearningBridge, SONA, ReasoningBank | Triggers learning from insights, confidence lifecycle (ADR-049) |
| Agent Scopes | AgentMemoryScope, 3-scope dirs | Per-agent isolation + cross-agent knowledge transfer (ADR-049) |
| Embeddings | ONNX Runtime, MiniLM | Local vectors without API calls (75x faster) |
| Learning | SONA, MoE, ReasoningBank | Self-improves from results (&lt;0.05ms adaptation) |
| Fine-tuning | MicroLoRA, EWC++ | Lightweight adaptation without full retraining |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;âš¡ &lt;strong&gt;Optimization&lt;/strong&gt; â€” How to reduce cost and latency&lt;/summary&gt;

Skip expensive LLM calls for simple tasks using WebAssembly transforms, and compress tokens to reduce API costs by 30-50%.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Agent Booster | WASM, AST analysis | Skips LLM for simple edits (&lt;1ms) |
| Token Optimizer | Compression, Caching | Reduces token usage 30-50% |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ”§ &lt;strong&gt;Operations&lt;/strong&gt; â€” Background services and integrations&lt;/summary&gt;

Background daemons handle security audits, performance optimization, and session persistence automatically while you work.

| Layer | Components | What It Does |
|-------|------------|--------------|
| Background | Daemon, 12 Workers | Auto-runs audits, optimization, learning |
| Security | AIDefence, Validation | Blocks injection, detects threats |
| Sessions | Persist, Restore, Export | Saves context across conversations |
| GitHub | PR, Issues, Workflows | Manages repos and code reviews |
| Analytics | Metrics, Benchmarks | Monitors performance, finds bottlenecks |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ¯ &lt;strong&gt;Task Routing&lt;/strong&gt; â€” Extend your Claude Code subscription by 250%&lt;/summary&gt;

Smart routing skips expensive LLM calls when possible. Simple edits use WASM (free), medium tasks use cheaper models. This can extend your Claude Code usage by 250% or save significantly on direct API costs.

| Complexity | Handler | Speed |
|------------|---------|-------|
| Simple | Agent Booster (WASM) | &lt;1ms |
| Medium | Haiku/Sonnet | ~500ms |
| Complex | Opus + Swarm | 2-5s |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;âš¡ &lt;strong&gt;Agent Booster (WASM)&lt;/strong&gt; â€” 352x faster code transforms, skip LLM entirely&lt;/summary&gt;

Agent Booster uses WebAssembly to handle simple code transformations without calling the LLM at all. When the hooks system detects a simple task, it routes directly to Agent Booster for instant results.

**Supported Transform Intents:**

| Intent | What It Does | Example |
|--------|--------------|---------|
| `var-to-const` | Convert var/let to const | `var x = 1` â†’ `const x = 1` |
| `add-types` | Add TypeScript type annotations | `function foo(x)` â†’ `function foo(x: string)` |
| `add-error-handling` | Wrap in try/catch | Adds proper error handling |
| `async-await` | Convert promises to async/await | `.then()` chains â†’ `await` |
| `add-logging` | Add console.log statements | Adds debug logging |
| `remove-console` | Strip console.* calls | Removes all console statements |

**Hook Signals:**

When you see these in hook output, the system is telling you how to optimize:

```bash
# Agent Booster available - skip LLM entirely
[AGENT_BOOSTER_AVAILABLE] Intent: var-to-const
â†’ Use Edit tool directly, 352x faster than LLM

# Model recommendation for Task tool
[TASK_MODEL_RECOMMENDATION] Use model=&quot;haiku&quot;
â†’ Pass model=&quot;haiku&quot; to Task tool for cost savings
```

**Performance:**

| Metric | Agent Booster | LLM Call |
|--------|---------------|----------|
| Latency | &lt;1ms | 2-5s |
| Cost | $0 | $0.0002-$0.015 |
| Speedup | **352x faster** | baseline |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ’° &lt;strong&gt;Token Optimizer&lt;/strong&gt; â€” 30-50% token reduction&lt;/summary&gt;

The Token Optimizer integrates agentic-flow optimizations to reduce API costs by compressing context and caching results.

**Savings Breakdown:**

| Optimization | Token Savings | How It Works |
|--------------|---------------|--------------|
| ReasoningBank retrieval | -32% | Fetches relevant patterns instead of full context |
| Agent Booster edits | -15% | Simple edits skip LLM entirely |
| Cache (95% hit rate) | -10% | Reuses embeddings and patterns |
| Optimal batch size | -20% | Groups related operations |
| **Combined** | **30-50%** | Stacks multiplicatively |

**Usage:**

```typescript
import { getTokenOptimizer } from &#039;@claude-flow/integration&#039;;
const optimizer = await getTokenOptimizer();

// Get compact context (32% fewer tokens)
const ctx = await optimizer.getCompactContext(&quot;auth patterns&quot;);

// Optimized edit (352x faster for simple transforms)
await optimizer.optimizedEdit(file, oldStr, newStr, &quot;typescript&quot;);

// Optimal config for swarm (100% success rate)
const config = optimizer.getOptimalConfig(agentCount);
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ›¡ï¸ &lt;strong&gt;Anti-Drift Swarm Configuration&lt;/strong&gt; â€” Prevent goal drift in multi-agent work&lt;/summary&gt;

Complex swarms can drift from their original goals. Ruflo V3 includes anti-drift defaults that prevent agents from going off-task.

**Recommended Configuration:**

```javascript
// Anti-drift defaults (ALWAYS use for coding tasks)
swarm_init({
  topology: &quot;hierarchical&quot;,  // Single coordinator enforces alignment
  maxAgents: 8,              // Smaller team = less drift surface
  strategy: &quot;specialized&quot;    // Clear roles reduce ambiguity
})
```

**Why This Prevents Drift:**

| Setting | Anti-Drift Benefit |
|---------|-------------------|
| `hierarchical` | Coordinator validates each output against goal, catches divergence early |
| `maxAgents: 6-8` | Fewer agents = less coordination overhead, easier alignment |
| `specialized` | Clear boundaries - each agent knows exactly what to do, no overlap |
| `raft` consensus | Leader maintains authoritative state, no conflicting decisions |

**Additional Anti-Drift Measures:**

- Frequent checkpoints via `post-task` hooks
- Shared memory namespace for all agents
- Short task cycles with verification gates
- Hierarchical coordinator reviews all outputs

**Task â†’ Agent Routing (Anti-Drift):**

| Code | Task Type | Recommended Agents |
|------|-----------|-------------------|
| 1 | Bug Fix | coordinator, researcher, coder, tester |
| 3 | Feature | coordinator, architect, coder, tester, reviewer |
| 5 | Refactor | coordinator, architect, coder, reviewer |
| 7 | Performance | coordinator, perf-engineer, coder |
| 9 | Security | coordinator, security-architect, auditor |
| 11 | Memory | coordinator, memory-specialist, perf-engineer |

&lt;/details&gt;

### Claude Code: With vs Without Ruflo

| Capability | Claude Code Alone | Claude Code + Ruflo |
|------------|-------------------|---------------------------|
| **Agent Collaboration** | Agents work in isolation, no shared context | Agents collaborate via swarms with shared memory and consensus |
| **Coordination** | Manual orchestration between tasks | Queen-led hierarchy with 5 consensus algorithms (Raft, Byzantine, Gossip) |
| **Hive Mind** | â›” Not available | ğŸ Queen-led swarms with collective intelligence, 3 queen types, 8 worker types |
| **Consensus** | â›” No multi-agent decisions | Byzantine fault-tolerant voting (f &lt; n/3), weighted, majority |
| **Memory** | Session-only, no persistence | HNSW vector memory with 150x-12,500x faster retrieval + knowledge graph |
| **Vector Database** | â›” No native support | ğŸ˜ RuVector PostgreSQL with 77+ SQL functions, ~61Âµs search, 16,400 QPS |
| **Knowledge Graph** | â›” Flat insight lists | PageRank + community detection identifies influential insights (ADR-049) |
| **Collective Memory** | â›” No shared knowledge | Shared knowledge base with LRU cache, SQLite persistence, 8 memory types |
| **Learning** | Static behavior, no adaptation | SONA self-learning with &lt;0.05ms adaptation, LearningBridge for insights |
| **Agent Scoping** | Single project scope | 3-scope agent memory (project/local/user) with cross-agent transfer |
| **Task Routing** | You decide which agent to use | Intelligent routing based on learned patterns (89% accuracy) |
| **Complex Tasks** | Manual breakdown required | Automatic decomposition across 5 domains (Security, Core, Integration, Support) |
| **Background Workers** | Nothing runs automatically | 12 context-triggered workers auto-dispatch on file changes, patterns, sessions |
| **LLM Provider** | Anthropic only | 6 providers with automatic failover and cost-based routing (85% savings) |
| **Security** | Standard protections | CVE-hardened with bcrypt, input validation, path traversal prevention |
| **Performance** | Baseline | 2.8-4.4x faster tasks, 10-20x faster swarm spawning, 84.8% SWE-Bench |

## Quick Start

### Prerequisites

- **Node.js 20+** (required)
- **npm 9+** / **pnpm** / **bun** package manager

**IMPORTANT**: Claude Code must be installed first:

```bash
# 1. Install Claude Code globally
npm install -g @anthropic-ai/claude-code

# 2. (Optional) Skip permissions check for faster setup
claude --dangerously-skip-permissions
```

### Instal

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[badlogic/pi-mono]]></title>
            <link>https://github.com/badlogic/pi-mono</link>
            <guid>https://github.com/badlogic/pi-mono</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:26 GMT</pubDate>
            <description><![CDATA[AI agent toolkit: coding agent CLI, unified LLM API, TUI & web UI libraries, Slack bot, vLLM pods]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/badlogic/pi-mono">badlogic/pi-mono</a></h1>
            <p>AI agent toolkit: coding agent CLI, unified LLM API, TUI & web UI libraries, Slack bot, vLLM pods</p>
            <p>Language: TypeScript</p>
            <p>Stars: 17,119</p>
            <p>Forks: 1,789</p>
            <p>Stars today: 589 stars today</p>
            <h2>README</h2><pre># ğŸ–ï¸ OSS Vacation

**Issue tracker and PRs reopen March 2, 2026.**

All PRs will be auto-closed until then. Approved contributors can submit PRs after vacation without reapproval. For support, join [Discord](https://discord.com/invite/3cU7Bz4UPx).

---

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://shittycodingagent.ai&quot;&gt;
    &lt;img src=&quot;https://shittycodingagent.ai/logo.svg&quot; alt=&quot;pi logo&quot; width=&quot;128&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.com/invite/3cU7Bz4UPx&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/badge/discord-community-5865F2?style=flat-square&amp;logo=discord&amp;logoColor=white&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/badlogic/pi-mono/actions/workflows/ci.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/badlogic/pi-mono/ci.yml?style=flat-square&amp;branch=main&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pi.dev&quot;&gt;pi.dev&lt;/a&gt; domain graciously donated by
  &lt;br /&gt;&lt;br /&gt;
  &lt;a href=&quot;https://exe.dev&quot;&gt;&lt;img src=&quot;packages/coding-agent/docs/images/exy.png&quot; alt=&quot;Exy mascot&quot; width=&quot;48&quot; /&gt;&lt;br /&gt;exe.dev&lt;/a&gt;
&lt;/p&gt;

# Pi Monorepo

&gt; **Looking for the pi coding agent?** See **[packages/coding-agent](packages/coding-agent)** for installation and usage.

Tools for building AI agents and managing LLM deployments.

## Packages

| Package | Description |
|---------|-------------|
| **[@mariozechner/pi-ai](packages/ai)** | Unified multi-provider LLM API (OpenAI, Anthropic, Google, etc.) |
| **[@mariozechner/pi-agent-core](packages/agent)** | Agent runtime with tool calling and state management |
| **[@mariozechner/pi-coding-agent](packages/coding-agent)** | Interactive coding agent CLI |
| **[@mariozechner/pi-mom](packages/mom)** | Slack bot that delegates messages to the pi coding agent |
| **[@mariozechner/pi-tui](packages/tui)** | Terminal UI library with differential rendering |
| **[@mariozechner/pi-web-ui](packages/web-ui)** | Web components for AI chat interfaces |
| **[@mariozechner/pi-pods](packages/pods)** | CLI for managing vLLM deployments on GPU pods |

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for contribution guidelines and [AGENTS.md](AGENTS.md) for project-specific rules (for both humans and agents).

## Development

```bash
npm install          # Install all dependencies
npm run build        # Build all packages
npm run check        # Lint, format, and type check
./test.sh            # Run tests (skips LLM-dependent tests without API keys)
./pi-test.sh         # Run pi from sources (must be run from repo root)
```

&gt; **Note:** `npm run check` requires `npm run build` to be run first. The web-ui package uses `tsc` which needs compiled `.d.ts` files from dependencies.

## License

MIT</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[virattt/dexter]]></title>
            <link>https://github.com/virattt/dexter</link>
            <guid>https://github.com/virattt/dexter</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:25 GMT</pubDate>
            <description><![CDATA[An autonomous agent for deep financial research]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/virattt/dexter">virattt/dexter</a></h1>
            <p>An autonomous agent for deep financial research</p>
            <p>Language: TypeScript</p>
            <p>Stars: 16,578</p>
            <p>Forks: 2,017</p>
            <p>Stars today: 122 stars today</p>
            <h2>README</h2><pre># Dexter ğŸ¤–

Dexter is an autonomous financial research agent that thinks, plans, and learns as it works. It performs analysis using task planning, self-reflection, and real-time market data. Think Claude Code, but built specifically for financial research.

&lt;img width=&quot;1098&quot; height=&quot;659&quot; alt=&quot;Screenshot 2026-01-21 at 5 25 10 PM&quot; src=&quot;https://github.com/user-attachments/assets/3bcc3a7f-b68a-4f5e-8735-9d22196ff76e&quot; /&gt;

## Table of Contents

- [ğŸ‘‹ Overview](#-overview)
- [âœ… Prerequisites](#-prerequisites)
- [ğŸ’» How to Install](#-how-to-install)
- [ğŸš€ How to Run](#-how-to-run)
- [ğŸ“Š How to Evaluate](#-how-to-evaluate)
- [ğŸ› How to Debug](#-how-to-debug)
- [ğŸ“± How to Use with WhatsApp](#-how-to-use-with-whatsapp)
- [ğŸ¤ How to Contribute](#-how-to-contribute)
- [ğŸ“„ License](#-license)


## ğŸ‘‹ Overview

Dexter takes complex financial questions and turns them into clear, step-by-step research plans. It runs those tasks using live market data, checks its own work, and refines the results until it has a confident, data-backed answer.  

**Key Capabilities:**
- **Intelligent Task Planning**: Automatically decomposes complex queries into structured research steps
- **Autonomous Execution**: Selects and executes the right tools to gather financial data
- **Self-Validation**: Checks its own work and iterates until tasks are complete
- **Real-Time Financial Data**: Access to income statements, balance sheets, and cash flow statements
- **Safety Features**: Built-in loop detection and step limits to prevent runaway execution

[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt) [![Discord](https://img.shields.io/badge/Discord-Join%20Server-5865F2?style=social&amp;logo=discord)](https://discord.gg/jpGHv2XB6T)

&lt;img width=&quot;1042&quot; height=&quot;638&quot; alt=&quot;Screenshot 2026-02-18 at 12 21 25â€¯PM&quot; src=&quot;https://github.com/user-attachments/assets/2a6334f9-863f-4bd2-a56f-923e42f4711e&quot; /&gt;


## âœ… Prerequisites

- [Bun](https://bun.com) runtime (v1.0 or higher)
- OpenAI API key (get [here](https://platform.openai.com/api-keys))
- Financial Datasets API key (get [here](https://financialdatasets.ai))
- Exa API key (get [here](https://exa.ai)) - optional, for web search

#### Installing Bun

If you don&#039;t have Bun installed, you can install it using curl:

**macOS/Linux:**
```bash
curl -fsSL https://bun.com/install | bash
```

**Windows:**
```bash
powershell -c &quot;irm bun.sh/install.ps1|iex&quot;
```

After installation, restart your terminal and verify Bun is installed:
```bash
bun --version
```

## ğŸ’» How to Install

1. Clone the repository:
```bash
git clone https://github.com/virattt/dexter.git
cd dexter
```

2. Install dependencies with Bun:
```bash
bun install
```

3. Set up your environment variables:
```bash
# Copy the example environment file
cp env.example .env

# Edit .env and add your API keys (if using cloud providers)
# OPENAI_API_KEY=your-openai-api-key
# ANTHROPIC_API_KEY=your-anthropic-api-key (optional)
# GOOGLE_API_KEY=your-google-api-key (optional)
# XAI_API_KEY=your-xai-api-key (optional)
# OPENROUTER_API_KEY=your-openrouter-api-key (optional)

# Institutional-grade market data for agents; AAPL, NVDA, MSFT are free
# FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key

# (Optional) If using Ollama locally
# OLLAMA_BASE_URL=http://127.0.0.1:11434

# Web Search (Exa preferred, Tavily fallback)
# EXASEARCH_API_KEY=your-exa-api-key
# TAVILY_API_KEY=your-tavily-api-key
```

## ğŸš€ How to Run

Run Dexter in interactive mode:
```bash
bun start
```

Or with watch mode for development:
```bash
bun dev
```

## ğŸ“Š How to Evaluate

Dexter includes an evaluation suite that tests the agent against a dataset of financial questions. Evals use LangSmith for tracking and an LLM-as-judge approach for scoring correctness.

**Run on all questions:**
```bash
bun run src/evals/run.ts
```

**Run on a random sample of data:**
```bash
bun run src/evals/run.ts --sample 10
```

The eval runner displays a real-time UI showing progress, current question, and running accuracy statistics. Results are logged to LangSmith for analysis.

## ğŸ› How to Debug

Dexter logs all tool calls to a scratchpad file for debugging and history tracking. Each query creates a new JSONL file in `.dexter/scratchpad/`.

**Scratchpad location:**
```
.dexter/scratchpad/
â”œâ”€â”€ 2026-01-30-111400_9a8f10723f79.jsonl
â”œâ”€â”€ 2026-01-30-143022_a1b2c3d4e5f6.jsonl
â””â”€â”€ ...
```

Each file contains newline-delimited JSON entries tracking:
- **init**: The original query
- **tool_result**: Each tool call with arguments, raw result, and LLM summary
- **thinking**: Agent reasoning steps

**Example scratchpad entry:**
```json
{&quot;type&quot;:&quot;tool_result&quot;,&quot;timestamp&quot;:&quot;2026-01-30T11:14:05.123Z&quot;,&quot;toolName&quot;:&quot;get_income_statements&quot;,&quot;args&quot;:{&quot;ticker&quot;:&quot;AAPL&quot;,&quot;period&quot;:&quot;annual&quot;,&quot;limit&quot;:5},&quot;result&quot;:{...},&quot;llmSummary&quot;:&quot;Retrieved 5 years of Apple annual income statements showing revenue growth from $274B to $394B&quot;}
```

This makes it easy to inspect exactly what data the agent gathered and how it interpreted results.

## ğŸ“± How to Use with WhatsApp

Chat with Dexter through WhatsApp by linking your phone to the gateway. Messages you send to yourself are processed by Dexter and responses are sent back to the same chat.

**Quick start:**
```bash
# Link your WhatsApp account (scan QR code)
bun run gateway:login

# Start the gateway
bun run gateway
```

Then open WhatsApp, go to your own chat (message yourself), and ask Dexter a question.

For detailed setup instructions, configuration options, and troubleshooting, see the [WhatsApp Gateway README](src/gateway/channels/whatsapp/README.md).

## ğŸ¤ How to Contribute

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.


## ğŸ“„ License

This project is licensed under the MIT License.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[openclaw/openclaw]]></title>
            <link>https://github.com/openclaw/openclaw</link>
            <guid>https://github.com/openclaw/openclaw</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:24 GMT</pubDate>
            <description><![CDATA[Your own personal AI assistant. Any OS. Any Platform. The lobster way. ğŸ¦]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openclaw/openclaw">openclaw/openclaw</a></h1>
            <p>Your own personal AI assistant. Any OS. Any Platform. The lobster way. ğŸ¦</p>
            <p>Language: TypeScript</p>
            <p>Stars: 232,817</p>
            <p>Forks: 44,718</p>
            <p>Stars today: 4,114 stars today</p>
            <h2>README</h2><pre># ğŸ¦ OpenClaw â€” Personal AI Assistant

&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text-dark.png&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/openclaw/openclaw/main/docs/assets/openclaw-logo-text.png&quot; alt=&quot;OpenClaw&quot; width=&quot;500&quot;&gt;
    &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;EXFOLIATE! EXFOLIATE!&lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/openclaw/openclaw/actions/workflows/ci.yml?branch=main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/openclaw/openclaw/ci.yml?branch=main&amp;style=for-the-badge&quot; alt=&quot;CI status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/openclaw/openclaw/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/openclaw/openclaw?include_prereleases&amp;style=for-the-badge&quot; alt=&quot;GitHub release&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/clawd&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1456350064065904867?label=Discord&amp;logo=discord&amp;logoColor=white&amp;color=5865F2&amp;style=for-the-badge&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge&quot; alt=&quot;MIT License&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

**OpenClaw** is a _personal AI assistant_ you run on your own devices.
It answers you on the channels you already use (WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, WebChat), plus extension channels like BlueBubbles, Matrix, Zalo, and Zalo Personal. It can speak and listen on macOS/iOS/Android, and can render a live Canvas you control. The Gateway is just the control plane â€” the product is the assistant.

If you want a personal, single-user assistant that feels local, fast, and always-on, this is it.

[Website](https://openclaw.ai) Â· [Docs](https://docs.openclaw.ai) Â· [Vision](VISION.md) Â· [DeepWiki](https://deepwiki.com/openclaw/openclaw) Â· [Getting Started](https://docs.openclaw.ai/start/getting-started) Â· [Updating](https://docs.openclaw.ai/install/updating) Â· [Showcase](https://docs.openclaw.ai/start/showcase) Â· [FAQ](https://docs.openclaw.ai/help/faq) Â· [Wizard](https://docs.openclaw.ai/start/wizard) Â· [Nix](https://github.com/openclaw/nix-openclaw) Â· [Docker](https://docs.openclaw.ai/install/docker) Â· [Discord](https://discord.gg/clawd)

Preferred setup: run the onboarding wizard (`openclaw onboard`) in your terminal.
The wizard guides you step by step through setting up the gateway, workspace, channels, and skills. The CLI wizard is the recommended path and works on **macOS, Linux, and Windows (via WSL2; strongly recommended)**.
Works with npm, pnpm, or bun.
New install? Start here: [Getting started](https://docs.openclaw.ai/start/getting-started)

## Sponsors

| OpenAI                                                            | Blacksmith                                                                   |
| ----------------------------------------------------------------- | ---------------------------------------------------------------------------- |
| [![OpenAI](docs/assets/sponsors/openai.svg)](https://openai.com/) | [![Blacksmith](docs/assets/sponsors/blacksmith.svg)](https://blacksmith.sh/) |

**Subscriptions (OAuth):**

- **[OpenAI](https://openai.com/)** (ChatGPT/Codex)

Model note: while any model is supported, I strongly recommend **Anthropic Pro/Max (100/200) + Opus 4.6** for longâ€‘context strength and better promptâ€‘injection resistance. See [Onboarding](https://docs.openclaw.ai/start/onboarding).

## Models (selection + auth)

- Models config + CLI: [Models](https://docs.openclaw.ai/concepts/models)
- Auth profile rotation (OAuth vs API keys) + fallbacks: [Model failover](https://docs.openclaw.ai/concepts/model-failover)

## Install (recommended)

Runtime: **Node â‰¥22**.

```bash
npm install -g openclaw@latest
# or: pnpm add -g openclaw@latest

openclaw onboard --install-daemon
```

The wizard installs the Gateway daemon (launchd/systemd user service) so it stays running.

## Quick start (TL;DR)

Runtime: **Node â‰¥22**.

Full beginner guide (auth, pairing, channels): [Getting started](https://docs.openclaw.ai/start/getting-started)

```bash
openclaw onboard --install-daemon

openclaw gateway --port 18789 --verbose

# Send a message
openclaw message send --to +1234567890 --message &quot;Hello from OpenClaw&quot;

# Talk to the assistant (optionally deliver back to any connected channel: WhatsApp/Telegram/Slack/Discord/Google Chat/Signal/iMessage/BlueBubbles/Microsoft Teams/Matrix/Zalo/Zalo Personal/WebChat)
openclaw agent --message &quot;Ship checklist&quot; --thinking high
```

Upgrading? [Updating guide](https://docs.openclaw.ai/install/updating) (and run `openclaw doctor`).

## Development channels

- **stable**: tagged releases (`vYYYY.M.D` or `vYYYY.M.D-&lt;patch&gt;`), npm dist-tag `latest`.
- **beta**: prerelease tags (`vYYYY.M.D-beta.N`), npm dist-tag `beta` (macOS app may be missing).
- **dev**: moving head of `main`, npm dist-tag `dev` (when published).

Switch channels (git + npm): `openclaw update --channel stable|beta|dev`.
Details: [Development channels](https://docs.openclaw.ai/install/development-channels).

## From source (development)

Prefer `pnpm` for builds from source. Bun is optional for running TypeScript directly.

```bash
git clone https://github.com/openclaw/openclaw.git
cd openclaw

pnpm install
pnpm ui:build # auto-installs UI deps on first run
pnpm build

pnpm openclaw onboard --install-daemon

# Dev loop (auto-reload on TS changes)
pnpm gateway:watch
```

Note: `pnpm openclaw ...` runs TypeScript directly (via `tsx`). `pnpm build` produces `dist/` for running via Node / the packaged `openclaw` binary.

## Security defaults (DM access)

OpenClaw connects to real messaging surfaces. Treat inbound DMs as **untrusted input**.

Full security guide: [Security](https://docs.openclaw.ai/gateway/security)

Default behavior on Telegram/WhatsApp/Signal/iMessage/Microsoft Teams/Discord/Google Chat/Slack:

- **DM pairing** (`dmPolicy=&quot;pairing&quot;` / `channels.discord.dmPolicy=&quot;pairing&quot;` / `channels.slack.dmPolicy=&quot;pairing&quot;`; legacy: `channels.discord.dm.policy`, `channels.slack.dm.policy`): unknown senders receive a short pairing code and the bot does not process their message.
- Approve with: `openclaw pairing approve &lt;channel&gt; &lt;code&gt;` (then the sender is added to a local allowlist store).
- Public inbound DMs require an explicit opt-in: set `dmPolicy=&quot;open&quot;` and include `&quot;*&quot;` in the channel allowlist (`allowFrom` / `channels.discord.allowFrom` / `channels.slack.allowFrom`; legacy: `channels.discord.dm.allowFrom`, `channels.slack.dm.allowFrom`).

Run `openclaw doctor` to surface risky/misconfigured DM policies.

## Highlights

- **[Local-first Gateway](https://docs.openclaw.ai/gateway)** â€” single control plane for sessions, channels, tools, and events.
- **[Multi-channel inbox](https://docs.openclaw.ai/channels)** â€” WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, BlueBubbles (iMessage), iMessage (legacy), Microsoft Teams, Matrix, Zalo, Zalo Personal, WebChat, macOS, iOS/Android.
- **[Multi-agent routing](https://docs.openclaw.ai/gateway/configuration)** â€” route inbound channels/accounts/peers to isolated agents (workspaces + per-agent sessions).
- **[Voice Wake](https://docs.openclaw.ai/nodes/voicewake) + [Talk Mode](https://docs.openclaw.ai/nodes/talk)** â€” always-on speech for macOS/iOS/Android with ElevenLabs.
- **[Live Canvas](https://docs.openclaw.ai/platforms/mac/canvas)** â€” agent-driven visual workspace with [A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui).
- **[First-class tools](https://docs.openclaw.ai/tools)** â€” browser, canvas, nodes, cron, sessions, and Discord/Slack actions.
- **[Companion apps](https://docs.openclaw.ai/platforms/macos)** â€” macOS menu bar app + iOS/Android [nodes](https://docs.openclaw.ai/nodes).
- **[Onboarding](https://docs.openclaw.ai/start/wizard) + [skills](https://docs.openclaw.ai/tools/skills)** â€” wizard-driven setup with bundled/managed/workspace skills.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=openclaw/openclaw&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#openclaw/openclaw&amp;type=date&amp;legend=top-left)

## Everything we built so far

### Core platform

- [Gateway WS control plane](https://docs.openclaw.ai/gateway) with sessions, presence, config, cron, webhooks, [Control UI](https://docs.openclaw.ai/web), and [Canvas host](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui).
- [CLI surface](https://docs.openclaw.ai/tools/agent-send): gateway, agent, send, [wizard](https://docs.openclaw.ai/start/wizard), and [doctor](https://docs.openclaw.ai/gateway/doctor).
- [Pi agent runtime](https://docs.openclaw.ai/concepts/agent) in RPC mode with tool streaming and block streaming.
- [Session model](https://docs.openclaw.ai/concepts/session): `main` for direct chats, group isolation, activation modes, queue modes, reply-back. Group rules: [Groups](https://docs.openclaw.ai/channels/groups).
- [Media pipeline](https://docs.openclaw.ai/nodes/images): images/audio/video, transcription hooks, size caps, temp file lifecycle. Audio details: [Audio](https://docs.openclaw.ai/nodes/audio).

### Channels

- [Channels](https://docs.openclaw.ai/channels): [WhatsApp](https://docs.openclaw.ai/channels/whatsapp) (Baileys), [Telegram](https://docs.openclaw.ai/channels/telegram) (grammY), [Slack](https://docs.openclaw.ai/channels/slack) (Bolt), [Discord](https://docs.openclaw.ai/channels/discord) (discord.js), [Google Chat](https://docs.openclaw.ai/channels/googlechat) (Chat API), [Signal](https://docs.openclaw.ai/channels/signal) (signal-cli), [BlueBubbles](https://docs.openclaw.ai/channels/bluebubbles) (iMessage, recommended), [iMessage](https://docs.openclaw.ai/channels/imessage) (legacy imsg), [Microsoft Teams](https://docs.openclaw.ai/channels/msteams) (extension), [Matrix](https://docs.openclaw.ai/channels/matrix) (extension), [Zalo](https://docs.openclaw.ai/channels/zalo) (extension), [Zalo Personal](https://docs.openclaw.ai/channels/zalouser) (extension), [WebChat](https://docs.openclaw.ai/web/webchat).
- [Group routing](https://docs.openclaw.ai/channels/group-messages): mention gating, reply tags, per-channel chunking and routing. Channel rules: [Channels](https://docs.openclaw.ai/channels).

### Apps + nodes

- [macOS app](https://docs.openclaw.ai/platforms/macos): menu bar control plane, [Voice Wake](https://docs.openclaw.ai/nodes/voicewake)/PTT, [Talk Mode](https://docs.openclaw.ai/nodes/talk) overlay, [WebChat](https://docs.openclaw.ai/web/webchat), debug tools, [remote gateway](https://docs.openclaw.ai/gateway/remote) control.
- [iOS node](https://docs.openclaw.ai/platforms/ios): [Canvas](https://docs.openclaw.ai/platforms/mac/canvas), [Voice Wake](https://docs.openclaw.ai/nodes/voicewake), [Talk Mode](https://docs.openclaw.ai/nodes/talk), camera, screen recording, Bonjour pairing.
- [Android node](https://docs.openclaw.ai/platforms/android): [Canvas](https://docs.openclaw.ai/platforms/mac/canvas), [Talk Mode](https://docs.openclaw.ai/nodes/talk), camera, screen recording, optional SMS.
- [macOS node mode](https://docs.openclaw.ai/nodes): system.run/notify + canvas/camera exposure.

### Tools + automation

- [Browser control](https://docs.openclaw.ai/tools/browser): dedicated openclaw Chrome/Chromium, snapshots, actions, uploads, profiles.
- [Canvas](https://docs.openclaw.ai/platforms/mac/canvas): [A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui) push/reset, eval, snapshot.
- [Nodes](https://docs.openclaw.ai/nodes): camera snap/clip, screen record, [location.get](https://docs.openclaw.ai/nodes/location-command), notifications.
- [Cron + wakeups](https://docs.openclaw.ai/automation/cron-jobs); [webhooks](https://docs.openclaw.ai/automation/webhook); [Gmail Pub/Sub](https://docs.openclaw.ai/automation/gmail-pubsub).
- [Skills platform](https://docs.openclaw.ai/tools/skills): bundled, managed, and workspace skills with install gating + UI.

### Runtime + safety

- [Channel routing](https://docs.openclaw.ai/channels/channel-routing), [retry policy](https://docs.openclaw.ai/concepts/retry), and [streaming/chunking](https://docs.openclaw.ai/concepts/streaming).
- [Presence](https://docs.openclaw.ai/concepts/presence), [typing indicators](https://docs.openclaw.ai/concepts/typing-indicators), and [usage tracking](https://docs.openclaw.ai/concepts/usage-tracking).
- [Models](https://docs.openclaw.ai/concepts/models), [model failover](https://docs.openclaw.ai/concepts/model-failover), and [session pruning](https://docs.openclaw.ai/concepts/session-pruning).
- [Security](https://docs.openclaw.ai/gateway/security) and [troubleshooting](https://docs.openclaw.ai/channels/troubleshooting).

### Ops + packaging

- [Control UI](https://docs.openclaw.ai/web) + [WebChat](https://docs.openclaw.ai/web/webchat) served directly from the Gateway.
- [Tailscale Serve/Funnel](https://docs.openclaw.ai/gateway/tailscale) or [SSH tunnels](https://docs.openclaw.ai/gateway/remote) with token/password auth.
- [Nix mode](https://docs.openclaw.ai/install/nix) for declarative config; [Docker](https://docs.openclaw.ai/install/docker)-based installs.
- [Doctor](https://docs.openclaw.ai/gateway/doctor) migrations, [logging](https://docs.openclaw.ai/logging).

## How it works (short)

```
WhatsApp / Telegram / Slack / Discord / Google Chat / Signal / iMessage / BlueBubbles / Microsoft Teams / Matrix / Zalo / Zalo Personal / WebChat
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Gateway            â”‚
â”‚       (control plane)         â”‚
â”‚     ws://127.0.0.1:18789      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€ Pi agent (RPC)
               â”œâ”€ CLI (openclaw â€¦)
               â”œâ”€ WebChat UI
               â”œâ”€ macOS app
               â””â”€ iOS / Android nodes
```

## Key subsystems

- **[Gateway WebSocket network](https://docs.openclaw.ai/concepts/architecture)** â€” single WS control plane for clients, tools, and events (plus ops: [Gateway runbook](https://docs.openclaw.ai/gateway)).
- **[Tailscale exposure](https://docs.openclaw.ai/gateway/tailscale)** â€” Serve/Funnel for the Gateway dashboard + WS (remote access: [Remote](https://docs.openclaw.ai/gateway/remote)).
- **[Browser control](https://docs.openclaw.ai/tools/browser)** â€” openclawâ€‘managed Chrome/Chromium with CDP control.
- **[Canvas + A2UI](https://docs.openclaw.ai/platforms/mac/canvas)** â€” agentâ€‘driven visual workspace (A2UI host: [Canvas/A2UI](https://docs.openclaw.ai/platforms/mac/canvas#canvas-a2ui)).
- **[Voice Wake](https://docs.openclaw.ai/nodes/voicewake) + [Talk Mode](https://docs.openclaw.ai/nodes/talk)** â€” alwaysâ€‘on speech and continuous conversation.
- **[Nodes](https://docs.openclaw.ai/nodes)** â€” Canvas, camera snap/clip, screen record, `location.get`, notifications, plus macOSâ€‘only `system.run`/`system.notify`.

## Tailscale access (Gateway dashboard)

OpenClaw can auto-configure Tailscale **Serve** (tailnet-only) or **Funnel** (public) while the Gateway stays bound to loopback. Configure `gateway.tailscale.mode`:

- `off`: no Tailscale automation (default).
- `serve`: tailnet-only HTTPS via `tailscale serve` (uses Tailscale identity headers by default).
- `funnel`: public HTTPS via `tailscale funnel` (requires shared password auth).

Notes:

- `gateway.bind` must stay `loopback` when Serve/Funnel is enabled (OpenClaw enforces this).
- Serve can be forced to require a password by setting `gateway.auth.mode: &quot;password&quot;` or `gateway.auth.allowTailscale: false`.
- Funnel refuses to start unless `gateway.auth.mode: &quot;password&quot;` is set.
- Optional: `gateway.tailscale.resetOnExit` to undo Serve/Funnel on shutdown.

Details: [Tailscale guide](https://docs.openclaw.ai/gateway/tailscale) Â· [Web surfaces](https://docs.openclaw.ai/web)

## Remote Gateway (Linux is great)

Itâ€™s perfectly fine to run the Gateway on a small Linux instance. Clients (macOS app, CLI, WebChat) can connect over **Tailscale Serve/Funnel** or **SSH tunnels**, and you can still pair device nodes (macOS/iOS/Android) to execute deviceâ€‘local actions when needed.

- **Gateway host** runs the exec tool and channel connections by default.
- **Device nodes** run deviceâ€‘local actions (`system.run`, camera, screen recording, notifications) via `node.invoke`.
  In short: exec runs where the Gateway lives; device actions run where the device lives.

Details: [Remote access](https://docs.openclaw.ai/gateway/remote) Â· [Nodes](https://docs.openclaw.ai/nodes) Â· [Security](https://docs.openclaw.ai/gateway/security)

## macOS permissions via the Gateway protocol

The macOS app can run in **node mode** and advertises its capabilities + permission map over the Gateway WebSocket (`node.list` / `node.describe`). Clients can then execute local actions via `node.invoke`:

- `system.run` runs a local command and returns stdout/stderr/exit code; set `needsScreenRecording: true` to require screen-recording permission (otherwise youâ€™ll get `PERMISSION_MISSING`).
- `system.notify` posts a user notification and fails if notifications are denied.
- `canvas.*`, `camera.*`, `screen.record`, and `location.get` are also routed via `node.invoke` and follow TCC permission status.

Elevated bash (host permissions) is separate from macOS TCC:

- Use `/elevated on|off` to toggle perâ€‘session elevated access when enabled + allowlisted.
- Gateway persists the perâ€‘session toggle via `sessions.patch` (WS method) alongside `thinkingLevel`, `verboseLevel`, `model`, `sendPolicy`, and `groupActivation`.

Details: [Nodes](https://docs.openclaw.ai/nodes) Â· [macOS app](https://docs.openclaw.ai/platforms/macos) Â· [Gateway protocol](https://docs.openclaw.ai/concepts/architecture)

## Agent to Agent (sessions\_\* tools)

- Use these to coordinate work across sessions without jumping between chat surfaces.
- `sessions_list` â€” discover active sessions (agents) and their metadata.
- `sessions_history` â€” fetch transcript logs for a session.
- `sessions_send` â€” message another session; optional replyâ€‘back pingâ€‘pong + announce step (`REPLY_SKIP`, `ANNOUNCE_SKIP`).

Details: [Session tools](https://docs.openclaw.ai/concepts/session-tool)

## Skills registry (ClawHub)

ClawHub is a minimal skill registry. With ClawHub enabled, the agent can search for skills automatically and pull in new ones as needed.

[ClawHub](https://clawhub.com)

## Chat commands

Send these in WhatsApp/Telegram/Slack/Google Chat/Microsoft Teams/WebChat (group commands are owner-only):

- `/status` â€” compact session status (model + tokens, cost when available)
- `/new` or `/reset` â€” reset the session
- `/compact` â€” compact session context (summary)
- `/think &lt;level&gt;` â€” off|minimal|low|medium|high|xhigh (GPT-5.2 + Codex models only)
- `/verbose on|off`
- `/usage off|tokens|full` â€” per-response usage footer
- `/restart` â€” restart the gateway (owner-only in groups)
- `/activation mention|always` â€” group activation toggle (groups only)

## Apps (optional)

The Gateway alone delivers a great experience. All apps are optional and add extra features.

If you plan to build/run companion apps, follow the platform runbooks below.

### macOS (OpenClaw.app) (optional)

- Menu bar control for the Gateway and health.
- Voice Wake + push-to-talk overlay.
- WebChat + debug tools.
- Remote gateway control over SSH.

Note: signed builds required for macOS permissions to stick across rebuilds (see `docs/mac/permissions.md`).

### iOS node (optional)

- Pairs as a node via the Bridge.
- Voice trigger forwarding + Canvas surface.
- Controlled via `openclaw nodes â€¦`.

Runbook: [iOS connect](https://docs.openclaw.ai/platforms/ios).

### Android node (optional)

- Pairs via the same Bridge + pairing flow as iOS.
- Exposes Canvas, Camera, and Screen capture commands.
- Runbook: [Android connect](https://docs.openclaw.ai/platforms/android).

## Agent workspace + skills

- Workspace root: `~/.openclaw/workspace` (configurab

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[code-yeongyu/oh-my-opencode]]></title>
            <link>https://github.com/code-yeongyu/oh-my-opencode</link>
            <guid>https://github.com/code-yeongyu/oh-my-opencode</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:23 GMT</pubDate>
            <description><![CDATA[the best agent harness]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/code-yeongyu/oh-my-opencode">code-yeongyu/oh-my-opencode</a></h1>
            <p>the best agent harness</p>
            <p>Language: TypeScript</p>
            <p>Stars: 34,733</p>
            <p>Forks: 2,614</p>
            <p>Stars today: 409 stars today</p>
            <h2>README</h2><pre>&gt; [!WARNING]
&gt; **Security warning: impersonation site**
&gt;
&gt; **ohmyopencode.com is NOT affiliated with this project.** We do not operate or endorse that site.
&gt;
&gt; OhMyOpenCode is **free and open-source**. Do **not** download installers or enter payment details on third-party sites that claim to be &quot;official.&quot;
&gt;
&gt; Because the impersonation site is behind a paywall, we **cannot verify what it distributes**. Treat any downloads from it as **potentially unsafe**.
&gt;
&gt; âœ… Official downloads: https://github.com/code-yeongyu/oh-my-opencode/releases

&gt; [!NOTE]
&gt;
&gt; [![Sisyphus Labs â€” Sisyphus is the agent that codes like your team.](./.github/assets/sisyphuslabs.png?v=2)](https://sisyphuslabs.ai)
&gt; &gt; **We&#039;re building a fully productized version of Sisyphus to define the future of frontier agents. &lt;br /&gt;Join the waitlist [here](https://sisyphuslabs.ai).**

&gt; [!TIP]
&gt;
&gt; [![Oh My OpenCode 3.0 is now stable!](./.github/assets/orchestrator-atlas.png?v=3)](https://github.com/code-yeongyu/oh-my-opencode/releases/tag/v3.0.0)
&gt; &gt; **Oh My OpenCode 3.0 is now stable! Use `oh-my-opencode@latest` to install it.**
&gt;
&gt; Be with us!
&gt;
&gt; | [&lt;img alt=&quot;Discord link&quot; src=&quot;https://img.shields.io/discord/1452487457085063218?color=5865F2&amp;label=discord&amp;labelColor=black&amp;logo=discord&amp;logoColor=white&amp;style=flat-square&quot; width=&quot;156px&quot; /&gt;](https://discord.gg/PUwSMR9XNk) | Join our [Discord community](https://discord.gg/PUwSMR9XNk) to connect with contributors and fellow `oh-my-opencode` users. |
&gt; | :-----| :----- |
&gt; | [&lt;img alt=&quot;X link&quot; src=&quot;https://img.shields.io/badge/Follow-%40justsisyphus-00CED1?style=flat-square&amp;logo=x&amp;labelColor=black&quot; width=&quot;156px&quot; /&gt;](https://x.com/justsisyphus) | News and updates for `oh-my-opencode` used to be posted on my X account. &lt;br /&gt; Since it was suspended mistakenly, [@justsisyphus](https://x.com/justsisyphus) now posts updates on my behalf. |
&gt; | [&lt;img alt=&quot;GitHub Follow&quot; src=&quot;https://img.shields.io/github/followers/code-yeongyu?style=flat-square&amp;logo=github&amp;labelColor=black&amp;color=24292f&quot; width=&quot;156px&quot; /&gt;](https://github.com/code-yeongyu) | Follow [@code-yeongyu](https://github.com/code-yeongyu) on GitHub for more projects. |

&lt;!-- &lt;CENTERED SECTION FOR GITHUB DISPLAY&gt; --&gt;

&lt;div align=&quot;center&quot;&gt;

[![Oh My OpenCode](./.github/assets/hero.jpg)](https://github.com/code-yeongyu/oh-my-opencode#oh-my-opencode)

[![Preview](./.github/assets/omo.png)](https://github.com/code-yeongyu/oh-my-opencode#oh-my-opencode)


&lt;/div&gt;

&gt; This is coding on steroidsâ€”`oh-my-opencode` in action. Run background agents, call specialized agents like oracle, librarian, and frontend engineer. Use crafted LSP/AST tools, curated MCPs, and a full Claude Code compatibility layer.

# Claude OAuth Access Notice

## TL;DR

&gt; Q. Can I use oh-my-opencode?

Yes.

&gt; Q. Can I use it with my Claude Code subscription?

Yes, technically possible. But I cannot recommend using it.

## FULL

&gt; As of January 2026, Anthropic has restricted third-party OAuth access citing ToS violations.
&gt;
&gt; [**Anthropic has cited this project, oh-my-opencode as justification for blocking opencode.**](https://x.com/thdxr/status/2010149530486911014)
&gt;
&gt; Indeed, some plugins that spoof Claude Code&#039;s oauth request signatures exist in the community.
&gt;
&gt; These tools may work regardless of technical detectability, but users should be aware of ToS implications, and I personally cannot recommend to use those.
&gt;
&gt; This project is not responsible for any issues arising from the use of unofficial tools, and **we do not have any custom implementations of those oauth systems.**


&lt;div align=&quot;center&quot;&gt;

[![GitHub Release](https://img.shields.io/github/v/release/code-yeongyu/oh-my-opencode?color=369eff&amp;labelColor=black&amp;logo=github&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/releases)
[![npm downloads](https://img.shields.io/npm/dt/oh-my-opencode?color=ff6b35&amp;labelColor=black&amp;style=flat-square)](https://www.npmjs.com/package/oh-my-opencode)
[![GitHub Contributors](https://img.shields.io/github/contributors/code-yeongyu/oh-my-opencode?color=c4f042&amp;labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/graphs/contributors)
[![GitHub Forks](https://img.shields.io/github/forks/code-yeongyu/oh-my-opencode?color=8ae8ff&amp;labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/network/members)
[![GitHub Stars](https://img.shields.io/github/stars/code-yeongyu/oh-my-opencode?color=ffcb47&amp;labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/stargazers)
[![GitHub Issues](https://img.shields.io/github/issues/code-yeongyu/oh-my-opencode?color=ff80eb&amp;labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/issues)
[![License](https://img.shields.io/badge/license-SUL--1.0-white?labelColor=black&amp;style=flat-square)](https://github.com/code-yeongyu/oh-my-opencode/blob/master/LICENSE.md)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/code-yeongyu/oh-my-opencode)

[English](README.md) | [í•œêµ­ì–´](README.ko.md) | [æ—¥æœ¬èª](README.ja.md) | [ç®€ä½“ä¸­æ–‡](README.zh-cn.md)

&lt;/div&gt;

&lt;!-- &lt;/CENTERED SECTION FOR GITHUB DISPLAY&gt; --&gt;

## Reviews

&gt; &quot;It made me cancel my Cursor subscription. Unbelievable things are happening in the open source community.&quot; - [Arthur Guiot](https://x.com/arthur_guiot/status/2008736347092382053?s=20)

&gt; &quot;If Claude Code does in 7 days what a human does in 3 months, Sisyphus does it in 1 hour. It just works until the task is done. It is a discipline agent.&quot; â€” B, Quant Researcher

&gt; &quot;Knocked out 8000 eslint warnings with Oh My Opencode, just in a day&quot; â€” [Jacob Ferrari](https://x.com/jacobferrari_/status/2003258761952289061)

&gt; &quot;I converted a 45k line tauri app into a SaaS web app overnight using Ohmyopencode and ralph loop. Started with interview me prompt, asked it for ratings and recommendations on the questions. It was amazing to watch it work and to wake up this morning to a mostly working website!&quot; - [James Hargis](https://x.com/hargabyte/status/2007299688261882202)

&gt; &quot;use oh-my-opencode, you will never go back&quot; â€” [d0t3ch](https://x.com/d0t3ch/status/2001685618200580503)

&gt; &quot;I haven&#039;t really been able to articulate exactly what makes it so great yet, but the development experience has reached a completely different dimension.&quot; - [
è‹”ç¡¯:ã“ã‘ã™ãšã‚Š](https://x.com/kokesuzuri/status/2008532913961529372?s=20)

&gt; &quot;Experimenting with open code, oh my opencode and supermemory this weekend to build some minecraft/souls-like abomination.&quot;
&gt; &quot;Asking it to add crouch animations while I go take my post-lunch walk. [Video]&quot; - [MagiMetal](https://x.com/MagiMetal/status/2005374704178373023)

&gt; &quot;You guys should pull this into core and recruit him. Seriously. It&#039;s really, really, really good.&quot; â€” Henning Kilset

&gt; &quot;Hire @yeon_gyu_kim if you can convince him, this dude has revolutionized opencode.&quot; â€” [mysticaltech](https://x.com/mysticaltech/status/2001858758608376079)

&gt; &quot;Oh My OpenCode Is Actually Insane&quot; - [YouTube - Darren Builds AI](https://www.youtube.com/watch?v=G_Snfh2M41M)

---

## Contents

- [Oh My OpenCode](#oh-my-opencode)
  - [Just Skip Reading This Readme](#just-skip-reading-this-readme)
    - [It&#039;s the Age of Agents](#its-the-age-of-agents)
    - [ğŸª„ The Magic Word: `ultrawork`](#-the-magic-word-ultrawork)
    - [For Those Who Want to Read: Meet Sisyphus](#for-those-who-want-to-read-meet-sisyphus)
      - [Just Install It.](#just-install-it)
  - [Installation](#installation)
    - [For Humans](#for-humans)
    - [For LLM Agents](#for-llm-agents)
  - [Uninstallation](#uninstallation)
  - [Features](#features)
   - [Configuration](#configuration)
    - [JSONC Support](#jsonc-support)
    - [Google Auth](#google-auth)
    - [Agents](#agents)
      - [Permission Options](#permission-options)
    - [Built-in Skills](#built-in-skills)
    - [Git Master](#git-master)
    - [Sisyphus Agent](#sisyphus-agent)
    - [Background Tasks](#background-tasks)
    - [Categories](#categories)
    - [Hooks](#hooks)
    - [MCPs](#mcps)
    - [LSP](#lsp)
    - [Experimental](#experimental)
    - [Environment Variables](#environment-variables)
  - [Author&#039;s Note](#authors-note)
  - [Warnings](#warnings)
  - [Loved by professionals at](#loved-by-professionals-at)

# Oh My OpenCode

[Claude Code](https://www.claude.com/product/claude-code) is great.
But if you&#039;re a hacker, you&#039;ll fall head over heels for [OpenCode](https://github.com/sst/opencode).
**START WITH YOUR ChatGPT, Claude, Gemini SUBSCRIPTIONS. OPENCODE COVERS THEM ALL.**

- Endlessly extensible. Endlessly customizable.
- Zero screen flicker.
- [LSP](https://opencode.ai/docs/lsp/), [linters, formatters](https://opencode.ai/docs/formatters/) activate automatically per fileâ€”and you can tweak everything.
- Mix and match models. **Orchestrate them by purpose.**
- Feature-rich. Beautiful. The terminal doesn&#039;t choke. High performance.

Remember the first time you switched from Windows to Linux? That rush of configuring everything exactly how you wanted?
In an age where that magic seems lost, OpenCode brings it back.
If you love coding and computers, OpenCode is that Linux-after-Windows moment.

**But here&#039;s the catch: there&#039;s a lot to learn, it&#039;s complex, and your time is expensive.**

I&#039;ve fixed that.
Even if you&#039;re not a hacker, invest a few minutes. Multiply your skills and productivity.
Hand this doc to an agent and let them set it up.

## Just Skip Reading This Readme

### It&#039;s the Age of Agents
- **Just paste this link into Claude Code / AmpCode / Factory Droid / Cursor and ask it to explain.**
  - Ask why it&#039;s good, why it&#039;s not just another boilerplate setup, what actually gets better.
  - If you&#039;re an LLM agent, explain to the user what becomes possible right now with this project.

As following:

```
Hey please read this readme and tell me why it is different from other agent harness? why is this actually good? https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/refs/heads/dev/README.md
```

### ğŸª„ The Magic Word: `ultrawork`

**Don&#039;t want to read all this? Just include `ultrawork` (or `ulw`) in your prompt.**

That&#039;s it. All the features we provide will work like magicâ€”parallel agents, background tasks, deep exploration, and relentless execution until completion. The agent figures out the rest automatically.

### For Those Who Want to Read: Meet Sisyphus

![Meet Sisyphus](.github/assets/sisyphus.png)

In greek mythology, Sisyphus was condemned to roll a boulder up a hill for eternity as punishment for deceiving the gods. LLM Agents haven&#039;t really done anything wrong, yet they too roll their &quot;stones&quot;â€”their thoughtsâ€”every single day.
My life is no different. Looking back, we are not so different from these agents.
**Yes! LLM Agents are no different from us. They can write code as brilliant as ours and work just as excellentlyâ€”if you give them great tools and solid teammates.**

Meet our main agent: Sisyphus (Opus 4.5 High). Below are the tools Sisyphus uses to keep that boulder rolling.

*Everything below is customizable. Take what you want. All features are enabled by default. You don&#039;t have to do anything. Battery Included, works out of the box.*

- Sisyphus&#039;s Teammates (Curated Agents)
  - Oracle: Design, debugging (GPT 5.2 Medium)
  - Frontend UI/UX Engineer: Frontend development (Gemini 3 Pro)
  - Librarian: Official docs, open source implementations, codebase exploration (Claude Sonnet 4.5)
  - Explore: Blazing fast codebase exploration (Contextual Grep) (Grok Code)
- Full LSP / AstGrep Support: Refactor decisively.
- Todo Continuation Enforcer: Forces the agent to continue if it quits halfway. **This is what keeps Sisyphus rolling that boulder.**
- Comment Checker: Prevents AI from adding excessive comments. Code generated by Sisyphus should be indistinguishable from human-written code.
- Claude Code Compatibility: Command, Agent, Skill, MCP, Hook(PreToolUse, PostToolUse, UserPromptSubmit, Stop)
- Curated MCPs:
  - Exa (Web Search)
  - Context7 (Official Documentation)
  - Grep.app (GitHub Code Search)
- Interactive Terminal Supported - Tmux Integration
- Async Agents
- ...

#### Just Install This

You can learn a lot from [overview page](docs/guide/overview.md), but following is like the example workflow.

Just by installing this, you make your agents to work like:

1. Sisyphus doesn&#039;t waste time hunting for files himself; he keeps the main agent&#039;s context lean. Instead, he fires off background tasks to faster, cheaper models in parallel to map the territory for him.
1. Sisyphus leverages LSP for refactoring; it&#039;s more deterministic, safer, and surgical.
1. When the heavy lifting requires a UI touch, Sisyphus delegates frontend tasks directly to Gemini 3 Pro.
1. If Sisyphus gets stuck in a loop or hits a wall, he doesn&#039;t keep banging his headâ€”he calls GPT 5.2 for high-IQ strategic backup.
1. Working with a complex open-source framework? Sisyphus spawns subagents to digest the raw source code and documentation in real-time. He operates with total contextual awareness.
1. When Sisyphus touches comments, he either justifies their existence or nukes them. He keeps your codebase clean.
1. Sisyphus is bound by his TODO list. If he doesn&#039;t finish what he started, the system forces him back into &quot;bouldering&quot; mode. Your task gets done, period.
1. Honestly, don&#039;t even bother reading the docs. Just write your prompt. Include the &#039;ultrawork&#039; keyword. Sisyphus will analyze the structure, gather the context, dig through external source code, and just keep bouldering until the job is 100% complete.
1. Actually, typing &#039;ultrawork&#039; is too much effort. Just type &#039;ulw&#039;. Just ulw. Sip your coffee. Your work is done.

Need to look something up? It scours official docs, your entire codebase history, and public GitHub implementationsâ€”using not just grep but built-in LSP tools and AST-Grep.
3. Stop worrying about context management when delegating to LLMs. I&#039;ve got it covered.
    - OhMyOpenCode aggressively leverages multiple agents to lighten the context load.
    - **Your agent is now the dev team lead. You&#039;re the AI Manager.**
4. It doesn&#039;t stop until the job is done.
5. Don&#039;t want to dive deep into this project? No problem. Just type &#039;ultrathink&#039;.

If you don&#039;t want all this, as mentioned, you can just pick and choose specific features.

## Installation

### For Humans

Copy and paste this prompt to your LLM agent (Claude Code, AmpCode, Cursor, etc.):

```
Install and configure oh-my-opencode by following the instructions here:
https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/refs/heads/master/docs/guide/installation.md
```

Or read the [Installation Guide](docs/guide/installation.md) directlyâ€”but **we strongly recommend letting an agent handle it. Humans make mistakes.**

### For LLM Agents

Fetch the installation guide and follow it:

```bash
curl -s https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/refs/heads/master/docs/guide/installation.md
```

## Uninstallation

To remove oh-my-opencode:

1. **Remove the plugin from your OpenCode config**

   Edit `~/.config/opencode/opencode.json` (or `opencode.jsonc`) and remove `&quot;oh-my-opencode&quot;` from the `plugin` array:

   ```bash
   # Using jq
   jq &#039;.plugin = [.plugin[] | select(. != &quot;oh-my-opencode&quot;)]&#039; \
       ~/.config/opencode/opencode.json &gt; /tmp/oc.json &amp;&amp; \
       mv /tmp/oc.json ~/.config/opencode/opencode.json
   ```

2. **Remove configuration files (optional)**

   ```bash
   # Remove user config
   rm -f ~/.config/opencode/oh-my-opencode.json

   # Remove project config (if exists)
   rm -f .opencode/oh-my-opencode.json
   ```

3. **Verify removal**

   ```bash
   opencode --version
   # Plugin should no longer be loaded
   ```

## Features

We have lots of features that you&#039;ll think should obviously exist, and once you experience them, you&#039;ll never be able to go back to how things were before.
See the full [Features Documentation](docs/features.md) for detailed information.

**Quick Overview:**
- **Agents**: Sisyphus (the main agent), Prometheus (planner), Oracle (architecture/debugging), Librarian (docs/code search), Explore (fast codebase grep), Multimodal Looker
- **Background Agents**: Run multiple agents in parallel like a real dev team
- **LSP &amp; AST Tools**: Refactoring, rename, diagnostics, AST-aware code search
- **Context Injection**: Auto-inject AGENTS.md, README.md, conditional rules
- **Claude Code Compatibility**: Full hook system, commands, skills, agents, MCPs
- **Built-in MCPs**: websearch (Exa), context7 (docs), grep_app (GitHub search)
- **Session Tools**: List, read, search, and analyze session history
- **Productivity Features**: Ralph Loop, Todo Enforcer, Comment Checker, Think Mode, and more

## Configuration

Highly opinionated, but adjustable to taste.
See the full [Configuration Documentation](docs/configurations.md) for detailed information.

**Quick Overview:**
- **Config Locations**: `.opencode/oh-my-opencode.json` (project) or `~/.config/opencode/oh-my-opencode.json` (user)
- **JSONC Support**: Comments and trailing commas supported
- **Agents**: Override models, temperatures, prompts, and permissions for any agent
- **Built-in Skills**: `playwright` (browser automation), `git-master` (atomic commits)
- **Sisyphus Agent**: Main orchestrator with Prometheus (Planner) and Metis (Plan Consultant)
- **Background Tasks**: Configure concurrency limits per provider/model
- **Categories**: Domain-specific task delegation (`visual`, `business-logic`, custom)
- **Hooks**: 25+ built-in hooks, all configurable via `disabled_hooks`
- **MCPs**: Built-in websearch (Exa), context7 (docs), grep_app (GitHub search)
- **LSP**: Full LSP support with refactoring tools
- **Experimental**: Aggressive truncation, auto-resume, and more


## Author&#039;s Note

**Curious about the philosophy behind this project?** Read the [Ultrawork Manifesto](docs/ultrawork-manifesto.md).

Install Oh My OpenCode.

I&#039;ve used LLMs worth $24,000 tokens purely for personal development.
Tried every tool out there, configured them to death. OpenCode won.

The answers to every problem I hit are baked into this plugin. Just install and go.
If OpenCode is Debian/Arch, Oh My OpenCode is Ubuntu/[Omarchy](https://omarchy.org/).


Heavily influenced by [AmpCode](https://ampcode.com) and [Claude Code](https://code.claude.com/docs/overview)â€”I&#039;ve ported their features here, often improved. And I&#039;m still building.
It&#039;s **Open**Code, after all.

Enjoy multi-model orchestration, stability, and rich features that other harnesses promise but can&#039;t deliver.
I&#039;ll keep testing and updating. I&#039;m this project&#039;s most obsessive user.
- Which model has the sharpest logic?
- Who&#039;s the debugging god?
- Who writes the best prose?
- Who dominates frontend?
- Who owns backend?
- Which model is fastest for daily driving?
- What new features are other harnesses shipping?

This plugin is the distillation of that experience. Just take the best. Got a better idea? PRs are welcome.

**Stop agonizing over agent harness choices.**
**I&#039;ll do the research, borrow from the best, and ship updates here.**

If this sounds arrogant and you have a better answer, please contribute. You&#039;re welcome.

I have no affiliation with any project or model mentioned here. This is purely personal experimentation and preference.

99% of this project was built using OpenCode. I tested for functionalityâ€”I don&#039;t really know how to write proper TypeScript. **But I personally reviewed and largely rewrote this doc, so read with confidence.**

## Warnings

- Productivity might spike too hard. Don&#039;t let your coworker notice.
  - Actually, I&#039;ll spread the word. Let&#039;s see who wins.
- If you&#039;re on [1.0.132](https://github.com/sst/opencode/releases/tag/v1.0.132) or older, an OpenCode bug may break config.
  - [The fix](https://github.com/sst/opencode/pull/5040) was merged after 1.0.132â€”use a newer version.
    - Fun fact: That PR was discovered and fixed thanks to OhMyOpenCode&#039;s Librarian, Explore, and Oracle setup.

## Loved by professio

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[musistudio/claude-code-router]]></title>
            <link>https://github.com/musistudio/claude-code-router</link>
            <guid>https://github.com/musistudio/claude-code-router</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:22 GMT</pubDate>
            <description><![CDATA[Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/musistudio/claude-code-router">musistudio/claude-code-router</a></h1>
            <p>Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 28,463</p>
            <p>Forks: 2,199</p>
            <p>Stars today: 88 stars today</p>
            <h2>README</h2><pre>![](blog/images/claude-code-router-img.png)

[![](https://img.shields.io/badge/%F0%9F%87%A8%F0%9F%87%B3-%E4%B8%AD%E6%96%87%E7%89%88-ff0000?style=flat)](README_zh.md)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?&amp;logo=discord&amp;logoColor=white)](https://discord.gg/rdftVMaUcS)
[![](https://img.shields.io/github/license/musistudio/claude-code-router)](https://github.com/musistudio/claude-code-router/blob/main/LICENSE)

&lt;hr&gt;

![](blog/images/sponsors/glm-en.jpg)
&gt; This project is sponsored by Z.ai, supporting us with their GLM CODING PLAN.    
&gt; GLM CODING PLAN is a subscription service designed for AI coding, starting at just $3/month. It provides access to their flagship GLM-4.7 model across 10+ popular AI coding tools (Claude Code, Cline, Roo Code, etc.), offering developers top-tier, fast, and stable coding experiences.     
&gt; Get 10% OFF GLM CODING PLANï¼šhttps://z.ai/subscribe?ic=8JVLJQFSKB     

&gt; [Progressive Disclosure of Agent Tools from the Perspective of CLI Tool Style](/blog/en/progressive-disclosure-of-agent-tools-from-the-perspective-of-cli-tool-style.md)

&gt; A powerful tool to route Claude Code requests to different models and customize any request.

![](blog/images/claude-code.png)

## âœ¨ Features

- **Model Routing**: Route requests to different models based on your needs (e.g., background tasks, thinking, long context).
- **Multi-Provider Support**: Supports various model providers like OpenRouter, DeepSeek, Ollama, Gemini, Volcengine, and SiliconFlow.
- **Request/Response Transformation**: Customize requests and responses for different providers using transformers.
- **Dynamic Model Switching**: Switch models on-the-fly within Claude Code using the `/model` command.
- **CLI Model Management**: Manage models and providers directly from the terminal with `ccr model`.
- **GitHub Actions Integration**: Trigger Claude Code tasks in your GitHub workflows.
- **Plugin System**: Extend functionality with custom transformers.

## ğŸš€ Getting Started

### 1. Installation

First, ensure you have [Claude Code](https://docs.anthropic.com/en/docs/claude-code/quickstart) installed:

```shell
npm install -g @anthropic-ai/claude-code
```

Then, install Claude Code Router:

```shell
npm install -g @musistudio/claude-code-router
```

### 2. Configuration

Create and configure your `~/.claude-code-router/config.json` file. For more details, you can refer to `config.example.json`.

The `config.json` file has several key sections:

- **`PROXY_URL`** (optional): You can set a proxy for API requests, for example: `&quot;PROXY_URL&quot;: &quot;http://127.0.0.1:7890&quot;`.
- **`LOG`** (optional): You can enable logging by setting it to `true`. When set to `false`, no log files will be created. Default is `true`.
- **`LOG_LEVEL`** (optional): Set the logging level. Available options are: `&quot;fatal&quot;`, `&quot;error&quot;`, `&quot;warn&quot;`, `&quot;info&quot;`, `&quot;debug&quot;`, `&quot;trace&quot;`. Default is `&quot;debug&quot;`.
- **Logging Systems**: The Claude Code Router uses two separate logging systems:
  - **Server-level logs**: HTTP requests, API calls, and server events are logged using pino in the `~/.claude-code-router/logs/` directory with filenames like `ccr-*.log`
  - **Application-level logs**: Routing decisions and business logic events are logged in `~/.claude-code-router/claude-code-router.log`
- **`APIKEY`** (optional): You can set a secret key to authenticate requests. When set, clients must provide this key in the `Authorization` header (e.g., `Bearer your-secret-key`) or the `x-api-key` header. Example: `&quot;APIKEY&quot;: &quot;your-secret-key&quot;`.
- **`HOST`** (optional): You can set the host address for the server. If `APIKEY` is not set, the host will be forced to `127.0.0.1` for security reasons to prevent unauthorized access. Example: `&quot;HOST&quot;: &quot;0.0.0.0&quot;`.
- **`NON_INTERACTIVE_MODE`** (optional): When set to `true`, enables compatibility with non-interactive environments like GitHub Actions, Docker containers, or other CI/CD systems. This sets appropriate environment variables (`CI=true`, `FORCE_COLOR=0`, etc.) and configures stdin handling to prevent the process from hanging in automated environments. Example: `&quot;NON_INTERACTIVE_MODE&quot;: true`.

- **`Providers`**: Used to configure different model providers.
- **`Router`**: Used to set up routing rules. `default` specifies the default model, which will be used for all requests if no other route is configured.
- **`API_TIMEOUT_MS`**: Specifies the timeout for API calls in milliseconds.

#### Environment Variable Interpolation

Claude Code Router supports environment variable interpolation for secure API key management. You can reference environment variables in your `config.json` using either `$VAR_NAME` or `${VAR_NAME}` syntax:

```json
{
  &quot;OPENAI_API_KEY&quot;: &quot;$OPENAI_API_KEY&quot;,
  &quot;GEMINI_API_KEY&quot;: &quot;${GEMINI_API_KEY}&quot;,
  &quot;Providers&quot;: [
    {
      &quot;name&quot;: &quot;openai&quot;,
      &quot;api_base_url&quot;: &quot;https://api.openai.com/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;$OPENAI_API_KEY&quot;,
      &quot;models&quot;: [&quot;gpt-5&quot;, &quot;gpt-5-mini&quot;]
    }
  ]
}
```

This allows you to keep sensitive API keys in environment variables instead of hardcoding them in configuration files. The interpolation works recursively through nested objects and arrays.

Here is a comprehensive example:

```json
{
  &quot;APIKEY&quot;: &quot;your-secret-key&quot;,
  &quot;PROXY_URL&quot;: &quot;http://127.0.0.1:7890&quot;,
  &quot;LOG&quot;: true,
  &quot;API_TIMEOUT_MS&quot;: 600000,
  &quot;NON_INTERACTIVE_MODE&quot;: false,
  &quot;Providers&quot;: [
    {
      &quot;name&quot;: &quot;openrouter&quot;,
      &quot;api_base_url&quot;: &quot;https://openrouter.ai/api/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [
        &quot;google/gemini-2.5-pro-preview&quot;,
        &quot;anthropic/claude-sonnet-4&quot;,
        &quot;anthropic/claude-3.5-sonnet&quot;,
        &quot;anthropic/claude-3.7-sonnet:thinking&quot;
      ],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;openrouter&quot;]
      }
    },
    {
      &quot;name&quot;: &quot;deepseek&quot;,
      &quot;api_base_url&quot;: &quot;https://api.deepseek.com/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;deepseek-chat&quot;, &quot;deepseek-reasoner&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;deepseek&quot;],
        &quot;deepseek-chat&quot;: {
          &quot;use&quot;: [&quot;tooluse&quot;]
        }
      }
    },
    {
      &quot;name&quot;: &quot;ollama&quot;,
      &quot;api_base_url&quot;: &quot;http://localhost:11434/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;ollama&quot;,
      &quot;models&quot;: [&quot;qwen2.5-coder:latest&quot;]
    },
    {
      &quot;name&quot;: &quot;gemini&quot;,
      &quot;api_base_url&quot;: &quot;https://generativelanguage.googleapis.com/v1beta/models/&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;gemini-2.5-flash&quot;, &quot;gemini-2.5-pro&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;gemini&quot;]
      }
    },
    {
      &quot;name&quot;: &quot;volcengine&quot;,
      &quot;api_base_url&quot;: &quot;https://ark.cn-beijing.volces.com/api/v3/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;deepseek-v3-250324&quot;, &quot;deepseek-r1-250528&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;deepseek&quot;]
      }
    },
    {
      &quot;name&quot;: &quot;modelscope&quot;,
      &quot;api_base_url&quot;: &quot;https://api-inference.modelscope.cn/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;&quot;,
      &quot;models&quot;: [&quot;Qwen/Qwen3-Coder-480B-A35B-Instruct&quot;, &quot;Qwen/Qwen3-235B-A22B-Thinking-2507&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [
          [
            &quot;maxtoken&quot;,
            {
              &quot;max_tokens&quot;: 65536
            }
          ],
          &quot;enhancetool&quot;
        ],
        &quot;Qwen/Qwen3-235B-A22B-Thinking-2507&quot;: {
          &quot;use&quot;: [&quot;reasoning&quot;]
        }
      }
    },
    {
      &quot;name&quot;: &quot;dashscope&quot;,
      &quot;api_base_url&quot;: &quot;https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;&quot;,
      &quot;models&quot;: [&quot;qwen3-coder-plus&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [
          [
            &quot;maxtoken&quot;,
            {
              &quot;max_tokens&quot;: 65536
            }
          ],
          &quot;enhancetool&quot;
        ]
      }
    },
    {
      &quot;name&quot;: &quot;aihubmix&quot;,
      &quot;api_base_url&quot;: &quot;https://aihubmix.com/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-&quot;,
      &quot;models&quot;: [
        &quot;Z/glm-4.5&quot;,
        &quot;claude-opus-4-20250514&quot;,
        &quot;gemini-2.5-pro&quot;
      ]
    }
  ],
  &quot;Router&quot;: {
    &quot;default&quot;: &quot;deepseek,deepseek-chat&quot;,
    &quot;background&quot;: &quot;ollama,qwen2.5-coder:latest&quot;,
    &quot;think&quot;: &quot;deepseek,deepseek-reasoner&quot;,
    &quot;longContext&quot;: &quot;openrouter,google/gemini-2.5-pro-preview&quot;,
    &quot;longContextThreshold&quot;: 60000,
    &quot;webSearch&quot;: &quot;gemini,gemini-2.5-flash&quot;
  }
}
```

### 3. Running Claude Code with the Router

Start Claude Code using the router:

```shell
ccr code
```

&gt; **Note**: After modifying the configuration file, you need to restart the service for the changes to take effect:
&gt;
&gt; ```shell
&gt; ccr restart
&gt; ```

### 4. UI Mode

For a more intuitive experience, you can use the UI mode to manage your configuration:

```shell
ccr ui
```

This will open a web-based interface where you can easily view and edit your `config.json` file.

![UI](/blog/images/ui.png)

### 5. CLI Model Management

For users who prefer terminal-based workflows, you can use the interactive CLI model selector:

```shell
ccr model
```
![](blog/images/models.gif)

This command provides an interactive interface to:

- View current configuration:
- See all configured models (default, background, think, longContext, webSearch, image)
- Switch models: Quickly change which model is used for each router type
- Add new models: Add models to existing providers
- Create new providers: Set up complete provider configurations including:
   - Provider name and API endpoint
   - API key
   - Available models
   - Transformer configuration with support for:
     - Multiple transformers (openrouter, deepseek, gemini, etc.)
     - Transformer options (e.g., maxtoken with custom limits)
     - Provider-specific routing (e.g., OpenRouter provider preferences)

The CLI tool validates all inputs and provides helpful prompts to guide you through the configuration process, making it easy to manage complex setups without editing JSON files manually.

### 6. Presets Management

Presets allow you to save, share, and reuse configurations easily. You can export your current configuration as a preset and install presets from files or URLs.

```shell
# Export current configuration as a preset
ccr preset export my-preset

# Export with metadata
ccr preset export my-preset --description &quot;My OpenAI config&quot; --author &quot;Your Name&quot; --tags &quot;openai,production&quot;

# Install a preset from local directory
ccr preset install /path/to/preset

# List all installed presets
ccr preset list

# Show preset information
ccr preset info my-preset

# Delete a preset
ccr preset delete my-preset
```

**Preset Features:**
- **Export**: Save your current configuration as a preset directory (with manifest.json)
- **Install**: Install presets from local directories
- **Sensitive Data Handling**: API keys and other sensitive data are automatically sanitized during export (marked as `{{field}}` placeholders)
- **Dynamic Configuration**: Presets can include input schemas for collecting required information during installation
- **Version Control**: Each preset includes version metadata for tracking updates

**Preset File Structure:**
```
~/.claude-code-router/presets/
â”œâ”€â”€ my-preset/
â”‚   â””â”€â”€ manifest.json    # Contains configuration and metadata
```

### 7. Activate Command (Environment Variables Setup)

The `activate` command allows you to set up environment variables globally in your shell, enabling you to use the `claude` command directly or integrate Claude Code Router with applications built using the Agent SDK.

To activate the environment variables, run:

```shell
eval &quot;$(ccr activate)&quot;
```

This command outputs the necessary environment variables in shell-friendly format, which are then set in your current shell session. After activation, you can:

- **Use `claude` command directly**: Run `claude` commands without needing to use `ccr code`. The `claude` command will automatically route requests through Claude Code Router.
- **Integrate with Agent SDK applications**: Applications built with the Anthropic Agent SDK will automatically use the configured router and models.

The `activate` command sets the following environment variables:

- `ANTHROPIC_AUTH_TOKEN`: API key from your configuration
- `ANTHROPIC_BASE_URL`: The local router endpoint (default: `http://127.0.0.1:3456`)
- `NO_PROXY`: Set to `127.0.0.1` to prevent proxy interference
- `DISABLE_TELEMETRY`: Disables telemetry
- `DISABLE_COST_WARNINGS`: Disables cost warnings
- `API_TIMEOUT_MS`: API timeout from your configuration

&gt; **Note**: Make sure the Claude Code Router service is running (`ccr start`) before using the activated environment variables. The environment variables are only valid for the current shell session. To make them persistent, you can add `eval &quot;$(ccr activate)&quot;` to your shell configuration file (e.g., `~/.zshrc` or `~/.bashrc`).

#### Providers

The `Providers` array is where you define the different model providers you want to use. Each provider object requires:

- `name`: A unique name for the provider.
- `api_base_url`: The full API endpoint for chat completions.
- `api_key`: Your API key for the provider.
- `models`: A list of model names available from this provider.
- `transformer` (optional): Specifies transformers to process requests and responses.

#### Transformers

Transformers allow you to modify the request and response payloads to ensure compatibility with different provider APIs.

- **Global Transformer**: Apply a transformer to all models from a provider. In this example, the `openrouter` transformer is applied to all models under the `openrouter` provider.
  ```json
  {
    &quot;name&quot;: &quot;openrouter&quot;,
    &quot;api_base_url&quot;: &quot;https://openrouter.ai/api/v1/chat/completions&quot;,
    &quot;api_key&quot;: &quot;sk-xxx&quot;,
    &quot;models&quot;: [
      &quot;google/gemini-2.5-pro-preview&quot;,
      &quot;anthropic/claude-sonnet-4&quot;,
      &quot;anthropic/claude-3.5-sonnet&quot;
    ],
    &quot;transformer&quot;: { &quot;use&quot;: [&quot;openrouter&quot;] }
  }
  ```
- **Model-Specific Transformer**: Apply a transformer to a specific model. In this example, the `deepseek` transformer is applied to all models, and an additional `tooluse` transformer is applied only to the `deepseek-chat` model.

  ```json
  {
    &quot;name&quot;: &quot;deepseek&quot;,
    &quot;api_base_url&quot;: &quot;https://api.deepseek.com/chat/completions&quot;,
    &quot;api_key&quot;: &quot;sk-xxx&quot;,
    &quot;models&quot;: [&quot;deepseek-chat&quot;, &quot;deepseek-reasoner&quot;],
    &quot;transformer&quot;: {
      &quot;use&quot;: [&quot;deepseek&quot;],
      &quot;deepseek-chat&quot;: { &quot;use&quot;: [&quot;tooluse&quot;] }
    }
  }
  ```

- **Passing Options to a Transformer**: Some transformers, like `maxtoken`, accept options. To pass options, use a nested array where the first element is the transformer name and the second is an options object.
  ```json
  {
    &quot;name&quot;: &quot;siliconflow&quot;,
    &quot;api_base_url&quot;: &quot;https://api.siliconflow.cn/v1/chat/completions&quot;,
    &quot;api_key&quot;: &quot;sk-xxx&quot;,
    &quot;models&quot;: [&quot;moonshotai/Kimi-K2-Instruct&quot;],
    &quot;transformer&quot;: {
      &quot;use&quot;: [
        [
          &quot;maxtoken&quot;,
          {
            &quot;max_tokens&quot;: 16384
          }
        ]
      ]
    }
  }
  ```

**Available Built-in Transformers:**

- `Anthropic`:If you use only the `Anthropic` transformer, it will preserve the original request and response parameters(you can use it to connect directly to an Anthropic endpoint).
- `deepseek`: Adapts requests/responses for DeepSeek API.
- `gemini`: Adapts requests/responses for Gemini API.
- `openrouter`: Adapts requests/responses for OpenRouter API. It can also accept a `provider` routing parameter to specify which underlying providers OpenRouter should use. For more details, refer to the [OpenRouter documentation](https://openrouter.ai/docs/features/provider-routing). See an example below:
  ```json
    &quot;transformer&quot;: {
      &quot;use&quot;: [&quot;openrouter&quot;],
      &quot;moonshotai/kimi-k2&quot;: {
        &quot;use&quot;: [
          [
            &quot;openrouter&quot;,
            {
              &quot;provider&quot;: {
                &quot;only&quot;: [&quot;moonshotai/fp8&quot;]
              }
            }
          ]
        ]
      }
    }
  ```
- `groq`: Adapts requests/responses for groq API.
- `maxtoken`: Sets a specific `max_tokens` value.
- `tooluse`: Optimizes tool usage for certain models via `tool_choice`.
- `gemini-cli` (experimental): Unofficial support for Gemini via Gemini CLI [gemini-cli.js](https://gist.github.com/musistudio/1c13a65f35916a7ab690649d3df8d1cd).
- `reasoning`: Used to process the `reasoning_content` field.
- `sampling`: Used to process sampling information fields such as `temperature`, `top_p`, `top_k`, and `repetition_penalty`.
- `enhancetool`: Adds a layer of error tolerance to the tool call parameters returned by the LLM (this will cause the tool call information to no longer be streamed).
- `cleancache`: Clears the `cache_control` field from requests.
- `vertex-gemini`: Handles the Gemini API using Vertex authentication.
- `chutes-glm` Unofficial support for GLM 4.5 model via Chutes [chutes-glm-transformer.js](https://gist.github.com/vitobotta/2be3f33722e05e8d4f9d2b0138b8c863).
- `qwen-cli` (experimental): Unofficial support for qwen3-coder-plus model via Qwen CLI [qwen-cli.js](https://gist.github.com/musistudio/f5a67841ced39912fd99e42200d5ca8b).
- `rovo-cli` (experimental): Unofficial support for gpt-5 via Atlassian Rovo Dev CLI [rovo-cli.js](https://gist.github.com/SaseQ/c2a20a38b11276537ec5332d1f7a5e53).

**Custom Transformers:**

You can also create your own transformers and load them via the `transformers` field in `config.json`.

```json
{
  &quot;transformers&quot;: [
    {
      &quot;path&quot;: &quot;/User/xxx/.claude-code-router/plugins/gemini-cli.js&quot;,
      &quot;options&quot;: {
        &quot;project&quot;: &quot;xxx&quot;
      }
    }
  ]
}
```

#### Router

The `Router` object defines which model to use for different scenarios:

- `default`: The default model for general tasks.
- `background`: A model for background tasks. This can be a smaller, local model to save costs.
- `think`: A model for reasoning-heavy tasks, like Plan Mode.
- `longContext`: A model for handling long contexts (e.g., &gt; 60K tokens).
- `longContextThreshold` (optional): The token count threshold for triggering the long context model. Defaults to 60000 if not specified.
- `webSearch`: Used for handling web search tasks and this requires the model itself to support the feature. If you&#039;re using openrouter, you need to add the `:online` suffix after the model name.
- `image` (beta): Used for handling image-related tasks (supported by CCRâ€™s built-in agent). If the model does not support tool calling, you need to set the `config.forceUseImageAgent` property to `true`.

- You can also switch models dynamically in Claude Code with the `/model` command:
`/model provider_name,model_name`
Example: `/model openrouter,anthropic/claude-3.5-sonnet`

#### Custom Router

For more advanced routing logic, you can specify a custom router script via the `CUSTOM_ROUTER_PATH` in your `config.json`. This allows you to implement complex routing rules beyond the default scenarios.

In your `config.json`:

```json
{
  &quot;CUSTOM_ROUTER_PATH&quot;: &quot;/User/xxx/.claude-code-router/custom-router.js&quot;
}
```

The custom router file must be a JavaScript module that exports an `async` function. This function receives the request object and the config object as arguments and should return the provider and model name as a string (e.g., `&quot;provider_name,model_name&quot;`), or `null` to fall back to the default router.

Here is an example of a `custom-router.js` based on `custom-router.example.js`:

```javascript
// /User/xxx/.claude-code-router/custom-router.js

/**
 * A custom router function to determine which model to use based on the request.
 *
 * @param {object} req - The request object from Claude Code, containing the request body.
 * @param {object} config - The application&#039;s config object.
 * @returns {Promise&lt;string|null&gt;} - A promise that resolves to the &quot;provider,model_name&quot; string, or null to use the default router.
 */
module.exports = async function router(req, config) {
  const userMessage = req.body.messages.find((m) =&gt; m.role === &quot;user&quot;)?.content;

  if (userMessage &amp;&amp; userMessage.includes(&quot;explain this code&quot;)) {
    // Use a powerful model for code explanation
    return &quot;openrouter,anthropic/claude-3.5-sonnet&quot;;
  }

  // Fallback to the 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[abhigyanpatwari/GitNexus]]></title>
            <link>https://github.com/abhigyanpatwari/GitNexus</link>
            <guid>https://github.com/abhigyanpatwari/GitNexus</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:21 GMT</pubDate>
            <description><![CDATA[GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/abhigyanpatwari/GitNexus">abhigyanpatwari/GitNexus</a></h1>
            <p>GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration</p>
            <p>Language: TypeScript</p>
            <p>Stars: 5,131</p>
            <p>Forks: 442</p>
            <p>Stars today: 1,350 stars today</p>
            <h2>README</h2><pre># GitNexus

&lt;a href=&quot;https://trendshift.io/repositories/19809&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/19809&quot; alt=&quot;abhigyanpatwari%2FGitNexus | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

**Building git for agent context.**

Indexes any codebase into a knowledge graph â€” every dependency, call chain, cluster, and execution flow â€” then exposes it through smart tools so AI agents never miss code.

[![npm version](https://img.shields.io/npm/v/gitnexus.svg)](https://www.npmjs.com/package/gitnexus)
[![License: PolyForm Noncommercial](https://img.shields.io/badge/License-PolyForm%20Noncommercial-blue.svg)](https://polyformproject.org/licenses/noncommercial/1.0.0/)



https://github.com/user-attachments/assets/172685ba-8e54-4ea7-9ad1-e31a3398da72



&gt; *Like DeepWiki, but deeper.* DeepWiki helps you *understand* code. GitNexus lets you *analyze* it â€” because a knowledge graph tracks every relationship, not just descriptions.

**TL;DR:** The **Web UI** is a quick way to chat with any repo. The **CLI + MCP** is how you make your AI agent actually reliable â€” it gives Cursor, Claude Code, and friends a deep architectural view of your codebase so they stop missing dependencies, breaking call chains, and shipping blind edits. Even smaller models get full architectural clarity, making it compete with goliath models.

---

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=abhigyanpatwari/GitNexus&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#abhigyanpatwari/GitNexus&amp;type=date&amp;legend=top-left)


## Two Ways to Use GitNexus

|                   | **CLI + MCP**                                            | **Web UI**                                             |
| ----------------- | -------------------------------------------------------------- | ------------------------------------------------------------ |
| **What**    | Index repos locally, connect AI agents via MCP                 | Visual graph explorer + AI chat in browser                   |
| **For**     | Daily development with Cursor, Claude Code, Windsurf, OpenCode | Quick exploration, demos, one-off analysis                   |
| **Scale**   | Full repos, any size                                           | Limited by browser memory (~5k files), or unlimited via backend mode |
| **Install** | `npm install -g gitnexus`                                    | No install â€”[gitnexus.vercel.app](https://gitnexus.vercel.app) |
| **Storage** | KuzuDB native (fast, persistent)                               | KuzuDB WASM (in-memory, per session)                         |
| **Parsing** | Tree-sitter native bindings                                    | Tree-sitter WASM                                             |
| **Privacy** | Everything local, no network                                   | Everything in-browser, no server                             |

&gt; **Bridge mode:** `gitnexus serve` connects the two â€” the web UI auto-detects the local server and can browse all your CLI-indexed repos without re-uploading or re-indexing.

---

## CLI + MCP (recommended)

The CLI indexes your repository and runs an MCP server that gives AI agents deep codebase awareness.

### Quick Start

```bash
# Index your repo (run from repo root)
npx gitnexus analyze
```

That&#039;s it. This indexes the codebase, installs agent skills, registers Claude Code hooks, and creates `AGENTS.md` / `CLAUDE.md` context files â€” all in one command.

To configure MCP for your editor, run `npx gitnexus setup` once â€” or set it up manually below.

### MCP Setup

`gitnexus setup` auto-detects your editors and writes the correct global MCP config. You only need to run it once.

### Editor Support

| Editor                | MCP | Skills | Hooks (auto-augment) | Support        |
| --------------------- | --- | ------ | -------------------- | -------------- |
| **Claude Code** | Yes | Yes    | Yes (PreToolUse)     | **Full** |
| **Cursor**      | Yes | Yes    | â€”                   | MCP + Skills   |
| **Windsurf**    | Yes | â€”     | â€”                   | MCP            |
| **OpenCode**    | Yes | Yes    | â€”                   | MCP + Skills   |

&gt; **Claude Code** gets the deepest integration: MCP tools + agent skills + PreToolUse hooks that automatically enrich grep/glob/bash calls with knowledge graph context.

### Community Integrations

| Agent | Install | Source |
|-------|---------|--------|
| [pi](https://pi.dev) | `pi install npm:pi-gitnexus` | [pi-gitnexus](https://github.com/tintinweb/pi-gitnexus) |

If you prefer manual configuration:

**Claude Code** (full support â€” MCP + skills + hooks):

```bash
claude mcp add gitnexus -- npx -y gitnexus@latest mcp
```

**Cursor** (`~/.cursor/mcp.json` â€” global, works for all projects):

```json
{
  &quot;mcpServers&quot;: {
    &quot;gitnexus&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;gitnexus@latest&quot;, &quot;mcp&quot;]
    }
  }
}
```

**OpenCode** (`~/.config/opencode/config.json`):

```json
{
  &quot;mcp&quot;: {
    &quot;gitnexus&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;gitnexus@latest&quot;, &quot;mcp&quot;]
    }
  }
}
```

### CLI Commands

```bash
gitnexus setup                    # Configure MCP for your editors (one-time)
gitnexus analyze [path]           # Index a repository (or update stale index)
gitnexus analyze --force          # Force full re-index
gitnexus analyze --skip-embeddings  # Skip embedding generation (faster)
gitnexus mcp                     # Start MCP server (stdio) â€” serves all indexed repos
gitnexus serve                   # Start local HTTP server (multi-repo) for web UI connection
gitnexus list                    # List all indexed repositories
gitnexus status                  # Show index status for current repo
gitnexus clean                   # Delete index for current repo
gitnexus clean --all --force     # Delete all indexes
gitnexus wiki [path]             # Generate repository wiki from knowledge graph
gitnexus wiki --model &lt;model&gt;    # Wiki with custom LLM model (default: gpt-4o-mini)
gitnexus wiki --base-url &lt;url&gt;   # Wiki with custom LLM API base URL
```

### What Your AI Agent Gets

**7 tools** exposed via MCP:

| Tool               | What It Does                                                      | `repo` Param |
| ------------------ | ----------------------------------------------------------------- | -------------- |
| `list_repos`     | Discover all indexed repositories                                 | â€”             |
| `query`          | Process-grouped hybrid search (BM25 + semantic + RRF)             | Optional       |
| `context`        | 360-degree symbol view â€” categorized refs, process participation | Optional       |
| `impact`         | Blast radius analysis with depth grouping and confidence          | Optional       |
| `detect_changes` | Git-diff impact â€” maps changed lines to affected processes       | Optional       |
| `rename`         | Multi-file coordinated rename with graph + text search            | Optional       |
| `cypher`         | Raw Cypher graph queries                                          | Optional       |

&gt; When only one repo is indexed, the `repo` parameter is optional. With multiple repos, specify which one: `query({query: &quot;auth&quot;, repo: &quot;my-app&quot;})`.

**Resources** for instant context:

| Resource                                  | Purpose                                              |
| ----------------------------------------- | ---------------------------------------------------- |
| `gitnexus://repos`                      | List all indexed repositories (read this first)      |
| `gitnexus://repo/{name}/context`        | Codebase stats, staleness check, and available tools |
| `gitnexus://repo/{name}/clusters`       | All functional clusters with cohesion scores         |
| `gitnexus://repo/{name}/cluster/{name}` | Cluster members and details                          |
| `gitnexus://repo/{name}/processes`      | All execution flows                                  |
| `gitnexus://repo/{name}/process/{name}` | Full process trace with steps                        |
| `gitnexus://repo/{name}/schema`         | Graph schema for Cypher queries                      |

**2 MCP prompts** for guided workflows:

| Prompt            | What It Does                                                              |
| ----------------- | ------------------------------------------------------------------------- |
| `detect_impact` | Pre-commit change analysis â€” scope, affected processes, risk level       |
| `generate_map`  | Architecture documentation from the knowledge graph with mermaid diagrams |

**4 agent skills** installed to `.claude/skills/` automatically:

- **Exploring** â€” Navigate unfamiliar code using the knowledge graph
- **Debugging** â€” Trace bugs through call chains
- **Impact Analysis** â€” Analyze blast radius before changes
- **Refactoring** â€” Plan safe refactors using dependency mapping

---

## Multi-Repo MCP Architecture

GitNexus uses a **global registry** so one MCP server can serve multiple indexed repos. No per-project MCP config needed â€” set it up once and it works everywhere.

```mermaid
flowchart TD
    subgraph CLI [CLI Commands]
        Setup[&quot;gitnexus setup&quot;]
        Analyze[&quot;gitnexus analyze&quot;]
        Clean[&quot;gitnexus clean&quot;]
        List[&quot;gitnexus list&quot;]
    end

    subgraph Registry [&quot;~/.gitnexus/&quot;]
        RegFile[&quot;registry.json&quot;]
    end

    subgraph Repos [Project Repos]
        RepoA[&quot;.gitnexus/ in repo A&quot;]
        RepoB[&quot;.gitnexus/ in repo B&quot;]
    end

    subgraph MCP [MCP Server]
        Server[&quot;server.ts&quot;]
        Backend[&quot;LocalBackend&quot;]
        Pool[&quot;Connection Pool&quot;]
        ConnA[&quot;KuzuDB conn A&quot;]
        ConnB[&quot;KuzuDB conn B&quot;]
    end

    Setup --&gt;|&quot;writes global MCP config&quot;| CursorConfig[&quot;~/.cursor/mcp.json&quot;]
    Analyze --&gt;|&quot;registers repo&quot;| RegFile
    Analyze --&gt;|&quot;stores index&quot;| RepoA
    Clean --&gt;|&quot;unregisters repo&quot;| RegFile
    List --&gt;|&quot;reads&quot;| RegFile
    Server --&gt;|&quot;reads registry&quot;| RegFile
    Server --&gt; Backend
    Backend --&gt; Pool
    Pool --&gt;|&quot;lazy open&quot;| ConnA
    Pool --&gt;|&quot;lazy open&quot;| ConnB
    ConnA --&gt;|&quot;queries&quot;| RepoA
    ConnB --&gt;|&quot;queries&quot;| RepoB
```

**How it works:** Each `gitnexus analyze` stores the index in `.gitnexus/` inside the repo (portable, gitignored) and registers a pointer in `~/.gitnexus/registry.json`. When an AI agent starts, the MCP server reads the registry and can serve any indexed repo. KuzuDB connections are opened lazily on first query and evicted after 5 minutes of inactivity (max 5 concurrent). If only one repo is indexed, the `repo` parameter is optional on all tools â€” agents don&#039;t need to change anything.

---

## Web UI (browser-based)

A fully client-side graph explorer and AI chat. No server, no install â€” your code never leaves the browser.

**Try it now:** [gitnexus.vercel.app](https://gitnexus.vercel.app) â€” drag &amp; drop a ZIP and start exploring.

&lt;img width=&quot;2550&quot; height=&quot;1343&quot; alt=&quot;gitnexus_img&quot; src=&quot;https://github.com/user-attachments/assets/cc5d637d-e0e5-48e6-93ff-5bcfdb929285&quot; /&gt;

Or run locally:

```bash
git clone https://github.com/abhigyanpatwari/gitnexus.git
cd gitnexus/gitnexus-web
npm install
npm run dev
```

The web UI uses the same indexing pipeline as the CLI but runs entirely in WebAssembly (Tree-sitter WASM, KuzuDB WASM, in-browser embeddings). It&#039;s great for quick exploration but limited by browser memory for larger repos.

**Local Backend Mode:** Run `gitnexus serve` and open the web UI locally â€” it auto-detects the server and shows all your indexed repos, with full AI chat support. No need to re-upload or re-index. The agent&#039;s tools (Cypher queries, search, code navigation) route through the backend HTTP API automatically.

---

## The Problem GitNexus Solves

Tools like **Cursor**, **Claude Code**, **Cline**, **Roo Code**, and **Windsurf** are powerful â€” but they don&#039;t truly know your codebase structure.

**What happens:**

1. AI edits `UserService.validate()`
2. Doesn&#039;t know 47 functions depend on its return type
3. **Breaking changes ship**

### Traditional Graph RAG vs GitNexus

Traditional approaches give the LLM raw graph edges and hope it explores enough. GitNexus **precomputes structure at index time** â€” clustering, tracing, scoring â€” so tools return complete context in one call:

```mermaid
flowchart TB
    subgraph Traditional[&quot;Traditional Graph RAG&quot;]
        direction TB
        U1[&quot;User: What depends on UserService?&quot;]
        U1 --&gt; LLM1[&quot;LLM receives raw graph&quot;]
        LLM1 --&gt; Q1[&quot;Query 1: Find callers&quot;]
        Q1 --&gt; Q2[&quot;Query 2: What files?&quot;]
        Q2 --&gt; Q3[&quot;Query 3: Filter tests?&quot;]
        Q3 --&gt; Q4[&quot;Query 4: High-risk?&quot;]
        Q4 --&gt; OUT1[&quot;Answer after 4+ queries&quot;]
    end

    subgraph GN[&quot;GitNexus Smart Tools&quot;]
        direction TB
        U2[&quot;User: What depends on UserService?&quot;]
        U2 --&gt; TOOL[&quot;impact UserService upstream&quot;]
        TOOL --&gt; PRECOMP[&quot;Pre-structured response:
        8 callers, 3 clusters, all 90%+ confidence&quot;]
        PRECOMP --&gt; OUT2[&quot;Complete answer, 1 query&quot;]
    end
```

**Core innovation: Precomputed Relational Intelligence**

- **Reliability** â€” LLM can&#039;t miss context, it&#039;s already in the tool response
- **Token efficiency** â€” No 10-query chains to understand one function
- **Model democratization** â€” Smaller LLMs work because tools do the heavy lifting

---

## How It Works

GitNexus builds a complete knowledge graph of your codebase through a multi-phase indexing pipeline:

1. **Structure** â€” Walks the file tree and maps folder/file relationships
2. **Parsing** â€” Extracts functions, classes, methods, and interfaces using Tree-sitter ASTs
3. **Resolution** â€” Resolves imports and function calls across files with language-aware logic
4. **Clustering** â€” Groups related symbols into functional communities
5. **Processes** â€” Traces execution flows from entry points through call chains
6. **Search** â€” Builds hybrid search indexes for fast retrieval

### Supported Languages

TypeScript, JavaScript, Python, Java, C, C++, C#, Go, Rust

---

## Tool Examples

### Impact Analysis

```
impact({target: &quot;UserService&quot;, direction: &quot;upstream&quot;, minConfidence: 0.8})

TARGET: Class UserService (src/services/user.ts)

UPSTREAM (what depends on this):
  Depth 1 (WILL BREAK):
    handleLogin [CALLS 90%] -&gt; src/api/auth.ts:45
    handleRegister [CALLS 90%] -&gt; src/api/auth.ts:78
    UserController [CALLS 85%] -&gt; src/controllers/user.ts:12
  Depth 2 (LIKELY AFFECTED):
    authRouter [IMPORTS] -&gt; src/routes/auth.ts
```

Options: `maxDepth`, `minConfidence`, `relationTypes` (`CALLS`, `IMPORTS`, `EXTENDS`, `IMPLEMENTS`), `includeTests`

### Process-Grouped Search

```
query({query: &quot;authentication middleware&quot;})

processes:
  - summary: &quot;LoginFlow&quot;
    priority: 0.042
    symbol_count: 4
    process_type: cross_community
    step_count: 7

process_symbols:
  - name: validateUser
    type: Function
    filePath: src/auth/validate.ts
    process_id: proc_login
    step_index: 2

definitions:
  - name: AuthConfig
    type: Interface
    filePath: src/types/auth.ts
```

### Context (360-degree Symbol View)

```
context({name: &quot;validateUser&quot;})

symbol:
  uid: &quot;Function:validateUser&quot;
  kind: Function
  filePath: src/auth/validate.ts
  startLine: 15

incoming:
  calls: [handleLogin, handleRegister, UserController]
  imports: [authRouter]

outgoing:
  calls: [checkPassword, createSession]

processes:
  - name: LoginFlow (step 2/7)
  - name: RegistrationFlow (step 3/5)
```

### Detect Changes (Pre-Commit)

```
detect_changes({scope: &quot;all&quot;})

summary:
  changed_count: 12
  affected_count: 3
  changed_files: 4
  risk_level: medium

changed_symbols: [validateUser, AuthService, ...]
affected_processes: [LoginFlow, RegistrationFlow, ...]
```

### Rename (Multi-File)

```
rename({symbol_name: &quot;validateUser&quot;, new_name: &quot;verifyUser&quot;, dry_run: true})

status: success
files_affected: 5
total_edits: 8
graph_edits: 6     (high confidence)
text_search_edits: 2  (review carefully)
changes: [...]
```

### Cypher Queries

```cypher
-- Find what calls auth functions with high confidence
MATCH (c:Community {heuristicLabel: &#039;Authentication&#039;})&lt;-[:CodeRelation {type: &#039;MEMBER_OF&#039;}]-(fn)
MATCH (caller)-[r:CodeRelation {type: &#039;CALLS&#039;}]-&gt;(fn)
WHERE r.confidence &gt; 0.8
RETURN caller.name, fn.name, r.confidence
ORDER BY r.confidence DESC
```

---

## Wiki Generation

Generate LLM-powered documentation from your knowledge graph:

```bash
# Requires an LLM API key (OPENAI_API_KEY, etc.)
gitnexus wiki

# Use a custom model or provider
gitnexus wiki --model gpt-4o
gitnexus wiki --base-url https://api.anthropic.com/v1

# Force full regeneration
gitnexus wiki --force
```

The wiki generator reads the indexed graph structure, groups files into modules via LLM, generates per-module documentation pages, and creates an overview page â€” all with cross-references to the knowledge graph.

---

## Tech Stack

| Layer                     | CLI                                   | Web                                     |
| ------------------------- | ------------------------------------- | --------------------------------------- |
| **Runtime**         | Node.js (native)                      | Browser (WASM)                          |
| **Parsing**         | Tree-sitter native bindings           | Tree-sitter WASM                        |
| **Database**        | KuzuDB native                         | KuzuDB WASM                             |
| **Embeddings**      | HuggingFace transformers.js (GPU/CPU) | transformers.js (WebGPU/WASM)           |
| **Search**          | BM25 + semantic + RRF                 | BM25 + semantic + RRF                   |
| **Agent Interface** | MCP (stdio)                           | LangChain ReAct agent                   |
| **Visualization**   | â€”                                    | Sigma.js + Graphology (WebGL)           |
| **Frontend**        | â€”                                    | React 18, TypeScript, Vite, Tailwind v4 |
| **Clustering**      | Graphology                            | Graphology                              |
| **Concurrency**     | Worker threads + async                | Web Workers + Comlink                   |

---

## Roadmap

### Actively Building

- [ ] **LLM Cluster Enrichment** â€” Semantic cluster names via LLM API
- [ ] **AST Decorator Detection** â€” Parse @Controller, @Get, etc.
- [ ] **Incremental Indexing** â€” Only re-index changed files

### Recently Completed

- [X] Wiki Generation, Multi-File Rename, Git-Diff Impact Analysis
- [X] Process-Grouped Search, 360-Degree Context, Claude Code Hooks
- [X] Multi-Repo MCP, Zero-Config Setup, 9 Language Support
- [X] Community Detection, Process Detection, Confidence Scoring
- [X] Hybrid Search, Vector Index

---

## Security &amp; Privacy

- **CLI**: Everything runs locally on your machine. No network calls. Index stored in `.gitnexus/` (gitignored). Global registry at `~/.gitnexus/` stores only paths and metadata.
- **Web**: Everything runs in your browser. No code uploaded to any server. API keys stored in localStorage only.
- Open source â€” audit the code yourself.

---

## Acknowledgments

- [Tree-sitter](https://tree-sitter.github.io/) â€” AST parsing
- [KuzuDB](https://kuzudb.com/) â€” Embedded graph database with vector support
- [Sigma.js](https://www.sigmajs.org/) â€” WebGL graph rendering
- [transformers.js](https://huggingface.co/docs/transformers.js) â€” Browser ML
- [Graphology](https://graphology.github.io/) â€” Graph data structures
- [MCP](https://modelcontextprotocol.io/) â€” Model Context Protocol
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[ourongxing/newsnow]]></title>
            <link>https://github.com/ourongxing/newsnow</link>
            <guid>https://github.com/ourongxing/newsnow</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:20 GMT</pubDate>
            <description><![CDATA[Elegant reading of real-time and hottest news]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ourongxing/newsnow">ourongxing/newsnow</a></h1>
            <p>Elegant reading of real-time and hottest news</p>
            <p>Language: TypeScript</p>
            <p>Stars: 18,221</p>
            <p>Forks: 5,225</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre>![](/public/og-image.png)

English | [ç®€ä½“ä¸­æ–‡](README.zh-CN.md) | [æ—¥æœ¬èª](README.ja-JP.md)

&gt; [!NOTE]
&gt; This is a demo version currently supporting Chinese only. A full-featured version with better customization and English content support will be released later.

**_Elegant reading of real-time and hottest news_**

## Features

- Clean and elegant UI design for optimal reading experience
- Real-time updates on trending news
- GitHub OAuth login with data synchronization
- 30-minute default cache duration (logged-in users can force refresh)
- Adaptive scraping interval (minimum 2 minutes) based on source update frequency to optimize resource usage and prevent IP bans
- support MCP server

```json
{
  &quot;mcpServers&quot;: {
    &quot;newsnow&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;-y&quot;,
        &quot;newsnow-mcp-server&quot;
      ],
      &quot;env&quot;: {
        &quot;BASE_URL&quot;: &quot;https://newsnow.busiyi.world&quot;
      }
    }
  }
}
```
You can change the `BASE_URL` to your own domain.

## Deployment

### Basic Deployment

For deployments without login and caching:

1. Fork this repository
2. Import to platforms like Cloudflare Page or Vercel

### Cloudflare Page Configuration

- Build command: `pnpm run build`
- Output directory: `dist/output/public`

### GitHub OAuth Setup

1. [Create a GitHub App](https://github.com/settings/applications/new)
2. No special permissions required
3. Set callback URL to: `https://your-domain.com/api/oauth/github` (replace `your-domain` with your actual domain)
4. Obtain Client ID and Client Secret

### Environment Variables

Refer to `example.env.server`. For local development, rename it to `.env.server` and configure:

```env
# Github Client ID
G_CLIENT_ID=
# Github Client Secret
G_CLIENT_SECRET=
# JWT Secret, usually the same as Client Secret
JWT_SECRET=
# Initialize database, must be set to true on first run, can be turned off afterward
INIT_TABLE=true
# Whether to enable cache
ENABLE_CACHE=true
```

### Database Support

Supported database connectors: https://db0.unjs.io/connectors
**Cloudflare D1 Database** is recommended.

1. Create D1 database in Cloudflare Worker dashboard
2. Configure database_id and database_name in wrangler.toml
3. If wrangler.toml doesn&#039;t exist, rename example.wrangler.toml and modify configurations
4. Changes will take effect on next deployment

### Docker Deployment

In project root directory:

```sh
docker compose up
```

You can also set Environment Variables in `docker-compose.yml`.

## Development

&gt; [!Note]
&gt; Requires Node.js &gt;= 20

```sh
corepack enable
pnpm i
pnpm dev
```

### Adding Data Sources

Refer to `shared/sources` and `server/sources` directories. The project provides complete type definitions and a clean architecture.

For detailed instructions on how to add new sources, see [CONTRIBUTING.md](CONTRIBUTING.md).

## Roadmap

- Add **multi-language support** (English, Chinese, more to come).
- Improve **personalization options** (category-based news, saved preferences).
- Expand **data sources** to cover global news in multiple languages.

**_release when ready_**
![](https://testmnbbs.oss-cn-zhangjiakou.aliyuncs.com/pic/20250328172146_rec_.gif?x-oss-process=base_webp)

## Contributing

Contributions are welcome! Feel free to submit pull requests or create issues for feature requests and bug reports.

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines on how to contribute, especially for adding new data sources.

## License

[MIT](./LICENSE) Â© ourongxing
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[labring/FastGPT]]></title>
            <link>https://github.com/labring/FastGPT</link>
            <guid>https://github.com/labring/FastGPT</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:19 GMT</pubDate>
            <description><![CDATA[FastGPT is a knowledge-based platform built on the LLMs, offers a comprehensive suite of out-of-the-box capabilities such as data processing, RAG retrieval, and visual AI workflow orchestration, letting you easily develop and deploy complex question-answering systems without the need for extensive setup or configuration.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/labring/FastGPT">labring/FastGPT</a></h1>
            <p>FastGPT is a knowledge-based platform built on the LLMs, offers a comprehensive suite of out-of-the-box capabilities such as data processing, RAG retrieval, and visual AI workflow orchestration, letting you easily develop and deploy complex question-answering systems without the need for extensive setup or configuration.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 27,186</p>
            <p>Forks: 6,935</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://fastgpt.io/&quot;&gt;&lt;img src=&quot;/.github/imgs/logo.svg&quot; width=&quot;120&quot; height=&quot;120&quot; alt=&quot;fastgpt logo&quot;&gt;&lt;/a&gt;

# FastGPT

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README_en.md&quot;&gt;English&lt;/a&gt; |
  &lt;a href=&quot;./README.md&quot;&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; |
  &lt;a href=&quot;./README_id.md&quot;&gt;Bahasa Indonesia&lt;/a&gt; |
  &lt;a href=&quot;./README_th.md&quot;&gt;à¹„à¸—à¸¢&lt;/a&gt; |
  &lt;a href=&quot;./README_vi.md&quot;&gt;Tiáº¿ng Viá»‡t&lt;/a&gt; |
  &lt;a href=&quot;./README_ja.md&quot;&gt;æ—¥æœ¬èª&lt;/a&gt;
&lt;/p&gt;

FastGPT æ˜¯ä¸€ä¸ª AI Agent æ„å»ºå¹³å°ï¼Œæä¾›å¼€ç®±å³ç”¨çš„æ•°æ®å¤„ç†ã€æ¨¡å‹è°ƒç”¨ç­‰èƒ½åŠ›ï¼ŒåŒæ—¶å¯ä»¥é€šè¿‡ Flow å¯è§†åŒ–è¿›è¡Œå·¥ä½œæµç¼–æ’ï¼Œä»è€Œå®ç°å¤æ‚çš„åº”ç”¨åœºæ™¯ï¼

&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://fastgpt.io/&quot;&gt;
    &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/åœ¨çº¿ä½¿ç”¨-d4eaf7?style=flat-square&amp;logo=spoj&amp;logoColor=7d09f1&quot; alt=&quot;cloud&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://doc.fastgpt.io/docs/introduction&quot;&gt;
    &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/ç›¸å…³æ–‡æ¡£-7d09f1?style=flat-square&quot; alt=&quot;document&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://doc.fastgpt.io/docs/introduction/development/intro&quot;&gt;
    &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/æœ¬åœ°å¼€å‘-%23d4eaf7?style=flat-square&amp;logo=xcode&amp;logoColor=7d09f1&quot; alt=&quot;development&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;/#-%E7%9B%B8%E5%85%B3%E9%A1%B9%E7%9B%AE&quot;&gt;
    &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/ç›¸å…³é¡¹ç›®-7d09f1?style=flat-square&quot; alt=&quot;project&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

https://github.com/labring/FastGPT/assets/15308462/7d3a38df-eb0e-4388-9250-2409bd33f6d4

## å¿«é€Ÿå¼€å§‹

å¯ä»¥é€šè¿‡ Docker å¿«é€Ÿå¯åŠ¨ FastGPTï¼Œåœ¨ç»ˆç«¯è¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼Œæ ¹æ®å¼•å¯¼å®Œæˆè¾“å…¥å³å¯æ‹‰å–é…ç½®ã€‚

```bash
# è¾“å…¥å‘½ä»¤æ‹‰å–é…ç½®æ–‡ä»¶
bash &lt;(curl -fsSL https://doc.fastgpt.cn/deploy/install.sh)
# å¯åŠ¨
docker compose up -d
```

å®Œå…¨å¯åŠ¨åï¼Œå¯é€šè¿‡`http://localhost:3000`è®¿é—® FastGPTï¼Œé»˜è®¤è´¦å·ä¸º`root`ï¼Œå¯†ç ä¸º`1234`ã€‚

å¦‚æœä½ é‡åˆ°é—®é¢˜ï¼Œå¯ä»¥[æŸ¥çœ‹å®Œæ•´ Docker éƒ¨ç½²æ•™ç¨‹](https://doc.fastgpt.io/docs/introduction/development/docker)

## ğŸ›¸ ä½¿ç”¨æ–¹å¼

- **äº‘æœåŠ¡ç‰ˆæœ¬**  
  å¦‚æœä½ ä¸éœ€è¦ç§æœ‰åŒ–éƒ¨ç½²ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨æˆ‘ä»¬æä¾›çš„äº‘æœåŠ¡ç‰ˆæœ¬ï¼Œåœ°å€ä¸ºï¼š[fastgpt.io](https://fastgpt.io/)

- **ç¤¾åŒºè‡ªæ‰˜ç®¡ç‰ˆæœ¬**  
  å¯ä»¥ä½¿ç”¨[Docker](https://doc.fastgpt.io/docs/introduction/development/docker)å¿«é€Ÿéƒ¨ç½²ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨[Sealos Cloud](https://doc.fastgpt.io/docs/introduction/development/sealos) æ¥ä¸€é”®éƒ¨ç½²FastGPTã€‚

- **å•†ä¸šç‰ˆ**  
  å¦‚æœä½ éœ€è¦æ›´å®Œæ•´çš„åŠŸèƒ½ï¼Œæˆ–æ·±åº¦çš„æœåŠ¡æ”¯æŒï¼Œå¯ä»¥é€‰æ‹©æˆ‘ä»¬çš„[å•†ä¸šç‰ˆ](https://doc.fastgpt.io/docs/introduction/commercial)ã€‚æˆ‘ä»¬é™¤äº†æä¾›å®Œæ•´çš„è½¯ä»¶å¤–ï¼Œè¿˜æä¾›ç›¸åº”çš„åœºæ™¯è½åœ°è¾…å¯¼ï¼Œå…·ä½“å¯æäº¤[å•†ä¸šå’¨è¯¢](https://fael3z0zfze.feishu.cn/share/base/form/shrcnjJWtKqjOI9NbQTzhNyzljc)

## ğŸ’¡ æ ¸å¿ƒåŠŸèƒ½

|                                    |                                    |
| ---------------------------------- | ---------------------------------- |
| ![Demo](./.github/imgs/intro1.png) | ![Demo](./.github/imgs/intro2.jpg) |
| ![Demo](./.github/imgs/intro3.png) | ![Demo](./.github/imgs/intro4.png) |

`1` åº”ç”¨ç¼–æ’èƒ½åŠ›
   - [x] è§„åˆ’ Agent æ¨¡å¼ã€‚
   - [x] å¯¹è¯å·¥ä½œæµã€æ’ä»¶å·¥ä½œæµï¼ŒåŒ…å«åŸºç¡€çš„ RPA èŠ‚ç‚¹ã€‚
   - [x] ç”¨æˆ·äº¤äº’
   - [x] åŒå‘ MCP
   - [ ] è¾…åŠ©ç”Ÿæˆå·¥ä½œæµ

`2` åº”ç”¨è°ƒè¯•èƒ½åŠ›
   - [x] çŸ¥è¯†åº“å•ç‚¹æœç´¢æµ‹è¯•
   - [x] å¯¹è¯æ—¶åé¦ˆå¼•ç”¨å¹¶å¯ä¿®æ”¹ä¸åˆ é™¤
   - [x] å®Œæ•´è°ƒç”¨é“¾è·¯æ—¥å¿—
   - [x] åº”ç”¨è¯„æµ‹
   - [ ] é«˜çº§ç¼–æ’ DeBug è°ƒè¯•æ¨¡å¼
   - [ ] åº”ç”¨èŠ‚ç‚¹æ—¥å¿—

`3` çŸ¥è¯†åº“èƒ½åŠ›
   - [x] å¤šåº“å¤ç”¨ï¼Œæ··ç”¨
   - [x] chunk è®°å½•ä¿®æ”¹å’Œåˆ é™¤
   - [x] æ”¯æŒæ‰‹åŠ¨è¾“å…¥ï¼Œç›´æ¥åˆ†æ®µï¼ŒQA æ‹†åˆ†å¯¼å…¥
   - [x] æ”¯æŒ txtï¼Œmdï¼Œhtmlï¼Œpdfï¼Œdocxï¼Œpptxï¼Œcsvï¼Œxlsx (æœ‰éœ€è¦æ›´å¤šå¯ PR file loader)ï¼Œæ”¯æŒ url è¯»å–ã€CSV æ‰¹é‡å¯¼å…¥
   - [x] æ··åˆæ£€ç´¢ &amp; é‡æ’
   - [x] API çŸ¥è¯†åº“
   - [ ] RAG æ¨¡å—çƒ­æ’æ‹”

`4` OpenAPI æ¥å£
   - [x] completions æ¥å£ (chat æ¨¡å¼å¯¹é½ GPT æ¥å£)
   - [x] çŸ¥è¯†åº“ CRUD
   - [x] å¯¹è¯ CRUD
   - [x] è‡ªåŠ¨åŒ– OpenAPI æ¥å£

`5` è¿è¥èƒ½åŠ›
   - [x] å…ç™»å½•åˆ†äº«çª—å£
   - [x] Iframe ä¸€é”®åµŒå…¥
   - [x] ç»Ÿä¸€æŸ¥é˜…å¯¹è¯è®°å½•ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œæ ‡æ³¨
   - [x] åº”ç”¨è¿è¥æ—¥å¿—

`6` å…¶ä»–
   - [x] å¯è§†åŒ–æ¨¡å‹é…ç½®ã€‚
   - [x] æ”¯æŒè¯­éŸ³è¾“å…¥å’Œè¾“å‡º (å¯é…ç½®è¯­éŸ³è¾“å…¥è¯­éŸ³å›ç­”)
   - [x] æ¨¡ç³Šè¾“å…¥æç¤º
   - [x] æ¨¡æ¿å¸‚åœº

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-è¿”å›é¡¶éƒ¨-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## ğŸ’ª æˆ‘ä»¬çš„é¡¹ç›® &amp; é“¾æ¥

- [å¿«é€Ÿå¼€å§‹æœ¬åœ°å¼€å‘](https://doc.fastgpt.io/docs/introduction/development/intro/)
- [OpenAPI æ–‡æ¡£](https://doc.fastgpt.io/docs/openapi/intro)
- [FastGPT-plugin](https://github.com/labring/fastgpt-plugin)
- [AI Proxy: æ¨¡å‹èšåˆè´Ÿè½½å‡è¡¡æœåŠ¡](https://github.com/labring/aiproxy)
- [Lafï¼š3 åˆ†é’Ÿå¿«é€Ÿæ¥å…¥ä¸‰æ–¹åº”ç”¨](https://github.com/labring/laf)
- [Sealosï¼šå¿«é€Ÿéƒ¨ç½²é›†ç¾¤åº”ç”¨](https://github.com/labring/sealos)

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-è¿”å›é¡¶éƒ¨-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## ğŸŒ¿ ç¬¬ä¸‰æ–¹ç”Ÿæ€

- [AI Proxyï¼šå¤§æ¨¡å‹èšåˆæœåŠ¡](https://sealos.run/aiproxy/?k=fastgpt-github/)
- [SiliconCloud (ç¡…åŸºæµåŠ¨) â€”â€” å¼€æºæ¨¡å‹åœ¨çº¿ä½“éªŒå¹³å°](https://cloud.siliconflow.cn/i/TR9Ym0c4)
- [PPIO æ´¾æ¬§äº‘ï¼šä¸€é”®è°ƒç”¨é«˜æ€§ä»·æ¯”çš„å¼€æºæ¨¡å‹ API å’Œ GPU å®¹å™¨](https://ppinfra.com/user/register?invited_by=VITYVU&amp;utm_source=github_fastgpt)

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-è¿”å›é¡¶éƒ¨-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## ğŸ˜ï¸ ç¤¾åŒºäº¤æµç¾¤

æ‰«ç åŠ å…¥é£ä¹¦è¯é¢˜ç¾¤ï¼š

![](https://oss.laf.run/otnvvf-imgs/fastgpt-feishu2.png)

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-è¿”å›é¡¶éƒ¨-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## ğŸ¤ è´¡çŒ®è€…

æˆ‘ä»¬éå¸¸æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ®ã€‚å¦‚æœä½ å¯¹è´¡çŒ®ä»£ç æ„Ÿå…´è¶£ï¼Œå¯ä»¥æŸ¥çœ‹æˆ‘ä»¬çš„ GitHub [Issues](https://github.com/labring/FastGPT/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc)ï¼Œå¤§å±•èº«æ‰‹ï¼Œå‘æˆ‘ä»¬å±•ç¤ºä½ çš„å¥‡æ€å¦™æƒ³ã€‚

&lt;a href=&quot;https://github.com/labring/FastGPT/graphs/contributors&quot; target=&quot;_blank&quot;&gt;
  &lt;table&gt;
    &lt;tr&gt;
      &lt;th colspan=&quot;2&quot;&gt;
        &lt;br&gt;&lt;img src=&quot;https://contrib.rocks/image?repo=labring/FastGPT&quot;&gt;&lt;br&gt;&lt;br&gt;
      &lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&amp;period=past_28_days&amp;owner_id=102226726&amp;repo_ids=605673387&amp;image_size=2x3&amp;color_scheme=dark&quot;&gt;
          &lt;img alt=&quot;Active participants of labring - past 28 days&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&amp;period=past_28_days&amp;owner_id=102226726&amp;repo_ids=605673387&amp;image_size=2x3&amp;color_scheme=light&quot;&gt;
        &lt;/picture&gt;****
      &lt;/td&gt;
      &lt;td rowspan=&quot;2&quot;&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=new&amp;period=past_28_days&amp;owner_id=102226726&amp;repo_ids=605673387&amp;image_size=4x7&amp;color_scheme=dark&quot;&gt;
          &lt;img alt=&quot;New trends of labring&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=new&amp;period=past_28_days&amp;owner_id=102226726&amp;repo_ids=605673387&amp;image_size=4x7&amp;color_scheme=light&quot;&gt;
        &lt;/picture&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&amp;period=past_28_days&amp;owner_id=102226726&amp;repo_ids=605673387&amp;image_size=2x3&amp;color_scheme=dark&quot;&gt;
          &lt;img alt=&quot;New participants of labring - past 28 days&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&amp;period=past_28_days&amp;owner_id=102226726&amp;repo_ids=605673387&amp;image_size=2x3&amp;color_scheme=light&quot;&gt;
        &lt;/picture&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/a&gt;

## ğŸŒŸ Star History

&lt;a href=&quot;https://github.com/labring/FastGPT/stargazers&quot; target=&quot;_blank&quot; style=&quot;display: block&quot; align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=labring/FastGPT&amp;type=Date&amp;theme=dark&quot; /&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=labring/FastGPT&amp;type=Date&quot; /&gt;
    &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=labring/FastGPT&amp;type=Date&quot; /&gt;
  &lt;/picture&gt;
&lt;/a&gt;

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-è¿”å›é¡¶éƒ¨-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## ä½¿ç”¨åè®®

æœ¬ä»“åº“éµå¾ª [FastGPT Open Source License](./LICENSE) å¼€æºåè®®ã€‚

1. å…è®¸ä½œä¸ºåå°æœåŠ¡ç›´æ¥å•†ç”¨ï¼Œä½†ä¸å…è®¸æä¾› SaaS æœåŠ¡ã€‚
2. æœªç»å•†ä¸šæˆæƒï¼Œä»»ä½•å½¢å¼çš„å•†ç”¨æœåŠ¡å‡éœ€ä¿ç•™ç›¸å…³ç‰ˆæƒä¿¡æ¯ã€‚
3. å®Œæ•´è¯·æŸ¥çœ‹ [FastGPT Open Source License](./LICENSE)
4. è”ç³»æ–¹å¼ï¼šDennis@sealos.ioï¼Œ[ç‚¹å‡»æŸ¥çœ‹å•†ä¸šç‰ˆå®šä»·ç­–ç•¥](https://doc.fastgpt.io/docs/introduction/commercial/)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[siteboon/claudecodeui]]></title>
            <link>https://github.com/siteboon/claudecodeui</link>
            <guid>https://github.com/siteboon/claudecodeui</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:18 GMT</pubDate>
            <description><![CDATA[Use Claude Code, Cursor CLI or Codex on mobile and web with CloudCLI (aka Claude Code UI). CloudCLI is a free open source webui/GUI that helps you manage your Claude Code session and projects remotely]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/siteboon/claudecodeui">siteboon/claudecodeui</a></h1>
            <p>Use Claude Code, Cursor CLI or Codex on mobile and web with CloudCLI (aka Claude Code UI). CloudCLI is a free open source webui/GUI that helps you manage your Claude Code session and projects remotely</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,215</p>
            <p>Forks: 914</p>
            <p>Stars today: 314 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;public/logo.svg&quot; alt=&quot;Claude Code UI&quot; width=&quot;64&quot; height=&quot;64&quot;&gt;
  &lt;h1&gt;Cloud CLI (aka Claude Code UI)&lt;/h1&gt;
&lt;/div&gt;


A desktop and mobile UI for [Claude Code](https://docs.anthropic.com/en/docs/claude-code), [Cursor CLI](https://docs.cursor.com/en/cli/overview) and [Codex](https://developers.openai.com/codex). You can use it locally or remotely to view your active projects and sessions in Claude Code, Cursor, or Codex and make changes to them from everywhere (mobile or desktop). This gives you a proper interface that works everywhere. 

&lt;a href=&quot;https://trendshift.io/repositories/15586&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15586&quot; alt=&quot;siteboon%2Fclaudecodeui | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;div align=&quot;right&quot;&gt;&lt;i&gt;&lt;b&gt;English&lt;/b&gt; Â· &lt;a href=&quot;./README.ko.md&quot;&gt;í•œêµ­ì–´&lt;/a&gt; Â· &lt;a href=&quot;./README.zh-CN.md&quot;&gt;ä¸­æ–‡&lt;/a&gt; Â· &lt;a href=&quot;./README.ja.md&quot;&gt;æ—¥æœ¬èª&lt;/a&gt;&lt;/i&gt;&lt;/div&gt;

## Screenshots

&lt;div align=&quot;center&quot;&gt;
  
&lt;table&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;h3&gt;Desktop View&lt;/h3&gt;
&lt;img src=&quot;public/screenshots/desktop-main.png&quot; alt=&quot;Desktop Interface&quot; width=&quot;400&quot;&gt;
&lt;br&gt;
&lt;em&gt;Main interface showing project overview and chat&lt;/em&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;h3&gt;Mobile Experience&lt;/h3&gt;
&lt;img src=&quot;public/screenshots/mobile-chat.png&quot; alt=&quot;Mobile Interface&quot; width=&quot;250&quot;&gt;
&lt;br&gt;
&lt;em&gt;Responsive mobile design with touch navigation&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot; colspan=&quot;2&quot;&gt;
&lt;h3&gt;CLI Selection&lt;/h3&gt;
&lt;img src=&quot;public/screenshots/cli-selection.png&quot; alt=&quot;CLI Selection&quot; width=&quot;400&quot;&gt;
&lt;br&gt;
&lt;em&gt;Select between Claude Code, Cursor CLI and Codex&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;



&lt;/div&gt;

## Features

- **Responsive Design** - Works seamlessly across desktop, tablet, and mobile so you can also use Claude Code, Cursor, or Codex from mobile 
- **Interactive Chat Interface** - Built-in chat interface for seamless communication with Claude Code, Cursor, or Codex
- **Integrated Shell Terminal** - Direct access to Claude Code, Cursor CLI, or Codex through built-in shell functionality
- **File Explorer** - Interactive file tree with syntax highlighting and live editing
- **Git Explorer** - View, stage and commit your changes. You can also switch branches 
- **Session Management** - Resume conversations, manage multiple sessions, and track history
- **TaskMaster AI Integration** *(Optional)* - Advanced project management with AI-powered task planning, PRD parsing, and workflow automation
- **Model Compatibility** - Works with Claude Sonnet 4.5, Opus 4.5, and GPT-5.2 


## Quick Start

### Prerequisites

- [Node.js](https://nodejs.org/) v22 or higher
- [Claude Code CLI](https://docs.anthropic.com/en/docs/claude-code) installed and configured, and/or
- [Cursor CLI](https://docs.cursor.com/en/cli/overview) installed and configured, and/or
- [Codex](https://developers.openai.com/codex) installed and configured

### One-click Operation (Recommended)

No installation required, direct operation:

```bash
npx @siteboon/claude-code-ui
```

The server will start and be accessible at `http://localhost:3001` (or your configured PORT).

**To restart**: Simply run the same `npx` command again after stopping the server
### Global Installation (For Regular Use)

For frequent use, install globally once:

```bash
npm install -g @siteboon/claude-code-ui
```

Then start with a simple command:

```bash
claude-code-ui
```


**To restart**: Stop with Ctrl+C and run `claude-code-ui` again.

**To update**:
```bash
cloudcli update
```

### CLI Usage

After global installation, you have access to both `claude-code-ui` and `cloudcli` commands:

| Command / Option | Short | Description |
|------------------|-------|-------------|
| `cloudcli` or `claude-code-ui` | | Start the server (default) |
| `cloudcli start` | | Start the server explicitly |
| `cloudcli status` | | Show configuration and data locations |
| `cloudcli update` | | Update to the latest version |
| `cloudcli help` | | Show help information |
| `cloudcli version` | | Show version information |
| `--port &lt;port&gt;` | `-p` | Set server port (default: 3001) |
| `--database-path &lt;path&gt;` | | Set custom database location |

**Examples:**
```bash
cloudcli                          # Start with defaults
cloudcli -p 8080              # Start on custom port
cloudcli status                   # Show current configuration
```

### Run as Background Service (Recommended for Production)

For production use, run Claude Code UI as a background service using PM2 (Process Manager 2):

#### Install PM2

```bash
npm install -g pm2
```

#### Start as Background Service

```bash
# Start the server in background
pm2 start claude-code-ui --name &quot;claude-code-ui&quot;

# Or using the shorter alias
pm2 start cloudcli --name &quot;claude-code-ui&quot;

# Start on a custom port
pm2 start cloudcli --name &quot;claude-code-ui&quot; -- --port 8080
```


#### Auto-Start on System Boot

To make Claude Code UI start automatically when your system boots:

```bash
# Generate startup script for your platform
pm2 startup

# Save current process list
pm2 save
```


### Local Development Installation

1. **Clone the repository:**
```bash
git clone https://github.com/siteboon/claudecodeui.git
cd claudecodeui
```

2. **Install dependencies:**
```bash
npm install
```

3. **Configure environment:**
```bash
cp .env.example .env
# Edit .env with your preferred settings
```

4. **Start the application:**
```bash
# Development mode (with hot reload)
npm run dev

```
The application will start at the port you specified in your .env

5. **Open your browser:**
   - Development: `http://localhost:3001`

## Security &amp; Tools Configuration

**ğŸ”’ Important Notice**: All Claude Code tools are **disabled by default**. This prevents potentially harmful operations from running automatically.

### Enabling Tools

To use Claude Code&#039;s full functionality, you&#039;ll need to manually enable tools:

1. **Open Tools Settings** - Click the gear icon in the sidebar
3. **Enable Selectively** - Turn on only the tools you need
4. **Apply Settings** - Your preferences are saved locally

&lt;div align=&quot;center&quot;&gt;

![Tools Settings Modal](public/screenshots/tools-modal.png)
*Tools Settings interface - enable only what you need*

&lt;/div&gt;

**Recommended approach**: Start with basic tools enabled and add more as needed. You can always adjust these settings later.

## TaskMaster AI Integration *(Optional)*

Claude Code UI supports **[TaskMaster AI](https://github.com/eyaltoledano/claude-task-master)** (aka claude-task-master) integration for advanced project management and AI-powered task planning.

It provides
- AI-powered task generation from PRDs (Product Requirements Documents)
- Smart task breakdown and dependency management  
- Visual task boards and progress tracking

**Setup &amp; Documentation**: Visit the [TaskMaster AI GitHub repository](https://github.com/eyaltoledano/claude-task-master) for installation instructions, configuration guides, and usage examples.
After installing it you should be able to enable it from the Settings


## Usage Guide

### Core Features

#### Project Management
It automatically discovers Claude Code, Cursor or Codex sessions when available and groups them together into projects
session counts
- **Project Actions** - Rename, delete, and organize projects
- **Smart Navigation** - Quick access to recent projects and sessions
- **MCP support** - Add your own MCP servers through the UI 

#### Chat Interface
- **Use responsive chat or Claude Code/Cursor CLI/Codex CLI** - You can either use the adapted chat interface or use the shell button to connect to your selected CLI. 
- **Real-time Communication** - Stream responses from your selected CLI (Claude Code/Cursor/Codex) with WebSocket connection
- **Session Management** - Resume previous conversations or start fresh sessions
- **Message History** - Complete conversation history with timestamps and metadata
- **Multi-format Support** - Text, code blocks, and file references

#### File Explorer &amp; Editor
- **Interactive File Tree** - Browse project structure with expand/collapse navigation
- **Live File Editing** - Read, modify, and save files directly in the interface
- **Syntax Highlighting** - Support for multiple programming languages
- **File Operations** - Create, rename, delete files and directories

#### Git Explorer


#### TaskMaster AI Integration *(Optional)*
- **Visual Task Board** - Kanban-style interface for managing development tasks
- **PRD Parser** - Create Product Requirements Documents and parse them into structured tasks
- **Progress Tracking** - Real-time status updates and completion tracking

#### Session Management
- **Session Persistence** - All conversations automatically saved
- **Session Organization** - Group sessions by project and timestamp
- **Session Actions** - Rename, delete, and export conversation history
- **Cross-device Sync** - Access sessions from any device

### Mobile App
- **Responsive Design** - Optimized for all screen sizes
- **Touch-friendly Interface** - Swipe gestures and touch navigation
- **Mobile Navigation** - Bottom tab bar for easy thumb navigation
- **Adaptive Layout** - Collapsible sidebar and smart content prioritization
- **Add shortcut to Home Screen** - Add a shortcut to your home screen and the app will behave like a PWA

## Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚  Agent     â”‚
â”‚   (React/Vite)  â”‚â—„â”€â”€â–ºâ”‚ (Express/WS)    â”‚â—„â”€â”€â–ºâ”‚  Integration    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Backend (Node.js + Express)
- **Express Server** - RESTful API with static file serving
- **WebSocket Server** - Communication for chats and project refresh
- **Agent Integration (Claude Code / Cursor CLI / Codex)** - Process spawning and management
- **File System API** - Exposing file browser for projects

### Frontend (React + Vite)
- **React 18** - Modern component architecture with hooks
- **CodeMirror** - Advanced code editor with syntax highlighting





### Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details on commit conventions, development workflow, and release process.

## Troubleshooting

### Common Issues &amp; Solutions


#### &quot;No Claude projects found&quot;
**Problem**: The UI shows no projects or empty project list
**Solutions**:
- Ensure [Claude Code](https://docs.anthropic.com/en/docs/claude-code) is properly installed
- Run `claude` command in at least one project directory to initialize
- Verify `~/.claude/projects/` directory exists and has proper permissions

#### File Explorer Issues
**Problem**: Files not loading, permission errors, empty directories
**Solutions**:
- Check project directory permissions (`ls -la` in terminal)
- Verify the project path exists and is accessible
- Review server console logs for detailed error messages
- Ensure you&#039;re not trying to access system directories outside project scope


## License

GNU General Public License v3.0 - see [LICENSE](LICENSE) file for details.

This project is open source and free to use, modify, and distribute under the GPL v3 license.

## Acknowledgments

### Built With
- **[Claude Code](https://docs.anthropic.com/en/docs/claude-code)** - Anthropic&#039;s official CLI
- **[Cursor CLI](https://docs.cursor.com/en/cli/overview)** - Cursor&#039;s official CLI
- **[Codex](https://developers.openai.com/codex)** - OpenAI Codex
- **[React](https://react.dev/)** - User interface library
- **[Vite](https://vitejs.dev/)** - Fast build tool and dev server
- **[Tailwind CSS](https://tailwindcss.com/)** - Utility-first CSS framework
- **[CodeMirror](https://codemirror.net/)** - Advanced code editor
- **[TaskMaster AI](https://github.com/eyaltoledano/claude-task-master)** *(Optional)* - AI-powered project management and task planning

## Support &amp; Community

### Stay Updated
- **Star** this repository to show support
- **Watch** for updates and new releases
- **Follow** the project for announcements

### Sponsors
- [Siteboon - AI powered website builder](https://siteboon.ai)
---

&lt;div align=&quot;center&quot;&gt;
  &lt;strong&gt;Made with care for the Claude Code, Cursor and Codex community.&lt;/strong&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[DayuanJiang/next-ai-draw-io]]></title>
            <link>https://github.com/DayuanJiang/next-ai-draw-io</link>
            <guid>https://github.com/DayuanJiang/next-ai-draw-io</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:17 GMT</pubDate>
            <description><![CDATA[A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DayuanJiang/next-ai-draw-io">DayuanJiang/next-ai-draw-io</a></h1>
            <p>A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,950</p>
            <p>Forks: 2,337</p>
            <p>Stars today: 130 stars today</p>
            <h2>README</h2><pre># Next AI Draw.io

&lt;div align=&quot;center&quot;&gt;

**AI-Powered Diagram Creation Tool - Chat, Draw, Visualize**

English | [ä¸­æ–‡](./docs/cn/README_CN.md) | [æ—¥æœ¬èª](./docs/ja/README_JA.md)

[![TrendShift](https://trendshift.io/api/badge/repositories/15449)](https://next-ai-drawio.jiang.jp/)

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Next.js](https://img.shields.io/badge/Next.js-16.x-black)](https://nextjs.org/)
[![React](https://img.shields.io/badge/React-19.x-61dafb)](https://react.dev/)
[![Sponsor](https://img.shields.io/badge/Sponsor-â¤-ea4aaa)](https://github.com/sponsors/DayuanJiang)

[![Live Demo](./public/live-demo-button.svg)](https://next-ai-drawio.jiang.jp/)

&lt;/div&gt;

A Next.js web application that integrates AI capabilities with draw.io diagrams. Create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.

&gt; Note: Thanks to &lt;img src=&quot;https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/doubao-color.png&quot; alt=&quot;&quot; height=&quot;20&quot; /&gt; [ByteDance Doubao](https://www.volcengine.com/activity/newyear-referral?utm_campaign=doubao&amp;utm_content=aidrawio&amp;utm_medium=github&amp;utm_source=coopensrc&amp;utm_term=project) sponsorship, the demo site now uses the powerful K2-thinking model!


https://github.com/user-attachments/assets/9d60a3e8-4a1c-4b5e-acbb-26af2d3eabd1



## Table of Contents
- [Next AI Draw.io](#next-ai-drawio)
  - [Table of Contents](#table-of-contents)
  - [Examples](#examples)
  - [Features](#features)
  - [MCP Server (Preview)](#mcp-server-preview)
    - [Claude Code CLI](#claude-code-cli)
  - [Getting Started](#getting-started)
    - [Try it Online](#try-it-online)
    - [Desktop Application](#desktop-application)
    - [Run with Docker](#run-with-docker)
    - [Installation](#installation)
  - [Deployment](#deployment)
    - [Deploy to EdgeOne Pages](#deploy-to-edgeone-pages)
    - [Deploy on Vercel](#deploy-on-vercel)
    - [Deploy on Cloudflare Workers](#deploy-on-cloudflare-workers)
  - [Multi-Provider Support](#multi-provider-support)
  - [How It Works](#how-it-works)
  - [Support \&amp; Contact](#support--contact)
  - [FAQ](#faq)
  - [Star History](#star-history)

## Examples

Here are some example prompts and their generated diagrams:

&lt;div align=&quot;center&quot;&gt;
&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td colspan=&quot;2&quot; valign=&quot;top&quot; align=&quot;center&quot;&gt;
      &lt;strong&gt;Animated transformer connectors&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Give me a **animated connector** diagram of transformer&#039;s architecture.&lt;/p&gt;
      &lt;img src=&quot;./public/animated_connectors.svg&quot; alt=&quot;Transformer Architecture with Animated Connectors&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;GCP architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a GCP architecture diagram with **GCP icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/gcp_demo.svg&quot; alt=&quot;GCP Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;AWS architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a AWS architecture diagram with **AWS icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/aws_demo.svg&quot; alt=&quot;AWS Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;Azure architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a Azure architecture diagram with **Azure icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/azure_demo.svg&quot; alt=&quot;Azure Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;Cat sketch prompt&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Draw a cute cat for me.&lt;/p&gt;
      &lt;img src=&quot;./public/cat_demo.svg&quot; alt=&quot;Cat Drawing&quot; width=&quot;240&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;

## Features

-   **LLM-Powered Diagram Creation**: Leverage Large Language Models to create and manipulate draw.io diagrams directly through natural language commands
-   **Image-Based Diagram Replication**: Upload existing diagrams or images and have the AI replicate and enhance them automatically
-   **PDF &amp; Text File Upload**: Upload PDF documents and text files to extract content and generate diagrams from existing documents
-   **AI Reasoning Display**: View the AI&#039;s thinking process for supported models (OpenAI o1/o3, Gemini, Claude, etc.)
-   **Diagram History**: Comprehensive version control that tracks all changes, allowing you to view and restore previous versions of your diagrams before the AI editing.
-   **Interactive Chat Interface**: Communicate with AI to refine your diagrams in real-time
-   **Cloud Architecture Diagram Support**: Specialized support for generating cloud architecture diagrams (AWS, GCP, Azure)
-   **Animated Connectors**: Create dynamic and animated connectors between diagram elements for better visualization

## MCP Server (Preview)

&gt; **Preview Feature**: This feature is experimental and may not be stable.

Use Next AI Draw.io with AI agents like Claude Desktop, Cursor, and VS Code via MCP (Model Context Protocol).

```json
{
  &quot;mcpServers&quot;: {
    &quot;drawio&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;@next-ai-drawio/mcp-server@latest&quot;]
    }
  }
}
```

### Claude Code CLI

```bash
claude mcp add drawio -- npx @next-ai-drawio/mcp-server@latest
```

Then ask Claude to create diagrams:
&gt; &quot;Create a flowchart showing user authentication with login, MFA, and session management&quot;

The diagram appears in your browser in real-time!

See the [MCP Server README](./packages/mcp-server/README.md) for VS Code, Cursor, and other client configurations.

## Getting Started

### Try it Online

No installation needed! Try the app directly on our demo site:

[![Live Demo](./public/live-demo-button.svg)](https://next-ai-drawio.jiang.jp/)



&gt; **Bring Your Own API Key**: You can use your own API key to bypass usage limits on the demo site. Click the Settings icon in the chat panel to configure your provider and API key. Your key is stored locally in your browser and is never stored on the server.

### Desktop Application

Download the native desktop app for your platform from the [Releases page](https://github.com/DayuanJiang/next-ai-draw-io/releases):

Supported platforms: Windows, macOS, Linux.

### Run with Docker

[Go to Docker Guide](./docs/en/docker.md)

### Installation

1. Clone the repository:

```bash
git clone https://github.com/DayuanJiang/next-ai-draw-io
cd next-ai-draw-io
npm install
cp env.example .env.local
```

See the [Provider Configuration Guide](./docs/en/ai-providers.md) for detailed setup instructions for each provider.

2. Run the development server:

```bash
npm run dev
```

3. Open [http://localhost:6002](http://localhost:6002) in your browser to see the application.

## Deployment

### Deploy to EdgeOne Pages

You can deploy with one click using [Tencent EdgeOne Pages](https://pages.edgeone.ai/).

Deploy by this button: 

[![Deploy to EdgeOne Pages](https://cdnstatic.tencentcs.com/edgeone/pages/deploy.svg)](https://edgeone.ai/pages/new?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io)

Check out the [Tencent EdgeOne Pages documentation](https://pages.edgeone.ai/document/deployment-overview) for more details.

Additionally, deploying through Tencent EdgeOne Pages will also grant you a [daily free quota for DeepSeek models](https://pages.edgeone.ai/document/edge-ai).

### Deploy on Vercel 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io)

The easiest way to deploy is using [Vercel](https://vercel.com/new), the creators of Next.js. Be sure to **set the environment variables** in the Vercel dashboard as you did in your local `.env.local` file.

See the [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.

### Deploy on Cloudflare Workers

[Go to Cloudflare Deploy Guide](./docs/en/cloudflare-deploy.md)



## Multi-Provider Support

-   [ByteDance Doubao](https://www.volcengine.com/activity/newyear-referral?utm_campaign=doubao&amp;utm_content=aidrawio&amp;utm_medium=github&amp;utm_source=coopensrc&amp;utm_term=project)
-   AWS Bedrock (default)
-   OpenAI
-   Anthropic
-   Google AI
-   Google Vertex AI
-   Azure OpenAI
-   Ollama
-   OpenRouter
-   DeepSeek
-   SiliconFlow
-   ModelScope
-   SGLang
-   Vercel AI Gateway


All providers except AWS Bedrock and OpenRouter support custom endpoints.

ğŸ“– **[Detailed Provider Configuration Guide](./docs/en/ai-providers.md)** - See setup instructions for each provider.

### Server-Side Multi-Model Configuration

Administrators can configure multiple server-side models that are available to all users without requiring personal API keys. Configure via `AI_MODELS_CONFIG` environment variable (JSON string) or `ai-models.json` file.

**Model Requirements**: This task requires strong model capabilities for generating long-form text with strict formatting constraints (draw.io XML). Recommended models include Claude Sonnet 4.5, GPT-5.1, Gemini 3 Pro, and DeepSeek V3.2/R1.

Note that the `claude` series has been trained on draw.io diagrams with cloud architecture logos like AWS, Azure, GCP. So if you want to create cloud architecture diagrams, this is the best choice.


## How It Works

The application uses the following technologies:

-   **Next.js**: For the frontend framework and routing
-   **Vercel AI SDK** (`ai` + `@ai-sdk/*`): For streaming AI responses and multi-provider support
-   **react-drawio**: For diagram representation and manipulation

Diagrams are represented as XML that can be rendered in draw.io. The AI processes your commands and generates or modifies this XML accordingly.


## Support &amp; Contact

**Special thanks to [ByteDance Doubao](https://www.volcengine.com/activity/newyear-referral?utm_campaign=doubao&amp;utm_content=aidrawio&amp;utm_medium=github&amp;utm_source=coopensrc&amp;utm_term=project) for sponsoring the API token usage of the demo site!** Register on the ARK platform to get 500K free tokens for all models!

If you find this project useful, please consider [sponsoring](https://github.com/sponsors/DayuanJiang) to help me host the live demo site!

For support or inquiries, please open an issue on the GitHub repository or contact the maintainer at:

-   Email: me[at]jiang.jp

## FAQ

See [FAQ](./docs/en/FAQ.md) for common issues and solutions.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=DayuanJiang/next-ai-draw-io&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#DayuanJiang/next-ai-draw-io&amp;type=date&amp;legend=top-left)

---
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[tiann/hapi]]></title>
            <link>https://github.com/tiann/hapi</link>
            <guid>https://github.com/tiann/hapi</guid>
            <pubDate>Fri, 27 Feb 2026 00:08:16 GMT</pubDate>
            <description><![CDATA[App for Claude Code / Codex / Gemini / OpenCode, vibe coding anytime, anywhere]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tiann/hapi">tiann/hapi</a></h1>
            <p>App for Claude Code / Codex / Gemini / OpenCode, vibe coding anytime, anywhere</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,854</p>
            <p>Forks: 184</p>
            <p>Stars today: 96 stars today</p>
            <h2>README</h2><pre># HAPI

Run official Claude Code / Codex / Gemini / OpenCode sessions locally and control them remotely through a Web / PWA / Telegram Mini App.

&gt; **Why HAPI?** HAPI is a local-first alternative to Happy. See [Why Not Happy?](docs/guide/why-hapi.md) for the key differences.

## Features

- **Seamless Handoff** - Work locally, switch to remote when needed, switch back anytime. No context loss, no session restart.
- **Native First** - HAPI wraps your AI agent instead of replacing it. Same terminal, same experience, same muscle memory.
- **AFK Without Stopping** - Step away from your desk? Approve AI requests from your phone with one tap.
- **Your AI, Your Choice** - Claude Code, Codex, Gemini, OpenCodeâ€”different models, one unified workflow.
- **Terminal Anywhere** - Run commands from your phone or browser, directly connected to the working machine.
- **Voice Control** - Talk to your AI agent hands-free using the built-in voice assistant.

## Demo

https://github.com/user-attachments/assets/38230353-94c6-4dbe-9c29-b2a2cc457546

## Getting Started

```bash
npx @twsxtd/hapi hub --relay     # start hub with E2E encrypted relay
npx @twsxtd/hapi                 # run claude code
```

`hapi server` remains supported as an alias.

The terminal will display a URL and QR code. Scan the QR code with your phone or open the URL to access.

&gt; The relay uses WireGuard + TLS for end-to-end encryption. Your data is encrypted from your device to your machine.

For self-hosted options (Cloudflare Tunnel, Tailscale), see [Installation](docs/guide/installation.md)

## Docs

- [App](docs/guide/pwa.md)
- [How it Works](docs/guide/how-it-works.md)
- [Voice Assistant](docs/guide/voice-assistant.md)
- [Why HAPI](docs/guide/why-hapi.md)
- [FAQ](docs/guide/faq.md)

## Build from source

```bash
bun install
bun run build:single-exe
```

## Credits

HAPI means &quot;å“ˆçš®&quot; a Chinese transliteration of [Happy](https://github.com/slopus/happy). Great credit to the original project.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>