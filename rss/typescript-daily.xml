<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Thu, 15 Jan 2026 00:05:29 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[iOfficeAI/AionUi]]></title>
            <link>https://github.com/iOfficeAI/AionUi</link>
            <guid>https://github.com/iOfficeAI/AionUi</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:29 GMT</pubDate>
            <description><![CDATA[Free, local, open-source Cowork for Gemini CLI, Claude Code, Codex, Qwen Code, Goose Cli, Auggie, and more | üåü Star if you like it!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/iOfficeAI/AionUi">iOfficeAI/AionUi</a></h1>
            <p>Free, local, open-source Cowork for Gemini CLI, Claude Code, Codex, Qwen Code, Goose Cli, Auggie, and more | üåü Star if you like it!</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,585</p>
            <p>Forks: 297</p>
            <p>Stars today: 75 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[badlogic/pi-mono]]></title>
            <link>https://github.com/badlogic/pi-mono</link>
            <guid>https://github.com/badlogic/pi-mono</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:28 GMT</pubDate>
            <description><![CDATA[AI agent toolkit: coding agent CLI, unified LLM API, TUI & web UI libraries, Slack bot, vLLM pods]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/badlogic/pi-mono">badlogic/pi-mono</a></h1>
            <p>AI agent toolkit: coding agent CLI, unified LLM API, TUI & web UI libraries, Slack bot, vLLM pods</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,737</p>
            <p>Forks: 224</p>
            <p>Stars today: 84 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://shittycodingagent.ai&quot;&gt;
    &lt;img src=&quot;https://shittycodingagent.ai/logo.svg&quot; alt=&quot;pi logo&quot; width=&quot;128&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.com/invite/nKXTsAcmbT&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/badge/discord-community-5865F2?style=flat-square&amp;logo=discord&amp;logoColor=white&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/badlogic/pi-mono/actions/workflows/ci.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/badlogic/pi-mono/ci.yml?style=flat-square&amp;branch=main&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

# Pi Monorepo

&gt; **Looking for the pi coding agent?** See **[packages/coding-agent](packages/coding-agent)** for installation and usage.

Tools for building AI agents and managing LLM deployments.

## Packages

| Package | Description |
|---------|-------------|
| **[@mariozechner/pi-ai](packages/ai)** | Unified multi-provider LLM API (OpenAI, Anthropic, Google, etc.) |
| **[@mariozechner/pi-agent-core](packages/agent)** | Agent runtime with tool calling and state management |
| **[@mariozechner/pi-coding-agent](packages/coding-agent)** | Interactive coding agent CLI |
| **[@mariozechner/pi-mom](packages/mom)** | Slack bot that delegates messages to the pi coding agent |
| **[@mariozechner/pi-tui](packages/tui)** | Terminal UI library with differential rendering |
| **[@mariozechner/pi-web-ui](packages/web-ui)** | Web components for AI chat interfaces |
| **[@mariozechner/pi-pods](packages/pods)** | CLI for managing vLLM deployments on GPU pods |

## Development

### Setup

```bash
npm install          # Install all dependencies
npm run build        # Build all packages
npm run check        # Lint, format, and type check
```

&gt; **Note:** `npm run check` requires `npm run build` to be run first. The web-ui package uses `tsc` which needs compiled `.d.ts` files from dependencies.

### CI

GitHub Actions runs on push to `main` and on pull requests. The workflow runs `npm run check` and `npm run test` for each package in parallel.

**Do not add LLM API keys as secrets to this repository.** Tests that require LLM access use `describe.skipIf()` to skip when API keys are missing. This is intentional:

- PRs from external contributors would have access to secrets in the CI environment
- Malicious PR code could exfiltrate API keys
- Tests that need LLM calls are skipped on CI and run locally by developers who have keys configured

If you need to run LLM-dependent tests, run them locally with your own API keys.

### Development

Start watch builds for all packages:
```bash
npm run dev
```

Then run with tsx:
```bash
cd packages/coding-agent &amp;&amp; npx tsx src/cli.ts
cd packages/pods &amp;&amp; npx tsx src/cli.ts
```

To run tests that don&#039;t require an LLM endpoint:
```bash
./test.sh
```

### Versioning (Lockstep)

**All packages MUST always have the same version number.** Use these commands to bump versions:

```bash
npm run version:patch    # 0.7.5 -&gt; 0.7.6
npm run version:minor    # 0.7.5 -&gt; 0.8.0
npm run version:major    # 0.7.5 -&gt; 1.0.0
```

These commands:
1. Update all package versions to the same number
2. Update inter-package dependency versions (e.g., `pi-agent` depends on `pi-ai@^0.7.7`)
3. Update `package-lock.json`

**Never manually edit version numbers.** The lockstep system ensures consistency across the monorepo.

### Publishing

```bash
npm run release:patch    # Bug fixes
npm run release:minor    # New features
npm run release:major    # Breaking changes
```

This handles version bump, CHANGELOG updates, commit, tag, publish, and push.

**NPM Token Setup**: Requires a granular access token with &quot;Bypass 2FA on publish&quot; enabled.
- Go to https://www.npmjs.com/settings/badlogic/tokens/
- Create a new &quot;Granular Access Token&quot; with &quot;Bypass 2FA on publish&quot;
- Set the token: `npm config set //registry.npmjs.org/:_authToken=YOUR_TOKEN`

## License

MIT</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[anomalyco/opencode]]></title>
            <link>https://github.com/anomalyco/opencode</link>
            <guid>https://github.com/anomalyco/opencode</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:27 GMT</pubDate>
            <description><![CDATA[The open source coding agent.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anomalyco/opencode">anomalyco/opencode</a></h1>
            <p>The open source coding agent.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 69,250</p>
            <p>Forks: 6,011</p>
            <p>Stars today: 2,396 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencode.ai&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;packages/console/app/src/asset/logo-ornate-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;packages/console/app/src/asset/logo-ornate-light.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;packages/console/app/src/asset/logo-ornate-light.svg&quot; alt=&quot;OpenCode logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;The open source AI coding agent.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencode.ai/discord&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;label=discord&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/opencode-ai&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/opencode-ai?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/anomalyco/opencode/actions/workflows/publish.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/anomalyco/opencode/publish.yml?style=flat-square&amp;branch=dev&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

[![OpenCode Terminal UI](packages/web/src/assets/lander/screenshot.png)](https://opencode.ai)

---

### Installation

```bash
# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
scoop bucket add extras; scoop install extras/opencode  # Windows
choco install opencode             # Windows
brew install anomalyco/tap/opencode # macOS and Linux (recommended, always up to date)
brew install opencode              # macOS and Linux (official brew formula, updated less)
paru -S opencode-bin               # Arch Linux
mise use -g opencode               # Any OS
nix run nixpkgs#opencode           # or github:anomalyco/opencode for latest dev branch
```

&gt; [!TIP]
&gt; Remove versions older than 0.1.x before installing.

### Desktop App (BETA)

OpenCode is also available as a desktop application. Download directly from the [releases page](https://github.com/anomalyco/opencode/releases) or [opencode.ai/download](https://opencode.ai/download).

| Platform              | Download                              |
| --------------------- | ------------------------------------- |
| macOS (Apple Silicon) | `opencode-desktop-darwin-aarch64.dmg` |
| macOS (Intel)         | `opencode-desktop-darwin-x64.dmg`     |
| Windows               | `opencode-desktop-windows-x64.exe`    |
| Linux                 | `.deb`, `.rpm`, or AppImage           |

```bash
# macOS (Homebrew)
brew install --cask opencode-desktop
```

#### Installation Directory

The install script respects the following priority order for the installation path:

1. `$OPENCODE_INSTALL_DIR` - Custom installation directory
2. `$XDG_BIN_DIR` - XDG Base Directory Specification compliant path
3. `$HOME/bin` - Standard user binary directory (if exists or can be created)
4. `$HOME/.opencode/bin` - Default fallback

```bash
# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
```

### Agents

OpenCode includes two built-in agents you can switch between with the `Tab` key.

- **build** - Default, full access agent for development work
- **plan** - Read-only agent for analysis and code exploration
  - Denies file edits by default
  - Asks permission before running bash commands
  - Ideal for exploring unfamiliar codebases or planning changes

Also, included is a **general** subagent for complex searches and multistep tasks.
This is used internally and can be invoked using `@general` in messages.

Learn more about [agents](https://opencode.ai/docs/agents).

### Documentation

For more info on how to configure OpenCode [**head over to our docs**](https://opencode.ai/docs).

### Contributing

If you&#039;re interested in contributing to OpenCode, please read our [contributing docs](./CONTRIBUTING.md) before submitting a pull request.

### Building on OpenCode

If you are working on a project that&#039;s related to OpenCode and is using &quot;opencode&quot; as a part of its name; for example, &quot;opencode-dashboard&quot; or &quot;opencode-mobile&quot;, please add a note to your README to clarify that it is not built by the OpenCode team and is not affiliated with us in any way.

### FAQ

#### How is this different from Claude Code?

It&#039;s very similar to Claude Code in terms of capability. Here are the key differences:

- 100% open source
- Not coupled to any provider. Although we recommend the models we provide through [OpenCode Zen](https://opencode.ai/zen); OpenCode can be used with Claude, OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.
- Out of the box LSP support
- A focus on TUI. OpenCode is built by neovim users and the creators of [terminal.shop](https://terminal.shop); we are going to push the limits of what&#039;s possible in the terminal.
- A client/server architecture. This for example can allow OpenCode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.

---

**Join our community** [Discord](https://discord.gg/opencode) | [X.com](https://x.com/opencode)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[stan-smith/FossFLOW]]></title>
            <link>https://github.com/stan-smith/FossFLOW</link>
            <guid>https://github.com/stan-smith/FossFLOW</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:26 GMT</pubDate>
            <description><![CDATA[Make beautiful isometric infrastructure diagrams]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stan-smith/FossFLOW">stan-smith/FossFLOW</a></h1>
            <p>Make beautiful isometric infrastructure diagrams</p>
            <p>Language: TypeScript</p>
            <p>Stars: 16,311</p>
            <p>Forks: 1,051</p>
            <p>Stars today: 167 stars today</p>
            <h2>README</h2><pre># FossFLOW - Isometric Diagramming Tool &lt;img width=&quot;30&quot; height=&quot;30&quot; alt=&quot;fossflow&quot; src=&quot;https://github.com/user-attachments/assets/56d78887-601c-4336-ab87-76f8ee4cde96&quot; /&gt;

&lt;p align=&quot;center&quot;&gt;
 &lt;a href=&quot;README.md&quot;&gt;English&lt;/a&gt; | &lt;a href=&quot;docs/README.cn.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href=&quot;docs/README.es.md&quot;&gt;Espa√±ol&lt;/a&gt; | &lt;a href=&quot;docs/README.pt.md&quot;&gt;Portugu√™s&lt;/a&gt; | &lt;a href=&quot;docs/README.fr.md&quot;&gt;Fran√ßais&lt;/a&gt; | &lt;a href=&quot;docs/README.hi.md&quot;&gt;‡§π‡§ø‡§®‡•ç‡§¶‡•Ä&lt;/a&gt; | &lt;a href=&quot;docs/README.bn.md&quot;&gt;‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt; | &lt;a href=&quot;docs/README.ru.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href=&quot;docs/README.id.md&quot;&gt;Bahasa Indonesia&lt;/a&gt; | &lt;a href=&quot;docs/README.de.md&quot;&gt;Deutsch&lt;/a&gt;
&lt;/p&gt;


&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/15118&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15118&quot; alt=&quot;stan-smith%2FFossFLOW | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;b&gt;Hey!&lt;/b&gt; Stan here, if you&#039;ve used FossFLOW and it&#039;s helped you, &lt;b&gt;I&#039;d really appreciate if you could donate something small :)&lt;/b&gt; I work full time, and finding the time to work on this project is challenging enough.
If you&#039;ve had a feature that I&#039;ve implemented for you, or fixed a bug it&#039;d be great if you could :) if not, that&#039;s not a problem, this software will always remain free!


&lt;b&gt;Also!&lt;/b&gt; If you haven&#039;t yet, please check out the underlying library this is built on by &lt;a href=&quot;https://github.com/markmanx/isoflow&quot;&gt;@markmanx&lt;/a&gt; I truly stand on the shoulders of a giant here ü´°

[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/P5P61KBXA3)

&lt;a href=&quot;https://www.buymeacoffee.com/stan.smith&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://cdn.buymeacoffee.com/buttons/default-orange.png&quot; alt=&quot;Buy Me A Coffee&quot; height=&quot;41&quot; width=&quot;174&quot;&gt;&lt;/a&gt;

Thanks,

-Stan

## Try it online
&lt;p align=&quot;center&quot;&gt;
Go to  &lt;b&gt; --&gt; https://stan-smith.github.io/FossFLOW/ &lt;-- &lt;/b&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;

 &lt;a href=&quot;https://github.com/stan-smith/SlingShot&quot;&gt;
  Check out my latest project: &lt;b&gt;SlingShot&lt;/b&gt; - Dead easy video streaming over QUIC
 &lt;/a&gt;
&lt;/p&gt;

------------------------------------------------------------------------------------------------------------------------------
FossFLOW is a powerful, open-source Progressive Web App (PWA) for creating beautiful isometric diagrams. Built with React and the &lt;a href=&quot;https://github.com/markmanx/isoflow&quot;&gt;Isoflow&lt;/a&gt; (Now forked and published to NPM as fossflow) library, it runs entirely in your browser with offline support.

![Screenshot_20250630_160954](https://github.com/user-attachments/assets/e7f254ad-625f-4b8a-8efc-5293b5be9d55)

- **üìù [FOSSFLOW_TODO.md](https://github.com/stan-smith/FossFLOW/blob/master/FOSSFLOW_TODO.md)** - Current issues and roadmap with codebase mappings, most gripes are with the isoflow library itself.
- **ü§ù [CONTRIBUTING.md](https://github.com/stan-smith/FossFLOW/blob/master/CONTRIBUTING.md)** - How to contribute to the project.

### Performance updates
 - **Reduced frame refresh delay, should look much smoother now**

### Multilingual Support
- **9 Languages Supported** - Full interface translation in English, Chinese (Simplified), Spanish, Portuguese (Brazilian), French, Hindi, Bengali, Russian, and Indonesian
- **Language Selector** - Easy-to-use language switcher in the app header
- **Complete Translation** - All menus, dialogs, settings, tooltips, and help content translated
- **Locale-Aware** - Automatically detects and remembers your language preference

### Improved Connector Tool
- **Click-based Creation** - New default mode: click first node, then second node to connect
- **Drag Mode Option** - Original drag-and-drop still available via settings
- **Mode Selection** - Switch between click and drag modes in Settings ‚Üí Connectors tab
- **Better Reliability** - Click mode provides more predictable connection creation


## üê≥ Quick Deploy with Docker

```bash
# Using Docker Compose (recommended - includes persistent storage)
docker compose up

# Or run directly from Docker Hub with persistent storage
docker run -p 80:80 -v $(pwd)/diagrams:/data/diagrams stnsmith/fossflow:latest
```

Server storage is enabled by default in Docker. Your diagrams will be saved to `./diagrams` on the host.

To disable server storage, set `ENABLE_SERVER_STORAGE=false`:
```bash
docker run -p 80:80 -e ENABLE_SERVER_STORAGE=false stnsmith/fossflow:latest
```

## Quick Start (Local Development)

```bash
# Clone the repository
git clone https://github.com/stan-smith/FossFLOW
cd FossFLOW

# Install dependencies
npm install

# Build the library (required first time)
npm run build:lib

# Start development server
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

## Monorepo Structure

This is a monorepo containing two packages:

- `packages/fossflow-lib` - React component library for drawing network diagrams (built with Webpack)
- `packages/fossflow-app` - Progressive Web App which wraps the lib and presents it (built with RSBuild)

### Development Commands

```bash
# Development
npm run dev          # Start app development server
npm run dev:lib      # Watch mode for library development

# Building
npm run build        # Build both library and app
npm run build:lib    # Build library only
npm run build:app    # Build app only

# Testing &amp; Linting
npm test             # Run unit tests
npm run lint         # Check for linting errors

# E2E Tests (Selenium)
cd e2e-tests
./run-tests.sh       # Run end-to-end tests (requires Docker &amp; Python)

# Publishing
npm run publish:lib  # Publish library to npm
```

## How to Use

### Creating Diagrams

1. **Add Items**:
   - Press the &quot;+&quot; button on the top right menu, the library of components will appear on the left
   - Drag and drop components from the library onto the canvas
   - Or right-click on the grid and select &quot;Add node&quot;

2. **Connect Items**: 
   - Select the Connector tool (press &#039;C&#039; or click connector icon)
   - **Click mode** (default): Click first node, then click second node
   - **Drag mode** (optional): Click and drag from first to second node
   - Switch modes in Settings ‚Üí Connectors tab

3. **Save Your Work**:
   - **Quick Save** - Saves to browser session
   - **Export** - Download as JSON file
   - **Import** - Load from JSON file

### Storage Options

- **Session Storage**: Temporary saves cleared when browser closes
- **Export/Import**: Permanent storage as JSON files
- **Auto-Save**: Automatically saves changes every 5 seconds to session

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## Documentation

- [FOSSFLOW_ENCYCLOPEDIA.md](FOSSFLOW_ENCYCLOPEDIA.md) - Comprehensive guide to the codebase
- [FOSSFLOW_TODO.md](FOSSFLOW_TODO.md) - Current issues and roadmap
- [CONTRIBUTING.md](CONTRIBUTING.md) - Contributing guidelines

## License

MIT
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[open-metadata/OpenMetadata]]></title>
            <link>https://github.com/open-metadata/OpenMetadata</link>
            <guid>https://github.com/open-metadata/OpenMetadata</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:25 GMT</pubDate>
            <description><![CDATA[OpenMetadata is a unified metadata platform for data discovery, data observability, and data governance powered by a central metadata repository, in-depth column level lineage, and seamless team collaboration.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-metadata/OpenMetadata">open-metadata/OpenMetadata</a></h1>
            <p>OpenMetadata is a unified metadata platform for data discovery, data observability, and data governance powered by a central metadata repository, in-depth column level lineage, and seamless team collaboration.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 8,427</p>
            <p>Forks: 1,591</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://open-metadata.org&quot;&gt;
        &lt;img alt=&quot;Logo&quot; src=&quot;https://github.com/open-metadata/OpenMetadata/assets/40225091/e794ced8-7220-4393-8efc-3faf93bfb503&quot; width=&quot;49%&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Empower your Data Journey with OpenMetadata&lt;/b&gt;&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    
![Commit Activity](https://img.shields.io/github/commit-activity/m/open-metadata/OpenMetadata?style=for-the-badge)
[![Release](https://img.shields.io/github/release/open-metadata/OpenMetadata/all.svg?style=for-the-badge)](https://github.com/open-metadata/OpenMetadata/releases)

&lt;/div&gt;

## What is OpenMetadata?
[OpenMetadata](https://open-metadata.org/)  is a unified metadata platform for data discovery, data observability, and data governance powered by a central metadata repository, in-depth column-level lineage, and seamless team collaboration. It is one of the fastest-growing open-source projects with a vibrant community and adoption by a diverse set of companies in a variety of industry verticals. Based on Open Metadata Standards and APIs, supporting connectors to a wide range of data services, OpenMetadata enables end-to-end metadata management, giving you the freedom to unlock the value of your data assets.
&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/open-metadata/OpenMetadata/assets/40225091/ebfb4ec5-f0a2-4d58-8ce5-a082b5cf0f76&quot; width=800&gt;
&lt;/div&gt;

&lt;br /&gt;
Contents:

- [Features](#key-features-of-openmetadata)
- [Try our Sandbox](#try-our-sandbox)
- [Install &amp; Run](#install-and-run-openmetadata)
- [Roadmap](https://docs.open-metadata.org/latest/roadmap)
- [Documentation and Support](#documentation-and-support)
- [Contributors](#contributors)

OpenMetadata Consists of Four Main Components:
- **Metadata Schemas**: These are the core definitions and vocabulary for metadata based on common abstractions and types. They also allow for custom extensions and properties to suit different use cases and domains.
- **Metadata Store**: This is the central repository for storing and managing the metadata graph, which connects data assets, users, and tool-generated metadata in a unified way.
- **Metadata APIs**: These are the interfaces for producing and consuming metadata, built on top of the metadata schemas. They enable seamless integration of user interfaces and tools, systems, and services with the metadata store.
- **Ingestion Framework**: This is a pluggable framework for ingesting metadata from various sources and tools to the metadata store. It supports about 84+ connectors for data warehouses, databases, dashboard services, messaging services, pipeline services, and more.

## Key Features of OpenMetadata
**Data Discovery**: Find and explore all your data assets in a single place using various strategies, such as keyword search, data associations, and advanced queries. You can search across tables, topics, dashboards, pipelines, and services.

![12](https://github.com/open-metadata/OpenMetadata/assets/40225091/0dbd2746-c93d-4a47-8d3e-ceb3ae01436f)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Collaboration**: Communicate, converse, and cooperate with other users and teams on data assets. You can get event notifications, send alerts, add announcements, create tasks, and use conversation threads.

![11](https://github.com/open-metadata/OpenMetadata/assets/40225091/7df29e12-8a29-44b7-9466-42474823783f)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Quality and Profiler**: Measure and monitor the quality with **no-code** to build trust in your data. You can define and run data quality tests, group them into test suites, and view the results in an interactive dashboard. With powerful collaboration, make data quality a shared responsibility in your organization.

![8](https://github.com/open-metadata/OpenMetadata/assets/40225091/6b330827-cc2d-4d06-abf0-a4d42ce532ba)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Governance**: Enforce data policies and standards across your organization. You can define data domains and data products, assign owners and stakeholders, and classify data assets using tags and terms. Use powerful automation features to auto-classify your data.

![10](https://github.com/open-metadata/OpenMetadata/assets/40225091/f7384a71-6b58-44ad-983f-e302718ee3f1)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Insights and KPIs**: Use reports and platform analytics to understand how your organization&#039;s data is doing. Data Insights provides a single-pane view of all the key metrics to reflect the state of your data best. Define the Key Performance Indicators (KPIs) and set goals within OpenMetadata to work towards better documentation, ownership, and tiering. Alerts can be set against the KPIs to be received on a specified schedule.

![9](https://github.com/open-metadata/OpenMetadata/assets/40225091/61fc2f65-2436-4fc9-9434-c27ee9b25183)
&lt;br&gt;&lt;br&gt;&lt;br&gt;
**Data Lineage**: Track and visualize the origin and transformation of your data assets end-to-end. You can view column-level lineage, filter queries, and edit lineage manually using a no-code editor.
  
**Data Documentation**: Document your data assets and metadata entities using rich text, images, and links. You can also add comments and annotations and generate data dictionaries and data catalogs.
  
**Data Observability**: Monitor the health and performance of your data assets and pipelines. You can view metrics such as data freshness, data volume, data quality, and data latency. You can also set up alerts and notifications for any anomalies or failures.
  
**Data Security**: Secure your data and metadata using various authentication and authorization mechanisms. You can integrate with different identity providers for single sign-on and define roles and policies for access control.
  
**Webhooks**: Integrate with external applications and services using webhooks. You can register URLs to receive metadata event notifications and integrate with Slack, Microsoft Teams, and Google Chat.
  
**Connectors**: Ingest metadata from various sources and tools using connectors. OpenMetadata supports about 84+ connectors for data warehouses, databases, dashboard services, messaging services, pipeline services, and more.

## Try our Sandbox

Take a look and play with sample data at [http://sandbox.open-metadata.org](http://sandbox.open-metadata.org)

## Install and Run OpenMetadata
Get up and running in a few minutes. See the OpenMetadata documentation for [installation instructions](https://docs.open-metadata.org/quick-start/local-docker-deployment).

## Documentation and Support

We&#039;re here to help and make OpenMetadata even better! Check out [OpenMetadata documentation](https://docs.open-metadata.org/) for a complete description of OpenMetadata&#039;s features. Join our [Slack Community](https://slack.open-metadata.org/) to get in touch with us if you want to chat, need help, or discuss new feature requirements.


## Contributors

We ‚ù§Ô∏è all contributions, big and small! Check out our [CONTRIBUTING](./CONTRIBUTING.md) guide to get started, and let us know how we can help.

Don&#039;t want to miss anything? Give the project a ‚≠ê üöÄ 

A HUGE THANK YOU to all our supporters!

&lt;a href=&quot;https://github.com/open-metadata/OpenMetadata/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=open-metadata/OpenMetadata&amp;max=4000&amp;columns=30&quot; /&gt;
&lt;/a&gt;

## Stargazers

[![Stargazers of @open-metadata/OpenMetadata repo](http://reporoster.com/stars/open-metadata/OpenMetadata)](https://github.com/open-metadata/OpenMetadata/stargazers)

## License
OpenMetadata is released under [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[moeru-ai/airi]]></title>
            <link>https://github.com/moeru-ai/airi</link>
            <guid>https://github.com/moeru-ai/airi</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:24 GMT</pubDate>
            <description><![CDATA[üíñüß∏ Self hosted, you owned Grok Companion, a container of souls of waifu, cyber livings to bring them into our worlds, wishing to achieve Neuro-sama's altitude. Capable of realtime voice chat, Minecraft, Factorio playing. Web / macOS / Windows supported.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/moeru-ai/airi">moeru-ai/airi</a></h1>
            <p>üíñüß∏ Self hosted, you owned Grok Companion, a container of souls of waifu, cyber livings to bring them into our worlds, wishing to achieve Neuro-sama's altitude. Capable of realtime voice chat, Minecraft, Factorio playing. Web / macOS / Windows supported.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 16,828</p>
            <p>Forks: 1,596</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
  &lt;source
    width=&quot;100%&quot;
    srcset=&quot;./docs/content/public/banner-dark-1280x640.avif&quot;
    media=&quot;(prefers-color-scheme: dark)&quot;
  /&gt;
  &lt;source
    width=&quot;100%&quot;
    srcset=&quot;./docs/content/public/banner-light-1280x640.avif&quot;
    media=&quot;(prefers-color-scheme: light), (prefers-color-scheme: no-preference)&quot;
  /&gt;
  &lt;img width=&quot;250&quot; src=&quot;./docs/content/public/banner-light-1280x640.avif&quot; /&gt;
&lt;/picture&gt;

&lt;h1 align=&quot;center&quot;&gt;Project AIRI&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;Re-creating Neuro-sama, a soul container of AI waifu / virtual characters to bring them into our world.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  [&lt;a href=&quot;https://discord.gg/TgQ3Cu2F7A&quot;&gt;Join Discord Server&lt;/a&gt;] [&lt;a href=&quot;https://airi.moeru.ai&quot;&gt;Try it&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.zh-CN.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.ja-JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.ru-RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.vi.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] [&lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/docs/README.fr.md&quot;&gt;Fran√ßais&lt;/a&gt;]
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://deepwiki.com/moeru-ai/airi&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/moeru-ai/airi/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/moeru-ai/airi.svg?style=flat&amp;colorA=080f12&amp;colorB=1fa669&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/TgQ3Cu2F7A&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2FTgQ3Cu2F7A%3Fwith_counts%3Dtrue&amp;query=%24.approximate_member_count&amp;suffix=%20members&amp;logo=discord&amp;logoColor=white&amp;label=%20&amp;color=7389D8&amp;labelColor=6A7EC2&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/proj_airi&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%40proj__airi-black?style=flat&amp;logo=x&amp;labelColor=%23101419&amp;color=%232d2e30&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://t.me/+7M_ZKO3zUHFlOThh&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Telegram-%235AA9E6?logo=telegram&amp;labelColor=FFFFFF&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./docs/wechat.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/WeChat-%2307C160?logo=wechat&amp;logoColor=%2307C160&amp;labelColor=FFFFFF&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://qun.qq.com/universal-share/share?ac=1&amp;authKey=9g00d%2BZS7nORzcJugNNddJ7rCghZTIR7fhXabGwch2S%2BG%2BKGIKwlN1N2nIqkh2jg&amp;busi_data=eyJncm91cENvZGUiOiIxMDU4MTU2Njk3IiwidG9rZW4iOiJmcnkra1hWNFIxNytEcG0zcHRUdVJIaldlRDFxN0dzK080QWtvTEdOQjJkNEY2eUFta1g1clNpbkxSMS9FQWFYIiwidWluIjoiMTI2MDkwNzMzNSJ9&amp;data=b1eJrwn3GVOUh7YIxZ7l9vHQo99HPmRxKPpMKlDCmfzx8Y57IXb2EZCMaOC9rVTd2U558qpNjwUYUWlPHxVHvg&amp;svctype=4&amp;tempid=h5_group_info&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/QQ-%2312B7F5?logo=qq&amp;labelColor=FFFFFF&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.producthunt.com/products/airi?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_source=badge-airi&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=993524&amp;theme=neutral&amp;t=1752696535380&quot; alt=&quot;AIRI - A&amp;#0032;container&amp;#0032;of&amp;#0032;cyber&amp;#0032;living&amp;#0032;souls&amp;#0044;&amp;#0032;re&amp;#0045;creation&amp;#0032;of&amp;#0032;Neuro&amp;#0045;sama | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/14636&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14636&quot; alt=&quot;moeru-ai%2Fairi | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; Heavily inspired by [Neuro-sama](https://www.youtube.com/@Neurosama)

&gt; [!WARNING]
&gt; **Attention:** We **do not** have any officially minted cryptocurrency or token associated with this project. Please check the information and proceed with caution.

&gt; [!NOTE]
&gt;
&gt; We&#039;ve got a whole dedicated organization [@proj-airi](https://github.com/proj-airi) for all the sub-projects born from Project AIRI. Check it out!
&gt;
&gt; RAG, memory system, embedded database, icons, Live2D utilities, and more!

&gt; [!TIP]
&gt; We have a translation project on [Crowdin](https://crowdin.com/project/proj-airi). If you find any inaccurate translations, feel free to contribute improvements there.
&gt; &lt;a href=&quot;https://crowdin.com/project/proj-airi&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img style=&quot;width: 140px; height: 40px;&quot; src=&quot;https://badges.crowdin.net/badge/light/crowdin-on-dark.png&quot; srcset=&quot;https://badges.crowdin.net/badge/light/crowdin-on-dark.png 1x, https://badges.crowdin.net/badge/light/crowdin-on-dark@2x.png 2x&quot; alt=&quot;Crowdin | Agile localization for tech companies&quot; width=&quot;140&quot; height=&quot;40&quot; /&gt;&lt;/a&gt;

Have you dreamed about having a cyber living being (cyber waifu, digital pet) or digital companion that could play with and talk to you?

With the power of modern large language models like [ChatGPT](https://chatgpt.com) and famous [Claude](https://claude.ai), asking a virtual being to roleplay and chat with us is already easy enough for everyone. Platforms like [Character.ai (a.k.a. c.ai)](https://character.ai) and [JanitorAI](https://janitorai.com/) as well as local playgrounds like [SillyTavern](https://github.com/SillyTavern/SillyTavern) are already good-enough solutions for a chat based or visual adventure game like experience.

&gt; But, what about the abilities to play games? And see what you are coding at? Chatting while playing games, watching videos, and is capable of doing many other things.

Perhaps you know [Neuro-sama](https://www.youtube.com/@Neurosama) already. She is currently the best virtual streamer capable of playing games, chatting, and interacting with you and the participants. Some also call this kind of being &quot;digital human.&quot; **Sadly, as it&#039;s not open sourced, you cannot interact with her after her live streams go offline**.

Therefore, this project, AIRI, offers another possibility here: **let you own your digital life, cyber living, easily, anywhere, anytime**.

## DevLogs We Posted &amp; Recent Updates

- [DevLog @ 2026.01.01](https://airi.moeru.ai/docs/en/blog/DevLog-2026.01.01/) on January 1, 2026
- [DevLog @ 2025.10.20](https://airi.moeru.ai/docs/en/blog/DevLog-2025.10.20/) on October 20, 2025
- [DevLog @ 2025.08.05](https://airi.moeru.ai/docs/en/blog/DevLog-2025.08.05/) on August 5, 2025
- [DevLog @ 2025.08.01](https://airi.moeru.ai/docs/en/blog/DevLog-2025.08.01/) on August 1, 2025
- [DevLog @ 2025.07.18](https://airi.moeru.ai/docs/en/blog/DevLog-2025.07.18/) on July 18, 2025
- [DreamLog 0x1](https://airi.moeru.ai/docs/en/blog/dreamlog-0x1/) on June 16, 2025
- ...more on [documentation site](https://airi.moeru.ai/docs/en/)

## What&#039;s So Special About This Project?

Unlike the other AI driven VTuber open source projects, „Ç¢„Ç§„É™ was built with support of many Web technologies such as [WebGPU](https://www.w3.org/TR/webgpu/), [WebAudio](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API), [Web Workers](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers), [WebAssembly](https://webassembly.org/), [WebSocket](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket), etc. from the first day.

&gt; [!TIP]
&gt; Worrying about the performance drop since we are using Web related technologies?
&gt;
&gt; Don&#039;t worry, while Web browser version is meant to give an insight about how much we can push and do inside browsers, and webviews, we will never fully rely on this, the desktop version of AIRI is capable of using native [NVIDIA CUDA](https://developer.nvidia.com/cuda-toolkit) and [Apple Metal](https://developer.apple.com/metal/) by default (thanks to HuggingFace &amp; beloved [candle](https://github.com/huggingface/candle) project), without any complex dependency managements, considering the tradeoff, it was partially powered by Web technologies for graphics, layouts, animations, and the WIP plugin systems for everyone to integrate things.

This means that **„Ç¢„Ç§„É™ is capable of running on modern browsers and devices** and even on mobile devices (already done with PWA support). This brings a lot of possibilities for us (the developers) to build and extend the power of „Ç¢„Ç§„É™ VTuber to the next level, while still leaving the flexibilities for users to enable features that requires TCP connections or other non-Web technologies such as connecting to a Discord voice channel or playing Minecraft and Factorio with friends.

&gt; [!NOTE]
&gt;
&gt; We are still in the early stage of development where we are seeking out talented developers to join us and help us to make „Ç¢„Ç§„É™ a reality.
&gt;
&gt; It&#039;s ok if you are not familiar with Vue.js, TypeScript, and devtools required for this project, you can join us as an artist, designer, or even help us to launch our first live stream.
&gt;
&gt; Even if you are a big fan of React, Svelte or even Solid, we welcome you. You can open a sub-directory to add features that you want to see in „Ç¢„Ç§„É™, or would like to experiment with.
&gt;
&gt; Fields (and related projects) that we are looking for:
&gt;
&gt; - Live2D modeller
&gt; - VRM modeller
&gt; - VRChat avatar designer
&gt; - Computer Vision
&gt; - Reinforcement Learning
&gt; - Speech Recognition
&gt; - Speech Synthesis
&gt; - ONNX Runtime
&gt; - Transformers.js
&gt; - vLLM
&gt; - WebGPU
&gt; - Three.js
&gt; - WebXR ([checkout the another project](https://github.com/moeru-ai/chat) we have under the @moeru-ai organization)
&gt;
&gt; **If you are interested, why not introduce yourself here? [Would like to join part of us to build AIRI?](https://github.com/moeru-ai/airi/discussions/33)**

## Current Progress

Capable of

- [x] Brain
  - [x] Play [Minecraft](https://www.minecraft.net)
  - [x] Play [Factorio](https://www.factorio.com) (WIP, but [PoC and demo available](https://github.com/moeru-ai/airi-factorio))
  - [x] Chat in [Telegram](https://telegram.org)
  - [x] Chat in [Discord](https://discord.com)
  - [ ] Memory
    - [x] Pure in-browser database support (DuckDB WASM | `pglite`)
    - [ ] Memory Alaya (WIP)
  - [ ] Pure in-browser local (WebGPU) inference
- [x] Ears
  - [x] Audio input from browser
  - [x] Audio input from [Discord](https://discord.com)
  - [x] Client side speech recognition
  - [x] Client side talking detection
- [x] Mouth
  - [x] [ElevenLabs](https://elevenlabs.io/) voice synthesis
- [x] Body
  - [x] VRM support
    - [x] Control VRM model
  - [x] VRM model animations
    - [x] Auto blink
    - [x] Auto look at
    - [x] Idle eye movement
  - [x] Live2D support
    - [x] Control Live2D model
  - [x] Live2D model animations
    - [x] Auto blink
    - [x] Auto look at
    - [x] Idle eye movement

## Development

&gt; For detailed instructions to develop this project, follow [CONTRIBUTING.md](./.github/CONTRIBUTING.md)

&gt; [!NOTE]
&gt; By default, `pnpm dev` will start the development server for the Stage Web (browser version). If you would
&gt; like to try developing the desktop version, please make sure you read [CONTRIBUTING.md](./.github/CONTRIBUTING.md)
&gt; to setup the environment correctly.

```shell
pnpm i
pnpm dev
```

### Stage Web (Browser Version at [airi.moeru.ai](https://airi.moeru.ai))

```shell
pnpm dev
```

### Stage Tamagotchi (Desktop Version)

```shell
pnpm dev:tamagotchi
```

A Nix package for Tamagotchi is included. To run airi with Nix, first make sure to enable flakes, then run:

```shell
nix run github:moeru-ai/airi
```

### Stage Capacitor (Mobile Version)

Start the development server for the capacitor web version:

```shell
pnpm dev:capacitor
```

Check your IP address in the output of the command above:

```shell
  ROLLDOWN-VITE v7.3.0  ready in 1073 ms

  ‚ûú  Local:   https://localhost:5273/
  ‚ûú  Network: https://&lt;ip-will-be-here&gt;:5273/
  ‚ûú  Vue DevTools: Open https://localhost:5273/__devtools__/ as a separate window
  ‚ûú  Vue DevTools: Press Option(‚å•)+Shift(‚áß)+D in App to toggle the Vue DevTools
  ‚ûú  UnoCSS Inspector: https://localhost:5273/__unocss/
```

Open the Xcode project:

```shell
CAPACITOR_DEV_SERVER_URL=https://&lt;your-ip-address&gt;:5273 pnpm open:ios
```

Then Xcode will open and you can click the &quot;Run&quot; button to run the app on your iPhone.

### Documentation Site

```shell
pnpm dev:docs
```

### Publish

Please update the version in `Cargo.toml` after running `bumpp`:

```shell
npx bumpp --no-commit --no-tag
```

## Support of LLM API Providers (powered by [xsai](https://github.com/moeru-ai/xsai))

- [x] [302.AI (sponsored)](https://share.302.ai/514k2v)
- [x] [OpenRouter](https://openrouter.ai/)
- [x] [vLLM](https://github.com/vllm-project/vllm)
- [x] [SGLang](https://github.com/sgl-project/sglang)
- [x] [Ollama](https://github.com/ollama/ollama)
- [x] [Google Gemini](https://developers.generativeai.google)
- [x] [OpenAI](https://platform.openai.com/docs/guides/gpt/chat-completions-api)
  - [ ] [Azure OpenAI API](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference) (PR welcome)
- [x] [Anthropic Claude](https://anthropic.com)
  - [ ] [AWS Claude](https://docs.anthropic.com/en/api/claude-on-amazon-bedrock) (PR welcome)
- [x] [DeepSeek](https://www.deepseek.com/)
- [x] [Qwen](https://help.aliyun.com/document_detail/2400395.html)
- [x] [xAI](https://x.ai/)
- [x] [Groq](https://wow.groq.com/)
- [x] [Mistral](https://mistral.ai/)
- [x] [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/)
- [x] [Together.ai](https://www.together.ai/)
- [x] [Fireworks.ai](https://www.together.ai/)
- [x] [Novita](https://www.novita.ai/)
- [x] [Zhipu](https://bigmodel.cn)
- [x] [SiliconFlow](https://cloud.siliconflow.cn/i/rKXmRobW)
- [x] [Stepfun](https://platform.stepfun.com/)
- [x] [Baichuan](https://platform.baichuan-ai.com)
- [x] [Minimax](https://api.minimax.chat/)
- [x] [Moonshot AI](https://platform.moonshot.cn/)
- [x] [ModelScope](https://modelscope.cn/docs/model-service/API-Inference/intro)
- [x] [Player2](https://player2.game/)
- [x] [Tencent Cloud](https://cloud.tencent.com/document/product/1729)
- [ ] [Sparks](https://www.xfyun.cn/doc/spark/Web.html) (PR welcome)
- [ ] [Volcano Engine](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;ac=DSASUQY5&amp;rc=2QXCA1VI) (PR welcome)

## Sub-projects Born from This Project

- [Awesome AI VTuber](https://github.com/proj-airi/awesome-ai-vtuber): A curated list of AI VTubers and related projects
- [`unspeech`](https://github.com/moeru-ai/unspeech): Universal endpoint proxy server for `/audio/transcriptions` and `/audio/speech`, like LiteLLM but for any ASR and TTS
- [`hfup`](https://github.com/moeru-ai/hfup): tools to help on deploying, bundling to HuggingFace Spaces
- [`xsai-transformers`](https://github.com/moeru-ai/xsai-transformers): Experimental [ü§ó Transformers.js](https://github.com/huggingface/transformers.js) provider for [xsAI](https://github.com/moeru-ai/xsai).
- [WebAI: Realtime Voice Chat](https://github.com/proj-airi/webai-realtime-voice-chat): Full example of implementing ChatGPT&#039;s realtime voice from scratch with VAD + STT + LLM + TTS.
- [`@proj-airi/drizzle-duckdb-wasm`](https://github.com/moeru-ai/airi/tree/main/packages/drizzle-duckdb-wasm/README.md): Drizzle ORM driver for DuckDB WASM
- [`@proj-airi/duckdb-wasm`](https://github.com/moeru-ai/airi/tree/main/packages/duckdb-wasm/README.md): Easy to use wrapper for `@duckdb/duckdb-wasm`
- [`tauri-plugin-mcp`](https://github.com/moeru-ai/airi/blob/main/crates/tauri-plugin-mcp/README.md): A Tauri plugin for interacting with MCP servers.
- [AIRI Factorio](https://github.com/moeru-ai/airi-factorio): Allow AIRI to play Factorio
- [Factorio RCON API](https://github.com/nekomeowww/factorio-rcon-api): RESTful API wrapper for Factorio headless server console
- [`autorio`](https://github.com/moeru-ai/airi-factorio/tree/main/packages/autorio): Factorio automation library
- [`tstl-plugin-reload-factorio-mod`](https://github.com/moeru-ai/airi-factorio/tree/main/packages/tstl-plugin-reload-factorio-mod): Reload Factorio mod when developing
- [Velin](https://github.com/luoling8192/velin): Use Vue SFC and Markdown to write easy to manage stateful prompts for LLM
- [`demodel`](https://github.com/moeru-ai/demodel): Easily boost the speed of pulling your models and datasets from various of inference runtimes.
- [`inventory`](https://github.com/moeru-ai/inventory): Centralized model catalog and default provider configurations backend service
- [MCP Launcher](https://github.com/moeru-ai/mcp-launcher): Easy to use MCP builder &amp; launcher for all possible MCP servers, just like Ollama for models!
- [ü•∫ SAD](https://github.com/moeru-ai/sad): Documentation and notes for self-host and browser running LLMs.

```mermaid
%%{ init: { &#039;flowchart&#039;: { &#039;curve&#039;: &#039;catmullRom&#039; } } }%%

flowchart TD
  Core(&quot;Core&quot;)
  Unspeech(&quot;unspeech&quot;)
  DBDriver(&quot;@proj-airi/drizzle-duckdb-wasm&quot;)
  MemoryDriver(&quot;[WIP] Memory Alaya&quot;)
  DB1(&quot;@proj-airi/duckdb-wasm&quot;)
  SVRT(&quot;@proj-airi/server-runtime&quot;)
  Memory(&quot;Memory&quot;)
  STT(&quot;STT&quot;)
  Stage(&quot;Stage&quot;)
  StageUI(&quot;@proj-airi/stage-ui&quot;)
  UI(&quot;@proj-airi/ui&quot;)

  subgraph AIRI
    DB1 --&gt; DBDriver --&gt; MemoryDriver --&gt; Memory --&gt; Core
    UI --&gt; StageUI --&gt; Stage --&gt; Core
    Core --&gt; STT
    Core --&gt; SVRT
  end

  subgraph UI_Components
    UI --&gt; StageUI
    UITransitions(&quot;@proj-airi/ui-transitions&quot;) --&gt; StageUI
    UILoadingScreens(&quot;@proj-airi/ui-loading-screens&quot;) --&gt; StageUI
    FontCJK(&quot;@proj-airi/font-cjkfonts-allseto&quot;) --&gt; StageUI
    FontXiaolai(&quot;@proj-airi/font-xiaolai&quot;) --&gt; StageUI
  end

  subgraph Apps
    Stage --&gt; StageWeb(&quot;@proj-airi/stage-web&quot;)
    Stage --&gt; StageTamagotchi(&quot;@proj-airi/stage-tamagotchi&quot;)
    Core --&gt; RealtimeAudio(&quot;@proj-airi/realtime-audio&quot;)
    Core --&gt; PromptEngineering(&quot;@proj-airi/playground-prompt-engineering&quot;)
  end

  subgraph Server_Components
    Core --&gt; ServerSDK(&quot;@proj-airi/server-sdk&quot;)
    ServerShared(&quot;@proj-airi/server-shared&quot;) --&gt; SVRT
    ServerShared --&gt; ServerSDK
  end

  STT --&gt;|Speaking| Unspeech
  SVRT --&gt;|Playing Factorio| F_AGENT
  SVRT --&gt;|Playing Minecraft| MC_AGENT

  subgraph Factorio_Agent
    F_AGENT(&quot;Factorio Agent&quot;)
    F_API(&quot;Factorio RCON API&quot;)
    factorio-server(&quot;factorio-server&quot;)
    F_MOD1(&quot;autorio&quot;)

    F_AGENT --&gt; F_API -.-&gt; factorio-server
    F_MOD1 -.-&gt; factorio-server
  end

  subgraph Minecraft_Agent
    MC_AGENT(&quot;Minecraft Agent&quot;)
    Mineflayer(&quot;Mineflayer&quot;)
    minecraft-server(&quot;minecraft-server&quot;)

    MC_AGENT --&gt; Mineflayer -.-&gt; minecraft-server
  end

  XSAI(&quot;xsAI&quot;) --&gt; Core
  XSAI --&gt; F_AGENT
  XSAI --&gt; MC_AGENT

  Core --&gt; TauriMCP(&quot;@proj-airi/tauri-plugin-mcp&quot;)
  Memory_PGVector(&quot;@proj-airi/memory-pgvector&quot;) --&gt; Memory

  style Core fill:#f9d4d4,stroke:#333,stroke-width:1px
  style AIRI fill:#fcf7f7,stroke:#333,stroke-width:1px
  style UI fill:#d4f9d4,stroke:#333,stroke-width:1px
  style Stage fill:#d4f9d4,stroke:#333,stroke-width:1px
  style UI_Components fill:#d4f9d4,stroke:#333,stroke-width:1px
  style Server_Components fill:#d4e6f9,stroke:#333,stroke-width:1px
  style Apps fill:#d4d4f9,stroke:#333,stroke-width:1px
  style Factorio_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px
  style Minecraft_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px

  style DBDriver fill:#f9f9d4,stroke:#333,stroke-width:1px
  style MemoryDriver fill:#f9f9d4,stroke:#333,stroke-width:1px
  style DB1 fill:#f9f9d4,stroke:#333,stroke-width:1px
  style Memory fill:#f9f9d4,stroke:#333,stroke-width:1px
  style Memory_PGVector fill:#f9f9d4,stroke:#333,stroke-width:1px
```

## Similar Projects

### Open sourced ones

- [kimjammer/Neuro: A recreation of Neuro-Sama originally created in 7 days.](https://github.com/kimjammer/Neuro): very well completed implementation.
- [SugarcaneDefender/z-waif](https://github.com/SugarcaneDefender/z-waif): Great at gaming, autonomous, and prompt engineering
- [semperai/amica](https://github.com/semperai/amica/): Great at VRM, WebXR
- [elizaOS/eliza](https://github.com/elizaOS/eliza): Great examples and software engineering on how to integrate agent into various of systems and APIs
- [ardha27/AI-Waifu-Vtuber](https://github.com/ardha27/AI-Waifu-Vtuber): Great about Twitch API integrations
- [InsanityLabs/AIVTuber](https://github.com/InsanityLabs/AIVTuber): Nice UI and UX
- [IRedDragonICY/vixevia](https://github.com/IRedDragonICY/vixevia)
- [t41372/Open-LLM-VTuber](https://github.com/t41372/O

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[blakeblackshear/frigate]]></title>
            <link>https://github.com/blakeblackshear/frigate</link>
            <guid>https://github.com/blakeblackshear/frigate</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:23 GMT</pubDate>
            <description><![CDATA[NVR with realtime local object detection for IP cameras]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/blakeblackshear/frigate">blakeblackshear/frigate</a></h1>
            <p>NVR with realtime local object detection for IP cameras</p>
            <p>Language: TypeScript</p>
            <p>Stars: 29,189</p>
            <p>Forks: 2,723</p>
            <p>Stars today: 340 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img align=&quot;center&quot; alt=&quot;logo&quot; src=&quot;docs/static/img/frigate.png&quot;&gt;
&lt;/p&gt;

# Frigate - NVR With Realtime Object Detection for IP Cameras

&lt;a href=&quot;https://hosted.weblate.org/engage/frigate-nvr/&quot;&gt;
&lt;img src=&quot;https://hosted.weblate.org/widget/frigate-nvr/language-badge.svg&quot; alt=&quot;Translation status&quot; /&gt;
&lt;/a&gt;

\[English\] | [ÁÆÄ‰Ωì‰∏≠Êñá](https://github.com/blakeblackshear/frigate/blob/dev/README_CN.md)

A complete and local NVR designed for [Home Assistant](https://www.home-assistant.io) with AI object detection. Uses OpenCV and Tensorflow to perform realtime object detection locally for IP cameras.

Use of a GPU, Integrated GPU, or AI accelerator such as a [Hailo](https://hailo.ai/) is highly recommended. Dedicated hardware will outperform even the best CPUs with very little overhead.

- Tight integration with Home Assistant via a [custom component](https://github.com/blakeblackshear/frigate-hass-integration)
- Designed to minimize resource use and maximize performance by only looking for objects when and where it is necessary
- Leverages multiprocessing heavily with an emphasis on realtime over processing every frame
- Uses a very low overhead motion detection to determine where to run object detection
- Object detection with TensorFlow runs in separate processes for maximum FPS
- Communicates over MQTT for easy integration into other systems
- Records video with retention settings based on detected objects
- 24/7 recording
- Re-streaming via RTSP to reduce the number of connections to your camera
- WebRTC &amp; MSE support for low-latency live view

## Documentation

View the documentation at https://docs.frigate.video

## Donations

If you would like to make a donation to support development, please use [Github Sponsors](https://github.com/sponsors/blakeblackshear).

## Screenshots

### Live dashboard

&lt;div&gt;
&lt;img width=&quot;800&quot; alt=&quot;Live dashboard&quot; src=&quot;https://github.com/blakeblackshear/frigate/assets/569905/5e713cb9-9db5-41dc-947a-6937c3bc376e&quot;&gt;
&lt;/div&gt;

### Streamlined review workflow

&lt;div&gt;
&lt;img width=&quot;800&quot; alt=&quot;Streamlined review workflow&quot; src=&quot;https://github.com/blakeblackshear/frigate/assets/569905/6fed96e8-3b18-40e5-9ddc-31e6f3c9f2ff&quot;&gt;
&lt;/div&gt;

### Multi-camera scrubbing

&lt;div&gt;
&lt;img width=&quot;800&quot; alt=&quot;Multi-camera scrubbing&quot; src=&quot;https://github.com/blakeblackshear/frigate/assets/569905/d6788a15-0eeb-4427-a8d4-80b93cae3d74&quot;&gt;
&lt;/div&gt;

### Built-in mask and zone editor

&lt;div&gt;
&lt;img width=&quot;800&quot; alt=&quot;Multi-camera scrubbing&quot; src=&quot;https://github.com/blakeblackshear/frigate/assets/569905/d7885fc3-bfe6-452f-b7d0-d957cb3e31f5&quot;&gt;
&lt;/div&gt;

## Translations

We use [Weblate](https://hosted.weblate.org/projects/frigate-nvr/) to support language translations. Contributions are always welcome.

&lt;a href=&quot;https://hosted.weblate.org/engage/frigate-nvr/&quot;&gt;
&lt;img src=&quot;https://hosted.weblate.org/widget/frigate-nvr/multi-auto.svg&quot; alt=&quot;Translation status&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[GitbookIO/gitbook]]></title>
            <link>https://github.com/GitbookIO/gitbook</link>
            <guid>https://github.com/GitbookIO/gitbook</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:22 GMT</pubDate>
            <description><![CDATA[The open source frontend for GitBook doc sites]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GitbookIO/gitbook">GitbookIO/gitbook</a></h1>
            <p>The open source frontend for GitBook doc sites</p>
            <p>Language: TypeScript</p>
            <p>Stars: 28,560</p>
            <p>Forks: 4,021</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;GitBook&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://gitbook.com/docs/&quot;&gt;Docs&lt;/a&gt; - &lt;a href=&quot;https://github.com/GitbookIO/community&quot;&gt;Community&lt;/a&gt; - &lt;a href=&quot;https://developer.gitbook.com/&quot;&gt;Developer Docs&lt;/a&gt; - &lt;a href=&quot;https://changelog.gitbook.com/&quot;&gt;Changelog&lt;/a&gt; - &lt;a href=&quot;https://github.com/GitbookIO/gitbook/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&quot;&gt;Bug reports&lt;/a&gt; - &lt;a href=&quot;https://github.com/orgs/GitbookIO/discussions/categories/feature-requests&quot;&gt;Feature requests&lt;/a&gt; 
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://gitbook.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?message=Documented%20on%20GitBook&amp;logo=gitbook&amp;logoColor=ffffff&amp;label=%20&amp;labelColor=5c5c5c&amp;color=3F89A1&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;#&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Open_Source-‚ù§Ô∏è-FDA599?&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-GNU_GPLv3-F4E28D&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;/.github/CONTRIBUTING.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/gitbookIO/gitbook&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/gitbookIO/gitbook/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/gitbookIO/gitbook&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Welcome to GitBook, the platform for managing technical knowledge for teams.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;This repository contains the open source code used to render GitBook&#039;s published content.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;GitBook Open Published Site&quot; src=&quot;./assets/published-site.png&quot;&gt;
&lt;/p&gt;

## Table of Contents

-   [Getting Started](#getting-started)
-   [Contributing](#contributing)
    -   [Types of contributions](#types-of-contributions)
-   [Licensing](#license)
-   [Acknowledgements](#acknowledgements)
-   [Legacy GitBook](#legacy-gitbook-deprecated)

## Getting Started

To run a local version of this project, please follow these simple steps.

### Prerequisites

- Node.js (Version: &gt;= 22.3)
    - Use nvm for easy Node management
- [Bun](https://bun.sh/) (Version: &gt;=1.2.15)
  - We use a text-based lockfile which isn&#039;t supported below 1.2.15

### Set up

1. Clone the repo into a **public** GitHub repository. If you plan to distribute the code, keep the source code public to comply with GNU GPLv3. To clone in a private repository, acquire a [commercial license](https://www.gitbook.com/pricing).

```
git clone https://github.com/gitbookIO/gitbook.git
```

2. Ensure you are using the project&#039;s version of `node`. Running `nvm use` will change your local version to the correct one.

3. Install the project&#039;s dependencies through Bun.

```
bun install
```

4. Start your local development server.

```
bun dev
```

6. Open a published GitBook space in your web browser, prefixing it with `http://localhost:3000/url`.

examples:

-   http://localhost:3000/url/gitbook.com/docs
-   http://localhost:3000/url/open-source.gitbook.io/midjourney

Any published GitBook site can be accessed through your local development instance, and any updates you make to the codebase will be reflected in your browser.

### CI and testing

All pull-requests will be tested against both visual and performances testing to prevent regressions.

## Fonts and Icons

GitBook Open uses fontawesome. During development, your local environment will use the free version. However, only the pro version will be accepted by CI. If you see the following error:

```
The GitBook icon is missing. It indicates that the dependencies were installed without the correct font-awesome package. These changes have probably been persisted in the Bun lockfile. Read the README for more information.
```

It means that you&#039;ve changed the GBO dependencies and bundled in the free version. Only GitBook staff can help with this - if you&#039;re not on the GitBook team, please ping us in the PR and we&#039;ll help get things moving.

If you are GitBook staff, you&#039;ll need our NPM token in your local environment.

```
.env.local

BUN_NPM_TOKEN=xxx
```

and then reinstall dependencies.

## Contributing

GitBook&#039;s rendering engine is fully open source and built on top of [Next.js](https://nextjs.org/). Head to our [contributing guide](https://github.com/GitbookIO/gitbook/blob/main/.github/CONTRIBUTING.md) to learn more about the workflow on adding your first Pull Request.

### Types of contributions

We encourage you to contribute to GitBook to help us build the best tool for documenting technical knowledge. If you&#039;re looking for some quick ways to contribute, continue reading to learn more about popular contributions.

#### Translations

The GitBook UI is rendered using a set of translation files found in [`packages/gitbook/src/intl/translations`](/packages/gitbook/src/intl/translations/). We welcome all additional translations for the UI.

#### Bugs

Encounter a bug or find an issue you&#039;d like to fix? Helping us fix issues related to GitBook greatly improves the experience for everyone. Head to the issues section of this repository to learn more about the types of bugs you can already help out with.

## Deployment

&gt; [!WARNING]  
&gt; While it is possible to self-host this project, we do not recommend this unless you are certain this option fits your need.
&gt;
&gt; _Looking to add a specific feature in GitBook? Head to our [contributing guide](https://github.com/GitbookIO/gitbook/blob/main/.github/CONTRIBUTING.md) to get started._
&gt;
&gt; Self-hosting this project puts the responsibility of maintaining and merging future updates on **you**. We cannot guarantee support, maintenance, or updates to forked and self-hosted instances of this project.
&gt;
&gt; We want to make it as easy as possible for our community to collaborate and push the future of GitBook, which is why we encourage you to contribute to our product directly instead of creating your own version.

This project allows you to self-host the rendering portion of your GitBook published content. Self-hosting has pros and cons.

On the pro side, you can customize the look and feel of your content, and better embed your documentation in your application.

On the con side, you become responsible for the reliability of your published site, and keeping the renderer up-to-date with the changes made to the GitBook platform.

## License

Distributed under the [GNU GPLv3 License](https://github.com/GitBookIO/gitbook/blob/main/LICENSE).

If you plan to distribute the code, you must make the source code public to comply with the GNU GPLv3. To clone in a private repository, acquire a [commercial license](https://www.gitbook.com/pricing).

See `LICENSE` for more information.

## Badges

&lt;p align=&quot;left&quot;&gt;
  &lt;a href=&quot;https://gitbook.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?message=Documented%20on%20GitBook&amp;logo=gitbook&amp;logoColor=ffffff&amp;label=%20&amp;labelColor=5c5c5c&amp;color=3F89A1&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://gitbook.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?message=Documented%20on%20GitBook&amp;logo=gitbook&amp;logoColor=ffffff&amp;label=%20&amp;labelColor=5c5c5c&amp;color=F4E28D&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://gitbook.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?message=Documented%20on%20GitBook&amp;logo=gitbook&amp;logoColor=ffffff&amp;label=%20&amp;labelColor=5c5c5c&amp;color=FDA599&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

```md
[![GitBook](https://img.shields.io/static/v1?message=Documented%20on%20GitBook&amp;logo=gitbook&amp;logoColor=ffffff&amp;label=%20&amp;labelColor=5c5c5c&amp;color=3F89A1)](https://www.gitbook.com/preview?utm_source=gitbook_readme_badge&amp;utm_medium=organic&amp;utm_campaign=preview_documentation&amp;utm_content=link)
```

```html
&lt;a href=&quot;https://www.gitbook.com/preview?utm_source=gitbook_readme_badge&amp;utm_medium=organic&amp;utm_campaign=preview_documentation&amp;utm_content=link&quot;&gt;
    &lt;img
        src=&quot;https://img.shields.io/static/v1?message=Documented%20on%20GitBook&amp;logo=gitbook&amp;logoColor=ffffff&amp;label=%20&amp;labelColor=5c5c5c&amp;color=3F89A1&quot;
    /&gt;
&lt;/a&gt;
```

## Acknowledgements

GitBook wouldn&#039;t be possible without these projects:

-   [Next.js](https://nextjs.org/)
-   [Bun](https://bun.sh/)
-   [Tailwind CSS](https://tailwindcss.com/)
-   [Framer Motion](https://www.npmjs.com/package/framer-motion)

## Contributors

&lt;a href=&quot;https://github.com/gitbookIO/gitbook/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=gitbookIO/gitbook&quot; /&gt;
&lt;/a&gt;

## Legacy GitBook (Deprecated)

Our previous version of GitBook and it&#039;s CLI tool are now deprecated. You can still view the old repository and it&#039;s commits on this [branch](https://github.com/GitbookIO/gitbook/tree/legacy).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[onlook-dev/onlook]]></title>
            <link>https://github.com/onlook-dev/onlook</link>
            <guid>https://github.com/onlook-dev/onlook</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:21 GMT</pubDate>
            <description><![CDATA[The Cursor for Designers ‚Ä¢ An Open-Source AI-First Design tool ‚Ä¢ Visually build, style, and edit your React App with AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/onlook-dev/onlook">onlook-dev/onlook</a></h1>
            <p>The Cursor for Designers ‚Ä¢ An Open-Source AI-First Design tool ‚Ä¢ Visually build, style, and edit your React App with AI</p>
            <p>Language: TypeScript</p>
            <p>Stars: 24,353</p>
            <p>Forks: 1,792</p>
            <p>Stars today: 366 stars today</p>
            <h2>README</h2><pre>&lt;!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 --&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img width=&quot;800&quot; alt=&quot;header image&quot; src=&quot;assets/web-preview.png&quot;&gt;
&lt;h3 align=&quot;center&quot;&gt;Onlook&lt;/h3&gt;
  &lt;p align=&quot;center&quot;&gt;
    Cursor for Designers
    &lt;br /&gt;
    &lt;a href=&quot;https://docs.onlook.com&quot;&gt;&lt;strong&gt;Explore the docs ¬ª&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
  &lt;/p&gt;
  &lt;p align=&quot;center&quot;&gt;
    üë®‚Äçüíªüë©‚Äçüíªüë®‚Äçüíª
    &lt;a href=&quot;https://www.ycombinator.com/companies/onlook/jobs/e4gHv1n-founding-engineer-fullstack&quot;&gt;We&#039;re hiring engineers in SF!&lt;/a&gt;
    üë©‚Äçüíªüë®‚Äçüíªüë©‚Äçüíª
  &lt;/p&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://youtu.be/RSX_3EaO5eU?feature=shared&quot;&gt;View Demo&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/onlook-dev/onlook/issues/new?labels=bug&amp;template=bug-report---.md&quot;&gt;Report Bug&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/onlook-dev/onlook/issues/new?labels=enhancement&amp;template=feature-request---.md&quot;&gt;Request Feature&lt;/a&gt;
  &lt;/p&gt;
  &lt;!-- PROJECT SHIELDS --&gt;
&lt;!--
*** I&#039;m using markdown &quot;reference style&quot; links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
--&gt;
&lt;!-- [![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![Apache License][license-shield]][license-url] --&gt;

[![Discord][discord-shield]][discord-url]
[![LinkedIn][linkedin-shield]][linkedin-url]
[![Twitter][twitter-shield]][twitter-url]

[‰∏≠Êñá](https://www.readme-i18n.com/onlook-dev/onlook?lang=zh) |
[Espa√±ol](https://www.readme-i18n.com/onlook-dev/onlook?lang=es) |
[Deutsch](https://www.readme-i18n.com/onlook-dev/onlook?lang=de) |
[fran√ßais](https://www.readme-i18n.com/onlook-dev/onlook?lang=fr) |
[Portugu√™s](https://www.readme-i18n.com/onlook-dev/onlook?lang=pt) |
[–†—É—Å—Å–∫–∏–π](https://www.readme-i18n.com/onlook-dev/onlook?lang=ru) |
[Êó•Êú¨Ë™û](https://www.readme-i18n.com/onlook-dev/onlook?lang=ja) |
[ÌïúÍµ≠Ïñ¥](https://www.readme-i18n.com/onlook-dev/onlook?lang=ko)

&lt;/div&gt;

# An Open-Source, Visual-First Code Editor

Craft websites, prototypes, and designs with AI in Next.js + TailwindCSS. Make
edits directly in the browser DOM with a visual editor. Design in realtime with
code. An open-source alternative to Bolt.new, Lovable, V0, Replit Agent, Figma
Make, Webflow, etc.

### üöß üöß üöß Onlook is still under development üöß üöß üöß

We&#039;re actively looking for contributors to help make Onlook for Web an
incredible prompt-to-build experience. Check the
[open issues](https://github.com/onlook-dev/onlook/issues) for a full list of
proposed features (and known issues), and join our
[Discord](https://discord.gg/hERDfFZCsH) to collaborate with hundreds of other
builders.

## What you can do with Onlook:

- [x] Create Next.js app in seconds
  - [x] Start from text or image
  - [x] Use prebuilt templates
  - [ ] Import from Figma
  - [ ] Import from GitHub repo
  - [ ] Make a PR to a GitHub repo
- [x] Visually edit your app
  - [x] Use Figma-like UI
  - [x] Preview your app in real-time
  - [x] Manage brand assets and tokens
  - [x] Create and navigate to Pages
  - [x] Browse layers
  - [x] Manage project Images
  - [x] Detect and use Components ‚Äì _Previously in
        [Onlook Desktop](https://github.com/onlook-dev/desktop)_
  - [ ] Drag-and-drop Components Panel
  - [x] Use Branching to experiment with designs
- [x] Development Tools
  - [x] Real-time code editor
  - [x] Save and restore from checkpoints
  - [x] Run commands via CLI
  - [x] Connect with app marketplace
- [x] Deploy your app in seconds
  - [x] Generate sharable links
  - [x] Link your custom domain    
- [ ] Collaborate with your team
  - [x] Real-time editing
  - [ ] Leave comments
- [ ] Advanced AI capabilities
  - [x] Queue multiple messages at once
  - [ ] Use Images as references and as assets in a project
  - [ ] Setup and use MCPs in projects
  - [ ] Allow Onlook to use itself as a toolcall for branch creation and iteration
- [ ] Advanced project support
  - [ ] Support non-NextJS projects
  - [ ] Support non-Tailwind projects

![Onlook-GitHub-Example](https://github.com/user-attachments/assets/642de37a-72cc-4056-8eb7-8eb42714cdc4)

## Getting Started

Use our [hosted app](https://onlook.com) or
[run locally](https://docs.onlook.com/developers/running-locally).

### Usage

Onlook will run on any Next.js + TailwindCSS project, import your project into
Onlook or start from scratch within the editor.

Use the AI chat to create or edit a project you&#039;re working on. At any time, you
can always right-click an element to open up the exact location of the element
in code.

&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/4ad9f411-b172-4430-81ef-650f4f314666&quot; /&gt;

&lt;br&gt;

Draw-in new divs and re-arrange them within their parent containers by
dragging-and-dropping.

&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;assets/insert-div.png&quot;&gt;

&lt;br&gt;

Preview the code side-by-side with your site design.

&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;assets/code-connect.png&quot;&gt;

&lt;br&gt;

Use Onlook&#039;s editor toolbar to adjust Tailwind styles, directly manipulate
objects, and experiment with layouts.

&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;assets/text-styling.png&quot; /&gt;

## Documentation

For full documentation, visit [docs.onlook.com](https://docs.onlook.com)

To see how to Contribute, visit
[Contributing to Onlook](https://docs.onlook.com/developers) in our docs.

## How it works

&lt;img width=&quot;676&quot; alt=&quot;architecture&quot; src=&quot;assets/architecture.png&quot;&gt;

1. When you create an app, we load the code into a web container
2. The container runs and serves the code
3. Our editor receives the preview link and displays it in an iFrame
4. Our editor reads and indexes the code from the container
5. We instrument the code in order to map elements to their place in code
6. When the element is edited, we edit the element in our iFrame, then in code
7. Our AI chat also has code access and tools to understand and edit the code

This architecture can theoretically scale to any language or framework that
displays DOM elements declaratively (e.g. jsx/tsx/html). We are focused on
making it work well with Next.js and TailwindCSS for now.

For a full walkthrough, check out our
[Architecture Docs](https://docs.onlook.com/developers/architecture).

### Our Tech Stack

#### Front-end

- [Next.js](https://nextjs.org/) - Full stack
- [TailwindCSS](https://tailwindcss.com/) - Styling
- [tRPC](https://trpc.io/) - Server interface

#### Database

- [Supabase](https://supabase.com/) - Auth, Database, Storage
- [Drizzle](https://orm.drizzle.team/) - ORM

#### AI

- [AI SDK](https://ai-sdk.dev/) - LLM client
- [OpenRouter](https://openrouter.ai/) - LLM model provider
- [Morph Fast Apply](https://morphllm.com) - Fast apply model provider
- [Relace](https://relace.ai) - Fast apply model provider

#### Sandbox and hosting

- [CodeSandboxSDK](https://codesandbox.io/docs/sdk) - Dev sandbox
- [Freestyle](https://www.freestyle.sh/) - Hosting

#### Runtime

- [Bun](https://bun.sh/) - Monorepo, runtime, bundler
- [Docker](https://www.docker.com/) - Container management

## Contributing

![image](https://github.com/user-attachments/assets/ecc94303-df23-46ae-87dc-66b040396e0b)

If you have a suggestion that would make this better, please fork the repo and
create a pull request. You can also
[open issues](https://github.com/onlook-dev/onlook/issues).

See the [CONTRIBUTING.md](CONTRIBUTING.md) for instructions and code of conduct.

#### Contributors

&lt;a href=&quot;https://github.com/onlook-dev/onlook/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=onlook-dev/onlook&quot; /&gt;
&lt;/a&gt;

## Contact

![image](https://github.com/user-attachments/assets/60684b68-1925-4550-8efd-51a1509fc953)

- Team: [Discord](https://discord.gg/hERDfFZCsH) -
  [Twitter](https://twitter.com/onlookdev) -
  [LinkedIn](https://www.linkedin.com/company/onlook-dev/) -
  [Email](mailto:contact@onlook.com)
- Project:
  [https://github.com/onlook-dev/onlook](https://github.com/onlook-dev/onlook)
- Website: [https://onlook.com](https://onlook.com)

## License

Distributed under the Apache 2.0 License. See [LICENSE.md](LICENSE.md) for more
information.

&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/onlook-dev/studio.svg?style=for-the-badge
[contributors-url]: https://github.com/onlook-dev/onlook/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/onlook-dev/studio.svg?style=for-the-badge
[forks-url]: https://github.com/onlook-dev/onlook/network/members
[stars-shield]: https://img.shields.io/github/stars/onlook-dev/studio.svg?style=for-the-badge
[stars-url]: https://github.com/onlook-dev/onlook/stargazers
[issues-shield]: https://img.shields.io/github/issues/onlook-dev/studio.svg?style=for-the-badge
[issues-url]: https://github.com/onlook-dev/onlook/issues
[license-shield]: https://img.shields.io/github/license/onlook-dev/studio.svg?style=for-the-badge
[license-url]: https://github.com/onlook-dev/onlook/blob/master/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?logo=linkedin&amp;colorB=555
[linkedin-url]: https://www.linkedin.com/company/onlook-dev
[twitter-shield]: https://img.shields.io/badge/-Twitter-black?logo=x&amp;colorB=555
[twitter-url]: https://x.com/onlookdev
[discord-shield]: https://img.shields.io/badge/-Discord-black?logo=discord&amp;colorB=555
[discord-url]: https://discord.gg/hERDfFZCsH
[React.js]: https://img.shields.io/badge/react-%2320232a.svg?logo=react&amp;logoColor=%2361DAFB
[React-url]: https://reactjs.org/
[TailwindCSS]: https://img.shields.io/badge/tailwindcss-%2338B2AC.svg?logo=tailwind-css&amp;logoColor=white
[Tailwind-url]: https://tailwindcss.com/
[Electron.js]: https://img.shields.io/badge/Electron-191970?logo=Electron&amp;logoColor=white
[Electron-url]: https://www.electronjs.org/
[Vite.js]: https://img.shields.io/badge/vite-%23646CFF.svg?logo=vite&amp;logoColor=white
[Vite-url]: https://vitejs.dev/
[product-screenshot]: assets/brand.png
[weave-shield]: https://img.shields.io/endpoint?url=https%3A%2F%2Fapp.workweave.ai%2Fapi%2Frepository%2Fbadge%2Forg_pWcXBHJo3Li2Te2Y4WkCPA33%2F820087727&amp;cacheSeconds=3600&amp;labelColor=#131313
[weave-url]: https://app.workweave.ai/reports/repository/org_pWcXBHJo3Li2Te2Y4WkCPA33/820087727
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[docmost/docmost]]></title>
            <link>https://github.com/docmost/docmost</link>
            <guid>https://github.com/docmost/docmost</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:20 GMT</pubDate>
            <description><![CDATA[Docmost is an open-source collaborative wiki and documentation software. It is an open-source alternative to Confluence and Notion.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/docmost/docmost">docmost/docmost</a></h1>
            <p>Docmost is an open-source collaborative wiki and documentation software. It is an open-source alternative to Confluence and Notion.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 18,588</p>
            <p>Forks: 1,067</p>
            <p>Stars today: 27 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;h1&gt;&lt;b&gt;Docmost&lt;/b&gt;&lt;/h1&gt;
    &lt;p&gt;
        Open-source collaborative wiki and documentation software.
        &lt;br /&gt;
        &lt;a href=&quot;https://docmost.com&quot;&gt;&lt;strong&gt;Website&lt;/strong&gt;&lt;/a&gt; | 
        &lt;a href=&quot;https://docmost.com/docs&quot;&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt; |
        &lt;a href=&quot;https://twitter.com/DocmostHQ&quot;&gt;&lt;strong&gt;Twitter / X&lt;/strong&gt;&lt;/a&gt;
    &lt;/p&gt;
&lt;/div&gt;
&lt;br /&gt;

## Getting started

To get started with Docmost, please refer to our [documentation](https://docmost.com/docs) or try our [cloud version](https://docmost.com/pricing) .

## Features

- Real-time collaboration
- Diagrams (Draw.io, Excalidraw and Mermaid)
- Spaces
- Permissions management
- Groups
- Comments
- Page history
- Search
- File attachments
- Embeds (Airtable, Loom, Miro and more)
- Translations (10+ languages)

### Screenshots

&lt;p align=&quot;center&quot;&gt;
&lt;img alt=&quot;home&quot; src=&quot;https://docmost.com/screenshots/home.png&quot; width=&quot;70%&quot;&gt;
&lt;img alt=&quot;editor&quot; src=&quot;https://docmost.com/screenshots/editor.png&quot; width=&quot;70%&quot;&gt;
&lt;/p&gt;

### License
Docmost core is licensed under the open-source AGPL 3.0 license.  
Enterprise features are available under an enterprise license (Enterprise Edition).  

All files in the following directories are licensed under the Docmost Enterprise license defined in `packages/ee/License`.
  - apps/server/src/ee
  - apps/client/src/ee
  - packages/ee

### Contributing

See the [development documentation](https://docmost.com/docs/self-hosting/development)

## Thanks
Special thanks to;

&lt;img width=&quot;100&quot; alt=&quot;Crowdin&quot; src=&quot;https://github.com/user-attachments/assets/a6c3d352-e41b-448d-b6cd-3fbca3109f07&quot; /&gt;

[Crowdin](https://crowdin.com/) for providing access to their localization platform.


&lt;img width=&quot;48&quot; alt=&quot;Algolia-mark-square-white&quot; src=&quot;https://github.com/user-attachments/assets/6ccad04a-9589-4965-b6a1-d5cb1f4f9e94&quot; /&gt;

[Algolia](https://www.algolia.com/) for providing full-text search to the docs.

</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>