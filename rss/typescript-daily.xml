<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Sun, 31 Aug 2025 00:05:39 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[activepieces/activepieces]]></title>
            <link>https://github.com/activepieces/activepieces</link>
            <guid>https://github.com/activepieces/activepieces</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:39 GMT</pubDate>
            <description><![CDATA[AI Agents & MCPs & AI Workflow Automation ‚Ä¢ (280+ MCP servers for AI agents) ‚Ä¢ AI Automation / AI Agent with MCPs ‚Ä¢ AI Workflows & AI Agents ‚Ä¢ MCPs for AI Agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/activepieces/activepieces">activepieces/activepieces</a></h1>
            <p>AI Agents & MCPs & AI Workflow Automation ‚Ä¢ (280+ MCP servers for AI agents) ‚Ä¢ AI Automation / AI Agent with MCPs ‚Ä¢ AI Workflows & AI Agents ‚Ä¢ MCPs for AI Agents</p>
            <p>Language: TypeScript</p>
            <p>Stars: 16,650</p>
            <p>Forks: 2,426</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>
&lt;h1 align=&quot;center&quot;&gt;
  &lt;a
    target=&quot;_blank&quot;
    href=&quot;https://activepieces.com&quot;
  &gt;
    &lt;img
      align=&quot;center&quot;
      alt=&quot;Activepieces&quot;
src=&quot;https://github.com/activepieces/activepieces/assets/1812998/76c97441-c285-4480-bc75-30a0c73ed340&quot;
      style=&quot;width:100%;&quot;
    /&gt;
    
  &lt;/a&gt;
&lt;/h1&gt;


&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;/LICENSE&quot; target=&quot;_blank&quot;&gt;&lt;img src=&#039;https://img.shields.io/badge/license-MIT-green?style=for-the-badge&#039; /&gt;&lt;/a&gt;&amp;nbsp;&lt;img src=&#039;https://img.shields.io/github/commit-activity/w/activepieces/activepieces/main?style=for-the-badge&#039; /&gt;&amp;nbsp;&lt;a href=&#039;https://discord.gg/2jUXBKDdP8&#039;&gt;&lt;img src=&#039;https://img.shields.io/discord/966798490984382485?style=for-the-badge&#039; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
   An open source replacement for Zapier
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a
    href=&quot;https://www.activepieces.com/docs&quot;
    target=&quot;_blank&quot;
  &gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;üå™Ô∏è&amp;nbsp;&amp;nbsp;&amp;nbsp;
   &lt;a
    href=&quot;https://www.activepieces.com/docs/developers/overview&quot;
    target=&quot;_blank&quot;
  &gt;&lt;b&gt;Create a Piece&lt;/b&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;üñâ&amp;nbsp;&amp;nbsp;&amp;nbsp;
  &lt;a
    href=&quot;https://www.activepieces.com/docs/install/overview&quot;
    target=&quot;_blank&quot;
  &gt;&lt;b&gt;Deploy&lt;/b&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;üî•&amp;nbsp;&amp;nbsp;&amp;nbsp;
  &lt;a
    href=&quot;https://discord.gg/yvxF5k5AUb&quot;
    target=&quot;_blank&quot;
  &gt;
    &lt;b&gt;Join Discord&lt;/b&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;
&lt;br&gt;

# ü§Ø Welcome to Activepieces

All-in-one AI automation designed to be **extensible** through a **type-safe** pieces framework written in **TypeScript**.
When you contribute pieces to Activepieces they become automatically available as MCP servers that you can use with LLMs through Claude Desktop, Cursor or Windsurf!

&lt;br&gt;
&lt;br&gt;

## üî• Why Activepieces is Different:

- **üíñ Loved by Everyone**: Intuitive interface and great experience for both technical and non-technical users with a quick learning curve.

&lt;img src=&quot;/docs/resources/templates.gif&quot;&gt;

- **üåê Open Ecosystem:** All pieces are open source and available on npmjs.com, **60% of the pieces are contributed by the community**.

- **üõ†Ô∏è Largest open source MCP toolkit**: All our pieces (280+) are available as MCP that you can use with LLMs on Claude Desktop, Cursor or Windsurf.

- **üõ†Ô∏è  Pieces are written in Typescript**: Pieces are npm packages in TypeScript, offering full customization with the best developer experience, including **hot reloading** for **local** piece development on your machine. üòé

&lt;img src=&quot;/docs/resources/create-action.png&quot; alt=&quot;&quot;&gt;

- **ü§ñ AI-First**: Native AI pieces let you experiment with various providers, or create your own agents using our AI SDK, and there is Copilot to help you build flows inside the builder.

- **üè¢ Enterprise-Ready**: Developers set up the tools, and anyone in the organization can use the no-code builder. Full customization from branding to control.

- **üîí Secure by Design**: Self-hosted and network-gapped for maximum security and control over your data.

- **üß† Human in the Loop**: Delay execution for a period of time or require approval. These are just pieces built on top of the piece framework, and you can build many pieces like that. üé®

- **üíª Human Input Interfaces**: Built-in support for human input triggers like &quot;Chat Interface&quot; üí¨ and &quot;Form Interface&quot; üìù



## üõ†Ô∏è  Builder Features:

- [x] Loops
- [x] Branches
- [x] Auto Retries
- [x] HTTP
- [x] Code with **NPM**
- [x] ASK AI in Code Piece (Non technical user can clean data without knowing to code)
- [x] Flows are fully versioned.
- [x] Languages Translations
- [x] Customizable Templates
- [X] 200+ Pieces, check https://www.activepieces.com/pieces

**We release updates frequently. Check the product changelog for the latest features.**


## üîå Create Your Own Piece

Activepieces supports integrations with Google Sheets, OpenAI, Discord, RSS, and over 200 other services. [Check out the full list of supported integrations](https://www.activepieces.com/pieces), which is constantly expanding thanks to our community&#039;s contributions.

As an **open ecosystem**, all integration source code is accessible in our repository. These integrations are versioned and [published](https://www.npmjs.com/search?q=%40activepieces) directly to npmjs.com upon contribution.

You can easily create your own integration using our TypeScript framework. For detailed instructions, please refer to our [Contributor&#039;s Guide](https://www.activepieces.com/docs/contributing/overview).

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;


# License

Activepieces&#039; Community Edition is released as open source under the [MIT license](https://github.com/activepieces/activepieces/blob/main/LICENSE) and enterprise features are released under [Commercial License](https://github.com/activepieces/activepieces/blob/main/packages/ee/LICENSE)


Read more about the feature comparison here https://www.activepieces.com/docs/about/editions
&lt;br&gt;
&lt;br&gt;


# üí≠ Join Our Community

&lt;a href=&quot;https://discord.gg/2jUXBKDdP8&quot; target=&quot;_blank&quot;&gt;
&lt;img src=&quot;https://discordapp.com/api/guilds/966798490984382485/widget.png?style=banner3&quot; alt=&quot;&quot;&gt;
&lt;/a&gt;

&lt;br&gt;
&lt;br&gt;

# üåê Contributions

We welcome contributions big or small and in different directions. The best way to do this is to check this [document](https://www.activepieces.com/docs/contributing/building-pieces/create-action) and we are always up to talk on [our Discord Server](https://discord.gg/2jUXBKDdP8).

## üìö Translations

Not into coding but still interested in contributing? Come join our [Discord](https://discord.gg/2jUXBKDdP8) and visit https://www.activepieces.com/docs/about/i18n for more information.

![fr translation](https://img.shields.io/badge/dynamic/json?color=blue&amp;label=fr&amp;style=for-the-badge&amp;logo=crowdin&amp;query=%24.progress[?(@.data.languageId==%27fr%27)].data.translationProgress&amp;url=https%3A%2F%2Fbadges.awesome-crowdin.com%2Fstats-16093902-626364-update.json)

![it translation](https://img.shields.io/badge/dynamic/json?color=blue&amp;label=it&amp;style=for-the-badge&amp;logo=crowdin&amp;query=%24.progress[?(@.data.languageId==%27it%27)].data.translationProgress&amp;url=https%3A%2F%2Fbadges.awesome-crowdin.com%2Fstats-16093902-626364-update.json)

![de translation](https://img.shields.io/badge/dynamic/json?color=blue&amp;label=de&amp;style=for-the-badge&amp;logo=crowdin&amp;query=%24.progress[?(@.data.languageId==%27de%27)].data.translationProgress&amp;url=https%3A%2F%2Fbadges.awesome-crowdin.com%2Fstats-16093902-626364-update.json)

![ja translation](https://img.shields.io/badge/dynamic/json?color=blue&amp;label=ja&amp;style=for-the-badge&amp;logo=crowdin&amp;query=%24.progress[?(@.data.languageId==%27ja%27)].data.translationProgress&amp;url=https%3A%2F%2Fbadges.awesome-crowdin.com%2Fstats-16093902-626364-update.json)


![pt-BR translation](https://img.shields.io/badge/dynamic/json?color=blue&amp;label=pt-BR&amp;style=for-the-badge&amp;logo=crowdin&amp;query=%24.progress[?(@.data.languageId==%27pt-BR%27)].data.translationProgress&amp;url=https%3A%2F%2Fbadges.awesome-crowdin.com%2Fstats-16093902-626364-update.json)


## ü¶´ Contributors

&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/ShahedAlMashni&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/41443850?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;ShahedAlMashni&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;ShahedAlMashni&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-ShahedAlMashni&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/AbdulTheActivePiecer&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/106555838?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;AbdulTheActivePiecer&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;AbdulTheActivePiecer&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#maintenance-AbdulTheActivePiecer&quot; title=&quot;Maintenance&quot;&gt;üöß&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/khaledmashaly&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/61781545?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Khaled Mashaly&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Khaled Mashaly&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#maintenance-khaledmashaly&quot; title=&quot;Maintenance&quot;&gt;üöß&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/abuaboud&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/1812998?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Mohammed Abu Aboud&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mohammed Abu Aboud&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#maintenance-abuaboud&quot; title=&quot;Maintenance&quot;&gt;üöß&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://aboudzein.github.io&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/12976630?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Abdulrahman Zeineddin&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Abdulrahman Zeineddin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-aboudzein&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/creed983&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/62152944?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;ahmad jaber&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;ahmad jaber&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-creed983&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/ashrafsamhouri&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/97393596?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;ashrafsamhouri&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;ashrafsamhouri&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-ashrafsamhouri&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://steercampaign.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/12627658?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Mohammad Abu Musa&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mohammad Abu Musa&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#projectManagement-mabumusa1&quot; title=&quot;Project Management&quot;&gt;üìÜ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/kanarelo&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/393261?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Mukewa Wekalao&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mukewa Wekalao&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-kanarelo&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://osamahaikal.me/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/72370395?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Osama Abdallah Essa Haikal&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Osama Abdallah Essa Haikal&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-OsamaHaikal&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/M-Arman&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/54455592?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Arman&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Arman&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#security-M-Arman&quot; title=&quot;Security&quot;&gt;üõ°Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/oskarkraemer&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/42745862?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Oskar Kr√§mer&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Oskar Kr√§mer&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/activepieces/activepieces/commits?author=oskarkraemer&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://thibpat.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/494686?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Thibaut Patel&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Thibaut Patel&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#ideas-tpatel&quot; title=&quot;Ideas, Planning, &amp; Feedback&quot;&gt;ü§î&lt;/a&gt; &lt;a href=&quot;#plugin-tpatel&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Applesaucesomer&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/18318905?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Applesaucesomer&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Applesaucesomer&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#ideas-Applesaucesomer&quot; title=&quot;Ideas, Planning, &amp; Feedback&quot;&gt;ü§î&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/crazyTweek&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/6828237?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;crazyTweek&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;crazyTweek&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#ideas-crazyTweek&quot; title=&quot;Ideas, Planning, &amp; Feedback&quot;&gt;ü§î&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://linkedin.com/in/muhammad-tabaza&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/23503983?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Muhammad Tabaza&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Muhammad Tabaza&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-m-tabaza&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://shaypunter.co.uk&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/18310437?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Shay Punter&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Shay Punter&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/activepieces/activepieces/commits?author=ShayPunter&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt; &lt;a href=&quot;#plugin-ShayPunter&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/abaza738&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/50132270?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;abaza738&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;abaza738&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-abaza738&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/jonaboe&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/51358680?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Jona Boeddinghaus&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jona Boeddinghaus&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-jonaboe&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/fomojola&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/264253?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;fomojola&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;fomojola&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/activepieces/activepieces/commits?author=fomojola&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/astorozhevsky&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/11055414?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Alexander Storozhevsky&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Alexander Storozhevsky&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/activepieces/activepieces/commits?author=astorozhevsky&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/J0LGER&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/54769522?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;J0LGER&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;J0LGER&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#security-J0LGER&quot; title=&quot;Security&quot;&gt;üõ°Ô∏è&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://about.me/veverkap&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/22348?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Patrick Veverka&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Patrick Veverka&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/activepieces/activepieces/issues?q=author%3Aveverkap&quot; title=&quot;Bug reports&quot;&gt;üêõ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://berksmbl.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/10000339?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Berk S√ºmb√ºl&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Berk S√ºmb√ºl&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/activepieces/activepieces/commits?author=berksmbl&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Willianwg&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/51550522?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Willian Guedes&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Willian Guedes&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-Willianwg&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/abdullahranginwala&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/19731056?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Abdullah Ranginwala&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Abdullah Ranginwala&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/activepieces/activepieces/commits?author=abdullahranginwala&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/dentych&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/2256372?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Dennis Tychsen&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Dennis Tychsen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-dentych&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/MyWay&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/1765284?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;MyWay&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;MyWay&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-MyWay&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/bibhuty-did-this&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/28416188?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Bibhuti Bhusan Panda&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Bibhuti Bhusan Panda&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-bibhuty-did-this&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/tarunsamanta2k20&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/55488549?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Tarun Samanta&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Tarun Samanta&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/activepieces/activepieces/issues?q=author%3Atarunsamanta2k20&quot; title=&quot;Bug reports&quot;&gt;üêõ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.linkedin.com/in/herman-kudria-10868b207/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/9007211?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Herman Kudria&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Herman Kudria&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-HKudria&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://nulldev.imagefoo.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/66683380?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;[NULL] Dev&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;[NULL] Dev&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-Abdallah-Alwarawreh&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/JanHolger&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/25184957?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Jan Bebendorf&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jan Bebendorf&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-JanHolger&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://blog.nileshtrivedi.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/19304?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Nilesh&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Nilesh&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-nileshtrivedi&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://certopus.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/40790016?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Vraj Gohil&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Vraj Gohil&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-VrajGohil&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/BastienMe&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/71411115?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;BastienMe&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;BastienMe&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#plugin-BastienMe&quot; title=&quot;Plugin/utility libraries&quot;&gt;üîå&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://blog.fosketts.net&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/8627862?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Stephen Foskett&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Stephen Foskett&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/activepieces/activepieces/commits?author=SFoskett&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://ganapati.fr&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/15729117?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Nathan&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Nathan&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/activepieces/activepieces/commits?author=asuri0n&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.n-soft.pl&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/4056319?v=4?s=100&quot; width=&quot;100px;&quot; alt=

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[Canner/WrenAI]]></title>
            <link>https://github.com/Canner/WrenAI</link>
            <guid>https://github.com/Canner/WrenAI</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:38 GMT</pubDate>
            <description><![CDATA[‚ö°Ô∏è GenBI (Generative BI) queries any database in natural language, generates accurate SQL (Text-to-SQL), charts (Text-to-Chart), and AI-powered insights in seconds.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Canner/WrenAI">Canner/WrenAI</a></h1>
            <p>‚ö°Ô∏è GenBI (Generative BI) queries any database in natural language, generates accurate SQL (Text-to-SQL), charts (Text-to-Chart), and AI-powered insights in seconds.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 10,990</p>
            <p>Forks: 1,102</p>
            <p>Stars today: 271 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot; id=&quot;top&quot;&gt;
  &lt;a href=&quot;https://getwren.ai/?utm_source=github&amp;utm_medium=title&amp;utm_campaign=readme&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./misc/wrenai_logo.png&quot;&gt;
      &lt;img src=&quot;./misc/wrenai_logo_white.png&quot; width=&quot;300px&quot;&gt;
    &lt;/picture&gt;
    &lt;h1 align=&quot;center&quot;&gt;Wren AI - Open-Source GenBI Agent&lt;/h1&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;Follow us on X&quot; href=&quot;https://x.com/getwrenai&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/badge/-@getwrenai-blue?style=for-the-badge&amp;logo=x&amp;logoColor=white&amp;labelColor=gray&amp;logoWidth=20&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Releases&quot; href=&quot;https://github.com/canner/WrenAI/releases&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/github/v/release/canner/WrenAI?logo=github&amp;label=GitHub%20Release&amp;color=blue&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;License&quot; href=&quot;https://github.com/Canner/WrenAI/blob/main/LICENSE&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/github/license/canner/WrenAI?color=blue&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://docs.getwren.ai&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/docs-online-brightgreen?style=for-the-badge&quot; alt=&quot;Docs&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Join the community on GitHub&quot; href=&quot;https://discord.gg/5DvshJqG8Z&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/badge/-JOIN%20THE%20COMMUNITY-blue?style=for-the-badge&amp;logo=discord&amp;logoColor=white&amp;labelColor=grey&amp;logoWidth=20&quot;&gt;
  &lt;/a&gt;
  &lt;a aria-label=&quot;Canner&quot; href=&quot;https://cannerdata.com/?utm_source=github&amp;utm_medium=badge&amp;utm_campaign=readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/%F0%9F%A7%A1-Made%20by%20Canner-blue?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/9263&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/9263&quot; alt=&quot;Canner%2FWrenAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; Wren AI is your GenBI Agent, that you can query any database with natural language ‚Üí get accurate SQL(Text-to-SQL), charts(Text-to-Charts) &amp; AI-generated insights in seconds. ‚ö°Ô∏è

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./misc/workflow.png&quot;&gt;
&lt;/p&gt;

## üòç Demos

https://github.com/user-attachments/assets/f9c1cb34-5a95-4580-8890-ec9644da4160

[Watch GenBI Demo](https://github.com/user-attachments/assets/90ad1d35-bb1e-490b-9676-b29863ff090b)

## ü§ñ Features

|                    | What you get | Why it matters |
|--------------------|--------------|----------------|
| **Talk to Your Data** | Ask in any language ‚Üí precise SQL &amp; answers | Slash the SQL learning curveÔªø |
| **GenBI Insights** | AI-written summaries, charts &amp; reports | Decision-ready context in one clickÔªø |
| **Semantic Layer** | MDL models encode schema, metrics, joins | Keeps LLM outputs accurate &amp; governedÔªø |
| **Embed via API**  | Generate queries &amp; charts inside your apps ([API Docs](https://wrenai.readme.io/reference/cloud-getting-started)) | Build custom agents, SaaS features, chatbotsÔªø ([Streamlit Live Demo](https://huggingface.co/spaces/getWrenAI/wrenai-cloud-api-demo)) |

ü§© [Learn more about GenBI](https://getwren.ai/genbi?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme)

## üöÄ Getting Started

Using Wren AI is super simple, you can set it up within 3 minutes, and start to interact with your data!

- Visit our [Install in your local environment](http://docs.getwren.ai/oss/installation?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme).
- Visit the [Usage Guides](https://docs.getwren.ai/oss/guide/connect/overview?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme) to learn more about how to use Wren AI.
- Or just start with [Wren AI Cloud](https://getwren.ai/?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme) our Managed Cloud Service. ([OSS vs. Commercial Plans](https://docs.getwren.ai/oss/overview/cloud_vs_self_host)).

## üèóÔ∏è Architecture

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./misc/how_wrenai_works.png&quot;&gt;
&lt;/p&gt;

üëâ [Learn more about our Design](https://getwren.ai/post/how-we-design-our-semantic-engine-for-llms-the-backbone-of-the-semantic-layer-for-llm-architecture?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme)


## üîå Data Sources

If your data source is not listed here, vote for it in our [GitHub discussion thread](https://github.com/Canner/WrenAI/discussions/327). It will be a valuable input for us to decide on the next supported data sources.
- Athena (Trino)
- Redshift
- BigQuery
- DuckDB
- PostgreSQL
- MySQL
- Microsoft SQL Server
- ClickHouse
- Oracle
- Trino
- Snowflake

## ü§ñ LLM Models

Wren AI supports integration with various Large Language Models (LLMs), including but not limited to:
- OpenAI Models
- Azure OpenAI Models
- DeepSeek Models
- Google AI Studio ‚Äì Gemini Models
- Vertex AI Models (Gemini + Anthropic)
- Bedrock Models
- Anthropic API Models
- Groq Models
- Ollama Models
- Databricks Models

Check [configuration examples here](https://github.com/Canner/WrenAI/tree/main/wren-ai-service/docs/config_examples)!

&gt; [!CAUTION]
&gt; The performance of Wren AI depends significantly on the capabilities of the LLM you choose. We strongly recommend using the most powerful model available for optimal results. Using less capable models may lead to reduced performance, slower response times, or inaccurate outputs.

## üìö Documentation

Visit [Wren AI documentation](https://docs.getwren.ai/oss/overview/introduction?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme) to view the full documentation.

## üì™ Keep Posted?

[Subscribe our blog](https://www.getwren.ai/blog/?utm_source=github&amp;utm_medium=content&amp;utm_campaign=readme) and [Follow our LinkedIn](https://www.linkedin.com/company/wrenai)

## üõ†Ô∏è Contribution

1.	Star ‚≠ê the repo to show support (it really helps).
2.	Open an issue for bugs, ideas, or discussions.
3.	Read [Contribution Guidelines](https://github.com/Canner/WrenAI/blob/main/CONTRIBUTING.md) for setup &amp; PR guidelines.

## ‚≠êÔ∏è Community

- Join 1.3k+ developers in our [Discord](https://discord.gg/5DvshJqG8Z) for real-time help and roadmap previews.
- If there are any issues, please visit [GitHub Issues](https://github.com/Canner/WrenAI/issues).
- Explore our [public roadmap](https://wrenai.notion.site/) to stay updated on upcoming features and improvements!

Please note that our [Code of Conduct](./CODE_OF_CONDUCT.md) applies to all Wren AI community channels. Users are **highly encouraged** to read and adhere to them to avoid repercussions.

## üéâ Our Contributors
&lt;a href=&quot;https://github.com/canner/wrenAI/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=Canner/WrenAI&quot; /&gt;
&lt;/a&gt;

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;#top&quot;&gt;‚¨ÜÔ∏è Back to Top&lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[transformerlab/transformerlab-app]]></title>
            <link>https://github.com/transformerlab/transformerlab-app</link>
            <guid>https://github.com/transformerlab/transformerlab-app</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:37 GMT</pubDate>
            <description><![CDATA[Open Source Application for Advanced LLM + Diffusion Engineering: interact, train, fine-tune, and evaluate large language models on your own computer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/transformerlab/transformerlab-app">transformerlab/transformerlab-app</a></h1>
            <p>Open Source Application for Advanced LLM + Diffusion Engineering: interact, train, fine-tune, and evaluate large language models on your own computer.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 4,147</p>
            <p>Forks: 377</p>
            <p>Stars today: 163 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://transformerlab.ai&quot;&gt;&lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/transformerlab/transformerlab-app/refs/heads/main/assets/Transformer-Lab_Logo_Reverse.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/transformerlab/transformerlab-app/refs/heads/main/assets/Transformer-Lab_Logo.svg&quot;&gt;
    &lt;img alt=&quot;transformer lab logo&quot; src=&quot;https://raw.githubusercontent.com/transformerlab/transformerlab-app/refs/heads/main/assets/Transformer-Lab_Logo.svg&quot; style=&quot;max-width: 650px&quot;&gt;
  &lt;/picture&gt;&lt;/a&gt;

  &lt;p align=&quot;center&quot;&gt;
    100% Open Source Toolkit for Large Language Models: Train, Tune, Chat on your own Machine
    &lt;br /&gt;
    &lt;a href=&quot;https://transformerlab.ai/docs/download/&quot;&gt;&lt;strong&gt;Download&lt;/strong&gt;&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://transformerlab.ai/docs/intro&quot;&gt;&lt;strong&gt;Explore the docs ¬ª&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://youtu.be/tY5TAvKviLo&quot;&gt;View Demo&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/transformerlab/transformerlab-app/issues&quot;&gt;Report Bugs&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/transformerlab/transformerlab-app/issues/new&quot;&gt;Suggest Features&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://discord.gg/transformerlab&quot;&gt;Join Discord&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://twitter.com/transformerlab&quot;&gt;Follow on Twitter&lt;/a&gt;
  &lt;/p&gt;
  &lt;p align=&quot;center&quot;&gt;
   Note: Transformer Lab is actively being developed. Please join our Discord or follow us on Twitter for updates. Questions, feedback and contributions are highly valued!&lt;/p&gt;
&lt;/div&gt;

&lt;!-- ABOUT THE PROJECT --&gt;

## Download Now

[![Download Icon]][Download URL]

## About The Project

![Product Screen Shot](assets/transformerlab-demo-jan2025.gif)

Transformer Lab is an app that allows anyone to experiment with Large Language Models.

## Backed by Mozilla

Transformer Lab is proud to be supported by Mozilla through the &lt;a href=&quot;https://future.mozilla.org/builders/&quot;&gt;Mozilla Builders Program&lt;/a&gt;

&lt;a href=&quot;https://future.mozilla.org/builders/&quot;&gt;
    &lt;img src=&quot;https://transformerlab.ai/img/mozilla-builders-2024.png&quot; alt=&quot;Mozilla Builders Logo&quot; width=300&gt;
&lt;/a&gt;

## Features


Transformer Lab allows you to:

- üíï **One-click Download Hundreds of Popular Models**:
  - DeepSeek, Qwen, Gemma, Phi4, Llama, Mistral, Mixtral, Stable Diffusion, Flux, Command-R, and dozens more
- ‚¨á **Download any LLM, VLM, or Diffusion model from Huggingface**
- üé∂ **Finetune / Train Across Different Hardware**
  - Finetune using MLX on Apple Silicon
  - Finetune using Huggingface on GPU
  - Finetune Diffusion LoRAs on GPU
- ‚öñÔ∏è **RLHF and Preference Optimization**
  - DPO
  - ORPO
  - SIMPO
  - Reward Modeling
- üíª **Work with Models Across Operating Systems**:
  - Windows App
  - MacOS App
  - Linux
- üí¨ **Chat with Models**
  - Chat
  - Completions
  - Visualize Model Architecture
  - Inspect activations &amp; attention for each generated token
  - Preset (Templated) Prompts
  - Chat History
  - Tweak generation parameters
  - Batched Inference
  - Tool Use / Function Calling (in alpha)
- üöÇ **Use Different Inference Engines**
  - MLX on Apple Silicon
  - FastChat
  - vLLM
  - Llama CPP
  - SGLang
- üñºÔ∏è **Support for Image Diffusion Models**
  - Run and experiment with image generation models (e.g., Stable Diffusion, Flux, etc.)
- üßë‚Äçüéì **Evaluate models**
- üìñ **RAG (Retreival Augmented Generation)**
  - Drag and Drop File UI
  - Works on Apple MLX, FastChat, and other engines
- üìì **Build Datasets for Training**
  - Pull from hundreds of common datasets available on HuggingFace
  - Provide your own dataset using drag and drop
- üî¢ **Calculate Embeddings**
- üíÅ **Full REST API**
- üå© **Run in the Cloud**
  - You can run the user interface on your desktop/laptop while the engine runs on a remote or cloud machine
  - Or you can run everything locally on a single machine
- üîÄ **Convert Models Across Platforms**
  - Convert from/to Huggingface, MLX, GGUF
- üîå **Plugin Support**
  - Easily install from a gallery of existing plugins
  - Write your own plugins to extend functionality
- üßë‚Äçüíª **Embedded Monaco Code Editor**
  - Edit plugins and view what&#039;s happening behind the scenes
- üìù **Prompt Editing**
  - Easily edit System Messages or Prompt Templates
- üìú **Inference Logs**
  - While doing inference or RAG, view a log of the raw queries sent to the model

And you can do the above, all through a simple cross-platform GUI.

&lt;!-- GETTING STARTED --&gt;

## Getting Started

&lt;a href=&quot;https://transformerlab.ai/docs/download&quot;&gt;Click here&lt;/a&gt; to download Transformer Lab.

&lt;a href=&quot;https://transformerlab.ai/docs/intro&quot;&gt;Read this page&lt;/a&gt; to learn how to install and use.

### Built With

- [![Electron][Electron]][Electron-url]
- [![React][React.js]][React-url]
- [![HuggingFace][HuggingFace]][HuggingFace-url]

## Developers

### Building from Scratch

To build the app yourself, pull this repo, and follow the steps below:

(Please note that the current build doesn&#039;t work on Node v23 but it works on v22)

```bash
npm install
```

```bash
npm start
```

## Packaging for Production

To package apps for the local platform:

```bash
npm run package
```

&lt;!-- LICENSE --&gt;

## License

Distributed under the AGPL V3 License. See `LICENSE.txt` for more information.

## Reference

If you found Transformer Lab useful in your research or applications, please cite using the following BibTeX:

```
@software{transformerlab,
  author = {Asaria, Ali},
  title = {Transformer Lab: Experiment with Large Language Models},
  month = December,
  year = 2023,
  url = {https://github.com/transformerlab/transformerlab-app}
}
```

&lt;!-- CONTACT --&gt;

## Contact

- [@aliasaria](https://twitter.com/aliasaria) - Ali Asasria
- [@dadmobile](https://github.com/dadmobile) - Tony Salomone

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;

[product-screenshot]: https://transformerlab.ai/assets/images/screenshot01-53ecb8c52338db3c9246cf2ebbbdc40d.png
[React.js]: https://img.shields.io/badge/React-20232A?style=for-the-badge&amp;logo=react&amp;logoColor=61DAFB
[React-url]: https://reactjs.org/
[Electron]: https://img.shields.io/badge/Electron-20232A?style=for-the-badge&amp;logo=electron&amp;logoColor=61DAFB
[Electron-url]: https://www.electronjs.org/
[HuggingFace]: https://img.shields.io/badge/ü§ó_HuggingFace-20232A?style=for-the-badge
[HuggingFace-url]: https://huggingface.co/
[Download Icon]: https://img.shields.io/badge/Download-EF2D5E?style=for-the-badge&amp;logoColor=white&amp;logo=DocuSign
[Download URL]: https://transformerlab.ai/docs/download
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[mercurjs/mercur]]></title>
            <link>https://github.com/mercurjs/mercur</link>
            <guid>https://github.com/mercurjs/mercur</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:36 GMT</pubDate>
            <description><![CDATA[Open-source multi-vendor marketplace platform for B2B & B2C. Built on top of MedusaJS. Create your own custom marketplace. üõçÔ∏è]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mercurjs/mercur">mercurjs/mercur</a></h1>
            <p>Open-source multi-vendor marketplace platform for B2B & B2C. Built on top of MedusaJS. Create your own custom marketplace. üõçÔ∏è</p>
            <p>Language: TypeScript</p>
            <p>Stars: 908</p>
            <p>Forks: 165</p>
            <p>Stars today: 155 stars today</p>
            <h2>README</h2><pre>![Mercur Main Cover](https://cdn.prod.website-files.com/6790aeffc4b432ccaf1b56e5/67a225dc6fa298afc1cc4ae6_Mercur%20Cover.png)

&lt;div align=&quot;center&quot;&gt;
  &lt;h1&gt;Mercur &lt;br&gt; Open Source Marketplace Platform&lt;/h1&gt; 
  &lt;!-- Shields.io Badges --&gt;
  &lt;a href=&quot;https://github.com/mercurjs/mercur/tree/main?tab=MIT-1-ov-file&quot;&gt;
    &lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/license-MIT-blue.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;#&quot;&gt;
    &lt;img alt=&quot;PRs Welcome&quot; src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://rigbyjs.com/#contact&quot;&gt;
    &lt;img alt=&quot;Support&quot; src=&quot;https://img.shields.io/badge/support-contact%20author-blueviolet.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Website Links --&gt;
  &lt;p&gt;
    &lt;a href=&quot;https://mercurjs.com/&quot;&gt;Mercur&lt;/a&gt; |   &lt;a href=&quot;https://docs.mercurjs.com/&quot;&gt;Docs&lt;/a&gt; 
  &lt;/p&gt; 
&lt;/div&gt;

# What is Mercur?

&lt;a href=&quot;https://www.mercurjs.com/&quot;&gt;Mercur&lt;/a&gt; is the first truly limitless open source marketplace platform that combines the simplicity of SaaS with the freedom of open source. Built on [MedusaJS](https://github.com/medusajs/medusa), it empowers businesses to create custom marketplaces without choosing between ownership and ease of use.

Mercur is a platform to start, customize, manage, and scale your marketplace for every business model with a modern technology stack.

## Announcing Mercur 1.0

After months of development, testing, and close collaboration with early adopters, we‚Äôre excited to announce the official release of **Mercur 1.0** - the first truly limitless marketplace platform. Version 1.0 is fully open source and ready to be self-hosted, giving you **full control over infrastructure, customizations, and data**.

With this version, **Mercur is production-ready for B2C marketplaces**. The first complete version includes a vendor system, admin panel, and a fully built B2C Storefront. Read more in **[official release announcement](https://www.mercurjs.com/updates/mercur-1-0-release)**

## Why Choose Mercur?

- Full Ownership: Unlike SaaS platforms, you own your marketplace with no transaction fees or vendor lock-in
- Modern Foundation: Built on MedusaJS, offering a modern tech stack that developers love
- Beautiful by Default: Create stunning storefronts without sacrificing customization

## Power Any Marketplace Model

- Custom B2B Marketplace: Build enterprise-grade platforms with specialized workflows
- Custom B2C Marketplace: Create engaging consumer marketplaces with modern UX
- eCommerce Extension: Transform your store into a marketplace (coming soon)

![Mercur Use Cases](https://cdn.prod.website-files.com/6790aeffc4b432ccaf1b56e5/67b46aa08180d5b8499c6a15_Use-cases.jpg)
&amp;nbsp;

# Ready-to-go marketplace features

&lt;b&gt;Storefronts for Marketplace &lt;/b&gt; &lt;br&gt;
Customizable storefronts designed for B2B and B2C with all elements including browsing and buying products across multiple vendors at once.

Discover &lt;a href=&quot;https://github.com/mercurjs/b2c-marketplace-storefront&quot;&gt;B2C Storefront Repository&lt;/a&gt; - &lt;a href=&quot;https://b2c.mercurjs.com/&quot;&gt;üõçÔ∏è Check demo &lt;/a&gt;

&lt;b&gt;Admin Panel&lt;/b&gt; &lt;br&gt;
Control over whole marketplace: setting product categories, vendors, commissions and rules

&lt;b&gt;Vendor Panel&lt;/b&gt; &lt;br&gt;
A powerful dashboard giving sellers complete control over their products, orders, and store management in one intuitive interface.

Discover &lt;a href=&quot;https://github.com/mercurjs/vendor-panel&quot;&gt;Vendor Panel&lt;/a&gt; - &lt;a href=&quot;https://www.mercurjs.com/contact&quot;&gt; Contact us to get demo &lt;/a&gt;

&lt;b&gt;Integrations&lt;/b&gt; &lt;br&gt;
Built-in integration with Stripe for payments and Resend for communication needs. More integrations coming soon.

![Mercur](https://cdn.prod.website-files.com/6790aeffc4b432ccaf1b56e5/67a1020f202572832c954ead_6b96703adfe74613f85133f83a19b1f0_Fleek%20Tilt%20-%20Readme.png)

&amp;nbsp;

## Quickstart

#### Setup Medusa project

```bash
# Clone the repository
git clone https://github.com/mercurjs/mercur.git

# Change directory
cd mercur

# Install dependencies
yarn install

# Build packages
yarn build

# Go to backend folder
cd apps/backend

# Clone .env.template
cp .env.template .env

# In the .env file replace user, password, address and port parameters in the DATABASE_URL variable with your values
DATABASE_URL=postgres://[user]:[password]@[address]:[port]/$DB_NAME
# For example:
DATABASE_URL=postgres://postgres:postgres@localhost:5432/$DB_NAME

# Setup database and run migrations
yarn medusa db:create &amp;&amp; yarn medusa db:migrate &amp;&amp; yarn run seed

# Create admin user
npx medusa user --email &lt;email&gt; --password &lt;password&gt;

# Go to root folder
cd ../..

# Start Mercur
yarn dev
```

&amp;nbsp;

## Prerequisites

- Node.js v20+
- PostgreSQL
- Git CLI

# Resources

#### Learn more about Mercur

- [Mercur Website](https://www.mercurjs.com/)
- [Mercur Docs](https://docs.mercurjs.com/introduction)

#### Learn more about Medusa

- [Medusa Website](https://www.medusajs.com/)
- [Medusa Docs](https://docs.medusajs.com/v2)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lobehub/lobe-chat]]></title>
            <link>https://github.com/lobehub/lobe-chat</link>
            <guid>https://github.com/lobehub/lobe-chat</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:35 GMT</pubDate>
            <description><![CDATA[ü§Ø Lobe Chat - an open-source, modern design AI chat framework. Supports multiple AI providers (OpenAI / Claude 4 / Gemini / DeepSeek / Ollama / Qwen), Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobe-chat">lobehub/lobe-chat</a></h1>
            <p>ü§Ø Lobe Chat - an open-source, modern design AI chat framework. Supports multiple AI providers (OpenAI / Claude 4 / Gemini / DeepSeek / Ollama / Qwen), Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 65,010</p>
            <p>Forks: 13,472</p>
            <p>Stars today: 51 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# Lobe Chat

An open-source, modern design ChatGPT/LLMs UI/framework.&lt;br/&gt;
Supports speech synthesis, multi-modal, and extensible ([function call][docs-function-call]) plugin system.&lt;br/&gt;
One-click **FREE** deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.

**English** ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md) ¬∑ [Official Site][official-site] ¬∑ [Changelog][changelog] ¬∑ [Documents][docs] ¬∑ [Blog][blog] ¬∑ [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeChat Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Pioneering the new age of thinking and creating. Built for you, the Super Individual.&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url] &lt;br /&gt; &lt;br /&gt; &lt;a href=&quot;https://vercel.com/oss&quot;&gt; &lt;img alt=&quot;Vercel OSS Program&quot; src=&quot;https://vercel.com/oss/program-badge.svg&quot; /&gt; &lt;/a&gt;

![][image-overview]

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [üëãüèª Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [‚ú® Features](#-features)
  - [‚ú® MCP Plugin One-Click Installation](#-mcp-plugin-one-click-installation)
  - [üè™ MCP Marketplace](#-mcp-marketplace)
  - [üñ•Ô∏è Desktop App](#Ô∏è-desktop-app)
  - [üåê Smart Internet Search](#-smart-internet-search)
  - [Chain of Thought](#chain-of-thought)
  - [Branching Conversations](#branching-conversations)
  - [Artifacts Support](#artifacts-support)
  - [File Upload /Knowledge Base](#file-upload-knowledge-base)
  - [Multi-Model Service Provider Support](#multi-model-service-provider-support)
  - [Local Large Language Model (LLM) Support](#local-large-language-model-llm-support)
  - [Model Visual Recognition](#model-visual-recognition)
  - [TTS &amp; STT Voice Conversation](#tts--stt-voice-conversation)
  - [Text to Image Generation](#text-to-image-generation)
  - [Plugin System (Function Calling)](#plugin-system-function-calling)
  - [Agent Market (GPTs)](#agent-market-gpts)
  - [Support Local / Remote Database](#support-local--remote-database)
  - [Support Multi-User Management](#support-multi-user-management)
  - [Progressive Web App (PWA)](#progressive-web-app-pwa)
  - [Mobile Device Adaptation](#mobile-device-adaptation)
  - [Custom Themes](#custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [‚ö°Ô∏è Performance](#Ô∏è-performance)
- [üõ≥ Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [üì¶ Ecosystem](#-ecosystem)
- [üß© Plugins](#-plugins)
- [‚å®Ô∏è Local Development](#Ô∏è-local-development)
- [ü§ù Contributing](#-contributing)
- [‚ù§Ô∏è Sponsor](#Ô∏è-sponsor)
- [üîó More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

## üëãüèª Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![][vercel-shield-badge]][vercel-link]   | No installation or registration necessary! Visit our website to experience it firsthand.                           |
| :---------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link] | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub. |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ ‚≠êÔ∏è

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## ‚ú® Features

Transform your AI experience with LobeChat&#039;s powerful features designed for seamless connectivity, enhanced productivity, and unlimited creativity.

![][image-feat-mcp]

### ‚ú® MCP Plugin One-Click Installation

**Seamlessly Connect Your AI to the World**

Unlock the full potential of your AI by enabling smooth, secure, and dynamic interactions with external tools, data sources, and services. LobeChat&#039;s MCP (Model Context Protocol) plugin system breaks down the barriers between your AI and the digital ecosystem, allowing for unprecedented connectivity and functionality.

Transform your conversations into powerful workflows by connecting to databases, APIs, file systems, and more. Experience the freedom of AI that truly understands and interacts with your world.

[![][back-to-top]](#readme-top)

![][image-feat-mcp-market]

### üè™ MCP Marketplace

**Discover, Connect, Extend**

Browse a growing library of MCP plugins to expand your AI&#039;s capabilities and streamline your workflows effortlessly. Visit [lobehub.com/mcp](https://lobehub.com/mcp) to explore the MCP Marketplace, which offers a curated collection of integrations that enhance your AI&#039;s ability to work with various tools and services.

From productivity tools to development environments, discover new ways to extend your AI&#039;s reach and effectiveness. Connect with the community and find the perfect plugins for your specific needs.

[![][back-to-top]](#readme-top)

![][image-feat-desktop]

### üñ•Ô∏è Desktop App

**Peak Performance, Zero Distractions**

Get the full LobeChat experience without browser limitations‚Äîlightweight, focused, and always ready to go. Our desktop application provides a dedicated environment for your AI interactions, ensuring optimal performance and minimal distractions.

Experience faster response times, better resource management, and a more stable connection to your AI assistant. The desktop app is designed for users who demand the best performance from their AI tools.

[![][back-to-top]](#readme-top)

![][image-feat-web-search]

### üåê Smart Internet Search

**Online Knowledge On Demand**

With real-time internet access, your AI keeps up with the world‚Äînews, data, trends, and more. Stay informed and get the most current information available, enabling your AI to provide accurate and up-to-date responses.

Access live information, verify facts, and explore current events without leaving your conversation. Your AI becomes a gateway to the world&#039;s knowledge, always current and comprehensive.

[![][back-to-top]](#readme-top)

[![][image-feat-cot]][docs-feat-cot]

### [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeChat. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [üìò LobeChat Knowledge Base Launch ‚Äî From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

- **[OpenAI](https://lobechat.com/discover/provider/openai)**: OpenAI is a global leader in artificial intelligence research, with models like the GPT series pushing the frontiers of natural language processing. OpenAI is committed to transforming multiple industries through innovative and efficient AI solutions. Their products demonstrate significant performance and cost-effectiveness, widely used in research, business, and innovative applications.
- **[Ollama](https://lobechat.com/discover/provider/ollama)**: Ollama provides models that cover a wide range of fields, including code generation, mathematical operations, multilingual processing, and conversational interaction, catering to diverse enterprise-level and localized deployment needs.
- **[Anthropic](https://lobechat.com/discover/provider/anthropic)**: Anthropic is a company focused on AI research and development, offering a range of advanced language models such as Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Opus, and Claude 3 Haiku. These models achieve an ideal balance between intelligence, speed, and cost, suitable for various applications from enterprise workloads to rapid-response scenarios. Claude 3.5 Sonnet, as their latest model, has excelled in multiple evaluations while maintaining a high cost-performance ratio.
- **[Bedrock](https://lobechat.com/discover/provider/bedrock)**: Bedrock is a service provided by Amazon AWS, focusing on delivering advanced AI language and visual models for enterprises. Its model family includes Anthropic&#039;s Claude series, Meta&#039;s Llama 3.1 series, and more, offering a range of options from lightweight to high-performance, supporting tasks such as text generation, conversation, and image processing for businesses of varying scales and needs.
- **[Google](https://lobechat.com/discover/provider/google)**: Google&#039;s Gemini series represents its most advanced, versatile AI models, developed by Google DeepMind, designed for multimodal capabilities, supporting seamless understanding and processing of text, code, images, audio, and video. Suitable for various environments from data centers to mobile devices, it significantly enhances the efficiency and applicability of AI models.
- **[DeepSeek](https://lobechat.com/discover/provider/deepseek)**: DeepSeek is a company focused on AI technology research and application, with its latest model DeepSeek-V2.5 integrating general dialogue and code processing capabilities, achieving significant improvements in human preference alignment, writing tasks, and instruction following.
- **[Moonshot](https://lobechat.com/discover/provider/moonshot)**: Moonshot is an open-source platform launched by Beijing Dark Side Technology Co., Ltd., providing various natural language processing models with a wide range of applications, including but not limited to content creation, academic research, intelligent recommendations, and medical diagnosis, supporting long text processing and complex generation tasks.
- **[OpenRouter](https://lobechat.com/discover/provider/openrouter)**: OpenRouter is a service platform providing access to various cutting-edge large model interfaces, supporting OpenAI, Anthropic, LLaMA, and more, suitable for diverse development and application needs. Users can flexibly choose the optimal model and pricing based on their requirements, enhancing the AI experience.
- **[HuggingFace](https://lobechat.com/discover/provider/huggingface)**: The HuggingFace Inference API provides a fast and free way for you to explore thousands of models for various tasks. Whether you are prototyping for a new application or experimenting with the capabilities of machine learning, this API gives you instant access to high-performance models across multiple domains.
- **[Cloudflare Workers AI](https://lobechat.com/discover/provider/cloudflare)**: Run serverless GPU-powered machine learning models on Cloudflare&#039;s global network.

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+32)&lt;/kbd&gt;&lt;/summary&gt;

- **[GitHub](https://lobechat.com/discover/provider/github)**: With GitHub Models, developers can become AI engineers and leverage the industry&#039;s leading AI models.
- **[Novita](https://lobechat.com/discover/provider/novita)**: Novita AI is a platform providing a variety of large language models and AI image generation API services, flexible, reliable, and cost-effective. It supports the latest open-source models like Llama3 and Mistral, offering a comprehensive, user-friendly, and auto-scaling API solution for generative AI application development, suitable for the rapid growth of AI startups.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[302.AI](https://lobechat.com/discover/provider/ai302)**: 302.AI is an on-demand AI application platform offering the most comprehensive AI APIs and online AI applications available on the market.
- **[Together AI](https://lobechat.com/discover/provider/togetherai)**: Together AI is dedicated to achieving leading performance through innovative AI models, offering extensive customization capabilities, including rapid scaling support and intuitive deployment processes to meet various enterprise needs.
- **[Fireworks AI](https://lobechat.com/discover/provider/fireworksai)**: Fireworks AI is a leading provider of advanced language model services, focusing on functional calling and multimodal processing. Its latest model, Firefunction V2, is based on Llama-3, optimized for function calling, conversation, and instruction following. The visual language model FireLLaVA-13B supports mixed input of images and text. Other notable models include the Llama series and Mixtral series, providing efficient multilingual instruction following and generation support.
- **[Groq](https://lobechat.com/discover/provider/groq)**: Groq&#039;s LPU inference engine has excelled in the latest independent large language model (LLM) benchmarks, redefining the standards for AI solutions with its remarkable speed and efficiency. Groq represents instant inference speed, demonstrating strong performance in cloud-based deployments.
- **[Perplexity](https://lobechat.com/discover/provider/perplexity)**: Perplexity is a leading provider of conversational generation models, offering various advanced Llama 3.1 models that support both online and offline applications, particularly suited for complex natural language processing tasks.
- **[Mistral](https://lobechat.com/discover/provider/mistral)**: Mistral provides advanced general, specialized, and research models widely used in complex reasoning, multilingual tasks, and code generation. Through functional calling interfaces, users can integrate custom functionalities for specific applications.
- **[ModelScope](https://lobechat.com/discover/provider/modelscope)**: ModelScope is a model-as-a-service platform launched by Alibaba Cloud, offering a wide range of AI models and inference services.
- **[Ai21Labs](https://lobechat.com/discover/provider/ai21)**: AI21 Labs builds foundational models and AI systems for enterprises, accelerating the application of generative AI in production.
- **[Upstage](https://lobechat.com/discover/provider/upstage)**: Upstage focuses on developing AI models for various business needs, including Solar LLM and document AI, aiming to achieve artificial general intelligence (AGI) for work. It allows for the creation of simple conversational agents through Chat API and supports functional calling, translation, embedding, and domain-specific applications.
- **[xAI (Grok)](https://lobechat.com/discover/provider/xai)**: xAI is a company dedicated to building artificial intelligence to accelerate human scientific discovery. Our mission is to advance our collective understanding of the universe.
- **[Aliyun Bailian](https://lobechat.com/discover/provider/qwen)**: Tongyi Qianwen is a large-scale language model independently developed by Alibaba Cloud, featuring strong natural language understanding and generation capabilities. It can answer various questions, create written content, express opinions, and write code, playing a role in multiple fields.
- **[Wenxin](https://lobechat.com/discover/provider/wenxin)**: An enterprise-level one-stop platform for large model and AI-native application development and services, providing the most comprehensive and user-friendly toolchain for the entire proc

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[openai/openai-realtime-agents]]></title>
            <link>https://github.com/openai/openai-realtime-agents</link>
            <guid>https://github.com/openai/openai-realtime-agents</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[This is a simple demonstration of more advanced, agentic patterns built on top of the Realtime API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/openai-realtime-agents">openai/openai-realtime-agents</a></h1>
            <p>This is a simple demonstration of more advanced, agentic patterns built on top of the Realtime API.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 6,221</p>
            <p>Forks: 904</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># Realtime API Agents Demo

This is a demonstration of more advanced patterns for voice agents, using the OpenAI Realtime API and the OpenAI Agents SDK. 

## About the OpenAI Agents SDK

This project uses the [OpenAI Agents SDK](https://github.com/openai/openai-agents-js), a toolkit for building, managing, and deploying advanced AI agents. The SDK provides:

- A unified interface for defining agent behaviors and tool integrations.
- Built-in support for agent orchestration, state management, and event handling.
- Easy integration with the OpenAI Realtime API for low-latency, streaming interactions.
- Extensible patterns for multi-agent collaboration, handoffs, tool use, and guardrails.

For full documentation, guides, and API references, see the official [OpenAI Agents SDK Documentation](https://github.com/openai/openai-agents-js#readme).

**NOTE:** For a version that does not use the OpenAI Agents SDK, see the [branch without-agents-sdk](https://github.com/openai/openai-realtime-agents/tree/without-agents-sdk).

There are two main patterns demonstrated:
1. **Chat-Supervisor:** A realtime-based chat agent interacts with the user and handles basic tasks, while a more intelligent, text-based supervisor model (e.g., `gpt-4.1`) is used extensively for tool calls and more complex responses. This approach provides an easy onramp and high-quality answers, with a small increase in latency.
2. **Sequential Handoff:** Specialized agents (powered by realtime api) transfer the user between them to handle specific user intents. This is great for customer service, where user intents can be handled sequentially by specialist models that excel in a specific domains. This helps avoid the model having all instructions and tools in a single agent, which can degrade performance.

## Setup

- This is a Next.js typescript app. Install dependencies with `npm i`.
- Add your `OPENAI_API_KEY` to your env. Either add it to your `.bash_profile` or equivalent, or copy `.env.sample` to `.env` and add it there.
- Start the server with `npm run dev`
- Open your browser to [http://localhost:3000](http://localhost:3000). It should default to the `chatSupervisor` Agent Config.
- You can change examples via the &quot;Scenario&quot; dropdown in the top right.

# Agentic Pattern 1: Chat-Supervisor

This is demonstrated in the [chatSupervisor](src/app/agentConfigs/chatSupervisor/index.ts) Agent Config. The chat agent uses the realtime model to converse with the user and handle basic tasks, like greeting the user, casual conversation, and collecting information, and a more intelligent, text-based supervisor model (e.g. `gpt-4.1`) is used extensively to handle tool calls and more challenging responses. You can control the decision boundary by &quot;opting in&quot; specific tasks to the chat agent as desired.

Video walkthrough: [https://x.com/noahmacca/status/1927014156152058075](https://x.com/noahmacca/status/1927014156152058075)

## Example
![Screenshot of the Chat Supervisor Flow](/public/screenshot_chat_supervisor.png)
*In this exchange, note the immediate response to collect the phone number, and the deferral to the supervisor agent to handle the tool call and formulate the response. There ~2s between the end of &quot;give me a moment to check on that.&quot; being spoken aloud and the start of the &quot;Thanks for waiting. Your last bill...&quot;.*

## Schematic
```mermaid
sequenceDiagram
    participant User
    participant ChatAgent as Chat Agent&lt;br/&gt;(gpt-4o-realtime-mini)
    participant Supervisor as Supervisor Agent&lt;br/&gt;(gpt-4.1)
    participant Tool as Tool

    alt Basic chat or info collection
        User-&gt;&gt;ChatAgent: User message
        ChatAgent-&gt;&gt;User: Responds directly
    else Requires higher intelligence and/or tool call
        User-&gt;&gt;ChatAgent: User message
        ChatAgent-&gt;&gt;User: &quot;Let me think&quot;
        ChatAgent-&gt;&gt;Supervisor: Forwards message/context
        alt Tool call needed
            Supervisor-&gt;&gt;Tool: Calls tool
            Tool-&gt;&gt;Supervisor: Returns result
        end
        Supervisor-&gt;&gt;ChatAgent: Returns response
        ChatAgent-&gt;&gt;User: Delivers response
    end
```

## Benefits
- **Simpler onboarding.** If you already have a performant text-based chat agent, you can give that same prompt and set of tools to the supervisor agent, and make some tweaks to the chat agent prompt, you&#039;ll have a natural voice agent that will perform on par with your text agent.
- **Simple ramp to a full realtime agent**: Rather than switching your whole agent to the realtime api, you can move one task at a time, taking time to validate and build trust for each before deploying to production.
- **High intelligence**: You benefit from the high intelligence, excellent tool calling and instruction following of models like `gpt-4.1` in your voice agents.
- **Lower cost**: If your chat agent is only being used for basic tasks, you can use the realtime-mini model, which, even when combined with GPT-4.1, should be cheaper than using the full 4o-realtime model.
- **User experience**: It&#039;s a more natural conversational experience than using a stitched model architecture, where response latency is often 1.5s or longer after a user has finished speaking. In this architecture, the model responds to the user right away, even if it has to lean on the supervisor agent.
  - However, more assistant responses will start with &quot;Let me think&quot;, rather than responding immediately with the full response.

## Modifying for your own agent
1. Update [supervisorAgent](src/app/agentConfigs/chatSupervisorDemo/supervisorAgent.ts).
  - Add your existing text agent prompt and tools if you already have them. This should contain the &quot;meat&quot; of your voice agent logic and be very specific with what it should/shouldn&#039;t do and how exactly it should respond. Add this information below `==== Domain-Specific Agent Instructions ====`.
  - You should likely update this prompt to be more appropriate for voice, for example with instructions to be concise and avoiding long lists of items.
2. Update [chatAgent](src/app/agentConfigs/chatSupervisor/index.ts).
  - Customize the chatAgent instructions with your own tone, greeting, etc.
  - Add your tool definitions to `chatAgentInstructions`. We recommend a brief yaml description rather than json to ensure the model doesn&#039;t get confused and try calling the tool directly.
  - You can modify the decision boundary by adding new items to the `# Allow List of Permitted Actions` section.
3. To reduce cost, try using `gpt-4o-mini-realtime` for the chatAgent and/or `gpt-4.1-mini` for the supervisor model. To maximize intelligence on particularly difficult or high-stakes tasks, consider trading off latency and adding chain-of-thought to your supervisor prompt, or using an additional reasoning model-based supervisor that uses `o4-mini`.

# Agentic Pattern 2: Sequential Handoffs

This pattern is inspired by [OpenAI Swarm](https://github.com/openai/swarm) and involves the sequential handoff of a user between specialized agents. Handoffs are decided by the model and coordinated via tool calls, and possible handoffs are defined explicitly in an agent graph. A handoff triggers a session.update event with new instructions and tools. This pattern is effective for handling a variety of user intents with specialist agents, each of which might have long instructions and numerous tools.

Here&#039;s a [video walkthrough](https://x.com/OpenAIDevs/status/1880306081517432936) showing how it works. You should be able to use this repo to prototype your own multi-agent realtime voice app in less than 20 minutes!

![Screenshot of the Realtime API Agents Demo](/public/screenshot_handoff.png)
*In this simple example, the user is transferred from a greeter agent to a haiku agent. See below for the simple, full configuration of this flow.*

Configuration in `src/app/agentConfigs/simpleExample.ts`
```typescript
import { RealtimeAgent } from &#039;@openai/agents/realtime&#039;;

// Define agents using the OpenAI Agents SDK
export const haikuWriterAgent = new RealtimeAgent({
  name: &#039;haikuWriter&#039;,
  handoffDescription: &#039;Agent that writes haikus.&#039;, // Context for the agent_transfer tool
  instructions:
    &#039;Ask the user for a topic, then reply with a haiku about that topic.&#039;,
  tools: [],
  handoffs: [],
});

export const greeterAgent = new RealtimeAgent({
  name: &#039;greeter&#039;,
  handoffDescription: &#039;Agent that greets the user.&#039;,
  instructions:
    &quot;Please greet the user and ask them if they&#039;d like a haiku. If yes, hand off to the &#039;haikuWriter&#039; agent.&quot;,
  tools: [],
  handoffs: [haikuWriterAgent], // Define which agents this agent can hand off to
});

// An Agent Set is just an array of the agents that participate in the scenario
export default [greeterAgent, haikuWriterAgent];
```
## CustomerServiceRetail Flow

This is a more complex, representative implementation that illustrates a customer service flow, with the following features:
- A more complex agent graph with agents for user authentication, returns, sales, and a placeholder human agent for escalations.
- An escalation by the [returns](https://github.com/openai/openai-realtime-agents/blob/60f4effc50a539b19b2f1fa4c38846086b58c295/src/app/agentConfigs/customerServiceRetail/returns.ts#L233) agent to `o4-mini` to validate and initiate a return, as an example high-stakes decision, using a similar pattern to the above.
- Prompting models to follow a state machine, for example to accurately collect things like names and phone numbers with confirmation character by character to authenticate a user.
  - To test this flow, say that you&#039;d like to return your snowboard and go through the necessary prompts!

Configuration in [src/app/agentConfigs/customerServiceRetail/index.ts](src/app/agentConfigs/customerServiceRetail/index.ts).
```javascript
import authentication from &quot;./authentication&quot;;
import returns from &quot;./returns&quot;;
import sales from &quot;./sales&quot;;
import simulatedHuman from &quot;./simulatedHuman&quot;;
import { injectTransferTools } from &quot;../utils&quot;;

authentication.downstreamAgents = [returns, sales, simulatedHuman];
returns.downstreamAgents = [authentication, sales, simulatedHuman];
sales.downstreamAgents = [authentication, returns, simulatedHuman];
simulatedHuman.downstreamAgents = [authentication, returns, sales];

const agents = injectTransferTools([
  authentication,
  returns,
  sales,
  simulatedHuman,
]);

export default agents;
```

## Schematic

This diagram illustrates a more advanced interaction flow defined in `src/app/agentConfigs/customerServiceRetail/`, including detailed events.

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Show CustomerServiceRetail Flow Diagram&lt;/strong&gt;&lt;/summary&gt;

```mermaid
sequenceDiagram
    participant User
    participant WebClient as Next.js Client
    participant NextAPI as /api/session
    participant RealtimeAPI as OpenAI Realtime API
    participant AgentManager as Agents (authentication, returns, sales, simulatedHuman)
    participant o1mini as &quot;o4-mini&quot; (Escalation Model)

    Note over WebClient: User navigates to ?agentConfig=customerServiceRetail
    User-&gt;&gt;WebClient: Open Page
    WebClient-&gt;&gt;NextAPI: GET /api/session
    NextAPI-&gt;&gt;RealtimeAPI: POST /v1/realtime/sessions
    RealtimeAPI-&gt;&gt;NextAPI: Returns ephemeral session
    NextAPI-&gt;&gt;WebClient: Returns ephemeral token (JSON)

    Note right of WebClient: Start RTC handshake
    WebClient-&gt;&gt;RealtimeAPI: Offer SDP (WebRTC)
    RealtimeAPI-&gt;&gt;WebClient: SDP answer
    WebClient-&gt;&gt;WebClient: DataChannel &quot;oai-events&quot; established

    Note over AgentManager: Default agent is &quot;authentication&quot;
    User-&gt;&gt;WebClient: &quot;Hi, I&#039;d like to return my snowboard.&quot;
    WebClient-&gt;&gt;AgentManager: conversation.item.create (role=user)
    WebClient-&gt;&gt;RealtimeAPI: {type: &quot;conversation.item.create&quot;}
    WebClient-&gt;&gt;RealtimeAPI: {type: &quot;response.create&quot;}

    authentication-&gt;&gt;AgentManager: Requests user info, calls authenticate_user_information()
    AgentManager--&gt;&gt;WebClient: function_call =&gt; name=&quot;authenticate_user_information&quot;
    WebClient-&gt;&gt;WebClient: handleFunctionCall =&gt; verifies details

    Note over AgentManager: After user is authenticated
    authentication-&gt;&gt;AgentManager: transferAgents(&quot;returns&quot;)
    AgentManager--&gt;&gt;WebClient: function_call =&gt; name=&quot;transferAgents&quot; args={ destination: &quot;returns&quot; }
    WebClient-&gt;&gt;WebClient: setSelectedAgentName(&quot;returns&quot;)

    Note over returns: The user wants to process a return
    returns-&gt;&gt;AgentManager: function_call =&gt; checkEligibilityAndPossiblyInitiateReturn
    AgentManager--&gt;&gt;WebClient: function_call =&gt; name=&quot;checkEligibilityAndPossiblyInitiateReturn&quot;

    Note over WebClient: The WebClient calls /api/chat/completions with model=&quot;o4-mini&quot;
    WebClient-&gt;&gt;o1mini: &quot;Is this item eligible for return?&quot;
    o1mini-&gt;&gt;WebClient: &quot;Yes/No (plus notes)&quot;

    Note right of returns: Returns uses the result from &quot;o4-mini&quot;
    returns-&gt;&gt;AgentManager: &quot;Return is approved&quot; or &quot;Return is denied&quot;
    AgentManager-&gt;&gt;WebClient: conversation.item.create (assistant role)
    WebClient-&gt;&gt;User: Displays final verdict
```

&lt;/details&gt;

# Other Info
## Next Steps
- You can copy these templates to make your own multi-agent voice app! Once you make a new agent set config, add it to `src/app/agentConfigs/index.ts` and you should be able to select it in the UI in the &quot;Scenario&quot; dropdown menu.
- Each agentConfig can define instructions, tools, and toolLogic. By default all tool calls simply return `True`, unless you define the toolLogic, which will run your specific tool logic and return an object to the conversation (e.g. for retrieved RAG context).
- If you want help creating your own prompt using the conventions shown in customerServiceRetail, including defining a state machine, we&#039;ve included a metaprompt [here](src/app/agentConfigs/voiceAgentMetaprompt.txt), or you can use our [Voice Agent Metaprompter GPT](https://chatgpt.com/g/g-678865c9fb5c81918fa28699735dd08e-voice-agent-metaprompt-gpt)

## Output Guardrails
Assistant messages are checked for safety and compliance before they are shown in the UI.  The guardrail call now lives directly inside `src/app/App.tsx`: when a `response.text.delta` stream starts we mark the message as **IN_PROGRESS**, and once the server emits `guardrail_tripped` or `response.done` we mark the message as **FAIL** or **PASS** respectively.  If you want to change how moderation is triggered or displayed, search for `guardrail_tripped` inside `App.tsx` and tweak the logic there.

## Navigating the UI
- You can select agent scenarios in the Scenario dropdown, and automatically switch to a specific agent with the Agent dropdown.
- The conversation transcript is on the left, including tool calls, tool call responses, and agent changes. Click to expand non-message elements.
- The event log is on the right, showing both client and server events. Click to see the full payload.
- On the bottom, you can disconnect, toggle between automated voice-activity detection or PTT, turn off audio playback, and toggle logs.

## Pull Requests

Feel free to open an issue or pull request and we&#039;ll do our best to review it. The spirit of this repo is to demonstrate the core logic for new agentic flows; PRs that go beyond this core scope will likely not be merged.

# Core Contributors
- Noah MacCallum - [noahmacca](https://x.com/noahmacca)
- Ilan Bigio - [ibigio](https://github.com/ibigio)
- Brian Fioca - [bfioca](https://github.com/bfioca)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[adobe/react-spectrum]]></title>
            <link>https://github.com/adobe/react-spectrum</link>
            <guid>https://github.com/adobe/react-spectrum</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[A collection of libraries and tools that help you build adaptive, accessible, and robust user experiences.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/adobe/react-spectrum">adobe/react-spectrum</a></h1>
            <p>A collection of libraries and tools that help you build adaptive, accessible, and robust user experiences.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 14,288</p>
            <p>Forks: 1,303</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>#  [React Spectrum Libraries](https://react-spectrum.adobe.com/)

A collection of libraries and tools that help you build adaptive, accessible, and robust user experiences.

### React Spectrum

A React implementation of Spectrum, Adobe‚Äôs design system. Spectrum provides adaptive, accessible, and cohesive experiences for all Adobe applications.

[Explore React Spectrum](https://react-spectrum.adobe.com/react-spectrum/index.html)

### React Aria

A library of unstyled React components and hooks that helps you build accessible, high quality UI components for your application or design system.

[Learn more about React Aria](https://react-spectrum.adobe.com/react-aria/index.html)

### React Stately

A library of React Hooks that provides cross-platform state management for your design system.

[More information about React Stately](https://react-spectrum.adobe.com/react-stately/index.html)

### Internationalized

A collection of framework-agnostic internationalization libraries for the web.

[Internationalized Packages](https://react-spectrum.adobe.com/internationalized/index.html)

## Features

* ‚ôøÔ∏è **[Accessible](https://react-spectrum.adobe.com/react-aria/accessibility.html)** ‚Äì Accessibility and behavior is implemented according to [WAI-ARIA Authoring Practices](https://www.w3.org/TR/wai-aria-practices-1.2/), including full screen reader and keyboard navigation support. All components have been tested across a wide variety of screen readers and devices to ensure the best experience possible for all users.
* üì± **[Adaptive](https://react-spectrum.adobe.com/react-aria/interactions.html)** ‚Äì All components are designed to work with mouse, touch, and keyboard interactions. They‚Äôre built with responsive design principles to deliver a great experience, no matter the device.
* üåç **[International](https://react-spectrum.adobe.com/react-aria/internationalization.html)** ‚Äì Support over 30 languages is included out of the box, including support for right-to-left languages, date and number formatting, and more.
* üé® **[Customizable](https://react-spectrum.adobe.com/react-spectrum/theming.html)** ‚Äì React Spectrum components support custom themes, and automatically adapt for dark mode. For even more customizability, you can build your own components with your own DOM structure and styling using the [React Aria](https://react-spectrum.adobe.com/react-aria/index.html) and [React Stately](https://react-spectrum.adobe.com/react-stately/index.html) hooks to provide behavior, accessibility, and interactions.

## Getting started

React Spectrum includes several libraries, which you can choose depending on your usecase.

* [React Spectrum](https://react-spectrum.adobe.com/react-spectrum/getting-started.html) is an implementation of Adobe&#039;s design system. If you‚Äôre integrating with Adobe software or would like a complete component library to use in your project, look no further!
* [React Aria](https://react-spectrum.adobe.com/react-aria/getting-started.html) is a collection of unstyled React components and hooks that helps you build accessible, high quality UI components for your own application or design system. If you&#039;re building a component library for the web from scratch with your own styling, start here.
* [React Stately](https://react-spectrum.adobe.com/react-stately/getting-started.html) is a library of state management hooks for use in your component library. If you&#039;re using React Aria, you&#039;ll likely also use React Stately, but it can also be used independently (e.g. on other platforms like React Native).

[Read more about our architecture](https://react-spectrum.adobe.com/architecture.html).

## Contributing

One of the goals of the React Spectrum project is to make building design systems and component libraries as easy as possible, while maintaining high quality interactions and accessibility support. We aim to raise the bar for web applications. The best way to achieve that goal is **together**. We would love contributions from the community no matter how big or small. üòç

Read our [contributing guide](https://react-spectrum.adobe.com/contribute.html) to learn about how to propose bugfixes and improvements, and how the development process works. For detailed information about our architecture, and how all of the pieces fit together, read our [architecture docs](https://react-spectrum.adobe.com/architecture.html).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[Lissy93/web-check]]></title>
            <link>https://github.com/Lissy93/web-check</link>
            <guid>https://github.com/Lissy93/web-check</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[üïµÔ∏è‚Äç‚ôÇÔ∏è All-in-one OSINT tool for analysing any website]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Lissy93/web-check">Lissy93/web-check</a></h1>
            <p>üïµÔ∏è‚Äç‚ôÇÔ∏è All-in-one OSINT tool for analysing any website</p>
            <p>Language: TypeScript</p>
            <p>Stars: 26,261</p>
            <p>Forks: 2,097</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[angular/angular]]></title>
            <link>https://github.com/angular/angular</link>
            <guid>https://github.com/angular/angular</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[Deliver web apps with confidence üöÄ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/angular/angular">angular/angular</a></h1>
            <p>Deliver web apps with confidence üöÄ</p>
            <p>Language: TypeScript</p>
            <p>Stars: 98,580</p>
            <p>Forks: 26,553</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;Angular - The modern web developer&#039;s platform&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;adev/src/assets/images/press-kit/angular_icon_gradient.gif&quot; alt=&quot;angular-logo&quot; width=&quot;120px&quot; height=&quot;120px&quot;/&gt;
  &lt;br&gt;
  &lt;em&gt;Angular is a development platform for building mobile and desktop web applications
    &lt;br&gt; using TypeScript/JavaScript and other languages.&lt;/em&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://angular.dev/&quot;&gt;&lt;strong&gt;angular.dev&lt;/strong&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;Contributing Guidelines&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://github.com/angular/angular/issues&quot;&gt;Submit an Issue&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://blog.angular.dev/&quot;&gt;Blog&lt;/a&gt;
  &lt;br&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/@angular/core&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/@angular/core.svg?logo=npm&amp;logoColor=fff&amp;label=NPM+package&amp;color=limegreen&quot; alt=&quot;Angular on npm&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;hr&gt;

## Documentation

Get started with Angular, learn the fundamentals and explore advanced topics on our documentation website.

- [Getting Started][quickstart]
- [Architecture][architecture]
- [Components and Templates][componentstemplates]
- [Forms][forms]
- [API][api]

### Advanced

- [Angular Elements][angularelements]
- [Server Side Rendering][ssr]
- [Schematics][schematics]
- [Lazy Loading][lazyloading]
- [Animations][animations]

### Local Development

To contribute to the Angular Docs, check out the [Angular.dev README](adev/README.md)

## Development Setup

### Prerequisites

- Install [Node.js] which includes [Node Package Manager][npm]

### Setting Up a Project

Install the Angular CLI globally:

```
npm install -g @angular/cli
```

Create workspace:

```
ng new [PROJECT NAME]
```

Run the application:

```
cd [PROJECT NAME]
ng serve
```

Angular is cross-platform, fast, scalable, has incredible tooling, and is loved by millions.

## Quickstart

[Get started in 5 minutes][quickstart].

## Ecosystem

&lt;p&gt;
  &lt;img src=&quot;/contributing-docs/images/angular-ecosystem-logos.png&quot; alt=&quot;angular ecosystem logos&quot; width=&quot;500px&quot; height=&quot;auto&quot;&gt;
&lt;/p&gt;

- [Angular Command Line (CLI)][cli]
- [Angular Material][angularmaterial]

## Changelog

[Learn about the latest improvements][changelog].

## Upgrading

Check out our [upgrade guide](https://angular.dev/update-guide/) to find out the best way to upgrade your project.

## Contributing

### Contributing Guidelines

Read through our [contributing guidelines][contributing] to learn about our submission process, coding rules, and more.

### Want to Help?

Want to report a bug, contribute some code, or improve the documentation? Excellent! Read up on our guidelines for [contributing][contributing] and then check out one of our issues labeled as &lt;kbd&gt;[help wanted](https://github.com/angular/angular/labels/help%20wanted)&lt;/kbd&gt; or &lt;kbd&gt;[good first issue](https://github.com/angular/angular/labels/good%20first%20issue)&lt;/kbd&gt;.

### Code of Conduct

Help us keep Angular open and inclusive. Please read and follow our [Code of Conduct][codeofconduct].

## Community

Join the conversation and help the community.

- [X (formerly Twitter)][X (formerly Twitter)]
- [Bluesky][bluesky]
- [Discord][discord]
- [YouTube][youtube]
- [StackOverflow][stackoverflow]
- Find a Local [Meetup][meetup]

[![Love Angular badge](https://img.shields.io/badge/angular-love-blue?logo=angular&amp;angular=love)](https://www.github.com/angular/angular)

**Love Angular? Give our repo a star :star: :arrow_up:.**

[contributing]: CONTRIBUTING.md
[quickstart]: https://angular.dev/tutorials/learn-angular
[changelog]: CHANGELOG.md
[ng]: https://angular.dev
[documentation]: https://angular.dev/overview
[angularmaterial]: https://material.angular.dev/
[cli]: https://angular.dev/tools/cli
[architecture]: https://angular.dev/essentials
[componentstemplates]: https://angular.dev/tutorials/learn-angular/1-components-in-angular
[forms]: https://angular.dev/tutorials/learn-angular/15-forms
[api]: https://angular.dev/api
[angularelements]: https://angular.dev/guide/elements
[ssr]: https://angular.dev/guide/ssr
[schematics]: https://angular.dev/tools/cli/schematics
[lazyloading]: https://angular.dev/guide/ngmodules/lazy-loading
[node.js]: https://nodejs.org/
[npm]: https://www.npmjs.com/get-npm
[codeofconduct]: CODE_OF_CONDUCT.md
[X (formerly Twitter)]: https://www.twitter.com/angular
[bluesky]: https://bsky.app/profile/angular.dev
[discord]: https://discord.gg/angular
[stackoverflow]: https://stackoverflow.com/questions/tagged/angular
[youtube]: https://youtube.com/angular
[meetup]: https://www.meetup.com/find/?keywords=angular
[animations]: https://angular.dev/guide/animations
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[humanlayer/humanlayer]]></title>
            <link>https://github.com/humanlayer/humanlayer</link>
            <guid>https://github.com/humanlayer/humanlayer</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[HumanLayer enables AI agents to communicate with humans in tool-based and async workflows. Guarantee human oversight of high-stakes function calls with approval workflows across slack, email and more. Bring your LLM and Framework of choice and start giving your AI agents safe access to the world. Agentic Workflows, human in the loop, tool calling]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/humanlayer/humanlayer">humanlayer/humanlayer</a></h1>
            <p>HumanLayer enables AI agents to communicate with humans in tool-based and async workflows. Guarantee human oversight of high-stakes function calls with approval workflows across slack, email and more. Bring your LLM and Framework of choice and start giving your AI agents safe access to the world. Agentic Workflows, human in the loop, tool calling</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,613</p>
            <p>Forks: 152</p>
            <p>Stars today: 217 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![Wordmark Logo of HumanLayer](./docs/images/wordmark-light.svg)

&lt;/div&gt;

üöß **HumanLayer** is undergoing some changes...stay tuned! üöß

&lt;div align=&quot;center&quot;&gt;

&lt;h3&gt;

[HumanLayer Code](https://humanlayer.dev/code) | [Discord](https://humanlayer.dev/discord) | [Release](https://github.com/humanlayer/humanlayer/releases)


&lt;/h3&gt;

[![GitHub Repo stars](https://img.shields.io/github/stars/humanlayer/humanlayer)](https://github.com/humanlayer/humanlayer)
[![License: Apache-2](https://img.shields.io/badge/License-Apache-green.svg)](https://opensource.org/licenses/Apache-2)

&lt;img referrerpolicy=&quot;no-referrer-when-downgrade&quot; src=&quot;https://static.scarf.sh/a.png?x-pxid=fcfc0926-d841-47fb-b8a6-6aba3a6c3228&quot; /&gt;

&lt;/div&gt;

## Table of contents

- [Getting Started](#getting-started)
- [Why HumanLayer?](#why-humanlayer)
- [Key Features](#key-features)
- [Examples](#examples)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License](#license)

## Why HumanLayer?

Functions and tools are a key part of [Agentic Workflows](https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance). They enable LLMs to interact meaningfully with the outside world and automate broad scopes of impactful work. Correct and accurate function calling is essential for AI agents that do meaningful things like book appointments, interact with customers, manage billing information, write+execute code, and more.

[![Tool Calling Loop from Louis Dupont](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r8rEqjGZs_e6dibWeaqaQg.png)](https://louis-dupont.medium.com/transforming-software-interactions-with-tool-calling-and-llms-dc39185247e9)
_From https://louis-dupont.medium.com/transforming-software-interactions-with-tool-calling-and-llms-dc39185247e9_

**However**, the most useful functions we can give to an LLM are also the most risky. We can all imagine the value of an AI Database Administrator that constantly tunes and refactors our SQL database, but most teams wouldn&#039;t give an LLM access to run arbitrary SQL statements against a production database (heck, we mostly don&#039;t even let humans do that). That is:

&lt;div align=&quot;center&quot;&gt;
&lt;h3&gt;&lt;blockquote&gt;Even with state-of-the-art agentic reasoning and prompt routing, LLMs are not sufficiently reliable to be given access to high-stakes functions without human oversight&lt;/blockquote&gt;&lt;/h3&gt;
&lt;/div&gt;

To better define what is meant by &quot;high stakes&quot;, some examples:

- **Low Stakes**: Read Access to public data (e.g. search wikipedia, access public APIs and DataSets)
- **Low Stakes**: Communicate with agent author (e.g. an engineer might empower an agent to send them a private Slack message with updates on progress)
- **Medium Stakes**: Read Access to Private Data (e.g. read emails, access calendars, query a CRM)
- **Medium Stakes**: Communicate with strict rules (e.g. sending based on a specific sequence of hard-coded email templates)
- **High Stakes**: Communicate on my Behalf or on behalf of my Company (e.g. send emails, post to slack, publish social/blog content)
- **High Stakes**: Write Access to Private Data (e.g. update CRM records, modify feature toggles, update billing information)

&lt;div align=&quot;center&quot;&gt;&lt;img style=&quot;width: 600px&quot; alt=&quot;Image showing the levels of function stakes stacked on top of one another&quot; src=&quot;./docs/images/function_stakes.png&quot;&gt;&lt;/div&gt;

The high stakes functions are the ones that are the most valuable and promise the most impact in automating away human workflows. But they are also the ones where &quot;90% accuracy&quot; is not acceptable. Reliability is further impacted by today&#039;s LLMs&#039; tendency to hallucinate or craft low-quality text that is clearly AI generated. The sooner teams can get Agents reliably and safely calling these tools with high-quality inputs, the sooner they can reap massive benefits.

HumanLayer provides a set of tools to _deterministically_ guarantee human oversight of high stakes function calls. Even if the LLM makes a mistake or hallucinates, HumanLayer is baked into the tool/function itself, guaranteeing a human in the loop.

&lt;div align=&quot;center&quot;&gt;&lt;img style=&quot;width: 400px&quot; alt=&quot;HumanLayer @require_approval decorator wrapping the Commnicate on my behalf function&quot; src=&quot;./docs/images/humanlayer_require_approval.png&quot;&gt;&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;h3&gt;&lt;blockquote&gt;
HumanLayer provides a set of tools to *deterministically* guarantee human oversight of high stakes function calls
&lt;/blockquote&gt;&lt;/h3&gt;
&lt;/div&gt;

### The Future: Autonomous Agents and the &quot;Outer Loop&quot;

_Read More: [OpenAI&#039;s RealTime API is a step towards outer-loop agents](https://theouterloop.substack.com/p/openais-realtime-api-is-a-step-towards)_

Between `require_approval` and `human_as_tool`, HumanLayer is built to empower the next generation of AI agents - Autonomous Agents, but it&#039;s just a piece of the puzzle. To clarify &quot;next generation&quot;, we can summarize briefly the history of LLM applications.

- **Gen 1**: Chat - human-initiated question / response interface
- **Gen 2**: Agentic Assistants - frameworks drive prompt routing, tool calling, chain of thought, and context window management to get much more reliability and functionality. Most workflows are initiated by humans in single-shot &quot;here&#039;s a task, go do it&quot; or rolling chat interfaces.
- **Gen 3**: Autonomous Agents - no longer human initiated, agents will live in the &quot;outer loop&quot; driving toward their goals using various tools and functions. Human/Agent communication is Agent-initiated rather than human-initiated.

![gen2 vs gen 3 agents](./docs/images/gen-2-gen-3-agents.png)

Gen 3 autonomous agents will need ways to consult humans for input on various tasks. In order for these agents to perform actual useful work, they&#039;ll need human oversight for sensitive operations.

These agents will require ways to contact one or more humans across various channels including chat, email, sms, and more.

While early versions of these agents may technically be &quot;human initiated&quot; in that they get kicked off on a regular schedule by e.g. a cron or similar, the best ones will be managing their own scheduling and costs. This will require toolkits for inspecting costs and something akin to `sleep_until`. They&#039;ll need to run in orchestration frameworks that can durably serialize and resume agent workflows across tool calls that might not return for hours or days. These frameworks will need to support context window management by a &quot;manager LLM&quot; and enable agents to fork sub-chains to handle specialized tasks and roles.

Example use cases for these outer loop agents include [the linkedin inbox assistant](./examples/langchain/04-human_as_tool_linkedin.py) and [the customer onboarding assistant](./examples/langchain/05-approvals_and_humans_composite.py), but that&#039;s really just scratching the surface.

## Contributing

The HumanLayer SDK and docs are open-source and we welcome contributions in the form of issues, documentation, pull requests, and more. See [CONTRIBUTING.md](./CONTRIBUTING.md) for more details.

## Fun Stuff

[![Star History Chart](https://api.star-history.com/svg?repos=humanlayer/humanlayer&amp;type=Date)](https://star-history.com/#humanlayer/humanlayer&amp;Date)


## Development Conventions

### TODO Annotations

We use a priority-based TODO annotation system throughout the codebase:

- `TODO(0)`: Critical - never merge
- `TODO(1)`: High - architectural flaws, major bugs
- `TODO(2)`: Medium - minor bugs, missing features
- `TODO(3)`: Low - polish, tests, documentation
- `TODO(4)`: Questions/investigations needed
- `PERF`: Performance optimization opportunities

## License

The HumanLayer SDK and CodeLayer sources in this repo are licensed under the Apache 2 License.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[prevwong/craft.js]]></title>
            <link>https://github.com/prevwong/craft.js</link>
            <guid>https://github.com/prevwong/craft.js</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[üöÄ A React Framework for building extensible drag and drop page editors]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prevwong/craft.js">prevwong/craft.js</a></h1>
            <p>üöÄ A React Framework for building extensible drag and drop page editors</p>
            <p>Language: TypeScript</p>
            <p>Stars: 8,278</p>
            <p>Forks: 797</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>packages/core/README.md</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[elizaOS/eliza]]></title>
            <link>https://github.com/elizaOS/eliza</link>
            <guid>https://github.com/elizaOS/eliza</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[Autonomous agents for everyone]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/elizaOS/eliza">elizaOS/eliza</a></h1>
            <p>Autonomous agents for everyone</p>
            <p>Language: TypeScript</p>
            <p>Stars: 16,718</p>
            <p>Forks: 5,306</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre># Eliza

A framework for multi-agent development and deployment

## ‚ú® Features

- üõ†Ô∏è Full-featured Discord, Telegram, and Farcaster connectors (and many more!)
- üîó Support for every model (Llama, Grok, OpenAI, Anthropic, Gemini, etc.)
- üé® Modern and professional UI with a redesigned dashboard for managing agents and groups.
- üí¨ Robust real-time communication with enhanced channel and message handling.
- üë• Multi-agent and group support with intuitive management.
- üìö Easily ingest and interact with your documents.
- üíæ Retrievable memory and document store.
- üöÄ Highly extensible - create your own actions and clients.
- üì¶ Just works!

## üéØ Use Cases

- ü§ñ Chatbots
- üïµÔ∏è Autonomous Agents
- üìà Business Process Handling
- üéÆ Video Game NPCs
- üß† Trading

## üöÄ Quick Start

### Prerequisites

- [Node.js](https://nodejs.org/) (v23 or higher recommended)
- [bun](https://bun.sh/docs/installation)

&gt; **Note for Windows Users:** [WSL 2](https://learn.microsoft.com/en-us/windows/wsl/install-manual) is required.

### Use the CLI (Recommended)

The ElizaOS CLI provides the fastest and most reliable way to create, configure, and run agents. It handles all the complex setup automatically.

#### 1. Install the CLI

```bash
# Install the ElizaOS CLI globally
bun install -g @elizaos/cli

# Verify installation
elizaos --version

# Get help with available commands
elizaos --help
```

#### 2. Create Your First Project

```bash
# Create a new project with interactive setup
elizaos create my-agent

# Or create with specific options (skips prompts)
elizaos create my-agent --yes --type project
```

**Recommended Options for Beginners:**

- **Database**: `pglite` (lightweight, no setup required)
- **Model Provider**: `openai` (most reliable and well-tested)
- **Project Type**: `project` (full ElizaOS application with runtime and agents)

#### 3. Configure Your Agent

```bash
cd my-agent

# Edit your local env file
elizaos env edit-local

# Or manually edit the .env file with your preferred editor
nano .env
```

**Essential Environment Variables:**

```bash
# Required: Your model API key
OPENAI_API_KEY=your_api_key_here

# Optional: Logging level (info, debug, error)
LOG_LEVEL=info

# Optional: Discord bot token (if using Discord)
DISCORD_APPLICATION_ID=your_discord_app_id
DISCORD_API_TOKEN=your_discord_bot_token
```

#### 4. Start Your Agent

```bash
# Build and start your agent
elizaos start

# Or start with debug logging for development
LOG_LEVEL=debug elizaos start
```

After starting, your agent will be available at:

- **Web Interface**: http://localhost:3000
- **API Endpoint**: http://localhost:3000/api

#### 5. Development Workflow

```bash
# Make changes to your agent code
# Then rebuild and restart
bun run build
elizaos start

# Run tests to verify your changes
elizaos test
```

#### Advanced CLI Commands

```bash
# Create specific components
elizaos create my-plugin --type plugin    # Create a new plugin
elizaos create my-agent --type agent      # Create a new agent character
elizaos create my-tee --type tee          # Create a TEE project

# Environment management
elizaos env list            # Show all environment variables
elizaos env reset           # Reset to default .env.example

# Testing options
elizaos test --name &quot;my-test&quot;    # Run specific tests (case sensitive)
elizaos test e2e                 # Run end-to-end tests only
elizaos test component           # Run component tests only

# Agent management
elizaos agent list                      # List all available agents
elizaos agent start --name &quot;Agent&quot;     # Start a specific agent by name
elizaos agent stop --name &quot;Agent&quot;      # Stop a running agent
elizaos agent get --name &quot;Agent&quot;       # Get agent details
elizaos agent set --name &quot;Agent&quot; --file config.json  # Update agent configuration
```

#### Debugging and Logging

ElizaOS uses comprehensive logging to help you understand what your agent is doing:

```bash
# Different log levels
LOG_LEVEL=error elizaos start    # Only errors
LOG_LEVEL=info elizaos start     # General information (default)
LOG_LEVEL=debug elizaos start    # Detailed debugging info
LOG_LEVEL=verbose elizaos start  # Everything (very detailed)

# Advanced debugging (combine with LOG_LEVEL=debug)
ELIZA_DEBUG=true elizaos start          # Enable ElizaOS debug output
NODE_ENV=development elizaos start      # Development mode with extra logging
```

**Pro Tips:**

- Use `elizaos --help` to see all available commands and global options
- Use `elizaos &lt;command&gt; --help` for detailed help on any specific command
- Use `LOG_LEVEL=debug` during development to see detailed execution flow
- Check the web interface at http://localhost:3000 for real-time agent status
- Use `elizaos test` frequently to catch issues early
- Keep your `.env` file secure and never commit it to version control

#### Available Commands Reference

**All CLI Commands:**

```bash
elizaos create     # Create new projects, plugins, agents, or TEE projects
elizaos start      # Start the agent server with character profiles
elizaos agent      # Manage agents (list, start, stop, get, set)
elizaos test       # Run tests (component, e2e, or all)
elizaos env        # Manage environment variables and configuration
elizaos dev        # Start in development mode with auto-rebuild
elizaos update     # Update CLI and project dependencies
# To stop agents, use Ctrl+C in the terminal where elizaos start is running
elizaos publish    # Publish plugins to registry
elizaos plugins    # Manage and discover plugins
elizaos monorepo   # Monorepo development utilities
elizaos tee        # Trusted Execution Environment commands

# Get help for any specific command
elizaos &lt;command&gt; --help    # e.g., elizaos create --help, elizaos agent --help
```

### Manually Start Eliza (Only recommended if you know what you are doing)

#### Prerequisites

- **Node.js** (v18+ recommended)
- **bun** (for CLI and dependencies)
- **git** (for project/plugin tests)

#### Checkout the latest release

```bash
# Clone the repository
git clone https://github.com/elizaos/eliza.git

# This project iterates fast, so we recommend checking out the latest release
git checkout $(git describe --tags --abbrev=0)
# If the above doesn&#039;t checkout the latest release, this should work:
# git checkout $(git describe --tags `git rev-list --tags --max-count=1`)
```

#### Edit the .env file

Copy .env.example to .env and fill in the appropriate values.

```
cp .env.example .env
```

Note: .env is optional. If you&#039;re planning to run multiple distinct agents, you can pass secrets through the character JSON

#### Start Eliza

Important! We now use Bun. If you are using npm, you will need to install Bun:
https://bun.sh/docs/installation

```bash
bun install
bun run build
bun start
```

### Interact via Browser

Once Eliza is running, access the modern web interface at http://localhost:3000. It has been professionally redesigned and features:

- A welcoming dashboard with a gradient hero section and clear calls-to-action for creating agents and groups.
- Visually enhanced cards for managing agents and groups, including status indicators and member counts.
- Real-time chat capabilities with your agents.
- Character configuration options.
- Plugin management.
- Comprehensive memory and conversation history.
- Responsive design for an optimal experience on various screen sizes.

## Citation

We now have a [paper](https://arxiv.org/pdf/2501.06781) you can cite for the Eliza OS:

```bibtex
@article{walters2025eliza,
  title={Eliza: A Web3 friendly AI Agent Operating System},
  author={Walters, Shaw and Gao, Sam and Nerd, Shakker and Da, Feng and Williams, Warren and Meng, Ting-Chien and Han, Hunter and He, Frank and Zhang, Allen and Wu, Ming and others},
  journal={arXiv preprint arXiv:2501.06781},
  year={2025}
}
```

## Contributors

&lt;a href=&quot;https://github.com/elizaos/eliza/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=elizaos/eliza&quot; alt=&quot;Eliza project contributors&quot; /&gt;
&lt;/a&gt;

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=elizaos/eliza&amp;type=Date)](https://star-history.com/#elizaos/eliza&amp;Date)

## Git Hooks

This project uses git hooks to ensure code quality:

- **pre-commit**: Automatically formats staged files using Prettier before committing

To run the pre-commit hook manually:

```bash
bun run pre-commit
```

## üìÇ Repository Structure

Eliza is organized as a monorepo using Bun, Lerna, and Turbo for efficient package management and build orchestration. Here&#039;s a detailed overview of the project structure:

- **`/` (Root)**:

  - `.github/`: GitHub Actions workflows for CI/CD pipelines and issue templates
  - `.husky/`: Git hooks configuration, including pre-commit formatting
  - `.devcontainer/`: Development container configurations for consistent environments
  - `packages/`: Core packages and modules (detailed below)
  - `scripts/`: Build, development, and utility scripts
  - `data/`: Application and user data storage
  - `AGENTS.md`: Comprehensive agent documentation and specifications
  - `CHANGELOG.md`: Detailed version history and changes
  - `Dockerfile`, `docker-compose.yaml`: Container configurations for deployment
  - `lerna.json`, `package.json`, `turbo.json`: Monorepo configuration and workspace definitions

- **`/packages/`**: Core components of the Eliza framework:
  - `core/`: The foundational package (@elizaos/core) implementing:
    - PDF processing capabilities
    - Logging and error handling infrastructure
  - `app/`: Tauri-based cross-platform application (@elizaos/app)
    - React-based UI implementation
    - Tauri plugins for system integration
    - Desktop and mobile builds support
  - `autodoc/`: Documentation automation tool (@elizaos/autodoc)
    - LangChain-powered documentation generation
    - TypeScript parsing and analysis
    - GitHub integration via Octokit
  - `cli/`: Command-line interface for Eliza management
  - `client/`: Client libraries for web interfaces
  - `create-eliza/`: Project scaffolding tool
  - `docs/`: Official documentation source files
  - `plugin-bootstrap/`: **Essential communication core** (@elizaos/plugin-bootstrap)
    - **Required for basic agent functionality** - handles all message processing
    - Provides critical event handlers (MESSAGE_RECEIVED, VOICE_MESSAGE_RECEIVED, etc.)
    - Implements fundamental agent actions (reply, follow/unfollow, mute/unmute)
    - Contains core evaluators and providers for agent cognition
    - Manages message processing pipeline and response generation
    - **Mandatory unless building custom event handling system**
  - `plugin-sql/`: Database integration (@elizaos/plugin-sql)
    - PostgreSQL integration with PGLite support
    - Drizzle ORM for type-safe queries
    - Migration management tools
    - Integration testing support
  - `plugin-starter/`: Template for creating new plugins
  - `project-starter/`, `project-tee-starter/`: Project templates

This architecture enables modular development, clear separation of concerns, and scalable feature implementation across the Eliza ecosystem.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[vercel/ai-chatbot]]></title>
            <link>https://github.com/vercel/ai-chatbot</link>
            <guid>https://github.com/vercel/ai-chatbot</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[A full-featured, hackable Next.js AI chatbot built by Vercel]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vercel/ai-chatbot">vercel/ai-chatbot</a></h1>
            <p>A full-featured, hackable Next.js AI chatbot built by Vercel</p>
            <p>Language: TypeScript</p>
            <p>Stars: 17,698</p>
            <p>Forks: 5,384</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://chat.vercel.ai/&quot;&gt;
  &lt;img alt=&quot;Next.js 14 and App Router-ready AI chatbot.&quot; src=&quot;app/(chat)/opengraph-image.png&quot;&gt;
  &lt;h1 align=&quot;center&quot;&gt;Chat SDK&lt;/h1&gt;
&lt;/a&gt;

&lt;p align=&quot;center&quot;&gt;
    Chat SDK is a free, open-source template built with Next.js and the AI SDK that helps you quickly build powerful chatbot applications.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://chat-sdk.dev&quot;&gt;&lt;strong&gt;Read Docs&lt;/strong&gt;&lt;/a&gt; ¬∑
  &lt;a href=&quot;#features&quot;&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/a&gt; ¬∑
  &lt;a href=&quot;#model-providers&quot;&gt;&lt;strong&gt;Model Providers&lt;/strong&gt;&lt;/a&gt; ¬∑
  &lt;a href=&quot;#deploy-your-own&quot;&gt;&lt;strong&gt;Deploy Your Own&lt;/strong&gt;&lt;/a&gt; ¬∑
  &lt;a href=&quot;#running-locally&quot;&gt;&lt;strong&gt;Running locally&lt;/strong&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;br/&gt;

## Features

- [Next.js](https://nextjs.org) App Router
  - Advanced routing for seamless navigation and performance
  - React Server Components (RSCs) and Server Actions for server-side rendering and increased performance
- [AI SDK](https://sdk.vercel.ai/docs)
  - Unified API for generating text, structured objects, and tool calls with LLMs
  - Hooks for building dynamic chat and generative user interfaces
  - Supports xAI (default), OpenAI, Fireworks, and other model providers
- [shadcn/ui](https://ui.shadcn.com)
  - Styling with [Tailwind CSS](https://tailwindcss.com)
  - Component primitives from [Radix UI](https://radix-ui.com) for accessibility and flexibility
- Data Persistence
  - [Neon Serverless Postgres](https://vercel.com/marketplace/neon) for saving chat history and user data
  - [Vercel Blob](https://vercel.com/storage/blob) for efficient file storage
- [Auth.js](https://authjs.dev)
  - Simple and secure authentication

## Model Providers

This template ships with [xAI](https://x.ai) `grok-2-1212` as the default chat model. However, with the [AI SDK](https://sdk.vercel.ai/docs), you can switch LLM providers to [OpenAI](https://openai.com), [Anthropic](https://anthropic.com), [Cohere](https://cohere.com/), and [many more](https://sdk.vercel.ai/providers/ai-sdk-providers) with just a few lines of code.

## Deploy Your Own

You can deploy your own version of the Next.js AI Chatbot to Vercel with one click:

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fvercel%2Fai-chatbot&amp;env=AUTH_SECRET&amp;envDescription=Learn+more+about+how+to+get+the+API+Keys+for+the+application&amp;envLink=https%3A%2F%2Fgithub.com%2Fvercel%2Fai-chatbot%2Fblob%2Fmain%2F.env.example&amp;demo-title=AI+Chatbot&amp;demo-description=An+Open-Source+AI+Chatbot+Template+Built+With+Next.js+and+the+AI+SDK+by+Vercel.&amp;demo-url=https%3A%2F%2Fchat.vercel.ai&amp;products=%5B%7B%22type%22%3A%22integration%22%2C%22protocol%22%3A%22ai%22%2C%22productSlug%22%3A%22grok%22%2C%22integrationSlug%22%3A%22xai%22%7D%2C%7B%22type%22%3A%22integration%22%2C%22protocol%22%3A%22storage%22%2C%22productSlug%22%3A%22neon%22%2C%22integrationSlug%22%3A%22neon%22%7D%2C%7B%22type%22%3A%22integration%22%2C%22protocol%22%3A%22storage%22%2C%22productSlug%22%3A%22upstash-kv%22%2C%22integrationSlug%22%3A%22upstash%22%7D%2C%7B%22type%22%3A%22blob%22%7D%5D)

## Running locally

You will need to use the environment variables [defined in `.env.example`](.env.example) to run Next.js AI Chatbot. It&#039;s recommended you use [Vercel Environment Variables](https://vercel.com/docs/projects/environment-variables) for this, but a `.env` file is all that is necessary.

&gt; Note: You should not commit your `.env` file or it will expose secrets that will allow others to control access to your various AI and authentication provider accounts.

1. Install Vercel CLI: `npm i -g vercel`
2. Link local instance with Vercel and GitHub accounts (creates `.vercel` directory): `vercel link`
3. Download your environment variables: `vercel env pull`

```bash
pnpm install
pnpm dev
```

Your app template should now be running on [localhost:3000](http://localhost:3000).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[miurla/morphic]]></title>
            <link>https://github.com/miurla/morphic</link>
            <guid>https://github.com/miurla/morphic</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[An AI-powered search engine with a generative UI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/miurla/morphic">miurla/morphic</a></h1>
            <p>An AI-powered search engine with a generative UI</p>
            <p>Language: TypeScript</p>
            <p>Stars: 8,030</p>
            <p>Forks: 2,196</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># Morphic

An AI-powered search engine with a generative UI.

![capture](/public/screenshot-2025-05-04.png)

## üóÇÔ∏è Overview

- üõ† [Features](#-features)
- üß± [Stack](#-stack)
- üöÄ [Quickstart](#-quickstart)
- üåê [Deploy](#-deploy)
- üîé [Search Engine](#-search-engine)
- üíô [Sponsors](#-sponsors)
- üë• [Contributing](#-contributing)
- üìÑ [License](#-license)

üìù Explore AI-generated documentation on [DeepWiki](https://deepwiki.com/miurla/morphic)

## üõ† Features

### Core Features

- AI-powered search with GenerativeUI
- Natural language question understanding
- Multiple search providers support (Tavily, SearXNG, Exa)
- Model selection from UI (switch between available AI models)
  - Reasoning models with visible thought process

### Authentication

- User authentication powered by [Supabase Auth](https://supabase.com/docs/guides/auth)
- Supports Email/Password sign-up and sign-in
- Supports Social Login with Google

### Chat &amp; History

- Chat history functionality (Optional)
- Share search results (Optional)
- Redis support (Local/Upstash)

### AI Providers

The following AI providers are supported:

- OpenAI (Default)
- Google Generative AI
- Azure OpenAI
- Anthropic
- Ollama
- Groq
- DeepSeek
- Fireworks
- xAI (Grok)
- OpenAI Compatible

Models are configured in `public/config/models.json`. Each model requires its corresponding API key to be set in the environment variables. See [Configuration Guide](docs/CONFIGURATION.md) for details.

### Search Capabilities

- URL-specific search
- Video search support (Optional)
- SearXNG integration with:
  - Customizable search depth (basic/advanced)
  - Configurable engines
  - Adjustable results limit
  - Safe search options
  - Custom time range filtering

### Additional Features

- Docker deployment ready
- Browser search engine integration

## üß± Stack

### Core Framework

- [Next.js](https://nextjs.org/) - App Router, React Server Components
- [TypeScript](https://www.typescriptlang.org/) - Type safety
- [Vercel AI SDK](https://sdk.vercel.ai/docs) - Text streaming / Generative UI

### Authentication &amp; Authorization (Updated Category)

- [Supabase](https://supabase.com/) - User authentication and backend services

### AI &amp; Search

- [OpenAI](https://openai.com/) - Default AI provider (Optional: Google AI, Anthropic, Groq, Ollama, Azure OpenAI, DeepSeek, Fireworks)
- [Tavily AI](https://tavily.com/) - Default search provider
- Alternative providers:
  - [SearXNG](https://docs.searxng.org/) - Self-hosted search
  - [Exa](https://exa.ai/) - Neural search

### Data Storage

- [Upstash](https://upstash.com/) - Serverless Redis
- [Redis](https://redis.io/) - Local Redis option

### UI &amp; Styling

- [Tailwind CSS](https://tailwindcss.com/) - Utility-first CSS framework
- [shadcn/ui](https://ui.shadcn.com/) - Re-usable components
- [Radix UI](https://www.radix-ui.com/) - Unstyled, accessible components
- [Lucide Icons](https://lucide.dev/) - Beautiful &amp; consistent icons

## üöÄ Quickstart

### 1. Fork and Clone repo

Fork the repo to your Github account, then run the following command to clone the repo:

```bash
git clone git@github.com:[YOUR_GITHUB_ACCOUNT]/morphic.git
```

### 2. Install dependencies

```bash
cd morphic
bun install
```

### 3. Configure environment variables

```bash
cp .env.local.example .env.local
```

Fill in the required environment variables in `.env.local`:

```bash
# Required for Core Functionality
OPENAI_API_KEY=     # Get from https://platform.openai.com/api-keys
TAVILY_API_KEY=     # Get from https://app.tavily.com/home
```

For optional features configuration (Redis, SearXNG, etc.), see [CONFIGURATION.md](./docs/CONFIGURATION.md)

### 4. Run app locally

#### Using Bun

```bash
bun dev
```

#### Using Docker

```bash
docker compose up -d
```

Visit http://localhost:3000 in your browser.

## üåê Deploy

Host your own live version of Morphic with Vercel, Cloudflare Pages, or Docker.

### Vercel

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fmiurla%2Fmorphic&amp;env=OPENAI_API_KEY,TAVILY_API_KEY,UPSTASH_REDIS_REST_URL,UPSTASH_REDIS_REST_TOKEN)

### Docker Prebuilt Image

Prebuilt Docker images are available on GitHub Container Registry:

```bash
docker pull ghcr.io/miurla/morphic:latest
```

You can use it with docker-compose:

```yaml
services:
  morphic:
    image: ghcr.io/miurla/morphic:latest
    env_file: .env.local
    ports:
      - &#039;3000:3000&#039;
    volumes:
      - ./models.json:/app/public/config/models.json # Optional: Override default model configuration
```

The default model configuration is located at `public/config/models.json`. For Docker deployment, you can create `models.json` alongside `.env.local` to override the default configuration.

## üîé Search Engine

### Setting up the Search Engine in Your Browser

If you want to use Morphic as a search engine in your browser, follow these steps:

1. Open your browser settings.
2. Navigate to the search engine settings section.
3. Select &quot;Manage search engines and site search&quot;.
4. Under &quot;Site search&quot;, click on &quot;Add&quot;.
5. Fill in the fields as follows:
   - **Search engine**: Morphic
   - **Shortcut**: morphic
   - **URL with %s in place of query**: `https://morphic.sh/search?q=%s`
6. Click &quot;Add&quot; to save the new search engine.
7. Find &quot;Morphic&quot; in the list of site search, click on the three dots next to it, and select &quot;Make default&quot;.

This will allow you to use Morphic as your default search engine in the browser.

## üíô Sponsors

This project is proudly supported by:

&lt;a href=&quot;https://vercel.com/oss&quot;&gt;
  &lt;img alt=&quot;Vercel OSS Program&quot; src=&quot;https://vercel.com/oss/program-badge.svg&quot; /&gt;
&lt;/a&gt;

## üë• Contributing

We welcome contributions to Morphic! Whether it&#039;s bug reports, feature requests, or pull requests, all contributions are appreciated.

Please see our [Contributing Guide](CONTRIBUTING.md) for details on:

- How to submit issues
- How to submit pull requests
- Commit message conventions
- Development setup

## üìÑ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[onlook-dev/onlook]]></title>
            <link>https://github.com/onlook-dev/onlook</link>
            <guid>https://github.com/onlook-dev/onlook</guid>
            <pubDate>Sun, 31 Aug 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[The Cursor for Designers ‚Ä¢ An Open-Source AI-First Design tool ‚Ä¢ Visually build, style, and edit your React App with AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/onlook-dev/onlook">onlook-dev/onlook</a></h1>
            <p>The Cursor for Designers ‚Ä¢ An Open-Source AI-First Design tool ‚Ä¢ Visually build, style, and edit your React App with AI</p>
            <p>Language: TypeScript</p>
            <p>Stars: 22,199</p>
            <p>Forks: 1,529</p>
            <p>Stars today: 109 stars today</p>
            <h2>README</h2><pre>&lt;!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 --&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img width=&quot;800&quot; alt=&quot;header image&quot; src=&quot;assets/web-preview.png&quot;&gt;
&lt;h3 align=&quot;center&quot;&gt;Onlook&lt;/h3&gt;
  &lt;p align=&quot;center&quot;&gt;
    Cursor for Designers
    &lt;br /&gt;
    &lt;a href=&quot;https://docs.onlook.com&quot;&gt;&lt;strong&gt;Explore the docs ¬ª&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
  &lt;/p&gt;
  &lt;p align=&quot;center&quot;&gt;
    üë®‚Äçüíªüë©‚Äçüíªüë®‚Äçüíª
    &lt;a href=&quot;https://www.ycombinator.com/companies/onlook/jobs/e4gHv1n-founding-engineer-fullstack&quot;&gt;We&#039;re hiring engineers in SF!&lt;/a&gt;
    üë©‚Äçüíªüë®‚Äçüíªüë©‚Äçüíª
  &lt;/p&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://youtu.be/RSX_3EaO5eU?feature=shared&quot;&gt;View Demo&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/onlook-dev/onlook/issues/new?labels=bug&amp;template=bug-report---.md&quot;&gt;Report Bug&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/onlook-dev/onlook/issues/new?labels=enhancement&amp;template=feature-request---.md&quot;&gt;Request Feature&lt;/a&gt;
  &lt;/p&gt;
  &lt;!-- PROJECT SHIELDS --&gt;
&lt;!--
*** I&#039;m using markdown &quot;reference style&quot; links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
--&gt;
&lt;!-- [![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![Apache License][license-shield]][license-url] --&gt;

[![Discord][discord-shield]][discord-url]
[![LinkedIn][linkedin-shield]][linkedin-url]
[![Twitter][twitter-shield]][twitter-url]

[‰∏≠Êñá](https://www.readme-i18n.com/onlook-dev/onlook?lang=zh) |
[Espa√±ol](https://www.readme-i18n.com/onlook-dev/onlook?lang=es) |
[Deutsch](https://www.readme-i18n.com/onlook-dev/onlook?lang=de) |
[fran√ßais](https://www.readme-i18n.com/onlook-dev/onlook?lang=fr) |
[Portugu√™s](https://www.readme-i18n.com/onlook-dev/onlook?lang=pt) |
[–†—É—Å—Å–∫–∏–π](https://www.readme-i18n.com/onlook-dev/onlook?lang=ru) |
[Êó•Êú¨Ë™û](https://www.readme-i18n.com/onlook-dev/onlook?lang=ja) |
[ÌïúÍµ≠Ïñ¥](https://www.readme-i18n.com/onlook-dev/onlook?lang=ko)

&lt;/div&gt;

# An Open-Source, Visual-First Code Editor

Craft websites, prototypes, and designs with AI in Next.js + TailwindCSS. Make
edits directly in the browser DOM with a visual editor. Design in realtime with
code. An open-source alternative to Bolt.new, Lovable, V0, Replit Agent, Figma
Make, Webflow, etc.

### üöß üöß üöß Onlook is still under development üöß üöß üöß

We&#039;re actively looking for contributors to help make Onlook for Web an
incredible prompt-to-build experience. Check the
[open issues](https://github.com/onlook-dev/onlook/issues) for a full list of
proposed features (and known issues), and join our
[Discord](https://discord.gg/hERDfFZCsH) to collaborate with hundreds of other
builders.

## What you can do with Onlook:

- [x] Create Next.js app in seconds
  - [x] Start from text or image
  - [ ] Use prebuilt templates
  - [ ] Import from Figma
  - [ ] Start from GitHub repo
- [x] Visually edit your app
  - [x] Use Figma-like UI
  - [x] Preview your app in real-time
  - [x] Manage brand assets and tokens
  - [x] Create and navigate to Pages
  - [x] Browse layers
  - [x] Manage project Images
  - [ ] Detect and use Components ‚Äì _Previously in
        [Onlook Desktop](https://github.com/onlook-dev/desktop)_
- [x] Development Tools
  - [x] Real-time code editor
  - [x] Save and restore from checkpoints
  - [x] Run commands via CLI
  - [x] Connect with app marketplace

- [x] Deploy your app in seconds
  - [x] Generate sharable links
  - [x] Link your custom domain
- [ ] Collaborate with your team
  - [ ] Real-time editing
  - [ ] Leave comments

![Onlook-GitHub-Example](https://github.com/user-attachments/assets/642de37a-72cc-4056-8eb7-8eb42714cdc4)

## Getting Started

Available soon with a [hosted app](https://onlook.com) or
[run locally](https://docs.onlook.com/developers/running-locally).

### Usage

Onlook will run on any Next.js + TailwindCSS project, import your project into
Onlook or start from scratch within the editor.

Use the AI chat to create or edit a project you&#039;re working on. At any time, you
can always right-click an element to open up the exact location of the element
in code.

&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/4ad9f411-b172-4430-81ef-650f4f314666&quot; /&gt;

&lt;br&gt;

Draw-in new divs and re-arrange them within their parent containers by
dragging-and-dropping.

&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;assets/insert-div.png&quot;&gt;

&lt;br&gt;

Preview the code side-by-side with your site design.

&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;assets/code-connect.png&quot;&gt;

&lt;br&gt;

Use Onlook&#039;s editor toolbar to adjust Tailwind styles, directly manipulate
objects, and experiment with layouts.

&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;assets/text-styling.png&quot; /&gt;

## Documentation

For full documentation, visit [docs.onlook.com](https://docs.onlook.com)

To see how to Contribute, visit
[Contributing to Onlook](https://docs.onlook.com/developers) in our docs.

## How it works

&lt;img width=&quot;676&quot; alt=&quot;architecture&quot; src=&quot;assets/architecture.png&quot;&gt;

1. When you create an app, we load the code into a web container
2. The container runs and serves the code
3. Our editor receives the preview link and displays it in an iFrame
4. Our editor reads and indexes the code from the container
5. We instrument the code in order to map elements to their place in code
6. When the element is edited, we edit the element in our iFrame, then in code
7. Our AI chat also has code access and tools to understand and edit the code

This architecture can theoretically scale to any language or framework that
displays DOM elements declaratively (e.g. jsx/tsx/html). We are focused on
making it work well with Next.js and TailwindCSS for now.

For a full walkthrough, check out our
[Architecture Docs](https://docs.onlook.com/developers/architecture).

### Our Tech Stack

#### Front-end

- [Next.js](https://nextjs.org/) - Full stack
- [TailwindCSS](https://tailwindcss.com/) - Styling
- [tRPC](https://trpc.io/) - Server interface

#### Database

- [Supabase](https://supabase.com/) - Auth, Database, Storage
- [Drizzle](https://orm.drizzle.team/) - ORM

#### AI

- [AI SDK](https://ai-sdk.dev/) - LLM client
- [OpenRouter](https://openrouter.ai/) - LLM model provider
- [Morph Fast Apply](https://morphllm.com) - Fast apply model provider
- [Relace](https://relace.ai) - Fast apply model provider

#### Sandbox and hosting

- [CodeSandboxSDK](https://codesandbox.io/docs/sdk) - Dev sandbox
- [Freestyle](https://www.freestyle.sh/) - Hosting

#### Runtime

- [Bun](https://bun.sh/) - Monorepo, runtime, bundler
- [Docker](https://www.docker.com/) - Container management

## Contributing

![image](https://github.com/user-attachments/assets/ecc94303-df23-46ae-87dc-66b040396e0b)

If you have a suggestion that would make this better, please fork the repo and
create a pull request. You can also
[open issues](https://github.com/onlook-dev/onlook/issues).

See the [CONTRIBUTING.md](CONTRIBUTING.md) for instructions and code of conduct.

#### Contributors

&lt;a href=&quot;https://github.com/onlook-dev/onlook/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=onlook-dev/onlook&quot; /&gt;
&lt;/a&gt;

## Contact

![image](https://github.com/user-attachments/assets/60684b68-1925-4550-8efd-51a1509fc953)

- Team: [Discord](https://discord.gg/hERDfFZCsH) -
  [Twitter](https://twitter.com/onlookdev) -
  [LinkedIn](https://www.linkedin.com/company/onlook-dev/) -
  [Email](mailto:contact@onlook.com)
- Project:
  [https://github.com/onlook-dev/onlook](https://github.com/onlook-dev/onlook)
- Website: [https://onlook.com](https://onlook.com)

## License

Distributed under the Apache 2.0 License. See [LICENSE.md](LICENSE.md) for more
information.

&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/onlook-dev/studio.svg?style=for-the-badge
[contributors-url]: https://github.com/onlook-dev/onlook/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/onlook-dev/studio.svg?style=for-the-badge
[forks-url]: https://github.com/onlook-dev/onlook/network/members
[stars-shield]: https://img.shields.io/github/stars/onlook-dev/studio.svg?style=for-the-badge
[stars-url]: https://github.com/onlook-dev/onlook/stargazers
[issues-shield]: https://img.shields.io/github/issues/onlook-dev/studio.svg?style=for-the-badge
[issues-url]: https://github.com/onlook-dev/onlook/issues
[license-shield]: https://img.shields.io/github/license/onlook-dev/studio.svg?style=for-the-badge
[license-url]: https://github.com/onlook-dev/onlook/blob/master/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?logo=linkedin&amp;colorB=555
[linkedin-url]: https://www.linkedin.com/company/onlook-dev
[twitter-shield]: https://img.shields.io/badge/-Twitter-black?logo=x&amp;colorB=555
[twitter-url]: https://x.com/onlookdev
[discord-shield]: https://img.shields.io/badge/-Discord-black?logo=discord&amp;colorB=555
[discord-url]: https://discord.gg/hERDfFZCsH
[React.js]: https://img.shields.io/badge/react-%2320232a.svg?logo=react&amp;logoColor=%2361DAFB
[React-url]: https://reactjs.org/
[TailwindCSS]: https://img.shields.io/badge/tailwindcss-%2338B2AC.svg?logo=tailwind-css&amp;logoColor=white
[Tailwind-url]: https://tailwindcss.com/
[Electron.js]: https://img.shields.io/badge/Electron-191970?logo=Electron&amp;logoColor=white
[Electron-url]: https://www.electronjs.org/
[Vite.js]: https://img.shields.io/badge/vite-%23646CFF.svg?logo=vite&amp;logoColor=white
[Vite-url]: https://vitejs.dev/
[product-screenshot]: assets/brand.png
[weave-shield]: https://img.shields.io/endpoint?url=https%3A%2F%2Fapp.workweave.ai%2Fapi%2Frepository%2Fbadge%2Forg_pWcXBHJo3Li2Te2Y4WkCPA33%2F820087727&amp;cacheSeconds=3600&amp;labelColor=#131313
[weave-url]: https://app.workweave.ai/reports/repository/org_pWcXBHJo3Li2Te2Y4WkCPA33/820087727
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>