<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Thu, 29 Jan 2026 00:06:10 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[badlogic/pi-mono]]></title>
            <link>https://github.com/badlogic/pi-mono</link>
            <guid>https://github.com/badlogic/pi-mono</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:10 GMT</pubDate>
            <description><![CDATA[AI agent toolkit: coding agent CLI, unified LLM API, TUI & web UI libraries, Slack bot, vLLM pods]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/badlogic/pi-mono">badlogic/pi-mono</a></h1>
            <p>AI agent toolkit: coding agent CLI, unified LLM API, TUI & web UI libraries, Slack bot, vLLM pods</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,114</p>
            <p>Forks: 383</p>
            <p>Stars today: 467 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://shittycodingagent.ai&quot;&gt;
    &lt;img src=&quot;https://shittycodingagent.ai/logo.svg&quot; alt=&quot;pi logo&quot; width=&quot;128&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.com/invite/nKXTsAcmbT&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/badge/discord-community-5865F2?style=flat-square&amp;logo=discord&amp;logoColor=white&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/badlogic/pi-mono/actions/workflows/ci.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/badlogic/pi-mono/ci.yml?style=flat-square&amp;branch=main&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

# Pi Monorepo

&gt; **Looking for the pi coding agent?** See **[packages/coding-agent](packages/coding-agent)** for installation and usage.

Tools for building AI agents and managing LLM deployments.

## Packages

| Package | Description |
|---------|-------------|
| **[@mariozechner/pi-ai](packages/ai)** | Unified multi-provider LLM API (OpenAI, Anthropic, Google, etc.) |
| **[@mariozechner/pi-agent-core](packages/agent)** | Agent runtime with tool calling and state management |
| **[@mariozechner/pi-coding-agent](packages/coding-agent)** | Interactive coding agent CLI |
| **[@mariozechner/pi-mom](packages/mom)** | Slack bot that delegates messages to the pi coding agent |
| **[@mariozechner/pi-tui](packages/tui)** | Terminal UI library with differential rendering |
| **[@mariozechner/pi-web-ui](packages/web-ui)** | Web components for AI chat interfaces |
| **[@mariozechner/pi-pods](packages/pods)** | CLI for managing vLLM deployments on GPU pods |

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for contribution guidelines and [AGENTS.md](AGENTS.md) for project-specific rules (for both humans and agents).

## Development

```bash
npm install          # Install all dependencies
npm run build        # Build all packages
npm run check        # Lint, format, and type check
./test.sh            # Run tests (skips LLM-dependent tests without API keys)
./pi-test.sh         # Run pi from sources (must be run from repo root)
```

&gt; **Note:** `npm run check` requires `npm run build` to be run first. The web-ui package uses `tsc` which needs compiled `.d.ts` files from dependencies.

## License

MIT</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lobehub/lobehub]]></title>
            <link>https://github.com/lobehub/lobehub</link>
            <guid>https://github.com/lobehub/lobehub</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:09 GMT</pubDate>
            <description><![CDATA[The ultimate space for work and life ‚Äî to find, build, and collaborate with agent teammates that grow with you. We are taking agent harness to the next level ‚Äî enabling multi-agent collaboration, effortless agent team design, and introducing agents as the unit of work interaction.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobehub">lobehub/lobehub</a></h1>
            <p>The ultimate space for work and life ‚Äî to find, build, and collaborate with agent teammates that grow with you. We are taking agent harness to the next level ‚Äî enabling multi-agent collaboration, effortless agent team design, and introducing agents as the unit of work interaction.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 70,885</p>
            <p>Forks: 14,494</p>
            <p>Stars today: 144 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# LobeHub

LobeHub is the ultimate space for work and life: &lt;br/&gt;
to find, build, and collaborate with agent teammates that grow with you.&lt;br/&gt;
We‚Äôre building the world‚Äôs largest human‚Äìagent co-evolving network.

**English** ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md) ¬∑ [Official Site][official-site] ¬∑ [Changelog][changelog] ¬∑ [Documents][docs] ¬∑ [Blog][blog] ¬∑ [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeHub Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Agent teams that grow with you&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url]

[![](https://vercel.com/oss/program-badge.svg)](https://vercel.com/oss)

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [üëãüèª Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [‚ú® Features](#-features)
  - [Create: Agents as the Unit of Work](#create-agents-as-the-unit-of-work)
  - [Collaborate: Scale New Forms of Collaboration Networks](#collaborate-scale-new-forms-of-collaboration-networks)
  - [Evolve: Co-evolution of Humans and Agents](#evolve-co-evolution-of-humans-and-agents)
  - [MCP Plugin One-Click Installation](#mcp-plugin-one-click-installation)
  - [MCP Marketplace](#mcp-marketplace)
  - [Desktop App](#desktop-app)
  - [Smart Internet Search](#smart-internet-search)
  - [Chain of Thought](#chain-of-thought)
  - [Branching Conversations](#branching-conversations)
  - [Artifacts Support](#artifacts-support)
  - [File Upload /Knowledge Base](#file-upload-knowledge-base)
  - [Multi-Model Service Provider Support](#multi-model-service-provider-support)
  - [Local Large Language Model (LLM) Support](#local-large-language-model-llm-support)
  - [Model Visual Recognition](#model-visual-recognition)
  - [TTS &amp; STT Voice Conversation](#tts--stt-voice-conversation)
  - [Text to Image Generation](#text-to-image-generation)
  - [Plugin System (Function Calling)](#plugin-system-function-calling)
  - [Agent Market (GPTs)](#agent-market-gpts)
  - [Support Local / Remote Database](#support-local--remote-database)
  - [Support Multi-User Management](#support-multi-user-management)
  - [Progressive Web App (PWA)](#progressive-web-app-pwa)
  - [Mobile Device Adaptation](#mobile-device-adaptation)
  - [Custom Themes](#custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [üõ≥ Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [üì¶ Ecosystem](#-ecosystem)
- [üß© Plugins](#-plugins)
- [‚å®Ô∏è Local Development](#Ô∏è-local-development)
- [ü§ù Contributing](#-contributing)
- [‚ù§Ô∏è Sponsor](#Ô∏è-sponsor)
- [üîó More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

&lt;br/&gt;

&lt;https://github.com/user-attachments/assets/6710ad97-03d0-4175-bd75-adff9b55eca2&gt;

## üëãüèª Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeHub is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![](https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=1065874&amp;theme=light&amp;t=1769347414733)](https://www.producthunt.com/products/lobehub?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_campaign=badge-lobehub) | We are live on Product Hunt! We are thrilled to bring LobeHub to the world. If you believe in a future where humans and agents co-evolve, please support our journey. |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link]                                                                                                                                                                                                         | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub.                                                    |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ ‚≠êÔ∏è

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## ‚ú® Features

Today‚Äôs agents are one-off, task-driven tools. They lack context, live in isolation, and require manual hand-offs between different windows and models. While some maintain memory, it is often global, shallow, and impersonal. In this mode, users are forced to toggle between fragmented conversations, making it difficult to form structured productivity.

**LobeHub changes everything.**

LobeHub is a work-and-lifestyle space to find, build, and collaborate with agent teammates that grow with you. In LobeHub, we treat **Agents as the unit of work**, providing an infrastructure where humans and agents co-evolve.

![](https://hub-apac-1.lobeobjects.space/blog/assets/2204cde2228fb3f583f3f2c090bc49fb.webp)

### Create: Agents as the Unit of Work

Building a personalized AI team starts with the **Agent Builder**. You can describe what you need once, and the agent setup starts right away, applying auto-configurations so you can use it instantly.

- **Unified Intelligence**: Seamlessly access any model and any modality‚Äîall under your control.
- **10,000+ Skills**: Connect your agents to the skills you use every day with a library of over 10,000 tools and MCP-compatible plugins.

[![][back-to-top]](#readme-top)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

![](https://hub-apac-1.lobeobjects.space/blog/assets/771ff3d30b9ef93e65e55021cc43d356.webp)

### Collaborate: Scale New Forms of Collaboration Networks

LobeHub introduces **Agent Groups**, allowing you to work with agents like real teammates. The system assembles the right agents for the task, enabling parallel collaboration and iterative improvement.

- **Pages**: Write and refine content with multiple agents in one place with a shared context.
- **Schedule**: Schedule runs and let agents do the work at the right time, even while you are away.
- **Project**: Organize work by project to keep everything structured and easy to track.
- **Workspace**: A shared space for teams to collaborate with agents, ensuring clear ownership and visibility across the organization.

[![][back-to-top]](#readme-top)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

![](https://hub-apac-1.lobeobjects.space/blog/assets/fe98eae9fcb6acc47c8e1fb69bdb4b50.webp)

### Evolve: Co-evolution of Humans and Agents

The best AI is one that understands you deeply. LobeHub features **Personal Memory** that builds a clear understanding of your needs.

- **Continual Learning**: Your agents learn from how you work, adapting their behavior to act at the right moment.
- **White-Box Memory**: We believe in transparency. Your agents use structured, editable memory, giving you full control over what they remember.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;More Features&lt;/summary&gt;

![][image-feat-mcp]

### MCP Plugin One-Click Installation

**Seamlessly Connect Your AI to the World**

Unlock the full potential of your AI by enabling smooth, secure, and dynamic interactions with external tools, data sources, and services. LobeHub&#039;s MCP (Model Context Protocol) plugin system breaks down the barriers between your AI and the digital ecosystem, allowing for unprecedented connectivity and functionality.

Transform your conversations into powerful workflows by connecting to databases, APIs, file systems, and more. Experience the freedom of AI that truly understands and interacts with your world.

[![][back-to-top]](#readme-top)

![][image-feat-mcp-market]

### MCP Marketplace

**Discover, Connect, Extend**

Browse a growing library of MCP plugins to expand your AI&#039;s capabilities and streamline your workflows effortlessly. Visit [lobehub.com/mcp](https://lobehub.com/mcp) to explore the MCP Marketplace, which offers a curated collection of integrations that enhance your AI&#039;s ability to work with various tools and services.

From productivity tools to development environments, discover new ways to extend your AI&#039;s reach and effectiveness. Connect with the community and find the perfect plugins for your specific needs.

[![][back-to-top]](#readme-top)

![][image-feat-desktop]

### Desktop App

**Peak Performance, Zero Distractions**

Get the full LobeHub experience without browser limitations‚Äîcomprehensive, focused, and always ready to go. Our desktop application provides a dedicated environment for your AI interactions, ensuring optimal performance and minimal distractions.

Experience faster response times, better resource management, and a more stable connection to your AI assistant. The desktop app is designed for users who demand the best performance from their AI tools.

[![][back-to-top]](#readme-top)

![][image-feat-web-search]

### Smart Internet Search

**Online Knowledge On Demand**

With real-time internet access, your AI keeps up with the world‚Äînews, data, trends, and more. Stay informed and get the most current information available, enabling your AI to provide accurate and up-to-date responses.

Access live information, verify facts, and explore current events without leaving your conversation. Your AI becomes a gateway to the world&#039;s knowledge, always current and comprehensive.

[![][back-to-top]](#readme-top)

[![][image-feat-cot]][docs-feat-cot]

### [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeHub. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeHub supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [üìò LobeHub Knowledge Base Launch ‚Äî From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeHub, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeHub can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+-10)&lt;/kbd&gt;&lt;/summary&gt;

&lt;/details&gt;

&gt; üìä Total providers: [&lt;kbd&gt;**0**&lt;/kbd&gt;](https://lobechat.com/discover/providers)

 &lt;!-- PROVIDER LIST --&gt;

At the same time, we are also planning to support more model service providers. If you would like LobeHub to support your favorite service provider, feel free to join our [üí¨ community discussion](https://github.com/lobehub/lobe-chat/discussions/1284).

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-local]][docs-feat-local]

### [Local Large Language Model (LLM) Support][docs-feat-local]

To meet the specific needs of users, LobeHub also supports the use of local models based on [Ollama](https://ollama.ai), allowing users to flexibly use their own or third-party models.

&gt; \[!TIP]
&gt;
&gt; Learn more about [üìò Using Ollama in LobeHub][docs-usage-ollama] by checking it out.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-vision]][docs-feat-vision]

### [Model Visual Recognition][docs-feat-vision]

LobeHub now supports OpenAI&#039;s latest [`gpt-4-vision`](https://platform.openai.com/docs/guides/vision) model with visual recognition capabilities,
a multimodal intelligence that can perceive visuals. Users can easily upload or drag and drop images into the dialogue box,
and the agent will be able to recognize the content of the images and engage in intelligent conversation based on this,
creating smarter and more diversified chat scenarios.

This feature opens up new interactive methods, allowing communication to transcend text and include a wealth of visual elements.
Whether it&#039;s sharing images in daily use or interpreting images within specific industries, the agent provides an outstanding conversational experience.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-tts]][docs-feat-tts]

### [TTS &amp; STT Voice Conversation][docs-feat-tts]

LobeHub supports Text-to-Speech (TTS) and Speech-to-Text (STT) technologies, enabling our application to convert text messages into clear voice outputs,
allowing users to interact with our conversational agent as if they were talking to a real person. Users can choose from a variety of voices to pair with the agent.

Moreover, TTS offers an excellent solution for those who prefer auditory learning or desire to receive information while busy.
In LobeHub, we have meticulously selected a range of high-quality voice options (OpenAI Audio, Microsoft Edge Speech) to meet the needs of users from different regions and cultural backgrounds.
Users can choose the voice that suits their personal preferences or specific scenarios, resulting in a personalized communication experience.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-t2i]][docs-feat-t2i]

### [Text to Image Generation][docs-feat-t2i]

With support for the latest text-to-image generation technology, LobeHub now allows users to invoke image creation tools directly within conversations with the agent. By leveraging the capabilities of AI tools such as [`DALL-E 3`](https://openai.com/dall-e-3), [`MidJourney`](https://www.midjourney.com/), and [`Pollinations`](https://pollinations.ai/), the agents are now equipped to transform your ideas into images.

This enables a more private and immersive creative process, allowing for the seamless integration of visual storytelling into your personal dialogue with the agent.

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-plugin]][docs-feat-plugin]

### [Plugin System (Function Calling)][docs-feat-plugin]

The plugin ecosystem of LobeHub is an important extension of its core functionality, greatly enhancing the practicality and flexibility of the LobeHub assistant.

&lt;video controls src=&quot;https://github.com/lobehub/lobe-chat/assets/28616219/f29475a3-f346-4196-a435-41a6373ab9e2&quot; muted=&quot;false&quot;&gt;&lt;/video&gt;

By utilizing plugins, LobeHub assistants can obtain and process real-time information, such as searching for web information and providing users with instant and relevant news.

In addition, these plugins are not limited to news aggregation, but can also extend to other practical functions, such as quickly searching documents, generating images, obtaining data from various platforms like Bilibili, Steam, and interacting with various third-party services.

&gt; \[!TIP]
&gt;
&gt; Learn more about [üìò Plugin Usage][docs-usage-plugin] by checking it out.

&lt;!-- PLUGIN LIST --&gt;

| Recent Submits                                                                                                             | Description                                                                                                                                     |
| -------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[DayuanJiang/next-ai-draw-io]]></title>
            <link>https://github.com/DayuanJiang/next-ai-draw-io</link>
            <guid>https://github.com/DayuanJiang/next-ai-draw-io</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:08 GMT</pubDate>
            <description><![CDATA[A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DayuanJiang/next-ai-draw-io">DayuanJiang/next-ai-draw-io</a></h1>
            <p>A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 20,100</p>
            <p>Forks: 2,099</p>
            <p>Stars today: 300 stars today</p>
            <h2>README</h2><pre># Next AI Draw.io

&lt;div align=&quot;center&quot;&gt;

**AI-Powered Diagram Creation Tool - Chat, Draw, Visualize**

English | [‰∏≠Êñá](./docs/cn/README_CN.md) | [Êó•Êú¨Ë™û](./docs/ja/README_JA.md)

[![TrendShift](https://trendshift.io/api/badge/repositories/15449)](https://next-ai-drawio.jiang.jp/)

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Next.js](https://img.shields.io/badge/Next.js-16.x-black)](https://nextjs.org/)
[![React](https://img.shields.io/badge/React-19.x-61dafb)](https://react.dev/)
[![Sponsor](https://img.shields.io/badge/Sponsor-‚ù§-ea4aaa)](https://github.com/sponsors/DayuanJiang)

[![Live Demo](./public/live-demo-button.svg)](https://next-ai-drawio.jiang.jp/)

&lt;/div&gt;

A Next.js web application that integrates AI capabilities with draw.io diagrams. Create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.

&gt; Note: Thanks to &lt;img src=&quot;https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/doubao-color.png&quot; alt=&quot;&quot; height=&quot;20&quot; /&gt; [ByteDance Doubao](https://console.volcengine.com/ark/region:ark+cn-beijing/overview?briefPage=0&amp;briefType=introduce&amp;type=new&amp;utm_campaign=doubao&amp;utm_content=aidrawio&amp;utm_medium=github&amp;utm_source=coopensrc&amp;utm_term=project) sponsorship, the demo site now uses the powerful K2-thinking model!


https://github.com/user-attachments/assets/9d60a3e8-4a1c-4b5e-acbb-26af2d3eabd1



## Table of Contents
- [Next AI Draw.io](#next-ai-drawio)
  - [Table of Contents](#table-of-contents)
  - [Examples](#examples)
  - [Features](#features)
  - [MCP Server (Preview)](#mcp-server-preview)
    - [Claude Code CLI](#claude-code-cli)
  - [Getting Started](#getting-started)
    - [Try it Online](#try-it-online)
    - [Desktop Application](#desktop-application)
    - [Run with Docker](#run-with-docker)
    - [Installation](#installation)
  - [Deployment](#deployment)
    - [Deploy to EdgeOne Pages](#deploy-to-edgeone-pages)
    - [Deploy on Vercel](#deploy-on-vercel)
    - [Deploy on Cloudflare Workers](#deploy-on-cloudflare-workers)
  - [Multi-Provider Support](#multi-provider-support)
  - [How It Works](#how-it-works)
  - [Support \&amp; Contact](#support--contact)
  - [FAQ](#faq)
  - [Star History](#star-history)

## Examples

Here are some example prompts and their generated diagrams:

&lt;div align=&quot;center&quot;&gt;
&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td colspan=&quot;2&quot; valign=&quot;top&quot; align=&quot;center&quot;&gt;
      &lt;strong&gt;Animated transformer connectors&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Give me a **animated connector** diagram of transformer&#039;s architecture.&lt;/p&gt;
      &lt;img src=&quot;./public/animated_connectors.svg&quot; alt=&quot;Transformer Architecture with Animated Connectors&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;GCP architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a GCP architecture diagram with **GCP icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/gcp_demo.svg&quot; alt=&quot;GCP Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;AWS architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a AWS architecture diagram with **AWS icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/aws_demo.svg&quot; alt=&quot;AWS Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;Azure architecture diagram&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a Azure architecture diagram with **Azure icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt;
      &lt;img src=&quot;./public/azure_demo.svg&quot; alt=&quot;Azure Architecture Diagram&quot; width=&quot;480&quot; /&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;strong&gt;Cat sketch prompt&lt;/strong&gt;&lt;br /&gt;
      &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Draw a cute cat for me.&lt;/p&gt;
      &lt;img src=&quot;./public/cat_demo.svg&quot; alt=&quot;Cat Drawing&quot; width=&quot;240&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;

## Features

-   **LLM-Powered Diagram Creation**: Leverage Large Language Models to create and manipulate draw.io diagrams directly through natural language commands
-   **Image-Based Diagram Replication**: Upload existing diagrams or images and have the AI replicate and enhance them automatically
-   **PDF &amp; Text File Upload**: Upload PDF documents and text files to extract content and generate diagrams from existing documents
-   **AI Reasoning Display**: View the AI&#039;s thinking process for supported models (OpenAI o1/o3, Gemini, Claude, etc.)
-   **Diagram History**: Comprehensive version control that tracks all changes, allowing you to view and restore previous versions of your diagrams before the AI editing.
-   **Interactive Chat Interface**: Communicate with AI to refine your diagrams in real-time
-   **Cloud Architecture Diagram Support**: Specialized support for generating cloud architecture diagrams (AWS, GCP, Azure)
-   **Animated Connectors**: Create dynamic and animated connectors between diagram elements for better visualization

## MCP Server (Preview)

&gt; **Preview Feature**: This feature is experimental and may not be stable.

Use Next AI Draw.io with AI agents like Claude Desktop, Cursor, and VS Code via MCP (Model Context Protocol).

```json
{
  &quot;mcpServers&quot;: {
    &quot;drawio&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;@next-ai-drawio/mcp-server@latest&quot;]
    }
  }
}
```

### Claude Code CLI

```bash
claude mcp add drawio -- npx @next-ai-drawio/mcp-server@latest
```

Then ask Claude to create diagrams:
&gt; &quot;Create a flowchart showing user authentication with login, MFA, and session management&quot;

The diagram appears in your browser in real-time!

See the [MCP Server README](./packages/mcp-server/README.md) for VS Code, Cursor, and other client configurations.

## Getting Started

### Try it Online

No installation needed! Try the app directly on our demo site:

[![Live Demo](./public/live-demo-button.svg)](https://next-ai-drawio.jiang.jp/)



&gt; **Bring Your Own API Key**: You can use your own API key to bypass usage limits on the demo site. Click the Settings icon in the chat panel to configure your provider and API key. Your key is stored locally in your browser and is never stored on the server.

### Desktop Application

Download the native desktop app for your platform from the [Releases page](https://github.com/DayuanJiang/next-ai-draw-io/releases):

Supported platforms: Windows, macOS, Linux.

### Run with Docker

[Go to Docker Guide](./docs/en/docker.md)

### Installation

1. Clone the repository:

```bash
git clone https://github.com/DayuanJiang/next-ai-draw-io
cd next-ai-draw-io
npm install
cp env.example .env.local
```

See the [Provider Configuration Guide](./docs/en/ai-providers.md) for detailed setup instructions for each provider.

2. Run the development server:

```bash
npm run dev
```

3. Open [http://localhost:6002](http://localhost:6002) in your browser to see the application.

## Deployment

### Deploy to EdgeOne Pages

You can deploy with one click using [Tencent EdgeOne Pages](https://pages.edgeone.ai/).

Deploy by this button: 

[![Deploy to EdgeOne Pages](https://cdnstatic.tencentcs.com/edgeone/pages/deploy.svg)](https://edgeone.ai/pages/new?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io)

Check out the [Tencent EdgeOne Pages documentation](https://pages.edgeone.ai/document/deployment-overview) for more details.

Additionally, deploying through Tencent EdgeOne Pages will also grant you a [daily free quota for DeepSeek models](https://pages.edgeone.ai/document/edge-ai).

### Deploy on Vercel 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io)

The easiest way to deploy is using [Vercel](https://vercel.com/new), the creators of Next.js. Be sure to **set the environment variables** in the Vercel dashboard as you did in your local `.env.local` file.

See the [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.

### Deploy on Cloudflare Workers

[Go to Cloudflare Deploy Guide](./docs/en/cloudflare-deploy.md)



## Multi-Provider Support

-   [ByteDance Doubao](https://console.volcengine.com/ark/region:ark+cn-beijing/overview?briefPage=0&amp;briefType=introduce&amp;type=new&amp;utm_campaign=doubao&amp;utm_content=aidrawio&amp;utm_medium=github&amp;utm_source=coopensrc&amp;utm_term=project)
-   AWS Bedrock (default)
-   OpenAI
-   Anthropic
-   Google AI
-   Google Vertex AI
-   Azure OpenAI
-   Ollama
-   OpenRouter
-   DeepSeek
-   SiliconFlow
-   ModelScope
-   SGLang
-   Vercel AI Gateway


All providers except AWS Bedrock and OpenRouter support custom endpoints.

üìñ **[Detailed Provider Configuration Guide](./docs/en/ai-providers.md)** - See setup instructions for each provider.

### Server-Side Multi-Model Configuration

Administrators can configure multiple server-side models that are available to all users without requiring personal API keys. Configure via `AI_MODELS_CONFIG` environment variable (JSON string) or `ai-models.json` file.

**Model Requirements**: This task requires strong model capabilities for generating long-form text with strict formatting constraints (draw.io XML). Recommended models include Claude Sonnet 4.5, GPT-5.1, Gemini 3 Pro, and DeepSeek V3.2/R1.

Note that the `claude` series has been trained on draw.io diagrams with cloud architecture logos like AWS, Azure, GCP. So if you want to create cloud architecture diagrams, this is the best choice.


## How It Works

The application uses the following technologies:

-   **Next.js**: For the frontend framework and routing
-   **Vercel AI SDK** (`ai` + `@ai-sdk/*`): For streaming AI responses and multi-provider support
-   **react-drawio**: For diagram representation and manipulation

Diagrams are represented as XML that can be rendered in draw.io. The AI processes your commands and generates or modifies this XML accordingly.


## Support &amp; Contact

**Special thanks to [ByteDance Doubao](https://console.volcengine.com/ark/region:ark+cn-beijing/overview?briefPage=0&amp;briefType=introduce&amp;type=new&amp;utm_campaign=doubao&amp;utm_content=aidrawio&amp;utm_medium=github&amp;utm_source=coopensrc&amp;utm_term=project) for sponsoring the API token usage of the demo site!** Register on the ARK platform to get 500K free tokens for all models!

If you find this project useful, please consider [sponsoring](https://github.com/sponsors/DayuanJiang) to help me host the live demo site!

For support or inquiries, please open an issue on the GitHub repository or contact the maintainer at:

-   Email: me[at]jiang.jp

## FAQ

See [FAQ](./docs/en/FAQ.md) for common issues and solutions.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=DayuanJiang/next-ai-draw-io&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#DayuanJiang/next-ai-draw-io&amp;type=date&amp;legend=top-left)

---
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[suitenumerique/meet]]></title>
            <link>https://github.com/suitenumerique/meet</link>
            <guid>https://github.com/suitenumerique/meet</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:07 GMT</pubDate>
            <description><![CDATA[Open source video conferencing app powered by LiveKit.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/suitenumerique/meet">suitenumerique/meet</a></h1>
            <p>Open source video conferencing app powered by LiveKit.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,248</p>
            <p>Forks: 119</p>
            <p>Stars today: 90 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;meet logo&quot; src=&quot;./docs/assets/banner-meet-fr.png&quot; maxWidth=&quot;100%&quot;&gt;
&lt;/p&gt;


&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/suitenumerique/meet/stargazers/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/suitenumerique/meet&quot; alt=&quot;&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&#039;http://makeapullrequest.com&#039;&gt;&lt;img alt=&#039;PRs Welcome&#039; src=&#039;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=shields&#039;/&gt;&lt;/a&gt;
  &lt;img alt=&quot;GitHub commit activity&quot; src=&quot;https://img.shields.io/github/commit-activity/m/suitenumerique/meet&quot;/&gt;
  &lt;img alt=&quot;GitHub closed issues&quot; src=&quot;https://img.shields.io/github/issues-closed/suitenumerique/meet&quot;/&gt;
  &lt;a href=&quot;https://github.com/suitenumerique/meet/blob/main/LICENSE&quot;&gt;
    &lt;img alt=&quot;GitHub closed issues&quot; src=&quot;https://img.shields.io/github/license/suitenumerique/meet&quot;/&gt;
  &lt;/a&gt;    
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://livekit.io/&quot;&gt;LiveKit&lt;/a&gt; - &lt;a href=&quot;https://matrix.to/#/#meet-official:matrix.org&quot;&gt;Chat with us&lt;/a&gt; - &lt;a href=&quot;https://github.com/orgs/suitenumerique/projects/3/views/2&quot;&gt;Roadmap&lt;/a&gt; - &lt;a href=&quot;https://github.com/suitenumerique/meet/blob/main/CHANGELOG.md&quot;&gt;Changelog&lt;/a&gt; - &lt;a href=&quot;https://github.com/suitenumerique/meet/issues/new?assignees=&amp;labels=bug&amp;template=Bug_report.md&quot;&gt;Bug reports&lt;/a&gt; 
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://visio.numerique.gouv.fr/&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/09c1faa1-de88-4848-af3a-6fbe793999bf&quot; alt=&quot;La Suite Meet Demonstration&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

## La Suite Meet: Simple Video Conferencing

Powered by [LiveKit](https://livekit.io/), La Suite Meet offers Zoom-level performance with high-quality video and audio. No installation required‚Äîsimply join calls directly from your browser. Check out LiveKit&#039;s impressive optimizations in their [blog post](https://blog.livekit.io/livekit-one-dot-zero/).
### Features
- Optimized for stability in large meetings (+100 p.)
- Support for multiple screen sharing streams
- Non-persistent, secure chat
- End-to-end encryption (coming soon)
- Meeting recording
- Meeting transcription &amp; Summary (currently in beta)
- Telephony integration
- Secure participation with robust authentication and access control
- Customizable frontend style
- LiveKit Advances features including :
  - speaker detection 
  - simulcast 
  - end-to-end optimizations 
  - selective subscription
  - SVC codecs (VP9, AV1)


La Suite Meet is fully self-hostable and released under the MIT License, ensuring complete control and flexibility. It&#039;s simple to [get started](https://visio.numerique.gouv.fr/) or [request a demo](mailto:visio@numerique.gouv.fr). 

We‚Äôre continuously adding new features to enhance your experience, with the latest updates coming soon!

### üöÄ Major roll out to all French public servants

On the 25th of January 2026, David Amiel, France‚Äôs Minister for Civil Service and State Reform, announced the full deployment of Visio‚Äîthe French government‚Äôs dedicated Meet platform‚Äîto all public servants. ([Source in French](https://www.latribune.fr/article/la-tribune-dimanche/politique/73157688099661/david-amiel-ministre-delegue-de-la-fonction-publique-nous-allons-sortir-de-la-dependance-aux-outils-americains))

## Table of Contents

- [Get started](#get-started)
- [Docs](#docs)
- [Self-host](#self-host)
- [Contributing](#contributing)
- [Philosophy](#philosophy)
- [Open source](#open-source)


## Get started

## Docs

We&#039;re currently working on both technical and user documentation for La Suite Meet. In the meantime, many of the essential aspects are already well covered by the [LiveKit documentation](https://docs.livekit.io/home/) and their [self-hosting guide](https://docs.livekit.io/home/self-hosting/deployment/). Stay tuned for more updates!

## Self-host

### La Suite Meet is easy to install on your own servers

We use Kubernetes for our [production instance](https://visio.numerique.gouv.fr/) but also support Docker Compose. The community contributed a couple other methods (Nix, YunoHost etc.) check out the [docs](/docs/installation/README.md) to get detailed instructions and examples.

**Questions?** Open an issue on [GitHub](https://github.com/suitenumerique/meet/issues/new?assignees=&amp;labels=bug&amp;template=Bug_report.md) or join our [Matrix community](https://matrix.to/#/#meet-official:matrix.org).

&gt; [!NOTE]
&gt; Some advanced features (ex: recording, transcription) lack detailed documentation. We&#039;re working hard to provide comprehensive guides soon.

#### Known instances
We hope to see many more, here is an incomplete list of public La Suite Meet instances. Feel free to make a PR to add ones that are not listed belowüôè

| Url                                                           | Org | Access |
|---------------------------------------------------------------| --- | ------- |
| [visio.numerique.gouv.fr](https://visio.numerique.gouv.fr/)   | DINUM    | French public agents working for the central administration and the extended public sphere. ProConnect is required to login in or sign up|
| [visio.suite.anct.gouv.fr](https://visio.suite.anct.gouv.fr/) | ANCT    | French public agents working for the territorial administration and the extended public sphere. ProConnect is required to login in or sign up|
| [visio.lasuite.coop](https://visio.lasuite.coop/)             | lasuite.coop    | Free and open demo to all. Content and accounts are reset after one month |
| [mosacloud.cloud](https://mosa.cloud/)                        | mosa.cloud    | Demo instance of mosa.cloud, a dutch company providing services around La Suite apps. |


## Contributing

We &lt;3 contributions of any kind, big and small:

- Vote on features or get early access to beta functionality in our [roadmap](https://github.com/orgs/suitenumerique/projects/11/views/4)
- Open a PR (see our instructions on [developing La Suite Meet locally](https://github.com/suitenumerique/meet/blob/main/docs/developping_locally.md))
- Submit a [feature request](https://github.com/suitenumerique/meet/issues/new?assignees=&amp;labels=enhancement&amp;template=Feature_request.md) or [bug report](https://github.com/suitenumerique/meet/issues/new?assignees=&amp;labels=bug&amp;template=Bug_report.md)


## Philosophy

We‚Äôre relentlessly focused on building the best open-source video conferencing product‚ÄîLa Suite Meet. Growth comes from creating something people truly need, not just from chasing metrics.

Our users come first. We‚Äôre committed to making La Suite Meet as accessible and easy to use as proprietary solutions, ensuring it meets the highest standards.

Most of the heavy engineering is handled by the incredible LiveKit team, allowing us to focus on delivering a top-tier product. We follow extreme programming practices, favoring pair programming and quick, iterative releases. Challenge our tech and architecture‚Äîsimplicity is always our top priority.


## Open-source

Gov üá´üá∑ supports open source! This project is available under [MIT license](https://github.com/suitenumerique/meet/blob/0cc2a7b7b4f4821e2c4d9d790efa739622bb6601/LICENSE).

All features we develop will always remain open-source, and we are committed to contributing back to the LiveKit community whenever feasible.
To learn more, don&#039;t hesitate to [reach out](mailto:visio@numerique.gouv.fr).

### Help us!

Come help us make La Suite Meet even better. We&#039;re growing fast and [would love some help](mailto:visio@numerique.gouv.fr).


## Contributors üßû

&lt;a href=&quot;https://github.com/suitenumerique/meet/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=suitenumerique/meet&quot; /&gt;
&lt;/a&gt;

## Credits 

We&#039;re using the awesome [LiveKit](https://livekit.io/) implementation. We&#039;re also thankful to the teams behind [Django Rest Framework](https://www.django-rest-framework.org/), [Vite.js](https://vite.dev/), and [React Aria](https://github.com/adobe/react-spectrum) ‚Äî Thanks for your amazing work!
This project is tested with BrowserStack.

## License

Code in this repository is published under the MIT license by DINUM (Direction interminist√©riel du num√©rique).
Documentation (in the docs/) directory is released under the [Etalab-2.0 license](https://spdx.org/licenses/etalab-2.0.html).

</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[letta-ai/letta-code]]></title>
            <link>https://github.com/letta-ai/letta-code</link>
            <guid>https://github.com/letta-ai/letta-code</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:06 GMT</pubDate>
            <description><![CDATA[The memory-first coding agent]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/letta-ai/letta-code">letta-ai/letta-code</a></h1>
            <p>The memory-first coding agent</p>
            <p>Language: TypeScript</p>
            <p>Stars: 926</p>
            <p>Forks: 114</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre># Letta Code

[![npm](https://img.shields.io/npm/v/@letta-ai/letta-code.svg?style=flat-square)](https://www.npmjs.com/package/@letta-ai/letta-code) [![Discord](https://img.shields.io/badge/discord-join-blue?style=flat-square&amp;logo=discord)](https://discord.gg/letta)

Letta Code is a memory-first coding harness, built on top of the Letta API. Instead of working in independent sessions, you work with a persisted agent that learns over time and is portable across models (Claude Sonnet/Opus 4.5, GPT-5.2-Codex, Gemini 3 Pro, GLM-4.7, and more).

**Read more about how to use Letta Code on the [official docs page](https://docs.letta.com/letta-code).**

![](https://github.com/letta-ai/letta-code/blob/main/assets/letta-code-demo.gif)

## Get started
Install the package via [npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm):
```bash
npm install -g @letta-ai/letta-code
```
Navigate to your project directory and run `letta` (see various command-line options [on the docs](https://docs.letta.com/letta-code/commands)). 

Run `/connect` to configure your own LLM API keys (OpenAI, Anthropic, etc.), and use `/model` to swap models.

&gt; [!NOTE]
&gt;  By default, Letta Code will to connect to the [Letta API](https://app.letta.com/). Use `/connect` to use your own LLM API keys and coding plans (Codex, zAI, Minimax) for free. Set `LETTA_BASE_URL` to connect to an external [Docker server](https://docs.letta.com/letta-code/docker).

## Philosophy 
Letta Code is built around long-lived agents that persist across sessions and improve with use. Rather than working in independent sessions, each session is tied to a persisted agent that learns.

**Claude Code / Codex / Gemini CLI** (Session-Based)
- Sessions are independent
- No learning between sessions
- Context = messages in the current session + `AGENTS.md`
- Relationship: Every conversation is like meeting a new contractor

**Letta Code** (Agent-Based)
- Same agent across sessions
- Persistent memory and learning over time
- `/clear` starts a new conversation (aka &quot;thread&quot; or &quot;session&quot;), but memory persists
- Relationship: Like having a coworker or mentee that learns and remembers

## Agent Memory &amp; Learning
If you‚Äôre using Letta Code for the first time, you will likely want to run the `/init` command to initialize the agent‚Äôs memory system:
```bash
&gt; /init
```

Over time, the agent will update its memory as it learns. To actively guide your agents memory, you can use the `/remember` command:
```bash
&gt; /remember [optional instructions on what to remember]
```
Letta Code works with skills (reusable modules that teach your agent new capabilities in a `.skills` directory), but additionally supports [skill learning](https://www.letta.com/blog/skill-learning). You can ask your agent to learn a skill from it&#039;s current trajectory with the command: 
```bash
&gt; /skill [optional instructions on what skill to learn]
```

Read the docs to learn more about [skills and skill learning](https://docs.letta.com/letta-code/skills).

Community maintained packages are available for Arch Linux users on the [AUR](https://aur.archlinux.org/packages/letta-code):
```bash
yay -S letta-code # release
yay -S letta-code-git # nightly
yay -S letta-code-bin # prebuilt release
```

---

Made with üíú in San Francisco
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[CherryHQ/cherry-studio]]></title>
            <link>https://github.com/CherryHQ/cherry-studio</link>
            <guid>https://github.com/CherryHQ/cherry-studio</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:05 GMT</pubDate>
            <description><![CDATA[AI Agent + Coding Agent + 300+ assistants: agentic AI desktop with autonomous coding, intelligent automation, and unified access to frontier LLMs.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/CherryHQ/cherry-studio">CherryHQ/cherry-studio</a></h1>
            <p>AI Agent + Coding Agent + 300+ assistants: agentic AI desktop with autonomous coding, intelligent automation, and unified access to frontier LLMs.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 38,740</p>
            <p>Forks: 3,569</p>
            <p>Stars today: 157 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;right&quot; &gt;
  &lt;details&gt;
    &lt;summary &gt;üåê Language&lt;/summary&gt;
    &lt;div&gt;
      &lt;div align=&quot;right&quot;&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=en&quot;&gt;English&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=zh-CN&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=zh-TW&quot;&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=ja&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=ko&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=hi&quot;&gt;‡§π‡§ø‡§®‡•ç‡§¶‡•Ä&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=th&quot;&gt;‡πÑ‡∏ó‡∏¢&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=fr&quot;&gt;Fran√ßais&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=de&quot;&gt;Deutsch&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=es&quot;&gt;Espa√±ol&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=it&quot;&gt;Italiano&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=ru&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=pt&quot;&gt;Portugu√™s&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=nl&quot;&gt;Nederlands&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=pl&quot;&gt;Polski&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=ar&quot;&gt;ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=fa&quot;&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=tr&quot;&gt;T√ºrk√ße&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=vi&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;&lt;/p&gt;
        &lt;p&gt;&lt;a href=&quot;https://openaitx.github.io/view.html?user=CherryHQ&amp;project=cherry-studio&amp;lang=id&quot;&gt;Bahasa Indonesia&lt;/a&gt;&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/details&gt;
&lt;/div&gt;

&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/CherryHQ/cherry-studio/releases&quot;&gt;
    &lt;img src=&quot;https://github.com/CherryHQ/cherry-studio/blob/main/build/icon.png?raw=true&quot; width=&quot;150&quot; height=&quot;150&quot; alt=&quot;banner&quot; /&gt;&lt;br&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;English | &lt;a href=&quot;./docs/zh/README.md&quot;&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href=&quot;https://cherry-ai.com&quot;&gt;Official Site&lt;/a&gt; | &lt;a href=&quot;https://docs.cherry-ai.com/docs/en-us&quot;&gt;Documents&lt;/a&gt; | &lt;a href=&quot;./docs/en/guides/development.md&quot;&gt;Development&lt;/a&gt; | &lt;a href=&quot;https://github.com/CherryHQ/cherry-studio/issues&quot;&gt;Feedback&lt;/a&gt;&lt;br&gt;&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![][deepwiki-shield]][deepwiki-link]
[![][twitter-shield]][twitter-link]
[![][discord-shield]][discord-link]
[![][telegram-shield]][telegram-link]

&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;

[![][github-release-shield]][github-release-link]
[![][github-nightly-shield]][github-nightly-link]
[![][github-contributors-shield]][github-contributors-link]
[![][license-shield]][license-link]
[![][commercial-shield]][commercial-link]
[![][sponsor-shield]][sponsor-link]

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
 &lt;a href=&quot;https://hellogithub.com/repository/1605492e1e2a4df3be07abfa4578dd37&quot; target=&quot;_blank&quot; style=&quot;text-decoration: none&quot;&gt;&lt;img src=&quot;https://api.hellogithub.com/v1/widgets/recommend.svg?rid=1605492e1e2a4df3be07abfa4578dd37&quot; alt=&quot;FeaturedÔΩúHelloGitHub&quot;  width=&quot;220&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;
 &lt;a href=&quot;https://trendshift.io/repositories/14318&quot; target=&quot;_blank&quot; style=&quot;text-decoration: none&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14318&quot; alt=&quot;CherryHQ%2Fcherry-studio | Trendshift&quot; width=&quot;220&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;
 &lt;a href=&quot;https://www.producthunt.com/posts/cherry-studio?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-cherry&amp;#0045;studio&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=496640&amp;theme=light&quot; alt=&quot;Cherry&amp;#0032;Studio - AI&amp;#0032;Chatbots&amp;#0044;&amp;#0032;AI&amp;#0032;Desktop&amp;#0032;Client | Product Hunt&quot; width=&quot;220&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

# üçí Cherry Studio

Cherry Studio is a desktop client that supports multiple LLM providers, available on Windows, Mac and Linux.

üëè Join [Telegram Group](https://t.me/CherryStudioAI)ÔΩú[Discord](https://discord.gg/wez8HtpxqQ) | [QQ Group(575014769)](https://qm.qq.com/q/lo0D4qVZKi)

‚ù§Ô∏è Like Cherry Studio? Give it a star üåü or [Sponsor](docs/zh/guides/sponsor.md) to support the development!

# üå† Screenshot

![](https://github.com/user-attachments/assets/36dddb2c-e0fb-4a5f-9411-91447bab6e18)

![](https://github.com/user-attachments/assets/f549e8a0-2385-40b4-b52b-2039e39f2930)

![](https://github.com/user-attachments/assets/58e0237c-4d36-40de-b428-53051d982026)

# üåü Key Features

1. **Diverse LLM Provider Support**:

- ‚òÅÔ∏è Major LLM Cloud Services: OpenAI, Gemini, Anthropic, and more
- üîó AI Web Service Integration: Claude, Perplexity, [Poe](https://poe.com/), and others
- üíª Local Model Support with Ollama, LM Studio

2. **AI Assistants &amp; Conversations**:

- üìö 300+ Pre-configured AI Assistants
- ü§ñ Custom Assistant Creation
- üí¨ Multi-model Simultaneous Conversations

3. **Document &amp; Data Processing**:

- üìÑ Supports Text, Images, Office, PDF, and more
- ‚òÅÔ∏è WebDAV File Management and Backup
- üìä Mermaid Chart Visualization
- üíª Code Syntax Highlighting

4. **Practical Tools Integration**:

- üîç Global Search Functionality
- üìù Topic Management System
- üî§ AI-powered Translation
- üéØ Drag-and-drop Sorting
- üîå Mini Program Support
- ‚öôÔ∏è MCP(Model Context Protocol) Server

5. **Enhanced User Experience**:

- üñ•Ô∏è Cross-platform Support for Windows, Mac, and Linux
- üì¶ Ready to Use - No Environment Setup Required
- üé® Light/Dark Themes and Transparent Window
- üìù Complete Markdown Rendering
- ü§≤ Easy Content Sharing

# üìù Roadmap

We&#039;re actively working on the following features and improvements:

1. üéØ **Core Features**

- Selection Assistant with smart content selection enhancement
- Deep Research with advanced research capabilities
- Memory System with global context awareness
- Document Preprocessing with improved document handling
- MCP Marketplace for Model Context Protocol ecosystem

2. üóÇ **Knowledge Management**

- Notes and Collections
- Dynamic Canvas visualization
- OCR capabilities
- TTS (Text-to-Speech) support

3. üì± **Platform Support**

- HarmonyOS Edition (PC)
- Android App (Phase 1)
- iOS App (Phase 1)
- Multi-Window support
- Window Pinning functionality
- Intel AI PC (Core Ultra) Support

4. üîå **Advanced Features**

- Plugin System
- ASR (Automatic Speech Recognition)
- Assistant and Topic Interaction Refactoring

Track our progress and contribute on our [project board](https://github.com/orgs/CherryHQ/projects/7).

Want to influence our roadmap? Join our [GitHub Discussions](https://github.com/CherryHQ/cherry-studio/discussions) to share your ideas and feedback!

# üåà Theme

- Theme Gallery: &lt;https://cherrycss.com&gt;
- Aero Theme: &lt;https://github.com/hakadao/CherryStudio-Aero&gt;
- PaperMaterial Theme: &lt;https://github.com/rainoffallingstar/CherryStudio-PaperMaterial&gt;
- Claude dynamic-style: &lt;https://github.com/bjl101501/CherryStudio-Claudestyle-dynamic&gt;
- Maple Neon Theme: &lt;https://github.com/BoningtonChen/CherryStudio_themes&gt;

Welcome PR for more themes

# ü§ù Contributing

We welcome contributions to Cherry Studio! Here are some ways you can contribute:

1. **Contribute Code**: Develop new features or optimize existing code.
2. **Fix Bugs**: Submit fixes for any bugs you find.
3. **Maintain Issues**: Help manage GitHub issues.
4. **Product Design**: Participate in design discussions.
5. **Write Documentation**: Improve user manuals and guides.
6. **Community Engagement**: Join discussions and help users.
7. **Promote Usage**: Spread the word about Cherry Studio.

Refer to the [Branching Strategy](docs/en/guides/branching-strategy.md) for contribution guidelines

## Getting Started

1. **Fork the Repository**: Fork and clone it to your local machine.
2. **Create a Branch**: For your changes.
3. **Submit Changes**: Commit and push your changes.
4. **Open a Pull Request**: Describe your changes and reasons.

For more detailed guidelines, please refer to our [Contributing Guide](CONTRIBUTING.md).

Thank you for your support and contributions!

# üîß Developer Co-creation Program

We are launching the Cherry Studio Developer Co-creation Program to foster a healthy and positive-feedback loop within the open-source ecosystem. We believe that great software is built collaboratively, and every merged pull request breathes new life into the project.

We sincerely invite you to join our ranks of contributors and shape the future of Cherry Studio with us.

## Contributor Rewards Program

To give back to our core contributors and create a virtuous cycle, we have established the following long-term incentive plan.

**The inaugural tracking period for this program will be Q3 2025 (July, August, September). Rewards for this cycle will be distributed on October 1st.**

Within any tracking period (e.g., July 1st to September 30th for the first cycle), any developer who contributes more than **30 meaningful commits** to any of Cherry Studio&#039;s open-source projects on GitHub will be eligible for the following benefits:

- **Cursor Subscription Sponsorship**: Receive a **$70 USD** credit or reimbursement for your [Cursor](https://cursor.sh/) subscription, making AI your most efficient coding partner.
- **Unlimited Model Access**: Get **unlimited** API calls for the **DeepSeek** and **Qwen** models.
- **Cutting-Edge Tech Access**: Enjoy occasional perks, including API access to models like **Claude**, **Gemini**, and **OpenAI**, keeping you at the forefront of technology.

## Growing Together &amp; Future Plans

A vibrant community is the driving force behind any sustainable open-source project. As Cherry Studio grows, so will our rewards program. We are committed to continuously aligning our benefits with the best-in-class tools and resources in the industry. This ensures our core contributors receive meaningful support, creating a positive cycle where developers, the community, and the project grow together.

**Moving forward, the project will also embrace an increasingly open stance to give back to the entire open-source community.**

## How to Get Started?

We look forward to your first Pull Request!

You can start by exploring our repositories, picking up a `good first issue`, or proposing your own enhancements. Every commit is a testament to the spirit of open source.

Thank you for your interest and contributions.

Let&#039;s build together.

# üè¢ Enterprise Edition

Building on the Community Edition, we are proud to introduce **Cherry Studio Enterprise Edition**‚Äîa privately-deployable AI productivity and management platform designed for modern teams and enterprises.

The Enterprise Edition addresses core challenges in team collaboration by centralizing the management of AI resources, knowledge, and data. It empowers organizations to enhance efficiency, foster innovation, and ensure compliance, all while maintaining 100% control over their data in a secure environment.

## Core Advantages

- **Unified Model Management**: Centrally integrate and manage various cloud-based LLMs (e.g., OpenAI, Anthropic, Google Gemini) and locally deployed private models. Employees can use them out-of-the-box without individual configuration.
- **Enterprise-Grade Knowledge Base**: Build, manage, and share team-wide knowledge bases. Ensures knowledge retention and consistency, enabling team members to interact with AI based on unified and accurate information.
- **Fine-Grained Access Control**: Easily manage employee accounts and assign role-based permissions for different models, knowledge bases, and features through a unified admin backend.
- **Fully Private Deployment**: Deploy the entire backend service on your on-premises servers or private cloud, ensuring your data remains 100% private and under your control to meet the strictest security and compliance standards.
- **Reliable Backend Services**: Provides stable API services and enterprise-grade data backup and recovery mechanisms to ensure business continuity.

## ‚ú® Online Demo

**üîó [Cherry Studio Enterprise](https://www.cherry-ai.com/enterprise)**

## Version Comparison

| Feature           | Community Edition                                                                    | Enterprise Edition                                                                                                                      |
| :---------------- | :----------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------- |
| **Open Source**   | ‚úÖ Yes                                                                               | ‚≠ïÔ∏è Partially released to customers                                                                                                      |
| **Cost**          | [AGPL-3.0 License](https://github.com/CherryHQ/cherry-studio?tab=AGPL-3.0-1-ov-file) | Buyout / Subscription Fee                                                                                                               |
| **Admin Backend** | ‚Äî                                                                                    | ‚óè Centralized **Model** Access&lt;br&gt;‚óè **Employee** Management&lt;br&gt;‚óè Shared **Knowledge Base**&lt;br&gt;‚óè **Access** Control&lt;br&gt;‚óè **Data** Backup |
| **Server**        | ‚Äî                                                                                    | ‚úÖ Dedicated Private Deployment                                                                                                         |

## Get the Enterprise Edition

We believe the Enterprise Edition will become your team&#039;s AI productivity engine. If you are interested in Cherry Studio Enterprise Edition and would like to learn more, request a quote, or schedule a demo, please feel free to contact us.

- **For Business Inquiries &amp; Purchasing**:
  **üìß [bd@cherry-ai.com](mailto:bd@cherry-ai.com)**

# üîó Related Projects

- [new-api](https://github.com/QuantumNous/new-api): The next-generation LLM gateway and AI asset management system supports multiple languages.

- [one-api](https://github.com/songquanpeng/one-api): LLM API management and distribution system supporting mainstream models like OpenAI, Azure, and Anthropic. Features a unified API interface, suitable for key management and secondary distribution.

- [Poe](https://poe.com/): Poe gives you access to the best AI, all in one place. Explore GPT-5, Claude Opus 4.1, DeepSeek-R1, Veo 3, ElevenLabs, and millions of others.

- [ublacklist](https://github.com/iorate/ublacklist): Blocks specific sites from appearing in Google search results

# üöÄ Contributors

&lt;a href=&quot;https://github.com/CherryHQ/cherry-studio/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=CherryHQ/cherry-studio&quot; /&gt;
&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;

# üìä GitHub Stats

![Stats](https://repobeats.axiom.co/api/embed/a693f2e5f773eed620f70031e974552156c7f397.svg &quot;Repobeats analytics image&quot;)

# ‚≠êÔ∏è Star History

&lt;a href=&quot;https://www.star-history.com/#CherryHQ/cherry-studio&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=CherryHQ/cherry-studio&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=CherryHQ/cherry-studio&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=CherryHQ/cherry-studio&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

# üìú License

The Cherry Studio Community Edition is governed by the standard GNU Affero General Public License v3.0 (AGPL-3.0), available at https://www.gnu.org/licenses/agpl-3.0.html.

Use of the Cherry Studio Community Edition for commercial purposes is permitted, subject to full compliance with the terms and conditions of the AGPL-3.0 license.

Should you require a commercial license that provides an exemption from the AGPL-3.0 requirements, please contact us at bd@cherry-ai.com.

&lt;!-- Links &amp; Images --&gt;

[deepwiki-shield]: https://img.shields.io/badge/Deepwiki-CherryHQ-0088CC?logo=data:image/svg+xml;base64,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

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[tonyantony300/alt-sendme]]></title>
            <link>https://github.com/tonyantony300/alt-sendme</link>
            <guid>https://github.com/tonyantony300/alt-sendme</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:04 GMT</pubDate>
            <description><![CDATA[Send files and folders anywhere in the world without storing in cloud - any size, any format, no accounts, no restrictions.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tonyantony300/alt-sendme">tonyantony300/alt-sendme</a></h1>
            <p>Send files and folders anywhere in the world without storing in cloud - any size, any format, no accounts, no restrictions.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 5,200</p>
            <p>Forks: 292</p>
            <p>Stars today: 45 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# File transfer doesn&#039;t need to be complicated

&lt;/div&gt;


![AltSendme Header](assets/header.png)

&lt;div align=&quot;center&quot;&gt;

![AltSendme working demo](assets/animation.gif)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

![Version][badge-version]
![Website][badge-website]
![Platforms][badge-platforms]
[![Sponsor][badge-sponsor]](https://github.com/sponsors/tonyantony300)


&lt;/div&gt;



A free and open-source file transfer tool that harnesses the power of [cutting-edge peer-to-peer networking](https://www.iroh.computer), letting you transfer files directly without storing them on cloud servers.

Why rely on WeTransfer, Dropbox, or Google Drive when you can reliably and easily transfer files directly, end-to-end encrypted and without revealing any personal information?

[Drop your Email for receiving major project updates üì´](https://tally.so/r/ob2Vkx)

## Features

- **Send anywhere** ‚Äì Works seamlessly on local networks or across continents.
- **Peer-to-peer direct transfer** ‚Äì Send files straight between devices, with no cloud storage in between.
- **End-to-end encryption** ‚Äì Always-on protection with QUIC + TLS 1.3 for forward and backward secrecy.
- **No accounts or personal info** ‚Äì Transfer files without sign-ups or exposing personal info.
- [**Transfer anything**](https://www.iroh.computer/proto/iroh-blobs) ‚Äì Send files or directories of any size or any format, verified with BLAKE3-based integrity checks.
- **Resumable transfers** ‚Äì Interrupted downloads automatically resume where they left off.
- **Fast &amp; reliable** ‚Äì Capable of saturating multi-gigabit connections for lightning-fast transfers.
- [**NAT traversal via QUIC**](https://www.iroh.computer/docs/faq#does-iroh-use-relay-servers) ‚Äì Secure, low-latency connections using QUIC hole punching with encrypted relay fallback.
- **CLI integration** ‚Äì Interoperable with the [Sendme CLI](https://www.iroh.computer/sendme).
- **Mobile &amp; web** ‚Äì Coming soon.
- **Free &amp; open source** ‚Äì No upload costs, no size limits, and fully community-driven.



## Installation

The easiest way to get started is by downloading one of the following versions for your respective operating system:

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Platform&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;Download&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Windows&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a href=&#039;https://github.com/tonyantony300/alt-sendme/releases/download/v0.3.1/AltSendme_0.3.1_x64-setup.exe&#039;&gt;AltSendme.exe&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;macOS&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a href=&#039;https://github.com/tonyantony300/alt-sendme/releases/download/v0.3.1/AltSendme_0.3.1_universal.dmg&#039;&gt;AltSendme.dmg&lt;/a&gt;&lt;/td&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Linux &lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a href=&#039;https://github.com/tonyantony300/alt-sendme/releases/download/v0.3.1/AltSendme_0.3.1_amd64.deb&#039;&gt;AltSendme.deb&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;


More download options in [GitHub Releases](https://github.com/tonyantony300/alt-sendme/releases).


## How it works 

1. Drop your file or folder - AltSendme creates a one-time share code (called a &quot;ticket&quot;).
2. ¬†Share the ticket via chat, email, or text.
3. Your friend pastes the ticket in their app, and the transfer begins.


## Under the hood ‚öôÔ∏èüõ†Ô∏è

AltSendme uses [Iroh](https://www.iroh.computer) under the hood to enable peer-to-peer file transfer. It is a modern modular alternative to technologies like WebRTC and libp2p.

### Important concepts 

- *Blobs*
- *Tickets*
- *Peer Discovery*, *Hole-punching* &amp; *NAT traversal*
- *QUIC* &amp; *End-to-end encryption*
- *Relays*


### 1. Blobs

Content-addressed blob storage and transfer. `iroh-blobs` implements request/response and streaming transfers of arbitrary-sized byte blobs, using BLAKE3-verified streams and content-addressed links.

- Blob: an opaque sequence of bytes (no embedded metadata).
- Link: a 32-byte BLAKE3 hash that identifies a blob.
- HashSeq: a blob that contains a sequence of links (useful for chunking/trees).
- Provider / Requester: provider serves data; requester fetches it. An endpoint can be both.

### 2. Tickets

Tickets are a way to share dialing information between iroh endpoints. They&#039;re a single token that contains everything needed to connect to another endpoint, or to fetch a blob in this case. Contains Ed25519 NodeIds: Your device&#039;s cryptographic identity for authentication.They&#039;re also very powerful. It&#039;s worth pointing out this setup is considerably better than full peer-2-peer systems, which broadcast your IP to peers. Instead in iroh, tickets are used to form a &quot;cozy network&quot; between peers you explicitly want to connect with. It&#039;s possible to go &quot;full p2p&quot; &amp; configure your app to broadcast dialing details, but tickets represent a better middle-ground default.


### 3. Peer Discovery, NAT Traversal &amp; Hole Punching

Peers register with an open-source public relay servers at startup to help traverse firewalls and NATs, enabling connection setup. Once connected, Iroh uses QUIC hole punching to try and establish a direct peer-to-peer connection, bypassing the relay. If direct connection is possible, communication happens directly between peers with end-to-end encryption; otherwise, the relay operates only temporarily as a fallback. This enables smooth reliable connections between peers within local-network and across the internet.

###  4. QUIC &amp; Encryption

QUIC is a modern transport protocol built on UDP, designed to reduce latency and improve web performance over TCP. Developed originally by Google and now standardized by the IETF as HTTP/3&#039;s foundation, it integrates TLS 1.3 encryption directly into the protocol.

QUIC allows following super-powers:
* encryption &amp; authentication
* stream multiplexing
    * no head-of-line blocking issues
    * stream priorities
    * one shared congestion controller
* an encrypted, unreliable datagram transport
* zero round trip time connection establishment if you&#039;ve connected to another endpoint before


### 5. Relays

AltSendme uses open-source public relay servers to support establishing direct connections, to speed up initial connection times, and to provide a fallback should direct connections between two endpoints fail or be impossible otherwise. All connections are end-to-end encrypted. The relay is ‚Äújust another UDP socket‚Äù for sending encrypted packets around. [Read more.](https://docs.iroh.computer/about/faq)


## Roadmap üöß

- Better support for Linux distros, Windows and mac.
- Mobile versions
- Faster transfers
- Easier transfers
- Better insights into transfer process and system/network info
- Advanced user interface for power users and simple functional UI for those who just want to share stuff.
- Features for those who needs better privacy
- Features for those who wants speed and convenience


## Contributing &amp; Community ‚ù§Ô∏è

We‚Äôd love to meet you! Before diving into code or opening a PR, join our [Discord](https://discord.gg/xwb7z22Eve) to hang out, ask questions, and discuss ideas.

It‚Äôs the best place to get context, align on direction, and collaborate with the community.


## Supported Languages
 üá∫üá∏ üá∑üá∫ üá∑üá∏ üá´üá∑ üá®üá≥ üáπüáº üá©üá™ üáØüáµ üáπüá≠ üáÆüáπ üá®üáø üá™üá∏ üáßüá∑ üá∏üá¶ üáÆüá∑ üá∞üá∑ üáÆüá≥ üáµüá± üá∫üá¶ üáπüá∑ üá≥üá¥ üáßüá©

## Troubleshooting

### 1. AltSendme Won&#039;t Launch on Windows (Missing Edge WebView2 Runtime)

#### Symptom

- When you double-click `AltSendme.exe`, nothing happens. No window appears, and Task Manager does not show the process.
- This can affect both the standard installer and the portable version.

#### Cause

- Microsoft Edge WebView2 Runtime is either missing, outdated, or improperly installed on your system.  
  AltSendme depends on WebView2 to render the interface on Windows.

#### How to Fix

1. **Check if WebView2 is installed**
   - Open **Add or Remove Programs** (a.k.a. *Apps &amp; features*) on Windows.
   - Look for **Microsoft Edge WebView2 Runtime**.

2. **Install or Update WebView2**
   - Download the WebView2 Runtime directly from Microsoft: [link](https://developer.microsoft.com/en-us/microsoft-edge/webview2?form=MA13LH).
   - If you prefer an offline installer, download the offline package and run it as an Administrator.

3. **Re-run AltSendme**
   - After installing/updating WebView2, launch `AltSendme.exe` again.
   - If you still encounter problems, reboot your PC and try again.

#### Additional Tips

- If reinstalling once doesn‚Äôt work, uninstall Edge WebView2 completely, then reinstall it with Administrator privileges.
- Verify your Windows installation has the latest updates from Microsoft.

#### Still Stuck?

- Head over to our [Discord](https://discord.gg/xwb7z22Eve) server and open a support discussion with detailed logs of your environment and the steps you‚Äôve taken.


## Development Setup

### Prerequisites

- Rust 1.81+
- Node.js 18+
- npm or yarn

### Getting Started

1. **Fork and clone the repository**:
   ```bash
   git clone https://github.com/your-username/alt-sendme.git
   cd alt-sendme
   ```

2. **Install frontend dependencies**:
   ```bash
   npm install
   ```

3. **Run in development mode**:
   ```bash
   npm run app:dev
   ```

4. **Build for production** (optional):
   ```bash
   npm run app:build -- --no-bundle
   ```


## License

AGPL-3.0

## Privacy Policy

See [PRIVACY.md](PRIVACY.md) for information about how AltSendme handles your data and privacy.

[![Sponsor](https://img.shields.io/badge/sponsor-30363D?style=for-the-badge&amp;logo=GitHub-Sponsors&amp;logoColor=#EA4AAA)](https://github.com/sponsors/tonyantony300) [![Buy Me Coffee](https://img.shields.io/badge/Buy%20Me%20Coffee-FF5A5F?style=for-the-badge&amp;logo=coffee&amp;logoColor=FFFFFF)](https://buymeacoffee.com/tny_antny)


## Contributors

&lt;a href=&quot;https://github.com/tonyantony300/alt-sendme/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=tonyantony300/alt-sendme&quot; /&gt;
&lt;/a&gt;


## Acknowledgements


- [Iroh](https://www.iroh.computer)
- [Tauri](https://v2.tauri.app)


## Contact

Reach me [here](https://www.altsendme.com/en/contact) for suggestions, feedback or media related communication.


Thank you for checking out this project! If you find it useful, consider giving it a star and helping spread the word.




&lt;!-- &lt;div align=&quot;center&quot; style=&quot;color: gray;&quot;&gt;&lt;/div&gt; --&gt;

[badge-website]: https://img.shields.io/badge/website-altsendme.com-orange
[badge-version]: https://img.shields.io/badge/version-0.3.1-blue
[badge-platforms]: https://img.shields.io/badge/platforms-macOS%2C%20Windows%2C%20Linux%2C%20-green
[badge-sponsor]: https://img.shields.io/badge/sponsor-ff69b4


</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[yangshun/tech-interview-handbook]]></title>
            <link>https://github.com/yangshun/tech-interview-handbook</link>
            <guid>https://github.com/yangshun/tech-interview-handbook</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:03 GMT</pubDate>
            <description><![CDATA[Curated coding interview preparation materials for busy software engineers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/yangshun/tech-interview-handbook">yangshun/tech-interview-handbook</a></h1>
            <p>Curated coding interview preparation materials for busy software engineers</p>
            <p>Language: TypeScript</p>
            <p>Stars: 137,169</p>
            <p>Forks: 16,395</p>
            <p>Stars today: 92 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;Tech Interview Handbook&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.techinterviewhandbook.org/&quot;&gt;
    &lt;img src=&quot;assets/logo.svg&quot; alt=&quot;Tech Interview Handbook&quot; width=&quot;400&quot; /&gt;
  &lt;/a&gt;
  &lt;br /&gt;
  &lt;h3&gt;
    &lt;a href=&quot;https://www.techinterviewhandbook.org/&quot;&gt;Read on the website&lt;/a&gt;
  &lt;/h3&gt;
  &lt;p&gt;
    Join/follow us on &lt;a href=&quot;https://discord.com/invite/usMqNaPczq&quot; target=&quot;_blank&quot;&gt;Discord&lt;/a&gt; | &lt;a href=&quot;https://twitter.com/techinterviewhb&quot; target=&quot;_blank&quot;&gt;ùïè (Twitter)&lt;/a&gt; | &lt;a href=&quot;https://t.me/techinterviewhandbook&quot; target=&quot;_blank&quot;&gt;Telegram&lt;/a&gt; |  &lt;a href=&quot;https://facebook.com/techinterviewhandbook&quot; target=&quot;_blank&quot;&gt;Facebook&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

---

&lt;a href=&quot;https://www.techinterviewhandbook.org/software-engineering-interview-guide/&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;assets/start-reading-button.jpg&quot; alt=&quot;Start Reading Tech Interview Handbook&quot; /&gt;
&lt;/a&gt;

## What is this?

Not everyone has the time to do a few hundred LeetCode questions. Here are _free and curated_ technical interview preparation materials for busy engineers, brought to you by me, the author of [Blind 75](https://www.teamblind.com/post/New-Year-Gift---Curated-List-of-Top-75-LeetCode-Questions-to-Save-Your-Time-OaM1orEU). Over 1,000,000 people have benefitted from this handbook!

Besides the usual algorithm questions, other **awesome** stuff includes:

- [Best practice questions](https://www.techinterviewhandbook.org/coding-interview-study-plan/) for coding interviews
- [Grind 75](https://www.techinterviewhandbook.org/grind75/) - the next evolution of Blind 75, bigger and better
- [How to prepare](https://www.techinterviewhandbook.org/coding-interview-prep/) for coding interviews
- [Coding interview best practices](https://www.techinterviewhandbook.org/coding-interview-cheatsheet/) - Straight-to-the-point Do&#039;s and Don&#039;ts
- [Algorithm cheatsheets and tips](https://www.techinterviewhandbook.org/algorithms/study-cheatsheet/) categorized by topic
- [Step-by-step Software Engineer resume guide](https://www.techinterviewhandbook.org/resume/) to prepare a FAANG-ready resume
- [Behavioral questions](https://www.techinterviewhandbook.org/behavioral-interview-questions/) asked by the top tech companies
- [Front end interview preparation](https://www.frontendinterviewhandbook.com)

Help from you in contributing content would be very much appreciated!

## Why would you read this?

This repository has **practical** content that covers all phases of a technical interview, from applying for a job to passing the interviews to offer negotiation. Technically competent candidates might still find the non-technical content helpful.

The information in this repository is condensed. Ultimately, the key to succeeding in technical interviews is consistent practice and I don&#039;t want to bore you with too many words. I tell you the minimum you need to know on how to go about navigating the interview process, you go and practice and land your dream job.

## Who is this for?

Anybody who wants to land a job at a tech company but is new to technical interviews, seasoned engineers who have not been on the other side of the interviewing table in a while and want to get back into the game, or anyone who wants to be better at technical interviewing.

---

&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;üí° Stop grinding mindlessly! Study coding question patterns efficiently with
    &lt;a href=&quot;https://www.designgurus.io/course/grokking-the-coding-interview?aff=kJSIoU&quot;&gt;Grokking the Coding Interview&lt;/a&gt; by Design Gurus üí°
  &lt;/h3&gt;
&lt;/div&gt;

---

## How is this repository different?

There are many awesome books like &quot;Cracking the Coding Interview&quot; and interview-related repositories out there on GitHub, what makes this repository different? The difference is that many existing interview repositories contain mainly links to external resources whereas this repository contains top-quality curated content directly for your consumption.

Also, existing resources focus mainly on algorithm questions and lack coverage for more domain-specific and non-technical questions. This handbook aims to cover content beyond the typical algorithmic coding questions. üòé

## Looking for interview courses?

### [AlgoMonster](https://shareasale.com/r.cfm?b=1873647&amp;u=3114753&amp;m=114505&amp;urllink=&amp;afftrack=)

AlgoMonster aims to help you ace the technical interview **in the shortest time possible**. By Google engineers, AlgoMonster uses a data-driven approach to teach you the most useful key question patterns and has contents to help you quickly revise basic data structures and algorithms. Best of all, AlgoMonster is not subscription-based - pay a one-time fee and get **lifetime access**. [**Join today for a 70% discount ‚Üí**](https://shareasale.com/r.cfm?b=1873647&amp;u=3114753&amp;m=114505&amp;urllink=&amp;afftrack=)

### [Grokking the Coding Interview: Patterns for Coding Questions](https://www.designgurus.io/course/grokking-the-coding-interview?aff=kJSIoU)

This course by Design Gurus expands upon the questions on the recommended practice questions but approaches the practicing from a questions pattern perspective, which is an approach I also agree with for learning and have personally used to get better at coding interviews. The course allows you to practice selected questions in Java, Python, C++, JavaScript and also provides sample solutions in those languages. **Learn and understand patterns, not memorize answers!** [**Get lifetime access today ‚Üí**](https://www.designgurus.io/course/grokking-the-coding-interview?aff=kJSIoU)

## Looking for Front End content?

Front-end-related content has been moved to a separate website - [Front End Interview Handbook](https://frontendinterviewhandbook.com).

## Looking for System Design content?

We&#039;re still working on System Design content. In the meanwhile, check out [ByteByteGo&#039;s System Design Interview course](https://bytebytego.com?fpr=techinterviewhandbook) or Design Gurus&#039; [Grokking the System Design Interview course](https://www.designgurus.io/course/grokking-the-system-design-interview?aff=kJSIoU), which in our opinion are among the most useful resources for getting started on system design interviews preparation.

## Contents

A [Docusaurus](https://github.com/facebook/docusaurus) website has been created to provide a better reading experience. Check out the website [here](https://www.techinterviewhandbook.org)!

---

&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;üí° Stop the grind and study with a plan! Developed by Google engineers, &lt;a href=&quot;https://shareasale.com/r.cfm?b=1873647&amp;u=3114753&amp;m=114505&amp;urllink=&amp;afftrack=&quot;&gt;AlgoMonster&lt;/a&gt; is the fastest way to get a software engineering job. &lt;a href=&quot;https://shareasale.com/r.cfm?b=1873647&amp;u=3114753&amp;m=114505&amp;urllink=&amp;afftrack=&quot;&gt;Join today for a 70% discount!&lt;/a&gt; üí°&lt;/h3&gt;
&lt;/div&gt;

---

## Related

If you are interested in how data structures are implemented, check out [Lago](https://github.com/yangshun/lago), a Data Structures and Algorithms library for JavaScript. It is pretty much still WIP but I intend to make it into a library that can be used in production and also a reference resource for revising Data Structures and Algorithms.

## Contributing

There are no formal contributing guidelines at the moment as things are still in flux and we might find a better approach to structure content as we go along. You are welcome to contribute whatever you think will be helpful to fellow engineers. If you would like to contribute content for different domains, feel free to create an issue or submit a pull request and we can discuss further.

### Contributors

This project exists thanks to all the people who contributed. [[Contribute](CONTRIBUTING.md)]. &lt;a href=&quot;https://github.com/yangshun/tech-interview-handbook/graphs/contributors&quot;&gt;&lt;img src=&quot;https://opencollective.com/tech-interview-handbook/contributors.svg?width=890&amp;button=false&quot;&gt;&lt;/a&gt;

### Backers

Thank you to all our backers! üôè [[Become a backer](https://opencollective.com/tech-interview-handbook#backer)]

&lt;a href=&quot;https://opencollective.com/tech-interview-handbook#backers&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/tech-interview-handbook/backers.svg?width=890&quot;&gt;&lt;/a&gt;

&lt;a href=&quot;https://www.buymeacoffee.com/yangshun&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png&quot; alt=&quot;Buy Me A Coffee&quot; style=&quot;height: auto !important; width: auto !important;&quot;&gt;&lt;/a&gt;

### Sponsors

Support this project by becoming a sponsor. Your logo/profile picture will show up here with a link to your website. [[Become a sponsor](https://opencollective.com/tech-interview-handbook#sponsor)]

&lt;a href=&quot;https://opencollective.com/tech-interview-handbook/sponsor/0/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/tech-interview-handbook/sponsor/0/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/tech-interview-handbook/sponsor/1/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/tech-interview-handbook/sponsor/1/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/tech-interview-handbook/sponsor/2/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/tech-interview-handbook/sponsor/2/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/tech-interview-handbook/sponsor/3/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/tech-interview-handbook/sponsor/3/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/tech-interview-handbook/sponsor/4/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/tech-interview-handbook/sponsor/4/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/tech-interview-handbook/sponsor/5/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/tech-interview-handbook/sponsor/5/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/tech-interview-handbook/sponsor/6/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/tech-interview-handbook/sponsor/6/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/tech-interview-handbook/sponsor/7/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/tech-interview-handbook/sponsor/7/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/tech-interview-handbook/sponsor/8/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/tech-interview-handbook/sponsor/8/avatar.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/tech-interview-handbook/sponsor/9/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/tech-interview-handbook/sponsor/9/avatar.svg&quot;&gt;&lt;/a&gt;

## Disclaimer

I am providing code in the repository to you under an open source license. Because this is my personal repository, the license you receive to my code is from me and not my employer (Meta).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[supermemoryai/supermemory]]></title>
            <link>https://github.com/supermemoryai/supermemory</link>
            <guid>https://github.com/supermemoryai/supermemory</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:02 GMT</pubDate>
            <description><![CDATA[Memory engine and app that is extremely fast, scalable. The Memory API for the AI era.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/supermemoryai/supermemory">supermemoryai/supermemory</a></h1>
            <p>Memory engine and app that is extremely fast, scalable. The Memory API for the AI era.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 15,810</p>
            <p>Forks: 1,608</p>
            <p>Stars today: 381 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot; style=&quot;padding-bottom:20px;padding-top:20px&quot;&gt;
  &lt;picture&gt;
    &lt;source srcset=&quot;apps/web/public/logo-fullmark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
    &lt;source srcset=&quot;apps/web/public/logo-light-fullmark.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
    &lt;img src=&quot;apps/web/public/logo-fullmark.svg&quot; alt=&quot;supermemory Logo&quot; width=&quot;400&quot; /&gt;
  &lt;/picture&gt;
  &lt;br/&gt;&lt;br/&gt;
  &lt;em&gt;Your AI second brain for saving and organizing everything that matters.&lt;/em&gt;
  &lt;br/&gt;&lt;br/&gt;
  &lt;a href=&quot;https://app.supermemory.ai&quot; style=&quot;text-decoration: none;&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Web-App-000000?style=for-the-badge&quot; alt=&quot;Web App&quot; /&gt;
  &lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://chromewebstore.google.com/detail/supermemory/afpgkkipfdpeaflnpoaffkcankadgjfc&quot; style=&quot;text-decoration: none;&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Chrome-Extension-4285F4?style=for-the-badge&amp;logo=googlechrome&amp;logoColor=white&quot; alt=&quot;Chrome Extension&quot; /&gt;
  &lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.raycast.com/supermemory/supermemory&quot; style=&quot;text-decoration: none;&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Raycast-Extension-FF6363?style=for-the-badge&amp;logo=raycast&amp;logoColor=white&quot; alt=&quot;Raycast Extension&quot; /&gt;
  &lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://supermemory.link/discord&quot; style=&quot;text-decoration: none;&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Discord&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p style=&quot;font-size: 0.9em; color: #666;&quot;&gt;
    &lt;strong&gt;Building with Supermemory?&lt;/strong&gt; Check out the &lt;a href=&quot;https://console.supermemory.ai?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=consumer_app&quot;&gt;Developer Console&lt;/a&gt; and &lt;a href=&quot;https://docs.supermemory.ai?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=consumer_app&quot;&gt;Documentation&lt;/a&gt; for API access.
&lt;/p&gt;
&lt;p style=&quot;font-size: 0.9em; color: #666;&quot;&gt;
    &lt;strong&gt;Want to self-host?&lt;/strong&gt; See our &lt;a href=&quot;https://supermemory.ai/docs/deployment/self-hosting#self-hosting&quot;&gt;Self-Hosting Guide&lt;/a&gt; for enterprise deployment options.
&lt;/p&gt;
&lt;br/&gt;

&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/landing-page.jpeg&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

## Features

### Core Functionality

- **[Add Memories from Any Content](#add-memory)**: Easily add memories from URLs, PDFs, and plain text‚Äîjust paste, upload, or link.
- **[Chat with Your Memories](#chat-memories)**: Converse with your stored content using natural language chat.
- **[Supermemory MCP Integration](#mcp-integration)**: Seamlessly connect with all major AI tools (Claude, Cursor, etc.) via Supermemory MCP.
- **[Browser Extension](#browser-extension)**: Save memories directly from your browser with integrations for ChatGPT, Claude, and Twitter/X.
- **[Raycast Extension](#raycast-extension)**: Add and search memories directly from Raycast with keyboard shortcuts.

## How do I use this?

Go to [app.supermemory.ai](https://app.supermemory.ai) and sign in with your account

1. &lt;a id=&quot;add-memory&quot;&gt;&lt;/a&gt;Start Adding Memory with your choice of format (Note, Link, File)
&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/add-memory.png&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

2. You can also Connect to your favourite services (Notion, Google Drive, OneDrive)
&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/add-connections.png&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

3. &lt;a id=&quot;chat-memories&quot;&gt;&lt;/a&gt;Once Memories are added, you can chat with Supermemory by clicking on &quot;Open Chat&quot; and retrieve info from your saved memories
&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/chat.png&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

4. &lt;a id=&quot;mcp-integration&quot;&gt;&lt;/a&gt;Add MCP to your AI Tools (by clicking on &quot;Connect to your AI&quot; and select the AI tool you are trying to integrate)
&lt;div align=&quot;center&quot; style=&quot;padding-bottom:10px;padding-top:10px&quot;&gt;
  &lt;img src=&quot;apps/web/public/mcp.png&quot; alt=&quot;supermemory&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

5. &lt;a id=&quot;browser-extension&quot;&gt;&lt;/a&gt;**Browser Extension**: Install the [Chrome/Edge extension](https://chromewebstore.google.com/detail/supermemory/afpgkkipfdpeaflnpoaffkcankadgjfc) to save memories directly from any webpage, integrate with ChatGPT and Claude conversations, and import from Twitter/X. Right-click on any content or use the extension popup to save memories instantly.

6. &lt;a id=&quot;raycast-extension&quot;&gt;&lt;/a&gt;**Raycast Extension**: Install the [Raycast extension](https://www.raycast.com/supermemory/supermemory) to add and search memories directly from Raycast. Use the &quot;Add Memory&quot; command to quickly save content, or &quot;Search Memories&quot; to find and retrieve your saved information with keyboard shortcuts.

## Support

Have questions or feedback? We&#039;re here to help:

- Email: [support@supermemory.ai](mailto:support@supermemory.ai)
- Discord: [Join our Discord server](https://supermemory.link/discord)
- Documentation: [docs.supermemory.ai](https://docs.supermemory.ai)

## Contributing

We welcome contributions from developers of all skill levels! Whether you&#039;re fixing bugs, adding features, or improving documentation, your help makes supermemory better for everyone.

For detailed guidelines, development setup, coding standards, and the complete contribution workflow, please see our [**Contributing Guide**](CONTRIBUTING.md).

### Ways to Contribute

- üêõ **Bug fixes** - Help us squash those pesky issues
- ‚ú® **New features** - Add functionality that users will love
- üé® **UI/UX improvements** - Make the interface more intuitive
- ‚ö° **Performance optimizations** - Help us make supermemory faster

Check out our [Issues](https://github.com/supermemoryai/supermemory/issues) page for `good first issue` and `help wanted` labels to get started!

## Updates &amp; Roadmap

Stay up to date with the latest improvements:

- [Changelog](https://docs.supermemory.ai/changelog/overview)
- [X](https://x.com/supermemory).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[codeforreal1/compressO]]></title>
            <link>https://github.com/codeforreal1/compressO</link>
            <guid>https://github.com/codeforreal1/compressO</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:01 GMT</pubDate>
            <description><![CDATA[Convert any video into a tiny size.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/codeforreal1/compressO">codeforreal1/compressO</a></h1>
            <p>Convert any video into a tiny size.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,081</p>
            <p>Forks: 115</p>
            <p>Stars today: 170 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
   &lt;img width=&quot;100&quot; height=&quot;100&quot; src=&quot;public/logo.png&quot; alt=&quot;Logo&quot; /&gt;
  &lt;/div&gt;
	&lt;h1 align=&quot;center&quot;&gt;CompressO&lt;/h1&gt;
	&lt;p align=&quot;center&quot;&gt;
		Compress any video into a tiny size.
    &lt;/p&gt;
    &lt;i align=&quot;center&quot;&gt;
		CompressO (üîâ pronounced like &quot;Espresso&quot; ) is a free and open-sourced cross-platform video compression app powered by FFmpeg.
    &lt;/i&gt;
    &lt;br /&gt;
    &lt;p align=&quot;center&quot;&gt;
		Available for &lt;strong&gt;Linux&lt;/strong&gt;, &lt;strong&gt;Windows&lt;/strong&gt; &amp; &lt;strong&gt;MacOS&lt;/strong&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;strong&gt;Download üì¶&lt;/strong&gt;
    &lt;/p&gt;
    &lt;div&gt;
      &lt;a href=&quot;https://github.com/codeforreal1/compressO/releases&quot;&gt;
        &lt;img alt=&quot;Linux&quot; src=&quot;https://img.shields.io/badge/-Linux-yellow?style=flat-square&amp;logo=linux&amp;logoColor=black&amp;color=orange&quot; /&gt;
      &lt;/a&gt;
      &lt;a href=&quot;https://github.com/codeforreal1/compressO/releases&quot;&gt;
        &lt;img alt=&quot;Windows&quot; src=&quot;https://img.shields.io/badge/-Windows-blue?style=flat-square&amp;logo=windows&amp;logoColor=white&quot; /&gt;
      &lt;/a&gt;
      &lt;a href=&quot;https://github.com/codeforreal1/compressO/releases&quot;&gt;
        &lt;img alt=&quot;macOS&quot; src=&quot;https://img.shields.io/badge/-macOS-black?style=flat-square&amp;logo=apple&amp;logoColor=white&quot; /&gt;
      &lt;/a&gt;
    &lt;/div&gt;
    &lt;br /&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;public/screenshot.png&quot; alt=&quot;Screenshot&quot; height=&quot;500&quot; style=&quot;border-radius: 16px;&quot; /&gt;
&lt;/div&gt;

### Tech ‚å®

This app is created using [Tauri](https://tauri.app/), a Rustü¶Ä framework for building a cross-platform desktop app. It uses [Vite](https://vite.dev/) as a frontend layer. The compression is done entirely by [FFmpeg](https://ffmpeg.org/) using platform specific standalone binaries.
The app works completely offline and no any network requests is made to/from the app.

### Downloads ‚¨áÔ∏è

Download installers for the specific platform can be accessed from the [releases](https://github.com/codeforreal1/compressO/releases) page.

&lt;strong&gt;Installer Info:&lt;/strong&gt;

- `CompressO_amd64.deb`: Debian derivative of Linux like Ubuntu
- `CompressO_amd64.AppImage`: Universal package for all Linux distros
- `CompressO_aarch64.dmg` : For Macbooks with Apple Silicon Chips
- `CompressO_x64.dmg` : For Macbooks with Intel Chip
- `CompressO_x64.msi`: Windows 64 bit
- `CompressO_x86.msi`: Windows 32 bit

### Roadmap üèÅ

- [x] Cancel during compression
- [x] Drag &amp; Drop video
- [x] Mute video
- [ ] Batch compression
      ...

### FAQs ‚ùì

1.  &lt;strong&gt; MacOS: &quot;CompressO&quot; is damaged and can&#039;t be opened. You should move it to trash. &lt;/strong&gt;
    ![&quot;CompressO&quot; is damaged and can&#039;t be opened. You should move it to trash.](assets/image.png)
    &lt;p&gt;
    This error is shown by Apple to gatekeep app developers from using their apps unless it&#039;s signed by Apple after paying $100/year fee. The message is completely misleading since the app is not damaged at all. Since this is a free app, I&#039;m not going to go Apple&#039;s route just to appease them to make people trust my app. Here&#039;s a simple solution for this issue. Open your terminal and run the command:
    &lt;/p&gt;

        ```
        xattr -cr /Applications/CompressO.app
        ```

      &lt;p&gt;
           If you don&#039;t feel comfortable applying the above solution, you can simply move the app to trash (which also means you cannot use CompressO on your Mac).
        &lt;/p&gt;

2.  &lt;strong&gt; MacOS: &quot;CompressO&quot; cannot be opened because developer cannot be verified. &lt;/strong&gt;

    ![&quot;CompressO&quot; cannot be opened because developer cannot be verified.](assets/image-1.png)

      &lt;p&gt;
        This error is same as the one above on FAQ 1. It&#039;s just, Apple made the message different to scare the end user. Please have a look at the solution above.
          &lt;/p&gt;

    &lt;br /&gt;

3.  &lt;strong&gt;Windows: Microsoft Defender SmartScreen prevented an unrecognized app from starting. Running this app might put your PC at risk.&lt;/strong&gt;
    ![alt text](assets/image-2.png)

    This is because you downloaded the windows installer from outside source and Windows Defender is warning you before installation. You can simply click on &quot;More Info&quot; and proceed with the installation.

4.  &lt;strong&gt;App not working on Debian 13 &amp; Ubuntu 24 &lt;/strong&gt;
    &lt;p&gt;
    Tauri seems to be missing some packages that was removed in Debian 13 and it&#039;s derivatives like Ubuntu 24. Tauri team is investigating the issue. No solution atm, unfortunately.
    &lt;/p&gt;

### License üö®

&lt;a href=&quot;./LICENSE&quot;&gt;AGPL 3.0 License&lt;/a&gt;

&lt;p className=&quot;block text-sm&quot;&gt;
This software uses libraries from the FFmpeg project under the LGPLv2.1.
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>