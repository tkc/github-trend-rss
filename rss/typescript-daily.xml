<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Fri, 23 Jan 2026 00:05:51 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[remotion-dev/remotion]]></title>
            <link>https://github.com/remotion-dev/remotion</link>
            <guid>https://github.com/remotion-dev/remotion</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:51 GMT</pubDate>
            <description><![CDATA[üé• Make videos programmatically with React]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/remotion-dev/remotion">remotion-dev/remotion</a></h1>
            <p>üé• Make videos programmatically with React</p>
            <p>Language: TypeScript</p>
            <p>Stars: 26,912</p>
            <p>Forks: 1,582</p>
            <p>Stars today: 537 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/remotion-dev/logo&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-dark.apng&quot;&gt;
      &lt;img alt=&quot;Animated Remotion Logo&quot; src=&quot;https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-light.gif&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

[![Discord Shield](https://img.shields.io/discord/809501355504959528?color=000000&amp;label=Discord&amp;logo=fdgssdf)](https://remotion.dev/discord)
[![NPM Version](https://img.shields.io/npm/v/remotion.svg?style=flat&amp;color=black)](https://www.npmjs.org/package/remotion)
[![NPM Downloads](https://img.shields.io/npm/dm/remotion.svg?style=flat&amp;color=black&amp;label=Downloads)](https://npmcharts.com/compare/remotion?minimal=true)
[![Open Bounties](https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2Fremotion%2Fbounties%3Fstatus%3Dopen&amp;style=flat&amp;color=black&amp;labelColor=grey&amp;label=Open+Bounties)](https://github.com/remotion-dev/remotion/issues?q=is%3Aopen+label%3A%22%F0%9F%92%8E+Bounty%22+sort%3Aupdated-desc)
&lt;a href=&quot;https://twitter.com/remotion&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/remotion?label=Twitter&amp;color=black&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;

Remotion is a framework for **creating videos programmatically using React.**

## Why create videos in React?

- **Leverage web technologies**: Use all of CSS, Canvas, SVG, WebGL, etc.
- **Leverage programming**: Use variables, functions, APIs, math and algorithms to create new effects
- **Leverage React**: Reusable components, Powerful composition, Fast Refresh, Package ecosystem

## Created with Remotion

&lt;table&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;img style=&quot;width: 290px&quot; src=&quot;https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/fireship-quick.gif&quot; /&gt;
&lt;p&gt;&quot;This video was made with code&quot; &lt;em&gt;- Fireship&lt;/em&gt; &lt;a href=&quot;https://youtu.be/deg8bOoziaE&quot;&gt;Watch&lt;/a&gt; ‚Ä¢ &lt;a href=&quot;https://github.com/wcandillon/remotion-fireship&quot;&gt;Source&lt;/a&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;img style=&quot;width: 240px&quot; src=&quot;https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/unwrapped-2023.gif&quot; /&gt;
&lt;p&gt;GitHub Unwrapped - Personalized Year in Review &lt;a href=&quot;https://www.githubunwrapped.com&quot;&gt;Try&lt;/a&gt; ‚Ä¢ &lt;a href=&quot;https://github.com/remotion-dev/github-unwrapped&quot;&gt;Source&lt;/a&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;em&gt;View more in the &lt;a href=&quot;https://remotion.dev/showcase&quot;&gt;Remotion Showcase&lt;/a&gt;!&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

## Get started

If you already have Node.JS installed, type

```console
npx create-video@latest
```

to get started. Otherwise, read the [installation page](https://www.remotion.dev/docs/) in the documentation.

## Documentation

Documentation: [**remotion.dev/docs**](https://www.remotion.dev/docs)  
API Reference: [**remotion.dev/api**](https://www.remotion.dev/api)

## License

Be aware of that Remotion has a special license and requires obtaining a company license in some cases. Read the [LICENSE](LICENSE.md) page for more information.

## Contributing

Please read [CONTRIBUTING.md](CONTRIBUTING.md) to learn about contributing to this project.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[iOfficeAI/AionUi]]></title>
            <link>https://github.com/iOfficeAI/AionUi</link>
            <guid>https://github.com/iOfficeAI/AionUi</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:50 GMT</pubDate>
            <description><![CDATA[Free, local, open-source Cowork for Gemini CLI, Claude Code, Codex, Opencode, Qwen Code, Goose Cli, Auggie, and more | üåü Star if you like it!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/iOfficeAI/AionUi">iOfficeAI/AionUi</a></h1>
            <p>Free, local, open-source Cowork for Gemini CLI, Claude Code, Codex, Opencode, Qwen Code, Goose Cli, Auggie, and more | üåü Star if you like it!</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,194</p>
            <p>Forks: 714</p>
            <p>Stars today: 554 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[mastra-ai/mastra]]></title>
            <link>https://github.com/mastra-ai/mastra</link>
            <guid>https://github.com/mastra-ai/mastra</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:49 GMT</pubDate>
            <description><![CDATA[From the team behind Gatsby, Mastra is a framework for building AI-powered applications and agents with a modern TypeScript stack.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mastra-ai/mastra">mastra-ai/mastra</a></h1>
            <p>From the team behind Gatsby, Mastra is a framework for building AI-powered applications and agents with a modern TypeScript stack.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 20,144</p>
            <p>Forks: 1,447</p>
            <p>Stars today: 227 stars today</p>
            <h2>README</h2><pre># Mastra

[![npm version](https://badge.fury.io/js/@mastra%2Fcore.svg)](https://www.npmjs.com/package/@mastra/core)
[![CodeQl](https://github.com/mastra-ai/mastra/actions/workflows/github-code-scanning/codeql/badge.svg)](https://github.com/mastra-ai/mastra/actions/workflows/github-code-scanning/codeql)
[![GitHub Repo stars](https://img.shields.io/github/stars/mastra-ai/mastra)](https://github.com/mastra-ai/mastra/stargazers)
[![Discord](https://img.shields.io/discord/1309558646228779139?logo=discord&amp;label=Discord&amp;labelColor=white&amp;color=7289DA)](https://discord.gg/BTYqqHKUrf)
[![Twitter Follow](https://img.shields.io/twitter/follow/mastra_ai?style=social)](https://x.com/mastra_ai)
[![NPM Downloads](https://img.shields.io/npm/dm/%40mastra%252Fcore)](https://www.npmjs.com/package/@mastra/core)
[![Static Badge](https://img.shields.io/badge/Y%20Combinator-W25-orange)](https://www.ycombinator.com/companies?batch=W25)

Mastra is a framework for building AI-powered applications and agents with a modern TypeScript stack.

It includes everything you need to go from early prototypes to production-ready applications. Mastra integrates with frontend and backend frameworks like React, Next.js, and Node, or you can deploy it anywhere as a standalone server. It&#039;s the easiest way to build, tune, and scale reliable AI products.

## Why Mastra?

Purpose-built for TypeScript and designed around established AI patterns, Mastra gives you everything you need to build great AI applications out-of-the-box.

Some highlights include:

- [**Model routing**](https://mastra.ai/models) - Connect to 40+ providers through one standard interface. Use models from OpenAI, Anthropic, Gemini, and more.

- [**Agents**](https://mastra.ai/docs/agents/overview) - Build autonomous agents that use LLMs and tools to solve open-ended tasks. Agents reason about goals, decide which tools to use, and iterate internally until the model emits a final answer or an optional stopping condition is met.

- [**Workflows**](https://mastra.ai/docs/workflows/overview) - When you need explicit control over execution, use Mastra&#039;s graph-based workflow engine to orchestrate complex multi-step processes. Mastra workflows use an intuitive syntax for control flow (`.then()`, `.branch()`, `.parallel()`).

- [**Human-in-the-loop**](https://mastra.ai/docs/workflows/suspend-and-resume) - Suspend an agent or workflow and await user input or approval before resuming. Mastra uses [storage](https://mastra.ai/docs/server-db/storage) to remember execution state, so you can pause indefinitely and resume where you left off.

- **Context management** - Give your agents the right context at the right time. Provide [conversation history](https://mastra.ai/docs/memory/conversation-history), [retrieve](https://mastra.ai/docs/rag/overview) data from your sources (APIs, databases, files), and add human-like [working](https://mastra.ai/docs/memory/working-memory) and [semantic](https://mastra.ai/docs/memory/semantic-recall) memory so your agents behave coherently.

- **Integrations** - Bundle agents and workflows into existing React, Next.js, or Node.js apps, or ship them as standalone endpoints. When building UIs, integrate with agentic libraries like Vercel&#039;s AI SDK UI and CopilotKit to bring your AI assistant to life on the web.

- [**MCP servers**](https://mastra.ai/docs/tools-mcp/mcp-overview) - Author Model Context Protocol servers, exposing agents, tools, and other structured resources via the MCP interface. These can then be accessed by any system or agent that supports the protocol.

- **Production essentials** - Shipping reliable agents takes ongoing insight, evaluation, and iteration. With built-in [evals](https://mastra.ai/docs/evals/overview) and [observability](https://mastra.ai/docs/observability/overview), Mastra gives you the tools to observe, measure, and refine continuously.

## Get started

The **recommended** way to get started with Mastra is by running the command below:

```shell
npm create mastra@latest
```

Follow the [Installation guide](https://mastra.ai/docs/getting-started/installation) for step-by-step setup with the CLI or a manual install.

If you&#039;re new to AI agents, check out our [templates](https://mastra.ai/docs/getting-started/templates), [course](https://mastra.ai/course), and [YouTube videos](https://youtube.com/@mastra-ai) to start building with Mastra today.

## Documentation

Visit our [official documentation](https://mastra.ai/docs).

## MCP Servers

Learn how to make your IDE a Mastra expert by following the [`@mastra/mcp-docs-server` guide](https://mastra.ai/docs/getting-started/mcp-docs-server).

## Contributing

Looking to contribute? All types of help are appreciated, from coding to testing and feature specification.

If you are a developer and would like to contribute with code, please open an issue to discuss before opening a Pull Request.

Information about the project setup can be found in the [development documentation](./DEVELOPMENT.md)

## Support

We have an [open community Discord](https://discord.gg/BTYqqHKUrf). Come and say hello and let us know if you have any questions or need any help getting things running.

It&#039;s also super helpful if you leave the project a star here at the [top of the page](https://github.com/mastra-ai/mastra)

## Security

We are committed to maintaining the security of this repo and of Mastra as a whole. If you discover a security finding
we ask you to please responsibly disclose this to us at [security@mastra.ai](mailto:security@mastra.ai) and we will get
back to you.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[nexmoe/VidBee]]></title>
            <link>https://github.com/nexmoe/VidBee</link>
            <guid>https://github.com/nexmoe/VidBee</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:48 GMT</pubDate>
            <description><![CDATA[Download videos from almost any website worldwide]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nexmoe/VidBee">nexmoe/VidBee</a></h1>
            <p>Download videos from almost any website worldwide</p>
            <p>Language: TypeScript</p>
            <p>Stars: 4,579</p>
            <p>Forks: 328</p>
            <p>Stars today: 267 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/nexmoe/VidBee&quot;&gt;
    &lt;img src=&quot;build/icon.png&quot; alt=&quot;Logo&quot; width=&quot;80&quot; height=&quot;80&quot;&gt;
  &lt;/a&gt;

  &lt;h3&gt;VidBee&lt;/h3&gt;
  &lt;p&gt;
    &lt;a href=&quot;https://github.com/nexmoe/VidBee/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/nexmoe/VidBee?color=ffcb47&amp;labelColor=black&amp;logo=github&amp;label=Stars&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/nexmoe/VidBee/graphs/contributors&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/nexmoe/VidBee?ogo=github&amp;label=Contributors&amp;labelColor=black&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/nexmoe/VidBee/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/downloads/nexmoe/VidBee/total?color=369eff&amp;labelColor=black&amp;logo=github&amp;label=Downloads&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/nexmoe/VidBee/releases/latest&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/nexmoe/VidBee?color=369eff&amp;labelColor=black&amp;logo=github&amp;label=Latest%20Release&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://x.com/intent/follow?screen_name=nexmoex&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Follow-blue?color=1d9bf0&amp;logo=x&amp;labelColor=black&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://deepwiki.com/nexmoe/VidBee&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://github.com/nexmoe/VidBee/releases/latest&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;screenshots/main-interface.png&quot; alt=&quot;VidBee Desktop&quot; width=&quot;46%&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/nexmoe/VidBee/releases/latest&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;screenshots/download-queue.png&quot; alt=&quot;VidBee Download Queue&quot; width=&quot;46%&quot;/&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
  &lt;/p&gt;
&lt;/div&gt;

VidBee is a modern, open-source video downloader that lets you download videos and audios from 1000+ websites worldwide. Built with Electron and powered by yt-dlp, VidBee offers a clean, intuitive interface with powerful features for all your downloading needs, including RSS auto-download automation that automatically subscribes to feeds and downloads new videos from your favorite creators in the background.

## üëãüèª Getting Started

VidBee is currently under active development, and feedback is welcome for any [issue](https://github.com/nexmoe/VidBee/issues) encountered.

[üì• Download VidBee](https://vidbee.org/download/) | [üìö Documentation](https://docs.vidbee.org)

&gt; [!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay ~

&lt;a href=&quot;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats?repo_id=1081230042&quot; target=&quot;_blank&quot; style=&quot;display: block&quot; align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=1081230042&amp;image_size=auto&amp;color_scheme=dark&quot; width=&quot;655&quot; height=&quot;auto&quot;&gt;
    &lt;img alt=&quot;Performance Stats of nexmoe/VidBee - Last 28 days&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=1081230042&amp;image_size=auto&amp;color_scheme=light&quot; width=&quot;655&quot; height=&quot;auto&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;

&lt;!-- Made with [OSS Insight](https://ossinsight.io/) --&gt;

## ‚ú® Features

### üåç Global Video Download Support

Download videos from almost any website worldwide through the powerful yt-dlp engine. Support for 1000+ sites including YouTube, TikTok, Instagram, Twitter, and many more.

![VidBee Main Interface](screenshots/main-interface.png)

### üé® Best-in-class UI Experience

Modern, clean interface with intuitive operations. One-click pause/resume/retry, real-time progress tracking, and comprehensive download queue management.

![VidBee Download Queue](screenshots/download-queue.png)

### üì° RSS Auto Download

Automatically subscribe to RSS feeds and auto-download new videos in the background from your favorite creators across YouTube, TikTok, and more. Set up RSS subscriptions once, and VidBee will automatically download new uploads without manual intervention, perfect for keeping up with your favorite channels and creators.

## üåê Supported Sites

VidBee supports 1000+ video and audio platforms through yt-dlp. For the complete list of supported sites, visit [https://vidbee.org/supported-sites/](https://vidbee.org/supported-sites/)

## ü§ù Contributing

You are welcome to join the open source community to build together. For more details, check out:

- [Contributing Guide](./CONTRIBUTING.md)
- [DeepWiki Documentation](https://deepwiki.com/nexmoe/VidBee)

## üìÑ License

This project is distributed under the MIT License. See [`LICENSE`](LICENSE) for details.

## üôè Thanks

- [yt-dlp](https://github.com/yt-dlp/yt-dlp) - The powerful video downloader engine
- [FFmpeg](https://ffmpeg.org/) - The multimedia framework for video and audio processing
- [Electron](https://www.electronjs.org/) - Build cross-platform desktop apps
- [React](https://react.dev/) - The UI library
- [Vite](https://vitejs.dev/) - Next generation frontend tooling
- [Tailwind CSS](https://tailwindcss.com/) - Utility-first CSS framework
- [shadcn/ui](https://ui.shadcn.com/) - Beautifully designed components
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[virattt/dexter]]></title>
            <link>https://github.com/virattt/dexter</link>
            <guid>https://github.com/virattt/dexter</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:47 GMT</pubDate>
            <description><![CDATA[An autonomous agent for deep financial research]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/virattt/dexter">virattt/dexter</a></h1>
            <p>An autonomous agent for deep financial research</p>
            <p>Language: TypeScript</p>
            <p>Stars: 8,371</p>
            <p>Forks: 1,041</p>
            <p>Stars today: 248 stars today</p>
            <h2>README</h2><pre># Dexter ü§ñ

Dexter is an autonomous financial research agent that thinks, plans, and learns as it works. It performs analysis using task planning, self-reflection, and real-time market data. Think Claude Code, but built specifically for financial research.


&lt;img width=&quot;1098&quot; height=&quot;659&quot; alt=&quot;Screenshot 2026-01-21 at 5 25 10‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/3bcc3a7f-b68a-4f5e-8735-9d22196ff76e&quot; /&gt;


## Overview

Dexter takes complex financial questions and turns them into clear, step-by-step research plans. It runs those tasks using live market data, checks its own work, and refines the results until it has a confident, data-backed answer.  

**Key Capabilities:**
- **Intelligent Task Planning**: Automatically decomposes complex queries into structured research steps
- **Autonomous Execution**: Selects and executes the right tools to gather financial data
- **Self-Validation**: Checks its own work and iterates until tasks are complete
- **Real-Time Financial Data**: Access to income statements, balance sheets, and cash flow statements
- **Safety Features**: Built-in loop detection and step limits to prevent runaway execution

[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)

&lt;img width=&quot;875&quot; height=&quot;558&quot; alt=&quot;Screenshot 2026-01-21 at 5 22 19‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/72d28363-69ea-4c74-a297-dfa60aa347f7&quot; /&gt;


### Prerequisites

- [Bun](https://bun.com) runtime (v1.0 or higher)
- OpenAI API key (get [here](https://platform.openai.com/api-keys))
- Financial Datasets API key (get [here](https://financialdatasets.ai))
- Tavily API key (get [here](https://tavily.com)) - optional, for web search

#### Installing Bun

If you don&#039;t have Bun installed, you can install it using curl:

**macOS/Linux:**
```bash
curl -fsSL https://bun.com/install | bash
```

**Windows:**
```bash
powershell -c &quot;irm bun.sh/install.ps1|iex&quot;
```

After installation, restart your terminal and verify Bun is installed:
```bash
bun --version
```

### Installing Dexter

1. Clone the repository:
```bash
git clone https://github.com/virattt/dexter.git
cd dexter
```

2. Install dependencies with Bun:
```bash
bun install
```

3. Set up your environment variables:
```bash
# Copy the example environment file (from parent directory)
cp env.example .env

# Edit .env and add your API keys (if using cloud providers)
# OPENAI_API_KEY=your-openai-api-key
# ANTHROPIC_API_KEY=your-anthropic-api-key
# GOOGLE_API_KEY=your-google-api-key
# XAI_API_KEY=your-xai-api-key

# (Optional) If using Ollama locally
# OLLAMA_BASE_URL=http://127.0.0.1:11434

# Other required keys
# FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
# TAVILY_API_KEY=your-tavily-api-key
```

### Usage

Run Dexter in interactive mode:
```bash
bun start
```

Or with watch mode for development:
```bash
bun dev
```

## How to Contribute

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.


## License

This project is licensed under the MIT License.

</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[tambo-ai/tambo]]></title>
            <link>https://github.com/tambo-ai/tambo</link>
            <guid>https://github.com/tambo-ai/tambo</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:46 GMT</pubDate>
            <description><![CDATA[Generative UI SDK for React]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tambo-ai/tambo">tambo-ai/tambo</a></h1>
            <p>Generative UI SDK for React</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,663</p>
            <p>Forks: 220</p>
            <p>Stars today: 558 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/octo-white-background-rounded.png&quot; width=&quot;150&quot;&gt;
  &lt;h1&gt;Tambo AI&lt;/h1&gt;
  &lt;h3&gt;Generative UI for React&lt;/h3&gt;
  &lt;p&gt;Build apps that adapt to your users.&lt;/p&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/@tambo-ai/react&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/%40tambo-ai%2Freact?logo=npm&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/tambo-ai/tambo/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/tambo-ai/tambo&quot; alt=&quot;License&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/tambo-ai/tambo/commits/main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/last-commit/tambo-ai/tambo&quot; alt=&quot;Last Commit&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/dJNvPEHth6&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1251581895414911016?color=7289da&amp;label=discord&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/tambo-ai/tambo&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/tambo-ai/tambo&quot; alt=&quot;GitHub stars&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/15734&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15734&quot; alt=&quot;tambo-ai/tambo | Trendshift&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.tambo.co&quot;&gt;Documentation&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://discord.gg/dJNvPEHth6&quot;&gt;Discord&lt;/a&gt;
&lt;/p&gt;

---

## What is Tambo?

Tambo is a generative UI SDK for React. Register your components, and the AI decides which ones to render based on natural language conversations.

https://github.com/user-attachments/assets/8381d607-b878-4823-8b24-ecb8053bef23

## Why We Built This

Most software is built around a one-size-fits-all mental model that doesn&#039;t fit every user.

**Users shouldn&#039;t have to learn your app.** Generative UI shows the right components based on what someone is trying to do. First-time users and power users see different things.

**Users shouldn&#039;t have to click through your workflows.** &quot;Show me sales from last quarter grouped by region&quot; should just work. The AI translates what users want into the right interface.

```tsx
const components: TamboComponent[] = [{
  name: &quot;Graph&quot;,
  description: &quot;Displays data as charts&quot;,
  component: Graph,
  propsSchema: z.object({ data: z.array(...), type: z.enum([&quot;line&quot;, &quot;bar&quot;, &quot;pie&quot;]) })
}];
```

## Get Started

```bash
npx tambo create-app my-tambo-app
cd my-tambo-app
npx tambo init      # choose cloud or self-hosted
npm run dev
```

**Tambo Cloud** is a free hosted backend. **Self-hosted** runs on your own infrastructure.

Check out the [pre-built component library](https://ui.tambo.co) for ready-made primitives, or fork a template:

| Template                                                                 | Description                                       |
| ------------------------------------------------------------------------ | ------------------------------------------------- |
| [AI Chat with Generative UI](https://github.com/tambo-ai/tambo-template) | Chat interface with dynamic component generation  |
| [AI Analytics Dashboard](https://github.com/tambo-ai/analytics-template) | Analytics dashboard with AI-powered visualization |

https://github.com/user-attachments/assets/6cbc103b-9cc7-40f5-9746-12e04c976dff

## How It Works

Tambo supports two kinds of components.

**Generative components** render once in response to a message. Charts, summaries, data visualizations.

https://github.com/user-attachments/assets/3bd340e7-e226-4151-ae40-aab9b3660d8b

**Interactable components** persist and update as users refine requests. Shopping carts, spreadsheets, task boards.

https://github.com/user-attachments/assets/12d957cd-97f1-488e-911f-0ff900ef4062

### Registering Components

Tell the AI which components it can use. Zod schemas define the props.

```tsx
// Generative: AI creates on-demand
const components: TamboComponent[] = [
  {
    name: &quot;Graph&quot;,
    description: &quot;Displays data as charts using Recharts library&quot;,
    component: Graph,
    propsSchema: z.object({
      data: z.array(z.object({ name: z.string(), value: z.number() })),
      type: z.enum([&quot;line&quot;, &quot;bar&quot;, &quot;pie&quot;]),
    }),
  },
];

// Interactable: persists and updates by ID
const InteractableNote = withInteractable(Note, {
  componentName: &quot;Note&quot;,
  description: &quot;A note supporting title, content, and color modifications&quot;,
  propsSchema: z.object({
    title: z.string(),
    content: z.string(),
    color: z.enum([&quot;white&quot;, &quot;yellow&quot;, &quot;blue&quot;, &quot;green&quot;]).optional(),
  }),
});
```

Docs: [generative components](https://docs.tambo.co/concepts/components/defining-tambo-components), [interactable components](https://docs.tambo.co/concepts/components/interactable-components)

### The Provider

Wrap your app with `TamboProvider`.

```tsx
&lt;TamboProvider
  apiKey={process.env.NEXT_PUBLIC_TAMBO_API_KEY!}
  components={components}
&gt;
  &lt;Chat /&gt;
  &lt;InteractableNote id=&quot;note-1&quot; title=&quot;My Note&quot; content=&quot;Start writing...&quot; /&gt;
&lt;/TamboProvider&gt;
```

For apps with signed-in users, pass a per-user `userToken` (OAuth access token) to `TamboProvider` to enable per-user auth and connect Tambo to your app&#039;s end-user identity. See [User Authentication](https://docs.tambo.co/concepts/user-authentication) for details.

Docs: [provider options](https://docs.tambo.co/api-reference/tambo-provider)

### Hooks

Send messages with `useTamboThreadInput`. `useTamboThread` handles streaming, including props for generated components and tool calls.

```tsx
const { value, setValue, submit, isPending } = useTamboThreadInput();

&lt;input value={value} onChange={(e) =&gt; setValue(e.target.value)} /&gt;
&lt;button onClick={() =&gt; submit()} disabled={isPending}&gt;Send&lt;/button&gt;
```

```tsx
const { thread } = useTamboThread();

{
  thread.messages.map((message) =&gt; (
    &lt;div key={message.id}&gt;
      {Array.isArray(message.content) ? (
        message.content.map((part, i) =&gt;
          part.type === &quot;text&quot; ? &lt;p key={i}&gt;{part.text}&lt;/p&gt; : null,
        )
      ) : (
        &lt;p&gt;{String(message.content)}&lt;/p&gt;
      )}
      {message.renderedComponent}
    &lt;/div&gt;
  ));
}
```

Track streaming status if you want progressive loading:

```tsx
const { streamStatus, propStatus } = useTamboStreamStatus();

if (!streamStatus.isSuccess) return &lt;Spinner /&gt;;
{
  propStatus[&quot;title&quot;]?.isSuccess &amp;&amp; &lt;h3&gt;{title}&lt;/h3&gt;;
}
```

Docs: [threads and messages](https://docs.tambo.co/concepts/message-threads), [streaming status](https://docs.tambo.co/concepts/streaming/component-streaming-status)

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.tambo.co/getting-started/quickstart&quot;&gt;Full tutorial&lt;/a&gt;
&lt;/p&gt;

## Features

### MCP Integrations

Connect to Linear, Slack, databases, or your own MCP servers. Tambo supports the full MCP protocol: tools, prompts, elicitations, and sampling.

```tsx
import { MCPTransport } from &quot;@tambo-ai/react/mcp&quot;;

const mcpServers = [
  {
    name: &quot;filesystem&quot;,
    url: &quot;http://localhost:8261/mcp&quot;,
    transport: MCPTransport.HTTP,
  },
];

&lt;TamboProvider components={components} mcpServers={mcpServers}&gt;
  &lt;App /&gt;
&lt;/TamboProvider&gt;;
```

https://github.com/user-attachments/assets/c7a13915-8fed-4758-be1b-30a60fad0cda

Supports the full MCP protocol: tools, prompts, elicitations, and sampling.

Docs: [MCP integration](https://docs.tambo.co/concepts/model-context-protocol)

### Local Tools

Sometimes you need functions that run in the browser. DOM manipulation, authenticated fetches, accessing React state. Define them as tools and the AI can call them.

```tsx
const tools: TamboTool[] = [
  {
    name: &quot;getWeather&quot;,
    description: &quot;Fetches weather for a location&quot;,
    tool: async (location: string) =&gt;
      fetch(`/api/weather?q=${encodeURIComponent(location)}`).then((r) =&gt;
        r.json(),
      ),
    toolSchema: z
      .function()
      .args(z.string())
      .returns(
        z.object({
          temperature: z.number(),
          condition: z.string(),
          location: z.string(),
        }),
      ),
  },
];

&lt;TamboProvider tools={tools} components={components}&gt;
  &lt;App /&gt;
&lt;/TamboProvider&gt;;
```

Docs: [local tools](https://docs.tambo.co/concepts/tools/adding-tools)

### Context, Auth, and Suggestions

**Additional context** lets you pass metadata to give the AI better responses. User state, app settings, current page. **User authentication** passes tokens from your auth provider. **Suggestions** generates prompts users can click based on what they&#039;re doing.

```tsx
&lt;TamboProvider
  userToken={userToken}
  contextHelpers={{
    selectedItems: () =&gt; ({
      key: &quot;selectedItems&quot;,
      value: selectedItems.map((i) =&gt; i.name).join(&quot;, &quot;),
    }),
    currentPage: () =&gt; ({ key: &quot;page&quot;, value: window.location.pathname }),
  }}
/&gt;
```

```tsx
const { suggestions, accept } = useTamboSuggestions({ maxSuggestions: 3 });

suggestions.map((s) =&gt; (
  &lt;button key={s.id} onClick={() =&gt; accept(s)}&gt;
    {s.title}
  &lt;/button&gt;
));
```

Docs: [additional context](https://docs.tambo.co/concepts/additional-context), [user authentication](https://docs.tambo.co/concepts/user-authentication), [suggestions](https://docs.tambo.co/concepts/suggestions)

### Supported LLM Providers

OpenAI, Anthropic, Cerebras, Google Gemini, Mistral, and any OpenAI-compatible provider. [Full list](https://docs.tambo.co/models). Missing one? [Let us know](https://github.com/tambo-ai/tambo/issues).

## How Tambo Compares

| Feature                            | Tambo                                 | Vercel AI SDK                    | CopilotKit                       | Assistant UI         |
| ---------------------------------- | ------------------------------------- | -------------------------------- | -------------------------------- | -------------------- |
| **Component selection**            | AI decides which components to render | Manual tool-to-component mapping | Via agent frameworks (LangGraph) | Chat-focused tool UI |
| **MCP integration**                | Built-in                              | Experimental (v4.2+)             | Recently added                   | Requires AI SDK v5   |
| **Persistent stateful components** | Yes                                   | No                               | Shared state patterns            | No                   |
| **Client-side tool execution**     | Declarative, automatic                | Manual via onToolCall            | Agent-side only                  | No                   |
| **Self-hostable**                  | MIT (SDK + backend)                   | Apache 2.0 (SDK only)            | MIT                              | MIT                  |
| **Hosted option**                  | Tambo Cloud                           | No                               | CopilotKit Cloud                 | Assistant Cloud      |
| **Best for**                       | Full app UI control                   | Streaming and tool abstractions  | Multi-agent workflows            | Chat interfaces      |

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.tambo.co&quot;&gt;Full documentation&lt;/a&gt;
&lt;/p&gt;

---

## Pricing

### Self-Hosted

Free forever. MIT licensed. 5-minute Docker setup.

```bash
npx tambo init
# Select &quot;Self-hosted&quot;
```

### Tambo Cloud

Free tier, then pay as you grow.

- **Free**: 10,000 messages/month
- **Growth**: $25/mo for 200k messages + email support
- **Enterprise**: Custom volume, SLA, SOC 2, HIPAA

[Pricing details](https://tambo.co/pricing)

## Repository Structure

This Turborepo hosts the React SDK ecosystem and Tambo Cloud platform.

`apps/` has the web dashboard (Next.js), the API (NestJS), and MCP services.

`packages/` has shared code. Database schema (Drizzle), LLM helpers, pure utilities, and tooling configs.

The root holds framework packages: `react-sdk/`, `cli/`, `showcase/`, `docs/`, `create-tambo-app/`.

## Development

You&#039;ll need Node.js 22+, npm 11+, and optionally Docker.

```bash
git clone https://github.com/tambo-ai/tambo.git
cd tambo
npm install
npm run dev        # apps/web + apps/api
```

Useful commands:

```bash
npm run build        # Build everything
npm run lint         # Lint (lint:fix to autofix)
npm run check-types  # Type check
npm test             # Run tests
```

Database (requires Docker):

```bash
npm run db:generate  # Generate migrations
npm run db:migrate   # Apply migrations
npm run db:studio    # Open Drizzle Studio
```

Docker workflow lives in `scripts/cloud/`. See [README.DOCKER.md](./README.DOCKER.md) for details.

[Contributing Guide](./CONTRIBUTING.md)

## Community

[Discord](https://discord.gg/dJNvPEHth6) for help and discussion. [GitHub](https://github.com/tambo-ai/tambo) to contribute. [@tambo_ai](https://twitter.com/tambo_ai) for updates.

### Built with Tambo

| Project                                                                                           | Preview                                                           | Description                                                                                             | Links                                                                                      |
| ------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------ |
| **[db-thing](https://db-thing.vercel.app)** by [@akinloluwami](https://github.com/akinloluwami)   | &lt;img src=&quot;community/db-thing.png&quot; alt=&quot;db-thing&quot; width=&quot;300&quot;&gt;     | Database design through conversation. Create schemas, generate ERDs, get optimization tips, export SQL. | [GitHub](https://github.com/akinloluwami/db-thing) ‚Ä¢ [Demo](https://db-thing.vercel.app)   |
| **[CheatSheet](https://cheatsheet.tambo.co)** by [@michaelmagan](https://github.com/michaelmagan) | &lt;img src=&quot;community/cheatsheet.png&quot; alt=&quot;CheatSheet&quot; width=&quot;300&quot;&gt; | Spreadsheet editor with natural language. Edit cells, create charts, connect external data via MCP.     | [GitHub](https://github.com/michaelmagan/cheatsheet) ‚Ä¢ [Demo](https://cheatsheet.tambo.co) |

Built something? [Open a PR](https://github.com/tambo-ai/tambo/pulls) or [share it in Discord](https://discord.gg/dJNvPEHth6).

---

## License

Unless otherwise noted in a workspace (app or package), code in this repo is
licensed under MIT (see the root [LICENSE](LICENSE)).

Some workspaces are licensed under Apache-2.0; see the accompanying `LICENSE`
and `NOTICE` files in those workspaces.

---

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/tambo-animation.gif&quot; alt=&quot;Tambo AI Animation&quot; width=&quot;800&quot;&gt;
&lt;/p&gt;

---

**For AI/LLM agents:** [docs.tambo.co/llms.txt](https://docs.tambo.co/llms.txt)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[maotoumao/MusicFree]]></title>
            <link>https://github.com/maotoumao/MusicFree</link>
            <guid>https://github.com/maotoumao/MusicFree</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:45 GMT</pubDate>
            <description><![CDATA[Êèí‰ª∂Âåñ„ÄÅÂÆöÂà∂Âåñ„ÄÅÊó†ÂπøÂëäÁöÑÂÖçË¥πÈü≥‰πêÊí≠ÊîæÂô®]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/maotoumao/MusicFree">maotoumao/MusicFree</a></h1>
            <p>Êèí‰ª∂Âåñ„ÄÅÂÆöÂà∂Âåñ„ÄÅÊó†ÂπøÂëäÁöÑÂÖçË¥πÈü≥‰πêÊí≠ÊîæÂô®</p>
            <p>Language: TypeScript</p>
            <p>Stars: 22,960</p>
            <p>Forks: 1,593</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[CyberTimon/RapidRAW]]></title>
            <link>https://github.com/CyberTimon/RapidRAW</link>
            <guid>https://github.com/CyberTimon/RapidRAW</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:44 GMT</pubDate>
            <description><![CDATA[A beautiful, non-destructive, and GPU-accelerated RAW image editor built with performance in mind.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/CyberTimon/RapidRAW">CyberTimon/RapidRAW</a></h1>
            <p>A beautiful, non-destructive, and GPU-accelerated RAW image editor built with performance in mind.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 4,301</p>
            <p>Forks: 144</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/editor.png&quot; alt=&quot;RapidRAW Editor&quot;&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![Rust](https://img.shields.io/badge/rust-%23000000.svg?style=for-the-badge&amp;logo=rust&amp;logoColor=white)](https://www.rust-lang.org/)
[![wgpu](https://img.shields.io/badge/wgpu-%23282C34.svg?style=for-the-badge&amp;logo=webgpu&amp;logoColor=white)](https://wgpu.rs/)
[![React](https://img.shields.io/badge/react-%2320232a.svg?style=for-the-badge&amp;logo=react&amp;logoColor=%2361DAFB)](https://react.dev/)
[![Tauri](https://img.shields.io/badge/Tauri-24C8DB?style=for-the-badge&amp;logo=tauri&amp;logoColor=white)](https://tauri.app/)
[![AGPL-3.0](https://img.shields.io/badge/License-AGPL_v3-blue.svg?style=for-the-badge)](https://opensource.org/licenses/AGPL-3.0)
[![GitHub stars](https://img.shields.io/github/stars/CyberTimon/RapidRAW?style=for-the-badge&amp;logo=github&amp;label=Stars)](https://github.com/CyberTimon/RapidRAW/stargazers)
&lt;br&gt;
[![www.getrapidraw.com](https://img.shields.io/badge/getrapidraw.com-%232ea44f?style=for-the-badge&amp;logo=safari&amp;logoColor=white)](https://www.getrapidraw.com)
[![Instagram](https://img.shields.io/badge/Instagram-%23E4405F.svg?style=for-the-badge&amp;logo=Instagram&amp;logoColor=white)](https://www.instagram.com/getrapidraw/)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.gg/cvFugZ2Hw8)

&lt;/div&gt;

# RapidRAW

&gt; A beautiful, non-destructive, and GPU-accelerated RAW image editor built with performance in mind.

RapidRAW is a modern, high-performance alternative to Adobe Lightroom¬Æ. It delivers a simple, beautiful editing experience in a lightweight package (under 20MB) for Windows, macOS, and Linux.

I started developing this project as a personal challenge when I was 18. My goal was to create a high-performance tool for my own photography workflow while deepening my understanding of React, WGSL and Rust, with the support from Google Gemini.

&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot; align=&quot;center&quot;&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://github.com/CyberTimon/RapidRAW/releases/latest&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/CyberTimon/RapidRAW/main/src-tauri/icons/full_res_original.png&quot; alt=&quot;Download RapidRAW&quot; height=&quot;96&quot;&gt;
      &lt;/a&gt;
      &lt;h3&gt;Download RapidRAW&lt;/h3&gt;
      &lt;p&gt;Get the latest release for Windows, macOS, and Linux. Packaged and ready to run.&lt;/p&gt;
      &lt;strong&gt;&lt;a href=&quot;https://github.com/CyberTimon/RapidRAW/releases/latest&quot;&gt;Download Latest Version ‚Üí&lt;/a&gt;&lt;/strong&gt;
      &lt;br&gt;&lt;br&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot; align=&quot;center&quot;&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://github.com/CyberTimon/RapidRAW-Docs&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/CyberTimon/RapidRAW/main/src-tauri/icons/docs.png&quot; alt=&quot;Read the Docs&quot; height=&quot;96&quot;&gt;
      &lt;/a&gt;
      &lt;h3&gt;Read the Docs&lt;/h3&gt;
      &lt;p&gt;Learn how to use RapidRAW with step-by-step tutorials, from adjustments to masking.&lt;/p&gt;
      &lt;strong&gt;&lt;a href=&quot;https://github.com/CyberTimon/RapidRAW-Docs&quot;&gt;View Tutorials &amp; Examples ‚Üí&lt;/a&gt;&lt;/strong&gt;
      &lt;br&gt;&lt;br&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

Have fun!

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;For Who Is This?&lt;/strong&gt;&lt;/summary&gt;
RapidRAW is for photographers who love to edit their photos in a &lt;strong&gt;clean, fast, and simple workflow&lt;/strong&gt;. It prioritizes speed, a beautiful user interface, and powerful tools that let you achieve your creative color vision quickly.
&lt;br&gt;&lt;br&gt;
It is &lt;strong&gt;not&lt;/strong&gt; for users who seek absolute, perfect color accuracy. While the results are great for most purposes, the focus is on a fluid, creative process rather than perfect color precision.
&lt;br&gt;&lt;br&gt;
RapidRAW is still in active development and isn&#039;t yet as polished as mature tools like Darktable, RawTherapee, or Adobe Lightroom¬Æ. Right now, the focus is on building a fast, enjoyable core editing experience. You may encounter bugs - if you do, please report them so I can fix them :) Your feedback really helps!
&lt;br&gt;&lt;br&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Recent Changes&lt;/strong&gt;&lt;/summary&gt;

*   **2026-01-20:** Export preset management for saving export settings 
*   **2026-01-19:** Preload library for faster startup &amp; automatic geometry transformation helper lines
*   **2026-01-18:** Implement image geometry transformation utils
*   **2026-01-17:** Refactor AI panel to correctly work with the new masking system
*   **2026-01-16:** Major masking system overhaul with drag &amp; drop, per-mask opacity/invert &amp; UI improvements
*   **2026-01-13:** New python middleware client for external generative AI integration (ComfyUI)
*   **2026-01-12:** Created a RapidRAW community discord server
*   **2026-01-11:** Separate preview worker, optional high-quality live previews &amp; mask/ai patch caching
*   **2026-01-10:** Enhanced EXIF UI, optimized color wheels/curves &amp; rawler update
*   **2026-01-09:** Live previews for all adjustments &amp; masks with optimized GPU processing


&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Expand further&lt;/strong&gt;&lt;/summary&gt;

*   **2026-01-05:** Collage maker upgrade (drag &amp; drop, zoom, ratio options)
*   **2026-01-05:** &#039;Prefer RAW&#039; filter option added to library
*   **2026-01-05:** Support for uppercase file extensions
*   **2026-01-05:** Flush thumbnail cache on folder switch
*   **2025-12-27:** Fix LUT banding issues with improved sampling
*   **2025-12-26:** AI masking stability improvements under load
*   **2025-12-23:** Metadata card in toolbar &amp; context menu export
*   **2025-12-23:** Monochromatic grain &amp; white balance picker improvements
*   **2025-12-22:** BM3D Denoising with comparison slider
*   **2025-12-20:** Batch export stability improvements &amp; RAM optimization
*   **2025-12-14:** Exposure slider added to masking tools
*   **2025-12-14:** Improved delete workflow
*   **2025-12-08:** Improved mask eraser tool behavior &amp; ORT v2 migration
*   **2025-12-07:** Write EXIF metadata to file
*   **2025-12-07:** Color picker for white balance
*   **2025-11-30:** HSL luminance artifacts fix
*   **2025-11-29:** Improved mask stacking &amp; many bug fixes
*   **2025-11-28:** QOI support
*   **2025-11-25:** Update rawler
*   **2025-11-23:** Recursive library view to display images from all subfolders
*   **2025-11-22:** DNG loader improvements
*   **2025-11-18:** Improved vibrancy adjustment
*   **2025-11-15:** Virtual copies &amp; library improvements
*   **2025-11-14:** Open-with-file cross plattform compatibilty &amp; single instance lock
*   **2025-11-13:** Rewritten tagging system to support pill-like image tagging
*   **2025-11-10:** Improved folder tree with search functionality
*   **2025-11-08:** Added EXR file format support
*   **2025-11-XX:** Improving AgX
*   **2025-11-02:** Optimize image loading &amp; add processing engine settings
*   **2025-10-31:** Expose highlights compression point to user &amp; improve keybinds detection
*   **2025-10-28:** Copy paste settings &amp; brightness adjustment
*   **2025-10-XX:** Working on tonemapping - ongoing...
*   **2025-10-24:** Getting AgX right isn&#039;t as easy as it seems :=)
*   **2025-10-22:** AgX tone mapping
*   **2025-10-19:** Whole image mask component &amp; organize mask components better
*   **2025-10-19:** You can now apply presets to masks &amp; improved auto adjustments
*   **2025-10-17:** New centr√© adjustment, rawler now as a submodule &amp; improved logger
*   **2025-10-15:** Ability to pin folders, improved session handling &amp; smooth library thumbnail updating
*   **2025-10-11:** Realistic, complex &amp; non-dulling exposure &amp; highlights slider
*   **2025-10-11:** Smooth filmstrip thumbnail updates
*   **2025-10-07:** New watermarking support
*   **2025-10-06:** Improve crop quality by transforming before scaling
*   **2025-10-XX:** Many small improvements - ongoing...
*   **2025-09-27:** Sort library by exif metadata &amp; release cleanup / bug fixes
*   **2025-09-26:** Collage maker to create unique collages with many different layouts, spacing &amp; border radius
*   **2025-09-23:** Color calibration tool to adjust RGB primaries &amp; adjustments visibility settings
*   **2025-09-22:** Issue template &amp; CI/CD improvements
*   **2025-09-20:** Universal presets importer, prioritize dGPU &amp; improved local contrast tools (sharpness, clarity etc.)
*   **2025-09-17:** Automatic image culling (duplicate &amp; blur detection)
*   **2025-09-14:** Grid previews in community panel &amp; improved ComfyUi workflow
*   **2025-09-12:** New community presets panel to share &amp; showcase presets
*   **2025-09-10:** Extended generative AI roadmap &amp; started building RapidRAW website
*   **2025-09-09:** Many shader improvements &amp; bug fixes, invert tint slider
*   **2025-09-06:** New update notifier that alerts users when a new version becomes available
*   **2025-09-04:** Added toggleable clipping warnings (blue = shadows, red = highlights)
*   **2025-09-02:** Transition to Rust 2024 &amp; Cache image on GPU
*   **2025-08-31:** Cancel thumbnail generation on folder change &amp; optimized ai patch saving  
*   **2025-08-30:** Optimize ComfyUI image transfer &amp; speed
*   **2025-08-28:** Chromatic aberration correction &amp; Shader improvements
*   **2025-08-26:** User customisable ComfyUI workflow selection
*   **2025-08-25:** Make LUTs parser more robust (support more advanced formats)
*   **2025-08-24:** Improved keyboard shortcuts
*   **2025-08-23:** Estimate file size before exporting
*   **2025-08-21:** Added LUTs (.cube, .3dl, .png, .jpg, .jpeg, .tiff) support
*   **2025-08-16:** Fast AI sky masks
*   **2025-08-15:** Show full resolution image when zooming in
*   **2025-08-15:** Implement Tauri&#039;s IPC as a replacement for the slow Base64 image transfer
*   **2025-08-12:** Relative zoom indicator
*   **2025-08-11:** TypeScript cleanup &amp; many bug fixes
*   **2025-08-09:** Local inpainting without the need for ComfyUI, ability to change thumbnail aspect ratio
*   **2025-08-09:** Frontend refactored to TypeScript thanks to @varjolintu
*   **2025-08-08:** New onnxruntime download strategy &amp; the base for local inpainting
*   **2025-08-05:** Improved HSL cascading, UI &amp; animation improvements, ability to grow &amp; shrink / feather AI masks
*   **2025-08-03:** New high performance, seamless image panorama stitcher (without any dependencies on OpenCV)
*   **2025-08-02:** Added an image straightening tool and improved crop &amp; rotation functionality (especially on portrait images)
*   **2025-08-02:** A new dedicated image importer, ability to rename and batch rename files, improved dark theme, and other fixes
*   **2025-07-31:** Ability to tag &amp; filter images by color labels, refactored image right clicking
*   **2025-07-31:** Reimplemented the functionality of GPU processing (GPU cropping, etc.) -&gt; No longer dependent on TEXTURE_BINDING_ARRAY
*   **2025-07-29:** Refactored generative AI foundation, many small fixes
*   **2025-07-27:** Automatic AI image tagging, overall mask transparency setting per mask
*   **2025-07-25:** Fuji RAF X-Trans sensor support (new x-trans demosaicing algo)
*   **2025-07-24:** Auto crop when cropping an image (to prevent black borders), added drag &amp; drop sort abilty to presets panel
*   **2025-07-22:** Significant improvements to the shader: More accurate exposure slider, better tone mapper (simplified ACES)
*   **2025-07-21:** Remember scroll position when going into the editing section
*   **2025-07-20:** Ability to add presets to folders, export preset folders etc, preset _animations_
*   **2025-07-20:** Tutorials on how to use RapidRAW
*   **2025-07-19:** Initial color negative conversion implementation, shader improvements
*   **2025-07-19:** New color wheels, persistent collapsed / expanded state for UI elements
*   **2025-07-19:** Fixed banding &amp; purple artefacts on RAW images, better color noise reduction, show exposure in stops
*   **2025-07-18:** Smooth zoom slider, new adaptive editor theme setting
*   **2025-07-18:** New export functionality: Export with metadata, GPS metadata remover, batch export file naming scheme using tags
*   **2025-07-18:** Ability to delete the associated RAW/JPEG in right click delete operations
*   **2025-07-17:** Small bug fixes
*   **2025-07-13:** Native looking titlebar and ability to input precise number into sliders
*   **2025-07-13:** Huge update to masks: You can now add multiple masks to a mask containers, subtract / add / combine masks etc.
*   **2025-07-12:** Improved curves tool, more shader improvements, improved handling of very large files
*   **2025-07-11:** More accurate shader, reorganized main library preferences dropdown, smoother histogram, more realistic film grain
*   **2025-07-11:** Added a HUD-like waveform overlay toggle to display specific channel waveforms (w-key)
*   **2025-07-10:** Rewritten batch export system and async thumbnail generation (makes the loading of large folders a lot more fluid)
*   **2025-07-10:** Window transparency can now be toggled in the settings, thanks to @andrewazores
*   **2025-07-08:** Ability to toggle the visibility of individual adjustments sections
*   **2025-07-08:** Fixed top-left zoom bug, corrected scale behavior in crop panel, keep default original aspect ratio
*   **2025-07-08:** Added image rating filter and redesigned the metadata panel with improved layout, clearer sections, and an embedded GPS map
*   **2025-07-07:** Improved generative AI features and updated [AI Roadmap](#ai-roadmap)
*   **2025-07-06:** Initial generative AI integration with [ComfyUI](https://github.com/comfyanonymous/ComfyUI) - for more details, checkout the [AI Roadmap](#ai-roadmap)
*   **2025-07-05:** Ability to overwrite preset with current settings
*   **2025-07-04:** High speed and precise cache to significantly accelerate large image editing
*   **2025-07-04:** Greatly improved shader with better dehaze, more accurate curves etc
*   **2025-07-04:** Predefined 90¬∞ clockwise rotation and ability to flip images
*   **2025-07-03:** Switched from [rawloader](https://github.com/pedrocr/rawloader) to [rawler](https://github.com/dnglab/dnglab/tree/main/rawler) to support a wider range of RAW formats
*   **2025-07-02:** AI-powered foreground / background masking
*   **2025-06-30:** AI-powered subject masking
*   **2025-06-30:** Precompiled Linux builds
*   **2025-06-29:** New 5:4 aspect ratio, new low contrast grey theme and more cameras support (DJI Mavic lineup)
*   **2025-06-28:** Release cleanup, CI/CD improvements and minor fixes
*   **2025-06-27:** Initial release. For more information about the earlier progress, look at the [Initial Development Log](#initial-development-log)

&lt;/details&gt;
&lt;/details&gt;
&lt;br&gt;

**Table of Contents**
- [Key Features](#key-features)
- [Demo &amp; Screenshots](#demo--screenshots)
- [The Idea](#the-idea)
- [Current Priorities](#current-priorities)
- [AI Roadmap](#ai-roadmap)
- [Initial Development Log](#initial-development-log)
- [Getting Started](#getting-started)
- [System Requirements](#system-requirements)
- [Contributing](#contributing)
- [Special Thanks](#special-thanks)
- [Support the Project](#support-the-project)
- [License &amp; Philosophy](#license--philosophy)

---

## Key Features

&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td valign=&quot;top&quot; width=&quot;50%&quot;&gt;
      &lt;h4&gt;Core Editing Engine&lt;/h4&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;GPU-Accelerated Processing:&lt;/strong&gt; All image adjustments are processed on the GPU using a custom WGSL shader for rapid feedback.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Masking:&lt;/strong&gt; Create masks with AI subject, sky and foreground detection. Combine with traditional Brush, Linear, and Radial masks for great control.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Generative Edits:&lt;/strong&gt; Remove objects or add new elements with text prompts. Each edit creates a non-destructive patch layer, powered by an optional ComfyUI backend.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Full RAW Support:&lt;/strong&gt; Supports a wide range of RAW camera formats thanks to rawler.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Non-Destructive Workflow:&lt;/strong&gt; All edits are stored in a &lt;code&gt;.rrdata&lt;/code&gt; sidecar file, leaving your original images untouched.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;32-bit Precision:&lt;/strong&gt; Ensures high-quality adjustments without banding or data loss.&lt;/li&gt;
      &lt;/ul&gt;
      &lt;h4&gt;Professional Grade Adjustments&lt;/h4&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Tonal Controls:&lt;/strong&gt; Exposure, Contrast, Highlights, Shadows, Whites, and Blacks.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Tone Curves:&lt;/strong&gt; Full control over Luma, Red, Green, and Blue channels.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Color Grading:&lt;/strong&gt; Temperature, Tint, Vibrance, Saturation, and a full HSL color mixer.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Detail Enhancement:&lt;/strong&gt; Sharpening, Clarity, Structure, and Noise Reduction.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Effects:&lt;/strong&gt; LUTs, Dehaze, Vignette, and Film Grain simulation.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Transform Tools:&lt;/strong&gt; Crop with aspect ratio locking, Rotate, and Flip.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
    &lt;td valign=&quot;top&quot; width=&quot;50%&quot;&gt;
      &lt;h4&gt;Library &amp; Workflow&lt;/h4&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Image Library:&lt;/strong&gt; Effortlessly sort, rate, tag, and manage your entire photo collection for a streamlined and efficient workflow.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Folder Management:&lt;/strong&gt; Integrated folder tree, create, rename, and delete folders directly within the app.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;File Operations:&lt;/strong&gt; Import, copy, move, rename, and duplicate images and their associated edits.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Filmstrip View:&lt;/strong&gt; Quickly navigate between all the images in your current folder while editing.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Batch Operations:&lt;/strong&gt; Save significant time by applying a consistent set of adjustments or exporting entire batches of images simultaneously.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;EXIF Data Viewer:&lt;/strong&gt; Gain insights by inspecting the complete metadata from your camera, including shutter speed, aperture, ISO, and lens information.&lt;/li&gt;
      &lt;/ul&gt;
      &lt;h4&gt;Productivity &amp; UI&lt;/h4&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;strong&gt;Preset System:&lt;/strong&gt; Create, save, import, and export your favorite looks.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Copy &amp; Paste Settings:&lt;/strong&gt; Quickly transfer adjustments between images.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Undo/Redo History:&lt;/strong&gt; A robust history system for every edit.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Customizable UI:&lt;/strong&gt; Resizable panels and multiple beautiful UI themes with smooth animations.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Panorama Stitcher:&lt;/strong&gt; Seamlessly combine multiple images into a wide panorama.&lt;/li&gt;
        &lt;li&gt;&lt;strong&gt;Exporting:&lt;/strong&gt; Control file format, quality, naming scheme, metadata, resizing options on export.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Demo &amp; Screenshots

Here&#039;s RapidRAW in action.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/editor.gif&quot; alt=&quot;The main editor interface in action&quot;&gt;&lt;/img&gt;&lt;br&gt;
  &lt;em&gt;The main editor interface in action.&lt;/em&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot;&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/batch.gif&quot; alt=&quot;Powerful batch operations and export&quot; style=&quot;max-width: 100%;&quot;&gt;
      &lt;br&gt;
      &lt;em&gt;Powerful batch operations and export.&lt;/em&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot;&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/customization.gif&quot; alt=&quot;Customizable editor layout and panels&quot; style=&quot;max-width: 100%;&quot;&gt;
      &lt;br&gt;
      &lt;em&gt;Customizable editor layout and panels.&lt;/em&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot;&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/masks.gif&quot; alt=&quot;Advanced masking to speedup workflow&quot; style=&quot;max-width: 100%;&quot;&gt;
      &lt;br&gt;
      &lt;em&gt;Advanced masking to speedup workflow.&lt;/em&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot;&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/CyberTimon/RapidRAW/assets/.github/assets/ai.gif&quot; alt=&quot;Experimental generative AI features&quot; style=&quot;max-width: 100%;&quot;&gt;
      &lt;br&gt;
      &lt;em&gt;Experiment

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[strapi/strapi]]></title>
            <link>https://github.com/strapi/strapi</link>
            <guid>https://github.com/strapi/strapi</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:43 GMT</pubDate>
            <description><![CDATA[üöÄ Strapi is the leading open-source headless CMS. It‚Äôs 100% JavaScript/TypeScript, fully customizable, and developer-first.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/strapi/strapi">strapi/strapi</a></h1>
            <p>üöÄ Strapi is the leading open-source headless CMS. It‚Äôs 100% JavaScript/TypeScript, fully customizable, and developer-first.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 71,047</p>
            <p>Forks: 9,385</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://strapi.io/#gh-light-mode-only&quot;&gt;
    &lt;img src=&quot;https://strapi.io/assets/strapi-logo-dark.svg&quot; width=&quot;318px&quot; alt=&quot;Strapi logo&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://strapi.io/#gh-dark-mode-only&quot;&gt;
    &lt;img src=&quot;https://strapi.io/assets/strapi-logo-light.svg&quot; width=&quot;318px&quot; alt=&quot;Strapi logo&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;Open-source headless CMS, self-hosted or Cloud you‚Äôre in control.&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;The leading open-source headless CMS, 100% JavaScript/TypeScript, flexible and fully customizable.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://cloud.strapi.io/signups?source=github1&quot;&gt;Cloud&lt;/a&gt; ¬∑ &lt;a href=&quot;https://strapi.io/demo?utm_campaign=Growth-Experiments&amp;utm_source=strapi%2Fstrapi%20README.md&quot;&gt;Try live demo&lt;/a&gt;&lt;/p&gt;
&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.org/package/@strapi/strapi&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/@strapi/strapi/latest.svg&quot; alt=&quot;NPM Version&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/strapi/strapi/actions/workflows/tests.yml&quot;&gt;
    &lt;img src=&quot;https://github.com/strapi/strapi/actions/workflows/tests.yml/badge.svg?branch=main&quot; alt=&quot;Tests&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.strapi.io&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/811989166782021633?label=Discord&quot; alt=&quot;Strapi on Discord&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/strapi/strapi/actions/workflows/nightly.yml&quot;&gt;
    &lt;img src=&quot;https://github.com/strapi/strapi/actions/workflows/nightly.yml/badge.svg&quot; alt=&quot;Strapi Nightly Release Build Status&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://strapi.io&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/strapi/strapi/main/public/assets/admin-demo.gif&quot; alt=&quot;Administration panel&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;

Strapi Community Edition is a free and open-source headless CMS enabling you to manage any content, anywhere.

- **Self-hosted or Cloud**: You can host and scale Strapi projects the way you want. You can save time by deploying to [Strapi Cloud](https://cloud.strapi.io/signups?source=github1) or deploy to the hosting platform you want\*\*: AWS, Azure, Google Cloud, DigitalOcean.
- **Modern Admin Panel**: Elegant, entirely customizable and a fully extensible admin panel.
- **Multi-database support**: You can choose the database you prefer: PostgreSQL, MySQL, MariaDB, and SQLite.
- **Customizable**: You can quickly build your logic by fully customizing APIs, routes, or plugins to fit your needs perfectly.
- **Blazing Fast and Robust**: Built on top of Node.js and TypeScript, Strapi delivers reliable and solid performance.
- **Front-end Agnostic**: Use any front-end framework (React, Next.js, Vue, Angular, etc.), mobile apps or even IoT.
- **Secure by default**: Reusable policies, CORS, CSP, P3P, Xframe, XSS, and more.
- **Powerful CLI**: Scaffold projects and APIs on the fly.

## Getting Started

&lt;a href=&quot;https://docs.strapi.io/developer-docs/latest/getting-started/quick-start.html&quot; target=&quot;_blank&quot;&gt;Read the Getting Started tutorial&lt;/a&gt; or follow the steps below:

### ‚è≥ Installation

Install Strapi with this **Quickstart** command to create a Strapi project instantly:

- (Use **yarn** to install the Strapi project (recommended). [Install yarn with these docs](https://yarnpkg.com/lang/en/docs/install/).)

```bash
yarn create strapi
```

**or**

- (Using npx to install the Strapi project.)

```bash
npx create-strapi@latest
```

This command generates a brand new project with the default features (authentication, permissions, content management, content type builder &amp; file upload).

Enjoy üéâ

### üñê Requirements

Complete installation requirements can be found in the documentation under &lt;a href=&quot;https://docs.strapi.io/developer-docs/latest/setup-deployment-guides/deployment.html&quot;&gt;Installation Requirements&lt;/a&gt;.

**Supported operating systems**:

| OS              | Recommended | Minimum    |
| --------------- | ----------- | ---------- |
| Ubuntu          | 24.04       | LTS        |
| Debian          | 11          | LTS        |
| RHEL            | 9           | LTS        |
| macOS           | 14          | 12         |
| Windows Desktop | 11          | 10         |
| Windows Server  | No Support  | No Support |
| Docker          | N/A         | N/A        |

(Please note that Strapi may work on other operating systems, but these are not tested nor officially supported at this time.)

**Node:**

Strapi only supports maintenance and LTS versions of Node.js. Please refer to the &lt;a href=&quot;https://nodejs.org/en/about/releases/&quot;&gt;Node.js release schedule&lt;/a&gt; for more information. NPM versions installed by default with Node.js are supported. Generally it&#039;s recommended to use yarn over npm where possible.

| Strapi Version  | Recommended | Minimum |
| --------------- | ----------- | ------- |
| 5.31.0 and up   | 24.x        | 20.x    |
| 5.0.0 to 5.30.1 | 20.x        | 18.x    |
| 4.14.5 and up   | 20.x        | 18.x    |
| 4.11.0 and up   | 18.x        | 16.x    |
| 4.3.9 to 4.10.x | 18.x        | 14.x    |
| 4.0.x to 4.3.8  | 16.x        | 14.x    |

**Database:**

| Database   | Recommended | Minimum |
| ---------- | ----------- | ------- |
| MySQL      | 8.0         | 8.0     |
| MariaDB    | 11.2        | 10.3    |
| PostgreSQL | 16.0        | 14.0    |
| SQLite     | 3           | 3       |

**We recommend always using the latest version of Strapi stable to start your new projects**.

## Features

- **Content Types Builder**: Build the most flexible publishing experience for your content managers, by giving them the freedom to create any page on the go with [fields](https://docs.strapi.io/user-docs/content-manager/writing-content#filling-up-fields), components and [Dynamic Zones](https://docs.strapi.io/user-docs/content-manager/writing-content#dynamic-zones).
- **Media Library**: Upload your images, videos, audio or documents to the media library. Easily find the right asset, edit and reuse it.
- **Internationalization**: The Internationalization (i18n) plugin allows Strapi users to create, manage and distribute localized content in different languages, called &quot;locales&quot;
- **Role Based Access Control**: Create an unlimited number of custom roles and permissions for admin and end users.
- **GraphQL or REST**: Consume the API using REST or GraphQL

You can unlock additional features such as SSO, Audit Logs, Review Workflows in [Strapi Cloud](https://cloud.strapi.io/login?source=github1) or [Strapi Enterprise](https://strapi.io/enterprise?source=github1).

**[See more on our website](https://strapi.io/overview)**.

## Contributing

Please read our [Contributing Guide](./CONTRIBUTING.md) before submitting a Pull Request to the project.

## Community support

For general help using Strapi, please refer to [the official Strapi documentation](https://docs.strapi.io). For additional help, you can use one of these channels to ask a question:

- [Discord](https://discord.strapi.io) (For live discussion with the Community and Strapi team)
- [GitHub](https://github.com/strapi/strapi) (Bug reports, Contributions)
- [Community Forum](https://forum.strapi.io) (Questions and Discussions)
- [Feedback section](https://feedback.strapi.io) (Roadmap, Feature requests)
- [Twitter](https://twitter.com/strapijs) (Get the news fast)
- [Facebook](https://www.facebook.com/Strapi-616063331867161)
- [YouTube Channel](https://www.youtube.com/strapi) (Learn from Video Tutorials)

## Migration

Follow our [migration guides](https://docs.strapi.io/developer-docs/latest/update-migration-guides/migration-guides.html) on the documentation to keep your projects up-to-date.

## Roadmap

Check out our [roadmap](https://feedback.strapi.io) to get informed of the latest features released and the upcoming ones. You may also give us insights and vote for a specific feature.

## Documentation

See our dedicated [repository](https://github.com/strapi/documentation) for the Strapi documentation, or view our documentation live:

- [Developer docs](https://docs.strapi.io/developer-docs/latest/getting-started/introduction.html)
- [User guide](https://docs.strapi.io/user-docs/latest/getting-started/introduction.html)
- [Cloud guide](https://docs.strapi.io/cloud/intro)

## Try live demo

See for yourself what&#039;s under the hood by getting access to a [hosted Strapi project](https://strapi.io/demo) with sample data.

## License

See the [LICENSE](./LICENSE) file for licensing information.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[vuetifyjs/vuetify]]></title>
            <link>https://github.com/vuetifyjs/vuetify</link>
            <guid>https://github.com/vuetifyjs/vuetify</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:42 GMT</pubDate>
            <description><![CDATA[üêâ Vue Component Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vuetifyjs/vuetify">vuetifyjs/vuetify</a></h1>
            <p>üêâ Vue Component Framework</p>
            <p>Language: TypeScript</p>
            <p>Stars: 40,911</p>
            <p>Forks: 7,145</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>packages/vuetify/README.md</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[vuejs/core]]></title>
            <link>https://github.com/vuejs/core</link>
            <guid>https://github.com/vuejs/core</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:41 GMT</pubDate>
            <description><![CDATA[üññ Vue.js is a progressive, incrementally-adoptable JavaScript framework for building UI on the web.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vuejs/core">vuejs/core</a></h1>
            <p>üññ Vue.js is a progressive, incrementally-adoptable JavaScript framework for building UI on the web.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 52,783</p>
            <p>Forks: 9,033</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># vuejs/core [![npm](https://img.shields.io/npm/v/vue.svg)](https://www.npmjs.com/package/vue) [![build status](https://github.com/vuejs/core/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/vuejs/core/actions/workflows/ci.yml) [![Download](https://img.shields.io/npm/dm/vue)](https://www.npmjs.com/package/vue)

## Getting Started

Please follow the documentation at [vuejs.org](https://vuejs.org/)!

## Sponsors

Vue.js is an MIT-licensed open source project with its ongoing development made possible entirely by the support of these awesome [backers](https://github.com/vuejs/core/blob/main/BACKERS.md). If you&#039;d like to join them, please consider [ sponsoring Vue&#039;s development](https://vuejs.org/sponsor/).

&lt;p align=&quot;center&quot;&gt;
  &lt;h3 align=&quot;center&quot;&gt;Special Sponsor&lt;/h3&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/appwrite/appwrite&quot;&gt;
  &lt;img alt=&quot;special sponsor appwrite&quot; src=&quot;https://sponsors.vuejs.org/images/appwrite.svg&quot; width=&quot;300&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://vuejs.org/sponsor/#current-sponsors&quot;&gt;
    &lt;img alt=&quot;sponsors&quot; src=&quot;https://sponsors.vuejs.org/sponsors.svg?v3&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

## Questions

For questions and support please use [the official forum](https://forum.vuejs.org) or [community chat](https://chat.vuejs.org/). The issue list of this repo is **exclusively** for bug reports and feature requests.

## Issues

Please make sure to respect issue requirements and use [the new issue helper](https://new-issue.vuejs.org/) when opening an issue. Issues not conforming to the guidelines may be closed immediately.

## Stay In Touch

- [X](https://x.com/vuejs)
- [Bluesky](https://bsky.app/profile/vuejs.org)
- [Blog](https://blog.vuejs.org/)
- [Job Board](https://vuejobs.com/?ref=vuejs)

## Contribution

Please make sure to read the [Contributing Guide](https://github.com/vuejs/core/blob/main/.github/contributing.md) before making a pull request. If you have a Vue-related project/component/tool, add it with a pull request to [this curated list](https://github.com/vuejs/awesome-vue)!

Thank you to all the people who already contributed to Vue!

&lt;a href=&quot;https://github.com/vuejs/core/graphs/contributors&quot;&gt;&lt;img src=&quot;https://opencollective.com/vuejs/contributors.svg?width=890&amp;limit=500&quot; /&gt;&lt;/a&gt;

&lt;sub&gt;_Note: Showing the first 500 contributors only due to GitHub image size limitations_&lt;/sub&gt;

## License

[MIT](https://opensource.org/licenses/MIT)

Copyright (c) 2013-present, Yuxi (Evan) You
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[langchain-ai/social-media-agent]]></title>
            <link>https://github.com/langchain-ai/social-media-agent</link>
            <guid>https://github.com/langchain-ai/social-media-agent</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:40 GMT</pubDate>
            <description><![CDATA[üì≤ An agent for sourcing, curating, and scheduling social media posts with human-in-the-loop.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langchain-ai/social-media-agent">langchain-ai/social-media-agent</a></h1>
            <p>üì≤ An agent for sourcing, curating, and scheduling social media posts with human-in-the-loop.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,982</p>
            <p>Forks: 354</p>
            <p>Stars today: 51 stars today</p>
            <h2>README</h2><pre># Social Media Agent

This repository contains an &#039;agent&#039; which can take in a URL, and generate a Twitter &amp; LinkedIn post based on the content of the URL. It uses a human-in-the-loop (HITL) flow to handle authentication with different social media platforms, and to allow the user to make changes, or accept/reject the generated post.

![Screenshot of the social media agent flow](./static/agent_flow.png)

## Table of contents

- [Quickstart](#quickstart)
  - [Environment variables](#set-environment-variables)
  - [LangGraph Server](#start-the-langgraph-server)
- [Full setup](#advanced-setup)
  - [Environment variables](#set-environment-variables-1)
  - [Authentication](#setup-authentication)
  - [Supabase](#setup-supabase)
  - [Slack](#setup-slack)
  - [GitHub](#setup-github)
- [Usage](#usage)
  - [Generate Post](#generate-post)
  - [Setup Crons](#setup-crons)
  - [Prebuilt Scripts](#prebuilt-scripts)
- [Setup Agent Inbox](#setup-agent-inbox)
  - [Using the deployed inbox](#using-the-deployed-inbox)
  - [Using the local inbox](#using-the-local-inbox)
- [Customization](#customization)
  - [Prompts](#prompts)
  - [Post Style](#post-style)

# Quickstart

&gt; [!TIP]
&gt; üé• For a visual guide, check out our [step-by-step video tutorial](https://youtu.be/TmTl5FMgkCQ) that walks you through the account setup process and project configuration.

This quickstart covers how to setup the Social Media Agent in a basic setup mode. This is the quickest way to get up and running, however it will lack some of the features of the full setup mode. See [here](#advanced-setup) for the full setup guide.

&lt;details&gt;
&lt;summary&gt;Running in basic setup mode will lack the following features:&lt;/summary&gt;

- Parsing content from GitHub, Twitter or YouTube URLs
- Ingesting data from Slack, or sending updates to Slack
- Image selection &amp; uploads

&lt;/details&gt;

To get started, you&#039;ll need the following API keys/software:

- [Anthropic API](https://console.anthropic.com/) - General LLM
- [LangSmith](https://smith.langchain.com/) - LangSmith API key required to run the LangGraph server locally (free)
- [FireCrawl API](https://www.firecrawl.dev/) - Web scraping. New users get 500 credits for free
- [Arcade](https://www.arcade.dev/) - Easy authentication for reading &amp; writing to social media platforms

## Setup Instructions

### Clone the repository:

```bash
git clone https://github.com/langchain-ai/social-media-agent.git
```

```bash
cd social-media-agent
```

### Install dependencies:

```bash
yarn install
```

### Set environment variables.

Copy the values of the quickstart `.env.quickstart.example` to `.env`, then add the values:

```bash
cp .env.quickstart.example .env
```

Once done, ensure you have the following environment variables set:

```bash
# For LangSmith tracing (optional)
LANGSMITH_API_KEY=
LANGSMITH_TRACING_V2=true

# For LLM generations
ANTHROPIC_API_KEY=

# For web scraping
FIRECRAWL_API_KEY=

# Arcade API key - used for fetching Tweets, and scheduling LinkedIn/Twitter posts
ARCADE_API_KEY=
```

If you plan to post to LinkedIn as an organization (rather than as yourself), you&#039;ll also need to set:

```bash
# Get the organization ID from the URL of the company page when you&#039;re logged in as an admin.
# For example, if the URL is `https://www.linkedin.com/company/12345678/admin/dashboard/`, the organization ID would be `12345678`.
POST_TO_LINKEDIN_ORGANIZATION=true
LINKEDIN_ORGANIZATION_ID=
```

### Install LangGraph CLI

```bash
pip install langgraph-cli
```

Then run the following command to check the CLI is installed:

```bash
langgraph --version
```

Click [here](https://langchain-ai.github.io/langgraph/cloud/reference/cli/) to read the full download instructions for the LangGraph CLI.

### Start the LangGraph server:

To start the LangGraph server, run this script:

```bash
yarn langgraph:in_mem:up
```

Under the hood, this will execute the following command:

```bash
npx @langchain/langgraph-cli dev --port 54367
```

&gt; [!NOTE]
&gt; The first time running this command (or if a new version of `@langchain/langgraph-cli` has been released), it will ask you to accept an install for the CLI. Enter `y` to accept.

Once the server is ready, you can execute the following command to generate a post:

```bash
yarn generate_post
```

You may also modify this script to pass different URLs to generate posts for other content.

This will kick off a new run to generate a post on a [LangChain blog post](https://blog.langchain.dev/customers-appfolio/).

To view the output, either inspect it in LangSmith, or use Agent Inbox.

&gt; [!TIP]
&gt; Follow these steps to setup &amp; configure the Agent Inbox: [Setup Agent Inbox Guide](#setup-agent-inbox)

# Advanced Setup

![Screenshot of the social media agent graph](./static/graph_screenshot.png)

To use all of the features of the Social Media Agent, you&#039;ll need the following:

- [Anthropic API](https://console.anthropic.com/) - General LLM
- [Google Vertex AI](https://cloud.google.com/vertex-ai) - For dealing with YouTube video content
- [LangSmith](https://smith.langchain.com/) - LangSmith API key required to run the LangGraph server locally (free)
- [FireCrawl API](https://www.firecrawl.dev/) - Web scraping
- [Arcade](https://www.arcade.dev) - Social media authentication and scheduling
- [Twitter Developer Account](https://developer.twitter.com/en/portal/dashboard) - For uploading media to Twitter
- [LinkedIn Developer Account](https://developer.linkedin.com/) - Posting to LinkedIn
- [GitHub API](https://github.com/settings/personal-access-tokens) - Reading GitHub content
- [Supabase](https://supabase.com/) - Storing images
- [Slack Developer Account](https://api.slack.com/apps) (optional) - ingesting data from a Slack channel

## Setup Instructions

### Clone the repository:

```bash
git clone https://github.com/langchain-ai/social-media-agent.git
```

```bash
cd social-media-agent
```

### Install dependencies:

```bash
yarn install
```

### Set environment variables.

Copy the values of the full env example file `.env.full.example` to `.env`, then update the values as needed.

```bash
cp .env.full.example .env
```

### Setup authentication

The agent needs your authorization to read and write to social media platforms. There are two ways to authorize the agent:

1. Use Arcade (quickest to set up)
2. Use your own Twitter and LinkedIn developer accounts

You can use either method, but not both.

#### Arcade setup

Create an Arcade account [here](https://www.arcade.dev). After you register, [get an Arcade API key](https://docs.arcade.dev/home/quickstart?lang=typescript). Set this value as `ARCADE_API_KEY` in your `.env` file.

Then, you will need to set these environment variables in your `.env` file:

- `TWITTER_USER_ID` - The ID/email of the Twitter account you want to use to post to Twitter.
- `LINKEDIN_USER_ID` - The ID/email of the LinkedIn account you want to use to post to LinkedIn.

Make sure you have the `USE_ARCADE_AUTH` environment variable set to `true` to have the graph use Arcade authentication.

If you plan to post to LinkedIn as an organization (rather than as yourself), you&#039;ll also need to set:

```bash
# Get the organization ID from the URL of the company page when you&#039;re logged in as an admin.
# For example, if the URL is `https://www.linkedin.com/company/12345678/admin/dashboard/`, the organization ID would be `12345678`.
LINKEDIN_ORGANIZATION_ID=
POST_TO_LINKEDIN_ORGANIZATION=true
```

&gt; [!NOTE]
&gt; If you want to upload media to Twitter, you will still need to set up your own Twitter developer account (below) in addition to using Arcade.
&gt;
&gt; If you are only planning to read/write text posts on Twitter, you can use Arcade without any additional setup.

#### Twitter app setup

You&#039;ll need to follow these instructions if you plan on uploading media to Twitter, and/or you are not using Arcade for authorization.

1. Create a Twitter developer account
2. Create a new app and give it a name.
3. Copy the `API Key`, `API Key Secret` and `Bearer Token` and set them as `TWITTER_API_KEY`, `TWITTER_API_KEY_SECRET`, and `TWITTER_BEARER_TOKEN` in your `.env` file.
4. After saving, visit the App Dashboard. Find the `User authentication settings` section, and click the `Set up` button. This is how you will authorize users to use the Twitter API on their behalf.
5. Set the following fields:

- `App permissions`: `Read and write`
- `Type of App`: `Web App, Automated App or Bot`
- `App info`:
  - `Callback URI/Redirect URL`: `http://localhost:3000/auth/twitter/callback`
  - `Website URL`: Your website URL

6. Save. You&#039;ll then be given a `Client ID` and `Client Secret`. Set these as `TWITTER_CLIENT_ID` and `TWITTER_CLIENT_SECRET` in your `.env` file.

Once done, run the `yarn start:auth` command to run the Twitter OAuth server. Open [http://localhost:3000](http://localhost:3000) in your browser, and click `Login with Twitter`.

After authorizing your account with the app, navigate to your terminal where you&#039;ll see a JSON object logged. Copy the `token` and `tokenSecret` values and set them as `TWITTER_USER_TOKEN` and `TWITTER_USER_TOKEN_SECRET` in your `.env` file.

#### LinkedIn app setup

You&#039;ll need to follow these instructions if you plan on posting to LinkedIn and are not using Arcade for authorization.

1. Create a new LinkedIn developer account, and app [here](https://developer.linkedin.com/)
2. After creating your app, navigate to the `Auth` tab, and add a new authorized redirect URL for OAuth 2.0. Set it to `http://localhost:3000/auth/linkedin/callback`
3. Go to the `Products` tab and enable the `Share on LinkedIn` and `Sign In with LinkedIn using OpenID Connect` products.

&lt;details&gt;
&lt;summary&gt;If you plan on posting from company pages, you&#039;ll need to do the following:&lt;/summary&gt;

1. If you plan on posting from company pages, you&#039;ll also need to enable the `Advertising API` product. Furthermore, ensure your personal account has at least one one of the following roles with the company page:

- `ADMINISTRATOR`
- `DIRECT_SPONSORED_CONTENT_POSTER`
- `RECRUITING_POSTER`

2. Next, ensure your company page has verified the app. You can create a verification link on the `Settings` tab of your app, then click the `Verify` button on the company page card.
3. Once requesting access, you&#039;ll need to fill out a form for verification. Once submitted, you should receive an email stating you&#039;ve been granted developer access which will give you the proper permission to test out the API until it&#039;s been approved.
4. Inside the [authorization server file (./src/clients/auth-server.ts)](./src/clients/auth-server.ts), ensure the `w_organization_social` scope is enabled inside the scopes string in the `/auth/linkedin` route. Once done, the scopes string should look like this: `openid profile email w_member_social w_organization_social`
5. Get the organization ID from the URL of the company page when you&#039;re logged in as an admin and set it as the `LINKEDIN_ORGANIZATION_ID` environment variable. For example, if the URL is `https://www.linkedin.com/company/12345678/admin/dashboard/`, the organization ID would be `12345678`.

&gt; [!NOTE]
&gt; If you plan on only posting from the company account, you can set the `POST_TO_LINKEDIN_ORGANIZATION` to `&quot;true&quot;` in your `.env` file. If you want to choose dynamically, you can set this to `true`/`false` in the configurable fields (`postToLinkedInOrganization`) when invoking the `generate_post` graph.
&gt;
&gt; This value will take precedence over the `POST_TO_LINKEDIN_ORGANIZATION` environment variable.

&lt;/details&gt;

4. Save the following environment variables in your `.env` file:

- `LINKEDIN_CLIENT_ID`
- `LINKEDIN_CLIENT_SECRET`

5. Run the `yarn start:auth` command to run the LinkedIn OAuth server. Open [http://localhost:3000](http://localhost:3000) in your browser, and click `Login with LinkedIn`.
6. After logging in, copy the `access_token` and `sub` values from the objects logged to the terminal. Set these values as `LINKEDIN_ACCESS_TOKEN` (`access_token`) and `LINKEDIN_PERSON_URN` (`sub`) in your `.env` file.

&lt;/details&gt;

### Setup Supabase

Supabase is required for storing images found/generated by the agent. This step is not required for running the agent in basic setup mode.

To setup Supabase, create an account and a new project.

Set the `SUPABASE_URL` and `SUPABASE_SERVICE_ROLE_KEY` environment variables to the values provided by Supabase.

Create a new storage bucket called `images`. Make sure the bucket is set to public to the image URLs are accessible. Also ensure the max upload size is set to at least 5MB inside the global project settings, and the bucket specific settings.

### Setup Slack

Slack integration is optional, but recommended if you intend on using the `ingest_data` agent, or having updates sent to Slack.

This agent can be used in a cron job to fetch messages from a Slack channel, and call the `generate_post` graph for each message. We use this flow internally at LangChain to enable having a single Slack channel for submitting relevant URLs to the agent, which are then turned into posts once daily.

To configure the Slack integration, create a new Slack app and install it into your desired Slack workspace.

Once installed, ensure it has access to the channel you want to ingest messages from. Additionally, if you want it to send update messages to Slack, it will need write permissions to the workspace.

Finally, make sure the `SLACK_BOT_TOKEN` environment variable is set in your `.env` file. Then, when you create a cron (see the [Setup Crons](#setup-crons) section), you&#039;ll only have to pass in the channel ID to ingest messages from.

To enable sending updates to Slack, add a `SLACK_CHANNEL_ID` environment variable to your `.env` file with the channel ID you want to send updates to (at LangChain, we have one channel for sending content links, and a separate one for sending update messages).

### Setup GitHub

The GitHub API token is required to fetch details about GitHub repository URLs submitted to the agent. This is not required if you do not plan on sending GitHub URLs to the agent.

To get a GitHub API token, create a new fine grained token with the `Public Repositories (read-only)` scope at a minimum. If you intend on using this agent for private GitHub repositories, you&#039;ll need to give the token access to those repositories as well.

Ensure this is set as `GITHUB_TOKEN` in your `.env` file.

# Usage

## Generate Post

Once all the setup steps have been completed, start your graph server by running:

```bash
yarn langgraph:in_mem:up
```

&gt; [!NOTE]
&gt; The first time running this command (or if a new version of `@langchain/langgraph-cli` has been released), it will ask you to accept an install for the CLI. Enter `y` to accept.

Once the server is ready, you can execute the following command to generate a post:

(before doing this, you should edit the file so that the text only mode is set to false: `[TEXT_ONLY_MODE]: false` if using advanced setup mode)

```bash
yarn generate_post
```

This will kick off a new run to generate a post on a [LangChain blog post](https://blog.langchain.dev/customers-appfolio/).

To view the output, either inspect it in LangSmith, or use [the Agent Inbox](#setup-agent-inbox).

You may also modify this script to pass different URLs to generate posts for other content.

## Setup Crons

The Agent Inbox is most powerful when used with cron jobs. Doing this allows you to send links to generate posts on to a Slack channel, and have the cron job check for these links asynchronously. With this setup, you can send links to Slack, and have the inbox handle the rest while you sleep.

We have a series of scripts to help with this, which you can find in the [`scripts/crons`](./scripts/crons) directory. In this section, we&#039;ll explain how to quickly create a cron for ingesting links to your graph from Slack.

### Slack Setup

Before we get started, ensure you have the proper Slack integration setup, as described in the [Setup Slack](#setup-slack) section. Then, edit the [`create-cron.ts`](./scripts/crons/create-cron.ts) file, and set the `slackChannelId` field to the channel ID of the channel you want to ingest links from.

After editing, run the following command to create the cron:

```bash
yarn cron:create
```

This will create a new cron job that will ingest links from Slack into your graph, once daily.

## Prebuilt Scripts

For more information on all of the prebuilt scripts, see the [`scripts/README.md`](./scripts/README.md) file.

# Setup Agent Inbox

The Agent Inbox is the easiest way to view interrupted events, and manage accepting, responding, or other allowed actions. To view your events in the inbox, you can either add your graph to the deployed version of the Agent Inbox, or clone &amp; run the Agent Inbox locally.

## Using the deployed inbox

The Agent Inbox is setup in a way that allows for any graph --local or deployed-- to be added &amp; accessed via the UI.

To add your local graph to the inbox, visit the deployed site here: [dev.agentinbox.ai](https://dev.agentinbox.ai/).

If it&#039;s your first time vising the site, you&#039;ll immediately be prompted to add a new graph. Fill out the form with the following values:

- Graph ID: `generate_post`
- Graph API URL: `http://localhost:54367`
- Name: (optional) `Generate Post (local)`

After saving, you should be able to view your graph in the inbox. If you do this after invoking your graph (and waiting for the thread to interrupt), it will automatically fetch the interrupted event.

## Using the local inbox

To run the Agent Inbox locally, follow the setup instructions [here](https://github.com/langchain-ai/agent-inbox/blob/main/README.md).

Once the web server is running, open your browser and visit [http://localhost:3000](http://localhost:3000). This will then prompt you to add your graph to the inbox.

Fill out the form with the following values:

- Graph ID: `generate_post`
- Graph API URL: `http://localhost:54367`
- Name: (optional) `Generate Post (local)`

## Using the Agent Inbox with a graph deployed on LangGraph Platform

The Agent Inbox can also be used with graph&#039;s deployed in production on LangGraph Platform. To use these graphs, the setup steps are the exact same, with the only difference being the graph API URL should be the URL of the deployed graph, and you&#039;re required to set a LangSmith API key. This is required to fetch &amp; invoke the deployed graph. LangSmith API keys are stored in your browser&#039;s local storage, and never stored on the server.

# Customization

## Prompts

This agent is setup to generate posts for LangChain, using LangChain products as context. To use the agent for your own use case, you should update the following prompts/prompt sections inside the [`prompts`](./src/agents/generate-post/prompts/index.ts) folder:

- `BUSINESS_CONTEXT` - Context to be used when checking whether or not content is relevant to your business/use case.
- `TWEET_EXAMPLES` ([`prompts/examples.ts`](./src/agents/generate-post/prompts/examples.ts)) - A list of examples of posts you&#039;d like the agent to use as a guide when generating the final post.
- `POST_STRUCTURE_INSTRUCTIONS` - A set of structure instructions for the agent to follow when generating the final post.
- `POST_CONTENT_RULES` - A set of general writing style/content guidelines for the agent to follow when generating a post.

The prompt for the marketing report is located in the [`generate-post/nodes/generate-report/prompts.ts`](./src/agents/generate-post/nodes/generate-report/prompts.ts) file. You likely don&#039;t need to update this, as it&#039;s already structured to be general.

## Post Style

There are two main prompts to modify to change the style of the posts.

1. Post structure instructions (`POST_STRUCTURE_INSTRUCTIONS`). These are the instructions the LLM will follow for how to structure the post generations. This should _not_ be where you specify tone, or writing style. This prompt is used to set the structure each post should follow. By default, it&#039;s pr

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[bia-pain-bache/BPB-Worker-Panel]]></title>
            <link>https://github.com/bia-pain-bache/BPB-Worker-Panel</link>
            <guid>https://github.com/bia-pain-bache/BPB-Worker-Panel</guid>
            <pubDate>Fri, 23 Jan 2026 00:05:39 GMT</pubDate>
            <description><![CDATA[A GUI Panel providing Worker subscriptions for VLESS, Trojan and Warp configs alongside chain proxies, offering full DNS, clean IP, Fragment, Warp, Warp pro and routing settings for cross-platform clients using Amnezia, Wireguard, Sing-box, Clash/Mihomo and Xray cores.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bia-pain-bache/BPB-Worker-Panel">bia-pain-bache/BPB-Worker-Panel</a></h1>
            <p>A GUI Panel providing Worker subscriptions for VLESS, Trojan and Warp configs alongside chain proxies, offering full DNS, clean IP, Fragment, Warp, Warp pro and routing settings for cross-platform clients using Amnezia, Wireguard, Sing-box, Clash/Mihomo and Xray cores.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,460</p>
            <p>Forks: 31,503</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;BPB Panel&lt;/h1&gt;

### üåè Readme in [Farsi](README_fa.md)

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/assets/images/panel-overview.jpg&quot;&gt;
&lt;/p&gt;
&lt;br&gt;

## Introduction

This project is aimed to provide a user panel to access FREE, SECURE and PRIVATE **VLESS**, **Trojan** and **Warp** configs, It ensures connectivity even when domains or Warp services are blocked by ISPs, offering two deployment options:

- **Workers** deployment
- **Pages** deployment

üåü If you found **BPB Panel** valuable, Your donations make all the difference üåü

### USDT (BEP20)

```text
0xbdf15d41C56f861f25b2b11C835bd45dfD5b792F
```

## Features

1. **Free and Private**: No costs involved and the server is private.
2. **Intuitive Panel:** Streamlined for effortless navigation, configuration and use.
3. **Versatile Protocols:** Provides VLESS, Trojan and Wireguard (Warp) protocols.
4. **Warp Pro configs:** Optimized Warp for crucial circumstances.
5. **Fragment support:** Supports Fragment functionality for crucial network situations.
6. **Comprehensive Routing Rules:** Bypassing Iran/China/Russia, Blocking QUIC, Porn, Ads, Malwares, Phishing and also bypassing sanctions.
7. **Chain Proxy:** Capable of adding a chain proxy (VLESS, Trojan, Shadowsocks, socks and http) to fix IP.
8. **Broad client compatibility:** Offers subscription links for Xray, Sing-box and Clash-Mihomo core clients.
9. **Password-protected panel:** Provides secure and private panel with password protection.
10. **Fully customizable:** Supports setting up clean IP-domains, Proxy IPs, DNS servers, choosing ports and protocols, Warp endpoints and more.

## Limitations

1. **UDP transport**: VLESS and Trojan protocols on workers do not handle **UDP** properly, so it is disabled by default (affecting features like Telegram video calls), UDP DNS is also unsupported. DoH is enabled by default for enhanced security.
2. **Request limit**: each worker supports 100K requests per day for VLESS and Trojan, suitable for 2-3 users. You can use limitless Warp configs.

## Getting started

- [Installation methods](https://bia-pain-bache.github.io/BPB-Worker-Panel/installation/wizard/)
- [Configuration](https://bia-pain-bache.github.io/BPB-Worker-Panel/configuration/)
- [How to use](https://bia-pain-bache.github.io/BPB-Worker-Panel/usage/)
- [FAQ](https://bia-pain-bache.github.io/BPB-Worker-Panel/faq/)

## Supported Clients

|       Client        |      Version      |  Fragment support  |  Warp Pro support  |
| :-----------------: | :---------------: | :----------------: | :----------------: |
|     **v2rayNG**     | 1.10.26 or higher | :heavy_check_mark: | :heavy_check_mark: |
|     **MahsaNG**     |   14 or higher    | :heavy_check_mark: | :heavy_check_mark: |
|     **v2rayN**      | 7.15.4 or higher  | :heavy_check_mark: | :heavy_check_mark: |
|   **v2rayN-PRO**    |   1.9 or higher   | :heavy_check_mark: | :heavy_check_mark: |
|    **Sing-box**     | 1.12.0 or higher  | :heavy_check_mark: |        :x:         |
|    **Streisand**    | 1.6.64 or higher  | :heavy_check_mark: | :heavy_check_mark: |
|   **Clash Meta**    |                   |        :x:         | :heavy_check_mark: |
| **Clash Verge Rev** |                   |        :x:         | :heavy_check_mark: |
|     **FLClash**     |                   |        :x:         | :heavy_check_mark: |
|   **AmneziaVPN**    |                   |        :x:         | :heavy_check_mark: |
|    **WG Tunnel**    |                   |        :x:         | :heavy_check_mark: |

## Environment variables

|   Variable   |               Usage                |     Mandatory      |
| :----------: | :--------------------------------: | :----------------: |
|   **UUID**   |             VLESS UUID             | :heavy_check_mark: |
| **TR_PASS**  |          Trojan Password           | :heavy_check_mark: |
| **PROXY_IP** | Proxy IP or domain (VLESS, Trojan) |        :x:         |
|  **PREFIX**  |   NAT64 Prefixes (VLESS, Trojan)   |        :x:         |
| **SUB_PATH** |         Subscriptions&#039; URI         |        :x:         |
| **FALLBACK** |  Fallback domain (VLESS, Trojan)   |        :x:         |
| **DOH_URL**  |              Core DOH              |        :x:         |

---

## Stargazers Over Time

[![Stargazers Over Time](https://starchart.cc/bia-pain-bache/BPB-Worker-Panel.svg?variant=adaptive)](https://starchart.cc/bia-pain-bache/BPB-Worker-Panel)

---

### Special Thanks

- VLESS, Trojan [Cloudflare-workers/pages proxy script](https://github.com/yonggekkk/Cloudflare-workers-pages-vless) created by [yonggekkk](https://github.com/yonggekkk)
- CF-vless code author [3Kmfi6HP](https://github.com/3Kmfi6HP/EDtunnel)
- CF preferred IP program author [badafans](https://github.com/badafans/Cloudflare-IP-SpeedTest), [XIU2](https://github.com/XIU2/CloudflareSpeedTest)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>