<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Fri, 08 Aug 2025 00:05:14 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[browserbase/stagehand]]></title>
            <link>https://github.com/browserbase/stagehand</link>
            <guid>https://github.com/browserbase/stagehand</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[The AI Browser Automation Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/browserbase/stagehand">browserbase/stagehand</a></h1>
            <p>The AI Browser Automation Framework</p>
            <p>Language: TypeScript</p>
            <p>Stars: 15,656</p>
            <p>Forks: 938</p>
            <p>Stars today: 354 stars today</p>
            <h2>README</h2><pre>&lt;div id=&quot;toc&quot; align=&quot;center&quot; style=&quot;margin-bottom: 0;&quot;&gt;
  &lt;ul style=&quot;list-style: none; margin: 0; padding: 0;&quot;&gt;
    &lt;a href=&quot;https://stagehand.dev&quot;&gt;
      &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;media/dark_logo.png&quot; /&gt;
        &lt;img alt=&quot;Stagehand&quot; src=&quot;media/light_logo.png&quot; width=&quot;200&quot; style=&quot;margin-right: 30px;&quot; /&gt;
      &lt;/picture&gt;
    &lt;/a&gt;
  &lt;/ul&gt;
&lt;/div&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;The AI Browser Automation Framework&lt;/strong&gt;&lt;br&gt;
  &lt;a href=&quot;https://docs.stagehand.dev&quot;&gt;Read the Docs&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/browserbase/stagehand/tree/main?tab=MIT-1-ov-file#MIT-1-ov-file&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;media/dark_license.svg&quot; /&gt;
      &lt;img alt=&quot;MIT License&quot; src=&quot;media/light_license.svg&quot; /&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;media/dark_slack.svg&quot; /&gt;
      &lt;img alt=&quot;Slack Community&quot; src=&quot;media/light_slack.svg&quot; /&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://trendshift.io/repositories/12122&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12122&quot; alt=&quot;browserbase%2Fstagehand | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
If you&#039;re looking for the Python implementation, you can find it 
&lt;a href=&quot;https://github.com/browserbase/stagehand-python&quot;&gt; here&lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot; style=&quot;display: flex; align-items: center; justify-content: center; gap: 4px; margin-bottom: 0;&quot;&gt;
  &lt;b&gt;Vibe code&lt;/b&gt;
  &lt;span style=&quot;font-size: 1.05em;&quot;&gt; Stagehand with &lt;/span&gt;
  &lt;a href=&quot;https://director.ai&quot; style=&quot;display: flex; align-items: center;&quot;&gt;
    &lt;span&gt;Director&lt;/span&gt;
  &lt;/a&gt;
  &lt;span&gt; &lt;/span&gt;
  &lt;picture&gt;
    &lt;img alt=&quot;Director&quot; src=&quot;media/director_icon.svg&quot; width=&quot;25&quot; /&gt;
  &lt;/picture&gt;
&lt;/div&gt;

## Why Stagehand?

Most existing browser automation tools either require you to write low-level code in a framework like Selenium, Playwright, or Puppeteer, or use high-level agents that can be unpredictable in production. By letting developers choose what to write in code vs. natural language, Stagehand is the natural choice for browser automations in production.

1. **Choose when to write code vs. natural language**: use AI when you want to navigate unfamiliar pages, and use code ([Playwright](https://playwright.dev/)) when you know exactly what you want to do.

2. **Preview and cache actions**: Stagehand lets you preview AI actions before running them, and also helps you easily cache repeatable actions to save time and tokens.

3. **Computer use models with one line of code**: Stagehand lets you integrate SOTA computer use models from OpenAI and Anthropic into the browser with one line of code.

## Example

Here&#039;s how to build a sample browser automation with Stagehand:

&lt;div align=&quot;center&quot;&gt;
  &lt;div style=&quot;max-width:300px;&quot;&gt;
    &lt;img src=&quot;/media/github_demo.gif&quot; alt=&quot;See Stagehand in Action&quot;&gt;
  &lt;/div&gt;
&lt;/div&gt;

```typescript
// Use Playwright functions on the page object
const page = stagehand.page;
await page.goto(&quot;https://github.com/browserbase&quot;);

// Use act() to execute individual actions
await page.act(&quot;click on the stagehand repo&quot;);

// Use Computer Use agents for larger actions
const agent = stagehand.agent({
    provider: &quot;openai&quot;,
    model: &quot;computer-use-preview&quot;,
});
await agent.execute(&quot;Get to the latest PR&quot;);

// Use extract() to read data from the page
const { author, title } = await page.extract({
  instruction: &quot;extract the author and title of the PR&quot;,
  schema: z.object({
    author: z.string().describe(&quot;The username of the PR author&quot;),
    title: z.string().describe(&quot;The title of the PR&quot;),
  }),
});
```

## Documentation

Visit [docs.stagehand.dev](https://docs.stagehand.dev) to view the full documentation.

## Getting Started

Start with Stagehand with one line of code, or check out our [Quickstart Guide](https://docs.stagehand.dev/get_started/quickstart) for more information:

```bash
npx create-browser-app
```

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.loom.com/share/f5107f86d8c94fa0a8b4b1e89740f7a7&quot;&gt;
      &lt;p&gt;Watch Anirudh demo create-browser-app to create a Stagehand project!&lt;/p&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://www.loom.com/share/f5107f86d8c94fa0a8b4b1e89740f7a7&quot;&gt;
      &lt;img style=&quot;max-width:300px;&quot; src=&quot;https://cdn.loom.com/sessions/thumbnails/f5107f86d8c94fa0a8b4b1e89740f7a7-ec3f428b6775ceeb-full-play.gif&quot;&gt;
    &lt;/a&gt;
  &lt;/div&gt;

### Build and Run from Source

```bash
git clone https://github.com/browserbase/stagehand.git
cd stagehand
pnpm install
pnpm playwright install
pnpm run build
pnpm run example # run the blank script at ./examples/example.ts
pnpm run example 2048 # run the 2048 example at ./examples/2048.ts
```

Stagehand is best when you have an API key for an LLM provider and Browserbase credentials. To add these to your project, run:

```bash
cp .env.example .env
nano .env # Edit the .env file to add API keys
```

## Contributing

&gt; [!NOTE]  
&gt; We highly value contributions to Stagehand! For questions or support, please join our [Slack community](https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg).

At a high level, we&#039;re focused on improving reliability, speed, and cost in that order of priority. If you&#039;re interested in contributing, we strongly recommend reaching out to [Miguel Gonzalez](https://x.com/miguel_gonzf) or [Paul Klein](https://x.com/pk_iv) in our [Slack community](https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg) before starting to ensure that your contribution aligns with our goals.

For more information, please see our [Contributing Guide](https://docs.stagehand.dev/examples/contributing).

## Acknowledgements

This project heavily relies on [Playwright](https://playwright.dev/) as a resilient backbone to automate the web. It also would not be possible without the awesome techniques and discoveries made by [tarsier](https://github.com/reworkd/tarsier), [gemini-zod](https://github.com/jbeoris/gemini-zod), and [fuji-web](https://github.com/normal-computing/fuji-web).

We&#039;d like to thank the following people for their major contributions to Stagehand:
- [Paul Klein](https://github.com/pkiv)
- [Anirudh Kamath](https://github.com/kamath)
- [Sean McGuire](https://github.com/seanmcguire12)
- [Miguel Gonzalez](https://github.com/miguelg719)
- [Sameel Arif](https://github.com/sameelarif)
- [Filip Michalsky](https://github.com/filip-michalsky)
- [Jeremy Press](https://x.com/jeremypress)
- [Navid Pour](https://github.com/navidpour)

## License

Licensed under the MIT License.

Copyright 2025 Browserbase, Inc.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[simstudioai/sim]]></title>
            <link>https://github.com/simstudioai/sim</link>
            <guid>https://github.com/simstudioai/sim</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[Sim is an open-source AI agent workflow builder. Sim Studio's interface is a lightweight, intuitive way to quickly build and deploy LLMs that connect with your favorite tools.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/simstudioai/sim">simstudioai/sim</a></h1>
            <p>Sim is an open-source AI agent workflow builder. Sim Studio's interface is a lightweight, intuitive way to quickly build and deploy LLMs that connect with your favorite tools.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,029</p>
            <p>Forks: 929</p>
            <p>Stars today: 263 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;apps/sim/public/static/sim.png&quot; alt=&quot;Sim Logo&quot; width=&quot;500&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.apache.org/licenses/LICENSE-2.0&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-blue.svg&quot; alt=&quot;License: Apache-2.0&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/Hr4UWYEcTT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20Server-7289DA?logo=discord&amp;logoColor=white&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/simdotai&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/simstudioai?style=social&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/simstudioai/sim/pulls&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg&quot; alt=&quot;PRs welcome&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://docs.sim.ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Docs-visit%20documentation-blue.svg&quot; alt=&quot;Documentation&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;Sim&lt;/strong&gt; is a lightweight, user-friendly platform for building AI agent workflows.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;apps/sim/public/static/demo.gif&quot; alt=&quot;Sim Demo&quot; width=&quot;800&quot;/&gt;
&lt;/p&gt;

## Getting Started

1. Use our [cloud-hosted version](https://sim.ai)
2. Self-host using one of the methods below

## Self-Hosting Options

### Option 1: NPM Package (Simplest)

The easiest way to run Sim locally is using our [NPM package](https://www.npmjs.com/package/simstudio?activeTab=readme):

```bash
npx simstudio
```

After running these commands, open [http://localhost:3000/](http://localhost:3000/) in your browser.

#### Options

- `-p, --port &lt;port&gt;`: Specify the port to run Sim on (default: 3000)
- `--no-pull`: Skip pulling the latest Docker images

#### Requirements

- Docker must be installed and running on your machine

### Option 2: Docker Compose

```bash
# Clone the repository
git clone https://github.com/simstudioai/sim.git

# Navigate to the project directory
cd sim

# Start Sim
docker compose -f docker-compose.prod.yml up -d
```

Access the application at [http://localhost:3000/](http://localhost:3000/)

#### Using Local Models with Ollama

Run Sim with local AI models using [Ollama](https://ollama.ai) - no external APIs required:

```bash
# Start with GPU support (automatically downloads gemma3:4b model)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# For CPU-only systems:
docker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d
```

Wait for the model to download, then visit [http://localhost:3000](http://localhost:3000). Add more models with:
```bash
docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b
```

### Option 3: Dev Containers

1. Open VS Code with the [Remote - Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)
2. Open the project and click &quot;Reopen in Container&quot; when prompted
3. Run `bun run dev:full` in the terminal or use the `sim-start` alias
   - This starts both the main application and the realtime socket server

### Option 4: Manual Setup

**Requirements:**
- [Bun](https://bun.sh/) runtime
- PostgreSQL 12+ with [pgvector extension](https://github.com/pgvector/pgvector) (required for AI embeddings)

**Note:** Sim uses vector embeddings for AI features like knowledge bases and semantic search, which requires the `pgvector` PostgreSQL extension.

1. Clone and install dependencies:

```bash
git clone https://github.com/simstudioai/sim.git
cd sim
bun install
```

2. Set up PostgreSQL with pgvector:

You need PostgreSQL with the `vector` extension for embedding support. Choose one option:

**Option A: Using Docker (Recommended)**
```bash
# Start PostgreSQL with pgvector extension
docker run --name simstudio-db \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=simstudio \
  -p 5432:5432 -d \
  pgvector/pgvector:pg17
```

**Option B: Manual Installation**
- Install PostgreSQL 12+ and the pgvector extension
- See [pgvector installation guide](https://github.com/pgvector/pgvector#installation)

3. Set up environment:

```bash
cd apps/sim
cp .env.example .env  # Configure with required variables (DATABASE_URL, BETTER_AUTH_SECRET, BETTER_AUTH_URL)
```

Update your `.env` file with the database URL:
```bash
DATABASE_URL=&quot;postgresql://postgres:your_password@localhost:5432/simstudio&quot;
```

4. Set up the database:

```bash
bunx drizzle-kit migrate 
```

5. Start the development servers:

**Recommended approach - run both servers together (from project root):**

```bash
bun run dev:full
```

This starts both the main Next.js application and the realtime socket server required for full functionality.

**Alternative - run servers separately:**

Next.js app (from project root):
```bash
bun run dev
```

Realtime socket server (from `apps/sim` directory in a separate terminal):
```bash
cd apps/sim
bun run dev:sockets
```

## Tech Stack

- **Framework**: [Next.js](https://nextjs.org/) (App Router)
- **Runtime**: [Bun](https://bun.sh/)
- **Database**: PostgreSQL with [Drizzle ORM](https://orm.drizzle.team)
- **Authentication**: [Better Auth](https://better-auth.com)
- **UI**: [Shadcn](https://ui.shadcn.com/), [Tailwind CSS](https://tailwindcss.com)
- **State Management**: [Zustand](https://zustand-demo.pmnd.rs/)
- **Flow Editor**: [ReactFlow](https://reactflow.dev/)
- **Docs**: [Fumadocs](https://fumadocs.vercel.app/)
- **Monorepo**: [Turborepo](https://turborepo.org/)
- **Realtime**: [Socket.io](https://socket.io/)
- **Background Jobs**: [Trigger.dev](https://trigger.dev/)

## Contributing

We welcome contributions! Please see our [Contributing Guide](.github/CONTRIBUTING.md) for details.

## License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

&lt;p align=&quot;center&quot;&gt;Made with ❤️ by the Sim Team&lt;/p&gt;</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[prisma/prisma]]></title>
            <link>https://github.com/prisma/prisma</link>
            <guid>https://github.com/prisma/prisma</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[Next-generation ORM for Node.js & TypeScript | PostgreSQL, MySQL, MariaDB, SQL Server, SQLite, MongoDB and CockroachDB]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prisma/prisma">prisma/prisma</a></h1>
            <p>Next-generation ORM for Node.js & TypeScript | PostgreSQL, MySQL, MariaDB, SQL Server, SQLite, MongoDB and CockroachDB</p>
            <p>Language: TypeScript</p>
            <p>Stars: 43,351</p>
            <p>Forks: 1,828</p>
            <p>Stars today: 230 stars today</p>
            <h2>README</h2><pre>![Prisma](https://i.imgur.com/h6UIYTu.png)

&lt;div align=&quot;center&quot;&gt;
  &lt;h1&gt;Prisma&lt;/h1&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/prisma&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/prisma.svg?style=flat&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/prisma/prisma/blob/main/CONTRIBUTING.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/prisma/prisma/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-Apache%202-blue&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://pris.ly/discord&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/937751382725886062?label=Discord&quot;&gt;&lt;/a&gt;
  &lt;br /&gt;
  &lt;br /&gt;
  &lt;a href=&quot;https://www.prisma.io/docs/getting-started/quickstart&quot;&gt;Quickstart&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://www.prisma.io/&quot;&gt;Website&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://www.prisma.io/docs/&quot;&gt;Docs&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://github.com/prisma/prisma-examples/&quot;&gt;Examples&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://www.prisma.io/blog&quot;&gt;Blog&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://pris.ly/discord?utm_source=github&amp;utm_medium=prisma&amp;utm_content=repo_readme&quot;&gt;Discord&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://pris.ly/x?utm_source=github&amp;utm_medium=prisma&amp;utm_content=repo_readme&quot;&gt;Twitter&lt;/a&gt;
  &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
  &lt;a href=&quot;https://pris.ly/youtube?utm_source=github&amp;utm_medium=prisma&amp;utm_content=repo_readme&quot;&gt;Youtube&lt;/a&gt;
  &lt;br /&gt;
  &lt;hr /&gt;
&lt;/div&gt;

## What is Prisma?

Prisma ORM is a **next-generation ORM** that consists of these tools:

- [**Prisma Client**](https://www.prisma.io/docs/concepts/components/prisma-client): Auto-generated and type-safe query builder for Node.js &amp; TypeScript
- [**Prisma Migrate**](https://www.prisma.io/docs/concepts/components/prisma-migrate): Declarative data modeling &amp; migration system
- [**Prisma Studio**](https://github.com/prisma/studio): GUI to view and edit data in your database

Prisma Client can be used in _any_ Node.js or TypeScript backend application (including serverless applications and microservices). This can be a [REST API](https://www.prisma.io/docs/concepts/overview/prisma-in-your-stack/rest), a [GraphQL API](https://www.prisma.io/docs/concepts/overview/prisma-in-your-stack/graphql), a gRPC API, or anything else that needs a database.

**If you need a database to use with Prisma ORM, check out [Prisma Postgres](https://www.prisma.io/docs/getting-started/quickstart-prismaPostgres?utm_source=github&amp;utm_medium=prisma-readme) or if you are looking for our MCP Server, head [here](https://github.com/prisma/mcp).**

## Getting started

### Quickstart (5min)

The fastest way to get started with Prisma is by following the quickstart guides. You can choose either of two databases:

- [Prisma Postgres](https://www.prisma.io/docs/getting-started/quickstart-prismaPostgres)
- [SQLite](https://www.prisma.io/docs/getting-started/quickstart-sqlite)

### Bring your own database

If you already have your own database, you can follow these guides:

- [Add Prisma to an existing project](https://www.prisma.io/docs/getting-started/setup-prisma/add-to-existing-project/relational-databases-typescript-postgresql)
- [Set up a new project with Prisma from scratch](https://www.prisma.io/docs/getting-started/setup-prisma/start-from-scratch/relational-databases-typescript-postgresql)

## How Prisma ORM works

This section provides a high-level overview of how Prisma ORM works and its most important technical components. For a more thorough introduction, visit the [Prisma documentation](https://www.prisma.io/docs/).

### The Prisma schema

Every project that uses a tool from the Prisma toolkit starts with a [Prisma schema file](https://www.prisma.io/docs/concepts/components/prisma-schema). The Prisma schema allows developers to define their _application models_ in an intuitive data modeling language. It also contains the connection to a database and defines a _generator_:

```prisma
// Data source
datasource db {
  provider = &quot;postgresql&quot;
  url      = env(&quot;DATABASE_URL&quot;)
}

// Generator
generator client {
  provider = &quot;prisma-client-js&quot;
}

// Data model
model Post {
  id        Int     @id @default(autoincrement())
  title     String
  content   String?
  published Boolean @default(false)
  author    User?   @relation(fields:  [authorId], references: [id])
  authorId  Int?
}

model User {
  id    Int     @id @default(autoincrement())
  email String  @unique
  name  String?
  posts Post[]
}
```

In this schema, you configure three things:

- **Data source**: Specifies your database connection (via an environment variable)
- **Generator**: Indicates that you want to generate Prisma Client
- **Data model**: Defines your application models

---

### The Prisma data model

On this page, the focus is on the data model. You can learn more about [Data sources](https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema/data-sources) and [Generators](https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema/generators) on the respective docs pages.

#### Functions of Prisma models

The data model is a collection of [models](https://www.prisma.io/docs/concepts/components/prisma-schema/data-model#defining-models). A model has two major functions:

- Represent a table in the underlying database
- Provide the foundation for the queries in the Prisma Client API

#### Getting a data model

There are two major workflows for &quot;getting&quot; a data model into your Prisma schema:

- Generate the data model from [introspecting](https://www.prisma.io/docs/concepts/components/introspection) a database
- Manually writing the data model and mapping it to the database with [Prisma Migrate](https://www.prisma.io/docs/concepts/components/prisma-migrate)

Once the data model is defined, you can [generate Prisma Client](https://www.prisma.io/docs/concepts/components/prisma-client/generating-prisma-client) which will expose CRUD and more queries for the defined models. If you&#039;re using TypeScript, you&#039;ll get full type-safety for all queries (even when only retrieving the subsets of a model&#039;s fields).

---

### Accessing your database with Prisma Client

#### Generating Prisma Client

The first step when using Prisma Client is installing its npm package:

```
npm install @prisma/client
```

Note that the installation of this package invokes the `prisma generate` command which reads your Prisma schema and _generates_ the Prisma Client code. The code will be located in `node_modules/.prisma/client`, which is exported by `node_modules/@prisma/client/index.d.ts`.

After you change your data model, you&#039;ll need to manually re-generate Prisma Client to ensure the code inside `node_modules/.prisma/client` gets updated:

```
npx prisma generate
```

Refer to the documentation for more information about [&quot;generating the Prisma client&quot;](https://www.prisma.io/docs/concepts/components/prisma-client/generating-prisma-client).

#### Using Prisma Client to send queries to your database

Once the Prisma Client is generated, you can import it in your code and send queries to your database. This is what the setup code looks like.

##### Import and instantiate Prisma Client

You can import and instantiate Prisma Client as follows:

```ts
import { PrismaClient } from &#039;@prisma/client&#039;

const prisma = new PrismaClient()
```

or

```js
const { PrismaClient } = require(&#039;@prisma/client&#039;)

const prisma = new PrismaClient()
```

Now you can start sending queries via the generated Prisma Client API, here are a few sample queries. Note that all Prisma Client queries return _plain old JavaScript objects_.

Learn more about the available operations in the [Prisma Client docs](https://www.prisma.io/docs/concepts/components/prisma-client) or watch this [demo video](https://www.youtube.com/watch?v=LggrE5kJ75I&amp;list=PLn2e1F9Rfr6k9PnR_figWOcSHgc_erDr5&amp;index=4) (2 min).

##### Retrieve all `User` records from the database

```ts
const allUsers = await prisma.user.findMany()
```

##### Include the `posts` relation on each returned `User` object

```ts
const allUsers = await prisma.user.findMany({
  include: { posts: true },
})
```

##### Filter all `Post` records that contain `&quot;prisma&quot;`

```ts
const filteredPosts = await prisma.post.findMany({
  where: {
    OR: [{ title: { contains: &#039;prisma&#039; } }, { content: { contains: &#039;prisma&#039; } }],
  },
})
```

##### Create a new `User` and a new `Post` record in the same query

```ts
const user = await prisma.user.create({
  data: {
    name: &#039;Alice&#039;,
    email: &#039;alice@prisma.io&#039;,
    posts: {
      create: { title: &#039;Join us for Prisma Day 2021&#039; },
    },
  },
})
```

##### Update an existing `Post` record

```ts
const post = await prisma.post.update({
  where: { id: 42 },
  data: { published: true },
})
```

#### Usage with TypeScript

Note that when using TypeScript, the result of this query will be _statically typed_ so that you can&#039;t accidentally access a property that doesn&#039;t exist (and any typos are caught at compile-time). Learn more about leveraging Prisma Client&#039;s generated types on the [Advanced usage of generated types](https://www.prisma.io/docs/concepts/components/prisma-client/advanced-usage-of-generated-types) page in the docs.

## Community

Prisma has a large and supportive [community](https://www.prisma.io/community) of enthusiastic application developers. You can join us on [Discord](https://pris.ly/discord) and here on [GitHub](https://github.com/prisma/prisma/discussions).

## Badges

[![Made with Prisma](http://made-with.prisma.io/dark.svg)](https://prisma.io) [![Made with Prisma](http://made-with.prisma.io/indigo.svg)](https://prisma.io)

Built something awesome with Prisma? 🌟 Show it off with these [badges](https://github.com/prisma/presskit?tab=readme-ov-file#badges), perfect for your readme or website.

```
[![Made with Prisma](http://made-with.prisma.io/dark.svg)](https://prisma.io)
```

```
[![Made with Prisma](http://made-with.prisma.io/indigo.svg)](https://prisma.io)
```

## Security

If you have a security issue to report, please contact us at [security@prisma.io](mailto:security@prisma.io?subject=[GitHub]%20Prisma%202%20Security%20Report%20).

## Support

### Ask a question about Prisma

You can ask questions and initiate [discussions](https://github.com/prisma/prisma/discussions/) about Prisma-related topics in the `prisma` repository on GitHub.

👉 [**Ask a question**](https://github.com/prisma/prisma/discussions/new)

### Create a bug report for Prisma

If you see an error message or run into an issue, please make sure to create a bug report! You can find [best practices for creating bug reports](https://www.prisma.io/docs/guides/other/troubleshooting-orm/creating-bug-reports) (like including additional debugging output) in the docs.

👉 [**Create bug report**](https://pris.ly/prisma-prisma-bug-report)

### Submit a feature request

If Prisma currently doesn&#039;t have a certain feature, be sure to check out the [roadmap](https://www.prisma.io/docs/more/roadmap) to see if this is already planned for the future.

If the feature on the roadmap is linked to a GitHub issue, please make sure to leave a 👍 reaction on the issue and ideally a comment with your thoughts about the feature!

👉 [**Submit feature request**](https://github.com/prisma/prisma/issues/new?assignees=&amp;labels=&amp;template=feature_request.md&amp;title=)

## Contributing

Refer to our [contribution guidelines](https://github.com/prisma/prisma/blob/main/CONTRIBUTING.md) and [Code of Conduct for contributors](https://github.com/prisma/prisma/blob/main/CODE_OF_CONDUCT.md).

## Tests Status

- Prisma Tests Status:
  [![Prisma Tests Status](https://github.com/prisma/prisma/workflows/CI/badge.svg)](https://github.com/prisma/prisma/actions/workflows/test.yml?query=branch%3Amain)
- Ecosystem Tests Status:
  [![Ecosystem Tests Status](https://github.com/prisma/ecosystem-tests/workflows/test/badge.svg)](https://github.com/prisma/ecosystem-tests/actions/workflows/test.yaml?query=branch%3Adev)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[thewh1teagle/vibe]]></title>
            <link>https://github.com/thewh1teagle/vibe</link>
            <guid>https://github.com/thewh1teagle/vibe</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[Transcribe on your own!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/thewh1teagle/vibe">thewh1teagle/vibe</a></h1>
            <p>Transcribe on your own!</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,617</p>
            <p>Forks: 209</p>
            <p>Stars today: 44 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a target=&quot;blank&quot; href=&quot;https://github.com/thewh1teagle/vibe&quot;&gt;
    &lt;img
        width=&quot;96px&quot;
        alt=&quot;Vibe logo&quot;
        src=&quot;./design/logo.png&quot;
    /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Vibe - Transcribe on your own!&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;⌨️ Transcribe audio / video offline using OpenAI Whisper&lt;/strong&gt;
  &lt;br/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://thewh1teagle.github.io/vibe/&quot;&gt;
    🔗 Download Vibe
  &lt;/a&gt;
    &amp;nbsp; | &amp;nbsp; Give it a Star ⭐ | &amp;nbsp;
    &lt;a target=&quot;_blank&quot; href=&quot;https://thewh1teagle.github.io/vibe/?action=support-vibe&quot;&gt;Support the project 🤝&lt;/a&gt;
&lt;/p&gt;

&lt;hr /&gt;

## Screenshots

&lt;p align=&quot;center&quot;&gt;
	&lt;a target=&quot;_blank&quot; href=&quot;https://thewh1teagle.github.io/vibe/&quot;&gt;
    	&lt;img width=600 src=&quot;https://github.com/thewh1teagle/vibe/assets/61390950/22779ac6-9e49-4c21-b528-29647f039da2&quot;&gt;
	&lt;/a&gt;
&lt;/p&gt;

# Features 🌟

-   🌍 Transcribe almost every language
-   🔒 Ultimate privacy: fully offline transcription, no data ever leaves your device
-   🎨 User friendly design
-   🎙️ Transcribe audio / video
-   🎶 Option to transcribe audio from popular websites (YouTube, Vimeo, Facebook, Twitter and more!)
-   📂 Batch transcribe multiple files!
-   📝 Support `SRT`, `VTT`, `TXT`, `HTML`, `PDF`, `JSON`, `DOCX` formats
-   👀 Realtime preview
-   ✨ Summarize transcripts: Get quick, multilingual summaries using the Claude API
-   🧠 Ollama support: Do local AI analysis and batch summaries with Ollama
-   🌐 Translate to English from any language
-   🖨️ Print transcript directly to any printer
-   🔄 Automatic updates
-   💻 Optimized for `GPU` (`macOS`, `Windows`, `Linux`)
-   🎮 Optimized for `Nvidia` / `AMD` / `Intel` GPUs! (`Vulkan`/`CoreML`)
-   🔧 Total Freedom: Customize Models Easily via Settings
-   ⚙️ Model arguments for advanced users
-   ⏳ Transcribe system audio
-   🎤 Transcribe from microphone
-   🖥️ CLI support: Use Vibe directly from the command line interface! (see `--help`)
-   👥 Speaker diarization
-   📱 ~iOS &amp; Android support~ (coming soon)
-   📥 Integrate custom models from your own site: Use `vibe://download/?url=&lt;model url&gt;`
-   📹 Choose caption length optimized for videos / reels
-   ⚡ HTTP API with Swagger docs! (use `--server` and open `http://&lt;host&gt;:3022/docs` for docs)

# Supported platforms 🖥️

`MacOS`
`Windows`
`Linux`

# Contribute 🤝

PRs are welcomed!
In addition, you&#039;re welcome to add translations.

We would like to express our sincere gratitude to all the contributors.

&lt;a href=&quot;https://github.com/thewh1teagle/vibe/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=thewh1teagle/vibe&quot; /&gt;
&lt;/a&gt;

# Community

[![Discord](https://img.shields.io/badge/chat-discord-7289da.svg)](https://discord.gg/EcxWSstQN8)

# Roadmap 🛣️

You can see the roadmap in [Vibe-Roadmap](https://github.com/users/thewh1teagle/projects/5/views/1)

# Add translation 🌐

1. Copy `en` from `desktop/src-tauri/locales` folder to new directory eg `pt-BR` (use [bcp47 language code](https://gist.github.com/thewh1teagle/c8877e5c4c5e2780754ddd065ae2592e))
2. Change every value in the files there, to the new language and keep the keys as is
3. create PR / issue in Github

In addition you can add translation to [Vibe website](https://thewh1teagle.github.io/vibe/) by creating new files in the `landing/static/locales`.

# Docs 📄

see [Vibe Docs](https://github.com/thewh1teagle/vibe/tree/main/docs)

# I want to know more!

Medium [post](https://medium.com/@thewh1teagle/creating-vibe-multilingual-audio-transcription-872ab6d9dbb0)

# Issue report

You can open [new issue](https://github.com/thewh1teagle/vibe/issues/new?assignees=octocat&amp;labels=bug&amp;projects=&amp;template=bug_report.yaml&amp;title=[Short+title]) and it&#039;s recommend to check [debug.md](docs/debug.md) first.

# Privacy Policy 🔒

Your privacy is important to us. Please review our [Privacy Policy](http://thewh1teagle.github.io/vibe/?action=open-privacy-policy) to understand how we handle your data.

# Credits

Thanks for [tauri.app](https://tauri.app/) for making the best apps framework I ever seen

Thanks for [wang-bin/avbuild](https://github.com/wang-bin/avbuild) for pre built `ffmpeg`

Thanks for [github.com/whisper.cpp](https://github.com/ggerganov/whisper.cpp) for outstanding interface for the AI model.

Thanks for [openai.com](https://openai.com/) for their amazing [Whisper model](https://openai.com/research/whisper)

Thanks for [github.com](https://github.com/) for their support in open source projects, providing infastructure completely free.

And for all the amazing open source frameworks and libraries which this project uses...
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[devlikeapro/waha]]></title>
            <link>https://github.com/devlikeapro/waha</link>
            <guid>https://github.com/devlikeapro/waha</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[WAHA - WhatsApp HTTP API (REST API) that you can configure in a click! 3 engines: WEBJS (browser based), NOWEB (websocket nodejs), GOWS (websocket go)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/devlikeapro/waha">devlikeapro/waha</a></h1>
            <p>WAHA - WhatsApp HTTP API (REST API) that you can configure in a click! 3 engines: WEBJS (browser based), NOWEB (websocket nodejs), GOWS (websocket go)</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,433</p>
            <p>Forks: 714</p>
            <p>Stars today: 470 stars today</p>
            <h2>README</h2><pre># WAHA

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./logo.png&quot; style=&#039;border-radius: 50%&#039; width=&#039;150&#039;/&gt;
&lt;/p&gt;

**WAHA** - **W**hats**A**pp **H**TTP **A**PI (REST API) that you can install on your own server and run in less than 5 minutes!

[![Docker Pulls](https://img.shields.io/docker/pulls/devlikeapro/waha)](https://hub.docker.com/r/devlikeapro/waha)

- Documentation: [https://waha.devlike.pro/](https://waha.devlike.pro/)
- Dashboard Example: [https://waha.devlike.pro/dashboard](https://waha.devlike.pro/dashboard)
- Swagger Example: [https://waha.devlike.pro/swagger](https://waha.devlike.pro/swagger)

# Tables of Contents

&lt;!-- toc --&gt;

- [Quick start](#quick-start)
  * [Requirements](#requirements)
  * [Send your first message](#send-your-first-message)
    + [1. Download image](#1-download-image)
    + [2. Run WhatsApp HTTP API](#2-run-whatsapp-http-api)
    + [3. Start a new session](#3-start-a-new-session)
    + [4. Get and scan QR](#4-get-and-scan-qr)
    + [5. Get the screenshot](#5-get-the-screenshot)
    + [6. Send a text message](#6-send-a-text-message)
  * [What is next?](#what-is-next)
- [Development](#development)
  * [Start the project](#start-the-project)

&lt;!-- tocstop --&gt;

# Quick start

## Requirements

Only thing that you must have - installed docker. Please follow the original
instruction &lt;a href=&quot;https://docs.docker.com/get-docker/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;how to install docker -&gt;&lt;/a&gt;.

When you are ready - come back and follows the below steps to send the first text message to WhatsApp via HTTP API!

## Send your first message

Let&#039;s go over steps that allow you to send your first text message via WhatsApp HTTP API!

### 1. Download image

Assuming you have installed [Docker](https://docs.docker.com/get-docker/), let&#039;s download the image.


```bash
docker pull devlikeapro/waha
```


```bash
docker login -u devlikeapro -p {KEY}
docker pull devlikeapro/waha-plus
docker logout
```

Read more about how to get `PASSWORD` for [**➕ WAHA Plus**](https://waha.devlike.pro/docs/how-to/waha-plus/)

### 2. Run WhatsApp HTTP API

Run WhatsApp HTTP API:

```bash
docker run -it --rm -p 3000:3000/tcp --name waha devlikeapro/waha

# It prints logs and the last line must be
# WhatsApp HTTP API is running on: http://[::1]:3000
```

Open the link in your browser [http://localhost:3000/](http://localhost:3000/) and you&#039;ll see API documentation
(Swagger).


### 3. Start a new session

To start a new session you should have your mobile phone with installed WhatsApp application close to you.

Please go and read how what we&#039;ll need to a bit
later:
&lt;a href=&quot;https://faq.whatsapp.com/381777293328336/?helpref=hc_fnav&quot; target=&quot;_blank&quot;&gt;
How to log in - the instruction on WhatsApp site
&lt;/a&gt;

When your ready - find `POST /api/sessions`, click on **Try it out**, then **Execute** a bit below.


The example payload:
```json
{
  &quot;name&quot;: &quot;default&quot;
}
```


By using the request with `name` values you can start multiple session (WhatsApp accounts) inside the single docker container in Plus


### 4. Get and scan QR

Find `GET /api/screenshot` and execute it, it shows you QR code.


**Scan the QR with your cell phone&#039;s WhatsApp app.**


### 5. Get the screenshot

Execute `GET /api/screenshot` after a few seconds after scanning the QR - it&#039;ll show you the screenshot of you Whatsapp
instance. If you can get the actual screenshot - then you&#039;re ready to start sending messages!


### 6. Send a text message

Let&#039;s send a text message - find `POST /api/sendText`  in [swagger](http://localhost:3000/) and change `chatId` this
way: use a phone international phone number without `+` symbol and add `@c.us` at the end.

For phone number `12132132131` the `chatId` is  `12132132131@c.us`.

The example payload:
```json
{
  &quot;chatId&quot;: &quot;12132132130@c.us&quot;,
  &quot;text&quot;: &quot;Hi there!&quot;,
  &quot;session&quot;: &quot;default&quot;
}
```

Also, you can use `curl` and send POST request like this:

```bash
# Phone without +
export PHONE=12132132130
curl -d &quot;{\&quot;chatId\&quot;: \&quot;${PHONE}@c.us\&quot;, \&quot;text\&quot;: \&quot;Hello from WhatsApp HTTP API\&quot; }&quot; -H &quot;Content-Type: application/json&quot; -X POST http://localhost:3000/api/sendText
```

## What is next?
[Go and read the full documentation!](https://waha.devlike.pro/docs/overview/introduction/)

# Development

## Start the project
1. Clone the repository
2. Make sure you&#039;re using node&gt;=22 (check [.nvmrc](/.nvmrc) to get the version)
3. Run the following commands:
```bash
# Install dependencies
yarn install
# Fetch and compile proto files
yarn gows:proto
# Run
yarn start
# open http://localhost:3000
```</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[n8n-io/n8n]]></title>
            <link>https://github.com/n8n-io/n8n</link>
            <guid>https://github.com/n8n-io/n8n</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/n8n-io/n8n">n8n-io/n8n</a></h1>
            <p>Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 127,709</p>
            <p>Forks: 39,276</p>
            <p>Stars today: 370 stars today</p>
            <h2>README</h2><pre>![Banner image](https://user-images.githubusercontent.com/10284570/173569848-c624317f-42b1-45a6-ab09-f0ea3c247648.png)

# n8n - Secure Workflow Automation for Technical Teams

n8n is a workflow automation platform that gives technical teams the flexibility of code with the speed of no-code. With 400+ integrations, native AI capabilities, and a fair-code license, n8n lets you build powerful automations while maintaining full control over your data and deployments.

![n8n.io - Screenshot](https://raw.githubusercontent.com/n8n-io/n8n/master/assets/n8n-screenshot-readme.png)

## Key Capabilities

- **Code When You Need It**: Write JavaScript/Python, add npm packages, or use the visual interface
- **AI-Native Platform**: Build AI agent workflows based on LangChain with your own data and models
- **Full Control**: Self-host with our fair-code license or use our [cloud offering](https://app.n8n.cloud/login)
- **Enterprise-Ready**: Advanced permissions, SSO, and air-gapped deployments
- **Active Community**: 400+ integrations and 900+ ready-to-use [templates](https://n8n.io/workflows)

## Quick Start

Try n8n instantly with [npx](https://docs.n8n.io/hosting/installation/npm/) (requires [Node.js](https://nodejs.org/en/)):

```
npx n8n
```

Or deploy with [Docker](https://docs.n8n.io/hosting/installation/docker/):

```
docker volume create n8n_data
docker run -it --rm --name n8n -p 5678:5678 -v n8n_data:/home/node/.n8n docker.n8n.io/n8nio/n8n
```

Access the editor at http://localhost:5678

## Resources

- 📚 [Documentation](https://docs.n8n.io)
- 🔧 [400+ Integrations](https://n8n.io/integrations)
- 💡 [Example Workflows](https://n8n.io/workflows)
- 🤖 [AI &amp; LangChain Guide](https://docs.n8n.io/langchain/)
- 👥 [Community Forum](https://community.n8n.io)
- 📖 [Community Tutorials](https://community.n8n.io/c/tutorials/28)

## Support

Need help? Our community forum is the place to get support and connect with other users:
[community.n8n.io](https://community.n8n.io)

## License

n8n is [fair-code](https://faircode.io) distributed under the [Sustainable Use License](https://github.com/n8n-io/n8n/blob/master/LICENSE.md) and [n8n Enterprise License](https://github.com/n8n-io/n8n/blob/master/LICENSE_EE.md).

- **Source Available**: Always visible source code
- **Self-Hostable**: Deploy anywhere
- **Extensible**: Add your own nodes and functionality

[Enterprise licenses](mailto:license@n8n.io) available for additional features and support.

Additional information about the license model can be found in the [docs](https://docs.n8n.io/reference/license/).

## Contributing

Found a bug 🐛 or have a feature idea ✨? Check our [Contributing Guide](https://github.com/n8n-io/n8n/blob/master/CONTRIBUTING.md) to get started.

## Join the Team

Want to shape the future of automation? Check out our [job posts](https://n8n.io/careers) and join our team!

## What does n8n mean?

**Short answer:** It means &quot;nodemation&quot; and is pronounced as n-eight-n.

**Long answer:** &quot;I get that question quite often (more often than I expected) so I decided it is probably best to answer it here. While looking for a good name for the project with a free domain I realized very quickly that all the good ones I could think of were already taken. So, in the end, I chose nodemation. &#039;node-&#039; in the sense that it uses a Node-View and that it uses Node.js and &#039;-mation&#039; for &#039;automation&#039; which is what the project is supposed to help with. However, I did not like how long the name was and I could not imagine writing something that long every time in the CLI. That is when I then ended up on &#039;n8n&#039;.&quot; - **Jan Oberhauser, Founder and CEO, n8n.io**
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[dyad-sh/dyad]]></title>
            <link>https://github.com/dyad-sh/dyad</link>
            <guid>https://github.com/dyad-sh/dyad</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[Free, local, open-source AI app builder ✨ v0 / lovable / Bolt alternative 🌟 Star if you like it!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dyad-sh/dyad">dyad-sh/dyad</a></h1>
            <p>Free, local, open-source AI app builder ✨ v0 / lovable / Bolt alternative 🌟 Star if you like it!</p>
            <p>Language: TypeScript</p>
            <p>Stars: 11,413</p>
            <p>Forks: 1,051</p>
            <p>Stars today: 1,161 stars today</p>
            <h2>README</h2><pre># dyad

Dyad is a local, open-source AI app builder. It&#039;s fast, private, and fully under your control — like Lovable, v0, or Bolt, but running right on your machine.

[![Image](https://github.com/user-attachments/assets/f6c83dfc-6ffd-4d32-93dd-4b9c46d17790)](http://dyad.sh/)

More info at: [http://dyad.sh/](http://dyad.sh/)

## 🚀 Features

- ⚡️ **Local**: Fast, private and no lock-in.
- 🛠 **Bring your own keys**: Use your own AI API keys — no vendor lock-in.
- 🖥️ **Cross-platform**: Easy to run on Mac or Windows.

## 📦 Download

No sign-up required. Just download and go.

### [👉 Download for your platform](https://www.dyad.sh/#download)

**Dyad** is open-source (Apache 2.0 licensed).

If you&#039;re interested in contributing to dyad, please read our [contributing](./CONTRIBUTING.md) doc.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[actualbudget/actual]]></title>
            <link>https://github.com/actualbudget/actual</link>
            <guid>https://github.com/actualbudget/actual</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[A local-first personal finance app]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/actualbudget/actual">actualbudget/actual</a></h1>
            <p>A local-first personal finance app</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,305</p>
            <p>Forks: 1,713</p>
            <p>Stars today: 42 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/demo.png&quot; alt=&quot;Actualbudget&quot; /&gt;
&lt;/p&gt;

## Getting Started

Actual is a local-first personal finance tool. It is 100% free and open-source, written in NodeJS, it has a synchronization element so that all your changes can move between devices without any heavy lifting.

If you are interested in contributing, or want to know how development works, see our [contributing](https://actualbudget.org/docs/contributing/) document we would love to have you.

Want to say thanks? Click the ⭐ at the top of the page.

## Key Links

- Actual [discord](https://discord.gg/pRYNYr4W5A) community.
- Actual [Community Documentation](https://actualbudget.org/docs)
- [Frequently asked questions](https://actualbudget.org/docs/faq)

## Installation

There are four ways to deploy Actual:

1. One-click deployment [via PikaPods](https://www.pikapods.com/pods?run=actual) (~1.40 $/month) - recommended for non-technical users
1. Managed hosting [via Fly.io](https://actualbudget.org/docs/install/fly) (~1.50 $/month)
1. Self-hosted by using [a Docker image](https://actualbudget.org/docs/install/docker)
1. Local-only apps - [downloadable Windows, Mac and Linux apps](https://actualbudget.org/download/) you can run on your device

Learn more in the [installation instructions docs](https://actualbudget.org/docs/install/).

## Ready to Start Budgeting?

Read about [Envelope budgeting](https://actualbudget.org/docs/getting-started/envelope-budgeting) to know more about the idea behind Actual Budget.

### Are you new to budgeting or want to start fresh?

Check out the community&#039;s [Starting Fresh](https://actualbudget.org/docs/getting-started/starting-fresh) guide so you can quickly get up and running!

### Are you migrating from other budgeting apps?

Check out the community&#039;s [Migration](https://actualbudget.org/docs/migration/) guide to start jumping on the Actual Budget train!

## Documentation

We have a wide range of documentation on how to use Actual, this is all available in our [Community Documentation](https://actualbudget.org/docs), this includes topics on Budgeting, Account Management, Tips &amp; Tricks and some documentation for developers.

## Contributing

Actual is a community driven product. Learn more about [contributing to Actual](https://actualbudget.org/docs/contributing/).

### Code structure

The Actual app is split up into a few packages:

- loot-core - The core application that runs on any platform
- desktop-client - The desktop UI
- desktop-electron - The desktop app

More information on the project structure is available in our [community documentation](https://actualbudget.org/docs/contributing/project-details).

### Feature Requests

Current feature requests can be seen [here](https://github.com/actualbudget/actual/issues?q=is%3Aissue+label%3A%22needs+votes%22+sort%3Areactions-%2B1-desc).
Vote for your favorite requests by reacting :+1: to the top comment of the request.

To add new feature requests, open a new Issue of the &quot;Feature Request&quot; type.

### Translation

Make Actual Budget accessible to more people by helping with the [Internationalization](https://actualbudget.org/docs/contributing/i18n/) of Actual. We are using a crowd sourcing tool to manage the translations, see our [Weblate Project](https://hosted.weblate.org/projects/actualbudget/). Weblate proudly supports open-source software projects through their [Libre plan](https://weblate.org/en/hosting/#libre).

&lt;a href=&quot;https://hosted.weblate.org/engage/actualbudget/&quot;&gt;
&lt;img src=&quot;https://hosted.weblate.org/widget/actualbudget/actual/287x66-grey.png&quot; alt=&quot;Translation status&quot; /&gt;
&lt;/a&gt;

## Repo Activity

![Alt](https://repobeats.axiom.co/api/embed/e20537dd8b74956f86736726ccfbc6f0565bec22.svg &#039;Repobeats analytics image&#039;)

## Sponsors

Thanks to our wonderful sponsors who make Actual Budget possible!

&lt;a href=&quot;https://www.netlify.com&quot;&gt; &lt;img src=&quot;https://www.netlify.com/v3/img/components/netlify-color-accent.svg&quot; alt=&quot;Deploys by Netlify&quot; /&gt; &lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[AsyncFuncAI/deepwiki-open]]></title>
            <link>https://github.com/AsyncFuncAI/deepwiki-open</link>
            <guid>https://github.com/AsyncFuncAI/deepwiki-open</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[Open Source DeepWiki: AI-Powered Wiki Generator for GitHub/Gitlab/Bitbucket Repositories. Join the discord: https://discord.gg/gMwThUMeme]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AsyncFuncAI/deepwiki-open">AsyncFuncAI/deepwiki-open</a></h1>
            <p>Open Source DeepWiki: AI-Powered Wiki Generator for GitHub/Gitlab/Bitbucket Repositories. Join the discord: https://discord.gg/gMwThUMeme</p>
            <p>Language: TypeScript</p>
            <p>Stars: 9,171</p>
            <p>Forks: 948</p>
            <p>Stars today: 47 stars today</p>
            <h2>README</h2><pre># DeepWiki-Open

![DeepWiki Banner](screenshots/Deepwiki.png)

**DeepWiki** is my own implementation attempt of DeepWiki, automatically creates beautiful, interactive wikis for any GitHub, GitLab, or BitBucket repository! Just enter a repo name, and DeepWiki will:

1. Analyze the code structure
2. Generate comprehensive documentation
3. Create visual diagrams to explain how everything works
4. Organize it all into an easy-to-navigate wiki

[![&quot;Buy Me A Coffee&quot;](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://buymeacoffee.com/sheing)
[![Tip in Crypto](https://tip.md/badge.svg)](https://tip.md/sng-asyncfunc)
[![Twitter/X](https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&amp;logo=twitter&amp;logoColor=white)](https://x.com/sashimikun_void)
[![Discord](https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.com/invite/VQMBGR8u5v)

[English](./README.md) | [简体中文](./README.zh.md) | [繁體中文](./README.zh-tw.md) | [日本語](./README.ja.md) | [Español](./README.es.md) | [한국어](./README.kr.md) | [Tiếng Việt](./README.vi.md) | [Português Brasileiro](./README.pt-br.md) | [Français](./README.fr.md) | [Русский](./README.ru.md)

## ✨ Features

- **Instant Documentation**: Turn any GitHub, GitLab or BitBucket repo into a wiki in seconds
- **Private Repository Support**: Securely access private repositories with personal access tokens
- **Smart Analysis**: AI-powered understanding of code structure and relationships
- **Beautiful Diagrams**: Automatic Mermaid diagrams to visualize architecture and data flow
- **Easy Navigation**: Simple, intuitive interface to explore the wiki
- **Ask Feature**: Chat with your repository using RAG-powered AI to get accurate answers
- **DeepResearch**: Multi-turn research process that thoroughly investigates complex topics
- **Multiple Model Providers**: Support for Google Gemini, OpenAI, OpenRouter, and local Ollama models

## 🚀 Quick Start (Super Easy!)

### Option 1: Using Docker

```bash
# Clone the repository
git clone https://github.com/AsyncFuncAI/deepwiki-open.git
cd deepwiki-open

# Create a .env file with your API keys
echo &quot;GOOGLE_API_KEY=your_google_api_key&quot; &gt; .env
echo &quot;OPENAI_API_KEY=your_openai_api_key&quot; &gt;&gt; .env
# Optional: Add OpenRouter API key if you want to use OpenRouter models
echo &quot;OPENROUTER_API_KEY=your_openrouter_api_key&quot; &gt;&gt; .env
# Optional: Add Ollama host if not local. defaults to http://localhost:11434
echo &quot;OLLAMA_HOST=your_ollama_host&quot; &gt;&gt; .env
# Optional: Add Azure API key, endpoint and version if you want to use azure openai models
echo &quot;AZURE_OPENAI_API_KEY=your_azure_openai_api_key&quot; &gt;&gt; .env
echo &quot;AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint&quot; &gt;&gt; .env
echo &quot;AZURE_OPENAI_VERSION=your_azure_openai_version&quot; &gt;&gt; .env
# Run with Docker Compose
docker-compose up
```

For detailed instructions on using DeepWiki with Ollama and Docker, see [Ollama Instructions](Ollama-instruction.md).

&gt; 💡 **Where to get these keys:**
&gt; - Get a Google API key from [Google AI Studio](https://makersuite.google.com/app/apikey)
&gt; - Get an OpenAI API key from [OpenAI Platform](https://platform.openai.com/api-keys)
&gt; - Get Azure OpenAI credentials from [Azure Portal](https://portal.azure.com/) - create an Azure OpenAI resource and get the API key, endpoint, and API version

### Option 2: Manual Setup (Recommended)

#### Step 1: Set Up Your API Keys

Create a `.env` file in the project root with these keys:

```
GOOGLE_API_KEY=your_google_api_key
OPENAI_API_KEY=your_openai_api_key
# Optional: Add this if you want to use OpenRouter models
OPENROUTER_API_KEY=your_openrouter_api_key
# Optional: Add this if you want to use Azure OpenAI models
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint
AZURE_OPENAI_VERSION=your_azure_openai_version
# Optional: Add Ollama host if not local. default: http://localhost:11434
OLLAMA_HOST=your_ollama_host
```

#### Step 2: Start the Backend

```bash
# Install Python dependencies
pip install -r api/requirements.txt

# Start the API server
python -m api.main
```

#### Step 3: Start the Frontend

```bash
# Install JavaScript dependencies
npm install
# or
yarn install

# Start the web app
npm run dev
# or
yarn dev
```

#### Step 4: Use DeepWiki!

1. Open [http://localhost:3000](http://localhost:3000) in your browser
2. Enter a GitHub, GitLab, or Bitbucket repository (like `https://github.com/openai/codex`, `https://github.com/microsoft/autogen`, `https://gitlab.com/gitlab-org/gitlab`, or `https://bitbucket.org/redradish/atlassian_app_versions`)
3. For private repositories, click &quot;+ Add access tokens&quot; and enter your GitHub or GitLab personal access token
4. Click &quot;Generate Wiki&quot; and watch the magic happen!

## 🔍 How It Works

DeepWiki uses AI to:

1. Clone and analyze the GitHub, GitLab, or Bitbucket repository (including private repos with token authentication)
2. Create embeddings of the code for smart retrieval
3. Generate documentation with context-aware AI (using Google Gemini, OpenAI, OpenRouter, Azure OpenAI, or local Ollama models)
4. Create visual diagrams to explain code relationships
5. Organize everything into a structured wiki
6. Enable intelligent Q&amp;A with the repository through the Ask feature
7. Provide in-depth research capabilities with DeepResearch

```mermaid
graph TD
    A[User inputs GitHub/GitLab/Bitbucket repo] --&gt; AA{Private repo?}
    AA --&gt;|Yes| AB[Add access token]
    AA --&gt;|No| B[Clone Repository]
    AB --&gt; B
    B --&gt; C[Analyze Code Structure]
    C --&gt; D[Create Code Embeddings]

    D --&gt; M{Select Model Provider}
    M --&gt;|Google Gemini| E1[Generate with Gemini]
    M --&gt;|OpenAI| E2[Generate with OpenAI]
    M --&gt;|OpenRouter| E3[Generate with OpenRouter]
    M --&gt;|Local Ollama| E4[Generate with Ollama]
    M --&gt;|Azure| E5[Generate with Azure]

    E1 --&gt; E[Generate Documentation]
    E2 --&gt; E
    E3 --&gt; E
    E4 --&gt; E
    E5 --&gt; E

    D --&gt; F[Create Visual Diagrams]
    E --&gt; G[Organize as Wiki]
    F --&gt; G
    G --&gt; H[Interactive DeepWiki]

    classDef process stroke-width:2px;
    classDef data stroke-width:2px;
    classDef result stroke-width:2px;
    classDef decision stroke-width:2px;

    class A,D data;
    class AA,M decision;
    class B,C,E,F,G,AB,E1,E2,E3,E4,E5 process;
    class H result;
```

## 🛠️ Project Structure

```
deepwiki/
├── api/                  # Backend API server
│   ├── main.py           # API entry point
│   ├── api.py            # FastAPI implementation
│   ├── rag.py            # Retrieval Augmented Generation
│   ├── data_pipeline.py  # Data processing utilities
│   └── requirements.txt  # Python dependencies
│
├── src/                  # Frontend Next.js app
│   ├── app/              # Next.js app directory
│   │   └── page.tsx      # Main application page
│   └── components/       # React components
│       └── Mermaid.tsx   # Mermaid diagram renderer
│
├── public/               # Static assets
├── package.json          # JavaScript dependencies
└── .env                  # Environment variables (create this)
```

## 🤖 Provider-Based Model Selection System

DeepWiki now implements a flexible provider-based model selection system supporting multiple LLM providers:

### Supported Providers and Models

- **Google**: Default `gemini-2.0-flash`, also supports `gemini-1.5-flash`, `gemini-1.0-pro`, etc.
- **OpenAI**: Default `gpt-4o`, also supports `o4-mini`, etc.
- **OpenRouter**: Access to multiple models via a unified API, including Claude, Llama, Mistral, etc.
- **Azure OpenAI**: Default `gpt-4o`, also supports `o4-mini`, etc.
- **Ollama**: Support for locally running open-source models like `llama3`

### Environment Variables

Each provider requires its corresponding API key environment variables:

```
# API Keys
GOOGLE_API_KEY=your_google_api_key        # Required for Google Gemini models
OPENAI_API_KEY=your_openai_api_key        # Required for OpenAI models
OPENROUTER_API_KEY=your_openrouter_api_key # Required for OpenRouter models
AZURE_OPENAI_API_KEY=your_azure_openai_api_key  #Required for Azure OpenAI models
AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint  #Required for Azure OpenAI models
AZURE_OPENAI_VERSION=your_azure_openai_version  #Required for Azure OpenAI models

# OpenAI API Base URL Configuration
OPENAI_BASE_URL=https://custom-api-endpoint.com/v1  # Optional, for custom OpenAI API endpoints

# Ollama host
OLLAMA_HOST=your_ollama_host # Optional, if Ollama is not local. default: http://localhost:11434

# Configuration Directory
DEEPWIKI_CONFIG_DIR=/path/to/custom/config/dir  # Optional, for custom config file location
```

### Configuration Files

DeepWiki uses JSON configuration files to manage various aspects of the system:

1. **`generator.json`**: Configuration for text generation models
   - Defines available model providers (Google, OpenAI, OpenRouter, Azure, Ollama)
   - Specifies default and available models for each provider
   - Contains model-specific parameters like temperature and top_p

2. **`embedder.json`**: Configuration for embedding models and text processing
   - Defines embedding models for vector storage
   - Contains retriever configuration for RAG
   - Specifies text splitter settings for document chunking

3. **`repo.json`**: Configuration for repository handling
   - Contains file filters to exclude certain files and directories
   - Defines repository size limits and processing rules

By default, these files are located in the `api/config/` directory. You can customize their location using the `DEEPWIKI_CONFIG_DIR` environment variable.

### Custom Model Selection for Service Providers

The custom model selection feature is specifically designed for service providers who need to:

- You can offer multiple AI model choices to users within your organization
- You can quickly adapt to the rapidly evolving LLM landscape without code changes
- You can support specialized or fine-tuned models that aren&#039;t in the predefined list

Service providers can implement their model offerings by selecting from the predefined options or entering custom model identifiers in the frontend interface.

### Base URL Configuration for Enterprise Private Channels

The OpenAI Client&#039;s base_url configuration is designed primarily for enterprise users with private API channels. This feature:

- Enables connection to private or enterprise-specific API endpoints
- Allows organizations to use their own self-hosted or custom-deployed LLM services
- Supports integration with third-party OpenAI API-compatible services

**Coming Soon**: In future updates, DeepWiki will support a mode where users need to provide their own API keys in requests. This will allow enterprise customers with private channels to use their existing API arrangements without sharing credentials with the DeepWiki deployment.

## 🧩 Using OpenAI-Compatible Embedding Models (e.g., Alibaba Qwen)

If you want to use embedding models compatible with the OpenAI API (such as Alibaba Qwen), follow these steps:

1. Replace the contents of `api/config/embedder.json` with those from `api/config/embedder_openai_compatible.json`.
2. In your project root `.env` file, set the relevant environment variables, for example:
   ```
   OPENAI_API_KEY=your_api_key
   OPENAI_BASE_URL=your_openai_compatible_endpoint
   ```
3. The program will automatically substitute placeholders in embedder.json with the values from your environment variables.

This allows you to seamlessly switch to any OpenAI-compatible embedding service without code changes.

### Logging

DeepWiki uses Python&#039;s built-in `logging` module for diagnostic output. You can configure the verbosity and log file destination via environment variables:

| Variable        | Description                                                        | Default                      |
|-----------------|--------------------------------------------------------------------|------------------------------|
| `LOG_LEVEL`     | Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL).             | INFO                         |
| `LOG_FILE_PATH` | Path to the log file. If set, logs will be written to this file.   | `api/logs/application.log`   |

To enable debug logging and direct logs to a custom file:
```bash
export LOG_LEVEL=DEBUG
export LOG_FILE_PATH=./debug.log
python -m api.main
```
Or with Docker Compose:
```bash
LOG_LEVEL=DEBUG LOG_FILE_PATH=./debug.log docker-compose up
```

When running with Docker Compose, the container&#039;s `api/logs` directory is bind-mounted to `./api/logs` on your host (see the `volumes` section in `docker-compose.yml`), ensuring log files persist across restarts.

Alternatively, you can store these settings in your `.env` file:

```bash
LOG_LEVEL=DEBUG
LOG_FILE_PATH=./debug.log
```
Then simply run:

```bash
docker-compose up
```

**Logging Path Security Considerations:** In production environments, ensure the `api/logs` directory and any custom log file path are secured with appropriate filesystem permissions and access controls. The application enforces that `LOG_FILE_PATH` resides within the project&#039;s `api/logs` directory to prevent path traversal or unauthorized writes.

## 🛠️ Advanced Setup

### Environment Variables

| Variable             | Description                                                  | Required | Note                                                                                                     |
|----------------------|--------------------------------------------------------------|----------|----------------------------------------------------------------------------------------------------------|
| `GOOGLE_API_KEY`     | Google Gemini API key for AI generation                      | No | Required only if you want to use Google Gemini models                                                    
| `OPENAI_API_KEY`     | OpenAI API key for embeddings                                | Yes | Note: This is required even if you&#039;re not using OpenAI models, as it&#039;s used for embeddings.              |
| `OPENROUTER_API_KEY` | OpenRouter API key for alternative models                    | No | Required only if you want to use OpenRouter models                                                       |
| `AZURE_OPENAI_API_KEY` | Azure OpenAI API key                    | No | Required only if you want to use Azure OpenAI models                                                       |
| `AZURE_OPENAI_ENDPOINT` | Azure OpenAI endpoint                    | No | Required only if you want to use Azure OpenAI models                                                       |
| `AZURE_OPENAI_VERSION` | Azure OpenAI version                     | No | Required only if you want to use Azure OpenAI models                                                       |
| `OLLAMA_HOST`        | Ollama Host (default: http://localhost:11434)                | No | Required only if you want to use external Ollama server                                                  |
| `PORT`               | Port for the API server (default: 8001)                      | No | If you host API and frontend on the same machine, make sure change port of `SERVER_BASE_URL` accordingly |
| `SERVER_BASE_URL`    | Base URL for the API server (default: http://localhost:8001) | No |
| `DEEPWIKI_AUTH_MODE` | Set to `true` or `1` to enable authorization mode. | No | Defaults to `false`. If enabled, `DEEPWIKI_AUTH_CODE` is required. |
| `DEEPWIKI_AUTH_CODE` | The secret code required for wiki generation when `DEEPWIKI_AUTH_MODE` is enabled. | No | Only used if `DEEPWIKI_AUTH_MODE` is `true` or `1`. |

If you&#039;re not using ollama mode, you need to configure an OpenAI API key for embeddings. Other API keys are only required when configuring and using models from the corresponding providers.

## Authorization Mode

DeepWiki can be configured to run in an authorization mode, where wiki generation requires a valid authorization code. This is useful if you want to control who can use the generation feature.
Restricts frontend initiation and protects cache deletion, but doesn&#039;t fully prevent backend generation if API endpoints are hit directly.

To enable authorization mode, set the following environment variables:

- `DEEPWIKI_AUTH_MODE`: Set this to `true` or `1`. When enabled, the frontend will display an input field for the authorization code.
- `DEEPWIKI_AUTH_CODE`: Set this to the desired secret code. Restricts frontend initiation and protects cache deletion, but doesn&#039;t fully prevent backend generation if API endpoints are hit directly.

If `DEEPWIKI_AUTH_MODE` is not set or is set to `false` (or any other value than `true`/`1`), the authorization feature will be disabled, and no code will be required.

### Docker Setup

You can use Docker to run DeepWiki:

#### Running the Container

```bash
# Pull the image from GitHub Container Registry
docker pull ghcr.io/asyncfuncai/deepwiki-open:latest

# Run the container with environment variables
docker run -p 8001:8001 -p 3000:3000 \
  -e GOOGLE_API_KEY=your_google_api_key \
  -e OPENAI_API_KEY=your_openai_api_key \
  -e OPENROUTER_API_KEY=your_openrouter_api_key \
  -e OLLAMA_HOST=your_ollama_host \
  -e AZURE_OPENAI_API_KEY=your_azure_openai_api_key \
  -e AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint \
  -e AZURE_OPENAI_VERSION=your_azure_openai_version \

  -v ~/.adalflow:/root/.adalflow \
  ghcr.io/asyncfuncai/deepwiki-open:latest
```

This command also mounts `~/.adalflow` on your host to `/root/.adalflow` in the container. This path is used to store:
- Cloned repositories (`~/.adalflow/repos/`)
- Their embeddings and indexes (`~/.adalflow/databases/`)
- Cached generated wiki content (`~/.adalflow/wikicache/`)

This ensures that your data persists even if the container is stopped or removed.

Or use the provided `docker-compose.yml` file:

```bash
# Edit the .env file with your API keys first
docker-compose up
```

(The `docker-compose.yml` file is pre-configured to mount `~/.adalflow` for data persistence, similar to the `docker run` command above.)

#### Using a .env file with Docker

You can also mount a .env file to the container:

```bash
# Create a .env file with your API keys
echo &quot;GOOGLE_API_KEY=your_google_api_key&quot; &gt; .env
echo &quot;OPENAI_API_KEY=your_openai_api_key&quot; &gt;&gt; .env
echo &quot;OPENROUTER_API_KEY=your_openrouter_api_key&quot; &gt;&gt; .env
echo &quot;AZURE_OPENAI_API_KEY=your_azure_openai_api_key&quot; &gt;&gt; .env
echo &quot;AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint&quot; &gt;&gt; .env
echo &quot;AZURE_OPENAI_VERSION=your_azure_openai_version&quot;  &gt;&gt;.env
echo &quot;OLLAMA_HOST=your_ollama_host&quot; &gt;&gt; .env

# Run the container with the .env file mounted
docker run -p 8001:8001 -p 3000:3000 \
  -v $(pwd)/.env:/app/.env \
  -v ~/.adalflow:/root/.adalflow \
  ghcr.io/asyncfuncai/deepwiki-open:latest
```

This command also mounts `~/.adalflow` on your host to `/root/.adalflow` in the container. This path is used to store:
- Cloned repositories (`~/.adalflow/repos/`)
- Their embeddings and indexes (`~/.adalflow/databases/`)
- Cached generated wiki content (`~/.adalflow/wikicache/`)

This ensures that your data persists even if the container is stopped or removed.

#### Building the Docker image locally

If you want to build the Docker image locally:

```bash
# Clone the repository
git clone https://github.com/AsyncFuncAI/deepwiki-open.git
cd deepwiki-open

# Build the Docker image
docker build -t deepwiki-open .

# Run the container
docker run -p 8001:8001 -p 3000:3000 \
  -e GOOGLE_API_KEY=your_google_api_key \
  -e OPENAI_API_KEY=your_openai_api_key \
  -e OPENROUTER_API_KEY=your_openrouter_api_key \
  -e AZURE_OPENAI_API_KEY=your_azure_openai_api_key \
  -e AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint \
  -e AZURE_OPENAI_VERSION=your_azure_openai_version \
  -e OLLAMA_HOST=your_ollama_host \
  deepwiki-open
```

#### Using Self-Signed Certificates in Docker

If you&#039;re in an environment that uses self-signed certificates, you can include them in the Docker build:

1. Create a directory fo

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[mui/mui-x]]></title>
            <link>https://github.com/mui/mui-x</link>
            <guid>https://github.com/mui/mui-x</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[MUI X: Build complex and data-rich applications using a growing list of advanced React components, like the Data Grid, Date and Time Pickers, Charts, and more!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mui/mui-x">mui/mui-x</a></h1>
            <p>MUI X: Build complex and data-rich applications using a growing list of advanced React components, like the Data Grid, Date and Time Pickers, Charts, and more!</p>
            <p>Language: TypeScript</p>
            <p>Stars: 5,392</p>
            <p>Forks: 1,529</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable-next-line --&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mui.com/x/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;&lt;img width=&quot;150&quot; height=&quot;133&quot; src=&quot;https://mui.com/static/logo.svg&quot; alt=&quot;MUI X logo&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;MUI X&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/mui/mui-x/blob/HEAD/LICENSE)
[![npm latest package](https://img.shields.io/npm/v/@mui/x-data-grid/latest.svg)](https://www.npmjs.com/package/@mui/x-data-grid)
[![npm downloads](https://img.shields.io/npm/dm/@mui/x-data-grid.svg)](https://www.npmjs.com/package/@mui/x-data-grid)
[![GitHub branch status](https://img.shields.io/github/checks-status/mui/mui-x/HEAD)](https://github.com/mui/mui-x/commits/HEAD/)
[![Coverage status](https://img.shields.io/codecov/c/github/mui/mui-x.svg)](https://codecov.io/gh/mui/mui-x/)
[![Follow on X](https://img.shields.io/twitter/follow/MUI_X_.svg?label=follow+MUI+X)](https://x.com/MUI_X_)
[![Renovate status](https://img.shields.io/badge/renovate-enabled-brightgreen.svg)](https://github.com/mui/mui-x/issues/2081)
[![Average time to resolve an issue](https://isitmaintained.com/badge/resolution/mui/mui-x.svg)](https://isitmaintained.com/project/mui/mui-x &#039;Average time to resolve an issue&#039;)
[![Open Collective backers and sponsors](https://img.shields.io/opencollective/all/mui-org)](https://opencollective.com/mui-org)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/6293/badge)](https://www.bestpractices.dev/projects/6293)

&lt;/div&gt;

[MUI X](https://mui.com/x/) is a suite of advanced React UI components for a wide range of complex use cases.
Each component provides best-in-class UX and DX, with sophisticated UX workflows for data-rich applications.
Components include the Data Grid, Date and Time Pickers, Charts, and Tree View.

MUI X extends the core functionality of [Material UI](https://github.com/mui/material-ui/), but the advanced components also stand on their own and can be fully customized to meet the needs of any design system.

MUI X is **open-core**: [Community](#community-plan) components are MIT-licensed and free forever, while more advanced features and components require a [Pro](#pro-plan) or [Premium](#premium-plan) commercial license.
See [Licensing](#licensing) for more information.

## Documentation

Get started in the [MUI X documentation](https://mui.com/x/introduction/).

- [Data Grid](https://mui.com/x/react-data-grid/)
- [Date and Time Pickers](https://mui.com/x/react-date-pickers/)
- [Charts](https://mui.com/x/react-charts/)
- [Tree View](https://mui.com/x/react-tree-view/)

### Installation

- [Data Grid installation](https://mui.com/x/react-data-grid/quickstart/#installation)
- [Date and Time Pickers installation](https://mui.com/x/react-date-pickers/quickstart/#installation)
- [Charts installation](https://mui.com/x/react-charts/quickstart/#installation)
- [Tree View installation](https://mui.com/x/react-tree-view/quickstart/#installation)

## Licensing

The MUI X team has been building MIT-licensed React components since 2014, starting with Material UI, and we&#039;re committed to the continued advancement of our open-source libraries.
Anything we release under an MIT license will remain MIT-licensed forever.
Learn more about [our stewardship ethos](https://mui-org.notion.site/Stewardship-542a2226043d4f4a96dfb429d16cf5bd).

We offer commercial licenses to developers who need the most advanced components and features that can&#039;t reasonably be maintained by the open-source community alone.
These licenses make it possible for us to support a full-time staff of engineers.

Rest assured that when we release features commercially, it&#039;s only because we believe you won&#039;t find a better MIT-licensed alternative anywhere else.

See the [Licensing page](https://mui.com/x/introduction/licensing/) for complete details.

### Plans

#### Community plan

The free Community version of MUI X contains components and features that we believe are maintainable by contributions from the open-source community.
It&#039;s published under an [MIT license](https://www.tldrlegal.com/license/mit-license) and it&#039;s [free forever](https://mui-org.notion.site/Stewardship-542a2226043d4f4a96dfb429d16cf5bd#20f609acab4441cf9346614119fbbac1).

- [`@mui/x-data-grid`](https://www.npmjs.com/package/@mui/x-data-grid)
- [`@mui/x-date-pickers`](https://www.npmjs.com/package/@mui/x-date-pickers)
- [`@mui/x-charts`](https://www.npmjs.com/package/@mui/x-charts)
- [`@mui/x-tree-view`](https://www.npmjs.com/package/@mui/x-tree-view)

#### Pro plan

MUI X Pro expands on the Community version with more advanced features and functionality.
The Data Grid Pro comes with multi-filtering, multi-sorting, column resizing, and column pinning; you also gain access to the Date and Time Range Picker components, advanced Charts, and drag-and-drop reordering for the Tree View.

The Pro version is available under a commercial license—visit the [Pricing page](https://mui.com/pricing/) for details.

- [`@mui/x-data-grid-pro`](https://www.npmjs.com/package/@mui/x-data-grid-pro)
- [`@mui/x-date-pickers-pro`](https://www.npmjs.com/package/@mui/x-date-pickers-pro)
- [`@mui/x-charts-pro`](https://www.npmjs.com/package/@mui/x-charts-pro)
- [`@mui/x-tree-view-pro`](https://www.npmjs.com/package/@mui/x-tree-view-pro)

#### Premium plan

MUI X Premium unlocks the most advanced features of the Data Grid, including row grouping and Excel exporting, as well as everything offered in the Pro plan.

The Premium version is available under a commercial license—visit the [Pricing page](https://mui.com/pricing/) for details.

- [`@mui/x-data-grid-premium`](https://www.npmjs.com/package/@mui/x-data-grid-premium)
  &lt;!-- TODO: CHARTS-PREMIUM: uncomment when ready --&gt;
  &lt;!-- - [`@mui/x-charts-premium`](https://www.npmjs.com/package/@mui/x-charts-premium) --&gt;

## Support

From community guidance to critical business support, we&#039;re here to help.
Read the [Support guide](https://mui.com/x/introduction/support/) for details.

## Contributing

Read the [Contributing guide](/CONTRIBUTING.md) to learn about our development process, how to propose bug fixes and improvements, and how to build and test your changes.

Contributing to MUI X is about more than just issues and pull requests!
There are many other ways to [support MUI X](https://mui.com/material-ui/getting-started/faq/#mui-is-an-awesome-organization-how-can-i-support-it) beyond contributing to the code base.

## Changelog

The [changelog](https://github.com/mui/mui-x/releases) is regularly updated to reflect what&#039;s changed in each new release.

## Roadmap

Future plans and high-priority features and enhancements can be found in the [roadmap](https://mui.com/x/introduction/roadmap/).

## Security

For details on supported versions and contact information for reporting security issues, please refer to the [security policy](https://github.com/mui/mui-x/security/policy).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[musistudio/claude-code-router]]></title>
            <link>https://github.com/musistudio/claude-code-router</link>
            <guid>https://github.com/musistudio/claude-code-router</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/musistudio/claude-code-router">musistudio/claude-code-router</a></h1>
            <p>Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 11,170</p>
            <p>Forks: 827</p>
            <p>Stars today: 495 stars today</p>
            <h2>README</h2><pre># Claude Code Router

[中文版](README_zh.md)

&gt; A powerful tool to route Claude Code requests to different models and customize any request.

![](blog/images/claude-code.png)

## ✨ Features

- **Model Routing**: Route requests to different models based on your needs (e.g., background tasks, thinking, long context).
- **Multi-Provider Support**: Supports various model providers like OpenRouter, DeepSeek, Ollama, Gemini, Volcengine, and SiliconFlow.
- **Request/Response Transformation**: Customize requests and responses for different providers using transformers.
- **Dynamic Model Switching**: Switch models on-the-fly within Claude Code using the `/model` command.
- **GitHub Actions Integration**: Trigger Claude Code tasks in your GitHub workflows.
- **Plugin System**: Extend functionality with custom transformers.

## 🚀 Getting Started

### 1. Installation

First, ensure you have [Claude Code](https://docs.anthropic.com/en/docs/claude-code/quickstart) installed:

```shell
npm install -g @anthropic-ai/claude-code
```

Then, install Claude Code Router:

```shell
npm install -g @musistudio/claude-code-router
```

### 2. Configuration

Create and configure your `~/.claude-code-router/config.json` file. For more details, you can refer to `config.example.json`.

The `config.json` file has several key sections:

- **`PROXY_URL`** (optional): You can set a proxy for API requests, for example: `&quot;PROXY_URL&quot;: &quot;http://127.0.0.1:7890&quot;`.
- **`LOG`** (optional): You can enable logging by setting it to `true`. The log file will be located at `$HOME/.claude-code-router.log`.
- **`APIKEY`** (optional): You can set a secret key to authenticate requests. When set, clients must provide this key in the `Authorization` header (e.g., `Bearer your-secret-key`) or the `x-api-key` header. Example: `&quot;APIKEY&quot;: &quot;your-secret-key&quot;`.
- **`HOST`** (optional): You can set the host address for the server. If `APIKEY` is not set, the host will be forced to `127.0.0.1` for security reasons to prevent unauthorized access. Example: `&quot;HOST&quot;: &quot;0.0.0.0&quot;`.
- **`NON_INTERACTIVE_MODE`** (optional): When set to `true`, enables compatibility with non-interactive environments like GitHub Actions, Docker containers, or other CI/CD systems. This sets appropriate environment variables (`CI=true`, `FORCE_COLOR=0`, etc.) and configures stdin handling to prevent the process from hanging in automated environments. Example: `&quot;NON_INTERACTIVE_MODE&quot;: true`.

- **`Providers`**: Used to configure different model providers.
- **`Router`**: Used to set up routing rules. `default` specifies the default model, which will be used for all requests if no other route is configured.
- **`API_TIMEOUT_MS`**: Specifies the timeout for API calls in milliseconds.

Here is a comprehensive example:

```json
{
  &quot;APIKEY&quot;: &quot;your-secret-key&quot;,
  &quot;PROXY_URL&quot;: &quot;http://127.0.0.1:7890&quot;,
  &quot;LOG&quot;: true,
  &quot;API_TIMEOUT_MS&quot;: 600000,
  &quot;NON_INTERACTIVE_MODE&quot;: false,
  &quot;Providers&quot;: [
    {
      &quot;name&quot;: &quot;openrouter&quot;,
      &quot;api_base_url&quot;: &quot;https://openrouter.ai/api/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [
        &quot;google/gemini-2.5-pro-preview&quot;,
        &quot;anthropic/claude-sonnet-4&quot;,
        &quot;anthropic/claude-3.5-sonnet&quot;,
        &quot;anthropic/claude-3.7-sonnet:thinking&quot;
      ],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;openrouter&quot;]
      }
    },
    {
      &quot;name&quot;: &quot;deepseek&quot;,
      &quot;api_base_url&quot;: &quot;https://api.deepseek.com/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;deepseek-chat&quot;, &quot;deepseek-reasoner&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;deepseek&quot;],
        &quot;deepseek-chat&quot;: {
          &quot;use&quot;: [&quot;tooluse&quot;]
        }
      }
    },
    {
      &quot;name&quot;: &quot;ollama&quot;,
      &quot;api_base_url&quot;: &quot;http://localhost:11434/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;ollama&quot;,
      &quot;models&quot;: [&quot;qwen2.5-coder:latest&quot;]
    },
    {
      &quot;name&quot;: &quot;gemini&quot;,
      &quot;api_base_url&quot;: &quot;https://generativelanguage.googleapis.com/v1beta/models/&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;gemini-2.5-flash&quot;, &quot;gemini-2.5-pro&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;gemini&quot;]
      }
    },
    {
      &quot;name&quot;: &quot;volcengine&quot;,
      &quot;api_base_url&quot;: &quot;https://ark.cn-beijing.volces.com/api/v3/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-xxx&quot;,
      &quot;models&quot;: [&quot;deepseek-v3-250324&quot;, &quot;deepseek-r1-250528&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [&quot;deepseek&quot;]
      }
    },
    {
      &quot;name&quot;: &quot;modelscope&quot;,
      &quot;api_base_url&quot;: &quot;https://api-inference.modelscope.cn/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;&quot;,
      &quot;models&quot;: [&quot;Qwen/Qwen3-Coder-480B-A35B-Instruct&quot;, &quot;Qwen/Qwen3-235B-A22B-Thinking-2507&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [
          [
            &quot;maxtoken&quot;,
            {
              &quot;max_tokens&quot;: 65536
            }
          ],
          &quot;enhancetool&quot;
        ],
        &quot;Qwen/Qwen3-235B-A22B-Thinking-2507&quot;: {
          &quot;use&quot;: [&quot;reasoning&quot;]
        }
      }
    },
    {
      &quot;name&quot;: &quot;dashscope&quot;,
      &quot;api_base_url&quot;: &quot;https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;&quot;,
      &quot;models&quot;: [&quot;qwen3-coder-plus&quot;],
      &quot;transformer&quot;: {
        &quot;use&quot;: [
          [
            &quot;maxtoken&quot;,
            {
              &quot;max_tokens&quot;: 65536
            }
          ],
          &quot;enhancetool&quot;
        ]
      }
    },
    {
      &quot;name&quot;: &quot;aihubmix&quot;,
      &quot;api_base_url&quot;: &quot;https://aihubmix.com/v1/chat/completions&quot;,
      &quot;api_key&quot;: &quot;sk-&quot;,
      &quot;models&quot;: [
        &quot;Z/glm-4.5&quot;,
        &quot;claude-opus-4-20250514&quot;,
        &quot;gemini-2.5-pro&quot;
      ]
    }
  ],
  &quot;Router&quot;: {
    &quot;default&quot;: &quot;deepseek,deepseek-chat&quot;,
    &quot;background&quot;: &quot;ollama,qwen2.5-coder:latest&quot;,
    &quot;think&quot;: &quot;deepseek,deepseek-reasoner&quot;,
    &quot;longContext&quot;: &quot;openrouter,google/gemini-2.5-pro-preview&quot;,
    &quot;longContextThreshold&quot;: 60000,
    &quot;webSearch&quot;: &quot;gemini,gemini-2.5-flash&quot;
  }
}
```

### 3. Running Claude Code with the Router

Start Claude Code using the router:

```shell
ccr code
```

&gt; **Note**: After modifying the configuration file, you need to restart the service for the changes to take effect:
&gt;
&gt; ```shell
&gt; ccr restart
&gt; ```

### 4. UI Mode (Beta)

For a more intuitive experience, you can use the UI mode to manage your configuration:

```shell
ccr ui
```

This will open a web-based interface where you can easily view and edit your `config.json` file.

![UI](/blog/images/ui.png)

&gt; **Note**: The UI mode is currently in beta. 100% vibe coding: including project initialization, I just created a folder and a project.md document, and all code was generated by ccr + qwen3-coder + gemini(webSearch). 
If you encounter any issues, please submit an issue on GitHub.

#### Providers

The `Providers` array is where you define the different model providers you want to use. Each provider object requires:

- `name`: A unique name for the provider.
- `api_base_url`: The full API endpoint for chat completions.
- `api_key`: Your API key for the provider.
- `models`: A list of model names available from this provider.
- `transformer` (optional): Specifies transformers to process requests and responses.

#### Transformers

Transformers allow you to modify the request and response payloads to ensure compatibility with different provider APIs.

- **Global Transformer**: Apply a transformer to all models from a provider. In this example, the `openrouter` transformer is applied to all models under the `openrouter` provider.
  ```json
  {
    &quot;name&quot;: &quot;openrouter&quot;,
    &quot;api_base_url&quot;: &quot;https://openrouter.ai/api/v1/chat/completions&quot;,
    &quot;api_key&quot;: &quot;sk-xxx&quot;,
    &quot;models&quot;: [
      &quot;google/gemini-2.5-pro-preview&quot;,
      &quot;anthropic/claude-sonnet-4&quot;,
      &quot;anthropic/claude-3.5-sonnet&quot;
    ],
    &quot;transformer&quot;: { &quot;use&quot;: [&quot;openrouter&quot;] }
  }
  ```
- **Model-Specific Transformer**: Apply a transformer to a specific model. In this example, the `deepseek` transformer is applied to all models, and an additional `tooluse` transformer is applied only to the `deepseek-chat` model.

  ```json
  {
    &quot;name&quot;: &quot;deepseek&quot;,
    &quot;api_base_url&quot;: &quot;https://api.deepseek.com/chat/completions&quot;,
    &quot;api_key&quot;: &quot;sk-xxx&quot;,
    &quot;models&quot;: [&quot;deepseek-chat&quot;, &quot;deepseek-reasoner&quot;],
    &quot;transformer&quot;: {
      &quot;use&quot;: [&quot;deepseek&quot;],
      &quot;deepseek-chat&quot;: { &quot;use&quot;: [&quot;tooluse&quot;] }
    }
  }
  ```

- **Passing Options to a Transformer**: Some transformers, like `maxtoken`, accept options. To pass options, use a nested array where the first element is the transformer name and the second is an options object.
  ```json
  {
    &quot;name&quot;: &quot;siliconflow&quot;,
    &quot;api_base_url&quot;: &quot;https://api.siliconflow.cn/v1/chat/completions&quot;,
    &quot;api_key&quot;: &quot;sk-xxx&quot;,
    &quot;models&quot;: [&quot;moonshotai/Kimi-K2-Instruct&quot;],
    &quot;transformer&quot;: {
      &quot;use&quot;: [
        [
          &quot;maxtoken&quot;,
          {
            &quot;max_tokens&quot;: 16384
          }
        ]
      ]
    }
  }
  ```

**Available Built-in Transformers:**

- `Anthropic`:If you use only the `Anthropic` transformer, it will preserve the original request and response parameters(you can use it to connect directly to an Anthropic endpoint).
- `deepseek`: Adapts requests/responses for DeepSeek API.
- `gemini`: Adapts requests/responses for Gemini API.
- `openrouter`: Adapts requests/responses for OpenRouter API. It can also accept a `provider` routing parameter to specify which underlying providers OpenRouter should use. For more details, refer to the [OpenRouter documentation](https://openrouter.ai/docs/features/provider-routing). See an example below:
  ```json
    &quot;transformer&quot;: {
      &quot;use&quot;: [&quot;openrouter&quot;],
      &quot;moonshotai/kimi-k2&quot;: {
        &quot;use&quot;: [
          [
            &quot;openrouter&quot;,
            {
              &quot;provider&quot;: {
                &quot;only&quot;: [&quot;moonshotai/fp8&quot;]
              }
            }
          ]
        ]
      }
    }
  ```
- `groq`: Adapts requests/responses for groq API.
- `maxtoken`: Sets a specific `max_tokens` value.
- `tooluse`: Optimizes tool usage for certain models via `tool_choice`.
- `gemini-cli` (experimental): Unofficial support for Gemini via Gemini CLI [gemini-cli.js](https://gist.github.com/musistudio/1c13a65f35916a7ab690649d3df8d1cd).
- `reasoning`: Used to process the `reasoning_content` field.
- `sampling`: Used to process sampling information fields such as `temperature`, `top_p`, `top_k`, and `repetition_penalty`.
- `enhancetool`: Adds a layer of error tolerance to the tool call parameters returned by the LLM (this will cause the tool call information to no longer be streamed).
- `cleancache`: Clears the `cache_control` field from requests.
- `vertex-gemini`: Handles the Gemini API using Vertex authentication.

**Custom Transformers:**

You can also create your own transformers and load them via the `transformers` field in `config.json`.

```json
{
  &quot;transformers&quot;: [
    {
      &quot;path&quot;: &quot;$HOME/.claude-code-router/plugins/gemini-cli.js&quot;,
      &quot;options&quot;: {
        &quot;project&quot;: &quot;xxx&quot;
      }
    }
  ]
}
```

#### Router

The `Router` object defines which model to use for different scenarios:

- `default`: The default model for general tasks.
- `background`: A model for background tasks. This can be a smaller, local model to save costs.
- `think`: A model for reasoning-heavy tasks, like Plan Mode.
- `longContext`: A model for handling long contexts (e.g., &gt; 60K tokens).
- `longContextThreshold` (optional): The token count threshold for triggering the long context model. Defaults to 60000 if not specified.
- `webSearch`: Used for handling web search tasks and this requires the model itself to support the feature. If you&#039;re using openrouter, you need to add the `:online` suffix after the model name.

You can also switch models dynamically in Claude Code with the `/model` command:
`/model provider_name,model_name`
Example: `/model openrouter,anthropic/claude-3.5-sonnet`

#### Custom Router

For more advanced routing logic, you can specify a custom router script via the `CUSTOM_ROUTER_PATH` in your `config.json`. This allows you to implement complex routing rules beyond the default scenarios.

In your `config.json`:

```json
{
  &quot;CUSTOM_ROUTER_PATH&quot;: &quot;$HOME/.claude-code-router/custom-router.js&quot;
}
```

The custom router file must be a JavaScript module that exports an `async` function. This function receives the request object and the config object as arguments and should return the provider and model name as a string (e.g., `&quot;provider_name,model_name&quot;`), or `null` to fall back to the default router.

Here is an example of a `custom-router.js` based on `custom-router.example.js`:

```javascript
// $HOME/.claude-code-router/custom-router.js

/**
 * A custom router function to determine which model to use based on the request.
 *
 * @param {object} req - The request object from Claude Code, containing the request body.
 * @param {object} config - The application&#039;s config object.
 * @returns {Promise&lt;string|null&gt;} - A promise that resolves to the &quot;provider,model_name&quot; string, or null to use the default router.
 */
module.exports = async function router(req, config) {
  const userMessage = req.body.messages.find((m) =&gt; m.role === &quot;user&quot;)?.content;

  if (userMessage &amp;&amp; userMessage.includes(&quot;explain this code&quot;)) {
    // Use a powerful model for code explanation
    return &quot;openrouter,anthropic/claude-3.5-sonnet&quot;;
  }

  // Fallback to the default router configuration
  return null;
};
```

##### Subagent Routing

For routing within subagents, you must specify a particular provider and model by including `&lt;CCR-SUBAGENT-MODEL&gt;provider,model&lt;/CCR-SUBAGENT-MODEL&gt;` at the **beginning** of the subagent&#039;s prompt. This allows you to direct specific subagent tasks to designated models.

**Example:**

```
&lt;CCR-SUBAGENT-MODEL&gt;openrouter,anthropic/claude-3.5-sonnet&lt;/CCR-SUBAGENT-MODEL&gt;
Please help me analyze this code snippet for potential optimizations...
```

## 🤖 GitHub Actions

Integrate Claude Code Router into your CI/CD pipeline. After setting up [Claude Code Actions](https://docs.anthropic.com/en/docs/claude-code/github-actions), modify your `.github/workflows/claude.yaml` to use the router:

```yaml
name: Claude Code

on:
  issue_comment:
    types: [created]
  # ... other triggers

jobs:
  claude:
    if: |
      (github.event_name == &#039;issue_comment&#039; &amp;&amp; contains(github.event.comment.body, &#039;@claude&#039;)) ||
      # ... other conditions
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: read
      issues: read
      id-token: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Prepare Environment
        run: |
          curl -fsSL https://bun.sh/install | bash
          mkdir -p $HOME/.claude-code-router
          cat &lt;&lt; &#039;EOF&#039; &gt; $HOME/.claude-code-router/config.json
          {
            &quot;log&quot;: true,
            &quot;NON_INTERACTIVE_MODE&quot;: true,
            &quot;OPENAI_API_KEY&quot;: &quot;${{ secrets.OPENAI_API_KEY }}&quot;,
            &quot;OPENAI_BASE_URL&quot;: &quot;https://api.deepseek.com&quot;,
            &quot;OPENAI_MODEL&quot;: &quot;deepseek-chat&quot;
          }
          EOF
        shell: bash

      - name: Start Claude Code Router
        run: |
          nohup ~/.bun/bin/bunx @musistudio/claude-code-router@1.0.8 start &amp;
        shell: bash

      - name: Run Claude Code
        id: claude
        uses: anthropics/claude-code-action@beta
        env:
          ANTHROPIC_BASE_URL: http://localhost:3456
        with:
          anthropic_api_key: &quot;any-string-is-ok&quot;
```

&gt; **Note**: When running in GitHub Actions or other automation environments, make sure to set `&quot;NON_INTERACTIVE_MODE&quot;: true` in your configuration to prevent the process from hanging due to stdin handling issues.

This setup allows for interesting automations, like running tasks during off-peak hours to reduce API costs.

## 📝 Further Reading

- [Project Motivation and How It Works](blog/en/project-motivation-and-how-it-works.md)
- [Maybe We Can Do More with the Router](blog/en/maybe-we-can-do-more-with-the-route.md)

## ❤️ Support &amp; Sponsoring

If you find this project helpful, please consider sponsoring its development. Your support is greatly appreciated!

[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/F1F31GN2GM)

[Paypal](https://paypal.me/musistudio1999)

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;/blog/images/alipay.jpg&quot; width=&quot;200&quot; alt=&quot;Alipay&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;/blog/images/wechat.jpg&quot; width=&quot;200&quot; alt=&quot;WeChat Pay&quot; /&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

### Our Sponsors

A huge thank you to all our sponsors for their generous support!


- [AIHubmix](https://aihubmix.com/)
- @Simon Leischnig
- [@duanshuaimin](https://github.com/duanshuaimin)
- [@vrgitadmin](https://github.com/vrgitadmin)
- @\*o
- [@ceilwoo](https://github.com/ceilwoo)
- @\*说
- @\*更
- @K\*g
- @R\*R
- [@bobleer](https://github.com/bobleer)
- @\*苗
- @\*划
- [@Clarence-pan](https://github.com/Clarence-pan)
- [@carter003](https://github.com/carter003)
- @S\*r
- @\*晖
- @\*敏
- @Z\*z
- @\*然
- [@cluic](https://github.com/cluic)
- @\*苗
- [@PromptExpert](https://github.com/PromptExpert)
- @\*应
- [@yusnake](https://github.com/yusnake)
- @\*飞
- @董\*
- @\*汀
- @\*涯
- @\*:-）
- @\*\*磊
- @\*琢
- @\*成
- @Z\*o
- @\*琨
- [@congzhangzh](https://github.com/congzhangzh)
- @\*\_
- @Z\*m
- @*鑫
- @c\*y
- @\*昕
- [@witsice](https://github.com/witsice)
- @b\*g
- @\*亿
- @\*辉
- @JACK 

(If your name is masked, please contact me via my homepage email to update it with your GitHub username.)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[mui/material-ui]]></title>
            <link>https://github.com/mui/material-ui</link>
            <guid>https://github.com/mui/material-ui</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[Material UI: Comprehensive React component library that implements Google's Material Design. Free forever.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mui/material-ui">mui/material-ui</a></h1>
            <p>Material UI: Comprehensive React component library that implements Google's Material Design. Free forever.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 96,325</p>
            <p>Forks: 32,616</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>&lt;!-- #host-reference --&gt;
&lt;!-- markdownlint-disable-next-line --&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mui.com/core/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;&lt;img width=&quot;150&quot; height=&quot;133&quot; src=&quot;https://mui.com/static/logo.svg&quot; alt=&quot;Material UI logo&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Material UI&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;

[![license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/mui/material-ui/blob/HEAD/LICENSE)
[![npm latest package](https://img.shields.io/npm/v/@mui/material/latest.svg)](https://www.npmjs.com/package/@mui/material)
[![npm next package](https://img.shields.io/npm/v/@mui/material/next.svg)](https://www.npmjs.com/package/@mui/material)
[![npm downloads](https://img.shields.io/npm/dm/@mui/material.svg)](https://www.npmjs.com/package/@mui/material)
[![GitHub branch status](https://img.shields.io/github/checks-status/mui/material-ui/HEAD)](https://github.com/mui/material-ui/commits/HEAD/)
[![Coverage Status](https://img.shields.io/codecov/c/github/mui/material-ui.svg)](https://app.codecov.io/gh/mui/material-ui/)
[![Follow on X](https://img.shields.io/twitter/follow/MaterialUI.svg?label=follow+Material+UI)](https://x.com/MaterialUI)
[![Renovate status](https://img.shields.io/badge/renovate-enabled-brightgreen.svg)](https://github.com/mui/material-ui/issues/27062)
[![Average time to resolve an issue](https://isitmaintained.com/badge/resolution/mui/material-ui.svg)](https://isitmaintained.com/project/mui/material-ui &#039;Average time to resolve an issue&#039;)
[![Open Collective backers and sponsors](https://img.shields.io/opencollective/all/mui-org)](https://opencollective.com/mui-org)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/1320/badge)](https://www.bestpractices.dev/projects/1320)

&lt;/div&gt;

[Material UI](https://mui.com/material-ui/) is a comprehensive library of React components that features our independent implementation of Google&#039;s [Material Design](https://m2.material.io/design/introduction/) system.
It&#039;s trusted by some of the world&#039;s greatest product teams because it&#039;s been rigorously battle-tested through more than a decade of development by thousands of open-source contributors.

Material UI&#039;s core functionality is extended by [MUI X](https://github.com/mui/mui-x), a suite of complex components for advanced use cases.
[Toolpad](https://github.com/mui/toolpad) builds on top of Material UI to provide full-stack components and a low-code internal tool builder.

## Documentation

Get started in the [Material UI documentation](https://mui.com/material-ui/getting-started/).

&lt;details&gt;
  &lt;summary&gt;Older versions&lt;/summary&gt;

- **[v5.x](https://v5.mui.com/)** ([Upgrading from v5 to v6](https://mui.com/material-ui/migration/upgrade-to-v6/))
- **[v4.x](https://v4.mui.com/)** ([Upgrading from v4 to v5](https://mui.com/material-ui/migration/migration-v4/))
- **[v3.x](https://v3.mui.com/)** ([Upgrading from v3 to v4](https://mui.com/material-ui/migration/migration-v3/))
- **[v0.x](https://v0.mui.com/)** ([Upgrading to v1](https://mui.com/material-ui/migration/migration-v0x/))

&lt;/details&gt;

**Note:** `@next` points to pre-releases.
Use `@latest` for the latest stable release.

## Joy UI

This repository also contains Joy UI, an experimental component library that implements our own in-house Joy Design.
Joy UI is in beta and _development is currently on hold_.
When starting a new project from scratch, we recommend Material UI over Joy UI because we can guarantee ongoing support.

Keep in mind that the maintainers are primarily focused on other projects and may not be able to respond in a timely manner to issues or pull requests related to Joy UI.

View the [Joy UI documentation](https://mui.com/joy-ui/getting-started/).

## Sponsors

### Diamond 💎

&lt;p&gt;
  &lt;a href=&quot;https://www.doit.com/?utm_source=mui.com&amp;utm_medium=referral&amp;utm_content=readme&quot; rel=&quot;noopener sponsored&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;128&quot; width=&quot;128&quot; src=&quot;https://mui.com/static/sponsors/doit-square.svg&quot; alt=&quot;doit&quot; title=&quot;Management Platform for Google Cloud and AWS&quot; loading=&quot;lazy&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

Diamond sponsors are those who have pledged \$1,500/month or more to MUI.

### Gold 🏆

via [Open Collective](https://opencollective.com/mui-org) or via [Patreon](https://www.patreon.com/oliviertassinari)

&lt;p&gt;
  &lt;a href=&quot;https://tidelift.com/?utm_source=npm-material-ui&amp;utm_medium=referral&amp;utm_campaign=homepage&quot; rel=&quot;noopener sponsored&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;96&quot; width=&quot;96&quot; src=&quot;https://avatars.githubusercontent.com/u/30204434?s=288&quot; alt=&quot;tidelift.com&quot; title=&quot;Tidelift: Enterprise-ready open-source software.&quot; loading=&quot;lazy&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.text-em-all.com/?utm_source=mui.com&amp;utm_medium=referral&amp;utm_content=readme&quot; rel=&quot;noopener sponsored&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/1262264?s=288&quot; alt=&quot;text-em-all.com&quot; title=&quot;Text-em-all: Mass text messaging and automated calling.&quot; height=&quot;96&quot; width=&quot;96&quot; loading=&quot;lazy&quot;&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.dialmycalls.com/?utm_source=mui.com&amp;utm_medium=referral&amp;utm_content=readme&quot; rel=&quot;noopener sponsored&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;96&quot; width=&quot;96&quot; src=&quot;https://images.opencollective.com/dialmycalls/f5ae9ab/avatar/288.png&quot; alt=&quot;dialmycalls.com&quot; title=&quot;DialMyCalls: Send text messages, calls, and emails.&quot; loading=&quot;lazy&quot; /&gt;&lt;/a&gt;
  &amp;nbsp;
&lt;/p&gt;

&lt;p&gt;
  &lt;a href=&quot;https://goread.io/?utm_source=mui.com&amp;utm_medium=referral&amp;utm_content=readme&quot; rel=&quot;noopener sponsored&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;26&quot; width=&quot;23&quot; src=&quot;https://images.opencollective.com/goread_io/eb6337d/logo/78.png&quot; alt=&quot;goread.io&quot; title=&quot;Goread.io: Instagram followers, likes, views, and comments.&quot; loading=&quot;lazy&quot; /&gt;Goread.io&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://buzzoid.com/?utm_source=mui.com&amp;utm_medium=referral&amp;utm_content=readme&quot; rel=&quot;noopener sponsored&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;26&quot; width=&quot;26&quot; src=&quot;https://images.opencollective.com/buzzoidz/d23d9bb/logo/78.png&quot; alt=&quot;buzzoid.com&quot; title=&quot;Buzzoid: Instant delivery Instagram followers.&quot; loading=&quot;lazy&quot; /&gt;Buzzoid&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://twicsy.com/?utm_source=mui.com&amp;utm_medium=referral&amp;utm_content=readme&quot; rel=&quot;noopener sponsored&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;26&quot; width=&quot;30&quot; src=&quot;https://images.opencollective.com/twicsy/7af290f/logo/78.png&quot; alt=&quot;twicsy.com&quot; title=&quot;Twicsy: Instant delivery Instagram followers.&quot; loading=&quot;lazy&quot; /&gt;Twicsy&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://views4you.com/?utm_source=mui.com&amp;utm_medium=referral&amp;utm_content=readme&quot; rel=&quot;noopener sponsored&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;26&quot; width=&quot;26&quot; src=&quot;https://images.opencollective.com/buy-instagram-followers-v4y/6364714/logo/78.png&quot; alt=&quot;views4you.com&quot; title=&quot;Views4you: Social media growth services.&quot; loading=&quot;lazy&quot; /&gt;Views4You&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://poprey.com/?utm_source=mui.com&amp;utm_medium=referral&amp;utm_content=readme&quot; rel=&quot;noopener sponsored&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;26&quot; width=&quot;26&quot; src=&quot;https://images.opencollective.com/instagram-likes/2a72a03/logo/78.png&quot; alt=&quot;poprey.com&quot; title=&quot;Poprey: Buy Instagram likes with crypto.&quot; loading=&quot;lazy&quot; /&gt;Poprey&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.socialwick.com/instagram/followers/?utm_source=mui.com&amp;utm_medium=referral&amp;utm_content=readme&quot; rel=&quot;noopener sponsored&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;26&quot; width=&quot;26&quot; src=&quot;https://images.opencollective.com/instagram-followers-socialwick/ac6033a/logo/256.png&quot; alt=&quot;socialwick.com/instagram/followers&quot; title=&quot;SocialWick: Buy Instagram followers.&quot; loading=&quot;lazy&quot; /&gt;SocialWick&lt;/a&gt;
  &amp;nbsp;
 &lt;a href=&quot;https://www.follower24.de/?utm_source=mui.com&amp;utm_medium=referral&amp;utm_content=readme&quot; rel=&quot;noopener sponsored&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;26&quot; width=&quot;26&quot; src=&quot;https://mui.com/static/sponsors/follower24-square.svg&quot; alt=&quot;follower24.de&quot; title=&quot;Follower24: Social media success.&quot; loading=&quot;lazy&quot; /&gt;Follower24&lt;/a&gt;
  &amp;nbsp;
&lt;/p&gt;

Gold sponsors are those who have pledged \$500/month or more to MUI.

### More backers

See the full list of [our backers](https://mui.com/material-ui/discover-more/backers/).

## Questions

For how-to questions that don&#039;t involve making changes to the code base, please use [Stack Overflow](https://stackoverflow.com/questions/) instead of GitHub issues.

## Examples

&lt;!-- #target-branch-reference --&gt;

Our documentation features [a collection of example projects](https://github.com/mui/material-ui/tree/master/examples).

## Premium templates

You can find complete templates and themes in the [MUI Store](https://mui.com/store/?utm_source=docs&amp;utm_medium=referral&amp;utm_campaign=readme-store).

## Contributing

Read the [contributing guide](/CONTRIBUTING.md) to learn about our development process, how to propose bug fixes and improvements, and how to build and test your changes.

Contributing is about more than just issues and pull requests!
There are many other ways to [support Material UI](https://mui.com/material-ui/getting-started/faq/#mui-is-an-awesome-organization-how-can-i-support-it) beyond contributing to the code base.

## Changelog

The [changelog](https://github.com/mui/material-ui/releases) is regularly updated to reflect what&#039;s changed in each new release.

## Roadmap

Future plans and high-priority features and enhancements can be found in the [roadmap](https://mui.com/material-ui/discover-more/roadmap/).

## License

This project is licensed under the terms of the [MIT license](/LICENSE).

## Security

For details on supported versions and contact information for reporting security issues, please refer to the [security policy](https://github.com/mui/material-ui/security/policy).

## Sponsoring services

These great services sponsor MUI&#039;s core infrastructure:

&lt;div&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://mui.com/static/readme/github-darkmode.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://mui.com/static/readme/github-lightmode.svg&quot;&gt;
  &lt;img alt=&quot;GitHub logo&quot; src=&quot;https://mui.com/static/readme/github-lightmode.svg&quot; width=&quot;80&quot; height=&quot;43&quot;&gt;
&lt;/picture&gt;

[GitHub](https://github.com/) lets us host the Git repository and coordinate contributions.

&lt;/div&gt;

&lt;div&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://mui.com/static/readme/netlify-darkmode.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://mui.com/static/readme/netlify-lightmode.svg&quot;&gt;
  &lt;img alt=&quot;Netlify logo&quot; src=&quot;https://mui.com/static/readme/netlify-lightmode.svg&quot; width=&quot;100&quot; height=&quot;27&quot;&gt;
&lt;/picture&gt;

[Netlify](https://www.netlify.com/) lets us distribute the documentation.

&lt;/div&gt;

&lt;div&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://mui.com/static/readme/browserstack-darkmode.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://mui.com/static/readme/browserstack-lightmode.svg&quot;&gt;
  &lt;img alt=&quot;BrowserStack logo&quot; src=&quot;https://mui.com/static/readme/browserstack-lightmode.svg&quot; width=&quot;140&quot; height=&quot;25&quot;&gt;
&lt;/picture&gt;

[BrowserStack](https://www.browserstack.com/) lets us test in real browsers.

&lt;/div&gt;

&lt;div&gt;
&lt;img loading=&quot;lazy&quot; alt=&quot;CodeCov logo&quot; src=&quot;https://avatars.githubusercontent.com/u/8226205?s=105&quot; width=&quot;35&quot; height=&quot;35&quot;&gt;

[CodeCov](https://about.codecov.io/) lets us monitor test coverage.

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[nuxt/nuxt]]></title>
            <link>https://github.com/nuxt/nuxt</link>
            <guid>https://github.com/nuxt/nuxt</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[The Intuitive Vue Framework.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nuxt/nuxt">nuxt/nuxt</a></h1>
            <p>The Intuitive Vue Framework.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 57,850</p>
            <p>Forks: 5,331</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>[![Nuxt banner](./.github/assets/banner.svg)](https://nuxt.com)

# Nuxt

&lt;p&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/nuxt&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/nuxt.svg?style=flat&amp;colorA=18181B&amp;colorB=28CF8D&quot; alt=&quot;Version&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/nuxt&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/nuxt.svg?style=flat&amp;colorA=18181B&amp;colorB=28CF8D&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/nuxt/nuxt/tree/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/nuxt/nuxt.svg?style=flat&amp;colorA=18181B&amp;colorB=28CF8D&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://nuxt.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Nuxt%20Docs-18181B?logo=nuxt&quot; alt=&quot;Website&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://chat.nuxt.dev&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Nuxt%20Discord-18181B?logo=discord&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://securityscorecards.dev/&quot;&gt;&lt;img src=&quot;https://api.securityscorecards.dev/projects/github.com/nuxt/nuxt/badge&quot; alt=&quot;Nuxt openssf scorecard score&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Nuxt is a free and open-source framework with an intuitive and extendable way to create type-safe, performant and production-grade full-stack web applications and websites with Vue.js.

It provides a number of features that make it easy to build fast, SEO-friendly, and scalable web applications, including:
- Server-side rendering, Static Site Generation, Hybrid Rendering and Edge-Side Rendering
- Automatic routing with code-splitting and pre-fetching
- Data fetching and state management
- SEO Optimization and Meta tags definition
- Auto imports of components, composables and utils
- TypeScript with zero configuration
- Go fullstack with our server/ directory
- Extensible with [200+ modules](https://nuxt.com/modules)
- Deployment to a variety of [hosting platforms](https://nuxt.com/deploy)
- ...[and much more](https://nuxt.com) 🚀

### Table of Contents

- 🚀 [Getting Started](#getting-started)
- 💻 [ Vue Development](#vue-development)
- 📖 [Documentation](#documentation)
- 🧩 [Modules](#modules)
- ❤️  [Contribute](#contribute)
- 🏠 [Local Development](#local-development)
- 🛟 [Professional Support](#professional-support)
- 🔗 [Follow Us](#follow-us)
- ⚖️ [License](#license)

---

## &lt;a name=&quot;getting-started&quot;&gt;🚀 Getting Started&lt;/a&gt;

Use the following command to create a new starter project. This will create a starter project with all the necessary files and dependencies:

```bash
npm create nuxt@latest &lt;my-project&gt;
```

&gt; [!TIP]
&gt; Discover also [nuxt.new](https://nuxt.new): Open a Nuxt starter on CodeSandbox, StackBlitz or locally to get up and running in a few seconds.

## &lt;a name=&quot;vue-development&quot;&gt;💻 Vue Development&lt;/a&gt;

Simple, intuitive and powerful, Nuxt lets you write Vue components in a way that makes sense. Every repetitive task is automated, so you can focus on writing your full-stack Vue application with confidence.

Example of an `app.vue`:

```vue
&lt;script setup lang=&quot;ts&quot;&gt;
useSeoMeta({
  title: &#039;Meet Nuxt&#039;,
  description: &#039;The Intuitive Vue Framework.&#039;
})
&lt;/script&gt;

&lt;template&gt;
  &lt;div id=&quot;app&quot;&gt;
    &lt;AppHeader /&gt;
    &lt;NuxtPage /&gt;
    &lt;AppFooter /&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;style scoped&gt;
#app {
  background-color: #020420;
  color: #00DC82;
}
&lt;/style&gt;
```

## &lt;a name=&quot;documentation&quot;&gt;📖 Documentation&lt;/a&gt;

We highly recommend you take a look at the [Nuxt documentation](https://nuxt.com/docs) to level up. It’s a great resource for learning more about the framework. It covers everything from getting started to advanced topics.

## &lt;a name=&quot;modules&quot;&gt;🧩 Modules&lt;/a&gt;

Discover our [list of modules](https://nuxt.com/modules) to supercharge your Nuxt project, created by the Nuxt team and community.

## &lt;a name=&quot;contribute&quot;&gt;❤️ Contribute&lt;/a&gt;

We invite you to contribute and help improve Nuxt 💚

Here are a few ways you can get involved:
- **Reporting Bugs:** If you come across any bugs or issues, please check out the [reporting bugs guide](https://nuxt.com/docs/community/reporting-bugs) to learn how to submit a bug report.
- **Suggestions:** Have ideas to enhance Nuxt? We&#039;d love to hear them! Check out the [contribution guide](https://nuxt.com/docs/community/contribution) to share your suggestions.
- **Questions:** If you have questions or need assistance, the [getting help guide](https://nuxt.com/docs/community/getting-help) provides resources to help you out.

## &lt;a name=&quot;local-development&quot;&gt;🏠 Local Development&lt;/a&gt;

Follow the docs to [Set Up Your Local Development Environment](https://nuxt.com/docs/community/framework-contribution#setup) to contribute to the framework and documentation.

## &lt;a name=&quot;professional-support&quot;&gt;🛟 Professional Support&lt;/a&gt;

- Technical audit &amp; consulting: [Nuxt Experts](https://nuxt.com/enterprise/support)
- Custom development &amp; more: [Nuxt Agencies Partners](https://nuxt.com/enterprise/agencies)

## &lt;a name=&quot;follow-us&quot;&gt;🔗 Follow Us&lt;/a&gt;

&lt;p valign=&quot;center&quot;&gt;
  &lt;a href=&quot;https://go.nuxt.com/discord&quot;&gt;&lt;img width=&quot;20px&quot; src=&quot;./.github/assets/discord.svg&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://go.nuxt.com/x&quot;&gt;&lt;img width=&quot;20px&quot; src=&quot;./.github/assets/twitter.svg&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://go.nuxt.com/github&quot;&gt;&lt;img width=&quot;20px&quot; src=&quot;./.github/assets/github.svg&quot; alt=&quot;GitHub&quot;&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://go.nuxt.com/bluesky&quot;&gt;&lt;img width=&quot;20px&quot; src=&quot;./.github/assets/bluesky.svg&quot; alt=&quot;Bluesky&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

## &lt;a name=&quot;license&quot;&gt;⚖️ License&lt;/a&gt;

[MIT](https://github.com/nuxt/nuxt/tree/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[apache/echarts]]></title>
            <link>https://github.com/apache/echarts</link>
            <guid>https://github.com/apache/echarts</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[Apache ECharts is a powerful, interactive charting and data visualization library for browser]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/apache/echarts">apache/echarts</a></h1>
            <p>Apache ECharts is a powerful, interactive charting and data visualization library for browser</p>
            <p>Language: TypeScript</p>
            <p>Stars: 64,235</p>
            <p>Forks: 19,756</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre># Apache ECharts

&lt;a href=&quot;https://echarts.apache.org/&quot;&gt;
    &lt;img style=&quot;vertical-align: top;&quot; src=&quot;./asset/logo.png?raw=true&quot; alt=&quot;logo&quot; height=&quot;50px&quot;&gt;
&lt;/a&gt;

Apache ECharts is a free, powerful charting and visualization library offering easy ways to add intuitive, interactive, and highly customizable charts to your commercial products. It is written in pure JavaScript and based on &lt;a href=&quot;https://github.com/ecomfe/zrender&quot;&gt;zrender&lt;/a&gt;, which is a whole new lightweight canvas library.

**[中文官网](https://echarts.apache.org/zh/index.html)** | **[ENGLISH HOMEPAGE](https://echarts.apache.org/en/index.html)**

[![License](https://img.shields.io/npm/l/echarts?color=5470c6)](https://github.com/apache/echarts/blob/master/LICENSE) [![Latest npm release](https://img.shields.io/npm/v/echarts?color=91cc75)](https://www.npmjs.com/package/echarts) [![NPM downloads](https://img.shields.io/npm/dm/echarts.svg?label=npm%20downloads&amp;style=flat&amp;color=fac858)](https://www.npmjs.com/package/echarts) [![Contributors](https://img.shields.io/github/contributors/apache/echarts?color=3ba272)](https://github.com/apache/echarts/graphs/contributors)

[![Build Status](https://github.com/apache/echarts/actions/workflows/ci.yml/badge.svg)](https://github.com/apache/echarts/actions/workflows/ci.yml)

## Get Apache ECharts

You may choose one of the following methods:

+ Download from the [official website](https://echarts.apache.org/download.html)
+ `npm install echarts --save`
+ CDN: [jsDelivr CDN](https://www.jsdelivr.com/package/npm/echarts?path=dist)

## Docs

+ [Get Started](https://echarts.apache.org/handbook)
+ [API](https://echarts.apache.org/api.html)
+ [Option Manual](https://echarts.apache.org/option.html)
+ [Examples](https://echarts.apache.org/examples)

## Get Help

+ [GitHub Issues](https://github.com/apache/echarts/issues) for bug report and feature requests
+ Email [dev@echarts.apache.org](mailto:dev@echarts.apache.org) for general questions
+ Subscribe to the [mailing list](https://echarts.apache.org/maillist.html) to get updated with the project

## Build

Build echarts source code:

Execute the instructions in the root directory of the echarts:
([Node.js](https://nodejs.org) is required)

```shell
# Install the dependencies from NPM:
npm install

# Rebuild source code immediately in watch mode when changing the source code.
# It opens the `./test` directory, and you may open `-cases.html` to get the list
# of all test cases.
# If you wish to create a test case, run `npm run mktest:help` to learn more.
npm run dev

# Check the correctness of TypeScript code.
npm run checktype

# If intending to build and get all types of the &quot;production&quot; files:
npm run release
```

Then the &quot;production&quot; files are generated in the `dist` directory.

## Contribution

Please refer to the [contributing](https://github.com/apache/echarts/blob/master/CONTRIBUTING.md) document if you wish to debug locally or make pull requests.

## Resources

### Awesome ECharts

[https://github.com/ecomfe/awesome-echarts](https://github.com/ecomfe/awesome-echarts)

### Extensions

+ [ECharts GL](https://github.com/ecomfe/echarts-gl) An extension pack of ECharts, which provides 3D plots, globe visualization, and WebGL acceleration.

+ [Liquidfill 水球图](https://github.com/ecomfe/echarts-liquidfill)

+ [Wordcloud 字符云](https://github.com/ecomfe/echarts-wordcloud)

+ [Extension for Baidu Map 百度地图扩展](https://github.com/apache/echarts/tree/master/extension-src/bmap) An extension provides a wrapper of Baidu Map Service SDK.

+ [vue-echarts](https://github.com/ecomfe/vue-echarts) ECharts component for Vue.js

+ [echarts-stat](https://github.com/ecomfe/echarts-stat) Statistics tool for ECharts

## License

ECharts is available under the Apache License V2.

## Code of Conduct

Please refer to [Apache Code of Conduct](https://www.apache.org/foundation/policies/conduct.html).

## Paper

Deqing Li, Honghui Mei, Yi Shen, Shuang Su, Wenli Zhang, Junting Wang, Ming Zu, Wei Chen.
[ECharts: A Declarative Framework for Rapid Construction of Web-based Visualization](https://www.sciencedirect.com/science/article/pii/S2468502X18300068).
Visual Informatics, 2018.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[google-gemini/gemini-cli]]></title>
            <link>https://github.com/google-gemini/gemini-cli</link>
            <guid>https://github.com/google-gemini/gemini-cli</guid>
            <pubDate>Fri, 08 Aug 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[An open-source AI agent that brings the power of Gemini directly into your terminal.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google-gemini/gemini-cli">google-gemini/gemini-cli</a></h1>
            <p>An open-source AI agent that brings the power of Gemini directly into your terminal.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 67,810</p>
            <p>Forks: 6,657</p>
            <p>Stars today: 308 stars today</p>
            <h2>README</h2><pre># Gemini CLI

[![Gemini CLI CI](https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml/badge.svg)](https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml)

![Gemini CLI Screenshot](./docs/assets/gemini-screenshot.png)

This repository contains the Gemini CLI, a command-line AI workflow tool that connects to your
tools, understands your code and accelerates your workflows.

With the Gemini CLI you can:

- Query and edit large codebases in and beyond Gemini&#039;s 1M token context window.
- Generate new apps from PDFs or sketches, using Gemini&#039;s multimodal capabilities.
- Automate operational tasks, like querying pull requests or handling complex rebases.
- Integrate with GitHub: Use the [Gemini CLI GitHub Action](https://github.com/google-github-actions/run-gemini-cli) for automated PR reviews, issue triage, and on-demand AI assistance directly in your repositories.
- Use tools and MCP servers to connect new capabilities, including [media generation with Imagen,
  Veo or Lyria](https://github.com/GoogleCloudPlatform/vertex-ai-creative-studio/tree/main/experiments/mcp-genmedia)
- Ground your queries with the [Google Search](https://ai.google.dev/gemini-api/docs/grounding)
  tool, built into Gemini.

## Quickstart

You have two options to install Gemini CLI.

### With Node

1. **Prerequisites:** Ensure you have [Node.js version 20](https://nodejs.org/en/download) or higher installed.
2. **Run the CLI:** Execute the following command in your terminal:

   ```bash
   npx https://github.com/google-gemini/gemini-cli
   ```

   Or install it with:

   ```bash
   npm install -g @google/gemini-cli
   ```

   Then, run the CLI from anywhere:

   ```bash
   gemini
   ```

### With Homebrew

1. **Prerequisites:** Ensure you have [Homebrew](https://brew.sh/) installed.
2. **Install the CLI:** Execute the following command in your terminal:

   ```bash
   brew install gemini-cli
   ```

   Then, run the CLI from anywhere:

   ```bash
   gemini
   ```

### Common Configuration steps

3. **Pick a color theme**
4. **Authenticate:** When prompted, sign in with your personal Google account. This will grant you up to 60 model requests per minute and 1,000 model requests per day using Gemini.

You are now ready to use the Gemini CLI!

### Use a Gemini API key:

The Gemini API provides a free tier with [100 requests per day](https://ai.google.dev/gemini-api/docs/rate-limits#free-tier) using Gemini 2.5 Pro, control over which model you use, and access to higher rate limits (with a paid plan):

1. Generate a key from [Google AI Studio](https://aistudio.google.com/apikey).
2. Set it as an environment variable in your terminal. Replace `YOUR_API_KEY` with your generated key.

   ```bash
   export GEMINI_API_KEY=&quot;YOUR_API_KEY&quot;
   ```

3. (Optionally) Upgrade your Gemini API project to a paid plan on the API key page (will automatically unlock [Tier 1 rate limits](https://ai.google.dev/gemini-api/docs/rate-limits#tier-1))

### Use a Vertex AI API key:

The Vertex AI API provides a [free tier](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview) using express mode for Gemini 2.5 Pro, control over which model you use, and access to higher rate limits with a billing account:

1. Generate a key from [Google Cloud](https://cloud.google.com/vertex-ai/generative-ai/docs/start/api-keys).
2. Set it as an environment variable in your terminal. Replace `YOUR_API_KEY` with your generated key and set GOOGLE_GENAI_USE_VERTEXAI to true

   ```bash
   export GOOGLE_API_KEY=&quot;YOUR_API_KEY&quot;
   export GOOGLE_GENAI_USE_VERTEXAI=true
   ```

3. (Optionally) Add a billing account on your project to get access to [higher usage limits](https://cloud.google.com/vertex-ai/generative-ai/docs/quotas)

For other authentication methods, including Google Workspace accounts, see the [authentication](./docs/cli/authentication.md) guide.

## Examples

Once the CLI is running, you can start interacting with Gemini from your shell.

You can start a project from a new directory:

```sh
cd new-project/
gemini
&gt; Write me a Gemini Discord bot that answers questions using a FAQ.md file I will provide
```

Or work with an existing project:

```sh
git clone https://github.com/google-gemini/gemini-cli
cd gemini-cli
gemini
&gt; Give me a summary of all of the changes that went in yesterday
```

### Next steps

- Learn how to [contribute to or build from the source](./CONTRIBUTING.md).
- Explore the available **[CLI Commands](./docs/cli/commands.md)**.
- If you encounter any issues, review the **[troubleshooting guide](./docs/troubleshooting.md)**.
- For more comprehensive documentation, see the [full documentation](./docs/index.md).
- Take a look at some [popular tasks](#popular-tasks) for more inspiration.
- Check out our **[Official Roadmap](./ROADMAP.md)**

### Troubleshooting

Head over to the [troubleshooting guide](docs/troubleshooting.md) if you&#039;re
having issues.

## GitHub Integration

Integrate Gemini CLI directly into your GitHub workflows with the [**Gemini CLI GitHub Action**](https://github.com/google-github-actions/run-gemini-cli). Key features include:

- **Pull Request Reviews**: Automatically review pull requests when they&#039;re opened.
- **Issue Triage**: Automatically triage and label GitHub issues.
- **On-demand Collaboration**: Mention `@gemini-cli` in issues and pull requests for assistance and task delegation.
- **Custom Workflows**: Set up your own scheduled tasks and event-driven automations.

## Popular tasks

### Explore a new codebase

Start by `cd`ing into an existing or newly-cloned repository and running `gemini`.

```text
&gt; Describe the main pieces of this system&#039;s architecture.
```

```text
&gt; What security mechanisms are in place?
```

```text
&gt; Provide a step-by-step dev onboarding doc for developers new to the codebase.
```

```text
&gt; Summarize this codebase and highlight the most interesting patterns or techniques I could learn from.
```

```text
&gt; Identify potential areas for improvement or refactoring in this codebase, highlighting parts that appear fragile, complex, or hard to maintain.
```

```text
&gt; Which parts of this codebase might be challenging to scale or debug?
```

```text
&gt; Generate a README section for the [module name] module explaining what it does and how to use it.
```

```text
&gt; What kind of error handling and logging strategies does the project use?
```

```text
&gt; Which tools, libraries, and dependencies are used in this project?
```

### Work with your existing code

```text
&gt; Implement a first draft for GitHub issue #123.
```

```text
&gt; Help me migrate this codebase to the latest version of Java. Start with a plan.
```

### Automate your workflows

Use MCP servers to integrate your local system tools with your enterprise collaboration suite.

```text
&gt; Make me a slide deck showing the git history from the last 7 days, grouped by feature and team member.
```

```text
&gt; Make a full-screen web app for a wall display to show our most interacted-with GitHub issues.
```

### Interact with your system

```text
&gt; Convert all the images in this directory to png, and rename them to use dates from the exif data.
```

```text
&gt; Organize my PDF invoices by month of expenditure.
```

### Uninstall

Head over to the [Uninstall](docs/Uninstall.md) guide for uninstallation instructions.

## Terms of Service and Privacy Notice

For details on the terms of service and privacy notice applicable to your use of Gemini CLI, see the [Terms of Service and Privacy Notice](./docs/tos-privacy.md).

## Security Disclosures

Please see our [security disclosure process](SECURITY.md). All [security advisories](https://github.com/google-gemini/gemini-cli/security/advisories) are managed on Github.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[cloudflare/workers-oauth-provider]]></title>
            <link>https://github.com/cloudflare/workers-oauth-provider</link>
            <guid>https://github.com/cloudflare/workers-oauth-provider</guid>
            <pubDate>Fri, 08 Aug 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[OAuth provider library for Cloudflare Workers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudflare/workers-oauth-provider">cloudflare/workers-oauth-provider</a></h1>
            <p>OAuth provider library for Cloudflare Workers</p>
            <p>Language: TypeScript</p>
            <p>Stars: 1,544</p>
            <p>Forks: 89</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># OAuth 2.1 Provider Framework for Cloudflare Workers

This is a TypeScript library that implements the provider side of the OAuth 2.1 protocol with PKCE support. The library is intended to be used on Cloudflare Workers.

## Benefits of this library

* The library acts as a wrapper around your Worker code, which adds authorization for your API endpoints.
* All token management is handled automatically.
* Your API handler is written like a regular fetch handler, but receives the already-authenticated user details as a parameter. No need to perform any checks of your own.
* The library is agnostic to how you manage and authenticate users.
* The library is agnostic to how you build your UI. Your authorization flow can be implemented using whatever UI framework you use for everything else.
* The library&#039;s storage does not store any secrets, only hashes of them.

## Usage

A Worker that uses the library might look like this:

```ts
import { OAuthProvider } from &quot;@cloudflare/workers-oauth-provider&quot;;
import { WorkerEntrypoint } from &quot;cloudflare:workers&quot;;

// We export the OAuthProvider instance as the entrypoint to our Worker. This means it
// implements the `fetch()` handler, receiving all HTTP requests.
export default new OAuthProvider({
  // Configure API routes. Any requests whose URL starts with any of these prefixes will be
  // considered API requests. The OAuth provider will check the access token on these requests,
  // and then, if the token is valid, send the request to the API handler.
  // You can provide:
  // - A single route (string) or multiple routes (array)
  // - Full URLs (which will match the hostname) or just paths (which will match any hostname)
  apiRoute: [
    &quot;/api/&quot;, // Path only - will match any hostname
    &quot;https://api.example.com/&quot; // Full URL - will check hostname
  ],

  // When the OAuth system receives an API request with a valid access token, it passes the request
  // to this handler object&#039;s fetch method.
  // You can provide either an object with a fetch method (ExportedHandler)
  // or a class extending WorkerEntrypoint.
  apiHandler: ApiHandler, // Using a WorkerEntrypoint class
  
  // For multi-handler setups, you can use apiHandlers instead of apiRoute+apiHandler.
  // This allows you to use different handlers for different API routes.
  // Note: You must use either apiRoute+apiHandler (single-handler) OR apiHandlers (multi-handler), not both.
  // Example:
  // apiHandlers: {
  //   &quot;/api/users/&quot;: UsersApiHandler,
  //   &quot;/api/documents/&quot;: DocumentsApiHandler,
  //   &quot;https://api.example.com/&quot;: ExternalApiHandler,
  // },

  // Any requests which aren&#039;t API request will be passed to the default handler instead.
  // Again, this can be either an object or a WorkerEntrypoint.
  defaultHandler: defaultHandler, // Using an object with a fetch method

  // This specifies the URL of the OAuth authorization flow UI. This UI is NOT implemented by
  // the OAuthProvider. It is up to the application to implement a UI here. The only reason why
  // this URL is given to the OAuthProvider is so that it can implement the RFC-8414 metadata
  // discovery endpoint, i.e. `.well-known/oauth-authorization-server`.
  // Can also be specified as just a path (e.g., &quot;/authorize&quot;).
  authorizeEndpoint: &quot;https://example.com/authorize&quot;,

  // This specifies the OAuth 2 token exchange endpoint. The OAuthProvider will implement this
  // endpoint (by directly responding to requests with a matching URL).
  // Can also be specified as just a path (e.g., &quot;/oauth/token&quot;).
  tokenEndpoint: &quot;https://example.com/oauth/token&quot;,

  // This specifies the RFC-7591 dynamic client registration endpoint. This setting is optional,
  // but if provided, the OAuthProvider will implement this endpoint to allow dynamic client
  // registration.
  // Can also be specified as just a path (e.g., &quot;/oauth/register&quot;).
  clientRegistrationEndpoint: &quot;https://example.com/oauth/register&quot;,

  // Optional list of scopes supported by this OAuth provider.
  // If provided, this will be included in the RFC 8414 metadata as &#039;scopes_supported&#039;.
  // If not provided, the &#039;scopes_supported&#039; field will be omitted from the metadata.
  scopesSupported: [&quot;document.read&quot;, &quot;document.write&quot;, &quot;profile&quot;],

  // Optional: Controls whether the OAuth implicit flow is allowed.
  // The implicit flow is discouraged in OAuth 2.1 but may be needed for some clients.
  // Defaults to false.
  allowImplicitFlow: false,

  // Optional: Controls whether public clients (clients without a secret, like SPAs)
  // can register via the dynamic client registration endpoint.
  // When true, only confidential clients can register.
  // Note: Creating public clients via the OAuthHelpers.createClient() method
  // is always allowed regardless of this setting.
  // Defaults to false.
  disallowPublicClientRegistration: false
});

// The default handler object - the OAuthProvider will pass through HTTP requests to this object&#039;s fetch method
// if they aren&#039;t API requests or do not have a valid access token
const defaultHandler = {
  // This fetch method works just like a standard Cloudflare Workers fetch handler
  //
  // The `request`, `env`, and `ctx` parameters are the same as for a normal Cloudflare Workers fetch
  // handler, and are exactly the objects that the `OAuthProvider` itself received from the Workers
  // runtime.
  //
  // The `env.OAUTH_PROVIDER` provides an API by which the application can call back to the
  // OAuthProvider.
  async fetch(request: Request, env, ctx) {
    let url = new URL(request.url);

    if (url.pathname == &quot;/authorize&quot;) {
      // This is a request for our OAuth authorization flow UI. It is up to the application to
      // implement this. However, the OAuthProvider library provides some helpers to assist.

      // `env.OAUTH_PROVIDER.parseAuthRequest()` parses the OAuth authorization request to extract the parameters
      // required by the OAuth 2 standard, namely response_type, client_id, redirect_uri, scope, and
      // state. It returns an object containing all these (using idiomatic camelCase naming).
      let oauthReqInfo = await env.OAUTH_PROVIDER.parseAuthRequest(request);

      // `env.OAUTH_PROVIDER.lookupClient()` looks up metadata about the client, as definetd by RFC-7591. This
      // includes things like redirect_uris, client_name, logo_uri, etc.
      let clientInfo = await env.OAUTH_PROVIDER.lookupClient(oauthReqInfo.clientId);

      // At this point, the application should use `oauthReqInfo` and `clientInfo` to render an
      // authorization consent UI to the user. The details of this are up to the app so are not
      // shown here.

      // After the user has granted consent, the application calls `env.OAUTH_PROVIDER.completeAuthorization()` to
      // grant the authorization.
      let {redirectTo} = await env.OAUTH_PROVIDER.completeAuthorization({
        // The application passes back the original OAuth request info that was returned by
        // `parseAuthRequest()` earlier.
        request: oauthReqInfo,

        // The application must specify the user&#039;s ID, which is some sort of string. This is needed
        // so that the application can later query the OAuthProvider to enumerate all grants
        // belonging to a particular user, e.g. to implement an audit and revocation UI.
        userId: &quot;1234&quot;,

        // The application can specify some arbitary metadata which describes this grant. The
        // metadata can contain any JSON-serializable content. This metadata is not used by the
        // OAuthProvider, but the application can read back the metadata attached to specific
        // grants when enumerating them later, again e.g. to implement an udit and revocation UI.
        metadata: {label: &quot;foo&quot;},

        // The application specifies the list of OAuth scope identifiers that were granted. This
        // may or may not be the same as was requested in `oauthReqInfo.scope`.
        scope: [&quot;document.read&quot;, &quot;document.write&quot;],

        // `props` is an arbitrary JSON-serializable object which will be passed back to the API
        // handler for every request authorized by this grant.
        props: {
          userId: 1234,
          username: &quot;Bob&quot;
        }
      });

      // `completeAuthorization()` will have returned the URL to which the user should be redirected
      // in order to complete the authorization flow. This is the requesting client&#039;s OAuth
      // redirect_uri with the appropriate query parameters added to complete the flow and obtain
      // tokens.
      return Response.redirect(redirectTo, 302);
    }

    // ... the application can implement other non-API HTTP endpoints here ...

    return new Response(&quot;Not found&quot;, {status: 404});
  }
};

// The API handler object - the OAuthProivder will pass authorized API requests to this object&#039;s fetch method
// (because we provided it as the `apiHandler` setting, above). This is ONLY called for API requests
// that had a valid access token.
class ApiHandler extends WorkerEntrypoint {
  // This fetch method works just like any other WorkerEntrypoint fetch method. The `request` is
  // passed as a parameter, while `env` and `ctx` are available as `this.env` and `this.ctx`.
  //
  // The `this.env.OAUTH_PROVIDER` is available just like in the default handler.
  //
  // The `this.ctx.props` property contains the `props` value that was passed to
  // `env.OAUTH_PROVIDER.completeAuthorization()` during the authorization flow that authorized this client.
  fetch(request: Request) {
    // The application can implement its API endpoints like normal. This app implements a single
    // endpoint, `/api/whoami`, which returns the user&#039;s authenticated identity.

    let url = new URL(request.url);
    if (url.pathname == &quot;/api/whoami&quot;) {
      // Since the username is embedded in `ctx.props`, which came from the access token that the
      // OAuthProivder already verified, we don&#039;t need to do any other authentication steps.
      return new Response(`You are authenticated as: ${this.ctx.props.username}`);
    }

    return new Response(&quot;Not found&quot;, {status: 404});
  }
};
```

This implementation requires that your worker is configured with a Workers KV namespace binding called `OAUTH_KV`, which is used to store token information. See the file `storage-schema.md` for details on the schema of this namespace.

The `env.OAUTH_PROVIDER` object available to the fetch handlers provides some methods to query the storage, including:

* Create, list, modify, and delete client_id registrations (in addition to `lookupClient()`, already shown in the example code).
* List all active authorization grants for a particular user.
* Revoke (delete) an authorization grant.

See the `OAuthHelpers` interface definition for full API details.

## Token Exchange Callback

This library allows you to update the `props` value during token exchanges by configuring a callback function. This is useful for scenarios where the application needs to perform additional processing when tokens are issued or refreshed.

For example, if your application is also a client to some other OAuth API, you might want to perform an equivalent upstream token exchange and store the result in the `props`. The callback can be used to update the props for both the grant record and specific access tokens.

To use this feature, provide a `tokenExchangeCallback` in your OAuthProvider options:

```ts
new OAuthProvider({
  // ... other options ...
  tokenExchangeCallback: async (options) =&gt; {
    // options.grantType is either &#039;authorization_code&#039; or &#039;refresh_token&#039;
    // options.props contains the current props
    // options.clientId, options.userId, and options.scope are also available

    if (options.grantType === &#039;authorization_code&#039;) {
      // For authorization code exchange, might want to obtain upstream tokens
      const upstreamTokens = await exchangeUpstreamToken(options.props.someCode);

      return {
        // Update the props stored in the access token
        accessTokenProps: {
          ...options.props,
          upstreamAccessToken: upstreamTokens.access_token
        },
        // Update the props stored in the grant (for future token refreshes)
        newProps: {
          ...options.props,
          upstreamRefreshToken: upstreamTokens.refresh_token
        }
      };
    }

    if (options.grantType === &#039;refresh_token&#039;) {
      // For refresh token exchanges, might want to refresh upstream tokens too
      const upstreamTokens = await refreshUpstreamToken(options.props.upstreamRefreshToken);

      return {
        accessTokenProps: {
          ...options.props,
          upstreamAccessToken: upstreamTokens.access_token
        },
        newProps: {
          ...options.props,
          upstreamRefreshToken: upstreamTokens.refresh_token || options.props.upstreamRefreshToken
        },
        // Optionally override the default access token TTL to match the upstream token
        accessTokenTTL: upstreamTokens.expires_in
      };
    }
  }
});
```

The callback can:
- Return both `accessTokenProps` and `newProps` to update both
- Return only `accessTokenProps` to update just the current access token
- Return only `newProps` to update both the grant and access token (the access token inherits these props)
- Return `accessTokenTTL` to override the default TTL for this specific access token
- Return nothing to keep the original props unchanged

The `accessTokenTTL` override is particularly useful when the application is also an OAuth client to another service and wants to match its access token TTL to the upstream access token TTL. This helps prevent situations where the downstream token is still valid but the upstream token has expired.

The `props` values are end-to-end encrypted, so they can safely contain sensitive information.

## Custom Error Responses

By using the `onError` option, you can emit notifications or take other actions when an error response was to be emitted:

```ts
new OAuthProvider({
  // ... other options ...
  onError({ code, description, status, headers }) {
    Sentry.captureMessage(/* ... */)
  }
})
```

By returning a `Response` you can also override what the OAuthProvider returns to your users:

```ts
new OAuthProvider({
  // ... other options ...
  onError({ code, description, status, headers }) {
    if (code === &#039;unsupported_grant_type&#039;) {
      return new Response(&#039;...&#039;, { status, headers })
    }
    // returning undefined (i.e. void) uses the default Response generation
  }
})
```

By default, the `onError` callback is set to ``({ status, code, description }) =&gt; console.warn(`OAuth error response: ${status} ${code} - ${description}`)``.

## Implementation Notes

### End-to-end encryption

This library stores records about authorization tokens in KV. The storage schema is carefully designed such that a complete leak of the storage only reveals mundane metadata about what has been granted. In particular:

* Secrets (including access tokens, refresh tokens, authorization codes, and client secrets) are stored only by hash. Hence, such secrets cannot be derived from the storage alone.
* The `props` associated with a grant (which are passed back to the application when API requests are performed) are stored encrypted with the secret token as key material. Hence, the contents of `props` are impossible to derive from storage unless a valid token is provided.

Note that the `userId` and the `metadata` associated with each grant are not encrypted, because the purpose of these values is to allow grants to be enumerated for audit and revocation purposes. However, these values are completely opaque to the library. An application is free to omit them or apply its own encryption to them before passing them into the library, if it desires.

### Single-use refresh tokens?

OAuth 2.1 requires that refresh tokens are either &quot;cryptographically bound&quot; to the client, or are single-use. This library currently does not implement any cryptographic binding, thus seemingly requiring single-use tokens. Under this requirement, every token refresh request invalidates the old refresh token and issues a new one.

This requirement is seemingly fundamentally flawed as it assumes that every refresh request will complete with no errors. In the real world, a transient network error, machine failure, or software fault could mean that the client fails to store the new refresh token after a refresh request. In this case, the client would be permanently unable to make any further requests, as the only token it has is no longer valid.

This library implements a compromise: At any particular time, a grant may have two valid refresh tokens. When the client uses one of them, the other one is invalidated, and a new one is generated and returned. Thus, if the client correctly uses the new refresh token each time, then older refresh tokens are continuously invalidated. But if a transient failure prevents the client from updating its token, it can always retry the request with the token it used previously.

## Written using Claude

This library (including the schema documentation) was largely written with the help of [Claude](https://claude.ai), the AI model by Anthropic. Claude&#039;s output was thoroughly reviewed by Cloudflare engineers with careful attention paid to security and compliance with standards. Many improvements were made on the initial output, mostly again by prompting Claude (and reviewing the results). Check out the commit history to see how Claude was prompted and what code it produced.

**&quot;NOOOOOOOO!!!! You can&#039;t just use an LLM to write an auth library!&quot;**

&quot;haha gpus go brrr&quot;

In all seriousness, two months ago (January 2025), I ([@kentonv](https://github.com/kentonv)) would have agreed. I was an AI skeptic. I thought LLMs were glorified Markov chain generators that didn&#039;t actually understand code and couldn&#039;t produce anything novel. I started this project on a lark, fully expecting the AI to produce terrible code for me to laugh at. And then, uh... the code actually looked pretty good. Not perfect, but I just told the AI to fix things, and it did. I was shocked.

To emphasize, **this is not &quot;vibe coded&quot;**. Every line was thoroughly reviewed and cross-referenced with relevant RFCs, by security experts with previous experience with those RFCs. I was *trying* to validate my skepticism. I ended up proving myself wrong.

Again, please check out the commit history -- especially early commits -- to understand how this went.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[dzhng/deep-research]]></title>
            <link>https://github.com/dzhng/deep-research</link>
            <guid>https://github.com/dzhng/deep-research</guid>
            <pubDate>Fri, 08 Aug 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[An AI-powered research assistant that performs iterative, deep research on any topic by combining search engines, web scraping, and large language models. The goal of this repo is to provide the simplest implementation of a deep research agent - e.g. an agent that can refine its research direction overtime and deep dive into a topic.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dzhng/deep-research">dzhng/deep-research</a></h1>
            <p>An AI-powered research assistant that performs iterative, deep research on any topic by combining search engines, web scraping, and large language models. The goal of this repo is to provide the simplest implementation of a deep research agent - e.g. an agent that can refine its research direction overtime and deep dive into a topic.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 17,338</p>
            <p>Forks: 1,797</p>
            <p>Stars today: 44 stars today</p>
            <h2>README</h2><pre># Open Deep Research

An AI-powered research assistant that performs iterative, deep research on any topic by combining search engines, web scraping, and large language models.

The goal of this repo is to provide the simplest implementation of a deep research agent - e.g. an agent that can refine its research direction over time and deep dive into a topic. Goal is to keep the repo size at &lt;500 LoC so it is easy to understand and build on top of.

If you like this project, please consider starring it and giving me a follow on [X/Twitter](https://x.com/dzhng). This project is sponsored by [Aomni](https://aomni.com).

## How It Works

```mermaid
flowchart TB
    subgraph Input
        Q[User Query]
        B[Breadth Parameter]
        D[Depth Parameter]
    end

    DR[Deep Research] --&gt;
    SQ[SERP Queries] --&gt;
    PR[Process Results]

    subgraph Results[Results]
        direction TB
        NL((Learnings))
        ND((Directions))
    end

    PR --&gt; NL
    PR --&gt; ND

    DP{depth &gt; 0?}

    RD[&quot;Next Direction:
    - Prior Goals
    - New Questions
    - Learnings&quot;]

    MR[Markdown Report]

    %% Main Flow
    Q &amp; B &amp; D --&gt; DR

    %% Results to Decision
    NL &amp; ND --&gt; DP

    %% Circular Flow
    DP --&gt;|Yes| RD
    RD --&gt;|New Context| DR

    %% Final Output
    DP --&gt;|No| MR

    %% Styling
    classDef input fill:#7bed9f,stroke:#2ed573,color:black
    classDef process fill:#70a1ff,stroke:#1e90ff,color:black
    classDef recursive fill:#ffa502,stroke:#ff7f50,color:black
    classDef output fill:#ff4757,stroke:#ff6b81,color:black
    classDef results fill:#a8e6cf,stroke:#3b7a57,color:black

    class Q,B,D input
    class DR,SQ,PR process
    class DP,RD recursive
    class MR output
    class NL,ND results
```

## Features

- **Iterative Research**: Performs deep research by iteratively generating search queries, processing results, and diving deeper based on findings
- **Intelligent Query Generation**: Uses LLMs to generate targeted search queries based on research goals and previous findings
- **Depth &amp; Breadth Control**: Configurable parameters to control how wide (breadth) and deep (depth) the research goes
- **Smart Follow-up**: Generates follow-up questions to better understand research needs
- **Comprehensive Reports**: Produces detailed markdown reports with findings and sources
- **Concurrent Processing**: Handles multiple searches and result processing in parallel for efficiency

## Requirements

- Node.js environment
- API keys for:
  - Firecrawl API (for web search and content extraction)
  - OpenAI API (for o3 mini model)

## Setup

### Node.js

1. Clone the repository
2. Install dependencies:

```bash
npm install
```

3. Set up environment variables in a `.env.local` file:

```bash
FIRECRAWL_KEY=&quot;your_firecrawl_key&quot;
# If you want to use your self-hosted Firecrawl, add the following below:
# FIRECRAWL_BASE_URL=&quot;http://localhost:3002&quot;

OPENAI_KEY=&quot;your_openai_key&quot;
```

To use local LLM, comment out `OPENAI_KEY` and instead uncomment `OPENAI_ENDPOINT` and `OPENAI_MODEL`:

- Set `OPENAI_ENDPOINT` to the address of your local server (eg.&quot;http://localhost:1234/v1&quot;)
- Set `OPENAI_MODEL` to the name of the model loaded in your local server.

### Docker

1. Clone the repository
2. Rename `.env.example` to `.env.local` and set your API keys

3. Run `docker build -f Dockerfile`

4. Run the Docker image:

```bash
docker compose up -d
```

5. Execute `npm run docker` in the docker service:

```bash
docker exec -it deep-research npm run docker
```

## Usage

Run the research assistant:

```bash
npm start
```

You&#039;ll be prompted to:

1. Enter your research query
2. Specify research breadth (recommended: 3-10, default: 4)
3. Specify research depth (recommended: 1-5, default: 2)
4. Answer follow-up questions to refine the research direction

The system will then:

1. Generate and execute search queries
2. Process and analyze search results
3. Recursively explore deeper based on findings
4. Generate a comprehensive markdown report

The final report will be saved as `report.md` or `answer.md` in your working directory, depending on which modes you selected.

### Concurrency

If you have a paid version of Firecrawl or a local version, feel free to increase the `ConcurrencyLimit` by setting the `CONCURRENCY_LIMIT` environment variable so it runs faster.

If you have a free version, you may sometimes run into rate limit errors, you can reduce the limit to 1 (but it will run a lot slower).

### DeepSeek R1

Deep research performs great on R1! We use [Fireworks](http://fireworks.ai) as the main provider for the R1 model. To use R1, simply set a Fireworks API key:

```bash
FIREWORKS_KEY=&quot;api_key&quot;
```

The system will automatically switch over to use R1 instead of `o3-mini` when the key is detected.

### Custom endpoints and models

There are 2 other optional env vars that lets you tweak the endpoint (for other OpenAI compatible APIs like OpenRouter or Gemini) as well as the model string.

```bash
OPENAI_ENDPOINT=&quot;custom_endpoint&quot;
CUSTOM_MODEL=&quot;custom_model&quot;
```

## How It Works

1. **Initial Setup**

   - Takes user query and research parameters (breadth &amp; depth)
   - Generates follow-up questions to understand research needs better

2. **Deep Research Process**

   - Generates multiple SERP queries based on research goals
   - Processes search results to extract key learnings
   - Generates follow-up research directions

3. **Recursive Exploration**

   - If depth &gt; 0, takes new research directions and continues exploration
   - Each iteration builds on previous learnings
   - Maintains context of research goals and findings

4. **Report Generation**
   - Compiles all findings into a comprehensive markdown report
   - Includes all sources and references
   - Organizes information in a clear, readable format

## License

MIT License - feel free to use and modify as needed.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>