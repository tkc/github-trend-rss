<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for typescript - TypeScript Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for typescript.</description>
        <lastBuildDate>Thu, 29 May 2025 00:04:52 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[n8n-io/n8n]]></title>
            <link>https://github.com/n8n-io/n8n</link>
            <guid>https://github.com/n8n-io/n8n</guid>
            <pubDate>Thu, 29 May 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/n8n-io/n8n">n8n-io/n8n</a></h1>
            <p>Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 100,379</p>
            <p>Forks: 27,882</p>
            <p>Stars today: 841 stars today</p>
            <h2>README</h2><pre>![Banner image](https://user-images.githubusercontent.com/10284570/173569848-c624317f-42b1-45a6-ab09-f0ea3c247648.png)

# n8n - Secure Workflow Automation for Technical Teams

n8n is a workflow automation platform that gives technical teams the flexibility of code with the speed of no-code. With 400+ integrations, native AI capabilities, and a fair-code license, n8n lets you build powerful automations while maintaining full control over your data and deployments.

![n8n.io - Screenshot](https://raw.githubusercontent.com/n8n-io/n8n/master/assets/n8n-screenshot-readme.png)

## Key Capabilities

- **Code When You Need It**: Write JavaScript/Python, add npm packages, or use the visual interface
- **AI-Native Platform**: Build AI agent workflows based on LangChain with your own data and models
- **Full Control**: Self-host with our fair-code license or use our [cloud offering](https://app.n8n.cloud/login)
- **Enterprise-Ready**: Advanced permissions, SSO, and air-gapped deployments
- **Active Community**: 400+ integrations and 900+ ready-to-use [templates](https://n8n.io/workflows)

## Quick Start

Try n8n instantly with [npx](https://docs.n8n.io/hosting/installation/npm/) (requires [Node.js](https://nodejs.org/en/)):

```
npx n8n
```

Or deploy with [Docker](https://docs.n8n.io/hosting/installation/docker/):

```
docker volume create n8n_data
docker run -it --rm --name n8n -p 5678:5678 -v n8n_data:/home/node/.n8n docker.n8n.io/n8nio/n8n
```

Access the editor at http://localhost:5678

## Resources

- 📚 [Documentation](https://docs.n8n.io)
- 🔧 [400+ Integrations](https://n8n.io/integrations)
- 💡 [Example Workflows](https://n8n.io/workflows)
- 🤖 [AI &amp; LangChain Guide](https://docs.n8n.io/langchain/)
- 👥 [Community Forum](https://community.n8n.io)
- 📖 [Community Tutorials](https://community.n8n.io/c/tutorials/28)

## Support

Need help? Our community forum is the place to get support and connect with other users:
[community.n8n.io](https://community.n8n.io)

## License

n8n is [fair-code](https://faircode.io) distributed under the [Sustainable Use License](https://github.com/n8n-io/n8n/blob/master/LICENSE.md) and [n8n Enterprise License](https://github.com/n8n-io/n8n/blob/master/LICENSE_EE.md).

- **Source Available**: Always visible source code
- **Self-Hostable**: Deploy anywhere
- **Extensible**: Add your own nodes and functionality

[Enterprise licenses](mailto:license@n8n.io) available for additional features and support.

Additional information about the license model can be found in the [docs](https://docs.n8n.io/reference/license/).

## Contributing

Found a bug 🐛 or have a feature idea ✨? Check our [Contributing Guide](https://github.com/n8n-io/n8n/blob/master/CONTRIBUTING.md) to get started.

## Join the Team

Want to shape the future of automation? Check out our [job posts](https://n8n.io/careers) and join our team!

## What does n8n mean?

**Short answer:** It means &quot;nodemation&quot; and is pronounced as n-eight-n.

**Long answer:** &quot;I get that question quite often (more often than I expected) so I decided it is probably best to answer it here. While looking for a good name for the project with a free domain I realized very quickly that all the good ones I could think of were already taken. So, in the end, I chose nodemation. &#039;node-&#039; in the sense that it uses a Node-View and that it uses Node.js and &#039;-mation&#039; for &#039;automation&#039; which is what the project is supposed to help with. However, I did not like how long the name was and I could not imagine writing something that long every time in the CLI. That is when I then ended up on &#039;n8n&#039;.&quot; - **Jan Oberhauser, Founder and CEO, n8n.io**
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[NomicFoundation/hardhat]]></title>
            <link>https://github.com/NomicFoundation/hardhat</link>
            <guid>https://github.com/NomicFoundation/hardhat</guid>
            <pubDate>Thu, 29 May 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[Hardhat is a development environment to compile, deploy, test, and debug your Ethereum software.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NomicFoundation/hardhat">NomicFoundation/hardhat</a></h1>
            <p>Hardhat is a development environment to compile, deploy, test, and debug your Ethereum software.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 7,769</p>
            <p>Forks: 1,561</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>packages/hardhat-core/README.md</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[labring/FastGPT]]></title>
            <link>https://github.com/labring/FastGPT</link>
            <guid>https://github.com/labring/FastGPT</guid>
            <pubDate>Thu, 29 May 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[FastGPT is a knowledge-based platform built on the LLMs, offers a comprehensive suite of out-of-the-box capabilities such as data processing, RAG retrieval, and visual AI workflow orchestration, letting you easily develop and deploy complex question-answering systems without the need for extensive setup or configuration.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/labring/FastGPT">labring/FastGPT</a></h1>
            <p>FastGPT is a knowledge-based platform built on the LLMs, offers a comprehensive suite of out-of-the-box capabilities such as data processing, RAG retrieval, and visual AI workflow orchestration, letting you easily develop and deploy complex question-answering systems without the need for extensive setup or configuration.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 24,385</p>
            <p>Forks: 6,296</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://tryfastgpt.ai/&quot;&gt;&lt;img src=&quot;/.github/imgs/logo.svg&quot; width=&quot;120&quot; height=&quot;120&quot; alt=&quot;fastgpt logo&quot;&gt;&lt;/a&gt;

# FastGPT

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README_en.md&quot;&gt;English&lt;/a&gt; |
  &lt;a href=&quot;./README.md&quot;&gt;简体中文&lt;/a&gt; |
  &lt;a href=&quot;./README_ja.md&quot;&gt;日语&lt;/a&gt;
&lt;/p&gt;

FastGPT 是一个 AI Agent 构建平台，提供开箱即用的数据处理、模型调用等能力，同时可以通过 Flow 可视化进行工作流编排，从而实现复杂的应用场景！

&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://tryfastgpt.ai/&quot;&gt;
    &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/在线使用-d4eaf7?style=flat-square&amp;logo=spoj&amp;logoColor=7d09f1&quot; alt=&quot;cloud&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://doc.tryfastgpt.ai/docs/intro&quot;&gt;
    &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/相关文档-7d09f1?style=flat-square&quot; alt=&quot;document&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://doc.tryfastgpt.ai/docs/development&quot;&gt;
    &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/本地开发-%23d4eaf7?style=flat-square&amp;logo=xcode&amp;logoColor=7d09f1&quot; alt=&quot;development&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;/#-%E7%9B%B8%E5%85%B3%E9%A1%B9%E7%9B%AE&quot;&gt;
    &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/相关项目-7d09f1?style=flat-square&quot; alt=&quot;project&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

https://github.com/labring/FastGPT/assets/15308462/7d3a38df-eb0e-4388-9250-2409bd33f6d4

## 🛸 在线使用

- 🌍 国际版：[tryfastgpt.ai](https://tryfastgpt.ai/)

|                                    |                                    |
| ---------------------------------- | ---------------------------------- |
| ![Demo](./.github/imgs/intro1.png) | ![Demo](./.github/imgs/intro2.png) |
| ![Demo](./.github/imgs/intro3.png) | ![Demo](./.github/imgs/intro4.png) |

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-返回顶部-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## 💡 RoadMap

`1` 应用编排能力
   - [x] 对话工作流、插件工作流
   - [x] 工具调用
   - [x] Code sandbox
   - [x] 循环调用
   - [x] 用户选择
   - [x] 表单输入

`2` 知识库能力
   - [x] 多库复用，混用
   - [x] chunk 记录修改和删除
   - [x] 支持手动输入，直接分段，QA 拆分导入
   - [x] 支持 txt，md，html，pdf，docx，pptx，csv，xlsx (有需要更多可 PR file loader)，支持 url 读取、CSV 批量导入
   - [x] 混合检索 &amp; 重排
   - [x] API 知识库
   - [ ] 自定义文件读取服务
   - [ ] 自定义分块服务
  
`3` 应用调试能力
   - [x] 知识库单点搜索测试
   - [x] 对话时反馈引用并可修改与删除
   - [x] 完整上下文呈现
   - [x] 完整模块中间值呈现
   - [ ] 高级编排 DeBug 模式
  
`4` OpenAPI 接口
   - [x] completions 接口 (chat 模式对齐 GPT 接口)
   - [x] 知识库 CRUD
   - [x] 对话 CRUD
  
`5` 运营能力
   - [x] 免登录分享窗口
   - [x] Iframe 一键嵌入
   - [x] 聊天窗口嵌入支持自定义 Icon，默认打开，拖拽等功能
   - [x] 统一查阅对话记录，并对数据进行标注
   
`6` 其他
   - [x] 可视化模型配置。
   - [x] 支持语音输入和输出 (可配置语音输入语音回答)
   - [x] 模糊输入提示
   - [x] 模板市场

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-返回顶部-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## 👨‍💻 开发

项目技术栈：NextJs + TS + ChakraUI + MongoDB + PostgreSQL (PG Vector 插件)/Milvus

- **⚡ 快速部署**

  &gt; 使用 [Sealos](https://sealos.io) 服务，无需采购服务器、无需域名，支持高并发 &amp; 动态伸缩，并且数据库应用采用 kubeblocks 的数据库，在 IO 性能方面，远超于简单的 Docker 容器部署。

  [点击查看 Sealos 一键部署 FastGPT 教程](https://doc.tryfastgpt.ai/docs/development/sealos/)

* [快速开始本地开发](https://doc.tryfastgpt.ai/docs/development/intro/)
* [部署 FastGPT](https://doc.tryfastgpt.ai/docs/development/sealos/)
* [系统配置文件说明](https://doc.tryfastgpt.ai/docs/development/configuration/)
* [多模型配置方案](https://doc.tryfastgpt.ai/docs/development/modelconfig/one-api/)
* [版本更新/升级介绍](https://doc.tryfastgpt.ai/docs/development/upgrading/)
* [OpenAPI API 文档](https://doc.tryfastgpt.ai/docs/development/openapi/)
* [知识库结构详解](https://doc.tryfastgpt.ai/docs/guide/knowledge_base/rag/)

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-返回顶部-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## 🏘️ 加入我们

我们正在寻找志同道合的小伙伴，加速 FastGPT 的发展。你可以通过 [FastGPT 2025 招聘](https://fael3z0zfze.feishu.cn/wiki/P7FOwEmPziVcaYkvVaacnVX1nvg)了解 FastGPT 的招聘信息。

## 💪 相关项目

- [Laf：3 分钟快速接入三方应用](https://github.com/labring/laf)
- [Sealos：快速部署集群应用](https://github.com/labring/sealos)
- [One API：多模型管理，支持 Azure、文心一言等](https://github.com/songquanpeng/one-api)

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-返回顶部-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## 🌿 第三方生态
- [PPIO 派欧云：一键调用高性价比的开源模型 API 和 GPU 容器](https://ppinfra.com/user/register?invited_by=VITYVU&amp;utm_source=github_fastgpt)
- [AI Proxy：国内模型聚合服务](https://sealos.run/aiproxy/?k=fastgpt-github/)
- [SiliconCloud (硅基流动) —— 开源模型在线体验平台](https://cloud.siliconflow.cn/i/TR9Ym0c4)
- [COW 个人微信/企微机器人](https://doc.tryfastgpt.ai/docs/use-cases/external-integration/onwechat/)

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-返回顶部-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## 🏘️ 社区交流群

扫码加入飞书话题群：

![](https://oss.laf.run/otnvvf-imgs/fastgpt-feishu1.png)

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-返回顶部-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## 👀 其他

- [保姆级 FastGPT 教程](https://www.bilibili.com/video/BV1n34y1A7Bo/?spm_id_from=333.999.0.0)
- [接入飞书](https://www.bilibili.com/video/BV1Su4y1r7R3/?spm_id_from=333.999.0.0)
- [接入企微](https://www.bilibili.com/video/BV1Tp4y1n72T/?spm_id_from=333.999.0.0)

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-返回顶部-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## 🤝 参与贡献

我们非常欢迎各种形式的贡献。如果你对贡献代码感兴趣，可以查看我们的 GitHub [Issues](https://github.com/labring/FastGPT/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc)，大展身手，向我们展示你的奇思妙想。

&lt;a href=&quot;https://github.com/labring/FastGPT/graphs/contributors&quot; target=&quot;_blank&quot;&gt;
  &lt;table&gt;
    &lt;tr&gt;
      &lt;th colspan=&quot;2&quot;&gt;
        &lt;br&gt;&lt;img src=&quot;https://contrib.rocks/image?repo=labring/FastGPT&quot;&gt;&lt;br&gt;&lt;br&gt;
      &lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&amp;period=past_28_days&amp;owner_id=102226726&amp;repo_ids=605673387&amp;image_size=2x3&amp;color_scheme=dark&quot;&gt;
          &lt;img alt=&quot;Active participants of labring - past 28 days&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&amp;period=past_28_days&amp;owner_id=102226726&amp;repo_ids=605673387&amp;image_size=2x3&amp;color_scheme=light&quot;&gt;
        &lt;/picture&gt;****
      &lt;/td&gt;
      &lt;td rowspan=&quot;2&quot;&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=new&amp;period=past_28_days&amp;owner_id=102226726&amp;repo_ids=605673387&amp;image_size=4x7&amp;color_scheme=dark&quot;&gt;
          &lt;img alt=&quot;New trends of labring&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=new&amp;period=past_28_days&amp;owner_id=102226726&amp;repo_ids=605673387&amp;image_size=4x7&amp;color_scheme=light&quot;&gt;
        &lt;/picture&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&amp;period=past_28_days&amp;owner_id=102226726&amp;repo_ids=605673387&amp;image_size=2x3&amp;color_scheme=dark&quot;&gt;
          &lt;img alt=&quot;New participants of labring - past 28 days&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&amp;period=past_28_days&amp;owner_id=102226726&amp;repo_ids=605673387&amp;image_size=2x3&amp;color_scheme=light&quot;&gt;
        &lt;/picture&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/a&gt;

## 🌟 Star History

&lt;a href=&quot;https://github.com/labring/FastGPT/stargazers&quot; target=&quot;_blank&quot; style=&quot;display: block&quot; align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=labring/FastGPT&amp;type=Date&amp;theme=dark&quot; /&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=labring/FastGPT&amp;type=Date&quot; /&gt;
    &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=labring/FastGPT&amp;type=Date&quot; /&gt;
  &lt;/picture&gt;
&lt;/a&gt;

&lt;a href=&quot;#readme&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-返回顶部-7d09f1.svg&quot; alt=&quot;#&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## 使用协议

本仓库遵循 [FastGPT Open Source License](./LICENSE) 开源协议。

1. 允许作为后台服务直接商用，但不允许提供 SaaS 服务。
2. 未经商业授权，任何形式的商用服务均需保留相关版权信息。
3. 完整请查看 [FastGPT Open Source License](./LICENSE)
4. 联系方式：Dennis@sealos.io，[点击查看商业版定价策略](https://doc.tryfastgpt.ai/docs/shopping_cart/intro/)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[wg-easy/wg-easy]]></title>
            <link>https://github.com/wg-easy/wg-easy</link>
            <guid>https://github.com/wg-easy/wg-easy</guid>
            <pubDate>Thu, 29 May 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[The easiest way to run WireGuard VPN + Web-based Admin UI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wg-easy/wg-easy">wg-easy/wg-easy</a></h1>
            <p>The easiest way to run WireGuard VPN + Web-based Admin UI.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 19,383</p>
            <p>Forks: 1,838</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre># WireGuard Easy

[![Build &amp; Publish latest Image](https://github.com/wg-easy/wg-easy/actions/workflows/deploy.yml/badge.svg?branch=production)](https://github.com/wg-easy/wg-easy/actions/workflows/deploy.yml)
[![Lint](https://github.com/wg-easy/wg-easy/actions/workflows/lint.yml/badge.svg?branch=master)](https://github.com/wg-easy/wg-easy/actions/workflows/lint.yml)
[![GitHub Stars](https://img.shields.io/github/stars/wg-easy/wg-easy)](https://github.com/wg-easy/wg-easy/stargazers)
[![License](https://img.shields.io/github/license/wg-easy/wg-easy)](LICENSE)
[![GitHub Release](https://img.shields.io/github/v/release/wg-easy/wg-easy)](https://github.com/wg-easy/wg-easy/releases/latest)
[![Image Pulls](https://img.shields.io/badge/image_pulls-12M+-blue)](https://github.com/wg-easy/wg-easy/pkgs/container/wg-easy)

You have found the easiest way to install &amp; manage WireGuard on any Linux host!

&lt;!-- TOOD: update screenshot --&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./assets/screenshot.png&quot; width=&quot;802&quot; /&gt;
&lt;/p&gt;

## Features

- All-in-one: WireGuard + Web UI.
- Easy installation, simple to use.
- List, create, edit, delete, enable &amp; disable clients.
- Show a client&#039;s QR code.
- Download a client&#039;s configuration file.
- Statistics for which clients are connected.
- Tx/Rx charts for each connected client.
- Gravatar support.
- Automatic Light / Dark Mode
- Multilanguage Support
- One Time Links
- Client Expiration
- Prometheus metrics support
- IPv6 support
- CIDR support
- 2FA support

&gt; [!NOTE]
&gt; To better manage documentation for this project, it has its own site here: [https://wg-easy.github.io/wg-easy/latest](https://wg-easy.github.io/wg-easy/latest)

- [Getting Started](https://wg-easy.github.io/wg-easy/latest/getting-started/)
- [Basic Installation](https://wg-easy.github.io/wg-easy/latest/examples/tutorials/basic-installation/)
- [Caddy](https://wg-easy.github.io/wg-easy/latest/examples/tutorials/caddy/)
- [Traefik](https://wg-easy.github.io/wg-easy/latest/examples/tutorials/traefik/)
- [Podman](https://wg-easy.github.io/wg-easy/latest/examples/tutorials/podman-nft/)
- [AdGuard Home](https://wg-easy.github.io/wg-easy/latest/examples/tutorials/adguard/)

&gt; [!NOTE]
&gt; If you want to migrate from the old version to the new version, you can find the migration guide here: [Migration Guide](https://wg-easy.github.io/wg-easy/latest/advanced/migrate/)

## Installation

This is a quick start guide to get you up and running with WireGuard Easy.

For a more detailed installation guide, please refer to the [Getting Started](https://wg-easy.github.io/wg-easy/latest/getting-started/) page.

### 1. Install Docker

If you haven&#039;t installed Docker yet, install it by running as root:

```shell
curl -sSL https://get.docker.com | sh
exit
```

And log in again.

### 2. Run WireGuard Easy

The easiest way to run WireGuard Easy is with Docker Compose.

Just download [`docker-compose.yml`](docker-compose.yml) and execute `sudo docker compose up -d`.

Now setup a reverse proxy to be able to access the Web UI securely from the internet.

If you want to access the Web UI over HTTP, change the env var `INSECURE` to `true`. This is not recommended. Only use this for testing

## Donate

Are you enjoying this project? Consider donating.

Founder: [Buy Emile a beer!](https://github.com/sponsors/WeeJeWel) 🍻

Maintainer: [Buy kaaax0815 a coffee!](https://github.com/sponsors/kaaax0815) ☕

## Development

### Prerequisites

- Docker
- Node LTS &amp; corepack enabled
- Visual Studio Code

### Dev Server

This starts the development server with docker

```shell
pnpm dev
```

### Update Auto Imports

If you add something that should be auto-importable and VSCode complains, run:

```shell
cd src
pnpm install
cd ..
```

### Test Cli

This starts the cli with docker

```shell
pnpm cli:dev
```

## License

This project is licensed under the AGPL-3.0-only License - see the [LICENSE](LICENSE) file for details

This project is not affiliated, associated, authorized, endorsed by, or in any way officially connected with Jason A. Donenfeld, ZX2C4 or Edge Security

&quot;WireGuard&quot; and the &quot;WireGuard&quot; logo are registered trademarks of Jason A. Donenfeld
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[microsoft/data-formulator]]></title>
            <link>https://github.com/microsoft/data-formulator</link>
            <guid>https://github.com/microsoft/data-formulator</guid>
            <pubDate>Thu, 29 May 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[🪄 Create rich visualizations with AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/data-formulator">microsoft/data-formulator</a></h1>
            <p>🪄 Create rich visualizations with AI</p>
            <p>Language: TypeScript</p>
            <p>Stars: 12,155</p>
            <p>Forks: 964</p>
            <p>Stars today: 57 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;
    &lt;img src=&quot;./public/favicon.ico&quot; alt=&quot;Data Formulator icon&quot; width=&quot;28&quot;&gt; &lt;b&gt;Data Formulator: Create Rich Visualizations with AI&lt;/b&gt;
&lt;/h1&gt;

&lt;div&gt;
    
[![arxiv](https://img.shields.io/badge/Paper-arXiv:2408.16119-b31b1b.svg)](https://arxiv.org/abs/2408.16119)&amp;ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)&amp;ensp;
[![YouTube](https://img.shields.io/badge/YouTube-white?logo=youtube&amp;logoColor=%23FF0000)](https://youtu.be/3ndlwt0Wi3c)&amp;ensp;
[![build](https://github.com/microsoft/data-formulator/actions/workflows/python-build.yml/badge.svg)](https://github.com/microsoft/data-formulator/actions/workflows/python-build.yml)
[![Discord](https://img.shields.io/badge/discord-chat-green?logo=discord)](https://discord.gg/mYCZMQKYZb)

&lt;/div&gt;

Transform data and create rich visualizations iteratively with AI 🪄. Try Data Formulator now!

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/data-formulator?quickstart=1)

&lt;kbd&gt;
  &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://codespaces.new/microsoft/data-formulator?quickstart=1&quot; title=&quot;open Data Formulator in GitHub Codespaces&quot;&gt;&lt;img src=&quot;public/data-formulator-screenshot.png&quot;&gt;&lt;/a&gt;
&lt;/kbd&gt;


## News 🔥🔥🔥

- [05-13-2025] Data Formulator 0.2.1: External Data Loader 
  - We introduced external data loader class to make import data easier. [Readme](https://github.com/microsoft/data-formulator/tree/main/py-src/data_formulator/data_loader) and [Demo](https://github.com/microsoft/data-formulator/pull/155)
    - Example data loaders from MySQL and Azure Data Explorer (Kusto) are provided.
  - Call for action [link](https://github.com/microsoft/data-formulator/issues/156):
    - Users: let us know which data source you&#039;d like to load data from.
    - Developers: let&#039;s build more data loaders.
  - Discord channel for discussions: join us! [![Discord](https://img.shields.io/badge/discord-chat-green?logo=discord)](https://discord.gg/mYCZMQKYZb)

- [04-23-2025] Data Formulator 0.2: working with *large* data 📦📦📦
  - Explore large data by:
    1. Upload large data file to the local database (powered by [DuckDB](https://github.com/duckdb/duckdb)).
    2. Use drag-and-drop to specify charts, and Data Formulator dynamically fetches data from the database to create visualizations (with ⚡️⚡️⚡️ speeds).
    3. Work with AI agents: they generate SQL queries to transform the data to create rich visualizations!
    4. Anchor the result / follow up / create a new branch / join tables; let&#039;s dive deeper. 
  - Checkout the demos at [[https://github.com/microsoft/data-formulator/releases/tag/0.2]](https://github.com/microsoft/data-formulator/releases/tag/0.2)
  - Improved overall system performance, and enjoy the updated derive concept functionality.

- [03-20-2025] Data Formulator 0.1.7: Anchoring ⚓︎
  - Anchor an intermediate dataset, so that followup data analysis are built on top of the anchored data, not the original one.
  - Clean a data and work with only the cleaned data; create a subset from the original data or join multiple data, and then go from there. AI agents will be less likely to get confused and work faster. ⚡️⚡️
  - Check out the demos at [[https://github.com/microsoft/data-formulator/releases/tag/0.1.7]](https://github.com/microsoft/data-formulator/releases/tag/0.1.7)
  - Don&#039;t forget to update Data Formulator to test it out!

- [02-20-2025] Data Formulator 0.1.6 released! 
  - Now supports working with multiple datasets at once! Tell Data Formulator which data tables you would like to use in the encoding shelf, and it will figure out how to join the tables to create a visualization to answer your question. 🪄
  - Checkout the demo at [[https://github.com/microsoft/data-formulator/releases/tag/0.1.6]](https://github.com/microsoft/data-formulator/releases/tag/0.1.6).
  - Update your Data Formulator to the latest version to play with the new features.

- [02-12-2025] More models supported now!
  - Now supports OpenAI, Azure, Ollama, and Anthropic models (and more powered by [LiteLLM](https://github.com/BerriAI/litellm));
  - Models with strong code generation and instruction following capabilities are recommended (gpt-4o, claude-3-5-sonnet etc.);
  - You can store API keys in `api-keys.env` to avoid typing them every time (see template `api-keys.env.template`).
  - Let us know which models you have good/bad experiences with, and what models you would like to see supported! [[comment here]](https://github.com/microsoft/data-formulator/issues/49)

- [11-07-2024] Minor fun update: data visualization challenges!
  - We added a few visualization challenges with the sample datasets. Can you complete them all? [[try them out!]](https://github.com/microsoft/data-formulator/issues/53#issue-2641841252)
  - Comment in the issue when you did, or share your results/questions with others! [[comment here]](https://github.com/microsoft/data-formulator/issues/53)

- [10-11-2024] Data Formulator python package released! 
  - You can now install Data Formulator using Python and run it locally, easily. [[check it out]](#get-started).
  - Our Codespaces configuration is also updated for fast start up ⚡️. [[try it now!]](https://codespaces.new/microsoft/data-formulator?quickstart=1)
  - New experimental feature: load an image or a messy text, and ask AI to parse and clean it for you(!). [[demo]](https://github.com/microsoft/data-formulator/pull/31#issuecomment-2403652717)
  
- [10-01-2024] Initial release of Data Formulator, check out our [[blog]](https://www.microsoft.com/en-us/research/blog/data-formulator-exploring-how-ai-can-help-analysts-create-rich-data-visualizations/) and [[video]](https://youtu.be/3ndlwt0Wi3c)!



## Overview

**Data Formulator** is an application from Microsoft Research that uses large language models to transform data, expediting the practice of data visualization.

Data Formulator is an AI-powered tool for analysts to iteratively create rich visualizations. Unlike most chat-based AI tools where users need to describe everything in natural language, Data Formulator combines *user interface interactions (UI)* and *natural language (NL) inputs* for easier interaction. This blended approach makes it easier for users to describe their chart designs while delegating data transformation to AI. 

## Get Started

Play with Data Formulator with one of the following options:

- **Option 1: Install via Python PIP**
  
  Use Python PIP for an easy setup experience, running locally (recommend: install it in a virtual environment).
  
  ```bash
  # install data_formulator
  pip install data_formulator

  # start data_formulator
  data_formulator 
  
  # alternatively, you can run data formulator with this command
  python -m data_formulator
  ```

  Data Formulator will be automatically opened in the browser at [http://localhost:5000](http://localhost:5000).

  *Update: you can specify the port number (e.g., 8080) by `python -m data_formulator --port 8080` if the default port is occupied.*

- **Option 2: Codespaces (5 minutes)**
  
  You can also run Data Formulator in Codespaces; we have everything pre-configured. For more details, see [CODESPACES.md](CODESPACES.md).
  
  [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/data-formulator?quickstart=1)

- **Option 3: Working in the developer mode**
  
  You can build Data Formulator locally if you prefer full control over your development environment and the ability to customize the setup to your specific needs. For detailed instructions, refer to [DEVELOPMENT.md](DEVELOPMENT.md).


## Using Data Formulator

Once you&#039;ve completed the setup using either option, follow these steps to start using Data Formulator:

### The basics of data visualization
* Provide OpenAI keys and select a model (GPT-4o suggested) and choose a dataset.
* Choose a chart type, and then drag-and-drop data fields to chart properties (x, y, color, ...) to specify visual encodings.

https://github.com/user-attachments/assets/0fbea012-1d2d-46c3-a923-b1fc5eb5e5b8


### Create visualization beyond the initial dataset (powered by 🤖)
* You can type names of **fields that do not exist in current data** in the encoding shelf:
    - this tells Data Formulator that you want to create visualizations that require computation or transformation from existing data,
    - you can optionally provide a natural language prompt to explain and clarify your intent (not necessary when field names are self-explanatory).
* Click the **Formulate** button.
    - Data Formulator will transform data and instantiate the visualization based on the encoding and prompt.
* Inspect the data, chart and code.
* To create a new chart based on existing ones, follow up in natural language:
    - provide a follow up prompt (e.g., *``show only top 5!&#039;&#039;*),
    - you may also update visual encodings for the new chart.

https://github.com/user-attachments/assets/160c69d2-f42d-435c-9ff3-b1229b5bddba

https://github.com/user-attachments/assets/c93b3e84-8ca8-49ae-80ea-f91ceef34acb

Repeat this process as needed to explore and understand your data. Your explorations are trackable in the **Data Threads** panel. 

## Developers&#039; Guide

Follow the [developers&#039; instructions](DEVELOPMENT.md) to build your new data analysis tools on top of Data Formulator.

## Research Papers
* [Data Formulator 2: Iteratively Creating Rich Visualizations with AI](https://arxiv.org/abs/2408.16119)

```
@article{wang2024dataformulator2iteratively,
      title={Data Formulator 2: Iteratively Creating Rich Visualizations with AI}, 
      author={Chenglong Wang and Bongshin Lee and Steven Drucker and Dan Marshall and Jianfeng Gao},
      year={2024},
      booktitle={ArXiv preprint arXiv:2408.16119},
}
```

* [Data Formulator: AI-powered Concept-driven Visualization Authoring](https://arxiv.org/abs/2309.10094)

```
@article{wang2023data,
  title={Data Formulator: AI-powered Concept-driven Visualization Authoring},
  author={Wang, Chenglong and Thompson, John and Lee, Bongshin},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2023},
  publisher={IEEE}
}
```


## Contributing

This project welcomes contributions and suggestions. Most contributions require you to
agree to a Contributor License Agreement (CLA) declaring that you have the right to,
and actually do, grant us the rights to use your contribution. For details, visit
https://cla.microsoft.com.

When you submit a pull request, a CLA-bot will automatically determine whether you need
to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the
instructions provided by the bot. You will only need to do this once across all repositories using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)
or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft 
trademarks or logos is subject to and must follow 
[Microsoft&#039;s Trademark &amp; Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party&#039;s policies.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[openai/openai-realtime-agents]]></title>
            <link>https://github.com/openai/openai-realtime-agents</link>
            <guid>https://github.com/openai/openai-realtime-agents</guid>
            <pubDate>Thu, 29 May 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[This is a simple demonstration of more advanced, agentic patterns built on top of the Realtime API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/openai-realtime-agents">openai/openai-realtime-agents</a></h1>
            <p>This is a simple demonstration of more advanced, agentic patterns built on top of the Realtime API.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 5,696</p>
            <p>Forks: 721</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre># Realtime API Agents Demo

This is a demonstration of more advanced patterns for voice agents, using the OpenAI Realtime API. There are two main patterns demonstrated:
1. **Chat-Supervisor:** A realtime-based chat agent interacts with the user and handles basic tasks, while a more intelligent, text-based supervisor model (e.g., `gpt-4.1`) is used extensively for tool calls and more complex responses. This approach provides an easy onramp and high-quality answers, with a small increase in latency.
2. **Sequential Handoff:** Specialized agents (powered by realtime api) transfer the user between them to handle specific user intents. This is great for customer service, where user intents can be handled sequentially by specialist models that excel in a specific domains. This helps avoid the model having all instructions and tools in a single agent, which can degrade performance.

## Setup

- This is a Next.js typescript app. Install dependencies with `npm i`.
- Add your `OPENAI_API_KEY` to your env. Either add it to your `.bash_profile` or equivalent, or copy `.env.sample` to `.env` and add it there.
- Start the server with `npm run dev`
- Open your browser to [http://localhost:3000](http://localhost:3000). It should default to the `chatSupervisor` Agent Config.
- You can change examples via the &quot;Scenario&quot; dropdown in the top right.

# Agentic Pattern 1: Chat-Supervisor

This is demonstrated in the [chatSupervisor](src/app/agentConfigs/chatSupervisor/index.ts) Agent Config. The chat agent uses the realtime model to converse with the user and handle basic tasks, like greeting the user, casual conversation, and collecting information, and a more intelligent, text-based supervisor model (e.g. `gpt-4.1`) is used extensively to handle tool calls and more challenging responses. You can control the decision boundary by &quot;opting in&quot; specific tasks to the chat agent as desired.

Video walkthrough: [https://x.com/noahmacca/status/1927014156152058075](https://x.com/noahmacca/status/1927014156152058075)

## Example
![Screenshot of the Chat Supervisor Flow](/public/screenshot_chat_supervisor.png)
*In this exchange, note the immediate response to collect the phone number, and the deferral to the supervisor agent to handle the tool call and formulate the response. There ~2s between the end of &quot;give me a moment to check on that.&quot; being spoken aloud and the start of the &quot;Thanks for waiting. Your last bill...&quot;.*

## Schematic
```mermaid
sequenceDiagram
    participant User
    participant ChatAgent as Chat Agent&lt;br/&gt;(gpt-4o-realtime-mini)
    participant Supervisor as Supervisor Agent&lt;br/&gt;(gpt-4.1)
    participant Tool as Tool

    alt Basic chat or info collection
        User-&gt;&gt;ChatAgent: User message
        ChatAgent-&gt;&gt;User: Responds directly
    else Requires higher intelligence and/or tool call
        User-&gt;&gt;ChatAgent: User message
        ChatAgent-&gt;&gt;User: &quot;Let me think&quot;
        ChatAgent-&gt;&gt;Supervisor: Forwards message/context
        alt Tool call needed
            Supervisor-&gt;&gt;Tool: Calls tool
            Tool-&gt;&gt;Supervisor: Returns result
        end
        Supervisor-&gt;&gt;ChatAgent: Returns response
        ChatAgent-&gt;&gt;User: Delivers response
    end
```

## Benefits
- **Simpler onboarding.** If you already have a performant text-based chat agent, you can give that same prompt and set of tools to the supervisor agent, and make some tweaks to the chat agent prompt, you&#039;ll have a natural voice agent that will perform on par with your text agent.
- **Simple ramp to a full realtime agent**: Rather than switching your whole agent to the realtime api, you can move one task at a time, taking time to validate and build trust for each before deploying to production.
- **High intelligence**: You benefit from the high intelligence, excellent tool calling and instruction following of models like `gpt-4.1` in your voice agents.
- **Lower cost**: If your chat agent is only being used for basic tasks, you can use the realtime-mini model, which, even when combined with GPT-4.1, should be cheaper than using the full 4o-realtime model.
- **User experience**: It&#039;s a more natural conversational experience than using a stitched model architecture, where response latency is often 1.5s or longer after a user has finished speaking. In this architecture, the model responds to the user right away, even if it has to lean on the supervisor agent.
  - However, more assistant responses will start with &quot;Let me think&quot;, rather than responding immediately with the full response.

## Modifying for your own agent
1. Update [supervisorAgent](src/app/agentConfigs/chatSupervisorDemo/supervisorAgent.ts).
  - Add your existing text agent prompt and tools if you already have them. This should contain the &quot;meat&quot; of your voice agent logic and be very specific with what it should/shouldn&#039;t do and how exactly it should respond. Add this information below `==== Domain-Specific Agent Instructions ====`.
  - You should likely update this prompt to be more appropriate for voice, for example with instructions to be concise and avoiding long lists of items.
2. Update [chatAgent](src/app/agentConfigs/chatSupervisor/index.ts).
  - Customize the chatAgent instructions with your own tone, greeting, etc.
  - Add your tool definitions to `chatAgentInstructions`. We recommend a brief yaml description rather than json to ensure the model doesn&#039;t get confused and try calling the tool directly.
  - You can modify the decision boundary by adding new items to the `# Allow List of Permitted Actions` section.
3. To reduce cost, try using `gpt-4o-mini-realtime` for the chatAgent and/or `gpt-4.1-mini` for the supervisor model. To maximize intelligence on particularly difficult or high-stakes tasks, consider trading off latency and adding chain-of-thought to your supervisor prompt, or using an additional reasoning model-based supervisor that uses `o4-mini`.

# Agentic Pattern 2: Sequential Handoffs

This pattern is inspired by [OpenAI Swarm](https://github.com/openai/swarm) and involves the sequential handoff of a user between specialized agents. Handoffs are decided by the model and coordinated via tool calls, and possible handoffs are defined explicitly in an agent graph. A handoff triggers a session.update event with new instructions and tools. This pattern is effective for handling a variety of user intents with specialist agents, each of which might have long instructions and numerous tools.

Here&#039;s a [video walkthrough](https://x.com/OpenAIDevs/status/1880306081517432936) showing how it works. You should be able to use this repo to prototype your own multi-agent realtime voice app in less than 20 minutes!

![Screenshot of the Realtime API Agents Demo](/public/screenshot_handoff.png)
*In this simple example, the user is transferred from a greeter agent to a haiku agent. See below for the simple, full configuration of this flow.*

Configuration in `src/app/agentConfigs/simpleExample.ts`
```javascript
import { AgentConfig } from &quot;@/app/types&quot;;
import { injectTransferTools } from &quot;./utils&quot;;

// Define agents
const haikuWriter: AgentConfig = {
  name: &quot;haikuWriter&quot;,
  publicDescription: &quot;Agent that writes haikus.&quot;, // Context for the agent_transfer tool
  instructions:
    &quot;Ask the user for a topic, then reply with a haiku about that topic.&quot;,
  tools: [],
};

const greeter: AgentConfig = {
  name: &quot;greeter&quot;,
  publicDescription: &quot;Agent that greets the user.&quot;,
  instructions:
    &quot;Please greet the user and ask them if they&#039;d like a Haiku. If yes, transfer them to the &#039;haiku&#039; agent.&quot;,
  tools: [],
  downstreamAgents: [haikuWriter],
};

// add the transfer tool to point to downstreamAgents
const agents = injectTransferTools([greeter, haikuWriter]);

export default agents;
```
## CustomerServiceRetail Flow

This is a more complex, representative implementation that illustrates a customer service flow, with the following features:
- A more complex agent graph with agents for user authentication, returns, sales, and a placeholder human agent for escalations.
- An escalation by the [returns](https://github.com/openai/openai-realtime-agents/blob/60f4effc50a539b19b2f1fa4c38846086b58c295/src/app/agentConfigs/customerServiceRetail/returns.ts#L233) agent to `o4-mini` to validate and initiate a return, as an example high-stakes decision, using a similar pattern to the above.
- Prompting models to follow a state machine, for example to accurately collect things like names and phone numbers with confirmation character by character to authenticate a user.
  - To test this flow, say that you&#039;d like to return your snowboard and go through the necessary prompts!

Configuration in [src/app/agentConfigs/customerServiceRetail/index.ts](src/app/agentConfigs/customerServiceRetail/index.ts).
```javascript
import authentication from &quot;./authentication&quot;;
import returns from &quot;./returns&quot;;
import sales from &quot;./sales&quot;;
import simulatedHuman from &quot;./simulatedHuman&quot;;
import { injectTransferTools } from &quot;../utils&quot;;

authentication.downstreamAgents = [returns, sales, simulatedHuman];
returns.downstreamAgents = [authentication, sales, simulatedHuman];
sales.downstreamAgents = [authentication, returns, simulatedHuman];
simulatedHuman.downstreamAgents = [authentication, returns, sales];

const agents = injectTransferTools([
  authentication,
  returns,
  sales,
  simulatedHuman,
]);

export default agents;
```

## Schematic

This diagram illustrates a more advanced interaction flow defined in `src/app/agentConfigs/customerServiceRetail/`, including detailed events.

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Show CustomerServiceRetail Flow Diagram&lt;/strong&gt;&lt;/summary&gt;

```mermaid
sequenceDiagram
    participant User
    participant WebClient as Next.js Client
    participant NextAPI as /api/session
    participant RealtimeAPI as OpenAI Realtime API
    participant AgentManager as Agents (authentication, returns, sales, simulatedHuman)
    participant o1mini as &quot;o4-mini&quot; (Escalation Model)

    Note over WebClient: User navigates to ?agentConfig=customerServiceRetail
    User-&gt;&gt;WebClient: Open Page
    WebClient-&gt;&gt;NextAPI: GET /api/session
    NextAPI-&gt;&gt;RealtimeAPI: POST /v1/realtime/sessions
    RealtimeAPI-&gt;&gt;NextAPI: Returns ephemeral session
    NextAPI-&gt;&gt;WebClient: Returns ephemeral token (JSON)

    Note right of WebClient: Start RTC handshake
    WebClient-&gt;&gt;RealtimeAPI: Offer SDP (WebRTC)
    RealtimeAPI-&gt;&gt;WebClient: SDP answer
    WebClient-&gt;&gt;WebClient: DataChannel &quot;oai-events&quot; established

    Note over AgentManager: Default agent is &quot;authentication&quot;
    User-&gt;&gt;WebClient: &quot;Hi, I&#039;d like to return my snowboard.&quot;
    WebClient-&gt;&gt;AgentManager: conversation.item.create (role=user)
    WebClient-&gt;&gt;RealtimeAPI: {type: &quot;conversation.item.create&quot;}
    WebClient-&gt;&gt;RealtimeAPI: {type: &quot;response.create&quot;}

    authentication-&gt;&gt;AgentManager: Requests user info, calls authenticate_user_information()
    AgentManager--&gt;&gt;WebClient: function_call =&gt; name=&quot;authenticate_user_information&quot;
    WebClient-&gt;&gt;WebClient: handleFunctionCall =&gt; verifies details

    Note over AgentManager: After user is authenticated
    authentication-&gt;&gt;AgentManager: transferAgents(&quot;returns&quot;)
    AgentManager--&gt;&gt;WebClient: function_call =&gt; name=&quot;transferAgents&quot; args={ destination: &quot;returns&quot; }
    WebClient-&gt;&gt;WebClient: setSelectedAgentName(&quot;returns&quot;)

    Note over returns: The user wants to process a return
    returns-&gt;&gt;AgentManager: function_call =&gt; checkEligibilityAndPossiblyInitiateReturn
    AgentManager--&gt;&gt;WebClient: function_call =&gt; name=&quot;checkEligibilityAndPossiblyInitiateReturn&quot;

    Note over WebClient: The WebClient calls /api/chat/completions with model=&quot;o4-mini&quot;
    WebClient-&gt;&gt;o1mini: &quot;Is this item eligible for return?&quot;
    o1mini-&gt;&gt;WebClient: &quot;Yes/No (plus notes)&quot;

    Note right of returns: Returns uses the result from &quot;o4-mini&quot;
    returns-&gt;&gt;AgentManager: &quot;Return is approved&quot; or &quot;Return is denied&quot;
    AgentManager-&gt;&gt;WebClient: conversation.item.create (assistant role)
    WebClient-&gt;&gt;User: Displays final verdict
```

&lt;/details&gt;

# Other Info
## Next Steps
- You can copy these templates to make your own multi-agent voice app! Once you make a new agent set config, add it to `src/app/agentConfigs/index.ts` and you should be able to select it in the UI in the &quot;Scenario&quot; dropdown menu.
- Each agentConfig can define instructions, tools, and toolLogic. By default all tool calls simply return `True`, unless you define the toolLogic, which will run your specific tool logic and return an object to the conversation (e.g. for retrieved RAG context).
- If you want help creating your own prompt using the conventions shown in customerServiceRetail, including defining a state machine, we&#039;ve included a metaprompt [here](src/app/agentConfigs/voiceAgentMetaprompt.txt), or you can use our [Voice Agent Metaprompter GPT](https://chatgpt.com/g/g-678865c9fb5c81918fa28699735dd08e-voice-agent-metaprompt-gpt)

## Output Guardrails
Assistant messages are checked for safety and compliance using a guardrail function before being finalized in the transcript. This is implemented in [`src/app/hooks/useHandleServerEvent.ts`](src/app/hooks/useHandleServerEvent.ts) as the `processGuardrail` function, which is invoked on each assistant message (after every 5 incremental words received) to run a moderation/classification check. You can review or customize this logic by editing the `processGuardrail` function definition and its invocation inside `useHandleServerEvent`.

## Navigating the UI
- You can select agent scenarios in the Scenario dropdown, and automatically switch to a specific agent with the Agent dropdown.
- The conversation transcript is on the left, including tool calls, tool call responses, and agent changes. Click to expand non-message elements.
- The event log is on the right, showing both client and server events. Click to see the full payload.
- On the bottom, you can disconnect, toggle between automated voice-activity detection or PTT, turn off audio playback, and toggle logs.

## Pull Requests

Feel free to open an issue or pull request and we&#039;ll do our best to review it. The spirit of this repo is to demonstrate the core logic for new agentic flows; PRs that go beyond this core scope will likely not be merged.

# Core Contributors
- Noah MacCallum - [noahmacca](https://x.com/noahmacca)
- Ilan Bigio - [ibigio](https://github.com/ibigio)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lobehub/lobe-chat]]></title>
            <link>https://github.com/lobehub/lobe-chat</link>
            <guid>https://github.com/lobehub/lobe-chat</guid>
            <pubDate>Thu, 29 May 2025 00:04:46 GMT</pubDate>
            <description><![CDATA[🤯 Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 4 / Gemini / Ollama / DeepSeek / Qwen), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Plugins/Artifacts) and Thinking. One-click FREE deployment of your private ChatGPT/ Claude / DeepSeek application.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lobehub/lobe-chat">lobehub/lobe-chat</a></h1>
            <p>🤯 Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 4 / Gemini / Ollama / DeepSeek / Qwen), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Plugins/Artifacts) and Thinking. One-click FREE deployment of your private ChatGPT/ Claude / DeepSeek application.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 61,889</p>
            <p>Forks: 12,889</p>
            <p>Stars today: 192 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![][image-banner]][vercel-link]

# Lobe Chat

An open-source, modern-design ChatGPT/LLMs UI/Framework.&lt;br/&gt;
Supports speech-synthesis, multi-modal, and extensible ([function call][docs-functionc-call]) plugin system.&lt;br/&gt;
One-click **FREE** deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.

**English** · [简体中文](./README.zh-CN.md) · [Official Site][official-site] · [Changelog][changelog] · [Documents][docs] · [Blog][blog] · [Feedback][github-issues-link]

&lt;!-- SHIELD GROUP --&gt;

[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][vercel-shield]][vercel-link]
[![][discord-shield]][discord-link]&lt;br/&gt;
[![][codecov-shield]][codecov-link]
[![][github-action-test-shield]][github-action-test-link]
[![][github-action-release-shield]][github-action-release-link]
[![][github-releasedate-shield]][github-releasedate-link]&lt;br/&gt;
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-license-shield]][github-license-link]&lt;br&gt;
[![][sponsor-shield]][sponsor-link]

**Share LobeChat Repository**

[![][share-x-shield]][share-x-link]
[![][share-telegram-shield]][share-telegram-link]
[![][share-whatsapp-shield]][share-whatsapp-link]
[![][share-reddit-shield]][share-reddit-link]
[![][share-weibo-shield]][share-weibo-link]
[![][share-mastodon-shield]][share-mastodon-link]
[![][share-linkedin-shield]][share-linkedin-link]

&lt;sup&gt;Pioneering the new age of thinking and creating. Built for you, the Super Individual.&lt;/sup&gt;

[![][github-trending-shield]][github-trending-url]

![][image-overview]

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt;

#### TOC

- [👋🏻 Getting Started &amp; Join Our Community](#-getting-started--join-our-community)
- [✨ Features](#-features)
  - [`1` Chain of Thought](#1-chain-of-thought)
  - [`2` Branching Conversations](#2-branching-conversations)
  - [`3` Artifacts Support](#3-artifacts-support)
  - [`4` File Upload /Knowledge Base](#4-file-upload-knowledge-base)
  - [`5` Multi-Model Service Provider Support](#5-multi-model-service-provider-support)
  - [`6` Local Large Language Model (LLM) Support](#6-local-large-language-model-llm-support)
  - [`7` Model Visual Recognition](#7-model-visual-recognition)
  - [`8` TTS &amp; STT Voice Conversation](#8-tts--stt-voice-conversation)
  - [`9` Text to Image Generation](#9-text-to-image-generation)
  - [`10` Plugin System (Function Calling)](#10-plugin-system-function-calling)
  - [`11` Agent Market (GPTs)](#11-agent-market-gpts)
  - [`12` Support Local / Remote Database](#12-support-local--remote-database)
  - [`13` Support Multi-User Management](#13-support-multi-user-management)
  - [`14` Progressive Web App (PWA)](#14-progressive-web-app-pwa)
  - [`15` Mobile Device Adaptation](#15-mobile-device-adaptation)
  - [`16` Custom Themes](#16-custom-themes)
  - [`*` What&#039;s more](#-whats-more)
- [⚡️ Performance](#️-performance)
- [🛳 Self Hosting](#-self-hosting)
  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)
  - [`B` Deploying with Docker](#b-deploying-with-docker)
  - [Environment Variable](#environment-variable)
- [📦 Ecosystem](#-ecosystem)
- [🧩 Plugins](#-plugins)
- [⌨️ Local Development](#️-local-development)
- [🤝 Contributing](#-contributing)
- [❤️ Sponsor](#️-sponsor)
- [🔗 More Products](#-more-products)

####

&lt;br/&gt;

&lt;/details&gt;

## 👋🏻 Getting Started &amp; Join Our Community

We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.
By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.

Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.

| [![][vercel-shield-badge]][vercel-link]   | No installation or registration necessary! Visit our website to experience it firsthand.                           |
| :---------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| [![][discord-shield-badge]][discord-link] | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub. |

&gt; \[!IMPORTANT]
&gt;
&gt; **Star Us**, You will receive all release notifications from GitHub without any delay \~ ⭐️

[![][image-star]][github-stars-link]

&lt;details&gt;
  &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;theme=dark&amp;type=Date&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;type=Date&quot;&gt;
  &lt;/picture&gt;
&lt;/details&gt;

## ✨ Features

[![][image-feat-cot]][docs-feat-cot]

### `1` [Chain of Thought][docs-feat-cot]

Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI&#039;s decision-making process, allowing you to observe how conclusions are reached in real-time.

By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI&#039;s problem-solving approach. Whether you&#039;re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.

[![][back-to-top]](#readme-top)

[![][image-feat-branch]][docs-feat-branch]

### `2` [Branching Conversations][docs-feat-branch]

Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.

Choose between two powerful modes:

- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context
- **Standalone Mode:** Start fresh with a new topic based on any previous message

This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.

[![][back-to-top]](#readme-top)

[![][image-feat-artifacts]][docs-feat-artifacts]

### `3` [Artifacts Support][docs-feat-artifacts]

Experience the power of Claude Artifacts, now integrated into LobeChat. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.

Create and visualize with unprecedented flexibility:

- Generate and display dynamic SVG graphics
- Build and render interactive HTML pages in real-time
- Produce professional documents in multiple formats

[![][back-to-top]](#readme-top)

[![][image-feat-knowledgebase]][docs-feat-knowledgebase]

### `4` [File Upload /Knowledge Base][docs-feat-knowledgebase]

LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.

&lt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&gt;

&gt; \[!TIP]
&gt;
&gt; Learn more on [📘 LobeChat Knowledge Base Launch — From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)

&lt;div align=&quot;right&quot;&gt;

[![][back-to-top]](#readme-top)

&lt;/div&gt;

[![][image-feat-privoder]][docs-feat-provider]

### `5` [Multi-Model Service Provider Support][docs-feat-provider]

In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.

In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.

#### Supported Model Service Providers

We have implemented support for the following model service providers:

&lt;!-- PROVIDER LIST --&gt;

- **[OpenAI](https://lobechat.com/discover/provider/openai)**: OpenAI is a global leader in artificial intelligence research, with models like the GPT series pushing the frontiers of natural language processing. OpenAI is committed to transforming multiple industries through innovative and efficient AI solutions. Their products demonstrate significant performance and cost-effectiveness, widely used in research, business, and innovative applications.
- **[Ollama](https://lobechat.com/discover/provider/ollama)**: Ollama provides models that cover a wide range of fields, including code generation, mathematical operations, multilingual processing, and conversational interaction, catering to diverse enterprise-level and localized deployment needs.
- **[Anthropic](https://lobechat.com/discover/provider/anthropic)**: Anthropic is a company focused on AI research and development, offering a range of advanced language models such as Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Opus, and Claude 3 Haiku. These models achieve an ideal balance between intelligence, speed, and cost, suitable for various applications from enterprise workloads to rapid-response scenarios. Claude 3.5 Sonnet, as their latest model, has excelled in multiple evaluations while maintaining a high cost-performance ratio.
- **[Bedrock](https://lobechat.com/discover/provider/bedrock)**: Bedrock is a service provided by Amazon AWS, focusing on delivering advanced AI language and visual models for enterprises. Its model family includes Anthropic&#039;s Claude series, Meta&#039;s Llama 3.1 series, and more, offering a range of options from lightweight to high-performance, supporting tasks such as text generation, conversation, and image processing for businesses of varying scales and needs.
- **[Google](https://lobechat.com/discover/provider/google)**: Google&#039;s Gemini series represents its most advanced, versatile AI models, developed by Google DeepMind, designed for multimodal capabilities, supporting seamless understanding and processing of text, code, images, audio, and video. Suitable for various environments from data centers to mobile devices, it significantly enhances the efficiency and applicability of AI models.
- **[DeepSeek](https://lobechat.com/discover/provider/deepseek)**: DeepSeek is a company focused on AI technology research and application, with its latest model DeepSeek-V2.5 integrating general dialogue and code processing capabilities, achieving significant improvements in human preference alignment, writing tasks, and instruction following.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[HuggingFace](https://lobechat.com/discover/provider/huggingface)**: The HuggingFace Inference API provides a fast and free way for you to explore thousands of models for various tasks. Whether you are prototyping for a new application or experimenting with the capabilities of machine learning, this API gives you instant access to high-performance models across multiple domains.
- **[OpenRouter](https://lobechat.com/discover/provider/openrouter)**: OpenRouter is a service platform providing access to various cutting-edge large model interfaces, supporting OpenAI, Anthropic, LLaMA, and more, suitable for diverse development and application needs. Users can flexibly choose the optimal model and pricing based on their requirements, enhancing the AI experience.
- **[Cloudflare Workers AI](https://lobechat.com/discover/provider/cloudflare)**: Run serverless GPU-powered machine learning models on Cloudflare&#039;s global network.

&lt;details&gt;&lt;summary&gt;&lt;kbd&gt;See more providers (+31)&lt;/kbd&gt;&lt;/summary&gt;

- **[GitHub](https://lobechat.com/discover/provider/github)**: With GitHub Models, developers can become AI engineers and leverage the industry&#039;s leading AI models.
- **[Novita](https://lobechat.com/discover/provider/novita)**: Novita AI is a platform providing a variety of large language models and AI image generation API services, flexible, reliable, and cost-effective. It supports the latest open-source models like Llama3 and Mistral, offering a comprehensive, user-friendly, and auto-scaling API solution for generative AI application development, suitable for the rapid growth of AI startups.
- **[PPIO](https://lobechat.com/discover/provider/ppio)**: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.
- **[Together AI](https://lobechat.com/discover/provider/togetherai)**: Together AI is dedicated to achieving leading performance through innovative AI models, offering extensive customization capabilities, including rapid scaling support and intuitive deployment processes to meet various enterprise needs.
- **[Fireworks AI](https://lobechat.com/discover/provider/fireworksai)**: Fireworks AI is a leading provider of advanced language model services, focusing on functional calling and multimodal processing. Its latest model, Firefunction V2, is based on Llama-3, optimized for function calling, conversation, and instruction following. The visual language model FireLLaVA-13B supports mixed input of images and text. Other notable models include the Llama series and Mixtral series, providing efficient multilingual instruction following and generation support.
- **[Groq](https://lobechat.com/discover/provider/groq)**: Groq&#039;s LPU inference engine has excelled in the latest independent large language model (LLM) benchmarks, redefining the standards for AI solutions with its remarkable speed and efficiency. Groq represents instant inference speed, demonstrating strong performance in cloud-based deployments.
- **[Perplexity](https://lobechat.com/discover/provider/perplexity)**: Perplexity is a leading provider of conversational generation models, offering various advanced Llama 3.1 models that support both online and offline applications, particularly suited for complex natural language processing tasks.
- **[Mistral](https://lobechat.com/discover/provider/mistral)**: Mistral provides advanced general, specialized, and research models widely used in complex reasoning, multilingual tasks, and code generation. Through functional calling interfaces, users can integrate custom functionalities for specific applications.
- **[Ai21Labs](https://lobechat.com/discover/provider/ai21)**: AI21 Labs builds foundational models and AI systems for enterprises, accelerating the application of generative AI in production.
- **[Upstage](https://lobechat.com/discover/provider/upstage)**: Upstage focuses on developing AI models for various business needs, including Solar LLM and document AI, aiming to achieve artificial general intelligence (AGI) for work. It allows for the creation of simple conversational agents through Chat API and supports functional calling, translation, embedding, and domain-specific applications.
- **[xAI](https://lobechat.com/discover/provider/xai)**: xAI is a company dedicated to building artificial intelligence to accelerate human scientific discovery. Our mission is to advance our collective understanding of the universe.
- **[Qwen](https://lobechat.com/discover/provider/qwen)**: Tongyi Qianwen is a large-scale language model independently developed by Alibaba Cloud, featuring strong natural language understanding and generation capabilities. It can answer various questions, create written content, express opinions, and write code, playing a role in multiple fields.
- **[Wenxin](https://lobechat.com/discover/provider/wenxin)**: An enterprise-level one-stop platform for large model and AI-native application development and services, providing the most comprehensive and user-friendly toolchain for the entire process of generative artificial intelligence model development and application development.
- **[Hunyuan](https://lobechat.com/discover/provider/hunyuan)**: A large language model developed by Tencent, equipped with powerful Chinese creative capabilities, logical reasoning abilities in complex contexts, and reliable task execution skills.
- **[ZhiPu](https://lobechat.com/discover/provider/zhipu)**: Zhipu AI offers an open platform for multimodal and language models, supporting a wide range of AI application scenarios, including text processing, image understanding, and programming assistance.
- **[SiliconCloud](https://lobechat.com/discover/provider/siliconcloud)**: SiliconFlow is dedicated to accelerating AGI for the benefit of humanity, enhancing large-scale AI efficiency through an easy-to-use and cost-effective GenAI stack.
- **[01.AI](https://lobechat.com/discover/provider/zeroone)**: 01.AI focuses on AI 2.0 era technologies, vigorously promoting the innovation and application of &#039;human + artificial intelligence&#039;, using powerful models and advanced AI technologies to enhance human productivity and achieve technological empowerment.
- **[Spark](https://lobechat.com/discover/provider/spark)**: iFlytek&#039;s Spark model provides powerful AI capabilities across multiple domains and languages, utilizing advanced natural language processing technology to build innovative applications suitable for smart hardware, smart healthcare, smart finance, and other vertical scenarios.
- **[SenseNova](https://lobechat.com/discover/provider/sensenova)**: SenseNova, backed by SenseTime&#039;s robust infrastructure, offers efficient and user-friendly full-stack large model services.
- **[Stepfun](https://lobechat.com/discover/provider/stepfun)**: StepFun&#039;s large model possesses industry-leading multimodal and complex reasoning capabilities, supporting ultra-long text understanding and powerful autonomous scheduling search engine functions.
- **[Moonshot](https://lobechat.com/discover/provider/moonshot)**: Moonshot is an open-source platform launched by Beijing Dark Side Technology Co., Ltd., providing various natural language processing models with a wide range of applications, including but not limited to content creation, academic research, intelligent recommendations, and medical diagnosis, supporting long text processing and complex generation tasks.
- **[Baichuan](https://lobechat.com/discover/provider/baichuan)**: Baichuan Intelligence is a company focused on the research and development of large AI models, with its models excelling in domestic knowledge encyclopedias, long text processing, and generative creation tasks in Chinese, surpassing mainstream foreign models. Baichuan Intelligence also possesses industry-leading multimodal capabilities, performing excellently in multiple authoritative evaluations. Its models include Baichuan 4, Baichuan 3 Turbo, and Baichuan 3 Turbo 128k, each optimized for different application scenarios, providing cost-effective solutions.
- **[Minimax](https://lobechat.com/discover/provider/minimax)**: MiniMax is a general artificial intelligence technology company established in 2021, dedicated to co-creating intelligence with users. MiniMax has independently developed general large models of different modalities, including trillion-parameter MoE text models, voice models, and image models, and has launched applications such as Conch AI.
- **[InternLM](https://lobechat.com/di

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[iib0011/omni-tools]]></title>
            <link>https://github.com/iib0011/omni-tools</link>
            <guid>https://github.com/iib0011/omni-tools</guid>
            <pubDate>Thu, 29 May 2025 00:04:45 GMT</pubDate>
            <description><![CDATA[Self-hosted collection of powerful web-based tools for everyday tasks. No ads, no tracking, just fast, accessible utilities right from your browser!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/iib0011/omni-tools">iib0011/omni-tools</a></h1>
            <p>Self-hosted collection of powerful web-based tools for everyday tasks. No ads, no tracking, just fast, accessible utilities right from your browser!</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,014</p>
            <p>Forks: 91</p>
            <p>Stars today: 27 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
        &lt;img src=&quot;src/assets/logo.png&quot; width=&quot;300&quot; /&gt;
        &lt;br /&gt;&lt;br /&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13055&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13055&quot; alt=&quot;iib0011%2Fomni-tools | Trendshift&quot; style=&quot;width: 200px;&quot; width=&quot;200&quot;/&gt;&lt;/a&gt;
   &lt;br /&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/iib0011/omni-tools/releases&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/badge/version-0.3.0-blue?style=for-the-badge&quot; /&gt;
        &lt;/a&gt;
        &lt;a href=&quot;https://hub.docker.com/r/iib0011/omni-tools&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/docker/pulls/iib0011/omni-tools?style=for-the-badge&amp;logo=docker&quot; /&gt;
        &lt;/a&gt;
        &lt;a href=&quot;https://github.com/iib0011&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/github/stars/iib0011/omni-tools?style=for-the-badge&amp;logo=github&quot; /&gt;
        &lt;/a&gt;
        &lt;a href=&quot;https://github.com/iib0011/omni-tools/blob/main/LICENSE&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/github/license/iib0011/omni-tools?style=for-the-badge&quot; /&gt;
        &lt;/a&gt;
        &lt;a href=&quot;https://discord.gg/SDbbn3hT4b&quot;&gt;
          &lt;img src=&quot;https://img.shields.io/discord/1342971141823664179?label=Discord&amp;style=for-the-badge&quot; /&gt;
        &lt;/a&gt;
        &lt;br /&gt;&lt;br /&gt;
&lt;/div&gt;

Welcome to OmniTools, a self-hosted web app offering a variety of online tools to simplify everyday tasks.
Whether you are coding, manipulating images/videos, PDFs or crunching numbers, OmniTools has you covered. Please don&#039;t
forget to
star the repo to support us.
Here is the [demo](https://omnitools.app) website.

![img.png](img.png)

## Table of Contents

- [Features](#features)
- [Self-host](#self-hostrun)
- [Contribute](#contribute)
- [License](#license)
- [Contact](#contact)

## Features

We strive to offer a variety of tools, including:

## **Image/Video/Binary Tools**

- Image Resizer
- Image Converter
- Video Trimmer
- Video Reverser
- And more...

## **String/List Tools**

- Case Converters
- List Shuffler
- Text Formatters
- And more...

## **Date and Time Tools**

- Date Calculators
- Time Zone Converters
- And more...

## **Math Tools**

- Generate Prime Numbers
- Generate Perfect Numbers
- And more...

## **Miscellaneous Tools**

- JSON Tools
- PDF Tools
- CSV Tools
- And more...

Stay tuned as we continue to expand and improve our collection!

## Self-host/Run

### Docker

```bash
docker run -d --name omni-tools --restart unless-stopped -p 8080:80 iib0011/omni-tools:latest
```

### Docker Compose

```yaml
services:
  omni-tools:
    image: iib0011/omni-tools:latest
    container_name: omni-tools
    restart: unless-stopped
    ports:
      - &quot;8080:80&quot;

```

## Contribute

This is a React Project with Typescript Material UI. We use icons from [Iconify](https://icon-sets.iconify.design)

### Project setup

```bash
git clone https://github.com/iib0011/omni-tools.git
cd omni-tools
npm i
npm run dev
```

### Create a new tool

```bash
npm run script:create:tool my-tool-name folder1 # npm run script:create:tool split pdf
```

For tools located under multiple nested directories, use:

```bash
npm run script:create:tool my-tool-name folder1/folder2 # npm run script:create:tool compress image/png
```

Use `folder1\folder2` on Windows.

### Run tests

```bash
npm run test
```

- For e2e tests

```bash
npm run test:e2e
```

&lt;img src=&quot;https://api.star-history.com/svg?repos=iib0011/omni-tools&amp;type=Date&quot;/&gt;

## 🤝 Looking to contribute?

We welcome contributions! You can help by:

- ✅ Reporting bugs
- ✅ Suggesting new features in Github issues or [here](https://tally.so/r/nrkkx2)
- ✅ Improving documentation
- ✅ Submitting pull requests

You can also join our [Discord server](https://discord.gg/SDbbn3hT4b)

### Contributors

&lt;a href=&quot;https://github.com/iib0011/omni-tools/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=iib0011/omni-tools&quot; /&gt;
&lt;/a&gt;

## Contact

For any questions or suggestions, feel free to open an issue or contact me at:
[ibracool99@gmail.com](mailto:ibracool99@gmail.com)

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[groupultra/telegram-search]]></title>
            <link>https://github.com/groupultra/telegram-search</link>
            <guid>https://github.com/groupultra/telegram-search</guid>
            <pubDate>Thu, 29 May 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[🔍 A powerful Telegram chat history search client that supports chat history backup and vector search.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/groupultra/telegram-search">groupultra/telegram-search</a></h1>
            <p>🔍 A powerful Telegram chat history search client that supports chat history backup and vector search.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 2,022</p>
            <p>Forks: 138</p>
            <p>Stars today: 133 stars today</p>
            <h2>README</h2><pre># Telegram Search

[English](./README_EN.md) | [快速开始](./getting-started.md)

[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;logo=telegram&amp;logoColor=white)](https://t.me/+Gs3SH2qAPeFhYmU9)
[![Discord](https://dcbadge.limes.pink/api/server/NzYsmJSgCT)](https://discord.gg/NzYsmJSgCT)

&lt;a href=&quot;https://trendshift.io/repositories/13868&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13868&quot; alt=&quot;groupultra%2Ftelegram-search | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

一个功能强大的 Telegram 聊天记录搜索工具，支持向量搜索和语义匹配。基于 OpenAI 的语义向量技术，让你的 Telegram 消息检索更智能、更精准。

- 欢迎 PR 贡献！
- 由于项目处于快速迭代阶段，可能会出现数据库不兼容的情况，建议定期备份数据。

![preview](./docs/assets/preview.png)

## 💖 赞助者

![Sponsors](https://github.com/luoling8192/luoling8192/raw/master/sponsorkit/sponsors.svg)

## 🚀 快速开始

### 安装步骤

1. 克隆仓库：

```bash
git clone https://github.com/GramSearch/telegram-search.git
cd telegram-search
```

2. 安装依赖：

```bash
pnpm install
```

3. 配置环境：

```bash
cp config/config.example.yaml config/config.yaml
```

4. 启动数据库容器：

```bash
docker compose up -d
```

5. 同步数据库表结构：

```bash
pnpm run db:migrate
```

6. 启动服务：

```bash
# 启动后端服务
pnpm run dev:server

# 启动前端界面
pnpm run dev:frontend
```

访问 `http://localhost:3333` 即可打开搜索界面。

## 🚀 Activity

[![Star History Chart](https://api.star-history.com/svg?repos=luoling8192/telegram-search&amp;type=Date)](https://star-history.com/#luoling8192/telegram-search&amp;Date)

![Alt](https://repobeats.axiom.co/api/embed/c0fe5f057a33ce830a632c6ae421433f50e9083f.svg &quot;Repobeats analytics image&quot;)

## 📝 License

MIT License © 2025
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[reduxjs/redux]]></title>
            <link>https://github.com/reduxjs/redux</link>
            <guid>https://github.com/reduxjs/redux</guid>
            <pubDate>Thu, 29 May 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[A JS library for predictable global state management]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/reduxjs/redux">reduxjs/redux</a></h1>
            <p>A JS library for predictable global state management</p>
            <p>Language: TypeScript</p>
            <p>Stars: 61,209</p>
            <p>Forks: 15,232</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># &lt;a href=&#039;https://redux.js.org&#039;&gt;&lt;img src=&#039;https://avatars.githubusercontent.com/u/13142323?s=200&amp;v=4&#039; height=&#039;60&#039; alt=&#039;Redux Logo&#039; aria-label=&#039;redux.js.org&#039; style=&quot;display: flex;align-items: center;&quot;/&gt;Redux&lt;/a&gt;

Redux is a JS library for predictable and maintainable global state management.

It helps you write applications that behave consistently, run in different environments (client, server, and native), and are easy to test. On top of that, it provides a great developer experience, such as [live code editing combined with a time traveling debugger](https://github.com/reduxjs/redux-devtools).

You can use Redux together with [React](https://react.dev), or with any other view library. The Redux core is tiny (2kB, including dependencies), and has a rich ecosystem of addons.

[**Redux Toolkit**](https://redux-toolkit.js.org) is our official recommended approach for writing Redux logic. It wraps around the Redux core, and contains packages and functions that we think are essential for building a Redux app. Redux Toolkit builds in our suggested best practices, simplifies most Redux tasks, prevents common mistakes, and makes it easier to write Redux applications.

![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/reduxjs/redux/test.yaml?branch=master&amp;event=push&amp;style=flat-square)
[![npm version](https://img.shields.io/npm/v/redux.svg?style=flat-square)](https://www.npmjs.com/package/redux)
[![npm downloads](https://img.shields.io/npm/dm/redux.svg?style=flat-square)](https://www.npmjs.com/package/redux)
[![redux channel on discord](https://img.shields.io/badge/discord-%23redux%20%40%20reactiflux-61dafb.svg?style=flat-square)](https://discord.gg/0ZcbPKXt5bZ6au5t)

## Installation

### Create a React Redux App

The recommended way to start new apps with React and Redux Toolkit is by using [our official Redux Toolkit + TS template for Vite](https://github.com/reduxjs/redux-templates), or by creating a new Next.js project using [Next&#039;s `with-redux` template](https://github.com/vercel/next.js/tree/canary/examples/with-redux).

Both of these already have Redux Toolkit and React-Redux configured appropriately for that build tool, and come with a small example app that demonstrates how to use several of Redux Toolkit&#039;s features.

```bash
# Vite with our Redux+TS template
# (using the `degit` tool to clone and extract the template)
npx degit reduxjs/redux-templates/packages/vite-template-redux my-app

# Next.js using the `with-redux` template
npx create-next-app --example with-redux my-app
```

We do not currently have official React Native templates, but recommend these templates for standard React Native and for Expo:

- https://github.com/rahsheen/react-native-template-redux-typescript
- https://github.com/rahsheen/expo-template-redux-typescript

```
npm install @reduxjs/toolkit react-redux
```

For the Redux core library by itself:

```
npm install redux
```

For more details, see [the Installation docs page](https://redux.js.org/introduction/installation).

## Documentation

The Redux core docs are located at **https://redux.js.org**, and include the full Redux tutorials, as well usage guides on general Redux patterns:

- [Introduction](https://redux.js.org/introduction/getting-started)
- [Tutorials](https://redux.js.org/tutorials/index)
- [Usage Guides](https://redux.js.org/usage/index)
- [FAQ](https://redux.js.org/faq)
- [API Reference](https://redux.js.org/api/api-reference)

The Redux Toolkit docs are available at **https://redux-toolkit.js.org**, including API references and usage guides for all of the APIs included in Redux Toolkit.

## Learn Redux

### Redux Essentials Tutorial

The [**Redux Essentials tutorial**](https://redux.js.org/tutorials/essentials/part-1-overview-concepts) is a &quot;top-down&quot; tutorial that teaches &quot;how to use Redux the right way&quot;, using our latest recommended APIs and best practices. We recommend starting there.

### Redux Fundamentals Tutorial

The [**Redux Fundamentals tutorial**](https://redux.js.org/tutorials/fundamentals/part-1-overview) is a &quot;bottom-up&quot; tutorial that teaches &quot;how Redux works&quot; from first principles and without any abstractions, and why standard Redux usage patterns exist.

### Help and Discussion

The **[#redux channel](https://discord.gg/0ZcbPKXt5bZ6au5t)** of the **[Reactiflux Discord community](https://www.reactiflux.com)** is our official resource for all questions related to learning and using Redux. Reactiflux is a great place to hang out, ask questions, and learn - please come and join us there!

## Before Proceeding Further

Redux is a valuable tool for organizing your state, but you should also consider whether it&#039;s appropriate for your situation. Please don&#039;t use Redux just because someone said you should - instead, please take some time to understand the potential benefits and tradeoffs of using it.

Here are some suggestions on when it makes sense to use Redux:

- You have reasonable amounts of data changing over time
- You need a single source of truth for your state
- You find that keeping all your state in a top-level component is no longer sufficient

Yes, these guidelines are subjective and vague, but this is for a good reason. The point at which you should integrate Redux into your application is different for every user and different for every application.

&gt; **For more thoughts on how Redux is meant to be used, please see:**&lt;br&gt;
&gt;
&gt; - **[When (and when not) to reach for Redux](https://changelog.com/posts/when-and-when-not-to-reach-for-redux)**
&gt; - **[You Might Not Need Redux](https://medium.com/@dan_abramov/you-might-not-need-redux-be46360cf367)**&lt;br&gt;
&gt; - **[The Tao of Redux, Part 1 - Implementation and Intent](https://blog.isquaredsoftware.com/2017/05/idiomatic-redux-tao-of-redux-part-1/)**&lt;br&gt;
&gt; - **[The Tao of Redux, Part 2 - Practice and Philosophy](https://blog.isquaredsoftware.com/2017/05/idiomatic-redux-tao-of-redux-part-2/)**
&gt; - **[Redux FAQ](https://redux.js.org/faq)**

## Basic Example

The whole global state of your app is stored in an object tree inside a single _store_.
The only way to change the state tree is to create an _action_, an object describing what happened, and _dispatch_ it to the store.
To specify how state gets updated in response to an action, you write pure _reducer_ functions that calculate a new state based on the old state and the action.

Redux Toolkit simplifies the process of writing Redux logic and setting up the store. With Redux Toolkit, the basic app logic looks like:

```js
import { createSlice, configureStore } from &#039;@reduxjs/toolkit&#039;

const counterSlice = createSlice({
  name: &#039;counter&#039;,
  initialState: {
    value: 0
  },
  reducers: {
    incremented: state =&gt; {
      // Redux Toolkit allows us to write &quot;mutating&quot; logic in reducers. It
      // doesn&#039;t actually mutate the state because it uses the Immer library,
      // which detects changes to a &quot;draft state&quot; and produces a brand new
      // immutable state based off those changes
      state.value += 1
    },
    decremented: state =&gt; {
      state.value -= 1
    }
  }
})

export const { incremented, decremented } = counterSlice.actions

const store = configureStore({
  reducer: counterSlice.reducer
})

// Can still subscribe to the store
store.subscribe(() =&gt; console.log(store.getState()))

// Still pass action objects to `dispatch`, but they&#039;re created for us
store.dispatch(incremented())
// {value: 1}
store.dispatch(incremented())
// {value: 2}
store.dispatch(decremented())
// {value: 1}
```

Redux Toolkit allows us to write shorter logic that&#039;s easier to read, while still following the original core Redux behavior and data flow.

## Logo

You can find the official logo [on GitHub](https://github.com/reduxjs/redux/tree/master/logo).

## Change Log

This project adheres to [Semantic Versioning](https://semver.org/).
Every release, along with the migration instructions, is documented on the GitHub [Releases](https://github.com/reduxjs/redux/releases) page.

## License

[MIT](LICENSE.md)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[shadcn-ui/ui]]></title>
            <link>https://github.com/shadcn-ui/ui</link>
            <guid>https://github.com/shadcn-ui/ui</guid>
            <pubDate>Thu, 29 May 2025 00:04:42 GMT</pubDate>
            <description><![CDATA[A set of beautifully-designed, accessible components and a code distribution platform. Works with your favorite frameworks. Open Source. Open Code.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/shadcn-ui/ui">shadcn-ui/ui</a></h1>
            <p>A set of beautifully-designed, accessible components and a code distribution platform. Works with your favorite frameworks. Open Source. Open Code.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 87,618</p>
            <p>Forks: 5,978</p>
            <p>Stars today: 68 stars today</p>
            <h2>README</h2><pre># shadcn/ui

Accessible and customizable components that you can copy and paste into your apps. Free. Open Source. **Use this to build your own component library**.

![hero](apps/www/public/og.jpg)

## Documentation

Visit http://ui.shadcn.com/docs to view the documentation.

## Contributing

Please read the [contributing guide](/CONTRIBUTING.md).

## License

Licensed under the [MIT license](https://github.com/shadcn/ui/blob/main/LICENSE.md).
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[benborla/mcp-server-mysql]]></title>
            <link>https://github.com/benborla/mcp-server-mysql</link>
            <guid>https://github.com/benborla/mcp-server-mysql</guid>
            <pubDate>Thu, 29 May 2025 00:04:41 GMT</pubDate>
            <description><![CDATA[A Model Context Protocol server that provides read-only access to MySQL databases. This server enables LLMs to inspect database schemas and execute read-only queries.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/benborla/mcp-server-mysql">benborla/mcp-server-mysql</a></h1>
            <p>A Model Context Protocol server that provides read-only access to MySQL databases. This server enables LLMs to inspect database schemas and execute read-only queries.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 417</p>
            <p>Forks: 61</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>
# MCP Server for MySQL based on NodeJS
[![smithery badge](https://smithery.ai/badge/@benborla29/mcp-server-mysql)](https://smithery.ai/server/@benborla29/mcp-server-mysql)

![Demo](assets/demo.gif)

A Model Context Protocol server that provides access to MySQL databases. This server enables LLMs to inspect database schemas and execute SQL queries.

## Table of Contents
- [Requirements](#requirements)
- [Installation](#installation)
  - [Smithery](#using-smithery)
  - [Clone to Local Repository](#running-from-local-repository)
- [Components](#components)
- [Configuration](#configuration)
- [Environment Variables](#environment-variables)
- [Multi-DB Mode](#multi-db-mode)
- [Schema-Specific Permissions](#schema-specific-permissions)
- [Testing](#testing)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [License](#license)

## Requirements

- Node.js v18 or higher
- MySQL 5.7 or higher (MySQL 8.0+ recommended)
- MySQL user with appropriate permissions for the operations you need
- For write operations: MySQL user with INSERT, UPDATE, and/or DELETE privileges

## Installation

There are several ways to install and configure the MCP server but the most common would be checking this website https://smithery.ai/server/@benborla29/mcp-server-mysql

### Cursor

For Cursor IDE, you can install this MCP server with the following command in your project:

1. Visit https://smithery.ai/server/@benborla29/mcp-server-mysql
2. Follow the instruction for Cursor


MCP Get provides a centralized registry of MCP servers and simplifies the installation process.

### Using NPM/PNPM

For manual installation:

```bash
# Using npm
npm install -g @benborla29/mcp-server-mysql

# Using pnpm
pnpm add -g @benborla29/mcp-server-mysql
```

After manual installation, you&#039;ll need to configure your LLM application to use the MCP server (see Configuration section below).

### Running from Local Repository

If you want to clone and run this MCP server directly from the source code, follow these steps:

1. **Clone the repository**
   ```bash
   git clone https://github.com/benborla/mcp-server-mysql.git
   cd mcp-server-mysql
   ```

2. **Install dependencies**
   ```bash
   npm install
   # or
   pnpm install
   ```

3. **Build the project**
   ```bash
   npm run build
   # or
   pnpm run build
   ```

4. **Configure Claude Desktop**

   Add the following to your Claude Desktop configuration file (`claude_desktop_config.json`):

   ```json
   {
     &quot;mcpServers&quot;: {
       &quot;mcp_server_mysql&quot;: {
         &quot;command&quot;: &quot;/path/to/node&quot;,
         &quot;args&quot;: [
           &quot;/full/path/to/mcp-server-mysql/dist/index.js&quot;
         ],
         &quot;env&quot;: {
           &quot;MYSQL_HOST&quot;: &quot;127.0.0.1&quot;,
           &quot;MYSQL_PORT&quot;: &quot;3306&quot;,
           &quot;MYSQL_USER&quot;: &quot;root&quot;,
           &quot;MYSQL_PASS&quot;: &quot;your_password&quot;,
           &quot;MYSQL_DB&quot;: &quot;your_database&quot;,
           &quot;ALLOW_INSERT_OPERATION&quot;: &quot;false&quot;,
           &quot;ALLOW_UPDATE_OPERATION&quot;: &quot;false&quot;,
           &quot;ALLOW_DELETE_OPERATION&quot;: &quot;false&quot;,
           &quot;PATH&quot;: &quot;/Users/atlasborla/Library/Application Support/Herd/config/nvm/versions/node/v22.9.0/bin:/usr/bin:/bin&quot;, // &lt;--- Important to add the following, run in your terminal `echo &quot;$(which node)/../&quot;` to get the path
           &quot;NODE_PATH&quot;: &quot;/Users/atlasborla/Library/Application Support/Herd/config/nvm/versions/node/v22.9.0/lib/node_modules&quot; // &lt;--- Important to add the following, run in your terminal `echo &quot;$(which node)/../../lib/node_modules&quot;`
         }
       }
     }
   }
   ```

   Replace:
   - `/path/to/node` with the full path to your Node.js binary (find it with `which node`)
   - `/full/path/to/mcp-server-mysql` with the full path to where you cloned the repository
   - Set the MySQL credentials to match your environment

5. **Test the server**
   ```bash
   # Run the server directly to test
   node dist/index.js
   ```

   If it connects to MySQL successfully, you&#039;re ready to use it with Claude Desktop.

## Components

### Tools

- **mysql_query**
  - Execute SQL queries against the connected database
  - Input: `sql` (string): The SQL query to execute
  - By default, limited to READ ONLY operations
  - Optional write operations (when enabled via configuration):
    - INSERT: Add new data to tables (requires `ALLOW_INSERT_OPERATION=true`)
    - UPDATE: Modify existing data (requires `ALLOW_UPDATE_OPERATION=true`)
    - DELETE: Remove data (requires `ALLOW_DELETE_OPERATION=true`)
  - All operations are executed within a transaction with proper commit/rollback handling
  - Supports prepared statements for secure parameter handling
  - Configurable query timeouts and result pagination
  - Built-in query execution statistics

### Resources

The server provides comprehensive database information:

- **Table Schemas**
  - JSON schema information for each table
  - Column names and data types
  - Index information and constraints
  - Foreign key relationships
  - Table statistics and metrics
  - Automatically discovered from database metadata

### Security Features

- SQL injection prevention through prepared statements
- Query whitelisting/blacklisting capabilities
- Rate limiting for query execution
- Query complexity analysis
- Configurable connection encryption
- Read-only transaction enforcement

### Performance Optimizations

- Optimized connection pooling
- Query result caching
- Large result set streaming
- Query execution plan analysis
- Configurable query timeouts

### Monitoring and Debugging

- Comprehensive query logging
- Performance metrics collection
- Error tracking and reporting
- Health check endpoints
- Query execution statistics

## Configuration

### Automatic Configuration with Smithery
If you installed using Smithery, your configuration is already set up. You can view or modify it with:

```bash
smithery configure @benborla29/mcp-server-mysql
```

When reconfiguring, you can update any of the MySQL connection details as well as the write operation settings:

- **Basic connection settings**:
  - MySQL Host, Port, User, Password, Database
  - SSL/TLS configuration (if your database requires secure connections)

- **Write operation permissions**:
  - Allow INSERT Operations: Set to true if you want to allow adding new data
  - Allow UPDATE Operations: Set to true if you want to allow updating existing data
  - Allow DELETE Operations: Set to true if you want to allow deleting data

For security reasons, all write operations are disabled by default. Only enable these settings if you specifically need Claude to modify your database data.

### Advanced Configuration Options
For more control over the MCP server&#039;s behavior, you can use these advanced configuration options:

```json
{
  &quot;mcpServers&quot;: {
    &quot;mcp_server_mysql&quot;: {
      &quot;command&quot;: &quot;/path/to/npx/binary/npx&quot;,
      &quot;args&quot;: [
        &quot;-y&quot;,
        &quot;@benborla29/mcp-server-mysql&quot;
      ],
      &quot;env&quot;: {
        // Basic connection settings
        &quot;MYSQL_HOST&quot;: &quot;127.0.0.1&quot;,
        &quot;MYSQL_PORT&quot;: &quot;3306&quot;,
        &quot;MYSQL_USER&quot;: &quot;root&quot;,
        &quot;MYSQL_PASS&quot;: &quot;&quot;,
        &quot;MYSQL_DB&quot;: &quot;db_name&quot;,
        &quot;PATH&quot;: &quot;/path/to/node/bin:/usr/bin:/bin&quot;,
        
        // Performance settings
        &quot;MYSQL_POOL_SIZE&quot;: &quot;10&quot;,
        &quot;MYSQL_QUERY_TIMEOUT&quot;: &quot;30000&quot;,
        &quot;MYSQL_CACHE_TTL&quot;: &quot;60000&quot;,
        
        // Security settings
        &quot;MYSQL_RATE_LIMIT&quot;: &quot;100&quot;,
        &quot;MYSQL_MAX_QUERY_COMPLEXITY&quot;: &quot;1000&quot;,
        &quot;MYSQL_SSL&quot;: &quot;true&quot;,
        
        // Monitoring settings
        &quot;ENABLE_LOGGING&quot;: &quot;true&quot;,
        &quot;MYSQL_LOG_LEVEL&quot;: &quot;info&quot;,
        &quot;MYSQL_METRICS_ENABLED&quot;: &quot;true&quot;,
        
        // Write operation flags
        &quot;ALLOW_INSERT_OPERATION&quot;: &quot;false&quot;,
        &quot;ALLOW_UPDATE_OPERATION&quot;: &quot;false&quot;,
        &quot;ALLOW_DELETE_OPERATION&quot;: &quot;false&quot;
      }
    }
  }
}
```

## Environment Variables

### Basic Connection
- `MYSQL_SOCKET_PATH`: Unix socket path for local connections (e.g., &quot;/tmp/mysql.sock&quot;)
- `MYSQL_HOST`: MySQL server host (default: &quot;127.0.0.1&quot;) - ignored if MYSQL_SOCKET_PATH is set
- `MYSQL_PORT`: MySQL server port (default: &quot;3306&quot;) - ignored if MYSQL_SOCKET_PATH is set
- `MYSQL_USER`: MySQL username (default: &quot;root&quot;)
- `MYSQL_PASS`: MySQL password
- `MYSQL_DB`: Target database name (leave empty for multi-DB mode)

### Performance Configuration
- `MYSQL_POOL_SIZE`: Connection pool size (default: &quot;10&quot;)
- `MYSQL_QUERY_TIMEOUT`: Query timeout in milliseconds (default: &quot;30000&quot;)
- `MYSQL_CACHE_TTL`: Cache time-to-live in milliseconds (default: &quot;60000&quot;)

### Security Configuration
- `MYSQL_RATE_LIMIT`: Maximum queries per minute (default: &quot;100&quot;)
- `MYSQL_MAX_QUERY_COMPLEXITY`: Maximum query complexity score (default: &quot;1000&quot;)
- `MYSQL_SSL`: Enable SSL/TLS encryption (default: &quot;false&quot;)
- `ALLOW_INSERT_OPERATION`: Enable INSERT operations (default: &quot;false&quot;)
- `ALLOW_UPDATE_OPERATION`: Enable UPDATE operations (default: &quot;false&quot;)
- `ALLOW_DELETE_OPERATION`: Enable DELETE operations (default: &quot;false&quot;)
- `ALLOW_DDL_OPERATION`: Enable DDL operations (default: &quot;false&quot;)
- `SCHEMA_INSERT_PERMISSIONS`: Schema-specific INSERT permissions
- `SCHEMA_UPDATE_PERMISSIONS`: Schema-specific UPDATE permissions
- `SCHEMA_DELETE_PERMISSIONS`: Schema-specific DELETE permissions
- `SCHEMA_DDL_PERMISSIONS`: Schema-specific DDL permissions
- `MULTI_DB_WRITE_MODE`: Enable write operations in multi-DB mode (default: &quot;false&quot;)

### Monitoring Configuration
- `MYSQL_ENABLE_LOGGING`: Enable query logging (default: &quot;false&quot;)
- `MYSQL_LOG_LEVEL`: Logging level (default: &quot;info&quot;)
- `MYSQL_METRICS_ENABLED`: Enable performance metrics (default: &quot;false&quot;)

## Multi-DB Mode

MCP-Server-MySQL supports connecting to multiple databases when no specific database is set. This allows the LLM to query any database the MySQL user has access to. For full details, see [README-MULTI-DB.md](./README-MULTI-DB.md).

### Enabling Multi-DB Mode

To enable multi-DB mode, simply leave the `MYSQL_DB` environment variable empty. In multi-DB mode, queries require schema qualification:

```sql
-- Use fully qualified table names
SELECT * FROM database_name.table_name;

-- Or use USE statements to switch between databases
USE database_name;
SELECT * FROM table_name;
```

## Schema-Specific Permissions

For fine-grained control over database operations, MCP-Server-MySQL now supports schema-specific permissions. This allows different databases to have different levels of access (read-only, read-write, etc.).

### Configuration Example

```
SCHEMA_INSERT_PERMISSIONS=development:true,test:true,production:false
SCHEMA_UPDATE_PERMISSIONS=development:true,test:true,production:false
SCHEMA_DELETE_PERMISSIONS=development:false,test:true,production:false
SCHEMA_DDL_PERMISSIONS=development:false,test:true,production:false
```

For complete details and security recommendations, see [README-MULTI-DB.md](./README-MULTI-DB.md).

## Testing

### Database Setup

Before running tests, you need to set up the test database and seed it with test data:

1. **Create Test Database and User**
   ```sql
   -- Connect as root and create test database
   CREATE DATABASE IF NOT EXISTS mcp_test;
   
   -- Create test user with appropriate permissions
   CREATE USER IF NOT EXISTS &#039;mcp_test&#039;@&#039;localhost&#039; IDENTIFIED BY &#039;mcp_test_password&#039;;
   GRANT ALL PRIVILEGES ON mcp_test.* TO &#039;mcp_test&#039;@&#039;localhost&#039;;
   FLUSH PRIVILEGES;
   ```

2. **Run Database Setup Script**
   ```bash
   # Run the database setup script
   pnpm run setup:test:db
   ```

   This will create the necessary tables and seed data. The script is located in `scripts/setup-test-db.ts`

3. **Configure Test Environment**
   Create a `.env.test` file in the project root (if not existing):
   ```env
   MYSQL_HOST=127.0.0.1
   MYSQL_PORT=3306
   MYSQL_USER=mcp_test
   MYSQL_PASS=mcp_test_password
   MYSQL_DB=mcp_test
   ```

4. **Update package.json Scripts**
   Add these scripts to your package.json:
   ```json
   {
     &quot;scripts&quot;: {
       &quot;setup:test:db&quot;: &quot;ts-node scripts/setup-test-db.ts&quot;,
       &quot;pretest&quot;: &quot;pnpm run setup:test:db&quot;,
       &quot;test&quot;: &quot;vitest run&quot;,
       &quot;test:watch&quot;: &quot;vitest&quot;,
       &quot;test:coverage&quot;: &quot;vitest run --coverage&quot;
     }
   }
   ```

### Running Tests

The project includes a comprehensive test suite to ensure functionality and reliability:

```bash
# First-time setup
pnpm run setup:test:db

# Run all tests
pnpm test
```



## Running evals

The evals package loads an mcp client that then runs the index.ts file, so there is no need to rebuild between tests. You can load environment variables by prefixing the npx command. Full documentation can be found [here](https://www.mcpevals.io/docs).

```bash
OPENAI_API_KEY=your-key  npx mcp-eval evals.ts index.ts
```
## Troubleshooting

### Common Issues

1. **Connection Issues**
   - Verify MySQL server is running and accessible
   - Check credentials and permissions
   - Ensure SSL/TLS configuration is correct if enabled
   - Try connecting with a MySQL client to confirm access

2. **Performance Issues**
   - Adjust connection pool size
   - Configure query timeout values
   - Enable query caching if needed
   - Check query complexity settings
   - Monitor server resource usage

3. **Security Restrictions**
   - Review rate limiting configuration
   - Check query whitelist/blacklist settings
   - Verify SSL/TLS settings
   - Ensure the user has appropriate MySQL permissions

4. **Path Resolution**
If you encounter an error &quot;Could not connect to MCP server mcp-server-mysql&quot;, explicitly set the path of all required binaries:
```json
{
  &quot;env&quot;: {
    &quot;PATH&quot;: &quot;/path/to/node/bin:/usr/bin:/bin&quot;
  }
}
```

*Where can I find my `node` bin path*
Run the following command to get it:

For **PATH**
```bash
echo &quot;$(which node)/../&quot;    
```

For **NODE_PATH**
```bash
echo &quot;$(which node)/../../lib/node_modules&quot;    
```

5. **Claude Desktop Specific Issues**
   - If you see &quot;Server disconnected&quot; logs in Claude Desktop, check the logs at `~/Library/Logs/Claude/mcp-server-mcp_server_mysql.log`
   - Ensure you&#039;re using the absolute path to both the Node binary and the server script
   - Check if your `.env` file is being properly loaded; use explicit environment variables in the configuration
   - Try running the server directly from the command line to see if there are connection issues
   - If you need write operations (INSERT, UPDATE, DELETE), set the appropriate flags to &quot;true&quot; in your configuration:
     ```json
     &quot;env&quot;: {
       &quot;ALLOW_INSERT_OPERATION&quot;: &quot;true&quot;,  // Enable INSERT operations
       &quot;ALLOW_UPDATE_OPERATION&quot;: &quot;true&quot;,  // Enable UPDATE operations
       &quot;ALLOW_DELETE_OPERATION&quot;: &quot;true&quot;   // Enable DELETE operations
     }
     ```
   - Ensure your MySQL user has the appropriate permissions for the operations you&#039;re enabling
   - For direct execution configuration, use:
     ```json
     {
       &quot;mcpServers&quot;: {
         &quot;mcp_server_mysql&quot;: {
           &quot;command&quot;: &quot;/full/path/to/node&quot;,
           &quot;args&quot;: [
             &quot;/full/path/to/mcp-server-mysql/dist/index.js&quot;
           ],
           &quot;env&quot;: {
             &quot;MYSQL_HOST&quot;: &quot;127.0.0.1&quot;,
             &quot;MYSQL_PORT&quot;: &quot;3306&quot;,
             &quot;MYSQL_USER&quot;: &quot;root&quot;,
             &quot;MYSQL_PASS&quot;: &quot;your_password&quot;,
             &quot;MYSQL_DB&quot;: &quot;your_database&quot;
           }
         }
       }
     }
     ```

6. **Authentication Issues**
   - For MySQL 8.0+, ensure the server supports the `caching_sha2_password` authentication plugin
   - Check if your MySQL user is configured with the correct authentication method
   - Try creating a user with legacy authentication if needed:
     ```sql
     CREATE USER &#039;user&#039;@&#039;localhost&#039; IDENTIFIED WITH mysql_native_password BY &#039;password&#039;;
     ```
     @lizhuangs

7. I am encountering `Error [ERR_MODULE_NOT_FOUND]: Cannot find package &#039;dotenv&#039; imported from` error
try this workaround:
```bash
npx -y -p @benborla29/mcp-server-mysql -p dotenv mcp-server-mysql
```
Thanks to @lizhuangs

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request to 
https://github.com/benborla/mcp-server-mysql

## Many Thanks to the following Contributors:
&lt;a href = &quot;https://github.com/benborla/mcp-server-mysql/graphs/contributors&quot;&gt;
  &lt;img src = &quot;https://contrib.rocks/image?repo=benborla/mcp-server-mysql&quot;/&gt;
&lt;/a&gt;

### Development Setup

1. Clone the repository
2. Install dependencies: `pnpm install`
3. Build the project: `pnpm run build`
4. Run tests: `pnpm test`

### Project Roadmap

We&#039;re actively working on enhancing this MCP server. Check our [CHANGELOG.md](./CHANGELOG.md) for details on planned features, including:

- Enhanced query capabilities with prepared statements
- Advanced security features
- Performance optimizations
- Comprehensive monitoring
- Expanded schema information

If you&#039;d like to contribute to any of these areas, please check the issues on GitHub or open a new one to discuss your ideas.

### Submitting Changes

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature-name`
3. Commit your changes: `git commit -am &#039;Add some feature&#039;`
4. Push to the branch: `git push origin feature/your-feature-name`
5. Submit a pull request

## License

This MCP server is licensed under the MIT License. See the LICENSE file for details.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[heroui-inc/heroui]]></title>
            <link>https://github.com/heroui-inc/heroui</link>
            <guid>https://github.com/heroui-inc/heroui</guid>
            <pubDate>Thu, 29 May 2025 00:04:40 GMT</pubDate>
            <description><![CDATA[🚀 Beautiful, fast and modern React UI library. (Previously NextUI)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/heroui-inc/heroui">heroui-inc/heroui</a></h1>
            <p>🚀 Beautiful, fast and modern React UI library. (Previously NextUI)</p>
            <p>Language: TypeScript</p>
            <p>Stars: 24,357</p>
            <p>Forks: 1,785</p>
            <p>Stars today: 50 stars today</p>
            <h2>README</h2><pre>packages/core/react/README.md</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[langgenius/dify]]></title>
            <link>https://github.com/langgenius/dify</link>
            <guid>https://github.com/langgenius/dify</guid>
            <pubDate>Thu, 29 May 2025 00:04:39 GMT</pubDate>
            <description><![CDATA[Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/langgenius/dify">langgenius/dify</a></h1>
            <p>Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 99,520</p>
            <p>Forks: 14,984</p>
            <p>Stars today: 203 stars today</p>
            <h2>README</h2><pre>![cover-v5-optimized](./images/GitHub_README_if.png)

&lt;p align=&quot;center&quot;&gt;
  📌 &lt;a href=&quot;https://dify.ai/blog/introducing-dify-workflow-file-upload-a-demo-on-ai-podcast&quot;&gt;Introducing Dify Workflow File Upload: Recreate Google NotebookLM Podcast&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cloud.dify.ai&quot;&gt;Dify Cloud&lt;/a&gt; ·
  &lt;a href=&quot;https://docs.dify.ai/getting-started/install-self-hosted&quot;&gt;Self-hosting&lt;/a&gt; ·
  &lt;a href=&quot;https://docs.dify.ai&quot;&gt;Documentation&lt;/a&gt; ·
  &lt;a href=&quot;https://dify.ai/pricing&quot;&gt;Dify edition overview&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://dify.ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Product-F04438&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://dify.ai/pricing&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/free-pricing?logo=free&amp;color=%20%23155EEF&amp;label=pricing&amp;labelColor=%20%23528bff&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/FngNHpbcY7&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1082486657678311454?logo=discord&amp;labelColor=%20%235462eb&amp;logoColor=%20%23f5f5f5&amp;color=%20%235462eb&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://reddit.com/r/difyai&quot; target=&quot;_blank&quot;&gt;  
        &lt;img src=&quot;https://img.shields.io/reddit/subreddit-subscribers/difyai?style=plastic&amp;logo=reddit&amp;label=r%2Fdifyai&amp;labelColor=white&quot;
            alt=&quot;join Reddit&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=dify_ai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/dify_ai?logo=X&amp;color=%20%23f5f5f5&quot;
            alt=&quot;follow on X(Twitter)&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.linkedin.com/company/langgenius/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&amp;logoColor=fff&quot;
            alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/u/langgenius&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/langgenius/dify-web?labelColor=%20%23FDB062&amp;color=%20%23f79009&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/graphs/commit-activity&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Commits last month&quot; src=&quot;https://img.shields.io/github/commit-activity/m/langgenius/dify?labelColor=%20%2332b583&amp;color=%20%2312b76a&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Issues closed&quot; src=&quot;https://img.shields.io/github/issues-search?query=repo%3Alanggenius%2Fdify%20is%3Aclosed&amp;label=issues%20closed&amp;labelColor=%20%237d89b0&amp;color=%20%235d6b98&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/langgenius/dify/discussions/&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Discussion posts&quot; src=&quot;https://img.shields.io/github/discussions/langgenius/dify?labelColor=%20%239b8afb&amp;color=%20%237a5af8&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_TW.md&quot;&gt;&lt;img alt=&quot;繁體中文文件&quot; src=&quot;https://img.shields.io/badge/繁體中文-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_CN.md&quot;&gt;&lt;img alt=&quot;简体中文版自述文件&quot; src=&quot;https://img.shields.io/badge/简体中文-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_JA.md&quot;&gt;&lt;img alt=&quot;日本語のREADME&quot; src=&quot;https://img.shields.io/badge/日本語-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_ES.md&quot;&gt;&lt;img alt=&quot;README en Español&quot; src=&quot;https://img.shields.io/badge/Español-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_FR.md&quot;&gt;&lt;img alt=&quot;README en Français&quot; src=&quot;https://img.shields.io/badge/Français-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_KL.md&quot;&gt;&lt;img alt=&quot;README tlhIngan Hol&quot; src=&quot;https://img.shields.io/badge/Klingon-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_KR.md&quot;&gt;&lt;img alt=&quot;README in Korean&quot; src=&quot;https://img.shields.io/badge/한국어-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_AR.md&quot;&gt;&lt;img alt=&quot;README بالعربية&quot; src=&quot;https://img.shields.io/badge/العربية-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_TR.md&quot;&gt;&lt;img alt=&quot;Türkçe README&quot; src=&quot;https://img.shields.io/badge/Türkçe-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_VI.md&quot;&gt;&lt;img alt=&quot;README Tiếng Việt&quot; src=&quot;https://img.shields.io/badge/Ti%E1%BA%BFng%20Vi%E1%BB%87t-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_DE.md&quot;&gt;&lt;img alt=&quot;README in Deutsch&quot; src=&quot;https://img.shields.io/badge/German-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_BN.md&quot;&gt;&lt;img alt=&quot;README in বাংলা&quot; src=&quot;https://img.shields.io/badge/বাংলা-d9d9d9&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Dify is an open-source LLM app development platform. Its intuitive interface combines agentic AI workflow, RAG pipeline, agent capabilities, model management, observability features, and more, allowing you to quickly move from prototype to production.

## Quick start

&gt; Before installing Dify, make sure your machine meets the following minimum system requirements:
&gt;
&gt; - CPU &gt;= 2 Core
&gt; - RAM &gt;= 4 GiB

&lt;/br&gt;

The easiest way to start the Dify server is through [docker compose](docker/docker-compose.yaml). Before running Dify with the following commands, make sure that [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) are installed on your machine:

```bash
cd dify
cd docker
cp .env.example .env
docker compose up -d
```

After running, you can access the Dify dashboard in your browser at [http://localhost/install](http://localhost/install) and start the initialization process.

#### Seeking help

Please refer to our [FAQ](https://docs.dify.ai/getting-started/install-self-hosted/faqs) if you encounter problems setting up Dify. Reach out to [the community and us](#community--contact) if you are still having issues.

&gt; If you&#039;d like to contribute to Dify or do additional development, refer to our [guide to deploying from source code](https://docs.dify.ai/getting-started/install-self-hosted/local-source-code)

## Key features

**1. Workflow**:
Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.

**2. Comprehensive model support**:
Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found [here](https://docs.dify.ai/getting-started/readme/model-providers).

![providers-v5](https://github.com/langgenius/dify/assets/13230914/5a17bdbe-097a-4100-8363-40255b70f6e3)

**3. Prompt IDE**:
Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.

**4. RAG Pipeline**:
Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.

**5. Agent capabilities**:
You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALL·E, Stable Diffusion and WolframAlpha.

**6. LLMOps**:
Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.

**7. Backend-as-a-Service**:
All of Dify&#039;s offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.

## Feature Comparison

&lt;table style=&quot;width: 100%;&quot;&gt;
  &lt;tr&gt;
    &lt;th align=&quot;center&quot;&gt;Feature&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;Dify.AI&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;LangChain&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;Flowise&lt;/th&gt;
    &lt;th align=&quot;center&quot;&gt;OpenAI Assistants API&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Programming Approach&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;API + App-oriented&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Python Code&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;App-oriented&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;API-oriented&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Supported LLMs&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;Rich Variety&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;OpenAI-only&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;RAG Engine&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Agent&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Workflow&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Observability&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Enterprise Feature (SSO/Access control)&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;Local Deployment&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;✅&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;❌&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Using Dify

- **Cloud &lt;/br&gt;**
  We host a [Dify Cloud](https://dify.ai) service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.

- **Self-hosting Dify Community Edition&lt;/br&gt;**
  Quickly get Dify running in your environment with this [starter guide](#quick-start).
  Use our [documentation](https://docs.dify.ai) for further references and more in-depth instructions.

- **Dify for enterprise / organizations&lt;/br&gt;**
  We provide additional enterprise-centric features. [Log your questions for us through this chatbot](https://udify.app/chat/22L1zSxg6yW1cWQg) or [send us an email](mailto:business@dify.ai?subject=[GitHub]Business%20License%20Inquiry) to discuss enterprise needs. &lt;/br&gt;
  &gt; For startups and small businesses using AWS, check out [Dify Premium on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6) and deploy it to your own AWS VPC with one click. It&#039;s an affordable AMI offering with the option to create apps with custom logo and branding.

## Staying ahead

Star Dify on GitHub and be instantly notified of new releases.

![star-us](https://github.com/langgenius/dify/assets/13230914/b823edc1-6388-4e25-ad45-2f6b187adbb4)

## Advanced Setup

If you need to customize the configuration, please refer to the comments in our [.env.example](docker/.env.example) file and update the corresponding values in your `.env` file. Additionally, you might need to make adjustments to the `docker-compose.yaml` file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run `docker-compose up -d`. You can find the full list of available environment variables [here](https://docs.dify.ai/getting-started/install-self-hosted/environments).

If you&#039;d like to configure a highly-available setup, there are community-contributed [Helm Charts](https://helm.sh/) and YAML files which allow Dify to be deployed on Kubernetes.

- [Helm Chart by @LeoQuote](https://github.com/douban/charts/tree/master/charts/dify)
- [Helm Chart by @BorisPolonsky](https://github.com/BorisPolonsky/dify-helm)
- [Helm Chart by @magicsong](https://github.com/magicsong/ai-charts)
- [YAML file by @Winson-030](https://github.com/Winson-030/dify-kubernetes)
- [YAML file by @wyy-holding](https://github.com/wyy-holding/dify-k8s)

#### Using Terraform for Deployment

Deploy Dify to Cloud Platform with a single click using [terraform](https://www.terraform.io/)

##### Azure Global

- [Azure Terraform by @nikawang](https://github.com/nikawang/dify-azure-terraform)

##### Google Cloud

- [Google Cloud Terraform by @sotazum](https://github.com/DeNA/dify-google-cloud-terraform)

#### Using AWS CDK for Deployment

Deploy Dify to AWS with [CDK](https://aws.amazon.com/cdk/)

##### AWS

- [AWS CDK by @KevinZhao](https://github.com/aws-samples/solution-for-deploying-dify-on-aws)

## Contributing

For those who&#039;d like to contribute code, see our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.

&gt; We are looking for contributors to help translate Dify into languages other than Mandarin or English. If you are interested in helping, please see the [i18n README](https://github.com/langgenius/dify/blob/main/web/i18n/README.md) for more information, and leave us a comment in the `global-users` channel of our [Discord Community Server](https://discord.gg/8Tpq4AcN9c).

## Community &amp; contact

- [GitHub Discussion](https://github.com/langgenius/dify/discussions). Best for: sharing feedback and asking questions.
- [GitHub Issues](https://github.com/langgenius/dify/issues). Best for: bugs you encounter using Dify.AI, and feature proposals. See our [Contribution Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md).
- [Discord](https://discord.gg/FngNHpbcY7). Best for: sharing your applications and hanging out with the community.
- [X(Twitter)](https://twitter.com/dify_ai). Best for: sharing your applications and hanging out with the community.

**Contributors**

&lt;a href=&quot;https://github.com/langgenius/dify/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=langgenius/dify&quot; /&gt;
&lt;/a&gt;

## Star history

[![Star History Chart](https://api.star-history.com/svg?repos=langgenius/dify&amp;type=Date)](https://star-history.com/#langgenius/dify&amp;Date)

## Security disclosure

To protect your privacy, please avoid posting security issues on GitHub. Instead, send your questions to security@dify.ai and we will provide you with a more detailed answer.

## License

This repository is available under the [Dify Open Source License](LICENSE), which is essentially Apache 2.0 with a few additional restrictions.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[google/brotli]]></title>
            <link>https://github.com/google/brotli</link>
            <guid>https://github.com/google/brotli</guid>
            <pubDate>Thu, 29 May 2025 00:04:38 GMT</pubDate>
            <description><![CDATA[Brotli compression format]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google/brotli">google/brotli</a></h1>
            <p>Brotli compression format</p>
            <p>Language: TypeScript</p>
            <p>Stars: 14,078</p>
            <p>Forks: 1,270</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/google/brotli/actions/workflows/build_test.yml/badge.svg&quot; alt=&quot;GitHub Actions Build Status&quot; href=&quot;https://github.com/google/brotli/actions?query=branch%3Amaster&quot;&gt;
  &lt;img src=&quot;https://oss-fuzz-build-logs.storage.googleapis.com/badges/brotli.svg&quot; alt=&quot;Fuzzing Status&quot; href=&quot;https://oss-fuzz-build-logs.storage.googleapis.com/index.html#brotli&quot;&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://brotli.org/brotli.svg&quot; alt=&quot;Brotli&quot; width=&quot;64&quot;&gt;&lt;/p&gt;

### Introduction

Brotli is a generic-purpose lossless compression algorithm that compresses data
using a combination of a modern variant of the LZ77 algorithm, Huffman coding
and 2nd order context modeling, with a compression ratio comparable to the best
currently available general-purpose compression methods. It is similar in speed
with deflate but offers more dense compression.

The specification of the Brotli Compressed Data Format is defined in [RFC 7932](https://tools.ietf.org/html/rfc7932).

Brotli is open-sourced under the MIT License, see the LICENSE file.

&gt; **Please note:** brotli is a &quot;stream&quot; format; it does not contain
&gt; meta-information, like checksums or uncompresssed data length. It is possible
&gt; to modify &quot;raw&quot; ranges of the compressed stream and the decoder will not
&gt; notice that.

### Build instructions

#### Vcpkg

You can download and install brotli using the [vcpkg](https://github.com/Microsoft/vcpkg/) dependency manager:

    git clone https://github.com/Microsoft/vcpkg.git
    cd vcpkg
    ./bootstrap-vcpkg.sh
    ./vcpkg integrate install
    ./vcpkg install brotli

The brotli port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.

#### Bazel

See [Bazel](http://www.bazel.build/)

#### CMake

The basic commands to build and install brotli are:

    $ mkdir out &amp;&amp; cd out
    $ cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=./installed ..
    $ cmake --build . --config Release --target install

You can use other [CMake](https://cmake.org/) configuration.

#### Python

To install the latest release of the Python module, run the following:

    $ pip install brotli

To install the tip-of-the-tree version, run:

    $ pip install --upgrade git+https://github.com/google/brotli

See the [Python readme](python/README.md) for more details on installing
from source, development, and testing.

### Contributing

We glad to answer/library related questions in
[brotli mailing list](https://groups.google.com/forum/#!forum/brotli).

Regular issues / feature requests should be reported in
[issue tracker](https://github.com/google/brotli/issues).

For reporting vulnerability please read [SECURITY](SECURITY.md).

For contributing changes please read [CONTRIBUTING](CONTRIBUTING.md).

### Benchmarks
* [Squash Compression Benchmark](https://quixdb.github.io/squash-benchmark/) / [Unstable Squash Compression Benchmark](https://quixdb.github.io/squash-benchmark/unstable/)
* [Large Text Compression Benchmark](http://mattmahoney.net/dc/text.html)
* [Lzturbo Benchmark](https://sites.google.com/site/powturbo/home/benchmark)

### Related projects
&gt; **Disclaimer:** Brotli authors take no responsibility for the third party projects mentioned in this section.

Independent [decoder](https://github.com/madler/brotli) implementation by Mark Adler, based entirely on format specification.

JavaScript port of brotli [decoder](https://github.com/devongovett/brotli.js). Could be used directly via `npm install brotli`

Hand ported [decoder / encoder](https://github.com/dominikhlbg/BrotliHaxe) in haxe by Dominik Homberger. Output source code: JavaScript, PHP, Python, Java and C#

7Zip [plugin](https://github.com/mcmilk/7-Zip-Zstd)

Dart [native bindings](https://github.com/thosakwe/brotli)

Dart compression framework with [fast FFI-based Brotli implementation](https://pub.dev/documentation/es_compression/latest/brotli/brotli-library.html) with ready-to-use prebuilt binaries for Win/Linux/Mac
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[jeffvli/feishin]]></title>
            <link>https://github.com/jeffvli/feishin</link>
            <guid>https://github.com/jeffvli/feishin</guid>
            <pubDate>Thu, 29 May 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[A modern self-hosted music player.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jeffvli/feishin">jeffvli/feishin</a></h1>
            <p>A modern self-hosted music player.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 3,901</p>
            <p>Forks: 150</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;assets/icon.png&quot; alt=&quot;sonixd logo&quot; title=&quot;sonixd&quot; align=&quot;right&quot; height=&quot;60px&quot; /&gt;

# Sonixd

  &lt;a href=&quot;https://github.com/jeffvli/sonixd/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/v/release/jeffvli/sonixd?style=flat-square&amp;color=blue&quot;
    alt=&quot;Release&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/jeffvli/sonixd/blob/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/jeffvli/sonixd?style=flat-square&amp;color=brightgreen&quot;
    alt=&quot;License&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/jeffvli/sonixd/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/downloads/jeffvli/sonixd/total?style=flat-square&amp;color=orange&quot;
    alt=&quot;Downloads&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/FVKpcMDy5f&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/922656312888811530?color=red&amp;label=discord&amp;logo=discord&amp;logoColor=white&quot;
    alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://matrix.to/#/#sonixd:matrix.org&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/matrix/sonixd:matrix.org?color=red&amp;label=matrix&amp;logo=matrix&amp;logoColor=white&quot;
    alt=&quot;Matrix&quot;&gt;
  &lt;/a&gt;

Sonixd is a cross-platform desktop client built for Subsonic-API (and Jellyfin in 0.8.0+) compatible music servers. This project was inspired by the many existing clients, but aimed to address a few key issues including &lt;strong&gt;scalability&lt;/strong&gt;, &lt;strong&gt;library management&lt;/strong&gt;, and &lt;strong&gt;user experience&lt;/strong&gt;.

- [**Usage documentation &amp; FAQ**](https://github.com/jeffvli/sonixd/discussions/15)
- [**Theming documentation**](https://github.com/jeffvli/sonixd/discussions/61)

Sonixd has been tested on the following: [Navidrome](https://github.com/navidrome/navidrome), [Airsonic](https://github.com/airsonic/airsonic), [Airsonic-Advanced](https://github.com/airsonic-advanced/airsonic-advanced), [Gonic](https://github.com/sentriz/gonic), [Astiga](https://asti.ga/), [Jellyfin](https://github.com/jellyfin/jellyfin)

### [Demo Sonixd using Navidrome](https://github.com/jeffvli/sonixd/discussions/244)

## Features

- HTML5 audio with crossfading and gapless\* playback
- Drag and drop rows with multi-select
- Modify and save playlists intuitively
- Handles large playlists and queues
- Global mediakeys (and partial MPRIS) support
- Multi-theme support
- Supports all Subsonic/Jellyfin API compatible servers
- Built with Electron, React with the [rsuite v4](https://github.com/rsuite/rsuite) component library

&lt;h5&gt;* Gapless playback is artifically created using the crossfading players so it may not be perfect, YMMV.&lt;/h5&gt;

## Screenshots

&lt;a href=&quot;https://raw.githubusercontent.com/jeffvli/sonixd/main/assets/screenshots/0.13.1/album.png&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jeffvli/sonixd/main/assets/screenshots/0.13.1/album.png&quot; width=&quot;49.5%&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://raw.githubusercontent.com/jeffvli/sonixd/main/assets/screenshots/0.13.1/artist.png&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jeffvli/sonixd/main/assets/screenshots/0.13.1/artist.png&quot; width=&quot;49.5%&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://raw.githubusercontent.com/jeffvli/sonixd/main/assets/screenshots/0.13.1/search.png&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jeffvli/sonixd/main/assets/screenshots/0.13.1/search.png&quot; width=&quot;49.5%&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://raw.githubusercontent.com/jeffvli/sonixd/main/assets/screenshots/0.13.1/now_playing.png&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jeffvli/sonixd/main/assets/screenshots/0.13.1/now_playing.png&quot; width=&quot;49.5%&quot;/&gt;&lt;/a&gt;

## Install

You can install sonixd by downloading the [latest release](https://github.com/jeffvli/sonixd/releases) for your specified operating system.

---

### Windows

If you prefer not to download the release binary, you can install using `winget`.

Using your favorite terminal (cmd/pwsh):

```
winget install sonixd
```

---

### Arch Linux

There is an AUR package of the latest AppImage release available [here](https://aur.archlinux.org/packages/sonixd-appimage).

To install it you can use your favourite AUR package manager and install the package: `sonixd-appimage`

For example using `yay`:

```
yay -S sonixd-appimage
```

If you encounter any problems please comment on the [AUR](https://aur.archlinux.org/packages/sonixd-appimage) or contact the [maintainer](mailto:robin@blckct.io) directly before you open an issue here.

---

Once installed, run the application and sign in to your music server with the following details. If you are using [airsonic-advanced](https://github.com/airsonic-advanced/airsonic-advanced), you will need to make sure that you create a `decodable` credential for your login user within the admin control panel.

- Server - `e.g. http://localhost:4040/`
- User name - `e.g. admin`
- Password - `e.g. supersecret!`

If you have any questions, feel free to check out the [Usage Documentation &amp; FAQ](https://github.com/jeffvli/sonixd/discussions/15).

## Development / Contributing

This project is built off of [electron-react-boilerplate](https://github.com/electron-react-boilerplate/electron-react-boilerplate) v2.3.0.
If you want to contribute to this project, please first create an [issue](https://github.com/jeffvli/sonixd/issues/new) or [discussion](https://github.com/jeffvli/sonixd/discussions/new) so that we can both discuss the idea and its feasability for integration.

First, clone the repo via git and install dependencies (Windows development now requires additional setup, see [#232](https://github.com/jeffvli/sonixd/issues/232)):

```bash
git clone https://github.com/jeffvli/sonixd.git
yarn install
```

Start the app in the `dev` environment:

```bash
yarn start
```

To package apps for the local platform:

```bash
yarn package
```

If you receive errors while packaging the application, try upgrading/downgrading your Node version (tested on v14.18.0).

If you are unable to run via debug in VS Code, check troubleshooting steps [here](https://github.com/electron-react-boilerplate/electron-react-boilerplate/issues/2757#issuecomment-784200527).

If your devtools extensions are failing to run/install, check troubleshooting steps [here](https://github.com/electron-react-boilerplate/electron-react-boilerplate/issues/2788).

## License

[GNU General Public License v3.0 ©](https://github.com/jeffvli/sonixd/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[kortix-ai/suna]]></title>
            <link>https://github.com/kortix-ai/suna</link>
            <guid>https://github.com/kortix-ai/suna</guid>
            <pubDate>Thu, 29 May 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[Suna - Open Source Generalist AI Agent]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kortix-ai/suna">kortix-ai/suna</a></h1>
            <p>Suna - Open Source Generalist AI Agent</p>
            <p>Language: TypeScript</p>
            <p>Stars: 13,311</p>
            <p>Forks: 1,904</p>
            <p>Stars today: 212 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# Suna - Open Source Generalist AI Agent

(that acts on your behalf)

![Suna Screenshot](frontend/public/banner.png)

Suna is a fully open source AI assistant that helps you accomplish real-world tasks with ease. Through natural conversation, Suna becomes your digital companion for research, data analysis, and everyday challenges—combining powerful capabilities with an intuitive interface that understands what you need and delivers results.

Suna&#039;s powerful toolkit includes seamless browser automation to navigate the web and extract data, file management for document creation and editing, web crawling and extended search capabilities, command-line execution for system tasks, website deployment, and integration with various APIs and services. These capabilities work together harmoniously, allowing Suna to solve your complex problems and automate workflows through simple conversations!

[![License](https://img.shields.io/badge/License-Apache--2.0-blue)](./license)
[![Discord Follow](https://dcbadge.limes.pink/api/server/Py6pCBUUPw?style=flat)](https://discord.gg/Py6pCBUUPw)
[![Twitter Follow](https://img.shields.io/twitter/follow/kortixai)](https://x.com/kortixai)
[![GitHub Repo stars](https://img.shields.io/github/stars/kortix-ai/suna)](https://github.com/kortix-ai/suna)
[![Issues](https://img.shields.io/github/issues/kortix-ai/suna)](https://github.com/kortix-ai/suna/labels/bug)

&lt;/div&gt;

## Table of Contents

- [Suna Architecture](#project-architecture)
  - [Backend API](#backend-api)
  - [Frontend](#frontend)
  - [Agent Docker](#agent-docker)
  - [Supabase Database](#supabase-database)
- [Use Cases](#use-cases)
- [Self-Hosting](#self-hosting)
- [Acknowledgements](#acknowledgements)
- [License](#license)

## Project Architecture

![Architecture Diagram](docs/images/diagram.png)

Suna consists of four main components:

### Backend API

Python/FastAPI service that handles REST endpoints, thread management, and LLM integration with Anthropic, and others via LiteLLM.

### Frontend

Next.js/React application providing a responsive UI with chat interface, dashboard, etc.

### Agent Docker

Isolated execution environment for every agent - with browser automation, code interpreter, file system access, tool integration, and security features.

### Supabase Database

Handles data persistence with authentication, user management, conversation history, file storage, agent state, analytics, and real-time subscriptions.

## Use Cases

1. **Competitor Analysis** ([Watch](https://www.suna.so/share/5ee791ac-e19c-4986-a61c-6d0659d0e5bc)) - _&quot;Analyze the market for my next company in the healthcare industry, located in the UK. Give me the major players, their market size, strengths, and weaknesses, and add their website URLs. Once done, generate a PDF report.&quot;_

2. **VC List** ([Watch](https://www.suna.so/share/804d20a3-cf1c-4adb-83bb-0e77cc6adeac)) - _&quot;Give me the list of the most important VC Funds in the United States based on Assets Under Management. Give me website URLs, and if possible an email to reach them out.&quot;_

3. **Looking for Candidates** ([Watch](https://www.suna.so/share/3ae581b0-2db8-4c63-b324-3b8d29762e74)) - _&quot;Go on LinkedIn, and find me 10 profiles available - they are not working right now - for a junior software engineer position, who are located in Munich, Germany. They should have at least one bachelor&#039;s degree in Computer Science or anything related to it, and 1-year of experience in any field/role.&quot;_

4. **Planning Company Trip** ([Watch](https://www.suna.so/share/725e64a0-f1e2-4bb6-8a1f-703c2833fd72)) - _&quot;Generate me a route plan for my company. We should go to California. We&#039;ll be in 8 people. Compose the trip from the departure (Paris, France) to the activities we can do considering that the trip will be 7 days long - departure on the 21st of Apr 2025. Check the weather forecast and temperature for the upcoming days, and based on that, you can plan our activities (outdoor vs indoor).&quot;_

5. **Working on Excel** ([Watch](https://www.suna.so/share/128f23a4-51cd-42a6-97a0-0b458b32010e)) - _&quot;My company asked me to set up an Excel spreadsheet with all the information about Italian lottery games (Lotto, 10eLotto, and Million Day). Based on that, generate and send me a spreadsheet with all the basic information (public ones).&quot;_

6. **Automate Event Speaker Prospecting** ([Watch](https://www.suna.so/share/7a7592ea-ed44-4c69-bcb5-5f9bb88c188c)) - _&quot;Find 20 AI ethics speakers from Europe who&#039;ve spoken at conferences in the past year. Scrapes conference sites, cross-references LinkedIn and YouTube, and outputs contact info + talk summaries.&quot;_

7. **Summarize and Cross-Reference Scientific Papers** ([Watch](https://www.suna.so/share/c2081b3c-786e-4e7c-9bf4-46e9b23bb662)) - _&quot;Research and compare scientific papers talking about Alcohol effects on our bodies during the last 5 years. Generate a report about the most important scientific papers talking about the topic I wrote before.&quot;_

8. **Research + First Contact Draft** ([Watch](https://www.suna.so/share/6b6296a6-8683-49e5-9ad0-a32952d12c44)) - _&quot;Research my potential customers (B2B) on LinkedIn. They should be in the clean tech industry. Find their websites and their email addresses. After that, based on the company profile, generate a personalized first contact email where I present my company which is offering consulting services to cleantech companies to maximize their profits and reduce their costs.&quot;_

9. **SEO Analysis** ([Watch](https://www.suna.so/share/43491cb0-cd6c-45f0-880c-66ddc8c4b842)) - _&quot;Based on my website suna.so, generate an SEO report analysis, find top-ranking pages by keyword clusters, and identify topics I&#039;m missing.&quot;_

10. **Generate a Personal Trip** ([Watch](https://www.suna.so/share/37b31907-8349-4f63-b0e5-27ca597ed02a)) - _&quot;Generate a personal trip to London, with departure from Bangkok on the 1st of May. The trip will last 10 days. Find an accommodation in the center of London, with a rating on Google reviews of at least 4.5. Find me interesting outdoor activities to do during the journey. Generate a detailed itinerary plan.&quot;_

11. **Recently Funded Startups** ([Watch](https://www.suna.so/share/8b2a897e-985a-4d5e-867b-15239274f764)) - _&quot;Go on Crunchbase, Dealroom, and TechCrunch, filter by Series A funding rounds in the SaaS Finance Space, and build a report with company data, founders, and contact info for outbound sales.&quot;_

12. **Scrape Forum Discussions** ([Watch](https://www.suna.so/share/7d7a5d93-a20d-48b0-82cc-e9a876e9fd04)) - _&quot;I need to find the best beauty centers in Rome, but I want to find them by using open forums that speak about this topic. Go on Google, and scrape the forums by looking for beauty center discussions located in Rome. Then generate a list of 5 beauty centers with the best comments about them.&quot;_

## Self-Hosting

Suna can be self-hosted on your own infrastructure using our setup wizard. For a comprehensive guide to self-hosting Suna, please refer to our [Self-Hosting Guide](./docs/SELF-HOSTING.md).

The setup process includes:

- Setting up a Supabase project for database and authentication
- Configuring Redis for caching and session management
- Setting up Daytona for secure agent execution
- Integrating with LLM providers (Anthropic, OpenAI, Groq, etc.)
- Configuring web search and scraping capabilities

### Quick Start

1. **Clone the repository**:

```bash
git clone https://github.com/kortix-ai/suna.git
cd suna
```

2. **Run the setup wizard**:

```bash
python setup.py
```

3. **Start or stop the containers**:

```bash
python start.py
```

### Manual Setup

See the [Self-Hosting Guide](./docs/SELF-HOSTING.md) for detailed manual setup instructions.

The wizard will guide you through all necessary steps to get your Suna instance up and running. For detailed instructions, troubleshooting tips, and advanced configuration options, see the [Self-Hosting Guide](./SELF-HOSTING.md).

## Contributing

We welcome contributions from the community! Please see our [Contributing Guide](./CONTRIBUTING.md) for more details.

## Acknowledgements

### Main Contributors

- [Adam Cohen Hillel](https://x.com/adamcohenhillel)
- [Dat-lequoc](https://x.com/datlqqq)
- [Marko Kraemer](https://twitter.com/markokraemer)

### Technologies

- [Daytona](https://daytona.io/) - Secure agent execution environment
- [Supabase](https://supabase.com/) - Database and authentication
- [Playwright](https://playwright.dev/) - Browser automation
- [OpenAI](https://openai.com/) - LLM provider
- [Anthropic](https://www.anthropic.com/) - LLM provider
- [Tavily](https://tavily.com/) - Search capabilities
- [Firecrawl](https://firecrawl.dev/) - Web scraping capabilities
- [RapidAPI](https://rapidapi.com/) - API services

## License

Kortix Suna is licensed under the Apache License, Version 2.0. See [LICENSE](./LICENSE) for the full license text.
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[vuejs/core]]></title>
            <link>https://github.com/vuejs/core</link>
            <guid>https://github.com/vuejs/core</guid>
            <pubDate>Thu, 29 May 2025 00:04:35 GMT</pubDate>
            <description><![CDATA[🖖 Vue.js is a progressive, incrementally-adoptable JavaScript framework for building UI on the web.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vuejs/core">vuejs/core</a></h1>
            <p>🖖 Vue.js is a progressive, incrementally-adoptable JavaScript framework for building UI on the web.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 50,185</p>
            <p>Forks: 8,660</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre># vuejs/core [![npm](https://img.shields.io/npm/v/vue.svg)](https://www.npmjs.com/package/vue) [![build status](https://github.com/vuejs/core/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/vuejs/core/actions/workflows/ci.yml) [![Download](https://img.shields.io/npm/dm/vue)](https://www.npmjs.com/package/vue)

## Getting Started

Please follow the documentation at [vuejs.org](https://vuejs.org/)!

## Sponsors

Vue.js is an MIT-licensed open source project with its ongoing development made possible entirely by the support of these awesome [backers](https://github.com/vuejs/core/blob/main/BACKERS.md). If you&#039;d like to join them, please consider [ sponsoring Vue&#039;s development](https://vuejs.org/sponsor/).

&lt;p align=&quot;center&quot;&gt;
  &lt;h3 align=&quot;center&quot;&gt;Special Sponsor&lt;/h3&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/appwrite/appwrite&quot;&gt;
  &lt;img alt=&quot;special sponsor appwrite&quot; src=&quot;https://sponsors.vuejs.org/images/appwrite.svg&quot; width=&quot;300&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://vuejs.org/sponsor/#current-sponsors&quot;&gt;
    &lt;img alt=&quot;sponsors&quot; src=&quot;https://sponsors.vuejs.org/sponsors.svg?v3&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

## Questions

For questions and support please use [the official forum](https://forum.vuejs.org) or [community chat](https://chat.vuejs.org/). The issue list of this repo is **exclusively** for bug reports and feature requests.

## Issues

Please make sure to respect issue requirements and use [the new issue helper](https://new-issue.vuejs.org/) when opening an issue. Issues not conforming to the guidelines may be closed immediately.

## Stay In Touch

- [X](https://x.com/vuejs)
- [Bluesky](https://bsky.app/profile/vuejs.org)
- [Blog](https://blog.vuejs.org/)
- [Job Board](https://vuejobs.com/?ref=vuejs)

## Contribution

Please make sure to read the [Contributing Guide](https://github.com/vuejs/core/blob/main/.github/contributing.md) before making a pull request. If you have a Vue-related project/component/tool, add it with a pull request to [this curated list](https://github.com/vuejs/awesome-vue)!

Thank you to all the people who already contributed to Vue!

&lt;a href=&quot;https://github.com/vuejs/core/graphs/contributors&quot;&gt;&lt;img src=&quot;https://opencollective.com/vuejs/contributors.svg?width=890&amp;limit=500&quot; /&gt;&lt;/a&gt;

&lt;sub&gt;_Note: Showing the first 500 contributors only due to GitHub image size limitations_&lt;/sub&gt;

## License

[MIT](https://opensource.org/licenses/MIT)

Copyright (c) 2013-present, Yuxi (Evan) You
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[cline/cline]]></title>
            <link>https://github.com/cline/cline</link>
            <guid>https://github.com/cline/cline</guid>
            <pubDate>Thu, 29 May 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[Autonomous coding agent right in your IDE, capable of creating/editing files, executing commands, using the browser, and more with your permission every step of the way.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cline/cline">cline/cline</a></h1>
            <p>Autonomous coding agent right in your IDE, capable of creating/editing files, executing commands, using the browser, and more with your permission every step of the way.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 44,691</p>
            <p>Forks: 5,356</p>
            <p>Stars today: 135 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;sub&gt;
English | &lt;a href=&quot;https://github.com/cline/cline/blob/main/locales/es/README.md&quot; target=&quot;_blank&quot;&gt;Español&lt;/a&gt; | &lt;a href=&quot;https://github.com/cline/cline/blob/main/locales/de/README.md&quot; target=&quot;_blank&quot;&gt;Deutsch&lt;/a&gt; | &lt;a href=&quot;https://github.com/cline/cline/blob/main/locales/ja/README.md&quot; target=&quot;_blank&quot;&gt;日本語&lt;/a&gt; | &lt;a href=&quot;https://github.com/cline/cline/blob/main/locales/zh-cn/README.md&quot; target=&quot;_blank&quot;&gt;简体中文&lt;/a&gt; | &lt;a href=&quot;https://github.com/cline/cline/blob/main/locales/zh-tw/README.md&quot; target=&quot;_blank&quot;&gt;繁體中文&lt;/a&gt; | &lt;a href=&quot;https://github.com/cline/cline/blob/main/locales/ko/README.md&quot; target=&quot;_blank&quot;&gt;한국어&lt;/a&gt;
&lt;/sub&gt;&lt;/div&gt;

# Cline – \#1 on OpenRouter

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://media.githubusercontent.com/media/cline/cline/main/assets/docs/demo.gif&quot; width=&quot;100%&quot; /&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Download on VS Marketplace&lt;/strong&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;https://discord.gg/cline&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Discord&lt;/strong&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.reddit.com/r/cline/&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;r/cline&lt;/strong&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/cline/cline/discussions/categories/feature-requests?discussions_q=is%3Aopen+category%3A%22Feature+Requests%22+sort%3Atop&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Feature Requests&lt;/strong&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;https://docs.cline.bot/getting-started/for-new-coders&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Getting Started&lt;/strong&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

Meet Cline, an AI assistant that can use your **CLI** a**N**d **E**ditor.

Thanks to [Claude 3.7 Sonnet&#039;s agentic coding capabilities](https://www.anthropic.com/claude/sonnet), Cline can handle complex software development tasks step-by-step. With tools that let him create &amp; edit files, explore large projects, use the browser, and execute terminal commands (after you grant permission), he can assist you in ways that go beyond code completion or tech support. Cline can even use the Model Context Protocol (MCP) to create new tools and extend his own capabilities. While autonomous AI scripts traditionally run in sandboxed environments, this extension provides a human-in-the-loop GUI to approve every file change and terminal command, providing a safe and accessible way to explore the potential of agentic AI.

1. Enter your task and add images to convert mockups into functional apps or fix bugs with screenshots.
2. Cline starts by analyzing your file structure &amp; source code ASTs, running regex searches, and reading relevant files to get up to speed in existing projects. By carefully managing what information is added to context, Cline can provide valuable assistance even for large, complex projects without overwhelming the context window.
3. Once Cline has the information he needs, he can:
    - Create and edit files + monitor linter/compiler errors along the way, letting him proactively fix issues like missing imports and syntax errors on his own.
    - Execute commands directly in your terminal and monitor their output as he works, letting him e.g., react to dev server issues after editing a file.
    - For web development tasks, Cline can launch the site in a headless browser, click, type, scroll, and capture screenshots + console logs, allowing him to fix runtime errors and visual bugs.
4. When a task is completed, Cline will present the result to you with a terminal command like `open -a &quot;Google Chrome&quot; index.html`, which you run with a click of a button.

&gt; [!TIP]
&gt; Use the `CMD/CTRL + Shift + P` shortcut to open the command palette and type &quot;Cline: Open In New Tab&quot; to open the extension as a tab in your editor. This lets you use Cline side-by-side with your file explorer, and see how he changes your workspace more clearly.

---

&lt;img align=&quot;right&quot; width=&quot;340&quot; src=&quot;https://github.com/user-attachments/assets/3cf21e04-7ce9-4d22-a7b9-ba2c595e88a4&quot;&gt;

### Use any API and Model

Cline supports API providers like OpenRouter, Anthropic, OpenAI, Google Gemini, AWS Bedrock, Azure, GCP Vertex, and Cerebras. You can also configure any OpenAI compatible API, or use a local model through LM Studio/Ollama. If you&#039;re using OpenRouter, the extension fetches their latest model list, allowing you to use the newest models as soon as they&#039;re available.

The extension also keeps track of total tokens and API usage cost for the entire task loop and individual requests, keeping you informed of spend every step of the way.

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

&lt;img align=&quot;left&quot; width=&quot;370&quot; src=&quot;https://github.com/user-attachments/assets/81be79a8-1fdb-4028-9129-5fe055e01e76&quot;&gt;

### Run Commands in Terminal

Thanks to the new [shell integration updates in VSCode v1.93](https://code.visualstudio.com/updates/v1_93#_terminal-shell-integration-api), Cline can execute commands directly in your terminal and receive the output. This allows him to perform a wide range of tasks, from installing packages and running build scripts to deploying applications, managing databases, and executing tests, all while adapting to your dev environment &amp; toolchain to get the job done right.

For long running processes like dev servers, use the &quot;Proceed While Running&quot; button to let Cline continue in the task while the command runs in the background. As Cline works he’ll be notified of any new terminal output along the way, letting him react to issues that may come up, such as compile-time errors when editing files.

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

&lt;img align=&quot;right&quot; width=&quot;400&quot; src=&quot;https://github.com/user-attachments/assets/c5977833-d9b8-491e-90f9-05f9cd38c588&quot;&gt;

### Create and Edit Files

Cline can create and edit files directly in your editor, presenting you a diff view of the changes. You can edit or revert Cline&#039;s changes directly in the diff view editor, or provide feedback in chat until you&#039;re satisfied with the result. Cline also monitors linter/compiler errors (missing imports, syntax errors, etc.) so he can fix issues that come up along the way on his own.

All changes made by Cline are recorded in your file&#039;s Timeline, providing an easy way to track and revert modifications if needed.

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

&lt;img align=&quot;left&quot; width=&quot;370&quot; src=&quot;https://github.com/user-attachments/assets/bc2e85ba-dfeb-4fe6-9942-7cfc4703cbe5&quot;&gt;

### Use the Browser

With Claude 3.5 Sonnet&#039;s new [Computer Use](https://www.anthropic.com/news/3-5-models-and-computer-use) capability, Cline can launch a browser, click elements, type text, and scroll, capturing screenshots and console logs at each step. This allows for interactive debugging, end-to-end testing, and even general web use! This gives him autonomy to fixing visual bugs and runtime issues without you needing to handhold and copy-pasting error logs yourself.

Try asking Cline to &quot;test the app&quot;, and watch as he runs a command like `npm run dev`, launches your locally running dev server in a browser, and performs a series of tests to confirm that everything works. [See a demo here.](https://x.com/sdrzn/status/1850880547825823989)

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

&lt;img align=&quot;right&quot; width=&quot;350&quot; src=&quot;https://github.com/user-attachments/assets/ac0efa14-5c1f-4c26-a42d-9d7c56f5fadd&quot;&gt;

### &quot;add a tool that...&quot;

Thanks to the [Model Context Protocol](https://github.com/modelcontextprotocol), Cline can extend his capabilities through custom tools. While you can use [community-made servers](https://github.com/modelcontextprotocol/servers), Cline can instead create and install tools tailored to your specific workflow. Just ask Cline to &quot;add a tool&quot; and he will handle everything, from creating a new MCP server to installing it into the extension. These custom tools then become part of Cline&#039;s toolkit, ready to use in future tasks.

-   &quot;add a tool that fetches Jira tickets&quot;: Retrieve ticket ACs and put Cline to work
-   &quot;add a tool that manages AWS EC2s&quot;: Check server metrics and scale instances up or down
-   &quot;add a tool that pulls the latest PagerDuty incidents&quot;: Fetch details and ask Cline to fix bugs

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

&lt;img align=&quot;left&quot; width=&quot;360&quot; src=&quot;https://github.com/user-attachments/assets/7fdf41e6-281a-4b4b-ac19-020b838b6970&quot;&gt;

### Add Context

**`@url`:** Paste in a URL for the extension to fetch and convert to markdown, useful when you want to give Cline the latest docs

**`@problems`:** Add workspace errors and warnings (&#039;Problems&#039; panel) for Cline to fix

**`@file`:** Adds a file&#039;s contents so you don&#039;t have to waste API requests approving read file (+ type to search files)

**`@folder`:** Adds folder&#039;s files all at once to speed up your workflow even more

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

&lt;img align=&quot;right&quot; width=&quot;350&quot; src=&quot;https://github.com/user-attachments/assets/140c8606-d3bf-41b9-9a1f-4dbf0d4c90cb&quot;&gt;

### Checkpoints: Compare and Restore

As Cline works through a task, the extension takes a snapshot of your workspace at each step. You can use the &#039;Compare&#039; button to see a diff between the snapshot and your current workspace, and the &#039;Restore&#039; button to roll back to that point.

For example, when working with a local web server, you can use &#039;Restore Workspace Only&#039; to quickly test different versions of your app, then use &#039;Restore Task and Workspace&#039; when you find the version you want to continue building from. This lets you safely explore different approaches without losing progress.

&lt;!-- Transparent pixel to create line break after floating image --&gt;

&lt;img width=&quot;2000&quot; height=&quot;0&quot; src=&quot;https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929&quot;&gt;&lt;br&gt;

## Contributing

To contribute to the project, start with our [Contributing Guide](CONTRIBUTING.md) to learn the basics. You can also join our [Discord](https://discord.gg/cline) to chat with other contributors in the `#contributors` channel. If you&#039;re looking for full-time work, check out our open positions on our [careers page](https://cline.bot/join-us)!

&lt;details&gt;
&lt;summary&gt;Local Development Instructions&lt;/summary&gt;

1. Clone the repository _(Requires [git-lfs](https://git-lfs.com/))_:
    ```bash
    git clone https://github.com/cline/cline.git
    ```
2. Open the project in VSCode:
    ```bash
    code cline
    ```
3. Install the necessary dependencies for the extension and webview-gui:
    ```bash
    npm run install:all
    ```
4. Launch by pressing `F5` (or `Run`-&gt;`Start Debugging`) to open a new VSCode window with the extension loaded. (You may need to install the [esbuild problem matchers extension](https://marketplace.visualstudio.com/items?itemName=connor4312.esbuild-problem-matchers) if you run into issues building the project.)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Creating a Pull Request&lt;/summary&gt;

1. Before creating a PR, generate a changeset entry:
    ```bash
    npm run changeset
    ```
   This will prompt you for:
   - Type of change (major, minor, patch)
     - `major` → breaking changes (1.0.0 → 2.0.0)
     - `minor` → new features (1.0.0 → 1.1.0)
     - `patch` → bug fixes (1.0.0 → 1.0.1)
   - Description of your changes

2. Commit your changes and the generated `.changeset` file

3. Push your branch and create a PR on GitHub. Our CI will:
   - Run tests and checks
   - Changesetbot will create a comment showing the version impact
   - When merged to main, changesetbot will create a Version Packages PR
   - When the Version Packages PR is merged, a new release will be published

&lt;/details&gt;


## License

[Apache 2.0 © 2025 Cline Bot Inc.](./LICENSE)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
    </channel>
</rss>