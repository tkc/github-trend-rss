<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Wed, 27 Aug 2025 00:05:42 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[0xJacky/nginx-ui]]></title>
            <link>https://github.com/0xJacky/nginx-ui</link>
            <guid>https://github.com/0xJacky/nginx-ui</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:42 GMT</pubDate>
            <description><![CDATA[Yet another WebUI for Nginx]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/0xJacky/nginx-ui">0xJacky/nginx-ui</a></h1>
            <p>Yet another WebUI for Nginx</p>
            <p>Language: Go</p>
            <p>Stars: 9,358</p>
            <p>Forks: 676</p>
            <p>Stars today: 27 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
      &lt;img src=&quot;resources/logo.png&quot; alt=&quot;Nginx UI Logo&quot;&gt;
&lt;/div&gt;

# Nginx UI

Yet another Nginx Web UI, developed by [0xJacky](https://jackyu.cn/), [Hintay](https://blog.kugeek.com/) and [Akino](https://github.com/akinoccc).

[![DeepWiki](https://img.shields.io/badge/DeepWiki-0xJacky%2Fnginx--ui-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/0xJacky/nginx-ui)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/0xJacky/nginx-ui)

[![Build and Publish](https://github.com/0xJacky/nginx-ui/actions/workflows/build.yml/badge.svg)](https://github.com/0xJacky/nginx-ui/actions/workflows/build.yml)
[![GitHub license](https://img.shields.io/github/license/0xJacky/nginx-ui?label=License&amp;logo=github)](https://github.com/0xJacky/nginx-ui &quot;Click to view the repo on Github&quot;)
[![Release Version](https://img.shields.io/github/release/0xJacky/nginx-ui?include_prereleases&amp;label=Release&amp;logo=github)](https://github.com/0xJacky/nginx-ui/releases/latest &quot;Click to view the repo on Github&quot;)
[![GitHub Star](https://img.shields.io/github/stars/0xJacky/nginx-ui?label=Stars&amp;logo=github)](https://github.com/0xJacky/nginx-ui &quot;Click to view the repo on Github&quot;)
[![GitHub Fork](https://img.shields.io/github/forks/0xJacky/nginx-ui?label=Forks&amp;logo=github)](https://github.com/0xJacky/nginx-ui &quot;Click to view the repo on Github&quot;)
[![Repo Size](https://img.shields.io/github/repo-size/0xJacky/nginx-ui?label=Size&amp;logo=github)](https://github.com/0xJacky/nginx-ui &quot;Click to view the repo on Github&quot;)
[![GitHub Fork](https://img.shields.io/github/issues-closed-raw/0xJacky/nginx-ui?label=Closed%20Issue&amp;logo=github)](https://github.com/0xJacky/nginx-ui/issues &quot;Click to view the repo on Github&quot;)

[![Docker Stars](https://img.shields.io/docker/stars/uozi/nginx-ui?label=Stars&amp;logo=docker)](https://hub.docker.com/r/uozi/nginx-ui &quot;Click to view the image on Docker Hub&quot;)
[![Docker Pulls](https://img.shields.io/docker/pulls/uozi/nginx-ui?label=Pulls&amp;logo=docker)](https://hub.docker.com/r/uozi/nginx-ui &quot;Click to view the image on Docker Hub&quot;)
[![Image Size](https://img.shields.io/docker/image-size/uozi/nginx-ui/latest?label=Image%20Size&amp;logo=docker)](https://hub.docker.com/r/uozi/nginx-ui &quot;Click to view the image on Docker Hub&quot;)

[![Translated Status](https://weblate.nginxui.com/widget/nginx-ui/frontend/svg-badge.svg)](https://weblate.nginxui.com/engage/nginx-ui/)
[![FeaturedÔΩúHelloGitHub](https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=86f3a8f779934748a34fe6f1b5cd442f&amp;claim_uid=MOFqadzAShCBeQj&amp;theme=small)](https://hellogithub.com/repository/86f3a8f779934748a34fe6f1b5cd442f)

## Documentation
To check out docs, visit [nginxui.com](https://nginxui.com).

## Sponsor

If you find this project helpful, please consider sponsoring us to support ongoing development and maintenance.

[![GitHub Sponsors](https://img.shields.io/badge/GitHub-Sponsors-ea4aaa?style=for-the-badge&amp;logo=github-sponsors&amp;logoColor=white)](https://github.com/sponsors/nginxui)
[![Afdian](https://img.shields.io/badge/Áà±ÂèëÁîµ-Support-946ce6?style=for-the-badge&amp;logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTEyIDJMMTMuMDkgOC4yNkwyMCA5TDEzLjA5IDE1Ljc0TDEyIDIyTDEwLjkxIDE1Ljc0TDQgOUwxMC45MSA4LjI2TDEyIDJaIiBmaWxsPSJ3aGl0ZSIvPgo8L3N2Zz4K)](https://afdian.com/a/nginxui)

Your support helps us:
- üöÄ Accelerate the development of new features
- üêõ Fix bugs and improve stability
- üìö Enhance documentation and tutorials
- üåê Provide better community support
- üíª Maintain infrastructure and demo servers

## Stargazers over time

[![Stargazers over time](https://starchart.cc/0xJacky/nginx-ui.svg)](https://starchart.cc/0xJacky/nginx-ui)

English | [Espa√±ol](README-es.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](README-zh_CN.md) | [ÁπÅÈ´î‰∏≠Êñá](README-zh_TW.md) | [Ti·∫øng Vi·ªát](README-vi_VN.md) | [Êó•Êú¨Ë™û](README-ja_JP.md)

&lt;details&gt;
  &lt;summary&gt;Table of Contents&lt;/summary&gt;
  &lt;ol&gt;
    &lt;li&gt;
      &lt;a href=&quot;#about-the-project&quot;&gt;About The Project&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&quot;#demo&quot;&gt;Demo&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#features&quot;&gt;Features&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#internationalization&quot;&gt;Internationalization&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#built-with&quot;&gt;Built With&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;a href=&quot;#getting-started&quot;&gt;Getting Started&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&quot;#before-use&quot;&gt;Before Use&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;
          &lt;a href=&quot;#usage&quot;&gt;Usage&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&quot;#from-executable&quot;&gt;From Executable&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&quot;#with-systemd&quot;&gt;With Systemd&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&quot;#with-docker&quot;&gt;With Docker&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;a href=&quot;#manual-build&quot;&gt;Manual Build&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&quot;#prerequisites&quot;&gt;Prerequisites&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#build-app&quot;&gt;Build Frontend&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#build-backend&quot;&gt;Build Backend&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;a href=&quot;#script-for-linux&quot;&gt;Script for Linux&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&quot;#basic-usage&quot;&gt;Basic Usage&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;#more-usage&quot;&gt;More Usage&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#example-of-nginx-reverse-proxy-configuration&quot;&gt;Example of Nginx Reverse Proxy Configuration&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/details&gt;

## About The Project

![Dashboard](resources/screenshots/dashboard_en.png)

### Demo
URLÔºö[https://demo.nginxui.com](https://demo.nginxui.com)
- UsernameÔºöadmin
- PasswordÔºöadmin

### Features

- Online statistics for server indicators such as CPU usage, memory usage, load average, and disk usage.
- Automatic configuration backup after changes, with version comparison and restore capabilities
- Cluster management supporting mirroring operations to multiple nodes, making multi-server environments easy to manage
- Export encrypted Nginx / Nginx UI configurations for quick deployment and recovery to new environments
- Enhanced online **ChatGPT** assistant supporting multiple models, including Deepseek-R1&#039;s chain-of-thought display to help you better understand and optimize configurations
- **MCP** (Model Context Protocol) provides special interfaces for AI agents to interact with Nginx UI, enabling automated configuration management and service control.
- One-click deployment and automatic renewal Let&#039;s Encrypt certificates.
- Online editing websites configurations with our self-designed **NgxConfigEditor** which is a user-friendly block editor for nginx configurations or **Ace Code Editor** which supports **LLM Code Completion** and highlighting nginx configuration syntax.
- Online view Nginx logs
- Written in Go and Vue, distribution is a single executable binary.
- Automatically test configuration file and reload nginx after saving configuration.
- Web Terminal
- Dark Mode
- Responsive Web Design

### Internationalization

We proudly offer official support for:

- English
- Simplified Chinese
- Traditional Chinese

As non-native English speakers, we strive for accuracy, but we know there&#039;s always room for improvement. If you spot any issues, we&#039;d love your feedback!

Thanks to our amazing community, additional languages are also available! Explore and contribute to translations on [Weblate](https://weblate.nginxui.com).

### Built With

- [The Go Programming Language](https://go.dev)
- [Gin Web Framework](https://gin-gonic.com)
- [GORM](http://gorm.io)
- [Vue 3](https://v3.vuejs.org)
- [Vite](https://vitejs.dev)
- [TypeScript](https://www.typescriptlang.org/)
- [Ant Design Vue](https://antdv.com)
- [vue3-gettext](https://github.com/jshmrtn/vue3-gettext)
- [vue3-ace-editor](https://github.com/CarterLi/vue3-ace-editor)
- [Gonginx](https://github.com/tufanbarisyildirim/gonginx)
- [lego](https://github.com/go-acme/lego)

## Getting Started

### Before Use

The Nginx UI follows the Debian web server configuration file standard. Created site configuration files will be placed in the `sites-available` folder that under the Nginx configuration folder (auto-detected). The configuration files for an enabled site will create a soft link to the `sites-enabled` folder. You may need to adjust the way the configuration files are organised.

For non-Debian (and Ubuntu) systems, you may need to change the contents of the `nginx.conf` configuration file to the Debian style as shown below.

```nginx
http {
	# ...
	include /etc/nginx/conf.d/*.conf;
	include /etc/nginx/sites-enabled/*;
}
```

For more information: [debian/conf/nginx.conf](https://salsa.debian.org/nginx-team/nginx/-/blob/master/debian/conf/nginx.conf#L59-L60)

### Installation

Nginx UI is available on the following platforms:

- macOS 11 Big Sur and later (amd64 / arm64)
- Windows 10 and later (amd64 / arm64)
- Linux 2.6.23 and later (x86 / amd64 / arm64 / armv5 / armv6 / armv7 / mips32 / mips64 / riscv64 / loongarch64)
  - Including but not limited to Debian 7 / 8, Ubuntu 12.04 / 14.04 and later, CentOS 6 / 7, Arch Linux
- FreeBSD
- OpenBSD
- Dragonfly BSD
- Openwrt

You can visit [latest release](https://github.com/0xJacky/nginx-ui/releases/latest) to download the latest distribution, or just use [installation scripts for Linux](#script-for-linux).

### Usage

In the first runtime of Nginx UI, please visit `http://&lt;your_server_ip&gt;:&lt;listen_port&gt;`
in your browser to complete the follow-up configurations.

#### From Executable
**Run Nginx UI in Terminal**

```shell
nginx-ui -config app.ini
```
Press `Control+C` in the terminal to exit Nginx UI.

**Run Nginx UI in Background**

```shell
nohup ./nginx-ui -config app.ini &amp;
```
Stop Nginx UI with the follow command.

```shell
kill -9 $(ps -aux | grep nginx-ui | grep -v grep | awk &#039;{print $2}&#039;)
```

#### With Systemd
If you are using the [installation script for Linux](#script-for-linux), the Nginx UI will be installed as `nginx-ui` service in systemd. Please use the `systemctl` command to control it.

**Start Nginx UI**

```shell
systemctl start nginx-ui
```
**Stop Nginx UI**

```shell
systemctl stop nginx-ui
```
**Restart Nginx UI**

```shell
systemctl restart nginx-ui
```

#### With Docker
Our docker image [uozi/nginx-ui:latest](https://hub.docker.com/r/uozi/nginx-ui) is based on the latest nginx image and
can be used to replace the Nginx on the host. By publishing the container&#039;s port 80 and 443 to the host,
you can easily make the switch.

##### Note
1. When using this container for the first time, ensure that the volume mapped to /etc/nginx is empty.
2. If you want to host static files, you can map directories to container.

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Deploy with Docker&lt;/b&gt;&lt;/summary&gt;

1. [Install Docker.](https://docs.docker.com/install/)

2. Then deploy nginx-ui like this:

```bash
docker run -dit \
  --name=nginx-ui \
  --restart=always \
  -e TZ=Asia/Shanghai \
  -v /mnt/user/appdata/nginx:/etc/nginx \
  -v /mnt/user/appdata/nginx-ui:/etc/nginx-ui \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -p 8080:80 -p 8443:443 \
  uozi/nginx-ui:latest
```

3. When your docker container is running, Log in to nginx-ui panel with `http://&lt;your_server_ip&gt;:8080/install`.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Deploy with Docker-Compose&lt;/b&gt;&lt;/summary&gt;

1. [Install Docker-Compose.](https://docs.docker.com/compose/install/)

2. Create a docker-compose.yml file like this:

```yml
services:
    nginx-ui:
        stdin_open: true
        tty: true
        container_name: nginx-ui
        restart: always
        environment:
            - TZ=Asia/Shanghai
        volumes:
            - &#039;/mnt/user/appdata/nginx:/etc/nginx&#039;
            - &#039;/mnt/user/appdata/nginx-ui:/etc/nginx-ui&#039;
            - &#039;/var/www:/var/www&#039;
            - &#039;/var/run/docker.sock:/var/run/docker.sock&#039;
        ports:
            - 8080:80
            - 8443:443
        image: &#039;uozi/nginx-ui:latest&#039;
```

3. Then creat your container by:
```bash
docker compose up -d
```

4. When your docker container is running, Log in to nginx-ui panel with `http://&lt;your_server_ip&gt;:8080/install`.

&lt;/details&gt;

## Manual Build

On platforms that do not have an official build version, they can be built manually.

### Prerequisites

- Make

- Golang 1.23+

- node.js 21+

  ```shell
  npx browserslist@latest --update-db
  ```

### Build Frontend

Please execute the following command in `app` directory.

```shell
pnpm install
pnpm build
```

### Build Backend

Please build the app first, and then execute the following command in the project root directory.

```shell
go generate
go build -tags=jsoniter -ldflags &quot;$LD_FLAGS -X &#039;github.com/0xJacky/Nginx-UI/settings.buildTime=$(date +%s)&#039;&quot; -o nginx-ui -v main.go
```

## Script for Linux

### Basic Usage

**Install and Upgrade**

```shell
bash -c &quot;$(curl -L https://cloud.nginxui.com/install.sh)&quot; @ install
```
The default listening port is `9000`, and the default HTTP Challenge port is `9180`.
If there is a port conflict, please modify `/usr/local/etc/nginx-ui/app.ini` manually,
then use `systemctl restart nginx-ui` to reload the Nginx UI service.

**Remove Nginx UI, except configuration and database files**

```shell
bash -c &quot;$(curl -L https://cloud.nginxui.com/install.sh)&quot; @ remove
```

### More Usage

````shell
bash -c &quot;$(curl -L https://cloud.nginxui.com/install.sh)&quot; @ help
````

## Example of Nginx Reverse Proxy Configuration

```nginx
server {
    listen          80;
    listen          [::]:80;

    server_name     &lt;your_server_name&gt;;
    rewrite ^(.*)$  https://$host$1 permanent;
}

map $http_upgrade $connection_upgrade {
    default upgrade;
    &#039;&#039;      close;
}

server {
    listen  443       ssl;
    listen  [::]:443  ssl;
    http2   on;

    server_name         &lt;your_server_name&gt;;

    ssl_certificate     /path/to/ssl_cert;
    ssl_certificate_key /path/to/ssl_cert_key;

    location / {
        proxy_set_header    Host                $host;
        proxy_set_header    X-Real-IP           $remote_addr;
        proxy_set_header    X-Forwarded-For     $proxy_add_x_forwarded_for;
        proxy_set_header    X-Forwarded-Proto   $scheme;
        proxy_http_version  1.1;
        proxy_set_header    Upgrade             $http_upgrade;
        proxy_set_header    Connection          $connection_upgrade;
        proxy_pass          http://127.0.0.1:9000/;
    }
}
```

## Contributing

Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you  make are **greatly appreciated**.

If you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag &quot;enhancement&quot;. Don&#039;t forget to give the project a star! Thanks again!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m &#039;Add some AmazingFeature&#039;`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## License

This project is provided under a GNU Affero General Public License v3.0 license that can be found in the [LICENSE](LICENSE) file. By using, distributing, or contributing to this project, you agree to the terms and conditions of this license.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kedacore/keda]]></title>
            <link>https://github.com/kedacore/keda</link>
            <guid>https://github.com/kedacore/keda</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:41 GMT</pubDate>
            <description><![CDATA[KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kedacore/keda">kedacore/keda</a></h1>
            <p>KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 9,392</p>
            <p>Forks: 1,213</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;images/logos/keda-word-colour.png&quot; width=&quot;300&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;font-size: 25px&quot; align=&quot;center&quot;&gt;&lt;b&gt;Kubernetes-based Event Driven Autoscaling&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;font-size: 25px&quot; align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/kedacore/keda/actions?query=workflow%3Amain-build&quot;&gt;&lt;img src=&quot;https://github.com/kedacore/keda/actions/workflows/main-build.yml/badge.svg&quot; alt=&quot;main build&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/kedacore/keda/actions?query=workflow%3Anightly-e2e-test&quot;&gt;&lt;img src=&quot;https://github.com/kedacore/keda/actions/workflows/nightly-e2e.yml/badge.svg&quot; alt=&quot;nightly e2e&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://bestpractices.coreinfrastructure.org/projects/3791&quot;&gt;&lt;img src=&quot;https://bestpractices.coreinfrastructure.org/projects/3791/badge&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://api.scorecard.dev/projects/github.com/kedacore/keda/badge&quot;&gt;&lt;img src=&quot;https://img.shields.io/ossf-scorecard/github.com/kedacore/keda?label=openssf%20scorecard&amp;style=flat&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://artifacthub.io/packages/helm/kedacore/keda&quot;&gt;&lt;img src=&quot;https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/kedacore&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fkedacore%2Fkeda?ref=badge_shield&quot; alt=&quot;FOSSA Status&quot;&gt;&lt;img src=&quot;https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fkedacore%2Fkeda.svg?type=shield&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://twitter.com/kedaorg&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/kedaorg?style=social&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;&lt;/p&gt;

KEDA allows for fine-grained autoscaling (including to/from zero) for event driven Kubernetes workloads. KEDA serves
as a Kubernetes Metrics Server and allows users to define autoscaling rules using a dedicated Kubernetes custom
resource definition.

KEDA can run on both the cloud and the edge, integrates natively with Kubernetes components such as the Horizontal
Pod Autoscaler, and has no external dependencies.

We are a Cloud Native Computing Foundation (CNCF) graduated project.
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/kedacore/keda/main/images/logo-cncf.svg&quot; height=&quot;75px&quot;&gt;&lt;/p&gt;

&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt;
&lt;!-- DON&#039;T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt;
**Table of contents**

- [Getting started](#getting-started)
  - [Deploying KEDA](#deploying-keda)
- [Documentation](#documentation)
- [Community](#community)
- [Adopters - Become a listed KEDA user!](#adopters---become-a-listed-keda-user)
- [Governance &amp; Policies](#governance--policies)
- [Support](#support)
- [Roadmap](#roadmap)
- [Releases](#releases)
- [Contributing](#contributing)
  - [Building &amp; deploying locally](#building--deploying-locally)
  - [Testing strategy](#testing-strategy)

&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt;

## Getting started

* [QuickStart - RabbitMQ and Go](https://github.com/kedacore/sample-go-rabbitmq)
* [QuickStart - Azure Functions and Queues](https://github.com/kedacore/sample-hello-world-azure-functions)
* [QuickStart - Azure Functions and Kafka on Openshift 4](https://github.com/kedacore/sample-azure-functions-on-ocp4)
* [QuickStart - Azure Storage Queue with ScaledJob](https://github.com/kedacore/sample-go-storage-queue)

You can find several samples for various event sources [here](https://github.com/kedacore/samples).

### Deploying KEDA

There are many ways to [deploy KEDA including Helm, Operator Hub and YAML files](https://keda.sh/docs/latest/deploy/).

## Documentation

Interested to learn more? Head over to [keda.sh](https://keda.sh).

## Community

If interested in contributing or participating in the direction of KEDA, you can join our community meetings! Learn more about them on [our website](https://keda.sh/community/).

Just want to learn or chat about KEDA? Feel free to join the conversation in
**[#KEDA](https://kubernetes.slack.com/messages/CKZJ36A5D)** on the **[Kubernetes Slack](https://slack.k8s.io/)**!

## Adopters - Become a listed KEDA user!

We are always happy to [list users](https://keda.sh/community/#users) who run KEDA in production, learn more about it [here](https://github.com/kedacore/keda-docs#become-a-listed-keda-user).

## Governance &amp; Policies

You can learn about the governance of KEDA [here](https://github.com/kedacore/governance).

## Support

Details on the KEDA support policy can found [here](https://keda.sh/support/).

## Roadmap

We use GitHub issues to build our backlog, a complete overview of all open items and our planning.

Learn more about our roadmap [here](ROADMAP.md).

## Releases

You can find the latest releases [here](https://github.com/kedacore/keda/releases).

## Contributing

You can find contributing guide [here](./CONTRIBUTING.md).

### Building &amp; deploying locally
Learn how to build &amp; deploy KEDA locally [here](./BUILD.md).

### Testing strategy
Learn more about our testing strategy [here](./TESTING.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[stretchr/testify]]></title>
            <link>https://github.com/stretchr/testify</link>
            <guid>https://github.com/stretchr/testify</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:40 GMT</pubDate>
            <description><![CDATA[A toolkit with common assertions and mocks that plays nicely with the standard library]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stretchr/testify">stretchr/testify</a></h1>
            <p>A toolkit with common assertions and mocks that plays nicely with the standard library</p>
            <p>Language: Go</p>
            <p>Stars: 25,072</p>
            <p>Forks: 1,667</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>Testify - Thou Shalt Write Tests
================================

&gt; [!NOTE]
&gt; Testify is being maintained at v1, no breaking changes will be accepted in this repo.  
&gt; [See discussion about v2](https://github.com/stretchr/testify/discussions/1560).

[![Build Status](https://github.com/stretchr/testify/actions/workflows/main.yml/badge.svg?branch=master)](https://github.com/stretchr/testify/actions/workflows/main.yml) [![Go Report Card](https://goreportcard.com/badge/github.com/stretchr/testify)](https://goreportcard.com/report/github.com/stretchr/testify) [![PkgGoDev](https://pkg.go.dev/badge/github.com/stretchr/testify)](https://pkg.go.dev/github.com/stretchr/testify)

Go code (golang) set of packages that provide many tools for testifying that your code will behave as you intend.

Features include:

  * [Easy assertions](#assert-package)
  * [Mocking](#mock-package)
  * [Testing suite interfaces and functions](#suite-package)

Get started:

  * Install testify with [one line of code](#installation), or [update it with another](#staying-up-to-date)
  * For an introduction to writing test code in Go, see https://go.dev/doc/code#Testing
  * Check out the API Documentation https://pkg.go.dev/github.com/stretchr/testify
  * Use [testifylint](https://github.com/Antonboom/testifylint) (via [golangci-lint](https://golangci-lint.run/)) to avoid common mistakes
  * A little about [Test-Driven Development (TDD)](https://en.wikipedia.org/wiki/Test-driven_development)

[`assert`](https://pkg.go.dev/github.com/stretchr/testify/assert &quot;API documentation&quot;) package
-------------------------------------------------------------------------------------------

The `assert` package provides some helpful methods that allow you to write better test code in Go.

  * Prints friendly, easy to read failure descriptions
  * Allows for very readable code
  * Optionally annotate each assertion with a message

See it in action:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	// assert equality
	assert.Equal(t, 123, 123, &quot;they should be equal&quot;)

	// assert inequality
	assert.NotEqual(t, 123, 456, &quot;they should not be equal&quot;)

	// assert for nil (good for errors)
	assert.Nil(t, object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(t, object) {
		// now we know that object isn&#039;t nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(t, &quot;Something&quot;, object.Value)
	}
}
```

  * Every assert func takes the `testing.T` object as the first argument.  This is how it writes the errors out through the normal `go test` capabilities.
  * Every assert func returns a bool indicating whether the assertion was successful or not, this is useful for if you want to go on making further assertions under certain conditions.

if you assert many times, use the below:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	assert := assert.New(t)

	// assert equality
	assert.Equal(123, 123, &quot;they should be equal&quot;)

	// assert inequality
	assert.NotEqual(123, 456, &quot;they should not be equal&quot;)

	// assert for nil (good for errors)
	assert.Nil(object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(object) {
		// now we know that object isn&#039;t nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(&quot;Something&quot;, object.Value)
	}
}
```

[`require`](https://pkg.go.dev/github.com/stretchr/testify/require &quot;API documentation&quot;) package
---------------------------------------------------------------------------------------------

The `require` package provides same global functions as the `assert` package, but instead of returning a boolean result they terminate current test.
These functions must be called from the goroutine running the test or benchmark function, not from other goroutines created during the test.
Otherwise race conditions may occur.

See [t.FailNow](https://pkg.go.dev/testing#T.FailNow) for details.

[`mock`](https://pkg.go.dev/github.com/stretchr/testify/mock &quot;API documentation&quot;) package
----------------------------------------------------------------------------------------

The `mock` package provides a mechanism for easily writing mock objects that can be used in place of real objects when writing test code.

An example test function that tests a piece of code that relies on an external object `testObj`, can set up expectations (testify) and assert that they indeed happened:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/mock&quot;
)

/*
  Test objects
*/

// MyMockedObject is a mocked object that implements an interface
// that describes an object that the code I am testing relies on.
type MyMockedObject struct {
	mock.Mock
}

// DoSomething is a method on MyMockedObject that implements some interface
// and just records the activity, and returns what the Mock object tells it to.
//
// In the real object, this method would do something useful, but since this
// is a mocked object - we&#039;re just going to stub it out.
//
// NOTE: This method is not being tested here, code that uses this object is.
func (m *MyMockedObject) DoSomething(number int) (bool, error) {
	args := m.Called(number)
	return args.Bool(0), args.Error(1)
}

/*
  Actual test functions
*/

// TestSomething is an example of how to use our test object to
// make assertions about some target code we are testing.
func TestSomething(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations
	testObj.On(&quot;DoSomething&quot;, 123).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)
}

// TestSomethingWithPlaceholder is a second example of how to use our test object to
// make assertions about some target code we are testing.
// This time using a placeholder. Placeholders might be used when the
// data being passed in is normally dynamically generated and cannot be
// predicted beforehand (eg. containing hashes that are time sensitive)
func TestSomethingWithPlaceholder(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

}

// TestSomethingElse2 is a third example that shows how you can use
// the Unset method to cleanup handlers and then add new ones.
func TestSomethingElse2(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	mockCall := testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

	// remove the handler now so we can add another one that takes precedence
	mockCall.Unset()

	// return false now instead of true
	testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(false, nil)

	testObj.AssertExpectations(t)
}
```

For more information on how to write mock code, check out the [API documentation for the `mock` package](https://pkg.go.dev/github.com/stretchr/testify/mock).

You can use the [mockery tool](https://vektra.github.io/mockery/latest/) to autogenerate the mock code against an interface as well, making using mocks much quicker.

[`suite`](https://pkg.go.dev/github.com/stretchr/testify/suite &quot;API documentation&quot;) package
-----------------------------------------------------------------------------------------
&gt; [!WARNING]
&gt; The suite package does not support parallel tests. See [#934](https://github.com/stretchr/testify/issues/934).

The `suite` package provides functionality that you might be used to from more common object-oriented languages.  With it, you can build a testing suite as a struct, build setup/teardown methods and testing methods on your struct, and run them with &#039;go test&#039; as per normal.

An example suite is shown below:

```go
// Basic imports
import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
	&quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including a T() method which
// returns the current testing context
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	assert.Equal(suite.T(), 5, suite.VariableThatShouldStartAtFive)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
```

For a more complete example, using all of the functionality provided by the suite package, look at our [example testing suite](https://github.com/stretchr/testify/blob/master/suite/suite_test.go)

For more information on writing suites, check out the [API documentation for the `suite` package](https://pkg.go.dev/github.com/stretchr/testify/suite).

`Suite` object has assertion methods:

```go
// Basic imports
import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including assertion methods.
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	suite.Equal(suite.VariableThatShouldStartAtFive, 5)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
```

------

Installation
============

To install Testify, use `go get`:

    go get github.com/stretchr/testify

This will then make the following packages available to you:

    github.com/stretchr/testify/assert
    github.com/stretchr/testify/require
    github.com/stretchr/testify/mock
    github.com/stretchr/testify/suite
    github.com/stretchr/testify/http (deprecated)

Import the `testify/assert` package into your code using this template:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	assert.True(t, true, &quot;True is true!&quot;)
}
```

------

Staying up to date
==================

To update Testify to the latest version, use `go get -u github.com/stretchr/testify`.

------

Supported go versions
==================

We currently support the most recent major Go versions from 1.19 onward.

------

Contributing
============

Please feel free to submit issues, fork the repository and send pull requests!

When submitting an issue, we ask that you please include a complete test function that demonstrates the issue. Extra credit for those using Testify to write the test code that demonstrates it.

Code generation is used. [Look for `Code generated with`](https://github.com/search?q=repo%3Astretchr%2Ftestify%20%22Code%20generated%20with%22&amp;type=code) at the top of some files. Run `go generate ./...` to update generated files.

We also chat on the [Gophers Slack](https://gophers.slack.com) group in the `#testify` and `#testify-dev` channels.

------

License
=======

This project is licensed under the terms of the MIT license.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-collector]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-collector</link>
            <guid>https://github.com/open-telemetry/opentelemetry-collector</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:39 GMT</pubDate>
            <description><![CDATA[OpenTelemetry Collector]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-collector">open-telemetry/opentelemetry-collector</a></h1>
            <p>OpenTelemetry Collector</p>
            <p>Language: Go</p>
            <p>Stars: 5,719</p>
            <p>Forks: 1,712</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>---

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/getting-started/&quot;&gt;Getting Started&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;Getting Involved&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;Getting In Touch&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/actions/workflows/build-and-test.yml?query=branch%3Amain&quot;&gt;
    &lt;img alt=&quot;Build Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector/build-and-test.yml?branch=main&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector&quot;&gt;
    &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/open-telemetry/opentelemetry-collector/branch/main/&quot;&gt;
    &lt;img alt=&quot;Codecov Status&quot; src=&quot;https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest by date including pre-releases)&quot; src=&quot;https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector?include_prereleases&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;/br&gt;
  &lt;a href=&quot;https://www.bestpractices.dev/projects/8404&quot;&gt;&lt;img src=&quot;https://www.bestpractices.dev/projects/8404/badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:opentelemetry&quot;&gt;
    &lt;img alt=&quot;Fuzzing Status&quot; src=&quot;https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry.svg&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;docs/vision.md&quot;&gt;Vision&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/configuration/&quot;&gt;Configuration&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/internal-telemetry/#use-internal-telemetry-to-monitor-the-collector&quot;&gt;Monitoring&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;docs/security-best-practices.md&quot;&gt;Security&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://pkg.go.dev/go.opentelemetry.io/collector&quot;&gt;Package&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

---

# &lt;img src=&quot;https://opentelemetry.io/img/logos/opentelemetry-logo-nav.png&quot; alt=&quot;OpenTelemetry Icon&quot; width=&quot;45&quot; height=&quot;&quot;&gt; OpenTelemetry Collector

The OpenTelemetry Collector offers a vendor-agnostic implementation on how to
receive, process and export telemetry data. In addition, it removes the need
to run, operate and maintain multiple agents/collectors in order to support
open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) to
multiple open-source or commercial back-ends.

Objectives:

- Usable: Reasonable default configuration, supports popular protocols, runs and collects out of the box.
- Performant: Highly stable and performant under varying loads and configurations.
- Observable: An exemplar of an observable service.
- Extensible: Customizable without touching the core code.
- Unified: Single codebase, deployable as an agent or collector with support for traces, metrics and logs.

## Community

The OpenTelemetry Collector SIG is present at the [#otel-collector](https://cloud-native.slack.com/archives/C01N6P7KR6W)
channel on the CNCF Slack and [meets once a week](https://github.com/open-telemetry/community#implementation-sigs) via
video calls. Everyone is invited to join those calls, which typically serves the following purposes:

- meet the humans behind the project
- get an opinion about specific proposals
- look for a sponsor for a proposed component after trying already via GitHub and Slack
- get attention to a specific pull-request that got stuck and is difficult to discuss asynchronously

We rotate our video calls between three time slots, in order to
allow everyone to join at least once every three meetings. The rotation order is as follows:

Tuesday:

- [17:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=1700)

Wednesday:

- [09:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=0900)
- [05:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=0500)

Contributors to the project are also welcome to have ad-hoc meetings for synchronous discussions about specific points.
Post a note in #otel-collector-dev on Slack inviting others, specifying the topic to be discussed. Unless there are strong
reasons to keep the meeting private, please make it an open invitation for other contributors to join. Try also to
identify who would be the other contributors interested on that topic and in which timezones they are.

Remember that our source of truth is GitHub: every decision made via Slack or video calls has to be recorded in the
relevant GitHub issue. Ideally, the agenda items from the meeting notes would include a link to the issue or pull
request where a discussion is happening already. We acknowledge that not everyone can join Slack or the synchronous
calls and don&#039;t want them to feel excluded.

## Supported OTLP version

This code base is currently built against using OTLP protocol v1.5.0,
considered Stable. [See the OpenTelemetry Protocol Stability
definition
here.](https://github.com/open-telemetry/opentelemetry-proto?tab=readme-ov-file#stability-definition)

## Stability levels

See [Stability Levels and versioning](docs/component-stability.md) for more details.

## Compatibility

When used as a library, the OpenTelemetry Collector attempts to track the currently supported versions of Go, as [defined by the Go team](https://go.dev/doc/devel/release#policy).
Removing support for an unsupported Go version is not considered a breaking change.

Support for Go versions on the OpenTelemetry Collector is updated as follows:

1. The first release after the release of a new Go minor version `N` will add build and tests steps for the new Go minor version.
2. The first release after the release of a new Go minor version `N` will remove support for Go version `N-2`.

Official OpenTelemetry Collector distro binaries will be built with a release in the latest Go minor version series.

## Verifying the images signatures

&gt; [!NOTE]
&gt; To verify a signed artifact or blob, first [install Cosign](https://docs.sigstore.dev/cosign/system_config/installation/), then follow the instructions below.

We are signing the images `otel/opentelemetry-collector` and `otel/opentelemetry-collector-contrib` using [sigstore cosign](https://github.com/sigstore/cosign) tool and to verify the signatures you can run the following command:

```console
$ cosign verify \
  --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/&lt;RELEASE_TAG&gt; \
  --certificate-oidc-issuer=https://token.actions.githubusercontent.com \
  &lt;OTEL_COLLECTOR_IMAGE&gt;
```

where:

- `&lt;RELEASE_TAG&gt;`: is the release that you want to validate
- `&lt;OTEL_COLLECTOR_IMAGE&gt;`: is the image that you want to check

Example:

```console
$ cosign verify --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0 --certificate-oidc-issuer=https://token.actions.githubusercontent.com ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0

Verification for ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0 --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - Existence of the claims in the transparency log was verified offline
  - The code-signing certificate was verified using trusted certificate authority certificates

[{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:{&quot;1.3.6.1.4.1.57264.1.1&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;1.3.6.1.4.1.57264.1.2&quot;:&quot;push&quot;,&quot;1.3.6.1.4.1.57264.1.3&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;1.3.6.1.4.1.57264.1.4&quot;:&quot;Release Contrib&quot;,&quot;1.3.6.1.4.1.57264.1.5&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;1.3.6.1.4.1.57264.1.6&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;Bundle&quot;:{&quot;SignedEntryTimestamp&quot;:&quot;MEUCIQDdlmNeKXQrHnonwWiHLhLLwFDVDNoOBCn2sv85J9P8mgIgDQFssWJImo1hn38VlojvSCL7Qq5FMmtnGu0oLsNdOm8=&quot;,&quot;Payload&quot;:{&quot;body&quot;:&quot;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&quot;,&quot;integratedTime&quot;:1712809120,&quot;logIndex&quot;:84797936,&quot;logID&quot;:&quot;c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d&quot;}},&quot;Issuer&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;Subject&quot;:&quot;https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0&quot;,&quot;githubWorkflowName&quot;:&quot;Release Contrib&quot;,&quot;githubWorkflowRef&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;githubWorkflowRepository&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;githubWorkflowSha&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;githubWorkflowTrigger&quot;:&quot;push&quot;}},{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:{&quot;1.3.6.1.4.1.57264.1.1&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;1.3.6.1.4.1.57264.1.2&quot;:&quot;push&quot;,&quot;1.3.6.1.4.1.57264.1.3&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;1.3.6.1.4.1.57264.1.4&quot;:&quot;Release Contrib&quot;,&quot;1.3.6.1.4.1.57264.1.5&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;1.3.6.1.4.1.57264.1.6&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;Bundle&quot;:{&quot;SignedEntryTimestamp&quot;:&quot;MEUCIQD1ehDnPO6fzoPIpeQ3KFuYHHBiX7RcEbpo9B2r7JAlzwIgZ1bsuQz7gAXbNU1IEdsTQgfAnRk3xVXO16GnKXM2sAQ=&quot;,&quot;Payload&quot;:{&quot;body&quot;:&quot;eyJhcGlWZXJzaW9uIjoiMC4wLjEiLCJraW5kIjoiaGFzaGVkcmVrb3JkIiwic3BlYyI6eyJkYXRhIjp7Imhhc2giOnsiYWxnb3JpdGhtIjoic2hhMjU2IiwidmFsdWUiOiIxMzVjY2RlN2YzZTNhYjU2NmFmYzJhYWU3MDljYmJlNmFhMDZlZWMzNDA2MWNkZjMyNmRhYzM2MmY0NWM4Yjg4In19LCJzaWduYXR1cmUiOnsiY29udGVudCI6Ik1FUUNJRU92QXl0aE5RVGNvNHFMdG9GZUVOV0toNCtEK2I5SUxyYWhoa09WMmVBM0FpQjNEL2FpUGd1T05zUlB5alhaWk1hdnlCam0vMkVxNFNUMkZJWHozTnpyYWc9PSIsInB1YmxpY0tleSI6eyJjb250ZW50IjoiTFMwdExTMUNSVWRKVGlCRFJWSlVTVVpKUTBGVVJTMHRMUzB0Q2sxSlNVaHBSRU5EUW5jMlowRjNTVUpCWjBsVlZuRlRLMnd4WXpoMWVFUktOWEppZDAxMlVuaDBSR3hXVW1nMGQwTm5XVWxMYjFwSmVtb3dSVUYzVFhjS1RucEZWazFDVFVkQk1WVkZRMmhOVFdNeWJHNWpNMUoyWTIxVmRWcEhWakpOVWpSM1NFRlpSRlpSVVVSRmVGWjZZVmRrZW1SSE9YbGFVekZ3WW01U2JBcGpiVEZzV2tkc2FHUkhWWGRJYUdOT1RXcFJkMDVFUlhoTlJGRjRUMFJSZVZkb1kwNU5hbEYzVGtSRmVFMUVVWGxQUkZGNVYycEJRVTFHYTNkRmQxbElDa3R2V2tsNmFqQkRRVkZaU1V0dldrbDZhakJFUVZGalJGRm5RVVYyWlRCdGJrRkdRVzl1TVZoUGRIVlRMMXBNT0djeE5YUlJkVmxPTmtRemVUUlBWM0FLT1ZSTFMwUlVkRkJHU2xST1ZrWlJkVTlKUWs1bVJqWk1ORTlGYkd4dlZuUndaSE5uYjB0NVZGTnlPR3hTV1c1S1JIRlBRMEpwTUhkbloxbHdUVUUwUndwQk1WVmtSSGRGUWk5M1VVVkJkMGxJWjBSQlZFSm5UbFpJVTFWRlJFUkJTMEpuWjNKQ1owVkdRbEZqUkVGNlFXUkNaMDVXU0ZFMFJVWm5VVlZDSzFkSENuVmtlRE5IZUcxS1RWUkpUVVJyYW13clJtdzFXRzkzZDBoM1dVUldVakJxUWtKbmQwWnZRVlV6T1ZCd2VqRlphMFZhWWpWeFRtcHdTMFpYYVhocE5Ga0tXa1E0ZDJkWldVZEJNVlZrUlZGRlFpOTNVamhOU0hGSFpVZG9NR1JJUW5wUGFUaDJXakpzTUdGSVZtbE1iVTUyWWxNNWRtTkhWblZNV0ZKc1lrZFdkQXBhV0ZKNVpWTTVkbU5IVm5Wa1IxWnpXbGN4YkdSSVNqVk1WMDUyWWtkNGJGa3pVblpqYVRGNVdsZDRiRmxZVG14amVUaDFXakpzTUdGSVZtbE1NMlIyQ21OdGRHMWlSemt6WTNrNWFWbFlUbXhNV0Vwc1lrZFdhR015VlhWbFYwWjBZa1ZDZVZwWFducE1NMUpvV2pOTmRtUnFRWFZQVkdkMVRVUkJOVUpuYjNJS1FtZEZSVUZaVHk5TlFVVkNRa04wYjJSSVVuZGplbTkyVEROU2RtRXlWblZNYlVacVpFZHNkbUp1VFhWYU1td3dZVWhXYVdSWVRteGpiVTUyWW01U2JBcGlibEYxV1RJNWRFMUNTVWREYVhOSFFWRlJRbWMzT0hkQlVVbEZRa2hDTVdNeVozZE9aMWxMUzNkWlFrSkJSMFIyZWtGQ1FYZFJiMDlYVlhsTlIwcHRDazVYVFhoT1JFcHNUbFJOZDA1NlFtcFpNa2swVFhwSmQxbFVTWGROZWtVeFdtMWFiVmxxVVhoT1JGazFXbFJCWkVKbmIzSkNaMFZGUVZsUEwwMUJSVVVLUWtFNVUxcFhlR3haV0U1c1NVVk9kbUp1VW5saFYwbDNVRkZaUzB0M1dVSkNRVWRFZG5wQlFrSlJVWFppTTBKc1lta3hNRnBYZUd4aVYxWXdZMjVyZGdwaU0wSnNZbTVTYkdKSFZuUmFXRko1WlZNeGFtSXllSE5hVjA0d1lqTkpkR050Vm5OYVYwWjZXbGhOZDBoM1dVdExkMWxDUWtGSFJIWjZRVUpDWjFGU0NtTnRWbTFqZVRrd1dWZGtla3d6V1hkTWFtczBUR3BCZDA5M1dVdExkMWxDUWtGSFJIWjZRVUpEUVZGMFJFTjBiMlJJVW5kamVtOTJURE5TZG1FeVZuVUtURzFHYW1SSGJIWmliazExV2pKc01HRklWbWxrV0U1c1kyMU9kbUp1VW14aWJsRjFXVEk1ZEUxSlIwbENaMjl5UW1kRlJVRlpUeTlOUVVWS1FraHZUUXBsUjJnd1pFaENlazlwT0haYU1td3dZVWhXYVV4dFRuWmlVemwyWTBkV2RVeFlVbXhpUjFaMFdsaFNlV1ZUT1haalIxWjFaRWRXYzFwWE1XeGtTRW8xQ2t4WFRuWmlSM2hzV1ROU2RtTnBNWGxhVjNoc1dWaE9iR041T0hWYU1td3dZVWhXYVV3elpIWmpiWFJ0WWtjNU0yTjVPV2xaV0U1c1RGaEtiR0pIVm1nS1l6SlZkV1ZYUm5SaVJVSjVXbGRhZWt3elVtaGFNMDEyWkdwQmRVOVVaM1ZOUkVFMFFtZHZja0puUlVWQldVOHZUVUZGUzBKRGIwMUxSR3hzVFdwQ2FRcGFhbFpxVFZSUmVWcFVWWHBOUkdOM1dUSk9hVTlFVFhsTlIwVjVUVVJOZUU1WFdtMWFiVWt3VFZSUk1rOVhWWGRJVVZsTFMzZFpRa0pCUjBSMmVrRkNDa04zVVZCRVFURnVZVmhTYjJSWFNYUmhSemw2WkVkV2EwMUdTVWREYVhOSFFWRlJRbWMzT0hkQlVYZEZVa0Y0UTJGSVVqQmpTRTAyVEhrNWJtRllVbThLWkZkSmRWa3lPWFJNTWpsM1dsYzBkR1JIVm5OYVZ6RnNaRWhLTlV3eU9YZGFWelV3V2xkNGJHSlhWakJqYm10MFdUSTVjMkpIVm1wa1J6bDVURmhLYkFwaVIxWm9ZekpXZWsxRVowZERhWE5IUVZGUlFtYzNPSGRCVVRCRlMyZDNiMDlYVlhsTlIwcHRUbGROZUU1RVNteE9WRTEzVG5wQ2Fsa3lTVFJOZWtsM0NsbFVTWGROZWtVeFdtMWFiVmxxVVhoT1JGazFXbFJCYUVKbmIzSkNaMFZGUVZsUEwwMUJSVTlDUWsxTlJWaEtiRnB1VFhaa1IwWnVZM2s1TWsxRE5EVUtUME0wZDAxQ2EwZERhWE5IUVZGUlFtYzNPSGRCVVRoRlEzZDNTazVFUVhkTmFsVjZUbXBqTWsxRVJVZERhWE5IUVZGUlFtYzNPSGRCVWtGRlNYZDNhQXBoU0ZJd1kwaE5Oa3g1T1c1aFdGSnZaRmRKZFZreU9YUk1NamwzV2xjMGRHUkhWbk5hVnpGc1pFaEtOVTFDWjBkRGFYTkhRVkZSUW1jM09IZEJVa1ZGQ2tObmQwbE9SR3MxVDFSbmQwMUVTWGRuV1hOSFEybHpSMEZSVVVKbk56aDNRVkpKUldaUmVEZGhTRkl3WTBoTk5reDVPVzVoV0ZKdlpGZEpkVmt5T1hRS1RESTVkMXBYTkhSa1IxWnpXbGN4YkdSSVNqVk1NamwzV2xjMU1GcFhlR3hpVjFZd1kyNXJkRmt5T1hOaVIxWnFaRWM1ZVV4WVNteGlSMVpvWXpKV2VncE1lVFZ1WVZoU2IyUlhTWFprTWpsNVlUSmFjMkl6WkhwTU0wcHNZa2RXYUdNeVZYUlpNamwxWkVoS2NGbHBOVFZaVnpGelVVaEtiRnB1VFhaa1IwWnVDbU41T1RKTlF6UTFUME0wZDAxRVowZERhWE5IUVZGUlFtYzNPSGRCVWsxRlMyZDNiMDlYVlhsTlIwcHRUbGROZUU1RVNteE9WRTEzVG5wQ2Fsa3lTVFFLVFhwSmQxbFVTWGROZWtVeFdtMWFiVmxxVVhoT1JGazFXbFJCVlVKbmIzSkNaMFZGUVZsUEwwMUJSVlZDUVZsTlFraENNV015WjNka1VWbExTM2RaUWdwQ1FVZEVkbnBCUWtaUlVtNUVSMVp2WkVoU2QyTjZiM1pNTW1Sd1pFZG9NVmxwTldwaU1qQjJZak5DYkdKcE1UQmFWM2hzWWxkV01HTnVhM1ppTTBKc0NtSnVVbXhpUjFaMFdsaFNlV1ZUTVdwaU1uaHpXbGRPTUdJelNYUmpiVlp6V2xkR2VscFlUWFpaVjA0d1lWYzVkV041T1hsa1Z6VjZUSHBuTWs1RVJYZ0tUbnBGTVU1cVkzWlpXRkl3V2xjeGQyUklUWFpOYWtGWFFtZHZja0puUlVWQldVOHZUVUZGVjBKQlowMUNia0l4V1cxNGNGbDZRMEpwZDFsTFMzZFpRZ3BDUVVoWFpWRkpSVUZuVWpsQ1NITkJaVkZDTTBGT01EbE5SM0pIZUhoRmVWbDRhMlZJU214dVRuZExhVk5zTmpRemFubDBMelJsUzJOdlFYWkxaVFpQQ2tGQlFVSnFjM1JvUjJKSlFVRkJVVVJCUldkM1VtZEphRUZQZUZNM2RteDRjVzVGYTBKVVRtSlZVRUpsUkZSbk0waGtlRlkyY0cxWk9FdGliREV6TjNBS1lWUnViMEZwUlVFelMyMUxVbU5uYWxBeVQzSmxORVpyVm5vNU4xaENNWGRsUzBOeWFXazFTMWx2UTB0bVkxRktSREJS

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ibnaleem/gosearch]]></title>
            <link>https://github.com/ibnaleem/gosearch</link>
            <guid>https://github.com/ibnaleem/gosearch</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:38 GMT</pubDate>
            <description><![CDATA[üîç Search anyone's digital footprint across 300+ websites]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ibnaleem/gosearch">ibnaleem/gosearch</a></h1>
            <p>üîç Search anyone's digital footprint across 300+ websites</p>
            <p>Language: Go</p>
            <p>Stars: 2,841</p>
            <p>Forks: 280</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>&lt;p align=&#039;center&#039;&gt;
&lt;img src=&#039;img/gosearch-logo.png&#039; height=50% width=50%&gt;&lt;br&gt;
&lt;i&gt;This project heavily relies on contributors, please see &lt;a href=&quot;#contributing&quot;&gt;Contributing&lt;/a&gt; for more details.&lt;/i&gt;&lt;br&gt;
&lt;code&gt;go install github.com/ibnaleem/gosearch@latest&lt;/code&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/ibnaleem/gosearch/actions/workflows/go.yml/badge.svg?event=push&quot; alt=&quot;GitHub Actions Badge&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/last-commit/ibnaleem/gosearch&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/commit-activity/w/ibnaleem/gosearch&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/contributors/ibnaleem/gosearch&quot;&gt; &lt;img alt=&quot;Number of websites&quot; src=&quot;https://img.shields.io/badge/websites-305-blue&quot;&gt; &lt;img alt=&quot;GitHub repo size&quot; src=&quot;https://img.shields.io/github/repo-size/ibnaleem/gosearch&quot;&gt; &lt;img alt=&quot;GitHub License&quot; src=&quot;https://img.shields.io/github/license/ibnaleem/gosearch&quot;&gt;
&lt;/p&gt;
&lt;hr&gt;

## Overview
&lt;p align=&#039;center&#039;&gt;
&lt;img src=&#039;img/1.png&#039; height=80% width=80%&gt;&lt;br&gt;
&lt;img src=&#039;img/2.png&#039; height=80% width=80%&gt;&lt;br&gt;
&lt;img src=&#039;img/3.png&#039; height=80% width=80%&gt;&lt;br&gt;
&lt;img src=&#039;img/4.png&#039; height=80% width=80%&gt;&lt;br&gt;
&lt;/p&gt;

You don&#039;t have time searching every profile with a username. Instead, you can leverage concurrency and a binary that does the work for you, and then some.

I initially wrote this project to learn Go, an upcoming programming language used for backend services. I decided to create a Sherlock clone, addressing some of its faults, limitations, and adding more features. This eventually led to a community driven OSINT tool that was [praised in the OSINT letter.](https://osintnewsletter.com/p/62)

GoSearch isn&#039;t limited to searching websites; it can search **900k leaked credentials** from [HudsonRock&#039;s Cybercrime Intelligence API](https://cavalier.hudsonrock.com/api/json/v2/osint-tools/search-by-username?username=mrrobot), over **3.2 billion leaked credentials** from [ProxyNova&#039;s Combination Of Many Breaches API](https://www.proxynova.com/tools/comb/), and **18 billion leaked credentials** from BreachDirectory.org with an API key (see [Use Cases](#use-cases))

## Installation
&gt; [!WARNING]  
&gt; If you are on 32-bit architecture, please [use this branch](https://github.com/ibnaleem/gosearch/tree/32-bit) or GoSearch will fail to build. For an in-depth overview of this issue, please see [#72](https://github.com/ibnaleem/gosearch/issues/72)

&gt; [!WARNING]  
&gt; If you&#039;re using Windows Defender, it might mistakenly flag GoSearch as malware. Rest assured, GoSearch is not malicious; you can review the full source code yourself to verify this. For an in-depth overview of this issue, please see [#90](https://github.com/ibnaleem/gosearch/issues/90)
```
$ go install github.com/ibnaleem/gosearch@latest
```
### Unix:
```
$ gosearch -u [username]
```
### Windows
```
C:\Users\Bob&gt; gosearch.exe -u [username]
```
## Use Cases
Ideally, it is best practice to run GoSearch with the `--no-false-positives` flag:
```
$ gosearch -u [USERNAME] --no-false-positives
```
This will display profiles GoSearch is confident exist on a website. GoSearch also allows you to search [BreachDirectory](https://breachdirectory.org) for compromised passwords associated with a specific username. For this, you must [obtain an API key](https://rapidapi.com/rohan-patra/api/breachdirectory) and provide it with the `-b` flag:
```
$ gosearch -u [USERNAME] -b [API-KEY] --no-false-positives
```
If GoSearch finds password hashes, it will attempt to crack them using [Weakpass](https://weakpass.com). The success rate is nearly 100%, as Weakpass uses a large wordlist of common data-wells, which align with the breaches reported by [BreachDirectory](https://breachdirectory.org). Every single password hash that&#039;s been found in [BreachDirectory](https://breachdirectory.org) has been cracked by [Weakpass](https://weakpass.com).

If you&#039;re not using BreachDirectory, GoSearch will search for breaches on HudsonRock&#039;s Cybercrime Intelligence &amp; ProxyNova&#039;s Databases, respectively. It will also search common TLDs for any domains associated with a given username. This is done whether BreachDirectory is searched or not.

## I Don&#039;t Have a Username
If you&#039;re uncertain about a person&#039;s username, you could try generating some by using [urbanadventurer/username-anarchy](https://github.com/urbanadventurer/username-anarchy). Note that `username-anarchy` can only run in Unix terminals (Mac/Linux)
```
$ git clone https://github.com/urbanadventurer/username-anarchy
$ cd username-anarchy
$ (username-anarchy) ./username-anarchy firstname lastname
```
## Why `GoSearch`?
`GoSearch` is inspired by [Sherlock](https://github.com/sherlock-project/sherlock), a popular username search tool. However, `GoSearch` improves upon Sherlock by addressing several of its key limitations:

1. Sherlock is Python-based, which makes it slower compared to Go.
2. Sherlock is outdated and lacks updates.
3. Sherlock sometimes reports false positives as valid results.
4. Sherlock frequently misses actual usernames, leading to false negatives.
5. Sherlock does not search HudsonRock&#039;s Cybercrime Intelligence database
6. Sherlock does not search ProxyNova&#039;s database
7. Sherlock does not search BreachDirectory&#039;s database

The primary issue with Sherlock is false negatives‚Äîwhen a username exists on a platform but is not detected. The secondary issue is false positives, where a username is incorrectly flagged as available. `GoSearch` tackles these problems by colour-coding uncertain results as yellow which indicates potential false positives. This allows users to easily filter out irrelevant links.

## Contributing
Please see [CONTRIBUTING.md.](https://github.com/ibnaleem/gosearch/blob/main/CONTRIBUTING.md)

&lt;table&gt;&lt;tr&gt;&lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/ibnaleem&quot;&gt;&lt;img alt=&quot;ibnaleem&quot; src=&quot;https://avatars.githubusercontent.com/u/134088573?v=4&quot; width=&quot;117&quot; /&gt;&lt;br /&gt;ibnaleem&lt;/a&gt;&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/shelepuginivan&quot;&gt;&lt;img alt=&quot;shelepuginivan&quot; src=&quot;https://avatars.githubusercontent.com/u/110753839?v=4&quot; width=&quot;117&quot; /&gt;&lt;br /&gt;shelepuginivan&lt;/a&gt;&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/arealibusadrealiora&quot;&gt;&lt;img alt=&quot;arealibusadrealiora&quot; src=&quot;https://avatars.githubusercontent.com/u/113445322?v=4&quot; width=&quot;117&quot; /&gt;&lt;br /&gt;arealibusadrealiora&lt;/a&gt;&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/AtahanPoyraz&quot;&gt;&lt;img alt=&quot;AtahanPoyraz&quot; src=&quot;https://avatars.githubusercontent.com/u/129458900?v=4&quot; width=&quot;117&quot; /&gt;&lt;br /&gt;AtahanPoyraz&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/vickychhetri&quot;&gt;&lt;img alt=&quot;vickychhetri&quot; src=&quot;https://avatars.githubusercontent.com/u/82648574?v=4&quot; width=&quot;117&quot; /&gt;&lt;br /&gt;vickychhetri&lt;/a&gt;&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/olekukonko&quot;&gt;&lt;img alt=&quot;olekukonko&quot; src=&quot;https://avatars.githubusercontent.com/u/2615393?v=4&quot; width=&quot;117&quot; /&gt;&lt;br /&gt;olekukonko&lt;/a&gt;&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/CptIdea&quot;&gt;&lt;img alt=&quot;CptIdea&quot; src=&quot;https://avatars.githubusercontent.com/u/59538729?v=4&quot; width=&quot;117&quot; /&gt;&lt;br /&gt;CptIdea&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/anotherhadi&quot;&gt;&lt;img alt=&quot;anotherhadi&quot; src=&quot;https://avatars.githubusercontent.com/u/112569860?v=4&quot; width=&quot;117&quot; /&gt;&lt;br /&gt;anotherhadi&lt;/a&gt;&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/paulpogoda&quot;&gt;&lt;img alt=&quot;paulpogoda&quot; src=&quot;https://avatars.githubusercontent.com/u/170966925?v=4&quot; width=&quot;117&quot; /&gt;&lt;br /&gt;paulpogoda&lt;/a&gt;&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/apps/dependabot&quot;&gt;&lt;img alt=&quot;dependabot[bot]&quot; src=&quot;https://avatars.githubusercontent.com/in/29110?v=4&quot; width=&quot;117&quot; /&gt;&lt;br /&gt;dependabot[bot]&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

## LICENSE
This project is licensed under the GNU General Public License - see the [LICENSE](https://github.com/ibnaleem/gosearch/blob/main/LICENSE) file for details.

## Support
[![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&amp;logo=buy-me-a-coffee&amp;logoColor=black)](https://buymeacoffee.com/gosearch)
[![Thanks.dev](https://img.shields.io/badge/thanks.dev-0a0a0a?style=for-the-badge&amp;logo=tv-time&amp;logoColor=white)](https://thanks.dev/u/gh/ibnaleem)
### Bitcoin
```
bc1qjrtyq8m7urapu7cvmvrrs6m7qkh2jpn5wqezfl
```
## Stargazers Over Time
[![Stargazers over time](https://starchart.cc/ibnaleem/gosearch.svg?variant=adaptive)](https://starchart.cc/ibnaleem/gosearch)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[argoproj/argo-cd]]></title>
            <link>https://github.com/argoproj/argo-cd</link>
            <guid>https://github.com/argoproj/argo-cd</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:37 GMT</pubDate>
            <description><![CDATA[Declarative Continuous Deployment for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/argoproj/argo-cd">argoproj/argo-cd</a></h1>
            <p>Declarative Continuous Deployment for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 20,461</p>
            <p>Forks: 6,323</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>**Releases:**
[![Release Version](https://img.shields.io/github/v/release/argoproj/argo-cd?label=argo-cd)](https://github.com/argoproj/argo-cd/releases/latest)
[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-cd)](https://artifacthub.io/packages/helm/argo/argo-cd)
[![SLSA 3](https://slsa.dev/images/gh-badge-level3.svg)](https://slsa.dev)

**Code:** 
[![Integration tests](https://github.com/argoproj/argo-cd/workflows/Integration%20tests/badge.svg?branch=master)](https://github.com/argoproj/argo-cd/actions?query=workflow%3A%22Integration+tests%22)
[![codecov](https://codecov.io/gh/argoproj/argo-cd/branch/master/graph/badge.svg)](https://codecov.io/gh/argoproj/argo-cd)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/4486/badge)](https://bestpractices.coreinfrastructure.org/projects/4486)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-cd/badge)](https://scorecard.dev/viewer/?uri=github.com/argoproj/argo-cd)

**Social:**
[![Twitter Follow](https://img.shields.io/twitter/follow/argoproj?style=social)](https://twitter.com/argoproj)
[![Slack](https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack)](https://argoproj.github.io/community/join-slack)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-argoproj-blue.svg?logo=linkedin)](https://www.linkedin.com/company/argoproj/)

# Argo CD - Declarative Continuous Delivery for Kubernetes

## What is Argo CD?

Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes.

![Argo CD UI](docs/assets/argocd-ui.gif)

[![Argo CD Demo](https://img.youtube.com/vi/0WAm0y2vLIo/0.jpg)](https://youtu.be/0WAm0y2vLIo)

## Why Argo CD?

1. Application definitions, configurations, and environments should be declarative and version controlled.
1. Application deployment and lifecycle management should be automated, auditable, and easy to understand.

## Who uses Argo CD?

[Official Argo CD user list](USERS.md)

## Documentation

To learn more about Argo CD [go to the complete documentation](https://argo-cd.readthedocs.io/).
Check live demo at https://cd.apps.argoproj.io/.

## Community

### Contribution, Discussion and Support

 You can reach the Argo CD community and developers via the following channels:

* Q &amp; A : [Github Discussions](https://github.com/argoproj/argo-cd/discussions)
* Chat : [The #argo-cd Slack channel](https://argoproj.github.io/community/join-slack)
* Contributors Office Hours: [Every Thursday](https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com) | [Agenda](https://docs.google.com/document/d/1xkoFkVviB70YBzSEa4bDnu-rUZ1sIFtwKKG1Uw8XsY8)
* User Community meeting: [First Wednesday of the month](https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com) | [Agenda](https://docs.google.com/document/d/1ttgw98MO45Dq7ZUHpIiOIEfbyeitKHNfMjbY5dLLMKQ)


Participation in the Argo CD project is governed by the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/master/code-of-conduct.md)


### Blogs and Presentations

1. [Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo](https://github.com/terrytangyuan/awesome-argo)
1. [Unveil the Secret Ingredients of Continuous Delivery at Enterprise Scale with Argo CD](https://akuity.io/blog/secret-ingredients-of-continuous-delivery-at-enterprise-scale-with-argocd/)
1. [GitOps Without Pipelines With ArgoCD Image Updater](https://youtu.be/avPUQin9kzU)
1. [Combining Argo CD (GitOps), Crossplane (Control Plane), And KubeVela (OAM)](https://youtu.be/eEcgn_gU3SM)
1. [How to Apply GitOps to Everything - Combining Argo CD and Crossplane](https://youtu.be/yrj4lmScKHQ)
1. [Couchbase - How To Run a Database Cluster in Kubernetes Using Argo CD](https://youtu.be/nkPoPaVzExY)
1. [Automation of Everything - How To Combine Argo Events, Workflows &amp; Pipelines, CD, and Rollouts](https://youtu.be/XNXJtxkUKeY)
1. [Environments Based On Pull Requests (PRs): Using Argo CD To Apply GitOps Principles On Previews](https://youtu.be/cpAaI8p4R60)
1. [Argo CD: Applying GitOps Principles To Manage Production Environment In Kubernetes](https://youtu.be/vpWQeoaiRM4)
1. [Creating Temporary Preview Environments Based On Pull Requests With Argo CD And Codefresh](https://codefresh.io/continuous-deployment/creating-temporary-preview-environments-based-pull-requests-argo-cd-codefresh/)
1. [Tutorial: Everything You Need To Become A GitOps Ninja](https://www.youtube.com/watch?v=r50tRQjisxw) 90m tutorial on GitOps and Argo CD.
1. [Comparison of Argo CD, Spinnaker, Jenkins X, and Tekton](https://www.inovex.de/blog/spinnaker-vs-argo-cd-vs-tekton-vs-jenkins-x/)
1. [Simplify and Automate Deployments Using GitOps with IBM Multicloud Manager 3.1.2](https://www.ibm.com/cloud/blog/simplify-and-automate-deployments-using-gitops-with-ibm-multicloud-manager-3-1-2)
1. [GitOps for Kubeflow using Argo CD](https://v0-6.kubeflow.org/docs/use-cases/gitops-for-kubeflow/)
1. [GitOps Toolsets on Kubernetes with CircleCI and Argo CD](https://www.digitalocean.com/community/tutorials/webinar-series-gitops-tool-sets-on-kubernetes-with-circleci-and-argo-cd)
1. [CI/CD in Light Speed with K8s and Argo CD](https://www.youtube.com/watch?v=OdzH82VpMwI&amp;feature=youtu.be)
1. [Machine Learning as Code](https://www.youtube.com/watch?v=VXrGp5er1ZE&amp;t=0s&amp;index=135&amp;list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU). Among other things, describes how Kubeflow uses Argo CD to implement GitOPs for ML
1. [Argo CD - GitOps Continuous Delivery for Kubernetes](https://www.youtube.com/watch?v=aWDIQMbp1cc&amp;feature=youtu.be&amp;t=1m4s)
1. [Introduction to Argo CD : Kubernetes DevOps CI/CD](https://www.youtube.com/watch?v=2WSJF7d8dUg&amp;feature=youtu.be)
1. [GitOps Deployment and Kubernetes - using Argo CD](https://medium.com/riskified-technology/gitops-deployment-and-kubernetes-f1ab289efa4b)
1. [Deploy Argo CD with Ingress and TLS in Three Steps: No YAML Yak Shaving Required](https://itnext.io/deploy-argo-cd-with-ingress-and-tls-in-three-steps-no-yaml-yak-shaving-required-bc536d401491)
1. [GitOps Continuous Delivery with Argo and Codefresh](https://codefresh.io/events/cncf-member-webinar-gitops-continuous-delivery-argo-codefresh/)
1. [Stay up to date with Argo CD and Renovate](https://mjpitz.com/blog/2020/12/03/renovate-your-gitops/)
1. [Setting up Argo CD with Helm](https://www.arthurkoziel.com/setting-up-argocd-with-helm/)
1. [Applied GitOps with Argo CD](https://thenewstack.io/applied-gitops-with-argocd/)
1. [Solving configuration drift using GitOps with Argo CD](https://www.cncf.io/blog/2020/12/17/solving-configuration-drift-using-gitops-with-argo-cd/)
1. [Decentralized GitOps over environments](https://blogs.sap.com/2021/05/06/decentralized-gitops-over-environments/)
1. [Getting Started with ArgoCD for GitOps Deployments](https://youtu.be/AvLuplh1skA)
1. [Using Argo CD &amp; Datree for Stable Kubernetes CI/CD Deployments](https://youtu.be/17894DTru2Y)
1. [How to create Argo CD Applications Automatically using ApplicationSet? &quot;Automation of GitOps&quot;](https://amralaayassen.medium.com/how-to-create-argocd-applications-automatically-using-applicationset-automation-of-the-gitops-59455eaf4f72)
1. [Progressive Delivery with Service Mesh ‚Äì Argo Rollouts with Istio](https://www.cncf.io/blog/2022/12/16/progressive-delivery-with-service-mesh-argo-rollouts-with-istio/)

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[google/pprof]]></title>
            <link>https://github.com/google/pprof</link>
            <guid>https://github.com/google/pprof</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:36 GMT</pubDate>
            <description><![CDATA[pprof is a tool for visualization and analysis of profiling data]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google/pprof">google/pprof</a></h1>
            <p>pprof is a tool for visualization and analysis of profiling data</p>
            <p>Language: Go</p>
            <p>Stars: 8,693</p>
            <p>Forks: 634</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>[![Github Action CI](https://github.com/google/pprof/workflows/ci/badge.svg)](https://github.com/google/pprof/actions)
[![Codecov](https://codecov.io/gh/google/pprof/graph/badge.svg)](https://codecov.io/gh/google/pprof)
[![Go Reference](https://pkg.go.dev/badge/github.com/google/pprof/profile.svg)](https://pkg.go.dev/github.com/google/pprof/profile)

# Introduction

pprof is a tool for visualization and analysis of profiling data.

pprof reads a collection of profiling samples in profile.proto format and
generates reports to visualize and help analyze the data. It can generate both
text and graphical reports (through the use of the dot visualization package).

profile.proto is a protocol buffer that describes a set of callstacks
and symbolization information. A common usage is to represent a set of
sampled callstacks from statistical profiling. The format is
described on the [proto/profile.proto](./proto/profile.proto) file. For details on protocol
buffers, see https://developers.google.com/protocol-buffers

Profiles can be read from a local file, or over http. Multiple
profiles of the same type can be aggregated or compared.

If the profile samples contain machine addresses, pprof can symbolize
them through the use of the native binutils tools (addr2line and nm).

**This is not an official Google product.**

# Building pprof

Prerequisites:

- Go development kit of a [supported version](https://golang.org/doc/devel/release.html#policy).
  Follow [these instructions](http://golang.org/doc/code.html) to prepare
  the environment.

- Graphviz: http://www.graphviz.org/
  Optional, used to generate graphic visualizations of profiles

To build and install it:

    go install github.com/google/pprof@latest

The binary will be installed `$GOPATH/bin` (`$HOME/go/bin` by default).

# Basic usage

pprof can read a profile from a file or directly from a server via http.
Specify the profile input(s) in the command line, and use options to
indicate how to format the report.

## Generate a text report of the profile, sorted by hotness:

```
% pprof -top [main_binary] profile.pb.gz
Where
    main_binary:  Local path to the main program binary, to enable symbolization
    profile.pb.gz: Local path to the profile in a compressed protobuf, or
                   URL to the http service that serves a profile.
```

## Generate a graph in an SVG file, and open it with a web browser:

```
pprof -web [main_binary] profile.pb.gz
```

## Run pprof on interactive mode:

If no output formatting option is specified, pprof runs on interactive mode,
where reads the profile and accepts interactive commands for visualization and
refinement of the profile.

```
pprof [main_binary] profile.pb.gz

This will open a simple shell that takes pprof commands to generate reports.
Type &#039;help&#039; for available commands/options.
```

## Run pprof via a web interface

If the `-http` flag is specified, pprof starts a web server at
the specified host:port that provides an interactive web-based interface to pprof.
Host is optional, and is &quot;localhost&quot; by default. Port is optional, and is a
random available port by default. `-http=&quot;:&quot;` starts a server locally at
a random port.

```
pprof -http=[host]:[port] [main_binary] profile.pb.gz
```

The preceding command should automatically open your web browser at
the right page; if not, you can manually visit the specified port in
your web browser.

## Using pprof with Linux Perf

pprof can read `perf.data` files generated by the
[Linux perf](https://perf.wiki.kernel.org/index.php/Main_Page) tool by using the
`perf_to_profile` program from the
[perf_data_converter](https://github.com/google/perf_data_converter) package.

## Viewing disassembly on Windows

To view disassembly of profiles collected from Go programs compiled as Windows executables,
the executable must be built with `go build -buildmode=exe`. LLVM or GCC must be installed,
so required tools like `addr2line` and `nm` are available to `pprof`.

## Further documentation

See [doc/README.md](doc/README.md) for more detailed end-user documentation.

See [CONTRIBUTING.md](CONTRIBUTING.md) for contribution documentation.

See [proto/README.md](proto/README.md) for a description of the profile.proto format.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-policy-agent/opa]]></title>
            <link>https://github.com/open-policy-agent/opa</link>
            <guid>https://github.com/open-policy-agent/opa</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:35 GMT</pubDate>
            <description><![CDATA[Open Policy Agent (OPA) is an open source, general-purpose policy engine.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-policy-agent/opa">open-policy-agent/opa</a></h1>
            <p>Open Policy Agent (OPA) is an open source, general-purpose policy engine.</p>
            <p>Language: Go</p>
            <p>Stars: 10,600</p>
            <p>Forks: 1,456</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># ![logo](./logo/logo-144x144.png) Open Policy Agent

[![Build Status](https://github.com/open-policy-agent/opa/workflows/Post%20Merge/badge.svg)](https://github.com/open-policy-agent/opa/actions) [![Go Report Card](https://goreportcard.com/badge/open-policy-agent/opa)](https://goreportcard.com/report/open-policy-agent/opa) [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1768/badge)](https://bestpractices.coreinfrastructure.org/projects/1768) [![Netlify Status](https://api.netlify.com/api/v1/badges/4a0a092a-8741-4826-a28f-826d4a576cab/deploy-status)](https://app.netlify.com/sites/openpolicyagent/deploys)

Open Policy Agent (OPA) is an open source, general-purpose policy engine that enables unified, context-aware policy enforcement across the entire stack.

OPA is proud to be a graduated project in the [Cloud Native Computing Foundation](https://cncf.io) (CNCF) landscape. For details read the CNCF [announcement](https://www.cncf.io/announcements/2021/02/04/cloud-native-computing-foundation-announces-open-policy-agent-graduation/).

## Get started with OPA

- Write your first Rego policy with the [Rego Playground](https://play.openpolicyagent.org) or use it to share your work with others for feedback and support. Have a look at the [Access Control examples](https://play.openpolicyagent.org/?example-group=access-control) if you&#039;re not sure where to start.
- Install the [VS Code extension](https://marketplace.visualstudio.com/items?itemName=tsandall.opa) to get started locally with live diagnostics, debugging and formatting. See [Editor and IDE Support](https://www.openpolicyagent.org/docs/editor-and-ide-support/) for other supported editors.
- Go to the [OPA Documentation](https://www.openpolicyagent.org/docs/latest/) to
  learn about the Rego language as well as how to deploy and integrate OPA.
- Check out the learning resources in the [Learning Rego](https://www.openpolicyagent.org/ecosystem/by-feature/learning-rego/) section of the ecosystem directory.
- Follow the [Running OPA](https://www.openpolicyagent.org/docs/latest/#running-opa) instructions to get started with the OPA CLI locally.
- See [Docker Hub](https://hub.docker.com/r/openpolicyagent/opa/tags/) for container images and the [GitHub releases](https://github.com/open-policy-agent/opa/releases) for binaries.
- Check out the [OPA Roadmap](https://docs.google.com/presentation/d/16QV6gvLDOV3I0_guPC3_19g6jHkEg3X9xqMYgtoCKrs/edit?usp=sharing) to see a high-level snapshot of OPA features in-progress and planned.

## Want to talk about OPA or get support?

- Join the [OPA Slack](https://slack.openpolicyagent.org) to talk to other OPA users and maintainers. See `#help` for support.
- Check out the [Community Discussions](https://github.com/orgs/open-policy-agent/discussions) to ask questions.
- See the [Support](https://www.openpolicyagent.org/support/) page for commercial support options.

## Interested to learn what others are doing with OPA?

- Browse community projects on the [OPA Ecosystem Directory](http://openpolicyagent.org/ecosystem/) - don&#039;t forget to [list your own](https://github.com/open-policy-agent/opa/tree/main/docs#opa-ecosystem)!
- Check out the [ADOPTERS.md](./ADOPTERS.md) file for a list of production adopters. Does your organization use OPA in production? Support the OPA project by submitting a PR to add your organization to the list with a short description of your OPA use cases!

## Want to integrate OPA?

- See the high-level [Go SDK](https://www.openpolicyagent.org/docs/latest/integration/#integrating-with-the-go-sdk) or the low-level Go API
  [![GoDoc](https://godoc.org/github.com/open-policy-agent/opa?status.svg)](https://godoc.org/github.com/open-policy-agent/opa/rego)
  to integrate OPA with services written in Go.
- See the [REST API](https://www.openpolicyagent.org/docs/rest-api.html)
  reference to integrate OPA with services written in other languages.
- See the [integration docs](https://www.openpolicyagent.org/docs/latest/integration/) for more options.

## Want to contribute to OPA?

- Read the [Contributing Guide](https://www.openpolicyagent.org/docs/latest/contributing/) to learn how to make your first contribution.
- Use [#contributors](https://openpolicyagent.slack.com/archives/C02L1TLPN59) in Slack to talk to other contributors and OPA maintainers.
- File a [GitHub Issue](https://github.com/open-policy-agent/opa/issues) to request features or report bugs.

## How does OPA work?

OPA gives you a high-level declarative language to author and enforce policies
across your stack.

With OPA, you define _rules_ that govern how your system should behave. These
rules exist to answer questions like:

- Can user X call operation Y on resource Z?
- What clusters should workload W be deployed to?
- What tags must be set on resource R before it&#039;s created?

You integrate services with OPA so that these kinds of policy decisions do not
have to be _hardcoded_ in your service. Services integrate with OPA by
executing _queries_ when policy decisions are needed.

When you query OPA for a policy decision, OPA evaluates the rules and data
(which you give it) to produce an answer. The policy decision is sent back as
the result of the query.

For example, in a simple API authorization use case:

- You write rules that allow (or deny) access to your service APIs.
- Your service queries OPA when it receives API requests.
- OPA returns allow (or deny) decisions to your service.
- Your service _enforces_ the decisions by accepting or rejecting requests accordingly.

For concrete examples of how to integrate OPA with systems like
[Kubernetes](https://www.openpolicyagent.org/docs/kubernetes),
[Terraform](https://www.openpolicyagent.org/docs/terraform),
[Docker](https://www.openpolicyagent.org/docs/docker-authorization),
[SSH](https://www.openpolicyagent.org/docs/ssh-and-sudo-authorization),
and more, see [openpolicyagent.org](https://www.openpolicyagent.org).

## Presentations

- Open Policy Agent (OPA) Intro &amp; Deep Dive @ Kubecon NA 2023: [video](https://www.youtube.com/watch?v=wJkjsvVpj_Q)
- Open Policy Agent (OPA) Intro &amp; Deep Dive @ Kubecon EU 2023: [video](https://www.youtube.com/watch?v=6RNp3m_THw4)
- Running Policy in Hard to Reach Places with WASM &amp; OPA @ CN Wasm Day EU 2023: [video](https://www.youtube.com/watch?v=BdeBhukLwt4)
- OPA maintainers talk @ Kubecon NA 2022: [video](https://www.youtube.com/watch?v=RMiovzGGCfI)
- Open Policy Agent (OPA) Intro &amp; Deep Dive @ Kubecon EU 2022: [video](https://www.youtube.com/watch?v=MhyQxIp1H58)
- Open Policy Agent Intro @ KubeCon EU 2021: [Video](https://www.youtube.com/watch?v=2CgeiWkliaw)
- Using Open Policy Agent to Meet Evolving Policy Requirements @ KubeCon NA 2020: [video](https://www.youtube.com/watch?v=zVuM7F_BTyc)
- Applying Policy Throughout The Application Lifecycle with Open Policy Agent @ CloudNativeCon 2019: [video](https://www.youtube.com/watch?v=cXfsaE6RKfc)
- Open Policy Agent Introduction @ CloudNativeCon EU 2018: [video](https://youtu.be/XEHeexPpgrA), [slides](https://www.slideshare.net/TorinSandall/opa-the-cloud-native-policy-engine)
- Rego Deep Dive @ CloudNativeCon EU 2018: [video](https://youtu.be/4mBJSIhs2xQ), [slides](https://www.slideshare.net/TorinSandall/rego-deep-dive)
- How Netflix Is Solving Authorization Across Their Cloud @ CloudNativeCon US 2017: [video](https://www.youtube.com/watch?v=R6tUNpRpdnY), [slides](https://www.slideshare.net/TorinSandall/how-netflix-is-solving-authorization-across-their-cloud).
- Policy-based Resource Placement in Kubernetes Federation @ LinuxCon Beijing 2017: [slides](https://www.slideshare.net/TorinSandall/policybased-resource-placement-across-hybrid-cloud), [screencast](https://www.youtube.com/watch?v=hRz13baBhfg&amp;feature=youtu.be)
- Enforcing Bespoke Policies In Kubernetes @ KubeCon US 2017: [video](https://www.youtube.com/watch?v=llDI8VvkUj8), [slides](https://www.slideshare.net/TorinSandall/enforcing-bespoke-policies-in-kubernetes)
- Istio&#039;s Mixer: Policy Enforcement with Custom Adapters @ CloudNativeCon US 2017: [video](https://www.youtube.com/watch?v=czZLXUqzd24), [slides](https://www.slideshare.net/TorinSandall/istios-mixer-policy-enforcement-with-custom-adapters-cloud-nativecon-17)

## Security

A third party security audit was performed by Cure53, you can see the full report [here](SECURITY_AUDIT.pdf).

Please report vulnerabilities by email to [open-policy-agent-security](mailto:open-policy-agent-security@googlegroups.com).
We will send a confirmation message to acknowledge that we have received the
report and then we will send additional messages to follow up once the issue
has been investigated.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[vitessio/vitess]]></title>
            <link>https://github.com/vitessio/vitess</link>
            <guid>https://github.com/vitessio/vitess</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[Vitess is a database clustering system for horizontal scaling of MySQL.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vitessio/vitess">vitessio/vitess</a></h1>
            <p>Vitess is a database clustering system for horizontal scaling of MySQL.</p>
            <p>Language: Go</p>
            <p>Stars: 20,038</p>
            <p>Forks: 2,239</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>[![Maven Central](https://maven-badges.herokuapp.com/maven-central/io.vitess/vitess-jdbc/badge.svg)](https://maven-badges.herokuapp.com/maven-central/io.vitess/vitess-jdbc)
[![Coverage Status](https://codecov.io/gh/vitessio/vitess/branch/main/graph/badge.svg)](https://app.codecov.io/gh/vitessio/vitess/tree/main)
[![Go Report Card](https://goreportcard.com/badge/vitess.io/vitess)](https://goreportcard.com/report/vitess.io/vitess)
[![FOSSA Status](https://app.fossa.com/api/projects/custom%2B162%2Fvitess.svg?type=shield&amp;issueType=license)](https://app.fossa.com/projects/custom%2B162%2Fvitess?ref=badge_shield&amp;issueType=license)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1724/badge)](https://bestpractices.coreinfrastructure.org/projects/1724)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/vitessio/vitess/badge)](https://scorecard.dev/viewer/?uri=github.com/vitessio/vitess)

# Vitess 

Vitess is a cloud-native horizontally-scalable distributed database system that is built around MySQL.
Vitess can achieve unlimited scaling through generalized sharding.

Vitess allows application code and database queries to remain agnostic to the distribution of data onto
multiple database servers. With Vitess, you can even split and merge shards as your needs
grow, with an atomic cutover step that takes only a few seconds.

Vitess was a core component of YouTube&#039;s database infrastructure
from 2011, and grew to encompass tens of thousands of MySQL nodes. 
Starting in 2015, Vitess was adopted by many other large companies, including Slack, Square (now Block), and JD.com.

For more about Vitess, please visit [vitess.io](https://vitess.io).

## Community

Vitess has a growing [community](https://github.com/vitessio/vitess/blob/main/ADOPTERS.md).

If you are interested in contributing or participating in our monthly community meetings, please visit the [Community page on our website](https://vitess.io/community/).

We also maintain a [roadmap](https://vitess.io/docs/roadmap/) on our website.

Follow our [blog](https://blog.vitess.io/) for low-frequency updates like new features and releases.

## Reporting a Problem, Issue, or Bug

To report a problem, create a [GitHub issue](https://github.com/vitessio/vitess/issues).

For topics that are better discussed live, please join the [Vitess Slack](https://vitess.io/slack) workspace.
You may post any questions on the #general channel or join some of the special-interest channels.

## Security

### Reporting Security Vulnerabilities

To report a security vulnerability, please email [vitess-maintainers](mailto:cncf-vitess-maintainers@lists.cncf.io).

See [Security](SECURITY.md) for a full outline of the security process.

### Security Audit

A third party security audit was performed by ADA Logics. [Read the full report](doc/VIT-03-report-security-audit.pdf).

## License

Unless otherwise noted, the Vitess source files are distributed
under the Apache Version 2.0 license found in the LICENSE file.

[![FOSSA Status](https://app.fossa.com/api/projects/custom%2B162%2Fvitess.svg?type=large&amp;issueType=license)](https://app.fossa.com/projects/custom%2B162%2Fvitess?ref=badge_large&amp;issueType=license)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[go-playground/validator]]></title>
            <link>https://github.com/go-playground/validator</link>
            <guid>https://github.com/go-playground/validator</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[üíØGo Struct and Field validation, including Cross Field, Cross Struct, Map, Slice and Array diving]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/go-playground/validator">go-playground/validator</a></h1>
            <p>üíØGo Struct and Field validation, including Cross Field, Cross Struct, Map, Slice and Array diving</p>
            <p>Language: Go</p>
            <p>Stars: 18,909</p>
            <p>Forks: 1,379</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>Package validator
=================
&lt;img align=&quot;right&quot; src=&quot;logo.png&quot;&gt;[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/go-playground/validator)](https://github.com/go-playground/validator/releases)
[![Build Status](https://github.com/go-playground/validator/actions/workflows/workflow.yml/badge.svg)](https://github.com/go-playground/validator/actions)
[![Coverage Status](https://coveralls.io/repos/go-playground/validator/badge.svg?branch=master&amp;service=github)](https://coveralls.io/github/go-playground/validator?branch=master)
[![Go Report Card](https://goreportcard.com/badge/github.com/go-playground/validator)](https://goreportcard.com/report/github.com/go-playground/validator)
[![GoDoc](https://godoc.org/github.com/go-playground/validator?status.svg)](https://pkg.go.dev/github.com/go-playground/validator/v10)
![License](https://img.shields.io/dub/l/vibe-d.svg)

Package validator implements value validations for structs and individual fields based on tags.

It has the following **unique** features:

-   Cross Field and Cross Struct validations by using validation tags or custom validators.
-   Slice, Array and Map diving, which allows any or all levels of a multidimensional field to be validated.
-   Ability to dive into both map keys and values for validation
-   Handles type interface by determining it&#039;s underlying type prior to validation.
-   Handles custom field types such as sql driver Valuer see [Valuer](https://golang.org/src/database/sql/driver/types.go?s=1210:1293#L29)
-   Alias validation tags, which allows for mapping of several validations to a single tag for easier defining of validations on structs
-   Extraction of custom defined Field Name e.g. can specify to extract the JSON name while validating and have it available in the resulting FieldError
-   Customizable i18n aware error messages.
-   Default validator for the [gin](https://github.com/gin-gonic/gin) web framework; upgrading from v8 to v9 in gin see [here](https://github.com/go-playground/validator/tree/master/_examples/gin-upgrading-overriding)

A Call for Maintainers
----------------------

Please read the discussiong started [here](https://github.com/go-playground/validator/discussions/1330) if you are interested in contributing/helping maintain this package.

Installation
------------

Use go get.

	go get github.com/go-playground/validator/v10

Then import the validator package into your own code.

	import &quot;github.com/go-playground/validator/v10&quot;

Error Return Value
-------

Validation functions return type error

They return type error to avoid the issue discussed in the following, where err is always != nil:

* http://stackoverflow.com/a/29138676/3158232
* https://github.com/go-playground/validator/issues/134

Validator returns only InvalidValidationError for bad validation input, nil or ValidationErrors as type error; so, in your code all you need to do is check if the error returned is not nil, and if it&#039;s not check if error is InvalidValidationError ( if necessary, most of the time it isn&#039;t ) type cast it to type ValidationErrors like so:

```go
err := validate.Struct(mystruct)
validationErrors := err.(validator.ValidationErrors)
 ```

Usage and documentation
------

Please see https://pkg.go.dev/github.com/go-playground/validator/v10 for detailed usage docs.

##### Examples:

- [Simple](https://github.com/go-playground/validator/blob/master/_examples/simple/main.go)
- [Custom Field Types](https://github.com/go-playground/validator/blob/master/_examples/custom/main.go)
- [Struct Level](https://github.com/go-playground/validator/blob/master/_examples/struct-level/main.go)
- [Translations &amp; Custom Errors](https://github.com/go-playground/validator/blob/master/_examples/translations/main.go)
- [Gin upgrade and/or override validator](https://github.com/go-playground/validator/tree/v9/_examples/gin-upgrading-overriding)
- [wash - an example application putting it all together](https://github.com/bluesuncorp/wash)

Baked-in Validations
------

### Special Notes:
- If new to using validator it is highly recommended to initialize it using the `WithRequiredStructEnabled` option which is opt-in to new behaviour that will become the default behaviour in v11+. See documentation for more details.
```go
validate := validator.New(validator.WithRequiredStructEnabled())
```

### Fields:

| Tag | Description |
| - | - |
| eqcsfield | Field Equals Another Field (relative)|
| eqfield | Field Equals Another Field |
| fieldcontains | Check the indicated characters are present in the Field |
| fieldexcludes | Check the indicated characters are not present in the field |
| gtcsfield | Field Greater Than Another Relative Field |
| gtecsfield | Field Greater Than or Equal To Another Relative Field |
| gtefield | Field Greater Than or Equal To Another Field |
| gtfield | Field Greater Than Another Field |
| ltcsfield | Less Than Another Relative Field |
| ltecsfield | Less Than or Equal To Another Relative Field |
| ltefield | Less Than or Equal To Another Field |
| ltfield | Less Than Another Field |
| necsfield | Field Does Not Equal Another Field (relative) |
| nefield | Field Does Not Equal Another Field |

### Network:

| Tag | Description |
| - | - |
| cidr | Classless Inter-Domain Routing CIDR |
| cidrv4 | Classless Inter-Domain Routing CIDRv4 |
| cidrv6 | Classless Inter-Domain Routing CIDRv6 |
| datauri | Data URL |
| fqdn | Full Qualified Domain Name (FQDN) |
| hostname | Hostname RFC 952 |
| hostname_port | HostPort |
| hostname_rfc1123 | Hostname RFC 1123 |
| ip | Internet Protocol Address IP |
| ip4_addr | Internet Protocol Address IPv4 |
| ip6_addr | Internet Protocol Address IPv6 |
| ip_addr | Internet Protocol Address IP |
| ipv4 | Internet Protocol Address IPv4 |
| ipv6 | Internet Protocol Address IPv6 |
| mac | Media Access Control Address MAC |
| tcp4_addr | Transmission Control Protocol Address TCPv4 |
| tcp6_addr | Transmission Control Protocol Address TCPv6 |
| tcp_addr | Transmission Control Protocol Address TCP |
| udp4_addr | User Datagram Protocol Address UDPv4 |
| udp6_addr | User Datagram Protocol Address UDPv6 |
| udp_addr | User Datagram Protocol Address UDP |
| unix_addr | Unix domain socket end point Address |
| uri | URI String |
| url | URL String |
| http_url | HTTP URL String |
| url_encoded | URL Encoded |
| urn_rfc2141 | Urn RFC 2141 String |

### Strings:

| Tag | Description |
| - | - |
| alpha | Alpha Only |
| alphanum | Alphanumeric |
| alphanumunicode | Alphanumeric Unicode |
| alphaunicode | Alpha Unicode |
| ascii | ASCII |
| boolean | Boolean |
| contains | Contains |
| containsany | Contains Any |
| containsrune | Contains Rune |
| endsnotwith | Ends Not With |
| endswith | Ends With |
| excludes | Excludes |
| excludesall | Excludes All |
| excludesrune | Excludes Rune |
| lowercase | Lowercase |
| multibyte | Multi-Byte Characters |
| number | Number |
| numeric | Numeric |
| printascii | Printable ASCII |
| startsnotwith | Starts Not With |
| startswith | Starts With |
| uppercase | Uppercase |

### Format:
| Tag | Description |
| - | - |
| base64 | Base64 String |
| base64url | Base64URL String |
| base64rawurl | Base64RawURL String |
| bic | Business Identifier Code (ISO 9362) |
| bcp47_language_tag | Language tag (BCP 47) |
| btc_addr | Bitcoin Address |
| btc_addr_bech32 | Bitcoin Bech32 Address (segwit) |
| credit_card | Credit Card Number |
| mongodb | MongoDB ObjectID |
| mongodb_connection_string | MongoDB Connection String |
| cron | Cron |
| spicedb | SpiceDb ObjectID/Permission/Type |
| datetime | Datetime |
| e164 | e164 formatted phone number |
| ein | U.S. Employeer Identification Number |
| email | E-mail String
| eth_addr | Ethereum Address |
| hexadecimal | Hexadecimal String |
| hexcolor | Hexcolor String |
| hsl | HSL String |
| hsla | HSLA String |
| html | HTML Tags |
| html_encoded | HTML Encoded |
| isbn | International Standard Book Number |
| isbn10 | International Standard Book Number 10 |
| isbn13 | International Standard Book Number 13 |
| issn | International Standard Serial Number |
| iso3166_1_alpha2 | Two-letter country code (ISO 3166-1 alpha-2) |
| iso3166_1_alpha3 | Three-letter country code (ISO 3166-1 alpha-3) |
| iso3166_1_alpha_numeric | Numeric country code (ISO 3166-1 numeric) |
| iso3166_2 | Country subdivision code (ISO 3166-2) |
| iso4217 | Currency code (ISO 4217) |
| json | JSON |
| jwt | JSON Web Token (JWT) |
| latitude | Latitude |
| longitude | Longitude |
| luhn_checksum | Luhn Algorithm Checksum (for strings and (u)int) |
| postcode_iso3166_alpha2 | Postcode |
| postcode_iso3166_alpha2_field | Postcode |
| rgb | RGB String |
| rgba | RGBA String |
| ssn | Social Security Number SSN |
| timezone | Timezone |
| uuid | Universally Unique Identifier UUID |
| uuid3 | Universally Unique Identifier UUID v3 |
| uuid3_rfc4122 | Universally Unique Identifier UUID v3 RFC4122 |
| uuid4 | Universally Unique Identifier UUID v4 |
| uuid4_rfc4122 | Universally Unique Identifier UUID v4 RFC4122 |
| uuid5 | Universally Unique Identifier UUID v5 |
| uuid5_rfc4122 | Universally Unique Identifier UUID v5 RFC4122 |
| uuid_rfc4122 | Universally Unique Identifier UUID RFC4122 |
| md4 | MD4 hash |
| md5 | MD5 hash |
| sha256 | SHA256 hash |
| sha384 | SHA384 hash |
| sha512 | SHA512 hash |
| ripemd128 | RIPEMD-128 hash |
| ripemd128 | RIPEMD-160 hash |
| tiger128 | TIGER128 hash |
| tiger160 | TIGER160 hash |
| tiger192 | TIGER192 hash |
| semver | Semantic Versioning 2.0.0 |
| ulid | Universally Unique Lexicographically Sortable Identifier ULID |
| cve | Common Vulnerabilities and Exposures Identifier (CVE id) |

### Comparisons:
| Tag | Description |
| - | - |
| eq | Equals |
| eq_ignore_case | Equals ignoring case |
| gt | Greater than|
| gte | Greater than or equal |
| lt | Less Than |
| lte | Less Than or Equal |
| ne | Not Equal |
| ne_ignore_case | Not Equal ignoring case |

### Other:
| Tag | Description |
| - | - |
| dir | Existing Directory |
| dirpath | Directory Path |
| file | Existing File |
| filepath | File Path |
| image | Image |
| isdefault | Is Default |
| len | Length |
| max | Maximum |
| min | Minimum |
| oneof | One Of |
| required | Required |
| required_if | Required If |
| required_unless | Required Unless |
| required_with | Required With |
| required_with_all | Required With All |
| required_without | Required Without |
| required_without_all | Required Without All |
| excluded_if | Excluded If |
| excluded_unless | Excluded Unless |
| excluded_with | Excluded With |
| excluded_with_all | Excluded With All |
| excluded_without | Excluded Without |
| excluded_without_all | Excluded Without All |
| unique | Unique |
| validateFn | Verify if the method `Validate() error` does not return an error (or any specified method) |


#### Aliases:
| Tag | Description |
| - | - |
| iscolor | hexcolor\|rgb\|rgba\|hsl\|hsla |
| country_code | iso3166_1_alpha2\|iso3166_1_alpha3\|iso3166_1_alpha_numeric |

Benchmarks
------
###### Run on MacBook Pro Max M3
```go
go version go1.23.3 darwin/arm64
goos: darwin
goarch: arm64
cpu: Apple M3 Max
pkg: github.com/go-playground/validator/v10
BenchmarkFieldSuccess-16                                                42461943                27.88 ns/op            0 B/op          0 allocs/op
BenchmarkFieldSuccessParallel-16                                        486632887                2.289 ns/op           0 B/op          0 allocs/op
BenchmarkFieldFailure-16                                                 9566167               121.3 ns/op           200 B/op          4 allocs/op
BenchmarkFieldFailureParallel-16                                        17551471                83.68 ns/op          200 B/op          4 allocs/op
BenchmarkFieldArrayDiveSuccess-16                                        7602306               155.6 ns/op            97 B/op          5 allocs/op
BenchmarkFieldArrayDiveSuccessParallel-16                               20664610                59.80 ns/op           97 B/op          5 allocs/op
BenchmarkFieldArrayDiveFailure-16                                        4659756               252.9 ns/op           301 B/op         10 allocs/op
BenchmarkFieldArrayDiveFailureParallel-16                                8010116               152.9 ns/op           301 B/op         10 allocs/op
BenchmarkFieldMapDiveSuccess-16                                          2834575               421.2 ns/op           288 B/op         14 allocs/op
BenchmarkFieldMapDiveSuccessParallel-16                                  7179700               171.8 ns/op           288 B/op         14 allocs/op
BenchmarkFieldMapDiveFailure-16                                          3081728               384.4 ns/op           376 B/op         13 allocs/op
BenchmarkFieldMapDiveFailureParallel-16                                  6058137               204.0 ns/op           377 B/op         13 allocs/op
BenchmarkFieldMapDiveWithKeysSuccess-16                                  2544975               464.8 ns/op           288 B/op         14 allocs/op
BenchmarkFieldMapDiveWithKeysSuccessParallel-16                          6661954               181.4 ns/op           288 B/op         14 allocs/op
BenchmarkFieldMapDiveWithKeysFailure-16                                  2435484               490.7 ns/op           553 B/op         16 allocs/op
BenchmarkFieldMapDiveWithKeysFailureParallel-16                          4249617               282.0 ns/op           554 B/op         16 allocs/op
BenchmarkFieldCustomTypeSuccess-16                                      14943525                77.35 ns/op           32 B/op          2 allocs/op
BenchmarkFieldCustomTypeSuccessParallel-16                              64051954                20.61 ns/op           32 B/op          2 allocs/op
BenchmarkFieldCustomTypeFailure-16                                      10721384               107.1 ns/op           184 B/op          3 allocs/op
BenchmarkFieldCustomTypeFailureParallel-16                              18714495                69.77 ns/op          184 B/op          3 allocs/op
BenchmarkFieldOrTagSuccess-16                                            4063124               294.3 ns/op            16 B/op          1 allocs/op
BenchmarkFieldOrTagSuccessParallel-16                                   31903756                41.22 ns/op           18 B/op          1 allocs/op
BenchmarkFieldOrTagFailure-16                                            7748558               146.8 ns/op           216 B/op          5 allocs/op
BenchmarkFieldOrTagFailureParallel-16                                   13139854                92.05 ns/op          216 B/op          5 allocs/op
BenchmarkStructLevelValidationSuccess-16                                16808389                70.25 ns/op           16 B/op          1 allocs/op
BenchmarkStructLevelValidationSuccessParallel-16                        90686955                14.47 ns/op           16 B/op          1 allocs/op
BenchmarkStructLevelValidationFailure-16                                 5818791               200.2 ns/op           264 B/op          7 allocs/op
BenchmarkStructLevelValidationFailureParallel-16                        11115874               107.5 ns/op           264 B/op          7 allocs/op
BenchmarkStructSimpleCustomTypeSuccess-16                                7764956               151.9 ns/op            32 B/op          2 allocs/op
BenchmarkStructSimpleCustomTypeSuccessParallel-16                       52316265                30.37 ns/op           32 B/op          2 allocs/op
BenchmarkStructSimpleCustomTypeFailure-16                                4195429               277.2 ns/op           416 B/op          9 allocs/op
BenchmarkStructSimpleCustomTypeFailureParallel-16                        7305661               164.6 ns/op           432 B/op         10 allocs/op
BenchmarkStructFilteredSuccess-16                                        6312625               186.1 ns/op           216 B/op          5 allocs/op
BenchmarkStructFilteredSuccessParallel-16                               13684459                93.42 ns/op          216 B/op          5 allocs/op
BenchmarkStructFilteredFailure-16                                        6751482               171.2 ns/op           216 B/op          5 allocs/op
BenchmarkStructFilteredFailureParallel-16                               14146070                86.93 ns/op          216 B/op          5 allocs/op
BenchmarkStructPartialSuccess-16                                         6544448               177.3 ns/op           224 B/op          4 allocs/op
BenchmarkStructPartialSuccessParallel-16                                13951946                88.73 ns/op          224 B/op          4 allocs/op
BenchmarkStructPartialFailure-16                                         4075833               287.5 ns/op           440 B/op          9 allocs/op
BenchmarkStructPartialFailureParallel-16                                 7490805               161.3 ns/op           440 B/op          9 allocs/op
BenchmarkStructExceptSuccess-16                                          4107187               281.4 ns/op           424 B/op          8 allocs/op
BenchmarkStructExceptSuccessParallel-16                                 15979173                80.86 ns/op          208 B/op          3 allocs/op
BenchmarkStructExceptFailure-16                                          4434372               264.3 ns/op           424 B/op          8 allocs/op
BenchmarkStructExceptFailureParallel-16                                  8081367               154.1 ns/op           424 B/op          8 allocs/op
BenchmarkStructSimpleCrossFieldSuccess-16                                6459542               183.4 ns/op            56 B/op          3 allocs/op
BenchmarkStructSimpleCrossFieldSuccessParallel-16                       41013781                37.95 ns/op           56 B/op          3 allocs/op
BenchmarkStructSimpleCrossFieldFailure-16                                4034998               292.1 ns/op           272 B/op          8 allocs/op
BenchmarkStructSimpleCrossFieldFailureParallel-16                       11348446               115.3 ns/op           272 B/op          8 allocs/op
BenchmarkStructSimpleCrossStructCrossFieldSuccess-16                     4448528               267.7 ns/op            64 B/op          4 allocs/op
BenchmarkStructSimpleCrossStructCrossFieldSuccessParallel-16            26813619                48.33 ns/op           64 B/op          4 allocs/op
BenchmarkStructSimpleCrossStructCrossFieldFailure-16                     3090646               384.5 ns/op           288 B/op          9 allocs/op
BenchmarkStructSimpleCrossStructCrossFieldFailureParallel-16             9870906               129.5 ns/op           288 B/op          9 allocs/op
BenchmarkStructSimpleSuccess-16                                         10675562               109.5 ns/op             0 B/op          0 allocs/op
BenchmarkStructSimpleSuccessParallel-16                                 131159784                8.932 ns/op           0 B/op          0 allocs/op
BenchmarkStructSimpleFailure-16                                          4094979               286.6 ns/op           416 B/op          9 allocs/op
BenchmarkStructSimpleFailureParallel-16                                  7606663               157.9 ns/op           416 B/op          9 allocs/op
BenchmarkStructComplexSuccess-16                                         2073470               576.0 ns/op           224 B/op          5 allocs/op
BenchmarkStructComplexSuccessParallel-16                                 7821831               161.3 ns/op           224 B/op          5 allocs/op
BenchmarkStructComplexFailure-16                                          576358              2001 ns/op            3042 B/op         48 allocs/op
BenchmarkStructComplexFailureParallel-16                                 1000000              1171 ns/op            3041 B/op         48 allocs/op
BenchmarkOneof

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[testcontainers/testcontainers-go]]></title>
            <link>https://github.com/testcontainers/testcontainers-go</link>
            <guid>https://github.com/testcontainers/testcontainers-go</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[Testcontainers for Go is a Go package that makes it simple to create and clean up container-based dependencies for automated integration/smoke tests. The clean, easy-to-use API enables developers to programmatically define containers that should be run as part of a test and clean up those resources when the test is done.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/testcontainers/testcontainers-go">testcontainers/testcontainers-go</a></h1>
            <p>Testcontainers for Go is a Go package that makes it simple to create and clean up container-based dependencies for automated integration/smoke tests. The clean, easy-to-use API enables developers to programmatically define containers that should be run as part of a test and clean up those resources when the test is done.</p>
            <p>Language: Go</p>
            <p>Stars: 4,294</p>
            <p>Forks: 567</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># Testcontainers

[![Main pipeline](https://github.com/testcontainers/testcontainers-go/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/testcontainers/testcontainers-go/actions/workflows/ci.yml)
[![GoDoc Reference](https://pkg.go.dev/badge/github.com/testcontainers/testcontainers-go.svg)](https://pkg.go.dev/github.com/testcontainers/testcontainers-go)
[![Go Report Card](https://goreportcard.com/badge/github.com/testcontainers/testcontainers-go)](https://goreportcard.com/report/github.com/testcontainers/testcontainers-go)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=testcontainers_testcontainers-go&amp;metric=alert_status)](https://sonarcloud.io/summary/new_code?id=testcontainers_testcontainers-go)
[![License](https://img.shields.io/badge/license-MIT-blue)](https://github.com/testcontainers/testcontainers-go/blob/main/LICENSE)

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://github.com/codespaces/new?hide_repo_select=true&amp;ref=main&amp;repo=141451032&amp;machine=standardLinux32gb&amp;devcontainer_path=.devcontainer%2Fdevcontainer.json&amp;location=EastUs)

[![Join our Slack](https://img.shields.io/badge/Slack-4A154B?logo=slack)](https://testcontainers.slack.com/)

_Testcontainers for Go_ is a Go package that makes it simple to create and clean up container-based dependencies for
automated integration/smoke tests. The clean, easy-to-use API enables developers to programmatically define containers
that should be run as part of a test and clean up those resources when the test is done.

You can find more information about _Testcontainers for Go_ at [golang.testcontainers.org](https://golang.testcontainers.org), which is rendered from the [./docs](./docs) directory.

## Using _Testcontainers for Go_

Please visit [the quickstart guide](https://golang.testcontainers.org/quickstart) to understand how to add the dependency to your Go project.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kopia/kopia]]></title>
            <link>https://github.com/kopia/kopia</link>
            <guid>https://github.com/kopia/kopia</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[Cross-platform backup tool for Windows, macOS & Linux with fast, incremental backups, client-side end-to-end encryption, compression and data deduplication. CLI and GUI included.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kopia/kopia">kopia/kopia</a></h1>
            <p>Cross-platform backup tool for Windows, macOS & Linux with fast, incremental backups, client-side end-to-end encryption, compression and data deduplication. CLI and GUI included.</p>
            <p>Language: Go</p>
            <p>Stars: 10,969</p>
            <p>Forks: 532</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>Kopia
=====

![Kopia](icons/kopia.svg)
[![Build Status](https://github.com/kopia/kopia/workflows/Build/badge.svg)](https://github.com/kopia/kopia/actions?query=workflow%3ABuild)
[![Slack](https://img.shields.io/badge/discuss-slack-blue.svg)](https://slack.kopia.io/) 
[![GoDoc](https://godoc.org/github.com/kopia/kopia/repo?status.svg)](https://godoc.org/github.com/kopia/kopia/repo)
[![Coverage Status](https://codecov.io/gh/kopia/kopia/branch/master/graph/badge.svg?token=CRK4RMRFSH)](https://codecov.io/gh/kopia/kopia)[![Go Report Card](https://goreportcard.com/badge/github.com/kopia/kopia)](https://goreportcard.com/report/github.com/kopia/kopia)
[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg)](CODE_OF_CONDUCT.md)
[![Docker Pulls](https://img.shields.io/docker/pulls/kopia/kopia)](https://hub.docker.com/r/kopia/kopia/tags?page=1&amp;ordering=name)
[![Downloads](https://img.shields.io/github/downloads/kopia/kopia/total.svg)](https://github.com/kopia/kopia/releases)
[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Kopia%20Guru-006BFF)](https://gurubase.io/g/kopia)

&gt; _n._
&gt;
&gt; 1. _[copy, replica](https://en.wikipedia.org/wiki/Replica) (Polish)_
&gt; 2. _[lance, spear](https://en.wikipedia.org/wiki/Kopia)_
&gt; 3. _[fast and secure backup tool](https://kopia.io)_


Kopia is a fast and secure open-source backup/restore tool that allows you to create [encrypted](https://kopia.io/docs/features/#end-to-end-zero-knowledge-encryption) snapshots of your data and save the snapshots to [remote or cloud storage](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage) of your choice, [to network-attached storage or server](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage), or [locally on your machine](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage). Kopia does not &#039;image&#039; your whole machine. Rather, Kopia allows you to backup/restore any and all files/directories that you deem are important or critical.

Kopia has both [CLI (command-line interface)](https://kopia.io/docs/features/#both-command-line-and-graphical-user-interfaces) and [GUI (graphical user interface)](https://kopia.io/docs/features/#both-command-line-and-graphical-user-interfaces) versions, making it the perfect tool for both advanced and regular users. You can read more about Kopia&#039;s unique [features](https://kopia.io/docs/features/) -- which include [compression](https://kopia.io/docs/features/#compression), [deduplication](https://kopia.io/docs/features/#backup-files-and-directories-using-snapshots), [end-to-end &#039;zero knowledge&#039; encryption](https://kopia.io/docs/features/#end-to-end-zero-knowledge-encryption), and [error correction](https://kopia.io/docs/features/#error-correction) -- to get a better understanding of how Kopia works.

When ready, head to the [installation](https://kopia.io/docs/installation/) page to download and install Kopia, and make sure to read the [Getting Started Guide](https://kopia.io/docs/getting-started/) for a step-by-step walkthrough of how to use Kopia.

Pick the Cloud Storage Provider You Want
---

Kopia supports saving your [encrypted](https://kopia.io/docs/features/#end-to-end-zero-knowledge-encryption) and [compressed](https://kopia.io/docs/features/#compression) snapshots to all of the following [storage locations](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage):

* **Amazon S3** and any **cloud storage that is compatible with S3**
* **Azure Blob Storage**
* **Backblaze B2**
* **Google Cloud Storage**
* Any remote server or cloud storage that supports **WebDAV**
* Any remote server or cloud storage that supports **SFTP**
* Some of the cloud storage options supported by **Rclone**
  * Requires you to download and setup Rclone in addition to Kopia, but after that Kopia manages/runs Rclone for you
  * Rclone support is experimental: not all the cloud storage products supported by Rclone have been tested to work with Kopia, and some may not work with Kopia; Kopia has been tested to work with **Dropbox**, **OneDrive**, and **Google Drive** through Rclone
* Your local machine and any network-attached storage or server
* Your own server by setting up a [Kopia Repository Server](https://kopia.io/docs/repository-server/)

And Kopia uses [data deduplication](https://kopia.io/docs/features/#backup-files-and-directories-using-snapshots) to save you money! Read the [repositories help page](https://kopia.io/docs/repositories/) for more information on supported storage locations.

With Kopia you are in full control of where to store your snapshots, that is, you pick the storage provider you want to use. You must provision and pay for the storage provider for whatever storage locations you want to use, and then tell Kopia what those storage locations are. You can even use multiple storage locations for different backup repositories if you want. Kopia also supports backing up multiple machines to the same storage location.

Kopia in Action
---

Using Kopia via command-line interface:

[![asciicast](https://asciinema.org/a/ykx6uzEhKY3451fWEnX9nm9uo.svg)](https://asciinema.org/a/ykx6uzEhKY3451fWEnX9nm9uo)

Using Kopia via graphical user interface (note: the video is of an older version of Kopia and the interface is different in the current version of Kopia, but the main principles of the interface are the same):

[![Kopia UI Tutorial](https://img.youtube.com/vi/sHJjSpasWIo/0.jpg)](https://www.youtube.com/watch?v=sHJjSpasWIo)

Getting Started
---
See [Kopia Documentation](https://kopia.io/docs/) for more information.

Building Kopia
---
See [Build Infrastructure](BUILD.md) for more information on building Kopia and working with the source code.

Licensing
---
Kopia is licensed under the Apache License, Version 2.0. See [LICENSE](LICENSE) for the full license text.

Contribution Guidelines
---
Kopia is open source and contributions are welcome. For more information on how to contribute see the [Contribution Guidelines](https://kopia.io/docs/contribution-guidelines/).

Reporting Security Issues
---
If you find a security issue you&#039;d like to disclose privately, please contact `security@kopia.io` or via direct message to maintainers on [Slack](https://slack.kopia.io).

[![Netlify Status](https://api.netlify.com/api/v1/badges/6b5c1fe4-a0da-4e7e-939b-ff1105251985/deploy-status)](https://app.netlify.com/sites/kopia/deploys)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gdy666/lucky]]></title>
            <link>https://github.com/gdy666/lucky</link>
            <guid>https://github.com/gdy666/lucky</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[ËΩØÁ°¨Ë∑ØÁî±ÂÖ¨ÁΩëÁ•ûÂô®,ipv6/ipv4 Á´ØÂè£ËΩ¨Âèë,ÂèçÂêë‰ª£ÁêÜ,DDNS,WOL,ipv4 stunÂÜÖÁΩëÁ©øÈÄè,cron,acme,ÈòøÈáå‰∫ëÁõò,ftp,webdav,filebrowser]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gdy666/lucky">gdy666/lucky</a></h1>
            <p>ËΩØÁ°¨Ë∑ØÁî±ÂÖ¨ÁΩëÁ•ûÂô®,ipv6/ipv4 Á´ØÂè£ËΩ¨Âèë,ÂèçÂêë‰ª£ÁêÜ,DDNS,WOL,ipv4 stunÂÜÖÁΩëÁ©øÈÄè,cron,acme,ÈòøÈáå‰∫ëÁõò,ftp,webdav,filebrowser</p>
            <p>Language: Go</p>
            <p>Stars: 6,297</p>
            <p>Forks: 588</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre># Lucky(‰∏áÂêâ)
 
 Êú¨È°πÁõÆ CDN Âä†ÈÄüÂèäÂÆâÂÖ®Èò≤Êä§Áî± Tencent EdgeOne ËµûÂä©
 [‰∫öÊ¥≤ÊúÄ‰Ω≥CDN„ÄÅËæπÁºòÂíåÂÆâÂÖ®Ëß£ÂÜ≥ÊñπÊ°à - Tencent EdgeOne](https://edgeone.ai/zh?from=github)

 ![](https://edgeone.ai/media/34fe3a45-492d-4ea4-ae5d-ea1087ca7b4b.png)
 


 ## Ê≥®ÊÑèÔºöÊ∫êÁ†ÅÂÖ¨Â∏ÉÂà∞1.4.10ÁâàÊú¨ÔºåÂêéÁª≠ÊöÇÊó†ÁªßÁª≠ÂºÄÊ∫êËÆ°Âàí„ÄÇ

 ## È∫ªÁÉ¶ÂêÑ‰ΩçÂ§ß‰Ω¨ÂèëË°®luckyÁõ∏ÂÖ≥ÊïôÁ®ãÁöÑÊó∂ÂÄô‰∏çË¶ÅÂä†‰∏ä‚ÄúÂºÄÊ∫ê‚ÄùÁ•ûÂô®ÔºåÂºÄÊ∫ê‰∫åÂ≠óÊàë‰∏çÈÖçÔºåluckyÂêéÁª≠‰πüÊ≤°ÂºÄÊ∫êÊâìÁÆó„ÄÇ
        1.ÂºÄÊ∫êÂπ∂‰∏çÁ≠â‰∫éÂÆâÂÖ®ÔºåÈó≠Ê∫êÂπ∂‰∏çÁ≠â‰∫é‰∏çÂÆâÂÖ®„ÄÇÈó≠Ê∫êËΩØ‰ª∂ÂºÄÂèë‰πü‰ºöÂèóÂà∞ÂÆâÂÖ®‰∫∫ÂëòÁöÑÂÆ°Êü•„ÄÇÊó†ËÆ∫ÊòØÂºÄÊ∫êËøòÊòØÈó≠Ê∫êËΩØ‰ª∂ÔºåÈÉΩÊúâÂèØËÉΩ‰ºöÂèóÂà∞ÂêÑÁßçÂÆâÂÖ®‰∫∫ÂëòÁöÑÂÆ°Êü•ÂíåÁ†îÁ©∂„ÄÇÂÆâÂÖ®‰∫∫ÂëòÂèØ‰ª•‰ΩøÁî®ÂêÑÁßçÊäÄÊúØÊâãÊÆµÊù•Ê£ÄÊµãËΩØ‰ª∂ÁöÑÂÆâÂÖ®ÊÄßÂíåÊºèÊ¥û„ÄÇ
        2. ‰∏™‰∫∫ËßÇÁÇπluckyËøôÁßçÂ∫îÁî®Á±ªËΩØ‰ª∂Êõ¥Â§öÂè™ÊòØ‰ΩìÂäõÊ¥ªÔºåÊØ´Êó†ÊäÄÊúØÂê´ÈáèÔºåÂºÄÊ∫êÁöÑ‰ºòÂäøÂú®‰∫éÈÄèÊòéÂ∫¶ÂíåÁ§æÂå∫ÂèÇ‰∏éÔºåÊõ¥Â§öÂä≥Âä®ÂäõÂèÇ‰∏éÔºå‰ΩÜ‰πüÂèØËÉΩÂØºËá¥ÂäüËÉΩËøáÂ§ö„ÄÅÂ§çÊùÇÂ∫¶Â¢ûÂä†ÁöÑÈóÆÈ¢ò„ÄÇÈó≠Ê∫êËΩØ‰ª∂ÁöÑ‰ºòÂäøÂú®‰∫éÊàëÊÉ≥ÊÄé‰πàÂÜôÂ∞±ÊÄé‰πàÂÜô,Âç≥‰ΩøËøòÊú™ËÉΩ‰ªélucky‰∏≠Ëé∑Âà©ÔºåluckyÂØπÊàë‰πüÊúâÊõ¥Ê∑±ÁöÑÁâπÊÆäÂê´‰πâ„ÄÇ
        3. ÊàëÂØπluckyÁöÑËßÑÂàíËøòÊúâ‰∏ÄÂ§ßÈÉ®ÂàÜÊú™ÂÆûÁé∞Ôºå‰∏çÊÉ≥Ë¢´‰∫∫ÂΩìÂÖçË¥πÂä≥Âä®Âäõ‰ΩøÂî§Ôºå‰∏çËß£ÈáäÂ§™Â§öÔºåÂ∞±ËøôÊ†∑„ÄÇ

 
 ## Â¶ÇÊûúÊÇ®ÊòØÁ¨¨‰∏ÄÊ¨°‰ΩøÁî®LuckyÔºåËØ∑Âä°ÂøÖÂÖàËÆøÈóÆ https://lucky666.cn ÔºåÂπ∂‰ªîÁªÜÈòÖËØªÁõ∏ÂÖ≥ÁöÑÊñáÊ°£Ôºå‰ª•Ëé∑ÂæóÂøÖË¶ÅÁöÑ‰ø°ÊÅØÂíåÁ≠îÊ°à„ÄÇÂú®Ëøô‰∫õÊñáÊ°£‰∏≠ÔºåÊÇ®ÂèØ‰ª•‰∫ÜËß£Âà∞LuckyÁöÑÂü∫Êú¨ÂäüËÉΩÂíåÁâπÊÄßÔºåÊéåÊè°LuckyÁöÑ‰ΩøÁî®ÊñπÊ≥ïÔºå‰ª•ÂèäËß£ÂÜ≥Â∏∏ËßÅÁöÑÈóÆÈ¢òÂíåÁñëÊÉë„ÄÇ
 

&lt;!-- TOC --&gt;
- [Lucky(‰∏áÂêâ)](#)
  - [ÁâπÊÄß](#ÁâπÊÄß)
  - [‰∏ÄÈîÆÂÆâË£Ö](#‰∏ÄÈîÆÂÆâË£Ö)
  - [OpenwrtIPKÂåÖÂÆâË£Ö](#OpenwrtIPKÂåÖÂÆâË£Ö)
  - [‰ΩøÁî®](#‰ΩøÁî®)
  - [Docker‰∏≠‰ΩøÁî®](#docker‰∏≠‰ΩøÁî®)
  - [ÂêéÂè∞ÁïåÈù¢](#ÂêéÂè∞ÁïåÈù¢)

  - [ÂºÄÂèëÁºñËØë](#ÂºÄÂèëÁºñËØë)
  - [Êõ¥Êñ∞Êó•Âøó](#Êõ¥Êñ∞Êó•Âøó)
  - [‰ΩøÁî®Ê≥®ÊÑè‰∏éÂ∏∏ËßÅÈóÆÈ¢ò](#‰ΩøÁî®Ê≥®ÊÑè‰∏éÂ∏∏ËßÅÈóÆÈ¢ò)

&lt;!-- /TOC --&gt;


## ÁâπÊÄß

LuckyÊúÄÂàùÊòØ‰Ωú‰∏∫‰∏Ä‰∏™Â∞èÂ∑•ÂÖ∑ÔºåÁî±ÂºÄÂèëËÄÖ‰∏∫Ëá™Â∑±ÁöÑ‰∏™‰∫∫‰ΩøÁî®ËÄåÂºÄÂèëÔºåÁî®‰∫éÊõø‰ª£socatÔºåÂú®Â∞èÁ±≥Ë∑ØÁî±AX6000ÂÆòÊñπÁ≥ªÁªü‰∏äÂÆûÁé∞ÂÖ¨ÁΩëIPv6ËΩ¨ÂÜÖÁΩëIPv4ÁöÑÂäüËÉΩ„ÄÇLuckyÁöÑËÆæËÆ°ÂßãÁªàËá¥Âäõ‰∫éËÆ©Êõ¥Â§öÁöÑLinuxÂµåÂÖ•ÂºèËÆæÂ§áËøêË°åÔºå‰ª•ÂÆûÁé∞ÊàñÈõÜÊàê‰∏™‰∫∫Áî®Êà∑Â∏∏Áî®ÂäüËÉΩÔºåÈôç‰ΩéÁî®Êà∑ÁöÑÁ°¨‰ª∂ÂíåËΩØ‰ª∂Êìç‰ΩúÂ≠¶‰π†ÊàêÊú¨ÔºåÂêåÊó∂ÂºïÂØº‰ΩøÁî®ËÄÖÊ≥®ÊÑèÁΩëÁªúÂÆâÂÖ®„ÄÇÈöèÁùÄÁâàÊú¨Êõ¥Êñ∞ÂíåÁΩëÂèãÂèçÈ¶àÔºåLucky‰∏çÊñ≠Ëø≠‰ª£ÊîπËøõÔºåÊã•ÊúâÊõ¥Â§öÂäüËÉΩÂíåÊõ¥Â•ΩÁöÑÊÄßËÉΩÔºåÊàê‰∏∫Áî®Êà∑ÂÄºÂæó‰ø°ËµñÁöÑÂ∑•ÂÖ∑„ÄÇ

Lucky ÁöÑÊ†∏ÂøÉÁ®ãÂ∫èÂÆåÂÖ®ÈááÁî® Golang ÂÆûÁé∞ÔºåÂÖ∑ÊúâÈ´òÊïà„ÄÅÁ®≥ÂÆö„ÄÅË∑®Âπ≥Âè∞Á≠â‰ºòÁÇπ„ÄÇÂÖ∂ÂêéÂè∞ÂâçÁ´ØÂàôÈááÁî® Vue3.2 ÊäÄÊúØËøõË°åÂºÄÂèëÔºåÂÖ∑ÊúâËâØÂ•ΩÁöÑÁî®Êà∑‰ΩìÈ™åÂíåÂìçÂ∫îÈÄüÂ∫¶„ÄÇÊ≠§Â§ñÔºåLucky ÁöÑÁÆ°ÁêÜÂêéÂè∞ÈááÁî®ÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑÊû∂ÊûÑÔºåÁ¨¨‰∏âÊñπÂºÄÂèëËÄÖ‰πüÂèØ‰ª•Ëá™Áî±‰ΩøÁî®OpenTokenËΩªÊùæË∞ÉÁî®LuckyÁöÑÂêÑÁßçÂäüËÉΩÊé•Âè£„ÄÇ



## ÂäüËÉΩÊ®°Âùó

ÁõÆÂâçÂ∑≤ÁªèÂÆûÁé∞/ÈõÜÊàêÁöÑ‰∏ªË¶ÅÂäüËÉΩÊ®°ÂùóÊúâ
  - Á´ØÂè£ËΩ¨Âèë
  - Âä®ÊÄÅÂüüÂêç(DDNS)
  - WebÊúçÂä°
  - StunÂÜÖÁΩëÁ©øÈÄè
  - ÁΩëÁªúÂî§ÈÜí
  - ËÆ°Âàí‰ªªÂä°
  - ACMEËá™Âä®ËØÅ‰π¶
  - ÁΩëÁªúÂ≠òÂÇ®



### Á´ØÂè£ËΩ¨Âèë
  1. ‰∏ªË¶ÅÁî®‰∫éÂÆûÁé∞ÂÖ¨ÁΩë IPv6 ËΩ¨ÂÜÖÁΩë IPv4 ÁöÑ TCP/UDP Á´ØÂè£ËΩ¨Âèë„ÄÇ
  2. ÊîØÊåÅÁïåÈù¢ÂåñÁöÑÁÆ°ÁêÜËΩ¨ÂèëËßÑÂàôÔºåÁî®Êà∑ÂèØ‰ª•ÈÄöËøá web ÂêéÂè∞ËΩªÊùæÂú∞ËøõË°åËßÑÂàôÁöÑÊ∑ªÂä†„ÄÅÂà†Èô§„ÄÅ‰øÆÊîπÁ≠âÊìç‰Ωú„ÄÇ
  3. ÂçïÊù°ËΩ¨ÂèëËßÑÂàôÊîØÊåÅËÆæÁΩÆÂ§ö‰∏™ËΩ¨ÂèëÁ´ØÂè£ÔºåËøôÊ†∑ÂèØ‰ª•ÂÆûÁé∞Â§ö‰∏™ÂÜÖÁΩëÊúçÂä°Á´ØÂè£ÁöÑËΩ¨Âèë„ÄÇ
  4. Êèê‰æõ‰∫Ü‰∏ÄÈîÆÂºÄÂÖ≥ÂíåÂÆöÊó∂ÂºÄÂÖ≥ÂäüËÉΩÔºåÁî®Êà∑ÂèØ‰ª•Ê†πÊçÆËá™Â∑±ÁöÑÈúÄÊ±ÇËÆæÁΩÆËΩ¨ÂèëËßÑÂàôÁöÑÂºÄÂêØÂíåÂÖ≥Èó≠Êó∂Èó¥ÔºåËøòÂèØ‰ª•‰ΩøÁî®ËÆ°Âàí‰ªªÂä°Ê®°ÂùóËøõË°åÂÆöÊó∂ÂºÄÂÖ≥„ÄÇ
  5. ÂçïÊù°ËßÑÂàôÊîØÊåÅÈªëÁôΩÂêçÂçïÂÆâÂÖ®Ê®°ÂºèÂàáÊç¢ÔºåÁî®Êà∑ÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅÈÄâÊã©‰ΩøÁî®ÁôΩÂêçÂçïÊ®°ÂºèÊàñÈªëÂêçÂçïÊ®°Âºè„ÄÇ
  6. ÁôΩÂêçÂçïÊ®°ÂºèÂèØ‰ª•ËÆ©Ê≤°ÊúâÂÆâÂÖ®È™åËØÅÁöÑÂÜÖÁΩëÊúçÂä°Á´ØÂè£Á®çÂæÆÂÆâÂÖ®‰∏ÄÁÇπÊö¥Èú≤Âà∞ÂÖ¨ÁΩëÔºåÊèêÈ´òÊúçÂä°ÂèØÁî®ÊÄß„ÄÇ
  7. ÂÆûÊó∂ËÆ∞ÂΩïÊúÄÊñ∞ÁöÑËÆøÈóÆÊó•ÂøóÔºåÊñπ‰æøÁî®Êà∑‰∫ÜËß£ËΩ¨ÂèëÊÉÖÂÜµ„ÄÇ
  8. ËßÑÂàôÂàóË°®Êó•Âøó‰∏ÄÁõÆ‰∫ÜÁÑ∂ÔºåÁî®Êà∑ÂèØ‰ª•Êñπ‰æøÂú∞ËøΩË∏™ËΩ¨ÂèëÂºÇÂ∏∏ÔºåÂèäÊó∂ËøõË°åÊéíÊü•ÂíåÂ§ÑÁêÜ„ÄÇ



### Âä®ÊÄÅÂüüÂêç(DDNS)
  1. ÊîØÊåÅÊé•ÂÖ•Â§ö‰∏™‰∏çÂêåÁöÑ DNS ÊúçÂä°ÂïÜ„ÄÇ
  2. ÊîØÊåÅÂÖ®ÂäüËÉΩËá™ÂÆö‰πâÂõûË∞ÉÔºàCallbackÔºâÔºåÂåÖÊã¨ËÆæÁΩÆ BasicAuthÔºåÊñπ‰æøÊé•ÂÖ•‰ªªÊÑè DNS ÊúçÂä°ÂïÜ„ÄÇ
  3. Webhook ÊîØÊåÅËá™ÂÆö‰πâ headers„ÄÇ
  4. ÂÜÖÁΩÆÂ∏∏Áî®ÂÖçË¥π DNS ÊúçÂä°ÂïÜËÆæÁΩÆÊ®°ÊùøÔºàÊØèÊ≠•„ÄÅNo-IP„ÄÅDynv6„ÄÅDynuÔºâÔºåÈÄöËøáËá™ÂÆö‰πâÂõûË∞ÉËøõË°åÂø´ÈÄüÊé•ÂÖ•Ôºå‰ªÖÈúÄ‰øÆÊîπÁõ∏Â∫îÁî®Êà∑ÂØÜÁ†ÅÊàñ token Âç≥ÂèØ‰∏ÄÈîÆÂ°´ÂÖÖ„ÄÇ
  5. ÊîØÊåÅ ÈòøÈáå‰∫ëÔºåÁôæÂ∫¶‰∫ëÔºåÂçé‰∏∫‰∫ëÔºå‰∫¨‰∏ú‰∫ëÔºåËÖæËÆØ‰∫ëÔºåÁÅ´Â±±ÂºïÊìéÔºåÂ∏ùÊÅ©Áà±ÊñØ-DNS.LA,CloudflareÔºådeSEC,DNSPod.CNÔºåDNSPod.COMÔºåDynadotÔºåDynv6ÔºåFreemyip ,GoDaddyÔºåName.comÔºåNameSilo,PorkbunÔºåVercelÁ≠âÊúçÂä°ÂïÜ„ÄÇ


### WebÊúçÂä°
  1. ÊîØÊåÅÂèçÂêë‰ª£ÁêÜ„ÄÅÈáçÂÆöÂêëÂíå URL Ë∑≥ËΩ¨„ÄÇ
  2. ÊîØÊåÅ HTTP Âü∫Êú¨ËÆ§ËØÅ„ÄÇ
  3. ÊîØÊåÅ IP ÈªëÁôΩÂêçÂçïÊ®°Âºè„ÄÇ
  4. ÊîØÊåÅ UserAgent ÈªëÁôΩÂêçÂçï„ÄÇ
  5. ËßÑÂàôÊó•ÂøóÊ∏ÖÊô∞ÊòìÊáÇÔºå‰æø‰∫éËøΩË∏™ÂºÇÂ∏∏„ÄÇ
  6. ÊîØÊåÅ‰∏ÄÈîÆÂºÄÂÖ≥ËßÑÂàôÂíåÂÆöÊó∂ÂºÄÂÖ≥ËßÑÂàô„ÄÇ


### StunÂÜÖÁΩëÁ©øÈÄè
  1. ÂÆûÁé∞ÂÜÖÁΩëÁ©øÈÄèÔºåÊó†ÈúÄÂÖ¨ÁΩëIPv4Âú∞ÂùÄ„ÄÇ
  2. ÈÄÇÂêà‰∫éÂõΩÂÜÖËøêËê•ÂïÜÁ∫ßNAT1ÂÆΩÂ∏¶ÁΩëÁªú. 

### ÁΩëÁªúÂî§ÈÜí
  1. ÊîØÊåÅËøúÁ®ãÊéßÂà∂Âî§ÈÜíÂíåÂÖ≥Êú∫Êìç‰Ωú
  2. ÊîØÊåÅÊé•ÂÖ•Á¨¨‰∏âÊñπÁâ©ËÅîÁΩëÂπ≥Âè∞(ÁÇπÁÅØÁßëÊäÄ Â∑¥Ê≥ï‰∫ë),ÂèØÈÄöËøáÂêÑÂ§ßÂπ≥Âè∞ÁöÑËØ≠Èü≥Âä©ÊâãÊéßÂà∂ËÆæÂ§áÂî§ÈÜíÂíåÂÖ≥Êú∫.

### ËÆ°Âàí‰ªªÂä°
  1. ‰∏ç‰æùËµñ Linux Á≥ªÁªüÁöÑ CronÔºåÊîØÊåÅ Windows Á≥ªÁªü„ÄÇ
  2. Êìç‰ΩúÁÆÄ‰æøÔºåÂèØËßÜÂåñÁºñËæë„ÄÇ
  3. ÂèØÊìç‰ΩúÊéßÂà∂ Lucky Ê°ÜÊû∂ÂÜÖÁöÑÂÖ∂‰ªñÊ®°ÂùóÂºÄÂÖ≥„ÄÇ

###  ACMEËá™Âä®ËØÅ‰π¶
  1. ÊîØÊåÅ ACME Ëá™Âä®ËØÅ‰π¶ÁöÑÁî≥ËØ∑ÂíåÁª≠Á≠æ„ÄÇ
  2. ÊîØÊåÅ ÈòøÈáå‰∫ëÔºåÁôæÂ∫¶‰∫ëÔºåÂçé‰∏∫‰∫ëÔºå‰∫¨‰∏ú‰∫ëÔºåËÖæËÆØ‰∫ëÔºåÁÅ´Â±±ÂºïÊìéÔºåÂ∏ùÊÅ©Áà±ÊñØ-DNS.LA,CloudflareÔºådeSEC,DNSPod.CNÔºåDNSPod.COMÔºåDynadotÔºåDynv6ÔºåFreemyip ,GoDaddyÔºåName.comÔºåNameSilo,PorkbunÔºåVercelÁ≠âÊúçÂä°ÂïÜ.


### ÁΩëÁªúÂ≠òÂÇ®
  1. ÁΩëÁªúÂ≠òÂÇ®Ê®°ÂùóÊòØ‰∏Ä‰∏™Â∫îÁî®ËåÉÂõ¥ÂπøÊ≥õÁöÑÊ®°ÂùóÔºåÂÆÉÊèê‰æõ‰∫ÜÂ∞ÜÊú¨Âú∞Â≠òÂÇ®„ÄÅWebDAVÂíåÈòøÈáå‰∫ëÁõòÊåÇËΩΩÂà∞LuckyÂÜÖÈÉ®ÁöÑÂêÑ‰∏™Êñá‰ª∂Á±ªÊúçÂä°ÂäüËÉΩ„ÄÇ
  2. ÈÄöËøáÁΩëÁªúÂ≠òÂÇ®Ê®°ÂùóÔºå‰Ω†ÂèØ‰ª•Â∞ÜÊ∑ªÂä†ÁöÑÂ≠òÂÇ®ÊåÇËΩΩÂà∞WebÊúçÂä°ÁöÑÊñá‰ª∂ÊúçÂä°„ÄÅWebDAV„ÄÅFTPÂíåFileBrowserÊ®°ÂùóÔºåÂÆûÁé∞Êõ¥Âä†‰æøÊç∑ÁöÑÊñá‰ª∂ÁÆ°ÁêÜÂíåËÆøÈóÆ„ÄÇ





## ‰∏ÄÈîÆÂÆâË£Ö

- [‰∏ÄÈîÆÂÆâË£ÖËØ¶ÁúãËøôÈáå](https://github.com/gdy666/lucky-files)


## OpenwrtIPKÂåÖÂÆâË£Ö

- [Openwrt IPKÂåÖ](https://github.com/gdy666/luci-app-lucky)


## ‰ΩøÁî®
    

- ÈªòËÆ§ÂêéÂè∞ÁÆ°ÁêÜÂú∞ÂùÄ http://&lt;ËøêË°åËÆæÂ§áIP&gt;:16601
  ÈªòËÆ§ÁôªÂΩïË¥¶Âè∑: 666
  ÈªòËÆ§ÁôªÂΩïÂØÜÁ†Å: 666

- Â∏∏ËßÑ‰ΩøÁî®ËØ∑Áî® -cd &lt;ÈÖçÁΩÆÊñá‰ª∂Â§πË∑ØÂæÑ&gt; ÊåáÂÆöÈÖçÁΩÆÊñá‰ª∂Â§πÁöÑÊñπÂºèËøêË°å 
    ```bash
    #‰ªÖÊåáÂÆöÈÖçÁΩÆÊñá‰ª∂Â§πË∑ØÂæÑ(Â¶ÇÊûúÈÖçÁΩÆÊñá‰ª∂Â§π‰∏çÂ≠òÂú®‰ºöËá™Âä®ÂàõÂª∫),Âª∫ËÆÆ‰ΩøÁî®ÁªùÂØπË∑ØÂæÑ
    lucky -cd luckyconf

    ```




## Docker‰∏≠‰ΩøÁî®

- ‰∏çÊåÇËΩΩ‰∏ªÊú∫ÁõÆÂΩï, Âà†Èô§ÂÆπÂô®ÂêåÊó∂‰ºöÂà†Èô§ÈÖçÁΩÆ

  ```bash
  # hostÊ®°Âºè, ÂêåÊó∂ÊîØÊåÅIPv4/IPv6, LiunxÁ≥ªÁªüÊé®Ëçê
  docker run -d --name lucky --restart=always --net=host gdy666/lucky
  # Ê°•Êé•Ê®°Âºè, Âè™ÊîØÊåÅIPv4, Mac/WindowsÊé®Ëçê,windows ‰∏çÊé®Ëçê‰ΩøÁî®dockerÁâàÊú¨
  docker run -d --name lucky --restart=always -p 16601:16601 gdy666/lucky
  ```

- Âú®ÊµèËßàÂô®‰∏≠ÊâìÂºÄ`http://‰∏ªÊú∫IP:16601`Ôºå‰øÆÊîπ‰Ω†ÁöÑÈÖçÁΩÆÔºåÊàêÂäü
- [ÂèØÈÄâ] ÊåÇËΩΩ‰∏ªÊú∫ÁõÆÂΩï, Âà†Èô§ÂÆπÂô®ÂêéÈÖçÁΩÆ‰∏ç‰ºö‰∏¢Â§±„ÄÇÂèØÊõøÊç¢ `/root/luckyconf` ‰∏∫‰∏ªÊú∫ÁõÆÂΩï, ÈÖçÁΩÆÊñá‰ª∂Â§π‰∏∫lucky

  ```bash
  docker run -d --name lucky --restart=always --net=host -v /root/luckyconf:/goodluck gdy666/lucky
  ```


## ÂÆùÂ°îDockerÂÆâË£Ö

1.  ÂÆâË£ÖÂÆùÂ°îÈù¢Êùø (9.2.0ÁâàÊú¨Âèä‰ª•‰∏ä)ÔºåÂâçÂæÄ [ÂÆùÂ°îÈù¢Êùø](https://www.bt.cn/new/download.html) ÂÆòÁΩëÔºåÈÄâÊã©Ê≠£ÂºèÁâàÁöÑËÑöÊú¨‰∏ãËΩΩÂÆâË£Ö
2.  ÂÆâË£ÖÂêéÁôªÂΩïÂÆùÂ°îÈù¢ÊùøÔºåÂú®ËèúÂçïÊ†è‰∏≠ÁÇπÂáª Docker ÔºåÈ¶ñÊ¨°ËøõÂÖ•‰ºöÊèêÁ§∫ÂÆâË£Ö Docker ÊúçÂä°ÔºåÁÇπÂáªÁ´ãÂç≥ÂÆâË£ÖÔºåÊåâÊèêÁ§∫ÂÆåÊàêÂÆâË£Ö
3.  ÂÆâË£ÖÂÆåÊàêÂêéÂú®Â∫îÁî®ÂïÜÂ∫ó‰∏≠ÊâæÂà∞ lucky ÔºåÁÇπÂáªÂÆâË£ÖÔºåÈÖçÁΩÆÂü∫Êú¨ÈÄâÈ°π Âç≥ÂèØÂÆåÊàêÂÆâË£Ö










#ÂºÄÂèëÁºñËØë


    ```bash
    go build -v -tags &quot;adminweb nomsgpack&quot; -ldflags=&quot;-s -w&quot;
    ```


# Êõ¥Êñ∞Êó•Âøó

    2025-08-24 v2.18.5 Êõ¥Êñ∞Êó•Âøó
        1. ‰øÆÂ§çÁî±‰Ωé‰∫é v2.15.0 ÁöÑÁâàÊú¨ÂçáÁ∫ßÊó∂ÔºåÂèØËÉΩÂØºËá¥ DDNS ÈÖçÁΩÆ‰∏¢Â§±ÁöÑÊÉÖÂÜµ„ÄÇ
        2. ‰øÆÂ§çÂâçÁ´ØÂ∑≤Áü• Bug
        3. Web ÊúçÂä°ÂäüËÉΩ‰ºòÂåñ
        Êñ∞Â¢û‰∏ªËßÑÂàôÂø´Êç∑ÁºñËæëÂäüËÉΩÔºö
        ÊîØÊåÅÊâπÈáèÊ∑ªÂä†„ÄÅ‰øÆÊîπ„ÄÅÂà†Èô§ÂâçÁ´ØÂüüÂêçÔºõ
        ÊîØÊåÅÊâπÈáèÊõøÊç¢„ÄÅ‰øÆÊîπÂêéÁ´ØÈÖçÁΩÆÔºõ
        Êñ∞Â¢û„ÄåÂ§çÂà∂ Web ÊúçÂä°ËßÑÂàô„ÄçÂäüËÉΩ„ÄÇ
        4.rclone ÂçáÁ∫ßËá≥ v1.17.0„ÄÇ

    2025-08-17 v2.18.4
        1. ‰ΩøÁî® Go 1.25.0 ÁºñËØëÊûÑÂª∫,macOS Á≥ªÁªüÊúÄ‰ΩéÊîØÊåÅÁâàÊú¨ÊèêÂçáËá≥ 12.0 Âèä‰ª•‰∏ä„ÄÇ
        2. ÁôªÂΩï‰ºòÂåñÔºö‰øÆÂ§çÂàáÊç¢ÂêéÁ´ØÊó∂Êú™ÂãæÈÄâ‚ÄúËÆ∞‰ΩèÂØÜÁ†Å‚ÄùÂØºËá¥Ë¥¶Âè∑ÂØÜÁ†ÅÊó†Ê≥ïËá™Âä®Â°´ÂÖÖÁöÑÈóÆÈ¢ò„ÄÇ
        3. ÂêéÁ´ØÊúçÂä°Âô®ÂàóË°®ÊîØÊåÅ ÂØºÂÖ•/ÂØºÂá∫„ÄÇÂâçÁ´Ø‰ΩøÁî® HTTPS Êó∂Ôºå‰ºöÈòªÊ≠¢ËøûÊé•Âà∞ HTTP ÂêéÁ´ØÂπ∂ÊèêÁ§∫„ÄÇ
        4. luckyÂêéÂè∞ËÆæÁΩÆÈ°µÈù¢Êñ∞Â¢û ÂêéÁ´ØÂàóË°®Â§á‰ªΩ‰∏éÊÅ¢Â§ç ÂäüËÉΩ„ÄÇ
        5. Filebrowser ÂçáÁ∫ßËá≥ v2.42.5„ÄÇ
        6. Cloudflare ÈößÈÅìÊñ∞Â¢û ÂÆöÊó∂Ê£ÄÊü•‰∏éËá™Âä®ÈáçËøû Êú∫Âà∂„ÄÇ

    2025-08-13 v2.18.3 beta1
        1. Lucky &amp; ‰∏áÂêâÔºöÊñ∞Â¢û Core Á≤æÁÆÄÁâàÊú¨
            ÁßªÈô§‰∫ÜÂâçÁ´ØÊñá‰ª∂Ôºå‰∫åËøõÂà∂Êñá‰ª∂‰ΩìÁßØÊØîÊ†áÂáÜÁâàÂáèÂ∞ëÁ∫¶ 1 MBÔºåÈÄÇÂêàÂ≠òÂÇ®Á©∫Èó¥ÊúâÈôêÁöÑË∑ØÁî±Âô®ÁéØÂ¢É„ÄÇ
            Core ÁâàËÆøÈóÆ Lucky ÂêéÂè∞Êó∂ÔºåÂ∞ÜËá™Âä®Ë∑≥ËΩ¨Ëá≥ÂÖ¨ÂÖ±ÂâçÁ´ØÂú∞ÂùÄÔºöhttps://lucky.666666.host/&lt;ÁâàÊú¨Âè∑&gt; ËøõË°åÁôªÂΩï„ÄÇ
            ÁôªÂΩïÈ°µÈù¢Â∫ïÈÉ®Êèê‰æõËá™ÂÆö‰πâÂêéÁ´ØÁÆ°ÁêÜÂÖ•Âè£ÔºåÂèØÊñπ‰æøÁªëÂÆöËá™Â∑±ÁöÑ Lucky Core ËäÇÁÇπ„ÄÇ.
            ‰πüÂèØ‰ΩøÁî®Ëá™Âª∫ÁöÑÈùû Core ÁâàÂâçÁ´ØÊù•ÁÆ°ÁêÜ Core ÁâàÂÆû‰æã„ÄÇ
        2. ÂâçÁ´Ø‰ºòÂåñ‰∏é Bug ‰øÆÂ§ç
            ‰øÆÂ§çÔºöÁ¶ÅÁî®ÂÆâÂÖ®ÂÖ•Âè£Ê£ÄÊµãÂêéÔºå‰ªçÊèêÁ§∫ÂÆâÂÖ®ÂÖ•Âè£Êú™ËÆæÁΩÆÁöÑÈóÆÈ¢òÔºà‰∏¥Êó∂Ëß£ÂÜ≥ÊñπÊ≥ïÔºöÂà∑Êñ∞È°µÈù¢Ôºâ„ÄÇ
            ÁôªÂΩïÈ°µÈù¢Êñ∞Â¢û‚ÄúÁÆ°ÁêÜÂàáÊç¢ÂêéÁ´Ø‚ÄùÂÖ•Âè£ÔºåÊñπ‰æøÂø´ÈÄüÂàáÊç¢ÂíåËÆøÈóÆ‰∏çÂêå Lucky ÂêéÁ´Ø„ÄÇ
        3. FileBrowser ÂçáÁ∫ßËá≥ v2.42.3„ÄÇ
        4. DDNS ‰ºòÂåñ
            ‰øÆÂ§çÂÅ∂Âèë‰ªªÂä°ÈòªÂ°ûÈóÆÈ¢ò„ÄÇ
            ‰øÆÂ§çÂ§ö‰∏™ DDNS Ë∞ÉÊï¥È°∫Â∫èÂêéÔºåÂâçÁ´ØÂàóË°®ÊòæÁ§∫ÂºÇÂ∏∏ÁöÑÈóÆÈ¢ò„ÄÇ
        5.ÂüüÂêç‰∏éËØÅ‰π¶
            ‰øÆÂ§ç deSEC.io Áî≥ËØ∑ËØÅ‰π¶Êó∂Âá∫ÈîôÁöÑÈóÆÈ¢ò„ÄÇ
            ÈíàÂØπ‰∏çÂêåÂüüÂêçÊâòÁÆ°ÂïÜÁöÑÊúÄÂ∞è TTLÔºåËá™Âä®Ë∞ÉÊï¥‰º†Êí≠Ê£ÄÊµãË∂ÖÊó∂Êó∂Èó¥„ÄÇ
        6.NTP ÊúçÂä°‰ºòÂåñ
            ÂÜÖÁΩÆ NTP ÊúçÂä°Âô®ÂàóË°®Êõ¥Êñ∞ÔºåÈÉ®ÂàÜÊîØÊåÅ IPv4/IPv6 ÂèåÊ†à

    2025-08-03 v2.18.2beta1
        1. DDNSÊ®°Âùó‰∏éACMEËØÅ‰π¶Ê®°ÂùóÊñ∞Â¢ûÂØπEdgeOneÊé•Âè£ÁöÑÊîØÊåÅÔºàÂÖºÂÆπ‰∏≠ÂõΩÁâà‰∏éÂõΩÈôÖÁâàÔºâ„ÄÇ
        2. ‰∏áÂêâÈõÜÊàê‰∫ÜCloudflare TunnelÂÆ¢Êà∑Á´ØÔºåÊèêÂçáËøúÁ®ãËÆøÈóÆËÉΩÂäõ„ÄÇ
        ‰ª§ÁâåËé∑ÂèñÊñπÊ≥ïÔºöÂú®ÈößÈÅìÊ¶ÇËø∞È°µÈù¢‰∏≠ÔºåËøêË°å‰ª•‰∏ãÂëΩ‰ª§Ôºö cloudflared.exe service install XXXÔºåÂÖ∂‰∏≠ÊúÄÂêé‰∏Ä‰∏™ÂèÇÊï∞Âç≥‰∏∫ÊâÄÈúÄÁöÑ‰ª§Áâå„ÄÇ
        Ê≤°ÊúâÈõÜÊàêFRPÁöÑËÆ°ÂàíÔºåÊó†È°ªÈáçÂ§çÂí®ËØ¢„ÄÇ
        3. filebrowser Êõ¥Êñ∞Ëá≥ 2.42.1 ÁâàÊú¨„ÄÇ
        4. rclone Êõ¥Êñ∞Ëá≥ v1.70.2 ÁâàÊú¨„ÄÇ

    2025-07-12 v2.18.1
      1.FileBrowser Êõ¥Êñ∞Ëá≥ v2.37.0
      2.rclone Êõ¥Êñ∞Ëá≥ v1.70.2
      3.‰øÆÂ§ç WebÊúçÂä° SNI TCPÂ±ÇÊã¶Êà™Êú™ËÉΩÊ≠£Á°ÆËØÜÂà´ÂíåÂà§Êñ≠Ê≥õÂüüÂêçÁöÑÈóÆÈ¢ò
      4.Coraza ÂÜÖÁΩÆËßÑÂàô ÂçáÁ∫ßËá≥ 4.16.0
      5.WebÊúçÂä° Â¢ûÂä† SNI ÂàÜÊµÅÂäüËÉΩ
      - Ê≥®ÊÑèÔºöSNIÂàÜÊµÅÂäüËÉΩ‰ªÖ‰æõ‰∏™‰∫∫ÂêàÊ≥ïÁî®ÈÄî‰ΩøÁî®ÔºåÂ¶ÇÂèëÁé∞Áõ∏ÂÖ≥ËøùÊ≥ï‰ΩøÁî®ÊïôÁ®ãÔºåÂ∞Ü‰∏ãÁ∫øÊ≠§ÂäüËÉΩ„ÄÇ
      6.‰øÆÂ§ç ‰∏ÄÈîÆÂÆâË£ÖÂú® openwrt ÁéØÂ¢É‰∏ãÂ§±Ë¥•ÁöÑÈóÆÈ¢ò
      7.‰ºòÂåñ SNI ÂåπÈÖçÂ≠êËßÑÂàôÂüüÂêçÁöÑÈÄªËæë

    2025-07-09 lucky v2.18.0
      1.WebÊúçÂä°ÔºöÂú®TCPÂ±ÇÈ¢ÑÂÖàËØÜÂà´HTTPSÁöÑSNI‰ø°ÊÅØÔºåÂΩìSNI‰∏çÂåπÈÖçËßÑÂàôÂüüÂêçÂπ∂‰∏îÈªòËÆ§ËßÑÂàô‰∏∫ÂÖ≥Èó≠ËøûÊé•Êó∂ÔºåÁ´ãÂç≥ÂÖ≥Èó≠ËøûÊé•ÔºåÊèêÂçáÂÆâÂÖ®ÊÄßÔºåÊúâÊïàÈò≤Ê≠¢Á´ØÂè£‰∏éÊúçÂä°Ë¢´Êé¢ÊµãÊàñËØÜÂà´„ÄÇ
      2.WebÊúçÂä°ÔºöÂ¢ûÂº∫ÂèçÂêë‰ª£ÁêÜÂäüËÉΩÔºåÊèêÈ´òÂØπÂçéÁ°ïAiCloudÁöÑÂÖºÂÆπÊÄßÔºå‰ºòÂåñÊé•ÂÖ•‰ΩìÈ™å„ÄÇ
      Áî±‰∫éÂ∞èÁà±Á≠âÂπ≥Âè∞ÂÆ°Ê†∏Ë¶ÅÊ±ÇÂèòÊõ¥Ôºå‰∏çÂÜçÊîØÊåÅ‰∏™‰∫∫DIYËÆæÂ§á‰ΩøÁî®ÔºàË¶ÅÊ±Ç‰∏äÁ∫ø‰∫ßÂìÅÂøÖÈ°ªÊúâ3CËÆ§ËØÅÔºâÁÇπÁÅØÂπ≥Âè∞Â∑≤‰∏ãÁ∫øÁé∞ÊúâËØ≠Èü≥Âä©ÊâãÁõ∏ÂÖ≥ÊúçÂä°„ÄÇ

    2025-06-03 v2.17.8
      ‰ºòÂåñÔºöÁΩëÈÄüË∂ãÂäøÊõ≤Á∫øÁé∞ÊîØÊåÅ Mbps ‰∏é MB/s ÂèåÂçï‰ΩçÂêåÊ≠•ÊòæÁ§∫ÔºåÊñπ‰æøÂêåÊó∂Êü•ÁúãÁΩëÁªúÂ∏¶ÂÆΩÂèä‰º†ËæìÈÄüÂ∫¶„ÄÇ

    2025-06-03 v2.17.8beta 
      1. Âä®ÊÄÅÂüüÂêç
      ‰øÆÂ§çÂêåÊ≠• dynv6 ÁöÑ CNAME„ÄÅSRV„ÄÅMX ËÆ∞ÂΩïÁöÑÂ∑≤Áü•ÈóÆÈ¢ò„ÄÇËØ∑ÂÖàÂú® dynv6 Âπ≥Âè∞Âà†Èô§ÂéüÊúâÂØπÊé•ËÆ∞ÂΩïÔºåÂÜçÈáçÊñ∞ÊâßË°åÂêåÊ≠•Êìç‰Ωú„ÄÇ
      2. Â≠òÂÇ®ÁÆ°ÁêÜ
      Â≠òÂÇ®ÁÆ°ÁêÜÂäüËÉΩÂ∑≤ÂÅúÊ≠¢Áª¥Êä§ÔºåÈòøÈáå‰∫ëÁõòÂèä WebDAV Â≠òÂÇ®ÂäüËÉΩÂÅúÁî®ÔºåËØ∑ÂãøÂÜç‰ΩøÁî®„ÄÇÂ¶ÇÈúÄËÆæÂÆöÊú¨Âú∞Ë∑ØÂæÑÔºåËØ∑Áõ¥Êé•Âú® FTP„ÄÅWebDAV„ÄÅFileBrowser Á≠âÊñá‰ª∂ÊúçÂä°‰∏≠ÈÖçÁΩÆ„ÄÇ
      3.WebÊúçÂä°
      Êñ∞Â¢û‚ÄúÁ¶ÅÁî®ËøûÊé•Â§çÁî®‚ÄùÂºÄÂÖ≥„ÄÇÂ¶Ç OpenWrt ÂêéÂè∞ÂèçÂêë‰ª£ÁêÜÂá∫Áé∞ &quot;Unsolicited response received on idle HTTP channel starting with &#039;0\r\n\r\n&#039;&quot; ÈîôËØØÔºåËØ∑Âú®ËØ•Â≠êËßÑÂàôÁöÑÂÆöÂà∂Ê®°Âºè-ÁΩëÁªúËÆæÁΩÆ‰∏≠ÂêØÁî®Ê≠§ÂºÄÂÖ≥„ÄÇ‰∏∫ÊèêÂçáÂèçÂêë‰ª£ÁêÜÊÄßËÉΩÔºåÂÖ∂‰ªñËßÑÂàôÈÄöÂ∏∏Êó†ÈúÄÂºÄÂêØ„ÄÇ
      4. WebDAVÊúçÂä°
      ÈÄöËøá RaiDrive ÊåÇËΩΩÂàÜÂå∫Êó∂ÊîØÊåÅÊòæÁ§∫ÁúüÂÆûÂèØÁî®Á©∫Èó¥„ÄÇ
      5. FileBrowserÂäüËÉΩ‰øÆÂ§ç
      ‰øÆÂ§ç FileBrowser Áî®Êà∑Ëá™Âä©Ê≥®ÂÜåÂäüËÉΩ„ÄÇ

    2025-05-31 v2.17.7 beta
      1. ‰øÆÂ§çËØÅ‰π¶Ë∑ØÂæÑÂØºÂÖ•Êó∂ÔºåÁî±‰∫éËØÅ‰π¶ÂüüÂêçÈ°∫Â∫è‰∏ç‰∏ÄËá¥ÂØºËá¥ÁöÑËØÅ‰π¶Âà∑Êñ∞Â§±Ë¥•ÈóÆÈ¢ò„ÄÇ
      2. ‰øÆÂ§çÂØπÊé•ÁÇπÁÅØÊúçÂä°Âô®Êó∂ÔºåÁÇπÁÅØÊó†Ê≥ïËøûÊé•ÂØºËá¥ÁöÑÂçèÁ®ãÊ≥ÑÊºèÁ≠âÈóÆÈ¢ò„ÄÇ
      3. Êõ¥Êñ∞ÂØπÊé•ÁÇπÁÅØÊúçÂä°Âô®Êó∂ÁöÑ User-Agent ‰∏∫ ‚ÄúLucky-Client/lucky666.cn‚ÄùÔºå‰ª•Ëß£ÂÜ≥ÂâçÈù¢ÁâàÊú¨Êó†Ê≥ïËøûÊé•ÁÇπÁÅØÊúçÂä°Âô®ÁöÑÈóÆÈ¢ò„ÄÇÂ¶ÇËØ• User-Agent Ë¢´ÁÇπÁÅØÊúçÂä°Âô®ÊãâÈªëÔºå‰∏éÁÇπÁÅØÂØπÊé•ÂäüËÉΩÂ∞ÜÊ∞∏‰πÖÂèñÊ∂à„ÄÇ
      4. ‰ºòÂåñÁ≥ªÁªüËµÑÊ∫êÁªüËÆ°Áõ∏ÂÖ≥‰ª£Á†ÅÔºåÊîπËøõ Lucky ÊÄªËßàÈ°µÈù¢ÔºåÊñ∞Â¢û CPU ‰ΩøÁî®Áéá„ÄÅÂÆûÊó∂ÁΩëÈÄüÊõ≤Á∫øÂõæ‰∏éËøõÁ®ãÂΩìÂâçÊâìÂºÄÂè•ÊüÑÊï∞Â±ïÁ§∫„ÄÇ
      5. ËÆæÁΩÆÈ°µÈù¢Êñ∞Â¢û‚ÄúÊåáÂÆöÁõëÊµãÁΩëÂç°‚ÄùÂäüËÉΩÔºåÊîØÊåÅÁî®Êà∑Ëá™ÂÆö‰πâÁõëÊµãÁöÑÁΩëÂç°„ÄÇ

    2025-05-25 v2.17.6 
        1.STUNÊ®°Âùó
          Êñ∞Â¢û NAT Á±ªÂûãÊ£ÄÊµãÂäüËÉΩ„ÄÇ
        2.ËÑöÊú¨ÊâßË°å
          ‰øÆÂ§ç #! È¶ñË°åÂà§Êñ≠ÈîôËØØÔºåÁ°Æ‰øùËÑöÊú¨Ê≠£Á°ÆË∞ÉÁî® Bash ÊâßË°å„ÄÇ
        3.DDNS
          ‰øÆÂ§çÈÉ®ÂàÜÊÉÖÂÜµ‰∏ã IPv6 Âú∞ÂùÄÊó†Ê≥ïÈÄöËøá odhcpv6 Ëé∑ÂèñÁöÑÈóÆÈ¢ò„ÄÇ
        4.WebÊúçÂä°
          4.1 ‰ºòÂåñÁªüËÆ°ÁªÑ‰ª∂ÁªÜËäÇÔºåÂΩìÂ≠êËßÑÂàô Coraza Êú™ÂêØÁî®Êó∂‰∏çÊòæÁ§∫ÁªüËÆ°Êï∞ÊçÆ„ÄÇ
          4.2 ‰∏ªËßÑÂàôÂÆâÂÖ®Ê®°ÂºèÊîπ‰∏∫Âú® TCP Â±ÇÂ§ÑÁêÜÔºåÂÆûÁé∞ÂõõÂ±ÇÂÆâÂÖ®Ê£ÄÊµã„ÄÇË¢´Êã¶Êà™ËøûÊé•Áõ¥Êé•Êñ≠ÂºÄÔºå‰∏çÂÜçËøîÂõû 403ÔºåÊèêÂçáÊ£ÄÊµãÊïàÁéá„ÄÇ
          4.3 Â¢ûÂä†ÂÖ®Â±ÄËÆ§ËØÅÈÖçÁΩÆÔºåÂ≠êËßÑÂàôÂèØÊåáÂÆöÁªßÊâøÁªü‰∏ÄËÆ§ËØÅÔºåÊó†ÈúÄÂçïÁã¨ÈáçÂ§çËÆæÁΩÆÔºåÂÆûÁé∞Áªü‰∏ÄÁÆ°ÁêÜ„ÄÇ
          4.4 ÊîØÊåÅËÆæÁΩÆÂçï‰∏™ IP ÁöÑ Coraza Êã¶Êà™Ê¨°Êï∞‰∏äÈôêÔºåË∂ÖÈôêÂêéËá™Âä®ÊãâÈªëÔºàÂäüËÉΩÂç≥Â∞ÜÂºÄÊîæÔºâ
        5.Coraza
          5.1 ÂÜÖÁΩÆËßÑÂàôÈõÜÂçáÁ∫ßËá≥ 4.14„ÄÇ
        6.ÂÖ®Â±ÄËÆæÁΩÆ
          6.1 Êñ∞Â¢ûÊîØÊåÅËá™ÂÆö‰πâÈÄâÊã©Á≥ªÁªüÈªòËÆ§ÂÜÖÁΩÆ DNS Ëß£ÊûêÂô®ÔºàÈÄâÈ°πÔºödefaultÔºâ„ÄÇ
          6.2 Êñ∞Â¢ûÂÖ®Â±ÄÊó†ÈôêÂà∂ CIDR ÂàóË°®ÔºåÂàóË°®ÂÜÖÂú∞ÂùÄÂ∞Ü‰∏çÂèóÊâÄÊúâ Web ÊúçÂä°ÈÄüÁéá‰∏éËøûÊé•Êï∞ÈôêÂà∂ÔºàÂäüËÉΩÂç≥Â∞ÜÂºÄÊîæÔºâ„ÄÇ
          6.3 OpenTokenÂÆâÂÖ®ÔºåËã•È™åËØÅÂ§±Ë¥•Ë∂ÖËøá 66 Ê¨°ÔºåÂ∞ÜËá™Âä®Á¶ÅÁî® OpenToken Âπ∂ÊèêÁ§∫ÈúÄÈáçÂêØ LuckyÔºåÂêåÊó∂ÊèêÈÜíÁî®Êà∑‰øÆÊîπÂÆâÂÖ®ÂÖ•Âè£„ÄÇ
        7. IP‰ø°ÊÅØÊü•ËØ¢
          Êü•ËØ¢ÊÄßËÉΩËøõ‰∏ÄÊ≠•‰ºòÂåñ„ÄÇ
        8. ‰øÆÂ§çÂ∑≤Áü•bugÂíåÂÖ∂ÂÆÉÁªÜËäÇÂèäÊÄßËÉΩ‰ºòÂåñ
        9.DockerÁâàÊú¨
          È¢ÑË£Ö curl Â∑•ÂÖ∑ÂåÖÔºåÊñπ‰æøÂÆπÂô®ÂÜÖËøõË°åÁΩëÁªúÁõ∏ÂÖ≥Êìç‰Ωú„ÄÇ

    2025-05-11 v2.17.5 beta
        1. ‰øÆÂ§çÔºöËß£ÂÜ≥‰∏ä‰∏™ beta ÁâàÊú¨Âõ†ÂéãÁº©ÈîôËØØÂØºËá¥Êó†Ê≥ïÂú® Linux Á≥ªÁªü‰∏ãËøêË°åÁöÑÈóÆÈ¢ò„ÄÇ
        2. Êñ∞Â¢ûÔºöWeb ÊúçÂä°ÊîØÊåÅ HomeBox ÂÜÖÁΩëÊµãÈÄüÂêéÁ´ØÊúçÂä°Á±ªÂûãÔºåÂèØ‰∏é HomeBox ‰øÆÊîπÁâàÂâçÁ´ØÈÖçÂêà‰ΩøÁî®„ÄÇ
            GitHub Âú∞ÂùÄÔºöhttps://github.com/gdy666/homebox
            Êé®Ëçê‰ΩøÁî® http ÂçèËÆÆËøõË°åÂÜÖÁΩëÊµãÈÄü„ÄÇ
            Â¶Ç‰∏çÊÉ≥Ëá™Âª∫ÂâçÁ´ØÔºåÂèØÁõ¥Êé•‰ΩøÁî®‰ª•‰∏ãÊµãÈÄüÈ°µÈù¢Ôºö
            http://speedtest.66666.host/
            https://speedtest.66666.host/
            ËØ∑Âú®È´òÁ∫ßÈÖçÁΩÆ‰∏≠Â°´ÂÜô‰Ω†Âú® Lucky ‰∏≠ËÆæÁΩÆÁöÑÂÜÖÁΩëÊµãÈÄüÂú∞ÂùÄ„ÄÇ

    2025-05-11 v2.17.4 Beta 
      ‰ºòÂåñÔºöËÆ°Âàí‰ªªÂä°Ê®°ÂùóÔºåÊèêÂçáIPÊü•ËØ¢ÊÄßËÉΩ„ÄÇ
      ‰øÆÂ§çÔºöWebÊúçÂä°‰∏≠ÔºåÊ†áËÆ∞Â≠êËßÑÂàôÊó∂ÈªòËÆ§ËßÑÂàôÊú™Ê≠£Á°ÆÈöêËóèÁöÑÈóÆÈ¢ò„ÄÇ
      Êñ∞Â¢ûÔºöWebÊúçÂä°ÊîØÊåÅProxy ProtocolÂçèËÆÆËá™Âä®ËØÜÂà´„ÄÇËØ∑ÂâçÂæÄLuckyËÆæÁΩÆÈ°µÈù¢ÔºåÂú®‚ÄúÂÖ®Â±Ä‰ª£ÁêÜÂçèËÆÆ‰ø°‰ªªÁöÑCIDRÂàóË°®‚Äù‰∏≠Ê∑ªÂä†Êú¨Âú∞Áõ¥Êé•ËÆøÈóÆIPÔºàÂ¶Ç127.0.0.1Ôºâ‰ª•ÂêØÁî®„ÄÇ
   
    2025-05-09 v2.17.3
        ‰øÆÂ§çÂú®ÁâπÊÆä Docker Â§öÁâàÊú¨ Lucky ÁéØÂ¢É‰∏ãÔºåÊàñÈ¢ëÁπÅÂçáÈôçÁ∫ß Lucky ÁâàÊú¨Êó∂ÔºåÂõ†ÈÖçÁΩÆÂèÇÊï∞‰∏¢Â§±ÂØºËá¥ DDNS ÊåÅÁª≠Êó†Èó¥Êñ≠Ê£ÄÊµãÔºå‰ªéËÄåÂºïÂèë CPU Âç†Áî®ËøáÈ´òÁöÑÈóÆÈ¢ò„ÄÇ
        2.17.2 ÁâàÊú¨‰ΩøÁî®Ê≠£Â∏∏ÁöÑÁî®Êà∑ÂèØÂøΩÁï•Êú¨Ê¨°Êõ¥Êñ∞„ÄÇÂ¶ÇÈÅá CPU Âç†Áî®ËøáÈ´òÔºå‰∫¶ÂèØÈÄöËøáÁºñËæëÂπ∂‰øùÂ≠ò‰∏ÄÊ¨° DDNS ‰ªªÂä°ÊÅ¢Â§çÊ≠£Â∏∏„ÄÇ

    2025-05-08 v2.17.2
        1. ‰ºòÂåñ‰∫Ü Docker ÁéØÂ¢ÉÁöÑÈÄÇÈÖçÔºåÊèêÂçá‰∫ÜÂêéÂè∞ÈÄöËøá Lucky ËøõË°å‰∏ä‰º†ÂçáÁ∫ßÁöÑÊàêÂäüÁéá„ÄÇ
        2. ‰øÆÂ§ç‰∫Ü DDNS ÂäüËÉΩÔºöËß£ÂÜ≥ÈÉ®ÂàÜÊé•Âè£Êú™ËøîÂõû IP ÂØºËá¥ÂçèÁ®ãÂ¥©Ê∫ÉÁöÑÈóÆÈ¢òÔºåÂ¢ûÂº∫‰∫ÜÁ≥ªÁªüÁ®≥ÂÆöÊÄß„ÄÇ
        3. ÂâçÁ´ØÁªÜËäÇ‰ºòÂåñ„ÄÇ
  
    2025-05-06 v2.17.1
      DDNS
      - ‰øÆÂ§ç‰∏ä‰∏™ÁâàÊú¨Â∑≤Áü•ÁöÑÁõ∏ÂÖ≥ bug„ÄÇ
      IPÂú∞ÂùÄÂ∫ì
      - ‰øÆÂ§çÁ∫ØÁúüIPÂ∫ìÂíåZX IPv6‰ΩøÁî®ÈîôËØØÁ±ªÂûãÊñá‰ª∂Êó∂ÔºåÂØºËá¥LuckyÁ®ãÂ∫èÂºÇÂ∏∏ÈÄÄÂá∫ÁöÑÈóÆÈ¢ò„ÄÇ
      WebÊúçÂä°
      - ‰ºòÂåñÂâçÁ´ØÊòæÁ§∫ÊïàÊûú„ÄÇ

    2025-05-04 v2.17.0 
      DDNSÔºö
        ‰øÆÂ§çËá™ÂÆö‰πâ Callback Êü•ËØ¢Êó∂ÁºìÂ≠òÂ§±ÊïàÁöÑÈóÆÈ¢ò„ÄÇ
        Dynv6 ‰∏ªÂüüÂêç A ËÆ∞ÂΩïÊØèÊ¨°ÈÉΩË¢´Âº∫Âà∂ÂêåÊ≠•ÁöÑÈóÆÈ¢ò„ÄÇ
        ‰øÆÂ§ç {ipv4Addr}„ÄÅ{ipv6Addr} ÂèòÈáèÂú®Êüê‰∫õÊÉÖÂÜµ‰∏ãËØÜÂà´ÂºÇÂ∏∏ÔºåÂØºËá¥ÈîôËØØËß¶ÂèëÂºÄÂÖ≥ÁöÑÈóÆÈ¢ò„ÄÇ
        ‰ºòÂåñ httpTimeout ÂèÇÊï∞ËåÉÂõ¥‰∏∫ 10-60 ÁßíÔºå‰øÆÊ≠£Ë∂ÖÊó∂ËøáÂ∞èÂØºËá¥ÁΩëÁªúËØ∑Ê±ÇÂ§±Ë¥•ÁöÑÈóÆÈ¢ò„ÄÇ
        ‰øÆÂ§çËá™ÂÆö‰πâ Callback ÂêåÊó∂ÂêØÁî® IPv4/IPv6 ÂèòÈáèÊó∂Âá∫Áé∞ÁöÑÂºÇÂ∏∏„ÄÇ
        Êñ∞Â¢ûÁΩëÂç°ÊîØÊåÅË¥üÊï∞ÔºåË°®Á§∫‰ªé IP ÂàóË°®Êú´Â∞æÈÄâÊã©„ÄÇ
        DDNS Â∑•‰ΩúÂçèÁ®ã‰ºòÂåñÔºåÂÆûÁé∞Âçï‰ªªÂä°ÂçïÂçèÁ®ã„ÄÇ
        Êñ∞Â¢û‰∏ÄÈîÆÊâãÂä®Ëß¶ÂèëÂêåÊ≠•ÂäüËÉΩ„ÄÇ
        ‰ºòÂåñÊé•Âè£ÂàóË°®ÁöÑË∞ÉÁî®Á≠ñÁï•„ÄÇ
      WebÊúçÂä°Ôºö
        Êñ∞Â¢ûÂÆûÊó∂ÁΩëÈÄüÊòæÁ§∫„ÄÇ
        ‰ºòÂåñ Nginx Ëá™ÂÆö‰πâÊ†ºÂºèÁöÑÂÖºÂÆπÊÄß„ÄÇ
      CorazaÔºö
        ÂÜÖÁΩÆËßÑÂàôÈõÜÊõ¥Êñ∞‰∏∫ OWASP_CRS/4.13.0„ÄÇ
      ÂÖ∂ÂÆÉ‰ºòÂåñ‰∏é‰øÆÂ§çÔºö
        ‰ºòÂåñÂ∫ïÂ±Ç DNS Êü•ËØ¢Êû∂ÊûÑÔºåÊîØÊåÅÂ§ö‰∏™ DNS ÊúçÂä°Âô®Âπ∂ÂèëÊü•ËØ¢„ÄÇ
        Ê∑ªÂä† DDNS ‰ªªÂä°/acmeËØÅ‰π¶Êó∂Êó∂ÔºåËá™Âä®ËØÜÂà´ DNS ÊâòÁÆ°ÂïÜÔºàÁé∞ÊîØÊåÅ Cloudflare„ÄÅDynv6„ÄÅÂçé‰∏∫‰∫ë„ÄÅDNSPod ÂõΩÈôÖÁâàÔºâ‰∏ãË¥¶Âè∑Â∑≤Â≠òÂú®ÁöÑÂ§öÁ∫ßÂüüÂêçÂêéÁºÄÔºåÂπ∂Ëá™Âä®Âä†ÂÖ• DDNS ËÆæÁΩÆ‰∏≠ÁöÑËá™ÂÆö‰πâÂ§öÁ∫ßÂêéÁºÄÂàóË°®„ÄÇ
        3. ‰øÆÂ§çÂÖ∂ÂÆÉÂ∑≤Áü• bug„ÄÇ

    2025-04-08 v2.16.1
        1. ‰øÆÂ§ç 2.16.0ÁâàÊú¨‰∏≠ÔºåÁî≥ËØ∑ËØÅ‰π¶ÊàêÂäüÂêéÊó†Ê≥ï‰øùÂ≠òÁöÑÈóÆÈ¢ò„ÄÇ
        2. ‰øÆÊ≠£‰∫ÜÂú®luckyÂêØÂä®Êó∂ÔºåWebDAVÂíåFileBrowserÊ®°ÂùóÈò≤ÁÅ´Â¢ôÁ´ØÂè£ÊîæË°åÂºÇÂ∏∏ÁöÑÈóÆÈ¢ò„ÄÇ
        3. ÈáçÊñ∞ÊîØÊåÅ Windows 7 Âíå Windows Server 2008 R2 Á≥ªÁªü„ÄÇÔºàÊ≤°ÊµãËØïÔºâ

    2025-04-08 v2.16.0
      ÂêéÂè∞ËÆæÁΩÆÔºö
        - Êñ∞Â¢ûÔºöÂ¢ûÂä†Âº∫Âà∂HTTPSËÆøÈóÆÁöÑÂºÄÂÖ≥ÔºåHTTPËØ∑Ê±ÇÂ∞ÜËá™Âä®ÈáçÂÆöÂêëÂà∞HTTPS„ÄÇ
      WebÊúçÂä°Ôºö
        - Êñ∞Â¢ûÔºöÊñáÊú¨ËæìÂá∫ÂäüËÉΩÊîØÊåÅÁ¶ÅÁî®ÈïøËøûÊé•„ÄÇ
        - ‰øÆÂ§çÔºöÊñá‰ª∂ÊúçÂä°ÁöÑË∑®ÂüüÂºÄÂÖ≥ÊîØÊåÅÈóÆÈ¢ò„ÄÇ
      ACMEÔºàËØÅ‰π¶ÁÆ°ÁêÜÔºâÔºö
        - Êñ∞Â¢ûÔºöÊîØÊåÅÂêåÊó∂Áî≥ËØ∑Â§ö‰∏™ACMEËØÅ‰π¶„ÄÇ
        - Êñ∞Â¢ûÔºöÊîØÊåÅÊâãÂä®‰∏≠Ê≠¢ËØÅ‰π¶Áî≥ËØ∑„ÄÇ
        - ‰ºòÂåñÔºöÈÄÇÈÖçÊîπÂñÑfreemyipÂüüÂêçËØÅ‰π¶Áî≥ËØ∑Ôºå‰∏ªÂüüÂêçÂíåÊ≥õÂüüÂêçÊó†ÈúÄÂàÜÂºÄËÆ∞ÂΩïÁî≥ËØ∑„ÄÇ
      ÂÖ∂‰ªñÔºö
        - Ë∞ÉÊï¥ÔºöÊîæÂÆΩÂêéÂè∞APIËØ∑Ê±ÇÈ¢ëÁéáÈôêÂà∂ÔºåÈôç‰Ωé‚Äútoo many request‚ÄùÈîôËØØÊèêÁ§∫ÁöÑÂá∫Áé∞Ê¶ÇÁéá„ÄÇ

    2025-03-31 v2.15.9 Êõ¥Êñ∞Êó•Âøó
      DDNSÔºö
        Êñ∞Â¢ûÔºöÂÖ®Èù¢ÊîØÊåÅspaceshipÁöÑ10ÁßçËÆ∞ÂΩïÁ±ªÂûãÔºàÂåÖÊã¨AËÆ∞ÂΩï„ÄÅAAAAËÆ∞ÂΩïÁ≠âÔºâ
        Êñ∞Â¢ûÔºöËá™Âä®ËØÜÂà´Â∏∏ËßÅ‰∫åÁ∫ßÂüüÂêçÂêéÁºÄÔºàÂ¶Ç.ip-ddns.com„ÄÅ.ggff.netÁ≠âÔºâ
        ‰øÆÂ§çÔºöÂ∑≤ÊàêÂäüËé∑ÂèñIPÂú∞ÂùÄÊó∂‰ªçÊòæÁ§∫ÈîôËØØÊèêÁ§∫ÁöÑÈóÆÈ¢ò
        ‰øÆÂ§çÔºöÂüüÂêçÂåÖÂê´Â§ßÂÜôÂ≠óÊØçÂØºËá¥ÈáçÂ§çÁîüÊàêËÆ∞ÂΩïÁöÑÈóÆÈ¢ò
        ‰øÆÂ§çÔºö‰ªé v2.15 ‰πãÂâçÁâàÊú¨ÂçáÁ∫ßÊó∂Ôºå‰∫åÁ∫ßÂüüÂêçËØÜÂà´ÂºÇÂ∏∏ÁöÑÈóÆÈ¢ò
        
      ACMEÔºö
        Êñ∞Â¢ûÔºöÊîØÊåÅspaceshipËØÅ‰π¶ÊúçÂä°
        Êñ∞Â¢ûÔºö ÂèØËá™Áî±ËÆæÁΩÆ ÊØèÊó•ËØÅ‰π¶Ê£ÄÊü•Êó∂Èó¥ Ôºå ËØÅ‰π¶Âà∞ÊúüÂâçÂ§öÂ∞ëÂ§©Ëá™Âä®Áª≠Êúü
        ‰ºòÂåñÔºöZeroSSLËØÅ‰π¶Áî≥ËØ∑Áé∞Âú®ÂÆåÂÖ®Ëá™Âä®Ëé∑ÂèñEABÈ™åËØÅ‰ø°ÊÅØÔºàÊó†ÈúÄÊâãÂä®Â°´ÂÜôÔºâ‚Äª Ê≥®ÊÑèÔºöÂ¶ÇÈúÄÂú®ZeroSSLÂÆòÁΩëÊü•ÁúãËØÅ‰π¶ÔºåËØ∑Á°Æ‰øùÊ≥®ÂÜåÈÇÆÁÆ±Â°´ÂÜôÊ≠£Á°Æ

      IPÂú∞ÂùÄÂ∫ìÔºö
        Êñ∞Â¢ûÔºöipipÊ†ºÂºèÊï∞ÊçÆÂ∫ìÁé∞Â∑≤ÊîØÊåÅIPv6Âú∞ÂùÄÊü•ËØ¢
        ‰øÆÂ§çÔºö‰∏™Âà´ÊÉÖÂÜµ‰∏ãÊüê‰∏™Êï∞ÊçÆÂ∫ìËøîÂõûÁ©∫Â≠óÁ¨¶‰∏≤Êó∂ÔºåÁé∞Âú®‰ºöËá™Âä®Â∞ùËØïÊü•ËØ¢‰∏ã‰∏Ä‰∏™ÂèØÁî®Êï∞ÊçÆÂ∫ì

   [Êõ¥Â§öÊó•ÂøóËØ∑Êü•Áúã](https://lucky666.cn/docs/category/%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97)

















„ÄÇ



</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[openbao/openbao]]></title>
            <link>https://github.com/openbao/openbao</link>
            <guid>https://github.com/openbao/openbao</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[OpenBao exists to provide a software solution to manage, store, and distribute sensitive data including secrets, certificates, and keys.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openbao/openbao">openbao/openbao</a></h1>
            <p>OpenBao exists to provide a software solution to manage, store, and distribute sensitive data including secrets, certificates, and keys.</p>
            <p>Language: Go</p>
            <p>Stars: 4,389</p>
            <p>Forks: 247</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># OpenBao

----

**Please note**: We take OpenBao&#039;s security and our users&#039; trust very seriously. If you believe you have found a security issue in OpenBao, _please responsibly disclose_ by contacting us at [openbao-security@lists.openssf.org](mailto:openbao-security@lists.openssf.org).

----

- [Website](https://www.openbao.org)
- [Mailing List](https://lists.openssf.org/g/openbao)
- [GitHub Discussions](https://github.com/openbao/openbao/discussions)
- [Chat Server](https://chat.lfx.linuxfoundation.org/)
  - `#openbao-announcements` ([matrix client](https://matrix.to/#/#openbao-announcements:chat.lfx.linuxfoundation.org), [home server](https://chat.lfx.linuxfoundation.org/#/room/#openbao-announcements:chat.lfx.linuxfoundation.org))
  - `#openbao-development` ([matrix client](https://matrix.to/#/#openbao-development:chat.lfx.linuxfoundation.org), [home server](https://chat.lfx.linuxfoundation.org/#/room/#openbao-development:chat.lfx.linuxfoundation.org))
  - `#openbao-general` ([matrix client](https://matrix.to/#/#openbao-general:chat.lfx.linuxfoundation.org), [home server](https://chat.lfx.linuxfoundation.org/#/room/#openbao-general:chat.lfx.linuxfoundation.org))
  - `#openbao-questions` ([matrix client](https://matrix.to/#/#openbao-questions:chat.lfx.linuxfoundation.org), [home server](https://chat.lfx.linuxfoundation.org/#/room/#openbao-questions:chat.lfx.linuxfoundation.org))
  - `#openbao-random` ([matrix client](https://matrix.to/#/#openbao-random:chat.lfx.linuxfoundation.org), [home server](https://chat.lfx.linuxfoundation.org/#/room/#openbao-random:chat.lfx.linuxfoundation.org))

&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;300&quot; alt=&quot;OpenBao Mascot&quot; src=&quot;https://raw.githubusercontent.com/openbao/artwork/main/color/openbao-color.svg&quot;&gt;
&lt;/p&gt;

**OpenBao exists to provide a software solution to manage, store, and distribute sensitive data including secrets, certificates, and keys. The OpenBao community intends to provide this software under an OSI-approved open-source license, led by a community run under open governance principles.**

A modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where OpenBao steps in.

The key features of OpenBao are:

* **Secure Secret Storage**: Arbitrary key/value secrets can be stored
  in OpenBao. OpenBao encrypts these secrets prior to writing them to persistent
  storage, so gaining access to the raw storage isn&#039;t enough to access
  your secrets. OpenBao can write to disk, [PostgreSQL](https://www.postgresql.org/),
  and more.

* **Dynamic Secrets**: OpenBao can generate secrets on-demand for some
  systems, such as AWS or SQL databases. For example, when an application
  needs to access an S3 bucket, it asks OpenBao for credentials, and OpenBao
  will generate an AWS keypair with valid permissions on demand. After
  creating these dynamic secrets, OpenBao will also automatically revoke them
  after the lease is up.

* **Data Encryption**: OpenBao can encrypt and decrypt data without storing
  it. This allows security teams to define encryption parameters and
  developers to store encrypted data in a location such as a SQL database without
  having to design their own encryption methods.

* **Leasing and Renewal**: All secrets in OpenBao have a _lease_ associated
  with them. At the end of the lease, OpenBao will automatically revoke that
  secret. Clients are able to renew leases via built-in renew APIs.

* **Revocation**: OpenBao has built-in support for secret revocation. OpenBao
  can revoke not only single secrets, but a tree of secrets, for example,
  all secrets read by a specific user, or all secrets of a particular type.
  Revocation assists in key rolling as well as locking down systems in the
  case of an intrusion.

Documentation, Getting Started, and Certification Exams
-------------------------------

Documentation is available on the [OpenBao website](https://www.openbao.org/docs/).

Developing OpenBao
--------------------

If you wish to work on OpenBao itself or any of its built-in systems, you&#039;ll
first need [Go](https://www.golang.org) installed on your machine.

For local dev first make sure Go is properly installed, including setting up a
[GOPATH](https://golang.org/doc/code.html#GOPATH). Ensure that `$GOPATH/bin` is in
your path as some distributions bundle the old version of build tools. Next, clone this
repository. OpenBao uses [Go Modules](https://github.com/golang/go/wiki/Modules),
so it is recommended that you clone the repository ***outside*** of the GOPATH.
You can then download any required build tools by bootstrapping your environment:

```sh
$ make bootstrap
...
```

To compile a development version of OpenBao, run `make` or `make dev`. This will
put the OpenBao binary in the `bin` and `$GOPATH/bin` folders:

```sh
$ make dev
...
$ bin/bao
...
```

To compile a development version of OpenBao with the UI, run `make static-dist dev-ui`. This will
put the OpenBao binary in the `bin` and `$GOPATH/bin` folders:

```sh
$ make static-dist dev-ui
...
$ bin/bao
...
```

To run tests, type `make test`. Note: this requires Docker to be installed. If
this exits with exit status 0, then everything is working!

```sh
$ make test
...
```

If you&#039;re developing a specific package, you can run tests for just that
package by specifying the `TEST` variable. For example below, only
`vault` package tests will be run.

```sh
$ make test TEST=./vault
...
```

### Importing OpenBao

This repository publishes two libraries that may be imported by other projects:
`github.com/openbao/openbao/api/v2` and `github.com/openbao/openbao/sdk/v2`.

Note that this repository also contains OpenBao (the product), and as with most Go
projects, OpenBao uses Go modules to manage its dependencies. The mechanism to do
that is the [go.mod](./go.mod) file. As it happens, the presence of that file
also makes it theoretically possible to import OpenBao as a dependency into other
projects. Some other projects have made a practice of doing so in order to take
advantage of testing tooling that was developed for testing OpenBao itself. This
is not, and has never been, a supported way to use the OpenBao project. We aren&#039;t
likely to fix bugs relating to failure to import `github.com/openbao/openbao`
into your project.

See also the section &quot;Docker-based tests&quot; below.

### Acceptance Tests

OpenBao has comprehensive [acceptance tests](https://en.wikipedia.org/wiki/Acceptance_testing)
covering most of the features of the secret and auth methods.

If you&#039;re working on a feature of a secret or auth method and want to
verify it is functioning (and also hasn&#039;t broken anything else), we recommend
running the acceptance tests.

**Warning:** The acceptance tests create/destroy/modify *real resources*, which
may incur real costs in some cases. In the presence of a bug, it is technically
possible that broken backends could leave dangling data behind. Therefore,
please run the acceptance tests at your own risk. At the very least,
we recommend running them in their own private account for whatever backend
you&#039;re testing.

To run the acceptance tests, invoke `make testacc`:

```sh
$ make testacc TEST=./builtin/logical/pki
...
```

The `TEST` variable is required, and you should specify the folder where the
backend is. The `TESTARGS` variable is recommended to filter down to a specific
resource to test, since testing all of them at once can sometimes take a very
long time.

Acceptance tests typically require other environment variables to be set for
things such as access keys. The test itself should error early and tell
you what to set, so it is not documented here.

### Docker-based Tests

We have created an experimental new testing mechanism inspired by NewTestCluster.
An example of how to use it:

```go
import (
  &quot;testing&quot;
  &quot;github.com/openbao/openbao/sdk/v2/helper/testcluster/docker&quot;
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;docker.DockerClusterOptions{
    ImageRepo: &quot;openbao/openbao&quot;,
    ImageTag:    &quot;latest&quot;,
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()

  client := cluster.Nodes()[0].APIClient()
  _, err := client.Logical().Read(&quot;sys/storage/raft/configuration&quot;)
  if err != nil {
    t.Fatal(err)
  }
}
```

Here is a more realistic example of how we use it in practice.  `DefaultOptions` uses
`hashicorp/vault:latest` as the repo and tag, but it also looks at the environment
variable `BAO_BINARY`. If populated, it will copy the local file referenced by
`BAO_BINARY` into the container. This is useful when testing local changes.

Optionally you can set `COMMIT_SHA`, which will be appended to the image name we
build as a debugging convenience.

```go
func Test_Custom_Build_With_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
```

Finally, here&#039;s an example of running an existing OSS docker test with a custom binary:

```bash
$ GOOS=linux make dev
$ VAULT_BINARY=$(pwd)/bin/bao go test -run &#039;TestRaft_Configuration_Docker&#039; ./vault/external_tests/raft/raft_binary
ok      github.com/openbao/openbao/vault/external_tests/raft/raft_binary        20.960s
```
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grafana/mimir]]></title>
            <link>https://github.com/grafana/mimir</link>
            <guid>https://github.com/grafana/mimir</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[Grafana Mimir provides horizontally scalable, highly available, multi-tenant, long-term storage for Prometheus.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grafana/mimir">grafana/mimir</a></h1>
            <p>Grafana Mimir provides horizontally scalable, highly available, multi-tenant, long-term storage for Prometheus.</p>
            <p>Language: Go</p>
            <p>Stars: 4,637</p>
            <p>Forks: 634</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># Grafana Mimir

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;images/logo.png&quot; alt=&quot;Grafana Mimir logo&quot; width=&quot;400&quot;&gt;&lt;/p&gt;

Grafana Mimir is an open source software project that provides a scalable long-term storage for [Prometheus](https://prometheus.io). Some of the core strengths of Grafana Mimir include:

- **Easy to install and maintain:** Grafana Mimir‚Äôs extensive documentation, tutorials, and deployment tooling make it quick to get started. Using its monolithic mode, you can get Grafana Mimir up and running with just one binary and no additional dependencies. Once deployed, the best-practice dashboards, alerts, and runbooks packaged with Grafana Mimir make it easy to monitor the health of the system.
- **Massive scalability:** You can run Grafana Mimir&#039;s horizontally-scalable architecture across multiple machines, resulting in the ability to process orders of magnitude more time series than a single Prometheus instance. Internal testing shows that Grafana Mimir handles up to 1 billion active time series.
- **Global view of metrics:** Grafana Mimir enables you to run queries that aggregate series from multiple Prometheus instances, giving you a global view of your systems. Its query engine extensively parallelizes query execution, so that even the highest-cardinality queries complete with blazing speed.
- **Cheap, durable metric storage:** Grafana Mimir uses object storage for long-term data storage, allowing it to take advantage of this ubiquitous, cost-effective, high-durability technology. It is compatible with multiple object store implementations, including AWS S3, Google Cloud Storage, Azure Blob Storage, OpenStack Swift, as well as any S3-compatible object storage.
- **High availability:** Grafana Mimir replicates incoming metrics, ensuring that no data is lost in the event of machine failure. Its horizontally scalable architecture also means that it can be restarted, upgraded, or downgraded with zero downtime, which means no interruptions to metrics ingestion or querying.
- **Natively multi-tenant:** Grafana Mimir‚Äôs multi-tenant architecture enables you to isolate data and queries from independent teams or business units, making it possible for these groups to share the same cluster. Advanced limits and quality-of-service controls ensure that capacity is shared fairly among tenants.

## Migrating to Grafana Mimir

If you&#039;re migrating to Grafana Mimir, refer to the following documents:

- [Migrating from Thanos or Prometheus to Grafana Mimir](https://grafana.com/docs/mimir/latest/set-up/migrate/migrate-from-thanos-or-prometheus/).
- [Migrating from Cortex to Grafana Mimir](https://grafana.com/docs/mimir/latest/set-up/migrate/migrate-from-cortex/)

## Deploying Grafana Mimir

For information about how to deploy Grafana Mimir, refer to [Deploy Grafana Mimir](https://grafana.com/docs/mimir/latest/operators-guide/deploy-grafana-mimir/).

## Getting started

If you‚Äôre new to Grafana Mimir, read the [Get started guide](https://grafana.com/docs/mimir/latest/get-started/).

Before deploying Grafana Mimir in a production environment, read:

1. [An overview of Grafana Mimir‚Äôs architecture](https://grafana.com/docs/mimir/latest/operators-guide/architecture/)
1. [Configure Grafana Mimir](https://grafana.com/docs/mimir/latest/operators-guide/configure/)
1. [Run Grafana Mimir in production](https://grafana.com/docs/mimir/latest/operators-guide/run-production-environment/)

## Documentation

Refer to the following links to access Grafana Mimir documentation:

- [Latest release](https://grafana.com/docs/mimir/latest/)
- [Upcoming release](https://grafana.com/docs/mimir/next/), at the tip of the `main` branch

## Contributing

To contribute to Grafana Mimir, refer to [Contributing to Grafana Mimir](https://github.com/grafana/mimir/tree/main/docs/internal/contributing).

## Join the Grafana Mimir discussion

If you have any questions or feedback regarding Grafana Mimir, join the [Grafana Mimir Discussion](https://github.com/grafana/mimir/discussions). Alternatively, consider joining the monthly [Grafana Mimir Community Call](https://docs.google.com/document/d/1E4jJcGicvLTyMEY6cUFFZUg_I8ytrBuW8r5yt1LyMv4).

Your feedback is always welcome, and you can also share it via the [`#mimir` Slack channel](https://slack.grafana.com/).

## License

Grafana Mimir is distributed under [AGPL-3.0-only](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[goharbor/harbor]]></title>
            <link>https://github.com/goharbor/harbor</link>
            <guid>https://github.com/goharbor/harbor</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[An open source trusted cloud native registry project that stores, signs, and scans content.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/goharbor/harbor">goharbor/harbor</a></h1>
            <p>An open source trusted cloud native registry project that stores, signs, and scans content.</p>
            <p>Language: Go</p>
            <p>Stars: 26,267</p>
            <p>Forks: 4,942</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre># Harbor

[![CI](https://github.com/goharbor/harbor/workflows/CI/badge.svg?branch=main&amp;event=push)](https://github.com/goharbor/harbor/actions?query=event%3Apush+branch%3Amain+workflow%3ACI+)
[![Coverage Status](https://codecov.io/gh/goharbor/harbor/branch/main/graph/badge.svg)](https://codecov.io/gh/goharbor/harbor)
[![Go Report Card](https://goreportcard.com/badge/github.com/goharbor/harbor)](https://goreportcard.com/report/github.com/goharbor/harbor)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/2095/badge)](https://bestpractices.coreinfrastructure.org/projects/2095)
[![Codacy Badge](https://app.codacy.com/project/badge/Grade/792fe1755edc4d6e91f4c3469f553389)](https://www.codacy.com/gh/goharbor/harbor/dashboard?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=goharbor/harbor&amp;amp;utm_campaign=Badge_Grade)
![Code scanning - action](https://github.com/goharbor/harbor/workflows/Code%20scanning%20-%20action/badge.svg)
[![Nightly Status](https://us-central1-eminent-nation-87317.cloudfunctions.net/harbor-nightly-result)](https://www.googleapis.com/storage/v1/b/harbor-nightly/o)
![CONFORMANCE_TEST](https://github.com/goharbor/harbor/workflows/CONFORMANCE_TEST/badge.svg)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fgoharbor%2Fharbor.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fgoharbor%2Fharbor?ref=badge_shield)
[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/harbor)](https://artifacthub.io/packages/helm/harbor/harbor)
&lt;/br&gt;

|![notification](https://raw.githubusercontent.com/goharbor/website/master/docs/img/readme/bell-outline-badged.svg)Community Meeting|
|------------------|
|The Harbor Project holds bi-weekly community calls in two different timezones. To join the community calls or to watch previous meeting notes and recordings, please visit the [meeting schedule](https://github.com/goharbor/community/blob/master/MEETING_SCHEDULE.md).|

&lt;/br&gt; &lt;/br&gt;

**Note**: The `main` branch may be in an *unstable or even broken state* during development.
Please use [releases](https://github.com/goharbor/harbor/releases) instead of the `main` branch in order to get a stable set of binaries.

&lt;img alt=&quot;Harbor&quot; src=&quot;https://raw.githubusercontent.com/goharbor/website/master/docs/img/readme/harbor_logo.png&quot;&gt;

Harbor is an open source trusted cloud native registry project that stores, signs, and scans content. Harbor extends the open source Docker Distribution by adding the functionalities usually required by users such as security, identity and management. Having a registry closer to the build and run environment can improve the image transfer efficiency. Harbor supports replication of images between registries, and also offers advanced security features such as user management, access control and activity auditing.

Harbor is hosted by the [Cloud Native Computing Foundation](https://cncf.io) (CNCF). If you are an organization that wants to help shape the evolution of cloud native technologies, consider joining the CNCF. For details about whose involved and how Harbor plays a role, read the CNCF
[announcement](https://www.cncf.io/blog/2018/07/31/cncf-to-host-harbor-in-the-sandbox/).

## Features

* **Cloud native registry**: With support for both container images and [Helm](https://helm.sh) charts, Harbor serves as registry for cloud native environments like container runtimes and orchestration platforms.
* **Role based access control**: Users access different repositories through &#039;projects&#039; and a user can have different permission for images or Helm charts under a project.
* **Policy based replication**: Images and charts can be replicated (synchronized) between multiple registry instances based on policies with using filters (repository, tag and label). Harbor automatically retries a replication if it encounters any errors. This can be used to assist loadbalancing, achieve high availability, and facilitate multi-datacenter deployments in hybrid and multi-cloud scenarios.
* **Vulnerability Scanning**: Harbor scans images regularly for vulnerabilities and has policy checks to prevent vulnerable images from being deployed.
* **LDAP/AD support**: Harbor integrates with existing enterprise LDAP/AD for user authentication and management, and supports importing LDAP groups into Harbor that can then be given permissions to specific projects.
* **OIDC support**: Harbor leverages OpenID Connect (OIDC) to verify the identity of users authenticated by an external authorization server or identity provider. Single sign-on can be enabled to log into the Harbor portal.
* **Image deletion &amp; garbage collection**: System admin can run garbage collection jobs so that images(dangling manifests and unreferenced blobs) can be deleted and their space can be freed up periodically.
* **Notary**: Support signing container images using Docker Content Trust (leveraging Notary) for guaranteeing authenticity and provenance.  In addition, policies that prevent unsigned images from being deployed can also be activated.
* **Graphical user portal**: User can easily browse, search repositories and manage projects.
* **Auditing**: All the operations to the repositories are tracked through logs.
* **RESTful API**: RESTful APIs are provided to facilitate administrative operations, and are easy to use for integration with external systems. An embedded Swagger UI is available for exploring and testing the API.
* **Easy deployment**: Harbor can be deployed via Docker compose as well Helm Chart, and a Harbor Operator was added recently as well.

## Architecture

For learning the architecture design of Harbor, check the document [Architecture Overview of Harbor](https://github.com/goharbor/harbor/wiki/Architecture-Overview-of-Harbor).

## API

* Harbor RESTful API: The APIs for most administrative operations of Harbor and can be used to perform integrations with Harbor programmatically.
  * Part 1: [New or changed APIs](https://editor.swagger.io/?url=https://raw.githubusercontent.com/goharbor/harbor/main/api/v2.0/swagger.yaml)

## Install &amp; Run

**System requirements:**

**On a Linux host:** docker 20.10.10-ce+ and docker-compose 1.18.0+ .

Download binaries of **[Harbor release ](https://github.com/goharbor/harbor/releases)** and follow **[Installation &amp; Configuration Guide](https://goharbor.io/docs/latest/install-config/)** to install Harbor.

If you want to deploy Harbor on Kubernetes, please use the **[Harbor chart](https://github.com/goharbor/harbor-helm)**.

Refer to the **[documentation](https://goharbor.io/docs/)** for more details on how to use Harbor.

## OCI Distribution Conformance Tests

Check the OCI distribution conformance tests [report](https://storage.googleapis.com/harbor-conformance-test/report.html) of Harbor.

## Compatibility

The [compatibility list](https://goharbor.io/docs/edge/install-config/harbor-compatibility-list/) document provides compatibility information for the Harbor components.

* [Replication adapters](https://goharbor.io/docs/edge/install-config/harbor-compatibility-list/#replication-adapters)
* [OIDC adapters](https://goharbor.io/docs/edge/install-config/harbor-compatibility-list/#oidc-adapters)
* [Scanner adapters](https://goharbor.io/docs/edge/install-config/harbor-compatibility-list/#scanner-adapters)

## Community

* **Twitter:** [@project_harbor](https://twitter.com/project_harbor)
* **User Group:** Join Harbor user email group: [harbor-users@lists.cncf.io](https://lists.cncf.io/g/harbor-users) to get update of Harbor&#039;s news, features, releases, or to provide suggestion and feedback.
* **Developer Group:** Join Harbor developer group: [harbor-dev@lists.cncf.io](https://lists.cncf.io/g/harbor-dev) for discussion on Harbor development and contribution.
* **Slack:** Join Harbor&#039;s community for discussion and ask questions: [Cloud Native Computing Foundation](https://slack.cncf.io/), channel: [#harbor](https://cloud-native.slack.com/messages/harbor/) and [#harbor-dev](https://cloud-native.slack.com/messages/harbor-dev/)

## Demos

* **[Live Demo](https://demo.goharbor.io)** - A demo environment with the latest Harbor stable build installed. For additional information please refer to [this page](https://goharbor.io/docs/latest/install-config/demo-server/).
* **[Video Demos](https://github.com/goharbor/harbor/wiki/Video-demos-for-Harbor)** - Demos for Harbor features and continuously updated.

## Partners and Users

For a list of users, please refer to [ADOPTERS.md](ADOPTERS.md).

## Security

### Security Audit

A third party security audit was performed by Cure53 in October 2019. You can see the full report [here](https://goharbor.io/docs/2.0.0/security/Harbor_Security_Audit_Oct2019.pdf).

### Reporting security vulnerabilities

If you&#039;ve found a security related issue, a vulnerability, or a potential vulnerability in Harbor please let the [Harbor Security Team](mailto:cncf-harbor-security@lists.cncf.io) know with the details of the vulnerability. We&#039;ll send a confirmation
email to acknowledge your report, and we&#039;ll send an additional email when we&#039;ve identified the issue
positively or negatively.

For further details please see our complete [security release process](SECURITY.md).

## License

Harbor is available under the [Apache 2 license](LICENSE).

This project uses open source components which have additional licensing terms.  The official docker images and licensing terms for these open source components can be found at the following locations:

* Photon OS 1.0: [docker image](https://hub.docker.com/_/photon/), [license](https://github.com/vmware/photon/blob/master/COPYING)


## Fossa Status

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fgoharbor%2Fharbor.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Fgoharbor%2Fharbor?ref=badge_large)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[karmada-io/karmada]]></title>
            <link>https://github.com/karmada-io/karmada</link>
            <guid>https://github.com/karmada-io/karmada</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[Open, Multi-Cloud, Multi-Cluster Kubernetes Orchestration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/karmada-io/karmada">karmada-io/karmada</a></h1>
            <p>Open, Multi-Cloud, Multi-Cluster Kubernetes Orchestration</p>
            <p>Language: Go</p>
            <p>Stars: 5,007</p>
            <p>Forks: 993</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># Karmada

![Karmada-logo](docs/images/Karmada-logo-horizontal-color.png)


[![LICENSE](https://img.shields.io/github/license/karmada-io/karmada.svg)](/LICENSE)
[![Releases](https://img.shields.io/github/v/release/karmada-io/karmada)](https://github.com/karmada-io/karmada/releases/latest)
[![Slack](https://img.shields.io/badge/slack-join-brightgreen)](https://slack.cncf.io)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5301/badge)](https://bestpractices.coreinfrastructure.org/projects/5301)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/karmada-io/karmada/badge)](https://securityscorecards.dev/viewer/?uri=github.com/karmada-io/karmada)
![build](https://github.com/karmada-io/karmada/actions/workflows/ci.yml/badge.svg)
[![Go Report Card](https://goreportcard.com/badge/github.com/karmada-io/karmada)](https://goreportcard.com/report/github.com/karmada-io/karmada)
[![codecov](https://codecov.io/gh/karmada-io/karmada/branch/master/graph/badge.svg?token=ROM8CMPXZ6)](https://codecov.io/gh/karmada-io/karmada)
[![FOSSA Status](https://app.fossa.com/api/projects/custom%2B28176%2Fgithub.com%2Fkarmada-io%2Fkarmada.svg?type=shield)](https://app.fossa.com/projects/custom%2B28176%2Fgithub.com%2Fkarmada-io%2Fkarmada?ref=badge_shield)
[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/karmada)](https://artifacthub.io/packages/krew/krew-index/karmada)
[![CLOMonitor](https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/karmada/badge)](https://clomonitor.io/projects/cncf/karmada)

## Karmada: Open, Multi-Cloud, Multi-Cluster Kubernetes Orchestration

Karmada (Kubernetes Armada) is a Kubernetes management system that enables you to run your cloud-native applications across multiple Kubernetes clusters and clouds, with no changes to your applications. By speaking Kubernetes-native APIs and providing advanced scheduling capabilities, Karmada enables truly open, multi-cloud Kubernetes.

Karmada aims to provide turnkey automation for multi-cluster application management in multi-cloud and hybrid cloud scenarios,
with key features such as centralized multi-cloud management, high availability, failure recovery, and traffic scheduling.

![cncf_logo](docs/images/cncf-logo.png)

Karmada is an incubation project of the [Cloud Native Computing Foundation](https://cncf.io/) (CNCF).

## Why Karmada:
- __K8s Native API Compatible__
    - Zero change upgrade, from single-cluster to multi-cluster
    - Seamless integration of existing K8s tool chain

- __Out of the Box__
    - Built-in policy sets for scenarios, including: Active-active, Remote DR, Geo Redundant, etc.
    - Cross-cluster applications auto-scaling, failover and load-balancing on multi-cluster.

- __Avoid Vendor Lock-in__
    - Integration with mainstream cloud providers
    - Automatic allocation, migration across clusters
    - Not tied to proprietary vendor orchestration

- __Centralized Management__
    - Location agnostic cluster management
    - Support clusters in Public cloud, on-prem or edge

- __Fruitful Multi-Cluster Scheduling Policies__
    - Cluster Affinity, Multi Cluster Splitting/Rebalancing
    - Multi-Dimension HA: Region/AZ/Cluster/Provider

- __Open and Neutral__
    - Jointly initiated by Internet, finance, manufacturing, teleco, cloud providers, etc.
    - Target for open governance with CNCF



**Notice: this project is developed in continuation of Kubernetes [Federation v1](https://github.com/kubernetes-retired/federation) and [v2](https://github.com/kubernetes-sigs/kubefed). Some basic concepts are inherited from these two versions.**


## Architecture

![Architecture](docs/images/architecture.png)

The Karmada Control Plane consists of the following components:

- Karmada API Server
- Karmada Controller Manager
- Karmada Scheduler

ETCD stores the Karmada API objects, the API Server is the REST endpoint all other components talk to, and the Karmada Controller Manager performs operations based on the API objects you create through the API server.

The Karmada Controller Manager runs the various controllers,  the controllers watch Karmada objects and then talk to the underlying clusters&#039; API servers to create regular Kubernetes resources.

1. Cluster Controller: attach Kubernetes clusters to Karmada for managing the lifecycle of the clusters by creating cluster objects.
2. Policy Controller: the controller watches PropagationPolicy objects. When the PropagationPolicy object is added, it selects a group of resources matching the resourceSelector and creates ResourceBinding with each single resource object.
3. Binding Controller: the controller watches ResourceBinding object and create Work object corresponding to each cluster with a single resource manifest.
4. Execution Controller: the controller watches Work objects. When Work objects are created, it will distribute the resources to member clusters.


## Concepts

**Resource template**: Karmada uses Kubernetes Native API definition for federated resource template, to make it easy to integrate with existing tools that already adopt on Kubernetes

**Propagation Policy**: Karmada offers a standalone Propagation(placement) Policy API to define multi-cluster scheduling and spreading requirements.
- Support 1:n mapping of Policy: workload, users don&#039;t need to indicate scheduling constraints every time creating federated applications.
- With default policies, users can just interact with K8s API

**Override Policy**: Karmada provides standalone Override Policy API for specializing cluster relevant configuration automation. E.g.:
- Override image prefix according to member cluster region
- Override StorageClass according to cloud provider


The following diagram shows how Karmada resources are involved when propagating resources to member clusters.

![karmada-resource-relation](docs/images/karmada-resource-relation.png)

## Quick Start

This guide will cover:
- Install `karmada` control plane components in a Kubernetes cluster which is known as `host cluster`.
- Join a member cluster to `karmada` control plane.
- Propagate an application by using `karmada`.

### Prerequisites
- [Go](https://golang.org/) version follows [go.mod](https://github.com/karmada-io/karmada/blob/master/go.mod#L3)
- [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) version v1.19+
- [kind](https://kind.sigs.k8s.io/) version v0.14.0+

### Install the Karmada control plane

#### 1. Clone this repo to your machine:

```bash
git clone https://github.com/karmada-io/karmada
```

#### 2. Change to the karmada directory:

```bash
cd karmada
```

#### 3. Deploy and run Karmada control plane:

run the following script:

```bash
hack/local-up-karmada.sh
```
This script will do the following tasks for you:
- Start a Kubernetes cluster to run the Karmada control plane, aka. the `host cluster`.
- Build Karmada control plane components based on a current codebase.
- Deploy Karmada control plane components on the `host cluster`.
- Create member clusters and join Karmada.

If everything goes well, at the end of the script output, you will see similar messages as follows:

```bash
Local Karmada is running.

To start using your Karmada environment, run:
  export KUBECONFIG=&quot;$HOME/.kube/karmada.config&quot;
Please use &#039;kubectl config use-context karmada-host/karmada-apiserver&#039; to switch the host and control plane cluster.

To manage your member clusters, run:
  export KUBECONFIG=&quot;$HOME/.kube/members.config&quot;
Please use &#039;kubectl config use-context member1/member2/member3&#039; to switch to the different member cluster.
```

There are two contexts in Karmada:
- karmada-apiserver `kubectl config use-context karmada-apiserver`
- karmada-host `kubectl config use-context karmada-host`

The `karmada-apiserver` is the **main kubeconfig** to be used when interacting with the Karmada control plane, while `karmada-host` is only used for debugging Karmada installation with the host cluster. You can check all clusters at any time by running: `kubectl config view`. To switch cluster contexts, run `kubectl config use-context [CONTEXT_NAME]`


### Demo

![Demo](docs/images/sample-nginx.svg)

### Propagate application
In the following steps, we are going to propagate a deployment by Karmada.

#### 1. Create nginx deployment in Karmada.
First, create a [deployment](samples/nginx/deployment.yaml) named `nginx`:

```bash
kubectl create -f samples/nginx/deployment.yaml
```

#### 2. Create PropagationPolicy that will propagate nginx to member cluster
Then, we need to create a policy to propagate the deployment to our member cluster.

```bash
kubectl create -f samples/nginx/propagationpolicy.yaml
```

#### 3. Check the deployment status from Karmada
You can check deployment status from Karmada, don&#039;t need to access member cluster:

```bash
$ kubectl get deployment
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   2/2     2            2           20s
```

## Kubernetes compatibility

Karmada is compatible with a wide range of Kubernetes versions. For detailed compatibility instructions, 
please refer to the [Kubernetes Compatibility](https://karmada.io/docs/administrator/compatibility/). 

The following table shows the compatibility test results against the latest 10 Kubernetes versions:

|                       | Kubernetes 1.33 | Kubernetes 1.32 | Kubernetes 1.31 | Kubernetes 1.30 | Kubernetes 1.29 | Kubernetes 1.28 | Kubernetes 1.27 | Kubernetes 1.26 | Kubernetes 1.25 | Kubernetes 1.24 | Kubernetes 1.23 |
|-----------------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|
| Karmada v1.12         |                 |                 | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               |
| Karmada v1.13         |                 |                 | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               |
| Karmada v1.14         |                 | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               |
| Karmada HEAD (master) |                 | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               | ‚úì               |

Key:
* `‚úì` Karmada and the Kubernetes version are exactly compatible.
* `+` Karmada has features or API objects that may not be present in the Kubernetes version.
* `-` The Kubernetes version has features or API objects that Karmada can&#039;t use.

## Meeting

Regular Community Meeting:
* Tuesday at 14:30 UTC+8 (Chinese)(biweekly). [Convert to your timezone](https://dateful.com/convert/utc8?t=1430).
* Tuesday at 15:00 UTC+0 (English)(biweekly). [Convert to your timezone](https://dateful.com/convert/coordinated-universal-time-utc?t=15).

Resources:
- [Meeting Notes and Agenda](https://docs.google.com/document/d/1y6YLVC-v7cmVAdbjedoyR5WL0-q45DBRXTvz5_I7bkA/edit)
- [Meeting Calendar](https://calendar.google.com/calendar/embed?src=karmadaoss%40gmail.com&amp;ctz=Asia%2FShanghai) | [Subscribe](https://calendar.google.com/calendar/u/1?cid=a2FybWFkYW9zc0BnbWFpbC5jb20)
- [Meeting Link](https://zoom.com/my/karmada)

## Contact

If you have questions, feel free to reach out to us in the following ways:

- [mailing list](https://groups.google.com/forum/#!forum/karmada)
- [slack](https://cloud-native.slack.com/archives/C02MUF8QXUN) | [Join](https://slack.cncf.io/)
- [twitter](https://twitter.com/karmada_io)

## Talks and References

|                  | Link                                                                                                                    |
|------------------|-------------------------------------------------------------------------------------------------------------------------|
| KubeCon(EU 2021) | [Beyond federation: automating multi-cloud workloads with K8s native APIs](https://www.youtube.com/watch?v=LJJoaGszBVk) |
| KubeCon(EU 2022) | [Sailing Multi Cloud Traffic Management With Karmada](https://youtu.be/rzFbxeZQHWI)                                     |
| KubeDay(Israel 2023)| [Simplifying Multi-cluster Kubernetes Management with Karmada](https://www.youtube.com/watch?v=WCrIhRNBZ9I) |
| KubeCon(China 2023) | [Multi-Cloud Multi-Cluster HPA Helps Trip.com Group Deal with Business Downturn and Rapid Recovery](https://www.youtube.com/watch?v=uninSyVBKO4) |
| KubeCon(China 2023) | [Break Through Cluster Boundaries to Autoscale Workloads Across Them on a Large Scale](https://www.youtube.com/watch?v=22W1yrEJjtQ) |
| KubeCon(China 2023) | [Cross-Cluster Traffic Orchestration with eBPF](https://www.youtube.com/watch?v=e4GA5e-C7n0) |
| KubeCon(China 2023) | [Non-Intrusively Enable OpenKruise and Argo Workflow in a Multi-Cluster Federation](https://www.youtube.com/watch?v=gcllTXRkz-E) |

For blogs, please refer to [website](https://karmada.io/blog/).

## Contributing

If you&#039;re interested in being a contributor and want to get involved in
developing the Karmada code, please see [CONTRIBUTING](CONTRIBUTING.md) for
details on submitting patches and the contribution workflow.

## License

Karmada is under the Apache 2.0 license. See the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[k3s-io/k3s]]></title>
            <link>https://github.com/k3s-io/k3s</link>
            <guid>https://github.com/k3s-io/k3s</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[Lightweight Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/k3s-io/k3s">k3s-io/k3s</a></h1>
            <p>Lightweight Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 30,604</p>
            <p>Forks: 2,499</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>K3s - Lightweight Kubernetes
===============================================
[![FOSSA Status](https://app.fossa.com/api/projects/custom%2B25850%2Fgithub.com%2Fk3s-io%2Fk3s.svg?type=shield)](https://app.fossa.com/projects/custom%2B25850%2Fgithub.com%2Fk3s-io%2Fk3s?ref=badge_shield)
[![Nightly CI](https://github.com/k3s-io/k3s/actions/workflows/nightly-install.yaml/badge.svg)](https://github.com/k3s-io/k3s/actions/workflows/nightly-install.yaml)
[![Build Status](https://drone-publish.k3s.io/api/badges/k3s-io/k3s/status.svg)](https://drone-publish.k3s.io/k3s-io/k3s)
[![Integration Test Coverage](https://github.com/k3s-io/k3s/actions/workflows/integration.yaml/badge.svg)](https://github.com/k3s-io/k3s/actions/workflows/integration.yaml)
[![Unit Test Coverage](https://github.com/k3s-io/k3s/actions/workflows/unitcoverage.yaml/badge.svg)](https://github.com/k3s-io/k3s/actions/workflows/unitcoverage.yaml)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/6835/badge)](https://www.bestpractices.dev/projects/6835)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/k3s-io/k3s/badge)](https://scorecard.dev/viewer/?uri=github.com/k3s-io/k3s)
[![Releases](https://img.shields.io/github/downloads/k3s-io/k3s/total.svg)](https://github.com/k3s-io/k3s/tags?label=Downloads)
[![CLOMonitor](https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/k3s/badge)](https://clomonitor.io/projects/cncf/k3s)

Lightweight Kubernetes.  Production ready, easy to install, half the memory, all in a binary less than 100 MB.

Great for:

* Edge
* IoT
* CI
* Development
* ARM
* Embedding k8s
* Situations where a PhD in k8s clusterology is infeasible

What is this?
---

K3s is a [fully conformant](https://github.com/cncf/k8s-conformance/pulls?q=is%3Apr+k3s) production-ready Kubernetes distribution with the following changes:

1. It is packaged as a single binary.
1. It adds support for sqlite3 as the default storage backend. Etcd3, MariaDB, MySQL, and Postgres are also supported.
1. It wraps Kubernetes and other components in a single, simple launcher.
1. It is secure by default with reasonable defaults for lightweight environments.
1. It has minimal to no OS dependencies (just a sane kernel and cgroup mounts needed).
1. It eliminates the need to expose a port on Kubernetes worker nodes for the kubelet API by exposing this API to the Kubernetes control plane nodes over a websocket tunnel.

K3s bundles the following technologies together into a single cohesive distribution:

* [Containerd](https://containerd.io/) &amp; [runc](https://github.com/opencontainers/runc)
* [Flannel](https://github.com/flannel-io/flannel) for CNI
* [CoreDNS](https://coredns.io/)
* [Metrics Server](https://github.com/kubernetes-sigs/metrics-server)
* [Traefik](https://containo.us/traefik/) for ingress
* [Klipper-lb](https://github.com/k3s-io/klipper-lb) as an embedded service load balancer provider
* [Kube-router](https://www.kube-router.io/) netpol controller for network policy
* [Helm-controller](https://github.com/k3s-io/helm-controller) to allow for CRD-driven deployment of helm manifests
* [Kine](https://github.com/k3s-io/kine) as a datastore shim that allows etcd to be replaced with other databases
* [Local-path-provisioner](https://github.com/rancher/local-path-provisioner) for provisioning volumes using local storage
* [Host utilities](https://github.com/k3s-io/k3s-root) such as iptables/nftables, ebtables, ethtool, &amp; socat

These technologies can be disabled or swapped out for technologies of your choice.

Additionally, K3s simplifies Kubernetes operations by maintaining functionality for:

* Managing the TLS certificates of Kubernetes components
* Managing the connection between worker and server nodes
* Auto-deploying Kubernetes resources from local manifests in realtime as they are changed.
* Managing an embedded etcd cluster

What&#039;s with the name?
--------------------

We wanted an installation of Kubernetes that was half the size in terms of memory footprint. Kubernetes is a
10 letter word stylized as k8s. So something half as big as Kubernetes would be a 5 letter word stylized as
K3s. A &#039;3&#039; is also an &#039;8&#039; cut in half vertically. There is neither a long-form of K3s nor official pronunciation.

Is this a fork?
---------------

No, it&#039;s a distribution. A fork implies continued divergence from the original. This is not K3s&#039;s goal or practice. K3s explicitly intends not to change any core Kubernetes functionality. We seek to remain as close to upstream Kubernetes as possible. However, we maintain a small set of patches (well under 1000 lines) important to K3s&#039;s use case and deployment model. We maintain patches for other components as well. When possible, we contribute these changes back to the upstream projects, for example, with [SELinux support in containerd](https://github.com/containerd/cri/pull/1487/commits/24209b91bf361e131478d15cfea1ab05694dc3eb). This is a common practice amongst software distributions.

K3s is a distribution because it packages additional components and services necessary for a fully functional cluster that go beyond vanilla Kubernetes. These are opinionated choices on technologies for components like ingress, storage class, network policy, service load balancer, and even container runtime. These choices and technologies are touched on in more detail in the [What is this?](#what-is-this) section.

How is this lightweight or smaller than upstream Kubernetes?
---

There are two major ways that K3s is lighter weight than upstream Kubernetes:
1. The memory footprint to run it is smaller
2. The binary, which contains all the non-containerized components needed to run a cluster, is smaller

The memory footprint is reduced primarily by running many components inside of a single process. This eliminates significant overhead that would otherwise be duplicated for each component.

The binary is smaller by removing third-party storage drivers and cloud providers, explained in more detail below.

What have you removed from upstream Kubernetes?
---

This is a common point of confusion because it has changed over time. Early versions of K3s had much more removed than the current version. K3s currently removes two things:

1. In-tree storage drivers
1. In-tree cloud provider

Both of these have out-of-tree alternatives in the form of [CSI](https://github.com/container-storage-interface/spec/blob/master/spec.md) and [CCM](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/), which work in K3s and which upstream is moving towards.

We remove these to achieve a smaller binary size. They can be removed while remaining conformant because neither affects core Kubernetes functionality. They are also dependent on third-party cloud or data center technologies/services, which may not be available in many K3s&#039; use cases.

Getting Started
---
- [Quick Install](https://docs.k3s.io/quick-start)
- [Architecture](https://docs.k3s.io/architecture)
- [FAQ](https://docs.k3s.io/faq)
- [Contribute](CONTRIBUTING.md)

Community
---
- ### Slack

Join [Slack](https://slack.rancher.io/) to chat with K3s developers and other K3s users. Great place to learn and ask questions: [#k3s](https://rancher-users.slack.com/archives/CGGQEHPPW) and [#k3s-contributor](https://rancher-users.slack.com/archives/CGXR87T8B) and [#k3s](https://cloud-native.slack.com/archives/C0196ULKX8S) channel in [CNCF Slack](https://cloud-native.slack.com)

- ### Getting involved
[GitHub Issues](https://github.com/k3s-io/k3s/issues) - Submit your issues and feature requests via GitHub.

- ### Community Meetings and Office hours
The K3s developer community hangs out on Zoom to chat. Everybody is welcome.

**Add the [Linux Foundation iCal](https://webcal.prod.itx.linuxfoundation.org/lfx/a092M00001IkYIjQAN) to your calendar**: 
- AMS/EMEA TZ 10:00 am PST - every *second* Tuesday of the month
- EMEA/APAC TimeZone friendly - every *third* Tuesday of the month

**Meeting notes and agenda**: https://hackmd.io/@k3s/meet-notes/

**Meeting recordings**: [K3s Channel](https://www.youtube.com/watch?v=HRuJROA6Z3k&amp;list=PLlBG85HKlLE9KFDqJ_K6NOpup-zVw8ANl&amp;pp=gAQB)

You can check also the full details on the website: https://k3s.io/community


What&#039;s next?
---

Check out our [roadmap](ROADMAP.md) to see what we have planned moving forward.

Release cadence
---

K3s maintains pace with upstream Kubernetes releases. Our goal is to release patch releases within one week, and new minors within 30 days.

Our release versioning reflects the version of upstream Kubernetes that is being released. For example, the K3s release [v1.27.4+k3s1](https://github.com/k3s-io/k3s/releases/tag/v1.27.4%2Bk3s1) maps to the `v1.27.4` Kubernetes release. We add a postfix in the form of `+k3s&lt;number&gt;` to allow us to make additional releases using the same version of upstream Kubernetes while remaining [semver](https://semver.org/) compliant. For example, if we discovered a high severity bug in `v1.27.4+k3s1` and needed to release an immediate fix for it, we would release `v1.27.4+k3s2`.

Documentation
-------------

Please see [the official docs site](https://docs.k3s.io) for complete documentation.

Quick-Start - Install Script
--------------

The `install.sh` script provides a convenient way to download K3s and add a service to systemd or openrc.

To install k3s as a service, run:

```bash
curl -sfL https://get.k3s.io | sh -
```

A kubeconfig file is written to `/etc/rancher/k3s/k3s.yaml` and the service is automatically started or restarted.
The install script will install K3s and additional utilities, such as `kubectl`, `crictl`, `k3s-killall.sh`, and `k3s-uninstall.sh`, for example:

```bash
sudo kubectl get nodes
```

`K3S_TOKEN` is created at `/var/lib/rancher/k3s/server/node-token` on your server.
To install on worker nodes, pass `K3S_URL` along with
`K3S_TOKEN` environment variables, for example:

```bash
curl -sfL https://get.k3s.io | K3S_URL=https://myserver:6443 K3S_TOKEN=XXX sh -
```

Manual Download
---------------

1. Download `k3s` from latest [release](https://github.com/k3s-io/k3s/releases/latest), x86_64, armhf, arm64 and s390x are supported.
1. Run the server.

```bash
sudo k3s server &amp;
# Kubeconfig is written to /etc/rancher/k3s/k3s.yaml
sudo k3s kubectl get nodes

# On a different node run the below. NODE_TOKEN comes from
# /var/lib/rancher/k3s/server/node-token on your server
sudo k3s agent --server https://myserver:6443 --token ${NODE_TOKEN}
```

Contributing
------------

Please check out our [contributing guide](CONTRIBUTING.md) if you&#039;re interested in contributing to K3s.

Security
--------

Security issues in K3s can be reported by sending an email to [security@k3s.io](mailto:security@k3s.io).
Please do not file issues about security issues.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[bytedance/sonic]]></title>
            <link>https://github.com/bytedance/sonic</link>
            <guid>https://github.com/bytedance/sonic</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[A blazingly fast JSON serializing & deserializing library]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytedance/sonic">bytedance/sonic</a></h1>
            <p>A blazingly fast JSON serializing & deserializing library</p>
            <p>Language: Go</p>
            <p>Stars: 8,532</p>
            <p>Forks: 412</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># Sonic

English | [‰∏≠Êñá](README_ZH_CN.md)

A blazingly fast JSON serializing &amp;amp; deserializing library, accelerated by JIT (just-in-time compiling) and SIMD (single-instruction-multiple-data).

## Requirement

- Go: 1.17~1.24
  - Notice: Go1.24.0 is not supported due to the [issue](https://github.com/golang/go/issues/71672), please use higher go version or add build tag `--ldflags=&quot;-checklinkname=0&quot;` 
- OS: Linux / MacOS / Windows
- CPU: AMD64 / (ARM64, need go1.20 above)

## Features

- Runtime object binding without code generation
- Complete APIs for JSON value manipulation
- Fast, fast, fast!

## APIs

see [go.dev](https://pkg.go.dev/github.com/bytedance/sonic)

## Benchmarks

For **all sizes** of json and **all scenarios** of usage, **Sonic performs best**.

- [Medium](https://github.com/bytedance/sonic/blob/main/decoder/testdata_test.go#L19) (13KB, 300+ key, 6 layers)

```powershell
goversion: 1.17.1
goos: darwin
goarch: amd64
cpu: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz
BenchmarkEncoder_Generic_Sonic-16                      32393 ns/op         402.40 MB/s       11965 B/op          4 allocs/op
BenchmarkEncoder_Generic_Sonic_Fast-16                 21668 ns/op         601.57 MB/s       10940 B/op          4 allocs/op
BenchmarkEncoder_Generic_JsonIter-16                   42168 ns/op         309.12 MB/s       14345 B/op        115 allocs/op
BenchmarkEncoder_Generic_GoJson-16                     65189 ns/op         199.96 MB/s       23261 B/op         16 allocs/op
BenchmarkEncoder_Generic_StdLib-16                    106322 ns/op         122.60 MB/s       49136 B/op        789 allocs/op
BenchmarkEncoder_Binding_Sonic-16                       6269 ns/op        2079.26 MB/s       14173 B/op          4 allocs/op
BenchmarkEncoder_Binding_Sonic_Fast-16                  5281 ns/op        2468.16 MB/s       12322 B/op          4 allocs/op
BenchmarkEncoder_Binding_JsonIter-16                   20056 ns/op         649.93 MB/s        9488 B/op          2 allocs/op
BenchmarkEncoder_Binding_GoJson-16                      8311 ns/op        1568.32 MB/s        9481 B/op          1 allocs/op
BenchmarkEncoder_Binding_StdLib-16                     16448 ns/op         792.52 MB/s        9479 B/op          1 allocs/op
BenchmarkEncoder_Parallel_Generic_Sonic-16              6681 ns/op        1950.93 MB/s       12738 B/op          4 allocs/op
BenchmarkEncoder_Parallel_Generic_Sonic_Fast-16         4179 ns/op        3118.99 MB/s       10757 B/op          4 allocs/op
BenchmarkEncoder_Parallel_Generic_JsonIter-16           9861 ns/op        1321.84 MB/s       14362 B/op        115 allocs/op
BenchmarkEncoder_Parallel_Generic_GoJson-16            18850 ns/op         691.52 MB/s       23278 B/op         16 allocs/op
BenchmarkEncoder_Parallel_Generic_StdLib-16            45902 ns/op         283.97 MB/s       49174 B/op        789 allocs/op
BenchmarkEncoder_Parallel_Binding_Sonic-16              1480 ns/op        8810.09 MB/s       13049 B/op          4 allocs/op
BenchmarkEncoder_Parallel_Binding_Sonic_Fast-16         1209 ns/op        10785.23 MB/s      11546 B/op          4 allocs/op
BenchmarkEncoder_Parallel_Binding_JsonIter-16           6170 ns/op        2112.58 MB/s        9504 B/op          2 allocs/op
BenchmarkEncoder_Parallel_Binding_GoJson-16             3321 ns/op        3925.52 MB/s        9496 B/op          1 allocs/op
BenchmarkEncoder_Parallel_Binding_StdLib-16             3739 ns/op        3486.49 MB/s        9480 B/op          1 allocs/op

BenchmarkDecoder_Generic_Sonic-16                      66812 ns/op         195.10 MB/s       57602 B/op        723 allocs/op
BenchmarkDecoder_Generic_Sonic_Fast-16                 54523 ns/op         239.07 MB/s       49786 B/op        313 allocs/op
BenchmarkDecoder_Generic_StdLib-16                    124260 ns/op         104.90 MB/s       50869 B/op        772 allocs/op
BenchmarkDecoder_Generic_JsonIter-16                   91274 ns/op         142.81 MB/s       55782 B/op       1068 allocs/op
BenchmarkDecoder_Generic_GoJson-16                     88569 ns/op         147.17 MB/s       66367 B/op        973 allocs/op
BenchmarkDecoder_Binding_Sonic-16                      32557 ns/op         400.38 MB/s       28302 B/op        137 allocs/op
BenchmarkDecoder_Binding_Sonic_Fast-16                 28649 ns/op         455.00 MB/s       24999 B/op         34 allocs/op
BenchmarkDecoder_Binding_StdLib-16                    111437 ns/op         116.97 MB/s       10576 B/op        208 allocs/op
BenchmarkDecoder_Binding_JsonIter-16                   35090 ns/op         371.48 MB/s       14673 B/op        385 allocs/op
BenchmarkDecoder_Binding_GoJson-16                     28738 ns/op         453.59 MB/s       22039 B/op         49 allocs/op
BenchmarkDecoder_Parallel_Generic_Sonic-16             12321 ns/op        1057.91 MB/s       57233 B/op        723 allocs/op
BenchmarkDecoder_Parallel_Generic_Sonic_Fast-16        10644 ns/op        1224.64 MB/s       49362 B/op        313 allocs/op
BenchmarkDecoder_Parallel_Generic_StdLib-16            57587 ns/op         226.35 MB/s       50874 B/op        772 allocs/op
BenchmarkDecoder_Parallel_Generic_JsonIter-16          38666 ns/op         337.12 MB/s       55789 B/op       1068 allocs/op
BenchmarkDecoder_Parallel_Generic_GoJson-16            30259 ns/op         430.79 MB/s       66370 B/op        974 allocs/op
BenchmarkDecoder_Parallel_Binding_Sonic-16              5965 ns/op        2185.28 MB/s       27747 B/op        137 allocs/op
BenchmarkDecoder_Parallel_Binding_Sonic_Fast-16         5170 ns/op        2521.31 MB/s       24715 B/op         34 allocs/op
BenchmarkDecoder_Parallel_Binding_StdLib-16            27582 ns/op         472.58 MB/s       10576 B/op        208 allocs/op
BenchmarkDecoder_Parallel_Binding_JsonIter-16          13571 ns/op         960.51 MB/s       14685 B/op        385 allocs/op
BenchmarkDecoder_Parallel_Binding_GoJson-16            10031 ns/op        1299.51 MB/s       22111 B/op         49 allocs/op

BenchmarkGetOne_Sonic-16                                3276 ns/op        3975.78 MB/s          24 B/op          1 allocs/op
BenchmarkGetOne_Gjson-16                                9431 ns/op        1380.81 MB/s           0 B/op          0 allocs/op
BenchmarkGetOne_Jsoniter-16                            51178 ns/op         254.46 MB/s       27936 B/op        647 allocs/op
BenchmarkGetOne_Parallel_Sonic-16                      216.7 ns/op       60098.95 MB/s          24 B/op          1 allocs/op
BenchmarkGetOne_Parallel_Gjson-16                       1076 ns/op        12098.62 MB/s          0 B/op          0 allocs/op
BenchmarkGetOne_Parallel_Jsoniter-16                   17741 ns/op         734.06 MB/s       27945 B/op        647 allocs/op
BenchmarkSetOne_Sonic-16                               9571 ns/op         1360.61 MB/s        1584 B/op         17 allocs/op
BenchmarkSetOne_Sjson-16                               36456 ns/op         357.22 MB/s       52180 B/op          9 allocs/op
BenchmarkSetOne_Jsoniter-16                            79475 ns/op         163.86 MB/s       45862 B/op        964 allocs/op
BenchmarkSetOne_Parallel_Sonic-16                      850.9 ns/op       15305.31 MB/s        1584 B/op         17 allocs/op
BenchmarkSetOne_Parallel_Sjson-16                      18194 ns/op         715.77 MB/s       52247 B/op          9 allocs/op
BenchmarkSetOne_Parallel_Jsoniter-16                   33560 ns/op         388.05 MB/s       45892 B/op        964 allocs/op
BenchmarkLoadNode/LoadAll()-16                         11384 ns/op        1143.93 MB/s        6307 B/op         25 allocs/op
BenchmarkLoadNode_Parallel/LoadAll()-16                 5493 ns/op        2370.68 MB/s        7145 B/op         25 allocs/op
BenchmarkLoadNode/Interface()-16                       17722 ns/op         734.85 MB/s       13323 B/op         88 allocs/op
BenchmarkLoadNode_Parallel/Interface()-16              10330 ns/op        1260.70 MB/s       15178 B/op         88 allocs/op
```

- [Small](https://github.com/bytedance/sonic/blob/main/testdata/small.go) (400B, 11 keys, 3 layers)
![small benchmarks](./docs/imgs/bench-small.png)
- [Large](https://github.com/bytedance/sonic/blob/main/testdata/twitter.json) (635KB, 10000+ key, 6 layers)
![large benchmarks](./docs/imgs/bench-large.png)

See [bench.sh](https://github.com/bytedance/sonic/blob/main/scripts/bench.sh) for benchmark codes.

## How it works

See [INTRODUCTION.md](./docs/INTRODUCTION.md).

## Usage

### Marshal/Unmarshal

Default behaviors are mostly consistent with `encoding/json`, except HTML escaping form (see [Escape HTML](https://github.com/bytedance/sonic/blob/main/README.md#escape-html)) and `SortKeys` feature (optional support see [Sort Keys](https://github.com/bytedance/sonic/blob/main/README.md#sort-keys)) that is **NOT** in conformity to [RFC8259](https://datatracker.ietf.org/doc/html/rfc8259).

 ```go
import &quot;github.com/bytedance/sonic&quot;

var data YourSchema
// Marshal
output, err := sonic.Marshal(&amp;data)
// Unmarshal
err := sonic.Unmarshal(output, &amp;data)
 ```

### Streaming IO

Sonic supports decoding json from `io.Reader` or encoding objects into `io.Writer`, aims at handling multiple values as well as reducing memory consumption.

- encoder

```go
var o1 = map[string]interface{}{
    &quot;a&quot;: &quot;b&quot;,
}
var o2 = 1
var w = bytes.NewBuffer(nil)
var enc = sonic.ConfigDefault.NewEncoder(w)
enc.Encode(o1)
enc.Encode(o2)
fmt.Println(w.String())
// Output:
// {&quot;a&quot;:&quot;b&quot;}
// 1
```

- decoder

```go
var o =  map[string]interface{}{}
var r = strings.NewReader(`{&quot;a&quot;:&quot;b&quot;}{&quot;1&quot;:&quot;2&quot;}`)
var dec = sonic.ConfigDefault.NewDecoder(r)
dec.Decode(&amp;o)
dec.Decode(&amp;o)
fmt.Printf(&quot;%+v&quot;, o)
// Output:
// map[1:2 a:b]
```

### Use Number/Use Int64

 ```go
import &quot;github.com/bytedance/sonic/decoder&quot;

var input = `1`
var data interface{}

// default float64
dc := decoder.NewDecoder(input)
dc.Decode(&amp;data) // data == float64(1)
// use json.Number
dc = decoder.NewDecoder(input)
dc.UseNumber()
dc.Decode(&amp;data) // data == json.Number(&quot;1&quot;)
// use int64
dc = decoder.NewDecoder(input)
dc.UseInt64()
dc.Decode(&amp;data) // data == int64(1)

root, err := sonic.GetFromString(input)
// Get json.Number
jn := root.Number()
jm := root.InterfaceUseNumber().(json.Number) // jn == jm
// Get float64
fn := root.Float64()
fm := root.Interface().(float64) // jn == jm
 ```

### Sort Keys

On account of the performance loss from sorting (roughly 10%), sonic doesn&#039;t enable this feature by default. If your component depends on it to work (like [zstd](https://github.com/facebook/zstd)), Use it like this:

```go
import &quot;github.com/bytedance/sonic&quot;
import &quot;github.com/bytedance/sonic/encoder&quot;

// Binding map only
m := map[string]interface{}{}
v, err := encoder.Encode(m, encoder.SortMapKeys)

// Or ast.Node.SortKeys() before marshal
var root := sonic.Get(JSON)
err := root.SortKeys()
```

### Escape HTML

On account of the performance loss (roughly 15%), sonic doesn&#039;t enable this feature by default. You can use `encoder.EscapeHTML` option to open this feature (align with `encoding/json.HTMLEscape`).

```go
import &quot;github.com/bytedance/sonic&quot;

v := map[string]string{&quot;&amp;&amp;&quot;:&quot;&lt;&gt;&quot;}
ret, err := Encode(v, EscapeHTML) // ret == `{&quot;\u0026\u0026&quot;:{&quot;X&quot;:&quot;\u003c\u003e&quot;}}`
```

### Compact Format

Sonic encodes primitive objects (struct/map...) as compact-format JSON by default, except marshaling `json.RawMessage` or `json.Marshaler`: sonic ensures validating their output JSON but **DO NOT** compacting them for performance concerns. We provide the option `encoder.CompactMarshaler` to add compacting process.

### Print Error

If there invalid syntax in input JSON, sonic will return `decoder.SyntaxError`, which supports pretty-printing of error position

```go
import &quot;github.com/bytedance/sonic&quot;
import &quot;github.com/bytedance/sonic/decoder&quot;

var data interface{}
err := sonic.UnmarshalString(&quot;[[[}]]&quot;, &amp;data)
if err != nil {
    /* One line by default */
    println(e.Error()) // &quot;Syntax error at index 3: invalid char\n\n\t[[[}]]\n\t...^..\n&quot;
    /* Pretty print */
    if e, ok := err.(decoder.SyntaxError); ok {
        /*Syntax error at index 3: invalid char

            [[[}]]
            ...^..
        */
        print(e.Description())
    } else if me, ok := err.(*decoder.MismatchTypeError); ok {
        // decoder.MismatchTypeError is new to Sonic v1.6.0
        print(me.Description())
    }
}
```

#### Mismatched Types [Sonic v1.6.0]

If there a **mismatch-typed** value for a given key, sonic will report `decoder.MismatchTypeError` (if there are many, report the last one), but still skip wrong the value and keep decoding next JSON.

```go
import &quot;github.com/bytedance/sonic&quot;
import &quot;github.com/bytedance/sonic/decoder&quot;

var data = struct{
    A int
    B int
}{}
err := UnmarshalString(`{&quot;A&quot;:&quot;1&quot;,&quot;B&quot;:1}`, &amp;data)
println(err.Error())    // Mismatch type int with value string &quot;at index 5: mismatched type with value\n\n\t{\&quot;A\&quot;:\&quot;1\&quot;,\&quot;B\&quot;:1}\n\t.....^.........\n&quot;
fmt.Printf(&quot;%+v&quot;, data) // {A:0 B:1}
```

### Ast.Node

Sonic/ast.Node is a completely self-contained AST for JSON. It implements serialization and deserialization both and provides robust APIs for obtaining and modification of generic data.

#### Get/Index

Search partial JSON by given paths, which must be non-negative integer or string, or nil

```go
import &quot;github.com/bytedance/sonic&quot;

input := []byte(`{&quot;key1&quot;:[{},{&quot;key2&quot;:{&quot;key3&quot;:[1,2,3]}}]}`)

// no path, returns entire json
root, err := sonic.Get(input)
raw := root.Raw() // == string(input)

// multiple paths
root, err := sonic.Get(input, &quot;key1&quot;, 1, &quot;key2&quot;)
sub := root.Get(&quot;key3&quot;).Index(2).Int64() // == 3
```

**Tip**: since `Index()` uses offset to locate data, which is much faster than scanning like `Get()`, we suggest you use it as much as possible. And sonic also provides another API `IndexOrGet()` to underlying use offset as well as ensure the key is matched.

#### SearchOption

`Searcher` provides some options for user to meet different needs:

```go
opts := ast.SearchOption{ CopyReturn: true ... }
val, err := sonic.GetWithOptions(JSON, opts, &quot;key&quot;)
```

- CopyReturn
Indicate the searcher to copy the result JSON string instead of refer from the input. This can help to reduce memory usage if you cache the results
- ConcurentRead
Since `ast.Node` use `Lazy-Load` design, it doesn&#039;t support Concurrently-Read by default. If you want to read it concurrently, please specify it.
- ValidateJSON
Indicate the searcher to validate the entire JSON. This option is enabled by default, which slow down the search speed a little.

#### Set/Unset

Modify the json content by Set()/Unset()

```go
import &quot;github.com/bytedance/sonic&quot;

// Set
exist, err := root.Set(&quot;key4&quot;, NewBool(true)) // exist == false
alias1 := root.Get(&quot;key4&quot;)
println(alias1.Valid()) // true
alias2 := root.Index(1)
println(alias1 == alias2) // true

// Unset
exist, err := root.UnsetByIndex(1) // exist == true
println(root.Get(&quot;key4&quot;).Check()) // &quot;value not exist&quot;
```

#### Serialize

To encode `ast.Node` as json, use `MarshalJson()` or `json.Marshal()` (MUST pass the node&#039;s pointer)

```go
import (
    &quot;encoding/json&quot;
    &quot;github.com/bytedance/sonic&quot;
)

buf, err := root.MarshalJson()
println(string(buf))                // {&quot;key1&quot;:[{},{&quot;key2&quot;:{&quot;key3&quot;:[1,2,3]}}]}
exp, err := json.Marshal(&amp;root)     // WARN: use pointer
println(string(buf) == string(exp)) // true
```

#### APIs

- validation: `Check()`, `Error()`, `Valid()`, `Exist()`
- searching: `Index()`, `Get()`, `IndexPair()`, `IndexOrGet()`, `GetByPath()`
- go-type casting: `Int64()`, `Float64()`, `String()`, `Number()`, `Bool()`, `Map[UseNumber|UseNode]()`, `Array[UseNumber|UseNode]()`, `Interface[UseNumber|UseNode]()`
- go-type packing: `NewRaw()`, `NewNumber()`, `NewNull()`, `NewBool()`, `NewString()`, `NewObject()`, `NewArray()`
- iteration: `Values()`, `Properties()`, `ForEach()`, `SortKeys()`
- modification: `Set()`, `SetByIndex()`, `Add()`

### Ast.Visitor

Sonic provides an advanced API for fully parsing JSON into non-standard types (neither `struct` not `map[string]interface{}`) without using any intermediate representation (`ast.Node` or `interface{}`). For example, you might have the following types which are like `interface{}` but actually not `interface{}`:

```go
type UserNode interface {}

// the following types implement the UserNode interface.
type (
    UserNull    struct{}
    UserBool    struct{ Value bool }
    UserInt64   struct{ Value int64 }
    UserFloat64 struct{ Value float64 }
    UserString  struct{ Value string }
    UserObject  struct{ Value map[string]UserNode }
    UserArray   struct{ Value []UserNode }
)
```

Sonic provides the following API to return **the preorder traversal of a JSON AST**. The `ast.Visitor` is a SAX style interface which is used in some C++ JSON library. You should implement `ast.Visitor` by yourself and pass it to `ast.Preorder()` method. In your visitor you can make your custom types to represent JSON values. There may be an O(n) space container (such as stack) in your visitor to record the object / array hierarchy.

```go
func Preorder(str string, visitor Visitor, opts *VisitorOptions) error

type Visitor interface {
    OnNull() error
    OnBool(v bool) error
    OnString(v string) error
    OnInt64(v int64, n json.Number) error
    OnFloat64(v float64, n json.Number) error
    OnObjectBegin(capacity int) error
    OnObjectKey(key string) error
    OnObjectEnd() error
    OnArrayBegin(capacity int) error
    OnArrayEnd() error
}
```

See [ast/visitor.go](https://github.com/bytedance/sonic/blob/main/ast/visitor.go) for detailed usage. We also implement a demo visitor for `UserNode` in [ast/visitor_test.go](https://github.com/bytedance/sonic/blob/main/ast/visitor_test.go).

## Compatibility

For developers who want to use sonic to meet different scenarios, we provide some integrated configs as `sonic.API`

- `ConfigDefault`: the sonic&#039;s default config (`EscapeHTML=false`,`SortKeys=false`...) to run sonic fast meanwhile ensure security.
- `ConfigStd`: the std-compatible config (`EscapeHTML=true`,`SortKeys=true`...)
- `ConfigFastest`: the fastest config (`NoQuoteTextMarshaler=true`) to run on sonic as fast as possible.
Sonic **DOES NOT** ensure to support all environments, due to the difficulty of developing high-performance codes. On non-sonic-supporting environment, the implementation will fall back to `encoding/json`. Thus below configs will all equal to `ConfigStd`.

## Tips

### Pretouch

Since Sonic uses [golang-asm](https://github.com/twitchyliquid64/golang-asm) as a JIT assembler, which is NOT very suitable for runtime compiling, first-hit running of a huge schema may cause request-timeout or even process-OOM. For better stability, we advise **using `Pretouch()` for huge-schema or compact-memory applications** before `Marshal()/Unmarshal()`.

```go
import (
    &quot;reflect&quot;
    &quot;github.com/bytedance/sonic&quot;
    &quot;github.com/bytedance/sonic/option&quot;
)

func init() {
    var v HugeStruct

    // For most large types (nesting depth &lt;= option.DefaultMaxInlineDepth)
    err := sonic.Pretouch(reflect.TypeOf(v))

    // with more CompileOption...
    err := sonic.Pretouch(reflect.TypeOf(v),
        // If the type is too deep nesting (nesting depth &gt; option.DefaultMaxInlineDepth),
        // you can set compile recursive loops in Pretouch for better stability in JIT.
        option.WithCompileRecursiveDepth(loop),
        // For a large nested struct, try to set a smaller depth to reduce compiling time.
        option.WithCompileMaxInlineDepth(depth),
    )
}
```

### Copy string

When decoding **string values without any escaped characters**, sonic references them from the origin JSON buffer instead of mallocing a new buffer to copy. This helps a lot for CPU performance but may leave the whole JSON buffer in memory as long as the decoded objects are being used. In practice, we found the extra memory introduced by referring JSON buffer is usually 20% ~ 80% of decoded objects. Once an application holds the

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[jackc/pgx]]></title>
            <link>https://github.com/jackc/pgx</link>
            <guid>https://github.com/jackc/pgx</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[PostgreSQL driver and toolkit for Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jackc/pgx">jackc/pgx</a></h1>
            <p>PostgreSQL driver and toolkit for Go</p>
            <p>Language: Go</p>
            <p>Stars: 12,354</p>
            <p>Forks: 939</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>[![Go Reference](https://pkg.go.dev/badge/github.com/jackc/pgx/v5.svg)](https://pkg.go.dev/github.com/jackc/pgx/v5)
[![Build Status](https://github.com/jackc/pgx/actions/workflows/ci.yml/badge.svg)](https://github.com/jackc/pgx/actions/workflows/ci.yml)

# pgx - PostgreSQL Driver and Toolkit

pgx is a pure Go driver and toolkit for PostgreSQL.

The pgx driver is a low-level, high performance interface that exposes PostgreSQL-specific features such as `LISTEN` /
`NOTIFY` and `COPY`. It also includes an adapter for the standard `database/sql` interface.

The toolkit component is a related set of packages that implement PostgreSQL functionality such as parsing the wire protocol
and type mapping between PostgreSQL and Go. These underlying packages can be used to implement alternative drivers,
proxies, load balancers, logical replication clients, etc.

## Example Usage

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;os&quot;

	&quot;github.com/jackc/pgx/v5&quot;
)

func main() {
	// urlExample := &quot;postgres://username:password@localhost:5432/database_name&quot;
	conn, err := pgx.Connect(context.Background(), os.Getenv(&quot;DATABASE_URL&quot;))
	if err != nil {
		fmt.Fprintf(os.Stderr, &quot;Unable to connect to database: %v\n&quot;, err)
		os.Exit(1)
	}
	defer conn.Close(context.Background())

	var name string
	var weight int64
	err = conn.QueryRow(context.Background(), &quot;select name, weight from widgets where id=$1&quot;, 42).Scan(&amp;name, &amp;weight)
	if err != nil {
		fmt.Fprintf(os.Stderr, &quot;QueryRow failed: %v\n&quot;, err)
		os.Exit(1)
	}

	fmt.Println(name, weight)
}
```

See the [getting started guide](https://github.com/jackc/pgx/wiki/Getting-started-with-pgx) for more information.

## Features

* Support for approximately 70 different PostgreSQL types
* Automatic statement preparation and caching
* Batch queries
* Single-round trip query mode
* Full TLS connection control
* Binary format support for custom types (allows for much quicker encoding/decoding)
* `COPY` protocol support for faster bulk data loads
* Tracing and logging support
* Connection pool with after-connect hook for arbitrary connection setup
* `LISTEN` / `NOTIFY`
* Conversion of PostgreSQL arrays to Go slice mappings for integers, floats, and strings
* `hstore` support
* `json` and `jsonb` support
* Maps `inet` and `cidr` PostgreSQL types to `netip.Addr` and `netip.Prefix`
* Large object support
* NULL mapping to pointer to pointer
* Supports `database/sql.Scanner` and `database/sql/driver.Valuer` interfaces for custom types
* Notice response handling
* Simulated nested transactions with savepoints

## Choosing Between the pgx and database/sql Interfaces

The pgx interface is faster. Many PostgreSQL specific features such as `LISTEN` / `NOTIFY` and `COPY` are not available
through the `database/sql` interface.

The pgx interface is recommended when:

1. The application only targets PostgreSQL.
2. No other libraries that require `database/sql` are in use.

It is also possible to use the `database/sql` interface and convert a connection to the lower-level pgx interface as needed.

## Testing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for setup instructions.

## Architecture

See the presentation at Golang Estonia, [PGX Top to Bottom](https://www.youtube.com/watch?v=sXMSWhcHCf8) for a description of pgx architecture.

## Supported Go and PostgreSQL Versions

pgx supports the same versions of Go and PostgreSQL that are supported by their respective teams. For [Go](https://golang.org/doc/devel/release.html#policy) that is the two most recent major releases and for [PostgreSQL](https://www.postgresql.org/support/versioning/) the major releases in the last 5 years. This means pgx supports Go 1.23 and higher and PostgreSQL 13 and higher. pgx also is tested against the latest version of [CockroachDB](https://www.cockroachlabs.com/product/).

## Version Policy

pgx follows semantic versioning for the documented public API on stable releases. `v5` is the latest stable major version.

## PGX Family Libraries

### [github.com/jackc/pglogrepl](https://github.com/jackc/pglogrepl)

pglogrepl provides functionality to act as a client for PostgreSQL logical replication.

### [github.com/jackc/pgmock](https://github.com/jackc/pgmock)

pgmock offers the ability to create a server that mocks the PostgreSQL wire protocol. This is used internally to test pgx by purposely inducing unusual errors. pgproto3 and pgmock together provide most of the foundational tooling required to implement a PostgreSQL proxy or MitM (such as for a custom connection pooler).

### [github.com/jackc/tern](https://github.com/jackc/tern)

tern is a stand-alone SQL migration system.

### [github.com/jackc/pgerrcode](https://github.com/jackc/pgerrcode)

pgerrcode contains constants for the PostgreSQL error codes.

## Adapters for 3rd Party Types

* [github.com/jackc/pgx-gofrs-uuid](https://github.com/jackc/pgx-gofrs-uuid)
* [github.com/jackc/pgx-shopspring-decimal](https://github.com/jackc/pgx-shopspring-decimal)
* [github.com/twpayne/pgx-geos](https://github.com/twpayne/pgx-geos) ([PostGIS](https://postgis.net/) and [GEOS](https://libgeos.org/) via [go-geos](https://github.com/twpayne/go-geos))
* [github.com/vgarvardt/pgx-google-uuid](https://github.com/vgarvardt/pgx-google-uuid)


## Adapters for 3rd Party Tracers

* [github.com/jackhopner/pgx-xray-tracer](https://github.com/jackhopner/pgx-xray-tracer)
* [github.com/exaring/otelpgx](https://github.com/exaring/otelpgx)

## Adapters for 3rd Party Loggers

These adapters can be used with the tracelog package.

* [github.com/jackc/pgx-go-kit-log](https://github.com/jackc/pgx-go-kit-log)
* [github.com/jackc/pgx-log15](https://github.com/jackc/pgx-log15)
* [github.com/jackc/pgx-logrus](https://github.com/jackc/pgx-logrus)
* [github.com/jackc/pgx-zap](https://github.com/jackc/pgx-zap)
* [github.com/jackc/pgx-zerolog](https://github.com/jackc/pgx-zerolog)
* [github.com/mcosta74/pgx-slog](https://github.com/mcosta74/pgx-slog)
* [github.com/kataras/pgx-golog](https://github.com/kataras/pgx-golog)

## 3rd Party Libraries with PGX Support

### [github.com/pashagolub/pgxmock](https://github.com/pashagolub/pgxmock)

pgxmock is a mock library implementing pgx interfaces.
pgxmock has one and only purpose - to simulate pgx behavior in tests, without needing a real database connection.

### [github.com/georgysavva/scany](https://github.com/georgysavva/scany)

Library for scanning data from a database into Go structs and more.

### [github.com/vingarcia/ksql](https://github.com/vingarcia/ksql)

A carefully designed SQL client for making using SQL easier,
more productive, and less error-prone on Golang.

### [github.com/otan/gopgkrb5](https://github.com/otan/gopgkrb5)

Adds GSSAPI / Kerberos authentication support.

### [github.com/wcamarao/pmx](https://github.com/wcamarao/pmx)

Explicit data mapping and scanning library for Go structs and slices.

### [github.com/stephenafamo/scan](https://github.com/stephenafamo/scan)

Type safe and flexible package for scanning database data into Go types.
Supports, structs, maps, slices and custom mapping functions.

### [github.com/z0ne-dev/mgx](https://github.com/z0ne-dev/mgx)

Code first migration library for native pgx (no database/sql abstraction).

### [github.com/amirsalarsafaei/sqlc-pgx-monitoring](https://github.com/amirsalarsafaei/sqlc-pgx-monitoring)

A database monitoring/metrics library for pgx and sqlc. Trace, log and monitor your sqlc query performance using OpenTelemetry.

### [https://github.com/nikolayk812/pgx-outbox](https://github.com/nikolayk812/pgx-outbox)

Simple Golang implementation for transactional outbox pattern for PostgreSQL using jackc/pgx driver.

### [https://github.com/Arlandaren/pgxWrappy](https://github.com/Arlandaren/pgxWrappy)

Simplifies working with the pgx library, providing convenient scanning of nested structures.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grpc/grpc-go]]></title>
            <link>https://github.com/grpc/grpc-go</link>
            <guid>https://github.com/grpc/grpc-go</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[The Go language implementation of gRPC. HTTP/2 based RPC]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grpc/grpc-go">grpc/grpc-go</a></h1>
            <p>The Go language implementation of gRPC. HTTP/2 based RPC</p>
            <p>Language: Go</p>
            <p>Stars: 22,134</p>
            <p>Forks: 4,551</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># gRPC-Go

[![GoDoc](https://pkg.go.dev/badge/google.golang.org/grpc)][API]
[![GoReportCard](https://goreportcard.com/badge/grpc/grpc-go)](https://goreportcard.com/report/github.com/grpc/grpc-go)
[![codecov](https://codecov.io/gh/grpc/grpc-go/graph/badge.svg)](https://codecov.io/gh/grpc/grpc-go)

The [Go][] implementation of [gRPC][]: A high performance, open source, general
RPC framework that puts mobile and HTTP/2 first. For more information see the
[Go gRPC docs][], or jump directly into the [quick start][].

## Prerequisites

- **[Go][]**: any one of the **two latest major** [releases][go-releases].

## Installation

Simply add the following import to your code, and then `go [build|run|test]`
will automatically fetch the necessary dependencies:


```go
import &quot;google.golang.org/grpc&quot;
```

&gt; **Note:** If you are trying to access `grpc-go` from **China**, see the
&gt; [FAQ](#FAQ) below.

## Learn more

- [Go gRPC docs][], which include a [quick start][] and [API
  reference][API] among other resources
- [Low-level technical docs](Documentation) from this repository
- [Performance benchmark][]
- [Examples](examples)
- [Contribution guidelines](CONTRIBUTING.md)

## FAQ

### I/O Timeout Errors

The `golang.org` domain may be blocked from some countries. `go get` usually
produces an error like the following when this happens:

```console
$ go get -u google.golang.org/grpc
package google.golang.org/grpc: unrecognized import path &quot;google.golang.org/grpc&quot; (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)
```

To build Go code, there are several options:

- Set up a VPN and access google.golang.org through that.

- With Go module support: it is possible to use the `replace` feature of `go
  mod` to create aliases for golang.org packages.  In your project&#039;s directory:

  ```sh
  go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest
  go mod tidy
  go mod vendor
  go build -mod=vendor
  ```

  Again, this will need to be done for all transitive dependencies hosted on
  golang.org as well. For details, refer to [golang/go issue
  #28652](https://github.com/golang/go/issues/28652).

### Compiling error, undefined: grpc.SupportPackageIsVersion

Please update to the latest version of gRPC-Go using
`go get google.golang.org/grpc`.

### How to turn on logging

The default logger is controlled by environment variables. Turn everything on
like this:

```console
$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99
$ export GRPC_GO_LOG_SEVERITY_LEVEL=info
```

### The RPC failed with error `&quot;code = Unavailable desc = transport is closing&quot;`

This error means the connection the RPC is using was closed, and there are many
possible reasons, including:
 1. mis-configured transport credentials, connection failed on handshaking
 1. bytes disrupted, possibly by a proxy in between
 1. server shutdown
 1. Keepalive parameters caused connection shutdown, for example if you have
    configured your server to terminate connections regularly to [trigger DNS
    lookups](https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779).
    If this is the case, you may want to increase your
    [MaxConnectionAgeGrace](https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters),
    to allow longer RPC calls to finish.

It can be tricky to debug this because the error happens on the client side but
the root cause of the connection being closed is on the server side. Turn on
logging on __both client and server__, and see if there are any transport
errors.

[API]: https://pkg.go.dev/google.golang.org/grpc
[Go]: https://golang.org
[Go module]: https://github.com/golang/go/wiki/Modules
[gRPC]: https://grpc.io
[Go gRPC docs]: https://grpc.io/docs/languages/go
[Performance benchmark]: https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608
[quick start]: https://grpc.io/docs/languages/go/quickstart
[go-releases]: https://golang.org/doc/devel/release.html
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[juicedata/juicefs]]></title>
            <link>https://github.com/juicedata/juicefs</link>
            <guid>https://github.com/juicedata/juicefs</guid>
            <pubDate>Wed, 27 Aug 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[JuiceFS is a distributed POSIX file system built on top of Redis and S3.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/juicedata/juicefs">juicedata/juicefs</a></h1>
            <p>JuiceFS is a distributed POSIX file system built on top of Redis and S3.</p>
            <p>Language: Go</p>
            <p>Stars: 12,075</p>
            <p>Forks: 1,070</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/juicedata/juicefs&quot;&gt;&lt;img alt=&quot;JuiceFS Logo&quot; src=&quot;docs/en/images/juicefs-logo-new.svg&quot; width=&quot;50%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/juicedata/juicefs/releases/latest&quot;&gt;&lt;img alt=&quot;Latest Stable Release&quot; src=&quot;https://img.shields.io/github/v/release/juicedata/juicefs&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/juicedata/juicefs/actions/workflows/unittests.yml&quot;&gt;&lt;img alt=&quot;GitHub Workflow Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/unittests.yml?branch=main&amp;label=Unit%20Testing&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/juicedata/juicefs/actions/workflows/integrationtests.yml&quot;&gt;&lt;img alt=&quot;GitHub Workflow Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/integrationtests.yml?branch=main&amp;label=Integration%20Testing&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://goreportcard.com/report/github.com/juicedata/juicefs&quot;&gt;&lt;img alt=&quot;Go Report&quot; src=&quot;https://goreportcard.com/badge/github.com/juicedata/juicefs&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://juicefs.com/docs/community/introduction&quot;&gt;&lt;img alt=&quot;English doc&quot; src=&quot;https://img.shields.io/badge/docs-Doc%20Center-brightgreen&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://go.juicefs.com/slack&quot;&gt;&lt;img alt=&quot;Join Slack&quot; src=&quot;https://badgen.net/badge/Slack/Join%20JuiceFS/0abd59?icon=slack&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

**JuiceFS** is a high-performance [POSIX](https://en.wikipedia.org/wiki/POSIX) file system released under Apache License 2.0, particularly designed for the cloud-native environment. The data, stored via JuiceFS, will be persisted in Object Storage _(e.g. Amazon S3)_, and the corresponding metadata can be persisted in various compatible database engines such as Redis, MySQL, and TiKV based on the scenarios and requirements.

With JuiceFS, massive cloud storage can be directly connected to big data, machine learning, artificial intelligence, and various application platforms in production environments. Without modifying code, the massive cloud storage can be used as efficiently as local storage.

üìñ **Document**: [Quick Start Guide](https://juicefs.com/docs/community/quick_start_guide)

## Highlighted Features

1. **Fully POSIX-compatible**: Use as a local file system, seamlessly docking with existing applications without breaking business workflow.
2. **Fully Hadoop-compatible**: JuiceFS&#039; [Hadoop Java SDK](https://juicefs.com/docs/community/hadoop_java_sdk) is compatible with Hadoop 2.x and Hadoop 3.x as well as a variety of components in the Hadoop ecosystems.
3. **S3-compatible**:  JuiceFS&#039; [S3 Gateway](https://juicefs.com/docs/community/s3_gateway) provides an S3-compatible interface.
4. **Cloud Native**: A [Kubernetes CSI Driver](https://juicefs.com/docs/community/how_to_use_on_kubernetes) is provided for easily using JuiceFS in Kubernetes.
5. **Shareable**: JuiceFS is a shared file storage that can be read and written by thousands of clients.
6. **Strong Consistency**: The confirmed modification will be immediately visible on all the servers mounted with the same file system.
7. **Outstanding Performance**: The latency can be as low as a few milliseconds, and the throughput can be expanded nearly unlimitedly _(depending on the size of the Object Storage)_. [Test results](https://juicefs.com/docs/community/benchmark)
8. **Data Encryption**: Supports data encryption in transit and at rest (please refer to [the guide](https://juicefs.com/docs/community/security/encrypt) for more information).
9. **Global File Locks**: JuiceFS supports both BSD locks (flock) and POSIX record locks (fcntl).
10. **Data Compression**: JuiceFS supports [LZ4](https://lz4.github.io/lz4) or [Zstandard](https://facebook.github.io/zstd) to compress all your data.

---

[Architecture](#architecture) | [Getting Started](#getting-started) | [Advanced Topics](#advanced-topics) | [POSIX Compatibility](#posix-compatibility) | [Performance Benchmark](#performance-benchmark) | [Supported Object Storage](#supported-object-storage) | [Who is using](#who-is-using) | [Roadmap](#roadmap) | [Reporting Issues](#reporting-issues) | [Contributing](#contributing) | [Community](#community) | [Usage Tracking](#usage-tracking) | [License](#license) | [Credits](#credits) | [FAQ](#faq)

---

## Architecture

JuiceFS consists of three parts:

1. **JuiceFS Client**: Coordinates Object Storage and metadata storage engine as well as implementation of file system interfaces such as POSIX, Hadoop, Kubernetes, and S3 gateway.
2. **Data Storage**: Stores data, with supports of a variety of data storage media, e.g., local disk, public or private cloud Object Storage, and HDFS.
3. **Metadata Engine**: Stores the corresponding metadata that contains information of file name, file size, permission group, creation and modification time and directory structure, etc., with supports of different metadata engines, e.g., Redis, MySQL, SQLite and TiKV.

![JuiceFS Architecture](docs/en/images/juicefs-arch-new.png)

JuiceFS can store the metadata of file system on different metadata engines, like Redis, which is a fast, open-source, in-memory key-value data storage, particularly suitable for storing metadata; meanwhile, all the data will be stored in Object Storage through JuiceFS client. [Learn more](https://juicefs.com/docs/community/architecture)

![data-structure-diagram](docs/en/images/data-structure-diagram.svg)

Each file stored in JuiceFS is split into **&quot;Chunk&quot;** s at a fixed size with the default upper limit of 64 MiB. Each Chunk is composed of one or more **&quot;Slice&quot;**(s), and the length of the slice varies depending on how the file is written. Each slice is composed of size-fixed **&quot;Block&quot;** s, which are 4 MiB by default. These blocks will be stored in Object Storage in the end; at the same time, the metadata information of the file and its Chunks, Slices, and Blocks will be stored in metadata engines via JuiceFS. [Learn more](https://juicefs.com/docs/community/architecture/#how-juicefs-store-files)

![How JuiceFS stores your files](docs/en/images/how-juicefs-stores-files.svg)

When using JuiceFS, files will eventually be split into Chunks, Slices and Blocks and stored in Object Storage. Therefore, the source files stored in JuiceFS cannot be found in the file browser of the Object Storage platform; instead, there are only a chunks directory and a bunch of digitally numbered directories and files in the bucket. Don&#039;t panic! This is just the secret of the high-performance operation of JuiceFS!

## Getting Started

Before you begin, make sure you have:

1. One supported metadata engine, see [How to Set Up Metadata Engine](https://juicefs.com/docs/community/databases_for_metadata)
2. One supported Object Storage for storing data blocks, see [Supported Object Storage](https://juicefs.com/docs/community/how_to_setup_object_storage)
3. [JuiceFS Client](https://juicefs.com/docs/community/installation) downloaded and installed

Please refer to [Quick Start Guide](https://juicefs.com/docs/community/quick_start_guide) to start using JuiceFS right away!

### Command Reference

Check out all the command line options in [command reference](https://juicefs.com/docs/community/command_reference).

### Containers

JuiceFS can be used as a persistent volume for Docker and Podman, please check [here](https://juicefs.com/docs/community/juicefs_on_docker) for details.

### Kubernetes

It is also very easy to use JuiceFS on Kubernetes. Please find more information [here](https://juicefs.com/docs/community/how_to_use_on_kubernetes).

### Hadoop Java SDK

If you wanna use JuiceFS in Hadoop, check [Hadoop Java SDK](https://juicefs.com/docs/community/hadoop_java_sdk).

## Advanced Topics

- [Redis Best Practices](https://juicefs.com/docs/community/redis_best_practices)
- [How to Setup Object Storage](https://juicefs.com/docs/community/how_to_setup_object_storage)
- [Cache](https://juicefs.com/docs/community/cache)
- [Fault Diagnosis and Analysis](https://juicefs.com/docs/community/fault_diagnosis_and_analysis)
- [FUSE Mount Options](https://juicefs.com/docs/community/fuse_mount_options)
- [Using JuiceFS on Windows](https://juicefs.com/docs/community/installation#windows)
- [S3 Gateway](https://juicefs.com/docs/community/s3_gateway)

Please refer to [JuiceFS Document Center](https://juicefs.com/docs/community/introduction) for more information.

## POSIX Compatibility

JuiceFS has passed all of the compatibility tests (8813 in total) in the latest [pjdfstest](https://github.com/pjd/pjdfstest) .

```
All tests successful.

Test Summary Report
-------------------
/root/soft/pjdfstest/tests/chown/00.t          (Wstat: 0 Tests: 1323 Failed: 0)
  TODO passed:   693, 697, 708-709, 714-715, 729, 733
Files=235, Tests=8813, 233 wallclock secs ( 2.77 usr  0.38 sys +  2.57 cusr  3.93 csys =  9.65 CPU)
Result: PASS
```

Aside from the POSIX features covered by pjdfstest, JuiceFS also provides:

- **Close-to-open consistency**. Once a file is written _and_ closed, it is guaranteed to view the written data in the following opens and reads from any client. Within the same mount point, all the written data can be read immediately.
- Rename and all other metadata operations are atomic, which are guaranteed by supported metadata engine transaction.
- Opened files remain accessible after unlink from same mount point.
- Mmap (tested with FSx).
- Fallocate with punch hole support.
- Extended attributes (xattr).
- BSD locks (flock).
- POSIX record locks (fcntl).

## Performance Benchmark

### Basic benchmark

JuiceFS provides a subcommand that can run a few basic benchmarks to help you understand how it works in your environment:

![JuiceFS Bench](docs/en/images/juicefs-bench.png)

### Throughput

A sequential read/write benchmark has also been performed on JuiceFS, [EFS](https://aws.amazon.com/efs) and [S3FS](https://github.com/s3fs-fuse/s3fs-fuse) by [fio](https://github.com/axboe/fio).

![Sequential Read Write Benchmark](docs/en/images/sequential-read-write-benchmark.svg)

Above result figure shows that JuiceFS can provide 10X more throughput than the other two (see [more details](https://juicefs.com/docs/community/fio)).

### Metadata IOPS

A simple mdtest benchmark has been performed on JuiceFS, [EFS](https://aws.amazon.com/efs) and [S3FS](https://github.com/s3fs-fuse/s3fs-fuse) by [mdtest](https://github.com/hpc/ior).

![Metadata Benchmark](docs/en/images/metadata-benchmark.svg)

The result shows that JuiceFS can provide significantly more metadata IOPS than the other two (see [more details](https://juicefs.com/docs/community/mdtest)).

### Analyze performance

See [Real-Time Performance Monitoring](https://juicefs.com/docs/community/fault_diagnosis_and_analysis#performance-monitor) if you encountered performance issues.

## Supported Object Storage

- Amazon S3 _(and other S3 compatible Object Storage services)_
- Google Cloud Storage
- Azure Blob Storage
- Alibaba Cloud Object Storage Service (OSS)
- Tencent Cloud Object Storage (COS)
- Qiniu Cloud Object Storage (Kodo)
- QingStor Object Storage
- Ceph RGW
- MinIO
- Local disk
- Redis
- ...

JuiceFS supports numerous Object Storage services. [Learn more](https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage).

## Who is using

JuiceFS is production ready and used by thousands of machines in production. A list of users has been assembled and documented [here](https://juicefs.com/docs/community/adopters). In addition JuiceFS has several collaborative projects that integrate with other open source projects, which we have documented [here](https://juicefs.com/docs/community/integrations). If you are also using JuiceFS, please feel free to let us know, and you are welcome to share your specific experience with everyone.

The storage format is stable, and will be supported by all future releases.

## Roadmap

- User and group quotas
- Snapshots
- Write once read many (WORM)

## Reporting Issues

We use [GitHub Issues](https://github.com/juicedata/juicefs/issues) to track community reported issues. You can also [contact](#community) the community for any questions.

## Contributing

Thank you for your contribution! Please refer to the [JuiceFS Contributing Guide](https://juicefs.com/docs/community/development/contributing_guide) for more information.

## Community

Welcome to join the [Discussions](https://github.com/juicedata/juicefs/discussions) and the [Slack channel](https://go.juicefs.com/slack) to connect with JuiceFS team members and other users.

## Usage Tracking

JuiceFS collects **anonymous** usage data by default to help us better understand how the community is using JuiceFS. Only core metrics (e.g. version number) will be reported, and user data and any other sensitive data will not be included. The related code can be viewed [here](pkg/usage/usage.go).

You could also disable reporting easily by command line option `--no-usage-report`:

```bash
juicefs mount --no-usage-report
```

## License

JuiceFS is open-sourced under Apache License 2.0, see [LICENSE](LICENSE).

## Credits

The design of JuiceFS was inspired by [Google File System](https://research.google/pubs/pub51), [HDFS](https://hadoop.apache.org) and [MooseFS](https://moosefs.com). Thanks for their great work!

## FAQ

### Why doesn&#039;t JuiceFS support XXX Object Storage?

JuiceFS supports many Object Storage services. Please check out [this list](https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage) first. If the Object Storage you want to use is compatible with S3, you could treat it as S3. Otherwise, try reporting any issue.

### Can I use Redis Cluster as metadata engine?

Yes. Since [v1.0.0 Beta3](https://github.com/juicedata/juicefs/releases/tag/v1.0.0-beta3) JuiceFS supports the use of [Redis Cluster](https://redis.io/docs/manual/scaling) as the metadata engine, but it should be noted that Redis Cluster requires that the keys of all operations in a transaction must be in the same hash slot, so a JuiceFS file system can only use one hash slot.

See [&quot;Redis Best Practices&quot;](https://juicefs.com/docs/community/redis_best_practices) for more information.

### What&#039;s the difference between JuiceFS and XXX?

See [&quot;Comparison with Others&quot;](https://juicefs.com/docs/community/comparison/juicefs_vs_alluxio) for more information.

For more FAQs, please see the [full list](https://juicefs.com/docs/community/faq).

## Stargazers over time

[![Star History Chart](https://api.star-history.com/svg?repos=juicedata/juicefs&amp;type=Date)](https://star-history.com/#juicedata/juicefs&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>