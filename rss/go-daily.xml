<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Sun, 22 Jun 2025 00:05:32 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[mudler/LocalAI]]></title>
            <link>https://github.com/mudler/LocalAI</link>
            <guid>https://github.com/mudler/LocalAI</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mudler/LocalAI">mudler/LocalAI</a></h1>
            <p>ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference</p>
            <p>Language: Go</p>
            <p>Stars: 33,351</p>
            <p>Forks: 2,567</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;img height=&quot;300&quot; src=&quot;./core/http/static/logo.png&quot;&gt; &lt;br&gt;
&lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/fork&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI forks&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/stargazers&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI stars&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/pulls&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI pull-requests&quot;/&gt;
&lt;/a&gt;
&lt;a href=&#039;https://github.com/go-skynet/LocalAI/releases&#039;&gt;
&lt;img src=&#039;https://img.shields.io/github/release/go-skynet/LocalAI?&amp;label=Latest&amp;style=for-the-badge&#039;&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://hub.docker.com/r/localai/localai&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker&quot; alt=&quot;LocalAI Docker hub&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;tag=latest&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/quay.io-images-important.svg?&quot; alt=&quot;LocalAI Quay.io&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://twitter.com/LocalAI_API&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white&amp;label=LocalAI_API&quot; alt=&quot;Follow LocalAI_API&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://discord.gg/uJAeKSAGDy&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://dcbadge.vercel.app/api/server/uJAeKSAGDy?style=flat-square&amp;theme=default-inverted&quot; alt=&quot;Join LocalAI Discord Community&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/5539&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/5539&quot; alt=&quot;mudler%2FLocalAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; :bulb: Get help - [‚ùìFAQ](https://localai.io/faq/) [üí≠Discussions](https://github.com/go-skynet/LocalAI/discussions) [:speech_balloon: Discord](https://discord.gg/uJAeKSAGDy) [:book: Documentation website](https://localai.io/)
&gt;
&gt; [üíª Quickstart](https://localai.io/basics/getting_started/) [üñºÔ∏è Models](https://models.localai.io/) [üöÄ Roadmap](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap) [ü•Ω Demo](https://demo.localai.io) [üåç Explorer](https://explorer.localai.io) [üõ´ Examples](https://github.com/mudler/LocalAI-examples) Try on 
[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;logo=telegram&amp;logoColor=white)](https://t.me/localaiofficial_bot)

[![tests](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml)[![Build and Release](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml)[![build container images](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml)[![Bump dependencies](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml)[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai)](https://artifacthub.io/packages/search?repo=localai)

**LocalAI** is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that&#039;s compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by [Ettore Di Giacinto](https://github.com/mudler).


## üìöüÜï Local Stack Family

üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:

&lt;table&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png&quot; width=&quot;300&quot; alt=&quot;LocalAGI Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI&#039;s Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png&quot; width=&quot;300&quot; alt=&quot;LocalRecall Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Screenshots


| Talk Interface | Generate Audio |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk](./docs/assets/images/screenshots/screenshot_tts.png) | ![Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low](./docs/assets/images/screenshots/screenshot_tts.png) |

| Models Overview | Generate Images |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-20 LocalAI - Models](./docs/assets/images/screenshots/screenshot_gallery.png) | ![Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev](./docs/assets/images/screenshots/screenshot_image.png) |

| Chat Interface | Home |
| --- | --- |
| ![Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5](./docs/assets/images/screenshots/screenshot_chat.png) | ![Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)](./docs/assets/images/screenshots/screenshot_home.png) |

| Login | Swarm |
| --- | --- |
|![Screenshot 2025-03-31 at 12-09-59 ](./docs/assets/images/screenshots/screenshot_login.png) | ![Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard](./docs/assets/images/screenshots/screenshot_p2p.png) |

## üíª Quickstart

Run the installer script:

```bash
# Basic installation
curl https://localai.io/install.sh | sh
```

For more installation options, see [Installer Options](https://localai.io/docs/advanced/installer/).

Or run with docker:

### CPU only image:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
```

### NVIDIA GPU Images:

```bash
# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# CUDA 11.7
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-11

# NVIDIA Jetson (L4T) ARM64
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64
```

### AMD GPU Images (ROCm):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
```

### Intel GPU Images (oneAPI):

```bash
# Intel GPU with FP16 support
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-intel-f16

# Intel GPU with FP32 support
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-intel-f32
```

### Vulkan GPU Images:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
```

### AIO Images (pre-downloaded models):

```bash
# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# NVIDIA CUDA 11 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-11

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel-f16

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
```

For more information about the AIO images and pre-downloaded models, see [Container Documentation](https://localai.io/basics/container/).

To load models:

```bash
# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
```

For more information, see [üíª Getting started](https://localai.io/basics/getting_started/index.html)

## üì∞ Latest project news

- June 2025: [Backend management](https://github.com/mudler/LocalAI/pull/5607) has been added. Attention: extras images are going to be deprecated from the next release! Read [the backend management PR](https://github.com/mudler/LocalAI/pull/5607).
- May 2025: [Audio input](https://github.com/mudler/LocalAI/pull/5466) and [Reranking](https://github.com/mudler/LocalAI/pull/5396) in llama.cpp backend, [Realtime API](https://github.com/mudler/LocalAI/pull/5392),  Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).
- May 2025: Important: image name changes [See release](https://github.com/mudler/LocalAI/releases/tag/v2.29.0)
- Apr 2025: Rebrand, WebUI enhancements
- Apr 2025: [LocalAGI](https://github.com/mudler/LocalAGI) and [LocalRecall](https://github.com/mudler/LocalRecall) join the LocalAI family stack.
- Apr 2025: WebUI overhaul, AIO images updates
- Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images
- Jan 2025: LocalAI model release: https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3, SANA support in diffusers: https://github.com/mudler/LocalAI/pull/4603
- Dec 2024: stablediffusion.cpp backend (ggml) added ( https://github.com/mudler/LocalAI/pull/4289 )
- Nov 2024: Bark.cpp backend added ( https://github.com/mudler/LocalAI/pull/4287 )
- Nov 2024: Voice activity detection models (**VAD**) added to the API: https://github.com/mudler/LocalAI/pull/4204
- Oct 2024: examples moved to [LocalAI-examples](https://github.com/mudler/LocalAI-examples)
- Aug 2024:  üÜï FLUX-1, [P2P Explorer](https://explorer.localai.io)
- July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: https://github.com/mudler/LocalAI/pull/2723. P2P Global community pools: https://github.com/mudler/LocalAI/issues/3113
- May 2024: üî•üî• Decentralized P2P llama.cpp:  https://github.com/mudler/LocalAI/pull/2343 (peer2peer llama.cpp!) üëâ Docs  https://localai.io/features/distribute/
- May 2024: üî•üî• Distributed inferencing: https://github.com/mudler/LocalAI/pull/2324
- April 2024: Reranker API: https://github.com/mudler/LocalAI/pull/2121

Roadmap items: [List of issues](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)

## üöÄ [Features](https://localai.io/features/)

- üìñ [Text generation with GPTs](https://localai.io/features/text-generation/) (`llama.cpp`, `transformers`, `vllm` ... [:book: and more](https://localai.io/model-compatibility/index.html#model-compatibility-table))
- üó£ [Text to Audio](https://localai.io/features/text-to-audio/)
- üîà [Audio to Text](https://localai.io/features/audio-to-text/) (Audio transcription with `whisper.cpp`)
- üé® [Image generation](https://localai.io/features/image-generation)
- üî• [OpenAI-alike tools API](https://localai.io/features/openai-functions/) 
- üß† [Embeddings generation for vector databases](https://localai.io/features/embeddings/)
- ‚úçÔ∏è [Constrained grammars](https://localai.io/features/constrained_grammars/)
- üñºÔ∏è [Download Models directly from Huggingface ](https://localai.io/models/)
- ü•Ω [Vision API](https://localai.io/features/gpt-vision/)
- üìà [Reranker API](https://localai.io/features/reranker/)
- üÜïüñß [P2P Inferencing](https://localai.io/features/distribute/)
- [Agentic capabilities](https://github.com/mudler/LocalAGI)
- üîä Voice activity detection (Silero-VAD support)
- üåç Integrated WebUI!


### üîó Community and integrations

Build and deploy custom containers:
- https://github.com/sozercan/aikit

WebUIs:
- https://github.com/Jirubizu/localai-admin
- https://github.com/go-skynet/LocalAI-frontend
- QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) https://github.com/reid41/QA-Pilot

Model galleries
- https://github.com/go-skynet/model-gallery

Other:
- Helm chart https://github.com/go-skynet/helm-charts
- VSCode extension https://github.com/badgooooor/localai-vscode-plugin
- Langchain: https://python.langchain.com/docs/integrations/providers/localai/
- Terminal utility https://github.com/djcopley/ShellOracle
- Local Smart assistant https://github.com/mudler/LocalAGI
- Home Assistant https://github.com/sammcj/homeassistant-localai / https://github.com/drndos/hass-openai-custom-conversation / https://github.com/valentinfrlch/ha-gpt4vision
- Discord bot https://github.com/mudler/LocalAGI/tree/main/examples/discord
- Slack bot https://github.com/mudler/LocalAGI/tree/main/examples/slack
- Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) https://github.com/reid41/shell-pilot
- Telegram bot https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot
- Another Telegram Bot https://github.com/JackBekket/Hellper
- Auto-documentation https://github.com/JackBekket/Reflexia
- Github bot which answer on issues, with code and documentation as context https://github.com/JackBekket/GitHelper
- Github Actions: https://github.com/marketplace/actions/start-localai
- Examples: https://github.com/mudler/LocalAI/tree/master/examples/
  

### üîó Resources

- [LLM finetuning guide](https://localai.io/docs/advanced/fine-tuning/)
- [How to build locally](https://localai.io/basics/build/index.html)
- [How to install in Kubernetes](https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes)
- [Projects integrating LocalAI](https://localai.io/docs/integrations/)
- [How tos section](https://io.midori-ai.xyz/howtos/) (curated by our community)

## :book: üé• [Media, Blogs, Social](https://localai.io/basics/news/#media-blogs-social)

- [Run Visual studio code with LocalAI (SUSE)](https://www.suse.com/c/running-ai-locally/)
- üÜï [Run LocalAI on Jetson Nano Devkit](https://mudler.pm/posts/local-ai-jetson-nano-devkit/)
- [Run LocalAI on AWS EKS with Pulumi](https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/)
- [Run LocalAI on AWS](https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance)
- [Create a slackbot for teams and OSS projects that answer to documentation](https://mudler.pm/posts/smart-slackbot-for-teams/)
- [LocalAI meets k8sgpt](https://www.youtube.com/watch?v=PKrDNuJ_dfE)
- [Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All](https://mudler.pm/posts/localai-question-answering/)
- [Tutorial to use k8sgpt with LocalAI](https://medium.com/@tyler_97636/k8sgpt-localai-unlock-kubernetes-superpowers-for-free-584790de9b65)

## Citation

If you utilize this repository, data in a downstream project, please consider citing it with:

```
@misc{localai,
  author = {Ettore Di Giacinto},
  title = {LocalAI: The free, Open source OpenAI alternative},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/go-skynet/LocalAI}},
```

## ‚ù§Ô∏è Sponsors

&gt; Do you find LocalAI useful?

Support the project by becoming [a backer or sponsor](https://github.com/sponsors/mudler). Your logo will show up here with a link to your website.

A huge thank you to our generous sponsors who support this project covering CI expenses, and our [Sponsor list](https://github.com/sponsors/mudler):

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.spectrocloud.com/&quot; target=&quot;blank&quot;&gt;
    &lt;img height=&quot;200&quot; src=&quot;https://github.com/user-attachments/assets/72eab1dd-8b93-4fc0-9ade-84db49f24962&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.premai.io/&quot; target=&quot;blank&quot;&gt;
    &lt;img height=&quot;200&quot; src=&quot;https://github.com/mudler/LocalAI/assets/2420543/42e4ca83-661e-4f79-8e46-ae43689683d6&quot;&gt; &lt;br&gt;
  &lt;/a&gt;
&lt;/p&gt;

## üåü Star history

[![LocalAI Star history Chart](https://api.star-history.com/svg?repos=go-skynet/LocalAI&amp;type=Date)](https://star-history.com/#go-skynet/LocalAI&amp;Date)

## üìñ License

LocalAI is a community-driven project created by [Ettore Di Giacinto](https://github.com/mudler/).

MIT - Author Ettore Di Giacinto &lt;mudler@localai.io&gt;

## üôá Acknowledgements

LocalAI couldn&#039;t have been built without the help of great software already available from the community. Thank you!

- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- https://github.com/tatsu-lab/stanford_alpaca
- https://github.com/cornelk/llama-go for the initial ideas
- https://github.com/antimatter15/alpaca.cpp
- https://github.com/EdVince/Stable-Diffusion-NCNN
- https://github.com/ggerganov/whisper.cpp
- https://github.com/rhasspy/piper

## ü§ó Contributors

This is a community project, a special thanks to our contributors! ü§ó
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=go-skynet/LocalAI&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[go-gorm/gorm]]></title>
            <link>https://github.com/go-gorm/gorm</link>
            <guid>https://github.com/go-gorm/gorm</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[The fantastic ORM library for Golang, aims to be developer friendly]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/go-gorm/gorm">go-gorm/gorm</a></h1>
            <p>The fantastic ORM library for Golang, aims to be developer friendly</p>
            <p>Language: Go</p>
            <p>Stars: 38,382</p>
            <p>Forks: 4,048</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># GORM

The fantastic ORM library for Golang, aims to be developer friendly.

[![go report card](https://goreportcard.com/badge/github.com/go-gorm/gorm &quot;go report card&quot;)](https://goreportcard.com/report/github.com/go-gorm/gorm)
[![test status](https://github.com/go-gorm/gorm/workflows/tests/badge.svg?branch=master &quot;test status&quot;)](https://github.com/go-gorm/gorm/actions)
[![MIT license](https://img.shields.io/badge/license-MIT-brightgreen.svg)](https://opensource.org/licenses/MIT)
[![Go.Dev reference](https://img.shields.io/badge/go.dev-reference-blue?logo=go&amp;logoColor=white)](https://pkg.go.dev/gorm.io/gorm?tab=doc)

## Overview

* Full-Featured ORM
* Associations (Has One, Has Many, Belongs To, Many To Many, Polymorphism, Single-table inheritance)
* Hooks (Before/After Create/Save/Update/Delete/Find)
* Eager loading with `Preload`, `Joins`
* Transactions, Nested Transactions, Save Point, RollbackTo to Saved Point
* Context, Prepared Statement Mode, DryRun Mode
* Batch Insert, FindInBatches, Find To Map
* SQL Builder, Upsert, Locking, Optimizer/Index/Comment Hints, NamedArg, Search/Update/Create with SQL Expr
* Composite Primary Key
* Auto Migrations
* Logger
* Extendable, flexible plugin API: Database Resolver (Multiple Databases, Read/Write Splitting) / Prometheus‚Ä¶
* Every feature comes with tests
* Developer Friendly

## Getting Started

* GORM Guides [https://gorm.io](https://gorm.io)
* Gen Guides [https://gorm.io/gen/index.html](https://gorm.io/gen/index.html)

## Contributing

[You can help to deliver a better GORM, check out things you can do](https://gorm.io/contribute.html)

## Contributors

[Thank you](https://github.com/go-gorm/gorm/graphs/contributors) for contributing to the GORM framework!

## License

¬© Jinzhu, 2013~time.Now

Released under the [MIT License](https://github.com/go-gorm/gorm/blob/master/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[go-gitea/gitea]]></title>
            <link>https://github.com/go-gitea/gitea</link>
            <guid>https://github.com/go-gitea/gitea</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[Git with a cup of tea! Painless self-hosted all-in-one software development service, including Git hosting, code review, team collaboration, package registry and CI/CD]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/go-gitea/gitea">go-gitea/gitea</a></h1>
            <p>Git with a cup of tea! Painless self-hosted all-in-one software development service, including Git hosting, code review, team collaboration, package registry and CI/CD</p>
            <p>Language: Go</p>
            <p>Stars: 49,160</p>
            <p>Forks: 5,866</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre># Gitea

[![](https://github.com/go-gitea/gitea/actions/workflows/release-nightly.yml/badge.svg?branch=main)](https://github.com/go-gitea/gitea/actions/workflows/release-nightly.yml?query=branch%3Amain &quot;Release Nightly&quot;)
[![](https://img.shields.io/discord/322538954119184384.svg?logo=discord&amp;logoColor=white&amp;label=Discord&amp;color=5865F2)](https://discord.gg/Gitea &quot;Join the Discord chat at https://discord.gg/Gitea&quot;)
[![](https://goreportcard.com/badge/code.gitea.io/gitea)](https://goreportcard.com/report/code.gitea.io/gitea &quot;Go Report Card&quot;)
[![](https://pkg.go.dev/badge/code.gitea.io/gitea?status.svg)](https://pkg.go.dev/code.gitea.io/gitea &quot;GoDoc&quot;)
[![](https://img.shields.io/github/release/go-gitea/gitea.svg)](https://github.com/go-gitea/gitea/releases/latest &quot;GitHub release&quot;)
[![](https://www.codetriage.com/go-gitea/gitea/badges/users.svg)](https://www.codetriage.com/go-gitea/gitea &quot;Help Contribute to Open Source&quot;)
[![](https://opencollective.com/gitea/tiers/backers/badge.svg?label=backers&amp;color=brightgreen)](https://opencollective.com/gitea &quot;Become a backer/sponsor of gitea&quot;)
[![](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT &quot;License: MIT&quot;)
[![Contribute with Gitpod](https://img.shields.io/badge/Contribute%20with-Gitpod-908a85?logo=gitpod&amp;color=green)](https://gitpod.io/#https://github.com/go-gitea/gitea)
[![](https://badges.crowdin.net/gitea/localized.svg)](https://translate.gitea.com &quot;Crowdin&quot;)

[ÁπÅÈ´î‰∏≠Êñá](./README.zh-tw.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-cn.md)

## Purpose

The goal of this project is to make the easiest, fastest, and most
painless way of setting up a self-hosted Git service.

As Gitea is written in Go, it works across **all** the platforms and
architectures that are supported by Go, including Linux, macOS, and
Windows on x86, amd64, ARM and PowerPC architectures.
This project has been
[forked](https://blog.gitea.com/welcome-to-gitea/) from
[Gogs](https://gogs.io) since November of 2016, but a lot has changed.

For online demonstrations, you can visit [demo.gitea.com](https://demo.gitea.com).

For accessing free Gitea service (with a limited number of repositories), you can visit [gitea.com](https://gitea.com/user/login).

To quickly deploy your own dedicated Gitea instance on Gitea Cloud, you can start a free trial at [cloud.gitea.com](https://cloud.gitea.com).

## Documentation

You can find comprehensive documentation on our official [documentation website](https://docs.gitea.com/).

It includes installation, administration, usage, development, contributing guides, and more to help you get started and explore all features effectively.

If you have any suggestions or would like to contribute to it, you can visit the [documentation repository](https://gitea.com/gitea/docs)

## Building

From the root of the source tree, run:

    TAGS=&quot;bindata&quot; make build

or if SQLite support is required:

    TAGS=&quot;bindata sqlite sqlite_unlock_notify&quot; make build

The `build` target is split into two sub-targets:

- `make backend` which requires [Go Stable](https://go.dev/dl/), the required version is defined in [go.mod](/go.mod).
- `make frontend` which requires [Node.js LTS](https://nodejs.org/en/download/) or greater.

Internet connectivity is required to download the go and npm modules. When building from the official source tarballs which include pre-built frontend files, the `frontend` target will not be triggered, making it possible to build without Node.js.

More info: https://docs.gitea.com/installation/install-from-source

## Using

After building, a binary file named `gitea` will be generated in the root of the source tree by default. To run it, use:

    ./gitea web

&gt; [!NOTE]
&gt; If you&#039;re interested in using our APIs, we have experimental support with [documentation](https://docs.gitea.com/api).

## Contributing

Expected workflow is: Fork -&gt; Patch -&gt; Push -&gt; Pull Request

&gt; [!NOTE]
&gt;
&gt; 1. **YOU MUST READ THE [CONTRIBUTORS GUIDE](CONTRIBUTING.md) BEFORE STARTING TO WORK ON A PULL REQUEST.**
&gt; 2. If you have found a vulnerability in the project, please write privately to **security@gitea.io**. Thanks!

## Translating

[![Crowdin](https://badges.crowdin.net/gitea/localized.svg)](https://translate.gitea.com)

Translations are done through [Crowdin](https://translate.gitea.com). If you want to translate to a new language ask one of the managers in the Crowdin project to add a new language there.

You can also just create an issue for adding a language or ask on discord on the #translation channel. If you need context or find some translation issues, you can leave a comment on the string or ask on Discord. For general translation questions there is a section in the docs. Currently a bit empty but we hope to fill it as questions pop up.

Get more information from [documentation](https://docs.gitea.com/contributing/localization).

## Official and Third-Party Projects

We provide an official [go-sdk](https://gitea.com/gitea/go-sdk), a CLI tool called [tea](https://gitea.com/gitea/tea) and an [action runner](https://gitea.com/gitea/act_runner) for Gitea Action.

We maintain a list of Gitea-related projects at [gitea/awesome-gitea](https://gitea.com/gitea/awesome-gitea), where you can discover more third-party projects, including SDKs, plugins, themes, and more.

## Communication

[![](https://img.shields.io/discord/322538954119184384.svg?logo=discord&amp;logoColor=white&amp;label=Discord&amp;color=5865F2)](https://discord.gg/Gitea &quot;Join the Discord chat at https://discord.gg/Gitea&quot;)

If you have questions that are not covered by the [documentation](https://docs.gitea.com/), you can get in contact with us on our [Discord server](https://discord.gg/Gitea) or create a post in the [discourse forum](https://forum.gitea.com/).

## Authors

- [Maintainers](https://github.com/orgs/go-gitea/people)
- [Contributors](https://github.com/go-gitea/gitea/graphs/contributors)
- [Translators](options/locale/TRANSLATORS)

## Backers

Thank you to all our backers! üôè [[Become a backer](https://opencollective.com/gitea#backer)]

&lt;a href=&quot;https://opencollective.com/gitea#backers&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/backers.svg?width=890&quot;&gt;&lt;/a&gt;

## Sponsors

Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [[Become a sponsor](https://opencollective.com/gitea#sponsor)]

&lt;a href=&quot;https://opencollective.com/gitea/sponsor/0/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/0/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/1/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/1/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/2/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/2/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/3/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/3/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/4/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/4/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/5/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/5/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/6/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/6/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/7/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/7/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/8/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/8/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/9/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/9/avatar.svg&quot;&gt;&lt;/a&gt;

## FAQ

**How do you pronounce Gitea?**

Gitea is pronounced [/…°…™‚Äôti:/](https://youtu.be/EM71-2uDAoY) as in &quot;gi-tea&quot; with a hard g.

**Why is this not hosted on a Gitea instance?**

We&#039;re [working on it](https://github.com/go-gitea/gitea/issues/1029).

**Where can I find the security patches?**

In the [release log](https://github.com/go-gitea/gitea/releases) or the [change log](https://github.com/go-gitea/gitea/blob/main/CHANGELOG.md), search for the keyword `SECURITY` to find the security patches.

## License

This project is licensed under the MIT License.
See the [LICENSE](https://github.com/go-gitea/gitea/blob/main/LICENSE) file
for the full license text.

## Further information

&lt;details&gt;
&lt;summary&gt;Looking for an overview of the interface? Check it out!&lt;/summary&gt;

### Login/Register Page

![Login](https://dl.gitea.com/screenshots/login.png)
![Register](https://dl.gitea.com/screenshots/register.png)

### User Dashboard

![Home](https://dl.gitea.com/screenshots/home.png)
![Issues](https://dl.gitea.com/screenshots/issues.png)
![Pull Requests](https://dl.gitea.com/screenshots/pull_requests.png)
![Milestones](https://dl.gitea.com/screenshots/milestones.png)

### User Profile

![Profile](https://dl.gitea.com/screenshots/user_profile.png)

### Explore

![Repos](https://dl.gitea.com/screenshots/explore_repos.png)
![Users](https://dl.gitea.com/screenshots/explore_users.png)
![Orgs](https://dl.gitea.com/screenshots/explore_orgs.png)

### Repository

![Home](https://dl.gitea.com/screenshots/repo_home.png)
![Commits](https://dl.gitea.com/screenshots/repo_commits.png)
![Branches](https://dl.gitea.com/screenshots/repo_branches.png)
![Labels](https://dl.gitea.com/screenshots/repo_labels.png)
![Milestones](https://dl.gitea.com/screenshots/repo_milestones.png)
![Releases](https://dl.gitea.com/screenshots/repo_releases.png)
![Tags](https://dl.gitea.com/screenshots/repo_tags.png)

#### Repository Issue

![List](https://dl.gitea.com/screenshots/repo_issues.png)
![Issue](https://dl.gitea.com/screenshots/repo_issue.png)

#### Repository Pull Requests

![List](https://dl.gitea.com/screenshots/repo_pull_requests.png)
![Pull Request](https://dl.gitea.com/screenshots/repo_pull_request.png)
![File](https://dl.gitea.com/screenshots/repo_pull_request_file.png)
![Commits](https://dl.gitea.com/screenshots/repo_pull_request_commits.png)

#### Repository Actions

![List](https://dl.gitea.com/screenshots/repo_actions.png)
![Details](https://dl.gitea.com/screenshots/repo_actions_run.png)

#### Repository Activity

![Activity](https://dl.gitea.com/screenshots/repo_activity.png)
![Contributors](https://dl.gitea.com/screenshots/repo_contributors.png)
![Code Frequency](https://dl.gitea.com/screenshots/repo_code_frequency.png)
![Recent Commits](https://dl.gitea.com/screenshots/repo_recent_commits.png)

### Organization

![Home](https://dl.gitea.com/screenshots/org_home.png)

&lt;/details&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ehang-io/nps]]></title>
            <link>https://github.com/ehang-io/nps</link>
            <guid>https://github.com/ehang-io/nps</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[‰∏ÄÊ¨æËΩªÈáèÁ∫ß„ÄÅÈ´òÊÄßËÉΩ„ÄÅÂäüËÉΩÂº∫Â§ßÁöÑÂÜÖÁΩëÁ©øÈÄè‰ª£ÁêÜÊúçÂä°Âô®„ÄÇÊîØÊåÅtcp„ÄÅudp„ÄÅsocks5„ÄÅhttpÁ≠âÂá†‰πéÊâÄÊúâÊµÅÈáèËΩ¨ÂèëÔºåÂèØÁî®Êù•ËÆøÈóÆÂÜÖÁΩëÁΩëÁ´ô„ÄÅÊú¨Âú∞ÊîØ‰ªòÊé•Âè£Ë∞ÉËØï„ÄÅsshËÆøÈóÆ„ÄÅËøúÁ®ãÊ°åÈù¢ÔºåÂÜÖÁΩëdnsËß£Êûê„ÄÅÂÜÖÁΩësocks5‰ª£ÁêÜÁ≠âÁ≠â‚Ä¶‚Ä¶ÔºåÂπ∂Â∏¶ÊúâÂäüËÉΩÂº∫Â§ßÁöÑwebÁÆ°ÁêÜÁ´Ø„ÄÇa lightweight, high-performance, powerful intranet penetration proxy server, with a powerful web management terminal.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ehang-io/nps">ehang-io/nps</a></h1>
            <p>‰∏ÄÊ¨æËΩªÈáèÁ∫ß„ÄÅÈ´òÊÄßËÉΩ„ÄÅÂäüËÉΩÂº∫Â§ßÁöÑÂÜÖÁΩëÁ©øÈÄè‰ª£ÁêÜÊúçÂä°Âô®„ÄÇÊîØÊåÅtcp„ÄÅudp„ÄÅsocks5„ÄÅhttpÁ≠âÂá†‰πéÊâÄÊúâÊµÅÈáèËΩ¨ÂèëÔºåÂèØÁî®Êù•ËÆøÈóÆÂÜÖÁΩëÁΩëÁ´ô„ÄÅÊú¨Âú∞ÊîØ‰ªòÊé•Âè£Ë∞ÉËØï„ÄÅsshËÆøÈóÆ„ÄÅËøúÁ®ãÊ°åÈù¢ÔºåÂÜÖÁΩëdnsËß£Êûê„ÄÅÂÜÖÁΩësocks5‰ª£ÁêÜÁ≠âÁ≠â‚Ä¶‚Ä¶ÔºåÂπ∂Â∏¶ÊúâÂäüËÉΩÂº∫Â§ßÁöÑwebÁÆ°ÁêÜÁ´Ø„ÄÇa lightweight, high-performance, powerful intranet penetration proxy server, with a powerful web management terminal.</p>
            <p>Language: Go</p>
            <p>Stars: 32,908</p>
            <p>Forks: 5,924</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>
# NPS
![](https://img.shields.io/github/stars/ehang-io/nps.svg)   ![](https://img.shields.io/github/forks/ehang-io/nps.svg)
[![Gitter](https://badges.gitter.im/cnlh-nps/community.svg)](https://gitter.im/cnlh-nps/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge)
![Release](https://github.com/ehang-io/nps/workflows/Release/badge.svg)
![GitHub All Releases](https://img.shields.io/github/downloads/ehang-io/nps/total)

[README](https://github.com/ehang-io/nps/blob/master/README.md)|[‰∏≠ÊñáÊñáÊ°£](https://github.com/ehang-io/nps/blob/master/README_zh.md)

NPS is a lightweight, high-performance, powerful **intranet penetration** proxy server, with a powerful web management terminal.


![image](https://github.com/ehang-io/nps/blob/master/image/web.png?raw=true)

## Feature

- Comprehensive protocol support, compatible with almost all commonly used protocols, such as tcp, udp, http(s), socks5, p2p, http proxy ...
- Full platform compatibility (linux, windows, macos, Synology, etc.), support installation as a system service simply.
- Comprehensive control, both client and server control are allowed.
- Https integration, support to convert backend proxy and web services to https, and support multiple certificates.
- Just simple configuration on web ui can complete most requirements.
- Complete information display, such as traffic, system information, real-time bandwidth, client version, etc.
- Powerful extension functions, everything is available (cache, compression, encryption, traffic limit, bandwidth limit, port reuse, etc.)
- Domain name resolution has functions such as custom headers, 404 page configuration, host modification, site protection, URL routing, and pan-resolution.
- Multi-user and user registration support on server.

**Didn&#039;t find the feature you want? It doesn&#039;t matter, click [Enter the document](https://ehang-io.github.io/nps/) to find it!**

## Quick start

### Installation

&gt; [releases](https://github.com/ehang-io/nps/releases)

Download the corresponding system version, the server and client are separate.

### Server start

After downloading the server compressed package, unzip it, and then enter the unzipped folder.

- execute installation command

For linux„ÄÅdarwin ```sudo ./nps install```

For windows, run cmd as administrator and enter the installation directory ```nps.exe install```

- default ports

The default configuration file of nps use 80Ôºå443Ôºå8080Ôºå8024 ports

80 and 443 ports for host mode default ports

8080 for web management access port

8024 for net bridge port, to communicate between server and client

- start up

For linux„ÄÅdarwin ```sudo nps start```

For windows, run cmd as administrator and enter the program directory ```nps.exe start```

```After installation, the windows configuration file is located at C:\Program Files\nps, linux or darwin is located at /etc/nps```

**If you don&#039;t find it started successfully, you can check the log (Windows log files are located in the current running directory, linux and darwin are located in /var/log/nps.log).**

- Access server IP:web service port (default is 8080).
- Login with username and password (default is admin/123, must be modified when officially used).
- Create a client.

### Client connection
- Click the + sign in front of the client in web management and copy the startup command.
- Execute the startup command, Linux can be executed directly, Windows will replace ./npc with npc.exe and execute it with cmd.


If you need to register to the system service, you can check [Register to the system service](https://ehang-io.github.io/nps/#/use?id=Ê≥®ÂÜåÂà∞Á≥ªÁªüÊúçÂä°)

### Configuration
- After the client connects, configure the corresponding penetration service in the web.
- For more advanced usage, see [Complete Documentation](https://ehang-io.github.io/nps/)

## Contribution
- If you encounter a bug, you can submit it to the dev branch directly.
- If you encounter a problem, you can feedback through the issue.
- The project is under development, and there is still a lot of room for improvement. If you can contribute code, please submit PR to the dev branch.
- If there is feedback on new features, you can feedback via issues or qq group.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grafana/loki]]></title>
            <link>https://github.com/grafana/loki</link>
            <guid>https://github.com/grafana/loki</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[Like Prometheus, but for logs.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grafana/loki">grafana/loki</a></h1>
            <p>Like Prometheus, but for logs.</p>
            <p>Language: Go</p>
            <p>Stars: 25,805</p>
            <p>Forks: 3,697</p>
            <p>Stars today: 102 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/sources/logo_and_name.png&quot; alt=&quot;Loki Logo&quot;&gt;&lt;/p&gt;

&lt;a href=&quot;https://github.com/grafana/loki/actions/workflows/check.yml&quot;&gt;&lt;img src=&quot;https://github.com/grafana/loki/actions/workflows/check.yml/badge.svg&quot; alt=&quot;Check&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://goreportcard.com/report/github.com/grafana/loki&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/grafana/loki&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://slack.grafana.com/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/join%20slack-%23loki-brightgreen.svg&quot; alt=&quot;Slack&quot; /&gt;&lt;/a&gt;
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/loki.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:loki)

# Loki: like Prometheus, but for logs.

Loki is a horizontally-scalable, highly-available, multi-tenant log aggregation system inspired by [Prometheus](https://prometheus.io/).
It is designed to be very cost effective and easy to operate.
It does not index the contents of the logs, but rather a set of labels for each log stream.

Compared to other log aggregation systems, Loki:

- does not do full text indexing on logs. By storing compressed, unstructured logs and only indexing metadata, Loki is simpler to operate and cheaper to run.
- indexes and groups log streams using the same labels you‚Äôre already using with Prometheus, enabling you to seamlessly switch between metrics and logs using the same labels that you‚Äôre already using with Prometheus.
- is an especially good fit for storing [Kubernetes](https://kubernetes.io/) Pod logs. Metadata such as Pod labels is automatically scraped and indexed.
- has native support in Grafana (needs Grafana v6.0).

A Loki-based logging stack consists of 3 components:

- [Alloy](https://github.com/grafana/alloy) is agent, responsible for gathering logs and sending them to Loki.
- [Loki](https://github.com/grafana/loki) is the main service, responsible for storing logs and processing queries.
- [Grafana](https://github.com/grafana/grafana) for querying and displaying the logs.

**Note that Alloy replaced Promtail in the stack, because Promtail is considered to be feature complete, and future development for logs collection will be in [Grafana Alloy](https://github.com/grafana/alloy).**

Loki is like Prometheus, but for logs: we prefer a multidimensional label-based approach to indexing, and want a single-binary, easy to operate system with no dependencies.
Loki differs from Prometheus by focusing on logs instead of metrics, and delivering logs via push, instead of pull.

## Getting started

* [Installing Loki](https://grafana.com/docs/loki/latest/installation/)
* [Installing Alloy](https://grafana.com/docs/loki/latest/send-data/alloy/)
* [Getting Started](https://grafana.com/docs/loki/latest/get-started/)

## Upgrading

* [Upgrading Loki](https://grafana.com/docs/loki/latest/upgrading/)

## Documentation

* [Latest release](https://grafana.com/docs/loki/latest/)
* [Upcoming release](https://grafana.com/docs/loki/next/), at the tip of the main branch

Commonly used sections:

- [API documentation](https://grafana.com/docs/loki/latest/api/) for getting logs into Loki.
- [Labels](https://grafana.com/docs/loki/latest/getting-started/labels/)
- [Operations](https://grafana.com/docs/loki/latest/operations/)
- [Promtail](https://grafana.com/docs/loki/latest/clients/promtail/) is an agent which tails log files and pushes them to Loki.
- [Pipelines](https://grafana.com/docs/loki/latest/clients/promtail/pipelines/) details the log processing pipeline.
- [Docker Driver Client](https://grafana.com/docs/loki/latest/clients/docker-driver/) is a Docker plugin to send logs directly to Loki from Docker containers.
- [LogCLI](https://grafana.com/docs/loki/latest/query/logcli/) provides a command-line interface for querying logs.
- [Loki Canary](https://grafana.com/docs/loki/latest/operations/loki-canary/) monitors your Loki installation for missing logs.
- [Troubleshooting](https://grafana.com/docs/loki/latest/operations/troubleshooting/) presents help dealing with error messages.
- [Loki in Grafana](https://grafana.com/docs/loki/latest/operations/grafana/) describes how to set up a Loki datasource in Grafana.

## Getting Help

If you have any questions or feedback regarding Loki:

- Search existing thread in the Grafana Labs community forum for Loki: [https://community.grafana.com](https://community.grafana.com/c/grafana-loki/)
- Ask a question on the Loki Slack channel. To invite yourself to the Grafana Slack, visit [https://slack.grafana.com/](https://slack.grafana.com/) and join the #loki channel.
- [File an issue](https://github.com/grafana/loki/issues/new) for bugs, issues and feature suggestions.
- Send an email to [lokiproject@googlegroups.com](mailto:lokiproject@googlegroups.com), or use the [web interface](https://groups.google.com/forum/#!forum/lokiproject).
- UI issues should be filed directly in [Grafana](https://github.com/grafana/grafana/issues/new).

Your feedback is always welcome.

## Further Reading

- The original [design doc](https://docs.google.com/document/d/11tjK_lvp1-SVsFZjgOTr1vV3-q6vBAsZYIQ5ZeYBkyM/view) for Loki is a good source for discussion of the motivation and design decisions.
- Callum Styan&#039;s March 2019 DevOpsDays Vancouver talk &quot;[Grafana Loki: Log Aggregation for Incident Investigations][devopsdays19-talk]&quot;.
- Grafana Labs blog post &quot;[How We Designed Loki to Work Easily Both as Microservices and as Monoliths][architecture-blog]&quot;.
- Tom Wilkie&#039;s early-2019 CNCF Paris/FOSDEM talk &quot;[Grafana Loki: like Prometheus, but for logs][fosdem19-talk]&quot; ([slides][fosdem19-slides], [video][fosdem19-video]).
- David Kaltschmidt&#039;s KubeCon 2018 talk &quot;[On the OSS Path to Full Observability with Grafana][kccna18-event]&quot; ([slides][kccna18-slides], [video][kccna18-video]) on how Loki fits into a cloud-native environment.
- Goutham Veeramachaneni&#039;s blog post &quot;[Loki: Prometheus-inspired, open source logging for cloud natives](https://grafana.com/blog/2018/12/12/loki-prometheus-inspired-open-source-logging-for-cloud-natives/)&quot; on details of the Loki architecture.
- David Kaltschmidt&#039;s blog post &quot;[Closer look at Grafana&#039;s user interface for Loki](https://grafana.com/blog/2019/01/02/closer-look-at-grafanas-user-interface-for-loki/)&quot; on the ideas that went into the logging user interface.

[devopsdays19-talk]: https://grafana.com/blog/2019/05/06/how-loki-correlates-metrics-and-logs--and-saves-you-money/
[architecture-blog]: https://grafana.com/blog/2019/04/15/how-we-designed-loki-to-work-easily-both-as-microservices-and-as-monoliths/
[fosdem19-talk]: https://fosdem.org/2019/schedule/event/loki_prometheus_for_logs/
[fosdem19-slides]: https://speakerdeck.com/grafana/grafana-loki-like-prometheus-but-for-logs
[fosdem19-video]: https://mirror.as35701.net/video.fosdem.org/2019/UB2.252A/loki_prometheus_for_logs.mp4
[kccna18-event]: https://kccna18.sched.com/event/GrXC/on-the-oss-path-to-full-observability-with-grafana-david-kaltschmidt-grafana-labs
[kccna18-slides]: https://speakerdeck.com/davkal/on-the-path-to-full-observability-with-oss-and-launch-of-loki
[kccna18-video]: https://www.youtube.com/watch?v=U7C5SpRtK74&amp;list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU&amp;index=346

## Contributing

Refer to [CONTRIBUTING.md](CONTRIBUTING.md)

### Building from source

Loki can be run in a single host, no-dependencies mode using the following commands.

You need an up-to-date version of [Go](https://go.dev/), we recommend using the version found in our [Makefile](https://github.com/grafana/loki/blob/main/Makefile)

```bash
# Checkout source code
$ git clone https://github.com/grafana/loki
$ cd loki

# Build binary
$ go build ./cmd/loki

# Run executable
$ ./loki -config.file=./cmd/loki/loki-local-config.yaml
```

Alternatively, on Unix systems you can use `make` to build the binary, which adds additional arguments to the `go build` command.

```bash
# Build binary
$ make loki

# Run executable
$ ./cmd/loki/loki -config.file=./cmd/loki/loki-local-config.yaml
```

To build Promtail on non-Linux platforms, use the following command:

```bash
$ go build ./clients/cmd/promtail
```

On Linux, Promtail requires the systemd headers to be installed if
Journal support is enabled.
To enable Journal support the go build tag flag `promtail_journal_enabled` should be passed

With Journal support on Ubuntu, run with the following commands:

```bash
$ sudo apt install -y libsystemd-dev
$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail
```

With Journal support on CentOS, run with the following commands:

```bash
$ sudo yum install -y systemd-devel
$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail
```

Otherwise, to build Promtail without Journal support, run `go build`
with CGO disabled:

```bash
$ CGO_ENABLED=0 go build ./clients/cmd/promtail
```

## Adopters

Please see [ADOPTERS.md](ADOPTERS.md) for some of the organizations using Loki today.
If you would like to add your organization to the list, please open a PR to add it to the list.

## License

Grafana Loki is distributed under [AGPL-3.0-only](LICENSE). For Apache-2.0 exceptions, see [LICENSING.md](LICENSING.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[php/frankenphp]]></title>
            <link>https://github.com/php/frankenphp</link>
            <guid>https://github.com/php/frankenphp</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[üßü The modern PHP app server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/php/frankenphp">php/frankenphp</a></h1>
            <p>üßü The modern PHP app server</p>
            <p>Language: Go</p>
            <p>Stars: 9,019</p>
            <p>Forks: 335</p>
            <p>Stars today: 118 stars today</p>
            <h2>README</h2><pre># FrankenPHP: Modern App Server for PHP

&lt;h1 align=&quot;center&quot;&gt;&lt;a href=&quot;https://frankenphp.dev&quot;&gt;&lt;img src=&quot;frankenphp.png&quot; alt=&quot;FrankenPHP&quot; width=&quot;600&quot;&gt;&lt;/a&gt;&lt;/h1&gt;

FrankenPHP is a modern application server for PHP built on top of the [Caddy](https://caddyserver.com/) web server.

FrankenPHP gives superpowers to your PHP apps thanks to its stunning features: [_Early Hints_](https://frankenphp.dev/docs/early-hints/), [worker mode](https://frankenphp.dev/docs/worker/), [real-time capabilities](https://frankenphp.dev/docs/mercure/), automatic HTTPS, HTTP/2, and HTTP/3 support...

FrankenPHP works with any PHP app and makes your Laravel and Symfony projects faster than ever thanks to their official integrations with the worker mode.

FrankenPHP can also be used as a standalone Go library to embed PHP in any app using `net/http`.

[**Learn more** on _frankenphp.dev_](https://frankenphp.dev) and in this slide deck:

&lt;a href=&quot;https://dunglas.dev/2022/10/frankenphp-the-modern-php-app-server-written-in-go/&quot;&gt;&lt;img src=&quot;https://dunglas.dev/wp-content/uploads/2022/10/frankenphp.png&quot; alt=&quot;Slides&quot; width=&quot;600&quot;&gt;&lt;/a&gt;

## Getting Started

### Standalone Binary

We provide static FrankenPHP binaries for Linux and macOS
containing [PHP 8.4](https://www.php.net/releases/8.4/en.php) and most popular PHP extensions.

On Windows, use [WSL](https://learn.microsoft.com/windows/wsl/) to run FrankenPHP.

[Download FrankenPHP](https://github.com/dunglas/frankenphp/releases) or copy this line into your
terminal to automatically install the version appropriate for your platform:

```console
curl https://frankenphp.dev/install.sh | sh
mv frankenphp /usr/local/bin/
```

To serve the content of the current directory, run:

```console
frankenphp php-server
```

You can also run command-line scripts with:

```console
frankenphp php-cli /path/to/your/script.php
```

### Docker

Alternatively, [Docker images](https://frankenphp.dev/docs/docker/) are available:

```console
docker run -v .:/app/public \
    -p 80:80 -p 443:443 -p 443:443/udp \
    dunglas/frankenphp
```

Go to `https://localhost`, and enjoy!

&gt; [!TIP]
&gt;
&gt; Do not attempt to use `https://127.0.0.1`. Use `https://localhost` and accept the self-signed certificate.
&gt; Use the [`SERVER_NAME` environment variable](docs/config.md#environment-variables) to change the domain to use.

### Homebrew

FrankenPHP is also available as a [Homebrew](https://brew.sh) package for macOS and Linux.

To install it:

```console
brew install dunglas/frankenphp/frankenphp
```

To serve the content of the current directory, run:

```console
frankenphp php-server
```

## Docs

- [Classic mode](https://frankenphp.dev/docs/classic/)
- [Worker mode](https://frankenphp.dev/docs/worker/)
- [Early Hints support (103 HTTP status code)](https://frankenphp.dev/docs/early-hints/)
- [Real-time](https://frankenphp.dev/docs/mercure/)
- [Efficiently Serving Large Static Files](https://frankenphp.dev/docs/x-sendfile/)
- [Configuration](https://frankenphp.dev/docs/config/)
- [Docker images](https://frankenphp.dev/docs/docker/)
- [Deploy in production](https://frankenphp.dev/docs/production/)
- [Performance optimization](https://frankenphp.dev/docs/performance/)
- [Create **standalone**, self-executable PHP apps](https://frankenphp.dev/docs/embed/)
- [Create static binaries](https://frankenphp.dev/docs/static/)
- [Compile from sources](https://frankenphp.dev/docs/compile/)
- [Monitoring FrankenPHP](https://frankenphp.dev/docs/metrics/)
- [Laravel integration](https://frankenphp.dev/docs/laravel/)
- [Known issues](https://frankenphp.dev/docs/known-issues/)
- [Demo app (Symfony) and benchmarks](https://github.com/dunglas/frankenphp-demo)
- [Go library documentation](https://pkg.go.dev/github.com/dunglas/frankenphp)
- [Contributing and debugging](https://frankenphp.dev/docs/contributing/)

## Examples and Skeletons

- [Symfony](https://github.com/dunglas/symfony-docker)
- [API Platform](https://api-platform.com/docs/symfony)
- [Laravel](https://frankenphp.dev/docs/laravel/)
- [Sulu](https://sulu.io/blog/running-sulu-with-frankenphp)
- [WordPress](https://github.com/StephenMiracle/frankenwp)
- [Drupal](https://github.com/dunglas/frankenphp-drupal)
- [Joomla](https://github.com/alexandreelise/frankenphp-joomla)
- [TYPO3](https://github.com/ochorocho/franken-typo3)
- [Magento2](https://github.com/ekino/frankenphp-magento2)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kopia/kopia]]></title>
            <link>https://github.com/kopia/kopia</link>
            <guid>https://github.com/kopia/kopia</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[Cross-platform backup tool for Windows, macOS & Linux with fast, incremental backups, client-side end-to-end encryption, compression and data deduplication. CLI and GUI included.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kopia/kopia">kopia/kopia</a></h1>
            <p>Cross-platform backup tool for Windows, macOS & Linux with fast, incremental backups, client-side end-to-end encryption, compression and data deduplication. CLI and GUI included.</p>
            <p>Language: Go</p>
            <p>Stars: 9,888</p>
            <p>Forks: 483</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>Kopia
=====

![Kopia](icons/kopia.svg)
[![Build Status](https://github.com/kopia/kopia/workflows/Build/badge.svg)](https://github.com/kopia/kopia/actions?query=workflow%3ABuild)
[![Slack](https://img.shields.io/badge/discuss-slack-blue.svg)](https://slack.kopia.io/) 
[![GoDoc](https://godoc.org/github.com/kopia/kopia/repo?status.svg)](https://godoc.org/github.com/kopia/kopia/repo)
[![Coverage Status](https://codecov.io/gh/kopia/kopia/branch/master/graph/badge.svg?token=CRK4RMRFSH)](https://codecov.io/gh/kopia/kopia)[![Go Report Card](https://goreportcard.com/badge/github.com/kopia/kopia)](https://goreportcard.com/report/github.com/kopia/kopia)
[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg)](CODE_OF_CONDUCT.md)
[![Docker Pulls](https://img.shields.io/docker/pulls/kopia/kopia)](https://hub.docker.com/r/kopia/kopia/tags?page=1&amp;ordering=name)
[![Downloads](https://img.shields.io/github/downloads/kopia/kopia/total.svg)](https://github.com/kopia/kopia/releases)
[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Kopia%20Guru-006BFF)](https://gurubase.io/g/kopia)

&gt; _n._
&gt;
&gt; 1. _[copy, replica](https://en.wikipedia.org/wiki/Replica) (Polish)_
&gt; 2. _[lance, spear](https://en.wikipedia.org/wiki/Kopia)_
&gt; 3. _[fast and secure backup tool](https://kopia.io)_


Kopia is a fast and secure open-source backup/restore tool that allows you to create [encrypted](https://kopia.io/docs/features/#end-to-end-zero-knowledge-encryption) snapshots of your data and save the snapshots to [remote or cloud storage](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage) of your choice, [to network-attached storage or server](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage), or [locally on your machine](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage). Kopia does not &#039;image&#039; your whole machine. Rather, Kopia allows you to backup/restore any and all files/directories that you deem are important or critical.

Kopia has both [CLI (command-line interface)](https://kopia.io/docs/features/#both-command-line-and-graphical-user-interfaces) and [GUI (graphical user interface)](https://kopia.io/docs/features/#both-command-line-and-graphical-user-interfaces) versions, making it the perfect tool for both advanced and regular users. You can read more about Kopia&#039;s unique [features](https://kopia.io/docs/features/) -- which include [compression](https://kopia.io/docs/features/#compression), [deduplication](https://kopia.io/docs/features/#backup-files-and-directories-using-snapshots), [end-to-end &#039;zero knowledge&#039; encryption](https://kopia.io/docs/features/#end-to-end-zero-knowledge-encryption), and [error correction](https://kopia.io/docs/features/#error-correction) -- to get a better understanding of how Kopia works.

When ready, head to the [installation](https://kopia.io/docs/installation/) page to download and install Kopia, and make sure to read the [Getting Started Guide](https://kopia.io/docs/getting-started/) for a step-by-step walkthrough of how to use Kopia.

Pick the Cloud Storage Provider You Want
---

Kopia supports saving your [encrypted](https://kopia.io/docs/features/#end-to-end-zero-knowledge-encryption) and [compressed](https://kopia.io/docs/features/#compression) snapshots to all of the following [storage locations](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage):

* **Amazon S3** and any **cloud storage that is compatible with S3**
* **Azure Blob Storage**
* **Backblaze B2**
* **Google Cloud Storage**
* Any remote server or cloud storage that supports **WebDAV**
* Any remote server or cloud storage that supports **SFTP**
* Some of the cloud storage options supported by **Rclone**
  * Requires you to download and setup Rclone in addition to Kopia, but after that Kopia manages/runs Rclone for you
  * Rclone support is experimental: not all the cloud storage products supported by Rclone have been tested to work with Kopia, and some may not work with Kopia; Kopia has been tested to work with **Dropbox**, **OneDrive**, and **Google Drive** through Rclone
* Your local machine and any network-attached storage or server
* Your own server by setting up a [Kopia Repository Server](https://kopia.io/docs/repository-server/)

And Kopia uses [data deduplication](https://kopia.io/docs/features/#backup-files-and-directories-using-snapshots) to save you money! Read the [repositories help page](https://kopia.io/docs/repositories/) for more information on supported storage locations.

With Kopia you are in full control of where to store your snapshots, that is, you pick the storage provider you want to use. You must provision and pay for the storage provider for whatever storage locations you want to use, and then tell Kopia what those storage locations are. You can even use multiple storage locations for different backup repositories if you want. Kopia also supports backing up multiple machines to the same storage location.

Kopia in Action
---

Using Kopia via command-line interface:

[![asciicast](https://asciinema.org/a/ykx6uzEhKY3451fWEnX9nm9uo.svg)](https://asciinema.org/a/ykx6uzEhKY3451fWEnX9nm9uo)

Using Kopia via graphical user interface (note: the video is of an older version of Kopia and the interface is different in the current version of Kopia, but the main principles of the interface are the same):

[![Kopia UI Tutorial](https://img.youtube.com/vi/sHJjSpasWIo/0.jpg)](https://www.youtube.com/watch?v=sHJjSpasWIo)

Getting Started
---
See [Kopia Documentation](https://kopia.io/docs/) for more information.

Building Kopia
---
See [Build Infrastructure](BUILD.md) for more information on building Kopia and working with the source code.

Licensing
---
Kopia is licensed under the Apache License, Version 2.0. See [LICENSE](LICENSE) for the full license text.

Contribution Guidelines
---
Kopia is open source and contributions are welcome. For more information on how to contribute see the [Contribution Guidelines](https://kopia.io/docs/contribution-guidelines/).

Reporting Security Issues
---
If you find a security issue you&#039;d like to disclose privately, please contact `security@kopia.io` or via direct message to maintainers on [Slack](https://slack.kopia.io).

[![Netlify Status](https://api.netlify.com/api/v1/badges/6b5c1fe4-a0da-4e7e-939b-ff1105251985/deploy-status)](https://app.netlify.com/sites/kopia/deploys)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hashicorp/hcl]]></title>
            <link>https://github.com/hashicorp/hcl</link>
            <guid>https://github.com/hashicorp/hcl</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[HCL is the HashiCorp configuration language.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hashicorp/hcl">hashicorp/hcl</a></h1>
            <p>HCL is the HashiCorp configuration language.</p>
            <p>Language: Go</p>
            <p>Stars: 5,491</p>
            <p>Forks: 632</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># HCL

HCL is a toolkit for creating structured configuration languages that are
both human- and machine-friendly, for use with command-line tools.
Although intended to be generally useful, it is primarily targeted
towards devops tools, servers, etc.

&gt; **NOTE:** This is major version 2 of HCL, whose Go API is incompatible with
&gt; major version 1. Both versions are available for selection in Go Modules
&gt; projects. HCL 2 _cannot_ be imported from Go projects that are not using Go Modules. For more information, see
&gt; [our version selection guide](https://github.com/hashicorp/hcl/wiki/Version-Selection).

HCL has both a _native syntax_, intended to be pleasant to read and write for
humans, and a JSON-based variant that is easier for machines to generate
and parse.

The HCL native syntax is inspired by [libucl](https://github.com/vstakhov/libucl),
[nginx configuration](http://nginx.org/en/docs/beginners_guide.html#conf_structure),
and others.

It includes an expression syntax that allows basic inline computation and,
with support from the calling application, use of variables and functions
for more dynamic configuration languages.

HCL provides a set of constructs that can be used by a calling application to
construct a configuration language. The application defines which attribute
names and nested block types are expected, and HCL parses the configuration
file, verifies that it conforms to the expected structure, and returns
high-level objects that the application can use for further processing.

```go
package main

import (
	&quot;log&quot;

	&quot;github.com/hashicorp/hcl/v2/hclsimple&quot;
)

type Config struct {
	IOMode  string        `hcl:&quot;io_mode&quot;`
	Service ServiceConfig `hcl:&quot;service,block&quot;`
}

type ServiceConfig struct {
	Protocol   string          `hcl:&quot;protocol,label&quot;`
	Type       string          `hcl:&quot;type,label&quot;`
	ListenAddr string          `hcl:&quot;listen_addr&quot;`
	Processes  []ProcessConfig `hcl:&quot;process,block&quot;`
}

type ProcessConfig struct {
	Type    string   `hcl:&quot;type,label&quot;`
	Command []string `hcl:&quot;command&quot;`
}

func main() {
	var config Config
	err := hclsimple.DecodeFile(&quot;config.hcl&quot;, nil, &amp;config)
	if err != nil {
		log.Fatalf(&quot;Failed to load configuration: %s&quot;, err)
	}
	log.Printf(&quot;Configuration is %#v&quot;, config)
}
```

A lower-level API is available for applications that need more control over
the parsing, decoding, and evaluation of configuration. For more information,
see [the package documentation](https://pkg.go.dev/github.com/hashicorp/hcl/v2).

## Why?

Newcomers to HCL often ask: why not JSON, YAML, etc?

Whereas JSON and YAML are formats for serializing data structures, HCL is
a syntax and API specifically designed for building structured configuration
formats.

HCL attempts to strike a compromise between generic serialization formats
such as JSON and configuration formats built around full programming languages
such as Ruby. HCL syntax is designed to be easily read and written by humans,
and allows _declarative_ logic to permit its use in more complex applications.

HCL is intended as a base syntax for configuration formats built
around key-value pairs and hierarchical blocks whose structure is well-defined
by the calling application, and this definition of the configuration structure
allows for better error messages and more convenient definition within the
calling application.

It can&#039;t be denied that JSON is very convenient as a _lingua franca_
for interoperability between different pieces of software. Because of this,
HCL defines a common configuration model that can be parsed from either its
native syntax or from a well-defined equivalent JSON structure. This allows
configuration to be provided as a mixture of human-authored configuration
files in the native syntax and machine-generated files in JSON.

## Information Model and Syntax

HCL is built around two primary concepts: _attributes_ and _blocks_. In
native syntax, a configuration file for a hypothetical application might look
something like this:

```hcl
io_mode = &quot;async&quot;

service &quot;http&quot; &quot;web_proxy&quot; {
  listen_addr = &quot;127.0.0.1:8080&quot;
  
  process &quot;main&quot; {
    command = [&quot;/usr/local/bin/awesome-app&quot;, &quot;server&quot;]
  }

  process &quot;mgmt&quot; {
    command = [&quot;/usr/local/bin/awesome-app&quot;, &quot;mgmt&quot;]
  }
}
```

The JSON equivalent of this configuration is the following:

```json
{
  &quot;io_mode&quot;: &quot;async&quot;,
  &quot;service&quot;: {
    &quot;http&quot;: {
      &quot;web_proxy&quot;: {
        &quot;listen_addr&quot;: &quot;127.0.0.1:8080&quot;,
        &quot;process&quot;: {
          &quot;main&quot;: {
            &quot;command&quot;: [&quot;/usr/local/bin/awesome-app&quot;, &quot;server&quot;]
          },
          &quot;mgmt&quot;: {
            &quot;command&quot;: [&quot;/usr/local/bin/awesome-app&quot;, &quot;mgmt&quot;]
          },
        }
      }
    }
  }
}
```

Regardless of which syntax is used, the API within the calling application
is the same. It can either work directly with the low-level attributes and
blocks, for more advanced use-cases, or it can use one of the _decoder_
packages to declaratively extract into either Go structs or dynamic value
structures.

Attribute values can be expressions as well as just literal values:

```hcl
# Arithmetic with literals and application-provided variables
sum = 1 + addend

# String interpolation and templates
message = &quot;Hello, ${name}!&quot;

# Application-provided functions
shouty_message = upper(message)
```

Although JSON syntax doesn&#039;t permit direct use of expressions, the interpolation
syntax allows use of arbitrary expressions within JSON strings:

```json
{
  &quot;sum&quot;: &quot;${1 + addend}&quot;,
  &quot;message&quot;: &quot;Hello, ${name}!&quot;,
  &quot;shouty_message&quot;: &quot;${upper(message)}&quot;
}
```

For more information, see the detailed specifications:

* [Syntax-agnostic Information Model](spec.md)
* [HCL Native Syntax](hclsyntax/spec.md)
* [JSON Representation](json/spec.md)

## Changes in 2.0

Version 2.0 of HCL combines the features of HCL 1.0 with those of the
interpolation language HIL to produce a single configuration language that
supports arbitrary expressions.

This new version has a completely new parser and Go API, with no direct
migration path. Although the syntax is similar, the implementation takes some
very different approaches to improve on some &quot;rough edges&quot; that existed with
the original implementation and to allow for more robust error handling.

It&#039;s possible to import both HCL 1 and HCL 2 into the same program using Go&#039;s
_semantic import versioning_ mechanism:

```go
import (
    hcl1 &quot;github.com/hashicorp/hcl&quot;
    hcl2 &quot;github.com/hashicorp/hcl/v2&quot;
)
```

## Acknowledgements

HCL was heavily inspired by [libucl](https://github.com/vstakhov/libucl),
by [Vsevolod Stakhov](https://github.com/vstakhov).

HCL and HIL originate in [HashiCorp Terraform](https://terraform.io/),
with the original parsers for each written by
[Mitchell Hashimoto](https://github.com/mitchellh).

The original HCL parser was ported to pure Go (from yacc) by
[Fatih Arslan](https://github.com/fatih). The structure-related portions of
the new native syntax parser build on that work.

The original HIL parser was ported to pure Go (from yacc) by
[Martin Atkins](https://github.com/apparentlymart). The expression-related
portions of the new native syntax parser build on that work.

HCL 2, which merged the original HCL and HIL languages into this single new
language, builds on design and prototyping work by
[Martin Atkins](https://github.com/apparentlymart) in
[zcl](https://github.com/zclconf/go-zcl).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[aaPanel/BillionMail]]></title>
            <link>https://github.com/aaPanel/BillionMail</link>
            <guid>https://github.com/aaPanel/BillionMail</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[BillionMail gives you open-source MailServer, NewsLetter, Email Marketing ‚Äî fully self-hosted, dev-friendly, and free from monthly fees. Join the discord: https://discord.gg/asfXzBUhZr]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aaPanel/BillionMail">aaPanel/BillionMail</a></h1>
            <p>BillionMail gives you open-source MailServer, NewsLetter, Email Marketing ‚Äî fully self-hosted, dev-friendly, and free from monthly fees. Join the discord: https://discord.gg/asfXzBUhZr</p>
            <p>Language: Go</p>
            <p>Stars: 6,134</p>
            <p>Forks: 502</p>
            <p>Stars today: 70 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;
  &lt;h1&gt;&lt;a href=&quot;https://www.billionmail.com/&quot; target=&quot;_blank&quot;&gt;BillionMail üìß&lt;/a&gt;&lt;/h1&gt;


## An Open-Source MailServer, NewsLetter, Email Marketing Solution for Smarter Campaigns

[![][license-shield]][license-link] [![][docs-shield]][docs-link] [![][github-release-shield]][github-release-link] [![][github-stars-shield]][github-stars-link]

English | [ÁÆÄ‰Ωì‰∏≠Êñá](README-zh_CN.md) | [Êó•Êú¨Ë™û](README-ja.md)
&lt;/div&gt;
&lt;br/&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13842&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13842&quot; alt=&quot;aaPanel%2FBillionMail | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

## What is BillionMail?

BillionMail is a **future open-source Mail server, Email marketing platform** designed to help businesses and individuals manage their email campaigns with ease. Whether you&#039;re sending newsletters, promotional emails, or transactional messages, this tool will provide **full control** over your email marketing efforts. With features like **advanced analytics**, and **customer management**, you&#039;ll be able to create, send, and track emails like a pro.

![BillionMail Banner](https://www.billionmail.com/home.png?v1)

# Just 3 steps to send a billion emails!
**Billion emails. Any business. Guaranteed.**

### Step 1Ô∏è‚É£ Install BillionMail: 
‚úÖ It takes **only 8Ô∏è‚É£ minutes** from installation to **‚úÖ successful email sending**
```shell
cd /opt &amp;&amp; git clone https://github.com/aaPanel/BillionMail &amp;&amp; cd BillionMail &amp;&amp; bash install.sh
```


### Step 2Ô∏è‚É£: Connect Your Domain
- Add the sending domain
- Verify DNS records
- Auto-enable free SSL


### Step 3Ô∏è‚É£: Build Your Campaign

- Write or paste your email
- Choose list &amp; tags
- Set send time or send now


&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/embed/UHgxZa_9jGs?si=0-f1B5hDtcWImvQv&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.youtube.com/vi/UHgxZa_9jGs/maxresdefault.jpg&quot; alt=&quot;&quot; width=&quot;80%&quot;&gt;
    &lt;br /&gt;
    &lt;img src=&quot;https://www.iconfinder.com/icons/317714/download/png/16&quot; alt=&quot;YouTube&quot; width=&quot;16&quot;/&gt;
    &lt;b&gt;Watch on Youtube&lt;/b&gt;
  &lt;/a&gt;
&lt;/div&gt;


## Other installation methods

### One-click installation on aaPanel
üëâ https://www.aapanel.com/new/download.html  (Log in to ‚úÖaaPanel --&gt; üê≥Docker --&gt; 1Ô∏è‚É£OneClick install)




**Docker**
```shell
cd /opt &amp;&amp; git clone https://github.com/aaPanel/BillionMail &amp;&amp; cd BillionMail &amp;&amp; cp env_init .env &amp;&amp; docker compose up -d || docker-compose up -d
```

## Management script
- Management help

  `bm help`

- View Login default info

  `bm default`

- Show domain DNS record

  `bm show-record`

- Update BillionMail

  `bm update`

## Live Demo
BillionMail Demo: [https://demo.billionmail.com/billionmail](https://demo.billionmail.com/billionmail)

Username: `billionmail` 

Password: `billionmail` 


## WebMail

BillionMail has integrated **RoundCube**, you can access WebMail via `/roundcube/`.

## Why BillionMail?

Most email marketing platforms are either **expensive**, **closed-source**, or **lack essential features**. BillionMail aims to be different:

‚úÖ **Fully Open-Source** ‚Äì No hidden costs, no vendor lock-in.  
üìä **Advanced Analytics** ‚Äì Track email delivery, open rates, click-through rates, and more.  
üìß **Unlimited Sending** ‚Äì No restrictions on the number of emails you can send.  
üé® **Customizable Templates** ‚Äì Custom professional marketing templates for reuse.
üîí **Privacy-First** ‚Äì Your data stays with you, no third-party tracking.  
üöÄ **Self-Hosted** ‚Äì Run it on your own server for complete control.  

## How You Can Help üåü

BillionMail is a **community-driven project**, and we need your support to get started! Here&#039;s how you can help:

1. **Star This Repository**: Show your interest by starring this repo.  
2. **Spread the Word**: Share BillionMail with your network‚Äîdevelopers, marketers, and open-source enthusiasts.  
3. **Share Feedback**: Let us know what features you&#039;d like to see in BillionMail by opening an issue or joining the discussion.  
4. **Contribute**: Once development begins, we&#039;ll welcome contributions from the community. Stay tuned for updates!

---

üìß **BillionMail ‚Äì The Future of Open-Source Email Marketing.**

## Issues

If you encounter any issues or have feature requests, please [open an issue](https://github.com/aaPanel/BillionMail/issues). Be sure to include:

- A clear description of the problem or request.
- Steps to reproduce the issue (if applicable).
- Screenshots or error logs (if applicable).

## Install Now:
‚úÖIt takes **only 8 minutes** from installation to **successful email sending**
```shell
cd /opt &amp;&amp; git clone https://github.com/aaPanel/BillionMail &amp;&amp; cd BillionMail &amp;&amp; bash install.sh
```


**Install with Docker:** (Please install Docker and docker-compose-plugin manually, and modify .env file)
```shell
cd /opt &amp;&amp; git clone https://github.com/aaPanel/BillionMail &amp;&amp; cd BillionMail &amp;&amp; cp env_init .env &amp;&amp; docker compose up -d || docker-compose up -d
```

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=aapanel/billionmail&amp;type=Date)](https://www.star-history.com/#aapanel/billionmail&amp;Date)

## License

BillionMail is licensed under the **AGPLv3 License**. This means you can:

‚úÖ Use the software for free.  
‚úÖ Modify and distribute the code.  
‚úÖ Use it privately without restrictions.

See the [LICENSE](LICENSE) file for more details.

---

&lt;!-- BillionMail official link --&gt;
[docs-link]: https://www.billionmail.com/

&lt;!-- BillionMail Other link--&gt;
[license-link]: https://www.gnu.org/licenses/agpl-3.0.html
[github-release-link]: https://github.com/aaPanel/BillionMail/releases/latest
[github-stars-link]: https://github.com/aaPanel/BillionMail
[github-issues-link]: https://github.com/aaPanel/BillionMail/issues

&lt;!-- Shield link--&gt;
[docs-shield]: https://img.shields.io/badge/documentation-148F76
[github-release-shield]: https://img.shields.io/github/v/release/aaPanel/BillionMail
[github-stars-shield]: https://img.shields.io/github/stars/aaPanel/BillionMail?color=%231890FF&amp;style=flat-square¬†¬†¬†
[license-shield]: https://img.shields.io/github/license/aaPanel/BillionMail
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[psviderski/uncloud]]></title>
            <link>https://github.com/psviderski/uncloud</link>
            <guid>https://github.com/psviderski/uncloud</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[A lightweight tool for deploying and managing containerised applications across a network of Docker hosts. Bridging the gap between Docker and Kubernetes ‚ú®]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/psviderski/uncloud">psviderski/uncloud</a></h1>
            <p>A lightweight tool for deploying and managing containerised applications across a network of Docker hosts. Bridging the gap between Docker and Kubernetes ‚ú®</p>
            <p>Language: Go</p>
            <p>Stars: 884</p>
            <p>Forks: 21</p>
            <p>Stars today: 53 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./website/images/logo.svg&quot; height=&quot;100&quot; alt=&quot;Uncloud logo&quot;/&gt;
  &lt;h1&gt;Uncloud&lt;/h1&gt;
  &lt;p&gt;&lt;strong&gt;Docker simplicity. Multi-machine power.&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;
    &lt;a href=&quot;https://docs.uncloud.run&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Docs-blue.svg?style=for-the-badge&amp;logo=gitbook&amp;logoColor=white&quot; alt=&quot;Documentation&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/eR35KQJhPu&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/discord-5865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Join Discord&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://x.com/psviderski&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/follow-black?style=for-the-badge&amp;logo=X&amp;logoColor=while&quot; alt=&quot;Follow on X&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/sponsors/psviderski&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Donate-EA4AAA.svg?style=for-the-badge&amp;logo=githubsponsors&amp;logoColor=white&quot; alt=&quot;Donate&quot;&gt;&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

Uncloud is a lightweight clustering and container orchestration tool that lets you deploy and manage web apps across
cloud VMs and bare metal with minimised cluster management overhead. It creates a secure WireGuard mesh network between
your Docker hosts and provides automatic service discovery, load balancing, ingress with HTTPS, and simple CLI commands
to manage your apps.

Unlike traditional orchestrators, there&#039;s no central control plane and quorum to maintain. Each machine maintains a
synchronised copy of the cluster state through peer-to-peer communication, keeping cluster operations functional even if
some machines go offline.

Uncloud is the solution for developers who want the flexibility of self-hosted infrastructure without the operational
complexity of Kubernetes.

## ‚ú® Features

* **Deploy anywhere**: Combine cloud VMs, dedicated servers, and bare metal into a unified computing environment ‚Äî
  regardless of location or provider.
* **Docker Compose**: Familiar [Docker Compose](https://compose-spec.io/) format for defining services and volumes. No
  need to learn a new bespoke DSL.
* **Zero-downtime deployments**: Rolling updates without service interruption. Automatic rollback on failure is coming
  soon.
* **Service discovery**: Built-in DNS server resolves service names to container IPs.
* **Persistent storage**: Run stateful services with Docker volumes managed across machines.
* **Zero-config private network**: Automatic WireGuard mesh with peer discovery and NAT traversal. Containers get unique
  IPs for direct cross-machine communication.
* **No control plane**: Fully decentralised design eliminates single points of failure and reduces operational overhead.
* **Imperative over declarative**: Favoring imperative operations over state reconciliation simplifies both the mental
  model and troubleshooting.
* **Managed DNS**: Automatic DNS records `*.&lt;id&gt;.cluster.uncloud.run` for services with public access via managed
  [Uncloud DNS](https://github.com/psviderski/uncloud-dns) service.
* **Automatic HTTPS**: Built-in Caddy reverse proxy handles TLS certificate provisioning and renewal using Let&#039;s
  Encrypt.
* **Docker-like CLI**: Familiar commands for managing both infrastructure and applications.
* **Remote management**: Control your entire infrastructure through SSH access to any single machine in the cluster.

### üöÄ Coming soon
* **[Unregistry](https://github.com/psviderski/unregistry) integration**: Push your Docker images directly to your
  machines without an external registry. It will transfer only the missing layers, making it fast and efficient.

## üé¨ Quick demo

The screenshot below demonstrates how I use Uncloud to deploy the [Uncloud Documentation](https://docs.uncloud.run)
website to 2 remote machines (why not?) from the [`compose.yaml`](docs/compose.yaml) file on my local machine.

It exposes the container port `8000/tcp` as HTTPS on the domain `docs.uncloud.run`, served by the Caddy reverse proxy on
the remote machines. All managed by Uncloud.

![Uncloud compose deployment demo](.github/images/compose-deploy.jpg)

Here is a more advanced use case. Deploy a highly available web app with automatic HTTPS across multiple regions and
on-premises in just a couple minutes.

&lt;a href=&quot;https://uncloud.wistia.com/medias/k47uwt9uau?wvideo=k47uwt9uau&quot;&gt;
&lt;img src=&quot;https://embed-ssl.wistia.com/deliveries/3cf7014a48b93afc556444bed3e39a8c.jpg?image_crop_resized=900x526&amp;image_play_button_rounded=true&amp;image_play_button_size=2x&amp;image_play_button_color=18181Be0&quot; alt=&quot;Uncloud demo&quot; width=&quot;450&quot; height=&quot;263&quot; /&gt;
&lt;/a&gt;

## üí´ Why Uncloud?

Modern cloud platforms like Heroku and Render offer amazing developer experiences but at a premium price. Traditional
container orchestrators like Kubernetes provide power and flexibility but require significant operational expertise. I
believe there&#039;s a sweet spot in between ‚Äî a pragmatic solution for the majority of us who aren&#039;t running at Google
scale. You should be able to:

* **Own your infrastructure and data**: Whether driven by costs, compliance, or flexibility, run applications on any
  combination of cloud VMs and personal hardware while controlling your data and maintaining the cloud-like experience
  you love.
* **Stay simple as you grow**: Start with a single machine and add more whenever you need without changing your
  workflow. No worrying about highly-available control planes or complex YAML configurations.
* **Build with proven primitives**: Get production-grade networking, deployment primitives, service discovery, load
  balancing, and ingress with HTTPS out of the box without becoming a distributed systems expert.
* **Support sustainable computing** üåø: Minimise system overhead to maximise resources available for your applications.

Uncloud&#039;s goal is to make deployment and management of containerised applications feel as seamless as using a cloud
platform, whether you&#039;re running on a $5 VPS, a spare Mac mini, or a rack of bare metal servers.

## üöÄ Quick start

1. Install Uncloud CLI:

   ```bash
   brew install psviderski/tap/uncloud

   # or using curl (macOS/Linux)
   curl -fsS https://get.uncloud.run/install.sh | sh
   ```

2. Initialise your first machine:

   ```bash
   uc machine init root@your-server-ip
   ```

3. Deploy your app from a Docker image and publish its container port 8000 as HTTPS using `app.example.com` domain:

   ```bash
   uc run -p app.example.com:8000/https image/my-app
   ```

4. Create a DNS A record in your DNS provider (Cloudflare, Namecheap, etc.) that points `app.example.com` to your
   server&#039;s IP address. Allow a few minutes for DNS propagation.

   That&#039;s it! Your app is now running and accessible at https://app.example.com ‚ú®

5. Clean up when you&#039;re done:

   ```bash
   uc ls
   # Copy the service name from the output and run the rm command:
   uc rm my-app-name
   ```

   If you want to fully uninstall Uncloud on a machine, run:

   ```bash
   uncloud-uninstall
   ```

View the [Documentation](https://docs.uncloud.run) for more information.

## ‚öôÔ∏è How it works

Check out the [design document](docs/design.md) to understand Uncloud&#039;s design philosophy and goals.

Here is a diagram of an Uncloud multi-provider cluster of 3 machines:

![Diagram: multi-provider cluster of 3 machines](website/images/diagram.webp)

&lt;details&gt;
&lt;summary&gt;Peek under the hood to see what happens when you run certain commands.&lt;/summary&gt;

**When you initialise a new cluster on a machine:**

```bash
$ uc machine init --name oracle-vm ubuntu@152.67.101.197

Downloading Uncloud install script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/install.sh
‚è≥ Running Uncloud install script...
‚úì Docker is already installed.
‚è≥ Installing Docker...
...
‚úì Docker installed successfully.
‚úì Linux user and group &#039;uncloud&#039; created.
‚úì Linux user &#039;ubuntu&#039; added to group &#039;uncloud&#039;.
‚è≥ Installing Uncloud binaries...
‚è≥ Downloading uncloudd binary: https://github.com/psviderski/uncloud/releases/latest/download/uncloudd_linux_arm64.tar.gz
‚úì uncloudd binary installed: /usr/local/bin/uncloudd
‚è≥ Downloading uninstall script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/uninstall.sh
‚úì uncloud-uninstall script installed: /usr/local/bin/uncloud-uninstall
‚úì Systemd unit file created: /etc/systemd/system/uncloud.service
Created symlink /etc/systemd/system/multi-user.target.wants/uncloud.service ‚Üí /etc/systemd/system/uncloud.service.
‚è≥ Downloading uncloud-corrosion binary: https://github.com/psviderski/corrosion/releases/latest/download/corrosion-aarch64-unknown-linux-gnu.tar.gz
‚úì uncloud-corrosion binary installed: /usr/local/bin/uncloud-corrosion
‚úì Systemd unit file created: /etc/systemd/system/uncloud-corrosion.service
‚è≥ Starting Uncloud machine daemon (uncloud.service)...
‚úì Uncloud machine daemon started.
‚úì Uncloud installed on the machine successfully! üéâ
Cluster &quot;default&quot; initialised with machine &quot;oracle-vm&quot;
Waiting for the machine to be ready...

Reserved cluster domain: xuw3xd.cluster.uncloud.run
[+] Deploying service caddy 1/1
 ‚úî Container caddy-c47x on oracle-vm  Started                                                                                                                                          0.9s

Updating cluster domain records in Uncloud DNS to point to machines running caddy service...
[+] Verifying internet access to caddy service 1/1
 ‚úî Machine oracle-vm (152.67.101.197)  Reachable                                                                                                                                       0.1s

DNS records updated to use only the internet-reachable machines running caddy service:
  *.xuw3xd.cluster.uncloud.run  A ‚Üí 152.67.101.197
```

1. The CLI SSHs into the machine and installs Docker, the `uncloudd` machine daemon and
   [corrosion](https://github.com/superfly/corrosion) service, managed by systemd.
2. Generates a unique WireGuard key pair, allocates a dedicated subnet `10.210.0.0/24` for the machine and its
   containers, and configures `uncloudd` accordingly. All subsequent communication happens with `uncloudd`
   through its gRPC API over SSH.
3. Configures and starts `corrosion`, a CRDT-based distributed SQLite database to share cluster state between machines.
4. Creates a Docker bridge network connected to the WireGuard interface.
5. This machine becomes an entry point for the newly created cluster which is stored in the cluster config under
   `~/.config/uncloud` on your local machine.

**When you add another machine:**

```bash
$ uc machine add --name hetzner-server root@5.223.45.199
Downloading Uncloud install script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/install.sh
‚è≥ Running Uncloud install script...
‚úì Docker is already installed.
‚úì Linux user and group &#039;uncloud&#039; created.
‚è≥ Installing Uncloud binaries...
‚è≥ Downloading uncloudd binary: https://github.com/psviderski/uncloud/releases/latest/download/uncloudd_linux_amd64.tar.gz
‚úì uncloudd binary installed: /usr/local/bin/uncloudd
‚è≥ Downloading uninstall script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/uninstall.sh
‚úì uncloud-uninstall script installed: /usr/local/bin/uncloud-uninstall
‚úì Systemd unit file created: /etc/systemd/system/uncloud.service
Created symlink /etc/systemd/system/multi-user.target.wants/uncloud.service ‚Üí /etc/systemd/system/uncloud.service.
‚è≥ Downloading uncloud-corrosion binary: https://github.com/psviderski/corrosion/releases/latest/download/corrosion-x86_64-unknown-linux-gnu.tar.gz
‚úì uncloud-corrosion binary installed: /usr/local/bin/uncloud-corrosion
‚úì Systemd unit file created: /etc/systemd/system/uncloud-corrosion.service
‚è≥ Starting Uncloud machine daemon (uncloud.service)...
‚úì Uncloud machine daemon started.
‚úì Uncloud installed on the machine successfully! üéâ
Machine &quot;hetzner-server&quot; added to cluster
Waiting for the machine to be ready...

[+] Deploying service caddy 1/1
 ‚úî Container caddy-d36c on hetzner-server  Started                                                                                                                                     1.0s

Updating cluster domain records in Uncloud DNS to point to machines running caddy service...
[+] Verifying internet access to caddy service 2/2
 ‚úî Machine hetzner-server (5.223.45.199)  Reachable                                                                                                                                    0.2s
 ‚úî Machine oracle-vm (152.67.101.197)     Reachable                                                                                                                                    0.1s

DNS records updated to use only the internet-reachable machines running caddy service:
  *.xuw3xd.cluster.uncloud.run  A ‚Üí 152.67.101.197, 5.223.45.199

$ uc machine ls
NAME             STATE   ADDRESS         PUBLIC IP        WIREGUARD ENDPOINTS
oracle-vm        Up      10.210.0.1/24   152.67.101.197   10.0.0.95:51820, 152.67.101.197:51820
hetzner-server   Up      10.210.1.1/24   5.223.45.199     5.223.45.199:51820, [2a01:4ff:2f0:128b::1]:51820
```

1. The second machine gets provisioned just like the first. A non-root SSH user will need `sudo` access.
2. Allocates a new subnet `10.210.1.0/24` for the second machine and its containers.
3. Registers the second machine in the cluster state and exchanges WireGuard keys with the first machine.
4. Both machines establish a WireGuard tunnel between each other, allowing Docker containers connected to the bridge
   network to communicate directly across machines.
5. Configures and starts `corrosion` on the second machine to sync the cluster state.
6. The second machine is added as an alternative entry point in the cluster config.
7. If one of the machines goes offline, the other machine can still serve cluster operations.

If one more machine is added, the process repeats with a new subnet. The new machine needs to establish a WireGuard
connection with only one of the existing machines. Other machines will learn about it through the shared cluster state
and automatically establish a WireGuard tunnel with it.

**When you run a service:**

```bash
$ uc run -p app.example.com:8000/https image/my-app

[+] Running service my-app-1b3b (replicated mode) 1/1
 ‚úî Container my-app-1b3b-tcex on oracle-vm  Started

my-app-1b3b endpoints:
 ‚Ä¢ https://app.example.com ‚Üí :8000
 ‚Ä¢ https://my-app-1b3b.xuw3xd.cluster.uncloud.run ‚Üí :8000
```

1. CLI picks a machine to run your container.
2. `uncloudd` that the CLI communicates with uses [`grpc-proxy`](https://github.com/siderolabs/grpc-proxy) to forward
   the request to the target machine to launch a container there.
3. `uncloudd` on the target machine starts the Docker container in the bridge network and stores its info in the
   cluster&#039;s distributed state.
4. The container gets a cluster-unique IP address from the bridge network (in the `10.210.X.2-254` range) and becomes
   accessible from other machines in the cluster.
5. Caddy reverse proxy which runs in [`global`](https://github.com/compose-spec/compose-spec/blob/main/deploy.md#mode)
   mode on each machine watches the cluster state for new services and updates its configuration to route traffic to the
   new container.

Look ma, no control plane or master nodes to maintain! Just a simple overlay network and eventually consistent state
sync that lets machines work together. Want to check on things or make changes? Connect to any machine either implicitly
using the CLI or directly over SSH. They all have the complete cluster state and can control everything. It&#039;s like each
machine is a full backup of your control plane.
&lt;/details&gt;

## üèó Project status

Uncloud is currently in active development and is **not ready for production use**. Features may change significantly
and there may be breaking changes between releases.

We&#039;d love your input! Here&#039;s how you can contribute:

* üêõ Found a bug? [Open an issue](https://github.com/psviderski/uncloud/issues)
* üí° Have ideas or need help? [Join our Discord community](https://discord.gg/eR35KQJhPu) where we discuss features,
  roadmap, implementation details, and help each other out.

## üôè Inspiration &amp; Acknowledgements

I&#039;m grateful to the following projects that inspired Uncloud&#039;s design and implementation:

* [Kamal](https://kamal-deploy.org/) ‚Äî for proving that even in the declarative era of Kubernetes there is a place for
  simple deployment tools that use imperative commands without complex orchestration. Kamal powers the multi-billion
  dollar company [37signals](https://37signals.com/) where it was created, and that&#039;s truly inspiring!
* [Fly.io](https://fly.io/) ‚Äî for inspiring my vision for what self-hosted infrastructure should feel like, proving that
  developer experience and powerful infrastructure can coexist beautifully.
* [Tailscale](https://tailscale.com/) ‚Äî for pioneering the vision of decentralised flat mesh networking with an amazing
  user experience that feels like magic.
* [Talos Linux](https://github.com/siderolabs/talos)
  and [KubeSpan](https://www.talos.dev/v1.10/talos-guides/network/kubespan/) ‚Äî for the machine API design using
  [grpc-proxy](https://github.com/siderolabs/grpc-proxy) and for its elegant approach to secure WireGuard-based overlay
  networking with zero configuration.
* [Docker Swarm Classic](https://github.com/docker-archive/classicswarm) and
  [Rancher 1.x](http://rancher-com-website-main-elb-elb-1798790864.us-west-2.elb.amazonaws.com/docs/rancher/v1.6/en/)
  ‚Äî for showing the power of simplicity and pragmatism in container orchestration and that not every problem needs the
  complexity of Kubernetes.

Special thanks to the [Corrosion](https://github.com/superfly/corrosion) project by Fly.io for providing the distributed
SQLite database used to share Uncloud&#039;s cluster state.

## üì´ Stay updated

* Join our [Discord server](https://discord.gg/eR35KQJhPu) for real-time discussions, support, and updates.
* Follow [@psviderski](https://x.com/psviderski) on X/Twitter.
* Subscribe to [my newsletter](https://uncloud.run/#subscribe) to follow the progress, get early insights into new
  features, and be the first to know when it&#039;s ready for production use.
* Watch this repository for releases.

## ‚ù§Ô∏è Contributors

Thank you [@cedws](https://github.com/cedws) for being the first contributor to Uncloud! üéâ

&lt;a href=&quot;https://github.com/psviderski/uncloud/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=psviderski/uncloud&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gruntwork-io/terragrunt]]></title>
            <link>https://github.com/gruntwork-io/terragrunt</link>
            <guid>https://github.com/gruntwork-io/terragrunt</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in OpenTofu/Terraform to scale.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gruntwork-io/terragrunt">gruntwork-io/terragrunt</a></h1>
            <p>Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in OpenTofu/Terraform to scale.</p>
            <p>Language: Go</p>
            <p>Stars: 8,734</p>
            <p>Forks: 1,053</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># Terragrunt

[![Maintained by Gruntwork.io](https://img.shields.io/badge/maintained%20by-gruntwork.io-%235849a6.svg)](https://gruntwork.io/?ref=repo_terragrunt)
[![Go Report Card](https://goreportcard.com/badge/github.com/gruntwork-io/terragrunt)](https://goreportcard.com/report/github.com/gruntwork-io/terragrunt)
[![GoDoc](https://godoc.org/github.com/gruntwork-io/terragrunt?status.svg)](https://godoc.org/github.com/gruntwork-io/terragrunt)
![OpenTofu Version](https://img.shields.io/badge/tofu-%3E%3D1.6.0-blue.svg)
![Terraform Version](https://img.shields.io/badge/tf-%3E%3D0.12.0-blue.svg)

Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in [OpenTofu](https://opentofu.org)/[Terraform](https://www.terraform.io) to scale.

Please see the following for more info, including install instructions and complete documentation:

* [Terragrunt Website](https://terragrunt.gruntwork.io)
* [Getting started with Terragrunt](https://terragrunt.gruntwork.io/docs/getting-started/quick-start/)
* [Terragrunt Documentation](https://terragrunt.gruntwork.io/docs)
* [Contributing to Terragrunt](https://terragrunt.gruntwork.io/docs/community/contributing)
* [Commercial Support](https://gruntwork.io/support/)

## Join the Discord!

Join [our community](https://discord.gg/YENaT9h8jh) for discussions, support, and contributions:

[![](https://dcbadge.limes.pink/api/server/https://discord.gg/YENaT9h8jh)](https://discord.gg/YENaT9h8jh)

## License

This code is released under the MIT License. See [LICENSE.txt](LICENSE.txt).

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[krillinai/KlicStudio]]></title>
            <link>https://github.com/krillinai/KlicStudio</link>
            <guid>https://github.com/krillinai/KlicStudio</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[A video translation and dubbing tool powered by LLMs, offering professional-grade translations and one-click full-process deployment. It can generate content optimized for platforms like YouTubeÔºåTikTok, and Shorts. Âü∫‰∫éAIÂ§ßÊ®°ÂûãÁöÑËßÜÈ¢ëÁøªËØëÂíåÈÖçÈü≥Â∑•ÂÖ∑Ôºå‰∏ì‰∏öÁ∫ßÁøªËØëÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÂÖ®ÊµÅÁ®ãÔºåÂèØ‰ª•ÁîüÊàêÈÄÇÈÖçÊäñÈü≥ÔºåÂ∞èÁ∫¢‰π¶ÔºåÂìîÂì©ÂìîÂì©ÔºåËßÜÈ¢ëÂè∑ÔºåTikTokÔºåYoutube ShortsÁ≠âÂΩ¢ÊÄÅÁöÑÂÜÖÂÆπ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/krillinai/KlicStudio">krillinai/KlicStudio</a></h1>
            <p>A video translation and dubbing tool powered by LLMs, offering professional-grade translations and one-click full-process deployment. It can generate content optimized for platforms like YouTubeÔºåTikTok, and Shorts. Âü∫‰∫éAIÂ§ßÊ®°ÂûãÁöÑËßÜÈ¢ëÁøªËØëÂíåÈÖçÈü≥Â∑•ÂÖ∑Ôºå‰∏ì‰∏öÁ∫ßÁøªËØëÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÂÖ®ÊµÅÁ®ãÔºåÂèØ‰ª•ÁîüÊàêÈÄÇÈÖçÊäñÈü≥ÔºåÂ∞èÁ∫¢‰π¶ÔºåÂìîÂì©ÂìîÂì©ÔºåËßÜÈ¢ëÂè∑ÔºåTikTokÔºåYoutube ShortsÁ≠âÂΩ¢ÊÄÅÁöÑÂÜÖÂÆπ</p>
            <p>Language: Go</p>
            <p>Stars: 7,879</p>
            <p>Forks: 608</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;/docs/images/logo.jpg&quot; alt=&quot;KlicStudio&quot; height=&quot;90&quot;&gt;

  # Minimalist AI Video Translation and Dubbing Tool

  &lt;a href=&quot;https://trendshift.io/repositories/13360&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13360&quot; alt=&quot;KrillinAI%2FKlicStudio | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

  **[English](/README.md)ÔΩú[ÁÆÄ‰Ωì‰∏≠Êñá](/docs/zh/README.md)ÔΩú[Êó•Êú¨Ë™û](/docs/jp/README.md)ÔΩú[ÌïúÍµ≠Ïñ¥](/docs/kr/README.md)ÔΩú[Ti·∫øng Vi·ªát](/docs/vi/README.md)ÔΩú[Fran√ßais](/docs/fr/README.md)ÔΩú[Deutsch](/docs/de/README.md)ÔΩú[Espa√±ol](/docs/es/README.md)ÔΩú[Portugu√™s](/docs/pt/README.md)ÔΩú[–†—É—Å—Å–∫–∏–π](/docs/rus/README.md)ÔΩú[ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](/docs/ar/README.md)**

[![Twitter](https://img.shields.io/badge/Twitter-KrillinAI-orange?logo=twitter)](https://x.com/KrillinAI)
[![QQ Áæ§](https://img.shields.io/badge/QQ%20Áæ§-754069680-green?logo=tencent-qq)](https://jq.qq.com/?_wv=1027&amp;k=754069680)
[![Bilibili](https://img.shields.io/badge/dynamic/json?label=Bilibili&amp;query=%24.data.follower&amp;suffix=Á≤â‰∏ù&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Frelation%2Fstat%3Fvmid%3D242124650&amp;logo=bilibili&amp;color=00A1D6&amp;labelColor=FE7398&amp;logoColor=FFFFFF)](https://space.bilibili.com/242124650)

&lt;/div&gt;

 ## Project Introduction  ([Try the online version now!](https://www.klic.studio/))

Klic Studio is a versatile audio and video localization and enhancement solution developed by Krillin AI. This minimalist yet powerful tool integrates video translation, dubbing, and voice cloning, supporting both landscape and portrait formats to ensure perfect presentation on all major platforms (Bilibili, Xiaohongshu, Douyin, WeChat Video, Kuaishou, YouTube, TikTok, etc.). With an end-to-end workflow, you can transform raw materials into beautifully ready-to-use cross-platform content with just a few clicks.

## Key Features and Functions:
üéØ **One-click Start**: No complex environment configuration required, automatic dependency installation, ready to use immediately, with a new desktop version for easier access!

üì• **Video Acquisition**: Supports yt-dlp downloads or local file uploads

üìú **Accurate Recognition**: High-accuracy speech recognition based on Whisper

üß† **Intelligent Segmentation**: Subtitle segmentation and alignment using LLM

üîÑ **Terminology Replacement**: One-click replacement of professional vocabulary 

üåç **Professional Translation**: LLM translation with context to maintain natural semantics

üéôÔ∏è **Voice Cloning**: Offers selected voice tones from CosyVoice or custom voice cloning

üé¨ **Video Composition**: Automatically processes landscape and portrait videos and subtitle layout

üíª **Cross-Platform**: Supports Windows, Linux, macOS, providing both desktop and server versions


## Effect Demonstration
The image below shows the effect of the subtitle file generated after importing a 46-minute local video and executing it with one click, without any manual adjustments. There are no omissions or overlaps, the segmentation is natural, and the translation quality is very high.
![Alignment Effect](/docs/images/alignment.png)

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;33%&quot;&gt;

### Subtitle Translation
---
https://github.com/user-attachments/assets/bba1ac0a-fe6b-4947-b58d-ba99306d0339

&lt;/td&gt;
&lt;td width=&quot;33%&quot;&gt;



### Dubbing
---
https://github.com/user-attachments/assets/0b32fad3-c3ad-4b6a-abf0-0865f0dd2385

&lt;/td&gt;

&lt;td width=&quot;33%&quot;&gt;

### Portrait Mode
---
https://github.com/user-attachments/assets/c2c7b528-0ef8-4ba9-b8ac-f9f92f6d4e71

&lt;/td&gt;

&lt;/tr&gt;
&lt;/table&gt;

## üîç Supported Speech Recognition Services
_**All local models in the table below support automatic installation of executable files + model files; you just need to choose, and Klic will prepare everything for you.**_

| Service Source          | Supported Platforms | Model Options                             | Local/Cloud | Remarks                     |
|------------------------|---------------------|------------------------------------------|-------------|-----------------------------|
| **OpenAI Whisper**     | All Platforms        | -                                        | Cloud       | Fast speed and good effect  |
| **FasterWhisper**      | Windows/Linux       | `tiny`/`medium`/`large-v2` (recommended medium+) | Local       | Faster speed, no cloud service cost |
| **WhisperKit**         | macOS (M-series only) | `large-v2`                              | Local       | Native optimization for Apple chips |
| **WhisperCpp**         | All Platforms        | `large-v2`                              | Local       | Supports all platforms       |
| **Alibaba Cloud ASR**  | All Platforms        | -                                        | Cloud       | Avoids network issues in mainland China |

## üöÄ Large Language Model Support

‚úÖ Compatible with all cloud/local large language model services that comply with **OpenAI API specifications**, including but not limited to:
- OpenAI
- Gemini
- DeepSeek
- Tongyi Qianwen
- Locally deployed open-source models
- Other API services compatible with OpenAI format

## üé§ TTS Text-to-Speech Support
- Alibaba Cloud Voice Service
- OpenAI TTS

## Language Support
Input languages supported: Chinese, English, Japanese, German, Turkish, Korean, Russian, Malay (continuously increasing)

Translation languages supported: English, Chinese, Russian, Spanish, French, and 101 other languages

## Interface Preview
![Interface Preview](/docs/images/ui_desktop.png)


## üöÄ Quick Start
### Basic Steps
First, download the executable file that matches your device system from the [Release](https://github.com/KrillinAI/KlicStudio/releases), then follow the tutorial below to choose between the desktop version or non-desktop version. Place the software download in an empty folder, as running it will generate some directories, and keeping it in an empty folder will make management easier.  

„ÄêIf it is the desktop version, i.e., the release file with &quot;desktop,&quot; see here„Äë  
_The desktop version is newly released to address the issues of new users struggling to edit configuration files correctly, and there are some bugs that are continuously being updated._
1. Double-click the file to start using it (the desktop version also requires configuration within the software)

„ÄêIf it is the non-desktop version, i.e., the release file without &quot;desktop,&quot; see here„Äë  
_The non-desktop version is the initial version, which has a more complex configuration but is stable in functionality and suitable for server deployment, as it provides a UI in a web format._
1. Create a `config` folder within the folder, then create a `config.toml` file in the `config` folder. Copy the contents of the `config-example.toml` file from the source code&#039;s `config` directory into `config.toml`, and fill in your configuration information according to the comments.
2. Double-click or execute the executable file in the terminal to start the service 
3. Open your browser and enter `http://127.0.0.1:8888` to start using it (replace 8888 with the port you specified in the configuration file)

### To: macOS Users
„ÄêIf it is the desktop version, i.e., the release file with &quot;desktop,&quot; see here„Äë  
Due to signing issues, the desktop version currently cannot be double-clicked to run or installed via dmg; you need to manually trust the application. The method is as follows:
1. Open the terminal in the directory where the executable file (assuming the file name is KlicStudio_1.0.0_desktop_macOS_arm64) is located
2. Execute the following commands in order:
```
sudo xattr -cr ./KlicStudio_1.0.0_desktop_macOS_arm64
sudo chmod +x ./KlicStudio_1.0.0_desktop_macOS_arm64 
./KlicStudio_1.0.0_desktop_macOS_arm64
```

„ÄêIf it is the non-desktop version, i.e., the release file without &quot;desktop,&quot; see here„Äë  
This software is not signed, so when running on macOS, after completing the file configuration in the &quot;Basic Steps,&quot; you also need to manually trust the application. The method is as follows:
1. Open the terminal in the directory where the executable file (assuming the file name is KlicStudio_1.0.0_macOS_arm64) is located
2. Execute the following commands in order:
   ```
    sudo xattr -rd com.apple.quarantine ./KlicStudio_1.0.0_macOS_arm64
    sudo chmod +x ./KlicStudio_1.0.0_macOS_arm64
    ./KlicStudio_1.0.0_macOS_arm64
    ```
    This will start the service

### Docker Deployment
This project supports Docker deployment; please refer to the [Docker Deployment Instructions](./docker.md)

### Cookie Configuration Instructions (Optional)

If you encounter issues with video downloads

Please refer to the [Cookie Configuration Instructions](./get_cookies.md) to configure your Cookie information.

### Configuration Help (Must Read)
The quickest and easiest configuration method:
* Fill in `transcribe.provider.name` with `openai`, so you only need to fill in the `transcribe.openai` block and the large model configuration in the `llm` block to perform subtitle translation. (`app.proxy`, `model`, and `openai.base_url` can be filled in as needed)

Using a local speech recognition model configuration method (balancing cost, speed, and quality):
* Fill in `transcribe.provider.name` with `fasterwhisper`, `transcribe.fasterwhisper.model` with `large-v2`, and then fill in the `llm` block with the large model configuration to perform subtitle translation. The local model will be automatically downloaded and installed. (`app.proxy` and `openai.base_url` are the same as above)

Text-to-speech (TTS) is optional; the configuration logic is the same as above. Fill in `tts.provider.name`, and then fill in the corresponding configuration block under `tts`. The voice codes in the UI should be filled in according to the documentation of the selected provider (the documentation address is in the common questions section below). Filling in Alibaba Cloud&#039;s AccessKey, Bucket, AppKey, etc., may be repetitive to ensure a clear configuration structure.  
Note: If using voice cloning, `tts` only supports selecting `aliyun`.

**For obtaining Alibaba Cloud AccessKey, Bucket, and AppKey, please read**: [Alibaba Cloud Configuration Instructions](./aliyun.md) 

Please understand that the task = speech recognition + large model translation + voice service (TTS, etc., optional), which will help you understand the configuration file better.

## Frequently Asked Questions

Please visit [Frequently Asked Questions](./faq.md)

## Contribution Guidelines
1. Do not submit useless files, such as .vscode, .idea, etc.; please use .gitignore to filter them out.
2. Do not submit config.toml; instead, submit config-example.toml.

## Contact Us
1. Join our QQ group for questions: 754069680
2. Follow our social media accounts, [Bilibili](https://space.bilibili.com/242124650), where we share quality content in the AI technology field every day.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=KrillinAI/KlicStudio&amp;type=Date)](https://star-history.com/#KrillinAI/KlicStudio&amp;Date)</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[putyy/res-downloader]]></title>
            <link>https://github.com/putyy/res-downloader</link>
            <guid>https://github.com/putyy/res-downloader</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÁõ¥Êí≠ÊµÅ„ÄÅm3u8„ÄÅÈÖ∑Áãó„ÄÅQQÈü≥‰πêÁ≠âÂ∏∏ËßÅÁΩëÁªúËµÑÊ∫ê‰∏ãËΩΩ!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/putyy/res-downloader">putyy/res-downloader</a></h1>
            <p>ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÁõ¥Êí≠ÊµÅ„ÄÅm3u8„ÄÅÈÖ∑Áãó„ÄÅQQÈü≥‰πêÁ≠âÂ∏∏ËßÅÁΩëÁªúËµÑÊ∫ê‰∏ãËΩΩ!</p>
            <p>Language: Go</p>
            <p>Stars: 7,361</p>
            <p>Forks: 918</p>
            <p>Stars today: 52 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://github.com/putyy/res-downloader&quot;&gt;&lt;img src=&quot;build/appicon.png&quot; width=&quot;120&quot;/&gt;&lt;/a&gt;
&lt;h1&gt;res-downloader&lt;/h1&gt;
&lt;h4&gt;üìñ ‰∏≠Êñá | &lt;a href=&quot;https://github.com/putyy/res-downloader/blob/master/README-EN.md&quot;&gt;English&lt;/a&gt;&lt;/h4&gt;

[![GitHub stars](https://img.shields.io/github/stars/putyy/res-downloader)](https://github.com/putyy/res-downloader/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/putyy/res-downloader)](https://github.com/putyy/res-downloader/fork)
[![GitHub release](https://img.shields.io/github/release/putyy/res-downloader)](https://github.com/putyy/res-downloader/releases)
![GitHub All Releases](https://img.shields.io/github/downloads/putyy/res-downloader/total)
[![License](https://img.shields.io/github/license/putyy/res-downloader)](https://github.com/putyy/res-downloader/blob/master/LICENSE)

&lt;/div&gt;

---

### üéâ Áà±‰∫´Á¥†Êùê‰∏ãËΩΩÂô®

&gt; ‰∏ÄÊ¨æÂü∫‰∫é Go + [Wails](https://github.com/wailsapp/wails) ÁöÑË∑®Âπ≥Âè∞ËµÑÊ∫ê‰∏ãËΩΩÂ∑•ÂÖ∑ÔºåÁÆÄÊ¥ÅÊòìÁî®ÔºåÊîØÊåÅÂ§öÁßçËµÑÊ∫êÂóÖÊé¢‰∏é‰∏ãËΩΩ„ÄÇ

## ‚ú® ÂäüËÉΩÁâπËâ≤

- üöÄ **ÁÆÄÂçïÊòìÁî®**ÔºöÊìç‰ΩúÁÆÄÂçïÔºåÁïåÈù¢Ê∏ÖÊô∞ÁæéËßÇ
- üñ•Ô∏è **Â§öÂπ≥Âè∞ÊîØÊåÅ**ÔºöWindows / macOS / Linux
- üåê **Â§öËµÑÊ∫êÁ±ªÂûãÊîØÊåÅ**ÔºöËßÜÈ¢ë / Èü≥È¢ë / ÂõæÁâá / m3u8 / Áõ¥Êí≠ÊµÅÁ≠â
- üì± **Âπ≥Âè∞ÂÖºÂÆπÂπøÊ≥õ**ÔºöÊîØÊåÅÂæÆ‰ø°ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÈÖ∑ÁãóÈü≥‰πê„ÄÅQQÈü≥‰πêÁ≠â
- üåç **‰ª£ÁêÜÊäìÂåÖ**ÔºöÊîØÊåÅËÆæÁΩÆ‰ª£ÁêÜËé∑ÂèñÂèóÈôêÁΩëÁªú‰∏ãÁöÑËµÑÊ∫ê

## üìö ÊñáÊ°£ &amp; ÁâàÊú¨

- üìò [Âú®Á∫øÊñáÊ°£](https://res.putyy.com/)
- üí¨ [Âä†ÂÖ•‰∫§ÊµÅÁæ§](https://www.putyy.com/app/admin/upload/img/20250418/6801d9554dc7.webp)
- üß© [ÊúÄÊñ∞Áâà](https://github.com/putyy/res-downloader/releases) ÔΩú [MiniÁâà ‰ΩøÁî®ÈªòËÆ§ÊµèËßàÂô®Â±ïÁ§∫UI](https://github.com/putyy/resd-mini) ÔΩú [ElectronÊóßÁâà ÊîØÊåÅWin7](https://github.com/putyy/res-downloader/tree/old)
  &gt; *Áæ§Êª°Êó∂ÂèØÂä†ÂæÆ‰ø° `AmorousWorld`ÔºåËØ∑Â§áÊ≥®‚ÄúÊù•Ê∫ê‚Äù*

## üß© ‰∏ãËΩΩÂú∞ÂùÄ

- üÜï [GitHub ‰∏ãËΩΩ](https://github.com/putyy/res-downloader/releases)
- üÜï [ËìùÂ•è‰∫ë‰∏ãËΩΩÔºàÂØÜÁ†ÅÔºö9vs5Ôºâ](https://wwjv.lanzoum.com/b04wgtfyb)
- ‚ö†Ô∏è *Win7 Áî®Êà∑ËØ∑‰∏ãËΩΩ `2.3.0` ÁâàÊú¨*


## üñºÔ∏è È¢ÑËßà

![È¢ÑËßà](docs/images/show.webp)

[![Powered by DartNode]( https://dartnode.com/branding/DN-Open-Source-sm.png)]( https://dartnode.com &quot;Powered by DartNode - Free VPS for Open Source&quot;)
--- 

## üöÄ ‰ΩøÁî®ÊñπÊ≥ï

&gt; ËØ∑Êåâ‰ª•‰∏ãÊ≠•È™§Êìç‰Ωú‰ª•Ê≠£Á°Æ‰ΩøÁî®ËΩØ‰ª∂Ôºö

1. ÂÆâË£ÖÊó∂Âä°ÂøÖ **ÂÖÅËÆ∏ÂÆâË£ÖËØÅ‰π¶Êñá‰ª∂** Âπ∂ **ÂÖÅËÆ∏ÁΩëÁªúËÆøÈóÆ**
2. ÊâìÂºÄËΩØ‰ª∂ ‚Üí È¶ñÈ°µÂ∑¶‰∏äËßíÁÇπÂáª **‚ÄúÂêØÂä®‰ª£ÁêÜ‚Äù**
3. ÈÄâÊã©Ë¶ÅËé∑ÂèñÁöÑËµÑÊ∫êÁ±ªÂûãÔºàÈªòËÆ§ÂÖ®ÈÉ®Ôºâ
4. Âú®Â§ñÈÉ®ÊâìÂºÄËµÑÊ∫êÈ°µÈù¢ÔºàÂ¶ÇËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÁΩëÈ°µÁ≠âÔºâ
5. ËøîÂõûËΩØ‰ª∂È¶ñÈ°µÔºåÂç≥ÂèØÁúãÂà∞ËµÑÊ∫êÂàóË°®

## ‚ùì Â∏∏ËßÅÈóÆÈ¢ò

### üì∫ m3u8 ËßÜÈ¢ëËµÑÊ∫ê

- Âú®Á∫øÈ¢ÑËßàÔºö[m3u8play](https://m3u8play.com/)
- ËßÜÈ¢ë‰∏ãËΩΩÔºö[m3u8-down](https://m3u8-down.gowas.cn/)

### üì° Áõ¥Êí≠ÊµÅËµÑÊ∫ê

- Êé®Ëçê‰ΩøÁî® [OBS](https://obsproject.com/) ËøõË°åÂΩïÂà∂ÔºàÊïôÁ®ãËØ∑ÁôæÂ∫¶Ôºâ

### üê¢ ‰∏ãËΩΩÊÖ¢„ÄÅÂ§ßÊñá‰ª∂Â§±Ë¥•Ôºü

- Êé®ËçêÂ∑•ÂÖ∑Ôºö
  - [Neat Download Manager](https://www.neatdownloadmanager.com/index.php/en/)
  - [Motrix](https://motrix.app/download)
- ËßÜÈ¢ëÂè∑ËµÑÊ∫ê‰∏ãËΩΩÂêéÂèØÂú®Êìç‰ΩúÈ°πÁÇπÂáª `ËßÜÈ¢ëËß£ÂØÜÔºàËßÜÈ¢ëÂè∑Ôºâ`

### üß© ËΩØ‰ª∂Êó†Ê≥ïÊã¶Êà™ËµÑÊ∫êÔºü

- Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°ÆËÆæÁΩÆÁ≥ªÁªü‰ª£ÁêÜÔºö  
  Âú∞ÂùÄÔºö127.0.0.1
  Á´ØÂè£Ôºö8899

### üåê ÂÖ≥Èó≠ËΩØ‰ª∂ÂêéÊó†Ê≥ï‰∏äÁΩëÔºü

- ÊâãÂä®ÂÖ≥Èó≠Á≥ªÁªü‰ª£ÁêÜËÆæÁΩÆ

### üß† Êõ¥Â§öÈóÆÈ¢ò

- [GitHub Issues](https://github.com/putyy/res-downloader/issues)
- [Áà±‰∫´ËÆ∫ÂùõËÆ®ËÆ∫Â∏ñ](https://s.gowas.cn/d/4089)

## üí° ÂÆûÁé∞ÂéüÁêÜ &amp; ÂàùË°∑

Êú¨Â∑•ÂÖ∑ÈÄöËøá‰ª£ÁêÜÊñπÂºèÂÆûÁé∞ÁΩëÁªúÊäìÂåÖÔºåÂπ∂Á≠õÈÄâÂèØÁî®ËµÑÊ∫ê„ÄÇ‰∏é Fiddler„ÄÅCharles„ÄÅÊµèËßàÂô® DevTools ÂéüÁêÜÁ±ª‰ººÔºå‰ΩÜÂØπËµÑÊ∫êËøõË°å‰∫ÜÊõ¥ÂèãÂ•ΩÁöÑÁ≠õÈÄâ„ÄÅÂ±ïÁ§∫ÂíåÂ§ÑÁêÜÔºåÂ§ßÂπÖÂ∫¶Èôç‰Ωé‰∫Ü‰ΩøÁî®Èó®ÊßõÔºåÊõ¥ÈÄÇÂêàÂ§ß‰ºóÁî®Êà∑‰ΩøÁî®„ÄÇ

---

## ‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé

&gt; Êú¨ËΩØ‰ª∂‰ªÖ‰æõÂ≠¶‰π†‰∏éÁ†îÁ©∂Áî®ÈÄîÔºåÁ¶ÅÊ≠¢Áî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÊàñËøùÊ≥ïÁî®ÈÄî„ÄÇ  
Â¶ÇÂõ†Ê≠§‰∫ßÁîüÁöÑ‰ªª‰ΩïÊ≥ïÂæãË¥£‰ªªÔºåÊ¶Ç‰∏é‰ΩúËÄÖÊó†ÂÖ≥ÔºÅ
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[samber/lo]]></title>
            <link>https://github.com/samber/lo</link>
            <guid>https://github.com/samber/lo</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[üí• A Lodash-style Go library based on Go 1.18+ Generics (map, filter, contains, find...)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/samber/lo">samber/lo</a></h1>
            <p>üí• A Lodash-style Go library based on Go 1.18+ Generics (map, filter, contains, find...)</p>
            <p>Language: Go</p>
            <p>Stars: 19,622</p>
            <p>Forks: 878</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>
# lo - Iterate over slices, maps, channels...

[![tag](https://img.shields.io/github/tag/samber/lo.svg)](https://github.com/samber/lo/releases)
![Go Version](https://img.shields.io/badge/Go-%3E%3D%201.18-%23007d9c)
[![GoDoc](https://godoc.org/github.com/samber/lo?status.svg)](https://pkg.go.dev/github.com/samber/lo)
![Build Status](https://github.com/samber/lo/actions/workflows/test.yml/badge.svg)
[![Go report](https://goreportcard.com/badge/github.com/samber/lo)](https://goreportcard.com/report/github.com/samber/lo)
[![Coverage](https://img.shields.io/codecov/c/github/samber/lo)](https://codecov.io/gh/samber/lo)
[![Contributors](https://img.shields.io/github/contributors/samber/lo)](https://github.com/samber/lo/graphs/contributors)
[![License](https://img.shields.io/github/license/samber/lo)](./LICENSE)

‚ú® **`samber/lo` is a Lodash-style Go library based on Go 1.18+ Generics.**

A utility library based on Go 1.18+ generics that makes it easier to work with slices, maps, strings, channels, and functions. It provides dozens of handy methods to simplify common coding tasks and improve code readability. It may look like [Lodash](https://github.com/lodash/lodash) in some aspects.

5 to 10 helpers may overlap with those from the Go standard library, in packages `slices` and `maps`. I feel this library is legitimate and offers many more valuable abstractions.

**See also:**

- [samber/do](https://github.com/samber/do): A dependency injection toolkit based on Go 1.18+ Generics
- [samber/mo](https://github.com/samber/mo): Monads based on Go 1.18+ Generics (Option, Result, Either...)

**Why this name?**

I wanted a **short name**, similar to &quot;Lodash&quot;, and no Go package uses this name.

![lo](img/logo-full.png)

## üöÄ Install

```sh
go get github.com/samber/lo@v1
```

This library is v1 and follows SemVer strictly.

No breaking changes will be made to exported APIs before v2.0.0.

This library has no dependencies outside the Go standard library.

## üí° Usage

You can import `lo` using:

```go
import (
    &quot;github.com/samber/lo&quot;
    lop &quot;github.com/samber/lo/parallel&quot;
    lom &quot;github.com/samber/lo/mutable&quot;
)
```

Then use one of the helpers below:

```go
names := lo.Uniq([]string{&quot;Samuel&quot;, &quot;John&quot;, &quot;Samuel&quot;})
// []string{&quot;Samuel&quot;, &quot;John&quot;}
```

### Tips for lazy developers

I cannot recommend it, but in case you are too lazy for repeating `lo.` everywhere, you can import the entire library into the namespace.

```go
import (
    . &quot;github.com/samber/lo&quot;
)
```

I take no responsibility on this junk. üòÅ üí©

## ü§† Spec

GoDoc: [https://godoc.org/github.com/samber/lo](https://godoc.org/github.com/samber/lo)

Supported helpers for slices:

- [Filter](#filter)
- [Map](#map)
- [UniqMap](#uniqmap)
- [FilterMap](#filtermap)
- [FlatMap](#flatmap)
- [Reduce](#reduce)
- [ReduceRight](#reduceright)
- [ForEach](#foreach)
- [ForEachWhile](#foreachwhile)
- [Times](#times)
- [Uniq](#uniq)
- [UniqBy](#uniqby)
- [GroupBy](#groupby)
- [GroupByMap](#groupbymap)
- [Chunk](#chunk)
- [PartitionBy](#partitionby)
- [Flatten](#flatten)
- [Interleave](#interleave)
- [Shuffle](#shuffle)
- [Reverse](#reverse)
- [Fill](#fill)
- [Repeat](#repeat)
- [RepeatBy](#repeatby)
- [KeyBy](#keyby)
- [SliceToMap / Associate](#slicetomap-alias-associate)
- [FilterSliceToMap](#filterslicetomap)
- [Keyify](#keyify)
- [Drop](#drop)
- [DropRight](#dropright)
- [DropWhile](#dropwhile)
- [DropRightWhile](#droprightwhile)
- [DropByIndex](#DropByIndex)
- [Reject](#reject)
- [RejectMap](#rejectmap)
- [FilterReject](#filterreject)
- [Count](#count)
- [CountBy](#countby)
- [CountValues](#countvalues)
- [CountValuesBy](#countvaluesby)
- [Subset](#subset)
- [Slice](#slice)
- [Replace](#replace)
- [ReplaceAll](#replaceall)
- [Compact](#compact)
- [IsSorted](#issorted)
- [IsSortedByKey](#issortedbykey)
- [Splice](#Splice)

Supported helpers for maps:

- [Keys](#keys)
- [UniqKeys](#uniqkeys)
- [HasKey](#haskey)
- [ValueOr](#valueor)
- [Values](#values)
- [UniqValues](#uniqvalues)
- [PickBy](#pickby)
- [PickByKeys](#pickbykeys)
- [PickByValues](#pickbyvalues)
- [OmitBy](#omitby)
- [OmitByKeys](#omitbykeys)
- [OmitByValues](#omitbyvalues)
- [Entries / ToPairs](#entries-alias-topairs)
- [FromEntries / FromPairs](#fromentries-alias-frompairs)
- [Invert](#invert)
- [Assign (merge of maps)](#assign)
- [MapKeys](#mapkeys)
- [MapValues](#mapvalues)
- [MapEntries](#mapentries)
- [MapToSlice](#maptoslice)
- [FilterMapToSlice](#FilterMapToSlice)

Supported math helpers:

- [Range / RangeFrom / RangeWithSteps](#range--rangefrom--rangewithsteps)
- [Clamp](#clamp)
- [Sum](#sum)
- [SumBy](#sumby)
- [Product](#product)
- [ProductBy](#productby)
- [Mean](#mean)
- [MeanBy](#meanby)

Supported helpers for strings:

- [RandomString](#randomstring)
- [Substring](#substring)
- [ChunkString](#chunkstring)
- [RuneLength](#runelength)
- [PascalCase](#pascalcase)
- [CamelCase](#camelcase)
- [KebabCase](#kebabcase)
- [SnakeCase](#snakecase)
- [Words](#words)
- [Capitalize](#capitalize)
- [Ellipsis](#ellipsis)

Supported helpers for tuples:

- [T2 -&gt; T9](#t2---t9)
- [Unpack2 -&gt; Unpack9](#unpack2---unpack9)
- [Zip2 -&gt; Zip9](#zip2---zip9)
- [ZipBy2 -&gt; ZipBy9](#zipby2---zipby9)
- [Unzip2 -&gt; Unzip9](#unzip2---unzip9)
- [UnzipBy2 -&gt; UnzipBy9](#unzipby2---unzipby9)
- [CrossJoin2 -&gt; CrossJoin2](#crossjoin2---crossjoin9)
- [CrossJoinBy2 -&gt; CrossJoinBy2](#crossjoinby2---crossjoinby9)

Supported helpers for time and duration:

- [Duration](#duration)
- [Duration0 -&gt; Duration10](#duration0---duration10)

Supported helpers for channels:

- [ChannelDispatcher](#channeldispatcher)
- [SliceToChannel](#slicetochannel)
- [Generator](#generator)
- [Buffer](#buffer)
- [BufferWithContext](#bufferwithcontext)
- [BufferWithTimeout](#bufferwithtimeout)
- [FanIn](#fanin)
- [FanOut](#fanout)

Supported intersection helpers:

- [Contains](#contains)
- [ContainsBy](#containsby)
- [Every](#every)
- [EveryBy](#everyby)
- [Some](#some)
- [SomeBy](#someby)
- [None](#none)
- [NoneBy](#noneby)
- [Intersect](#intersect)
- [Difference](#difference)
- [Union](#union)
- [Without](#without)
- [WithoutBy](#withoutby)
- [WithoutEmpty](#withoutempty)
- [WithoutNth](#withoutnth)
- [ElementsMatch](#ElementsMatch)
- [ElementsMatchBy](#ElementsMatchBy)

Supported search helpers:

- [IndexOf](#indexof)
- [LastIndexOf](#lastindexof)
- [Find](#find)
- [FindIndexOf](#findindexof)
- [FindLastIndexOf](#findlastindexof)
- [FindOrElse](#findorelse)
- [FindKey](#findkey)
- [FindKeyBy](#findkeyby)
- [FindUniques](#finduniques)
- [FindUniquesBy](#finduniquesby)
- [FindDuplicates](#findduplicates)
- [FindDuplicatesBy](#findduplicatesby)
- [Min](#min)
- [MinIndex](#minindex)
- [MinBy](#minby)
- [MinIndexBy](#minindexby)
- [Earliest](#earliest)
- [EarliestBy](#earliestby)
- [Max](#max)
- [MaxIndex](#maxindex)
- [MaxBy](#maxby)
- [MaxIndexBy](#maxindexby)
- [Latest](#latest)
- [LatestBy](#latestby)
- [First](#first)
- [FirstOrEmpty](#FirstOrEmpty)
- [FirstOr](#FirstOr)
- [Last](#last)
- [LastOrEmpty](#LastOrEmpty)
- [LastOr](#LastOr)
- [Nth](#nth)
- [NthOr](#nthor)
- [NthOrEmpty](#nthorempty)
- [Sample](#sample)
- [SampleBy](#sampleby)
- [Samples](#samples)
- [SamplesBy](#samplesby)

Conditional helpers:

- [Ternary](#ternary)
- [TernaryF](#ternaryf)
- [If / ElseIf / Else](#if--elseif--else)
- [Switch / Case / Default](#switch--case--default)

Type manipulation helpers:

- [IsNil](#isnil)
- [IsNotNil](#isnotnil)
- [ToPtr](#toptr)
- [Nil](#nil)
- [EmptyableToPtr](#emptyabletoptr)
- [FromPtr](#fromptr)
- [FromPtrOr](#fromptror)
- [ToSlicePtr](#tosliceptr)
- [FromSlicePtr](#fromsliceptr)
- [FromSlicePtrOr](#fromsliceptror)
- [ToAnySlice](#toanyslice)
- [FromAnySlice](#fromanyslice)
- [Empty](#empty)
- [IsEmpty](#isempty)
- [IsNotEmpty](#isnotempty)
- [Coalesce](#coalesce)
- [CoalesceOrEmpty](#coalesceorempty)
- [CoalesceSlice](#coalesceslice)
- [CoalesceSliceOrEmpty](#coalescesliceorempty)
- [CoalesceMap](#coalescemap)
- [CoalesceMapOrEmpty](#coalescemaporempty)

Function helpers:

- [Partial](#partial)
- [Partial2 -&gt; Partial5](#partial2---partial5)

Concurrency helpers:

- [Attempt](#attempt)
- [AttemptWhile](#attemptwhile)
- [AttemptWithDelay](#attemptwithdelay)
- [AttemptWhileWithDelay](#attemptwhilewithdelay)
- [Debounce](#debounce)
- [DebounceBy](#debounceby)
- [Throttle](#throttle)
- [ThrottleWithCount](#throttle)
- [ThrottleBy](#throttle)
- [ThrottleByWithCount](#throttle)
- [Synchronize](#synchronize)
- [Async](#async)
- [Transaction](#transaction)
- [WaitFor](#waitfor)
- [WaitForWithContext](#waitforwithcontext)

Error handling:

- [Validate](#validate)
- [Must](#must)
- [Try](#try)
- [Try1 -&gt; Try6](#try0-6)
- [TryOr](#tryor)
- [TryOr1 -&gt; TryOr6](#tryor0-6)
- [TryCatch](#trycatch)
- [TryWithErrorValue](#trywitherrorvalue)
- [TryCatchWithErrorValue](#trycatchwitherrorvalue)
- [ErrorsAs](#errorsas)
- [Assert](#assert)
- [Assertf](#assertf)

Constraints:

- Clonable

### Filter

Iterates over a collection and returns an array of all the elements the predicate function returns `true` for.

```go
even := lo.Filter([]int{1, 2, 3, 4}, func(x int, index int) bool {
    return x%2 == 0
})
// []int{2, 4}
```

[[play](https://go.dev/play/p/Apjg3WeSi7K)]

Mutable: like `lo.Filter()`, but the slice is updated in place.

```go
import lom &quot;github.com/samber/lo/mutable&quot;

list := []int{1, 2, 3, 4}
newList := lom.Filter(list, func(x int) bool {
    return x%2 == 0
})

list
// []int{2, 4, 3, 4}

newList
// []int{2, 4}
```

### Map

Manipulates a slice of one type and transforms it into a slice of another type:

```go
import &quot;github.com/samber/lo&quot;

lo.Map([]int64{1, 2, 3, 4}, func(x int64, index int) string {
    return strconv.FormatInt(x, 10)
})
// []string{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;}
```

[[play](https://go.dev/play/p/OkPcYAhBo0D)]

Parallel processing: like `lo.Map()`, but the mapper function is called in a goroutine. Results are returned in the same order.

```go
import lop &quot;github.com/samber/lo/parallel&quot;

lop.Map([]int64{1, 2, 3, 4}, func(x int64, _ int) string {
    return strconv.FormatInt(x, 10)
})
// []string{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;}
```

Mutable: like `lo.Map()`, but the slice is updated in place.

```go
import lom &quot;github.com/samber/lo/mutable&quot;

list := []int{1, 2, 3, 4}
lom.Map(list, func(x int) int {
    return x*2
})
// []int{2, 4, 6, 8}
```

### UniqMap

Manipulates a slice and transforms it to a slice of another type with unique values.

```go
type User struct {
    Name string
    Age  int
}
users := []User{{Name: &quot;Alex&quot;, Age: 10}, {Name: &quot;Alex&quot;, Age: 12}, {Name: &quot;Bob&quot;, Age: 11}, {Name: &quot;Alice&quot;, Age: 20}}

names := lo.UniqMap(users, func(u User, index int) string {
    return u.Name
})
// []string{&quot;Alex&quot;, &quot;Bob&quot;, &quot;Alice&quot;}
```

### FilterMap

Returns a slice which obtained after both filtering and mapping using the given callback function.

The callback function should return two values: the result of the mapping operation and whether the result element should be included or not.

```go
matching := lo.FilterMap([]string{&quot;cpu&quot;, &quot;gpu&quot;, &quot;mouse&quot;, &quot;keyboard&quot;}, func(x string, _ int) (string, bool) {
    if strings.HasSuffix(x, &quot;pu&quot;) {
        return &quot;xpu&quot;, true
    }
    return &quot;&quot;, false
})
// []string{&quot;xpu&quot;, &quot;xpu&quot;}
```

[[play](https://go.dev/play/p/-AuYXfy7opz)]

### FlatMap

Manipulates a slice and transforms and flattens it to a slice of another type. The transform function can either return a slice or a `nil`, and in the `nil` case no value is added to the final slice.

```go
lo.FlatMap([]int64{0, 1, 2}, func(x int64, _ int) []string {
    return []string{
        strconv.FormatInt(x, 10),
        strconv.FormatInt(x, 10),
    }
})
// []string{&quot;0&quot;, &quot;0&quot;, &quot;1&quot;, &quot;1&quot;, &quot;2&quot;, &quot;2&quot;}
```

[[play](https://go.dev/play/p/YSoYmQTA8-U)]

### Reduce

Reduces a collection to a single value. The value is calculated by accumulating the result of running each element in the collection through an accumulator function. Each successive invocation is supplied with the return value returned by the previous call.

```go
sum := lo.Reduce([]int{1, 2, 3, 4}, func(agg int, item int, _ int) int {
    return agg + item
}, 0)
// 10
```

[[play](https://go.dev/play/p/R4UHXZNaaUG)]

### ReduceRight

Like `lo.Reduce` except that it iterates over elements of collection from right to left.

```go
result := lo.ReduceRight([][]int{{0, 1}, {2, 3}, {4, 5}}, func(agg []int, item []int, _ int) []int {
    return append(agg, item...)
}, []int{})
// []int{4, 5, 2, 3, 0, 1}
```

[[play](https://go.dev/play/p/Fq3W70l7wXF)]

### ForEach

Iterates over elements of a collection and invokes the function over each element.

```go
import &quot;github.com/samber/lo&quot;

lo.ForEach([]string{&quot;hello&quot;, &quot;world&quot;}, func(x string, _ int) {
    println(x)
})
// prints &quot;hello\nworld\n&quot;
```

[[play](https://go.dev/play/p/oofyiUPRf8t)]

Parallel processing: like `lo.ForEach()`, but the callback is called as a goroutine.

```go
import lop &quot;github.com/samber/lo/parallel&quot;

lop.ForEach([]string{&quot;hello&quot;, &quot;world&quot;}, func(x string, _ int) {
    println(x)
})
// prints &quot;hello\nworld\n&quot; or &quot;world\nhello\n&quot;
```

### ForEachWhile

Iterates over collection elements and invokes iteratee for each element collection return value decide to continue or break, like do while().

```go
list := []int64{1, 2, -42, 4}

lo.ForEachWhile(list, func(x int64, _ int) bool {
	if x &lt; 0 {
		return false
	}
	fmt.Println(x)
	return true
})
// 1
// 2
```

[[play](https://go.dev/play/p/QnLGt35tnow)]

### Times

Times invokes the iteratee n times, returning an array of the results of each invocation. The iteratee is invoked with index as argument.

```go
import &quot;github.com/samber/lo&quot;

lo.Times(3, func(i int) string {
    return strconv.FormatInt(int64(i), 10)
})
// []string{&quot;0&quot;, &quot;1&quot;, &quot;2&quot;}
```

[[play](https://go.dev/play/p/vgQj3Glr6lT)]

Parallel processing: like `lo.Times()`, but callback is called in goroutine.

```go
import lop &quot;github.com/samber/lo/parallel&quot;

lop.Times(3, func(i int) string {
    return strconv.FormatInt(int64(i), 10)
})
// []string{&quot;0&quot;, &quot;1&quot;, &quot;2&quot;}
```

### Uniq

Returns a duplicate-free version of an array, in which only the first occurrence of each element is kept. The order of result values is determined by the order they occur in the array.

```go
uniqValues := lo.Uniq([]int{1, 2, 2, 1})
// []int{1, 2}
```

[[play](https://go.dev/play/p/DTzbeXZ6iEN)]

### UniqBy

Returns a duplicate-free version of an array, in which only the first occurrence of each element is kept. The order of result values is determined by the order they occur in the array. It accepts `iteratee` which is invoked for each element in array to generate the criterion by which uniqueness is computed.

```go
uniqValues := lo.UniqBy([]int{0, 1, 2, 3, 4, 5}, func(i int) int {
    return i%3
})
// []int{0, 1, 2}
```

[[play](https://go.dev/play/p/g42Z3QSb53u)]

### GroupBy

Returns an object composed of keys generated from the results of running each element of collection through iteratee.

```go
import lo &quot;github.com/samber/lo&quot;

groups := lo.GroupBy([]int{0, 1, 2, 3, 4, 5}, func(i int) int {
    return i%3
})
// map[int][]int{0: []int{0, 3}, 1: []int{1, 4}, 2: []int{2, 5}}
```

[[play](https://go.dev/play/p/XnQBd_v6brd)]

Parallel processing: like `lo.GroupBy()`, but callback is called in goroutine.

```go
import lop &quot;github.com/samber/lo/parallel&quot;

lop.GroupBy([]int{0, 1, 2, 3, 4, 5}, func(i int) int {
    return i%3
})
// map[int][]int{0: []int{0, 3}, 1: []int{1, 4}, 2: []int{2, 5}}
```

### GroupByMap

Returns an object composed of keys generated from the results of running each element of collection through iteratee.

```go
import lo &quot;github.com/samber/lo&quot;

groups := lo.GroupByMap([]int{0, 1, 2, 3, 4, 5}, func(i int) (int, int) {
    return i%3, i*2
})
// map[int][]int{0: []int{0, 6}, 1: []int{2, 8}, 2: []int{4, 10}}
```

### Chunk

Returns an array of elements split into groups the length of size. If array can&#039;t be split evenly, the final chunk will be the remaining elements.

```go
lo.Chunk([]int{0, 1, 2, 3, 4, 5}, 2)
// [][]int{{0, 1}, {2, 3}, {4, 5}}

lo.Chunk([]int{0, 1, 2, 3, 4, 5, 6}, 2)
// [][]int{{0, 1}, {2, 3}, {4, 5}, {6}}

lo.Chunk([]int{}, 2)
// [][]int{}

lo.Chunk([]int{0}, 2)
// [][]int{{0}}
```

[[play](https://go.dev/play/p/EeKl0AuTehH)]

### PartitionBy

Returns an array of elements split into groups. The order of grouped values is determined by the order they occur in collection. The grouping is generated from the results of running each element of collection through iteratee.

```go
import lo &quot;github.com/samber/lo&quot;

partitions := lo.PartitionBy([]int{-2, -1, 0, 1, 2, 3, 4, 5}, func(x int) string {
    if x &lt; 0 {
        return &quot;negative&quot;
    } else if x%2 == 0 {
        return &quot;even&quot;
    }
    return &quot;odd&quot;
})
// [][]int{{-2, -1}, {0, 2, 4}, {1, 3, 5}}
```

[[play](https://go.dev/play/p/NfQ_nGjkgXW)]

Parallel processing: like `lo.PartitionBy()`, but callback is called in goroutine. Results are returned in the same order.

```go
import lop &quot;github.com/samber/lo/parallel&quot;

partitions := lop.PartitionBy([]int{-2, -1, 0, 1, 2, 3, 4, 5}, func(x int) string {
    if x &lt; 0 {
        return &quot;negative&quot;
    } else if x%2 == 0 {
        return &quot;even&quot;
    }
    return &quot;odd&quot;
})
// [][]int{{-2, -1}, {0, 2, 4}, {1, 3, 5}}
```

### Flatten

Returns an array a single level deep.

```go
flat := lo.Flatten([][]int{{0, 1}, {2, 3, 4, 5}})
// []int{0, 1, 2, 3, 4, 5}
```

[[play](https://go.dev/play/p/rbp9ORaMpjw)]

### Interleave

Round-robin alternating input slices and sequentially appending value at index into result.

```go
interleaved := lo.Interleave([]int{1, 4, 7}, []int{2, 5, 8}, []int{3, 6, 9})
// []int{1, 2, 3, 4, 5, 6, 7, 8, 9}

interleaved := lo.Interleave([]int{1}, []int{2, 5, 8}, []int{3, 6}, []int{4, 7, 9, 10})
// []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}
```

[[play](https://go.dev/play/p/-RJkTLQEDVt)]

### Shuffle

Returns an array of shuffled values. Uses the Fisher-Yates shuffle algorithm.

‚ö†Ô∏è This helper is **mutable**.

```go
import lom &quot;github.com/samber/lo/mutable&quot;

list := []int{0, 1, 2, 3, 4, 5}
lom.Shuffle(list)

list
// []int{1, 4, 0, 3, 5, 2}
```

[[play](https://go.dev/play/p/2xb3WdLjeSJ)]

### Reverse

Reverses array so that the first element becomes the last, the second element becomes the second to last, and so on.

‚ö†Ô∏è This helper is **mutable**.

```go
import lom &quot;github.com/samber/lo/mutable&quot;

list := []int{0, 1, 2, 3, 4, 5}
lom.Reverse(list)

list
// []int{5, 4, 3, 2, 1, 0}
```

[[play](https://go.dev/play/p/O-M5pmCRgzV)]

### Fill

Fills elements of array with `initial` value.

```go
type foo struct {
  bar string
}

func (f foo) Clone() foo {
  return foo{f.bar}
}

initializedSlice := lo.Fill([]foo{foo{&quot;a&quot;}, foo{&quot;a&quot;}}, foo{&quot;b&quot;})
// []foo{foo{&quot;b&quot;}, foo{&quot;b&quot;}}
```

[[play](https://go.dev/play/p/VwR34GzqEub)]

### Repeat

Builds a slice with N copies of initial value.

```go
type foo struct {
  bar string
}

func (f foo) Clone() foo {
  return foo{f.bar}
}

slice := lo.Repeat(2, foo{&quot;a&quot;})
// []foo{foo{&quot;a&quot;}, foo{&quot;a&quot;}}
```

[[play](https://go.dev/play/p/g3uHXbmc3b6)]

### RepeatBy

Builds a slice with values returned by N calls of callback.

```go
slice := lo.RepeatBy(0, func (i int) string {
    return strconv.FormatInt(int64(math.Pow(float64(i), 2)), 10)
})
// []string{}

slice := lo.RepeatBy(5, func(i int) string {
    return strconv.FormatInt(int64(math.Pow(float64(i), 2)), 10)
})
// []string{&quot;0&quot;, &quot;1&quot;, &quot;4&quot;, &quot;9&quot;, &quot;16&quot;}
```

[[play](https://go.dev/play/p/ozZLCtX_hNU)]

### KeyBy

Transforms a slice or an array of structs to a map based on a pivot callback.

```go
m := lo.KeyBy([]string{&quot;a&quot;, &quot;aa&quot;, &quot;aaa&quot;}, func(str string) int {
    return len(str)
})
// map[int]string{1: &quot;a&quot;, 2: &quot;aa&quot;, 3: &quot;aaa&quot;}

type Character struct {
  dir  string
  code int
}
characters := []Character{
    {dir: &quot;left&quot;, code: 97},
    {dir: &quot;right&quot;, code: 100},
}
result := lo.KeyBy(characters, func(char Character) string {
    return string(rune(char.code))
})
//map[a:{dir:left code:97} d:{dir:right code:100}]
```

[[play](https://go.dev/play/p/mdaClUAT-zZ)]

### SliceToMap (alias: Associate)

Returns a map c

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[seaweedfs/seaweedfs]]></title>
            <link>https://github.com/seaweedfs/seaweedfs</link>
            <guid>https://github.com/seaweedfs/seaweedfs</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, cross-DC active-active replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/seaweedfs/seaweedfs">seaweedfs/seaweedfs</a></h1>
            <p>SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, cross-DC active-active replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding.</p>
            <p>Language: Go</p>
            <p>Stars: 24,874</p>
            <p>Forks: 2,422</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># SeaweedFS


[![Slack](https://img.shields.io/badge/slack-purple)](https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY)
[![Twitter](https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;label=Follow)](https://twitter.com/intent/follow?screen_name=seaweedfs)
[![Build Status](https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml)](https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml)
[![GoDoc](https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg)](https://godoc.org/github.com/seaweedfs/seaweedfs/weed)
[![Wiki](https://img.shields.io/badge/docs-wiki-blue.svg)](https://github.com/seaweedfs/seaweedfs/wiki)
[![Docker Pulls](https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800)](https://hub.docker.com/r/chrislusf/seaweedfs/)
[![SeaweedFS on Maven Central](https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client)](https://search.maven.org/search?q=g:com.github.chrislusf)
[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs)](https://artifacthub.io/packages/search?repo=seaweedfs)

![SeaweedFS Logo](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png)

&lt;h2 align=&quot;center&quot;&gt;&lt;a href=&quot;https://www.patreon.com/seaweedfs&quot;&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt;

SeaweedFS is an independent Apache-licensed open source project with its ongoing development made
possible entirely thanks to the support of these awesome [backers](https://github.com/seaweedfs/seaweedfs/blob/master/backers.md).
If you&#039;d like to grow SeaweedFS even stronger, please consider joining our
&lt;a href=&quot;https://www.patreon.com/seaweedfs&quot;&gt;sponsors on Patreon&lt;/a&gt;.

Your support will be really appreciated by me and other supporters!

&lt;!--
&lt;h4 align=&quot;center&quot;&gt;Platinum&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;&quot; target=&quot;_blank&quot;&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt;

### Gold Sponsors
[![nodion](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png)](https://www.nodion.com)
[![piknik](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png)](https://www.piknik.com)
[![keepsec](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png)](https://www.keepsec.ca)

---

- [Download Binaries for different platforms](https://github.com/seaweedfs/seaweedfs/releases/latest)
- [SeaweedFS on Slack](https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY)
- [SeaweedFS on Twitter](https://twitter.com/SeaweedFS)
- [SeaweedFS on Telegram](https://t.me/Seaweedfs) 
- [SeaweedFS on Reddit](https://www.reddit.com/r/SeaweedFS/)
- [SeaweedFS Mailing List](https://groups.google.com/d/forum/seaweedfs)
- [Wiki Documentation](https://github.com/seaweedfs/seaweedfs/wiki)
- [SeaweedFS White Paper](https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf)
- [SeaweedFS Introduction Slides 2025.5](https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing)
- [SeaweedFS Introduction Slides 2021.5](https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing)
- [SeaweedFS Introduction Slides 2019.3](https://www.slideshare.net/chrislusf/seaweedfs-introduction)

Table of Contents
=================

* [Quick Start](#quick-start)
    * [Quick Start for S3 API on Docker](#quick-start-for-s3-api-on-docker)
    * [Quick Start with Single Binary](#quick-start-with-single-binary)
    * [Quick Start SeaweedFS S3 on AWS](#quick-start-seaweedfs-s3-on-aws)
* [Introduction](#introduction)
* [Features](#features)
    * [Additional Features](#additional-features)
    * [Filer Features](#filer-features)
* [Example: Using Seaweed Object Store](#example-using-seaweed-object-store)
* [Architecture](#object-store-architecture)
* [Compared to Other File Systems](#compared-to-other-file-systems)
    * [Compared to HDFS](#compared-to-hdfs)
    * [Compared to GlusterFS, Ceph](#compared-to-glusterfs-ceph)
    * [Compared to GlusterFS](#compared-to-glusterfs)
    * [Compared to Ceph](#compared-to-ceph)
    * [Compared to Minio](#compared-to-minio)
* [Dev Plan](#dev-plan)
* [Installation Guide](#installation-guide)
* [Disk Related Topics](#disk-related-topics)
* [Benchmark](#benchmark)
* [License](#license)

# Quick Start #

## Quick Start for S3 API on Docker ##

`docker run -p 8333:8333 chrislusf/seaweedfs server -s3`

## Quick Start with Single Binary ##
* Download the latest binary from https://github.com/seaweedfs/seaweedfs/releases and unzip a single binary file `weed` or `weed.exe`. Or run `go install github.com/seaweedfs/seaweedfs/weed@latest`.
* Run `weed server -dir=/some/data/dir -s3` to start one master, one volume server, one filer, and one S3 gateway.

Also, to increase capacity, just add more volume servers by running `weed volume -dir=&quot;/some/data/dir2&quot; -mserver=&quot;&lt;master_host&gt;:9333&quot; -port=8081` locally, or on a different machine, or on thousands of machines. That is it!

## Quick Start SeaweedFS S3 on AWS ##
* Setup fast production-ready [SeaweedFS S3 on AWS with cloudformation](https://aws.amazon.com/marketplace/pp/prodview-nzelz5gprlrjc)

# Introduction #

SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:

1. to store billions of files!
2. to serve the files fast!

SeaweedFS started as an Object Store to handle small files efficiently. 
Instead of managing all file metadata in a central master, 
the central master only manages volumes on volume servers, 
and these volume servers manage files and their metadata. 
This relieves concurrency pressure from the central master and spreads file metadata into volume servers, 
allowing faster file access (O(1), usually just one disk read operation).

There is only 40 bytes of disk storage overhead for each file&#039;s metadata. 
It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.

SeaweedFS started by implementing [Facebook&#039;s Haystack design paper](http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf). 
Also, SeaweedFS implements erasure coding with ideas from 
[f4: Facebook‚Äôs Warm BLOB Storage System](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf), and has a lot of similarities with [Facebook‚Äôs Tectonic Filesystem](https://www.usenix.org/system/files/fast21-pan.pdf)

On top of the object store, optional [Filer] can support directories and POSIX attributes. 
Filer is a separate linearly-scalable stateless server with customizable metadata stores, 
e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.

For any distributed key value stores, the large values can be offloaded to SeaweedFS. 
With the fast access speed and linearly scalable capacity, 
SeaweedFS can work as a distributed [Key-Large-Value store][KeyLargeValueStore].

SeaweedFS can transparently integrate with the cloud. 
With hot data on local cluster, and warm data on the cloud with O(1) access time, 
SeaweedFS can achieve both fast local access time and elastic cloud storage capacity.
What&#039;s more, the cloud storage access API cost is minimized. 
Faster and cheaper than direct cloud storage!

[Back to TOC](#table-of-contents)

# Features #
## Additional Features ##
* Can choose no replication or different replication levels, rack and data center aware.
* Automatic master servers failover - no single point of failure (SPOF).
* Automatic Gzip compression depending on file MIME type.
* Automatic compaction to reclaim disk space after deletion or update.
* [Automatic entry TTL expiration][VolumeServerTTL].
* Any server with some disk space can add to the total storage space.
* Adding/Removing servers does **not** cause any data re-balancing unless triggered by admin commands.
* Optional picture resizing.
* Support ETag, Accept-Range, Last-Modified, etc.
* Support in-memory/leveldb/readonly mode tuning for memory/performance balance.
* Support rebalancing the writable and readonly volumes.
* [Customizable Multiple Storage Tiers][TieredStorage]: Customizable storage disk types to balance performance and cost.
* [Transparent cloud integration][CloudTier]: unlimited capacity via tiered cloud storage for warm data.
* [Erasure Coding for warm storage][ErasureCoding]  Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.

[Back to TOC](#table-of-contents)

## Filer Features ##
* [Filer server][Filer] provides &quot;normal&quot; directories and files via HTTP.
* [File TTL][FilerTTL] automatically expires file metadata and actual file data.
* [Mount filer][Mount] reads and writes files directly as a local directory via FUSE.
* [Filer Store Replication][FilerStoreReplication] enables HA for filer meta data stores.
* [Active-Active Replication][ActiveActiveAsyncReplication] enables asynchronous one-way or two-way cross cluster continuous replication.
* [Amazon S3 compatible API][AmazonS3API] accesses files with S3 tooling.
* [Hadoop Compatible File System][Hadoop] accesses files from Hadoop/Spark/Flink/etc or even runs HBase.
* [Async Replication To Cloud][BackupToCloud] has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.
* [WebDAV] accesses as a mapped drive on Mac and Windows, or from mobile devices.
* [AES256-GCM Encrypted Storage][FilerDataEncryption] safely stores the encrypted data.
* [Super Large Files][SuperLargeFiles] stores large or super large files in tens of TB.
* [Cloud Drive][CloudDrive] mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.
* [Gateway to Remote Object Store][GatewayToRemoteObjectStore] mirrors bucket operations to remote object storage, in addition to [Cloud Drive][CloudDrive]

## Kubernetes ##
* [Kubernetes CSI Driver][SeaweedFsCsiDriver] A Container Storage Interface (CSI) Driver. [![Docker Pulls](https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800)](https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/)
* [SeaweedFS Operator](https://github.com/seaweedfs/seaweedfs-operator)

[Filer]: https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files
[SuperLargeFiles]: https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files
[Mount]: https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount
[AmazonS3API]: https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API
[BackupToCloud]: https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud
[Hadoop]: https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System
[WebDAV]: https://github.com/seaweedfs/seaweedfs/wiki/WebDAV
[ErasureCoding]: https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage
[TieredStorage]: https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage
[CloudTier]: https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier
[FilerDataEncryption]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption
[FilerTTL]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores
[VolumeServerTTL]: https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live
[SeaweedFsCsiDriver]: https://github.com/seaweedfs/seaweedfs-csi-driver
[ActiveActiveAsyncReplication]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization
[FilerStoreReplication]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication
[KeyLargeValueStore]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store
[CloudDrive]: https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture
[GatewayToRemoteObjectStore]: https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage


[Back to TOC](#table-of-contents)

## Example: Using Seaweed Object Store ##

By default, the master node runs on port 9333, and the volume nodes run on port 8080.
Let&#039;s start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We&#039;ll use localhost as an example.

SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.

### Start Master Server ###

```
&gt; ./weed master
```

### Start Volume Servers ###

```
&gt; weed volume -dir=&quot;/tmp/data1&quot; -max=5  -mserver=&quot;localhost:9333&quot; -port=8080 &amp;
&gt; weed volume -dir=&quot;/tmp/data2&quot; -max=10 -mserver=&quot;localhost:9333&quot; -port=8081 &amp;
```

### Write File ###

To upload a file: first, send a HTTP POST, PUT, or GET request to `/dir/assign` to get an `fid` and a volume server URL:

```
&gt; curl http://localhost:9333/dir/assign
{&quot;count&quot;:1,&quot;fid&quot;:&quot;3,01637037d6&quot;,&quot;url&quot;:&quot;127.0.0.1:8080&quot;,&quot;publicUrl&quot;:&quot;localhost:8080&quot;}
```

Second, to store the file content, send a HTTP multi-part POST request to `url + &#039;/&#039; + fid` from the response:

```
&gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{&quot;name&quot;:&quot;myphoto.jpg&quot;,&quot;size&quot;:43234,&quot;eTag&quot;:&quot;1cc0118e&quot;}
```

To update, send another POST request with updated file content.

For deletion, send an HTTP DELETE request to the same `url + &#039;/&#039; + fid` URL:

```
&gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
```

### Save File Id ###

Now, you can save the `fid`, 3,01637037d6 in this case, to a database field.

The number 3 at the start represents a volume id. After the comma, it&#039;s one file key, 01, and a file cookie, 637037d6.

The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.

The file key and file cookie are both coded in hex. You can store the &lt;volume id, file key, file cookie&gt; tuple in your own format, or simply store the `fid` as a string.

If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.

If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.

### Read File ###

Here is an example of how to render the URL.

First look up the volume server&#039;s URLs by the file&#039;s volumeId:

```
&gt; curl http://localhost:9333/dir/lookup?volumeId=3
{&quot;volumeId&quot;:&quot;3&quot;,&quot;locations&quot;:[{&quot;publicUrl&quot;:&quot;localhost:8080&quot;,&quot;url&quot;:&quot;localhost:8080&quot;}]}
```

Since (usually) there are not too many volume servers, and volumes don&#039;t move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.

Now you can take the public URL, render the URL or directly read from the volume server via URL:

```
 http://localhost:8080/3,01637037d6.jpg
```

Notice we add a file extension &quot;.jpg&quot; here. It&#039;s optional and just one way for the client to specify the file content type.

If you want a nicer URL, you can use one of these alternative URL formats:

```
 http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
```

If you want to get a scaled version of an image, you can add some params:

```
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200&amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200&amp;mode=fill
```

### Rack-Aware and Data Center-Aware Replication ###

SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:

```
curl http://localhost:9333/dir/assign?replication=001
```

The replication parameter options are:

```
000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
```

More details about replication can be found [on the wiki][Replication].

[Replication]: https://github.com/seaweedfs/seaweedfs/wiki/Replication

You can also set the default replication strategy when starting the master server.

### Allocate File Key on Specific Data Center ###

Volume servers can be started with a specific data center name:

```
 weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
```

When requesting a file key, an optional &quot;dataCenter&quot; parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to &#039;dc1&#039;:

```
 http://localhost:9333/dir/assign?dataCenter=dc1
```

### Other Features ###
  * [No Single Point of Failure][feat-1]
  * [Insert with your own keys][feat-2]
  * [Chunking large files][feat-3]
  * [Collection as a Simple Name Space][feat-4]

[feat-1]: https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server
[feat-2]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys
[feat-3]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files
[feat-4]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space

[Back to TOC](#table-of-contents)

## Object Store Architecture ##

Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.

The main drawback is that the central master can&#039;t handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.

Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.

The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.

For comparison, consider that an xfs inode structure in Linux is 536 bytes.

### Master Server and Volume Server ###

The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.

All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.

On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.

### Write and Read files ###

When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.

When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for the (volume node URL, volume node public URL), or retrieves this from a cache. Then the client can GET the content, or just render the URL on web pages 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[redis/go-redis]]></title>
            <link>https://github.com/redis/go-redis</link>
            <guid>https://github.com/redis/go-redis</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Redis Go client]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/redis/go-redis">redis/go-redis</a></h1>
            <p>Redis Go client</p>
            <p>Language: Go</p>
            <p>Stars: 20,981</p>
            <p>Forks: 2,448</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># Redis client for Go

[![build workflow](https://github.com/redis/go-redis/actions/workflows/build.yml/badge.svg)](https://github.com/redis/go-redis/actions)
[![PkgGoDev](https://pkg.go.dev/badge/github.com/redis/go-redis/v9)](https://pkg.go.dev/github.com/redis/go-redis/v9?tab=doc)
[![Documentation](https://img.shields.io/badge/redis-documentation-informational)](https://redis.uptrace.dev/)
[![Go Report Card](https://goreportcard.com/badge/github.com/redis/go-redis/v9)](https://goreportcard.com/report/github.com/redis/go-redis/v9)
[![codecov](https://codecov.io/github/redis/go-redis/graph/badge.svg?token=tsrCZKuSSw)](https://codecov.io/github/redis/go-redis)

[![Discord](https://img.shields.io/discord/697882427875393627.svg?style=social&amp;logo=discord)](https://discord.gg/W4txy5AeKM)
[![Twitch](https://img.shields.io/twitch/status/redisinc?style=social)](https://www.twitch.tv/redisinc)
[![YouTube](https://img.shields.io/youtube/channel/views/UCD78lHSwYqMlyetR0_P4Vig?style=social)](https://www.youtube.com/redisinc)
[![Twitter](https://img.shields.io/twitter/follow/redisinc?style=social)](https://twitter.com/redisinc)
[![Stack Exchange questions](https://img.shields.io/stackexchange/stackoverflow/t/go-redis?style=social&amp;logo=stackoverflow&amp;label=Stackoverflow)](https://stackoverflow.com/questions/tagged/go-redis)

&gt; go-redis is the official Redis client library for the Go programming language. It offers a straightforward interface for interacting with Redis servers. 

## Supported versions

In `go-redis` we are aiming to support the last three releases of Redis. Currently, this means we do support:
- [Redis 7.2](https://raw.githubusercontent.com/redis/redis/7.2/00-RELEASENOTES) - using Redis Stack 7.2 for modules support
- [Redis 7.4](https://raw.githubusercontent.com/redis/redis/7.4/00-RELEASENOTES) - using Redis Stack 7.4 for modules support
- [Redis 8.0](https://raw.githubusercontent.com/redis/redis/8.0/00-RELEASENOTES) - using Redis CE 8.0 where modules are included

Although the `go.mod` states it requires at minimum `go 1.18`, our CI is configured to run the tests against all three
versions of Redis and latest two versions of Go ([1.23](https://go.dev/doc/devel/release#go1.23.0),
[1.24](https://go.dev/doc/devel/release#go1.24.0)). We observe that some modules related test may not pass with
Redis Stack 7.2 and some commands are changed with Redis CE 8.0.
Please do refer to the documentation and the tests if you experience any issues. We do plan to update the go version
in the `go.mod` to `go 1.24` in one of the next releases.

## How do I Redis?

[Learn for free at Redis University](https://university.redis.com/)

[Build faster with the Redis Launchpad](https://launchpad.redis.com/)

[Try the Redis Cloud](https://redis.com/try-free/)

[Dive in developer tutorials](https://developer.redis.com/)

[Join the Redis community](https://redis.com/community/)

[Work at Redis](https://redis.com/company/careers/jobs/)

## Documentation

- [English](https://redis.uptrace.dev)
- [ÁÆÄ‰Ωì‰∏≠Êñá](https://redis.uptrace.dev/zh/)

## Resources

- [Discussions](https://github.com/redis/go-redis/discussions)
- [Chat](https://discord.gg/W4txy5AeKM)
- [Reference](https://pkg.go.dev/github.com/redis/go-redis/v9)
- [Examples](https://pkg.go.dev/github.com/redis/go-redis/v9#pkg-examples)

## Ecosystem

- [Redis Mock](https://github.com/go-redis/redismock)
- [Distributed Locks](https://github.com/bsm/redislock)
- [Redis Cache](https://github.com/go-redis/cache)
- [Rate limiting](https://github.com/go-redis/redis_rate)

This client also works with [Kvrocks](https://github.com/apache/incubator-kvrocks), a distributed
key value NoSQL database that uses RocksDB as storage engine and is compatible with Redis protocol.

## Features

- Redis commands except QUIT and SYNC.
- Automatic connection pooling.
- [StreamingCredentialsProvider (e.g. entra id, oauth)](#1-streaming-credentials-provider-highest-priority) (experimental)
- [Pub/Sub](https://redis.uptrace.dev/guide/go-redis-pubsub.html).
- [Pipelines and transactions](https://redis.uptrace.dev/guide/go-redis-pipelines.html).
- [Scripting](https://redis.uptrace.dev/guide/lua-scripting.html).
- [Redis Sentinel](https://redis.uptrace.dev/guide/go-redis-sentinel.html).
- [Redis Cluster](https://redis.uptrace.dev/guide/go-redis-cluster.html).
- [Redis Ring](https://redis.uptrace.dev/guide/ring.html).
- [Redis Performance Monitoring](https://redis.uptrace.dev/guide/redis-performance-monitoring.html).
- [Redis Probabilistic [RedisStack]](https://redis.io/docs/data-types/probabilistic/)

## Installation

go-redis supports 2 last Go versions and requires a Go version with
[modules](https://github.com/golang/go/wiki/Modules) support. So make sure to initialize a Go
module:

```shell
go mod init github.com/my/repo
```

Then install go-redis/**v9**:

```shell
go get github.com/redis/go-redis/v9
```

## Quickstart

```go
import (
    &quot;context&quot;
    &quot;fmt&quot;

    &quot;github.com/redis/go-redis/v9&quot;
)

var ctx = context.Background()

func ExampleClient() {
    rdb := redis.NewClient(&amp;redis.Options{
        Addr:     &quot;localhost:6379&quot;,
        Password: &quot;&quot;, // no password set
        DB:       0,  // use default DB
    })

    err := rdb.Set(ctx, &quot;key&quot;, &quot;value&quot;, 0).Err()
    if err != nil {
        panic(err)
    }

    val, err := rdb.Get(ctx, &quot;key&quot;).Result()
    if err != nil {
        panic(err)
    }
    fmt.Println(&quot;key&quot;, val)

    val2, err := rdb.Get(ctx, &quot;key2&quot;).Result()
    if err == redis.Nil {
        fmt.Println(&quot;key2 does not exist&quot;)
    } else if err != nil {
        panic(err)
    } else {
        fmt.Println(&quot;key2&quot;, val2)
    }
    // Output: key value
    // key2 does not exist
}
```

### Authentication

The Redis client supports multiple ways to provide authentication credentials, with a clear priority order. Here are the available options:

#### 1. Streaming Credentials Provider (Highest Priority) - Experimental feature

The streaming credentials provider allows for dynamic credential updates during the connection lifetime. This is particularly useful for managed identity services and token-based authentication.

```go
type StreamingCredentialsProvider interface {
    Subscribe(listener CredentialsListener) (Credentials, UnsubscribeFunc, error)
}

type CredentialsListener interface {
    OnNext(credentials Credentials)  // Called when credentials are updated
    OnError(err error)              // Called when an error occurs
}

type Credentials interface {
    BasicAuth() (username string, password string)
    RawCredentials() string
}
```

Example usage:
```go
rdb := redis.NewClient(&amp;redis.Options{
    Addr: &quot;localhost:6379&quot;,
    StreamingCredentialsProvider: &amp;MyCredentialsProvider{},
})
```

**Note:** The streaming credentials provider can be used with [go-redis-entraid](https://github.com/redis/go-redis-entraid) to enable Entra ID (formerly Azure AD) authentication. This allows for seamless integration with Azure&#039;s managed identity services and token-based authentication.

Example with Entra ID:
```go
import (
    &quot;github.com/redis/go-redis/v9&quot;
    &quot;github.com/redis/go-redis-entraid&quot;
)

// Create an Entra ID credentials provider
provider := entraid.NewDefaultAzureIdentityProvider()

// Configure Redis client with Entra ID authentication
rdb := redis.NewClient(&amp;redis.Options{
    Addr: &quot;your-redis-server.redis.cache.windows.net:6380&quot;,
    StreamingCredentialsProvider: provider,
    TLSConfig: &amp;tls.Config{
        MinVersion: tls.VersionTLS12,
    },
})
```

#### 2. Context-based Credentials Provider

The context-based provider allows credentials to be determined at the time of each operation, using the context.

```go
rdb := redis.NewClient(&amp;redis.Options{
    Addr: &quot;localhost:6379&quot;,
    CredentialsProviderContext: func(ctx context.Context) (string, string, error) {
        // Return username, password, and any error
        return &quot;user&quot;, &quot;pass&quot;, nil
    },
})
```

#### 3. Regular Credentials Provider

A simple function-based provider that returns static credentials.

```go
rdb := redis.NewClient(&amp;redis.Options{
    Addr: &quot;localhost:6379&quot;,
    CredentialsProvider: func() (string, string) {
        // Return username and password
        return &quot;user&quot;, &quot;pass&quot;
    },
})
```

#### 4. Username/Password Fields (Lowest Priority)

The most basic way to provide credentials is through the `Username` and `Password` fields in the options.

```go
rdb := redis.NewClient(&amp;redis.Options{
    Addr:     &quot;localhost:6379&quot;,
    Username: &quot;user&quot;,
    Password: &quot;pass&quot;,
})
```

#### Priority Order

The client will use credentials in the following priority order:
1. Streaming Credentials Provider (if set)
2. Context-based Credentials Provider (if set)
3. Regular Credentials Provider (if set)
4. Username/Password fields (if set)

If none of these are set, the client will attempt to connect without authentication.

### Protocol Version

The client supports both RESP2 and RESP3 protocols. You can specify the protocol version in the options:

```go
rdb := redis.NewClient(&amp;redis.Options{
    Addr:     &quot;localhost:6379&quot;,
    Password: &quot;&quot;, // no password set
    DB:       0,  // use default DB
    Protocol: 3,  // specify 2 for RESP 2 or 3 for RESP 3
})
```

### Connecting via a redis url

go-redis also supports connecting via the
[redis uri specification](https://github.com/redis/redis-specifications/tree/master/uri/redis.txt).
The example below demonstrates how the connection can easily be configured using a string, adhering
to this specification.

```go
import (
    &quot;github.com/redis/go-redis/v9&quot;
)

func ExampleClient() *redis.Client {
    url := &quot;redis://user:password@localhost:6379/0?protocol=3&quot;
    opts, err := redis.ParseURL(url)
    if err != nil {
        panic(err)
    }

    return redis.NewClient(opts)
}

```

### Instrument with OpenTelemetry

```go
import (
    &quot;github.com/redis/go-redis/v9&quot;
    &quot;github.com/redis/go-redis/extra/redisotel/v9&quot;
    &quot;errors&quot;
)

func main() {
    ...
    rdb := redis.NewClient(&amp;redis.Options{...})

    if err := errors.Join(redisotel.InstrumentTracing(rdb), redisotel.InstrumentMetrics(rdb)); err != nil {
        log.Fatal(err)
    }
```


### Advanced Configuration

go-redis supports extending the client identification phase to allow projects to send their own custom client identification.

#### Default Client Identification

By default, go-redis automatically sends the client library name and version during the connection process. This feature is available in redis-server as of version 7.2. As a result, the command is &quot;fire and forget&quot;, meaning it should fail silently, in the case that the redis server does not support this feature.

#### Disabling Identity Verification

When connection identity verification is not required or needs to be explicitly disabled, a `DisableIdentity` configuration option exists.
Initially there was a typo and the option was named `DisableIndentity` instead of `DisableIdentity`. The misspelled option is marked as Deprecated and will be removed in V10 of this library.
Although both options will work at the moment, the correct option is `DisableIdentity`. The deprecated option will be removed in V10 of this library, so please use the correct option name to avoid any issues.

To disable verification, set the `DisableIdentity` option to `true` in the Redis client options:

```go
rdb := redis.NewClient(&amp;redis.Options{
    Addr:            &quot;localhost:6379&quot;,
    Password:        &quot;&quot;,
    DB:              0,
    DisableIdentity: true, // Disable set-info on connect
})
```

#### Unstable RESP3 Structures for RediSearch Commands
When integrating Redis with application functionalities using RESP3, it&#039;s important to note that some response structures aren&#039;t final yet. This is especially true for more complex structures like search and query results. We recommend using RESP2 when using the search and query capabilities, but we plan to stabilize the RESP3-based API-s in the coming versions. You can find more guidance in the upcoming release notes.

To enable unstable RESP3, set the option in your client configuration:

```go
redis.NewClient(&amp;redis.Options{
			UnstableResp3: true,
		})
```
**Note:** When UnstableResp3 mode is enabled, it&#039;s necessary to use RawResult() and RawVal() to retrieve a raw data.
          Since, raw response is the only option for unstable search commands Val() and Result() calls wouldn&#039;t have any affect on them:

```go
res1, err := client.FTSearchWithArgs(ctx, &quot;txt&quot;, &quot;foo bar&quot;, &amp;redis.FTSearchOptions{}).RawResult()
val1 := client.FTSearchWithArgs(ctx, &quot;txt&quot;, &quot;foo bar&quot;, &amp;redis.FTSearchOptions{}).RawVal()
```

#### Redis-Search Default Dialect

In the Redis-Search module, **the default dialect is 2**. If needed, you can explicitly specify a different dialect using the appropriate configuration in your queries.

**Important**: Be aware that the query dialect may impact the results returned. If needed, you can revert to a different dialect version by passing the desired dialect in the arguments of the command you want to execute.
For example:
```
	res2, err := rdb.FTSearchWithArgs(ctx,
		&quot;idx:bicycle&quot;,
		&quot;@pickup_zone:[CONTAINS $bike]&quot;,
		&amp;redis.FTSearchOptions{
			Params: map[string]interface{}{
				&quot;bike&quot;: &quot;POINT(-0.1278 51.5074)&quot;,
			},
			DialectVersion: 3,
		},
	).Result()
```
You can find further details in the [query dialect documentation](https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/dialects/).

## Contributing
We welcome contributions to the go-redis library! If you have a bug fix, feature request, or improvement, please open an issue or pull request on GitHub.
We appreciate your help in making go-redis better for everyone.
If you are interested in contributing to the go-redis library, please check out our [contributing guidelines](CONTRIBUTING.md) for more information on how to get started.

## Look and feel

Some corner cases:

```go
// SET key value EX 10 NX
set, err := rdb.SetNX(ctx, &quot;key&quot;, &quot;value&quot;, 10*time.Second).Result()

// SET key value keepttl NX
set, err := rdb.SetNX(ctx, &quot;key&quot;, &quot;value&quot;, redis.KeepTTL).Result()

// SORT list LIMIT 0 2 ASC
vals, err := rdb.Sort(ctx, &quot;list&quot;, &amp;redis.Sort{Offset: 0, Count: 2, Order: &quot;ASC&quot;}).Result()

// ZRANGEBYSCORE zset -inf +inf WITHSCORES LIMIT 0 2
vals, err := rdb.ZRangeByScoreWithScores(ctx, &quot;zset&quot;, &amp;redis.ZRangeBy{
    Min: &quot;-inf&quot;,
    Max: &quot;+inf&quot;,
    Offset: 0,
    Count: 2,
}).Result()

// ZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3 AGGREGATE SUM
vals, err := rdb.ZInterStore(ctx, &quot;out&quot;, &amp;redis.ZStore{
    Keys: []string{&quot;zset1&quot;, &quot;zset2&quot;},
    Weights: []int64{2, 3}
}).Result()

// EVAL &quot;return {KEYS[1],ARGV[1]}&quot; 1 &quot;key&quot; &quot;hello&quot;
vals, err := rdb.Eval(ctx, &quot;return {KEYS[1],ARGV[1]}&quot;, []string{&quot;key&quot;}, &quot;hello&quot;).Result()

// custom command
res, err := rdb.Do(ctx, &quot;set&quot;, &quot;key&quot;, &quot;value&quot;).Result()
```

## Run the test

go-redis will start a redis-server and run the test cases.

The paths of redis-server bin file and redis config file are defined in `main_test.go`:

```go
var (
	redisServerBin, _  = filepath.Abs(filepath.Join(&quot;testdata&quot;, &quot;redis&quot;, &quot;src&quot;, &quot;redis-server&quot;))
	redisServerConf, _ = filepath.Abs(filepath.Join(&quot;testdata&quot;, &quot;redis&quot;, &quot;redis.conf&quot;))
)
```

For local testing, you can change the variables to refer to your local files, or create a soft link
to the corresponding folder for redis-server and copy the config file to `testdata/redis/`:

```shell
ln -s /usr/bin/redis-server ./go-redis/testdata/redis/src
cp ./go-redis/testdata/redis.conf ./go-redis/testdata/redis/
```

Lastly, run:

```shell
go test
```

Another option is to run your specific tests with an already running redis. The example below, tests
against a redis running on port 9999.:

```shell
REDIS_PORT=9999 go test &lt;your options&gt;
```

## See also

- [Golang ORM](https://bun.uptrace.dev) for PostgreSQL, MySQL, MSSQL, and SQLite
- [Golang PostgreSQL](https://bun.uptrace.dev/postgres/)
- [Golang HTTP router](https://bunrouter.uptrace.dev/)
- [Golang ClickHouse ORM](https://github.com/uptrace/go-clickhouse)

## Contributors

&gt; The go-redis project was originally initiated by :star: [**uptrace/uptrace**](https://github.com/uptrace/uptrace).
&gt; Uptrace is an open-source APM tool that supports distributed tracing, metrics, and logs. You can
&gt; use it to monitor applications and set up automatic alerts to receive notifications via email,
&gt; Slack, Telegram, and others.
&gt;
&gt; See [OpenTelemetry](https://github.com/redis/go-redis/tree/master/example/otel) example which
&gt; demonstrates how you can use Uptrace to monitor go-redis.

Thanks to all the people who already contributed!

&lt;a href=&quot;https://github.com/redis/go-redis/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=redis/go-redis&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[dagger/dagger]]></title>
            <link>https://github.com/dagger/dagger</link>
            <guid>https://github.com/dagger/dagger</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[An open-source runtime for composable workflows. Great for AI agents and CI/CD.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dagger/dagger">dagger/dagger</a></h1>
            <p>An open-source runtime for composable workflows. Great for AI agents and CI/CD.</p>
            <p>Language: Go</p>
            <p>Stars: 14,000</p>
            <p>Forks: 744</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>## What is Dagger?

Dagger is an open-source runtime for composable workflows. It&#039;s perfect for systems with many moving parts and a strong need for **repeatability**, **modularity**, **observability** and **cross-platform support**. This makes it a great choice for AI agents and CI/CD workflows.

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/static/img/current_docs/index/dagger-factory.jpg&quot; width=&quot;75%&quot;&gt;&lt;/p&gt;

## Key Features

- **Containerized Workflow Execution:** Transform code into containerized, composable operations. Build reproducible workflows in any language with custom environments, parallel processing, and seamless chaining.

- **Universal Type System:** Mix and match components from any language with type-safe connections. Use the best tools from each ecosystem without translation headaches.

- **Automatic Artifact Caching:** Operations produce cacheable, immutable artifacts ‚Äî even for LLMs and API calls. Your workflows run faster and cost less.

- **Built-in Observability:** Full visibility into operations with tracing, logs, and metrics. Debug complex workflows and know exactly what&#039;s happening.

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/static/img/current_docs/index/cloud-trace.gif&quot; width=&quot;60%&quot;&gt;&lt;/a&gt;

- **Open Platform:** Works with any compute platform and tech stack ‚Äî today and tomorrow. Ship faster, experiment freely, and don‚Äôt get locked into someone else&#039;s choices.

- **LLM Augmentation:** Native integration of any LLM that automatically discovers and uses available functions in your workflow. Ship mind-blowing agents in just a few dozen lines of code.

- **Interactive Terminal:** Directly interact with your workflow or agents in real-time through your terminal. Prototype, test, debug, and ship even faster.

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/static/img/current_docs/index/da-robots-white-box.svg&quot; width=&quot;60%&quot;&gt;&lt;/a&gt;

## Getting started

- [Dagger for AI Agents](https://docs.dagger.io/ai-agents)
- [Dagger for CI](https://docs.dagger.io/quickstart)

## Join the community

- Join the [Dagger community server](https://discord.gg/NpzVhsGnZu)
- Follow us on [Twitter](https://twitter.com/dagger_io)
- Check out our [community activities](https://dagger.io/community)
- Read more in our [documentation](https://docs.dagger.io)

## Contributing

Interested in contributing or building dagger from scratch? See
[CONTRIBUTING.md](https://github.com/dagger/dagger/tree/main/CONTRIBUTING.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Ingenimax/agent-sdk-go]]></title>
            <link>https://github.com/Ingenimax/agent-sdk-go</link>
            <guid>https://github.com/Ingenimax/agent-sdk-go</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:15 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Ingenimax/agent-sdk-go">Ingenimax/agent-sdk-go</a></h1>
            <p></p>
            <p>Language: Go</p>
            <p>Stars: 156</p>
            <p>Forks: 51</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/docs/img/logo-header.png#gh-light-mode-only&quot; alt=&quot;Ingenimax&quot; width=&quot;600&quot;&gt;
&lt;img src=&quot;/docs/img/logo-header-inverted.png#gh-dark-mode-only&quot; alt=&quot;Ingenimax&quot; width=&quot;600&quot;&gt;
&lt;/div&gt;

# Agent Go SDK

A powerful Go framework for building production-ready AI agents that seamlessly integrates memory management, tool execution, multi-LLM support, and enterprise features into a flexible, extensible architecture.

## Features

### Core Capabilities
- üß† **Multi-Model Intelligence**: Seamless integration with OpenAI, Anthropic, and Google Vertex AI (Gemini models).
- üîß **Modular Tool Ecosystem**: Expand agent capabilities with plug-and-play tools for web search, data retrieval, and custom operations
- üìù **Advanced Memory Management**: Persistent conversation tracking with buffer and vector-based retrieval options
- üîå **MCP Integration**: Support for Model Context Protocol (MCP) servers via HTTP and stdio transports

### Enterprise-Ready
- üö¶ **Built-in Guardrails**: Comprehensive safety mechanisms for responsible AI deployment
- üìà **Complete Observability**: Integrated tracing and logging for monitoring and debugging
- üè¢ **Enterprise Multi-tenancy**: Securely support multiple organizations with isolated resources

### Development Experience
- üõ†Ô∏è **Structured Task Framework**: Plan, approve, and execute complex multi-step operations
- üìÑ **Declarative Configuration**: Define sophisticated agents and tasks using intuitive YAML definitions
- üßô **Zero-Effort Bootstrapping**: Auto-generate complete agent configurations from simple system prompts

## Getting Started

### Prerequisites

- Go 1.23+
- Redis (optional, for distributed memory)

### Installation

Add the SDK to your Go project:

```bash
go get github.com/Ingenimax/agent-sdk-go
```

### Configuration

The SDK uses environment variables for configuration. Key variables include:

- `OPENAI_API_KEY`: Your OpenAI API key
- `OPENAI_MODEL`: The model to use (e.g., gpt-4o-mini)
- `LOG_LEVEL`: Logging level (debug, info, warn, error)
- `REDIS_ADDRESS`: Redis server address (if using Redis for memory)

See `.env.example` for a complete list of configuration options.

## Usage Examples

### Creating a Simple Agent

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/agent&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/config&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/openai&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/logging&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/memory&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/multitenancy&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/tools&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/tools/websearch&quot;
)

func main() {
	// Create a logger
	logger := logging.New()

	// Get configuration
	cfg := config.Get()

	// Create a new agent with OpenAI
	openaiClient := openai.NewClient(cfg.LLM.OpenAI.APIKey,
		openai.WithLogger(logger))

	agent, err := agent.NewAgent(
		agent.WithLLM(openaiClient),
		agent.WithMemory(memory.NewConversationBuffer()),
		agent.WithTools(createTools(logger).List()...),
		agent.WithSystemPrompt(&quot;You are a helpful AI assistant. When you don&#039;t know the answer or need real-time information, use the available tools to find the information.&quot;),
		agent.WithName(&quot;ResearchAssistant&quot;),
	)
	if err != nil {
		logger.Error(context.Background(), &quot;Failed to create agent&quot;, map[string]interface{}{&quot;error&quot;: err.Error()})
		return
	}

	// Create a context with organization ID and conversation ID
	ctx := context.Background()
	ctx = multitenancy.WithOrgID(ctx, &quot;default-org&quot;)
	ctx = context.WithValue(ctx, memory.ConversationIDKey, &quot;conversation-123&quot;)

	// Run the agent
	response, err := agent.Run(ctx, &quot;What&#039;s the weather in San Francisco?&quot;)
	if err != nil {
		logger.Error(ctx, &quot;Failed to run agent&quot;, map[string]interface{}{&quot;error&quot;: err.Error()})
		return
	}

	fmt.Println(response)
}

func createTools(logger logging.Logger) *tools.Registry {
	// Get configuration
	cfg := config.Get()

	// Create tools registry
	toolRegistry := tools.NewRegistry()

	// Add web search tool if API keys are available
	if cfg.Tools.WebSearch.GoogleAPIKey != &quot;&quot; &amp;&amp; cfg.Tools.WebSearch.GoogleSearchEngineID != &quot;&quot; {
		searchTool := websearch.New(
			cfg.Tools.WebSearch.GoogleAPIKey,
			cfg.Tools.WebSearch.GoogleSearchEngineID,
		)
		toolRegistry.Register(searchTool)
	}

	return toolRegistry
}
```

### Creating an Agent with YAML Configuration

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;log&quot;
	&quot;os&quot;
	&quot;path/filepath&quot;
	&quot;strings&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/agent&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/openai&quot;
)

func main() {
	// Get OpenAI API key from environment
	apiKey := os.Getenv(&quot;OPENAI_API_KEY&quot;)
	if apiKey == &quot;&quot; {
		log.Fatal(&quot;OpenAI API key not provided. Set OPENAI_API_KEY environment variable.&quot;)
	}

	// Create the LLM client
	llm := openai.NewClient(apiKey)

	// Load agent configurations
	agentConfigs, err := agent.LoadAgentConfigsFromFile(&quot;agents.yaml&quot;)
	if err != nil {
		log.Fatalf(&quot;Failed to load agent configurations: %v&quot;, err)
	}

	// Load task configurations
	taskConfigs, err := agent.LoadTaskConfigsFromFile(&quot;tasks.yaml&quot;)
	if err != nil {
		log.Fatalf(&quot;Failed to load task configurations: %v&quot;, err)
	}

	// Create variables map for template substitution
	variables := map[string]string{
		&quot;topic&quot;: &quot;Artificial Intelligence&quot;,
	}

	// Create the agent for a specific task
	taskName := &quot;research_task&quot;
	agent, err := agent.CreateAgentForTask(taskName, agentConfigs, taskConfigs, variables, agent.WithLLM(llm))
	if err != nil {
		log.Fatalf(&quot;Failed to create agent for task: %v&quot;, err)
	}

	// Execute the task
	fmt.Printf(&quot;Executing task &#039;%s&#039; with topic &#039;%s&#039;...\n&quot;, taskName, variables[&quot;topic&quot;])
	result, err := agent.ExecuteTaskFromConfig(context.Background(), taskName, taskConfigs, variables)
	if err != nil {
		log.Fatalf(&quot;Failed to execute task: %v&quot;, err)
	}

	// Print the result
	fmt.Println(&quot;\nTask Result:&quot;)
	fmt.Println(result)
}
```

Example YAML configurations:

**agents.yaml**:
```yaml
researcher:
  role: &gt;
    {topic} Senior Data Researcher
  goal: &gt;
    Uncover cutting-edge developments in {topic}
  backstory: &gt;
    You&#039;re a seasoned researcher with a knack for uncovering the latest
    developments in {topic}. Known for your ability to find the most relevant
    information and present it in a clear and concise manner.

reporting_analyst:
  role: &gt;
    {topic} Reporting Analyst
  goal: &gt;
    Create detailed reports based on {topic} data analysis and research findings
  backstory: &gt;
    You&#039;re a meticulous analyst with a keen eye for detail. You&#039;re known for
    your ability to turn complex data into clear and concise reports, making
    it easy for others to understand and act on the information you provide.
```

**tasks.yaml**:
```yaml
research_task:
  description: &gt;
    Conduct a thorough research about {topic}
    Make sure you find any interesting and relevant information given
    the current year is 2025.
  expected_output: &gt;
    A list with 10 bullet points of the most relevant information about {topic}
  agent: researcher

reporting_task:
  description: &gt;
    Review the context you got and expand each topic into a full section for a report.
    Make sure the report is detailed and contains any and all relevant information.
  expected_output: &gt;
    A fully fledged report with the main topics, each with a full section of information.
    Formatted as markdown without &#039;```&#039;
  agent: reporting_analyst
  output_file: &quot;{topic}_report.md&quot;
```

### Auto-Generating Agent Configurations

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;os&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/agent&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/config&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/openai&quot;
)

func main() {
	// Load configuration
	cfg := config.Get()

	// Create LLM client
	openaiClient := openai.NewClient(cfg.LLM.OpenAI.APIKey)

	// Create agent with auto-configuration from system prompt
	agent, err := agent.NewAgentWithAutoConfig(
		context.Background(),
		agent.WithLLM(openaiClient),
		agent.WithSystemPrompt(&quot;You are a travel advisor who helps users plan trips and vacations. You specialize in finding hidden gems and creating personalized itineraries based on travelers&#039; preferences.&quot;),
		agent.WithName(&quot;Travel Assistant&quot;),
	)
	if err != nil {
		panic(err)
	}

	// Access the generated configurations
	agentConfig := agent.GetGeneratedAgentConfig()
	taskConfigs := agent.GetGeneratedTaskConfigs()

	// Print generated agent details
	fmt.Printf(&quot;Generated Agent Role: %s\n&quot;, agentConfig.Role)
	fmt.Printf(&quot;Generated Agent Goal: %s\n&quot;, agentConfig.Goal)
	fmt.Printf(&quot;Generated Agent Backstory: %s\n&quot;, agentConfig.Backstory)

	// Print generated tasks
	fmt.Println(&quot;\nGenerated Tasks:&quot;)
	for taskName, taskConfig := range taskConfigs {
		fmt.Printf(&quot;- %s: %s\n&quot;, taskName, taskConfig.Description)
	}

	// Save the generated configurations to YAML files
	agentConfigMap := map[string]agent.AgentConfig{
		&quot;Travel Assistant&quot;: *agentConfig,
	}

	// Save agent configs to file
	agentYaml, _ := os.Create(&quot;agent_config.yaml&quot;)
	defer agentYaml.Close()
	agent.SaveAgentConfigsToFile(agentConfigMap, agentYaml)

	// Save task configs to file
	taskYaml, _ := os.Create(&quot;task_config.yaml&quot;)
	defer taskYaml.Close()
	agent.SaveTaskConfigsToFile(taskConfigs, taskYaml)

	// Use the auto-configured agent
	response, err := agent.Run(context.Background(), &quot;I want to plan a 3-day trip to Tokyo.&quot;)
	if err != nil {
		panic(err)
	}
	fmt.Println(response)
}
```

The auto-configuration feature uses LLM reasoning to derive a complete agent profile and associated tasks from a simple system prompt. The generated configurations include:

- **Agent Profile**: Role, goal, and backstory that define the agent&#039;s persona
- **Task Definitions**: Specialized tasks the agent can perform, with descriptions and expected outputs
- **Reusable YAML**: Save configurations for reuse in other applications

This approach dramatically reduces the effort needed to create specialized agents while ensuring consistency and quality.

### Using MCP Servers with an Agent

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;log&quot;
	&quot;os&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/agent&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/interfaces&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/openai&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/mcp&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/memory&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/multitenancy&quot;
)

func main() {
	logger := log.New(os.Stderr, &quot;AGENT: &quot;, log.LstdFlags)

	// Create OpenAI LLM client
	apiKey := os.Getenv(&quot;OPENAI_API_KEY&quot;)
	if apiKey == &quot;&quot; {
		logger.Fatal(&quot;Please set the OPENAI_API_KEY environment variable.&quot;)
	}
	llm := openai.NewClient(apiKey, openai.WithModel(&quot;gpt-4o-mini&quot;))

	// Create MCP servers
	var mcpServers []interfaces.MCPServer

	// Connect to HTTP-based MCP server
	httpServer, err := mcp.NewHTTPServer(context.Background(), mcp.HTTPServerConfig{
		BaseURL: &quot;http://localhost:8083/mcp&quot;,
	})
	if err != nil {
		logger.Printf(&quot;Warning: Failed to initialize HTTP MCP server: %v&quot;, err)
	} else {
		mcpServers = append(mcpServers, httpServer)
		logger.Println(&quot;Successfully initialized HTTP MCP server.&quot;)
	}

	// Connect to stdio-based MCP server
	stdioServer, err := mcp.NewStdioServer(context.Background(), mcp.StdioServerConfig{
		Command: &quot;go&quot;,
		Args:    []string{&quot;run&quot;, &quot;./server-stdio/main.go&quot;},
	})
	if err != nil {
		logger.Printf(&quot;Warning: Failed to initialize STDIO MCP server: %v&quot;, err)
	} else {
		mcpServers = append(mcpServers, stdioServer)
		logger.Println(&quot;Successfully initialized STDIO MCP server.&quot;)
	}

	// Create agent with MCP server support
	myAgent, err := agent.NewAgent(
		agent.WithLLM(llm),
		agent.WithMCPServers(mcpServers),
		agent.WithMemory(memory.NewConversationBuffer()),
		agent.WithSystemPrompt(&quot;You are an AI assistant that can use tools from MCP servers.&quot;),
		agent.WithName(&quot;MCPAgent&quot;),
	)
	if err != nil {
		logger.Fatalf(&quot;Failed to create agent: %v&quot;, err)
	}

	// Create context with organization and conversation IDs
	ctx := context.Background()
	ctx = multitenancy.WithOrgID(ctx, &quot;default-org&quot;)
	ctx = context.WithValue(ctx, memory.ConversationIDKey, &quot;mcp-demo&quot;)

	// Run the agent with a query that will use MCP tools
	response, err := myAgent.Run(ctx, &quot;What time is it right now?&quot;)
	if err != nil {
		logger.Fatalf(&quot;Agent run failed: %v&quot;, err)
	}

	fmt.Println(&quot;Agent response:&quot;, response)
}
```

## Architecture

The SDK follows a modular architecture with these key components:

- **Agent**: Coordinates the LLM, memory, and tools
- **LLM**: Interface to language model providers (OpenAI, Anthropic, Google Vertex AI)
- **Memory**: Stores conversation history and context
- **Tools**: Extend the agent&#039;s capabilities
- **Vector Store**: For semantic search and retrieval
- **Guardrails**: Ensures safe and responsible AI usage
- **Execution Plan**: Manages planning, approval, and execution of complex tasks
- **Configuration**: YAML-based agent and task definitions

### Supported LLM Providers

- **OpenAI**: GPT-4, GPT-3.5, and other OpenAI models
- **Anthropic**: Claude 3.5 Sonnet, Claude 3 Haiku, and other Claude models  
- **Google Vertex AI**: Gemini 1.5 Pro, Gemini 1.5 Flash, Gemini 2.0 Flash, and Gemini Pro Vision
  - Advanced reasoning modes (none, minimal, comprehensive)
  - Multimodal capabilities with vision models
  - Function calling and tool integration
  - Flexible authentication (ADC or service account files)

## Examples

Check out the `cmd/examples` directory for complete examples:

- **Simple Agent**: Basic agent with system prompt
- **YAML Configuration**: Defining agents and tasks in YAML
- **Auto-Configuration**: Generating agent configurations from system prompts
- **Agent Config Wizard**: Interactive CLI for creating and using agents
- **MCP Integration**: Using Model Context Protocol servers with agents
- **Multi-LLM Support**: Examples using OpenAI, Anthropic, and Vertex AI
- **Vertex AI Integration**: Comprehensive examples with Gemini models, reasoning modes, and tools

### LLM Provider Examples

- `examples/llm/openai/`: OpenAI integration examples
- `examples/llm/anthropic/`: Anthropic Claude integration examples  
- `examples/llm/vertex/`: Google Vertex AI integration examples with Gemini models

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Documentation

For more detailed information, refer to the following documents:

- [Environment Variables](docs/environment_variables.md)
- [Memory](docs/memory.md)
- [Tracing](docs/tracing.md)
- [Vector Store](docs/vectorstore.md)
- [LLM](docs/llm.md)
- [Multitenancy](docs/multitenancy.md)
- [Task](docs/task.md)
- [Tools](docs/tools.md)
- [Agent](docs/agent.md)
- [Execution Plan](docs/execution_plan.md)
- [Guardrails](docs/guardrails.md)
- [MCP](docs/mcp.md)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[bytebase/bytebase]]></title>
            <link>https://github.com/bytebase/bytebase</link>
            <guid>https://github.com/bytebase/bytebase</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[World's most advanced database DevSecOps solution for Developer, Security, DBA and Platform Engineering teams. The GitHub/GitLab for database DevSecOps.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytebase/bytebase">bytebase/bytebase</a></h1>
            <p>World's most advanced database DevSecOps solution for Developer, Security, DBA and Platform Engineering teams. The GitHub/GitLab for database DevSecOps.</p>
            <p>Language: Go</p>
            <p>Stars: 12,611</p>
            <p>Forks: 817</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a
    target=&quot;_blank&quot;
    href=&quot;https://www.bytebase.com?source=github&quot;
  &gt;
    &lt;img
      align=&quot;center&quot;
      alt=&quot;Bytebase&quot;
      src=&quot;https://raw.githubusercontent.com/bytebase/bytebase/main/docs/assets/banner.webp&quot;
      style=&quot;width:100%;&quot;
    /&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.bytebase.com/get-started/self-host&quot; target=&quot;_blank&quot;&gt;&lt;b&gt;‚öôÔ∏è Install&lt;/b&gt;&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://docs.bytebase.com/introduction/what-is-bytebase&quot;&gt;&lt;b&gt;üìö Docs&lt;/b&gt;&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://discord.gg/huyw7gRsyA&quot;&gt;&lt;b&gt;üí¨ Discord&lt;/b&gt;&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://www.bytebase.com/request-demo/&quot;&gt;&lt;b&gt;üôã‚Äç‚ôÄÔ∏è Book Demo&lt;/b&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/bytebase/bytebase&quot;&gt;
    &lt;img alt=&quot;go report&quot; src=&quot;https://goreportcard.com/badge/github.com/bytebase/bytebase&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://artifacthub.io/packages/search?repo=bytebase&quot;&gt;
    &lt;img alt=&quot;Artifact Hub&quot; src=&quot;https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/bytebase&quot; /&gt;
  &lt;/a&gt;
    &lt;a
    href=&quot;https://github.com/bytebase/bytebase&quot;
    target=&quot;_blank&quot;
  &gt;
    &lt;img alt=&quot;Github Stars&quot; src=&quot;https://img.shields.io/github/stars/bytebase/bytebase?logo=github&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt; Different &lt;/b&gt; database development tasks
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt; Multiple &lt;/b&gt; database systems
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt; Unified &lt;/b&gt; process
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt; Single &lt;/b&gt; tool
&lt;/p&gt;

&lt;br /&gt;

&lt;p align=&quot;center&quot; &gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/bytebase/bytebase/main/docs/assets/your-dev-vs-competitor-hitman.webp&quot; /&gt;
&lt;/p&gt;

&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/bytebase/bytebase/main/docs/assets/fish.webp&quot; /&gt;
&lt;/p&gt;

&lt;br /&gt;

&lt;p align=&quot;center&quot; &gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/bytebase/bytebase/main/docs/assets/change-query-secure-govern.webp&quot; /&gt;
&lt;/p&gt;

&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;ü™ú&lt;/p&gt;
&lt;h1 align=&quot;center&quot;&gt;Change&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;
  Want to formalize the database change process but don&#039;t know how?
&lt;/p&gt;

|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                                                                                                      |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |
| &lt;b&gt;Standard Operating Procedure (SOP) &lt;/b&gt;&lt;br /&gt;Standardize the database schema and data change process across different database systems, small or [large tables](https://docs.bytebase.com/change-database/online-schema-migration-for-mysql) and [different tenants](https://docs.bytebase.com/change-database/batch-change/#change-databases-from-multiple-tenants).&lt;br /&gt;&lt;br/&gt;&lt;b&gt;SQL Review&lt;/b&gt;&lt;br /&gt;[100+ lint rules](https://docs.bytebase.com/sql-review/review-rules) to detect SQL anti-patterns and enforce consistent SQL style in the organization.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;GitOps&lt;/b&gt;&lt;br /&gt;[Point-and-click GitHub and GitLab integration](https://docs.bytebase.com/vcs-integration/overview) to enable GitOps workflow for changing database. | &lt;img src=&quot;https://raw.githubusercontent.com/bytebase/bytebase/main/docs/assets/issue-detail.webp&quot; /&gt; |

&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;üîÆ&lt;/p&gt;
&lt;h1 align=&quot;center&quot;&gt;Query&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;
  Want to control the data access but don&#039;t know how?
&lt;/p&gt;

|                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                                                                                                    |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- |
| &lt;b&gt;All-in-one SQL Editor&lt;/b&gt;&lt;br /&gt;Web-based IDE specifically for performing SQL specific tasks.&lt;br /&gt;&lt;br/&gt;&lt;b&gt;Data Masking&lt;/b&gt;&lt;br /&gt;State-of-the-art [column level masking](https://docs.bytebase.com/sql-editor/mask-data) engine to cover complex situations like subquery, CTE.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Data Access Control&lt;/b&gt;&lt;br /&gt;Organization level policy to centralize the [database permission](https://docs.bytebase.com/security/database-permission/overview). | &lt;img src=&quot;https://raw.githubusercontent.com/bytebase/bytebase/main/docs/assets/sql-editor.webp&quot; /&gt; |

&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;üîí&lt;/p&gt;
&lt;h1 align=&quot;center&quot;&gt;Secure&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;
  Want to avoid data leakage, change outage and detect malicious behavior but don&#039;t know how?
&lt;/p&gt;

|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |                                                                                                      |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------- |
| &lt;b&gt;Centralize Change, Query and Admin Tasks&lt;/b&gt;&lt;br /&gt;A single place to perform different tasks on different databases, thus enforce policy and monitor activity accordingly. &lt;br /&gt;&lt;br /&gt;&lt;b&gt;RBAC&lt;/b&gt;&lt;br /&gt;[Two-level RBAC model](https://docs.bytebase.com/concepts/roles-and-permissions) mapping to the organization wide privileges and application team privileges respectively.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Drift detection and Audit Logging&lt;/b&gt;&lt;br /&gt; Capture all database schema drifts, user actions and system events and present them in a holistic view. | &lt;img src=&quot;https://raw.githubusercontent.com/bytebase/bytebase/main/docs/assets/grant-access.webp&quot; /&gt; |

&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;üë©‚Äçüíº&lt;/p&gt;
&lt;h1 align=&quot;center&quot;&gt;Govern&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;
  Want to enforce organization policy but don&#039;t know how?
&lt;/p&gt;

|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |                                                                                                           |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- |
| &lt;b&gt;Manage Database Resources&lt;/b&gt;&lt;br /&gt; A single place to manage environments, database instances, database users for application development, with optional [Terraform integration](https://registry.terraform.io/providers/bytebase/bytebase/latest/docs). &lt;br /&gt;&lt;br /&gt;&lt;b&gt;Policy Enforcement&lt;/b&gt;&lt;br /&gt;Enforce organization wide SQL Review policy, backup policy and data access policy.&lt;br /&gt;&lt;br/&gt;&lt;b&gt;SQL Editor Admin mode&lt;/b&gt;&lt;br /&gt;[CLI like experience](https://docs.bytebase.com/sql-editor/admin-mode) without setting up bastion. | &lt;img src=&quot;https://raw.githubusercontent.com/bytebase/bytebase/main/docs/assets/sql-review-policy.webp&quot; /&gt; |

&lt;br /&gt;

# üññ Intro

[![Watch the 30-second product video](https://raw.githubusercontent.com/bytebase/bytebase/main/docs/assets/product-video-thumbnail.webp)](https://www.youtube.com/watch?v=7UE78BufSLM)

Bytebase is a Database CI/CD solution for the Developers and DBAs. It&#039;s the **only database CI/CD project** included by the [CNCF Landscape](https://landscape.cncf.io/?selected=bytebase) and [Platform Engineering](https://platformengineering.org/tools/bytebase). The Bytebase family consists of these tools:

- [Bytebase Console](https://www.bytebase.com/?source=github): A web-based GUI for developers and DBAs to manage the database development lifecycle.
- [Bytebase API](https://docs.bytebase.com/api/overview): Provide both gRPC and RESTful API to manipulate every aspect of Bytebase.
- [SQL Review GitHub Action](https://github.com/bytebase/sql-review-action): The GitHub Action to detect SQL anti-patterns and enforce a consistent SQL style guide during Pull Request.
- [Terraform Bytebase Provider](https://registry.terraform.io/providers/bytebase/bytebase/latest/docs): The Terraform
  provider enables team to manage Bytebase resources via Terraform. A typical setup involves teams using
  Terraform to provision database instances from Cloud vendors, followed by using Bytebase provider to
  prepare those instances ready for application use.

|     | Topic                                                               |
| --- | :------------------------------------------------------------------ |
| üîß  | &lt;b&gt;[Installation](#-installation)&lt;/b&gt;                               |
| üéÆ  | &lt;b&gt;[Demo](#-demo)&lt;/b&gt;                                               |
| üë©‚Äçüè´  | &lt;b&gt;[Tutorials](#-tutorials)&lt;/b&gt;                                     |
| üíé  | &lt;b&gt;[Design Principles](#-design-principles)&lt;/b&gt;                     |
| üß©  | &lt;b&gt;[Data Model](#-data-model)&lt;/b&gt;                                   |
| üé≠  | &lt;b&gt;[Roles](#-roles)&lt;/b&gt;                                             |
| üïä   | &lt;b&gt;[Developing and Contributing](#-developing-and-contributing)&lt;/b&gt; |
| ü§∫  | &lt;b&gt;[Bytebase vs Alternatives](#-bytebase-vs-alternatives)&lt;/b&gt;       |

&lt;br /&gt;

# üîß Installation

- [Docker](https://docs.bytebase.com/get-started/self-host/)
- [Kubernetes](https://docs.bytebase.com/get-started/install/deploy-to-kubernetes)
- [Build from source](https://docs.bytebase.com/get-started/install/build-from-source-code)

&lt;br /&gt;

# üéÆ Demo

Live demo at https://demo.bytebase.com

You can also [book a 30min product walkthrough](https://cal.com/bytebase/product-walkthrough) with one of
our product experts.

&lt;br /&gt;

# üë©‚Äçüè´ Tutorials

Product tutorials are available at https://docs.bytebase.com/tutorials.

## Integrations

- [Manage Supabase PostgreSQL](https://docs.bytebase.com/integrations/supabase)
- [Manage render PostgreSQL](https://docs.bytebase.com/integrations/render)
- [Manage Neon database](https://docs.bytebase.com/integrations/neon)
- [Deploy to sealos](https://docs.bytebase.com/get-started/install/deploy-to-sealos)
- [Deploy to Rainbond](https://docs.bytebase.com/get-started/install/deploy-to-rainbond)

&lt;br /&gt;

# üíé Design Principles

|     |                         |                                                                                                                                                                                                                                                                                                                                                |
| --- | ----------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ü™∂  | Dependency Free         | Start with a single command `./bytebase` without any external dependency. External PostgreSQL data store and others are optional.                                                                                                                                                                                                              |
| üîó  | Integration First       | Solely focus on database management and leave the rest to others. We have native VCS integration with [GitHub/GitLab](https://docs.bytebase.com/vcs-integration/overview), [Terraform Provider](https://registry.terraform.io/providers/bytebase/bytebase/latest/docs), [webhook](https://docs.bytebase.com/change-database/webhook), and etc. |
| üíÇ‚Äç‚ôÄÔ∏è  | Engineering Disciplined | Disciplined [bi-weekly release](https://docs.bytebase.com/changelog) and [engineering practice](https://github.com/bytebase/bytebase/blob/main/docs/life-of-a-feature.md).                                                                                                                                                                     |

&lt;br /&gt;

# üß© Data Model

More details in [Data Model Doc](https://docs.bytebase.com/concepts/data-model).

&lt;p align=&quot;center&quot;&gt;
    &lt;img
      align=&quot;center&quot;
      alt=&quot;Data Model&quot;
      src=&quot;https://raw.githubusercontent.com/bytebase/bytebase/main/docs/assets/data-model-v2.webp&quot;
      style=&quot;width:100%;&quot;
    /&gt;
&lt;/p&gt;

&lt;br /&gt;

# üé≠ Roles

More details in [Roles and Permissions Doc](https://docs.bytebase.com/concepts/roles-and-permissions).

Bytebase employs RBAC (role based access control) and provides two role sets at the workspace and project level:

- Workspace roles: `Admin`, `DBA`, `Member`. The workspace role maps to the role in an organization.
- Project roles: `Owner`, `Developer`, `Releaser`, `SQL Editor User`, `Exporter`, `Viewer`. The project level role maps to the role in a specific team or project.

Every user is assigned a workspace role, and if a particular user is involved in a particular project, then she will also be assigned a project role accordingly.

Below diagram describes a typical mapping between an engineering org and the corresponding roles in the Bytebase workspace

&lt;p align=&quot;center&quot;&gt;
    &lt;img
      align=&quot;center&quot;
      alt=&quot;Role Mapping&quot;
      src=&quot;https://raw.githubusercontent.com/bytebase/bytebase/main/docs/assets/org-role-mapping.webp&quot;
      style=&quot;width:100%;&quot;
    /&gt;
&lt;/p&gt;

&lt;br /&gt;

# üïä Developing and Contributing

&lt;p align=&quot;center&quot;&gt;
    &lt;img
      align=&quot;center&quot;
      alt=&quot;Tech Stack&quot;
      src=&quot;https://raw.githubusercontent.com/bytebase/bytebase/main/docs/assets/techstack.webp&quot;
      style=&quot;width:100%;&quot;
    /&gt;
&lt;/p&gt;

- Bytebase is built with a curated tech stack. It is optimized for **developer experience** and is very easy to start
  working on the code:

  1. It has no external dependency.
  1. It requires zero config.
  1. 1 command to start backend and 1 command to start frontend, both with live reload support.

- Interactive code walkthrough

  - [Life of a schema change](https://sourcegraph.com/github.com/bytebase/bytebase/-/blob/docs/design/life-of-a-schema-change.snb.md)
  - [SQL Review](https://sourcegraph.com/github.com/bytebase/bytebase/-/blob/docs/design/sql-review-source-code-tour.snb.md)

- Follow [Life of a Feature](https://github.com/bytebase/bytebase/blob/main/docs/life-of-a-feature.md).

## Dev Environment Setup

### Prerequisites

- [Go](https://golang.org/doc/install)
- [pnpm](https://pnpm.io/installation)

### Steps

1. Pull source.

   ```bash
   git clone https://github.com/bytebase/bytebase
   ```

1. Create an external Postgres database on localhost.

   ```sql
   CREATE USER bbdev SUPERUSER;
   CREATE DATABASE bbdev;
   ```

1. Start backend.

   ```bash
   PG_URL=postgresql://bbdev@localhost/bbdev
   go build -ldflags &quot;-w -s&quot; -p=16 -o ./bytebase-build/bytebase ./backend/bin/server/main.go &amp;&amp; ./bytebase-build/bytebase --port 8080 --data . --debug --disable-sample
   ```

1. Start frontend (with live reload).

   ```bash
   pnpm --dir frontend i &amp;&amp; pnpm --dir frontend dev
   ```

   Bytebase should now be running at http://localhost:3000 and change either frontend or backend code would trigger live reload.

### Tips

- Use [Code Inspector](https://en.inspector.fe-dev.cn/guide/start.html#method1-recommend) to locate
  frontend code from UI. Hold `Option + Shift` on Mac or `Alt + Shift` on Windows

&lt;br /&gt;

# ü§∫ Bytebase vs Alternatives

## Bytebase vs Flyway, Liquibase

- [Bytebase vs Liquibase](https://www.bytebase.com/blog/bytebase-vs-liquibase/)
- [Bytebase vs Flyway](https://www.bytebase.com/blog/bytebase-vs-flyway/)

Either Flyway or Liquibase is a library and CLI focusing on schema change. While Bytebase is an one-stop
solution covering the entire database development lifecycle for Developers and DBAs to collaborate through a GUI-based workspace.

Bytebase offers broad database support and provides a more comprehensive platform beyond schema migration, including features for security, governance, and observability. Many of our users tell us Bytebase is by far the best (and sometimes the only) database tool that can support their PostgreSQL and ClickHouse use cases, highlighting our robust tooling across various database systems.

[![Star History Chart](https://api.star-history.com/svg?repos=bytebase/bytebase,liquibase/liquibase,flyway/flyway&amp;type=Date)](https://star-history.com/#bytebase/bytebase&amp;liquibase/liquibase&amp;flyway/flyway&amp;Date)

## Bytebase vs Yearning, Archery

Either Yearning or Archery provides a DBA operation portal. While Byteba

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[traefik/traefik]]></title>
            <link>https://github.com/traefik/traefik</link>
            <guid>https://github.com/traefik/traefik</guid>
            <pubDate>Sun, 22 Jun 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[The Cloud Native Application Proxy]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/traefik/traefik">traefik/traefik</a></h1>
            <p>The Cloud Native Application Proxy</p>
            <p>Language: Go</p>
            <p>Stars: 55,241</p>
            <p>Forks: 5,371</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/content/assets/img/traefik.logo-dark.png&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/content/assets/img/traefik.logo.png&quot;&gt;
      &lt;img alt=&quot;Traefik&quot; title=&quot;Traefik&quot; src=&quot;docs/content/assets/img/traefik.logo.png&quot;&gt;
    &lt;/picture&gt;
&lt;/p&gt;

[![Build Status SemaphoreCI](https://traefik-oss.semaphoreci.com/badges/traefik/branches/master.svg?style=shields)](https://traefik-oss.semaphoreci.com/projects/traefik)
[![Docs](https://img.shields.io/badge/docs-current-brightgreen.svg)](https://doc.traefik.io/traefik)
[![Go Report Card](https://goreportcard.com/badge/traefik/traefik)](https://goreportcard.com/report/traefik/traefik)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/traefik/traefik/blob/master/LICENSE.md)
[![Join the community support forum at https://community.traefik.io/](https://img.shields.io/badge/style-register-green.svg?style=social&amp;label=Discourse)](https://community.traefik.io/)
[![Twitter](https://img.shields.io/twitter/follow/traefik.svg?style=social)](https://twitter.com/intent/follow?screen_name=traefik)

Traefik (pronounced _traffic_) is a modern HTTP reverse proxy and load balancer that makes deploying microservices easy.
Traefik integrates with your existing infrastructure components ([Docker](https://www.docker.com/), [Swarm mode](https://docs.docker.com/engine/swarm/), [Kubernetes](https://kubernetes.io), [Consul](https://www.consul.io/), [Etcd](https://coreos.com/etcd/), [Rancher v2](https://rancher.com), [Amazon ECS](https://aws.amazon.com/ecs), ...) and configures itself automatically and dynamically.
Pointing Traefik at your orchestrator should be the _only_ configuration step you need.

---

. **[Overview](#overview)** .
**[Features](#features)** .
**[Supported backends](#supported-backends)** .
**[Quickstart](#quickstart)** .
**[Web UI](#web-ui)** .
**[Documentation](#documentation)** .

. **[Support](#support)** .
**[Release cycle](#release-cycle)** .
**[Contributing](#contributing)** .
**[Maintainers](#maintainers)** .
**[Credits](#credits)** .

---

:warning: When migrating to a new major version of Traefik, please refer to the [migration guide](https://doc.traefik.io/traefik/migration/v2-to-v3/) to ensure a smooth transition and to be aware of any breaking changes.


## Overview

Imagine that you have deployed a bunch of microservices with the help of an orchestrator (like Swarm or Kubernetes) or a service registry (like etcd or consul).
Now you want users to access these microservices, and you need a reverse proxy.

Traditional reverse-proxies require that you configure _each_ route that will connect paths and subdomains to _each_ microservice. 
In an environment where you add, remove, kill, upgrade, or scale your services _many_ times a day, the task of keeping the routes up to date becomes tedious. 

**This is when Traefik can help you!**

Traefik listens to your service registry/orchestrator API and instantly generates the routes so your microservices are connected to the outside world -- without further intervention from your part. 

**Run Traefik and let it do the work for you!** 
_(But if you&#039;d rather configure some of your routes manually, Traefik supports that too!)_

![Architecture](docs/content/assets/img/traefik-architecture.png)

## Features

- Continuously updates its configuration (No restarts!)
- Supports multiple load balancing algorithms
- Provides HTTPS to your microservices by leveraging [Let&#039;s Encrypt](https://letsencrypt.org) (wildcard certificates support)
- Circuit breakers, retry
- See the magic through its clean web UI
- WebSocket, HTTP/2, gRPC ready
- Provides metrics (Rest, Prometheus, Datadog, Statsd, InfluxDB 2.X)
- Keeps access logs (JSON, CLF)
- Fast
- Exposes a Rest API
- Packaged as a single binary file (made with :heart: with go) and available as an [official](https://hub.docker.com/r/_/traefik/) docker image

## Supported Backends

- [Docker](https://doc.traefik.io/traefik/providers/docker/) / [Swarm mode](https://doc.traefik.io/traefik/providers/docker/)
- [Kubernetes](https://doc.traefik.io/traefik/providers/kubernetes-crd/)
- [ECS](https://doc.traefik.io/traefik/providers/ecs/)
- [File](https://doc.traefik.io/traefik/providers/file/)

## Quickstart

To get your hands on Traefik, you can use the [5-Minute Quickstart](https://doc.traefik.io/traefik/getting-started/quick-start/) in our documentation (you will need Docker).

## Web UI

You can access the simple HTML frontend of Traefik.

![Web UI Providers](docs/content/assets/img/webui-dashboard.png)

## Documentation

You can find the complete documentation of Traefik v3 at [https://doc.traefik.io/traefik/](https://doc.traefik.io/traefik/).

## Support

To get community support, you can:

- join the Traefik community forum: [![Join the chat at https://community.traefik.io/](https://img.shields.io/badge/style-register-green.svg?style=social&amp;label=Discourse)](https://community.traefik.io/)

If you need commercial support, please contact [Traefik.io](https://traefik.io) by mail: &lt;mailto:support@traefik.io&gt;.

## Download

- Grab the latest binary from the [releases](https://github.com/traefik/traefik/releases) page and run it with the [sample configuration file](https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml):

```shell
./traefik --configFile=traefik.toml
```

- Or use the official tiny Docker image and run it with the [sample configuration file](https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml):

```shell
docker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik
```

- Or get the sources:

```shell
git clone https://github.com/traefik/traefik
```

## Introductory Videos

You can find high level and deep dive videos on [videos.traefik.io](https://videos.traefik.io).

## Maintainers

We are strongly promoting a philosophy of openness and sharing, and firmly standing against the elitist closed approach. Being part of the core team should be accessible to anyone who is motivated and want to be part of that journey!
This [document](docs/content/contributing/maintainers-guidelines.md) describes how to be part of the [maintainers&#039; team](docs/content/contributing/maintainers.md) as well as various responsibilities and guidelines for Traefik maintainers.
You can also find more information on our process to review pull requests and manage issues [in this document](https://github.com/traefik/contributors-guide/blob/master/issue_triage.md).

## Contributing

If you&#039;d like to contribute to the project, refer to the [contributing documentation](CONTRIBUTING.md).

Please note that this project is released with a [Contributor Code of Conduct](CODE_OF_CONDUCT.md).
By participating in this project, you agree to abide by its terms.

## Release Cycle

- We usually release 3/4 new versions (e.g. 1.1.0, 1.2.0, 1.3.0) per year.
- Release Candidates are available before the release (e.g. 1.1.0-rc1, 1.1.0-rc2, 1.1.0-rc3, 1.1.0-rc4, before 1.1.0).
- Bug-fixes (e.g. 1.1.1, 1.1.2, 1.2.1, 1.2.3) are released as needed (no additional features are delivered in those versions, bug-fixes only).

Each version is supported until the next one is released (e.g. 1.1.x will be supported until 1.2.0 is out).

We use [Semantic Versioning](https://semver.org/).

## Mailing Lists

- General announcements, new releases: mail at news+subscribe@traefik.io or on [the online viewer](https://groups.google.com/a/traefik.io/forum/#!forum/news).
- Security announcements: mail at security+subscribe@traefik.io or on [the online viewer](https://groups.google.com/a/traefik.io/forum/#!forum/security).

## Credits

Kudos to [Peka](http://peka.byethost11.com/photoblog/) for his awesome work on the gopher&#039;s logo!.

The gopher&#039;s logo of Traefik is licensed under the Creative Commons 3.0 Attributions license.

The gopher&#039;s logo of Traefik was inspired by the gopher stickers made by [Takuya Ueda](https://twitter.com/tenntenn).
The original Go gopher was designed by [Renee French](https://reneefrench.blogspot.com/).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>