<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Sat, 18 Oct 2025 00:05:28 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[wavetermdev/waveterm]]></title>
            <link>https://github.com/wavetermdev/waveterm</link>
            <guid>https://github.com/wavetermdev/waveterm</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[An open-source, cross-platform terminal for seamless workflows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wavetermdev/waveterm">wavetermdev/waveterm</a></h1>
            <p>An open-source, cross-platform terminal for seamless workflows</p>
            <p>Language: Go</p>
            <p>Stars: 11,644</p>
            <p>Forks: 472</p>
            <p>Stars today: 85 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.waveterm.dev&quot;&gt;
	&lt;picture&gt;
		&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./assets/wave-dark.png&quot;&gt;
		&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./assets/wave-light.png&quot;&gt;
		&lt;img alt=&quot;Wave Terminal Logo&quot; src=&quot;./assets/wave-light.png&quot; width=&quot;240&quot;&gt;
	&lt;/picture&gt;
  &lt;/a&gt;
  &lt;br/&gt;
&lt;/p&gt;

# Wave Terminal

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm?ref=badge_shield)

Wave is an open-source terminal that combines traditional terminal features with graphical capabilities like file previews, web browsing, and AI assistance. It runs on MacOS, Linux, and Windows.

Modern development involves constantly switching between terminals and browsers - checking documentation, previewing files, monitoring systems, and using AI tools. Wave brings these graphical tools directly into the terminal, letting you control them from the command line. This means you can stay in your terminal workflow while still having access to the visual interfaces you need.

![WaveTerm Screenshot](./assets/wave-screenshot.webp)

## Key Features

- Flexible drag &amp; drop interface to organize terminal blocks, editors, web browsers, and AI assistants
- Built-in editor for seamlessly editing remote files with syntax highlighting and modern editor features
- Rich file preview system for remote files (markdown, images, video, PDFs, CSVs, directories)
- Integrated AI chat with support for multiple models (OpenAI, Claude, Azure, Perplexity, Ollama)
- Command Blocks for isolating and monitoring individual commands with auto-close options
- One-click remote connections with full terminal and file system access
- Rich customization including tab themes, terminal styles, and background images
- Powerful `wsh` command system for managing your workspace from the CLI and sharing data between terminal sessions

## Installation

Wave Terminal works on macOS, Linux, and Windows.

Platform-specific installation instructions can be found [here](https://docs.waveterm.dev/gettingstarted).

You can also install Wave Terminal directly from: [www.waveterm.dev/download](https://www.waveterm.dev/download).

### Minimum requirements

Wave Terminal runs on the following platforms:

- macOS 11 or later (arm64, x64)
- Windows 10 1809 or later (x64)
- Linux based on glibc-2.28 or later (Debian 10, RHEL 8, Ubuntu 20.04, etc.) (arm64, x64)

The WSH helper runs on the following platforms:

- macOS 11 or later (arm64, x64)
- Windows 10 or later (arm64, x64)
- Linux Kernel 2.6.32 or later (x64), Linux Kernel 3.1 or later (arm64)

## Roadmap

Wave is constantly improving! Our roadmap will be continuously updated with our goals for each release. You can find it [here](./ROADMAP.md).

Want to provide input to our future releases? Connect with us on [Discord](https://discord.gg/XfvZ334gwU) or open a [Feature Request](https://github.com/wavetermdev/waveterm/issues/new/choose)!

## Links

- Homepage &amp;mdash; https://www.waveterm.dev
- Download Page &amp;mdash; https://www.waveterm.dev/download
- Documentation &amp;mdash; https://docs.waveterm.dev
- Legacy Documentation &amp;mdash; https://legacydocs.waveterm.dev
- Blog &amp;mdash; https://blog.waveterm.dev
- X &amp;mdash; https://x.com/wavetermdev
- Discord Community &amp;mdash; https://discord.gg/XfvZ334gwU

## Building from Source

See [Building Wave Terminal](BUILD.md).

## Contributing

Wave uses GitHub Issues for issue tracking.

Find more information in our [Contributions Guide](CONTRIBUTING.md), which includes:

- [Ways to contribute](CONTRIBUTING.md#contributing-to-wave-terminal)
- [Contribution guidelines](CONTRIBUTING.md#before-you-start)
- [Storybook](https://docs.waveterm.dev/storybook)

## License

Wave Terminal is licensed under the Apache-2.0 License. For more information on our dependencies, see [here](./ACKNOWLEDGEMENTS.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[DataDog/datadog-agent]]></title>
            <link>https://github.com/DataDog/datadog-agent</link>
            <guid>https://github.com/DataDog/datadog-agent</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[Main repository for Datadog Agent]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DataDog/datadog-agent">DataDog/datadog-agent</a></h1>
            <p>Main repository for Datadog Agent</p>
            <p>Language: Go</p>
            <p>Stars: 3,351</p>
            <p>Forks: 1,350</p>
            <p>Stars today: 55 stars today</p>
            <h2>README</h2><pre># Datadog Agent

![GitHub Release](https://img.shields.io/github/v/release/DataDog/datadog-agent?style=flat&amp;logo=datadog&amp;logoColor=%23632CA6&amp;labelColor=%23FFF&amp;color=%23632CA6)
[![Coverage status](https://codecov.io/github/DataDog/datadog-agent/coverage.svg?branch=main)](https://codecov.io/github/DataDog/datadog-agent?branch=main)
[![GoDoc](https://godoc.org/github.com/DataDog/datadog-agent?status.svg)](https://godoc.org/github.com/DataDog/datadog-agent)

This repository contains the source code of the Datadog Agent version 7 and version 6. Please refer to the [Agent user documentation](https://docs.datadoghq.com/agent/) for information about differences between Agent v5, Agent v6 and Agent v7. Additionally, we provide a list of prepackaged binaries for an easy install process [here](https://app.datadoghq.com/fleet/install-agent/latest?platform=overview).

## Documentation

The [developer docs site](https://datadoghq.dev/datadog-agent/setup/) contains information about how to develop the Datadog Agent itself.

The source of the content is located under [the docs directory](docs) and may contain pages that are not yet published.

## Contributing code

You&#039;ll find information and help on how to contribute code to this project under
[the `docs/dev` directory](docs/dev) of the present repo.

## License

The Datadog Agent user space components are licensed under the
[Apache License, Version 2.0](LICENSE). The BPF code is licensed
under the [General Public License, Version 2.0](pkg/ebpf/c/COPYING).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[stacklok/toolhive]]></title>
            <link>https://github.com/stacklok/toolhive</link>
            <guid>https://github.com/stacklok/toolhive</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[ToolHive makes deploying MCP servers easy, secure and fun]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stacklok/toolhive">stacklok/toolhive</a></h1>
            <p>ToolHive makes deploying MCP servers easy, secure and fun</p>
            <p>Language: Go</p>
            <p>Stars: 1,303</p>
            <p>Forks: 132</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;p float=&quot;left&quot;&gt;
  &lt;picture&gt;
    &lt;img src=&quot;docs/images/toolhive-icon-1024.png&quot; alt=&quot;ToolHive Studio logo&quot; height=&quot;100&quot; align=&quot;middle&quot; /&gt;
  &lt;/picture&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/images/toolhive-wordmark-white.png&quot;&gt;
    &lt;img src=&quot;docs/images/toolhive-wordmark-black.png&quot; alt=&quot;ToolHive wordmark&quot; width=&quot;500&quot; align=&quot;middle&quot; hspace=&quot;20&quot; /&gt;
  &lt;/picture&gt;
  &lt;picture&gt;
    &lt;img src=&quot;docs/images/toolhive.png&quot; alt=&quot;ToolHive mascot&quot; width=&quot;125&quot; align=&quot;middle&quot;/&gt;
  &lt;/picture&gt;
&lt;/p&gt;

[![Release][release-img]][release] [![Build status][ci-img]][ci]
[![Coverage Status][coveralls-img]][coveralls]
[![License: Apache 2.0][license-img]][license]
[![Star on GitHub][stars-img]][stars] [![Discord][discord-img]][discord]

# ToolHive - simplify and secure MCP servers

**Run any Model Context Protocol (MCP) server ‚Äî securely, instantly, anywhere.**

ToolHive is the easiest way to discover, deploy, and manage MCP servers. Launch
any MCP server in a locked-down container with a single command. No manual
setup, no security headaches, no runtime hassles.

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/images/toolhive-diagram-dark.svg&quot;&gt;
  &lt;img src=&quot;docs/images/toolhive-diagram-light.svg&quot; alt=&quot;ToolHive diagram&quot; width=&quot;800&quot; style=&quot;padding: 20px 0&quot; /&gt;
&lt;/picture&gt;

---

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;

## Why ToolHive?

- **Instant deployment:** Start any MCP server with one click or command, using
  Docker or Kubernetes.
- **Secure by default:** Every server runs in an isolated container with only
  the permissions it needs. Secrets are managed securely, never in plaintext.
- **Works everywhere:** Use the UI and CLI for local development, or the
  Kubernetes Operator for production and scale.
- **Seamless integration:** ToolHive auto-configures popular clients like GitHub
  Copilot, Cursor, and more.

ToolHive is available as a GUI desktop app, CLI, and Kubernetes Operator.

&lt;br&gt;
&lt;/td&gt;
&lt;td width=&quot;50%&quot; align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/images/toolhive-sources-dark.svg&quot;&gt;
    &lt;img src=&quot;docs/images/toolhive-sources-light.svg&quot; alt=&quot;ToolHive sources diagram&quot; width=&quot;400px&quot; /&gt;
  &lt;/picture&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

## Kubernetes Operator

ToolHive includes a Kubernetes Operator for enterprise and production deployments:

### Features

- **MCPServer CRD**: Deploy and manage MCP servers as Kubernetes resources
- **MCPRegistry CRD** Centralized registry management with automated sync
- **Secure isolation**: Container-based server execution with permission profiles
- **Protocol proxying**: Stdio servers exposed via HTTP/SSE networking protocols
- **Service discovery**: Automatic service creation and DNS integration

### Documentation

- [Operator Guide](cmd/thv-operator/README.md) - Complete operator documentation
- [MCPRegistry Reference](cmd/thv-operator/REGISTRY.md) - Registry management
- [CRD API Reference](docs/operator/crd-api.md) - Auto-generated API documentation
- [Deployment Guide](docs/kind/deploying-toolhive-operator.md) - Step-by-step installation
- [Examples](examples/operator/) - Sample configurations

## Quick links

- üìö [Documentation](https://docs.stacklok.com/toolhive/)
- üöÄ Quickstart guides:
  - [Desktop app](https://docs.stacklok.com/toolhive/tutorials/quickstart-ui)
  - [CLI](https://docs.stacklok.com/toolhive/tutorials/quickstart-cli)
  - [Kubernetes Operator](https://docs.stacklok.com/toolhive/tutorials/quickstart-k8s)
- üí¨ [Discord](https://discord.gg/stacklok)

---

## Contributing

We welcome contributions and feedback from the community!

- üêõ [Report issues](https://github.com/stacklok/toolhive/issues)
- üí¨ [Join our Discord](https://discord.gg/stacklok)

If you have ideas, suggestions, or want to get involved, check out our
contributing guide or open an issue. Join us in making ToolHive even better!

Contribute to the CLI, API, and Kubernetes Operator:

- ü§ù [Contributing guide](./CONTRIBUTING.md)
- üìñ [Developer guide](./docs/README.md)

Contribute to the desktop UI:

- üñ•Ô∏è [Desktop UI repository](https://github.com/stacklok/toolhive-studio)

Contribute to the documentation:

- üìö [Documentation repository](https://github.com/stacklok/docs-website)

---

## License

This project is licensed under the [Apache 2.0 License](./LICENSE).

&lt;!-- Badge links --&gt;
&lt;!-- prettier-ignore-start --&gt;
[release-img]: https://img.shields.io/github/v/release/stacklok/toolhive?style=flat&amp;label=Latest%20version
[release]: https://github.com/stacklok/toolhive/releases/latest
[ci-img]: https://img.shields.io/github/actions/workflow/status/stacklok/toolhive/run-on-main.yml?style=flat&amp;logo=github&amp;label=Build
[ci]: https://github.com/stacklok/toolhive/actions/workflows/run-on-main.yml
[coveralls-img]: https://coveralls.io/repos/github/stacklok/toolhive/badge.svg?branch=main
[coveralls]: https://coveralls.io/github/stacklok/toolhive?branch=main
[license-img]: https://img.shields.io/badge/License-Apache2.0-blue.svg?style=flat
[license]: https://opensource.org/licenses/Apache-2.0
[stars-img]: https://img.shields.io/github/stars/stacklok/toolhive.svg?style=flat&amp;logo=github&amp;label=Stars
[stars]: https://github.com/stacklok/toolhive
[discord-img]: https://img.shields.io/discord/1184987096302239844?style=flat&amp;logo=discord&amp;logoColor=white&amp;label=Discord
[discord]: https://discord.gg/stacklok
&lt;!-- prettier-ignore-end --&gt;

&lt;!-- markdownlint-disable-file first-line-heading no-inline-html --&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[containers/kubernetes-mcp-server]]></title>
            <link>https://github.com/containers/kubernetes-mcp-server</link>
            <guid>https://github.com/containers/kubernetes-mcp-server</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[Model Context Protocol (MCP) server for Kubernetes and OpenShift]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/containers/kubernetes-mcp-server">containers/kubernetes-mcp-server</a></h1>
            <p>Model Context Protocol (MCP) server for Kubernetes and OpenShift</p>
            <p>Language: Go</p>
            <p>Stars: 696</p>
            <p>Forks: 150</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># Kubernetes MCP Server

[![GitHub License](https://img.shields.io/github/license/containers/kubernetes-mcp-server)](https://github.com/containers/kubernetes-mcp-server/blob/main/LICENSE)
[![npm](https://img.shields.io/npm/v/kubernetes-mcp-server)](https://www.npmjs.com/package/kubernetes-mcp-server)
[![PyPI - Version](https://img.shields.io/pypi/v/kubernetes-mcp-server)](https://pypi.org/project/kubernetes-mcp-server/)
[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/containers/kubernetes-mcp-server?sort=semver)](https://github.com/containers/kubernetes-mcp-server/releases/latest)
[![Build](https://github.com/containers/kubernetes-mcp-server/actions/workflows/build.yaml/badge.svg)](https://github.com/containers/kubernetes-mcp-server/actions/workflows/build.yaml)

[‚ú® Features](#features) | [üöÄ Getting Started](#getting-started) | [üé• Demos](#demos) | [‚öôÔ∏è Configuration](#configuration) | [üõ†Ô∏è Tools](#tools-and-functionalities) | [üßë‚Äçüíª Development](#development)

https://github.com/user-attachments/assets/be2b67b3-fc1c-4d11-ae46-93deba8ed98e

## ‚ú® Features &lt;a id=&quot;features&quot;&gt;&lt;/a&gt;

A powerful and flexible Kubernetes [Model Context Protocol (MCP)](https://blog.marcnuri.com/model-context-protocol-mcp-introduction) server implementation with support for **Kubernetes** and **OpenShift**.

- **‚úÖ Configuration**:
  - Automatically detect changes in the Kubernetes configuration and update the MCP server.
  - **View** and manage the current [Kubernetes `.kube/config`](https://blog.marcnuri.com/where-is-my-default-kubeconfig-file) or in-cluster configuration.
- **‚úÖ Generic Kubernetes Resources**: Perform operations on **any** Kubernetes or OpenShift resource.
  - Any CRUD operation (Create or Update, Get, List, Delete).
- **‚úÖ Pods**: Perform Pod-specific operations.
  - **List** pods in all namespaces or in a specific namespace.
  - **Get** a pod by name from the specified namespace.
  - **Delete** a pod by name from the specified namespace.
  - **Show logs** for a pod by name from the specified namespace.
  - **Top** gets resource usage metrics for all pods or a specific pod in the specified namespace.
  - **Exec** into a pod and run a command.
  - **Run** a container image in a pod and optionally expose it.
- **‚úÖ Namespaces**: List Kubernetes Namespaces.
- **‚úÖ Events**: View Kubernetes events in all namespaces or in a specific namespace.
- **‚úÖ Projects**: List OpenShift Projects.
- **‚ò∏Ô∏è Helm**:
  - **Install** a Helm chart in the current or provided namespace.
  - **List** Helm releases in all namespaces or in a specific namespace.
  - **Uninstall** a Helm release in the current or provided namespace.

Unlike other Kubernetes MCP server implementations, this **IS NOT** just a wrapper around `kubectl` or `helm` command-line tools.
It is a **Go-based native implementation** that interacts directly with the Kubernetes API server.

There is **NO NEED** for external dependencies or tools to be installed on the system.
If you&#039;re using the native binaries you don&#039;t need to have Node or Python installed on your system.

- **‚úÖ Lightweight**: The server is distributed as a single native binary for Linux, macOS, and Windows.
- **‚úÖ High-Performance / Low-Latency**: Directly interacts with the Kubernetes API server without the overhead of calling and waiting for external commands.
- **‚úÖ Multi-Cluster**: Can interact with multiple Kubernetes clusters simultaneously (as defined in your kubeconfig files).
- **‚úÖ Cross-Platform**: Available as a native binary for Linux, macOS, and Windows, as well as an npm package, a Python package, and container/Docker image.
- **‚úÖ Configurable**: Supports [command-line arguments](#configuration)  to configure the server behavior.
- **‚úÖ Well tested**: The server has an extensive test suite to ensure its reliability and correctness across different Kubernetes environments.

## üöÄ Getting Started &lt;a id=&quot;getting-started&quot;&gt;&lt;/a&gt;

### Requirements

- Access to a Kubernetes cluster.

### Claude Desktop

#### Using npx

If you have npm installed, this is the fastest way to get started with `kubernetes-mcp-server` on Claude Desktop.

Open your `claude_desktop_config.json` and add the mcp server to the list of `mcpServers`:
``` json
{
  &quot;mcpServers&quot;: {
    &quot;kubernetes&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;-y&quot;,
        &quot;kubernetes-mcp-server@latest&quot;
      ]
    }
  }
}
```

### VS Code / VS Code Insiders

Install the Kubernetes MCP server extension in VS Code Insiders by pressing the following link:

[&lt;img src=&quot;https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&amp;label=Install%20Server&amp;color=0098FF&quot; alt=&quot;Install in VS Code&quot;&gt;](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522kubernetes%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522kubernetes-mcp-server%2540latest%2522%255D%257D)
[&lt;img alt=&quot;Install in VS Code Insiders&quot; src=&quot;https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&amp;label=Install%20Server&amp;color=24bfa5&quot;&gt;](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522kubernetes%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522kubernetes-mcp-server%2540latest%2522%255D%257D)

Alternatively, you can install the extension manually by running the following command:

```shell
# For VS Code
code --add-mcp &#039;{&quot;name&quot;:&quot;kubernetes&quot;,&quot;command&quot;:&quot;npx&quot;,&quot;args&quot;:[&quot;kubernetes-mcp-server@latest&quot;]}&#039;
# For VS Code Insiders
code-insiders --add-mcp &#039;{&quot;name&quot;:&quot;kubernetes&quot;,&quot;command&quot;:&quot;npx&quot;,&quot;args&quot;:[&quot;kubernetes-mcp-server@latest&quot;]}&#039;
```

### Cursor

Install the Kubernetes MCP server extension in Cursor by pressing the following link:

[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=kubernetes-mcp-server&amp;config=eyJjb21tYW5kIjoibnB4IC15IGt1YmVybmV0ZXMtbWNwLXNlcnZlckBsYXRlc3QifQ%3D%3D)

Alternatively, you can install the extension manually by editing the `mcp.json` file:

```json
{
  &quot;mcpServers&quot;: {
    &quot;kubernetes-mcp-server&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;kubernetes-mcp-server@latest&quot;]
    }
  }
}
```

### Goose CLI

[Goose CLI](https://blog.marcnuri.com/goose-on-machine-ai-agent-cli-introduction) is the easiest (and cheapest) way to get rolling with artificial intelligence (AI) agents.

#### Using npm

If you have npm installed, this is the fastest way to get started with `kubernetes-mcp-server`.

Open your goose `config.yaml` and add the mcp server to the list of `mcpServers`:
```yaml
extensions:
  kubernetes:
    command: npx
    args:
      - -y
      - kubernetes-mcp-server@latest

```

## üé• Demos &lt;a id=&quot;demos&quot;&gt;&lt;/a&gt;

### Diagnosing and automatically fixing an OpenShift Deployment

Demo showcasing how Kubernetes MCP server is leveraged by Claude Desktop to automatically diagnose and fix a deployment in OpenShift without any user assistance.

https://github.com/user-attachments/assets/a576176d-a142-4c19-b9aa-a83dc4b8d941

### _Vibe Coding_ a simple game and deploying it to OpenShift

In this demo, I walk you through the process of _Vibe Coding_ a simple game using VS Code and how to leverage [Podman MCP server](https://github.com/manusa/podman-mcp-server) and Kubernetes MCP server to deploy it to OpenShift.

&lt;a href=&quot;https://www.youtube.com/watch?v=l05jQDSrzVI&quot; target=&quot;_blank&quot;&gt;
 &lt;img src=&quot;docs/images/vibe-coding.jpg&quot; alt=&quot;Vibe Coding: Build &amp; Deploy a Game on Kubernetes&quot; width=&quot;240&quot;  /&gt;
&lt;/a&gt;

### Supercharge GitHub Copilot with Kubernetes MCP Server in VS Code - One-Click Setup!

In this demo, I&#039;ll show you how to set up Kubernetes MCP server in VS code just by clicking a link.

&lt;a href=&quot;https://youtu.be/AI4ljYMkgtA&quot; target=&quot;_blank&quot;&gt;
 &lt;img src=&quot;docs/images/kubernetes-mcp-server-github-copilot.jpg&quot; alt=&quot;Supercharge GitHub Copilot with Kubernetes MCP Server in VS Code - One-Click Setup!&quot; width=&quot;240&quot;  /&gt;
&lt;/a&gt;

## ‚öôÔ∏è Configuration &lt;a id=&quot;configuration&quot;&gt;&lt;/a&gt;

The Kubernetes MCP server can be configured using command line (CLI) arguments.

You can run the CLI executable either by using `npx`, `uvx`, or by downloading the [latest release binary](https://github.com/containers/kubernetes-mcp-server/releases/latest).

```shell
# Run the Kubernetes MCP server using npx (in case you have npm and node installed)
npx kubernetes-mcp-server@latest --help
```

```shell
# Run the Kubernetes MCP server using uvx (in case you have uv and python installed)
uvx kubernetes-mcp-server@latest --help
```

```shell
# Run the Kubernetes MCP server using the latest release binary
./kubernetes-mcp-server --help
```

### Configuration Options

| Option                    | Description                                                                                                                                                                                                                                                                                   |
|---------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `--port`                  | Starts the MCP server in Streamable HTTP mode (path /mcp) and Server-Sent Event (SSE) (path /sse) mode and listens on the specified port .                                                                                                                                                    |
| `--log-level`             | Sets the logging level (values [from 0-9](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md)). Similar to [kubectl logging levels](https://kubernetes.io/docs/reference/kubectl/quick-reference/#kubectl-output-verbosity-and-debugging). |
| `--kubeconfig`            | Path to the Kubernetes configuration file. If not provided, it will try to resolve the configuration (in-cluster, default location, etc.).                                                                                                                                                    |
| `--list-output`           | Output format for resource list operations (one of: yaml, table) (default &quot;table&quot;)                                                                                                                                                                                                            |
| `--read-only`             | If set, the MCP server will run in read-only mode, meaning it will not allow any write operations (create, update, delete) on the Kubernetes cluster. This is useful for debugging or inspecting the cluster without making changes.                                                          |
| `--disable-destructive`   | If set, the MCP server will disable all destructive operations (delete, update, etc.) on the Kubernetes cluster. This is useful for debugging or inspecting the cluster without accidentally making changes. This option has no effect when `--read-only` is used.                            |
| `--toolsets`              | Comma-separated list of toolsets to enable. Check the [üõ†Ô∏è Tools and Functionalities](#tools-and-functionalities) section for more information.                                                                                                                                               |
| `--disable-multi-cluster` | If set, the MCP server will disable multi-cluster support and will only use the current context from the kubeconfig file. This is useful if you want to restrict the MCP server to a single cluster.                                                                                          |

## üõ†Ô∏è Tools and Functionalities &lt;a id=&quot;tools-and-functionalities&quot;&gt;&lt;/a&gt;

The Kubernetes MCP server supports enabling or disabling specific groups of tools and functionalities (tools, resources, prompts, and so on) via the `--toolsets` command-line flag or `toolsets` configuration option.
This allows you to control which Kubernetes functionalities are available to your AI tools.
Enabling only the toolsets you need can help reduce the context size and improve the LLM&#039;s tool selection accuracy.

### Available Toolsets

The following sets of tools are available (all on by default):

&lt;!-- AVAILABLE-TOOLSETS-START --&gt;

| Toolset | Description                                                                         |
|---------|-------------------------------------------------------------------------------------|
| config  | View and manage the current local Kubernetes configuration (kubeconfig)             |
| core    | Most common tools for Kubernetes management (Pods, Generic Resources, Events, etc.) |
| helm    | Tools for managing Helm charts and releases                                         |

&lt;!-- AVAILABLE-TOOLSETS-END --&gt;

### Tools

In case multi-cluster support is enabled (default) and you have access to multiple clusters, all applicable tools will include an additional `context` argument to specify the Kubernetes context (cluster) to use for that operation.

&lt;!-- AVAILABLE-TOOLSETS-TOOLS-START --&gt;

&lt;details&gt;

&lt;summary&gt;config&lt;/summary&gt;

- **configuration_contexts_list** - List all available context names and associated server urls from the kubeconfig file

- **configuration_view** - Get the current Kubernetes configuration content as a kubeconfig YAML
  - `minified` (`boolean`) - Return a minified version of the configuration. If set to true, keeps only the current-context and the relevant pieces of the configuration for that context. If set to false, all contexts, clusters, auth-infos, and users are returned in the configuration. (Optional, default true)

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;core&lt;/summary&gt;

- **events_list** - List all the Kubernetes events in the current cluster from all namespaces
  - `namespace` (`string`) - Optional Namespace to retrieve the events from. If not provided, will list events from all namespaces

- **namespaces_list** - List all the Kubernetes namespaces in the current cluster

- **projects_list** - List all the OpenShift projects in the current cluster

- **pods_list** - List all the Kubernetes pods in the current cluster from all namespaces
  - `labelSelector` (`string`) - Optional Kubernetes label selector (e.g. &#039;app=myapp,env=prod&#039; or &#039;app in (myapp,yourapp)&#039;), use this option when you want to filter the pods by label

- **pods_list_in_namespace** - List all the Kubernetes pods in the specified namespace in the current cluster
  - `labelSelector` (`string`) - Optional Kubernetes label selector (e.g. &#039;app=myapp,env=prod&#039; or &#039;app in (myapp,yourapp)&#039;), use this option when you want to filter the pods by label
  - `namespace` (`string`) **(required)** - Namespace to list pods from

- **pods_get** - Get a Kubernetes Pod in the current or provided namespace with the provided name
  - `name` (`string`) **(required)** - Name of the Pod
  - `namespace` (`string`) - Namespace to get the Pod from

- **pods_delete** - Delete a Kubernetes Pod in the current or provided namespace with the provided name
  - `name` (`string`) **(required)** - Name of the Pod to delete
  - `namespace` (`string`) - Namespace to delete the Pod from

- **pods_top** - List the resource consumption (CPU and memory) as recorded by the Kubernetes Metrics Server for the specified Kubernetes Pods in the all namespaces, the provided namespace, or the current namespace
  - `all_namespaces` (`boolean`) - If true, list the resource consumption for all Pods in all namespaces. If false, list the resource consumption for Pods in the provided namespace or the current namespace
  - `label_selector` (`string`) - Kubernetes label selector (e.g. &#039;app=myapp,env=prod&#039; or &#039;app in (myapp,yourapp)&#039;), use this option when you want to filter the pods by label (Optional, only applicable when name is not provided)
  - `name` (`string`) - Name of the Pod to get the resource consumption from (Optional, all Pods in the namespace if not provided)
  - `namespace` (`string`) - Namespace to get the Pods resource consumption from (Optional, current namespace if not provided and all_namespaces is false)

- **pods_exec** - Execute a command in a Kubernetes Pod in the current or provided namespace with the provided name and command
  - `command` (`array`) **(required)** - Command to execute in the Pod container. The first item is the command to be run, and the rest are the arguments to that command. Example: [&quot;ls&quot;, &quot;-l&quot;, &quot;/tmp&quot;]
  - `container` (`string`) - Name of the Pod container where the command will be executed (Optional)
  - `name` (`string`) **(required)** - Name of the Pod where the command will be executed
  - `namespace` (`string`) - Namespace of the Pod where the command will be executed

- **pods_log** - Get the logs of a Kubernetes Pod in the current or provided namespace with the provided name
  - `container` (`string`) - Name of the Pod container to get the logs from (Optional)
  - `name` (`string`) **(required)** - Name of the Pod to get the logs from
  - `namespace` (`string`) - Namespace to get the Pod logs from
  - `previous` (`boolean`) - Return previous terminated container logs (Optional)
  - `tail` (`integer`) - Number of lines to retrieve from the end of the logs (Optional, default: 100)

- **pods_run** - Run a Kubernetes Pod in the current or provided namespace with the provided container image and optional name
  - `image` (`string`) **(required)** - Container Image to run in the Pod
  - `name` (`string`) - Name of the Pod (Optional, random name if not provided)
  - `namespace` (`string`) - Namespace to run the Pod in
  - `port` (`number`) - TCP/IP port to expose from the Pod container (Optional, no port exposed if not provided)

- **resources_list** - List Kubernetes resources and objects in the current cluster by providing their apiVersion and kind and optionally the namespace and label selector
(common apiVersion and kind include: v1 Pod, v1 Service, v1 Node, apps/v1 Deployment, networking.k8s.io/v1 Ingress, route.openshift.io/v1 Route)
  - `apiVersion` (`string`) **(required)** - apiVersion of the resources (examples of valid apiVersion are: v1, apps/v1, networking.k8s.io/v1)
  - `kind` (`string`) **(required)** - kind of the resources (examples of valid kind are: Pod, Service, Deployment, Ingress)
  - `labelSelector` (`string`) - Optional Kubernetes label selector (e.g. &#039;app=myapp,env=prod&#039; or &#039;app in (myapp,yourapp)&#039;), use this option when you want to filter the pods by label
  - `namespace` (`string`) - Optional Namespace to retrieve the namespaced resources from (ignored in case of cluster scoped resources). If not provided, will list resources from all namespaces

- **resources_get** - Get a Kubernetes resource in the current cluster by providing its apiVersion, kind, optionally the namespace, and its name
(common apiVersion and kind include: v1 Pod, v1 Service, v1 Node, apps/v1 Deployment, networking.k8s.io/v1 Ingress, route.openshift.io/v1 Route)
  - `apiVersion` (`string`) **(required)** - apiVersion of the resource (examples of valid apiVersion are: v1, apps/v1, networking.k8s.io/v1)
  - `kind` (`string`) **(required)** - kind of the resource (examples of valid kind are: Pod, Service, Deployment, Ingress)
  - `name` (`string`) **(required)** - Name of the resource
  - `namespace` (`string`) - Optional Namespace to retrieve the namespaced resource from (ignored in case of cluster scoped resources). If not provided, will get resource from configured namespace

- **resources_create_or_update** - Create or update a Kubernetes resource in the current cluster by providing a YAML or JSON representation of the resource
(common apiVersion and kind include: v1 Pod, v1 Service, v1 Node, apps/v1 Deployment, networking.k8s.io/v1 Ingress, route.openshift.io/v1 Route)
  - `resource` (

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ZenPrivacy/zen-desktop]]></title>
            <link>https://github.com/ZenPrivacy/zen-desktop</link>
            <guid>https://github.com/ZenPrivacy/zen-desktop</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[Simple, free and efficient ad-blocker and privacy guard for Windows, macOS and Linux]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ZenPrivacy/zen-desktop">ZenPrivacy/zen-desktop</a></h1>
            <p>Simple, free and efficient ad-blocker and privacy guard for Windows, macOS and Linux</p>
            <p>Language: Go</p>
            <p>Stars: 3,474</p>
            <p>Forks: 107</p>
            <p>Stars today: 56 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;img src=&quot;https://github.com/ZenPrivacy/zen-desktop/blob/master/assets/appicon.png?raw=true&quot; alt=&quot;Zen&#039;s Blue Shield Logo&quot; width=&quot;150&quot; /&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
  Zen: Your Comprehensive Ad-Blocker and Privacy Guard
&lt;/h3&gt;
&lt;blockquote align=&quot;center&quot;&gt;
There is, simply, no way, to ignore privacy. Because a citizenry‚Äôs freedoms are interdependent, to surrender your own privacy is really to surrender everyone‚Äôs.

Edward Snowden, Permanent Record

&lt;/blockquote&gt;

![GitHub License](https://img.shields.io/github/license/ZenPrivacy/zen-desktop)
![GitHub release](https://img.shields.io/github/v/release/ZenPrivacy/zen-desktop)
![GitHub download counter](https://img.shields.io/github/downloads/ZenPrivacy/zen-desktop/total)
&lt;a href=&quot;https://discord.gg/jSzEwby7JY&quot;&gt;
&lt;img alt=&quot;Discord&quot; src=&quot;https://dcbadge.limes.pink/api/server/https://discord.gg/jSzEwby7JY?style=flat&quot;/&gt;
&lt;/a&gt;

Zen is an open-source system-wide ad-blocker and privacy guard for Windows, macOS, and Linux. It works by setting up a proxy that intercepts HTTP requests from all applications, and blocks those serving ads, tracking scripts that monitor your behavior, malware, and other unwanted content. By operating at the system level, Zen can protect against threats that browser extensions cannot, such as trackers embedded in desktop applications and operating system components. Zen comes with many pre-installed filters, but also allows you to easily add hosts files and EasyList-style filters, enabling you to tailor your protection to your specific needs.

## Downloads

During the first run, Zen will prompt you to install a root certificate. This is required for Zen to be able to intercept and modify HTTPS requests. This certificate is generated locally and never leaves your device. For details on how this works and the steps we take to secure it, see our [security architecture](/docs/internal/security-architecture.md).

### Windows

- x64: [üíæ Installer](https://github.com/ZenPrivacy/zen-desktop/releases/latest/download/Zen-amd64-installer.exe) | [üì¶ Portable](https://github.com/ZenPrivacy/zen-desktop/releases/latest/download/Zen_windows_amd64.zip)
- ARM64: [üíæ Installer](https://github.com/ZenPrivacy/zen-desktop/releases/latest/download/Zen-arm64-installer.exe) | [üì¶ Portable](https://github.com/ZenPrivacy/zen-desktop/releases/latest/download/Zen_windows_arm64.zip)

Unsure which version to download? Click on &#039;Start&#039; and type &#039;View processor info&#039;. The &#039;System type&#039; field under &#039;Device specifications&#039; will tell you which one you need.

#### Winget

Zen is available via [Winget (Windows Package Manager)](https://github.com/microsoft/winget-pkgs/tree/master/manifests/z/ZenPrivacy). To install, run:

```bash
winget install ZenPrivacy.ZenDesktop
```

### macOS

- x64 (Intel): [üíæ Installer](https://github.com/ZenPrivacy/zen-desktop/releases/latest/download/Zen-amd64.dmg) | [üì¶ Portable](https://github.com/ZenPrivacy/zen-desktop/releases/latest/download/Zen_darwin_amd64.tar.gz)
- ARM64 (Apple Silicon): [üíæ Installer](https://github.com/ZenPrivacy/zen-desktop/releases/latest/download/Zen-arm64.dmg) | [üì¶ Portable](https://github.com/ZenPrivacy/zen-desktop/releases/latest/download/Zen_darwin_arm64.tar.gz)

Unsure which version to download? Learn at [Apple&#039;s website](https://support.apple.com/en-us/HT211814).

#### üç∫ Homebrew

Zen is available via [Homebrew](https://formulae.brew.sh/cask/zen-privacy) for both Intel and Apple Silicon. To install it, run:

```bash
brew install --cask zen-privacy
```

### Linux

- AUR: [üëæ zen-adblocker-bin](https://aur.archlinux.org/packages/zen-adblocker-bin)
- x64: [üì¶ Portable](https://github.com/ZenPrivacy/zen-desktop/releases/latest/download/Zen_linux_amd64.tar.gz)
- ARM64: [üì¶ Portable](https://github.com/ZenPrivacy/zen-desktop/releases/latest/download/Zen_linux_arm64.tar.gz)

On Linux, automatic proxy configuration is currently only supported on GNOME-based desktop environments.

## Screenshots

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
        &lt;th&gt;Request history&lt;/th&gt;
        &lt;th&gt;Filter list manager&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;
        Request history shows all requests blocked by Zen. Each request can be inspected to see which filter and rule blocked it.
      &lt;/td&gt;
      &lt;td&gt;
        Zen comes with many pre-installed filters. You can also add your own by providing a URL to a hosts file or an EasyList-style filter.
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot;&gt;&lt;img src=&quot;https://github.com/ZenPrivacy/zen-desktop/blob/master/assets/screenshots/main-window.png?raw=true&quot; alt=&quot;Zen&#039;s main window&quot;/&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot;&gt;&lt;img src=&quot;https://github.com/ZenPrivacy/zen-desktop/blob/master/assets/screenshots/filter-lists.png?raw=true&quot; alt=&quot;Zen&#039;s filter list manager&quot;/&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

## Development

Follow the [getting started guide](docs/internal/index.md#getting-started) to begin working on Zen development. If you have any questions, feel free to ask in the [Discussions](https://github.com/ZenPrivacy/zen-desktop/discussions/categories/q-a).

## Contributing

Zen needs your help! You can report bugs, suggest and implement features, improve the codebase, or help translate Zen into your language. Please refer to the [Contributing Guidelines](CONTRIBUTING.md) for more information.

## Special Thanks

Zen exists thanks to the support of many incredible people and organizations, including:

- Our contributors
  &lt;a href=&quot;https://github.com/ZenPrivacy/zen-desktop/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://opencollective.com/zen-privacy/contributors.svg?width=890&amp;button=false&quot; alt=&quot;Avatars of all GitHub contributors to Zen&quot; /&gt;
  &lt;/a&gt;

- Our sponsors
  &lt;a href=&quot;https://opencollective.com/zen-privacy#backers&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;
  &lt;img src=&quot;https://opencollective.com/zen-privacy/backers.svg?width=890&amp;button=false&quot; alt=&quot;Avatars of all backers of Zen on Open Collective&quot; /&gt;
  &lt;/a&gt;

- [SignPath](https://signpath.io) and [SignPath Foundation](https://signpath.org/), who generously provide a free Windows certificate and code signing

  &lt;a href=&quot;https://signpath.io&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;
  &lt;img src=&quot;./assets/signpath-logo.png&quot; width=&quot;260&quot; /&gt;
  &lt;/a&gt;

## License

This project is licensed under the [MIT License](https://github.com/ZenPrivacy/zen-desktop/blob/master/LICENSE). Some code and assets included with Zen are licensed under different terms. For more information, see the [COPYING](https://github.com/ZenPrivacy/zen-desktop/blob/master/COPYING.md) file.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[opentofu/opentofu]]></title>
            <link>https://github.com/opentofu/opentofu</link>
            <guid>https://github.com/opentofu/opentofu</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[OpenTofu lets you declaratively manage your cloud infrastructure.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/opentofu/opentofu">opentofu/opentofu</a></h1>
            <p>OpenTofu lets you declaratively manage your cloud infrastructure.</p>
            <p>Language: Go</p>
            <p>Stars: 26,772</p>
            <p>Forks: 1,103</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre># OpenTofu

- [HomePage](https://opentofu.org/)
- [How to install](https://opentofu.org/docs/intro/install)
- [Join our Slack community!](https://opentofu.org/slack)

![](https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-dark.svg#gh-dark-mode-only)
![](https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-light.svg#gh-light-mode-only)

[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10508/badge)](https://www.bestpractices.dev/projects/10508)

OpenTofu is an OSS tool for building, changing, and versioning infrastructure safely and efficiently. OpenTofu can manage existing and popular service providers as well as custom in-house solutions.

The key features of OpenTofu are:

- **Infrastructure as Code**: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.

- **Execution Plans**: OpenTofu has a &quot;planning&quot; step where it generates an execution plan. The execution plan shows what OpenTofu will do when you call apply. This lets you avoid any surprises when OpenTofu manipulates infrastructure.

- **Resource Graph**: OpenTofu builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, OpenTofu builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.

- **Change Automation**: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what OpenTofu will change and in what order, avoiding many possible human errors.

## Getting help and contributing

- Have a question?
  - Post it in [GitHub Discussions](https://github.com/orgs/opentofu/discussions)
  - Open a [GitHub issue](https://github.com/opentofu/opentofu/issues/new/choose)
  - Join the [OpenTofu Slack](https://opentofu.org/slack/)!
- Want to contribute?
  - Please read the [Contribution Guide](CONTRIBUTING.md).
- Recurring Events
  - [Community Meetings](https://meet.google.com/xfm-cgms-has) on Wednesdays at 12:30 UTC at this link: https://meet.google.com/xfm-cgms-has ([üìÖ calendar link](https://calendar.google.com/calendar/event?eid=NDg0aWl2Y3U1aHFva3N0bGhyMHBhNzdpZmsgY18zZjJkZDNjMWZlMGVmNGU5M2VmM2ZjNDU2Y2EyZGQyMTlhMmU4ZmQ4NWY2YjQwNzUwYWYxNmMzZGYzNzBiZjkzQGc))
  - [Technical Steering Committee Meetings](https://meet.google.com/cry-houa-qbk) every other Tuesday at 4pm UTC at this link: https://meet.google.com/cry-houa-qbk ([üìÖ calendar link](https://calendar.google.com/calendar/u/0/event?eid=M3JyMWtuYWptdXI0Zms4ZnJpNmppcDczb3RfMjAyNTA1MjdUMTYwMDAwWiBjXzNmMmRkM2MxZmUwZWY0ZTkzZWYzZmM0NTZjYTJkZDIxOWEyZThmZDg1ZjZiNDA3NTBhZjE2YzNkZjM3MGJmOTNAZw))

&gt; [!TIP]
&gt; For more OpenTofu events, subscribe to the [OpenTofu Events Calendar](https://calendar.google.com/calendar/embed?src=c_3f2dd3c1fe0ef4e93ef3fc456ca2dd219a2e8fd85f6b40750af16c3df370bf93%40group.calendar.google.com)!

## Reporting security vulnerabilities
If you&#039;ve found a vulnerability or a potential vulnerability in OpenTofu please follow [Security Policy](https://github.com/opentofu/opentofu/security/policy). We&#039;ll send a confirmation email to acknowledge your report, and we&#039;ll send an additional email when we&#039;ve identified the issue positively or negatively.

## Reporting possible copyright issues

If you believe you have found any possible copyright or intellectual property issues, please contact liaison@opentofu.org. We&#039;ll send a confirmation email to acknowledge your report.

## Registry Access

In an effort to comply with applicable sanctions, we block access from specific countries of origin.

## License

[Mozilla Public License v2.0](https://github.com/opentofu/opentofu/blob/main/LICENSE)

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[github/github-mcp-server]]></title>
            <link>https://github.com/github/github-mcp-server</link>
            <guid>https://github.com/github/github-mcp-server</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[GitHub's official MCP Server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/github/github-mcp-server">github/github-mcp-server</a></h1>
            <p>GitHub's official MCP Server</p>
            <p>Language: Go</p>
            <p>Stars: 23,697</p>
            <p>Forks: 2,772</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre># GitHub MCP Server

The GitHub MCP Server connects AI tools directly to GitHub&#039;s platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code files, manage issues and PRs, analyze code, and automate workflows. All through natural language interactions.

### Use Cases

- Repository Management: Browse and query code, search files, analyze commits, and understand project structure across any repository you have access to.
- Issue &amp; PR Automation: Create, update, and manage issues and pull requests. Let AI help triage bugs, review code changes, and maintain project boards.
- CI/CD &amp; Workflow Intelligence: Monitor GitHub Actions workflow runs, analyze build failures, manage releases, and get insights into your development pipeline.
- Code Analysis: Examine security findings, review Dependabot alerts, understand code patterns, and get comprehensive insights into your codebase.
- Team Collaboration: Access discussions, manage notifications, analyze team activity, and streamline processes for your team.

Built for developers who want to connect their AI tools to GitHub context and capabilities, from simple natural language queries to complex multi-step agent workflows.

---

## Remote GitHub MCP Server

[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D&amp;quality=insiders)

The remote GitHub MCP Server is hosted by GitHub and provides the easiest method for getting up and running. If your MCP host does not support remote MCP servers, don&#039;t worry! You can use the [local version of the GitHub MCP Server](https://github.com/github/github-mcp-server?tab=readme-ov-file#local-github-mcp-server) instead.

### Prerequisites

1. A compatible MCP host with remote server support (VS Code 1.101+, Claude Desktop, Cursor, Windsurf, etc.)
2. Any applicable [policies enabled](https://github.com/github/github-mcp-server/blob/main/docs/policies-and-governance.md)

### Install in VS Code

For quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start. Make sure you&#039;re using [VS Code 1.101](https://code.visualstudio.com/updates/v1_101) or [later](https://code.visualstudio.com/updates) for remote MCP and OAuth support.

Alternatively, to manually configure VS Code, choose the appropriate JSON block from the examples below and add it to your host configuration:

&lt;table&gt;
&lt;tr&gt;&lt;th&gt;Using OAuth&lt;/th&gt;&lt;th&gt;Using a GitHub PAT&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th align=left colspan=2&gt;VS Code (version 1.101 or greater)&lt;/th&gt;&lt;/tr&gt;
&lt;tr valign=top&gt;
&lt;td&gt;

```json
{
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;
    }
  }
}
```

&lt;/td&gt;
&lt;td&gt;

```json
{
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;,
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;Bearer ${input:github_mcp_pat}&quot;
      }
    }
  },
  &quot;inputs&quot;: [
    {
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;id&quot;: &quot;github_mcp_pat&quot;,
      &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
      &quot;password&quot;: true
    }
  ]
}
```

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

### Install in other MCP hosts
- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot
- **[Claude Applications](/docs/installation-guides/install-claude.md)** - Installation guide for Claude Web, Claude Desktop and Claude Code CLI
- **[Cursor](/docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE
- **[Windsurf](/docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE

&gt; **Note:** Each MCP host application needs to configure a GitHub App or OAuth App to support remote access via OAuth. Any host application that supports remote MCP servers should support the remote GitHub server with PAT authentication. Configuration details and support levels vary by host. Make sure to refer to the host application&#039;s documentation for more info.

### Configuration

#### Toolset configuration

See [Remote Server Documentation](docs/remote-server.md) for full details on remote server configuration, toolsets, headers, and advanced usage. This file provides comprehensive instructions and examples for connecting, customizing, and installing the remote GitHub MCP Server in VS Code and other MCP hosts.

When no toolsets are specified, [default toolsets](#default-toolset) are used.

#### Enterprise Cloud with data residency (ghe.com)

GitHub Enterprise Cloud can also make use of the remote server.

Example for `https://octocorp.ghe.com`:
```
{
    ...
    &quot;proxima-github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://copilot-api.octocorp.ghe.com/mcp&quot;,
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;Bearer ${input:github_mcp_pat}&quot;
      }
    },
    ...
}
```

GitHub Enterprise Server does not support remote server hosting. Please refer to [GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)](#github-enterprise-server-and-enterprise-cloud-with-data-residency-ghecom) from the local server configuration.

---

## Local GitHub MCP Server

[![Install with Docker in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&amp;config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D) [![Install with Docker in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&amp;config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D&amp;quality=insiders)

### Prerequisites

1. To run the server in a container, you will need to have [Docker](https://www.docker.com/) installed.
2. Once Docker is installed, you will also need to ensure Docker is running. The image is public; if you get errors on pull, you may have an expired token and need to `docker logout ghcr.io`.
3. Lastly you will need to [Create a GitHub Personal Access Token](https://github.com/settings/personal-access-tokens/new).
The MCP server can use many of the GitHub APIs, so enable the permissions that you feel comfortable granting your AI tools (to learn more about access tokens, please check out the [documentation](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)).

&lt;details&gt;&lt;summary&gt;&lt;b&gt;Handling PATs Securely&lt;/b&gt;&lt;/summary&gt;

### Environment Variables (Recommended)
To keep your GitHub PAT secure and reusable across different MCP hosts:

1. **Store your PAT in environment variables**
   ```bash
   export GITHUB_PAT=your_token_here
   ```
   Or create a `.env` file:
   ```env
   GITHUB_PAT=your_token_here
   ```

2. **Protect your `.env` file**
   ```bash
   # Add to .gitignore to prevent accidental commits
   echo &quot;.env&quot; &gt;&gt; .gitignore
   ```

3. **Reference the token in configurations**
   ```bash
   # CLI usage
   claude mcp update github -e GITHUB_PERSONAL_ACCESS_TOKEN=$GITHUB_PAT

   # In config files (where supported)
   &quot;env&quot;: {
     &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;$GITHUB_PAT&quot;
   }
   ```

&gt; **Note**: Environment variable support varies by host app and IDE. Some applications (like Windsurf) require hardcoded tokens in config files.

### Token Security Best Practices

- **Minimum scopes**: Only grant necessary permissions
  - `repo` - Repository operations
  - `read:packages` - Docker image access
  - `read:org` - Organization team access
- **Separate tokens**: Use different PATs for different projects/environments
- **Regular rotation**: Update tokens periodically
- **Never commit**: Keep tokens out of version control
- **File permissions**: Restrict access to config files containing tokens
  ```bash
  chmod 600 ~/.your-app/config.json
  ```

&lt;/details&gt;

### GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)

The flag `--gh-host` and the environment variable `GITHUB_HOST` can be used to set
the hostname for GitHub Enterprise Server or GitHub Enterprise Cloud with data residency.

- For GitHub Enterprise Server, prefix the hostname with the `https://` URI scheme, as it otherwise defaults to `http://`, which GitHub Enterprise Server does not support.
- For GitHub Enterprise Cloud with data residency, use `https://YOURSUBDOMAIN.ghe.com` as the hostname.
``` json
&quot;github&quot;: {
    &quot;command&quot;: &quot;docker&quot;,
    &quot;args&quot;: [
    &quot;run&quot;,
    &quot;-i&quot;,
    &quot;--rm&quot;,
    &quot;-e&quot;,
    &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
    &quot;-e&quot;,
    &quot;GITHUB_HOST&quot;,
    &quot;ghcr.io/github/github-mcp-server&quot;
    ],
    &quot;env&quot;: {
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;,
        &quot;GITHUB_HOST&quot;: &quot;https://&lt;your GHES or ghe.com domain name&gt;&quot;
    }
}
```

## Installation

### Install in GitHub Copilot on VS Code

For quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start.

More about using MCP server tools in VS Code&#039;s [agent mode documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers).

Install in GitHub Copilot on other IDEs (JetBrains, Visual Studio, Eclipse, etc.)

Add the following JSON block to your IDE&#039;s MCP settings.

```json
{
  &quot;mcp&quot;: {
    &quot;inputs&quot;: [
      {
        &quot;type&quot;: &quot;promptString&quot;,
        &quot;id&quot;: &quot;github_token&quot;,
        &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
        &quot;password&quot;: true
      }
    ],
    &quot;servers&quot;: {
      &quot;github&quot;: {
        &quot;command&quot;: &quot;docker&quot;,
        &quot;args&quot;: [
          &quot;run&quot;,
          &quot;-i&quot;,
          &quot;--rm&quot;,
          &quot;-e&quot;,
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
          &quot;ghcr.io/github/github-mcp-server&quot;
        ],
        &quot;env&quot;: {
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;
        }
      }
    }
  }
}
```

Optionally, you can add a similar example (i.e. without the mcp key) to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with other host applications that accept the same format.

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Example JSON block without the MCP key included&lt;/b&gt;&lt;/summary&gt;
&lt;br&gt;

```json
{
  &quot;inputs&quot;: [
    {
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;id&quot;: &quot;github_token&quot;,
      &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
      &quot;password&quot;: true
    }
  ],
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;-i&quot;,
        &quot;--rm&quot;,
        &quot;-e&quot;,
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
        &quot;ghcr.io/github/github-mcp-server&quot;
      ],
      &quot;env&quot;: {
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;
      }
    }
  }
}
```

&lt;/details&gt;

### Install in Other MCP Hosts

For other MCP host applications, please refer to our installation guides:

- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot
- **[Claude Code &amp; Claude Desktop](docs/installation-guides/install-claude.md)** - Installation guide for Claude Code and Claude Desktop
- **[Cursor](docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE
- **[Google Gemini CLI](docs/installation-guides/install-gemini-cli.md)** - Installation guide for Google Gemini CLI
- **[Windsurf](docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE

For a complete overview of all installation options, see our **[Installation Guides Index](docs/installation-guides)**.

&gt; **Note:** Any host application that supports local MCP servers should be able to access the local GitHub MCP server. However, the specific configuration process, syntax and stability of the integration will vary by host application. While many may follow a similar format to the examples above, this is not guaranteed. Please refer to your host application&#039;s documentation for the correct MCP configuration syntax and setup process.

### Build from source

If you don&#039;t have Docker, you can use `go build` to build the binary in the
`cmd/github-mcp-server` directory, and use the `github-mcp-server stdio` command with the `GITHUB_PERSONAL_ACCESS_TOKEN` environment variable set to your token. To specify the output location of the build, use the `-o` flag. You should configure your server to use the built executable as its `command`. For example:

```JSON
{
  &quot;mcp&quot;: {
    &quot;servers&quot;: {
      &quot;github&quot;: {
        &quot;command&quot;: &quot;/path/to/github-mcp-server&quot;,
        &quot;args&quot;: [&quot;stdio&quot;],
        &quot;env&quot;: {
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;&lt;YOUR_TOKEN&gt;&quot;
        }
      }
    }
  }
}
```

## Tool Configuration

The GitHub MCP Server supports enabling or disabling specific groups of functionalities via the `--toolsets` flag. This allows you to control which GitHub API capabilities are available to your AI tools. Enabling only the toolsets that you need can help the LLM with tool choice and reduce the context size.

_Toolsets are not limited to Tools. Relevant MCP Resources and Prompts are also included where applicable._

When no toolsets are specified, [default toolsets](#default-toolset) are used.

#### Specifying Toolsets

To specify toolsets you want available to the LLM, you can pass an allow-list in two ways:

1. **Using Command Line Argument**:

   ```bash
   github-mcp-server --toolsets repos,issues,pull_requests,actions,code_security
   ```

2. **Using Environment Variable**:
   ```bash
   GITHUB_TOOLSETS=&quot;repos,issues,pull_requests,actions,code_security&quot; ./github-mcp-server
   ```

The environment variable `GITHUB_TOOLSETS` takes precedence over the command line argument if both are provided.

### Using Toolsets With Docker

When using Docker, you can pass the toolsets as environment variables:

```bash
docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&lt;your-token&gt; \
  -e GITHUB_TOOLSETS=&quot;repos,issues,pull_requests,actions,code_security,experiments&quot; \
  ghcr.io/github/github-mcp-server
```

### Special toolsets

#### &quot;all&quot; toolset

The special toolset `all` can be provided to enable all available toolsets regardless of any other configuration:

```bash
./github-mcp-server --toolsets all
```

Or using the environment variable:

```bash
GITHUB_TOOLSETS=&quot;all&quot; ./github-mcp-server
```

#### &quot;default&quot; toolset
The default toolset `default` is the configuration that gets passed to the server if no toolsets are specified.

The default configuration is:
- context
- repos
- issues
- pull_requests
- users

To keep the default configuration and add additional toolsets:

```bash
GITHUB_TOOLSETS=&quot;default,stargazers&quot; ./github-mcp-server
```

### Available Toolsets

The following sets of tools are available:

&lt;!-- START AUTOMATED TOOLSETS --&gt;
| Toolset                 | Description                                                   |
| ----------------------- | ------------------------------------------------------------- |
| `context`               | **Strongly recommended**: Tools that provide context about the current user and GitHub context you are operating in |
| `actions` | GitHub Actions workflows and CI/CD operations |
| `code_security` | Code security related tools, such as GitHub Code Scanning |
| `dependabot` | Dependabot tools |
| `discussions` | GitHub Discussions related tools |
| `experiments` | Experimental features that are not considered stable yet |
| `gists` | GitHub Gist related tools |
| `issues` | GitHub Issues related tools |
| `labels` | GitHub Labels related tools |
| `notifications` | GitHub Notifications related tools |
| `orgs` | GitHub Organization related tools |
| `projects` | GitHub Projects related tools |
| `pull_requests` | GitHub Pull Request related tools |
| `repos` | GitHub Repository related tools |
| `secret_protection` | Secret protection related tools, such as GitHub Secret Scanning |
| `security_advisories` | Security advisories related tools |
| `stargazers` | GitHub Stargazers related tools |
| `users` | GitHub User related tools |
&lt;!-- END AUTOMATED TOOLSETS --&gt;

### Additional Toolsets in Remote Github MCP Server

| Toolset                 | Description                                                   |
| ----------------------- | ------------------------------------------------------------- |
| `copilot` | Copilot related tools (e.g. Copilot Coding Agent) |
| `copilot_spaces` | Copilot Spaces related tools |
| `github_support_docs_search` | Search docs to answer GitHub product and support questions |

## Tools

&lt;!-- START AUTOMATED TOOLS --&gt;
&lt;details&gt;

&lt;summary&gt;Actions&lt;/summary&gt;

- **cancel_workflow_run** - Cancel workflow run
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **delete_workflow_run_logs** - Delete workflow logs
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **download_workflow_run_artifact** - Download workflow artifact
  - `artifact_id`: The unique identifier of the artifact (number, required)
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)

- **get_job_logs** - Get job logs
  - `failed_only`: When true, gets logs for all failed jobs in run_id (boolean, optional)
  - `job_id`: The unique identifier of the workflow job (required for single job logs) (number, optional)
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `return_content`: Returns actual log content instead of URLs (boolean, optional)
  - `run_id`: Workflow run ID (required when using failed_only) (number, optional)
  - `tail_lines`: Number of lines to return from the end of the log (number, optional)

- **get_workflow_run** - Get workflow run
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **get_workflow_run_logs** - Get workflow run logs
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **get_workflow_run_usage** - Get workflow usage
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **list_workflow_jobs** - List workflow jobs
  - `filter`

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[derailed/k9s]]></title>
            <link>https://github.com/derailed/k9s</link>
            <guid>https://github.com/derailed/k9s</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[üê∂ Kubernetes CLI To Manage Your Clusters In Style!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/derailed/k9s">derailed/k9s</a></h1>
            <p>üê∂ Kubernetes CLI To Manage Your Clusters In Style!</p>
            <p>Language: Go</p>
            <p>Stars: 31,542</p>
            <p>Forks: 1,985</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;assets/k9s.png&quot; alt=&quot;k9s&quot;&gt;

## K9s - Kubernetes CLI To Manage Your Clusters In Style!

K9s provides a terminal UI to interact with your Kubernetes clusters.
The aim of this project is to make it easier to navigate, observe and manage
your applications in the wild. K9s continually watches Kubernetes
for changes and offers subsequent commands to interact with your observed resources.

---

## Note...

K9s is not pimped out by a big corporation with deep pockets.
It is a complex OSS project that demands a lot of my time to maintain and support.
K9s will always remain OSS and therefore free! That said, if you feel k9s makes your day to day Kubernetes journey a tad brighter, saves you time and makes you more productive, please consider [sponsoring us!](https://github.com/sponsors/derailed)
Your donations will go a long way in keeping our servers lights on and beers in our fridge!

**Thank you!**

---

[![Go Report Card](https://goreportcard.com/badge/github.com/derailed/k9s?)](https://goreportcard.com/report/github.com/derailed/k9s)
[![golangci badge](https://github.com/golangci/golangci-web/blob/master/src/assets/images/badge_a_plus_flat.svg)](https://golangci.com/r/github.com/derailed/k9s)
[![codebeat badge](https://codebeat.co/badges/89e5a80e-dfe8-4426-acf6-6be781e0a12e)](https://codebeat.co/projects/github-com-derailed-k9s-master)
[![Docker Repository on Quay](https://quay.io/repository/derailed/k9s/status &quot;Docker Repository on Quay&quot;)](https://quay.io/repository/derailed/k9s)
[![release](https://img.shields.io/github/release-pre/derailed/k9s.svg)](https://github.com/derailed/k9s/releases)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/mum4k/termdash/blob/master/LICENSE)
[![Releases](https://img.shields.io/github/downloads/derailed/k9s/total.svg)](https://github.com/derailed/k9s/releases)

---

## Screenshots

1. Pods
      &lt;img src=&quot;assets/screen_po.png&quot;/&gt;
2. Logs
      &lt;img src=&quot;assets/screen_logs.png&quot;/&gt;
3. Deployments
      &lt;img src=&quot;assets/screen_dp.png&quot;/&gt;

---

## Demo Videos/Recordings

* [K9s v0.40.0 -Column Blow- Sneak peek](https://youtu.be/iy6RDozAM4A)
* [K9s v0.31.0 Configs+Sneak peek](https://youtu.be/X3444KfjguE)
* [K9s v0.30.0 Sneak peek](https://youtu.be/mVBc1XneRJ4)
* [Vulnerability Scans](https://youtu.be/ULkl0MsaidU)
* [K9s v0.29.0](https://youtu.be/oiU3wmoAkBo)
* [K9s v0.21.3](https://youtu.be/wG8KCwDAhnw)
* [K9s v0.19.X](https://youtu.be/kj-WverKZ24)
* [K9s v0.18.0](https://www.youtube.com/watch?v=zMnD5e53yRw)
* [K9s v0.17.0](https://www.youtube.com/watch?v=7S33CNLAofk&amp;feature=youtu.be)
* [K9s Pulses](https://asciinema.org/a/UbXKPal6IWpTaVAjBBFmizcGN)
* [K9s v0.15.1](https://youtu.be/7Fx4XQ2ftpM)
* [K9s v0.13.0](https://www.youtube.com/watch?v=qaeR2iK7U0o&amp;t=15s)
* [K9s v0.9.0](https://www.youtube.com/watch?v=bxKfqumjW4I)
* [K9s v0.7.0 Features](https://youtu.be/83jYehwlql8)
* [K9s v0 Demo](https://youtu.be/k7zseUhaXeU)

---

## Documentation

Please refer to our [K9s documentation](https://k9scli.io) site for installation, usage, customization and tips.

---

## Slack Channel

Wanna discuss K9s features with your fellow `K9sers` or simply show your support for this tool?

* Channel: [K9sersSlack](https://k9sers.slack.com/)
* Invite: [K9slackers Invite](https://join.slack.com/t/k9sers/shared_invite/zt-3360a389v-ElLHrb0Dp1kAXqYUItSAFA)

---

## Installation

K9s is available on Linux, macOS and Windows platforms.
Binaries for Linux, Windows and Mac are available as tarballs in the [release page](https://github.com/derailed/k9s/releases).

* Via [Homebrew](https://brew.sh/) for macOS or Linux

   ```shell
   brew install derailed/k9s/k9s
   ```

* Via [MacPorts](https://www.macports.org)

   ```shell
   sudo port install k9s
   ```

* Via [snap](https://snapcraft.io/k9s) for Linux

  ```shell
  snap install k9s --devmode
  ```

* On Arch Linux

  ```shell
  pacman -S k9s
  ```

* On OpenSUSE Linux distribution

  ```shell
  zypper install k9s
  ```

* On FreeBSD

  ```shell
  pkg install k9s
  ```

* On Ubuntu

  ```shell
  wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_amd64.deb &amp;&amp; apt install ./k9s_linux_amd64.deb &amp;&amp; rm k9s_linux_amd64.deb
  ```

* Via [Winget](https://github.com/microsoft/winget-cli) for Windows

  ```shell
  winget install k9s
  ```

* Via [Scoop](https://scoop.sh) for Windows

  ```shell
  scoop install k9s
  ```

* Via [Chocolatey](https://chocolatey.org/packages/k9s) for Windows

  ```shell
  choco install k9s
  ```

* Via a GO install

  ```shell
  # NOTE: The dev version will be in effect!
  go install github.com/derailed/k9s@latest
  ```

* Via [Webi](https://webinstall.dev) for Linux and macOS

  ```shell
  curl -sS https://webinstall.dev/k9s | bash
  ```

* Via [pkgx](https://pkgx.dev/pkgs/k9scli.io/) for Linux and macOS

  ```shell
  pkgx k9s
  ```

* Via [gah](https://github.com/marverix/gah) for Linux and macOS

  ```shell
  gah install k9s
  ```

* Via [Webi](https://webinstall.dev) for Windows

  ```shell
  curl.exe -A MS https://webinstall.dev/k9s | powershell
  ```

* As a [Docker Desktop Extension](https://docs.docker.com/desktop/extensions/) (for the Docker Desktop built in Kubernetes Server)

  ```shell
  docker extension install spurin/k9s-dd-extension:latest
  ```

---

## Building From Source

 K9s is currently using GO v1.23.X or above.
 In order to build K9s from source you must:

 1. Clone the repo
 2. Build and run the executable

      ```shell
      make build &amp;&amp; ./execs/k9s
      ```

---

## Running with Docker

### Running the official Docker image

  You can run k9s as a Docker container by mounting your `KUBECONFIG`:

  ```shell
  docker run --rm -it -v $KUBECONFIG:/root/.kube/config quay.io/derailed/k9s
  ```

  For default path it would be:

  ```shell
  docker run --rm -it -v ~/.kube/config:/root/.kube/config quay.io/derailed/k9s
  ```

### Building your own Docker image

  You can build your own Docker image of k9s from the [Dockerfile](Dockerfile) with the following:

  ```shell
  docker build -t k9s-docker:v0.0.1 .
  ```

  You can get the latest stable `kubectl` version and pass it to the `docker build` command with the `--build-arg` option.
  You can use the `--build-arg` option to pass any valid `kubectl` version (like `v1.18.0` or `v1.19.1`).

  ```shell
  KUBECTL_VERSION=$(make kubectl-stable-version 2&gt;/dev/null)
  docker build --build-arg KUBECTL_VERSION=${KUBECTL_VERSION} -t k9s-docker:0.1 .
  ```

  Run your container:

  ```shell
  docker run --rm -it -v ~/.kube/config:/root/.kube/config k9s-docker:0.1
  ```

---

## PreFlight Checks

* K9s uses 256 colors terminal mode. On `Nix system make sure TERM is set accordingly.

    ```shell
    export TERM=xterm-256color
    ```

* In order to issue resource edit commands make sure your EDITOR and KUBE_EDITOR env vars are set.

    ```shell
    # Kubectl edit command will use this env var.
    export KUBE_EDITOR=my_fav_editor
    ```

* K9s prefers recent kubernetes versions ie 1.28+

---

## K8S Compatibility Matrix

|         k9s        | k8s client |
| ------------------ | ---------- |
|     &gt;= v0.27.0     |   1.26.1   |
| v0.26.7 - v0.26.6  |   1.25.3   |
| v0.26.5 - v0.26.4  |   1.25.1   |
| v0.26.3 - v0.26.1  |   1.24.3   |
| v0.26.0 - v0.25.19 |   1.24.2   |
| v0.25.18 - v0.25.3 |   1.22.3   |
| v0.25.2 - v0.25.0  |   1.22.0   |
|      &lt;= v0.24      |   1.21.3   |

---

## The Command Line

```shell
# List current version
k9s version

# To get info about K9s runtime (logs, configs, etc..)
k9s info

# List all available CLI options
k9s help

# To run K9s in a given namespace
k9s -n mycoolns

# Start K9s in an existing KubeConfig context
k9s --context coolCtx

# Start K9s in readonly mode - with all cluster modification commands disabled
k9s --readonly
```

## Logs And Debug Logs

Given the nature of the ui k9s does produce logs to a specific location.
To view the logs and turn on debug mode, use the following commands:

```shell
# Find out where the logs are stored
k9s info
```

```text
 ____  __.________
|    |/ _/   __   \______
|      &lt; \____    /  ___/
|    |  \   /    /\___ \
|____|__ \ /____//____  &gt;
        \/            \/

Version:           vX.Y.Z
Config:            /Users/fernand/.config/k9s/config.yaml
Logs:              /Users/fernand/.local/state/k9s/k9s.log
Dumps dir:         /Users/fernand/.local/state/k9s/screen-dumps
Benchmarks dir:    /Users/fernand/.local/state/k9s/benchmarks
Skins dir:         /Users/fernand/.local/share/k9s/skins
Contexts dir:      /Users/fernand/.local/share/k9s/clusters
Custom views file: /Users/fernand/.local/share/k9s/views.yaml
Plugins file:      /Users/fernand/.local/share/k9s/plugins.yaml
Hotkeys file:      /Users/fernand/.local/share/k9s/hotkeys.yaml
Alias file:        /Users/fernand/.local/share/k9s/aliases.yaml
```

### View K9s logs

```shell
tail -f /Users/fernand/.local/data/k9s/k9s.log
```

### Start K9s in debug mode

```shell
k9s -l debug
```

### Customize logs destination

You can override the default log file destination either with the `--logFile` argument:

```shell
k9s --logFile /tmp/k9s.log
less /tmp/k9s.log
```

Or through the `K9S_LOGS_DIR` environment variable:

```shell
K9S_LOGS_DIR=/var/log k9s
less /var/log/k9s.log
```

## Key Bindings

K9s uses aliases to navigate most K8s resources.

| Action                                                                          | Command                       | Comment                                                                |
|---------------------------------------------------------------------------------|-------------------------------|------------------------------------------------------------------------|
| Show active keyboard mnemonics and help                                         | `?`                           |                                                                        |
| Show all available resource alias                                               | `ctrl-a`                      |                                                                        |
| To bail out of K9s                                                              | `:quit`, `:q`, `ctrl-c`       |                                                                        |
| To go up/back to the previous view                                              | `esc`                         | If you have crumbs on, this will go to the previous one                |
| View a Kubernetes resource using singular/plural or short-name                  | `:`pod‚èé                       | accepts singular, plural, short-name or alias ie pod or pods           |
| View a Kubernetes resource in a given namespace                                 | `:`pod ns-x‚èé                  |                                                                        |
| View filtered pods (New v0.30.0!)                                               | `:`pod /fred‚èé                 | View all pods filtered by fred                                         |
| View labeled pods (New v0.30.0!)                                                | `:`pod app=fred,env=dev‚èé      | View all pods with labels matching app=fred and env=dev                |
| View pods in a given context (New v0.30.0!)                                     | `:`pod @ctx1‚èé                 | View all pods in context ctx1. Switches out your current k9s context!  |
| Filter out a resource view given a filter                                       | `/`filter‚èé                    | Regex2 supported ie `fred|blee` to filter resources named fred or blee |
| Inverse regex filter                                                            | `/`! filter‚èé                  | Keep everything that *doesn&#039;t* match.                                  |
| Filter resource view by labels                                                  | `/`-l label-selector‚èé         |                                                                        |
| Fuzzy find a resource given a filter                                            | `/`-f filter‚èé                 |                                                                        |
| Bails out of view/command/filter mode                                           | `&lt;esc&gt;`                       |                                                                        |
| Key mapping to describe, view, edit, view logs,...                              | `d`,`v`, `e`, `l`,...         |                                                                        |
| To view and switch to another Kubernetes context (Pod view)                     | `:`ctx‚èé                       |                                                                        |
| To view and switch directly to another Kubernetes context (Last used view)      | `:`ctx context-name‚èé          |                                                                        |
| To view and switch to another Kubernetes namespace                              | `:`ns‚èé                        |                                                                        |
| To switch back to the last active command (like how &quot;cd -&quot; works)               | `-`                           | Navigation that adds breadcrumbs to the bottom are not commands        |
| To go back and forward through the command history                              | back: `[`, forward: `]`       | Same as above                                                          |
| To view all saved resources                                                     | `:`screendump or sd‚èé          |                                                                        |
| To delete a resource (TAB and ENTER to confirm)                                 | `ctrl-d`                      |                                                                        |
| To kill a resource (no confirmation dialog, equivalent to kubectl delete --now) | `ctrl-k`                      |                                                                        |
| Launch pulses view                                                              | `:`pulses or pu‚èé              |                                                                        |
| Launch XRay view                                                                | `:`xray RESOURCE [NAMESPACE]‚èé | RESOURCE can be one of po, svc, dp, rs, sts, ds, NAMESPACE is optional |
| Launch Popeye view                                                              | `:`popeye or pop‚èé             | See [popeye](#popeye)                                                  |

---

## K9s Configuration

  K9s keeps its configurations as YAML files inside of a `k9s` directory and the location depends on your operating system. K9s leverages [XDG](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html) to load its various configurations files. For information on the default locations for your OS please see [this link](https://github.com/adrg/xdg/blob/master/README.md). If you are still confused a quick `k9s info` will reveal where k9s is loading its configurations from. Alternatively, you can set `K9S_CONFIG_DIR` to tell K9s the directory location to pull its configurations from.

  | Unix            | macOS                              | Windows               |
  |-----------------|------------------------------------|-----------------------|
  | `~/.config/k9s` | `~/Library/Application Support/k9s` | `%LOCALAPPDATA%\k9s`  |

  &gt; NOTE: This is still in flux and will change while in pre-release stage!

You can now override the context portForward default address configuration by setting an env variable that can override all clusters portForward local address using `K9S_DEFAULT_PF_ADDRESS=a.b.c.d`

  ```yaml
  # $XDG_CONFIG_HOME/k9s/config.yaml
  k9s:
    # Enable periodic refresh of resource browser windows. Default false
    liveViewAutoRefresh: false
    # !!New!! v0.50.8...
    # Extends the list of supported GPU vendors. The key is the vendor name, the value must correspond to k8s resource driver designation.
    # Default known GPU vendors:
    # nvidia: nvidia.com/gpu
	  # nvidia-shared: nvidia.com/gpu.shared
	  # amd: amd.com/gpu
	  # intel: gpu.intel.com/i915
    gpuVendors:
      bozo: bozo/gpu  # extends the gpu vendor and add &quot;bozo&quot;
    # The path to screen dump. Default: &#039;%temp_dir%/k9s-screens-%username%&#039; (k9s info)
    screenDumpDir: /tmp/dumps
    # Represents ui poll intervals in seconds. Default 2.0 secs. Minimum value is 2.0 - values below will be capped to the minimum.
    refreshRate: 2
    # Overrides the default k8s api server requests timeout. Defaults 120s
    apiServerTimeout: 15s
    # Number of retries once the connection to the api-server is lost. Default 15.
    maxConnRetry: 5
    # Indicates whether modification commands like delete/kill/edit are disabled. Default is false
    readOnly: false
    # This setting allows users to specify the default view, but it is not set by default.
    defaultView: &quot;&quot;
    # Toggles whether k9s should exit when CTRL-C is pressed. When set to true, you will need to exit k9s via the :quit command. Default is false.
    noExitOnCtrlC: false
    #UI settings
    ui:
      # Enable mouse support. Default false
      enableMouse: false
      # Set to true to hide K9s header. Default false
      headless: false
      # Set to true to hide the K9S logo Default false
      logoless: false
      # Set to true to hide K9s crumbs. Default false
      crumbsless: false
      # Set to true to suppress the K9s splash screen on start. Default false. Note that for larger clusters or higher latency connections, there may be no resources visible initially until local caches have finished populating.
      splashless: false
      # Toggles icons display as not all terminal support these chars. Default: true
      noIcons: false
      # Toggles reactive UI. This option provide for watching on disk artifacts changes and update the UI live Defaults to false.
      reactive: false
      # By default all contexts will use the dracula skin unless explicitly overridden in the context config file.
      skin: dracula # =&gt; assumes the file skins/dracula.yaml is present in the  $XDG_DATA_HOME/k9s/skins directory. Can be overriden with K9S_SKIN.
      # Allows to set certain views default fullscreen mode. (yaml, helm history, describe, value_extender, details, logs) Default false
      defaultsToFullScreen: false
      # Show full resource GVR (Group/Version/Resource) vs just R. Default: false.
      useFullGVRTitle: false
    # Toggles icons display as not all terminal support these chars.
    noIcons: false
    # Toggles whether k9s should check for the latest revision from the GitHub repository releases. Default is false.
    skipLatestRevCheck: false
    # When altering kubeconfig or using multiple kube configs, k9s will clean up clusters configurations that are no longer in use. Setting this flag to true will keep k9s from cleaning up inactive cluster configs. Defaults to false.
    keepMissingClusters: false
    # Logs configuration
    logger:
      # Defines the number of lines to return. Default 100
      tail: 200
      # Defines the total number of log lines to allow in the view. Default 1000
      buffer: 500
      # Represents how far to go back in the log timeline in seconds. Setting to -1 will tail logs. Default is -1.
      sinceSeconds: 300 # =&gt; tail the last 5 mins.
      # Toggles log line wrap. Default false
      textWrap: false
      # Autoscroll in logs will be disabled. Default is false.
      disableAutoscroll: false
      # Toggles log line timestamp info. Default false
      showTime: false
    # Provide shell pod customization when nodeShell feature gate is enabled!
    shellPod:
      # The shell pod image to use.
      image: killerAdmin
      # The namespace to launch to shell pod into.
      namespace: default
      # The resource limit to set on the shell 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[NVIDIA/nvidia-container-toolkit]]></title>
            <link>https://github.com/NVIDIA/nvidia-container-toolkit</link>
            <guid>https://github.com/NVIDIA/nvidia-container-toolkit</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[Build and run containers leveraging NVIDIA GPUs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NVIDIA/nvidia-container-toolkit">NVIDIA/nvidia-container-toolkit</a></h1>
            <p>Build and run containers leveraging NVIDIA GPUs</p>
            <p>Language: Go</p>
            <p>Stars: 3,740</p>
            <p>Forks: 422</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># NVIDIA Container Toolkit

[![GitHub license](https://img.shields.io/github/license/NVIDIA/nvidia-container-toolkit?style=flat-square)](https://raw.githubusercontent.com/NVIDIA/nvidia-container-toolkit/main/LICENSE)
[![Documentation](https://img.shields.io/badge/documentation-wiki-blue.svg?style=flat-square)](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html)
[![Package repository](https://img.shields.io/badge/packages-repository-b956e8.svg?style=flat-square)](https://nvidia.github.io/libnvidia-container)

![nvidia-container-stack](https://cloud.githubusercontent.com/assets/3028125/12213714/5b208976-b632-11e5-8406-38d379ec46aa.png)

## Introduction

The NVIDIA Container Toolkit allows users to build and run GPU-accelerated containers. The toolkit includes a container runtime [library](https://github.com/NVIDIA/libnvidia-container) and utilities to automatically configure containers to leverage NVIDIA GPUs.

Product documentation including an architecture overview, platform support, and installation and usage guides can be found in the [documentation repository](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html).

## Getting Started

**Make sure you have installed the [NVIDIA driver](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#nvidia-drivers) for your Linux Distribution**
**Note that you do not need to install the CUDA Toolkit on the host system, but the NVIDIA driver needs to be installed**

For instructions on getting started with the NVIDIA Container Toolkit, refer to the [installation guide](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installation-guide).

## Usage

The [user guide](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html) provides information on the configuration and command line options available when running GPU containers with Docker.

## Issues and Contributing

[Checkout the Contributing document!](CONTRIBUTING.md)

* Please let us know by [filing a new issue](https://github.com/NVIDIA/nvidia-container-toolkit/issues/new)
* You can contribute by creating a [pull request](https://github.com/NVIDIA/nvidia-container-toolkit/compare) to our public GitHub repository
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gravitational/teleport]]></title>
            <link>https://github.com/gravitational/teleport</link>
            <guid>https://github.com/gravitational/teleport</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[The easiest, and most secure way to access and protect all of your infrastructure.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gravitational/teleport">gravitational/teleport</a></h1>
            <p>The easiest, and most secure way to access and protect all of your infrastructure.</p>
            <p>Language: Go</p>
            <p>Stars: 19,243</p>
            <p>Forks: 1,937</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>Teleport provides connectivity, authentication, access controls and audit for infrastructure.

Here is why you might use Teleport:

* Set up SSO for all of your cloud infrastructure [1].
* Protect access to cloud and on-prem services using mTLS endpoints and short-lived certificates.
* Establish tunnels to access services behind NATs and firewalls.
* Provide an audit log with session recording and replay for various protocols.
* Unify Role-Based Access Control (RBAC) and enforce the principle of least privilege with  [access requests](https://goteleport.com/features/access-requests/).

[1] The open source version supports only GitHub SSO.

Teleport works with SSH, Kubernetes, databases, RDP, and web services.

* Architecture: https://goteleport.com/docs/reference/architecture/
* Getting Started: https://goteleport.com/docs/get-started/

&lt;div align=&quot;center&quot;&gt;
   &lt;a href=&quot;https://goteleport.com/download&quot;&gt;
   &lt;img src=&quot;./assets/img/hero-teleport-platform.png&quot; width=750/&gt;
   &lt;/a&gt;
   &lt;div align=&quot;center&quot; style=&quot;padding: 25px&quot;&gt;
      &lt;a href=&quot;https://goteleport.com/download&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/github/v/release/gravitational/teleport?sort=semver&amp;label=Release&amp;color=651FFF&quot; /&gt;
      &lt;/a&gt;
      &lt;a href=&quot;https://golang.org/&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/github/go-mod/go-version/gravitational/teleport?color=7fd5ea&quot; /&gt;
      &lt;/a&gt;
      &lt;a href=&quot;https://github.com/gravitational/teleport/blob/master/CODE_OF_CONDUCT.md&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Contribute-üôå-green.svg&quot; /&gt;
      &lt;/a&gt;
      &lt;a href=&quot;https://www.gnu.org/licenses/agpl-3.0.en.html&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/AGPL-3.0-red.svg&quot; /&gt;
      &lt;/a&gt;
   &lt;/div&gt;
&lt;/div&gt;
&lt;/br&gt;

## Table of Contents

1. [Introduction](#introduction)
1. [Installing and Running](#installing-and-running)
1. [Docker](#docker)
1. [Building Teleport](#building-teleport)
1. [Why Did We Build Teleport?](#why-did-we-build-teleport)
1. [More Information](#more-information)
1. [Support and Contributing](#support-and-contributing)
1. [Is Teleport Secure and Production Ready?](#is-teleport-secure-and-production-ready)
1. [Who Built Teleport?](#who-built-teleport)
1. [License](#license)

## Introduction

Teleport includes an identity-aware access proxy, a CA that issues short-lived certificates, a unified access control system and a tunneling system to access resources behind the firewall.

We have implemented Teleport as a single Go binary that integrates with multiple protocols and cloud services:

* [SSH nodes](https://goteleport.com/docs/enroll-resources/server-access/introduction/).
* [Kubernetes clusters](https://goteleport.com/docs/enroll-resources/kubernetes-access/introduction/)
* [PostgreSQL, MongoDB, CockroachDB and MySQL databases](https://goteleport.com/docs/enroll-resources/database-access/).
* [Internal Web apps](https://goteleport.com/docs/enroll-resources/application-access/introduction/).
* [Windows Hosts](https://goteleport.com/docs/enroll-resources/desktop-access/introduction/).
* [Networked servers](https://goteleport.com/docs/enroll-resources/server-access/introduction/).

You can set up Teleport as a [Linux daemon](https://goteleport.com/docs/admin-guides/deploy-a-cluster/linux-demo) or a [Kubernetes deployment](https://goteleport.com/docs/admin-guides/deploy-a-cluster/helm-deployments/).

Teleport focuses on best practices for infrastructure security:

- No need to manage shared secrets such as SSH keys or Kubernetes tokens: it uses certificate-based auth with certificate expiration for all protocols.
- Two-factor authentication (2FA) for everything.
- Collaboratively troubleshoot issues through session sharing.
- Single sign-on (SSO) for everything via GitHub Auth, OpenID Connect, or SAML with endpoints like Okta or Microsoft Entra ID.
- Infrastructure introspection: Use Teleport via the CLI or Web UI to view the status of every SSH node, database instance, Kubernetes cluster, or internal web app.

Teleport uses [Go crypto](https://godoc.org/golang.org/x/crypto). It is _fully compatible with OpenSSH_, `sshd` servers, and `ssh` clients, Kubernetes clusters and more.

|Project Links| Description
|---|----
| [Teleport Website](https://goteleport.com/) | The official website of the project. |
| [Documentation](https://goteleport.com/docs/) | Admin guide, user manual and more. |
| [Blog](https://goteleport.com/blog/) | Our blog where we publish Teleport news. |
| [Forum](https://github.com/gravitational/teleport/discussions) | Ask us a setup question, post your tutorial, feedback, or idea on our forum. |
| [Slack](https://goteleport.com/slack) | Need help with your setup? Ping us in our Slack channel. |
| [Cloud-hosted](https://goteleport.com/pricing) | We offer Enterprise with a Cloud-hosted option. For teams that require easy and secure access to their computing environments. |


## Installing and Running

To set up a single-instance Teleport cluster, follow our [getting started
guide](https://goteleport.com/docs/admin-guides/deploy-a-cluster/linux-demo/). You can then register your
servers, Kubernetes clusters, and other infrastructure with your Teleport
cluster.

You can also get started with Teleport Enterprise Cloud, a managed Teleport
deployment that makes it easier to enable secure access to your infrastructure.

[Sign up for a free trial](https://goteleport.com/signup) of Teleport Enterprise
Cloud.

Follow our guide to [registering your first
server](https://goteleport.com/docs/get-started/)
with Teleport Enterprise Cloud.

## Docker

### Deploy Teleport

If you wish to deploy Teleport inside a Docker container see the
[installation guide](https://goteleport.com/docs/installation/#running-teleport-on-docker).

### For Local Testing and Development

To run a full test suite locally, see [the test dependencies list](BUILD_macos.md#local-tests-dependencies)

## Building Teleport

The `teleport` repository contains the Teleport daemon binary (written in Go)
and a web UI written in TypeScript.

If your intention is to build and deploy for use in a production infrastructure
a released tag should be used.  The default branch, `master`, is the current
development branch for an upcoming major version.  Get the latest release tags
listed at https://goteleport.com/download/ and then use that tag in the `git clone`.
For example `git clone https://github.com/gravitational/teleport.git -b v16.0.0` gets release v16.0.0.

### Dockerized Build

It is often easiest to build with Docker, which ensures that all required
tooling is available for the build. To execute a dockerized build, ensure
that docker is installed and running, and execute:

```
make -C build.assets build-binaries
```

### Local Build

#### Dependencies

The following dependencies are required to build Teleport from source. For
maximum compatibility, install the versions of these dependencies using the
versions listed in [`build.assets/versions.mk`](/build.assets/versions.mk):

1. [`Go`](https://golang.org/dl/)
1. [`Rust`](https://www.rust-lang.org/tools/install)
1. [`Node.js`](https://nodejs.org/en/download/)
1. [`libfido2`](https://github.com/Yubico/libfido2)
1. [`pkg-config`](https://www.freedesktop.org/wiki/Software/pkg-config/)

For an example of Dev Environment setup on a Mac, see [these
instructions](/BUILD_macos.md).

#### Perform a build

&gt;**Important**
&gt;
&gt;* The Go compiler is somewhat sensitive to the amount of memory: you will need
   **at least** 1GB of virtual memory to compile Teleport. A 512MB instance
   without swap will **not** work.
&gt;* This will build the latest version of Teleport, **regardless** of whether it
   is stable. If you want to build the latest stable release, run `git checkout`
   and `git submodule update --recursive` to the corresponding tag (for example,
&gt;* run `git checkout v8.0.0`) **before** performing a build.

Get the source

```shell
git clone https://github.com/gravitational/teleport.git
cd teleport
```

To perform a build

```shell
make full
```

`tsh` dynamically links against libfido2 by default, to support development
environments, as long as the library itself can be found:

```shell
$ brew install libfido2 pkg-config  # Replace with your package manager of choice

$ make build/tsh
&gt; libfido2 found, setting FIDO2=dynamic
&gt; (...)
```

Release binaries are linked statically against libfido2. You may switch the
linking mode using the FIDO2 variable:

```shell
make build/tsh FIDO2=dynamic # dynamic linking
make build/tsh FIDO2=static  # static linking, for an easy setup use `make enter`
                             # or `build.assets/macos/build-fido2-macos.sh`.
make build/tsh FIDO2=off     # doesn&#039;t link libfido2 in any way
```

`tsh` builds with Touch ID support require access to an Apple Developer account.
If you are a Teleport maintainer, ask the team for access.

#### Build output and run locally

If the build succeeds, the installer will place the binaries in the `build` directory.

Before starting, create default data directories:

```shell
sudo mkdir -p -m0700 /var/lib/teleport
sudo chown $USER /var/lib/teleport
```

#### Running Teleport in a hot reload mode

To speed up your development process, you can run Teleport using
[`CompileDaemon`](https://github.com/githubnemo/CompileDaemon). This will build
and run the Teleport binary, and then rebuild and restart it whenever any Go
source files change.

1. Install CompileDaemon:

    ```shell
    go install github.com/githubnemo/CompileDaemon@latest
    ```

    Note that we use `go install` instead of the suggested `go get`, because we
    don&#039;t want CompileDaemon to become a dependency of the project.

1. Build and run the Teleport binary:

    ```shell
    make teleport-hot-reload
    ```

    By default, this runs a `teleport start` command. If you want to customize
    the command, for example by providing a custom config file location, you can
    use the `TELEPORT_ARGS` parameter:

    ```shell
    make teleport-hot-reload TELEPORT_ARGS=&#039;start --config=/path/to/config.yaml&#039;
    ```

Note that you still need to run [`make grpc`](api/proto/README.md) if you modify
any Protocol Buffers files to regenerate the generated Go sources; regenerating
these sources should in turn cause the CompileDaemon to rebuild and restart
Teleport.

### Web UI

The Teleport Web UI resides in the [web](web) directory.

#### Rebuilding Web UI for development

To rebuild the Teleport UI package, run the following command:

```bash
make docker-ui
```

Then you can replace Teleport Web UI files with the files from the newly-generated `/dist` folder.

To enable speedy iterations on the Web UI, you can run a [local web-dev server](web#web-ui).

You can also tell Teleport to load the Web UI assets from the source directory.
To enable this behavior, set the environment variable `DEBUG=1` and rebuild with the default target:

```bash
# Run Teleport as a single-node cluster in development mode:
DEBUG=1 ./build/teleport start -d
```

Keep the server running in this mode, and make your UI changes in `/dist` directory.
For instructions about how to update the Web UI, read [the `web` README](web#readme).

### Managing dependencies

All dependencies are managed using [Go modules](https://blog.golang.org/using-go-modules). Here are the instructions for some common tasks:

#### Add a new dependency

Latest version:

```bash
go get github.com/new/dependency
```

and update the source to use this dependency.


To get a specific version, use `go get github.com/new/dependency@version` instead.

#### Set dependency to a specific version

```bash
go get github.com/new/dependency@version
```

#### Update dependency to the latest version

```bash
go get -u github.com/new/dependency
```

#### Update all dependencies

```bash
go get -u all
```

#### Debugging dependencies

Why is a specific package imported?

`go mod why $pkgname`

Why is a specific module imported?

`go mod why -m $modname`

Why is a specific version of a module imported?

`go mod graph | grep $modname`

## Why did We Build Teleport?

The Teleport creators used to work together at Rackspace. We noticed that most cloud computing users struggle with setting up and configuring infrastructure security because popular tools, while flexible, are complex to understand and expensive to maintain. Additionally, most organizations use multiple infrastructure form factors such as several cloud providers, multiple cloud accounts, servers in colocation, and even smart devices. Some of those devices run on untrusted networks, behind third-party firewalls. This only magnifies complexity and increases operational overhead.

We had a choice, either start a security consulting business or build a solution that&#039;s dead-easy to use and understand. A real-time representation of all of your servers in the same room as you, as if they were magically _teleported_. Thus, Teleport was born!

## More Information

* [Teleport Getting Started](https://goteleport.com/docs/get-started/)
* [Teleport
  Architecture](https://goteleport.com/docs/reference/architecture/)
* [Reference](https://goteleport.com/docs/reference/)
* [FAQ](https://goteleport.com/docs/faq)

## Support and Contributing

We offer a few different options for support. First of all, we try to provide clear and comprehensive documentation. The docs are also in GitHub, so feel free to create a PR or file an issue if you have ideas for improvements. If you still have questions after reviewing our docs, you can also:

* Join [Teleport Discussions](https://github.com/gravitational/teleport/discussions) to ask questions. Our engineers are available there to help you.
* If you want to contribute to Teleport or file a bug report/issue, you can create an issue here in GitHub.
* If you are interested in Teleport Enterprise or more responsive support during a POC, we can also create a dedicated Slack channel for you during your POC. You can [reach out to us through our website](https://goteleport.com/pricing/) to arrange for a POC.

## Is Teleport Secure and Production-Ready?

Yes -- Teleport is production-ready and designed to protect and facilitate
access to the most precious and mission-critical applications.

Teleport has completed several security audits from nationally and
internationally recognized technology security companies.

We publicize some of our audit results, security philosophy and related
information on our [trust page](https://trust.goteleport.com/).

You can see the list of companies that use Teleport in production on the Teleport
[product page](https://goteleport.com/case-study/).

## Who Built Teleport?

Teleport was created by [Gravitational, Inc.](https://goteleport.com). We have
built Teleport by borrowing from our previous experiences at Rackspace. [Learn more
about Teleport and our history](https://goteleport.com/about/).

## License

Teleport is distributed in multiple forms with different licensing implications.

The Teleport API module (all code in this repository under `/api`) is available
under the [Apache 2.0 license](./api/LICENSE).

The remainder of the source code in this repository is available under the
[GNU Affero General Public License](./LICENSE). Users compiling Teleport
from source must comply with the terms of this license.

Teleport Community Edition builds distributed on http://goteleport.com/download
are available under a [modified Apache 2.0 license](./build.assets/LICENSE-community).
# tickattack
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ollama/ollama]]></title>
            <link>https://github.com/ollama/ollama</link>
            <guid>https://github.com/ollama/ollama</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ollama/ollama">ollama/ollama</a></h1>
            <p>Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.</p>
            <p>Language: Go</p>
            <p>Stars: 154,286</p>
            <p>Forks: 13,400</p>
            <p>Stars today: 79 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
¬† &lt;a href=&quot;https://ollama.com&quot;&gt;
    &lt;img alt=&quot;ollama&quot; width=&quot;240&quot; src=&quot;https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

# Ollama

Get up and running with large language models.

### macOS

[Download](https://ollama.com/download/Ollama.dmg)

### Windows

[Download](https://ollama.com/download/OllamaSetup.exe)

### Linux

```shell
curl -fsSL https://ollama.com/install.sh | sh
```

[Manual install instructions](https://github.com/ollama/ollama/blob/main/docs/linux.md)

### Docker

The official [Ollama Docker image](https://hub.docker.com/r/ollama/ollama) `ollama/ollama` is available on Docker Hub.

### Libraries

- [ollama-python](https://github.com/ollama/ollama-python)
- [ollama-js](https://github.com/ollama/ollama-js)

### Community

- [Discord](https://discord.gg/ollama)
- [Reddit](https://reddit.com/r/ollama)

## Quickstart

To run and chat with [Gemma 3](https://ollama.com/library/gemma3):

```shell
ollama run gemma3
```

## Model library

Ollama supports a list of models available on [ollama.com/library](https://ollama.com/library &#039;ollama model library&#039;)

Here are some example models that can be downloaded:

| Model              | Parameters | Size  | Download                         |
| ------------------ | ---------- | ----- | -------------------------------- |
| Gemma 3            | 1B         | 815MB | `ollama run gemma3:1b`           |
| Gemma 3            | 4B         | 3.3GB | `ollama run gemma3`              |
| Gemma 3            | 12B        | 8.1GB | `ollama run gemma3:12b`          |
| Gemma 3            | 27B        | 17GB  | `ollama run gemma3:27b`          |
| QwQ                | 32B        | 20GB  | `ollama run qwq`                 |
| DeepSeek-R1        | 7B         | 4.7GB | `ollama run deepseek-r1`         |
| DeepSeek-R1        | 671B       | 404GB | `ollama run deepseek-r1:671b`    |
| Llama 4            | 109B       | 67GB  | `ollama run llama4:scout`        |
| Llama 4            | 400B       | 245GB | `ollama run llama4:maverick`     |
| Llama 3.3          | 70B        | 43GB  | `ollama run llama3.3`            |
| Llama 3.2          | 3B         | 2.0GB | `ollama run llama3.2`            |
| Llama 3.2          | 1B         | 1.3GB | `ollama run llama3.2:1b`         |
| Llama 3.2 Vision   | 11B        | 7.9GB | `ollama run llama3.2-vision`     |
| Llama 3.2 Vision   | 90B        | 55GB  | `ollama run llama3.2-vision:90b` |
| Llama 3.1          | 8B         | 4.7GB | `ollama run llama3.1`            |
| Llama 3.1          | 405B       | 231GB | `ollama run llama3.1:405b`       |
| Phi 4              | 14B        | 9.1GB | `ollama run phi4`                |
| Phi 4 Mini         | 3.8B       | 2.5GB | `ollama run phi4-mini`           |
| Mistral            | 7B         | 4.1GB | `ollama run mistral`             |
| Moondream 2        | 1.4B       | 829MB | `ollama run moondream`           |
| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`         |
| Starling           | 7B         | 4.1GB | `ollama run starling-lm`         |
| Code Llama         | 7B         | 3.8GB | `ollama run codellama`           |
| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored`   |
| LLaVA              | 7B         | 4.5GB | `ollama run llava`               |
| Granite-3.3         | 8B         | 4.9GB | `ollama run granite3.3`          |

&gt; [!NOTE]
&gt; You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.

## Customize a model

### Import from GGUF

Ollama supports importing GGUF models in the Modelfile:

1. Create a file named `Modelfile`, with a `FROM` instruction with the local filepath to the model you want to import.

   ```
   FROM ./vicuna-33b.Q4_0.gguf
   ```

2. Create the model in Ollama

   ```shell
   ollama create example -f Modelfile
   ```

3. Run the model

   ```shell
   ollama run example
   ```

### Import from Safetensors

See the [guide](docs/import.md) on importing models for more information.

### Customize a prompt

Models from the Ollama library can be customized with a prompt. For example, to customize the `llama3.2` model:

```shell
ollama pull llama3.2
```

Create a `Modelfile`:

```
FROM llama3.2

# set the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# set the system message
SYSTEM &quot;&quot;&quot;
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
&quot;&quot;&quot;
```

Next, create and run the model:

```
ollama create mario -f ./Modelfile
ollama run mario
&gt;&gt;&gt; hi
Hello! It&#039;s your friend Mario.
```

For more information on working with a Modelfile, see the [Modelfile](docs/modelfile.md) documentation.

## CLI Reference

### Create a model

`ollama create` is used to create a model from a Modelfile.

```shell
ollama create mymodel -f ./Modelfile
```

### Pull a model

```shell
ollama pull llama3.2
```

&gt; This command can also be used to update a local model. Only the diff will be pulled.

### Remove a model

```shell
ollama rm llama3.2
```

### Copy a model

```shell
ollama cp llama3.2 my-model
```

### Multiline input

For multiline input, you can wrap text with `&quot;&quot;&quot;`:

```
&gt;&gt;&gt; &quot;&quot;&quot;Hello,
... world!
... &quot;&quot;&quot;
I&#039;m a basic program that prints the famous &quot;Hello, world!&quot; message to the console.
```

### Multimodal models

```
ollama run llava &quot;What&#039;s in this image? /Users/jmorgan/Desktop/smile.png&quot;
```

&gt; **Output**: The image features a yellow smiley face, which is likely the central focus of the picture.

### Pass the prompt as an argument

```shell
ollama run llama3.2 &quot;Summarize this file: $(cat README.md)&quot;
```

&gt; **Output**: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.

### Show model information

```shell
ollama show llama3.2
```

### List models on your computer

```shell
ollama list
```

### List which models are currently loaded

```shell
ollama ps
```

### Stop a model which is currently running

```shell
ollama stop llama3.2
```

### Start Ollama

`ollama serve` is used when you want to start ollama without running the desktop application.

## Building

See the [developer guide](https://github.com/ollama/ollama/blob/main/docs/development.md)

### Running local builds

Next, start the server:

```shell
./ollama serve
```

Finally, in a separate shell, run a model:

```shell
./ollama run llama3.2
```

## REST API

Ollama has a REST API for running and managing models.

### Generate a response

```shell
curl http://localhost:11434/api/generate -d &#039;{
  &quot;model&quot;: &quot;llama3.2&quot;,
  &quot;prompt&quot;:&quot;Why is the sky blue?&quot;
}&#039;
```

### Chat with a model

```shell
curl http://localhost:11434/api/chat -d &#039;{
  &quot;model&quot;: &quot;llama3.2&quot;,
  &quot;messages&quot;: [
    { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;why is the sky blue?&quot; }
  ]
}&#039;
```

See the [API documentation](./docs/api.md) for all endpoints.

## Community Integrations

### Web &amp; Desktop

- [Open WebUI](https://github.com/open-webui/open-webui)
- [SwiftChat (macOS with ReactNative)](https://github.com/aws-samples/swift-chat)
- [Enchanted (macOS native)](https://github.com/AugustDev/enchanted)
- [Hollama](https://github.com/fmaclen/hollama)
- [Lollms-Webui](https://github.com/ParisNeo/lollms-webui)
- [LibreChat](https://github.com/danny-avila/LibreChat)
- [Bionic GPT](https://github.com/bionic-gpt/bionic-gpt)
- [HTML UI](https://github.com/rtcfirefly/ollama-ui)
- [Saddle](https://github.com/jikkuatwork/saddle)
- [TagSpaces](https://www.tagspaces.org) (A platform for file-based apps, [utilizing Ollama](https://docs.tagspaces.org/ai/) for the generation of tags and descriptions)
- [Chatbot UI](https://github.com/ivanfioravanti/chatbot-ollama)
- [Chatbot UI v2](https://github.com/mckaywrigley/chatbot-ui)
- [Typescript UI](https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file)
- [Minimalistic React UI for Ollama Models](https://github.com/richawo/minimal-llm-ui)
- [Ollamac](https://github.com/kevinhermawan/Ollamac)
- [big-AGI](https://github.com/enricoros/big-AGI)
- [Cheshire Cat assistant framework](https://github.com/cheshire-cat-ai/core)
- [Amica](https://github.com/semperai/amica)
- [chatd](https://github.com/BruceMacD/chatd)
- [Ollama-SwiftUI](https://github.com/kghandour/Ollama-SwiftUI)
- [Dify.AI](https://github.com/langgenius/dify)
- [MindMac](https://mindmac.app)
- [NextJS Web Interface for Ollama](https://github.com/jakobhoeg/nextjs-ollama-llm-ui)
- [Msty](https://msty.app)
- [Chatbox](https://github.com/Bin-Huang/Chatbox)
- [WinForm Ollama Copilot](https://github.com/tgraupmann/WinForm_Ollama_Copilot)
- [NextChat](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web) with [Get Started Doc](https://docs.nextchat.dev/models/ollama)
- [Alpaca WebUI](https://github.com/mmo80/alpaca-webui)
- [OllamaGUI](https://github.com/enoch1118/ollamaGUI)
- [OpenAOE](https://github.com/InternLM/OpenAOE)
- [Odin Runes](https://github.com/leonid20000/OdinRunes)
- [LLM-X](https://github.com/mrdjohnson/llm-x) (Progressive Web App)
- [AnythingLLM (Docker + MacOs/Windows/Linux native app)](https://github.com/Mintplex-Labs/anything-llm)
- [Ollama Basic Chat: Uses HyperDiv Reactive UI](https://github.com/rapidarchitect/ollama_basic_chat)
- [Ollama-chats RPG](https://github.com/drazdra/ollama-chats)
- [IntelliBar](https://intellibar.app/) (AI-powered assistant for macOS)
- [Jirapt](https://github.com/AliAhmedNada/jirapt) (Jira Integration to generate issues, tasks, epics)
- [ojira](https://github.com/AliAhmedNada/ojira) (Jira chrome plugin to easily generate descriptions for tasks)
- [QA-Pilot](https://github.com/reid41/QA-Pilot) (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)
- [ChatOllama](https://github.com/sugarforever/chat-ollama) (Open Source Chatbot based on Ollama with Knowledge Bases)
- [CRAG Ollama Chat](https://github.com/Nagi-ovo/CRAG-Ollama-Chat) (Simple Web Search with Corrective RAG)
- [RAGFlow](https://github.com/infiniflow/ragflow) (Open-source Retrieval-Augmented Generation engine based on deep document understanding)
- [StreamDeploy](https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold) (LLM Application Scaffold)
- [chat](https://github.com/swuecho/chat) (chat web app for teams)
- [Lobe Chat](https://github.com/lobehub/lobe-chat) with [Integrating Doc](https://lobehub.com/docs/self-hosting/examples/ollama)
- [Ollama RAG Chatbot](https://github.com/datvodinh/rag-chatbot.git) (Local Chat with multiple PDFs using Ollama and RAG)
- [BrainSoup](https://www.nurgo-software.com/products/brainsoup) (Flexible native client with RAG &amp; multi-agent automation)
- [macai](https://github.com/Renset/macai) (macOS client for Ollama, ChatGPT, and other compatible API back-ends)
- [RWKV-Runner](https://github.com/josStorer/RWKV-Runner) (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)
- [Ollama Grid Search](https://github.com/dezoito/ollama-grid-search) (app to evaluate and compare models)
- [Olpaka](https://github.com/Otacon/olpaka) (User-friendly Flutter Web App for Ollama)
- [Casibase](https://casibase.org) (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)
- [OllamaSpring](https://github.com/CrazyNeil/OllamaSpring) (Ollama Client for macOS)
- [LLocal.in](https://github.com/kartikm7/llocal) (Easy to use Electron Desktop Client for Ollama)
- [Shinkai Desktop](https://github.com/dcSpark/shinkai-apps) (Two click install Local AI using Ollama + Files + RAG)
- [AiLama](https://github.com/zeyoyt/ailama) (A Discord User App that allows you to interact with Ollama anywhere in Discord)
- [Ollama with Google Mesop](https://github.com/rapidarchitect/ollama_mesop/) (Mesop Chat Client implementation with Ollama)
- [R2R](https://github.com/SciPhi-AI/R2R) (Open-source RAG engine)
- [Ollama-Kis](https://github.com/elearningshow/ollama-kis) (A simple easy-to-use GUI with sample custom LLM for Drivers Education)
- [OpenGPA](https://opengpa.org) (Open-source offline-first Enterprise Agentic Application)
- [Painting Droid](https://github.com/mateuszmigas/painting-droid) (Painting app with AI integrations)
- [Kerlig AI](https://www.kerlig.com/) (AI writing assistant for macOS)
- [AI Studio](https://github.com/MindWorkAI/AI-Studio)
- [Sidellama](https://github.com/gyopak/sidellama) (browser-based LLM client)
- [LLMStack](https://github.com/trypromptly/LLMStack) (No-code multi-agent framework to build LLM agents and workflows)
- [BoltAI for Mac](https://boltai.com) (AI Chat Client for Mac)
- [Harbor](https://github.com/av/harbor) (Containerized LLM Toolkit with Ollama as default backend)
- [PyGPT](https://github.com/szczyglis-dev/py-gpt) (AI desktop assistant for Linux, Windows, and Mac)
- [Alpaca](https://github.com/Jeffser/Alpaca) (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)
- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT/blob/master/docs/content/platform/ollama.md) (AutoGPT Ollama integration)
- [Go-CREW](https://www.jonathanhecl.com/go-crew/) (Powerful Offline RAG in Golang)
- [PartCAD](https://github.com/openvmp/partcad/) (CAD model generation with OpenSCAD and CadQuery)
- [Ollama4j Web UI](https://github.com/ollama4j/ollama4j-web-ui) - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j
- [PyOllaMx](https://github.com/kspviswa/pyOllaMx) - macOS application capable of chatting with both Ollama and Apple MLX models.
- [Cline](https://github.com/cline/cline) - Formerly known as Claude Dev is a VSCode extension for multi-file/whole-repo coding
- [Cherry Studio](https://github.com/kangfenmao/cherry-studio) (Desktop client with Ollama support)
- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)
- [Archyve](https://github.com/nickthecook/archyve) (RAG-enabling document library)
- [crewAI with Mesop](https://github.com/rapidarchitect/ollama-crew-mesop) (Mesop Web Interface to run crewAI with Ollama)
- [Tkinter-based client](https://github.com/chyok/ollama-gui) (Python tkinter-based Client for Ollama)
- [LLMChat](https://github.com/trendy-design/llmchat) (Privacy focused, 100% local, intuitive all-in-one chat interface)
- [Local Multimodal AI Chat](https://github.com/Leon-Sander/Local-Multimodal-AI-Chat) (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)
- [ARGO](https://github.com/xark-argo/argo) (Locally download and run Ollama and Huggingface models with RAG and deep research on Mac/Windows/Linux)
- [OrionChat](https://github.com/EliasPereirah/OrionChat) - OrionChat is a web interface for chatting with different AI providers
- [G1](https://github.com/bklieger-groq/g1) (Prototype of using prompting strategies to improve the LLM&#039;s reasoning through o1-like reasoning chains.)
- [Web management](https://github.com/lemonit-eric-mao/ollama-web-management) (Web management page)
- [Promptery](https://github.com/promptery/promptery) (desktop client for Ollama.)
- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)
- [chat-ollama](https://github.com/annilq/chat-ollama) (a React Native client for Ollama)
- [SpaceLlama](https://github.com/tcsenpai/spacellama) (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)
- [YouLama](https://github.com/tcsenpai/youlama) (Webapp to quickly summarize any YouTube video, supporting Invidious as well)
- [DualMind](https://github.com/tcsenpai/dualmind) (Experimental app allowing two models to talk to each other in the terminal or in a web interface)
- [ollamarama-matrix](https://github.com/h1ddenpr0cess20/ollamarama-matrix) (Ollama chatbot for the Matrix chat protocol)
- [ollama-chat-app](https://github.com/anan1213095357/ollama-chat-app) (Flutter-based chat app)
- [Perfect Memory AI](https://www.perfectmemory.ai/) (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)
- [Hexabot](https://github.com/hexastack/hexabot) (A conversational AI builder)
- [Reddit Rate](https://github.com/rapidarchitect/reddit_analyzer) (Search and Rate Reddit topics with a weighted summation)
- [OpenTalkGpt](https://github.com/adarshM84/OpenTalkGpt) (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)
- [VT](https://github.com/vinhnx/vt.ai) (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)
- [Nosia](https://github.com/nosia-ai/nosia) (Easy to install and use RAG platform based on Ollama)
- [Witsy](https://github.com/nbonamy/witsy) (An AI Desktop application available for Mac/Windows/Linux)
- [Abbey](https://github.com/US-Artificial-Intelligence/abbey) (A configurable AI interface server with notebooks, document storage, and YouTube support)
- [Minima](https://github.com/dmayboroda/minima) (RAG with on-premises or fully local workflow)
- [aidful-ollama-model-delete](https://github.com/AidfulAI/aidful-ollama-model-delete) (User interface for simplified model cleanup)
- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) (An AI-powered search engine &amp; an open-source alternative to Perplexity AI)
- [Ollama Chat WebUI for Docker ](https://github.com/oslook/ollama-webui) (Support for local docker deployment, lightweight ollama webui)
- [AI Toolkit for Visual Studio Code](https://aka.ms/ai-tooklit/ollama-docs) (Microsoft-official VSCode extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)
- [MinimalNextOllamaChat](https://github.com/anilkay/MinimalNextOllamaChat) (Minimal Web UI for Chat and Model Control)
- [Chipper](https://github.com/TilmanGriesel/chipper) AI interface for tinkerers (Ollama, Haystack RAG, Python)
- [ChibiChat](https://github.com/CosmicEventHorizon/ChibiChat) (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)
- [LocalLLM](https://github.com/qusaismael/localllm) (Minimal Web-App to run ollama models on it with a GUI)
- [Ollamazing](https://github.com/buiducnhat/ollamazing) (Web extension to run Ollama models)
- [OpenDeepResearcher-via-searxng](https://github.com/benhaotang/OpenDeepResearcher-via-searxng) (A Deep Research equivalent endpoint with Ollama support for running locally)
- [AntSK](https://github.com/AIDotNet/AntSK) (Out-of-the-box &amp; Adaptable RAG Chatbot)
- [MaxKB](https://github.com/1Panel-dev/MaxKB/) (Ready-to-use &amp; flexible RAG Chatbot)
- [yla](https://github.com/danielekp/yla) (Web interface to freely interact with your customized models)
- [LangBot](https://github.com/RockChinQ/LangBot) (LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)
- [1Panel](https://github.com/1Panel-dev/1Panel/) (Web-based Linux Server Management Tool)
- [AstrBot](https://github.com/Soulter/AstrBot/) (User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)
- [Reins](https://github.com/ibrahimcetin/reins) (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)
- [Flufy](https://github.com/Aharon-Bensadoun/Flufy) (A beautiful chat interface for interacting with Ollama&#039;s API. Built with React, TypeScript, and Material-UI.)
- [Ellama](https://github.com/zeozeozeo/ellama) (Friendly native app to chat with an Ollama instance)
- [screenpipe](https://github.com/mediar-ai/screenpipe) Build agents powered by your screen history
- [Ollamb](https://github.com/heng

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubeflow/trainer]]></title>
            <link>https://github.com/kubeflow/trainer</link>
            <guid>https://github.com/kubeflow/trainer</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Distributed AI Model Training and Fine-Tuning on Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubeflow/trainer">kubeflow/trainer</a></h1>
            <p>Distributed AI Model Training and Fine-Tuning on Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 1,945</p>
            <p>Forks: 834</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># Kubeflow Trainer

[![Join Slack](https://img.shields.io/badge/Join_Slack-blue?logo=slack)](https://www.kubeflow.org/docs/about/community/#kubeflow-slack-channels)
[![Coverage Status](https://coveralls.io/repos/github/kubeflow/trainer/badge.svg?branch=master)](https://coveralls.io/github/kubeflow/trainer?branch=master)
[![Go Report Card](https://goreportcard.com/badge/github.com/kubeflow/trainer)](https://goreportcard.com/report/github.com/kubeflow/trainer)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10435/badge)](https://www.bestpractices.dev/projects/10435)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/kubeflow/trainer)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fkubeflow%2Ftrainer.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fkubeflow%2Ftrainer?ref=badge_shield)

&lt;h1 align=&quot;center&quot;&gt;
    &lt;img src=&quot;./docs/images/trainer-logo.svg&quot; alt=&quot;logo&quot; width=&quot;200&quot;&gt;
  &lt;br&gt;
&lt;/h1&gt;

Latest News üî•

- [2025/09] Kubeflow SDK v0.1 is officially released with support for CustomTrainer,
  BuiltinTrainer, and local PyTorch execution. Check out
  [the GitHub release notes](https://github.com/kubeflow/sdk/releases/tag/0.1.0).
- [2025/07] PyTorch on Kubernetes: Kubeflow Trainer Joins the PyTorch Ecosystem. Find the
  announcement in [the PyTorch blog post](https://pytorch.org/blog/pytorch-on-kubernetes-kubeflow-trainer-joins-the-pytorch-ecosystem/).
- [2025/07] Kubeflow Trainer v2.0 has been officially released. Check out
  [the blog post announcement](https://blog.kubeflow.org/trainer/intro/) and [the
  release notes](https://github.com/kubeflow/trainer/releases/tag/v2.0.0).
- [2025/04] From High Performance Computing To AI Workloads on Kubernetes: MPI Runtime in
  Kubeflow TrainJob. See the [KubeCon + CloudNativeCon London talk](https://youtu.be/Fnb1a5Kaxgo)

## Overview

Kubeflow Trainer is a Kubernetes-native project designed for large language models (LLMs)
fine-tuning and enabling scalable, distributed training of machine learning (ML) models across
various frameworks, including PyTorch, JAX, TensorFlow, and others.

You can integrate other ML libraries such as [HuggingFace](https://huggingface.co),
[DeepSpeed](https://github.com/microsoft/DeepSpeed), or [Megatron-LM](https://github.com/NVIDIA/Megatron-LM)
with Kubeflow Trainer to run them on Kubernetes.

Kubeflow Trainer enables you to effortlessly develop your LLMs with the
[Kubeflow Python SDK](https://github.com/kubeflow/sdk/), and build Kubernetes-native Training
Runtimes using Kubernetes Custom Resource APIs.

&lt;h1 align=&quot;center&quot;&gt;
    &lt;img src=&quot;./docs/images/trainer-tech-stack.drawio.svg&quot; alt=&quot;logo&quot; width=&quot;500&quot;&gt;
  &lt;br&gt;
&lt;/h1&gt;

## Kubeflow Trainer Introduction

The following KubeCon + CloudNativeCon 2024 talk provides an overview of Kubeflow Trainer capabilities:

[![Kubeflow Trainer](https://img.youtube.com/vi/Lgy4ir1AhYw/0.jpg)](https://www.youtube.com/watch?v=Lgy4ir1AhYw)

## Getting Started

Please check [the official Kubeflow Trainer documentation](https://www.kubeflow.org/docs/components/trainer/getting-started)
to install and get started with Kubeflow Trainer.

## Community

The following links provide information on how to get involved in the community:

- Join our [`#kubeflow-trainer` Slack channel](https://www.kubeflow.org/docs/about/community/#kubeflow-slack).
- Attend [the bi-weekly AutoML and Training Working Group](https://bit.ly/2PWVCkV) community meeting.
- Check out [who is using Kubeflow Trainer](ADOPTERS.md).

## Contributing

Please refer to the [CONTRIBUTING guide](CONTRIBUTING.md).

## Changelog

Please refer to the [CHANGELOG](CHANGELOG.md).

## Kubeflow Training Operator V1

Kubeflow Trainer project is currently in &lt;strong&gt;alpha&lt;/strong&gt; status, and APIs may change.
If you are using Kubeflow Training Operator V1, please refer [to this migration document](https://www.kubeflow.org/docs/components/trainer/operator-guides/migration/).

Kubeflow Community will maintain the Training Operator V1 source code at
[the `release-1.9` branch](https://github.com/kubeflow/trainer/tree/release-1.9).

You can find the documentation for Kubeflow Training Operator V1 in [these guides](https://www.kubeflow.org/docs/components/trainer/legacy-v1).

## Acknowledgement

This project was originally started as a distributed training operator for TensorFlow and later we
merged efforts from other Kubeflow Training Operators to provide a unified and simplified experience
for both users and developers. We are very grateful to all who filed issues or helped resolve them,
asked and answered questions, and were part of inspiring discussions.
We&#039;d also like to thank everyone who&#039;s contributed to and maintained the original operators.

- PyTorch Operator: [list of contributors](https://github.com/kubeflow/pytorch-operator/graphs/contributors)
  and [maintainers](https://github.com/kubeflow/pytorch-operator/blob/master/OWNERS).
- MPI Operator: [list of contributors](https://github.com/kubeflow/mpi-operator/graphs/contributors)
  and [maintainers](https://github.com/kubeflow/mpi-operator/blob/master/OWNERS).
- XGBoost Operator: [list of contributors](https://github.com/kubeflow/xgboost-operator/graphs/contributors)
  and [maintainers](https://github.com/kubeflow/xgboost-operator/blob/master/OWNERS).
- Common library: [list of contributors](https://github.com/kubeflow/common/graphs/contributors) and
  [maintainers](https://github.com/kubeflow/common/blob/master/OWNERS).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[NexaAI/nexa-sdk]]></title>
            <link>https://github.com/NexaAI/nexa-sdk</link>
            <guid>https://github.com/NexaAI/nexa-sdk</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[Run the latest LLMs and VLMs across GPU, NPU, and CPU with PC (Python/C++) & mobile (Android & iOS) support, running quickly with OpenAI gpt-oss, Granite4, Qwen3VL, Gemma 3n and more.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NexaAI/nexa-sdk">NexaAI/nexa-sdk</a></h1>
            <p>Run the latest LLMs and VLMs across GPU, NPU, and CPU with PC (Python/C++) & mobile (Android & iOS) support, running quickly with OpenAI gpt-oss, Granite4, Qwen3VL, Gemma 3n and more.</p>
            <p>Language: Go</p>
            <p>Stars: 5,385</p>
            <p>Forks: 705</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;
      &lt;img width=&quot;100%&quot; src=&quot;assets/banner.png&quot; alt=&quot;Nexa AI Banner&quot;&gt;
  &lt;/p&gt;

  &lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://docs.nexa.ai&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/docs-website-brightgreen?logo=readthedocs&quot; alt=&quot;Documentation&quot;&gt;
    &lt;/a&gt;
   &lt;a href=&quot;https://x.com/nexa_ai&quot;&gt;&lt;img alt=&quot;X account&quot; src=&quot;https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&amp;label=Follow%20%40Nexa_AI&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.com/invite/nexa-ai&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1192186167391682711?color=5865F2&amp;logo=discord&amp;logoColor=white&amp;style=flat-square&quot; alt=&quot;Join us on Discord&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://join.slack.com/t/nexa-ai-community/shared_invite/zt-3837k9xpe-LEty0disTTUnTUQ4O3uuNw&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/slack-join%20chat-4A154B?logo=slack&amp;logoColor=white&quot; alt=&quot;Join us on Slack&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;
  
  ![OS](https://img.shields.io/badge/os-linux%20|%20macOS%20|%20windows-purple)
  ![Hardware](https://img.shields.io/badge/hardware-CPU%20|%20GPU%20|%20NPU-yellow)

&lt;/div&gt;

# Nexa SDK

Nexa SDK is an on-device inference framework that runs any model on any device, across any backend. It runs on CPUs, GPUs, NPUs with backend support for CUDA, Metal, Vulkan, and Qualcomm / Intel / AMD NPU. It handles multiple input modalities including text üìù, image üñºÔ∏è, and audio üéß. The SDK includes an OpenAI-compatible API server with support for JSON schema-based function calling and streaming. It supports model formats such as GGUF, MLX, Nexa AI&#039;s own `.nexa` format, enabling efficient quantized inference across diverse platforms.

## Qualcomm NPU PC Demos

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;img width=&quot;100%&quot; src=&quot;assets/PC_demo_2_image.gif&quot; alt=&quot;Multi-Image Reasoning Demo&quot;&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;üñºÔ∏è Multi-Image Reasoning&lt;/b&gt;&lt;br&gt;Spot the difference across two images in multi-round dialogue.&lt;/p&gt;
&lt;/td&gt;

&lt;td width=&quot;50%&quot;&gt;
&lt;img width=&quot;100%&quot; src=&quot;assets/PC_Demo_Agent.gif&quot; alt=&quot;Image + Audio Function Call Demo&quot;&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;üé§ Image + Text ‚Üí Function Call&lt;/b&gt;&lt;br&gt;Snap a poster, add a voice note, and AI agent creates a calendar event.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&quot;2&quot; align=&quot;center&quot;&gt;
&lt;img width=&quot;50%&quot; src=&quot;assets/PC_Demo_Audio.gif&quot; alt=&quot;Multi-Audio Comparison Demo&quot;&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;üé∂ Multi-Audio Comparison&lt;/b&gt;&lt;br&gt;Tell the difference between two music clips locally.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;


## Recent updates

#### üì£  **2025.10.14: Day-0 Support : Qwen3-VL-4B-Instruct, Qwen3-VL-4B-Thinking, Qwen3-VL-8B-Instruct, Qwen3-VL-8B-Thinking**
- We support [Qwen3-VL-4B series models](https://huggingface.co/collections/NexaAI/qwen3vl-68d46de18fdc753a7295190a) with Nexa SDK on Day-0!
- We support Qualcomm NPU/GPU/CPU, Apple GPU/CPU, Intel/AMD/MediaTek/Nvidia GPU/CPUs and more

#### üì£  **2025.10.04: Day-0 Support : Qwen3-VL-30B-A3B-Instruct**
- We support [Qwen3-VL-30B-A3B-Instruct](https://huggingface.co/NexaAI/qwen3vl-30B-A3B-mlx) with Nexa SDK on Day-0!
- Try it on Apple GPU with `nexa infer NexaAI/qwen3vl-30B-A3B-mlx` on MLX backend.

#### üì£  **2025.10.02: Day-0 Support on NPU/GPU/CPU : IBM Granite 4.0**
- We support [IBM Granite 4.0](https://sdk.nexa.ai/model/Granite-4-Micro) with Nexa SDK on Day-0!
- Try it on AMD / Intel / Qualcomm / Apple GPU with `nexa infer NexaAI/granite-4.0-micro-GGUF` and on Qualcomm NPU with `nexa infer NexaAI/Granite-4-Micro-NPU`

#### üì£  **2025.10.01: AMD NPU Support**
- Image Generation with [SDXL](https://huggingface.co/NexaAI/sdxl-turbo-amd-npu) on AMD NPU

#### üì£  **2025.09.23: Intel NPU Support**
- LLM inference with [DeepSeek-r1-distill-Qwen-1.5B](https://sdk.nexa.ai/model/DeepSeek-R1-Distill-Qwen-1.5B-Intel-NPU) and [Llama3.2-3B](https://sdk.nexa.ai/model/Llama3.2-3B-Intel-NPU) on Intel NPU

#### üì£  **2025.09.22: Apple Neural Engine (ANE) Support**
- Real-time speech recognition with [Parakeet v3 model](https://sdk.nexa.ai/model/parakeet-v3-ane)

#### üì£  **2025.09.15: New Models Support**
- First-ever [Gemma-3n](https://sdk.nexa.ai/model/Gemma3n-E4B) **multimodal** inference for GPU &amp; CPU, in GGUF format.
- [SDXL image generation](https://sdk.nexa.ai/model/Prefect-illustrious-XL-v2.0p) from Civitai for GPU
- [EmbeddingGemma](https://sdk.nexa.ai/model/embeddinggemma-300m-npu) for Qualcomm NPU
- [Phi4-mini turbo](https://sdk.nexa.ai/model/phi4-mini-npu-turbo) and [Phi3.5-mini](https://sdk.nexa.ai/model/phi3.5-mini-npu) for Qualcomm NPU
- [Parakeet V3 model](https://sdk.nexa.ai/model/parakeet-v3-npu) for Qualcomm NPU

#### üì£  **2025.09.05: Turbo Engine &amp; Unified Interface**
- [Nexa ML Turbo engine](https://nexa.ai/blogs/nexaml-turbo) for optimized NPU performance
    - Try [Phi4-mini turbo](https://sdk.nexa.ai/model/phi4-mini-npu-turbo) and [Llama3.2-3B-NPU-Turbo](https://sdk.nexa.ai/model/Llama3.2-3B-NPU-Turbo)
    - 80% faster at shorter contexts (&lt;=2048), 33% faster at longer contexts (&gt;2048) than current NPU solutions
- [Unified interface](https://nexa.ai/blogs/sdk-unifiedarchitecture) supporting NPU/GPU/CPU backends:
    - Single installer architecture eliminating dependency conflicts
    - Lazy loading and plugin isolation for improved performance

#### üì£  **2025.08.20: Qualcomm NPU Support with NexaML Turbo Engine**
- OmniNeural-4B: the **first multimodal AI model built natively for NPUs** ‚Äî handling text, images, and audio in one model
- Check the model and demos at [Hugging Face repo](https://huggingface.co/NexaAI/OmniNeural-4B)
- Check our [OmniNeural-4B technical blog](https://nexa.ai/blogs/omnineural-4b)

#### üì£  **2025.08.12: ASR &amp; TTS Support in MLX format**
- Parakeet and Kokoro models support in MLX format.
- new `/mic` mode to transcribe live speech directly in your terminal.
  
## Installation

### macOS
* [arm64 with Apple Neural Engine support](https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_macos_arm64.pkg)
* [x86_64](https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_macos_x86_64.pkg)

### Windows
* [arm64 with Qualcomm NPU support](https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_windows_arm64.exe)
* [x86_64 with Intel / AMD NPU support](https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_windows_x86_64.exe)


### Linux
```bash
curl -fsSL https://github.com/NexaAI/nexa-sdk/releases/latest/download/nexa-cli_linux_x86_64.sh -o install.sh &amp;&amp; chmod +x install.sh &amp;&amp; ./install.sh &amp;&amp; rm install.sh
```

## Supported Models

You can run any compatible GGUF, MLX, or nexa model from ü§ó Hugging Face by using the `&lt;full repo name&gt;`.

### Qualcomm NPU models
&gt; [!TIP]
&gt; You need to download the [arm64 with Qualcomm NPU support](https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_windows_arm64.exe) and make sure you have Snapdragon¬Æ X Elite chip on your laptop.

#### Quick Start (Windows arm64, Snapdragon X Elite)

1. **Login &amp; Get Access Token (required for Pro Models)**  
   - Create an account at [sdk.nexa.ai](https://sdk.nexa.ai)  
   - Go to **Deployment ‚Üí Create Token**  
   - Run this once in your terminal (replace with your token):  
     ```bash
     nexa config set license &#039;&lt;your_token_here&gt;&#039;
     ```

2. Run and chat with our multimodal model, OmniNeural-4B, or other models on NPU

```bash
nexa infer omni-neural
nexa infer NexaAI/OmniNeural-4B
nexa infer NexaAI/qwen3-1.7B-npu
```


### GGUF models

&gt; [!TIP]
&gt; GGUF runs on macOS, Linux, and Windows.

üìù Run and chat with LLMs, e.g. Qwen3:

```bash
nexa infer ggml-org/Qwen3-1.7B-GGUF
```

üñºÔ∏è Run and chat with Multimodal models, e.g. Qwen2.5-Omni:

```bash
nexa infer NexaAI/Qwen2.5-Omni-3B-GGUF
```

### MLX models
&gt; [!TIP]
&gt; MLX is macOS-only (Apple Silicon). Many MLX models in the Hugging Face mlx-community organization have quality issues and may not run reliably.
&gt; We recommend starting with models from our curated [NexaAI Collection](https://huggingface.co/NexaAI/collections) for best results. For example

üìù Run and chat with LLMs, e.g. Qwen3:

```bash
nexa infer NexaAI/Qwen3-4B-4bit-MLX
```

üñºÔ∏è Run and chat with Multimodal models, e.g. Gemma3n:

```bash
nexa infer NexaAI/gemma-3n-E4B-it-4bit-MLX
```

## CLI Reference

| Essential Command                          | What it does                                                        |
|----------------------------------|----------------------------------------------------------------------|
| `nexa -h`              | show all CLI commands                              |
| `nexa pull &lt;repo&gt;`              | Interactive download &amp; cache of a model                              |
| `nexa infer &lt;repo&gt;`             | Local inference          |
| `nexa list`                     | Show all cached models with sizes                                    |
| `nexa remove &lt;repo&gt;` / `nexa clean` | Delete one / all cached models                                   |
| `nexa serve --host 127.0.0.1:8080` | Launch OpenAI‚Äëcompatible REST server                            |
| `nexa run &lt;repo&gt;`              | Chat with a model via an existing server                             |

üëâ To interact with multimodal models, you can drag photos or audio clips directly into the CLI ‚Äî you can even drop multiple images at once!

See [CLI Reference](https://nexaai.mintlify.app/nexa-sdk-go/NexaCLI) for full commands.

## Acknowledgements

We would like to thank the following projects:
- [llama.cpp](https://github.com/ggml-org/llama.cpp)
- [mlx-lm](https://github.com/ml-explore/mlx-lm)
- [mlx-vlm](https://github.com/Blaizzy/mlx-vlm)
- [mlx-audio](https://github.com/Blaizzy/mlx-audio)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[uber-go/mock]]></title>
            <link>https://github.com/uber-go/mock</link>
            <guid>https://github.com/uber-go/mock</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[GoMock is a mocking framework for the Go programming language.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/uber-go/mock">uber-go/mock</a></h1>
            <p>GoMock is a mocking framework for the Go programming language.</p>
            <p>Language: Go</p>
            <p>Stars: 3,104</p>
            <p>Forks: 155</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># gomock

[![Build Status][ci-badge]][ci-runs] [![Go Reference][reference-badge]][reference]

gomock is a mocking framework for the [Go programming language][golang]. It
integrates well with Go&#039;s built-in `testing` package, but can be used in other
contexts too.

This project originates from Google&#039;s `golang/mock` repo. Unfortunately, Google
no longer maintains this project, and given the heavy usage of gomock project
within Uber, we&#039;ve decided to fork and maintain this going forward at Uber.

[Contributions](./CONTRIBUTING.md) are welcome in the form of GitHub issue or PR!

## Supported Go Versions

go.uber.org/mock supports all Go versions supported by the official
[Go Release Policy](https://go.dev/doc/devel/release#policy). That is,
the two most recent releases of Go.

## Installation

Install the `mockgen` tool.

```
go install go.uber.org/mock/mockgen@latest
```

To ensure it was installed correctly, use:

```
mockgen -version
```

If that fails, make sure your GOPATH/bin is in your PATH. You can add it with:

```
export PATH=$PATH:$(go env GOPATH)/bin
```

## Running mockgen

`mockgen` has three modes of operation: archive, source and package.

### Archive mode

Archive mode generates mock interfaces from a package archive
file (.a). It is enabled by using the -archive flag. An import
path and a comma-separated list of symbols should be provided
as a non-flag argument to the command.

Example:

```bash
# Build the package to a archive.
go build -o pkg.a database/sql/driver

mockgen -archive=pkg.a database/sql/driver Conn,Driver
```

### Source mode

Source mode generates mock interfaces from a source file.
It is enabled by using the -source flag. Other flags that
may be useful in this mode are -imports and -aux_files.

Example:

```bash
mockgen -source=foo.go [other options]
```

### Package mode

Package mode works by specifying the package and interface names.
It is enabled by passing two non-flag arguments: an import path, and a
comma-separated list of symbols.

You can use &quot;.&quot; to refer to the current path&#039;s package.

Example:

```bash
mockgen database/sql/driver Conn,Driver

# Convenient for `go:generate`.
mockgen . Conn,Driver
```

### Flags

The `mockgen` command is used to generate source code for a mock
class given a Go source file containing interfaces to be mocked.
It supports the following flags:

- `-archive`: A package archive file containing interfaces to be mocked.

- `-source`: A file containing interfaces to be mocked.

- `-destination`: A file to which to write the resulting source code. If you
  don&#039;t set this, the code is printed to standard output.

- `-package`: The package to use for the resulting mock class
  source code. If you don&#039;t set this, the package name is `mock_` concatenated
  with the package of the input file.

- `-imports`: A list of explicit imports that should be used in the resulting
  source code, specified as a comma-separated list of elements of the form
  `foo=bar/baz`, where `bar/baz` is the package being imported and `foo` is
  the identifier to use for the package in the generated source code.

- `-aux_files`: A list of additional files that should be consulted to
  resolve e.g. embedded interfaces defined in a different file. This is
  specified as a comma-separated list of elements of the form
  `foo=bar/baz.go`, where `bar/baz.go` is the source file and `foo` is the
  package name of that file used by the -source file.

- `-build_flags`: (package mode only) Flags passed verbatim to `go list`.

- `-mock_names`: A list of custom names for generated mocks. This is specified
  as a comma-separated list of elements of the form
  `Repository=MockSensorRepository,Endpoint=MockSensorEndpoint`, where
  `Repository` is the interface name and `MockSensorRepository` is the desired
  mock name (mock factory method and mock recorder will be named after the mock).
  If one of the interfaces has no custom name specified, then default naming
  convention will be used.

- `-self_package`: The full package import path for the generated code. The
  purpose of this flag is to prevent import cycles in the generated code by
  trying to include its own package. This can happen if the mock&#039;s package is
  set to one of its inputs (usually the main one) and the output is stdio so
  mockgen cannot detect the final output package. Setting this flag will then
  tell mockgen which import to exclude.

- `-copyright_file`: Copyright file used to add copyright header to the resulting source code.

- `-debug_parser`: Print out parser results only.

- `-write_package_comment`: Writes package documentation comment (godoc) if true. (default true)

- `-write_generate_directive`: Add //go:generate directive to regenerate the mock. (default false)

- `-write_source_comment`: Writes original file (source mode) or interface names (package mode) comment if true. (default true)

- `-typed`: Generate Type-safe &#039;Return&#039;, &#039;Do&#039;, &#039;DoAndReturn&#039; function. (default false)

- `-exclude_interfaces`: Comma-separated names of interfaces to be excluded

For an example of the use of `mockgen`, see the `sample/` directory. In simple
cases, you will need only the `-source` flag.

## Building Mocks

```go
type Foo interface {
  Bar(x int) int
}

func SUT(f Foo) {
 // ...
}

```

```go
func TestFoo(t *testing.T) {
  ctrl := gomock.NewController(t)

  m := NewMockFoo(ctrl)

  // Asserts that the first and only call to Bar() is passed 99.
  // Anything else will fail.
  m.
    EXPECT().
    Bar(gomock.Eq(99)).
    Return(101)

  SUT(m)
}
```

## Building Stubs

```go
type Foo interface {
  Bar(x int) int
}

func SUT(f Foo) {
 // ...
}

```

```go
func TestFoo(t *testing.T) {
  ctrl := gomock.NewController(t)

  m := NewMockFoo(ctrl)

  // Does not make any assertions. Executes the anonymous functions and returns
  // its result when Bar is invoked with 99.
  m.
    EXPECT().
    Bar(gomock.Eq(99)).
    DoAndReturn(func(_ int) int {
      time.Sleep(1*time.Second)
      return 101
    }).
    AnyTimes()

  // Does not make any assertions. Returns 103 when Bar is invoked with 101.
  m.
    EXPECT().
    Bar(gomock.Eq(101)).
    Return(103).
    AnyTimes()

  SUT(m)
}
```

## Modifying Failure Messages

When a matcher reports a failure, it prints the received (`Got`) vs the
expected (`Want`) value.

```shell
Got: [3]
Want: is equal to 2
Expected call at user_test.go:33 doesn&#039;t match the argument at index 1.
Got: [0 1 1 2 3]
Want: is equal to 1
```

### Modifying `Want`

The `Want` value comes from the matcher&#039;s `String()` method. If the matcher&#039;s
default output doesn&#039;t meet your needs, then it can be modified as follows:

```go
gomock.WantFormatter(
  gomock.StringerFunc(func() string { return &quot;is equal to fifteen&quot; }),
  gomock.Eq(15),
)
```

This modifies the `gomock.Eq(15)` matcher&#039;s output for `Want:` from `is equal
to 15` to `is equal to fifteen`.

### Modifying `Got`

The `Got` value comes from the object&#039;s `String()` method if it is available.
In some cases the output of an object is difficult to read (e.g., `[]byte`) and
it would be helpful for the test to print it differently. The following
modifies how the `Got` value is formatted:

```go
gomock.GotFormatterAdapter(
  gomock.GotFormatterFunc(func(i any) string {
    // Leading 0s
    return fmt.Sprintf(&quot;%02d&quot;, i)
  }),
  gomock.Eq(15),
)
```

If the received value is `3`, then it will be printed as `03`.

[golang]:              http://go.dev/
[ci-badge]:            https://github.com/uber-go/mock/actions/workflows/test.yaml/badge.svg
[ci-runs]:             https://github.com/uber-go/mock/actions
[reference-badge]:     https://pkg.go.dev/badge/go.uber.org/mock.svg
[reference]:           https://pkg.go.dev/go.uber.org/mock
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes/autoscaler]]></title>
            <link>https://github.com/kubernetes/autoscaler</link>
            <guid>https://github.com/kubernetes/autoscaler</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[Autoscaling components for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes/autoscaler">kubernetes/autoscaler</a></h1>
            <p>Autoscaling components for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 8,630</p>
            <p>Forks: 4,227</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># Kubernetes Autoscaler

[![Release Charts](https://github.com/kubernetes/autoscaler/actions/workflows/release.yaml/badge.svg)](https://github.com/kubernetes/autoscaler/actions/workflows/release.yaml) [![Tests](https://github.com/kubernetes/autoscaler/actions/workflows/ci.yaml/badge.svg)](https://github.com/kubernetes/autoscaler/actions/workflows/ci.yaml) [![GoDoc Widget]][GoDoc]

This repository contains autoscaling-related components for Kubernetes.

## What&#039;s inside

[Cluster Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler) - a component that automatically adjusts the size of a Kubernetes
Cluster so that all pods have a place to run and there are no unneeded nodes. Supports several public cloud providers. Version 1.0 (GA) was released with kubernetes 1.8.

[Cluster Autoscaler Helm Chart](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler/charts) - Supported Helm chart for Cluster Autoscaler.

[Vertical Pod Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler) - a set of components that automatically adjust the
amount of CPU and memory requested by pods running in the Kubernetes Cluster. Current state - beta.

[Vertical Pod Autoscaler Helm Chart](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/charts) - Supported Helm chart for Vertical Pod Autoscaler.

[Addon Resizer](https://github.com/kubernetes/autoscaler/tree/master/addon-resizer) - a simplified version of vertical pod autoscaler that modifies
resource requests of a deployment based on the number of nodes in the Kubernetes Cluster. Current state - beta.

## Contact Info

Interested in autoscaling? Want to talk? Have questions, concerns or great ideas?

Please join us on #sig-autoscaling at https://kubernetes.slack.com/, or join one
of our weekly meetings.  See [the Kubernetes Community Repo](https://github.com/kubernetes/community/blob/master/sig-autoscaling/README.md) for more information.

## Getting the Code

Fork the repository in the cloud:
1. Visit https://github.com/kubernetes/autoscaler
1. Click Fork button (top right) to establish a cloud-based fork.

The code must be checked out as a subdirectory of `k8s.io`, and not `github.com`.

```shell
mkdir -p $GOPATH/src/k8s.io
cd $GOPATH/src/k8s.io
# Replace &quot;$YOUR_GITHUB_USERNAME&quot; below with your github username
git clone https://github.com/$YOUR_GITHUB_USERNAME/autoscaler.git
cd autoscaler
```

Please refer to Kubernetes [Github workflow guide] for more details.

[GoDoc]: https://godoc.org/k8s.io/autoscaler
[GoDoc Widget]: https://godoc.org/k8s.io/autoscaler?status.svg
[Github workflow guide]: https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[GoogleCloudPlatform/kubectl-ai]]></title>
            <link>https://github.com/GoogleCloudPlatform/kubectl-ai</link>
            <guid>https://github.com/GoogleCloudPlatform/kubectl-ai</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[AI powered Kubernetes Assistant]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GoogleCloudPlatform/kubectl-ai">GoogleCloudPlatform/kubectl-ai</a></h1>
            <p>AI powered Kubernetes Assistant</p>
            <p>Language: Go</p>
            <p>Stars: 6,918</p>
            <p>Forks: 625</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># kubectl-ai

[![Go Report Card](https://goreportcard.com/badge/github.com/GoogleCloudPlatform/kubectl-ai)](https://goreportcard.com/report/github.com/GoogleCloudPlatform/kubectl-ai)
![GitHub License](https://img.shields.io/github/license/GoogleCloudPlatform/kubectl-ai)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/GoogleCloudPlatform/kubectl-ai)
[![GitHub stars](https://img.shields.io/github/stars/GoogleCloudPlatform/kubectl-ai.svg)](https://github.com/GoogleCloudPlatform/kubectl-ai/stargazers)


`kubectl-ai` acts as an intelligent interface, translating user intent into
precise Kubernetes operations, making Kubernetes management more accessible and
efficient.

![kubectl-ai demo GIF using: kubectl-ai &quot;how&#039;s nginx app doing in my cluster&quot;](./.github/kubectl-ai.gif)

## Quick Start

First, ensure that kubectl is installed and configured.

### Installation

#### Quick Install (Linux &amp; MacOS only)

```shell
curl -sSL https://raw.githubusercontent.com/GoogleCloudPlatform/kubectl-ai/main/install.sh | bash
```

&lt;details&gt;

&lt;summary&gt;Other Installation Methods&lt;/summary&gt;

#### Manual Installation (Linux, MacOS and Windows)

1. Download the latest release from the [releases page](https://github.com/GoogleCloudPlatform/kubectl-ai/releases/latest) for your target machine.

2. Untar the release, make the binary executable and move it to a directory in your $PATH (as shown below).

```shell
tar -zxvf kubectl-ai_Darwin_arm64.tar.gz
chmod a+x kubectl-ai
sudo mv kubectl-ai /usr/local/bin/
```

#### Install with Krew (Linux/macOS/Windows)

First of all, you need to have krew insatlled, refer to [krew document](https://krew.sigs.k8s.io/docs/user-guide/setup/install/) for more details
Then you can install with krew

```shell
kubectl krew install ai
```

Now you can invoke `kubectl-ai` as a kubectl plugin like this: `kubectl ai`.

#### Install on NixOS

There are multiple ways to install `kubectl-ai` on NixOS. For a permantent installation add the following to your NixOS-Configuration:

```nix
  environment.systemPackages = with pkgs; [
    kubectl-ai
  ];
```

For a temporary installation, you can use the following command:

```
nix-shell -p kubectl-ai
```

&lt;/details&gt;

### Usage

`kubectl-ai` supports AI models from `gemini`, `vertexai`, `azopenai`, `openai`, `grok`, `bedrock` and local LLM providers such as `ollama` and `llama.cpp`.

#### Using Gemini (Default)

Set your Gemini API key as an environment variable. If you don&#039;t have a key, get one from [Google AI Studio](https://aistudio.google.com).

```bash
export GEMINI_API_KEY=your_api_key_here
kubectl-ai

# Use different gemini model
kubectl-ai --model gemini-2.5-pro-exp-03-25

# Use 2.5 flash (faster) model
kubectl-ai --quiet --model gemini-2.5-flash-preview-04-17 &quot;check logs for nginx app in hello namespace&quot;
```

&lt;details&gt;

&lt;summary&gt;Use other AI models&lt;/summary&gt;

#### Using AI models running locally (ollama or llama.cpp)

You can use `kubectl-ai` with AI models running locally. `kubectl-ai` supports [ollama](https://ollama.com/) and [llama.cpp](https://github.com/ggml-org/llama.cpp) to use the AI models running locally.

Additionally, the [`modelserving`](modelserving/) directory provides tools and instructions for deploying your own `llama.cpp`-based LLM serving endpoints locally or on a Kubernetes cluster. This allows you to host models like Gemma directly in your environment.

An example of using Google&#039;s `gemma3` model with `ollama`:

```shell
# assuming ollama is already running and you have pulled one of the gemma models
# ollama pull gemma3:12b-it-qat

# if your ollama server is at remote, use OLLAMA_HOST variable to specify the host
# export OLLAMA_HOST=http://192.168.1.3:11434/

# enable-tool-use-shim because models require special prompting to enable tool calling
kubectl-ai --llm-provider ollama --model gemma3:12b-it-qat --enable-tool-use-shim

# you can use `models` command to discover the locally available models
&gt;&gt; models
```

#### Using Grok

You can use X.AI&#039;s Grok model by setting your X.AI API key:

```bash
export GROK_API_KEY=your_xai_api_key_here
kubectl-ai --llm-provider=grok --model=grok-3-beta
```

#### Using AWS Bedrock

You can use AWS Bedrock Claude models with your AWS credentials:

```bash
# Configure AWS credentials using AWS SSO
aws sso login --profile your-profile-name
# Or use other AWS credential methods (IAM roles, environment variables, etc.)

# Use Claude 4 Sonnet (default)
kubectl-ai --llm-provider=bedrock --model=us.anthropic.claude-sonnet-4-20250514-v1:0

# Use Claude 3.7 Sonnet
kubectl-ai --llm-provider=bedrock --model=us.anthropic.claude-3-7-sonnet-20250219-v1:0

# Override model via environment variable
export BEDROCK_MODEL=us.anthropic.claude-sonnet-4-20250514-v1:0
kubectl-ai --llm-provider=bedrock
```

AWS Bedrock uses the standard AWS SDK credential chain, supporting:
- AWS SSO profiles
- IAM roles (for EC2/ECS/Lambda)
- Environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
- AWS CLI configuration files

#### Using Azure OpenAI

You can also use Azure OpenAI deployment by setting your OpenAI API key and specifying the provider:

```bash
export AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
export AZURE_OPENAI_ENDPOINT=https://your_azure_openai_endpoint_here
kubectl-ai --llm-provider=azopenai --model=your_azure_openai_deployment_name_here
# or
az login
kubectl-ai --llm-provider=openai://your_azure_openai_endpoint_here --model=your_azure_openai_deployment_name_here
```

#### Using OpenAI

You can also use OpenAI models by setting your OpenAI API key and specifying the provider:

```bash
export OPENAI_API_KEY=your_openai_api_key_here
kubectl-ai --llm-provider=openai --model=gpt-4.1
```

#### Using OpenAI Compatible API

For example, you can use aliyun qwen-xxx models as follows

```bash
export OPENAI_API_KEY=your_openai_api_key_here
export OPENAI_ENDPOINT=https://dashscope.aliyuncs.com/compatible-mode/v1
kubectl-ai --llm-provider=openai --model=qwen-plus
```

&lt;/details&gt;

Run interactively:

```shell
kubectl-ai
```

The interactive mode allows you to have a chat with `kubectl-ai`, asking multiple questions in sequence while maintaining context from previous interactions. Simply type your queries and press Enter to receive responses. To exit the interactive shell, type `exit` or press Ctrl+C.

Or, run with a task as input:

```shell
kubectl-ai --quiet &quot;fetch logs for nginx app in hello namespace&quot;
```

Combine it with other unix commands:

```shell
kubectl-ai &lt; query.txt
# OR
echo &quot;list pods in the default namespace&quot; | kubectl-ai
```

You can even combine a positional argument with stdin input. The positional argument will be used as a prefix to the stdin content:

```shell
cat error.log | kubectl-ai &quot;explain the error&quot;
```

We also support persistence between runs with an opt-in. This lets you save a session to the local filesystem, and resume it to maintain previous context. It even works between different interfaces!

```shell
kubectl-ai --new-session # start a new session
kubectl-ai --list-sessions # list all saved sessions
kubectl-ai --resume-session 20250807-510872 # resume session 20250807-510872
kubectl-ai --delete-session 20250807-510872 # delete session 20250807-510872
```

## Configuration

You can also configure `kubectl-ai` using a YAML configuration file at `~/.config/kubectl-ai/config.yaml`:

```shell
mkdir -p ~/.config/kubectl-ai/
cat &lt;&lt;EOF &gt; ~/.config/kubectl-ai/config.yaml
model: gemini-2.5-flash-preview-04-17
llmProvider: gemini
toolConfigPaths: ~/.config/kubectl-ai/tools.yaml
EOF
```

Verify your configuration:

```shell
kubectl-ai --quiet model
```

&lt;details&gt;

&lt;summary&gt;More configuration Options&lt;/summary&gt;

Here&#039;s a complete configuration file with all available options and their default values:

```yaml
# LLM provider configuration
llmProvider: &quot;gemini&quot;               # Default LLM provider
model: &quot;gemini-2.5-pro-preview-06-05&quot; # Default model
skipVerifySSL: false              # Skip SSL verification for LLM API calls

# Tool and permission settings
toolConfigPaths: [&quot;~/.config/kubectl-ai/tools.yaml&quot;]  # Custom tools configuration paths
skipPermissions: false             # Skip confirmation for resource-modifying commands
enableToolUseShim: false        # Enable tool use shim for certain models

# MCP configuration
mcpServer: false                  # Run in MCP server mode
mcpClient: false                  # Enable MCP client mode
externalTools: false             # Discover external MCP tools (requires mcp-server)

# Runtime settings
maxIterations: 20                 # Maximum iterations for the agent
quiet: false                       # Run in non-interactive mode
removeWorkdir: false             # Remove temporary working directory after execution

# Kubernetes configuration
kubeconfig: &quot;~/.kube/config&quot;      # Path to kubeconfig file

# UI configuration
uiType: &quot;terminal&quot;                # UI mode: &quot;terminal&quot; or &quot;web&quot;
uiListenAddress: &quot;localhost:8888&quot; # Address for HTML UI server

# Prompt configuration
promptTemplateFilePath: &quot;&quot;      # Custom prompt template file
extraPromptPaths: []            # Additional prompt template paths

# Debug and trace settings
tracePath: &quot;/tmp/kubectl-ai-trace.txt&quot; # Path to trace file
```

&lt;/details&gt;

All these settings can be configured through either:

1. Command line flags (e.g., `--model=gemini-2.5-pro`)
2. Configuration file (`~/.config/kubectl-ai/config.yaml`)
3. Environment variables (e.g., `GEMINI_API_KEY`)

Command line flags take precedence over configuration file settings.

## Tools

`kubectl-ai` leverages LLMs to suggest and execute Kubernetes operations using a set of powerful tools. It comes with built-in tools like `kubectl` and `bash`.

You can also extend its capabilities by defining your own custom tools. By default, `kubectl-ai` looks for your tool configurations in `~/.config/kubectl-ai/tools.yaml`.

To specify tools configuration files or directories containing tools configuration files, use:

```sh
./kubectl-ai --custom-tools-config=&lt;path-to-tools-directory&gt; &quot;your prompt here&quot;
```

For further details on how to configure your own tools, [go here](docs/tools.md).

## Docker Quick Start 
This project provides a Docker image that gives you a standalone environment for running kubectl-ai, including against a GKE cluster.

### Running the container against GKE

#### Step 1: Build the Image

Clone the repository and build the image with the following command 

```bash
git clone https://github.com/GoogleCloudPlatform/kubectl-ai.git
cd kubectl-ai
docker build -t kubectl-ai:latest -f images/kubectl-ai/Dockerfile .
```

#### Step 2: Connect to Your GKE Cluster
Set up application default credentials and connect to your GKE cluster.
```bash
gcloud auth application-default login # If in a gcloud shell this is not necessary
gcloud container clusters get-credentials &lt;cluster-name&gt; --zone &lt;zone&gt;
```

#### Step 3: Run the kubectl-ai container
Below is a sample command that can be used to launch the container with a locally hosted web-ui. Be sure to replace the placeholder values with your specific Google Cloud project ID and location. Note you 
do not need to mount the gcloud config directory if you&#039;re on a cloudshell machine. 

```bash
docker run --rm -it -p 8080:8080 -v ~/.kube:/root/.kube -v ~/.config/gcloud:/root/.config/gcloud -e GOOGLE_CLOUD_LOCATION=us-central1 -e GOOGLE_CLOUD_PROJECT=my-gcp-project kubectl-ai:latest --llm-provider vertexai --ui-listen-address 0.0.0.0:8080 --ui-type web
```

For more info about running from the container image see [CONTAINER.md](CONTAINER.md)

## MCP Client Mode

&gt; **Note:** MCP Client Mode is available in `kubectl-ai` version v0.0.12 and onwards.

`kubectl-ai` can connect to external [MCP](https://modelcontextprotocol.io/examples) Servers to access additional tools in addition to built-in tools.

### Quick Start

Enable MCP client mode:

```bash
kubectl-ai --mcp-client
```

### Configuration

Create or edit `~/.config/kubectl-ai/mcp.yaml` to customize MCP servers:

```yaml
servers:
  # Local MCP server (stdio-based)
  # sequential-thinking: Advanced reasoning and step-by-step analysis
  - name: sequential-thinking
    command: npx
    args:
      - -y
      - &quot;@modelcontextprotocol/server-sequential-thinking&quot;
  
  # Remote MCP server (HTTP-based)
  - name: cloudflare-documentation
    url: https://docs.mcp.cloudflare.com/mcp
    
  # Optional: Remote MCP server with authentication
  - name: custom-api
    url: https://api.example.com/mcp
    auth:
      type: &quot;bearer&quot;
      token: &quot;${MCP_TOKEN}&quot;
```

The system automatically:

- Converts parameter names (snake_case ‚Üí camelCase)
- Handles type conversion (strings ‚Üí numbers/booleans when appropriate)
- Provides fallback behavior for unknown servers

No additional setup required - just use the `--mcp-client` flag and the AI will have access to all configured MCP tools.

üìñ **For detailed configuration options, troubleshooting, and advanced features for MCP Client mode, see the [MCP Client Documentation](pkg/mcp/README.md).**

üìñ **For multi-server orchestration and security automation examples, see the [MCP Client Integration Guide](docs/mcp-client.md).**

## Extras

You can use the following special keywords for specific actions:

- `model`: Display the currently selected model.
- `models`: List all available models.
- `tools`: List all available tools.
- `version`: Display the `kubectl-ai` version.
- `reset`: Clear the conversational context.
- `clear`: Clear the terminal screen.
- `exit` or `quit`: Terminate the interactive shell (Ctrl+C also works).

### Invoking as kubectl plugin

You can also run `kubectl ai`. `kubectl` finds any executable file in your `PATH` whose name begins with `kubectl-` as a [plugin](https://kubernetes.io/docs/tasks/extend-kubectl/kubectl-plugins/).

## MCP Server Mode

`kubectl-ai` can act as an MCP server that exposes kubectl tools to other MCP clients (like Claude, Cursor, or VS Code). The server can run in two modes:

### Basic MCP Server (Built-in tools only)

Expose only kubectl-ai&#039;s native Kubernetes tools:

```bash
kubectl-ai --mcp-server
```

### Enhanced MCP Server (With external tool discovery)

Additionally discover and expose tools from other MCP servers as a unified interface:

```bash
kubectl-ai --mcp-server --external-tools
```

This creates a powerful **tool aggregation hub** where kubectl-ai acts as both:

- **MCP Server**: Exposing kubectl tools to clients
- **MCP Client**: Consuming tools from other MCP servers

To serve clients over HTTP using the streamable transport, run:

```bash
kubectl-ai --mcp-server --mcp-server-mode streamable-http --http-port 9080
```

This starts an MCP endpoint at `http://localhost:9080/mcp`.

The enhanced mode provides AI clients with access to both Kubernetes operations and general-purpose tools (filesystem, web search, databases, etc.) through a single MCP endpoint.

üìñ **For detailed configuration, examples, and troubleshooting, see the [MCP Server Documentation](./docs/mcp-server.md).**

## k8s-bench

kubectl-ai project includes [k8s-bench](./k8s-bench/README.md) - a benchmark to evaluate performance of different LLM models on kubernetes related tasks. 

### Latest Benchmark Results (August 2025)

Comprehensive evaluation on identical 10-task Kubernetes benchmark with proper CNI environment:

| Model | Success | Fail | Success Rate |
|-------|---------|------|--------------|
| gemini-2.5-flash-preview-04-17 | 10 | 0 | 100% |
| gemini-2.5-pro-preview-03-25 | 10 | 0 | 100% |
| AWS Bedrock Claude 3.7 Sonnet | 10 | 0 | 100% |
| AWS Bedrock Claude Sonnet 4 | 10 | 0 | 100% |
| gemma-3-27b-it | 8 | 2 | 80% |

**Test Environment**: Kind cluster v1.27.3 with Calico CNI (full NetworkPolicy support)  
**Tasks**: create-pod, create-pod-mount-configmaps, create-pod-resources-limits, create-network-policy, fix-crashloop, fix-image-pull, fix-service-routing, list-images-for-pods, scale-deployment, scale-down-deployment

See [full report](./k8s-bench.md) for more details.

## Start Contributing

We welcome contributions to `kubectl-ai` from the community. Take a look at our
[contribution guide](contributing.md) to get started.

---

*Note: This is not an officially supported Google product. This project is not
eligible for the [Google Open Source Software Vulnerability Rewards
Program](https://bughunters.google.com/open-source-security).*
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[seaweedfs/seaweedfs]]></title>
            <link>https://github.com/seaweedfs/seaweedfs</link>
            <guid>https://github.com/seaweedfs/seaweedfs</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/seaweedfs/seaweedfs">seaweedfs/seaweedfs</a></h1>
            <p>SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.</p>
            <p>Language: Go</p>
            <p>Stars: 26,070</p>
            <p>Forks: 2,482</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># SeaweedFS


[![Slack](https://img.shields.io/badge/slack-purple)](https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY)
[![Twitter](https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;label=Follow)](https://twitter.com/intent/follow?screen_name=seaweedfs)
[![Build Status](https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml)](https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml)
[![GoDoc](https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg)](https://godoc.org/github.com/seaweedfs/seaweedfs/weed)
[![Wiki](https://img.shields.io/badge/docs-wiki-blue.svg)](https://github.com/seaweedfs/seaweedfs/wiki)
[![Docker Pulls](https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800)](https://hub.docker.com/r/chrislusf/seaweedfs/)
[![SeaweedFS on Maven Central](https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client)](https://search.maven.org/search?q=g:com.github.chrislusf)
[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs)](https://artifacthub.io/packages/search?repo=seaweedfs)

![SeaweedFS Logo](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png)

&lt;h2 align=&quot;center&quot;&gt;&lt;a href=&quot;https://www.patreon.com/seaweedfs&quot;&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt;

SeaweedFS is an independent Apache-licensed open source project with its ongoing development made
possible entirely thanks to the support of these awesome [backers](https://github.com/seaweedfs/seaweedfs/blob/master/backers.md).
If you&#039;d like to grow SeaweedFS even stronger, please consider joining our
&lt;a href=&quot;https://www.patreon.com/seaweedfs&quot;&gt;sponsors on Patreon&lt;/a&gt;.

Your support will be really appreciated by me and other supporters!

&lt;!--
&lt;h4 align=&quot;center&quot;&gt;Platinum&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;&quot; target=&quot;_blank&quot;&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt;

### Gold Sponsors
[![nodion](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png)](https://www.nodion.com)
[![piknik](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png)](https://www.piknik.com)
[![keepsec](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png)](https://www.keepsec.ca)

---

- [Download Binaries for different platforms](https://github.com/seaweedfs/seaweedfs/releases/latest)
- [SeaweedFS on Slack](https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY)
- [SeaweedFS on Twitter](https://twitter.com/SeaweedFS)
- [SeaweedFS on Telegram](https://t.me/Seaweedfs) 
- [SeaweedFS on Reddit](https://www.reddit.com/r/SeaweedFS/)
- [SeaweedFS Mailing List](https://groups.google.com/d/forum/seaweedfs)
- [Wiki Documentation](https://github.com/seaweedfs/seaweedfs/wiki)
- [SeaweedFS White Paper](https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf)
- [SeaweedFS Introduction Slides 2025.5](https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing)
- [SeaweedFS Introduction Slides 2021.5](https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing)
- [SeaweedFS Introduction Slides 2019.3](https://www.slideshare.net/chrislusf/seaweedfs-introduction)

Table of Contents
=================

* [Quick Start](#quick-start)
    * [Quick Start for S3 API on Docker](#quick-start-for-s3-api-on-docker)
    * [Quick Start with Single Binary](#quick-start-with-single-binary)
    * [Quick Start SeaweedFS S3 on AWS](#quick-start-seaweedfs-s3-on-aws)
* [Introduction](#introduction)
* [Features](#features)
    * [Additional Features](#additional-features)
    * [Filer Features](#filer-features)
* [Example: Using Seaweed Object Store](#example-using-seaweed-object-store)
* [Architecture](#object-store-architecture)
* [Compared to Other File Systems](#compared-to-other-file-systems)
    * [Compared to HDFS](#compared-to-hdfs)
    * [Compared to GlusterFS, Ceph](#compared-to-glusterfs-ceph)
    * [Compared to GlusterFS](#compared-to-glusterfs)
    * [Compared to Ceph](#compared-to-ceph)
    * [Compared to Minio](#compared-to-minio)
* [Dev Plan](#dev-plan)
* [Installation Guide](#installation-guide)
* [Disk Related Topics](#disk-related-topics)
* [Benchmark](#benchmark)
* [Enterprise](#enterprise)
* [License](#license)

# Quick Start #

## Quick Start for S3 API on Docker ##

`docker run -p 8333:8333 chrislusf/seaweedfs server -s3`

## Quick Start with Single Binary ##
* Download the latest binary from https://github.com/seaweedfs/seaweedfs/releases and unzip a single binary file `weed` or `weed.exe`. Or run `go install github.com/seaweedfs/seaweedfs/weed@latest`.
* `export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key` as the admin credentials to access the object store.
* Run `weed server -dir=/some/data/dir -s3` to start one master, one volume server, one filer, and one S3 gateway.

Also, to increase capacity, just add more volume servers by running `weed volume -dir=&quot;/some/data/dir2&quot; -mserver=&quot;&lt;master_host&gt;:9333&quot; -port=8081` locally, or on a different machine, or on thousands of machines. That is it!

## Quick Start SeaweedFS S3 on AWS ##
* Setup fast production-ready [SeaweedFS S3 on AWS with cloudformation](https://aws.amazon.com/marketplace/pp/prodview-nzelz5gprlrjc)

# Introduction #

SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:

1. to store billions of files!
2. to serve the files fast!

SeaweedFS started as an Object Store to handle small files efficiently. 
Instead of managing all file metadata in a central master, 
the central master only manages volumes on volume servers, 
and these volume servers manage files and their metadata. 
This relieves concurrency pressure from the central master and spreads file metadata into volume servers, 
allowing faster file access (O(1), usually just one disk read operation).

There is only 40 bytes of disk storage overhead for each file&#039;s metadata. 
It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.

SeaweedFS started by implementing [Facebook&#039;s Haystack design paper](http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf). 
Also, SeaweedFS implements erasure coding with ideas from 
[f4: Facebook‚Äôs Warm BLOB Storage System](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf), and has a lot of similarities with [Facebook‚Äôs Tectonic Filesystem](https://www.usenix.org/system/files/fast21-pan.pdf)

On top of the object store, optional [Filer] can support directories and POSIX attributes. 
Filer is a separate linearly-scalable stateless server with customizable metadata stores, 
e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.

For any distributed key value stores, the large values can be offloaded to SeaweedFS. 
With the fast access speed and linearly scalable capacity, 
SeaweedFS can work as a distributed [Key-Large-Value store][KeyLargeValueStore].

SeaweedFS can transparently integrate with the cloud. 
With hot data on local cluster, and warm data on the cloud with O(1) access time, 
SeaweedFS can achieve both fast local access time and elastic cloud storage capacity.
What&#039;s more, the cloud storage access API cost is minimized. 
Faster and cheaper than direct cloud storage!

[Back to TOC](#table-of-contents)

# Features #
## Additional Features ##
* Can choose no replication or different replication levels, rack and data center aware.
* Automatic master servers failover - no single point of failure (SPOF).
* Automatic Gzip compression depending on file MIME type.
* Automatic compaction to reclaim disk space after deletion or update.
* [Automatic entry TTL expiration][VolumeServerTTL].
* Any server with some disk space can add to the total storage space.
* Adding/Removing servers does **not** cause any data re-balancing unless triggered by admin commands.
* Optional picture resizing.
* Support ETag, Accept-Range, Last-Modified, etc.
* Support in-memory/leveldb/readonly mode tuning for memory/performance balance.
* Support rebalancing the writable and readonly volumes.
* [Customizable Multiple Storage Tiers][TieredStorage]: Customizable storage disk types to balance performance and cost.
* [Transparent cloud integration][CloudTier]: unlimited capacity via tiered cloud storage for warm data.
* [Erasure Coding for warm storage][ErasureCoding]  Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.

[Back to TOC](#table-of-contents)

## Filer Features ##
* [Filer server][Filer] provides &quot;normal&quot; directories and files via HTTP.
* [File TTL][FilerTTL] automatically expires file metadata and actual file data.
* [Mount filer][Mount] reads and writes files directly as a local directory via FUSE.
* [Filer Store Replication][FilerStoreReplication] enables HA for filer meta data stores.
* [Active-Active Replication][ActiveActiveAsyncReplication] enables asynchronous one-way or two-way cross cluster continuous replication.
* [Amazon S3 compatible API][AmazonS3API] accesses files with S3 tooling.
* [Hadoop Compatible File System][Hadoop] accesses files from Hadoop/Spark/Flink/etc or even runs HBase.
* [Async Replication To Cloud][BackupToCloud] has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.
* [WebDAV] accesses as a mapped drive on Mac and Windows, or from mobile devices.
* [AES256-GCM Encrypted Storage][FilerDataEncryption] safely stores the encrypted data.
* [Super Large Files][SuperLargeFiles] stores large or super large files in tens of TB.
* [Cloud Drive][CloudDrive] mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.
* [Gateway to Remote Object Store][GatewayToRemoteObjectStore] mirrors bucket operations to remote object storage, in addition to [Cloud Drive][CloudDrive]

## Kubernetes ##
* [Kubernetes CSI Driver][SeaweedFsCsiDriver] A Container Storage Interface (CSI) Driver. [![Docker Pulls](https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800)](https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/)
* [SeaweedFS Operator](https://github.com/seaweedfs/seaweedfs-operator)

[Filer]: https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files
[SuperLargeFiles]: https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files
[Mount]: https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount
[AmazonS3API]: https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API
[BackupToCloud]: https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud
[Hadoop]: https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System
[WebDAV]: https://github.com/seaweedfs/seaweedfs/wiki/WebDAV
[ErasureCoding]: https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage
[TieredStorage]: https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage
[CloudTier]: https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier
[FilerDataEncryption]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption
[FilerTTL]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores
[VolumeServerTTL]: https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live
[SeaweedFsCsiDriver]: https://github.com/seaweedfs/seaweedfs-csi-driver
[ActiveActiveAsyncReplication]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization
[FilerStoreReplication]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication
[KeyLargeValueStore]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store
[CloudDrive]: https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture
[GatewayToRemoteObjectStore]: https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage


[Back to TOC](#table-of-contents)

## Example: Using Seaweed Object Store ##

By default, the master node runs on port 9333, and the volume nodes run on port 8080.
Let&#039;s start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We&#039;ll use localhost as an example.

SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.

### Start Master Server ###

```
&gt; ./weed master
```

### Start Volume Servers ###

```
&gt; weed volume -dir=&quot;/tmp/data1&quot; -max=5  -mserver=&quot;localhost:9333&quot; -port=8080 &amp;
&gt; weed volume -dir=&quot;/tmp/data2&quot; -max=10 -mserver=&quot;localhost:9333&quot; -port=8081 &amp;
```

### Write File ###

To upload a file: first, send a HTTP POST, PUT, or GET request to `/dir/assign` to get an `fid` and a volume server URL:

```
&gt; curl http://localhost:9333/dir/assign
{&quot;count&quot;:1,&quot;fid&quot;:&quot;3,01637037d6&quot;,&quot;url&quot;:&quot;127.0.0.1:8080&quot;,&quot;publicUrl&quot;:&quot;localhost:8080&quot;}
```

Second, to store the file content, send a HTTP multi-part POST request to `url + &#039;/&#039; + fid` from the response:

```
&gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{&quot;name&quot;:&quot;myphoto.jpg&quot;,&quot;size&quot;:43234,&quot;eTag&quot;:&quot;1cc0118e&quot;}
```

To update, send another POST request with updated file content.

For deletion, send an HTTP DELETE request to the same `url + &#039;/&#039; + fid` URL:

```
&gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
```

### Save File Id ###

Now, you can save the `fid`, 3,01637037d6 in this case, to a database field.

The number 3 at the start represents a volume id. After the comma, it&#039;s one file key, 01, and a file cookie, 637037d6.

The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.

The file key and file cookie are both coded in hex. You can store the &lt;volume id, file key, file cookie&gt; tuple in your own format, or simply store the `fid` as a string.

If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.

If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.

### Read File ###

Here is an example of how to render the URL.

First look up the volume server&#039;s URLs by the file&#039;s volumeId:

```
&gt; curl http://localhost:9333/dir/lookup?volumeId=3
{&quot;volumeId&quot;:&quot;3&quot;,&quot;locations&quot;:[{&quot;publicUrl&quot;:&quot;localhost:8080&quot;,&quot;url&quot;:&quot;localhost:8080&quot;}]}
```

Since (usually) there are not too many volume servers, and volumes don&#039;t move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.

Now you can take the public URL, render the URL or directly read from the volume server via URL:

```
 http://localhost:8080/3,01637037d6.jpg
```

Notice we add a file extension &quot;.jpg&quot; here. It&#039;s optional and just one way for the client to specify the file content type.

If you want a nicer URL, you can use one of these alternative URL formats:

```
 http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
```

If you want to get a scaled version of an image, you can add some params:

```
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200&amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200&amp;mode=fill
```

### Rack-Aware and Data Center-Aware Replication ###

SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:

```
curl http://localhost:9333/dir/assign?replication=001
```

The replication parameter options are:

```
000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
```

More details about replication can be found [on the wiki][Replication].

[Replication]: https://github.com/seaweedfs/seaweedfs/wiki/Replication

You can also set the default replication strategy when starting the master server.

### Allocate File Key on Specific Data Center ###

Volume servers can be started with a specific data center name:

```
 weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
```

When requesting a file key, an optional &quot;dataCenter&quot; parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to &#039;dc1&#039;:

```
 http://localhost:9333/dir/assign?dataCenter=dc1
```

### Other Features ###
  * [No Single Point of Failure][feat-1]
  * [Insert with your own keys][feat-2]
  * [Chunking large files][feat-3]
  * [Collection as a Simple Name Space][feat-4]

[feat-1]: https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server
[feat-2]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys
[feat-3]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files
[feat-4]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space

[Back to TOC](#table-of-contents)

## Object Store Architecture ##

Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.

The main drawback is that the central master can&#039;t handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.

Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.

The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.

For comparison, consider that an xfs inode structure in Linux is 536 bytes.

### Master Server and Volume Server ###

The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.

All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.

On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.

### Write and Read files ###

When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.

When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for t

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[nats-io/nats-server]]></title>
            <link>https://github.com/nats-io/nats-server</link>
            <guid>https://github.com/nats-io/nats-server</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[High-Performance server for NATS.io, the cloud and edge native messaging system.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nats-io/nats-server">nats-io/nats-server</a></h1>
            <p>High-Performance server for NATS.io, the cloud and edge native messaging system.</p>
            <p>Language: Go</p>
            <p>Stars: 18,387</p>
            <p>Forks: 1,665</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;logos/nats-horizontal-color.png&quot; width=&quot;300&quot; alt=&quot;NATS Logo&quot;&gt;
&lt;/p&gt;

[NATS](https://nats.io) is a simple, secure and performant communications system for digital systems, services and devices. NATS is part of the Cloud Native Computing Foundation ([CNCF](https://cncf.io)). NATS has over [40 client language implementations](https://nats.io/download/), and its server can run on-premise, in the cloud, at the edge, and even on a Raspberry Pi. NATS can secure and simplify design and operation of modern distributed systems.

[![License][License-Image]][License-Url] [![Build][Build-Status-Image]][Build-Status-Url] [![Release][Release-Image]][Release-Url] [![Slack][Slack-Image]][Slack-Url] [![Coverage][Coverage-Image]][Coverage-Url] [![Docker Downloads][Docker-Image]][Docker-Url] [![GitHub Downloads][GitHub-Image]][Somsubhra-URL] [![CII Best Practices][CIIBestPractices-Image]][CIIBestPractices-Url] [![Artifact Hub][ArtifactHub-Image]][ArtifactHub-Url]

## Documentation

- [Official Website](https://nats.io)
- [Official Documentation](https://docs.nats.io)
- [FAQ](https://docs.nats.io/reference/faq)
- Watch [a video overview](https://rethink.synadia.com/episodes/1/) of NATS.
- Watch [this video from SCALE 13x](https://www.youtube.com/watch?v=sm63oAVPqAM) to learn more about its origin story and design philosophy.

## Contact

- [Twitter](https://twitter.com/nats_io): Follow us on Twitter!
- [Google Groups](https://groups.google.com/forum/#!forum/natsio): Where you can ask questions
- [Slack](https://natsio.slack.com): Click [here](https://slack.nats.io) to join. You can ask questions to our maintainers and to the rich and active community.

## Contributing

If you are interested in contributing to NATS, read about our...

- [Contributing guide](./CONTRIBUTING.md)
- [Report issues or propose Pull Requests](https://github.com/nats-io)

[License-Url]: https://www.apache.org/licenses/LICENSE-2.0
[License-Image]: https://img.shields.io/badge/License-Apache2-blue.svg
[Docker-Image]: https://img.shields.io/docker/pulls/_/nats.svg
[Docker-Url]: https://hub.docker.com/_/nats
[Slack-Image]: https://img.shields.io/badge/chat-on%20slack-green
[Slack-Url]: https://slack.nats.io
[Fossa-Url]: https://app.fossa.io/projects/git%2Bgithub.com%2Fnats-io%2Fnats-server?ref=badge_shield
[Fossa-Image]: https://app.fossa.io/api/projects/git%2Bgithub.com%2Fnats-io%2Fnats-server.svg?type=shield
[Build-Status-Url]: https://github.com/nats-io/nats-server/actions/workflows/tests.yaml
[Build-Status-Image]: https://github.com/nats-io/nats-server/actions/workflows/tests.yaml/badge.svg?branch=main
[Release-Url]: https://github.com/nats-io/nats-server/releases/latest
[Release-Image]: https://img.shields.io/github/v/release/nats-io/nats-server
[Coverage-Url]: https://coveralls.io/r/nats-io/nats-server?branch=main
[Coverage-image]: https://coveralls.io/repos/github/nats-io/nats-server/badge.svg?branch=main
[ReportCard-Url]: https://goreportcard.com/report/nats-io/nats-server
[ReportCard-Image]: https://goreportcard.com/badge/github.com/nats-io/nats-server
[CIIBestPractices-Url]: https://bestpractices.coreinfrastructure.org/projects/1895
[CIIBestPractices-Image]: https://bestpractices.coreinfrastructure.org/projects/1895/badge
[ArtifactHub-Url]: https://artifacthub.io/packages/helm/nats/nats
[ArtifactHub-Image]: https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/nats
[GitHub-Release]: https://github.com/nats-io/nats-server/releases/
[GitHub-Image]: https://img.shields.io/github/downloads/nats-io/nats-server/total.svg?logo=github
[Somsubhra-url]: https://somsubhra.github.io/github-release-stats/?username=nats-io&amp;repository=nats-server

## Roadmap

The NATS product roadmap can be found [here](https://nats.io/about/#roadmap).

## Adopters

Who uses NATS? See our [list of users](https://nats.io/#who-uses-nats) on [https://nats.io](https://nats.io).

## Security

### Security Audit

A third party security audit was performed by Trail of Bits following engagement by the Open Source Technology Improvement Fund (OSTIF). You can see the [full report from April 2025 here](https://github.com/trailofbits/publications/blob/master/reviews/2025-04-ostif-nats-securityreview.pdf).

### Reporting Security Vulnerabilities

If you&#039;ve found a vulnerability or a potential vulnerability in the NATS server, please let us know at
[nats-security](mailto:security@nats.io).

## License

Unless otherwise noted, the NATS source files are distributed
under the Apache Version 2.0 license found in the LICENSE file.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[argoproj/argo-workflows]]></title>
            <link>https://github.com/argoproj/argo-workflows</link>
            <guid>https://github.com/argoproj/argo-workflows</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[Workflow Engine for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/argoproj/argo-workflows">argoproj/argo-workflows</a></h1>
            <p>Workflow Engine for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 16,109</p>
            <p>Forks: 3,390</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable-next-line MD041 --&gt;
[![Security Status](https://github.com/argoproj/argo-workflows/actions/workflows/snyk.yml/badge.svg?branch=main)](https://github.com/argoproj/argo-workflows/actions/workflows/snyk.yml?query=branch%3Amain)
[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/3830/badge)](https://bestpractices.coreinfrastructure.org/projects/3830)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-workflows/badge)](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-workflows)
[![FOSSA License Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fargoproj%2Fargo-workflows.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fargoproj%2Fargo-workflows?ref=badge_shield)
[![Slack](https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack)](https://argoproj.github.io/community/join-slack)
[![X Follow](https://img.shields.io/twitter/follow/argoproj?style=social)](https://x.com/argoproj)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-argoproj-blue.svg?logo=linkedin)](https://www.linkedin.com/company/argoproj/)
[![Release Version](https://img.shields.io/github/v/release/argoproj/argo-workflows?label=argo-workflows)](https://github.com/argoproj/argo-workflows/releases/latest)
[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-workflows)](https://artifacthub.io/packages/helm/argo/argo-workflows)

## What is Argo Workflows?

Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes.
Argo Workflows is implemented as a Kubernetes CRD (Custom Resource Definition).

* Define workflows where each step is a container.
* Model multi-step workflows as a sequence of tasks or capture the dependencies between tasks using a directed acyclic graph (DAG).
* Easily run compute intensive jobs for machine learning or data processing in a fraction of the time using Argo Workflows on Kubernetes.

Argo is a [Cloud Native Computing Foundation (CNCF)](https://cncf.io/) graduated project.

## Use Cases

* [Machine Learning pipelines](https://argo-workflows.readthedocs.io/en/latest/use-cases/machine-learning/)
* [Data and batch processing](https://argo-workflows.readthedocs.io/en/latest/use-cases/data-processing/)
* [Infrastructure automation](https://argo-workflows.readthedocs.io/en/latest/use-cases/infrastructure-automation/)
* [CI/CD](https://argo-workflows.readthedocs.io/en/latest/use-cases/ci-cd/)
* [Other use cases](https://argo-workflows.readthedocs.io/en/latest/use-cases/other/)

## Why Argo Workflows?

* Argo Workflows is the most popular workflow execution engine for Kubernetes.
* Light-weight, scalable, and easier to use.
    * Including for Python users through [the Hera Python SDK for Argo Workflows](https://hera.readthedocs.io/en/stable/).
* Designed from the ground up for containers without the overhead and limitations of legacy VM and server-based environments.
* Cloud agnostic and can run on any Kubernetes cluster.

[Read what people said in our latest survey](https://blog.argoproj.io/argo-workflows-events-2023-user-survey-results-82c53bc30543)

## Try Argo Workflows

You can try Argo Workflows via one of the following:

1. [Interactive Training Material](https://killercoda.com/argoproj/course/argo-workflows/)
1. [Access the demo environment](https://workflows.apps.argoproj.io/workflows/argo)

![Screenshot](docs/assets/screenshot.png)

## Who uses Argo Workflows?

[About 200+ organizations are officially using Argo Workflows](USERS.md)

## Ecosystem

Just some of the projects that use or rely on Argo Workflows (complete list [here](https://github.com/akuity/awesome-argo#ecosystem-projects)):

* [Argo Events](https://github.com/argoproj/argo-events)
* [Couler](https://github.com/couler-proj/couler)
* [Hera](https://github.com/argoproj-labs/hera-workflows)
* [Katib](https://github.com/kubeflow/katib)
* [Kedro](https://kedro.readthedocs.io/en/stable/)
* [Kubeflow Pipelines](https://github.com/kubeflow/pipelines)
* [Netflix Metaflow](https://metaflow.org)
* [Onepanel](https://github.com/onepanelio/onepanel)
* [Orchest](https://github.com/orchest/orchest/)
* [Piper](https://github.com/quickube/piper)
* [Ploomber](https://github.com/ploomber/ploomber)
* [Seldon](https://github.com/SeldonIO/seldon-core)
* [SQLFlow](https://github.com/sql-machine-learning/sqlflow)

## Client Libraries

Check out our [Java, Golang and Python clients](docs/client-libraries.md).

## Quickstart

* [Get started here](https://argo-workflows.readthedocs.io/en/latest/quick-start/)
* [Walk-through examples](https://argo-workflows.readthedocs.io/en/latest/walk-through/)

## Documentation

[View the docs](https://argo-workflows.readthedocs.io/en/latest/)

## Features

An incomplete list of features Argo Workflows provides:

* UI to visualize and manage Workflows
* Artifact support (S3, Artifactory, Alibaba Cloud OSS, Azure Blob Storage, HTTP, Git, GCS, raw)
* Workflow templating to store commonly used Workflows in the cluster
* Archiving Workflows after executing for later access
* Scheduled workflows using cron
* Server interface with REST API (HTTP and GRPC)
* DAG or Steps based declaration of workflows
* Step level input &amp; outputs (artifacts/parameters)
* Loops
* Parameterization
* Conditionals
* Timeouts (step &amp; workflow level)
* Retry (step &amp; workflow level)
* Resubmit (memoized)
* Suspend &amp; Resume
* Cancellation
* K8s resource orchestration
* Exit Hooks (notifications, cleanup)
* Garbage collection of completed workflow
* Scheduling (affinity/tolerations/node selectors)
* Volumes (ephemeral/existing)
* Parallelism limits
* Daemoned steps
* DinD (docker-in-docker)
* Script steps
* Event emission
* Prometheus metrics
* Multiple executors
* Multiple pod and workflow garbage collection strategies
* Automatically calculated resource usage per step
* Java/Golang/Python SDKs
* Pod Disruption Budget support
* Single-sign on (OAuth2/OIDC)
* Webhook triggering
* CLI
* Out-of-the box and custom Prometheus metrics
* Windows container support
* Embedded widgets
* Multiplex log viewer

## Community Meetings

We host monthly community meetings where we and the community showcase demos and discuss the current and future state of the project. Feel free to join us!
For Community Meeting information, minutes and recordings, please [see here](https://bit.ly/argo-wf-cmty-mtng).

Participation in Argo Workflows is governed by the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/master/code-of-conduct.md)

## Community Blogs and Presentations

* [Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo](https://github.com/terrytangyuan/awesome-argo)
* [Automation of Everything - How To Combine Argo Events, Workflows &amp; Pipelines, CD, and Rollouts](https://youtu.be/XNXJtxkUKeY)
* [Argo Workflows and Pipelines - CI/CD, Machine Learning, and Other Kubernetes Workflows](https://youtu.be/UMaivwrAyTA)
* [Argo Ansible role: Provisioning Argo Workflows on OpenShift](https://medium.com/@marekermk/provisioning-argo-on-openshift-with-ansible-and-kustomize-340a1fda8b50)
* [Argo Workflows vs Apache Airflow](http://bit.ly/30YNIvT)
* [Beyond Prototypes: Production-Ready ML Systems with Metaflow and Argo](https://github.com/terrytangyuan/public-talks/tree/main/talks/kubecon-na-2023-metaflow-argo)
* [CI/CD with Argo on Kubernetes](https://medium.com/@bouwe.ceunen/ci-cd-with-argo-on-kubernetes-28c1a99616a9)
* [Define Your CI/CD Pipeline with Argo Workflows](https://haque-zubair.medium.com/define-your-ci-cd-pipeline-with-argo-workflows-25aefb02fa63)
* [Distributed Machine Learning Patterns from Manning Publication](https://github.com/terrytangyuan/distributed-ml-patterns)
* [Engineering Cloud Native AI Platform](https://github.com/terrytangyuan/public-talks/tree/main/talks/platform-con-2024-engineering-cloud-native-ai-platform)
* [Managing Thousands of Automatic Machine Learning Experiments with Argo and Katib](https://github.com/terrytangyuan/public-talks/blob/main/talks/argocon-automl-experiments-2022)
* [Revolutionizing Scientific Simulations with Argo Workflows](https://www.youtube.com/watch?v=BYVf7GhfiRg)
* [Running Argo Workflows Across Multiple Kubernetes Clusters](https://admiralty.io/blog/running-argo-workflows-across-multiple-kubernetes-clusters/)
* [Scaling Kubernetes: Best Practices for Managing Large-Scale Batch Jobs with Spark and Argo Workflow](https://www.youtube.com/watch?v=KqEKRPjy4aE)
* [Open Source Model Management Roundup: Polyaxon, Argo, and Seldon](https://www.anaconda.com/blog/developer-blog/open-source-model-management-roundup-polyaxon-argo-and-seldon/)
* [Producing 200 OpenStreetMap extracts in 35 minutes using a scalable data workflow](https://www.interline.io/blog/scaling-openstreetmap-data-workflows/)
* [Production-Ready AI Platform on Kubernetes](https://github.com/terrytangyuan/public-talks/tree/main/talks/kubecon-europe-2024-production-ai-platform-on-k8s)
* [Argo integration review](http://dev.matt.hillsdon.net/2018/03/24/argo-integration-review.html)
* TGI Kubernetes with Joe Beda: [Argo workflow system](https://www.youtube.com/watch?v=M_rxPPLG8pU&amp;start=859)

## Project Resources

* [Argo Project GitHub organization](https://github.com/argoproj)
* [Argo Website](https://argoproj.github.io/)
* [Argo Slack](https://argoproj.github.io/community/join-slack)

## Security

See [SECURITY.md](SECURITY.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cloudnative-pg/cloudnative-pg]]></title>
            <link>https://github.com/cloudnative-pg/cloudnative-pg</link>
            <guid>https://github.com/cloudnative-pg/cloudnative-pg</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[CloudNativePG is a comprehensive platform designed to seamlessly manage PostgreSQL databases within Kubernetes environments, covering the entire operational lifecycle from initial deployment to ongoing maintenance]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudnative-pg/cloudnative-pg">cloudnative-pg/cloudnative-pg</a></h1>
            <p>CloudNativePG is a comprehensive platform designed to seamlessly manage PostgreSQL databases within Kubernetes environments, covering the entire operational lifecycle from initial deployment to ongoing maintenance</p>
            <p>Language: Go</p>
            <p>Stars: 7,089</p>
            <p>Forks: 527</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre>[![CNCF Landscape](https://img.shields.io/badge/CNCF%20Landscape-5699C6)][cncf-landscape]
[![Latest Release](https://img.shields.io/github/v/release/cloudnative-pg/cloudnative-pg.svg)][latest-release]
[![GitHub License](https://img.shields.io/github/license/cloudnative-pg/cloudnative-pg)][license]
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9933/badge)][openssf]
[![OpenSSF Scorecard Badge][openssf-scorecard-badge]][openssf-socrecard-view]
[![Documentation][documentation-badge]][documentation]
[![Stack Overflow](https://img.shields.io/badge/stackoverflow-cloudnative--pg-blue?logo=stackoverflow&amp;logoColor=%23F48024&amp;link=https%3A%2F%2Fstackoverflow.com%2Fquestions%2Ftagged%2Fcloudnative-pg)][stackoverflow]
[![FOSSA Status][fossa-badge]][fossa]

# Welcome to the CloudNativePG Project!

**CloudNativePG (CNPG)** is an open-source platform designed to seamlessly
manage [PostgreSQL](https://www.postgresql.org/) databases in Kubernetes
environments. It covers the entire operational lifecycle‚Äîfrom deployment to
ongoing maintenance‚Äîthrough its core component, the CloudNativePG operator.

## Table of Contents

- [Code of Conduct](CODE_OF_CONDUCT.md)
- [Governance Policies](https://github.com/cloudnative-pg/governance/blob/main/GOVERNANCE.md)
- [Contributing](CONTRIBUTING.md)
- [Adopters](ADOPTERS.md)
- [Commercial Support](https://cloudnative-pg.io/support/)
- [License](LICENSE)

## Getting Started

The best way to get started is the [Quickstart Guide](https://cloudnative-pg.io/documentation/current/quickstart/).

## Scope

### Mission

CloudNativePG aims to increase PostgreSQL adoption within Kubernetes by making
it an integral part of the development process and GitOps-driven CI/CD
automation.

### Core Principles &amp; Features

Designed by PostgreSQL experts for Kubernetes administrators, CloudNativePG
follows a Kubernetes-native approach to PostgreSQL primary/standby cluster
management. Instead of relying on external high-availability tools (like
Patroni, repmgr, or Stolon), it integrates directly with the Kubernetes API to
automate database operations that a skilled DBA would perform manually.

Key design decisions include:

- Direct integration with Kubernetes API: The PostgreSQL cluster‚Äôs status is
  available directly in the `Cluster` resource, allowing users to inspect it
  via the Kubernetes API.
- Operator pattern: The operator ensures that the desired PostgreSQL state is
  reconciled automatically, following Kubernetes best practices.
- Immutable application containers: Updates follow an immutable infrastructure
  model, as explained in
  [&quot;Why EDB Chose Immutable Application Containers&quot;](https://www.enterprisedb.com/blog/why-edb-chose-immutable-application-containers).

### How CloudNativePG Works

The operator continuously monitors and updates the PostgreSQL cluster state.
Examples of automated actions include:

- Failover management: If the primary instance fails, the operator elects a new
  primary, updates the cluster status, and orchestrates the transition.
- Scaling read replicas: When the number of desired replicas changes, the
  operator provisions or removes resources such as persistent volumes, secrets,
  and config maps while managing streaming replication.
- Service updates: Kubernetes remains the single source of truth, ensuring
  that PostgreSQL service endpoints are always up to date.
- Rolling updates: When an image is updated, the operator follows a rolling
  strategy‚Äîfirst updating replica pods before performing a controlled
  switchover for the primary.

CloudNativePG manages additional Kubernetes resources to enhance PostgreSQL
management, including: `Backup`, `ClusterImageCatalog`, `Database`,
`ImageCatalog`, `Pooler`, `Publication`, `ScheduledBackup`, and `Subscription`.

## Out of Scope

- **Kubernetes only:** CloudNativePG is dedicated to vanilla Kubernetes
  maintained by the [Cloud Native Computing Foundation
  (CNCF)](https://kubernetes.io/).
- **PostgreSQL only:** CloudNativePG is dedicated to vanilla PostgreSQL
  maintained by the [PostgreSQL Global Development Group
  (PGDG)](https://www.postgresql.org/about/).
- **No support for forks:** Features from PostgreSQL forks will only be
  considered if they can be integrated as extensions or pluggable frameworks.
- **Not a general-purpose database operator:** CloudNativePG does not support
  other databases (e.g., MariaDB).

CloudNativePG can be extended via the [CNPG-I plugin interface](https://github.com/cloudnative-pg/cnpg-i).

## Communications

- [Github Discussions](https://github.com/cloudnative-pg/cloudnative-pg/discussions)
- [Slack](https://cloud-native.slack.com/archives/C08MAUJ7NPM)
  (join the [CNCF Slack Workspace](https://communityinviter.com/apps/cloud-native/cncf)).
- [Twitter](https://twitter.com/CloudNativePg)
- [Mastodon](https://mastodon.social/@CloudNativePG)
- [Bluesky](https://bsky.app/profile/cloudnativepg.bsky.social)

## Resources

- [Roadmap](https://github.com/orgs/cloudnative-pg/projects/1)
- [Website](https://cloudnative-pg.io)
- [FAQ](docs/src/faq.md)
- [Blog](https://cloudnative-pg.io/blog/)
- [CloudNativePG plugin Interface (CNPG-I)](https://github.com/cloudnative-pg/cnpg-i).

## Adopters

A list of publicly known users of the CloudNativePG operator is in [ADOPTERS.md](ADOPTERS.md).
Help us grow our community and CloudNativePG by adding yourself and your
organization to this list!

### CloudNativePG at KubeCon

- April 4 2025, KubeCon Europe in London: [&quot;Consistent Volume Group Snapshots, Unraveling the Magic&quot;](https://sched.co/1tx8g) - Leonardo Cecchi (EDB) and Xing Yang (VMware)
- November 11 2024, Cloud Native Rejekts NA 2024: [&quot;Maximising Microservice Databases with Kubernetes, Postgres, and CloudNativePG&quot;](https://www.youtube.com/watch?v=uBzl_stoxoc&amp;ab_channel=CloudNativeRejekts) - Gabriele Bartolini (EDB) and Leonardo Cecchi (EDB)
- March 21 2024, KubeCon Europe 2024 in Paris: [&quot;Scaling Heights: Mastering Postgres Database Vertical Scalability with Kubernetes Storage Magic&quot;](https://kccnceu2024.sched.com/event/1YeM4/scaling-heights-mastering-postgres-database-vertical-scalability-with-kubernetes-storage-magic-gabriele-bartolini-edb-gari-singh-google) - Gari Singh, Google &amp; Gabriele Bartolini, EDB
- March 19 2024, Data on Kubernetes Day at KubeCon Europe 2024 in Paris: [&quot;From Zero to Hero: Scaling Postgres in Kubernetes Using the Power of CloudNativePG&quot;](https://colocatedeventseu2024.sched.com/event/1YFha/from-zero-to-hero-scaling-postgres-in-kubernetes-using-the-power-of-cloudnativepg-gabriele-bartolini-edb) - Gabriele Bartolini, EDB
- 7 November 2023, KubeCon North America 2023 in Chicago: [&quot;Disaster Recovery with Very Large Postgres Databases (in Kubernetes)&quot;](https://kccncna2023.sched.com/event/1R2ml/disaster-recovery-with-very-large-postgres-databases-gabriele-bartolini-edb-michelle-au-google) - Michelle Au, Google &amp; Gabriele Bartolini, EDB
- 27 October 2022, KubeCon North America 2022 in Detroit: [&quot;Data On Kubernetes, Deploying And Running PostgreSQL And Patterns For Databases In a Kubernetes Cluster&quot;](https://kccncna2022.sched.com/event/182GB/data-on-kubernetes-deploying-and-running-postgresql-and-patterns-for-databases-in-a-kubernetes-cluster-chris-milsted-ondat-gabriele-bartolini-edb) - Chris Milsted, Ondat &amp; Gabriele Bartolini, EDB

### Useful links

- [Data on Kubernetes (DoK) Community](https://dok.community/)
- [&quot;Cloud Neutral Postgres Databases with Kubernetes and CloudNativePG&quot; by Gabriele Bartolini](https://www.cncf.io/blog/2024/11/20/cloud-neutral-postgres-databases-with-kubernetes-and-cloudnativepg/) (November 2024)
- [&quot;How to migrate your PostgreSQL database in Kubernetes with ~0 downtime from anywhere&quot; by Gabriele Bartolini](https://gabrielebartolini.it/articles/2024/03/cloudnativepg-recipe-5-how-to-migrate-your-postgresql-database-in-kubernetes-with-~0-downtime-from-anywhere/) (March 2024)
- [&quot;Maximizing Microservice Databases with Kubernetes, Postgres, and CloudNativePG&quot; by Gabriele Bartolini](https://gabrielebartolini.it/articles/2024/02/maximizing-microservice-databases-with-kubernetes-postgres-and-cloudnativepg/) (February 2024)
- [&quot;Recommended Architectures for PostgreSQL in Kubernetes&quot; by Gabriele Bartolini](https://www.cncf.io/blog/2023/09/29/recommended-architectures-for-postgresql-in-kubernetes/) (September 2023)
- [&quot;The Current State of Major PostgreSQL Upgrades with CloudNativePG&quot; by Gabriele Bartolini](https://www.enterprisedb.com/blog/current-state-major-postgresql-upgrades-cloudnativepg-kubernetes) (August 2023)
- [&quot;The Rise of the Kubernetes Native Database&quot; by Jeff Carpenter](https://thenewstack.io/the-rise-of-the-kubernetes-native-database/) (December 2022)
- [&quot;Why Run Postgres in Kubernetes?&quot; by Gabriele Bartolini](https://cloudnativenow.com/kubecon-cnc-eu-2022/why-run-postgres-in-kubernetes/) (May 2022)
- [&quot;Shift-Left Security: The Path To PostgreSQL On Kubernetes&quot; by Gabriele Bartolini](https://www.tfir.io/shift-left-security-the-path-to-postgresql-on-kubernetes/) (April 2021)
- [&quot;Local Persistent Volumes and PostgreSQL usage in Kubernetes&quot; by Gabriele Bartolini](https://www.2ndquadrant.com/en/blog/local-persistent-volumes-and-postgresql-usage-in-kubernetes/) (June 2020)

---

&lt;p align=&quot;center&quot;&gt;
We are a &lt;a href=&quot;https://www.cncf.io/sandbox-projects/&quot;&gt;Cloud Native Computing Foundation Sandbox project&lt;/a&gt;.
&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; align=&quot;center&quot;&gt;
      &lt;picture align=&quot;center&quot;&gt;
         &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/white/cncf-white.svg?raw=true&quot;&gt;
         &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/color/cncf-color.svg?raw=true&quot;&gt;
         &lt;img align=&quot;center&quot; src=&quot;https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/color/cncf-color.svg?raw=true&quot; alt=&quot;CNCF logo&quot; width=&quot;50%&quot;/&gt;
      &lt;/picture&gt;
&lt;/p&gt;

---

&lt;p align=&quot;center&quot;&gt;
CloudNativePG was originally built and sponsored by &lt;a href=&quot;https://www.enterprisedb.com&quot;&gt;EDB&lt;/a&gt;.
&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; align=&quot;center&quot;&gt;
      &lt;picture align=&quot;center&quot;&gt;
         &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_white.svg&quot;&gt;
         &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_grey.svg&quot;&gt;
         &lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_grey.svg&quot; alt=&quot;EDB logo&quot; width=&quot;25%&quot;/&gt;
      &lt;/picture&gt;
&lt;/p&gt;

---

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.postgresql.org/about/policies/trademarks/&quot;&gt;Postgres, PostgreSQL, and the Slonik Logo&lt;/a&gt;
are trademarks or registered trademarks of the PostgreSQL Community Association
of Canada, and used with their permission.
&lt;/p&gt;

---

[cncf-landscape]: https://landscape.cncf.io/?item=app-definition-and-development--database--cloudnativepg
[stackoverflow]: https://stackoverflow.com/questions/tagged/cloudnative-pg
[latest-release]: https://github.com/cloudnative-pg/cloudnative-pg/releases/latest
[documentation]: https://cloudnative-pg.io/documentation/current/
[license]: https://github.com/cloudnative-pg/cloudnative-pg?tab=Apache-2.0-1-ov-file#readme
[openssf]: https://www.bestpractices.dev/projects/9933
[openssf-scorecard-badge]: https://api.scorecard.dev/projects/github.com/cloudnative-pg/cloudnative-pg/badge
[openssf-socrecard-view]: https://scorecard.dev/viewer/?uri=github.com/cloudnative-pg/cloudnative-pg
[documentation-badge]: https://img.shields.io/badge/Documentation-white?logo=data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAGN0lEQVR4nJRXXWwcVxU%2B8%2F%2BzP%2BPZtR2v7dqy07jUJUALNaiK6lZyUVVKWgGKaIv8QCMekBAVQlQICcEzVZFQVYFKQhASEBHlISJPCRJEshTFChgrIYHEiYMh69jetffHM7Mzc%2B9Bs7vjnTs7yZpZWbt37s%2F5zne%2Bc861CD0eXRkbHc3NfjeffvxNAGEAgULD2756v35%2B3qe1Nc4fnQVEXlA2LnOcXlCF8S%2B6vvVgq%2FL3M65X3e51PvfQCU4WJgZe%2B8GQ8fS7AKgjBB8KEHwjDXZSjkf0CREAaXM2eI9c65siqWxWl360Xl74ANHz%2Fy8AitxnTBfmz%2BhyYS4wGhwObQCIHSA0AigOMBzvOsXzd4pnjyL6NMmWEH8hi2b28Og3%2FqRJA0ewfQy0v1vGO2NovwPo%2FEU%2FwVgSU1PI%2BSu79v3lJAB8HM%2BTI%2FO%2FUUXzM4xHIe0xI4DdRqOAwnF%2F38ePPyzaDIDh%2FMxcWh462m08aojuGY97C0nrAEHg9BlF0fmeAPr0J15vbaKsp0BZQzEDEAlP9B209UIIVXUta%2FQEQHwxgxFjTc%2BRskAwrgVWmHtg22vMPJwLDqGUNJIAMHVAkGu3WdpZz6NAkgSXpINSycluV28er1a3rJ4M3F2%2F9AtCvXKycRrTQttrjINjxxxIL9jevxdaDHU%2FTBr6pL5ruzuLZubgUQBOY2hPij3GBUe7tBCMBRE2KrXVSz0BBI%2FtPVgtV%2F%2FxkZ5WSjI%2F%2BFIXC3sHJwgT4yFqrZFFTSlVrp3sGYLwcfxSmXCbS00j2Ms4K7qkOsFx6qdTuiHtG4AimfmM8NyvOvR2G48qXtZ2fsfrN7%2BqpcRyUp0glKiimDm4TwAcHBp%2B9WeA4ki0GMWNR9OVF8BZvn7xtI%2FF09H8jzLEgz6yLwCDuelnFXHkTZZOytCOEdqDOtGwsm%2BNj00fXt%2B6%2Bj4vcA7bwNrZwENmXwAKuZnvsNRThs5ozMPfPiHyoDF7xiduHcXb70A8dRFheHjiySQATBZk0nl9MHPkBEWUoEtYjyrPFNwGzfdlD37Zdu98KCv%2BMmD2BYpUCvcST39e0%2BS1Wr249FAAg7mPzWrS5NstEbE0xrsiA6QN1PfRFLnhr%2BspxVJTlY8Mw1DqNXeyCQFREEXz9cHB0QOev73QaNhOF4B%2B45PHFHFgDhJTqjuubJFqX1KQco7NTTuW8kq95k2G4eLEGzM7lfItnjNeTKcOfV%2FT8hOuV77A9IK0XjgMpCO0ZiuV3L%2F6njCFAOmucGB3OII5XgCXEJTDdZLElVbu3Vz0fWexvL30k0B6ggBACOmIUBAEUKX0dDTvW7RCYcdZPq6n%2FSsQnUO2RuyBRgQ9Rc5mMvJ6CNIj1nXfd9qWAsCkaZzJAk1L8UjVqY737dSjfCGrPHWqXL32Q0mB%2F2BXnke00WaEYv2aTzAbnuV5pcWkDGAAGJmhSafh6hjr%2BW2SVYHrP7bb%2BOdPW%2FUgflGlTM2gaK%2Ft7tp6%2BN6yixdN89DcIwGktIFPABfNbwoQqQWEUnDJzg1g0jDeK5p7Kp7nensXFI7uyAr%2FLyM7fYLnpa6LYScE8vDnot5hrKlslm%2BfE3nVxJgO4o3KcYu%2FF8XM8yFQ27n%2F65Te%2FzKl3Jhpjj6TCIDneRD5%2FItxr1vdkALw7p1qfeWPpjHxMtsXaPxu6FLc%2BrnbSB1r7fcrlr36nqwMzQfnplJDryQCGOh%2FbLjhcM%2FEvQ4Pdund9xRV5m1LfTXaF%2BK9gsLGB9nsgddcz8thM%2FarPzYM8%2FFazf9sMFaU%2Fi%2FwvNANwEhPvUGR8ozn7d%2BiDKXixtKpbHp81nV9E7puRy31ixKUbOe%2Fv3Ud891ghhDrL5Z975eaOvV%2BCNRp0Gfz%2BcJjDABdTwlpdfKbId0t5XYAcHz5D5ZVtWUp9%2Flog2L7PgVJqZx0HOE5Cqghemv1%2Bt%2FeGBmZ%2BdB2yNN72UEpnzXG32YADA186i3bIpPxMhuKrFK%2Fd77JUnbkKbYvRJlC8DzKSZK76Lq1he2dKy%2BZuSfesSz5a2xHDbLJ%2BJaqdv5H4EUY%2BzbG2m9HgN7mg81bfw4W1uu7AjvHaqDhqF%2FZ3Fq5XFy%2FcESSDsx5fvZ7wLEsNfXk%2BjlVHfpSCOB%2FAQAA%2F%2F8zd8orZc2N9AAAAABJRU5ErkJggg%3D%3D
[fossa-badge]: https://app.fossa.com/api/projects/git%2Bgithub.com%2Fcloudnative-pg%2Fcloudnative-pg.svg?type=small
[fossa]: https://app.fossa.com/projects/git%2Bgithub.com%2Fcloudnative-pg%2Fcloudnative-pg?ref=badge_small
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hashicorp/terraform-provider-aws]]></title>
            <link>https://github.com/hashicorp/terraform-provider-aws</link>
            <guid>https://github.com/hashicorp/terraform-provider-aws</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[The AWS Provider enables Terraform to manage AWS resources.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hashicorp/terraform-provider-aws">hashicorp/terraform-provider-aws</a></h1>
            <p>The AWS Provider enables Terraform to manage AWS resources.</p>
            <p>Language: Go</p>
            <p>Stars: 10,551</p>
            <p>Forks: 9,762</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable first-line-h1 no-inline-html --&gt;
&lt;a href=&quot;https://terraform.io&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;.github/terraform_logo_dark.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;.github/terraform_logo_light.svg&quot;&gt;
    &lt;img src=&quot;.github/terraform_logo_light.svg&quot; alt=&quot;Terraform logo&quot; title=&quot;Terraform&quot; align=&quot;right&quot; height=&quot;50&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;

# Terraform AWS Provider

[![Forums][discuss-badge]][discuss]

[discuss-badge]: https://img.shields.io/badge/discuss-terraform--aws-623CE4.svg?style=flat
[discuss]: https://discuss.hashicorp.com/c/terraform-providers/tf-aws/

The [AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs) enables [Terraform](https://terraform.io) to manage [AWS](https://aws.amazon.com) resources.

- [Contributing guide](https://hashicorp.github.io/terraform-provider-aws/)
- [Quarterly development roadmap](ROADMAP.md)
- [FAQ](https://hashicorp.github.io/terraform-provider-aws/faq/)
- [Tutorials](https://learn.hashicorp.com/collections/terraform/aws-get-started)
- [discuss.hashicorp.com](https://discuss.hashicorp.com/c/terraform-providers/tf-aws/)

_**Please note:** We take Terraform&#039;s security and our users&#039; trust very seriously. If you believe you have found a security issue in the Terraform AWS Provider, please responsibly disclose it by contacting us at security@hashicorp.com._
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[charmbracelet/crush]]></title>
            <link>https://github.com/charmbracelet/crush</link>
            <guid>https://github.com/charmbracelet/crush</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[The glamourous AI coding agent for your favourite terminal üíò]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/charmbracelet/crush">charmbracelet/crush</a></h1>
            <p>The glamourous AI coding agent for your favourite terminal üíò</p>
            <p>Language: Go</p>
            <p>Stars: 14,021</p>
            <p>Forks: 736</p>
            <p>Stars today: 60 stars today</p>
            <h2>README</h2><pre># Crush

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://stuff.charm.sh/crush/charm-crush.png&quot;&gt;&lt;img width=&quot;450&quot; alt=&quot;Charm Crush Logo&quot; src=&quot;https://github.com/user-attachments/assets/adc1a6f4-b284-4603-836c-59038caa2e8b&quot; /&gt;&lt;/a&gt;&lt;br /&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/crush/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/charmbracelet/crush&quot; alt=&quot;Latest Release&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/crush/actions&quot;&gt;&lt;img src=&quot;https://github.com/charmbracelet/crush/actions/workflows/build.yml/badge.svg&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Your new coding bestie, now available in your favourite terminal.&lt;br /&gt;Your tools, your code, and your workflows, wired into your LLM of choice.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;‰Ω†ÁöÑÊñ∞ÁºñÁ®ã‰ºô‰º¥ÔºåÁé∞Âú®Â∞±Âú®‰Ω†ÊúÄÁà±ÁöÑÁªàÁ´Ø‰∏≠„ÄÇ&lt;br /&gt;‰Ω†ÁöÑÂ∑•ÂÖ∑„ÄÅ‰ª£Á†ÅÂíåÂ∑•‰ΩúÊµÅÔºåÈÉΩ‰∏éÊÇ®ÈÄâÊã©ÁöÑ LLM Ê®°ÂûãÁ¥ßÂØÜÁõ∏Ëøû„ÄÇ&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;800&quot; alt=&quot;Crush Demo&quot; src=&quot;https://github.com/user-attachments/assets/58280caf-851b-470a-b6f7-d5c4ea8a1968&quot; /&gt;&lt;/p&gt;

## Features

- **Multi-Model:** choose from a wide range of LLMs or add your own via OpenAI- or Anthropic-compatible APIs
- **Flexible:** switch LLMs mid-session while preserving context
- **Session-Based:** maintain multiple work sessions and contexts per project
- **LSP-Enhanced:** Crush uses LSPs for additional context, just like you do
- **Extensible:** add capabilities via MCPs (`http`, `stdio`, and `sse`)
- **Works Everywhere:** first-class support in every terminal on macOS, Linux, Windows (PowerShell and WSL), FreeBSD, OpenBSD, and NetBSD

## Installation

Use a package manager:

```bash
# Homebrew
brew install charmbracelet/tap/crush

# NPM
npm install -g @charmland/crush

# Arch Linux (btw)
yay -S crush-bin

# Nix
nix run github:numtide/nix-ai-tools#crush
```

Windows users:

```bash
# Winget
winget install charmbracelet.crush

# Scoop
scoop bucket add charm https://github.com/charmbracelet/scoop-bucket.git
scoop install crush
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Nix (NUR)&lt;/strong&gt;&lt;/summary&gt;

Crush is available via [NUR](https://github.com/nix-community/NUR) in `nur.repos.charmbracelet.crush`.

You can also try out Crush via `nix-shell`:

```bash
# Add the NUR channel.
nix-channel --add https://github.com/nix-community/NUR/archive/main.tar.gz nur
nix-channel --update

# Get Crush in a Nix shell.
nix-shell -p &#039;(import &lt;nur&gt; { pkgs = import &lt;nixpkgs&gt; {}; }).repos.charmbracelet.crush&#039;
```

### NixOS &amp; Home Manager Module Usage via NUR

Crush provides NixOS and Home Manager modules via NUR.
You can use these modules directly in your flake by importing them from NUR. Since it auto detects whether its a home manager or nixos context you can use the import the exact same way :)

```nix
{
  inputs = {
    nixpkgs.url = &quot;github:NixOS/nixpkgs/nixos-unstable&quot;;
    nur.url = &quot;github:nix-community/NUR&quot;;
  };

  outputs = { self, nixpkgs, nur, ... }: {
    nixosConfigurations.your-hostname = nixpkgs.lib.nixosSystem {
      system = &quot;x86_64-linux&quot;;
      modules = [
        nur.modules.nixos.default
        nur.repos.charmbracelet.modules.crush
        {
          programs.crush = {
            enable = true;
            settings = {
              providers = {
                openai = {
                  id = &quot;openai&quot;;
                  name = &quot;OpenAI&quot;;
                  base_url = &quot;https://api.openai.com/v1&quot;;
                  type = &quot;openai&quot;;
                  api_key = &quot;sk-fake123456789abcdef...&quot;;
                  models = [
                    {
                      id = &quot;gpt-4&quot;;
                      name = &quot;GPT-4&quot;;
                    }
                  ];
                };
              };
              lsp = {
                go = { command = &quot;gopls&quot;; enabled = true; };
                nix = { command = &quot;nil&quot;; enabled = true; };
              };
              options = {
                context_paths = [ &quot;/etc/nixos/configuration.nix&quot; ];
                tui = { compact_mode = true; };
                debug = false;
              };
            };
          };
        }
      ];
    };
  };
}
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Debian/Ubuntu&lt;/strong&gt;&lt;/summary&gt;

```bash
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg
echo &quot;deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *&quot; | sudo tee /etc/apt/sources.list.d/charm.list
sudo apt update &amp;&amp; sudo apt install crush
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Fedora/RHEL&lt;/strong&gt;&lt;/summary&gt;

```bash
echo &#039;[charm]
name=Charm
baseurl=https://repo.charm.sh/yum/
enabled=1
gpgcheck=1
gpgkey=https://repo.charm.sh/yum/gpg.key&#039; | sudo tee /etc/yum.repos.d/charm.repo
sudo yum install crush
```

&lt;/details&gt;

Or, download it:

- [Packages][releases] are available in Debian and RPM formats
- [Binaries][releases] are available for Linux, macOS, Windows, FreeBSD, OpenBSD, and NetBSD

[releases]: https://github.com/charmbracelet/crush/releases

Or just install it with Go:

```
go install github.com/charmbracelet/crush@latest
```

&gt; [!WARNING]
&gt; Productivity may increase when using Crush and you may find yourself nerd
&gt; sniped when first using the application. If the symptoms persist, join the
&gt; [Discord][discord] and nerd snipe the rest of us.

## Getting Started

The quickest way to get started is to grab an API key for your preferred
provider such as Anthropic, OpenAI, Groq, or OpenRouter and just start
Crush. You&#039;ll be prompted to enter your API key.

That said, you can also set environment variables for preferred providers.

| Environment Variable        | Provider                                           |
| --------------------------- | -------------------------------------------------- |
| `ANTHROPIC_API_KEY`         | Anthropic                                          |
| `OPENAI_API_KEY`            | OpenAI                                             |
| `OPENROUTER_API_KEY`        | OpenRouter                                         |
| `GEMINI_API_KEY`            | Google Gemini                                      |
| `CEREBRAS_API_KEY`          | Cerebras                                           |
| `HF_TOKEN`                  | Huggingface Inference                              |
| `VERTEXAI_PROJECT`          | Google Cloud VertexAI (Gemini)                     |
| `VERTEXAI_LOCATION`         | Google Cloud VertexAI (Gemini)                     |
| `GROQ_API_KEY`              | Groq                                               |
| `AWS_ACCESS_KEY_ID`         | AWS Bedrock (Claude)                               |
| `AWS_SECRET_ACCESS_KEY`     | AWS Bedrock (Claude)                               |
| `AWS_REGION`                | AWS Bedrock (Claude)                               |
| `AWS_PROFILE`               | Custom AWS Profile                                 |
| `AWS_REGION`                | AWS Region                                         |
| `AZURE_OPENAI_API_ENDPOINT` | Azure OpenAI models                                |
| `AZURE_OPENAI_API_KEY`      | Azure OpenAI models (optional when using Entra ID) |
| `AZURE_OPENAI_API_VERSION`  | Azure OpenAI models                                |

### By the Way

Is there a provider you‚Äôd like to see in Crush? Is there an existing model that needs an update?

Crush‚Äôs default model listing is managed in [Catwalk](https://github.com/charmbracelet/catwalk), a community-supported, open source repository of Crush-compatible models, and you‚Äôre welcome to contribute.

&lt;a href=&quot;https://github.com/charmbracelet/catwalk&quot;&gt;&lt;img width=&quot;174&quot; height=&quot;174&quot; alt=&quot;Catwalk Badge&quot; src=&quot;https://github.com/user-attachments/assets/95b49515-fe82-4409-b10d-5beb0873787d&quot; /&gt;&lt;/a&gt;

## Configuration

Crush runs great with no configuration. That said, if you do need or want to
customize Crush, configuration can be added either local to the project itself,
or globally, with the following priority:

1. `.crush.json`
2. `crush.json`
3. `$HOME/.config/crush/crush.json` (Windows: `%USERPROFILE%\AppData\Local\crush\crush.json`)

Configuration itself is stored as a JSON object:

```json
{
  &quot;this-setting&quot;: { &quot;this&quot;: &quot;that&quot; },
  &quot;that-setting&quot;: [&quot;ceci&quot;, &quot;cela&quot;]
}
```

As an additional note, Crush also stores ephemeral data, such as application state, in one additional location:

```bash
# Unix
$HOME/.local/share/crush/crush.json

# Windows
%LOCALAPPDATA%\crush\crush.json
```

### LSPs

Crush can use LSPs for additional context to help inform its decisions, just
like you would. LSPs can be added manually like so:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;lsp&quot;: {
    &quot;go&quot;: {
      &quot;command&quot;: &quot;gopls&quot;,
      &quot;env&quot;: {
        &quot;GOTOOLCHAIN&quot;: &quot;go1.24.5&quot;
      }
    },
    &quot;typescript&quot;: {
      &quot;command&quot;: &quot;typescript-language-server&quot;,
      &quot;args&quot;: [&quot;--stdio&quot;]
    },
    &quot;nix&quot;: {
      &quot;command&quot;: &quot;nil&quot;
    }
  }
}
```

### MCPs

Crush also supports Model Context Protocol (MCP) servers through three
transport types: `stdio` for command-line servers, `http` for HTTP endpoints,
and `sse` for Server-Sent Events. Environment variable expansion is supported
using `$(echo $VAR)` syntax.

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;mcp&quot;: {
    &quot;filesystem&quot;: {
      &quot;type&quot;: &quot;stdio&quot;,
      &quot;command&quot;: &quot;node&quot;,
      &quot;args&quot;: [&quot;/path/to/mcp-server.js&quot;],
      &quot;timeout&quot;: 120,
      &quot;disabled&quot;: false,
      &quot;env&quot;: {
        &quot;NODE_ENV&quot;: &quot;production&quot;
      }
    },
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://example.com/mcp/&quot;,
      &quot;timeout&quot;: 120,
      &quot;disabled&quot;: false,
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;$(echo Bearer $EXAMPLE_MCP_TOKEN)&quot;
      }
    },
    &quot;streaming-service&quot;: {
      &quot;type&quot;: &quot;sse&quot;,
      &quot;url&quot;: &quot;https://example.com/mcp/sse&quot;,
      &quot;timeout&quot;: 120,
      &quot;disabled&quot;: false,
      &quot;headers&quot;: {
        &quot;API-Key&quot;: &quot;$(echo $API_KEY)&quot;
      }
    }
  }
}
```

### Ignoring Files

Crush respects `.gitignore` files by default, but you can also create a
`.crushignore` file to specify additional files and directories that Crush
should ignore. This is useful for excluding files that you want in version
control but don&#039;t want Crush to consider when providing context.

The `.crushignore` file uses the same syntax as `.gitignore` and can be placed
in the root of your project or in subdirectories.

### Allowing Tools

By default, Crush will ask you for permission before running tool calls. If
you&#039;d like, you can allow tools to be executed without prompting you for
permissions. Use this with care.

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;permissions&quot;: {
    &quot;allowed_tools&quot;: [
      &quot;view&quot;,
      &quot;ls&quot;,
      &quot;grep&quot;,
      &quot;edit&quot;,
      &quot;mcp_context7_get-library-doc&quot;
    ]
  }
}
```

You can also skip all permission prompts entirely by running Crush with the
`--yolo` flag. Be very, very careful with this feature.

### Attribution Settings

By default, Crush adds attribution information to Git commits and pull requests
it creates. You can customize this behavior with the `attribution` option:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;attribution&quot;: {
      &quot;co_authored_by&quot;: true,
      &quot;generated_with&quot;: true
    }
  }
}
```

- `co_authored_by`: When true (default), adds `Co-Authored-By: Crush &lt;crush@charm.land&gt;` to commit messages
- `generated_with`: When true (default), adds `üíò Generated with Crush` line to commit messages and PR descriptions

### Local Models

Local models can also be configured via OpenAI-compatible API. Here are two common examples:

#### Ollama

```json
{
  &quot;providers&quot;: {
    &quot;ollama&quot;: {
      &quot;name&quot;: &quot;Ollama&quot;,
      &quot;base_url&quot;: &quot;http://localhost:11434/v1/&quot;,
      &quot;type&quot;: &quot;openai&quot;,
      &quot;models&quot;: [
        {
          &quot;name&quot;: &quot;Qwen 3 30B&quot;,
          &quot;id&quot;: &quot;qwen3:30b&quot;,
          &quot;context_window&quot;: 256000,
          &quot;default_max_tokens&quot;: 20000
        }
      ]
    }
  }
}
```

#### LM Studio

```json
{
  &quot;providers&quot;: {
    &quot;lmstudio&quot;: {
      &quot;name&quot;: &quot;LM Studio&quot;,
      &quot;base_url&quot;: &quot;http://localhost:1234/v1/&quot;,
      &quot;type&quot;: &quot;openai&quot;,
      &quot;models&quot;: [
        {
          &quot;name&quot;: &quot;Qwen 3 30B&quot;,
          &quot;id&quot;: &quot;qwen/qwen3-30b-a3b-2507&quot;,
          &quot;context_window&quot;: 256000,
          &quot;default_max_tokens&quot;: 20000
        }
      ]
    }
  }
}
```

### Custom Providers

Crush supports custom provider configurations for both OpenAI-compatible and
Anthropic-compatible APIs.

#### OpenAI-Compatible APIs

Here‚Äôs an example configuration for Deepseek, which uses an OpenAI-compatible
API. Don&#039;t forget to set `DEEPSEEK_API_KEY` in your environment.

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;providers&quot;: {
    &quot;deepseek&quot;: {
      &quot;type&quot;: &quot;openai&quot;,
      &quot;base_url&quot;: &quot;https://api.deepseek.com/v1&quot;,
      &quot;api_key&quot;: &quot;$DEEPSEEK_API_KEY&quot;,
      &quot;models&quot;: [
        {
          &quot;id&quot;: &quot;deepseek-chat&quot;,
          &quot;name&quot;: &quot;Deepseek V3&quot;,
          &quot;cost_per_1m_in&quot;: 0.27,
          &quot;cost_per_1m_out&quot;: 1.1,
          &quot;cost_per_1m_in_cached&quot;: 0.07,
          &quot;cost_per_1m_out_cached&quot;: 1.1,
          &quot;context_window&quot;: 64000,
          &quot;default_max_tokens&quot;: 5000
        }
      ]
    }
  }
}
```

#### Anthropic-Compatible APIs

Custom Anthropic-compatible providers follow this format:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;providers&quot;: {
    &quot;custom-anthropic&quot;: {
      &quot;type&quot;: &quot;anthropic&quot;,
      &quot;base_url&quot;: &quot;https://api.anthropic.com/v1&quot;,
      &quot;api_key&quot;: &quot;$ANTHROPIC_API_KEY&quot;,
      &quot;extra_headers&quot;: {
        &quot;anthropic-version&quot;: &quot;2023-06-01&quot;
      },
      &quot;models&quot;: [
        {
          &quot;id&quot;: &quot;claude-sonnet-4-20250514&quot;,
          &quot;name&quot;: &quot;Claude Sonnet 4&quot;,
          &quot;cost_per_1m_in&quot;: 3,
          &quot;cost_per_1m_out&quot;: 15,
          &quot;cost_per_1m_in_cached&quot;: 3.75,
          &quot;cost_per_1m_out_cached&quot;: 0.3,
          &quot;context_window&quot;: 200000,
          &quot;default_max_tokens&quot;: 50000,
          &quot;can_reason&quot;: true,
          &quot;supports_attachments&quot;: true
        }
      ]
    }
  }
}
```

### Amazon Bedrock

Crush currently supports running Anthropic models through Bedrock, with caching disabled.

- A Bedrock provider will appear once you have AWS configured, i.e. `aws configure`
- Crush also expects the `AWS_REGION` or `AWS_DEFAULT_REGION` to be set
- To use a specific AWS profile set `AWS_PROFILE` in your environment, i.e. `AWS_PROFILE=myprofile crush`

### Vertex AI Platform

Vertex AI will appear in the list of available providers when `VERTEXAI_PROJECT` and `VERTEXAI_LOCATION` are set. You will also need to be authenticated:

```bash
gcloud auth application-default login
```

To add specific models to the configuration, configure as such:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;providers&quot;: {
    &quot;vertexai&quot;: {
      &quot;models&quot;: [
        {
          &quot;id&quot;: &quot;claude-sonnet-4@20250514&quot;,
          &quot;name&quot;: &quot;VertexAI Sonnet 4&quot;,
          &quot;cost_per_1m_in&quot;: 3,
          &quot;cost_per_1m_out&quot;: 15,
          &quot;cost_per_1m_in_cached&quot;: 3.75,
          &quot;cost_per_1m_out_cached&quot;: 0.3,
          &quot;context_window&quot;: 200000,
          &quot;default_max_tokens&quot;: 50000,
          &quot;can_reason&quot;: true,
          &quot;supports_attachments&quot;: true
        }
      ]
    }
  }
}
```

## Logging

Sometimes you need to look at logs. Luckily, Crush logs all sorts of
stuff. Logs are stored in `./.crush/logs/crush.log` relative to the project.

The CLI also contains some helper commands to make perusing recent logs easier:

```bash
# Print the last 1000 lines
crush logs

# Print the last 500 lines
crush logs --tail 500

# Follow logs in real time
crush logs --follow
```

Want more logging? Run `crush` with the `--debug` flag, or enable it in the
config:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;debug&quot;: true,
    &quot;debug_lsp&quot;: true
  }
}
```

## Provider Auto-Updates

By default, Crush automatically checks for the latest and greatest list of
providers and models from [Catwalk](https://github.com/charmbracelet/catwalk),
the open source Crush provider database. This means that when new providers and
models are available, or when model metadata changes, Crush automatically
updates your local configuration.

### Disabling automatic provider updates

For those with restricted internet access, or those who prefer to work in
air-gapped environments, this might not be want you want, and this feature can
be disabled.

To disable automatic provider updates, set `disable_provider_auto_update` into
your `crush.json` config:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;disable_provider_auto_update&quot;: true
  }
}
```

Or set the `CRUSH_DISABLE_PROVIDER_AUTO_UPDATE` environment variable:

```bash
export CRUSH_DISABLE_PROVIDER_AUTO_UPDATE=1
```

### Manually updating providers

Manually updating providers is possible with the `crush update-providers`
command:

```bash
# Update providers remotely from Catwalk.
crush update-providers

# Update providers from a custom Catwalk base URL.
crush update-providers https://example.com/

# Update providers from a local file.
crush update-providers /path/to/local-providers.json

# Reset providers to the embedded version, embedded at crush at build time.
crush update-providers embedded

# For more info:
crush update-providers --help
```

## Metrics

Crush records pseudonymous usage metrics (tied to a device-specific hash),
which maintainers rely on to inform development and support priorities. The
metrics include solely usage metadata; prompts and responses are NEVER
collected.

Details on exactly what‚Äôs collected are in the source code ([here](https://github.com/charmbracelet/crush/tree/main/internal/event)
and [here](https://github.com/charmbracelet/crush/blob/main/internal/llm/agent/event.go)).

You can opt out of metrics collection at any time by setting the environment
variable by setting the following in your environment:

```bash
export CRUSH_DISABLE_METRICS=1
```

Or by setting the following in your config:

```json
{
  &quot;options&quot;: {
    &quot;disable_metrics&quot;: true
  }
}
```

Crush also respects the [`DO_NOT_TRACK`](https://consoledonottrack.com)
convention which can be enabled via `export DO_NOT_TRACK=1`.

## A Note on Claude Max and GitHub Copilot

Crush only supports model providers through official, compliant APIs. We do not
support or endorse any methods that rely on personal Claude Max and GitHub
Copilot accounts or OAuth workarounds, which violate Anthropic and
Microsoft‚Äôs Terms of Service.

We‚Äôre committed to building sustainable, trusted integrations with model
providers. If you‚Äôre a provider interested in working with us,
[reach out](mailto:vt100@charm.sh).

## Contributing

See the [contributing guide](https://github.com/charmbracelet/crush?tab=contributing-ov-file#contributing).

## Whatcha think?

We‚Äôd love to hear your thoughts on this project. Need help? We gotchu. You can find us on:

- [Twitter](https://twitter.com/charmcli)
- [Discord][discord]
- [Slack](https://charm.land/slack)
- [The Fediverse](https://mastodon.social/@charmcli)
- [Bluesky](https://bsky.app/profile/charm.land)

[discord]: https://charm.land/discord

## License

[FSL-1.1-MIT](https://github.com/charmbracelet/crush/raw/main/LICENSE.md)

---

Part of [Charm](https://charm.land).

&lt;a href=&quot;https://charm.land/&quot;&gt;&lt;img alt=&quot;The Charm logo&quot; width=&quot;400&quot; src=&quot;https://stuff.charm.sh/charm-banner-next.jpg&quot; /&gt;&lt;/a&gt;

&lt;!--prettier-ignore--&gt;
CharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[influxdata/telegraf]]></title>
            <link>https://github.com/influxdata/telegraf</link>
            <guid>https://github.com/influxdata/telegraf</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/influxdata/telegraf">influxdata/telegraf</a></h1>
            <p>Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.</p>
            <p>Language: Go</p>
            <p>Stars: 16,367</p>
            <p>Forks: 5,729</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># ![tiger](assets/TelegrafTigerSmall.png &quot;tiger&quot;) Telegraf

[![GoDoc](https://img.shields.io/badge/doc-reference-00ADD8.svg?logo=go)](https://godoc.org/github.com/influxdata/telegraf)
[![Docker pulls](https://img.shields.io/docker/pulls/library/telegraf.svg)](https://hub.docker.com/_/telegraf/)
[![Go Report Card](https://goreportcard.com/badge/github.com/influxdata/telegraf)](https://goreportcard.com/report/github.com/influxdata/telegraf)
[![Circle CI](https://circleci.com/gh/influxdata/telegraf.svg?style=svg)](https://circleci.com/gh/influxdata/telegraf)

Telegraf is an agent for collecting, processing, aggregating, and writing
metrics, logs, and other arbitrary data.

* Offers a comprehensive suite of over 300 plugins, covering a wide range of
  functionalities including system monitoring, cloud services, and message
  passing
* Enables the integration of user-defined code to collect, transform, and
  transmit data efficiently
* Compiles into a standalone static binary without any external dependencies,
  ensuring a streamlined deployment process
* Utilizes TOML for configuration, providing a user-friendly and unambiguous
  setup experience
* Developed with contributions from a diverse community of over 1,200
  contributors

Users can choose plugins from a wide range of topics, including but not limited
to:

* Devices: [OPC UA][], [Modbus][]
* Logs: [File][], [Tail][], [Directory Monitor][]
* Messaging: [AMQP][], [Kafka][], [MQTT][]
* Monitoring: [OpenTelemetry][], [Prometheus][]
* Networking: [Cisco TelemetryMDT][], [gNMI][]
* System monitoring: [CPU][], [Memory][], [Disk][], [Network][], [SMART][],
  [Docker][], [Nvidia SMI][], etc.
* Universal: [Exec][], [HTTP][], [HTTP Listener][], [SNMP][], [SQL][]
* Windows: [Event Log][], [Management Instrumentation][],
  [Performance Counters][]

## üî® Installation

For binary builds, Docker images, RPM &amp; DEB packages, and other builds of
Telegraf, please see the [install guide](/docs/INSTALL_GUIDE.md).

See the [releases documentation](/docs/RELEASES.md) for details on versioning
and when releases are made.

## üíª Usage

Users define a TOML configuration with the plugins and settings they wish to
use, then pass that configuration to Telegraf. The Telegraf agent then
collects data from inputs at each interval and sends data to outputs at each
flush interval.

For a basic walkthrough see [quick start](/docs/QUICK_START.md).

## üìñ Documentation

For a full list of documentation including tutorials, reference and other
material, start with the [/docs directory](/docs/README.md).

Additionally, each plugin has its own README that includes details about how to
configure, use, and sometimes debug or troubleshoot. Look under the
[/plugins directory](/plugins/) for specific plugins.

Here are some commonly used documents:

* [Changelog](/CHANGELOG.md)
* [Configuration](/docs/CONFIGURATION.md)
* [FAQ](/docs/FAQ.md)
* [Releases](https://github.com/influxdata/telegraf/releases)
* [Security](/SECURITY.md)

## ‚ù§Ô∏è Contribute

[![Contribute](https://img.shields.io/badge/contribute-to_telegraf-blue.svg?logo=influxdb)](https://github.com/influxdata/telegraf/blob/master/CONTRIBUTING.md)

We love our community of over 1,200 contributors! Many of the plugins included
in Telegraf were originally contributed by community members. Check out
our [contributing guide](CONTRIBUTING.md) if you are interested in helping out.
Also, join us on our [Community Slack](https://influxdata.com/slack) or
[Community Forums](https://community.influxdata.com/) if you have questions or
comments for our engineering teams.

If you are completely new to Telegraf and InfluxDB, you can also enroll for free
at [InfluxDB university](https://www.influxdata.com/university/) to take courses
to learn more.

## ‚ÑπÔ∏è Support

[![Slack](https://img.shields.io/badge/slack-join_chat-blue.svg?logo=slack)](https://www.influxdata.com/slack)
[![Forums](https://img.shields.io/badge/discourse-join_forums-blue.svg?logo=discourse)](https://community.influxdata.com/)

Please use the [Community Slack](https://influxdata.com/slack) or
[Community Forums](https://community.influxdata.com/) if you have questions or
comments for our engineering teams. GitHub issues are limited to actual issues
and feature requests only.

## üìú License

[![MIT](https://img.shields.io/badge/license-MIT-blue)](https://github.com/influxdata/telegraf/blob/master/LICENSE)

[OPC UA]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opcua
[Modbus]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/modbus
[File]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/file
[Tail]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/tail
[Directory Monitor]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/directory_monitor
[AMQP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/amqp_consumer
[Kafka]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/kafka_consumer
[MQTT]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mqtt_consumer
[OpenTelemetry]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opentelemetry
[Prometheus]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/prometheus
[Cisco TelemetryMDT]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cisco_telemetry_mdt
[gNMI]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/gnmi
[CPU]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cpu
[Memory]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mem
[Disk]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/disk
[Network]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/net
[SMART]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/smartctl
[Docker]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker
[Nvidia SMI]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/nvidia_smi
[Exec]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/exec
[HTTP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http
[HTTP Listener]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http_listener_v2
[SNMP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/snmp
[SQL]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/sql
[Event Log]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_eventlog
[Management Instrumentation]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_wmi
[Performance Counters]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cert-manager/cert-manager]]></title>
            <link>https://github.com/cert-manager/cert-manager</link>
            <guid>https://github.com/cert-manager/cert-manager</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[Automatically provision and manage TLS certificates in Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cert-manager/cert-manager">cert-manager/cert-manager</a></h1>
            <p>Automatically provision and manage TLS certificates in Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 13,216</p>
            <p>Forks: 2,253</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./logo/logo-small.png&quot; height=&quot;256&quot; width=&quot;256&quot; alt=&quot;cert-manager project logo&quot; /&gt;
&lt;/p&gt;
&lt;!-- note that the cert-manager logo in this repo is referred to in other README files in the cert-manager org
     as well as in Helm charts, etc.
     if you change its location or name, you&#039;ll need to update several other repos too! --&gt;

&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://prow.infra.cert-manager.io/?job=ci-cert-manager-master-make-test&quot;&gt;
&lt;!-- prow build badge, godoc, and go report card--&gt;
&lt;img alt=&quot;Build Status&quot; src=&quot;https://prow.infra.cert-manager.io/badge.svg?jobs=ci-cert-manager-master-make-test&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://godoc.org/github.com/cert-manager/cert-manager&quot;&gt;&lt;img src=&quot;https://godoc.org/github.com/cert-manager/cert-manager?status.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://goreportcard.com/report/github.com/cert-manager/cert-manager&quot;&gt;&lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/cert-manager/cert-manager&quot; /&gt;&lt;/a&gt;
&lt;br /&gt;
&lt;a href=&quot;https://artifacthub.io/packages/search?repo=cert-manager&quot;&gt;&lt;img alt=&quot;Artifact Hub&quot; src=&quot;https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/cert-manager&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://scorecard.dev/viewer/?uri=github.com/cert-manager/cert-manager&quot;&gt;&lt;img src=&quot;https://api.scorecard.dev/projects/github.com/cert-manager/cert-manager/badge&quot; alt=&quot;Scorecard score&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://clomonitor.io/projects/cncf/cert-manager&quot;&gt;&lt;img src=&quot;https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/cert-manager/badge&quot; alt=&quot;CLOMonitor&quot;/&gt;&lt;/a&gt;
&lt;br /&gt;
&lt;a href=&quot;https://www.bestpractices.dev/projects/8079&quot;&gt;&lt;img src=&quot;https://www.bestpractices.dev/projects/8079/badge&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

# cert-manager

cert-manager adds certificates and certificate issuers as resource types in Kubernetes clusters, and simplifies the process of obtaining, renewing and using those certificates.

It supports issuing certificates from a variety of sources, including Let&#039;s Encrypt (ACME), HashiCorp Vault, and Venafi TPP / TLS Protect Cloud, as well as local in-cluster issuance.

cert-manager also ensures certificates remain valid and up to date, attempting to renew certificates at an appropriate time before expiry to reduce the risk of outages and remove toil.

![cert-manager high level overview diagram](https://cert-manager.io/images/high-level-overview.svg)

## Documentation

Documentation for cert-manager can be found at [cert-manager.io](https://cert-manager.io/docs/).

For the common use-case of automatically issuing TLS certificates for
Ingress resources, see the [cert-manager nginx-ingress quick start guide](https://cert-manager.io/docs/tutorials/acme/nginx-ingress/).

For a more comprehensive guide to issuing your first certificate, see our [getting started guide](https://cert-manager.io/docs/getting-started/).

### Installation

[Installation](https://cert-manager.io/docs/installation/) is documented on the website, with a variety of supported methods.

## Developing cert-manager

We actively welcome contributions and we support both Linux and macOS environments for development.

Different platforms have different requirements; we document everything on our [Building cert-manager](https://cert-manager.io/docs/contributing/building/)
website page.

Note in particular that macOS has several extra requirements, to ensure that modern tools are installed and available. Read the page before
getting started!

## Troubleshooting

If you encounter any issues whilst using cert-manager, we have a number of ways to get help:

- A [troubleshooting guide](https://cert-manager.io/docs/faq/troubleshooting/) on our website.
- Our official [Kubernetes Slack channel](https://cert-manager.io/docs/contributing/#slack) - the quickest way to ask! ([#cert-manager](https://kubernetes.slack.com/messages/cert-manager) and [#cert-manager-dev](https://kubernetes.slack.com/messages/cert-manager-dev))
- [Searching for an existing issue](https://github.com/cert-manager/cert-manager/issues).

If you believe you&#039;ve found a bug and cannot find an existing issue, feel free to [open a new issue](https://github.com/cert-manager/cert-manager/issues)!
Be sure to include as much information as you can about your environment.

## Community

The [`cert-manager-dev` Google Group](https://groups.google.com/forum/#!forum/cert-manager-dev)
is used for project wide announcements and development coordination.
Anybody with a Google account can join the group by visiting the group and clicking &quot;Join Group&quot;.

### Meetings

We have several public meetings which any member of our Google Group is more than welcome to join!

Check out the details on [our website](https://cert-manager.io/docs/contributing/#meetings). Feel
free to drop in and ask questions, chat with us or just to say hi!

## Contributing

We welcome pull requests with open arms! There&#039;s a lot of work to do here, and
we&#039;re especially concerned with ensuring the longevity and reliability of the
project. The [contributing guide](https://cert-manager.io/docs/contributing/)
will help you get started.

## Coding Conventions

Code style guidelines are documented on the [coding conventions](https://cert-manager.io/docs/contributing/coding-conventions/) page
of the cert-manager website. Please try to follow those guidelines if you&#039;re submitting a pull request for cert-manager.

## Importing cert-manager as a Module

‚ö†Ô∏è Please note that cert-manager **does not** currently provide a Go module compatibility guarantee. That means that
**most code under `pkg/` is subject to change in a breaking way**, even between minor or patch releases and even if
the code is currently publicly exported.

The lack of a Go module compatibility guarantee does not affect API version guarantees
under the [Kubernetes Deprecation Policy](https://kubernetes.io/docs/reference/using-api/deprecation-policy/).

For more details see [Importing cert-manager in Go](https://cert-manager.io/docs/contributing/importing/) on the
cert-manager website.

The import path for cert-manager versions 1.8 and later is `github.com/cert-manager/cert-manager`.

For all versions of cert-manager before 1.8, including minor and patch releases, the import path is `github.com/jetstack/cert-manager`.

## Security Reporting

Security is the number one priority for cert-manager. If you think you&#039;ve found a security vulnerability, we&#039;d love to hear from you.

Follow the instructions in [SECURITY.md](./SECURITY.md) to make a report.

## Changelog

[Every release](https://github.com/cert-manager/cert-manager/releases) on GitHub has a changelog,
and we also publish release notes on [the website](https://cert-manager.io/docs/release-notes/).

## History

cert-manager is loosely based upon the work of [kube-lego](https://github.com/jetstack/kube-lego)
and has borrowed some wisdom from other similar projects such as [kube-cert-manager](https://github.com/PalmStoneGames/kube-cert-manager).


&lt;sub&gt;&lt;sup&gt;Logo design by [Zoe Paterson](https://zoepatersonmedia.com)&lt;/sup&gt;&lt;/sub&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[alibaba/higress]]></title>
            <link>https://github.com/alibaba/higress</link>
            <guid>https://github.com/alibaba/higress</guid>
            <pubDate>Sat, 18 Oct 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[ü§ñ AI Gateway | AI Native API Gateway]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/alibaba/higress">alibaba/higress</a></h1>
            <p>ü§ñ AI Gateway | AI Native API Gateway</p>
            <p>Language: Go</p>
            <p>Stars: 6,615</p>
            <p>Forks: 853</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;
&lt;h1 align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://img.alicdn.com/imgextra/i2/O1CN01NwxLDd20nxfGBjxmZ_!!6000000006895-2-tps-960-290.png&quot; alt=&quot;Higress&quot; width=&quot;240&quot; height=&quot;72.5&quot;&gt;
  &lt;br&gt;
  AI Gateway
&lt;/h1&gt;
&lt;h4 align=&quot;center&quot;&gt; AI Native API Gateway &lt;/h4&gt;

&lt;div align=&quot;center&quot;&gt;
    
[![Build Status](https://github.com/alibaba/higress/actions/workflows/build-and-test.yaml/badge.svg?branch=main)](https://github.com/alibaba/higress/actions)
[![license](https://img.shields.io/github/license/alibaba/higress.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)
[![discord](https://img.shields.io/discord/1364956090566971515?color=5865F2&amp;label=discord&amp;labelColor=black&amp;logo=discord&amp;logoColor=white&amp;style=flat-square)](https://discord.gg/tSbww9VDaM)

&lt;a href=&quot;https://trendshift.io/repositories/10918&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/10918&quot; alt=&quot;alibaba%2Fhigress | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://www.producthunt.com/posts/higress?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-higress&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=951287&amp;theme=light&amp;t=1745492822283&quot; alt=&quot;Higress - Global&amp;#0032;APIs&amp;#0032;as&amp;#0032;MCP&amp;#0032;powered&amp;#0032;by&amp;#0032;AI&amp;#0032;Gateway | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;

&lt;/div&gt;

[**Official Site**](https://higress.ai/en/) &amp;nbsp; |
&amp;nbsp; [**Docs**](https://higress.cn/en/docs/latest/overview/what-is-higress/) &amp;nbsp; |
&amp;nbsp; [**Blog**](https://higress.cn/en/blog/) &amp;nbsp; |
&amp;nbsp; [**MCP Server QuickStart**](https://higress.cn/en/ai/mcp-quick-start/) &amp;nbsp; |
&amp;nbsp; [**Developer Guide**](https://higress.cn/en/docs/latest/dev/architecture/) &amp;nbsp; |
&amp;nbsp; [**Wasm Plugin Hub**](https://higress.cn/en/plugin/) &amp;nbsp; |

&lt;p&gt;
   English | &lt;a href=&quot;README_ZH.md&quot;&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href=&quot;README_JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;
&lt;/p&gt;

## What is Higress?

Higress is a cloud-native API gateway based on Istio and Envoy, which can be extended with Wasm plugins written in Go/Rust/JS. It provides dozens of ready-to-use general-purpose plugins and an out-of-the-box console (try the [demo here](http://demo.higress.io/)).

### Core Use Cases

Higress&#039;s AI gateway capabilities support all [mainstream model providers](https://github.com/alibaba/higress/tree/main/plugins/wasm-go/extensions/ai-proxy/provider) both domestic and international. It also supports hosting MCP (Model Context Protocol) Servers through its plugin mechanism, enabling AI Agents to easily call various tools and services. With the [openapi-to-mcp tool](https://github.com/higress-group/openapi-to-mcpserver), you can quickly convert OpenAPI specifications into remote MCP servers for hosting. Higress provides unified management for both LLM API and MCP API. 

**üåü Try it now at [https://mcp.higress.ai/](https://mcp.higress.ai/)** to experience Higress-hosted Remote MCP Servers firsthand:

![Higress MCP Server Platform](https://img.alicdn.com/imgextra/i2/O1CN01nmVa0a1aChgpyyWOX_!!6000000003294-0-tps-3430-1742.jpg)

### Enterprise Adoption

Higress was born within Alibaba to solve the issues of Tengine reload affecting long-connection services and insufficient load balancing capabilities for gRPC/Dubbo. Within Alibaba Cloud, Higress&#039;s AI gateway capabilities support core AI applications such as Tongyi Bailian model studio, machine learning PAI platform, and other critical AI services. Alibaba Cloud has built its cloud-native API gateway product based on Higress, providing 99.99% gateway high availability guarantee service capabilities for a large number of enterprise customers.

## Summary

- [**Quick Start**](#quick-start)    
- [**Feature Showcase**](#feature-showcase)
- [**Use Cases**](#use-cases)
- [**Core Advantages**](#core-advantages)
- [**Community**](#community)

## Quick Start

Higress can be started with just Docker, making it convenient for individual developers to set up locally for learning or for building simple sites:

```bash
# Create a working directory
mkdir higress; cd higress
# Start higress, configuration files will be written to the working directory
docker run -d --rm --name higress-ai -v ${PWD}:/data \
        -p 8001:8001 -p 8080:8080 -p 8443:8443  \
        higress-registry.cn-hangzhou.cr.aliyuncs.com/higress/all-in-one:latest
```

Port descriptions:

- Port 8001: Higress UI console entry
- Port 8080: Gateway HTTP protocol entry
- Port 8443: Gateway HTTPS protocol entry

&gt; All Higress Docker images use Higress&#039;s own image repository and are not affected by Docker Hub rate limits.
&gt; In addition, the submission and updates of the images are protected by a security scanning mechanism (powered by Alibaba Cloud ACR), making them very secure for use in production environments.
&gt; 
&gt; If you experience a timeout when pulling image from `higress-registry.cn-hangzhou.cr.aliyuncs.com`, you can try replacing it with the following docker registry mirror source:
&gt; 
&gt; **Southeast Asia**: `higress-registry.ap-southeast-7.cr.aliyuncs.com`

For other installation methods such as Helm deployment under K8s, please refer to the official [Quick Start documentation](https://higress.io/en-us/docs/user/quickstart).

## Use Cases

- **MCP Server Hosting**:

  Higress hosts MCP Servers through its plugin mechanism, enabling AI Agents to easily call various tools and services. With the [openapi-to-mcp tool](https://github.com/higress-group/openapi-to-mcpserver), you can quickly convert OpenAPI specifications into remote MCP servers.

  ![](https://img.alicdn.com/imgextra/i1/O1CN01wv8H4g1mS4MUzC1QC_!!6000000004952-2-tps-1764-597.png)

  Key benefits of hosting MCP Servers with Higress:
  - Unified authentication and authorization mechanisms
  - Fine-grained rate limiting to prevent abuse
  - Comprehensive audit logs for all tool calls
  - Rich observability for monitoring performance
  - Simplified deployment through Higress&#039;s plugin mechanism
  - Dynamic updates without disruption or connection drops

     [Learn more...](https://higress.cn/en/ai/mcp-quick-start/?spm=36971b57.7beea2de.0.0.d85f20a94jsWGm)

- **AI Gateway**:

  Higress connects to all LLM model providers using a unified protocol, with AI observability, multi-model load balancing, token rate limiting, and caching capabilities:

  ![](https://img.alicdn.com/imgextra/i2/O1CN01izmBNX1jbHT7lP3Yr_!!6000000004566-0-tps-1920-1080.jpg)

- **Kubernetes ingress controller**:

  Higress can function as a feature-rich ingress controller, which is compatible with many annotations of K8s&#039; nginx ingress controller.
  
  [Gateway API](https://gateway-api.sigs.k8s.io/) support is coming soon and will support smooth migration from Ingress API to Gateway API.
  
- **Microservice gateway**:

  Higress can function as a microservice gateway, which can discovery microservices from various service registries, such as Nacos, ZooKeeper, Consul, Eureka, etc.
  
  It deeply integrates with [Dubbo](https://github.com/apache/dubbo), [Nacos](https://github.com/alibaba/nacos), [Sentinel](https://github.com/alibaba/Sentinel) and other microservice technology stacks.
  
- **Security gateway**:

  Higress can be used as a security gateway, supporting WAF and various authentication strategies, such as key-auth, hmac-auth, jwt-auth, basic-auth, oidc, etc.


## Core Advantages

- **Production Grade**

  Born from Alibaba&#039;s internal product with over 2 years of production validation, supporting large-scale scenarios with hundreds of thousands of requests per second.

  Completely eliminates traffic jitter caused by Nginx reload, configuration changes take effect in milliseconds and are transparent to business. Especially friendly to long-connection scenarios such as AI businesses.

- **Streaming Processing**

  Supports true complete streaming processing of request/response bodies, Wasm plugins can easily customize the handling of streaming protocols such as SSE (Server-Sent Events).

  In high-bandwidth scenarios such as AI businesses, it can significantly reduce memory overhead.
    
- **Easy to Extend**
  
  Provides a rich official plugin library covering AI, traffic management, security protection and other common functions, meeting more than 90% of business scenario requirements.

  Focuses on Wasm plugin extensions, ensuring memory safety through sandbox isolation, supporting multiple programming languages, allowing plugin versions to be upgraded independently, and achieving traffic-lossless hot updates of gateway logic.

- **Secure and Easy to Use**
  
  Based on Ingress API and Gateway API standards, provides out-of-the-box UI console, WAF protection plugin, IP/Cookie CC protection plugin ready to use.

  Supports connecting to Let&#039;s Encrypt for automatic issuance and renewal of free certificates, and can be deployed outside of K8s, started with a single Docker command, convenient for individual developers to use.

## Community

Join our Discord community! This is where you can connect with developers and other enthusiastic users of Higress.

[![discord](https://img.shields.io/discord/1364956090566971515?color=5865F2&amp;label=discord&amp;labelColor=black&amp;logo=discord&amp;logoColor=white&amp;style=for-the-badge)](https://discord.gg/tSbww9VDaM)


### Thanks

Higress would not be possible without the valuable open-source work of projects in the community. We would like to extend a special thank you to Envoy and Istio.

### Related Repositories

- Higress Console: https://github.com/higress-group/higress-console
- Higress Standalone: https://github.com/higress-group/higress-standalone

### Contributors

&lt;a href=&quot;https://github.com/alibaba/higress/graphs/contributors&quot;&gt;
  &lt;img alt=&quot;contributors&quot; src=&quot;https://contrib.rocks/image?repo=alibaba/higress&quot;/&gt;
&lt;/a&gt;

### Star History

[![Star History Chart](https://api.star-history.com/svg?repos=alibaba/higress&amp;type=Date)](https://star-history.com/#alibaba/higress&amp;Date)

&lt;p align=&quot;right&quot; style=&quot;font-size: 14px; color: #555; margin-top: 20px;&quot;&gt;
    &lt;a href=&quot;#readme-top&quot; style=&quot;text-decoration: none; color: #007bff; font-weight: bold;&quot;&gt;
        ‚Üë Back to Top ‚Üë
    &lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>