<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Thu, 29 Jan 2026 00:06:26 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[hashicorp/vault]]></title>
            <link>https://github.com/hashicorp/vault</link>
            <guid>https://github.com/hashicorp/vault</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:26 GMT</pubDate>
            <description><![CDATA[A tool for secrets management, encryption as a service, and privileged access management]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hashicorp/vault">hashicorp/vault</a></h1>
            <p>A tool for secrets management, encryption as a service, and privileged access management</p>
            <p>Language: Go</p>
            <p>Stars: 34,370</p>
            <p>Forks: 4,540</p>
            <p>Stars today: 352 stars today</p>
            <h2>README</h2><pre># Vault [![build](https://github.com/hashicorp/vault/actions/workflows/build.yml/badge.svg)](https://github.com/hashicorp/vault/actions/workflows/build.yml) [![ci](https://github.com/hashicorp/vault/actions/workflows/ci.yml/badge.svg)](https://github.com/hashicorp/vault/actions/workflows/ci.yml)  [![vault enterprise](https://img.shields.io/badge/vault-enterprise-yellow.svg?colorB=7c8797&amp;colorA=000000)](https://www.hashicorp.com/products/vault/?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=github-vault-enterprise)

----

**Please note**: We take Vault&#039;s security and our users&#039; trust very seriously. If you believe you have found a security issue in Vault, _please responsibly disclose_ by contacting us at [security@hashicorp.com](mailto:security@hashicorp.com).

----

- Website: [developer.hashicorp.com/vault](https://developer.hashicorp.com/vault)
- Announcement list: [Google Groups](https://groups.google.com/group/hashicorp-announce)
- Discussion forum: [Discuss](https://discuss.hashicorp.com/c/vault)
- Documentation: [https://developer.hashicorp.com/vault/docs](https://developer.hashicorp.com/vault/docs)
- Tutorials: [https://developer.hashicorp.com/vault/tutorials](https://developer.hashicorp.com/vault/tutorials)
- Certification exam: [https://developer.hashicorp.com/certifications/security-automation](https://developer.hashicorp.com/certifications/security-automation)
- Documentation source: [https://github.com/hashicorp/web-unified-docs](https://github.com/hashicorp/web-unified-docs)

&lt;img width=&quot;300&quot; alt=&quot;Vault Logo&quot; src=&quot;https://github.com/hashicorp/vault/blob/f22d202cde2018f9455dec755118a9b84586e082/Vault_PrimaryLogo_Black.png&quot;&gt;

Vault is a tool for securely accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, and more. Vault provides a unified interface to any secret, while providing tight access control and recording a detailed audit log.

A modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where Vault steps in.

The key features of Vault are:

* **Secure Secret Storage**: Vault can store arbitrary key/value pairs. Vault encrypts data before writing it to persistent
  storage, so gaining access to the raw storage isn&#039;t enough to access
  your secrets. Vault can write to disk, [Consul](https://www.consul.io),
  and more.

* **Dynamic Secrets**: Vault can generate secrets on-demand for some
  systems, such as AWS or SQL databases. For example, when an application
  needs to access an S3 bucket, it asks Vault for credentials, and Vault
  will generate an AWS keypair with valid permissions on demand. After
  creating these dynamic secrets, Vault will also automatically revoke them
  after the lease is up.

* **Data Encryption**: Vault can encrypt and decrypt data without storing
  it. This allows security teams to define encryption parameters and
  developers to store encrypted data in a location such as a SQL database without
  having to design their own encryption methods.

* **Leasing and Renewal**: Vault associates a **lease** with each secret.
  At the end of the lease, Vault automatically revokes the
  secret. Clients are able to renew leases via built-in renew APIs.

* **Revocation**: Vault has built-in support for secret revocation. Vault
  can revoke not only single secrets, but a tree of secrets, for example,
  all secrets read by a specific user, or all secrets of a particular type.
  Revocation assists in key rolling as well as locking down systems in the
  case of an intrusion.

Documentation, Getting Started, and Certification Exams
-------------------------------

Documentation is available on the [Vault website](https://developer.hashicorp.com/vault/docs).

If you&#039;re new to Vault and want to get started with security automation, please
check out our [Getting Started guides](https://learn.hashicorp.com/collections/vault/getting-started)
on HashiCorp&#039;s learning platform. There are also [additional guides](https://learn.hashicorp.com/vault)
to continue your learning.

For examples of how to interact with Vault from inside your application in different programming languages, see the [vault-examples](https://github.com/hashicorp/vault-examples) repo. An out-of-the-box [sample application](https://github.com/hashicorp/hello-vault-go) is also available.

Show off your Vault knowledge by passing a certification exam. Visit the
[certification page](https://www.hashicorp.com/certification/#hashicorp-certified-vault-associate)
for information about exams and find [study materials](https://learn.hashicorp.com/collections/vault/certification)
on HashiCorp&#039;s learning platform.

Developing Vault
--------------------

If you wish to work on Vault itself or any of its built-in systems, you&#039;ll
first need [Go](https://www.golang.org) installed on your machine.

For local dev first make sure Go is properly installed, including setting up a
[GOPATH](https://golang.org/doc/code.html#GOPATH), then setting the 
[GOBIN](https://pkg.go.dev/cmd/go#hdr-Environment_variables) variable to `$GOPATH/bin`. 
Ensure that `$GOPATH/bin` is in your path as some distributions bundle the old version 
of build tools. 

Next, clone this repository. Vault uses [Go Modules](https://github.com/golang/go/wiki/Modules),
so it is recommended that you clone the repository ***outside*** of the GOPATH.
You can then download any required build tools by bootstrapping your environment:

```sh
$ make bootstrap
...
```

To compile a development version of Vault, run `make` or `make dev`. This will
put the Vault binary in the `bin` and `$GOPATH/bin` folders:

```sh
$ make dev
...
$ bin/vault
...
```

To compile a development version of Vault with the UI, run `make static-dist dev-ui`. This will
put the Vault binary in the `bin` and `$GOPATH/bin` folders:

```sh
$ make static-dist dev-ui
...
$ bin/vault
...
```

To run tests, type `make test`. Note: this requires Docker to be installed. If
this exits with exit status 0, then everything is working!

```sh
$ make test
...
```

If you&#039;re developing a specific package, you can run tests for just that
package by specifying the `TEST` variable. For example below, only
`vault` package tests will be run.

```sh
$ make test TEST=./vault
...
```

### Troubleshooting

If you encounter an error like `could not read Username for &#039;https://github.com&#039;` you may need to adjust your git config like so:

```sh
$ git config --global --add url.&quot;git@github.com:&quot;.insteadOf &quot;https://github.com/&quot;
```


### Importing Vault

This repository publishes two libraries that may be imported by other projects:
`github.com/hashicorp/vault/api` and `github.com/hashicorp/vault/sdk`.

Note that this repository also contains Vault (the product), and as with most Go
projects, Vault uses Go modules to manage its dependencies. The mechanism to do
that is the [go.mod](./go.mod) file. As it happens, the presence of that file
also makes it theoretically possible to import Vault as a dependency into other
projects. Some other projects have made a practice of doing so in order to take
advantage of testing tooling that was developed for testing Vault itself. This
is not, and has never been, a supported way to use the Vault project. We aren&#039;t 
likely to fix bugs relating to failure to import `github.com/hashicorp/vault` 
into your project.

See also the section &quot;Docker-based tests&quot; below.

### Acceptance Tests

Vault has comprehensive [acceptance tests](https://en.wikipedia.org/wiki/Acceptance_testing)
covering most of the features of the secret and auth methods.

If you&#039;re working on a feature of a secret or auth method and want to
verify it is functioning (and also hasn&#039;t broken anything else), we recommend
running the acceptance tests.

**Warning:** The acceptance tests create/destroy/modify *real resources*, which
may incur real costs in some cases. In the presence of a bug, it is technically
possible that broken backends could leave dangling data behind. Therefore,
please run the acceptance tests at your own risk. At the very least,
we recommend running them in their own private account for whatever backend
you&#039;re testing.

To run the acceptance tests, invoke `make testacc`:

```sh
$ make testacc TEST=./builtin/logical/consul
...
```

The `TEST` variable is required, and you should specify the folder where the
backend is. The `TESTARGS` variable is recommended to filter down to a specific
resource to test, since testing all of them at once can sometimes take a very
long time.

Acceptance tests typically require other environment variables to be set for
things such as access keys. The test itself should error early and tell
you what to set, so it is not documented here.

For more information on Vault Enterprise features, visit the [Vault Enterprise site](https://www.hashicorp.com/products/vault/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=github-vault-enterprise).

### Docker-based Tests

We have created an experimental new testing mechanism inspired by NewTestCluster.
An example of how to use it:

```go
import (
  &quot;testing&quot;
  &quot;github.com/hashicorp/vault/sdk/helper/testcluster/docker&quot;
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;docker.DockerClusterOptions{
    ImageRepo: &quot;hashicorp/vault&quot;, // or &quot;hashicorp/vault-enterprise&quot;
    ImageTag:    &quot;latest&quot;,
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
  
  client := cluster.Nodes()[0].APIClient()
  _, err := client.Logical().Read(&quot;sys/storage/raft/configuration&quot;)
  if err != nil {
    t.Fatal(err)
  }
}
```

Or for Enterprise:

```go
import (
  &quot;testing&quot;
  &quot;github.com/hashicorp/vault/sdk/helper/testcluster/docker&quot;
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;docker.DockerClusterOptions{
    ImageRepo: &quot;hashicorp/vault-enterprise&quot;,
    ImageTag:  &quot;latest&quot;,
	VaultLicense: licenseString, // not a path, the actual license bytes
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
```

Here is a more realistic example of how we use it in practice.  DefaultOptions uses 
`hashicorp/vault`:`latest` as the repo and tag, but it also looks at the environment
variable VAULT_BINARY. If populated, it will copy the local file referenced by
VAULT_BINARY into the container. This is useful when testing local changes.

Instead of setting the VaultLicense option, you can set the VAULT_LICENSE_CI environment
variable, which is better than committing a license to version control.

Optionally you can set COMMIT_SHA, which will be appended to the image name we
build as a debugging convenience.

```go
func Test_Custom_Build_With_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
```

There are a variety of helpers in the `github.com/hashicorp/vault/sdk/helper/testcluster`
package, e.g. these tests below will create a pair of 3-node clusters and link them using
PR or DR replication respectively, and fail if the replication state doesn&#039;t become healthy
before the passed context expires.

Again, as written, these depend on having a Vault Enterprise binary locally and the env
var VAULT_BINARY set to point to it, as well as having VAULT_LICENSE_CI set.

```go
func TestStandardPerfReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
      t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardPerfReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}

func TestStandardDRReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
    t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardDRReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}
```

Finally, here&#039;s an example of running an existing OSS docker test with a custom binary:

```bash
$ GOOS=linux make dev
$ VAULT_BINARY=$(pwd)/bin/vault go test -run &#039;TestRaft_Configuration_Docker&#039; ./vault/external_tests/raft/raft_binary
ok      github.com/hashicorp/vault/vault/external_tests/raft/raft_binary        20.960s
```
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes/ingress-nginx]]></title>
            <link>https://github.com/kubernetes/ingress-nginx</link>
            <guid>https://github.com/kubernetes/ingress-nginx</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:25 GMT</pubDate>
            <description><![CDATA[Ingress NGINX Controller for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes/ingress-nginx">kubernetes/ingress-nginx</a></h1>
            <p>Ingress NGINX Controller for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 19,347</p>
            <p>Forks: 8,512</p>
            <p>Stars today: 29 stars today</p>
            <h2>README</h2><pre># Ingress NGINX Retirement

## Retiring

[What You Need to Know about Ingress NGINX Retirement](https://www.kubernetes.io/blog/2025/11/11/ingress-nginx-retirement/):

* Best-effort maintenance will continue until March 2026.
* Afterward, there will be no further releases, no bugfixes, and no updates to resolve any security vulnerabilities that may be discovered.
* Existing deployments of Ingress NGINX will not be broken.
  * Existing project artifacts such as Helm charts and container images will remain available.

# Ingress NGINX Controller

[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5691/badge)](https://bestpractices.coreinfrastructure.org/projects/5691)
[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/ingress-nginx)](https://goreportcard.com/report/github.com/kubernetes/ingress-nginx)
[![GitHub license](https://img.shields.io/github/license/kubernetes/ingress-nginx.svg)](https://github.com/kubernetes/ingress-nginx/blob/main/LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/kubernetes/ingress-nginx.svg)](https://github.com/kubernetes/ingress-nginx/stargazers)

## Overview

ingress-nginx was an Ingress controller for Kubernetes using [NGINX](https://www.nginx.org/) as a reverse proxy and load
balancer.

[Learn more about Ingress on the Kubernetes documentation site](https://kubernetes.io/docs/concepts/services-networking/ingress/).

## Usage warnings

If you are not already using ingress-nginx, you should not be deploying it as it is [not being developed](#retiring). Instead you should identify a [Gateway API](https://gateway-api.sigs.k8s.io/guides/) implementation and use it.

Do not use in multi-tenant Kubernetes production installations. This project assumes that users that can create Ingress objects are administrators of the cluster. See the [FAQ](https://kubernetes.github.io/ingress-nginx/faq/#faq) for more.

## Troubleshooting

If you encounter issues, review the [troubleshooting docs](docs/troubleshooting.md),
[search for an issue](https://github.com/kubernetes/ingress-nginx/issues), or talk to us on the
[#ingress-nginx-users channel](https://kubernetes.slack.com/messages/ingress-nginx-users) on the Kubernetes Slack server.

## Changelog

See [the list of releases](https://github.com/kubernetes/ingress-nginx/releases) for all changes.
For detailed changes for each release, please check the [changelog-$version.md](./changelog) file for the release version.
For detailed changes on the `ingress-nginx` helm chart, please check the changelog folder for a specific version.
[CHANGELOG-$current-version.md](./charts/ingress-nginx/changelog) file.

### Supported Versions table

Supported versions for the ingress-nginx project mean that we have completed E2E tests, and they are passing for
the versions listed. Ingress-Nginx versions **may** work on older versions, but the project does not make that guarantee.

| Supported | Ingress-NGINX version | k8s supported version         | Alpine Version | Nginx Version | Helm Chart Version |
| :-------: | --------------------- | ----------------------------- | -------------- | ------------- | ------------------ |
|    üîÑ     | **v1.14.2**           | 1.34, 1.33, 1.32, 1.31, 1.30  | 3.23.2         | 1.27.1        | 4.14.2             |
|    üîÑ     | **v1.14.1**           | 1.34, 1.33, 1.32, 1.31, 1.30  | 3.22.2         | 1.27.1        | 4.14.1             |
|    üîÑ     | **v1.14.0**           | 1.34, 1.33, 1.32, 1.31, 1.30  | 3.22.2         | 1.27.1        | 4.14.0             |
|    üîÑ     | **v1.13.6**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.23.2         | 1.27.1        | 4.13.6             |
|    üîÑ     | **v1.13.5**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.22.2         | 1.27.1        | 4.13.5             |
|    üîÑ     | **v1.13.4**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.22.2         | 1.27.1        | 4.13.4             |
|    üîÑ     | **v1.13.3**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.22.1         | 1.27.1        | 4.13.3             |
|    üîÑ     | **v1.13.2**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.22.1         | 1.27.1        | 4.13.2             |
|    üîÑ     | **v1.13.1**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.22.1         | 1.27.1        | 4.13.1             |
|    üîÑ     | **v1.13.0**           | 1.33, 1.32, 1.31, 1.30, 1.29  | 3.22.0         | 1.27.1        | 4.13.0             |
|           | v1.12.8               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.22.2         | 1.25.5        | 4.12.8             |
|           | v1.12.7               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.22.1         | 1.25.5        | 4.12.7             |
|           | v1.12.6               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.22.1         | 1.25.5        | 4.12.6             |
|           | v1.12.5               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.22.1         | 1.25.5        | 4.12.5             |
|           | v1.12.4               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.22.0         | 1.25.5        | 4.12.4             |
|           | v1.12.3               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.21.3         | 1.25.5        | 4.12.3             |
|           | v1.12.2               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.21.3         | 1.25.5        | 4.12.2             |
|           | v1.12.1               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.21.3         | 1.25.5        | 4.12.1             |
|           | v1.12.0               | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.21.0         | 1.25.5        | 4.12.0             |
|           | v1.12.0-beta.0        | 1.32, 1.31, 1.30, 1.29, 1.28  | 3.20.3         | 1.25.5        | 4.12.0-beta.0      |
|           | v1.11.8               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.22.0         | 1.25.5        | 4.11.8             |
|           | v1.11.7               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.3         | 1.25.5        | 4.11.7             |
|           | v1.11.6               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.3         | 1.25.5        | 4.11.6             |
|           | v1.11.5               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.3         | 1.25.5        | 4.11.5             |
|           | v1.11.4               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.0         | 1.25.5        | 4.11.4             |
|           | v1.11.3               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.3         | 1.25.5        | 4.11.3             |
|           | v1.11.2               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.11.2             |
|           | v1.11.1               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.11.1             |
|           | v1.11.0               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.11.0             |
|           | v1.10.6               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.0         | 1.25.5        | 4.10.6             |
|           | v1.10.5               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.3         | 1.25.5        | 4.10.5             |
|           | v1.10.4               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.10.4             |
|           | v1.10.3               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.10.3             |
|           | v1.10.2               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.10.2             |
|           | v1.10.1               | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.19.1         | 1.25.3        | 4.10.1             |
|           | v1.10.0               | 1.29, 1.28, 1.27, 1.26        | 3.19.1         | 1.25.3        | 4.10.0             |
|           | v1.9.6                | 1.29, 1.28, 1.27, 1.26, 1.25  | 3.19.0         | 1.21.6        | 4.9.1              |
|           | v1.9.5                | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.9.0              |
|           | v1.9.4                | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.8.3              |
|           | v1.9.3                | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.8.*              |
|           | v1.9.1                | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.8.*              |
|           | v1.9.0                | 1.28, 1.27, 1.26, 1.25        | 3.18.2         | 1.21.6        | 4.8.*              |
|           | v1.8.4                | 1.27, 1.26, 1.25, 1.24        | 3.18.2         | 1.21.6        | 4.7.*              |
|           | v1.7.1                | 1.27, 1.26, 1.25, 1.24        | 3.17.2         | 1.21.6        | 4.6.*              |
|           | v1.6.4                | 1.26, 1.25, 1.24, 1.23        | 3.17.0         | 1.21.6        | 4.5.*              |
|           | v1.5.1                | 1.25, 1.24, 1.23              | 3.16.2         | 1.21.6        | 4.4.*              |
|           | v1.4.0                | 1.25, 1.24, 1.23, 1.22        | 3.16.2         | 1.19.10‚Ä†      | 4.3.0              |
|           | v1.3.1                | 1.24, 1.23, 1.22, 1.21, 1.20  | 3.16.2         | 1.19.10‚Ä†      | 4.2.5              |

See [Updating NGINX-Ingress to use the stable Ingress API (July 26, 2021)](https://kubernetes.io/blog/2021/07/26/update-with-ingress-nginx/)
to upgrade to the stable Ingress API before upgrading to Kubernetes 1.22.

## Get Involved

Thanks for taking the time to join our community and start contributing!

- This project adheres to the [Kubernetes Community Code of Conduct](https://git.k8s.io/community/code-of-conduct.md).
  By participating in this project, you agree to abide by its terms.
- **Contributing**: Documentation contributions are welcome.

  - Read [`CONTRIBUTING.md`](CONTRIBUTING.md) for information about the workflow that we
    expect and instructions on the developer certificate of origin that we require.
  - Join our Kubernetes Slack channel for developer discussion : [#ingress-nginx-dev](https://kubernetes.slack.com/archives/C021E147ZA4).
  - Submit GitHub issues for documentation problems.
    - Please make sure to read the [Issue Reporting Checklist](https://github.com/kubernetes/ingress-nginx/blob/main/CONTRIBUTING.md#issue-reporting-guidelines) before opening an issue. Issues not conforming to the guidelines **may be closed immediately**.

- **Support**:

  - Join the [#ingress-nginx-users](https://kubernetes.slack.com/messages/CANQGM8BA/) channel inside the [Kubernetes Slack](http://slack.kubernetes.io/) to ask questions or get support from the maintainers and other users.
  - The [GitHub issues](https://github.com/kubernetes/ingress-nginx/issues) in the repository are **exclusively** for bug reports and feature requests.

## License

[Apache License 2.0](https://github.com/kubernetes/ingress-nginx/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Tencent/WeKnora]]></title>
            <link>https://github.com/Tencent/WeKnora</link>
            <guid>https://github.com/Tencent/WeKnora</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:24 GMT</pubDate>
            <description><![CDATA[LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Tencent/WeKnora">Tencent/WeKnora</a></h1>
            <p>LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.</p>
            <p>Language: Go</p>
            <p>Stars: 12,586</p>
            <p>Forks: 1,417</p>
            <p>Stars today: 51 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;img src=&quot;./docs/images/logo.png&quot; alt=&quot;WeKnora Logo&quot; height=&quot;120&quot;/&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/15289&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://trendshift.io/api/badge/repositories/15289&quot; alt=&quot;Tencent%2FWeKnora | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
    &lt;/a&gt;
  &lt;/picture&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://weknora.weixin.qq.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;ÂÆòÊñπÁΩëÁ´ô&quot; src=&quot;https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://chatbot.weixin.qq.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞&quot; src=&quot;https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/Tencent/WeKnora/blob/main/LICENSE&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;License&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;./CHANGELOG.md&quot;&gt;
        &lt;img alt=&quot;Version&quot; src=&quot;https://img.shields.io/badge/version-0.2.10-2e6cc4?labelColor=d4eaf7&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
| &lt;b&gt;English&lt;/b&gt; | &lt;a href=&quot;./README_CN.md&quot;&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;./README_JA.md&quot;&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; |
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;h4 align=&quot;center&quot;&gt;

  [Overview](#-overview) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [Key Features](#-key-features) ‚Ä¢ [Getting Started](#-getting-started) ‚Ä¢ [API Reference](#-api-reference) ‚Ä¢ [Developer Guide](#-developer-guide)
  
  &lt;/h4&gt;
&lt;/p&gt;

# üí° WeKnora - LLM-Powered Document Understanding &amp; Retrieval Framework

## üìå Overview

[**WeKnora**](https://weknora.weixin.qq.com) is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents. 

It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the **RAG (Retrieval-Augmented Generation)** paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.

**Website:** https://weknora.weixin.qq.com

## ‚ú® Latest Updates

**v0.2.0 Highlights:**

- ü§ñ **Agent Mode**: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection
- üìö **Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry
- ‚öôÔ∏è **Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior
- üåê **Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine
- üîå **MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods
- üé® **New UI**: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade
- ‚ö° **Infrastructure Upgrade**: Introduced MQ async task management, support for automatic database migration, and fast development mode

## üîí Security Notice

**Important:** Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:

- Deploy WeKnora services in internal/private network environments rather than public internet
- Avoid exposing the service directly to public networks to prevent potential information leakage
- Configure proper firewall rules and access controls for your deployment environment
- Regularly update to the latest version for security patches and improvements

## üèóÔ∏è Architecture

![weknora-architecture.png](./docs/images/architecture.png)

WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.

## üéØ Key Features

- **ü§ñ Agent Mode**: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection
- **üîç Precise Understanding**: Structured content extraction from PDFs, Word documents, images and more into unified semantic views
- **üß† Intelligent Reasoning**: Leverages LLMs to understand document context and user intent for accurate Q&amp;A and multi-turn conversations
- **üìö Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities
- **üîß Flexible Extension**: All components from parsing and embedding to retrieval and generation are decoupled for easy customization
- **‚ö° Efficient Retrieval**: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support
- **üåê Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine
- **üîå MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods
- **‚öôÔ∏è Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior
- **üéØ User-Friendly**: Intuitive web interface and standardized APIs for zero technical barriers
- **üîí Secure &amp; Controlled**: Support for local deployment and private cloud, ensuring complete data sovereignty

## üìä Application Scenarios

| Scenario | Applications | Core Value |
|---------|----------|----------|
| **Enterprise Knowledge Management** | Internal document retrieval, policy Q&amp;A, operation manual search | Improve knowledge discovery efficiency, reduce training costs |
| **Academic Research Analysis** | Paper retrieval, research report analysis, scholarly material organization | Accelerate literature review, assist research decisions |
| **Product Technical Support** | Product manual Q&amp;A, technical documentation search, troubleshooting | Enhance customer service quality, reduce support burden |
| **Legal &amp; Compliance Review** | Contract clause retrieval, regulatory policy search, case analysis | Improve compliance efficiency, reduce legal risks |
| **Medical Knowledge Assistance** | Medical literature retrieval, treatment guideline search, case analysis | Support clinical decisions, improve diagnosis quality |

## üß© Feature Matrix

| Module | Support                                                                        | Description                                                                                                                                                        |
|---------|--------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Agent Mode | ‚úÖ ReACT Agent Mode                                                             | Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations               |
| Knowledge Base Types | ‚úÖ FAQ / Document                                                               | Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry                                       |
| Document Formats | ‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)                    | Support for structured and unstructured documents with text extraction from images                                                                                 |
| Model Management | ‚úÖ Centralized configuration, built-in model sharing                            | Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models                                   |
| Embedding Models | ‚úÖ Local models, BGE / GTE APIs, etc.                                           | Customizable embedding models, compatible with local deployment and cloud vector generation APIs                                                                   |
| Vector DB Integration | ‚úÖ PostgreSQL (pgvector), Elasticsearch                                         | Support for mainstream vector index backends, flexible switching for different retrieval scenarios                                                                 |
| Retrieval Strategies | ‚úÖ BM25 / Dense Retrieval / GraphRAG                                            | Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines                                        |
| LLM Integration | ‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching  | Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration                                                     |
| Conversation Strategy | ‚úÖ Agent models, normal mode models, retrieval thresholds, Prompt configuration | Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior |
| Web Search | ‚úÖ Extensible search engines, DuckDuckGo / Google                               | Support for extensible web search engines with built-in DuckDuckGo search engine                                                                                   |
| MCP Tools | ‚úÖ uvx, npx launchers, Stdio/HTTP Streamable/SSE                                | Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods                                      |
| QA Capabilities | ‚úÖ Context-aware, multi-turn dialogue, prompt templates                         | Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;A with configurable prompts and context windows                                  |
| E2E Testing | ‚úÖ Retrieval+generation process visualization and metric evaluation             | End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics                                                            |
| Deployment Modes | ‚úÖ Support for local deployment / Docker images                                 | Meets private, offline deployment and flexible operation requirements, with fast development mode support                                                          |
| User Interfaces | ‚úÖ Web UI + RESTful API                                                         | Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display                                              |
| Task Management | ‚úÖ MQ async tasks, automatic database migration                                 | MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades                                            |

## üöÄ Getting Started

### üõ† Prerequisites

Make sure the following tools are installed on your system:

* [Docker](https://www.docker.com/)
* [Docker Compose](https://docs.docker.com/compose/)
* [Git](https://git-scm.com/)

### üì¶ Installation

#### ‚ë† Clone the repository

```bash
# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
```

#### ‚ë° Configure environment variables

```bash
# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
```

#### ‚ë¢ Start the services (include Ollama)

Check the images that need to be started in the .env file.

```bash
./scripts/start_all.sh
```

or

```bash
make start-all
```

#### ‚ë¢.0 Start ollama services (Optional)

```bash
ollama serve &gt; /dev/null 2&gt;&amp;1 &amp;
```

#### ‚ë¢.1 Activate different combinations of features

- Minimum core services
```bash
docker compose up -d
```

- All features enabled
```bash
docker-compose --profile full up -d
```

- Tracing logs required
```bash
docker-compose --profile jaeger up -d
```

- Neo4j knowledge graph required
```bash
docker-compose --profile neo4j up -d
```

- Minio file storage service required
```bash
docker-compose --profile minio up -d
```

- Multiple options combination
```bash
docker-compose --profile neo4j --profile minio up -d
```

#### ‚ë£ Stop the services

```bash
./scripts/start_all.sh --stop
# Or
make stop-all
```

### üåê Access Services

Once started, services will be available at:

* Web UI: `http://localhost`
* Backend API: `http://localhost:8080`
* Jaeger Tracing: `http://localhost:16686`

### üîå Using WeChat Dialog Open Platform

WeKnora serves as the core technology framework for the [WeChat Dialog Open Platform](https://chatbot.weixin.qq.com), providing a more convenient usage approach:

- **Zero-code Deployment**: Simply upload knowledge to quickly deploy intelligent Q&amp;A services within the WeChat ecosystem, achieving an &quot;ask and answer&quot; experience
- **Efficient Question Management**: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers
- **WeChat Ecosystem Integration**: Through the WeChat Dialog Open Platform, WeKnora&#039;s intelligent Q&amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences

### üîó Access WeKnora via MCP Server

#### 1Ô∏è‚É£ Clone the repository
```
git clone https://github.com/Tencent/WeKnora
```

#### 2Ô∏è‚É£ Configure MCP Server
&gt; It is recommended to directly refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for configuration.

Configure the MCP client to connect to the server:
```json
{
  &quot;mcpServers&quot;: {
    &quot;weknora&quot;: {
      &quot;args&quot;: [
        &quot;path/to/WeKnora/mcp-server/run_server.py&quot;
      ],
      &quot;command&quot;: &quot;python&quot;,
      &quot;env&quot;:{
        &quot;WEKNORA_API_KEY&quot;:&quot;Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk&quot;,
        &quot;WEKNORA_BASE_URL&quot;:&quot;http(s)://your-weknora-address/api/v1&quot;
      }
    }
  }
}
```

Run directly using stdio command:
```
pip install weknora-mcp-server
python -m weknora-mcp-server
```

## üîß Initialization Configuration Guide

To help users quickly configure various models and reduce trial-and-error costs, we&#039;ve improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows:
If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.

### ‚ë† Stop the services

```bash
./scripts/start_all.sh --stop
```

### ‚ë° Clear existing data tables (recommended when no important data exists)

```bash
make clean-db
```

### ‚ë¢ Compile and start services

```bash
./scripts/start_all.sh
```

### ‚ë£ Access Web UI

http://localhost

On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.

## üì± Interface Showcase

### Web UI Interface

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/knowledgebases.png&quot; alt=&quot;Knowledge Base Management&quot;&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/settings.png&quot; alt=&quot;Conversation Settings&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td colspan=&quot;2&quot;&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/agent-qa.png&quot; alt=&quot;Agent Mode Tool Call Process&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

**Knowledge Base Management:** Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.

**Agent Mode:** Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.

**Conversation Strategy:** Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.

### Document Knowledge Graph

WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.

For detailed configuration, please refer to the [Knowledge Graph Configuration Guide](./docs/KnowledgeGraph.md).

### MCP Server

Please refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for the necessary setup.

## üìò API Reference

Troubleshooting FAQ: [Troubleshooting FAQ](./docs/QA.md)

Detailed API documentation is available at: [API Docs](./docs/api/README.md)

## üß≠ Developer Guide

### ‚ö° Fast Development Mode (Recommended)

If you need to frequently modify code, **you don&#039;t need to rebuild Docker images every time**! Use fast development mode:

```bash
# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
```

**Development Advantages:**
- ‚úÖ Frontend modifications auto hot-reload (no restart needed)
- ‚úÖ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)
- ‚úÖ No need to rebuild Docker images
- ‚úÖ Support IDE breakpoint debugging

**Detailed Documentation:** [Development Environment Quick Start](./docs/ÂºÄÂèëÊåáÂçó.md)

### üìÅ Directory Structure

```
WeKnora/
‚îú‚îÄ‚îÄ client/      # go client
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ docker/      # docker images files
‚îú‚îÄ‚îÄ docreader/   # Document parsing app
‚îú‚îÄ‚îÄ docs/        # Project documentation
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ mcp-server/  # MCP server
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îî‚îÄ‚îÄ scripts/     # Shell scripts
```

## ü§ù Contributing

We welcome community contributions! For suggestions, bugs, or feature requests, please submit an [Issue](https://github.com/Tencent/WeKnora/issues) or directly create a Pull Request.

### üéØ How to Contribute

- üêõ **Bug Fixe

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[containers/podman]]></title>
            <link>https://github.com/containers/podman</link>
            <guid>https://github.com/containers/podman</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:23 GMT</pubDate>
            <description><![CDATA[Podman: A tool for managing OCI containers and pods.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/containers/podman">containers/podman</a></h1>
            <p>Podman: A tool for managing OCI containers and pods.</p>
            <p>Language: Go</p>
            <p>Stars: 30,500</p>
            <p>Forks: 2,957</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>![PODMAN logo](https://raw.githubusercontent.com/containers/common/main/logos/podman-logo-full-vert.png)

# Podman: A tool for managing OCI containers and pods
![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)
![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/containers/podman)
[![Go Report Card](https://goreportcard.com/badge/github.com/containers/podman/v6)](https://goreportcard.com/report/github.com/containers/podman/v6)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10499/badge)](https://www.bestpractices.dev/projects/10499)

[![LFX Health Score](https://insights.linuxfoundation.org/api/badge/health-score?project=podman-container-tools&amp;repos=https://github.com/containers/podman)](https://insights.linuxfoundation.org/project/podman-container-tools/repository/containers-podman)
[![LFX Contributors](https://insights.linuxfoundation.org/api/badge/contributors?project=podman-container-tools&amp;repos=https://github.com/containers/podman)](https://insights.linuxfoundation.org/project/podman-container-tools/repository/containers-podman)


&lt;br/&gt;

Podman (the POD MANager) is a tool for managing containers and images, volumes mounted into those containers, and pods made from groups of containers.
Podman runs containers on Linux, but can also be used on Mac and Windows systems using a Podman-managed virtual machine.
Podman is based on libpod, a library for container lifecycle management that is also contained in this repository. The libpod library provides APIs for managing containers, pods, container images, and volumes.

Podman releases a new major or minor release 4 times a year, during the second week of February, May, August, and November. Patch releases are more frequent and may occur at any time to get bugfixes out to users. All releases are PGP signed. Public keys of members of the team approved to make releases are located [here](https://github.com/containers/release-keys/tree/main/podman).

* Continuous Integration:
  * [![Build Status](https://api.cirrus-ci.com/github/containers/podman.svg)](https://cirrus-ci.com/github/containers/podman/main)
  * [GoDoc: ![GoDoc](https://godoc.org/github.com/containers/podman/libpod?status.svg)](https://godoc.org/github.com/containers/podman/libpod)
  * [Downloads](DOWNLOADS.md)

## Overview and scope

At a high level, the scope of Podman and libpod is the following:

* Support for multiple container image formats, including OCI and Docker images.
* Full management of those images, including pulling from various sources (including trust and verification), creating (built via Containerfile or Dockerfile or committed from a container), and pushing to registries and other storage backends.
* Full management of container lifecycle, including creation (both from an image and from an exploded root filesystem), running, checkpointing and restoring (via CRIU), and removal.
* Full management of container networking, using Netavark.
* Support for pods, groups of containers that share resources and are managed together.
* Support for running containers and pods without root or other elevated privileges.
* Resource isolation of containers and pods.
* Support for a Docker-compatible CLI interface, which can both run containers locally and on remote systems.
* No manager daemon, for improved security and lower resource utilization at idle.
* Support for a REST API providing both a Docker-compatible interface and an improved interface exposing advanced Podman functionality.
* Support for running on Windows and Mac via virtual machines run by `podman machine`.

## Roadmap

The future of Podman feature development can be found in its **[roadmap](ROADMAP.md)**.

## Communications

If you think you&#039;ve identified a security issue in the project, please *DO NOT* report the issue publicly via the GitHub issue tracker, mailing list, or IRC.
Instead, send an email with as many details as possible to `security@lists.podman.io`. This is a private mailing list for the core maintainers.

For general questions and discussion, please use Podman&#039;s
[channels](https://podman.io/community/#slack-irc-matrix-and-discord).

For discussions around issues/bugs and features, you can use the GitHub
[issues](https://github.com/containers/podman/issues)
and
[PRs](https://github.com/containers/podman/pulls)
tracking system.

There is also a [mailing list](https://lists.podman.io/archives/) at `lists.podman.io`.
You can subscribe by sending a message to `podman-join@lists.podman.io` with the subject `subscribe`.

## Rootless
Podman can be easily run as a normal user, without requiring a setuid binary.
When run without root, Podman containers use user namespaces to set root in the container to the user running Podman.
Rootless Podman runs locked-down containers with no privileges that the user running the container does not have.
Some of these restrictions can be lifted (via `--privileged`, for example), but rootless containers will never have more privileges than the user that launched them.
If you run Podman as your user and mount in `/etc/passwd` from the host, you still won&#039;t be able to change it, since your user doesn&#039;t have permission to do so.

Almost all normal Podman functionality is available, though there are some [shortcomings](https://github.com/containers/podman/blob/main/rootless.md).
Any recent Podman release should be able to run rootless without any additional configuration, though your operating system may require some additional configuration detailed in the [install guide](https://podman.io/getting-started/installation).

A little configuration by an administrator is required before rootless Podman can be used, the necessary setup is documented [here](https://github.com/containers/podman/blob/main/docs/tutorials/rootless_tutorial.md).

## Podman Desktop

[Podman Desktop](https://podman-desktop.io/) provides a local development environment for Podman and Kubernetes on Linux, Windows, and Mac machines.
It is a full-featured desktop UI frontend for Podman which uses the `podman machine` backend on non-Linux operating systems to run containers.
It supports full container lifecycle management (building, pulling, and pushing images, creating and managing containers, creating and managing pods, and working with Kubernetes YAML).
The project develops on [GitHub](https://github.com/containers/podman-desktop) and contributions are welcome.

## Out of scope

* Specialized signing and pushing of images to various storage backends.
  See [Skopeo](https://github.com/containers/skopeo/) for those tasks.
* Support for the Kubernetes CRI interface for container management.
  The [CRI-O](https://github.com/cri-o/cri-o) daemon specializes in that.

## OCI Projects Plans

Podman uses OCI projects and best of breed libraries for different aspects:
- Runtime: We use the [OCI runtime tools](https://github.com/opencontainers/runtime-tools) to generate OCI runtime configurations that can be used with any OCI-compliant runtime, like [crun](https://github.com/containers/crun/) and [runc](https://github.com/opencontainers/runc/).
- Images: Image management uses the [containers/image](https://github.com/containers/image) library.
- Storage: Container and image storage is managed by [containers/storage](https://github.com/containers/storage).
- Networking: Networking support through use of [Netavark](https://github.com/containers/netavark) and [Aardvark](https://github.com/containers/aardvark-dns).  Rootless networking is handled via [pasta](https://passt.top/passt) or [slirp4netns](https://github.com/rootless-containers/slirp4netns).
- Builds: Builds are supported via [Buildah](https://github.com/containers/buildah).
- Conmon: [Conmon](https://github.com/containers/conmon) is a tool for monitoring OCI runtimes, used by both Podman and CRI-O.
- Seccomp: A unified [Seccomp](https://github.com/containers/common/blob/main/pkg/seccomp/seccomp.json) policy for Podman, Buildah, and CRI-O.

## Podman Information for Developers

For blogs, release announcements and more, please checkout the [podman.io](https://podman.io) website!

**[Installation notes](install.md)**
Information on how to install Podman in your environment.

**[OCI Hooks Support](https://github.com/containers/common/blob/main/pkg/hooks/README.md)**
Information on how Podman configures [OCI Hooks][spec-hooks] to run when launching a container.

**[Podman API](https://docs.podman.io/en/latest/_static/api.html)**
Documentation on the Podman REST API.

**[Podman Commands](https://podman.readthedocs.io/en/latest/Commands.html)**
A list of the Podman commands with links to their man pages and in many cases videos
showing the commands in use.

**[Podman Container Images](https://github.com/containers/image_build/blob/main/podman/README.md)**
Information on the Podman Container Images found on [quay.io](https://quay.io/podman/stable).

**[Podman Troubleshooting Guide](troubleshooting.md)**
A list of common issues and solutions for Podman.

**[Podman Usage Transfer](transfer.md)**
Useful information for ops and dev transfer as it relates to infrastructure that utilizes Podman.  This page
includes tables showing Docker commands and their Podman equivalent commands.

**[Tutorials](docs/tutorials)**
Tutorials on using Podman.

**[Remote Client](https://github.com/containers/podman/blob/main/docs/tutorials/remote_client.md)**
A brief how-to on using the Podman remote client.

**[Basic Setup and Use of Podman in a Rootless environment](https://github.com/containers/podman/blob/main/docs/tutorials/rootless_tutorial.md)**
A tutorial showing the setup and configuration necessary to run Rootless Podman.

**[Release Notes](RELEASE_NOTES.md)**
Release notes for recent Podman versions.

**[Contributing](CONTRIBUTING.md)**
Information about contributing to this project.

[spec-hooks]: https://github.com/opencontainers/runtime-spec/blob/v1.0.2/config.md#posix-platform-hooks

## Buildah and Podman relationship

Buildah and Podman are two complementary open-source projects that are
available on most Linux platforms and both projects reside at
[GitHub.com](https://github.com) with Buildah
[here](https://github.com/containers/buildah) and Podman
[here](https://github.com/containers/podman).  Both, Buildah and Podman are
command line tools that work on Open Container Initiative (OCI) images and
containers.  The two projects differentiate in their specialization.

Buildah specializes in building OCI images.  Buildah&#039;s commands replicate all
of the commands that are found in a Dockerfile.  This allows building images
with and without Dockerfiles while not requiring any root privileges.
Buildah‚Äôs ultimate goal is to provide a lower-level coreutils interface to
build images.  The flexibility of building images without Dockerfiles allows
for the integration of other scripting languages into the build process.
Buildah follows a simple fork-exec model and does not run as a daemon
but it is based on a comprehensive API in golang, which can be vendored
into other tools.

Podman specializes in all of the commands and functions that help you to maintain and modify
OCI images, such as pulling and tagging.  It also allows you to create, run, and maintain those containers
created from those images.  For building container images via Dockerfiles, Podman uses Buildah&#039;s
golang API and can be installed independently from Buildah.

A major difference between Podman and Buildah is their concept of a container.  Podman
allows users to create &quot;traditional containers&quot; where the intent of these containers is
to be long lived.  While Buildah containers are really just created to allow content
to be added back to the container image.  An easy way to think of it is the
`buildah run` command emulates the RUN command in a Dockerfile while the `podman run`
command emulates the `docker run` command in functionality.  Because of this and their underlying
storage differences, you can not see Podman containers from within Buildah or vice versa.

In short, Buildah is an efficient way to create OCI images while Podman allows
you to manage and maintain those images and containers in a production environment using
familiar container cli commands.  For more details, see the
[Container Tools Guide](https://github.com/containers/buildah/tree/main/docs/containertools).

## Podman Hello
```
$ podman run quay.io/podman/hello
Trying to pull quay.io/podman/hello:latest...
Getting image source signatures
Copying blob a6b3126f3807 done
Copying config 25c667d086 done
Writing manifest to image destination
Storing signatures
!... Hello Podman World ...!

         .--&quot;--.
       / -     - \
      / (O)   (O) \
   ~~~| -=(,Y,)=- |
    .---. /`  \   |~~
 ~/  o  o \~~~~.----. ~~
  | =(X)= |~  / (O (O) \
   ~~~~~~~  ~| =(Y_)=-  |
  ~~~~    ~~~|   U      |~~

Project:   https://github.com/containers/podman
Website:   https://podman.io
Documents: https://docs.podman.io
Twitter:   @Podman_io
```
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grpc/grpc-go]]></title>
            <link>https://github.com/grpc/grpc-go</link>
            <guid>https://github.com/grpc/grpc-go</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:22 GMT</pubDate>
            <description><![CDATA[The Go language implementation of gRPC. HTTP/2 based RPC]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grpc/grpc-go">grpc/grpc-go</a></h1>
            <p>The Go language implementation of gRPC. HTTP/2 based RPC</p>
            <p>Language: Go</p>
            <p>Stars: 22,750</p>
            <p>Forks: 4,637</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># gRPC-Go

[![GoDoc](https://pkg.go.dev/badge/google.golang.org/grpc)][API]
[![GoReportCard](https://goreportcard.com/badge/grpc/grpc-go)](https://goreportcard.com/report/github.com/grpc/grpc-go)
[![codecov](https://codecov.io/gh/grpc/grpc-go/graph/badge.svg)](https://codecov.io/gh/grpc/grpc-go)

The [Go][] implementation of [gRPC][]: A high performance, open source, general
RPC framework that puts mobile and HTTP/2 first. For more information see the
[Go gRPC docs][], or jump directly into the [quick start][].

## Prerequisites

- **[Go][]**: any one of the **two latest major** [releases][go-releases].

## Installation

Simply add the following import to your code, and then `go [build|run|test]`
will automatically fetch the necessary dependencies:


```go
import &quot;google.golang.org/grpc&quot;
```

&gt; **Note:** If you are trying to access `grpc-go` from **China**, see the
&gt; [FAQ](#FAQ) below.

## Learn more

- [Go gRPC docs][], which include a [quick start][] and [API
  reference][API] among other resources
- [Low-level technical docs](Documentation) from this repository
- [Performance benchmark][]
- [Examples](examples)
- [Contribution guidelines](CONTRIBUTING.md)

## FAQ

### I/O Timeout Errors

The `golang.org` domain may be blocked from some countries. `go get` usually
produces an error like the following when this happens:

```console
$ go get -u google.golang.org/grpc
package google.golang.org/grpc: unrecognized import path &quot;google.golang.org/grpc&quot; (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)
```

To build Go code, there are several options:

- Set up a VPN and access google.golang.org through that.

- With Go module support: it is possible to use the `replace` feature of `go
  mod` to create aliases for golang.org packages.  In your project&#039;s directory:

  ```sh
  go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest
  go mod tidy
  go mod vendor
  go build -mod=vendor
  ```

  Again, this will need to be done for all transitive dependencies hosted on
  golang.org as well. For details, refer to [golang/go issue
  #28652](https://github.com/golang/go/issues/28652).

### Compiling error, undefined: grpc.SupportPackageIsVersion

Please update to the latest version of gRPC-Go using
`go get google.golang.org/grpc`.

### How to turn on logging

The default logger is controlled by environment variables. Turn everything on
like this:

```console
$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99
$ export GRPC_GO_LOG_SEVERITY_LEVEL=info
```

### The RPC failed with error `&quot;code = Unavailable desc = transport is closing&quot;`

This error means the connection the RPC is using was closed, and there are many
possible reasons, including:
 1. mis-configured transport credentials, connection failed on handshaking
 1. bytes disrupted, possibly by a proxy in between
 1. server shutdown
 1. Keepalive parameters caused connection shutdown, for example if you have
    configured your server to terminate connections regularly to [trigger DNS
    lookups](https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779).
    If this is the case, you may want to increase your
    [MaxConnectionAgeGrace](https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters),
    to allow longer RPC calls to finish.

It can be tricky to debug this because the error happens on the client side but
the root cause of the connection being closed is on the server side. Turn on
logging on __both client and server__, and see if there are any transport
errors.

[API]: https://pkg.go.dev/google.golang.org/grpc
[Go]: https://golang.org
[Go module]: https://github.com/golang/go/wiki/Modules
[gRPC]: https://grpc.io
[Go gRPC docs]: https://grpc.io/docs/languages/go
[Performance benchmark]: https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608
[quick start]: https://grpc.io/docs/languages/go/quickstart
[go-releases]: https://golang.org/doc/devel/release.html
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[navidrome/navidrome]]></title>
            <link>https://github.com/navidrome/navidrome</link>
            <guid>https://github.com/navidrome/navidrome</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:21 GMT</pubDate>
            <description><![CDATA[üéß‚òÅÔ∏è Your Personal Streaming Service]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/navidrome/navidrome">navidrome/navidrome</a></h1>
            <p>üéß‚òÅÔ∏è Your Personal Streaming Service</p>
            <p>Language: Go</p>
            <p>Stars: 18,865</p>
            <p>Forks: 1,346</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://www.navidrome.org&quot;&gt;&lt;img src=&quot;resources/logo-192x192.png&quot; alt=&quot;Navidrome logo&quot; title=&quot;navidrome&quot; align=&quot;right&quot; height=&quot;60px&quot; /&gt;&lt;/a&gt;

# Navidrome Music Server &amp;nbsp;[![Tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=Tired%20of%20paying%20for%20music%20subscriptions%2C%20and%20not%20finding%20what%20you%20really%20like%3F%20Roll%20your%20own%20streaming%20service%21&amp;url=https://navidrome.org&amp;via=navidrome)

[![Last Release](https://img.shields.io/github/v/release/navidrome/navidrome?logo=github&amp;label=latest&amp;style=flat-square)](https://github.com/navidrome/navidrome/releases)
[![Build](https://img.shields.io/github/actions/workflow/status/navidrome/navidrome/pipeline.yml?branch=master&amp;logo=github&amp;style=flat-square)](https://nightly.link/navidrome/navidrome/workflows/pipeline/master)
[![Downloads](https://img.shields.io/github/downloads/navidrome/navidrome/total?logo=github&amp;style=flat-square)](https://github.com/navidrome/navidrome/releases/latest)
[![Docker Pulls](https://img.shields.io/docker/pulls/deluan/navidrome?logo=docker&amp;label=pulls&amp;style=flat-square)](https://hub.docker.com/r/deluan/navidrome)
[![Dev Chat](https://img.shields.io/discord/671335427726114836?logo=discord&amp;label=discord&amp;style=flat-square)](https://discord.gg/xh7j7yF)
[![Subreddit](https://img.shields.io/reddit/subreddit-subscribers/navidrome?logo=reddit&amp;label=/r/navidrome&amp;style=flat-square)](https://www.reddit.com/r/navidrome/)
[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v2.0-ff69b4.svg?style=flat-square)](CODE_OF_CONDUCT.md)
[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Navidrome%20Guru-006BFF?style=flat-square)](https://gurubase.io/g/navidrome)

Navidrome is an open source web-based music collection server and streamer. It gives you freedom to listen to your
music collection from any browser or mobile device. It&#039;s like your personal Spotify!


**Note**: The `master` branch may be in an unstable or even broken state during development. 
Please use [releases](https://github.com/navidrome/navidrome/releases) instead of 
the `master` branch in order to get a stable set of binaries.

## [Check out our Live Demo!](https://www.navidrome.org/demo/)

__Any feedback is welcome!__ If you need/want a new feature, find a bug or think of any way to improve Navidrome, 
please file a [GitHub issue](https://github.com/navidrome/navidrome/issues) or join the discussion in our 
[Subreddit](https://www.reddit.com/r/navidrome/). If you want to contribute to the project in any other way 
([ui/backend dev](https://www.navidrome.org/docs/developers/), 
[translations](https://www.navidrome.org/docs/developers/translations/), 
[themes](https://www.navidrome.org/docs/developers/creating-themes)), please join the chat in our 
[Discord server](https://discord.gg/xh7j7yF). 

## Installation

See instructions on the [project&#039;s website](https://www.navidrome.org/docs/installation/)

## Cloud Hosting

[PikaPods](https://www.pikapods.com) has partnered with us to offer you an 
[officially supported, cloud-hosted solution](https://www.navidrome.org/docs/installation/managed/#pikapods). 
A share of the revenue helps fund the development of Navidrome at no additional cost for you.

[![PikaPods](https://www.pikapods.com/static/run-button.svg)](https://www.pikapods.com/pods?run=navidrome)

## Features
 
 - Handles very **large music collections**
 - Streams virtually **any audio format** available
 - Reads and uses all your beautifully curated **metadata**
 - Great support for **compilations** (Various Artists albums) and **box sets** (multi-disc albums)
 - **Multi-user**, each user has their own play counts, playlists, favourites, etc...
 - Very **low resource usage**
 - **Multi-platform**, runs on macOS, Linux and Windows. **Docker** images are also provided
 - Ready to use binaries for all major platforms, including **Raspberry Pi**
 - Automatically **monitors your library** for changes, importing new files and reloading new metadata 
 - **Themeable**, modern and responsive **Web interface** based on [Material UI](https://material-ui.com)
 - **Compatible** with all Subsonic/Madsonic/Airsonic [clients](https://www.navidrome.org/docs/overview/#apps)
 - **Transcoding** on the fly. Can be set per user/player. **Opus encoding is supported**
 - Translated to **various languages**

## Translations

Navidrome uses [POEditor](https://poeditor.com/) for translations, and we are always looking 
for [more contributors](https://www.navidrome.org/docs/developers/translations/)

&lt;a href=&quot;https://poeditor.com/&quot;&gt; 
&lt;img height=&quot;32&quot; src=&quot;https://github.com/user-attachments/assets/c19b1d2b-01e1-4682-a007-12356c42147c&quot;&gt;
&lt;/a&gt;

## Documentation
All documentation can be found in the project&#039;s website: https://www.navidrome.org/docs. 
Here are some useful direct links:

- [Overview](https://www.navidrome.org/docs/overview/)
- [Installation](https://www.navidrome.org/docs/installation/)
  - [Docker](https://www.navidrome.org/docs/installation/docker/)
  - [Binaries](https://www.navidrome.org/docs/installation/pre-built-binaries/)
  - [Build from source](https://www.navidrome.org/docs/installation/build-from-source/)
- [Development](https://www.navidrome.org/docs/developers/)
- [Subsonic API Compatibility](https://www.navidrome.org/docs/developers/subsonic-api/)

## Screenshots

&lt;p align=&quot;left&quot;&gt;
    &lt;img height=&quot;550&quot; src=&quot;https://raw.githubusercontent.com/navidrome/navidrome/master/.github/screenshots/ss-mobile-login.png&quot;&gt;
    &lt;img height=&quot;550&quot; src=&quot;https://raw.githubusercontent.com/navidrome/navidrome/master/.github/screenshots/ss-mobile-player.png&quot;&gt;
    &lt;img height=&quot;550&quot; src=&quot;https://raw.githubusercontent.com/navidrome/navidrome/master/.github/screenshots/ss-mobile-album-view.png&quot;&gt;
    &lt;img width=&quot;550&quot; src=&quot;https://raw.githubusercontent.com/navidrome/navidrome/master/.github/screenshots/ss-desktop-player.png&quot;&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[opencost/opencost]]></title>
            <link>https://github.com/opencost/opencost</link>
            <guid>https://github.com/opencost/opencost</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:20 GMT</pubDate>
            <description><![CDATA[Cost monitoring for Kubernetes workloads and cloud costs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/opencost/opencost">opencost/opencost</a></h1>
            <p>Cost monitoring for Kubernetes workloads and cloud costs</p>
            <p>Language: Go</p>
            <p>Stars: 6,315</p>
            <p>Forks: 731</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/6219/badge)](https://www.bestpractices.dev/projects/6219)
[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20OpenCost%20Guru-006BFF)](https://gurubase.io/g/opencost)

![](./opencost-header.png)

# OpenCost ‚Äî your favorite open source cost monitoring tool for Kubernetes and cloud spend

OpenCost give teams visibility into current and historical Kubernetes and cloud spend and resource allocation.
These models provide cost transparency in Kubernetes environments that support multiple applications, teams, departments, etc.
It also provides visibility into the cloud costs across multiple providers.

OpenCost was originally developed and open sourced by [Kubecost](https://kubecost.com). This project combines a [specification](/spec/) as well as a Golang implementation of these detailed requirements. The web UI is available in the [opencost/opencost-ui](http://github.com/opencost/opencost-ui) repository.

[![OpenCost UI Walkthrough](./ui/src/thumbnail.png)](https://youtu.be/lCP4Ci9Kcdg)
*OpenCost UI Walkthrough*

To see the full functionality of OpenCost you can view [OpenCost features](https://opencost.io). Here is a summary of features enabled:

- Real-time cost allocation by Kubernetes cluster, node, namespace, controller kind, controller, service, or pod
- Multi-cloud cost monitoring for all cloud services on AWS, Azure, GCP
- Dynamic on-demand k8s asset pricing enabled by integrations with AWS, Azure, and GCP billing APIs
- Supports on-prem k8s clusters with custom CSV pricing
- Allocation for in-cluster K8s resources like CPU, GPU, memory, and persistent volumes
- Easily export pricing data to Prometheus with /metrics endpoint ([learn more](https://www.opencost.io/docs/installation/prometheus))
- Carbon costs for cloud resources
- MCP support
- Support for external costs like Datadog through [OpenCost Plugins](https://github.com/opencost/opencost-plugins)
- Free and open source distribution ([Apache2 license](LICENSE))

## Getting Started

OpenCost is now installed and managed via the official Helm chart only.

Quick install on any Kubernetes 1.20+ cluster:

```bash
helm repo add opencost https://opencost.github.io/opencost-helm-chart
helm repo update
helm install opencost opencost/opencost
```

Note: The standalone Kubernetes manifest files have been removed. Please use Helm for all installations and upgrades. See the [Helm installation docs](https://www.opencost.io/docs/installation/install) for details and configuration.

&gt; **Note for sharded Prometheus users:**
&gt; If you run Prometheus in a sharded (HA) setup, set `PROMETHEUS_SERVER_ENDPOINT` to a global query endpoint (e.g., Thanos Query, Cortex, or Mimir). Pointing to a single Prometheus pod may result in incomplete or intermittent export results. See the [Prometheus integration docs](https://www.opencost.io/docs/installation/prometheus) for details.

## Usage

- [Cost APIs](https://www.opencost.io/docs/integrations/api)
- [CLI / kubectl cost](https://www.opencost.io/docs/integrations/kubectl-cost)
- [Prometheus Metrics](https://www.opencost.io/docs/integrations/prometheus)
- [User Interface](https://www.opencost.io/docs/installation/ui)

## MCP Server

The OpenCost MCP (Model Context Protocol) server provides AI agents with access to cost allocation and asset data through a standardized interface. The MCP server is **enabled by default** in all OpenCost deployments, runs on port 8081, and is **built into the Helm chart** for easy production deployment. Users have full control to disable it or configure custom ports and settings.

### Features

- **Enabled by Default**: MCP server starts automatically with OpenCost
- **Full User Control**: Easy to disable or configure port and settings
- **Allocation Queries**: Retrieve cost allocation data with filtering and aggregation
- **Asset Queries**: Access detailed asset information including nodes, disks, load balancers, and more
- **Cloud Cost Queries**: Query cloud cost data with provider, service, and region filtering
- **HTTP Transport**: Uses HTTP for reliable communication with MCP clients
- **Zero Configuration**: Works out of the box with default OpenCost deployment
- **Helm Integration**: Built into the official Helm chart for production deployments

### Quick Start

#### Using Tilt (Development)
```bash
# Clone and start OpenCost with MCP server
git clone https://github.com/opencost/opencost.git
cd opencost
tilt up
```

Tilt configuration notes (cloud costs):

OpenCost&#039;s Tilt values (`tilt-values.yaml`) include extra environment variables to enable Cloud Cost ingestion in dev:

```yaml
# tilt-values.yaml (excerpt)
opencost:
  exporter:
    extraEnv:
      CLOUD_COST_ENABLED: &quot;true&quot;
      CLOUD_COST_CONFIG_PATH: &quot;/var/cloud-integration/cloud-integration.json&quot;
```

- Set `CLOUD_COST_ENABLED` to &quot;true&quot; to turn on cloud cost ingestion.
- Point `CLOUD_COST_CONFIG_PATH` to the mounted cloud integration file used by Tilt (e.g., `/var/cloud-integration/cloud-integration.json`).
- Adjust other values in `tilt-values.yaml` as needed during development.

#### Using Helm (Production)
```bash
# Add the OpenCost Helm repository
helm repo add opencost https://opencost.github.io/opencost-helm-chart
helm repo update

# Deploy OpenCost with MCP server (enabled by default)
helm install opencost opencost/opencost

# Access MCP server via port forwarding (example)
kubectl port-forward svc/opencost 8081:8081
```

The MCP server is **enabled by default** in the Helm chart. For custom configuration:

```bash
# Deploy with MCP server disabled
helm install opencost opencost/opencost \
  --set opencost.mcp.enabled=false

# Deploy with custom MCP port
helm install opencost opencost/opencost \
  --set opencost.mcp.port=9091

# Deploy with debug logging
helm install opencost opencost/opencost \
  --set opencost.mcp.extraEnv.MCP_LOG_LEVEL=debug
```

#### Configuration Summary

| Configuration | Command | Description |
|---------------|---------|-------------|
| **Default** | `helm install opencost opencost/opencost` | MCP enabled on port 8081 |
| **Disable** | `--set opencost.mcp.enabled=false` | Completely disable MCP server |
| **Custom Port** | `--set opencost.mcp.port=9091` | Use different port |
| **Debug Mode** | `--set opencost.mcp.extraEnv.MCP_LOG_LEVEL=debug` | Enable debug logging |

### MCP Client Configuration

Configure your MCP client (e.g., Cursor) to connect to the OpenCost MCP server:

**Default configuration (port 8081):**
```json
{
  &quot;mcpServers&quot;: {
    &quot;opencost&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;http://localhost:8081&quot;
    }
  }
}
```

**Custom port configuration:**
```json
{
  &quot;mcpServers&quot;: {
    &quot;opencost&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;http://localhost:9091&quot;
    }
  }
}
```

**For Kubernetes deployments:**
```json
{
  &quot;mcpServers&quot;: {
    &quot;opencost&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;http://opencost.opencost.svc.cluster.local:8081&quot;
    }
  }
}
```

**For external access (with LoadBalancer/Ingress):**
```json
{
  &quot;mcpServers&quot;: {
    &quot;opencost&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;http://your-opencost-domain.com:8081&quot;
    }
  }
}
```

### Available MCP Tools

The MCP server provides these tools for AI agents:

#### `get_allocation_costs`
Retrieve cost allocation data with filtering and aggregation.

**Parameters:**
- `window` (required): Time window (e.g., &quot;7d&quot;, &quot;1h&quot;, &quot;30m&quot;)
- `aggregate` (optional): Aggregation properties (e.g., &quot;namespace&quot;, &quot;pod&quot;, &quot;node&quot;)
- `step` (optional): Resolution step size
- `accumulate` (optional): Whether to accumulate over time
- `share_idle` (optional): Whether to share idle costs
- `include_idle` (optional): Whether to include idle resources

#### `get_asset_costs`
Retrieve asset cost data including nodes, disks, load balancers, and more.

**Parameters:**
- `window` (required): Time window (e.g., &quot;7d&quot;, &quot;1h&quot;, &quot;30m&quot;)

#### `get_cloud_costs`
Retrieve cloud cost data with provider, service, and region filtering.

**Parameters:**
- `window` (required): Time window (e.g., &quot;7d&quot;, &quot;1h&quot;, &quot;30m&quot;)
- `aggregate` (optional): Aggregation properties (e.g., &quot;provider&quot;, &quot;service&quot;, &quot;region&quot;)
- `accumulate` (optional): Time accumulation (&quot;day&quot;, &quot;week&quot;, &quot;month&quot;)
- `provider` (optional): Filter by cloud provider (e.g., &quot;aws&quot;, &quot;gcp&quot;, &quot;azure&quot;)
- `service` (optional): Filter by service (e.g., &quot;ec2&quot;, &quot;compute&quot;, &quot;s3&quot;)
- `category` (optional): Filter by category (e.g., &quot;compute&quot;, &quot;storage&quot;, &quot;network&quot;)
- `region` (optional): Filter by region (e.g., &quot;us-west-1&quot;, &quot;us-central1&quot;)
- `accountID` (optional): Filter by account ID

### Supported Asset Types

- **Node**: Compute instances with CPU, RAM, GPU details
- **Disk**: Storage volumes with usage and cost breakdown
- **LoadBalancer**: Load balancer instances with IP and private status
- **Network**: Network-related costs and usage
- **Cloud**: Cloud service costs with credit information
- **ClusterManagement**: Kubernetes cluster management costs

### Example Usage

Once configured, AI agents can query cost data like:

```javascript
// Get cost allocation for the last 7 days
const allocation = await mcpClient.callTool(&#039;get_allocation_costs&#039;, {
  window: &#039;7d&#039;,
  aggregate: &#039;namespace,node&#039;
});

// Get asset costs for the last 24 hours
const assets = await mcpClient.callTool(&#039;get_asset_costs&#039;, {
  window: &#039;1d&#039;
});

// Get cloud costs for AWS EC2 in us-west-1
const cloudCosts = await mcpClient.callTool(&#039;get_cloud_costs&#039;, {
  window: &#039;7d&#039;,
  aggregate: &#039;service&#039;,
  provider: &#039;aws&#039;,
  service: &#039;ec2&#039;,
  accumulate: &#039;day&#039;,
  filter: &#039;regionID:&quot;us-west-1&quot;&#039;
});
```

For detailed setup instructions and advanced configuration, see the [Helm chart documentation](https://github.com/opencost/opencost-helm-chart/blob/main/charts/opencost/README.md#mcp-server).

## Contributing

We :heart: pull requests! See [`CONTRIBUTING.md`](CONTRIBUTING.md) for information on building the project from source and contributing changes.

## Community

If you need any support or have any questions on contributing to the project, you can reach us on [CNCF Slack](https://slack.cncf.io/) in the [#opencost](https://cloud-native.slack.com/archives/C03D56FPD4G) channel or attend the biweekly [OpenCost Working Group community meeting](https://bit.ly/opencost-meeting) from the [Community Calendar](https://bit.ly/opencost-calendar) to discuss OpenCost development.

## FAQ

You can view [OpenCost documentation](https://www.opencost.io/docs/FAQ) for a list of commonly asked questions.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[projectcalico/calico]]></title>
            <link>https://github.com/projectcalico/calico</link>
            <guid>https://github.com/projectcalico/calico</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:19 GMT</pubDate>
            <description><![CDATA[Cloud native networking and network security]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/projectcalico/calico">projectcalico/calico</a></h1>
            <p>Cloud native networking and network security</p>
            <p>Language: Go</p>
            <p>Stars: 7,029</p>
            <p>Forks: 1,532</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>[![Go Report Card](https://goreportcard.com/badge/github.com/projectcalico/calico)](https://goreportcard.com/report/github.com/projectcalico/calico)
[![ArtifactHub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/tigera-operator)](https://artifacthub.io/packages/helm/projectcalico/tigera-operator)
[![License](https://img.shields.io/badge/license-Apache-blue.svg)](calico/LICENSE)
[![GoPkg](https://pkg.go.dev/badge/k8s.io/kubernetes.svg)](https://pkg.go.dev/github.com/projectcalico/api)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6064/badge)](https://bestpractices.coreinfrastructure.org/projects/6064)

&lt;div align=center&gt;
&lt;h1&gt;Calico&lt;/h1&gt;
&lt;h2&gt;
&lt;a href=&quot;https://projectcalico.docs.tigera.io/getting-started/kubernetes/quickstart&quot;&gt;Quickstart&lt;/a&gt; |
&lt;a href=&quot;https://projectcalico.docs.tigera.io&quot;&gt;Docs&lt;/a&gt; |
&lt;a href=&quot;CONTRIBUTING.md&quot;&gt;Contribute&lt;/a&gt; |
&lt;a href=&quot;https://slack.projectcalico.org&quot;&gt;Slack&lt;/a&gt; |
&lt;a href=&quot;https://github.com/projectcalico/calico/releases&quot;&gt;Releases&lt;/a&gt;
&lt;/h2&gt;
&lt;/div&gt;

## üêæ Welcome to Project Calico!

Project Calico, created and maintained by [Tigera][tigera], is an open-source project with an active development and user community. Calico Open Source has grown to be the most widely adopted solution for container networking and security, powering 8M+ nodes daily across 166 countries.

## üåü Why use Calico?

- **Data Plane Choice**: eBPF, standard Linux, Windows, and VPP ‚Äî versatility in network solutions.
- **Interoperability**: Works across multiple distros, multiple clouds, bare metal, and VMs.
- **Optimized Performance**: Engineered for high speed and low CPU usage, maximizing your cluster investments.
- **Scalable Architecture**: Grows seamlessly with your Kubernetes clusters without sacrificing performance.
- **Advanced Security**: Get granular access controls and WireGuard encryption.
- **Kubernetes Networking Policy Support**: Continually defining excellence in Kubernetes network policy standards and support.
- **Vibrant Contributor Community**: Over 200 contributors from a wide array of global companies.
- **Flexible networking**: An array of networking tools at your disposal, including BGP, VXLAN, service advertisement, and more.

&lt;div align=center&gt;
&lt;img src=&quot;https://www.tigera.io/app/uploads/2026/01/Ecosystem_2026.svg&quot;&gt;
&lt;/div&gt;

## ü§ù Join the Calico Community

- [Calico Big Cats][big-cats]: Become an ambassador and share your journey
- [Community Meetings][community-meetings]: Engage and contribute
- [Contribute on GitHub][first-issues]: Start with &#039;good first issues&#039;
- [Connect on Slack][slack]: Join the conversation with fellow contributors and our developers

## üí° Contributing to Project Calico

- [Get Started with Project Calico][get-started]
- [Repositories][repos]
- [Contribute to our docs][docs-contrib]
- Documentation: [Dive into our training and resources][resources]
- [Make Calico better][issues]

## üõ†Ô∏è Projects We Maintain

- [Calico Golang API][api]
- [Calico operator][operator]
- [VPP dataplane][vpp]
- [Calico BIRD][bird]

## üì¢ Stay Connected

- Subscribe: [Join our newsletter][news]
- [YouTube channel for updates &amp; tutorials][youtube]
- [Technical Blog][blog]
- [Careers][join]: Passionate about open source? Join our team.

[tigera]: https://www.tigera.io/
[big-cats]: https://www.tigera.io/project-calico/calico-big-cats-ambassador-program/#meet-calico-big-cats
[community-meetings]: https://calendar.google.com/calendar/u/0/embed?src=tigera.io_uunmavdev5ndovf0hc4frtl0i0@group.calendar.google.com
[first-issues]: https://github.com/projectcalico/calico/labels/good%20first%20issue
[slack]: https://slack.projectcalico.org/
[get-started]: https://docs.tigera.io/calico/latest/about
[repos]: https://github.com/orgs/projectcalico/repositories
[docs-contrib]: https://github.com/projectcalico/calico/blob/master/CONTRIBUTING_DOCS.md
[resources]: https://docs.tigera.io/calico/latest/about/training-resources
[issues]: https://github.com/projectcalico/calico/issues
[api]: https://github.com/projectcalico/api
[operator]: https://github.com/tigera/operator
[vpp]: https://github.com/projectcalico/vpp-dataplane
[news]: https://www.tigera.io/project-calico/#:~:text=Join%20Calico%20Open%20Source%20community%20newsletter
[youtube]: https://www.youtube.com/channel/UCFpTnXDNcBoXI4gqCDmegFA
[blog]: https://www.tigera.io/blog/?_sft_category=technical-blog
[join]: https://www.tigera.io/careers/
[bird]: https://github.com/projectcalico/bird
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[opentofu/opentofu]]></title>
            <link>https://github.com/opentofu/opentofu</link>
            <guid>https://github.com/opentofu/opentofu</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:18 GMT</pubDate>
            <description><![CDATA[OpenTofu lets you declaratively manage your cloud infrastructure.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/opentofu/opentofu">opentofu/opentofu</a></h1>
            <p>OpenTofu lets you declaratively manage your cloud infrastructure.</p>
            <p>Language: Go</p>
            <p>Stars: 27,668</p>
            <p>Forks: 1,150</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># OpenTofu

- [HomePage](https://opentofu.org/)
- [How to install](https://opentofu.org/docs/intro/install)
- [Join our Slack community!](https://opentofu.org/slack)

![](https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-dark.svg#gh-dark-mode-only)
![](https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-light.svg#gh-light-mode-only)

[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10508/badge)](https://www.bestpractices.dev/projects/10508)

OpenTofu is an OSS tool for building, changing, and versioning infrastructure safely and efficiently. OpenTofu can manage existing and popular service providers as well as custom in-house solutions.

The key features of OpenTofu are:

- **Infrastructure as Code**: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.

- **Execution Plans**: OpenTofu has a &quot;planning&quot; step where it generates an execution plan. The execution plan shows what OpenTofu will do when you call apply. This lets you avoid any surprises when OpenTofu manipulates infrastructure.

- **Resource Graph**: OpenTofu builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, OpenTofu builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.

- **Change Automation**: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what OpenTofu will change and in what order, avoiding many possible human errors.

## Getting help and contributing

- Have a question?
  - Post it in [GitHub Discussions](https://github.com/orgs/opentofu/discussions)
  - Open a [GitHub issue](https://github.com/opentofu/opentofu/issues/new/choose)
  - Join the [OpenTofu Slack](https://opentofu.org/slack/)!
- Want to contribute?
  - Please read the [Contribution Guide](CONTRIBUTING.md).
- Recurring Events
  - [Community Meetings](https://meet.google.com/xfm-cgms-has) on Wednesdays at 12:30 UTC at this link: https://meet.google.com/xfm-cgms-has ([üìÖ calendar link](https://calendar.google.com/calendar/event?eid=NDg0aWl2Y3U1aHFva3N0bGhyMHBhNzdpZmsgY18zZjJkZDNjMWZlMGVmNGU5M2VmM2ZjNDU2Y2EyZGQyMTlhMmU4ZmQ4NWY2YjQwNzUwYWYxNmMzZGYzNzBiZjkzQGc))
  - [Technical Steering Committee Meetings](https://meet.google.com/cry-houa-qbk) every other Tuesday at 4pm UTC at this link: https://meet.google.com/cry-houa-qbk ([üìÖ calendar link](https://calendar.google.com/calendar/u/0/event?eid=M3JyMWtuYWptdXI0Zms4ZnJpNmppcDczb3RfMjAyNTA1MjdUMTYwMDAwWiBjXzNmMmRkM2MxZmUwZWY0ZTkzZWYzZmM0NTZjYTJkZDIxOWEyZThmZDg1ZjZiNDA3NTBhZjE2YzNkZjM3MGJmOTNAZw))

&gt; [!TIP]
&gt; For more OpenTofu events, subscribe to the [OpenTofu Events Calendar](https://calendar.google.com/calendar/embed?src=c_3f2dd3c1fe0ef4e93ef3fc456ca2dd219a2e8fd85f6b40750af16c3df370bf93%40group.calendar.google.com)!

## Reporting security vulnerabilities
If you&#039;ve found a vulnerability or a potential vulnerability in OpenTofu please follow [Security Policy](https://github.com/opentofu/opentofu/security/policy). We&#039;ll send a confirmation email to acknowledge your report, and we&#039;ll send an additional email when we&#039;ve identified the issue positively or negatively.

## Reporting possible copyright issues

If you believe you have found any possible copyright or intellectual property issues, please contact liaison@opentofu.org. We&#039;ll send a confirmation email to acknowledge your report.

## Registry Access

In an effort to comply with applicable sanctions, we block access from specific countries of origin.

## License

[Mozilla Public License v2.0](https://github.com/opentofu/opentofu/blob/main/LICENSE)

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ollama/ollama]]></title>
            <link>https://github.com/ollama/ollama</link>
            <guid>https://github.com/ollama/ollama</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:17 GMT</pubDate>
            <description><![CDATA[Get up and running with GLM-4.7, DeepSeek, gpt-oss, Qwen, Gemma and other models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ollama/ollama">ollama/ollama</a></h1>
            <p>Get up and running with GLM-4.7, DeepSeek, gpt-oss, Qwen, Gemma and other models.</p>
            <p>Language: Go</p>
            <p>Stars: 160,950</p>
            <p>Forks: 14,328</p>
            <p>Stars today: 153 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
¬† &lt;a href=&quot;https://ollama.com&quot;&gt;
    &lt;img alt=&quot;ollama&quot; width=&quot;240&quot; src=&quot;https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

# Ollama

Get up and running with large language models.

### macOS

[Download](https://ollama.com/download/Ollama.dmg)

### Windows

[Download](https://ollama.com/download/OllamaSetup.exe)

### Linux

```shell
curl -fsSL https://ollama.com/install.sh | sh
```

[Manual install instructions](https://docs.ollama.com/linux#manual-install)

### Docker

The official [Ollama Docker image](https://hub.docker.com/r/ollama/ollama) `ollama/ollama` is available on Docker Hub.

### Libraries

- [ollama-python](https://github.com/ollama/ollama-python)
- [ollama-js](https://github.com/ollama/ollama-js)

### Community

- [Discord](https://discord.gg/ollama)
- [Reddit](https://reddit.com/r/ollama)

## Quickstart

To run and chat with [Gemma 3](https://ollama.com/library/gemma3):

```shell
ollama run gemma3
```

## Model library

Ollama supports a list of models available on [ollama.com/library](https://ollama.com/library &quot;ollama model library&quot;)

Here are some example models that can be downloaded:

| Model              | Parameters | Size  | Download                         |
| ------------------ | ---------- | ----- | -------------------------------- |
| Gemma 3            | 1B         | 815MB | `ollama run gemma3:1b`           |
| Gemma 3            | 4B         | 3.3GB | `ollama run gemma3`              |
| Gemma 3            | 12B        | 8.1GB | `ollama run gemma3:12b`          |
| Gemma 3            | 27B        | 17GB  | `ollama run gemma3:27b`          |
| QwQ                | 32B        | 20GB  | `ollama run qwq`                 |
| DeepSeek-R1        | 7B         | 4.7GB | `ollama run deepseek-r1`         |
| DeepSeek-R1        | 671B       | 404GB | `ollama run deepseek-r1:671b`    |
| Llama 4            | 109B       | 67GB  | `ollama run llama4:scout`        |
| Llama 4            | 400B       | 245GB | `ollama run llama4:maverick`     |
| Llama 3.3          | 70B        | 43GB  | `ollama run llama3.3`            |
| Llama 3.2          | 3B         | 2.0GB | `ollama run llama3.2`            |
| Llama 3.2          | 1B         | 1.3GB | `ollama run llama3.2:1b`         |
| Llama 3.2 Vision   | 11B        | 7.9GB | `ollama run llama3.2-vision`     |
| Llama 3.2 Vision   | 90B        | 55GB  | `ollama run llama3.2-vision:90b` |
| Llama 3.1          | 8B         | 4.7GB | `ollama run llama3.1`            |
| Llama 3.1          | 405B       | 231GB | `ollama run llama3.1:405b`       |
| Phi 4              | 14B        | 9.1GB | `ollama run phi4`                |
| Phi 4 Mini         | 3.8B       | 2.5GB | `ollama run phi4-mini`           |
| Mistral            | 7B         | 4.1GB | `ollama run mistral`             |
| Moondream 2        | 1.4B       | 829MB | `ollama run moondream`           |
| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`         |
| Starling           | 7B         | 4.1GB | `ollama run starling-lm`         |
| Code Llama         | 7B         | 3.8GB | `ollama run codellama`           |
| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored`   |
| LLaVA              | 7B         | 4.5GB | `ollama run llava`               |
| Granite-3.3        | 8B         | 4.9GB | `ollama run granite3.3`          |

&gt; [!NOTE]
&gt; You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.

## Customize a model

### Import from GGUF

Ollama supports importing GGUF models in the Modelfile:

1. Create a file named `Modelfile`, with a `FROM` instruction with the local filepath to the model you want to import.

   ```
   FROM ./vicuna-33b.Q4_0.gguf
   ```

2. Create the model in Ollama

   ```shell
   ollama create example -f Modelfile
   ```

3. Run the model

   ```shell
   ollama run example
   ```

### Import from Safetensors

See the [guide](https://docs.ollama.com/import) on importing models for more information.

### Customize a prompt

Models from the Ollama library can be customized with a prompt. For example, to customize the `llama3.2` model:

```shell
ollama pull llama3.2
```

Create a `Modelfile`:

```
FROM llama3.2

# set the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# set the system message
SYSTEM &quot;&quot;&quot;
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
&quot;&quot;&quot;
```

Next, create and run the model:

```
ollama create mario -f ./Modelfile
ollama run mario
&gt;&gt;&gt; hi
Hello! It&#039;s your friend Mario.
```

For more information on working with a Modelfile, see the [Modelfile](https://docs.ollama.com/modelfile) documentation.

## CLI Reference

### Create a model

`ollama create` is used to create a model from a Modelfile.

```shell
ollama create mymodel -f ./Modelfile
```

### Pull a model

```shell
ollama pull llama3.2
```

&gt; This command can also be used to update a local model. Only the diff will be pulled.

### Remove a model

```shell
ollama rm llama3.2
```

### Copy a model

```shell
ollama cp llama3.2 my-model
```

### Multiline input

For multiline input, you can wrap text with `&quot;&quot;&quot;`:

```
&gt;&gt;&gt; &quot;&quot;&quot;Hello,
... world!
... &quot;&quot;&quot;
I&#039;m a basic program that prints the famous &quot;Hello, world!&quot; message to the console.
```

### Multimodal models

```
ollama run llava &quot;What&#039;s in this image? /Users/jmorgan/Desktop/smile.png&quot;
```

&gt; **Output**: The image features a yellow smiley face, which is likely the central focus of the picture.

### Pass the prompt as an argument

```shell
ollama run llama3.2 &quot;Summarize this file: $(cat README.md)&quot;
```

&gt; **Output**: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.

### Show model information

```shell
ollama show llama3.2
```

### List models on your computer

```shell
ollama list
```

### List which models are currently loaded

```shell
ollama ps
```

### Stop a model which is currently running

```shell
ollama stop llama3.2
```

### Generate embeddings from the CLI

```shell
ollama run embeddinggemma &quot;Your text to embed&quot;
```

You can also pipe text for scripted workflows:

```shell
echo &quot;Your text to embed&quot; | ollama run embeddinggemma
```

### Start Ollama

`ollama serve` is used when you want to start ollama without running the desktop application.

## Building

See the [developer guide](https://github.com/ollama/ollama/blob/main/docs/development.md)

### Running local builds

Next, start the server:

```shell
./ollama serve
```

Finally, in a separate shell, run a model:

```shell
./ollama run llama3.2
```

## Building with MLX (experimental)

First build the MLX libraries:

```shell
cmake --preset MLX
cmake --build --preset MLX --parallel
cmake --install build --component MLX
```

When building with the `-tags mlx` flag, the main `ollama` binary includes MLX support for experimental features like image generation:

```shell
go build -tags mlx .
```

Finally, start the server:

```
./ollama serve
```

### Building MLX with CUDA

When building with CUDA, use the preset &quot;MLX CUDA 13&quot; or &quot;MLX CUDA 12&quot; to enable CUDA with default architectures:

```shell
cmake --preset &#039;MLX CUDA 13&#039;
cmake --build --preset &#039;MLX CUDA 13&#039; --parallel
cmake --install build --component MLX
```

## REST API

Ollama has a REST API for running and managing models.

### Generate a response

```shell
curl http://localhost:11434/api/generate -d &#039;{
  &quot;model&quot;: &quot;llama3.2&quot;,
  &quot;prompt&quot;:&quot;Why is the sky blue?&quot;
}&#039;
```

### Chat with a model

```shell
curl http://localhost:11434/api/chat -d &#039;{
  &quot;model&quot;: &quot;llama3.2&quot;,
  &quot;messages&quot;: [
    { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;why is the sky blue?&quot; }
  ]
}&#039;
```

See the [API documentation](./docs/api.md) for all endpoints.

## Community Integrations

### Web &amp; Desktop

- [Onyx](https://github.com/onyx-dot-app/onyx)
- [Open WebUI](https://github.com/open-webui/open-webui)
- [SwiftChat (macOS with ReactNative)](https://github.com/aws-samples/swift-chat)
- [Enchanted (macOS native)](https://github.com/AugustDev/enchanted)
- [Hollama](https://github.com/fmaclen/hollama)
- [Lollms WebUI (Single user)](https://github.com/ParisNeo/lollms-webui)
- [Lollms (Multi users)](https://github.com/ParisNeo/lollms)
- [LibreChat](https://github.com/danny-avila/LibreChat)
- [Bionic GPT](https://github.com/bionic-gpt/bionic-gpt)
- [HTML UI](https://github.com/rtcfirefly/ollama-ui)
- [AI-UI](https://github.com/bajahaw/ai-ui)
- [Saddle](https://github.com/jikkuatwork/saddle)
- [TagSpaces](https://www.tagspaces.org) (A platform for file-based apps, [utilizing Ollama](https://docs.tagspaces.org/ai/) for the generation of tags and descriptions)
- [Chatbot UI](https://github.com/ivanfioravanti/chatbot-ollama)
- [Chatbot UI v2](https://github.com/mckaywrigley/chatbot-ui)
- [Typescript UI](https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file)
- [Minimalistic React UI for Ollama Models](https://github.com/richawo/minimal-llm-ui)
- [Ollamac](https://github.com/kevinhermawan/Ollamac)
- [big-AGI](https://github.com/enricoros/big-AGI)
- [Cheshire Cat assistant framework](https://github.com/cheshire-cat-ai/core)
- [Amica](https://github.com/semperai/amica)
- [chatd](https://github.com/BruceMacD/chatd)
- [Ollama-SwiftUI](https://github.com/kghandour/Ollama-SwiftUI)
- [Dify.AI](https://github.com/langgenius/dify)
- [MindMac](https://mindmac.app)
- [NextJS Web Interface for Ollama](https://github.com/jakobhoeg/nextjs-ollama-llm-ui)
- [Msty](https://msty.app)
- [Chatbox](https://github.com/Bin-Huang/Chatbox)
- [WinForm Ollama Copilot](https://github.com/tgraupmann/WinForm_Ollama_Copilot)
- [NextChat](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web) with [Get Started Doc](https://docs.nextchat.dev/models/ollama)
- [Alpaca WebUI](https://github.com/mmo80/alpaca-webui)
- [OllamaGUI](https://github.com/enoch1118/ollamaGUI)
- [OpenAOE](https://github.com/InternLM/OpenAOE)
- [Odin Runes](https://github.com/leonid20000/OdinRunes)
- [LLM-X](https://github.com/mrdjohnson/llm-x) (Progressive Web App)
- [AnythingLLM (Docker + MacOs/Windows/Linux native app)](https://github.com/Mintplex-Labs/anything-llm)
- [Ollama Basic Chat: Uses HyperDiv Reactive UI](https://github.com/rapidarchitect/ollama_basic_chat)
- [Ollama-chats RPG](https://github.com/drazdra/ollama-chats)
- [IntelliBar](https://intellibar.app/) (AI-powered assistant for macOS)
- [Jirapt](https://github.com/AliAhmedNada/jirapt) (Jira Integration to generate issues, tasks, epics)
- [ojira](https://github.com/AliAhmedNada/ojira) (Jira chrome plugin to easily generate descriptions for tasks)
- [QA-Pilot](https://github.com/reid41/QA-Pilot) (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)
- [ChatOllama](https://github.com/sugarforever/chat-ollama) (Open Source Chatbot based on Ollama with Knowledge Bases)
- [CRAG Ollama Chat](https://github.com/Nagi-ovo/CRAG-Ollama-Chat) (Simple Web Search with Corrective RAG)
- [RAGFlow](https://github.com/infiniflow/ragflow) (Open-source Retrieval-Augmented Generation engine based on deep document understanding)
- [StreamDeploy](https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold) (LLM Application Scaffold)
- [chat](https://github.com/swuecho/chat) (chat web app for teams)
- [Lobe Chat](https://github.com/lobehub/lobe-chat) with [Integrating Doc](https://lobehub.com/docs/self-hosting/examples/ollama)
- [Ollama RAG Chatbot](https://github.com/datvodinh/rag-chatbot.git) (Local Chat with multiple PDFs using Ollama and RAG)
- [BrainSoup](https://www.nurgo-software.com/products/brainsoup) (Flexible native client with RAG &amp; multi-agent automation)
- [macai](https://github.com/Renset/macai) (macOS client for Ollama, ChatGPT, and other compatible API back-ends)
- [RWKV-Runner](https://github.com/josStorer/RWKV-Runner) (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)
- [Ollama Grid Search](https://github.com/dezoito/ollama-grid-search) (app to evaluate and compare models)
- [Olpaka](https://github.com/Otacon/olpaka) (User-friendly Flutter Web App for Ollama)
- [Casibase](https://casibase.org) (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)
- [OllamaSpring](https://github.com/CrazyNeil/OllamaSpring) (Ollama Client for macOS)
- [LLocal.in](https://github.com/kartikm7/llocal) (Easy to use Electron Desktop Client for Ollama)
- [Shinkai Desktop](https://github.com/dcSpark/shinkai-apps) (Two click install Local AI using Ollama + Files + RAG)
- [AiLama](https://github.com/zeyoyt/ailama) (A Discord User App that allows you to interact with Ollama anywhere in Discord)
- [Ollama with Google Mesop](https://github.com/rapidarchitect/ollama_mesop/) (Mesop Chat Client implementation with Ollama)
- [R2R](https://github.com/SciPhi-AI/R2R) (Open-source RAG engine)
- [Ollama-Kis](https://github.com/elearningshow/ollama-kis) (A simple easy-to-use GUI with sample custom LLM for Drivers Education)
- [OpenGPA](https://opengpa.org) (Open-source offline-first Enterprise Agentic Application)
- [Painting Droid](https://github.com/mateuszmigas/painting-droid) (Painting app with AI integrations)
- [Kerlig AI](https://www.kerlig.com/) (AI writing assistant for macOS)
- [AI Studio](https://github.com/MindWorkAI/AI-Studio)
- [Sidellama](https://github.com/gyopak/sidellama) (browser-based LLM client)
- [LLMStack](https://github.com/trypromptly/LLMStack) (No-code multi-agent framework to build LLM agents and workflows)
- [BoltAI for Mac](https://boltai.com) (AI Chat Client for Mac)
- [Harbor](https://github.com/av/harbor) (Containerized LLM Toolkit with Ollama as default backend)
- [PyGPT](https://github.com/szczyglis-dev/py-gpt) (AI desktop assistant for Linux, Windows, and Mac)
- [Alpaca](https://github.com/Jeffser/Alpaca) (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)
- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT/blob/master/docs/content/platform/ollama.md) (AutoGPT Ollama integration)
- [Go-CREW](https://www.jonathanhecl.com/go-crew/) (Powerful Offline RAG in Golang)
- [PartCAD](https://github.com/openvmp/partcad/) (CAD model generation with OpenSCAD and CadQuery)
- [Ollama4j Web UI](https://github.com/ollama4j/ollama4j-web-ui) - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j
- [PyOllaMx](https://github.com/kspviswa/pyOllaMx) - macOS application capable of chatting with both Ollama and Apple MLX models.
- [Cline](https://github.com/cline/cline) - Formerly known as Claude Dev is a VS Code extension for multi-file/whole-repo coding
- [Void](https://github.com/voideditor/void) (Open source AI code editor and Cursor alternative)
- [Cherry Studio](https://github.com/kangfenmao/cherry-studio) (Desktop client with Ollama support)
- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)
- [Archyve](https://github.com/nickthecook/archyve) (RAG-enabling document library)
- [crewAI with Mesop](https://github.com/rapidarchitect/ollama-crew-mesop) (Mesop Web Interface to run crewAI with Ollama)
- [Tkinter-based client](https://github.com/chyok/ollama-gui) (Python tkinter-based Client for Ollama)
- [LLMChat](https://github.com/trendy-design/llmchat) (Privacy focused, 100% local, intuitive all-in-one chat interface)
- [Local Multimodal AI Chat](https://github.com/Leon-Sander/Local-Multimodal-AI-Chat) (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)
- [ARGO](https://github.com/xark-argo/argo) (Locally download and run Ollama and Huggingface models with RAG and deep research on Mac/Windows/Linux)
- [OrionChat](https://github.com/EliasPereirah/OrionChat) - OrionChat is a web interface for chatting with different AI providers
- [G1](https://github.com/bklieger-groq/g1) (Prototype of using prompting strategies to improve the LLM&#039;s reasoning through o1-like reasoning chains.)
- [Web management](https://github.com/lemonit-eric-mao/ollama-web-management) (Web management page)
- [Promptery](https://github.com/promptery/promptery) (desktop client for Ollama.)
- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)
- [chat-ollama](https://github.com/annilq/chat-ollama) (a React Native client for Ollama)
- [SpaceLlama](https://github.com/tcsenpai/spacellama) (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)
- [YouLama](https://github.com/tcsenpai/youlama) (Webapp to quickly summarize any YouTube video, supporting Invidious as well)
- [DualMind](https://github.com/tcsenpai/dualmind) (Experimental app allowing two models to talk to each other in the terminal or in a web interface)
- [ollamarama-matrix](https://github.com/h1ddenpr0cess20/ollamarama-matrix) (Ollama chatbot for the Matrix chat protocol)
- [ollama-chat-app](https://github.com/anan1213095357/ollama-chat-app) (Flutter-based chat app)
- [Perfect Memory AI](https://www.perfectmemory.ai/) (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)
- [Hexabot](https://github.com/hexastack/hexabot) (A conversational AI builder)
- [Reddit Rate](https://github.com/rapidarchitect/reddit_analyzer) (Search and Rate Reddit topics with a weighted summation)
- [OpenTalkGpt](https://github.com/adarshM84/OpenTalkGpt) (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)
- [VT](https://github.com/vinhnx/vt.ai) (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)
- [Nosia](https://github.com/nosia-ai/nosia) (Easy to install and use RAG platform based on Ollama)
- [Witsy](https://github.com/nbonamy/witsy) (An AI Desktop application available for Mac/Windows/Linux)
- [Abbey](https://github.com/US-Artificial-Intelligence/abbey) (A configurable AI interface server with notebooks, document storage, and YouTube support)
- [Minima](https://github.com/dmayboroda/minima) (RAG with on-premises or fully local workflow)
- [aidful-ollama-model-delete](https://github.com/AidfulAI/aidful-ollama-model-delete) (User interface for simplified model cleanup)
- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) (An AI-powered search engine &amp; an open-source alternative to Perplexity AI)
- [Ollama Chat WebUI for Docker ](https://github.com/oslook/ollama-webui) (Support for local docker deployment, lightweight ollama webui)
- [AI Toolkit for Visual Studio Code](https://aka.ms/ai-tooklit/ollama-docs) (Microsoft-official VS Code extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)
- [MinimalNextOllamaChat](https://github.com/anilkay/MinimalNextOllamaChat) (Minimal Web UI for Chat and Model Control)
- [Chipper](https://github.com/TilmanGriesel/chipper) AI interface for tinkerers (Ollama, Haystack RAG, Python)
- [ChibiChat](https://github.com/CosmicEventHorizon/ChibiChat) (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)
- [LocalLLM](https://github.com/qusaismael/localllm) (Minimal Web-App to run ollama models on it with a GUI)
- [Ollamazing](https://github.com/buiducnhat/ollamazing) (Web extension to run Ollama models)
- [OpenDeepResearcher-via-searxng](https://github.com/benhaotang/OpenDeepResearcher-via-searxng) (A Deep Research equivalent endpoint with Ollama support for running locally)
- [AntSK](https://github.com/AIDotNet/AntSK) (Out-of-the-box &amp; Adaptable RAG Chatb

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[charmbracelet/crush]]></title>
            <link>https://github.com/charmbracelet/crush</link>
            <guid>https://github.com/charmbracelet/crush</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:16 GMT</pubDate>
            <description><![CDATA[Glamourous agentic coding for all üíò]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/charmbracelet/crush">charmbracelet/crush</a></h1>
            <p>Glamourous agentic coding for all üíò</p>
            <p>Language: Go</p>
            <p>Stars: 19,085</p>
            <p>Forks: 1,162</p>
            <p>Stars today: 92 stars today</p>
            <h2>README</h2><pre># Crush

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://stuff.charm.sh/crush/charm-crush.png&quot;&gt;&lt;img width=&quot;450&quot; alt=&quot;Charm Crush Logo&quot; src=&quot;https://github.com/user-attachments/assets/cf8ca3ce-8b02-43f0-9d0f-5a331488da4b&quot; /&gt;&lt;/a&gt;&lt;br /&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/crush/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/charmbracelet/crush&quot; alt=&quot;Latest Release&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/crush/actions&quot;&gt;&lt;img src=&quot;https://github.com/charmbracelet/crush/actions/workflows/build.yml/badge.svg&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Your new coding bestie, now available in your favourite terminal.&lt;br /&gt;Your tools, your code, and your workflows, wired into your LLM of choice.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;ÁªàÁ´ØÈáåÁöÑÁºñÁ®ãÊñ∞Êê≠Ê°£Ôºå&lt;br /&gt;Êó†ÁºùÊé•ÂÖ•‰Ω†ÁöÑÂ∑•ÂÖ∑„ÄÅ‰ª£Á†Å‰∏éÂ∑•‰ΩúÊµÅÔºåÂÖ®Èù¢ÂÖºÂÆπ‰∏ªÊµÅ LLM Ê®°Âûã„ÄÇ&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;800&quot; alt=&quot;Crush Demo&quot; src=&quot;https://github.com/user-attachments/assets/58280caf-851b-470a-b6f7-d5c4ea8a1968&quot; /&gt;&lt;/p&gt;

## Features

- **Multi-Model:** choose from a wide range of LLMs or add your own via OpenAI- or Anthropic-compatible APIs
- **Flexible:** switch LLMs mid-session while preserving context
- **Session-Based:** maintain multiple work sessions and contexts per project
- **LSP-Enhanced:** Crush uses LSPs for additional context, just like you do
- **Extensible:** add capabilities via MCPs (`http`, `stdio`, and `sse`)
- **Works Everywhere:** first-class support in every terminal on macOS, Linux, Windows (PowerShell and WSL), Android, FreeBSD, OpenBSD, and NetBSD
- **Industrial Grade:** built on the Charm ecosystem, powering 25k+ applications, from leading open source projects to business-critical infrastructure

## Installation

Use a package manager:

```bash
# Homebrew
brew install charmbracelet/tap/crush

# NPM
npm install -g @charmland/crush

# Arch Linux (btw)
yay -S crush-bin

# Nix
nix run github:numtide/nix-ai-tools#crush

# FreeBSD
pkg install crush
```

Windows users:

```bash
# Winget
winget install charmbracelet.crush

# Scoop
scoop bucket add charm https://github.com/charmbracelet/scoop-bucket.git
scoop install crush
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Nix (NUR)&lt;/strong&gt;&lt;/summary&gt;

Crush is available via the official Charm [NUR](https://github.com/nix-community/NUR) in `nur.repos.charmbracelet.crush`, which is the most up-to-date way to get Crush in Nix.

You can also try out Crush via the NUR with `nix-shell`:

```bash
# Add the NUR channel.
nix-channel --add https://github.com/nix-community/NUR/archive/main.tar.gz nur
nix-channel --update

# Get Crush in a Nix shell.
nix-shell -p &#039;(import &lt;nur&gt; { pkgs = import &lt;nixpkgs&gt; {}; }).repos.charmbracelet.crush&#039;
```

### NixOS &amp; Home Manager Module Usage via NUR

Crush provides NixOS and Home Manager modules via NUR.
You can use these modules directly in your flake by importing them from NUR. Since it auto detects whether its a home manager or nixos context you can use the import the exact same way :)

```nix
{
  inputs = {
    nixpkgs.url = &quot;github:NixOS/nixpkgs/nixos-unstable&quot;;
    nur.url = &quot;github:nix-community/NUR&quot;;
  };

  outputs = { self, nixpkgs, nur, ... }: {
    nixosConfigurations.your-hostname = nixpkgs.lib.nixosSystem {
      system = &quot;x86_64-linux&quot;;
      modules = [
        nur.modules.nixos.default
        nur.repos.charmbracelet.modules.crush
        {
          programs.crush = {
            enable = true;
            settings = {
              providers = {
                openai = {
                  id = &quot;openai&quot;;
                  name = &quot;OpenAI&quot;;
                  base_url = &quot;https://api.openai.com/v1&quot;;
                  type = &quot;openai&quot;;
                  api_key = &quot;sk-fake123456789abcdef...&quot;;
                  models = [
                    {
                      id = &quot;gpt-4&quot;;
                      name = &quot;GPT-4&quot;;
                    }
                  ];
                };
              };
              lsp = {
                go = { command = &quot;gopls&quot;; enabled = true; };
                nix = { command = &quot;nil&quot;; enabled = true; };
              };
              options = {
                context_paths = [ &quot;/etc/nixos/configuration.nix&quot; ];
                tui = { compact_mode = true; };
                debug = false;
              };
            };
          };
        }
      ];
    };
  };
}
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Debian/Ubuntu&lt;/strong&gt;&lt;/summary&gt;

```bash
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg
echo &quot;deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *&quot; | sudo tee /etc/apt/sources.list.d/charm.list
sudo apt update &amp;&amp; sudo apt install crush
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Fedora/RHEL&lt;/strong&gt;&lt;/summary&gt;

```bash
echo &#039;[charm]
name=Charm
baseurl=https://repo.charm.sh/yum/
enabled=1
gpgcheck=1
gpgkey=https://repo.charm.sh/yum/gpg.key&#039; | sudo tee /etc/yum.repos.d/charm.repo
sudo yum install crush
```

&lt;/details&gt;

Or, download it:

- [Packages][releases] are available in Debian and RPM formats
- [Binaries][releases] are available for Linux, macOS, Windows, FreeBSD, OpenBSD, and NetBSD

[releases]: https://github.com/charmbracelet/crush/releases

Or just install it with Go:

```
go install github.com/charmbracelet/crush@latest
```

&gt; [!WARNING]
&gt; Productivity may increase when using Crush and you may find yourself nerd
&gt; sniped when first using the application. If the symptoms persist, join the
&gt; [Discord][discord] and nerd snipe the rest of us.

## Getting Started

The quickest way to get started is to grab an API key for your preferred
provider such as Anthropic, OpenAI, Groq, OpenRouter, or Vercel AI Gateway and just start
Crush. You&#039;ll be prompted to enter your API key.

That said, you can also set environment variables for preferred providers.

| Environment Variable        | Provider                                           |
| --------------------------- | -------------------------------------------------- |
| `ANTHROPIC_API_KEY`         | Anthropic                                          |
| `OPENAI_API_KEY`            | OpenAI                                             |
| `VERCEL_API_KEY`            | Vercel AI Gateway                                  |
| `GEMINI_API_KEY`            | Google Gemini                                      |
| `SYNTHETIC_API_KEY`         | Synthetic                                          |
| `ZAI_API_KEY`               | Z.ai                                               |
| `HF_TOKEN`                  | Hugging Face Inference                             |
| `CEREBRAS_API_KEY`          | Cerebras                                           |
| `OPENROUTER_API_KEY`        | OpenRouter                                         |
| `GROQ_API_KEY`              | Groq                                               |
| `VERTEXAI_PROJECT`          | Google Cloud VertexAI (Gemini)                     |
| `VERTEXAI_LOCATION`         | Google Cloud VertexAI (Gemini)                     |
| `AWS_ACCESS_KEY_ID`         | Amazon Bedrock (Claude)                            |
| `AWS_SECRET_ACCESS_KEY`     | Amazon Bedrock (Claude)                            |
| `AWS_REGION`                | Amazon Bedrock (Claude)                            |
| `AWS_PROFILE`               | Amazon Bedrock (Custom Profile)                    |
| `AWS_BEARER_TOKEN_BEDROCK`  | Amazon Bedrock                                     |
| `AZURE_OPENAI_API_ENDPOINT` | Azure OpenAI models                                |
| `AZURE_OPENAI_API_KEY`      | Azure OpenAI models (optional when using Entra ID) |
| `AZURE_OPENAI_API_VERSION`  | Azure OpenAI models                                |

### By the Way

Is there a provider you‚Äôd like to see in Crush? Is there an existing model that needs an update?

Crush‚Äôs default model listing is managed in [Catwalk](https://github.com/charmbracelet/catwalk), a community-supported, open source repository of Crush-compatible models, and you‚Äôre welcome to contribute.

&lt;a href=&quot;https://github.com/charmbracelet/catwalk&quot;&gt;&lt;img width=&quot;174&quot; height=&quot;174&quot; alt=&quot;Catwalk Badge&quot; src=&quot;https://github.com/user-attachments/assets/95b49515-fe82-4409-b10d-5beb0873787d&quot; /&gt;&lt;/a&gt;

## Configuration

Crush runs great with no configuration. That said, if you do need or want to
customize Crush, configuration can be added either local to the project itself,
or globally, with the following priority:

1. `.crush.json`
2. `crush.json`
3. `$HOME/.config/crush/crush.json`

Configuration itself is stored as a JSON object:

```json
{
  &quot;this-setting&quot;: { &quot;this&quot;: &quot;that&quot; },
  &quot;that-setting&quot;: [&quot;ceci&quot;, &quot;cela&quot;]
}
```

As an additional note, Crush also stores ephemeral data, such as application state, in one additional location:

```bash
# Unix
$HOME/.local/share/crush/crush.json

# Windows
%LOCALAPPDATA%\crush\crush.json
```

&gt; [!TIP]
&gt; You can override the user and data config locations by setting:
&gt; * `CRUSH_GLOBAL_CONFIG`
&gt; * `CRUSH_GLOBAL_DATA`

### LSPs

Crush can use LSPs for additional context to help inform its decisions, just
like you would. LSPs can be added manually like so:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;lsp&quot;: {
    &quot;go&quot;: {
      &quot;command&quot;: &quot;gopls&quot;,
      &quot;env&quot;: {
        &quot;GOTOOLCHAIN&quot;: &quot;go1.24.5&quot;
      }
    },
    &quot;typescript&quot;: {
      &quot;command&quot;: &quot;typescript-language-server&quot;,
      &quot;args&quot;: [&quot;--stdio&quot;]
    },
    &quot;nix&quot;: {
      &quot;command&quot;: &quot;nil&quot;
    }
  }
}
```

### MCPs

Crush also supports Model Context Protocol (MCP) servers through three
transport types: `stdio` for command-line servers, `http` for HTTP endpoints,
and `sse` for Server-Sent Events. Environment variable expansion is supported
using `$(echo $VAR)` syntax.

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;mcp&quot;: {
    &quot;filesystem&quot;: {
      &quot;type&quot;: &quot;stdio&quot;,
      &quot;command&quot;: &quot;node&quot;,
      &quot;args&quot;: [&quot;/path/to/mcp-server.js&quot;],
      &quot;timeout&quot;: 120,
      &quot;disabled&quot;: false,
      &quot;disabled_tools&quot;: [&quot;some-tool-name&quot;],
      &quot;env&quot;: {
        &quot;NODE_ENV&quot;: &quot;production&quot;
      }
    },
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;,
      &quot;timeout&quot;: 120,
      &quot;disabled&quot;: false,
      &quot;disabled_tools&quot;: [&quot;create_issue&quot;, &quot;create_pull_request&quot;],
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;Bearer $GH_PAT&quot;
      }
    },
    &quot;streaming-service&quot;: {
      &quot;type&quot;: &quot;sse&quot;,
      &quot;url&quot;: &quot;https://example.com/mcp/sse&quot;,
      &quot;timeout&quot;: 120,
      &quot;disabled&quot;: false,
      &quot;headers&quot;: {
        &quot;API-Key&quot;: &quot;$(echo $API_KEY)&quot;
      }
    }
  }
}
```

### Ignoring Files

Crush respects `.gitignore` files by default, but you can also create a
`.crushignore` file to specify additional files and directories that Crush
should ignore. This is useful for excluding files that you want in version
control but don&#039;t want Crush to consider when providing context.

The `.crushignore` file uses the same syntax as `.gitignore` and can be placed
in the root of your project or in subdirectories.

### Allowing Tools

By default, Crush will ask you for permission before running tool calls. If
you&#039;d like, you can allow tools to be executed without prompting you for
permissions. Use this with care.

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;permissions&quot;: {
    &quot;allowed_tools&quot;: [
      &quot;view&quot;,
      &quot;ls&quot;,
      &quot;grep&quot;,
      &quot;edit&quot;,
      &quot;mcp_context7_get-library-doc&quot;
    ]
  }
}
```

You can also skip all permission prompts entirely by running Crush with the
`--yolo` flag. Be very, very careful with this feature.

### Disabling Built-In Tools

If you&#039;d like to prevent Crush from using certain built-in tools entirely, you
can disable them via the `options.disabled_tools` list. Disabled tools are
completely hidden from the agent.

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;disabled_tools&quot;: [
      &quot;bash&quot;,
      &quot;sourcegraph&quot;
    ]
  }
}
```

To disable tools from MCP servers, see the [MCP config section](#mcps).

### Agent Skills

Crush supports the [Agent Skills](https://agentskills.io) open standard for
extending agent capabilities with reusable skill packages. Skills are folders
containing a `SKILL.md` file with instructions that Crush can discover and
activate on demand.

Skills are discovered from:

- `~/.config/crush/skills/` on Unix (default, can be overridden with `CRUSH_SKILLS_DIR`)
- `%LOCALAPPDATA%\crush\skills\` on Windows (default, can be overridden with `CRUSH_SKILLS_DIR`)
- Additional paths configured via `options.skills_paths`

```jsonc
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;skills_paths&quot;: [
      &quot;~/.config/crush/skills&quot;, // Windows: &quot;%LOCALAPPDATA%\\crush\\skills&quot;,
      &quot;./project-skills&quot;
    ]
  }
}
```

You can get started with example skills from [anthropics/skills](https://github.com/anthropics/skills):

```bash
# Unix
mkdir -p ~/.config/crush/skills
cd ~/.config/crush/skills
git clone https://github.com/anthropics/skills.git _temp
mv _temp/skills/* . &amp;&amp; rm -rf _temp
```

```powershell
# Windows (PowerShell)
mkdir -Force &quot;$env:LOCALAPPDATA\crush\skills&quot;
cd &quot;$env:LOCALAPPDATA\crush\skills&quot;
git clone https://github.com/anthropics/skills.git _temp
mv _temp/skills/* . ; rm -r -force _temp
```

### Initialization

When you initialize a project, Crush analyzes your codebase and creates
a context file that helps it work more effectively in future sessions.
By default, this file is named `AGENTS.md`, but you can customize the
name and location with the `initialize_as` option:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;initialize_as&quot;: &quot;AGENTS.md&quot;
  }
}
```

This is useful if you prefer a different naming convention or want to
place the file in a specific directory (e.g., `CRUSH.md` or
`docs/LLMs.md`). Crush will fill the file with project-specific context
like build commands, code patterns, and conventions it discovered during
initialization.

### Attribution Settings

By default, Crush adds attribution information to Git commits and pull requests
it creates. You can customize this behavior with the `attribution` option:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;attribution&quot;: {
      &quot;trailer_style&quot;: &quot;co-authored-by&quot;,
      &quot;generated_with&quot;: true
    }
  }
}
```

- `trailer_style`: Controls the attribution trailer added to commit messages
  (default: `assisted-by`)
	- `assisted-by`: Adds `Assisted-by: [Model Name] via Crush &lt;crush@charm.land&gt;`
	  (includes the model name)
	- `co-authored-by`: Adds `Co-Authored-By: Crush &lt;crush@charm.land&gt;`
	- `none`: No attribution trailer
- `generated_with`: When true (default), adds `üíò Generated with Crush` line to
  commit messages and PR descriptions

### Custom Providers

Crush supports custom provider configurations for both OpenAI-compatible and
Anthropic-compatible APIs.

&gt; [!NOTE]
&gt; Note that we support two &quot;types&quot; for OpenAI. Make sure to choose the right one
&gt; to ensure the best experience!
&gt; * `openai` should be used when proxying or routing requests through OpenAI.
&gt; * `openai-compat` should be used when using non-OpenAI providers that have OpenAI-compatible APIs.

#### OpenAI-Compatible APIs

Here‚Äôs an example configuration for Deepseek, which uses an OpenAI-compatible
API. Don&#039;t forget to set `DEEPSEEK_API_KEY` in your environment.

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;providers&quot;: {
    &quot;deepseek&quot;: {
      &quot;type&quot;: &quot;openai-compat&quot;,
      &quot;base_url&quot;: &quot;https://api.deepseek.com/v1&quot;,
      &quot;api_key&quot;: &quot;$DEEPSEEK_API_KEY&quot;,
      &quot;models&quot;: [
        {
          &quot;id&quot;: &quot;deepseek-chat&quot;,
          &quot;name&quot;: &quot;Deepseek V3&quot;,
          &quot;cost_per_1m_in&quot;: 0.27,
          &quot;cost_per_1m_out&quot;: 1.1,
          &quot;cost_per_1m_in_cached&quot;: 0.07,
          &quot;cost_per_1m_out_cached&quot;: 1.1,
          &quot;context_window&quot;: 64000,
          &quot;default_max_tokens&quot;: 5000
        }
      ]
    }
  }
}
```

#### Anthropic-Compatible APIs

Custom Anthropic-compatible providers follow this format:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;providers&quot;: {
    &quot;custom-anthropic&quot;: {
      &quot;type&quot;: &quot;anthropic&quot;,
      &quot;base_url&quot;: &quot;https://api.anthropic.com/v1&quot;,
      &quot;api_key&quot;: &quot;$ANTHROPIC_API_KEY&quot;,
      &quot;extra_headers&quot;: {
        &quot;anthropic-version&quot;: &quot;2023-06-01&quot;
      },
      &quot;models&quot;: [
        {
          &quot;id&quot;: &quot;claude-sonnet-4-20250514&quot;,
          &quot;name&quot;: &quot;Claude Sonnet 4&quot;,
          &quot;cost_per_1m_in&quot;: 3,
          &quot;cost_per_1m_out&quot;: 15,
          &quot;cost_per_1m_in_cached&quot;: 3.75,
          &quot;cost_per_1m_out_cached&quot;: 0.3,
          &quot;context_window&quot;: 200000,
          &quot;default_max_tokens&quot;: 50000,
          &quot;can_reason&quot;: true,
          &quot;supports_attachments&quot;: true
        }
      ]
    }
  }
}
```

### Amazon Bedrock

Crush currently supports running Anthropic models through Bedrock, with caching disabled.

- A Bedrock provider will appear once you have AWS configured, i.e. `aws configure`
- Crush also expects the `AWS_REGION` or `AWS_DEFAULT_REGION` to be set
- To use a specific AWS profile set `AWS_PROFILE` in your environment, i.e. `AWS_PROFILE=myprofile crush`
- Alternatively to `aws configure`, you can also just set `AWS_BEARER_TOKEN_BEDROCK`

### Vertex AI Platform

Vertex AI will appear in the list of available providers when `VERTEXAI_PROJECT` and `VERTEXAI_LOCATION` are set. You will also need to be authenticated:

```bash
gcloud auth application-default login
```

To add specific models to the configuration, configure as such:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;providers&quot;: {
    &quot;vertexai&quot;: {
      &quot;models&quot;: [
        {
          &quot;id&quot;: &quot;claude-sonnet-4@20250514&quot;,
          &quot;name&quot;: &quot;VertexAI Sonnet 4&quot;,
          &quot;cost_per_1m_in&quot;: 3,
          &quot;cost_per_1m_out&quot;: 15,
          &quot;cost_per_1m_in_cached&quot;: 3.75,
          &quot;cost_per_1m_out_cached&quot;: 0.3,
          &quot;context_window&quot;: 200000,
          &quot;default_max_tokens&quot;: 50000,
          &quot;can_reason&quot;: true,
          &quot;supports_attachments&quot;: true
        }
      ]
    }
  }
}
```

### Local Models

Local models can also be configured via OpenAI-compatible API. Here are two common examples:

#### Ollama

```json
{
  &quot;providers&quot;: {
    &quot;ollama&quot;: {
      &quot;name&quot;: &quot;Ollama&quot;,
      &quot;base_url&quot;: &quot;http://localhost:11434/v1/&quot;,
      &quot;type&quot;: &quot;openai-compat&quot;,
      &quot;models&quot;: [
        {
          &quot;name&quot;: &quot;Qwen 3 30B&quot;,
          &quot;id&quot;: &quot;qwen3:30b&quot;,
          &quot;context_window&quot;: 256000,
          &quot;default_max_tokens&quot;: 20000
        }
      ]
    }
  }
}
```

#### LM Studio

```json
{
  &quot;providers&quot;: {
    &quot;lmstudio&quot;: {
      &quot;name&quot;: &quot;LM Studio&quot;,
      &quot;base_url&quot;: &quot;http://localhost:1234/v1/&quot;,
      &quot;type&quot;: &quot;openai-compat&quot;,
      &quot;models&quot;: [
        {
          &quot;name&quot;: &quot;Qwen 3 30B&quot;,
          &quot;id&quot;: &quot;qwen/qwen3-30b-a3b-2507&quot;,
          &quot;context_window&quot;: 256000,
          &quot;default_max_tokens&quot;: 20000
        }
      ]
    }
  }
}
```

## Logging

Sometimes you need to look at logs. Luckily, Crush logs all sorts of
stuff. Logs are stored in `./.crush/logs/crush.log` relative to the project.

The CLI also contains some helper commands to make perusing recent logs easier:

```bash
# Print the last 1000 lines
crush logs

# Print the last 500 lines
crush logs --tail 500

# Follow logs in real time
crush logs --follow
```

Want more logging? Run `crush` with the `--debug` flag, or enable it in the
config:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;debug&quot;: true,
    &quot;debug_lsp&quot;: true
  }
}
```

## Provider Auto-Updates

By default, Crush automatically checks for the latest and greatest list of
providers and models from [Catwalk](https://github.com/charmbracelet/catwalk),
the open source Crush provider database. This means that when new providers and
models are available, or when model metadata changes, Crush automatically
updates your local configuration.

### Disabling automatic provider updates

For those with restricted internet access, or those who prefer to work in
air-gapped environments, this might not be want you want, and this feature can
be disabled.

To disable automatic provider updates, set `disable_pro

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[influxdata/telegraf]]></title>
            <link>https://github.com/influxdata/telegraf</link>
            <guid>https://github.com/influxdata/telegraf</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:15 GMT</pubDate>
            <description><![CDATA[Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/influxdata/telegraf">influxdata/telegraf</a></h1>
            <p>Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.</p>
            <p>Language: Go</p>
            <p>Stars: 16,664</p>
            <p>Forks: 5,762</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># ![tiger](assets/TelegrafTigerSmall.png &quot;tiger&quot;) Telegraf

[![GoDoc](https://img.shields.io/badge/doc-reference-00ADD8.svg?logo=go)](https://godoc.org/github.com/influxdata/telegraf)
[![Docker pulls](https://img.shields.io/docker/pulls/library/telegraf.svg)](https://hub.docker.com/_/telegraf/)
[![Go Report Card](https://goreportcard.com/badge/github.com/influxdata/telegraf)](https://goreportcard.com/report/github.com/influxdata/telegraf)
[![Circle CI](https://circleci.com/gh/influxdata/telegraf.svg?style=svg)](https://circleci.com/gh/influxdata/telegraf)

Telegraf is an agent for collecting, processing, aggregating, and writing
metrics, logs, and other arbitrary data.

* Offers a comprehensive suite of over 300 plugins, covering a wide range of
  functionalities including system monitoring, cloud services, and message
  passing
* Enables the integration of user-defined code to collect, transform, and
  transmit data efficiently
* Compiles into a standalone static binary without any external dependencies,
  ensuring a streamlined deployment process
* Utilizes TOML for configuration, providing a user-friendly and unambiguous
  setup experience
* Developed with contributions from a diverse community of over 1,200
  contributors

Users can choose plugins from a wide range of topics, including but not limited
to:

* Devices: [OPC UA][], [Modbus][]
* Logs: [File][], [Tail][], [Directory Monitor][]
* Messaging: [AMQP][], [Kafka][], [MQTT][]
* Monitoring: [OpenTelemetry][], [Prometheus][]
* Networking: [Cisco TelemetryMDT][], [gNMI][]
* System monitoring: [CPU][], [Memory][], [Disk][], [Network][], [SMART][],
  [Docker][], [Nvidia SMI][], etc.
* Universal: [Exec][], [HTTP][], [HTTP Listener][], [SNMP][], [SQL][]
* Windows: [Event Log][], [Management Instrumentation][],
  [Performance Counters][]

## üî® Installation

For binary builds, Docker images, RPM &amp; DEB packages, and other builds of
Telegraf, please see the [install guide](/docs/INSTALL_GUIDE.md).

See the [releases documentation](/docs/RELEASES.md) for details on versioning
and when releases are made.

## üíª Usage

Users define a TOML configuration with the plugins and settings they wish to
use, then pass that configuration to Telegraf. The Telegraf agent then
collects data from inputs at each interval and sends data to outputs at each
flush interval.

For a basic walkthrough see [quick start](/docs/QUICK_START.md).

## üìñ Documentation

For a full list of documentation including tutorials, reference and other
material, start with the [/docs directory](/docs/README.md).

Additionally, each plugin has its own README that includes details about how to
configure, use, and sometimes debug or troubleshoot. Look under the
[/plugins directory](/plugins/) for specific plugins.

Here are some commonly used documents:

* [Changelog](/CHANGELOG.md)
* [Configuration](/docs/CONFIGURATION.md)
* [FAQ](/docs/FAQ.md)
* [Releases](https://github.com/influxdata/telegraf/releases)
* [Security](/SECURITY.md)

## ‚ù§Ô∏è Contribute

[![Contribute](https://img.shields.io/badge/contribute-to_telegraf-blue.svg?logo=influxdb)](https://github.com/influxdata/telegraf/blob/master/CONTRIBUTING.md)

We love our community of over 1,200 contributors! Many of the plugins included
in Telegraf were originally contributed by community members. Check out
our [contributing guide](CONTRIBUTING.md) if you are interested in helping out.
Also, join us on our [Community Slack](https://influxdata.com/slack) or
[Community Forums](https://community.influxdata.com/) if you have questions or
comments for our engineering teams.

If you are completely new to Telegraf and InfluxDB, you can also enroll for free
at [InfluxDB university](https://www.influxdata.com/university/) to take courses
to learn more.

## ‚ÑπÔ∏è Support

[![Slack](https://img.shields.io/badge/slack-join_chat-blue.svg?logo=slack)](https://www.influxdata.com/slack)
[![Forums](https://img.shields.io/badge/discourse-join_forums-blue.svg?logo=discourse)](https://community.influxdata.com/)

Please use the [Community Slack](https://influxdata.com/slack) or
[Community Forums](https://community.influxdata.com/) if you have questions or
comments for our engineering teams. GitHub issues are limited to actual issues
and feature requests only.

## üìú License

[![MIT](https://img.shields.io/badge/license-MIT-blue)](https://github.com/influxdata/telegraf/blob/master/LICENSE)

[OPC UA]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opcua
[Modbus]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/modbus
[File]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/file
[Tail]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/tail
[Directory Monitor]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/directory_monitor
[AMQP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/amqp_consumer
[Kafka]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/kafka_consumer
[MQTT]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mqtt_consumer
[OpenTelemetry]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opentelemetry
[Prometheus]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/prometheus
[Cisco TelemetryMDT]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cisco_telemetry_mdt
[gNMI]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/gnmi
[CPU]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cpu
[Memory]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mem
[Disk]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/disk
[Network]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/net
[SMART]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/smartctl
[Docker]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker
[Nvidia SMI]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/nvidia_smi
[Exec]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/exec
[HTTP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http
[HTTP Listener]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http_listener_v2
[SNMP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/snmp
[SQL]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/sql
[Event Log]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_eventlog
[Management Instrumentation]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_wmi
[Performance Counters]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[docker/cagent]]></title>
            <link>https://github.com/docker/cagent</link>
            <guid>https://github.com/docker/cagent</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:14 GMT</pubDate>
            <description><![CDATA[Agent Builder and Runtime by Docker Engineering]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/docker/cagent">docker/cagent</a></h1>
            <p>Agent Builder and Runtime by Docker Engineering</p>
            <p>Language: Go</p>
            <p>Stars: 1,920</p>
            <p>Forks: 229</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># ü§ñ Docker `cagent` ü§ñ

&gt; A powerful, easy-to-use, customizable multi-agent runtime that orchestrates AI
&gt; agents with specialized capabilities and tools, and the interactions between
&gt; agents.

![cagent in action](docs/demo.gif)

## ‚ú® What is Docker `cagent`? ‚ú®

Docker `cagent` lets you create and run intelligent AI agents, where each agent has
specialized knowledge, tools and capabilities.

Think of it as allowing you to quickly build, share and run a team of virtual
experts that collaborate to solve complex problems for you.

**And it&#039;s dead easy to use! In most cases, you don&#039;t need to write a single line of code.**

## üéØ Key Features

- **üèóÔ∏è Multi-agent architecture** - Create specialized agents for different
  domains.
- **üîß Rich tool ecosystem** - Agents can use external tools and APIs via the
  MCP protocol.
- **üîÑ Smart delegation** - Agents can automatically route tasks to the most
  suitable specialist.
- **üìù YAML configuration** - Declarative model and agent configuration.
- **üí≠ Advanced reasoning** - Built-in &quot;think&quot;, &quot;todo&quot; and &quot;memory&quot; tools for
  complex problem-solving.
- **üîç RAG (Retrieval-Augmented Generation)** - Pluggable retrieval strategies
  (BM25, chunked-embeddings, semantic-embeddings) with hybrid retrieval, result fusion and reranking support.
- **üåê AI provider agnostic** - Support for OpenAI, Anthropic, Gemini, AWS
  Bedrock, xAI, Mistral, Nebius and [Docker Model
  Runner](https://docs.docker.com/ai/model-runner/).
- **üîÄ Runtime model switching** - Change models on-the-fly during a session
  with the `/model` command, with automatic persistence across session reloads.

## Your First Agent

Creating agents with Docker `cagent` is straightforward. They are described in a `.yaml`
file, like this one:

```yaml
agents:
  root:
    model: openai/gpt-5-mini
    description: A helpful AI assistant
    instruction: |
      You are a knowledgeable assistant that helps users with various tasks.
      Be helpful, accurate, and concise in your responses.
```

+ Follow the installation instructions.
+ Create a`basic_agent.yaml` file with the above content.
+ Run it in a terminal with `cagent run basic_agent.yaml`.

Many more examples can be found [here](/examples/README.md)!

## üöÄ Installation üöÄ

### It ships with Docker Desktop!

Starting with [Docker Desktop 4.49.0](https://docs.docker.com/desktop/release-notes/#4490),
Docker `cagent` is automatically installed.

```sh
$ cagent run default &quot;Hi, what can you do for me?&quot;
```

### Using Homebrew

As an alternative, it&#039;s also on [homebrew](https://brew.sh/):

```sh
$ brew install cagent
```

### Using binary releases

Finally, [Prebuilt binaries](https://github.com/docker/cagent/releases) for Windows,
macOS and Linux can be found on the release page of the [project&#039;s GitHub
repository](https://github.com/docker/cagent/releases).

Once you&#039;ve downloaded the appropriate binary for your platform, you may need to
give it executable permissions. On macOS and Linux, this is done with the
following command:

```sh
# linux amd64 build example
chmod +x /path/to/downloads/cagent-linux-amd64
```

You can then rename the binary to Docker `cagent` and configure your `PATH` to be able
to find it (configuration varies by platform).

### **Set your API keys**

Based on the models you configure your agents to use, you will need to set the
corresponding provider API key accordingly, all these keys are optional, you
will likely need at least one of these, though:

```bash
export OPENAI_API_KEY=your_api_key_here              # For OpenAI models
export ANTHROPIC_API_KEY=your_api_key_here           # For Anthropic models
export GOOGLE_API_KEY=your_api_key_here              # For Gemini models
export AWS_BEARER_TOKEN_BEDROCK=your_api_key_here    # For AWS Bedrock available models
export XAI_API_KEY=your_api_key_here                 # For xAI models
export NEBIUS_API_KEY=your_api_key_here              # For Nebius models
export MISTRAL_API_KEY=your_api_key_here             # For Mistral models
```

**Note:** For the different AWS Bedrock authentication options, take a look [here](docs/USAGE.md#aws-bedrock-provider-usage).

### Run Agents!

```bash
# Run an agent!
cagent run ./examples/pirate.yaml

# or specify a different starting agent from the config, useful for agent teams
cagent run ./examples/gopher.yaml -a planner

# or run directly from an image reference.
# Here we&#039;re pulling the pirate agent from the creek repository
cagent run creek/pirate
```

Many more examples can be found [here](/examples/README.md)!

### Multi-agent team example

```yaml
agents:
  root:
    model: claude
    description: &quot;Main coordinator agent that delegates tasks and manages workflow&quot;
    instruction: |
      You are the root coordinator agent. Your job is to:
      1. Understand user requests and break them down into manageable tasks
      2. Delegate appropriate tasks to your helper agent
      3. Coordinate responses and ensure tasks are completed properly
      4. Provide final responses to the user
      When you receive a request, analyze what needs to be done and decide whether to:
      - Handle it yourself if it&#039;s simple
      - Delegate to the helper agent if it requires specific assistance
      - Break complex requests into multiple sub-tasks
    sub_agents: [&quot;helper&quot;]

  helper:
    model: claude
    description: &quot;Assistant agent that helps with various tasks as directed by the root agent&quot;
    instruction: |
      You are a helpful assistant agent. Your role is to:
      1. Complete specific tasks assigned by the root agent
      2. Provide detailed and accurate responses
      3. Ask for clarification if tasks are unclear
      4. Report back to the root agent with your results

      Focus on being thorough and helpful in whatever task you&#039;re given.

models:
  claude:
    provider: anthropic
    model: claude-sonnet-4-0
    max_tokens: 64000
```

You&#039;ll find a curated list of agents examples, spread into 3 categories,
[Basic](https://github.com/docker/cagent/tree/main/examples#basic-configurations),
[Advanced](https://github.com/docker/cagent/tree/main/examples#advanced-configurations)
and
[multi-agents](https://github.com/docker/cagent/tree/main/examples#multi-agent-configurations)
in the `/examples/` directory.

### DMR (Docker Model Runner) provider options

When using the `dmr` provider, you can use the `provider_opts` key for DMR
runtime-specific (e.g. llama.cpp/vllm) options and speculative decoding:

```yaml
models:
  local-qwen:
    provider: dmr
    model: ai/qwen3
    max_tokens: 8192
    provider_opts:
      # general flags passed to the underlying model runtime
      runtime_flags: [&quot;--ngl=33&quot;, &quot;--repeat-penalty=1.2&quot;, ...] # or comma/space-separated string
      # speculative decoding for faster inference
      speculative_draft_model: ai/qwen3:1B
      speculative_num_tokens: 5
      speculative_acceptance_rate: 0.8
```

The default base_url Docker `cagent` will use for DMR providers is
`http://localhost:12434/engines/llama.cpp/v1`. DMR itself might need to be
enabled via [Docker Desktop&#039;s
settings](https://docs.docker.com/ai/model-runner/get-started/#enable-dmr-in-docker-desktop)
on macOS and Windows, and via the command-line on [Docker CE on
Linux](https://docs.docker.com/ai/model-runner/get-started/#enable-dmr-in-docker-engine).

See the [DMR Provider documentation](docs/USAGE.md#dmr-docker-model-runner-provider-usage) for more details on runtime flags and speculative decoding options.

### Improving an agent with MCP tools

Docker `cagent` supports MCP servers, enabling agents to use a wide variety of external
tools and services.

It supports all transport types: `stdio`, `http` and `sse`.

Giving an agent access to tools via MCP is a good way to greatly improve its
capabilities, the quality of its results and its general usefulness.

Get started with the [Docker MCP
Toolkit](https://docs.docker.com/ai/mcp-catalog-and-toolkit/toolkit/) and
[catalog](https://docs.docker.com/ai/mcp-catalog-and-toolkit/catalog/)

Here, we&#039;re giving the same basic agent from the example above access to a
**containerized** `duckduckgo` mcp server and its tools by using Docker&#039;s MCP
Gateway:

```yaml
agents:
  root:
    model: openai/gpt-5-mini
    description: A helpful AI assistant
    instruction: |
      You are a knowledgeable assistant that helps users with various tasks.
      Be helpful, accurate, and concise in your responses.
    toolsets:
      - type: mcp
        ref: docker:duckduckgo
```

When using a containerized server via the `Docker MCP gateway`, you can configure
any required settings/secrets/authentication using the [Docker MCP
Toolkit](https://docs.docker.com/ai/mcp-catalog-and-toolkit/toolkit/#example-use-the-github-official-mcp-server)
in Docker Desktop.

Aside from the containerized MCP servers the `Docker MCP Gateway` provides, any
standard MCP server can be used with Docker `cagent`!

Here&#039;s an example similar to the above but adding `read_file` and `write_file`
tools from the `rust-mcp-filesystem` MCP server:

```yaml
agents:
  root:
    model: openai/gpt-5-mini
    description: A helpful AI assistant
    instruction: |
      You are a knowledgeable assistant that helps users with various tasks.
      Be helpful, accurate, and concise in your responses. Write your search results to disk.
    toolsets:
      - type: mcp
        ref: docker:duckduckgo
      - type: mcp
        command: rust-mcp-filesystem # installed with `cargo install rust-mcp-filesystem`
        args: [&quot;--allow-write&quot;, &quot;.&quot;]
        tools: [&quot;read_file&quot;, &quot;write_file&quot;] # Optional: specific tools only
        env:
          - &quot;RUST_LOG=debug&quot;
```

See [the USAGE docs](./docs/USAGE.md#tool-configuration) for more detailed
information and examples

### Exposing agents as MCP tools

Docker `cagent` can expose agents as MCP tools via the `cagent mcp` command,
allowing other MCP clients to use your agents over MCP.

Each agent in your configuration becomes an MCP tool with its description.

```bash
# Start MCP server with local file
cagent mcp ./examples/dev-team.yaml

# Or use an OCI artifact
cagent mcp agentcatalog/pirate
```

This exposes each agent as a tool (e.g., `root`, `designer`, `awesome_engineer`) that MCP clients can call:

```json
{
  &quot;method&quot;: &quot;tools/call&quot;,
  &quot;params&quot;: {
    &quot;name&quot;: &quot;designer&quot;,
    &quot;arguments&quot;: {
      &quot;message&quot;: &quot;Design a login page&quot;
    }
  }
}
```

See [MCP Mode documentation](./docs/MCP-MODE.md) for detailed instructions on exposing your agents through MCP with Claude Desktop, Claude Code, and other MCP clients.

### RAG (Retrieval-Augmented Generation)

Give your agents access to your documents with Docker `cagent`&#039;s modular RAG system. It supports multiple retrieval strategies that can be used individually or combined for hybrid search.

### Quick RAG Example

```yaml
models:
  embedder:
    provider: openai
    model: text-embedding-3-small

rag:
  my_knowledge_base:
    docs: [./documents, ./pdfs]
    strategies:
      - type: chunked-embeddings
        model: embedder
        threshold: 0.5
        chunking:
          size: 1000
          overlap: 100
    results:
      limit: 5

agents:
  root:
    model: openai/gpt-4o
    instruction: |
      You are an assistant with access to an internal knowledge base.
      Use the knowledge base to gather context before answering user questions
    rag: [my_knowledge_base]
```

#### Hybrid Retrieval (Chunked-Embeddings + BM25)

Combine semantic search (chunked-embeddings) with keyword search (BM25) for best results:

```yaml
rag:
  hybrid_search:
    docs: [./shared_docs]
    
    strategies:
      - type: chunked-embeddings
        model: embedder
        threshold: 0.5
        limit: 20
        chunking:
          size: 1000
          overlap: 100
      
      - type: bm25
        k1: 1.5
        b: 0.75
        threshold: 0.3
        limit: 15
        chunking:
          size: 1000
          overlap: 100
    
    results:
      fusion:
        strategy: rrf  # Reciprocal Rank Fusion
        k: 60
      deduplicate: true
      limit: 5

agents:
  root:
    model: openai/gpt-4o
    rag: [hybrid_search]
```

**Features:**
- **Multiple strategies**: Vector embeddings, semantic embeddings, BM25 (keyword), or combinations
- **Parallel execution**: Strategies run concurrently for fast results
- **Pluggable fusion**: RRF, weighted, or max score combining
- **Result reranking**: Re-score results with specialized models for improved relevance
- **Per-strategy configuration**: Different thresholds, limits, and documents
- **Auto file watching**: Reindex automatically on file changes

#### Result Reranking

Improve search quality by re-scoring retrieved results with a reranking model:

```yaml
rag:
  knowledge_base:
    docs: [./documents]
    strategies:
      - type: chunked-embeddings
        model: openai/text-embedding-3-small
        limit: 20  # Retrieve more candidates for reranking
    
    results:
      reranking:
        model: openai/gpt-4.1-mini   # Any chat model or DMR reranker
        top_k: 10                   # Only rerank top 10 (optional)
        threshold: 0.3              # Filter low-scoring results (optional)
        criteria: |                 # Domain-specific relevance guidance (optional, not used with DMR reranking specific models)
          Prioritize recent documentation and practical examples.
          Documents from official sources are more relevant.
      limit: 5  # Final top results after reranking
```

**Supported providers:** DMR (native `/rerank` endpoint), OpenAI, Anthropic, Gemini (via structured outputs)  
**Note:** Temperature defaults to 0.0 for more deterministic scoring when not explicitly set.

See the [RAG documentation in USAGE.md](docs/USAGE.md#rag-configuration) for complete details, examples, and debugging guides.

## Quickly generate agents and agent teams with `cagent new`

Using the command `cagent new` you can quickly generate agents or multi-agent
teams using a single prompt!  
`cagent` has a built-in agent dedicated to this task.

To use the feature, you must have an Anthropic, OpenAI or Google API key
available in your environment or specify a local model to run with DMR (Docker
Model Runner).

You can choose what provider and model gets used by passing the `--model
provider/modelname` flag to `cagent new`

If `--model` is unspecified, `cagent new` will automatically choose between
these three providers in order based on the first api key it finds in your
environment.

```sh
export ANTHROPIC_API_KEY=your_api_key_here  # first choice. default model claude-sonnet-4-0
export OPENAI_API_KEY=your_api_key_here     # if anthropic key not set. default model gpt-5-mini
export GOOGLE_API_KEY=your_api_key_here     # if anthropic and openai keys are not set. default model gemini-2.5-flash
```

`--max-tokens` can be specified to override the context limit used.  
When using DMR, the default is 16k to limit memory usage. With all other
providers the default is 64k

`--max-iterations` can be specified to override how many times the agent is
allowed to loop when doing tool calling etc. When using DMR, the default is set
to 20 (small local models have the highest chance of getting confused and
looping endlessly). For all other providers, the default is 0 (unlimited).

Example of provider, model, context size and max iterations overriding:

```sh
# Use GPT-5 via OpenAI
cagent new --model openai/gpt-5

# Use a local model (ai/gemma3-qat:12B) via DMR
cagent new --model dmr/ai/gemma3-qat:12B

# Override the max_tokens used during generation, default is 64k, 16k when using the dmr provider
cagent new --model openai/gpt-5-mini --max-tokens 32000

# Override max_iterations to limit how much the model can loop autonomously when tool calling
cagent new --model dmr/ai/gemma3n:2B-F16 --max-iterations 15
```

---

```
$ cagent new

------- Welcome to cagent! -------
(Ctrl+C to stop the agent and exit)

What should your agent/agent team do? (describe its purpose):

&gt; I need an agent team that connects to &lt;some-service&gt; and does...
```

## Pushing and pulling agents from Docker Hub

### `cagent push`

Agent configurations can be packaged and shared to Docker Hub using the `cagent
push` command

```sh
cagent push ./&lt;agent-file&gt;.yaml namespace/reponame
```

Docker `cagent` will automatically build an OCI image and push it to the desired
repository using your Docker credentials

### `cagent pull`

Pulling agents from Docker Hub is also just one `cagent pull` command away.

```sh
cagent pull creek/pirate
```

`cagent` will pull the image, extract the .yaml file and place it in your working
directory for ease of use.

`cagent run creek.yaml` will run your newly pulled agent

## Usage

More details on the usage and configuration of Docker `cagent` can be found in
[USAGE.md](/docs/USAGE.md)

## Telemetry

We track anonymous usage data to improve the tool. See
[TELEMETRY.md](/docs/TELEMETRY.md) for details.

## Contributing

Want to hack on Docker `cagent`, or help us fix bugs and build out some features? üîß

Read the information on how to build from source and contribute to the project
in [CONTRIBUTING.md](/docs/CONTRIBUTING.md)

## DogFooding: using Docker `cagent` to code on Docker `cagent`

A smart way to improve Docker `cagent`&#039;s codebase and feature set is to do it with the
help of a Docker `cagent` agent!

We have one that we use and that you should use too:

```sh
cd cagent
cagent run ./golang_developer.yaml
```

This agent is an _expert Golang developer specializing in the Docker `cagent`
multi-agent AI system architecture_.

Ask it anything about Docker `cagent`. It can be questions about the current code or
about improvements to the code. It can also fix issues and implement new
features!

## Share your feedback

We‚Äôd love to hear your thoughts on this project. Feel free to join the [Docker Community Slack workspace](http://dockr.ly/comm-slack) and the [cagent Slack channel](https://dockercommunity.slack.com/archives/C09DASHHRU4).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[go-chi/chi]]></title>
            <link>https://github.com/go-chi/chi</link>
            <guid>https://github.com/go-chi/chi</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:13 GMT</pubDate>
            <description><![CDATA[lightweight, idiomatic and composable router for building Go HTTP services]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/go-chi/chi">go-chi/chi</a></h1>
            <p>lightweight, idiomatic and composable router for building Go HTTP services</p>
            <p>Language: Go</p>
            <p>Stars: 21,461</p>
            <p>Forks: 1,063</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># &lt;img alt=&quot;chi&quot; src=&quot;https://cdn.rawgit.com/go-chi/chi/master/_examples/chi.svg&quot; width=&quot;220&quot; /&gt;


[![GoDoc Widget]][GoDoc]

`chi` is a lightweight, idiomatic and composable router for building Go HTTP services. It&#039;s
especially good at helping you write large REST API services that are kept maintainable as your
project grows and changes. `chi` is built on the new `context` package introduced in Go 1.7 to
handle signaling, cancelation and request-scoped values across a handler chain.

The focus of the project has been to seek out an elegant and comfortable design for writing
REST API servers, written during the development of the Pressly API service that powers our
public API service, which in turn powers all of our client-side applications.

The key considerations of chi&#039;s design are: project structure, maintainability, standard http
handlers (stdlib-only), developer productivity, and deconstructing a large system into many small
parts. The core router `github.com/go-chi/chi` is quite small (less than 1000 LOC), but we&#039;ve also
included some useful/optional subpackages: [middleware](/middleware), [render](https://github.com/go-chi/render)
and [docgen](https://github.com/go-chi/docgen). We hope you enjoy it too!

## Install

```sh
go get -u github.com/go-chi/chi/v5
```


## Features

* **Lightweight** - cloc&#039;d in ~1000 LOC for the chi router
* **Fast** - yes, see [benchmarks](#benchmarks)
* **100% compatible with net/http** - use any http or middleware pkg in the ecosystem that is also compatible with `net/http`
* **Designed for modular/composable APIs** - middlewares, inline middlewares, route groups and sub-router mounting
* **Context control** - built on new `context` package, providing value chaining, cancellations and timeouts
* **Robust** - in production at Pressly, Cloudflare, Heroku, 99Designs, and many others (see [discussion](https://github.com/go-chi/chi/issues/91))
* **Doc generation** - `docgen` auto-generates routing documentation from your source to JSON or Markdown
* **Go.mod support** - as of v5, go.mod support (see [CHANGELOG](https://github.com/go-chi/chi/blob/master/CHANGELOG.md))
* **No external dependencies** - plain ol&#039; Go stdlib + net/http


## Examples

See [_examples/](https://github.com/go-chi/chi/blob/master/_examples/) for a variety of examples.


**As easy as:**

```go
package main

import (
	&quot;net/http&quot;

	&quot;github.com/go-chi/chi/v5&quot;
	&quot;github.com/go-chi/chi/v5/middleware&quot;
)

func main() {
	r := chi.NewRouter()
	r.Use(middleware.Logger)
	r.Get(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) {
		w.Write([]byte(&quot;welcome&quot;))
	})
	http.ListenAndServe(&quot;:3000&quot;, r)
}
```

**REST Preview:**

Here is a little preview of what routing looks like with chi. Also take a look at the generated routing docs
in JSON ([routes.json](https://github.com/go-chi/chi/blob/master/_examples/rest/routes.json)) and in
Markdown ([routes.md](https://github.com/go-chi/chi/blob/master/_examples/rest/routes.md)).

I highly recommend reading the source of the [examples](https://github.com/go-chi/chi/blob/master/_examples/) listed
above, they will show you all the features of chi and serve as a good form of documentation.

```go
import (
  //...
  &quot;context&quot;
  &quot;github.com/go-chi/chi/v5&quot;
  &quot;github.com/go-chi/chi/v5/middleware&quot;
)

func main() {
  r := chi.NewRouter()

  // A good base middleware stack
  r.Use(middleware.RequestID)
  r.Use(middleware.RealIP)
  r.Use(middleware.Logger)
  r.Use(middleware.Recoverer)

  // Set a timeout value on the request context (ctx), that will signal
  // through ctx.Done() that the request has timed out and further
  // processing should be stopped.
  r.Use(middleware.Timeout(60 * time.Second))

  r.Get(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) {
    w.Write([]byte(&quot;hi&quot;))
  })

  // RESTy routes for &quot;articles&quot; resource
  r.Route(&quot;/articles&quot;, func(r chi.Router) {
    r.With(paginate).Get(&quot;/&quot;, listArticles)                           // GET /articles
    r.With(paginate).Get(&quot;/{month}-{day}-{year}&quot;, listArticlesByDate) // GET /articles/01-16-2017

    r.Post(&quot;/&quot;, createArticle)                                        // POST /articles
    r.Get(&quot;/search&quot;, searchArticles)                                  // GET /articles/search

    // Regexp url parameters:
    r.Get(&quot;/{articleSlug:[a-z-]+}&quot;, getArticleBySlug)                // GET /articles/home-is-toronto

    // Subrouters:
    r.Route(&quot;/{articleID}&quot;, func(r chi.Router) {
      r.Use(ArticleCtx)
      r.Get(&quot;/&quot;, getArticle)                                          // GET /articles/123
      r.Put(&quot;/&quot;, updateArticle)                                       // PUT /articles/123
      r.Delete(&quot;/&quot;, deleteArticle)                                    // DELETE /articles/123
    })
  })

  // Mount the admin sub-router
  r.Mount(&quot;/admin&quot;, adminRouter())

  http.ListenAndServe(&quot;:3333&quot;, r)
}

func ArticleCtx(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    articleID := chi.URLParam(r, &quot;articleID&quot;)
    article, err := dbGetArticle(articleID)
    if err != nil {
      http.Error(w, http.StatusText(404), 404)
      return
    }
    ctx := context.WithValue(r.Context(), &quot;article&quot;, article)
    next.ServeHTTP(w, r.WithContext(ctx))
  })
}

func getArticle(w http.ResponseWriter, r *http.Request) {
  ctx := r.Context()
  article, ok := ctx.Value(&quot;article&quot;).(*Article)
  if !ok {
    http.Error(w, http.StatusText(422), 422)
    return
  }
  w.Write([]byte(fmt.Sprintf(&quot;title:%s&quot;, article.Title)))
}

// A completely separate router for administrator routes
func adminRouter() http.Handler {
  r := chi.NewRouter()
  r.Use(AdminOnly)
  r.Get(&quot;/&quot;, adminIndex)
  r.Get(&quot;/accounts&quot;, adminListAccounts)
  return r
}

func AdminOnly(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()
    perm, ok := ctx.Value(&quot;acl.permission&quot;).(YourPermissionType)
    if !ok || !perm.IsAdmin() {
      http.Error(w, http.StatusText(403), 403)
      return
    }
    next.ServeHTTP(w, r)
  })
}
```


## Router interface

chi&#039;s router is based on a kind of [Patricia Radix trie](https://en.wikipedia.org/wiki/Radix_tree).
The router is fully compatible with `net/http`.

Built on top of the tree is the `Router` interface:

```go
// Router consisting of the core routing methods used by chi&#039;s Mux,
// using only the standard net/http.
type Router interface {
	http.Handler
	Routes

	// Use appends one or more middlewares onto the Router stack.
	Use(middlewares ...func(http.Handler) http.Handler)

	// With adds inline middlewares for an endpoint handler.
	With(middlewares ...func(http.Handler) http.Handler) Router

	// Group adds a new inline-Router along the current routing
	// path, with a fresh middleware stack for the inline-Router.
	Group(fn func(r Router)) Router

	// Route mounts a sub-Router along a `pattern` string.
	Route(pattern string, fn func(r Router)) Router

	// Mount attaches another http.Handler along ./pattern/*
	Mount(pattern string, h http.Handler)

	// Handle and HandleFunc adds routes for `pattern` that matches
	// all HTTP methods.
	Handle(pattern string, h http.Handler)
	HandleFunc(pattern string, h http.HandlerFunc)

	// Method and MethodFunc adds routes for `pattern` that matches
	// the `method` HTTP method.
	Method(method, pattern string, h http.Handler)
	MethodFunc(method, pattern string, h http.HandlerFunc)

	// HTTP-method routing along `pattern`
	Connect(pattern string, h http.HandlerFunc)
	Delete(pattern string, h http.HandlerFunc)
	Get(pattern string, h http.HandlerFunc)
	Head(pattern string, h http.HandlerFunc)
	Options(pattern string, h http.HandlerFunc)
	Patch(pattern string, h http.HandlerFunc)
	Post(pattern string, h http.HandlerFunc)
	Put(pattern string, h http.HandlerFunc)
	Trace(pattern string, h http.HandlerFunc)

	// NotFound defines a handler to respond whenever a route could
	// not be found.
	NotFound(h http.HandlerFunc)

	// MethodNotAllowed defines a handler to respond whenever a method is
	// not allowed.
	MethodNotAllowed(h http.HandlerFunc)
}

// Routes interface adds two methods for router traversal, which is also
// used by the github.com/go-chi/docgen package to generate documentation for Routers.
type Routes interface {
	// Routes returns the routing tree in an easily traversable structure.
	Routes() []Route

	// Middlewares returns the list of middlewares in use by the router.
	Middlewares() Middlewares

	// Match searches the routing tree for a handler that matches
	// the method/path - similar to routing a http request, but without
	// executing the handler thereafter.
	Match(rctx *Context, method, path string) bool
}
```

Each routing method accepts a URL `pattern` and chain of `handlers`. The URL pattern
supports named params (ie. `/users/{userID}`) and wildcards (ie. `/admin/*`). URL parameters
can be fetched at runtime by calling `chi.URLParam(r, &quot;userID&quot;)` for named parameters
and `chi.URLParam(r, &quot;*&quot;)` for a wildcard parameter.


### Middleware handlers

chi&#039;s middlewares are just stdlib net/http middleware handlers. There is nothing special
about them, which means the router and all the tooling is designed to be compatible and
friendly with any middleware in the community. This offers much better extensibility and reuse
of packages and is at the heart of chi&#039;s purpose.

Here is an example of a standard net/http middleware where we assign a context key `&quot;user&quot;`
the value of `&quot;123&quot;`. This middleware sets a hypothetical user identifier on the request
context and calls the next handler in the chain.

```go
// HTTP middleware setting a value on the request context
func MyMiddleware(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    // create new context from `r` request context, and assign key `&quot;user&quot;`
    // to value of `&quot;123&quot;`
    ctx := context.WithValue(r.Context(), &quot;user&quot;, &quot;123&quot;)

    // call the next handler in the chain, passing the response writer and
    // the updated request object with the new context value.
    //
    // note: context.Context values are nested, so any previously set
    // values will be accessible as well, and the new `&quot;user&quot;` key
    // will be accessible from this point forward.
    next.ServeHTTP(w, r.WithContext(ctx))
  })
}
```


### Request handlers

chi uses standard net/http request handlers. This little snippet is an example of a http.Handler
func that reads a user identifier from the request context - hypothetically, identifying
the user sending an authenticated request, validated+set by a previous middleware handler.

```go
// HTTP handler accessing data from the request context.
func MyRequestHandler(w http.ResponseWriter, r *http.Request) {
  // here we read from the request context and fetch out `&quot;user&quot;` key set in
  // the MyMiddleware example above.
  user := r.Context().Value(&quot;user&quot;).(string)

  // respond to the client
  w.Write([]byte(fmt.Sprintf(&quot;hi %s&quot;, user)))
}
```


### URL parameters

chi&#039;s router parses and stores URL parameters right onto the request context. Here is
an example of how to access URL params in your net/http handlers. And of course, middlewares
are able to access the same information.

```go
// HTTP handler accessing the url routing parameters.
func MyRequestHandler(w http.ResponseWriter, r *http.Request) {
  // fetch the url parameter `&quot;userID&quot;` from the request of a matching
  // routing pattern. An example routing pattern could be: /users/{userID}
  userID := chi.URLParam(r, &quot;userID&quot;)

  // fetch `&quot;key&quot;` from the request context
  ctx := r.Context()
  key := ctx.Value(&quot;key&quot;).(string)

  // respond to the client
  w.Write([]byte(fmt.Sprintf(&quot;hi %v, %v&quot;, userID, key)))
}
```


## Middlewares

chi comes equipped with an optional `middleware` package, providing a suite of standard
`net/http` middlewares. Please note, any middleware in the ecosystem that is also compatible
with `net/http` can be used with chi&#039;s mux.

### Core middlewares

----------------------------------------------------------------------------------------------------
| chi/middleware Handler | description                                                             |
| :--------------------- | :---------------------------------------------------------------------- |
| [AllowContentEncoding] | Enforces a whitelist of request Content-Encoding headers                |
| [AllowContentType]     | Explicit whitelist of accepted request Content-Types                    |
| [BasicAuth]            | Basic HTTP authentication                                               |
| [Compress]             | Gzip compression for clients that accept compressed responses           |
| [ContentCharset]       | Ensure charset for Content-Type request headers                         |
| [CleanPath]            | Clean double slashes from request path                                  |
| [GetHead]              | Automatically route undefined HEAD requests to GET handlers             |
| [Heartbeat]            | Monitoring endpoint to check the servers pulse                          |
| [Logger]               | Logs the start and end of each request with the elapsed processing time |
| [NoCache]              | Sets response headers to prevent clients from caching                   |
| [Profiler]             | Easily attach net/http/pprof to your routers                            |
| [RealIP]               | Sets a http.Request&#039;s RemoteAddr to either X-Real-IP or X-Forwarded-For |
| [Recoverer]            | Gracefully absorb panics and prints the stack trace                     |
| [RequestID]            | Injects a request ID into the context of each request                   |
| [RedirectSlashes]      | Redirect slashes on routing paths                                       |
| [RouteHeaders]         | Route handling for request headers                                      |
| [SetHeader]            | Short-hand middleware to set a response header key/value                |
| [StripSlashes]         | Strip slashes on routing paths                                          |
| [Sunset]               | Sunset set Deprecation/Sunset header to response                        |
| [Throttle]             | Puts a ceiling on the number of concurrent requests                     |
| [Timeout]              | Signals to the request context when the timeout deadline is reached     |
| [URLFormat]            | Parse extension from url and put it on request context                  |
| [WithValue]            | Short-hand middleware to set a key/value on the request context         |
----------------------------------------------------------------------------------------------------

[AllowContentEncoding]: https://pkg.go.dev/github.com/go-chi/chi/middleware#AllowContentEncoding
[AllowContentType]: https://pkg.go.dev/github.com/go-chi/chi/middleware#AllowContentType
[BasicAuth]: https://pkg.go.dev/github.com/go-chi/chi/middleware#BasicAuth
[Compress]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Compress
[ContentCharset]: https://pkg.go.dev/github.com/go-chi/chi/middleware#ContentCharset
[CleanPath]: https://pkg.go.dev/github.com/go-chi/chi/middleware#CleanPath
[GetHead]: https://pkg.go.dev/github.com/go-chi/chi/middleware#GetHead
[GetReqID]: https://pkg.go.dev/github.com/go-chi/chi/middleware#GetReqID
[Heartbeat]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Heartbeat
[Logger]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Logger
[NoCache]: https://pkg.go.dev/github.com/go-chi/chi/middleware#NoCache
[Profiler]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Profiler
[RealIP]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RealIP
[Recoverer]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Recoverer
[RedirectSlashes]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RedirectSlashes
[RequestLogger]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RequestLogger
[RequestID]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RequestID
[RouteHeaders]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RouteHeaders
[SetHeader]: https://pkg.go.dev/github.com/go-chi/chi/middleware#SetHeader
[StripSlashes]: https://pkg.go.dev/github.com/go-chi/chi/middleware#StripSlashes
[Sunset]: https://pkg.go.dev/github.com/go-chi/chi/v5/middleware#Sunset
[Throttle]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Throttle
[ThrottleBacklog]: https://pkg.go.dev/github.com/go-chi/chi/middleware#ThrottleBacklog
[ThrottleWithOpts]: https://pkg.go.dev/github.com/go-chi/chi/middleware#ThrottleWithOpts
[Timeout]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Timeout
[URLFormat]: https://pkg.go.dev/github.com/go-chi/chi/middleware#URLFormat
[WithLogEntry]: https://pkg.go.dev/github.com/go-chi/chi/middleware#WithLogEntry
[WithValue]: https://pkg.go.dev/github.com/go-chi/chi/middleware#WithValue
[Compressor]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Compressor
[DefaultLogFormatter]: https://pkg.go.dev/github.com/go-chi/chi/middleware#DefaultLogFormatter
[EncoderFunc]: https://pkg.go.dev/github.com/go-chi/chi/middleware#EncoderFunc
[HeaderRoute]: https://pkg.go.dev/github.com/go-chi/chi/middleware#HeaderRoute
[HeaderRouter]: https://pkg.go.dev/github.com/go-chi/chi/middleware#HeaderRouter
[LogEntry]: https://pkg.go.dev/github.com/go-chi/chi/middleware#LogEntry
[LogFormatter]: https://pkg.go.dev/github.com/go-chi/chi/middleware#LogFormatter
[LoggerInterface]: https://pkg.go.dev/github.com/go-chi/chi/middleware#LoggerInterface
[ThrottleOpts]: https://pkg.go.dev/github.com/go-chi/chi/middleware#ThrottleOpts
[WrapResponseWriter]: https://pkg.go.dev/github.com/go-chi/chi/middleware#WrapResponseWriter

### Extra middlewares &amp; packages

Please see https://github.com/go-chi for additional packages.

--------------------------------------------------------------------------------------------------------------------
| package                                            | description                                                 |
|:---------------------------------------------------|:-------------------------------------------------------------
| [cors](https://github.com/go-chi/cors)             | Cross-origin resource sharing (CORS)                        |
| [docgen](https://github.com/go-chi/docgen)         | Print chi.Router routes at runtime                          |
| [jwtauth](https://github.com/go-chi/jwtauth)       | JWT authentication                                          |
| [hostrouter](https://github.com/go-chi/hostrouter) | Domain/host based request routing                           |
| [httplog](https://github.com/go-chi/httplog)       | Small but powerful structured HTTP request logging          |
| [httprate](https://github.com/go-chi/httprate)     | HTTP request rate limiter                                   |
| [httptracer](https://github.com/go-chi/httptracer) | HTTP request performance tracing library                    |
| [httpvcr](https://github.com/go-chi/httpvcr)       | Write deterministic tests for external sources              |
| [stampede](https://github.com/go-chi/stampede)     | HTTP request coalescer                                      |
--------------------------------------------------------------------------------------------------------------------


## context?

`context` is a tiny pkg that provides simple interface to signal context across call stacks
and goroutines. It was originally written by [Sameer Ajmani](https://github.com/Sajmani)
and is available in stdlib since go1.7.

Learn more at https://blog.golang.org/context

and..
* Docs: https://golang.org/pkg/context
* Source: https://github.com/golang/go/tree/master/src/context


## Benchmarks

The benchmark suite: https://github.com/pkieltyka/go-http-routing-benchmark

Results as of Nov 29, 2020 with Go 1.15.5 on Linux AMD 3950x

```shell
BenchmarkChi_Param          	3075895	        384 ns/op	      400 B/op      2 all

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[opencontainers/runc]]></title>
            <link>https://github.com/opencontainers/runc</link>
            <guid>https://github.com/opencontainers/runc</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:12 GMT</pubDate>
            <description><![CDATA[CLI tool for spawning and running containers according to the OCI specification]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/opencontainers/runc">opencontainers/runc</a></h1>
            <p>CLI tool for spawning and running containers according to the OCI specification</p>
            <p>Language: Go</p>
            <p>Stars: 13,010</p>
            <p>Forks: 2,253</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># runc

[![Go Report Card](https://goreportcard.com/badge/github.com/opencontainers/runc)](https://goreportcard.com/report/github.com/opencontainers/runc)
[![Go Reference](https://pkg.go.dev/badge/github.com/opencontainers/runc.svg)](https://pkg.go.dev/github.com/opencontainers/runc)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/588/badge)](https://bestpractices.coreinfrastructure.org/projects/588)
[![gha/validate](https://github.com/opencontainers/runc/workflows/validate/badge.svg)](https://github.com/opencontainers/runc/actions?query=workflow%3Avalidate)
[![gha/ci](https://github.com/opencontainers/runc/workflows/ci/badge.svg)](https://github.com/opencontainers/runc/actions?query=workflow%3Aci)
[![CirrusCI](https://api.cirrus-ci.com/github/opencontainers/runc.svg)](https://cirrus-ci.com/github/opencontainers/runc)

## Introduction

`runc` is a CLI tool for spawning and running containers on Linux according to the OCI specification.

## Releases

You can find official releases of `runc` on the [release](https://github.com/opencontainers/runc/releases) page.

All releases are signed by one of the keys listed in the [`runc.keyring` file in the root of this repository](runc.keyring).

## Security

The reporting process and disclosure communications are outlined [here](https://github.com/opencontainers/org/blob/master/SECURITY.md).

### Security Audit
A third party security audit was performed by Cure53, you can see the full report [here](https://github.com/opencontainers/runc/blob/master/docs/Security-Audit.pdf).

## Building

`runc` only supports Linux. See the header of [`go.mod`](./go.mod) for the minimally required Go version.

### Pre-Requisites

#### Utilities and Libraries

In addition to Go, building `runc` requires multiple utilities and libraries to be installed on your system.

On Ubuntu/Debian, you can install the required dependencies with:

```bash
apt update &amp;&amp; apt install -y make gcc linux-libc-dev libseccomp-dev pkg-config git
```

On CentOS/Fedora, you can install the required dependencies with:

```bash
yum install -y make gcc kernel-headers libseccomp-devel pkg-config git
```

On Alpine Linux, you can install the required dependencies with:

```bash
apk --update add bash make gcc libseccomp-dev musl-dev linux-headers git
```

The following dependencies are optional:

* `libseccomp` - only required if you enable seccomp support; to disable, see [Build Tags](#build-tags)

### Build

```bash
# create a &#039;github.com/opencontainers&#039; in your GOPATH/src
cd github.com/opencontainers
git clone https://github.com/opencontainers/runc
cd runc

make
sudo make install
```

You can also use `go get` to install to your `GOPATH`, assuming that you have a `github.com` parent folder already created under `src`:

```bash
go get github.com/opencontainers/runc
cd $GOPATH/src/github.com/opencontainers/runc
make
sudo make install
```

`runc` will be installed to `/usr/local/sbin/runc` on your system.

#### Version string customization

You can see the runc version by running `runc --version`. You can append a custom string to the
version using the `EXTRA_VERSION` make variable when building, e.g.:

```bash
make EXTRA_VERSION=&quot;+build-1&quot;
```

Bear in mind to include some separator for readability.

#### Build Tags

`runc` supports optional build tags for compiling support of various features,
with some of them enabled by default (see `BUILDTAGS` in top-level `Makefile`).

To change build tags from the default, set the `BUILDTAGS` variable for make,
e.g. to disable seccomp:

```bash
make BUILDTAGS=&quot;&quot;
```

To add some more build tags to the default set, use the `EXTRA_BUILDTAGS`
make variable, e.g. to disable checkpoint/restore:

```bash
make EXTRA_BUILDTAGS=&quot;runc_nocriu&quot;
```

| Build Tag     | Feature                               | Enabled by Default | Dependencies        |
|---------------|---------------------------------------|--------------------|---------------------|
| `seccomp`     | Syscall filtering using `libseccomp`. | yes                | `libseccomp`        |
| `runc_nocriu` | **Disables** runc checkpoint/restore. | no                 | `criu`              |

The following build tags were used earlier, but are now obsoleted:
 - **runc_nodmz** (since runc v1.2.1 runc dmz binary is dropped)
 - **nokmem** (since runc v1.0.0-rc94 kernel memory settings are ignored)
 - **apparmor** (since runc v1.0.0-rc93 the feature is always enabled)
 - **selinux**  (since runc v1.0.0-rc93 the feature is always enabled)

### Running the test suite

`runc` currently supports running its test suite via Docker.
To run the suite just type `make test`.

```bash
make test
```

There are additional make targets for running the tests outside of a container but this is not recommended as the tests are written with the expectation that they can write and remove anywhere.

You can run a specific test case by setting the `TESTFLAGS` variable.

```bash
# make test TESTFLAGS=&quot;-run=SomeTestFunction&quot;
```

You can run a specific integration test by setting the `TESTPATH` variable.

```bash
# make test TESTPATH=&quot;/checkpoint.bats&quot;
```

You can run a specific rootless integration test by setting the `ROOTLESS_TESTPATH` variable.

```bash
# make test ROOTLESS_TESTPATH=&quot;/checkpoint.bats&quot;
```

You can run a test using your container engine&#039;s flags by setting `CONTAINER_ENGINE_BUILD_FLAGS` and `CONTAINER_ENGINE_RUN_FLAGS` variables.

```bash
# make test CONTAINER_ENGINE_BUILD_FLAGS=&quot;--build-arg http_proxy=http://yourproxy/&quot; CONTAINER_ENGINE_RUN_FLAGS=&quot;-e http_proxy=http://yourproxy/&quot;
```

### Go Dependencies Management

`runc` uses [Go Modules](https://github.com/golang/go/wiki/Modules) for dependencies management.
Please refer to [Go Modules](https://github.com/golang/go/wiki/Modules) for how to add or update
new dependencies.

```
# Update vendored dependencies
make vendor
# Verify all dependencies
make verify-dependencies
```

## Using runc

Please note that runc is a low level tool not designed with an end user
in mind. It is mostly employed by other higher level container software.

Therefore, unless there is some specific use case that prevents the use
of tools like Docker or Podman, it is not recommended to use runc directly.

If you still want to use runc, here&#039;s how.

### Creating an OCI Bundle

In order to use runc you must have your container in the format of an OCI bundle.
If you have Docker installed you can use its `export` method to acquire a root filesystem from an existing Docker container.

```bash
# create the top most bundle directory
mkdir /mycontainer
cd /mycontainer

# create the rootfs directory
mkdir rootfs

# export busybox via Docker into the rootfs directory
docker export $(docker create busybox) | tar -C rootfs -xvf -
```

After a root filesystem is populated you just generate a spec in the format of a `config.json` file inside your bundle.
`runc` provides a `spec` command to generate a base template spec that you are then able to edit.
To find features and documentation for fields in the spec please refer to the [specs](https://github.com/opencontainers/runtime-spec) repository.

```bash
runc spec
```

### Running Containers

Assuming you have an OCI bundle from the previous step you can execute the container in two different ways.

The first way is to use the convenience command `run` that will handle creating, starting, and deleting the container after it exits.

```bash
# run as root
cd /mycontainer
runc run mycontainerid
```

If you used the unmodified `runc spec` template this should give you a `sh` session inside the container.

The second way to start a container is using the specs lifecycle operations.
This gives you more power over how the container is created and managed while it is running.
This will also launch the container in the background so you will have to edit
the `config.json` to remove the `terminal` setting for the simple examples
below (see more details about [runc terminal handling](docs/terminals.md)).
Your process field in the `config.json` should look like this below with `&quot;terminal&quot;: false` and `&quot;args&quot;: [&quot;sleep&quot;, &quot;5&quot;]`.


```json
        &quot;process&quot;: {
                &quot;terminal&quot;: false,
                &quot;user&quot;: {
                        &quot;uid&quot;: 0,
                        &quot;gid&quot;: 0
                },
                &quot;args&quot;: [
                        &quot;sleep&quot;, &quot;5&quot;
                ],
                &quot;env&quot;: [
                        &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,
                        &quot;TERM=xterm&quot;
                ],
                &quot;cwd&quot;: &quot;/&quot;,
                &quot;capabilities&quot;: {
                        &quot;bounding&quot;: [
                                &quot;CAP_AUDIT_WRITE&quot;,
                                &quot;CAP_KILL&quot;,
                                &quot;CAP_NET_BIND_SERVICE&quot;
                        ],
                        &quot;effective&quot;: [
                                &quot;CAP_AUDIT_WRITE&quot;,
                                &quot;CAP_KILL&quot;,
                                &quot;CAP_NET_BIND_SERVICE&quot;
                        ],
                        &quot;inheritable&quot;: [
                                &quot;CAP_AUDIT_WRITE&quot;,
                                &quot;CAP_KILL&quot;,
                                &quot;CAP_NET_BIND_SERVICE&quot;
                        ],
                        &quot;permitted&quot;: [
                                &quot;CAP_AUDIT_WRITE&quot;,
                                &quot;CAP_KILL&quot;,
                                &quot;CAP_NET_BIND_SERVICE&quot;
                        ],
                        &quot;ambient&quot;: [
                                &quot;CAP_AUDIT_WRITE&quot;,
                                &quot;CAP_KILL&quot;,
                                &quot;CAP_NET_BIND_SERVICE&quot;
                        ]
                },
                &quot;rlimits&quot;: [
                        {
                                &quot;type&quot;: &quot;RLIMIT_NOFILE&quot;,
                                &quot;hard&quot;: 1024,
                                &quot;soft&quot;: 1024
                        }
                ],
                &quot;noNewPrivileges&quot;: true
        },
```

Now we can go through the lifecycle operations in your shell.


```bash
# run as root
cd /mycontainer
runc create mycontainerid

# view the container is created and in the &quot;created&quot; state
runc list

# start the process inside the container
runc start mycontainerid

# after 5 seconds view that the container has exited and is now in the stopped state
runc list

# now delete the container
runc delete mycontainerid
```

This allows higher level systems to augment the containers creation logic with setup of various settings after the container is created and/or before it is deleted. For example, the container&#039;s network stack is commonly set up after `create` but before `start`.

#### Rootless containers
`runc` has the ability to run containers without root privileges. This is called `rootless`. You need to pass some parameters to `runc` in order to run rootless containers. See below and compare with the previous version.

**Note:** In order to use this feature, &quot;User Namespaces&quot; must be compiled and enabled in your kernel. There are various ways to do this depending on your distribution:
- Confirm `CONFIG_USER_NS=y` is set in your kernel configuration (normally found in `/proc/config.gz`)
- Arch/Debian: `echo 1 &gt; /proc/sys/kernel/unprivileged_userns_clone`
- RHEL/CentOS 7: `echo 28633 &gt; /proc/sys/user/max_user_namespaces`

Run the following commands as an ordinary user:
```bash
# Same as the first example
mkdir ~/mycontainer
cd ~/mycontainer
mkdir rootfs
docker export $(docker create busybox) | tar -C rootfs -xvf -

# The --rootless parameter instructs runc spec to generate a configuration for a rootless container, which will allow you to run the container as a non-root user.
runc spec --rootless

# The --root parameter tells runc where to store the container state. It must be writable by the user.
runc --root /tmp/runc run mycontainerid
```

#### Supervisors

`runc` can be used with process supervisors and init systems to ensure that containers are restarted when they exit.
An example systemd unit file looks something like this.

```systemd
[Unit]
Description=Start My Container

[Service]
Type=forking
ExecStart=/usr/local/sbin/runc run -d --pid-file /run/mycontainerid.pid mycontainerid
ExecStopPost=/usr/local/sbin/runc delete mycontainerid
WorkingDirectory=/mycontainer
PIDFile=/run/mycontainerid.pid

[Install]
WantedBy=multi-user.target
```

## More documentation

* [Spec conformance](./docs/spec-conformance.md)
* [cgroup v2](./docs/cgroup-v2.md)
* [Checkpoint and restore](./docs/checkpoint-restore.md)
* [systemd cgroup driver](./docs/systemd.md)
* [Terminals and standard IO](./docs/terminals.md)
* [Experimental features](./docs/experimental.md)
* [Deprecated features](./docs/deprecated.md)

## License

The code and docs are released under the [Apache 2.0 license](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[knadh/koanf]]></title>
            <link>https://github.com/knadh/koanf</link>
            <guid>https://github.com/knadh/koanf</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:11 GMT</pubDate>
            <description><![CDATA[Simple, extremely lightweight, extensible, configuration management library for Go. Supports JSON, TOML, YAML, env, command line, file, S3 etc. Alternative to viper.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/knadh/koanf">knadh/koanf</a></h1>
            <p>Simple, extremely lightweight, extensible, configuration management library for Go. Supports JSON, TOML, YAML, env, command line, file, S3 etc. Alternative to viper.</p>
            <p>Language: Go</p>
            <p>Stars: 3,809</p>
            <p>Forks: 184</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://zerodha.tech&quot;&gt;&lt;img src=&quot;https://zerodha.tech/static/images/github-badge.svg&quot; align=&quot;right&quot; /&gt;&lt;/a&gt;

![koanf](https://user-images.githubusercontent.com/547147/72681838-6981dd00-3aed-11ea-8f5d-310816c70c08.png)

**koanf** is a library for reading configuration from different sources in different formats in Go applications. It is a cleaner, lighter [alternative to spf13/viper](#alternative-to-viper) with better abstractions and extensibility and far fewer dependencies.

koanf v2 has modules (Providers) for reading configuration from a variety of sources such as files, command line flags, environment variables, Vault, and S3 and for parsing (Parsers) formats such as JSON, YAML, TOML, HUML, Hashicorp HCL. It is easy to plug in custom parsers and providers.

All external dependencies in providers and parsers are detached from the core and can be installed separately as necessary.

[![Run Tests](https://github.com/knadh/koanf/actions/workflows/test.yml/badge.svg)](https://github.com/knadh/koanf/actions/workflows/test.yml) [![GoDoc](https://pkg.go.dev/badge/github.com/knadh/koanf?utm_source=godoc)](https://pkg.go.dev/github.com/knadh/koanf/v2) 

### Installation

```shell
# Install the core.
go get -u github.com/knadh/koanf/v2

# Install the necessary Provider(s).
# Available: file, env/v2, posflag, basicflag, confmap, rawbytes,
#            structs, fs, s3, appconfig/v2, consul/v2, etcd/v2, vault/v2, parameterstore/v2
# eg: go get -u github.com/knadh/koanf/providers/s3
# eg: go get -u github.com/knadh/koanf/providers/consul/v2

go get -u github.com/knadh/koanf/providers/file


# Install the necessary Parser(s).
# Available: toml, toml/v2, json, yaml, huml, dotenv, hcl, hjson, nestedtext
# go get -u github.com/knadh/koanf/parsers/$parser

go get -u github.com/knadh/koanf/parsers/toml
```

[See the list](#api) of all bundled Providers and Parsers.

### Contents

- [Concepts](#concepts)
- [Reading config from files](#reading-config-from-files)
- [Watching file for changes](#watching-file-for-changes)
- [Reading from command line](#reading-from-command-line)
- [Reading environment variables](#reading-environment-variables)
- [Reading from an S3 bucket](#reading-from-an-s3-bucket)
- [Reading raw bytes](#reading-raw-bytes)
- [Reading from maps and structs](#reading-from-nested-maps)
- [Unmarshalling and marshalling](#unmarshalling-and-marshalling)
- [Order of merge and key case sensitivity](#order-of-merge-and-key-case-sensitivity)
- [Custom Providers and Parsers](#custom-providers-and-parsers)
- [Custom merge strategies](#custom-merge-strategies)
- [List of installable Providers and Parsers](#api)

### Concepts

- `koanf.Provider` is a generic interface that provides configuration, for example, from files, environment variables, HTTP sources, or anywhere. The configuration can either be raw bytes that a parser can parse, or it can be a nested `map[string]any` that can be directly loaded.
- `koanf.Parser` is a generic interface that takes raw bytes, parses, and returns a nested `map[string]any`. For example, JSON and YAML parsers.
- Once loaded into koanf, configuration are values queried by a delimited key path syntax. eg: `app.server.port`. Any delimiter can be chosen.
- Configuration from multiple sources can be loaded and merged into a koanf instance, for example, load from a file first and override certain values with flags from the command line.

With these two interface implementations, koanf can obtain configuration in any format from any source, parse it, and make it available to an application.

### Reading config from files

```go
package main

import (
	&quot;fmt&quot;
	&quot;log&quot;

	&quot;github.com/knadh/koanf/v2&quot;
	&quot;github.com/knadh/koanf/parsers/json&quot;
	&quot;github.com/knadh/koanf/parsers/yaml&quot;
	&quot;github.com/knadh/koanf/providers/file&quot;
)

// Global koanf instance. Use &quot;.&quot; as the key path delimiter. This can be &quot;/&quot; or any character.
var k = koanf.New(&quot;.&quot;)

func main() {
	// Load JSON config.
	if err := k.Load(file.Provider(&quot;mock/mock.json&quot;), json.Parser()); err != nil {
		log.Fatalf(&quot;error loading config: %v&quot;, err)
	}

	// Load YAML config and merge into the previously loaded config (because we can).
	k.Load(file.Provider(&quot;mock/mock.yml&quot;), yaml.Parser())

	fmt.Println(&quot;parent&#039;s name is = &quot;, k.String(&quot;parent1.name&quot;))
	fmt.Println(&quot;parent&#039;s ID is = &quot;, k.Int(&quot;parent1.id&quot;))
}

```

### Watching file for changes
Some providers expose a `Watch()` method that makes the provider watch for changes
in configuration and trigger a callback to reload the configuration.
This is not goroutine safe if there are concurrent `*Get()` calls happening on the
koanf object while it is doing a `Load()`. Such scenarios will need mutex locking.

`file, appconfig, vault, consul` providers have a `Watch()` method.


```go
package main

import (
	&quot;fmt&quot;
	&quot;log&quot;

	&quot;github.com/knadh/koanf/v2&quot;
	&quot;github.com/knadh/koanf/parsers/json&quot;
	&quot;github.com/knadh/koanf/parsers/yaml&quot;
	&quot;github.com/knadh/koanf/providers/file&quot;
)

// Global koanf instance. Use &quot;.&quot; as the key path delimiter. This can be &quot;/&quot; or any character.
var k = koanf.New(&quot;.&quot;)

func main() {
	// Load JSON config.
	f := file.Provider(&quot;mock/mock.json&quot;)
	if err := k.Load(f, json.Parser()); err != nil {
		log.Fatalf(&quot;error loading config: %v&quot;, err)
	}

	// Load YAML config and merge into the previously loaded config (because we can).
	k.Load(file.Provider(&quot;mock/mock.yml&quot;), yaml.Parser())

	fmt.Println(&quot;parent&#039;s name is = &quot;, k.String(&quot;parent1.name&quot;))
	fmt.Println(&quot;parent&#039;s ID is = &quot;, k.Int(&quot;parent1.id&quot;))

	// Watch the file and get a callback on change. The callback can do whatever,
	// like re-load the configuration.
	// File provider always returns a nil `event`.
	f.Watch(func(event any, err error) {
		if err != nil {
			log.Printf(&quot;watch error: %v&quot;, err)
			return
		}

		// Throw away the old config and load a fresh copy.
		log.Println(&quot;config changed. Reloading ...&quot;)
		k = koanf.New(&quot;.&quot;)
		k.Load(f, json.Parser())
		k.Print()
	})

	// To stop a file watcher, call:
	// f.Unwatch()

	// Block forever (and manually make a change to mock/mock.json) to
	// reload the config.
	log.Println(&quot;waiting forever. Try making a change to mock/mock.json to live reload&quot;)
	&lt;-make(chan bool)
}
```


### Reading from command line

The following example shows the use of `posflag.Provider`, a wrapper over the [spf13/pflag](https://github.com/spf13/pflag) library, an advanced commandline lib. For Go&#039;s built in `flag` package, use `basicflag.Provider`.

```go
package main

import (
	&quot;fmt&quot;
	&quot;log&quot;
	&quot;os&quot;

	&quot;github.com/knadh/koanf/v2&quot;
	&quot;github.com/knadh/koanf/parsers/toml&quot;

	// TOML version 2 is available at:
	// &quot;github.com/knadh/koanf/parsers/toml/v2&quot;

	&quot;github.com/knadh/koanf/providers/file&quot;
	&quot;github.com/knadh/koanf/providers/posflag&quot;
	flag &quot;github.com/spf13/pflag&quot;
)

// Global koanf instance. Use &quot;.&quot; as the key path delimiter. This can be &quot;/&quot; or any character.
var k = koanf.New(&quot;.&quot;)

func main() {
	// Use the POSIX compliant pflag lib instead of Go&#039;s flag lib.
	f := flag.NewFlagSet(&quot;config&quot;, flag.ContinueOnError)
	f.Usage = func() {
		fmt.Println(f.FlagUsages())
		os.Exit(0)
	}
	// Path to one or more config files to load into koanf along with some config params.
	f.StringSlice(&quot;conf&quot;, []string{&quot;mock/mock.toml&quot;}, &quot;path to one or more .toml config files&quot;)
	f.String(&quot;time&quot;, &quot;2020-01-01&quot;, &quot;a time string&quot;)
	f.String(&quot;type&quot;, &quot;xxx&quot;, &quot;type of the app&quot;)
	f.Parse(os.Args[1:])

	// Load the config files provided in the commandline.
	cFiles, _ := f.GetStringSlice(&quot;conf&quot;)
	for _, c := range cFiles {
		if err := k.Load(file.Provider(c), toml.Parser()); err != nil {
			log.Fatalf(&quot;error loading file: %v&quot;, err)
		}
	}

	// &quot;time&quot; and &quot;type&quot; may have been loaded from the config file, but
	// they can still be overridden with the values from the command line.
	// The bundled posflag.Provider takes a flagset from the spf13/pflag lib.
	// Passing the Koanf instance to posflag helps it deal with default command
	// line flag values that are not present in conf maps from previously loaded
	// providers.
	if err := k.Load(posflag.Provider(f, &quot;.&quot;, k), nil); err != nil {
		log.Fatalf(&quot;error loading config: %v&quot;, err)
	}

	fmt.Println(&quot;time is = &quot;, k.String(&quot;time&quot;))
}
```

### Reading environment variables

```go
package main

import (
	&quot;fmt&quot;
	&quot;log&quot;
	&quot;strings&quot;

	&quot;github.com/knadh/koanf/v2&quot;
	&quot;github.com/knadh/koanf/parsers/json&quot;
	&quot;github.com/knadh/koanf/providers/env/v2&quot;
	&quot;github.com/knadh/koanf/providers/file&quot;
)

// Global koanf instance. Use . as the key path delimiter. This can be / or anything.
var k = koanf.New(&quot;.&quot;)

func main() {
	// Load JSON config.
	if err := k.Load(file.Provider(&quot;mock/mock.json&quot;), json.Parser()); err != nil {
		log.Fatalf(&quot;error loading config: %v&quot;, err)
	}

	// Load only environment variables with prefix &quot;MYVAR_&quot; and merge into config.
	// Transform var names by:
	// 1. Converting to lowercase
	// 2. Removing &quot;MYVAR_&quot; prefix  
	// 3. Replacing &quot;_&quot; with &quot;.&quot; to representing nesting using the . delimiter.
	// Example: MYVAR_PARENT1_CHILD1_NAME becomes &quot;parent1.child1.name&quot;
	k.Load(env.Provider(&quot;.&quot;, env.Opt{
		Prefix: &quot;MYVAR_&quot;,
		TransformFunc: func(k, v string) (string, any) {
			// Transform the key.
			k = strings.ReplaceAll(strings.ToLower(strings.TrimPrefix(k, &quot;MYVAR_&quot;)), &quot;_&quot;, &quot;.&quot;)

			// Transform the value into slices, if they contain spaces.
			// Eg: MYVAR_TAGS=&quot;foo bar baz&quot; -&gt; tags: [&quot;foo&quot;, &quot;bar&quot;, &quot;baz&quot;]
			// This is to demonstrate that string values can be transformed to any type
			// where necessary.
			if strings.Contains(v, &quot; &quot;) {
				return k, strings.Split(v, &quot; &quot;)
			}

			return k, v
		},
	}), nil)

	fmt.Println(&quot;name is =&quot;, k.String(&quot;parent1.child1.name&quot;))
	fmt.Println(&quot;time is =&quot;, k.Time(&quot;time&quot;, time.DateOnly))
	fmt.Println(&quot;ids are =&quot;, k.Strings(&quot;parent1.child1.grandchild1.ids&quot;))
}
```

### Reading from an S3 bucket

```go
// Load JSON config from s3.
if err := k.Load(s3.Provider(s3.Config{
	AccessKey: os.Getenv(&quot;AWS_S3_ACCESS_KEY&quot;),
	SecretKey: os.Getenv(&quot;AWS_S3_SECRET_KEY&quot;),
	Region:    os.Getenv(&quot;AWS_S3_REGION&quot;),
	Bucket:    os.Getenv(&quot;AWS_S3_BUCKET&quot;),
	ObjectKey: &quot;dir/config.json&quot;,
}), json.Parser()); err != nil {
	log.Fatalf(&quot;error loading config: %v&quot;, err)
}
```

### Reading raw bytes

The bundled `rawbytes` Provider can be used to read arbitrary bytes from a source, like a database or an HTTP call.

```go
package main

import (
	&quot;fmt&quot;

	&quot;github.com/knadh/koanf/v2&quot;
	&quot;github.com/knadh/koanf/parsers/json&quot;
	&quot;github.com/knadh/koanf/providers/rawbytes&quot;
)

// Global koanf instance. Use . as the key path delimiter. This can be / or anything.
var k = koanf.New(&quot;.&quot;)

func main() {
	b := []byte(`{&quot;type&quot;: &quot;rawbytes&quot;, &quot;parent1&quot;: {&quot;child1&quot;: {&quot;type&quot;: &quot;rawbytes&quot;}}}`)
	k.Load(rawbytes.Provider(b), json.Parser())
	fmt.Println(&quot;type is = &quot;, k.String(&quot;parent1.child1.type&quot;))
}
```

### Unmarshalling and marshalling
`Parser`s can be used to unmarshal and scan the values in a Koanf instance into a struct based on the field tags, and to marshal a Koanf instance back into serialized bytes, for example to JSON or YAML files

```go
package main

import (
	&quot;fmt&quot;
	&quot;log&quot;

	&quot;github.com/knadh/koanf/v2&quot;
	&quot;github.com/knadh/koanf/parsers/json&quot;
	&quot;github.com/knadh/koanf/providers/file&quot;
)

// Global koanf instance. Use . as the key path delimiter. This can be / or anything.
var (
	k      = koanf.New(&quot;.&quot;)
	parser = json.Parser()
)

func main() {
	// Load JSON config.
	if err := k.Load(file.Provider(&quot;mock/mock.json&quot;), parser); err != nil {
		log.Fatalf(&quot;error loading config: %v&quot;, err)
	}

	// Structure to unmarshal nested conf to.
	type childStruct struct {
		Name       string            `koanf:&quot;name&quot;`
		Type       string            `koanf:&quot;type&quot;`
		Empty      map[string]string `koanf:&quot;empty&quot;`
		GrandChild struct {
			Ids []int `koanf:&quot;ids&quot;`
			On  bool  `koanf:&quot;on&quot;`
		} `koanf:&quot;grandchild1&quot;`
	}

	var out childStruct

	// Quick unmarshal.
	k.Unmarshal(&quot;parent1.child1&quot;, &amp;out)
	fmt.Println(out)

	// Unmarshal with advanced config.
	out = childStruct{}
	k.UnmarshalWithConf(&quot;parent1.child1&quot;, &amp;out, koanf.UnmarshalConf{Tag: &quot;koanf&quot;})
	fmt.Println(out)

	// Marshal the instance back to JSON.
	// The parser instance can be anything, eg: json.Parser(), yaml.Parser() etc.
	b, _ := k.Marshal(parser)
	fmt.Println(string(b))
}
```

### Unmarshalling with flat paths

Sometimes it is necessary to unmarshal an assortment of keys from various nested structures into a flat target structure. This is possible with the `UnmarshalConf.FlatPaths` flag.

```go
package main

import (
	&quot;fmt&quot;
	&quot;log&quot;

	&quot;github.com/knadh/koanf/v2&quot;
	&quot;github.com/knadh/koanf/parsers/json&quot;
	&quot;github.com/knadh/koanf/providers/file&quot;
)

// Global koanf instance. Use . as the key path delimiter. This can be / or anything.
var k = koanf.New(&quot;.&quot;)

func main() {
	// Load JSON config.
	if err := k.Load(file.Provider(&quot;mock/mock.json&quot;), json.Parser()); err != nil {
		log.Fatalf(&quot;error loading config: %v&quot;, err)
	}

	type rootFlat struct {
		Type                        string            `koanf:&quot;type&quot;`
		Empty                       map[string]string `koanf:&quot;empty&quot;`
		Parent1Name                 string            `koanf:&quot;parent1.name&quot;`
		Parent1ID                   int               `koanf:&quot;parent1.id&quot;`
		Parent1Child1Name           string            `koanf:&quot;parent1.child1.name&quot;`
		Parent1Child1Type           string            `koanf:&quot;parent1.child1.type&quot;`
		Parent1Child1Empty          map[string]string `koanf:&quot;parent1.child1.empty&quot;`
		Parent1Child1Grandchild1IDs []int             `koanf:&quot;parent1.child1.grandchild1.ids&quot;`
		Parent1Child1Grandchild1On  bool              `koanf:&quot;parent1.child1.grandchild1.on&quot;`
	}

	// Unmarshal the whole root with FlatPaths: True.
	var o1 rootFlat
	k.UnmarshalWithConf(&quot;&quot;, &amp;o1, koanf.UnmarshalConf{Tag: &quot;koanf&quot;, FlatPaths: true})
	fmt.Println(o1)

	// Unmarshal a child structure of &quot;parent1&quot;.
	type subFlat struct {
		Name                 string            `koanf:&quot;name&quot;`
		ID                   int               `koanf:&quot;id&quot;`
		Child1Name           string            `koanf:&quot;child1.name&quot;`
		Child1Type           string            `koanf:&quot;child1.type&quot;`
		Child1Empty          map[string]string `koanf:&quot;child1.empty&quot;`
		Child1Grandchild1IDs []int             `koanf:&quot;child1.grandchild1.ids&quot;`
		Child1Grandchild1On  bool              `koanf:&quot;child1.grandchild1.on&quot;`
	}

	var o2 subFlat
	k.UnmarshalWithConf(&quot;parent1&quot;, &amp;o2, koanf.UnmarshalConf{Tag: &quot;koanf&quot;, FlatPaths: true})
	fmt.Println(o2)
}
```

#### Reading from nested maps

The bundled `confmap` provider takes a `map[string]any` that can be loaded into a koanf instance. 

```go
package main

import (
	&quot;fmt&quot;
	&quot;log&quot;

	&quot;github.com/knadh/koanf/v2&quot;
	&quot;github.com/knadh/koanf/providers/confmap&quot;
	&quot;github.com/knadh/koanf/providers/file&quot;
	&quot;github.com/knadh/koanf/parsers/json&quot;
	&quot;github.com/knadh/koanf/parsers/yaml&quot;
)

// Global koanf instance. Use &quot;.&quot; as the key path delimiter. This can be &quot;/&quot; or any character.
var k = koanf.New(&quot;.&quot;)

func main() {
	// Load default values using the confmap provider.
	// We provide a flat map with the &quot;.&quot; delimiter.
	// A nested map can be loaded by setting the delimiter to an empty string &quot;&quot;.
	k.Load(confmap.Provider(map[string]any{
		&quot;parent1.name&quot;: &quot;Default Name&quot;,
		&quot;parent3.name&quot;: &quot;New name here&quot;,
	}, &quot;.&quot;), nil)

	// Load JSON config on top of the default values.
	if err := k.Load(file.Provider(&quot;mock/mock.json&quot;), json.Parser()); err != nil {
		log.Fatalf(&quot;error loading config: %v&quot;, err)
	}

	// Load YAML config and merge into the previously loaded config (because we can).
	k.Load(file.Provider(&quot;mock/mock.yml&quot;), yaml.Parser())

	fmt.Println(&quot;parent&#039;s name is = &quot;, k.String(&quot;parent1.name&quot;))
	fmt.Println(&quot;parent&#039;s ID is = &quot;, k.Int(&quot;parent1.id&quot;))
}
```

#### Reading from struct 

The bundled `structs` provider can be used to read data from a struct to load into a koanf instance.

```go
package main

import (
	&quot;fmt&quot;

	&quot;github.com/knadh/koanf/v2&quot;
	&quot;github.com/knadh/koanf/providers/structs&quot;
)

// Global koanf instance. Use &quot;.&quot; as the key path delimiter. This can be &quot;/&quot; or any character.
var k = koanf.New(&quot;.&quot;)

type parentStruct struct {
	Name   string      `koanf:&quot;name&quot;`
	ID     int         `koanf:&quot;id&quot;`
	Child1 childStruct `koanf:&quot;child1&quot;`
}
type childStruct struct {
	Name        string            `koanf:&quot;name&quot;`
	Type        string            `koanf:&quot;type&quot;`
	Empty       map[string]string `koanf:&quot;empty&quot;`
	Grandchild1 grandchildStruct  `koanf:&quot;grandchild1&quot;`
}
type grandchildStruct struct {
	Ids []int `koanf:&quot;ids&quot;`
	On  bool  `koanf:&quot;on&quot;`
}
type sampleStruct struct {
	Type    string            `koanf:&quot;type&quot;`
	Empty   map[string]string `koanf:&quot;empty&quot;`
	Parent1 parentStruct      `koanf:&quot;parent1&quot;`
}

func main() {
	// Load default values using the structs provider.
	// We provide a struct along with the struct tag `koanf` to the
	// provider.
	k.Load(structs.Provider(sampleStruct{
		Type:  &quot;json&quot;,
		Empty: make(map[string]string),
		Parent1: parentStruct{
			Name: &quot;parent1&quot;,
			ID:   1234,
			Child1: childStruct{
				Name:  &quot;child1&quot;,
				Type:  &quot;json&quot;,
				Empty: make(map[string]string),
				Grandchild1: grandchildStruct{
					Ids: []int{1, 2, 3},
					On:  true,
				},
			},
		},
	}, &quot;koanf&quot;), nil)

	fmt.Printf(&quot;name is = `%s`\n&quot;, k.String(&quot;parent1.child1.name&quot;))
}
```
### Merge behavior
#### Default behavior
The default behavior when you create Koanf this way is: `koanf.New(delim)` that the latest loaded configuration will
merge with the previous one.

For example:
`first.yml`
```yaml
key: [1,2,3]
```
`second.yml`
```yaml
key: &#039;string&#039;
```
When `second.yml` is loaded it will override the type of the `first.yml`.

If this behavior is not desired, you can merge &#039;strictly&#039;. In the same scenario, `Load` will return an error.

```go
package main

import (
	&quot;errors&quot;
	&quot;log&quot;

	&quot;github.com/knadh/koanf/v2&quot;
	&quot;github.com/knadh/koanf/maps&quot;
	&quot;github.com/knadh/koanf/parsers/json&quot;
	&quot;github.com/knadh/koanf/parsers/yaml&quot;
	&quot;github.com/knadh/koanf/providers/file&quot;
)

var conf = koanf.Conf{
	Delim:       &quot;.&quot;,
	StrictMerge: true,
}
var k = koanf.NewWithConf(conf)

func main() {
	yamlPath := &quot;mock/mock.yml&quot;
	if err := k.Load(file.Provider(yamlPath), yaml.Parser()); err != nil {
		log.Fatalf(&quot;error loading config: %v&quot;, err)
	}

	jsonPath := &quot;mock/mock.json&quot;
	if err := k.Load(file.Provider(jsonPath), json.Parser()); err != nil {
		log.Fatalf(&quot;error loading config: %v&quot;, err)
	}
}
```
**Note:** When merging different extensions, each parser can treat his types differently,
 meaning even though you the load same types there is a probability that it will fail with `StrictMerge: true`.

For example: merging JSON and YAML will most likely fail because JSON treats integers as float64 and YAML treats them as integers.

### Order of merge and key case sensitivity

- Config keys are case-sensitive in koanf. For example, `app.server.port` and `APP.SERVER.port` are not the same.
- koanf does not impose any ordering on loading config from various providers. Every successive `Load()` or `Merge()` merges new config into the existing config. That is, it is possible to load environment variables first, then files on top of it, and then command line variables on top of it, or any such order.

### Custom Providers and Parsers

A Provider returns a nested `map[string]any` config that can be loaded directly into koanf with `koanf.Load()` or it can return raw bytes that can be parsed with a Parser (again, loaded using `koanf.Load()`. Writing Providers and Parsers are easy. See the bundled implementations in the [providers](https://github.com/knadh/koanf/tree/master/providers) and [parsers](https://github.com/knadh/koanf/tree/master/parsers) directories.

### Custom merge strategies

By default, when merging two config sources using `Load()`, koanf recursively merges keys of nested maps (`map[string]any`),
while static values are overwritten (slices, strings, etc). This behaviour can be changed by providing a custom merge function with the `WithMergeFunc` option.

```go
package main

import (
	&quot;errors&quot;
	&quot;log&quot;

	&quot;github.com/knadh/koanf/v2&quot;
	&quot;github.com/knadh/koanf/maps&quot;
	&quot;g

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[charmbracelet/bubbletea]]></title>
            <link>https://github.com/charmbracelet/bubbletea</link>
            <guid>https://github.com/charmbracelet/bubbletea</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:10 GMT</pubDate>
            <description><![CDATA[A powerful little TUI framework üèó]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/charmbracelet/bubbletea">charmbracelet/bubbletea</a></h1>
            <p>A powerful little TUI framework üèó</p>
            <p>Language: Go</p>
            <p>Stars: 38,860</p>
            <p>Forks: 1,075</p>
            <p>Stars today: 50 stars today</p>
            <h2>README</h2><pre># Bubble Tea

&lt;p&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://stuff.charm.sh/bubbletea/bubble-tea-v2-light.png&quot; width=&quot;308&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://stuff.charm.sh/bubbletea/bubble-tea-v2-dark.png&quot; width=&quot;312&quot;&gt;
      &lt;img src=&quot;https://stuff.charm.sh/bubbletea/bubble-tea-v2-light.png&quot; width=&quot;308&quot; /&gt;
    &lt;/picture&gt;
    &lt;br&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/bubbletea/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/charmbracelet/bubbletea.svg&quot; alt=&quot;Latest Release&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://pkg.go.dev/github.com/charmbracelet/bubbletea?tab=doc&quot;&gt;&lt;img src=&quot;https://godoc.org/github.com/charmbracelet/bubbletea?status.svg&quot; alt=&quot;GoDoc&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/bubbletea/actions&quot;&gt;&lt;img src=&quot;https://github.com/charmbracelet/bubbletea/actions/workflows/build.yml/badge.svg?branch=main&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

The fun, functional and stateful way to build terminal apps. A Go framework
based on [The Elm Architecture][elm]. Bubble Tea is well-suited for simple and
complex terminal applications, either inline, full-window, or a mix of both.

&lt;p&gt;
    &lt;img src=&quot;https://stuff.charm.sh/bubbletea/bubbletea-example.gif&quot; width=&quot;100%&quot; alt=&quot;Bubble Tea Example&quot;&gt;
&lt;/p&gt;

Bubble Tea is in use in production and includes a number of features and
performance optimizations we‚Äôve added along the way. Among those is
a framerate-based renderer, mouse support, focus reporting and more.

To get started, see the tutorial below, the [examples][examples], the
[docs][docs], the [video tutorials][youtube] and some common [resources](#libraries-we-use-with-bubble-tea).

[youtube]: https://charm.sh/yt

## By the way

Be sure to check out [Bubbles][bubbles], a library of common UI components for Bubble Tea.

&lt;p&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/bubbles&quot;&gt;&lt;img src=&quot;https://stuff.charm.sh/bubbles/bubbles-badge.png&quot; width=&quot;174&quot; alt=&quot;Bubbles Badge&quot;&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/charmbracelet/bubbles&quot;&gt;&lt;img src=&quot;https://stuff.charm.sh/bubbles-examples/textinput.gif&quot; width=&quot;400&quot; alt=&quot;Text Input Example from Bubbles&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

---

## Tutorial

Bubble Tea is based on the functional design paradigms of [The Elm
Architecture][elm], which happens to work nicely with Go. It&#039;s a delightful way
to build applications.

This tutorial assumes you have a working knowledge of Go.

By the way, the non-annotated source code for this program is available
[on GitHub][tut-source].

[elm]: https://guide.elm-lang.org/architecture/
[tut-source]: https://github.com/charmbracelet/bubbletea/tree/main/tutorials/basics

### Enough! Let&#039;s get to it.

For this tutorial, we&#039;re making a shopping list.

To start we&#039;ll define our package and import some libraries. Our only external
import will be the Bubble Tea library, which we&#039;ll call `tea` for short.

```go
package main

// These imports will be used later on the tutorial. If you save the file
// now, Go might complain they are unused, but that&#039;s fine.
// You may also need to run `go mod tidy` to download bubbletea and its
// dependencies.
import (
    &quot;fmt&quot;
    &quot;os&quot;

    tea &quot;github.com/charmbracelet/bubbletea&quot;
)
```

Bubble Tea programs are comprised of a **model** that describes the application
state and three simple methods on that model:

- **Init**, a function that returns an initial command for the application to run.
- **Update**, a function that handles incoming events and updates the model accordingly.
- **View**, a function that renders the UI based on the data in the model.

### The Model

So let&#039;s start by defining our model which will store our application&#039;s state.
It can be any type, but a `struct` usually makes the most sense.

```go
type model struct {
    choices  []string           // items on the to-do list
    cursor   int                // which to-do list item our cursor is pointing at
    selected map[int]struct{}   // which to-do items are selected
}
```

### Initialization

Next, we‚Äôll define our application‚Äôs initial state. In this case, we‚Äôre defining
a function to return our initial model, however, we could just as easily define
the initial model as a variable elsewhere, too.

```go
func initialModel() model {
	return model{
		// Our to-do list is a grocery list
		choices:  []string{&quot;Buy carrots&quot;, &quot;Buy celery&quot;, &quot;Buy kohlrabi&quot;},

		// A map which indicates which choices are selected. We&#039;re using
		// the  map like a mathematical set. The keys refer to the indexes
		// of the `choices` slice, above.
		selected: make(map[int]struct{}),
	}
}
```

Next, we define the `Init` method. `Init` can return a `Cmd` that could perform
some initial I/O. For now, we don&#039;t need to do any I/O, so for the command,
we&#039;ll just return `nil`, which translates to &quot;no command.&quot;

```go
func (m model) Init() tea.Cmd {
    // Just return `nil`, which means &quot;no I/O right now, please.&quot;
    return nil
}
```

### The Update Method

Next up is the update method. The update function is called when ‚Äùthings
happen.‚Äù Its job is to look at what has happened and return an updated model in
response. It can also return a `Cmd` to make more things happen, but for now
don&#039;t worry about that part.

In our case, when a user presses the down arrow, `Update`‚Äôs job is to notice
that the down arrow was pressed and move the cursor accordingly (or not).

The ‚Äúsomething happened‚Äù comes in the form of a `Msg`, which can be any type.
Messages are the result of some I/O that took place, such as a keypress, timer
tick, or a response from a server.

We usually figure out which type of `Msg` we received with a type switch, but
you could also use a type assertion.

For now, we&#039;ll just deal with `tea.KeyMsg` messages, which are automatically
sent to the update function when keys are pressed.

```go
func (m model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
    switch msg := msg.(type) {

    // Is it a key press?
    case tea.KeyMsg:

        // Cool, what was the actual key pressed?
        switch msg.String() {

        // These keys should exit the program.
        case &quot;ctrl+c&quot;, &quot;q&quot;:
            return m, tea.Quit

        // The &quot;up&quot; and &quot;k&quot; keys move the cursor up
        case &quot;up&quot;, &quot;k&quot;:
            if m.cursor &gt; 0 {
                m.cursor--
            }

        // The &quot;down&quot; and &quot;j&quot; keys move the cursor down
        case &quot;down&quot;, &quot;j&quot;:
            if m.cursor &lt; len(m.choices)-1 {
                m.cursor++
            }

        // The &quot;enter&quot; key and the spacebar (a literal space) toggle
        // the selected state for the item that the cursor is pointing at.
        case &quot;enter&quot;, &quot; &quot;:
            _, ok := m.selected[m.cursor]
            if ok {
                delete(m.selected, m.cursor)
            } else {
                m.selected[m.cursor] = struct{}{}
            }
        }
    }

    // Return the updated model to the Bubble Tea runtime for processing.
    // Note that we&#039;re not returning a command.
    return m, nil
}
```

You may have noticed that &lt;kbd&gt;ctrl+c&lt;/kbd&gt; and &lt;kbd&gt;q&lt;/kbd&gt; above return
a `tea.Quit` command with the model. That‚Äôs a special command which instructs
the Bubble Tea runtime to quit, exiting the program.

### The View Method

At last, it‚Äôs time to render our UI. Of all the methods, the view is the
simplest. We look at the model in its current state and use it to return
a `string`. That string is our UI!

Because the view describes the entire UI of your application, you don‚Äôt have to
worry about redrawing logic and stuff like that. Bubble Tea takes care of it
for you.

```go
func (m model) View() string {
    // The header
    s := &quot;What should we buy at the market?\n\n&quot;

    // Iterate over our choices
    for i, choice := range m.choices {

        // Is the cursor pointing at this choice?
        cursor := &quot; &quot; // no cursor
        if m.cursor == i {
            cursor = &quot;&gt;&quot; // cursor!
        }

        // Is this choice selected?
        checked := &quot; &quot; // not selected
        if _, ok := m.selected[i]; ok {
            checked = &quot;x&quot; // selected!
        }

        // Render the row
        s += fmt.Sprintf(&quot;%s [%s] %s\n&quot;, cursor, checked, choice)
    }

    // The footer
    s += &quot;\nPress q to quit.\n&quot;

    // Send the UI for rendering
    return s
}
```

### All Together Now

The last step is to simply run our program. We pass our initial model to
`tea.NewProgram` and let it rip:

```go
func main() {
    p := tea.NewProgram(initialModel())
    if _, err := p.Run(); err != nil {
        fmt.Printf(&quot;Alas, there&#039;s been an error: %v&quot;, err)
        os.Exit(1)
    }
}
```

## What‚Äôs Next?

This tutorial covers the basics of building an interactive terminal UI, but
in the real world you&#039;ll also need to perform I/O. To learn about that have a
look at the [Command Tutorial][cmd]. It&#039;s pretty simple.

There are also several [Bubble Tea examples][examples] available and, of course,
there are [Go Docs][docs].

[cmd]: https://github.com/charmbracelet/bubbletea/tree/main/tutorials/commands/
[examples]: https://github.com/charmbracelet/bubbletea/tree/main/examples
[docs]: https://pkg.go.dev/github.com/charmbracelet/bubbletea?tab=doc

## Debugging

### Debugging with Delve

Since Bubble Tea apps assume control of stdin and stdout, you‚Äôll need to run
delve in headless mode and then connect to it:

```bash
# Start the debugger
$ dlv debug --headless --api-version=2 --listen=127.0.0.1:43000 .
API server listening at: 127.0.0.1:43000

# Connect to it from another terminal
$ dlv connect 127.0.0.1:43000
```

If you do not explicitly supply the `--listen` flag, the port used will vary
per run, so passing this in makes the debugger easier to use from a script
or your IDE of choice.

Additionally, we pass in `--api-version=2` because delve defaults to version 1
for backwards compatibility reasons. However, delve recommends using version 2
for all new development and some clients may no longer work with version 1.
For more information, see the [Delve documentation](https://github.com/go-delve/delve/tree/master/Documentation/api).

### Logging Stuff

You can‚Äôt really log to stdout with Bubble Tea because your TUI is busy
occupying that! You can, however, log to a file by including something like
the following prior to starting your Bubble Tea program:

```go
if len(os.Getenv(&quot;DEBUG&quot;)) &gt; 0 {
	f, err := tea.LogToFile(&quot;debug.log&quot;, &quot;debug&quot;)
	if err != nil {
		fmt.Println(&quot;fatal:&quot;, err)
		os.Exit(1)
	}
	defer f.Close()
}
```

To see what‚Äôs being logged in real time, run `tail -f debug.log` while you run
your program in another window.

## Libraries we use with Bubble Tea

- [Bubbles][bubbles]: Common Bubble Tea components such as text inputs, viewports, spinners and so on
- [Lip Gloss][lipgloss]: Style, format and layout tools for terminal applications
- [Harmonica][harmonica]: A spring animation library for smooth, natural motion
- [BubbleZone][bubblezone]: Easy mouse event tracking for Bubble Tea components
- [ntcharts][ntcharts]: A terminal charting library built for Bubble Tea and [Lip Gloss][lipgloss]

[bubbles]: https://github.com/charmbracelet/bubbles
[lipgloss]: https://github.com/charmbracelet/lipgloss
[harmonica]: https://github.com/charmbracelet/harmonica
[bubblezone]: https://github.com/lrstanley/bubblezone
[ntcharts]: https://github.com/NimbleMarkets/ntcharts

## Bubble Tea in the Wild

There are over [10,000 applications](https://github.com/charmbracelet/bubbletea/network/dependents) built with Bubble Tea! Here are a handful of ‚Äôem.

### Staff favourites

- [chezmoi](https://github.com/twpayne/chezmoi): securely manage your dotfiles across multiple machines
- [circumflex](https://github.com/bensadeh/circumflex): read Hacker News in the terminal
- [gh-dash](https://www.github.com/dlvhdr/gh-dash): a GitHub CLI extension for PRs and issues
- [Tetrigo](https://github.com/Broderick-Westrope/tetrigo): Tetris in the terminal
- [Signls](https://github.com/emprcl/signls): a generative midi sequencer designed for composition and live performance
- [Superfile](https://github.com/yorukot/superfile): a super file manager

### In Industry

- Microsoft Azure ‚Äì¬†[Aztify](https://github.com/Azure/aztfy): bring Microsoft Azure resources under Terraform
- Daytona ‚Äì¬†[Daytona](https://github.com/daytonaio/daytona): open source dev environment manager
- Cockroach Labs ‚Äì [CockroachDB](https://github.com/cockroachdb/cockroach): a cloud-native, high-availability distributed SQL database
- Truffle Security Co. ‚Äì¬†[Trufflehog](https://github.com/trufflesecurity/trufflehog): find leaked credentials
- NVIDIA ‚Äì¬†[container-canary](https://github.com/NVIDIA/container-canary): a container validator
- AWS ‚Äì¬†[eks-node-viewer](https://github.com/awslabs/eks-node-viewer): a tool for visualizing dynamic node usage within an EKS cluster
- MinIO ‚Äì¬†[mc](https://github.com/minio/mc): the official [MinIO](https://min.io) client
- Ubuntu ‚Äì¬†[Authd](https://github.com/ubuntu/authd): an authentication daemon for cloud-based identity providers

### Charm stuff

- [Glow](https://github.com/charmbracelet/glow): a markdown reader, browser, and online markdown stash
- [Huh?](https://github.com/charmbracelet/huh): an interactive prompt and form toolkit
- [Mods](https://github.com/charmbracelet/mods): AI on the CLI, built for pipelines
- [Wishlist](https://github.com/charmbracelet/wishlist): an SSH directory (and bastion!)

### There‚Äôs so much more where that came from

For more applications built with Bubble Tea see [Charm &amp; Friends][community].
Is there something cool you made with Bubble Tea you want to share? [PRs][community] are
welcome!

## Contributing

See [contributing][contribute].

[contribute]: https://github.com/charmbracelet/bubbletea/contribute

## Feedback

We‚Äôd love to hear your thoughts on this project. Feel free to drop us a note!

- [Twitter](https://twitter.com/charmcli)
- [The Fediverse](https://mastodon.social/@charmcli)
- [Discord](https://charm.sh/chat)

## Acknowledgments

Bubble Tea is based on the paradigms of [The Elm Architecture][elm] by Evan
Czaplicki et alia and the excellent [go-tea][gotea] by TJ Holowaychuk. It‚Äôs
inspired by the many great [_Zeichenorientierte Benutzerschnittstellen_][zb]
of days past.

[elm]: https://guide.elm-lang.org/architecture/
[gotea]: https://github.com/tj/go-tea
[zb]: https://de.wikipedia.org/wiki/Zeichenorientierte_Benutzerschnittstelle
[community]: https://github.com/charm-and-friends/charm-in-the-wild

## License

[MIT](https://github.com/charmbracelet/bubbletea/raw/main/LICENSE)

---

Part of [Charm](https://charm.sh).

&lt;a href=&quot;https://charm.sh/&quot;&gt;&lt;img alt=&quot;The Charm logo&quot; src=&quot;https://stuff.charm.sh/charm-banner-next.jpg&quot; width=&quot;400&quot;&gt;&lt;/a&gt;

CharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source ‚Ä¢ ŸÜÿ≠ŸÜŸè ŸÜÿ≠ÿ® ÿßŸÑŸÖÿµÿßÿØÿ± ÿßŸÑŸÖŸÅÿ™Ÿàÿ≠ÿ©
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[nats-io/nats.go]]></title>
            <link>https://github.com/nats-io/nats.go</link>
            <guid>https://github.com/nats-io/nats.go</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:09 GMT</pubDate>
            <description><![CDATA[Golang client for NATS, the cloud native messaging system.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nats-io/nats.go">nats-io/nats.go</a></h1>
            <p>Golang client for NATS, the cloud native messaging system.</p>
            <p>Language: Go</p>
            <p>Stars: 6,398</p>
            <p>Forks: 789</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># NATS - Go Client
A [Go](http://golang.org) client for the [NATS messaging system](https://nats.io).

[![License Apache 2][License-Image]][License-Url] [![Go Report Card][ReportCard-Image]][ReportCard-Url] [![Build Status][Build-Status-Image]][Build-Status-Url] [![GoDoc][GoDoc-Image]][GoDoc-Url] [![Coverage Status][Coverage-image]][Coverage-Url]

[License-Url]: https://www.apache.org/licenses/LICENSE-2.0
[License-Image]: https://img.shields.io/badge/License-Apache2-blue.svg
[ReportCard-Url]: https://goreportcard.com/report/github.com/nats-io/nats.go
[ReportCard-Image]: https://goreportcard.com/badge/github.com/nats-io/nats.go
[Build-Status-Url]: https://github.com/nats-io/nats.go/actions
[Build-Status-Image]: https://github.com/nats-io/nats.go/actions/workflows/ci.yaml/badge.svg?branch=main
[GoDoc-Url]: https://pkg.go.dev/github.com/nats-io/nats.go
[GoDoc-Image]: https://img.shields.io/badge/GoDoc-reference-007d9c
[Coverage-Url]: https://coveralls.io/r/nats-io/nats.go?branch=main
[Coverage-image]: https://coveralls.io/repos/github/nats-io/nats.go/badge.svg?branch=main

**Check out [NATS by example](https://natsbyexample.com) - An evolving collection of runnable, cross-client reference examples for NATS.**

## Installation

```bash
# To get the latest released Go client:
go get github.com/nats-io/nats.go@latest

# To get a specific version:
go get github.com/nats-io/nats.go@v1.48.0

# Note that the latest major version for NATS Server is v2:
go get github.com/nats-io/nats-server/v2@latest
```

## Basic Usage

```go
import &quot;github.com/nats-io/nats.go&quot;

// Connect to a server
nc, _ := nats.Connect(nats.DefaultURL)

// Simple Publisher
nc.Publish(&quot;foo&quot;, []byte(&quot;Hello World&quot;))

// Simple Async Subscriber
nc.Subscribe(&quot;foo&quot;, func(m *nats.Msg) {
    fmt.Printf(&quot;Received a message: %s\n&quot;, string(m.Data))
})

// Responding to a request message
nc.Subscribe(&quot;request&quot;, func(m *nats.Msg) {
    m.Respond([]byte(&quot;answer is 42&quot;))
})

// Simple Sync Subscriber
sub, err := nc.SubscribeSync(&quot;foo&quot;)
m, err := sub.NextMsg(timeout)

// Channel Subscriber
ch := make(chan *nats.Msg, 64)
sub, err := nc.ChanSubscribe(&quot;foo&quot;, ch)
msg := &lt;- ch

// Unsubscribe
sub.Unsubscribe()

// Drain
sub.Drain()

// Requests
msg, err := nc.Request(&quot;help&quot;, []byte(&quot;help me&quot;), 10*time.Millisecond)

// Replies
nc.Subscribe(&quot;help&quot;, func(m *nats.Msg) {
    nc.Publish(m.Reply, []byte(&quot;I can help!&quot;))
})

// Drain connection (Preferred for responders)
// Close() not needed if this is called.
nc.Drain()

// Close connection
nc.Close()
```

## JetStream
[![JetStream API Reference](https://pkg.go.dev/badge/github.com/nats-io/nats.go/jetstream.svg)](https://pkg.go.dev/github.com/nats-io/nats.go/jetstream)

JetStream is the built-in NATS persistence system. `nats.go` provides a built-in
API enabling both managing JetStream assets as well as publishing/consuming
persistent messages.


### Basic usage

```go
// connect to nats server
nc, _ := nats.Connect(nats.DefaultURL)

// create jetstream context from nats connection
js, _ := jetstream.New(nc)

ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
defer cancel()

// get existing stream handle
stream, _ := js.Stream(ctx, &quot;foo&quot;)

// retrieve consumer handle from a stream
cons, _ := stream.Consumer(ctx, &quot;cons&quot;)

// consume messages from the consumer in callback
cc, _ := cons.Consume(func(msg jetstream.Msg) {
    fmt.Println(&quot;Received jetstream message: &quot;, string(msg.Data()))
    msg.Ack()
})
defer cc.Stop()
```

To find more information on `nats.go` JetStream API, visit
[`jetstream/README.md`](jetstream/README.md)

&gt; The current JetStream API replaces the [legacy JetStream API](legacy_jetstream.md)

## Service API

The service API (`micro`) allows you to [easily build NATS services](micro/README.md) The
services API is currently in beta release.

## New Authentication (Nkeys and User Credentials)
This requires server with version &gt;= 2.0.0

NATS servers have a new security and authentication mechanism to authenticate with user credentials and Nkeys.
The simplest form is to use the helper method UserCredentials(credsFilepath).
```go
nc, err := nats.Connect(url, nats.UserCredentials(&quot;user.creds&quot;))
```

The helper method creates two callback handlers to present the user JWT and sign the nonce challenge from the server.
The core client library never has direct access to your private key and simply performs the callback for signing the server challenge.
The helper will load and wipe and erase memory it uses for each connect or reconnect.

The helper also can take two entries, one for the JWT and one for the NKey seed file.
```go
nc, err := nats.Connect(url, nats.UserCredentials(&quot;user.jwt&quot;, &quot;user.nk&quot;))
```

You can also set the callback handlers directly and manage challenge signing directly.
```go
nc, err := nats.Connect(url, nats.UserJWT(jwtCB, sigCB))
```

Bare Nkeys are also supported. The nkey seed should be in a read only file, e.g. seed.txt
```bash
&gt; cat seed.txt
# This is my seed nkey!
SUAGMJH5XLGZKQQWAWKRZJIGMOU4HPFUYLXJMXOO5NLFEO2OOQJ5LPRDPM
```

This is a helper function which will load and decode and do the proper signing for the server nonce.
It will clear memory in between invocations.
You can choose to use the low level option and provide the public key and a signature callback on your own.

```go
opt, err := nats.NkeyOptionFromSeed(&quot;seed.txt&quot;)
nc, err := nats.Connect(serverUrl, opt)

// Direct
nc, err := nats.Connect(serverUrl, nats.Nkey(pubNkey, sigCB))
```

## TLS

```go
// tls as a scheme will enable secure connections by default. This will also verify the server name.
nc, err := nats.Connect(&quot;tls://nats.demo.io:4443&quot;)

// If you are using a self-signed certificate, you need to have a tls.Config with RootCAs setup.
// We provide a helper method to make this case easier.
nc, err = nats.Connect(&quot;tls://localhost:4443&quot;, nats.RootCAs(&quot;./configs/certs/ca.pem&quot;))

// If the server requires client certificate, there is a helper function for that too:
cert := nats.ClientCert(&quot;./configs/certs/client-cert.pem&quot;, &quot;./configs/certs/client-key.pem&quot;)
nc, err = nats.Connect(&quot;tls://localhost:4443&quot;, cert)

// You can also supply a complete tls.Config

certFile := &quot;./configs/certs/client-cert.pem&quot;
keyFile := &quot;./configs/certs/client-key.pem&quot;
cert, err := tls.LoadX509KeyPair(certFile, keyFile)
if err != nil {
    t.Fatalf(&quot;error parsing X509 certificate/key pair: %v&quot;, err)
}

config := &amp;tls.Config{
    ServerName: 	opts.Host,
    Certificates: 	[]tls.Certificate{cert},
    RootCAs:    	pool,
    MinVersion: 	tls.VersionTLS12,
}

nc, err = nats.Connect(&quot;nats://localhost:4443&quot;, nats.Secure(config))
if err != nil {
	t.Fatalf(&quot;Got an error on Connect with Secure Options: %+v\n&quot;, err)
}

```

## Wildcard Subscriptions

```go

// &quot;*&quot; matches any token, at any level of the subject.
nc.Subscribe(&quot;foo.*.baz&quot;, func(m *Msg) {
    fmt.Printf(&quot;Msg received on [%s] : %s\n&quot;, m.Subject, string(m.Data))
})

nc.Subscribe(&quot;foo.bar.*&quot;, func(m *Msg) {
    fmt.Printf(&quot;Msg received on [%s] : %s\n&quot;, m.Subject, string(m.Data))
})

// &quot;&gt;&quot; matches any length of the tail of a subject, and can only be the last token
// E.g. &#039;foo.&gt;&#039; will match &#039;foo.bar&#039;, &#039;foo.bar.baz&#039;, &#039;foo.foo.bar.bax.22&#039;
nc.Subscribe(&quot;foo.&gt;&quot;, func(m *Msg) {
    fmt.Printf(&quot;Msg received on [%s] : %s\n&quot;, m.Subject, string(m.Data))
})

// Matches all of the above
nc.Publish(&quot;foo.bar.baz&quot;, []byte(&quot;Hello World&quot;))

```

## Queue Groups

```go
// All subscriptions with the same queue name will form a queue group.
// Each message will be delivered to only one subscriber per queue group,
// using queuing semantics. You can have as many queue groups as you wish.
// Normal subscribers will continue to work as expected.

nc.QueueSubscribe(&quot;foo&quot;, &quot;job_workers&quot;, func(_ *Msg) {
  received += 1
})
```

## Advanced Usage

```go

// Normally, the library will return an error when trying to connect and
// there is no server running. The RetryOnFailedConnect option will set
// the connection in reconnecting state if it failed to connect right away.
nc, err := nats.Connect(nats.DefaultURL,
    nats.RetryOnFailedConnect(true),
    nats.MaxReconnects(10),
    nats.ReconnectWait(time.Second),
    nats.ReconnectHandler(func(_ *nats.Conn) {
        // Note that this will be invoked for the first asynchronous connect.
    }))
if err != nil {
    // Should not return an error even if it can&#039;t connect, but you still
    // need to check in case there are some configuration errors.
}

// Flush connection to server, returns when all messages have been processed.
nc.Flush()
fmt.Println(&quot;All clear!&quot;)

// FlushTimeout specifies a timeout value as well.
err := nc.FlushTimeout(1*time.Second)
if err != nil {
    fmt.Println(&quot;Flushed timed out!&quot;)
} else {
    fmt.Println(&quot;All clear!&quot;)
}

// Auto-unsubscribe after MAX_WANTED messages received
const MAX_WANTED = 10
sub, err := nc.Subscribe(&quot;foo&quot;)
sub.AutoUnsubscribe(MAX_WANTED)

// Multiple connections
nc1 := nats.Connect(&quot;nats://host1:4222&quot;)
nc2 := nats.Connect(&quot;nats://host2:4222&quot;)

nc1.Subscribe(&quot;foo&quot;, func(m *Msg) {
    fmt.Printf(&quot;Received a message: %s\n&quot;, string(m.Data))
})

nc2.Publish(&quot;foo&quot;, []byte(&quot;Hello World!&quot;))

```

## Clustered Usage

```go

var servers = &quot;nats://localhost:1222, nats://localhost:1223, nats://localhost:1224&quot;

nc, err := nats.Connect(servers)

// Optionally set ReconnectWait and MaxReconnect attempts.
// This example means 10 seconds total per backend.
nc, err = nats.Connect(servers, nats.MaxReconnects(5), nats.ReconnectWait(2 * time.Second))

// You can also add some jitter for the reconnection.
// This call will add up to 500 milliseconds for non TLS connections and 2 seconds for TLS connections.
// If not specified, the library defaults to 100 milliseconds and 1 second, respectively.
nc, err = nats.Connect(servers, nats.ReconnectJitter(500*time.Millisecond, 2*time.Second))

// You can also specify a custom reconnect delay handler. If set, the library will invoke it when it has tried
// all URLs in its list. The value returned will be used as the total sleep time, so add your own jitter.
// The library will pass the number of times it went through the whole list.
nc, err = nats.Connect(servers, nats.CustomReconnectDelay(func(attempts int) time.Duration {
    return someBackoffFunction(attempts)
}))

// Optionally disable randomization of the server pool
nc, err = nats.Connect(servers, nats.DontRandomize())

// Setup callbacks to be notified on disconnects, reconnects and connection closed.
nc, err = nats.Connect(servers,
	nats.DisconnectErrHandler(func(nc *nats.Conn, err error) {
		fmt.Printf(&quot;Got disconnected! Reason: %q\n&quot;, err)
	}),
	nats.ReconnectHandler(func(nc *nats.Conn) {
		fmt.Printf(&quot;Got reconnected to %v!\n&quot;, nc.ConnectedUrl())
	}),
	nats.ClosedHandler(func(nc *nats.Conn) {
		fmt.Printf(&quot;Connection closed. Reason: %q\n&quot;, nc.LastError())
	})
)

// When connecting to a mesh of servers with auto-discovery capabilities,
// you may need to provide a username/password or token in order to connect
// to any server in that mesh when authentication is required.
// Instead of providing the credentials in the initial URL, you will use
// new option setters:
nc, err = nats.Connect(&quot;nats://localhost:4222&quot;, nats.UserInfo(&quot;foo&quot;, &quot;bar&quot;))

// For token based authentication:
nc, err = nats.Connect(&quot;nats://localhost:4222&quot;, nats.Token(&quot;S3cretT0ken&quot;))

// You can even pass the two at the same time in case one of the servers
// in the mesh requires token instead of user name and password.
nc, err = nats.Connect(&quot;nats://localhost:4222&quot;,
    nats.UserInfo(&quot;foo&quot;, &quot;bar&quot;),
    nats.Token(&quot;S3cretT0ken&quot;))

// Note that if credentials are specified in the initial URLs, they take
// precedence on the credentials specified through the options.
// For instance, in the connect call below, the client library will use
// the user &quot;my&quot; and password &quot;pwd&quot; to connect to localhost:4222, however,
// it will use username &quot;foo&quot; and password &quot;bar&quot; when (re)connecting to
// a different server URL that it got as part of the auto-discovery.
nc, err = nats.Connect(&quot;nats://my:pwd@localhost:4222&quot;, nats.UserInfo(&quot;foo&quot;, &quot;bar&quot;))

```

## Context support (+Go 1.7)

```go
ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
defer cancel()

nc, err := nats.Connect(nats.DefaultURL)

// Request with context
msg, err := nc.RequestWithContext(ctx, &quot;foo&quot;, []byte(&quot;bar&quot;))

// Synchronous subscriber with context
sub, err := nc.SubscribeSync(&quot;foo&quot;)
msg, err := sub.NextMsgWithContext(ctx)

```

## Backward compatibility

In the development of nats.go, we are committed to maintaining backward compatibility and ensuring a stable and reliable  experience for all users. In general, we follow the standard go compatibility guidelines.
However, it&#039;s important to clarify our stance on certain types of changes:

- **Expanding structures:**
Adding new fields to structs is not considered a breaking change.

- **Adding methods to exported interfaces:**
Extending public interfaces with new methods is also not viewed as a breaking change within the context of this project. It is important to note that no unexported methods will be added to interfaces allowing users to implement them.

Additionally, this library always supports at least 2 latest minor Go versions. For example, if the latest Go version is 1.22, the library will support Go 1.21 and 1.22.

## License

Unless otherwise noted, the NATS source files are distributed
under the Apache Version 2.0 license found in the LICENSE file.

[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fnats-io%2Fgo-nats.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Fnats-io%2Fgo-nats?ref=badge_large)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[go-vikunja/vikunja]]></title>
            <link>https://github.com/go-vikunja/vikunja</link>
            <guid>https://github.com/go-vikunja/vikunja</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:08 GMT</pubDate>
            <description><![CDATA[The to-do app to organize your life.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/go-vikunja/vikunja">go-vikunja/vikunja</a></h1>
            <p>The to-do app to organize your life.</p>
            <p>Language: Go</p>
            <p>Stars: 3,152</p>
            <p>Forks: 296</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://vikunja.io/images/vikunja-logo.svg&quot; alt=&quot;&quot; style=&quot;display: block;width: 50%;margin: 0 auto;&quot; width=&quot;50%&quot;/&gt;

[![Build Status](https://github.com/go-vikunja/vikunja/actions/workflows/ci.yml/badge.svg)](https://github.com/go-vikunja/vikunja/actions/workflows/ci.yml)
[![License: AGPL-3.0-or-later](https://img.shields.io/badge/License-AGPL--3.0--or--later-blue.svg)](LICENSE)
[![Install](https://img.shields.io/badge/download-v1.0.0-brightgreen.svg)](https://vikunja.io/docs/installing)
[![Docker Pulls](https://img.shields.io/docker/pulls/vikunja/vikunja.svg)](https://hub.docker.com/r/vikunja/vikunja/)
[![Swagger Docs](https://img.shields.io/badge/swagger-docs-brightgreen.svg)](https://try.vikunja.io/api/v1/docs)
[![Go Report Card](https://goreportcard.com/badge/kolaente.dev/vikunja/vikunja)](https://goreportcard.com/report/kolaente.dev/vikunja/vikunja)

# Vikunja

&gt; The Todo-app to organize your life.

If Vikunja is useful to you, please consider [buying me a coffee](https://www.buymeacoffee.com/kolaente), [sponsoring me on GitHub](https://github.com/sponsors/kolaente) or buying [a sticker pack](https://vikunja.io/stickers).
I&#039;m also offering [a hosted version of Vikunja](https://vikunja.cloud/) if you want a hassle-free solution for yourself or your team.

## Table of contents

- [Security Reports](#security-reports)
- [Features](#features)
- [Docs](#docs)
	- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License](#license)
	- [Unsplash Images](#unsplash-images)

## Security Reports

If you find any security-related issues you don&#039;t want to disclose publicly, please use [the contact information on our website](https://vikunja.io/contact/#security).

## Features

See [the features page](https://vikunja.io/features/) on our website for a more exhaustive list or 
try it on [try.vikunja.io](https://try.vikunja.io)!

## Docs

* [Installing](https://vikunja.io/docs/installing/)
* [Build from source](https://vikunja.io/docs/build-from-sources/)
* [Development setup](https://vikunja.io/docs/development/)
* [Magefile](https://vikunja.io/docs/magefile/)
* [Testing](https://vikunja.io/docs/testing/)

All docs can be found on [the Vikunja home page](https://vikunja.io/docs/).

### Roadmap

See [the roadmap](https://my.vikunja.cloud/share/QFyzYEmEYfSyQfTOmIRSwLUpkFjboaBqQCnaPmWd/auth) (hosted on Vikunja!) for more!

## Contributing

Please check out the contribution guidelines on [the website](https://vikunja.io/docs/development/).

## License

Most of this repository is licensed under [AGPL‚Äë3.0‚Äëor‚Äëlater](LICENSE).
The contents of [`desktop/`](desktop/) are licensed under
[GPL‚Äë3.0‚Äëor‚Äëlater](desktop/LICENSE).

### Unsplash Images

Background images from Unsplash are distributed under the [Unsplash License](https://unsplash.com/license). The license requires giving credit to the photographer and Unsplash. See [Unsplash‚Äôs terms](https://unsplash.com/terms) for more information.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[tailscale/tailscale]]></title>
            <link>https://github.com/tailscale/tailscale</link>
            <guid>https://github.com/tailscale/tailscale</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:07 GMT</pubDate>
            <description><![CDATA[The easiest, most secure way to use WireGuard and 2FA.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tailscale/tailscale">tailscale/tailscale</a></h1>
            <p>The easiest, most secure way to use WireGuard and 2FA.</p>
            <p>Language: Go</p>
            <p>Stars: 27,560</p>
            <p>Forks: 2,241</p>
            <p>Stars today: 42 stars today</p>
            <h2>README</h2><pre># Tailscale

https://tailscale.com

Private WireGuard¬Æ networks made easy

## Overview

This repository contains the majority of Tailscale&#039;s open source code.
Notably, it includes the `tailscaled` daemon and
the `tailscale` CLI tool. The `tailscaled` daemon runs on Linux, Windows,
[macOS](https://tailscale.com/kb/1065/macos-variants/), and to varying degrees
on FreeBSD and OpenBSD. The Tailscale iOS and Android apps use this repo&#039;s
code, but this repo doesn&#039;t contain the mobile GUI code.

Other [Tailscale repos](https://github.com/orgs/tailscale/repositories) of note:

* the Android app is at https://github.com/tailscale/tailscale-android
* the Synology package is at https://github.com/tailscale/tailscale-synology
* the QNAP package is at https://github.com/tailscale/tailscale-qpkg
* the Chocolatey packaging is at https://github.com/tailscale/tailscale-chocolatey

For background on which parts of Tailscale are open source and why,
see [https://tailscale.com/opensource/](https://tailscale.com/opensource/).

## Using

We serve packages for a variety of distros and platforms at
[https://pkgs.tailscale.com](https://pkgs.tailscale.com/).

## Other clients

The [macOS, iOS, and Windows clients](https://tailscale.com/download)
use the code in this repository but additionally include small GUI
wrappers. The GUI wrappers on non-open source platforms are themselves
not open source.

## Building

We always require the latest Go release, currently Go 1.25. (While we build
releases with our [Go fork](https://github.com/tailscale/go/), its use is not
required.)

```
go install tailscale.com/cmd/tailscale{,d}
```

If you&#039;re packaging Tailscale for distribution, use `build_dist.sh`
instead, to burn commit IDs and version info into the binaries:

```
./build_dist.sh tailscale.com/cmd/tailscale
./build_dist.sh tailscale.com/cmd/tailscaled
```

If your distro has conventions that preclude the use of
`build_dist.sh`, please do the equivalent of what it does in your
distro&#039;s way, so that bug reports contain useful version information.

## Bugs

Please file any issues about this code or the hosted service on
[the issue tracker](https://github.com/tailscale/tailscale/issues).

## Contributing

PRs welcome! But please file bugs. Commit messages should [reference
bugs](https://docs.github.com/en/github/writing-on-github/autolinked-references-and-urls).

We require [Developer Certificate of
Origin](https://en.wikipedia.org/wiki/Developer_Certificate_of_Origin)
`Signed-off-by` lines in commits.

See [commit-messages.md](docs/commit-messages.md) (or skim `git log`) for our commit message style.

## About Us

[Tailscale](https://tailscale.com/) is primarily developed by the
people at https://github.com/orgs/tailscale/people. For other contributors,
see:

* https://github.com/tailscale/tailscale/graphs/contributors
* https://github.com/tailscale/tailscale-android/graphs/contributors

## Legal

WireGuard is a registered trademark of Jason A. Donenfeld.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gin-gonic/gin]]></title>
            <link>https://github.com/gin-gonic/gin</link>
            <guid>https://github.com/gin-gonic/gin</guid>
            <pubDate>Thu, 29 Jan 2026 00:06:06 GMT</pubDate>
            <description><![CDATA[Gin is a high-performance HTTP web framework written in Go. It provides a Martini-like API but with significantly better performance‚Äîup to 40 times faster‚Äîthanks to httprouter. Gin is designed for building REST APIs, web applications, and microservices.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gin-gonic/gin">gin-gonic/gin</a></h1>
            <p>Gin is a high-performance HTTP web framework written in Go. It provides a Martini-like API but with significantly better performance‚Äîup to 40 times faster‚Äîthanks to httprouter. Gin is designed for building REST APIs, web applications, and microservices.</p>
            <p>Language: Go</p>
            <p>Stars: 87,826</p>
            <p>Forks: 8,548</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># Gin Web Framework

&lt;img align=&quot;right&quot; width=&quot;159px&quot; src=&quot;https://raw.githubusercontent.com/gin-gonic/logo/master/color.png&quot;&gt;

[![Build Status](https://github.com/gin-gonic/gin/actions/workflows/gin.yml/badge.svg?branch=master)](https://github.com/gin-gonic/gin/actions/workflows/gin.yml)
[![Trivy Security Scan](https://github.com/gin-gonic/gin/actions/workflows/trivy-scan.yml/badge.svg)](https://github.com/gin-gonic/gin/actions/workflows/trivy-scan.yml)
[![codecov](https://codecov.io/gh/gin-gonic/gin/branch/master/graph/badge.svg)](https://codecov.io/gh/gin-gonic/gin)
[![Go Report Card](https://goreportcard.com/badge/github.com/gin-gonic/gin)](https://goreportcard.com/report/github.com/gin-gonic/gin)
[![Go Reference](https://pkg.go.dev/badge/github.com/gin-gonic/gin?status.svg)](https://pkg.go.dev/github.com/gin-gonic/gin?tab=doc)
[![Sourcegraph](https://sourcegraph.com/github.com/gin-gonic/gin/-/badge.svg)](https://sourcegraph.com/github.com/gin-gonic/gin?badge)
[![Open Source Helpers](https://www.codetriage.com/gin-gonic/gin/badges/users.svg)](https://www.codetriage.com/gin-gonic/gin)
[![Release](https://img.shields.io/github/release/gin-gonic/gin.svg?style=flat-square)](https://github.com/gin-gonic/gin/releases)

## üì∞ [Announcing Gin 1.11.0!](https://gin-gonic.com/en/blog/news/gin-1-11-0-release-announcement/)

Read about the latest features and improvements in Gin 1.11.0 on our official blog.

---

Gin is a high-performance HTTP web framework written in [Go](https://go.dev/). It provides a Martini-like API but with significantly better performance‚Äîup to 40 times faster‚Äîthanks to [httprouter](https://github.com/julienschmidt/httprouter). Gin is designed for building REST APIs, web applications, and microservices where speed and developer productivity are essential.

**Why choose Gin?**

Gin combines the simplicity of Express.js-style routing with Go&#039;s performance characteristics, making it ideal for:

- Building high-throughput REST APIs
- Developing microservices that need to handle many concurrent requests
- Creating web applications that require fast response times
- Prototyping web services quickly with minimal boilerplate

**Gin&#039;s key features:**

- **Zero allocation router** - Extremely memory-efficient routing with no heap allocations
- **High performance** - Benchmarks show superior speed compared to other Go web frameworks
- **Middleware support** - Extensible middleware system for authentication, logging, CORS, etc.
- **Crash-free** - Built-in recovery middleware prevents panics from crashing your server
- **JSON validation** - Automatic request/response JSON binding and validation
- **Route grouping** - Organize related routes and apply common middleware
- **Error management** - Centralized error handling and logging
- **Built-in rendering** - Support for JSON, XML, HTML templates, and more
- **Extensible** - Large ecosystem of community middleware and plugins

## Getting Started

### Prerequisites

- **Go version**: Gin requires [Go](https://go.dev/) version [1.24](https://go.dev/doc/devel/release#go1.24.0) or above
- **Basic Go knowledge**: Familiarity with Go syntax and package management is helpful

### Installation

With [Go&#039;s module support](https://go.dev/wiki/Modules#how-to-use-modules), simply import Gin in your code and Go will automatically fetch it during build:

```go
import &quot;github.com/gin-gonic/gin&quot;
```

### Your First Gin Application

Here&#039;s a complete example that demonstrates Gin&#039;s simplicity:

```go
package main

import (
  &quot;log&quot;
  &quot;net/http&quot;

  &quot;github.com/gin-gonic/gin&quot;
)

func main() {
  // Create a Gin router with default middleware (logger and recovery)
  r := gin.Default()

  // Define a simple GET endpoint
  r.GET(&quot;/ping&quot;, func(c *gin.Context) {
    // Return JSON response
    c.JSON(http.StatusOK, gin.H{
      &quot;message&quot;: &quot;pong&quot;,
    })
  })

  // Start server on port 8080 (default)
  // Server will listen on 0.0.0.0:8080 (localhost:8080 on Windows)
  if err := r.Run(); err != nil {
    log.Fatalf(&quot;failed to run server: %v&quot;, err)
  }
}
```

**Running the application:**

1. Save the code above as `main.go`
2. Run the application:

   ```sh
   go run main.go
   ```

3. Open your browser and visit [`http://localhost:8080/ping`](http://localhost:8080/ping)
4. You should see: `{&quot;message&quot;:&quot;pong&quot;}`

**What this example demonstrates:**

- Creating a Gin router with default middleware
- Defining HTTP endpoints with simple handler functions
- Returning JSON responses
- Starting an HTTP server

### Next Steps

After running your first Gin application, explore these resources to learn more:

#### üìö Learning Resources

- **[Gin Quick Start Guide](docs/doc.md)** - Comprehensive tutorial with API examples and build configurations
- **[Example Repository](https://github.com/gin-gonic/examples)** - Ready-to-run examples demonstrating various Gin use cases:
  - REST API development
  - Authentication &amp; middleware
  - File uploads and downloads
  - WebSocket connections
  - Template rendering

## üìñ Documentation

### API Reference

- **[Go.dev API Documentation](https://pkg.go.dev/github.com/gin-gonic/gin)** - Complete API reference with examples

### User Guides

The comprehensive documentation is available on [gin-gonic.com](https://gin-gonic.com) in multiple languages:

- [English](https://gin-gonic.com/en/docs/) | [ÁÆÄ‰Ωì‰∏≠Êñá](https://gin-gonic.com/zh-cn/docs/) | [ÁπÅÈ´î‰∏≠Êñá](https://gin-gonic.com/zh-tw/docs/)
- [Êó•Êú¨Ë™û](https://gin-gonic.com/ja/docs/) | [ÌïúÍµ≠Ïñ¥](https://gin-gonic.com/ko-kr/docs/) | [Espa√±ol](https://gin-gonic.com/es/docs/)
- [Turkish](https://gin-gonic.com/tr/docs/) | [Persian](https://gin-gonic.com/fa/docs/) | [Portugu√™s](https://gin-gonic.com/pt/docs/)
- [Russian](https://gin-gonic.com/ru/docs/) | [Indonesian](https://gin-gonic.com/id/docs/)

### Official Tutorials

- [Go.dev Tutorial: Developing a RESTful API with Go and Gin](https://go.dev/doc/tutorial/web-service-gin)

## ‚ö° Performance Benchmarks

Gin demonstrates exceptional performance compared to other Go web frameworks. It uses a custom version of [HttpRouter](https://github.com/julienschmidt/httprouter) for maximum efficiency. [View detailed benchmarks ‚Üí](/BENCHMARKS.md)

**Gin vs. Other Go Frameworks** (GitHub API routing benchmark):

| Benchmark name                 |       (1) |             (2) |          (3) |             (4) |
| ------------------------------ | --------: | --------------: | -----------: | --------------: |
| BenchmarkGin_GithubAll         | **43550** | **27364 ns/op** |   **0 B/op** | **0 allocs/op** |
| BenchmarkAce_GithubAll         |     40543 |     29670 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkAero_GithubAll        |     57632 |     20648 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkBear_GithubAll        |      9234 |    216179 ns/op |   86448 B/op |   943 allocs/op |
| BenchmarkBeego_GithubAll       |      7407 |    243496 ns/op |   71456 B/op |   609 allocs/op |
| BenchmarkBone_GithubAll        |       420 |   2922835 ns/op |  720160 B/op |  8620 allocs/op |
| BenchmarkChi_GithubAll         |      7620 |    238331 ns/op |   87696 B/op |   609 allocs/op |
| BenchmarkDenco_GithubAll       |     18355 |     64494 ns/op |   20224 B/op |   167 allocs/op |
| BenchmarkEcho_GithubAll        |     31251 |     38479 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkGocraftWeb_GithubAll  |      4117 |    300062 ns/op |  131656 B/op |  1686 allocs/op |
| BenchmarkGoji_GithubAll        |      3274 |    416158 ns/op |   56112 B/op |   334 allocs/op |
| BenchmarkGojiv2_GithubAll      |      1402 |    870518 ns/op |  352720 B/op |  4321 allocs/op |
| BenchmarkGoJsonRest_GithubAll  |      2976 |    401507 ns/op |  134371 B/op |  2737 allocs/op |
| BenchmarkGoRestful_GithubAll   |       410 |   2913158 ns/op |  910144 B/op |  2938 allocs/op |
| BenchmarkGorillaMux_GithubAll  |       346 |   3384987 ns/op |  251650 B/op |  1994 allocs/op |
| BenchmarkGowwwRouter_GithubAll |     10000 |    143025 ns/op |   72144 B/op |   501 allocs/op |
| BenchmarkHttpRouter_GithubAll  |     55938 |     21360 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkHttpTreeMux_GithubAll |     10000 |    153944 ns/op |   65856 B/op |   671 allocs/op |
| BenchmarkKocha_GithubAll       |     10000 |    106315 ns/op |   23304 B/op |   843 allocs/op |
| BenchmarkLARS_GithubAll        |     47779 |     25084 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkMacaron_GithubAll     |      3266 |    371907 ns/op |  149409 B/op |  1624 allocs/op |
| BenchmarkMartini_GithubAll     |       331 |   3444706 ns/op |  226551 B/op |  2325 allocs/op |
| BenchmarkPat_GithubAll         |       273 |   4381818 ns/op | 1483152 B/op | 26963 allocs/op |
| BenchmarkPossum_GithubAll      |     10000 |    164367 ns/op |   84448 B/op |   609 allocs/op |
| BenchmarkR2router_GithubAll    |     10000 |    160220 ns/op |   77328 B/op |   979 allocs/op |
| BenchmarkRivet_GithubAll       |     14625 |     82453 ns/op |   16272 B/op |   167 allocs/op |
| BenchmarkTango_GithubAll       |      6255 |    279611 ns/op |   63826 B/op |  1618 allocs/op |
| BenchmarkTigerTonic_GithubAll  |      2008 |    687874 ns/op |  193856 B/op |  4474 allocs/op |
| BenchmarkTraffic_GithubAll     |       355 |   3478508 ns/op |  820744 B/op | 14114 allocs/op |
| BenchmarkVulcan_GithubAll      |      6885 |    193333 ns/op |   19894 B/op |   609 allocs/op |

- (1): Total Repetitions achieved in constant time, higher means more confident result
- (2): Single Repetition Duration (ns/op), lower is better
- (3): Heap Memory (B/op), lower is better
- (4): Average Allocations per Repetition (allocs/op), lower is better

## üîå Middleware Ecosystem

Gin has a rich ecosystem of middleware for common web development needs. Explore community-contributed middleware:

- **[gin-contrib](https://github.com/gin-contrib)** - Official middleware collection including:
  - Authentication (JWT, Basic Auth, Sessions)
  - CORS, Rate limiting, Compression
  - Logging, Metrics, Tracing
  - Static file serving, Template engines
- **[gin-gonic/contrib](https://github.com/gin-gonic/contrib)** - Additional community middleware

## üè¢ Production Usage

Gin powers many high-traffic applications and services in production:

- **[gorush](https://github.com/appleboy/gorush)** - High-performance push notification server
- **[fnproject](https://github.com/fnproject/fn)** - Container-native, serverless platform
- **[photoprism](https://github.com/photoprism/photoprism)** - AI-powered personal photo management
- **[lura](https://github.com/luraproject/lura)** - Ultra-performant API Gateway framework
- **[picfit](https://github.com/thoas/picfit)** - Real-time image processing server
- **[dkron](https://github.com/distribworks/dkron)** - Distributed job scheduling system

## ü§ù Contributing

Gin is the work of hundreds of contributors from around the world. We welcome and appreciate your contributions!

### How to Contribute

- üêõ **Report bugs** - Help us identify and fix issues
- üí° **Suggest features** - Share your ideas for improvements
- üìù **Improve documentation** - Help make our docs clearer
- üîß **Submit code** - Fix bugs or implement new features
- üß™ **Write tests** - Improve our test coverage

### Getting Started with Contributing

1. Check out our [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines
2. Join our community discussions and ask questions

**All contributions are valued and help make Gin better for everyone!**
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>