<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Sat, 17 Jan 2026 00:05:17 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[docker/compose]]></title>
            <link>https://github.com/docker/compose</link>
            <guid>https://github.com/docker/compose</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:17 GMT</pubDate>
            <description><![CDATA[Define and run multi-container applications with Docker]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/docker/compose">docker/compose</a></h1>
            <p>Define and run multi-container applications with Docker</p>
            <p>Language: Go</p>
            <p>Stars: 36,829</p>
            <p>Forks: 5,703</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># Table of Contents
- [Docker Compose](#docker-compose)
- [Where to get Docker Compose](#where-to-get-docker-compose)
    + [Windows and macOS](#windows-and-macos)
    + [Linux](#linux)
- [Quick Start](#quick-start)
- [Contributing](#contributing)
- [Legacy](#legacy)

# Docker Compose

[![GitHub release](https://img.shields.io/github/v/release/docker/compose.svg?style=flat-square)](https://github.com/docker/compose/releases/latest)
[![PkgGoDev](https://img.shields.io/badge/go.dev-docs-007d9c?style=flat-square&amp;logo=go&amp;logoColor=white)](https://pkg.go.dev/github.com/docker/compose/v5)
[![Build Status](https://img.shields.io/github/actions/workflow/status/docker/compose/ci.yml?label=ci&amp;logo=github&amp;style=flat-square)](https://github.com/docker/compose/actions?query=workflow%3Aci)
[![Go Report Card](https://goreportcard.com/badge/github.com/docker/compose/v5?style=flat-square)](https://goreportcard.com/report/github.com/docker/compose/v5)
[![Codecov](https://codecov.io/gh/docker/compose/branch/main/graph/badge.svg?token=HP3K4Y4ctu)](https://codecov.io/gh/docker/compose)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/docker/compose/badge)](https://api.securityscorecards.dev/projects/github.com/docker/compose)
![Docker Compose](logo.png?raw=true &quot;Docker Compose Logo&quot;)

Docker Compose is a tool for running multi-container applications on Docker
defined using the [Compose file format](https://compose-spec.io).
A Compose file is used to define how one or more containers that make up
your application are configured.
Once you have a Compose file, you can create and start your application with a
single command: `docker compose up`.

&gt; **Note**: About Docker Swarm
&gt; Docker Swarm used to rely on the legacy compose file format but did not adopt the compose specification
&gt; so is missing some of the recent enhancements in the compose syntax. After 
&gt; [acquisition by Mirantis](https://www.mirantis.com/software/swarm/) swarm isn&#039;t maintained by Docker Inc, and
&gt; as such some Docker Compose features aren&#039;t accessible to swarm users.

# Where to get Docker Compose

### Windows and macOS

Docker Compose is included in
[Docker Desktop](https://www.docker.com/products/docker-desktop/)
for Windows and macOS.

### Linux

You can download Docker Compose binaries from the
[release page](https://github.com/docker/compose/releases) on this repository.

Rename the relevant binary for your OS to `docker-compose` and copy it to `$HOME/.docker/cli-plugins`

Or copy it into one of these folders to install it system-wide:

* `/usr/local/lib/docker/cli-plugins` OR `/usr/local/libexec/docker/cli-plugins`
* `/usr/lib/docker/cli-plugins` OR `/usr/libexec/docker/cli-plugins`

(might require making the downloaded file executable with `chmod +x`)


Quick Start
-----------

Using Docker Compose is a three-step process:
1. Define your app&#039;s environment with a `Dockerfile` so it can be
   reproduced anywhere.
2. Define the services that make up your app in `compose.yaml` so
   they can be run together in an isolated environment.
3. Lastly, run `docker compose up` and Compose will start and run your entire
   app.

A Compose file looks like this:

```yaml
services:
  web:
    build: .
    ports:
      - &quot;5000:5000&quot;
    volumes:
      - .:/code
  redis:
    image: redis
```

Contributing
------------

Want to help develop Docker Compose? Check out our
[contributing documentation](CONTRIBUTING.md).

If you find an issue, please report it on the
[issue tracker](https://github.com/docker/compose/issues/new/choose).

Legacy
-------------

The Python version of Compose is available under the `v1` [branch](https://github.com/docker/compose/tree/v1).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mudler/LocalAI]]></title>
            <link>https://github.com/mudler/LocalAI</link>
            <guid>https://github.com/mudler/LocalAI</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:16 GMT</pubDate>
            <description><![CDATA[ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, MCP, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mudler/LocalAI">mudler/LocalAI</a></h1>
            <p>ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, MCP, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference</p>
            <p>Language: Go</p>
            <p>Stars: 42,089</p>
            <p>Forks: 3,444</p>
            <p>Stars today: 254 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;img width=&quot;300&quot; src=&quot;./core/http/static/logo.png&quot;&gt; &lt;br&gt;
&lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/fork&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI forks&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/stargazers&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI stars&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/pulls&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI pull-requests&quot;/&gt;
&lt;/a&gt;
&lt;a href=&#039;https://github.com/go-skynet/LocalAI/releases&#039;&gt;
&lt;img src=&#039;https://img.shields.io/github/release/go-skynet/LocalAI?&amp;label=Latest&amp;style=for-the-badge&#039;&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://hub.docker.com/r/localai/localai&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker&quot; alt=&quot;LocalAI Docker hub&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;tag=latest&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/quay.io-images-important.svg?&quot; alt=&quot;LocalAI Quay.io&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://twitter.com/LocalAI_API&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white&amp;label=LocalAI_API&quot; alt=&quot;Follow LocalAI_API&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://discord.gg/uJAeKSAGDy&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?color=blue&amp;label=Discord&amp;style=for-the-badge&amp;query=approximate_member_count&amp;url=https%3A%2F%2Fdiscordapp.com%2Fapi%2Finvites%2FuJAeKSAGDy%3Fwith_counts%3Dtrue&amp;logo=discord&quot; alt=&quot;Join LocalAI Discord Community&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/5539&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/5539&quot; alt=&quot;mudler%2FLocalAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; :bulb: Get help - [‚ùìFAQ](https://localai.io/faq/) [üí≠Discussions](https://github.com/go-skynet/LocalAI/discussions) [:speech_balloon: Discord](https://discord.gg/uJAeKSAGDy) [:book: Documentation website](https://localai.io/)
&gt;
&gt; [üíª Quickstart](https://localai.io/basics/getting_started/) [üñºÔ∏è Models](https://models.localai.io/) [üöÄ Roadmap](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap) [üõ´ Examples](https://github.com/mudler/LocalAI-examples) Try on 
[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;logo=telegram&amp;logoColor=white)](https://t.me/localaiofficial_bot)

[![tests](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml)[![Build and Release](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml)[![build container images](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml)[![Bump dependencies](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml)[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai)](https://artifacthub.io/packages/search?repo=localai)

**LocalAI** is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that&#039;s compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by [Ettore Di Giacinto](https://github.com/mudler).


## üìöüÜï Local Stack Family

üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:

&lt;table&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png&quot; width=&quot;300&quot; alt=&quot;LocalAGI Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI&#039;s Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png&quot; width=&quot;300&quot; alt=&quot;LocalRecall Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Screenshots / Video

### Youtube video

&lt;h1 align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=PDqYhB9nNHA&quot; target=&quot;_blank&quot;&gt; &lt;img width=&quot;300&quot; src=&quot;https://img.youtube.com/vi/PDqYhB9nNHA/0.jpg&quot;&gt; &lt;/a&gt;&lt;br&gt;
&lt;br&gt;
&lt;/h1&gt;


### Screenshots

| Talk Interface | Generate Audio |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk](./docs/assets/images/screenshots/screenshot_tts.png) | ![Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low](./docs/assets/images/screenshots/screenshot_tts.png) |

| Models Overview | Generate Images |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-20 LocalAI - Models](./docs/assets/images/screenshots/screenshot_gallery.png) | ![Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev](./docs/assets/images/screenshots/screenshot_image.png) |

| Chat Interface | Home |
| --- | --- |
| ![Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5](./docs/assets/images/screenshots/screenshot_chat.png) | ![Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)](./docs/assets/images/screenshots/screenshot_home.png) |

| Login | Swarm |
| --- | --- |
|![Screenshot 2025-03-31 at 12-09-59 ](./docs/assets/images/screenshots/screenshot_login.png) | ![Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard](./docs/assets/images/screenshots/screenshot_p2p.png) |

## üíª Quickstart

&gt; ‚ö†Ô∏è **Note:** The `install.sh` script is currently experiencing issues due to the heavy changes currently undergoing in LocalAI and may produce broken or misconfigured installations. Please use Docker installation (see below) or manual binary installation until [issue #8032](https://github.com/mudler/LocalAI/issues/8032) is resolved.

Run the installer script:

```bash
# Basic installation
curl https://localai.io/install.sh | sh
```

For more installation options, see [Installer Options](https://localai.io/installation/).

### macOS Download:

&lt;a href=&quot;https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;logo=apple&amp;logoColor=white&quot; alt=&quot;Download LocalAI for macOS&quot;/&gt;
&lt;/a&gt;

&gt; Note: the DMGs are not signed by Apple as quarantined. See https://github.com/mudler/LocalAI/issues/6268 for a workaround, fix is tracked here: https://github.com/mudler/LocalAI/issues/6244

### Containers (Docker, podman, ...)

&gt; **üí° Docker Run vs Docker Start**
&gt; 
&gt; - `docker run` creates and starts a new container. If a container with the same name already exists, this command will fail.
&gt; - `docker start` starts an existing container that was previously created with `docker run`.
&gt; 
&gt; If you&#039;ve already run LocalAI before and want to start it again, use: `docker start -i local-ai`

#### CPU only image:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
```

#### NVIDIA GPU Images:

```bash
# CUDA 13.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-13

# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# NVIDIA Jetson (L4T) ARM64
# CUDA 12 (for Nvidia AGX Orin and similar platforms)
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64

# CUDA 13 (for Nvidia DGX Spark)
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64-cuda-13
```

#### AMD GPU Images (ROCm):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
```

#### Intel GPU Images (oneAPI):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
```

#### Vulkan GPU Images:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
```

#### AIO Images (pre-downloaded models):

```bash
# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 13 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-13

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
```

For more information about the AIO images and pre-downloaded models, see [Container Documentation](https://localai.io/basics/container/).

To load models:

```bash
# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
```

&gt; ‚ö° **Automatic Backend Detection**: When you install models from the gallery or YAML files, LocalAI automatically detects your system&#039;s GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see [GPU Acceleration](https://localai.io/features/gpu-acceleration/#automatic-backend-detection).

For more information, see [üíª Getting started](https://localai.io/basics/getting_started/index.html), if you are interested in our roadmap items and future enhancements, you can see the [Issues labeled as Roadmap here](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)

## üì∞ Latest project news

- December 2025: [Dynamic Memory Resource reclaimer](https://github.com/mudler/LocalAI/pull/7583), [Automatic fitting of models to multiple GPUS(llama.cpp)](https://github.com/mudler/LocalAI/pull/7584), [Added Vibevoice backend](https://github.com/mudler/LocalAI/pull/7494)
- November 2025: Major improvements to the UX. Among these: [Import models via URL](https://github.com/mudler/LocalAI/pull/7245) and [Multiple chats and history](https://github.com/mudler/LocalAI/pull/7325)
- October 2025: üîå [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) support added for agentic capabilities with external tools
- September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.
- August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with `development` suffix in the gallery ): https://github.com/mudler/LocalAI/pull/6049 https://github.com/mudler/LocalAI/pull/6119 https://github.com/mudler/LocalAI/pull/6121 https://github.com/mudler/LocalAI/pull/6060
- July/August 2025: üîç [Object Detection](https://localai.io/features/object-detection/) added to the API featuring [rf-detr](https://github.com/roboflow/rf-detr)
- July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. [Read the release notes](https://github.com/mudler/LocalAI/releases/tag/v3.2.0)
- June 2025: [Backend management](https://github.com/mudler/LocalAI/pull/5607) has been added. Attention: extras images are going to be deprecated from the next release! Read [the backend management PR](https://github.com/mudler/LocalAI/pull/5607).
- May 2025: [Audio input](https://github.com/mudler/LocalAI/pull/5466) and [Reranking](https://github.com/mudler/LocalAI/pull/5396) in llama.cpp backend, [Realtime API](https://github.com/mudler/LocalAI/pull/5392),  Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).
- May 2025: Important: image name changes [See release](https://github.com/mudler/LocalAI/releases/tag/v2.29.0)
- Apr 2025: Rebrand, WebUI enhancements
- Apr 2025: [LocalAGI](https://github.com/mudler/LocalAGI) and [LocalRecall](https://github.com/mudler/LocalRecall) join the LocalAI family stack.
- Apr 2025: WebUI overhaul, AIO images updates
- Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images
- Jan 2025: LocalAI model release: https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3, SANA support in diffusers: https://github.com/mudler/LocalAI/pull/4603
- Dec 2024: stablediffusion.cpp backend (ggml) added ( https://github.com/mudler/LocalAI/pull/4289 )
- Nov 2024: Bark.cpp backend added ( https://github.com/mudler/LocalAI/pull/4287 )
- Nov 2024: Voice activity detection models (**VAD**) added to the API: https://github.com/mudler/LocalAI/pull/4204
- Oct 2024: examples moved to [LocalAI-examples](https://github.com/mudler/LocalAI-examples)
- Aug 2024:  üÜï FLUX-1, [P2P Explorer](https://explorer.localai.io)
- July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: https://github.com/mudler/LocalAI/pull/2723. P2P Global community pools: https://github.com/mudler/LocalAI/issues/3113
- May 2024: üî•üî• Decentralized P2P llama.cpp:  https://github.com/mudler/LocalAI/pull/2343 (peer2peer llama.cpp!) üëâ Docs  https://localai.io/features/distribute/
- May 2024: üî•üî• Distributed inferencing: https://github.com/mudler/LocalAI/pull/2324
- April 2024: Reranker API: https://github.com/mudler/LocalAI/pull/2121

Roadmap items: [List of issues](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)

## üöÄ [Features](https://localai.io/features/)

- üß© [Backend Gallery](https://localai.io/backends/): Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.
- üìñ [Text generation with GPTs](https://localai.io/features/text-generation/) (`llama.cpp`, `transformers`, `vllm` ... [:book: and more](https://localai.io/model-compatibility/index.html#model-compatibility-table))
- üó£ [Text to Audio](https://localai.io/features/text-to-audio/)
- üîà [Audio to Text](https://localai.io/features/audio-to-text/) (Audio transcription with `whisper.cpp`)
- üé® [Image generation](https://localai.io/features/image-generation)
- üî• [OpenAI-alike tools API](https://localai.io/features/openai-functions/) 
- üß† [Embeddings generation for vector databases](https://localai.io/features/embeddings/)
- ‚úçÔ∏è [Constrained grammars](https://localai.io/features/constrained_grammars/)
- üñºÔ∏è [Download Models directly from Huggingface ](https://localai.io/models/)
- ü•Ω [Vision API](https://localai.io/features/gpt-vision/)
- üîç [Object Detection](https://localai.io/features/object-detection/)
- üìà [Reranker API](https://localai.io/features/reranker/)
- üÜïüñß [P2P Inferencing](https://localai.io/features/distribute/)
- üÜïüîå [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) - Agentic capabilities with external tools and [LocalAGI&#039;s Agentic capabilities](https://github.com/mudler/LocalAGI)
- üîä Voice activity detection (Silero-VAD support)
- üåç Integrated WebUI!

## üß© Supported Backends &amp; Acceleration

LocalAI supports a comprehensive range of AI backends with multiple acceleration options:

### Text Generation &amp; Language Models
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **llama.cpp** | LLM inference in C/C++ | CUDA 12/13, ROCm, Intel SYCL, Vulkan, Metal, CPU |
| **vLLM** | Fast LLM inference with PagedAttention | CUDA 12/13, ROCm, Intel |
| **transformers** | HuggingFace transformers framework | CUDA 12/13, ROCm, Intel, CPU |
| **exllama2** | GPTQ inference library | CUDA 12/13 |
| **MLX** | Apple Silicon LLM inference | Metal (M1/M2/M3+) |
| **MLX-VLM** | Apple Silicon Vision-Language Models | Metal (M1/M2/M3+) |

### Audio &amp; Speech Processing
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **whisper.cpp** | OpenAI Whisper in C/C++ | CUDA 12/13, ROCm, Intel SYCL, Vulkan, CPU |
| **faster-whisper** | Fast Whisper with CTranslate2 | CUDA 12/13, ROCm, Intel, CPU |
| **bark** | Text-to-audio generation | CUDA 12/13, ROCm, Intel |
| **bark-cpp** | C++ implementation of Bark | CUDA, Metal, CPU |
| **coqui** | Advanced TTS with 1100+ languages | CUDA 12/13, ROCm, Intel, CPU |
| **kokoro** | Lightweight TTS model | CUDA 12/13, ROCm, Intel, CPU |
| **chatterbox** | Production-grade TTS | CUDA 12/13, CPU |
| **piper** | Fast neural TTS system | CPU |
| **kitten-tts** | Kitten TTS models | CPU |
| **silero-vad** | Voice Activity Detection | CPU |
| **neutts** | Text-to-speech with voice cloning | CUDA 12/13, ROCm, CPU |
| **vibevoice** | Real-time TTS with voice cloning | CUDA 12/13, ROCm, Intel, CPU |
| **pocket-tts** | Lightweight CPU-based TTS | CUDA 12/13, ROCm, Intel, CPU |

### Image &amp; Video Generation
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **stablediffusion.cpp** | Stable Diffusion in C/C++ | CUDA 12/13, Intel SYCL, Vulkan, CPU |
| **diffusers** | HuggingFace diffusion models | CUDA 12/13, ROCm, Intel, Metal, CPU |

### Specialized AI Tasks
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **rfdetr** | Real-time object detection | CUDA 12/13, Intel, CPU |
| **rerankers** | Document reranking API | CUDA 12/13, ROCm, Intel, CPU |
| **local-store** | Vector database | CPU |
| **huggingface** | HuggingFace API integration | API-based |

### Hardware Acceleration Matrix

| Acceleration Type | Supported Backends | Hardware Support |
|-------------------|-------------------|------------------|
| **NVIDIA CUDA 12** | All CUDA-compatible backends | Nvidia hardware |
| **NVIDIA CUDA 13** | All CUDA-compatible backends | Nvidia hardware |
| **AMD ROCm** | llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts, vibevoice, pocket-tts | AMD Graphics |
| **Intel oneAPI** | llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark, vibevoice, pocket-tts | Intel Arc, Intel iGPUs |
| **Apple Metal** | llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp | Apple M1/M2/M3+ |
| **Vulkan** | llama.cpp, whisper, stablediffusion | Cross-platform GPUs |
| **NVIDIA Jetson (CUDA 12)** | llama.cpp, whisper, stablediffusi

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Tencent/WeKnora]]></title>
            <link>https://github.com/Tencent/WeKnora</link>
            <guid>https://github.com/Tencent/WeKnora</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:15 GMT</pubDate>
            <description><![CDATA[LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Tencent/WeKnora">Tencent/WeKnora</a></h1>
            <p>LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.</p>
            <p>Language: Go</p>
            <p>Stars: 11,999</p>
            <p>Forks: 1,323</p>
            <p>Stars today: 173 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;img src=&quot;./docs/images/logo.png&quot; alt=&quot;WeKnora Logo&quot; height=&quot;120&quot;/&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/15289&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://trendshift.io/api/badge/repositories/15289&quot; alt=&quot;Tencent%2FWeKnora | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
    &lt;/a&gt;
  &lt;/picture&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://weknora.weixin.qq.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;ÂÆòÊñπÁΩëÁ´ô&quot; src=&quot;https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://chatbot.weixin.qq.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞&quot; src=&quot;https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/Tencent/WeKnora/blob/main/LICENSE&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;License&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;./CHANGELOG.md&quot;&gt;
        &lt;img alt=&quot;Version&quot; src=&quot;https://img.shields.io/badge/version-0.2.10-2e6cc4?labelColor=d4eaf7&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
| &lt;b&gt;English&lt;/b&gt; | &lt;a href=&quot;./README_CN.md&quot;&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;./README_JA.md&quot;&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; |
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;h4 align=&quot;center&quot;&gt;

  [Overview](#-overview) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [Key Features](#-key-features) ‚Ä¢ [Getting Started](#-getting-started) ‚Ä¢ [API Reference](#-api-reference) ‚Ä¢ [Developer Guide](#-developer-guide)
  
  &lt;/h4&gt;
&lt;/p&gt;

# üí° WeKnora - LLM-Powered Document Understanding &amp; Retrieval Framework

## üìå Overview

[**WeKnora**](https://weknora.weixin.qq.com) is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents. 

It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the **RAG (Retrieval-Augmented Generation)** paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.

**Website:** https://weknora.weixin.qq.com

## ‚ú® Latest Updates

**v0.2.0 Highlights:**

- ü§ñ **Agent Mode**: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection
- üìö **Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry
- ‚öôÔ∏è **Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior
- üåê **Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine
- üîå **MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods
- üé® **New UI**: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade
- ‚ö° **Infrastructure Upgrade**: Introduced MQ async task management, support for automatic database migration, and fast development mode

## üîí Security Notice

**Important:** Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:

- Deploy WeKnora services in internal/private network environments rather than public internet
- Avoid exposing the service directly to public networks to prevent potential information leakage
- Configure proper firewall rules and access controls for your deployment environment
- Regularly update to the latest version for security patches and improvements

## üèóÔ∏è Architecture

![weknora-architecture.png](./docs/images/architecture.png)

WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.

## üéØ Key Features

- **ü§ñ Agent Mode**: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection
- **üîç Precise Understanding**: Structured content extraction from PDFs, Word documents, images and more into unified semantic views
- **üß† Intelligent Reasoning**: Leverages LLMs to understand document context and user intent for accurate Q&amp;A and multi-turn conversations
- **üìö Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities
- **üîß Flexible Extension**: All components from parsing and embedding to retrieval and generation are decoupled for easy customization
- **‚ö° Efficient Retrieval**: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support
- **üåê Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine
- **üîå MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods
- **‚öôÔ∏è Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior
- **üéØ User-Friendly**: Intuitive web interface and standardized APIs for zero technical barriers
- **üîí Secure &amp; Controlled**: Support for local deployment and private cloud, ensuring complete data sovereignty

## üìä Application Scenarios

| Scenario | Applications | Core Value |
|---------|----------|----------|
| **Enterprise Knowledge Management** | Internal document retrieval, policy Q&amp;A, operation manual search | Improve knowledge discovery efficiency, reduce training costs |
| **Academic Research Analysis** | Paper retrieval, research report analysis, scholarly material organization | Accelerate literature review, assist research decisions |
| **Product Technical Support** | Product manual Q&amp;A, technical documentation search, troubleshooting | Enhance customer service quality, reduce support burden |
| **Legal &amp; Compliance Review** | Contract clause retrieval, regulatory policy search, case analysis | Improve compliance efficiency, reduce legal risks |
| **Medical Knowledge Assistance** | Medical literature retrieval, treatment guideline search, case analysis | Support clinical decisions, improve diagnosis quality |

## üß© Feature Matrix

| Module | Support                                                                        | Description                                                                                                                                                        |
|---------|--------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Agent Mode | ‚úÖ ReACT Agent Mode                                                             | Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations               |
| Knowledge Base Types | ‚úÖ FAQ / Document                                                               | Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry                                       |
| Document Formats | ‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)                    | Support for structured and unstructured documents with text extraction from images                                                                                 |
| Model Management | ‚úÖ Centralized configuration, built-in model sharing                            | Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models                                   |
| Embedding Models | ‚úÖ Local models, BGE / GTE APIs, etc.                                           | Customizable embedding models, compatible with local deployment and cloud vector generation APIs                                                                   |
| Vector DB Integration | ‚úÖ PostgreSQL (pgvector), Elasticsearch                                         | Support for mainstream vector index backends, flexible switching for different retrieval scenarios                                                                 |
| Retrieval Strategies | ‚úÖ BM25 / Dense Retrieval / GraphRAG                                            | Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines                                        |
| LLM Integration | ‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching  | Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration                                                     |
| Conversation Strategy | ‚úÖ Agent models, normal mode models, retrieval thresholds, Prompt configuration | Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior |
| Web Search | ‚úÖ Extensible search engines, DuckDuckGo / Google                               | Support for extensible web search engines with built-in DuckDuckGo search engine                                                                                   |
| MCP Tools | ‚úÖ uvx, npx launchers, Stdio/HTTP Streamable/SSE                                | Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods                                      |
| QA Capabilities | ‚úÖ Context-aware, multi-turn dialogue, prompt templates                         | Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;A with configurable prompts and context windows                                  |
| E2E Testing | ‚úÖ Retrieval+generation process visualization and metric evaluation             | End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics                                                            |
| Deployment Modes | ‚úÖ Support for local deployment / Docker images                                 | Meets private, offline deployment and flexible operation requirements, with fast development mode support                                                          |
| User Interfaces | ‚úÖ Web UI + RESTful API                                                         | Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display                                              |
| Task Management | ‚úÖ MQ async tasks, automatic database migration                                 | MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades                                            |

## üöÄ Getting Started

### üõ† Prerequisites

Make sure the following tools are installed on your system:

* [Docker](https://www.docker.com/)
* [Docker Compose](https://docs.docker.com/compose/)
* [Git](https://git-scm.com/)

### üì¶ Installation

#### ‚ë† Clone the repository

```bash
# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
```

#### ‚ë° Configure environment variables

```bash
# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
```

#### ‚ë¢ Start the services (include Ollama)

Check the images that need to be started in the .env file.

```bash
./scripts/start_all.sh
```

or

```bash
make start-all
```

#### ‚ë¢.0 Start ollama services (Optional)

```bash
ollama serve &gt; /dev/null 2&gt;&amp;1 &amp;
```

#### ‚ë¢.1 Activate different combinations of features

- Minimum core services
```bash
docker compose up -d
```

- All features enabled
```bash
docker-compose --profile full up -d
```

- Tracing logs required
```bash
docker-compose --profile jaeger up -d
```

- Neo4j knowledge graph required
```bash
docker-compose --profile neo4j up -d
```

- Minio file storage service required
```bash
docker-compose --profile minio up -d
```

- Multiple options combination
```bash
docker-compose --profile neo4j --profile minio up -d
```

#### ‚ë£ Stop the services

```bash
./scripts/start_all.sh --stop
# Or
make stop-all
```

### üåê Access Services

Once started, services will be available at:

* Web UI: `http://localhost`
* Backend API: `http://localhost:8080`
* Jaeger Tracing: `http://localhost:16686`

### üîå Using WeChat Dialog Open Platform

WeKnora serves as the core technology framework for the [WeChat Dialog Open Platform](https://chatbot.weixin.qq.com), providing a more convenient usage approach:

- **Zero-code Deployment**: Simply upload knowledge to quickly deploy intelligent Q&amp;A services within the WeChat ecosystem, achieving an &quot;ask and answer&quot; experience
- **Efficient Question Management**: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers
- **WeChat Ecosystem Integration**: Through the WeChat Dialog Open Platform, WeKnora&#039;s intelligent Q&amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences

### üîó Access WeKnora via MCP Server

#### 1Ô∏è‚É£ Clone the repository
```
git clone https://github.com/Tencent/WeKnora
```

#### 2Ô∏è‚É£ Configure MCP Server
&gt; It is recommended to directly refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for configuration.

Configure the MCP client to connect to the server:
```json
{
  &quot;mcpServers&quot;: {
    &quot;weknora&quot;: {
      &quot;args&quot;: [
        &quot;path/to/WeKnora/mcp-server/run_server.py&quot;
      ],
      &quot;command&quot;: &quot;python&quot;,
      &quot;env&quot;:{
        &quot;WEKNORA_API_KEY&quot;:&quot;Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk&quot;,
        &quot;WEKNORA_BASE_URL&quot;:&quot;http(s)://your-weknora-address/api/v1&quot;
      }
    }
  }
}
```

Run directly using stdio command:
```
pip install weknora-mcp-server
python -m weknora-mcp-server
```

## üîß Initialization Configuration Guide

To help users quickly configure various models and reduce trial-and-error costs, we&#039;ve improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows:
If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.

### ‚ë† Stop the services

```bash
./scripts/start_all.sh --stop
```

### ‚ë° Clear existing data tables (recommended when no important data exists)

```bash
make clean-db
```

### ‚ë¢ Compile and start services

```bash
./scripts/start_all.sh
```

### ‚ë£ Access Web UI

http://localhost

On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.

## üì± Interface Showcase

### Web UI Interface

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/knowledgebases.png&quot; alt=&quot;Knowledge Base Management&quot;&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/settings.png&quot; alt=&quot;Conversation Settings&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td colspan=&quot;2&quot;&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/agent-qa.png&quot; alt=&quot;Agent Mode Tool Call Process&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

**Knowledge Base Management:** Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.

**Agent Mode:** Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.

**Conversation Strategy:** Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.

### Document Knowledge Graph

WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.

For detailed configuration, please refer to the [Knowledge Graph Configuration Guide](./docs/KnowledgeGraph.md).

### MCP Server

Please refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for the necessary setup.

## üìò API Reference

Troubleshooting FAQ: [Troubleshooting FAQ](./docs/QA.md)

Detailed API documentation is available at: [API Docs](./docs/api/README.md)

## üß≠ Developer Guide

### ‚ö° Fast Development Mode (Recommended)

If you need to frequently modify code, **you don&#039;t need to rebuild Docker images every time**! Use fast development mode:

```bash
# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
```

**Development Advantages:**
- ‚úÖ Frontend modifications auto hot-reload (no restart needed)
- ‚úÖ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)
- ‚úÖ No need to rebuild Docker images
- ‚úÖ Support IDE breakpoint debugging

**Detailed Documentation:** [Development Environment Quick Start](./docs/ÂºÄÂèëÊåáÂçó.md)

### üìÅ Directory Structure

```
WeKnora/
‚îú‚îÄ‚îÄ client/      # go client
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ docker/      # docker images files
‚îú‚îÄ‚îÄ docreader/   # Document parsing app
‚îú‚îÄ‚îÄ docs/        # Project documentation
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ mcp-server/  # MCP server
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îî‚îÄ‚îÄ scripts/     # Shell scripts
```

## ü§ù Contributing

We welcome community contributions! For suggestions, bugs, or feature requests, please submit an [Issue](https://github.com/Tencent/WeKnora/issues) or directly create a Pull Request.

### üéØ How to Contribute

- üêõ **Bug Fixe

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cilium/cilium]]></title>
            <link>https://github.com/cilium/cilium</link>
            <guid>https://github.com/cilium/cilium</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:14 GMT</pubDate>
            <description><![CDATA[eBPF-based Networking, Security, and Observability]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cilium/cilium">cilium/cilium</a></h1>
            <p>eBPF-based Networking, Security, and Observability</p>
            <p>Language: Go</p>
            <p>Stars: 23,439</p>
            <p>Forks: 3,540</p>
            <p>Stars today: 128 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[memodb-io/Acontext]]></title>
            <link>https://github.com/memodb-io/Acontext</link>
            <guid>https://github.com/memodb-io/Acontext</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:13 GMT</pubDate>
            <description><![CDATA[Data platform for context engineering. Context data platform that stores, observes and learns. Join the community‚ù§Ô∏è: https://discord.acontext.io]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/memodb-io/Acontext">memodb-io/Acontext</a></h1>
            <p>Data platform for context engineering. Context data platform that stores, observes and learns. Join the community‚ù§Ô∏è: https://discord.acontext.io</p>
            <p>Language: Go</p>
            <p>Stars: 2,624</p>
            <p>Forks: 239</p>
            <p>Stars today: 190 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.acontext.io&quot;&gt;
      &lt;img alt=&quot;Show Acontext header banner&quot; src=&quot;./assets/Acontext-header-banner.png&quot;&gt;
  &lt;/a&gt;
  &lt;p&gt;
    &lt;h4&gt;Context Data Platform for Building Cloud-native AI Agents&lt;/h4&gt;
  &lt;/p&gt;
  &lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://pypi.org/project/acontext/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/acontext.svg&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.npmjs.com/package/@acontext/acontext&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@acontext/acontext.svg?logo=npm&amp;logoColor=fff&amp;style=flat&amp;labelColor=2C2C2C&amp;color=28CF8D&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/memodb-io/acontext/actions/workflows/core-test.yaml&quot;&gt;&lt;img src=&quot;https://github.com/memodb-io/acontext/actions/workflows/core-test.yaml/badge.svg&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/memodb-io/acontext/actions/workflows/api-test.yaml&quot;&gt;&lt;img src=&quot;https://github.com/memodb-io/acontext/actions/workflows/api-test.yaml/badge.svg&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/memodb-io/acontext/actions/workflows/cli-test.yaml&quot;&gt;&lt;img src=&quot;https://github.com/memodb-io/acontext/actions/workflows/cli-test.yaml/badge.svg&quot;&gt;&lt;/a&gt;
  &lt;/p&gt;
  &lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://x.com/acontext_io&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/acontext_io?style=social&quot; alt=&quot;Twitter Follow&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.acontext.io&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?label=Acontext&amp;style=flat&amp;query=approximate_member_count&amp;url=https%3A%2F%2Fdiscord.com%2Fapi%2Fv10%2Finvites%2FSG9xJcqVBu%3Fwith_counts%3Dtrue&amp;logo=discord&amp;logoColor=white&amp;suffix=+members&amp;color=36393f&amp;labelColor=5765F2&quot; alt=&quot;Acontext Discord&quot;&gt;&lt;/a&gt;
  &lt;/p&gt;
  &lt;div align=&quot;center&quot;&gt;
    &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
    &lt;a href=&quot;./readme/de/README.md&quot;&gt;Deutsch&lt;/a&gt; | 
    &lt;a href=&quot;./readme/es/README.md&quot;&gt;Espa√±ol&lt;/a&gt; | 
    &lt;a href=&quot;./readme/fr/README.md&quot;&gt;Fran√ßais&lt;/a&gt; | 
    &lt;a href=&quot;./readme/ja/README.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; | 
    &lt;a href=&quot;./readme/ko/README.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | 
    &lt;a href=&quot;./readme/pt/README.md&quot;&gt;Portugu√™s&lt;/a&gt; | 
    &lt;a href=&quot;./readme/ru/README.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | 
    &lt;a href=&quot;./readme/zh/README.md&quot;&gt;‰∏≠Êñá&lt;/a&gt;
  &lt;/div&gt;
  &lt;br/&gt;
&lt;/div&gt;


*Everyone is telling you how to use their agents. But what if YOU need to build an agent for 100,000 users, how would you start?*

**üì¶ Problem 1: 99% of your DB is just LLM messages.** 

&gt; Poor schema design makes your most valuable data expensive and slow. Acontext handles context storage and retrieval via PG, Redis, and S3. 
&gt;
&gt; ChatGPT, Gemini, Anthropic, images, audio, files... we&#039;ve got you covered.

**‚è∞ Problem 2: Long-running agents are a nightmare.** 

&gt; You know context engineering, but you&#039;re always writing it from scratch. Acontext comes with built-in context editing methods and a todo agent out of the box.
&gt;
&gt; Managing agent state? Piece of cake.

**üëÄ Problem 3: You can&#039;t see how your agent is doing.** 

&gt; How satisfied are your users, really? Acontext tracks tasks per session and shows you your agent&#039;s actual success rate. 
&gt;
&gt; Stop obsessing over token costs, improve the agent first.

**üß† Problem 4: Your agent is hit or miss.**

&gt; Can it learn from its wins? Acontext&#039;s experience agent remembers successful runs and turns them into reusable tool-use SOPs.
&gt;
&gt; Consistency is everything.



To solve those problems at once, Acontext becomes the **Context Data Platform**:

&lt;div align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;img alt=&quot;Acontext Learning&quot; src=&quot;./assets/acontext-components.jpg&quot; width=&quot;100%&quot;&gt;
    &lt;/picture&gt;
  &lt;p&gt;Context Data Platform that Store, Observe and Learn&lt;/p&gt;
&lt;/div&gt;


# üí° Core Features

- **Context Engineering**
  - [Session](https://docs.acontext.io/store/messages/multi-provider): unified message storage for any llm, any modal.
  - [Disk](https://docs.acontext.io/store/disk): save/download artifacts with file path.
  - [Context Editing](https://docs.acontext.io/store/editing) - manage your context window in one api.

&lt;div align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;img alt=&quot;Acontext Learning&quot; src=&quot;./assets/acontext-context-engineering.png&quot; width=&quot;80%&quot;&gt;
    &lt;/picture&gt;
  &lt;p&gt;Context Engineering in Acontext&lt;/p&gt;
&lt;/div&gt;

- **Observe agent tasks and user feedback**
  - [Task](https://docs.acontext.io/observe/agent_tasks): collect agent&#039;s working status, progress and preferences in near real-time.
- **Agent self-learning**
  - [Experience](https://docs.acontext.io/learn/advance/experience-agent): let agent learn SOPs for each user.
- **View everything in one [dashboard](https://docs.acontext.io/observe/dashboard)**

&lt;div align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;img alt=&quot;Dashboard&quot; src=&quot;./docs/images/dashboard/BI.png&quot; width=&quot;80%&quot;&gt;
    &lt;/picture&gt;
  &lt;p&gt;Dashboard of Agent Success Rate and Other Metrics&lt;/p&gt;
&lt;/div&gt;



# üèóÔ∏è How it works?

&lt;details&gt;
&lt;summary&gt;click to open&lt;/summary&gt;

```mermaid
graph TB
    subgraph &quot;Client Layer&quot;
        PY[&quot;pip install acontext&quot;]
        TS[&quot;npm i @acontext/acontext&quot;]
    end
    
    subgraph &quot;Acontext Backend&quot;
      subgraph &quot; &quot;
          API[&quot;API&lt;br/&gt;localhost:8029&quot;]
          CORE[&quot;Core&quot;]
          API --&gt;|FastAPI &amp; MQ| CORE
      end
      
      subgraph &quot; &quot;
          Infrastructure[&quot;Infrastructures&quot;]
          PG[&quot;PostgreSQL&quot;]
          S3[&quot;S3&quot;]
          REDIS[&quot;Redis&quot;]
          MQ[&quot;RabbitMQ&quot;]
      end
    end
    
    subgraph &quot;Dashboard&quot;
        UI[&quot;Web Dashboard&lt;br/&gt;localhost:3000&quot;]
    end
    
    PY --&gt;|RESTFUL API| API
    TS --&gt;|RESTFUL API| API
    UI --&gt;|RESTFUL API| API
    API --&gt; Infrastructure
    CORE --&gt; Infrastructure

    Infrastructure --&gt; PG
    Infrastructure --&gt; S3
    Infrastructure --&gt; REDIS
    Infrastructure --&gt; MQ
    
    
    style PY fill:#3776ab,stroke:#fff,stroke-width:2px,color:#fff
    style TS fill:#3178c6,stroke:#fff,stroke-width:2px,color:#fff
    style API fill:#00add8,stroke:#fff,stroke-width:2px,color:#fff
    style CORE fill:#ffd43b,stroke:#333,stroke-width:2px,color:#333
    style UI fill:#000,stroke:#fff,stroke-width:2px,color:#fff
    style PG fill:#336791,stroke:#fff,stroke-width:2px,color:#fff
    style S3 fill:#ff9900,stroke:#fff,stroke-width:2px,color:#fff
    style REDIS fill:#dc382d,stroke:#fff,stroke-width:2px,color:#fff
    style MQ fill:#ff6600,stroke:#fff,stroke-width:2px,color:#fff
```

## How They Work Together

```txt
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ User ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ Your Agent ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   Session    ‚îÇ    ‚îÇ Artifact Disk ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ                  ‚îÇ # if enable
                  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ         ‚îÇ Observed Tasks  ‚îÇ
                  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ                  ‚îÇ # if enable
                  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ         ‚îÇ   Learn Skills  ‚îÇ
                  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      Search skills
```



## Data Structures

&lt;details&gt;
&lt;summary&gt;üìñ Task Structure&lt;/summary&gt;

```json
{
  &quot;task_description&quot;: &quot;Star https://github.com/memodb-io/Acontext&quot;,
  &quot;progresses&quot;: [
    &quot;I have navigated to Acontext repo&quot;,
    &quot;Tried to Star but a pop-up required me to login&quot;,
    ...
  ],
  &quot;user_preferences&quot;: [
    &quot;user wants to use outlook email to login&quot;
  ]
}
```
&lt;/details&gt;



&lt;details&gt;
&lt;summary&gt;üìñ Skill Structure&lt;/summary&gt;


```json
{
    &quot;use_when&quot;: &quot;star a repo on github.com&quot;,
    &quot;preferences&quot;: &quot;use user&#039;s outlook account&quot;,
    &quot;tool_sops&quot;: [
        {&quot;tool_name&quot;: &quot;goto&quot;, &quot;action&quot;: &quot;goto github.com&quot;},
        {&quot;tool_name&quot;: &quot;click&quot;, &quot;action&quot;: &quot;find login button if any. login first&quot;},
        ...
    ]
}
```

&lt;/details&gt;



&lt;details&gt;
&lt;summary&gt;üìñ Space Structure&lt;/summary&gt;

```txt
/
‚îî‚îÄ‚îÄ github/ (folder)
    ‚îî‚îÄ‚îÄ GTM (page)
        ‚îú‚îÄ‚îÄ find_trending_repos (sop)
        ‚îî‚îÄ‚îÄ find_contributor_emails (sop)
    ‚îî‚îÄ‚îÄ basic_ops (page)
        ‚îú‚îÄ‚îÄ create_repo (sop)
        ‚îî‚îÄ‚îÄ delete_repo (sop)
    ...
```
&lt;/details&gt;

&lt;/details&gt;





# üöÄ Connect to Acontext

1. Go to [Acontext.io](https://acontext.io), claim your free credits.
2. Go through a one-click onboarding to get your API Key: `sk-ac-xxx`

&lt;div align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;img alt=&quot;Dashboard&quot; src=&quot;./assets/onboard.png&quot; width=&quot;80%&quot;&gt;
    &lt;/picture&gt;
&lt;/div&gt;




&lt;details&gt;
&lt;summary&gt;üíª Self-host Acontext&lt;/summary&gt;

We have an `acontext-cli` to help you do quick proof-of-concept. Download it first in your terminal:

```bash
curl -fsSL https://install.acontext.io | sh
```

You should have [docker](https://www.docker.com/get-started/) installed and an OpenAI API Key to start an Acontext backend on your computer:

```bash
mkdir acontext_server &amp;&amp; cd acontext_server
acontext docker up
```

&gt; [!IMPORTANT]
&gt;
&gt; Make sure your LLM has the ability to [call tools](https://platform.openai.com/docs/guides/function-calling). By default, Acontext will use `gpt-4.1`.

`acontext docker up` will create/use  `.env` and `config.yaml` for Acontext, and create a `db` folder to persist data.



Once it&#039;s done, you can access the following endpoints:

- Acontext API Base URL: http://localhost:8029/api/v1
- Acontext Dashboard: http://localhost:3000/

&lt;/details&gt;






# üßê Use Acontext to build Agent

Download end-to-end scripts with `acontext`:

**Python**

```bash
acontext create my-proj --template-path &quot;python/openai-basic&quot;
```

&gt; More examples on Python:
&gt;
&gt; - `python/openai-agent-basic`: self-learning agent in openai agent sdk.
&gt; - `python/agno-basic`: self-learning agent in agno framework.
&gt; - `python/openai-agent-artifacts`: agent that can edit and download artifacts.

**Typescript**

```bash
acontext create my-proj --template-path &quot;typescript/openai-basic&quot;
```

&gt; More examples on Typescript:
&gt;
&gt; - `typescript/vercel-ai-basic`: self-learning agent in @vercel/ai-sdk



&gt; [!NOTE]
&gt;
&gt; Check our example repo for more templates: [Acontext-Examples](https://github.com/memodb-io/Acontext-Examples).
&gt;
&gt; We&#039;re cooking more full-stack Agent Applications! [Tell us what you want!](https://discord.acontext.io)



## Step-by-step Quickstart

&lt;details&gt;
&lt;summary&gt;click to open&lt;/summary&gt;


We&#039;re maintaining Python [![pypi](https://img.shields.io/pypi/v/acontext.svg)](https://pypi.org/project/acontext/) and Typescript [![npm](https://img.shields.io/npm/v/@acontext/acontext.svg?logo=npm&amp;logoColor=fff&amp;style=flat&amp;labelColor=2C2C2C&amp;color=28CF8D)](https://www.npmjs.com/package/@acontext/acontext) SDKs. The snippets below are using Python.

## Install SDKs

```
pip install acontext # for Python
npm i @acontext/acontext # for Typescript
```



## Initialize Client

```python
import os
from acontext import AcontextClient

client = AcontextClient(
    api_key=os.getenv(&quot;ACONTEXT_API_KEY&quot;),
)

# If you&#039;re using self-hosted Acontext:
# client = AcontextClient(
#     base_url=&quot;http://localhost:8029/api/v1&quot;,
#     api_key=&quot;sk-ac-your-root-api-bearer-token&quot;,
# )
```

&gt; [üìñ async client doc](https://docs.acontext.io/settings/core)



## Store

Acontext can manage agent sessions and artifacts.

### Save Messages [üìñ](https://docs.acontext.io/api-reference/session/store-message-to-session)

Acontext offers persistent storage for message data. When you call `session.store_message`, Acontext will persist the message and start to monitor this session:

&lt;details&gt;
&lt;summary&gt;Code Snippet&lt;/summary&gt;

```python
session = client.sessions.create()

messages = [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;I need to write a landing page of iPhone 15 pro max&quot;},
    {
        &quot;role&quot;: &quot;assistant&quot;,
        &quot;content&quot;: &quot;Sure, my plan is below:\n1. Search for the latest news about iPhone 15 pro max\n2. Init Next.js project for the landing page\n3. Deploy the landing page to the website&quot;,
    }
]

# Save messages
for msg in messages:
    client.sessions.store_message(session_id=session.id, blob=msg, format=&quot;openai&quot;)
```

&gt; [üìñ](https://docs.acontext.io/store/messages/multi-modal) We also support multi-modal message storage and anthropic SDK.


&lt;/details&gt;

### Load Messages [üìñ](https://docs.acontext.io/api-reference/session/get-messages-from-session)

Obtain your session messages using `sessions.get_messages`

&lt;details&gt;
&lt;summary&gt;Code Snippet&lt;/summary&gt;

```python
r = client.sessions.get_messages(session.id)
new_msg = r.items

new_msg.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;How are you doing?&quot;})
r = openai_client.chat.completions.create(model=&quot;gpt-4.1&quot;, messages=new_msg)
print(r.choices[0].message.content)
client.sessions.store_message(session_id=session.id, blob=r.choices[0].message)
```

&lt;/details&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;img alt=&quot;Session&quot; src=&quot;./docs/images/dashboard/message_viewer.png&quot; width=&quot;100%&quot;&gt;
    &lt;/picture&gt;
  &lt;p&gt;You can view sessions in your local Dashboard&lt;/p&gt;
&lt;/div&gt;


### Artifacts [üìñ](https://docs.acontext.io/store/disk)

Create a disk for your agent to store and read artifacts using file paths:

&lt;details&gt;
&lt;summary&gt;Code Snippet&lt;/summary&gt;

```python
from acontext import FileUpload

disk = client.disks.create()

file = FileUpload(
    filename=&quot;todo.md&quot;,
    content=b&quot;# Sprint Plan\n\n## Goals\n- Complete user authentication\n- Fix critical bugs&quot;
)
artifact = client.disks.artifacts.upsert(
    disk.id,
    file=file,
    file_path=&quot;/todo/&quot;
)


print(client.disks.artifacts.list(
    disk.id,
    path=&quot;/todo/&quot;
))

result = client.disks.artifacts.get(
    disk.id,
    file_path=&quot;/todo/&quot;,
    filename=&quot;todo.md&quot;,
    with_public_url=True,
    with_content=True
)
print(f&quot;‚úì File content: {result.content.raw}&quot;)
print(f&quot;‚úì Download URL: {result.public_url}&quot;)        
```
&lt;/details&gt;



&lt;div align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;img alt=&quot;Artifacts&quot; src=&quot;./docs/images/dashboard/artifact_viewer.png&quot; width=&quot;100%&quot;&gt;
    &lt;/picture&gt;
  &lt;p&gt;You can view artifacts in your local Dashboard&lt;/p&gt;
&lt;/div&gt;



## Observe [üìñ](https://docs.acontext.io/observe)

For every session, Acontext will **automatically** launch a background agent to track the task progress and user feedback. **It&#039;s like a background TODO agent**. Acontext will use it to observe your daily agent success rate.

You can use the SDK to retrieve the current state of the agent session, for Context Engineering like Reduction and Compression. 

&lt;details&gt;
&lt;summary&gt;Full Script&lt;/summary&gt;

```python
from acontext import AcontextClient

# Initialize client
client = AcontextClient(
    base_url=&quot;http://localhost:8029/api/v1&quot;, api_key=&quot;sk-ac-your-root-api-bearer-token&quot;
)

# Create a project and session
session = client.sessions.create()

# Conversation messages
messages = [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;I need to write a landing page of iPhone 15 pro max&quot;},
    {
        &quot;role&quot;: &quot;assistant&quot;,
        &quot;content&quot;: &quot;Sure, my plan is below:\n1. Search for the latest news about iPhone 15 pro max\n2. Init Next.js project for the landing page\n3. Deploy the landing page to the website&quot;,
    },
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;That sounds good. Let&#039;s first collect the message and report to me before any landing page coding.&quot;,
    },
    {
        &quot;role&quot;: &quot;assistant&quot;,
        &quot;content&quot;: &quot;Sure, I will first collect the message then report to you before any landing page coding.&quot;,
      	&quot;tool_calls&quot;: [
            {
                &quot;id&quot;: &quot;call_001&quot;,
                &quot;type&quot;: &quot;function&quot;,
                &quot;function&quot;: {
                    &quot;name&quot;: &quot;search_news&quot;,
                    &quot;arguments&quot;: &quot;{\&quot;query\&quot;: \&quot;iPhone news\&quot;}&quot;
                }
            }
        ]
    },
]

# Store messages in a loop
for msg in messages:
    client.sessions.store_message(session_id=session.id, blob=msg, format=&quot;openai&quot;)

# Wait for task extraction to complete
client.sessions.flush(session.id)

# Display extracted tasks
tasks_response = client.sessions.get_tasks(session.id)
print(tasks_response)
for task in tasks_response.items:
    print(f&quot;\nTask #{task.order}:&quot;)
    print(f&quot;  ID: {task.id}&quot;)
    print(f&quot;  Title: {task.data.task_description}&quot;)
    print(f&quot;  Status: {task.status}&quot;)

    # Show progress updates if available
    if task.data.progresses:
        print(f&quot;  Progress updates: {len(task.data.progresses)}&quot;)
        for progress in task.data.progresses:
            print(f&quot;    - {progress}&quot;)

    # Show user preferences if available
    if task.data.user_preferences:
        print(&quot;  User preferences:&quot;)
        for pref in task.data.user_preferences:
            print(f&quot;    - {pref}&quot;)

```
&gt; `flush` is a blocking call, it will wait for the task extraction to complete.
&gt; You don&#039;t need to call it in production, Acontext has a [buffer mechanism](https://docs.acontext.io/observe/buffer) to ensure the task extraction is completed right on time.

&lt;/details&gt;

Example Task Return:

```txt
Task #1:
  Title: Search for the latest news about iPhone 15 Pro Max and report findings to the user before any landing page coding.
  Status: success
  Progress updates: 2
    - I confirmed that the first step will be reporting before moving on to landing page development.
    - I have already collected all the iPhone 15 pro max info and reported to the user, waiting for approval for next step.
  User preferences:
    - user expects a report on latest news about iPhone 15 pro max before any coding work on the landing page.

Task #2:
  Title: Initialize a Next.js project for the iPhone 15 Pro Max landing page.
  Status: pending

Task #3:
  Title: Deploy the completed landing page to the website.
  Status: pending
```



You can view the session tasks&#039; statuses in the Dashboard:

&lt;div align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;img alt=&quot;Acontext Learning&quot; src=&quot;./docs/images/dashboard/session_task_viewer.png&quot; width=&quot;100%&quot;&gt;
    &lt;/picture&gt;
  &lt;p&gt;A Task Demo&lt;/p&gt;
&lt;/div&gt;



## Self-learning

Acontext can gather a bunch of sessions and learn skills (SOPs) on how to call tools for certain tasks.

### Learn Skills to a `Space` [üìñ](https://docs.acontext.io/learn/skill-space)

&lt;div align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;img alt=&quot;A Space Demo&quot; src=&quot;./assets/acontext_dataflow.png&quot; width=&quot;100%&quot;&gt;
    &lt;/picture&gt;
  &lt;p&gt;How self-learning works?&lt;/p&gt;
&lt;/div&gt;

A `Space` can store skills, and memories in a Notion-like system. You first need to connect a session to `Space` to enable the learning process:

```python
# Step 1: Create a Space for skill learning
space = client.spaces.create()
print(f&quot;Created Space: {space.id}&quot;)

# Step 2: Create a session attached to the space
session = client.sessions.create(space_id=space.id)

# ... push the agent working context
```

The learning happens in the background and is not real-time (delay around 10-30s). 

What Acontext will do in the background:

```mermaid
graph LR
    A[Task Completed] --&gt; B[Task Extraction]
    B --&gt; C{Space Connected?}
    C --&gt;|Yes| D[Queue for Learning]
    C --&gt;|No| E[Skip Learning]
    D --&gt; F[Extract SOP]
    F --&gt; G{Hard Enough?}
    G --&gt;|No - Too Simple| H[Skip Learning]
    G --&gt;|Yes - Complex| I[Store as Skill Block]
    I --&gt; J[Available for Future Sessions]
```

Eventually, SOP blocks with tool-call pattern will be saved to `Space`. You can view every `Space` in the Dashboard:

&lt;div align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;img alt=&quot;A Space Demo&quot; src=&quot;./docs/images/dashboard/skill_viewer.png&quot; width=&quot;100%&quot;&gt;
    &lt;/picture&gt;
  &lt;p&gt;A Space Demo&lt;/p&gt;
&lt;/div&gt;




### Search Skills from a `Space` [üìñ](https://docs.acontext.io/learn/search-skills)

To search skills from a `Space` and use them in the next session:

```python
result = client.spaces.experience_search(
    space_id=space.id,
    query=&quot;I need to implement authentication&quot;,
  	mode=&quot;fast&quot;
)
```

Acontext supports `fast` and `agentic` modes for search. The former uses embeddings to match skills. The latter uses an Experience Agent to explore the entire `Space` and tries to cover every skill needed.

The return is a list of sop blocks, which look like below:

```json
{
    &quot;use_when&quot;: &quot;star a github repo&quot;,
    &quot;preferences&quot;: &quot;use personal account. star but not fork&quot;,
    &quot;tool_sops&quot;: [
        {&quot;tool_name&quot;: &quot;goto&quot;, &quot;action&quot;: &quot;goto the user given github repo url&quot;},
        {&quot;tool_name&quot;: &quot;click&quot;, &quot;action&quot;: &quot;find login button if any, and start to login first&quot;},
        ...
  

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[dagger/dagger]]></title>
            <link>https://github.com/dagger/dagger</link>
            <guid>https://github.com/dagger/dagger</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:12 GMT</pubDate>
            <description><![CDATA[Automation engine to build, test and ship any codebase. Runs locally, in CI, or directly in the cloud]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dagger/dagger">dagger/dagger</a></h1>
            <p>Automation engine to build, test and ship any codebase. Runs locally, in CI, or directly in the cloud</p>
            <p>Language: Go</p>
            <p>Stars: 15,281</p>
            <p>Forks: 844</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>## Dagger: a better way to ship

Dagger is a platform for automating software delivery. It can build, test and ship any codebase, reliably and at scale.

Dagger runs locally, in your CI server, or directly in the cloud. 

```
brew install dagger/tap/dagger
```

## Why Dagger?

Dagger makes your software delivery *programmable*, *local-first*, *repeatable* and *observable*.

**Programmable**. Shell scripts and proprietary YAML are no longer acceptable for automating software delivery. Dagger provides: a complete execution engine and system API; SDKs for 8 languages; an interactive REPL; a rich ecosystem of reusable modules; and more.

**Local-first**. Once you automate a task with Dagger, it will reliably run on any supported system: your laptop, AI sandbox, CI server, or dedicated cloud infrastructure. The only dependency is a container runtime like Docker.

**Repeatable**. Tools run in containers, orchestrated by sandboxed functions. Host dependencies are explicit and strictly typed. Intermediate artifacts are built just-in-time. Every operation is incremental by default, with advanced cache control. Whether it&#039;s a test report, a build or a deployment, Dagger gives you an output you can trust.

**Observable**. Every operation emits a full OpenTelemetry trace, enriched by granular logs and metrics. Visualize the trace in directly in the terminal, or in a web view. Debug complex workflows immediately instead of guessing what went wrong from a wall of text logs.

## Features

**System API**. A cross-language API for orchestrating containers, filesystems, secrets, git repositories, network tunnels, and more. Every operation is typed and composable.

**SDKs in 8 languages**. Native SDKs for Go, Python, TypeScript, PHP, Java, .NET, Elixir and Rust. Each SDK is generated from the API schema, so you get idiomatic code with full type safety and editor support.

**Typed artifacts**. Define custom object types with encapsulated state and functions. Types are content-addressed and can be passed across SDK language boundaries and module boundaries without serialization.

**Incremental execution**. Every operation is keyed by its inputs. Change one file and only the affected operations re-run. Caching is content-addressed and works automatically across local runs and CI.

**Runs anywhere**. The only requirement is a Linux container runtime. Runs natively on Linux, or via Docker Desktop and similar products on macOS and Windows. Local and CI behavior are identical.

**Built-in tracing**. Every operation emits OpenTelemetry spans. The CLI includes a live TUI; traces can also be exported to Jaeger, Honeycomb, or any OTel-compatible backend.


## Getting started

- [Documentation](https://docs.dagger.io)
- [Quickstart](https://docs.dagger.io/quickstart)

## Community

- [Discord](https://discord.gg/dagger-io)
- [GitHub Discussions](https://github.com/dagger/dagger/discussions)

## Contributing

See [CONTRIBUTING.md](https://github.com/dagger/dagger/blob/main/CONTRIBUTING.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[wavetermdev/waveterm]]></title>
            <link>https://github.com/wavetermdev/waveterm</link>
            <guid>https://github.com/wavetermdev/waveterm</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:11 GMT</pubDate>
            <description><![CDATA[An open-source, cross-platform terminal for seamless workflows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wavetermdev/waveterm">wavetermdev/waveterm</a></h1>
            <p>An open-source, cross-platform terminal for seamless workflows</p>
            <p>Language: Go</p>
            <p>Stars: 16,573</p>
            <p>Forks: 716</p>
            <p>Stars today: 220 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.waveterm.dev&quot;&gt;
	&lt;picture&gt;
		&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./assets/wave-dark.png&quot;&gt;
		&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./assets/wave-light.png&quot;&gt;
		&lt;img alt=&quot;Wave Terminal Logo&quot; src=&quot;./assets/wave-light.png&quot; width=&quot;240&quot;&gt;
	&lt;/picture&gt;
  &lt;/a&gt;
  &lt;br/&gt;
&lt;/p&gt;

# Wave Terminal

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm?ref=badge_shield)

Wave is an open-source terminal that combines traditional terminal features with graphical capabilities like file previews, web browsing, and AI assistance. It runs on MacOS, Linux, and Windows.

Modern development involves constantly switching between terminals and browsers - checking documentation, previewing files, monitoring systems, and using AI tools. Wave brings these graphical tools directly into the terminal, letting you control them from the command line. This means you can stay in your terminal workflow while still having access to the visual interfaces you need.

![WaveTerm Screenshot](./assets/wave-screenshot.webp)

## Key Features

- Flexible drag &amp; drop interface to organize terminal blocks, editors, web browsers, and AI assistants
- Built-in editor for seamlessly editing remote files with syntax highlighting and modern editor features
- Rich file preview system for remote files (markdown, images, video, PDFs, CSVs, directories)
- Quick full-screen toggle for any block - expand terminals, editors, and previews for better visibility, then instantly return to multi-block view
- Wave AI - Context-aware terminal assistant that reads your terminal output, analyzes widgets, and performs file operations
- AI chat widget with support for multiple models (OpenAI, Claude, Azure, Perplexity, Ollama)
- Command Blocks for isolating and monitoring individual commands with auto-close options
- One-click remote connections with full terminal and file system access
- Secure secret storage using native system backends - store API keys and credentials locally, access them across SSH sessions
- Rich customization including tab themes, terminal styles, and background images
- Powerful `wsh` command system for managing your workspace from the CLI and sharing data between terminal sessions
- Connected file management with `wsh file` - seamlessly copy and sync files between local, remote SSH hosts, Wave filesystem, and S3

## Wave AI

Wave AI is your context-aware terminal assistant with access to your workspace:

- **Terminal Context**: Reads terminal output and scrollback for debugging and analysis
- **File Operations**: Read, write, and edit files with automatic backups and user approval
- **CLI Integration**: Use `wsh ai` to pipe output or attach files directly from the command line
- **Free Beta**: Included AI credits while we refine the experience
- **Coming Soon**: Command execution (with approval), local model support, and alternate AI providers (BYOK)

Learn more in our [Wave AI documentation](https://docs.waveterm.dev/waveai).

## Installation

Wave Terminal works on macOS, Linux, and Windows.

Platform-specific installation instructions can be found [here](https://docs.waveterm.dev/gettingstarted).

You can also install Wave Terminal directly from: [www.waveterm.dev/download](https://www.waveterm.dev/download).

### Minimum requirements

Wave Terminal runs on the following platforms:

- macOS 11 or later (arm64, x64)
- Windows 10 1809 or later (x64)
- Linux based on glibc-2.28 or later (Debian 10, RHEL 8, Ubuntu 20.04, etc.) (arm64, x64)

The WSH helper runs on the following platforms:

- macOS 11 or later (arm64, x64)
- Windows 10 or later (arm64, x64)
- Linux Kernel 2.6.32 or later (x64), Linux Kernel 3.1 or later (arm64)

## Roadmap

Wave is constantly improving! Our roadmap will be continuously updated with our goals for each release. You can find it [here](./ROADMAP.md).

Want to provide input to our future releases? Connect with us on [Discord](https://discord.gg/XfvZ334gwU) or open a [Feature Request](https://github.com/wavetermdev/waveterm/issues/new/choose)!

## Links

- Homepage &amp;mdash; https://www.waveterm.dev
- Download Page &amp;mdash; https://www.waveterm.dev/download
- Documentation &amp;mdash; https://docs.waveterm.dev
- Legacy Documentation &amp;mdash; https://legacydocs.waveterm.dev
- Blog &amp;mdash; https://blog.waveterm.dev
- X &amp;mdash; https://x.com/wavetermdev
- Discord Community &amp;mdash; https://discord.gg/XfvZ334gwU

## Building from Source

See [Building Wave Terminal](BUILD.md).

## Contributing

Wave uses GitHub Issues for issue tracking.

Find more information in our [Contributions Guide](CONTRIBUTING.md), which includes:

- [Ways to contribute](CONTRIBUTING.md#contributing-to-wave-terminal)
- [Contribution guidelines](CONTRIBUTING.md#before-you-start)

## License

Wave Terminal is licensed under the Apache-2.0 License. For more information on our dependencies, see [here](./ACKNOWLEDGEMENTS.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[istio/istio]]></title>
            <link>https://github.com/istio/istio</link>
            <guid>https://github.com/istio/istio</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:10 GMT</pubDate>
            <description><![CDATA[Connect, secure, control, and observe services.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/istio/istio">istio/istio</a></h1>
            <p>Connect, secure, control, and observe services.</p>
            <p>Language: Go</p>
            <p>Stars: 37,831</p>
            <p>Forks: 8,215</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># Istio

[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1395/badge)](https://bestpractices.coreinfrastructure.org/projects/1395)
[![Go Report Card](https://goreportcard.com/badge/github.com/istio/istio)](https://goreportcard.com/report/github.com/istio/istio)
[![GoDoc](https://godoc.org/istio.io/istio?status.svg)](https://godoc.org/istio.io/istio)

&lt;a href=&quot;https://istio.io/&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/projects/istio/icon/color/istio-icon-color.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/istio/istio/raw/master/logo/istio-bluelogo-whitebackground-unframed.svg&quot;&gt;
      &lt;img title=&quot;Istio&quot; height=&quot;100&quot; width=&quot;100&quot; alt=&quot;Istio logo&quot; src=&quot;https://github.com/istio/istio/raw/master/logo/istio-bluelogo-whitebackground-unframed.svg&quot;&gt;
    &lt;/picture&gt;
&lt;/a&gt;

---

Istio is an open source service mesh that layers transparently onto existing distributed applications. Istio‚Äôs powerful features provide a uniform and more efficient way to secure, connect, and monitor services. Istio is the path to load balancing, service-to-service authentication, and monitoring ‚Äì with few or no service code changes.

- For in-depth information about how to use Istio, visit [istio.io](https://istio.io)
- To ask questions and get assistance from our community, visit [GitHub Discussions](https://github.com/istio/istio/discussions)
- To learn how to participate in our overall community, visit [our community page](https://istio.io/about/community)

In this README:

- [Introduction](#introduction)
- [Repositories](#repositories)
- [Issue management](#issue-management)

In addition, here are some other documents you may wish to read:

- [Istio Community](https://github.com/istio/community#istio-community) - describes how to get involved and contribute to the Istio project
- [Istio Developer&#039;s Guide](https://github.com/istio/istio/wiki/Preparing-for-Development) - explains how to set up and use an Istio development environment
- [Project Conventions](https://github.com/istio/istio/wiki/Development-Conventions) - describes the conventions we use within the code base
- [Creating Fast and Lean Code](https://github.com/istio/istio/wiki/Writing-Fast-and-Lean-Code) - performance-oriented advice and guidelines for the code base

You&#039;ll find many other useful documents on our [Wiki](https://github.com/istio/istio/wiki).

## Introduction

[Istio](https://istio.io/latest/docs/concepts/what-is-istio/) is an open platform for providing a uniform way to [integrate
microservices](https://istio.io/latest/docs/examples/microservices-istio/), manage [traffic flow](https://istio.io/latest/docs/concepts/traffic-management/) across microservices, enforce policies
and aggregate telemetry data. Istio&#039;s control plane provides an abstraction
layer over the underlying cluster management platform, such as Kubernetes.

Istio is composed of these components:

- **Envoy** - Sidecar proxies per microservice to handle ingress/egress traffic
   between services in the cluster and from a service to external
   services. The proxies form a _secure microservice mesh_ providing a rich
   set of functions like discovery, rich layer-7 routing, circuit breakers,
   policy enforcement and telemetry recording/reporting
   functions.

  &gt; Note: The service mesh is not an overlay network. It
  &gt; simplifies and enhances how microservices in an application talk to each
  &gt; other over the network provided by the underlying platform.

* **Ztunnel** - A lightweight data plane proxy written in Rust,
    used in Ambient mesh mode to provide secure connectivity and observability for workloads without sidecar proxies.

- **Istiod** - The Istio control plane. It provides service discovery, configuration and certificate management.

## Repositories

The Istio project is divided across a few GitHub repositories:

- [istio/api](https://github.com/istio/api). This repository defines
component-level APIs and common configuration formats for the Istio platform.

- [istio/community](https://github.com/istio/community). This repository contains
information on the Istio community, including the various documents that govern
the Istio open source project.

- [istio/istio](README.md). This is the main code repository. It hosts Istio&#039;s
core components, install artifacts, and sample programs. It includes:

    - [istioctl](istioctl/). This directory contains code for the
[_istioctl_](https://istio.io/latest/docs/reference/commands/istioctl/) command line utility.

    - [pilot](pilot/). This directory
contains platform-specific code to populate the
[abstract service model](https://istio.io/docs/concepts/traffic-management/#pilot), dynamically reconfigure the proxies
when the application topology changes, as well as translate
[routing rules](https://istio.io/latest/docs/reference/config/networking/) into proxy specific configuration.

    - [security](security/). This directory contains [security](https://istio.io/latest/docs/concepts/security/) related code.

- [istio/proxy](https://github.com/istio/proxy). The Istio proxy contains
extensions to the [Envoy proxy](https://github.com/envoyproxy/envoy) (in the form of
Envoy filters) that support authentication, authorization, and telemetry collection.

- [istio/ztunnel](https://github.com/istio/ztunnel). The repository contains the Rust implementation of the ztunnel
component of Ambient mesh.

- [istio/client-go](https://github.com/istio/client-go). This repository defines
  auto-generated Kubernetes clients for interacting with Istio resources programmatically.

&gt; [!NOTE]
&gt; Only the `istio/api` and `istio/client-go` repositories expose stable interfaces intended for direct usage as libraries.

## Issue management

We use GitHub to track all of our bugs and feature requests. Each issue we track has a variety of metadata:

- **Epic**. An epic represents a feature area for Istio as a whole. Epics are fairly broad in scope and are basically product-level things.
Each issue is ultimately part of an epic.

- **Milestone**. Each issue is assigned a milestone. This is 0.1, 0.2, ..., or &#039;Nebulous Future&#039;. The milestone indicates when we
think the issue should get addressed.

- **Priority**. Each issue has a priority which is represented by the column in the [Prioritization](https://github.com/orgs/istio/projects/6) project. Priority can be one of
P0, P1, P2, or &gt;P2. The priority indicates how important it is to address the issue within the milestone. P0 says that the
milestone cannot be considered achieved if the issue isn&#039;t resolved.

---

&lt;div align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color-whitetext/cncf-color-whitetext.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/color/cncf-color.svg&quot;&gt;
      &lt;img width=&quot;300&quot; alt=&quot;Cloud Native Computing Foundation logo&quot; src=&quot;https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color-whitetext/cncf-color-whitetext.svg&quot;&gt;
    &lt;/picture&gt;
    &lt;p&gt;Istio is a &lt;a href=&quot;https://cncf.io&quot;&gt;Cloud Native Computing Foundation&lt;/a&gt; project.&lt;/p&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[rancher/rancher]]></title>
            <link>https://github.com/rancher/rancher</link>
            <guid>https://github.com/rancher/rancher</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:09 GMT</pubDate>
            <description><![CDATA[Complete container management platform]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rancher/rancher">rancher/rancher</a></h1>
            <p>Complete container management platform</p>
            <p>Language: Go</p>
            <p>Stars: 25,250</p>
            <p>Forks: 3,149</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># Rancher

[![Docker Pulls](https://img.shields.io/docker/pulls/rancher/rancher.svg)](https://store.docker.com/community/images/rancher/rancher)
[![Go Report Card](https://goreportcard.com/badge/github.com/rancher/rancher)](https://goreportcard.com/report/github.com/rancher/rancher)

Rancher is an open source container management platform built for organizations that deploy containers in production. Rancher makes it easy to run Kubernetes everywhere, meet IT requirements, and empower DevOps teams.

## Stable Release

&lt;!-- stable v2.13.1 DO NOT REMOVE THIS LINE --&gt;
* v2.13.1 - `rancher/rancher:v2.13.1` / `rancher/rancher:stable` - Read the full release [notes](https://github.com/rancher/rancher/releases/tag/v2.13.1).
  
To get automated notifications of our latest release, you can watch the announcements category in our [forums](http://forums.rancher.com/c/announcements), or subscribe to the RSS feed `https://forums.rancher.com/c/announcements.rss`.

## Quick Start

    sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher

Open your browser to https://localhost

## Installation

See [Installing/Upgrading Rancher](https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-and-upgrade) for all installation options.

### Minimum Requirements

* Operating Systems
  * Please see [Support Matrix](https://rancher.com/support-matrix/) for specific OS versions for each Rancher version. Note that the link will default to the support matrix for the latest version of Rancher. Use the left navigation menu to select a different Rancher version. 
* Hardware &amp; Software
  * Please see [Installation Requirements](https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-requirements) for hardware and software requirements.

### Using Rancher

To learn more about using Rancher, please refer to our [Rancher Documentation](https://ranchermanager.docs.rancher.com/v2.8).

## Source Code

This repo is a meta-repo used for packaging and contains the majority of Rancher codebase. For other Rancher projects and modules, [see go.mod](https://github.com/rancher/rancher/blob/release/v2.8/go.mod) for the full list.

Rancher also includes other open source libraries and projects, [see go.mod](https://github.com/rancher/rancher/blob/release/v2.8/go.mod) for the full list.

## Build configuration

Refer to the [build docs](docs/build.md) on how to customize the building and packaging of Rancher.

## Support, Discussion, and Community
If you need any help with Rancher, please join us at either our [Rancher forums](http://forums.rancher.com/) or [Slack](https://slack.rancher.io/) where most of our team hangs out at.

Please submit any Rancher bugs, issues, and feature requests to [rancher/rancher](https://github.com/rancher/rancher/issues).

For security issues, please first check our [security policy](https://github.com/rancher/rancher/security) and email security-rancher@suse.com instead of posting a public issue in GitHub.  You may (but are not required to) use the GPG key located on [Keybase](https://keybase.io/rancher).

# License

Copyright (c) 2014-2025 [SUSE](http://rancher.com)

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[loong/go-concurrency-exercises]]></title>
            <link>https://github.com/loong/go-concurrency-exercises</link>
            <guid>https://github.com/loong/go-concurrency-exercises</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:08 GMT</pubDate>
            <description><![CDATA[Hands on exercises with real-life examples to study and practice Go concurrency patterns. Test-cases are provided to verify your answers.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/loong/go-concurrency-exercises">loong/go-concurrency-exercises</a></h1>
            <p>Hands on exercises with real-life examples to study and practice Go concurrency patterns. Test-cases are provided to verify your answers.</p>
            <p>Language: Go</p>
            <p>Stars: 1,779</p>
            <p>Forks: 532</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre># Go Concurrency Exercises [![Build Status](https://travis-ci.org/loong/go-concurrency-exercises.svg?branch=main)](https://travis-ci.org/loong/go-concurrency-exercises) [![Go Report Card](https://goreportcard.com/badge/github.com/loong/go-concurrency-exercises)](https://goreportcard.com/report/github.com/loong/go-concurrency-exercises)
Exercises for Golang&#039;s concurrency patterns.

## Why
The Go community has plenty resources to read about go&#039;s concurrency model and how to use it effectively. But *who actually wants to read all this*!? This repo tries to teach concurrency patterns by following the &#039;learning by doing&#039; approach.

![Image of excited gopher](https://golang.org/doc/gopher/pkg.png)

## How to take this challenge
1. *Only edit `main.go`* to solve the problem. Do not touch any of the other files.
2. If you find a `*_test.go` file, you can test the correctness of your solution with `go test`
3. If you get stuck, join us on [Discord](https://discord.com/invite/golang) or [Slack](https://invite.slack.golangbridge.org/)! Surely there are people who are happy to give you some code reviews (if not, find me via `@loong` ;) )

## Overview
| # | Name of the Challenge + URL           | 
| - |:-------------|
| 0 | [Limit your Crawler](https://github.com/loong/go-concurrency-exercises/tree/main/0-limit-crawler) |
| 1 | [Producer-Consumer](https://github.com/loong/go-concurrency-exercises/tree/main/1-producer-consumer)  |
| 2 | [Race Condition in Caching Cache](https://github.com/loong/go-concurrency-exercises/tree/main/2-race-in-cache#race-condition-in-caching-szenario)  |
| 3 | [Limit Service Time for Free-tier Users](https://github.com/loong/go-concurrency-exercises/tree/main/3-limit-service-time)  |
| 4 | [Graceful SIGINT Killing](https://github.com/loong/go-concurrency-exercises/tree/main/4-graceful-sigint)  |
| 5 | [Clean Inactive Sessions to Prevent Memory Overflow](https://github.com/loong/go-concurrency-exercises/tree/main/5-session-cleaner)  |

## License

```
 DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE 
                    Version 2, December 2004 

 Copyleft from 2017 Long Hoang

 Everyone is permitted to copy and distribute verbatim or modified 
 copies of this license document, and changing it is allowed as long 
 as the name is changed.

            DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE 
   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION 

  0. You just DO WHAT THE FUCK YOU WANT TO.
```
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[juicedata/juicefs]]></title>
            <link>https://github.com/juicedata/juicefs</link>
            <guid>https://github.com/juicedata/juicefs</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:07 GMT</pubDate>
            <description><![CDATA[JuiceFS is a distributed POSIX file system built on top of Redis and S3.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/juicedata/juicefs">juicedata/juicefs</a></h1>
            <p>JuiceFS is a distributed POSIX file system built on top of Redis and S3.</p>
            <p>Language: Go</p>
            <p>Stars: 12,975</p>
            <p>Forks: 1,142</p>
            <p>Stars today: 235 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/juicedata/juicefs&quot;&gt;&lt;img alt=&quot;JuiceFS Logo&quot; src=&quot;docs/en/images/juicefs-logo-new.svg&quot; width=&quot;50%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/juicedata/juicefs/releases/latest&quot;&gt;&lt;img alt=&quot;Latest Stable Release&quot; src=&quot;https://img.shields.io/github/v/release/juicedata/juicefs&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/juicedata/juicefs/actions/workflows/unittests.yml&quot;&gt;&lt;img alt=&quot;GitHub Workflow Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/unittests.yml?branch=main&amp;label=Unit%20Testing&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/juicedata/juicefs/actions/workflows/integrationtests.yml&quot;&gt;&lt;img alt=&quot;GitHub Workflow Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/integrationtests.yml?branch=main&amp;label=Integration%20Testing&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://goreportcard.com/report/github.com/juicedata/juicefs&quot;&gt;&lt;img alt=&quot;Go Report&quot; src=&quot;https://goreportcard.com/badge/github.com/juicedata/juicefs&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://juicefs.com/docs/community/introduction&quot;&gt;&lt;img alt=&quot;English doc&quot; src=&quot;https://img.shields.io/badge/docs-Doc%20Center-brightgreen&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://go.juicefs.com/slack&quot;&gt;&lt;img alt=&quot;Join Slack&quot; src=&quot;https://badgen.net/badge/Slack/Join%20JuiceFS/0abd59?icon=slack&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

**JuiceFS** is a high-performance [POSIX](https://en.wikipedia.org/wiki/POSIX) file system released under Apache License 2.0, particularly designed for the cloud-native environment. The data, stored via JuiceFS, will be persisted in Object Storage _(e.g. Amazon S3)_, and the corresponding metadata can be persisted in various compatible database engines such as Redis, MySQL, and TiKV based on the scenarios and requirements.

With JuiceFS, massive cloud storage can be directly connected to big data, machine learning, artificial intelligence, and various application platforms in production environments. Without modifying code, the massive cloud storage can be used as efficiently as local storage.

üìñ **Document**: [Quick Start Guide](https://juicefs.com/docs/community/quick_start_guide)

## Highlighted Features

1. **Fully POSIX-compatible**: Use as a local file system, seamlessly docking with existing applications without breaking business workflow.
2. **Fully Hadoop-compatible**: JuiceFS&#039; [Hadoop Java SDK](https://juicefs.com/docs/community/hadoop_java_sdk) is compatible with Hadoop 2.x and Hadoop 3.x as well as a variety of components in the Hadoop ecosystems.
3. **S3-compatible**:  JuiceFS&#039; [S3 Gateway](https://juicefs.com/docs/community/s3_gateway) provides an S3-compatible interface.
4. **Cloud Native**: A [Kubernetes CSI Driver](https://juicefs.com/docs/community/how_to_use_on_kubernetes) is provided for easily using JuiceFS in Kubernetes.
5. **Shareable**: JuiceFS is a shared file storage that can be read and written by thousands of clients.
6. **Strong Consistency**: The confirmed modification will be immediately visible on all the servers mounted with the same file system.
7. **Outstanding Performance**: The latency can be as low as a few milliseconds, and the throughput can be expanded nearly unlimitedly _(depending on the size of the Object Storage)_. [Test results](https://juicefs.com/docs/community/benchmark)
8. **Data Encryption**: Supports data encryption in transit and at rest (please refer to [the guide](https://juicefs.com/docs/community/security/encrypt) for more information).
9. **Global File Locks**: JuiceFS supports both BSD locks (flock) and POSIX record locks (fcntl).
10. **Data Compression**: JuiceFS supports [LZ4](https://lz4.github.io/lz4) or [Zstandard](https://facebook.github.io/zstd) to compress all your data.

---

[Architecture](#architecture) | [Getting Started](#getting-started) | [Advanced Topics](#advanced-topics) | [POSIX Compatibility](#posix-compatibility) | [Performance Benchmark](#performance-benchmark) | [Supported Object Storage](#supported-object-storage) | [Who is using](#who-is-using) | [Roadmap](#roadmap) | [Reporting Issues](#reporting-issues) | [Contributing](#contributing) | [Community](#community) | [Usage Tracking](#usage-tracking) | [License](#license) | [Credits](#credits) | [FAQ](#faq)

---

## Architecture

JuiceFS consists of three parts:

1. **JuiceFS Client**: Coordinates Object Storage and metadata storage engine as well as implementation of file system interfaces such as POSIX, Hadoop, Kubernetes, and S3 gateway.
2. **Data Storage**: Stores data, with supports of a variety of data storage media, e.g., local disk, public or private cloud Object Storage, and HDFS.
3. **Metadata Engine**: Stores the corresponding metadata that contains information of file name, file size, permission group, creation and modification time and directory structure, etc., with supports of different metadata engines, e.g., Redis, MySQL, SQLite and TiKV.

![JuiceFS Architecture](docs/en/images/juicefs-arch-new.png)

JuiceFS can store the metadata of file system on different metadata engines, like Redis, which is a fast, open-source, in-memory key-value data storage, particularly suitable for storing metadata; meanwhile, all the data will be stored in Object Storage through JuiceFS client. [Learn more](https://juicefs.com/docs/community/architecture)

![data-structure-diagram](docs/en/images/data-structure-diagram.svg)

Each file stored in JuiceFS is split into **&quot;Chunk&quot;** s at a fixed size with the default upper limit of 64 MiB. Each Chunk is composed of one or more **&quot;Slice&quot;**(s), and the length of the slice varies depending on how the file is written. Each slice is composed of size-fixed **&quot;Block&quot;** s, which are 4 MiB by default. These blocks will be stored in Object Storage in the end; at the same time, the metadata information of the file and its Chunks, Slices, and Blocks will be stored in metadata engines via JuiceFS. [Learn more](https://juicefs.com/docs/community/architecture/#how-juicefs-store-files)

![How JuiceFS stores your files](docs/en/images/how-juicefs-stores-files.svg)

When using JuiceFS, files will eventually be split into Chunks, Slices and Blocks and stored in Object Storage. Therefore, the source files stored in JuiceFS cannot be found in the file browser of the Object Storage platform; instead, there are only a chunks directory and a bunch of digitally numbered directories and files in the bucket. Don&#039;t panic! This is just the secret of the high-performance operation of JuiceFS!

## Getting Started

Before you begin, make sure you have:

1. One supported metadata engine, see [How to Set Up Metadata Engine](https://juicefs.com/docs/community/databases_for_metadata)
2. One supported Object Storage for storing data blocks, see [Supported Object Storage](https://juicefs.com/docs/community/how_to_setup_object_storage)
3. [JuiceFS Client](https://juicefs.com/docs/community/installation) downloaded and installed

Please refer to [Quick Start Guide](https://juicefs.com/docs/community/quick_start_guide) to start using JuiceFS right away!

### Command Reference

Check out all the command line options in [command reference](https://juicefs.com/docs/community/command_reference).

### Containers

JuiceFS can be used as a persistent volume for Docker and Podman, please check [here](https://juicefs.com/docs/community/juicefs_on_docker) for details.

### Kubernetes

It is also very easy to use JuiceFS on Kubernetes. Please find more information [here](https://juicefs.com/docs/community/how_to_use_on_kubernetes).

### Hadoop Java SDK

If you wanna use JuiceFS in Hadoop, check [Hadoop Java SDK](https://juicefs.com/docs/community/hadoop_java_sdk).

## Advanced Topics

- [Redis Best Practices](https://juicefs.com/docs/community/redis_best_practices)
- [How to Setup Object Storage](https://juicefs.com/docs/community/how_to_setup_object_storage)
- [Cache](https://juicefs.com/docs/community/cache)
- [Fault Diagnosis and Analysis](https://juicefs.com/docs/community/fault_diagnosis_and_analysis)
- [FUSE Mount Options](https://juicefs.com/docs/community/fuse_mount_options)
- [Using JuiceFS on Windows](https://juicefs.com/docs/community/installation#windows)
- [S3 Gateway](https://juicefs.com/docs/community/s3_gateway)

Please refer to [JuiceFS Document Center](https://juicefs.com/docs/community/introduction) for more information.

## POSIX Compatibility

JuiceFS has passed all of the compatibility tests (8813 in total) in the latest [pjdfstest](https://github.com/pjd/pjdfstest) .

```
All tests successful.

Test Summary Report
-------------------
/root/soft/pjdfstest/tests/chown/00.t          (Wstat: 0 Tests: 1323 Failed: 0)
  TODO passed:   693, 697, 708-709, 714-715, 729, 733
Files=235, Tests=8813, 233 wallclock secs ( 2.77 usr  0.38 sys +  2.57 cusr  3.93 csys =  9.65 CPU)
Result: PASS
```

Aside from the POSIX features covered by pjdfstest, JuiceFS also provides:

- **Close-to-open consistency**. Once a file is written _and_ closed, it is guaranteed to view the written data in the following opens and reads from any client. Within the same mount point, all the written data can be read immediately.
- Rename and all other metadata operations are atomic, which are guaranteed by supported metadata engine transaction.
- Opened files remain accessible after unlink from same mount point.
- Mmap (tested with FSx).
- Fallocate with punch hole support.
- Extended attributes (xattr).
- BSD locks (flock).
- POSIX record locks (fcntl).

## Performance Benchmark

### Basic benchmark

JuiceFS provides a subcommand that can run a few basic benchmarks to help you understand how it works in your environment:

![JuiceFS Bench](docs/en/images/juicefs-bench.png)

### Throughput

A sequential read/write benchmark has also been performed on JuiceFS, [EFS](https://aws.amazon.com/efs) and [S3FS](https://github.com/s3fs-fuse/s3fs-fuse) by [fio](https://github.com/axboe/fio).

![Sequential Read Write Benchmark](docs/en/images/sequential-read-write-benchmark.svg)

Above result figure shows that JuiceFS can provide 10X more throughput than the other two (see [more details](https://juicefs.com/docs/community/fio)).

### Metadata IOPS

A simple mdtest benchmark has been performed on JuiceFS, [EFS](https://aws.amazon.com/efs) and [S3FS](https://github.com/s3fs-fuse/s3fs-fuse) by [mdtest](https://github.com/hpc/ior).

![Metadata Benchmark](docs/en/images/metadata-benchmark.svg)

The result shows that JuiceFS can provide significantly more metadata IOPS than the other two (see [more details](https://juicefs.com/docs/community/mdtest)).

### Analyze performance

See [Real-Time Performance Monitoring](https://juicefs.com/docs/community/fault_diagnosis_and_analysis#performance-monitor) if you encountered performance issues.

## Supported Object Storage

- Amazon S3 _(and other S3 compatible Object Storage services)_
- Google Cloud Storage
- Azure Blob Storage
- Alibaba Cloud Object Storage Service (OSS)
- Tencent Cloud Object Storage (COS)
- Qiniu Cloud Object Storage (Kodo)
- QingStor Object Storage
- Ceph RGW
- MinIO
- Local disk
- Redis
- ...

JuiceFS supports numerous Object Storage services. [Learn more](https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage).

## Who is using

JuiceFS is production ready and used by thousands of machines in production. A list of users has been assembled and documented [here](https://juicefs.com/docs/community/adopters). In addition JuiceFS has several collaborative projects that integrate with other open source projects, which we have documented [here](https://juicefs.com/docs/community/integrations). If you are also using JuiceFS, please feel free to let us know, and you are welcome to share your specific experience with everyone.

The storage format is stable, and will be supported by all future releases.

## Roadmap

- Gateway Optimization
- Resumable Sync
- Read-ahead Optimization
- Optimization for Large-scale Scenarios
- Snapshots

## Reporting Issues

We use [GitHub Issues](https://github.com/juicedata/juicefs/issues) to track community reported issues. You can also [contact](#community) the community for any questions.

## Contributing

Thank you for your contribution! Please refer to the [JuiceFS Contributing Guide](https://juicefs.com/docs/community/development/contributing_guide) for more information.

## Community

Welcome to join the [Discussions](https://github.com/juicedata/juicefs/discussions) and the [Slack channel](https://go.juicefs.com/slack) to connect with JuiceFS team members and other users.

## Usage Tracking

JuiceFS collects **anonymous** usage data by default to help us better understand how the community is using JuiceFS. Only core metrics (e.g. version number) will be reported, and user data and any other sensitive data will not be included. The related code can be viewed [here](pkg/usage/usage.go).

You could also disable reporting easily by command line option `--no-usage-report`:

```bash
juicefs mount --no-usage-report
```

## License

JuiceFS is open-sourced under Apache License 2.0, see [LICENSE](LICENSE).

## Credits

The design of JuiceFS was inspired by [Google File System](https://research.google/pubs/pub51), [HDFS](https://hadoop.apache.org) and [MooseFS](https://moosefs.com). Thanks for their great work!

## FAQ

### Why doesn&#039;t JuiceFS support XXX Object Storage?

JuiceFS supports many Object Storage services. Please check out [this list](https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage) first. If the Object Storage you want to use is compatible with S3, you could treat it as S3. Otherwise, try reporting any issue.

### Can I use Redis Cluster as metadata engine?

Yes. Since [v1.0.0 Beta3](https://github.com/juicedata/juicefs/releases/tag/v1.0.0-beta3) JuiceFS supports the use of [Redis Cluster](https://redis.io/docs/manual/scaling) as the metadata engine, but it should be noted that Redis Cluster requires that the keys of all operations in a transaction must be in the same hash slot, so a JuiceFS file system can only use one hash slot.

See [&quot;Redis Best Practices&quot;](https://juicefs.com/docs/community/redis_best_practices) for more information.

### What&#039;s the difference between JuiceFS and XXX?

See [&quot;Comparison with Others&quot;](https://juicefs.com/docs/community/comparison/juicefs_vs_alluxio) for more information.

For more FAQs, please see the [full list](https://juicefs.com/docs/community/faq).

## Stargazers over time

[![Star History Chart](https://api.star-history.com/svg?repos=juicedata/juicefs&amp;type=Date)](https://star-history.com/#juicedata/juicefs&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ArvinLovegood/go-stock]]></title>
            <link>https://github.com/ArvinLovegood/go-stock</link>
            <guid>https://github.com/ArvinLovegood/go-stock</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:06 GMT</pubDate>
            <description><![CDATA[ü¶Ñü¶Ñü¶ÑAIËµãËÉΩËÇ°Á•®ÂàÜÊûêÔºöAIÂä†ÊåÅÁöÑËÇ°Á•®ÂàÜÊûê/ÈÄâËÇ°Â∑•ÂÖ∑„ÄÇËÇ°Á•®Ë°åÊÉÖËé∑ÂèñÔºåAIÁÉ≠ÁÇπËµÑËÆØÂàÜÊûêÔºåAIËµÑÈáë/Ë¥¢Âä°ÂàÜÊûêÔºåÊ∂®Ë∑åÊä•Ë≠¶Êé®ÈÄÅ„ÄÇÊîØÊåÅAËÇ°ÔºåÊ∏ØËÇ°ÔºåÁæéËÇ°„ÄÇÊîØÊåÅÂ∏ÇÂú∫Êï¥‰Ωì/‰∏™ËÇ°ÊÉÖÁª™ÂàÜÊûêÔºåAIËæÖÂä©ÈÄâËÇ°Á≠â„ÄÇÊï∞ÊçÆÂÖ®ÈÉ®‰øùÁïôÂú®Êú¨Âú∞„ÄÇÊîØÊåÅDeepSeekÔºåOpenAIÔºå OllamaÔºåLMStudioÔºåAnythingLLMÔºåÁ°ÖÂü∫ÊµÅÂä®ÔºåÁÅ´Â±±ÊñπËàüÔºåÈòøÈáå‰∫ëÁôæÁÇºÁ≠âÂπ≥Âè∞ÊàñÊ®°Âûã„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ArvinLovegood/go-stock">ArvinLovegood/go-stock</a></h1>
            <p>ü¶Ñü¶Ñü¶ÑAIËµãËÉΩËÇ°Á•®ÂàÜÊûêÔºöAIÂä†ÊåÅÁöÑËÇ°Á•®ÂàÜÊûê/ÈÄâËÇ°Â∑•ÂÖ∑„ÄÇËÇ°Á•®Ë°åÊÉÖËé∑ÂèñÔºåAIÁÉ≠ÁÇπËµÑËÆØÂàÜÊûêÔºåAIËµÑÈáë/Ë¥¢Âä°ÂàÜÊûêÔºåÊ∂®Ë∑åÊä•Ë≠¶Êé®ÈÄÅ„ÄÇÊîØÊåÅAËÇ°ÔºåÊ∏ØËÇ°ÔºåÁæéËÇ°„ÄÇÊîØÊåÅÂ∏ÇÂú∫Êï¥‰Ωì/‰∏™ËÇ°ÊÉÖÁª™ÂàÜÊûêÔºåAIËæÖÂä©ÈÄâËÇ°Á≠â„ÄÇÊï∞ÊçÆÂÖ®ÈÉ®‰øùÁïôÂú®Êú¨Âú∞„ÄÇÊîØÊåÅDeepSeekÔºåOpenAIÔºå OllamaÔºåLMStudioÔºåAnythingLLMÔºåÁ°ÖÂü∫ÊµÅÂä®ÔºåÁÅ´Â±±ÊñπËàüÔºåÈòøÈáå‰∫ëÁôæÁÇºÁ≠âÂπ≥Âè∞ÊàñÊ®°Âûã„ÄÇ</p>
            <p>Language: Go</p>
            <p>Stars: 3,859</p>
            <p>Forks: 630</p>
            <p>Stars today: 42 stars today</p>
            <h2>README</h2><pre># go-stock : Âü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑAIËµãËÉΩËÇ°Á•®ÂàÜÊûêÂ∑•ÂÖ∑
## ![go-stock](./build/appicon.png)
![GitHub Release](https://img.shields.io/github/v/release/ArvinLovegood/go-stock?link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock%2Freleases&amp;link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock%2Freleases)
[![GitHub Repo stars](https://img.shields.io/github/stars/ArvinLovegood/go-stock?link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock)](https://github.com/ArvinLovegood/go-stock)
[![star](https://gitee.com/arvinlovegood_admin/go-stock/badge/star.svg?theme=dark)](https://gitee.com/arvinlovegood_admin/go-stock)

[//]: # ([![star]&amp;#40;https://gitcode.com/ArvinLovegood/go-stock/star/badge.svg&amp;#41;]&amp;#40;https://gitcode.com/ArvinLovegood/go-stock&amp;#41;)

### üåüÂÖ¨‰ºóÂè∑
![Êâ´Á†Å_ÊêúÁ¥¢ËÅîÂêà‰º†Êí≠Ê†∑Âºè-ÁôΩËâ≤Áâà.png](build/screenshot/%E6%89%AB%E7%A0%81_%E6%90%9C%E7%B4%A2%E8%81%94%E5%90%88%E4%BC%A0%E6%92%AD%E6%A0%B7%E5%BC%8F-%E7%99%BD%E8%89%B2%E7%89%88.png)

### üìà ‰∫§ÊµÅÁæ§
- QQ‰∫§ÊµÅÁæ§2Ôºö[ÁÇπÂáªÈìæÊé•Âä†ÂÖ•Áæ§ËÅä„Äêgo-stock‰∫§ÊµÅÁæ§2„ÄëÔºö892666282](https://qm.qq.com/q/5mYiy6Yxh0)
- QQ‰∫§ÊµÅÁæ§Ôºö[ÁÇπÂáªÈìæÊé•Âä†ÂÖ•Áæ§ËÅä„Äêgo-stock‰∫§ÊµÅÁæ§„ÄëÔºö491605333(Â∑≤Êª°‰ºöÂÆöÊúüÊ∏ÖÁêÜÔºåÈöèÁºòÂÖ•Áæ§)](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&amp;k=0YQ8qD3exahsD4YLNhzQTWe5ssstWC89&amp;authKey=usOMMRFtIQDC%2FYcatHYapcxQbJ7PwXPHK9OypTXWzNjAq%2FRVvQu9bj2lRgb%2BSZ3p&amp;noverify=0&amp;group_code=491605333)

###  ‚ú® ÁÆÄ‰ªã
- Êú¨È°πÁõÆÂü∫‰∫éWailsÂíåNaiveUIÂºÄÂèëÔºåÁªìÂêàAIÂ§ßÊ®°ÂûãÊûÑÂª∫ÁöÑËÇ°Á•®ÂàÜÊûêÂ∑•ÂÖ∑„ÄÇ
- ÁõÆÂâçÂ∑≤ÊîØÊåÅAËÇ°ÔºåÊ∏ØËÇ°ÔºåÁæéËÇ°ÔºåÊú™Êù•ËÆ°ÂàíÂä†ÂÖ•Âü∫ÈáëÔºåETFÁ≠âÊîØÊåÅ„ÄÇ
- ÊîØÊåÅÂ∏ÇÂú∫Êï¥‰Ωì/‰∏™ËÇ°ÊÉÖÁª™ÂàÜÊûêÔºåKÁ∫øÊäÄÊúØÊåáÊ†áÂàÜÊûêÁ≠âÂäüËÉΩ„ÄÇ
- Êú¨È°πÁõÆ‰ªÖ‰æõÂ®±‰πêÔºå‰∏çÂñúÂãøÂñ∑ÔºåAIÂàÜÊûêËÇ°Á•®ÁªìÊûú‰ªÖ‰æõÂ≠¶‰π†Á†îÁ©∂ÔºåÊäïËµÑÊúâÈ£éÈô©ÔºåËØ∑Ë∞®ÊÖé‰ΩøÁî®„ÄÇ
- ÂºÄÂèëÁéØÂ¢É‰∏ªË¶ÅÂü∫‰∫éWindows10+ÔºåÂÖ∂‰ªñÂπ≥Âè∞Êú™ÊµãËØïÊàñÂäüËÉΩÂèóÈôê„ÄÇ

### üì¶ Á´ãÂç≥‰ΩìÈ™å
- ÂÆâË£ÖÁâàÔºö[go-stock-amd64-installer.exe](https://github.com/ArvinLovegood/go-stock/releases)
- ÁªøËâ≤ÁâàÔºö[go-stock-windows-amd64.exe](https://github.com/ArvinLovegood/go-stock/releases)


### üí¨ ÊîØÊåÅÂ§ßÊ®°Âûã/Âπ≥Âè∞
| Ê®°Âûã | Áä∂ÊÄÅ | Â§áÊ≥®                                                                                                                                                            |
| --- | --- |---------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [OpenAI](https://platform.openai.com/) | ‚úÖ | ÂèØÊé•ÂÖ•‰ªª‰Ωï OpenAI Êé•Âè£Ê†ºÂºèÊ®°Âûã                                                                                                                                           |
| [Ollama](https://ollama.com/) | ‚úÖ | Êú¨Âú∞Â§ßÊ®°ÂûãËøêË°åÂπ≥Âè∞                                                                                                                                                     |
| [LMStudio](https://lmstudio.ai/) | ‚úÖ | Êú¨Âú∞Â§ßÊ®°ÂûãËøêË°åÂπ≥Âè∞                                                                                                                                                     |
| [AnythingLLM](https://anythingllm.com/) | ‚úÖ | Êú¨Âú∞Áü•ËØÜÂ∫ì                                                                                                                                                         |
| [DeepSeek](https://www.deepseek.com/) | ‚úÖ | deepseek-reasoner,deepseek-chat                                                                                                                               |
| [Â§ßÊ®°ÂûãËÅöÂêàÂπ≥Âè∞](https://cloud.siliconflow.cn/i/foufCerk) | ‚úÖ | Â¶ÇÔºö[Á°ÖÂü∫ÊµÅÂä®](https://cloud.siliconflow.cn/i/foufCerk)Ôºå[ÁÅ´Â±±ÊñπËàü](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;ac=DSASUQY5&amp;rc=IJSE43PZ) ,[‰ºò‰∫ëÊô∫ÁÆó](https://www.compshare.cn/image-community?ytag=GPU_YY-gh_gostock) |

### &lt;span style=&quot;color: #568DF4;&quot;&gt;ÂêÑ‰Ωç‰∫≤Áà±ÁöÑÊúãÂèã‰ª¨ÔºåÂ¶ÇÊûúÊÇ®ÂØπËøô‰∏™È°πÁõÆÊÑüÂÖ¥Ë∂£ÔºåËØ∑ÂÖàÁªôÊàë‰∏Ä‰∏™&lt;i style=&quot;color: #EA2626;&quot;&gt;star&lt;/i&gt;ÂêßÔºåË∞¢Ë∞¢ÔºÅ&lt;/span&gt;üíï
- ‰ºò‰∫ëÊô∫ÁÆóÔºàby UCloudÔºâÔºö‰∏áÂç°ËßÑÊ®°4090ÂÖçË¥πÁî®10Â∞èÊó∂ÔºåÊñ∞‰∫∫Ê≥®ÂÜåÂè¶Â¢û50‰∏átokensÔºåÊµ∑ÈáèÁÉ≠Èó®Ê∫êÈ°πÁõÆÈïúÂÉè‰∏ÄÈîÆÈÉ®ÁΩ≤Ôºå[Ê≥®ÂÜåÈìæÊé•](https://www.compshare.cn/image-community?ytag=GPU_YY-gh_gostock)
- ÁªèÊµãËØïÁõÆÂâçÁ°ÖÂü∫ÊµÅÂä®(siliconflow)Êèê‰æõÁöÑdeepSeek api ÊúçÂä°ÊØîËæÉÁ®≥ÂÆöÔºåÊ≥®ÂÜåÂç≥ÈÄÅ2000‰∏áTokensÔºå[Ê≥®ÂÜåÈìæÊé•](https://cloud.siliconflow.cn/i/foufCerk)
- ÁÅ´Â±±ÊñπËàüÔºöÊØè‰∏™Ê®°ÂûãÊ≥®ÂÜåÂç≥ÈÄÅ50‰∏átokensÔºå[Ê≥®ÂÜåÈìæÊé•](https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;ac=DSASUQY5&amp;rc=IJSE43PZ)
- TushareÂ§ßÊï∞ÊçÆÂºÄÊîæÁ§æÂå∫,ÂÖçË¥πÊèê‰æõÂêÑÁ±ªÈáëËûçÊï∞ÊçÆ,Âä©ÂäõË°å‰∏öÂíåÈáèÂåñÁ†îÁ©∂(Ê≥®ÊÑèÔºöTushareÂè™ÈúÄË¶Å120ÁßØÂàÜÂç≥ÂèØÔºåÊ≥®ÂÜåÂÆåÊàê‰∏™‰∫∫ËµÑÊñôË°•ÂÖÖÂç≥ÂèØÂæó120ÁßØÂàÜÔºÅÔºÅÔºÅ)Ôºå[Ê≥®ÂÜåÈìæÊé•](https://tushare.pro/register?reg=701944)
- ËΩØ‰ª∂Âø´ÈÄüËø≠‰ª£ÂºÄÂèë‰∏≠,ËØ∑Â§ßÂÆ∂‰ºòÂÖàÊµãËØïÂíå‰ΩøÁî®ÊúÄÊñ∞ÂèëÂ∏ÉÁöÑÁâàÊú¨„ÄÇ
- Ê¨¢ËøéÂ§ßÂÆ∂ÊèêÂá∫ÂÆùË¥µÁöÑÂª∫ËÆÆÔºåÊ¨¢ËøéÊèêissue,PR„ÄÇÂΩìÁÑ∂Êõ¥Ê¨¢Ëøé[ËµûÂä©Êàë](#ÈÉΩÂàíÂà∞Ëøô‰∫ÜÂ¶ÇÊûúÊàëÁöÑÈ°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ËØ∑ËµûÂä©ÊàëÂêß)„ÄÇüíï


## üß© ÈáçÂ§ßÂäüËÉΩÂºÄÂèëËÆ°Âàí
| ÂäüËÉΩËØ¥Êòé            | Áä∂ÊÄÅ | Â§áÊ≥®                                                                                                       |
|-----------------|----|----------------------------------------------------------------------------------------------------------|
| ËÇ°Á•®ÂàÜÊûêÁü•ËØÜÂ∫ì         | üöß | Êú™Êù•ËÆ°Âàí                                                                                                     |
| AiÊô∫ËÉΩÈÄâËÇ°          | üöß | AiÊô∫ËÉΩÈÄâËÇ°ÂäüËÉΩÂºÄÂèë‰∏≠(‰∏ãÂçäÂπ¥ÈáçÁÇπÂºÄÂèëËÆ°Âàí)                                                                                   |
| ETFÊîØÊåÅ           | üöß | ETFÊï∞ÊçÆÊîØÊåÅ (ÁõÆÂâçÂèØ‰ª•Êü•ÁúãÂáÄÂÄºÂíå‰º∞ÂÄº)                                                                                    |
| ÁæéËÇ°ÊîØÊåÅ            | ‚úÖ  | ÁæéËÇ°Êï∞ÊçÆÊîØÊåÅ                                                                                                   |
| Ê∏ØËÇ°ÊîØÊåÅ            | ‚úÖ  | Ê∏ØËÇ°Êï∞ÊçÆÊîØÊåÅ                                                                                                   |
| Â§öËΩÆÂØπËØù            | ‚úÖ  | AIÂàÜÊûêÂêéÂèØÁªßÁª≠ÂØπËØùÊèêÈóÆ                                                                                             |
| Ëá™ÂÆö‰πâAIÂàÜÊûêÊèêÈóÆÊ®°Êùø     | ‚úÖ  | ÂèØÈÖçÁΩÆÁöÑÊèêÈóÆÊ®°Êùø [v2025.2.12.7-alpha](https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.12.7-alpha) |
| ‰∏çÂÜçÂº∫Âà∂‰æùËµñChromeÊµèËßàÂô® | ‚úÖ  | ÈªòËÆ§‰ΩøÁî®edgeÊµèËßàÂô®ÊäìÂèñÊñ∞ÈóªËµÑËÆØ                                                                                        |

## üëÄ Êõ¥Êñ∞Êó•Âøó
### 2025.06.30 Ê∑ªÂä†ÊåáÊ†áÈÄâËÇ°ÂäüËÉΩ
### 2025.06.27 Ê∑ªÂä†Ë¥¢ÁªèÊó•ÂéÜÂíåÈáçÂ§ß‰∫ã‰ª∂Êó∂Èó¥ËΩ¥ÂäüËÉΩ
### 2025.06.25 Ê∑ªÂä†ÁÉ≠Èó®ËÇ°Á•®„ÄÅ‰∫ã‰ª∂ÂíåËØùÈ¢òÂäüËÉΩ
### 2025.06.18 Êõ¥Êñ∞ÂÜÖÁΩÆËÇ°Á•®Âü∫Á°ÄÊï∞ÊçÆ,ËΩØ‰ª∂ÂÜÖÂÆûÊó∂Â∏ÇÂú∫ËµÑËÆØ‰ø°ÊÅØÊèêÈÜíÔºåÊ∑ªÂä†Ë°å‰∏öÁ†îÁ©∂ÂäüËÉΩ
### 2025.06.15 Ê∑ªÂä†ÂÖ¨Âè∏ÂÖ¨Âëä‰ø°ÊÅØÊêúÁ¥¢/Êü•ÁúãÂäüËÉΩ
### 2025.06.15 Ê∑ªÂä†‰∏™ËÇ°Á†îÊä•Âà∞ÂºπÂá∫ËèúÂçï
### 2025.06.13 Ê∑ªÂä†‰∏™ËÇ°Á†îÊä•ÂäüËÉΩ
### 2025.06.12 Ê∑ªÂä†ÈæôËôéÊ¶úÂäüËÉΩÔºåÊñ∞Â¢ûË°å‰∏öÊéíÂêçÂàÜÁ±ª
### 2025.05.30 ‰ºòÂåñËÇ°Á•®ÂàÜÊó∂ÂõæÊòæÁ§∫
### 2025.05.20 ‰øÆÂ§çË¥¢ËÅîÁ§æÁîµÊä•Ëé∑ÂèñÈóÆÈ¢ò
### 2025.05.16 ‰ºòÂåñËµÑÈáëË∂ãÂäøÂõæË°®ÁªÑ‰ª∂
### 2025.05.15 ÈáçÊûÑÂ∫îÁî®Âä†ËΩΩÂíåÊï∞ÊçÆÂàùÂßãÂåñÈÄªËæëÔºåÊ∑ªÂä†ËÇ°Á•®ËµÑÈáëË∂ãÂäøÂäüËÉΩÔºåËµÑÈáëË∂ãÂäøÂõæË°®Â¢ûÂä†‰∏ªÂäõÂΩìÊó•ÂáÄÊµÅÂÖ•Êï∞ÊçÆÂπ∂‰ºòÂåñÂ±ïÁ§∫ÊïàÊûú
### 2025.05.14 Ê∑ªÂä†‰∏™ËÇ°ËµÑÈáëÊµÅÂêëÂäüËÉΩÔºåÊéíË°åÊ¶úÂ¢ûÂä†ËÇ°Á•®Ë°åÊÉÖKÁ∫øÂõæÂºπÁ™ó
### 2025.05.13 Ê∑ªÂä†Ë°å‰∏öÊéíÂêçÂäüËÉΩ
### 2025.05.09 Ê∑ªÂä†AËÇ°ÁõòÂè£Êï∞ÊçÆËß£ÊûêÂíåÂ±ïÁ§∫ÂäüËÉΩ
### 2025.05.07 ‰ºòÂåñÂàÜÊó∂ÂõæÁöÑÂ±ïÁ§∫
### 2025.04.29 Ë°•ÂÖ®Ê∏ØËÇ°/ÁæéËÇ°Âü∫Á°ÄÊï∞ÊçÆÔºå‰ºòÂåñÊ∏ØËÇ°ËÇ°‰ª∑Âª∂ËøüÈóÆÈ¢òÔºå‰ºòÂåñÂàùÂßãÂåñÈÄªËæë
### 2025.04.25 Â∏ÇÂú∫ËµÑËÆØÊîØÊåÅAIÂàÜÊûêÂíåÊÄªÁªìÔºöËÆ©AIÂ∏Æ‰Ω†ËØªÂ∏ÇÂú∫ÔºÅ
### 2025.04.24 Êñ∞Â¢ûÂ∏ÇÂú∫Ë°åÊÉÖÊ®°ÂùóÔºöÂç≥Êó∂ÊéåÊè°ÂÖ®ÁêÉÂ∏ÇÂú∫Ë°åÊÉÖËµÑËÆØ/Âä®ÊÄÅÔºå‰ªéÊ≠§ÂÜç‰πü‰∏çÁî®ÂÅ∑Êë∏ÂéªÂêÑÂ§ßË¥¢ÁªèÁΩëÁ´ôÂï¶„ÄÇgo-stock‰∏ÄÈîÆÂ∏Æ‰Ω†ÊêûÂÆöÔºÅ
### 2025.04.22 ‰ºòÂåñKÁ∫øÂõæÂ±ïÁ§∫ÔºåÊîØÊåÅÊãâ‰º∏ÊîæÂ§ßÔºåÁúãÂæóÊõ¥ËàíÊúçÂï¶ÔºÅ
### 2025.04.21 Ê∏ØËÇ°ÔºåÁæéËÇ°KÁ∫øÊï∞ÊçÆËé∑Âèñ‰ºòÂåñ
### 2025.04.01 ‰ºòÂåñÈÉ®ÂàÜËÆæÁΩÆÈÄâÈ°πÔºåÈÅøÂÖçÈáçÂêØËΩØ‰ª∂
### 2025.03.31 ‰ºòÂåñÊï∞ÊçÆÁà¨Âèñ
### 2025.03.30 AIËá™Âä®ÂÆöÊó∂ÂàÜÊûêÂäüËÉΩ
### 2025.03.29 Â§öÊèêÁ§∫ËØçÊ®°ÊùøÁÆ°ÁêÜÔºåAIÂàÜÊûêÊó∂ÊîØÊåÅÈÄâÊã©‰∏çÂêåÊèêÁ§∫ËØçÊ®°Êùø
### 2025.03.28 AIÂàÜÊûêÁªìÊûú‰øùÂ≠ò‰∏∫markdownÊñá‰ª∂Êó∂ÔºåÊîØÊåÅ‰øùÂ≠ò‰ΩçÁΩÆÁõÆÂΩïÈÄâÊã©
### 2025.03.15 Ëá™ÂÆö‰πâÁà¨Ëô´‰ΩøÁî®ÁöÑÊµèËßàÂô®Ë∑ØÂæÑÈÖçÁΩÆ
### 2025.03.14 ‰ºòÂåñÁºñËØëÊûÑÂª∫ÔºåÂ§ßÂπÖÂáèÂ∞ëÁºñËØëÂêéÁöÑÁ®ãÂ∫èÊñá‰ª∂Â§ßÂ∞è
### 2025.03.09 Âü∫Èáë‰º∞ÂÄºÂíåÂáÄÂÄºÁõëÊéßÊü•Áúã
### 2025.03.06 È°πÁõÆÁ§æÂå∫ÂàÜ‰∫´ÂäüËÉΩ
### 2025.02.28 ÁæéËÇ°Êï∞ÊçÆÊîØÊåÅ
### 2025.02.23 ÂºπÂπïÂäüËÉΩÔºåÁõØÁõò‰∏çÂÜçÂ≠§ÂçïÔºåÊó†ËÅäÂàí‰∏™Ê∞¥ÔºÅüòé
### 2025.02.22 Ê∏ØËÇ°Êï∞ÊçÆÊîØÊåÅ(ÁõÆÂâçÊúâÂª∂Ëøü)

### 2025.02.16 AIÂàÜÊûêÂêéÂèØÁªßÁª≠ÂØπËØùÊèêÈóÆ
- [v2025.2.16.1-alpha](https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.16.1-alpha)

### 2025.02.12 ÂèØÈÖçÁΩÆÁöÑÊèêÈóÆÊ®°Êùø
- [v2025.2.12.7-alpha](https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.12.7-alpha)


## ü¶Ñ ÈáçÂ§ßÊõ¥Êñ∞
### BIG NEWS !!! ÈáçÂ§ßÊõ¥Êñ∞ÔºÅÔºÅÔºÅ
- 2025.04.25 Â∏ÇÂú∫ËµÑËÆØÊîØÊåÅAIÂàÜÊûêÂíåÊÄªÁªìÔºöËÆ©AIÂ∏Æ‰Ω†ËØªÂ∏ÇÂú∫ÔºÅ
![img.png](img.png)
- 2025.04.24 Êñ∞Â¢ûÂ∏ÇÂú∫Ë°åÊÉÖÊ®°ÂùóÔºöÂç≥Êó∂ÊéåÊè°ÂÖ®ÁêÉÂ∏ÇÂú∫Ë°åÊÉÖËµÑËÆØ/Âä®ÊÄÅÔºå‰ªéÊ≠§ÂÜç‰πü‰∏çÁî®ÂÅ∑Êë∏ÂéªÂêÑÂ§ßË¥¢ÁªèÁΩëÁ´ôÂï¶„ÄÇgo-stock‰∏ÄÈîÆÂ∏Æ‰Ω†ÊêûÂÆöÔºÅ
![img.png](build/screenshot/img13.png)
![img_13.png](build/screenshot/img_13.png)
- ![img_14.png](build/screenshot/img_14.png)
- 2025.01.17 Êñ∞Â¢ûAIÂ§ßÊ®°ÂûãÂàÜÊûêËÇ°Á•®ÂäüËÉΩ
  ![img_5.png](build/screenshot/img.png)
## üì∏ ÂäüËÉΩÊà™Âõæ
![img_1.png](build/screenshot/img_6.png)
### ËÆæÁΩÆ
![img_12.png](build/screenshot/img_4.png)
### ÊàêÊú¨ËÆæÁΩÆ
![img.png](build/screenshot/img_7.png)
### Êó•K
![img_12.png](build/screenshot/img_12.png)
### ÂàÜÊó∂
![img_3.png](build/screenshot/img_9.png)
### ÈíâÈíâÊä•Ë≠¶ÈÄöÁü•
![img_4.png](build/screenshot/img_5.png)
### AIÂàÜÊûêËÇ°Á•®
![img_5.png](build/screenshot/img.png)
### ÁâàÊú¨‰ø°ÊÅØÊèêÁ§∫
![img_11.png](build/screenshot/img_11.png)

## üíï ÊÑüË∞¢‰ª•‰∏ãÈ°πÁõÆ
- [NaiveUI](https://www.naiveui.com/)
- [Wails](https://wails.io/)
- [Vue](https://vuejs.org/)
- [Vite](https://vitejs.dev/)
- [Tushare](https://tushare.pro/register?reg=701944)

## üòò ËµûÂä©Êàë
### ÈÉΩÂàíÂà∞Ëøô‰∫ÜÔºåÂ¶ÇÊûúÊàëÁöÑÈ°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑ËµûÂä©ÊàëÂêßÔºÅüòäüòäüòä
| ÊîØ‰ªòÂÆù | ÂæÆ‰ø°  |
|-----|-----| 
| ![alipay.jpg](build/screenshot/alipay.jpg)  | ![wxpay.jpg](build/screenshot/wxpay.jpg) |


## ‚≠ê Star History
[![Star History Chart](https://api.star-history.com/svg?repos=ArvinLovegood/go-stock&amp;type=Date)](https://star-history.com/#ArvinLovegood/go-stock&amp;Date)
## ü§ñ Áä∂ÊÄÅ
![Alt](https://repobeats.axiom.co/api/embed/40b07d415a42c2264a18c4fe1b6f182ff1470687.svg &quot;Repobeats analytics image&quot;)

## üê≥ ÂÖ≥‰∫éÊäÄÊúØÊîØÊåÅÁî≥Êòé
- Êú¨ËΩØ‰ª∂Âü∫‰∫éÂºÄÊ∫êÊäÄÊúØÊûÑÂª∫Ôºå‰ΩøÁî®Wails„ÄÅNaiveUI„ÄÅVue„ÄÅAIÂ§ßÊ®°ÂûãÁ≠âÂºÄÊ∫êÈ°πÁõÆ„ÄÇ ÊäÄÊúØ‰∏äÂ¶ÇÊúâÈóÆÈ¢òÔºåÂèØ‰ª•ÂÖàÂêëÂØπÂ∫îÁöÑÂºÄÊ∫êÁ§æÂå∫ËØ∑Ê±ÇÂ∏ÆÂä©„ÄÇ
- ÂºÄÊ∫ê‰∏çÊòìÔºåÊú¨‰∫∫Á≤æÂäõÂíåÊó∂Èó¥ÊúâÈôêÔºåÂ¶ÇÈúÄ‰∏ÄÂØπ‰∏ÄÊäÄÊúØÊîØÊåÅÔºåËØ∑ÂÖàËµûÂä©„ÄÇËÅîÁ≥ªÂæÆ‰ø°(Â§áÊ≥® ÊäÄÊúØÊîØÊåÅ)ÔºöArvinLovegood

&lt;img src=&quot;./build/wx.jpg&quot; width=&quot;301px&quot; height=&quot;402px&quot; alt=&quot;ArvinLovegood&quot;&gt;


| ÊäÄÊúØÊîØÊåÅÊñπÂºè                          | ËµûÂä©(ÂÖÉ) | 
|:--------------------------------|:-----:|
| Âä† QQÔºö506808970ÔºåÂæÆ‰ø°ÔºöArvinLovegood | 100/Ê¨° |
| ÈïøÊúüÊäÄÊúØÊîØÊåÅÔºà‰∏çÈôêÊ¨°Êï∞ÔºåÊñ∞ÂäüËÉΩ‰ºòÂÖà‰ΩìÈ™åÁ≠âÔºâ            | 5000  |                  



## License
[Apache License 2.0](LICENSE)

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[getlago/lago]]></title>
            <link>https://github.com/getlago/lago</link>
            <guid>https://github.com/getlago/lago</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:05 GMT</pubDate>
            <description><![CDATA[Open Source Metering and Usage Based Billing API ‚≠êÔ∏è Consumption tracking, Subscription management, Pricing iterations, Payment orchestration & Revenue analytics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/getlago/lago">getlago/lago</a></h1>
            <p>Open Source Metering and Usage Based Billing API ‚≠êÔ∏è Consumption tracking, Subscription management, Pricing iterations, Payment orchestration & Revenue analytics</p>
            <p>Language: Go</p>
            <p>Stars: 9,113</p>
            <p>Forks: 517</p>
            <p>Stars today: 38 stars today</p>
            <h2>README</h2><pre>&lt;!-- PROJECT LOGO --&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/getlago/lago&quot;&gt;
    &lt;img src=&quot;https://uploads-ssl.webflow.com/635119506e36baf5c267fecd/635b6df0ee8effaa54c1fa42_banner-open-graph.jpg&quot; alt=&quot;Lago&quot;&gt;
  &lt;/a&gt;

  &lt;h1 align=&quot;center&quot;&gt;Lago&lt;/h2&gt;

  &lt;p align=&quot;center&quot;&gt;
    Open Source Metering &amp; Usage-Based Billing
    &lt;br /&gt;
    &lt;br /&gt;
    The best alternative to Chargebee, Recurly or Stripe Billing.
    &lt;br /&gt;
    For usage-based, subscription-based, and all the nuances of pricing in between.
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://www.getlago.com/slack&quot;&gt;Slack&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://getlago.com&quot;&gt;Website&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/getlago/lago/issues&quot;&gt;Issues&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://getlago.canny.io/&quot;&gt;Roadmap&lt;/a&gt;
  &lt;/p&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.producthunt.com/posts/lago?utm_source=badge-top-post-badge&amp;utm_medium=badge&amp;utm_souce=badge-lago&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=386328&amp;theme=light&amp;period=monthly&quot; alt=&quot;Lago - Open&amp;#0045;source&amp;#0032;alternative&amp;#0032;to&amp;#0032;Stripe&amp;#0032;Billing&amp;#0032;and&amp;#0032;Chargebee | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.producthunt.com/posts/lago?utm_source=badge-top-post-topic-badge&amp;utm_medium=badge&amp;utm_souce=badge-lago&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=386328&amp;theme=light&amp;period=monthly&amp;topic_id=267&quot; alt=&quot;Lago - Open&amp;#0045;source&amp;#0032;alternative&amp;#0032;to&amp;#0032;Stripe&amp;#0032;Billing&amp;#0032;and&amp;#0032;Chargebee | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
   &lt;a href=&quot;https://www.getlago.com/slack&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Lago%20Slack%20Community-lago.slack.com-%234A154B&quot; alt=&quot;Join Lago on Slack&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://github.com/getlago/lago/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/getlago/lago&quot; alt=&quot;Github Stars&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://news.ycombinator.com/item?id=31424450&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Hacker%20News-777-%23FF6600&quot; alt=&quot;Hacker News&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://github.com/getlago/lago/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-AGPLv3-purple&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://twitter.com/getlago&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/getlago?style=flat&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://www.ycombinator.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Backed%20by-Y%20Combinator-%23f26625&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;!-- ABOUT THE PROJECT --&gt;
## The programmable API for usage-based billing
[![Lago Billing System Presentation](https://img.youtube.com/vi/dXnoMRetsr4/0.jpg)](https://www.youtube.com/watch?v=dXnoMRetsr4)

### The problem: Billing systems are still a nightmare for engineers
![Billing nightmare](https://uploads-ssl.webflow.com/6244531a40ad7ef5475ad9b3/62827b2f6fa52239b0db0fa4_Blog%20Post%20Image%20Standalone.png)
Engineers be like‚Ä¶

Read more first-hand experiences from Qonto, Algolia, Pleo, Segment, or the 350+. Hackernews comments [here](https://news.ycombinator.com/item?id=31424450).

**The Solution:** Lago, the open-source billing API for product-led SaaS
- Event-based: if you can track it, you can charge for it;
- Built for product-led growth companies;
- Hybrid pricing: subscription and usage;
- Hybrid go-to-market motion: self-serve and sales-led.

**Open-source, open architecture:**
- Composable: connect Lago to any of your internal systems or tools (i.e. any payment gateway, CRM, CPQ, accounting software);
- Pricing: we‚Äôre not rent seekers, we‚Äôre not asking for a % of your revenue. Our self-hosted version is free. Our cloud version is priced like a SaaS;
- Privacy: your data never has to leave your infrastructure.

## ‚ú® Features
- **[Usage metering](https://www.getlago.com/products/metering)**: Lago&#039;s event-based architecture provides a solid foundation for building a fair pricing model that scales with your business.
- **[Price plans](https://www.getlago.com/products/plans)**: Lago supports all pricing models. Create pay-as-you-go and hybrid plans in no time with our intuitive user interface or API.
- **[Coupons](https://www.getlago.com/products/coupons)**: Create engaging marketing campaigns and increase conversion with coupons that customers can redeem to get a discount.
- **[Add-ons](https://www.getlago.com/products/add-on)**: Why wait until the end of the billing cycle to get paid? Lago allows you to create one-time charges that are invoiced on the fly.
- **[Invoicing](https://www.getlago.com/products/invoicing)**: Depending on the configuration of your plans, Lago automatically calculates what each customer owes you and generates invoices.
- **[Prepaid credits](https://www.getlago.com/products/prepaid-credits)**: Unlock recurring revenue opportunities for pay-as-you-go pricing models with Lago&#039;s prepaid credit features.

## üìö Documentation
- **[Development Environment](./docs/dev_environment.md)**: Learn how to set up and run Lago locally for development
- **[Architecture](./docs/architecture.md)**: Understand Lago&#039;s technical architecture and flows

## üîî Stay up to date
Lago launched its v0.1 on June 2nd, 2022. Lots of new features are coming, and are generally released on a bi-weekly basis. Watch updates of this repository to be notified of future updates.

[Check out our public roadmap](https://getlago.canny.io/)

## üîñ License
Distributed under the AGPLv3 License. Read more [here](https://www.getlago.com/blog/open-source-licensing-and-why-lago-chose-agplv3).

## Current Releases

| Project            | Release Badge                                                                                       |
|--------------------|-----------------------------------------------------------------------------------------------------|
| **Lago**           | [![Lago Release](https://img.shields.io/github/v/release/getlago/lago)](https://github.com/getlago/lago/releases) |
| **Lago API**     | [![Lago API Release](https://img.shields.io/github/v/release/getlago/lago-api)](https://github.com/getlago/lago-api/releases) |
| **Lago front**     | [![Lago front Testing Release](https://img.shields.io/github/v/release/getlago/lago-front)](https://github.com/getlago/lago-front/releases) |
| **Lago Go Client**     | [![Lago Go Client Testing Release](https://img.shields.io/github/v/release/getlago/lago-go-client)](https://github.com/getlago/lago-go-client/releases) |
| **lago-gotenberg**     | [![lago-gotenberg Release](https://img.shields.io/github/v/release/getlago/lago-gotenberg)](https://github.com/getlago/lago-gotenberg/releases) |
| **Lago JavaScript Client**     | [![Lago JavaScript Client Release](https://img.shields.io/github/v/release/getlago/lago-javascript-client)](https://github.com/getlago/lago-javascript-client/releases) |
| **Lago OpenAPI**     | [![Lago OpenAPI Release](https://img.shields.io/github/v/release/getlago/lago-openapi)](https://github.com/getlago/lago-openapi/releases) |
| **Lago Python Client**     | [![Lago Python Client Release](https://img.shields.io/github/v/release/getlago/lago-python-client)](https://github.com/getlago/lago-python-client/releases) |
| **Lago Ruby Client**     | [![Lago Ruby Client Release](https://img.shields.io/github/v/release/getlago/lago-ruby-client)](https://github.com/getlago/lago-ruby-client/releases) |


## üíª Deploy locally

### Requirements
1. Install Docker on your machine;
2. Make sure Docker Compose is installed and available (it should be the case if you have chosen to install Docker via Docker Desktop); and
3. Make sure Git is installed on your machine.

### Run the app
To start using Lago, run the following commands in a shell:


#### On a fresh install
```bash
# Get the code
git clone --depth 1 https://github.com/getlago/lago.git

# Go to Lago folder
cd lago

# Set up environment configuration
echo &quot;LAGO_RSA_PRIVATE_KEY=\&quot;`openssl genrsa 2048 | openssl base64 -A`\&quot;&quot; &gt;&gt; .env
source .env

# Start all the components
docker compose up
```

#### After an update

```bash
docker compose up
```

You can now open your browser and go to http://localhost to connect to the application. Lago&#039;s API is exposed at http://localhost:3000.

Note that if our docker server is not at http://localhost, the following env variables must be set: `LAGO_API_URL`. This may be on the command line or in your .env file. For example:

```
LAGO_API_URL=&quot;http://192.168.122.71:3000&quot;
LAGO_FRONT_URL=&quot;http://192.168.122.71&quot;
```

### Find your API key
Your API Key can be found directly in the UI:

1. Access the **Developer** section from the sidebar;
2. The first tab of this section is related to your **API keys**; and
3. Click the **Copy** button to copy it to clipboard.

### Analytics and tracking
Please note that Lago, by default, tracks basic actions performed on your self-hosted instance. If you do not disable tracking, you may receive specific communications or product updates. However, rest assured that Lago will not collect any personal information about your customers or financial information about your invoices.

If you would like to know more about Lago&#039;s analytics or remove the entire tracking, please refer to [this page](https://doc.getlago.com/guide/self-hosted/tracking-analytics) for comprehensive information.

### Version, environment variables and components
Docker images are always updated to the last stable version in the docker-compose.yml file. You can use a different tag if needed by checking the releases list.

Lago uses the following environment variables to configure the components of the application. You can override them to customise your setup. Take a closer look are our [documentation](https://doc.getlago.com/docs/guide/self-hosting/docker#configuration).

## ‚òÅÔ∏è Use our cloud-based product
Contact our team at hello@getlago.com to get started with Lago Cloud. More information on [our website](https://www.getlago.com/pricing).

## üöÄ Getting the most out of Lago
- See the [documentation](https://doc.getlago.com) to learn more about all the features;
- Use our [templates](https://getlago.com/docs/templates/introduction) to get inspiration and learn how to reproduce Algolia‚Äôs, Segment‚Äôs and Klaviyo‚Äôs pricing models;
- Join our [Slack community](https://www.getlago.com/slack) if you need help, or want to chat, we‚Äôre here to help;
- Contribute on GitHub: read our [guidelines](https://github.com/getlago/lago/blob/main/CONTRIBUTING.md);
- Follow us on [Twitter](https://twitter.com/GetLago) for the latest news;
- You can email us as well: hello@getlago.com.

## üßë‚Äçüíª Contributions and development environment

You can follow this [guide](./docs/dev_environment.md) to set up a Lago development environment on your machine. This guide is intended for people willing to contribute to Lago. If you want to try Lago on your local system, we recommend that you take a look at Lago&#039;s public documentation.

You can contribute by following our [guidelines](https://github.com/getlago/lago/blob/main/CONTRIBUTING.md).

## üí° Philosophy
B2B SaaS has evolved, but billing has not yet.

### 1- We‚Äôre not in the ‚Äúsubscription economy‚Äù anymore. And we won‚Äôt go ‚Äúfull usage-based pricing‚Äù quite yet
Pricings are now mostly hybrid: they include a usage-based component (i.e. ‚Äúif you use more you pay more‚Äù) and a subscription component (i.e. a recurring fee for basic usage).

Not all software companies will go full ‚Äúusage-based‚Äù like Snowflake for instance. This model is the new standard for cloud infrastructure products. However, in other areas of SaaS, users want to know beforehand how much they will pay to control their spending and software companies want to be able to predict recurring revenues.

### 2- Go-to-market is not either bottom-up or top-down anymore
SaaS used to be either self-service (SMBs) or sales-led (Enterprises).
Go-to-market now mixes the self-service (all customers access the same price plans) and sales-led (customers get a custom quote from a sales representative) motions.
A typical journey involves an individual contributor in a company who tests a new tool, puts their corporate credit card in, and starts spreading the use of the tool within the organization. At that point, the VP or head of department might want to upgrade to a custom plan tailored to the needs of the whole organization.
As a result, billing needs to be flexible, automated, and transparent enough to embrace this hybrid go-to-market motion as well.

### 3- The ‚Äúrent seeker‚Äù pricing of current billing solutions needs to stop
Why do payment companies take a cut on revenues?
Because the higher the amount, the higher the risk for them (e.g. fraud, disputes, etc.).

Why did billing companies adopt the same pricing structure? We‚Äôre not able to provide an answer that makes sense. It‚Äôs been said on the internet that they did this because they could (read more [here](https://news.ycombinator.com/item?id=16766846)).

### One last thing‚Ä¶
Lago is agnostic and we aim at being as transparent as possible, so we won‚Äôt nudge or lock you into using a specific tool in exchange for using our billing API ([learn more](https://www.gmass.co/blog/negotiating-stripe-fees/)).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[moby/moby]]></title>
            <link>https://github.com/moby/moby</link>
            <guid>https://github.com/moby/moby</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:04 GMT</pubDate>
            <description><![CDATA[The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/moby/moby">moby/moby</a></h1>
            <p>The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems</p>
            <p>Language: Go</p>
            <p>Stars: 71,368</p>
            <p>Forks: 18,882</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>The Moby Project
================

[![PkgGoDev](https://pkg.go.dev/badge/github.com/moby/moby/v2)](https://pkg.go.dev/github.com/moby/moby/v2)
![GitHub License](https://img.shields.io/github/license/moby/moby)
[![Go Report Card](https://goreportcard.com/badge/github.com/moby/moby/v2)](https://goreportcard.com/report/github.com/moby/moby/v2)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/moby/moby/badge)](https://scorecard.dev/viewer/?uri=github.com/moby/moby)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10989/badge)](https://www.bestpractices.dev/projects/10989)


![Moby Project logo](docs/static_files/moby-project-logo.png &quot;The Moby Project&quot;)

Moby is an open-source project created by Docker to enable and accelerate software containerization.

It provides a &quot;Lego set&quot; of toolkit components, the framework for assembling them into custom container-based systems, and a place for all container enthusiasts and professionals to experiment and exchange ideas.
Components include container build tools, a container registry, orchestration tools, a runtime and more, and these can be used as building blocks in conjunction with other tools and projects.

## Principles

Moby is an open project guided by strong principles, aiming to be modular, flexible and without too strong an opinion on user experience.
It is open to the community to help set its direction.

- Modular: the project includes lots of components that have well-defined functions and APIs that work together.
- Batteries included but swappable: Moby includes enough components to build fully featured container systems, but its modular architecture ensures that most of the components can be swapped by different implementations.
- Usable security: Moby provides secure defaults without compromising usability.
- Developer focused: The APIs are intended to be functional and useful to build powerful tools.
They are not necessarily intended as end user tools but as components aimed at developers.
Documentation and UX is aimed at developers not end users.

## Audience

The Moby Project is intended for engineers, integrators and enthusiasts looking to modify, hack, fix, experiment, invent and build systems based on containers.
It is not for people looking for a commercially supported system, but for people who want to work and learn with open source code.

## Relationship with Docker

The components and tools in the Moby Project are initially the open source components that Docker and the community have built for the Docker Project.
New projects can be added if they fit with the community goals. Docker is committed to using Moby as the upstream for the Docker Product.
However, other projects are also encouraged to use Moby as an upstream, and to reuse the components in diverse ways, and all these uses will be treated in the same way. External maintainers and contributors are welcomed.

The Moby project is not intended as a location for support or feature requests for Docker products, but as a place for contributors to work on open source code, fix bugs, and make the code more useful.
The releases are supported by the maintainers, community and users, on a best efforts basis only. For customers who want enterprise or commercial support, [Docker Desktop](https://www.docker.com/products/docker-desktop/) and [Mirantis Container Runtime](https://www.mirantis.com/software/mirantis-container-runtime/) are the appropriate products for these use cases.

-----

Legal
=====

*Brought to you courtesy of our legal counsel. For more context,
please see the [NOTICE](https://github.com/moby/moby/blob/master/NOTICE) document in this repo.*

Use and transfer of Moby may be subject to certain restrictions by the
United States and other governments.

It is your responsibility to ensure that your use and/or transfer does not
violate applicable laws.

For more information, please see https://www.bis.doc.gov

Licensing
=========
Moby is licensed under the Apache License, Version 2.0. See
[LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full
license text.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grafana/loki]]></title>
            <link>https://github.com/grafana/loki</link>
            <guid>https://github.com/grafana/loki</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:03 GMT</pubDate>
            <description><![CDATA[Like Prometheus, but for logs.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grafana/loki">grafana/loki</a></h1>
            <p>Like Prometheus, but for logs.</p>
            <p>Language: Go</p>
            <p>Stars: 27,395</p>
            <p>Forks: 3,895</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/sources/logo_and_name.png&quot; alt=&quot;Loki Logo&quot;&gt;&lt;/p&gt;

&lt;a href=&quot;https://github.com/grafana/loki/actions/workflows/check.yml&quot;&gt;&lt;img src=&quot;https://github.com/grafana/loki/actions/workflows/check.yml/badge.svg&quot; alt=&quot;Check&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://goreportcard.com/report/github.com/grafana/loki&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/grafana/loki&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://slack.grafana.com/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/join%20slack-%23loki-brightgreen.svg&quot; alt=&quot;Slack&quot; /&gt;&lt;/a&gt;
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/loki.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:loki)

# Loki: like Prometheus, but for logs.

Loki is a horizontally-scalable, highly-available, multi-tenant log aggregation system inspired by [Prometheus](https://prometheus.io/).
It is designed to be very cost effective and easy to operate.
It does not index the contents of the logs, but rather a set of labels for each log stream.

Compared to other log aggregation systems, Loki:

- does not do full text indexing on logs. By storing compressed, unstructured logs and only indexing metadata, Loki is simpler to operate and cheaper to run.
- indexes and groups log streams using the same labels you‚Äôre already using with Prometheus, enabling you to seamlessly switch between metrics and logs using the same labels that you‚Äôre already using with Prometheus.
- is an especially good fit for storing [Kubernetes](https://kubernetes.io/) Pod logs. Metadata such as Pod labels is automatically scraped and indexed.
- has native support in Grafana (needs Grafana v6.0).

A Loki-based logging stack consists of 3 components:

- [Alloy](https://github.com/grafana/alloy) is agent, responsible for gathering logs and sending them to Loki.
- [Loki](https://github.com/grafana/loki) is the main service, responsible for storing logs and processing queries.
- [Grafana](https://github.com/grafana/grafana) for querying and displaying the logs.

**Note that Alloy replaced Promtail in the stack, because Promtail is considered to be feature complete, and future development for logs collection will be in [Grafana Alloy](https://github.com/grafana/alloy).**

Loki is like Prometheus, but for logs: we prefer a multidimensional label-based approach to indexing, and want a single-binary, easy to operate system with no dependencies.
Loki differs from Prometheus by focusing on logs instead of metrics, and delivering logs via push, instead of pull.

## Getting started

* [Installing Loki](https://grafana.com/docs/loki/latest/installation/)
* [Installing Alloy](https://grafana.com/docs/loki/latest/send-data/alloy/)
* [Getting Started](https://grafana.com/docs/loki/latest/get-started/)

## Upgrading

* [Upgrading Loki](https://grafana.com/docs/loki/latest/upgrading/)

## Documentation

* [Latest release](https://grafana.com/docs/loki/latest/)
* [Upcoming release](https://grafana.com/docs/loki/next/), at the tip of the main branch

Commonly used sections:

- [API documentation](https://grafana.com/docs/loki/latest/api/) for getting logs into Loki.
- [Labels](https://grafana.com/docs/loki/latest/getting-started/labels/)
- [Operations](https://grafana.com/docs/loki/latest/operations/)
- [Promtail](https://grafana.com/docs/loki/latest/clients/promtail/) is an agent which tails log files and pushes them to Loki.
- [Pipelines](https://grafana.com/docs/loki/latest/clients/promtail/pipelines/) details the log processing pipeline.
- [Docker Driver Client](https://grafana.com/docs/loki/latest/clients/docker-driver/) is a Docker plugin to send logs directly to Loki from Docker containers.
- [LogCLI](https://grafana.com/docs/loki/latest/query/logcli/) provides a command-line interface for querying logs.
- [Loki Canary](https://grafana.com/docs/loki/latest/operations/loki-canary/) monitors your Loki installation for missing logs.
- [Troubleshooting](https://grafana.com/docs/loki/latest/operations/troubleshooting/) presents help dealing with error messages.
- [Loki in Grafana](https://grafana.com/docs/loki/latest/operations/grafana/) describes how to set up a Loki datasource in Grafana.

## Getting Help

If you have any questions or feedback regarding Loki:

- Search existing thread in the Grafana Labs community forum for Loki: [https://community.grafana.com](https://community.grafana.com/c/grafana-loki/)
- Ask a question on the Loki Slack channel. To invite yourself to the Grafana Slack, visit [https://slack.grafana.com/](https://slack.grafana.com/) and join the #loki channel.
- [File an issue](https://github.com/grafana/loki/issues/new) for bugs, issues and feature suggestions.
- Send an email to [lokiproject@googlegroups.com](mailto:lokiproject@googlegroups.com), or use the [web interface](https://groups.google.com/forum/#!forum/lokiproject).
- UI issues should be filed directly in [Grafana](https://github.com/grafana/grafana/issues/new).

Your feedback is always welcome.

## Further Reading

- The original [design doc](https://docs.google.com/document/d/11tjK_lvp1-SVsFZjgOTr1vV3-q6vBAsZYIQ5ZeYBkyM/view) for Loki is a good source for discussion of the motivation and design decisions.
- Callum Styan&#039;s March 2019 DevOpsDays Vancouver talk &quot;[Grafana Loki: Log Aggregation for Incident Investigations][devopsdays19-talk]&quot;.
- Grafana Labs blog post &quot;[How We Designed Loki to Work Easily Both as Microservices and as Monoliths][architecture-blog]&quot;.
- Tom Wilkie&#039;s early-2019 CNCF Paris/FOSDEM talk &quot;[Grafana Loki: like Prometheus, but for logs][fosdem19-talk]&quot; ([slides][fosdem19-slides], [video][fosdem19-video]).
- David Kaltschmidt&#039;s KubeCon 2018 talk &quot;[On the OSS Path to Full Observability with Grafana][kccna18-event]&quot; ([slides][kccna18-slides], [video][kccna18-video]) on how Loki fits into a cloud-native environment.
- Goutham Veeramachaneni&#039;s blog post &quot;[Loki: Prometheus-inspired, open source logging for cloud natives](https://grafana.com/blog/2018/12/12/loki-prometheus-inspired-open-source-logging-for-cloud-natives/)&quot; on details of the Loki architecture.
- David Kaltschmidt&#039;s blog post &quot;[Closer look at Grafana&#039;s user interface for Loki](https://grafana.com/blog/2019/01/02/closer-look-at-grafanas-user-interface-for-loki/)&quot; on the ideas that went into the logging user interface.

[devopsdays19-talk]: https://grafana.com/blog/2019/05/06/how-loki-correlates-metrics-and-logs-and-saves-you-money/
[architecture-blog]: https://grafana.com/blog/2019/04/15/how-we-designed-loki-to-work-easily-both-as-microservices-and-as-monoliths/
[fosdem19-talk]: https://fosdem.org/2019/schedule/event/loki_prometheus_for_logs/
[fosdem19-slides]: https://speakerdeck.com/grafana/grafana-loki-like-prometheus-but-for-logs
[fosdem19-video]: https://mirror.as35701.net/video.fosdem.org/2019/UB2.252A/loki_prometheus_for_logs.mp4
[kccna18-event]: https://kccna18.sched.com/event/GrXC/on-the-oss-path-to-full-observability-with-grafana-david-kaltschmidt-grafana-labs
[kccna18-slides]: https://speakerdeck.com/davkal/on-the-path-to-full-observability-with-oss-and-launch-of-loki
[kccna18-video]: https://www.youtube.com/watch?v=U7C5SpRtK74&amp;list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU&amp;index=346

## Contributing

Refer to [CONTRIBUTING.md](CONTRIBUTING.md)

### Building from source

Loki can be run in a single host, no-dependencies mode using the following commands.

You need an up-to-date version of [Go](https://go.dev/), we recommend using the version found in our [Makefile](https://github.com/grafana/loki/blob/main/Makefile)

```bash
# Checkout source code
$ git clone https://github.com/grafana/loki
$ cd loki

# Build binary
$ go build ./cmd/loki

# Run executable
$ ./loki -config.file=./cmd/loki/loki-local-config.yaml
```

Alternatively, on Unix systems you can use `make` to build the binary, which adds additional arguments to the `go build` command.

```bash
# Build binary
$ make loki

# Run executable
$ ./cmd/loki/loki -config.file=./cmd/loki/loki-local-config.yaml
```

To build Promtail on non-Linux platforms, use the following command:

```bash
$ go build ./clients/cmd/promtail
```

On Linux, Promtail requires the systemd headers to be installed if
Journal support is enabled.
To enable Journal support the go build tag flag `promtail_journal_enabled` should be passed

With Journal support on Ubuntu, run with the following commands:

```bash
$ sudo apt install -y libsystemd-dev
$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail
```

With Journal support on CentOS, run with the following commands:

```bash
$ sudo yum install -y systemd-devel
$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail
```

Otherwise, to build Promtail without Journal support, run `go build`
with CGO disabled:

```bash
$ CGO_ENABLED=0 go build ./clients/cmd/promtail
```

## Adopters

Please see [ADOPTERS.md](ADOPTERS.md) for some of the organizations using Loki today.
If you would like to add your organization to the list, please open a PR to add it to the list.

## License

Grafana Loki is distributed under [AGPL-3.0-only](LICENSE). For Apache-2.0 exceptions, see [LICENSING.md](LICENSING.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[VictoriaMetrics/VictoriaMetrics]]></title>
            <link>https://github.com/VictoriaMetrics/VictoriaMetrics</link>
            <guid>https://github.com/VictoriaMetrics/VictoriaMetrics</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:02 GMT</pubDate>
            <description><![CDATA[VictoriaMetrics: fast, cost-effective monitoring solution and time series database]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/VictoriaMetrics/VictoriaMetrics">VictoriaMetrics/VictoriaMetrics</a></h1>
            <p>VictoriaMetrics: fast, cost-effective monitoring solution and time series database</p>
            <p>Language: Go</p>
            <p>Stars: 16,041</p>
            <p>Forks: 1,539</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre># VictoriaMetrics

[![Latest Release](https://img.shields.io/github/v/release/VictoriaMetrics/VictoriaMetrics?sort=semver&amp;label=&amp;filter=!*-victorialogs&amp;logo=github&amp;labelColor=gray&amp;color=gray&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Freleases%2Flatest)](https://github.com/VictoriaMetrics/VictoriaMetrics/releases)
![Docker Pulls](https://img.shields.io/docker/pulls/victoriametrics/victoria-metrics?label=&amp;logo=docker&amp;logoColor=white&amp;labelColor=2496ED&amp;color=2496ED&amp;link=https%3A%2F%2Fhub.docker.com%2Fr%2Fvictoriametrics%2Fvictoria-metrics)
[![Go Report](https://goreportcard.com/badge/github.com/VictoriaMetrics/VictoriaMetrics?link=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics)](https://goreportcard.com/report/github.com/VictoriaMetrics/VictoriaMetrics)
[![Build Status](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml/badge.svg?branch=master&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Factions)](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml)
[![codecov](https://codecov.io/gh/VictoriaMetrics/VictoriaMetrics/branch/master/graph/badge.svg?link=https%3A%2F%2Fcodecov.io%2Fgh%2FVictoriaMetrics%2FVictoriaMetrics)](https://app.codecov.io/gh/VictoriaMetrics/VictoriaMetrics)
[![License](https://img.shields.io/github/license/VictoriaMetrics/VictoriaMetrics?labelColor=green&amp;label=&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Fblob%2Fmaster%2FLICENSE)](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/LICENSE)
![Slack](https://img.shields.io/badge/Join-4A154B?logo=slack&amp;link=https%3A%2F%2Fslack.victoriametrics.com)
[![X](https://img.shields.io/twitter/follow/VictoriaMetrics?style=flat&amp;label=Follow&amp;color=black&amp;logo=x&amp;labelColor=black&amp;link=https%3A%2F%2Fx.com%2FVictoriaMetrics)](https://x.com/VictoriaMetrics/)
[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/VictoriaMetrics?style=flat&amp;label=Join&amp;labelColor=red&amp;logoColor=white&amp;logo=reddit&amp;link=https%3A%2F%2Fwww.reddit.com%2Fr%2FVictoriaMetrics)](https://www.reddit.com/r/VictoriaMetrics/)

&lt;picture&gt;
  &lt;source srcset=&quot;docs/victoriametrics/logo_white.webp&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
  &lt;source srcset=&quot;docs/victoriametrics/logo.webp&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
  &lt;img src=&quot;docs/victoriametrics/logo.webp&quot; width=&quot;300&quot; alt=&quot;VictoriaMetrics logo&quot;&gt;
&lt;/picture&gt;

VictoriaMetrics is a fast, cost-saving, and scalable solution for monitoring and managing time series data. It delivers high performance and reliability, making it an ideal choice for businesses of all sizes.

Here are some resources and information about VictoriaMetrics:

- Documentation: [docs.victoriametrics.com](https://docs.victoriametrics.com)
- Case studies: [Grammarly, Roblox, Wix,...](https://docs.victoriametrics.com/victoriametrics/casestudies/).
- Available: [Binary releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest), docker images [Docker Hub](https://hub.docker.com/r/victoriametrics/victoria-metrics/) and [Quay](https://quay.io/repository/victoriametrics/victoria-metrics), [Source code](https://github.com/VictoriaMetrics/VictoriaMetrics)
- Deployment types: [Single-node version](https://docs.victoriametrics.com/), [Cluster version](https://docs.victoriametrics.com/victoriametrics/cluster-victoriametrics/), and [Enterprise version](https://docs.victoriametrics.com/victoriametrics/enterprise/)
- Changelog: [CHANGELOG](https://docs.victoriametrics.com/victoriametrics/changelog/), and [How to upgrade](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-upgrade-victoriametrics)
- Community: [Slack](https://slack.victoriametrics.com/), [X (Twitter)](https://x.com/VictoriaMetrics), [LinkedIn](https://www.linkedin.com/company/victoriametrics/), [YouTube](https://www.youtube.com/@VictoriaMetrics)

Yes, we open-source both the single-node VictoriaMetrics and the cluster version.

## Prominent features

VictoriaMetrics is optimized for timeseries data, even when old time series are constantly replaced by new ones at a high rate, it offers a lot of features:

* **Long-term storage for Prometheus** or as a drop-in replacement for Prometheus and Graphite in Grafana.
* **Powerful stream aggregation**: Can be used as a StatsD alternative.
* **Ideal for big data**: Works well with large amounts of time series data from APM, Kubernetes, IoT sensors, connected cars, industrial telemetry, financial data and various [Enterprise workloads](https://docs.victoriametrics.com/victoriametrics/enterprise/).
* **Query language**: Supports both PromQL and the more performant MetricsQL.
* **Easy to setup**: No dependencies, single [small binary](https://medium.com/@valyala/stripping-dependency-bloat-in-victoriametrics-docker-image-983fb5912b0d), configuration through command-line flags, but the default is also fine-tuned; backup and restore with [instant snapshots](https://medium.com/@valyala/how-victoriametrics-makes-instant-snapshots-for-multi-terabyte-time-series-data-e1f3fb0e0282).
* **Global query view**: Multiple Prometheus instances or any other data sources may ingest data into VictoriaMetrics and queried via a single query.
* **Various Protocols**: Support metric scraping, ingestion and backfilling in various protocol.
    * [Prometheus exporters](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-scrape-prometheus-exporters-such-as-node-exporter), [Prometheus remote write API](https://docs.victoriametrics.com/victoriametrics/integrations/prometheus/), [Prometheus exposition format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-prometheus-exposition-format).
    * [InfluxDB line protocol](https://docs.victoriametrics.com/victoriametrics/integrations/influxdb/) over HTTP, TCP and UDP.
    * [Graphite plaintext protocol](https://docs.victoriametrics.com/victoriametrics/integrations/graphite/#ingesting) with [tags](https://graphite.readthedocs.io/en/latest/tags.html#carbon).
    * [OpenTSDB put message](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-telnet).
    * [HTTP OpenTSDB /api/put requests](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-http).
    * [JSON line format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-json-line-format).
    * [Arbitrary CSV data](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-csv-data).
    * [Native binary format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-native-format).
    * [DataDog agent or DogStatsD](https://docs.victoriametrics.com/victoriametrics/integrations/datadog/).
    * [NewRelic infrastructure agent](https://docs.victoriametrics.com/victoriametrics/integrations/newrelic/#sending-data-from-agent).
    * [OpenTelemetry metrics format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#sending-data-via-opentelemetry).
* **NFS-based storages**: Supports storing data on NFS-based storages such as Amazon EFS, Google Filestore.
* And many other features such as metrics relabeling, cardinality limiter, etc.

## Enterprise version

In addition, the Enterprise version includes extra features:

- **Anomaly detection**: Automation and simplification of your alerting rules, covering complex anomalies found in metrics data.
- **Backup automation**: Automates regular backup procedures.
- **Multiple retentions**: Reducing storage costs by specifying different retentions for different datasets.
- **Downsampling**: Reducing storage costs and increasing performance for queries over historical data.
- **Stable releases** with long-term support lines ([LTS](https://docs.victoriametrics.com/victoriametrics/lts-releases/)).
- **Comprehensive support**: First-class consulting, feature requests and technical support provided by the core VictoriaMetrics dev team.
- Many other features, which you can read about on [the Enterprise page](https://docs.victoriametrics.com/victoriametrics/enterprise/).

[Contact us](mailto:info@victoriametrics.com) if you need enterprise support for VictoriaMetrics. Or you can request a free trial license [here](https://victoriametrics.com/products/enterprise/trial/), downloaded Enterprise binaries are available at [Github Releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest).

We strictly apply security measures in everything we do. VictoriaMetrics has achieved security certifications for Database Software Development and Software-Based Monitoring Services. See [Security page](https://victoriametrics.com/security/) for more details.

## Benchmarks 

Some good benchmarks VictoriaMetrics achieved:

* **Minimal memory footprint**: handling millions of unique timeseries with [10x less RAM](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) than InfluxDB, up to [7x less RAM](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) than Prometheus, Thanos or Cortex.
* **Highly scalable and performance** for [data ingestion](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and [querying](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4), [20x outperforms](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) InfluxDB and TimescaleDB.
* **High data compression**: [70x more data points](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4) may be stored into limited storage than TimescaleDB, [7x less storage](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) space is required than Prometheus, Thanos or Cortex.
* **Reducing storage costs**: [10x more effective](https://docs.victoriametrics.com/victoriametrics/casestudies/#grammarly) than Graphite according to the Grammarly case study.
* **A single-node VictoriaMetrics** can replace medium-sized clusters built with competing solutions such as Thanos, M3DB, Cortex, InfluxDB or TimescaleDB. See [VictoriaMetrics vs Thanos](https://medium.com/@valyala/comparing-thanos-to-victoriametrics-cluster-b193bea1683), [Measuring vertical scalability](https://medium.com/@valyala/measuring-vertical-scalability-for-time-series-databases-in-google-cloud-92550d78d8ae), [Remote write storage wars - PromCon 2019](https://promcon.io/2019-munich/talks/remote-write-storage-wars/).
* **Optimized for storage**: [Works well with high-latency IO](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and low IOPS (HDD and network storage in AWS, Google Cloud, Microsoft Azure, etc.).

## Community and contributions

Feel free asking any questions regarding VictoriaMetrics:

* [Slack Inviter](https://slack.victoriametrics.com/) and [Slack channel](https://victoriametrics.slack.com/)
* [X (Twitter)](https://x.com/VictoriaMetrics/)
* [Linkedin](https://www.linkedin.com/company/victoriametrics/)
* [Reddit](https://www.reddit.com/r/VictoriaMetrics/)
* [Telegram-en](https://t.me/VictoriaMetrics_en)
* [Telegram-ru](https://t.me/VictoriaMetrics_ru1)
* [Mastodon](https://mastodon.social/@victoriametrics/)

If you like VictoriaMetrics and want to contribute, then please [read these docs](https://docs.victoriametrics.com/victoriametrics/contributing/).

## VictoriaMetrics Logo

The provided [ZIP file](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/VM_logo.zip) contains three folders with different logo orientations. Each folder includes the following file types:

* JPEG: Preview files
* PNG: Preview files with transparent background
* AI: Adobe Illustrator files

### VictoriaMetrics Logo Usage Guidelines

#### Font

* Font Used: Lato Black
* Download here: [Lato Font](https://fonts.google.com/specimen/Lato)

#### Color Palette

* Black [#000000](https://www.color-hex.com/color/000000)
* Purple [#4d0e82](https://www.color-hex.com/color/4d0e82)
* Orange [#ff2e00](https://www.color-hex.com/color/ff2e00)
* White [#ffffff](https://www.color-hex.com/color/ffffff)

### Logo Usage Rules

* Only use the Lato Black font as specified.
* Maintain sufficient clear space around the logo for visibility.
* Do not modify the spacing, alignment, or positioning of design elements.
* You may resize the logo as needed, but ensure all proportions remain intact.

Thank you for your cooperation!
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[VictoriaMetrics/VictoriaLogs]]></title>
            <link>https://github.com/VictoriaMetrics/VictoriaLogs</link>
            <guid>https://github.com/VictoriaMetrics/VictoriaLogs</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:01 GMT</pubDate>
            <description><![CDATA[Fast and easy to use database for logs, which can efficiently handle terabytes of logs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/VictoriaMetrics/VictoriaLogs">VictoriaMetrics/VictoriaLogs</a></h1>
            <p>Fast and easy to use database for logs, which can efficiently handle terabytes of logs</p>
            <p>Language: Go</p>
            <p>Stars: 1,322</p>
            <p>Forks: 81</p>
            <p>Stars today: 29 stars today</p>
            <h2>README</h2><pre># VictoriaLogs

[![Latest Release](https://img.shields.io/github/v/release/VictoriaMetrics/VictoriaLogs?sort=semver&amp;label=&amp;logo=github&amp;labelColor=gray&amp;color=gray&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaLogs%2Freleases%2Flatest)](https://github.com/VictoriaMetrics/VictoriaLogs/releases)
![Docker Pulls](https://img.shields.io/docker/pulls/victoriametrics/victoria-logs?label=&amp;logo=docker&amp;logoColor=white&amp;labelColor=2496ED&amp;color=2496ED&amp;link=https%3A%2F%2Fhub.docker.com%2Fr%2Fvictoriametrics%2Fvictoria-logs)
[![Go Report](https://goreportcard.com/badge/github.com/VictoriaMetrics/VictoriaLogs?link=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2FVictoriaMetrics%2FVictoriaLogs)](https://goreportcard.com/report/github.com/VictoriaMetrics/VictoriaLogs)
[![Build Status](https://github.com/VictoriaMetrics/VictoriaLogs/actions/workflows/main.yml/badge.svg?branch=master&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaLogs%2Factions)](https://github.com/VictoriaMetrics/VictoriaLogs/actions/workflows/main.yml)
[![codecov](https://codecov.io/gh/VictoriaMetrics/VictoriaLogs/branch/master/graph/badge.svg?link=https%3A%2F%2Fcodecov.io%2Fgh%2FVictoriaMetrics%2FVictoriaLogs)](https://app.codecov.io/gh/VictoriaMetrics/VictoriaLogs)
[![License](https://img.shields.io/github/license/VictoriaMetrics/VictoriaLogs?labelColor=green&amp;label=&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaLogs%2Fblob%2Fmaster%2FLICENSE)](https://github.com/VictoriaMetrics/VictoriaLogs/blob/master/LICENSE)
![Slack](https://img.shields.io/badge/Join-4A154B?logo=slack&amp;link=https%3A%2F%2Fslack.victoriametrics.com)
[![X](https://img.shields.io/twitter/follow/VictoriaMetrics?style=flat&amp;label=Follow&amp;color=black&amp;logo=x&amp;labelColor=black&amp;link=https%3A%2F%2Fx.com%2FVictoriaMetrics)](https://x.com/VictoriaMetrics/)
[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/VictoriaMetrics?style=flat&amp;label=Join&amp;labelColor=red&amp;logoColor=white&amp;logo=reddit&amp;link=https%3A%2F%2Fwww.reddit.com%2Fr%2FVictoriaMetrics)](https://www.reddit.com/r/VictoriaMetrics/)

VictoriaLogs is a fast easy to use database for logs.

Here are some resources and information about VictoriaLogs:

- Playgrounds: [playground for the built-in web UI](https://play-vmlogs.victoriametrics.com/), [playground for Grafana plugin for VictoriaLogs](https://play-grafana.victoriametrics.com/d/be5zidev72m80f/k8s-logs-via-victorialogs)
- [Documentation](https://docs.victoriametrics.com/victorialogs/)
- Available: [Binary releases](https://github.com/VictoriaMetrics/VictoriaLogs/releases/latest), docker images [Docker Hub](https://hub.docker.com/r/victoriametrics/victoria-logs/) and [Quay](https://quay.io/repository/victoriametrics/victoria-logs), [Source code](https://github.com/VictoriaMetrics/VictoriaLogs)
- Deployment types: [Single-node version](https://docs.victoriametrics.com/victorialogs/), [Cluster version](https://docs.victoriametrics.com/victorialogs/cluster/)
- Changelog: [CHANGELOG](https://docs.victoriametrics.com/victorialogs/changelog/), and [How to upgrade](https://docs.victoriametrics.com/victorialogs/#upgrading)
- Community: [Slack](https://slack.victoriametrics.com/), [X (Twitter)](https://x.com/VictoriaMetrics), [LinkedIn](https://www.linkedin.com/company/victoriametrics/), [YouTube](https://www.youtube.com/@VictoriaMetrics)

Both the single-node and the cluster versions of VictoriaLogs are open source and free to use.

## Community and contributions

Feel free asking any questions regarding VictoriaLogs:

* [Slack Inviter](https://slack.victoriametrics.com/) and [Slack channel](https://victoriametrics.slack.com/)
* [X (Twitter)](https://x.com/VictoriaMetrics/)
* [Linkedin](https://www.linkedin.com/company/victoriametrics/)
* [Reddit](https://www.reddit.com/r/VictoriaMetrics/)
* [Telegram-en](https://t.me/VictoriaMetrics_en)
* [Telegram-ru](https://t.me/VictoriaLogs_ru)
* [Mastodon](https://mastodon.social/@victoriametrics/)

If you like VictoriaLogs and want to contribute, then please [read these docs](https://docs.victoriametrics.com/victoriametrics/contributing/).

Thank you for your cooperation!
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kserve/kserve]]></title>
            <link>https://github.com/kserve/kserve</link>
            <guid>https://github.com/kserve/kserve</guid>
            <pubDate>Sat, 17 Jan 2026 00:05:00 GMT</pubDate>
            <description><![CDATA[Standardized Distributed Generative and Predictive AI Inference Platform for Scalable, Multi-Framework Deployment on Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kserve/kserve">kserve/kserve</a></h1>
            <p>Standardized Distributed Generative and Predictive AI Inference Platform for Scalable, Multi-Framework Deployment on Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 5,007</p>
            <p>Forks: 1,343</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># KServe
[![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;logoColor=white)](https://pkg.go.dev/github.com/kserve/kserve)
[![Coverage Status](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/andyi2it/5174bd748ac63a6e4803afea902e9810/raw/coverage.json)](https://github.com/kserve/kserve/actions/workflows/go.yml)
[![Go Report Card](https://goreportcard.com/badge/github.com/kserve/kserve)](https://goreportcard.com/report/github.com/kserve/kserve)
[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/6643/badge)](https://bestpractices.coreinfrastructure.org/projects/6643)
[![Releases](https://img.shields.io/github/release-pre/kserve/kserve.svg?sort=semver)](https://github.com/kserve/kserve/releases)
[![LICENSE](https://img.shields.io/github/license/kserve/kserve.svg)](https://github.com/kserve/kserve/blob/master/LICENSE)
[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&amp;style=social)](https://github.com/kserve/community/blob/main/README.md#questions-and-issues)
[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20KServe%20Guru-006BFF)](https://gurubase.io/g/kserve)

KServe is a standardized distributed generative and predictive AI inference platform for scalable, multi-framework deployment on Kubernetes.

KServe is being [used by many organizations](https://kserve.github.io/website/docs/community/adopters) and is a [Cloud Native Computing Foundation (CNCF)](https://www.cncf.io/) incubating project.

For more details, visit the [KServe website](https://kserve.github.io/website/).

![KServe](/docs/diagrams/kserve_new.png)

### Why KServe?

Single platform that unifies Generative and Predictive AI inference on Kubernetes. Simple enough for quick deployments, yet powerful enough to handle enterprise-scale AI workloads with advanced features.

### Features

**Generative AI**
  * üß† **LLM-Optimized**: OpenAI-compatible inference protocol for seamless integration with large language models
  * üöÖ **GPU Acceleration**: High-performance serving with GPU support and optimized memory management for large models
  * üíæ **Model Caching**: Intelligent model caching to reduce loading times and improve response latency for frequently used models
  * üóÇÔ∏è **KV Cache Offloading**: Advanced memory management with KV cache offloading to CPU/disk for handling longer sequences efficiently
  * üìà **Autoscaling**: Request-based autoscaling capabilities optimized for generative workload patterns
  * üîß **Hugging Face Ready**: Native support for Hugging Face models with streamlined deployment workflows

**Predictive AI**
  * üßÆ **Multi-Framework**: Support for TensorFlow, PyTorch, scikit-learn, XGBoost, ONNX, and more
  * üîÄ **Intelligent Routing**: Seamless request routing between predictor, transformer, and explainer components with automatic traffic management
  * üîÑ **Advanced Deployments**: Canary rollouts, inference pipelines, and ensembles with InferenceGraph
  * ‚ö° **Autoscaling**: Request-based autoscaling with scale-to-zero for predictive workloads
  * üîç **Model Explainability**: Built-in support for model explanations and feature attribution to understand prediction reasoning
  * üìä **Advanced Monitoring**: Enables payload logging, outlier detection, adversarial detection, and drift detection
  * üí∞ **Cost Efficient**: Scale-to-zero on expensive resources when not in use, reducing infrastructure costs

### Learn More
To learn more about KServe, how to use various supported features, and how to participate in the KServe community, 
please follow the [KServe website documentation](https://kserve.github.io/website). 
Additionally, we have compiled a list of [presentations and demos](https://kserve.github.io/website/docs/community/presentations) to dive through various details.

### :hammer_and_wrench: Installation

#### Standalone Installation
- **[Standard Kubernetes Installation](https://kserve.github.io/website/docs/admin-guide/overview#raw-kubernetes-deployment)**: Compared to Serverless Installation, this is a more **lightweight** installation. However, this option does not support canary deployment and request based autoscaling with scale-to-zero.
- **[Knative Installation](https://kserve.github.io/website/docs/admin-guide/overview#serverless-deployment)**: KServe by default installs Knative for **serverless deployment** for InferenceService.
- **[ModelMesh Installation](https://kserve.github.io/website/docs/admin-guide/overview#modelmesh-deployment)**: You can optionally install ModelMesh to enable **high-scale**, **high-density** and **frequently-changing model serving** use cases. 
- **[Quick Installation](https://kserve.github.io/website/docs/getting-started/quickstart-guide)**: Install KServe on your local machine.

#### Kubeflow Installation
KServe is an important addon component of Kubeflow, please learn more from the [Kubeflow KServe documentation](https://www.kubeflow.org/docs/external-add-ons/kserve/kserve). Check out the following guides for running [on AWS](https://awslabs.github.io/kubeflow-manifests/main/docs/component-guides/kserve) or [on OpenShift Container Platform](https://github.com/kserve/kserve/blob/master/docs/OPENSHIFT_GUIDE.md).

### :flight_departure: [Create your first InferenceService](https://kserve.github.io/website/docs/getting-started/genai-first-isvc)

### :bulb: [Roadmap](./ROADMAP.md)

### :blue_book: [InferenceService API Reference](https://kserve.github.io/website/docs/reference/crd-api)

### :toolbox: [Developer Guide](https://kserve.github.io/website/docs/developer-guide)

### :writing_hand: [Contributor Guide](https://kserve.github.io/website/docs/developer-guide/contribution)

### :handshake: [Adopters](https://kserve.github.io/website/docs/community/adopters)

### Star History

[![Star History Chart](https://api.star-history.com/svg?repos=kserve/kserve&amp;type=Date)](https://www.star-history.com/#kserve/kserve&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>