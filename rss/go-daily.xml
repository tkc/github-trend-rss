<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Thu, 18 Dec 2025 00:05:10 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[v2fly/domain-list-community]]></title>
            <link>https://github.com/v2fly/domain-list-community</link>
            <guid>https://github.com/v2fly/domain-list-community</guid>
            <pubDate>Thu, 18 Dec 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[Community managed domain list. Generate geosite.dat for V2Ray.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/v2fly/domain-list-community">v2fly/domain-list-community</a></h1>
            <p>Community managed domain list. Generate geosite.dat for V2Ray.</p>
            <p>Language: Go</p>
            <p>Stars: 6,974</p>
            <p>Forks: 1,151</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># Domain list community

This project manages a list of domains, to be used as geosites for routing purpose in Project V.

## Purpose of this project

This project is not opinionated. In other words, it does NOT endorse, claim or imply that a domain should be blocked or proxied. It can be used to generate routing rules on demand.

## Download links

- **dlc.dat**Ôºö[https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat](https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat)
- **dlc.dat.sha256sum**Ôºö[https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum](https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum)

## Usage example

Each file in the `data` directory can be used as a rule in this format: `geosite:filename`.

```json
&quot;routing&quot;: {
  &quot;domainStrategy&quot;: &quot;IPIfNonMatch&quot;,
  &quot;rules&quot;: [
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Reject&quot;,
      &quot;domain&quot;: [
        &quot;geosite:category-ads-all&quot;,
        &quot;geosite:category-porn&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Direct&quot;,
      &quot;domain&quot;: [
        &quot;domain:icloud.com&quot;,
        &quot;domain:icloud-content.com&quot;,
        &quot;domain:cdn-apple.com&quot;,
        &quot;geosite:cn&quot;,
        &quot;geosite:private&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Proxy-1&quot;,
      &quot;domain&quot;: [
        &quot;geosite:category-anticensorship&quot;,
        &quot;geosite:category-media&quot;,
        &quot;geosite:category-vpnservices&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Proxy-2&quot;,
      &quot;domain&quot;: [
        &quot;geosite:category-dev&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Proxy-3&quot;,
      &quot;domain&quot;: [
        &quot;geosite:geolocation-!cn&quot;
      ]
    }
  ]
}
```

## Generate `dlc.dat` manually

- Install `golang` and `git`
- Clone project code: `git clone https://github.com/v2fly/domain-list-community.git`
- Navigate to project root directory: `cd domain-list-community`
- Install project dependencies: `go mod download`
- Generate `dlc.dat` (without `datapath` option means to use domain lists in `data` directory of current working directory):
  - `go run ./`
  - `go run ./ --datapath=/path/to/your/custom/data/directory`

Run `go run ./ --help` for more usage information.

## Structure of data

All data are under `data` directory. Each file in the directory represents a sub-list of domains, named by the file name. File content is in the following format.

```
# comments
include:another-file
domain:google.com @attr1 @attr2
keyword:google
regexp:www\.google\.com$
full:www.google.com
```

**Syntax:**

&gt; The following types of rules are **NOT** fully compatible with the ones that defined by user in V2Ray config file. Do **Not** copy and paste directly.

- Comment begins with `#`. It may begin anywhere in the file. The content in the line after `#` is treated as comment and ignored in production.
- Inclusion begins with `include:`, followed by the file name of an existing file in the same directory.
- Subdomain begins with `domain:`, followed by a valid domain name. The prefix `domain:` may be omitted.
- Keyword begins with `keyword:`, followed by a string.
- Regular expression begins with `regexp:`, followed by a valid regular expression (per Golang&#039;s standard).
- Full domain begins with `full:`, followed by a complete and valid domain name.
- Domains (including `domain`, `keyword`, `regexp` and `full`) may have one or more attributes. Each attribute begins with `@` and followed by the name of the attribute.

&gt; **Note:** Adding new `regexp` and `keyword` rules is discouraged because it is easy to use them incorrectly, and proxy software cannot efficiently match these types of rules.

## How it works

The entire `data` directory will be built into an external `geosite` file for Project V. Each file in the directory represents a section in the generated file.

To generate a section:

1. Remove all the comments in the file.
2. Replace `include:` lines with the actual content of the file.
3. Omit all empty lines.
4. Generate each `domain:` line into a [sub-domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/routercommon/common.proto#L21).
5. Generate each `full:` line into a [full domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/routercommon/common.proto#L23).
6. Generate each `keyword:` line into a [plain domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/routercommon/common.proto#L17).
7. Generate each `regexp:` line into a [regex domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/routercommon/common.proto#L19).

## How to organize domains

### File name

Theoretically any string can be used as the name, as long as it is a valid file name. In practice, we prefer names for determinic group of domains, such as the owner (usually a company name) of the domains, e.g., &quot;google&quot;, &quot;netflix&quot;. Names with unclear scope are generally unrecommended, such as &quot;evil&quot;, or &quot;local&quot;.

### Attributes

Attribute is useful for sub-group of domains, especially for filtering purpose. For example, the list of `google` domains may contains its main domains, as well as domains that serve ads. The ads domains may be marked by attribute `@ads`, and can be used as `geosite:google@ads` in V2Ray routing.

## Contribution guideline

- Fork this repo, make modifications to your own repo, file a PR.
- Please begin with small size PRs, say modification in a single file.
- A PR must be reviewed and approved by another member.
- A script will verify your pull request to test whether your PR is correct or not every time you update the PR. Only the PR which passes the test will be merged. Please go to the Action label to get detailed information if you didn&#039;t pass it. We also provide the file which has been generated to make you test.
- After a few successful PRs, you may apply for manager access to this repository.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[vllm-project/semantic-router]]></title>
            <link>https://github.com/vllm-project/semantic-router</link>
            <guid>https://github.com/vllm-project/semantic-router</guid>
            <pubDate>Thu, 18 Dec 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[Intelligent Router for Mixture-of-Models]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vllm-project/semantic-router">vllm-project/semantic-router</a></h1>
            <p>Intelligent Router for Mixture-of-Models</p>
            <p>Language: Go</p>
            <p>Stars: 2,459</p>
            <p>Forks: 322</p>
            <p>Stars today: 31 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;website/static/img/code.png&quot; alt=&quot;vLLM Semantic Router&quot; width=&quot;100%&quot;/&gt;

[![Documentation](https://img.shields.io/badge/docs-read%20the%20docs-blue)](https://vllm-semantic-router.com)
[![Hugging Face](https://img.shields.io/badge/ü§ó%20Hugging%20Face-Community-yellow)](https://huggingface.co/LLM-Semantic-Router)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![Crates.io](https://img.shields.io/crates/v/candle-semantic-router.svg)](https://crates.io/crates/candle-semantic-router)
![Test And Build](https://github.com/vllm-project/semantic-router/workflows/Test%20And%20Build/badge.svg)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/vllm-project/semantic-router)

**üìö [Complete Documentation](https://vllm-semantic-router.com) | üöÄ [Quick Start](https://vllm-semantic-router.com/docs/installation) | üì£ [Blog](https://vllm-semantic-router.com/blog/) | üìñ [Publications](https://vllm-semantic-router.com/publications/)**

&lt;/div&gt;

---

*Latest News* üî•

- [2025/12/15] New Blog: [Token-Level Truth: Real-Time Hallucination Detection for Production LLMs](https://blog.vllm.ai/2025/12/14/halugate.html) üö™
- [2025/11/19] New Blog: [Signal-Decision Driven Architecture: Reshaping Semantic Routing at Scale](https://blog.vllm.ai/2025/11/19/signal-decision.html) üß†
- [2025/11/03] **Our paper** [Category-Aware Semantic Caching for Heterogeneous LLM Workloads](https://arxiv.org/abs/2510.26835) published üìù
- [2025/10/21] We announced the [2025 Q4 Roadmap: Journey to Iris](https://vllm-semantic-router.com/blog/q4-roadmap-iris) üìÖ.
- [2025/10/12] **Our paper** [When to Reason: Semantic Router for vLLM](https://arxiv.org/abs/2510.08731) accepted by NeurIPS 2025 MLForSys üß†.
- [2025/10/08] We announced the integration with [vLLM Production Stack](https://github.com/vllm-project/production-stack) Team üëã.
- [2025/10/01] We supported to deploy on [Kubernetes](https://vllm-semantic-router.com/docs/installation/k8s/ai-gateway) üåä.
- [2025/09/01] We released the project officially: [vLLM Semantic Router: Next Phase in LLM inference](https://blog.vllm.ai/2025/09/11/semantic-router.html) üöÄ.

---

## Innovations ‚ú®

![architecture](./website/static/img/architecture.png)

### Intelligent Routing üß†

#### Auto-Selection of Models and LoRA Adapters

A **Mixture-of-Models** (MoM) router that intelligently directs OpenAI API requests to the most suitable models or LoRA adapters from a defined pool based on **Semantic Understanding** of the request&#039;s intent (Complexity, Task, Tools).

![mom-overview](./website/static/img/mom-overview.png)

Conceptually similar to Mixture-of-Experts (MoE) which lives *within* a model, this system selects the best *entire model* for the nature of the task.

As such, the overall inference accuracy is improved by using a pool of models that are better suited for different types of tasks:

![Model Accuracy](./website/static/img/category_accuracies.png)

The router is implemented in two ways:

- Golang (with Rust FFI based on the [candle](https://github.com/huggingface/candle) rust ML framework)
- Python
Benchmarking will be conducted to determine the best implementation.

#### Request Flow

![architecture](./website/static/img/flow.png)

#### Auto-Selection of Tools

Select the tools to use based on the prompt, avoiding the use of tools that are not relevant to the prompt so as to reduce the number of prompt tokens and improve tool selection accuracy by the LLM.

#### Domain Aware System Prompts

Automatically inject specialized system prompts based on query classification, ensuring optimal model behavior for different domains (math, coding, business, etc.) without manual prompt engineering.

#### Domain Aware Similarity Caching ‚ö°Ô∏è

Cache the semantic representation of the prompt so as to reduce the number of prompt tokens and improve the overall inference latency.

### Enterprise Security üîí

#### PII detection

Detect PII in the prompt, avoiding sending PII to the LLM so as to protect the privacy of the user.

#### Prompt guard

Detect if the prompt is a jailbreak prompt, avoiding sending jailbreak prompts to the LLM so as to prevent the LLM from misbehaving. Can be configured globally or at the category level for fine-grained security control.

## Quick Start üöÄ

Get up and running in seconds with our interactive setup script:

```bash
bash ./scripts/quickstart.sh
```

This command will:

- üîç Check all prerequisites automatically
- üì¶ Install HuggingFace CLI if needed
- üì• Download all required AI models (~1.5GB)
- üê≥ Start all Docker services
- ‚è≥ Wait for services to become healthy
- üåê Show you all the endpoints and next steps

For detailed installation and configuration instructions, see the [Complete Documentation](https://vllm-semantic-router.com/docs/installation/).

## Documentation üìñ

For comprehensive documentation including detailed setup instructions, architecture guides, and API references, visit:

**üëâ [Complete Documentation at Read the Docs](https://vllm-semantic-router.com/)**

The documentation includes:

- **[Installation Guide](https://vllm-semantic-router.com/docs/installation/)** - Complete setup instructions
- **[System Architecture](https://vllm-semantic-router.com/docs/overview/architecture/system-architecture/)** - Technical deep dive
- **[Model Training](https://vllm-semantic-router.com/docs/training/training-overview/)** - How classification models work
- **[API Reference](https://vllm-semantic-router.com/docs/api/router/)** - Complete API documentation
- **[Dashboard](https://vllm-semantic-router.com/docs/overview/dashboard)** - vLLM Semantic Router Dashboard

## Community üëã

For questions, feedback, or to contribute, please join `#semantic-router` channel in vLLM Slack.

### Community Meetings üìÖ

We host bi-weekly community meetings to sync up with contributors across different time zones:

- **First Tuesday of the month**: 9:00-10:00 AM EST (accommodates US EST, EU, and Asia Pacific contributors)
  - [Zoom Link](https://us05web.zoom.us/j/84122485631?pwd=BB88v03mMNLVHn60YzVk4PihuqBV9d.1)
  - [Google Calendar Invite](https://us05web.zoom.us/meeting/tZAsdeuspj4sGdVraOOR4UaXSstrH2jjPYFq/calendar/google/add?meetingMasterEventId=4jjzUKSLSLiBHtIKZpGc3g)
  - [ics file](https://drive.google.com/file/d/15wO8cg0ZjNxdr8OtGiZyAgkSS8_Wry0J/view?usp=sharing)
- **Third Tuesday of the month**: 1:00-2:00 PM EST (accommodates US EST and California contributors)
  - [Zoom Link](https://us06web.zoom.us/j/86871492845?pwd=LcTtXm9gtGu23JeWqXxbnLLCCvbumB.1)
  - [Google Calendar Invite](https://us05web.zoom.us/meeting/tZIlcOispzkiHtH2dlkWlLym68bEqvuf3MU5/calendar/google/add?meetingMasterEventId=PqWz2vk7TOCszPXqconGAA)
  - [ics file](https://drive.google.com/file/d/1T54mwYpXXoV9QfR76I56BFBPNbykSsTw/view?usp=sharing)
- Meeting Recordings: [YouTube](https://www.youtube.com/@vLLMSemanticRouter/videos)

Join us to discuss the latest developments, share ideas, and collaborate on the project!

## Citation

If you find Semantic Router helpful in your research or projects, please consider citing it:

```
@misc{semanticrouter2025,
  title={vLLM Semantic Router},
  author={vLLM Semantic Router Team},
  year={2025},
  howpublished={\url{https://github.com/vllm-project/semantic-router}},
}
```

## Star History üî•

We opened the project at Aug 31, 2025. We love open source  and collaboration ‚ù§Ô∏è

[![Star History Chart](https://api.star-history.com/svg?repos=vllm-project/semantic-router&amp;type=Date)](https://www.star-history.com/#vllm-project/semantic-router&amp;Date)

## Sponsors üëã

We are grateful to our sponsors who support us:

---

[**AMD**](https://www.amd.com) provides us with GPU resources and [ROCm‚Ñ¢](https://www.amd.com/en/products/software/rocm.html) Software for training and researching the frontier router models, enhancing e2e testing, and building online models playground.

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.amd.com&quot;&gt;
  &lt;img src=&quot;website/static/img/amd-logo.svg&quot; alt=&quot;AMD&quot; width=&quot;40%&quot;/&gt;
&lt;/a&gt;
&lt;/div&gt;

---
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[VictoriaMetrics/VictoriaMetrics]]></title>
            <link>https://github.com/VictoriaMetrics/VictoriaMetrics</link>
            <guid>https://github.com/VictoriaMetrics/VictoriaMetrics</guid>
            <pubDate>Thu, 18 Dec 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[VictoriaMetrics: fast, cost-effective monitoring solution and time series database]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/VictoriaMetrics/VictoriaMetrics">VictoriaMetrics/VictoriaMetrics</a></h1>
            <p>VictoriaMetrics: fast, cost-effective monitoring solution and time series database</p>
            <p>Language: Go</p>
            <p>Stars: 15,681</p>
            <p>Forks: 1,515</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre># VictoriaMetrics

[![Latest Release](https://img.shields.io/github/v/release/VictoriaMetrics/VictoriaMetrics?sort=semver&amp;label=&amp;filter=!*-victorialogs&amp;logo=github&amp;labelColor=gray&amp;color=gray&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Freleases%2Flatest)](https://github.com/VictoriaMetrics/VictoriaMetrics/releases)
![Docker Pulls](https://img.shields.io/docker/pulls/victoriametrics/victoria-metrics?label=&amp;logo=docker&amp;logoColor=white&amp;labelColor=2496ED&amp;color=2496ED&amp;link=https%3A%2F%2Fhub.docker.com%2Fr%2Fvictoriametrics%2Fvictoria-metrics)
[![Go Report](https://goreportcard.com/badge/github.com/VictoriaMetrics/VictoriaMetrics?link=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics)](https://goreportcard.com/report/github.com/VictoriaMetrics/VictoriaMetrics)
[![Build Status](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml/badge.svg?branch=master&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Factions)](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml)
[![codecov](https://codecov.io/gh/VictoriaMetrics/VictoriaMetrics/branch/master/graph/badge.svg?link=https%3A%2F%2Fcodecov.io%2Fgh%2FVictoriaMetrics%2FVictoriaMetrics)](https://app.codecov.io/gh/VictoriaMetrics/VictoriaMetrics)
[![License](https://img.shields.io/github/license/VictoriaMetrics/VictoriaMetrics?labelColor=green&amp;label=&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Fblob%2Fmaster%2FLICENSE)](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/LICENSE)
![Slack](https://img.shields.io/badge/Join-4A154B?logo=slack&amp;link=https%3A%2F%2Fslack.victoriametrics.com)
[![X](https://img.shields.io/twitter/follow/VictoriaMetrics?style=flat&amp;label=Follow&amp;color=black&amp;logo=x&amp;labelColor=black&amp;link=https%3A%2F%2Fx.com%2FVictoriaMetrics)](https://x.com/VictoriaMetrics/)
[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/VictoriaMetrics?style=flat&amp;label=Join&amp;labelColor=red&amp;logoColor=white&amp;logo=reddit&amp;link=https%3A%2F%2Fwww.reddit.com%2Fr%2FVictoriaMetrics)](https://www.reddit.com/r/VictoriaMetrics/)

&lt;picture&gt;
  &lt;source srcset=&quot;docs/victoriametrics/logo_white.webp&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
  &lt;source srcset=&quot;docs/victoriametrics/logo.webp&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
  &lt;img src=&quot;docs/victoriametrics/logo.webp&quot; width=&quot;300&quot; alt=&quot;VictoriaMetrics logo&quot;&gt;
&lt;/picture&gt;

VictoriaMetrics is a fast, cost-saving, and scalable solution for monitoring and managing time series data. It delivers high performance and reliability, making it an ideal choice for businesses of all sizes.

Here are some resources and information about VictoriaMetrics:

- Documentation: [docs.victoriametrics.com](https://docs.victoriametrics.com)
- Case studies: [Grammarly, Roblox, Wix,...](https://docs.victoriametrics.com/victoriametrics/casestudies/).
- Available: [Binary releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest), docker images [Docker Hub](https://hub.docker.com/r/victoriametrics/victoria-metrics/) and [Quay](https://quay.io/repository/victoriametrics/victoria-metrics), [Source code](https://github.com/VictoriaMetrics/VictoriaMetrics)
- Deployment types: [Single-node version](https://docs.victoriametrics.com/), [Cluster version](https://docs.victoriametrics.com/victoriametrics/cluster-victoriametrics/), and [Enterprise version](https://docs.victoriametrics.com/victoriametrics/enterprise/)
- Changelog: [CHANGELOG](https://docs.victoriametrics.com/victoriametrics/changelog/), and [How to upgrade](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-upgrade-victoriametrics)
- Community: [Slack](https://slack.victoriametrics.com/), [X (Twitter)](https://x.com/VictoriaMetrics), [LinkedIn](https://www.linkedin.com/company/victoriametrics/), [YouTube](https://www.youtube.com/@VictoriaMetrics)

Yes, we open-source both the single-node VictoriaMetrics and the cluster version.

## Prominent features

VictoriaMetrics is optimized for timeseries data, even when old time series are constantly replaced by new ones at a high rate, it offers a lot of features:

* **Long-term storage for Prometheus** or as a drop-in replacement for Prometheus and Graphite in Grafana.
* **Powerful stream aggregation**: Can be used as a StatsD alternative.
* **Ideal for big data**: Works well with large amounts of time series data from APM, Kubernetes, IoT sensors, connected cars, industrial telemetry, financial data and various [Enterprise workloads](https://docs.victoriametrics.com/victoriametrics/enterprise/).
* **Query language**: Supports both PromQL and the more performant MetricsQL.
* **Easy to setup**: No dependencies, single [small binary](https://medium.com/@valyala/stripping-dependency-bloat-in-victoriametrics-docker-image-983fb5912b0d), configuration through command-line flags, but the default is also fine-tuned; backup and restore with [instant snapshots](https://medium.com/@valyala/how-victoriametrics-makes-instant-snapshots-for-multi-terabyte-time-series-data-e1f3fb0e0282).
* **Global query view**: Multiple Prometheus instances or any other data sources may ingest data into VictoriaMetrics and queried via a single query.
* **Various Protocols**: Support metric scraping, ingestion and backfilling in various protocol.
    * [Prometheus exporters](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-scrape-prometheus-exporters-such-as-node-exporter), [Prometheus remote write API](https://docs.victoriametrics.com/victoriametrics/integrations/prometheus/), [Prometheus exposition format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-prometheus-exposition-format).
    * [InfluxDB line protocol](https://docs.victoriametrics.com/victoriametrics/integrations/influxdb/) over HTTP, TCP and UDP.
    * [Graphite plaintext protocol](https://docs.victoriametrics.com/victoriametrics/integrations/graphite/#ingesting) with [tags](https://graphite.readthedocs.io/en/latest/tags.html#carbon).
    * [OpenTSDB put message](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-telnet).
    * [HTTP OpenTSDB /api/put requests](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-http).
    * [JSON line format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-json-line-format).
    * [Arbitrary CSV data](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-csv-data).
    * [Native binary format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-native-format).
    * [DataDog agent or DogStatsD](https://docs.victoriametrics.com/victoriametrics/integrations/datadog/).
    * [NewRelic infrastructure agent](https://docs.victoriametrics.com/victoriametrics/integrations/newrelic/#sending-data-from-agent).
    * [OpenTelemetry metrics format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#sending-data-via-opentelemetry).
* **NFS-based storages**: Supports storing data on NFS-based storages such as Amazon EFS, Google Filestore.
* And many other features such as metrics relabeling, cardinality limiter, etc.

## Enterprise version

In addition, the Enterprise version includes extra features:

- **Anomaly detection**: Automation and simplification of your alerting rules, covering complex anomalies found in metrics data.
- **Backup automation**: Automates regular backup procedures.
- **Multiple retentions**: Reducing storage costs by specifying different retentions for different datasets.
- **Downsampling**: Reducing storage costs and increasing performance for queries over historical data.
- **Stable releases** with long-term support lines ([LTS](https://docs.victoriametrics.com/victoriametrics/lts-releases/)).
- **Comprehensive support**: First-class consulting, feature requests and technical support provided by the core VictoriaMetrics dev team.
- Many other features, which you can read about on [the Enterprise page](https://docs.victoriametrics.com/victoriametrics/enterprise/).

[Contact us](mailto:info@victoriametrics.com) if you need enterprise support for VictoriaMetrics. Or you can request a free trial license [here](https://victoriametrics.com/products/enterprise/trial/), downloaded Enterprise binaries are available at [Github Releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest).

We strictly apply security measures in everything we do. VictoriaMetrics has achieved security certifications for Database Software Development and Software-Based Monitoring Services. See [Security page](https://victoriametrics.com/security/) for more details.

## Benchmarks 

Some good benchmarks VictoriaMetrics achieved:

* **Minimal memory footprint**: handling millions of unique timeseries with [10x less RAM](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) than InfluxDB, up to [7x less RAM](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) than Prometheus, Thanos or Cortex.
* **Highly scalable and performance** for [data ingestion](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and [querying](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4), [20x outperforms](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) InfluxDB and TimescaleDB.
* **High data compression**: [70x more data points](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4) may be stored into limited storage than TimescaleDB, [7x less storage](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) space is required than Prometheus, Thanos or Cortex.
* **Reducing storage costs**: [10x more effective](https://docs.victoriametrics.com/victoriametrics/casestudies/#grammarly) than Graphite according to the Grammarly case study.
* **A single-node VictoriaMetrics** can replace medium-sized clusters built with competing solutions such as Thanos, M3DB, Cortex, InfluxDB or TimescaleDB. See [VictoriaMetrics vs Thanos](https://medium.com/@valyala/comparing-thanos-to-victoriametrics-cluster-b193bea1683), [Measuring vertical scalability](https://medium.com/@valyala/measuring-vertical-scalability-for-time-series-databases-in-google-cloud-92550d78d8ae), [Remote write storage wars - PromCon 2019](https://promcon.io/2019-munich/talks/remote-write-storage-wars/).
* **Optimized for storage**: [Works well with high-latency IO](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and low IOPS (HDD and network storage in AWS, Google Cloud, Microsoft Azure, etc.).

## Community and contributions

Feel free asking any questions regarding VictoriaMetrics:

* [Slack Inviter](https://slack.victoriametrics.com/) and [Slack channel](https://victoriametrics.slack.com/)
* [X (Twitter)](https://x.com/VictoriaMetrics/)
* [Linkedin](https://www.linkedin.com/company/victoriametrics/)
* [Reddit](https://www.reddit.com/r/VictoriaMetrics/)
* [Telegram-en](https://t.me/VictoriaMetrics_en)
* [Telegram-ru](https://t.me/VictoriaMetrics_ru1)
* [Mastodon](https://mastodon.social/@victoriametrics/)

If you like VictoriaMetrics and want to contribute, then please [read these docs](https://docs.victoriametrics.com/victoriametrics/contributing/).

## VictoriaMetrics Logo

The provided [ZIP file](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/VM_logo.zip) contains three folders with different logo orientations. Each folder includes the following file types:

* JPEG: Preview files
* PNG: Preview files with transparent background
* AI: Adobe Illustrator files

### VictoriaMetrics Logo Usage Guidelines

#### Font

* Font Used: Lato Black
* Download here: [Lato Font](https://fonts.google.com/specimen/Lato)

#### Color Palette

* Black [#000000](https://www.color-hex.com/color/000000)
* Purple [#4d0e82](https://www.color-hex.com/color/4d0e82)
* Orange [#ff2e00](https://www.color-hex.com/color/ff2e00)
* White [#ffffff](https://www.color-hex.com/color/ffffff)

### Logo Usage Rules

* Only use the Lato Black font as specified.
* Maintain sufficient clear space around the logo for visibility.
* Do not modify the spacing, alignment, or positioning of design elements.
* You may resize the logo as needed, but ensure all proportions remain intact.

Thank you for your cooperation!
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[danielmiessler/Fabric]]></title>
            <link>https://github.com/danielmiessler/Fabric</link>
            <guid>https://github.com/danielmiessler/Fabric</guid>
            <pubDate>Thu, 18 Dec 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/danielmiessler/Fabric">danielmiessler/Fabric</a></h1>
            <p>Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.</p>
            <p>Language: Go</p>
            <p>Stars: 35,243</p>
            <p>Forks: 3,592</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://go.warp.dev/fabric&quot; target=&quot;_blank&quot;&gt;
        &lt;sup&gt;Special thanks to:&lt;/sup&gt;
        &lt;br&gt;
        &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png&quot;&gt;
        &lt;br&gt;
        &lt;h&gt;Warp, built for coding with multiple AI agents&lt;/b&gt;
        &lt;br&gt;
        &lt;sup&gt;Available for macOS, Linux and Windows&lt;/sup&gt;
    &lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;./docs/images/fabric-logo-gif.gif&quot; alt=&quot;fabriclogo&quot; width=&quot;400&quot; height=&quot;400&quot;/&gt;

# `fabric`

![Static Badge](https://img.shields.io/badge/mission-human_flourishing_via_AI_augmentation-purple)
&lt;br /&gt;
![GitHub top language](https://img.shields.io/github/languages/top/danielmiessler/fabric)
![GitHub last commit](https://img.shields.io/github/last-commit/danielmiessler/fabric)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/danielmiessler/fabric)

&lt;div align=&quot;center&quot;&gt;
&lt;h4&gt;&lt;code&gt;fabric&lt;/code&gt; is an open-source framework for augmenting humans using AI.&lt;/h4&gt;
&lt;/div&gt;

![Screenshot of fabric](./docs/images/fabric-summarize.png)

&lt;/div&gt;

[Updates](#updates) ‚Ä¢
[What and Why](#what-and-why) ‚Ä¢
[Philosophy](#philosophy) ‚Ä¢
[Installation](#installation) ‚Ä¢
[Usage](#usage) ‚Ä¢
[Examples](#examples) ‚Ä¢
[Just Use the Patterns](#just-use-the-patterns) ‚Ä¢
[Custom Patterns](#custom-patterns) ‚Ä¢
[Helper Apps](#helper-apps) ‚Ä¢
[Meta](#meta)

&lt;/div&gt;

## What and why

Since the start of modern AI in late 2022 we&#039;ve seen an **_extraordinary_** number of AI applications for accomplishing tasks. There are thousands of websites, chat-bots, mobile apps, and other interfaces for using all the different AI out there.

It&#039;s all really exciting and powerful, but _it&#039;s not easy to integrate this functionality into our lives._

&lt;div class=&quot;align center&quot;&gt;
&lt;h4&gt;In other words, AI doesn&#039;t have a capabilities problem‚Äîit has an &lt;em&gt;integration&lt;/em&gt; problem.&lt;/h4&gt;
&lt;/div&gt;

**Fabric was created to address this by creating and organizing the fundamental units of AI‚Äîthe prompts themselves!**

Fabric organizes prompts by real-world task, allowing people to create, collect, and organize their most important AI solutions in a single place for use in their favorite tools. And if you&#039;re command-line focused, you can use Fabric itself as the interface!

## Updates

&lt;details&gt;
&lt;summary&gt;Click to view recent updates&lt;/summary&gt;

Dear Users,

We&#039;ve been doing so many exciting things here at Fabric, I wanted to give a quick summary here to give you a sense of our development velocity!

Below are the **new features and capabilities** we&#039;ve added (newest first):

### Recent Major Features

- [v1.4.338](https://github.com/danielmiessler/fabric/releases/tag/v1.4.338) (Dec 4, 2025) ‚Äî Add Abacus vendor support for Chat-LLM
  models (see [RouteLLM APIs](https://abacus.ai/app/route-llm-apis)).
- [v1.4.337](https://github.com/danielmiessler/fabric/releases/tag/v1.4.337) (Dec 4, 2025) ‚Äî Add &quot;Z AI&quot; vendor support. See the [Z AI overview](https://docs.z.ai/guides/overview/overview) page for more details.
- [v1.4.334](https://github.com/danielmiessler/fabric/releases/tag/v1.4.334) (Nov 26, 2025) ‚Äî **Claude Opus 4.5**: Updates the Anthropic SDK to the latest and adds the new [Claude Opus 4.5](https://www.anthropic.com/news/claude-opus-4-5) to the available models.
- [v1.4.331](https://github.com/danielmiessler/fabric/releases/tag/v1.4.331) (Nov 23, 2025) ‚Äî **Support for GitHub Models**: Adds support for using GitHub Models.
- [v1.4.322](https://github.com/danielmiessler/fabric/releases/tag/v1.4.322) (Nov 5, 2025) ‚Äî **Interactive HTML Concept Maps and Claude Sonnet 4.5**: Adds `create_conceptmap` pattern for visual knowledge representation using Vis.js, introduces WELLNESS category with psychological analysis patterns, and upgrades to Claude Sonnet 4.5
- [v1.4.317](https://github.com/danielmiessler/fabric/releases/tag/v1.4.317) (Sep 21, 2025) ‚Äî **Portuguese Language Variants**: Adds BCP 47 locale normalization with support for Brazilian Portuguese (pt-BR) and European Portuguese (pt-PT) with intelligent fallback chains
- [v1.4.314](https://github.com/danielmiessler/fabric/releases/tag/v1.4.314) (Sep 17, 2025) ‚Äî **Azure OpenAI Migration**: Migrates to official `openai-go/azure` SDK with improved authentication and default API version support
- [v1.4.311](https://github.com/danielmiessler/fabric/releases/tag/v1.4.311) (Sep 13, 2025) ‚Äî **More internationalization support**: Adds de (German), fa (Persian / Farsi), fr (French), it (Italian),
  ja (Japanese), pt (Portuguese), zh (Chinese)
- [v1.4.309](https://github.com/danielmiessler/fabric/releases/tag/v1.4.309) (Sep 9, 2025) ‚Äî **Comprehensive internationalization support**: Includes English and Spanish locale files.
- [v1.4.303](https://github.com/danielmiessler/fabric/releases/tag/v1.4.303) (Aug 29, 2025) ‚Äî **New Binary Releases**: Linux ARM and Windows ARM targets. You can run Fabric on the Raspberry PI and on your Windows Surface!
- [v1.4.294](https://github.com/danielmiessler/fabric/releases/tag/v1.4.294) (Aug 20, 2025) ‚Äî **Venice AI Support**: Added the Venice AI provider. Venice is a Privacy-First, Open-Source AI provider. See their [&quot;About Venice&quot;](https://docs.venice.ai/overview/about-venice) page for details.
- [v1.4.291](https://github.com/danielmiessler/fabric/releases/tag/v1.4.291) (Aug 18, 2025) ‚Äî **Speech To Text**: Add OpenAI speech-to-text support with `--transcribe-file`, `--transcribe-model`, and `--split-media-file` flags.
- [v1.4.287](https://github.com/danielmiessler/fabric/releases/tag/v1.4.287) (Aug 16, 2025) ‚Äî **AI Reasoning**: Add Thinking to Gemini models and introduce `readme_updates` python script
- [v1.4.286](https://github.com/danielmiessler/fabric/releases/tag/v1.4.286) (Aug 14, 2025) ‚Äî **AI Reasoning**: Introduce Thinking Config Across Anthropic and OpenAI Providers
- [v1.4.285](https://github.com/danielmiessler/fabric/releases/tag/v1.4.285) (Aug 13, 2025) ‚Äî **Extended Context**: Enable One Million Token Context Beta Feature for Sonnet-4
- [v1.4.284](https://github.com/danielmiessler/fabric/releases/tag/v1.4.284) (Aug 12, 2025) ‚Äî **Easy Shell Completions Setup**: Introduce One-Liner Curl Install for Completions
- [v1.4.283](https://github.com/danielmiessler/fabric/releases/tag/v1.4.283) (Aug 12, 2025) ‚Äî **Model Management**: Add Vendor Selection Support for Models
- [v1.4.282](https://github.com/danielmiessler/fabric/releases/tag/v1.4.282) (Aug 11, 2025) ‚Äî **Enhanced Shell Completions**: Enhanced Shell Completions for Fabric CLI Binaries
- [v1.4.281](https://github.com/danielmiessler/fabric/releases/tag/v1.4.281) (Aug 11, 2025) ‚Äî **Gemini Search Tool**: Add Web Search Tool Support for Gemini Models
- [v1.4.278](https://github.com/danielmiessler/fabric/releases/tag/v1.4.278) (Aug 9, 2025) ‚Äî **Enhance YouTube Transcripts**: Enhance YouTube Support with Custom yt-dlp Arguments
- [v1.4.277](https://github.com/danielmiessler/fabric/releases/tag/v1.4.277) (Aug 8, 2025) ‚Äî **Desktop Notifications**: Add cross-platform desktop notifications to Fabric CLI
- [v1.4.274](https://github.com/danielmiessler/fabric/releases/tag/v1.4.274) (Aug 7, 2025) ‚Äî **Claude 4.1 Added**: Add Support for Claude Opus 4.1 Model
- [v1.4.271](https://github.com/danielmiessler/fabric/releases/tag/v1.4.271) (Jul 28, 2025) ‚Äî **AI Summarized Release Notes**: Enable AI summary updates for GitHub releases
- [v1.4.268](https://github.com/danielmiessler/fabric/releases/tag/v1.4.268) (Jul 26, 2025) ‚Äî **Gemini TTS Voice Selection**: add Gemini TTS voice selection and listing functionality
- [v1.4.267](https://github.com/danielmiessler/fabric/releases/tag/v1.4.267) (Jul 26, 2025) ‚Äî **Text-to-Speech**: Update Gemini Plugin to New SDK with TTS Support
- [v1.4.258](https://github.com/danielmiessler/fabric/releases/tag/v1.4.258) (Jul 17, 2025) ‚Äî **Onboarding Improved**: Add startup check to initialize config and .env file automatically
- [v1.4.257](https://github.com/danielmiessler/fabric/releases/tag/v1.4.257) (Jul 17, 2025) ‚Äî **OpenAI Routing Control**: Introduce CLI Flag to Disable OpenAI Responses API
- [v1.4.252](https://github.com/danielmiessler/fabric/releases/tag/v1.4.252) (Jul 16, 2025) ‚Äî **Hide Thinking Block**: Optional Hiding of Model Thinking Process with Configurable Tags
- [v1.4.246](https://github.com/danielmiessler/fabric/releases/tag/v1.4.246) (Jul 14, 2025) ‚Äî **Automatic ChangeLog Updates**: Add AI-powered changelog generation with high-performance Go tool and comprehensive caching
- [v1.4.245](https://github.com/danielmiessler/fabric/releases/tag/v1.4.245) (Jul 11, 2025) ‚Äî **Together AI**: Together AI Support with OpenAI Fallback Mechanism Added
- [v1.4.232](https://github.com/danielmiessler/fabric/releases/tag/v1.4.232) (Jul 6, 2025) ‚Äî **Add Custom**: Add Custom Patterns Directory Support
- [v1.4.231](https://github.com/danielmiessler/fabric/releases/tag/v1.4.231) (Jul 5, 2025) ‚Äî **OAuth Auto-Auth**: OAuth Authentication Support for Anthropic (Use your Max Subscription)
- [v1.4.230](https://github.com/danielmiessler/fabric/releases/tag/v1.4.230) (Jul 5, 2025) ‚Äî **Model Management**: Add advanced image generation parameters for OpenAI models with four new CLI flags
- [v1.4.227](https://github.com/danielmiessler/fabric/releases/tag/v1.4.227) (Jul 4, 2025) ‚Äî **Add Image**: Add Image Generation Support to Fabric
- [v1.4.226](https://github.com/danielmiessler/fabric/releases/tag/v1.4.226) (Jul 4, 2025) ‚Äî **Web Search**: OpenAI Plugin Now Supports Web Search Functionality
- [v1.4.225](https://github.com/danielmiessler/fabric/releases/tag/v1.4.225) (Jul 4, 2025) ‚Äî **Web Search**: Runtime Web Search Control via Command-Line `--search` Flag
- [v1.4.224](https://github.com/danielmiessler/fabric/releases/tag/v1.4.224) (Jul 1, 2025) ‚Äî **Add code_review**: Add code_review pattern and updates in Pattern_Descriptions
- [v1.4.222](https://github.com/danielmiessler/fabric/releases/tag/v1.4.222) (Jul 1, 2025) ‚Äî **OpenAI Plugin**: OpenAI Plugin Migrates to New Responses API
- [v1.4.218](https://github.com/danielmiessler/fabric/releases/tag/v1.4.218) (Jun 27, 2025) ‚Äî **Model Management**: Add Support for OpenAI Search and Research Model Variants
- [v1.4.217](https://github.com/danielmiessler/fabric/releases/tag/v1.4.217) (Jun 26, 2025) ‚Äî **New YouTube**: New YouTube Transcript Endpoint Added to REST API
- [v1.4.212](https://github.com/danielmiessler/fabric/releases/tag/v1.4.212) (Jun 23, 2025) ‚Äî **Add Langdock**: Add Langdock AI and enhance generic OpenAI compatible support
- [v1.4.211](https://github.com/danielmiessler/fabric/releases/tag/v1.4.211) (Jun 19, 2025) ‚Äî **REST API**: REST API and Web UI Now Support Dynamic Pattern Variables
- [v1.4.210](https://github.com/danielmiessler/fabric/releases/tag/v1.4.210) (Jun 18, 2025) ‚Äî **Add Citations**: Add Citation Support to Perplexity Response
- [v1.4.208](https://github.com/danielmiessler/fabric/releases/tag/v1.4.208) (Jun 17, 2025) ‚Äî **Add Perplexity**: Add Perplexity AI Provider with Token Limits Support
- [v1.4.203](https://github.com/danielmiessler/fabric/releases/tag/v1.4.203) (Jun 14, 2025) ‚Äî **Add Amazon Bedrock**: Add support for Amazon Bedrock

These features represent our commitment to making Fabric the most powerful and flexible AI augmentation framework available!

&lt;/details&gt;

## Intro videos

Keep in mind that many of these were recorded when Fabric was Python-based, so remember to use the current [install instructions](#installation) below.

- [Network Chuck](https://www.youtube.com/watch?v=UbDyjIIGaxQ)
- [David Bombal](https://www.youtube.com/watch?v=vF-MQmVxnCs)
- [My Own Intro to the Tool](https://www.youtube.com/watch?v=wPEyyigh10g)
- [More Fabric YouTube Videos](https://www.youtube.com/results?search_query=fabric+ai)

## Navigation

- [`fabric`](#fabric)
  - [What and why](#what-and-why)
  - [Updates](#updates)
    - [Recent Major Features](#recent-major-features)
  - [Intro videos](#intro-videos)
  - [Navigation](#navigation)
  - [Changelog](#changelog)
  - [Philosophy](#philosophy)
    - [Breaking problems into components](#breaking-problems-into-components)
    - [Too many prompts](#too-many-prompts)
  - [Installation](#installation)
    - [One-Line Install (Recommended)](#one-line-install-recommended)
    - [Manual Binary Downloads](#manual-binary-downloads)
    - [Using package managers](#using-package-managers)
      - [macOS (Homebrew)](#macos-homebrew)
      - [Arch Linux (AUR)](#arch-linux-aur)
      - [Windows](#windows)
    - [From Source](#from-source)
    - [Docker](#docker)
    - [Environment Variables](#environment-variables)
    - [Setup](#setup)
    - [Per-Pattern Model Mapping](#per-pattern-model-mapping)
    - [Add aliases for all patterns](#add-aliases-for-all-patterns)
      - [Save your files in markdown using aliases](#save-your-files-in-markdown-using-aliases)
    - [Migration](#migration)
    - [Upgrading](#upgrading)
    - [Shell Completions](#shell-completions)
      - [Quick install (no clone required)](#quick-install-no-clone-required)
      - [Zsh Completion](#zsh-completion)
      - [Bash Completion](#bash-completion)
      - [Fish Completion](#fish-completion)
  - [Usage](#usage)
    - [Debug Levels](#debug-levels)
    - [Extensions](#extensions)
  - [Our approach to prompting](#our-approach-to-prompting)
  - [Examples](#examples)
  - [Just use the Patterns](#just-use-the-patterns)
    - [Prompt Strategies](#prompt-strategies)
  - [Custom Patterns](#custom-patterns)
    - [Setting Up Custom Patterns](#setting-up-custom-patterns)
    - [Using Custom Patterns](#using-custom-patterns)
    - [How It Works](#how-it-works)
  - [Helper Apps](#helper-apps)
    - [`to_pdf`](#to_pdf)
    - [`to_pdf` Installation](#to_pdf-installation)
    - [`code_helper`](#code_helper)
  - [pbpaste](#pbpaste)
  - [Web Interface (Fabric Web App)](#web-interface-fabric-web-app)
  - [Meta](#meta)
    - [Primary contributors](#primary-contributors)
    - [Contributors](#contributors)

&lt;br /&gt;

## Changelog

Fabric is evolving rapidly.

Stay current with the latest features by reviewing the [CHANGELOG](./CHANGELOG.md) for all recent changes.

## Philosophy

&gt; AI isn&#039;t a thing; it&#039;s a _magnifier_ of a thing. And that thing is **human creativity**.

We believe the purpose of technology is to help humans flourish, so when we talk about AI we start with the **human** problems we want to solve.

### Breaking problems into components

Our approach is to break problems into individual pieces (see below) and then apply AI to them one at a time. See below for some examples.

&lt;img width=&quot;2078&quot; alt=&quot;augmented_challenges&quot; src=&quot;https://github.com/danielmiessler/fabric/assets/50654/31997394-85a9-40c2-879b-b347e4701f06&quot;&gt;

### Too many prompts

Prompts are good for this, but the biggest challenge I faced in 2023‚Äî‚Äîwhich still exists today‚Äîis **the sheer number of AI prompts out there**. We all have prompts that are useful, but it&#039;s hard to discover new ones, know if they are good or not, _and manage different versions of the ones we like_.

One of `fabric`&#039;s primary features is helping people collect and integrate prompts, which we call _Patterns_, into various parts of their lives.

Fabric has Patterns for all sorts of life and work activities, including:

- Extracting the most interesting parts of YouTube videos and podcasts
- Writing an essay in your own voice with just an idea as an input
- Summarizing opaque academic papers
- Creating perfectly matched AI art prompts for a piece of writing
- Rating the quality of content to see if you want to read/watch the whole thing
- Getting summaries of long, boring content
- Explaining code to you
- Turning bad documentation into usable documentation
- Creating social media posts from any content input
- And a million more‚Ä¶

## Installation

### One-Line Install (Recommended)

**Unix/Linux/macOS:**

```bash
curl -fsSL https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.sh | bash
```

**Windows PowerShell:**

```powershell
iwr -useb https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.ps1 | iex
```

&gt; See [scripts/installer/README.md](./scripts/installer/README.md) for custom installation options and troubleshooting.

### Manual Binary Downloads

The latest release binary archives and their expected SHA256 hashes can be found at &lt;https://github.com/danielmiessler/fabric/releases/latest&gt;

### Using package managers

**NOTE:** using Homebrew or the Arch Linux package managers makes `fabric` available as `fabric-ai`, so add
the following alias to your shell startup files to account for this:

```bash
alias fabric=&#039;fabric-ai&#039;
```

#### macOS (Homebrew)

`brew install fabric-ai`

#### Arch Linux (AUR)

`yay -S fabric-ai`

#### Windows

Use the official Microsoft supported `Winget` tool:

`winget install danielmiessler.Fabric`

### From Source

To install Fabric, [make sure Go is installed](https://go.dev/doc/install), and then run the following command.

```bash
# Install Fabric directly from the repo
go install github.com/danielmiessler/fabric/cmd/fabric@latest
```

### Docker

Run Fabric using pre-built Docker images:

```bash
# Use latest image from Docker Hub
docker run --rm -it kayvan/fabric:latest --version

# Use specific version from GHCR
docker run --rm -it ghcr.io/ksylvan/fabric:v1.4.305 --version

# Run setup (first time)
mkdir -p $HOME/.fabric-config
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --setup

# Use Fabric with your patterns
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest -p summarize

# Run the REST API server
docker run --rm -it -p 8080:8080 -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --serve
```

**Images available at:**

- Docker Hub: [kayvan/fabric](https://hub.docker.com/repository/docker/kayvan/fabric/general)
- GHCR: [ksylvan/fabric](https://github.com/ksylvan/fabric/pkgs/container/fabric)

See [scripts/docker/README.md](./scripts/docker/README.md) for building custom images and advanced configuration.

### Environment Variables

You may need to set some environment variables in your `~/.bashrc` on linux or `~/.zshrc` file on mac to be able to run the `fabric` command. Here is an example of what you can add:

For Intel based macs or linux

```bash
# Golang environment variables
export GOROOT=/usr/local/go
export GOPATH=$HOME/go

# Update PATH to include GOPATH and GOROOT binaries
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
```

for Apple Silicon based macs

```bash
# Golang environment variables
export GOROOT=$(brew --prefix go)/libexec
export GOPATH=$HOME/go
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
```

### Setup

Now run the following command

```bash
# Run the setup to set up your directories and keys
fabric --setup
```

If everything works you are good to go.

### Per-Pattern Model Mapping

 You can configure specific models for individual patterns using environment variables
 like `FABRIC_MODEL_PATTERN_NAME=vendor|model`

 This makes it easy to maintain these per-pattern model mappings in your shell startup files.

### Add aliases for all patterns

In order to add aliases for all your patterns and use them directly as commands, for example, `summarize` instead of `fabric --pattern summarize`
You can add the following to your `.zshrc` or `.bashrc` file. You
can also optionally set the `FABRIC_ALIAS_PREFIX` environment variable
before, if you&#039;d prefer all the fabric aliases to start with the same prefix.

```bash
# Loop through all files in the ~/.config/fabric/patterns directory
for pattern_file in $HOME/.config/fabric/patterns/*; do
    # Get the base name of the file (i.e., remove the directory path)
    pattern_name=&quot;$(basename &quot;$pattern_file&quot;)&quot;
    alias_name=&quot;${FABRIC_ALIAS_PREFIX:-}${pattern_name}&quot;

    # Create an alias in th

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[apernet/hysteria]]></title>
            <link>https://github.com/apernet/hysteria</link>
            <guid>https://github.com/apernet/hysteria</guid>
            <pubDate>Thu, 18 Dec 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[Hysteria is a powerful, lightning fast and censorship resistant proxy.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/apernet/hysteria">apernet/hysteria</a></h1>
            <p>Hysteria is a powerful, lightning fast and censorship resistant proxy.</p>
            <p>Language: Go</p>
            <p>Stars: 18,174</p>
            <p>Forks: 1,968</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre># ![Hysteria 2](logo.svg)

[![License][1]][2] [![Release][3]][4] [![Telegram][5]][6] [![Discussions][7]][8]

[1]: https://img.shields.io/badge/license-MIT-blue
[2]: LICENSE.md
[3]: https://img.shields.io/github/v/release/apernet/hysteria?style=flat-square
[4]: https://github.com/apernet/hysteria/releases
[5]: https://img.shields.io/badge/chat-Telegram-blue?style=flat-square
[6]: https://t.me/hysteria_github
[7]: https://img.shields.io/github/discussions/apernet/hysteria?style=flat-square
[8]: https://github.com/apernet/hysteria/discussions

&lt;h2 style=&quot;text-align: center;&quot;&gt;Hysteria is a powerful, lightning fast and censorship resistant proxy.&lt;/h2&gt;

### [Get Started](https://v2.hysteria.network/)

### [‰∏≠ÊñáÊñáÊ°£](https://v2.hysteria.network/zh/)

### [Hysteria 1.x (legacy)](https://v1.hysteria.network/)

---

&lt;div class=&quot;feature-grid&quot;&gt;
  &lt;div&gt;
    &lt;h3&gt;üõ†Ô∏è Jack of all trades&lt;/h3&gt;
    &lt;p&gt;Wide range of modes including SOCKS5, HTTP Proxy, TCP/UDP Forwarding, Linux TProxy, TUN - with more features being added constantly.&lt;/p&gt;
  &lt;/div&gt;

  &lt;div&gt;
    &lt;h3&gt;‚ö° Blazing fast&lt;/h3&gt;
    &lt;p&gt;Powered by a customized QUIC protocol, Hysteria is designed to deliver unparalleled performance over unreliable and lossy networks.&lt;/p&gt;
  &lt;/div&gt;

  &lt;div&gt;
    &lt;h3&gt;‚úä Censorship resistant&lt;/h3&gt;
    &lt;p&gt;The protocol masquerades as standard HTTP/3 traffic, making it very difficult for censors to detect and block without widespread collateral damage.&lt;/p&gt;
  &lt;/div&gt;
  
  &lt;div&gt;
    &lt;h3&gt;üíª Cross-platform&lt;/h3&gt;
    &lt;p&gt;We have builds for every major platform and architecture. Deploy anywhere &amp; use everywhere. Not to mention the long list of 3rd party apps.&lt;/p&gt;
  &lt;/div&gt;

  &lt;div&gt;
    &lt;h3&gt;üîó Easy integration&lt;/h3&gt;
    &lt;p&gt;With built-in support for custom authentication, traffic statistics &amp; access control, Hysteria is easy to integrate into your infrastructure.&lt;/p&gt;
  &lt;/div&gt;
  
  &lt;div&gt;
    &lt;h3&gt;ü§ó Chill and supportive&lt;/h3&gt;
    &lt;p&gt;We have well-documented specifications and code for developers to contribute and/or build their own apps. And a helpful community, too.&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;

---

**If you find Hysteria useful, consider giving it a ‚≠êÔ∏è!**

[![Star History Chart](https://api.star-history.com/svg?repos=apernet/hysteria&amp;type=Date)](https://star-history.com/#apernet/hysteria&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Ingenimax/agent-sdk-go]]></title>
            <link>https://github.com/Ingenimax/agent-sdk-go</link>
            <guid>https://github.com/Ingenimax/agent-sdk-go</guid>
            <pubDate>Thu, 18 Dec 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[A powerful Go framework for building production-ready AI agents!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Ingenimax/agent-sdk-go">Ingenimax/agent-sdk-go</a></h1>
            <p>A powerful Go framework for building production-ready AI agents!</p>
            <p>Language: Go</p>
            <p>Stars: 501</p>
            <p>Forks: 104</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/docs/img/logo-header.png#gh-light-mode-only&quot; alt=&quot;Ingenimax&quot; width=&quot;400&quot;&gt;
&lt;img src=&quot;/docs/img/logo-header-inverted.png#gh-dark-mode-only&quot; alt=&quot;Ingenimax&quot; width=&quot;400&quot;&gt;

&lt;a href=&quot;https://www.producthunt.com/products/agent-gogo?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_source=badge-agent&amp;#0045;gogo&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=1049356&amp;theme=light&amp;t=1765568756912&quot; alt=&quot;Agent&amp;#0032;GoGo - Build&amp;#0032;cloud&amp;#0045;native&amp;#0032;AI&amp;#0032;Agents | Product Hunt&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

# Agent Go SDK

A powerful Go framework for building production-ready AI agents that seamlessly integrates memory management, tool execution, multi-LLM support, and enterprise features into a flexible, extensible architecture.

## Documentation

üìñ **[docs.goagents.dev](https://docs.goagents.dev/)** ‚Äî Full documentation, guides, and reference.

## Community

[![Discord](https://img.shields.io/badge/Discord-Join%20Our%20Community-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.com/invite/MjJbDG2nQZ)

Join our Discord server to collaborate, share what you&#039;re building, and get community support for agent-sdk-go!

## Features

### Core Capabilities
- üß† **Multi-Model Intelligence**: Seamless integration with OpenAI, Anthropic, and Google Vertex AI (Gemini models).
- üîß **Modular Tool Ecosystem**: Expand agent capabilities with plug-and-play tools for web search, data retrieval, and custom operations
- üìù **Advanced Memory Management**: Persistent conversation tracking with buffer and vector-based retrieval options
- üîå **MCP Integration**: Support for Model Context Protocol (MCP) servers via HTTP and stdio transports
- üìä **Token Usage Tracking**: Built-in token counting for cost monitoring, usage analytics, and optimization

### Enterprise-Ready
- üö¶ **Built-in Guardrails**: Comprehensive safety mechanisms for responsible AI deployment
- üìà **Complete Observability**: Integrated tracing and logging for monitoring and debugging
- üè¢ **Enterprise Multi-tenancy**: Securely support multiple organizations with isolated resources

### Development Experience
- üõ†Ô∏è **Structured Task Framework**: Plan, approve, and execute complex multi-step operations
- üìÑ **Declarative Configuration**: Define sophisticated agents and tasks using intuitive YAML definitions
- üßô **Zero-Effort Bootstrapping**: Auto-generate complete agent configurations from simple system prompts

## Getting Started

### Prerequisites

- Go 1.23+
- Redis (optional, for distributed memory)

### Installation

#### As a Go Library

Add the SDK to your Go project:

```bash
go get github.com/Ingenimax/agent-sdk-go
```

#### As a CLI Tool (Headless SDK)

**Option 1: Download Pre-built Binaries (Recommended)**

Download the latest release for your platform from [GitHub Releases](https://github.com/Ingenimax/agent-sdk-go/releases) and add it to your PATH.

**Option 2: Install via Go**

```bash
go install github.com/Ingenimax/agent-sdk-go/cmd/agent-cli@latest
```

**Option 3: Build from Source**

```bash
# Clone the repository
git clone https://github.com/Ingenimax/agent-sdk-go
cd agent-sdk-go

# Build the CLI tool
make build-cli

# Install to system PATH (optional)
make install
```

**Quick CLI Start:**
```bash
# Initialize configuration
agent-cli init

# Option 1: Set environment variables
export OPENAI_API_KEY=your_api_key_here

# Option 2: Use .env file (recommended)
cp env.example .env
# Edit .env with your API keys

# Run a simple query
agent-cli run &quot;What&#039;s the weather in San Francisco?&quot;

# Start interactive chat
agent-cli chat
```

### Configuration

The SDK uses environment variables for configuration. Key variables include:

- `OPENAI_API_KEY`: Your OpenAI API key
- `OPENAI_MODEL`: The model to use (e.g., gpt-4o-mini)
- `LOG_LEVEL`: Logging level (debug, info, warn, error)
- `REDIS_ADDRESS`: Redis server address (if using Redis for memory)

See `.env.example` for a complete list of configuration options.

### Get Help with Nina (AI Assistant)

Nina is an AI assistant that knows the agent-sdk-go codebase inside and out. Connect to Nina via MCP (Model Context Protocol) to get help directly in your IDE.

#### Cursor IDE

Add to `~/.cursor/mcp.json`:

```json
{
  &quot;mcpServers&quot;: {
    &quot;agent-sdk-go&quot;: {
      &quot;url&quot;: &quot;https://nina.agentgogo.app/mcp&quot;,
      &quot;transport&quot;: &quot;sse&quot;
    }
  }
}
```

Restart Cursor IDE and Nina&#039;s tools will be available in your AI assistant.

#### Claude Desktop

Add to `claude_desktop_config.json`:

| Platform | Config Location |
|----------|-----------------|
| macOS | `~/Library/Application Support/Claude/claude_desktop_config.json` |
| Windows | `%APPDATA%\Claude\claude_desktop_config.json` |

```json
{
  &quot;mcpServers&quot;: {
    &quot;agent-sdk-go&quot;: {
      &quot;url&quot;: &quot;https://nina.agentgogo.app/mcp&quot;,
      &quot;transport&quot;: &quot;sse&quot;
    }
  }
}
```

Restart Claude Desktop and Nina&#039;s tools will be available via the üîå icon.

#### Available Tools

| Tool | Description |
|------|-------------|
| `ask_nina` | Ask questions about agent-sdk-go, Go programming, or development |
| `search_sdk` | Search the SDK documentation and source code |
| `get_sdk_status` | Get status of Nina&#039;s SDK knowledge base |

## Usage Examples

### Creating a Simple Agent

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/agent&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/config&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/openai&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/logging&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/memory&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/multitenancy&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/tools&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/tools/websearch&quot;
)

func main() {
	// Create a logger
	logger := logging.New()

	// Get configuration
	cfg := config.Get()

	// Create a new agent with OpenAI
	openaiClient := openai.NewClient(cfg.LLM.OpenAI.APIKey,
		openai.WithLogger(logger))

	agent, err := agent.NewAgent(
		agent.WithLLM(openaiClient),
		agent.WithMemory(memory.NewConversationBuffer()),
		agent.WithTools(createTools(logger).List()...),
		agent.WithSystemPrompt(&quot;You are a helpful AI assistant. When you don&#039;t know the answer or need real-time information, use the available tools to find the information.&quot;),
		agent.WithName(&quot;ResearchAssistant&quot;),
	)
	if err != nil {
		logger.Error(context.Background(), &quot;Failed to create agent&quot;, map[string]interface{}{&quot;error&quot;: err.Error()})
		return
	}

	// Create a context with organization ID and conversation ID
	ctx := context.Background()
	ctx = multitenancy.WithOrgID(ctx, &quot;default-org&quot;)
	ctx = context.WithValue(ctx, memory.ConversationIDKey, &quot;conversation-123&quot;)

	// Run the agent
	response, err := agent.Run(ctx, &quot;What&#039;s the weather in San Francisco?&quot;)
	if err != nil {
		logger.Error(ctx, &quot;Failed to run agent&quot;, map[string]interface{}{&quot;error&quot;: err.Error()})
		return
	}

	fmt.Println(response)
}

func createTools(logger logging.Logger) *tools.Registry {
	// Get configuration
	cfg := config.Get()

	// Create tools registry
	toolRegistry := tools.NewRegistry()

	// Add web search tool if API keys are available
	if cfg.Tools.WebSearch.GoogleAPIKey != &quot;&quot; &amp;&amp; cfg.Tools.WebSearch.GoogleSearchEngineID != &quot;&quot; {
		searchTool := websearch.New(
			cfg.Tools.WebSearch.GoogleAPIKey,
			cfg.Tools.WebSearch.GoogleSearchEngineID,
		)
		toolRegistry.Register(searchTool)
	}

	return toolRegistry
}
```

### Token Usage Tracking

The SDK provides built-in token usage tracking for cost monitoring and usage analytics. You can access token information using the detailed generation methods:

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;log&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/anthropic&quot;
)

func main() {
	// Create LLM client
	client := anthropic.NewClient(&quot;your-api-key&quot;,
		anthropic.WithModel(&quot;claude-3-haiku-20240307&quot;),
	)

	ctx := context.Background()
	prompt := &quot;Explain quantum computing in one paragraph.&quot;

	// Traditional method (backward compatible)
	content, err := client.Generate(ctx, prompt)
	if err != nil {
		log.Fatal(err)
	}
	fmt.Printf(&quot;Response: %s\n&quot;, content)

	// New detailed method with token usage
	response, err := client.GenerateDetailed(ctx, prompt)
	if err != nil {
		log.Fatal(err)
	}

	fmt.Printf(&quot;Response: %s\n&quot;, response.Content)
	fmt.Printf(&quot;Model: %s\n&quot;, response.Model)

	if response.Usage != nil {
		fmt.Printf(&quot;Token Usage:\n&quot;)
		fmt.Printf(&quot;  Input Tokens: %d\n&quot;, response.Usage.InputTokens)
		fmt.Printf(&quot;  Output Tokens: %d\n&quot;, response.Usage.OutputTokens)
		fmt.Printf(&quot;  Total Tokens: %d\n&quot;, response.Usage.TotalTokens)

		// Calculate estimated cost (adjust based on actual pricing)
		inputCost := float64(response.Usage.InputTokens) * 0.25 / 1000000
		outputCost := float64(response.Usage.OutputTokens) * 1.25 / 1000000
		fmt.Printf(&quot;  Estimated Cost: $%.6f\n&quot;, inputCost + outputCost)
	}
}
```

**Available Methods:**
- `Generate()` - Traditional method returning string (unchanged)
- `GenerateDetailed()` - New method returning `*LLMResponse` with usage info
- `GenerateWithTools()` - Traditional method with tools (unchanged)
- `GenerateWithToolsDetailed()` - New method with tools and usage info

**Provider Support:**
- ‚úÖ **Anthropic**: Full token usage support
- ‚úÖ **OpenAI**: Full support including reasoning tokens
- ‚úÖ **Azure OpenAI**: Full support (similar to OpenAI)
- ‚ùå **Ollama/vLLM**: Local models don&#039;t provide usage data (Usage=nil)

See the [token usage example](examples/token-usage/) for a complete demonstration.

### Advanced YAML Configuration

The SDK now supports comprehensive YAML-based agent configuration with advanced features including behavioral settings, tool configuration, MCP integration, sub-agents, and environment variable expansion.

**Example: Complete Agent with YAML Configuration**

```go
package main

import (
	&quot;context&quot;
	&quot;log&quot;
	&quot;os&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/agent&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/openai&quot;
)

func main() {
	// Create LLM client
	llm := openai.NewClient(os.Getenv(&quot;OPENAI_API_KEY&quot;))

	// Load agent configurations from YAML
	configs, err := agent.LoadAgentConfigsFromFile(&quot;agents.yaml&quot;)
	if err != nil {
		log.Fatal(err)
	}

	// Create agent directly from configuration
	agentInstance, err := agent.NewAgentFromConfig(&quot;research_assistant&quot;, configs, nil, agent.WithLLM(llm))
	if err != nil {
		log.Fatal(err)
	}

	// Run the agent
	result, err := agentInstance.Run(context.Background(), &quot;What are the latest developments in renewable energy?&quot;)
	if err != nil {
		log.Fatal(err)
	}

	println(result)
}
```

**agents.yaml** (Advanced Configuration):
```yaml
research_assistant:
  role: &quot;Advanced Research Assistant&quot;
  goal: &quot;Provide comprehensive research and analysis&quot;
  backstory: &quot;Expert researcher with access to multiple data sources and specialized sub-agents&quot;

  # Behavioral settings
  max_iterations: 15
  require_plan_approval: false

  # LLM configuration
  llm_config:
    temperature: 0.7
    enable_reasoning: true
    reasoning_budget: 20000

  # Built-in and custom tools
  tools:
    - type: &quot;builtin&quot;
      name: &quot;websearch&quot;
      enabled: true
      config:
        api_key: &quot;${SEARCH_API_KEY}&quot;
        engine: &quot;brave&quot;

    - type: &quot;builtin&quot;
      name: &quot;calculator&quot;
      enabled: true

  # MCP server integration
  mcp:
    mcpServers:
      filesystem:
        command: &quot;npx&quot;
        args: [&quot;-y&quot;, &quot;@modelcontextprotocol/server-filesystem&quot;, &quot;.&quot;]

      database:
        command: &quot;python&quot;
        args: [&quot;-m&quot;, &quot;mcp_server_database&quot;]
        env:
          DATABASE_URL: &quot;${DATABASE_URL}&quot;

  # Memory configuration
  memory:
    type: &quot;redis&quot;
    config:
      address: &quot;${REDIS_ADDRESS}&quot;
      db: 0

  # Sub-agents for specialized tasks
  sub_agents:
    data_analyzer:
      role: &quot;Data Analysis Specialist&quot;
      goal: &quot;Analyze complex datasets and provide insights&quot;
      backstory: &quot;Expert in statistical analysis and data visualization&quot;
      max_iterations: 8
      llm_config:
        temperature: 0.3

    report_writer:
      role: &quot;Technical Writer&quot;
      goal: &quot;Create comprehensive reports and documentation&quot;
      backstory: &quot;Skilled at converting complex data into clear reports&quot;
      tools:
        - type: &quot;builtin&quot;
          name: &quot;text_processor&quot;
          enabled: true

  # Runtime settings
  runtime:
    log_level: &quot;info&quot;
    enable_tracing: true
    timeout: &quot;300s&quot;
```

**Key Features of Advanced YAML Configuration:**

- **Environment Variable Expansion**: Use `${VAR}` syntax for sensitive data
- **Behavioral Settings**: Configure iterations, plan approval, and runtime behavior
- **LLM Configuration**: Fine-tune temperature, reasoning, and model-specific settings
- **Tool Integration**: Configure built-in, custom, MCP, and agent tools declaratively
- **Sub-Agents**: Create hierarchical agent structures with specialized capabilities
- **Memory Backends**: Configure buffer, Redis, or vector memory systems
- **MCP Integration**: Seamless Model Context Protocol server configuration
- **Structured Responses**: Define JSON schema for consistent output formats

### Creating an Agent with YAML Configuration (Basic)

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;log&quot;
	&quot;os&quot;
	&quot;path/filepath&quot;
	&quot;strings&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/agent&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/openai&quot;
)

func main() {
	// Get OpenAI API key from environment
	apiKey := os.Getenv(&quot;OPENAI_API_KEY&quot;)
	if apiKey == &quot;&quot; {
		log.Fatal(&quot;OpenAI API key not provided. Set OPENAI_API_KEY environment variable.&quot;)
	}

	// Create the LLM client
	llm := openai.NewClient(apiKey)

	// Load agent configurations
	agentConfigs, err := agent.LoadAgentConfigsFromFile(&quot;agents.yaml&quot;)
	if err != nil {
		log.Fatalf(&quot;Failed to load agent configurations: %v&quot;, err)
	}

	// Load task configurations
	taskConfigs, err := agent.LoadTaskConfigsFromFile(&quot;tasks.yaml&quot;)
	if err != nil {
		log.Fatalf(&quot;Failed to load task configurations: %v&quot;, err)
	}

	// Create variables map for template substitution
	variables := map[string]string{
		&quot;topic&quot;: &quot;Artificial Intelligence&quot;,
	}

	// Create the agent for a specific task
	taskName := &quot;research_task&quot;
	agent, err := agent.CreateAgentForTask(taskName, agentConfigs, taskConfigs, variables, agent.WithLLM(llm))
	if err != nil {
		log.Fatalf(&quot;Failed to create agent for task: %v&quot;, err)
	}

	// Execute the task
	fmt.Printf(&quot;Executing task &#039;%s&#039; with topic &#039;%s&#039;...\n&quot;, taskName, variables[&quot;topic&quot;])
	result, err := agent.ExecuteTaskFromConfig(context.Background(), taskName, taskConfigs, variables)
	if err != nil {
		log.Fatalf(&quot;Failed to execute task: %v&quot;, err)
	}

	// Print the result
	fmt.Println(&quot;\nTask Result:&quot;)
	fmt.Println(result)
}
```

Example YAML configurations:

**agents.yaml**:
```yaml
researcher:
  role: &gt;
    {topic} Senior Data Researcher
  goal: &gt;
    Uncover cutting-edge developments in {topic}
  backstory: &gt;
    You&#039;re a seasoned researcher with a knack for uncovering the latest
    developments in {topic}. Known for your ability to find the most relevant
    information and present it in a clear and concise manner.

reporting_analyst:
  role: &gt;
    {topic} Reporting Analyst
  goal: &gt;
    Create detailed reports based on {topic} data analysis and research findings
  backstory: &gt;
    You&#039;re a meticulous analyst with a keen eye for detail. You&#039;re known for
    your ability to turn complex data into clear and concise reports, making
    it easy for others to understand and act on the information you provide.
```

**tasks.yaml**:
```yaml
research_task:
  description: &gt;
    Conduct a thorough research about {topic}
    Make sure you find any interesting and relevant information given
    the current year is 2025.
  expected_output: &gt;
    A list with 10 bullet points of the most relevant information about {topic}
  agent: researcher

reporting_task:
  description: &gt;
    Review the context you got and expand each topic into a full section for a report.
    Make sure the report is detailed and contains any and all relevant information.
  expected_output: &gt;
    A fully fledged report with the main topics, each with a full section of information.
    Formatted as markdown without &#039;```&#039;
  agent: reporting_analyst
  output_file: &quot;{topic}_report.md&quot;
```

### Structured Output with YAML Configuration

The SDK supports defining structured output (JSON responses) directly in YAML configuration files. This allows you to automatically apply structured output when creating agents from YAML and unmarshal responses directly into Go structs.

**agents.yaml with structured output**:
```yaml
researcher:
  role: &gt;
    {topic} Senior Data Researcher
  goal: &gt;
    Uncover cutting-edge developments in {topic}
  backstory: &gt;
    You&#039;re a seasoned researcher with a knack for uncovering the latest
    developments in {topic}. Known for your ability to find the most relevant
    information and present it in a clear and concise manner.
  response_format:
    type: &quot;json_object&quot;
    schema_name: &quot;ResearchResult&quot;
    schema_definition:
      type: &quot;object&quot;
      properties:
        findings:
          type: &quot;array&quot;
          items:
            type: &quot;object&quot;
            properties:
              title:
                type: &quot;string&quot;
                description: &quot;Title of the finding&quot;
              description:
                type: &quot;string&quot;
                description: &quot;Detailed description&quot;
              source:
                type: &quot;string&quot;
                description: &quot;Source of the information&quot;
        summary:
          type: &quot;string&quot;
          description: &quot;Executive summary of findings&quot;
        metadata:
          type: &quot;object&quot;
          properties:
            total_findings:
              type: &quot;integer&quot;
            research_date:
              type: &quot;string&quot;
```

**tasks.yaml with structured output**:
```yaml
research_task:
  description: &gt;
    Conduct a thorough research about {topic}
    Make sure you find any interesting and relevant information.
  expected_output: &gt;
    A structured JSON response with findings, summary, and metadata
  agent: researcher
  output_file: &quot;{topic}_report.json&quot;
  response_format:
    type: &quot;json_object&quot;
    schema_name: &quot;ResearchResult&quot;
    schema_definition:
      # Same schema as above
```

**Usage in Go code**:
```go
// Define your Go struct to match the YAML schema
type ResearchResult struct {
    Findings []struct {
        Title       string `json:&quot;title&quot;`
        Description string `json:&quot;description&quot;`
        Source      string `json:&quot;source&quot;`
    } `json:&quot;findings&quot;`
    Summary  string `json:&quot;summary&quot;`
    Metadata struct {
        TotalFindings int    `json:&quot;total_findings&quot;`
        ResearchDate  string `json:&quot;research_date&quot;`
    } `json:&quot;metadata&quot;`
}

// Create agent and execute task
agent, err := agent.CreateAgentForTask(&quot;research_task&quot;, agentConfigs, taskConfigs, variables, agent.WithLLM(llm))
result, err := agent.ExecuteTaskFromConfig(context.Background(), &quot;research_task&quot;, taskConfigs, variables)

// Unmarshal structured output
var structured ResearchResult
err = json.Unmarshal([]byte(result), &amp;structured)
```

For more details, see [Structured Output with YAML Configuration](docs/structured_output_yaml.md).

### Auto-Generating Agent Configurations

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;os&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/agent&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/config&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/openai&quot;
)

func main() {
	// Load configuration
	cfg := config.Get()

	// Create LLM client
	openaiClient := openai.NewClient(cfg.LLM.OpenAI.APIKey)

	// Create agent with auto-configuration from system prompt
	agent, err := agent.NewAgentWithAutoConfig(
		context.Background(),
		agent.WithLLM(openaiClient),
		agent.WithSystemPrompt(&quot;You are a travel advisor who helps users plan trips and vacations. You specialize in finding hidden gems and creating personalized itineraries based on travelers&#039; prefer

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[junegunn/fzf]]></title>
            <link>https://github.com/junegunn/fzf</link>
            <guid>https://github.com/junegunn/fzf</guid>
            <pubDate>Thu, 18 Dec 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[üå∏ A command-line fuzzy finder]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/junegunn/fzf">junegunn/fzf</a></h1>
            <p>üå∏ A command-line fuzzy finder</p>
            <p>Language: Go</p>
            <p>Stars: 75,972</p>
            <p>Forks: 2,641</p>
            <p>Stars today: 69 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;
  &lt;sup&gt;Special thanks to:&lt;/sup&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://tuple.app/fzf&quot;&gt;
    &lt;img alt=&quot;Tuple&#039;s sponsorship image&quot; src=&quot;https://raw.githubusercontent.com/junegunn/i/master/tuple.png&quot; width=&quot;400&quot;&gt;
  &lt;/a&gt;

### [Tuple, the premier screen sharing app for developers](https://tuple.app/fzf)
[Available for MacOS &amp; Windows](https://tuple.app/fzf)&lt;br&gt;

---

   &lt;sup&gt;Special thanks to:&lt;/sup&gt;
   &lt;br&gt;
   &lt;a href=&quot;https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=fzf&quot;&gt;
      &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd7ecac94eae&quot;&gt;
   &lt;/a&gt;

### [Warp, the intelligent terminal for developers](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=fzf)
[Available for MacOS, Linux, &amp; Windows](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=fzf)&lt;br&gt;

&lt;/div&gt;

---

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-color.png&quot; alt=&quot;fzf - a command-line fuzzy finder&quot;&gt;
  &lt;a href=&quot;https://github.com/junegunn/fzf/actions&quot;&gt;&lt;img src=&quot;https://github.com/junegunn/fzf/actions/workflows/linux.yml/badge.svg?branch=master&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;http://github.com/junegunn/fzf/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/tag/junegunn/fzf&quot; alt=&quot;Version&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/junegunn/fzf?tab=MIT-1-ov-file#readme&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/junegunn/fzf&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/junegunn/fzf/graphs/contributors&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/junegunn/fzf&quot; alt=&quot;Contributors&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/sponsors/junegunn&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/sponsors/junegunn&quot; alt=&quot;Sponsors&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/junegunn/fzf/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/junegunn/fzf?style=flat&quot; alt=&quot;Stars&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

---

fzf is a general-purpose command-line fuzzy finder.

&lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-preview.png&quot; width=640&gt;

It&#039;s an interactive filter program for any kind of list; files, command
history, processes, hostnames, bookmarks, git commits, etc. It implements
a &quot;fuzzy&quot; matching algorithm, so you can quickly type in patterns with omitted
characters and still get the results you want.

Highlights
----------

- **Portable** ‚Äî Distributed as a single binary for easy installation
- **Fast** ‚Äî Optimized to process millions of items instantly
- **Versatile** ‚Äî Fully customizable through an event-action binding mechanism
- **All-inclusive** ‚Äî Comes with integrations for Bash, Zsh, Fish, Vim, and Neovim

Table of Contents
-----------------

&lt;!-- vim-markdown-toc GFM --&gt;

* [Installation](#installation)
    * [Using Homebrew](#using-homebrew)
    * [Linux packages](#linux-packages)
    * [Windows packages](#windows-packages)
    * [Using git](#using-git)
    * [Binary releases](#binary-releases)
    * [Setting up shell integration](#setting-up-shell-integration)
    * [Vim/Neovim plugin](#vimneovim-plugin)
* [Upgrading fzf](#upgrading-fzf)
* [Building fzf](#building-fzf)
* [Usage](#usage)
    * [Using the finder](#using-the-finder)
    * [Display modes](#display-modes)
        * [`--height` mode](#--height-mode)
        * [`--tmux` mode](#--tmux-mode)
    * [Search syntax](#search-syntax)
    * [Environment variables](#environment-variables)
    * [Customizing the look](#customizing-the-look)
    * [Options](#options)
    * [Demo](#demo)
* [Examples](#examples)
* [Key bindings for command-line](#key-bindings-for-command-line)
* [Fuzzy completion for bash and zsh](#fuzzy-completion-for-bash-and-zsh)
    * [Files and directories](#files-and-directories)
    * [Process IDs](#process-ids)
    * [Host names](#host-names)
    * [Environment variables / Aliases](#environment-variables--aliases)
    * [Customizing fzf options for completion](#customizing-fzf-options-for-completion)
    * [Customizing completion source for paths and directories](#customizing-completion-source-for-paths-and-directories)
    * [Supported commands](#supported-commands)
    * [Custom fuzzy completion](#custom-fuzzy-completion)
* [Vim plugin](#vim-plugin)
* [Advanced topics](#advanced-topics)
    * [Customizing for different types of input](#customizing-for-different-types-of-input)
    * [Performance](#performance)
    * [Executing external programs](#executing-external-programs)
    * [Turning into a different process](#turning-into-a-different-process)
    * [Reloading the candidate list](#reloading-the-candidate-list)
        * [1. Update the list of processes by pressing CTRL-R](#1-update-the-list-of-processes-by-pressing-ctrl-r)
        * [2. Switch between sources by pressing CTRL-D or CTRL-F](#2-switch-between-sources-by-pressing-ctrl-d-or-ctrl-f)
        * [3. Interactive ripgrep integration](#3-interactive-ripgrep-integration)
    * [Preview window](#preview-window)
    * [Previewing an image](#previewing-an-image)
* [Tips](#tips)
    * [Respecting `.gitignore`](#respecting-gitignore)
    * [Fish shell](#fish-shell)
    * [fzf Theme Playground](#fzf-theme-playground)
* [Related projects](#related-projects)
* [License](#license)
* [Goods](#goods)
* [Sponsors :heart:](#sponsors-heart)

&lt;!-- vim-markdown-toc --&gt;

Installation
------------

### Using Homebrew

You can use [Homebrew](https://brew.sh/) (on macOS or Linux) to install fzf.

```sh
brew install fzf
```

&gt; [!IMPORTANT]
&gt; To set up shell integration (key bindings and fuzzy completion),
&gt; see [the instructions below](#setting-up-shell-integration).

fzf is also available [via MacPorts][portfile]: `sudo port install fzf`

[portfile]: https://github.com/macports/macports-ports/blob/master/sysutils/fzf/Portfile

### Linux packages

| Package Manager | Linux Distribution      | Command                            |
| --------------- | ----------------------- | ---------------------------------- |
| APK             | Alpine Linux            | `sudo apk add fzf`                 |
| APT             | Debian 9+/Ubuntu 19.10+ | `sudo apt install fzf`             |
| Conda           |                         | `conda install -c conda-forge fzf` |
| DNF             | Fedora                  | `sudo dnf install fzf`             |
| Nix             | NixOS, etc.             | `nix-env -iA nixpkgs.fzf`          |
| Pacman          | Arch Linux              | `sudo pacman -S fzf`               |
| pkg             | FreeBSD                 | `pkg install fzf`                  |
| pkgin           | NetBSD                  | `pkgin install fzf`                |
| pkg_add         | OpenBSD                 | `pkg_add fzf`                      |
| Portage         | Gentoo                  | `emerge --ask app-shells/fzf`      |
| Spack           |                         | `spack install fzf`                |
| XBPS            | Void Linux              | `sudo xbps-install -S fzf`         |
| Zypper          | openSUSE                | `sudo zypper install fzf`          |

&gt; [!IMPORTANT]
&gt; To set up shell integration (key bindings and fuzzy completion),
&gt; see [the instructions below](#setting-up-shell-integration).

[![Packaging status](https://repology.org/badge/vertical-allrepos/fzf.svg?columns=3)](https://repology.org/project/fzf/versions)

### Windows packages

On Windows, fzf is available via [Chocolatey][choco], [Scoop][scoop],
[Winget][winget], and [MSYS2][msys2]:

| Package manager | Command                               |
| --------------- | ------------------------------------- |
| Chocolatey      | `choco install fzf`                   |
| Scoop           | `scoop install fzf`                   |
| Winget          | `winget install fzf`                  |
| MSYS2 (pacman)  | `pacman -S $MINGW_PACKAGE_PREFIX-fzf` |

[choco]: https://chocolatey.org/packages/fzf
[scoop]: https://github.com/ScoopInstaller/Main/blob/master/bucket/fzf.json
[winget]: https://github.com/microsoft/winget-pkgs/tree/master/manifests/j/junegunn/fzf
[msys2]: https://packages.msys2.org/base/mingw-w64-fzf

### Using git

Alternatively, you can &quot;git clone&quot; this repository to any directory and run
[install](https://github.com/junegunn/fzf/blob/master/install) script.

```sh
git clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf
~/.fzf/install
```

The install script will add lines to your shell configuration file to modify
`$PATH` and set up shell integration.

### Binary releases

You can download the official fzf binaries from the releases page.

* https://github.com/junegunn/fzf/releases

### Setting up shell integration

Add the following line to your shell configuration file.

* bash
  ```sh
  # Set up fzf key bindings and fuzzy completion
  eval &quot;$(fzf --bash)&quot;
  ```
* zsh
  ```sh
  # Set up fzf key bindings and fuzzy completion
  source &lt;(fzf --zsh)
  ```
* fish
  ```fish
  # Set up fzf key bindings
  fzf --fish | source
  ```

&gt; [!NOTE]
&gt; `--bash`, `--zsh`, and `--fish` options are only available in fzf 0.48.0 or
&gt; later. If you have an older version of fzf, or want finer control, you can
&gt; source individual script files in the [/shell](/shell) directory. The
&gt; location of the files may vary depending on the package manager you use.
&gt; Please refer to the package documentation for more information.
&gt; (e.g. `apt show fzf`)

&gt; [!TIP]
&gt; You can disable CTRL-T, CTRL-R, or ALT-C bindings by setting the
&gt; corresponding `*_COMMAND` variable to an empty string when sourcing the
&gt; script. For example, to disable CTRL-R and ALT-C:
&gt;
&gt; * bash: `FZF_CTRL_R_COMMAND= FZF_ALT_C_COMMAND= eval &quot;$(fzf --bash)&quot;`
&gt; * zsh: `FZF_CTRL_R_COMMAND= FZF_ALT_C_COMMAND= source &lt;(fzf --zsh)`
&gt; * fish: `fzf --fish | FZF_CTRL_R_COMMAND= FZF_ALT_C_COMMAND= source`
&gt;
&gt; Setting the variables after sourcing the script will have no effect.

### Vim/Neovim plugin

If you use [vim-plug](https://github.com/junegunn/vim-plug), add this to
your Vim configuration file:

```vim
Plug &#039;junegunn/fzf&#039;, { &#039;do&#039;: { -&gt; fzf#install() } }
Plug &#039;junegunn/fzf.vim&#039;
```

* `junegunn/fzf` provides the basic library functions
    * `fzf#install()` makes sure that you have the latest binary
* `junegunn/fzf.vim` is [a separate project](https://github.com/junegunn/fzf.vim)
  that provides a variety of useful commands

To learn more about the Vim integration, see [README-VIM.md](README-VIM.md).

&gt; [!TIP]
&gt; If you use Neovim and prefer Lua-based plugins, check out
&gt; [fzf-lua](https://github.com/ibhagwan/fzf-lua).

Upgrading fzf
-------------

fzf is being actively developed, and you might want to upgrade it once in a
while. Please follow the instruction below depending on the installation
method used.

- git: `cd ~/.fzf &amp;&amp; git pull &amp;&amp; ./install`
- brew: `brew update; brew upgrade fzf`
- macports: `sudo port upgrade fzf`
- chocolatey: `choco upgrade fzf`
- vim-plug: `:PlugUpdate fzf`

Building fzf
------------

See [BUILD.md](BUILD.md).

Usage
-----

fzf will launch interactive finder, read the list from STDIN, and write the
selected item to STDOUT.

```sh
find * -type f | fzf &gt; selected
```

Without STDIN pipe, fzf will traverse the file system under the current
directory to get the list of files.

```sh
vim $(fzf)
```

&gt; [!NOTE]
&gt; You can override the default behavior
&gt; * Either by setting `$FZF_DEFAULT_COMMAND` to a command that generates the desired list
&gt; * Or by setting `--walker`, `--walker-root`, and `--walker-skip` options in `$FZF_DEFAULT_OPTS`

&gt; [!WARNING]
&gt; A more robust solution would be to use `xargs` but we&#039;ve presented
&gt; the above as it&#039;s easier to grasp
&gt; ```sh
&gt; fzf --print0 | xargs -0 -o vim
&gt; ```

&gt; [!TIP]
&gt; fzf also has the ability to turn itself into a different process.
&gt;
&gt; ```sh
&gt; fzf --bind &#039;enter:become(vim {})&#039;
&gt; ```
&gt;
&gt; *See [Turning into a different process](#turning-into-a-different-process)
&gt; for more information.*

### Using the finder

- `CTRL-K` / `CTRL-J` (or `CTRL-P` / `CTRL-N`) to move cursor up and down
- `Enter` key to select the item, `CTRL-C` / `CTRL-G` / `ESC` to exit
- On multi-select mode (`-m`), `TAB` and `Shift-TAB` to mark multiple items
- Emacs style key bindings
- Mouse: scroll, click, double-click; shift-click and shift-scroll on
  multi-select mode

### Display modes

fzf by default runs in fullscreen mode, but there are other display modes.

#### `--height` mode

With `--height HEIGHT[%]`, fzf will start below the cursor with the given height.

```sh
fzf --height 40%
```

`reverse` layout and `--border` goes well with this option.

```sh
fzf --height 40% --layout reverse --border
```

By prepending `~` to the height, you&#039;re setting the maximum height.

```sh
# Will take as few lines as possible to display the list
seq 3 | fzf --height ~100%
seq 3000 | fzf --height ~100%
```

Height value can be a negative number.

```sh
# Screen height - 3
fzf --height -3
```

#### `--tmux` mode

With `--tmux` option, fzf will start in a tmux popup.

```sh
# --tmux [center|top|bottom|left|right][,SIZE[%]][,SIZE[%][,border-native]]

fzf --tmux center         # Center, 50% width and height
fzf --tmux 80%            # Center, 80% width and height
fzf --tmux 100%,50%       # Center, 100% width and 50% height
fzf --tmux left,40%       # Left, 40% width
fzf --tmux left,40%,90%   # Left, 40% width, 90% height
fzf --tmux top,40%        # Top, 40% height
fzf --tmux bottom,80%,40% # Bottom, 80% width, 40% height
```

`--tmux` is silently ignored when you&#039;re not on tmux.

&gt; [!NOTE]
&gt; If you&#039;re stuck with an old version of tmux that doesn&#039;t support popup,
&gt; or if you want to open fzf in a regular tmux pane, check out
&gt; [fzf-tmux](bin/fzf-tmux) script.

&gt; [!TIP]
&gt; You can add these options to `$FZF_DEFAULT_OPTS` so that they&#039;re applied by
&gt; default. For example,
&gt;
&gt; ```sh
&gt; # Open in tmux popup if on tmux, otherwise use --height mode
&gt; export FZF_DEFAULT_OPTS=&#039;--height 40% --tmux bottom,40% --layout reverse --border top&#039;
&gt; ```

### Search syntax

Unless otherwise specified, fzf starts in &quot;extended-search mode&quot; where you can
type in multiple search terms delimited by spaces. e.g. `^music .mp3$ sbtrkt
!fire`

| Token     | Match type                              | Description                                  |
| --------- | --------------------------------------  | ------------------------------------------   |
| `sbtrkt`  | fuzzy-match                             | Items that match `sbtrkt`                    |
| `&#039;wild`   | exact-match (quoted)                    | Items that include `wild`                    |
| `&#039;wild&#039;`  | exact-boundary-match (quoted both ends) | Items that include `wild` at word boundaries |
| `^music`  | prefix-exact-match                      | Items that start with `music`                |
| `.mp3$`   | suffix-exact-match                      | Items that end with `.mp3`                   |
| `!fire`   | inverse-exact-match                     | Items that do not include `fire`             |
| `!^music` | inverse-prefix-exact-match              | Items that do not start with `music`         |
| `!.mp3$`  | inverse-suffix-exact-match              | Items that do not end with `.mp3`            |

If you don&#039;t prefer fuzzy matching and do not wish to &quot;quote&quot; every word,
start fzf with `-e` or `--exact` option. Note that when  `--exact` is set,
`&#039;`-prefix &quot;unquotes&quot; the term.

A single bar character term acts as an OR operator. For example, the following
query matches entries that start with `core` and end with either `go`, `rb`,
or `py`.

```
^core go$ | rb$ | py$
```

### Environment variables

- `FZF_DEFAULT_COMMAND`
    - Default command to use when input is tty
    - e.g. `export FZF_DEFAULT_COMMAND=&#039;fd --type f&#039;`
- `FZF_DEFAULT_OPTS`
    - Default options
    - e.g. `export FZF_DEFAULT_OPTS=&quot;--layout=reverse --inline-info&quot;`
- `FZF_DEFAULT_OPTS_FILE`
    - If you prefer to manage default options in a file, set this variable to
      point to the location of the file
    - e.g. `export FZF_DEFAULT_OPTS_FILE=~/.fzfrc`

&gt; [!WARNING]
&gt; `FZF_DEFAULT_COMMAND` is not used by shell integration due to the
&gt; slight difference in requirements.
&gt;
&gt; * `CTRL-T` runs `$FZF_CTRL_T_COMMAND` to get a list of files and directories
&gt; * `ALT-C` runs `$FZF_ALT_C_COMMAND` to get a list of directories
&gt; * `vim ~/**&lt;tab&gt;` runs `fzf_compgen_path()` with the prefix (`~/`) as the first argument
&gt; * `cd foo**&lt;tab&gt;` runs `fzf_compgen_dir()` with the prefix (`foo`) as the first argument
&gt;
&gt; The available options are described later in this document.

### Customizing the look

The user interface of fzf is fully customizable with a large number of
configuration options. For a quick setup, you can start with one of the style
presets ‚Äî `default`, `full`, or `minimal` ‚Äî using the `--style` option.

```sh
fzf --style full \
    --preview &#039;fzf-preview.sh {}&#039; --bind &#039;focus:transform-header:file --brief {}&#039;
```

| Preset    | Screenshot                                                                             |
| :---      | :---                                                                                   |
| `default` | &lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-style-default.png&quot;/&gt; |
| `full`    | &lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-style-full.png&quot;/&gt;    |
| `minimal` | &lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-style-minimal.png&quot;/&gt; |

Here&#039;s an example based on the `full` preset:

&lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-4-borders.png&quot;/&gt;

&lt;details&gt;

```sh
git ls-files | fzf --style full \
    --border --padding 1,2 \
    --border-label &#039; Demo &#039; --input-label &#039; Input &#039; --header-label &#039; File Type &#039; \
    --preview &#039;fzf-preview.sh {}&#039; \
    --bind &#039;result:transform-list-label:
        if [[ -z $FZF_QUERY ]]; then
          echo &quot; $FZF_MATCH_COUNT items &quot;
        else
          echo &quot; $FZF_MATCH_COUNT matches for [$FZF_QUERY] &quot;
        fi
        &#039; \
    --bind &#039;focus:transform-preview-label:[[ -n {} ]] &amp;&amp; printf &quot; Previewing [%s] &quot; {}&#039; \
    --bind &#039;focus:+transform-header:file --brief {} || echo &quot;No file selected&quot;&#039; \
    --bind &#039;ctrl-r:change-list-label( Reloading the list )+reload(sleep 2; git ls-files)&#039; \
    --color &#039;border:#aaaaaa,label:#cccccc&#039; \
    --color &#039;preview-border:#9999cc,preview-label:#ccccff&#039; \
    --color &#039;list-border:#669966,list-label:#99cc99&#039; \
    --color &#039;input-border:#996666,input-label:#ffcccc&#039; \
    --color &#039;header-border:#6699cc,header-label:#99ccff&#039;
```

&lt;/details&gt;

### Options

See the man page (`fzf --man` or `man fzf`) for the full list of options.

### Demo
If you learn by watching videos, check out this screencast by [@samoshkin](https://github.com/samoshkin) to explore `fzf` features.

&lt;a title=&quot;fzf - command-line fuzzy finder&quot; href=&quot;https://www.youtube.com/watch?v=qgG5Jhi_Els&quot;&gt;
  &lt;img src=&quot;https://i.imgur.com/vtG8olE.png&quot; width=&quot;640&quot;&gt;
&lt;/a&gt;

Examples
--------

* [Wiki page of examples](https://github.com/junegunn/fzf/wiki/examples)
    * *Disclaimer: The examples on this page are maintained by the community
      and are not thoroughly tested*
* [Advanced fzf examples](https://github.com/junegunn/fzf/blob/master/ADVANCED.md)

Key bindings for command-line
-----------------------------

By [setting up shell integration](#setting-up-shell-integration), you can use
the following key bindings in bash, zsh, and fish.

- `CTRL-T` - Paste the selected files and directories onto the command-line
    - The list is generated using `--walker file,dir,follow,hidden` option
        - You can override the behavior by setting `FZF_CTRL_T_COMMAND` to a custom command that generates the desired list
        - Or you can set `--walker*` options in `FZF_CTRL_T_OPTS`
    - Set `FZF_CTRL_T_OPTS` to pass additional options to fzf
      ```sh
      # Preview file content using bat (https://github.com/sharkdp/bat)
      export FZF_CTRL_T_OPTS=&quot;
        --walker-skip .git,node_modules,target
        --preview &#039;bat -n --color=always {}&#039;
        --bind &#039;ctrl-/:change-preview-window(down|hidden|)&#039;&quot;
      ```
    - Ca

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[expr-lang/expr]]></title>
            <link>https://github.com/expr-lang/expr</link>
            <guid>https://github.com/expr-lang/expr</guid>
            <pubDate>Thu, 18 Dec 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[Expression language and expression evaluation for Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/expr-lang/expr">expr-lang/expr</a></h1>
            <p>Expression language and expression evaluation for Go</p>
            <p>Language: Go</p>
            <p>Stars: 7,523</p>
            <p>Forks: 473</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;&lt;a href=&quot;https://expr-lang.org&quot;&gt;&lt;img src=&quot;https://expr-lang.org/img/logo.png&quot; alt=&quot;Zx logo&quot; height=&quot;48&quot;align=&quot;right&quot;&gt;&lt;/a&gt; Expr&lt;/h1&gt;

&gt; [!IMPORTANT]
&gt; The repository [github.com/antonmedv/expr](https://github.com/antonmedv/expr) moved to [github.com/**expr-lang**/expr](https://github.com/expr-lang/expr).

[![test](https://github.com/expr-lang/expr/actions/workflows/test.yml/badge.svg)](https://github.com/expr-lang/expr/actions/workflows/test.yml) 
[![Go Report Card](https://goreportcard.com/badge/github.com/expr-lang/expr)](https://goreportcard.com/report/github.com/expr-lang/expr) 
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/expr.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:expr)
[![GoDoc](https://godoc.org/github.com/expr-lang/expr?status.svg)](https://godoc.org/github.com/expr-lang/expr)

**Expr** is a Go-centric expression language designed to deliver dynamic configurations with unparalleled accuracy, safety, and speed. 
**Expr** combines simple [syntax](https://expr-lang.org/docs/language-definition) with powerful features for ease of use:

```js
// Allow only admins and moderators to moderate comments.
user.Group in [&quot;admin&quot;, &quot;moderator&quot;] || user.Id == comment.UserId
```

```js
// Determine whether the request is in the permitted time window.
request.Time - resource.Age &lt; duration(&quot;24h&quot;)
```

```js
// Ensure all tweets are less than 240 characters.
all(tweets, len(.Content) &lt;= 240)
```

## Features

**Expr** is a safe, fast, and intuitive expression evaluator optimized for the Go language. 
Here are its standout features:

### Safety and Isolation
* **Memory-Safe**: Expr is designed with a focus on safety, ensuring that programs do not access unrelated memory or introduce memory vulnerabilities.
* **Side-Effect-Free**: Expressions evaluated in Expr only compute outputs from their inputs, ensuring no side-effects that can change state or produce unintended results.
* **Always Terminating**: Expr is designed to prevent infinite loops, ensuring that every program will conclude in a reasonable amount of time.

### Go Integration
* **Seamless with Go**: Integrate Expr into your Go projects without the need to redefine types.

### Static Typing
* Ensures type correctness and prevents runtime type errors.
  ```go
  out, err := expr.Compile(`name + age`)
  // err: invalid operation + (mismatched types string and int)
  // | name + age
  // | .....^
  ```

### User-Friendly
* Provides user-friendly error messages to assist with debugging and development.

### Flexibility and Utility
* **Rich Operators**: Offers a reasonable set of basic operators for a variety of applications.
* **Built-in Functions**: Functions like `all`, `none`, `any`, `one`, `filter`, and `map` are provided out-of-the-box.

### Performance
* **Optimized for Speed**: Expr stands out in its performance, utilizing an optimizing compiler and a bytecode virtual machine. Check out these [benchmarks](https://github.com/antonmedv/golang-expression-evaluation-comparison#readme) for more details.

## Install

```
go get github.com/expr-lang/expr
```

## Documentation

* See [Getting Started](https://expr-lang.org/docs/Getting-Started) page for developer documentation.
* See [Language Definition](https://expr-lang.org/docs/language-definition) page to learn the syntax.

## Examples

[Play Online](https://go.dev/play/p/XCoNXEjm3TS)

```go
package main

import (
	&quot;fmt&quot;
	&quot;github.com/expr-lang/expr&quot;
)

func main() {
	env := map[string]interface{}{
		&quot;greet&quot;:   &quot;Hello, %v!&quot;,
		&quot;names&quot;:   []string{&quot;world&quot;, &quot;you&quot;},
		&quot;sprintf&quot;: fmt.Sprintf,
	}

	code := `sprintf(greet, names[0])`

	program, err := expr.Compile(code, expr.Env(env))
	if err != nil {
		panic(err)
	}

	output, err := expr.Run(program, env)
	if err != nil {
		panic(err)
	}

	fmt.Println(output)
}
```

[Play Online](https://go.dev/play/p/tz-ZneBfSuw)

```go
package main

import (
	&quot;fmt&quot;
	&quot;github.com/expr-lang/expr&quot;
)

type Tweet struct {
	Len int
}

type Env struct {
	Tweets []Tweet
}

func main() {
	code := `all(Tweets, {.Len &lt;= 240})`

	program, err := expr.Compile(code, expr.Env(Env{}))
	if err != nil {
		panic(err)
	}

	env := Env{
		Tweets: []Tweet{{42}, {98}, {69}},
	}
	output, err := expr.Run(program, env)
	if err != nil {
		panic(err)
	}

	fmt.Println(output)
}
```

## Who uses Expr?

* [Google](https://google.com) uses Expr as one of its expression languages on the [Google Cloud Platform](https://cloud.google.com).
* [Uber](https://uber.com) uses Expr to allow customization of its Uber Eats marketplace.
* [GoDaddy](https://godaddy.com) employs Expr for the customization of its GoDaddy Pro product.
* [ByteDance](https://bytedance.com) incorporates Expr into its internal business rule engine.
* [Aviasales](https://aviasales.ru) utilizes Expr as a business rule engine for its flight search engine.
* [Alibaba](https://alibaba.com) uses Expr in a web framework for building recommendation services.
* [Argo](https://argoproj.github.io) integrates Expr into Argo Rollouts and Argo Workflows for Kubernetes.
* [Wish.com](https://www.wish.com) employs Expr in its decision-making rule engine for the Wish Assistant.
* [OpenTelemetry](https://opentelemetry.io) integrates Expr into the OpenTelemetry Collector.
* [Philips Labs](https://github.com/philips-labs/tabia) employs Expr in Tabia, a tool designed to collect insights on their code bases.
* [CrowdSec](https://crowdsec.net) incorporates Expr into its security automation tool.
* [CoreDNS](https://coredns.io) uses Expr in CoreDNS, which is a DNS server.
* [qiniu](https://www.qiniu.com) implements Expr in its trade systems.
* [Junglee Games](https://www.jungleegames.com/) uses Expr for its in-house marketing retention tool, Project Audience.
* [Faceit](https://www.faceit.com) uses Expr to enhance customization of its eSports matchmaking algorithm.
* [Chaos Mesh](https://chaos-mesh.org) incorporates Expr into Chaos Mesh, a cloud-native Chaos Engineering platform.
* [Visually.io](https://visually.io) employs Expr as a business rule engine for its personalization targeting algorithm.
* [Akvorado](https://github.com/akvorado/akvorado) utilizes Expr to classify exporters and interfaces in network flows.
* [keda.sh](https://keda.sh) uses Expr to allow customization of its Kubernetes-based event-driven autoscaling.
* [Span Digital](https://spandigital.com/) uses Expr in its Knowledge Management products.
* [Xiaohongshu](https://www.xiaohongshu.com/) combining yaml with Expr for dynamically policies delivery.
* [Melr≈çse](https://melr≈çse.org) uses Expr to implement its music programming language.
* [Tork](https://www.tork.run/) integrates Expr into its workflow execution.
* [Critical Moments](https://criticalmoments.io) uses Expr for its mobile realtime conditional targeting system.
* [WoodpeckerCI](https://woodpecker-ci.org) uses Expr for [filtering workflows/steps](https://woodpecker-ci.org/docs/usage/workflow-syntax#evaluate).
* [FastSchema](https://github.com/fastschema/fastschema) - A BaaS leveraging Expr for its customizable and dynamic Access Control system.
* [WunderGraph Cosmo](https://github.com/wundergraph/cosmo) - GraphQL Federeration Router uses Expr to customize Middleware behaviour
* [SOLO](https://solo.one) uses Expr interally to allow dynamic code execution with custom defined functions.
* [Naoma.AI](https://www.naoma.ai) uses Expr as a part of its call scoring engine.

[Add your company too](https://github.com/expr-lang/expr/edit/master/README.md)

## License

[MIT](https://github.com/expr-lang/expr/blob/master/LICENSE)

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://expr-lang.org/img/gopher-small.png&quot; width=&quot;150&quot; /&gt;&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[oauth2-proxy/oauth2-proxy]]></title>
            <link>https://github.com/oauth2-proxy/oauth2-proxy</link>
            <guid>https://github.com/oauth2-proxy/oauth2-proxy</guid>
            <pubDate>Thu, 18 Dec 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oauth2-proxy/oauth2-proxy">oauth2-proxy/oauth2-proxy</a></h1>
            <p>A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.</p>
            <p>Language: Go</p>
            <p>Stars: 13,461</p>
            <p>Forks: 1,959</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>[![Continuous Integration](https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml/badge.svg)](https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml)
[![Go Report Card](https://goreportcard.com/badge/github.com/oauth2-proxy/oauth2-proxy)](https://goreportcard.com/report/github.com/oauth2-proxy/oauth2-proxy)
[![GoDoc](https://godoc.org/github.com/oauth2-proxy/oauth2-proxy?status.svg)](https://godoc.org/github.com/oauth2-proxy/oauth2-proxy)
[![MIT licensed](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)
[![Maintainability](https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/maintainability)](https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/maintainability)
[![Test Coverage](https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/test_coverage)](https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/test_coverage)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Foauth2-proxy%2Foauth2-proxy.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Foauth2-proxy%2Foauth2-proxy?ref=badge_shield)

![OAuth2 Proxy](docs/static/img/logos/OAuth2_Proxy_horizontal.svg)

OAuth2-Proxy is a flexible, open-source tool that can act as either a standalone reverse proxy or a middleware component integrated into existing reverse proxy or load balancer setups. It provides a simple and secure way to protect your web applications with OAuth2 / OIDC authentication. As a reverse proxy, it intercepts requests to your application and redirects users to an OAuth2 provider for authentication. As a middleware, it can be seamlessly integrated into your existing infrastructure to handle authentication for multiple applications.

OAuth2-Proxy supports a lot of OAuth2 as well as OIDC providers. Either through a generic OIDC client or a specific implementation for Google, Microsoft Entra ID, GitHub, login.gov and others. Through specialised provider implementations oauth2-proxy can extract more details about the user like preferred usernames and groups. Those details can then be forwarded as HTTP headers to your upstream applications.

![Simplified Architecture](docs/static/img/simplified-architecture.svg)

## Get Started

OAuth2-Proxy&#039;s [Installation Docs](https://oauth2-proxy.github.io/oauth2-proxy/installation) cover how to install and configure your setup. Additionally you can take a further look at the [example setup files](https://github.com/oauth2-proxy/oauth2-proxy/tree/master/contrib/local-environment).

## Releases

### Binaries
We publish oauth2-proxy as compiled binaries on GitHub for all major architectures as well as more exotic ones like `ppc64le` as well as `s390x`.

Check out the [latest release](https://github.com/oauth2-proxy/oauth2-proxy/releases/latest).

### Images

From `v7.6.0` and up the base image has been changed from Alpine to [GoogleContainerTools/distroless](https://github.com/GoogleContainerTools/distroless).
This image comes with even fewer installed dependencies and thus should improve security. The image therefore is also slightly smaller than Alpine.
For debugging purposes (and those who really need it. e.g. `armv6`) we still provide images based on Alpine. The tags of these images are suffixed with `-alpine`.

Since 2023-11-18 we build nightly images directly from the `master` branch and provide them at `quay.io/oauth2-proxy/oauth2-proxy-nightly`.
These images are considered unstable and therefore should **NOT** be used for production purposes unless you know what you&#039;re doing.

## Sponsors

![Microsoft](https://upload.wikimedia.org/wikipedia/commons/9/96/Microsoft_logo_%282012%29.svg)
Microsoft Azure credits for open source projects

Would you like to sponsor the project then please contact us at [sponsors@oauth2-proxy.dev](mailto:sponsors@oauth2-proxy.dev)

## Getting Involved
[![Slack](https://img.shields.io/badge/slack-Gopher_%23oauth2--proxy-red?logo=slack)](https://gophers.slack.com/archives/CM2RSS25N)

Join the #oauth2-proxy [Slack channel](https://gophers.slack.com/archives/CM2RSS25N) to chat with other users of oauth2-proxy or reach out to the maintainers directly. Use the [public invite link](https://invite.slack.golangbridge.org/) to get an invite for the Gopher Slack space.

OAuth2-Proxy is a community-driven project. We rely on the contributÔ∏èions of our users to continually improve it. While review times can vary, we appreciate your patience and understanding. As a volunteer-driven project, we strive to keep this project stable and might take longer to merge changes.

If you want to contribute to the project. Please see our [Contributing](https://oauth2-proxy.github.io/oauth2-proxy/community/contribution) guide.

Who uses OAuth2-Proxy? Have a look at our new [ADOPTERS](ADOPTERS.md) file and
feel free to open a PR to add your organisation.

Thanks to all the people who already contributed ‚ù§

&lt;a href=&quot;https://github.com/oauth2-proxy/oauth2-proxy/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=oauth2-proxy/oauth2-proxy&amp;columns=15&amp;max=75&quot; /&gt;
  &lt;img src=&quot;https://img.shields.io/github/contributors/oauth2-proxy/oauth2-proxy&quot; /&gt;
&lt;/a&gt;

Made with [contrib.rocks](https://contrib.rocks).

## Security

If you believe you have found a vulnerability within OAuth2 Proxy or any of its dependencies, please do **NOT** open an issue or PR on GitHub, please do **NOT** post any details publicly.

Security disclosures **MUST** be done in private. If you have found an issue that you would like to bring to the attention of the maintainers, please compose an email and send it to the list of people listed in our [MAINTAINERS](MAINTAINERS) file.

For more details read our full [Security Docs](https://oauth2-proxy.github.io/oauth2-proxy/community/security#security-disclosures)

### Security Notice for v6.0.0 and older

If you are running a version older than v6.0.0 we **strongly recommend** to the current version.

See [open redirect vulnerability](https://github.com/oauth2-proxy/oauth2-proxy/security/advisories/GHSA-5m6c-jp6f-2vcv) for details.

## Repository History

**2018-11-27:** This repository was forked from [bitly/OAuth2_Proxy](https://github.com/bitly/oauth2_proxy). Versions v3.0.0 and up are from this fork and will have diverged from any changes in the original fork. A list of changes can be seen in the [CHANGELOG](CHANGELOG.md).

**2020-03-29:** This project was formerly hosted as `pusher/oauth2_proxy` but has been renamed to `oauth2-proxy/oauth2-proxy`. Going forward, all images shall be available at `quay.io/oauth2-proxy/oauth2-proxy` and binaries will be named `oauth2-proxy`.

## License

OAuth2-Proxy is distributed under [The MIT License](LICENSE).


[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Foauth2-proxy%2Foauth2-proxy.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Foauth2-proxy%2Foauth2-proxy?ref=badge_large)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-collector]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-collector</link>
            <guid>https://github.com/open-telemetry/opentelemetry-collector</guid>
            <pubDate>Thu, 18 Dec 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[OpenTelemetry Collector]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-collector">open-telemetry/opentelemetry-collector</a></h1>
            <p>OpenTelemetry Collector</p>
            <p>Language: Go</p>
            <p>Stars: 6,425</p>
            <p>Forks: 1,810</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>---

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/getting-started/&quot;&gt;Getting Started&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;Getting Involved&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;Getting In Touch&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/actions/workflows/build-and-test.yml?query=branch%3Amain&quot;&gt;
    &lt;img alt=&quot;Build Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector/build-and-test.yml?branch=main&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector&quot;&gt;
    &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/open-telemetry/opentelemetry-collector/branch/main/&quot;&gt;
    &lt;img alt=&quot;Codecov Status&quot; src=&quot;https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest by date including pre-releases)&quot; src=&quot;https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector?include_prereleases&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;/br&gt;
  &lt;a href=&quot;https://www.bestpractices.dev/projects/8404&quot;&gt;&lt;img src=&quot;https://www.bestpractices.dev/projects/8404/badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:opentelemetry&quot;&gt;
    &lt;img alt=&quot;Fuzzing Status&quot; src=&quot;https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry.svg&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;docs/vision.md&quot;&gt;Vision&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/configuration/&quot;&gt;Configuration&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/internal-telemetry/#use-internal-telemetry-to-monitor-the-collector&quot;&gt;Monitoring&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;docs/security-best-practices.md&quot;&gt;Security&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://pkg.go.dev/go.opentelemetry.io/collector&quot;&gt;Package&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

---

# &lt;img src=&quot;https://opentelemetry.io/img/logos/opentelemetry-logo-nav.png&quot; alt=&quot;OpenTelemetry Icon&quot; width=&quot;45&quot; height=&quot;&quot;&gt; OpenTelemetry Collector

The OpenTelemetry Collector offers a vendor-agnostic implementation on how to
receive, process and export telemetry data. In addition, it removes the need
to run, operate and maintain multiple agents/collectors in order to support
open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) to
multiple open-source or commercial back-ends.

Objectives:

- Usable: Reasonable default configuration, supports popular protocols, runs and collects out of the box.
- Performant: Highly stable and performant under varying loads and configurations.
- Observable: An exemplar of an observable service.
- Extensible: Customizable without touching the core code.
- Unified: Single codebase, deployable as an agent or collector with support for traces, metrics and logs.

## Community

The OpenTelemetry Collector SIG is present at the [#otel-collector](https://cloud-native.slack.com/archives/C01N6P7KR6W)
channel on the CNCF Slack and [meets once a week](https://github.com/open-telemetry/community#implementation-sigs) via
video calls. Everyone is invited to join those calls, which typically serves the following purposes:

- meet the humans behind the project
- get an opinion about specific proposals
- look for a sponsor for a proposed component after trying already via GitHub and Slack
- get attention to a specific pull-request that got stuck and is difficult to discuss asynchronously

We rotate our video calls between three time slots, in order to
allow everyone to join at least once every three meetings. The rotation order is as follows:

Tuesday:

- [17:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=1700)

Wednesday:

- [09:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=0900)
- [05:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=0500)

Contributors to the project are also welcome to have ad-hoc meetings for synchronous discussions about specific points.
Post a note in #otel-collector-dev on Slack inviting others, specifying the topic to be discussed. Unless there are strong
reasons to keep the meeting private, please make it an open invitation for other contributors to join. Try also to
identify who would be the other contributors interested on that topic and in which timezones they are.

Remember that our source of truth is GitHub: every decision made via Slack or video calls has to be recorded in the
relevant GitHub issue. Ideally, the agenda items from the meeting notes would include a link to the issue or pull
request where a discussion is happening already. We acknowledge that not everyone can join Slack or the synchronous
calls and don&#039;t want them to feel excluded.

## Supported OTLP version

This code base is currently built against using OTLP protocol v1.5.0,
considered Stable. [See the OpenTelemetry Protocol Stability
definition
here.](https://github.com/open-telemetry/opentelemetry-proto?tab=readme-ov-file#stability-definition)

## Stability levels

See [Stability Levels and versioning](docs/component-stability.md) for more details.

## Compatibility

When used as a library, the OpenTelemetry Collector attempts to track the currently supported versions of Go, as [defined by the Go team](https://go.dev/doc/devel/release#policy).
Removing support for an unsupported Go version is not considered a breaking change.

Support for Go versions on the OpenTelemetry Collector is updated as follows:

1. The first release after the release of a new Go minor version `N` will add build and tests steps for the new Go minor version.
2. The first release after the release of a new Go minor version `N` will remove support for Go version `N-2`.

Official OpenTelemetry Collector distro binaries will be built with a release in the latest Go minor version series.

## Verifying the images signatures

&gt; [!NOTE]
&gt; To verify a signed artifact or blob, first [install Cosign](https://docs.sigstore.dev/cosign/system_config/installation/), then follow the instructions below.

We are signing the images `otel/opentelemetry-collector` and `otel/opentelemetry-collector-contrib` using [sigstore cosign](https://github.com/sigstore/cosign) tool and to verify the signatures you can run the following command:

```console
$ cosign verify \
  --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/&lt;RELEASE_TAG&gt; \
  --certificate-oidc-issuer=https://token.actions.githubusercontent.com \
  &lt;OTEL_COLLECTOR_IMAGE&gt;
```

where:

- `&lt;RELEASE_TAG&gt;`: is the release that you want to validate
- `&lt;OTEL_COLLECTOR_IMAGE&gt;`: is the image that you want to check

Example:

```console
$ cosign verify --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0 --certificate-oidc-issuer=https://token.actions.githubusercontent.com ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0

Verification for ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0 --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - Existence of the claims in the transparency log was verified offline
  - The code-signing certificate was verified using trusted certificate authority certificates

[{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:{&quot;1.3.6.1.4.1.57264.1.1&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;1.3.6.1.4.1.57264.1.2&quot;:&quot;push&quot;,&quot;1.3.6.1.4.1.57264.1.3&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;1.3.6.1.4.1.57264.1.4&quot;:&quot;Release Contrib&quot;,&quot;1.3.6.1.4.1.57264.1.5&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;1.3.6.1.4.1.57264.1.6&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;Bundle&quot;:{&quot;SignedEntryTimestamp&quot;:&quot;MEUCIQDdlmNeKXQrHnonwWiHLhLLwFDVDNoOBCn2sv85J9P8mgIgDQFssWJImo1hn38VlojvSCL7Qq5FMmtnGu0oLsNdOm8=&quot;,&quot;Payload&quot;:{&quot;body&quot;:&quot;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&quot;,&quot;integratedTime&quot;:1712809120,&quot;logIndex&quot;:84797936,&quot;logID&quot;:&quot;c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d&quot;}},&quot;Issuer&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;Subject&quot;:&quot;https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0&quot;,&quot;githubWorkflowName&quot;:&quot;Release Contrib&quot;,&quot;githubWorkflowRef&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;githubWorkflowRepository&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;githubWorkflowSha&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;githubWorkflowTrigger&quot;:&quot;push&quot;}},{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:{&quot;1.3.6.1.4.1.57264.1.1&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;1.3.6.1.4.1.57264.1.2&quot;:&quot;push&quot;,&quot;1.3.6.1.4.1.57264.1.3&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;1.3.6.1.4.1.57264.1.4&quot;:&quot;Release Contrib&quot;,&quot;1.3.6.1.4.1.57264.1.5&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;1.3.6.1.4.1.57264.1.6&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;Bundle&quot;:{&quot;SignedEntryTimestamp&quot;:&quot;MEUCIQD1ehDnPO6fzoPIpeQ3KFuYHHBiX7RcEbpo9B2r7JAlzwIgZ1bsuQz7gAXbNU1IEdsTQgfAnRk3xVXO16GnKXM2sAQ=&quot;,&quot;Payload&quot;:{&quot;body&quot;:&quot;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

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[k3s-io/k3s]]></title>
            <link>https://github.com/k3s-io/k3s</link>
            <guid>https://github.com/k3s-io/k3s</guid>
            <pubDate>Thu, 18 Dec 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[Lightweight Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/k3s-io/k3s">k3s-io/k3s</a></h1>
            <p>Lightweight Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 31,618</p>
            <p>Forks: 2,554</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>K3s - Lightweight Kubernetes
===============================================
[![FOSSA Status](https://app.fossa.com/api/projects/custom%2B25850%2Fgithub.com%2Fk3s-io%2Fk3s.svg?type=shield)](https://app.fossa.com/projects/custom%2B25850%2Fgithub.com%2Fk3s-io%2Fk3s?ref=badge_shield)
[![Nightly CI](https://github.com/k3s-io/k3s/actions/workflows/nightly-install.yaml/badge.svg)](https://github.com/k3s-io/k3s/actions/workflows/nightly-install.yaml)
[![Build Status](https://drone-publish.k3s.io/api/badges/k3s-io/k3s/status.svg)](https://drone-publish.k3s.io/k3s-io/k3s)
[![Integration Test Coverage](https://github.com/k3s-io/k3s/actions/workflows/integration.yaml/badge.svg)](https://github.com/k3s-io/k3s/actions/workflows/integration.yaml)
[![Unit Test Coverage](https://github.com/k3s-io/k3s/actions/workflows/unitcoverage.yaml/badge.svg)](https://github.com/k3s-io/k3s/actions/workflows/unitcoverage.yaml)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/6835/badge)](https://www.bestpractices.dev/projects/6835)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/k3s-io/k3s/badge)](https://scorecard.dev/viewer/?uri=github.com/k3s-io/k3s)
[![Releases](https://img.shields.io/github/downloads/k3s-io/k3s/total.svg)](https://github.com/k3s-io/k3s/tags?label=Downloads)
[![CLOMonitor](https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/k3s/badge)](https://clomonitor.io/projects/cncf/k3s)

Lightweight Kubernetes.  Production ready, easy to install, half the memory, all in a binary less than 100 MB.

Great for:

* Edge
* IoT
* CI
* Development
* ARM
* Embedding k8s
* Situations where a PhD in k8s clusterology is infeasible

What is this?
---

K3s is a [fully conformant](https://github.com/cncf/k8s-conformance/pulls?q=is%3Apr+k3s) production-ready Kubernetes distribution with the following changes:

1. It is packaged as a single binary.
1. It adds support for sqlite3 as the default storage backend. Etcd3, MariaDB, MySQL, and Postgres are also supported.
1. It wraps Kubernetes and other components in a single, simple launcher.
1. It is secure by default with reasonable defaults for lightweight environments.
1. It has minimal to no OS dependencies (just a sane kernel and cgroup mounts needed).
1. It eliminates the need to expose a port on Kubernetes worker nodes for the kubelet API by exposing this API to the Kubernetes control plane nodes over a websocket tunnel.

K3s bundles the following technologies together into a single cohesive distribution:

* [Containerd](https://containerd.io/) &amp; [runc](https://github.com/opencontainers/runc)
* [Flannel](https://github.com/flannel-io/flannel) for CNI
* [CoreDNS](https://coredns.io/)
* [Metrics Server](https://github.com/kubernetes-sigs/metrics-server)
* [Traefik](https://containo.us/traefik/) for ingress
* [Klipper-lb](https://github.com/k3s-io/klipper-lb) as an embedded service load balancer provider
* [Kube-router](https://www.kube-router.io/) netpol controller for network policy
* [Helm-controller](https://github.com/k3s-io/helm-controller) to allow for CRD-driven deployment of helm manifests
* [Kine](https://github.com/k3s-io/kine) as a datastore shim that allows etcd to be replaced with other databases
* [Local-path-provisioner](https://github.com/rancher/local-path-provisioner) for provisioning volumes using local storage
* [Host utilities](https://github.com/k3s-io/k3s-root) such as iptables/nftables, ebtables, ethtool, &amp; socat

These technologies can be disabled or swapped out for technologies of your choice.

Additionally, K3s simplifies Kubernetes operations by maintaining functionality for:

* Managing the TLS certificates of Kubernetes components
* Managing the connection between worker and server nodes
* Auto-deploying Kubernetes resources from local manifests in realtime as they are changed.
* Managing an embedded etcd cluster

What&#039;s with the name?
--------------------

We wanted an installation of Kubernetes that was half the size in terms of memory footprint. Kubernetes is a
10 letter word stylized as k8s. So something half as big as Kubernetes would be a 5 letter word stylized as
K3s. A &#039;3&#039; is also an &#039;8&#039; cut in half vertically. There is neither a long-form of K3s nor official pronunciation.

Is this a fork?
---------------

No, it&#039;s a distribution. A fork implies continued divergence from the original. This is not K3s&#039;s goal or practice. K3s explicitly intends not to change any core Kubernetes functionality. We seek to remain as close to upstream Kubernetes as possible. However, we maintain a small set of patches (well under 1000 lines) important to K3s&#039;s use case and deployment model. We maintain patches for other components as well. When possible, we contribute these changes back to the upstream projects, for example, with [SELinux support in containerd](https://github.com/containerd/cri/pull/1487/commits/24209b91bf361e131478d15cfea1ab05694dc3eb). This is a common practice amongst software distributions.

K3s is a distribution because it packages additional components and services necessary for a fully functional cluster that go beyond vanilla Kubernetes. These are opinionated choices on technologies for components like ingress, storage class, network policy, service load balancer, and even container runtime. These choices and technologies are touched on in more detail in the [What is this?](#what-is-this) section.

How is this lightweight or smaller than upstream Kubernetes?
---

There are two major ways that K3s is lighter weight than upstream Kubernetes:
1. The memory footprint to run it is smaller
2. The binary, which contains all the non-containerized components needed to run a cluster, is smaller

The memory footprint is reduced primarily by running many components inside of a single process. This eliminates significant overhead that would otherwise be duplicated for each component.

The binary is smaller by removing third-party storage drivers and cloud providers, explained in more detail below.

What have you removed from upstream Kubernetes?
---

This is a common point of confusion because it has changed over time. Early versions of K3s had much more removed than the current version. K3s currently removes two things:

1. In-tree storage drivers
1. In-tree cloud provider

Both of these have out-of-tree alternatives in the form of [CSI](https://github.com/container-storage-interface/spec/blob/master/spec.md) and [CCM](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/), which work in K3s and which upstream is moving towards.

We remove these to achieve a smaller binary size. They can be removed while remaining conformant because neither affects core Kubernetes functionality. They are also dependent on third-party cloud or data center technologies/services, which may not be available in many K3s&#039; use cases.

Getting Started
---
- [Quick Install](https://docs.k3s.io/quick-start)
- [Architecture](https://docs.k3s.io/architecture)
- [FAQ](https://docs.k3s.io/faq)
- [Contribute](CONTRIBUTING.md)

Community
---
- ### Slack

Join [Slack](https://slack.rancher.io/) to chat with K3s developers and other K3s users. Great place to learn and ask questions: [#k3s](https://rancher-users.slack.com/archives/CGGQEHPPW) and [#k3s-contributor](https://rancher-users.slack.com/archives/CGXR87T8B) and [#k3s](https://cloud-native.slack.com/archives/C0196ULKX8S) channel in [CNCF Slack](https://cloud-native.slack.com)

- ### Getting involved
[GitHub Issues](https://github.com/k3s-io/k3s/issues) - Submit your issues and feature requests via GitHub.

- ### Community Meetings and Office hours
The K3s developer community hangs out on Zoom to chat. Everybody is welcome.

**Add the [Linux Foundation iCal](https://webcal.prod.itx.linuxfoundation.org/lfx/a092M00001IkYIjQAN) to your calendar**: 
- AMS/EMEA TZ 10:00 am PST - every *second* Tuesday of the month
- EMEA/APAC TimeZone friendly - every *third* Tuesday of the month

**Meeting notes and agenda**: https://hackmd.io/@k3s/meet-notes/

**Meeting recordings**: [K3s Channel](https://www.youtube.com/watch?v=HRuJROA6Z3k&amp;list=PLlBG85HKlLE9KFDqJ_K6NOpup-zVw8ANl&amp;pp=gAQB)

You can check also the full details on the website: https://k3s.io/community


What&#039;s next?
---

Check out our [roadmap](ROADMAP.md) to see what we have planned moving forward.

Release cadence
---

K3s maintains pace with upstream Kubernetes releases. Our goal is to release patch releases within one week, and new minors within 30 days.

Our release versioning reflects the version of upstream Kubernetes that is being released. For example, the K3s release [v1.27.4+k3s1](https://github.com/k3s-io/k3s/releases/tag/v1.27.4%2Bk3s1) maps to the `v1.27.4` Kubernetes release. We add a postfix in the form of `+k3s&lt;number&gt;` to allow us to make additional releases using the same version of upstream Kubernetes while remaining [semver](https://semver.org/) compliant. For example, if we discovered a high severity bug in `v1.27.4+k3s1` and needed to release an immediate fix for it, we would release `v1.27.4+k3s2`.

Documentation
-------------

Please see [the official docs site](https://docs.k3s.io) for complete documentation.

Quick-Start - Install Script
--------------

The `install.sh` script provides a convenient way to download K3s and add a service to systemd or openrc.

To install k3s as a service, run:

```bash
curl -sfL https://get.k3s.io | sh -
```

A kubeconfig file is written to `/etc/rancher/k3s/k3s.yaml` and the service is automatically started or restarted.
The install script will install K3s and additional utilities, such as `kubectl`, `crictl`, `k3s-killall.sh`, and `k3s-uninstall.sh`, for example:

```bash
sudo kubectl get nodes
```

`K3S_TOKEN` is created at `/var/lib/rancher/k3s/server/node-token` on your server.
To install on worker nodes, pass `K3S_URL` along with
`K3S_TOKEN` environment variables, for example:

```bash
curl -sfL https://get.k3s.io | K3S_URL=https://myserver:6443 K3S_TOKEN=XXX sh -
```

Manual Download
---------------

1. Download `k3s` from latest [release](https://github.com/k3s-io/k3s/releases/latest), x86_64, armhf, arm64 and s390x are supported.
1. Run the server.

```bash
sudo k3s server &amp;
# Kubeconfig is written to /etc/rancher/k3s/k3s.yaml
sudo k3s kubectl get nodes

# On a different node run the below. NODE_TOKEN comes from
# /var/lib/rancher/k3s/server/node-token on your server
sudo k3s agent --server https://myserver:6443 --token ${NODE_TOKEN}
```

Contributing
------------

Please check out our [contributing guide](CONTRIBUTING.md) if you&#039;re interested in contributing to K3s.

Security
--------

Security issues in K3s can be reported by sending an email to [security@k3s.io](mailto:security@k3s.io).
Please do not file issues about security issues.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[prometheus/prometheus]]></title>
            <link>https://github.com/prometheus/prometheus</link>
            <guid>https://github.com/prometheus/prometheus</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[The Prometheus monitoring system and time series database.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prometheus/prometheus">prometheus/prometheus</a></h1>
            <p>The Prometheus monitoring system and time series database.</p>
            <p>Language: Go</p>
            <p>Stars: 61,781</p>
            <p>Forks: 10,006</p>
            <p>Stars today: 29 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot; style=&quot;border-bottom: none&quot;&gt;
    &lt;a href=&quot;https://prometheus.io&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Prometheus&quot; src=&quot;/documentation/images/prometheus-logo.svg&quot;&gt;&lt;/a&gt;&lt;br&gt;Prometheus
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;Visit &lt;a href=&quot;https://prometheus.io&quot; target=&quot;_blank&quot;&gt;prometheus.io&lt;/a&gt; for the full documentation,
examples and guides.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![CI](https://github.com/prometheus/prometheus/actions/workflows/ci.yml/badge.svg)](https://github.com/prometheus/prometheus/actions/workflows/ci.yml)
[![Docker Repository on Quay](https://quay.io/repository/prometheus/prometheus/status)][quay]
[![Docker Pulls](https://img.shields.io/docker/pulls/prom/prometheus.svg?maxAge=604800)][hub]
[![Go Report Card](https://goreportcard.com/badge/github.com/prometheus/prometheus)](https://goreportcard.com/report/github.com/prometheus/prometheus)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/486/badge)](https://bestpractices.coreinfrastructure.org/projects/486)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/prometheus/prometheus/badge)](https://securityscorecards.dev/viewer/?uri=github.com/prometheus/prometheus)
[![CLOMonitor](https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/prometheus/badge)](https://clomonitor.io/projects/cncf/prometheus)
[![Gitpod ready-to-code](https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod)](https://gitpod.io/#https://github.com/prometheus/prometheus)
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/prometheus.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:prometheus)

&lt;/div&gt;

Prometheus, a [Cloud Native Computing Foundation](https://cncf.io/) project, is a systems and service monitoring system. It collects metrics
from configured targets at given intervals, evaluates rule expressions,
displays the results, and can trigger alerts when specified conditions are observed.

The features that distinguish Prometheus from other metrics and monitoring systems are:

* A **multi-dimensional** data model (time series defined by metric name and set of key/value dimensions)
* PromQL, a **powerful and flexible query language** to leverage this dimensionality
* No dependency on distributed storage; **single server nodes are autonomous**
* An HTTP **pull model** for time series collection
* **Pushing time series** is supported via an intermediary gateway for batch jobs
* Targets are discovered via **service discovery** or **static configuration**
* Multiple modes of **graphing and dashboarding support**
* Support for hierarchical and horizontal **federation**

## Architecture overview

![Architecture overview](documentation/images/architecture.svg)

## Install

There are various ways of installing Prometheus.

### Precompiled binaries

Precompiled binaries for released versions are available in the
[*download* section](https://prometheus.io/download/)
on [prometheus.io](https://prometheus.io). Using the latest production release binary
is the recommended way of installing Prometheus.
See the [Installing](https://prometheus.io/docs/introduction/install/)
chapter in the documentation for all the details.

### Docker images

Docker images are available on [Quay.io](https://quay.io/repository/prometheus/prometheus) or [Docker Hub](https://hub.docker.com/r/prom/prometheus/).

You can launch a Prometheus container for trying it out with

```bash
docker run --name prometheus -d -p 127.0.0.1:9090:9090 prom/prometheus
```

Prometheus will now be reachable at &lt;http://localhost:9090/&gt;.

### Building from source

To build Prometheus from source code, You need:

* Go: Version specified in [go.mod](./go.mod) or greater.
* NodeJS: Version specified in [.nvmrc](./web/ui/.nvmrc) or greater.
* npm: Version 8 or greater (check with `npm --version` and [here](https://www.npmjs.com/)).

Start by cloning the repository:

```bash
git clone https://github.com/prometheus/prometheus.git
cd prometheus
```

You can use the `go` tool to build and install the `prometheus`
and `promtool` binaries into your `GOPATH`:

```bash
go install github.com/prometheus/prometheus/cmd/...
prometheus --config.file=your_config.yml
```

*However*, when using `go install` to build Prometheus, Prometheus will expect to be able to
read its web assets from local filesystem directories under `web/ui/static` and
`web/ui/templates`. In order for these assets to be found, you will have to run Prometheus
from the root of the cloned repository. Note also that these directories do not include the
React UI unless it has been built explicitly using `make assets` or `make build`.

An example of the above configuration file can be found [here.](https://github.com/prometheus/prometheus/blob/main/documentation/examples/prometheus.yml)

You can also build using `make build`, which will compile in the web assets so that
Prometheus can be run from anywhere:

```bash
make build
./prometheus --config.file=your_config.yml
```

The Makefile provides several targets:

* *build*: build the `prometheus` and `promtool` binaries (includes building and compiling in web assets)
* *test*: run the tests
* *test-short*: run the short tests
* *format*: format the source code
* *vet*: check the source code for common errors
* *assets*: build the React UI

### Service discovery plugins

Prometheus is bundled with many service discovery plugins.
When building Prometheus from source, you can edit the [plugins.yml](./plugins.yml)
file to disable some service discoveries. The file is a yaml-formatted list of go
import path that will be built into the Prometheus binary.

After you have changed the file, you
need to run `make build` again.

If you are using another method to compile Prometheus, `make plugins` will
generate the plugins file accordingly.

If you add out-of-tree plugins, which we do not endorse at the moment,
additional steps might be needed to adjust the `go.mod` and `go.sum` files. As
always, be extra careful when loading third party code.

### Building the Docker image

You can build a docker image locally with the following commands:

```bash
make promu
promu crossbuild -p linux/amd64
make npm_licenses
make common-docker-amd64
```

The `make docker` target is intended only for use in our CI system and will not
produce a fully working image when run locally.

## Using Prometheus as a Go Library

### Remote Write

We are publishing our Remote Write protobuf independently at
[buf.build](https://buf.build/prometheus/prometheus/assets).

You can use that as a library:

```shell
go get buf.build/gen/go/prometheus/prometheus/protocolbuffers/go@latest
```

This is experimental.

### Prometheus code base

In order to comply with [go mod](https://go.dev/ref/mod#versions) rules,
Prometheus release number do not exactly match Go module releases.

For the
Prometheus v3.y.z releases, we are publishing equivalent v0.3y.z tags. The y in v0.3y.z is always padded to two digits, with a leading zero if needed.

Therefore, a user that would want to use Prometheus v3.0.0 as a library could do:

```shell
go get github.com/prometheus/prometheus@v0.300.0
```

For the
Prometheus v2.y.z releases, we published the equivalent v0.y.z tags.

Therefore, a user that would want to use Prometheus v2.35.0 as a library could do:

```shell
go get github.com/prometheus/prometheus@v0.35.0
```

This solution makes it clear that we might break our internal Go APIs between
minor user-facing releases, as [breaking changes are allowed in major version
zero](https://semver.org/#spec-item-4).

## React UI Development

For more information on building, running, and developing on the React-based UI, see the React app&#039;s [README.md](web/ui/README.md).

## More information

* Godoc documentation is available via [pkg.go.dev](https://pkg.go.dev/github.com/prometheus/prometheus). Due to peculiarities of Go Modules, v3.y.z will be displayed as v0.3y.z (the y in v0.3y.z is always padded to two digits, with a leading zero if needed), while v2.y.z will be displayed as v0.y.z.
* See the [Community page](https://prometheus.io/community) for how to reach the Prometheus developers and users on various communication channels.

## Contributing

Refer to [CONTRIBUTING.md](https://github.com/prometheus/prometheus/blob/main/CONTRIBUTING.md)

## License

Apache License 2.0, see [LICENSE](https://github.com/prometheus/prometheus/blob/main/LICENSE).

[hub]: https://hub.docker.com/r/prom/prometheus/
[quay]: https://quay.io/repository/prometheus/prometheus
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[bitnami-labs/sealed-secrets]]></title>
            <link>https://github.com/bitnami-labs/sealed-secrets</link>
            <guid>https://github.com/bitnami-labs/sealed-secrets</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[A Kubernetes controller and tool for one-way encrypted Secrets]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bitnami-labs/sealed-secrets">bitnami-labs/sealed-secrets</a></h1>
            <p>A Kubernetes controller and tool for one-way encrypted Secrets</p>
            <p>Language: Go</p>
            <p>Stars: 8,763</p>
            <p>Forks: 750</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># &quot;Sealed Secrets&quot; for Kubernetes

[![](https://img.shields.io/badge/install-docs-brightgreen.svg)](#Installation)
[![](https://img.shields.io/github/release/bitnami-labs/sealed-secrets.svg)](https://github.com/bitnami-labs/sealed-secrets/releases/latest)
[![](https://img.shields.io/homebrew/v/kubeseal)](https://formulae.brew.sh/formula/kubeseal)
[![Build Status](https://github.com/bitnami-labs/sealed-secrets/actions/workflows/ci.yml/badge.svg)](https://github.com/bitnami-labs/sealed-secrets/actions/workflows/ci.yml)
[![](https://img.shields.io/github/v/release/bitnami-labs/sealed-secrets?include_prereleases&amp;label=helm&amp;sort=semver)](https://github.com/bitnami-labs/sealed-secrets/releases)
[![Download Status](https://img.shields.io/docker/pulls/bitnami/sealed-secrets-controller.svg)](https://hub.docker.com/r/bitnami/sealed-secrets-controller)
[![Go Report Card](https://goreportcard.com/badge/github.com/bitnami-labs/sealed-secrets)](https://goreportcard.com/report/github.com/bitnami-labs/sealed-secrets)
![Downloads](https://img.shields.io/github/downloads/bitnami-labs/sealed-secrets/total.svg)

**Problem:** &quot;I can manage all my K8s config in git, except Secrets.&quot;

**Solution:** Encrypt your Secret into a SealedSecret, which *is* safe
to store - even inside a public repository. The SealedSecret can be
decrypted only by the controller running in the target cluster and
nobody else (not even the original author) is able to obtain the
original Secret from the SealedSecret.

&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt;
&lt;!-- DON&#039;T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt;

- [Overview](#overview)
  - [SealedSecrets as templates for secrets](#sealedsecrets-as-templates-for-secrets)
  - [Public key / Certificate](#public-key--certificate)
  - [Scopes](#scopes)
- [Installation](#installation)
  - [Controller](#controller)
    - [Kustomize](#kustomize)
    - [Helm Chart](#helm-chart)
  - [Kubeseal](#kubeseal)
    - [Homebrew](#homebrew)
    - [MacPorts](#macports)
    - [Linux](#linux)
    - [Installation from source](#installation-from-source)
- [Upgrade](#upgrade)
- [Usage](#usage)
  - [Managing existing secrets](#managing-existing-secrets)
  - [Patching existing secrets](#patching-existing-secrets)
  - [Update existing secrets](#update-existing-secrets)
  - [Raw mode (experimental)](#raw-mode-experimental)
  - [Validate a Sealed Secret](#validate-a-sealed-secret)
- [Secret Rotation](#secret-rotation)
  - [Sealing key renewal](#sealing-key-renewal)
  - [User secret rotation](#user-secret-rotation)
  - [Early key renewal](#early-key-renewal)
  - [Common misconceptions about key renewal](#common-misconceptions-about-key-renewal)
  - [Manual key management (advanced)](#manual-key-management-advanced)
  - [Re-encryption (advanced)](#re-encryption-advanced)
- [Details (advanced)](#details-advanced)
  - [Crypto](#crypto)
- [Developing](#developing)
- [FAQ](#faq)
  - [Will you still be able to decrypt if you no longer have access to your cluster?](#will-you-still-be-able-to-decrypt-if-you-no-longer-have-access-to-your-cluster)
  - [How can I do a backup of my SealedSecrets?](#how-can-i-do-a-backup-of-my-sealedsecrets)
  - [Can I decrypt my secrets offline with a backup key?](#can-i-decrypt-my-secrets-offline-with-a-backup-key)
  - [What flags are available for kubeseal?](#what-flags-are-available-for-kubeseal)
  - [How do I update parts of JSON/YAML/TOML/.. file encrypted with sealed secrets?](#how-do-i-update-parts-of-jsonyamltoml-file-encrypted-with-sealed-secrets)
  - [Can I bring my own (pre-generated) certificates?](#can-i-bring-my-own-pre-generated-certificates)
  - [How to use kubeseal if the controller is not running within the `kube-system` namespace?](#how-to-use-kubeseal-if-the-controller-is-not-running-within-the-kube-system-namespace)
  - [How to verify the images?](#how-to-verify-the-images)
  - [How to use one controller for a subset of namespaces](#How-to-use-one-controller-for-a-subset-of-namespaces)
  - [Can I configure the controller unseal retries](#can-i-configure-the-controller-unseal-retries)

- [Community](#community)
  - [Related projects](#related-projects)

&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt;

## Overview

Sealed Secrets is composed of two parts:

- A cluster-side controller / operator
- A client-side utility: `kubeseal`

The `kubeseal` utility uses asymmetric crypto to encrypt secrets that only the controller can decrypt.

These encrypted secrets are encoded in a `SealedSecret` resource, which you can see as a recipe for creating
a secret. Here is how it looks:

```yaml
apiVersion: bitnami.com/v1alpha1
kind: SealedSecret
metadata:
  name: mysecret
  namespace: mynamespace
spec:
  encryptedData:
    foo: AgBy3i4OJSWK+PiTySYZZA9rO43cGDEq.....
```

Once unsealed this will produce a secret equivalent to this:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: mysecret
  namespace: mynamespace
data:
  foo: YmFy  # &lt;- base64 encoded &quot;bar&quot;
```

This normal [kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/) will appear in the cluster
after a few seconds you can use it as you would use any secret that you would have created directly (e.g. reference it from a `Pod`).

Jump to the [Installation](#installation) section to get up and running.

The [Usage](#usage) section explores in more detail how you craft `SealedSecret` resources.

### SealedSecrets as templates for secrets

The previous example only focused on the encrypted secret items themselves, but the relationship between a `SealedSecret` custom resource and the `Secret` it unseals into is similar in many ways (but not in all of them) to the familiar `Deployment` vs `Pod`.

In particular, the annotations and labels of a `SealedSecret` resource are not the same as the annotations of the `Secret` that gets generated out of it.

To capture this distinction, the `SealedSecret` object has a `template` section which encodes all the fields you want the controller to put in the unsealed `Secret`.

The [Sprig function library](https://masterminds.github.io/sprig/) is available (except for `env`, `expandenv` and `getHostByName`) in addition to the default Go Text Template functions.

The `metadata` block is copied as is (the `ownerReference` field will be updated [unless disabled](#seal-secret-which-can-skip-set-owner-references)).

Other secret fields are handled individually. The `type` and `immutable` fields are copied, and the `data` field can be used to [template complex values](docs/examples/config-template) on the `Secret`. All other fields are currently ignored.

```yaml
apiVersion: bitnami.com/v1alpha1
kind: SealedSecret
metadata:
  name: mysecret
  namespace: mynamespace
  annotations:
    &quot;kubectl.kubernetes.io/last-applied-configuration&quot;: ....
spec:
  encryptedData:
    .dockerconfigjson: AgBy3i4OJSWK+PiTySYZZA9rO43cGDEq.....
  template:
    type: kubernetes.io/dockerconfigjson
    immutable: true
    # this is an example of labels and annotations that will be added to the output secret
    metadata:
      labels:
        &quot;jenkins.io/credentials-type&quot;: usernamePassword
      annotations:
        &quot;jenkins.io/credentials-description&quot;: credentials from Kubernetes
```

The controller would unseal that into something like:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: mysecret
  namespace: mynamespace
  labels:
    &quot;jenkins.io/credentials-type&quot;: usernamePassword
  annotations:
    &quot;jenkins.io/credentials-description&quot;: credentials from Kubernetes
  ownerReferences:
  - apiVersion: bitnami.com/v1alpha1
    controller: true
    kind: SealedSecret
    name: mysecret
    uid: 5caff6a0-c9ac-11e9-881e-42010aac003e
type: kubernetes.io/dockerconfigjson
immutable: true
data:
  .dockerconfigjson: ewogICJjcmVk...
```

As you can see, the generated `Secret` resource is a &quot;dependent object&quot; of the `SealedSecret` and as such
it will be updated and deleted whenever the `SealedSecret` object gets updated or deleted.

### Public key / Certificate

The key certificate (public key portion) is used for sealing secrets,
and needs to be available wherever `kubeseal` is going to be
used. The certificate is not secret information, although you need to
ensure you are using the correct one.

`kubeseal` will fetch the certificate from the controller at runtime
(requires secure access to the Kubernetes API server), which is
convenient for interactive use, but it&#039;s known to be brittle when users
have clusters with special configurations such as [private GKE clusters](docs/GKE.md#private-gke-clusters) that have
firewalls between control plane and nodes.

An alternative workflow
is to store the certificate somewhere (e.g. local disk) with
`kubeseal --fetch-cert &gt;mycert.pem`,
and use it offline with `kubeseal --cert mycert.pem`.
The certificate is also printed to the controller log on startup.

Since v0.9.x certificates get automatically renewed every 30 days. It&#039;s good practice that you and your team
update your offline certificate periodically. To help you with that, since v0.9.2 `kubeseal` accepts URLs too. You can set up your internal automation to publish certificates somewhere you trust.

```bash
kubeseal --cert https://your.intranet.company.com/sealed-secrets/your-cluster.cert
```

It also recognizes the `SEALED_SECRETS_CERT` env var. (pro-tip: see also [direnv](https://github.com/direnv/direnv)).

&gt; **NOTE**: we are working on providing key management mechanisms that offload the encryption to HSM based modules or managed cloud crypto solutions such as KMS.

### Scopes

SealedSecrets are from the POV of an end user a &quot;write only&quot; device.

The idea is that the SealedSecret can be decrypted only by the controller running in the target cluster and
nobody else (not even the original author) is able to obtain the original Secret from the SealedSecret.

The user may or may not have direct access to the target cluster.
More specifically, the user might or might not have access to the Secret unsealed by the controller.

There are many ways to configure RBAC on k8s, but it&#039;s quite common to forbid low-privilege users
from reading Secrets. It&#039;s also common to give users one or more namespaces where they have higher privileges,
which would allow them to create and read secrets (and/or create deployments that can reference those secrets).

Encrypted `SealedSecret` resources are designed to be safe to be looked at without gaining any knowledge about the secrets it conceals. This implies that we cannot allow users to read a SealedSecret meant for a namespace they wouldn&#039;t have access to
and just push a copy of it in a namespace where they can read secrets from.

Sealed-secrets thus behaves *as if* each namespace had its own independent encryption key and thus once you
seal a secret for a namespace, it cannot be moved in another namespace and decrypted there.

We don&#039;t technically use an independent private key for each namespace, but instead we *include* the namespace name
during the encryption process, effectively achieving the same result.

Furthermore, namespaces are not the only level at which RBAC configurations can decide who can see which secret. In fact, it&#039;s possible that users can access a secret called `foo` in a given namespace but not any other secret in the same namespace. We cannot thus by default let users freely rename `SealedSecret` resources otherwise a malicious user would be able to decrypt any SealedSecret for that namespace by just renaming it to overwrite the one secret user does have access to. We use the same mechanism used to include the namespace in the encryption key to also include the secret name.

That said, there are many scenarios where you might not care about this level of protection. For example, the only people who have access to your clusters are either admins or they cannot read any `Secret` resource at all. You might have a use case for moving a sealed secret to other namespaces (e.g. you might not know the namespace name upfront), or you might not know the name of the secret (e.g. it could contain a unique suffix based on the hash of the contents etc).

These are the possible scopes:

- `strict` (default): the secret must be sealed with exactly the same *name* and *namespace*. These attributes become *part of the encrypted data* and thus changing name and/or namespace would lead to &quot;decryption error&quot;.
- `namespace-wide`: you can freely *rename* the sealed secret within a given namespace.
- `cluster-wide`: the secret can be unsealed in *any* namespace and can be given *any* name.

In contrast to the restrictions of *name* and *namespace*, secret *items* (i.e. JSON object keys like `spec.encryptedData.my-key`) can be renamed at will without losing the ability to decrypt the sealed secret.

The scope is selected with the `--scope` flag:

```bash
kubeseal --scope cluster-wide &lt;secret.yaml &gt;sealed-secret.json
```

It&#039;s also possible to request a scope via annotations in the input secret you pass to `kubeseal`:

- `sealedsecrets.bitnami.com/namespace-wide: &quot;true&quot;` -&gt; for `namespace-wide`
- `sealedsecrets.bitnami.com/cluster-wide: &quot;true&quot;` -&gt; for `cluster-wide`

The lack of any of such annotations means `strict` mode. If both are set, `cluster-wide` takes precedence.

&gt; NOTE: Next release will consolidate this into a single `sealedsecrets.bitnami.com/scope` annotation.

## Installation

See https://github.com/bitnami-labs/sealed-secrets/releases for the latest release and detailed installation instructions.

Cloud platform specific notes and instructions:

- [GKE](docs/GKE.md)

### Controller

Once you deploy the manifest it will create the `SealedSecret` resource
and install the controller into `kube-system` namespace, create a service
account and necessary RBAC roles.

After a few moments, the controller will start, generate a key pair,
and be ready for operation. If it does not, check the controller logs.

#### Kustomize

The official controller manifest installation mechanism is just a YAML file.

In some cases you might need to apply your own customizations, like set a custom namespace or set some env variables.

`kubectl` has native support for that, see [kustomize](https://kustomize.io/).

#### Helm Chart

The Sealed Secrets helm chart is now officially supported and hosted in this GitHub repo.

```bash
helm repo add sealed-secrets https://bitnami-labs.github.io/sealed-secrets
```

&gt; NOTE: The versioning scheme of the helm chart differs from the versioning scheme of the sealed secrets project itself.

Originally the helm chart was maintained by the community and the first version adopted a major version of 1 while the
sealed secrets project itself is still at major 0.
This is ok because the version of the helm chart itself is not meant to be necessarily the version of the app itself.
However this is confusing, so our current versioning rule is:

1. The `SealedSecret` controller version scheme: 0.X.Y
2. The helm chart version scheme: 1.X.Y-rZ

There can be thus multiple revisions of the helm chart, with fixes that apply only to the helm chart without
affecting the static YAML manifests or the controller image itself.

&gt; NOTE: The helm chart readme still contains a deprecation notice, but it no longer reflects reality and will be removed upon the next release.

&gt; NOTE: The helm chart by default installs the controller with the name `sealed-secrets`, while the `kubeseal` command line interface (CLI) tries to access the controller with the name `sealed-secrets-controller`. You can explicitly pass `--controller-name` to the CLI:

```bash
kubeseal --controller-name sealed-secrets &lt;args&gt;
```

Alternatively, you can set `fullnameOverride` when installing the chart to override the name. Note also that `kubeseal` assumes that the controller is installed within the `kube-system` namespace by default. So if you want to use the `kubeseal` CLI without having to pass the expected controller name and namespace you should install the Helm Chart like this:

```bash
helm install sealed-secrets -n kube-system --set-string fullnameOverride=sealed-secrets-controller sealed-secrets/sealed-secrets
```

##### Helm Chart on a restricted environment

In some companies you might be given access only to a single namespace, not a full cluster.

One of the most restrictive environments you can encounter is:
- A `namespace` was allocated to you with some `service account`.
- You do not have access to the rest of the cluster, not even cluster CRDs.
- You may not even be able to create further service accounts or roles in your namespace.
- You are required to include resource limits in all your deployments.

Even with these restrictions you can still install the sealed secrets Helm Chart, there is only one pre-requisite:
- *The cluster must already have the sealed secrets CRDs installed*.

Once your admins installed the CRDs, if they were not there already, you can install the chart by preparing a YAML config file such as this:

```shell
serviceAccount:
  create: false
  name: {allocated-service-account}
rbac:
  create: false
  clusterRole: false
resources:
  limits:
    cpu: 150m
    memory: 256Mi
```

Note that:
- No service accounts are created, instead the one allocated to you will be used.
  - `{allocated-service-account}` is the name of the `service account` you were allocated on the cluster.
- No RBAC roles are created neither in the namespace nor the cluster.
- Resource limits must be specified.
  - The limits are samples that should work, but you might want to review them in your particular setup.

Once that file is ready, if you named it `config.yaml` you now can install the sealed secrets Helm Chart like this:

```shell
helm install sealed-secrets -n {allocated-namespace} sealed-secrets/sealed-secrets --skip-crds -f config.yaml
```

Where `{allocated-namespace}` is the name of the `namespace` you were allocated in the cluster.

### Kubeseal

#### Homebrew

The `kubeseal` client is also available on [homebrew](https://formulae.brew.sh/formula/kubeseal):

```bash
brew install kubeseal
```

#### MacPorts

The `kubeseal` client is also available on [MacPorts](https://ports.macports.org/port/kubeseal/summary):

```bash
port install kubeseal
```

#### Nixpkgs

The `kubeseal` client is also available on [Nixpkgs](https://search.nixos.org/packages?channel=unstable&amp;show=kubeseal&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=kubeseal): (**DISCLAIMER**: Not maintained by bitnami-labs)

```bash
nix-env -iA nixpkgs.kubeseal
```

#### Linux

The `kubeseal` client can be installed on Linux, using the below commands:

```bash
KUBESEAL_VERSION=&#039;&#039; # Set this to, for example, KUBESEAL_VERSION=&#039;0.23.0&#039;
curl -OL &quot;https://github.com/bitnami-labs/sealed-secrets/releases/download/v${KUBESEAL_VERSION:?}/kubeseal-${KUBESEAL_VERSION:?}-linux-amd64.tar.gz&quot;
tar -xvzf kubeseal-${KUBESEAL_VERSION:?}-linux-amd64.tar.gz kubeseal
sudo install -m 755 kubeseal /usr/local/bin/kubeseal
```

If you have `curl` and `jq` installed on your machine, you can get the version dynamically this way. This can be useful for environments used in automation and such.

```
# Fetch the latest sealed-secrets version using GitHub API
KUBESEAL_VERSION=$(curl -s https://api.github.com/repos/bitnami-labs/sealed-secrets/tags | jq -r &#039;.[0].name&#039; | cut -c 2-)

# Check if the version was fetched successfully
if [ -z &quot;$KUBESEAL_VERSION&quot; ]; then
    echo &quot;Failed to fetch the latest KUBESEAL_VERSION&quot;
    exit 1
fi

curl -OL &quot;https://github.com/bitnami-labs/sealed-secrets/releases/download/v${KUBESEAL_VERSION}/kubeseal-${KUBESEAL_VERSION}-linux-amd64.tar.gz&quot;
tar -xvzf kubeseal-${KUBESEAL_VERSION}-linux-amd64.tar.gz kubeseal
sudo install -m 755 kubeseal /usr/local/bin/kubeseal
```

where `KUBESEAL_VERSION` is the [version tag](https://github.com/bitnami-labs/sealed-secrets/tags) of the kubeseal release you want to use. For example: `v0.18.0`.

#### Installation from source

If you just want the latest client too

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cockroachdb/cockroach]]></title>
            <link>https://github.com/cockroachdb/cockroach</link>
            <guid>https://github.com/cockroachdb/cockroach</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[CockroachDB ‚Äî the cloud native, distributed SQL database designed for high availability, effortless scale, and control over data placement.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cockroachdb/cockroach">cockroachdb/cockroach</a></h1>
            <p>CockroachDB ‚Äî the cloud native, distributed SQL database designed for high availability, effortless scale, and control over data placement.</p>
            <p>Language: Go</p>
            <p>Stars: 31,611</p>
            <p>Forks: 4,039</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;docs/media/cockroach_db.png?raw=true&#039; width=&#039;70%&#039;&gt;
&lt;/p&gt;

---

CockroachDB is a cloud-native distributed SQL database designed to build,
scale, and manage modern, data-intensive applications. 

- [What is CockroachDB?](#what-is-cockroachdb)
- [Docs](#docs)
- [Starting with Cockroach Cloud](#starting-with-cockroachcloud)
- [Starting with CockroachDB](#starting-with-cockroachdb)
- [Client Drivers](#client-drivers)
- [Deployment](#deployment)
- [Need Help?](#need-help)
- [Contributing](#contributing)
- [Design](#design)
- [Comparison with Other Databases](#comparison-with-other-databases)
- [See Also](#see-also)

## What is CockroachDB?

CockroachDB is a distributed SQL database built on a transactional and
strongly-consistent key-value store. It **scales** horizontally;
**survives** disk, machine, rack, and even datacenter failures with
minimal latency disruption and no manual intervention; supports
**strongly-consistent** ACID transactions; and provides a familiar
**SQL** API for structuring, manipulating, and querying data.

For more details, see our [product overview](https://www.cockroachlabs.com/product/overview/), [FAQ](https://cockroachlabs.com/docs/stable/frequently-asked-questions.html) or [architecture document](
https://www.cockroachlabs.com/docs/stable/architecture/overview.html).

## Docs

For guidance on installation, development, deployment, and administration, see our [User Documentation](https://cockroachlabs.com/docs/stable/).

## Starting with CockroachCloud

We can run CockroachDB for you, so you don&#039;t have to run your own cluster.

See our online documentation: [Quickstart with CockroachCloud](https://www.cockroachlabs.com/docs/cockroachcloud/quickstart.html)

## Starting with CockroachDB

1. Install CockroachDB:  [using a pre-built executable](https://www.cockroachlabs.com/docs/stable/install-cockroachdb.html) or [build it from source](https://cockroachlabs.atlassian.net/wiki/spaces/CRDB/pages/181338446/Getting+and+building+CockroachDB+from+source).
2. [Start a local cluster](https://www.cockroachlabs.com/docs/stable/start-a-local-cluster.html) and connect to it via the [built-in SQL client](https://www.cockroachlabs.com/docs/stable/use-the-built-in-sql-client.html).
3. [Learn more about CockroachDB SQL](https://www.cockroachlabs.com/docs/stable/learn-cockroachdb-sql.html).
4. Use a PostgreSQL-compatible driver or ORM to [build an app with CockroachDB](https://www.cockroachlabs.com/docs/stable/hello-world-example-apps.html).
5. [Explore core features](https://www.cockroachlabs.com/docs/stable/demo-data-replication.html), such as data replication, automatic rebalancing, and fault tolerance and recovery.

## Client Drivers

CockroachDB supports the PostgreSQL wire protocol, so you can use any available PostgreSQL client drivers to connect from various languages.

- For recommended drivers that we&#039;ve tested, see [Install Client Drivers](https://www.cockroachlabs.com/docs/stable/install-client-drivers.html).
- For tutorials using these drivers, as well as supported ORMs, see [Example Apps](https://www.cockroachlabs.com/docs/stable/example-apps.html).

## Deployment

- [CockroachCloud](https://www.cockroachlabs.com/docs/cockroachcloud/quickstart) - Steps to create a [free CockroachCloud cluster](https://cockroachlabs.cloud/signup?referralId=githubquickstart) on your preferred Cloud platform.
- [Manual](https://www.cockroachlabs.com/docs/stable/manual-deployment.html) - Steps to deploy a CockroachDB cluster manually on multiple machines.
- [Cloud](https://www.cockroachlabs.com/docs/stable/cloud-deployment.html) - Guides for deploying CockroachDB on various cloud platforms.
- [Orchestration](https://www.cockroachlabs.com/docs/stable/orchestration.html) - Guides for running CockroachDB with popular open-source orchestration systems.

## Need Help?

- [CockroachDB Community Slack](https://go.crdb.dev/p/slack) - Join our slack to connect with our engineers and other users running CockroachDB.
- [CockroachDB Forum](https://forum.cockroachlabs.com/) and [Stack Overflow](https://stackoverflow.com/questions/tagged/cockroachdb) - Ask questions, find answers, and help other users.
- [Troubleshooting documentation](https://www.cockroachlabs.com/docs/stable/troubleshooting-overview.html) - Learn how to troubleshoot common errors, cluster setup, and SQL query behavior.
- For filing bugs, suggesting improvements, or requesting new features, help us out by [opening an issue](https://github.com/cockroachdb/cockroach/issues/new).

## Building from source

See [our wiki](https://wiki.crdb.io/wiki/spaces/CRDB/pages/181338446/Getting+and+building+from+source) for more details.

## Contributing

We welcome your contributions! If you&#039;re looking for issues to work on, try looking at the [good first issue list](https://github.com/cockroachdb/cockroach/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22). We do our best to tag issues suitable for new external contributors with that label, so it&#039;s a great way to find something you can help with!

See [our wiki](https://wiki.crdb.io/wiki/spaces/CRDB/pages/73204033/Contributing+to+CockroachDB) for more details.

Engineering discussions take place on our public mailing list, [cockroach-db@googlegroups.com](https://groups.google.com/forum/#!forum/cockroach-db). Also please join our [Community Slack](https://go.crdb.dev/p/slack) (there&#039;s a dedicated #contributors channel!) to ask questions, discuss your ideas, and connect with other contributors.

## Design

For an in-depth discussion of the CockroachDB architecture, see our
[Architecture
Guide](https://www.cockroachlabs.com/docs/stable/architecture/overview.html).
For the original design motivation, see our [design
doc](https://github.com/cockroachdb/cockroach/blob/master/docs/design.md).

## Licensing

All versions released on or after November 18, 2024 (specifically, major version series v24.3 and later, and patch fixes for v23.1.29+, v23.2.16+, v24.1.7+, and v24.2.5+) are published under the [CockroachDB Software License (CSL)](./LICENSE). Source code in a given file is licensed under the CSL and the copyright belongs to The Cockroach Authors unless otherwise noted in the file or in a LICENSE or README file located in the same or a parent directory of the file.

## Comparison with Other Databases

To see how key features of CockroachDB stack up against other databases,
check out [CockroachDB in Comparison](https://www.cockroachlabs.com/docs/stable/cockroachdb-in-comparison.html).

## See Also

- [Tech Talks](https://www.cockroachlabs.com/community/tech-talks/) (by CockroachDB founders, engineers, and customers!)
- [CockroachDB User Documentation](https://cockroachlabs.com/docs/stable/)
- [The CockroachDB Blog](https://www.cockroachlabs.com/blog/)
- Key design documents
  - [Serializable, Lockless, Distributed: Isolation in CockroachDB](https://www.cockroachlabs.com/blog/serializable-lockless-distributed-isolation-cockroachdb/)
  - [Consensus, Made Thrive](https://www.cockroachlabs.com/blog/consensus-made-thrive/)
  - [Trust, But Verify: How CockroachDB Checks Replication](https://www.cockroachlabs.com/blog/trust-but-verify-cockroachdb-checks-replication/)
  - [Living Without Atomic Clocks](https://www.cockroachlabs.com/blog/living-without-atomic-clocks/)
  - [The CockroachDB Architecture Document](https://github.com/cockroachdb/cockroach/blob/master/docs/design.md)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-policy-agent/opa]]></title>
            <link>https://github.com/open-policy-agent/opa</link>
            <guid>https://github.com/open-policy-agent/opa</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[Open Policy Agent (OPA) is an open source, general-purpose policy engine.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-policy-agent/opa">open-policy-agent/opa</a></h1>
            <p>Open Policy Agent (OPA) is an open source, general-purpose policy engine.</p>
            <p>Language: Go</p>
            <p>Stars: 10,982</p>
            <p>Forks: 1,490</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># ![logo](./logo/logo-144x144.png) Open Policy Agent

[![Build Status](https://github.com/open-policy-agent/opa/workflows/Post%20Merge/badge.svg)](https://github.com/open-policy-agent/opa/actions) [![Go Report Card](https://goreportcard.com/badge/open-policy-agent/opa)](https://goreportcard.com/report/open-policy-agent/opa) [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1768/badge)](https://bestpractices.coreinfrastructure.org/projects/1768) [![Netlify Status](https://api.netlify.com/api/v1/badges/4a0a092a-8741-4826-a28f-826d4a576cab/deploy-status)](https://app.netlify.com/sites/openpolicyagent/deploys)

Open Policy Agent (OPA) is an open source, general-purpose policy engine that enables unified, context-aware policy enforcement across the entire stack.

OPA is proud to be a graduated project in the [Cloud Native Computing Foundation](https://cncf.io) (CNCF) landscape. For details read the CNCF [announcement](https://www.cncf.io/announcements/2021/02/04/cloud-native-computing-foundation-announces-open-policy-agent-graduation/).

## Get started with OPA

- Write your first Rego policy with the [Rego Playground](https://play.openpolicyagent.org) or use it to share your work with others for feedback and support. Have a look at the [Access Control examples](https://play.openpolicyagent.org/?example-group=access-control) if you&#039;re not sure where to start.
- Install the [VS Code extension](https://marketplace.visualstudio.com/items?itemName=tsandall.opa) to get started locally with live diagnostics, debugging and formatting. See [Editor and IDE Support](https://www.openpolicyagent.org/docs/editor-and-ide-support/) for other supported editors.
- Go to the [OPA Documentation](https://www.openpolicyagent.org/docs/latest/) to
  learn about the Rego language as well as how to deploy and integrate OPA.
- Check out the learning resources in the [Learning Rego](https://www.openpolicyagent.org/ecosystem/by-feature/learning-rego/) section of the ecosystem directory.
- Follow the [Running OPA](https://www.openpolicyagent.org/docs/latest/#running-opa) instructions to get started with the OPA CLI locally.
- See [Docker Hub](https://hub.docker.com/r/openpolicyagent/opa/tags/) for container images and the [GitHub releases](https://github.com/open-policy-agent/opa/releases) for binaries.
- Check out the [OPA Roadmap](https://docs.google.com/presentation/d/16QV6gvLDOV3I0_guPC3_19g6jHkEg3X9xqMYgtoCKrs/edit?usp=sharing) to see a high-level snapshot of OPA features in-progress and planned.

## Want to talk about OPA or get support?

- Join the [OPA Slack](https://slack.openpolicyagent.org) to talk to other OPA users and maintainers. See `#help` for support.
- Check out the [Community Discussions](https://github.com/orgs/open-policy-agent/discussions) to ask questions.
- See the [Support](https://www.openpolicyagent.org/support/) page for commercial support options.

## Interested to learn what others are doing with OPA?

- Browse community projects on the [OPA Ecosystem Directory](http://openpolicyagent.org/ecosystem/) - don&#039;t forget to [list your own](https://github.com/open-policy-agent/opa/tree/main/docs#opa-ecosystem)!
- Check out the [ADOPTERS.md](./ADOPTERS.md) file for a list of production adopters. Does your organization use OPA in production? Support the OPA project by submitting a PR to add your organization to the list with a short description of your OPA use cases!

## Want to integrate OPA?

- See the high-level [Go SDK](https://www.openpolicyagent.org/docs/latest/integration/#integrating-with-the-go-sdk) or the low-level Go API
  [![GoDoc](https://godoc.org/github.com/open-policy-agent/opa?status.svg)](https://godoc.org/github.com/open-policy-agent/opa/rego)
  to integrate OPA with services written in Go.
- See the [REST API](https://www.openpolicyagent.org/docs/rest-api.html)
  reference to integrate OPA with services written in other languages.
- See the [integration docs](https://www.openpolicyagent.org/docs/latest/integration/) for more options.

## Want to contribute to OPA?

- Read the [Contributing Guide](https://www.openpolicyagent.org/docs/latest/contributing/) to learn how to make your first contribution.
- Use [#contributors](https://openpolicyagent.slack.com/archives/C02L1TLPN59) in Slack to talk to other contributors and OPA maintainers.
- File a [GitHub Issue](https://github.com/open-policy-agent/opa/issues) to request features or report bugs.

## How does OPA work?

OPA gives you a high-level declarative language to author and enforce policies
across your stack.

With OPA, you define _rules_ that govern how your system should behave. These
rules exist to answer questions like:

- Can user X call operation Y on resource Z?
- What clusters should workload W be deployed to?
- What tags must be set on resource R before it&#039;s created?

You integrate services with OPA so that these kinds of policy decisions do not
have to be _hardcoded_ in your service. Services integrate with OPA by
executing _queries_ when policy decisions are needed.

When you query OPA for a policy decision, OPA evaluates the rules and data
(which you give it) to produce an answer. The policy decision is sent back as
the result of the query.

For example, in a simple API authorization use case:

- You write rules that allow (or deny) access to your service APIs.
- Your service queries OPA when it receives API requests.
- OPA returns allow (or deny) decisions to your service.
- Your service _enforces_ the decisions by accepting or rejecting requests accordingly.

For concrete examples of how to integrate OPA with systems like
[Kubernetes](https://www.openpolicyagent.org/docs/kubernetes),
[Terraform](https://www.openpolicyagent.org/docs/terraform),
[Docker](https://www.openpolicyagent.org/docs/docker-authorization),
[SSH](https://www.openpolicyagent.org/docs/ssh-and-sudo-authorization),
and more, see [openpolicyagent.org](https://www.openpolicyagent.org).

## Presentations

- Open Policy Agent (OPA) Intro &amp; Deep Dive @ Kubecon NA 2023: [video](https://www.youtube.com/watch?v=wJkjsvVpj_Q)
- Open Policy Agent (OPA) Intro &amp; Deep Dive @ Kubecon EU 2023: [video](https://www.youtube.com/watch?v=6RNp3m_THw4)
- Running Policy in Hard to Reach Places with WASM &amp; OPA @ CN Wasm Day EU 2023: [video](https://www.youtube.com/watch?v=BdeBhukLwt4)
- OPA maintainers talk @ Kubecon NA 2022: [video](https://www.youtube.com/watch?v=RMiovzGGCfI)
- Open Policy Agent (OPA) Intro &amp; Deep Dive @ Kubecon EU 2022: [video](https://www.youtube.com/watch?v=MhyQxIp1H58)
- Open Policy Agent Intro @ KubeCon EU 2021: [Video](https://www.youtube.com/watch?v=2CgeiWkliaw)
- Using Open Policy Agent to Meet Evolving Policy Requirements @ KubeCon NA 2020: [video](https://www.youtube.com/watch?v=zVuM7F_BTyc)
- Applying Policy Throughout The Application Lifecycle with Open Policy Agent @ CloudNativeCon 2019: [video](https://www.youtube.com/watch?v=cXfsaE6RKfc)
- Open Policy Agent Introduction @ CloudNativeCon EU 2018: [video](https://youtu.be/XEHeexPpgrA), [slides](https://www.slideshare.net/TorinSandall/opa-the-cloud-native-policy-engine)
- Rego Deep Dive @ CloudNativeCon EU 2018: [video](https://youtu.be/4mBJSIhs2xQ), [slides](https://www.slideshare.net/TorinSandall/rego-deep-dive)
- How Netflix Is Solving Authorization Across Their Cloud @ CloudNativeCon US 2017: [video](https://www.youtube.com/watch?v=R6tUNpRpdnY), [slides](https://www.slideshare.net/TorinSandall/how-netflix-is-solving-authorization-across-their-cloud).
- Policy-based Resource Placement in Kubernetes Federation @ LinuxCon Beijing 2017: [slides](https://www.slideshare.net/TorinSandall/policybased-resource-placement-across-hybrid-cloud), [screencast](https://www.youtube.com/watch?v=hRz13baBhfg&amp;feature=youtu.be)
- Enforcing Bespoke Policies In Kubernetes @ KubeCon US 2017: [video](https://www.youtube.com/watch?v=llDI8VvkUj8), [slides](https://www.slideshare.net/TorinSandall/enforcing-bespoke-policies-in-kubernetes)
- Istio&#039;s Mixer: Policy Enforcement with Custom Adapters @ CloudNativeCon US 2017: [video](https://www.youtube.com/watch?v=czZLXUqzd24), [slides](https://www.slideshare.net/TorinSandall/istios-mixer-policy-enforcement-with-custom-adapters-cloud-nativecon-17)

## Security

A third party security audit was performed by Cure53, you can see the full report [here](SECURITY_AUDIT.pdf).

Please report vulnerabilities by email to [open-policy-agent-security](mailto:open-policy-agent-security@googlegroups.com).
We will send a confirmation message to acknowledge that we have received the
report and then we will send additional messages to follow up once the issue
has been investigated.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes/minikube]]></title>
            <link>https://github.com/kubernetes/minikube</link>
            <guid>https://github.com/kubernetes/minikube</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[Run Kubernetes locally]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes/minikube">kubernetes/minikube</a></h1>
            <p>Run Kubernetes locally</p>
            <p>Language: Go</p>
            <p>Stars: 31,240</p>
            <p>Forks: 5,115</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># minikube

[![Actions Status](https://github.com/kubernetes/minikube/workflows/build/badge.svg)](https://github.com/kubernetes/minikube/actions)
[![GoReport Widget]][GoReport Status]
[![GitHub All Releases](https://img.shields.io/github/downloads/kubernetes/minikube/total.svg)](https://github.com/kubernetes/minikube/releases/latest)
[![Latest Release](https://img.shields.io/github/v/release/kubernetes/minikube?include_prereleases)](https://github.com/kubernetes/minikube/releases/latest)
[![Open in GitHub Codespaces](https://img.shields.io/badge/Open%20in-GitHub%20Codespaces-blue?logo=github)](https://codespaces.new/kubernetes/minikube?quickstart=1) 

[GoReport Status]: https://goreportcard.com/report/github.com/kubernetes/minikube
[GoReport Widget]: https://goreportcard.com/badge/github.com/kubernetes/minikube

&lt;img src=&quot;https://github.com/kubernetes/minikube/raw/master/images/logo/logo.png&quot; width=&quot;100&quot; alt=&quot;minikube logo&quot;&gt;

minikube implements a local Kubernetes cluster on macOS, Linux, and Windows. minikube&#039;s [primary goals](https://minikube.sigs.k8s.io/docs/concepts/principles/) are to be the best tool for local Kubernetes application development and to support all Kubernetes features that fit. 

&lt;img src=&quot;https://raw.githubusercontent.com/kubernetes/minikube/master/site/static/images/screenshot.png&quot; width=&quot;575&quot; height=&quot;322&quot; alt=&quot;screenshot&quot;&gt;

## Features

minikube runs the latest stable release of Kubernetes, with support for standard Kubernetes features like:

* [LoadBalancer](https://minikube.sigs.k8s.io/docs/handbook/accessing/#loadbalancer-access) - using `minikube tunnel`
* Multi-cluster - using `minikube start -p &lt;name&gt;`
* [NodePorts](https://minikube.sigs.k8s.io/docs/handbook/accessing/#nodeport-access) - using `minikube service`
* [Persistent Volumes](https://minikube.sigs.k8s.io/docs/handbook/persistent_volumes/)
* [Ingress](https://kubernetes.io/docs/tasks/access-application-cluster/ingress-minikube/)
* [Dashboard](https://minikube.sigs.k8s.io/docs/handbook/dashboard/) - `minikube dashboard`
* [Container runtimes](https://minikube.sigs.k8s.io/docs/handbook/config/#runtime-configuration) - `minikube start --container-runtime`
* [Configure apiserver and kubelet options](https://minikube.sigs.k8s.io/docs/handbook/config/#modifying-kubernetes-defaults) via command-line flags
* Supports common [CI environments](https://github.com/minikube-ci/examples)

As well as developer-friendly features:

* [Addons](https://minikube.sigs.k8s.io/docs/handbook/deploying/#addons) - a marketplace for developers to share configurations for running services on minikube
* [NVIDIA GPU support](https://minikube.sigs.k8s.io/docs/tutorials/nvidia/) - for machine learning
* [AMD GPU support](https://minikube.sigs.k8s.io/docs/tutorials/amd/) - for machine learning
* [Filesystem mounts](https://minikube.sigs.k8s.io/docs/handbook/mount/)

**For more information, see the official [minikube website](https://minikube.sigs.k8s.io)**

## Installation

See the [Getting Started Guide](https://minikube.sigs.k8s.io/docs/start/)

:mega: **Please fill out our [fast 5-question survey](https://forms.gle/Gg3hG5ZySw8c1C24A)** so that we can learn how &amp; why you use minikube, and what improvements we should make. Thank you! :dancers:

## GitHub Codespace

You can run minikube in a GitHub Codespace by clicking here: 
[![Open in GitHub Codespaces](https://img.shields.io/badge/Open%20in-GitHub%20Codespaces-blue?logo=github)](https://codespaces.new/kubernetes/minikube?quickstart=1)

This will launch a Github Codespace. You can then run `minikube start` and `minikube dashboard` - You can then open Minikube Dashboard by clicking opening the link displayed in the terminal.  

You can also run Minikube in a Dev Container locally using your favorite IDE, for more information see Dev Containers https://code.visualstudio.com/docs/devcontainers/containers

## Documentation

See https://minikube.sigs.k8s.io/docs/

## More Examples

See minikube in action [here](https://minikube.sigs.k8s.io/docs/handbook/controls/)

## Governance

Kubernetes project is governed by a framework of principles, values, policies and processes to help our community and constituents towards our shared goals.

The [Kubernetes Community](https://github.com/kubernetes/community/blob/master/governance.md) is the launching point for learning about how we organize ourselves.

The [Kubernetes Steering community repo](https://github.com/kubernetes/steering) is used by the Kubernetes Steering Committee, which oversees governance of the Kubernetes project.

## Community

minikube is a Kubernetes [#sig-cluster-lifecycle](https://github.com/kubernetes/community/tree/master/sig-cluster-lifecycle)  project.

* [**#minikube on Kubernetes Slack**](https://kubernetes.slack.com/messages/minikube) - Live chat with minikube developers!
* [minikube-users mailing list](https://groups.google.com/g/minikube-users)
* [minikube-dev mailing list](https://groups.google.com/g/minikube-dev)

* [Contributing](https://minikube.sigs.k8s.io/docs/contrib/)
* [Development Roadmap](https://minikube.sigs.k8s.io/docs/contrib/roadmap/)

Join our community meetings:
* [Bi-weekly office hours, Mondays @ 11am PST](https://tinyurl.com/minikube-oh)
* [Triage Party](https://minikube.sigs.k8s.io/docs/contrib/triage/)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grafana/k6]]></title>
            <link>https://github.com/grafana/k6</link>
            <guid>https://github.com/grafana/k6</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[A modern load testing tool, using Go and JavaScript]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grafana/k6">grafana/k6</a></h1>
            <p>A modern load testing tool, using Go and JavaScript</p>
            <p>Language: Go</p>
            <p>Stars: 29,472</p>
            <p>Forks: 1,464</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://grafana.com/oss/k6/&quot;&gt;
    &lt;picture&gt;
      &lt;img src=&quot;assets/logo.svg&quot; alt=&quot;Grafana k6&quot; width=&quot;210&quot; height=&quot;210&quot; /&gt;&lt;br&gt;
    &lt;/picture&gt;
    &lt;br&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/grafana-labs-dark-theme.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/grafana-labs.svg&quot;&gt;
      &lt;img src=&quot;assets/grafana-labs.svg&quot; alt=&quot;Grafana Labs&quot; width=&quot;210&quot; /&gt;
    &lt;/picture&gt;
    &lt;br&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;Like unit testing, for performance&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;Modern load testing for developers and testers in the DevOps era.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/grafana/k6/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/grafana/k6.svg&quot; alt=&quot;Github release&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/grafana/k6/actions/workflows/all.yml&quot;&gt;&lt;img src=&quot;https://github.com/grafana/k6/actions/workflows/build.yml/badge.svg&quot; alt=&quot;Build status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/grafana/k6&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/grafana/k6&quot; alt=&quot;Go Report Card&quot;&gt;&lt;/a&gt;
 &lt;a href=&quot;https://codecov.io/gh/grafana/k6&quot;&gt;&lt;img src=&quot;https://img.shields.io/codecov/c/github/grafana/k6/master.svg&quot; alt=&quot;Codecov branch&quot;&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://twitter.com/k6_io&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/twitter-@k6_io-55acee.svg&quot; alt=&quot;@k6_io on Twitter&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/grafana/k6/releases&quot;&gt;Download&lt;/a&gt; ¬∑
    &lt;a href=&quot;https://grafana.com/docs/k6/latest/&quot;&gt;Documentation&lt;/a&gt; ¬∑
    &lt;a href=&quot;https://community.grafana.com/c/grafana-k6/70&quot;&gt;Community Forum&lt;/a&gt; ¬∑
    &lt;a href=&quot;https://github.com/orgs/grafana/projects/443/views/1&quot;&gt;Public Roadmap&lt;/a&gt;
&lt;/p&gt;

&lt;br/&gt;
&lt;img src=&quot;assets/github-hr.png&quot; alt=&quot;---&quot; /&gt;
&lt;br/&gt;

**k6** is a modern load-testing tool, built on [our years of experience](https://k6.io/about) in the performance and testing industries.
It&#039;s built to be powerful, extensible, and full-featured. The key design goal is to provide **the best developer experience**.

Its core features are:

- **Configurable load generation.** Even lower-end machines can simulate lots of traffic.
- **Tests as code.** Reuse scripts, modularize logic, version control, and integrate tests with your CI.
- **A full-featured API.** The scripting API is packed with features that help you simulate real application traffic.
- **An embedded JavaScript engine.** The performance of Go, the scripting familiarity of JavaScript.
- **Multiple Protocol support**. HTTP, WebSockets, gRPC, Browser, and more.
- **Large extension ecosystem.** You can extend k6 to support your needs. And many people have already shared their extensions with the community! [Explore](https://grafana.com/docs/k6/latest/extensions/explore) the available extensions.
- **Flexible metrics storage and visualization**. Summary statistics or granular metrics, exported to the service of your choice.
- **Native integration with Grafana cloud**. [SaaS solution](https://grafana.com/products/cloud/k6/) for test execution, metrics correlation, data analysis, and more.

This is what load testing looks like in the 21st century.

## Example script


```js
import http from &quot;k6/http&quot;;
import { check, sleep } from &quot;k6&quot;;

// Test configuration
export const options = {
  thresholds: {
    // Assert that 99% of requests finish within 3000ms.
    http_req_duration: [&quot;p(99) &lt; 3000&quot;],
  },
  // Ramp the number of virtual users up and down
  stages: [
    { duration: &quot;30s&quot;, target: 15 },
    { duration: &quot;1m&quot;, target: 15 },
    { duration: &quot;20s&quot;, target: 0 },
  ],
};

// Simulated user behavior
export default function () {
  let res = http.get(&quot;https://quickpizza.grafana.com&quot;);
  // Validate response status
  check(res, { &quot;status was 200&quot;: (r) =&gt; r.status == 200 });
  sleep(1);
}
```

You can run scripts like this on the CLI, or in your CI, or across a Kubernetes cluster.

&gt; [!NOTE]
&gt; Don&#039;t want to write code ?
&gt; 
&gt; We got you! Meet [k6 Studio](https://github.com/grafana/k6-studio), a desktop application made to help you generate k6 scripts without having to touch code!

## Documentation

The docs cover all aspects of using k6. Some highlights include:

- [Get Started](https://grafana.com/docs/k6/latest/). Install, run a test, inspect results.
- [HTTP requests](https://grafana.com/docs/k6/latest/using-k6/http-requests/). Have your virtual users use HTTP methods.
  Or, check the other [Protocols](https://grafana.com/docs/k6/latest/using-k6/protocols/).
- [Thresholds](https://grafana.com/docs/k6/latest/using-k6/thresholds/). Set goals for your test, and codify your SLOs.
- [Options](https://grafana.com/docs/k6/latest/using-k6/k6-options/). Configure your load, duration, TLS certificates, and much, much more.
- [Scenarios](https://grafana.com/docs/k6/latest/using-k6/scenarios/).
  Choose how to model your workload: open models, closed models, constant RPS, fixed iterations, and more.
- [Results output](https://grafana.com/docs/k6/latest/results-output/). Study, filter, and export your test results.
- [JavaScript API](https://grafana.com/docs/k6/latest/javascript-api/). Reference and examples of all k6 modules.
- [Extensions](https://grafana.com/docs/k6/latest/extensions/). Extend k6 for new protocols and use cases.

These links barely scratch the surface! If you&#039;re looking for conceptual information, you can read about [Test types](https://grafana.com/docs/k6/latest/testing-guides/test-types/), [Test strategies](https://grafana.com/docs/k6/latest/testing-guides/), or one of the many informative [Blog posts](https://k6.io/blog).

## Roadmap

Our team is dedicated to continuously improving and providing the best user experience possible. The [public roadmap](https://github.com/orgs/grafana/projects/443/views/1) covers user-oriented features, UX improvements and JavaScript support that our team will focus on. Remember that timeframes and priorities may shift, but we believe it&#039;s important to share our vision.

We hope it provides a clear overview of our plans for future development. We welcome feedback, corrections, and suggestions via GitHub to make it more comprehensive, accessible, and valuable for the community.

It&#039;s worth mentioning that we consider [upvotes (thumbs-up)](https://github.com/grafana/k6/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc) to be one of the essential metrics for determining community needs. If you want to show us the importance of a feature, please give it a thumbs-up.

## Contribute

If you want to contribute or help with the development of k6, start by reading [CONTRIBUTING.md](CONTRIBUTING.md). Before you start coding, it might be a good idea to first discuss your plans and implementation details with the k6 maintainers‚Äîespecially when it comes to big changes and features. You can do this in the [GitHub issue](https://github.com/grafana/k6/issues) for the problem you&#039;re solving (create one if it doesn&#039;t exist).

&gt; **Note:** To disclose security issues, refer to [SECURITY.md](SECURITY.md).

## Support

To get help, report bugs, suggest features, and discuss k6 with others, refer to [SUPPORT.md](SUPPORT.md).

## License

k6 is distributed under the [AGPL-3.0 license](https://github.com/grafana/k6/blob/master/LICENSE.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[base/node]]></title>
            <link>https://github.com/base/node</link>
            <guid>https://github.com/base/node</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[Everything required to run your own Base node]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/base/node">base/node</a></h1>
            <p>Everything required to run your own Base node</p>
            <p>Language: Go</p>
            <p>Stars: 68,765</p>
            <p>Forks: 3,182</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>![Base](logo.webp)

# Base Node

Base is a secure, low-cost, developer-friendly Ethereum L2 built on Optimism&#039;s [OP Stack](https://docs.optimism.io/). This repository contains Docker builds to run your own node on the Base network.

[![Website base.org](https://img.shields.io/website-up-down-green-red/https/base.org.svg)](https://base.org)
[![Docs](https://img.shields.io/badge/docs-up-green)](https://docs.base.org/)
[![Discord](https://img.shields.io/discord/1067165013397213286?label=discord)](https://base.org/discord)
[![Twitter Base](https://img.shields.io/twitter/follow/Base?style=social)](https://x.com/Base)
[![Farcaster Base](https://img.shields.io/badge/Farcaster_Base-3d8fcc)](https://farcaster.xyz/base)

## Quick Start

1. Ensure you have an Ethereum L1 full node RPC available
2. Choose your network:
   - For mainnet: Use `.env.mainnet`
   - For testnet: Use `.env.sepolia`
3. Configure your L1 endpoints in the appropriate `.env` file:
   ```bash
   OP_NODE_L1_ETH_RPC=&lt;your-preferred-l1-rpc&gt;
   OP_NODE_L1_BEACON=&lt;your-preferred-l1-beacon&gt;
   OP_NODE_L1_BEACON_ARCHIVER=&lt;your-preferred-l1-beacon-archiver&gt;
   ```
4. Start the node:

   ```bash
   # For mainnet (default):
   docker compose up --build

   # For testnet:
   NETWORK_ENV=.env.sepolia docker compose up --build

   # To use a specific client (optional):
   CLIENT=reth docker compose up --build

   # For testnet with a specific client:
   NETWORK_ENV=.env.sepolia CLIENT=reth docker compose up --build
   ```

### Supported Clients

- `reth` (default)
- `geth`
- `nethermind`

## Requirements

### Minimum Requirements

- Modern Multicore CPU
- 32GB RAM (64GB Recommended)
- NVMe SSD drive
- Storage: (2 \* [current chain size](https://base.org/stats) + [snapshot size](https://basechaindata.vercel.app) + 20% buffer) (to accommodate future growth)
- Docker and Docker Compose

### Production Hardware Specifications

The following are the hardware specifications we use in production:

#### Reth Archive Node (recommended)

- **Instance**: AWS i7i.12xlarge
- **Storage**: RAID 0 of all local NVMe drives (`/dev/nvme*`)
- **Filesystem**: ext4

#### Geth Full Node

- **Instance**: AWS i7i.12xlarge
- **Storage**: RAID 0 of all local NVMe drives (`/dev/nvme*`)
- **Filesystem**: ext4

&gt; [!NOTE]
To run the node using a supported client, you can use the following command:
`CLIENT=supported_client docker compose up --build`
 
Supported clients:
 - reth (runs vanilla node by default, Flashblocks mode enabled by providing RETH_FB_WEBSOCKET_URL, see [Reth Node README](./reth/README.md))
 - geth
 - nethermind

## Configuration

### Required Settings

- L1 Configuration:
  - `OP_NODE_L1_ETH_RPC`: Your Ethereum L1 node RPC endpoint
  - `OP_NODE_L1_BEACON`: Your L1 beacon node endpoint
  - `OP_NODE_L1_BEACON_ARCHIVER`: Your L1 beacon archiver endpoint
  - `OP_NODE_L1_RPC_KIND`: The type of RPC provider being used (default: &quot;debug_geth&quot;). Supported values:
    - `alchemy`: Alchemy RPC provider
    - `quicknode`: QuickNode RPC provider
    - `infura`: Infura RPC provider
    - `parity`: Parity RPC provider
    - `nethermind`: Nethermind RPC provider
    - `debug_geth`: Debug Geth RPC provider
    - `erigon`: Erigon RPC provider
    - `basic`: Basic RPC provider (standard receipt fetching only)
    - `any`: Any available RPC method
    - `standard`: Standard RPC methods including newer optimized methods

### Network Settings

- Mainnet:
  - `RETH_CHAIN=base`
  - `OP_NODE_NETWORK=base-mainnet`
  - Sequencer: `https://mainnet-sequencer.base.org`

### Performance Settings

- Cache Settings:
  - `GETH_CACHE=&quot;20480&quot;` (20GB)
  - `GETH_CACHE_DATABASE=&quot;20&quot;` (4GB)
  - `GETH_CACHE_GC=&quot;12&quot;`
  - `GETH_CACHE_SNAPSHOT=&quot;24&quot;`
  - `GETH_CACHE_TRIE=&quot;44&quot;`

### Optional Features

- EthStats Monitoring (uncomment to enable)
- Trusted RPC Mode (uncomment to enable)
- Snap Sync (experimental)

For full configuration options, see the `.env.mainnet` file.

## Snapshots

Snapshots are available to help you sync your node more quickly. See [docs.base.org](https://docs.base.org/chain/run-a-base-node#snapshots) for links and more details on how to restore from a snapshot.

## Supported Networks

| Network | Status |
| ------- | ------ |
| Mainnet | ‚úÖ     |
| Testnet | ‚úÖ     |

## Troubleshooting

For support please join our [Discord](https://discord.gg/buildonbase) post in `üõ†ÔΩúnode-operators`. You can alternatively open a new GitHub issue.

## Disclaimer

THE NODE SOFTWARE IS PROVIDED &quot;AS IS&quot; WITHOUT WARRANTY OF ANY KIND. We make no guarantees about asset protection or security. Usage is subject to applicable laws and regulations.

For more information, visit [docs.base.org](https://docs.base.org/).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[AlexxIT/go2rtc]]></title>
            <link>https://github.com/AlexxIT/go2rtc</link>
            <guid>https://github.com/AlexxIT/go2rtc</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[Ultimate camera streaming application with support RTSP, RTMP, HTTP-FLV, WebRTC, MSE, HLS, MP4, MJPEG, HomeKit, FFmpeg, etc.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AlexxIT/go2rtc">AlexxIT/go2rtc</a></h1>
            <p>Ultimate camera streaming application with support RTSP, RTMP, HTTP-FLV, WebRTC, MSE, HLS, MP4, MJPEG, HomeKit, FFmpeg, etc.</p>
            <p>Language: Go</p>
            <p>Stars: 10,867</p>
            <p>Forks: 826</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;

  ![go2rtc](assets/logo.gif)
  &lt;br&gt;
  [![stars](https://img.shields.io/github/stars/AlexxIT/go2rtc?style=flat-square&amp;logo=github)](https://github.com/AlexxIT/go2rtc/stargazers) 
  [![docker pulls](https://img.shields.io/docker/pulls/alexxit/go2rtc?style=flat-square&amp;logo=docker&amp;logoColor=white&amp;label=pulls)](https://hub.docker.com/r/alexxit/go2rtc) 
  [![releases](https://img.shields.io/github/downloads/AlexxIT/go2rtc/total?color=blue&amp;style=flat-square&amp;logo=github)](https://github.com/AlexxIT/go2rtc/releases)
  [![goreport](https://goreportcard.com/badge/github.com/AlexxIT/go2rtc)](https://goreportcard.com/report/github.com/AlexxIT/go2rtc)
&lt;/h1&gt;

Ultimate camera streaming application with support for RTSP, WebRTC, HomeKit, FFmpeg, RTMP, etc.

![](assets/go2rtc.png)

- zero-dependency and zero-config [small app](#go2rtc-binary) for all OS (Windows, macOS, Linux, ARM)
- zero-delay for many supported protocols (lowest possible streaming latency)
- streaming from [RTSP](#source-rtsp), [RTMP](#source-rtmp), [DVRIP](#source-dvrip), [HTTP](#source-http) (FLV/MJPEG/JPEG/TS), [USB Cameras](#source-ffmpeg-device) and [other sources](#module-streams)
- streaming from any sources, supported by [FFmpeg](#source-ffmpeg)
- streaming to [RTSP](#module-rtsp), [WebRTC](#module-webrtc), [MSE/MP4](#module-mp4), [HomeKit](#module-homekit) [HLS](#module-hls) or [MJPEG](#module-mjpeg)
- [publish](#publish-stream) any source to popular streaming services (YouTube, Telegram, etc.)
- first project in the World with support streaming from [HomeKit Cameras](#source-homekit)
- on-the-fly transcoding for unsupported codecs via [FFmpeg](#source-ffmpeg)
- play audio files and live streams on some cameras with [speaker](#stream-to-camera)
- multi-source two-way [codecs negotiation](#codecs-negotiation)
   - mixing tracks from different sources to single stream
   - auto-match client-supported codecs
   - [two-way audio](#two-way-audio) for some cameras
- can be [integrated to](#module-api) any smart home platform or be used as [standalone app](#go2rtc-binary)

**Inspired by:**

- series of streaming projects from [@deepch](https://github.com/deepch)
- [webrtc](https://github.com/pion/webrtc) go library and whole [@pion](https://github.com/pion) team
- [rtsp-simple-server](https://github.com/aler9/rtsp-simple-server) idea from [@aler9](https://github.com/aler9)
- [GStreamer](https://gstreamer.freedesktop.org/) framework pipeline idea
- [MediaSoup](https://mediasoup.org/) framework routing idea
- HomeKit Accessory Protocol from [@brutella](https://github.com/brutella/hap)
- creator of the project&#039;s logo [@v_novoseltsev](https://www.instagram.com/v_novoseltsev) 

&gt; [!CAUTION]
&gt; There is NO existing website for go2rtc project other than this GitHub repository. The website go2rtc[.]com is in no way associated with the authors of this project.

---

* [Fast start](#fast-start)
  * [go2rtc: Binary](#go2rtc-binary)
  * [go2rtc: Docker](#go2rtc-docker)
  * [go2rtc: Home Assistant Add-on](#go2rtc-home-assistant-add-on)
  * [go2rtc: Home Assistant Integration](#go2rtc-home-assistant-integration)
  * [go2rtc: Dev version](#go2rtc-dev-version)
* [Configuration](#configuration)
  * [Module: Streams](#module-streams)
    * [Two way audio](#two-way-audio)
    * [Source: RTSP](#source-rtsp)
    * [Source: RTMP](#source-rtmp)
    * [Source: HTTP](#source-http)
    * [Source: ONVIF](#source-onvif)
    * [Source: FFmpeg](#source-ffmpeg)
    * [Source: FFmpeg Device](#source-ffmpeg-device)
    * [Source: Exec](#source-exec)
    * [Source: Echo](#source-echo)
    * [Source: Expr](#source-expr)
    * [Source: HomeKit](#source-homekit)
    * [Source: Bubble](#source-bubble)
    * [Source: DVRIP](#source-dvrip)
    * [Source: Tapo](#source-tapo)
    * [Source: Kasa](#source-kasa)
    * [Source: Tuya](#source-tuya)
    * [Source: Xiaomi](#source-xiaomi)
    * [Source: GoPro](#source-gopro)
    * [Source: Ivideon](#source-ivideon)
    * [Source: Hass](#source-hass)
    * [Source: ISAPI](#source-isapi)
    * [Source: Nest](#source-nest)
    * [Source: Ring](#source-ring)
    * [Source: Roborock](#source-roborock)
    * [Source: Doorbird](#source-doorbird)
    * [Source: WebRTC](#source-webrtc)
    * [Source: WebTorrent](#source-webtorrent)
    * [Incoming sources](#incoming-sources)
    * [Stream to camera](#stream-to-camera)
    * [Publish stream](#publish-stream)
    * [Preload stream](#preload-stream)
  * [Module: API](#module-api)
  * [Module: RTSP](#module-rtsp)
  * [Module: RTMP](#module-rtmp)
  * [Module: WebRTC](#module-webrtc)
  * [Module: HomeKit](#module-homekit)
  * [Module: WebTorrent](#module-webtorrent)
  * [Module: ngrok](#module-ngrok)
  * [Module: Hass](#module-hass)
  * [Module: MP4](#module-mp4)
  * [Module: HLS](#module-hls)
  * [Module: MJPEG](#module-mjpeg)
  * [Module: Log](#module-log)
* [Security](#security)
* [Codecs filters](#codecs-filters)
* [Codecs madness](#codecs-madness)
* [Codecs negotiation](#codecs-negotiation)
* [Projects using go2rtc](#projects-using-go2rtc)
* [Camera experience](#cameras-experience)
* [TIPS](#tips)
* [FAQ](#faq)

## Fast start

1. Download [binary](#go2rtc-binary) or use [Docker](#go2rtc-docker) or Home Assistant [Add-on](#go2rtc-home-assistant-add-on) or [Integration](#go2rtc-home-assistant-integration)
2. Open web interface: `http://localhost:1984/`

**Optionally:**

- add your [streams](#module-streams) to [config](#configuration) file
- setup [external access](#module-webrtc) to webrtc

**Developers:**

- write your own [web interface](#module-api)
- integrate [web api](#module-api) into your smart home platform

### go2rtc: Binary

Download binary for your OS from [latest release](https://github.com/AlexxIT/go2rtc/releases/):

- `go2rtc_win64.zip` - Windows 10+ 64-bit
- `go2rtc_win32.zip` - Windows 10+ 32-bit
- `go2rtc_win_arm64.zip` - Windows ARM 64-bit
- `go2rtc_linux_amd64` - Linux 64-bit
- `go2rtc_linux_i386` - Linux 32-bit
- `go2rtc_linux_arm64` - Linux ARM 64-bit (ex. Raspberry 64-bit OS)
- `go2rtc_linux_arm` - Linux ARM 32-bit (ex. Raspberry 32-bit OS)
- `go2rtc_linux_armv6` - Linux ARMv6 (for old Raspberry 1 and Zero)
- `go2rtc_linux_mipsel` - Linux MIPS (ex. [Xiaomi Gateway 3](https://github.com/AlexxIT/XiaomiGateway3), [Wyze cameras](https://github.com/gtxaspec/wz_mini_hacks))
- `go2rtc_mac_amd64.zip` - macOS 11+ Intel 64-bit
- `go2rtc_mac_arm64.zip` - macOS ARM 64-bit
- `go2rtc_freebsd_amd64.zip` - FreeBSD 64-bit
- `go2rtc_freebsd_arm64.zip` - FreeBSD ARM 64-bit

Don&#039;t forget to fix the rights `chmod +x go2rtc_xxx_xxx` on Linux and Mac.

### go2rtc: Docker

The Docker container [`alexxit/go2rtc`](https://hub.docker.com/r/alexxit/go2rtc) supports multiple architectures including `amd64`, `386`, `arm64`, and `arm`. This container offers the same functionality as the [Home Assistant Add-on](#go2rtc-home-assistant-add-on) but is designed to operate independently of Home Assistant. It comes preinstalled with [FFmpeg](#source-ffmpeg) and [Python](#source-echo).

### go2rtc: Home Assistant Add-on

[![](https://my.home-assistant.io/badges/supervisor_addon.svg)](https://my.home-assistant.io/redirect/supervisor_addon/?addon=a889bffc_go2rtc&amp;repository_url=https%3A%2F%2Fgithub.com%2FAlexxIT%2Fhassio-addons)

1. Install Add-On:
    - Settings &gt; Add-ons &gt; Plus &gt; Repositories &gt; Add `https://github.com/AlexxIT/hassio-addons`
    - go2rtc &gt; Install &gt; Start
2. Setup [Integration](#module-hass)

### go2rtc: Home Assistant Integration

[WebRTC Camera](https://github.com/AlexxIT/WebRTC) custom component can be used on any [Home Assistant installation](https://www.home-assistant.io/installation/), including [HassWP](https://github.com/AlexxIT/HassWP) on Windows. It can automatically download and use the latest version of go2rtc. Or it can connect to an existing version of go2rtc. Addon installation in this case is optional.

### go2rtc: Dev version

Latest, but maybe unstable version:

- Binary: [latest nightly release](https://nightly.link/AlexxIT/go2rtc/workflows/build/master)
- Docker: `alexxit/go2rtc:master` or `alexxit/go2rtc:master-hardware` versions
- Hass Add-on: `go2rtc master` or `go2rtc master hardware` versions

## Configuration

- by default go2rtc will search `go2rtc.yaml` in the current work directory
- `api` server will start on default **1984 port** (TCP)
- `rtsp` server will start on default **8554 port** (TCP)
- `webrtc` will use port **8555** (TCP/UDP) for connections
- `ffmpeg` will use default transcoding options

Configuration options and a complete list of settings can be found in [the wiki](https://github.com/AlexxIT/go2rtc/wiki/Configuration).

Available modules:

- [streams](#module-streams)
- [api](#module-api) - HTTP API (important for WebRTC support)
- [rtsp](#module-rtsp) - RTSP Server (important for FFmpeg support)
- [webrtc](#module-webrtc) - WebRTC Server
- [mp4](#module-mp4) - MSE, MP4 stream and MP4 snapshot Server
- [hls](#module-hls) - HLS TS or fMP4 stream Server
- [mjpeg](#module-mjpeg) - MJPEG Server
- [ffmpeg](#source-ffmpeg) - FFmpeg integration
- [ngrok](#module-ngrok) - ngrok integration (external access for private network)
- [hass](#module-hass) - Home Assistant integration
- [log](#module-log) - logs config

### Module: Streams

**go2rtc** supports different stream source types. You can config one or multiple links of any type as a stream source.

Available source types:

- [rtsp](#source-rtsp) - `RTSP` and `RTSPS` cameras with [two-way audio](#two-way-audio) support
- [rtmp](#source-rtmp) - `RTMP` streams
- [http](#source-http) - `HTTP-FLV`, `MPEG-TS`, `JPEG` (snapshots), `MJPEG` streams
- [onvif](#source-onvif) - get camera `RTSP` link and snapshot link using `ONVIF` protocol
- [ffmpeg](#source-ffmpeg) - FFmpeg integration (`HLS`, `files` and many others)
- [ffmpeg:device](#source-ffmpeg-device) - local USB Camera or Webcam
- [exec](#source-exec) - get media from external app output
- [echo](#source-echo) - get stream link from bash or python
- [expr](#source-expr) - get stream link via built-in expression language
- [homekit](#source-homekit) - streaming from HomeKit Camera
- [bubble](#source-bubble) - streaming from ESeeCloud/dvr163 NVR
- [dvrip](#source-dvrip) - streaming from DVR-IP NVR
- [eseecloud](#source-eseecloud) - streaming from ESeeCloud/dvr163 NVR
- [tapo](#source-tapo) - TP-Link Tapo cameras with [two way audio](#two-way-audio) support
- [ring](#source-ring) - Ring cameras with [two way audio](#two-way-audio) support
- [tuya](#source-tuya) - Tuya cameras with [two way audio](#two-way-audio) support
- [xiaomi](#source-xiaomi) - Xiaomi cameras with [two way audio](#two-way-audio) support
- [kasa](#source-tapo) - TP-Link Kasa cameras
- [gopro](#source-gopro) - GoPro cameras
- [ivideon](#source-ivideon) - public cameras from [Ivideon](https://tv.ivideon.com/) service
- [hass](#source-hass) - Home Assistant integration
- [isapi](#source-isapi) - two-way audio for Hikvision (ISAPI) cameras
- [roborock](#source-roborock) - Roborock vacuums with cameras
- [doorbird](#source-doorbird) - Doorbird cameras with [two way audio](#two-way-audio) support
- [webrtc](#source-webrtc) - WebRTC/WHEP sources
- [webtorrent](#source-webtorrent) - WebTorrent source from another go2rtc

Read more about [incoming sources](#incoming-sources)

#### Two-way audio

Supported sources:

- [RTSP cameras](#source-rtsp) with [ONVIF Profile T](https://www.onvif.org/specs/stream/ONVIF-Streaming-Spec.pdf) (back channel connection)
- [DVRIP](#source-dvrip) cameras
- [TP-Link Tapo](#source-tapo) cameras
- [Hikvision ISAPI](#source-isapi) cameras
- [Roborock vacuums](#source-roborock) models with cameras
- [Doorbird](#source-doorbird) cameras
- [Exec](#source-exec) audio on server
- [Ring](#source-ring) cameras
- [Tuya](#source-tuya) cameras
- [Xiaomi](#source-xiaomi) cameras
- [Any Browser](#incoming-browser) as IP-camera

Two-way audio can be used in browser with [WebRTC](#module-webrtc) technology. The browser will give access to the microphone only for HTTPS sites ([read more](https://stackoverflow.com/questions/52759992/how-to-access-camera-and-microphone-in-chrome-without-https)).

go2rtc also supports [play audio](#stream-to-camera) files and live streams on this cameras.

#### Source: RTSP

```yaml
streams:
  sonoff_camera: rtsp://rtsp:12345678@192.168.1.123/av_stream/ch0
  dahua_camera:
    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=0&amp;unicast=true&amp;proto=Onvif
    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=1#backchannel=0
  amcrest_doorbell:
    - rtsp://username:password@192.168.1.123:554/cam/realmonitor?channel=1&amp;subtype=0#backchannel=0
  unifi_camera: rtspx://192.168.1.123:7441/fD6ouM72bWoFijxK
  glichy_camera: ffmpeg:rtsp://username:password@192.168.1.123/live/ch00_1 
```

**Recommendations**

- **Amcrest Doorbell** users may want to disable two-way audio, because with an active stream, you won&#039;t have a working call button. You need to add `#backchannel=0` to the end of your RTSP link in YAML config file
- **Dahua Doorbell** users may want to change [audio codec](https://github.com/AlexxIT/go2rtc/issues/49#issuecomment-2127107379) for proper 2-way audio. Make sure not to request backchannel multiple times by adding `#backchannel=0` to other stream sources of the same doorbell. The `unicast=true&amp;proto=Onvif` is preferred for 2-way audio as this makes the doorbell accept multiple codecs for the incoming audio
- **Reolink** users may want NOT to use RTSP protocol at all, some camera models have a very awful, unusable stream implementation
- **Ubiquiti UniFi** users may want to disable HTTPS verification. Use `rtspx://` prefix instead of `rtsps://`. And don&#039;t use `?enableSrtp` [suffix](https://github.com/AlexxIT/go2rtc/issues/81)
- **TP-Link Tapo** users may skip login and password, because go2rtc support login [without them](https://drmnsamoliu.github.io/video.html)
- If your camera has two RTSP links, you can add both as sources. This is useful when streams have different codecs, for example AAC audio with main stream and PCMU/PCMA audio with second stream
- If the stream from your camera is glitchy, try using [ffmpeg source](#source-ffmpeg). It will not add CPU load if you don&#039;t use transcoding
- If the stream from your camera is very glitchy, try to use transcoding with [ffmpeg source](#source-ffmpeg)

**Other options**

Format: `rtsp...#{param1}#{param2}#{param3}`

- Add custom timeout `#timeout=30` (in seconds)
- Ignore audio - `#media=video` or ignore video - `#media=audio` 
- Ignore two-way audio API `#backchannel=0` - important for some glitchy cameras
- Use WebSocket transport `#transport=ws...`

**RTSP over WebSocket**

```yaml
streams:
  # WebSocket with authorization, RTSP - without
  axis-rtsp-ws:  rtsp://192.168.1.123:4567/axis-media/media.amp?overview=0&amp;camera=1&amp;resolution=1280x720&amp;videoframeskipmode=empty&amp;Axis-Orig-Sw=true#transport=ws://user:pass@192.168.1.123:4567/rtsp-over-websocket
  # WebSocket without authorization, RTSP - with
  dahua-rtsp-ws: rtsp://user:pass@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=1&amp;proto=Private3#transport=ws://192.168.1.123/rtspoverwebsocket
```

#### Source: RTMP

You can get a stream from an RTMP server, for example [Nginx with nginx-rtmp-module](https://github.com/arut/nginx-rtmp-module).

```yaml
streams:
  rtmp_stream: rtmp://192.168.1.123/live/camera1
```

#### Source: HTTP

Support Content-Type:

- **HTTP-FLV** (`video/x-flv`) - same as RTMP, but over HTTP
- **HTTP-JPEG** (`image/jpeg`) - camera snapshot link, can be converted by go2rtc to MJPEG stream
- **HTTP-MJPEG** (`multipart/x`) - simple MJPEG stream over HTTP
- **MPEG-TS** (`video/mpeg`) - legacy [streaming format](https://en.wikipedia.org/wiki/MPEG_transport_stream)

Source also supports HTTP and TCP streams with autodetection for different formats: **MJPEG**, **H.264/H.265 bitstream**, **MPEG-TS**.

```yaml
streams:
  # [HTTP-FLV] stream in video/x-flv format
  http_flv: http://192.168.1.123:20880/api/camera/stream/780900131155/657617
  
  # [JPEG] snapshots from Dahua camera, will be converted to MJPEG stream
  dahua_snap: http://admin:password@192.168.1.123/cgi-bin/snapshot.cgi?channel=1

  # [MJPEG] stream will be proxied without modification
  http_mjpeg: https://mjpeg.sanford.io/count.mjpeg

  # [MJPEG or H.264/H.265 bitstream or MPEG-TS]
  tcp_magic: tcp://192.168.1.123:12345

  # Add custom header
  custom_header: &quot;https://mjpeg.sanford.io/count.mjpeg#header=Authorization: Bearer XXX&quot;
```

**PS.** Dahua camera has a bug: if you select MJPEG codec for RTSP second stream, snapshot won&#039;t work.

#### Source: ONVIF

*[New in v1.5.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.5.0)*

The source is not very useful if you already know RTSP and snapshot links for your camera. But it can be useful if you don&#039;t.

**WebUI &gt; Add** webpage support ONVIF autodiscovery. Your server must be on the same subnet as the camera. If you use Docker, you must use &quot;network host&quot;.

```yaml
streams:
  dahua1: onvif://admin:password@192.168.1.123
  reolink1: onvif://admin:password@192.168.1.123:8000
  tapo1: onvif://admin:password@192.168.1.123:2020
```

#### Source: FFmpeg

You can get any stream, file or device via FFmpeg and push it to go2rtc. The app will automatically start FFmpeg with the proper arguments when someone starts watching the stream.

- FFmpeg preistalled for **Docker** and **Hass Add-on** users
- **Hass Add-on** users can target files from [/media](https://www.home-assistant.io/more-info/local-media/setup-media/) folder

Format: `ffmpeg:{input}#{param1}#{param2}#{param3}`. Examples:

```yaml
streams:
  # [FILE] all tracks will be copied without transcoding codecs
  file1: ffmpeg:/media/BigBuckBunny.mp4

  # [FILE] video will be transcoded to H264, audio will be skipped
  file2: ffmpeg:/media/BigBuckBunny.mp4#video=h264

  # [FILE] video will be copied, audio will be transcoded to PCMU
  file3: ffmpeg:/media/BigBuckBunny.mp4#video=copy#audio=pcmu

  # [HLS] video will be copied, audio will be skipped
  hls: ffmpeg:https://devstreaming-cdn.apple.com/videos/streaming/examples/bipbop_16x9/gear5/prog_index.m3u8#video=copy

  # [MJPEG] video will be transcoded to H264
  mjpeg: ffmpeg:http://185.97.122.128/cgi-bin/faststream.jpg#video=h264

  # [RTSP] video with rotation, should be transcoded, so select H264
  rotate: ffmpeg:rtsp://12345678@192.168.1.123/av_stream/ch0#video=h264#rotate=90
```

All transcoding formats have [built-in templates](https://github.com/AlexxIT/go2rtc/blob/master/internal/ffmpeg/ffmpeg.go): `h264`, `h265`, `opus`, `pcmu`, `pcmu/16000`, `pcmu/48000`, `pcma`, `pcma/16000`, `pcma/48000`, `aac`, `aac/16000`.

But you can override them via YAML config. You can also add your own formats to the config and use them with source params.

```yaml
ffmpeg:
  bin: ffmpeg  # path to ffmpeg binary
  h264: &quot;-codec:v libx264 -g:v 30 -preset:v superfast -tune:v zerolatency -profile:v main -level:v 4.1&quot;
  mycodec: &quot;-any args that supported by ffmpeg...&quot;
  myinput: &quot;-fflags nobuffer -flags low_delay -timeout 5000000 -i {input}&quot;
  myraw: &quot;-ss 00:00:20&quot;
```

- You can use go2rtc stream name as ffmpeg input (ex. `ffmpeg:camera1#video=h264`)
- You can use `video` and `audio` params multiple times (ex. `#video=copy#audio=copy#audio=pcmu`)
- You can use `rotate` param with `90`, `180`, `270` or `-90` values, important with transcoding (ex. `#video=h264#rotate=90`)
- You can use `width` and/or `height` params, important with transcoding (ex. `#video=h264#width=1280`)
- You can use `drawtext` to add a timestamp (ex. `drawtext=x=2:y=2:fontsize=12:fontcolor=white:box=1:boxcolor=black`)
  - This will greatly increase the CPU of the server, even with hardware acceleration
- You can use `raw` param for any additional FFmpeg arguments (ex. `#raw=-vf transpose=1`)
- You can use `input` param to override default input template (ex. `#input=rtsp/udp` will change RTSP transport from TCP to UDP+TCP)
  - You can use raw

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[NexaAI/nexa-sdk]]></title>
            <link>https://github.com/NexaAI/nexa-sdk</link>
            <guid>https://github.com/NexaAI/nexa-sdk</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[Run the latest LLMs and VLMs across GPU, NPU, and CPU with PC (Python/C++) & mobile (Android & iOS) support, running quickly with OpenAI gpt-oss, Granite4, Qwen3VL, Gemma 3n and more.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NexaAI/nexa-sdk">NexaAI/nexa-sdk</a></h1>
            <p>Run the latest LLMs and VLMs across GPU, NPU, and CPU with PC (Python/C++) & mobile (Android & iOS) support, running quickly with OpenAI gpt-oss, Granite4, Qwen3VL, Gemma 3n and more.</p>
            <p>Language: Go</p>
            <p>Stars: 6,215</p>
            <p>Forks: 821</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;
      &lt;img width=&quot;100%&quot; src=&quot;assets/banner1.png&quot; alt=&quot;Nexa AI Banner&quot;&gt;
      &lt;div align=&quot;center&quot;&gt;
        &lt;p style=&quot;font-size: 1.3em; font-weight: 600; margin-bottom: 20px;&quot;&gt;ü§ù Supported chipmakers &lt;/p&gt;
          &lt;picture&gt;
            &lt;source srcset=&quot;assets/chipmakers-dark.png&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
            &lt;source srcset=&quot;assets/chipmakers.png&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
            &lt;img src=&quot;assets/chipmakers.png&quot; style=&quot;max-height:30px; height:auto; width:auto;&quot;&gt;
          &lt;/picture&gt;
        &lt;/p&gt;
      &lt;/div&gt;
  &lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://docs.nexa.ai&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/docs-website-brightgreen?logo=readthedocs&quot; alt=&quot;Documentation&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://sdk.nexa.ai/wishlist&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/üéØ_Vote_for-Next_Models-ff69b4?style=flat-square&quot; alt=&quot;Vote for Next Models&quot;&gt;
    &lt;/a&gt;
   &lt;a href=&quot;https://x.com/nexa_ai&quot;&gt;&lt;img alt=&quot;X account&quot; src=&quot;https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&amp;label=Follow%20%40Nexa_AI&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.com/invite/nexa-ai&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1192186167391682711?color=5865F2&amp;logo=discord&amp;logoColor=white&amp;style=flat-square&quot; alt=&quot;Join us on Discord&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://join.slack.com/t/nexa-ai-community/shared_invite/zt-3837k9xpe-LEty0disTTUnTUQ4O3uuNw&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/slack-join%20chat-4A154B?logo=slack&amp;logoColor=white&quot; alt=&quot;Join us on Slack&quot;&gt;
    &lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

# NexaSDK - Run any AI model on any backend

NexaSDK is an easy-to-use developer toolkit for running any AI model locally ‚Äî across NPUs, GPUs, and CPUs ‚Äî powered by our NexaML engine, built entirely from scratch for peak performance on every hardware stack. Unlike wrappers that depend on existing runtimes, NexaML is a unified inference engine built at the kernel level. It‚Äôs what lets NexaSDK achieve Day-0 support for new model architectures (LLMs, multimodal, audio, vision). NexaML supports 3 model formats: GGUF, MLX, and Nexa AI&#039;s own `.nexa` format.

### ‚öôÔ∏è Differentiation

&lt;div align=&quot;center&quot;&gt;

| Features                                    | **NexaSDK**                         | **Ollama** | **llama.cpp** | **LM Studio** |
| ------------------------------------------- | ----------------------------------- | ---------- | ------------- | ------------- |
| NPU support                                 | ‚úÖ NPU-first                        | ‚ùå         | ‚ùå            | ‚ùå            |
| Android SDK support                         | ‚úÖ NPU/GPU/CPU support              | ‚ö†Ô∏è         | ‚ö†Ô∏è            | ‚ùå            |
| Support any model in GGUF, MLX, NEXA format | ‚úÖ Low-level Control                | ‚ùå         | ‚ö†Ô∏è            | ‚ùå            |
| Full multimodality support                  | ‚úÖ Image, Audio, Text               | ‚ö†Ô∏è         | ‚ö†Ô∏è            | ‚ö†Ô∏è            |
| Cross-platform support                      | ‚úÖ Desktop, Mobile, Automotive, IoT | ‚ö†Ô∏è         | ‚ö†Ô∏è            | ‚ö†Ô∏è            |
| One line of code to run                     | ‚úÖ                                  | ‚úÖ         | ‚ö†Ô∏è            | ‚úÖ            |
| OpenAI-compatible API + Function calling    | ‚úÖ                                  | ‚úÖ         | ‚úÖ            | ‚úÖ            |

&lt;p align=&quot;center&quot; style=&quot;margin-top:14px&quot;&gt;
  &lt;i&gt;
      &lt;b&gt;Legend:&lt;/b&gt;
      &lt;span title=&quot;Full support&quot;&gt;‚úÖ Supported&lt;/span&gt; &amp;nbsp; | &amp;nbsp;
      &lt;span title=&quot;Partial or limited support&quot;&gt;‚ö†Ô∏è Partial or limited support &lt;/span&gt; &amp;nbsp; | &amp;nbsp;
      &lt;span title=&quot;Not Supported&quot;&gt;‚ùå No&lt;/span&gt;
  &lt;/i&gt;
&lt;/p&gt;
&lt;/div&gt;

## Recent Wins
- üì£ Release Nexa AI‚Äôs **AutoNeural-VL-1.5B**, an NPU-native vision‚Äìlanguage model built for real-time in-car assistants, delivering **14√ó** lower latency, **3√ó** faster decode, and **4√ó** longer context on Qualcomm SA8295P ‚Äî now also runnable on Qualcomm X Elite laptops.
- üì£ Support Mistral AI&#039;s **Ministral-3-3B** across Qualcomm Hexagon NPU, Apple Neural Engine, GPU and CPU.
- üì£ Release **Linux SDK** for NPU/GPU/CPU. See [Linux SDK Doc](https://docs.nexa.ai/nexa-sdk-docker/overview).
- üì£ Support **Apple Neural Engine** for [Granite-4.0](https://huggingface.co/NexaAI/Granite-4-Micro-ANE), [Qwen3](https://huggingface.co/NexaAI/Qwen3-0.6B-ANE), [Gemma3](https://huggingface.co/NexaAI/Gemma3-1B-ANE), and [Parakeetv3](https://huggingface.co/NexaAI/parakeet-tdt-0.6b-v3-ane). Download NexaSDK for ANE [here](https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/nexa_sdk/downloads/nexa-cli_macos_arm64_ane.pkg).
- üì£ Support **Android SDK** for NPU/GPU/CPU. See [Android SDK Doc](https://docs.nexa.ai/nexa-sdk-android/overview) and [Android SDK Demo App](bindings/android/README.md).
- üì£ Support **SDXL-turbo** image generation on AMD NPU. See [AMD blog : Advancing AI with Nexa AI](https://www.amd.com/en/developer/resources/technical-articles/2025/advancing-ai-with-nexa-ai--image-generation-on-amd-npu-with-sdxl.html).
- Support Android **Python SDK** for NPU/GPU/CPU. See [Android Python SDK Doc](https://docs.nexa.ai/nexa-sdk-android/python) and [Android Python SDK Demo App](bindings/android/README.md).
- üì£ Day-0 Support for **Qwen3-VL-4B and 8B** in GGUF, MLX, .nexa format for NPU/GPU/CPU. We are the only framework that supports the GGUF format. [Featured in Qwen&#039;s post about our partnership](https://x.com/Alibaba_Qwen/status/1978154384098754943).
- üì£ Day-0 Support for **IBM Granite 4.0** on NPU/GPU/CPU. [NexaML engine were featured right next to vLLM, llama.cpp, and MLX in IBM&#039;s blog](https://x.com/IBM/status/1978154384098754943).
- üì£ Day-0 Support for **Google EmbeddingGemma** on NPU. We are [featured in Google&#039;s social post](https://x.com/googleaidevs/status/1969188152049889511).
- üì£ Supported **vision capability for Gemma3n**: First-ever [Gemma-3n](https://sdk.nexa.ai/model/Gemma3n-E4B) **multimodal** inference for GPU &amp; CPU, in GGUF format.
- üì£ **Intel NPU** Support [DeepSeek-r1-distill-Qwen-1.5B](https://sdk.nexa.ai/model/DeepSeek-R1-Distill-Qwen-1.5B-Intel-NPU) and [Llama3.2-3B](https://sdk.nexa.ai/model/Llama3.2-3B-Intel-NPU)
- üì£ **Apple Neural Engine** Support for real-time speech recognition with [Parakeet v3 model](https://sdk.nexa.ai/model/parakeet-v3-ane)

# Quick Start

## Step 1: Download Nexa CLI with one click

### macOS
- [arm64 for Apple Neural Engine](https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/nexa_sdk/downloads/nexa-cli_macos_arm64_ane.pkg)
- [arm64 for MLX](https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_macos_arm64.pkg)
- [x86_64](https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_macos_x86_64.pkg)

### Windows

- [arm64 with Qualcomm NPU support](https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_windows_arm64.exe)
- [x86_64 with Intel / AMD NPU support](https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_windows_x86_64.exe)

### Linux

#### For x86_64:

```bash
curl -fsSL https://github.com/NexaAI/nexa-sdk/releases/latest/download/nexa-cli_linux_x86_64.sh -o install.sh &amp;&amp; chmod +x install.sh &amp;&amp; ./install.sh &amp;&amp; rm install.sh
```

#### For arm64:

```bash
curl -fsSL https://github.com/NexaAI/nexa-sdk/releases/latest/download/nexa-cli_linux_arm64.sh -o install.sh &amp;&amp; chmod +x install.sh &amp;&amp; ./install.sh &amp;&amp; rm install.sh
```

#### Uninstall

```bash
sudo rm -r /opt/nexa_sdk
sudo rm /usr/local/bin/nexa
# if you want to remove data as well
# rm -r $HOME/.cache/nexa.ai
```

## Step 2: Run models with one line of code

You can run any compatible GGUF, MLX, or nexa model from ü§ó Hugging Face by using the `nexa infer &lt;full repo name&gt;`.

### GGUF models

&gt; [!TIP]
&gt; GGUF runs on macOS, Linux, and Windows on CPU/GPU. Note certain GGUF models are only supported by NexaSDK (e.g. Qwen3-VL-4B and 8B).

üìù Run and chat with LLMs, e.g. Qwen3:

```bash
nexa infer ggml-org/Qwen3-1.7B-GGUF
```

üñºÔ∏è Run and chat with Multimodal models, e.g. Qwen3-VL-4B:

```bash
nexa infer NexaAI/Qwen3-VL-4B-Instruct-GGUF
```

### MLX models

&gt; [!TIP]
&gt; MLX is macOS-only (Apple Silicon). Many MLX models in the Hugging Face mlx-community organization have quality issues and may not run reliably.
&gt; We recommend starting with models from our curated [NexaAI Collection](https://huggingface.co/NexaAI/collections) for best results. For example

üìù Run and chat with LLMs, e.g. Qwen3:

```bash
nexa infer NexaAI/Qwen3-4B-4bit-MLX
```

üñºÔ∏è Run and chat with Multimodal models, e.g. Gemma3n:

```bash
nexa infer NexaAI/gemma-3n-E4B-it-4bit-MLX
```

### Qualcomm NPU models

&gt; [!TIP]
&gt; You need to download the [arm64 with Qualcomm NPU support](https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_windows_arm64.exe) and make sure you have Snapdragon¬Æ X Elite chip on your laptop.

#### Quick Start (Windows arm64, Snapdragon X Elite)

1. **Login &amp; Get Access Token (required for Pro Models)**
   - Create an account at [sdk.nexa.ai](https://sdk.nexa.ai)
   - Go to **Deployment ‚Üí Create Token**
   - Run this once in your terminal (replace with your token):
     ```bash
     nexa config set license &#039;&lt;your_token_here&gt;&#039;
     ```

2. Run and chat with our multimodal model, OmniNeural-4B, or other models on NPU

```bash
nexa infer NexaAI/OmniNeural-4B
nexa infer NexaAI/Granite-4-Micro-NPU
nexa infer NexaAI/Qwen3-VL-4B-Instruct-NPU
```

## CLI Reference

| Essential Command                   | What it does                             |
| ----------------------------------- | ---------------------------------------- |
| `nexa -h`                           | show all CLI commands                    |
| `nexa pull &lt;repo&gt;`                  | Interactive download &amp; cache of a model  |
| `nexa infer &lt;repo&gt;`                 | Local inference                          |
| `nexa list`                         | Show all cached models with sizes        |
| `nexa remove &lt;repo&gt;` / `nexa clean` | Delete one / all cached models           |
| `nexa serve --host 127.0.0.1:8080`  | Launch OpenAI‚Äëcompatible REST server     |
| `nexa run &lt;repo&gt;`                   | Chat with a model via an existing server |

üëâ To interact with multimodal models, you can drag photos or audio clips directly into the CLI ‚Äî you can even drop multiple images at once!

See [CLI Reference](https://nexaai.mintlify.app/nexa-sdk-go/NexaCLI) for full commands.

### Import model from local filesystem

```bash
# hf download &lt;model&gt; --local-dir /path/to/modeldir
nexa pull &lt;model&gt; --model-hub localfs --local-path /path/to/modeldir
```

## üéØ You Decide What Model We Support Next

**[Nexa Wishlist](https://sdk.nexa.ai/wishlist)** ‚Äî Request and vote for the models you want to run on-device.

Drop a Hugging Face repo ID, pick your preferred backend (GGUF, MLX, or Nexa format for Qualcomm + Apple NPUs), and watch the community&#039;s top requests go live in NexaSDK.

üëâ **[Vote now at sdk.nexa.ai/wishlist](https://sdk.nexa.ai/wishlist)**

## Acknowledgements

We would like to thank the following projects:

- [ggml](https://github.com/ggml-org/ggml)
- [mlx-lm](https://github.com/ml-explore/mlx-lm)
- [mlx-vlm](https://github.com/Blaizzy/mlx-vlm)
- [mlx-audio](https://github.com/Blaizzy/mlx-audio)

## Join Builder Bounty Program

Earn up to 1,500 USD for building with NexaSDK.

![Developer Bounty](assets/developer_bounty.png)

Learn more in our [Participant Details](https://docs.nexa.ai/community/builder-bounty).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[prometheus-operator/prometheus-operator]]></title>
            <link>https://github.com/prometheus-operator/prometheus-operator</link>
            <guid>https://github.com/prometheus-operator/prometheus-operator</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[Prometheus Operator creates/configures/manages Prometheus clusters atop Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prometheus-operator/prometheus-operator">prometheus-operator/prometheus-operator</a></h1>
            <p>Prometheus Operator creates/configures/manages Prometheus clusters atop Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 9,782</p>
            <p>Forks: 3,825</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># Prometheus Operator

[![Build Status](https://github.com/prometheus-operator/prometheus-operator/actions/workflows/checks.yaml/badge.svg)](https://github.com/prometheus-operator/prometheus-operator/actions)
[![Go Report Card](https://goreportcard.com/badge/prometheus-operator/prometheus-operator &quot;Go Report Card&quot;)](https://goreportcard.com/report/prometheus-operator/prometheus-operator)
[![Slack](https://img.shields.io/badge/join%20slack-%23prometheus--operator-brightgreen.svg)](https://kubernetes.slack.com)

## Overview

The Prometheus Operator provides [Kubernetes](https://kubernetes.io/) native deployment and management of
[Prometheus](https://prometheus.io/) and related monitoring components. The purpose of this project is to
simplify and automate the configuration of a Prometheus based monitoring stack for Kubernetes clusters.

The Prometheus operator includes, but is not limited to, the following features:

* **Kubernetes Custom Resources**: Use Kubernetes custom resources to deploy and manage Prometheus, Alertmanager,
  and related components.

* **Simplified Deployment Configuration**: Configure the fundamentals of Prometheus like versions, persistence,
  retention policies, and replicas from a native Kubernetes resource.

* **Prometheus Target Configuration**: Automatically generate monitoring target configurations based
  on familiar Kubernetes label queries; no need to learn a Prometheus specific configuration language.

For an introduction to the Prometheus Operator, see the [getting started](https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/developer/getting-started.md) guide.

## Project Status

The operator in itself is considered to be production ready. Please refer to the Custom Resource Definition (CRD) versions for the status of each CRD:

* `monitoring.coreos.com/v1`: **stable** CRDs and API, changes are made in a backward-compatible way.
* `monitoring.coreos.com/v1beta1`: **unstable** CRDs and API, changes can happen but the team is focused on avoiding them. We encourage usage in production for users that accept the risk of breaking changes.
* `monitoring.coreos.com/v1alpha1`: **unstable** CRDs and API, changes can happen frequently, and we suggest avoiding its usage on mission-critical environments.

## Prometheus Operator vs. kube-prometheus vs. community Helm chart

### Prometheus Operator

The Prometheus Operator uses Kubernetes [custom resources](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/) to simplify the deployment and configuration of Prometheus, Alertmanager, and related monitoring components.

### kube-prometheus

[kube-prometheus](https://github.com/prometheus-operator/kube-prometheus) provides example configurations for a complete cluster monitoring
stack based on Prometheus and the Prometheus Operator. This includes deployment of multiple Prometheus and Alertmanager instances,
metrics exporters such as the node_exporter for gathering node metrics, scrape target configuration linking Prometheus to various
metrics endpoints, and example alerting rules for notification of potential issues in the cluster.

### Helm chart

The [prometheus-community/kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack)
Helm chart provides a similar feature set to kube-prometheus. This chart is maintained by the Prometheus community.
For more information, please see the [chart&#039;s readme](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack#kube-prometheus-stack)

## Prerequisites

The Prometheus Operator requires at least Kubernetes version `1.16.0`. If you
are just starting out with the Prometheus Operator, it is highly recommended to
use the latest [stable
release](https://github.com/prometheus-operator/prometheus-operator/releases/latest).

## CustomResourceDefinitions

A core feature of the Prometheus Operator is to monitor the Kubernetes API server for changes
to specific objects and ensure that the current Prometheus deployments match these objects.
The Operator acts on the following [Custom Resource Definitions (CRDs)](https://kubernetes.io/docs/tasks/access-kubernetes-api/extend-api-custom-resource-definitions/):

* **`Prometheus`**, which defines a desired Prometheus deployment.

* **`PrometheusAgent`**, which defines a desired Prometheus deployment, but running in Agent mode.

* **`Alertmanager`**, which defines a desired Alertmanager deployment.

* **`ThanosRuler`**, which defines a desired Thanos Ruler deployment.

* **`ServiceMonitor`**, which declaratively specifies how groups of Kubernetes services should be monitored.
  The Operator automatically generates Prometheus scrape configuration based on the current state of the objects in the API server.

* **`PodMonitor`**, which declaratively specifies how group of pods should be monitored.
  The Operator automatically generates Prometheus scrape configuration based on the current state of the objects in the API server.

* **`Probe`**, which declaratively specifies how groups
  of ingresses or static targets should be monitored. The Operator automatically generates Prometheus scrape configuration
  based on the definition.

* **`ScrapeConfig`**, which declaratively specifies scrape configurations to be added to Prometheus. This CustomResourceDefinition helps with scraping resources outside the Kubernetes cluster.

* **`PrometheusRule`**, which defines a desired set of Prometheus alerting and/or recording rules.
  The Operator generates a rule file, which can be used by Prometheus instances.

* **`AlertmanagerConfig`**, which declaratively specifies subsections of the Alertmanager configuration, allowing
  routing of alerts to custom receivers, and setting inhibit rules.

The Prometheus operator automatically detects changes in the Kubernetes API server to any of the above objects, and ensures that
matching deployments and configurations are kept in sync.

To learn more about the CRDs introduced by the Prometheus Operator have a look
at the [design](https://prometheus-operator.dev/docs/getting-started/design/) page.

## Dynamic Admission Control

To prevent invalid Prometheus alerting and recording rules from causing failures in a deployed Prometheus instance,
an [admission webhook](https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/)
is provided to validate `PrometheusRule` resources upon initial creation or update.

For more information on this feature, see the [user guide](https://prometheus-operator.dev/docs/platform/webhook/).

## Quickstart

**Note:** this quickstart does not provision an entire monitoring stack; if that is what you are looking for,
see the [kube-prometheus](https://github.com/prometheus-operator/kube-prometheus) project. If you want the whole stack,
but have already applied the `bundle.yaml`, delete the bundle first (`kubectl delete -f bundle.yaml`).

To quickly try out *just* the Prometheus Operator inside a cluster, **choose a release** and run the following command which deploys the operator in the `default` namespace:

```sh
kubectl create -f bundle.yaml
```

If you want to deploy the Prometheus operator in a different namespace, you also need `kustomize`:

```sh
NAMESPACE=my_namespace kustomize edit set namespace $NAMESPACE &amp;&amp; kubectl create -k .
```

&gt; Note: make sure to adapt the namespace in the ClusterRoleBinding if deploying in a namespace other than the default namespace.

To run the Operator outside of a cluster:

```sh
make
scripts/run-external.sh &lt;kubectl cluster name&gt;
```

## Removal

To remove the operator and Prometheus, first delete any custom resources you created in each namespace. The
operator will automatically shut down and remove Prometheus and Alertmanager pods, and associated ConfigMaps.

```sh
for n in $(kubectl get namespaces -o jsonpath={..metadata.name}); do
  kubectl delete --all --namespace=$n prometheus,servicemonitor,podmonitor,alertmanager
done
```

After a couple of minutes you can go ahead and remove the operator itself.

```sh
kubectl delete -f bundle.yaml
```

The operator automatically creates services in each namespace where you created a Prometheus or Alertmanager resources,
and defines three custom resource definitions. You can clean these up now.

```sh
for n in $(kubectl get namespaces -o jsonpath={..metadata.name}); do
  kubectl delete --ignore-not-found --namespace=$n service prometheus-operated alertmanager-operated
done

kubectl delete --ignore-not-found customresourcedefinitions \
  prometheuses.monitoring.coreos.com \
  servicemonitors.monitoring.coreos.com \
  podmonitors.monitoring.coreos.com \
  alertmanagers.monitoring.coreos.com \
  prometheusrules.monitoring.coreos.com \
  alertmanagerconfigs.monitoring.coreos.com \
  scrapeconfigs.monitoring.coreos.com
```

## Testing

See [TESTING](TESTING.md)

## Contributing

See [CONTRIBUTING](CONTRIBUTING.md).

## Security

If you find a security vulnerability related to the Prometheus Operator which
isn&#039;t already publicly disclosed, please do not report it by opening a GitHub
issue, but instead please send an e-mail to the maintainers of the project
found in the [MAINTAINERS.md](MAINTAINERS.md) file.

Please refer to the [Prometheus
documentation](https://prometheus.io/docs/operating/security/#automated-security-scanners)
when reporting issues from automated security scanners.

## Troubleshooting

Check the [troubleshooting documentation](Documentation/platform/troubleshooting.md) for
common issues and frequently asked questions (FAQ).

## Acknowledgements

prometheus-operator organization logo was created and contributed by [Bianca Cheng Costanzo](https://github.com/bia).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[jaegertracing/jaeger]]></title>
            <link>https://github.com/jaegertracing/jaeger</link>
            <guid>https://github.com/jaegertracing/jaeger</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[CNCF Jaeger, a Distributed Tracing Platform]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jaegertracing/jaeger">jaegertracing/jaeger</a></h1>
            <p>CNCF Jaeger, a Distributed Tracing Platform</p>
            <p>Language: Go</p>
            <p>Stars: 22,235</p>
            <p>Forks: 2,694</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>[![Stand With Ukraine](https://raw.githubusercontent.com/vshymanskyy/StandWithUkraine/main/banner2-direct.svg)](https://stand-with-ukraine.pp.ua)

&lt;img align=&quot;right&quot; width=&quot;290&quot; height=&quot;290&quot; src=&quot;https://www.jaegertracing.io/img/jaeger-vector.svg&quot;&gt;

[![Slack chat][slack-img]](#get-in-touch)
[![Unit Tests][ci-img]][ci]
[![Coverage Status][cov-img]][cov]
[![Project+Community stats][community-badge]][community-stats]
[![FOSSA Status][fossa-img]][fossa]
[![OpenSSF Scorecard][openssf-img]][openssf]
[![OpenSSF Best Practices][openssf-bp-img]][openssf-bp] 
[![CLOMonitor][clomonitor-img]][clomonitor]
[![Artifact Hub][artifacthub-img]][artifacthub]

&lt;img src=&quot;https://raw.githubusercontent.com/cncf/artwork/main/other/cncf-member/graduated/color/cncf-graduated-color.svg&quot; width=&quot;250&quot;&gt;

# Jaeger - a Distributed Tracing System

üí•üí•üí• Jaeger v2 is out! Read the [blog post](https://medium.com/jaegertracing/jaeger-v2-released-09a6033d1b10) and [try it out](https://www.jaegertracing.io/docs/latest/getting-started/).

```mermaid
graph TD
    SDK[&quot;OpenTelemetry SDK&quot;] --&gt; |HTTP or gRPC| COLLECTOR
    COLLECTOR[&quot;Jaeger Collector&quot;] --&gt; STORE[Storage]
    COLLECTOR --&gt; |gRPC| PLUGIN[Storage Plugin]
    COLLECTOR --&gt; |gRPC/sampling| SDK
    PLUGIN --&gt; STORE
    QUERY[Jaeger Query Service] --&gt; STORE
    QUERY --&gt; |gRPC| PLUGIN
    UI[Jaeger UI] --&gt; |HTTP| QUERY
    subgraph Application Host
        subgraph User Application
            SDK
        end
    end
```

Jaeger is a distributed tracing platform created by [Uber Technologies](https://eng.uber.com/distributed-tracing/) and donated to [Cloud Native Computing Foundation](https://cncf.io).

See Jaeger [documentation][doc] for getting started, operational details, and other information.

Jaeger is hosted by the [Cloud Native Computing Foundation](https://cncf.io) (CNCF) as the 7th top-level project, graduated in October 2019. See the CNCF [Jaeger incubation announcement](https://www.cncf.io/blog/2017/09/13/cncf-hosts-jaeger/) and [Jaeger graduation announcement](https://www.cncf.io/announcement/2019/10/31/cloud-native-computing-foundation-announces-jaeger-graduation/).

## Get Involved

Jaeger is an open source project with open governance. We welcome contributions from the community, and we would love your help to improve and extend the project. Here are [some ideas](https://www.jaegertracing.io/get-involved/) for how to get involved. Many of them do not even require any coding.

## Version Compatibility Guarantees

Since Jaeger uses many components from the [OpenTelemetry Collector](https://github.com/open-telemetry/opentelemetry-collector/) we try to maintain configuration compatibility between Jaeger releases. Occasionally, configuration options in Jaeger (or in Jaeger v1 CLI flags) can be deprecated due to usability improvements, new functionality, or changes in our dependencies.
In such situations, developers introducing the deprecation are required to follow [these guidelines](./CONTRIBUTING.md#deprecating-cli-flags).

In short, for a deprecated configuration option, you should expect to see the following message in the documentation or release notes:
```
(deprecated, will be removed after yyyy-mm-dd or in release vX.Y.Z, whichever is later)
```

A grace period of at least **3 months** or **two minor version bumps** (whichever is later) from the first release
containing the deprecation notice will be provided before the deprecated configuration option _can_ be deleted.

For example, consider a scenario where v2.0.0 is released on 01-Sep-2024 containing a deprecation notice for a configuration option.
This configuration option will remain in a deprecated state until the later of 01-Dec-2024 or v2.2.0 where it _can_ be removed on or after either of those events.
It may remain deprecated for longer than the aforementioned grace period.

## Go Version Compatibility Guarantees

The Jaeger project attempts to track the currently supported versions of Go, as [defined by the Go team](https://go.dev/doc/devel/release#policy).
Removing support for an unsupported Go version is not considered a breaking change.

Starting with the release of Go 1.21, support for Go versions will be updated as follows:

1. Soon after the release of a new Go minor version `N`, updates will be made to the build and tests steps to accommodate the latest Go minor version.
2. Soon after the release of a new Go minor version `N`, support for Go version `N-2` will be removed and version `N-1` will become the minimum required version.

## Related Repositories

### Components

 * [UI](https://github.com/jaegertracing/jaeger-ui)
 * [Data model](https://github.com/jaegertracing/jaeger-idl)

### Documentation

  * Published: https://www.jaegertracing.io/docs/
  * Source: https://github.com/jaegertracing/documentation

## Building From Source

See [CONTRIBUTING](./CONTRIBUTING.md).

## Contributing

See [CONTRIBUTING](./CONTRIBUTING.md).

Thanks to all the people who already contributed!

&lt;a href=&quot;https://github.com/jaegertracing/jaeger/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=jaegertracing/jaeger&quot; /&gt;
&lt;/a&gt;

### Maintainers

Rules for becoming a maintainer are defined in the [GOVERNANCE](./GOVERNANCE.md) document.
The official maintainers of the Jaeger project are listed in the [MAINTAINERS](./MAINTAINERS.md) file.
Please use `@jaegertracing/jaeger-maintainers` to tag them on issues / PRs.

Some repositories under [jaegertracing](https://github.com/jaegertracing) org have additional maintainers.

## Project Status Meetings

The Jaeger maintainers and contributors meet regularly on a video call. Everyone is welcome to join, including end users. For meeting details, see https://www.jaegertracing.io/get-in-touch/.

## Roadmap

See https://www.jaegertracing.io/docs/roadmap/

## Get in Touch

Have questions, suggestions, bug reports? Reach the project community via these channels:

 * [Slack chat room `#jaeger`][slack] (need to join [CNCF Slack][slack-join] for the first time)
 * [`jaeger-tracing` mail group](https://groups.google.com/forum/#!forum/jaeger-tracing)
 * GitHub [issues](https://github.com/jaegertracing/jaeger/issues) and [discussions](https://github.com/jaegertracing/jaeger/discussions)

## Security

Third-party security audits of Jaeger are available in https://github.com/jaegertracing/security-audits. Please see [Issue #1718](https://github.com/jaegertracing/jaeger/issues/1718) for the summary of available security mechanisms in Jaeger.

## Adopters

Jaeger as a product consists of multiple components. We want to support different types of users,
whether they are only using our instrumentation libraries or full end to end Jaeger installation,
whether it runs in production or you use it to troubleshoot issues in development.

Please see [ADOPTERS.md](./ADOPTERS.md) for some of the organizations using Jaeger today.
If you would like to add your organization to the list, please comment on our
[survey issue](https://github.com/jaegertracing/jaeger/issues/207).

## Sponsors

The Jaeger project owes its success in open source largely to the Cloud Native Computing Foundation (CNCF), our primary supporter. We deeply appreciate their vital support.  Furthermore, we are grateful to Uber for their initial, project-launching donation, and for the continuous contributions of software and infrastructure from 1Password, Codecov.io, Dosu, GitHub, Google Analytics, Netlify, and Oracle Cloud Infrastructure. Thank you for your generous support.

## License

Copyright (c) The Jaeger Authors. [Apache 2.0 License](./LICENSE).

[doc]: https://jaegertracing.io/docs/
[ci-img]: https://github.com/jaegertracing/jaeger/actions/workflows/ci-unit-tests.yml/badge.svg?branch=main
[ci]: https://github.com/jaegertracing/jaeger/actions/workflows/ci-unit-tests.yml?query=branch%3Amain
[cov-img]: https://codecov.io/gh/jaegertracing/jaeger/branch/main/graph/badge.svg
[cov]: https://codecov.io/gh/jaegertracing/jaeger/branch/main/
[fossa-img]: https://app.fossa.com/api/projects/git%2Bgithub.com%2Fjaegertracing%2Fjaeger.svg?type=shield
[fossa]: https://app.fossa.io/projects/git%2Bgithub.com%2Fjaegertracing%2Fjaeger?ref=badge_shield
[openssf-img]: https://api.securityscorecards.dev/projects/github.com/jaegertracing/jaeger/badge
[openssf]: https://securityscorecards.dev/viewer/?uri=github.com/jaegertracing/jaeger
[openssf-bp-img]: https://www.bestpractices.dev/projects/1273/badge
[openssf-bp]: https://www.bestpractices.dev/projects/1273
[clomonitor-img]: https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/jaeger/badge
[clomonitor]: https://clomonitor.io/projects/cncf/jaeger
[artifacthub-img]: https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/jaegertracing
[artifacthub]: https://artifacthub.io/packages/search?repo=jaegertracing


[community-badge]: https://img.shields.io/badge/Project+Community-stats-blue.svg
[community-stats]: https://all.devstats.cncf.io/d/54/project-health?orgId=1&amp;var-repogroup_name=Jaeger
[hotrod-tutorial]: https://medium.com/jaegertracing/take-jaeger-for-a-hotrod-ride-233cf43e46c2
[slack]: https://cloud-native.slack.com/archives/CGG7NFUJ3
[slack-join]: https://slack.cncf.io
[slack-img]: https://img.shields.io/badge/slack-join%20chat%20%E2%86%92-brightgreen?logo=slack
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kgateway-dev/kgateway]]></title>
            <link>https://github.com/kgateway-dev/kgateway</link>
            <guid>https://github.com/kgateway-dev/kgateway</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[The Cloud-Native API Gateway and AI Gateway]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kgateway-dev/kgateway">kgateway-dev/kgateway</a></h1>
            <p>The Cloud-Native API Gateway and AI Gateway</p>
            <p>Language: Go</p>
            <p>Stars: 5,131</p>
            <p>Forks: 619</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo-dark.svg&quot; alt=&quot;kgateway&quot; width=&quot;400&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo.svg&quot; alt=&quot;kgateway&quot; width=&quot;400&quot;&gt;
    &lt;img alt=&quot;kgateway&quot; src=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo.svg&quot;&gt;
  &lt;/picture&gt;
  &lt;br/&gt;
  The most widely deployed gateway in Kubernetes for microservices and AI agents
&lt;/h1&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/kgateway-dev/kgateway/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/v/release/kgateway-dev/kgateway?style=flat&amp;label=Latest%20version&quot; alt=&quot;Release&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache2.0-brightgreen.svg?style=flat&quot; alt=&quot;License: Apache 2.0&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/kgateway-dev/kgateway&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/kgateway-dev/kgateway.svg?style=flat&amp;logo=github&amp;label=Stars&quot; alt=&quot;Stars&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.bestpractices.dev/projects/10534&quot;&gt;&lt;img src=&quot;https://www.bestpractices.dev/projects/10534/badge&quot; alt=&quot;OpenSSF Best Practices&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

## About kgateway

Kgateway is the most mature and widely deployed gateway in the market today. Built on open source and open standards, **kgateway is a dual control plane that implements the [Kubernetes Gateway API](https://gateway-api.sigs.k8s.io/) for both [Envoy](https://github.com/envoyproxy/envoy) and [agentgateway](https://github.com/agentgateway/agentgateway)**. This unique architecture enables kgateway to provide unified API connectivity spanning from traditional HTTP/gRPC workloads to advanced AI agent orchestration.

With a control plane that scales from lightweight microgateway deployments between services, to massively parallel centralized gateways handling billions of API calls, to advanced AI gateway use cases for safety, security, and governance, kgateway brings omni-directional API connectivity to any cloud and any environment.

### Use Cases

Kgateway is designed for:

* **Advanced Ingress Controller and Next-Gen API Gateway**: Aggregate web APIs and apply functions like authentication, authorization and rate limiting in one place. Powered by [Envoy](https://www.envoyproxy.io) or [agentgateway](https://github.com/agentgateway/agentgateway) and programmed with the [Gateway API](https://gateway-api.sigs.k8s.io/), kgateway is a world-leading Cloud Native ingress.

* **AI Gateway for LLM Consumption**: Protect models, tools, agents, and data from inappropriate access. Manage traffic to LLM providers, enrich prompts at a system level, and apply prompt guards for safety and compliance.

* **Inference Gateway for Generative Models**: Intelligently route to AI inference workloads in Kubernetes environments utilizing the [Inference Extension](https://gateway-api-inference-extension.sigs.k8s.io/) project.

* **Native MCP and Agent-to-Agent Gateway**: Federate Model Context Protocol tool services and secure agent-to-agent communications with a single scalable endpoint powered by agentgateway.

* **Hybrid Application Migration**: Route to backends implemented as microservices, serverless functions or legacy apps. Gradually migrate from legacy code while maintaining existing systems.

Kgateway is feature-rich, fast, and flexible. It excels in function-level routing, supports legacy apps, microservices and serverless, offers robust discovery capabilities, integrates seamlessly with open-source projects, and is designed to support hybrid applications with various technologies, architectures, protocols, and clouds.

### History

The project was launched in 2018 as **Gloo** by Solo.io and has been [production-ready since 2019](https://www.solo.io/blog/announcing-gloo-1-0-a-production-ready-envoy-based-api-gateway). Since then, it has steadily evolved to become the most trusted and feature-rich API gateway for Kubernetes, processing billions of API requests for many of the world&#039;s biggest companies. Please see [the migration plan](https://github.com/kgateway-dev/kgateway/issues/10363) for more information about the transition from Gloo to kgateway.

## Get involved

- [Join us on our Slack channel](https://kgateway.dev/slack/)
- [Check out the docs](https://kgateway.dev/docs)
- [Read the kgateway blog](https://kgateway.dev/blog/)
- [Learn more about the community](https://github.com/kgateway-dev/community)
- [Watch a video on our YouTube channel](https://www.youtube.com/@kgateway-dev)
- Follow us on [X](https://x.com/kgatewaydev), [Bluesky](https://bsky.app/profile/kgateway.dev), [Mastodon](https://mastodon.social/@kgateway) or [LinkedIn](https://www.linkedin.com/company/kgateway/)

## Contributing to kgateway

Please refer to [devel/contributing/README.md](/devel/contributing/README.md) as a starting point for contributing to the project.

## Releasing kgateway

Please refer to [devel/contributing/releasing.md](devel/contributing/releasing.md) as a starting point for understanding releases of the project.

## Security

See our [SECURITY.md](SECURITY.md) file for details.

## Thanks

Kgateway would not be possible without the valuable open source work of projects in the community. We would like to extend a special thank-you to [Envoy](https://www.envoyproxy.io) and [agentgateway](https://github.com/agentgateway/agentgateway), the two data planes upon which we build our dual control plane architecture.

## Contributors

Thanks to all contributors who are helping to make kgateway better!

&lt;a href=&quot;https://github.com/kgateway-dev/kgateway/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=kgateway-dev/kgateway&quot; /&gt;
&lt;/a&gt;

## Star History

&lt;a href=&quot;https://www.star-history.com/#kgateway-dev/kgateway&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=kgateway-dev/kgateway&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=kgateway-dev/kgateway&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star history of kgateway-dev/kgateway over time&quot; src=&quot;https://api.star-history.com/svg?repos=kgateway-dev/kgateway&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

---

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/cncf/artwork/main/other/cncf-sandbox/horizontal/color/cncf-sandbox-horizontal-color.svg&quot; width=&quot;300&quot; alt=&quot;Cloud Native Computing Foundation logo&quot;/&gt;
    &lt;p&gt;kgateway is a &lt;a href=&quot;https://cncf.io&quot;&gt;Cloud Native Computing Foundation&lt;/a&gt; sandbox project.&lt;/p&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[fleetdm/fleet]]></title>
            <link>https://github.com/fleetdm/fleet</link>
            <guid>https://github.com/fleetdm/fleet</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[Open device management]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fleetdm/fleet">fleetdm/fleet</a></h1>
            <p>Open device management</p>
            <p>Language: Go</p>
            <p>Stars: 5,841</p>
            <p>Forks: 739</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;&lt;a href=&quot;https://fleetdm.com&quot;&gt;&lt;img width=&quot;200&quot; alt=&quot;Fleet logo, landscape, dark text, transparent background&quot; src=&quot;https://github.com/user-attachments/assets/5b52c536-f33e-4159-b2a3-d48f31868cd2&quot;&gt;&lt;/a&gt;&lt;/h1&gt;


#### [News](https://fleetdm.com/announcements) &amp;nbsp; ¬∑ &amp;nbsp; [Report a bug](https://github.com/fleetdm/fleet/issues/new) &amp;nbsp; ¬∑ &amp;nbsp; [Handbook](https://fleetdm.com/handbook/company) &amp;nbsp; ¬∑ &amp;nbsp; [Why open source?](https://fleetdm.com/handbook/company/why-this-way#why-open-source) &amp;nbsp; ¬∑ &amp;nbsp; [Art](https://fleetdm.com/logos)


Open-source platform for IT and security teams with thousands of computers.  Designed for APIs, GitOps, webhooks, YAML, and humans.

&lt;a href=&quot;https://fleetdm.com/logos&quot;&gt;&lt;img src=&quot;https://github.com/fleetdm/fleet/assets/618009/f835ec29-1cb9-49ba-a0f3-395ffd9d5c9f&quot; alt=&quot;A glass city in the clouds&quot;/&gt;&lt;/a&gt;


## What&#039;s it for?
Organizations like Fastly and Gusto use Fleet for vulnerability reporting, detection engineering, device management (MDM), device health monitoring, posture-based access control, managing unused software licenses, and more.

#### Explore data
To see what kind of data you can use Fleet to gather, check out the [table reference documentation](https://fleetdm.com/tables).

#### Out-of-the-box policies
Fleet includes out-of-the box support for all [CIS benchmarks for macOS and Windows](https://fleetdm.com/docs/using-fleet/cis-benchmarks), as well as many [simpler queries](https://fleetdm.com/queries).

Take as much or as little as you need for your organization.

#### Supported platforms
Here are the platforms Fleet currently supports:

- Linux (all distros)
- macOS
- Windows
- Chromebooks
- Amazon Web Services (AWS)
- Google Cloud (GCP)
- Azure (Microsoft cloud)
- Data centers
- Containers (kube, etc)
- Linux-based IoT devices

## Lighter than air
Fleet is lightweight and modular.  You can use it for security without using it for MDM, and vice versa.  You can turn off features you are not using.

#### Openness
Fleet is dedicated to flexibility, accessibility, and clarity.  We think [everyone can contribute](https://fleetdm.com/handbook/company#openness) and that tools should be as easy as possible for everyone to understand.

#### Good neighbors
Fleet has no ambition to replace all of your other tools.  (Though it might replace some, if you want it to.)  Ready-to-use, enterprise-friendly integrations exist for Snowflake, Splunk, GitHub Actions, Vanta, Elastic Jira, Zendesk, and more.

Fleet plays well with Munki, Chef, Puppet, and Ansible, as well as with security tools like Crowdstrike and SentinelOne.  For example, you can use the free version of Fleet to quickly report on what hosts are _actually_ running your EDR agent.

#### Free as in free
The free version of Fleet will [always be free](https://fleetdm.com/pricing).  Fleet is [independently backed](https://linkedin.com/company/fleetdm) and actively maintained with the help of many amazing [contributors](https://github.com/fleetdm/fleet/graphs/contributors).

#### Longevity
The [company behind Fleet](https://fleetdm.com/handbook/company) is founded (and majority-owned) by [true believers in open source](https://fleetdm.com/handbook/company/why-this-way#why-open-source).  The company&#039;s business model is influenced by GitLab (NYSE: GTLB), with great investors, happy customers, and the capacity to become profitable at any time.

In keeping with Fleet&#039;s value of openness, [Fleet Device Management&#039;s company handbook](https://fleetdm.com/handbook/company) is public and open source.  You can read about the [history of Fleet and osquery](https://fleetdm.com/handbook/company#history) and our commitment to improving the product.

&lt;!-- &gt; To upgrade from Fleet ‚â§3.2.0, just follow the upgrading steps for the earliest subsequent major release from this repository (it&#039;ll work out of the box until the release of Fleet 5.0). --&gt;


## Is it any good?
Fleet is used in production by IT and security teams with thousands of laptops and servers.  Many deployments support tens of thousands of hosts, and a few large organizations manage deployments as large as 400,000+ hosts.



## Chat
Please join us in [MacAdmins Slack](https://www.macadmins.org/) or in [osquery Slack](https://fleetdm.com/slack).

The Fleet community is full of [kind and helpful people](https://fleetdm.com/handbook/company#empathy).  Whether or not you are a paying customer, if you need help, just ask.


## Contributing &amp;nbsp; [![Go Report Card](https://goreportcard.com/badge/github.com/fleetdm/fleet)](https://goreportcard.com/report/github.com/fleetdm/fleet) &amp;nbsp; [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5537/badge)](https://bestpractices.coreinfrastructure.org/projects/5537) &amp;nbsp; [![Twitter Follow](https://img.shields.io/twitter/follow/fleetctl.svg?style=social&amp;maxAge=3600)](https://twitter.com/fleetctl) &amp;nbsp; 

The landscape of cybersecurity and IT is too complex.  Let&#039;s open it up.

Contributions are welcome, whether you answer questions on [Slack](https://fleetdm.com/slack) / [GitHub](https://github.com/fleetdm/fleet/issues) / [StackOverflow](https://stackoverflow.com/search?q=osquery) / [LinkedIn](https://linkedin.com/company/fleetdm) / [Twitter](https://twitter.com/fleetctl), improve the documentation or [website](./website), write a tutorial, give a talk at a conference or local meetup, give an [interview on a podcast](https://fleetdm.com/podcasts), troubleshoot reported issues, or [submit a patch](https://fleetdm.com/docs/contributing/contributing).  The Fleet code of conduct is [on GitHub](https://github.com/fleetdm/fleet/blob/main/CODE_OF_CONDUCT.md).

&lt;!-- - Great contributions are motivated by real-world use cases or learning.
- Some of the most valuable contributions might not touch any code at all.
- Small, iterative, simple (boring) changes are the easiest to merge. --&gt;

## What&#039;s next?
To see what Fleet can do, head over to [fleetdm.com](https://fleetdm.com) and try it out for yourself, grab time with one of the maintainers to discuss, or visit the docs and roll it out to your organization.

#### Production deployment
Fleet is simple enough to [spin up for yourself](https://fleetdm.com/docs/get-started/tutorials-and-guides).  Or you can have us [host it for you](https://fleetdm.com/pricing).  Premium features are [available](https://fleetdm.com/pricing) either way.

#### Documentation
Complete documentation for Fleet can be found at [https://fleetdm.com/docs](https://fleetdm.com/docs).


## License
The free version of Fleet is available under the MIT license.  The commercial license is also designed to allow contributions to paid features for users whose employment agreements allow them to contribute to open source projects.  (See LICENSE.md for details.)

&gt; Fleet is built on [osquery](https://github.com/osquery/osquery), [nanoMDM](https://github.com/micromdm/nanomdm), [Nudge](https://github.com/macadmins/nudge), and [swiftDialog](https://github.com/swiftDialog/swiftDialog).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[keploy/keploy]]></title>
            <link>https://github.com/keploy/keploy</link>
            <guid>https://github.com/keploy/keploy</guid>
            <pubDate>Thu, 18 Dec 2025 00:04:46 GMT</pubDate>
            <description><![CDATA[API, Integration, E2E Testing Agent for Developers that actually work. Generate tests, mocks/stubs for your APIs!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/keploy/keploy">keploy/keploy</a></h1>
            <p>API, Integration, E2E Testing Agent for Developers that actually work. Generate tests, mocks/stubs for your APIs!</p>
            <p>Language: Go</p>
            <p>Stars: 13,621</p>
            <p>Forks: 1,874</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://docs.keploy.io/img/keploy-logo-dark.svg?s=200&amp;v=4&quot; height=&quot;80&quot; alt=&quot;Keploy Logo&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
 &lt;a href=&quot;https://trendshift.io/repositories/3262&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/3262&quot; alt=&quot;keploy%2Fkeploy | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;&lt;b&gt;‚ö°Ô∏è API tests faster than unit tests, from user traffic ‚ö°Ô∏è&lt;/b&gt;&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;üåü The must-have tool for developers in the AI-Gen era for 90% test coverage üåü&lt;/p&gt;


---

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Slack-4A154B?style=flat&amp;logo=slack&amp;logoColor=white&quot; alt=&quot;Slack&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.linkedin.com/company/keploy/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/LinkedIn-%230077B5.svg?style=flat&amp;logo=linkedin&amp;logoColor=white&quot; alt=&quot;LinkedIn&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.youtube.com/channel/UC6OTg7F4o0WkmNtSoob34lg&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/YouTube-%23FF0000.svg?style=flat&amp;logo=YouTube&amp;logoColor=white&quot; alt=&quot;YouTube&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/Keployio&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/X-%231DA1F2.svg?style=flat&amp;logo=X&amp;logoColor=white&quot; alt=&quot;X&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://landscape.cncf.io/?item=app-definition-and-development--continuous-integration-delivery--keploy&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/CNCF%20Landscape-5699C6?logo=cncf&amp;style=social&quot; alt=&quot;Keploy CNCF Landscape&quot; /&gt;
  &lt;/a&gt;
&lt;a href=&quot;https://github.com/Keploy/Keploy/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/keploy/keploy?color=%23EAC54F&amp;logo=github&quot; alt=&quot;GitHub Stars&quot; /&gt;&lt;/a&gt;

  &lt;a href=&quot;https://github.com/Keploy/Keploy/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/keploy/keploy?color=%23EAC54F&amp;logo=github&amp;label=Help%20us%20reach%2020K%20stars!%20Now%20at:&quot; alt=&quot;Help us reach 20k stars!&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;


[Keploy](https://keploy.io) is a **developer‚Äëcentric API and integration testing tool** that auto‚Äëgenerates **tests and data‚Äëmocks** faster than unit tests.  

It records API calls, database queries, and streaming events ‚Äî then replays them as tests. Under the hood, Keploy **uses eBPF to capture traffic at the network layer,** but for you it‚Äôs completely **code‚Äëless** and **language‚Äëagnostic**.


&lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-replay.gif&quot; width=&quot;100%&quot; alt=&quot;Convert API calls to API tests test cases and Data Mocks using AI&quot;/&gt;

&gt; üê∞ **Fun fact:** Keploy uses itself for testing! Check out our swanky coverage badge: [![Coverage Status](https://coveralls.io/repos/github/keploy/keploy/badge.svg?branch=main&amp;kill_cache=1)](https://coveralls.io/github/keploy/keploy?branch=main&amp;kill_cache=1) &amp;nbsp;

---

# Key Highlights

## üéØ No code changes

Just run your app with `keploy record`. Real API + integration flows are automatically captured as tests and mocks. *(Keploy uses eBPF under the hood to capture traffic, so you **don‚Äôt need** to add any SDKs or modify code.)* 

## üìπ Record and Replay complex Flows
Keploy can record and replay complex, distributed API flows as mocks and stubs.  It&#039;s like having a very light-weight time machine for your tests‚Äîsaving you tons of time!

üëâ [Read the docs on record-replay](https://keploy.io/docs/keploy-explained/introduction/)

&lt;img src=&quot;https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-tc.gif&quot; width=&quot;60%&quot; alt=&quot;Convert API calls to test cases&quot;/&gt;

## üêá Complete Infra‚ÄëVirtualization (beyond HTTP mocks)

Unlike tools that only mock HTTP endpoints, Keploy records **databases** (Postgres, MySQL, MongoDB), **streaming/queues** (Kafka, RabbitMQ), external APIs, and more. 

It replays them deterministically so you can run tests without re‚Äëprovisioning infra.

üëâ [Read the docs on infra virtualisation](https://keploy.io/docs/keploy-explained/how-keploy-works/)

&lt;img src=&quot;https://keploy-devrel.s3.us-west-2.amazonaws.com/Group+1261152745.png&quot; width=&quot;100%&quot; alt=&quot;Convert API calls to test cases&quot;/&gt;

## üß™ Combined Test Coverage

If you‚Äôre a **developer**, you probably care about *statement* and *branch* coverage ‚Äî Keploy calculates that for you. 

If you‚Äôre a **QA**, you focus more on *API schema* and *business use‚Äëcase coverage* ‚Äî Keploy calculates that too. This way coverage isn‚Äôt subjective anymore. 

üëâ [Read the docs on coverage](https://keploy.io/docs/server/sdk-installation/go/)

&lt;img src=&quot;https://keploy-devrel.s3.us-west-2.amazonaws.com/keploy+ai+test+gen+for+api+statement+schema+and+branch+coverage.jpg&quot; width=&quot;100%&quot; alt=&quot;ai test gen for api statement schema and branch coverage&quot;/&gt;

## ü§ñ Expand API Coverage using AI

Keploy uses existing recordings, Swagger/OpenAPI Schema to find: boundary values, missing/extra fields, wrong types, out‚Äëof‚Äëorder sequences, retries/timeouts. 

This helps expand API Schema, Statement, and Branch Coverage. 

üëâ [Read the docs on coverage](https://app.keploy.io/)

&lt;img src=&quot;https://keploy-devrel.s3.us-west-2.amazonaws.com/ai+test+case+generation+that+works.png&quot; width=&quot;100%&quot; alt=&quot;ai test gen for api statement schema and branch coverage&quot;/&gt;


### Other Capabilities

- üåê **CI/CD Integration:** Run tests with mocks anywhere you like‚Äîlocally on the CLI, in your CI pipeline (Jenkins, Github Actions..) , or even across a Kubernetes cluster. [Read more](https://keploy.io/docs/running-keploy/api-testing-cicd/)

- üé≠ **Multi-Purpose Mocks**: You can also use Keploy-generated Mocks, as server Tests!

- üìä **Reporting:** Unified reports for API, integration, unit, and e2e coverage with insights directly in your CI or PRs.
- üñ•Ô∏è **Console:** A developer-friendly console to view, manage, and debug recorded tests and mocks.
- ‚è±Ô∏è **Time Freezing:** Deterministically replay tests by freezing system time during execution. [Read more](https://keploy.io/docs/keploy-cloud/time-freezing/)
- üìö **Mock Registry:** Centralized registry to manage, reuse, and version mocks across teams and environments. [Read more](https://keploy.io/docs/keploy-cloud/mock-registry/)

---

## Quick Start

### 1. Install Keploy Agent

```bash
curl --silent -O -L https://keploy.io/install.sh &amp;&amp; source install.sh
```

### 2. Record Test Cases

Start your app under Keploy to convert real API calls into tests and mocks.

```bash
keploy record -c &quot;CMD_TO_RUN_APP&quot;
```

Example for Python:

```bash
keploy record -c &quot;python main.py&quot;
```

### 3. Run Tests

Run tests offline without external dependencies.

```bash
keploy test -c &quot;CMD_TO_RUN_APP&quot; --delay 10
```

## Resources
### - üìò [Installation](https://keploy.io/docs/server/installation/)
### - üèÅ [QuickStarts](https://keploy.io/docs/quickstart/quickstart-filter/)


---


## Languages &amp;amp; Frameworks (Any stack)

Because Keploy intercepts at the **network layer (eBPF)**, it works with **any language, framework, or runtime**‚Äîno SDK required. 
&gt; Note: Some of the dependencies are not open-source by nature because their protocols and parsings are not open-sourced. It&#039;s not supported in Keploy enterprise. 

&lt;p align=&quot;center&quot;&gt;

&lt;!-- Languages --&gt;
&lt;img src=&quot;https://img.shields.io/badge/Go-00ADD8?logo=go&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Java-ED8B00?logo=openjdk&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Node.js-43853D?logo=node.js&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Python-3776AB?logo=python&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Rust-000000?logo=rust&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/C%23-239120?logo=csharp&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/C/C++-00599C?logo=cplusplus&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/TypeScript-3178C6?logo=typescript&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Scala-DC322F?logo=scala&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Kotlin-7F52FF?logo=kotlin&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Swift-FA7343?logo=swift&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Dart-0175C2?logo=dart&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/PHP-777BB4?logo=php&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Ruby-CC342D?logo=ruby&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Elixir-4B275F?logo=elixir&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/.NET-512BD4?logo=dotnet&amp;amp;logoColor=white&quot; /&gt;

&lt;!-- Protocols &amp;amp; infra commonly virtualized --&gt;
&lt;img src=&quot;https://img.shields.io/badge/gRPC-5E35B1?logo=grpc&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/GraphQL-E10098?logo=graphql&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/HTTP%2FREST-0A84FF?logo=httpie&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Kafka-231F20?logo=apachekafka&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/RabbitMQ-FF6600?logo=rabbitmq&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/PostgreSQL-4169E1?logo=postgresql&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/MySQL-4479A1?logo=mysql&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/MongoDB-47A248?logo=mongodb&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Redis-DC382D?logo=redis&amp;amp;logoColor=white&quot; /&gt;
&lt;/p&gt;

---

## Questions? 

### Book a Live Demo / Enterprise Support

Want a guided walkthrough, dedicated support, or help planning enterprise rollout?

&lt;p&gt;
  &lt;a href=&quot;https://calendar.app.google/4ZKd1nz9A5wLuP4W7&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Request%20a%20Demo-Email-2ea44f?logo=gmail&quot; /&gt;
  &lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Chat%20with%20Us-Slack-4A154B?logo=slack&amp;amp;logoColor=white&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Optional: replace with your scheduling link (Cal.com/Calendly) --&gt;
  &lt;!-- &lt;a href=&quot;https://cal.com/keploy/demo&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Book%20via%20Calendar-Cal.com-111111&quot; /&gt;&lt;/a&gt; --&gt;
&lt;/p&gt;

Prefer a calendar invite? Mention your availability in the email‚Äîwe‚Äôll send a **calendar invite** right away.

---

## Documentation &amp; Community

- üìò [Documentation](https://keploy.io/docs/) ‚Äî Explore the full docs
- üí¨ [Slack Community](https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg) ‚Äî Join the conversation
- üìú [Contribution Guidelines](https://keploy.io/docs/keploy-explained/contribution-guide/)
- ‚ù§Ô∏è [Code of Conduct](https://github.com/keploy/keploy/blob/main/CODE_OF_CONDUCT.md)
- üì¢ [Blog](https://keploy.io/blog/) ‚Äî Read articles and updates

---

## Contribute &amp; Collaborate

Whether you&#039;re new or experienced, your input matters. Help us improve Keploy by contributing code, reporting issues, or sharing feedback.

Together, let&#039;s build better testing tools for modern applications.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>