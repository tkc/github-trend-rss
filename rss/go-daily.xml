<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Thu, 16 Oct 2025 00:05:33 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[tulir/whatsmeow]]></title>
            <link>https://github.com/tulir/whatsmeow</link>
            <guid>https://github.com/tulir/whatsmeow</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[Go library for the WhatsApp web multidevice API]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tulir/whatsmeow">tulir/whatsmeow</a></h1>
            <p>Go library for the WhatsApp web multidevice API</p>
            <p>Language: Go</p>
            <p>Stars: 4,518</p>
            <p>Forks: 710</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># whatsmeow
[![Go Reference](https://pkg.go.dev/badge/go.mau.fi/whatsmeow.svg)](https://pkg.go.dev/go.mau.fi/whatsmeow)

whatsmeow is a Go library for the WhatsApp web multidevice API.

## Discussion
Matrix room: [#whatsmeow:maunium.net](https://matrix.to/#/#whatsmeow:maunium.net)

For questions about the WhatsApp protocol (like how to send a specific type of
message), you can also use the [WhatsApp protocol Q&amp;A] section on GitHub
discussions.

[WhatsApp protocol Q&amp;A]: https://github.com/tulir/whatsmeow/discussions/categories/whatsapp-protocol-q-a

## Usage
The [godoc](https://pkg.go.dev/go.mau.fi/whatsmeow) includes docs for all methods and event types.
There&#039;s also a [simple example](https://pkg.go.dev/go.mau.fi/whatsmeow#example-package) at the top.

## Features
Most core features are already present:

* Sending messages to private chats and groups (both text and media)
* Receiving all messages
* Managing groups and receiving group change events
* Joining via invite messages, using and creating invite links
* Sending and receiving typing notifications
* Sending and receiving delivery and read receipts
* Reading and writing app state (contact list, chat pin/mute status, etc)
* Sending and handling retry receipts if message decryption fails
* Sending status messages (experimental, may not work for large contact lists)

Things that are not yet implemented:

* Sending broadcast list messages (this is not supported on WhatsApp web either)
* Calls
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grpc/grpc-go]]></title>
            <link>https://github.com/grpc/grpc-go</link>
            <guid>https://github.com/grpc/grpc-go</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[The Go language implementation of gRPC. HTTP/2 based RPC]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grpc/grpc-go">grpc/grpc-go</a></h1>
            <p>The Go language implementation of gRPC. HTTP/2 based RPC</p>
            <p>Language: Go</p>
            <p>Stars: 22,442</p>
            <p>Forks: 4,596</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># gRPC-Go

[![GoDoc](https://pkg.go.dev/badge/google.golang.org/grpc)][API]
[![GoReportCard](https://goreportcard.com/badge/grpc/grpc-go)](https://goreportcard.com/report/github.com/grpc/grpc-go)
[![codecov](https://codecov.io/gh/grpc/grpc-go/graph/badge.svg)](https://codecov.io/gh/grpc/grpc-go)

The [Go][] implementation of [gRPC][]: A high performance, open source, general
RPC framework that puts mobile and HTTP/2 first. For more information see the
[Go gRPC docs][], or jump directly into the [quick start][].

## Prerequisites

- **[Go][]**: any one of the **two latest major** [releases][go-releases].

## Installation

Simply add the following import to your code, and then `go [build|run|test]`
will automatically fetch the necessary dependencies:


```go
import &quot;google.golang.org/grpc&quot;
```

&gt; **Note:** If you are trying to access `grpc-go` from **China**, see the
&gt; [FAQ](#FAQ) below.

## Learn more

- [Go gRPC docs][], which include a [quick start][] and [API
  reference][API] among other resources
- [Low-level technical docs](Documentation) from this repository
- [Performance benchmark][]
- [Examples](examples)
- [Contribution guidelines](CONTRIBUTING.md)

## FAQ

### I/O Timeout Errors

The `golang.org` domain may be blocked from some countries. `go get` usually
produces an error like the following when this happens:

```console
$ go get -u google.golang.org/grpc
package google.golang.org/grpc: unrecognized import path &quot;google.golang.org/grpc&quot; (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)
```

To build Go code, there are several options:

- Set up a VPN and access google.golang.org through that.

- With Go module support: it is possible to use the `replace` feature of `go
  mod` to create aliases for golang.org packages.  In your project&#039;s directory:

  ```sh
  go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest
  go mod tidy
  go mod vendor
  go build -mod=vendor
  ```

  Again, this will need to be done for all transitive dependencies hosted on
  golang.org as well. For details, refer to [golang/go issue
  #28652](https://github.com/golang/go/issues/28652).

### Compiling error, undefined: grpc.SupportPackageIsVersion

Please update to the latest version of gRPC-Go using
`go get google.golang.org/grpc`.

### How to turn on logging

The default logger is controlled by environment variables. Turn everything on
like this:

```console
$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99
$ export GRPC_GO_LOG_SEVERITY_LEVEL=info
```

### The RPC failed with error `&quot;code = Unavailable desc = transport is closing&quot;`

This error means the connection the RPC is using was closed, and there are many
possible reasons, including:
 1. mis-configured transport credentials, connection failed on handshaking
 1. bytes disrupted, possibly by a proxy in between
 1. server shutdown
 1. Keepalive parameters caused connection shutdown, for example if you have
    configured your server to terminate connections regularly to [trigger DNS
    lookups](https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779).
    If this is the case, you may want to increase your
    [MaxConnectionAgeGrace](https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters),
    to allow longer RPC calls to finish.

It can be tricky to debug this because the error happens on the client side but
the root cause of the connection being closed is on the server side. Turn on
logging on __both client and server__, and see if there are any transport
errors.

[API]: https://pkg.go.dev/google.golang.org/grpc
[Go]: https://golang.org
[Go module]: https://github.com/golang/go/wiki/Modules
[gRPC]: https://grpc.io
[Go gRPC docs]: https://grpc.io/docs/languages/go
[Performance benchmark]: https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608
[quick start]: https://grpc.io/docs/languages/go/quickstart
[go-releases]: https://golang.org/doc/devel/release.html
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Project-HAMi/HAMi]]></title>
            <link>https://github.com/Project-HAMi/HAMi</link>
            <guid>https://github.com/Project-HAMi/HAMi</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[Heterogeneous AI Computing Virtualization Middleware(Project under CNCF)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Project-HAMi/HAMi">Project-HAMi/HAMi</a></h1>
            <p>Heterogeneous AI Computing Virtualization Middleware(Project under CNCF)</p>
            <p>Language: Go</p>
            <p>Stars: 2,359</p>
            <p>Forks: 393</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>English version | [中文版](README_cn.md)

&lt;img src=&quot;imgs/hami-horizontal-colordark.png&quot; width=&quot;600px&quot;&gt;

[![LICENSE](https://img.shields.io/github/license/Project-HAMi/HAMi.svg)](/LICENSE)
[![build status](https://github.com/Project-HAMi/HAMi/actions/workflows/ci.yaml/badge.svg)](https://github.com/Project-HAMi/HAMi/actions/workflows/ci.yaml)
[![Releases](https://img.shields.io/github/v/release/Project-HAMi/HAMi)](https://github.com/Project-HAMi/HAMi/releases/latest)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9416/badge)](https://www.bestpractices.dev/en/projects/9416)
[![Go Report Card](https://goreportcard.com/badge/github.com/Project-HAMi/HAMi)](https://goreportcard.com/report/github.com/Project-HAMi/HAMi)
[![codecov](https://codecov.io/gh/Project-HAMi/HAMi/branch/master/graph/badge.svg?token=ROM8CMPXZ6)](https://codecov.io/gh/Project-HAMi/HAMi)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2FProject-HAMi%2FHAMi.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2FProject-HAMi%2FHAMi?ref=badge_shield)
[![docker pulls](https://img.shields.io/docker/pulls/projecthami/hami.svg)](https://hub.docker.com/r/projecthami/hami)
[![slack](https://img.shields.io/badge/Slack-Join%20Slack-blue)](https://cloud-native.slack.com/archives/C07T10BU4R2)
[![discuss](https://img.shields.io/badge/Discuss-Ask%20Questions-blue)](https://github.com/Project-HAMi/HAMi/discussions)
[![website](https://img.shields.io/badge/website-blue)](http://project-hami.io)
[![Contact Me](https://img.shields.io/badge/Contact%20Me-blue)](https://github.com/Project-HAMi/HAMi#contact)

## Project-HAMi: Heterogeneous AI Computing Virtualization Middleware

## Introduction

HAMi, formerly known as &#039;k8s-vGPU-scheduler&#039;, is a Heterogeneous device management middleware for Kubernetes. It can manage different types of heterogeneous devices (like GPU, NPU, etc.), share heterogeneous devices among pods, make better scheduling decisions based on topology of devices and scheduling policies.

It aims to remove the gap between different Heterogeneous devices, and provide a unified interface for users to manage with no changes to their applications. As of December 2024, HAMi has been widely used not only in Internet, public cloud and private cloud, but also broadly adopted in various vertical industries including finance, securities, energy, telecommunications, education, and manufacturing. More than 50 companies or institutions are not only end users but also active contributors. 

![cncf_logo](imgs/cncf-logo.png)

HAMi is a sandbox and [landscape](https://landscape.cncf.io/?item=orchestration-management--scheduling-orchestration--hami) project of  
[Cloud Native Computing Foundation](https://cncf.io/)(CNCF), 
[CNAI Landscape project](https://landscape.cncf.io/?group=cnai&amp;item=cnai--general-orchestration--hami).


## Device virtualization

HAMi provides device virtualization for several heterogeneous devices including GPU, by supporting device sharing and device resource isolation. For the list of devices supporting device virtualization, see [supported devices](#supported-devices)

### Device sharing

- Allows partial device allocation by specifying device core usage.
- Allows partial device allocation by specifying device memory.
- Imposes a hard limit on streaming multiprocessors.
- Requires zero changes to existing programs.
- Support [dynamic-mig](docs/dynamic-mig-support.md) feature, [example](examples/nvidia/dynamic_mig_example.yaml)

&lt;img src=&quot;./imgs/example.png&quot; width = &quot;500&quot; /&gt; 

### Device Resources Isolation

A simple demonstration of device isolation:
A task with the following resources will see 3000M device memory inside container:

```yaml
      resources:
        limits:
          nvidia.com/gpu: 1 # declare how many physical GPUs the pod needs
          nvidia.com/gpumem: 3000 # identifies 3G GPU memory each physical GPU allocates to the pod
```

![img](./imgs/hard_limit.jpg)

&gt; Note:
1. **After installing HAMi, the value of `nvidia.com/gpu` registered on the node defaults to the number of vGPUs.**
2. **When requesting resources in a pod, `nvidia.com/gpu` refers to the number of physical GPUs required by the current pod.**

### Supported devices

[NVIDIA GPU](https://github.com/Project-HAMi/HAMi#preparing-your-gpu-nodes)   
[Cambricon MLU](docs/cambricon-mlu-support.md)   
[HYGON DCU](docs/hygon-dcu-support.md)   
[Iluvatar CoreX GPU](docs/iluvatar-gpu-support.md)   
[Moore Threads GPU](docs/mthreads-support.md)   
[HUAWEI Ascend NPU](https://github.com/Project-HAMi/ascend-device-plugin/blob/main/README.md)   
[MetaX GPU](docs/metax-support.md)   

## Architect

&lt;img src=&quot;./imgs/hami-arch.png&quot; width = &quot;600&quot; /&gt; 

HAMi consists of several components, including a unified mutatingwebhook, a unified scheduler extender, different device-plugins and different in-container virtualization technics for each heterogeneous AI devices.

## Quick Start

### Choose your orchestrator

[![kube-scheduler](https://img.shields.io/badge/kube-scheduler-blue)](#prerequisites)
[![volcano-scheduler](https://img.shields.io/badge/volcano-scheduler-orange)](docs/how-to-use-volcano-vgpu.md)

### Prerequisites

The list of prerequisites for running the NVIDIA device plugin is described below:

- NVIDIA drivers &gt;= 440
- nvidia-docker version &gt; 2.0
- default runtime configured as nvidia for containerd/docker/cri-o container runtime
- Kubernetes version &gt;= 1.18
- glibc &gt;= 2.17 &amp; glibc &lt; 2.30
- kernel version &gt;= 3.10
- helm &gt; 3.0

### Install

First, Label your GPU nodes for scheduling with HAMi by adding the label &quot;gpu=on&quot;. Without this label, the nodes cannot be managed by our scheduler.

```
kubectl label nodes {nodeid} gpu=on
```

Add our repo in helm

```
helm repo add hami-charts https://project-hami.github.io/HAMi/
```

Use the following command for deployment:

```
helm install hami hami-charts/hami -n kube-system
```

Customize your installation by adjusting the [configs](docs/config.md).

Verify your installation using the following command:

```
kubectl get pods -n kube-system
```

If both `hami-device-plugin` (formerly known as `vgpu-device-plugin`)  and `hami-scheduler` (formerly known as `vgpu-scheduler`)  pods are in the *Running* state, your installation is successful. You can try examples [here](examples/nvidia/default_use.yaml) 

### WebUI

[HAMi-WebUI](https://github.com/Project-HAMi/HAMi-WebUI) is available after HAMi v2.4

For installation guide, click [here](https://github.com/Project-HAMi/HAMi-WebUI/blob/main/docs/installation/helm/index.md)

### Monitor

Monitoring is automatically enabled after installation. Obtain an overview of cluster information by visiting the following URL:

```
http://{scheduler ip}:{monitorPort}/metrics
```

The default monitorPort is 31993; other values can be set using `--set devicePlugin.service.httpPort` during installation.

Grafana dashboard [example](docs/dashboard.md)

&gt; **Note** The status of a node won&#039;t be collected before you submit a task

## Notes

- If you don&#039;t request vGPUs when using the device plugin with NVIDIA images all the GPUs on the machine may be exposed inside your container
- Currently, A100 MIG can be supported in only &quot;none&quot; and &quot;mixed&quot; modes.
- Tasks with the &quot;nodeName&quot; field cannot be scheduled at the moment; please use &quot;nodeSelector&quot; instead.

## RoadMap, Governance &amp; Contributing

The project is governed by a group of [Maintainers](./MAINTAINERS.md) and [Contributors](./AUTHORS.md). How they are selected and govern is outlined in our [Governance Document](https://github.com/Project-HAMi/community/blob/main/governance.md).

If you&#039;re interested in being a contributor and want to get involved in developing the HAMi code, please see [CONTRIBUTING](CONTRIBUTING.md) for details on submitting patches and the contribution workflow.

See [RoadMap](docs/develop/roadmap.md) to see anything you interested.

## Meeting &amp; Contact

The HAMi community is committed to fostering an open and welcoming environment, with several ways to engage with other users and developers.

If you have any questions, please feel free to reach out to us through the following channels:

- Regular Community Meeting: Friday at 16:00 UTC+8 (Chinese)(weekly). [Convert to your timezone](https://www.thetimezoneconverter.com/?t=14%3A30&amp;tz=GMT%2B8&amp;).
  - [Meeting Notes and Agenda](https://docs.google.com/document/d/1YC6hco03_oXbF9IOUPJ29VWEddmITIKIfSmBX8JtGBw/edit#heading=h.g61sgp7w0d0c)
  - [Meeting Link](https://meeting.tencent.com/dm/Ntiwq1BICD1P)
- Email: refer to the [MAINTAINERS.md](MAINTAINERS.md) to find the email addresses of all maintainers. Feel free to contact them via email to report any issues or ask questions.
- [mailing list](https://groups.google.com/forum/#!forum/hami-project)
- [slack](https://cloud-native.slack.com/archives/C07T10BU4R2) | [Join](https://slack.cncf.io/)

## Talks and References

|                  | Link                                                                                                                    |
|------------------|-------------------------------------------------------------------------------------------------------------------------|
| CHINA CLOUD COMPUTING INFRASTRUCTURE DEVELOPER CONFERENCE (Beijing 2024) | [Unlocking heterogeneous AI infrastructure on k8s clusters](https://live.csdn.net/room/csdnnews/3zwDP09S) Starting from 03:06:15 |
| KubeDay(Japan 2024) | [Unlocking Heterogeneous AI Infrastructure K8s Cluster:Leveraging the Power of HAMi](https://www.youtube.com/watch?v=owoaSb4nZwg) |
| KubeCon &amp; AI_dev Open Source GenAI &amp; ML Summit(China 2024) | [Is Your GPU Really Working Efficiently in the Data Center?N Ways to Improve GPU Usage](https://www.youtube.com/watch?v=ApkyK3zLF5Q) |
| KubeCon &amp; AI_dev Open Source GenAI &amp; ML Summit(China 2024) | [Unlocking Heterogeneous AI Infrastructure K8s Cluster](https://www.youtube.com/watch?v=kcGXnp_QShs)                                     |
| KubeCon(EU 2024)| [Cloud Native Batch Computing with Volcano: Updates and Future](https://youtu.be/fVYKk6xSOsw) |

## License

HAMi is under the Apache 2.0 license. See the [LICENSE](LICENSE) file for details.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Project-HAMi/HAMi&amp;type=Date)](https://star-history.com/#Project-HAMi/HAMi&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[vxcontrol/pentagi]]></title>
            <link>https://github.com/vxcontrol/pentagi</link>
            <guid>https://github.com/vxcontrol/pentagi</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[✨ Fully autonomous AI Agents system capable of performing complex penetration testing tasks]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vxcontrol/pentagi">vxcontrol/pentagi</a></h1>
            <p>✨ Fully autonomous AI Agents system capable of performing complex penetration testing tasks</p>
            <p>Language: Go</p>
            <p>Stars: 685</p>
            <p>Forks: 117</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre># PentAGI

&lt;div align=&quot;center&quot; style=&quot;font-size: 1.5em; margin: 20px 0;&quot;&gt;
    &lt;strong&gt;P&lt;/strong&gt;enetration testing &lt;strong&gt;A&lt;/strong&gt;rtificial &lt;strong&gt;G&lt;/strong&gt;eneral &lt;strong&gt;I&lt;/strong&gt;ntelligence
&lt;/div&gt;
&lt;br&gt;
&lt;div align=&quot;center&quot;&gt;

&gt; 🚀 **Join the Community!** Connect with security researchers, AI enthusiasts, and fellow ethical hackers. Get support, share insights, and stay updated with the latest PentAGI developments.

[![Discord](https://img.shields.io/badge/Discord-7289DA?logo=discord&amp;logoColor=white)](https://discord.gg/2xrMh7qX6m)⠀[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?logo=telegram&amp;logoColor=white)](https://t.me/+Ka9i6CNwe71hMWQy)

&lt;/div&gt;

## 📖 Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Quick Start](#-quick-start)
- [Advanced Setup](#-advanced-setup)
- [Development](#-development)
- [Testing LLM Agents](#-testing-llm-agents)
- [Embedding Configuration and Testing](#-embedding-configuration-and-testing)
- [Function Testing with ftester](#-function-testing-with-ftester)
- [Building](#%EF%B8%8F-building)
- [Credits](#-credits)
- [License](#-license)

## 🎯 Overview

PentAGI is an innovative tool for automated security testing that leverages cutting-edge artificial intelligence technologies. The project is designed for information security professionals, researchers, and enthusiasts who need a powerful and flexible solution for conducting penetration tests.

You can watch the video **PentAGI overview**:
[![PentAGI Overview Video](https://github.com/user-attachments/assets/0828dc3e-15f1-4a1d-858e-9696a146e478)](https://youtu.be/R70x5Ddzs1o)

## ✨ Features

- 🛡️ Secure &amp; Isolated. All operations are performed in a sandboxed Docker environment with complete isolation.
- 🤖 Fully Autonomous. AI-powered agent that automatically determines and executes penetration testing steps.
- 🔬 Professional Pentesting Tools. Built-in suite of 20+ professional security tools including nmap, metasploit, sqlmap, and more.
- 🧠 Smart Memory System. Long-term storage of research results and successful approaches for future use.
- 🔍 Web Intelligence. Built-in browser via [scraper](https://hub.docker.com/r/vxcontrol/scraper) for gathering latest information from web sources.
- 🔎 External Search Systems. Integration with advanced search APIs including [Tavily](https://tavily.com), [Traversaal](https://traversaal.ai), [Perplexity](https://www.perplexity.ai), [DuckDuckGo](https://duckduckgo.com/), [Google Custom Search](https://programmablesearchengine.google.com/), and [Searxng](https://searxng.org) for comprehensive information gathering.
- 👥 Team of Specialists. Delegation system with specialized AI agents for research, development, and infrastructure tasks.
- 📊 Comprehensive Monitoring. Detailed logging and integration with Grafana/Prometheus for real-time system observation.
- 📝 Detailed Reporting. Generation of thorough vulnerability reports with exploitation guides.
- 📦 Smart Container Management. Automatic Docker image selection based on specific task requirements.
- 📱 Modern Interface. Clean and intuitive web UI for system management and monitoring.
- 🔌 API Integration. Support for REST and GraphQL APIs for seamless external system integration.
- 💾 Persistent Storage. All commands and outputs are stored in PostgreSQL with [pgvector](https://hub.docker.com/r/vxcontrol/pgvector) extension.
- 🎯 Scalable Architecture. Microservices-based design supporting horizontal scaling.
- 🏠 Self-Hosted Solution. Complete control over your deployment and data.
- 🔑 Flexible Authentication. Support for various LLM providers ([OpenAI](https://platform.openai.com/), [Anthropic](https://www.anthropic.com/), [Ollama](https://ollama.com/), [AWS Bedrock](https://aws.amazon.com/bedrock/), [Google AI/Gemini](https://ai.google.dev/), [Deep Infra](https://deepinfra.com/), [OpenRouter](https://openrouter.ai/), [DeepSeek](https://www.deepseek.com/en)) and custom configurations.
- ⚡ Quick Deployment. Easy setup through [Docker Compose](https://docs.docker.com/compose/) with comprehensive environment configuration.

## 🏗️ Architecture

### System Context

```mermaid
flowchart TB
    classDef person fill:#08427B,stroke:#073B6F,color:#fff
    classDef system fill:#1168BD,stroke:#0B4884,color:#fff
    classDef external fill:#666666,stroke:#0B4884,color:#fff

    pentester[&quot;👤 Security Engineer
    (User of the system)&quot;]

    pentagi[&quot;✨ PentAGI
    (Autonomous penetration testing system)&quot;]

    target[&quot;🎯 target-system
    (System under test)&quot;]
    llm[&quot;🧠 llm-provider
    (OpenAI/Anthropic/Ollama/Bedrock/Gemini/Custom)&quot;]
    search[&quot;🔍 search-systems
    (Google/DuckDuckGo/Tavily/Traversaal/Perplexity/Searxng)&quot;]
    langfuse[&quot;📊 langfuse-ui
    (LLM Observability Dashboard)&quot;]
    grafana[&quot;📈 grafana
    (System Monitoring Dashboard)&quot;]

    pentester --&gt; |Uses HTTPS| pentagi
    pentester --&gt; |Monitors AI HTTPS| langfuse
    pentester --&gt; |Monitors System HTTPS| grafana
    pentagi --&gt; |Tests Various protocols| target
    pentagi --&gt; |Queries HTTPS| llm
    pentagi --&gt; |Searches HTTPS| search
    pentagi --&gt; |Reports HTTPS| langfuse
    pentagi --&gt; |Reports HTTPS| grafana

    class pentester person
    class pentagi system
    class target,llm,search,langfuse,grafana external

    linkStyle default stroke:#ffffff,color:#ffffff
```

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;🔄 Container Architecture&lt;/b&gt; (click to expand)&lt;/summary&gt;

```mermaid
graph TB
    subgraph Core Services
        UI[Frontend UI&lt;br/&gt;React + TypeScript]
        API[Backend API&lt;br/&gt;Go + GraphQL]
        DB[(Vector Store&lt;br/&gt;PostgreSQL + pgvector)]
        MQ[Task Queue&lt;br/&gt;Async Processing]
        Agent[AI Agents&lt;br/&gt;Multi-Agent System]
    end

    subgraph Monitoring
        Grafana[Grafana&lt;br/&gt;Dashboards]
        VictoriaMetrics[VictoriaMetrics&lt;br/&gt;Time-series DB]
        Jaeger[Jaeger&lt;br/&gt;Distributed Tracing]
        Loki[Loki&lt;br/&gt;Log Aggregation]
        OTEL[OpenTelemetry&lt;br/&gt;Data Collection]
    end

    subgraph Analytics
        Langfuse[Langfuse&lt;br/&gt;LLM Analytics]
        ClickHouse[ClickHouse&lt;br/&gt;Analytics DB]
        Redis[Redis&lt;br/&gt;Cache + Rate Limiter]
        MinIO[MinIO&lt;br/&gt;S3 Storage]
    end

    subgraph Security Tools
        Scraper[Web Scraper&lt;br/&gt;Isolated Browser]
        PenTest[Security Tools&lt;br/&gt;20+ Pro Tools&lt;br/&gt;Sandboxed Execution]
    end

    UI --&gt; |HTTP/WS| API
    API --&gt; |SQL| DB
    API --&gt; |Events| MQ
    MQ --&gt; |Tasks| Agent
    Agent --&gt; |Commands| Tools
    Agent --&gt; |Queries| DB

    API --&gt; |Telemetry| OTEL
    OTEL --&gt; |Metrics| VictoriaMetrics
    OTEL --&gt; |Traces| Jaeger
    OTEL --&gt; |Logs| Loki

    Grafana --&gt; |Query| VictoriaMetrics
    Grafana --&gt; |Query| Jaeger
    Grafana --&gt; |Query| Loki

    API --&gt; |Analytics| Langfuse
    Langfuse --&gt; |Store| ClickHouse
    Langfuse --&gt; |Cache| Redis
    Langfuse --&gt; |Files| MinIO

    classDef core fill:#f9f,stroke:#333,stroke-width:2px,color:#000
    classDef monitoring fill:#bbf,stroke:#333,stroke-width:2px,color:#000
    classDef analytics fill:#bfb,stroke:#333,stroke-width:2px,color:#000
    classDef tools fill:#fbb,stroke:#333,stroke-width:2px,color:#000

    class UI,API,DB,MQ,Agent core
    class Grafana,VictoriaMetrics,Jaeger,Loki,OTEL monitoring
    class Langfuse,ClickHouse,Redis,MinIO analytics
    class Scraper,PenTest tools
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;📊 Entity Relationship&lt;/b&gt; (click to expand)&lt;/summary&gt;

```mermaid
erDiagram
    Flow ||--o{ Task : contains
    Task ||--o{ SubTask : contains
    SubTask ||--o{ Action : contains
    Action ||--o{ Artifact : produces
    Action ||--o{ Memory : stores

    Flow {
        string id PK
        string name &quot;Flow name&quot;
        string description &quot;Flow description&quot;
        string status &quot;active/completed/failed&quot;
        json parameters &quot;Flow parameters&quot;
        timestamp created_at
        timestamp updated_at
    }

    Task {
        string id PK
        string flow_id FK
        string name &quot;Task name&quot;
        string description &quot;Task description&quot;
        string status &quot;pending/running/done/failed&quot;
        json result &quot;Task results&quot;
        timestamp created_at
        timestamp updated_at
    }

    SubTask {
        string id PK
        string task_id FK
        string name &quot;Subtask name&quot;
        string description &quot;Subtask description&quot;
        string status &quot;queued/running/completed/failed&quot;
        string agent_type &quot;researcher/developer/executor&quot;
        json context &quot;Agent context&quot;
        timestamp created_at
        timestamp updated_at
    }

    Action {
        string id PK
        string subtask_id FK
        string type &quot;command/search/analyze/etc&quot;
        string status &quot;success/failure&quot;
        json parameters &quot;Action parameters&quot;
        json result &quot;Action results&quot;
        timestamp created_at
    }

    Artifact {
        string id PK
        string action_id FK
        string type &quot;file/report/log&quot;
        string path &quot;Storage path&quot;
        json metadata &quot;Additional info&quot;
        timestamp created_at
    }

    Memory {
        string id PK
        string action_id FK
        string type &quot;observation/conclusion&quot;
        vector embedding &quot;Vector representation&quot;
        text content &quot;Memory content&quot;
        timestamp created_at
    }
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;🤖 Agent Interaction&lt;/b&gt; (click to expand)&lt;/summary&gt;

```mermaid
sequenceDiagram
    participant O as Orchestrator
    participant R as Researcher
    participant D as Developer
    participant E as Executor
    participant VS as Vector Store
    participant KB as Knowledge Base

    Note over O,KB: Flow Initialization
    O-&gt;&gt;VS: Query similar tasks
    VS--&gt;&gt;O: Return experiences
    O-&gt;&gt;KB: Load relevant knowledge
    KB--&gt;&gt;O: Return context

    Note over O,R: Research Phase
    O-&gt;&gt;R: Analyze target
    R-&gt;&gt;VS: Search similar cases
    VS--&gt;&gt;R: Return patterns
    R-&gt;&gt;KB: Query vulnerabilities
    KB--&gt;&gt;R: Return known issues
    R-&gt;&gt;VS: Store findings
    R--&gt;&gt;O: Research results

    Note over O,D: Planning Phase
    O-&gt;&gt;D: Plan attack
    D-&gt;&gt;VS: Query exploits
    VS--&gt;&gt;D: Return techniques
    D-&gt;&gt;KB: Load tools info
    KB--&gt;&gt;D: Return capabilities
    D--&gt;&gt;O: Attack plan

    Note over O,E: Execution Phase
    O-&gt;&gt;E: Execute plan
    E-&gt;&gt;KB: Load tool guides
    KB--&gt;&gt;E: Return procedures
    E-&gt;&gt;VS: Store results
    E--&gt;&gt;O: Execution status
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;🧠 Memory System&lt;/b&gt; (click to expand)&lt;/summary&gt;

```mermaid
graph TB
    subgraph &quot;Long-term Memory&quot;
        VS[(Vector Store&lt;br/&gt;Embeddings DB)]
        KB[Knowledge Base&lt;br/&gt;Domain Expertise]
        Tools[Tools Knowledge&lt;br/&gt;Usage Patterns]
    end

    subgraph &quot;Working Memory&quot;
        Context[Current Context&lt;br/&gt;Task State]
        Goals[Active Goals&lt;br/&gt;Objectives]
        State[System State&lt;br/&gt;Resources]
    end

    subgraph &quot;Episodic Memory&quot;
        Actions[Past Actions&lt;br/&gt;Commands History]
        Results[Action Results&lt;br/&gt;Outcomes]
        Patterns[Success Patterns&lt;br/&gt;Best Practices]
    end

    Context --&gt; |Query| VS
    VS --&gt; |Retrieve| Context

    Goals --&gt; |Consult| KB
    KB --&gt; |Guide| Goals

    State --&gt; |Record| Actions
    Actions --&gt; |Learn| Patterns
    Patterns --&gt; |Store| VS

    Tools --&gt; |Inform| State
    Results --&gt; |Update| Tools

    VS --&gt; |Enhance| KB
    KB --&gt; |Index| VS

    classDef ltm fill:#f9f,stroke:#333,stroke-width:2px,color:#000
    classDef wm fill:#bbf,stroke:#333,stroke-width:2px,color:#000
    classDef em fill:#bfb,stroke:#333,stroke-width:2px,color:#000

    class VS,KB,Tools ltm
    class Context,Goals,State wm
    class Actions,Results,Patterns em
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;🔄 Chain Summarization&lt;/b&gt; (click to expand)&lt;/summary&gt;

The chain summarization system manages conversation context growth by selectively summarizing older messages. This is critical for preventing token limits from being exceeded while maintaining conversation coherence.

```mermaid
flowchart TD
    A[Input Chain] --&gt; B{Needs Summarization?}
    B --&gt;|No| C[Return Original Chain]
    B --&gt;|Yes| D[Convert to ChainAST]
    D --&gt; E[Apply Section Summarization]
    E --&gt; F[Process Oversized Pairs]
    F --&gt; G[Manage Last Section Size]
    G --&gt; H[Apply QA Summarization]
    H --&gt; I[Rebuild Chain with Summaries]
    I --&gt; J{Is New Chain Smaller?}
    J --&gt;|Yes| K[Return Optimized Chain]
    J --&gt;|No| C

    classDef process fill:#bbf,stroke:#333,stroke-width:2px,color:#000
    classDef decision fill:#bfb,stroke:#333,stroke-width:2px,color:#000
    classDef output fill:#fbb,stroke:#333,stroke-width:2px,color:#000

    class A,D,E,F,G,H,I process
    class B,J decision
    class C,K output
```

The algorithm operates on a structured representation of conversation chains (ChainAST) that preserves message types including tool calls and their responses. All summarization operations maintain critical conversation flow while reducing context size.

### Global Summarizer Configuration Options

| Parameter | Environment Variable | Default | Description |
|-----------|----------------------|---------|-------------|
| Preserve Last | `SUMMARIZER_PRESERVE_LAST` | `true` | Whether to keep all messages in the last section intact |
| Use QA Pairs | `SUMMARIZER_USE_QA` | `true` | Whether to use QA pair summarization strategy |
| Summarize Human in QA | `SUMMARIZER_SUM_MSG_HUMAN_IN_QA` | `false` | Whether to summarize human messages in QA pairs |
| Last Section Size | `SUMMARIZER_LAST_SEC_BYTES` | `51200` | Maximum byte size for last section (50KB) |
| Max Body Pair Size | `SUMMARIZER_MAX_BP_BYTES` | `16384` | Maximum byte size for a single body pair (16KB) |
| Max QA Sections | `SUMMARIZER_MAX_QA_SECTIONS` | `10` | Maximum QA pair sections to preserve |
| Max QA Size | `SUMMARIZER_MAX_QA_BYTES` | `65536` | Maximum byte size for QA pair sections (64KB) |
| Keep QA Sections | `SUMMARIZER_KEEP_QA_SECTIONS` | `1` | Number of recent QA sections to keep without summarization |

### Assistant Summarizer Configuration Options

Assistant instances can use customized summarization settings to fine-tune context management behavior:

| Parameter | Environment Variable | Default | Description |
|-----------|----------------------|---------|-------------|
| Preserve Last | `ASSISTANT_SUMMARIZER_PRESERVE_LAST` | `true` | Whether to preserve all messages in the assistant&#039;s last section |
| Last Section Size | `ASSISTANT_SUMMARIZER_LAST_SEC_BYTES` | `76800` | Maximum byte size for assistant&#039;s last section (75KB) |
| Max Body Pair Size | `ASSISTANT_SUMMARIZER_MAX_BP_BYTES` | `16384` | Maximum byte size for a single body pair in assistant context (16KB) |
| Max QA Sections | `ASSISTANT_SUMMARIZER_MAX_QA_SECTIONS` | `7` | Maximum QA sections to preserve in assistant context |
| Max QA Size | `ASSISTANT_SUMMARIZER_MAX_QA_BYTES` | `76800` | Maximum byte size for assistant&#039;s QA sections (75KB) |
| Keep QA Sections | `ASSISTANT_SUMMARIZER_KEEP_QA_SECTIONS` | `3` | Number of recent QA sections to preserve without summarization |

The assistant summarizer configuration provides more memory for context retention compared to the global settings, preserving more recent conversation history while still ensuring efficient token usage.

### Summarizer Environment Configuration

```bash
# Default values for global summarizer logic
SUMMARIZER_PRESERVE_LAST=true
SUMMARIZER_USE_QA=true
SUMMARIZER_SUM_MSG_HUMAN_IN_QA=false
SUMMARIZER_LAST_SEC_BYTES=51200
SUMMARIZER_MAX_BP_BYTES=16384
SUMMARIZER_MAX_QA_SECTIONS=10
SUMMARIZER_MAX_QA_BYTES=65536
SUMMARIZER_KEEP_QA_SECTIONS=1

# Default values for assistant summarizer logic
ASSISTANT_SUMMARIZER_PRESERVE_LAST=true
ASSISTANT_SUMMARIZER_LAST_SEC_BYTES=76800
ASSISTANT_SUMMARIZER_MAX_BP_BYTES=16384
ASSISTANT_SUMMARIZER_MAX_QA_SECTIONS=7
ASSISTANT_SUMMARIZER_MAX_QA_BYTES=76800
ASSISTANT_SUMMARIZER_KEEP_QA_SECTIONS=3
```

&lt;/details&gt;

The architecture of PentAGI is designed to be modular, scalable, and secure. Here are the key components:

1. **Core Services**
   - Frontend UI: React-based web interface with TypeScript for type safety
   - Backend API: Go-based REST and GraphQL APIs for flexible integration
   - Vector Store: PostgreSQL with pgvector for semantic search and memory storage
   - Task Queue: Async task processing system for reliable operation
   - AI Agent: Multi-agent system with specialized roles for efficient testing

2. **Monitoring Stack**
   - OpenTelemetry: Unified observability data collection and correlation
   - Grafana: Real-time visualization and alerting dashboards
   - VictoriaMetrics: High-performance time-series metrics storage
   - Jaeger: End-to-end distributed tracing for debugging
   - Loki: Scalable log aggregation and analysis

3. **Analytics Platform**
   - Langfuse: Advanced LLM observability and performance analytics
   - ClickHouse: Column-oriented analytics data warehouse
   - Redis: High-speed caching and rate limiting
   - MinIO: S3-compatible object storage for artifacts

4. **Security Tools**
   - Web Scraper: Isolated browser environment for safe web interaction
   - Pentesting Tools: Comprehensive suite of 20+ professional security tools
   - Sandboxed Execution: All operations run in isolated containers

5. **Memory Systems**
   - Long-term Memory: Persistent storage of knowledge and experiences
   - Working Memory: Active context and goals for current operations
   - Episodic Memory: Historical actions and success patterns
   - Knowledge Base: Structured domain expertise and tool capabilities
   - Context Management: Intelligently manages growing LLM context windows using chain summarization

The system uses Docker containers for isolation and easy deployment, with separate networks for core services, monitoring, and analytics to ensure proper security boundaries. Each component is designed to scale horizontally and can be configured for high availability in production environments.

## 🚀 Quick Start

### System Requirements

- Docker and Docker Compose
- Minimum 4GB RAM
- 10GB free disk space
- Internet access for downloading images and updates

### Using Installer (Recommended)

PentAGI provides an interactive installer with a terminal-based UI for streamlined configuration and deployment. The installer guides you through system checks, LLM provider setup, search engine configuration, and security hardening.

**Supported Platforms:**
- **Linux**: amd64 ([download](https://pentagi.com/downloads/linux/amd64/installer-latest.zip)) | arm64 ([download](https://pentagi.com/downloads/linux/arm64/installer-latest.zip))
- **Windows**: amd64
- **macOS**: amd64 (Intel) | arm64 (M-series)

**Quick Installation (Linux amd64):**

```bash
# Create installation directory
mkdir -p pentagi &amp;&amp; cd pentagi

# Download installer
wget -O installer.zip https://pentagi.com/downloads/linux/amd64/installer-latest.zip

# Extract
unzip installer.zip

# Run interactive installer
./installer
```

The installer will:
1. **System Checks**: Verify Docker, network connectivity, and system requirements
2. **Environment Setup**: Create and configure `.env` file with optimal defaults
3. **Provider Configuration**: Set up LLM providers (OpenAI, Anthropic, Gemini, Bedrock, Ollama, Custom)
4. **Search Engines**: Configure DuckDuckGo, Google, Tavily, Traversaal, Perplexity, Searxng
5. **Security Hardening**: Generate secure credentials and configure SSL certificates
6. **Deployment**: Start PentAGI with docker-compose

**For Production &amp; Enhanced Security:**

For production deployments or security-sensitive environments, we **strongly recommend** using a distributed two-node architecture where worker operations are isolated on a separate server. This prevents untrusted code execution and network access issues on your main system.

👉 **See detailed guide**: [Worker Node Setup](examples/guides/worker_node.md)

The two-node setup provides:
- **Isolated Execution**: Worker containers run on dedicated hardware
- **Network Isolation**: Separate network boundaries for penetration testing
- **Securit

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[opentofu/opentofu]]></title>
            <link>https://github.com/opentofu/opentofu</link>
            <guid>https://github.com/opentofu/opentofu</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[OpenTofu lets you declaratively manage your cloud infrastructure.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/opentofu/opentofu">opentofu/opentofu</a></h1>
            <p>OpenTofu lets you declaratively manage your cloud infrastructure.</p>
            <p>Language: Go</p>
            <p>Stars: 26,742</p>
            <p>Forks: 1,099</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre># OpenTofu

- [HomePage](https://opentofu.org/)
- [How to install](https://opentofu.org/docs/intro/install)
- [Join our Slack community!](https://opentofu.org/slack)

![](https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-dark.svg#gh-dark-mode-only)
![](https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-light.svg#gh-light-mode-only)

[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10508/badge)](https://www.bestpractices.dev/projects/10508)

OpenTofu is an OSS tool for building, changing, and versioning infrastructure safely and efficiently. OpenTofu can manage existing and popular service providers as well as custom in-house solutions.

The key features of OpenTofu are:

- **Infrastructure as Code**: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.

- **Execution Plans**: OpenTofu has a &quot;planning&quot; step where it generates an execution plan. The execution plan shows what OpenTofu will do when you call apply. This lets you avoid any surprises when OpenTofu manipulates infrastructure.

- **Resource Graph**: OpenTofu builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, OpenTofu builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.

- **Change Automation**: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what OpenTofu will change and in what order, avoiding many possible human errors.

## Getting help and contributing

- Have a question?
  - Post it in [GitHub Discussions](https://github.com/orgs/opentofu/discussions)
  - Open a [GitHub issue](https://github.com/opentofu/opentofu/issues/new/choose)
  - Join the [OpenTofu Slack](https://opentofu.org/slack/)!
- Want to contribute?
  - Please read the [Contribution Guide](CONTRIBUTING.md).
- Recurring Events
  - [Community Meetings](https://meet.google.com/xfm-cgms-has) on Wednesdays at 12:30 UTC at this link: https://meet.google.com/xfm-cgms-has ([📅 calendar link](https://calendar.google.com/calendar/event?eid=NDg0aWl2Y3U1aHFva3N0bGhyMHBhNzdpZmsgY18zZjJkZDNjMWZlMGVmNGU5M2VmM2ZjNDU2Y2EyZGQyMTlhMmU4ZmQ4NWY2YjQwNzUwYWYxNmMzZGYzNzBiZjkzQGc))
  - [Technical Steering Committee Meetings](https://meet.google.com/cry-houa-qbk) every other Tuesday at 4pm UTC at this link: https://meet.google.com/cry-houa-qbk ([📅 calendar link](https://calendar.google.com/calendar/u/0/event?eid=M3JyMWtuYWptdXI0Zms4ZnJpNmppcDczb3RfMjAyNTA1MjdUMTYwMDAwWiBjXzNmMmRkM2MxZmUwZWY0ZTkzZWYzZmM0NTZjYTJkZDIxOWEyZThmZDg1ZjZiNDA3NTBhZjE2YzNkZjM3MGJmOTNAZw))

&gt; [!TIP]
&gt; For more OpenTofu events, subscribe to the [OpenTofu Events Calendar](https://calendar.google.com/calendar/embed?src=c_3f2dd3c1fe0ef4e93ef3fc456ca2dd219a2e8fd85f6b40750af16c3df370bf93%40group.calendar.google.com)!

## Reporting security vulnerabilities
If you&#039;ve found a vulnerability or a potential vulnerability in OpenTofu please follow [Security Policy](https://github.com/opentofu/opentofu/security/policy). We&#039;ll send a confirmation email to acknowledge your report, and we&#039;ll send an additional email when we&#039;ve identified the issue positively or negatively.

## Reporting possible copyright issues

If you believe you have found any possible copyright or intellectual property issues, please contact liaison@opentofu.org. We&#039;ll send a confirmation email to acknowledge your report.

## Registry Access

In an effort to comply with applicable sanctions, we block access from specific countries of origin.

## License

[Mozilla Public License v2.0](https://github.com/opentofu/opentofu/blob/main/LICENSE)

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[nats-io/nats-server]]></title>
            <link>https://github.com/nats-io/nats-server</link>
            <guid>https://github.com/nats-io/nats-server</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[High-Performance server for NATS.io, the cloud and edge native messaging system.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nats-io/nats-server">nats-io/nats-server</a></h1>
            <p>High-Performance server for NATS.io, the cloud and edge native messaging system.</p>
            <p>Language: Go</p>
            <p>Stars: 18,370</p>
            <p>Forks: 1,663</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;logos/nats-horizontal-color.png&quot; width=&quot;300&quot; alt=&quot;NATS Logo&quot;&gt;
&lt;/p&gt;

[NATS](https://nats.io) is a simple, secure and performant communications system for digital systems, services and devices. NATS is part of the Cloud Native Computing Foundation ([CNCF](https://cncf.io)). NATS has over [40 client language implementations](https://nats.io/download/), and its server can run on-premise, in the cloud, at the edge, and even on a Raspberry Pi. NATS can secure and simplify design and operation of modern distributed systems.

[![License][License-Image]][License-Url] [![Build][Build-Status-Image]][Build-Status-Url] [![Release][Release-Image]][Release-Url] [![Slack][Slack-Image]][Slack-Url] [![Coverage][Coverage-Image]][Coverage-Url] [![Docker Downloads][Docker-Image]][Docker-Url] [![GitHub Downloads][GitHub-Image]][Somsubhra-URL] [![CII Best Practices][CIIBestPractices-Image]][CIIBestPractices-Url] [![Artifact Hub][ArtifactHub-Image]][ArtifactHub-Url]

## Documentation

- [Official Website](https://nats.io)
- [Official Documentation](https://docs.nats.io)
- [FAQ](https://docs.nats.io/reference/faq)
- Watch [a video overview](https://rethink.synadia.com/episodes/1/) of NATS.
- Watch [this video from SCALE 13x](https://www.youtube.com/watch?v=sm63oAVPqAM) to learn more about its origin story and design philosophy.

## Contact

- [Twitter](https://twitter.com/nats_io): Follow us on Twitter!
- [Google Groups](https://groups.google.com/forum/#!forum/natsio): Where you can ask questions
- [Slack](https://natsio.slack.com): Click [here](https://slack.nats.io) to join. You can ask questions to our maintainers and to the rich and active community.

## Contributing

If you are interested in contributing to NATS, read about our...

- [Contributing guide](./CONTRIBUTING.md)
- [Report issues or propose Pull Requests](https://github.com/nats-io)

[License-Url]: https://www.apache.org/licenses/LICENSE-2.0
[License-Image]: https://img.shields.io/badge/License-Apache2-blue.svg
[Docker-Image]: https://img.shields.io/docker/pulls/_/nats.svg
[Docker-Url]: https://hub.docker.com/_/nats
[Slack-Image]: https://img.shields.io/badge/chat-on%20slack-green
[Slack-Url]: https://slack.nats.io
[Fossa-Url]: https://app.fossa.io/projects/git%2Bgithub.com%2Fnats-io%2Fnats-server?ref=badge_shield
[Fossa-Image]: https://app.fossa.io/api/projects/git%2Bgithub.com%2Fnats-io%2Fnats-server.svg?type=shield
[Build-Status-Url]: https://github.com/nats-io/nats-server/actions/workflows/tests.yaml
[Build-Status-Image]: https://github.com/nats-io/nats-server/actions/workflows/tests.yaml/badge.svg?branch=main
[Release-Url]: https://github.com/nats-io/nats-server/releases/latest
[Release-Image]: https://img.shields.io/github/v/release/nats-io/nats-server
[Coverage-Url]: https://coveralls.io/r/nats-io/nats-server?branch=main
[Coverage-image]: https://coveralls.io/repos/github/nats-io/nats-server/badge.svg?branch=main
[ReportCard-Url]: https://goreportcard.com/report/nats-io/nats-server
[ReportCard-Image]: https://goreportcard.com/badge/github.com/nats-io/nats-server
[CIIBestPractices-Url]: https://bestpractices.coreinfrastructure.org/projects/1895
[CIIBestPractices-Image]: https://bestpractices.coreinfrastructure.org/projects/1895/badge
[ArtifactHub-Url]: https://artifacthub.io/packages/helm/nats/nats
[ArtifactHub-Image]: https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/nats
[GitHub-Release]: https://github.com/nats-io/nats-server/releases/
[GitHub-Image]: https://img.shields.io/github/downloads/nats-io/nats-server/total.svg?logo=github
[Somsubhra-url]: https://somsubhra.github.io/github-release-stats/?username=nats-io&amp;repository=nats-server

## Roadmap

The NATS product roadmap can be found [here](https://nats.io/about/#roadmap).

## Adopters

Who uses NATS? See our [list of users](https://nats.io/#who-uses-nats) on [https://nats.io](https://nats.io).

## Security

### Security Audit

A third party security audit was performed by Trail of Bits following engagement by the Open Source Technology Improvement Fund (OSTIF). You can see the [full report from April 2025 here](https://github.com/trailofbits/publications/blob/master/reviews/2025-04-ostif-nats-securityreview.pdf).

### Reporting Security Vulnerabilities

If you&#039;ve found a vulnerability or a potential vulnerability in the NATS server, please let us know at
[nats-security](mailto:security@nats.io).

## License

Unless otherwise noted, the NATS source files are distributed
under the Apache Version 2.0 license found in the LICENSE file.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[docker/model-runner]]></title>
            <link>https://github.com/docker/model-runner</link>
            <guid>https://github.com/docker/model-runner</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[Docker Model Runner]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/docker/model-runner">docker/model-runner</a></h1>
            <p>Docker Model Runner</p>
            <p>Language: Go</p>
            <p>Stars: 158</p>
            <p>Forks: 33</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre># Docker Model Runner

Docker Model Runner (DMR) makes it easy to manage, run, and deploy AI models using Docker. Designed for developers, Docker Model Runner streamlines the process of pulling, running, and serving large language models (LLMs) and other AI models directly from Docker Hub or any OCI-compliant registry.

## Overview

This package supports the Docker Model Runner in Docker Desktop and Docker Engine.

### Installation

For macOS and Windows, install Docker Desktop:

https://docs.docker.com/desktop/

For Linux, install Docker Engine:

```bash
curl -fsSL https://get.docker.com | sudo bash
```

Docker Model Runner is included in the above tools.

For more details refer to:

https://docs.docker.com/ai/model-runner/get-started/

### Prerequisites

Before building from source, ensure you have the following installed:

- **Go 1.24+** - Required for building both model-runner and model-cli
- **Git** - For cloning repositories
- **Make** - For using the provided Makefiles
- **Docker** (optional) - For building and running containerized versions
- **CGO dependencies** - Required for model-runner&#039;s GPU support:
  - On macOS: Xcode Command Line Tools (`xcode-select --install`)
  - On Linux: gcc/g++ and development headers
  - On Windows: MinGW-w64 or Visual Studio Build Tools

### Building the Complete Stack

#### Step 1: Clone and Build model-runner (Server/Daemon)

```bash
# Clone the model-runner repository
git clone https://github.com/docker/model-runner.git
cd model-runner

# Build the model-runner binary
make build

# Or build with specific backend arguments
make run LLAMA_ARGS=&quot;--verbose --jinja -ngl 999 --ctx-size 2048&quot;

# Run tests to verify the build
make test
```

The `model-runner` binary will be created in the current directory. This is the backend server that manages models.

#### Step 2: Build model-cli (Client)

```bash
# From the root directory, navigate to the model-cli directory
cd cmd/cli

# Build the CLI binary
make build

# The binary will be named &#039;model-cli&#039;
# Optionally, install it as a Docker CLI plugin
make install  # This will link it to ~/.docker/cli-plugins/docker-model
```

### Testing the Complete Stack End-to-End

&gt; **Note:** We use port 13434 in these examples to avoid conflicts with Docker Desktop&#039;s built-in Model Runner, which typically runs on port 12434.

#### Option 1: Local Development (Recommended for Contributors)

1. **Start model-runner in one terminal:**
```bash
cd model-runner
MODEL_RUNNER_PORT=13434 ./model-runner
# The server will start on port 13434
```

2. **Use model-cli in another terminal:**
```bash
cd cmd/cli
# List available models (connecting to port 13434)
MODEL_RUNNER_HOST=http://localhost:13434 ./model-cli list

# Pull and run a model
MODEL_RUNNER_HOST=http://localhost:13434 ./model-cli run ai/smollm2 &quot;Hello, how are you?&quot; 
```

#### Option 2: Using Docker

1. **Build and run model-runner in Docker:**
```bash
cd model-runner
make docker-build
make docker-run PORT=13434 MODELS_PATH=/path/to/models
```

2. **Connect with model-cli:**
```bash
cd cmd/cli
MODEL_RUNNER_HOST=http://localhost:13434 ./model-cli list
```

### Additional Resources

- [Model Runner Documentation](https://docs.docker.com/desktop/features/model-runner/)
- [Model CLI README](./cmd/cli/README.md)
- [Model Specification](https://github.com/docker/model-spec/blob/main/spec.md)
- [Community Slack Channel](https://app.slack.com/client/T0JK1PCN6/C09H9P5E57B)

## Using the Makefile

This project includes a Makefile to simplify common development tasks. It requires Docker Desktop &gt;= 4.41.0 
The Makefile provides the following targets:

- `build` - Build the Go application
- `run` - Run the application locally
- `clean` - Clean build artifacts
- `test` - Run tests
- `docker-build` - Build the Docker image
- `docker-run` - Run the application in a Docker container with TCP port access and mounted model storage
- `help` - Show available targets

### Running in Docker

The application can be run in Docker with the following features enabled by default:
- TCP port access (default port 8080)
- Persistent model storage in a local `models` directory

```sh
# Run with default settings
make docker-run

# Customize port and model storage location
make docker-run PORT=3000 MODELS_PATH=/path/to/your/models
```

This will:
- Create a `models` directory in your current working directory (or use the specified path)
- Mount this directory into the container
- Start the service on port 8080 (or the specified port)
- All models downloaded will be stored in the host&#039;s `models` directory and will persist between container runs

### llama.cpp integration

The Docker image includes the llama.cpp server binary from the `docker/docker-model-backend-llamacpp` image. You can specify the version of the image to use by setting the `LLAMA_SERVER_VERSION` variable. Additionally, you can configure the target OS, architecture, and acceleration type:

```sh
# Build with a specific llama.cpp server version
make docker-build LLAMA_SERVER_VERSION=v0.0.4

# Specify all parameters
make docker-build LLAMA_SERVER_VERSION=v0.0.4 LLAMA_SERVER_VARIANT=cpu
```

Default values:
- `LLAMA_SERVER_VERSION`: latest
- `LLAMA_SERVER_VARIANT`: cpu

The binary path in the image follows this pattern: `/com.docker.llama-server.native.linux.${LLAMA_SERVER_VARIANT}.${TARGETARCH}`

## API Examples

The Model Runner exposes a REST API that can be accessed via TCP port. You can interact with it using curl commands.

### Using the API

When running with `docker-run`, you can use regular HTTP requests:

```sh
# List all available models
curl http://localhost:8080/models

# Create a new model
curl http://localhost:8080/models/create -X POST -d &#039;{&quot;from&quot;: &quot;ai/smollm2&quot;}&#039;

# Get information about a specific model
curl http://localhost:8080/models/ai/smollm2

# Chat with a model
curl http://localhost:8080/engines/llama.cpp/v1/chat/completions -X POST -d &#039;{
  &quot;model&quot;: &quot;ai/smollm2&quot;,
  &quot;messages&quot;: [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello, how are you?&quot;}
  ]
}&#039;

# Delete a model
curl http://localhost:8080/models/ai/smollm2 -X DELETE

# Get metrics
curl http://localhost:8080/metrics
```

The response will contain the model&#039;s reply:

```json
{
  &quot;id&quot;: &quot;chat-12345&quot;,
  &quot;object&quot;: &quot;chat.completion&quot;,
  &quot;created&quot;: 1682456789,
  &quot;model&quot;: &quot;ai/smollm2&quot;,
  &quot;choices&quot;: [
    {
      &quot;index&quot;: 0,
      &quot;message&quot;: {
        &quot;role&quot;: &quot;assistant&quot;,
        &quot;content&quot;: &quot;I&#039;m doing well, thank you for asking! How can I assist you today?&quot;
      },
      &quot;finish_reason&quot;: &quot;stop&quot;
    }
  ],
  &quot;usage&quot;: {
    &quot;prompt_tokens&quot;: 24,
    &quot;completion_tokens&quot;: 16,
    &quot;total_tokens&quot;: 40
  }
}
```

## Metrics

The Model Runner exposes [the metrics endpoint](https://github.com/ggml-org/llama.cpp/tree/master/tools/server#get-metrics-prometheus-compatible-metrics-exporter) of llama.cpp server at the `/metrics` endpoint. This allows you to monitor model performance, request statistics, and resource usage.

### Accessing Metrics

```sh
# Get metrics in Prometheus format
curl http://localhost:8080/metrics
```

### Configuration

- **Enable metrics (default)**: Metrics are enabled by default
- **Disable metrics**: Set `DISABLE_METRICS=1` environment variable
- **Monitoring integration**: Add the endpoint to your Prometheus configuration

Check [METRICS.md](./METRICS.md) for more details.

##  Kubernetes

Experimental support for running in Kubernetes is available
in the form of [a Helm chart and static YAML](charts/docker-model-runner/README.md).

If you are interested in a specific Kubernetes use-case, please start a
discussion on the issue tracker.

## Community

For general questions and discussion, please use [Docker Model Runner&#039;s Slack channel](https://app.slack.com/client/T0JK1PCN6/C09H9P5E57B).

For discussions about issues/bugs and features, you can use GitHub Issues and Pull requests.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[github/github-mcp-server]]></title>
            <link>https://github.com/github/github-mcp-server</link>
            <guid>https://github.com/github/github-mcp-server</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[GitHub's official MCP Server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/github/github-mcp-server">github/github-mcp-server</a></h1>
            <p>GitHub's official MCP Server</p>
            <p>Language: Go</p>
            <p>Stars: 23,615</p>
            <p>Forks: 2,754</p>
            <p>Stars today: 94 stars today</p>
            <h2>README</h2><pre># GitHub MCP Server

The GitHub MCP Server connects AI tools directly to GitHub&#039;s platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code files, manage issues and PRs, analyze code, and automate workflows. All through natural language interactions.

### Use Cases

- Repository Management: Browse and query code, search files, analyze commits, and understand project structure across any repository you have access to.
- Issue &amp; PR Automation: Create, update, and manage issues and pull requests. Let AI help triage bugs, review code changes, and maintain project boards.
- CI/CD &amp; Workflow Intelligence: Monitor GitHub Actions workflow runs, analyze build failures, manage releases, and get insights into your development pipeline.
- Code Analysis: Examine security findings, review Dependabot alerts, understand code patterns, and get comprehensive insights into your codebase.
- Team Collaboration: Access discussions, manage notifications, analyze team activity, and streamline processes for your team.

Built for developers who want to connect their AI tools to GitHub context and capabilities, from simple natural language queries to complex multi-step agent workflows.

---

## Remote GitHub MCP Server

[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D&amp;quality=insiders)

The remote GitHub MCP Server is hosted by GitHub and provides the easiest method for getting up and running. If your MCP host does not support remote MCP servers, don&#039;t worry! You can use the [local version of the GitHub MCP Server](https://github.com/github/github-mcp-server?tab=readme-ov-file#local-github-mcp-server) instead.

### Prerequisites

1. A compatible MCP host with remote server support (VS Code 1.101+, Claude Desktop, Cursor, Windsurf, etc.)
2. Any applicable [policies enabled](https://github.com/github/github-mcp-server/blob/main/docs/policies-and-governance.md)

### Install in VS Code

For quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start. Make sure you&#039;re using [VS Code 1.101](https://code.visualstudio.com/updates/v1_101) or [later](https://code.visualstudio.com/updates) for remote MCP and OAuth support.

Alternatively, to manually configure VS Code, choose the appropriate JSON block from the examples below and add it to your host configuration:

&lt;table&gt;
&lt;tr&gt;&lt;th&gt;Using OAuth&lt;/th&gt;&lt;th&gt;Using a GitHub PAT&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th align=left colspan=2&gt;VS Code (version 1.101 or greater)&lt;/th&gt;&lt;/tr&gt;
&lt;tr valign=top&gt;
&lt;td&gt;

```json
{
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;
    }
  }
}
```

&lt;/td&gt;
&lt;td&gt;

```json
{
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;,
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;Bearer ${input:github_mcp_pat}&quot;
      }
    }
  },
  &quot;inputs&quot;: [
    {
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;id&quot;: &quot;github_mcp_pat&quot;,
      &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
      &quot;password&quot;: true
    }
  ]
}
```

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

### Install in other MCP hosts
- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot
- **[Claude Applications](/docs/installation-guides/install-claude.md)** - Installation guide for Claude Web, Claude Desktop and Claude Code CLI
- **[Cursor](/docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE
- **[Windsurf](/docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE

&gt; **Note:** Each MCP host application needs to configure a GitHub App or OAuth App to support remote access via OAuth. Any host application that supports remote MCP servers should support the remote GitHub server with PAT authentication. Configuration details and support levels vary by host. Make sure to refer to the host application&#039;s documentation for more info.

### Configuration

#### Toolset configuration

See [Remote Server Documentation](docs/remote-server.md) for full details on remote server configuration, toolsets, headers, and advanced usage. This file provides comprehensive instructions and examples for connecting, customizing, and installing the remote GitHub MCP Server in VS Code and other MCP hosts.

When no toolsets are specified, [default toolsets](#default-toolset) are used.

#### Enterprise Cloud with data residency (ghe.com)

GitHub Enterprise Cloud can also make use of the remote server.

Example for `https://octocorp.ghe.com`:
```
{
    ...
    &quot;proxima-github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://copilot-api.octocorp.ghe.com/mcp&quot;,
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;Bearer ${input:github_mcp_pat}&quot;
      }
    },
    ...
}
```

GitHub Enterprise Server does not support remote server hosting. Please refer to [GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)](#github-enterprise-server-and-enterprise-cloud-with-data-residency-ghecom) from the local server configuration.

---

## Local GitHub MCP Server

[![Install with Docker in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&amp;config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D) [![Install with Docker in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&amp;config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D&amp;quality=insiders)

### Prerequisites

1. To run the server in a container, you will need to have [Docker](https://www.docker.com/) installed.
2. Once Docker is installed, you will also need to ensure Docker is running. The image is public; if you get errors on pull, you may have an expired token and need to `docker logout ghcr.io`.
3. Lastly you will need to [Create a GitHub Personal Access Token](https://github.com/settings/personal-access-tokens/new).
The MCP server can use many of the GitHub APIs, so enable the permissions that you feel comfortable granting your AI tools (to learn more about access tokens, please check out the [documentation](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)).

&lt;details&gt;&lt;summary&gt;&lt;b&gt;Handling PATs Securely&lt;/b&gt;&lt;/summary&gt;

### Environment Variables (Recommended)
To keep your GitHub PAT secure and reusable across different MCP hosts:

1. **Store your PAT in environment variables**
   ```bash
   export GITHUB_PAT=your_token_here
   ```
   Or create a `.env` file:
   ```env
   GITHUB_PAT=your_token_here
   ```

2. **Protect your `.env` file**
   ```bash
   # Add to .gitignore to prevent accidental commits
   echo &quot;.env&quot; &gt;&gt; .gitignore
   ```

3. **Reference the token in configurations**
   ```bash
   # CLI usage
   claude mcp update github -e GITHUB_PERSONAL_ACCESS_TOKEN=$GITHUB_PAT

   # In config files (where supported)
   &quot;env&quot;: {
     &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;$GITHUB_PAT&quot;
   }
   ```

&gt; **Note**: Environment variable support varies by host app and IDE. Some applications (like Windsurf) require hardcoded tokens in config files.

### Token Security Best Practices

- **Minimum scopes**: Only grant necessary permissions
  - `repo` - Repository operations
  - `read:packages` - Docker image access
  - `read:org` - Organization team access
- **Separate tokens**: Use different PATs for different projects/environments
- **Regular rotation**: Update tokens periodically
- **Never commit**: Keep tokens out of version control
- **File permissions**: Restrict access to config files containing tokens
  ```bash
  chmod 600 ~/.your-app/config.json
  ```

&lt;/details&gt;

### GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)

The flag `--gh-host` and the environment variable `GITHUB_HOST` can be used to set
the hostname for GitHub Enterprise Server or GitHub Enterprise Cloud with data residency.

- For GitHub Enterprise Server, prefix the hostname with the `https://` URI scheme, as it otherwise defaults to `http://`, which GitHub Enterprise Server does not support.
- For GitHub Enterprise Cloud with data residency, use `https://YOURSUBDOMAIN.ghe.com` as the hostname.
``` json
&quot;github&quot;: {
    &quot;command&quot;: &quot;docker&quot;,
    &quot;args&quot;: [
    &quot;run&quot;,
    &quot;-i&quot;,
    &quot;--rm&quot;,
    &quot;-e&quot;,
    &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
    &quot;-e&quot;,
    &quot;GITHUB_HOST&quot;,
    &quot;ghcr.io/github/github-mcp-server&quot;
    ],
    &quot;env&quot;: {
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;,
        &quot;GITHUB_HOST&quot;: &quot;https://&lt;your GHES or ghe.com domain name&gt;&quot;
    }
}
```

## Installation

### Install in GitHub Copilot on VS Code

For quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start.

More about using MCP server tools in VS Code&#039;s [agent mode documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers).

Install in GitHub Copilot on other IDEs (JetBrains, Visual Studio, Eclipse, etc.)

Add the following JSON block to your IDE&#039;s MCP settings.

```json
{
  &quot;mcp&quot;: {
    &quot;inputs&quot;: [
      {
        &quot;type&quot;: &quot;promptString&quot;,
        &quot;id&quot;: &quot;github_token&quot;,
        &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
        &quot;password&quot;: true
      }
    ],
    &quot;servers&quot;: {
      &quot;github&quot;: {
        &quot;command&quot;: &quot;docker&quot;,
        &quot;args&quot;: [
          &quot;run&quot;,
          &quot;-i&quot;,
          &quot;--rm&quot;,
          &quot;-e&quot;,
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
          &quot;ghcr.io/github/github-mcp-server&quot;
        ],
        &quot;env&quot;: {
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;
        }
      }
    }
  }
}
```

Optionally, you can add a similar example (i.e. without the mcp key) to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with other host applications that accept the same format.

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Example JSON block without the MCP key included&lt;/b&gt;&lt;/summary&gt;
&lt;br&gt;

```json
{
  &quot;inputs&quot;: [
    {
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;id&quot;: &quot;github_token&quot;,
      &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
      &quot;password&quot;: true
    }
  ],
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;-i&quot;,
        &quot;--rm&quot;,
        &quot;-e&quot;,
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
        &quot;ghcr.io/github/github-mcp-server&quot;
      ],
      &quot;env&quot;: {
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;
      }
    }
  }
}
```

&lt;/details&gt;

### Install in Other MCP Hosts

For other MCP host applications, please refer to our installation guides:

- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot
- **[Claude Code &amp; Claude Desktop](docs/installation-guides/install-claude.md)** - Installation guide for Claude Code and Claude Desktop
- **[Cursor](docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE
- **[Google Gemini CLI](docs/installation-guides/install-gemini-cli.md)** - Installation guide for Google Gemini CLI
- **[Windsurf](docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE

For a complete overview of all installation options, see our **[Installation Guides Index](docs/installation-guides)**.

&gt; **Note:** Any host application that supports local MCP servers should be able to access the local GitHub MCP server. However, the specific configuration process, syntax and stability of the integration will vary by host application. While many may follow a similar format to the examples above, this is not guaranteed. Please refer to your host application&#039;s documentation for the correct MCP configuration syntax and setup process.

### Build from source

If you don&#039;t have Docker, you can use `go build` to build the binary in the
`cmd/github-mcp-server` directory, and use the `github-mcp-server stdio` command with the `GITHUB_PERSONAL_ACCESS_TOKEN` environment variable set to your token. To specify the output location of the build, use the `-o` flag. You should configure your server to use the built executable as its `command`. For example:

```JSON
{
  &quot;mcp&quot;: {
    &quot;servers&quot;: {
      &quot;github&quot;: {
        &quot;command&quot;: &quot;/path/to/github-mcp-server&quot;,
        &quot;args&quot;: [&quot;stdio&quot;],
        &quot;env&quot;: {
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;&lt;YOUR_TOKEN&gt;&quot;
        }
      }
    }
  }
}
```

## Tool Configuration

The GitHub MCP Server supports enabling or disabling specific groups of functionalities via the `--toolsets` flag. This allows you to control which GitHub API capabilities are available to your AI tools. Enabling only the toolsets that you need can help the LLM with tool choice and reduce the context size.

_Toolsets are not limited to Tools. Relevant MCP Resources and Prompts are also included where applicable._

When no toolsets are specified, [default toolsets](#default-toolset) are used.

#### Specifying Toolsets

To specify toolsets you want available to the LLM, you can pass an allow-list in two ways:

1. **Using Command Line Argument**:

   ```bash
   github-mcp-server --toolsets repos,issues,pull_requests,actions,code_security
   ```

2. **Using Environment Variable**:
   ```bash
   GITHUB_TOOLSETS=&quot;repos,issues,pull_requests,actions,code_security&quot; ./github-mcp-server
   ```

The environment variable `GITHUB_TOOLSETS` takes precedence over the command line argument if both are provided.

### Using Toolsets With Docker

When using Docker, you can pass the toolsets as environment variables:

```bash
docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&lt;your-token&gt; \
  -e GITHUB_TOOLSETS=&quot;repos,issues,pull_requests,actions,code_security,experiments&quot; \
  ghcr.io/github/github-mcp-server
```

### Special toolsets

#### &quot;all&quot; toolset

The special toolset `all` can be provided to enable all available toolsets regardless of any other configuration:

```bash
./github-mcp-server --toolsets all
```

Or using the environment variable:

```bash
GITHUB_TOOLSETS=&quot;all&quot; ./github-mcp-server
```

#### &quot;default&quot; toolset
The default toolset `default` is the configuration that gets passed to the server if no toolsets are specified.

The default configuration is:
- context
- repos
- issues
- pull_requests
- users

To keep the default configuration and add additional toolsets:

```bash
GITHUB_TOOLSETS=&quot;default,stargazers&quot; ./github-mcp-server
```

### Available Toolsets

The following sets of tools are available:

&lt;!-- START AUTOMATED TOOLSETS --&gt;
| Toolset                 | Description                                                   |
| ----------------------- | ------------------------------------------------------------- |
| `context`               | **Strongly recommended**: Tools that provide context about the current user and GitHub context you are operating in |
| `actions` | GitHub Actions workflows and CI/CD operations |
| `code_security` | Code security related tools, such as GitHub Code Scanning |
| `dependabot` | Dependabot tools |
| `discussions` | GitHub Discussions related tools |
| `experiments` | Experimental features that are not considered stable yet |
| `gists` | GitHub Gist related tools |
| `issues` | GitHub Issues related tools |
| `labels` | GitHub Labels related tools |
| `notifications` | GitHub Notifications related tools |
| `orgs` | GitHub Organization related tools |
| `projects` | GitHub Projects related tools |
| `pull_requests` | GitHub Pull Request related tools |
| `repos` | GitHub Repository related tools |
| `secret_protection` | Secret protection related tools, such as GitHub Secret Scanning |
| `security_advisories` | Security advisories related tools |
| `stargazers` | GitHub Stargazers related tools |
| `users` | GitHub User related tools |
&lt;!-- END AUTOMATED TOOLSETS --&gt;

### Additional Toolsets in Remote Github MCP Server

| Toolset                 | Description                                                   |
| ----------------------- | ------------------------------------------------------------- |
| `copilot` | Copilot related tools (e.g. Copilot Coding Agent) |
| `copilot_spaces` | Copilot Spaces related tools |
| `github_support_docs_search` | Search docs to answer GitHub product and support questions |

## Tools

&lt;!-- START AUTOMATED TOOLS --&gt;
&lt;details&gt;

&lt;summary&gt;Actions&lt;/summary&gt;

- **cancel_workflow_run** - Cancel workflow run
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **delete_workflow_run_logs** - Delete workflow logs
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **download_workflow_run_artifact** - Download workflow artifact
  - `artifact_id`: The unique identifier of the artifact (number, required)
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)

- **get_job_logs** - Get job logs
  - `failed_only`: When true, gets logs for all failed jobs in run_id (boolean, optional)
  - `job_id`: The unique identifier of the workflow job (required for single job logs) (number, optional)
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `return_content`: Returns actual log content instead of URLs (boolean, optional)
  - `run_id`: Workflow run ID (required when using failed_only) (number, optional)
  - `tail_lines`: Number of lines to return from the end of the log (number, optional)

- **get_workflow_run** - Get workflow run
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **get_workflow_run_logs** - Get workflow run logs
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **get_workflow_run_usage** - Get workflow usage
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **list_workflow_jobs** - List workflow jobs
  - `filter`

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[sjzar/chatlog]]></title>
            <link>https://github.com/sjzar/chatlog</link>
            <guid>https://github.com/sjzar/chatlog</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[chat log tool, easily use your own chat data. 聊天记录工具，轻松使用自己的聊天数据]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sjzar/chatlog">sjzar/chatlog</a></h1>
            <p>chat log tool, easily use your own chat data. 聊天记录工具，轻松使用自己的聊天数据</p>
            <p>Language: Go</p>
            <p>Stars: 8,952</p>
            <p>Forks: 1,274</p>
            <p>Stars today: 80 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![chatlog](https://github.com/user-attachments/assets/e085d3a2-e009-4463-b2fd-8bd7df2b50c3)

_聊天记录工具，帮助大家轻松使用自己的聊天数据_

[![ImgMCP](https://cdn.imgmcp.com/imgmcp-logo-small.png)](https://imgmcp.com)

[![Go Report Card](https://goreportcard.com/badge/github.com/sjzar/chatlog)](https://goreportcard.com/report/github.com/sjzar/chatlog)
[![GoDoc](https://godoc.org/github.com/sjzar/chatlog?status.svg)](https://godoc.org/github.com/sjzar/chatlog)
[![GitHub release](https://img.shields.io/github/release/sjzar/chatlog.svg)](https://github.com/sjzar/chatlog/releases)
[![GitHub license](https://img.shields.io/github/license/sjzar/chatlog.svg)](https://github.com/sjzar/chatlog/blob/main/LICENSE)


&lt;/div&gt;

## Feature

- 从本地数据库文件中获取聊天数据
- 支持 Windows / macOS 系统，兼容微信 3.x / 4.x 版本
- 支持获取数据与图片密钥 (Windows &lt; 4.0.3.36 / macOS &lt; 4.0.3.80)
- 支持图片、语音等多媒体数据解密，支持 wxgf 格式解析
- 支持自动解密数据库，并提供新消息 Webhook 回调
- 提供 Terminal UI 界面，同时支持命令行工具和 Docker 镜像部署
- 提供 HTTP API 服务，可轻松查询聊天记录、联系人、群聊、最近会话等信息
- 支持 MCP Streamable HTTP 协议，可与 AI 助手无缝集成
- 支持多账号管理，可在不同账号间切换

## Quick Start

### 基本步骤

1. **安装 Chatlog**：[下载预编译版本](#下载预编译版本) 或 [使用 Go 安装](#从源码安装)
2. **运行程序**：执行 `chatlog` 启动 Terminal UI 界面
3. **解密数据**：选择 `解密数据` 菜单项
4. **开启 HTTP 服务**：选择 `开启 HTTP 服务` 菜单项
5. **访问数据**：通过 [HTTP API](#http-api) 或 [MCP 集成](#mcp-集成) 访问聊天记录

&gt; 💡 **提示**: 如果电脑端微信聊天记录不全，可以[从手机端迁移数据](#从手机迁移聊天记录)  

### 常见问题快速解决

- **macOS 用户**：获取密钥前需[临时关闭 SIP](#macos-版本说明)
- **Windows 用户**：遇到界面显示问题请[使用 Windows Terminal](#windows-版本说明)
- **集成 AI 助手**：查看 [MCP 集成指南](#mcp-集成)
- **无法获取密钥**：查看 [FAQ](https://github.com/sjzar/chatlog/issues/197)

## 安装指南

### 从源码安装

```bash
go install github.com/sjzar/chatlog@latest
```

&gt; 💡 **提示**: 部分功能有 cgo 依赖，编译前需确认本地有 C 编译环境。

### 下载预编译版本

访问 [Releases](https://github.com/sjzar/chatlog/releases) 页面下载适合您系统的预编译版本。

## 使用指南

### Terminal UI 模式

最简单的使用方式是通过 Terminal UI 界面操作：

```bash
chatlog
```

操作方法：
- 使用 `↑` `↓` 键选择菜单项
- 按 `Enter` 确认选择
- 按 `Esc` 返回上级菜单
- 按 `Ctrl+C` 退出程序

### 命令行模式

对于熟悉命令行的用户，可以直接使用以下命令：

```bash
# 获取微信数据密钥
chatlog key

# 解密数据库文件
chatlog decrypt

# 启动 HTTP 服务
chatlog server
```

### Docker 部署

由于 Docker 部署时，程序运行环境与宿主机隔离，所以不支持获取密钥等操作，需要提前获取密钥数据。

一般用于 NAS 等设备部署，详细指南可参考 [Docker 部署指南](docs/docker.md)

**0. 获取密钥信息**

```shell
# 从本机运行 chatlog 获取密钥信息
$ chatlog key
Data Key: [c0163e***ac3dc6]
Image Key: [38636***653361]
```

**1. 拉取镜像**

chatlog 提供了两个镜像源：

**Docker Hub**:
```shell
docker pull sjzar/chatlog:latest
```

**GitHub Container Registry (ghcr)**:
```shell
docker pull ghcr.io/sjzar/chatlog:latest
```

&gt; 💡 **镜像地址**: 
&gt; - Docker Hub: https://hub.docker.com/r/sjzar/chatlog
&gt; - GitHub Container Registry: https://ghcr.io/sjzar/chatlog

**2. 运行容器**

```shell
$ docker run -d \
  --name chatlog \
  -p 5030:5030 \
  -v /path/to/your/wechat/data:/app/data \
  sjzar/chatlog:latest
```

### 从手机迁移聊天记录

如果电脑端微信聊天记录不全，可以从手机端迁移数据：

1. 打开手机微信，进入 `我 - 设置 - 通用 - 聊天记录迁移与备份`
2. 选择 `迁移 - 迁移到电脑`，按照提示操作
3. 完成迁移后，重新运行 `chatlog` 获取密钥并解密数据

&gt; 此操作不会影响手机上的聊天记录，只是将数据复制到电脑端

## 平台特定说明

### Windows 版本说明

如遇到界面显示异常（如花屏、乱码等），请使用 [Windows Terminal](https://github.com/microsoft/terminal) 运行程序

### macOS 版本说明

macOS 用户在获取密钥前需要临时关闭 SIP（系统完整性保护）：

1. **关闭 SIP**：
   ```shell
   # 进入恢复模式
   # Intel Mac: 重启时按住 Command + R
   # Apple Silicon: 重启时长按电源键
   
   # 在恢复模式中打开终端并执行
   csrutil disable
   
   # 重启系统
   ```

2. **安装必要工具**：
   ```shell
   # 安装 Xcode Command Line Tools
   xcode-select --install
   ```

3. **获取密钥后**：可以重新启用 SIP（`csrutil enable`），不影响后续使用

&gt; Apple Silicon 用户注意：确保微信、chatlog 和终端都不在 Rosetta 模式下运行

## HTTP API

启动 HTTP 服务后（默认地址 `http://127.0.0.1:5030`），可通过以下 API 访问数据：

### 聊天记录查询

```
GET /api/v1/chatlog?time=2023-01-01&amp;talker=wxid_xxx
```

参数说明：
- `time`: 时间范围，格式为 `YYYY-MM-DD` 或 `YYYY-MM-DD~YYYY-MM-DD`
- `talker`: 聊天对象标识（支持 wxid、群聊 ID、备注名、昵称等）
- `limit`: 返回记录数量
- `offset`: 分页偏移量
- `format`: 输出格式，支持 `json`、`csv` 或纯文本

### 其他 API 接口

- **联系人列表**：`GET /api/v1/contact`
- **群聊列表**：`GET /api/v1/chatroom`
- **会话列表**：`GET /api/v1/session`

### 多媒体内容

聊天记录中的多媒体内容会通过 HTTP 服务进行提供，可通过以下路径访问：

- **图片内容**：`GET /image/&lt;id&gt;`
- **视频内容**：`GET /video/&lt;id&gt;`
- **文件内容**：`GET /file/&lt;id&gt;`
- **语音内容**：`GET /voice/&lt;id&gt;`
- **多媒体内容**：`GET /data/&lt;data dir relative path&gt;`

当请求图片、视频、文件内容时，将返回 302 跳转到多媒体内容 URL。  
当请求语音内容时，将直接返回语音内容，并对原始 SILK 语音做了实时转码 MP3 处理。  
多媒体内容 URL 地址为基于`数据目录`的相对地址，请求多媒体内容将直接返回对应文件，并针对加密图片做了实时解密处理。

## Webhook

需开启自动解密功能，当收到特定新消息时，可以通过 HTTP POST 请求将消息推送到指定的 URL。

&gt; 延迟测试: 本地服务消息回调延迟约 13 秒; 远程同步消息回调延迟约 45 秒。

#### 0. 回调配置

使用 TUI 模式的话，在 `$HOME/.chatlog/chatlog.json` 配置文件中，新增 `webhook` 配置。  
（Windows 用户的配置文件在 `%USERPROFILE%/.chatlog/chatlog.json`)

```json
{
  &quot;history&quot;: [],
  &quot;last_account&quot;: &quot;wxuser_x&quot;,
  &quot;webhook&quot;: {
    &quot;host&quot;: &quot;localhost:5030&quot;,                   # 消息中的图片、文件等 URL host
    &quot;items&quot;: [
      {
        &quot;url&quot;: &quot;http://localhost:8080/webhook&quot;, # 必填，webhook 请求的URL，可配置为 n8n 等 webhook 入口 
        &quot;talker&quot;: &quot;wxid_123&quot;,                   # 必填，需要监控的私聊、群聊名称
        &quot;sender&quot;: &quot;&quot;,                           # 选填，消息发送者
        &quot;keyword&quot;: &quot;&quot;                           # 选填，关键词
      }
    ]
  }
}
```

使用 server 模式的话，可以通过 `CHATLOG_WEBHOOK` 环境变量进行设置。

```shell
# 方案 1
CHATLOG_WEBHOOK=&#039;{&quot;host&quot;:&quot;localhost:5030&quot;,&quot;items&quot;:[{&quot;url&quot;:&quot;http://localhost:8080/proxy&quot;,&quot;talker&quot;:&quot;wxid_123&quot;,&quot;sender&quot;:&quot;&quot;,&quot;keyword&quot;:&quot;&quot;}]}&#039;

# 方案 2（任选一种）
CHATLOG_WEBHOOK_HOST=&quot;localhost:5030&quot;
CHATLOG_WEBHOOK_ITEMS=&#039;[{&quot;url&quot;:&quot;http://localhost:8080/proxy&quot;,&quot;talker&quot;:&quot;wxid_123&quot;,&quot;sender&quot;:&quot;&quot;,&quot;keyword&quot;:&quot;&quot;}]&#039;
```

#### 1. 测试效果

启动 chatlog 并开启自动解密功能，测试回调效果

```shell
POST /webhook HTTP/1.1
Host: localhost:8080
Accept-Encoding: gzip
Content-Length: 386
Content-Type: application/json
User-Agent: Go-http-client/1.1

Body:
{
  &quot;keyword&quot;: &quot;&quot;,
  &quot;lastTime&quot;: &quot;2025-08-27 00:00:00&quot;,
  &quot;length&quot;: 1,
  &quot;messages&quot;: [
    {
      &quot;seq&quot;: 1756225000000,
      &quot;time&quot;: &quot;2025-08-27T00:00:00+08:00&quot;,
      &quot;talker&quot;: &quot;wxid_123&quot;,
      &quot;talkerName&quot;: &quot;&quot;,
      &quot;isChatRoom&quot;: false,
      &quot;sender&quot;: &quot;wxid_123&quot;,
      &quot;senderName&quot;: &quot;Name&quot;,
      &quot;isSelf&quot;: false,
      &quot;type&quot;: 1,
      &quot;subType&quot;: 0,
      &quot;content&quot;: &quot;测试消息&quot;,
      &quot;contents&quot;: {
        &quot;host&quot;: &quot;localhost:5030&quot;
      }
    }
  ],
  &quot;sender&quot;: &quot;&quot;,
  &quot;talker&quot;: &quot;wxid_123&quot;
}
```

## MCP 集成

Chatlog 支持 MCP (Model Context Protocol) 协议，可与支持 MCP 的 AI 助手无缝集成。  
启动 HTTP 服务后，通过 Streamable HTTP Endpoint 访问服务：

```
GET /mcp
```

### 快速集成

Chatlog 可以与多种支持 MCP 的 AI 助手集成，包括：

- **ChatWise**: 直接支持 Streamable HTTP，在工具设置中添加 `http://127.0.0.1:5030/mcp`
- **Cherry Studio**: 直接支持 Streamable HTTP，在 MCP 服务器设置中添加 `http://127.0.0.1:5030/mcp`

对于不直接支持 Streamable HTTP 的客户端，可以使用 [mcp-proxy](https://github.com/sparfenyuk/mcp-proxy) 工具转发请求：

- **Claude Desktop**: 通过 mcp-proxy 支持，需要配置 `claude_desktop_config.json`
- **Monica Code**: 通过 mcp-proxy 支持，需要配置 VSCode 插件设置

### 详细集成指南

查看 [MCP 集成指南](docs/mcp.md) 获取各平台的详细配置步骤和注意事项。

## Prompt 示例

为了帮助大家更好地利用 Chatlog 与 AI 助手，我们整理了一些 prompt 示例。希望这些 prompt 可以启发大家更有效地查询和分析聊天记录，获取更精准的信息。

查看 [Prompt 指南](docs/prompt.md) 获取详细示例。

同时欢迎大家分享使用经验和 prompt！如果您有好的 prompt 示例或使用技巧，请通过 [Discussions](https://github.com/sjzar/chatlog/discussions) 进行分享，共同进步。

## 免责声明

⚠️ **重要提示：使用本项目前，请务必阅读并理解完整的 [免责声明](./DISCLAIMER.md)。**

本项目仅供学习、研究和个人合法使用，禁止用于任何非法目的或未授权访问他人数据。下载、安装或使用本工具即表示您同意遵守免责声明中的所有条款，并自行承担使用过程中的全部风险和法律责任。

### 摘要（请阅读完整免责声明）

- 仅限处理您自己合法拥有的聊天数据或已获授权的数据
- 严禁用于未经授权获取、查看或分析他人聊天记录
- 开发者不对使用本工具可能导致的任何损失承担责任
- 使用第三方 LLM 服务时，您应遵守这些服务的使用条款和隐私政策

**本项目完全免费开源，任何以本项目名义收费的行为均与本项目无关。**

## License

本项目基于 [Apache-2.0 许可证](./LICENSE) 开源。

## 隐私政策

本项目不收集任何用户数据。所有数据处理均在用户本地设备上进行。使用第三方服务时，请参阅相应服务的隐私政策。

## Thanks

- [@0xlane](https://github.com/0xlane) 的 [wechat-dump-rs](https://github.com/0xlane/wechat-dump-rs) 项目
- [@xaoyaoo](https://github.com/xaoyaoo) 的 [PyWxDump](https://github.com/xaoyaoo/PyWxDump) 项目
- [@git-jiadong](https://github.com/git-jiadong) 的 [go-lame](https://github.com/git-jiadong/go-lame) 和 [go-silk](https://github.com/git-jiadong/go-silk) 项目
- [Anthropic](https://www.anthropic.com/) 的 [MCP]((https://github.com/modelcontextprotocol) ) 协议
- 各个 Go 开源库的贡献者们</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ollama/ollama]]></title>
            <link>https://github.com/ollama/ollama</link>
            <guid>https://github.com/ollama/ollama</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ollama/ollama">ollama/ollama</a></h1>
            <p>Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.</p>
            <p>Language: Go</p>
            <p>Stars: 154,148</p>
            <p>Forks: 13,391</p>
            <p>Stars today: 88 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://ollama.com&quot;&gt;
    &lt;img alt=&quot;ollama&quot; width=&quot;240&quot; src=&quot;https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

# Ollama

Get up and running with large language models.

### macOS

[Download](https://ollama.com/download/Ollama.dmg)

### Windows

[Download](https://ollama.com/download/OllamaSetup.exe)

### Linux

```shell
curl -fsSL https://ollama.com/install.sh | sh
```

[Manual install instructions](https://github.com/ollama/ollama/blob/main/docs/linux.md)

### Docker

The official [Ollama Docker image](https://hub.docker.com/r/ollama/ollama) `ollama/ollama` is available on Docker Hub.

### Libraries

- [ollama-python](https://github.com/ollama/ollama-python)
- [ollama-js](https://github.com/ollama/ollama-js)

### Community

- [Discord](https://discord.gg/ollama)
- [Reddit](https://reddit.com/r/ollama)

## Quickstart

To run and chat with [Gemma 3](https://ollama.com/library/gemma3):

```shell
ollama run gemma3
```

## Model library

Ollama supports a list of models available on [ollama.com/library](https://ollama.com/library &#039;ollama model library&#039;)

Here are some example models that can be downloaded:

| Model              | Parameters | Size  | Download                         |
| ------------------ | ---------- | ----- | -------------------------------- |
| Gemma 3            | 1B         | 815MB | `ollama run gemma3:1b`           |
| Gemma 3            | 4B         | 3.3GB | `ollama run gemma3`              |
| Gemma 3            | 12B        | 8.1GB | `ollama run gemma3:12b`          |
| Gemma 3            | 27B        | 17GB  | `ollama run gemma3:27b`          |
| QwQ                | 32B        | 20GB  | `ollama run qwq`                 |
| DeepSeek-R1        | 7B         | 4.7GB | `ollama run deepseek-r1`         |
| DeepSeek-R1        | 671B       | 404GB | `ollama run deepseek-r1:671b`    |
| Llama 4            | 109B       | 67GB  | `ollama run llama4:scout`        |
| Llama 4            | 400B       | 245GB | `ollama run llama4:maverick`     |
| Llama 3.3          | 70B        | 43GB  | `ollama run llama3.3`            |
| Llama 3.2          | 3B         | 2.0GB | `ollama run llama3.2`            |
| Llama 3.2          | 1B         | 1.3GB | `ollama run llama3.2:1b`         |
| Llama 3.2 Vision   | 11B        | 7.9GB | `ollama run llama3.2-vision`     |
| Llama 3.2 Vision   | 90B        | 55GB  | `ollama run llama3.2-vision:90b` |
| Llama 3.1          | 8B         | 4.7GB | `ollama run llama3.1`            |
| Llama 3.1          | 405B       | 231GB | `ollama run llama3.1:405b`       |
| Phi 4              | 14B        | 9.1GB | `ollama run phi4`                |
| Phi 4 Mini         | 3.8B       | 2.5GB | `ollama run phi4-mini`           |
| Mistral            | 7B         | 4.1GB | `ollama run mistral`             |
| Moondream 2        | 1.4B       | 829MB | `ollama run moondream`           |
| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`         |
| Starling           | 7B         | 4.1GB | `ollama run starling-lm`         |
| Code Llama         | 7B         | 3.8GB | `ollama run codellama`           |
| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored`   |
| LLaVA              | 7B         | 4.5GB | `ollama run llava`               |
| Granite-3.3         | 8B         | 4.9GB | `ollama run granite3.3`          |

&gt; [!NOTE]
&gt; You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.

## Customize a model

### Import from GGUF

Ollama supports importing GGUF models in the Modelfile:

1. Create a file named `Modelfile`, with a `FROM` instruction with the local filepath to the model you want to import.

   ```
   FROM ./vicuna-33b.Q4_0.gguf
   ```

2. Create the model in Ollama

   ```shell
   ollama create example -f Modelfile
   ```

3. Run the model

   ```shell
   ollama run example
   ```

### Import from Safetensors

See the [guide](docs/import.md) on importing models for more information.

### Customize a prompt

Models from the Ollama library can be customized with a prompt. For example, to customize the `llama3.2` model:

```shell
ollama pull llama3.2
```

Create a `Modelfile`:

```
FROM llama3.2

# set the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# set the system message
SYSTEM &quot;&quot;&quot;
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
&quot;&quot;&quot;
```

Next, create and run the model:

```
ollama create mario -f ./Modelfile
ollama run mario
&gt;&gt;&gt; hi
Hello! It&#039;s your friend Mario.
```

For more information on working with a Modelfile, see the [Modelfile](docs/modelfile.md) documentation.

## CLI Reference

### Create a model

`ollama create` is used to create a model from a Modelfile.

```shell
ollama create mymodel -f ./Modelfile
```

### Pull a model

```shell
ollama pull llama3.2
```

&gt; This command can also be used to update a local model. Only the diff will be pulled.

### Remove a model

```shell
ollama rm llama3.2
```

### Copy a model

```shell
ollama cp llama3.2 my-model
```

### Multiline input

For multiline input, you can wrap text with `&quot;&quot;&quot;`:

```
&gt;&gt;&gt; &quot;&quot;&quot;Hello,
... world!
... &quot;&quot;&quot;
I&#039;m a basic program that prints the famous &quot;Hello, world!&quot; message to the console.
```

### Multimodal models

```
ollama run llava &quot;What&#039;s in this image? /Users/jmorgan/Desktop/smile.png&quot;
```

&gt; **Output**: The image features a yellow smiley face, which is likely the central focus of the picture.

### Pass the prompt as an argument

```shell
ollama run llama3.2 &quot;Summarize this file: $(cat README.md)&quot;
```

&gt; **Output**: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.

### Show model information

```shell
ollama show llama3.2
```

### List models on your computer

```shell
ollama list
```

### List which models are currently loaded

```shell
ollama ps
```

### Stop a model which is currently running

```shell
ollama stop llama3.2
```

### Start Ollama

`ollama serve` is used when you want to start ollama without running the desktop application.

## Building

See the [developer guide](https://github.com/ollama/ollama/blob/main/docs/development.md)

### Running local builds

Next, start the server:

```shell
./ollama serve
```

Finally, in a separate shell, run a model:

```shell
./ollama run llama3.2
```

## REST API

Ollama has a REST API for running and managing models.

### Generate a response

```shell
curl http://localhost:11434/api/generate -d &#039;{
  &quot;model&quot;: &quot;llama3.2&quot;,
  &quot;prompt&quot;:&quot;Why is the sky blue?&quot;
}&#039;
```

### Chat with a model

```shell
curl http://localhost:11434/api/chat -d &#039;{
  &quot;model&quot;: &quot;llama3.2&quot;,
  &quot;messages&quot;: [
    { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;why is the sky blue?&quot; }
  ]
}&#039;
```

See the [API documentation](./docs/api.md) for all endpoints.

## Community Integrations

### Web &amp; Desktop

- [Open WebUI](https://github.com/open-webui/open-webui)
- [SwiftChat (macOS with ReactNative)](https://github.com/aws-samples/swift-chat)
- [Enchanted (macOS native)](https://github.com/AugustDev/enchanted)
- [Hollama](https://github.com/fmaclen/hollama)
- [Lollms-Webui](https://github.com/ParisNeo/lollms-webui)
- [LibreChat](https://github.com/danny-avila/LibreChat)
- [Bionic GPT](https://github.com/bionic-gpt/bionic-gpt)
- [HTML UI](https://github.com/rtcfirefly/ollama-ui)
- [Saddle](https://github.com/jikkuatwork/saddle)
- [TagSpaces](https://www.tagspaces.org) (A platform for file-based apps, [utilizing Ollama](https://docs.tagspaces.org/ai/) for the generation of tags and descriptions)
- [Chatbot UI](https://github.com/ivanfioravanti/chatbot-ollama)
- [Chatbot UI v2](https://github.com/mckaywrigley/chatbot-ui)
- [Typescript UI](https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file)
- [Minimalistic React UI for Ollama Models](https://github.com/richawo/minimal-llm-ui)
- [Ollamac](https://github.com/kevinhermawan/Ollamac)
- [big-AGI](https://github.com/enricoros/big-AGI)
- [Cheshire Cat assistant framework](https://github.com/cheshire-cat-ai/core)
- [Amica](https://github.com/semperai/amica)
- [chatd](https://github.com/BruceMacD/chatd)
- [Ollama-SwiftUI](https://github.com/kghandour/Ollama-SwiftUI)
- [Dify.AI](https://github.com/langgenius/dify)
- [MindMac](https://mindmac.app)
- [NextJS Web Interface for Ollama](https://github.com/jakobhoeg/nextjs-ollama-llm-ui)
- [Msty](https://msty.app)
- [Chatbox](https://github.com/Bin-Huang/Chatbox)
- [WinForm Ollama Copilot](https://github.com/tgraupmann/WinForm_Ollama_Copilot)
- [NextChat](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web) with [Get Started Doc](https://docs.nextchat.dev/models/ollama)
- [Alpaca WebUI](https://github.com/mmo80/alpaca-webui)
- [OllamaGUI](https://github.com/enoch1118/ollamaGUI)
- [OpenAOE](https://github.com/InternLM/OpenAOE)
- [Odin Runes](https://github.com/leonid20000/OdinRunes)
- [LLM-X](https://github.com/mrdjohnson/llm-x) (Progressive Web App)
- [AnythingLLM (Docker + MacOs/Windows/Linux native app)](https://github.com/Mintplex-Labs/anything-llm)
- [Ollama Basic Chat: Uses HyperDiv Reactive UI](https://github.com/rapidarchitect/ollama_basic_chat)
- [Ollama-chats RPG](https://github.com/drazdra/ollama-chats)
- [IntelliBar](https://intellibar.app/) (AI-powered assistant for macOS)
- [Jirapt](https://github.com/AliAhmedNada/jirapt) (Jira Integration to generate issues, tasks, epics)
- [ojira](https://github.com/AliAhmedNada/ojira) (Jira chrome plugin to easily generate descriptions for tasks)
- [QA-Pilot](https://github.com/reid41/QA-Pilot) (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)
- [ChatOllama](https://github.com/sugarforever/chat-ollama) (Open Source Chatbot based on Ollama with Knowledge Bases)
- [CRAG Ollama Chat](https://github.com/Nagi-ovo/CRAG-Ollama-Chat) (Simple Web Search with Corrective RAG)
- [RAGFlow](https://github.com/infiniflow/ragflow) (Open-source Retrieval-Augmented Generation engine based on deep document understanding)
- [StreamDeploy](https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold) (LLM Application Scaffold)
- [chat](https://github.com/swuecho/chat) (chat web app for teams)
- [Lobe Chat](https://github.com/lobehub/lobe-chat) with [Integrating Doc](https://lobehub.com/docs/self-hosting/examples/ollama)
- [Ollama RAG Chatbot](https://github.com/datvodinh/rag-chatbot.git) (Local Chat with multiple PDFs using Ollama and RAG)
- [BrainSoup](https://www.nurgo-software.com/products/brainsoup) (Flexible native client with RAG &amp; multi-agent automation)
- [macai](https://github.com/Renset/macai) (macOS client for Ollama, ChatGPT, and other compatible API back-ends)
- [RWKV-Runner](https://github.com/josStorer/RWKV-Runner) (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)
- [Ollama Grid Search](https://github.com/dezoito/ollama-grid-search) (app to evaluate and compare models)
- [Olpaka](https://github.com/Otacon/olpaka) (User-friendly Flutter Web App for Ollama)
- [Casibase](https://casibase.org) (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)
- [OllamaSpring](https://github.com/CrazyNeil/OllamaSpring) (Ollama Client for macOS)
- [LLocal.in](https://github.com/kartikm7/llocal) (Easy to use Electron Desktop Client for Ollama)
- [Shinkai Desktop](https://github.com/dcSpark/shinkai-apps) (Two click install Local AI using Ollama + Files + RAG)
- [AiLama](https://github.com/zeyoyt/ailama) (A Discord User App that allows you to interact with Ollama anywhere in Discord)
- [Ollama with Google Mesop](https://github.com/rapidarchitect/ollama_mesop/) (Mesop Chat Client implementation with Ollama)
- [R2R](https://github.com/SciPhi-AI/R2R) (Open-source RAG engine)
- [Ollama-Kis](https://github.com/elearningshow/ollama-kis) (A simple easy-to-use GUI with sample custom LLM for Drivers Education)
- [OpenGPA](https://opengpa.org) (Open-source offline-first Enterprise Agentic Application)
- [Painting Droid](https://github.com/mateuszmigas/painting-droid) (Painting app with AI integrations)
- [Kerlig AI](https://www.kerlig.com/) (AI writing assistant for macOS)
- [AI Studio](https://github.com/MindWorkAI/AI-Studio)
- [Sidellama](https://github.com/gyopak/sidellama) (browser-based LLM client)
- [LLMStack](https://github.com/trypromptly/LLMStack) (No-code multi-agent framework to build LLM agents and workflows)
- [BoltAI for Mac](https://boltai.com) (AI Chat Client for Mac)
- [Harbor](https://github.com/av/harbor) (Containerized LLM Toolkit with Ollama as default backend)
- [PyGPT](https://github.com/szczyglis-dev/py-gpt) (AI desktop assistant for Linux, Windows, and Mac)
- [Alpaca](https://github.com/Jeffser/Alpaca) (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)
- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT/blob/master/docs/content/platform/ollama.md) (AutoGPT Ollama integration)
- [Go-CREW](https://www.jonathanhecl.com/go-crew/) (Powerful Offline RAG in Golang)
- [PartCAD](https://github.com/openvmp/partcad/) (CAD model generation with OpenSCAD and CadQuery)
- [Ollama4j Web UI](https://github.com/ollama4j/ollama4j-web-ui) - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j
- [PyOllaMx](https://github.com/kspviswa/pyOllaMx) - macOS application capable of chatting with both Ollama and Apple MLX models.
- [Cline](https://github.com/cline/cline) - Formerly known as Claude Dev is a VSCode extension for multi-file/whole-repo coding
- [Cherry Studio](https://github.com/kangfenmao/cherry-studio) (Desktop client with Ollama support)
- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)
- [Archyve](https://github.com/nickthecook/archyve) (RAG-enabling document library)
- [crewAI with Mesop](https://github.com/rapidarchitect/ollama-crew-mesop) (Mesop Web Interface to run crewAI with Ollama)
- [Tkinter-based client](https://github.com/chyok/ollama-gui) (Python tkinter-based Client for Ollama)
- [LLMChat](https://github.com/trendy-design/llmchat) (Privacy focused, 100% local, intuitive all-in-one chat interface)
- [Local Multimodal AI Chat](https://github.com/Leon-Sander/Local-Multimodal-AI-Chat) (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)
- [ARGO](https://github.com/xark-argo/argo) (Locally download and run Ollama and Huggingface models with RAG and deep research on Mac/Windows/Linux)
- [OrionChat](https://github.com/EliasPereirah/OrionChat) - OrionChat is a web interface for chatting with different AI providers
- [G1](https://github.com/bklieger-groq/g1) (Prototype of using prompting strategies to improve the LLM&#039;s reasoning through o1-like reasoning chains.)
- [Web management](https://github.com/lemonit-eric-mao/ollama-web-management) (Web management page)
- [Promptery](https://github.com/promptery/promptery) (desktop client for Ollama.)
- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)
- [chat-ollama](https://github.com/annilq/chat-ollama) (a React Native client for Ollama)
- [SpaceLlama](https://github.com/tcsenpai/spacellama) (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)
- [YouLama](https://github.com/tcsenpai/youlama) (Webapp to quickly summarize any YouTube video, supporting Invidious as well)
- [DualMind](https://github.com/tcsenpai/dualmind) (Experimental app allowing two models to talk to each other in the terminal or in a web interface)
- [ollamarama-matrix](https://github.com/h1ddenpr0cess20/ollamarama-matrix) (Ollama chatbot for the Matrix chat protocol)
- [ollama-chat-app](https://github.com/anan1213095357/ollama-chat-app) (Flutter-based chat app)
- [Perfect Memory AI](https://www.perfectmemory.ai/) (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)
- [Hexabot](https://github.com/hexastack/hexabot) (A conversational AI builder)
- [Reddit Rate](https://github.com/rapidarchitect/reddit_analyzer) (Search and Rate Reddit topics with a weighted summation)
- [OpenTalkGpt](https://github.com/adarshM84/OpenTalkGpt) (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)
- [VT](https://github.com/vinhnx/vt.ai) (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)
- [Nosia](https://github.com/nosia-ai/nosia) (Easy to install and use RAG platform based on Ollama)
- [Witsy](https://github.com/nbonamy/witsy) (An AI Desktop application available for Mac/Windows/Linux)
- [Abbey](https://github.com/US-Artificial-Intelligence/abbey) (A configurable AI interface server with notebooks, document storage, and YouTube support)
- [Minima](https://github.com/dmayboroda/minima) (RAG with on-premises or fully local workflow)
- [aidful-ollama-model-delete](https://github.com/AidfulAI/aidful-ollama-model-delete) (User interface for simplified model cleanup)
- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) (An AI-powered search engine &amp; an open-source alternative to Perplexity AI)
- [Ollama Chat WebUI for Docker ](https://github.com/oslook/ollama-webui) (Support for local docker deployment, lightweight ollama webui)
- [AI Toolkit for Visual Studio Code](https://aka.ms/ai-tooklit/ollama-docs) (Microsoft-official VSCode extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)
- [MinimalNextOllamaChat](https://github.com/anilkay/MinimalNextOllamaChat) (Minimal Web UI for Chat and Model Control)
- [Chipper](https://github.com/TilmanGriesel/chipper) AI interface for tinkerers (Ollama, Haystack RAG, Python)
- [ChibiChat](https://github.com/CosmicEventHorizon/ChibiChat) (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)
- [LocalLLM](https://github.com/qusaismael/localllm) (Minimal Web-App to run ollama models on it with a GUI)
- [Ollamazing](https://github.com/buiducnhat/ollamazing) (Web extension to run Ollama models)
- [OpenDeepResearcher-via-searxng](https://github.com/benhaotang/OpenDeepResearcher-via-searxng) (A Deep Research equivalent endpoint with Ollama support for running locally)
- [AntSK](https://github.com/AIDotNet/AntSK) (Out-of-the-box &amp; Adaptable RAG Chatbot)
- [MaxKB](https://github.com/1Panel-dev/MaxKB/) (Ready-to-use &amp; flexible RAG Chatbot)
- [yla](https://github.com/danielekp/yla) (Web interface to freely interact with your customized models)
- [LangBot](https://github.com/RockChinQ/LangBot) (LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)
- [1Panel](https://github.com/1Panel-dev/1Panel/) (Web-based Linux Server Management Tool)
- [AstrBot](https://github.com/Soulter/AstrBot/) (User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)
- [Reins](https://github.com/ibrahimcetin/reins) (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)
- [Flufy](https://github.com/Aharon-Bensadoun/Flufy) (A beautiful chat interface for interacting with Ollama&#039;s API. Built with React, TypeScript, and Material-UI.)
- [Ellama](https://github.com/zeozeozeo/ellama) (Friendly native app to chat with an Ollama instance)
- [screenpipe](https://github.com/mediar-ai/screenpipe) Build agents powered by your screen history
- [Ollamb](https://github.com/heng

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hashicorp/terraform]]></title>
            <link>https://github.com/hashicorp/terraform</link>
            <guid>https://github.com/hashicorp/terraform</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[Terraform enables you to safely and predictably create, change, and improve infrastructure. It is a source-available tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hashicorp/terraform">hashicorp/terraform</a></h1>
            <p>Terraform enables you to safely and predictably create, change, and improve infrastructure. It is a source-available tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.</p>
            <p>Language: Go</p>
            <p>Stars: 46,769</p>
            <p>Forks: 10,061</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># Terraform

- Website: https://developer.hashicorp.com/terraform
- Forums: [HashiCorp Discuss](https://discuss.hashicorp.com/c/terraform-core)
- Documentation: [https://developer.hashicorp.com/terraform/docs](https://developer.hashicorp.com/terraform/docs)
- Tutorials: [HashiCorp&#039;s Learn Platform](https://developer.hashicorp.com/terraform/tutorials)
- Certification Exam: [HashiCorp Certified: Terraform Associate](https://www.hashicorp.com/certification/#hashicorp-certified-terraform-associate)

&lt;img alt=&quot;Terraform&quot; src=&quot;https://www.datocms-assets.com/2885/1731373310-terraform_white.svg&quot; width=&quot;600px&quot;&gt;

Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions.

The key features of Terraform are:

- **Infrastructure as Code**: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.

- **Execution Plans**: Terraform has a &quot;planning&quot; step where it generates an execution plan. The execution plan shows what Terraform will do when you call apply. This lets you avoid any surprises when Terraform manipulates infrastructure.

- **Resource Graph**: Terraform builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, Terraform builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.

- **Change Automation**: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what Terraform will change and in what order, avoiding many possible human errors.

For more information, refer to the [What is Terraform?](https://www.terraform.io/intro) page on the Terraform website.

## Getting Started &amp; Documentation

Documentation is available on the [Terraform website](https://developer.hashicorp.com/terraform):

- [Introduction](https://developer.hashicorp.com/terraform/intro)
- [Documentation](https://developer.hashicorp.com/terraform/docs)

If you&#039;re new to Terraform and want to get started creating infrastructure, please check out our [Getting Started guides](https://learn.hashicorp.com/terraform#getting-started) on HashiCorp&#039;s learning platform. There are also [additional guides](https://learn.hashicorp.com/terraform#operations-and-development) to continue your learning.

Show off your Terraform knowledge by passing a certification exam. Visit the [certification page](https://www.hashicorp.com/certification/) for information about exams and find [study materials](https://learn.hashicorp.com/terraform/certification/terraform-associate) on HashiCorp&#039;s learning platform.

## Developing Terraform

This repository contains only Terraform core, which includes the command line interface and the main graph engine. Providers are implemented as plugins, and Terraform can automatically download providers that are published on [the Terraform Registry](https://registry.terraform.io). HashiCorp develops some providers, and others are developed by other organizations. For more information, refer to [Plugin development](https://developer.hashicorp.com/terraform/plugin).

- To learn more about compiling Terraform and contributing suggested changes, refer to [the contributing guide](.github/CONTRIBUTING.md).

- To learn more about how we handle bug reports, refer to the [bug triage guide](./BUGPROCESS.md).

- To learn how to contribute to the Terraform documentation, refer to the [Web Unified Docs repository](https://github.com/hashicorp/web-unified-docs).

## License

[Business Source License 1.1](https://github.com/hashicorp/terraform/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes-sigs/kind]]></title>
            <link>https://github.com/kubernetes-sigs/kind</link>
            <guid>https://github.com/kubernetes-sigs/kind</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Kubernetes IN Docker - local clusters for testing Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes-sigs/kind">kubernetes-sigs/kind</a></h1>
            <p>Kubernetes IN Docker - local clusters for testing Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 14,635</p>
            <p>Forks: 1,667</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img alt=&quot;kind&quot; src=&quot;./logo/logo.png&quot; width=&quot;300px&quot; /&gt;&lt;/p&gt;

# Please see [Our Documentation](https://kind.sigs.k8s.io/docs/user/quick-start/) for more in-depth installation etc.

kind is a tool for running local Kubernetes clusters using Docker container &quot;nodes&quot;.
kind was primarily designed for testing Kubernetes itself, but may be used for local development or CI.

If you have [go] 1.16+ and [docker], [podman] or [nerdctl] installed `go install sigs.k8s.io/kind@v0.30.0 &amp;&amp; kind create cluster` is all you need!

![](site/static/images/kind-create-cluster.png)

kind consists of:
- Go [packages][packages] implementing [cluster creation][cluster package], [image build][build package], etc.
- A command line interface ([`kind`][kind cli]) built on these packages.
- Docker [image(s)][images] written to run systemd, Kubernetes, etc.
- [`kubetest`][kubetest] integration also built on these packages (WIP)

kind bootstraps each &quot;node&quot; with [kubeadm][kubeadm]. For more details see [the design documentation][design doc].

**NOTE**: kind is still a work in progress, see the [1.0 roadmap].

## Installation and usage

For a complete [install guide] see [the documentation here][install guide].

You can install kind with `go install sigs.k8s.io/kind@v0.30.0`.

**NOTE**: please use the latest go to do this. KIND is developed with the latest stable go, see [`.go-version`](./.go-version) for the exact version we&#039;re using.

This will put `kind` in `$(go env GOPATH)/bin`. If you encounter the error
`kind: command not found` after installation then you may need to either add that directory to your `$PATH` as
shown [here](https://golang.org/doc/code.html#GOPATH) or do a manual installation by cloning the repo and run
`make build` from the repository.

Without installing go, kind can be built reproducibly with docker using `make build`.

Stable binaries are also available on the [releases] page. Stable releases are
generally recommended for CI usage in particular.
To install, download the binary for your platform from &quot;Assets&quot; and place this
into your `$PATH`:

On Linux:

```console
# For AMD64 / x86_64
[ $(uname -m) = x86_64 ] &amp;&amp; curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.30.0/kind-$(uname)-amd64
# For ARM64
[ $(uname -m) = aarch64 ] &amp;&amp; curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.30.0/kind-$(uname)-arm64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind
```

On macOS via Homebrew:

```console
brew install kind
```

On macOS via MacPorts:

```console
sudo port selfupdate &amp;&amp; sudo port install kind
```

On macOS via Bash:

```console
# For Intel Macs
[ $(uname -m) = x86_64 ] &amp;&amp; curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.30.0/kind-darwin-amd64
# For M1 / ARM Macs
[ $(uname -m) = arm64 ] &amp;&amp; curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.30.0/kind-darwin-arm64
chmod +x ./kind
mv ./kind /some-dir-in-your-PATH/kind
```

On Windows:

```powershell
curl.exe -Lo kind-windows-amd64.exe https://kind.sigs.k8s.io/dl/v0.30.0/kind-windows-amd64
Move-Item .\kind-windows-amd64.exe c:\some-dir-in-your-PATH\kind.exe

# OR via Chocolatey (https://chocolatey.org/packages/kind)
choco install kind
```

To use kind, you will need to [install docker].
Once you have docker running you can create a cluster with:

```console
kind create cluster
```

To delete your cluster use:

```console
kind delete cluster
```

&lt;!--TODO(bentheelder): improve this part of the guide--&gt;
To create a cluster from Kubernetes source:
- ensure that Kubernetes is cloned in `$(go env GOPATH)/src/k8s.io/kubernetes`
- build a node image and create a cluster with:
```console
kind build node-image
kind create cluster --image kindest/node:latest
```

Multi-node clusters and other advanced features may be configured with a config
file, for more usage see [the docs][user guide] or run `kind [command] --help`

## Community

Please reach out for bugs, feature requests, and other issues!
The maintainers of this project are reachable via:

- [Kubernetes Slack] in the [#kind] channel
- [filing an issue] against this repo
- The Kubernetes [SIG-Testing Mailing List]

Current maintainers are [@aojea], [@BenTheElder], and [@stmcginnis] - feel free to
reach out if you have any questions!

Pull Requests are very welcome!
If you&#039;re planning a new feature, please file an issue to discuss first.

Check the [issue tracker] for `help wanted` issues if you&#039;re unsure where to
start, or feel free to reach out to discuss. 🙂

See also: our own [contributor guide] and the Kubernetes [community page].

## Why kind?

- kind supports multi-node (including HA) clusters
- kind supports building Kubernetes release builds from source
  - support for make / bash or docker, in addition to pre-published builds
- kind supports Linux, macOS and Windows
- kind is a [CNCF certified conformant Kubernetes installer](https://landscape.cncf.io/?selected=kind)

### Code of conduct

Participation in the Kubernetes community is governed by the [Kubernetes Code of Conduct].

&lt;!--links--&gt;
[go]: https://golang.org/
[go-supported]: https://golang.org/doc/devel/release.html#policy
[docker]: https://www.docker.com/
[podman]: https://podman.io/
[nerdctl]: https://github.com/containerd/nerdctl
[community page]: https://kubernetes.io/community/
[Kubernetes Code of Conduct]: code-of-conduct.md
[Go Report Card Badge]: https://goreportcard.com/badge/sigs.k8s.io/kind
[Go Report Card]: https://goreportcard.com/report/sigs.k8s.io/kind
[conformance tests]: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/conformance-tests.md
[packages]: ./pkg
[cluster package]: ./pkg/cluster
[build package]: ./pkg/build
[kind cli]: ./main.go
[images]: ./images
[kubetest]: https://github.com/kubernetes/test-infra/tree/master/kubetest
[kubeadm]: https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/
[design doc]: https://kind.sigs.k8s.io/docs/design/initial
[user guide]: https://kind.sigs.k8s.io/docs/user/quick-start
[SIG-Testing Mailing List]: https://groups.google.com/forum/#!forum/kubernetes-sig-testing
[issue tracker]: https://github.com/kubernetes-sigs/kind/issues
[filing an issue]: https://github.com/kubernetes-sigs/kind/issues/new
[Kubernetes Slack]: http://slack.k8s.io/
[#kind]: https://kubernetes.slack.com/messages/CEKK1KTN2/
[1.0 roadmap]: https://kind.sigs.k8s.io/docs/contributing/1.0-roadmap
[install docker]: https://docs.docker.com/install/
[@BenTheElder]: https://github.com/BenTheElder
[@munnerz]: https://github.com/munnerz
[@aojea]: https://github.com/aojea
[@amwat]: https://github.com/amwat
[@stmcginnis]: https://github.com/stmcginnis
[contributor guide]: https://kind.sigs.k8s.io/docs/contributing/getting-started
[releases]: https://github.com/kubernetes-sigs/kind/releases
[install guide]: https://kind.sigs.k8s.io/docs/user/quick-start/#installation
[modules]: https://github.com/golang/go/wiki/Modules
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes-sigs/kustomize]]></title>
            <link>https://github.com/kubernetes-sigs/kustomize</link>
            <guid>https://github.com/kubernetes-sigs/kustomize</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[Customization of kubernetes YAML configurations]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes-sigs/kustomize">kubernetes-sigs/kustomize</a></h1>
            <p>Customization of kubernetes YAML configurations</p>
            <p>Language: Go</p>
            <p>Stars: 11,736</p>
            <p>Forks: 2,334</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># kustomize

`kustomize` lets you customize raw, template-free YAML
files for multiple purposes, leaving the original YAML
untouched and usable as is.

`kustomize` targets kubernetes; it understands and can
patch [kubernetes style] API objects.  It&#039;s like
[`make`], in that what it does is declared in a file,
and it&#039;s like [`sed`], in that it emits edited text.

This tool is sponsored by [sig-cli] ([KEP]).

 - [Installation instructions](https://kubectl.docs.kubernetes.io/installation/kustomize/)
 - [General documentation](https://kubectl.docs.kubernetes.io/references/kustomize/)
 - [Examples](examples)

[![Build Status](https://prow.k8s.io/badge.svg?jobs=kustomize-presubmit-master)](https://prow.k8s.io/job-history/kubernetes-jenkins/pr-logs/directory/kustomize-presubmit-master)
[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes-sigs/kustomize)](https://goreportcard.com/report/github.com/kubernetes-sigs/kustomize)

## kubectl integration

To find the kustomize version embedded in recent versions of kubectl, run `kubectl version`:

```sh
&gt; kubectl version --client
Client Version: v1.31.0
Kustomize Version: v5.4.2
```

The kustomize build flow at [v2.0.3] was added
to [kubectl v1.14][kubectl announcement].  The kustomize
flow in kubectl remained frozen at v2.0.3 until kubectl v1.21,
which [updated it to v4.0.5][kust-in-kubectl update]. It will
be updated on a regular basis going forward, and such updates
will be reflected in the Kubernetes release notes.

| Kubectl version | Kustomize version |
| --------------- | ----------------- |
| &lt; v1.14         | n/a               |
| v1.14-v1.20     | v2.0.3            |
| v1.21           | v4.0.5            |
| v1.22           | v4.2.0            |
| v1.23           | v4.4.1            |
| v1.24           | v4.5.4            |
| v1.25           | v4.5.7            |
| v1.26           | v4.5.7            |
| v1.27           | v5.0.1            |

[v2.0.3]: https://github.com/kubernetes-sigs/kustomize/releases/tag/v2.0.3
[#2506]: https://github.com/kubernetes-sigs/kustomize/issues/2506
[#1500]: https://github.com/kubernetes-sigs/kustomize/issues/1500
[kust-in-kubectl update]: https://github.com/kubernetes/kubernetes/blob/4d75a6238a6e330337526e0513e67d02b1940b63/CHANGELOG/CHANGELOG-1.21.md#kustomize-updates-in-kubectl

For examples and guides for using the kubectl integration please
see the [kubernetes documentation].

## Usage


### 1) Make a [kustomization] file

In some directory containing your YAML [resource]
files (deployments, services, configmaps, etc.), create a
[kustomization] file.

This file should declare those resources, and any
customization to apply to them, e.g. _add a common
label_.

```

base: kustomization + resources

kustomization.yaml                                      deployment.yaml                                                 service.yaml
+---------------------------------------------+         +-------------------------------------------------------+       +-----------------------------------+
| apiVersion: kustomize.config.k8s.io/v1beta1 |         | apiVersion: apps/v1                                   |       | apiVersion: v1                    |
| kind: Kustomization                         |         | kind: Deployment                                      |       | kind: Service                     |
| labels:                                     |         | metadata:                                             |       | metadata:                         |
| - includeSelectors: true                    |         |   name: myapp                                         |       |   name: myapp                     |
|   pairs:                                    |         | spec:                                                 |       | spec:                             |
|     app: myapp                              |         |   selector:                                           |       |   selector:                       |
| resources:                                  |         |     matchLabels:                                      |       |     app: myapp                    |
|   - deployment.yaml                         |         |       app: myapp                                      |       |   ports:                          |
|   - service.yaml                            |         |   template:                                           |       |     - port: 6060                  |
| configMapGenerator:                         |         |     metadata:                                         |       |       targetPort: 6060            |
|   - name: myapp-map                         |         |       labels:                                         |       +-----------------------------------+
|     literals:                               |         |         app: myapp                                    |
|       - KEY=value                           |         |     spec:                                             |
+---------------------------------------------+         |       containers:                                     |
                                                        |         - name: myapp                                 |
                                                        |           image: myapp                                |
                                                        |           resources:                                  |
                                                        |             limits:                                   |
                                                        |               memory: &quot;128Mi&quot;                         |
                                                        |               cpu: &quot;500m&quot;                             |
                                                        |           ports:                                      |
                                                        |             - containerPort: 6060                     |
                                                        +-------------------------------------------------------+

```

File structure:

&gt; ```
&gt; ~/someApp
&gt; ├── deployment.yaml
&gt; ├── kustomization.yaml
&gt; └── service.yaml
&gt; ```

The resources in this directory could be a fork of
someone else&#039;s configuration.  If so, you can easily
rebase from the source material to capture
improvements, because you don&#039;t modify the resources
directly.

Generate customized YAML with:

```
kustomize build ~/someApp
```

The YAML can be directly [applied] to a cluster:

&gt; ```
&gt; kustomize build ~/someApp | kubectl apply -f -
&gt; ```


### 2) Create [variants] using [overlays]

Manage traditional [variants] of a configuration - like
_development_, _staging_ and _production_ - using
[overlays] that modify a common [base].

```

overlay: kustomization + patches

kustomization.yaml                                      replica_count.yaml                      cpu_count.yaml
+-----------------------------------------------+       +-------------------------------+       +------------------------------------------+
| apiVersion: kustomize.config.k8s.io/v1beta1   |       | apiVersion: apps/v1           |       | apiVersion: apps/v1                      |
| kind: Kustomization                           |       | kind: Deployment              |       | kind: Deployment                         |
| labels:                                       |       | metadata:                     |       | metadata:                                |
|  - includeSelectors: true                     |       |   name: myapp                 |       |   name: myapp                            |
|    pairs:                                     |       | spec:                         |       | spec:                                    |
|      variant: prod                            |       |   replicas: 80                |       |  template:                               |
| resources:                                    |       +-------------------------------+       |     spec:                                |
|   - ../../base                                |                                               |       containers:                        |
| patches:                                      |                                               |         - name: myapp                    |
|   - path: replica_count.yaml                  |                                               |           resources:                     |
|   - path: cpu_count.yaml                      |                                               |             limits:                      |
+-----------------------------------------------+                                               |               memory: &quot;128Mi&quot;            |
                                                                                                |               cpu: &quot;7000m&quot;               |
                                                                                                +------------------------------------------+
```


File structure:
&gt; ```
&gt; ~/someApp
&gt; ├── base
&gt; │   ├── deployment.yaml
&gt; │   ├── kustomization.yaml
&gt; │   └── service.yaml
&gt; └── overlays
&gt;     ├── development
&gt;     │   ├── cpu_count.yaml
&gt;     │   ├── kustomization.yaml
&gt;     │   └── replica_count.yaml
&gt;     └── production
&gt;         ├── cpu_count.yaml
&gt;         ├── kustomization.yaml
&gt;         └── replica_count.yaml
&gt; ```

Take the work from step (1) above, move it into a
`someApp` subdirectory called `base`, then
place overlays in a sibling directory.

An overlay is just another kustomization, referring to
the base, and referring to patches to apply to that
base.

This arrangement makes it easy to manage your
configuration with `git`.  The base could have files
from an upstream repository managed by someone else.
The overlays could be in a repository you own.
Arranging the repo clones as siblings on disk avoids
the need for git submodules (though that works fine, if
you are a submodule fan).

Generate YAML with

```sh
kustomize build ~/someApp/overlays/production
```

The YAML can be directly [applied] to a cluster:

&gt; ```sh
&gt; kustomize build ~/someApp/overlays/production | kubectl apply -f -
&gt; ```

## Community

- [file a bug](https://kubectl.docs.kubernetes.io/contributing/kustomize/bugs/)
- [contribute a feature](https://kubectl.docs.kubernetes.io/contributing/kustomize/features/)
- [propose a larger enhancement](https://github.com/kubernetes-sigs/kustomize/tree/master/proposals)

### Code of conduct

Participation in the Kubernetes community
is governed by the [Kubernetes Code of Conduct].

[`make`]: https://www.gnu.org/software/make
[`sed`]: https://www.gnu.org/software/sed
[DAM]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#declarative-application-management
[KEP]: https://github.com/kubernetes/enhancements/blob/master/keps/sig-cli/2377-Kustomize/README.md
[Kubernetes Code of Conduct]: code-of-conduct.md
[applied]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#apply
[base]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#base
[declarative configuration]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#declarative-application-management
[kubectl announcement]: https://kubernetes.io/blog/2019/03/25/kubernetes-1-14-release-announcement
[kubernetes documentation]: https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/
[kubernetes style]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#kubernetes-style-object
[kustomization]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#kustomization
[overlay]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#overlay
[overlays]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#overlay
[release page]: https://github.com/kubernetes-sigs/kustomize/releases
[resource]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#resource
[resources]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#resource
[sig-cli]: https://github.com/kubernetes/community/blob/master/sig-cli/README.md
[variants]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#variant
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hashicorp/terraform-provider-aws]]></title>
            <link>https://github.com/hashicorp/terraform-provider-aws</link>
            <guid>https://github.com/hashicorp/terraform-provider-aws</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[The AWS Provider enables Terraform to manage AWS resources.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hashicorp/terraform-provider-aws">hashicorp/terraform-provider-aws</a></h1>
            <p>The AWS Provider enables Terraform to manage AWS resources.</p>
            <p>Language: Go</p>
            <p>Stars: 10,546</p>
            <p>Forks: 9,760</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable first-line-h1 no-inline-html --&gt;
&lt;a href=&quot;https://terraform.io&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;.github/terraform_logo_dark.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;.github/terraform_logo_light.svg&quot;&gt;
    &lt;img src=&quot;.github/terraform_logo_light.svg&quot; alt=&quot;Terraform logo&quot; title=&quot;Terraform&quot; align=&quot;right&quot; height=&quot;50&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;

# Terraform AWS Provider

[![Forums][discuss-badge]][discuss]

[discuss-badge]: https://img.shields.io/badge/discuss-terraform--aws-623CE4.svg?style=flat
[discuss]: https://discuss.hashicorp.com/c/terraform-providers/tf-aws/

The [AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs) enables [Terraform](https://terraform.io) to manage [AWS](https://aws.amazon.com) resources.

- [Contributing guide](https://hashicorp.github.io/terraform-provider-aws/)
- [Quarterly development roadmap](ROADMAP.md)
- [FAQ](https://hashicorp.github.io/terraform-provider-aws/faq/)
- [Tutorials](https://learn.hashicorp.com/collections/terraform/aws-get-started)
- [discuss.hashicorp.com](https://discuss.hashicorp.com/c/terraform-providers/tf-aws/)

_**Please note:** We take Terraform&#039;s security and our users&#039; trust very seriously. If you believe you have found a security issue in the Terraform AWS Provider, please responsibly disclose it by contacting us at security@hashicorp.com._
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[iam-veeramalla/observability-zero-to-hero]]></title>
            <link>https://github.com/iam-veeramalla/observability-zero-to-hero</link>
            <guid>https://github.com/iam-veeramalla/observability-zero-to-hero</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[Repo for learning observability]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/iam-veeramalla/observability-zero-to-hero">iam-veeramalla/observability-zero-to-hero</a></h1>
            <p>Repo for learning observability</p>
            <p>Language: Go</p>
            <p>Stars: 2,430</p>
            <p>Forks: 3,812</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>
# 📚 7-Day Observability Tutorial Series

Welcome to the 7-Day Observability Tutorial Series! This repository contains the code and detailed explanations for setting up and understanding observability in Kubernetes using Prometheus, Grafana, Elasticsearch Fluentbit, Kibana, Jaeger, groundcover(eBPF), opentelemetry e.t.c.,.

## 📅 Overview of Each Day

### Day 1: Introduction to Observability
- **Concepts Covered**:
  - Introduction to Observability, Monitoring, Logging, and Tracing.
  - The difference between Monitoring and Observability.
  - Tools available for Monitoring and Observability.
  - Comparison between monitoring and observing in Bare-Metal Servers vs. Kubernetes.
- **Key Learning**:
  - Understand the fundamental concepts of observability.
  - Learn why monitoring and observability are crucial in modern IT environments.

### Day 2: Prometheus - Setting Up Monitoring
- **Concepts Covered**:
  - Introduction to Prometheus and its architecture.
  - Setup and configuration of Prometheus in an EKS cluster.
  - Installation of kube-prometheus-stack with Helm and integrating it with Grafana.
  - Basic queries and setup for monitoring with Prometheus and Grafana.
- **Key Learning**:
  - Get hands-on experience with Prometheus and Grafana.
  - Learn to install and configure Prometheus on Kubernetes.

### Day 3: Metrics and PromQL in Prometheus
- **Concepts Covered**:
  - Introduction to PromQL and basic querying techniques.
  - Aggregation and functions in PromQL to analyze metrics data.
- **Key Learning**:
  - Master the Prometheus Query Language (PromQL) for querying and analyzing metrics.

### Day 4: Instrumentation and Custom Metrics
- **Concepts Covered**:
  - Instrumentation for adding monitoring capabilities to applications.
  - Understanding different types of metrics in Prometheus: Counter, Gauge, Histogram, and Summary.
  - Writing custom metrics in a Node.js application using the `prom-client` library.
  - Dockerizing the application and deploying it on Kubernetes.
  - Setting up Alertmanager for alerting based on custom metrics.
- **Key Learning**:
  - Learn how to instrument applications to expose custom metrics.
  - Configure alerts in Alertmanager to monitor application performance.
  - Understand how to work with different types of metrics in Prometheus.

### Day 5: Logging with EFK Stack
- **Concepts Covered**:
  - Introduction to logging in distributed systems and Kubernetes.
  - Setting up the EFK stack (Elasticsearch, Fluentbit, Kibana) on Kubernetes.
  - Detailed setup and configuration for collecting and visualizing logs.
  - Cleaning up the Kubernetes cluster and resources.
- **Key Learning**:
  - Understand the importance of logging and how to set up

### Day 6: Distributed Tracing with Jaeger
- **Concepts Covered**:
  - Introduction to Jaeger and its architecture for distributed tracing.
  - Setting up Jaeger in a Kubernetes cluster using Helm.
  - Instrumenting services using OpenTelemetry to enable tracing.
  - Viewing and analyzing traces in the Jaeger UI.
  - Cleaning up the environment after setting up Jaeger.
- **Key Learning**:
  - Gain insights into distributed tracing and how it helps in debugging and performance optimization.
  - Learn how to set up and configure Jaeger for tracing in a microservices architecture.

### Day 7: OpenTelemetry – Setting Up Unified Observability
- **Concepts Covered**:
  - Introduction to OpenTelemetry, a unified framework for observability.
  - Understanding how OpenTelemetry integrates tracing, metrics, and logging.
  - Comparison of OpenTelemetry with prior observability tools like Jaeger, Prometheus
  - Supported programming languages and multi-language support in OpenTelemetry.
  - Step-by-step setup of OpenTelemetry in Kubernetes.
- **Key Learning**:
  - Learn how OpenTelemetry simplifies the process of collecting and exporting telemetry data.
  - Understand the benefits of a unified observability approach using OpenTelemetry.
  - Gain hands-on experience with setting up OpenTelemetry Collector, Prometheus, Jaeger, and Elasticsearch to monitor a Golang microservice application.

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[rancher/rancher]]></title>
            <link>https://github.com/rancher/rancher</link>
            <guid>https://github.com/rancher/rancher</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[Complete container management platform]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rancher/rancher">rancher/rancher</a></h1>
            <p>Complete container management platform</p>
            <p>Language: Go</p>
            <p>Stars: 24,770</p>
            <p>Forks: 3,105</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># Rancher

[![Docker Pulls](https://img.shields.io/docker/pulls/rancher/rancher.svg)](https://store.docker.com/community/images/rancher/rancher)
[![Go Report Card](https://goreportcard.com/badge/github.com/rancher/rancher)](https://goreportcard.com/report/github.com/rancher/rancher)

Rancher is an open source container management platform built for organizations that deploy containers in production. Rancher makes it easy to run Kubernetes everywhere, meet IT requirements, and empower DevOps teams.

## Stable Release


&lt;!-- stable v2.12.2 DO NOT REMOVE THIS LINE --&gt;
* v2.12
  * Stable - v2.12.2 - `rancher/rancher:v2.12.2` / `rancher/rancher:stable` - Read the full release [notes](https://github.com/rancher/rancher/releases/tag/v2.12.2).
* v2.11
  * Stable - v2.11.3 - `rancher/rancher:v2.11.3` - Read the full release [notes](https://github.com/rancher/rancher/releases/tag/v2.11.3).
* v2.10
  * Stable - v2.10.3 - `rancher/rancher:v2.10.3` - Read the full release [notes](https://github.com/rancher/rancher/releases/tag/v2.10.3).

To get automated notifications of our latest release, you can watch the announcements category in our [forums](http://forums.rancher.com/c/announcements), or subscribe to the RSS feed `https://forums.rancher.com/c/announcements.rss`.

## Quick Start

    sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher

Open your browser to https://localhost

## Installation

See [Installing/Upgrading Rancher](https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-and-upgrade) for all installation options.

### Minimum Requirements

* Operating Systems
  * Please see [Support Matrix](https://rancher.com/support-matrix/) for specific OS versions for each Rancher version. Note that the link will default to the support matrix for the latest version of Rancher. Use the left navigation menu to select a different Rancher version. 
* Hardware &amp; Software
  * Please see [Installation Requirements](https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-requirements) for hardware and software requirements.

### Using Rancher

To learn more about using Rancher, please refer to our [Rancher Documentation](https://ranchermanager.docs.rancher.com/v2.8).

## Source Code

This repo is a meta-repo used for packaging and contains the majority of Rancher codebase. For other Rancher projects and modules, [see go.mod](https://github.com/rancher/rancher/blob/release/v2.8/go.mod) for the full list.

Rancher also includes other open source libraries and projects, [see go.mod](https://github.com/rancher/rancher/blob/release/v2.8/go.mod) for the full list.

## Build configuration

Refer to the [build docs](docs/build.md) on how to customize the building and packaging of Rancher.

## Support, Discussion, and Community
If you need any help with Rancher, please join us at either our [Rancher forums](http://forums.rancher.com/) or [Slack](https://slack.rancher.io/) where most of our team hangs out at.

Please submit any Rancher bugs, issues, and feature requests to [rancher/rancher](https://github.com/rancher/rancher/issues).

For security issues, please first check our [security policy](https://github.com/rancher/rancher/security) and email security-rancher@suse.com instead of posting a public issue in GitHub.  You may (but are not required to) use the GPG key located on [Keybase](https://keybase.io/rancher).

# License

Copyright (c) 2014-2025 [SUSE](http://rancher.com)

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[asternic/wuzapi]]></title>
            <link>https://github.com/asternic/wuzapi</link>
            <guid>https://github.com/asternic/wuzapi</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Simple RESTful API for WhatsApp in Golang (using the Whatsmeow multi device library)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/asternic/wuzapi">asternic/wuzapi</a></h1>
            <p>Simple RESTful API for WhatsApp in Golang (using the Whatsmeow multi device library)</p>
            <p>Language: Go</p>
            <p>Stars: 555</p>
            <p>Forks: 312</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># WUZAPI

&lt;img src=&quot;static/favicon.ico&quot; width=&quot;30&quot;&gt; WuzAPI is an implementation 
of the [@tulir/whatsmeow](https://github.com/tulir/whatsmeow) library as a 
simple RESTful API service with multiple device support and concurrent 
sessions.

Whatsmeow does not use Puppeteer on headless Chrome, nor an Android emulator. It communicates directly with WhatsApp’s WebSocket servers, making it significantly faster and much less demanding on memory and CPU than those solutions. The drawback is that any changes to the WhatsApp protocol could break connections, requiring a library update.

## :warning: Warning

**Using this software in violation of WhatsApp’s Terms of Service can get your number banned**:  
Be very careful—do not use this to send SPAM or anything similar. Use at your own risk. If you need to develop something for commercial purposes, contact a WhatsApp global solution provider and sign up for the WhatsApp Business API service instead.
 
## Available endpoints

* **Session:** Connect, disconnect, and log out from WhatsApp. Retrieve connection status and QR codes for scanning.
* **Messages:** Send text, image, audio, document, template, video, sticker, location, contact, and poll messages.
* **Users:** Check if phone numbers have WhatsApp, get user information and avatars, and retrieve the full contact list.
* **Chat:** Set presence (typing/paused, recording media), mark messages as read, download images from messages, send reactions.
* **Groups:** Create, delete and list groups, get info, get invite links, set participants, change group photos and names.
* **Webhooks:** Set and get webhooks that will be called whenever events or messages are received.
 
## Prerequisites

**Required:**
* Go (Go Programming Language)

**Optional:**
* Docker (for containerization)

## Updating dependencies

This project uses the whatsmeow library to communicate with WhatsApp. To update the library to the latest version, run:

```bash
go get -u go.mau.fi/whatsmeow@latest
go mod tidy
```

## Building

```
go build .
```

## Run

By default it will start a REST service in port 8080. These are the parameters
you can use to alter behaviour

* -admintoken  : sets authentication token for admin endpoints. If not specified it will be read from .env
* -address  : sets the IP address to bind the server to (default 0.0.0.0)
* -port  : sets the port number (default 8080)
* -logtype : format for logs, either console (default) or json
* -color : enable colored output for console logs
* -osname : Connection OS Name in Whatsapp
* -skipmedia : Skip downloading media from messages
* -wadebug : enable whatsmeow debug, either INFO or DEBUG levels are suported

* -sslcertificate : SSL Certificate File
* -sslprivatekey : SSL Private Key File

Example:

To have colored logs:

```
./wuzapi -logtype=console -color=true
```

For JSON logs:

```
./wuzapi -logtype json 
```

With time zone: 

Set `TZ=America/New_York ./wuzapi ...` in your shell or in your .env file or Docker Compose environment: `TZ=America/New_York`.  

## Configuration

WuzAPI uses a `.env` file for configuration. You can use the provided `.env.sample` as a template:

```bash
cp .env.sample .env
```

### Environment Variables

#### Required Settings
```
WUZAPI_ADMIN_TOKEN=your_admin_token_here
```

#### Database Configuration

**For PostgreSQL:**
```
DB_USER=wuzapi
DB_PASSWORD=wuzapi
DB_NAME=wuzapi
DB_HOST=db  # Use &#039;db&#039; when running with Docker Compose, or &#039;localhost&#039; for native execution
DB_PORT=5432
DB_SSLMODE=false
```

**For SQLite (default):**
No database configuration needed - SQLite is used by default if no PostgreSQL settings are provided.

#### Optional Settings
```
TZ=America/New_York
WEBHOOK_FORMAT=json  # or &quot;form&quot; for the default
SESSION_DEVICE_NAME=WuzAPI
WUZAPI_PORT=8080     # Port for the WuzAPI server
```

### RabbitMQ Integration
WuzAPI supports sending WhatsApp events to a RabbitMQ queue for global event distribution. When enabled, all WhatsApp events will be published to the specified queue regardless of individual user webhook configurations.

Set these environment variables to enable RabbitMQ integration:

```
RABBITMQ_URL=amqp://guest:guest@localhost:5672
RABBITMQ_QUEUE=whatsapp  # Optional (default: whatsapp_events)
```

When enabled:

* All WhatsApp events (messages, presence updates, etc.) will be published to the configured queue regardless of event subscritions for regular webhooks
* Events will include the userId and instanceName
* This works alongside webhook configurations - events will be sent to both RabbitMQ and any configured webhooks
* The integration is global and affects all instances

#### Key configuration options:

* WUZAPI_ADMIN_TOKEN: Required - Authentication token for admin endpoints
* TZ: Optional - Timezone for server operations (default: UTC)
* PostgreSQL-specific options: Only required when using PostgreSQL backend
* RabbitMQ options: Optional, only required if you want to publish events to RabbitMQ

### Docker Configuration

When using Docker Compose, `docker-compose.yml` automatically loads environment variables from a `.env` file when available. However, `docker-compose-swarm.yaml` uses `docker stack deploy`, which does not automatically load from `.env` files. Variables in the swarm file will only be substituted if they are exported in the shell environment where the deploy command is run. For managing secrets in Swarm, consider using Docker secrets.

The Docker configuration will:
1. First load variables from the `.env` file (if present and supported)
2. Use default values as fallback if variables are not defined
3. Override with any variables explicitly set in the `environment` section of the compose file

**Key differences for Docker deployment:**
- Set `DB_HOST=db` instead of `localhost` to connect to the PostgreSQL container
- The `WUZAPI_PORT` variable controls the external port mapping in `docker-compose.yml`
- In swarm mode, `WUZAPI_PORT` configures the Traefik load balancer port

**Note:** The `.env` file is already included in `.gitignore` to avoid committing sensitive information to your repository.

## Usage

To interact with the API, you must include the `Authorization` header in HTTP requests, containing the user&#039;s authentication token. You can have multiple users (different WhatsApp numbers) on the same server.  

* A Swagger API reference at [/api](/api)
* A sample web page to connect and scan QR codes at [/login](/login)
* A fully featured Dashboard to create, manage and test instances at [/dashboard](dashboard)

## ADMIN Actions

You can list, add and remove users using the admin endpoints. For that you must use the WUZAPI_ADMIN_TOKEN in the Authorization header

Then you can use the /admin/users endpoint with the Authorization header containing the token to:

- `GET /admin/users` - List all users
- `POST /admin/users` - Create a new user
- `DELETE /admin/users/{id}` - Remove a user

The JSON body for creating a new user must contain:

- `name` [string] : User&#039;s name 
- `token` [string] : Security token to authorize/authenticate this user
- `webhook` [string] : URL to send events via POST (optional)
- `events` [string] : Comma-separated list of events to receive (required) - Valid events are: &quot;Message&quot;, &quot;ReadReceipt&quot;, &quot;Presence&quot;, &quot;HistorySync&quot;, &quot;ChatPresence&quot;, &quot;All&quot;
- `expiration` [int] : Expiration timestamp (optional, not enforced by the system)

## User Creation with Optional Proxy and S3 Configuration

You can create a user with optional proxy and S3 storage configuration. All fields are optional and backward compatible. If you do not provide these fields, the user will be created with default settings.

### Example Payload

```json
{
  &quot;name&quot;: &quot;test_user&quot;,
  &quot;token&quot;: &quot;user_token&quot;,
  &quot;proxyConfig&quot;: {
    &quot;enabled&quot;: true,
    &quot;proxyURL&quot;: &quot;socks5://user:pass@host:port&quot;
  },
  &quot;s3Config&quot;: {
    &quot;enabled&quot;: true,
    &quot;endpoint&quot;: &quot;https://s3.amazonaws.com&quot;,
    &quot;region&quot;: &quot;us-east-1&quot;,
    &quot;bucket&quot;: &quot;my-bucket&quot;,
    &quot;accessKey&quot;: &quot;AKIAIOSFODNN7EXAMPLE&quot;,
    &quot;secretKey&quot;: &quot;wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY&quot;,
    &quot;pathStyle&quot;: false,
    &quot;publicURL&quot;: &quot;https://cdn.yoursite.com&quot;,
    &quot;mediaDelivery&quot;: &quot;both&quot;,
    &quot;retentionDays&quot;: 30
  }
}
```

- `proxyConfig` (object, optional):
  - `enabled` (boolean): Enable proxy for this user.
  - `proxyURL` (string): Proxy URL (e.g., `socks5://user:pass@host:port`).
- `s3Config` (object, optional):
  - `enabled` (boolean): Enable S3 storage for this user.
  - `endpoint` (string): S3 endpoint URL.
  - `region` (string): S3 region.
  - `bucket` (string): S3 bucket name.
  - `accessKey` (string): S3 access key.
  - `secretKey` (string): S3 secret key.
  - `pathStyle` (boolean): Use path style addressing.
  - `publicURL` (string): Public URL for accessing files.
  - `mediaDelivery` (string): Media delivery type (`base64`, `s3`, or `both`).
  - `retentionDays` (integer): Number of days to retain files.

If you omit `proxyConfig` or `s3Config`, the user will be created without proxy or S3 integration, maintaining full backward compatibility.

## API reference 

API calls should be made with content type json, and parameters sent into the
request body, always passing the Token header for authenticating the request.

Check the [API Reference](https://github.com/asternic/wuzapi/blob/main/API.md)

## Contributors

&lt;table&gt;
&lt;tr&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/asternic&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/25182694?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Nicolas/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Nicolas&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/guilhermejansen&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/52773109?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Guilherme Jansen/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Guilherme Jansen&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/netrixken&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/9066682?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Netrix Ken/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Netrix Ken&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/pedroafonso18&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/157052926?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Pedro Afonso/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Pedro Afonso&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/RuanAyram&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/16547662?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Ruan Kaylo/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Ruan Kaylo&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/luizrgf2&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/71092163?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Luiz Ricardo Gonçalves Felipe/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Luiz Ricardo Gonçalves Felipe&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/chrsmendes&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/77082167?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Christopher Mendes/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Christopher Mendes&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/andreydruz&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/976438?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=andreydruz/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;andreydruz&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/ramon-victor&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/13617054?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=ramon-victor/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;ramon-victor&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/luiis716&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/97978347?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=luiis716/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;luiis716&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/joaosouz4dev&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/47183663?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=João Victor Souza/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;João Victor Souza&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/gusnips&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/981265?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Gustavo Salomé /&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Gustavo Salomé &lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/anilgulecha&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/1016984?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Anil Gulecha/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Anil Gulecha&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/AlanMartines&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/10979090?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Alan Martines/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Alan Martines&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/DwiRizqiH&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/69355492?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Ahmad Dwi Rizqi Hidayatulloh/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Ahmad Dwi Rizqi Hidayatulloh&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/elohmeier&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/2536303?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=elohmeier/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;elohmeier&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/fadlee&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/334797?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Fadlul Alim/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Fadlul Alim&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/JobasFernandes&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/26033148?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Joseph Fernandes/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Joseph Fernandes&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/renancesarti-cyber&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/235291917?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=renancesarti-cyber/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;renancesarti-cyber&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/ruben18salazar3&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/86245508?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Rubén Salazar/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Rubén Salazar&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/ryanachdiadsyah&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/165612793?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Ryan Achdiadsyah/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Ryan Achdiadsyah&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/ViFigueiredo&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/67883343?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=ViFigueiredo/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;ViFigueiredo&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/cadao7&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/306330?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-content:center;overflow:hidden;padding-top:10px&quot; alt=Ricardo Maminhak/&gt;
            &lt;br /&gt;
            &lt;sub style=&quot;font-size:14px&quot;&gt;&lt;b&gt;Ricardo Maminhak&lt;/b&gt;&lt;/sub&gt;
        &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; style=&quot;word-wrap: break-word; width: 150.0; height: 150.0&quot;&gt;
        &lt;a href=https://github.com/zennnez&gt;
            &lt;img src=https://avatars.githubusercontent.com/u/3524740?v=4 width=&quot;100;&quot;  style=&quot;border-radius:50%;align-items:center;justify-cont

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[spf13/cobra]]></title>
            <link>https://github.com/spf13/cobra</link>
            <guid>https://github.com/spf13/cobra</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[A Commander for modern Go CLI interactions]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/spf13/cobra">spf13/cobra</a></h1>
            <p>A Commander for modern Go CLI interactions</p>
            <p>Language: Go</p>
            <p>Stars: 42,164</p>
            <p>Forks: 3,013</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://cobra.dev&quot;&gt;
&lt;img width=&quot;512&quot; height=&quot;535&quot; alt=&quot;cobra-logo&quot; src=&quot;https://github.com/user-attachments/assets/c8bf9aad-b5ae-41d3-8899-d83baec10af8&quot; /&gt;
&lt;/a&gt;
&lt;/div&gt;

Cobra is a library for creating powerful modern CLI applications.

&lt;a href=&quot;https://cobra.dev&quot;&gt;Visit Cobra.dev for extensive documentation&lt;/a&gt; 


Cobra is used in many Go projects such as [Kubernetes](https://kubernetes.io/),
[Hugo](https://gohugo.io), and [GitHub CLI](https://github.com/cli/cli) to
name a few. [This list](site/content/projects_using_cobra.md) contains a more extensive list of projects using Cobra.

[![](https://img.shields.io/github/actions/workflow/status/spf13/cobra/test.yml?branch=main&amp;longCache=true&amp;label=Test&amp;logo=github%20actions&amp;logoColor=fff)](https://github.com/spf13/cobra/actions?query=workflow%3ATest)
[![Go Reference](https://pkg.go.dev/badge/github.com/spf13/cobra.svg)](https://pkg.go.dev/github.com/spf13/cobra)
[![Go Report Card](https://goreportcard.com/badge/github.com/spf13/cobra)](https://goreportcard.com/report/github.com/spf13/cobra)
[![Slack](https://img.shields.io/badge/Slack-cobra-brightgreen)](https://gophers.slack.com/archives/CD3LP1199)
&lt;hr&gt;
&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;
   &lt;sup&gt;Supported by:&lt;/sup&gt;
   &lt;br&gt;
   &lt;br&gt;
   &lt;a href=&quot;https://www.warp.dev/cobra&quot;&gt;
      &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd7ecac94eae&quot;&gt;
   &lt;/a&gt;

### [Warp, the AI terminal for devs](https://www.warp.dev/cobra)
[Try Cobra in Warp today](https://www.warp.dev/cobra)&lt;br&gt;

&lt;/div&gt;
&lt;hr&gt;

# Overview

Cobra is a library providing a simple interface to create powerful modern CLI
interfaces similar to git &amp; go tools.

Cobra provides:
* Easy subcommand-based CLIs: `app server`, `app fetch`, etc.
* Fully POSIX-compliant flags (including short &amp; long versions)
* Nested subcommands
* Global, local and cascading flags
* Intelligent suggestions (`app srver`... did you mean `app server`?)
* Automatic help generation for commands and flags
* Grouping help for subcommands
* Automatic help flag recognition of `-h`, `--help`, etc.
* Automatically generated shell autocomplete for your application (bash, zsh, fish, powershell)
* Automatically generated man pages for your application
* Command aliases so you can change things without breaking them
* The flexibility to define your own help, usage, etc.
* Optional seamless integration with [viper](https://github.com/spf13/viper) for 12-factor apps

# Concepts

Cobra is built on a structure of commands, arguments &amp; flags.

**Commands** represent actions, **Args** are things and **Flags** are modifiers for those actions.

The best applications read like sentences when used, and as a result, users
intuitively know how to interact with them.

The pattern to follow is
`APPNAME VERB NOUN --ADJECTIVE`
    or
`APPNAME COMMAND ARG --FLAG`.

A few good real world examples may better illustrate this point.

In the following example, &#039;server&#039; is a command, and &#039;port&#039; is a flag:

    hugo server --port=1313

In this command we are telling Git to clone the url bare.

    git clone URL --bare

## Commands

Command is the central point of the application. Each interaction that
the application supports will be contained in a Command. A command can
have children commands and optionally run an action.

In the example above, &#039;server&#039; is the command.

[More about cobra.Command](https://pkg.go.dev/github.com/spf13/cobra#Command)

## Flags

A flag is a way to modify the behavior of a command. Cobra supports
fully POSIX-compliant flags as well as the Go [flag package](https://golang.org/pkg/flag/).
A Cobra command can define flags that persist through to children commands
and flags that are only available to that command.

In the example above, &#039;port&#039; is the flag.

Flag functionality is provided by the [pflag
library](https://github.com/spf13/pflag), a fork of the flag standard library
which maintains the same interface while adding POSIX compliance.

# Installing
Using Cobra is easy. First, use `go get` to install the latest version
of the library.

```
go get -u github.com/spf13/cobra@latest
```

Next, include Cobra in your application:

```go
import &quot;github.com/spf13/cobra&quot;
```

# Usage
`cobra-cli` is a command line program to generate cobra applications and command files.
It will bootstrap your application scaffolding to rapidly
develop a Cobra-based application. It is the easiest way to incorporate Cobra into your application.

It can be installed by running:

```
go install github.com/spf13/cobra-cli@latest
```

For complete details on using the Cobra-CLI generator, please read [The Cobra Generator README](https://github.com/spf13/cobra-cli/blob/main/README.md)

For complete details on using the Cobra library, please read [The Cobra User Guide](site/content/user_guide.md).

# License

Cobra is released under the Apache 2.0 license. See [LICENSE.txt](LICENSE.txt)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[argoproj/argo-workflows]]></title>
            <link>https://github.com/argoproj/argo-workflows</link>
            <guid>https://github.com/argoproj/argo-workflows</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Workflow Engine for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/argoproj/argo-workflows">argoproj/argo-workflows</a></h1>
            <p>Workflow Engine for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 16,098</p>
            <p>Forks: 3,388</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable-next-line MD041 --&gt;
[![Security Status](https://github.com/argoproj/argo-workflows/actions/workflows/snyk.yml/badge.svg?branch=main)](https://github.com/argoproj/argo-workflows/actions/workflows/snyk.yml?query=branch%3Amain)
[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/3830/badge)](https://bestpractices.coreinfrastructure.org/projects/3830)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-workflows/badge)](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-workflows)
[![FOSSA License Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fargoproj%2Fargo-workflows.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fargoproj%2Fargo-workflows?ref=badge_shield)
[![Slack](https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack)](https://argoproj.github.io/community/join-slack)
[![X Follow](https://img.shields.io/twitter/follow/argoproj?style=social)](https://x.com/argoproj)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-argoproj-blue.svg?logo=linkedin)](https://www.linkedin.com/company/argoproj/)
[![Release Version](https://img.shields.io/github/v/release/argoproj/argo-workflows?label=argo-workflows)](https://github.com/argoproj/argo-workflows/releases/latest)
[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-workflows)](https://artifacthub.io/packages/helm/argo/argo-workflows)

## What is Argo Workflows?

Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes.
Argo Workflows is implemented as a Kubernetes CRD (Custom Resource Definition).

* Define workflows where each step is a container.
* Model multi-step workflows as a sequence of tasks or capture the dependencies between tasks using a directed acyclic graph (DAG).
* Easily run compute intensive jobs for machine learning or data processing in a fraction of the time using Argo Workflows on Kubernetes.

Argo is a [Cloud Native Computing Foundation (CNCF)](https://cncf.io/) graduated project.

## Use Cases

* [Machine Learning pipelines](https://argo-workflows.readthedocs.io/en/latest/use-cases/machine-learning/)
* [Data and batch processing](https://argo-workflows.readthedocs.io/en/latest/use-cases/data-processing/)
* [Infrastructure automation](https://argo-workflows.readthedocs.io/en/latest/use-cases/infrastructure-automation/)
* [CI/CD](https://argo-workflows.readthedocs.io/en/latest/use-cases/ci-cd/)
* [Other use cases](https://argo-workflows.readthedocs.io/en/latest/use-cases/other/)

## Why Argo Workflows?

* Argo Workflows is the most popular workflow execution engine for Kubernetes.
* Light-weight, scalable, and easier to use.
    * Including for Python users through [the Hera Python SDK for Argo Workflows](https://hera.readthedocs.io/en/stable/).
* Designed from the ground up for containers without the overhead and limitations of legacy VM and server-based environments.
* Cloud agnostic and can run on any Kubernetes cluster.

[Read what people said in our latest survey](https://blog.argoproj.io/argo-workflows-events-2023-user-survey-results-82c53bc30543)

## Try Argo Workflows

You can try Argo Workflows via one of the following:

1. [Interactive Training Material](https://killercoda.com/argoproj/course/argo-workflows/)
1. [Access the demo environment](https://workflows.apps.argoproj.io/workflows/argo)

![Screenshot](docs/assets/screenshot.png)

## Who uses Argo Workflows?

[About 200+ organizations are officially using Argo Workflows](USERS.md)

## Ecosystem

Just some of the projects that use or rely on Argo Workflows (complete list [here](https://github.com/akuity/awesome-argo#ecosystem-projects)):

* [Argo Events](https://github.com/argoproj/argo-events)
* [Couler](https://github.com/couler-proj/couler)
* [Hera](https://github.com/argoproj-labs/hera-workflows)
* [Katib](https://github.com/kubeflow/katib)
* [Kedro](https://kedro.readthedocs.io/en/stable/)
* [Kubeflow Pipelines](https://github.com/kubeflow/pipelines)
* [Netflix Metaflow](https://metaflow.org)
* [Onepanel](https://github.com/onepanelio/onepanel)
* [Orchest](https://github.com/orchest/orchest/)
* [Piper](https://github.com/quickube/piper)
* [Ploomber](https://github.com/ploomber/ploomber)
* [Seldon](https://github.com/SeldonIO/seldon-core)
* [SQLFlow](https://github.com/sql-machine-learning/sqlflow)

## Client Libraries

Check out our [Java, Golang and Python clients](docs/client-libraries.md).

## Quickstart

* [Get started here](https://argo-workflows.readthedocs.io/en/latest/quick-start/)
* [Walk-through examples](https://argo-workflows.readthedocs.io/en/latest/walk-through/)

## Documentation

[View the docs](https://argo-workflows.readthedocs.io/en/latest/)

## Features

An incomplete list of features Argo Workflows provides:

* UI to visualize and manage Workflows
* Artifact support (S3, Artifactory, Alibaba Cloud OSS, Azure Blob Storage, HTTP, Git, GCS, raw)
* Workflow templating to store commonly used Workflows in the cluster
* Archiving Workflows after executing for later access
* Scheduled workflows using cron
* Server interface with REST API (HTTP and GRPC)
* DAG or Steps based declaration of workflows
* Step level input &amp; outputs (artifacts/parameters)
* Loops
* Parameterization
* Conditionals
* Timeouts (step &amp; workflow level)
* Retry (step &amp; workflow level)
* Resubmit (memoized)
* Suspend &amp; Resume
* Cancellation
* K8s resource orchestration
* Exit Hooks (notifications, cleanup)
* Garbage collection of completed workflow
* Scheduling (affinity/tolerations/node selectors)
* Volumes (ephemeral/existing)
* Parallelism limits
* Daemoned steps
* DinD (docker-in-docker)
* Script steps
* Event emission
* Prometheus metrics
* Multiple executors
* Multiple pod and workflow garbage collection strategies
* Automatically calculated resource usage per step
* Java/Golang/Python SDKs
* Pod Disruption Budget support
* Single-sign on (OAuth2/OIDC)
* Webhook triggering
* CLI
* Out-of-the box and custom Prometheus metrics
* Windows container support
* Embedded widgets
* Multiplex log viewer

## Community Meetings

We host monthly community meetings where we and the community showcase demos and discuss the current and future state of the project. Feel free to join us!
For Community Meeting information, minutes and recordings, please [see here](https://bit.ly/argo-wf-cmty-mtng).

Participation in Argo Workflows is governed by the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/master/code-of-conduct.md)

## Community Blogs and Presentations

* [Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo](https://github.com/terrytangyuan/awesome-argo)
* [Automation of Everything - How To Combine Argo Events, Workflows &amp; Pipelines, CD, and Rollouts](https://youtu.be/XNXJtxkUKeY)
* [Argo Workflows and Pipelines - CI/CD, Machine Learning, and Other Kubernetes Workflows](https://youtu.be/UMaivwrAyTA)
* [Argo Ansible role: Provisioning Argo Workflows on OpenShift](https://medium.com/@marekermk/provisioning-argo-on-openshift-with-ansible-and-kustomize-340a1fda8b50)
* [Argo Workflows vs Apache Airflow](http://bit.ly/30YNIvT)
* [Beyond Prototypes: Production-Ready ML Systems with Metaflow and Argo](https://github.com/terrytangyuan/public-talks/tree/main/talks/kubecon-na-2023-metaflow-argo)
* [CI/CD with Argo on Kubernetes](https://medium.com/@bouwe.ceunen/ci-cd-with-argo-on-kubernetes-28c1a99616a9)
* [Define Your CI/CD Pipeline with Argo Workflows](https://haque-zubair.medium.com/define-your-ci-cd-pipeline-with-argo-workflows-25aefb02fa63)
* [Distributed Machine Learning Patterns from Manning Publication](https://github.com/terrytangyuan/distributed-ml-patterns)
* [Engineering Cloud Native AI Platform](https://github.com/terrytangyuan/public-talks/tree/main/talks/platform-con-2024-engineering-cloud-native-ai-platform)
* [Managing Thousands of Automatic Machine Learning Experiments with Argo and Katib](https://github.com/terrytangyuan/public-talks/blob/main/talks/argocon-automl-experiments-2022)
* [Revolutionizing Scientific Simulations with Argo Workflows](https://www.youtube.com/watch?v=BYVf7GhfiRg)
* [Running Argo Workflows Across Multiple Kubernetes Clusters](https://admiralty.io/blog/running-argo-workflows-across-multiple-kubernetes-clusters/)
* [Scaling Kubernetes: Best Practices for Managing Large-Scale Batch Jobs with Spark and Argo Workflow](https://www.youtube.com/watch?v=KqEKRPjy4aE)
* [Open Source Model Management Roundup: Polyaxon, Argo, and Seldon](https://www.anaconda.com/blog/developer-blog/open-source-model-management-roundup-polyaxon-argo-and-seldon/)
* [Producing 200 OpenStreetMap extracts in 35 minutes using a scalable data workflow](https://www.interline.io/blog/scaling-openstreetmap-data-workflows/)
* [Production-Ready AI Platform on Kubernetes](https://github.com/terrytangyuan/public-talks/tree/main/talks/kubecon-europe-2024-production-ai-platform-on-k8s)
* [Argo integration review](http://dev.matt.hillsdon.net/2018/03/24/argo-integration-review.html)
* TGI Kubernetes with Joe Beda: [Argo workflow system](https://www.youtube.com/watch?v=M_rxPPLG8pU&amp;start=859)

## Project Resources

* [Argo Project GitHub organization](https://github.com/argoproj)
* [Argo Website](https://argoproj.github.io/)
* [Argo Slack](https://argoproj.github.io/community/join-slack)

## Security

See [SECURITY.md](SECURITY.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cloudnative-pg/cloudnative-pg]]></title>
            <link>https://github.com/cloudnative-pg/cloudnative-pg</link>
            <guid>https://github.com/cloudnative-pg/cloudnative-pg</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[CloudNativePG is a comprehensive platform designed to seamlessly manage PostgreSQL databases within Kubernetes environments, covering the entire operational lifecycle from initial deployment to ongoing maintenance]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudnative-pg/cloudnative-pg">cloudnative-pg/cloudnative-pg</a></h1>
            <p>CloudNativePG is a comprehensive platform designed to seamlessly manage PostgreSQL databases within Kubernetes environments, covering the entire operational lifecycle from initial deployment to ongoing maintenance</p>
            <p>Language: Go</p>
            <p>Stars: 7,026</p>
            <p>Forks: 526</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>[![CNCF Landscape](https://img.shields.io/badge/CNCF%20Landscape-5699C6)][cncf-landscape]
[![Latest Release](https://img.shields.io/github/v/release/cloudnative-pg/cloudnative-pg.svg)][latest-release]
[![GitHub License](https://img.shields.io/github/license/cloudnative-pg/cloudnative-pg)][license]
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9933/badge)][openssf]
[![OpenSSF Scorecard Badge][openssf-scorecard-badge]][openssf-socrecard-view]
[![Documentation][documentation-badge]][documentation]
[![Stack Overflow](https://img.shields.io/badge/stackoverflow-cloudnative--pg-blue?logo=stackoverflow&amp;logoColor=%23F48024&amp;link=https%3A%2F%2Fstackoverflow.com%2Fquestions%2Ftagged%2Fcloudnative-pg)][stackoverflow]
[![FOSSA Status][fossa-badge]][fossa]

# Welcome to the CloudNativePG Project!

**CloudNativePG (CNPG)** is an open-source platform designed to seamlessly
manage [PostgreSQL](https://www.postgresql.org/) databases in Kubernetes
environments. It covers the entire operational lifecycle—from deployment to
ongoing maintenance—through its core component, the CloudNativePG operator.

## Table of Contents

- [Code of Conduct](CODE_OF_CONDUCT.md)
- [Governance Policies](https://github.com/cloudnative-pg/governance/blob/main/GOVERNANCE.md)
- [Contributing](CONTRIBUTING.md)
- [Adopters](ADOPTERS.md)
- [Commercial Support](https://cloudnative-pg.io/support/)
- [License](LICENSE)

## Getting Started

The best way to get started is the [Quickstart Guide](https://cloudnative-pg.io/documentation/current/quickstart/).

## Scope

### Mission

CloudNativePG aims to increase PostgreSQL adoption within Kubernetes by making
it an integral part of the development process and GitOps-driven CI/CD
automation.

### Core Principles &amp; Features

Designed by PostgreSQL experts for Kubernetes administrators, CloudNativePG
follows a Kubernetes-native approach to PostgreSQL primary/standby cluster
management. Instead of relying on external high-availability tools (like
Patroni, repmgr, or Stolon), it integrates directly with the Kubernetes API to
automate database operations that a skilled DBA would perform manually.

Key design decisions include:

- Direct integration with Kubernetes API: The PostgreSQL cluster’s status is
  available directly in the `Cluster` resource, allowing users to inspect it
  via the Kubernetes API.
- Operator pattern: The operator ensures that the desired PostgreSQL state is
  reconciled automatically, following Kubernetes best practices.
- Immutable application containers: Updates follow an immutable infrastructure
  model, as explained in
  [&quot;Why EDB Chose Immutable Application Containers&quot;](https://www.enterprisedb.com/blog/why-edb-chose-immutable-application-containers).

### How CloudNativePG Works

The operator continuously monitors and updates the PostgreSQL cluster state.
Examples of automated actions include:

- Failover management: If the primary instance fails, the operator elects a new
  primary, updates the cluster status, and orchestrates the transition.
- Scaling read replicas: When the number of desired replicas changes, the
  operator provisions or removes resources such as persistent volumes, secrets,
  and config maps while managing streaming replication.
- Service updates: Kubernetes remains the single source of truth, ensuring
  that PostgreSQL service endpoints are always up to date.
- Rolling updates: When an image is updated, the operator follows a rolling
  strategy—first updating replica pods before performing a controlled
  switchover for the primary.

CloudNativePG manages additional Kubernetes resources to enhance PostgreSQL
management, including: `Backup`, `ClusterImageCatalog`, `Database`,
`ImageCatalog`, `Pooler`, `Publication`, `ScheduledBackup`, and `Subscription`.

## Out of Scope

- **Kubernetes only:** CloudNativePG is dedicated to vanilla Kubernetes
  maintained by the [Cloud Native Computing Foundation
  (CNCF)](https://kubernetes.io/).
- **PostgreSQL only:** CloudNativePG is dedicated to vanilla PostgreSQL
  maintained by the [PostgreSQL Global Development Group
  (PGDG)](https://www.postgresql.org/about/).
- **No support for forks:** Features from PostgreSQL forks will only be
  considered if they can be integrated as extensions or pluggable frameworks.
- **Not a general-purpose database operator:** CloudNativePG does not support
  other databases (e.g., MariaDB).

CloudNativePG can be extended via the [CNPG-I plugin interface](https://github.com/cloudnative-pg/cnpg-i).

## Communications

- [Github Discussions](https://github.com/cloudnative-pg/cloudnative-pg/discussions)
- [Slack](https://cloud-native.slack.com/archives/C08MAUJ7NPM)
  (join the [CNCF Slack Workspace](https://communityinviter.com/apps/cloud-native/cncf)).
- [Twitter](https://twitter.com/CloudNativePg)
- [Mastodon](https://mastodon.social/@CloudNativePG)
- [Bluesky](https://bsky.app/profile/cloudnativepg.bsky.social)

## Resources

- [Roadmap](https://github.com/orgs/cloudnative-pg/projects/1)
- [Website](https://cloudnative-pg.io)
- [FAQ](docs/src/faq.md)
- [Blog](https://cloudnative-pg.io/blog/)
- [CloudNativePG plugin Interface (CNPG-I)](https://github.com/cloudnative-pg/cnpg-i).

## Adopters

A list of publicly known users of the CloudNativePG operator is in [ADOPTERS.md](ADOPTERS.md).
Help us grow our community and CloudNativePG by adding yourself and your
organization to this list!

### CloudNativePG at KubeCon

- April 4 2025, KubeCon Europe in London: [&quot;Consistent Volume Group Snapshots, Unraveling the Magic&quot;](https://sched.co/1tx8g) - Leonardo Cecchi (EDB) and Xing Yang (VMware)
- November 11 2024, Cloud Native Rejekts NA 2024: [&quot;Maximising Microservice Databases with Kubernetes, Postgres, and CloudNativePG&quot;](https://www.youtube.com/watch?v=uBzl_stoxoc&amp;ab_channel=CloudNativeRejekts) - Gabriele Bartolini (EDB) and Leonardo Cecchi (EDB)
- March 21 2024, KubeCon Europe 2024 in Paris: [&quot;Scaling Heights: Mastering Postgres Database Vertical Scalability with Kubernetes Storage Magic&quot;](https://kccnceu2024.sched.com/event/1YeM4/scaling-heights-mastering-postgres-database-vertical-scalability-with-kubernetes-storage-magic-gabriele-bartolini-edb-gari-singh-google) - Gari Singh, Google &amp; Gabriele Bartolini, EDB
- March 19 2024, Data on Kubernetes Day at KubeCon Europe 2024 in Paris: [&quot;From Zero to Hero: Scaling Postgres in Kubernetes Using the Power of CloudNativePG&quot;](https://colocatedeventseu2024.sched.com/event/1YFha/from-zero-to-hero-scaling-postgres-in-kubernetes-using-the-power-of-cloudnativepg-gabriele-bartolini-edb) - Gabriele Bartolini, EDB
- 7 November 2023, KubeCon North America 2023 in Chicago: [&quot;Disaster Recovery with Very Large Postgres Databases (in Kubernetes)&quot;](https://kccncna2023.sched.com/event/1R2ml/disaster-recovery-with-very-large-postgres-databases-gabriele-bartolini-edb-michelle-au-google) - Michelle Au, Google &amp; Gabriele Bartolini, EDB
- 27 October 2022, KubeCon North America 2022 in Detroit: [&quot;Data On Kubernetes, Deploying And Running PostgreSQL And Patterns For Databases In a Kubernetes Cluster&quot;](https://kccncna2022.sched.com/event/182GB/data-on-kubernetes-deploying-and-running-postgresql-and-patterns-for-databases-in-a-kubernetes-cluster-chris-milsted-ondat-gabriele-bartolini-edb) - Chris Milsted, Ondat &amp; Gabriele Bartolini, EDB

### Useful links

- [Data on Kubernetes (DoK) Community](https://dok.community/)
- [&quot;Cloud Neutral Postgres Databases with Kubernetes and CloudNativePG&quot; by Gabriele Bartolini](https://www.cncf.io/blog/2024/11/20/cloud-neutral-postgres-databases-with-kubernetes-and-cloudnativepg/) (November 2024)
- [&quot;How to migrate your PostgreSQL database in Kubernetes with ~0 downtime from anywhere&quot; by Gabriele Bartolini](https://gabrielebartolini.it/articles/2024/03/cloudnativepg-recipe-5-how-to-migrate-your-postgresql-database-in-kubernetes-with-~0-downtime-from-anywhere/) (March 2024)
- [&quot;Maximizing Microservice Databases with Kubernetes, Postgres, and CloudNativePG&quot; by Gabriele Bartolini](https://gabrielebartolini.it/articles/2024/02/maximizing-microservice-databases-with-kubernetes-postgres-and-cloudnativepg/) (February 2024)
- [&quot;Recommended Architectures for PostgreSQL in Kubernetes&quot; by Gabriele Bartolini](https://www.cncf.io/blog/2023/09/29/recommended-architectures-for-postgresql-in-kubernetes/) (September 2023)
- [&quot;The Current State of Major PostgreSQL Upgrades with CloudNativePG&quot; by Gabriele Bartolini](https://www.enterprisedb.com/blog/current-state-major-postgresql-upgrades-cloudnativepg-kubernetes) (August 2023)
- [&quot;The Rise of the Kubernetes Native Database&quot; by Jeff Carpenter](https://thenewstack.io/the-rise-of-the-kubernetes-native-database/) (December 2022)
- [&quot;Why Run Postgres in Kubernetes?&quot; by Gabriele Bartolini](https://cloudnativenow.com/kubecon-cnc-eu-2022/why-run-postgres-in-kubernetes/) (May 2022)
- [&quot;Shift-Left Security: The Path To PostgreSQL On Kubernetes&quot; by Gabriele Bartolini](https://www.tfir.io/shift-left-security-the-path-to-postgresql-on-kubernetes/) (April 2021)
- [&quot;Local Persistent Volumes and PostgreSQL usage in Kubernetes&quot; by Gabriele Bartolini](https://www.2ndquadrant.com/en/blog/local-persistent-volumes-and-postgresql-usage-in-kubernetes/) (June 2020)

---

&lt;p align=&quot;center&quot;&gt;
We are a &lt;a href=&quot;https://www.cncf.io/sandbox-projects/&quot;&gt;Cloud Native Computing Foundation Sandbox project&lt;/a&gt;.
&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; align=&quot;center&quot;&gt;
      &lt;picture align=&quot;center&quot;&gt;
         &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/white/cncf-white.svg?raw=true&quot;&gt;
         &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/color/cncf-color.svg?raw=true&quot;&gt;
         &lt;img align=&quot;center&quot; src=&quot;https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/color/cncf-color.svg?raw=true&quot; alt=&quot;CNCF logo&quot; width=&quot;50%&quot;/&gt;
      &lt;/picture&gt;
&lt;/p&gt;

---

&lt;p align=&quot;center&quot;&gt;
CloudNativePG was originally built and sponsored by &lt;a href=&quot;https://www.enterprisedb.com&quot;&gt;EDB&lt;/a&gt;.
&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; align=&quot;center&quot;&gt;
      &lt;picture align=&quot;center&quot;&gt;
         &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_white.svg&quot;&gt;
         &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_grey.svg&quot;&gt;
         &lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_grey.svg&quot; alt=&quot;EDB logo&quot; width=&quot;25%&quot;/&gt;
      &lt;/picture&gt;
&lt;/p&gt;

---

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.postgresql.org/about/policies/trademarks/&quot;&gt;Postgres, PostgreSQL, and the Slonik Logo&lt;/a&gt;
are trademarks or registered trademarks of the PostgreSQL Community Association
of Canada, and used with their permission.
&lt;/p&gt;

---

[cncf-landscape]: https://landscape.cncf.io/?item=app-definition-and-development--database--cloudnativepg
[stackoverflow]: https://stackoverflow.com/questions/tagged/cloudnative-pg
[latest-release]: https://github.com/cloudnative-pg/cloudnative-pg/releases/latest
[documentation]: https://cloudnative-pg.io/documentation/current/
[license]: https://github.com/cloudnative-pg/cloudnative-pg?tab=Apache-2.0-1-ov-file#readme
[openssf]: https://www.bestpractices.dev/projects/9933
[openssf-scorecard-badge]: https://api.scorecard.dev/projects/github.com/cloudnative-pg/cloudnative-pg/badge
[openssf-socrecard-view]: https://scorecard.dev/viewer/?uri=github.com/cloudnative-pg/cloudnative-pg
[documentation-badge]: https://img.shields.io/badge/Documentation-white?logo=data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAGN0lEQVR4nJRXXWwcVxU%2B8%2F%2BzP%2BPZtR2v7dqy07jUJUALNaiK6lZyUVVKWgGKaIv8QCMekBAVQlQICcEzVZFQVYFKQhASEBHlISJPCRJEshTFChgrIYHEiYMh69jetffHM7Mzc%2B9Bs7vjnTs7yZpZWbt37s%2F5zne%2Bc861CD0eXRkbHc3NfjeffvxNAGEAgULD2756v35%2B3qe1Nc4fnQVEXlA2LnOcXlCF8S%2B6vvVgq%2FL3M65X3e51PvfQCU4WJgZe%2B8GQ8fS7AKgjBB8KEHwjDXZSjkf0CREAaXM2eI9c65siqWxWl360Xl74ANHz%2Fy8AitxnTBfmz%2BhyYS4wGhwObQCIHSA0AigOMBzvOsXzd4pnjyL6NMmWEH8hi2b28Og3%2FqRJA0ewfQy0v1vGO2NovwPo%2FEU%2FwVgSU1PI%2BSu79v3lJAB8HM%2BTI%2FO%2FUUXzM4xHIe0xI4DdRqOAwnF%2F38ePPyzaDIDh%2FMxcWh462m08aojuGY97C0nrAEHg9BlF0fmeAPr0J15vbaKsp0BZQzEDEAlP9B209UIIVXUta%2FQEQHwxgxFjTc%2BRskAwrgVWmHtg22vMPJwLDqGUNJIAMHVAkGu3WdpZz6NAkgSXpINSycluV28er1a3rJ4M3F2%2F9AtCvXKycRrTQttrjINjxxxIL9jevxdaDHU%2FTBr6pL5ruzuLZubgUQBOY2hPij3GBUe7tBCMBRE2KrXVSz0BBI%2FtPVgtV%2F%2FxkZ5WSjI%2F%2BFIXC3sHJwgT4yFqrZFFTSlVrp3sGYLwcfxSmXCbS00j2Ms4K7qkOsFx6qdTuiHtG4AimfmM8NyvOvR2G48qXtZ2fsfrN7%2BqpcRyUp0glKiimDm4TwAcHBp%2B9WeA4ki0GMWNR9OVF8BZvn7xtI%2FF09H8jzLEgz6yLwCDuelnFXHkTZZOytCOEdqDOtGwsm%2BNj00fXt%2B6%2Bj4vcA7bwNrZwENmXwAKuZnvsNRThs5ozMPfPiHyoDF7xiduHcXb70A8dRFheHjiySQATBZk0nl9MHPkBEWUoEtYjyrPFNwGzfdlD37Zdu98KCv%2BMmD2BYpUCvcST39e0%2BS1Wr249FAAg7mPzWrS5NstEbE0xrsiA6QN1PfRFLnhr%2BspxVJTlY8Mw1DqNXeyCQFREEXz9cHB0QOev73QaNhOF4B%2B45PHFHFgDhJTqjuubJFqX1KQco7NTTuW8kq95k2G4eLEGzM7lfItnjNeTKcOfV%2FT8hOuV77A9IK0XjgMpCO0ZiuV3L%2F6njCFAOmucGB3OII5XgCXEJTDdZLElVbu3Vz0fWexvL30k0B6ggBACOmIUBAEUKX0dDTvW7RCYcdZPq6n%2FSsQnUO2RuyBRgQ9Rc5mMvJ6CNIj1nXfd9qWAsCkaZzJAk1L8UjVqY737dSjfCGrPHWqXL32Q0mB%2F2BXnke00WaEYv2aTzAbnuV5pcWkDGAAGJmhSafh6hjr%2BW2SVYHrP7bb%2BOdPW%2FUgflGlTM2gaK%2Ft7tp6%2BN6yixdN89DcIwGktIFPABfNbwoQqQWEUnDJzg1g0jDeK5p7Kp7nensXFI7uyAr%2FLyM7fYLnpa6LYScE8vDnot5hrKlslm%2BfE3nVxJgO4o3KcYu%2FF8XM8yFQ27n%2F65Te%2FzKl3Jhpjj6TCIDneRD5%2FItxr1vdkALw7p1qfeWPpjHxMtsXaPxu6FLc%2BrnbSB1r7fcrlr36nqwMzQfnplJDryQCGOh%2FbLjhcM%2FEvQ4Pdund9xRV5m1LfTXaF%2BK9gsLGB9nsgddcz8thM%2FarPzYM8%2FFazf9sMFaU%2Fi%2FwvNANwEhPvUGR8ozn7d%2BiDKXixtKpbHp81nV9E7puRy31ixKUbOe%2Fv3Ud891ghhDrL5Z975eaOvV%2BCNRp0Gfz%2BcJjDABdTwlpdfKbId0t5XYAcHz5D5ZVtWUp9%2Flog2L7PgVJqZx0HOE5Cqghemv1%2Bt%2FeGBmZ%2BdB2yNN72UEpnzXG32YADA186i3bIpPxMhuKrFK%2Fd77JUnbkKbYvRJlC8DzKSZK76Lq1he2dKy%2BZuSfesSz5a2xHDbLJ%2BJaqdv5H4EUY%2BzbG2m9HgN7mg81bfw4W1uu7AjvHaqDhqF%2FZ3Fq5XFy%2FcESSDsx5fvZ7wLEsNfXk%2BjlVHfpSCOB%2FAQAA%2F%2F8zd8orZc2N9AAAAABJRU5ErkJggg%3D%3D
[fossa-badge]: https://app.fossa.com/api/projects/git%2Bgithub.com%2Fcloudnative-pg%2Fcloudnative-pg.svg?type=small
[fossa]: https://app.fossa.com/projects/git%2Bgithub.com%2Fcloudnative-pg%2Fcloudnative-pg?ref=badge_small
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[francoismichel/ssh3]]></title>
            <link>https://github.com/francoismichel/ssh3</link>
            <guid>https://github.com/francoismichel/ssh3</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[SSH3: faster and rich secure shell using HTTP/3, checkout our article here: https://arxiv.org/abs/2312.08396 and our Internet-Draft: https://datatracker.ietf.org/doc/draft-michel-ssh3/]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/francoismichel/ssh3">francoismichel/ssh3</a></h1>
            <p>SSH3: faster and rich secure shell using HTTP/3, checkout our article here: https://arxiv.org/abs/2312.08396 and our Internet-Draft: https://datatracker.ietf.org/doc/draft-michel-ssh3/</p>
            <p>Language: Go</p>
            <p>Stars: 4,842</p>
            <p>Forks: 110</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>
&lt;div align=center&gt;
&lt;img src=&quot;resources/figures/ssh3.png&quot; style=&quot;display: block; width: 60%&quot;&gt;
&lt;/div&gt;

&gt; [!NOTE]
&gt; SSH3 is probably going to change its name. It is still the SSH Connection Protocol (RFC4254) running on top of HTTP/3 Extended connect, but the required changes are heavy and
&gt; too distant from the philosophy of popular SSH implementations to be considered for integration. The [specification draft](https://datatracker.ietf.org/doc/draft-michel-remote-terminal-http3/) has already been renamed (&quot;Remote Terminals over HTTP/3&quot;),
&gt; but we need some time to come up with a nice permanent name.

# SSH3: faster and rich secure shell using HTTP/3
SSH3 is a complete revisit of the SSH
protocol, mapping its semantics on top of the HTTP mechanisms. It comes from our research work and we (researchers) recently proposed it as an [Internet-Draft](https://www.ietf.org/how/ids/) ([draft-michel-remote-terminal-http3-00](https://datatracker.ietf.org/doc/draft-michel-remote-terminal-http3/)).

In a nutshell, SSH3 uses [QUIC](https://datatracker.ietf.org/doc/html/rfc9000)+[TLS1.3](https://datatracker.ietf.org/doc/html/rfc8446) for
secure channel establishment and the [HTTP Authorization](https://www.rfc-editor.org/rfc/rfc9110.html#name-authorization) mechanisms for user authentication.
Among others, SSH3 allows the following improvements:
- Significantly faster session establishment
- New HTTP authentication methods such as [OAuth 2.0](https://datatracker.ietf.org/doc/html/rfc6749) and [OpenID Connect](https://openid.net/specs/openid-connect-core-1_0.html) in addition to classical SSH authentication
- Robustness to port scanning attacks: your SSH3 server can be made **invisible** to other Internet users
- UDP port forwarding in addition to classical TCP port forwarding
- All the features allowed by the modern QUIC protocol: including connection migration (soon) and multipath connections

&gt; [!TIP]
&gt; Quickly want to get started ? Checkout how to [install SSH3](#installing-ssh3). You will learn to [setup an SSH3 server](#deploying-an-ssh3-server) and [use the SSH3 client](#using-the-ssh3-client).

## ⚡ SSH3 is faster
Faster for session establishment, not throughput ! SSH3 offers a significantly faster session establishment than SSHv2. Establishing a new session with SSHv2 can take 5 to 7 network round-trip times, which can easily be noticed by the user. SSH3 only needs 3 round-trip times. The keystroke latency in a running session is unchanged.

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;resources/figures/ssh3_100ms_rtt.gif&quot;/&gt;
&lt;i&gt;SSH3 (top) VS SSHv2 (bottom) session establishement with a 100ms ping towards the server.&lt;/i&gt;
&lt;/p&gt;

## 🔒 SSH3 security
While SSHv2 defines its own protocols for user authentication and secure channel establishment, SSH3 relies on the robust and time-tested mechanisms of TLS 1.3, QUIC and HTTP. These protocols are already extensively used to secure security-critical applications on the Internet such as e-commerce and Internet banking.

SSH3 already implements the common password-based and public-key (RSA and EdDSA/ed25519) authentication methods. It also supports new authentication methods such as OAuth 2.0 and allows logging in to your servers using your Google/Microsoft/Github accounts.

### 🧪 SSH3 is still experimental
While SSH3 shows promise for faster session establishment, it is still at an early proof-of-concept stage. As with any new complex protocol, **expert cryptographic review over an extended timeframe is required before reasonable security conclusions can be made**.

We are developing SSH3 as an open source project to facilitate community feedback and analysis. However, we **cannot yet endorse its appropriateness for production systems** without further peer review. Please collaborate with us if you have relevant expertise!

### 🥷 Do not deploy the SSH3 server on your production servers for now
Given the current prototype state, we advise *testing SSH3 in sandboxed environments or private networks*. Be aware that making experimental servers directly Internet-accessible could introduce risk before thorough security vetting.

While [hiding](#-your-ssh3-public-server-can-be-hidden) servers behind secret paths has potential benefits, it does not negate the need for rigorous vulnerability analysis before entering production. We are excited by SSH3&#039;s future possibilities but encourage additional scrutiny first.

## 🥷 Your SSH3 public server can be hidden
Using SSH3, you can avoid the usual stress of scanning and dictionary attacks against your SSH server. Similarly to your secret Google Drive documents, your SSH3 server can be hidden behind a secret link and only answer to authentication attempts that made an HTTP request to this specific link, like the following:

    ssh3-server -bind 192.0.2.0:443 -url-path &lt;my-long-secret&gt;

By replacing `&lt;my-long-secret&gt;` by, let&#039;s say, the random value `M3MzkxYWMxMjYxMjc5YzJkODZiMTAyMjU`, your SSH3 server will only answer to SSH3 connection attempts made to the URL `https://192.0.2.0:443/M3MzkxYWMxMjYxMjc5YzJkODZiMTAyMjU` and it will respond a `404 Not Found` to other requests. Attackers and crawlers on the Internet can therefore not detect the presence of your SSH3 server. They will only see a simple web server answering 404 status codes to every request.

**NOTE WELL**: placing your SSH3 server behind a secret URL may reduce the impact of scanning attacks but will and must *never* replace classical authentication mechanisms. The secret link should only be used to avoid your host to be discovered. Knowing the secret URL should not grant someone access to your server. Use the classical authentication mechanisms described above to protect your server. 

## 💐 SSH3 is already feature-rich
SSH3 provides new feature that could not be provided by the SSHv2 protocol.

### Brand new features
- **UDP port forwarding**: you can now access your QUIC, DNS, RTP or any UDP-based server that are only reachable from your SSH3 host.
UDP packets are forwarded using QUIC datagrams.
- **X.509 certificates**: you can now use your classical HTTPS certificates to authenticate your SSH3 server. This mechanism is more secure than the classical SSHv2 host key mechanism. Certificates can be obtained easily using LetsEncrypt for instance.
- **Hiding** your server behind a secret link.
- **Keyless** secure user authentication using **OpenID Connect**. You can connect to your SSH3 server using the SSO of your company or your Google/Github account, and you don&#039;t need to copy the public keys of your users anymore.

### Famous OpenSSH features implemented
This SSH3 implementation already provides many of the popular features of OpenSSH, so if you are used to OpenSSH, the process of adopting SSH3 will be smooth. Here is a list of some OpenSSH features that SSH3 also implements:
- Parses `~/.ssh/authorized_keys` on the server
- Certificate-based server authentication
- `known_hosts` mechanism when X.509 certificates are not used.
- Automatically using the `ssh-agent` for public key authentication
- SSH agent forwarding to use your local keys on your remote server
- Direct TCP port forwarding (reverse port forwarding will be implemented in the future)
- Proxy jump (see the `-proxy-jump` parameter). If A is an SSH3 client and B and C are both SSH3 servers, you can connect from A to C using B as a gateway/proxy. The proxy uses UDP forwarding to forward the QUIC packets from A to C, so B cannot decrypt the traffic A&lt;-&gt;C SSH3 traffic.
- Parses `~/.ssh/config` on the client and handles the `Hostname`, `User`, `Port` and `IdentityFile` config options (the other options are currently ignored). Also parses a new `UDPProxyJump` that behaves similarly to OpenSSH&#039;s `ProxyJump`.

## 🙏 Community support
Help us progress SSH3 responsibly! We welcome capable security researchers to review our codebase and provide feedback. Please also connect us with relevant standards bodies to potentially advance SSH3 through the formal IETF/IRTF processes over time.

With collaborative assistance, we hope to iteratively improve SSH3 towards safe production readiness. But we cannot credibly make definitive security claims without evidence of extensive expert cryptographic review and adoption by respected security authorities. Let&#039;s work together to realize SSH3&#039;s possibilities!

## Installing SSH3
You can either download the last [release binaries](https://github.com/francoismichel/ssh3/releases),
[install it using `go install`](#installing-ssh3-and-ssh3-server-using-go-install) or generate these binaries yourself by compiling the code from source.

&gt; [!TIP]
&gt; SSH3 is still experimental and is the fruit of a research work. If you are afraid of deploying publicly a new SSH3 server, you can use the
&gt; [secret path](#-your-ssh3-public-server-can-be-hidden) feature of SSH3 to hide it behing a secret URL.

### Installing ssh3 and ssh3-server using Go install
```bash
go install github.com/francoismichel/ssh3/cmd/...@latest
```



### Compiling SSH3 from source
You need a recent [Golang](https://go.dev/dl/) version to do this.
Downloading the source code and compiling the binaries can be done with the following steps:

```bash
git clone https://github.com/francoismichel/ssh3    # clone the repo
cd ssh3
go build -o ssh3 cmd/ssh3/main.go                        # build the client
CGO_ENABLED=1 go build -o ssh3-server cmd/ssh3-server/main.go   # build the server, requires having gcc installed
```

If you have root/sudo privileges and you want to make ssh3 accessible to all you users,
you can then directly copy the binaries to `/usr/bin`:

```bash
cp ssh3 /usr/bin/ &amp;&amp; cp ssh3-server /usr/bin
```

Otherwise, you can simply add the executables to your `PATH` environment variable by adding
the following line at the end of your `.bashrc` or equivalent:

```bash
export PATH=$PATH:/path/to/the/ssh3/directory
```

### Deploying an SSH3 server
Before connecting to your host, you need to deploy an SSH3 server on it. There is currently
no SSH3 daemon, so right now, you will have to run the `ssh3-server` executable in background
using `screen` or a similar utility.


&gt; [!NOTE]
&gt; As SSH3 runs on top of HTTP/3, a server needs an X.509 certificate and its corresponding private key. Public certificates can be generated automatically for your public domain name through Let&#039;s Encrypt using the `-generate-public-cert` command-line argument on the server. If you do not want to generate a certificate signed by a real certificate authority or if you don&#039;t have any public domain name, you can generate a self-signed one using the `-generate-selfsigned-cert` command-line argument. Self-signed certificates provide you with similar security guarantees to SSHv2&#039;s host keys mechanism, with the same security issue: you may be vulnerable to machine-in-the-middle attacks during your first connection to your server. Using real certificates signed by public certificate authorities such as Let&#039;s Encrypt avoids this issue.


Here is the usage of the `ssh3-server` executable:

```
Usage of ./ssh3-server:
  -bind string
        the address:port pair to listen to, e.g. 0.0.0.0:443 (default &quot;[::]:443&quot;)
  -cert string
        the filename of the server certificate (or fullchain) (default &quot;./cert.pem&quot;)
  -key string
        the filename of the certificate private key (default &quot;./priv.key&quot;)
  -enable-password-login
        if set, enable password authentication (disabled by default)
  -generate-public-cert value
        Automatically produce and use a valid public certificate usingLet&#039;s Encrypt for the provided domain name. The flag can be used several times to generate several certificates.If certificates have already been generated previously using this flag, they will simply be reused without being regenerated. The public certificates are automatically renewed as long as the server is running. Automatically-generated IP public certificates are not available yet.
  -generate-selfsigned-cert
        if set, generates a self-self-signed cerificate and key that will be stored at the paths indicated by the -cert and -key args (they must not already exist)
  -url-path string
        the secret URL path on which the ssh3 server listens (default &quot;/ssh3-term&quot;)
  -v    verbose mode, if set
  -version
        if set, displays the software version on standard output and exit
```

The following command starts a public SSH3 server on port 443 with a valid Let&#039;s Encrypt public certificate
for domain `my-domain.example.org` and answers to new sessions requests querying the `/ssh3` URL path:

    ssh3-server -generate-public-cert my-domain.example.org -url-path /ssh3

If you don&#039;t have a public domain name (i.e. only an IP address), you can either use an existing certificate
for your IP address using the `-cert` and `-key` arguments or generate a self-signed certificate using the
`-generate-selfsigned-cert` argument.

If you have existing certificates and keys, you can run the server as follows to use them=

    ssh3-server -cert /path/to/cert/or/fullchain -key /path/to/cert/private/key -url-path /ssh3

&gt; [!NOTE]
&gt; Similarly to OpenSSH, the server must be run with root priviledges to log in as other users.

#### Authorized keys and authorized identities
By default, the SSH3 server will look for identities in the `~/.ssh/authorized_keys` and `~/.ssh3/authorized_identities` files for each user.
`~/.ssh3/authorized_identities` allows new identities such as OpenID Connect (`oidc`) discussed [below](#openid-connect-authentication-still-experimental).
Popular key types such as `rsa`, `ed25519` and keys in the OpenSSH format can be used.

### Using the SSH3 client
Once you have an SSH3 server running, you can connect to it using the SSH3 client similarly to what
you did with your classical SSHv2 tool.

Here is the usage of the `ssh3` executable:

```
Usage of ssh3:
  -pubkey-for-agent string
        if set, use an agent key whose public key matches the one in the specified path
  -privkey string
        private key file
  -use-password
        if set, do classical password authentication
  -forward-agent
        if set, forwards ssh agent to be used with sshv2 connections on the remote host
  -forward-tcp string
        if set, take a localport/remoteip@remoteport forwarding localhost@localport towards remoteip@remoteport
  -forward-udp string
        if set, take a localport/remoteip@remoteport forwarding localhost@localport towards remoteip@remoteport
  -proxy-jump string
    	if set, performs a proxy jump using the specified remote host as proxy
  -insecure
        if set, skip server certificate verification
  -keylog string
        Write QUIC TLS keys and master secret in the specified keylog file: only for debugging purpose
  -use-oidc string
        if set, force the use of OpenID Connect with the specified issuer url as parameter
  -oidc-config string
        OpenID Connect json config file containing the &quot;client_id&quot; and &quot;client_secret&quot; fields needed for most identity providers
  -do-pkce
        if set, perform PKCE challenge-response with oidc
  -v    if set, enable verbose mode
```

#### Private-key authentication
You can connect to your SSH3 server at my-server.example.org listening on `/my-secret-path` using the private key located in `~/.ssh/id_rsa` with the following command:

      ssh3 -privkey ~/.ssh/id_rsa username@my-server.example.org/my-secret-path

#### Agent-based private key authentication
The SSH3 client works with the OpenSSH agent and uses the classical `SSH_AUTH_SOCK` environment variable to
communicate with this agent. Similarly to OpenSSH, SSH3 will list the keys provided by the SSH agent
and connect using the first key listen by the agent by default.
If you want to specify a specific key to use with the agent, you can either specify the private key
directly with the `-privkey` argument like above, or specify the corresponding public key using the
`-pubkey-for-agent` argument. This allows you to authenticate in situations where only the agent has
a direct access to the private key but you only have access to the public key.

#### Password-based authentication
While discouraged, you can connect to your server using passwords (if explicitly enabled on the `ssh3-server`)
with the following command:

      ssh3 -use-password username@my-server.example.org/my-secret-path

#### Config-based session establishment
`ssh3` parses your OpenSSH config. Currently, it only handles the `Hostname`; `User`, `Port` and `IdentityFile` OpenSSH options.
It also adds new option only used by SSH3, such as `URLPath` or `UDPProxyJump`. `URLPath` allows you to omit the secret URL path in your
SSH3 command. `UDPProxyJump` allows you to perform SSH3 (#proxy-jump)[Proxy Jump] and has the same meaning as the `-proxy-jump` command-line argument.
Let&#039;s say you have the following lines in your OpenSSH config located in `~/.ssh/config` :
```
IgnoreUnknown URLPath
Host my-server
  HostName 192.0.2.0
  User username
  IdentityFile ~/.ssh/id_rsa
  URLPath /my-secret-path
```

Similarly to what OpenSSH does, the following `ssh3` command will connect you to the SSH3 server running on 192.0.2.0 on UDP port 443 using public key authentication with the private key located in `.ssh/id_rsa` :

      ssh3 my-server/my-secret-path

If you do not want a config-based utilization of SSH3, you can read the sections below to see how to use the CLI parameters of `ssh3`.

#### OpenID Connect authentication (still experimental)
This feature allows you to connect using an external identity provider such as the one
of your company or any other provider that implements the OpenID Connect standard, such as Google Identity,
Github or Microsoft Entra. The authentication flow is illustrated in the GIF below.

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;resources/figures/ssh3_oidc.gif&quot; width=75%&gt;

*Secure connection without private key using a Google account.*
&lt;/div&gt;

The way it connects to your identity provider is configured in a file named `~/.ssh3/oidc_config.json`.
Below is an example `config.json` file for use with a Google account. This configuration file is an array
and can contain several identity providers configurations.
```json
[
    {
        &quot;issuer_url&quot;: &quot;https://accounts.google.com&quot;,
        &quot;client_id&quot;: &quot;&lt;your_client_id&gt;&quot;,
        &quot;client_secret&quot;: &quot;&lt;your_client_secret&gt;&quot;
    }
]
```
This might change in the future, but currently, to make this feature work with your Google account, you will need to setup a new experimental application in your Google Cloud console and add your email as authorized users.
This will provide you with a `client_id` and a `client_secret` that you can then set in your `~/.ssh3/oidc_config.json`. On the server side, you just have to add the following line in your `~/.ssh3/authorized_identities`:

```
oidc &lt;client_id&gt; https://accounts.google.com &lt;email&gt;
```
We currently consider removing the need of setting the client_id in the `authorized_identities` file in the future.

#### Proxy jump
It is often the case that some SSH hosts can only be accessed through a gateway. SSH3 allows you to perform a Proxy Jump similarly to what is proposed by OpenSSH.
You can connect from A to C using B as a gateway/proxy. B and C must both be running a valid SSH3 server. This works by establishing UDP port forwarding on B to forward QUIC packets from A to C.
The connection from A to C is therefore fully end-to-end and B cannot decrypt or alter the SSH3 traffic between A and C.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[spf13/viper]]></title>
            <link>https://github.com/spf13/viper</link>
            <guid>https://github.com/spf13/viper</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[Go configuration with fangs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/spf13/viper">spf13/viper</a></h1>
            <p>Go configuration with fangs</p>
            <p>Language: Go</p>
            <p>Stars: 29,406</p>
            <p>Forks: 2,082</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&gt; ## Viper v2 Feedback
&gt;
&gt; Viper is heading towards v2 and we would love to hear what _**you**_ would
&gt; like to see in it. Share your thoughts here:
&gt; https://forms.gle/R6faU74qPRPAzchZ9
&gt;
&gt; **Thank you!**

![viper logo](https://github.com/user-attachments/assets/acae9193-2974-41f3-808d-2d433f5ada5e)

[![Mentioned in Awesome Go](https://awesome.re/mentioned-badge-flat.svg)](https://github.com/avelino/awesome-go#configuration)
[![run on repl.it](https://repl.it/badge/github/sagikazarmark/Viper-example)](https://repl.it/@sagikazarmark/Viper-example#main.go)

[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/spf13/viper/ci.yaml?branch=master&amp;style=flat-square)](https://github.com/spf13/viper/actions?query=workflow%3ACI)
[![Join the chat at https://gitter.im/spf13/viper](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/spf13/viper?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge)
[![Go Report Card](https://goreportcard.com/badge/github.com/spf13/viper?style=flat-square)](https://goreportcard.com/report/github.com/spf13/viper)
![Go Version](https://img.shields.io/badge/go%20version-%3E=1.23-61CFDD.svg?style=flat-square)
[![PkgGoDev](https://pkg.go.dev/badge/mod/github.com/spf13/viper)](https://pkg.go.dev/mod/github.com/spf13/viper)

**Go configuration with fangs!**

Many Go projects are built using Viper including:

* [Hugo](http://gohugo.io)
* [EMC RexRay](http://rexray.readthedocs.org/en/stable/)
* [Imgur’s Incus](https://github.com/Imgur/incus)
* [Nanobox](https://github.com/nanobox-io/nanobox)/[Nanopack](https://github.com/nanopack)
* [Docker Notary](https://github.com/docker/Notary)
* [BloomApi](https://www.bloomapi.com/)
* [doctl](https://github.com/digitalocean/doctl)
* [Clairctl](https://github.com/jgsqware/clairctl)
* [Mercure](https://mercure.rocks)
* [Meshery](https://github.com/meshery/meshery)
* [Bearer](https://github.com/bearer/bearer)
* [Coder](https://github.com/coder/coder)
* [Vitess](https://vitess.io/)


## Install

```shell
go get github.com/spf13/viper
```

&gt; **NOTE** Viper uses [Go Modules](https://go.dev/wiki/Modules) to manage dependencies.


## Why use Viper?

Viper is a complete configuration solution for Go applications including
[12-Factor apps](https://12factor.net/#the_twelve_factors). It is designed to
work within any application, and can handle all types of configuration needs
and formats. It supports:

* setting defaults
* setting explicit values
* reading config files
* dynamic discovery of config files across multiple locations
* reading from environment variables
* reading from remote systems (e.g. Etcd or Consul)
* reading from command line flags
* reading from buffers
* live watching and updating configuration
* aliasing configuration keys for easy refactoring

Viper can be thought of as a registry for all of your applications&#039;
configuration needs.


## Putting Values in Viper

Viper can read from multiple configuration sources and merges them together
into one set of configuration keys and values.

Viper uses the following precedence for merging:

 * explicit call to `Set`
 * flags
 * environment variables
 * config files
 * external key/value stores
 * defaults

&gt; **NOTE** Viper configuration keys are case insensitive.

### Reading Config Files

Viper requires minimal configuration to load config files. Viper currently supports:

* JSON
* TOML
* YAML
* INI
* envfile
* Java Propeties

A single Viper instance only supports a single configuration file, but multiple
paths may be searched for one.

Here is an example of how to use Viper to search for and read a configuration
file. At least one path should be provided where a configuration file is
expected.

```go
// Name of the config file without an extension (Viper will intuit the type
// from an extension on the actual file)
viper.SetConfigName(&quot;config&quot;)

// Add search paths to find the file
viper.AddConfigPath(&quot;/etc/appname/&quot;)
viper.AddConfigPath(&quot;$HOME/.appname&quot;)
viper.AddConfigPath(&quot;.&quot;)

// Find and read the config file
err := viper.ReadInConfig()

// Handle errors
if err != nil {
	panic(fmt.Errorf(&quot;fatal error config file: %w&quot;, err))
}
```

You can handle the specific case where no config file is found.

```go
var fileLookupError viper.FileLookupError
if err := viper.ReadInConfig(); err != nil {
    if errors.As(err, &amp;fileLookupError) {
        // Indicates an explicitly set config file is not found (such as with
        // using `viper.SetConfigFile`) or that no config file was found in
        // any search path (such as when using `viper.AddConfigPath`)
    } else {
        // Config file was found but another error was produced
    }
}

// Config file found and successfully parsed
```

&gt; **NOTE (since 1.6)** You can also have a file without an extension and
&gt; specify the format programmatically, which is useful for files that naturally
&gt; have no extension (e.g., `.bashrc`).

### Writing Config Files

At times you may want to store all configuration modifications made during run
time.

```go
// Writes current config to the path set by `AddConfigPath` and `SetConfigName`
viper.WriteConfig()
viper.SafeWriteConfig() // Like the above, but will error if the config file exists

// Writes current config to a specific place
viper.WriteConfigAs(&quot;/path/to/my/.config&quot;)

// Will error since it has already been written
viper.SafeWriteConfigAs(&quot;/path/to/my/.config&quot;)

viper.SafeWriteConfigAs(&quot;/path/to/my/.other_config&quot;)
```

As a rule of the thumb, methods prefixed with `Safe` won&#039;t overwrite any
existing file, while other methods will.

### Watching and Re-reading Config Files

Gone are the days of needing to restart a server to have a config take
effect--Viper powered applications can read an update to a config file while
running and not miss a beat.

It&#039;s also possible to provide a function for Viper to run each time a change
occurs.

```go
// All config paths must be defined prior to calling `WatchConfig()`
viper.AddConfigPath(&quot;$HOME/.appname&quot;)

viper.OnConfigChange(func(e fsnotify.Event) {
	fmt.Println(&quot;Config file changed:&quot;, e.Name)
})

viper.WatchConfig()
```

### Reading Config from `io.Reader`

Viper predefines many configuration sources but you can also implement your own
required configuration source.

```go
viper.SetConfigType(&quot;yaml&quot;)

var yamlExample = []byte(`
hacker: true
hobbies:
- skateboarding
- snowboarding
- go
name: steve
`)

viper.ReadConfig(bytes.NewBuffer(yamlExample))

viper.Get(&quot;name&quot;) // &quot;steve&quot;
```

### Setting Defaults

A good configuration system will support default values, which are used if a
key hasn&#039;t been set in some other way.

Examples:

```go
viper.SetDefault(&quot;ContentDir&quot;, &quot;content&quot;)
viper.SetDefault(&quot;LayoutDir&quot;, &quot;layouts&quot;)
viper.SetDefault(&quot;Taxonomies&quot;, map[string]string{&quot;tag&quot;: &quot;tags&quot;, &quot;category&quot;: &quot;categories&quot;})
```

### Setting Overrides

Viper allows explict setting of configuration, such as from your own
application logic.

```go
viper.Set(&quot;verbose&quot;, true)
viper.Set(&quot;host.port&quot;, 5899) // Set an embedded key
```

### Registering and Using Aliases

Aliases permit a single value to be referenced by multiple keys

```go
viper.RegisterAlias(&quot;loud&quot;, &quot;Verbose&quot;)

viper.Set(&quot;verbose&quot;, true) // Same result as next line
viper.Set(&quot;loud&quot;, true)    // Same result as prior line

viper.GetBool(&quot;loud&quot;)    // true
viper.GetBool(&quot;verbose&quot;) // true
```

### Working with Environment Variables

Viper has full support for environment variables.

&gt; **NOTE** Unlike other configuration sources, environment variables are case
&gt; sensitive.

```go
// Tells Viper to use this prefix when reading environment variables
viper.SetEnvPrefix(&quot;spf&quot;)

// Viper will look for &quot;SPF_ID&quot;, automatically uppercasing the prefix and key
viper.BindEnv(&quot;id&quot;)

// Alternatively, we can search for any environment variable prefixed and load
// them in
viper.AutomaticEnv()

os.Setenv(&quot;SPF_ID&quot;, &quot;13&quot;)

id := viper.Get(&quot;id&quot;) // 13
```

* By default, empty environment variables are considered unset and will fall back to
  the next configuration source, unless `AllowEmptyEnv` is used.
* Viper does not &quot;cache&quot; environment variables--the value will be read each
  time it is accessed.
* `SetEnvKeyReplacer` and `EnvKeyReplacer` allow you to rewrite environment
  variable keys, which is useful to merge SCREAMING_SNAKE_CASE environment
  variables with kebab-cased configuration values from other sources.

### Working with Flags

Viper has the ability to bind to flags. Specifically, Viper supports
[pflag](https://github.com/spf13/pflag/) as used in the
[Cobra](https://github.com/spf13/cobra) library.

Like environment variables, the value is not set when the binding method is
called, but when it is accessed.

For individual flags, the `BindPFlag` method provides this functionality.

```go
serverCmd.Flags().Int(&quot;port&quot;, 1138, &quot;Port to run Application server on&quot;)

viper.BindPFlag(&quot;port&quot;, serverCmd.Flags().Lookup(&quot;port&quot;))
```

You can also bind an existing set of pflags.

```go
pflag.Int(&quot;flagname&quot;, 1234, &quot;help message for flagname&quot;)
pflag.Parse()

viper.BindPFlags(pflag.CommandLine)

i := viper.GetInt(&quot;flagname&quot;) // Retrieve values from viper instead of pflag
```

The standard library [flag](https://golang.org/pkg/flag/) package is not
directly supported, but may be parsed through pflag.

```go
package main

import (
	&quot;flag&quot;

	&quot;github.com/spf13/pflag&quot;
)

func main() {
	// Using standard library &quot;flag&quot; package
	flag.Int(&quot;flagname&quot;, 1234, &quot;help message for flagname&quot;)

    // Pass standard library flags to pflag
	pflag.CommandLine.AddGoFlagSet(flag.CommandLine)
	pflag.Parse()

    // Viper takes over
	viper.BindPFlags(pflag.CommandLine)
}
```

Use of pflag may be avoided entirely by implementing the `FlagValue` and
`FlagValueSet` interfaces.

```go
// Implementing FlagValue

type myFlag struct {}
func (f myFlag) HasChanged() bool { return false }
func (f myFlag) Name() string { return &quot;my-flag-name&quot; }
func (f myFlag) ValueString() string { return &quot;my-flag-value&quot; }
func (f myFlag) ValueType() string { return &quot;string&quot; }

viper.BindFlagValue(&quot;my-flag-name&quot;, myFlag{})

// Implementing FlagValueSet

type myFlagSet struct {
	flags []myFlag
}
func (f myFlagSet) VisitAll(fn func(FlagValue)) {
	for _, flag := range flags {
		fn(flag)
	}
}

fSet := myFlagSet{
	flags: []myFlag{myFlag{}, myFlag{}},
}
viper.BindFlagValues(&quot;my-flags&quot;, fSet)
```

### Remote Key/Value Store Support

To enable remote support in Viper, do a blank import of the `viper/remote`
package.

```go
import _ &quot;github.com/spf13/viper/remote&quot;
```

Viper supports the following remote key/value stores. Examples for each are
provided below.

* Etcd and Etcd3
* Consul
* Firestore
* NATS

Viper will read a config string retrieved from a path in a key/value store.

Viper supports multiple hosts separated by `;`. For example:
`http://127.0.0.1:4001;http://127.0.0.1:4002`.

#### Encryption

Viper uses [crypt](https://github.com/sagikazarmark/crypt) to retrieve
configuration from the key/value store, which means that you can store your
configuration values encrypted and have them automatically decrypted if you
have the correct GPG keyring. Encryption is optional.

Crypt has a command-line helper that you can use to put configurations in your
key/value store.

```bash
$ go get github.com/sagikazarmark/crypt/bin/crypt
$ crypt set -plaintext /config/hugo.json /Users/hugo/settings/config.json
$ crypt get -plaintext /config/hugo.json
```

See the Crypt documentation for examples of how to set encrypted values, or
how to use Consul.

### Remote Key/Value Store Examples (Unencrypted)

#### etcd

```go
viper.AddRemoteProvider(&quot;etcd&quot;, &quot;http://127.0.0.1:4001&quot;,&quot;/config/hugo.json&quot;)
viper.SetConfigType(&quot;json&quot;) // because there is no file extension in a stream of bytes, supported extensions are &quot;json&quot;, &quot;toml&quot;, &quot;yaml&quot;, &quot;yml&quot;, &quot;properties&quot;, &quot;props&quot;, &quot;prop&quot;, &quot;env&quot;, &quot;dotenv&quot;
err := viper.ReadRemoteConfig()
```

#### etcd3

```go
viper.AddRemoteProvider(&quot;etcd3&quot;, &quot;http://127.0.0.1:4001&quot;,&quot;/config/hugo.json&quot;)
viper.SetConfigType(&quot;json&quot;) // because there is no file extension in a stream of bytes, supported extensions are &quot;json&quot;, &quot;toml&quot;, &quot;yaml&quot;, &quot;yml&quot;, &quot;properties&quot;, &quot;props&quot;, &quot;prop&quot;, &quot;env&quot;, &quot;dotenv&quot;
err := viper.ReadRemoteConfig()
```

#### Consul

Given a Consul key `MY_CONSUL_KEY` with the value:

```json
{
    &quot;port&quot;: 8080,
    &quot;hostname&quot;: &quot;myhostname.com&quot;
}
```

```go
viper.AddRemoteProvider(&quot;consul&quot;, &quot;localhost:8500&quot;, &quot;MY_CONSUL_KEY&quot;)
viper.SetConfigType(&quot;json&quot;) // Need to explicitly set this to json
err := viper.ReadRemoteConfig()

fmt.Println(viper.Get(&quot;port&quot;)) // 8080
```

#### Firestore

```go
viper.AddRemoteProvider(&quot;firestore&quot;, &quot;google-cloud-project-id&quot;, &quot;collection/document&quot;)
viper.SetConfigType(&quot;json&quot;) // Config&#039;s format: &quot;json&quot;, &quot;toml&quot;, &quot;yaml&quot;, &quot;yml&quot;
err := viper.ReadRemoteConfig()
```

Of course, you&#039;re allowed to use `SecureRemoteProvider` also.

#### NATS

```go
viper.AddRemoteProvider(&quot;nats&quot;, &quot;nats://127.0.0.1:4222&quot;, &quot;myapp.config&quot;)
viper.SetConfigType(&quot;json&quot;)
err := viper.ReadRemoteConfig()
```

### Remote Key/Value Store Examples (Encrypted)

```go
viper.AddSecureRemoteProvider(&quot;etcd&quot;,&quot;http://127.0.0.1:4001&quot;,&quot;/config/hugo.json&quot;,&quot;/etc/secrets/mykeyring.gpg&quot;)
viper.SetConfigType(&quot;json&quot;) // because there is no file extension in a stream of bytes,  supported extensions are &quot;json&quot;, &quot;toml&quot;, &quot;yaml&quot;, &quot;yml&quot;, &quot;properties&quot;, &quot;props&quot;, &quot;prop&quot;, &quot;env&quot;, &quot;dotenv&quot;
err := viper.ReadRemoteConfig()
```

### Watching Key/Value Store Changes

```go
// Alternatively, you can create a new viper instance
var runtime_viper = viper.New()

runtime_viper.AddRemoteProvider(&quot;etcd&quot;, &quot;http://127.0.0.1:4001&quot;, &quot;/config/hugo.yml&quot;)
runtime_viper.SetConfigType(&quot;yaml&quot;) // because there is no file extension in a stream of bytes, supported extensions are &quot;json&quot;, &quot;toml&quot;, &quot;yaml&quot;, &quot;yml&quot;, &quot;properties&quot;, &quot;props&quot;, &quot;prop&quot;, &quot;env&quot;, &quot;dotenv&quot;

// Read from remote config the first time
err := runtime_viper.ReadRemoteConfig()

// Unmarshal config
runtime_viper.Unmarshal(&amp;runtime_conf)

// Open a goroutine to watch remote changes forever
go func(){
	for {
		time.Sleep(time.Second * 5) // delay after each request

		// Currently, only tested with Etcd support
		err := runtime_viper.WatchRemoteConfig()
		if err != nil {
			log.Errorf(&quot;unable to read remote config: %v&quot;, err)
			continue
		}

		// Unmarshal new config into our runtime config struct
		runtime_viper.Unmarshal(&amp;runtime_conf)
	}
}()
```

## Getting Values From Viper

The simplest way to retrieve configuration values from Viper is to use `Get*`
functions. `Get` will return an any type, but specific types may be retrieved
with `Get&lt;Type&gt;` functions.

Note that each `Get*` function will return a zero value if it’s key is not
found. To check if a key exists, use the `IsSet` method.

Nested keys use `.` as a delimiter and numbers for array indexes. Given the
following configuration:

```jsonc
{
    &quot;datastore&quot;: {
        &quot;metric&quot;: {
            &quot;host&quot;: &quot;127.0.0.1&quot;,
            &quot;ports&quot;: [
                5799,
                6029
            ]
        }
    }
}

```

```go
GetString(&quot;datastore.metric.host&quot;) // &quot;127.0.0.1&quot;
GetInt(&quot;host.ports.1&quot;) // 6029
```

&gt; **NOTE** Viper _does not_ deep merge configuration values. Complex values
&gt; that are overridden will be entirely replaced.

If there exists a key that matches the delimited key path, its value will be
returned instead.

```jsonc
{
    &quot;datastore.metric.host&quot;: &quot;0.0.0.0&quot;,
    &quot;datastore&quot;: {
        &quot;metric&quot;: {
            &quot;host&quot;: &quot;127.0.0.1&quot;
        }
    }
}
```

```go
GetString(&quot;datastore.metric.host&quot;) // &quot;0.0.0.0&quot;
```

### Configuration Subsets

It&#039;s often useful to extract a subset of configuration (e.g., when developing a
reusable module which should accept specific sections of configuration).

```yaml
cache:
  cache1:
    item-size: 64
    max-items: 100
  cache2:
    item-size: 80
    max-items: 200
```

```go
func NewCache(v *Viper) *Cache {
	return &amp;Cache{
		ItemSize: v.GetInt(&quot;item-size&quot;),
		MaxItems: v.GetInt(&quot;max-items&quot;),
	}
}

cache1Config := viper.Sub(&quot;cache.cache1&quot;)

if cache1Config == nil {
    // Sub returns nil if the key cannot be found
	panic(&quot;cache configuration not found&quot;)
}

cache1 := NewCache(cache1Config)
```

### Unmarshaling

You also have the option of unmarshaling configuration to a struct, map, etc.,
using `Unmarshal*` methods.

```go
type config struct {
	Port int
	Name string
	PathMap string `mapstructure:&quot;path_map&quot;`
}

var C config

err := viper.Unmarshal(&amp;C)
if err != nil {
	t.Fatalf(&quot;unable to decode into struct, %v&quot;, err)
}
```

If you want to unmarshal configuration where the keys themselves contain `.`
(the default key delimiter), you can change the delimiter.

```go
v := viper.NewWithOptions(viper.KeyDelimiter(&quot;::&quot;))

v.SetDefault(&quot;chart::values&quot;, map[string]any{
	&quot;ingress&quot;: map[string]any{
		&quot;annotations&quot;: map[string]any{
			&quot;traefik.frontend.rule.type&quot;:                 &quot;PathPrefix&quot;,
			&quot;traefik.ingress.kubernetes.io/ssl-redirect&quot;: &quot;true&quot;,
		},
	},
})

type config struct {
	Chart struct{
		Values map[string]any
	}
}

var C config

v.Unmarshal(&amp;C)
```

Viper also supports unmarshaling into embedded structs.

```go
/*
Example config:

module:
    enabled: true
    token: 89h3f98hbwf987h3f98wenf89ehf
*/
type config struct {
	Module struct {
		Enabled bool

		moduleConfig `mapstructure:&quot;,squash&quot;`
	}
}

type moduleConfig struct {
	Token string
}

var C config

err := viper.Unmarshal(&amp;C)
if err != nil {
	t.Fatalf(&quot;unable to decode into struct, %v&quot;, err)
}
```

Viper uses
[github.com/go-viper/mapstructure](https://github.com/go-viper/mapstructure)
under the hood for unmarshaling values which uses `mapstructure` tags, by
default.

### Marshalling to String

You may need to marshal all the settings held in Viper into a string. You can
use your favorite format&#039;s marshaller with the config returned by
`AllSettings`.

```go
import (
	yaml &quot;go.yaml.in/yaml/v3&quot;
)

func yamlStringSettings() string {
	c := viper.AllSettings()
	bs, err := yaml.Marshal(c)
	if err != nil {
		log.Fatalf(&quot;unable to marshal config to YAML: %v&quot;, err)
	}
	return string(bs)
}
```

### Decoding Custom Formats

A frequently requested feature is adding more value formats and decoders (for
example; parsing character delimited strings into slices. This is already
available in Viper using mapstructure decode hooks.

Read more in [this blog
post](https://sagikazarmark.hu/blog/decoding-custom-formats-with-viper/).


## FAQ

### Why is it called “Viper”?

Viper is designed to be a
[companion](http://en.wikipedia.org/wiki/Viper_(G.I._Joe)) to
[Cobra](https://github.com/spf13/cobra). While both can operate completely
independently, together they make a powerful pair to handle much of your
application foundation needs.

### I found a bug or want a feature, should I file an issue or a PR?

Yes, but there are two things to be aware of.

1.  The Viper project is currently prioritizing backwards compatibility and
    stability over features.
2.  Features may be deferred until Viper 2 forms.

### Can multiple Viper instances be used?

**tl;dr:** Yes.

Each will have its own unique configuration and can read from a different
configuration source. All of the functions that the Viper package supports are
mirrored as methods on a Viper instance.

```go
x := viper.New()
y := viper.New()

x.SetDefault(&quot;ContentDir&quot;, &quot;content&quot;)
y.SetDefault(&quot;ContentDir&quot;, &quot;foobar&quot;)
```

### Should Viper be a global singleton or passed around?

The best practice is to initialize a Viper instance and pass that around when
necessary.

Viper comes with a global instance (singleton) out of the box. Although it
makes setting up configuration easy, using it is generally discouraged as it
makes testing harder and can lead to unexpected behavior.

The global instance may be deprecated in the future. See
[#1855](https://github.com/spf13/viper/issues/1855) for more details.

### Does Viper support case sensitive keys?

**tl;dr:** No.

Viper merges configuration from various sources, many of which are either case
insensitive or use different casing than other sourc

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[stretchr/testify]]></title>
            <link>https://github.com/stretchr/testify</link>
            <guid>https://github.com/stretchr/testify</guid>
            <pubDate>Thu, 16 Oct 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[A toolkit with common assertions and mocks that plays nicely with the standard library]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stretchr/testify">stretchr/testify</a></h1>
            <p>A toolkit with common assertions and mocks that plays nicely with the standard library</p>
            <p>Language: Go</p>
            <p>Stars: 25,288</p>
            <p>Forks: 1,678</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>Testify - Thou Shalt Write Tests
================================

&gt; [!NOTE]
&gt; Testify is being maintained at v1, no breaking changes will be accepted in this repo.  
&gt; [See discussion about v2](https://github.com/stretchr/testify/discussions/1560).

[![Build Status](https://github.com/stretchr/testify/actions/workflows/main.yml/badge.svg?branch=master)](https://github.com/stretchr/testify/actions/workflows/main.yml) [![Go Report Card](https://goreportcard.com/badge/github.com/stretchr/testify)](https://goreportcard.com/report/github.com/stretchr/testify) [![PkgGoDev](https://pkg.go.dev/badge/github.com/stretchr/testify)](https://pkg.go.dev/github.com/stretchr/testify)

Go code (golang) set of packages that provide many tools for testifying that your code will behave as you intend.

Features include:

  * [Easy assertions](#assert-package)
  * [Mocking](#mock-package)
  * [Testing suite interfaces and functions](#suite-package)

Get started:

  * Install testify with [one line of code](#installation), or [update it with another](#staying-up-to-date)
  * For an introduction to writing test code in Go, see https://go.dev/doc/code#Testing
  * Check out the API Documentation https://pkg.go.dev/github.com/stretchr/testify
  * Use [testifylint](https://github.com/Antonboom/testifylint) (via [golangci-lint](https://golangci-lint.run/)) to avoid common mistakes
  * A little about [Test-Driven Development (TDD)](https://en.wikipedia.org/wiki/Test-driven_development)

[`assert`](https://pkg.go.dev/github.com/stretchr/testify/assert &quot;API documentation&quot;) package
-------------------------------------------------------------------------------------------

The `assert` package provides some helpful methods that allow you to write better test code in Go.

  * Prints friendly, easy to read failure descriptions
  * Allows for very readable code
  * Optionally annotate each assertion with a message

See it in action:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	// assert equality
	assert.Equal(t, 123, 123, &quot;they should be equal&quot;)

	// assert inequality
	assert.NotEqual(t, 123, 456, &quot;they should not be equal&quot;)

	// assert for nil (good for errors)
	assert.Nil(t, object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(t, object) {
		// now we know that object isn&#039;t nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(t, &quot;Something&quot;, object.Value)
	}
}
```

  * Every assert func takes the `testing.T` object as the first argument.  This is how it writes the errors out through the normal `go test` capabilities.
  * Every assert func returns a bool indicating whether the assertion was successful or not, this is useful for if you want to go on making further assertions under certain conditions.

if you assert many times, use the below:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	assert := assert.New(t)

	// assert equality
	assert.Equal(123, 123, &quot;they should be equal&quot;)

	// assert inequality
	assert.NotEqual(123, 456, &quot;they should not be equal&quot;)

	// assert for nil (good for errors)
	assert.Nil(object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(object) {
		// now we know that object isn&#039;t nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(&quot;Something&quot;, object.Value)
	}
}
```

[`require`](https://pkg.go.dev/github.com/stretchr/testify/require &quot;API documentation&quot;) package
---------------------------------------------------------------------------------------------

The `require` package provides same global functions as the `assert` package, but instead of returning a boolean result they terminate current test.
These functions must be called from the goroutine running the test or benchmark function, not from other goroutines created during the test.
Otherwise race conditions may occur.

See [t.FailNow](https://pkg.go.dev/testing#T.FailNow) for details.

[`mock`](https://pkg.go.dev/github.com/stretchr/testify/mock &quot;API documentation&quot;) package
----------------------------------------------------------------------------------------

The `mock` package provides a mechanism for easily writing mock objects that can be used in place of real objects when writing test code.

An example test function that tests a piece of code that relies on an external object `testObj`, can set up expectations (testify) and assert that they indeed happened:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/mock&quot;
)

/*
  Test objects
*/

// MyMockedObject is a mocked object that implements an interface
// that describes an object that the code I am testing relies on.
type MyMockedObject struct {
	mock.Mock
}

// DoSomething is a method on MyMockedObject that implements some interface
// and just records the activity, and returns what the Mock object tells it to.
//
// In the real object, this method would do something useful, but since this
// is a mocked object - we&#039;re just going to stub it out.
//
// NOTE: This method is not being tested here, code that uses this object is.
func (m *MyMockedObject) DoSomething(number int) (bool, error) {
	args := m.Called(number)
	return args.Bool(0), args.Error(1)
}

/*
  Actual test functions
*/

// TestSomething is an example of how to use our test object to
// make assertions about some target code we are testing.
func TestSomething(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations
	testObj.On(&quot;DoSomething&quot;, 123).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)
}

// TestSomethingWithPlaceholder is a second example of how to use our test object to
// make assertions about some target code we are testing.
// This time using a placeholder. Placeholders might be used when the
// data being passed in is normally dynamically generated and cannot be
// predicted beforehand (eg. containing hashes that are time sensitive)
func TestSomethingWithPlaceholder(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

}

// TestSomethingElse2 is a third example that shows how you can use
// the Unset method to cleanup handlers and then add new ones.
func TestSomethingElse2(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	mockCall := testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

	// remove the handler now so we can add another one that takes precedence
	mockCall.Unset()

	// return false now instead of true
	testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(false, nil)

	testObj.AssertExpectations(t)
}
```

For more information on how to write mock code, check out the [API documentation for the `mock` package](https://pkg.go.dev/github.com/stretchr/testify/mock).

You can use the [mockery tool](https://vektra.github.io/mockery/latest/) to autogenerate the mock code against an interface as well, making using mocks much quicker.

[`suite`](https://pkg.go.dev/github.com/stretchr/testify/suite &quot;API documentation&quot;) package
-----------------------------------------------------------------------------------------
&gt; [!WARNING]
&gt; The suite package does not support parallel tests. See [#934](https://github.com/stretchr/testify/issues/934).

The `suite` package provides functionality that you might be used to from more common object-oriented languages.  With it, you can build a testing suite as a struct, build setup/teardown methods and testing methods on your struct, and run them with &#039;go test&#039; as per normal.

An example suite is shown below:

```go
// Basic imports
import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
	&quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including a T() method which
// returns the current testing context
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	assert.Equal(suite.T(), 5, suite.VariableThatShouldStartAtFive)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
```

For a more complete example, using all of the functionality provided by the suite package, look at our [example testing suite](https://github.com/stretchr/testify/blob/master/suite/suite_test.go)

For more information on writing suites, check out the [API documentation for the `suite` package](https://pkg.go.dev/github.com/stretchr/testify/suite).

`Suite` object has assertion methods:

```go
// Basic imports
import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including assertion methods.
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	suite.Equal(suite.VariableThatShouldStartAtFive, 5)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
```

------

Installation
============

To install Testify, use `go get`:

    go get github.com/stretchr/testify

This will then make the following packages available to you:

    github.com/stretchr/testify/assert
    github.com/stretchr/testify/require
    github.com/stretchr/testify/mock
    github.com/stretchr/testify/suite
    github.com/stretchr/testify/http (deprecated)

Import the `testify/assert` package into your code using this template:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	assert.True(t, true, &quot;True is true!&quot;)
}
```

------

Staying up to date
==================

To update Testify to the latest version, use `go get -u github.com/stretchr/testify`.

------

Supported go versions
==================

We currently support the most recent major Go versions from 1.19 onward.

------

Contributing
============

Please feel free to submit issues, fork the repository and send pull requests!

When submitting an issue, we ask that you please include a complete test function that demonstrates the issue. Extra credit for those using Testify to write the test code that demonstrates it.

Code generation is used. [Look for `Code generated with`](https://github.com/search?q=repo%3Astretchr%2Ftestify%20%22Code%20generated%20with%22&amp;type=code) at the top of some files. Run `go generate ./...` to update generated files.

We also chat on the [Gophers Slack](https://gophers.slack.com) group in the `#testify` and `#testify-dev` channels.

------

License
=======

This project is licensed under the terms of the MIT license.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>