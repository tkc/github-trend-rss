<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Sat, 29 Mar 2025 00:04:59 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[milvus-io/milvus]]></title>
            <link>https://github.com/milvus-io/milvus</link>
            <guid>https://github.com/milvus-io/milvus</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[Milvus is a high-performance, cloud-native vector database built for scalable vector ANN search]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/milvus-io/milvus">milvus-io/milvus</a></h1>
            <p>Milvus is a high-performance, cloud-native vector database built for scalable vector ANN search</p>
            <p>Language: Go</p>
            <p>Stars: 33,668</p>
            <p>Forks: 3,119</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://github.com/user-attachments/assets/51e33300-7f85-43ff-a05a-3a0317a961f3&quot; alt=&quot;milvus banner&quot;&gt;

&lt;div class=&quot;column&quot; align=&quot;middle&quot;&gt;
  &lt;a href=&quot;https://github.com/milvus-io/milvus/blob/master/LICENSE&quot;&gt;&lt;img height=&quot;20&quot; src=&quot;https://img.shields.io/github/license/milvus-io/milvus&quot; alt=&quot;license&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://milvus.io/docs/install_standalone-docker.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/milvusdb/milvus&quot; alt=&quot;docker-pull-count&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://milvus.io/docs/roadmap.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/2025-roadmap-orange&quot; alt=&quot;fully-managed-milvus&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://cloud.zilliz.com/signup?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/fully_managed-milvus-blue&quot; alt=&quot;fully-managed-milvus&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://milvus.io/docs/tutorials-overview.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/tutorials-green&quot; alt=&quot;tutorials&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/mKc3R95yE5&quot;&gt;&lt;img height=&quot;20&quot; src=&quot;https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;discord&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/milvusio&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/milvusio&quot; alt=&quot;twitter&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

## What is Milvus?

üê¶ [Milvus](https://milvus.io/) is a high-performance vector database built for scale. It powers AI applications by efficiently organizing and searching vast amounts of unstructured data, such as text, images, and multi-modal information.

üßë‚Äçüíª Written in Go and C++, Milvus implements hardware accelaration for CPU/GPU to achieve best-in-class vector search performance. Thanks to its [fully-distributed and K8s-native architecture](https://milvus.io/docs/overview.md#What-Makes-Milvus-so-Scalable), Milvus can scale horizontally, handle tens of thousands of search queries on billions of vectors, and keep data fresh with real-time streaming updates. Milvus also supports [Standalone mode](https://milvus.io/docs/install_standalone-docker.md) for single machine deployment. [Milvus Lite](https://milvus.io/docs/milvus_lite.md) is a lightweight version good for quickstart in python with `pip install`.

Want to use Milvus with zero setup? Try out [Zilliz Cloud ‚òÅÔ∏è](https://cloud.zilliz.com/signup?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global) for free. Milvus is available as a fully managed service on Zilliz Cloud, with [Serverless](https://zilliz.com/serverless?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global), [Dedicated](https://zilliz.com/cloud?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global) and [BYOC](https://zilliz.com/bring-your-own-cloud?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global) options available.

For questions about how to use Milvus, join the community on [Discord](https://discord.gg/33mfvwep3J) to get help. For reporting problems, file bugs and feature requests in GitHub [Issues](https://github.com/milvus-io/milvus/issues) or ask in [Discussions](https://github.com/milvus-io/milvus/discussions).

The Milvus open-source project is
under [LF AI &amp; Data Foundation](https://lfaidata.foundation/projects/milvus/), distributed with [Apache 2.0](https://github.com/milvus-io/milvus/blob/master/LICENSE) License.

## Quickstart

```python
$ pip install -U pymilvus
```
This installs `pymilvus`, the Python SDK for Milvus. Use `MilvusClient` to create a client:
```python
from pymilvus import MilvusClient
```

* `pymilvus` also includes Milvus Lite for quickstart. To create a local vector database, simply instantiate a client with a local file name for persisting data:

  ```python
  client = MilvusClient(&quot;milvus_demo.db&quot;)
  ```

* You can also specify the credentials to connect to your deployed [Milvus server](https://milvus.io/docs/authenticate.md?tab=docker) or [Zilliz Cloud](https://docs.zilliz.com/docs/quick-start):

  ```python
  client = MilvusClient(
    uri=&quot;&lt;endpoint_of_self_hosted_milvus_or_zilliz_cloud&gt;&quot;,
    token=&quot;&lt;username_and_password_or_zilliz_cloud_api_key&gt;&quot;)
  ```

With the client, you can create collection:
```python
client.create_collection(
    collection_name=&quot;demo_collection&quot;,
    dimension=768,  # The vectors we will use in this demo have 768 dimensions
)
```

Ingest data:
```python
res = client.insert(collection_name=&quot;demo_collection&quot;, data=data)
```

Perform vector search:

```python
query_vectors = embedding_fn.encode_queries([&quot;Who is Alan Turing?&quot;, &quot;What is AI?&quot;])
res = client.search(
    collection_name=&quot;demo_collection&quot;,  # target collection
    data=query_vectors,  # a list of one or more query vectors, supports batch
    limit=2,  # how many results to return (topK)
    output_fields=[&quot;vector&quot;, &quot;text&quot;, &quot;subject&quot;],  # what fields to return
)
```

## Why Milvus

Milvus is designed to handle vector search at scale. It stores vectors, which are learned representations of unstructured data, together with other scalar data types such as integers, strings, and JSON objects. Users can conduct efficient vector search with metadata filtering or hybrid search. Here are why developers choose Milvus as the vector database for AI applications:

**High Performance at Scale and High Availability**  
  * Milvus features a [distributed architecture](https://milvus.io/docs/architecture_overview.md ) that separates [compute](https://milvus.io/docs/data_processing.md#Data-query) and [storage](https://milvus.io/docs/data_processing.md#Data-insertion). Milvus can horizontally scale and adapt to diverse traffic patterns, achieving optimal performance by independently increasing query nodes for read-heavy workload and data node for write-heavy workload. The stateless microservices on K8s allow [quick recovery](https://milvus.io/docs/coordinator_ha.md#Coordinator-HA) from failure, ensuring high availability. The support for [replicas](https://milvus.io/docs/replica.md) further enhances fault tolerance and throughput by loading data segments on multiple query nodes. See [benchmark](https://zilliz.com/vector-database-benchmark-tool) for performance comparison.


**Support for Various Vector Index Types and Hardware Acceleration**  
  * Milvus separates the system and core vector search engine, allowing it to support all major vector index types that are optimized for different scenarios, including HNSW, IVF, FLAT (brute-force), SCANN, and DiskANN, with [quantization-based](https://milvus.io/docs/index.md?tab=floating#IVFPQ) variations and [mmap](https://milvus.io/docs/mmap.md). Milvus optimizes vector search for advanced features such as [metadata filtering](https://milvus.io/docs/scalar_index.md#Scalar-Index) and [range search](https://milvus.io/docs/single-vector-search.md#Range-search). Additionally, Milvus implements hardware acceleration to enhance vector search performance and supports GPU indexing, such as NVIDIA&#039;s [CAGRA](https://github.com/rapidsai/cuvs).


**Flexible Multi-tenancy and Hot/Cold Storage**
  * Milvus supports [multi-tenancy](https://milvus.io/docs/multi_tenancy.md#Multi-tenancy-strategies) through isolation at database, collection, partition, or partition key level. The flexible strategies allow a single cluster to handle hundreds to millions of tenants, also ensures optimized search performance and flexible access control. Milvus enhances cost-effectiveness with hot/cold storage. Frequently accessed hot data can be stored in memory or on SSDs for better performance, while less-accessed cold data is kept on slower, cost-effective storage. This mechanism can significantly reduce costs while maintaining high performance for critical tasks.

**Sparse Vector for Full Text Search and Hybrid Search**
  * In addition to semantic search through dense vector, Milvus also natively supports [full text search](https://milvus.io/docs/full-text-search.md) with BM25 as well as learned sparse embedding such as SPLADE and BGE-M3. Users can store sparse vector and dense vector in the same collection, and define functions to rerank results from multiple search requests. See examples of [Hybrid Search with semantic search + full text search](https://milvus.io/docs/full_text_search_with_milvus.md).

**Data Security and Fine-grain Access Control**
  * Milvus ensures data security by implementing mandatory user authentication, TLS encryption, and Role-Based Access Control (RBAC). User authentication ensures that only authorized users with valid credentials can access the database, while TLS encryption secures all communications within the network. Additionally, RBAC allows for fine-grained access control by assigning specific permissions to users based on their roles. These features make Milvus a robust and secure choice for enterprise applications, protecting sensitive data from unauthorized access and potential breaches.

Milvus is trusted by AI developers to build applications such as text and image search, Retrieval-Augmented Generation (RAG), and recommendation systems. Milvus powers [many mission-critical business]((https://milvus.io/use-cases)) for startups and enterprises.

## Demos and Tutorials

Here is a selection of demos and tutorials to show how to build various types of AI applications made with Milvus:

You can explore a comprehensive [Tutorials Overview](https://milvus.io/docs/tutorials-overview.md) covering topics such as Retrieval-Augmented Generation (RAG), Semantic Search, Hybrid Search, Question Answering, Recommendation Systems, and various quick-start guides. These resources are designed to help you get started quickly and efficiently.

| Tutorial | Use Case | Related Milvus Features |
| -------- | -------- | --------- |
| [Build RAG with Milvus](https://milvus.io/docs/build-rag-with-milvus.md) |  RAG | vector search |
| [Advanced RAG Optimizations](https://milvus.io/docs/how_to_enhance_your_rag.md) | RAG | vector search, full text search |
| [Full Text Search with Milvus](https://milvus.io/docs/full_text_search_with_milvus.md) | Text Search | full text search |
| [Hybrid Search with Milvus](https://milvus.io/docs/hybrid_search_with_milvus.md) | Hybrid Search | hybrid search, multi vector, dense embedding, sparse embedding |
| [Image Search with Milvus](https://milvus.io/docs/image_similarity_search.md) | Semantic Search | vector search, dynamic field |
| [Multimodal Search using Multi Vectors](https://milvus.io/docs/multimodal_rag_with_milvus.md) | Semantic Search | multi vector, hybrid search |
| [Movie Recommendation with Milvus](https://milvus.io/docs/movie_recommendation_with_milvus.md) | Recommendation System | vector search |
| [Graph RAG with Milvus](https://milvus.io/docs/graph_rag_with_milvus.md) | RAG | graph search |
| [Contextual Retrieval with Milvus](https://milvus.io/docs/contextual_retrieval_with_milvus.md) | Quickstart | vector search |
| [Vector Visualization](https://milvus.io/docs/vector_visualization.md) | Quickstart | vector search |
| [HDBSCAN Clustering with Milvus](https://milvus.io/docs/hdbscan_clustering_with_milvus.md) | Quickstart | vector search |
| [Use ColPali for Multi-Modal Retrieval with Milvus](https://milvus.io/docs/use_ColPali_with_milvus.md) | Quickstart | vector search |

&lt;table&gt;
  &lt;tr&gt;
    &lt;td width=&quot;30%&quot;&gt;
      &lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;
        &lt;img src=&quot;https://assets.zilliz.com/image_search_59a64e4f22.gif&quot; /&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;30%&quot;&gt;
&lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;
&lt;img src=&quot;https://assets.zilliz.com/qa_df5ee7bd83.gif&quot; /&gt;
&lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;30%&quot;&gt;
&lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;
&lt;img src=&quot;https://assets.zilliz.com/mole_search_76f8340572.gif&quot; /&gt;
&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;
      &lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;Image Search&lt;/a&gt;
    &lt;/th&gt;
    &lt;th&gt;
      &lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;RAG&lt;/a&gt;
    &lt;/th&gt;
    &lt;th&gt;
      &lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;Drug Discovery&lt;/a&gt;
    &lt;/th&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Ecosystem and Integration
   Milvus integrates with a comprehensive suite of [AI development tools](https://milvus.io/docs/integrations_overview.md), such as LangChain, LlamaIndex, OpenAI and HuggingFace, making it an ideal vector store for GenAI applications such as Retrieval-Augmented Generation (RAG). Milvus works with both open-source embedding models and embedding service, in text, image and video modalities. Milvus also provides a convenient util [`pymilvus[model]`](https://milvus.io/docs/embeddings.md), users can use the simple wrapper code to transform unstructured data into vector embeddings and leverage reranking models for optimized search results. The Milvus ecosystem also includes [Attu](https://github.com/zilliztech/attu?tab=readme-ov-file#attu) for GUI-based administration, [Birdwatcher](https://milvus.io/docs/birdwatcher_overview.md) for system debugging, [Prometheus/Grafana](https://milvus.io/docs/monitor_overview.md) for monitoring, [Milvus CDC](https://milvus.io/docs/milvus-cdc-overview.md) for data synchronization, [VTS](https://github.com/zilliztech/vts?tab=readme-ov-file#vts) for data migration and data connectors for [Spark](https://milvus.io/docs/integrate_with_spark.md#Spark-Milvus-Connector-User-Guide), [Kafka](https://github.com/zilliztech/kafka-connect-milvus?tab=readme-ov-file#kafka-connect-milvus-connector), [Fivetran](https://fivetran.com/docs/destinations/milvus), and [Airbyte](https://milvus.io/docs/integrate_with_airbyte.md) to build search pipelines.

Check out https://milvus.io/docs/integrations_overview.md for more details.

## Documentation

For guidance on installation, usage, deployment, and administration, check out [Milvus Docs](https://milvus.io/docs). For technical milestones and enhancement proposals, check out [issues on GitHub](https://github.com/milvus-io/milvus/issues).

## Contributing

The Milvus open-source project accepts contribution from everyone. See [Guidelines for Contributing](https://github.com/milvus-io/milvus/blob/master/CONTRIBUTING.md) for details on submitting patches and the development workflow. See our [community repository](https://github.com/milvus-io/community) to learn about project governance and access more community resources.

### Build Milvus from Source Code

Requirements:

* Linux systems (Ubuntu 20.04 or later recommended):
  ```bash
  go: &gt;= 1.21
  cmake: &gt;= 3.26.4
  gcc: 9.5
  python: &gt; 3.8 and  &lt;= 3.11
  ```

* MacOS systems with x86_64 (Big Sur 11.5 or later recommended):
  ```bash
  go: &gt;= 1.21
  cmake: &gt;= 3.26.4
  llvm: &gt;= 15
  python: &gt; 3.8 and  &lt;= 3.11
  ```

* MacOS systems with Apple Silicon (Monterey 12.0.1 or later recommended):
  ```bash
  go: &gt;= 1.21 (Arch=ARM64)
  cmake: &gt;= 3.26.4
  llvm: &gt;= 15
  python: &gt; 3.8 and  &lt;= 3.11
  ```

Clone Milvus repo and build.

```bash
# Clone github repository.
$ git clone https://github.com/milvus-io/milvus.git

# Install third-party dependencies.
$ cd milvus/
$ ./scripts/install_deps.sh

# Compile Milvus.
$ make
```

For full instructions, see [developer&#039;s documentation](https://github.com/milvus-io/milvus/blob/master/DEVELOPMENT.md).

## Community

Join the Milvus community on [Discord](https://discord.gg/8uyFbECzPX) to share your suggestions, advice, and questions with our engineering team.

To learn latest news about Milvus, follow us on social media:

- [X](https://twitter.com/milvusio)
- [LinkedIn](https://www.linkedin.com/company/the-milvus-project)
- [Youtube](https://www.youtube.com/channel/UCMCo_F7pKjMHBlfyxwOPw-g)
- [Medium](https://medium.com/@milvusio)

You can also check out our [FAQ page](https://milvus.io/docs/performance_faq.md) to discover solutions or answers to your issues or questions, and subscribe to Milvus mailing lists:

- [Technical Steering Committee](https://lists.lfai.foundation/g/milvus-tsc)
- [Technical Discussions](https://lists.lfai.foundation/g/milvus-technical-discuss)
- [Announcement](https://lists.lfai.foundation/g/milvus-announce)

## Reference

Reference to cite when you use Milvus in a research paper:

```
@inproceedings{2021milvus,
  title={Milvus: A Purpose-Built Vector Data Management System},
  author={Wang, Jianguo and Yi, Xiaomeng and Guo, Rentong and Jin, Hai and Xu, Peng and Li, Shengjun and Wang, Xiangyu and Guo, Xiangzhou and Li, Chengming and Xu, Xiaohai and others},
  booktitle={Proceedings of the 2021 International Conference on Management of Data},
  pages={2614--2627},
  year={2021}
}

@article{2022manu,
  title={Manu: a cloud native vector database management system},
  author={Guo, Rentong and Luan, Xiaofan and Xiang, Long and Yan, Xiao and Yi, Xiaomeng and Luo, Jigao and Cheng, Qianya and Xu, Weizhi and Luo, Jiarui and Liu, Frank and others},
  journal={Proceedings of the VLDB Endowment},
  volume={15},
  number={12},
  pages={3548--3561},
  year={2022},
  publisher={VLDB Endowment}
}
```
&lt;!-- Do not remove start of hero-bot --&gt;
&lt;img src=&quot;https://img.shields.io/badge/all--contributors-433-orange&quot;&gt;&lt;br&gt;
&lt;a href=&quot;https://github.com/0xflotus&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/26602940?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ABNER-1&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/24547351?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Abhijnan-Bajpai&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/57059194?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Accagain2014&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/9635216?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Ahmetyasin&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/34247619?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Ald392&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/166891594?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/AliDotS&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/33119433?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/AllenYu1987&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/12489985?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Anosh21&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/90505226?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/AnthonyTsu1984&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/115786031?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Aredcap&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/40494761?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ArenaSu&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/21214629?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Armaggheddon&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/47779194?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Arya0812&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/114047052?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/BUPTAnderson&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/13449703?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Ben-Aaron-Bio-Rad&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/54123439?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Bennu-Li&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/53458891?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Biki-das&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/72331432?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/BossZou&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/40255591?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/CNLHC&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/21005146?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/CaoHaiNam&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/47685795?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Chisdo&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/36720318?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ChunelFeng&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/37905059?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/CocytusElias&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/79587688?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/CodeI

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[dolthub/dolt]]></title>
            <link>https://github.com/dolthub/dolt</link>
            <guid>https://github.com/dolthub/dolt</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[Dolt ‚Äì Git for Data]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dolthub/dolt">dolthub/dolt</a></h1>
            <p>Dolt ‚Äì Git for Data</p>
            <p>Language: Go</p>
            <p>Stars: 18,452</p>
            <p>Forks: 547</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;img height=&quot;100&quot; src=&quot;./images/Dolt-Logo@3x.svg&quot;/&gt;

# Dolt is Git for Data!

Dolt is a SQL database that you can fork, clone, branch, merge, push
and pull just like a Git repository. 

Connect to Dolt just like any MySQL database to read or modify schema 
and data. Version control functionality is exposed in SQL via system 
tables, functions, and procedures. 

Or, use the Git-like command line interface to import CSV files, commit 
your changes, push them to a remote, or merge your teammate&#039;s changes.
All the commands you know for Git work exactly the same for Dolt. 

Git versions files. Dolt versions tables. It&#039;s like Git and MySQL had a
baby.

We also built [DoltHub](https://www.dolthub.com), a place to share
Dolt databases. We host public data for free. If you want to host
your own version of DoltHub, we have [DoltLab](https://www.doltlab.com). 
If you want us to run a Dolt server for you, we have [Hosted Dolt](https://hosted.doltdb.com). 
If you are looking for a Postgres version of Dolt, we built 
[DoltgreSQL](https://github.com/dolthub/doltgresql). Warning, it&#039;s 
early Alpha. Dolt is production-ready.

[Join us on Discord](https://discord.com/invite/RFwfYpu) to say hi and
ask questions, or [check out our roadmap](https://docs.dolthub.com/other/roadmap) 
to see what we&#039;re building next.

# Video Introduction

[![Dolt Explainer Video](https://img.youtube.com/vi/H2iZy0Cme10/maxresdefault.jpg)](https://www.youtube.com/watch?v=H2iZy0Cme10)

# What&#039;s it for?

Lots of things! Dolt is a generally useful tool with countless
applications. But if you want some ideas, [here&#039;s how people are using
it so far](https://dolthub.com/blog/2024-10-15-dolt-use-cases/).

Dolt can be [set up as a replica of your existing MySQL](https://www.dolthub.com/blog/2023-02-17-binlog-replication-preview/)
database using standard MySQL binlog replication. Every write becomes
a Dolt commit. This is a great way to get the version control benefits 
of Dolt and keep an existing MySQL database. 

# Dolt CLI

The `dolt` CLI has the same commands as `git`, with some extras.

```
$ dolt
Valid commands for dolt are
                init - Create an empty Dolt data repository.
              status - Show the working tree status.
                 add - Add table changes to the list of staged table changes.
                diff - Diff a table.
               reset - Remove table changes from the list of staged table changes.
               clean - Remove untracked tables from working set.
              commit - Record changes to the repository.
                 sql - Run a SQL query against tables in repository.
          sql-server - Start a MySQL-compatible server.
                 log - Show commit logs.
              branch - Create, list, edit, delete branches.
            checkout - Checkout a branch or overwrite a table from HEAD.
               merge - Merge a branch.
           conflicts - Commands for viewing and resolving merge conflicts.
         cherry-pick - Apply the changes introduced by an existing commit.
              revert - Undo the changes introduced in a commit.
               clone - Clone from a remote data repository.
               fetch - Update the database from a remote data repository.
                pull - Fetch from a dolt remote data repository and merge.
                push - Push to a dolt remote.
              config - Dolt configuration.
              remote - Manage set of tracked repositories.
              backup - Manage a set of server backups.
               login - Login to a dolt remote host.
               creds - Commands for managing credentials.
                  ls - List tables in the working set.
              schema - Commands for showing and importing table schemas.
               table - Commands for copying, renaming, deleting, and exporting tables.
                 tag - Create, list, delete tags.
               blame - Show what revision and author last modified each row of a table.
         constraints - Commands for handling constraints.
             migrate - Executes a database migration to use the latest Dolt data format.
         read-tables - Fetch table(s) at a specific commit into a new dolt repo
                  gc - Cleans up unreferenced data from the repository.
       filter-branch - Edits the commit history using the provided query.
          merge-base - Find the common ancestor of two commits.
             version - Displays the current Dolt cli version.
                dump - Export all tables in the working set into a file.
```

# Installation

Dolt is a single ~103 megabyte program. 

```bash
dolt $ du -h /Users/timsehn/go/bin/dolt
103M	/Users/timsehn/go/bin/dolt
```

It&#039;s really easy to install. Download it and put it on your `PATH`. 
We have a bunch of ways to make this even easier for most platforms.

## From Latest Release

To install on Linux or Mac based systems run this command in your
terminal:

```
sudo bash -c &#039;curl -L https://github.com/dolthub/dolt/releases/latest/download/install.sh | bash&#039;
```

This will download the latest `dolt` release and put it in
`/usr/local/bin/`, which is probably on your `$PATH`.

The install script needs sudo in order to put `dolt` in `/usr/local/bin`. If you don&#039;t have root
privileges or aren&#039;t comfortable running a script with them, you can download the dolt binary
for your platform from [the latest release](https://github.com/dolthub/dolt/releases), unzip it,
and put the binary somewhere on your `$PATH`.

### Linux

#### Arch Linux

Dolt is packaged in the official repositories for Arch Linux.

```
pacman -S dolt
```

### Mac

#### Homebrew

Dolt is on Homebrew, updated every release.

```
brew install dolt
```
#### MacPorts

On macOS, Dolt can also be installed via a [community-managed port](https://ports.macports.org/port/dolt/) via [MacPorts](https://www.macports.org):

```sh
sudo port install dolt
```

### Windows

Download the latest Microsoft Installer (`.msi` file) in
[releases](https://github.com/dolthub/dolt/releases) and run
it.

For information on running on Windows, see [here](https://docs.dolthub.com/introduction/installation/windows).

#### Chocolatey

You can install `dolt` using [Chocolatey](https://chocolatey.org/):

```sh
choco install dolt
```

#### Docker

There are following official Docker images for Dolt:

* [`dolthub/dolt`](https://hub.docker.com/r/dolthub/dolt) for running Dolt
as CLI tool.
* [`dolthub/dolt-sql-server`](https://hub.docker.com/r/dolthub/dolt-sql-server) for running Dolt in server mode.

## From Source

Make sure you have Go installed, and that `go` is in your path. Dolt has a dependency on [cgo](https://pkg.go.dev/cmd/cgo), so you will need a working C compiler and toolchain as well.

Clone this repository and cd into the `go` directory. Then run:

```
go install ./cmd/dolt
```

The output will be in `$GOPATH/bin`, which defaults to `~/go/bin`. To test your build, try:

```
~/go/bin/dolt version
```

# Configuration

Verify that your installation has succeeded by running `dolt` in your
terminal.

```
$ dolt
Valid commands for dolt are
[...]
```

Configure `dolt` with your user name and email, which you&#039;ll need to
create commits. The commands work exactly the same as git.

```
$ dolt config --global --add user.email YOU@DOMAIN.COM
$ dolt config --global --add user.name &quot;YOUR NAME&quot;
```

# Getting started

## Navigate to the directory where you would like your data stored

Dolt needs a place to store your databases. I&#039;m going to put my databases in `~/dolt`. 

```bash
% cd ~
% mkdir dolt
% cd dolt
```

Any databases you create will be stored in this directory. So, for this example, a directory named `getting_started` will be created here once you run `create database getting_started`. Navigating to `~/dolt/getting_started` will allow you to access this database using the Dolt command line.

NOTE: For this example, the `getting_started` directory will be created after you run `create database getting_started;` in a SQL shell in the [Create a schema section](#create-a-schema). Don&#039;t do anything except make the directory and navigate to it just yet.

## Start a MySQL-compatible database server

Dolt ships with a MySQL compatible database server built in. To start it you use the command `dolt sql-server`. Running this command starts the server on port 3306. 

```bash
dolt sql-server
Starting server with Config HP=&quot;localhost:3306&quot;|T=&quot;28800000&quot;|R=&quot;false&quot;|L=&quot;info&quot;
```

Your terminal will just hang there. This means the server is running. Any errors will be printed in this terminal. Just leave it there and open a new terminal.

## Connect with a MySQL client (up to version 8.4)

In the new terminal, we will now connect to the running database server using a client. Dolt also ships with a MySQL compatible client. 

```bash
% dolt -u root -p &quot;&quot; sql
# Welcome to the Dolt MySQL client.
# Statements must be terminated with &#039;;&#039;.
# &quot;exit&quot; or &quot;quit&quot; (or Ctrl-D) to exit.
mysql&gt;
```

In the other terminal where you ran `dolt sql-server`, you&#039;ll see the following log line.

```
2022-06-06T13:14:32-07:00 INFO [conn 1] NewConnection {DisableClientMultiStatements=false}
```

You are connected!

While we&#039;re here let&#039;s grab a copy of MySQL so we can connect with that client. Head over to the [MySQL Getting Started](https://dev.mysql.com/doc/mysql-getting-started/en/) documentation and install MySQL on your machine. I used [Homebrew](https://brew.sh/) to install MySQL on my Mac: `brew install mysql@8.4`. Alternatively, you can install only the client component by running `brew install mysql-client@8.4`.

NOTE: Make sure you install a MySQL 8.4 release. MySQL 8.4 is the current Long Term Support (LTS) release, meaning this is the stable and supported version of MySQL. MySQL 9.0 is also available, but is an &quot;innovation&quot; release, meaning it has more recent changes and features, but may not be as stable as the LTS release. The 9.0 release changes authentication support and isn&#039;t able to connect to a Dolt SQL server by default. You can install MySQL 8.4 with Homebrew by running `brew install mysql@8.4`. If you do want to use MySQL-9.0, read [our post on how to configure Dolt for `caching_sha2_password` authentication](https://www.dolthub.com/blog/2024-12-11-mysql9-and-caching-sha2-auth-support/). 

MySQL comes with a MySQL server called `mysqld` and a MySQL client called `mysql`. You&#039;re only interested in the client. After following the instructions from MySQL&#039;s documentation, make sure you have a copy of the `mysql` client on your path:

```bash
% mysql --version
mysql  Ver 8.0.29 for macos12.2 on x86_64 (Homebrew)
```

Now, to connect the `mysql` client to Dolt, you are going to force the MySQL client through the TCP interface by passing in a host and port. The default is the socket interface which Dolt supports, but is only available on `localhost`. So, it&#039;s better to show off the TCP interface. The MySQL client also requires you specify a user, in this case `root`.

```bash
% mysql --host 127.0.0.1 --port 3306 -uroot
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.7.9-Vitess 

Copyright (c) 2000, 2022, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type &#039;help;&#039; or &#039;\h&#039; for help. Type &#039;\c&#039; to clear the current input statement.

mysql&gt;
```

Again, to ensure the client actually connected, you should see the following in the `dolt sql-server` terminal 

```
2022-06-06T13:26:55-07:00 INFO [conn 2] NewConnection {DisableClientMultiStatements=false}
```

As you can see, Dolt supports any MySQL-compatible client. Dolt ships with a client but you can use any MySQL client, like the one that comes with MySQL.

## Create a schema

Now we&#039;re actually ready to do something interesting. I&#039;ll stay in the `mysql` client and execute the following SQL statements to create a database called `getting_started`. The `getting_started` database will have three tables: `employees`, `teams`, and `employees_teams`.

```
mysql&gt; create database getting_started;
Query OK, 1 row affected (0.04 sec)

mysql&gt; use getting_started;
Database changed
mysql&gt; create table employees (
    id int, 
    last_name varchar(255), 
    first_name varchar(255), 
    primary key(id));
Query OK, 0 rows affected (0.01 sec)

mysql&gt; create table teams (
    id int, 
    team_name varchar(255), 
    primary key(id)); 
Query OK, 0 rows affected (0.00 sec)

mysql&gt; create table employees_teams(
    team_id int, 
    employee_id int, 
    primary key(team_id, employee_id), 
    foreign key (team_id) references teams(id), 
    foreign key (employee_id) references employees(id));
Query OK, 0 rows affected (0.01 sec)

mysql&gt; show tables;
+---------------------------+
| Tables_in_getting_started |
+---------------------------+
| employees                 |
| employees_teams           |
| teams                     |
+---------------------------+
3 rows in set (0.00 sec)
```

Dolt supports foreign keys, secondary indexes, triggers, check constraints, and stored procedures. It&#039;s a modern, feature-rich SQL database.

## Make a Dolt commit

It&#039;s time to use your first Dolt feature. We&#039;re going to make a Dolt [commit](https://docs.dolthub.com/concepts/dolt/commits). A Dolt commit allows you to time travel and see lineage. Make a Dolt commit whenever you want to restore or compare to this point in time.

Dolt exposes version control functionality through a Git-style interface. On the command line, Dolt commands map exactly to their Git equivalent with the targets being tables instead of files. In SQL, Dolt exposes version control read operations as [system tables](https://docs.dolthub.com/sql-reference/version-control/dolt-system-tables) and version control write operations as [stored procedures](https://docs.dolthub.com/sql-reference/version-control/dolt-sql-procedures). 

The naming of the system tables and stored procedures follows the `dolt_&lt;command&gt;` pattern. So `dolt add` on the CLI becomes `dolt_add` as a stored procedure. Passing options also follows the command line model. For instance, to specify tables to add, send the table names in as options to the `dolt_add` procedure. For named arguments like sending a message into the `dolt_commit` command use two arguments in sequence like `(&#039;-m&#039;, &#039;This is a message&#039;)`. If you know Git, the version control procedures and system tables should feel familiar.

So, we add and commit our new schema like so.

```
mysql&gt; call dolt_add(&#039;teams&#039;, &#039;employees&#039;, &#039;employees_teams&#039;);
+--------+
| status |
+--------+
|      0 |
+--------+
1 row in set (0.03 sec)

mysql&gt; call dolt_commit(&#039;-m&#039;, &#039;Created initial schema&#039;);
+----------------------------------+
| hash                             |
+----------------------------------+
| ne182jemgrlm8jnjmoubfqsstlfi1s98 |
+----------------------------------+
1 row in set (0.02 sec)

mysql&gt; select * from dolt_log;
+----------------------------------+-----------+-----------------+-------------------------+----------------------------+
| commit_hash                      | committer | email           | date                    | message                    |
+----------------------------------+-----------+-----------------+-------------------------+----------------------------+
| ne182jemgrlm8jnjmoubfqsstlfi1s98 | Tim Sehn  | tim@dolthub.com | 2022-06-07 16:35:49.277 | Created initial schema     |
| vluuhvd0bn59598utedt77ed9q5okbcb | Tim Sehn  | tim@dolthub.com | 2022-06-07 16:33:59.531 | Initialize data repository |
+----------------------------------+-----------+-----------------+-------------------------+----------------------------+
2 rows in set (0.01 sec)
```

There you have it. Your schema is created and you have a Dolt commit tracking the creation, as seen in the `dolt_log` system table.

Note, a Dolt commit is different than a standard SQL transaction `COMMIT`. In this case, I am running the database with [`AUTOCOMMIT`](https://dev.mysql.com/doc/refman/5.6/en/innodb-autocommit-commit-rollback.html) on, so each SQL statement is automatically generating a transaction `COMMIT`. If you want system to generate a Dolt commit for every transaction use the system variable, [`@@dolt_transaction_commit`](https://docs.dolthub.com/sql-reference/version-control/dolt-sysvars#dolt_transaction_commit).

## Insert some data

Now, I&#039;m going to populate the database with a few employees here at DoltHub. Then, I&#039;ll assign the employees to two teams: engineering and sales. The CEO wears many hats at a start up so he&#039;ll be assigned to multiple teams.

```
mysql&gt; insert into employees values 
    (0, &#039;Sehn&#039;, &#039;Tim&#039;), 
    (1, &#039;Hendriks&#039;, &#039;Brian&#039;), 
    (2, &#039;Son&#039;,&#039;Aaron&#039;), 
    (3, &#039;Fitzgerald&#039;, &#039;Brian&#039;);
Query OK, 4 rows affected (0.01 sec)

mysql&gt; select * from employees where first_name=&#039;Brian&#039;;
+------+------------+------------+
| id   | last_name  | first_name |
+------+------------+------------+
|    1 | Hendriks   | Brian      |
|    3 | Fitzgerald | Brian      |
+------+------------+------------+
2 rows in set (0.00 sec)

mysql&gt; insert into teams values 
    (0, &#039;Engineering&#039;), 
    (1, &#039;Sales&#039;);
Query OK, 2 rows affected (0.00 sec)

mysql&gt; insert into employees_teams values 
    (0,0), 
    (1,0), 
    (2,0), 
    (0,1), 
    (3,1);
ERROR 1452 (HY000): cannot add or update a child row - Foreign key violation on fk: `rv9ek7ft`, table: `employees_teams`, referenced table: `teams`, key: `[2]`
```

Oops, I violated a constraint. It looks like I created the table with teams before employees. You should always specify your columns when you insert, not rely on natural ordering. Serves me right! Dolt comes with the full power of a modern SQL relational database to ensure data integrity.

```
mysql&gt; insert into employees_teams(employee_id, team_id) values 
    (0,0), 
    (1,0), 
    (2,0), 
    (0,1), 
    (3,1);
Query OK, 5 rows affected (0.01 sec)

mysql&gt; select first_name, last_name, team_name from employees 
    join employees_teams on (employees.id=employees_teams.employee_id) 
    join teams on (teams.id=employees_teams.team_id) 
    where team_name=&#039;Engineering&#039;;
+------------+-----------+-------------+
| first_name | last_name | team_name   |
+------------+-----------+-------------+
| Tim        | Sehn      | Engineering |
| Brian      | Hendriks  | Engineering |
| Aaron      | Son       | Engineering |
+------------+-----------+-------------+
3 rows in set (0.00 sec)
```

Looks like everything is inserted and correct. I was able to list the members of the engineering team using that three table `JOIN`. Dolt supports up to twelve table `JOIN`s. Again, Dolt is a modern SQL relational database paired with Git-style version control.

## Examine the diff

Now, what if you want to see what changed in your working set before you make a commit? You use the `dolt_status` and `dolt_diff_&lt;tablename&gt;` system tables. 

```
mysql&gt; select * from dolt_status;
+-----------------+--------+----------+
| table_name      | staged | status   |
+-----------------+--------+----------+
| teams           |      0 | modified |
| employees       |      0 | modified |
| employees_teams |      0 | modified |
+-----------------+--------+----------+
3 rows in set (0.01 sec)

mysql&gt; select * from dolt_diff_employees;
+--------------+---------------+-------+-----------+----------------+----------------+-----------------+---------+----------------------------------+-------------------------+-----------+
| to_last_name | to_first_name | to_id | to_commit | to_commit_date | from_last_name | from_first_name | from_id | from_commit                      | from_commit_date        | diff_type |
+--------------+---------------+-------+-----------+----------------+----------------+-----------------+---------+----------------------------------+-------------------------+-----------+
| Sehn         | Tim           |     0 | WORKING   | NULL           | NULL           | NULL            |   

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grpc/grpc-go]]></title>
            <link>https://github.com/grpc/grpc-go</link>
            <guid>https://github.com/grpc/grpc-go</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[The Go language implementation of gRPC. HTTP/2 based RPC]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grpc/grpc-go">grpc/grpc-go</a></h1>
            <p>The Go language implementation of gRPC. HTTP/2 based RPC</p>
            <p>Language: Go</p>
            <p>Stars: 21,595</p>
            <p>Forks: 4,464</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># gRPC-Go

[![GoDoc](https://pkg.go.dev/badge/google.golang.org/grpc)][API]
[![GoReportCard](https://goreportcard.com/badge/grpc/grpc-go)](https://goreportcard.com/report/github.com/grpc/grpc-go)
[![codecov](https://codecov.io/gh/grpc/grpc-go/graph/badge.svg)](https://codecov.io/gh/grpc/grpc-go)

The [Go][] implementation of [gRPC][]: A high performance, open source, general
RPC framework that puts mobile and HTTP/2 first. For more information see the
[Go gRPC docs][], or jump directly into the [quick start][].

## Prerequisites

- **[Go][]**: any one of the **two latest major** [releases][go-releases].

## Installation

Simply add the following import to your code, and then `go [build|run|test]`
will automatically fetch the necessary dependencies:


```go
import &quot;google.golang.org/grpc&quot;
```

&gt; **Note:** If you are trying to access `grpc-go` from **China**, see the
&gt; [FAQ](#FAQ) below.

## Learn more

- [Go gRPC docs][], which include a [quick start][] and [API
  reference][API] among other resources
- [Low-level technical docs](Documentation) from this repository
- [Performance benchmark][]
- [Examples](examples)

## FAQ

### I/O Timeout Errors

The `golang.org` domain may be blocked from some countries. `go get` usually
produces an error like the following when this happens:

```console
$ go get -u google.golang.org/grpc
package google.golang.org/grpc: unrecognized import path &quot;google.golang.org/grpc&quot; (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)
```

To build Go code, there are several options:

- Set up a VPN and access google.golang.org through that.

- With Go module support: it is possible to use the `replace` feature of `go
  mod` to create aliases for golang.org packages.  In your project&#039;s directory:

  ```sh
  go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest
  go mod tidy
  go mod vendor
  go build -mod=vendor
  ```

  Again, this will need to be done for all transitive dependencies hosted on
  golang.org as well. For details, refer to [golang/go issue
  #28652](https://github.com/golang/go/issues/28652).

### Compiling error, undefined: grpc.SupportPackageIsVersion

Please update to the latest version of gRPC-Go using
`go get google.golang.org/grpc`.

### How to turn on logging

The default logger is controlled by environment variables. Turn everything on
like this:

```console
$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99
$ export GRPC_GO_LOG_SEVERITY_LEVEL=info
```

### The RPC failed with error `&quot;code = Unavailable desc = transport is closing&quot;`

This error means the connection the RPC is using was closed, and there are many
possible reasons, including:
 1. mis-configured transport credentials, connection failed on handshaking
 1. bytes disrupted, possibly by a proxy in between
 1. server shutdown
 1. Keepalive parameters caused connection shutdown, for example if you have
    configured your server to terminate connections regularly to [trigger DNS
    lookups](https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779).
    If this is the case, you may want to increase your
    [MaxConnectionAgeGrace](https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters),
    to allow longer RPC calls to finish.

It can be tricky to debug this because the error happens on the client side but
the root cause of the connection being closed is on the server side. Turn on
logging on __both client and server__, and see if there are any transport
errors.

[API]: https://pkg.go.dev/google.golang.org/grpc
[Go]: https://golang.org
[Go module]: https://github.com/golang/go/wiki/Modules
[gRPC]: https://grpc.io
[Go gRPC docs]: https://grpc.io/docs/languages/go
[Performance benchmark]: https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608
[quick start]: https://grpc.io/docs/languages/go/quickstart
[go-releases]: https://golang.org/doc/devel/release.html
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gogs/gogs]]></title>
            <link>https://github.com/gogs/gogs</link>
            <guid>https://github.com/gogs/gogs</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[Gogs is a painless self-hosted Git service]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gogs/gogs">gogs/gogs</a></h1>
            <p>Gogs is a painless self-hosted Git service</p>
            <p>Language: Go</p>
            <p>Stars: 45,806</p>
            <p>Forks: 5,006</p>
            <p>Stars today: 52 stars today</p>
            <h2>README</h2><pre>![gogs-brand](https://user-images.githubusercontent.com/2946214/146899259-6a8b58ad-8d6e-40d2-ab02-79dc6aadabbf.png)

[![GitHub Workflow Status](https://img.shields.io/github/checks-status/gogs/gogs/main?logo=github&amp;style=for-the-badge)](https://github.com/gogs/gogs/actions?query=branch%3Amain) [![Discord](https://img.shields.io/discord/382595433060499458.svg?style=for-the-badge&amp;logo=discord)](https://discord.gg/9aqdHU7) [![Sourcegraph](https://img.shields.io/badge/view%20on-Sourcegraph-brightgreen.svg?style=for-the-badge&amp;logo=sourcegraph)](https://sourcegraph.com/github.com/gogs/gogs)

[ÁÆÄ‰Ωì‰∏≠Êñá](README_ZH.md)

## üîÆ Vision

The Gogs (`/g…ëgz/`) project aims to build a simple, stable and extensible self-hosted Git service that can be set up in the most painless way. With Go, this can be done with an independent binary distribution across all platforms that Go supports, including Linux, macOS, Windows and ARM-based systems.

## üì° Overview

- Please visit [our home page](https://gogs.io) for user documentation.
- Please refer to [CHANGELOG.md](CHANGELOG.md) for list of changes in each releases.
- Want to try it before doing anything else? Do it [online](https://try.gogs.io/gogs/gogs)!
- Having trouble? Help yourself with [troubleshooting](https://gogs.io/docs/intro/troubleshooting.html) or ask questions in [Discussions](https://github.com/gogs/gogs/discussions).
- Want to help with localization? Check out the [localization documentation](https://gogs.io/docs/features/i18n.html).
- Ready to get hands dirty? Read our [contributing guide](.github/CONTRIBUTING.md).
- Hmm... What about APIs? We have experimental support with [documentation](https://github.com/gogs/docs-api).

## üíå Features

- User dashboard, user profile and activity timeline.
- Access repositories via SSH, HTTP and HTTPS protocols.
- User, organization and repository management.
- Repository and organization webhooks, including Slack, Discord and Dingtalk.
- Repository Git hooks, deploy keys and Git LFS.
- Repository issues, pull requests, wiki, protected branches and collaboration.
- Migrate and mirror repositories with wiki from other code hosts.
- Web editor for quick editing repository files and wiki.
- Jupyter Notebook and PDF rendering.
- Authentication via SMTP, LDAP, reverse proxy, GitHub.com and GitHub Enterprise with 2FA.
- Customize HTML templates, static files and many others.
- Rich database backend support, including PostgreSQL, MySQL, SQLite3 or any database backend that speaks one of those protocols.
- Have localization over [31 languages](https://crowdin.com/project/gogs).

## üíæ Hardware requirements

- A Raspberry Pi or $5 Digital Ocean Droplet is more than enough to get you started. Some even use 64MB RAM Docker [CaaS](https://www.docker.com/blog/containers-as-a-service-caas/).
- 2 CPU cores and 512MB RAM would be the baseline for teamwork.
- Increase CPU cores when your team size gets significantly larger, memory footprint remains low.

## üíª Browser support

- Please see [Semantic UI](https://github.com/Semantic-Org/Semantic-UI#browser-support) for specific versions of supported browsers.
- The smallest resolution officially supported is **1024*768**, however the UI may still look right in smaller resolutions, but no promises or fixes.

## üìú Installation

Make sure you install the [prerequisites](https://gogs.io/docs/installation) first.

There are 6 ways to install Gogs:

- [Install from binary](https://gogs.io/docs/installation/install_from_binary.html)
- [Install from source](https://gogs.io/docs/installation/install_from_source.html)
- [Install from packages](https://gogs.io/docs/installation/install_from_packages.html)
- [Ship with Docker](https://github.com/gogs/gogs/tree/main/docker)
- [Try with Vagrant](https://github.com/geerlingguy/ansible-vagrant-examples/tree/master/gogs)

### Deploy to cloud

- [Cloudron](https://www.cloudron.io/store/io.gogs.cloudronapp.html)
- [YunoHost](https://github.com/YunoHost-Apps/gogs_ynh)
- [alwaysdata](https://www.alwaysdata.com/en/marketplace/gogs/)

### Tutorials

- [Private Git Web Portal in Raspberry PI With Gogs](https://peppe8o.com/private-git-web-portal-in-raspberry-pi-with-gogs/)
- [How To Set Up Gogs on Ubuntu 14.04](https://www.digitalocean.com/community/tutorials/how-to-set-up-gogs-on-ubuntu-14-04)
- [Run your own GitHub-like service with the help of Docker](https://blog.hypriot.com/post/run-your-own-github-like-service-with-docker/)
- [Dockerized Gogs git server and alpine postgres in 20 minutes or less](https://garthwaite.org/docker-gogs.html)
- [Host Your Own Private GitHub with Gogs](https://eladnava.com/host-your-own-private-github-with-gogs-io/)
- [‰ΩøÁî® Gogs Êê≠Âª∫Ëá™Â∑±ÁöÑ Git ÊúçÂä°Âô®](https://blog.mynook.info/post/host-your-own-git-server-using-gogs/) (Chinese)
- [ÈòøÈáå‰∫ë‰∏ä Ubuntu 14.04 64 ‰ΩçÂÆâË£Ö Gogs](https://my.oschina.net/luyao/blog/375654) (Chinese)
- [Installing Gogs on FreeBSD](https://www.codejam.info/2015/03/installing-gogs-on-freebsd.html)
- [How to install Gogs on a Linux Server (DigitalOcean)](https://www.youtube.com/watch?v=deSfX0gqefE)

## üì¶ Software, service and product support

- [Jenkins](https://plugins.jenkins.io/gogs-webhook/) (CI)
- [Puppet](https://forge.puppet.com/modules/Siteminds/gogs) (IT)
- [Synology](https://www.synology.com) (Docker)
- [Syncloud](https://syncloud.org/) (App Store)

## üôá‚Äç‚ôÇÔ∏è Acknowledgments

&lt;p&gt;This project is proudly supported by:&lt;/p&gt;
&lt;p&gt;
  &lt;a href=&quot;https://www.digitalocean.com/&quot;&gt;
    &lt;img src=&quot;https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg&quot; width=&quot;201px&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

Other acknowledgments:

- Thanks [Egon Elbre](https://twitter.com/egonelbre) for designing the original version of the logo.
- Thanks [Crowdin](https://crowdin.com/project/gogs) for sponsoring open source translation plan.
- Thanks [MonoVM](https://monovm.com/linux-vps/) for sponsoring VPS services.
- Thanks [Buildkite](https://buildkite.com) for sponsoring open source CI/CD plan.

## üëã Contributors

- See [contributors page](https://github.com/gogs/gogs/graphs/contributors) for top 100 contributors.
- See [TRANSLATORS](conf/locale/TRANSLATORS) for public list of translators.

## ‚öñÔ∏è License

This project is under the MIT License. See the [LICENSE](https://github.com/gogs/gogs/blob/main/LICENSE) file for the full license text.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[aquasecurity/trivy]]></title>
            <link>https://github.com/aquasecurity/trivy</link>
            <guid>https://github.com/aquasecurity/trivy</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aquasecurity/trivy">aquasecurity/trivy</a></h1>
            <p>Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more</p>
            <p>Language: Go</p>
            <p>Stars: 25,185</p>
            <p>Forks: 2,467</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;docs/imgs/logo.png&quot; width=&quot;200&quot;&gt;

[![GitHub Release][release-img]][release]
[![Test][test-img]][test]
[![Go Report Card][go-report-img]][go-report]
[![License: Apache-2.0][license-img]][license]
[![GitHub Downloads][github-downloads-img]][release]
![Docker Pulls][docker-pulls]

[üìñ Documentation][docs]
&lt;/div&gt;

Trivy ([pronunciation][pronunciation]) is a comprehensive and versatile security scanner.
Trivy has *scanners* that look for security issues, and *targets* where it can find those issues.

Targets (what Trivy can scan):

- Container Image
- Filesystem
- Git Repository (remote)
- Virtual Machine Image
- Kubernetes

Scanners (what Trivy can find there):

- OS packages and software dependencies in use (SBOM)
- Known vulnerabilities (CVEs)
- IaC issues and misconfigurations
- Sensitive information and secrets
- Software licenses

Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the [Scanning Coverage] page.

To learn more, go to the [Trivy homepage][homepage] for feature highlights, or to the [Documentation site][docs] for detailed information.

## Quick Start

### Get Trivy

Trivy is available in most common distribution channels. The full list of installation options is available in the [Installation] page. Here are a few popular examples:

- `brew install trivy`
- `docker run aquasec/trivy`
- Download binary from &lt;https://github.com/aquasecurity/trivy/releases/latest/&gt;
- See [Installation] for more

Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the [Ecosystem] page. Here are a few popular examples:

- [GitHub Actions](https://github.com/aquasecurity/trivy-action)
- [Kubernetes operator](https://github.com/aquasecurity/trivy-operator)
- [VS Code plugin](https://github.com/aquasecurity/trivy-vscode-extension)
- See [Ecosystem] for more

### Canary builds
There are canary builds ([Docker Hub](https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;name=canary), [GitHub](https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary), [ECR](https://gallery.ecr.aws/aquasecurity/trivy#canary) images and [binaries](https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml)) as generated every push to main branch.

Please be aware: canary builds might have critical bugs, it&#039;s not recommended for use in production.

### General usage

```bash
trivy &lt;target&gt; [--scanners &lt;scanner1,scanner2&gt;] &lt;subject&gt;
```

Examples:

```bash
trivy image python:3.4-alpine
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov

&lt;/details&gt;

```bash
trivy fs --scanners vuln,secret,misconfig myproject/
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov

&lt;/details&gt;

```bash
trivy k8s --report summary cluster
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

![k8s summary](docs/imgs/trivy-k8s.png)

&lt;/details&gt;

## FAQ

### How to pronounce the name &quot;Trivy&quot;?

`tri` is pronounced like **tri**gger, `vy` is pronounced like en**vy**.

## Want more? Check out Aqua

If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.  
You can find a high level comparison table specific to Trivy users [here](https://trivy.dev/latest/commercial/compare/).
In addition check out the &lt;https://aquasec.com&gt; website for more information about our products and services.
If you&#039;d like to contact Aqua or request a demo, please use this form: &lt;https://www.aquasec.com/demo&gt;

## Community

Trivy is an [Aqua Security][aquasec] open source project.  
Learn about our open source work and portfolio [here][oss].  
Contact us about any matter by opening a GitHub Discussion [here][discussions]

Please ensure to abide by our [Code of Conduct][code-of-conduct] during all interactions.

[test]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml
[test-img]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg
[go-report]: https://goreportcard.com/report/github.com/aquasecurity/trivy
[go-report-img]: https://goreportcard.com/badge/github.com/aquasecurity/trivy
[release]: https://github.com/aquasecurity/trivy/releases
[release-img]: https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github
[github-downloads-img]: https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github
[docker-pulls]: https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;label=docker%20pulls%20%2F%20trivy
[license]: https://github.com/aquasecurity/trivy/blob/main/LICENSE
[license-img]: https://img.shields.io/badge/License-Apache%202.0-blue.svg
[homepage]: https://trivy.dev
[docs]: https://trivy.dev/latest/docs/
[pronunciation]: #how-to-pronounce-the-name-trivy
[code-of-conduct]: https://github.com/aquasecurity/community/blob/main/CODE_OF_CONDUCT.md

[Installation]:https://trivy.dev/latest/getting-started/installation/
[Ecosystem]: https://trivy.dev/latest/ecosystem/
[Scanning Coverage]: https://trivy.dev/latest/docs/coverage/

[alpine]: https://ariadne.space/2021/06/08/the-vulnerability-remediation-lifecycle-of-alpine-containers/
[rego]: https://www.openpolicyagent.org/docs/latest/#rego
[sigstore]: https://www.sigstore.dev/

[aquasec]: https://aquasec.com
[oss]: https://www.aquasec.com/products/open-source-projects/
[discussions]: https://github.com/aquasecurity/trivy/discussions
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[etcd-io/etcd]]></title>
            <link>https://github.com/etcd-io/etcd</link>
            <guid>https://github.com/etcd-io/etcd</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[Distributed reliable key-value store for the most critical data of a distributed system]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/etcd-io/etcd">etcd-io/etcd</a></h1>
            <p>Distributed reliable key-value store for the most critical data of a distributed system</p>
            <p>Language: Go</p>
            <p>Stars: 48,896</p>
            <p>Forks: 9,996</p>
            <p>Stars today: 57 stars today</p>
            <h2>README</h2><pre># etcd

[![Go Report Card](https://goreportcard.com/badge/github.com/etcd-io/etcd?style=flat-square)](https://goreportcard.com/report/github.com/etcd-io/etcd)
[![Coverage](https://codecov.io/gh/etcd-io/etcd/branch/main/graph/badge.svg)](https://app.codecov.io/gh/etcd-io/etcd/tree/main)
[![Tests](https://github.com/etcd-io/etcd/actions/workflows/tests.yaml/badge.svg)](https://github.com/etcd-io/etcd/actions/workflows/tests.yaml)
[![codeql-analysis](https://github.com/etcd-io/etcd/actions/workflows/codeql-analysis.yml/badge.svg)](https://github.com/etcd-io/etcd/actions/workflows/codeql-analysis.yml)
[![Docs](https://img.shields.io/badge/docs-latest-green.svg)](https://etcd.io/docs)
[![Godoc](http://img.shields.io/badge/go-documentation-blue.svg?style=flat-square)](https://godoc.org/github.com/etcd-io/etcd)
[![Releases](https://img.shields.io/github/release/etcd-io/etcd/all.svg?style=flat-square)](https://github.com/etcd-io/etcd/releases)
[![LICENSE](https://img.shields.io/github/license/etcd-io/etcd.svg?style=flat-square)](https://github.com/etcd-io/etcd/blob/main/LICENSE)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/etcd-io/etcd/badge)](https://scorecard.dev/viewer/?uri=github.com/etcd-io/etcd)

**Note**: The `main` branch may be in an *unstable or even broken state* during development. For stable versions, see [releases][github-release].

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/cncf/artwork/9870640f123303a355611065195c43ac3f27aa19/projects/etcd/horizontal/white/etcd-horizontal-white.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;logos/etcd-horizontal-color.svg&quot;&gt;
  &lt;img alt=&quot;etcd logo&quot; src=&quot;logos/etcd-horizontal-color.svg&quot; width=269 /&gt;
&lt;/picture&gt;

etcd is a distributed reliable key-value store for the most critical data of a distributed system, with a focus on being:

* *Simple*: well-defined, user-facing API (gRPC)
* *Secure*: automatic TLS with optional client cert authentication
* *Fast*: benchmarked 10,000 writes/sec
* *Reliable*: properly distributed using Raft

etcd is written in Go and uses the [Raft][] consensus algorithm to manage a highly-available replicated log.

etcd is used [in production by many companies](./ADOPTERS.md), and the development team stands behind it in critical deployment scenarios, where etcd is frequently teamed with applications such as [Kubernetes][k8s], [locksmith][], [vulcand][], [Doorman][], and many others. Reliability is further ensured by rigorous [**robustness testing**](https://github.com/etcd-io/etcd/tree/main/tests/robustness).

See [etcdctl][etcdctl] for a simple command line client.

![etcd reliability is important](logos/etcd-xkcd-2347.png)

&lt;sub&gt;Original image credited to  xkcd.com/2347, alterations by Josh Berkus.&lt;/sub&gt;

[raft]: https://raft.github.io/
[k8s]: http://kubernetes.io/
[doorman]: https://github.com/youtube/doorman
[locksmith]: https://github.com/coreos/locksmith
[vulcand]: https://github.com/vulcand/vulcand
[etcdctl]: https://github.com/etcd-io/etcd/tree/main/etcdctl

## Maintainers

[Maintainers](OWNERS) strive to shape an inclusive open source project culture where users are heard and contributors feel respected and empowered. Maintainers aim to build productive relationships across different companies and disciplines. Read more about [Maintainers role and responsibilities](Documentation/contributor-guide/community-membership.md#maintainers).

## Getting started

### Getting etcd

The easiest way to get etcd is to use one of the pre-built release binaries which are available for OSX, Linux, Windows, and Docker on the [release page][github-release].

For more installation guides, please check out [play.etcd.io](http://play.etcd.io) and [operating etcd](https://etcd.io/docs/latest/op-guide).

[github-release]: https://github.com/etcd-io/etcd/releases

### Running etcd

First start a single-member cluster of etcd.

If etcd is installed using the [pre-built release binaries][github-release], run it from the installation location as below:

```bash
/tmp/etcd-download-test/etcd
```

The etcd command can be simply run as such if it is moved to the system path as below:

```bash
mv /tmp/etcd-download-test/etcd /usr/local/bin/
etcd
```

This will bring up etcd listening on port 2379 for client communication and on port 2380 for server-to-server communication.

Next, let&#039;s set a single key, and then retrieve it:

```bash
etcdctl put mykey &quot;this is awesome&quot;
etcdctl get mykey
```

etcd is now running and serving client requests. For more, please check out:

* [Interactive etcd playground](http://play.etcd.io)
* [Animated quick demo](https://etcd.io/docs/latest/demo)

### etcd TCP ports

The [official etcd ports][iana-ports] are 2379 for client requests, and 2380 for peer communication.

[iana-ports]: http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt

### Running a local etcd cluster

First install [goreman](https://github.com/mattn/goreman), which manages Procfile-based applications.

Our [Procfile script](./Procfile) will set up a local example cluster. Start it with:

```bash
goreman start
```

This will bring up 3 etcd members `infra1`, `infra2` and `infra3` and optionally etcd `grpc-proxy`, which runs locally and composes a cluster.

Every cluster member and proxy accepts key value reads and key value writes.

Follow the comments in [Procfile script](./Procfile) to add a learner node to the cluster.

### Install etcd client v3

```bash
go get go.etcd.io/etcd/client/v3
```

### Next steps

Now it&#039;s time to dig into the full etcd API and other guides.

* Read the full [documentation].
* Review etcd [frequently asked questions].
* Explore the full gRPC [API].
* Set up a [multi-machine cluster][clustering].
* Learn the [config format, env variables and flags][configuration].
* Find [language bindings and tools][integrations].
* Use TLS to [secure an etcd cluster][security].
* [Tune etcd][tuning].

[documentation]: https://etcd.io/docs/latest
[api]: https://etcd.io/docs/latest/learning/api
[clustering]: https://etcd.io/docs/latest/op-guide/clustering
[configuration]: https://etcd.io/docs/latest/op-guide/configuration
[integrations]: https://etcd.io/docs/latest/integrations
[security]: https://etcd.io/docs/latest/op-guide/security
[tuning]: https://etcd.io/docs/latest/tuning

## Contact

* Email: [etcd-dev](https://groups.google.com/g/etcd-dev)
* Slack: [#sig-etcd](https://kubernetes.slack.com/archives/C3HD8ARJ5) channel on Kubernetes ([get an invite](http://slack.kubernetes.io/))
* [Community meetings](#community-meetings)

### Community meetings

etcd contributors and maintainers meet every week at `11:00` AM (USA Pacific) on Thursday and meetings alternate between community meetings and issue triage meetings. Meeting agendas are recorded in a [shared Google doc][shared-meeting-notes] and everyone is welcome to suggest additional topics or other agendas.

Issue triage meetings are aimed at getting through our backlog of PRs and Issues. Triage meetings are open to any contributor; you don&#039;t have to be a reviewer or approver to help out! They can also be a good way to get started contributing.

The meeting lead role is rotated for each meeting between etcd maintainers or sig-etcd leads and is recorded in a [shared Google sheet][shared-rotation-sheet].

Meeting recordings are uploaded to the official etcd [YouTube channel].

Get calendar invitations by joining [etcd-dev](https://groups.google.com/g/etcd-dev) mailing group.

Join the CNCF-funded Zoom channel: [zoom.us/my/cncfetcdproject](https://zoom.us/my/cncfetcdproject)

[shared-meeting-notes]: https://docs.google.com/document/d/16XEGyPBisZvmmoIHSZzv__LoyOeluC5a4x353CX0SIM/edit
[shared-rotation-sheet]: https://docs.google.com/spreadsheets/d/1jodHIO7Dk2VWTs1IRnfMFaRktS9IH8XRyifOnPdSY8I/edit
[YouTube channel]: https://www.youtube.com/@etcdio

## Contributing

See [CONTRIBUTING](CONTRIBUTING.md) for details on setting up your development environment, submitting patches and the contribution workflow.

Please refer to [community-membership.md](Documentation/contributor-guide/community-membership.md#member) for information on becoming an etcd project member.  We welcome and look forward to your contributions to the project!

Please also refer to [roadmap](Documentation/contributor-guide/roadmap.md) to get more details on the priorities for the next few major or minor releases.

## Reporting bugs

See [reporting bugs](https://github.com/etcd-io/etcd/blob/main/Documentation/contributor-guide/reporting_bugs.md) for details about reporting any issues. Before opening an issue please check it is not covered in our [frequently asked questions].

[frequently asked questions]: https://etcd.io/docs/latest/faq

## Reporting a security vulnerability

See [security disclosure and release process](security/README.md) for details on how to report a security vulnerability and how the etcd team manages it.

## Issue and PR management

See [issue triage guidelines](https://github.com/etcd-io/etcd/blob/main/Documentation/contributor-guide/triage_issues.md) for details on how issues are managed.

See [PR management](https://github.com/etcd-io/etcd/blob/main/Documentation/contributor-guide/triage_prs.md) for guidelines on how pull requests are managed.

## etcd Emeritus Maintainers

These emeritus maintainers dedicated a part of their career to etcd and reviewed code, triaged bugs and pushed the project forward over a substantial period of time. Their contribution is greatly appreciated.

* Fanmin Shi
* Anthony Romano
* Brandon Philips
* Joe Betz
* Gyuho Lee
* Jingyi Hu
* Xiang Li
* Ben Darnell
* Sam Batschelet
* Piotr Tabor
* Hitoshi Mitake

### License

etcd is under the Apache 2.0 license. See the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Calcium-Ion/new-api]]></title>
            <link>https://github.com/Calcium-Ion/new-api</link>
            <guid>https://github.com/Calcium-Ion/new-api</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[AIÊ®°ÂûãÊé•Âè£ÁÆ°ÁêÜ‰∏éÂàÜÂèëÁ≥ªÁªüÔºåÊîØÊåÅÂ∞ÜÂ§öÁßçÂ§ßÊ®°ÂûãËΩ¨‰∏∫Áªü‰∏ÄÊ†ºÂºèË∞ÉÁî®ÔºåÊîØÊåÅOpenAI„ÄÅClaudeÁ≠âÊ†ºÂºèÔºåÂèØ‰æõ‰∏™‰∫∫ÊàñËÄÖ‰ºÅ‰∏öÂÜÖÈÉ®ÁÆ°ÁêÜ‰∏éÂàÜÂèëÊ∏†ÈÅì‰ΩøÁî®ÔºåÊú¨È°πÁõÆÂü∫‰∫éOne API‰∫åÊ¨°ÂºÄÂèë„ÄÇüç• The next-generation LLM gateway and AI asset management system supports multiple languages.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Calcium-Ion/new-api">Calcium-Ion/new-api</a></h1>
            <p>AIÊ®°ÂûãÊé•Âè£ÁÆ°ÁêÜ‰∏éÂàÜÂèëÁ≥ªÁªüÔºåÊîØÊåÅÂ∞ÜÂ§öÁßçÂ§ßÊ®°ÂûãËΩ¨‰∏∫Áªü‰∏ÄÊ†ºÂºèË∞ÉÁî®ÔºåÊîØÊåÅOpenAI„ÄÅClaudeÁ≠âÊ†ºÂºèÔºåÂèØ‰æõ‰∏™‰∫∫ÊàñËÄÖ‰ºÅ‰∏öÂÜÖÈÉ®ÁÆ°ÁêÜ‰∏éÂàÜÂèëÊ∏†ÈÅì‰ΩøÁî®ÔºåÊú¨È°πÁõÆÂü∫‰∫éOne API‰∫åÊ¨°ÂºÄÂèë„ÄÇüç• The next-generation LLM gateway and AI asset management system supports multiple languages.</p>
            <p>Language: Go</p>
            <p>Stars: 6,248</p>
            <p>Forks: 1,252</p>
            <p>Stars today: 31 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;right&quot;&gt;
   &lt;strong&gt;‰∏≠Êñá&lt;/strong&gt; | &lt;a href=&quot;./README.en.md&quot;&gt;English&lt;/a&gt;
&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;

![new-api](/web/public/logo.png)

# New API

üç•Êñ∞‰∏Ä‰ª£Â§ßÊ®°ÂûãÁΩëÂÖ≥‰∏éAIËµÑ‰∫ßÁÆ°ÁêÜÁ≥ªÁªü

&lt;a href=&quot;https://trendshift.io/repositories/8227&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/8227&quot; alt=&quot;Calcium-Ion%2Fnew-api | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://raw.githubusercontent.com/Calcium-Ion/new-api/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/Calcium-Ion/new-api?color=brightgreen&quot; alt=&quot;license&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/Calcium-Ion/new-api/releases/latest&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/v/release/Calcium-Ion/new-api?color=brightgreen&amp;include_prereleases&quot; alt=&quot;release&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/users/Calcium-Ion/packages/container/package/new-api&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/docker-ghcr.io-blue&quot; alt=&quot;docker&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://hub.docker.com/r/CalciumIon/new-api&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/docker-dockerHub-blue&quot; alt=&quot;docker&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/Calcium-Ion/new-api&quot;&gt;
    &lt;img src=&quot;https://goreportcard.com/badge/github.com/Calcium-Ion/new-api&quot; alt=&quot;GoReportCard&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

## üìù È°πÁõÆËØ¥Êòé

&gt; [!NOTE]  
&gt; Êú¨È°πÁõÆ‰∏∫ÂºÄÊ∫êÈ°πÁõÆÔºåÂú®[One API](https://github.com/songquanpeng/one-api)ÁöÑÂü∫Á°Ä‰∏äËøõË°å‰∫åÊ¨°ÂºÄÂèë

&gt; [!IMPORTANT]  
&gt; - Êú¨È°πÁõÆ‰ªÖ‰æõ‰∏™‰∫∫Â≠¶‰π†‰ΩøÁî®Ôºå‰∏ç‰øùËØÅÁ®≥ÂÆöÊÄßÔºå‰∏î‰∏çÊèê‰æõ‰ªª‰ΩïÊäÄÊúØÊîØÊåÅ„ÄÇ
&gt; - ‰ΩøÁî®ËÄÖÂøÖÈ°ªÂú®ÈÅµÂæ™ OpenAI ÁöÑ[‰ΩøÁî®Êù°Ê¨æ](https://openai.com/policies/terms-of-use)‰ª•Âèä**Ê≥ïÂæãÊ≥ïËßÑ**ÁöÑÊÉÖÂÜµ‰∏ã‰ΩøÁî®Ôºå‰∏çÂæóÁî®‰∫éÈùûÊ≥ïÁî®ÈÄî„ÄÇ
&gt; - Ê†πÊçÆ[„ÄäÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúçÂä°ÁÆ°ÁêÜÊöÇË°åÂäûÊ≥ï„Äã](http://www.cac.gov.cn/2023-07/13/c_1690898327029107.htm)ÁöÑË¶ÅÊ±ÇÔºåËØ∑ÂãøÂØπ‰∏≠ÂõΩÂú∞Âå∫ÂÖ¨‰ºóÊèê‰æõ‰∏ÄÂàáÊú™ÁªèÂ§áÊ°àÁöÑÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúçÂä°„ÄÇ

## üìö ÊñáÊ°£

ËØ¶ÁªÜÊñáÊ°£ËØ∑ËÆøÈóÆÊàë‰ª¨ÁöÑÂÆòÊñπWikiÔºö[https://docs.newapi.pro/](https://docs.newapi.pro/)

## ‚ú® ‰∏ªË¶ÅÁâπÊÄß

New APIÊèê‰æõ‰∫Ü‰∏∞ÂØåÁöÑÂäüËÉΩÔºåËØ¶ÁªÜÁâπÊÄßËØ∑ÂèÇËÄÉ[ÁâπÊÄßËØ¥Êòé](https://docs.newapi.pro/wiki/features-introduction)Ôºö

1. üé® ÂÖ®Êñ∞ÁöÑUIÁïåÈù¢
2. üåç Â§öËØ≠Ë®ÄÊîØÊåÅ
3. üí∞ ÊîØÊåÅÂú®Á∫øÂÖÖÂÄºÂäüËÉΩÔºàÊòìÊîØ‰ªòÔºâ
4. üîç ÊîØÊåÅÁî®keyÊü•ËØ¢‰ΩøÁî®È¢ùÂ∫¶ÔºàÈÖçÂêà[neko-api-key-tool](https://github.com/Calcium-Ion/neko-api-key-tool)Ôºâ
5. üîÑ ÂÖºÂÆπÂéüÁâàOne APIÁöÑÊï∞ÊçÆÂ∫ì
6. üíµ ÊîØÊåÅÊ®°ÂûãÊåâÊ¨°Êï∞Êî∂Ë¥π
7. ‚öñÔ∏è ÊîØÊåÅÊ∏†ÈÅìÂä†ÊùÉÈöèÊú∫
8. üìà Êï∞ÊçÆÁúãÊùøÔºàÊéßÂà∂Âè∞Ôºâ
9. üîí ‰ª§ÁâåÂàÜÁªÑ„ÄÅÊ®°ÂûãÈôêÂà∂
10. ü§ñ ÊîØÊåÅÊõ¥Â§öÊéàÊùÉÁôªÈôÜÊñπÂºèÔºàLinuxDO,Telegram„ÄÅOIDCÔºâ
11. üîÑ ÊîØÊåÅRerankÊ®°ÂûãÔºàCohereÂíåJinaÔºâÔºå[Êé•Âè£ÊñáÊ°£](https://docs.newapi.pro/api/jinaai-rerank)
12. ‚ö° ÊîØÊåÅOpenAI Realtime APIÔºàÂåÖÊã¨AzureÊ∏†ÈÅìÔºâÔºå[Êé•Âè£ÊñáÊ°£](https://docs.newapi.pro/api/openai-realtime)
13. ‚ö° ÊîØÊåÅClaude Messages Ê†ºÂºèÔºå[Êé•Âè£ÊñáÊ°£](https://docs.newapi.pro/api/anthropic-chat)
14. ÊîØÊåÅ‰ΩøÁî®Ë∑ØÁî±/chat2linkËøõÂÖ•ËÅäÂ§©ÁïåÈù¢
15. üß† ÊîØÊåÅÈÄöËøáÊ®°ÂûãÂêçÁß∞ÂêéÁºÄËÆæÁΩÆ reasoning effortÔºö
    1. OpenAI oÁ≥ªÂàóÊ®°Âûã
        - Ê∑ªÂä†ÂêéÁºÄ `-high` ËÆæÁΩÆ‰∏∫ high reasoning effort (‰æãÂ¶Ç: `o3-mini-high`)
        - Ê∑ªÂä†ÂêéÁºÄ `-medium` ËÆæÁΩÆ‰∏∫ medium reasoning effort (‰æãÂ¶Ç: `o3-mini-medium`)
        - Ê∑ªÂä†ÂêéÁºÄ `-low` ËÆæÁΩÆ‰∏∫ low reasoning effort (‰æãÂ¶Ç: `o3-mini-low`)
    2. Claude ÊÄùËÄÉÊ®°Âûã
        - Ê∑ªÂä†ÂêéÁºÄ `-thinking` ÂêØÁî®ÊÄùËÄÉÊ®°Âºè (‰æãÂ¶Ç: `claude-3-7-sonnet-20250219-thinking`)
16. üîÑ ÊÄùËÄÉËΩ¨ÂÜÖÂÆπÂäüËÉΩ
17. üîÑ ÈíàÂØπÁî®Êà∑ÁöÑÊ®°ÂûãÈôêÊµÅÂäüËÉΩ
18. üí∞ ÁºìÂ≠òËÆ°Ë¥πÊîØÊåÅÔºåÂºÄÂêØÂêéÂèØ‰ª•Âú®ÁºìÂ≠òÂëΩ‰∏≠Êó∂ÊåâÁÖßËÆæÂÆöÁöÑÊØî‰æãËÆ°Ë¥πÔºö
    1. Âú® `Á≥ªÁªüËÆæÁΩÆ-ËøêËê•ËÆæÁΩÆ` ‰∏≠ËÆæÁΩÆ `ÊèêÁ§∫ÁºìÂ≠òÂÄçÁéá` ÈÄâÈ°π
    2. Âú®Ê∏†ÈÅì‰∏≠ËÆæÁΩÆ `ÊèêÁ§∫ÁºìÂ≠òÂÄçÁéá`ÔºåËåÉÂõ¥ 0-1Ôºå‰æãÂ¶ÇËÆæÁΩÆ‰∏∫ 0.5 Ë°®Á§∫ÁºìÂ≠òÂëΩ‰∏≠Êó∂ÊåâÁÖß 50% ËÆ°Ë¥π
    3. ÊîØÊåÅÁöÑÊ∏†ÈÅìÔºö
        - [x] OpenAI
        - [x] Azure
        - [x] DeepSeek
        - [x] Claude

## Ê®°ÂûãÊîØÊåÅ

Ê≠§ÁâàÊú¨ÊîØÊåÅÂ§öÁßçÊ®°ÂûãÔºåËØ¶ÊÉÖËØ∑ÂèÇËÄÉ[Êé•Âè£ÊñáÊ°£-‰∏≠ÁªßÊé•Âè£](https://docs.newapi.pro/api)Ôºö

1. Á¨¨‰∏âÊñπÊ®°Âûã **gpts** Ôºàgpt-4-gizmo-*Ôºâ
2. Á¨¨‰∏âÊñπÊ∏†ÈÅì[Midjourney-Proxy(Plus)](https://github.com/novicezk/midjourney-proxy)Êé•Âè£Ôºå[Êé•Âè£ÊñáÊ°£](https://docs.newapi.pro/api/midjourney-proxy-image)
3. Á¨¨‰∏âÊñπÊ∏†ÈÅì[Suno API](https://github.com/Suno-API/Suno-API)Êé•Âè£Ôºå[Êé•Âè£ÊñáÊ°£](https://docs.newapi.pro/api/suno-music)
4. Ëá™ÂÆö‰πâÊ∏†ÈÅìÔºåÊîØÊåÅÂ°´ÂÖ•ÂÆåÊï¥Ë∞ÉÁî®Âú∞ÂùÄ
5. RerankÊ®°ÂûãÔºà[Cohere](https://cohere.ai/)Âíå[Jina](https://jina.ai/)ÔºâÔºå[Êé•Âè£ÊñáÊ°£](https://docs.newapi.pro/api/jinaai-rerank)
6. Claude Messages Ê†ºÂºèÔºå[Êé•Âè£ÊñáÊ°£](https://docs.newapi.pro/api/anthropic-chat)
7. DifyÔºåÂΩìÂâç‰ªÖÊîØÊåÅchatflow

## ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ

ËØ¶ÁªÜÈÖçÁΩÆËØ¥ÊòéËØ∑ÂèÇËÄÉ[ÂÆâË£ÖÊåáÂçó-ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ](https://docs.newapi.pro/installation/environment-variables)Ôºö

- `GENERATE_DEFAULT_TOKEN`ÔºöÊòØÂê¶‰∏∫Êñ∞Ê≥®ÂÜåÁî®Êà∑ÁîüÊàêÂàùÂßã‰ª§ÁâåÔºåÈªòËÆ§‰∏∫ `false`
- `STREAMING_TIMEOUT`ÔºöÊµÅÂºèÂõûÂ§çË∂ÖÊó∂Êó∂Èó¥ÔºåÈªòËÆ§60Áßí
- `DIFY_DEBUG`ÔºöDifyÊ∏†ÈÅìÊòØÂê¶ËæìÂá∫Â∑•‰ΩúÊµÅÂíåËäÇÁÇπ‰ø°ÊÅØÔºåÈªòËÆ§ `true`
- `FORCE_STREAM_OPTION`ÔºöÊòØÂê¶Ë¶ÜÁõñÂÆ¢Êà∑Á´Østream_optionsÂèÇÊï∞ÔºåÈªòËÆ§ `true`
- `GET_MEDIA_TOKEN`ÔºöÊòØÂê¶ÁªüËÆ°ÂõæÁâátokenÔºåÈªòËÆ§ `true`
- `GET_MEDIA_TOKEN_NOT_STREAM`ÔºöÈùûÊµÅÊÉÖÂÜµ‰∏ãÊòØÂê¶ÁªüËÆ°ÂõæÁâátokenÔºåÈªòËÆ§ `true`
- `UPDATE_TASK`ÔºöÊòØÂê¶Êõ¥Êñ∞ÂºÇÊ≠•‰ªªÂä°ÔºàMidjourney„ÄÅSunoÔºâÔºåÈªòËÆ§ `true`
- `COHERE_SAFETY_SETTING`ÔºöCohereÊ®°ÂûãÂÆâÂÖ®ËÆæÁΩÆÔºåÂèØÈÄâÂÄº‰∏∫ `NONE`, `CONTEXTUAL`, `STRICT`ÔºåÈªòËÆ§ `NONE`
- `GEMINI_VISION_MAX_IMAGE_NUM`ÔºöGeminiÊ®°ÂûãÊúÄÂ§ßÂõæÁâáÊï∞ÈáèÔºåÈªòËÆ§ `16`
- `MAX_FILE_DOWNLOAD_MB`: ÊúÄÂ§ßÊñá‰ª∂‰∏ãËΩΩÂ§ßÂ∞èÔºåÂçï‰ΩçMBÔºåÈªòËÆ§ `20`
- `CRYPTO_SECRET`ÔºöÂä†ÂØÜÂØÜÈí•ÔºåÁî®‰∫éÂä†ÂØÜÊï∞ÊçÆÂ∫ìÂÜÖÂÆπ
- `AZURE_DEFAULT_API_VERSION`ÔºöAzureÊ∏†ÈÅìÈªòËÆ§APIÁâàÊú¨ÔºåÈªòËÆ§ `2024-12-01-preview`
- `NOTIFICATION_LIMIT_DURATION_MINUTE`ÔºöÈÄöÁü•ÈôêÂà∂ÊåÅÁª≠Êó∂Èó¥ÔºåÈªòËÆ§ `10`ÂàÜÈíü
- `NOTIFY_LIMIT_COUNT`ÔºöÁî®Êà∑ÈÄöÁü•Âú®ÊåáÂÆöÊåÅÁª≠Êó∂Èó¥ÂÜÖÁöÑÊúÄÂ§ßÊï∞ÈáèÔºåÈªòËÆ§ `2`

## ÈÉ®ÁΩ≤

ËØ¶ÁªÜÈÉ®ÁΩ≤ÊåáÂçóËØ∑ÂèÇËÄÉ[ÂÆâË£ÖÊåáÂçó-ÈÉ®ÁΩ≤ÊñπÂºè](https://docs.newapi.pro/installation)Ôºö

&gt; [!TIP]
&gt; ÊúÄÊñ∞ÁâàDockerÈïúÂÉèÔºö`calciumion/new-api:latest`  
&gt; ÈªòËÆ§Ë¥¶Âè∑root ÂØÜÁ†Å123456

### Â§öÊú∫ÈÉ®ÁΩ≤Ê≥®ÊÑè‰∫ãÈ°π
- ÂøÖÈ°ªËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè `SESSION_SECRET`ÔºåÂê¶Âàô‰ºöÂØºËá¥Â§öÊú∫ÈÉ®ÁΩ≤Êó∂ÁôªÂΩïÁä∂ÊÄÅ‰∏ç‰∏ÄËá¥
- Â¶ÇÊûúÂÖ¨Áî®RedisÔºåÂøÖÈ°ªËÆæÁΩÆ `CRYPTO_SECRET`ÔºåÂê¶Âàô‰ºöÂØºËá¥Â§öÊú∫ÈÉ®ÁΩ≤Êó∂RedisÂÜÖÂÆπÊó†Ê≥ïËé∑Âèñ

### ÈÉ®ÁΩ≤Ë¶ÅÊ±Ç
- Êú¨Âú∞Êï∞ÊçÆÂ∫ìÔºàÈªòËÆ§ÔºâÔºöSQLiteÔºàDockerÈÉ®ÁΩ≤ÂøÖÈ°ªÊåÇËΩΩ`/data`ÁõÆÂΩïÔºâ
- ËøúÁ®ãÊï∞ÊçÆÂ∫ìÔºöMySQLÁâàÊú¨ &gt;= 5.7.8ÔºåPgSQLÁâàÊú¨ &gt;= 9.6

### ÈÉ®ÁΩ≤ÊñπÂºè

#### ‰ΩøÁî®ÂÆùÂ°îÈù¢ÊùøDockerÂäüËÉΩÈÉ®ÁΩ≤
ÂÆâË£ÖÂÆùÂ°îÈù¢ÊùøÔºà**9.2.0ÁâàÊú¨**Âèä‰ª•‰∏äÔºâÔºåÂú®Â∫îÁî®ÂïÜÂ∫ó‰∏≠ÊâæÂà∞**New-API**ÂÆâË£ÖÂç≥ÂèØ„ÄÇ
[ÂõæÊñáÊïôÁ®ã](BT.md)

#### ‰ΩøÁî®Docker ComposeÈÉ®ÁΩ≤ÔºàÊé®ËçêÔºâ
```shell
# ‰∏ãËΩΩÈ°πÁõÆ
git clone https://github.com/Calcium-Ion/new-api.git
cd new-api
# ÊåâÈúÄÁºñËæëdocker-compose.yml
# ÂêØÂä®
docker-compose up -d
```

#### Áõ¥Êé•‰ΩøÁî®DockerÈïúÂÉè
```shell
# ‰ΩøÁî®SQLite
docker run --name new-api -d --restart always -p 3000:3000 -e TZ=Asia/Shanghai -v /home/ubuntu/data/new-api:/data calciumion/new-api:latest

# ‰ΩøÁî®MySQL
docker run --name new-api -d --restart always -p 3000:3000 -e SQL_DSN=&quot;root:123456@tcp(localhost:3306)/oneapi&quot; -e TZ=Asia/Shanghai -v /home/ubuntu/data/new-api:/data calciumion/new-api:latest
```

## Ê∏†ÈÅìÈáçËØï‰∏éÁºìÂ≠ò
Ê∏†ÈÅìÈáçËØïÂäüËÉΩÂ∑≤ÁªèÂÆûÁé∞ÔºåÂèØ‰ª•Âú®`ËÆæÁΩÆ-&gt;ËøêËê•ËÆæÁΩÆ-&gt;ÈÄöÁî®ËÆæÁΩÆ`ËÆæÁΩÆÈáçËØïÊ¨°Êï∞Ôºå**Âª∫ËÆÆÂºÄÂêØÁºìÂ≠ò**ÂäüËÉΩ„ÄÇ

### ÁºìÂ≠òËÆæÁΩÆÊñπÊ≥ï
1. `REDIS_CONN_STRING`ÔºöËÆæÁΩÆRedis‰Ωú‰∏∫ÁºìÂ≠ò
2. `MEMORY_CACHE_ENABLED`ÔºöÂêØÁî®ÂÜÖÂ≠òÁºìÂ≠òÔºàËÆæÁΩÆ‰∫ÜRedisÂàôÊó†ÈúÄÊâãÂä®ËÆæÁΩÆÔºâ

## Êé•Âè£ÊñáÊ°£

ËØ¶ÁªÜÊé•Âè£ÊñáÊ°£ËØ∑ÂèÇËÄÉ[Êé•Âè£ÊñáÊ°£](https://docs.newapi.pro/api)Ôºö

- [ËÅäÂ§©Êé•Âè£ÔºàChatÔºâ](https://docs.newapi.pro/api/openai-chat)
- [ÂõæÂÉèÊé•Âè£ÔºàImageÔºâ](https://docs.newapi.pro/api/openai-image)
- [ÈáçÊéíÂ∫èÊé•Âè£ÔºàRerankÔºâ](https://docs.newapi.pro/api/jinaai-rerank)
- [ÂÆûÊó∂ÂØπËØùÊé•Âè£ÔºàRealtimeÔºâ](https://docs.newapi.pro/api/openai-realtime)
- [ClaudeËÅäÂ§©Êé•Âè£ÔºàmessagesÔºâ](https://docs.newapi.pro/api/anthropic-chat)

## Áõ∏ÂÖ≥È°πÁõÆ
- [One API](https://github.com/songquanpeng/one-api)ÔºöÂéüÁâàÈ°πÁõÆ
- [Midjourney-Proxy](https://github.com/novicezk/midjourney-proxy)ÔºöMidjourneyÊé•Âè£ÊîØÊåÅ
- [chatnio](https://github.com/Deeptrain-Community/chatnio)Ôºö‰∏ã‰∏Ä‰ª£AI‰∏ÄÁ´ôÂºèB/CÁ´ØËß£ÂÜ≥ÊñπÊ°à
- [neko-api-key-tool](https://github.com/Calcium-Ion/neko-api-key-tool)ÔºöÁî®keyÊü•ËØ¢‰ΩøÁî®È¢ùÂ∫¶

ÂÖ∂‰ªñÂü∫‰∫éNew APIÁöÑÈ°πÁõÆÔºö
- [new-api-horizon](https://github.com/Calcium-Ion/new-api-horizon)ÔºöNew APIÈ´òÊÄßËÉΩ‰ºòÂåñÁâà
- [VoAPI](https://github.com/VoAPI/VoAPI)ÔºöÂü∫‰∫éNew APIÁöÑÂâçÁ´ØÁæéÂåñÁâàÊú¨

## Â∏ÆÂä©ÊîØÊåÅ

Â¶ÇÊúâÈóÆÈ¢òÔºåËØ∑ÂèÇËÄÉ[Â∏ÆÂä©ÊîØÊåÅ](https://docs.newapi.pro/support)Ôºö
- [Á§æÂå∫‰∫§ÊµÅ](https://docs.newapi.pro/support/community-interaction)
- [ÂèçÈ¶àÈóÆÈ¢ò](https://docs.newapi.pro/support/feedback-issues)
- [Â∏∏ËßÅÈóÆÈ¢ò](https://docs.newapi.pro/support/faq)

## üåü Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Calcium-Ion/new-api&amp;type=Date)](https://star-history.com/#Calcium-Ion/new-api&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[pulumi/pulumi-aws]]></title>
            <link>https://github.com/pulumi/pulumi-aws</link>
            <guid>https://github.com/pulumi/pulumi-aws</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[An Amazon Web Services (AWS) Pulumi resource package, providing multi-language access to AWS]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pulumi/pulumi-aws">pulumi/pulumi-aws</a></h1>
            <p>An Amazon Web Services (AWS) Pulumi resource package, providing multi-language access to AWS</p>
            <p>Language: Go</p>
            <p>Stars: 541</p>
            <p>Forks: 167</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.pulumi.com?utm_campaign=pulumi-pulumi-aws-github-repo&amp;utm_source=github.com&amp;utm_medium=top-logo&quot; title=&quot;Pulumi AWS Provider - Build and Deploy Infrastructure as Code Solutions on Any Cloud&quot;&gt;
    &lt;img src=&quot;https://www.pulumi.com/images/logo/logo-on-white-box.svg?&quot; width=&quot;350&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

[![Actions Status](https://github.com/pulumi/pulumi-aws/workflows/master/badge.svg)](https://github.com/pulumi/pulumi-aws/actions)
[![Slack](http://www.pulumi.com/images/docs/badges/slack.svg)](https://slack.pulumi.com)
[![NPM version](https://badge.fury.io/js/%40pulumi%2Faws.svg)](https://www.npmjs.com/package/@pulumi/aws)
[![Python version](https://badge.fury.io/py/pulumi-aws.svg)](https://pypi.org/project/pulumi-aws)
[![NuGet version](https://badge.fury.io/nu/pulumi.aws.svg)](https://badge.fury.io/nu/pulumi.aws)
[![PkgGoDev](https://pkg.go.dev/badge/github.com/pulumi/pulumi-aws/sdk/v6/go)](https://pkg.go.dev/github.com/pulumi/pulumi-aws/sdk/v6/go)
[![License](https://img.shields.io/github/license/pulumi/pulumi-aws)](https://github.com/pulumi/pulumi-aws/blob/master/LICENSE)

# Amazon Web Services (AWS) provider

The Amazon Web Services (AWS) resource provider for Pulumi lets you use AWS resources in your cloud programs. To use
this package, [install the Pulumi CLI](https://www.pulumi.com/docs/get-started/install/). For a streamlined Pulumi walkthrough, including language runtime installation and AWS configuration, select &quot;Get Started&quot; below.

&lt;div&gt;
    &lt;a href=&quot;https://www.pulumi.com/docs/get-started/aws/?utm_campaign=pulumi-pulumi-aws-github-repo&amp;utm_source=github.com&amp;utm_medium=get-started&quot; title=&quot;Get Started&quot;&gt;
       &lt;img src=&quot;https://www.pulumi.com/images/get-started.svg?&quot; width=&quot;120&quot;&gt;
    &lt;/a&gt;
&lt;/div&gt;

## Installing

This package is available in many languages in the standard packaging formats.

### Node.js (Java/TypeScript)

To use from JavaScript or TypeScript in Node.js, install using either `npm`:

    $ npm install @pulumi/aws

or `yarn`:

    $ yarn add @pulumi/aws

### Python

To use from Python, install using `pip`:

    $ pip install pulumi_aws

### Go

To use from Go, use `go get` to grab the latest version of the library

    $ go get github.com/pulumi/pulumi-aws/sdk/v6

### .NET

To use from .NET, install using `dotnet add package`:

    $ dotnet add package Pulumi.Aws

## Concepts

The `@pulumi/aws` package provides a strongly-typed means to create cloud applications that create and interact closely
with AWS resources.  Resources are exposed for the entirety of AWS resources and their properties, including (but not
limited to), &#039;apigateway&#039;, &#039;cloudformation&#039;, &#039;EC2&#039;, &#039;ECS&#039;, &#039;iam&#039;, &#039;lambda&#039;, etc.  Many convenience APIs have also been
added to make development easier and to help avoid common mistakes, and to get stronger typing.

### Serverless Functions

The `aws.lambda.CallbackFunction` class allows you to create an AWS lambda function directly out of a JavaScript/TypeScript
function object of the right signature. This allows a Pulumi program to simply define a lambda using a simple lambda in
the language of choice, while having Pulumi itself do the appropriate transformation into the final AWS Lambda resource.

This makes many APIs easier to use, such as defining a Lambda to execute when an S3 Bucket is manipulated,
or a CloudWatch timer is fired. To see some examples of this in action, please refer to the `examples/` directory.

## Configuration

The following configuration points are available:

- `aws:region` - (Required) This is the AWS region.

- `aws:accessKey` - (Optional) This is the AWS access key. It can also be sourced from the
  `AWS_ACCESS_KEY_ID` environment variable, or via a shared credentials file if `aws:profile` is specified.
- `aws:secretKey` - (Optional) This is the AWS secret key. It can also be sourced from the
  `AWS_SECRET_ACCESS_KEY` environment variable, or via a shared credentials file if `aws:profile` is specified.
- `aws:profile` - (Optional) This is the AWS profile name as set in the shared credentials file.
- `aws:sharedCredentialsFiles` - (Optional) List of paths to the shared credentials file. If not set and a profile
  is used, the default value is [~/.aws/credentials]. A single value can also be set with the
  `AWS_SHARED_CREDENTIALS_FILE` environment variable.
- `aws:token` - (Optional) Session token for validating temporary credentials. Typically provided after successful
  identity federation or Multi-Factor Authentication (MFA) login. With MFA login, this is the session token provided
  afterward, not the 6 digit MFA code used to get temporary credentials. It can also be sourced from the
  `AWS_SESSION_TOKEN` environment variable.
- `aws:maxRetries` - (Optional) This is the maximum number of times an API call is retried, in the case where requests
  are being throttled or experiencing transient failures. The delay between the subsequent API calls increases
  exponentially. If omitted, the default value is `25`.
- `aws:allowedAccountIds` - (Optional)  List of allowed AWS account IDs to prevent you from mistakenly using an incorrect
  one. Conflicts with `aws:forbiddenAccountIds`.
- `aws:endpoints` - (Optional) Configuration block for customizing service endpoints. See the Custom Service Endpoints Guide for more information about connecting to alternate AWS endpoints or AWS compatible solutions. See also `aws:useFipsEndpoint`.
- `aws:forbiddenAccountIds` - (Optional) List of forbidden AWS account IDs to prevent you from mistakenly using the wrong
  one. Conflicts with `aws:allowedAccountIds`.
- `aws:assumeRole` - (Optional) Supports the following (optional) arguments:
  `durationSections`: Number of seconds to restrict the assume role session duration.
  `externalId`: External identifier to use when assuming the role.
  `policy`: IAM Policy JSON describing further restricting permissions for the IAM Role being assumed.
  `policyArns`: Set of Amazon Resource Names (ARNs) of IAM Policies describing further restricting permissions for the role.
  `roleArn`: Amazon Resource Name (ARN) of the IAM Role to assume.
  `sessionName`: Session name to use when assuming the role.
  `tags`: Map of assume role session tags.
- `aws:insecure` - (Optional) Explicitly allow the provider to perform &quot;insecure&quot; SSL requests. If omitted, the default value is `false`.
- `aws:skipCredentialsValidation` - (Optional) Skip the credentials validation via the STS API. Useful for AWS API implementations that do not have STS available or implemented. Default value is `false`. Can be set via the environment variable `AWS_SKIP_CREDENTIALS_VALIDATION`.
- `aws:skipRegionValidation` - (Optional) Skip validation of provided region name. Useful for AWS-like implementations that use their own region names or to bypass the validation for regions that aren&#039;t publicly available yet. Default value is `true`.
- `aws:skipRequestionAccountId` - (Optional) Skip requesting the account ID. Useful for AWS API implementations that do not have the IAM, STS API, or metadata API. Default value is `false`. When specified, the use of ARNs is compromised as there is no accountID available to construct the ARN.
- `aws:skipMetadataApiCheck` - (Optional) Skip the AWS Metadata API check. Useful for AWS API implementations that do not have a metadata API endpoint. This provider from authenticating via the Metadata API by default. You may need to use other authentication methods like static credentials, configuration variables, or environment variables. Can be set via the environment variable `AWS_SKIP_METADATA_API_CHECK`.
- `aws:s3UsePathStyle` - (Optional) Set this to true to force the request to use path-style addressing, i.e., `http://s3.amazonaws.com/BUCKET/KEY`. By default, the S3 client will use virtual hosted bucket addressing, `http://BUCKET.s3.amazonaws.com/KEY`, when possible. Specific to the Amazon S3 service. Default is `false`.
- `aws:useFipsEndpoint` - (Optional) Force the provider to resolve endpoints with FIPS capability. Can also be set with the `AWS_USE_FIPS_ENDPOINT` environment variable.

## Reference

For further information, visit [AWS in the Pulumi Registry](https://www.pulumi.com/registry/packages/aws/?utm_campaign=pulumi-pulumi-aws-github-repo&amp;utm_source=github.com&amp;utm_medium=reference)
or for detailed API reference documentation, visit [AWS API Docs in the Pulumi Registry](https://www.pulumi.com/registry/packages/aws/api-docs/?utm_campaign=pulumi-pulumi-aws-github-repo&amp;utm_source=github.com&amp;utm_medium=reference).

## Pulumi developer resources

Delve deeper into our project with additional resources:

- [Get Started with Pulumi](https://www.pulumi.com/docs/get-started/?utm_campaign=pulumi-pulumi-aws-github-repo&amp;utm_source=github.com&amp;utm_medium=examples-resources): Deploy a simple application in AWS, Azure, Google Cloud, or Kubernetes using Pulumi.
- [Documentation](https://www.pulumi.com/docs/?utm_campaign=pulumi-pulumi-aws-github-repo&amp;utm_source=github.com&amp;utm_medium=examples-resources): Learn about Pulumi concepts, follow user guides, and consult the reference documentation.
- [Pulumi Blog](https://www.pulumi.com/blog/?utm_campaign=pulumi-pulumi-aws-github-repo&amp;utm_source=github.com&amp;utm_medium=examples-resources) - Stay in the loop with our latest tech announcements, insightful articles, and updates.
- [Registry](https://www.pulumi.com/registry/?utm_campaign=pulumi-pulumi-aws-github-repo&amp;utm_source=github.com&amp;utm_medium=examples-resources): Search for packages and learn about the supported resources you need. Install the package directly into your project, browse the API documentation, and start building.
- [Try Pulumi AI](https://www.pulumi.com/ai/?utm_campaign=pulumi-pulumi-aws-github-repo&amp;utm_source=github.com&amp;utm_medium=examples-resources) - Use natural-language prompts to generate Pulumi infrastructure-as-code programs in any language.

## Pulumi roadmap

Review the planned work for the upcoming quarter and a selected backlog of issues that are on our mind but not yet scheduled on the [Pulumi Roadmap.](https://github.com/orgs/pulumi/projects/44)</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes/ingress-nginx]]></title>
            <link>https://github.com/kubernetes/ingress-nginx</link>
            <guid>https://github.com/kubernetes/ingress-nginx</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[Ingress NGINX Controller for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes/ingress-nginx">kubernetes/ingress-nginx</a></h1>
            <p>Ingress NGINX Controller for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 18,294</p>
            <p>Forks: 8,348</p>
            <p>Stars today: 72 stars today</p>
            <h2>README</h2><pre># Ingress NGINX Controller

[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5691/badge)](https://bestpractices.coreinfrastructure.org/projects/5691)
[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/ingress-nginx)](https://goreportcard.com/report/github.com/kubernetes/ingress-nginx)
[![GitHub license](https://img.shields.io/github/license/kubernetes/ingress-nginx.svg)](https://github.com/kubernetes/ingress-nginx/blob/main/LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/kubernetes/ingress-nginx.svg)](https://github.com/kubernetes/ingress-nginx/stargazers)
[![GitHub stars](https://img.shields.io/badge/contributions-welcome-orange.svg)](https://github.com/kubernetes/ingress-nginx/blob/main/CONTRIBUTING.md)

## Overview

ingress-nginx is an Ingress controller for Kubernetes using [NGINX](https://www.nginx.org/) as a reverse proxy and load
balancer.

[Learn more about Ingress on the Kubernetes documentation site](https://kubernetes.io/docs/concepts/services-networking/ingress/).

## Get started

See the [Getting Started](https://kubernetes.github.io/ingress-nginx/deploy/) document.

Do not use in multi-tenant Kubernetes production installations. This project assumes that users that can create Ingress objects are administrators of the cluster. See the [FAQ](https://kubernetes.github.io/ingress-nginx/faq/#faq) for more.

## Troubleshooting

If you encounter issues, review the [troubleshooting docs](docs/troubleshooting.md),
[file an issue](https://github.com/kubernetes/ingress-nginx/issues), or talk to us on the
[#ingress-nginx channel](https://kubernetes.slack.com/messages/ingress-nginx) on the Kubernetes Slack server.

## Changelog

See [the list of releases](https://github.com/kubernetes/ingress-nginx/releases) for all changes.
For detailed changes for each release, please check the [changelog-$version.md](./changelog) file for the release version.
For detailed changes on the `ingress-nginx` helm chart, please check the changelog folder for a specific version.
[CHANGELOG-$current-version.md](./charts/ingress-nginx/changelog) file.

### Supported Versions table

Supported versions for the ingress-nginx project mean that we have completed E2E tests, and they are passing for
the versions listed. Ingress-Nginx versions **may** work on older versions, but the project does not make that guarantee.

| Supported | Ingress-NGINX version | k8s supported version         | Alpine Version | Nginx Version | Helm Chart Version |
| :-------: | --------------------- | ----------------------------- | -------------- | ------------- | ------------------ |
|    üîÑ     | **v1.12.1**           | 1.32, 1.31, 1.30,¬†1.29, 1.28  | 3.21.3         | 1.25.5        | 4.12.1             |
|    üîÑ     | **v1.12.0**           | 1.32, 1.31, 1.30,¬†1.29, 1.28  | 3.21.0         | 1.25.5        | 4.12.0             |
|    üîÑ     | **v1.12.0-beta.0**    | 1.32, 1.31, 1.30,¬†1.29, 1.28  | 3.20.3         | 1.25.5        | 4.12.0-beta.0      |
|    üîÑ     | **v1.11.5**           | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.3         | 1.25.5        | 4.11.5             |
|    üîÑ     | **v1.11.4**           | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.0         | 1.25.5        | 4.11.4             |
|    üîÑ     | **v1.11.3**           | 1.30,¬†1.29, 1.28, 1.27, 1.26  | 3.20.3         | 1.25.5        | 4.11.3             |
|    üîÑ     | **v1.11.2**           | 1.30,¬†1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.11.2             |
|    üîÑ     | **v1.11.1**           | 1.30,¬†1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.11.1             |
|    üîÑ     | **v1.11.0**           | 1.30,¬†1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.11.0             |
|           | **v1.10.6**           | 1.30, 1.29, 1.28, 1.27, 1.26  | 3.21.0         | 1.25.5        | 4.10.6             |
|           | **v1.10.5**           | 1.30,¬†1.29, 1.28, 1.27, 1.26  | 3.20.3         | 1.25.5        | 4.10.5             |
|           | **v1.10.4**           | 1.30,¬†1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.10.4             |
|           | **v1.10.3**           | 1.30,¬†1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.10.3             |
|           | **v1.10.2**           | 1.30,¬†1.29, 1.28, 1.27, 1.26  | 3.20.0         | 1.25.5        | 4.10.2             |
|           | **v1.10.1**           | 1.30,¬†1.29, 1.28, 1.27, 1.26  | 3.19.1         | 1.25.3        | 4.10.1             |
|           | **v1.10.0**           | 1.29, 1.28, 1.27, 1.26        | 3.19.1         | 1.25.3        | 4.10.0             |
|           | v1.9.6                | 1.29, 1.28, 1.27, 1.26, 1.25  | 3.19.0         | 1.21.6        | 4.9.1              |
|           | v1.9.5                | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.9.0              |
|           | v1.9.4                | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.8.3              |
|           | v1.9.3                | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.8.*              |
|           | v1.9.1                | 1.28, 1.27, 1.26, 1.25        | 3.18.4         | 1.21.6        | 4.8.*              |
|           | v1.9.0                | 1.28, 1.27, 1.26, 1.25        | 3.18.2         | 1.21.6        | 4.8.*              |
|           | v1.8.4                | 1.27, 1.26, 1.25, 1.24        | 3.18.2         | 1.21.6        | 4.7.*              |
|           | v1.7.1                | 1.27, 1.26, 1.25, 1.24        | 3.17.2         | 1.21.6        | 4.6.*              |
|           | v1.6.4                | 1.26, 1.25, 1.24, 1.23        | 3.17.0         | 1.21.6        | 4.5.*              |
|           | v1.5.1                | 1.25, 1.24, 1.23              | 3.16.2         | 1.21.6        | 4.4.*              |
|           | v1.4.0                | 1.25, 1.24, 1.23, 1.22        | 3.16.2         | 1.19.10‚Ä†      | 4.3.0              |
|           | v1.3.1                | 1.24, 1.23, 1.22, 1.21, 1.20  | 3.16.2         | 1.19.10‚Ä†      | 4.2.5              |

See [this article](https://kubernetes.io/blog/2021/07/26/update-with-ingress-nginx/) if you want upgrade to the stable
Ingress API.

## Get Involved

Thanks for taking the time to join our community and start contributing!

- This project adheres to the [Kubernetes Community Code of Conduct](https://git.k8s.io/community/code-of-conduct.md).
  By participating in this project, you agree to abide by its terms.
- **Contributing**: Contributions of all kinds are welcome!

  - Read [`CONTRIBUTING.md`](CONTRIBUTING.md) for information about setting up your environment, the workflow that we
    expect, and instructions on the developer certificate of origin that we require.
  - Join our Kubernetes Slack channel for developer discussion : [#ingress-nginx-dev](https://kubernetes.slack.com/archives/C021E147ZA4).
  - Submit GitHub issues for any feature enhancements, bugs, or documentation problems.
    - Please make sure to read the [Issue Reporting Checklist](https://github.com/kubernetes/ingress-nginx/blob/main/CONTRIBUTING.md#issue-reporting-guidelines) before opening an issue. Issues not conforming to the guidelines **may be closed immediately**.
  - Join our [ingress-nginx-dev mailing list](https://groups.google.com/a/kubernetes.io/g/ingress-nginx-dev/c/ebbBMo-zX-w)
- **Support**:

  - Join the [#ingress-nginx-users](https://kubernetes.slack.com/messages/CANQGM8BA/) channel inside the [Kubernetes Slack](http://slack.kubernetes.io/) to ask questions or get support from the maintainers and other users.
  - The [GitHub issues](https://github.com/kubernetes/ingress-nginx/issues) in the repository are **exclusively** for bug reports and feature requests.
  - **Discuss**: Tweet using the `#IngressNginx` hashtag or sharing with us [@IngressNginx](https://twitter.com/IngressNGINX).

## License

[Apache License 2.0](https://github.com/kubernetes/ingress-nginx/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mark3labs/mcp-go]]></title>
            <link>https://github.com/mark3labs/mcp-go</link>
            <guid>https://github.com/mark3labs/mcp-go</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[A Go implementation of the Model Context Protocol (MCP), enabling seamless integration between LLM applications and external data sources and tools.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mark3labs/mcp-go">mark3labs/mcp-go</a></h1>
            <p>A Go implementation of the Model Context Protocol (MCP), enabling seamless integration between LLM applications and external data sources and tools.</p>
            <p>Language: Go</p>
            <p>Stars: 1,491</p>
            <p>Forks: 137</p>
            <p>Stars today: 103 stars today</p>
            <h2>README</h2><pre>&lt;!-- omit in toc --&gt;
# MCP Go üöÄ
[![Build](https://github.com/mark3labs/mcp-go/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/mark3labs/mcp-go/actions/workflows/ci.yml)
[![Go Report Card](https://goreportcard.com/badge/github.com/mark3labs/mcp-go?cache)](https://goreportcard.com/report/github.com/mark3labs/mcp-go)
[![GoDoc](https://pkg.go.dev/badge/github.com/mark3labs/mcp-go.svg)](https://pkg.go.dev/github.com/mark3labs/mcp-go)

&lt;div align=&quot;center&quot;&gt;

&lt;strong&gt;A Go implementation of the Model Context Protocol (MCP), enabling seamless integration between LLM applications and external data sources and tools.&lt;/strong&gt;

&lt;br&gt;

[![Tutorial](http://img.youtube.com/vi/qoaeYMrXJH0/0.jpg)](http://www.youtube.com/watch?v=qoaeYMrXJH0 &quot;Tutorial&quot;)

&lt;/div&gt;

```go
package main

import (
    &quot;context&quot;
    &quot;errors&quot;
    &quot;fmt&quot;

    &quot;github.com/mark3labs/mcp-go/mcp&quot;
    &quot;github.com/mark3labs/mcp-go/server&quot;
)

func main() {
    // Create MCP server
    s := server.NewMCPServer(
        &quot;Demo üöÄ&quot;,
        &quot;1.0.0&quot;,
    )

    // Add tool
    tool := mcp.NewTool(&quot;hello_world&quot;,
        mcp.WithDescription(&quot;Say hello to someone&quot;),
        mcp.WithString(&quot;name&quot;,
            mcp.Required(),
            mcp.Description(&quot;Name of the person to greet&quot;),
        ),
    )

    // Add tool handler
    s.AddTool(tool, helloHandler)

    // Start the stdio server
    if err := server.ServeStdio(s); err != nil {
        fmt.Printf(&quot;Server error: %v\n&quot;, err)
    }
}

func helloHandler(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    name, ok := request.Params.Arguments[&quot;name&quot;].(string)
    if !ok {
        return nil, errors.New(&quot;name must be a string&quot;)
    }

    return mcp.NewToolResultText(fmt.Sprintf(&quot;Hello, %s!&quot;, name)), nil
}
```

That&#039;s it!

MCP Go handles all the complex protocol details and server management, so you can focus on building great tools. It aims to be high-level and easy to use.

### Key features:
* **Fast**: High-level interface means less code and faster development
* **Simple**: Build MCP servers with minimal boilerplate
* **Complete***: MCP Go aims to provide a full implementation of the core MCP specification

(\*emphasis on *aims*)

üö® üöß üèóÔ∏è *MCP Go is under active development, as is the MCP specification itself. Core features are working but some advanced capabilities are still in progress.* 


&lt;!-- omit in toc --&gt;
## Table of Contents

- [Installation](#installation)
- [Quickstart](#quickstart)
- [What is MCP?](#what-is-mcp)
- [Core Concepts](#core-concepts)
  - [Server](#server)
  - [Resources](#resources)
  - [Tools](#tools)
  - [Prompts](#prompts)
- [Examples](#examples)
- [Contributing](#contributing)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation-1)
  - [Testing](#testing)
  - [Opening a Pull Request](#opening-a-pull-request)

## Installation

```bash
go get github.com/mark3labs/mcp-go
```

## Quickstart

Let&#039;s create a simple MCP server that exposes a calculator tool and some data:

```go
package main

import (
    &quot;context&quot;
    &quot;errors&quot;
    &quot;fmt&quot;

    &quot;github.com/mark3labs/mcp-go/mcp&quot;
    &quot;github.com/mark3labs/mcp-go/server&quot;
)

func main() {
    // Create a new MCP server
    s := server.NewMCPServer(
        &quot;Calculator Demo&quot;,
        &quot;1.0.0&quot;,
        server.WithResourceCapabilities(true, true),
        server.WithLogging(),
    )

    // Add a calculator tool
    calculatorTool := mcp.NewTool(&quot;calculate&quot;,
        mcp.WithDescription(&quot;Perform basic arithmetic operations&quot;),
        mcp.WithString(&quot;operation&quot;,
            mcp.Required(),
            mcp.Description(&quot;The operation to perform (add, subtract, multiply, divide)&quot;),
            mcp.Enum(&quot;add&quot;, &quot;subtract&quot;, &quot;multiply&quot;, &quot;divide&quot;),
        ),
        mcp.WithNumber(&quot;x&quot;,
            mcp.Required(),
            mcp.Description(&quot;First number&quot;),
        ),
        mcp.WithNumber(&quot;y&quot;,
            mcp.Required(),
            mcp.Description(&quot;Second number&quot;),
        ),
    )

    // Add the calculator handler
    s.AddTool(calculatorTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
        op := request.Params.Arguments[&quot;operation&quot;].(string)
        x := request.Params.Arguments[&quot;x&quot;].(float64)
        y := request.Params.Arguments[&quot;y&quot;].(float64)

        var result float64
        switch op {
        case &quot;add&quot;:
            result = x + y
        case &quot;subtract&quot;:
            result = x - y
        case &quot;multiply&quot;:
            result = x * y
        case &quot;divide&quot;:
            if y == 0 {
                return nil, errors.New(&quot;Cannot divide by zero&quot;)
            }
            result = x / y
        }

        return mcp.NewToolResultText(fmt.Sprintf(&quot;%.2f&quot;, result)), nil
    })

    // Start the server
    if err := server.ServeStdio(s); err != nil {
        fmt.Printf(&quot;Server error: %v\n&quot;, err)
    }
}
```
## What is MCP?

The [Model Context Protocol (MCP)](https://modelcontextprotocol.io) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way. Think of it like a web API, but specifically designed for LLM interactions. MCP servers can:

- Expose data through **Resources** (think of these sort of like GET endpoints; they are used to load information into the LLM&#039;s context)
- Provide functionality through **Tools** (sort of like POST endpoints; they are used to execute code or otherwise produce a side effect)
- Define interaction patterns through **Prompts** (reusable templates for LLM interactions)
- And more!


## Core Concepts


### Server

&lt;details&gt;
&lt;summary&gt;Show Server Examples&lt;/summary&gt;

The server is your core interface to the MCP protocol. It handles connection management, protocol compliance, and message routing:

```go
// Create a basic server
s := server.NewMCPServer(
    &quot;My Server&quot;,  // Server name
    &quot;1.0.0&quot;,     // Version
)

// Start the server using stdio
if err := server.ServeStdio(s); err != nil {
    log.Fatalf(&quot;Server error: %v&quot;, err)
}
```

&lt;/details&gt;

### Resources

&lt;details&gt;
&lt;summary&gt;Show Resource Examples&lt;/summary&gt;
Resources are how you expose data to LLMs. They can be anything - files, API responses, database queries, system information, etc. Resources can be:

- Static (fixed URI)
- Dynamic (using URI templates)

Here&#039;s a simple example of a static resource:

```go
// Static resource example - exposing a README file
resource := mcp.NewResource(
    &quot;docs://readme&quot;,
    &quot;Project README&quot;,
    mcp.WithResourceDescription(&quot;The project&#039;s README file&quot;), 
    mcp.WithMIMEType(&quot;text/markdown&quot;),
)

// Add resource with its handler
s.AddResource(resource, func(ctx context.Context, request mcp.ReadResourceRequest) ([]mcp.ResourceContents, error) {
    content, err := os.ReadFile(&quot;README.md&quot;)
    if err != nil {
        return nil, err
    }
    
    return []mcp.ResourceContents{
        mcp.TextResourceContents{
            URI:      &quot;docs://readme&quot;,
            MIMEType: &quot;text/markdown&quot;,
            Text:     string(content),
        },
    }, nil
})
```

And here&#039;s an example of a dynamic resource using a template:

```go
// Dynamic resource example - user profiles by ID
template := mcp.NewResourceTemplate(
    &quot;users://{id}/profile&quot;,
    &quot;User Profile&quot;,
    mcp.WithTemplateDescription(&quot;Returns user profile information&quot;),
    mcp.WithTemplateMIMEType(&quot;application/json&quot;),
)

// Add template with its handler
s.AddResourceTemplate(template, func(ctx context.Context, request mcp.ReadResourceRequest) ([]mcp.ResourceContents, error) {
    // Extract ID from the URI using regex matching
    // The server automatically matches URIs to templates
    userID := extractIDFromURI(request.Params.URI)
    
    profile, err := getUserProfile(userID)  // Your DB/API call here
    if err != nil {
        return nil, err
    }
    
    return []mcp.ResourceContents{
        mcp.TextResourceContents{
            URI:      request.Params.URI,
            MIMEType: &quot;application/json&quot;,
            Text:     profile,
        },
    }, nil
})
```

The examples are simple but demonstrate the core concepts. Resources can be much more sophisticated - serving multiple contents, integrating with databases or external APIs, etc.
&lt;/details&gt;

### Tools

&lt;details&gt;
&lt;summary&gt;Show Tool Examples&lt;/summary&gt;

Tools let LLMs take actions through your server. Unlike resources, tools are expected to perform computation and have side effects. They&#039;re similar to POST endpoints in a REST API.

Simple calculation example:
```go
calculatorTool := mcp.NewTool(&quot;calculate&quot;,
    mcp.WithDescription(&quot;Perform basic arithmetic calculations&quot;),
    mcp.WithString(&quot;operation&quot;,
        mcp.Required(),
        mcp.Description(&quot;The arithmetic operation to perform&quot;),
        mcp.Enum(&quot;add&quot;, &quot;subtract&quot;, &quot;multiply&quot;, &quot;divide&quot;),
    ),
    mcp.WithNumber(&quot;x&quot;,
        mcp.Required(),
        mcp.Description(&quot;First number&quot;),
    ),
    mcp.WithNumber(&quot;y&quot;,
        mcp.Required(),
        mcp.Description(&quot;Second number&quot;),
    ),
)

s.AddTool(calculatorTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    op := request.Params.Arguments[&quot;operation&quot;].(string)
    x := request.Params.Arguments[&quot;x&quot;].(float64)
    y := request.Params.Arguments[&quot;y&quot;].(float64)

    var result float64
    switch op {
    case &quot;add&quot;:
        result = x + y
    case &quot;subtract&quot;:
        result = x - y
    case &quot;multiply&quot;:
        result = x * y
    case &quot;divide&quot;:
        if y == 0 {
            return nil, errors.New(&quot;Division by zero is not allowed&quot;)
        }
        result = x / y
    }
    
    return mcp.FormatNumberResult(result), nil
})
```

HTTP request example:
```go
httpTool := mcp.NewTool(&quot;http_request&quot;,
    mcp.WithDescription(&quot;Make HTTP requests to external APIs&quot;),
    mcp.WithString(&quot;method&quot;,
        mcp.Required(),
        mcp.Description(&quot;HTTP method to use&quot;),
        mcp.Enum(&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;),
    ),
    mcp.WithString(&quot;url&quot;,
        mcp.Required(),
        mcp.Description(&quot;URL to send the request to&quot;),
        mcp.Pattern(&quot;^https?://.*&quot;),
    ),
    mcp.WithString(&quot;body&quot;,
        mcp.Description(&quot;Request body (for POST/PUT)&quot;),
    ),
)

s.AddTool(httpTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    method := request.Params.Arguments[&quot;method&quot;].(string)
    url := request.Params.Arguments[&quot;url&quot;].(string)
    body := &quot;&quot;
    if b, ok := request.Params.Arguments[&quot;body&quot;].(string); ok {
        body = b
    }

    // Create and send request
    var req *http.Request
    var err error
    if body != &quot;&quot; {
        req, err = http.NewRequest(method, url, strings.NewReader(body))
    } else {
        req, err = http.NewRequest(method, url, nil)
    }
    if err != nil {
        return nil, fmt.Errorf(&quot;Failed to create request: %v&quot;, err)
    }

    client := &amp;http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        return nil, fmt.Errorf(&quot;Request failed: %v&quot;, err)
    }
    defer resp.Body.Close()

    // Return response
    respBody, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, fmt.Errorf(&quot;Failed to read response: %v&quot;, err)
    }

    return mcp.NewToolResultText(fmt.Sprintf(&quot;Status: %d\nBody: %s&quot;, resp.StatusCode, string(respBody))), nil
})
```

Tools can be used for any kind of computation or side effect:
- Database queries
- File operations  
- External API calls
- Calculations
- System operations

Each tool should:
- Have a clear description
- Validate inputs
- Handle errors gracefully 
- Return structured responses
- Use appropriate result types

&lt;/details&gt;

### Prompts

&lt;details&gt;
&lt;summary&gt;Show Prompt Examples&lt;/summary&gt;

Prompts are reusable templates that help LLMs interact with your server effectively. They&#039;re like &quot;best practices&quot; encoded into your server. Here are some examples:

```go
// Simple greeting prompt
s.AddPrompt(mcp.NewPrompt(&quot;greeting&quot;,
    mcp.WithPromptDescription(&quot;A friendly greeting prompt&quot;),
    mcp.WithArgument(&quot;name&quot;,
        mcp.ArgumentDescription(&quot;Name of the person to greet&quot;),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    name := request.Params.Arguments[&quot;name&quot;]
    if name == &quot;&quot; {
        name = &quot;friend&quot;
    }
    
    return mcp.NewGetPromptResult(
        &quot;A friendly greeting&quot;,
        []mcp.PromptMessage{
            mcp.NewPromptMessage(
                mcp.RoleAssistant,
                mcp.NewTextContent(fmt.Sprintf(&quot;Hello, %s! How can I help you today?&quot;, name)),
            ),
        },
    ), nil
})

// Code review prompt with embedded resource
s.AddPrompt(mcp.NewPrompt(&quot;code_review&quot;,
    mcp.WithPromptDescription(&quot;Code review assistance&quot;),
    mcp.WithArgument(&quot;pr_number&quot;,
        mcp.ArgumentDescription(&quot;Pull request number to review&quot;),
        mcp.RequiredArgument(),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    prNumber := request.Params.Arguments[&quot;pr_number&quot;]
    if prNumber == &quot;&quot; {
        return nil, fmt.Errorf(&quot;pr_number is required&quot;)
    }
    
    return mcp.NewGetPromptResult(
        &quot;Code review assistance&quot;,
        []mcp.PromptMessage{
            mcp.NewPromptMessage(
                mcp.RoleSystem,
                mcp.NewTextContent(&quot;You are a helpful code reviewer. Review the changes and provide constructive feedback.&quot;),
            ),
            mcp.NewPromptMessage(
                mcp.RoleAssistant,
                mcp.NewEmbeddedResource(mcp.ResourceContents{
                    URI: fmt.Sprintf(&quot;git://pulls/%s/diff&quot;, prNumber),
                    MIMEType: &quot;text/x-diff&quot;,
                }),
            ),
        },
    ), nil
})

// Database query builder prompt
s.AddPrompt(mcp.NewPrompt(&quot;query_builder&quot;,
    mcp.WithPromptDescription(&quot;SQL query builder assistance&quot;),
    mcp.WithArgument(&quot;table&quot;,
        mcp.ArgumentDescription(&quot;Name of the table to query&quot;),
        mcp.RequiredArgument(),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    tableName := request.Params.Arguments[&quot;table&quot;]
    if tableName == &quot;&quot; {
        return nil, fmt.Errorf(&quot;table name is required&quot;)
    }
    
    return mcp.NewGetPromptResult(
        &quot;SQL query builder assistance&quot;,
        []mcp.PromptMessage{
            mcp.NewPromptMessage(
                mcp.RoleSystem,
                mcp.NewTextContent(&quot;You are a SQL expert. Help construct efficient and safe queries.&quot;),
            ),
            mcp.NewPromptMessage(
                mcp.RoleAssistant,
                mcp.NewEmbeddedResource(mcp.ResourceContents{
                    URI: fmt.Sprintf(&quot;db://schema/%s&quot;, tableName),
                    MIMEType: &quot;application/json&quot;,
                }),
            ),
        },
    ), nil
})
```

Prompts can include:
- System instructions
- Required arguments
- Embedded resources
- Multiple messages
- Different content types (text, images, etc.)
- Custom URI schemes

&lt;/details&gt;

## Examples

For examples, see the `examples/` directory.

## Extras

### Request Hooks

Hook into the request lifecycle by creating a `Hooks` object with your
selection among the possible callbacks.  This enables telemetry across all
functionality, and observability of various facts, for example the ability
to count improperly-formatted requests, or to log the agent identity during
initialization.

Add the `Hooks` to the server at the time of creation using the
`server.WithHooks` option.

## Contributing

&lt;details&gt;

&lt;summary&gt;&lt;h3&gt;Open Developer Guide&lt;/h3&gt;&lt;/summary&gt;

### Prerequisites

Go version &gt;= 1.23

### Installation

Create a fork of this repository, then clone it:

```bash
git clone https://github.com/mark3labs/mcp-go.git
cd mcp-go
```

### Testing

Please make sure to test any new functionality. Your tests should be simple and atomic and anticipate change rather than cement complex patterns.

Run tests from the root directory:

```bash
go test -v &#039;./...&#039;
```

### Opening a Pull Request

Fork the repository and create a new branch:

```bash
git checkout -b my-branch
```

Make your changes and commit them:


```bash
git add . &amp;&amp; git commit -m &quot;My changes&quot;
```

Push your changes to your fork:


```bash
git push origin my-branch
```

Feel free to reach out in a GitHub issue or discussion if you have any questions!

&lt;/details&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mailhog/MailHog]]></title>
            <link>https://github.com/mailhog/MailHog</link>
            <guid>https://github.com/mailhog/MailHog</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[Web and API based SMTP testing]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mailhog/MailHog">mailhog/MailHog</a></h1>
            <p>Web and API based SMTP testing</p>
            <p>Language: Go</p>
            <p>Stars: 14,662</p>
            <p>Forks: 1,091</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>MailHog [ ![Download](https://img.shields.io/github/release/mailhog/MailHog.svg) ](https://github.com/mailhog/MailHog/releases/tag/v1.0.0) [![GoDoc](https://godoc.org/github.com/mailhog/MailHog?status.svg)](https://godoc.org/github.com/mailhog/MailHog) [![Build Status](https://travis-ci.org/mailhog/MailHog.svg?branch=master)](https://travis-ci.org/mailhog/MailHog)
=========

Inspired by [MailCatcher](https://mailcatcher.me/), easier to install.

* Download and run MailHog
* Configure your outgoing SMTP server
* View your outgoing email in a web UI
* Release it to a real mail server

Built with Go - MailHog runs without installation on multiple platforms.

### Overview

MailHog is an email testing tool for developers:

* Configure your application to use MailHog for SMTP delivery
* View messages in the web UI, or retrieve them with the JSON API
* Optionally release messages to real SMTP servers for delivery

### Installation

#### Manual installation
[Download the latest release for your platform](/docs/RELEASES.md). Then
[read the deployment guide](/docs/DEPLOY.md) for deployment options.

#### MacOS
```bash
brew update &amp;&amp; brew install mailhog
```

Then, start MailHog by running `mailhog` in the command line.

#### Debian / Ubuntu Go &lt; v1.18
```bash
sudo apt-get -y install golang-go
go get github.com/mailhog/MailHog
```

#### Go &gt;= v1.17 (Debian Bookworm) 
```bash
sudo apt-get -y install golang-go
go install github.com/mailhog/MailHog@latest
```

Then, start MailHog by running `/path/to/MailHog` in the command line.

E.g. the path to Go&#039;s bin files on Ubuntu is `~/go/bin/`, so to start the MailHog run:

```bash
~/go/bin/MailHog
```

#### FreeBSD
```bash
pkg install mailhog
sysrc mailhog_enable=&quot;YES&quot;
service mailhog start
```

#### Docker
[Run it from Docker Hub](https://registry.hub.docker.com/r/mailhog/mailhog/) or using the provided [Dockerfile](Dockerfile)

### Configuration

Check out how to [configure MailHog](/docs/CONFIG.md), or use the default settings:
  * the SMTP server starts on port 1025
  * the HTTP server starts on port 8025
  * in-memory message storage

### Features

See [MailHog libraries](docs/LIBRARIES.md) for a list of MailHog client libraries.

* ESMTP server implementing RFC5321
* Support for SMTP AUTH (RFC4954) and PIPELINING (RFC2920)
* Web interface to view messages (plain text, HTML or source)
  * Supports RFC2047 encoded headers
* Real-time updates using EventSource
* Release messages to real SMTP servers
* Chaos Monkey for failure testing
  * See [Introduction to Jim](/docs/JIM.md) for more information
* HTTP API to list, retrieve and delete messages
  * See [APIv1](/docs/APIv1.md) and [APIv2](/docs/APIv2.md) documentation for more information
* [HTTP basic authentication](docs/Auth.md) for MailHog UI and API
* Multipart MIME support
* Download individual MIME parts
* In-memory message storage
* MongoDB and file based storage for message persistence
* Lightweight and portable
* No installation required

#### sendmail

[mhsendmail](https://github.com/mailhog/mhsendmail) is a sendmail replacement for MailHog.

It redirects mail to MailHog using SMTP.

You can also use `MailHog sendmail ...` instead of the separate mhsendmail binary.

Alternatively, you can use your native `sendmail` command by providing `-S`, for example:

```bash
/usr/sbin/sendmail -S mail:1025
```

For example, in PHP you could add either of these lines to `php.ini`:

```
sendmail_path = /usr/local/bin/mhsendmail
sendmail_path = /usr/sbin/sendmail -S mail:1025
```

#### Web UI

![Screenshot of MailHog web interface](/docs/MailHog.png &quot;MailHog web interface&quot;)

### Contributing

MailHog is a rewritten version of [MailHog](https://github.com/ian-kent/MailHog), which was born out of [M3MTA](https://github.com/ian-kent/M3MTA).

Clone this repository to ```$GOPATH/src/github.com/mailhog/MailHog``` and type ```make deps```.

See the [Building MailHog](/docs/BUILD.md) guide.

Requires Go 1.4+ to build.

Run tests using ```make test``` or ```goconvey```.

If you make any changes, run ```go fmt ./...``` before submitting a pull request.

### Licence

Copyright ¬©‚Äé 2014 - 2017, Ian Kent (http://iankent.uk)

Released under MIT license, see [LICENSE](LICENSE.md) for details.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[zitadel/zitadel]]></title>
            <link>https://github.com/zitadel/zitadel</link>
            <guid>https://github.com/zitadel/zitadel</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[ZITADEL - Identity infrastructure, simplified for¬†you.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zitadel/zitadel">zitadel/zitadel</a></h1>
            <p>ZITADEL - Identity infrastructure, simplified for¬†you.</p>
            <p>Language: Go</p>
            <p>Stars: 10,132</p>
            <p>Forks: 674</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;./docs/static/logos/zitadel-logo-dark@2x.png#gh-light-mode-only&quot; alt=&quot;Zitadel Logo&quot; max-height=&quot;200px&quot; width=&quot;auto&quot; /&gt;
    &lt;img src=&quot;./docs/static/logos/zitadel-logo-light@2x.png#gh-dark-mode-only&quot; alt=&quot;Zitadel Logo&quot; max-height=&quot;200px&quot; width=&quot;auto&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/zitadel/zitadel/blob/main/LICENSE&quot; alt=&quot;License&quot;&gt;
        &lt;img src=&quot;https://badgen.net/github/license/zitadel/zitadel/&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://bestpractices.coreinfrastructure.org/projects/6662&quot;&gt;&lt;img src=&quot;https://bestpractices.coreinfrastructure.org/projects/6662/badge&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/semantic-release/semantic-release&quot; alt=&quot;semantic-release&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/zitadel/zitadel/actions&quot; alt=&quot;ZITADEL Release&quot;&gt;
        &lt;img alt=&quot;GitHub Workflow Status (with event)&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/zitadel/zitadel/build.yml?event=pull_request&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://zitadel.com/docs/support/software-release-cycles-support&quot; alt=&quot;Release&quot;&gt;
        &lt;img src=&quot;https://badgen.net/github/release/zitadel/zitadel/stable&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://goreportcard.com/report/github.com/zitadel/zitadel&quot; alt=&quot;Go Report Card&quot;&gt;
        &lt;img src=&quot;https://goreportcard.com/badge/github.com/zitadel/zitadel&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://codecov.io/gh/zitadel/zitadel&quot; alt=&quot;Code Coverage&quot;&gt;
        &lt;img src=&quot;https://codecov.io/gh/zitadel/zitadel/branch/main/graph/badge.svg&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/zitadel/zitadel/graphs/contributors&quot; alt=&quot;Release&quot;&gt;
        &lt;img alt=&quot;GitHub contributors&quot; src=&quot;https://img.shields.io/github/contributors/zitadel/zitadel&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/YgjEuJzZ3x&quot; alt=&quot;Discord Chat&quot;&gt;
        &lt;img src=&quot;https://badgen.net/discord/online-members/YgjEuJzZ3x&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://openid.net/certification/#OPs&quot; alt=&quot;OpenID Connect Certified&quot;&gt;
        &lt;img src=&quot;./docs/static/logos/oidc-cert.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

Are you searching for a user management tool that is quickly set up like Auth0 and open source like Keycloak?

Do you have a project that requires multi-tenant user management with self-service for your customers?

Look no further ‚Äî ZITADEL is the identity infrastructure, simplified for you.

We provide you with a wide range of out-of-the-box features to accelerate your project, including:

:white_check_mark: Multi-tenancy with team management  
:white_check_mark: Secure login  
:white_check_mark: Self-service  
:white_check_mark: OpenID Connect  
:white_check_mark: OAuth2.x  
:white_check_mark: SAML2  
:white_check_mark: LDAP  
:white_check_mark: Passkeys / FIDO2  
:white_check_mark: OTP  
:white_check_mark: SCIM 2.0 Server
and an unlimited audit trail is there for you, ready to use.

With ZITADEL, you are assured of a robust and customizable turnkey solution for all your authentication and authorization needs.

---

**[üè° Website](https://zitadel.com) [üí¨ Chat](https://zitadel.com/chat) [üìã Docs](https://zitadel.com/docs/) [üßë‚Äçüíª Blog](https://zitadel.com/blog) [üìû Contact](https://zitadel.com/contact/)**

## Get started

üëâ [Quick Start Guide](https://zitadel.com/docs/guides/start/quickstart)

### Deploy ZITADEL (Self-Hosted)

Deploying ZITADEL locally takes less than 3 minutes. Go ahead and give it a try!

* [Linux](https://zitadel.com/docs/self-hosting/deploy/linux)
* [MacOS](https://zitadel.com/docs/self-hosting/deploy/macos)
* [Docker compose](https://zitadel.com/docs/self-hosting/deploy/compose)
* [Knative](https://zitadel.com/docs/self-hosting/deploy/knative)
* [Kubernetes](https://zitadel.com/docs/self-hosting/deploy/kubernetes)

See all guides [here](https://zitadel.com/docs/self-hosting/deploy/overview)

&gt; If you are interested to get professional support for your self-hosted ZITADEL [please reach out to us](https://zitadel.com/contact)!

### Setup ZITADEL Cloud (SaaS)

If you want to experience a hands-free ZITADEL, you should use [ZITADEL Cloud](https://zitadel.com).
Available data regions are: 
* üá∫üá∏ United States
* üá™üá∫ European Union
* üá¶üá∫ Australia
* üá®üá≠ Switzerland

ZITADEL Cloud comes with a free tier, providing you with all the same features as the open-source version.
Learn more about the [pay-as-you-go pricing](https://zitadel.com/pricing).

## Adopters

We are grateful to the organizations and individuals who are using ZITADEL. If you are using ZITADEL, please consider adding your name to our [Adopters list](./ADOPTERS.md) by submitting a pull request.

### Example applications

Clone one of our [example applications](https://zitadel.com/docs/sdk-examples/introduction) or deploy them directly to Vercel.

### SDKs

Use our [SDKs](https://zitadel.com/docs/sdk-examples/introduction) for your favorite language and framework.

## Why choose ZITADEL

We built ZITADEL with a complex multi-tenancy architecture in mind and provide the best solution to handle [B2B customers and partners](https://zitadel.com/docs/guides/solution-scenarios/b2b).
Yet it offers everything you need for a customer identity ([CIAM](https://zitadel.com/docs/guides/solution-scenarios/b2c)) use case.

- [API-first approach](https://zitadel.com/docs/apis/introduction)
- [Multi-tenancy](https://zitadel.com/docs/guides/solution-scenarios/b2b) authentication and access management
- [Strong audit trail](https://zitadel.com/docs/concepts/features/audit-trail) thanks to [event sourcing](https://zitadel.com/docs/concepts/eventstore/overview) as storage pattern
- [Actions](https://zitadel.com/docs/apis/actions/introduction) to react on events with custom code and extended ZITADEL for you needs
- [Branding](https://zitadel.com/docs/guides/manage/customize/branding) for a uniform user experience across multiple organizations
- [Self-service](https://zitadel.com/docs/concepts/features/selfservice) for end-users, business customers, and administrators
- [CockroachDB](https://www.cockroachlabs.com/) or a [Postgres](https://www.postgresql.org/) database as reliable and widespread storage option

## Features

Authentication

- Single Sign On (SSO)
- [Passkeys support (FIDO2 / WebAuthN)](https://zitadel.com/docs/concepts/features/passkeys)
- Username / Password
- Multifactor authentication with OTP, U2F, Email OTP, SMS OTP
- [LDAP](https://zitadel.com/docs/guides/integrate/identity-providers/ldap)
- [External enterprise identity providers  and social logins](https://zitadel.com/docs/guides/integrate/identity-providers/introduction)
- [Device authorization](https://zitadel.com/docs/guides/solution-scenarios/device-authorization)
- [OpenID Connect certified](https://openid.net/certification/#OPs) =&gt; [OIDC Endpoints](https://zitadel.com/docs/apis/openidoauth/endpoints)
- [SAML 2.0](http://docs.oasis-open.org/security/saml/Post2.0/sstc-saml-tech-overview-2.0.html) =&gt; [SAML Endpoints](https://zitadel.com/docs/apis/saml/endpoints)
- [Custom sessions](https://zitadel.com/docs/guides/integrate/login-ui/username-password) if you need to go beyond OIDC or SAML 
- [Machine-to-machine](https://zitadel.com/docs/guides/integrate/service-users/authenticate-service-users) with JWT profile, Personal Access Tokens (PAT), and Client Credentials
- [Token exchange and impersonation](https://zitadel.com/docs/guides/integrate/token-exchange)
- [Beta: Hosted Login V2](https://zitadel.com/docs/guides/integrate/login/hosted-login#hosted-login-version-2-beta) our new login version 2.0

Multi-Tenancy

- [Identity Brokering](https://zitadel.com/docs/guides/integrate/identity-brokering) with templates for popular identity providers
- [Customizable onboaring](https://zitadel.com/docs/guides/solution-scenarios/onboarding) for B2B and their users
- [Delegate role management to third-parties](https://zitadel.com/docs/guides/manage/console/projects)
- [Domain discovery](https://zitadel.com/docs/guides/solution-scenarios/domain-discovery)

Integration

- [GRPC and REST APIs](https://zitadel.com/docs/apis/introduction) for every functionality and resource
- [Actions](https://zitadel.com/docs/apis/actions/introduction) to call any API, send webhooks, adjust workflows, or customize tokens
- [Role Based Access Control (RBAC)](https://zitadel.com/docs/guides/integrate/retrieve-user-roles)
- [SCIM 2.0 Server](https://zitadel.com/docs/apis/scim2)
- [Examples and SDKs](https://zitadel.com/docs/sdk-examples/introduction)
- [Audit Log and SOC/SIEM](https://zitadel.com/docs/guides/integrate/external-audit-log)
- [User registration and onboarding](https://zitadel.com/docs/guides/integrate/onboarding)
- [Hosted and custom login user interface](https://zitadel.com/docs/guides/integrate/login/login-users)

Self-Service
- [Self-registration](https://zitadel.com/docs/concepts/features/selfservice#registration) including verification
- [Self-service](https://zitadel.com/docs/concepts/features/selfservice) for end-users, business customers, and administrators
- [Administration UI (Console)](https://zitadel.com/docs/guides/manage/console/overview)

Deployment
- [Postgres](https://zitadel.com/docs/self-hosting/manage/database#postgres) (version &gt;= 14) or [CockroachDB](https://zitadel.com/docs/self-hosting/manage/database#cockroach) (version latest stable)
- [Zero Downtime Updates](https://zitadel.com/docs/concepts/architecture/solution#zero-downtime-updates)
- [High scalability](https://zitadel.com/docs/self-hosting/manage/production)

Track upcoming features on our [roadmap](https://zitadel.com/roadmap) and follow our [changelog](https://zitadel.com/changelog) for recent updates.

## How To Contribute

Find details about how you can contribute in our [Contribution Guide](./CONTRIBUTING.md).
Join our [Discord Chat](https://zitadel.com/chat) to get help.

## Contributors

&lt;a href=&quot;https://github.com/zitadel/zitadel/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=zitadel/zitadel&quot; /&gt;
&lt;/a&gt;

Made with [contrib.rocks](https://contrib.rocks/preview?repo=zitadel/zitadel).

## Showcase

### Quick Start Guide

Secure a React Application using OpenID Connect Authorization Code with PKCE

[![Quick Start Guide](https://user-images.githubusercontent.com/1366906/223662449-f17b734d-405c-4945-a8a1-200440c459e5.gif)](http://www.youtube.com/watch?v=5THbQljoPKg &quot;Quick Start Guide&quot;)

### Login with Passkeys

Use our login widget to allow easy and secure access to your applications and enjoy all the benefits of Passkeys (FIDO 2 / WebAuthN):

[![Passkeys](https://user-images.githubusercontent.com/1366906/223664178-4132faef-4832-4014-b9ab-90c2a8d15436.gif)](https://www.youtube.com/watch?v=cZjHQYurSjw&amp;list=PLTDa7jTlOyRLdABgD2zL0LGM7rx5GZ1IR&amp;index=2 &quot;Passkeys&quot;)

### Admin Console

Use [Console](https://zitadel.com/docs/guides/manage/console/overview) or our [APIs](https://zitadel.com/docs/apis/introduction) to setup organizations, projects and applications.

[![Console Showcase](https://user-images.githubusercontent.com/1366906/223663344-67038d5f-4415-4285-ab20-9a4d397e2138.gif)](http://www.youtube.com/watch?v=RPpHktAcCtk &quot;Console Showcase&quot;)

### Login V2

Check out our new Login V2 version in our [typescript repository](https://github.com/zitadel/typescript) or in our [documentation](https://zitadel.com/docs/guides/integrate/login/hosted-login#hosted-login-version-2-beta)
[![New Login Showcase](https://github.com/user-attachments/assets/cb5c5212-128b-4dc9-b11d-cabfd3f73e26)]

## Security

You can find our security policy [here](./SECURITY.md).

[Technical Advisories](https://zitadel.com/docs/support/technical_advisory) are published regarding major issues with the ZITADEL platform that could potentially impact security or stability in production environments.

## License

[here](./LICENSE) are our exact licensing terms.

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See our [license](./LICENSE) for detailed information governing permissions and limitations on use.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gonum/gonum]]></title>
            <link>https://github.com/gonum/gonum</link>
            <guid>https://github.com/gonum/gonum</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[Gonum is a set of numeric libraries for the Go programming language. It contains libraries for matrices, statistics, optimization, and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gonum/gonum">gonum/gonum</a></h1>
            <p>Gonum is a set of numeric libraries for the Go programming language. It contains libraries for matrices, statistics, optimization, and more</p>
            <p>Language: Go</p>
            <p>Stars: 7,900</p>
            <p>Forks: 563</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># Gonum

[![Build status](https://github.com/gonum/gonum/workflows/CI/badge.svg)](https://github.com/gonum/gonum/actions)
[![Build status](https://ci.appveyor.com/api/projects/status/valslkp8sr50eepn/branch/master?svg=true)](https://ci.appveyor.com/project/Gonum/gonum/branch/master)
[![codecov.io](https://codecov.io/gh/gonum/gonum/branch/master/graph/badge.svg)](https://codecov.io/gh/gonum/gonum)
[![go.dev reference](https://pkg.go.dev/badge/gonum.org/v1/gonum)](https://pkg.go.dev/gonum.org/v1/gonum)
[![GoDoc](https://godocs.io/gonum.org/v1/gonum?status.svg)](https://godocs.io/gonum.org/v1/gonum)
[![Go Report Card](https://goreportcard.com/badge/github.com/gonum/gonum)](https://goreportcard.com/report/github.com/gonum/gonum)
[![stability-unstable](https://img.shields.io/badge/stability-unstable-yellow.svg)](https://github.com/emersion/stability-badges#unstable)

## Installation

The core packages of the Gonum suite are written in pure Go with some assembly.
Installation is done using `go get`.
```
go get -u gonum.org/v1/gonum/...
```

## Supported Go versions

Gonum supports and tests using the gc compiler on the [two most recent Go releases](https://github.com/gonum/gonum/blob/master/.github/workflows/ci.yml#L14-L15) on Linux (386, amd64 and arm64), macOS and Windows (both on amd64).

Note that floating point behavior may differ between compiler versions and between architectures due to differences in floating point operation implementations.

## Release schedule

The Gonum modules are released on a six-month release schedule, aligned with the Go releases.
_i.e.:_ when `Go-1.x` is released, `Gonum-v0.n.0` is released around the same time.
Six months after, `Go-1.x+1` is released, and `Gonum-v0.n+1.0` as well.

The release schedule, based on the current Go release schedule is thus:

- `Gonum-v0.n.0`: February
- `Gonum-v0.n+1.0`: August

## Build tags

The Gonum packages use a variety of build tags to set non-standard build conditions.
Building Gonum applications will work without knowing how to use these tags, but they can be used during testing and to control the use of assembly and CGO code.

The current list of non-internal tags is as follows:

- safe ‚Äî do not use assembly or unsafe
- bounds ‚Äî use bounds checks even in internal calls
- noasm ‚Äî do not use assembly implementations
- tomita ‚Äî use [Tomita, Tanaka, Takahashi pivot choice](https://doi.org/10.1016%2Fj.tcs.2006.06.015) for maximal clique calculation, otherwise use random pivot (only in [topo package](https://pkg.go.dev/gonum.org/v1/gonum/graph/topo))


## Issues [![TODOs](https://badgen.net/https/api.tickgit.com/badgen/github.com/gonum/gonum)](https://www.tickgit.com/browse?repo=github.com/gonum/gonum)

If you find any bugs, feel free to file an issue on the github issue tracker. Discussions on API changes, added features, code review, or similar requests are preferred on the gonum-dev Google Group.

https://groups.google.com/forum/#!forum/gonum-dev

## License

Original code is licensed under the Gonum License found in the LICENSE file. Portions of the code are subject to the additional licenses found in THIRD_PARTY_LICENSES. All third party code is licensed either under a BSD or MIT license.

Code in graph/formats/dot is dual licensed [Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/) and Gonum License, and users are free to choose the license which suits their needs for this code.

The W3C test suites in graph/formats/rdf are distributed under both the [W3C Test Suite License](http://www.w3.org/Consortium/Legal/2008/04-testsuite-license) and the [W3C 3-clause BSD License](http://www.w3.org/Consortium/Legal/2008/03-bsd-license).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cadence-workflow/cadence]]></title>
            <link>https://github.com/cadence-workflow/cadence</link>
            <guid>https://github.com/cadence-workflow/cadence</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:46 GMT</pubDate>
            <description><![CDATA[Cadence is a distributed, scalable, durable, and highly available orchestration engine to execute asynchronous long-running business logic in a scalable and resilient way.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cadence-workflow/cadence">cadence-workflow/cadence</a></h1>
            <p>Cadence is a distributed, scalable, durable, and highly available orchestration engine to execute asynchronous long-running business logic in a scalable and resilient way.</p>
            <p>Language: Go</p>
            <p>Stars: 8,562</p>
            <p>Forks: 820</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># Cadence
[![Build Status](https://badge.buildkite.com/159887afd42000f11126f85237317d4090de97b26c287ebc40.svg?theme=github&amp;branch=master)](https://buildkite.com/uberopensource/cadence-server)
[![Coverage](https://codecov.io/gh/cadence-workflow/cadence/graph/badge.svg?token=7SD244ImNF)](https://codecov.io/gh/cadence-workflow/cadence)
[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&amp;style=social)](http://t.uber.com/cadence-slack)
[![Github release](https://img.shields.io/github/v/release/cadence-workflow/cadence.svg)](https://github.com/cadence-workflow/cadence/releases)
[![License](https://img.shields.io/github/license/cadence-workflow/cadence.svg)](http://www.apache.org/licenses/LICENSE-2.0)

Cadence Workflow is an open-source platform since 2017 for building and running scalable, fault-tolerant, and long-running workflows. This repository contains the core orchestration engine and tools including CLI, schema managment, benchmark and canary.


## Getting Started

Cadence backend consists of multiple services, a database (Cassandra/MySQL/PostgreSQL) and optionally Kafka+Elasticsearch.
As a user, you need a worker which contains your workflow implementation.
Once you have Cadence backend and worker(s) running, you can trigger workflows by using SDKs or via CLI.

1. Start cadence backend components locally

```
docker-compose -f docker/docker-compose.yml up
```

2. Run the Samples

Try out the sample recipes for [Go](https://github.com/cadence-workflow/cadence-samples) or [Java](https://github.com/cadence-workflow/cadence-java-samples).

3. Visit UI

Visit http://localhost:8080 to check workflow histories and detailed traces.


### Client Libraries
You can implement your workflows with one of our client libraries:
- [Official Cadence Go SDK](https://github.com/cadence-workflow/cadence-go-client)
- [Official Cadence Java SDK](https://github.com/cadence-workflow/cadence-java-client)
There are also unofficial [Python](https://github.com/firdaus/cadence-python) and [Ruby](https://github.com/coinbase/cadence-ruby) SDKs developed by the community.

You can also use [iWF](https://github.com/indeedeng/iwf) as a DSL framework on top of Cadence.

### CLI

Cadence CLI can be used to operate workflows, tasklist, domain and even the clusters.

You can use the following ways to install Cadence CLI:
* Use brew to install CLI: `brew install cadence-workflow`
  * Follow the [instructions](https://github.com/cadence-workflow/cadence/discussions/4457) if you need to install older versions of CLI via homebrew. Usually this is only needed when you are running a server of a too old version.
* Use docker image for CLI: `docker run --rm ubercadence/cli:&lt;releaseVersion&gt;`  or `docker run --rm ubercadence/cli:master ` . Be sure to update your image when you want to try new features: `docker pull ubercadence/cli:master `
* Build the CLI binary yourself, check out the repo and run `make cadence` to build all tools. See [CONTRIBUTING](CONTRIBUTING.md) for prerequisite of make command.
* Build the CLI image yourself, see [instructions](docker/README.md#diy-building-an-image-for-any-tag-or-branch)

Cadence CLI is a powerful tool. The commands are organized by tabs. E.g. `workflow`-&gt;`batch`-&gt;`start`, or `admin`-&gt;`workflow`-&gt;`describe`.

Please read the [documentation](https://cadenceworkflow.io/docs/cli/#documentation) and always try out `--help` on any tab to learn &amp; explore.

### UI

Try out [Cadence Web UI](https://github.com/cadence-workflow/cadence-web) to view your workflows on Cadence.
(This is already available at localhost:8088 if you run Cadence with docker compose)


### Other binaries in this repo

#### Bench/stress test workflow tools
See [bench documentation](./bench/README.md).

#### Periodical feature health check workflow tools(aka Canary)
See [canary documentation](./canary/README.md).

#### Schema tools for SQL and Cassandra
The tools are for [manual setup or upgrading database schema](docs/persistence.md)

  * If server runs with Cassandra, Use [Cadence Cassandra tool](tools/cassandra/README.md)
  * If server runs with SQL database, Use [Cadence SQL tool](tools/sql/README.md)

The easiest way to get the schema tool is via homebrew.

`brew install cadence-workflow` also includes `cadence-sql-tool` and `cadence-cassandra-tool`.
 * The schema files are located at `/usr/local/etc/cadence/schema/`.
 * To upgrade, make sure you remove the old ElasticSearch schema first: `mv /usr/local/etc/cadence/schema/elasticsearch /usr/local/etc/cadence/schema/elasticsearch.old &amp;&amp; brew upgrade cadence-workflow`. Otherwise ElasticSearch schemas may not be able to get updated.
 * Follow the [instructions](https://github.com/cadence-workflow/cadence/discussions/4457) if you need to install older versions of schema tools via homebrew.
 However, easier way is to use new versions of schema tools with old versions of schemas.
 All you need is to check out the older version of schemas from this repo. Run `git checkout v0.21.3` to get the v0.21.3 schemas in [the schema folder](/schema).


## Contributing

We&#039;d love your help in making Cadence great. Please review our [contribution guide](CONTRIBUTING.md).

If you&#039;d like to propose a new feature, first join the [Slack channel](http://t.uber.com/cadence-slack) to start a discussion.

Please visit our [documentation](https://cadenceworkflow.io/docs/operation-guide/) site for production/cluster setup.


### Learning Resources
See Maxim&#039;s talk at [Data@Scale Conference](https://atscaleconference.com/videos/cadence-microservice-architecture-beyond-requestreply) for an architectural overview of Cadence.

Visit [cadenceworkflow.io](https://cadenceworkflow.io) to learn more about Cadence. Join us in [Cadence Documentation](https://github.com/cadence-workflow/Cadence-Docs) project. Feel free to raise an Issue or Pull Request there.

### Community
* [Github Discussion](https://github.com/cadence-workflow/cadence/discussions)
  * Best for Q&amp;A, support/help, general discusion, and annoucement
* [Github Issues](https://github.com/cadence-workflow/cadence/issues)
  * Best for reporting bugs and feature requests
* [StackOverflow](https://stackoverflow.com/questions/tagged/cadence-workflow)
  * Best for Q&amp;A and general discusion
* [Slack](http://t.uber.com/cadence-slack)
  * Best for contributing/development discussion


## Stars over time
[![Stargazers over time](https://starchart.cc/uber/cadence.svg?variant=adaptive)](https://starchart.cc/uber/cadence)


## License

MIT License, please see [LICENSE](https://github.com/cadence-workflow/cadence/blob/master/LICENSE) for details.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grafana/mimir]]></title>
            <link>https://github.com/grafana/mimir</link>
            <guid>https://github.com/grafana/mimir</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:45 GMT</pubDate>
            <description><![CDATA[Grafana Mimir provides horizontally scalable, highly available, multi-tenant, long-term storage for Prometheus.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grafana/mimir">grafana/mimir</a></h1>
            <p>Grafana Mimir provides horizontally scalable, highly available, multi-tenant, long-term storage for Prometheus.</p>
            <p>Language: Go</p>
            <p>Stars: 4,399</p>
            <p>Forks: 577</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre># Grafana Mimir

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;images/logo.png&quot; alt=&quot;Grafana Mimir logo&quot; width=&quot;400&quot;&gt;&lt;/p&gt;

Grafana Mimir is an open source software project that provides a scalable long-term storage for [Prometheus](https://prometheus.io). Some of the core strengths of Grafana Mimir include:

- **Easy to install and maintain:** Grafana Mimir‚Äôs extensive documentation, tutorials, and deployment tooling make it quick to get started. Using its monolithic mode, you can get Grafana Mimir up and running with just one binary and no additional dependencies. Once deployed, the best-practice dashboards, alerts, and runbooks packaged with Grafana Mimir make it easy to monitor the health of the system.
- **Massive scalability:** You can run Grafana Mimir&#039;s horizontally-scalable architecture across multiple machines, resulting in the ability to process orders of magnitude more time series than a single Prometheus instance. Internal testing shows that Grafana Mimir handles up to 1 billion active time series.
- **Global view of metrics:** Grafana Mimir enables you to run queries that aggregate series from multiple Prometheus instances, giving you a global view of your systems. Its query engine extensively parallelizes query execution, so that even the highest-cardinality queries complete with blazing speed.
- **Cheap, durable metric storage:** Grafana Mimir uses object storage for long-term data storage, allowing it to take advantage of this ubiquitous, cost-effective, high-durability technology. It is compatible with multiple object store implementations, including AWS S3, Google Cloud Storage, Azure Blob Storage, OpenStack Swift, as well as any S3-compatible object storage.
- **High availability:** Grafana Mimir replicates incoming metrics, ensuring that no data is lost in the event of machine failure. Its horizontally scalable architecture also means that it can be restarted, upgraded, or downgraded with zero downtime, which means no interruptions to metrics ingestion or querying.
- **Natively multi-tenant:** Grafana Mimir‚Äôs multi-tenant architecture enables you to isolate data and queries from independent teams or business units, making it possible for these groups to share the same cluster. Advanced limits and quality-of-service controls ensure that capacity is shared fairly among tenants.

## Migrating to Grafana Mimir

If you&#039;re migrating to Grafana Mimir, refer to the following documents:

- [Migrating from Thanos or Prometheus to Grafana Mimir](https://grafana.com/docs/mimir/latest/set-up/migrate/migrate-from-thanos-or-prometheus/).
- [Migrating from Cortex to Grafana Mimir](https://grafana.com/docs/mimir/latest/set-up/migrate/migrate-from-cortex/)

## Deploying Grafana Mimir

For information about how to deploy Grafana Mimir, refer to [Deploy Grafana Mimir](https://grafana.com/docs/mimir/latest/operators-guide/deploy-grafana-mimir/).

## Getting started

If you‚Äôre new to Grafana Mimir, read the [Get started guide](https://grafana.com/docs/mimir/latest/get-started/).

Before deploying Grafana Mimir in a production environment, read:

1. [An overview of Grafana Mimir‚Äôs architecture](https://grafana.com/docs/mimir/latest/operators-guide/architecture/)
1. [Configure Grafana Mimir](https://grafana.com/docs/mimir/latest/operators-guide/configure/)
1. [Run Grafana Mimir in production](https://grafana.com/docs/mimir/latest/operators-guide/run-production-environment/)

## Documentation

Refer to the following links to access Grafana Mimir documentation:

- [Latest release](https://grafana.com/docs/mimir/latest/)
- [Upcoming release](https://grafana.com/docs/mimir/next/), at the tip of the `main` branch

## Contributing

To contribute to Grafana Mimir, refer to [Contributing to Grafana Mimir](https://github.com/grafana/mimir/tree/main/docs/internal/contributing).

## Join the Grafana Mimir discussion

If you have any questions or feedback regarding Grafana Mimir, join the [Grafana Mimir Discussion](https://github.com/grafana/mimir/discussions). Alternatively, consider joining the monthly [Grafana Mimir Community Call](https://docs.google.com/document/d/1E4jJcGicvLTyMEY6cUFFZUg_I8ytrBuW8r5yt1LyMv4).

Your feedback is always welcome, and you can also share it via the [`#mimir` Slack channel](https://slack.grafana.com/).

## License

Grafana Mimir is distributed under [AGPL-3.0-only](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[sundowndev/phoneinfoga]]></title>
            <link>https://github.com/sundowndev/phoneinfoga</link>
            <guid>https://github.com/sundowndev/phoneinfoga</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[Information gathering framework for phone numbers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sundowndev/phoneinfoga">sundowndev/phoneinfoga</a></h1>
            <p>Information gathering framework for phone numbers</p>
            <p>Language: Go</p>
            <p>Stars: 14,021</p>
            <p>Forks: 3,945</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/banner.png&quot; width=500  alt=&quot;project logo&quot;/&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/sundowndev/phoneinfoga/actions&quot;&gt;
    &lt;img src=&quot;https://github.com/sundowndev/phoneinfoga/workflows/Build/badge.svg&quot; alt=&quot;build status&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/sundowndev/phoneinfoga/v2&quot;&gt;
    &lt;img src=&quot;https://goreportcard.com/badge/github.com/sundowndev/phoneinfoga/v2&quot; alt=&quot;go report&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codeclimate.com/github/sundowndev/phoneinfoga/maintainability&quot;&gt;
    &lt;img src=&quot;https://api.codeclimate.com/v1/badges/3259feb1c68df1cd4f71/maintainability&quot;  alt=&quot;code climate badge&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&#039;https://coveralls.io/github/sundowndev/phoneinfoga&#039;&gt;
    &lt;img src=&#039;https://coveralls.io/repos/github/sundowndev/phoneinfoga/badge.svg&#039; alt=&#039;Coverage Status&#039; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/sundowndev/phoneinfoga/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/release/SundownDEV/phoneinfoga.svg&quot; alt=&quot;Latest version&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://hub.docker.com/r/sundowndev/phoneinfoga&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/docker/pulls/sundowndev/phoneinfoga.svg&quot; alt=&quot;Docker pulls&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;h4 align=&quot;center&quot;&gt;Information gathering framework for phone numbers&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://sundowndev.github.io/phoneinfoga/&quot;&gt;Documentation&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://petstore.swagger.io/?url=https://raw.githubusercontent.com/sundowndev/phoneinfoga/master/web/docs/swagger.yaml&quot;&gt;API documentation&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://medium.com/@SundownDEV/phone-number-scanning-osint-recon-tool-6ad8f0cac27b&quot;&gt;Related blog post&lt;/a&gt;
&lt;/p&gt;

## About

PhoneInfoga is one of the most advanced tools to scan international phone numbers. It allows you to first gather basic information such as country, area, carrier and line type, then use various techniques to try to find the VoIP provider or identify the owner. It works with a collection of scanners that must be configured in order for the tool to be effective. PhoneInfoga doesn&#039;t automate everything, it&#039;s just there to help investigating on phone numbers.

## Current status

This project is stable and production-ready.

#### Demo instance termination

The demo instance has been terminated on December 21th, 2023. It&#039;s been expensive to maintain this instance throughout the years given the number of requests it received (~20K/month), without bringing much value to users compared to using it locally. Use it locally with your own API keys for a better experience.

## Features

- Check if phone number exists
- Gather basic information such as country, line type and carrier
- OSINT footprinting using external APIs, phone books &amp; search engines
- Check for reputation reports, social media, disposable numbers and more
- Use the graphical user interface to run scans from the browser
- Programmatic usage with the [REST API](https://petstore.swagger.io/?url=https://raw.githubusercontent.com/sundowndev/phoneinfoga/master/web/docs/swagger.yaml) and [Go modules](https://pkg.go.dev/github.com/sundowndev/phoneinfoga/v2)

## Anti-features

- Does not claim to provide relevant or verified data, it&#039;s just a tool !
- Does not allow to &quot;track&quot; a phone or its owner in real time
- Does not allow to get the precise phone location
- Does not allow to hack a phone

## License

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fsundowndev%2FPhoneInfoga.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fsundowndev%2FPhoneInfoga?ref=badge_shield)

This tool is licensed under the GNU General Public License v3.0.

[Icon](https://www.flaticon.com/free-icon/fingerprint-search-symbol-of-secret-service-investigation_48838) made by &lt;a href=&quot;https://www.freepik.com/&quot; title=&quot;Freepik&quot;&gt;Freepik&lt;/a&gt; from &lt;a href=&quot;https://www.flaticon.com/&quot; title=&quot;Flaticon&quot;&gt;flaticon.com&lt;/a&gt; is licensed by &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/&quot; title=&quot;Creative Commons BY 3.0&quot; target=&quot;_blank&quot;&gt;CC 3.0 BY&lt;/a&gt;.

## Support

Support me by signing up to DigitalOcean using my link ($200 free credits)

[![DigitalOcean Referral Badge](https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%203.svg)](https://www.digitalocean.com/?refcode=31f5ef768eb3&amp;utm_campaign=Referral_Invite&amp;utm_medium=Referral_Program&amp;utm_source=badge)

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/sundowndev/static/raw/main/sponsors.svg?v=c68eba9&quot; width=&quot;100%&quot; heigh=&quot;auto&quot; /&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[netbirdio/netbird]]></title>
            <link>https://github.com/netbirdio/netbird</link>
            <guid>https://github.com/netbirdio/netbird</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[Connect your devices into a secure WireGuard¬Æ-based overlay network with SSO, MFA and granular access controls.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/netbirdio/netbird">netbirdio/netbird</a></h1>
            <p>Connect your devices into a secure WireGuard¬Æ-based overlay network with SSO, MFA and granular access controls.</p>
            <p>Language: Go</p>
            <p>Stars: 12,712</p>
            <p>Forks: 611</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;br/&gt;
  &lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;234&quot; src=&quot;docs/media/logo-full.png&quot;/&gt;
&lt;/p&gt;
  &lt;p&gt;
   &lt;a href=&quot;https://img.shields.io/badge/license-BSD--3-blue)&quot;&gt;
       &lt;img src=&quot;https://sonarcloud.io/api/project_badges/measure?project=netbirdio_netbird&amp;metric=alert_status&quot; /&gt;
     &lt;/a&gt; 
     &lt;a href=&quot;https://github.com/netbirdio/netbird/blob/main/LICENSE&quot;&gt;
       &lt;img src=&quot;https://img.shields.io/badge/license-BSD--3-blue&quot; /&gt;
     &lt;/a&gt; 
    &lt;br&gt;
    &lt;a href=&quot;https://join.slack.com/t/netbirdio/shared_invite/zt-31rofwmxc-27akKd0Le0vyRpBcwXkP0g&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/slack-@netbird-red.svg?logo=slack&quot;/&gt;
     &lt;/a&gt;  
     &lt;br&gt;
    &lt;a href=&quot;https://gurubase.io/g/netbird&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/Gurubase-Ask%20NetBird%20Guru-006BFF&quot;/&gt;
     &lt;/a&gt;    
  &lt;/p&gt;
&lt;/div&gt;


&lt;p align=&quot;center&quot;&gt;
&lt;strong&gt;
  Start using NetBird at &lt;a href=&quot;https://netbird.io/pricing&quot;&gt;netbird.io&lt;/a&gt;
  &lt;br/&gt;
  See &lt;a href=&quot;https://netbird.io/docs/&quot;&gt;Documentation&lt;/a&gt;
  &lt;br/&gt;
   Join our &lt;a href=&quot;https://join.slack.com/t/netbirdio/shared_invite/zt-31rofwmxc-27akKd0Le0vyRpBcwXkP0g&quot;&gt;Slack channel&lt;/a&gt;
  &lt;br/&gt;
 
&lt;/strong&gt;
&lt;br&gt;
&lt;a href=&quot;https://github.com/netbirdio/kubernetes-operator&quot;&gt;
    New: NetBird Kubernetes Operator
  &lt;/a&gt; 
&lt;/p&gt;

&lt;br&gt;

**NetBird combines a configuration-free peer-to-peer private network and a centralized access control system in a single platform, making it easy to create secure private networks for your organization or home.**

**Connect.** NetBird creates a WireGuard-based overlay network that automatically connects your machines over an encrypted tunnel, leaving behind the hassle of opening ports, complex firewall rules, VPN gateways, and so forth.

**Secure.** NetBird enables secure remote access by applying granular access policies while allowing you to manage them intuitively from a single place. Works universally on any infrastructure.

### Open-Source Network Security in a Single Platform


![netbird_2](https://github.com/netbirdio/netbird/assets/700848/46bc3b73-508d-4a0e-bb9a-f465d68646ab)

### NetBird on Lawrence Systems (Video)
[![Watch the video](https://img.youtube.com/vi/Kwrff6h0rEw/0.jpg)](https://www.youtube.com/watch?v=Kwrff6h0rEw)

### Key features

| Connectivity                                                                                                                 | Management                                                                                               | Security                                                                                                                              | Automation                                                                                                                               | Platforms                                                                               |
|------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|
| &lt;ul&gt;&lt;li&gt; - \[x] Kernel WireGuard &lt;/ul&gt;&lt;/li&gt;                                                                                  | &lt;ul&gt;&lt;li&gt; - \[x] [Admin Web UI](https://github.com/netbirdio/dashboard) &lt;/ul&gt;&lt;/li&gt;                        | &lt;ul&gt;&lt;li&gt; - \[x] [SSO &amp; MFA support](https://docs.netbird.io/how-to/installation#running-net-bird-with-sso-login) &lt;/ul&gt;&lt;/li&gt;           | &lt;ul&gt;&lt;li&gt; - \[x] [Public API](https://docs.netbird.io/api) &lt;/ul&gt;&lt;/li&gt;                                                                     | &lt;ul&gt;&lt;li&gt; - \[x] Linux &lt;/ul&gt;&lt;/li&gt;                                                        |
| &lt;ul&gt;&lt;li&gt; - \[x] Peer-to-peer connections &lt;/ul&gt;&lt;/li&gt;                                                                          | &lt;ul&gt;&lt;li&gt; - \[x] Auto peer discovery and configuration &lt;/ul&gt;&lt;/li&gt;                                         | &lt;ul&gt;&lt;li&gt; - \[x] [Access control - groups &amp; rules](https://docs.netbird.io/how-to/manage-network-access) &lt;/ul&gt;&lt;/li&gt;                    | &lt;ul&gt;&lt;li&gt; - \[x] [Setup keys for bulk network provisioning](https://docs.netbird.io/how-to/register-machines-using-setup-keys) &lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt; - \[x] Mac &lt;/ul&gt;&lt;/li&gt;                                                          |
| &lt;ul&gt;&lt;li&gt; - \[x] Connection relay fallback &lt;/ul&gt;&lt;/li&gt;                                                                         | &lt;ul&gt;&lt;li&gt; - \[x] [IdP integrations](https://docs.netbird.io/selfhosted/identity-providers) &lt;/ul&gt;&lt;/li&gt;     | &lt;ul&gt;&lt;li&gt; - \[x] [Activity logging](https://docs.netbird.io/how-to/monitor-system-and-network-activity) &lt;/ul&gt;&lt;/li&gt;                     | &lt;ul&gt;&lt;li&gt; - \[x] [Self-hosting quickstart script](https://docs.netbird.io/selfhosted/selfhosted-quickstart) &lt;/ul&gt;&lt;/li&gt;                    | &lt;ul&gt;&lt;li&gt; - \[x] Windows &lt;/ul&gt;&lt;/li&gt;                                                      |
| &lt;ul&gt;&lt;li&gt; - \[x] [Routes to external networks](https://docs.netbird.io/how-to/routing-traffic-to-private-networks) &lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt; - \[x] [Private DNS](https://docs.netbird.io/how-to/manage-dns-in-your-network) &lt;/ul&gt;&lt;/li&gt;      | &lt;ul&gt;&lt;li&gt; - \[x] [Device posture checks](https://docs.netbird.io/how-to/manage-posture-checks) &lt;/ul&gt;&lt;/li&gt;                              | &lt;ul&gt;&lt;li&gt; - \[x] IdP groups sync with JWT &lt;/ul&gt;&lt;/li&gt;                                                                                      | &lt;ul&gt;&lt;li&gt; - \[x] Android &lt;/ul&gt;&lt;/li&gt;                                                      |
| &lt;ul&gt;&lt;li&gt; - \[x] NAT traversal with BPF &lt;/ul&gt;&lt;/li&gt;                                                                            | &lt;ul&gt;&lt;li&gt; - \[x] [Multiuser support](https://docs.netbird.io/how-to/add-users-to-your-network) &lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt; -  \[x] Peer-to-peer encryption &lt;/ul&gt;&lt;/li&gt;                                                                                   |                                                                                                                                          | &lt;ul&gt;&lt;li&gt; - \[x] iOS &lt;/ul&gt;&lt;/li&gt;                                                          |
|                                                                                                                              |                                                                                                          | &lt;ul&gt;&lt;li&gt; - \[x] [Quantum-resistance with Rosenpass](https://netbird.io/knowledge-hub/the-first-quantum-resistant-mesh-vpn) &lt;/ul&gt;&lt;/li&gt; |                                                                                                                                          | &lt;ul&gt;&lt;li&gt; - \[x] OpenWRT &lt;/ul&gt;&lt;/li&gt;                                                      |
|                                                                                                                              |                                                                                                          | &lt;ui&gt;&lt;li&gt; - \[x] [Periodic re-authentication](https://docs.netbird.io/how-to/enforce-periodic-user-authentication)&lt;/ul&gt;&lt;/li&gt;           |                                                                                                                                          | &lt;ul&gt;&lt;li&gt; - \[x] [Serverless](https://docs.netbird.io/how-to/netbird-on-faas) &lt;/ul&gt;&lt;/li&gt; |
|                                                                                                                              |                                                                                                          |                                                                                                                                       |                                                                                                                                          | &lt;ul&gt;&lt;li&gt; - \[x] Docker &lt;/ul&gt;&lt;/li&gt;                                                       |

### Quickstart with NetBird Cloud

- Download and install NetBird at [https://app.netbird.io/install](https://app.netbird.io/install)
- Follow the steps to sign-up with Google, Microsoft, GitHub or your email address.
- Check NetBird [admin UI](https://app.netbird.io/).
- Add more machines.

### Quickstart with self-hosted NetBird

&gt; This is the quickest way to try self-hosted NetBird. It should take around 5 minutes to get started if you already have a public domain and a VM.
Follow the [Advanced guide with a custom identity provider](https://docs.netbird.io/selfhosted/selfhosted-guide#advanced-guide-with-a-custom-identity-provider) for installations with different IDPs.

**Infrastructure requirements:**
- A Linux VM with at least **1CPU** and **2GB** of memory.
- The VM should be publicly accessible on TCP ports **80** and **443** and UDP ports: **3478**, **49152-65535**.
- **Public domain** name pointing to the VM.

**Software requirements:**
- Docker installed on the VM with the docker-compose plugin ([Docker installation guide](https://docs.docker.com/engine/install/)) or docker with docker-compose in version 2 or higher.
- [jq](https://jqlang.github.io/jq/) installed. In most distributions
  Usually available in the official repositories and can be installed with `sudo apt install jq` or `sudo yum install jq`
- [curl](https://curl.se/) installed.
  Usually available in the official repositories and can be installed with `sudo apt install curl` or `sudo yum install curl`

**Steps**
- Download and run the installation script:
```bash
export NETBIRD_DOMAIN=netbird.example.com; curl -fsSL https://github.com/netbirdio/netbird/releases/latest/download/getting-started-with-zitadel.sh | bash
```
- Once finished, you can manage the resources via `docker-compose`

### A bit on NetBird internals
-  Every machine in the network runs [NetBird Agent (or Client)](client/) that manages WireGuard.
-  Every agent connects to [Management Service](management/) that holds network state, manages peer IPs, and distributes network updates to agents (peers).
-  NetBird agent uses WebRTC ICE implemented in [pion/ice library](https://github.com/pion/ice) to discover connection candidates when establishing a peer-to-peer connection between machines.
-  Connection candidates are discovered with the help of [STUN](https://en.wikipedia.org/wiki/STUN) servers.
-  Agents negotiate a connection through [Signal Service](signal/) passing p2p encrypted messages with candidates.
-  Sometimes the NAT traversal is unsuccessful due to strict NATs (e.g. mobile carrier-grade NAT) and a p2p connection isn&#039;t possible. When this occurs the system falls back to a relay server called [TURN](https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT), and a secure WireGuard tunnel is established via the TURN server. 
 
[Coturn](https://github.com/coturn/coturn) is the one that has been successfully used for STUN and TURN in NetBird setups.

&lt;p float=&quot;left&quot; align=&quot;middle&quot;&gt;
  &lt;img src=&quot;https://docs.netbird.io/docs-static/img/architecture/high-level-dia.png&quot; width=&quot;700&quot;/&gt;
&lt;/p&gt;

See a complete [architecture overview](https://docs.netbird.io/about-netbird/how-netbird-works#architecture) for details.

### Community projects
-  [NetBird installer script](https://github.com/physk/netbird-installer)
-  [NetBird ansible collection by Dominion Solutions](https://galaxy.ansible.com/ui/repo/published/dominion_solutions/netbird/)

**Note**: The `main` branch may be in an *unstable or even broken state* during development.
For stable versions, see [releases](https://github.com/netbirdio/netbird/releases).

### Support acknowledgement

In November 2022, NetBird joined the [StartUpSecure program](https://www.forschung-it-sicherheit-kommunikationssysteme.de/foerderung/bekanntmachungen/startup-secure) sponsored by The Federal Ministry of Education and Research of The Federal Republic of Germany. Together with [CISPA Helmholtz Center for Information Security](https://cispa.de/en) NetBird brings the security best practices and simplicity to private networking.

![CISPA_Logo_BLACK_EN_RZ_RGB (1)](https://user-images.githubusercontent.com/700848/203091324-c6d311a0-22b5-4b05-a288-91cbc6cdcc46.png)

### Testimonials
We use open-source technologies like [WireGuard¬Æ](https://www.wireguard.com/), [Pion ICE (WebRTC)](https://github.com/pion/ice), [Coturn](https://github.com/coturn/coturn), and [Rosenpass](https://rosenpass.eu). We very much appreciate the work these guys are doing and we&#039;d greatly appreciate if you could support them in any way (e.g., by giving a star or a contribution).

### Legal
 _WireGuard_ and the _WireGuard_ logo are [registered trademarks](https://www.wireguard.com/trademark-policy/) of Jason A. Donenfeld.

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[stretchr/testify]]></title>
            <link>https://github.com/stretchr/testify</link>
            <guid>https://github.com/stretchr/testify</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:42 GMT</pubDate>
            <description><![CDATA[A toolkit with common assertions and mocks that plays nicely with the standard library]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stretchr/testify">stretchr/testify</a></h1>
            <p>A toolkit with common assertions and mocks that plays nicely with the standard library</p>
            <p>Language: Go</p>
            <p>Stars: 24,320</p>
            <p>Forks: 1,627</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>Testify - Thou Shalt Write Tests
================================

&gt; [!NOTE]
&gt; Testify is being maintained at v1, no breaking changes will be accepted in this repo.  
&gt; [See discussion about v2](https://github.com/stretchr/testify/discussions/1560).

[![Build Status](https://github.com/stretchr/testify/actions/workflows/main.yml/badge.svg?branch=master)](https://github.com/stretchr/testify/actions/workflows/main.yml) [![Go Report Card](https://goreportcard.com/badge/github.com/stretchr/testify)](https://goreportcard.com/report/github.com/stretchr/testify) [![PkgGoDev](https://pkg.go.dev/badge/github.com/stretchr/testify)](https://pkg.go.dev/github.com/stretchr/testify)

Go code (golang) set of packages that provide many tools for testifying that your code will behave as you intend.

Features include:

  * [Easy assertions](#assert-package)
  * [Mocking](#mock-package)
  * [Testing suite interfaces and functions](#suite-package)

Get started:

  * Install testify with [one line of code](#installation), or [update it with another](#staying-up-to-date)
  * For an introduction to writing test code in Go, see https://go.dev/doc/code#Testing
  * Check out the API Documentation https://pkg.go.dev/github.com/stretchr/testify
  * Use [testifylint](https://github.com/Antonboom/testifylint) (via [golangci-lint](https://golangci-lint.run/)) to avoid common mistakes
  * A little about [Test-Driven Development (TDD)](https://en.wikipedia.org/wiki/Test-driven_development)

[`assert`](https://pkg.go.dev/github.com/stretchr/testify/assert &quot;API documentation&quot;) package
-------------------------------------------------------------------------------------------

The `assert` package provides some helpful methods that allow you to write better test code in Go.

  * Prints friendly, easy to read failure descriptions
  * Allows for very readable code
  * Optionally annotate each assertion with a message

See it in action:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	// assert equality
	assert.Equal(t, 123, 123, &quot;they should be equal&quot;)

	// assert inequality
	assert.NotEqual(t, 123, 456, &quot;they should not be equal&quot;)

	// assert for nil (good for errors)
	assert.Nil(t, object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(t, object) {
		// now we know that object isn&#039;t nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(t, &quot;Something&quot;, object.Value)
	}
}
```

  * Every assert func takes the `testing.T` object as the first argument.  This is how it writes the errors out through the normal `go test` capabilities.
  * Every assert func returns a bool indicating whether the assertion was successful or not, this is useful for if you want to go on making further assertions under certain conditions.

if you assert many times, use the below:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	assert := assert.New(t)

	// assert equality
	assert.Equal(123, 123, &quot;they should be equal&quot;)

	// assert inequality
	assert.NotEqual(123, 456, &quot;they should not be equal&quot;)

	// assert for nil (good for errors)
	assert.Nil(object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(object) {
		// now we know that object isn&#039;t nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(&quot;Something&quot;, object.Value)
	}
}
```

[`require`](https://pkg.go.dev/github.com/stretchr/testify/require &quot;API documentation&quot;) package
---------------------------------------------------------------------------------------------

The `require` package provides same global functions as the `assert` package, but instead of returning a boolean result they terminate current test.
These functions must be called from the goroutine running the test or benchmark function, not from other goroutines created during the test.
Otherwise race conditions may occur.

See [t.FailNow](https://pkg.go.dev/testing#T.FailNow) for details.

[`mock`](https://pkg.go.dev/github.com/stretchr/testify/mock &quot;API documentation&quot;) package
----------------------------------------------------------------------------------------

The `mock` package provides a mechanism for easily writing mock objects that can be used in place of real objects when writing test code.

An example test function that tests a piece of code that relies on an external object `testObj`, can set up expectations (testify) and assert that they indeed happened:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/mock&quot;
)

/*
  Test objects
*/

// MyMockedObject is a mocked object that implements an interface
// that describes an object that the code I am testing relies on.
type MyMockedObject struct {
	mock.Mock
}

// DoSomething is a method on MyMockedObject that implements some interface
// and just records the activity, and returns what the Mock object tells it to.
//
// In the real object, this method would do something useful, but since this
// is a mocked object - we&#039;re just going to stub it out.
//
// NOTE: This method is not being tested here, code that uses this object is.
func (m *MyMockedObject) DoSomething(number int) (bool, error) {
	args := m.Called(number)
	return args.Bool(0), args.Error(1)
}

/*
  Actual test functions
*/

// TestSomething is an example of how to use our test object to
// make assertions about some target code we are testing.
func TestSomething(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations
	testObj.On(&quot;DoSomething&quot;, 123).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)
}

// TestSomethingWithPlaceholder is a second example of how to use our test object to
// make assertions about some target code we are testing.
// This time using a placeholder. Placeholders might be used when the
// data being passed in is normally dynamically generated and cannot be
// predicted beforehand (eg. containing hashes that are time sensitive)
func TestSomethingWithPlaceholder(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

}

// TestSomethingElse2 is a third example that shows how you can use
// the Unset method to cleanup handlers and then add new ones.
func TestSomethingElse2(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	mockCall := testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

	// remove the handler now so we can add another one that takes precedence
	mockCall.Unset()

	// return false now instead of true
	testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(false, nil)

	testObj.AssertExpectations(t)
}
```

For more information on how to write mock code, check out the [API documentation for the `mock` package](https://pkg.go.dev/github.com/stretchr/testify/mock).

You can use the [mockery tool](https://vektra.github.io/mockery/latest/) to autogenerate the mock code against an interface as well, making using mocks much quicker.

[`suite`](https://pkg.go.dev/github.com/stretchr/testify/suite &quot;API documentation&quot;) package
-----------------------------------------------------------------------------------------
&gt; [!WARNING]
&gt; The suite package does not support parallel tests. See [#934](https://github.com/stretchr/testify/issues/934).

The `suite` package provides functionality that you might be used to from more common object-oriented languages.  With it, you can build a testing suite as a struct, build setup/teardown methods and testing methods on your struct, and run them with &#039;go test&#039; as per normal.

An example suite is shown below:

```go
// Basic imports
import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
	&quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including a T() method which
// returns the current testing context
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	assert.Equal(suite.T(), 5, suite.VariableThatShouldStartAtFive)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
```

For a more complete example, using all of the functionality provided by the suite package, look at our [example testing suite](https://github.com/stretchr/testify/blob/master/suite/suite_test.go)

For more information on writing suites, check out the [API documentation for the `suite` package](https://pkg.go.dev/github.com/stretchr/testify/suite).

`Suite` object has assertion methods:

```go
// Basic imports
import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including assertion methods.
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	suite.Equal(suite.VariableThatShouldStartAtFive, 5)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
```

------

Installation
============

To install Testify, use `go get`:

    go get github.com/stretchr/testify

This will then make the following packages available to you:

    github.com/stretchr/testify/assert
    github.com/stretchr/testify/require
    github.com/stretchr/testify/mock
    github.com/stretchr/testify/suite
    github.com/stretchr/testify/http (deprecated)

Import the `testify/assert` package into your code using this template:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	assert.True(t, true, &quot;True is true!&quot;)
}
```

------

Staying up to date
==================

To update Testify to the latest version, use `go get -u github.com/stretchr/testify`.

------

Supported go versions
==================

We currently support the most recent major Go versions from 1.19 onward.

------

Contributing
============

Please feel free to submit issues, fork the repository and send pull requests!

When submitting an issue, we ask that you please include a complete test function that demonstrates the issue. Extra credit for those using Testify to write the test code that demonstrates it.

Code generation is used. [Look for `Code generated with`](https://github.com/search?q=repo%3Astretchr%2Ftestify%20%22Code%20generated%20with%22&amp;type=code) at the top of some files. Run `go generate ./...` to update generated files.

We also chat on the [Gophers Slack](https://gophers.slack.com) group in the `#testify` and `#testify-dev` channels.

------

License
=======

This project is licensed under the terms of the MIT license.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kgateway-dev/kgateway]]></title>
            <link>https://github.com/kgateway-dev/kgateway</link>
            <guid>https://github.com/kgateway-dev/kgateway</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:41 GMT</pubDate>
            <description><![CDATA[The Cloud-Native API Gateway and AI Gateway]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kgateway-dev/kgateway">kgateway-dev/kgateway</a></h1>
            <p>The Cloud-Native API Gateway and AI Gateway</p>
            <p>Language: Go</p>
            <p>Stars: 4,308</p>
            <p>Forks: 480</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo-dark.svg&quot; alt=&quot;kgateway&quot; width=&quot;400&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo.svg&quot; alt=&quot;kgateway&quot; width=&quot;400&quot;&gt;
    &lt;img alt=&quot;kgateway&quot; src=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo.svg&quot;&gt;
  &lt;/picture&gt;
  &lt;br/&gt;
  An Envoy-Powered, Kubernetes-Native API Gateway
&lt;/h1&gt;

## About kgateway
Kgateway is a feature-rich, fast, and flexible Kubernetes-native ingress controller and next-generation API gateway that is built on top of [Envoy proxy](https://www.envoyproxy.io) and the Kubernetes Gateway API. It excels in function-level routing, supports legacy apps, microservices and serverless, offers robust discovery capabilities, integrates seamlessly with open-source projects, and is designed to support hybrid applications with various technologies, architectures, protocols, and clouds.

Please see [the plan](https://github.com/kgateway-dev/kgateway/issues/10363) for more information and current status.

[**Installation**](https://kgateway.dev/docs/quickstart/) &amp;nbsp; |
&amp;nbsp; [**Documentation**](https://kgateway.dev/docs) &amp;nbsp; |
&amp;nbsp; [**Blog**](https://kgateway.dev/blog/) &amp;nbsp; |
&amp;nbsp; [**Slack invite**](https://slack.cncf.io/) &amp;nbsp; |
&amp;nbsp; [**Slack channel**](https://cloud-native.slack.com/archives/C080D3PJMS4)

&lt;BR&gt;&lt;center&gt;&lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/assets/img/component-architecture.svg&quot; alt=&quot;kgateway Architecture&quot; width=&quot;700&quot;&gt;&lt;/center&gt;

### Using kgateway
- **Kubernetes Gateway API**: Kgateway is a feature-rich ingress controller, built on top of the Envoy Proxy and fully conformant with the Kubernetes Gateway API.
- **Next-generation API gateway**: Kgateway provides a long list of API gateway features including rate limiting, circuit breaking, retries, caching, transformation, service-mesh integration, security, external authentication and authorization.
- **Hybrid apps**: Kgateway creates applications that route to backends implemented as microservices, serverless functions and legacy apps. This feature can help users to
  * Gradually migrate from their legacy code to microservices and serverless.
  * Add new functionalities using cloud-native technologies while maintaining their legacy codebase.
  * Allow different teams in an organization choose different architectures.

&lt;!---
PLEASE DO NOT RENAME THIS SECTION
This header is used as an anchor in our CNCF Donation Issue
--&gt;
### What makes kgateway unique
- **Function-level routing allows integration of legacy applications, microservices and serverless**: Kgateway can route requests directly to functions. Request to Function can be a serverless function call (e.g. Lambda, Google Cloud Function, OpenFaaS Function, etc.), an API call on a microservice or a legacy service (e.g. a REST API call, OpenAPI operation, XML/SOAP request etc.), or publishing to a message queue (e.g. NATS, AMQP, etc.). This unique ability is what makes kgateway the only API gateway that supports hybrid apps as well as the only one that does not tie the user to a specific paradigm.
- **Kgateway incorporates vetted open-source projects to provide broad functionality**: Kgateway supports high-quality features by integrating with top open-source projects, including gRPC, OpenTracing, NATS and more. Kgateway&#039;s architecture allows rapid integration of future popular open-source projects as they emerge.
- **Full automated discovery lets users move fast**: Upon launch, kgateway creates a catalog of all available destinations and continuously keeps them up to date. This takes the responsibility for &#039;bookkeeping&#039; away from the developers and guarantees that new features become available as soon as they are ready. Kgateway discovers across IaaS, PaaS and FaaS providers as well as Swagger, and gRPC.


## Next steps
- Join us on our Slack channel: [#kgateway](https://cloud-native.slack.com/archives/C080D3PJMS4) ([get an invite here]((https://slack.cncf.io/)))
- Check out the docs: [https://kgateway.dev/docs](https://kgateway.dev/docs)
- Learn more about the [community](https://github.com/kgateway-dev/community)

## Contributing to kgateway
The [devel](devel) folder should be the starting point for understanding the code, and contributing to the product.

## Thanks
Kgateway would not be possible without the valuable open-source work of projects in the community. We would like to extend a special thank-you to [Envoy](https://www.envoyproxy.io).

## Security
*Reporting security issues* : We take kgateway&#039;s security very seriously. If you&#039;ve found a security issue or a potential security issue in kgateway, please DO NOT file a public GitHub issue. Instead follow [the directions laid out in the kgateway/community repository](https://github.com/kgateway-dev/community/blob/main/CVE.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[GoogleCloudPlatform/terraformer]]></title>
            <link>https://github.com/GoogleCloudPlatform/terraformer</link>
            <guid>https://github.com/GoogleCloudPlatform/terraformer</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:40 GMT</pubDate>
            <description><![CDATA[CLI tool to generate terraform files from existing infrastructure (reverse Terraform). Infrastructure to Code]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GoogleCloudPlatform/terraformer">GoogleCloudPlatform/terraformer</a></h1>
            <p>CLI tool to generate terraform files from existing infrastructure (reverse Terraform). Infrastructure to Code</p>
            <p>Language: Go</p>
            <p>Stars: 13,358</p>
            <p>Forks: 1,720</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># Terraformer

[![tests](https://github.com/GoogleCloudPlatform/terraformer/actions/workflows/test.yml/badge.svg)](https://github.com/GoogleCloudPlatform/terraformer/actions/workflows/test.yml)
[![linter](https://github.com/GoogleCloudPlatform/terraformer/actions/workflows/linter.yml/badge.svg)](https://github.com/GoogleCloudPlatform/terraformer/actions/workflows/linter.yml)
[![Go Report Card](https://goreportcard.com/badge/github.com/GoogleCloudPlatform/terraformer)](https://goreportcard.com/report/github.com/GoogleCloudPlatform/terraformer)
[![AUR package](https://img.shields.io/aur/version/terraformer)](https://aur.archlinux.org/packages/terraformer/)
[![Homebrew](https://img.shields.io/badge/dynamic/json.svg?url=https://formulae.brew.sh/api/formula/terraformer.json&amp;query=$.versions.stable&amp;label=homebrew)](https://formulae.brew.sh/formula/terraformer)

A CLI tool that generates `tf`/`json` and `tfstate` files based on existing infrastructure
(reverse Terraform).

*   Disclaimer: This is not an official Google product
*   Created by: Waze SRE

![Waze SRE logo](assets/waze-sre-logo.png)

# Table of Contents
- [Demo GCP](#demo-gcp)
- [Capabilities](#capabilities)
- [Installation](#installation)
- [Supported Providers](/docs)
    * Major Cloud
        * [Google Cloud](/docs/gcp.md)
        * [AWS](/docs/aws.md)
        * [Azure](/docs/azure.md)
        * [AliCloud](/docs/alicloud.md)
        * [IBM Cloud](/docs/ibmcloud.md)
    * Cloud
        * [DigitalOcean](/docs/digitalocean.md)
        * [Equinix Metal](/docs/equinixmetal.md)
        * [Fastly](/docs/fastly.md)
        * [Heroku](/docs/heroku.md)
        * [LaunchDarkly](/docs/launchdarkly.md)
        * [Linode](/docs/linode.md)
        * [NS1](/docs/ns1.md)
        * [OpenStack](/docs/openstack.md)
        * [TencentCloud](/docs/tencentcloud.md)
        * [Vultr](/docs/vultr.md)
        * [Yandex Cloud](/docs/yandex.md)
        * [Ionos Cloud](/docs/ionoscloud.md)
    * Infrastructure Software
        * [Kubernetes](/docs/kubernetes.md)
        * [OctopusDeploy](/docs/octopus.md)
        * [RabbitMQ](/docs/rabbitmq.md)
    * Network
        * [Cloudflare](/docs/cloudflare.md) (broken, see #1761)
        * [Myrasec](/docs/myrasec.md)
        * [PAN-OS](/docs/panos.md)
    * VCS
        * [Azure DevOps](/docs/azuredevops.md)
        * [GitHub](/docs/github.md)
        * [Gitlab](/docs/gitlab.md)
    * Monitoring &amp; System Management
        * [Datadog](/docs/datadog.md)
        * [New Relic](/docs/relic.md)
        * [Mackerel](/docs/mackerel.md)
        * [PagerDuty](/docs/pagerduty.md)
        * [Opsgenie](/docs/opsgenie.md)
        * [Honeycomb.io](/docs/honeycombio.md)
        * [Opal](/docs/opal.md)
    * Community
        * [Keycloak](/docs/keycloak.md)
        * [Logz.io](/docs/logz.md)
        * [Commercetools](/docs/commercetools.md)
        * [Mikrotik](/docs/mikrotik.md)
        * [Xen Orchestra](/docs/xen.md)
        * [GmailFilter](/docs/gmailfilter.md)
        * [Grafana](/docs/grafana.md)
        * [Vault](/docs/vault.md)
    * Identity
        * [Okta](/docs/okta.md)
        * [Auth0](/docs/auth0.md)
        * [AzureAD](/docs/azuread.md)
- [Contributing](#contributing)
- [Developing](#developing)
- [Infrastructure](#infrastructure)
- [Stargazers over time](#stargazers-over-time)

## Demo GCP
[![asciicast](https://asciinema.org/a/243961.svg)](https://asciinema.org/a/243961)

## Capabilities

1.  Generate `tf`/`json` + `tfstate` files from existing infrastructure for all
    supported objects by resource.
2.  Remote state can be uploaded to a GCS bucket.
3.  Connect between resources with `terraform_remote_state` (local and bucket).
4.  Save `tf`/`json` files using a custom folder tree pattern.
5.  Import by resource name and type.
6.  Support terraform 0.13 (for terraform 0.11 use v0.7.9).

Terraformer uses Terraform providers and is designed to easily support newly added resources.
To upgrade resources with new fields, all you need to do is upgrade the relevant Terraform providers.
```
Import current state to Terraform configuration from a provider

Usage:
   import [provider] [flags]
   import [provider] [command]

Available Commands:
  list        List supported resources for a provider

Flags:
  -b, --bucket string         gs://terraform-state
  -c, --connect                (default true)
  -–°, --compact                (default false)
  -x, --excludes strings      firewalls,networks
  -f, --filter strings        compute_firewall=id1:id2:id4
  -h, --help                  help for google
  -O, --output string         output format hcl or json (default &quot;hcl&quot;)
  -o, --path-output string     (default &quot;generated&quot;)
  -p, --path-pattern string   {output}/{provider}/ (default &quot;{output}/{provider}/{service}/&quot;)
      --projects strings
  -z, --regions strings       europe-west1, (default [global])
  -r, --resources strings     firewall,networks or * for all services
  -s, --state string          local or bucket (default &quot;local&quot;)
  -v, --verbose               verbose mode
  -n, --retry-number          number of retries to perform if refresh fails
  -m, --retry-sleep-ms        time in ms to sleep between retries

Use &quot; import [provider] [command] --help&quot; for more information about a command.
```
#### Permissions

The tool requires read-only permissions to list service resources.

#### Resources

You can use `--resources` parameter to tell resources from what service you want to import.

To import resources from all services, use `--resources=&quot;*&quot;` . If you want to exclude certain services, you can combine the parameter with `--excludes` to exclude resources from services you don&#039;t want to import e.g. `--resources=&quot;*&quot; --excludes=&quot;iam&quot;`.

#### Filtering

Filters are a way to choose which resources `terraformer` imports. It&#039;s possible to filter resources by its identifiers or attributes. Multiple filtering values are separated by `:`. If an identifier contains this symbol, value should be wrapped in `&#039;` e.g. `--filter=resource=id1:&#039;project:dataset_id&#039;`. Identifier based filters will be executed before Terraformer will try to refresh remote state.

Use `Type` when you need to filter only one of several types of resources. Multiple filters can be combined when importing different resource types. An example would be importing all AWS security groups from a specific AWS VPC:
```
terraformer import aws -r sg,vpc --filter Type=sg;Name=vpc_id;Value=VPC_ID --filter Type=vpc;Name=id;Value=VPC_ID
```
Notice how the `Name` is different for `sg` than it is for `vpc`.

##### Migration state version
For terraform &gt;= 0.13, you can use `replace-provider` to migrate state from previous versions.

Example usage:
```
terraform state replace-provider -auto-approve &quot;registry.terraform.io/-/aws&quot; &quot;hashicorp/aws&quot;
```

##### Resource ID

Filtering is based on Terraform resource ID patterns. To find valid ID patterns for your resource, check the import part of the [Terraform documentation][terraform-providers].

[terraform-providers]: https://www.terraform.io/docs/providers/

Example usage:

```
terraformer import aws --resources=vpc,subnet --filter=vpc=myvpcid --regions=eu-west-1
```
Will only import the vpc with id `myvpcid`. This form of filters can help when it&#039;s necessary to select resources by its identifiers.

##### Field name only

It is possible to filter by specific field name only. It can be used e.g. when you want to retrieve resources only with a specific tag key.

Example usage:

```
terraformer import aws --resources=s3 --filter=&quot;Name=tags.Abc&quot; --regions=eu-west-1
```
Will only import the s3 resources that have tag `Abc`. This form of filters can help when the field values are not important from filtering perspective.

##### Field with dots

It is possible to filter by a field that contains a dot.

Example usage:

```
terraformer import aws --resources=s3 --filter=&quot;Name=tags.Abc.def&quot; --regions=eu-west-1
```
Will only import the s3 resources that have tag `Abc.def`.

#### Planning

The `plan` command generates a planfile that contains all the resources set to be imported. By modifying the planfile before running the `import` command, you can rename or filter the resources you&#039;d like to import.

The rest of subcommands and parameters are identical to the `import` command.

```
$ terraformer plan google --resources=networks,firewall --projects=my-project --regions=europe-west1-d
(snip)

Saving planfile to generated/google/my-project/terraformer/plan.json
```

After reviewing/customizing the planfile, begin the import by running `import plan`.

```
$ terraformer import plan generated/google/my-project/terraformer/plan.json
```

### Resource structure

Terraformer by default separates each resource into a file, which is put into a given service directory.

The default path for resource files is `{output}/{provider}/{service}/{resource}.tf` and can vary for each provider.

It&#039;s possible to adjust the generated structure by:
1. Using `--compact` parameter to group resource files within a single service into one `resources.tf` file
2. Adjusting the `--path-pattern` parameter and passing e.g. `--path-pattern {output}/{provider}/` to generate resources for all services in one directory

It&#039;s possible to combine `--compact` `--path-pattern` parameters together.

### Installation

Both Terraformer and a Terraform provider plugin need to be installed.

#### Terraformer

**From a package manager**
- [Homebrew](https://brew.sh/) users can use `brew install terraformer`.
- [MacPorts](https://www.macports.org/) users can use `sudo port install terraformer`.
- [Chocolatey](https://chocolatey.org/) users can use `choco install terraformer`.

**From releases**
This installs all providers, set `PROVIDER` to one of `google`, `aws` or `kubernetes` if you only need one.

* Linux
```
export PROVIDER=all
curl -LO &quot;https://github.com/GoogleCloudPlatform/terraformer/releases/download/$(curl -s https://api.github.com/repos/GoogleCloudPlatform/terraformer/releases/latest | grep tag_name | cut -d &#039;&quot;&#039; -f 4)/terraformer-${PROVIDER}-linux-amd64&quot;
chmod +x terraformer-${PROVIDER}-linux-amd64
sudo mv terraformer-${PROVIDER}-linux-amd64 /usr/local/bin/terraformer
```
* MacOS
```
export PROVIDER=all
curl -LO &quot;https://github.com/GoogleCloudPlatform/terraformer/releases/download/$(curl -s https://api.github.com/repos/GoogleCloudPlatform/terraformer/releases/latest | grep tag_name | cut -d &#039;&quot;&#039; -f 4)/terraformer-${PROVIDER}-darwin-amd64&quot;
chmod +x terraformer-${PROVIDER}-darwin-amd64
sudo mv terraformer-${PROVIDER}-darwin-amd64 /usr/local/bin/terraformer
```
* Windows
1. Install Terraform - https://www.terraform.io/downloads
2. Download exe file for required provider from here - https://github.com/GoogleCloudPlatform/terraformer/releases
3. Add the exe file path to path variable

**From source**
1.  Run `git clone &lt;terraformer repo&gt; &amp;&amp; cd terraformer/`
2.  Run `go mod download`
3.  Run `go build -v` for all providers OR build with one provider
`go run build/main.go {google,aws,azure,kubernetes,etc}`

#### Terraform Providers

Create a working folder and initialize the Terraform provider plugin.  This folder will be where you run Terraformer commands.

Run ```terraform init``` against a ```versions.tf``` file to install the plugins required for your platform. For example, if you need plugins for the google provider, ```versions.tf``` should contain:
```
terraform {
  required_providers {
    google = {
      source = &quot;hashicorp/google&quot;
    }
  }
  required_version = &quot;&gt;= 0.13&quot;
}
```

Or, copy your Terraform provider&#039;s plugin(s) from the list below to folder `~/.terraform.d/plugins/`, as appropriate.

Links to download Terraform provider plugins:
* Major Cloud
    * Google Cloud provider &gt;2.11.0 - [here](https://releases.hashicorp.com/terraform-provider-google/)
    * AWS provider &gt;2.25.0 - [here](https://releases.hashicorp.com/terraform-provider-aws/)
    * Azure provider &gt;1.35.0 - [here](https://releases.hashicorp.com/terraform-provider-azurerm/)
    * Alicloud provider &gt;1.57.1 - [here](https://releases.hashicorp.com/terraform-provider-alicloud/)
* Cloud
    * DigitalOcean provider &gt;1.9.1 - [here](https://releases.hashicorp.com/terraform-provider-digitalocean/)
    * Heroku provider &gt;2.2.1 - [here](https://releases.hashicorp.com/terraform-provider-heroku/)
    * LaunchDarkly provider &gt;=2.1.1 - [here](https://releases.hashicorp.com/terraform-provider-launchdarkly/)
    * Linode provider &gt;1.8.0 - [here](https://releases.hashicorp.com/terraform-provider-linode/)
    * OpenStack provider &gt;1.21.1 - [here](https://releases.hashicorp.com/terraform-provider-openstack/)
    * TencentCloud provider &gt;1.50.0 - [here](https://releases.hashicorp.com/terraform-provider-tencentcloud/)
    * Vultr provider &gt;1.0.5 - [here](https://releases.hashicorp.com/terraform-provider-vultr/)
    * Yandex provider &gt;0.42.0 - [here](https://releases.hashicorp.com/terraform-provider-yandex/)
    * Ionoscloud provider &gt;6.3.3 - [here](https://github.com/ionos-cloud/terraform-provider-ionoscloud/releases)
* Infrastructure Software
    * Kubernetes provider &gt;=1.9.0 - [here](https://releases.hashicorp.com/terraform-provider-kubernetes/)
    * RabbitMQ provider &gt;=1.1.0 - [here](https://releases.hashicorp.com/terraform-provider-rabbitmq/)
* Network
    * Myrasec provider &gt;1.44 - [here](https://github.com/Myra-Security-GmbH/terraform-provider-myrasec)
    * Cloudflare provider &gt;1.16 - [here](https://releases.hashicorp.com/terraform-provider-cloudflare/)
    * Fastly provider &gt;0.16.1 - [here](https://releases.hashicorp.com/terraform-provider-fastly/)
    * NS1 provider &gt;1.8.3 - [here](https://releases.hashicorp.com/terraform-provider-ns1/)
    * PAN-OS provider &gt;= 1.8.3 - [here](https://github.com/PaloAltoNetworks/terraform-provider-panos)
* VCS
    * GitHub provider &gt;=2.2.1 - [here](https://releases.hashicorp.com/terraform-provider-github/)
* Monitoring &amp; System Management
    * Datadog provider &gt;2.1.0 - [here](https://releases.hashicorp.com/terraform-provider-datadog/)
    * New Relic provider &gt;2.0.0 - [here](https://releases.hashicorp.com/terraform-provider-newrelic/)
    * Mackerel provider &gt; 0.0.6 - [here](https://github.com/mackerelio-labs/terraform-provider-mackerel)
    * Pagerduty &gt;=1.9 - [here](https://releases.hashicorp.com/terraform-provider-pagerduty/)
    * Opsgenie &gt;= 0.6.0 [here](https://releases.hashicorp.com/terraform-provider-opsgenie/)
    * Honeycomb.io &gt;= 0.10.0 - [here](https://github.com/honeycombio/terraform-provider-honeycombio/releases)
    * Opal &gt;= 0.0.2 - [here](https://github.com/opalsecurity/terraform-provider-opal/releases)
* Community
    * Keycloak provider &gt;=1.19.0 - [here](https://github.com/mrparkers/terraform-provider-keycloak/)
    * Logz.io provider &gt;=1.1.1 - [here](https://github.com/jonboydell/logzio_terraform_provider/)
    * Commercetools provider &gt;= 0.21.0 - [here](https://github.com/labd/terraform-provider-commercetools)
    * Mikrotik provider &gt;= 0.2.2 - [here](https://github.com/ddelnano/terraform-provider-mikrotik)
    * Xen Orchestra provider &gt;= 0.18.0 - [here](https://github.com/ddelnano/terraform-provider-xenorchestra)
    * GmailFilter provider &gt;= 1.0.1 - [here](https://github.com/yamamoto-febc/terraform-provider-gmailfilter)
    * Vault provider - [here](https://github.com/hashicorp/terraform-provider-vault)
    * Auth0 provider - [here](https://github.com/alexkappa/terraform-provider-auth0)
    * AzureAD provider - [here](https://github.com/hashicorp/terraform-provider-azuread)

Information on provider plugins:
https://www.terraform.io/docs/configuration/providers.html


## High-Level steps to add new provider
 * Initialize provider details in cmd/root.go and create a provider initialization file in the terraformer/cmd folder
 * Create a folder under terraformer/providers/ for your provider
 * Create two files under this folder
   * &lt;provide_name&gt;_provider.go
   * &lt;provide_name&gt;_service.go
* Initialize all provider&#039;s supported services in &lt;provide_name&gt;_provider.go file
* Create script for each supported service in same folder

## Contributing

If you have improvements or fixes, we would love to have your contributions.
Please read [CONTRIBUTING.md](./CONTRIBUTING.md) for more information on the process we would like
contributors to follow.

## Developing

Terraformer was built so you can easily add new providers of any kind.

Process for generating `tf`/`json` + `tfstate` files:

1.  Call GCP/AWS/other api and get list of resources.
2.  Iterate over resources and take only the ID (we don&#039;t need mapping fields!).
3.  Call to provider for readonly fields.
4.  Call to infrastructure and take tf + tfstate.

## Infrastructure

1.  Call to provider using the refresh method and get all data.
2.  Convert refresh data to go struct.
3.  Generate HCL file - `tf`/`json` files.
4.  Generate `tfstate` files.

All mapping of resource is made by providers and Terraform. Upgrades are needed only
for providers.

##### GCP compute resources

For GCP compute resources, use generated code from
`providers/gcp/gcp_compute_code_generator`.

To regenerate code:

```
go run providers/gcp/gcp_compute_code_generator/*.go
```

### Similar projects

#### [terraforming](https://github.com/dtan4/terraforming)

##### Terraformer Benefits

* Simpler to add new providers and resources - already supports AWS, GCP, GitHub, Kubernetes, and Openstack. Terraforming supports only AWS.
* Better support for HCL + tfstate, including updates for Terraform 0.12.
* If a provider adds new attributes to a resource, there is no need change Terraformer code - just update the Terraform provider on your laptop.
* Automatically supports connections between resources in HCL files.

##### Comparison

Terraforming gets all attributes from cloud APIs and creates HCL and tfstate files with templating. Each attribute in the API needs to map to attribute in Terraform. Generated files from templating can be broken with illegal syntax. When a provider adds new attributes the terraforming code needs to be updated.

Terraformer instead uses Terraform provider files for mapping attributes, HCL library from Hashicorp, and Terraform code.

Look for S3 support in terraforming here and official S3 support
Terraforming lacks full coverage for resources - as an example you can see that 70% of S3 options are not supported:

* terraforming - https://github.com/dtan4/terraforming/blob/master/lib/terraforming/template/tf/s3.erb
* official S3 support - https://www.terraform.io/docs/providers/aws/r/s3_bucket

## Stargazers over time

[![Stargazers over time](https://starchart.cc/GoogleCloudPlatform/terraformer.svg)](https://starchart.cc/GoogleCloudPlatform/terraformer)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[crossplane/crossplane]]></title>
            <link>https://github.com/crossplane/crossplane</link>
            <guid>https://github.com/crossplane/crossplane</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:39 GMT</pubDate>
            <description><![CDATA[The Cloud Native Control Plane]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/crossplane/crossplane">crossplane/crossplane</a></h1>
            <p>The Cloud Native Control Plane</p>
            <p>Language: Go</p>
            <p>Stars: 10,076</p>
            <p>Forks: 1,015</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/3260/badge)](https://www.bestpractices.dev/projects/3260) ![CI](https://github.com/crossplane/crossplane/workflows/CI/badge.svg) [![Go Report Card](https://goreportcard.com/badge/github.com/crossplane/crossplane)](https://goreportcard.com/report/github.com/crossplane/crossplane)

![Crossplane](banner.png)

Crossplane is a framework for building cloud native control planes without
needing to write code. It has a highly extensible backend that enables you to
build a control plane that can orchestrate applications and infrastructure no
matter where they run, and a highly configurable frontend that puts you in
control of the schema of the declarative API it offers.

Crossplane is a [Cloud Native Computing Foundation][cncf] project.

## Get Started

Crossplane&#039;s [Get Started Docs] cover install and cloud provider quickstarts.

## Releases

[![GitHub release](https://img.shields.io/github/release/crossplane/crossplane/all.svg)](https://github.com/crossplane/crossplane/releases) [![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/crossplane)](https://artifacthub.io/packages/helm/crossplane/crossplane)

Currently maintained releases, as well as the next few upcoming releases are
listed below. For more information take a look at the Crossplane [release cycle
documentation].

| Release | Release Date  |   EOL    |
|:-------:|:-------------:|:--------:|
|  v1.17  | Aug 29, 2024  | May 2025 |
|  v1.18  | Nov 5, 2024   | Aug 2025 |
|  v1.19  | Feb 11, 2025  | Nov 2025 |
|  v1.20  | Early May &#039;25 | Feb 2026 |
|  v1.21  | Early Aug &#039;25 | May 2026 |
|  v1.22  | Early Nov &#039;25 | Aug 2026 |

You can subscribe to the [community calendar] to track all release dates, and
find the most recent releases on the [releases] page.

## Roadmap

The public roadmap for Crossplane is published as a GitHub project board. Issues
added to the roadmap have been triaged and identified as valuable to the
community, and therefore a priority for the project that we expect to invest in.

The maintainer team regularly triages requests from the community to identify
features and issues of suitable scope and impact to include in this roadmap. The
community is encouraged to show their support for potential roadmap issues by
adding a :+1: reaction, leaving descriptive comments, and attending the
[regular community meetings] to discuss their requirements and use cases.

The maintainer team updates the roadmap on an as needed basis, in response to
demand, priority, and available resources. The public roadmap can be updated at
any time.

Milestones assigned to any issues in the roadmap are intended to give a sense of
overall priority and the expected order of delivery. They should be considered
approximate estimations and are **not** a strict commitment to a specific
delivery timeline.

[Crossplane Roadmap]

## Get Involved

[![Slack](https://img.shields.io/badge/slack-crossplane-red?logo=slack)](https://slack.crossplane.io) [![Bluesky Follow](https://img.shields.io/badge/bluesky-Follow-blue?logo=bluesky)](https://bsky.app/profile/crossplane.io) [![Twitter Follow](https://img.shields.io/twitter/follow/crossplane_io?logo=X&amp;label=Follow&amp;style=flat)](https://twitter.com/intent/follow?screen_name=crossplane_io&amp;user_id=788180534543339520) [![YouTube Channel Subscribers](https://img.shields.io/youtube/channel/subscribers/UC19FgzMBMqBro361HbE46Fw)](https://www.youtube.com/@Crossplane)

Crossplane is a community driven project; we welcome your contribution. To file
a bug, suggest an improvement, or request a new feature please open an [issue
against Crossplane] or the relevant provider. Refer to our [contributing guide]
for more information on how you can help.

* Discuss Crossplane on [Slack] or our [developer mailing list].
* Follow us on [Bluesky], [Twitter], or [LinkedIn], or subscribe to our [newsletter].
* Contact us via [Email].
* Join our regular community meetings.
* Provide feedback on our [roadmap and releases board].

The Crossplane community meeting takes place every 4 weeks on [Thursday at
10:00am Pacific Time][community meeting time]. You can find the up to date
meeting schedule on the [Community Calendar][community calendar].

Anyone who wants to discuss the direction of the project, design and
implementation reviews, or raise general questions with the broader community is
encouraged to join.

* Meeting link: &lt;https://zoom.us/j/425148449?pwd=NEk4N0tHWGpEazhuam1yR28yWHY5QT09&gt;
* [Current agenda and past meeting notes]
* [Past meeting recordings]
* [Community Calendar][community calendar]

### Special Interest Groups (SIG)

Each SIG collaborates in Slack and some groups have regular meetings, you can
find the meetings in the [Community Calendar][community calendar].
- [#sig-composition-environments][sig-composition-environments-slack]
- [#sig-composition-functions][sig-composition-functions-slack]
- [#sig-deletion-ordering][sig-deletion-ordering-slack]
- [#sig-devex][sig-devex-slack]
- [#sig-docs][sig-docs-slack]
- [#sig-e2e-testing][sig-e2e-testing-slack]
- [#sig-observability][sig-observability-slack]
- [#sig-observe-only][sig-observe-only-slack]
- [#sig-provider-families][sig-provider-families-slack]
- [#sig-secret-stores][sig-secret-stores-slack]
- [#sig-upjet][sig-upjet-slack]

## Adopters

A list of publicly known users of the Crossplane project can be found in [ADOPTERS.md].  We
encourage all users of Crossplane to add themselves to this list - we want to see the community&#039;s
growing success!

## License

Crossplane is under the Apache 2.0 license.

[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fcrossplane%2Fcrossplane.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Fcrossplane%2Fcrossplane?ref=badge_large)

&lt;!-- Named links --&gt;

[Crossplane]: https://crossplane.io
[release cycle documentation]: https://docs.crossplane.io/knowledge-base/guides/release-cycle
[install]: https://crossplane.io/docs/latest
[Slack]: https://slack.crossplane.io
[developer mailing list]: https://groups.google.com/forum/#!forum/crossplane-dev
[Bluesky]: https://bsky.app/profile/crossplane.io
[Twitter]: https://twitter.com/crossplane_io
[LinkedIn]: https://www.linkedin.com/company/crossplane/
[newsletter]: https://eepurl.com/ivy4v-/
[Email]: mailto:info@crossplane.io
[issue against Crossplane]: https://github.com/crossplane/crossplane/issues
[contributing guide]: contributing/README.md
[community meeting time]: https://www.thetimezoneconverter.com/?t=10:00&amp;tz=PT%20%28Pacific%20Time%29
[Current agenda and past meeting notes]: https://docs.google.com/document/d/1q_sp2jLQsDEOX7Yug6TPOv7Fwrys6EwcF5Itxjkno7Y/edit?usp=sharing
[Past meeting recordings]: https://www.youtube.com/playlist?list=PL510POnNVaaYYYDSICFSNWFqNbx1EMr-M
[roadmap and releases board]: https://github.com/orgs/crossplane/projects/20/views/9?pane=info
[cncf]: https://www.cncf.io/
[Get Started Docs]: https://docs.crossplane.io/latest/getting-started/
[community calendar]: https://calendar.google.com/calendar/embed?src=c_2cdn0hs9e2m05rrv1233cjoj1k%40group.calendar.google.com
[releases]: https://github.com/crossplane/crossplane/releases
[ADOPTERS.md]: ADOPTERS.md
[regular community meetings]: https://github.com/crossplane/crossplane/blob/main/README.md#get-involved
[Crossplane Roadmap]: https://github.com/orgs/crossplane/projects/20/views/9?pane=info
[sig-composition-environments-slack]: https://crossplane.slack.com/archives/C05BP6QFLUW
[sig-composition-functions-slack]: https://crossplane.slack.com/archives/C031Y29CSAE
[sig-deletion-ordering-slack]: https://crossplane.slack.com/archives/C05BP8W5ALW
[sig-devex-slack]: https://crossplane.slack.com/archives/C05U1LLM3B2
[sig-docs-slack]: https://crossplane.slack.com/archives/C02CAQ52DPU
[sig-e2e-testing-slack]: https://crossplane.slack.com/archives/C05C8CCTVNV
[sig-observability-slack]: https://crossplane.slack.com/archives/C061GNH3LA0
[sig-observe-only-slack]: https://crossplane.slack.com/archives/C04D5988QEA
[sig-provider-families-slack]: https://crossplane.slack.com/archives/C056YAQRV16
[sig-secret-stores-slack]: https://crossplane.slack.com/archives/C05BY7DKFV2
[sig-upjet-slack]: https://crossplane.slack.com/archives/C05T19TB729
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[minio/minio]]></title>
            <link>https://github.com/minio/minio</link>
            <guid>https://github.com/minio/minio</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:38 GMT</pubDate>
            <description><![CDATA[MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/minio/minio">minio/minio</a></h1>
            <p>MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.</p>
            <p>Language: Go</p>
            <p>Stars: 51,165</p>
            <p>Forks: 5,739</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre># MinIO Quickstart Guide

[![Slack](https://slack.min.io/slack?type=svg)](https://slack.min.io) [![Docker Pulls](https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800)](https://hub.docker.com/r/minio/minio/) [![license](https://img.shields.io/badge/license-AGPL%20V3-blue)](https://github.com/minio/minio/blob/master/LICENSE)

[![MinIO](https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true)](https://min.io)

MinIO is a High Performance Object Storage released under GNU Affero General Public License v3.0. It is API compatible with Amazon S3 cloud storage service. Use MinIO to build high performance infrastructure for machine learning, analytics and application data workloads. To learn more about what MinIO is doing for AI storage, go to [AI storage documentation](https://min.io/solutions/object-storage-for-ai).

This README provides quickstart instructions on running MinIO on bare metal hardware, including container-based installations. For Kubernetes environments, use the [MinIO Kubernetes Operator](https://github.com/minio/operator/blob/master/README.md).

## Container Installation

Use the following commands to run a standalone MinIO server as a container.

Standalone MinIO servers are best suited for early development and evaluation. Certain features such as versioning, object locking, and bucket replication
require distributed deploying MinIO with Erasure Coding. For extended development and production, deploy MinIO with Erasure Coding enabled - specifically,
with a *minimum* of 4 drives per MinIO server. See [MinIO Erasure Code Overview](https://min.io/docs/minio/linux/operations/concepts/erasure-coding.html)
for more complete documentation.

### Stable

Run the following command to run the latest stable image of MinIO as a container using an ephemeral data volume:

```sh
podman run -p 9000:9000 -p 9001:9001 \
  quay.io/minio/minio server /data --console-address &quot;:9001&quot;
```

The MinIO deployment starts using default root credentials `minioadmin:minioadmin`. You can test the deployment using the MinIO Console, an embedded
object browser built into MinIO Server. Point a web browser running on the host machine to &lt;http://127.0.0.1:9000&gt; and log in with the
root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.

You can also connect using any S3-compatible tool, such as the MinIO Client `mc` commandline tool. See
[Test using MinIO Client `mc`](#test-using-minio-client-mc) for more information on using the `mc` commandline tool. For application developers,
see &lt;https://min.io/docs/minio/linux/developers/minio-drivers.html&gt; to view MinIO SDKs for supported languages.

&gt; NOTE: To deploy MinIO on with persistent storage, you must map local persistent directories from the host OS to the container using the `podman -v` option. For example, `-v /mnt/data:/data` maps the host OS drive at `/mnt/data` to `/data` on the container.

## macOS

Use the following commands to run a standalone MinIO server on macOS.

Standalone MinIO servers are best suited for early development and evaluation. Certain features such as versioning, object locking, and bucket replication require distributed deploying MinIO with Erasure Coding. For extended development and production, deploy MinIO with Erasure Coding enabled - specifically, with a *minimum* of 4 drives per MinIO server. See [MinIO Erasure Code Overview](https://min.io/docs/minio/linux/operations/concepts/erasure-coding.html) for more complete documentation.

### Homebrew (recommended)

Run the following command to install the latest stable MinIO package using [Homebrew](https://brew.sh/). Replace ``/data`` with the path to the drive or directory in which you want MinIO to store data.

```sh
brew install minio/stable/minio
minio server /data
```

&gt; NOTE: If you previously installed minio using `brew install minio` then it is recommended that you reinstall minio from `minio/stable/minio` official repo instead.

```sh
brew uninstall minio
brew install minio/stable/minio
```

The MinIO deployment starts using default root credentials `minioadmin:minioadmin`. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;http://127.0.0.1:9000&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.

You can also connect using any S3-compatible tool, such as the MinIO Client `mc` commandline tool. See [Test using MinIO Client `mc`](#test-using-minio-client-mc) for more information on using the `mc` commandline tool. For application developers, see &lt;https://min.io/docs/minio/linux/developers/minio-drivers.html/&gt; to view MinIO SDKs for supported languages.

### Binary Download

Use the following command to download and run a standalone MinIO server on macOS. Replace ``/data`` with the path to the drive or directory in which you want MinIO to store data.

```sh
wget https://dl.min.io/server/minio/release/darwin-amd64/minio
chmod +x minio
./minio server /data
```

The MinIO deployment starts using default root credentials `minioadmin:minioadmin`. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;http://127.0.0.1:9000&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.

You can also connect using any S3-compatible tool, such as the MinIO Client `mc` commandline tool. See [Test using MinIO Client `mc`](#test-using-minio-client-mc) for more information on using the `mc` commandline tool. For application developers, see &lt;https://min.io/docs/minio/linux/developers/minio-drivers.html&gt; to view MinIO SDKs for supported languages.

## GNU/Linux

Use the following command to run a standalone MinIO server on Linux hosts running 64-bit Intel/AMD architectures. Replace ``/data`` with the path to the drive or directory in which you want MinIO to store data.

```sh
wget https://dl.min.io/server/minio/release/linux-amd64/minio
chmod +x minio
./minio server /data
```

The following table lists supported architectures. Replace the `wget` URL with the architecture for your Linux host.

| Architecture                   | URL                                                        |
| --------                       | ------                                                     |
| 64-bit Intel/AMD               | &lt;https://dl.min.io/server/minio/release/linux-amd64/minio&gt;   |
| 64-bit ARM                     | &lt;https://dl.min.io/server/minio/release/linux-arm64/minio&gt;   |
| 64-bit PowerPC LE (ppc64le)    | &lt;https://dl.min.io/server/minio/release/linux-ppc64le/minio&gt; |

The MinIO deployment starts using default root credentials `minioadmin:minioadmin`. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;http://127.0.0.1:9000&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.

You can also connect using any S3-compatible tool, such as the MinIO Client `mc` commandline tool. See [Test using MinIO Client `mc`](#test-using-minio-client-mc) for more information on using the `mc` commandline tool. For application developers, see &lt;https://min.io/docs/minio/linux/developers/minio-drivers.html&gt; to view MinIO SDKs for supported languages.

&gt; NOTE: Standalone MinIO servers are best suited for early development and evaluation. Certain features such as versioning, object locking, and bucket replication require distributed deploying MinIO with Erasure Coding. For extended development and production, deploy MinIO with Erasure Coding enabled - specifically, with a *minimum* of 4 drives per MinIO server. See [MinIO Erasure Code Overview](https://min.io/docs/minio/linux/operations/concepts/erasure-coding.html#) for more complete documentation.

## Microsoft Windows

To run MinIO on 64-bit Windows hosts, download the MinIO executable from the following URL:

```sh
https://dl.min.io/server/minio/release/windows-amd64/minio.exe
```

Use the following command to run a standalone MinIO server on the Windows host. Replace ``D:\`` with the path to the drive or directory in which you want MinIO to store data. You must change the terminal or powershell directory to the location of the ``minio.exe`` executable, *or* add the path to that directory to the system ``$PATH``:

```sh
minio.exe server D:\
```

The MinIO deployment starts using default root credentials `minioadmin:minioadmin`. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;http://127.0.0.1:9000&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.

You can also connect using any S3-compatible tool, such as the MinIO Client `mc` commandline tool. See [Test using MinIO Client `mc`](#test-using-minio-client-mc) for more information on using the `mc` commandline tool. For application developers, see &lt;https://min.io/docs/minio/linux/developers/minio-drivers.html&gt; to view MinIO SDKs for supported languages.

&gt; NOTE: Standalone MinIO servers are best suited for early development and evaluation. Certain features such as versioning, object locking, and bucket replication require distributed deploying MinIO with Erasure Coding. For extended development and production, deploy MinIO with Erasure Coding enabled - specifically, with a *minimum* of 4 drives per MinIO server. See [MinIO Erasure Code Overview](https://min.io/docs/minio/linux/operations/concepts/erasure-coding.html#) for more complete documentation.

## Install from Source

Use the following commands to compile and run a standalone MinIO server from source. Source installation is only intended for developers and advanced users. If you do not have a working Golang environment, please follow [How to install Golang](https://golang.org/doc/install). Minimum version required is [go1.21](https://golang.org/dl/#stable)

```sh
go install github.com/minio/minio@latest
```

The MinIO deployment starts using default root credentials `minioadmin:minioadmin`. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;http://127.0.0.1:9000&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.

You can also connect using any S3-compatible tool, such as the MinIO Client `mc` commandline tool. See [Test using MinIO Client `mc`](#test-using-minio-client-mc) for more information on using the `mc` commandline tool. For application developers, see &lt;https://min.io/docs/minio/linux/developers/minio-drivers.html&gt; to view MinIO SDKs for supported languages.

&gt; NOTE: Standalone MinIO servers are best suited for early development and evaluation. Certain features such as versioning, object locking, and bucket replication require distributed deploying MinIO with Erasure Coding. For extended development and production, deploy MinIO with Erasure Coding enabled - specifically, with a *minimum* of 4 drives per MinIO server. See [MinIO Erasure Code Overview](https://min.io/docs/minio/linux/operations/concepts/erasure-coding.html) for more complete documentation.

MinIO strongly recommends *against* using compiled-from-source MinIO servers for production environments.

## Deployment Recommendations

### Allow port access for Firewalls

By default MinIO uses the port 9000 to listen for incoming connections. If your platform blocks the port by default, you may need to enable access to the port.

### ufw

For hosts with ufw enabled (Debian based distros), you can use `ufw` command to allow traffic to specific ports. Use below command to allow access to port 9000

```sh
ufw allow 9000
```

Below command enables all incoming traffic to ports ranging from 9000 to 9010.

```sh
ufw allow 9000:9010/tcp
```

### firewall-cmd

For hosts with firewall-cmd enabled (CentOS), you can use `firewall-cmd` command to allow traffic to specific ports. Use below commands to allow access to port 9000

```sh
firewall-cmd --get-active-zones
```

This command gets the active zone(s). Now, apply port rules to the relevant zones returned above. For example if the zone is `public`, use

```sh
firewall-cmd --zone=public --add-port=9000/tcp --permanent
```

Note that `permanent` makes sure the rules are persistent across firewall start, restart or reload. Finally reload the firewall for changes to take effect.

```sh
firewall-cmd --reload
```

### iptables

For hosts with iptables enabled (RHEL, CentOS, etc), you can use `iptables` command to enable all traffic coming to specific ports. Use below command to allow
access to port 9000

```sh
iptables -A INPUT -p tcp --dport 9000 -j ACCEPT
service iptables restart
```

Below command enables all incoming traffic to ports ranging from 9000 to 9010.

```sh
iptables -A INPUT -p tcp --dport 9000:9010 -j ACCEPT
service iptables restart
```

## Test MinIO Connectivity

### Test using MinIO Console

MinIO Server comes with an embedded web based object browser. Point your web browser to &lt;http://127.0.0.1:9000&gt; to ensure your server has started successfully.

&gt; NOTE: MinIO runs console on random port by default, if you wish to choose a specific port use `--console-address` to pick a specific interface and port.

### Things to consider

MinIO redirects browser access requests to the configured server port (i.e. `127.0.0.1:9000`) to the configured Console port. MinIO uses the hostname or IP address specified in the request when building the redirect URL. The URL and port *must* be accessible by the client for the redirection to work.

For deployments behind a load balancer, proxy, or ingress rule where the MinIO host IP address or port is not public, use the `MINIO_BROWSER_REDIRECT_URL` environment variable to specify the external hostname for the redirect. The LB/Proxy must have rules for directing traffic to the Console port specifically.

For example, consider a MinIO deployment behind a proxy `https://minio.example.net`, `https://console.minio.example.net` with rules for forwarding traffic on port :9000 and :9001 to MinIO and the MinIO Console respectively on the internal network. Set `MINIO_BROWSER_REDIRECT_URL` to `https://console.minio.example.net` to ensure the browser receives a valid reachable URL.

| Dashboard                                                                                   | Creating a bucket                                                                           |
| -------------                                                                               | -------------                                                                               |
| ![Dashboard](https://github.com/minio/minio/blob/master/docs/screenshots/pic1.png?raw=true) | ![Dashboard](https://github.com/minio/minio/blob/master/docs/screenshots/pic2.png?raw=true) |

## Test using MinIO Client `mc`

`mc` provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services. Follow the MinIO Client [Quickstart Guide](https://min.io/docs/minio/linux/reference/minio-mc.html#quickstart) for further instructions.

## Upgrading MinIO

Upgrades require zero downtime in MinIO, all upgrades are non-disruptive, all transactions on MinIO are atomic. So upgrading all the servers simultaneously is the recommended way to upgrade MinIO.

&gt; NOTE: requires internet access to update directly from &lt;https://dl.min.io&gt;, optionally you can host any mirrors at &lt;https://my-artifactory.example.com/minio/&gt;

- For deployments that installed the MinIO server binary by hand, use [`mc admin update`](https://min.io/docs/minio/linux/reference/minio-mc-admin/mc-admin-update.html)

```sh
mc admin update &lt;minio alias, e.g., myminio&gt;
```

- For deployments without external internet access (e.g. airgapped environments), download the binary from &lt;https://dl.min.io&gt; and replace the existing MinIO binary let&#039;s say for example `/opt/bin/minio`, apply executable permissions `chmod +x /opt/bin/minio` and proceed to perform `mc admin service restart alias/`.

- For installations using Systemd MinIO service, upgrade via RPM/DEB packages **parallelly** on all servers or replace the binary lets say `/opt/bin/minio` on all nodes, apply executable permissions `chmod +x /opt/bin/minio` and process to perform `mc admin service restart alias/`.

### Upgrade Checklist

- Test all upgrades in a lower environment (DEV, QA, UAT) before applying to production. Performing blind upgrades in production environments carries significant risk.
- Read the release notes for MinIO *before* performing any upgrade, there is no forced requirement to upgrade to latest release upon every release. Some release may not be relevant to your setup, avoid upgrading production environments unnecessarily.
- If you plan to use `mc admin update`, MinIO process must have write access to the parent directory where the binary is present on the host system.
- `mc admin update` is not supported and should be avoided in kubernetes/container environments, please upgrade containers by upgrading relevant container images.
- **We do not recommend upgrading one MinIO server at a time, the product is designed to support parallel upgrades please follow our recommended guidelines.**

## Explore Further

- [MinIO Erasure Code Overview](https://min.io/docs/minio/linux/operations/concepts/erasure-coding.html)
- [Use `mc` with MinIO Server](https://min.io/docs/minio/linux/reference/minio-mc.html)
- [Use `minio-go` SDK with MinIO Server](https://min.io/docs/minio/linux/developers/go/minio-go.html)
- [The MinIO documentation website](https://min.io/docs/minio/linux/index.html)

## Contribute to MinIO Project

Please follow MinIO [Contributor&#039;s Guide](https://github.com/minio/minio/blob/master/CONTRIBUTING.md)

## License

- MinIO source is licensed under the [GNU AGPLv3](https://github.com/minio/minio/blob/master/LICENSE).
- MinIO [documentation](https://github.com/minio/minio/tree/master/docs) is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).
- [License Compliance](https://github.com/minio/minio/blob/master/COMPLIANCE.md)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grpc-ecosystem/grpc-gateway]]></title>
            <link>https://github.com/grpc-ecosystem/grpc-gateway</link>
            <guid>https://github.com/grpc-ecosystem/grpc-gateway</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[gRPC to JSON proxy generator following the gRPC HTTP spec]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grpc-ecosystem/grpc-gateway">grpc-ecosystem/grpc-gateway</a></h1>
            <p>gRPC to JSON proxy generator following the gRPC HTTP spec</p>
            <p>Language: Go</p>
            <p>Stars: 19,097</p>
            <p>Forks: 2,302</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;h1&gt;gRPC-Gateway&lt;/h1&gt;
&lt;p&gt;
gRPC to JSON proxy generator following the gRPC HTTP spec
&lt;/p&gt;
&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/actions/workflows/main.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/workflow/status/grpc-ecosystem/grpc-gateway/main?color=379c9c&amp;label=build&amp;logo=github&amp;logoColor=ffffff&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://app.slack.com/client/T029RQSE6/CBATURP1D&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/slack-grpc--gateway-379c9c?logo=slack&amp;logoColor=ffffff&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/grpc-ecosystem/grpc-gateway?color=379c9c&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/grpc-ecosystem/grpc-gateway?color=379c9c&amp;logoColor=ffffff&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/grpc-ecosystem/grpc-gateway?color=379c9c&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://slsa.dev/images/gh-badge-level3.svg&quot;&gt;&lt;img src=&quot;https://slsa.dev/images/gh-badge-level3.svg&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

## About

The gRPC-Gateway is a plugin of the Google protocol buffers compiler
[protoc](https://github.com/protocolbuffers/protobuf).
It reads protobuf service definitions and generates a reverse-proxy server which
translates a RESTful HTTP API into gRPC. This server is generated according to the
[`google.api.http`](https://github.com/googleapis/googleapis/blob/master/google/api/http.proto#L46)
annotations in your service definitions.

This helps you provide your APIs in both gRPC and RESTful style at the same time.

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;docs/assets/images/architecture_introduction_diagram.svg&quot; /&gt;
&lt;/div&gt;

## Docs

You can read our docs at:

- https://grpc-ecosystem.github.io/grpc-gateway/

## Testimonials

&gt; We use the gRPC-Gateway to serve millions of API requests per day,
&gt; and have been since 2018 and through all of that,
&gt; we have never had any issues with it.
&gt;
&gt; _- William Mill, [Ad Hoc](http://adhocteam.us/)_

## Background

gRPC is great -- it generates API clients and server stubs in many programming
languages, it is fast, easy-to-use, bandwidth-efficient and its design is
combat-proven by Google. However, you might still want to provide a traditional
RESTful JSON API as well. Reasons can range from maintaining
backward-compatibility, supporting languages or clients that are not well supported by
gRPC, to simply maintaining the aesthetics and tooling involved with a RESTful
JSON architecture.

This project aims to provide that HTTP+JSON interface to your gRPC service.
A small amount of configuration in your service to attach HTTP semantics is all
that&#039;s needed to generate a reverse-proxy with this library.

## Installation

### Compile from source

The following instructions assume you are using
[Go Modules](https://go.dev/wiki/Modules) for dependency
management. Use a
[tool dependency](https://go.dev/wiki/Modules#how-can-i-track-tool-dependencies-for-a-module)
to track the versions of the following executable packages:

```go
// +build tools

package tools

import (
    _ &quot;github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway&quot;
    _ &quot;github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2&quot;
    _ &quot;google.golang.org/grpc/cmd/protoc-gen-go-grpc&quot;
    _ &quot;google.golang.org/protobuf/cmd/protoc-gen-go&quot;
)
```

Run `go mod tidy` to resolve the versions. Install by running

```sh
go install \
    github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway \
    github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2 \
    google.golang.org/protobuf/cmd/protoc-gen-go \
    google.golang.org/grpc/cmd/protoc-gen-go-grpc
```

This will place four binaries in your `$GOBIN`;

- `protoc-gen-grpc-gateway`
- `protoc-gen-openapiv2`
- `protoc-gen-go`
- `protoc-gen-go-grpc`

Make sure that your `$GOBIN` is in your `$PATH`.

### **Using the `tool` Directive in Go 1.24**

Starting from Go 1.24, the `tool` directive in `go.mod` provides a structured way to track and manage executable dependencies. This replaces the previous workaround of using a separate `tools.go` file with blank imports.

#### **Tracking Tools in `go.mod`**

Instead of manually importing tool dependencies in a Go source file, you can now use the `tool` directive in `go.mod` to declare the tools your project depends on. For example:

```go
module tools

go 1.24

tool (
	github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway
	github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2
	google.golang.org/grpc/cmd/protoc-gen-go-grpc
	google.golang.org/protobuf/cmd/protoc-gen-go
)
```

#### **Managing Tool Dependencies**

To add tools to your module, use the `-tool` flag with `go get`:

```sh
go get -tool github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway
go get -tool github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2
go get -tool google.golang.org/protobuf/cmd/protoc-gen-go
go get -tool google.golang.org/grpc/cmd/protoc-gen-go-grpc
```

This automatically updates `go.mod`, adding the tools under the `tool` directive along with `require` statements to ensure version tracking.

### Install Tools

Once the tool dependencies are properly recorded in the `go.mod` file, simply execute the following command in the root directory of your project:

```sh
go install ./...
```

### Download the binaries

You may alternatively download the binaries from the [GitHub releases page](https://github.com/grpc-ecosystem/grpc-gateway/releases/latest).
We generate [SLSA3 signatures](slsa.dev) using the OpenSSF&#039;s [slsa-framework/slsa-github-generator](https://github.com/slsa-framework/slsa-github-generator) during the release process. To verify a release binary:

1. Install the verification tool from [slsa-framework/slsa-verifier#installation](https://github.com/slsa-framework/slsa-verifier#installation).
2. Download the provenance file `attestation.intoto.jsonl` from the [GitHub releases page](https://github.com/grpc-ecosystem/grpc-gateway/releases/latest).
3. Run the verifier:

```shell
slsa-verifier -artifact-path &lt;the-binary&gt; -provenance attestation.intoto.jsonl -source github.com/grpc-ecosystem/grpc-gateway -tag &lt;the-tag&gt;
```

Alternatively, see the section on remotely managed plugin versions below.

## Usage

### 1.Define your [gRPC](https://grpc.io/docs/) service using protocol buffers

`your_service.proto`:

```protobuf
 syntax = &quot;proto3&quot;;
 package your.service.v1;
 option go_package = &quot;github.com/yourorg/yourprotos/gen/go/your/service/v1&quot;;

 message StringMessage {
   string value = 1;
 }

 service YourService {
   rpc Echo(StringMessage) returns (StringMessage) {}
 }
```

### 2. Generate gRPC stubs

This step generates the gRPC stubs that you can use to implement the service and consume from clients:

Here&#039;s an example `buf.gen.yaml` you can use to generate the stubs with [buf](https://github.com/bufbuild/buf):

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
```

With this file in place, you can generate your files using `buf generate`.

&gt; For a complete example of using `buf generate` to generate protobuf stubs, see
&gt; [the boilerplate repo](https://github.com/johanbrandhorst/grpc-gateway-boilerplate).
&gt; For more information on generating the stubs with buf, see
&gt; [the official documentation](https://docs.buf.build/generate-usage).

If you are using `protoc` to generate stubs, here&#039;s an example of what a command
might look like:

```sh
protoc -I . \
    --go_out ./gen/go/ --go_opt paths=source_relative \
    --go-grpc_out ./gen/go/ --go-grpc_opt paths=source_relative \
    your/service/v1/your_service.proto
```

### 3. Implement your service in gRPC as usual.

### 4. Generate reverse-proxy using `protoc-gen-grpc-gateway`

At this point, you have 3 options:

- no further modifications, use the default mapping to HTTP semantics (method, path, etc.)
  - this will work on any `.proto` file, but will not allow setting HTTP paths, request parameters or similar
- additional `.proto` modifications to use a custom mapping
  - relies on parameters in the `.proto` file to set custom HTTP mappings
- no `.proto` modifications, but use an external configuration file
  - relies on an external configuration file to set custom HTTP mappings
  - mostly useful when the source proto file isn&#039;t under your control

#### 1. Using the default mapping

This requires no additional modification to the `.proto` file but does require enabling a specific option when executing the plugin.
The `generate_unbound_methods` should be enabled.

Here&#039;s what a `buf.gen.yaml` file might look like with this option enabled:

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - generate_unbound_methods=true
```

With `protoc` (just the grpc-gateway stubs):

```sh
protoc -I . --grpc-gateway_out ./gen/go \
    --grpc-gateway_opt paths=source_relative \
    --grpc-gateway_opt generate_unbound_methods=true \
    your/service/v1/your_service.proto
```

#### 2. With custom annotations

Add a [`google.api.http`](https://github.com/googleapis/googleapis/blob/master/google/api/http.proto#L46)
annotation to your .proto file

`your_service.proto`:

```diff
 syntax = &quot;proto3&quot;;
 package your.service.v1;
 option go_package = &quot;github.com/yourorg/yourprotos/gen/go/your/service/v1&quot;;
+
+import &quot;google/api/annotations.proto&quot;;
+
 message StringMessage {
   string value = 1;
 }

 service YourService {
-  rpc Echo(StringMessage) returns (StringMessage) {}
+  rpc Echo(StringMessage) returns (StringMessage) {
+    option (google.api.http) = {
+      post: &quot;/v1/example/echo&quot;
+      body: &quot;*&quot;
+    };
+  }
 }
```

&gt; You will need to provide the required third party protobuf files to the protobuf compiler.
&gt; If you are using [buf](https://github.com/bufbuild/buf), this dependency can
&gt; be added to the `deps` array in your `buf.yaml` under the name
&gt; `buf.build/googleapis/googleapis`:
&gt;
&gt; ```yaml
&gt; version: v2
&gt; name: buf.build/yourorg/myprotos
&gt; deps:
&gt;   - buf.build/googleapis/googleapis
&gt; ```
&gt;
&gt; Always run `buf dep update` after adding a dependency to your `buf.yaml`.

See [a_bit_of_everything.proto](examples/internal/proto/examplepb/a_bit_of_everything.proto)
for examples of more annotations you can add to customize gateway behavior
and generated OpenAPI output.

Here&#039;s what a `buf.gen.yaml` file might look like:

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
```

If you are using `protoc` to generate stubs, you need to ensure the required
dependencies are available to the compiler at compile time. These can be found
by manually cloning and copying the relevant files from the
[googleapis repository](https://github.com/googleapis/googleapis), and providing
them to `protoc` when running. The files you will need are:

```
google/api/annotations.proto
google/api/field_behavior.proto
google/api/http.proto
google/api/httpbody.proto
```

Here&#039;s what a `protoc` execution might look like:

```sh
protoc -I . --grpc-gateway_out ./gen/go \
    --grpc-gateway_opt paths=source_relative \
    your/service/v1/your_service.proto
```

#### 3. External configuration

If you do not want to (or cannot) modify the proto file for use with gRPC-Gateway you can
alternatively use an external
[gRPC Service Configuration](https://cloud.google.com/endpoints/docs/grpc/grpc-service-config) file.
[Check our documentation](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/grpc_api_configuration/)
for more information. This is best combined with the `standalone=true` option
to generate a file that can live in its own package, separate from the files
generated by the source protobuf file.

Here&#039;s what a `buf.gen.yaml` file might look like with this option enabled:

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - grpc_api_configuration=path/to/config.yaml
      - standalone=true
```

With `protoc` (just the grpc-gateway stubs):

```sh
protoc -I . --grpc-gateway_out ./gen/go \
    --grpc-gateway_opt paths=source_relative \
    --grpc-gateway_opt grpc_api_configuration=path/to/config.yaml \
    --grpc-gateway_opt standalone=true \
    your/service/v1/your_service.proto
```

### 5. Write an entrypoint for the HTTP reverse-proxy server

```go
package main

import (
  &quot;context&quot;
  &quot;flag&quot;
  &quot;net/http&quot;

  &quot;github.com/grpc-ecosystem/grpc-gateway/v2/runtime&quot;
  &quot;google.golang.org/grpc&quot;
  &quot;google.golang.org/grpc/credentials/insecure&quot;
  &quot;google.golang.org/grpc/grpclog&quot;

  gw &quot;github.com/yourorg/yourrepo/proto/gen/go/your/service/v1/your_service&quot;  // Update
)

var (
  // command-line options:
  // gRPC server endpoint
  grpcServerEndpoint = flag.String(&quot;grpc-server-endpoint&quot;,  &quot;localhost:9090&quot;, &quot;gRPC server endpoint&quot;)
)

func run() error {
  ctx := context.Background()
  ctx, cancel := context.WithCancel(ctx)
  defer cancel()

  // Register gRPC server endpoint
  // Note: Make sure the gRPC server is running properly and accessible
  mux := runtime.NewServeMux()
  opts := []grpc.DialOption{grpc.WithTransportCredentials(insecure.NewCredentials())}
  err := gw.RegisterYourServiceHandlerFromEndpoint(ctx, mux,  *grpcServerEndpoint, opts)
  if err != nil {
    return err
  }

  // Start HTTP server (and proxy calls to gRPC server endpoint)
  return http.ListenAndServe(&quot;:8081&quot;, mux)
}

func main() {
  flag.Parse()

  if err := run(); err != nil {
    grpclog.Fatal(err)
  }
}
```

### 6. (Optional) Generate OpenAPI definitions using `protoc-gen-openapiv2`

Here&#039;s what a `buf.gen.yaml` file might look like:

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - generate_unbound_methods=true
  - local: protoc-gen-openapiv2
    out: gen/go
```

To use the custom protobuf annotations supported by `protoc-gen-openapiv2`, we need
another dependency added to our protobuf generation step. If you are using
`buf`, you can add the `buf.build/grpc-ecosystem/grpc-gateway` dependency
to your `deps` array:

```yaml
version: v2
name: buf.build/yourorg/myprotos
deps:
  - buf.build/googleapis/googleapis
  - buf.build/grpc-ecosystem/grpc-gateway
```

With `protoc` (just the swagger file):

```sh
protoc -I . --openapiv2_out ./gen/openapiv2 \
    your/service/v1/your_service.proto
```

If you are using `protoc` to generate stubs, you will need to copy the protobuf
files from the `protoc-gen-openapiv2/options` directory of this repository,
and providing them to `protoc` when running.

Note that this plugin also supports generating OpenAPI definitions for unannotated methods;
use the `generate_unbound_methods` option to enable this.

It is possible with the HTTP mapping for a gRPC service method to create duplicate mappings
with the only difference being constraints on the path parameter.

`/v1/{name=projects/*}` and `/v1/{name=organizations/*}` both become `/v1/{name}`. When
this occurs the plugin will rename the path parameter with a &quot;\_1&quot; (or &quot;\_2&quot; etc) suffix
to differentiate the different operations. So in the above example, the 2nd path would become
`/v1/{name_1=organizations/*}`. This can also cause OpenAPI clients to URL encode the &quot;/&quot; that is
part of the path parameter as that is what OpenAPI defines in the specification. To allow gRPC gateway to
accept the URL encoded slash and still route the request, use the UnescapingModeAllCharacters or
UnescapingModeLegacy (which is the default currently though may change in future versions). See
[Customizing Your Gateway](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/customizing_your_gateway/)
for more information.

## Usage with remote plugins

As an alternative to all of the above, you can use `buf` with
[remote plugins](https://buf.build/docs/bsr/remote-plugins/usage)
to manage plugin versions and generation. An example `buf.gen.yaml` using remote
plugin generation looks like this:

```yaml
version: v2
plugins:
  - remote: buf.build/protocolbuffers/go:v1.31.0
    out: gen/go
    opt:
      - paths=source_relative
  - remote: buf.build/grpc/go:v1.3.0
    out: gen/go
    opt:
      - paths=source_relative
  - remote: buf.build/grpc-ecosystem/gateway:v2.16.2
    out: gen/go
    opt:
      - paths=source_relative
  - remote: buf.build/grpc-ecosystem/openapiv2:v2.16.2
    out: gen/openapiv2
```

This requires no local installation of any plugins. Be careful to use the same
version of the generator as the runtime library, i.e. if using `v2.16.2`, run

```shell
$ go get github.com/grpc-ecosystem/grpc-gateway/v2@v2.16.2
```

To get the same version of the runtime in your `go.mod`.

Note that usage of remote plugins is incompatible with usage of external configuration files like [grpc_api_configuration](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/grpc_api_configuration/#using-an-external-configuration-file).

## Video intro

This GopherCon UK 2019 presentation from our maintainer [@JohanBrandhorst](https://github.com/johanbrandhorst) provides a good intro to using the gRPC-Gateway. It uses the following boilerplate repo as a base: https://github.com/johanbrandhorst/grpc-gateway-boilerplate.

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.youtube.com/watch?v=Pq1paKC-fXk&quot;&gt;
&lt;img src=&quot;https://img.youtube.com/vi/Pq1paKC-fXk/0.jpg&quot; /&gt;
&lt;/a&gt;
&lt;/div&gt;

## Parameters and flags

When using `buf` to generate stubs, flags and parameters are passed through
the `opt` field in your `buf.gen.yaml` file, for example:

```yaml
version: v2
plugins:
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - grpc_api_configuration=path/to/config.yaml
      - standalone=true
```

During code generation with `protoc`, flags to gRPC-Gateway tools must be passed
through `protoc` using one of 2 patterns:

- as part of the `--&lt;tool_suffix&gt;_out` `protoc` parameter: `--&lt;tool_suffix&gt;_out=&lt;flags&gt;:&lt;path&gt;`

```sh
--grpc-gateway_out=repeated_path_param_separator=ssv:.
--openapiv2_out=repeated_path_param_separator=ssv:.
```

- using additional `--&lt;tool_suffix&gt;_opt` parameters: `--&lt;tool_suffix&gt;_opt=&lt;flag&gt;[,&lt;flag&gt;]*`

```sh
--grpc-gateway_opt repeated_path_param_separator=ssv
--openapiv2_opt repeated_path_param_separator=ssv
```

## More examples

More examples are available under the `examples` directory.

- `proto/examplepb/echo_service.proto`, `proto/examplepb/a_bit_of_everything.proto`, `proto/examplepb/unannotated_echo_service.proto`: service definition
  - `proto/examplepb/echo_service.pb.go`, `proto/examplepb/a_bit_of_everything.pb.go`, `proto/examplepb/unannotated_echo_service.pb.go`: [generated] stub of the service
  - `proto/examplepb/echo_service.pb.gw.go`, `proto/examplepb/a_bit_of_everything.pb.gw.go`, `proto/examplepb/uannotated_echo_service.pb.gw.go`: [generated] reverse proxy for the service
  - `proto/examplepb/unannotated_echo_service.yaml`: gRPC API Configuration for `unannotated_echo_service.proto`
- `server/main.go`: service implementation
- `main.go`:

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[asdf-vm/asdf]]></title>
            <link>https://github.com/asdf-vm/asdf</link>
            <guid>https://github.com/asdf-vm/asdf</guid>
            <pubDate>Sat, 29 Mar 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[Extendable version manager with support for Ruby, Node.js, Elixir, Erlang & more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/asdf-vm/asdf">asdf-vm/asdf</a></h1>
            <p>Extendable version manager with support for Ruby, Node.js, Elixir, Erlang & more</p>
            <p>Language: Go</p>
            <p>Stars: 23,226</p>
            <p>Forks: 851</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># asdf

[![Lint](https://github.com/asdf-vm/asdf/actions/workflows/lint.yml/badge.svg)](https://github.com/asdf-vm/asdf/actions/workflows/lint.yml) [![Tests](https://github.com/asdf-vm/asdf/actions/workflows/tests.yml/badge.svg)](https://github.com/asdf-vm/asdf/actions/workflows/tests.yml)

**Manage multiple runtime versions with a single CLI tool, extendable via plugins** - [docs at asdf-vm.com](https://asdf-vm.com/)

asdf is a CLI tool that can manage multiple language runtime versions on a per-project basis. It is like `gvm`, `nvm`, `rbenv` &amp; `pyenv` (and more) all in one! Simply install your language&#039;s plugin!

## Why use asdf?

- single CLI for multiple languages
- consistent commands to manage all your languages
- single global config keeping defaults in one place
- single `.tool-versions` config file per project
- support for existing config files `.node-version`, `.nvmrc`, `.ruby-version` for easy migration
- automatically switches runtime versions as you traverse your directories
- simple plugin system to add support for your language of choice
- shell completion available for common shells (Bash, Zsh, Fish, Elvish)

## Documentation

[Please head over to the documentation site for more information](https://asdf-vm.com/)!

- [Getting Started](https://asdf-vm.com/guide/getting-started.html)
- [All Commands](https://asdf-vm.com/manage/commands.html)
- [All Plugins](https://github.com/asdf-vm/asdf-plugins)
- [Create a Plugin](https://asdf-vm.com/plugins/create.html) with our [asdf-plugin-template](https://github.com/asdf-vm/asdf-plugin-template)
- [asdf GitHub Actions](https://github.com/asdf-vm/actions)

## Contributing

See [CONTRIBUTING.md in the repo](https://github.com/asdf-vm/asdf/blob/master/CONTRIBUTING.md) or the [Contributing section on the docs site](http://asdf-vm.com/contribute/core.html#initial-setup).

## Community &amp; Questions

- [FAQ](https://asdf-vm.com/more/faq.html)
- [![GitHub Issues](https://icongr.am/simple/github.svg?color=808080&amp;size=16) GitHub Issues](https://github.com/asdf-vm/asdf/issues): report a bug or raise a feature request to the `asdf` core team
- [![StackOverflow Tag](https://icongr.am/fontawesome/stack-overflow.svg?size=16&amp;color=808080) StackOverflow Tag](https://stackoverflow.com/questions/tagged/asdf-vm): see existing Q&amp;A for `asdf`. Some of the core team watch this tag in addition to our helpful community

## Ballad of asdf

&gt; Once upon a time there was a programming language&lt;br/&gt;
&gt; There were many versions of it&lt;br/&gt;
&gt; So people wrote a version manager for it&lt;br/&gt;
&gt; To switch between versions for projects&lt;br/&gt;
&gt; Different, old, new.
&gt; 
&gt; Then there came more programming languages&lt;br/&gt;
&gt; So there came more version managers&lt;br/&gt;
&gt; And many commands for them
&gt; 
&gt; I installed a lot of them&lt;br/&gt;
&gt; I learnt a lot of commands
&gt; 
&gt; Then I said, just one more version manager&lt;br/&gt;
&gt; Which I will write instead
&gt; 
&gt; So, there came another version manager&lt;br/&gt;
&gt; **asdf version manager** - &lt;https://github.com/asdf-vm/asdf&gt;
&gt; 
&gt; A version manager so extendable&lt;br/&gt;
&gt; for which anyone can create a plugin&lt;br/&gt;
&gt; To support their favourite language&lt;br/&gt;
&gt; No more installing more version managers&lt;br/&gt;
&gt; Or learning more commands

---

&lt;figure&gt;
  &lt;blockquote&gt;
  This was the mail I wrote to a few friends to tell them about the project. Thanks to &lt;a href=&quot;https://twitter.com/roshanvid&quot; target=&quot;_blank&quot; rel=&quot;noreferrer&quot;&gt;@roshanvid&lt;/a&gt; for suggesting that this go into the readme
  &lt;/blockquote&gt;
  &lt;figcaption&gt;
    &lt;a href=&quot;https://github.com/HashNuke&quot; target=&quot;_blank&quot; rel=&quot;noreferrer&quot;&gt;@HashNuke&lt;/a&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>