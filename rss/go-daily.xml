<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Fri, 20 Jun 2025 00:05:28 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[php/frankenphp]]></title>
            <link>https://github.com/php/frankenphp</link>
            <guid>https://github.com/php/frankenphp</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[üßü The modern PHP app server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/php/frankenphp">php/frankenphp</a></h1>
            <p>üßü The modern PHP app server</p>
            <p>Language: Go</p>
            <p>Stars: 8,767</p>
            <p>Forks: 328</p>
            <p>Stars today: 177 stars today</p>
            <h2>README</h2><pre># FrankenPHP: Modern App Server for PHP

&lt;h1 align=&quot;center&quot;&gt;&lt;a href=&quot;https://frankenphp.dev&quot;&gt;&lt;img src=&quot;frankenphp.png&quot; alt=&quot;FrankenPHP&quot; width=&quot;600&quot;&gt;&lt;/a&gt;&lt;/h1&gt;

FrankenPHP is a modern application server for PHP built on top of the [Caddy](https://caddyserver.com/) web server.

FrankenPHP gives superpowers to your PHP apps thanks to its stunning features: [_Early Hints_](https://frankenphp.dev/docs/early-hints/), [worker mode](https://frankenphp.dev/docs/worker/), [real-time capabilities](https://frankenphp.dev/docs/mercure/), automatic HTTPS, HTTP/2, and HTTP/3 support...

FrankenPHP works with any PHP app and makes your Laravel and Symfony projects faster than ever thanks to their official integrations with the worker mode.

FrankenPHP can also be used as a standalone Go library to embed PHP in any app using `net/http`.

[**Learn more** on _frankenphp.dev_](https://frankenphp.dev) and in this slide deck:

&lt;a href=&quot;https://dunglas.dev/2022/10/frankenphp-the-modern-php-app-server-written-in-go/&quot;&gt;&lt;img src=&quot;https://dunglas.dev/wp-content/uploads/2022/10/frankenphp.png&quot; alt=&quot;Slides&quot; width=&quot;600&quot;&gt;&lt;/a&gt;

## Getting Started

### Standalone Binary

We provide static FrankenPHP binaries for Linux and macOS
containing [PHP 8.4](https://www.php.net/releases/8.4/en.php) and most popular PHP extensions.

On Windows, use [WSL](https://learn.microsoft.com/windows/wsl/) to run FrankenPHP.

[Download FrankenPHP](https://github.com/dunglas/frankenphp/releases) or copy this line into your
terminal to automatically install the version appropriate for your platform:

```console
curl https://frankenphp.dev/install.sh | sh
mv frankenphp /usr/local/bin/
```

To serve the content of the current directory, run:

```console
frankenphp php-server
```

You can also run command-line scripts with:

```console
frankenphp php-cli /path/to/your/script.php
```

### Docker

Alternatively, [Docker images](https://frankenphp.dev/docs/docker/) are available:

```console
docker run -v .:/app/public \
    -p 80:80 -p 443:443 -p 443:443/udp \
    dunglas/frankenphp
```

Go to `https://localhost`, and enjoy!

&gt; [!TIP]
&gt;
&gt; Do not attempt to use `https://127.0.0.1`. Use `https://localhost` and accept the self-signed certificate.
&gt; Use the [`SERVER_NAME` environment variable](docs/config.md#environment-variables) to change the domain to use.

### Homebrew

FrankenPHP is also available as a [Homebrew](https://brew.sh) package for macOS and Linux.

To install it:

```console
brew install dunglas/frankenphp/frankenphp
```

To serve the content of the current directory, run:

```console
frankenphp php-server
```

## Docs

- [Classic mode](https://frankenphp.dev/docs/classic/)
- [Worker mode](https://frankenphp.dev/docs/worker/)
- [Early Hints support (103 HTTP status code)](https://frankenphp.dev/docs/early-hints/)
- [Real-time](https://frankenphp.dev/docs/mercure/)
- [Efficiently Serving Large Static Files](https://frankenphp.dev/docs/x-sendfile/)
- [Configuration](https://frankenphp.dev/docs/config/)
- [Docker images](https://frankenphp.dev/docs/docker/)
- [Deploy in production](https://frankenphp.dev/docs/production/)
- [Performance optimization](https://frankenphp.dev/docs/performance/)
- [Create **standalone**, self-executable PHP apps](https://frankenphp.dev/docs/embed/)
- [Create static binaries](https://frankenphp.dev/docs/static/)
- [Compile from sources](https://frankenphp.dev/docs/compile/)
- [Monitoring FrankenPHP](https://frankenphp.dev/docs/metrics/)
- [Laravel integration](https://frankenphp.dev/docs/laravel/)
- [Known issues](https://frankenphp.dev/docs/known-issues/)
- [Demo app (Symfony) and benchmarks](https://github.com/dunglas/frankenphp-demo)
- [Go library documentation](https://pkg.go.dev/github.com/dunglas/frankenphp)
- [Contributing and debugging](https://frankenphp.dev/docs/contributing/)

## Examples and Skeletons

- [Symfony](https://github.com/dunglas/symfony-docker)
- [API Platform](https://api-platform.com/docs/symfony)
- [Laravel](https://frankenphp.dev/docs/laravel/)
- [Sulu](https://sulu.io/blog/running-sulu-with-frankenphp)
- [WordPress](https://github.com/StephenMiracle/frankenwp)
- [Drupal](https://github.com/dunglas/frankenphp-drupal)
- [Joomla](https://github.com/alexandreelise/frankenphp-joomla)
- [TYPO3](https://github.com/ochorocho/franken-typo3)
- [Magento2](https://github.com/ekino/frankenphp-magento2)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ollama/ollama]]></title>
            <link>https://github.com/ollama/ollama</link>
            <guid>https://github.com/ollama/ollama</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 3, Mistral Small 3.1 and other large language models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ollama/ollama">ollama/ollama</a></h1>
            <p>Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 3, Mistral Small 3.1 and other large language models.</p>
            <p>Language: Go</p>
            <p>Stars: 144,186</p>
            <p>Forks: 12,136</p>
            <p>Stars today: 130 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
¬† &lt;a href=&quot;https://ollama.com&quot;&gt;
    &lt;img alt=&quot;ollama&quot; height=&quot;200px&quot; src=&quot;https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

# Ollama

Get up and running with large language models.

### macOS

[Download](https://ollama.com/download/Ollama-darwin.zip)

### Windows

[Download](https://ollama.com/download/OllamaSetup.exe)

### Linux

```shell
curl -fsSL https://ollama.com/install.sh | sh
```

[Manual install instructions](https://github.com/ollama/ollama/blob/main/docs/linux.md)

### Docker

The official [Ollama Docker image](https://hub.docker.com/r/ollama/ollama) `ollama/ollama` is available on Docker Hub.

### Libraries

- [ollama-python](https://github.com/ollama/ollama-python)
- [ollama-js](https://github.com/ollama/ollama-js)

### Community

- [Discord](https://discord.gg/ollama)
- [Reddit](https://reddit.com/r/ollama)

## Quickstart

To run and chat with [Gemma 3](https://ollama.com/library/gemma3):

```shell
ollama run gemma3
```

## Model library

Ollama supports a list of models available on [ollama.com/library](https://ollama.com/library &#039;ollama model library&#039;)

Here are some example models that can be downloaded:

| Model              | Parameters | Size  | Download                         |
| ------------------ | ---------- | ----- | -------------------------------- |
| Gemma 3            | 1B         | 815MB | `ollama run gemma3:1b`           |
| Gemma 3            | 4B         | 3.3GB | `ollama run gemma3`              |
| Gemma 3            | 12B        | 8.1GB | `ollama run gemma3:12b`          |
| Gemma 3            | 27B        | 17GB  | `ollama run gemma3:27b`          |
| QwQ                | 32B        | 20GB  | `ollama run qwq`                 |
| DeepSeek-R1        | 7B         | 4.7GB | `ollama run deepseek-r1`         |
| DeepSeek-R1        | 671B       | 404GB | `ollama run deepseek-r1:671b`    |
| Llama 4            | 109B       | 67GB  | `ollama run llama4:scout`        |
| Llama 4            | 400B       | 245GB | `ollama run llama4:maverick`     |
| Llama 3.3          | 70B        | 43GB  | `ollama run llama3.3`            |
| Llama 3.2          | 3B         | 2.0GB | `ollama run llama3.2`            |
| Llama 3.2          | 1B         | 1.3GB | `ollama run llama3.2:1b`         |
| Llama 3.2 Vision   | 11B        | 7.9GB | `ollama run llama3.2-vision`     |
| Llama 3.2 Vision   | 90B        | 55GB  | `ollama run llama3.2-vision:90b` |
| Llama 3.1          | 8B         | 4.7GB | `ollama run llama3.1`            |
| Llama 3.1          | 405B       | 231GB | `ollama run llama3.1:405b`       |
| Phi 4              | 14B        | 9.1GB | `ollama run phi4`                |
| Phi 4 Mini         | 3.8B       | 2.5GB | `ollama run phi4-mini`           |
| Mistral            | 7B         | 4.1GB | `ollama run mistral`             |
| Moondream 2        | 1.4B       | 829MB | `ollama run moondream`           |
| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`         |
| Starling           | 7B         | 4.1GB | `ollama run starling-lm`         |
| Code Llama         | 7B         | 3.8GB | `ollama run codellama`           |
| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored`   |
| LLaVA              | 7B         | 4.5GB | `ollama run llava`               |
| Granite-3.3         | 8B         | 4.9GB | `ollama run granite3.3`          |

&gt; [!NOTE]
&gt; You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.

## Customize a model

### Import from GGUF

Ollama supports importing GGUF models in the Modelfile:

1. Create a file named `Modelfile`, with a `FROM` instruction with the local filepath to the model you want to import.

   ```
   FROM ./vicuna-33b.Q4_0.gguf
   ```

2. Create the model in Ollama

   ```shell
   ollama create example -f Modelfile
   ```

3. Run the model

   ```shell
   ollama run example
   ```

### Import from Safetensors

See the [guide](docs/import.md) on importing models for more information.

### Customize a prompt

Models from the Ollama library can be customized with a prompt. For example, to customize the `llama3.2` model:

```shell
ollama pull llama3.2
```

Create a `Modelfile`:

```
FROM llama3.2

# set the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# set the system message
SYSTEM &quot;&quot;&quot;
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
&quot;&quot;&quot;
```

Next, create and run the model:

```
ollama create mario -f ./Modelfile
ollama run mario
&gt;&gt;&gt; hi
Hello! It&#039;s your friend Mario.
```

For more information on working with a Modelfile, see the [Modelfile](docs/modelfile.md) documentation.

## CLI Reference

### Create a model

`ollama create` is used to create a model from a Modelfile.

```shell
ollama create mymodel -f ./Modelfile
```

### Pull a model

```shell
ollama pull llama3.2
```

&gt; This command can also be used to update a local model. Only the diff will be pulled.

### Remove a model

```shell
ollama rm llama3.2
```

### Copy a model

```shell
ollama cp llama3.2 my-model
```

### Multiline input

For multiline input, you can wrap text with `&quot;&quot;&quot;`:

```
&gt;&gt;&gt; &quot;&quot;&quot;Hello,
... world!
... &quot;&quot;&quot;
I&#039;m a basic program that prints the famous &quot;Hello, world!&quot; message to the console.
```

### Multimodal models

```
ollama run llava &quot;What&#039;s in this image? /Users/jmorgan/Desktop/smile.png&quot;
```

&gt; **Output**: The image features a yellow smiley face, which is likely the central focus of the picture.

### Pass the prompt as an argument

```shell
ollama run llama3.2 &quot;Summarize this file: $(cat README.md)&quot;
```

&gt; **Output**: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.

### Show model information

```shell
ollama show llama3.2
```

### List models on your computer

```shell
ollama list
```

### List which models are currently loaded

```shell
ollama ps
```

### Stop a model which is currently running

```shell
ollama stop llama3.2
```

### Start Ollama

`ollama serve` is used when you want to start ollama without running the desktop application.

## Building

See the [developer guide](https://github.com/ollama/ollama/blob/main/docs/development.md)

### Running local builds

Next, start the server:

```shell
./ollama serve
```

Finally, in a separate shell, run a model:

```shell
./ollama run llama3.2
```

## REST API

Ollama has a REST API for running and managing models.

### Generate a response

```shell
curl http://localhost:11434/api/generate -d &#039;{
  &quot;model&quot;: &quot;llama3.2&quot;,
  &quot;prompt&quot;:&quot;Why is the sky blue?&quot;
}&#039;
```

### Chat with a model

```shell
curl http://localhost:11434/api/chat -d &#039;{
  &quot;model&quot;: &quot;llama3.2&quot;,
  &quot;messages&quot;: [
    { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;why is the sky blue?&quot; }
  ]
}&#039;
```

See the [API documentation](./docs/api.md) for all endpoints.

## Community Integrations

### Web &amp; Desktop

- [Open WebUI](https://github.com/open-webui/open-webui)
- [SwiftChat (macOS with ReactNative)](https://github.com/aws-samples/swift-chat)
- [Enchanted (macOS native)](https://github.com/AugustDev/enchanted)
- [Hollama](https://github.com/fmaclen/hollama)
- [Lollms-Webui](https://github.com/ParisNeo/lollms-webui)
- [LibreChat](https://github.com/danny-avila/LibreChat)
- [Bionic GPT](https://github.com/bionic-gpt/bionic-gpt)
- [HTML UI](https://github.com/rtcfirefly/ollama-ui)
- [Saddle](https://github.com/jikkuatwork/saddle)
- [TagSpaces](https://www.tagspaces.org) (A platform for file-based apps, [utilizing Ollama](https://docs.tagspaces.org/ai/) for the generation of tags and descriptions)
- [Chatbot UI](https://github.com/ivanfioravanti/chatbot-ollama)
- [Chatbot UI v2](https://github.com/mckaywrigley/chatbot-ui)
- [Typescript UI](https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file)
- [Minimalistic React UI for Ollama Models](https://github.com/richawo/minimal-llm-ui)
- [Ollamac](https://github.com/kevinhermawan/Ollamac)
- [big-AGI](https://github.com/enricoros/big-AGI)
- [Cheshire Cat assistant framework](https://github.com/cheshire-cat-ai/core)
- [Amica](https://github.com/semperai/amica)
- [chatd](https://github.com/BruceMacD/chatd)
- [Ollama-SwiftUI](https://github.com/kghandour/Ollama-SwiftUI)
- [Dify.AI](https://github.com/langgenius/dify)
- [MindMac](https://mindmac.app)
- [NextJS Web Interface for Ollama](https://github.com/jakobhoeg/nextjs-ollama-llm-ui)
- [Msty](https://msty.app)
- [Chatbox](https://github.com/Bin-Huang/Chatbox)
- [WinForm Ollama Copilot](https://github.com/tgraupmann/WinForm_Ollama_Copilot)
- [NextChat](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web) with [Get Started Doc](https://docs.nextchat.dev/models/ollama)
- [Alpaca WebUI](https://github.com/mmo80/alpaca-webui)
- [OllamaGUI](https://github.com/enoch1118/ollamaGUI)
- [OpenAOE](https://github.com/InternLM/OpenAOE)
- [Odin Runes](https://github.com/leonid20000/OdinRunes)
- [LLM-X](https://github.com/mrdjohnson/llm-x) (Progressive Web App)
- [AnythingLLM (Docker + MacOs/Windows/Linux native app)](https://github.com/Mintplex-Labs/anything-llm)
- [Ollama Basic Chat: Uses HyperDiv Reactive UI](https://github.com/rapidarchitect/ollama_basic_chat)
- [Ollama-chats RPG](https://github.com/drazdra/ollama-chats)
- [IntelliBar](https://intellibar.app/) (AI-powered assistant for macOS)
- [Jirapt](https://github.com/AliAhmedNada/jirapt) (Jira Integration to generate issues, tasks, epics)
- [ojira](https://github.com/AliAhmedNada/ojira) (Jira chrome plugin to easily generate descriptions for tasks)
- [QA-Pilot](https://github.com/reid41/QA-Pilot) (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)
- [ChatOllama](https://github.com/sugarforever/chat-ollama) (Open Source Chatbot based on Ollama with Knowledge Bases)
- [CRAG Ollama Chat](https://github.com/Nagi-ovo/CRAG-Ollama-Chat) (Simple Web Search with Corrective RAG)
- [RAGFlow](https://github.com/infiniflow/ragflow) (Open-source Retrieval-Augmented Generation engine based on deep document understanding)
- [StreamDeploy](https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold) (LLM Application Scaffold)
- [chat](https://github.com/swuecho/chat) (chat web app for teams)
- [Lobe Chat](https://github.com/lobehub/lobe-chat) with [Integrating Doc](https://lobehub.com/docs/self-hosting/examples/ollama)
- [Ollama RAG Chatbot](https://github.com/datvodinh/rag-chatbot.git) (Local Chat with multiple PDFs using Ollama and RAG)
- [BrainSoup](https://www.nurgo-software.com/products/brainsoup) (Flexible native client with RAG &amp; multi-agent automation)
- [macai](https://github.com/Renset/macai) (macOS client for Ollama, ChatGPT, and other compatible API back-ends)
- [RWKV-Runner](https://github.com/josStorer/RWKV-Runner) (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)
- [Ollama Grid Search](https://github.com/dezoito/ollama-grid-search) (app to evaluate and compare models)
- [Olpaka](https://github.com/Otacon/olpaka) (User-friendly Flutter Web App for Ollama)
- [Casibase](https://casibase.org) (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)
- [OllamaSpring](https://github.com/CrazyNeil/OllamaSpring) (Ollama Client for macOS)
- [LLocal.in](https://github.com/kartikm7/llocal) (Easy to use Electron Desktop Client for Ollama)
- [Shinkai Desktop](https://github.com/dcSpark/shinkai-apps) (Two click install Local AI using Ollama + Files + RAG)
- [AiLama](https://github.com/zeyoyt/ailama) (A Discord User App that allows you to interact with Ollama anywhere in Discord)
- [Ollama with Google Mesop](https://github.com/rapidarchitect/ollama_mesop/) (Mesop Chat Client implementation with Ollama)
- [R2R](https://github.com/SciPhi-AI/R2R) (Open-source RAG engine)
- [Ollama-Kis](https://github.com/elearningshow/ollama-kis) (A simple easy-to-use GUI with sample custom LLM for Drivers Education)
- [OpenGPA](https://opengpa.org) (Open-source offline-first Enterprise Agentic Application)
- [Painting Droid](https://github.com/mateuszmigas/painting-droid) (Painting app with AI integrations)
- [Kerlig AI](https://www.kerlig.com/) (AI writing assistant for macOS)
- [AI Studio](https://github.com/MindWorkAI/AI-Studio)
- [Sidellama](https://github.com/gyopak/sidellama) (browser-based LLM client)
- [LLMStack](https://github.com/trypromptly/LLMStack) (No-code multi-agent framework to build LLM agents and workflows)
- [BoltAI for Mac](https://boltai.com) (AI Chat Client for Mac)
- [Harbor](https://github.com/av/harbor) (Containerized LLM Toolkit with Ollama as default backend)
- [PyGPT](https://github.com/szczyglis-dev/py-gpt) (AI desktop assistant for Linux, Windows, and Mac)
- [Alpaca](https://github.com/Jeffser/Alpaca) (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)
- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT/blob/master/docs/content/platform/ollama.md) (AutoGPT Ollama integration)
- [Go-CREW](https://www.jonathanhecl.com/go-crew/) (Powerful Offline RAG in Golang)
- [PartCAD](https://github.com/openvmp/partcad/) (CAD model generation with OpenSCAD and CadQuery)
- [Ollama4j Web UI](https://github.com/ollama4j/ollama4j-web-ui) - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j
- [PyOllaMx](https://github.com/kspviswa/pyOllaMx) - macOS application capable of chatting with both Ollama and Apple MLX models.
- [Cline](https://github.com/cline/cline) - Formerly known as Claude Dev is a VSCode extension for multi-file/whole-repo coding
- [Cherry Studio](https://github.com/kangfenmao/cherry-studio) (Desktop client with Ollama support)
- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)
- [Archyve](https://github.com/nickthecook/archyve) (RAG-enabling document library)
- [crewAI with Mesop](https://github.com/rapidarchitect/ollama-crew-mesop) (Mesop Web Interface to run crewAI with Ollama)
- [Tkinter-based client](https://github.com/chyok/ollama-gui) (Python tkinter-based Client for Ollama)
- [LLMChat](https://github.com/trendy-design/llmchat) (Privacy focused, 100% local, intuitive all-in-one chat interface)
- [Local Multimodal AI Chat](https://github.com/Leon-Sander/Local-Multimodal-AI-Chat) (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)
- [ARGO](https://github.com/xark-argo/argo) (Locally download and run Ollama and Huggingface models with RAG on Mac/Windows/Linux)
- [OrionChat](https://github.com/EliasPereirah/OrionChat) - OrionChat is a web interface for chatting with different AI providers
- [G1](https://github.com/bklieger-groq/g1) (Prototype of using prompting strategies to improve the LLM&#039;s reasoning through o1-like reasoning chains.)
- [Web management](https://github.com/lemonit-eric-mao/ollama-web-management) (Web management page)
- [Promptery](https://github.com/promptery/promptery) (desktop client for Ollama.)
- [Ollama App](https://github.com/JHubi1/ollama-app) (Modern and easy-to-use multi-platform client for Ollama)
- [chat-ollama](https://github.com/annilq/chat-ollama) (a React Native client for Ollama)
- [SpaceLlama](https://github.com/tcsenpai/spacellama) (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)
- [YouLama](https://github.com/tcsenpai/youlama) (Webapp to quickly summarize any YouTube video, supporting Invidious as well)
- [DualMind](https://github.com/tcsenpai/dualmind) (Experimental app allowing two models to talk to each other in the terminal or in a web interface)
- [ollamarama-matrix](https://github.com/h1ddenpr0cess20/ollamarama-matrix) (Ollama chatbot for the Matrix chat protocol)
- [ollama-chat-app](https://github.com/anan1213095357/ollama-chat-app) (Flutter-based chat app)
- [Perfect Memory AI](https://www.perfectmemory.ai/) (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)
- [Hexabot](https://github.com/hexastack/hexabot) (A conversational AI builder)
- [Reddit Rate](https://github.com/rapidarchitect/reddit_analyzer) (Search and Rate Reddit topics with a weighted summation)
- [OpenTalkGpt](https://github.com/adarshM84/OpenTalkGpt) (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)
- [VT](https://github.com/vinhnx/vt.ai) (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)
- [Nosia](https://github.com/nosia-ai/nosia) (Easy to install and use RAG platform based on Ollama)
- [Witsy](https://github.com/nbonamy/witsy) (An AI Desktop application available for Mac/Windows/Linux)
- [Abbey](https://github.com/US-Artificial-Intelligence/abbey) (A configurable AI interface server with notebooks, document storage, and YouTube support)
- [Minima](https://github.com/dmayboroda/minima) (RAG with on-premises or fully local workflow)
- [aidful-ollama-model-delete](https://github.com/AidfulAI/aidful-ollama-model-delete) (User interface for simplified model cleanup)
- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) (An AI-powered search engine &amp; an open-source alternative to Perplexity AI)
- [Ollama Chat WebUI for Docker ](https://github.com/oslook/ollama-webui) (Support for local docker deployment, lightweight ollama webui)
- [AI Toolkit for Visual Studio Code](https://aka.ms/ai-tooklit/ollama-docs) (Microsoft-official VSCode extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)
- [MinimalNextOllamaChat](https://github.com/anilkay/MinimalNextOllamaChat) (Minimal Web UI for Chat and Model Control)
- [Chipper](https://github.com/TilmanGriesel/chipper) AI interface for tinkerers (Ollama, Haystack RAG, Python)
- [ChibiChat](https://github.com/CosmicEventHorizon/ChibiChat) (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)
- [LocalLLM](https://github.com/qusaismael/localllm) (Minimal Web-App to run ollama models on it with a GUI)
- [Ollamazing](https://github.com/buiducnhat/ollamazing) (Web extension to run Ollama models)
- [OpenDeepResearcher-via-searxng](https://github.com/benhaotang/OpenDeepResearcher-via-searxng) (A Deep Research equivalent endpoint with Ollama support for running locally)
- [AntSK](https://github.com/AIDotNet/AntSK) (Out-of-the-box &amp; Adaptable RAG Chatbot)
- [MaxKB](https://github.com/1Panel-dev/MaxKB/) (Ready-to-use &amp; flexible RAG Chatbot)
- [yla](https://github.com/danielekp/yla) (Web interface to freely interact with your customized models)
- [LangBot](https://github.com/RockChinQ/LangBot) (LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)
- [1Panel](https://github.com/1Panel-dev/1Panel/) (Web-based Linux Server Management Tool)
- [AstrBot](https://github.com/Soulter/AstrBot/) (User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)
- [Reins](https://github.com/ibrahimcetin/reins) (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)
- [Flufy](https://github.com/Aharon-Bensadoun/Flufy) (A beautiful chat interface for interacting with Ollama&#039;s API. Built with React, TypeScript, and Material-UI.)
- [Ellama](https://github.com/zeozeozeo/ellama) (Friendly native app to chat with an Ollama instance)
- [screenpipe](https://github.com/mediar-ai/screenpipe) Build agents powered by your screen history
- [Ollamb](https://github.com/hengkysteen/

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[argoproj/argo-cd]]></title>
            <link>https://github.com/argoproj/argo-cd</link>
            <guid>https://github.com/argoproj/argo-cd</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[Declarative Continuous Deployment for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/argoproj/argo-cd">argoproj/argo-cd</a></h1>
            <p>Declarative Continuous Deployment for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 19,860</p>
            <p>Forks: 6,100</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>**Releases:**
[![Release Version](https://img.shields.io/github/v/release/argoproj/argo-cd?label=argo-cd)](https://github.com/argoproj/argo-cd/releases/latest)
[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-cd)](https://artifacthub.io/packages/helm/argo/argo-cd)
[![SLSA 3](https://slsa.dev/images/gh-badge-level3.svg)](https://slsa.dev)

**Code:** 
[![Integration tests](https://github.com/argoproj/argo-cd/workflows/Integration%20tests/badge.svg?branch=master)](https://github.com/argoproj/argo-cd/actions?query=workflow%3A%22Integration+tests%22)
[![codecov](https://codecov.io/gh/argoproj/argo-cd/branch/master/graph/badge.svg)](https://codecov.io/gh/argoproj/argo-cd)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/4486/badge)](https://bestpractices.coreinfrastructure.org/projects/4486)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-cd/badge)](https://scorecard.dev/viewer/?uri=github.com/argoproj/argo-cd)

**Social:**
[![Twitter Follow](https://img.shields.io/twitter/follow/argoproj?style=social)](https://twitter.com/argoproj)
[![Slack](https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack)](https://argoproj.github.io/community/join-slack)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-argoproj-blue.svg?logo=linkedin)](https://www.linkedin.com/company/argoproj/)

# Argo CD - Declarative Continuous Delivery for Kubernetes

## What is Argo CD?

Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes.

![Argo CD UI](docs/assets/argocd-ui.gif)

[![Argo CD Demo](https://img.youtube.com/vi/0WAm0y2vLIo/0.jpg)](https://youtu.be/0WAm0y2vLIo)

## Why Argo CD?

1. Application definitions, configurations, and environments should be declarative and version controlled.
1. Application deployment and lifecycle management should be automated, auditable, and easy to understand.

## Who uses Argo CD?

[Official Argo CD user list](USERS.md)

## Documentation

To learn more about Argo CD [go to the complete documentation](https://argo-cd.readthedocs.io/).
Check live demo at https://cd.apps.argoproj.io/.

## Community

### Contribution, Discussion and Support

 You can reach the Argo CD community and developers via the following channels:

* Q &amp; A : [Github Discussions](https://github.com/argoproj/argo-cd/discussions)
* Chat : [The #argo-cd Slack channel](https://argoproj.github.io/community/join-slack)
* Contributors Office Hours: [Every Thursday](https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com) | [Agenda](https://docs.google.com/document/d/1xkoFkVviB70YBzSEa4bDnu-rUZ1sIFtwKKG1Uw8XsY8)
* User Community meeting: [First Wednesday of the month](https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com) | [Agenda](https://docs.google.com/document/d/1ttgw98MO45Dq7ZUHpIiOIEfbyeitKHNfMjbY5dLLMKQ)


Participation in the Argo CD project is governed by the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/master/code-of-conduct.md)


### Blogs and Presentations

1. [Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo](https://github.com/terrytangyuan/awesome-argo)
1. [Unveil the Secret Ingredients of Continuous Delivery at Enterprise Scale with Argo CD](https://akuity.io/blog/secret-ingredients-of-continuous-delivery-at-enterprise-scale-with-argocd/)
1. [GitOps Without Pipelines With ArgoCD Image Updater](https://youtu.be/avPUQin9kzU)
1. [Combining Argo CD (GitOps), Crossplane (Control Plane), And KubeVela (OAM)](https://youtu.be/eEcgn_gU3SM)
1. [How to Apply GitOps to Everything - Combining Argo CD and Crossplane](https://youtu.be/yrj4lmScKHQ)
1. [Couchbase - How To Run a Database Cluster in Kubernetes Using Argo CD](https://youtu.be/nkPoPaVzExY)
1. [Automation of Everything - How To Combine Argo Events, Workflows &amp; Pipelines, CD, and Rollouts](https://youtu.be/XNXJtxkUKeY)
1. [Environments Based On Pull Requests (PRs): Using Argo CD To Apply GitOps Principles On Previews](https://youtu.be/cpAaI8p4R60)
1. [Argo CD: Applying GitOps Principles To Manage Production Environment In Kubernetes](https://youtu.be/vpWQeoaiRM4)
1. [Creating Temporary Preview Environments Based On Pull Requests With Argo CD And Codefresh](https://codefresh.io/continuous-deployment/creating-temporary-preview-environments-based-pull-requests-argo-cd-codefresh/)
1. [Tutorial: Everything You Need To Become A GitOps Ninja](https://www.youtube.com/watch?v=r50tRQjisxw) 90m tutorial on GitOps and Argo CD.
1. [Comparison of Argo CD, Spinnaker, Jenkins X, and Tekton](https://www.inovex.de/blog/spinnaker-vs-argo-cd-vs-tekton-vs-jenkins-x/)
1. [Simplify and Automate Deployments Using GitOps with IBM Multicloud Manager 3.1.2](https://www.ibm.com/cloud/blog/simplify-and-automate-deployments-using-gitops-with-ibm-multicloud-manager-3-1-2)
1. [GitOps for Kubeflow using Argo CD](https://v0-6.kubeflow.org/docs/use-cases/gitops-for-kubeflow/)
1. [GitOps Toolsets on Kubernetes with CircleCI and Argo CD](https://www.digitalocean.com/community/tutorials/webinar-series-gitops-tool-sets-on-kubernetes-with-circleci-and-argo-cd)
1. [CI/CD in Light Speed with K8s and Argo CD](https://www.youtube.com/watch?v=OdzH82VpMwI&amp;feature=youtu.be)
1. [Machine Learning as Code](https://www.youtube.com/watch?v=VXrGp5er1ZE&amp;t=0s&amp;index=135&amp;list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU). Among other things, describes how Kubeflow uses Argo CD to implement GitOPs for ML
1. [Argo CD - GitOps Continuous Delivery for Kubernetes](https://www.youtube.com/watch?v=aWDIQMbp1cc&amp;feature=youtu.be&amp;t=1m4s)
1. [Introduction to Argo CD : Kubernetes DevOps CI/CD](https://www.youtube.com/watch?v=2WSJF7d8dUg&amp;feature=youtu.be)
1. [GitOps Deployment and Kubernetes - using Argo CD](https://medium.com/riskified-technology/gitops-deployment-and-kubernetes-f1ab289efa4b)
1. [Deploy Argo CD with Ingress and TLS in Three Steps: No YAML Yak Shaving Required](https://itnext.io/deploy-argo-cd-with-ingress-and-tls-in-three-steps-no-yaml-yak-shaving-required-bc536d401491)
1. [GitOps Continuous Delivery with Argo and Codefresh](https://codefresh.io/events/cncf-member-webinar-gitops-continuous-delivery-argo-codefresh/)
1. [Stay up to date with Argo CD and Renovate](https://mjpitz.com/blog/2020/12/03/renovate-your-gitops/)
1. [Setting up Argo CD with Helm](https://www.arthurkoziel.com/setting-up-argocd-with-helm/)
1. [Applied GitOps with Argo CD](https://thenewstack.io/applied-gitops-with-argocd/)
1. [Solving configuration drift using GitOps with Argo CD](https://www.cncf.io/blog/2020/12/17/solving-configuration-drift-using-gitops-with-argo-cd/)
1. [Decentralized GitOps over environments](https://blogs.sap.com/2021/05/06/decentralized-gitops-over-environments/)
1. [Getting Started with ArgoCD for GitOps Deployments](https://youtu.be/AvLuplh1skA)
1. [Using Argo CD &amp; Datree for Stable Kubernetes CI/CD Deployments](https://youtu.be/17894DTru2Y)
1. [How to create Argo CD Applications Automatically using ApplicationSet? &quot;Automation of GitOps&quot;](https://amralaayassen.medium.com/how-to-create-argocd-applications-automatically-using-applicationset-automation-of-the-gitops-59455eaf4f72)
1. [Progressive Delivery with Service Mesh ‚Äì Argo Rollouts with Istio](https://www.cncf.io/blog/2022/12/16/progressive-delivery-with-service-mesh-argo-rollouts-with-istio/)

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kedacore/keda]]></title>
            <link>https://github.com/kedacore/keda</link>
            <guid>https://github.com/kedacore/keda</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kedacore/keda">kedacore/keda</a></h1>
            <p>KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 9,176</p>
            <p>Forks: 1,163</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;images/logos/keda-word-colour.png&quot; width=&quot;300&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;font-size: 25px&quot; align=&quot;center&quot;&gt;&lt;b&gt;Kubernetes-based Event Driven Autoscaling&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;font-size: 25px&quot; align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/kedacore/keda/actions?query=workflow%3Amain-build&quot;&gt;&lt;img src=&quot;https://github.com/kedacore/keda/actions/workflows/main-build.yml/badge.svg&quot; alt=&quot;main build&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/kedacore/keda/actions?query=workflow%3Anightly-e2e-test&quot;&gt;&lt;img src=&quot;https://github.com/kedacore/keda/actions/workflows/nightly-e2e.yml/badge.svg&quot; alt=&quot;nightly e2e&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://bestpractices.coreinfrastructure.org/projects/3791&quot;&gt;&lt;img src=&quot;https://bestpractices.coreinfrastructure.org/projects/3791/badge&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://api.scorecard.dev/projects/github.com/kedacore/keda/badge&quot;&gt;&lt;img src=&quot;https://img.shields.io/ossf-scorecard/github.com/kedacore/keda?label=openssf%20scorecard&amp;style=flat&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://artifacthub.io/packages/helm/kedacore/keda&quot;&gt;&lt;img src=&quot;https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/kedacore&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fkedacore%2Fkeda?ref=badge_shield&quot; alt=&quot;FOSSA Status&quot;&gt;&lt;img src=&quot;https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fkedacore%2Fkeda.svg?type=shield&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://twitter.com/kedaorg&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/kedaorg?style=social&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;&lt;/p&gt;

KEDA allows for fine-grained autoscaling (including to/from zero) for event driven Kubernetes workloads. KEDA serves
as a Kubernetes Metrics Server and allows users to define autoscaling rules using a dedicated Kubernetes custom
resource definition.

KEDA can run on both the cloud and the edge, integrates natively with Kubernetes components such as the Horizontal
Pod Autoscaler, and has no external dependencies.

We are a Cloud Native Computing Foundation (CNCF) graduated project.
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/kedacore/keda/main/images/logo-cncf.svg&quot; height=&quot;75px&quot;&gt;&lt;/p&gt;

&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt;
&lt;!-- DON&#039;T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt;
**Table of contents**

- [Getting started](#getting-started)
  - [Deploying KEDA](#deploying-keda)
- [Documentation](#documentation)
- [Community](#community)
- [Adopters - Become a listed KEDA user!](#adopters---become-a-listed-keda-user)
- [Governance &amp; Policies](#governance--policies)
- [Support](#support)
- [Roadmap](#roadmap)
- [Releases](#releases)
- [Contributing](#contributing)
  - [Building &amp; deploying locally](#building--deploying-locally)
  - [Testing strategy](#testing-strategy)

&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt;

## Getting started

* [QuickStart - RabbitMQ and Go](https://github.com/kedacore/sample-go-rabbitmq)
* [QuickStart - Azure Functions and Queues](https://github.com/kedacore/sample-hello-world-azure-functions)
* [QuickStart - Azure Functions and Kafka on Openshift 4](https://github.com/kedacore/sample-azure-functions-on-ocp4)
* [QuickStart - Azure Storage Queue with ScaledJob](https://github.com/kedacore/sample-go-storage-queue)

You can find several samples for various event sources [here](https://github.com/kedacore/samples).

### Deploying KEDA

There are many ways to [deploy KEDA including Helm, Operator Hub and YAML files](https://keda.sh/docs/latest/deploy/).

## Documentation

Interested to learn more? Head over to [keda.sh](https://keda.sh).

## Community

If interested in contributing or participating in the direction of KEDA, you can join our community meetings! Learn more about them on [our website](https://keda.sh/community/).

Just want to learn or chat about KEDA? Feel free to join the conversation in
**[#KEDA](https://kubernetes.slack.com/messages/CKZJ36A5D)** on the **[Kubernetes Slack](https://slack.k8s.io/)**!

## Adopters - Become a listed KEDA user!

We are always happy to [list users](https://keda.sh/community/#users) who run KEDA in production, learn more about it [here](https://github.com/kedacore/keda-docs#become-a-listed-keda-user).

## Governance &amp; Policies

You can learn about the governance of KEDA [here](https://github.com/kedacore/governance).

## Support

Details on the KEDA support policy can found [here](https://keda.sh/support/).

## Roadmap

We use GitHub issues to build our backlog, a complete overview of all open items and our planning.

Learn more about our roadmap [here](ROADMAP.md).

## Releases

You can find the latest releases [here](https://github.com/kedacore/keda/releases).

## Contributing

You can find contributing guide [here](./CONTRIBUTING.md).

### Building &amp; deploying locally
Learn how to build &amp; deploy KEDA locally [here](./BUILD.md).

### Testing strategy
Learn more about our testing strategy [here](./TESTING.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[loft-sh/devpod]]></title>
            <link>https://github.com/loft-sh/devpod</link>
            <guid>https://github.com/loft-sh/devpod</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[Codespaces but open-source, client-only and unopinionated: Works with any IDE and lets you use any cloud, kubernetes or just localhost docker.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/loft-sh/devpod">loft-sh/devpod</a></h1>
            <p>Codespaces but open-source, client-only and unopinionated: Works with any IDE and lets you use any cloud, kubernetes or just localhost docker.</p>
            <p>Language: Go</p>
            <p>Stars: 13,785</p>
            <p>Forks: 450</p>
            <p>Stars today: 36 stars today</p>
            <h2>README</h2><pre>&lt;br&gt;
&lt;a href=&quot;https://www.devpod.sh&quot;&gt;
  &lt;picture width=&quot;500&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/static/media/devpod_dark.png&quot;&gt;
    &lt;img alt=&quot;DevPod wordmark&quot; width=&quot;500&quot; src=&quot;docs/static/media/devpod.png&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;

### **[Website](https://www.devpod.sh)** ‚Ä¢ **[Quickstart](https://www.devpod.sh/docs/getting-started/install)** ‚Ä¢ **[Documentation](https://www.devpod.sh/docs/what-is-devpod)** ‚Ä¢ **[Blog](https://loft.sh/blog)** ‚Ä¢ **[ùïè (Twitter)](https://x.com/loft_sh)** ‚Ä¢ **[Slack](https://slack.loft.sh/)**

[![Join us on Slack!](docs/static/media/slack.svg)](https://slack.loft.sh/) [![Open in DevPod!](https://devpod.sh/assets/open-in-devpod.svg)](https://devpod.sh/open#https://github.com/loft-sh/devpod)

**[We are hiring!](https://www.loft.sh/careers) Come build the future of remote development environments with us.**

DevPod is a client-only tool to create reproducible developer environments based on a [devcontainer.json](https://containers.dev/) on any backend. Each developer environment runs in a container and is specified through a [devcontainer.json](https://containers.dev/). Through DevPod providers, these environments can be created on any backend, such as the local computer, a Kubernetes cluster, any reachable remote machine, or in a VM in the cloud.

![Codespaces](docs/static/media/codespaces-but.png)

You can think of DevPod as the glue that connects your local IDE to a machine where you want to develop. So depending on the requirements of your project, you can either create a workspace locally on the computer, on a beefy cloud machine with many GPUs, or a spare remote computer. Within DevPod, every workspace is managed the same way, which also makes it easy to switch between workspaces that might be hosted somewhere else.

![DevPod Flow](docs/static/media/devpod-flow.gif)

## Quickstart

Download DevPod Desktop:
- [MacOS Silicon/ARM](https://github.com/loft-sh/devpod/releases/latest/download/DevPod_macos_aarch64.dmg)
- [MacOS Intel/AMD](https://github.com/loft-sh/devpod/releases/latest/download/DevPod_macos_x64.dmg)
- [Windows](https://github.com/loft-sh/devpod/releases/latest/download/DevPod_windows_x64_en-US.msi)
- [Linux AppImage](https://github.com/loft-sh/devpod/releases/latest/download/DevPod_linux_amd64.AppImage)

Take a look at the [DevPod Docs](https://devpod.sh/docs/getting-started/install) for more information.

## Why DevPod?

DevPod reuses the open [DevContainer standard](https://containers.dev/) (used by GitHub Codespaces and VSCode DevContainers) to create a consistent developer experience no matter what backend you want to use.

Compared to hosted services such as Github Codespaces, JetBrains Spaces, or Google Cloud Workstations, DevPod has the following advantages:
* **Cost savings**: DevPod is usually around 5-10 times cheaper than existing services with comparable feature sets because it uses bare virtual machines in any cloud and shuts down unused virtual machines automatically.
* **No vendor lock-in**: Choose whatever cloud provider suits you best, be it the cheapest one or the most powerful, DevPod supports all cloud providers. If you are tired of using a provider, change it with a single command.
* **Local development**: You get the same developer experience also locally, so you don&#039;t need to rely on a cloud provider at all.
* **Cross IDE support**: VSCode and the full JetBrains suite is supported, all others can be connected through simple ssh.
* **Client-only**: No need to install a server backend, DevPod runs only on your computer.
* **Open-Source**: DevPod is 100% open-source and extensible. A provider doesn&#039;t exist? Just create your own.
* **Rich feature set**: DevPod already supports prebuilds, auto inactivity shutdown, git &amp; docker credentials sync, and many more features to come.
* **Desktop App**: DevPod comes with an easy-to-use desktop application that abstracts all the complexity away. If you want to build your own integration, DevPod offers a feature-rich CLI as well.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Ingenimax/agent-sdk-go]]></title>
            <link>https://github.com/Ingenimax/agent-sdk-go</link>
            <guid>https://github.com/Ingenimax/agent-sdk-go</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:23 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Ingenimax/agent-sdk-go">Ingenimax/agent-sdk-go</a></h1>
            <p></p>
            <p>Language: Go</p>
            <p>Stars: 128</p>
            <p>Forks: 43</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/docs/img/logo-header.png#gh-light-mode-only&quot; alt=&quot;Ingenimax&quot; width=&quot;600&quot;&gt;
&lt;img src=&quot;/docs/img/logo-header-inverted.png#gh-dark-mode-only&quot; alt=&quot;Ingenimax&quot; width=&quot;600&quot;&gt;
&lt;/div&gt;

# Agent Go SDK

A powerful Go framework for building production-ready AI agents that seamlessly integrates memory management, tool execution, multi-LLM support, and enterprise features into a flexible, extensible architecture.

## Features

### Core Capabilities
- üß† **Multi-Model Intelligence**: Seamless integration with OpenAI, Anthropic, and Google Vertex AI (Gemini models).
- üîß **Modular Tool Ecosystem**: Expand agent capabilities with plug-and-play tools for web search, data retrieval, and custom operations
- üìù **Advanced Memory Management**: Persistent conversation tracking with buffer and vector-based retrieval options
- üîå **MCP Integration**: Support for Model Context Protocol (MCP) servers via HTTP and stdio transports

### Enterprise-Ready
- üö¶ **Built-in Guardrails**: Comprehensive safety mechanisms for responsible AI deployment
- üìà **Complete Observability**: Integrated tracing and logging for monitoring and debugging
- üè¢ **Enterprise Multi-tenancy**: Securely support multiple organizations with isolated resources

### Development Experience
- üõ†Ô∏è **Structured Task Framework**: Plan, approve, and execute complex multi-step operations
- üìÑ **Declarative Configuration**: Define sophisticated agents and tasks using intuitive YAML definitions
- üßô **Zero-Effort Bootstrapping**: Auto-generate complete agent configurations from simple system prompts

## Getting Started

### Prerequisites

- Go 1.23+
- Redis (optional, for distributed memory)

### Installation

Add the SDK to your Go project:

```bash
go get github.com/Ingenimax/agent-sdk-go
```

### Configuration

The SDK uses environment variables for configuration. Key variables include:

- `OPENAI_API_KEY`: Your OpenAI API key
- `OPENAI_MODEL`: The model to use (e.g., gpt-4o-mini)
- `LOG_LEVEL`: Logging level (debug, info, warn, error)
- `REDIS_ADDRESS`: Redis server address (if using Redis for memory)

See `.env.example` for a complete list of configuration options.

## Usage Examples

### Creating a Simple Agent

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/agent&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/config&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/openai&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/logging&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/memory&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/multitenancy&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/tools&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/tools/websearch&quot;
)

func main() {
	// Create a logger
	logger := logging.New()

	// Get configuration
	cfg := config.Get()

	// Create a new agent with OpenAI
	openaiClient := openai.NewClient(cfg.LLM.OpenAI.APIKey,
		openai.WithLogger(logger))

	agent, err := agent.NewAgent(
		agent.WithLLM(openaiClient),
		agent.WithMemory(memory.NewConversationBuffer()),
		agent.WithTools(createTools(logger).List()...),
		agent.WithSystemPrompt(&quot;You are a helpful AI assistant. When you don&#039;t know the answer or need real-time information, use the available tools to find the information.&quot;),
		agent.WithName(&quot;ResearchAssistant&quot;),
	)
	if err != nil {
		logger.Error(context.Background(), &quot;Failed to create agent&quot;, map[string]interface{}{&quot;error&quot;: err.Error()})
		return
	}

	// Create a context with organization ID and conversation ID
	ctx := context.Background()
	ctx = multitenancy.WithOrgID(ctx, &quot;default-org&quot;)
	ctx = context.WithValue(ctx, memory.ConversationIDKey, &quot;conversation-123&quot;)

	// Run the agent
	response, err := agent.Run(ctx, &quot;What&#039;s the weather in San Francisco?&quot;)
	if err != nil {
		logger.Error(ctx, &quot;Failed to run agent&quot;, map[string]interface{}{&quot;error&quot;: err.Error()})
		return
	}

	fmt.Println(response)
}

func createTools(logger logging.Logger) *tools.Registry {
	// Get configuration
	cfg := config.Get()

	// Create tools registry
	toolRegistry := tools.NewRegistry()

	// Add web search tool if API keys are available
	if cfg.Tools.WebSearch.GoogleAPIKey != &quot;&quot; &amp;&amp; cfg.Tools.WebSearch.GoogleSearchEngineID != &quot;&quot; {
		searchTool := websearch.New(
			cfg.Tools.WebSearch.GoogleAPIKey,
			cfg.Tools.WebSearch.GoogleSearchEngineID,
		)
		toolRegistry.Register(searchTool)
	}

	return toolRegistry
}
```

### Creating an Agent with YAML Configuration

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;log&quot;
	&quot;os&quot;
	&quot;path/filepath&quot;
	&quot;strings&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/agent&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/openai&quot;
)

func main() {
	// Get OpenAI API key from environment
	apiKey := os.Getenv(&quot;OPENAI_API_KEY&quot;)
	if apiKey == &quot;&quot; {
		log.Fatal(&quot;OpenAI API key not provided. Set OPENAI_API_KEY environment variable.&quot;)
	}

	// Create the LLM client
	llm := openai.NewClient(apiKey)

	// Load agent configurations
	agentConfigs, err := agent.LoadAgentConfigsFromFile(&quot;agents.yaml&quot;)
	if err != nil {
		log.Fatalf(&quot;Failed to load agent configurations: %v&quot;, err)
	}

	// Load task configurations
	taskConfigs, err := agent.LoadTaskConfigsFromFile(&quot;tasks.yaml&quot;)
	if err != nil {
		log.Fatalf(&quot;Failed to load task configurations: %v&quot;, err)
	}

	// Create variables map for template substitution
	variables := map[string]string{
		&quot;topic&quot;: &quot;Artificial Intelligence&quot;,
	}

	// Create the agent for a specific task
	taskName := &quot;research_task&quot;
	agent, err := agent.CreateAgentForTask(taskName, agentConfigs, taskConfigs, variables, agent.WithLLM(llm))
	if err != nil {
		log.Fatalf(&quot;Failed to create agent for task: %v&quot;, err)
	}

	// Execute the task
	fmt.Printf(&quot;Executing task &#039;%s&#039; with topic &#039;%s&#039;...\n&quot;, taskName, variables[&quot;topic&quot;])
	result, err := agent.ExecuteTaskFromConfig(context.Background(), taskName, taskConfigs, variables)
	if err != nil {
		log.Fatalf(&quot;Failed to execute task: %v&quot;, err)
	}

	// Print the result
	fmt.Println(&quot;\nTask Result:&quot;)
	fmt.Println(result)
}
```

Example YAML configurations:

**agents.yaml**:
```yaml
researcher:
  role: &gt;
    {topic} Senior Data Researcher
  goal: &gt;
    Uncover cutting-edge developments in {topic}
  backstory: &gt;
    You&#039;re a seasoned researcher with a knack for uncovering the latest
    developments in {topic}. Known for your ability to find the most relevant
    information and present it in a clear and concise manner.

reporting_analyst:
  role: &gt;
    {topic} Reporting Analyst
  goal: &gt;
    Create detailed reports based on {topic} data analysis and research findings
  backstory: &gt;
    You&#039;re a meticulous analyst with a keen eye for detail. You&#039;re known for
    your ability to turn complex data into clear and concise reports, making
    it easy for others to understand and act on the information you provide.
```

**tasks.yaml**:
```yaml
research_task:
  description: &gt;
    Conduct a thorough research about {topic}
    Make sure you find any interesting and relevant information given
    the current year is 2025.
  expected_output: &gt;
    A list with 10 bullet points of the most relevant information about {topic}
  agent: researcher

reporting_task:
  description: &gt;
    Review the context you got and expand each topic into a full section for a report.
    Make sure the report is detailed and contains any and all relevant information.
  expected_output: &gt;
    A fully fledged report with the main topics, each with a full section of information.
    Formatted as markdown without &#039;```&#039;
  agent: reporting_analyst
  output_file: &quot;{topic}_report.md&quot;
```

### Auto-Generating Agent Configurations

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;os&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/agent&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/config&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/openai&quot;
)

func main() {
	// Load configuration
	cfg := config.Get()

	// Create LLM client
	openaiClient := openai.NewClient(cfg.LLM.OpenAI.APIKey)

	// Create agent with auto-configuration from system prompt
	agent, err := agent.NewAgentWithAutoConfig(
		context.Background(),
		agent.WithLLM(openaiClient),
		agent.WithSystemPrompt(&quot;You are a travel advisor who helps users plan trips and vacations. You specialize in finding hidden gems and creating personalized itineraries based on travelers&#039; preferences.&quot;),
		agent.WithName(&quot;Travel Assistant&quot;),
	)
	if err != nil {
		panic(err)
	}

	// Access the generated configurations
	agentConfig := agent.GetGeneratedAgentConfig()
	taskConfigs := agent.GetGeneratedTaskConfigs()

	// Print generated agent details
	fmt.Printf(&quot;Generated Agent Role: %s\n&quot;, agentConfig.Role)
	fmt.Printf(&quot;Generated Agent Goal: %s\n&quot;, agentConfig.Goal)
	fmt.Printf(&quot;Generated Agent Backstory: %s\n&quot;, agentConfig.Backstory)

	// Print generated tasks
	fmt.Println(&quot;\nGenerated Tasks:&quot;)
	for taskName, taskConfig := range taskConfigs {
		fmt.Printf(&quot;- %s: %s\n&quot;, taskName, taskConfig.Description)
	}

	// Save the generated configurations to YAML files
	agentConfigMap := map[string]agent.AgentConfig{
		&quot;Travel Assistant&quot;: *agentConfig,
	}

	// Save agent configs to file
	agentYaml, _ := os.Create(&quot;agent_config.yaml&quot;)
	defer agentYaml.Close()
	agent.SaveAgentConfigsToFile(agentConfigMap, agentYaml)

	// Save task configs to file
	taskYaml, _ := os.Create(&quot;task_config.yaml&quot;)
	defer taskYaml.Close()
	agent.SaveTaskConfigsToFile(taskConfigs, taskYaml)

	// Use the auto-configured agent
	response, err := agent.Run(context.Background(), &quot;I want to plan a 3-day trip to Tokyo.&quot;)
	if err != nil {
		panic(err)
	}
	fmt.Println(response)
}
```

The auto-configuration feature uses LLM reasoning to derive a complete agent profile and associated tasks from a simple system prompt. The generated configurations include:

- **Agent Profile**: Role, goal, and backstory that define the agent&#039;s persona
- **Task Definitions**: Specialized tasks the agent can perform, with descriptions and expected outputs
- **Reusable YAML**: Save configurations for reuse in other applications

This approach dramatically reduces the effort needed to create specialized agents while ensuring consistency and quality.

### Using MCP Servers with an Agent

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;log&quot;
	&quot;os&quot;

	&quot;github.com/Ingenimax/agent-sdk-go/pkg/agent&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/interfaces&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/llm/openai&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/mcp&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/memory&quot;
	&quot;github.com/Ingenimax/agent-sdk-go/pkg/multitenancy&quot;
)

func main() {
	logger := log.New(os.Stderr, &quot;AGENT: &quot;, log.LstdFlags)

	// Create OpenAI LLM client
	apiKey := os.Getenv(&quot;OPENAI_API_KEY&quot;)
	if apiKey == &quot;&quot; {
		logger.Fatal(&quot;Please set the OPENAI_API_KEY environment variable.&quot;)
	}
	llm := openai.NewClient(apiKey, openai.WithModel(&quot;gpt-4o-mini&quot;))

	// Create MCP servers
	var mcpServers []interfaces.MCPServer

	// Connect to HTTP-based MCP server
	httpServer, err := mcp.NewHTTPServer(context.Background(), mcp.HTTPServerConfig{
		BaseURL: &quot;http://localhost:8083/mcp&quot;,
	})
	if err != nil {
		logger.Printf(&quot;Warning: Failed to initialize HTTP MCP server: %v&quot;, err)
	} else {
		mcpServers = append(mcpServers, httpServer)
		logger.Println(&quot;Successfully initialized HTTP MCP server.&quot;)
	}

	// Connect to stdio-based MCP server
	stdioServer, err := mcp.NewStdioServer(context.Background(), mcp.StdioServerConfig{
		Command: &quot;go&quot;,
		Args:    []string{&quot;run&quot;, &quot;./server-stdio/main.go&quot;},
	})
	if err != nil {
		logger.Printf(&quot;Warning: Failed to initialize STDIO MCP server: %v&quot;, err)
	} else {
		mcpServers = append(mcpServers, stdioServer)
		logger.Println(&quot;Successfully initialized STDIO MCP server.&quot;)
	}

	// Create agent with MCP server support
	myAgent, err := agent.NewAgent(
		agent.WithLLM(llm),
		agent.WithMCPServers(mcpServers),
		agent.WithMemory(memory.NewConversationBuffer()),
		agent.WithSystemPrompt(&quot;You are an AI assistant that can use tools from MCP servers.&quot;),
		agent.WithName(&quot;MCPAgent&quot;),
	)
	if err != nil {
		logger.Fatalf(&quot;Failed to create agent: %v&quot;, err)
	}

	// Create context with organization and conversation IDs
	ctx := context.Background()
	ctx = multitenancy.WithOrgID(ctx, &quot;default-org&quot;)
	ctx = context.WithValue(ctx, memory.ConversationIDKey, &quot;mcp-demo&quot;)

	// Run the agent with a query that will use MCP tools
	response, err := myAgent.Run(ctx, &quot;What time is it right now?&quot;)
	if err != nil {
		logger.Fatalf(&quot;Agent run failed: %v&quot;, err)
	}

	fmt.Println(&quot;Agent response:&quot;, response)
}
```

## Architecture

The SDK follows a modular architecture with these key components:

- **Agent**: Coordinates the LLM, memory, and tools
- **LLM**: Interface to language model providers (OpenAI, Anthropic, Google Vertex AI)
- **Memory**: Stores conversation history and context
- **Tools**: Extend the agent&#039;s capabilities
- **Vector Store**: For semantic search and retrieval
- **Guardrails**: Ensures safe and responsible AI usage
- **Execution Plan**: Manages planning, approval, and execution of complex tasks
- **Configuration**: YAML-based agent and task definitions

### Supported LLM Providers

- **OpenAI**: GPT-4, GPT-3.5, and other OpenAI models
- **Anthropic**: Claude 3.5 Sonnet, Claude 3 Haiku, and other Claude models  
- **Google Vertex AI**: Gemini 1.5 Pro, Gemini 1.5 Flash, Gemini 2.0 Flash, and Gemini Pro Vision
  - Advanced reasoning modes (none, minimal, comprehensive)
  - Multimodal capabilities with vision models
  - Function calling and tool integration
  - Flexible authentication (ADC or service account files)

## Examples

Check out the `cmd/examples` directory for complete examples:

- **Simple Agent**: Basic agent with system prompt
- **YAML Configuration**: Defining agents and tasks in YAML
- **Auto-Configuration**: Generating agent configurations from system prompts
- **Agent Config Wizard**: Interactive CLI for creating and using agents
- **MCP Integration**: Using Model Context Protocol servers with agents
- **Multi-LLM Support**: Examples using OpenAI, Anthropic, and Vertex AI
- **Vertex AI Integration**: Comprehensive examples with Gemini models, reasoning modes, and tools

### LLM Provider Examples

- `examples/llm/openai/`: OpenAI integration examples
- `examples/llm/anthropic/`: Anthropic Claude integration examples  
- `examples/llm/vertex/`: Google Vertex AI integration examples with Gemini models

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Documentation

For more detailed information, refer to the following documents:

- [Environment Variables](docs/environment_variables.md)
- [Memory](docs/memory.md)
- [Tracing](docs/tracing.md)
- [Vector Store](docs/vectorstore.md)
- [LLM](docs/llm.md)
- [Multitenancy](docs/multitenancy.md)
- [Task](docs/task.md)
- [Tools](docs/tools.md)
- [Agent](docs/agent.md)
- [Execution Plan](docs/execution_plan.md)
- [Guardrails](docs/guardrails.md)
- [MCP](docs/mcp.md)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[etcd-io/etcd]]></title>
            <link>https://github.com/etcd-io/etcd</link>
            <guid>https://github.com/etcd-io/etcd</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Distributed reliable key-value store for the most critical data of a distributed system]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/etcd-io/etcd">etcd-io/etcd</a></h1>
            <p>Distributed reliable key-value store for the most critical data of a distributed system</p>
            <p>Language: Go</p>
            <p>Stars: 49,650</p>
            <p>Forks: 10,083</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># etcd

[![Go Report Card](https://goreportcard.com/badge/github.com/etcd-io/etcd?style=flat-square)](https://goreportcard.com/report/github.com/etcd-io/etcd)
[![Coverage](https://codecov.io/gh/etcd-io/etcd/branch/main/graph/badge.svg)](https://app.codecov.io/gh/etcd-io/etcd/tree/main)
[![Tests](https://github.com/etcd-io/etcd/actions/workflows/tests.yaml/badge.svg)](https://github.com/etcd-io/etcd/actions/workflows/tests.yaml)
[![codeql-analysis](https://github.com/etcd-io/etcd/actions/workflows/codeql-analysis.yml/badge.svg)](https://github.com/etcd-io/etcd/actions/workflows/codeql-analysis.yml)
[![Docs](https://img.shields.io/badge/docs-latest-green.svg)](https://etcd.io/docs)
[![Godoc](http://img.shields.io/badge/go-documentation-blue.svg?style=flat-square)](https://godocs.io/go.etcd.io/etcd/v3)
[![Releases](https://img.shields.io/github/release/etcd-io/etcd/all.svg?style=flat-square)](https://github.com/etcd-io/etcd/releases)
[![LICENSE](https://img.shields.io/github/license/etcd-io/etcd.svg?style=flat-square)](https://github.com/etcd-io/etcd/blob/main/LICENSE)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/etcd-io/etcd/badge)](https://scorecard.dev/viewer/?uri=github.com/etcd-io/etcd)

**Note**: The `main` branch may be in an *unstable or even broken state* during development. For stable versions, see [releases][github-release].

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/cncf/artwork/9870640f123303a355611065195c43ac3f27aa19/projects/etcd/horizontal/white/etcd-horizontal-white.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;logos/etcd-horizontal-color.svg&quot;&gt;
  &lt;img alt=&quot;etcd logo&quot; src=&quot;logos/etcd-horizontal-color.svg&quot; width=269 /&gt;
&lt;/picture&gt;

etcd is a distributed reliable key-value store for the most critical data of a distributed system, with a focus on being:

* *Simple*: well-defined, user-facing API (gRPC)
* *Secure*: automatic TLS with optional client cert authentication
* *Fast*: benchmarked 10,000 writes/sec
* *Reliable*: properly distributed using Raft

etcd is written in Go and uses the [Raft][] consensus algorithm to manage a highly-available replicated log.

etcd is used [in production by many companies](./ADOPTERS.md), and the development team stands behind it in critical deployment scenarios, where etcd is frequently teamed with applications such as [Kubernetes][k8s], [locksmith][], [vulcand][], [Doorman][], and many others. Reliability is further ensured by rigorous [**robustness testing**](https://github.com/etcd-io/etcd/tree/main/tests/robustness).

See [etcdctl][etcdctl] for a simple command line client.

![etcd reliability is important](logos/etcd-xkcd-2347.png)

&lt;sub&gt;Original image credited to  xkcd.com/2347, alterations by Josh Berkus.&lt;/sub&gt;

[raft]: https://raft.github.io/
[k8s]: http://kubernetes.io/
[doorman]: https://github.com/youtube/doorman
[locksmith]: https://github.com/coreos/locksmith
[vulcand]: https://github.com/vulcand/vulcand
[etcdctl]: https://github.com/etcd-io/etcd/tree/main/etcdctl

## Documentation

The most common API documentation you&#039;ll need can be found here:

* [go.etcd.io/etcd/api/v3](https://godocs.io/go.etcd.io/etcd/api/v3)
* [go.etcd.io/etcd/client/pkg/v3](https://godocs.io/go.etcd.io/etcd/client/pkg/v3)
* [go.etcd.io/etcd/client/v3](https://godocs.io/go.etcd.io/etcd/client/v3)
* [go.etcd.io/etcd/etcdctl/v3](https://godocs.io/go.etcd.io/etcd/etcdctl/v3)
* [go.etcd.io/etcd/pkg/v3](https://godocs.io/go.etcd.io/etcd/pkg/v3)
* [go.etcd.io/etcd/raft/v3](https://godocs.io/go.etcd.io/etcd/raft/v3)
* [go.etcd.io/etcd/server/v3](https://godocs.io/go.etcd.io/etcd/server/v3)

## Maintainers

[Maintainers](OWNERS) strive to shape an inclusive open source project culture where users are heard and contributors feel respected and empowered. Maintainers aim to build productive relationships across different companies and disciplines. Read more about [Maintainers role and responsibilities](Documentation/contributor-guide/community-membership.md#maintainers).

## Getting started

### Getting etcd

The easiest way to get etcd is to use one of the pre-built release binaries which are available for OSX, Linux, Windows, and Docker on the [release page][github-release].

For more installation guides, please check out [play.etcd.io](http://play.etcd.io) and [operating etcd](https://etcd.io/docs/latest/op-guide).

[github-release]: https://github.com/etcd-io/etcd/releases

### Running etcd

First start a single-member cluster of etcd.

If etcd is installed using the [pre-built release binaries][github-release], run it from the installation location as below:

```bash
/tmp/etcd-download-test/etcd
```

The etcd command can be simply run as such if it is moved to the system path as below:

```bash
mv /tmp/etcd-download-test/etcd /usr/local/bin/
etcd
```

This will bring up etcd listening on port 2379 for client communication and on port 2380 for server-to-server communication.

Next, let&#039;s set a single key, and then retrieve it:

```bash
etcdctl put mykey &quot;this is awesome&quot;
etcdctl get mykey
```

etcd is now running and serving client requests. For more, please check out:

* [Interactive etcd playground](http://play.etcd.io)
* [Animated quick demo](https://etcd.io/docs/latest/demo)

### etcd TCP ports

The [official etcd ports][iana-ports] are 2379 for client requests, and 2380 for peer communication.

[iana-ports]: http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt

### Running a local etcd cluster

First install [goreman](https://github.com/mattn/goreman), which manages Procfile-based applications.

Our [Procfile script](./Procfile) will set up a local example cluster. Start it with:

```bash
goreman start
```

This will bring up 3 etcd members `infra1`, `infra2` and `infra3` and optionally etcd `grpc-proxy`, which runs locally and composes a cluster.

Every cluster member and proxy accepts key value reads and key value writes.

Follow the comments in [Procfile script](./Procfile) to add a learner node to the cluster.

### Install etcd client v3

```bash
go get go.etcd.io/etcd/client/v3
```

### Next steps

Now it&#039;s time to dig into the full etcd API and other guides.

* Read the full [documentation].
* Review etcd [frequently asked questions].
* Explore the full gRPC [API].
* Set up a [multi-machine cluster][clustering].
* Learn the [config format, env variables and flags][configuration].
* Find [language bindings and tools][integrations].
* Use TLS to [secure an etcd cluster][security].
* [Tune etcd][tuning].

[documentation]: https://etcd.io/docs/latest
[api]: https://etcd.io/docs/latest/learning/api
[clustering]: https://etcd.io/docs/latest/op-guide/clustering
[configuration]: https://etcd.io/docs/latest/op-guide/configuration
[integrations]: https://etcd.io/docs/latest/integrations
[security]: https://etcd.io/docs/latest/op-guide/security
[tuning]: https://etcd.io/docs/latest/tuning

## Contact

* Email: [etcd-dev](https://groups.google.com/g/etcd-dev)
* Slack: [#sig-etcd](https://kubernetes.slack.com/archives/C3HD8ARJ5) channel on Kubernetes ([get an invite](http://slack.kubernetes.io/))
* [Community meetings](#community-meetings)

### Community meetings

etcd contributors and maintainers meet every week at `11:00` AM (USA Pacific) on Thursday and meetings alternate between community meetings and issue triage meetings. Meeting agendas are recorded in a [shared Google doc][shared-meeting-notes] and everyone is welcome to suggest additional topics or other agendas.

Issue triage meetings are aimed at getting through our backlog of PRs and Issues. Triage meetings are open to any contributor; you don&#039;t have to be a reviewer or approver to help out! They can also be a good way to get started contributing.

The meeting lead role is rotated for each meeting between etcd maintainers or sig-etcd leads and is recorded in a [shared Google sheet][shared-rotation-sheet].

Meeting recordings are uploaded to the official etcd [YouTube channel].

Get calendar invitations by joining [etcd-dev](https://groups.google.com/g/etcd-dev) mailing group.

Join the CNCF-funded Zoom channel: [zoom.us/my/cncfetcdproject](https://zoom.us/my/cncfetcdproject)

[shared-meeting-notes]: https://docs.google.com/document/d/16XEGyPBisZvmmoIHSZzv__LoyOeluC5a4x353CX0SIM/edit
[shared-rotation-sheet]: https://docs.google.com/spreadsheets/d/1jodHIO7Dk2VWTs1IRnfMFaRktS9IH8XRyifOnPdSY8I/edit
[YouTube channel]: https://www.youtube.com/@etcdio

## Contributing

See [CONTRIBUTING](CONTRIBUTING.md) for details on setting up your development environment, submitting patches and the contribution workflow.

Please refer to [community-membership.md](Documentation/contributor-guide/community-membership.md#member) for information on becoming an etcd project member.  We welcome and look forward to your contributions to the project!

Please also refer to [roadmap](Documentation/contributor-guide/roadmap.md) to get more details on the priorities for the next few major or minor releases.

## Reporting bugs

See [reporting bugs](https://github.com/etcd-io/etcd/blob/main/Documentation/contributor-guide/reporting_bugs.md) for details about reporting any issues. Before opening an issue please check it is not covered in our [frequently asked questions].

[frequently asked questions]: https://etcd.io/docs/latest/faq

## Reporting a security vulnerability

See [security disclosure and release process](security/README.md) for details on how to report a security vulnerability and how the etcd team manages it.

## Issue and PR management

See [issue triage guidelines](https://github.com/etcd-io/etcd/blob/main/Documentation/contributor-guide/triage_issues.md) for details on how issues are managed.

See [PR management](https://github.com/etcd-io/etcd/blob/main/Documentation/contributor-guide/triage_prs.md) for guidelines on how pull requests are managed.

## etcd Emeritus Maintainers

These emeritus maintainers dedicated a part of their career to etcd and reviewed code, triaged bugs and pushed the project forward over a substantial period of time. Their contribution is greatly appreciated.

* Fanmin Shi
* Anthony Romano
* Brandon Philips
* Joe Betz
* Gyuho Lee
* Jingyi Hu
* Xiang Li
* Ben Darnell
* Sam Batschelet
* Piotr Tabor
* Hitoshi Mitake

### License

etcd is under the Apache 2.0 license. See the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[manusa/kubernetes-mcp-server]]></title>
            <link>https://github.com/manusa/kubernetes-mcp-server</link>
            <guid>https://github.com/manusa/kubernetes-mcp-server</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[Model Context Protocol (MCP) server for Kubernetes and OpenShift]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/manusa/kubernetes-mcp-server">manusa/kubernetes-mcp-server</a></h1>
            <p>Model Context Protocol (MCP) server for Kubernetes and OpenShift</p>
            <p>Language: Go</p>
            <p>Stars: 291</p>
            <p>Forks: 53</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># Kubernetes MCP Server

[![GitHub License](https://img.shields.io/github/license/manusa/kubernetes-mcp-server)](https://github.com/manusa/kubernetes-mcp-server/blob/main/LICENSE)
[![npm](https://img.shields.io/npm/v/kubernetes-mcp-server)](https://www.npmjs.com/package/kubernetes-mcp-server)
[![PyPI - Version](https://img.shields.io/pypi/v/kubernetes-mcp-server)](https://pypi.org/project/kubernetes-mcp-server/)
[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/manusa/kubernetes-mcp-server?sort=semver)](https://github.com/manusa/kubernetes-mcp-server/releases/latest)
[![Build](https://github.com/manusa/kubernetes-mcp-server/actions/workflows/build.yaml/badge.svg)](https://github.com/manusa/kubernetes-mcp-server/actions/workflows/build.yaml)

[‚ú® Features](#features) | [üöÄ Getting Started](#getting-started) | [üé• Demos](#demos) | [‚öôÔ∏è Configuration](#configuration) | [üõ†Ô∏è Tools](#tools) | [üßë‚Äçüíª Development](#development)

https://github.com/user-attachments/assets/be2b67b3-fc1c-4d11-ae46-93deba8ed98e

## ‚ú® Features &lt;a id=&quot;features&quot;&gt;&lt;/a&gt;

A powerful and flexible Kubernetes [Model Context Protocol (MCP)](https://blog.marcnuri.com/model-context-protocol-mcp-introduction) server implementation with support for **Kubernetes** and **OpenShift**.

- **‚úÖ Configuration**:
  - Automatically detect changes in the Kubernetes configuration and update the MCP server.
  - **View** and manage the current [Kubernetes `.kube/config`](https://blog.marcnuri.com/where-is-my-default-kubeconfig-file) or in-cluster configuration.
- **‚úÖ Generic Kubernetes Resources**: Perform operations on **any** Kubernetes or OpenShift resource.
  - Any CRUD operation (Create or Update, Get, List, Delete).
- **‚úÖ Pods**: Perform Pod-specific operations.
  - **List** pods in all namespaces or in a specific namespace.
  - **Get** a pod by name from the specified namespace.
  - **Delete** a pod by name from the specified namespace.
  - **Show logs** for a pod by name from the specified namespace.
  - **Top** gets resource usage metrics for all pods or a specific pod in the specified namespace.
  - **Exec** into a pod and run a command.
  - **Run** a container image in a pod and optionally expose it.
- **‚úÖ Namespaces**: List Kubernetes Namespaces.
- **‚úÖ Events**: View Kubernetes events in all namespaces or in a specific namespace.
- **‚úÖ Projects**: List OpenShift Projects.
- **‚ò∏Ô∏è Helm**:
  - **Install** a Helm chart in the current or provided namespace.
  - **List** Helm releases in all namespaces or in a specific namespace.
  - **Uninstall** a Helm release in the current or provided namespace.

Unlike other Kubernetes MCP server implementations, this **IS NOT** just a wrapper around `kubectl` or `helm` command-line tools.
It is a **Go-based native implementation** that interacts directly with the Kubernetes API server.

There is **NO NEED** for external dependencies or tools to be installed on the system.
If you&#039;re using the native binaries you don&#039;t need to have Node or Python installed on your system.

- **‚úÖ Lightweight**: The server is distributed as a single native binary for Linux, macOS, and Windows.
- **‚úÖ High-Performance / Low-Latency**: Directly interacts with the Kubernetes API server without the overhead of calling and waiting for external commands.
- **‚úÖ Cross-Platform**: Available as a native binary for Linux, macOS, and Windows, as well as an npm package, a Python package, and container/Docker image.
- **‚úÖ Configurable**: Supports [command-line arguments](#configuration)  to configure the server behavior.
- **‚úÖ Well tested**: The server has an extensive test suite to ensure its reliability and correctness across different Kubernetes environments.

## üöÄ Getting Started &lt;a id=&quot;getting-started&quot;&gt;&lt;/a&gt;

### Requirements

- Access to a Kubernetes cluster.

### Claude Desktop

#### Using npx

If you have npm installed, this is the fastest way to get started with `kubernetes-mcp-server` on Claude Desktop.

Open your `claude_desktop_config.json` and add the mcp server to the list of `mcpServers`:
``` json
{
  &quot;mcpServers&quot;: {
    &quot;kubernetes&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [
        &quot;-y&quot;,
        &quot;kubernetes-mcp-server@latest&quot;
      ]
    }
  }
}
```

### VS Code / VS Code Insiders

Install the Kubernetes MCP server extension in VS Code Insiders by pressing the following link:

[&lt;img src=&quot;https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&amp;label=Install%20Server&amp;color=0098FF&quot; alt=&quot;Install in VS Code&quot;&gt;](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522kubernetes%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522kubernetes-mcp-server%2540latest%2522%255D%257D)
[&lt;img alt=&quot;Install in VS Code Insiders&quot; src=&quot;https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&amp;label=Install%20Server&amp;color=24bfa5&quot;&gt;](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522kubernetes%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522kubernetes-mcp-server%2540latest%2522%255D%257D)

Alternatively, you can install the extension manually by running the following command:

```shell
# For VS Code
code --add-mcp &#039;{&quot;name&quot;:&quot;kubernetes&quot;,&quot;command&quot;:&quot;npx&quot;,&quot;args&quot;:[&quot;kubernetes-mcp-server@latest&quot;]}&#039;
# For VS Code Insiders
code-insiders --add-mcp &#039;{&quot;name&quot;:&quot;kubernetes&quot;,&quot;command&quot;:&quot;npx&quot;,&quot;args&quot;:[&quot;kubernetes-mcp-server@latest&quot;]}&#039;
```

### Goose CLI

[Goose CLI](https://blog.marcnuri.com/goose-on-machine-ai-agent-cli-introduction) is the easiest (and cheapest) way to get rolling with artificial intelligence (AI) agents.

#### Using npm

If you have npm installed, this is the fastest way to get started with `kubernetes-mcp-server`.

Open your goose `config.yaml` and add the mcp server to the list of `mcpServers`:
```yaml
extensions:
  kubernetes:
    command: npx
    args:
      - -y
      - kubernetes-mcp-server@latest

```

## üé• Demos &lt;a id=&quot;demos&quot;&gt;&lt;/a&gt;

### Diagnosing and automatically fixing an OpenShift Deployment

Demo showcasing how Kubernetes MCP server is leveraged by Claude Desktop to automatically diagnose and fix a deployment in OpenShift without any user assistance.

https://github.com/user-attachments/assets/a576176d-a142-4c19-b9aa-a83dc4b8d941

### _Vibe Coding_ a simple game and deploying it to OpenShift

In this demo, I walk you through the process of _Vibe Coding_ a simple game using VS Code and how to leverage [Podman MCP server](https://github.com/manusa/podman-mcp-server) and Kubernetes MCP server to deploy it to OpenShift.

&lt;a href=&quot;https://www.youtube.com/watch?v=l05jQDSrzVI&quot; target=&quot;_blank&quot;&gt;
 &lt;img src=&quot;docs/images/vibe-coding.jpg&quot; alt=&quot;Vibe Coding: Build &amp; Deploy a Game on Kubernetes&quot; width=&quot;240&quot;  /&gt;
&lt;/a&gt;

### Supercharge GitHub Copilot with Kubernetes MCP Server in VS Code - One-Click Setup!

In this demo, I&#039;ll show you how to set up Kubernetes MCP server in VS code just by clicking a link.

&lt;a href=&quot;https://youtu.be/AI4ljYMkgtA&quot; target=&quot;_blank&quot;&gt;
 &lt;img src=&quot;docs/images/kubernetes-mcp-server-github-copilot.jpg&quot; alt=&quot;Supercharge GitHub Copilot with Kubernetes MCP Server in VS Code - One-Click Setup!&quot; width=&quot;240&quot;  /&gt;
&lt;/a&gt;

## ‚öôÔ∏è Configuration &lt;a id=&quot;configuration&quot;&gt;&lt;/a&gt;

The Kubernetes MCP server can be configured using command line (CLI) arguments.

You can run the CLI executable either by using `npx`, `uvx`, or by downloading the [latest release binary](https://github.com/manusa/kubernetes-mcp-server/releases/latest).

```shell
# Run the Kubernetes MCP server using npx (in case you have npm and node installed)
npx kubernetes-mcp-server@latest --help
```

```shell
# Run the Kubernetes MCP server using uvx (in case you have uv and python installed)
uvx kubernetes-mcp-server@latest --help
```

```shell
# Run the Kubernetes MCP server using the latest release binary
./kubernetes-mcp-server --help
```

### Configuration Options

| Option                  | Description                                                                                                                                                                                                                                                                                   |
|-------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `--http-port`           | Starts the MCP server in Streamable HTTP mode and listens on the specified port (path /mcp).                                                                                                                                                                                                  |
| `--sse-port`            | Starts the MCP server in Server-Sent Event (SSE) mode and listens on the specified port (path /sse).                                                                                                                                                                                          |
| `--log-level`           | Sets the logging level (values [from 0-9](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md)). Similar to [kubectl logging levels](https://kubernetes.io/docs/reference/kubectl/quick-reference/#kubectl-output-verbosity-and-debugging). |
| `--kubeconfig`          | Path to the Kubernetes configuration file. If not provided, it will try to resolve the configuration (in-cluster, default location, etc.).                                                                                                                                                    |
| `--list-output`         | Output format for resource list operations (one of: yaml, table) (default &quot;table&quot;)                                                                                                                                                                                                            |
| `--read-only`           | If set, the MCP server will run in read-only mode, meaning it will not allow any write operations (create, update, delete) on the Kubernetes cluster. This is useful for debugging or inspecting the cluster without making changes.                                                          |
| `--disable-destructive` | If set, the MCP server will disable all destructive operations (delete, update, etc.) on the Kubernetes cluster. This is useful for debugging or inspecting the cluster without accidentally making changes. This option has no effect when `--read-only` is used.                            |

## üõ†Ô∏è Tools &lt;a id=&quot;tools&quot;&gt;&lt;/a&gt;

### `configuration_view`

Get the current Kubernetes configuration content as a kubeconfig YAML

**Parameters:**
- `minified` (`boolean`, optional, default: `true`)
  - Return a minified version of the configuration
  - If `true`, keeps only the current-context and relevant configuration pieces
  - If `false`, returns all contexts, clusters, auth-infos, and users

### `events_list`

List all the Kubernetes events in the current cluster from all namespaces

**Parameters:**
- `namespace` (`string`, optional)
  - Namespace to retrieve the events from. If not provided, will list events from all namespaces

### `helm_install`

Install a Helm chart in the current or provided namespace with the provided name and chart

**Parameters:**
- `chart` (`string`, required)
  - Name of the Helm chart to install
  - Can be a local path or a remote URL
  - Example: `./my-chart.tgz` or `https://example.com/my-chart.tgz`
- `values` (`object`, optional)
  - Values to pass to the Helm chart
  - Example: `{&quot;key&quot;: &quot;value&quot;}`
- `name` (`string`, optional)
  - Name of the Helm release
  - Random name if not provided
- `namespace` (`string`, optional)
  - Namespace to install the Helm chart in
  - If not provided, will use the configured namespace

### `helm_list`

List all the Helm releases in the current or provided namespace (or in all namespaces if specified)

**Parameters:**
- `namespace` (`string`, optional)
  - Namespace to list the Helm releases from
  - If not provided, will use the configured namespace
- `all_namespaces` (`boolean`, optional)
  - If `true`, will list Helm releases from all namespaces
  - If `false`, will list Helm releases from the specified namespace

### `helm_uninstall`

Uninstall a Helm release in the current or provided namespace with the provided name

**Parameters:**
- `name` (`string`, required)
  - Name of the Helm release to uninstall
- `namespace` (`string`, optional)
  - Namespace to uninstall the Helm release from
  - If not provided, will use the configured namespace

### `namespaces_list`

List all the Kubernetes namespaces in the current cluster

**Parameters:** None

### `pods_delete`

Delete a Kubernetes Pod in the current or provided namespace with the provided name

**Parameters:**
- `name` (`string`, required)
  - Name of the Pod to delete
- `namespace` (`string`, required)
  - Namespace to delete the Pod from

### `pods_exec`

Execute a command in a Kubernetes Pod in the current or provided namespace with the provided name and command

**Parameters:**
- `command` (`string[]`, required)
  - Command to execute in the Pod container
  - First item is the command, rest are arguments
  - Example: `[&quot;ls&quot;, &quot;-l&quot;, &quot;/tmp&quot;]`
- `name` (string, required)
  - Name of the Pod
- `namespace` (string, required)
  - Namespace of the Pod
- `container` (`string`, optional)
  - Name of the Pod container to get logs from

### `pods_get`

Get a Kubernetes Pod in the current or provided namespace with the provided name

**Parameters:**
- `name` (`string`, required)
  - Name of the Pod
- `namespace` (`string`, required)
  - Namespace to get the Pod from

### `pods_list`

List all the Kubernetes pods in the current cluster from all namespaces

**Parameters:**
- `labelSelector` (`string`, optional)
  - Kubernetes label selector (e.g., &#039;app=myapp,env=prod&#039; or &#039;app in (myapp,yourapp)&#039;). Use this option to filter the pods by label

### `pods_list_in_namespace`

List all the Kubernetes pods in the specified namespace in the current cluster

**Parameters:**
- `namespace` (`string`, required)
  - Namespace to list pods from
- `labelSelector` (`string`, optional)
  - Kubernetes label selector (e.g., &#039;app=myapp,env=prod&#039; or &#039;app in (myapp,yourapp)&#039;). Use this option to filter the pods by label

### `pods_log`

Get the logs of a Kubernetes Pod in the current or provided namespace with the provided name

**Parameters:**
- `name` (`string`, required)
  - Name of the Pod to get logs from
- `namespace` (`string`, required)
  - Namespace to get the Pod logs from
- `container` (`string`, optional)
  - Name of the Pod container to get logs from

### `pods_run`

Run a Kubernetes Pod in the current or provided namespace with the provided container image and optional name

**Parameters:**
- `image` (`string`, required)
  - Container Image to run in the Pod
- `namespace` (`string`, required)
  - Namespace to run the Pod in
- `name` (`string`, optional)
  - Name of the Pod (random name if not provided)
- `port` (`number`, optional)
  - TCP/IP port to expose from the Pod container
  - No port exposed if not provided

### `pods_top`

Lists the resource consumption (CPU and memory) as recorded by the Kubernetes Metrics Server for the specified Kubernetes Pods in the all namespaces, the provided namespace, or the current namespace

**Parameters:**
- `all_namespaces` (`boolean`, optional, default: `true`)
  - If `true`, lists resource consumption for Pods in all namespaces
  - If `false`, lists resource consumption for Pods in the configured or provided namespace
- `namespace` (`string`, optional)
  - Namespace to list the Pod resources from
  - If not provided, will list Pods from the configured namespace (in case all_namespaces is false)
- `name` (`string`, optional)
  - Name of the Pod to get resource consumption from
  - If not provided, will list resource consumption for all Pods in the applicable namespace(s)
- `label_selector` (`string`, optional)
  - Kubernetes label selector (e.g. &#039;app=myapp,env=prod&#039; or &#039;app in (myapp,yourapp)&#039;), use this option when you want to filter the pods by label (Optional, only applicable when name is not provided)

### `projects_list`

List all the OpenShift projects in the current cluster

### `resources_create_or_update`

Create or update a Kubernetes resource in the current cluster by providing a YAML or JSON representation of the resource

**Parameters:**
- `resource` (`string`, required)
  - A JSON or YAML containing a representation of the Kubernetes resource
  - Should include top-level fields such as apiVersion, kind, metadata, and spec

**Common apiVersion and kind include:**
- v1 Pod
- v1 Service
- v1 Node
- apps/v1 Deployment
- networking.k8s.io/v1 Ingress

### `resources_delete`

Delete a Kubernetes resource in the current cluster

**Parameters:**
- `apiVersion` (`string`, required)
  - apiVersion of the resource (e.g., `v1`, `apps/v1`, `networking.k8s.io/v1`)
- `kind` (`string`, required)
  - kind of the resource (e.g., `Pod`, `Service`, `Deployment`, `Ingress`)
- `name` (`string`, required)
  - Name of the resource
- `namespace` (`string`, optional)
  - Namespace to delete the namespaced resource from
  - Ignored for cluster-scoped resources
  - Uses configured namespace if not provided

### `resources_get`

Get a Kubernetes resource in the current cluster

**Parameters:**
- `apiVersion` (`string`, required)
  - apiVersion of the resource (e.g., `v1`, `apps/v1`, `networking.k8s.io/v1`)
- `kind` (`string`, required)
  - kind of the resource (e.g., `Pod`, `Service`, `Deployment`, `Ingress`)
- `name` (`string`, required)
  - Name of the resource
- `namespace` (`string`, optional)
  - Namespace to retrieve the namespaced resource from
  - Ignored for cluster-scoped resources
  - Uses configured namespace if not provided

### `resources_list`

List Kubernetes resources and objects in the current cluster

**Parameters:**
- `apiVersion` (`string`, required)
  - apiVersion of the resources (e.g., `v1`, `apps/v1`, `networking.k8s.io/v1`)
- `kind` (`string`, required)
  - kind of the resources (e.g., `Pod`, `Service`, `Deployment`, `Ingress`)
- `namespace` (`string`, optional)
  - Namespace to retrieve the namespaced resources from
  - Ignored for cluster-scoped resources
  - Lists resources from all namespaces if not provided
- `labelSelector` (`string`, optional)
  - Kubernetes label selector (e.g., &#039;app=myapp,env=prod&#039; or &#039;app in (myapp,yourapp)&#039;). Use this option to filter the pods by label.

## üßë‚Äçüíª Development &lt;a id=&quot;development&quot;&gt;&lt;/a&gt;

### Running with mcp-inspector

Compile the project and run the Kubernetes MCP server with [mcp-inspector](https://modelcontextprotocol.io/docs/tools/inspector) to inspect the MCP server.

```shell
# Compile the project
make build
# Run the Kubernetes MCP server with mcp-inspector
npx @modelcontextprotocol/inspector@latest $(pwd)/kubernetes-mcp-server
```
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[external-secrets/external-secrets]]></title>
            <link>https://github.com/external-secrets/external-secrets</link>
            <guid>https://github.com/external-secrets/external-secrets</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[External Secrets Operator reads information from a third-party service like AWS Secrets Manager and automatically injects the values as Kubernetes Secrets.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/external-secrets/external-secrets">external-secrets/external-secrets</a></h1>
            <p>External Secrets Operator reads information from a third-party service like AWS Secrets Manager and automatically injects the values as Kubernetes Secrets.</p>
            <p>Language: Go</p>
            <p>Stars: 5,111</p>
            <p>Forks: 978</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;assets/eso-logo-large.png&quot; width=&quot;30%&quot; align=&quot;center&quot; alt=&quot;external-secrets&quot;&gt;
&lt;/p&gt;

# External Secrets

![ci](https://github.com/external-secrets/external-secrets/actions/workflows/ci.yml/badge.svg?branch=main)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5327/badge)](https://bestpractices.coreinfrastructure.org/projects/5947)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/external-secrets/external-secrets/badge)](https://securityscorecards.dev/viewer/?uri=github.com/external-secrets/external-secrets)
[![Go Report Card](https://goreportcard.com/badge/github.com/external-secrets/external-secrets)](https://goreportcard.com/report/github.com/external-secrets/external-secrets)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets?ref=badge_shield)
&lt;a href=&quot;https://artifacthub.io/packages/helm/external-secrets-operator/external-secrets&quot;&gt;&lt;img alt=&quot;Artifact Hub&quot; src=&quot;https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/external-secrets&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://operatorhub.io/operator/external-secrets-operator&quot;&gt;&lt;img alt=&quot;operatorhub.io&quot; src=&quot;https://img.shields.io/badge/operatorhub.io-external--secrets-brightgreen&quot; /&gt;&lt;/a&gt;

**External Secrets Operator** is a Kubernetes operator that integrates external
secret management systems like [AWS Secrets
Manager](https://aws.amazon.com/secrets-manager/), [HashiCorp
Vault](https://www.vaultproject.io/), [Google Secrets
Manager](https://cloud.google.com/secret-manager), [Azure Key
Vault](https://azure.microsoft.com/en-us/services/key-vault/), [IBM Cloud Secrets Manager](https://www.ibm.com/cloud/secrets-manager), [Akeyless](https://akeyless.io), [CyberArk Conjur](https://www.conjur.org), [Pulumi ESC](https://www.pulumi.com/product/esc/) and many more. The
operator reads information from external APIs and automatically injects the
values into a [Kubernetes
Secret](https://kubernetes.io/docs/concepts/configuration/secret/).

Multiple people and organizations are joining efforts to create a single External Secrets solution based on existing projects. If you are curious about the origins of this project, check out [this issue](https://github.com/external-secrets/kubernetes-external-secrets/issues/47) and [this PR](https://github.com/external-secrets/kubernetes-external-secrets/pull/477).

## Documentation

External Secrets Operator guides and reference documentation is available at [external-secrets.io](https://external-secrets.io). Also see our [stability and support](https://external-secrets.io/main/introduction/stability-support/) policy.

## Contributing

We welcome and encourage contributions to this project! Please read the [Developer](https://www.external-secrets.io/main/contributing/devguide/) and [Contribution process](https://www.external-secrets.io/main/contributing/process/) guides. Also make sure to check the [Code of Conduct](https://www.external-secrets.io/main/contributing/coc/) and adhere to its guidelines.

### Sponsoring

Please consider sponsoring this project, there are many ways you can help us with: engineering time, providing infrastructure, donating money, etc. We are open to cooperations, feel free to approach as and we discuss how this could look like. We can keep your contribution anonymized if that&#039;s required (depending on the type of contribution), and anonymous donations are possible inside [Opencollective](https://opencollective.com/external-secrets-org).

## Bi-weekly Development Meeting

We host our development meeting every odd wednesday on [Jitsi](https://meet.jit.si/eso-community-meeting). We run the meeting with alternating times [8:00 PM Berlin Time](https://dateful.com/time-zone-converter?t=20:00&amp;tz=Europe/Berlin) and [1:00 PM Berlin Time](https://dateful.com/time-zone-converter?t=13:00&amp;tz=Europe/Berlin), we&#039;ll announce the time in our [Kubernetes Slack
  channel](https://kubernetes.slack.com/messages/external-secrets). Meeting notes are recorded on [hackmd](https://hackmd.io/GSGEpTVdRZCP6LDxV3FHJA).

Anyone is welcome to join. Feel free to ask questions, request feedback, raise awareness for an issue, or just say hi. ;)

## Security

Please report vulnerabilities by email to cncf-ExternalSecretsOp-maintainers@lists.cncf.io. Also see our [SECURITY.md file](SECURITY.md) for details.

## software bill of materials
We attach SBOM and provenance file to our GitHub release. Also, they are attached to container images.

## Adopters

Please create a PR and add your company or project to our [ADOPTERS.md file](ADOPTERS.md) if you are using our project!

## Roadmap

You can find the roadmap in our documentation: https://external-secrets.io/main/contributing/roadmap/

## Kicked off by

![](assets/Godaddylogo_2020.png)

## Sponsored by

![External Secrets Inc.](assets/ESI_Logo.svg)
![Container Solutions](assets/CS_logo_1.png)
![Form 3](assets/form3_logo.png)
![Pento ](assets/pento_logo.png)


## License
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets?ref=badge_large)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[go-playground/validator]]></title>
            <link>https://github.com/go-playground/validator</link>
            <guid>https://github.com/go-playground/validator</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[üíØGo Struct and Field validation, including Cross Field, Cross Struct, Map, Slice and Array diving]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/go-playground/validator">go-playground/validator</a></h1>
            <p>üíØGo Struct and Field validation, including Cross Field, Cross Struct, Map, Slice and Array diving</p>
            <p>Language: Go</p>
            <p>Stars: 18,506</p>
            <p>Forks: 1,373</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>Package validator
=================
&lt;img align=&quot;right&quot; src=&quot;logo.png&quot;&gt;[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/go-playground/validator)](https://github.com/go-playground/validator/releases)
[![Build Status](https://github.com/go-playground/validator/actions/workflows/workflow.yml/badge.svg)](https://github.com/go-playground/validator/actions)
[![Coverage Status](https://coveralls.io/repos/go-playground/validator/badge.svg?branch=master&amp;service=github)](https://coveralls.io/github/go-playground/validator?branch=master)
[![Go Report Card](https://goreportcard.com/badge/github.com/go-playground/validator)](https://goreportcard.com/report/github.com/go-playground/validator)
[![GoDoc](https://godoc.org/github.com/go-playground/validator?status.svg)](https://pkg.go.dev/github.com/go-playground/validator/v10)
![License](https://img.shields.io/dub/l/vibe-d.svg)

Package validator implements value validations for structs and individual fields based on tags.

It has the following **unique** features:

-   Cross Field and Cross Struct validations by using validation tags or custom validators.
-   Slice, Array and Map diving, which allows any or all levels of a multidimensional field to be validated.
-   Ability to dive into both map keys and values for validation
-   Handles type interface by determining it&#039;s underlying type prior to validation.
-   Handles custom field types such as sql driver Valuer see [Valuer](https://golang.org/src/database/sql/driver/types.go?s=1210:1293#L29)
-   Alias validation tags, which allows for mapping of several validations to a single tag for easier defining of validations on structs
-   Extraction of custom defined Field Name e.g. can specify to extract the JSON name while validating and have it available in the resulting FieldError
-   Customizable i18n aware error messages.
-   Default validator for the [gin](https://github.com/gin-gonic/gin) web framework; upgrading from v8 to v9 in gin see [here](https://github.com/go-playground/validator/tree/master/_examples/gin-upgrading-overriding)

A Call for Maintainers
----------------------

Please read the discussiong started [here](https://github.com/go-playground/validator/discussions/1330) if you are interested in contributing/helping maintain this package.

Installation
------------

Use go get.

	go get github.com/go-playground/validator/v10

Then import the validator package into your own code.

	import &quot;github.com/go-playground/validator/v10&quot;

Error Return Value
-------

Validation functions return type error

They return type error to avoid the issue discussed in the following, where err is always != nil:

* http://stackoverflow.com/a/29138676/3158232
* https://github.com/go-playground/validator/issues/134

Validator returns only InvalidValidationError for bad validation input, nil or ValidationErrors as type error; so, in your code all you need to do is check if the error returned is not nil, and if it&#039;s not check if error is InvalidValidationError ( if necessary, most of the time it isn&#039;t ) type cast it to type ValidationErrors like so:

```go
err := validate.Struct(mystruct)
validationErrors := err.(validator.ValidationErrors)
 ```

Usage and documentation
------

Please see https://pkg.go.dev/github.com/go-playground/validator/v10 for detailed usage docs.

##### Examples:

- [Simple](https://github.com/go-playground/validator/blob/master/_examples/simple/main.go)
- [Custom Field Types](https://github.com/go-playground/validator/blob/master/_examples/custom/main.go)
- [Struct Level](https://github.com/go-playground/validator/blob/master/_examples/struct-level/main.go)
- [Translations &amp; Custom Errors](https://github.com/go-playground/validator/blob/master/_examples/translations/main.go)
- [Gin upgrade and/or override validator](https://github.com/go-playground/validator/tree/v9/_examples/gin-upgrading-overriding)
- [wash - an example application putting it all together](https://github.com/bluesuncorp/wash)

Baked-in Validations
------

### Special Notes:
- If new to using validator it is highly recommended to initialize it using the `WithRequiredStructEnabled` option which is opt-in to new behaviour that will become the default behaviour in v11+. See documentation for more details.
```go
validate := validator.New(validator.WithRequiredStructEnabled())
```

### Fields:

| Tag | Description |
| - | - |
| eqcsfield | Field Equals Another Field (relative)|
| eqfield | Field Equals Another Field |
| fieldcontains | Check the indicated characters are present in the Field |
| fieldexcludes | Check the indicated characters are not present in the field |
| gtcsfield | Field Greater Than Another Relative Field |
| gtecsfield | Field Greater Than or Equal To Another Relative Field |
| gtefield | Field Greater Than or Equal To Another Field |
| gtfield | Field Greater Than Another Field |
| ltcsfield | Less Than Another Relative Field |
| ltecsfield | Less Than or Equal To Another Relative Field |
| ltefield | Less Than or Equal To Another Field |
| ltfield | Less Than Another Field |
| necsfield | Field Does Not Equal Another Field (relative) |
| nefield | Field Does Not Equal Another Field |

### Network:

| Tag | Description |
| - | - |
| cidr | Classless Inter-Domain Routing CIDR |
| cidrv4 | Classless Inter-Domain Routing CIDRv4 |
| cidrv6 | Classless Inter-Domain Routing CIDRv6 |
| datauri | Data URL |
| fqdn | Full Qualified Domain Name (FQDN) |
| hostname | Hostname RFC 952 |
| hostname_port | HostPort |
| hostname_rfc1123 | Hostname RFC 1123 |
| ip | Internet Protocol Address IP |
| ip4_addr | Internet Protocol Address IPv4 |
| ip6_addr | Internet Protocol Address IPv6 |
| ip_addr | Internet Protocol Address IP |
| ipv4 | Internet Protocol Address IPv4 |
| ipv6 | Internet Protocol Address IPv6 |
| mac | Media Access Control Address MAC |
| tcp4_addr | Transmission Control Protocol Address TCPv4 |
| tcp6_addr | Transmission Control Protocol Address TCPv6 |
| tcp_addr | Transmission Control Protocol Address TCP |
| udp4_addr | User Datagram Protocol Address UDPv4 |
| udp6_addr | User Datagram Protocol Address UDPv6 |
| udp_addr | User Datagram Protocol Address UDP |
| unix_addr | Unix domain socket end point Address |
| uri | URI String |
| url | URL String |
| http_url | HTTP URL String |
| url_encoded | URL Encoded |
| urn_rfc2141 | Urn RFC 2141 String |

### Strings:

| Tag | Description |
| - | - |
| alpha | Alpha Only |
| alphanum | Alphanumeric |
| alphanumunicode | Alphanumeric Unicode |
| alphaunicode | Alpha Unicode |
| ascii | ASCII |
| boolean | Boolean |
| contains | Contains |
| containsany | Contains Any |
| containsrune | Contains Rune |
| endsnotwith | Ends Not With |
| endswith | Ends With |
| excludes | Excludes |
| excludesall | Excludes All |
| excludesrune | Excludes Rune |
| lowercase | Lowercase |
| multibyte | Multi-Byte Characters |
| number | Number |
| numeric | Numeric |
| printascii | Printable ASCII |
| startsnotwith | Starts Not With |
| startswith | Starts With |
| uppercase | Uppercase |

### Format:
| Tag | Description |
| - | - |
| base64 | Base64 String |
| base64url | Base64URL String |
| base64rawurl | Base64RawURL String |
| bic | Business Identifier Code (ISO 9362) |
| bcp47_language_tag | Language tag (BCP 47) |
| btc_addr | Bitcoin Address |
| btc_addr_bech32 | Bitcoin Bech32 Address (segwit) |
| credit_card | Credit Card Number |
| mongodb | MongoDB ObjectID |
| mongodb_connection_string | MongoDB Connection String |
| cron | Cron |
| spicedb | SpiceDb ObjectID/Permission/Type |
| datetime | Datetime |
| e164 | e164 formatted phone number |
| ein | U.S. Employeer Identification Number |
| email | E-mail String
| eth_addr | Ethereum Address |
| hexadecimal | Hexadecimal String |
| hexcolor | Hexcolor String |
| hsl | HSL String |
| hsla | HSLA String |
| html | HTML Tags |
| html_encoded | HTML Encoded |
| isbn | International Standard Book Number |
| isbn10 | International Standard Book Number 10 |
| isbn13 | International Standard Book Number 13 |
| issn | International Standard Serial Number |
| iso3166_1_alpha2 | Two-letter country code (ISO 3166-1 alpha-2) |
| iso3166_1_alpha3 | Three-letter country code (ISO 3166-1 alpha-3) |
| iso3166_1_alpha_numeric | Numeric country code (ISO 3166-1 numeric) |
| iso3166_2 | Country subdivision code (ISO 3166-2) |
| iso4217 | Currency code (ISO 4217) |
| json | JSON |
| jwt | JSON Web Token (JWT) |
| latitude | Latitude |
| longitude | Longitude |
| luhn_checksum | Luhn Algorithm Checksum (for strings and (u)int) |
| postcode_iso3166_alpha2 | Postcode |
| postcode_iso3166_alpha2_field | Postcode |
| rgb | RGB String |
| rgba | RGBA String |
| ssn | Social Security Number SSN |
| timezone | Timezone |
| uuid | Universally Unique Identifier UUID |
| uuid3 | Universally Unique Identifier UUID v3 |
| uuid3_rfc4122 | Universally Unique Identifier UUID v3 RFC4122 |
| uuid4 | Universally Unique Identifier UUID v4 |
| uuid4_rfc4122 | Universally Unique Identifier UUID v4 RFC4122 |
| uuid5 | Universally Unique Identifier UUID v5 |
| uuid5_rfc4122 | Universally Unique Identifier UUID v5 RFC4122 |
| uuid_rfc4122 | Universally Unique Identifier UUID RFC4122 |
| md4 | MD4 hash |
| md5 | MD5 hash |
| sha256 | SHA256 hash |
| sha384 | SHA384 hash |
| sha512 | SHA512 hash |
| ripemd128 | RIPEMD-128 hash |
| ripemd128 | RIPEMD-160 hash |
| tiger128 | TIGER128 hash |
| tiger160 | TIGER160 hash |
| tiger192 | TIGER192 hash |
| semver | Semantic Versioning 2.0.0 |
| ulid | Universally Unique Lexicographically Sortable Identifier ULID |
| cve | Common Vulnerabilities and Exposures Identifier (CVE id) |

### Comparisons:
| Tag | Description |
| - | - |
| eq | Equals |
| eq_ignore_case | Equals ignoring case |
| gt | Greater than|
| gte | Greater than or equal |
| lt | Less Than |
| lte | Less Than or Equal |
| ne | Not Equal |
| ne_ignore_case | Not Equal ignoring case |

### Other:
| Tag | Description |
| - | - |
| dir | Existing Directory |
| dirpath | Directory Path |
| file | Existing File |
| filepath | File Path |
| image | Image |
| isdefault | Is Default |
| len | Length |
| max | Maximum |
| min | Minimum |
| oneof | One Of |
| required | Required |
| required_if | Required If |
| required_unless | Required Unless |
| required_with | Required With |
| required_with_all | Required With All |
| required_without | Required Without |
| required_without_all | Required Without All |
| excluded_if | Excluded If |
| excluded_unless | Excluded Unless |
| excluded_with | Excluded With |
| excluded_with_all | Excluded With All |
| excluded_without | Excluded Without |
| excluded_without_all | Excluded Without All |
| unique | Unique |
| validateFn | Verify if the method `Validate() error` does not return an error (or any specified method) |


#### Aliases:
| Tag | Description |
| - | - |
| iscolor | hexcolor\|rgb\|rgba\|hsl\|hsla |
| country_code | iso3166_1_alpha2\|iso3166_1_alpha3\|iso3166_1_alpha_numeric |

Benchmarks
------
###### Run on MacBook Pro Max M3
```go
go version go1.23.3 darwin/arm64
goos: darwin
goarch: arm64
cpu: Apple M3 Max
pkg: github.com/go-playground/validator/v10
BenchmarkFieldSuccess-16                                                42461943                27.88 ns/op            0 B/op          0 allocs/op
BenchmarkFieldSuccessParallel-16                                        486632887                2.289 ns/op           0 B/op          0 allocs/op
BenchmarkFieldFailure-16                                                 9566167               121.3 ns/op           200 B/op          4 allocs/op
BenchmarkFieldFailureParallel-16                                        17551471                83.68 ns/op          200 B/op          4 allocs/op
BenchmarkFieldArrayDiveSuccess-16                                        7602306               155.6 ns/op            97 B/op          5 allocs/op
BenchmarkFieldArrayDiveSuccessParallel-16                               20664610                59.80 ns/op           97 B/op          5 allocs/op
BenchmarkFieldArrayDiveFailure-16                                        4659756               252.9 ns/op           301 B/op         10 allocs/op
BenchmarkFieldArrayDiveFailureParallel-16                                8010116               152.9 ns/op           301 B/op         10 allocs/op
BenchmarkFieldMapDiveSuccess-16                                          2834575               421.2 ns/op           288 B/op         14 allocs/op
BenchmarkFieldMapDiveSuccessParallel-16                                  7179700               171.8 ns/op           288 B/op         14 allocs/op
BenchmarkFieldMapDiveFailure-16                                          3081728               384.4 ns/op           376 B/op         13 allocs/op
BenchmarkFieldMapDiveFailureParallel-16                                  6058137               204.0 ns/op           377 B/op         13 allocs/op
BenchmarkFieldMapDiveWithKeysSuccess-16                                  2544975               464.8 ns/op           288 B/op         14 allocs/op
BenchmarkFieldMapDiveWithKeysSuccessParallel-16                          6661954               181.4 ns/op           288 B/op         14 allocs/op
BenchmarkFieldMapDiveWithKeysFailure-16                                  2435484               490.7 ns/op           553 B/op         16 allocs/op
BenchmarkFieldMapDiveWithKeysFailureParallel-16                          4249617               282.0 ns/op           554 B/op         16 allocs/op
BenchmarkFieldCustomTypeSuccess-16                                      14943525                77.35 ns/op           32 B/op          2 allocs/op
BenchmarkFieldCustomTypeSuccessParallel-16                              64051954                20.61 ns/op           32 B/op          2 allocs/op
BenchmarkFieldCustomTypeFailure-16                                      10721384               107.1 ns/op           184 B/op          3 allocs/op
BenchmarkFieldCustomTypeFailureParallel-16                              18714495                69.77 ns/op          184 B/op          3 allocs/op
BenchmarkFieldOrTagSuccess-16                                            4063124               294.3 ns/op            16 B/op          1 allocs/op
BenchmarkFieldOrTagSuccessParallel-16                                   31903756                41.22 ns/op           18 B/op          1 allocs/op
BenchmarkFieldOrTagFailure-16                                            7748558               146.8 ns/op           216 B/op          5 allocs/op
BenchmarkFieldOrTagFailureParallel-16                                   13139854                92.05 ns/op          216 B/op          5 allocs/op
BenchmarkStructLevelValidationSuccess-16                                16808389                70.25 ns/op           16 B/op          1 allocs/op
BenchmarkStructLevelValidationSuccessParallel-16                        90686955                14.47 ns/op           16 B/op          1 allocs/op
BenchmarkStructLevelValidationFailure-16                                 5818791               200.2 ns/op           264 B/op          7 allocs/op
BenchmarkStructLevelValidationFailureParallel-16                        11115874               107.5 ns/op           264 B/op          7 allocs/op
BenchmarkStructSimpleCustomTypeSuccess-16                                7764956               151.9 ns/op            32 B/op          2 allocs/op
BenchmarkStructSimpleCustomTypeSuccessParallel-16                       52316265                30.37 ns/op           32 B/op          2 allocs/op
BenchmarkStructSimpleCustomTypeFailure-16                                4195429               277.2 ns/op           416 B/op          9 allocs/op
BenchmarkStructSimpleCustomTypeFailureParallel-16                        7305661               164.6 ns/op           432 B/op         10 allocs/op
BenchmarkStructFilteredSuccess-16                                        6312625               186.1 ns/op           216 B/op          5 allocs/op
BenchmarkStructFilteredSuccessParallel-16                               13684459                93.42 ns/op          216 B/op          5 allocs/op
BenchmarkStructFilteredFailure-16                                        6751482               171.2 ns/op           216 B/op          5 allocs/op
BenchmarkStructFilteredFailureParallel-16                               14146070                86.93 ns/op          216 B/op          5 allocs/op
BenchmarkStructPartialSuccess-16                                         6544448               177.3 ns/op           224 B/op          4 allocs/op
BenchmarkStructPartialSuccessParallel-16                                13951946                88.73 ns/op          224 B/op          4 allocs/op
BenchmarkStructPartialFailure-16                                         4075833               287.5 ns/op           440 B/op          9 allocs/op
BenchmarkStructPartialFailureParallel-16                                 7490805               161.3 ns/op           440 B/op          9 allocs/op
BenchmarkStructExceptSuccess-16                                          4107187               281.4 ns/op           424 B/op          8 allocs/op
BenchmarkStructExceptSuccessParallel-16                                 15979173                80.86 ns/op          208 B/op          3 allocs/op
BenchmarkStructExceptFailure-16                                          4434372               264.3 ns/op           424 B/op          8 allocs/op
BenchmarkStructExceptFailureParallel-16                                  8081367               154.1 ns/op           424 B/op          8 allocs/op
BenchmarkStructSimpleCrossFieldSuccess-16                                6459542               183.4 ns/op            56 B/op          3 allocs/op
BenchmarkStructSimpleCrossFieldSuccessParallel-16                       41013781                37.95 ns/op           56 B/op          3 allocs/op
BenchmarkStructSimpleCrossFieldFailure-16                                4034998               292.1 ns/op           272 B/op          8 allocs/op
BenchmarkStructSimpleCrossFieldFailureParallel-16                       11348446               115.3 ns/op           272 B/op          8 allocs/op
BenchmarkStructSimpleCrossStructCrossFieldSuccess-16                     4448528               267.7 ns/op            64 B/op          4 allocs/op
BenchmarkStructSimpleCrossStructCrossFieldSuccessParallel-16            26813619                48.33 ns/op           64 B/op          4 allocs/op
BenchmarkStructSimpleCrossStructCrossFieldFailure-16                     3090646               384.5 ns/op           288 B/op          9 allocs/op
BenchmarkStructSimpleCrossStructCrossFieldFailureParallel-16             9870906               129.5 ns/op           288 B/op          9 allocs/op
BenchmarkStructSimpleSuccess-16                                         10675562               109.5 ns/op             0 B/op          0 allocs/op
BenchmarkStructSimpleSuccessParallel-16                                 131159784                8.932 ns/op           0 B/op          0 allocs/op
BenchmarkStructSimpleFailure-16                                          4094979               286.6 ns/op           416 B/op          9 allocs/op
BenchmarkStructSimpleFailureParallel-16                                  7606663               157.9 ns/op           416 B/op          9 allocs/op
BenchmarkStructComplexSuccess-16                                         2073470               576.0 ns/op           224 B/op          5 allocs/op
BenchmarkStructComplexSuccessParallel-16                                 7821831               161.3 ns/op           224 B/op          5 allocs/op
BenchmarkStructComplexFailure-16                                          576358              2001 ns/op            3042 B/op         48 allocs/op
BenchmarkStructComplexFailureParallel-16                                 1000000              1171 ns/op            3041 B/op         48 allocs/op
BenchmarkOneof

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[google/syzkaller]]></title>
            <link>https://github.com/google/syzkaller</link>
            <guid>https://github.com/google/syzkaller</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[syzkaller is an unsupervised coverage-guided kernel fuzzer]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google/syzkaller">google/syzkaller</a></h1>
            <p>syzkaller is an unsupervised coverage-guided kernel fuzzer</p>
            <p>Language: Go</p>
            <p>Stars: 5,718</p>
            <p>Forks: 1,293</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># syzkaller - kernel fuzzer

[![CI Status](https://github.com/google/syzkaller/workflows/ci/badge.svg)](https://github.com/google/syzkaller/actions?query=workflow/ci)
[![OSS-Fuzz](https://oss-fuzz-build-logs.storage.googleapis.com/badges/syzkaller.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?q=label:Proj-syzkaller)
[![Go Report Card](https://goreportcard.com/badge/github.com/google/syzkaller)](https://goreportcard.com/report/github.com/google/syzkaller)
[![Coverage Status](https://codecov.io/gh/google/syzkaller/graph/badge.svg)](https://codecov.io/gh/google/syzkaller)
[![GoDoc](https://godoc.org/github.com/google/syzkaller?status.svg)](https://godoc.org/github.com/google/syzkaller)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)

`syzkaller` (`[siÀêzÀàk…îÀêl…ô]`) is an unsupervised coverage-guided kernel fuzzer.\
Supported OSes: `FreeBSD`, `Fuchsia`, `gVisor`, `Linux`, `NetBSD`, `OpenBSD`, `Windows`.

Mailing list: [syzkaller@googlegroups.com](https://groups.google.com/forum/#!forum/syzkaller) (join on [web](https://groups.google.com/forum/#!forum/syzkaller) or by [email](mailto:syzkaller+subscribe@googlegroups.com)).

Found bugs: [Darwin/XNU](docs/darwin/README.md), [FreeBSD](docs/freebsd/found_bugs.md), [Linux](docs/linux/found_bugs.md), [NetBSD](docs/netbsd/found_bugs.md), [OpenBSD](docs/openbsd/found_bugs.md), [Windows](docs/windows/README.md).

## Documentation

Initially, syzkaller was developed with Linux kernel fuzzing in mind, but now
it&#039;s being extended to support other OS kernels as well.
Most of the documentation at this moment is related to the [Linux](docs/linux/setup.md) kernel.
For other OS kernels check:
[Darwin/XNU](docs/darwin/README.md),
[FreeBSD](docs/freebsd/README.md),
[Fuchsia](docs/fuchsia/README.md),
[NetBSD](docs/netbsd/README.md),
[OpenBSD](docs/openbsd/setup.md),
[Starnix](docs/starnix/README.md),
[Windows](docs/windows/README.md),
[gVisor](docs/gvisor/README.md).
[Akaros](docs/akaros/README.md),

- [How to install syzkaller](docs/setup.md)
- [How to use syzkaller](docs/usage.md)
- [How syzkaller works](docs/internals.md)
- [How to install syzbot](docs/setup_syzbot.md)
- [How to contribute to syzkaller](docs/contributing.md)
- [How to report Linux kernel bugs](docs/linux/reporting_kernel_bugs.md)
- [Tech talks and articles](docs/talks.md)
- [Research work based on syzkaller](docs/research.md)

## Disclaimer

This is not an official Google product.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[prometheus/node_exporter]]></title>
            <link>https://github.com/prometheus/node_exporter</link>
            <guid>https://github.com/prometheus/node_exporter</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Exporter for machine metrics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prometheus/node_exporter">prometheus/node_exporter</a></h1>
            <p>Exporter for machine metrics</p>
            <p>Language: Go</p>
            <p>Stars: 12,166</p>
            <p>Forks: 2,490</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># Node exporter

[![CircleCI](https://circleci.com/gh/prometheus/node_exporter/tree/master.svg?style=shield)][circleci]
![bsd workflow](https://github.com/prometheus/node_exporter/actions/workflows/bsd.yml/badge.svg)
![golangci-lint workflow](https://github.com/prometheus/node_exporter/actions/workflows/golangci-lint.yml/badge.svg)
[![Docker Repository on Quay](https://quay.io/repository/prometheus/node-exporter/status)][quay]
[![Docker Pulls](https://img.shields.io/docker/pulls/prom/node-exporter.svg?maxAge=604800)][hub]
[![Go Report Card](https://goreportcard.com/badge/github.com/prometheus/node_exporter)][goreportcard]

Prometheus exporter for hardware and OS metrics exposed by \*NIX kernels, written
in Go with pluggable metric collectors.

The [Windows exporter](https://github.com/prometheus-community/windows_exporter) is recommended for Windows users.
To expose NVIDIA GPU metrics, [prometheus-dcgm
](https://github.com/NVIDIA/dcgm-exporter)
can be used.

## Installation and Usage

If you are new to Prometheus and `node_exporter` there is a [simple step-by-step guide](https://prometheus.io/docs/guides/node-exporter/).

The `node_exporter` listens on HTTP port 9100 by default. See the `--help` output for more options.

### Ansible

For automated installs with [Ansible](https://www.ansible.com/), there is the [Prometheus Community role](https://github.com/prometheus-community/ansible).

### Docker

The `node_exporter` is designed to monitor the host system. Deploying in containers requires
extra care in order to avoid monitoring the container itself.

For situations where containerized deployment is needed, some extra flags must be used to allow
the `node_exporter` access to the host namespaces.

Be aware that any non-root mount points you want to monitor will need to be bind-mounted
into the container.

If you start container for host monitoring, specify `path.rootfs` argument.
This argument must match path in bind-mount of host root. The node\_exporter will use
`path.rootfs` as prefix to access host filesystem.

```bash
docker run -d \
  --net=&quot;host&quot; \
  --pid=&quot;host&quot; \
  -v &quot;/:/host:ro,rslave&quot; \
  quay.io/prometheus/node-exporter:latest \
  --path.rootfs=/host
```

For Docker compose, similar flag changes are needed.

```yaml
---
version: &#039;3.8&#039;

services:
  node_exporter:
    image: quay.io/prometheus/node-exporter:latest
    container_name: node_exporter
    command:
      - &#039;--path.rootfs=/host&#039;
    network_mode: host
    pid: host
    restart: unless-stopped
    volumes:
      - &#039;/:/host:ro,rslave&#039;
```

On some systems, the `timex` collector requires an additional Docker flag,
`--cap-add=SYS_TIME`, in order to access the required syscalls.

## Collectors

There is varying support for collectors on each operating system. The tables
below list all existing collectors and the supported systems.

Collectors are enabled by providing a `--collector.&lt;name&gt;` flag.
Collectors that are enabled by default can be disabled by providing a `--no-collector.&lt;name&gt;` flag.
To enable only some specific collector(s), use `--collector.disable-defaults --collector.&lt;name&gt; ...`.

### Include &amp; Exclude flags

A few collectors can be configured to include or exclude certain patterns using dedicated flags. The exclude flags are used to indicate &quot;all except&quot;, while the include flags are used to say &quot;none except&quot;. Note that these flags are mutually exclusive on collectors that support both.

Example:

```txt
--collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
```

List:

Collector | Scope | Include Flag | Exclude Flag
--- | --- | --- | ---
arp | device | --collector.arp.device-include | --collector.arp.device-exclude
cpu | bugs | --collector.cpu.info.bugs-include | N/A
cpu | flags | --collector.cpu.info.flags-include | N/A
diskstats | device | --collector.diskstats.device-include | --collector.diskstats.device-exclude
ethtool | device | --collector.ethtool.device-include | --collector.ethtool.device-exclude
ethtool | metrics | --collector.ethtool.metrics-include | N/A
filesystem | fs-types | --collector.filesystem.fs-types-include | --collector.filesystem.fs-types-exclude
filesystem | mount-points | --collector.filesystem.mount-points-include | --collector.filesystem.mount-points-exclude
hwmon | chip | --collector.hwmon.chip-include | --collector.hwmon.chip-exclude
hwmon | sensor | --collector.hwmon.sensor-include | --collector.hwmon.sensor-exclude
interrupts | name | --collector.interrupts.name-include | --collector.interrupts.name-exclude
netdev | device | --collector.netdev.device-include | --collector.netdev.device-exclude
qdisk | device | --collector.qdisk.device-include | --collector.qdisk.device-exclude
slabinfo | slab-names | --collector.slabinfo.slabs-include | --collector.slabinfo.slabs-exclude
sysctl | all | --collector.sysctl.include | N/A
systemd | unit | --collector.systemd.unit-include | --collector.systemd.unit-exclude

### Enabled by default

Name     | Description | OS
---------|-------------|----
arp | Exposes ARP statistics from `/proc/net/arp`. | Linux
bcache | Exposes bcache statistics from `/sys/fs/bcache/`. | Linux
bonding | Exposes the number of configured and active slaves of Linux bonding interfaces. | Linux
btrfs | Exposes btrfs statistics | Linux
boottime | Exposes system boot time derived from the `kern.boottime` sysctl. | Darwin, Dragonfly, FreeBSD, NetBSD, OpenBSD, Solaris
conntrack | Shows conntrack statistics (does nothing if no `/proc/sys/net/netfilter/` present). | Linux
cpu | Exposes CPU statistics | Darwin, Dragonfly, FreeBSD, Linux, Solaris, OpenBSD
cpufreq | Exposes CPU frequency statistics | Linux, Solaris
diskstats | Exposes disk I/O statistics. | Darwin, Linux, OpenBSD
dmi | Expose Desktop Management Interface (DMI) info from `/sys/class/dmi/id/` | Linux
edac | Exposes error detection and correction statistics. | Linux
entropy | Exposes available entropy. | Linux
exec | Exposes execution statistics. | Dragonfly, FreeBSD
fibrechannel | Exposes fibre channel information and statistics from `/sys/class/fc_host/`. | Linux
filefd | Exposes file descriptor statistics from `/proc/sys/fs/file-nr`. | Linux
filesystem | Exposes filesystem statistics, such as disk space used. | Darwin, Dragonfly, FreeBSD, Linux, OpenBSD
hwmon | Expose hardware monitoring and sensor data from `/sys/class/hwmon/`. | Linux
infiniband | Exposes network statistics specific to InfiniBand and Intel OmniPath configurations. | Linux
ipvs | Exposes IPVS status from `/proc/net/ip_vs` and stats from `/proc/net/ip_vs_stats`. | Linux
loadavg | Exposes load average. | Darwin, Dragonfly, FreeBSD, Linux, NetBSD, OpenBSD, Solaris
mdadm | Exposes statistics about devices in `/proc/mdstat` (does nothing if no `/proc/mdstat` present). | Linux
meminfo | Exposes memory statistics. | Darwin, Dragonfly, FreeBSD, Linux, OpenBSD
netclass | Exposes network interface info from `/sys/class/net/` | Linux
netdev | Exposes network interface statistics such as bytes transferred. | Darwin, Dragonfly, FreeBSD, Linux, OpenBSD
netisr | Exposes netisr statistics | FreeBSD
netstat | Exposes network statistics from `/proc/net/netstat`. This is the same information as `netstat -s`. | Linux
nfs | Exposes NFS client statistics from `/proc/net/rpc/nfs`. This is the same information as `nfsstat -c`. | Linux
nfsd | Exposes NFS kernel server statistics from `/proc/net/rpc/nfsd`. This is the same information as `nfsstat -s`. | Linux
nvme | Exposes NVMe info from `/sys/class/nvme/` | Linux
os | Expose OS release info from `/etc/os-release` or `/usr/lib/os-release` | _any_
powersupplyclass | Exposes Power Supply statistics from `/sys/class/power_supply` | Linux
pressure | Exposes pressure stall statistics from `/proc/pressure/`. | Linux (kernel 4.20+ and/or [CONFIG\_PSI](https://www.kernel.org/doc/html/latest/accounting/psi.html))
rapl | Exposes various statistics from `/sys/class/powercap`. | Linux
schedstat | Exposes task scheduler statistics from `/proc/schedstat`. | Linux
selinux | Exposes SELinux statistics. | Linux
sockstat | Exposes various statistics from `/proc/net/sockstat`. | Linux
softnet | Exposes statistics from `/proc/net/softnet_stat`. | Linux
stat | Exposes various statistics from `/proc/stat`. This includes boot time, forks and interrupts. | Linux
tapestats | Exposes statistics from `/sys/class/scsi_tape`. | Linux
textfile | Exposes statistics read from local disk. The `--collector.textfile.directory` flag must be set. | _any_
thermal | Exposes thermal statistics like `pmset -g therm`. | Darwin
thermal\_zone | Exposes thermal zone &amp; cooling device statistics from `/sys/class/thermal`. | Linux
time | Exposes the current system time. | _any_
timex | Exposes selected adjtimex(2) system call stats. | Linux
udp_queues | Exposes UDP total lengths of the rx_queue and tx_queue from `/proc/net/udp` and `/proc/net/udp6`. | Linux
uname | Exposes system information as provided by the uname system call. | Darwin, FreeBSD, Linux, OpenBSD
vmstat | Exposes statistics from `/proc/vmstat`. | Linux
watchdog | Exposes statistics from `/sys/class/watchdog` | Linux
xfs | Exposes XFS runtime statistics. | Linux (kernel 4.4+)
zfs | Exposes [ZFS](http://open-zfs.org/) performance statistics. | FreeBSD, [Linux](http://zfsonlinux.org/), Solaris

### Disabled by default

`node_exporter` also implements a number of collectors that are disabled by default.  Reasons for this vary by
collector, and may include:
* High cardinality
* Prolonged runtime that exceeds the Prometheus `scrape_interval` or `scrape_timeout`
* Significant resource demands on the host

You can enable additional collectors as desired by adding them to your
init system&#039;s or service supervisor&#039;s startup configuration for
`node_exporter` but caution is advised.  Enable at most one at a time,
testing first on a non-production system, then by hand on a single
production node.  When enabling additional collectors, you should
carefully monitor the change by observing the `
scrape_duration_seconds` metric to ensure that collection completes
and does not time out.  In addition, monitor the
`scrape_samples_post_metric_relabeling` metric to see the changes in
cardinality.

Name     | Description | OS
---------|-------------|----
buddyinfo | Exposes statistics of memory fragments as reported by /proc/buddyinfo. | Linux
cgroups | A summary of the number of active and enabled cgroups | Linux
cpu\_vulnerabilities | Exposes CPU vulnerability information from sysfs. | Linux
devstat | Exposes device statistics | Dragonfly, FreeBSD
drm | Expose GPU metrics using sysfs / DRM, `amdgpu` is the only driver which exposes this information through DRM | Linux
drbd | Exposes Distributed Replicated Block Device statistics (to version 8.4) | Linux
ethtool | Exposes network interface information and network driver statistics equivalent to `ethtool`, `ethtool -S`, and `ethtool -i`. | Linux
interrupts | Exposes detailed interrupts statistics. | Linux, OpenBSD
ksmd | Exposes kernel and system statistics from `/sys/kernel/mm/ksm`. | Linux
lnstat | Exposes stats from `/proc/net/stat/`. | Linux
logind | Exposes session counts from [logind](http://www.freedesktop.org/wiki/Software/systemd/logind/). | Linux
meminfo\_numa | Exposes memory statistics from `/sys/devices/system/node/node[0-9]*/meminfo`, `/sys/devices/system/node/node[0-9]*/numastat`. | Linux
mountstats | Exposes filesystem statistics from `/proc/self/mountstats`. Exposes detailed NFS client statistics. | Linux
network_route | Exposes the routing table as metrics | Linux
perf | Exposes perf based metrics (Warning: Metrics are dependent on kernel configuration and settings). | Linux
processes | Exposes aggregate process statistics from `/proc`. | Linux
qdisc | Exposes [queuing discipline](https://en.wikipedia.org/wiki/Network_scheduler#Linux_kernel) statistics | Linux
slabinfo | Exposes slab statistics from `/proc/slabinfo`. Note that permission of `/proc/slabinfo` is usually 0400, so set it appropriately. | Linux
softirqs | Exposes detailed softirq statistics from `/proc/softirqs`. | Linux
sysctl | Expose sysctl values from `/proc/sys`. Use `--collector.sysctl.include(-info)` to configure. | Linux
systemd | Exposes service and system status from [systemd](http://www.freedesktop.org/wiki/Software/systemd/). | Linux
tcpstat | Exposes TCP connection status information from `/proc/net/tcp` and `/proc/net/tcp6`. (Warning: the current version has potential performance issues in high load situations.) | Linux
wifi | Exposes WiFi device and station statistics. | Linux
xfrm | Exposes statistics from `/proc/net/xfrm_stat` | Linux
zoneinfo | Exposes NUMA memory zone metrics. | Linux

### Deprecated

These collectors are deprecated and will be removed in the next major release.

Name     | Description | OS
---------|-------------|----
ntp | Exposes local NTP daemon health to check [time](./docs/TIME.md) | _any_
runit | Exposes service status from [runit](http://smarden.org/runit/). | _any_
supervisord | Exposes service status from [supervisord](http://supervisord.org/). | _any_

### Perf Collector

The `perf` collector may not work out of the box on some Linux systems due to kernel
configuration and security settings. To allow access, set the following `sysctl`
parameter:

```
sysctl -w kernel.perf_event_paranoid=X
```

- 2 allow only user-space measurements (default since Linux 4.6).
- 1 allow both kernel and user measurements (default before Linux 4.6).
- 0 allow access to CPU-specific data but not raw tracepoint samples.
- -1 no restrictions.

Depending on the configured value different metrics will be available, for most
cases `0` will provide the most complete set. For more information see [`man 2
perf_event_open`](http://man7.org/linux/man-pages/man2/perf_event_open.2.html).

By default, the `perf` collector will only collect metrics of the CPUs that
`node_exporter` is running on (ie
[`runtime.NumCPU`](https://golang.org/pkg/runtime/#NumCPU). If this is
insufficient (e.g. if you run `node_exporter` with its CPU affinity set to
specific CPUs), you can specify a list of alternate CPUs by using the
`--collector.perf.cpus` flag. For example, to collect metrics on CPUs 2-6, you
would specify: `--collector.perf --collector.perf.cpus=2-6`. The CPU
configuration is zero indexed and can also take a stride value; e.g.
`--collector.perf --collector.perf.cpus=1-10:5` would collect on CPUs
1, 5, and 10.

The `perf` collector is also able to collect
[tracepoint](https://www.kernel.org/doc/html/latest/core-api/tracepoint.html)
counts when using the `--collector.perf.tracepoint` flag. Tracepoints can be
found using [`perf list`](http://man7.org/linux/man-pages/man1/perf.1.html) or
from debugfs. And example usage of this would be
`--collector.perf.tracepoint=&quot;sched:sched_process_exec&quot;`.

### Sysctl Collector

The `sysctl` collector can be enabled with `--collector.sysctl`. It supports exposing numeric sysctl values
as metrics using the `--collector.sysctl.include` flag and string values as info metrics by using the
`--collector.sysctl.include-info` flag. The flags can be repeated. For sysctl with multiple numeric values,
an optional mapping can be given to expose each value as its own metric. Otherwise an `index` label is used
to identify the different fields.

#### Examples
##### Numeric values
###### Single values
Using `--collector.sysctl.include=vm.user_reserve_kbytes`:
`vm.user_reserve_kbytes = 131072` -&gt; `node_sysctl_vm_user_reserve_kbytes 131072`

###### Multiple values
A sysctl can contain multiple values, for example:
```
net.ipv4.tcp_rmem = 4096	131072	6291456
```
Using `--collector.sysctl.include=net.ipv4.tcp_rmem` the collector will expose:
```
node_sysctl_net_ipv4_tcp_rmem{index=&quot;0&quot;} 4096
node_sysctl_net_ipv4_tcp_rmem{index=&quot;1&quot;} 131072
node_sysctl_net_ipv4_tcp_rmem{index=&quot;2&quot;} 6291456
```
If the indexes have defined meaning like in this case, the values can be mapped to multiple metrics by appending the mapping to the --collector.sysctl.include flag:
Using `--collector.sysctl.include=net.ipv4.tcp_rmem:min,default,max` the collector will expose:
```
node_sysctl_net_ipv4_tcp_rmem_min 4096
node_sysctl_net_ipv4_tcp_rmem_default 131072
node_sysctl_net_ipv4_tcp_rmem_max 6291456
```

##### String values
String values need to be exposed as info metric. The user selects them by using the `--collector.sysctl.include-info` flag.

###### Single values
`kernel.core_pattern = core` -&gt; `node_sysctl_info{key=&quot;kernel.core_pattern_info&quot;, value=&quot;core&quot;} 1`

###### Multiple values
Given the following sysctl:
```
kernel.seccomp.actions_avail = kill_process kill_thread trap errno trace log allow
```
Setting `--collector.sysctl.include-info=kernel.seccomp.actions_avail` will yield:
```
node_sysctl_info{key=&quot;kernel.seccomp.actions_avail&quot;, index=&quot;0&quot;, value=&quot;kill_process&quot;} 1
node_sysctl_info{key=&quot;kernel.seccomp.actions_avail&quot;, index=&quot;1&quot;, value=&quot;kill_thread&quot;} 1
...
```

### Textfile Collector

The `textfile` collector is similar to the [Pushgateway](https://github.com/prometheus/pushgateway),
in that it allows exporting of statistics from batch jobs. It can also be used
to export static metrics, such as what role a machine has. The Pushgateway
should be used for service-level metrics. The `textfile` module is for metrics
that are tied to a machine.

To use it, set the `--collector.textfile.directory` flag on the `node_exporter` commandline. The
collector will parse all files in that directory matching the glob `*.prom`
using the [text
format](http://prometheus.io/docs/instrumenting/exposition_formats/). **Note:** Timestamps are not supported.

To atomically push completion time for a cron job:
```
echo my_batch_job_completion_time $(date +%s) &gt; /path/to/directory/my_batch_job.prom.$$
mv /path/to/directory/my_batch_job.prom.$$ /path/to/directory/my_batch_job.prom
```

To statically set roles for a machine using labels:
```
echo &#039;role{role=&quot;application_server&quot;} 1&#039; &gt; /path/to/directory/role.prom.$$
mv /path/to/directory/role.prom.$$ /path/to/directory/role.prom
```

### Filtering enabled collectors

The `node_exporter` will expose all metrics from enabled collectors by default.  This is the recommended way to collect metrics to avoid errors when comparing metrics of different families.

For advanced use the `node_exporter` can be passed an optional list of collectors to filter metrics. The parameters `collect[]` and `exclude[]` can be used multiple times (but cannot be combined).  In Prometheus configuration you can use this syntax under the [scrape config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#&lt;scrape_config&gt;).

Collect only `cpu` and `meminfo` collector metrics:
```
  params:
    collect[]:
      - cpu
      - meminfo
```

Collect all enabled collector metrics but exclude `netdev`:
```
  params:
    exclude[]:
      - netdev
```

This can be useful for having different Prometheus servers collect specific metrics from nodes.

## Development building and running

Prerequisites:

* [Go compiler](https://golang.org/dl/)
* RHEL/CentOS: `glibc-static` package.

Building:

    git clone https://github.com/prometheus/node_exporter.git
    cd node_exporter
    make build
    ./node_exporter &lt;flags&gt;

To see all available configuration flags:

    ./node_exporter -h

## Running tests

    make test

## TLS endpoint

**EXPERIMENTAL**

The exporter supports TLS via a new web configuration file.

```console
./node_exporter --web.config.file=web-config.yml
```

See the [exporter-toolkit web-configuration](https://github.com/prometheus/exporter-toolkit/blob/master/docs/web-configuration.md) for more details.

[travis]: https://travis-ci.org/prometheus/node_exporter
[hub]: https://hub.docker.com/r/prom/node-exporter/
[circleci]: https://circleci.com/gh/prometheus/node_exporter
[quay]: https://quay.io/repository/prometheus/node-exporter
[goreportcard]: https://goreportcard.com/report/github.com/prometheus/node_exporter
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[keploy/keploy]]></title>
            <link>https://github.com/keploy/keploy</link>
            <guid>https://github.com/keploy/keploy</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[Unit, API & Integration Testing Agent for Developers. Generate tests, mocks/stubs for your APIs that actually work!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/keploy/keploy">keploy/keploy</a></h1>
            <p>Unit, API & Integration Testing Agent for Developers. Generate tests, mocks/stubs for your APIs that actually work!</p>
            <p>Language: Go</p>
            <p>Stars: 10,245</p>
            <p>Forks: 1,441</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot;&gt;
  &lt;img align=&quot;center&quot; src=&quot;https://docs.keploy.io/img/keploy-logo-dark.svg?s=200&amp;v=4&quot; height=&quot;40%&quot; width=&quot;40%&quot;  alt=&quot;keploy logo&quot;/&gt;
&lt;/p&gt;
&lt;h3 align=&quot;center&quot;&gt;
&lt;b&gt;
‚ö°Ô∏è API tests faster than unit tests, from user traffic ‚ö°Ô∏è
&lt;/b&gt;
&lt;/h3 &gt;
&lt;p align=&quot;center&quot;&gt;
üåü The must-have tool for developers in the AI-Gen era üåü
&lt;/p&gt;

---

&lt;h4 align=&quot;center&quot;&gt;

   &lt;a href=&quot;https://x.com/Keployio&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/follow-%40keployio-1DA1F2?logo=X&amp;style=social&quot; alt=&quot;Keploy X!&quot; /&gt;
  &lt;/a&gt;
  
  &lt;a href=&quot;https://github.com/Keploy/Keploy/&quot;&gt;
   &lt;img src=&quot;https://img.shields.io/github/stars/keploy/keploy?color=%23EAC54F&amp;logo=github&amp;label=Help%20us%20reach%2020K%20stars!%20Now%20at:&quot; alt=&quot;Help us reach 20k stars!&quot; /&gt;
&lt;/a&gt;

  &lt;a href=&quot;https://landscape.cncf.io/?item=app-definition-and-development--continuous-integration-delivery--keploy&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/CNCF%20Landscape-5699C6?logo=cncf&amp;style=social&quot; alt=&quot;Keploy CNCF Landscape&quot; /&gt;
  &lt;/a&gt;

[![Slack](https://img.shields.io/badge/Slack-4A154B?style=for-the-badge&amp;logo=slack&amp;logoColor=white)](https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg)
[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white)](https://www.linkedin.com/company/keploy/)
[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&amp;logo=YouTube&amp;logoColor=white)](https://www.youtube.com/channel/UC6OTg7F4o0WkmNtSoob34lg)
[![X](https://img.shields.io/badge/X-%231DA1F2.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white)](https://x.com/Keployio)

&lt;a href=&quot;https://trendshift.io/repositories/3262&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/3262&quot; alt=&quot;keploy%2Fkeploy | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/h4&gt;


[Keploy](https://keploy.io) is **developer-centric** API testing tool that creates **tests along with built-in-mocks**, faster than unit tests.

Keploy not only records API calls, but also records database calls and replays them during testing, making it **easy to use, powerful, and extensible**.

&lt;img src=&quot;https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-tc.gif&quot; width=&quot;60%&quot; alt=&quot;Convert API calls to test cases&quot;/&gt;

&gt; üê∞ **Fun fact:** Keploy uses itself for testing! Check out our swanky coverage badge: [![Coverage Status](https://coveralls.io/repos/github/keploy/keploy/badge.svg?branch=main&amp;kill_cache=1)](https://coveralls.io/github/keploy/keploy?branch=main&amp;kill_cache=1) &amp;nbsp;

## üö® Here for  [Unit Test Generator](README-UnitGen.md) (ut-gen)? 
Keploy has newly launched the world&#039;s first unit test generator(ut-gen) implementation of [Meta LLM research paper](https://arxiv.org/pdf/2402.09171), it understands code semantics and generates meaningful unit tests, aiming to:

- **Automate unit test generation (UTG)**: Quickly generate comprehensive unit tests and reduce redundant manual effort.

- **Improve edge cases**: Extend and improve the scope of automated tests to cover more complex scenarios, often missed manually.

- **Boost test coverage**: As codebases grow, ensuring exhaustive coverage should become feasible, aligning with our mission.

### üìú Follow [Unit Test Generator README](README-UnitGen.md)! ‚úÖ

## üìò Documentation!
Become a Keploy pro with **[Keploy Documentation](https://keploy.io/docs/)**.

&lt;img src=&quot;https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-replay.gif&quot; width=&quot;100%&quot; alt=&quot;Record Replay Testing&quot;/&gt;

# üöÄ Quick Installation (API test generator)

Integrate Keploy by installing the agent locally. No code-changes required.

```shell
curl --silent -O -L https://keploy.io/install.sh &amp;&amp; source install.sh
```

##  üé¨ Recording Testcases

Start your app with Keploy to convert API calls as Tests and Mocks/Stubs.

```zsh
keploy record -c &quot;CMD_TO_RUN_APP&quot; 
```
For example, if you&#039;re using a simple Python app the `CMD_TO_RUN_APP` would resemble to `python main.py`, for  Golang `go run main.go`, for java `java -jar xyz.jar`, for node `npm start`..

```zsh
keploy record -c &quot;python main.py&quot;
```

## üß™ Running Tests
Shut down the databases, redis, kafka or any other services your application uses. Keploy doesn&#039;t need those during test.
```zsh
keploy test -c &quot;CMD_TO_RUN_APP&quot; --delay 10
```

## ‚úÖ Test Coverage Integration
To integrate with your unit-testing library and see combine test coverage, follow this [test-coverage guide](https://keploy.io/docs/server/sdk-installation/go/).

&gt; ####  **If You Had Fun:** Please leave a üåü star on this repo! It&#039;s free and will bring a smile. üòÑ üëè

## One-Click Setup üöÄ

Setup and run keploy quickly, with no local machine installation required:

[![GitHub Codescape](https://img.shields.io/badge/GH%20codespace-3670A0?style=for-the-badge&amp;logo=github&amp;logoColor=fff)]([https://github.dev/Sonichigo/mux-sql](https://github.dev/Sonichigo/mux-sql))

## ü§î Questions?
Reach out to us. We&#039;re here to help!

[![Slack](https://img.shields.io/badge/Slack-4A154B?style=for-the-badge&amp;logo=slack&amp;logoColor=white)](https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg)
[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white)](https://www.linkedin.com/company/keploy/)
[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&amp;logo=YouTube&amp;logoColor=white)](https://www.youtube.com/channel/UC6OTg7F4o0WkmNtSoob34lg)
[![X](https://img.shields.io/badge/X-%231DA1F2.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white)](https://x.com/Keployio)


## üåê Language Support
From Go&#039;s gopher üêπ to Python&#039;s snake üêç, we support:

![Go](https://img.shields.io/badge/go-%2300ADD8.svg?style=for-the-badge&amp;logo=go&amp;logoColor=white)
![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&amp;logo=java&amp;logoColor=white)
![NodeJS](https://img.shields.io/badge/node.js-6DA55F?style=for-the-badge&amp;logo=node.js&amp;logoColor=white)
![Rust](https://img.shields.io/badge/Rust-darkred?style=for-the-badge&amp;logo=rust&amp;logoColor=white)
![C#](https://img.shields.io/badge/csharp-purple?style=for-the-badge&amp;logo=csharp&amp;logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&amp;logo=python&amp;logoColor=ffdd54)

## ü´∞ Keploy Adopters üß°

So you and your organisation are using Keploy? That‚Äôs great. Please add yourselves to [**this list,**](https://github.com/orgs/keploy/discussions/1765) and we&#039;ll send you goodies! üíñ


We are happy and proud to have you all as part of our community! üíñ

## üé© How&#039;s the Magic Happen?
Keploy proxy captures and replays **ALL** (CRUD operations, including non-idempotent APIs) of your app&#039;s network interactions.


Take a journey to **[How Keploy Works?](https://keploy.io/docs/keploy-explained/how-keploy-works/)** to discover the tricks behind the curtain!

  ## üîß Core Features

- ‚ôªÔ∏è **Combined Test Coverage:** Merge your Keploy Tests with your fave testing libraries(JUnit, go-test, py-test, jest) to see a combined test coverage.


- ü§ñ **EBPF Instrumentation:** Keploy uses EBPF like a secret sauce to make integration code-less, language-agnostic, and oh-so-lightweight.


- üåê **CI/CD Integration:** Run tests with mocks anywhere you like‚Äîlocally on the CLI, in your CI pipeline (Jenkins, Github Actions..) , or even across a Kubernetes cluster.


- üìΩÔ∏è **Record-Replay Complex Flows:** Keploy can record and replay complex, distributed API flows as mocks and stubs. It&#039;s like having a time machine for your tests‚Äîsaving you tons of time!


- üé≠ **Multi-Purpose Mocks:** You can also use Keploy-generated Mocks, as server Tests!


üëâ **Explore the code on GitHub**: [github.com/keploy/keploy](https://github.com/keploy/keploy)


## üë®üèª‚Äçüíª Let&#039;s Build Together! üë©üèª‚Äçüíª
Whether you&#039;re a newbie coder or a wizard üßô‚Äç‚ôÄÔ∏è, your perspective is golden. Take a peek at our:

üìú [Contribution Guidelines](https://github.com/keploy/keploy/blob/main/CONTRIBUTING.md)

‚ù§Ô∏è [Code of Conduct](https://github.com/keploy/keploy/blob/main/CODE_OF_CONDUCT.md)


## üê≤ Current Limitations!
- **Unit Testing:** While Keploy is designed to run alongside unit testing frameworks (Go test, JUnit..) and can add to the overall code coverage, it still generates integration tests.
- **Production Lands**: Keploy is currently focused on generating tests for developers. These tests can be captured from any environment, but we have not tested it on high volume production environments. This would need robust deduplication to avoid too many redundant tests being captured. We do have ideas on building a robust deduplication system [#27](https://github.com/keploy/keploy/issues/27)

## ‚ú® Resources!
ü§î [FAQs](https://keploy.io/docs/keploy-explained/faq/)

üïµÔ∏è‚ÄçÔ∏è [Why Keploy](https://keploy.io/docs/keploy-explained/why-keploy/)

‚öôÔ∏è [Installation Guide](https://keploy.io/docs/application-development/)

üìñ [Contribution Guide](https://keploy.io/docs/keploy-explained/contribution-guide/)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[oapi-codegen/oapi-codegen]]></title>
            <link>https://github.com/oapi-codegen/oapi-codegen</link>
            <guid>https://github.com/oapi-codegen/oapi-codegen</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Generate Go client and server boilerplate from OpenAPI 3 specifications]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oapi-codegen/oapi-codegen">oapi-codegen/oapi-codegen</a></h1>
            <p>Generate Go client and server boilerplate from OpenAPI 3 specifications</p>
            <p>Language: Go</p>
            <p>Stars: 7,228</p>
            <p>Forks: 945</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># `oapi-codegen`

[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9450/badge)](https://www.bestpractices.dev/projects/9450)

`oapi-codegen` is a command-line tool and library to convert OpenAPI specifications to Go code, be it [server-side implementations](#generating-server-side-boilerplate), [API clients](#generating-api-clients), or simply [HTTP models](#generating-api-models).

Using `oapi-codegen` allows you to reduce the boilerplate required to create or integrate with services based on [OpenAPI 3.0](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.0.md), and instead focus on writing your business logic, and working on the real value-add for your organisation.

With `oapi-codegen`, there are a few [Key Design Decisions](#key-design-decisions) we&#039;ve made, including:

- idiomatic Go, where possible
- fairly simple generated code, erring on the side of duplicate code over nicely refactored code
- supporting as much of OpenAPI 3.x as is possible, alongside Go&#039;s type system

`oapi-codegen` is one part of a wider ecosystem, which can be found described in further detail in the [oapi-codegen organisation on GitHub](https://github.com/oapi-codegen).

‚ö†Ô∏è This README may be for the latest development version, which may contain unreleased changes. Please ensure you&#039;re looking at the README for the latest release version.

## Action Required: The repository for this project has changed

As announced in [May 2024](https://github.com/oapi-codegen/oapi-codegen/discussions/1605),
we have moved the project from the deepmap organization to our own organization, and you will need to update your
import paths to pull updates past this point. You need to do a recursive search/replace from
`github.com/deepmap/oapi-codegen/v2` to `github.com/oapi-codegen/oapi-codegen/v2`.

&gt; [!IMPORTANT]
&gt; `oapi-codegen` moved to its new home with the version tag `v2.3.0`.

If you are using `v2.2.0` or below, please install like so:

```sh
# for the binary install
go install github.com/deepmap/oapi-codegen/v2/cmd/oapi-codegen@v2.2.0
```

If you are using `v2.3.0` or above, please install like so, using the new module import path:

```sh
# for the binary install
go install github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen@latest
```

## Install

## For Go 1.24+

It is recommended to follow [the `go tool` support available from Go 1.24+](https://www.jvt.me/posts/2025/01/27/go-tools-124/) for managing the dependency of `oapi-codegen` alongside your core application.

To do this, you run `go get -tool`:

```sh
$ go get -tool github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen@latest
# this will then modify your `go.mod`
```

From there, each invocation of `oapi-codegen` would be used like so:

```go
//go:generate go tool oapi-codegen -config cfg.yaml ../../api.yaml
```

## Prior to Go 1.24

It is recommended to follow [the `tools.go` pattern](https://www.jvt.me/posts/2022/06/15/go-tools-dependency-management/) for managing the dependency of `oapi-codegen` alongside your core application.

This would give you a `tools/tools.go`:

```go
//go:build tools
// +build tools

package main

import (
	_ &quot;github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen&quot;
)
```

Then, each invocation of `oapi-codegen` would be used like so:

```go
//go:generate go run github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen --config=config.yaml ../../api.yaml
```

Alternatively, you can install it as a binary with:

```sh
$ go install github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen@latest
$ oapi-codegen -version
```

Which then means you can invoke it like so:

```go
//go:generate oapi-codegen --config=config.yaml ../../api.yaml
```

Note that you can also [move your `tools.go` into its own sub-module](https://www.jvt.me/posts/2024/09/30/go-tools-module/) to reduce the impact on your top-level `go.mod`.

### Pinning to commits

While the project does not ([yet](https://github.com/oapi-codegen/oapi-codegen/issues/1519)) have a defined release cadence, there may be cases where you want to pull in yet-unreleased changes to your codebase.

Therefore, you may want to pin your dependency on `oapi-codegen` to a given commit hash, rather than a tag.

This is **officially recommended** for consumers of `oapi-codegen`, who want features/bug fixes that haven&#039;t yet been released.

We aim to keep the default branch ready-to-release so you should be able to safely pin.

To do so, you can run:

```sh
# pin to the latest version on the default branch
$ go get github.com/oapi-codegen/oapi-codegen/v2@main
# alternatively, to a commit hash i.e. https://github.com/oapi-codegen/oapi-codegen/commit/71e916c59688a6379b5774dfe5904ec222b9a537
$ go get github.com/oapi-codegen/oapi-codegen/v2@71e916c59688a6379b5774dfe5904ec222b9a537
```

This will then make a change such as:

```diff
diff --git go.mod go.mod
index 44f29a4..436a780 100644
--- go.mod
+++ go.mod
@@ -2,21 +2,20 @@
-require github.com/oapi-codegen/oapi-codegen/v2 v2.1.0
+require github.com/oapi-codegen/oapi-codegen/v2 v2.1.1-0.20240331212514-80f0b978ef16
```

## Usage

`oapi-codegen` is largely configured using a YAML configuration file, to simplify the number of flags that users need to remember, and to make reading the `go:generate` command less daunting.

For full details of what is supported, it&#039;s worth checking out [the GoDoc for `codegen.Configuration`](https://pkg.go.dev/github.com/oapi-codegen/oapi-codegen/v2/pkg/codegen#Configuration).

We also have [a JSON Schema](configuration-schema.json) that can be used by IDEs/editors with the Language Server Protocol (LSP) to perform intelligent suggestions, i.e.:

```yaml
# yaml-language-server: $schema=https://raw.githubusercontent.com/oapi-codegen/oapi-codegen/HEAD/configuration-schema.json
package: api
# ...
```

### Backwards compatibility

Although we strive to retain backwards compatibility - as a project that&#039;s using a stable API per SemVer - there are sometimes opportunities we must take to fix a bug that could cause a breaking change for [people relying upon the behaviour](https://xkcd.com/1172/).

In this case, we will expose a [compatibility option](https://pkg.go.dev/github.com/oapi-codegen/oapi-codegen/v2/pkg/codegen#CompatibilityOptions) to restore old behaviour.

## Features

At a high level, `oapi-codegen` supports:

- Generating server-side boilerplate for [a number of servers](#supported-servers) ([docs](#generating-server-side-boilerplate))
- Generating client API boilerplate ([docs](#generating-api-clients))
- Generating the types ([docs](#generating-api-models))
- Splitting large OpenAPI specs across multiple packages([docs](#import-mapping))
  - This is also known as &quot;Import Mapping&quot; or &quot;external references&quot; across our documentation / discussion in GitHub issues

## What does it look like?

Below we can see a trimmed down example taken from the OpenAPI Petstore [example](examples/petstore-expanded/stdhttp/api/petstore.gen.go):

```go
// generated code

type ServerInterface interface {
	// ...
	// Returns all pets
	// (GET /pets)
	FindPets(w http.ResponseWriter, r *http.Request, params FindPetsParams)
	// ...
}

// FindPets operation middleware
func (siw *ServerInterfaceWrapper) FindPets(w http.ResponseWriter, r *http.Request) {

	var err error

	// Parameter object where we will unmarshal all parameters from the context
	var params FindPetsParams

	// ------------- Optional query parameter &quot;tags&quot; -------------

	err = runtime.BindQueryParameter(&quot;form&quot;, true, false, &quot;tags&quot;, r.URL.Query(), &amp;params.Tags)
	if err != nil {
		siw.ErrorHandlerFunc(w, r, &amp;InvalidParamFormatError{ParamName: &quot;tags&quot;, Err: err})
		return
	}

	// ------------- Optional query parameter &quot;limit&quot; -------------

	err = runtime.BindQueryParameter(&quot;form&quot;, true, false, &quot;limit&quot;, r.URL.Query(), &amp;params.Limit)
	if err != nil {
		siw.ErrorHandlerFunc(w, r, &amp;InvalidParamFormatError{ParamName: &quot;limit&quot;, Err: err})
		return
	}

	handler := http.Handler(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		siw.Handler.FindPets(w, r, params)
	}))

	for _, middleware := range siw.HandlerMiddlewares {
		handler = middleware(handler)
	}

	handler.ServeHTTP(w, r)
}

// HandlerWithOptions creates http.Handler with additional options
func HandlerWithOptions(si ServerInterface, options StdHTTPServerOptions) http.Handler {
	m := options.BaseRouter

	if m == nil {
		m = http.NewServeMux()
	}
	if options.ErrorHandlerFunc == nil {
		options.ErrorHandlerFunc = func(w http.ResponseWriter, r *http.Request, err error) {
			http.Error(w, err.Error(), http.StatusBadRequest)
		}
	}

	wrapper := ServerInterfaceWrapper{
		Handler:            si,
		HandlerMiddlewares: options.Middlewares,
		ErrorHandlerFunc:   options.ErrorHandlerFunc,
	}

	m.HandleFunc(&quot;GET &quot;+options.BaseURL+&quot;/pets&quot;, wrapper.FindPets)

	return m
}
```

Then, in your own code, you implement the underlying logic for the `FindPets` implementation:

```go
type PetStore struct {
	Pets   map[int64]Pet
	NextId int64
	Lock   sync.Mutex
}

// Make sure we conform to ServerInterface

var _ ServerInterface = (*PetStore)(nil)

func NewPetStore() *PetStore {
	return &amp;PetStore{
		Pets:   make(map[int64]Pet),
		NextId: 1000,
	}
}

// FindPets implements all the handlers in the ServerInterface
func (p *PetStore) FindPets(w http.ResponseWriter, r *http.Request, params FindPetsParams) {
	p.Lock.Lock()
	defer p.Lock.Unlock()

	var result []Pet

	for _, pet := range p.Pets {
		if params.Tags != nil {
			// If we have tags,  filter pets by tag
			for _, t := range *params.Tags {
				if pet.Tag != nil &amp;&amp; (*pet.Tag == t) {
					result = append(result, pet)
				}
			}
		} else {
			// Add all pets if we&#039;re not filtering
			result = append(result, pet)
		}

		if params.Limit != nil {
			l := int(*params.Limit)
			if len(result) &gt;= l {
				// We&#039;re at the limit
				break
			}
		}
	}

	w.WriteHeader(http.StatusOK)
	_ = json.NewEncoder(w).Encode(result)
}
```

As we can see, `oapi-codegen` simplifies some of the boilerplate by taking parameters out of the request and instead allows us to focus on the implementation.

You&#039;ll note that there&#039;s still a bit more marshaling of request/response data, which is further reduced by using the [Strict server](#strict-server) functionality.

&lt;a name=&quot;what-does-it-look-like-strict&quot;&gt;&lt;/a&gt;
When using the strict server, you&#039;ll have the following generated code:

```go
// StrictServerInterface represents all server handlers.
type StrictServerInterface interface {
	// ...
	// Returns all pets
	// (GET /pets)
	FindPets(ctx context.Context, request FindPetsRequestObject) (FindPetsResponseObject, error)
	// ...
}

func NewStrictHandlerWithOptions(ssi StrictServerInterface, middlewares []StrictMiddlewareFunc, options StrictHTTPServerOptions) ServerInterface {
	return &amp;strictHandler{ssi: ssi, middlewares: middlewares, options: options}
}

// FindPets operation middleware
func (sh *strictHandler) FindPets(w http.ResponseWriter, r *http.Request, params FindPetsParams) {
	var request FindPetsRequestObject

	request.Params = params

	handler := func(ctx context.Context, w http.ResponseWriter, r *http.Request, request interface{}) (interface{}, error) {
		return sh.ssi.FindPets(ctx, request.(FindPetsRequestObject))
	}
	for _, middleware := range sh.middlewares {
		handler = middleware(handler, &quot;FindPets&quot;)
	}

	response, err := handler(r.Context(), w, r, request)

	if err != nil {
		sh.options.ResponseErrorHandlerFunc(w, r, err)
	} else if validResponse, ok := response.(FindPetsResponseObject); ok {
		if err := validResponse.VisitFindPetsResponse(w); err != nil {
			sh.options.ResponseErrorHandlerFunc(w, r, err)
		}
	} else if response != nil {
		sh.options.ResponseErrorHandlerFunc(w, r, fmt.Errorf(&quot;unexpected response type: %T&quot;, response))
	}
}
```

Then, in your own code, you implement the underlying logic for the `FindPets` implementation:

```go
// Make sure we conform to StrictServerInterface

var _ StrictServerInterface = (*PetStore)(nil)

func NewPetStore() *PetStore {
	return &amp;PetStore{
		Pets:   make(map[int64]Pet),
		NextId: 1000,
	}
}

// FindPets implements all the handlers in the ServerInterface
func (p *PetStore) FindPets(ctx context.Context, request FindPetsRequestObject) (FindPetsResponseObject, error) {
	p.Lock.Lock()
	defer p.Lock.Unlock()

	var result []Pet

	for _, pet := range p.Pets {
		if request.Params.Tags != nil {
			// If we have tags,  filter pets by tag
			for _, t := range *request.Params.Tags {
				if pet.Tag != nil &amp;&amp; (*pet.Tag == t) {
					result = append(result, pet)
				}
			}
		} else {
			// Add all pets if we&#039;re not filtering
			result = append(result, pet)
		}

		if request.Params.Limit != nil {
			l := int(*request.Params.Limit)
			if len(result) &gt;= l {
				// We&#039;re at the limit
				break
			}
		}
	}

	return FindPets200JSONResponse(result), nil
}
```

We can see that this provides the best means to focus on the implementation of the business logic within the endpoint, rather than (un)marshalling types to and from JSON, or wrangling cookies or headers.

## Key design decisions

- Produce an interface that can be satisfied by your implementation, with reduced boilerplate
- Bulk processing and parsing of OpenAPI document in Go
- Resulting output is using Go&#039;s `text/template`s, which are user-overridable
- Attempts to produce Idiomatic Go
- Single-file output
- Support multiple OpenAPI files by having a package-per-OpenAPI file
- Support of OpenAPI 3.0
  - OpenAPI 3.1 support is [awaiting upstream support](https://github.com/oapi-codegen/oapi-codegen/issues/373)
  - Note that this does not include OpenAPI 2.0 (aka Swagger)
- Extract parameters from requests, to reduce work required by your implementation
- Implicit `additionalProperties` are ignored by default ([more details](#additional-properties-additionalproperties))
- Prune unused types by default

## Generating server-side boilerplate

`oapi-codegen` shines by making it fairly straightforward (note that this is a purposeful choice of wording here - we want to avoid words like &quot;easy&quot;) to generate the server-side boilerplate for a backend API.

Below you can find the supported servers, and more information about how to implement a server using them.

To provide you a fully Test Driven Development style test harness to confirm you are following the specification, you could use a tool such as [openapi.tanna.dev/go/validator](https://openapi.tanna.dev/go/validator/), or craft your own.

### Supported Servers

Right now, we support the following servers, and are supportive of adding new servers, too!

&lt;table&gt;

&lt;tr&gt;
&lt;th&gt;
Server
&lt;/th&gt;
&lt;th&gt;
&lt;code&gt;generate&lt;/code&gt; flag to enable code generation
&lt;/th&gt;
&lt;th&gt;
Example usage
&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;

[Chi](https://github.com/go-chi/chi)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;chi-server&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;


For a Chi server, you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  chi-server: true
  models: true
output: gen.go
```

To implement this, check out [the Chi docs](#impl-chi).

&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;

[Echo](https://github.com/labstack/echo)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;echo-server&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;

For an Echo server, you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  echo-server: true
  models: true
output: gen.go
```

To implement this, check out [the Echo docs](#impl-echo).

&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;

[Fiber](https://github.com/gofiber/fiber)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;fiber-server&lt;/code&gt;
&lt;/td&gt;

&lt;td&gt;

For a Fiber server, you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  fiber-server: true
  models: true
output: gen.go
```

To implement this, check out [the Fiber docs](#impl-fiber).

&lt;/td&gt;
&lt;/tr&gt;


&lt;tr&gt;
&lt;td&gt;

[Gin](https://github.com/gin-gonic/gin)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;gin-server&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;

For a Gin server, you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  gin-server: true
  models: true
output: gen.go
```

To implement this, check out [the Gin docs](#impl-gin).

&lt;/td&gt;

&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;

[gorilla/mux](https://github.com/gorilla/mux)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;gorilla-server&lt;/code&gt;
&lt;/td&gt;

&lt;td&gt;

For a gorilla/mux server, you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  gorilla-server: true
  models: true
output: gen.go
```

To implement this, check out [the gorilla/mux docs](#impl-gorillamux).

&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;

[Iris](https://github.com/kataras/iris)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;iris-server&lt;/code&gt;
&lt;/td&gt;

&lt;td&gt;

For a Iris server, you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  iris-server: true
  models: true
output: gen.go
```

To implement this, check out [the Iris docs](#impl-iris).

&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;

[1.22+ `net/http`](https://pkg.go.dev/net/http)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;std-http-server&lt;/code&gt;
&lt;/td&gt;

&lt;td&gt;

To use purely `net/http` (for Go 1.22+), you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  std-http-server: true
  models: true
output: gen.go
```

To implement this, check out [the Go 1.22+ `net/http` docs](#impl-stdhttp).

&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

### Go 1.22+ `net/http`
&lt;a name=&quot;impl-stdhttp&quot;&gt;&lt;/a&gt;

As of Go 1.22, enhancements have been made to the routing of the `net/http` package in the standard library, which makes it a great starting point for implementing a server with, before needing to reach for another router or a full framework.

For instance, let&#039;s take this straightforward specification:

```yaml
openapi: &quot;3.0.0&quot;
info:
  version: 1.0.0
  title: Minimal ping API server
paths:
  /ping:
    get:
      responses:
        &#039;200&#039;:
          description: pet response
          content:
            application/json:
              schema:
                $ref: &#039;#/components/schemas/Pong&#039;
components:
  schemas:
    # base types
    Pong:
      type: object
      required:
        - ping
      properties:
        ping:
          type: string
          example: pong
```

This then generates code such as:

```go
// Pong defines model for Pong.
type Pong struct {
	Ping string `json:&quot;ping&quot;`
}

// ServerInterface represents all server handlers.
type ServerInterface interface {

	// (GET /ping)
	GetPing(w http.ResponseWriter, r *http.Request)
}

func HandlerFromMux(si ServerInterface, m ServeMux) http.Handler {
	return HandlerWithOptions(si, StdHTTPServerOptions{
		BaseRouter: m,
	})
}

// HandlerWithOptions creates http.Handler with additional options
func HandlerWithOptions(si ServerInterface, options StdHTTPServerOptions) http.Handler {
	m := options.BaseRouter

	// ... omitted for brevity

	m.HandleFunc(&quot;GET &quot;+options.BaseURL+&quot;/ping&quot;, wrapper.GetPing)

	return m
}
```

To implement this HTTP server, we need to write the following code in our [`api/impl.go`](examples/minimal-server/stdhttp/api/impl.go):

```go
import (
	&quot;encoding/json&quot;
	&quot;net/http&quot;
)

// optional code omitted

type Server struct{}

func NewServer() Server {
	return Server{}
}

// (GET /ping)
func (Server) GetPing(w http.ResponseWriter, r *http.Request) {
	resp := Pong{
		Ping: &quot;pong&quot;,
	}

	w.WriteHeader(http.StatusOK)
	_ = json.NewEncoder(w).Encode(resp)
}
```

Now we&#039;ve got our implementation, we can then write the following code to wire it up and get a running server:

```go
import (
	&quot;log&quot;
	&quot;net/http&quot;

	&quot;github.com/oapi-codegen/oapi-codegen/v2/examples/minimal-server/stdhttp/api&quot;
)

func main() {
	// create a type that satisfies the `api.ServerInterface`, which contains an implementation of every operation from the generated code
	server := api.NewServer()

	r := http.NewServeMux()

	// get an `http.Handler` that we can use
	h := api.HandlerFromMux(server, r)

	s := &amp;http.Server{
		Handler: h,
		Addr:    &quot;0.0.0.0:8080&quot;,
	}

	// And we serve HTTP until the world ends.
	log.Fatal(s.ListenAndServe())
}
```

&gt; [!NOTE]
&gt; This doesn&#039;t include [validation of incoming requests](#re

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grpc-ecosystem/grpc-gateway]]></title>
            <link>https://github.com/grpc-ecosystem/grpc-gateway</link>
            <guid>https://github.com/grpc-ecosystem/grpc-gateway</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[gRPC to JSON proxy generator following the gRPC HTTP spec]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grpc-ecosystem/grpc-gateway">grpc-ecosystem/grpc-gateway</a></h1>
            <p>gRPC to JSON proxy generator following the gRPC HTTP spec</p>
            <p>Language: Go</p>
            <p>Stars: 19,311</p>
            <p>Forks: 2,317</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;h1&gt;gRPC-Gateway&lt;/h1&gt;
&lt;p&gt;
gRPC to JSON proxy generator following the gRPC HTTP spec
&lt;/p&gt;
&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/grpc-ecosystem/grpc-gateway/ci.yml?color=379c9c&amp;label=build&amp;logo=github&amp;logoColor=ffffff&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://app.slack.com/client/T029RQSE6/CBATURP1D&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/slack-grpc--gateway-379c9c?logo=slack&amp;logoColor=ffffff&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/grpc-ecosystem/grpc-gateway?color=379c9c&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/grpc-ecosystem/grpc-gateway?color=379c9c&amp;logoColor=ffffff&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/grpc-ecosystem/grpc-gateway?color=379c9c&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://slsa.dev/images/gh-badge-level3.svg&quot;&gt;&lt;img src=&quot;https://slsa.dev/images/gh-badge-level3.svg&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

## About

The gRPC-Gateway is a plugin of the Google protocol buffers compiler
[protoc](https://github.com/protocolbuffers/protobuf).
It reads protobuf service definitions and generates a reverse-proxy server which
translates a RESTful HTTP API into gRPC. This server is generated according to the
[`google.api.http`](https://github.com/googleapis/googleapis/blob/master/google/api/http.proto#L46)
annotations in your service definitions.

This helps you provide your APIs in both gRPC and RESTful style at the same time.

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;docs/assets/images/architecture_introduction_diagram.svg&quot; /&gt;
&lt;/div&gt;

## Docs

You can read our docs at:

- https://grpc-ecosystem.github.io/grpc-gateway/

## Testimonials

&gt; We use the gRPC-Gateway to serve millions of API requests per day,
&gt; and have been since 2018 and through all of that,
&gt; we have never had any issues with it.
&gt;
&gt; _- William Mill, [Ad Hoc](http://adhocteam.us/)_

## Background

gRPC is great -- it generates API clients and server stubs in many programming
languages, it is fast, easy-to-use, bandwidth-efficient and its design is
combat-proven by Google. However, you might still want to provide a traditional
RESTful JSON API as well. Reasons can range from maintaining
backward-compatibility, supporting languages or clients that are not well supported by
gRPC, to simply maintaining the aesthetics and tooling involved with a RESTful
JSON architecture.

This project aims to provide that HTTP+JSON interface to your gRPC service.
A small amount of configuration in your service to attach HTTP semantics is all
that&#039;s needed to generate a reverse-proxy with this library.

## Installation

### Compile from source

The following instructions assume you are using
[Go Modules](https://go.dev/wiki/Modules) for dependency
management. Use a
[tool dependency](https://go.dev/wiki/Modules#how-can-i-track-tool-dependencies-for-a-module)
to track the versions of the following executable packages:

```go
// +build tools

package tools

import (
    _ &quot;github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway&quot;
    _ &quot;github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2&quot;
    _ &quot;google.golang.org/grpc/cmd/protoc-gen-go-grpc&quot;
    _ &quot;google.golang.org/protobuf/cmd/protoc-gen-go&quot;
)
```

Run `go mod tidy` to resolve the versions. Install by running

```sh
go install \
    github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway \
    github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2 \
    google.golang.org/protobuf/cmd/protoc-gen-go \
    google.golang.org/grpc/cmd/protoc-gen-go-grpc
```

This will place four binaries in your `$GOBIN`;

- `protoc-gen-grpc-gateway`
- `protoc-gen-openapiv2`
- `protoc-gen-go`
- `protoc-gen-go-grpc`

Make sure that your `$GOBIN` is in your `$PATH`.

### **Using the `tool` Directive in Go 1.24**

Starting from Go 1.24, the `tool` directive in `go.mod` provides a structured way to track and manage executable dependencies. This replaces the previous workaround of using a separate `tools.go` file with blank imports.

#### **Tracking Tools in `go.mod`**

Instead of manually importing tool dependencies in a Go source file, you can now use the `tool` directive in `go.mod` to declare the tools your project depends on. For example:

```go
module tools

go 1.24

tool (
	github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway
	github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2
	google.golang.org/grpc/cmd/protoc-gen-go-grpc
	google.golang.org/protobuf/cmd/protoc-gen-go
)
```

#### **Managing Tool Dependencies**

To add tools to your module, use the `-tool` flag with `go get`:

```sh
go get -tool github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway
go get -tool github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2
go get -tool google.golang.org/protobuf/cmd/protoc-gen-go
go get -tool google.golang.org/grpc/cmd/protoc-gen-go-grpc
```

This automatically updates `go.mod`, adding the tools under the `tool` directive along with `require` statements to ensure version tracking.

### Install Tools

Once the tool dependencies are properly recorded in the `go.mod` file, simply execute the following command in the root directory of your project:

```sh
go install tool
```

This will place four binaries in your `$GOBIN`;

- `protoc-gen-grpc-gateway`
- `protoc-gen-openapiv2`
- `protoc-gen-go`
- `protoc-gen-go-grpc`

Make sure that your `$GOBIN` is in your `$PATH`.

### Download the binaries

You may alternatively download the binaries from the [GitHub releases page](https://github.com/grpc-ecosystem/grpc-gateway/releases/latest).
We generate [SLSA3 signatures](slsa.dev) using the OpenSSF&#039;s [slsa-framework/slsa-github-generator](https://github.com/slsa-framework/slsa-github-generator) during the release process. To verify a release binary:

1. Install the verification tool from [slsa-framework/slsa-verifier#installation](https://github.com/slsa-framework/slsa-verifier#installation).
2. Download the provenance file `attestation.intoto.jsonl` from the [GitHub releases page](https://github.com/grpc-ecosystem/grpc-gateway/releases/latest).
3. Run the verifier:

```shell
slsa-verifier -artifact-path &lt;the-binary&gt; -provenance attestation.intoto.jsonl -source github.com/grpc-ecosystem/grpc-gateway -tag &lt;the-tag&gt;
```

Alternatively, see the section on remotely managed plugin versions below.

## Usage

### 1.Define your [gRPC](https://grpc.io/docs/) service using protocol buffers

`your_service.proto`:

```protobuf
 syntax = &quot;proto3&quot;;
 package your.service.v1;
 option go_package = &quot;github.com/yourorg/yourprotos/gen/go/your/service/v1&quot;;

 message StringMessage {
   string value = 1;
 }

 service YourService {
   rpc Echo(StringMessage) returns (StringMessage) {}
 }
```

### 2. Generate gRPC stubs

This step generates the gRPC stubs that you can use to implement the service and consume from clients:

Here&#039;s an example `buf.gen.yaml` you can use to generate the stubs with [buf](https://github.com/bufbuild/buf):

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
```

With this file in place, you can generate your files using `buf generate`.

&gt; For a complete example of using `buf generate` to generate protobuf stubs, see
&gt; [the boilerplate repo](https://github.com/johanbrandhorst/grpc-gateway-boilerplate).
&gt; For more information on generating the stubs with buf, see
&gt; [the official documentation](https://docs.buf.build/generate-usage).

If you are using `protoc` to generate stubs, here&#039;s an example of what a command
might look like:

```sh
protoc -I . \
    --go_out ./gen/go/ --go_opt paths=source_relative \
    --go-grpc_out ./gen/go/ --go-grpc_opt paths=source_relative \
    your/service/v1/your_service.proto
```

### 3. Implement your service in gRPC as usual.

### 4. Generate reverse-proxy using `protoc-gen-grpc-gateway`

At this point, you have 3 options:

- no further modifications, use the default mapping to HTTP semantics (method, path, etc.)
  - this will work on any `.proto` file, but will not allow setting HTTP paths, request parameters or similar
- additional `.proto` modifications to use a custom mapping
  - relies on parameters in the `.proto` file to set custom HTTP mappings
- no `.proto` modifications, but use an external configuration file
  - relies on an external configuration file to set custom HTTP mappings
  - mostly useful when the source proto file isn&#039;t under your control

#### 1. Using the default mapping

This requires no additional modification to the `.proto` file but does require enabling a specific option when executing the plugin.
The `generate_unbound_methods` should be enabled.

Here&#039;s what a `buf.gen.yaml` file might look like with this option enabled:

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - generate_unbound_methods=true
```

With `protoc` (just the grpc-gateway stubs):

```sh
protoc -I . --grpc-gateway_out ./gen/go \
    --grpc-gateway_opt paths=source_relative \
    --grpc-gateway_opt generate_unbound_methods=true \
    your/service/v1/your_service.proto
```

#### 2. With custom annotations

Add a [`google.api.http`](https://github.com/googleapis/googleapis/blob/master/google/api/http.proto#L46)
annotation to your .proto file

`your_service.proto`:

```diff
 syntax = &quot;proto3&quot;;
 package your.service.v1;
 option go_package = &quot;github.com/yourorg/yourprotos/gen/go/your/service/v1&quot;;
+
+import &quot;google/api/annotations.proto&quot;;
+
 message StringMessage {
   string value = 1;
 }

 service YourService {
-  rpc Echo(StringMessage) returns (StringMessage) {}
+  rpc Echo(StringMessage) returns (StringMessage) {
+    option (google.api.http) = {
+      post: &quot;/v1/example/echo&quot;
+      body: &quot;*&quot;
+    };
+  }
 }
```

&gt; You will need to provide the required third party protobuf files to the protobuf compiler.
&gt; If you are using [buf](https://github.com/bufbuild/buf), this dependency can
&gt; be added to the `deps` array in your `buf.yaml` under the name
&gt; `buf.build/googleapis/googleapis`:
&gt;
&gt; ```yaml
&gt; version: v2
&gt; name: buf.build/yourorg/myprotos
&gt; deps:
&gt;   - buf.build/googleapis/googleapis
&gt; ```
&gt;
&gt; Always run `buf dep update` after adding a dependency to your `buf.yaml`.

See [a_bit_of_everything.proto](examples/internal/proto/examplepb/a_bit_of_everything.proto)
for examples of more annotations you can add to customize gateway behavior
and generated OpenAPI output.

Here&#039;s what a `buf.gen.yaml` file might look like:

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
```

If you are using `protoc` to generate stubs, you need to ensure the required
dependencies are available to the compiler at compile time. These can be found
by manually cloning and copying the relevant files from the
[googleapis repository](https://github.com/googleapis/googleapis), and providing
them to `protoc` when running. The files you will need are:

```
google/api/annotations.proto
google/api/field_behavior.proto
google/api/http.proto
google/api/httpbody.proto
```

Here&#039;s what a `protoc` execution might look like:

```sh
protoc -I . --grpc-gateway_out ./gen/go \
    --grpc-gateway_opt paths=source_relative \
    your/service/v1/your_service.proto
```

#### 3. External configuration

If you do not want to (or cannot) modify the proto file for use with gRPC-Gateway you can
alternatively use an external
[gRPC Service Configuration](https://cloud.google.com/endpoints/docs/grpc/grpc-service-config) file.
[Check our documentation](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/grpc_api_configuration/)
for more information. This is best combined with the `standalone=true` option
to generate a file that can live in its own package, separate from the files
generated by the source protobuf file.

Here&#039;s what a `buf.gen.yaml` file might look like with this option enabled:

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - grpc_api_configuration=path/to/config.yaml
      - standalone=true
```

With `protoc` (just the grpc-gateway stubs):

```sh
protoc -I . --grpc-gateway_out ./gen/go \
    --grpc-gateway_opt paths=source_relative \
    --grpc-gateway_opt grpc_api_configuration=path/to/config.yaml \
    --grpc-gateway_opt standalone=true \
    your/service/v1/your_service.proto
```

### 5. Write an entrypoint for the HTTP reverse-proxy server

```go
package main

import (
  &quot;context&quot;
  &quot;flag&quot;
  &quot;net/http&quot;

  &quot;github.com/grpc-ecosystem/grpc-gateway/v2/runtime&quot;
  &quot;google.golang.org/grpc&quot;
  &quot;google.golang.org/grpc/credentials/insecure&quot;
  &quot;google.golang.org/grpc/grpclog&quot;

  gw &quot;github.com/yourorg/yourrepo/proto/gen/go/your/service/v1/your_service&quot;  // Update
)

var (
  // command-line options:
  // gRPC server endpoint
  grpcServerEndpoint = flag.String(&quot;grpc-server-endpoint&quot;,  &quot;localhost:9090&quot;, &quot;gRPC server endpoint&quot;)
)

func run() error {
  ctx := context.Background()
  ctx, cancel := context.WithCancel(ctx)
  defer cancel()

  // Register gRPC server endpoint
  // Note: Make sure the gRPC server is running properly and accessible
  mux := runtime.NewServeMux()
  opts := []grpc.DialOption{grpc.WithTransportCredentials(insecure.NewCredentials())}
  err := gw.RegisterYourServiceHandlerFromEndpoint(ctx, mux,  *grpcServerEndpoint, opts)
  if err != nil {
    return err
  }

  // Start HTTP server (and proxy calls to gRPC server endpoint)
  return http.ListenAndServe(&quot;:8081&quot;, mux)
}

func main() {
  flag.Parse()

  if err := run(); err != nil {
    grpclog.Fatal(err)
  }
}
```

### 6. (Optional) Generate OpenAPI definitions using `protoc-gen-openapiv2`

Here&#039;s what a `buf.gen.yaml` file might look like:

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - generate_unbound_methods=true
  - local: protoc-gen-openapiv2
    out: gen/go
```

To use the custom protobuf annotations supported by `protoc-gen-openapiv2`, we need
another dependency added to our protobuf generation step. If you are using
`buf`, you can add the `buf.build/grpc-ecosystem/grpc-gateway` dependency
to your `deps` array:

```yaml
version: v2
name: buf.build/yourorg/myprotos
deps:
  - buf.build/googleapis/googleapis
  - buf.build/grpc-ecosystem/grpc-gateway
```

With `protoc` (just the swagger file):

```sh
protoc -I . --openapiv2_out ./gen/openapiv2 \
    your/service/v1/your_service.proto
```

If you are using `protoc` to generate stubs, you will need to copy the protobuf
files from the `protoc-gen-openapiv2/options` directory of this repository,
and providing them to `protoc` when running.

Note that this plugin also supports generating OpenAPI definitions for unannotated methods;
use the `generate_unbound_methods` option to enable this.

It is possible with the HTTP mapping for a gRPC service method to create duplicate mappings
with the only difference being constraints on the path parameter.

`/v1/{name=projects/*}` and `/v1/{name=organizations/*}` both become `/v1/{name}`. When
this occurs the plugin will rename the path parameter with a &quot;\_1&quot; (or &quot;\_2&quot; etc) suffix
to differentiate the different operations. So in the above example, the 2nd path would become
`/v1/{name_1=organizations/*}`. This can also cause OpenAPI clients to URL encode the &quot;/&quot; that is
part of the path parameter as that is what OpenAPI defines in the specification. To allow gRPC gateway to
accept the URL encoded slash and still route the request, use the UnescapingModeAllCharacters or
UnescapingModeLegacy (which is the default currently though may change in future versions). See
[Customizing Your Gateway](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/customizing_your_gateway/)
for more information.

## Usage with remote plugins

As an alternative to all of the above, you can use `buf` with
[remote plugins](https://buf.build/docs/bsr/remote-plugins/usage)
to manage plugin versions and generation. An example `buf.gen.yaml` using remote
plugin generation looks like this:

```yaml
version: v2
plugins:
  - remote: buf.build/protocolbuffers/go:v1.31.0
    out: gen/go
    opt:
      - paths=source_relative
  - remote: buf.build/grpc/go:v1.3.0
    out: gen/go
    opt:
      - paths=source_relative
  - remote: buf.build/grpc-ecosystem/gateway:v2.16.2
    out: gen/go
    opt:
      - paths=source_relative
  - remote: buf.build/grpc-ecosystem/openapiv2:v2.16.2
    out: gen/openapiv2
```

This requires no local installation of any plugins. Be careful to use the same
version of the generator as the runtime library, i.e. if using `v2.16.2`, run

```shell
$ go get github.com/grpc-ecosystem/grpc-gateway/v2@v2.16.2
```

To get the same version of the runtime in your `go.mod`.

Note that usage of remote plugins is incompatible with usage of external configuration files like [grpc_api_configuration](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/grpc_api_configuration/#using-an-external-configuration-file).

## Video intro

This GopherCon UK 2019 presentation from our maintainer [@JohanBrandhorst](https://github.com/johanbrandhorst) provides a good intro to using the gRPC-Gateway. It uses the following boilerplate repo as a base: https://github.com/johanbrandhorst/grpc-gateway-boilerplate.

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.youtube.com/watch?v=Pq1paKC-fXk&quot;&gt;
&lt;img src=&quot;https://img.youtube.com/vi/Pq1paKC-fXk/0.jpg&quot; /&gt;
&lt;/a&gt;
&lt;/div&gt;

## Parameters and flags

When using `buf` to generate stubs, flags and parameters are passed through
the `opt` field in your `buf.gen.yaml` file, for example:

```yaml
version: v2
plugins:
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - grpc_api_configuration=path/to/config.yaml
      - standalone=true
```

During code generation with `protoc`, flags to gRPC-Gateway tools must be passed
through `protoc` using one of 2 patterns:

- as part of the `--&lt;tool_suffix&gt;_out` `protoc` parameter: `--&lt;tool_suffix&gt;_out=&lt;flags&gt;:&lt;path&gt;`

```sh
--grpc-gateway_out=repeated_path_param_separator=ssv:.
--openapiv2_out=repeated_path_param_separator=ssv:.
```

- using additional `--&lt;tool_suffix&gt;_opt` parameters: `--&lt;tool_suffix&gt;_opt=&lt;flag&gt;[,&lt;flag&gt;]*`

```sh
--grpc-gateway_opt repeated_path_param_separator=ssv
--openapiv2_opt repeated_path_param_separator=ssv
```

## More examples

More examples are available under the `examples` directory.

- `proto/examplepb/echo_service.proto`, `proto/examplepb/a_bit_of_everything.proto`, `proto/examplepb/unannotated_echo_service.proto`: service definition
  - `proto/examplepb/echo_service.pb.go`, `proto/examplepb/a_bit_of_everything.pb.go`, `proto/examplepb/unannotated_echo_service.pb.go`: [generated] stub of the service
  - `proto/examplepb/echo_service.pb.gw.go`, `proto/examplepb/a_bit_of_everything.pb.gw.go`, `proto/examplepb/uannotated_echo_service.pb.gw.go`: [generate

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes/dashboard]]></title>
            <link>https://github.com/kubernetes/dashboard</link>
            <guid>https://github.com/kubernetes/dashboard</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[General-purpose web UI for Kubernetes clusters]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes/dashboard">kubernetes/dashboard</a></h1>
            <p>General-purpose web UI for Kubernetes clusters</p>
            <p>Language: Go</p>
            <p>Stars: 15,001</p>
            <p>Forks: 4,237</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># Kubernetes Dashboard

[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/dashboard)](https://goreportcard.com/report/github.com/kubernetes/dashboard)
[![Coverage Status](https://codecov.io/github/kubernetes/dashboard/coverage.svg?branch=master)](https://codecov.io/github/kubernetes/dashboard?branch=master)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/kubernetes/dashboard/blob/master/LICENSE)

## Introduction

Kubernetes Dashboard is a general purpose, web-based UI for Kubernetes clusters. It allows users to manage applications running in the cluster and troubleshoot them, as well as manage the cluster itself.

As of version 7.0.0, we have dropped support for Manifest-based installation. Only Helm-based installation is supported now. Due to multi-container setup and hard dependency on Kong gateway API proxy
it would not be feasible to easily support Manifest-based installation.

Additionally, we have changed the versioning scheme and dropped `appVersion` from Helm chart. It is because, with a multi-container setup, every module is now versioned separately. Helm chart version
can be considered an app version now.

![Dashboard UI workloads page](docs/images/overview.png)

## Installation

Kubernetes Dashboard supports only Helm-based installation currently as it is faster and gives us better control
over all dependencies required by Dashboard to run. We now use a single-container, DBless [Kong](https://hub.docker.com/r/kong/kong-gateway) installation
as a gateway that connects all our containers and exposes the UI. Users can then use any ingress controller or proxy
in front of kong gateway. To find out more about ways to customize your installation check out [helm chart values](charts/kubernetes-dashboard/values.yaml).

In order to install Kubernetes Dashboard simply run:
```console
# Add kubernetes-dashboard repository
helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/
# Deploy a Helm Release named &quot;kubernetes-dashboard&quot; using the kubernetes-dashboard chart
helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard --create-namespace --namespace kubernetes-dashboard
```

For more information about our Helm chart visit [ArtifactHub](https://artifacthub.io/packages/helm/k8s-dashboard/kubernetes-dashboard).

## Documentation

Dashboard documentation can be found in the [docs](docs/README.md) directory which contains:

* [Common](docs/common/README.md): Entry-level overview.
* [User Guide](docs/user/README.md): Helpful information for users.
* [How to access Dashboard](docs/user/accessing-dashboard/README.md) - Everything you need to know to get access to you Kubernetes Dashboard instance after installation.
* [Access Control](docs/user/access-control/README.md): Find out how to control access to your Kubernetes Dashboard and [create sample user](docs/user/access-control/creating-sample-user.md) that can be used to log in.
* [Developer Guide](DEVELOPMENT.md): Important information for contributors that would like to test, run and work on Dashboard locally.

## Community, discussion, contribution, and support

Learn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).

You can reach the maintainers of this project at:

* [**#sig-ui on Kubernetes Slack**](https://kubernetes.slack.com)
* [**kubernetes-sig-ui mailing list** ](https://groups.google.com/forum/#!forum/kubernetes-sig-ui)
* [**Issue tracker**](https://github.com/kubernetes/dashboard/issues)
* [**SIG info**](https://github.com/kubernetes/community/tree/master/sig-ui)
* [**Roles**](ROLES.md)

### Contribution

Learn how to start contributing to the [Contributing Guideline](CONTRIBUTING.md).

### Code of conduct

Participation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).

## License

[Apache License 2.0](https://github.com/kubernetes/dashboard/blob/master/LICENSE)

----
_Copyright 2019 [The Kubernetes Dashboard Authors](https://github.com/kubernetes/dashboard/graphs/contributors)_
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[aquasecurity/kube-bench]]></title>
            <link>https://github.com/aquasecurity/kube-bench</link>
            <guid>https://github.com/aquasecurity/kube-bench</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[Checks whether Kubernetes is deployed according to security best practices as defined in the CIS Kubernetes Benchmark]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aquasecurity/kube-bench">aquasecurity/kube-bench</a></h1>
            <p>Checks whether Kubernetes is deployed according to security best practices as defined in the CIS Kubernetes Benchmark</p>
            <p>Language: Go</p>
            <p>Stars: 7,531</p>
            <p>Forks: 1,279</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>[![GitHub Release][release-img]][release]
[![Downloads][download]][release]
[![Docker Pulls][docker-pull]][docker]
[![Go Report Card][report-card-img]][report-card]
[![Build Status](https://github.com/aquasecurity/kube-bench/workflows/Build/badge.svg?branch=main)](https://github.com/aquasecurity/kube-bench/actions)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/aquasecurity/kube-bench/blob/main/LICENSE)
[![Coverage Status][cov-img]][cov]

[download]: https://img.shields.io/github/downloads/aquasecurity/kube-bench/total?logo=github
[release-img]: https://img.shields.io/github/release/aquasecurity/kube-bench.svg?logo=github
[release]: https://github.com/aquasecurity/kube-bench/releases
[docker-pull]: https://img.shields.io/docker/pulls/aquasec/kube-bench?logo=docker&amp;label=docker%20pulls%20%2F%20kube-bench
[docker]: https://hub.docker.com/r/aquasec/kube-bench
[cov-img]: https://codecov.io/github/aquasecurity/kube-bench/branch/main/graph/badge.svg
[cov]: https://codecov.io/github/aquasecurity/kube-bench
[report-card-img]: https://goreportcard.com/badge/github.com/aquasecurity/kube-bench
[report-card]: https://goreportcard.com/report/github.com/aquasecurity/kube-bench

&lt;img src=&quot;docs/images/kube-bench.png&quot; width=&quot;200&quot; alt=&quot;kube-bench logo&quot;&gt;

kube-bench is a tool that checks whether Kubernetes is deployed securely by running the checks documented in the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/).

Tests are configured with YAML files, making this tool easy to update as test specifications evolve.

![Kubernetes Bench for Security](/docs/images/output.png &quot;Kubernetes Bench for Security&quot;)

## CIS Scanning as part of Trivy and the Trivy Operator

[Trivy](https://github.com/aquasecurity/trivy), the all in one cloud native security scanner, can be deployed as a [Kubernetes Operator](https://github.com/aquasecurity/trivy-operator) inside a cluster.
Both, the [Trivy CLI](https://github.com/aquasecurity/trivy), and the [Trivy Operator](https://github.com/aquasecurity/trivy-operator) support CIS Kubernetes Benchmark scanning among several other features.

## Quick start

There are multiple ways to run kube-bench.
You can run kube-bench inside a pod, but it will need access to the host&#039;s PID namespace in order to check the running processes, as well as access to some directories on the host where config files and other files are stored.

The supplied `job.yaml` [file](job.yaml) can be applied to run the tests as a job. For example:

```bash
$ kubectl apply -f job.yaml
job.batch/kube-bench created

$ kubectl get pods
NAME                      READY   STATUS              RESTARTS   AGE
kube-bench-j76s9   0/1     ContainerCreating   0          3s

# Wait for a few seconds for the job to complete
$ kubectl get pods
NAME                      READY   STATUS      RESTARTS   AGE
kube-bench-j76s9   0/1     Completed   0          11s

# The results are held in the pod&#039;s logs
kubectl logs kube-bench-j76s9
[INFO] 1 Master Node Security Configuration
[INFO] 1.1 API Server
...
```
For more information and different ways to run kube-bench see [documentation](docs/running.md)
### Please Note

1. kube-bench implements the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as closely as possible. Please raise issues here if kube-bench is not correctly implementing the test as described in the Benchmark. To report issues in the Benchmark itself (for example, tests that you believe are inappropriate), please join the [CIS community](https://cisecurity.org).

1. There is not a one-to-one mapping between releases of Kubernetes and releases of the CIS benchmark. See [CIS Kubernetes Benchmark support](docs/platforms.md#cis-kubernetes-benchmark-support) to see which releases of Kubernetes are covered by different releases of the benchmark.


By default, kube-bench will determine the test set to run based on the Kubernetes version running on the machine.
- see the following documentation on [Running kube-bench](docs/running.md#running-kube-bench) for more details.


## Contributing
Kindly read [Contributing](CONTRIBUTING.md) before contributing. 
We welcome PRs and issue reports.

## Roadmap

Going forward we plan to release updates to kube-bench to add support for new releases of the CIS Benchmark. Note that these are not released as frequently as Kubernetes releases.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[stretchr/testify]]></title>
            <link>https://github.com/stretchr/testify</link>
            <guid>https://github.com/stretchr/testify</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[A toolkit with common assertions and mocks that plays nicely with the standard library]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stretchr/testify">stretchr/testify</a></h1>
            <p>A toolkit with common assertions and mocks that plays nicely with the standard library</p>
            <p>Language: Go</p>
            <p>Stars: 24,764</p>
            <p>Forks: 1,652</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>Testify - Thou Shalt Write Tests
================================

&gt; [!NOTE]
&gt; Testify is being maintained at v1, no breaking changes will be accepted in this repo.  
&gt; [See discussion about v2](https://github.com/stretchr/testify/discussions/1560).

[![Build Status](https://github.com/stretchr/testify/actions/workflows/main.yml/badge.svg?branch=master)](https://github.com/stretchr/testify/actions/workflows/main.yml) [![Go Report Card](https://goreportcard.com/badge/github.com/stretchr/testify)](https://goreportcard.com/report/github.com/stretchr/testify) [![PkgGoDev](https://pkg.go.dev/badge/github.com/stretchr/testify)](https://pkg.go.dev/github.com/stretchr/testify)

Go code (golang) set of packages that provide many tools for testifying that your code will behave as you intend.

Features include:

  * [Easy assertions](#assert-package)
  * [Mocking](#mock-package)
  * [Testing suite interfaces and functions](#suite-package)

Get started:

  * Install testify with [one line of code](#installation), or [update it with another](#staying-up-to-date)
  * For an introduction to writing test code in Go, see https://go.dev/doc/code#Testing
  * Check out the API Documentation https://pkg.go.dev/github.com/stretchr/testify
  * Use [testifylint](https://github.com/Antonboom/testifylint) (via [golangci-lint](https://golangci-lint.run/)) to avoid common mistakes
  * A little about [Test-Driven Development (TDD)](https://en.wikipedia.org/wiki/Test-driven_development)

[`assert`](https://pkg.go.dev/github.com/stretchr/testify/assert &quot;API documentation&quot;) package
-------------------------------------------------------------------------------------------

The `assert` package provides some helpful methods that allow you to write better test code in Go.

  * Prints friendly, easy to read failure descriptions
  * Allows for very readable code
  * Optionally annotate each assertion with a message

See it in action:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	// assert equality
	assert.Equal(t, 123, 123, &quot;they should be equal&quot;)

	// assert inequality
	assert.NotEqual(t, 123, 456, &quot;they should not be equal&quot;)

	// assert for nil (good for errors)
	assert.Nil(t, object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(t, object) {
		// now we know that object isn&#039;t nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(t, &quot;Something&quot;, object.Value)
	}
}
```

  * Every assert func takes the `testing.T` object as the first argument.  This is how it writes the errors out through the normal `go test` capabilities.
  * Every assert func returns a bool indicating whether the assertion was successful or not, this is useful for if you want to go on making further assertions under certain conditions.

if you assert many times, use the below:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	assert := assert.New(t)

	// assert equality
	assert.Equal(123, 123, &quot;they should be equal&quot;)

	// assert inequality
	assert.NotEqual(123, 456, &quot;they should not be equal&quot;)

	// assert for nil (good for errors)
	assert.Nil(object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(object) {
		// now we know that object isn&#039;t nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(&quot;Something&quot;, object.Value)
	}
}
```

[`require`](https://pkg.go.dev/github.com/stretchr/testify/require &quot;API documentation&quot;) package
---------------------------------------------------------------------------------------------

The `require` package provides same global functions as the `assert` package, but instead of returning a boolean result they terminate current test.
These functions must be called from the goroutine running the test or benchmark function, not from other goroutines created during the test.
Otherwise race conditions may occur.

See [t.FailNow](https://pkg.go.dev/testing#T.FailNow) for details.

[`mock`](https://pkg.go.dev/github.com/stretchr/testify/mock &quot;API documentation&quot;) package
----------------------------------------------------------------------------------------

The `mock` package provides a mechanism for easily writing mock objects that can be used in place of real objects when writing test code.

An example test function that tests a piece of code that relies on an external object `testObj`, can set up expectations (testify) and assert that they indeed happened:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/mock&quot;
)

/*
  Test objects
*/

// MyMockedObject is a mocked object that implements an interface
// that describes an object that the code I am testing relies on.
type MyMockedObject struct {
	mock.Mock
}

// DoSomething is a method on MyMockedObject that implements some interface
// and just records the activity, and returns what the Mock object tells it to.
//
// In the real object, this method would do something useful, but since this
// is a mocked object - we&#039;re just going to stub it out.
//
// NOTE: This method is not being tested here, code that uses this object is.
func (m *MyMockedObject) DoSomething(number int) (bool, error) {
	args := m.Called(number)
	return args.Bool(0), args.Error(1)
}

/*
  Actual test functions
*/

// TestSomething is an example of how to use our test object to
// make assertions about some target code we are testing.
func TestSomething(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations
	testObj.On(&quot;DoSomething&quot;, 123).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)
}

// TestSomethingWithPlaceholder is a second example of how to use our test object to
// make assertions about some target code we are testing.
// This time using a placeholder. Placeholders might be used when the
// data being passed in is normally dynamically generated and cannot be
// predicted beforehand (eg. containing hashes that are time sensitive)
func TestSomethingWithPlaceholder(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

}

// TestSomethingElse2 is a third example that shows how you can use
// the Unset method to cleanup handlers and then add new ones.
func TestSomethingElse2(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	mockCall := testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

	// remove the handler now so we can add another one that takes precedence
	mockCall.Unset()

	// return false now instead of true
	testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(false, nil)

	testObj.AssertExpectations(t)
}
```

For more information on how to write mock code, check out the [API documentation for the `mock` package](https://pkg.go.dev/github.com/stretchr/testify/mock).

You can use the [mockery tool](https://vektra.github.io/mockery/latest/) to autogenerate the mock code against an interface as well, making using mocks much quicker.

[`suite`](https://pkg.go.dev/github.com/stretchr/testify/suite &quot;API documentation&quot;) package
-----------------------------------------------------------------------------------------
&gt; [!WARNING]
&gt; The suite package does not support parallel tests. See [#934](https://github.com/stretchr/testify/issues/934).

The `suite` package provides functionality that you might be used to from more common object-oriented languages.  With it, you can build a testing suite as a struct, build setup/teardown methods and testing methods on your struct, and run them with &#039;go test&#039; as per normal.

An example suite is shown below:

```go
// Basic imports
import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
	&quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including a T() method which
// returns the current testing context
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	assert.Equal(suite.T(), 5, suite.VariableThatShouldStartAtFive)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
```

For a more complete example, using all of the functionality provided by the suite package, look at our [example testing suite](https://github.com/stretchr/testify/blob/master/suite/suite_test.go)

For more information on writing suites, check out the [API documentation for the `suite` package](https://pkg.go.dev/github.com/stretchr/testify/suite).

`Suite` object has assertion methods:

```go
// Basic imports
import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including assertion methods.
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	suite.Equal(suite.VariableThatShouldStartAtFive, 5)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
```

------

Installation
============

To install Testify, use `go get`:

    go get github.com/stretchr/testify

This will then make the following packages available to you:

    github.com/stretchr/testify/assert
    github.com/stretchr/testify/require
    github.com/stretchr/testify/mock
    github.com/stretchr/testify/suite
    github.com/stretchr/testify/http (deprecated)

Import the `testify/assert` package into your code using this template:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	assert.True(t, true, &quot;True is true!&quot;)
}
```

------

Staying up to date
==================

To update Testify to the latest version, use `go get -u github.com/stretchr/testify`.

------

Supported go versions
==================

We currently support the most recent major Go versions from 1.19 onward.

------

Contributing
============

Please feel free to submit issues, fork the repository and send pull requests!

When submitting an issue, we ask that you please include a complete test function that demonstrates the issue. Extra credit for those using Testify to write the test code that demonstrates it.

Code generation is used. [Look for `Code generated with`](https://github.com/search?q=repo%3Astretchr%2Ftestify%20%22Code%20generated%20with%22&amp;type=code) at the top of some files. Run `go generate ./...` to update generated files.

We also chat on the [Gophers Slack](https://gophers.slack.com) group in the `#testify` and `#testify-dev` channels.

------

License
=======

This project is licensed under the terms of the MIT license.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gruntwork-io/terragrunt]]></title>
            <link>https://github.com/gruntwork-io/terragrunt</link>
            <guid>https://github.com/gruntwork-io/terragrunt</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in OpenTofu/Terraform to scale.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gruntwork-io/terragrunt">gruntwork-io/terragrunt</a></h1>
            <p>Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in OpenTofu/Terraform to scale.</p>
            <p>Language: Go</p>
            <p>Stars: 8,729</p>
            <p>Forks: 1,050</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># Terragrunt

[![Maintained by Gruntwork.io](https://img.shields.io/badge/maintained%20by-gruntwork.io-%235849a6.svg)](https://gruntwork.io/?ref=repo_terragrunt)
[![Go Report Card](https://goreportcard.com/badge/github.com/gruntwork-io/terragrunt)](https://goreportcard.com/report/github.com/gruntwork-io/terragrunt)
[![GoDoc](https://godoc.org/github.com/gruntwork-io/terragrunt?status.svg)](https://godoc.org/github.com/gruntwork-io/terragrunt)
![OpenTofu Version](https://img.shields.io/badge/tofu-%3E%3D1.6.0-blue.svg)
![Terraform Version](https://img.shields.io/badge/tf-%3E%3D0.12.0-blue.svg)

Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in [OpenTofu](https://opentofu.org)/[Terraform](https://www.terraform.io) to scale.

Please see the following for more info, including install instructions and complete documentation:

* [Terragrunt Website](https://terragrunt.gruntwork.io)
* [Getting started with Terragrunt](https://terragrunt.gruntwork.io/docs/getting-started/quick-start/)
* [Terragrunt Documentation](https://terragrunt.gruntwork.io/docs)
* [Contributing to Terragrunt](https://terragrunt.gruntwork.io/docs/community/contributing)
* [Commercial Support](https://gruntwork.io/support/)

## Join the Discord!

Join [our community](https://discord.gg/YENaT9h8jh) for discussions, support, and contributions:

[![](https://dcbadge.limes.pink/api/server/https://discord.gg/YENaT9h8jh)](https://discord.gg/YENaT9h8jh)

## License

This code is released under the MIT License. See [LICENSE.txt](LICENSE.txt).

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[golang/tools]]></title>
            <link>https://github.com/golang/tools</link>
            <guid>https://github.com/golang/tools</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[[mirror] Go Tools]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/golang/tools">golang/tools</a></h1>
            <p>[mirror] Go Tools</p>
            <p>Language: Go</p>
            <p>Stars: 7,731</p>
            <p>Forks: 2,310</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># Go Tools

[![PkgGoDev](https://pkg.go.dev/badge/golang.org/x/tools)](https://pkg.go.dev/golang.org/x/tools)

This repository provides the `golang.org/x/tools` module, comprising
various tools and packages mostly for static analysis of Go programs,
some of which are listed below.
Use the &quot;Go reference&quot; link above for more information about any package.

It also contains the
[`golang.org/x/tools/gopls`](https://pkg.go.dev/golang.org/x/tools/gopls)
module, whose root package is a language-server protocol (LSP) server for Go.
An LSP server analyses the source code of a project and
responds to requests from a wide range of editors such as VSCode and
Vim, allowing them to support IDE-like functionality.

&lt;!-- List only packages of general interest below. --&gt;

Selected commands:

- `cmd/goimports` formats a Go program like `go fmt` and additionally
  inserts import statements for any packages required by the file
  after it is edited.
- `cmd/callgraph` prints the call graph of a Go program.
- `cmd/digraph` is a utility for manipulating directed graphs in textual notation.
- `cmd/stringer` generates declarations (including a `String` method) for &quot;enum&quot; types.
- `cmd/toolstash` is a utility to simplify working with multiple versions of the Go toolchain.

These commands may be fetched with a command such as
```
go install golang.org/x/tools/cmd/goimports@latest
```

Selected packages:

- `go/ssa` provides a static single-assignment form (SSA) intermediate
  representation (IR) for Go programs, similar to a typical compiler,
  for use by analysis tools.

- `go/packages` provides a simple interface for loading, parsing, and
  type checking a complete Go program from source code.

- `go/analysis` provides a framework for modular static analysis of Go
  programs.

- `go/callgraph` provides call graphs of Go programs using a variety
  of algorithms with different trade-offs.

- `go/ast/inspector` provides an optimized means of traversing a Go
  parse tree for use in analysis tools.

- `go/cfg` provides a simple control-flow graph (CFG) for a Go function.

- `go/gcexportdata` and `go/gccgoexportdata` read and write the binary
  files containing type information used by the standard and `gccgo` compilers.

- `go/types/objectpath` provides a stable naming scheme for named
  entities (&quot;objects&quot;) in the `go/types` API.

Numerous other packages provide more esoteric functionality.

&lt;!-- Some that didn&#039;t make the cut:

golang.org/x/tools/benchmark/parse
golang.org/x/tools/go/ast/astutil
golang.org/x/tools/go/types/typeutil
golang.org/x/tools/playground
golang.org/x/tools/present
golang.org/x/tools/refactor/importgraph
golang.org/x/tools/refactor/rename
golang.org/x/tools/refactor/satisfy
golang.org/x/tools/txtar

--&gt;

## Contributing

This repository uses Gerrit for code changes.
To learn how to submit changes, see https://go.dev/doc/contribute.

The git repository is https://go.googlesource.com/tools.

The main issue tracker for the tools repository is located at
https://go.dev/issues. Prefix your issue with &quot;x/tools/(your
subdir):&quot; in the subject line, so it is easy to find.

### JavaScript and CSS Formatting

This repository uses [prettier](https://prettier.io/) to format JS and CSS files.

The version of `prettier` used is 1.18.2.

It is encouraged that all JS and CSS code be run through this before submitting
a change. However, it is not a strict requirement enforced by CI.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[fleetdm/fleet]]></title>
            <link>https://github.com/fleetdm/fleet</link>
            <guid>https://github.com/fleetdm/fleet</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[Open-source platform for IT, security, and infrastructure teams. (Linux, macOS, Chrome, Windows, cloud, data center)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fleetdm/fleet">fleetdm/fleet</a></h1>
            <p>Open-source platform for IT, security, and infrastructure teams. (Linux, macOS, Chrome, Windows, cloud, data center)</p>
            <p>Language: Go</p>
            <p>Stars: 5,107</p>
            <p>Forks: 597</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;&lt;a href=&quot;https://fleetdm.com&quot;&gt;&lt;img width=&quot;200&quot; alt=&quot;Fleet logo, landscape, dark text, transparent background&quot; src=&quot;https://github.com/user-attachments/assets/5b52c536-f33e-4159-b2a3-d48f31868cd2&quot;&gt;&lt;/a&gt;&lt;/h1&gt;


#### [News](https://fleetdm.com/announcements) &amp;nbsp; ¬∑ &amp;nbsp; [Report a bug](https://github.com/fleetdm/fleet/issues/new) &amp;nbsp; ¬∑ &amp;nbsp; [Handbook](https://fleetdm.com/handbook/company) &amp;nbsp; ¬∑ &amp;nbsp; [Why open source?](https://fleetdm.com/handbook/company/why-this-way#why-open-source) &amp;nbsp; ¬∑ &amp;nbsp; [Art](https://fleetdm.com/logos)


Open-source platform for IT and security teams with thousands of computers.  Designed for APIs, GitOps, webhooks, YAML, and humans.

&lt;a href=&quot;https://fleetdm.com/logos&quot;&gt;&lt;img src=&quot;https://github.com/fleetdm/fleet/assets/618009/f835ec29-1cb9-49ba-a0f3-395ffd9d5c9f&quot; alt=&quot;A glass city in the clouds&quot;/&gt;&lt;/a&gt;


## What&#039;s it for?
Organizations like Fastly and Gusto use Fleet for vulnerability reporting, detection engineering, device management (MDM), device health monitoring, posture-based access control, managing unused software licenses, and more.

#### Explore data
To see what kind of data you can use Fleet to gather, check out the [table reference documentation](https://fleetdm.com/tables).

#### Out-of-the-box policies
Fleet includes out-of-the box support for all [CIS benchmarks for macOS and Windows](https://fleetdm.com/docs/using-fleet/cis-benchmarks), as well as many [simpler queries](https://fleetdm.com/queries).

Take as much or as little as you need for your organization.

#### Supported platforms
Here are the platforms Fleet currently supports:

- Linux (all distros)
- macOS
- Windows
- Chromebooks
- Amazon Web Services (AWS)
- Google Cloud (GCP)
- Azure (Microsoft cloud)
- Data centers
- Containers (kube, etc)
- Linux-based IoT devices

## Lighter than air
Fleet is lightweight and modular.  You can use it for security without using it for MDM, and vice versa.  You can turn off features you are not using.

#### Openness
Fleet is dedicated to flexibility, accessibility, and clarity.  We think [everyone can contribute](https://fleetdm.com/handbook/company#openness) and that tools should be as easy as possible for everyone to understand.

#### Good neighbors
Fleet has no ambition to replace all of your other tools.  (Though it might replace some, if you want it to.)  Ready-to-use, enterprise-friendly integrations exist for Snowflake, Splunk, GitHub Actions, Vanta, Elastic Jira, Zendesk, and more.

Fleet plays well with Munki, Chef, Puppet, and Ansible, as well as with security tools like Crowdstrike and SentinelOne.  For example, you can use the free version of Fleet to quickly report on what hosts are _actually_ running your EDR agent.

#### Free as in free
The free version of Fleet will [always be free](https://fleetdm.com/pricing).  Fleet is [independently backed](https://linkedin.com/company/fleetdm) and actively maintained with the help of many amazing [contributors](https://github.com/fleetdm/fleet/graphs/contributors).

#### Longevity
The [company behind Fleet](https://fleetdm.com/handbook/company) is founded (and majority-owned) by [true believers in open source](https://fleetdm.com/handbook/company/why-this-way#why-open-source).  The company&#039;s business model is influenced by GitLab (NYSE: GTLB), with great investors, happy customers, and the capacity to become profitable at any time.

In keeping with Fleet&#039;s value of openness, [Fleet Device Management&#039;s company handbook](https://fleetdm.com/handbook/company) is public and open source.  You can read about the [history of Fleet and osquery](https://fleetdm.com/handbook/company#history) and our commitment to improving the product.

&lt;!-- &gt; To upgrade from Fleet ‚â§3.2.0, just follow the upgrading steps for the earliest subsequent major release from this repository (it&#039;ll work out of the box until the release of Fleet 5.0). --&gt;


## Is it any good?
Fleet is used in production by IT and security teams with thousands of laptops and servers.  Many deployments support tens of thousands of hosts, and a few large organizations manage deployments as large as 400,000+ hosts.



## Chat
Please join us in [MacAdmins Slack](https://www.macadmins.org/) or in [osquery Slack](https://fleetdm.com/slack).

The Fleet community is full of [kind and helpful people](https://fleetdm.com/handbook/company#empathy).  Whether or not you are a paying customer, if you need help, just ask.


## Contributing &amp;nbsp; [![Run Tests](https://github.com/fleetdm/fleet/actions/workflows/test.yml/badge.svg)](https://github.com/fleetdm/fleet/actions/workflows/test.yml) &amp;nbsp; [![Go Report Card](https://goreportcard.com/badge/github.com/fleetdm/fleet)](https://goreportcard.com/report/github.com/fleetdm/fleet) &amp;nbsp; [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5537/badge)](https://bestpractices.coreinfrastructure.org/projects/5537) &amp;nbsp; [![Twitter Follow](https://img.shields.io/twitter/follow/fleetctl.svg?style=social&amp;maxAge=3600)](https://twitter.com/fleetctl) &amp;nbsp; 

The landscape of cybersecurity and IT is too complex.  Let&#039;s open it up.

Contributions are welcome, whether you answer questions on [Slack](https://fleetdm.com/slack) / [GitHub](https://github.com/fleetdm/fleet/issues) / [StackOverflow](https://stackoverflow.com/search?q=osquery) / [LinkedIn](https://linkedin.com/company/fleetdm) / [Twitter](https://twitter.com/fleetctl), improve the documentation or [website](./website), write a tutorial, give a talk at a conference or local meetup, give an [interview on a podcast](https://fleetdm.com/podcasts), troubleshoot reported issues, or [submit a patch](https://fleetdm.com/docs/contributing/contributing).  The Fleet code of conduct is [on GitHub](https://github.com/fleetdm/fleet/blob/main/CODE_OF_CONDUCT.md).

&lt;!-- - Great contributions are motivated by real-world use cases or learning.
- Some of the most valuable contributions might not touch any code at all.
- Small, iterative, simple (boring) changes are the easiest to merge. --&gt;

## What&#039;s next?
To see what Fleet can do, head over to [fleetdm.com](https://fleetdm.com) and try it out for yourself, grab time with one of the maintainers to discuss, or visit the docs and roll it out to your organization.

#### Production deployment
Fleet is simple enough to [spin up for yourself](https://fleetdm.com/docs/get-started/tutorials-and-guides).  Or you can have us [host it for you](https://fleetdm.com/pricing).  Premium features are [available](https://fleetdm.com/pricing) either way.

#### Documentation
Complete documentation for Fleet can be found at [https://fleetdm.com/docs](https://fleetdm.com/docs).


## License
The free version of Fleet is available under the MIT license.  The commercial license is also designed to allow contributions to paid features for users whose employment agreements allow them to contribute to open source projects.  (See LICENSE.md for details.)

&gt; Fleet is built on [osquery](https://github.com/osquery/osquery), [nanoMDM](https://github.com/micromdm/nanomdm), [Nudge](https://github.com/macadmins/nudge), and [swiftDialog](https://github.com/swiftDialog/swiftDialog).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grafana/loki]]></title>
            <link>https://github.com/grafana/loki</link>
            <guid>https://github.com/grafana/loki</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[Like Prometheus, but for logs.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grafana/loki">grafana/loki</a></h1>
            <p>Like Prometheus, but for logs.</p>
            <p>Language: Go</p>
            <p>Stars: 25,681</p>
            <p>Forks: 3,687</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/sources/logo_and_name.png&quot; alt=&quot;Loki Logo&quot;&gt;&lt;/p&gt;

&lt;a href=&quot;https://github.com/grafana/loki/actions/workflows/check.yml&quot;&gt;&lt;img src=&quot;https://github.com/grafana/loki/actions/workflows/check.yml/badge.svg&quot; alt=&quot;Check&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://goreportcard.com/report/github.com/grafana/loki&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/grafana/loki&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://slack.grafana.com/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/join%20slack-%23loki-brightgreen.svg&quot; alt=&quot;Slack&quot; /&gt;&lt;/a&gt;
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/loki.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:loki)

# Loki: like Prometheus, but for logs.

Loki is a horizontally-scalable, highly-available, multi-tenant log aggregation system inspired by [Prometheus](https://prometheus.io/).
It is designed to be very cost effective and easy to operate.
It does not index the contents of the logs, but rather a set of labels for each log stream.

Compared to other log aggregation systems, Loki:

- does not do full text indexing on logs. By storing compressed, unstructured logs and only indexing metadata, Loki is simpler to operate and cheaper to run.
- indexes and groups log streams using the same labels you‚Äôre already using with Prometheus, enabling you to seamlessly switch between metrics and logs using the same labels that you‚Äôre already using with Prometheus.
- is an especially good fit for storing [Kubernetes](https://kubernetes.io/) Pod logs. Metadata such as Pod labels is automatically scraped and indexed.
- has native support in Grafana (needs Grafana v6.0).

A Loki-based logging stack consists of 3 components:

- [Alloy](https://github.com/grafana/alloy) is agent, responsible for gathering logs and sending them to Loki.
- [Loki](https://github.com/grafana/loki) is the main service, responsible for storing logs and processing queries.
- [Grafana](https://github.com/grafana/grafana) for querying and displaying the logs.

**Note that Alloy replaced Promtail in the stack, because Promtail is considered to be feature complete, and future development for logs collection will be in [Grafana Alloy](https://github.com/grafana/alloy).**

Loki is like Prometheus, but for logs: we prefer a multidimensional label-based approach to indexing, and want a single-binary, easy to operate system with no dependencies.
Loki differs from Prometheus by focusing on logs instead of metrics, and delivering logs via push, instead of pull.

## Getting started

* [Installing Loki](https://grafana.com/docs/loki/latest/installation/)
* [Installing Alloy](https://grafana.com/docs/loki/latest/send-data/alloy/)
* [Getting Started](https://grafana.com/docs/loki/latest/get-started/)

## Upgrading

* [Upgrading Loki](https://grafana.com/docs/loki/latest/upgrading/)

## Documentation

* [Latest release](https://grafana.com/docs/loki/latest/)
* [Upcoming release](https://grafana.com/docs/loki/next/), at the tip of the main branch

Commonly used sections:

- [API documentation](https://grafana.com/docs/loki/latest/api/) for getting logs into Loki.
- [Labels](https://grafana.com/docs/loki/latest/getting-started/labels/)
- [Operations](https://grafana.com/docs/loki/latest/operations/)
- [Promtail](https://grafana.com/docs/loki/latest/clients/promtail/) is an agent which tails log files and pushes them to Loki.
- [Pipelines](https://grafana.com/docs/loki/latest/clients/promtail/pipelines/) details the log processing pipeline.
- [Docker Driver Client](https://grafana.com/docs/loki/latest/clients/docker-driver/) is a Docker plugin to send logs directly to Loki from Docker containers.
- [LogCLI](https://grafana.com/docs/loki/latest/query/logcli/) provides a command-line interface for querying logs.
- [Loki Canary](https://grafana.com/docs/loki/latest/operations/loki-canary/) monitors your Loki installation for missing logs.
- [Troubleshooting](https://grafana.com/docs/loki/latest/operations/troubleshooting/) presents help dealing with error messages.
- [Loki in Grafana](https://grafana.com/docs/loki/latest/operations/grafana/) describes how to set up a Loki datasource in Grafana.

## Getting Help

If you have any questions or feedback regarding Loki:

- Search existing thread in the Grafana Labs community forum for Loki: [https://community.grafana.com](https://community.grafana.com/c/grafana-loki/)
- Ask a question on the Loki Slack channel. To invite yourself to the Grafana Slack, visit [https://slack.grafana.com/](https://slack.grafana.com/) and join the #loki channel.
- [File an issue](https://github.com/grafana/loki/issues/new) for bugs, issues and feature suggestions.
- Send an email to [lokiproject@googlegroups.com](mailto:lokiproject@googlegroups.com), or use the [web interface](https://groups.google.com/forum/#!forum/lokiproject).
- UI issues should be filed directly in [Grafana](https://github.com/grafana/grafana/issues/new).

Your feedback is always welcome.

## Further Reading

- The original [design doc](https://docs.google.com/document/d/11tjK_lvp1-SVsFZjgOTr1vV3-q6vBAsZYIQ5ZeYBkyM/view) for Loki is a good source for discussion of the motivation and design decisions.
- Callum Styan&#039;s March 2019 DevOpsDays Vancouver talk &quot;[Grafana Loki: Log Aggregation for Incident Investigations][devopsdays19-talk]&quot;.
- Grafana Labs blog post &quot;[How We Designed Loki to Work Easily Both as Microservices and as Monoliths][architecture-blog]&quot;.
- Tom Wilkie&#039;s early-2019 CNCF Paris/FOSDEM talk &quot;[Grafana Loki: like Prometheus, but for logs][fosdem19-talk]&quot; ([slides][fosdem19-slides], [video][fosdem19-video]).
- David Kaltschmidt&#039;s KubeCon 2018 talk &quot;[On the OSS Path to Full Observability with Grafana][kccna18-event]&quot; ([slides][kccna18-slides], [video][kccna18-video]) on how Loki fits into a cloud-native environment.
- Goutham Veeramachaneni&#039;s blog post &quot;[Loki: Prometheus-inspired, open source logging for cloud natives](https://grafana.com/blog/2018/12/12/loki-prometheus-inspired-open-source-logging-for-cloud-natives/)&quot; on details of the Loki architecture.
- David Kaltschmidt&#039;s blog post &quot;[Closer look at Grafana&#039;s user interface for Loki](https://grafana.com/blog/2019/01/02/closer-look-at-grafanas-user-interface-for-loki/)&quot; on the ideas that went into the logging user interface.

[devopsdays19-talk]: https://grafana.com/blog/2019/05/06/how-loki-correlates-metrics-and-logs--and-saves-you-money/
[architecture-blog]: https://grafana.com/blog/2019/04/15/how-we-designed-loki-to-work-easily-both-as-microservices-and-as-monoliths/
[fosdem19-talk]: https://fosdem.org/2019/schedule/event/loki_prometheus_for_logs/
[fosdem19-slides]: https://speakerdeck.com/grafana/grafana-loki-like-prometheus-but-for-logs
[fosdem19-video]: https://mirror.as35701.net/video.fosdem.org/2019/UB2.252A/loki_prometheus_for_logs.mp4
[kccna18-event]: https://kccna18.sched.com/event/GrXC/on-the-oss-path-to-full-observability-with-grafana-david-kaltschmidt-grafana-labs
[kccna18-slides]: https://speakerdeck.com/davkal/on-the-path-to-full-observability-with-oss-and-launch-of-loki
[kccna18-video]: https://www.youtube.com/watch?v=U7C5SpRtK74&amp;list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU&amp;index=346

## Contributing

Refer to [CONTRIBUTING.md](CONTRIBUTING.md)

### Building from source

Loki can be run in a single host, no-dependencies mode using the following commands.

You need an up-to-date version of [Go](https://go.dev/), we recommend using the version found in our [Makefile](https://github.com/grafana/loki/blob/main/Makefile)

```bash
# Checkout source code
$ git clone https://github.com/grafana/loki
$ cd loki

# Build binary
$ go build ./cmd/loki

# Run executable
$ ./loki -config.file=./cmd/loki/loki-local-config.yaml
```

Alternatively, on Unix systems you can use `make` to build the binary, which adds additional arguments to the `go build` command.

```bash
# Build binary
$ make loki

# Run executable
$ ./cmd/loki/loki -config.file=./cmd/loki/loki-local-config.yaml
```

To build Promtail on non-Linux platforms, use the following command:

```bash
$ go build ./clients/cmd/promtail
```

On Linux, Promtail requires the systemd headers to be installed if
Journal support is enabled.
To enable Journal support the go build tag flag `promtail_journal_enabled` should be passed

With Journal support on Ubuntu, run with the following commands:

```bash
$ sudo apt install -y libsystemd-dev
$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail
```

With Journal support on CentOS, run with the following commands:

```bash
$ sudo yum install -y systemd-devel
$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail
```

Otherwise, to build Promtail without Journal support, run `go build`
with CGO disabled:

```bash
$ CGO_ENABLED=0 go build ./clients/cmd/promtail
```

## Adopters

Please see [ADOPTERS.md](ADOPTERS.md) for some of the organizations using Loki today.
If you would like to add your organization to the list, please open a PR to add it to the list.

## License

Grafana Loki is distributed under [AGPL-3.0-only](LICENSE). For Apache-2.0 exceptions, see [LICENSING.md](LICENSING.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grpc/grpc-go]]></title>
            <link>https://github.com/grpc/grpc-go</link>
            <guid>https://github.com/grpc/grpc-go</guid>
            <pubDate>Fri, 20 Jun 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[The Go language implementation of gRPC. HTTP/2 based RPC]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grpc/grpc-go">grpc/grpc-go</a></h1>
            <p>The Go language implementation of gRPC. HTTP/2 based RPC</p>
            <p>Language: Go</p>
            <p>Stars: 21,944</p>
            <p>Forks: 4,517</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># gRPC-Go

[![GoDoc](https://pkg.go.dev/badge/google.golang.org/grpc)][API]
[![GoReportCard](https://goreportcard.com/badge/grpc/grpc-go)](https://goreportcard.com/report/github.com/grpc/grpc-go)
[![codecov](https://codecov.io/gh/grpc/grpc-go/graph/badge.svg)](https://codecov.io/gh/grpc/grpc-go)

The [Go][] implementation of [gRPC][]: A high performance, open source, general
RPC framework that puts mobile and HTTP/2 first. For more information see the
[Go gRPC docs][], or jump directly into the [quick start][].

## Prerequisites

- **[Go][]**: any one of the **two latest major** [releases][go-releases].

## Installation

Simply add the following import to your code, and then `go [build|run|test]`
will automatically fetch the necessary dependencies:


```go
import &quot;google.golang.org/grpc&quot;
```

&gt; **Note:** If you are trying to access `grpc-go` from **China**, see the
&gt; [FAQ](#FAQ) below.

## Learn more

- [Go gRPC docs][], which include a [quick start][] and [API
  reference][API] among other resources
- [Low-level technical docs](Documentation) from this repository
- [Performance benchmark][]
- [Examples](examples)
- [Contribution guidelines](CONTRIBUTING.md)

## FAQ

### I/O Timeout Errors

The `golang.org` domain may be blocked from some countries. `go get` usually
produces an error like the following when this happens:

```console
$ go get -u google.golang.org/grpc
package google.golang.org/grpc: unrecognized import path &quot;google.golang.org/grpc&quot; (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)
```

To build Go code, there are several options:

- Set up a VPN and access google.golang.org through that.

- With Go module support: it is possible to use the `replace` feature of `go
  mod` to create aliases for golang.org packages.  In your project&#039;s directory:

  ```sh
  go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest
  go mod tidy
  go mod vendor
  go build -mod=vendor
  ```

  Again, this will need to be done for all transitive dependencies hosted on
  golang.org as well. For details, refer to [golang/go issue
  #28652](https://github.com/golang/go/issues/28652).

### Compiling error, undefined: grpc.SupportPackageIsVersion

Please update to the latest version of gRPC-Go using
`go get google.golang.org/grpc`.

### How to turn on logging

The default logger is controlled by environment variables. Turn everything on
like this:

```console
$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99
$ export GRPC_GO_LOG_SEVERITY_LEVEL=info
```

### The RPC failed with error `&quot;code = Unavailable desc = transport is closing&quot;`

This error means the connection the RPC is using was closed, and there are many
possible reasons, including:
 1. mis-configured transport credentials, connection failed on handshaking
 1. bytes disrupted, possibly by a proxy in between
 1. server shutdown
 1. Keepalive parameters caused connection shutdown, for example if you have
    configured your server to terminate connections regularly to [trigger DNS
    lookups](https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779).
    If this is the case, you may want to increase your
    [MaxConnectionAgeGrace](https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters),
    to allow longer RPC calls to finish.

It can be tricky to debug this because the error happens on the client side but
the root cause of the connection being closed is on the server side. Turn on
logging on __both client and server__, and see if there are any transport
errors.

[API]: https://pkg.go.dev/google.golang.org/grpc
[Go]: https://golang.org
[Go module]: https://github.com/golang/go/wiki/Modules
[gRPC]: https://grpc.io
[Go gRPC docs]: https://grpc.io/docs/languages/go
[Performance benchmark]: https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608
[quick start]: https://grpc.io/docs/languages/go/quickstart
[go-releases]: https://golang.org/doc/devel/release.html
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>