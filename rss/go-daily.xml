<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Thu, 15 Jan 2026 00:05:52 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[mudler/LocalAI]]></title>
            <link>https://github.com/mudler/LocalAI</link>
            <guid>https://github.com/mudler/LocalAI</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:52 GMT</pubDate>
            <description><![CDATA[ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, MCP, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mudler/LocalAI">mudler/LocalAI</a></h1>
            <p>ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, MCP, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference</p>
            <p>Language: Go</p>
            <p>Stars: 41,547</p>
            <p>Forks: 3,404</p>
            <p>Stars today: 64 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;img width=&quot;300&quot; src=&quot;./core/http/static/logo.png&quot;&gt; &lt;br&gt;
&lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/fork&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI forks&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/stargazers&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI stars&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/pulls&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI pull-requests&quot;/&gt;
&lt;/a&gt;
&lt;a href=&#039;https://github.com/go-skynet/LocalAI/releases&#039;&gt;
&lt;img src=&#039;https://img.shields.io/github/release/go-skynet/LocalAI?&amp;label=Latest&amp;style=for-the-badge&#039;&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://hub.docker.com/r/localai/localai&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker&quot; alt=&quot;LocalAI Docker hub&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;tag=latest&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/quay.io-images-important.svg?&quot; alt=&quot;LocalAI Quay.io&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://twitter.com/LocalAI_API&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white&amp;label=LocalAI_API&quot; alt=&quot;Follow LocalAI_API&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://discord.gg/uJAeKSAGDy&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?color=blue&amp;label=Discord&amp;style=for-the-badge&amp;query=approximate_member_count&amp;url=https%3A%2F%2Fdiscordapp.com%2Fapi%2Finvites%2FuJAeKSAGDy%3Fwith_counts%3Dtrue&amp;logo=discord&quot; alt=&quot;Join LocalAI Discord Community&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/5539&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/5539&quot; alt=&quot;mudler%2FLocalAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; :bulb: Get help - [‚ùìFAQ](https://localai.io/faq/) [üí≠Discussions](https://github.com/go-skynet/LocalAI/discussions) [:speech_balloon: Discord](https://discord.gg/uJAeKSAGDy) [:book: Documentation website](https://localai.io/)
&gt;
&gt; [üíª Quickstart](https://localai.io/basics/getting_started/) [üñºÔ∏è Models](https://models.localai.io/) [üöÄ Roadmap](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap) [üõ´ Examples](https://github.com/mudler/LocalAI-examples) Try on 
[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;logo=telegram&amp;logoColor=white)](https://t.me/localaiofficial_bot)

[![tests](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml)[![Build and Release](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml)[![build container images](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml)[![Bump dependencies](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml)[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai)](https://artifacthub.io/packages/search?repo=localai)

**LocalAI** is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that&#039;s compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by [Ettore Di Giacinto](https://github.com/mudler).


## üìöüÜï Local Stack Family

üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:

&lt;table&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png&quot; width=&quot;300&quot; alt=&quot;LocalAGI Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI&#039;s Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png&quot; width=&quot;300&quot; alt=&quot;LocalRecall Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Screenshots / Video

### Youtube video

&lt;h1 align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=PDqYhB9nNHA&quot; target=&quot;_blank&quot;&gt; &lt;img width=&quot;300&quot; src=&quot;https://img.youtube.com/vi/PDqYhB9nNHA/0.jpg&quot;&gt; &lt;/a&gt;&lt;br&gt;
&lt;br&gt;
&lt;/h1&gt;


### Screenshots

| Talk Interface | Generate Audio |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk](./docs/assets/images/screenshots/screenshot_tts.png) | ![Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low](./docs/assets/images/screenshots/screenshot_tts.png) |

| Models Overview | Generate Images |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-20 LocalAI - Models](./docs/assets/images/screenshots/screenshot_gallery.png) | ![Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev](./docs/assets/images/screenshots/screenshot_image.png) |

| Chat Interface | Home |
| --- | --- |
| ![Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5](./docs/assets/images/screenshots/screenshot_chat.png) | ![Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)](./docs/assets/images/screenshots/screenshot_home.png) |

| Login | Swarm |
| --- | --- |
|![Screenshot 2025-03-31 at 12-09-59 ](./docs/assets/images/screenshots/screenshot_login.png) | ![Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard](./docs/assets/images/screenshots/screenshot_p2p.png) |

## üíª Quickstart

&gt; ‚ö†Ô∏è **Note:** The `install.sh` script is currently experiencing issues due to the heavy changes currently undergoing in LocalAI and may produce broken or misconfigured installations. Please use Docker installation (see below) or manual binary installation until [issue #8032](https://github.com/mudler/LocalAI/issues/8032) is resolved.

Run the installer script:

```bash
# Basic installation
curl https://localai.io/install.sh | sh
```

For more installation options, see [Installer Options](https://localai.io/installation/).

### macOS Download:

&lt;a href=&quot;https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;logo=apple&amp;logoColor=white&quot; alt=&quot;Download LocalAI for macOS&quot;/&gt;
&lt;/a&gt;

&gt; Note: the DMGs are not signed by Apple as quarantined. See https://github.com/mudler/LocalAI/issues/6268 for a workaround, fix is tracked here: https://github.com/mudler/LocalAI/issues/6244

### Containers (Docker, podman, ...)

&gt; **üí° Docker Run vs Docker Start**
&gt; 
&gt; - `docker run` creates and starts a new container. If a container with the same name already exists, this command will fail.
&gt; - `docker start` starts an existing container that was previously created with `docker run`.
&gt; 
&gt; If you&#039;ve already run LocalAI before and want to start it again, use: `docker start -i local-ai`

#### CPU only image:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
```

#### NVIDIA GPU Images:

```bash
# CUDA 13.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-13

# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# NVIDIA Jetson (L4T) ARM64
# CUDA 12 (for Nvidia AGX Orin and similar platforms)
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64

# CUDA 13 (for Nvidia DGX Spark)
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64-cuda-13
```

#### AMD GPU Images (ROCm):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
```

#### Intel GPU Images (oneAPI):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
```

#### Vulkan GPU Images:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
```

#### AIO Images (pre-downloaded models):

```bash
# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 13 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-13

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
```

For more information about the AIO images and pre-downloaded models, see [Container Documentation](https://localai.io/basics/container/).

To load models:

```bash
# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
```

&gt; ‚ö° **Automatic Backend Detection**: When you install models from the gallery or YAML files, LocalAI automatically detects your system&#039;s GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see [GPU Acceleration](https://localai.io/features/gpu-acceleration/#automatic-backend-detection).

For more information, see [üíª Getting started](https://localai.io/basics/getting_started/index.html), if you are interested in our roadmap items and future enhancements, you can see the [Issues labeled as Roadmap here](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)

## üì∞ Latest project news

- December 2025: [Dynamic Memory Resource reclaimer](https://github.com/mudler/LocalAI/pull/7583), [Automatic fitting of models to multiple GPUS(llama.cpp)](https://github.com/mudler/LocalAI/pull/7584), [Added Vibevoice backend](https://github.com/mudler/LocalAI/pull/7494)
- November 2025: Major improvements to the UX. Among these: [Import models via URL](https://github.com/mudler/LocalAI/pull/7245) and [Multiple chats and history](https://github.com/mudler/LocalAI/pull/7325)
- October 2025: üîå [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) support added for agentic capabilities with external tools
- September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.
- August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with `development` suffix in the gallery ): https://github.com/mudler/LocalAI/pull/6049 https://github.com/mudler/LocalAI/pull/6119 https://github.com/mudler/LocalAI/pull/6121 https://github.com/mudler/LocalAI/pull/6060
- July/August 2025: üîç [Object Detection](https://localai.io/features/object-detection/) added to the API featuring [rf-detr](https://github.com/roboflow/rf-detr)
- July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. [Read the release notes](https://github.com/mudler/LocalAI/releases/tag/v3.2.0)
- June 2025: [Backend management](https://github.com/mudler/LocalAI/pull/5607) has been added. Attention: extras images are going to be deprecated from the next release! Read [the backend management PR](https://github.com/mudler/LocalAI/pull/5607).
- May 2025: [Audio input](https://github.com/mudler/LocalAI/pull/5466) and [Reranking](https://github.com/mudler/LocalAI/pull/5396) in llama.cpp backend, [Realtime API](https://github.com/mudler/LocalAI/pull/5392),  Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).
- May 2025: Important: image name changes [See release](https://github.com/mudler/LocalAI/releases/tag/v2.29.0)
- Apr 2025: Rebrand, WebUI enhancements
- Apr 2025: [LocalAGI](https://github.com/mudler/LocalAGI) and [LocalRecall](https://github.com/mudler/LocalRecall) join the LocalAI family stack.
- Apr 2025: WebUI overhaul, AIO images updates
- Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images
- Jan 2025: LocalAI model release: https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3, SANA support in diffusers: https://github.com/mudler/LocalAI/pull/4603
- Dec 2024: stablediffusion.cpp backend (ggml) added ( https://github.com/mudler/LocalAI/pull/4289 )
- Nov 2024: Bark.cpp backend added ( https://github.com/mudler/LocalAI/pull/4287 )
- Nov 2024: Voice activity detection models (**VAD**) added to the API: https://github.com/mudler/LocalAI/pull/4204
- Oct 2024: examples moved to [LocalAI-examples](https://github.com/mudler/LocalAI-examples)
- Aug 2024:  üÜï FLUX-1, [P2P Explorer](https://explorer.localai.io)
- July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: https://github.com/mudler/LocalAI/pull/2723. P2P Global community pools: https://github.com/mudler/LocalAI/issues/3113
- May 2024: üî•üî• Decentralized P2P llama.cpp:  https://github.com/mudler/LocalAI/pull/2343 (peer2peer llama.cpp!) üëâ Docs  https://localai.io/features/distribute/
- May 2024: üî•üî• Distributed inferencing: https://github.com/mudler/LocalAI/pull/2324
- April 2024: Reranker API: https://github.com/mudler/LocalAI/pull/2121

Roadmap items: [List of issues](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)

## üöÄ [Features](https://localai.io/features/)

- üß© [Backend Gallery](https://localai.io/backends/): Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.
- üìñ [Text generation with GPTs](https://localai.io/features/text-generation/) (`llama.cpp`, `transformers`, `vllm` ... [:book: and more](https://localai.io/model-compatibility/index.html#model-compatibility-table))
- üó£ [Text to Audio](https://localai.io/features/text-to-audio/)
- üîà [Audio to Text](https://localai.io/features/audio-to-text/) (Audio transcription with `whisper.cpp`)
- üé® [Image generation](https://localai.io/features/image-generation)
- üî• [OpenAI-alike tools API](https://localai.io/features/openai-functions/) 
- üß† [Embeddings generation for vector databases](https://localai.io/features/embeddings/)
- ‚úçÔ∏è [Constrained grammars](https://localai.io/features/constrained_grammars/)
- üñºÔ∏è [Download Models directly from Huggingface ](https://localai.io/models/)
- ü•Ω [Vision API](https://localai.io/features/gpt-vision/)
- üîç [Object Detection](https://localai.io/features/object-detection/)
- üìà [Reranker API](https://localai.io/features/reranker/)
- üÜïüñß [P2P Inferencing](https://localai.io/features/distribute/)
- üÜïüîå [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) - Agentic capabilities with external tools and [LocalAGI&#039;s Agentic capabilities](https://github.com/mudler/LocalAGI)
- üîä Voice activity detection (Silero-VAD support)
- üåç Integrated WebUI!

## üß© Supported Backends &amp; Acceleration

LocalAI supports a comprehensive range of AI backends with multiple acceleration options:

### Text Generation &amp; Language Models
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **llama.cpp** | LLM inference in C/C++ | CUDA 12/13, ROCm, Intel SYCL, Vulkan, Metal, CPU |
| **vLLM** | Fast LLM inference with PagedAttention | CUDA 12/13, ROCm, Intel |
| **transformers** | HuggingFace transformers framework | CUDA 12/13, ROCm, Intel, CPU |
| **exllama2** | GPTQ inference library | CUDA 12/13 |
| **MLX** | Apple Silicon LLM inference | Metal (M1/M2/M3+) |
| **MLX-VLM** | Apple Silicon Vision-Language Models | Metal (M1/M2/M3+) |

### Audio &amp; Speech Processing
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **whisper.cpp** | OpenAI Whisper in C/C++ | CUDA 12/13, ROCm, Intel SYCL, Vulkan, CPU |
| **faster-whisper** | Fast Whisper with CTranslate2 | CUDA 12/13, ROCm, Intel, CPU |
| **bark** | Text-to-audio generation | CUDA 12/13, ROCm, Intel |
| **bark-cpp** | C++ implementation of Bark | CUDA, Metal, CPU |
| **coqui** | Advanced TTS with 1100+ languages | CUDA 12/13, ROCm, Intel, CPU |
| **kokoro** | Lightweight TTS model | CUDA 12/13, ROCm, Intel, CPU |
| **chatterbox** | Production-grade TTS | CUDA 12/13, CPU |
| **piper** | Fast neural TTS system | CPU |
| **kitten-tts** | Kitten TTS models | CPU |
| **silero-vad** | Voice Activity Detection | CPU |
| **neutts** | Text-to-speech with voice cloning | CUDA 12/13, ROCm, CPU |
| **vibevoice** | Real-time TTS with voice cloning | CUDA 12/13, ROCm, Intel, CPU |
| **pocket-tts** | Lightweight CPU-based TTS | CUDA 12/13, ROCm, Intel, CPU |

### Image &amp; Video Generation
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **stablediffusion.cpp** | Stable Diffusion in C/C++ | CUDA 12/13, Intel SYCL, Vulkan, CPU |
| **diffusers** | HuggingFace diffusion models | CUDA 12/13, ROCm, Intel, Metal, CPU |

### Specialized AI Tasks
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **rfdetr** | Real-time object detection | CUDA 12/13, Intel, CPU |
| **rerankers** | Document reranking API | CUDA 12/13, ROCm, Intel, CPU |
| **local-store** | Vector database | CPU |
| **huggingface** | HuggingFace API integration | API-based |

### Hardware Acceleration Matrix

| Acceleration Type | Supported Backends | Hardware Support |
|-------------------|-------------------|------------------|
| **NVIDIA CUDA 12** | All CUDA-compatible backends | Nvidia hardware |
| **NVIDIA CUDA 13** | All CUDA-compatible backends | Nvidia hardware |
| **AMD ROCm** | llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts, vibevoice, pocket-tts | AMD Graphics |
| **Intel oneAPI** | llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark, vibevoice, pocket-tts | Intel Arc, Intel iGPUs |
| **Apple Metal** | llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp | Apple M1/M2/M3+ |
| **Vulkan** | llama.cpp, whisper, stablediffusion | Cross-platform GPUs |
| **NVIDIA Jetson (CUDA 12)** | llama.cpp, whisper, stablediffusi

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[rancher/rancher]]></title>
            <link>https://github.com/rancher/rancher</link>
            <guid>https://github.com/rancher/rancher</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:51 GMT</pubDate>
            <description><![CDATA[Complete container management platform]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rancher/rancher">rancher/rancher</a></h1>
            <p>Complete container management platform</p>
            <p>Language: Go</p>
            <p>Stars: 25,132</p>
            <p>Forks: 3,142</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># Rancher

[![Docker Pulls](https://img.shields.io/docker/pulls/rancher/rancher.svg)](https://store.docker.com/community/images/rancher/rancher)
[![Go Report Card](https://goreportcard.com/badge/github.com/rancher/rancher)](https://goreportcard.com/report/github.com/rancher/rancher)

Rancher is an open source container management platform built for organizations that deploy containers in production. Rancher makes it easy to run Kubernetes everywhere, meet IT requirements, and empower DevOps teams.

## Stable Release


&lt;!-- stable v2.13.1 DO NOT REMOVE THIS LINE --&gt;
* v2.13
  * Stable - v2.13.1 - `rancher/rancher:v2.13.1` / `rancher/rancher:stable` - Read the full release [notes](https://github.com/rancher/rancher/releases/tag/v2.13.1).
* v2.12
  * Stable - v2.12.3 - `rancher/rancher:v2.12.3` - Read the full release [notes](https://github.com/rancher/rancher/releases/tag/v2.12.3).
* v2.11
  * Stable - v2.11.3 - `rancher/rancher:v2.11.3` - Read the full release [notes](https://github.com/rancher/rancher/releases/tag/v2.11.3).
  
To get automated notifications of our latest release, you can watch the announcements category in our [forums](http://forums.rancher.com/c/announcements), or subscribe to the RSS feed `https://forums.rancher.com/c/announcements.rss`.

## Quick Start

    sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher

Open your browser to https://localhost

## Installation

See [Installing/Upgrading Rancher](https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-and-upgrade) for all installation options.

### Minimum Requirements

* Operating Systems
  * Please see [Support Matrix](https://rancher.com/support-matrix/) for specific OS versions for each Rancher version. Note that the link will default to the support matrix for the latest version of Rancher. Use the left navigation menu to select a different Rancher version. 
* Hardware &amp; Software
  * Please see [Installation Requirements](https://ranchermanager.docs.rancher.com/v2.8/pages-for-subheaders/installation-requirements) for hardware and software requirements.

### Using Rancher

To learn more about using Rancher, please refer to our [Rancher Documentation](https://ranchermanager.docs.rancher.com/v2.8).

## Source Code

This repo is a meta-repo used for packaging and contains the majority of Rancher codebase. For other Rancher projects and modules, [see go.mod](https://github.com/rancher/rancher/blob/release/v2.8/go.mod) for the full list.

Rancher also includes other open source libraries and projects, [see go.mod](https://github.com/rancher/rancher/blob/release/v2.8/go.mod) for the full list.

## Build configuration

Refer to the [build docs](docs/build.md) on how to customize the building and packaging of Rancher.

## Support, Discussion, and Community
If you need any help with Rancher, please join us at either our [Rancher forums](http://forums.rancher.com/) or [Slack](https://slack.rancher.io/) where most of our team hangs out at.

Please submit any Rancher bugs, issues, and feature requests to [rancher/rancher](https://github.com/rancher/rancher/issues).

For security issues, please first check our [security policy](https://github.com/rancher/rancher/security) and email security-rancher@suse.com instead of posting a public issue in GitHub.  You may (but are not required to) use the GPG key located on [Keybase](https://keybase.io/rancher).

# License

Copyright (c) 2014-2025 [SUSE](http://rancher.com)

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Tencent/WeKnora]]></title>
            <link>https://github.com/Tencent/WeKnora</link>
            <guid>https://github.com/Tencent/WeKnora</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:50 GMT</pubDate>
            <description><![CDATA[LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Tencent/WeKnora">Tencent/WeKnora</a></h1>
            <p>LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.</p>
            <p>Language: Go</p>
            <p>Stars: 11,617</p>
            <p>Forks: 1,274</p>
            <p>Stars today: 114 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;img src=&quot;./docs/images/logo.png&quot; alt=&quot;WeKnora Logo&quot; height=&quot;120&quot;/&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/15289&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://trendshift.io/api/badge/repositories/15289&quot; alt=&quot;Tencent%2FWeKnora | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
    &lt;/a&gt;
  &lt;/picture&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://weknora.weixin.qq.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;ÂÆòÊñπÁΩëÁ´ô&quot; src=&quot;https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://chatbot.weixin.qq.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞&quot; src=&quot;https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/Tencent/WeKnora/blob/main/LICENSE&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;License&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;./CHANGELOG.md&quot;&gt;
        &lt;img alt=&quot;Version&quot; src=&quot;https://img.shields.io/badge/version-0.2.6-2e6cc4?labelColor=d4eaf7&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
| &lt;b&gt;English&lt;/b&gt; | &lt;a href=&quot;./README_CN.md&quot;&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;./README_JA.md&quot;&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; |
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;h4 align=&quot;center&quot;&gt;

  [Overview](#-overview) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [Key Features](#-key-features) ‚Ä¢ [Getting Started](#-getting-started) ‚Ä¢ [API Reference](#-api-reference) ‚Ä¢ [Developer Guide](#-developer-guide)
  
  &lt;/h4&gt;
&lt;/p&gt;

# üí° WeKnora - LLM-Powered Document Understanding &amp; Retrieval Framework

## üìå Overview

[**WeKnora**](https://weknora.weixin.qq.com) is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents. 

It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the **RAG (Retrieval-Augmented Generation)** paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.

**Website:** https://weknora.weixin.qq.com

## ‚ú® Latest Updates

**v0.2.0 Highlights:**

- ü§ñ **Agent Mode**: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection
- üìö **Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry
- ‚öôÔ∏è **Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior
- üåê **Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine
- üîå **MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods
- üé® **New UI**: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade
- ‚ö° **Infrastructure Upgrade**: Introduced MQ async task management, support for automatic database migration, and fast development mode

## üîí Security Notice

**Important:** Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:

- Deploy WeKnora services in internal/private network environments rather than public internet
- Avoid exposing the service directly to public networks to prevent potential information leakage
- Configure proper firewall rules and access controls for your deployment environment
- Regularly update to the latest version for security patches and improvements

## üèóÔ∏è Architecture

![weknora-architecture.png](./docs/images/architecture.png)

WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.

## üéØ Key Features

- **ü§ñ Agent Mode**: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection
- **üîç Precise Understanding**: Structured content extraction from PDFs, Word documents, images and more into unified semantic views
- **üß† Intelligent Reasoning**: Leverages LLMs to understand document context and user intent for accurate Q&amp;A and multi-turn conversations
- **üìö Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities
- **üîß Flexible Extension**: All components from parsing and embedding to retrieval and generation are decoupled for easy customization
- **‚ö° Efficient Retrieval**: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support
- **üåê Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine
- **üîå MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods
- **‚öôÔ∏è Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior
- **üéØ User-Friendly**: Intuitive web interface and standardized APIs for zero technical barriers
- **üîí Secure &amp; Controlled**: Support for local deployment and private cloud, ensuring complete data sovereignty

## üìä Application Scenarios

| Scenario | Applications | Core Value |
|---------|----------|----------|
| **Enterprise Knowledge Management** | Internal document retrieval, policy Q&amp;A, operation manual search | Improve knowledge discovery efficiency, reduce training costs |
| **Academic Research Analysis** | Paper retrieval, research report analysis, scholarly material organization | Accelerate literature review, assist research decisions |
| **Product Technical Support** | Product manual Q&amp;A, technical documentation search, troubleshooting | Enhance customer service quality, reduce support burden |
| **Legal &amp; Compliance Review** | Contract clause retrieval, regulatory policy search, case analysis | Improve compliance efficiency, reduce legal risks |
| **Medical Knowledge Assistance** | Medical literature retrieval, treatment guideline search, case analysis | Support clinical decisions, improve diagnosis quality |

## üß© Feature Matrix

| Module | Support                                                                        | Description                                                                                                                                                        |
|---------|--------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Agent Mode | ‚úÖ ReACT Agent Mode                                                             | Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations               |
| Knowledge Base Types | ‚úÖ FAQ / Document                                                               | Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry                                       |
| Document Formats | ‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)                    | Support for structured and unstructured documents with text extraction from images                                                                                 |
| Model Management | ‚úÖ Centralized configuration, built-in model sharing                            | Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models                                   |
| Embedding Models | ‚úÖ Local models, BGE / GTE APIs, etc.                                           | Customizable embedding models, compatible with local deployment and cloud vector generation APIs                                                                   |
| Vector DB Integration | ‚úÖ PostgreSQL (pgvector), Elasticsearch                                         | Support for mainstream vector index backends, flexible switching for different retrieval scenarios                                                                 |
| Retrieval Strategies | ‚úÖ BM25 / Dense Retrieval / GraphRAG                                            | Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines                                        |
| LLM Integration | ‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching  | Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration                                                     |
| Conversation Strategy | ‚úÖ Agent models, normal mode models, retrieval thresholds, Prompt configuration | Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior |
| Web Search | ‚úÖ Extensible search engines, DuckDuckGo / Google                               | Support for extensible web search engines with built-in DuckDuckGo search engine                                                                                   |
| MCP Tools | ‚úÖ uvx, npx launchers, Stdio/HTTP Streamable/SSE                                | Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods                                      |
| QA Capabilities | ‚úÖ Context-aware, multi-turn dialogue, prompt templates                         | Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;A with configurable prompts and context windows                                  |
| E2E Testing | ‚úÖ Retrieval+generation process visualization and metric evaluation             | End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics                                                            |
| Deployment Modes | ‚úÖ Support for local deployment / Docker images                                 | Meets private, offline deployment and flexible operation requirements, with fast development mode support                                                          |
| User Interfaces | ‚úÖ Web UI + RESTful API                                                         | Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display                                              |
| Task Management | ‚úÖ MQ async tasks, automatic database migration                                 | MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades                                            |

## üöÄ Getting Started

### üõ† Prerequisites

Make sure the following tools are installed on your system:

* [Docker](https://www.docker.com/)
* [Docker Compose](https://docs.docker.com/compose/)
* [Git](https://git-scm.com/)

### üì¶ Installation

#### ‚ë† Clone the repository

```bash
# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
```

#### ‚ë° Configure environment variables

```bash
# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
```

#### ‚ë¢ Start the services (include Ollama)

Check the images that need to be started in the .env file.

```bash
./scripts/start_all.sh
```

or

```bash
make start-all
```

#### ‚ë¢.0 Start ollama services (Optional)

```bash
ollama serve &gt; /dev/null 2&gt;&amp;1 &amp;
```

#### ‚ë¢.1 Activate different combinations of features

- Minimum core services
```bash
docker compose up -d
```

- All features enabled
```bash
docker-compose --profile full up -d
```

- Tracing logs required
```bash
docker-compose --profile jaeger up -d
```

- Neo4j knowledge graph required
```bash
docker-compose --profile neo4j up -d
```

- Minio file storage service required
```bash
docker-compose --profile minio up -d
```

- Multiple options combination
```bash
docker-compose --profile neo4j --profile minio up -d
```

#### ‚ë£ Stop the services

```bash
./scripts/start_all.sh --stop
# Or
make stop-all
```

### üåê Access Services

Once started, services will be available at:

* Web UI: `http://localhost`
* Backend API: `http://localhost:8080`
* Jaeger Tracing: `http://localhost:16686`

### üîå Using WeChat Dialog Open Platform

WeKnora serves as the core technology framework for the [WeChat Dialog Open Platform](https://chatbot.weixin.qq.com), providing a more convenient usage approach:

- **Zero-code Deployment**: Simply upload knowledge to quickly deploy intelligent Q&amp;A services within the WeChat ecosystem, achieving an &quot;ask and answer&quot; experience
- **Efficient Question Management**: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers
- **WeChat Ecosystem Integration**: Through the WeChat Dialog Open Platform, WeKnora&#039;s intelligent Q&amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences

### üîó Access WeKnora via MCP Server

#### 1Ô∏è‚É£ Clone the repository
```
git clone https://github.com/Tencent/WeKnora
```

#### 2Ô∏è‚É£ Configure MCP Server
&gt; It is recommended to directly refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for configuration.

Configure the MCP client to connect to the server:
```json
{
  &quot;mcpServers&quot;: {
    &quot;weknora&quot;: {
      &quot;args&quot;: [
        &quot;path/to/WeKnora/mcp-server/run_server.py&quot;
      ],
      &quot;command&quot;: &quot;python&quot;,
      &quot;env&quot;:{
        &quot;WEKNORA_API_KEY&quot;:&quot;Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk&quot;,
        &quot;WEKNORA_BASE_URL&quot;:&quot;http(s)://your-weknora-address/api/v1&quot;
      }
    }
  }
}
```

Run directly using stdio command:
```
pip install weknora-mcp-server
python -m weknora-mcp-server
```

## üîß Initialization Configuration Guide

To help users quickly configure various models and reduce trial-and-error costs, we&#039;ve improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows:
If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.

### ‚ë† Stop the services

```bash
./scripts/start_all.sh --stop
```

### ‚ë° Clear existing data tables (recommended when no important data exists)

```bash
make clean-db
```

### ‚ë¢ Compile and start services

```bash
./scripts/start_all.sh
```

### ‚ë£ Access Web UI

http://localhost

On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.

## üì± Interface Showcase

### Web UI Interface

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/knowledgebases.png&quot; alt=&quot;Knowledge Base Management&quot;&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/settings.png&quot; alt=&quot;Conversation Settings&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td colspan=&quot;2&quot;&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/agent-qa.png&quot; alt=&quot;Agent Mode Tool Call Process&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

**Knowledge Base Management:** Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.

**Agent Mode:** Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.

**Conversation Strategy:** Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.

### Document Knowledge Graph

WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.

For detailed configuration, please refer to the [Knowledge Graph Configuration Guide](./docs/KnowledgeGraph.md).

### MCP Server

Please refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for the necessary setup.

## üìò API Reference

Troubleshooting FAQ: [Troubleshooting FAQ](./docs/QA.md)

Detailed API documentation is available at: [API Docs](./docs/api/README.md)

## üß≠ Developer Guide

### ‚ö° Fast Development Mode (Recommended)

If you need to frequently modify code, **you don&#039;t need to rebuild Docker images every time**! Use fast development mode:

```bash
# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
```

**Development Advantages:**
- ‚úÖ Frontend modifications auto hot-reload (no restart needed)
- ‚úÖ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)
- ‚úÖ No need to rebuild Docker images
- ‚úÖ Support IDE breakpoint debugging

**Detailed Documentation:** [Development Environment Quick Start](./docs/ÂºÄÂèëÊåáÂçó.md)

### üìÅ Directory Structure

```
WeKnora/
‚îú‚îÄ‚îÄ client/      # go client
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ docker/      # docker images files
‚îú‚îÄ‚îÄ docreader/   # Document parsing app
‚îú‚îÄ‚îÄ docs/        # Project documentation
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ mcp-server/  # MCP server
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îî‚îÄ‚îÄ scripts/     # Shell scripts
```

## ü§ù Contributing

We welcome community contributions! For suggestions, bugs, or feature requests, please submit an [Issue](https://github.com/Tencent/WeKnora/issues) or directly create a Pull Request.

### üéØ How to Contribute

- üêõ **Bug Fixes

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[github/gh-ost]]></title>
            <link>https://github.com/github/gh-ost</link>
            <guid>https://github.com/github/gh-ost</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:49 GMT</pubDate>
            <description><![CDATA[GitHub's Online Schema-migration Tool for MySQL]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/github/gh-ost">github/gh-ost</a></h1>
            <p>GitHub's Online Schema-migration Tool for MySQL</p>
            <p>Language: Go</p>
            <p>Stars: 13,143</p>
            <p>Forks: 1,350</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># gh-ost

[![ci](https://github.com/github/gh-ost/actions/workflows/ci.yml/badge.svg)](https://github.com/github/gh-ost/actions/workflows/ci.yml) [![replica-tests](https://github.com/github/gh-ost/actions/workflows/replica-tests.yml/badge.svg)](https://github.com/github/gh-ost/actions/workflows/replica-tests.yml) [![downloads](https://img.shields.io/github/downloads/github/gh-ost/total.svg)](https://github.com/github/gh-ost/releases) [![release](https://img.shields.io/github/release/github/gh-ost.svg)](https://github.com/github/gh-ost/releases)

#### GitHub&#039;s online schema migration for MySQL &lt;img src=&quot;doc/images/gh-ost-logo-light-160.png&quot; align=&quot;right&quot;&gt;

 `gh-ost` is a triggerless online schema migration solution for MySQL. It is testable and provides pausability, dynamic control/reconfiguration, auditing, and many operational perks.

`gh-ost` produces a light workload on the master throughout the migration, decoupled from the existing workload on the migrated table.

It has been designed based on years of experience with existing solutions, and changes the paradigm of table migrations.



## How?

All existing online-schema-change tools operate in similar manner: they create a _ghost_ table in the likeness of your original table, migrate that table while empty, slowly and incrementally copy data from your original table to the _ghost_ table, meanwhile propagating ongoing changes (any `INSERT`, `DELETE`, `UPDATE` applied to your table) to the _ghost_ table. Finally, at the right time, they replace your original table with the _ghost_ table.

`gh-ost` uses the same pattern. However it differs from all existing tools by not using triggers. We have recognized the triggers to be the source of [many limitations and risks](doc/why-triggerless.md).

Instead, `gh-ost` [uses the binary log stream](doc/triggerless-design.md) to capture table changes, and asynchronously applies them onto the _ghost_ table. `gh-ost` takes upon itself some tasks that other tools leave for the database to perform. As result, `gh-ost` has greater control over the migration process; can truly suspend it; can truly decouple the migration&#039;s write load from the master&#039;s workload.

In addition, it offers many [operational perks](doc/perks.md) that make it safer, trustworthy and fun to use.

![gh-ost general flow](doc/images/gh-ost-general-flow.png)

## Highlights

- Build your trust in `gh-ost` by testing it on replicas. `gh-ost` will issue same flow as it would have on the master, to migrate a table on a replica, without actually replacing the original table, leaving the replica with two tables you can then compare and satisfy yourself that the tool operates correctly. This is how we continuously test `gh-ost` in production.
- True pause: when `gh-ost` [throttles](doc/throttle.md), it truly ceases writes on master: no row copies and no ongoing events processing. By throttling, you return your master to its original workload
- Dynamic control: you can [interactively](doc/interactive-commands.md) reconfigure `gh-ost`, even as migration still runs. You may forcibly initiate throttling.
- Auditing: you may query `gh-ost` for status. `gh-ost` listens on unix socket or TCP.
- Control over cut-over phase: `gh-ost` can be instructed to postpone what is probably the most critical step: the swap of tables, until such time that you&#039;re comfortably available. No need to worry about ETA being outside office hours.
- External [hooks](doc/hooks.md) can couple `gh-ost` with your particular environment.

Please refer to the [docs](doc) for more information. No, really, read the [docs](doc).

## Usage

The [cheatsheet](doc/cheatsheet.md) has it all. You may be interested in invoking `gh-ost` in various modes:

- a _noop_ migration (merely testing that the migration is valid and good to go)
- a real migration, utilizing a replica (the migration runs on the master; `gh-ost` figures out identities of servers involved. Required mode if your master uses Statement Based Replication)
- a real migration, run directly on the master (but `gh-ost` prefers the former)
- a real migration on a replica (master untouched)
- a test migration on a replica, the way for you to build trust with `gh-ost`&#039;s operation.

Our tips:

- [Testing above all](doc/testing-on-replica.md), try out `--test-on-replica` first few times. Better yet, make it continuous. We have multiple replicas where we iterate our entire fleet of production tables, migrating them one by one, checksumming the results, verifying migration is good.
- For each master migration, first issue a _noop_
- Then issue the real thing via `--execute`.

More tips:

- Use `--exact-rowcount` for accurate progress indication
- Use `--postpone-cut-over-flag-file` to gain control over cut-over timing
- Get familiar with the [interactive commands](doc/interactive-commands.md)

Also see:

- [requirements and limitations](doc/requirements-and-limitations.md)
- [common questions](doc/questions.md)
- [what if?](doc/what-if.md)
- [the fine print](doc/the-fine-print.md)
- [Community questions](https://github.com/github/gh-ost/issues?q=label%3Aquestion)
- [Using `gh-ost` on AWS RDS](doc/rds.md)
- [Using `gh-ost` on Azure Database for MySQL](doc/azure.md)

## What&#039;s in a name?

Originally this was named `gh-osc`: GitHub Online Schema Change, in the likes of [Facebook online schema change](https://www.facebook.com/notes/mysql-at-facebook/online-schema-change-for-mysql/430801045932/) and [pt-online-schema-change](https://www.percona.com/doc/percona-toolkit/2.2/pt-online-schema-change.html).

But then a rare genetic mutation happened, and the `c` transformed into `t`. And that sent us down the path of trying to figure out a new acronym. `gh-ost` (pronounce: _Ghost_), stands for GitHub&#039;s Online Schema Transmogrifier/Translator/Transformer/Transfigurator

## License

`gh-ost` is licensed under the [MIT license](https://github.com/github/gh-ost/blob/master/LICENSE)

`gh-ost` uses 3rd party libraries, each with their own license. These are found [here](https://github.com/github/gh-ost/tree/master/vendor).

## Community

`gh-ost` is released at a stable state, but with mileage to go. We are [open to pull requests](https://github.com/github/gh-ost/blob/master/.github/CONTRIBUTING.md). Please first discuss your intentions via [Issues](https://github.com/github/gh-ost/issues).

We develop `gh-ost` at GitHub and for the community. We may have different priorities than others. From time to time we may suggest a contribution that is not on our immediate roadmap but which may appeal to others.

Please see [Coding gh-ost](doc/coding-ghost.md) for a guide to getting started developing with gh-ost.

## Download/binaries/source

`gh-ost` is now GA and stable.

`gh-ost` is available in binary format for Linux and Mac OS/X

[Download latest release here](https://github.com/github/gh-ost/releases/latest)

`gh-ost` is a Go project; it is built with Go `1.15` and above. To build on your own, use either:
- [script/build](https://github.com/github/gh-ost/blob/master/script/build) - this is the same build script used by CI hence the authoritative; artifact is `./bin/gh-ost` binary.
- [build.sh](https://github.com/github/gh-ost/blob/master/build.sh) for building `tar.gz` artifacts in `/tmp/gh-ost-release`

Generally speaking, `master` branch is stable, but only [releases](https://github.com/github/gh-ost/releases) are to be used in production.

## Authors

`gh-ost` is designed, authored, reviewed and tested by the database infrastructure team at GitHub:
- [@jonahberquist](https://github.com/jonahberquist)
- [@ggunson](https://github.com/ggunson)
- [@tomkrouper](https://github.com/tomkrouper)
- [@shlomi-noach](https://github.com/shlomi-noach)
- [@jessbreckenridge](https://github.com/jessbreckenridge)
- [@gtowey](https://github.com/gtowey)
- [@timvaillancourt](https://github.com/timvaillancourt)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ory/hydra]]></title>
            <link>https://github.com/ory/hydra</link>
            <guid>https://github.com/ory/hydra</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:48 GMT</pubDate>
            <description><![CDATA[Internet-scale OpenID Certified‚Ñ¢ OpenID Connect and OAuth2.1 provider that integrates with your user management through headless APIs. Solve OIDC/OAuth2 user cases over night. Consume as a service on Ory Network or self-host. Trusted by OpenAI and many others for scale and security. Written in Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ory/hydra">ory/hydra</a></h1>
            <p>Internet-scale OpenID Certified‚Ñ¢ OpenID Connect and OAuth2.1 provider that integrates with your user management through headless APIs. Solve OIDC/OAuth2 user cases over night. Consume as a service on Ory Network or self-host. Trusted by OpenAI and many others for scale and security. Written in Go.</p>
            <p>Language: Go</p>
            <p>Stars: 16,849</p>
            <p>Forks: 1,605</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/banners/hydra.svg&quot; alt=&quot;Ory Hydra - Open Source OAuth 2 and OpenID Connect server&quot;&gt;
&lt;/h1&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.ory.sh/chat&quot;&gt;Chat&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://github.com/ory/hydra/discussions&quot;&gt;Discussions&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://www.ory.sh/l/sign-up-newsletter&quot;&gt;Newsletter&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://www.ory.sh/docs/&quot;&gt;Docs&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://console.ory.sh/&quot;&gt;Try Ory Network&lt;/a&gt; ¬∑
  &lt;a href=&quot;https://www.ory.sh/jobs/&quot;&gt;Jobs&lt;/a&gt;
&lt;/h4&gt;

Ory Hydra is a hardened, OpenID Certified OAuth 2.0 Server and OpenID Connect
Provider optimized for low-latency, high throughput, and low resource
consumption. It connects to your existing identity provider through a login and
consent app, giving you absolute control over the user interface and experience.

---

&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt;
&lt;!-- DON&#039;T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt;

- [What is Ory Hydra?](#what-is-ory-hydra)
  - [Why Ory Hydra](#why-ory-hydra)
  - [OAuth2 and OpenID Connect: Open Standards](#oauth2-and-openid-connect-open-standards)
  - [OpenID Connect Certified](#openid-connect-certified)
- [Deployment options](#deployment-options)
  - [Use Ory Hydra on the Ory Network](#use-ory-hydra-on-the-ory-network)
  - [Self-host Ory Hydra](#self-host-ory-hydra)
- [Quickstart](#quickstart)
- [Who is using Ory Hydra](#who-is-using-ory-hydra)
- [Ecosystem](#ecosystem)
  - [Ory Kratos: Identity and User Infrastructure and Management](#ory-kratos-identity-and-user-infrastructure-and-management)
  - [Ory Hydra: OAuth2 &amp; OpenID Connect Server](#ory-hydra-oauth2--openid-connect-server)
  - [Ory Oathkeeper: Identity &amp; Access Proxy](#ory-oathkeeper-identity--access-proxy)
  - [Ory Keto: Access Control Policies as a Server](#ory-keto-access-control-policies-as-a-server)
- [Documentation](#documentation)
- [Developing Ory Hydra](#developing-ory-hydra)
- [Security](#security)
  - [Disclosing vulnerabilities](#disclosing-vulnerabilities)
- [Telemetry](#telemetry)
- [Libraries and third-party projects](#libraries-and-third-party-projects)

&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt;

## What is Ory Hydra?

Ory Hydra is a server implementation of the OAuth 2.0 authorization framework
and the OpenID Connect Core 1.0. It follows
[cloud architecture best practices](https://www.ory.sh/docs/ecosystem/software-architecture-philosophy)
and focuses on:

- OAuth 2.0 and OpenID Connect flows
- Token issuance and validation
- Client management
- Consent and login flow orchestration
- JWKS management
- Low latency and high throughput

We recommend starting with the
[Ory Hydra introduction docs](https://www.ory.sh/docs/hydra) to learn more about
its architecture, feature set, and how it compares to other systems.

### Why Ory Hydra

Ory Hydra is designed to:

- Be a standalone OAuth 2.0 and OpenID Connect server without user management
- Connect to any existing identity provider through a login and consent app
- Give you absolute control over the user interface and experience flows
- Work with any authentication endpoint:
  [Ory Kratos](https://github.com/ory/kratos),
  [authboss](https://github.com/go-authboss/authboss),
  [User Frosting](https://www.userfrosting.com/), or your proprietary system
- Scale to large numbers of clients and tokens
- Fit into modern cloud native environments such as Kubernetes and managed
  platforms

### OAuth2 and OpenID Connect: Open Standards

Ory Hydra implements Open Standards set by the IETF:

- [The OAuth 2.0 Authorization Framework](https://tools.ietf.org/html/rfc6749)
- [OAuth 2.0 Threat Model and Security Considerations](https://tools.ietf.org/html/rfc6819)
- [OAuth 2.0 Token Revocation](https://tools.ietf.org/html/rfc7009)
- [OAuth 2.0 Token Introspection](https://tools.ietf.org/html/rfc7662)
- [OAuth 2.0 for Native Apps](https://tools.ietf.org/html/draft-ietf-oauth-native-apps-10)
- [OAuth 2.0 Dynamic Client Registration Protocol](https://datatracker.ietf.org/doc/html/rfc7591)
- [OAuth 2.0 Dynamic Client Registration Management Protocol](https://datatracker.ietf.org/doc/html/rfc7592)
- [Proof Key for Code Exchange by OAuth Public Clients](https://tools.ietf.org/html/rfc7636)
- [JSON Web Token (JWT) Profile for OAuth 2.0 Client Authentication and Authorization Grants](https://tools.ietf.org/html/rfc7523)

and the OpenID Foundation:

- [OpenID Connect Core 1.0](http://openid.net/specs/openid-connect-core-1_0.html)
- [OpenID Connect Discovery 1.0](https://openid.net/specs/openid-connect-discovery-1_0.html)
- [OpenID Connect Dynamic Client Registration 1.0](https://openid.net/specs/openid-connect-registration-1_0.html)
- [OpenID Connect Front-Channel Logout 1.0](https://openid.net/specs/openid-connect-frontchannel-1_0.html)
- [OpenID Connect Back-Channel Logout 1.0](https://openid.net/specs/openid-connect-backchannel-1_0.html)

### OpenID Connect Certified

Ory Hydra is an OpenID Foundation
[certified OpenID Provider (OP)](http://openid.net/certification/#OPs).

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/ory/docs/blob/master/docs/hydra/images/oidc-cert.png&quot; alt=&quot;Ory Hydra is a certified OpenID Providier&quot; width=&quot;256px&quot;&gt;
&lt;/p&gt;

The following OpenID profiles are certified:

- [Basic OpenID Provider](http://openid.net/specs/openid-connect-core-1_0.html#CodeFlowAuth)
  (response types `code`)
- [Implicit OpenID Provider](http://openid.net/specs/openid-connect-core-1_0.html#ImplicitFlowAuth)
  (response types `id_token`, `id_token+token`)
- [Hybrid OpenID Provider](http://openid.net/specs/openid-connect-core-1_0.html#HybridFlowAuth)
  (response types `code+id_token`, `code+id_token+token`, `code+token`)
- [OpenID Provider Publishing Configuration Information](https://openid.net/specs/openid-connect-discovery-1_0.html)
- [Dynamic OpenID Provider](https://openid.net/specs/openid-connect-registration-1_0.html)

To obtain certification, we deployed the
[reference user login and consent app](https://github.com/ory/hydra-login-consent-node)
(unmodified) and Ory Hydra v1.0.0.

## Deployment options

You can run Ory Hydra in two main ways:

- As a managed service on the Ory Network
- As a self hosted service under your own control, with or without the Ory
  Enterprise License

### Use Ory Hydra on the Ory Network

The [Ory Network](https://www.ory.sh/cloud) is the fastest way to use Ory
services in production. **Ory OAuth2 &amp; OpenID Connect** is powered by the open
source Ory Hydra server and is API compatible.

The Ory Network provides:

- OAuth2 and OpenID Connect for single sign on, API access, and machine to
  machine authorization
- Identity and credential management that scales to billions of users and
  devices
- Registration, login, and account management flows for passkeys, biometrics,
  social login, SSO, and multi factor authentication
- Prebuilt login, registration, and account management pages and components
- Low latency permission checks based on the Zanzibar model with the Ory
  Permission Language
- GDPR friendly storage with data locality and compliance in mind
- Web based Ory Console and Ory CLI for administration and operations
- Cloud native APIs compatible with the open source servers
- Fair, usage based [pricing](https://www.ory.sh/pricing)

Sign up for a
[free developer account](https://console.ory.sh/registration?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=hydra-readme)
to get started.

### Self-host Ory Hydra

You can run Ory Hydra yourself for full control over infrastructure, deployment,
and customization.

The [install guide](https://www.ory.sh/docs/hydra/install) explains how to:

- Install Hydra on Linux, macOS, Windows, and Docker
- Configure databases such as PostgreSQL, MySQL, and CockroachDB
- Deploy to Kubernetes and other orchestration systems
- Build Hydra from source

This guide uses the open source distribution to get you started without license
requirements. It is a great fit for individuals, researchers, hackers, and
companies that want to experiment, prototype, or run unimportant workloads
without SLAs. You get the full core engine, and you are free to inspect, extend,
and build it from source.

If you run Hydra as part of a business-critical system, for example OAuth2 and
OpenID Connect for all your users, you should use a commercial agreement to
reduce operational and security risk. The **Ory Enterprise License (OEL)**
layers on top of self-hosted Hydra and provides:

- Additional enterprise features that are not available in the open source
  version
- Regular security releases, including CVE patches, with service level
  agreements
- Support for advanced scaling, multi-tenancy, and complex deployments
- Premium support options with SLAs, direct access to engineers, and onboarding
  help
- Access to a private Docker registry with frequent and vetted, up-to-date
  enterprise builds

For guaranteed CVE fixes, current enterprise builds, advanced features, and
support in production, you need a valid
[Ory Enterprise License](https://www.ory.com/ory-enterprise-license) and access
to the Ory Enterprise Docker registry. To learn more,
[contact the Ory team](https://www.ory.sh/contact/).

## Quickstart

Install the [Ory CLI](https://www.ory.sh/docs/guides/cli/installation) and
create a new project to try Ory OAuth2 &amp; OpenID Connect.

```bash
# Install the Ory CLI if you do not have it yet:
bash &lt;(curl https://raw.githubusercontent.com/ory/meta/master/install.sh) -b . ory
sudo mv ./ory /usr/local/bin/

# Sign in or sign up
ory auth

# Create a new project
ory create project --create-workspace &quot;Ory Open Source&quot; --name &quot;GitHub Quickstart&quot; --use-project
```

Try out the OAuth 2.0 Client Credentials flow:

```bash
ory create oauth2-client \
    --name &quot;Client Credentials Demo&quot; \
    --grant-type client_credentials
# Note the client ID and secret from output

ory perform client-credentials \
    --client-id &lt;your-client-id&gt; \
    --client-secret &lt;your-client-secret&gt;
# Note the access token from output

ory introspect token &lt;your-access-token&gt;
```

Try out the OAuth 2.0 Authorize Code + OpenID Connect flow:

```bash
ory create oauth2-client \
    --name &quot;Authorize Code with OpenID Connect Demo&quot; \
    --grant-type authorization_code,refresh_token \
    --response-type code \
    --redirect-uri http://127.0.0.1:4446/callback

ory perform authorization-code \
    --client-id &lt;your-client-id&gt; \
    --client-secret &lt;your-client-secret&gt;
```

## Who is using Ory Hydra

&lt;!--BEGIN ADOPTERS--&gt;

The Ory community stands on the shoulders of individuals, companies, and
maintainers. The Ory team thanks everyone involved - from submitting bug reports
and feature requests, to contributing patches and documentation. The Ory
community counts more than 50.000 members and is growing. The Ory stack protects
7.000.000.000+ API requests every day across thousands of companies. None of
this would have been possible without each and everyone of you!

The following list represents companies that have accompanied us along the way
and that have made outstanding contributions to our ecosystem. _If you think
that your company deserves a spot here, reach out to
&lt;a href=&quot;mailto:office@ory.sh&quot;&gt;office@ory.sh&lt;/a&gt; now_!

&lt;table&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;Name&lt;/th&gt;
            &lt;th&gt;Logo&lt;/th&gt;
            &lt;th&gt;Website&lt;/th&gt;
            &lt;th&gt;Case Study&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;OpenAI&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/openai.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/openai.svg&quot; alt=&quot;OpenAI&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://openai.com/&quot;&gt;openai.com&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/openai&quot;&gt;OpenAI Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Fandom&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/fandom.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/fandom.svg&quot; alt=&quot;Fandom&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.fandom.com/&quot;&gt;fandom.com&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/fandom&quot;&gt;Fandom Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Lumin&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/lumin.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/lumin.svg&quot; alt=&quot;Lumin&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.luminpdf.com/&quot;&gt;luminpdf.com&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/lumin&quot;&gt;Lumin Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Sencrop&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/sencrop.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/sencrop.svg&quot; alt=&quot;Sencrop&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://sencrop.com/&quot;&gt;sencrop.com&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/sencrop&quot;&gt;Sencrop Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;OSINT Industries&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/osint.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/osint.svg&quot; alt=&quot;OSINT Industries&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.osint.industries/&quot;&gt;osint.industries&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/osint&quot;&gt;OSINT Industries Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;HGV&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/hgv.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/hgv.svg&quot; alt=&quot;HGV&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.hgv.it/&quot;&gt;hgv.it&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/hgv&quot;&gt;HGV Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Maxroll&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/maxroll.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/maxroll.svg&quot; alt=&quot;Maxroll&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://maxroll.gg/&quot;&gt;maxroll.gg&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/maxroll&quot;&gt;Maxroll Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Zezam&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/zezam.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/zezam.svg&quot; alt=&quot;Zezam&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.zezam.io/&quot;&gt;zezam.io&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/zezam&quot;&gt;Zezam Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;T.RowePrice&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/troweprice.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/troweprice.svg&quot; alt=&quot;T.RowePrice&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.troweprice.com/&quot;&gt;troweprice.com&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Mistral&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/mistral.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/mistral.svg&quot; alt=&quot;Mistral&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.mistral.ai/&quot;&gt;mistral.ai&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Axel Springer&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/axelspringer.svg&quot; /&gt;
                    &lt;img height=&quot;22px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/axelspringer.svg&quot; alt=&quot;Axel Springer&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.axelspringer.com/&quot;&gt;axelspringer.com&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Hemnet&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/hemnet.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/hemnet.svg&quot; alt=&quot;Hemnet&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.hemnet.se/&quot;&gt;hemnet.se&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Cisco&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/cisco.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/cisco.svg&quot; alt=&quot;Cisco&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.cisco.com/&quot;&gt;cisco.com&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Presidencia de la Rep√∫blica Dominicana&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/republica-dominicana.svg&quot; /&gt;
                    &lt;img height=&quot;42px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/republica-dominicana.svg&quot; alt=&quot;Presidencia de la Rep√∫blica Dominicana&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.presidencia.gob.do/&quot;&gt;presidencia.gob.do&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Moonpig&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/o

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[edoardottt/cariddi]]></title>
            <link>https://github.com/edoardottt/cariddi</link>
            <guid>https://github.com/edoardottt/cariddi</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:47 GMT</pubDate>
            <description><![CDATA[Take a list of domains, crawl urls and scan for endpoints, secrets, api keys, file extensions, tokens and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/edoardottt/cariddi">edoardottt/cariddi</a></h1>
            <p>Take a list of domains, crawl urls and scan for endpoints, secrets, api keys, file extensions, tokens and more</p>
            <p>Language: Go</p>
            <p>Stars: 3,215</p>
            <p>Forks: 284</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/edoardottt/images/blob/main/cariddi/logo.png&quot;&gt;&lt;br&gt;
  &lt;b&gt;Take a list of domains, crawl urls and scan for endpoints, secrets, api keys, file extensions, tokens and more&lt;/b&gt;&lt;br&gt;
  &lt;br&gt;
  &lt;!-- go-report-card --&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/edoardottt/cariddi&quot;&gt;
    &lt;img src=&quot;https://goreportcard.com/badge/github.com/edoardottt/cariddi&quot; alt=&quot;go-report-card&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- workflows --&gt;
  &lt;a href=&quot;https://github.com/edoardottt/cariddi/actions&quot;&gt;
    &lt;img src=&quot;https://github.com/edoardottt/cariddi/actions/workflows/go.yml/badge.svg?branch=main&quot; alt=&quot;workflows&quot; /&gt;
  &lt;/a&gt;
  &lt;br&gt;
  &lt;sub&gt;
    Coded with üíô by edoardottt
  &lt;/sub&gt;
  &lt;br&gt;
  &lt;!--Tweet button--&gt;
  &lt;a href=&quot;https://twitter.com/intent/tweet?url=https://github.com/edoardottt/cariddi&amp;text=Take%20a%20list%20of%20domains,%20crawl%20urls%20and%20scan%20for%20endpoints,%20secrets,%20api%20keys,%20file%20extensions,%20tokens%20and%20more...%20%23network%20%23security%20%23infosec%20%23oss%20%23github%20%23bugbounty%20%23linux&quot; target=&quot;_blank&quot;&gt;Share on Twitter!
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#installation-&quot;&gt;Install&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#usage-&quot;&gt;Usage&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#get-started-&quot;&gt;Get Started&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#changelog-&quot;&gt;Changelog&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#contributing-&quot;&gt;Contributing&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#license-&quot;&gt;License&lt;/a&gt;
&lt;/p&gt;

&lt;!--[![asciicast](https://asciinema.org/a/415989.svg)](https://asciinema.org/a/415989)--&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/edoardottt/images/blob/main/cariddi/cariddi.gif&quot;&gt;
&lt;/p&gt;

Installation üì°
----------

#### Homebrew

```console
brew install cariddi
```

#### Snap

```console
sudo snap install cariddi
```

#### Golang

```console
go install -v github.com/edoardottt/cariddi/cmd/cariddi@latest
```

#### Pacman

```console
pacman -Syu cariddi
```

#### NixOS

```console
nix-shell -p cariddi
```

#### Building from source

You need [Go](https://go.dev/) (&gt;=1.24.0)

&lt;details&gt;
  &lt;summary&gt;Building from source for Linux and Windows&lt;/summary&gt;

#### Linux

```console
git clone https://github.com/edoardottt/cariddi.git
cd cariddi
go get ./...
make linux # (to install)
make unlinux # (to uninstall)
```

One-liner: `git clone https://github.com/edoardottt/cariddi.git &amp;&amp; cd cariddi &amp;&amp; go get ./... &amp;&amp; make linux`

#### Windows 

Note that the executable works only in cariddi folder.

```console
git clone https://github.com/edoardottt/cariddi.git
cd cariddi
go get ./...
.\make.bat windows # (to install)
.\make.bat unwindows # (to uninstall)
```

&lt;/details&gt;

Usage üí°
----------

If you want to scan only a single target you can use

```console
echo https://edoardottt.com/ | cariddi
```

With multiple targets you can use a file instead, e.g. urls.txt containing:

```console
https://edoardottt.com/
http://testphp.vulnweb.com/
```

For Windows:

- use `powershell.exe -Command &quot;cat urls.txt | .\cariddi.exe&quot;` inside the Command prompt
- or just `cat urls.txt | cariddi.exe` using PowerShell

### Basics

- `cariddi -version` (Print the version)
- `cariddi -h` (Print the help)
- `cariddi -examples` (Print the examples)

### Scan options

- `cat urls.txt | cariddi -intensive` (Crawl searching also subdomains, same as `*.target.com`)
- `cat urls.txt | cariddi -s` (Hunt for secrets)
- `cat urls.txt | cariddi -err` (Hunt for errors in websites)
- `cat urls.txt | cariddi -e` (Hunt for juicy endpoints)
- `cat urls.txt | cariddi -info` (Hunt for useful informations in websites)
- `cat urls.txt | cariddi -ext 2` (Hunt for juicy (level 2 out of 7) files)
- `cat urls.txt | cariddi -e -ef endpoints_file` (Hunt for custom endpoints)
- `cat urls.txt | cariddi -s -sf secrets_file` (Hunt for custom secrets)
- `cat urls.txt | cariddi -ie pdf,png,jpg` (Ignore these extensions while scanning)

Default: png, svg, jpg, jpeg, bmp, jfif, gif, webp, woff, woff2, ttf, tiff, tif are ignored while scanning for secrets, info and errors.

### Configuration

- `cat urls.txt | cariddi -proxy http://127.0.0.1:8080` (Set a Proxy, http and socks5 supported)
- `cat urls.txt | cariddi -d 2` (2 seconds between a page crawled and another)
- `cat urls.txt | cariddi -c 200` (Set the concurrency level to 200)
- `cat urls.txt | cariddi -i forum,blog,community,open` (Ignore urls containing these words)
- `cat urls.txt | cariddi -it ignore_file` (Ignore urls containing at least one line in the input file)
- `cat urls.txt | cariddi -cache` (Use the .cariddi_cache folder as cache)
- `cat urls.txt | cariddi -t 5` (Set the timeout for the requests)
- `cat urls.txt | cariddi -headers &quot;Cookie: auth=admin;type=2;; X-Custom: customHeader&quot;`
- `cat urls.txt | cariddi -headersfile headers.txt` (Read from an external file custom headers)
- `cat urls.txt | cariddi -ua &quot;Custom User Agent&quot;` (Use a custom User Agent)
- `cat urls.txt | cariddi -rua` (Use a random browser user agent on every request)

### Output

- `cat urls.txt | cariddi -plain` (Print only results)
- `cat urls.txt | cariddi -ot target_name` (Results in txt file)
- `cat urls.txt | cariddi -oh target_name` (Results in html file)
- `cat urls.txt | cariddi -json` (Print the output as JSON in stdout)
- `cat urls.txt | cariddi -sr` (Store HTTP responses)
- `cat urls.txt | cariddi -debug` (Print debug information while crawling)
- `cat urls.txt | cariddi -md 3` (Max 3 depth levels)

Get Started üéâ
----------

`cariddi -h` prints the help.

```console
Usage of cariddi:
  -c int
     Concurrency level. (default 20)
  -cache
     Use the .cariddi_cache folder as cache.
  -d int
     Delay between a page crawled and another.
  -debug
     Print debug information while crawling.
  -e Hunt for juicy endpoints.
  -ef string
     Use an external file (txt, one per line) to use custom parameters for endpoints hunting.
  -err
     Hunt for errors in websites.
  -examples
     Print the examples.
  -ext int
     Hunt for juicy file extensions. Integer from 1(juicy) to 7(not juicy).
  -h Print the help.
  -headers string
     Use custom headers for each request E.g. -headers &quot;Cookie: auth=yes;;Client: type=2&quot;.
  -headersfile string
     Read from an external file custom headers (same format of headers flag).
  -json
     Print the output as JSON in stdout.
  -md
     Maximum depth level the crawler will follow from the initial target URL.
  -i string
     Ignore the URL containing at least one of the elements of this array.
  -ie value
     Comma-separated list of extensions to ignore while scanning.
  -info
     Hunt for useful informations in websites.
  -intensive
     Crawl searching for resources matching 2nd level domain.
  -it string
     Ignore the URL containing at least one of the lines of this file.
  -oh string
     Write the output into an HTML file.
  -ot string
     Write the output into a TXT file.
  -plain
     Print only the results.
  -proxy string
     Set a Proxy to be used (http and socks5 supported).
  -rua
     Use a random browser user agent on every request.
  -s Hunt for secrets.
  -sf string
     Use an external file (txt, one per line) to use custom regexes for secrets hunting.
  -sr
     Store HTTP responses.
  -t int
     Set timeout for the requests. (default 10)
  -ua string
     Use a custom User Agent.
  -version
     Print the version.
```

&lt;details&gt;
  &lt;summary&gt;Click to understand &lt;strong&gt;How to integrate cariddi with Burpsuite&lt;/strong&gt;&lt;/summary&gt;

   Normally you use Burpsuite within your browser, so you just have to trust the burpsuite&#039;s certificate in the browser and you&#039;re done.  
   In order to use cariddi with the BurpSuite proxy you should do some steps further.  

   If you try to use cariddi with the option `-proxy http://127.0.0.1:8080` you will find this error in the burpsuite error log section:  

   ```bash
   Received fatal alert: bad_certificate (or something similar related to the certificate).
   ```

   To make cariddi working fine with Burpsuite you have also to trust the certificate within your entire pc, not just only the browser. These are the steps you have to follow:

   Go to Proxy tab in Bupsuite, then Options. Click on the CA Certificate button and export Certificate in DER format  

   ```bash
   openssl x509 -in burp.der -inform DER -out burp.pem -outform PEM
   sudo chown root:root burp.pem
   sudo chmod 644 burp.pem
   sudo cp burp.pem /usr/local/share/ca-certificates/
   sudo c_rehash
   cd /etc/ssl/certs/
   sudo ln -s /usr/local/share/ca-certificates/burp.pem
   sudo c_rehash .
   ```

   Source: Trust Burp Proxy certificate in Debian/Ubuntu  

   After these steps, in order to use cariddi with Burpsuite you have to:  

   1. Open Burpsuite, making sure that the proxy is listening.  
   2. Use cariddi with the flag `-proxy http://127.0.0.1:8080`.  
   3. You will see that requests and responses will be logged in Burpsuite.

&lt;/details&gt;

Changelog üìå
-------

Detailed changes for each release are documented in the [release notes](https://github.com/edoardottt/cariddi/releases).

Contributing üõ†
-------

Just open an [issue](https://github.com/edoardottt/cariddi/issues)/[pull request](https://github.com/edoardottt/cariddi/pulls).

Before opening a pull request, download [golangci-lint](https://golangci-lint.run/usage/install/) and run

```console
golangci-lint run
```

If there aren&#039;t errors, go ahead :)

Test using [https://edoardottt.github.io/cariddi-test/](https://edoardottt.github.io/cariddi-test/)

```console
echo &quot;https://edoardottt.github.io/cariddi-test/&quot; | cariddi
```

**Help me build this!**

Special thanks to: [go-colly](http://go-colly.org/), [ocervell](https://github.com/ocervell), [zricethezav](https://github.com/gitleaks/gitleaks/blob/master/config/gitleaks.toml), [projectdiscovery](https://github.com/projectdiscovery/nuclei-templates/tree/master/file/keys), [tomnomnom](https://github.com/tomnomnom/gf/tree/master/examples), [RegexPassive](https://github.com/hahwul/RegexPassive) and [all the contributors](https://github.com/edoardottt/cariddi/graphs/contributors).

License üìù
-------

This repository is under [GNU General Public License v3.0](https://github.com/edoardottt/cariddi/blob/main/LICENSE).  
[edoardottt.com](https://edoardottt.com/) to contact me.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grpc/grpc-go]]></title>
            <link>https://github.com/grpc/grpc-go</link>
            <guid>https://github.com/grpc/grpc-go</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:46 GMT</pubDate>
            <description><![CDATA[The Go language implementation of gRPC. HTTP/2 based RPC]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grpc/grpc-go">grpc/grpc-go</a></h1>
            <p>The Go language implementation of gRPC. HTTP/2 based RPC</p>
            <p>Language: Go</p>
            <p>Stars: 22,709</p>
            <p>Forks: 4,634</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># gRPC-Go

[![GoDoc](https://pkg.go.dev/badge/google.golang.org/grpc)][API]
[![GoReportCard](https://goreportcard.com/badge/grpc/grpc-go)](https://goreportcard.com/report/github.com/grpc/grpc-go)
[![codecov](https://codecov.io/gh/grpc/grpc-go/graph/badge.svg)](https://codecov.io/gh/grpc/grpc-go)

The [Go][] implementation of [gRPC][]: A high performance, open source, general
RPC framework that puts mobile and HTTP/2 first. For more information see the
[Go gRPC docs][], or jump directly into the [quick start][].

## Prerequisites

- **[Go][]**: any one of the **two latest major** [releases][go-releases].

## Installation

Simply add the following import to your code, and then `go [build|run|test]`
will automatically fetch the necessary dependencies:


```go
import &quot;google.golang.org/grpc&quot;
```

&gt; **Note:** If you are trying to access `grpc-go` from **China**, see the
&gt; [FAQ](#FAQ) below.

## Learn more

- [Go gRPC docs][], which include a [quick start][] and [API
  reference][API] among other resources
- [Low-level technical docs](Documentation) from this repository
- [Performance benchmark][]
- [Examples](examples)
- [Contribution guidelines](CONTRIBUTING.md)

## FAQ

### I/O Timeout Errors

The `golang.org` domain may be blocked from some countries. `go get` usually
produces an error like the following when this happens:

```console
$ go get -u google.golang.org/grpc
package google.golang.org/grpc: unrecognized import path &quot;google.golang.org/grpc&quot; (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)
```

To build Go code, there are several options:

- Set up a VPN and access google.golang.org through that.

- With Go module support: it is possible to use the `replace` feature of `go
  mod` to create aliases for golang.org packages.  In your project&#039;s directory:

  ```sh
  go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest
  go mod tidy
  go mod vendor
  go build -mod=vendor
  ```

  Again, this will need to be done for all transitive dependencies hosted on
  golang.org as well. For details, refer to [golang/go issue
  #28652](https://github.com/golang/go/issues/28652).

### Compiling error, undefined: grpc.SupportPackageIsVersion

Please update to the latest version of gRPC-Go using
`go get google.golang.org/grpc`.

### How to turn on logging

The default logger is controlled by environment variables. Turn everything on
like this:

```console
$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99
$ export GRPC_GO_LOG_SEVERITY_LEVEL=info
```

### The RPC failed with error `&quot;code = Unavailable desc = transport is closing&quot;`

This error means the connection the RPC is using was closed, and there are many
possible reasons, including:
 1. mis-configured transport credentials, connection failed on handshaking
 1. bytes disrupted, possibly by a proxy in between
 1. server shutdown
 1. Keepalive parameters caused connection shutdown, for example if you have
    configured your server to terminate connections regularly to [trigger DNS
    lookups](https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779).
    If this is the case, you may want to increase your
    [MaxConnectionAgeGrace](https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters),
    to allow longer RPC calls to finish.

It can be tricky to debug this because the error happens on the client side but
the root cause of the connection being closed is on the server side. Turn on
logging on __both client and server__, and see if there are any transport
errors.

[API]: https://pkg.go.dev/google.golang.org/grpc
[Go]: https://golang.org
[Go module]: https://github.com/golang/go/wiki/Modules
[gRPC]: https://grpc.io
[Go gRPC docs]: https://grpc.io/docs/languages/go
[Performance benchmark]: https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608
[quick start]: https://grpc.io/docs/languages/go/quickstart
[go-releases]: https://golang.org/doc/devel/release.html
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[uber-go/fx]]></title>
            <link>https://github.com/uber-go/fx</link>
            <guid>https://github.com/uber-go/fx</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:45 GMT</pubDate>
            <description><![CDATA[A dependency injection based application framework for Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/uber-go/fx">uber-go/fx</a></h1>
            <p>A dependency injection based application framework for Go.</p>
            <p>Language: Go</p>
            <p>Stars: 7,251</p>
            <p>Forks: 327</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre># :unicorn: Fx [![GoDoc](https://pkg.go.dev/badge/go.uber.org/fx)](https://pkg.go.dev/go.uber.org/fx) [![Github release](https://img.shields.io/github/release/uber-go/fx.svg)](https://github.com/uber-go/fx/releases) [![Build Status](https://github.com/uber-go/fx/actions/workflows/go.yml/badge.svg)](https://github.com/uber-go/fx/actions/workflows/go.yml) [![Coverage Status](https://codecov.io/gh/uber-go/fx/branch/master/graph/badge.svg)](https://codecov.io/gh/uber-go/fx/branch/master) [![Go Report Card](https://goreportcard.com/badge/go.uber.org/fx)](https://goreportcard.com/report/go.uber.org/fx)

Fx is a dependency injection system for Go.

**Benefits**

- Eliminate globals: Fx helps you remove global state from your application.
  No more `init()` or global variables. Use Fx-managed singletons.
- Code reuse: Fx lets teams within your organization build loosely-coupled
  and well-integrated shareable components.
- Battle tested: Fx is the backbone of nearly all Go services at Uber.

See our [docs](https://uber-go.github.io/fx/) to get started and/or
learn more about Fx.

## Installation

Use Go modules to install Fx in your application.

```shell
go get go.uber.org/fx@v1
```

## Getting started

To get started with Fx, [start here](https://uber-go.github.io/fx/get-started/).

## Stability

This library is `v1` and follows [SemVer](https://semver.org/) strictly.

No breaking changes will be made to exported APIs before `v2.0.0`.

This project follows the [Go Release Policy](https://golang.org/doc/devel/release.html#policy). Each major
version of Go is supported until there are two newer major releases.

## Stargazers over time

[![Stargazers over time](https://starchart.cc/uber-go/fx.svg)](https://starchart.cc/uber-go/fx)

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[usememos/memos]]></title>
            <link>https://github.com/usememos/memos</link>
            <guid>https://github.com/usememos/memos</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:44 GMT</pubDate>
            <description><![CDATA[An open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/usememos/memos">usememos/memos</a></h1>
            <p>An open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.</p>
            <p>Language: Go</p>
            <p>Stars: 54,114</p>
            <p>Forks: 3,885</p>
            <p>Stars today: 242 stars today</p>
            <h2>README</h2><pre># Memos

&lt;img align=&quot;right&quot; height=&quot;96px&quot; src=&quot;https://raw.githubusercontent.com/usememos/.github/refs/heads/main/assets/logo-rounded.png&quot; alt=&quot;Memos&quot; /&gt;

An open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.

[![Home](https://img.shields.io/badge/üè†-usememos.com-blue?style=flat-square)](https://usememos.com)
[![Live Demo](https://img.shields.io/badge/‚ú®-Try%20Demo-orange?style=flat-square)](https://demo.usememos.com/)
[![Docs](https://img.shields.io/badge/üìö-Documentation-green?style=flat-square)](https://usememos.com/docs)
[![Discord](https://img.shields.io/badge/üí¨-Discord-5865f2?style=flat-square&amp;logo=discord&amp;logoColor=white)](https://discord.gg/tfPJa4UmAv)
[![Docker Pulls](https://img.shields.io/docker/pulls/neosmemo/memos?style=flat-square&amp;logo=docker)](https://hub.docker.com/r/neosmemo/memos)

&lt;img src=&quot;https://raw.githubusercontent.com/usememos/.github/refs/heads/main/assets/demo.png&quot; alt=&quot;Memos Demo Screenshot&quot; height=&quot;512&quot; /&gt;

### üíé Featured Sponsors

[**Warp** ‚Äî The AI-powered terminal built for speed and collaboration](https://go.warp.dev/memos)

&lt;a href=&quot;https://go.warp.dev/memos&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/warpdotdev/brand-assets/main/Github/Sponsor/Warp-Github-LG-02.png&quot; alt=&quot;Warp - The AI-powered terminal built for speed and collaboration&quot; width=&quot;512&quot; /&gt;
&lt;/a&gt;

---

[**LambdaTest** - Cross-browser testing cloud](https://www.lambdatest.com/?utm_source=memos&amp;utm_medium=sponsor)
  
&lt;a href=&quot;https://www.lambdatest.com/?utm_source=memos&amp;utm_medium=sponsor&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  &lt;img src=&quot;https://www.lambdatest.com/blue-logo.png&quot; alt=&quot;LambdaTest - Cross-browser testing cloud&quot; height=&quot;50&quot; /&gt;
&lt;/a&gt;

## Overview

Memos is a privacy-first, self-hosted knowledge base that works seamlessly for personal notes, team wikis, and knowledge management. Built with Go and React, it offers lightning-fast performance without compromising on features or usability.

**Why choose Memos over cloud services?**

| Feature           | Memos                          | Cloud Services                |
| ----------------- | ------------------------------ | ----------------------------- |
| **Privacy**       | ‚úÖ Self-hosted, zero telemetry | ‚ùå Your data on their servers |
| **Cost**          | ‚úÖ Free forever, MIT license   | ‚ùå Subscription fees          |
| **Performance**   | ‚úÖ Instant load, no latency    | ‚ö†Ô∏è Depends on internet        |
| **Ownership**     | ‚úÖ Full control &amp; export       | ‚ùå Vendor lock-in             |
| **API Access**    | ‚úÖ Full REST + gRPC APIs       | ‚ö†Ô∏è Limited or paid            |
| **Customization** | ‚úÖ Open source, forkable       | ‚ùå Closed ecosystem           |

## Features

- **üîí Privacy-First Architecture**

  - Self-hosted on your infrastructure with zero telemetry
  - Complete data ownership and export capabilities
  - No tracking, no ads, no vendor lock-in

- **üìù Markdown Native**

  - Full markdown support
  - Plain text storage ‚Äî take your data anywhere

- **‚ö° Blazing Fast**

  - Built with Go backend and React frontend
  - Optimized for performance at any scale

- **üê≥ Simple Deployment**

  - One-line Docker installation
  - Supports SQLite, MySQL, and PostgreSQL

- **üîó Developer-Friendly**

  - Full REST and gRPC APIs
  - Easy integration with existing workflows

- **üé® Beautiful Interface**
  - Clean, minimal design and dark mode support
  - Mobile-responsive layout

## Quick Start

### Docker (Recommended)

```bash
docker run -d \
  --name memos \
  -p 5230:5230 \
  -v ~/.memos:/var/opt/memos \
  neosmemo/memos:stable
```

Open `http://localhost:5230` and start writing!

### Try the Live Demo

Don&#039;t want to install yet? Try our [live demo](https://demo.usememos.com/) first!

### Other Installation Methods

- **Docker Compose** - Recommended for production deployments
- **Pre-built Binaries** - Available for Linux, macOS, and Windows
- **Kubernetes** - Helm charts and manifests available
- **Build from Source** - For development and customization

See our [installation guide](https://usememos.com/docs/installation) for detailed instructions.

## Contributing

We welcome contributions of all kinds! Whether you&#039;re fixing bugs, adding features, improving documentation, or helping with translations ‚Äî every contribution matters.

**Ways to contribute:**

- üêõ [Report bugs](https://github.com/usememos/memos/issues/new?template=bug_report.md)
- üí° [Suggest features](https://github.com/usememos/memos/issues/new?template=feature_request.md)
- üîß [Submit pull requests](https://github.com/usememos/memos/pulls)
- üìñ [Improve documentation](https://github.com/usememos/memos/tree/main/docs)
- üåç [Help with translations](https://github.com/usememos/memos/tree/main/web/src/locales)

## Sponsors

Love Memos? [Sponsor us on GitHub](https://github.com/sponsors/usememos) to help keep the project growing!

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=usememos/memos&amp;type=Date)](https://star-history.com/#usememos/memos&amp;Date)

## License

Memos is open-source software licensed under the [MIT License](LICENSE).

## Privacy Policy

Memos is built with privacy as a core principle. As a self-hosted application, all your data stays on your infrastructure. There is no telemetry, no tracking, and no data collection. See our [Privacy Policy](https://usememos.com/privacy) for details.

---

**[Website](https://usememos.com)** ‚Ä¢ **[Documentation](https://usememos.com/docs)** ‚Ä¢ **[Demo](https://demo.usememos.com/)** ‚Ä¢ **[Discord](https://discord.gg/tfPJa4UmAv)** ‚Ä¢ **[X/Twitter](https://x.com/usememos)**

&lt;a href=&quot;https://vercel.com/oss&quot;&gt;
  &lt;img alt=&quot;Vercel OSS Program&quot; src=&quot;https://vercel.com/oss/program-badge.svg&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[labstack/echo]]></title>
            <link>https://github.com/labstack/echo</link>
            <guid>https://github.com/labstack/echo</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:43 GMT</pubDate>
            <description><![CDATA[High performance, minimalist Go web framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/labstack/echo">labstack/echo</a></h1>
            <p>High performance, minimalist Go web framework</p>
            <p>Language: Go</p>
            <p>Stars: 32,037</p>
            <p>Forks: 2,309</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>[![Sourcegraph](https://sourcegraph.com/github.com/labstack/echo/-/badge.svg?style=flat-square)](https://sourcegraph.com/github.com/labstack/echo?badge)
[![GoDoc](http://img.shields.io/badge/go-documentation-blue.svg?style=flat-square)](https://pkg.go.dev/github.com/labstack/echo/v4)
[![Go Report Card](https://goreportcard.com/badge/github.com/labstack/echo?style=flat-square)](https://goreportcard.com/report/github.com/labstack/echo)
[![GitHub Workflow Status (with event)](https://img.shields.io/github/actions/workflow/status/labstack/echo/echo.yml?style=flat-square)](https://github.com/labstack/echo/actions)
[![Codecov](https://img.shields.io/codecov/c/github/labstack/echo.svg?style=flat-square)](https://codecov.io/gh/labstack/echo)
[![Forum](https://img.shields.io/badge/community-forum-00afd1.svg?style=flat-square)](https://github.com/labstack/echo/discussions)
[![Twitter](https://img.shields.io/badge/twitter-@labstack-55acee.svg?style=flat-square)](https://twitter.com/labstack)
[![License](http://img.shields.io/badge/license-mit-blue.svg?style=flat-square)](https://raw.githubusercontent.com/labstack/echo/master/LICENSE)

## Echo

High performance, extensible, minimalist Go web framework.

* [Official website](https://echo.labstack.com)
* [Quick start](https://echo.labstack.com/docs/quick-start)
* [Middlewares](https://echo.labstack.com/docs/category/middleware)

Help and questions: [Github Discussions](https://github.com/labstack/echo/discussions)


### Feature Overview

- Optimized HTTP router which smartly prioritize routes
- Build robust and scalable RESTful APIs
- Group APIs
- Extensible middleware framework
- Define middleware at root, group or route level
- Data binding for JSON, XML and form payload
- Handy functions to send variety of HTTP responses
- Centralized HTTP error handling
- Template rendering with any template engine
- Define your format for the logger
- Highly customizable
- Automatic TLS via Let‚Äôs Encrypt
- HTTP/2 support

## Sponsors

&lt;div&gt;
  &lt;a href=&quot;https://encore.dev&quot; style=&quot;display: inline-flex; align-items: center; gap: 10px&quot;&gt;
    &lt;img src=&quot;https://user-images.githubusercontent.com/78424526/214602214-52e0483a-b5fc-4d4c-b03e-0b7b23e012df.svg&quot; height=&quot;28px&quot; alt=&quot;encore icon&quot;&gt;&lt;/img&gt;
  &lt;b&gt;Encore ‚Äì the platform for building Go-based cloud backends&lt;/b&gt;
    &lt;/a&gt;
&lt;/div&gt;
&lt;br/&gt;

Click [here](https://github.com/sponsors/labstack) for more information on sponsorship.

## [Guide](https://echo.labstack.com/guide)

### Installation

```sh
// go get github.com/labstack/echo/{version}
go get github.com/labstack/echo/v4
```
Latest version of Echo supports last four Go major [releases](https://go.dev/doc/devel/release) and might work with older versions.

### Example

```go
package main

import (
  &quot;github.com/labstack/echo/v4&quot;
  &quot;github.com/labstack/echo/v4/middleware&quot;
  &quot;log/slog&quot;
  &quot;net/http&quot;
)

func main() {
  // Echo instance
  e := echo.New()

  // Middleware
  e.Use(middleware.RequestLogger()) // use the default RequestLogger middleware with slog logger
  e.Use(middleware.Recover()) // recover panics as errors for proper error handling

  // Routes
  e.GET(&quot;/&quot;, hello)

  // Start server
  if err := e.Start(&quot;:8080&quot;); err != nil &amp;&amp; !errors.Is(err, http.ErrServerClosed) {
    slog.Error(&quot;failed to start server&quot;, &quot;error&quot;, err)
  }
}

// Handler
func hello(c echo.Context) error {
  return c.String(http.StatusOK, &quot;Hello, World!&quot;)
}
```

# Official middleware repositories

Following list of middleware is maintained by Echo team.

| Repository                                                                   | Description                                                                                                                                                                                                                                                                                                                   |
|------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [github.com/labstack/echo-jwt](https://github.com/labstack/echo-jwt)         | [JWT](https://github.com/golang-jwt/jwt) middleware                                                                                                                                                                                                                                                                           | 
| [github.com/labstack/echo-contrib](https://github.com/labstack/echo-contrib) | [casbin](https://github.com/casbin/casbin), [gorilla/sessions](https://github.com/gorilla/sessions), [jaegertracing](https://github.com/uber/jaeger-client-go), [prometheus](https://github.com/prometheus/client_golang/), [pprof](https://pkg.go.dev/net/http/pprof), [zipkin](https://github.com/openzipkin/zipkin-go) middlewares | 

# Third-party middleware repositories

Be careful when adding 3rd party middleware. Echo teams does not have time or manpower to guarantee safety and quality
of middlewares in this list.

| Repository                                                                                           | Description                                                                                                                                                                                              |
|------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [deepmap/oapi-codegen](https://github.com/deepmap/oapi-codegen)                                      | Automatically generate RESTful API documentation with [OpenAPI](https://swagger.io/specification/) Client and Server Code Generator                                                                      |
| [github.com/swaggo/echo-swagger](https://github.com/swaggo/echo-swagger)                             | Automatically generate RESTful API documentation with [Swagger](https://swagger.io/) 2.0.                                                                                                                |
| [github.com/ziflex/lecho](https://github.com/ziflex/lecho)                                           | [Zerolog](https://github.com/rs/zerolog) logging library wrapper for Echo logger interface.                                                                                                              |
| [github.com/brpaz/echozap](https://github.com/brpaz/echozap)                                         | Uber¬¥s [Zap](https://github.com/uber-go/zap) logging library wrapper for Echo logger interface.                                                                                                          |
| [github.com/samber/slog-echo](https://github.com/samber/slog-echo)                                         | Go [slog](https://pkg.go.dev/golang.org/x/exp/slog) logging library wrapper for Echo logger interface.                                                                                                          |
| [github.com/darkweak/souin/plugins/echo](https://github.com/darkweak/souin/tree/master/plugins/echo) | HTTP cache system based on [Souin](https://github.com/darkweak/souin) to automatically get your endpoints cached. It supports some distributed and non-distributed storage systems depending your needs. |
| [github.com/mikestefanello/pagoda](https://github.com/mikestefanello/pagoda)                         | Rapid, easy full-stack web development starter kit built with Echo.                                                                                                                                      |
| [github.com/go-woo/protoc-gen-echo](https://github.com/go-woo/protoc-gen-echo)                       | ProtoBuf generate Echo server side code                                                                                                                                                                  |

Please send a PR to add your own library here.

## Contribute

**Use issues for everything**

- For a small change, just send a PR.
- For bigger changes open an issue for discussion before sending a PR.
- PR should have:
  - Test case
  - Documentation
  - Example (If it makes sense)
- You can also contribute by:
  - Reporting issues
  - Suggesting new features or enhancements
  - Improve/fix documentation

## Credits

- [Vishal Rana](https://github.com/vishr) (Author)
- [Nitin Rana](https://github.com/nr17) (Consultant)
- [Roland Lammel](https://github.com/lammel) (Maintainer)
- [Martti T.](https://github.com/aldas) (Maintainer)
- [Pablo Andres Fuente](https://github.com/pafuent) (Maintainer)
- [Contributors](https://github.com/labstack/echo/graphs/contributors)

## License

[MIT](https://github.com/labstack/echo/blob/master/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[vllm-project/semantic-router]]></title>
            <link>https://github.com/vllm-project/semantic-router</link>
            <guid>https://github.com/vllm-project/semantic-router</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:42 GMT</pubDate>
            <description><![CDATA[System Level Intelligent Router for Mixture-of-Models at Cloud, Data Center and Edge]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vllm-project/semantic-router">vllm-project/semantic-router</a></h1>
            <p>System Level Intelligent Router for Mixture-of-Models at Cloud, Data Center and Edge</p>
            <p>Language: Go</p>
            <p>Stars: 2,811</p>
            <p>Forks: 432</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;website/static/img/code.png&quot; alt=&quot;vLLM Semantic Router&quot; width=&quot;100%&quot;/&gt;

[![Documentation](https://img.shields.io/badge/docs-read%20the%20docs-blue)](https://vllm-semantic-router.com)
[![Hugging Face](https://img.shields.io/badge/ü§ó%20Hugging%20Face-Community-yellow)](https://huggingface.co/LLM-Semantic-Router)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![Crates.io](https://img.shields.io/crates/v/candle-semantic-router.svg)](https://crates.io/crates/candle-semantic-router)
![Test And Build](https://github.com/vllm-project/semantic-router/workflows/Test%20And%20Build/badge.svg)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/vllm-project/semantic-router)

**üìö [Complete Documentation](https://vllm-semantic-router.com) | üöÄ [Quick Start](https://vllm-semantic-router.com/docs/installation) | üì£ [Blog](https://vllm-semantic-router.com/blog/) | üìñ [Publications](https://vllm-semantic-router.com/publications/)**

&lt;/div&gt;

---

*Latest News* üî•

- [2026/01/05] Iris v0.1 is Released: [vLLM Semantic Router v0.1 Iris: The First Major Release](https://blog.vllm.ai/2026/01/05/vllm-sr-iris.html)
- [2025/12/16] Collaboration: [AMD √ó vLLM Semantic Router: Building the System Intelligence Together](https://blog.vllm.ai/2025/12/16/vllm-sr-amd.html)
- [2025/12/15] New Blog: [Token-Level Truth: Real-Time Hallucination Detection for Production LLMs](https://blog.vllm.ai/2025/12/14/halugate.html)
- [2025/11/19] New Blog: [Signal-Decision Driven Architecture: Reshaping Semantic Routing at Scale](https://blog.vllm.ai/2025/11/19/signal-decision.html)
- [2025/11/03] Our paper [Category-Aware Semantic Caching for Heterogeneous LLM Workloads](https://arxiv.org/abs/2510.26835) published
- [2025/10/27] New Blog: [Scaling Semantic Routing with Extensible LoRA](https://blog.vllm.ai/2025/10/27/semantic-router-modular.html)
- [2025/10/12] Our paper [When to Reason: Semantic Router for vLLM](https://arxiv.org/abs/2510.08731) accepted by NeurIPS 2025 MLForSys.
- [2025/10/08] Collaboration: vLLM Semantic Router with [vLLM Production Stack](https://github.com/vllm-project/production-stack) Team.
- [2025/09/01] Released the project: [vLLM Semantic Router: Next Phase in LLM inference](https://blog.vllm.ai/2025/09/11/semantic-router.html).

---

## Goals

We are building the **System Level Intelligence** for Mixture-of-Models (MoM), bringing the **Collective Intelligence** into **LLM systems**, answering the following questions:

1. How to capture the missing signals in request, response and context?
2. How to combine the signals to make better decisions?
3. How to collaborate more efficiently between different models?
4. How to secure the real world and LLM system from jailbreaks, pii leaks, hallucinations?
5. How to collect the valuable signals and build a self-learning system?

![vLLM Semantic Router Banner](./website/static/img/banner.png)

### Where it lives

It lives between the real world and models:

![level](./website/static/img/level.png)

### Architecture

A quick overview of the current architecture:

![architecture](./website/static/img/architecture.png)

## Quick Start

### Installation

&gt; [!TIP]
&gt; We recommend that you setup a Python virtual environment to manage dependencies.

```bash
$ python -m venv vsr
$ source vsr/bin/activate
$ pip install vllm-sr
```

Installed successfully if you see the following help message:

```bash
$ vllm-sr

       _ _     __  __       ____  ____
__   _| | |_ _|  \/  |     / ___||  _ \
\ \ / / | | | | |\/| |_____\___ \| |_) |
 \ V /| | | |_| | |  |_____|___) |  _ &lt;
  \_/ |_|_|\__,_|_|  |     |____/|_| \_\

vLLM Semantic Router - Intelligent routing for vLLM

Usage: vllm-sr [OPTIONS] COMMAND [ARGS]...

  vLLM Semantic Router CLI - Intelligent routing and caching for vLLM
  endpoints.

Options:
  --version  Show version and exit.
  --help     Show this message and exit.

Commands:
  config  Print generated configuration.
  init    Initialize vLLM Semantic Router configuration.
  dashboard  Launch the vLLM Semantic Router dashboard.
  logs    Show logs from vLLM Semantic Router service.
  serve   Start vLLM Semantic Router.
  status  Show status of vLLM Semantic Router services.
  stop    Stop vLLM Semantic Router.
```

&gt; [!TIP]
&gt; You can specify the HF_ENDPOINT, HF_TOKEN, and HF_HOME environment variables to configure the Hugging Face credentials.

```bash
# Set environment variables (optional)
export HF_ENDPOINT=https://huggingface.co  # Or use mirror: https://hf-mirror.com
export HF_TOKEN=your_token_here  # Only for gated models
export HF_HOME=/path/to/cache  # Optional: custom cache directory

# Start the service - models download automatically
# Environment variables are automatically passed to the container
vllm-sr serve
```

### Configuration

**File Descriptor Limits**: The CLI automatically sets file descriptor limits to 65,536 for Envoy proxy. For custom limits:

```bash
export VLLM_SR_NOFILE_LIMIT=100000  # Optional: custom limit (min: 8192)
vllm-sr serve
```

See the [vllm-sr README](src/vllm-sr/README.md#configuration) for detailed configuration options and troubleshooting.

## Documentation üìñ

For comprehensive documentation including detailed setup instructions, architecture guides, and API references, visit:

Complete Documentation at Read the **[Docs](https://vllm-semantic-router.com/)**

The documentation includes:

- **[Installation Guide](https://vllm-semantic-router.com/docs/installation/)** - Complete setup instructions
- **[System Architecture](https://vllm-semantic-router.com/docs/overview/architecture/system-architecture/)** - Technical deep dive
- **[Model Training](https://vllm-semantic-router.com/docs/training/training-overview/)** - How classification models work
- **[API Reference](https://vllm-semantic-router.com/docs/api/router/)** - Complete API documentation

## Community üëã

For questions, feedback, or to contribute, please join `#semantic-router` channel in vLLM Slack.

### Community Meetings üìÖ

We host bi-weekly community meetings to sync up with contributors across different time zones:

- **First Tuesday of the month**: 9:00-10:00 AM EST (accommodates US EST, EU, and Asia Pacific contributors)
  - [Zoom Link](https://us05web.zoom.us/j/84122485631?pwd=BB88v03mMNLVHn60YzVk4PihuqBV9d.1)
  - [Google Calendar Invite](https://us05web.zoom.us/meeting/tZAsdeuspj4sGdVraOOR4UaXSstrH2jjPYFq/calendar/google/add?meetingMasterEventId=4jjzUKSLSLiBHtIKZpGc3g)
  - [ics file](https://drive.google.com/file/d/15wO8cg0ZjNxdr8OtGiZyAgkSS8_Wry0J/view?usp=sharing)
- **Third Tuesday of the month**: 1:00-2:00 PM EST (accommodates US EST and California contributors)
  - [Zoom Link](https://us06web.zoom.us/j/86871492845?pwd=LcTtXm9gtGu23JeWqXxbnLLCCvbumB.1)
  - [Google Calendar Invite](https://us05web.zoom.us/meeting/tZIlcOispzkiHtH2dlkWlLym68bEqvuf3MU5/calendar/google/add?meetingMasterEventId=PqWz2vk7TOCszPXqconGAA)
  - [ics file](https://drive.google.com/file/d/1T54mwYpXXoV9QfR76I56BFBPNbykSsTw/view?usp=sharing)
- Meeting Recordings: [YouTube](https://www.youtube.com/@vLLMSemanticRouter/videos)

Join us to discuss the latest developments, share ideas, and collaborate on the project!

## Citation

If you find Semantic Router helpful in your research or projects, please consider citing it:

```
@misc{semanticrouter2025,
  title={vLLM Semantic Router},
  author={vLLM Semantic Router Team},
  year={2025},
  howpublished={\url{https://github.com/vllm-project/semantic-router}},
}
```

## Star History üî•

We opened the project at Aug 31, 2025. We love open source  and collaboration ‚ù§Ô∏è

[![Star History Chart](https://api.star-history.com/svg?repos=vllm-project/semantic-router&amp;type=Date)](https://www.star-history.com/#vllm-project/semantic-router&amp;Date)

## Sponsors üëã

We are grateful to our sponsors who support us:

---

[**AMD**](https://www.amd.com) provides us with GPU resources and [ROCm‚Ñ¢](https://www.amd.com/en/products/software/rocm.html) Software for training and researching the frontier router models, enhancing e2e testing, and building online models playground.

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.amd.com&quot;&gt;
  &lt;img src=&quot;website/static/img/amd-logo.svg&quot; alt=&quot;AMD&quot; width=&quot;40%&quot;/&gt;
&lt;/a&gt;
&lt;/div&gt;

---
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[livekit/livekit]]></title>
            <link>https://github.com/livekit/livekit</link>
            <guid>https://github.com/livekit/livekit</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:41 GMT</pubDate>
            <description><![CDATA[End-to-end realtime stack for connecting humans and AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/livekit/livekit">livekit/livekit</a></h1>
            <p>End-to-end realtime stack for connecting humans and AI</p>
            <p>Language: Go</p>
            <p>Stars: 16,517</p>
            <p>Forks: 1,674</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;!--BEGIN_BANNER_IMAGE--&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;/.github/banner_dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;/.github/banner_light.png&quot;&gt;
  &lt;img style=&quot;width:100%;&quot; alt=&quot;The LiveKit icon, the name of the repository and some sample code in the background.&quot; src=&quot;https://raw.githubusercontent.com/livekit/livekit/main/.github/banner_light.png&quot;&gt;
&lt;/picture&gt;

&lt;!--END_BANNER_IMAGE--&gt;

# LiveKit: Real-time video, audio and data for developers

[LiveKit](https://livekit.io) is an open source project that provides scalable, multi-user conferencing based on WebRTC.
It&#039;s designed to provide everything you need to build real-time video audio data capabilities in your applications.

LiveKit&#039;s server is written in Go, using the awesome [Pion WebRTC](https://github.com/pion/webrtc) implementation.

[![GitHub stars](https://img.shields.io/github/stars/livekit/livekit?style=social&amp;label=Star&amp;maxAge=2592000)](https://github.com/livekit/livekit/stargazers/)
[![Slack community](https://img.shields.io/endpoint?url=https%3A%2F%2Flivekit.io%2Fbadges%2Fslack)](https://livekit.io/join-slack)
[![Twitter Follow](https://img.shields.io/twitter/follow/livekit)](https://twitter.com/livekit)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/livekit/livekit)
[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/livekit/livekit)](https://github.com/livekit/livekit/releases/latest)
[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/livekit/livekit/buildtest.yaml?branch=master)](https://github.com/livekit/livekit/actions/workflows/buildtest.yaml)
[![License](https://img.shields.io/github/license/livekit/livekit)](https://github.com/livekit/livekit/blob/master/LICENSE)

## Features

-   Scalable, distributed WebRTC SFU (Selective Forwarding Unit)
-   Modern, full-featured client SDKs
-   Built for production, supports JWT authentication
-   Robust networking and connectivity, UDP/TCP/TURN
-   Easy to deploy: single binary, Docker or Kubernetes
-   Advanced features including:
    -   [speaker detection](https://docs.livekit.io/home/client/tracks/subscribe/#speaker-detection)
    -   [simulcast](https://docs.livekit.io/home/client/tracks/publish/#video-simulcast)
    -   [end-to-end optimizations](https://blog.livekit.io/livekit-one-dot-zero/)
    -   [selective subscription](https://docs.livekit.io/home/client/tracks/subscribe/#selective-subscription)
    -   [moderation APIs](https://docs.livekit.io/home/server/managing-participants/)
    -   end-to-end encryption
    -   SVC codecs (VP9, AV1)
    -   [webhooks](https://docs.livekit.io/home/server/webhooks/)
    -   [distributed and multi-region](https://docs.livekit.io/home/self-hosting/distributed/)

## Documentation &amp; Guides

https://docs.livekit.io

## Live Demos

-   [LiveKit Meet](https://meet.livekit.io) ([source](https://github.com/livekit-examples/meet))
-   [Spatial Audio](https://spatial-audio-demo.livekit.io/) ([source](https://github.com/livekit-examples/spatial-audio))
-   Livestreaming from OBS Studio ([source](https://github.com/livekit-examples/livestream))
-   [AI voice assistant using ChatGPT](https://livekit.io/kitt) ([source](https://github.com/livekit-examples/kitt))

## Ecosystem

-   [Agents](https://github.com/livekit/agents): build real-time multimodal AI applications with programmable backend participants
-   [Egress](https://github.com/livekit/egress): record or multi-stream rooms and export individual tracks
-   [Ingress](https://github.com/livekit/ingress): ingest streams from external sources like RTMP, WHIP, HLS, or OBS Studio

## SDKs &amp; Tools

### Client SDKs

Client SDKs enable your frontend to include interactive, multi-user experiences.

&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;Language&lt;/th&gt;
    &lt;th&gt;Repo&lt;/th&gt;
    &lt;th&gt;
        &lt;a href=&quot;https://docs.livekit.io/home/client/events/#declarative-ui&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Declarative UI&lt;/a&gt;
    &lt;/th&gt;
    &lt;th&gt;Links&lt;/th&gt;
  &lt;/tr&gt;
  &lt;!-- BEGIN Template
  &lt;tr&gt;
    &lt;td&gt;Language&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  END --&gt;
  &lt;!-- JavaScript --&gt;
  &lt;tr&gt;
    &lt;td&gt;JavaScript (TypeScript)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-js&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-js&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/livekit-react&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;React&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-js/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-js/tree/main/example&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;JS example&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-js/tree/main/example&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;React example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Swift --&gt;
  &lt;tr&gt;
    &lt;td&gt;Swift (iOS / MacOS)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-swift&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-swift&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;Swift UI&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-swift/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-example-swift&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Kotlin --&gt;
  &lt;tr&gt;
    &lt;td&gt;Kotlin (Android)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-android&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-android&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;Compose&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-android/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-android/tree/main/sample-app/src/main/java/io/livekit/android/sample&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;example&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-android/tree/main/sample-app-compose/src/main/java/io/livekit/android/composesample&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Compose example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;!-- Flutter --&gt;
  &lt;tr&gt;
    &lt;td&gt;Flutter (all platforms)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-flutter&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;native&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-flutter/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter/tree/main/example&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Unity --&gt;
  &lt;tr&gt;
    &lt;td&gt;Unity WebGL&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-unity-web&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-unity-web&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://livekit.github.io/client-sdk-unity-web/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- React Native --&gt;
  &lt;tr&gt;
    &lt;td&gt;React Native (beta)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-react-native&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-react-native&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;native&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Rust --&gt;
  &lt;tr&gt;
    &lt;td&gt;Rust&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-rust&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-rust&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

### Server SDKs

Server SDKs enable your backend to generate [access tokens](https://docs.livekit.io/home/get-started/authentication/),
call [server APIs](https://docs.livekit.io/reference/server/server-apis/), and
receive [webhooks](https://docs.livekit.io/home/server/webhooks/). In addition, the Go SDK includes client capabilities,
enabling you to build automations that behave like end-users.

| Language                | Repo                                                                                    | Docs                                                        |
| :---------------------- | :-------------------------------------------------------------------------------------- | :---------------------------------------------------------- |
| Go                      | [server-sdk-go](https://github.com/livekit/server-sdk-go)                               | [docs](https://pkg.go.dev/github.com/livekit/server-sdk-go) |
| JavaScript (TypeScript) | [server-sdk-js](https://github.com/livekit/server-sdk-js)                               | [docs](https://docs.livekit.io/server-sdk-js/)              |
| Ruby                    | [server-sdk-ruby](https://github.com/livekit/server-sdk-ruby)                           |                                                             |
| Java (Kotlin)           | [server-sdk-kotlin](https://github.com/livekit/server-sdk-kotlin)                       |                                                             |
| Python (community)      | [python-sdks](https://github.com/livekit/python-sdks)                                   |                                                             |
| PHP (community)         | [agence104/livekit-server-sdk-php](https://github.com/agence104/livekit-server-sdk-php) |                                                             |

### Tools

-   [CLI](https://github.com/livekit/livekit-cli) - command line interface &amp; load tester
-   [Docker image](https://hub.docker.com/r/livekit/livekit-server)
-   [Helm charts](https://github.com/livekit/livekit-helm)

## Install

&gt; [!TIP]
&gt; We recommend installing [LiveKit CLI](https://github.com/livekit/livekit-cli) along with the server. It lets you access
&gt; server APIs, create tokens, and generate test traffic.

The following will install LiveKit&#039;s media server:

### MacOS

```shell
brew install livekit
```

### Linux

```shell
curl -sSL https://get.livekit.io | bash
```

### Windows

Download the [latest release here](https://github.com/livekit/livekit/releases/latest)

## Getting Started

### Starting LiveKit

Start LiveKit in development mode by running `livekit-server --dev`. It&#039;ll use a placeholder API key/secret pair.

```
API Key: devkey
API Secret: secret
```

To customize your setup for production, refer to our [deployment docs](https://docs.livekit.io/deploy/)

### Creating access token

A user connecting to a LiveKit room requires an [access token](https://docs.livekit.io/home/get-started/authentication/#creating-a-token). Access
tokens (JWT) encode the user&#039;s identity and the room permissions they&#039;ve been granted. You can generate a token with our
CLI:

```shell
lk token create \
    --api-key devkey --api-secret secret \
    --join --room my-first-room --identity user1 \
    --valid-for 24h
```

### Test with example app

Head over to our [example app](https://example.livekit.io) and enter a generated token to connect to your LiveKit
server. This app is built with our [React SDK](https://github.com/livekit/livekit-react).

Once connected, your video and audio are now being published to your new LiveKit instance!

### Simulating a test publisher

```shell
lk room join \
    --url ws://localhost:7880 \
    --api-key devkey --api-secret secret \
    --identity bot-user1 \
    --publish-demo \
    my-first-room
```

This command publishes a looped demo video to a room. Due to how the video clip was encoded (keyframes every 3s),
there&#039;s a slight delay before the browser has sufficient data to begin rendering frames. This is an artifact of the
simulation.

## Deployment

### Use LiveKit Cloud

LiveKit Cloud is the fastest and most reliable way to run LiveKit. Every project gets free monthly bandwidth and
transcoding credits.

Sign up for [LiveKit Cloud](https://cloud.livekit.io/).

### Self-host

Read our [deployment docs](https://docs.livekit.io/deploy/) for more information.

## Building from source

Pre-requisites:

-   Go 1.23+ is installed
-   GOPATH/bin is in your PATH

Then run

```shell
git clone https://github.com/livekit/livekit
cd livekit
./bootstrap.sh
mage
```

## Contributing

We welcome your contributions toward improving LiveKit! Please join us
[on Slack](http://livekit.io/join-slack) to discuss your ideas and/or PRs.

## License

LiveKit server is licensed under Apache License v2.0.

&lt;!--BEGIN_REPO_NAV--&gt;
&lt;br/&gt;&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;LiveKit Ecosystem&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;LiveKit SDKs&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/client-sdk-js&quot;&gt;Browser&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-swift&quot;&gt;iOS/macOS/visionOS&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-android&quot;&gt;Android&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter&quot;&gt;Flutter&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-react-native&quot;&gt;React Native&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/rust-sdks&quot;&gt;Rust&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/node-sdks&quot;&gt;Node.js&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/python-sdks&quot;&gt;Python&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-unity&quot;&gt;Unity&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-unity-web&quot;&gt;Unity (WebGL)&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-esp32&quot;&gt;ESP32&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Server APIs&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/node-sdks&quot;&gt;Node.js&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/server-sdk-go&quot;&gt;Golang&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/server-sdk-ruby&quot;&gt;Ruby&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/server-sdk-kotlin&quot;&gt;Java/Kotlin&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/python-sdks&quot;&gt;Python&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/rust-sdks&quot;&gt;Rust&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/agence104/livekit-server-sdk-php&quot;&gt;PHP (community)&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/pabloFuente/livekit-server-sdk-dotnet&quot;&gt;.NET (community)&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;UI Components&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/components-js&quot;&gt;React&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/components-android&quot;&gt;Android Compose&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/components-swift&quot;&gt;SwiftUI&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/components-flutter&quot;&gt;Flutter&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Agents Frameworks&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/agents&quot;&gt;Python&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/agents-js&quot;&gt;Node.js&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/agent-playground&quot;&gt;Playground&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Services&lt;/td&gt;&lt;td&gt;&lt;b&gt;LiveKit server&lt;/b&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/egress&quot;&gt;Egress&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/ingress&quot;&gt;Ingress&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/sip&quot;&gt;SIP&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Resources&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://docs.livekit.io&quot;&gt;Docs&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit-examples&quot;&gt;Example apps&lt;/a&gt; ¬∑ &lt;a href=&quot;https://livekit.io/cloud&quot;&gt;Cloud&lt;/a&gt; ¬∑ &lt;a href=&quot;https://docs.livekit.io/home/self-hosting/deployment&quot;&gt;Self-hosting&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/livekit-cli&quot;&gt;CLI&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!--END_REPO_NAV--&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[oauth2-proxy/oauth2-proxy]]></title>
            <link>https://github.com/oauth2-proxy/oauth2-proxy</link>
            <guid>https://github.com/oauth2-proxy/oauth2-proxy</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:40 GMT</pubDate>
            <description><![CDATA[A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oauth2-proxy/oauth2-proxy">oauth2-proxy/oauth2-proxy</a></h1>
            <p>A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.</p>
            <p>Language: Go</p>
            <p>Stars: 13,637</p>
            <p>Forks: 1,981</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>[![Continuous Integration](https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml/badge.svg)](https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml)
[![Go Report Card](https://goreportcard.com/badge/github.com/oauth2-proxy/oauth2-proxy)](https://goreportcard.com/report/github.com/oauth2-proxy/oauth2-proxy)
[![GoDoc](https://godoc.org/github.com/oauth2-proxy/oauth2-proxy?status.svg)](https://godoc.org/github.com/oauth2-proxy/oauth2-proxy)
[![MIT licensed](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)
[![Maintainability](https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/maintainability)](https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/maintainability)
[![Test Coverage](https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/test_coverage)](https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/test_coverage)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Foauth2-proxy%2Foauth2-proxy.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Foauth2-proxy%2Foauth2-proxy?ref=badge_shield)

![OAuth2 Proxy](docs/static/img/logos/OAuth2_Proxy_horizontal.svg)

OAuth2-Proxy is a flexible, open-source tool that can act as either a standalone reverse proxy or a middleware component integrated into existing reverse proxy or load balancer setups. It provides a simple and secure way to protect your web applications with OAuth2 / OIDC authentication. As a reverse proxy, it intercepts requests to your application and redirects users to an OAuth2 provider for authentication. As a middleware, it can be seamlessly integrated into your existing infrastructure to handle authentication for multiple applications.

OAuth2-Proxy supports a lot of OAuth2 as well as OIDC providers. Either through a generic OIDC client or a specific implementation for Google, Microsoft Entra ID, GitHub, login.gov and others. Through specialised provider implementations oauth2-proxy can extract more details about the user like preferred usernames and groups. Those details can then be forwarded as HTTP headers to your upstream applications.

![Simplified Architecture](docs/static/img/simplified-architecture.svg)

## Get Started

OAuth2-Proxy&#039;s [Installation Docs](https://oauth2-proxy.github.io/oauth2-proxy/installation) cover how to install and configure your setup. Additionally you can take a further look at the [example setup files](https://github.com/oauth2-proxy/oauth2-proxy/tree/master/contrib/local-environment).

## Releases

### Binaries
We publish oauth2-proxy as compiled binaries on GitHub for all major architectures as well as more exotic ones like `ppc64le` as well as `s390x`.

Check out the [latest release](https://github.com/oauth2-proxy/oauth2-proxy/releases/latest).

### Images

From `v7.6.0` and up the base image has been changed from Alpine to [GoogleContainerTools/distroless](https://github.com/GoogleContainerTools/distroless).
This image comes with even fewer installed dependencies and thus should improve security. The image therefore is also slightly smaller than Alpine.
For debugging purposes (and those who really need it. e.g. `armv6`) we still provide images based on Alpine. The tags of these images are suffixed with `-alpine`.

Since 2023-11-18 we build nightly images directly from the `master` branch and provide them at `quay.io/oauth2-proxy/oauth2-proxy-nightly`.
These images are considered unstable and therefore should **NOT** be used for production purposes unless you know what you&#039;re doing.

## Sponsors

![Microsoft](https://upload.wikimedia.org/wikipedia/commons/9/96/Microsoft_logo_%282012%29.svg)
Microsoft Azure credits for open source projects

Would you like to sponsor the project then please contact us at [sponsors@oauth2-proxy.dev](mailto:sponsors@oauth2-proxy.dev)

## Getting Involved
[![Slack](https://img.shields.io/badge/slack-Gopher_%23oauth2--proxy-red?logo=slack)](https://gophers.slack.com/archives/CM2RSS25N)

Join the #oauth2-proxy [Slack channel](https://gophers.slack.com/archives/CM2RSS25N) to chat with other users of oauth2-proxy or reach out to the maintainers directly. Use the [public invite link](https://invite.slack.golangbridge.org/) to get an invite for the Gopher Slack space.

OAuth2-Proxy is a community-driven project. We rely on the contributÔ∏èions of our users to continually improve it. While review times can vary, we appreciate your patience and understanding. As a volunteer-driven project, we strive to keep this project stable and might take longer to merge changes.

If you want to contribute to the project. Please see our [Contributing](https://oauth2-proxy.github.io/oauth2-proxy/community/contribution) guide.

Who uses OAuth2-Proxy? Have a look at our new [ADOPTERS](ADOPTERS.md) file and
feel free to open a PR to add your organisation.

Thanks to all the people who already contributed ‚ù§

&lt;a href=&quot;https://github.com/oauth2-proxy/oauth2-proxy/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=oauth2-proxy/oauth2-proxy&amp;columns=15&amp;max=75&quot; /&gt;
  &lt;img src=&quot;https://img.shields.io/github/contributors/oauth2-proxy/oauth2-proxy&quot; /&gt;
&lt;/a&gt;

Made with [contrib.rocks](https://contrib.rocks).

## Security

If you believe you have found a vulnerability within OAuth2 Proxy or any of its dependencies, please do **NOT** open an issue or PR on GitHub, please do **NOT** post any details publicly.

Security disclosures **MUST** be done in private. If you have found an issue that you would like to bring to the attention of the maintainers, please compose an email and send it to the list of people listed in our [MAINTAINERS](MAINTAINERS) file.

For more details read our full [Security Docs](https://oauth2-proxy.github.io/oauth2-proxy/community/security#security-disclosures)

### Security Notice for v6.0.0 and older

If you are running a version older than v6.0.0 we **strongly recommend** to the current version.

See [open redirect vulnerability](https://github.com/oauth2-proxy/oauth2-proxy/security/advisories/GHSA-5m6c-jp6f-2vcv) for details.

## Repository History

**2018-11-27:** This repository was forked from [bitly/OAuth2_Proxy](https://github.com/bitly/oauth2_proxy). Versions v3.0.0 and up are from this fork and will have diverged from any changes in the original fork. A list of changes can be seen in the [CHANGELOG](CHANGELOG.md).

**2020-03-29:** This project was formerly hosted as `pusher/oauth2_proxy` but has been renamed to `oauth2-proxy/oauth2-proxy`. Going forward, all images shall be available at `quay.io/oauth2-proxy/oauth2-proxy` and binaries will be named `oauth2-proxy`.

## License

OAuth2-Proxy is distributed under [The MIT License](LICENSE).


[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Foauth2-proxy%2Foauth2-proxy.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Foauth2-proxy%2Foauth2-proxy?ref=badge_large)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[henrygd/beszel]]></title>
            <link>https://github.com/henrygd/beszel</link>
            <guid>https://github.com/henrygd/beszel</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:39 GMT</pubDate>
            <description><![CDATA[Lightweight server monitoring hub with historical data, docker stats, and alerts.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/henrygd/beszel">henrygd/beszel</a></h1>
            <p>Lightweight server monitoring hub with historical data, docker stats, and alerts.</p>
            <p>Language: Go</p>
            <p>Stars: 18,624</p>
            <p>Forks: 597</p>
            <p>Stars today: 39 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[runatlantis/atlantis]]></title>
            <link>https://github.com/runatlantis/atlantis</link>
            <guid>https://github.com/runatlantis/atlantis</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:38 GMT</pubDate>
            <description><![CDATA[Terraform Pull Request Automation]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/runatlantis/atlantis">runatlantis/atlantis</a></h1>
            <p>Terraform Pull Request Automation</p>
            <p>Language: Go</p>
            <p>Stars: 8,759</p>
            <p>Forks: 1,208</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre># Atlantis &lt;!-- omit in toc --&gt;

[![Latest Release](https://img.shields.io/github/release/runatlantis/atlantis.svg)](https://github.com/runatlantis/atlantis/releases/latest)
[![SuperDopeBadge](./runatlantis.io/public/hightower-super-dope.svg)](https://twitter.com/kelseyhightower/status/893260922222813184)
[![Go Report Card](https://goreportcard.com/badge/github.com/runatlantis/atlantis)](https://goreportcard.com/report/github.com/runatlantis/atlantis)
[![Go Reference](https://pkg.go.dev/badge/github.com/runatlantis/atlantis.svg)](https://pkg.go.dev/github.com/runatlantis/atlantis)
[![Slack](https://img.shields.io/badge/Join-Atlantis%20Community%20Slack-red)](https://slack.cncf.io/)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/runatlantis/atlantis/badge)](https://scorecard.dev/viewer/?uri=github.com/runatlantis/atlantis)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9428/badge)](https://www.bestpractices.dev/projects/9428)

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./runatlantis.io/public/hero.png&quot; alt=&quot;Atlantis Logo&quot;/&gt;&lt;br&gt;&lt;br&gt;
  &lt;b&gt;Terraform Pull Request Automation&lt;/b&gt;
&lt;/p&gt;

- [Resources](#resources)
- [What is Atlantis?](#what-is-atlantis)
- [What does it do?](#what-does-it-do)
- [Why should you use it?](#why-should-you-use-it)
- [Stargazers over time](#stargazers-over-time)

## Resources
* How to get started: [www.runatlantis.io/guide](https://www.runatlantis.io/guide)
* Full documentation: [www.runatlantis.io/docs](https://www.runatlantis.io/docs)
* Download the latest release: [github.com/runatlantis/atlantis/releases/latest](https://github.com/runatlantis/atlantis/releases/latest)
* Get help in our [Slack channel](https://slack.cncf.io/) in channel #atlantis and development in #atlantis-contributors
* Start Contributing: [CONTRIBUTING.md](CONTRIBUTING.md)

## What is Atlantis?
A self-hosted golang application that listens for Terraform pull request events via webhooks.

## What does it do?
Runs `terraform plan`, `import`, `apply` remotely and comments back on the pull request with the output.

## Why should you use it?
* Make Terraform changes visible to your whole team.
* Enable non-operations engineers to collaborate on Terraform.
* Standardize your Terraform workflows.

## Stargazers over time

[![Stargazers over time](https://starchart.cc/runatlantis/atlantis.svg)](https://starchart.cc/runatlantis/atlantis)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-collector]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-collector</link>
            <guid>https://github.com/open-telemetry/opentelemetry-collector</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:37 GMT</pubDate>
            <description><![CDATA[OpenTelemetry Collector]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-collector">open-telemetry/opentelemetry-collector</a></h1>
            <p>OpenTelemetry Collector</p>
            <p>Language: Go</p>
            <p>Stars: 6,495</p>
            <p>Forks: 1,832</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>---

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/getting-started/&quot;&gt;Getting Started&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;Getting Involved&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;Getting In Touch&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/actions/workflows/build-and-test.yml?query=branch%3Amain&quot;&gt;
    &lt;img alt=&quot;Build Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector/build-and-test.yml?branch=main&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector&quot;&gt;
    &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/open-telemetry/opentelemetry-collector/branch/main/&quot;&gt;
    &lt;img alt=&quot;Codecov Status&quot; src=&quot;https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest by date including pre-releases)&quot; src=&quot;https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector?include_prereleases&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;/br&gt;
  &lt;a href=&quot;https://www.bestpractices.dev/projects/8404&quot;&gt;&lt;img src=&quot;https://www.bestpractices.dev/projects/8404/badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:opentelemetry&quot;&gt;
    &lt;img alt=&quot;Fuzzing Status&quot; src=&quot;https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry.svg&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;docs/vision.md&quot;&gt;Vision&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/configuration/&quot;&gt;Configuration&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/internal-telemetry/#use-internal-telemetry-to-monitor-the-collector&quot;&gt;Monitoring&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;docs/security-best-practices.md&quot;&gt;Security&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://pkg.go.dev/go.opentelemetry.io/collector&quot;&gt;Package&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

---

# &lt;img src=&quot;https://opentelemetry.io/img/logos/opentelemetry-logo-nav.png&quot; alt=&quot;OpenTelemetry Icon&quot; width=&quot;45&quot; height=&quot;&quot;&gt; OpenTelemetry Collector

The OpenTelemetry Collector offers a vendor-agnostic implementation on how to
receive, process and export telemetry data. In addition, it removes the need
to run, operate and maintain multiple agents/collectors in order to support
open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) to
multiple open-source or commercial back-ends.

Objectives:

- Usable: Reasonable default configuration, supports popular protocols, runs and collects out of the box.
- Performant: Highly stable and performant under varying loads and configurations.
- Observable: An exemplar of an observable service.
- Extensible: Customizable without touching the core code.
- Unified: Single codebase, deployable as an agent or collector with support for traces, metrics and logs.

## Community

The OpenTelemetry Collector SIG is present at the [#otel-collector](https://cloud-native.slack.com/archives/C01N6P7KR6W)
channel on the CNCF Slack and [meets once a week](https://github.com/open-telemetry/community#implementation-sigs) via
video calls. Everyone is invited to join those calls, which typically serves the following purposes:

- meet the humans behind the project
- get an opinion about specific proposals
- look for a sponsor for a proposed component after trying already via GitHub and Slack
- get attention to a specific pull-request that got stuck and is difficult to discuss asynchronously

We rotate our video calls between three time slots, in order to
allow everyone to join at least once every three meetings. The rotation order is as follows:

Tuesday:

- [17:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=1700)

Wednesday:

- [09:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=0900)
- [05:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=0500)

Contributors to the project are also welcome to have ad-hoc meetings for synchronous discussions about specific points.
Post a note in #otel-collector-dev on Slack inviting others, specifying the topic to be discussed. Unless there are strong
reasons to keep the meeting private, please make it an open invitation for other contributors to join. Try also to
identify who would be the other contributors interested on that topic and in which timezones they are.

Remember that our source of truth is GitHub: every decision made via Slack or video calls has to be recorded in the
relevant GitHub issue. Ideally, the agenda items from the meeting notes would include a link to the issue or pull
request where a discussion is happening already. We acknowledge that not everyone can join Slack or the synchronous
calls and don&#039;t want them to feel excluded.

## Supported OTLP version

This code base is currently built against using OTLP protocol v1.5.0,
considered Stable. [See the OpenTelemetry Protocol Stability
definition
here.](https://github.com/open-telemetry/opentelemetry-proto?tab=readme-ov-file#stability-definition)

## Stability levels

See [Stability Levels and versioning](docs/component-stability.md) for more details.

## Compatibility

When used as a library, the OpenTelemetry Collector attempts to track the currently supported versions of Go, as [defined by the Go team](https://go.dev/doc/devel/release#policy).
Removing support for an unsupported Go version is not considered a breaking change.

Support for Go versions on the OpenTelemetry Collector is updated as follows:

1. The first release after the release of a new Go minor version `N` will add build and tests steps for the new Go minor version.
2. The first release after the release of a new Go minor version `N` will remove support for Go version `N-2`.

Official OpenTelemetry Collector distro binaries will be built with a release in the latest Go minor version series.

## Verifying the images signatures

&gt; [!NOTE]
&gt; To verify a signed artifact or blob, first [install Cosign](https://docs.sigstore.dev/cosign/system_config/installation/), then follow the instructions below.

We are signing the images `otel/opentelemetry-collector` and `otel/opentelemetry-collector-contrib` using [sigstore cosign](https://github.com/sigstore/cosign) tool and to verify the signatures you can run the following command:

```console
$ cosign verify \
  --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/&lt;RELEASE_TAG&gt; \
  --certificate-oidc-issuer=https://token.actions.githubusercontent.com \
  &lt;OTEL_COLLECTOR_IMAGE&gt;
```

where:

- `&lt;RELEASE_TAG&gt;`: is the release that you want to validate
- `&lt;OTEL_COLLECTOR_IMAGE&gt;`: is the image that you want to check

Example:

```console
$ cosign verify --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0 --certificate-oidc-issuer=https://token.actions.githubusercontent.com ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0

Verification for ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0 --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - Existence of the claims in the transparency log was verified offline
  - The code-signing certificate was verified using trusted certificate authority certificates

[{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:{&quot;1.3.6.1.4.1.57264.1.1&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;1.3.6.1.4.1.57264.1.2&quot;:&quot;push&quot;,&quot;1.3.6.1.4.1.57264.1.3&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;1.3.6.1.4.1.57264.1.4&quot;:&quot;Release Contrib&quot;,&quot;1.3.6.1.4.1.57264.1.5&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;1.3.6.1.4.1.57264.1.6&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;Bundle&quot;:{&quot;SignedEntryTimestamp&quot;:&quot;MEUCIQDdlmNeKXQrHnonwWiHLhLLwFDVDNoOBCn2sv85J9P8mgIgDQFssWJImo1hn38VlojvSCL7Qq5FMmtnGu0oLsNdOm8=&quot;,&quot;Payload&quot;:{&quot;body&quot;:&quot;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&quot;,&quot;integratedTime&quot;:1712809120,&quot;logIndex&quot;:84797936,&quot;logID&quot;:&quot;c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d&quot;}},&quot;Issuer&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;Subject&quot;:&quot;https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0&quot;,&quot;githubWorkflowName&quot;:&quot;Release Contrib&quot;,&quot;githubWorkflowRef&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;githubWorkflowRepository&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;githubWorkflowSha&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;githubWorkflowTrigger&quot;:&quot;push&quot;}},{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:{&quot;1.3.6.1.4.1.57264.1.1&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;1.3.6.1.4.1.57264.1.2&quot;:&quot;push&quot;,&quot;1.3.6.1.4.1.57264.1.3&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;1.3.6.1.4.1.57264.1.4&quot;:&quot;Release Contrib&quot;,&quot;1.3.6.1.4.1.57264.1.5&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;1.3.6.1.4.1.57264.1.6&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;Bundle&quot;:{&quot;SignedEntryTimestamp&quot;:&quot;MEUCIQD1ehDnPO6fzoPIpeQ3KFuYHHBiX7RcEbpo9B2r7JAlzwIgZ1bsuQz7gAXbNU1IEdsTQgfAnRk3xVXO16GnKXM2sAQ=&quot;,&quot;Payload&quot;:{&quot;body&quot;:&quot;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

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[wavetermdev/waveterm]]></title>
            <link>https://github.com/wavetermdev/waveterm</link>
            <guid>https://github.com/wavetermdev/waveterm</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:36 GMT</pubDate>
            <description><![CDATA[An open-source, cross-platform terminal for seamless workflows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wavetermdev/waveterm">wavetermdev/waveterm</a></h1>
            <p>An open-source, cross-platform terminal for seamless workflows</p>
            <p>Language: Go</p>
            <p>Stars: 16,261</p>
            <p>Forks: 698</p>
            <p>Stars today: 111 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.waveterm.dev&quot;&gt;
	&lt;picture&gt;
		&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./assets/wave-dark.png&quot;&gt;
		&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./assets/wave-light.png&quot;&gt;
		&lt;img alt=&quot;Wave Terminal Logo&quot; src=&quot;./assets/wave-light.png&quot; width=&quot;240&quot;&gt;
	&lt;/picture&gt;
  &lt;/a&gt;
  &lt;br/&gt;
&lt;/p&gt;

# Wave Terminal

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm?ref=badge_shield)

Wave is an open-source terminal that combines traditional terminal features with graphical capabilities like file previews, web browsing, and AI assistance. It runs on MacOS, Linux, and Windows.

Modern development involves constantly switching between terminals and browsers - checking documentation, previewing files, monitoring systems, and using AI tools. Wave brings these graphical tools directly into the terminal, letting you control them from the command line. This means you can stay in your terminal workflow while still having access to the visual interfaces you need.

![WaveTerm Screenshot](./assets/wave-screenshot.webp)

## Key Features

- Flexible drag &amp; drop interface to organize terminal blocks, editors, web browsers, and AI assistants
- Built-in editor for seamlessly editing remote files with syntax highlighting and modern editor features
- Rich file preview system for remote files (markdown, images, video, PDFs, CSVs, directories)
- Quick full-screen toggle for any block - expand terminals, editors, and previews for better visibility, then instantly return to multi-block view
- Wave AI - Context-aware terminal assistant that reads your terminal output, analyzes widgets, and performs file operations
- AI chat widget with support for multiple models (OpenAI, Claude, Azure, Perplexity, Ollama)
- Command Blocks for isolating and monitoring individual commands with auto-close options
- One-click remote connections with full terminal and file system access
- Secure secret storage using native system backends - store API keys and credentials locally, access them across SSH sessions
- Rich customization including tab themes, terminal styles, and background images
- Powerful `wsh` command system for managing your workspace from the CLI and sharing data between terminal sessions
- Connected file management with `wsh file` - seamlessly copy and sync files between local, remote SSH hosts, Wave filesystem, and S3

## Wave AI

Wave AI is your context-aware terminal assistant with access to your workspace:

- **Terminal Context**: Reads terminal output and scrollback for debugging and analysis
- **File Operations**: Read, write, and edit files with automatic backups and user approval
- **CLI Integration**: Use `wsh ai` to pipe output or attach files directly from the command line
- **Free Beta**: Included AI credits while we refine the experience
- **Coming Soon**: Command execution (with approval), local model support, and alternate AI providers (BYOK)

Learn more in our [Wave AI documentation](https://docs.waveterm.dev/waveai).

## Installation

Wave Terminal works on macOS, Linux, and Windows.

Platform-specific installation instructions can be found [here](https://docs.waveterm.dev/gettingstarted).

You can also install Wave Terminal directly from: [www.waveterm.dev/download](https://www.waveterm.dev/download).

### Minimum requirements

Wave Terminal runs on the following platforms:

- macOS 11 or later (arm64, x64)
- Windows 10 1809 or later (x64)
- Linux based on glibc-2.28 or later (Debian 10, RHEL 8, Ubuntu 20.04, etc.) (arm64, x64)

The WSH helper runs on the following platforms:

- macOS 11 or later (arm64, x64)
- Windows 10 or later (arm64, x64)
- Linux Kernel 2.6.32 or later (x64), Linux Kernel 3.1 or later (arm64)

## Roadmap

Wave is constantly improving! Our roadmap will be continuously updated with our goals for each release. You can find it [here](./ROADMAP.md).

Want to provide input to our future releases? Connect with us on [Discord](https://discord.gg/XfvZ334gwU) or open a [Feature Request](https://github.com/wavetermdev/waveterm/issues/new/choose)!

## Links

- Homepage &amp;mdash; https://www.waveterm.dev
- Download Page &amp;mdash; https://www.waveterm.dev/download
- Documentation &amp;mdash; https://docs.waveterm.dev
- Legacy Documentation &amp;mdash; https://legacydocs.waveterm.dev
- Blog &amp;mdash; https://blog.waveterm.dev
- X &amp;mdash; https://x.com/wavetermdev
- Discord Community &amp;mdash; https://discord.gg/XfvZ334gwU

## Building from Source

See [Building Wave Terminal](BUILD.md).

## Contributing

Wave uses GitHub Issues for issue tracking.

Find more information in our [Contributions Guide](CONTRIBUTING.md), which includes:

- [Ways to contribute](CONTRIBUTING.md#contributing-to-wave-terminal)
- [Contribution guidelines](CONTRIBUTING.md#before-you-start)

## License

Wave Terminal is licensed under the Apache-2.0 License. For more information on our dependencies, see [here](./ACKNOWLEDGEMENTS.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-policy-agent/opa]]></title>
            <link>https://github.com/open-policy-agent/opa</link>
            <guid>https://github.com/open-policy-agent/opa</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:35 GMT</pubDate>
            <description><![CDATA[Open Policy Agent (OPA) is an open source, general-purpose policy engine.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-policy-agent/opa">open-policy-agent/opa</a></h1>
            <p>Open Policy Agent (OPA) is an open source, general-purpose policy engine.</p>
            <p>Language: Go</p>
            <p>Stars: 11,086</p>
            <p>Forks: 1,502</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># ![logo](./logo/logo-144x144.png) Open Policy Agent

[![Build Status](https://github.com/open-policy-agent/opa/workflows/Post%20Merge/badge.svg)](https://github.com/open-policy-agent/opa/actions) [![Go Report Card](https://goreportcard.com/badge/github.com/open-policy-agent/opa)](https://goreportcard.com/report/github.com/open-policy-agent/opa) [![CII Best Practices](https://www.bestpractices.dev/projects/1768/badge)](https://www.bestpractices.dev/en/projects/1768/passing) [![Netlify Status](https://api.netlify.com/api/v1/badges/4a0a092a-8741-4826-a28f-826d4a576cab/deploy-status)](https://app.netlify.com/sites/openpolicyagent/deploys)

Open Policy Agent (OPA) is an open source, general-purpose policy engine that enables unified, context-aware policy enforcement across the entire stack.

OPA is proud to be a graduated project in the [Cloud Native Computing Foundation](https://www.cncf.io/) (CNCF) landscape. For details read the CNCF [announcement](https://www.cncf.io/announcements/2021/02/04/cloud-native-computing-foundation-announces-open-policy-agent-graduation/).

## Get started with OPA

- Write your first Rego policy with the [Rego Playground](https://play.openpolicyagent.org) or use it to share your work with others for feedback and support. Have a look at the [Access Control examples](https://play.openpolicyagent.org/?example-group=access-control) if you&#039;re not sure where to start.
- Install the [VS Code extension](https://marketplace.visualstudio.com/items?itemName=tsandall.opa) to get started locally with live diagnostics, debugging and formatting. See [Editor and IDE Support](https://www.openpolicyagent.org/docs/editor-and-ide-support) for other supported editors.
- Go to the [OPA Documentation](https://www.openpolicyagent.org/docs) to
  learn about the Rego language as well as how to deploy and integrate OPA.
- Check out the learning resources in the [Learning Rego](https://www.openpolicyagent.org/ecosystem/by-feature/learning-rego) section of the ecosystem directory.
- Follow the [Running OPA](https://www.openpolicyagent.org/docs/latest/#running-opa) instructions to get started with the OPA CLI locally.
- See [Docker Hub](https://hub.docker.com/r/openpolicyagent/opa/tags/) for container images and the [GitHub releases](https://github.com/open-policy-agent/opa/releases) for binaries.
- Check out the [OPA Roadmap](https://docs.google.com/presentation/d/16QV6gvLDOV3I0_guPC3_19g6jHkEg3X9xqMYgtoCKrs/edit?usp=sharing) to see a high-level snapshot of OPA features in-progress and planned.

## Want to talk about OPA or get support?

- Join the [OPA Slack](https://slack.openpolicyagent.org) to talk to other OPA users and maintainers. See `#help` for support.
- Check out the [Community Discussions](https://github.com/orgs/open-policy-agent/discussions) to ask questions.
- See the [Support](https://www.openpolicyagent.org/support) page for commercial support options.

## Interested to learn what others are doing with OPA?

- Browse community projects on the [OPA Ecosystem Directory](https://www.openpolicyagent.org/ecosystem) - don&#039;t forget to [list your own](https://github.com/open-policy-agent/opa/tree/main/docs#opa-ecosystem)!
- Check out the [ADOPTERS.md](./ADOPTERS.md) file for a list of production adopters. Does your organization use OPA in production? Support the OPA project by submitting a PR to add your organization to the list with a short description of your OPA use cases!

## Want to integrate OPA?

- See the high-level [Go SDK](https://www.openpolicyagent.org/docs/latest/integration/#integrating-with-the-go-sdk) or the low-level Go API
  [![GoDoc](https://godoc.org/github.com/open-policy-agent/opa?status.svg)](https://godoc.org/github.com/open-policy-agent/opa/rego)
  to integrate OPA with services written in Go.
- See the [REST API](https://www.openpolicyagent.org/docs/rest-api.html)
  reference to integrate OPA with services written in other languages.
- See the [integration docs](https://www.openpolicyagent.org/docs/latest/integration/) for more options.

## Want to contribute to OPA?

- Read the [Contributing Guide](https://www.openpolicyagent.org/docs/latest/contributing/) to learn how to make your first contribution.
- Use [#contributors](https://openpolicyagent.slack.com/archives/C02L1TLPN59) in Slack to talk to other contributors and OPA maintainers.
- File a [GitHub Issue](https://github.com/open-policy-agent/opa/issues) to request features or report bugs.

## How does OPA work?

OPA gives you a high-level declarative language to author and enforce policies
across your stack.

With OPA, you define _rules_ that govern how your system should behave. These
rules exist to answer questions like:

- Can user X call operation Y on resource Z?
- What clusters should workload W be deployed to?
- What tags must be set on resource R before it&#039;s created?

You integrate services with OPA so that these kinds of policy decisions do not
have to be _hardcoded_ in your service. Services integrate with OPA by
executing _queries_ when policy decisions are needed.

When you query OPA for a policy decision, OPA evaluates the rules and data
(which you give it) to produce an answer. The policy decision is sent back as
the result of the query.

For example, in a simple API authorization use case:

- You write rules that allow (or deny) access to your service APIs.
- Your service queries OPA when it receives API requests.
- OPA returns allow (or deny) decisions to your service.
- Your service _enforces_ the decisions by accepting or rejecting requests accordingly.

For concrete examples of how to integrate OPA with systems like
[Kubernetes](https://www.openpolicyagent.org/docs/kubernetes),
[Terraform](https://www.openpolicyagent.org/docs/terraform),
[Docker](https://www.openpolicyagent.org/docs/docker-authorization),
[SSH](https://www.openpolicyagent.org/docs/ssh-and-sudo-authorization),
and more, see [openpolicyagent.org](https://www.openpolicyagent.org).

## Presentations

- Open Policy Agent (OPA) Intro &amp; Deep Dive @ Kubecon NA 2023: [video](https://www.youtube.com/watch?v=wJkjsvVpj_Q)
- Open Policy Agent (OPA) Intro &amp; Deep Dive @ Kubecon EU 2023: [video](https://www.youtube.com/watch?v=6RNp3m_THw4)
- Running Policy in Hard to Reach Places with WASM &amp; OPA @ CN Wasm Day EU 2023: [video](https://www.youtube.com/watch?v=BdeBhukLwt4)
- OPA maintainers talk @ Kubecon NA 2022: [video](https://www.youtube.com/watch?v=RMiovzGGCfI)
- Open Policy Agent (OPA) Intro &amp; Deep Dive @ Kubecon EU 2022: [video](https://www.youtube.com/watch?v=MhyQxIp1H58)
- Open Policy Agent Intro @ KubeCon EU 2021: [Video](https://www.youtube.com/watch?v=2CgeiWkliaw)
- Using Open Policy Agent to Meet Evolving Policy Requirements @ KubeCon NA 2020: [video](https://www.youtube.com/watch?v=zVuM7F_BTyc)
- Applying Policy Throughout The Application Lifecycle with Open Policy Agent @ CloudNativeCon 2019: [video](https://www.youtube.com/watch?v=cXfsaE6RKfc)
- Open Policy Agent Introduction @ CloudNativeCon EU 2018: [video](https://youtu.be/XEHeexPpgrA), [slides](https://www.slideshare.net/TorinSandall/opa-the-cloud-native-policy-engine)
- Rego Deep Dive @ CloudNativeCon EU 2018: [video](https://youtu.be/4mBJSIhs2xQ), [slides](https://www.slideshare.net/TorinSandall/rego-deep-dive)
- How Netflix Is Solving Authorization Across Their Cloud @ CloudNativeCon US 2017: [video](https://www.youtube.com/watch?v=R6tUNpRpdnY), [slides](https://www.slideshare.net/TorinSandall/how-netflix-is-solving-authorization-across-their-cloud).
- Policy-based Resource Placement in Kubernetes Federation @ LinuxCon Beijing 2017: [slides](https://www.slideshare.net/TorinSandall/policybased-resource-placement-across-hybrid-cloud), [screencast](https://www.youtube.com/watch?v=hRz13baBhfg&amp;feature=youtu.be)
- Enforcing Bespoke Policies In Kubernetes @ KubeCon US 2017: [video](https://www.youtube.com/watch?v=llDI8VvkUj8), [slides](https://www.slideshare.net/TorinSandall/enforcing-bespoke-policies-in-kubernetes)
- Istio&#039;s Mixer: Policy Enforcement with Custom Adapters @ CloudNativeCon US 2017: [video](https://www.youtube.com/watch?v=czZLXUqzd24), [slides](https://www.slideshare.net/TorinSandall/istios-mixer-policy-enforcement-with-custom-adapters-cloud-nativecon-17)

## Security

A third party security audit was performed by Cure53, you can see the full report [here](SECURITY_AUDIT.pdf).

Please report vulnerabilities by email to [open-policy-agent-security](mailto:open-policy-agent-security@googlegroups.com).
We will send a confirmation message to acknowledge that we have received the
report and then we will send additional messages to follow up once the issue
has been investigated.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[containers/buildah]]></title>
            <link>https://github.com/containers/buildah</link>
            <guid>https://github.com/containers/buildah</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:34 GMT</pubDate>
            <description><![CDATA[A tool that facilitates building OCI images.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/containers/buildah">containers/buildah</a></h1>
            <p>A tool that facilitates building OCI images.</p>
            <p>Language: Go</p>
            <p>Stars: 8,538</p>
            <p>Forks: 869</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>![buildah logo (light)](logos/buildah-logo_large.png#gh-light-mode-only)
![buildah logo (dark)](logos/buildah-logo_reverse_large.png#gh-dark-mode-only)

# [Buildah](https://www.youtube.com/embed/YVk5NgSiUw8) - a tool that facilitates building [Open Container Initiative (OCI)](https://www.opencontainers.org/) container images

[![Go Report Card](https://goreportcard.com/badge/github.com/containers/buildah)](https://goreportcard.com/report/github.com/containers/buildah)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10579/badge)](https://www.bestpractices.dev/projects/10579)


The Buildah package provides a command line tool that can be used to
* create a working container, either from scratch or using an image as a starting point
* create an image, either from a working container or via the instructions in a Dockerfile
* images can be built in either the OCI image format or the traditional upstream docker image format
* mount a working container&#039;s root filesystem for manipulation
* unmount a working container&#039;s root filesystem
* use the updated contents of a container&#039;s root filesystem as a filesystem layer to create a new image
* delete a working container or an image
* rename a local container

## Buildah Information for Developers

For blogs, release announcements and more, please checkout the [buildah.io](https://buildah.io) website!

**[Buildah Container Images](https://github.com/containers/image_build/blob/main/buildah/README.md)**

**[Buildah Demos](demos)**

**[Changelog](CHANGELOG.md)**

**[Contributing](CONTRIBUTING.md)**

**[Development Plan](developmentplan.md)**

**[Installation notes](install.md)**

**[Troubleshooting Guide](troubleshooting.md)**

**[Tutorials](docs/tutorials)**

## Buildah and Podman relationship

Buildah and Podman are two complementary open-source projects that are
available on most Linux platforms and both projects reside at
[GitHub.com](https://github.com) with Buildah
[here](https://github.com/containers/buildah) and Podman
[here](https://github.com/containers/podman).  Both, Buildah and Podman are
command line tools that work on Open Container Initiative (OCI) images and
containers.  The two projects differentiate in their specialization.

Buildah specializes in building OCI images.  Buildah&#039;s commands replicate all
of the commands that are found in a Dockerfile.  This allows building images
with and without Dockerfiles while not requiring any root privileges.
Buildah‚Äôs ultimate goal is to provide a lower-level coreutils interface to
build images.  The flexibility of building images without Dockerfiles allows
for the integration of other scripting languages into the build process.
Buildah follows a simple fork-exec model and does not run as a daemon
but it is based on a comprehensive API in golang, which can be vendored
into other tools.

Podman specializes in all of the commands and functions that help you to maintain and modify
OCI images, such as pulling and tagging.  It also allows you to create, run, and maintain those containers
created from those images.  For building container images via Dockerfiles, Podman uses Buildah&#039;s
golang API and can be installed independently from Buildah.

A major difference between Podman and Buildah is their concept of a container.  Podman
allows users to create &quot;traditional containers&quot; where the intent of these containers is
to be long lived.  While Buildah containers are really just created to allow content
to be added back to the container image.  An easy way to think of it is the
`buildah run` command emulates the RUN command in a Dockerfile while the `podman run`
command emulates the `docker run` command in functionality.  Because of this and their underlying
storage differences, you can not see Podman containers from within Buildah or vice versa.

In short, Buildah is an efficient way to create OCI images while Podman allows
you to manage and maintain those images and containers in a production environment using
familiar container cli commands.  For more details, see the
[Container Tools Guide](https://github.com/containers/buildah/tree/main/docs/containertools).

## Example

From [`./examples/lighttpd.sh`](examples/lighttpd.sh):

```bash
$ cat &gt; lighttpd.sh &lt;&lt;&quot;EOF&quot;
#!/usr/bin/env bash

set -x

ctr1=$(buildah from &quot;${1:-fedora}&quot;)

## Get all updates and install our minimal httpd server
buildah run &quot;$ctr1&quot; -- dnf update -y
buildah run &quot;$ctr1&quot; -- dnf install -y lighttpd

## Include some buildtime annotations
buildah config --annotation &quot;com.example.build.host=$(uname -n)&quot; &quot;$ctr1&quot;

## Run our server and expose the port
buildah config --cmd &quot;/usr/sbin/lighttpd -D -f /etc/lighttpd/lighttpd.conf&quot; &quot;$ctr1&quot;
buildah config --port 80 &quot;$ctr1&quot;

## Commit this container to an image name
buildah commit &quot;$ctr1&quot; &quot;${2:-$USER/lighttpd}&quot;
EOF

$ chmod +x lighttpd.sh
$ ./lighttpd.sh
```

## Commands
| Command                                              | Description                                                                                          |
| ---------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |
| [buildah-add(1)](/docs/buildah-add.1.md)               | Add the contents of a file, URL, or a directory to the container.                                    |
| [buildah-build(1)](/docs/buildah-build.1.md)           | Build an image using instructions from Containerfiles or Dockerfiles.                                |
| [buildah-commit(1)](/docs/buildah-commit.1.md)         | Create an image from a working container.                                                            |
| [buildah-config(1)](/docs/buildah-config.1.md)         | Update image configuration settings.                                                                 |
| [buildah-containers(1)](/docs/buildah-containers.1.md) | List the working containers and their base images.                                                   |
| [buildah-copy(1)](/docs/buildah-copy.1.md)             | Copies the contents of a file, URL, or directory into a container&#039;s working directory.               |
| [buildah-from(1)](/docs/buildah-from.1.md)             | Creates a new working container, either from scratch or using a specified image as a starting point. |
| [buildah-images(1)](/docs/buildah-images.1.md)         | List images in local storage.                                                                        |
| [buildah-info(1)](/docs/buildah-info.1.md)             | Display Buildah system information.                                                                  |
| [buildah-inspect(1)](/docs/buildah-inspect.1.md)       | Inspects the configuration of a container or image.                                                  |
| [buildah-mount(1)](/docs/buildah-mount.1.md)           | Mount the working container&#039;s root filesystem.                                                       |
| [buildah-pull(1)](/docs/buildah-pull.1.md)             | Pull an image from the specified location.                                                           |
| [buildah-push(1)](/docs/buildah-push.1.md)             | Push an image from local storage to elsewhere.                                                       |
| [buildah-rename(1)](/docs/buildah-rename.1.md)         | Rename a local container.                                                                            |
| [buildah-rm(1)](/docs/buildah-rm.1.md)                 | Removes one or more working containers.                                                              |
| [buildah-rmi(1)](/docs/buildah-rmi.1.md)               | Removes one or more images.                                                                          |
| [buildah-run(1)](/docs/buildah-run.1.md)               | Run a command inside of the container.                                                               |
| [buildah-tag(1)](/docs/buildah-tag.1.md)               | Add an additional name to a local image.                                                             |
| [buildah-umount(1)](/docs/buildah-umount.1.md)         | Unmount a working container&#039;s root file system.                                                      |
| [buildah-unshare(1)](/docs/buildah-unshare.1.md)       | Launch a command in a user namespace with modified ID mappings.                                      |
| [buildah-version(1)](/docs/buildah-version.1.md)       | Display the Buildah Version Information                                                              |

**Future goals include:**
* more CI tests
* additional CLI commands (?)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-go-contrib]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-go-contrib</link>
            <guid>https://github.com/open-telemetry/opentelemetry-go-contrib</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:33 GMT</pubDate>
            <description><![CDATA[Collection of extensions for OpenTelemetry-Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-go-contrib">open-telemetry/opentelemetry-go-contrib</a></h1>
            <p>Collection of extensions for OpenTelemetry-Go.</p>
            <p>Language: Go</p>
            <p>Stars: 1,578</p>
            <p>Forks: 727</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># OpenTelemetry-Go Contrib

[![build_and_test](https://github.com/open-telemetry/opentelemetry-go-contrib/workflows/build_and_test/badge.svg)](https://github.com/open-telemetry/opentelemetry-go-contrib/actions?query=workflow%3Abuild_and_test+branch%3Amain)
[![codecov.io](https://codecov.io/gh/open-telemetry/opentelemetry-go-contrib/coverage.svg?branch=main)](https://app.codecov.io/gh/open-telemetry/opentelemetry-go-contrib?branch=main)
[![Docs](https://godoc.org/go.opentelemetry.io/contrib?status.svg)](https://pkg.go.dev/go.opentelemetry.io/contrib)
[![Go Report Card](https://goreportcard.com/badge/go.opentelemetry.io/contrib)](https://goreportcard.com/report/go.opentelemetry.io/contrib)
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry-go-contrib.svg)](https://issues.oss-fuzz.com/issues?q=project:opentelemetry-go-contrib)
[![Slack](https://img.shields.io/badge/slack-@cncf/otel--go-brightgreen.svg?logo=slack)](https://cloud-native.slack.com/archives/C01NPAXACKT)

Collection of 3rd-party packages for [OpenTelemetry-Go](https://github.com/open-telemetry/opentelemetry-go).

## Contents

- [Examples](./examples/): Examples of OpenTelemetry libraries usage.
- [Instrumentation](./instrumentation/): Packages providing OpenTelemetry instrumentation for 3rd-party libraries.
- [Propagators](./propagators/): Packages providing OpenTelemetry context propagators for 3rd-party propagation formats.
- [Detectors](./detectors/): Packages providing OpenTelemetry resource detectors for 3rd-party cloud computing environments.
- [Exporters](./exporters/): Packages providing OpenTelemetry exporters for 3rd-party export formats.
- [Samplers](./samplers/): Packages providing additional implementations of OpenTelemetry samplers.
- [Bridges](./bridges/): Packages providing adapters for 3rd-party instrumentation frameworks.
- [Processors](./processors/): Packages providing additional implementations of OpenTelemetry processors.

## Project Status

This project contains both stable and unstable modules.
Refer to the module for its version or our [versioning manifest](./versions.yaml).

Project versioning information and stability guarantees can be found in the [versioning documentation](https://github.com/open-telemetry/opentelemetry-go/blob/a724cf884287e04785eaa91513d26a6ef9699288/VERSIONING.md).

Progress and status specific to this repository is tracked in our local [project boards](https://github.com/open-telemetry/opentelemetry-go-contrib/projects?query=is%3Aopen) and [milestones](https://github.com/open-telemetry/opentelemetry-go-contrib/milestones).

### Compatibility

OpenTelemetry-Go Contrib ensures compatibility with the current supported
versions of
the [Go language](https://golang.org/doc/devel/release#policy):

&gt; Each major Go release is supported until there are two newer major releases.
&gt; For example, Go 1.5 was supported until the Go 1.7 release, and Go 1.6 was supported until the Go 1.8 release.

For versions of Go that are no longer supported upstream, opentelemetry-go-contrib will
stop ensuring compatibility with these versions in the following manner:

- A minor release of opentelemetry-go-contrib will be made to add support for the new
  supported release of Go.
- The following minor release of opentelemetry-go-contrib will remove compatibility
  testing for the oldest (now archived upstream) version of Go. This, and
  future, releases of opentelemetry-go-contrib may include features only supported by
  the currently supported versions of Go.

This project is tested on the following systems.

| OS       | Go Version | Architecture |
| -------- | ---------- | ------------ |
| Ubuntu   | 1.25       | amd64        |
| Ubuntu   | 1.24       | amd64        |
| Ubuntu   | 1.25       | 386          |
| Ubuntu   | 1.24       | 386          |
| macOS    | 1.25       | amd64        |
| macOS    | 1.24       | amd64        |
| macOS    | 1.25       | arm64        |
| macOS    | 1.24       | arm64        |
| Windows  | 1.25       | amd64        |
| Windows  | 1.24       | amd64        |
| Windows  | 1.25       | 386          |
| Windows  | 1.24       | 386          |

While this project should work for other systems, no compatibility guarantees
are made for those systems currently.

## Contributing

For information on how to contribute, consult [the contributing guidelines](./CONTRIBUTING.md)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[golang-migrate/migrate]]></title>
            <link>https://github.com/golang-migrate/migrate</link>
            <guid>https://github.com/golang-migrate/migrate</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:32 GMT</pubDate>
            <description><![CDATA[Database migrations. CLI and Golang library.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/golang-migrate/migrate">golang-migrate/migrate</a></h1>
            <p>Database migrations. CLI and Golang library.</p>
            <p>Language: Go</p>
            <p>Stars: 17,949</p>
            <p>Forks: 1,541</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>[![GitHub Workflow Status (branch)](https://img.shields.io/github/actions/workflow/status/golang-migrate/migrate/ci.yaml?branch=master)](https://github.com/golang-migrate/migrate/actions/workflows/ci.yaml?query=branch%3Amaster)
[![GoDoc](https://pkg.go.dev/badge/github.com/golang-migrate/migrate)](https://pkg.go.dev/github.com/golang-migrate/migrate/v4)
[![Coverage Status](https://img.shields.io/coveralls/github/golang-migrate/migrate/master.svg)](https://coveralls.io/github/golang-migrate/migrate?branch=master)
[![packagecloud.io](https://img.shields.io/badge/deb-packagecloud.io-844fec.svg)](https://packagecloud.io/golang-migrate/migrate?filter=debs)
[![Docker Pulls](https://img.shields.io/docker/pulls/migrate/migrate.svg)](https://hub.docker.com/r/migrate/migrate/)
![Supported Go Versions](https://img.shields.io/badge/Go-1.24%2C%201.25-lightgrey.svg)
[![GitHub Release](https://img.shields.io/github/release/golang-migrate/migrate.svg)](https://github.com/golang-migrate/migrate/releases)
[![Go Report Card](https://goreportcard.com/badge/github.com/golang-migrate/migrate/v4)](https://goreportcard.com/report/github.com/golang-migrate/migrate/v4)

# migrate

__Database migrations written in Go. Use as [CLI](#cli-usage) or import as [library](#use-in-your-go-project).__

* Migrate reads migrations from [sources](#migration-sources)
   and applies them in correct order to a [database](#databases).
* Drivers are &quot;dumb&quot;, migrate glues everything together and makes sure the logic is bulletproof.
   (Keeps the drivers lightweight, too.)
* Database drivers don&#039;t assume things or try to correct user input. When in doubt, fail.

Forked from [mattes/migrate](https://github.com/mattes/migrate)

## Databases

Database drivers run migrations. [Add a new database?](database/driver.go)

* [PostgreSQL](database/postgres)
* [PGX v4](database/pgx)
* [PGX v5](database/pgx/v5)
* [Redshift](database/redshift)
* [Ql](database/ql)
* [Cassandra / ScyllaDB](database/cassandra)
* [SQLite](database/sqlite)
* [SQLite3](database/sqlite3) ([todo #165](https://github.com/mattes/migrate/issues/165))
* [SQLCipher](database/sqlcipher)
* [MySQL / MariaDB](database/mysql)
* [Neo4j](database/neo4j)
* [MongoDB](database/mongodb)
* [CrateDB](database/crate) ([todo #170](https://github.com/mattes/migrate/issues/170))
* [Shell](database/shell) ([todo #171](https://github.com/mattes/migrate/issues/171))
* [Google Cloud Spanner](database/spanner)
* [CockroachDB](database/cockroachdb)
* [YugabyteDB](database/yugabytedb)
* [ClickHouse](database/clickhouse)
* [Firebird](database/firebird)
* [MS SQL Server](database/sqlserver)
* [rqlite](database/rqlite)

### Database URLs

Database connection strings are specified via URLs. The URL format is driver dependent but generally has the form: `dbdriver://username:password@host:port/dbname?param1=true&amp;param2=false`

Any [reserved URL characters](https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_reserved_characters) need to be escaped. Note, the `%` character also [needs to be escaped](https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_the_percent_character)

Explicitly, the following characters need to be escaped:
`!`, `#`, `$`, `%`, `&amp;`, `&#039;`, `(`, `)`, `*`, `+`, `,`, `/`, `:`, `;`, `=`, `?`, `@`, `[`, `]`

It&#039;s easiest to always run the URL parts of your DB connection URL (e.g. username, password, etc) through an URL encoder. See the example Python snippets below:

```bash
$ python3 -c &#039;import urllib.parse; print(urllib.parse.quote(input(&quot;String to encode: &quot;), &quot;&quot;))&#039;
String to encode: FAKEpassword!#$%&amp;&#039;()*+,/:;=?@[]
FAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D
$ python2 -c &#039;import urllib; print urllib.quote(raw_input(&quot;String to encode: &quot;), &quot;&quot;)&#039;
String to encode: FAKEpassword!#$%&amp;&#039;()*+,/:;=?@[]
FAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D
$
```

## Migration Sources

Source drivers read migrations from local or remote sources. [Add a new source?](source/driver.go)

* [Filesystem](source/file) - read from filesystem
* [io/fs](source/iofs) - read from a Go [io/fs](https://pkg.go.dev/io/fs#FS)
* [Go-Bindata](source/go_bindata) - read from embedded binary data ([jteeuwen/go-bindata](https://github.com/jteeuwen/go-bindata))
* [pkger](source/pkger) - read from embedded binary data ([markbates/pkger](https://github.com/markbates/pkger))
* [GitHub](source/github) - read from remote GitHub repositories
* [GitHub Enterprise](source/github_ee) - read from remote GitHub Enterprise repositories
* [Bitbucket](source/bitbucket) - read from remote Bitbucket repositories
* [Gitlab](source/gitlab) - read from remote Gitlab repositories
* [AWS S3](source/aws_s3) - read from Amazon Web Services S3
* [Google Cloud Storage](source/google_cloud_storage) - read from Google Cloud Platform Storage

## CLI usage

* Simple wrapper around this library.
* Handles ctrl+c (SIGINT) gracefully.
* No config search paths, no config files, no magic ENV var injections.

[CLI Documentation](cmd/migrate) (includes CLI install instructions)

### Basic usage

```bash
$ migrate -source file://path/to/migrations -database postgres://localhost:5432/database up 2
```

### Docker usage

```bash
$ docker run -v {{ migration dir }}:/migrations --network host migrate/migrate
    -path=/migrations/ -database postgres://localhost:5432/database up 2
```

## Use in your Go project

* API is stable and frozen for this release (v3 &amp; v4).
* Uses [Go modules](https://golang.org/cmd/go/#hdr-Modules__module_versions__and_more) to manage dependencies.
* To help prevent database corruptions, it supports graceful stops via `GracefulStop chan bool`.
* Bring your own logger.
* Uses `io.Reader` streams internally for low memory overhead.
* Thread-safe and no goroutine leaks.

__[Go Documentation](https://pkg.go.dev/github.com/golang-migrate/migrate/v4)__

```go
import (
    &quot;github.com/golang-migrate/migrate/v4&quot;
    _ &quot;github.com/golang-migrate/migrate/v4/database/postgres&quot;
    _ &quot;github.com/golang-migrate/migrate/v4/source/github&quot;
)

func main() {
    m, err := migrate.New(
        &quot;github://mattes:personal-access-token@mattes/migrate_test&quot;,
        &quot;postgres://localhost:5432/database?sslmode=enable&quot;)
    m.Steps(2)
}
```

Want to use an existing database client?

```go
import (
    &quot;database/sql&quot;
    _ &quot;github.com/lib/pq&quot;
    &quot;github.com/golang-migrate/migrate/v4&quot;
    &quot;github.com/golang-migrate/migrate/v4/database/postgres&quot;
    _ &quot;github.com/golang-migrate/migrate/v4/source/file&quot;
)

func main() {
    db, err := sql.Open(&quot;postgres&quot;, &quot;postgres://localhost:5432/database?sslmode=enable&quot;)
    driver, err := postgres.WithInstance(db, &amp;postgres.Config{})
    m, err := migrate.NewWithDatabaseInstance(
        &quot;file:///migrations&quot;,
        &quot;postgres&quot;, driver)
    m.Up() // or m.Steps(2) if you want to explicitly set the number of migrations to run
}
```

## Getting started

Go to [getting started](GETTING_STARTED.md)

## Tutorials

* [CockroachDB](database/cockroachdb/TUTORIAL.md)
* [PostgreSQL](database/postgres/TUTORIAL.md)

(more tutorials to come)

## Migration files

Each migration has an up and down migration. [Why?](FAQ.md#why-two-separate-files-up-and-down-for-a-migration)

```bash
1481574547_create_users_table.up.sql
1481574547_create_users_table.down.sql
```

[Best practices: How to write migrations.](MIGRATIONS.md)

## Coming from another db migration tool?

Check out [migradaptor](https://github.com/musinit/migradaptor/).
*Note: migradaptor is not affiliated or supported by this project*

## Versions

Version | Supported? | Import | Notes
--------|------------|--------|------
**master** | :white_check_mark: | `import &quot;github.com/golang-migrate/migrate/v4&quot;` | New features and bug fixes arrive here first |
**v4** | :white_check_mark: | `import &quot;github.com/golang-migrate/migrate/v4&quot;` | Used for stable releases |
**v3** | :x: | `import &quot;github.com/golang-migrate/migrate&quot;` (with package manager) or `import &quot;gopkg.in/golang-migrate/migrate.v3&quot;` (not recommended) | **DO NOT USE** - No longer supported |

## Development and Contributing

Yes, please! [`Makefile`](Makefile) is your friend,
read the [development guide](CONTRIBUTING.md).

Also have a look at the [FAQ](FAQ.md).

---

Looking for alternatives? [https://awesome-go.com/#database](https://awesome-go.com/#database).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[abiosoft/colima]]></title>
            <link>https://github.com/abiosoft/colima</link>
            <guid>https://github.com/abiosoft/colima</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:31 GMT</pubDate>
            <description><![CDATA[Container runtimes on macOS (and Linux) with minimal setup]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/abiosoft/colima">abiosoft/colima</a></h1>
            <p>Container runtimes on macOS (and Linux) with minimal setup</p>
            <p>Language: Go</p>
            <p>Stars: 26,284</p>
            <p>Forks: 514</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>![colima-logo](colima.png)

## Colima - container runtimes on macOS (and Linux) with minimal setup.

[![Go](https://github.com/abiosoft/colima/actions/workflows/go.yml/badge.svg)](https://github.com/abiosoft/colima/actions/workflows/go.yml)
[![Integration](https://github.com/abiosoft/colima/actions/workflows/integration.yml/badge.svg)](https://github.com/abiosoft/colima/actions/workflows/integration.yml)
[![Go Report Card](https://goreportcard.com/badge/github.com/abiosoft/colima)](https://goreportcard.com/report/github.com/abiosoft/colima)

![Demonstration](colima.gif)

## Features

Support for Intel and Apple Silicon macOS, and Linux

- Simple CLI interface with sensible defaults
- Automatic Port Forwarding
- Volume mounts
- Multiple instances
- Support for multiple container runtimes
  - [Docker](https://docker.com) (with optional Kubernetes)
  - [Containerd](https://containerd.io) (with optional Kubernetes)
  - [Incus](https://linuxcontainers.org/incus) (containers and virtual machines)

## Getting Started

### Installation

Colima is available on Homebrew, MacPorts, Nix and [mise](http://github.com/jdx/mise). Check [here](docs/INSTALL.md) for other installation options.

```
# Homebrew
brew install colima

# MacPorts
sudo port install colima

# Nix
nix-env -iA nixpkgs.colima

# Mise
mise use -g colima@latest

```

Or stay on the bleeding edge (only Homebrew)

```
brew install --HEAD colima
```

### Upgrading

If upgrading from v0.5.6 or lower, it is required to start afresh by deleting existing instance.

```sh
colima delete # delete existing instance
colima start
```

## Usage

Start Colima with defaults

```
colima start
```

For more usage options

```
colima --help
colima start --help
```

Or use a config file

```
colima start --edit
```

## Using Templates
When you run the `colima template` command, Colima opens the default configuration in a temporary file using your editor (VS Code by default, if installed).

For example, you might see something like:
```sh
/var/folders/hm/xmq4vxs13dl2hx2jyct65r080000gn/T/colima-2758922589.yaml

```
You can edit this temporary file as needed. Once you save and close the file in the editor, Colima automatically overwrites the default template config located at:
```sh
~/.colima/_templates/default.yaml

```
To see more options for working with templates, run:
```
colima template --help

```

## Runtimes

On initial startup, Colima initiates with a user specified runtime that defaults to Docker.

### Docker

Docker client is required for Docker runtime. Installable with brew `brew install docker`.

You can use the `docker` client on macOS after `colima start` with no additional setup.

### Containerd

`colima start --runtime containerd` starts and setup Containerd. You can use `colima nerdctl` to interact with
Containerd using [nerdctl](https://github.com/containerd/nerdctl).

It is recommended to run `colima nerdctl install` to install `nerdctl` alias script in $PATH.

### Kubernetes

kubectl is required for Kubernetes. Installable with `brew install kubectl`.

To enable Kubernetes, start Colima with `--kubernetes` flag.

```
colima start --kubernetes
```

#### Interacting with Image Registry

For Docker runtime, images built or pulled with Docker are accessible to Kubernetes.

For Containerd runtime, images built or pulled in the `k8s.io` namespace are accessible to Kubernetes.

### Incus

&lt;small&gt;**Requires v0.7.0**&lt;/small&gt;


Incus client is required for Incus runtime. Installable with brew `brew install incus`.

`colima start --runtime incus` starts and setup Incus.

You can use the `incus` client on macOS after `colima start` with no additional setup.

**Note:** Running virtual machines on Incus is only supported on m3 or newer Apple Silicon devices.

### None

&lt;small&gt;**Requires v0.7.0**&lt;/small&gt;

Colima can also be utilised solely as a headless virtual machine manager by specifying `none` runtime.


### Customizing the VM

The default VM created by Colima has 2 CPUs, 2GiB memory and 100GiB storage.

The VM can be customized either by passing additional flags to `colima start`.
e.g. `--cpu`, `--memory`, `--disk`, `--runtime`.
Or by editing the config file with `colima start --edit`.

**NOTE**: ~~disk size cannot be changed after the VM is created.~~ From v0.5.3, disk size can be increased.

#### Customization Examples

- create VM with 1CPU, 2GiB memory and 10GiB storage.

  ```
  colima start --cpu 1 --memory 2 --disk 10
  ```

- modify an existing VM to 4CPUs and 8GiB memory.

  ```
  colima stop
  colima start --cpu 4 --memory 8
  ```

- create VM with Rosetta 2 emulation. Requires v0.5.3 and macOS &gt;= 13 (Ventura) on Apple Silicon.

  ```
  colima start --vm-type=vz --vz-rosetta
  ```

## Project Goal

To provide container runtimes on macOS with minimal setup.

## What is with the name?

Colima means Containers on [Lima](https://github.com/lima-vm/lima).

Since Lima is aka Linux Machines. By transitivity, Colima can also mean Containers on Linux Machines.

## And the Logo?

The logo was contributed by [Daniel Hodvogner](https://github.com/dhodvogner). Check [this issue](https://github.com/abiosoft/colima/issues/781) for more.

## Troubleshooting and FAQs

Check [here](docs/FAQ.md) for Frequently Asked Questions.

## How to Contribute?

Check [here](docs/CONTRIBUTE.md) for the instructions on contributing to the project.

## Community
- [GitHub Discussions](https://github.com/abiosoft/colima/discussions)
- [GitHub Issues](https://github.com/abiosoft/colima/issues)
- `#colima` channel in the CNCF Slack
  - New account: &lt;https://slack.cncf.io/&gt;
  - Login: &lt;https://cloud-native.slack.com/&gt;

## Help Wanted

- Documentation and project website

## License

MIT


## Sponsoring the Project

If you (or your company) are benefiting from the project and would like to support the contributors, kindly sponsor.

- [Github Sponsors](https://github.com/sponsors/abiosoft)
- [Buy me a coffee](https://www.buymeacoffee.com/abiosoft)
- [Patreon](https://patreon.com/colima)

---

[&lt;img src=&quot;https://uploads-ssl.webflow.com/5ac3c046c82724970fc60918/5c019d917bba312af7553b49_MacStadium-developerlogo.png&quot; style=&quot;max-height: 150px&quot;/&gt;](https://macstadium.com)


</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[seaweedfs/seaweedfs]]></title>
            <link>https://github.com/seaweedfs/seaweedfs</link>
            <guid>https://github.com/seaweedfs/seaweedfs</guid>
            <pubDate>Thu, 15 Jan 2026 00:05:30 GMT</pubDate>
            <description><![CDATA[SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/seaweedfs/seaweedfs">seaweedfs/seaweedfs</a></h1>
            <p>SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.</p>
            <p>Language: Go</p>
            <p>Stars: 29,529</p>
            <p>Forks: 2,667</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre># SeaweedFS


[![Slack](https://img.shields.io/badge/slack-purple)](https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY)
[![Twitter](https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;label=Follow)](https://twitter.com/intent/follow?screen_name=seaweedfs)
[![Build Status](https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml)](https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml)
[![GoDoc](https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg)](https://godoc.org/github.com/seaweedfs/seaweedfs/weed)
[![Wiki](https://img.shields.io/badge/docs-wiki-blue.svg)](https://github.com/seaweedfs/seaweedfs/wiki)
[![Docker Pulls](https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800)](https://hub.docker.com/r/chrislusf/seaweedfs/)
[![SeaweedFS on Maven Central](https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client)](https://search.maven.org/search?q=g:com.github.chrislusf)
[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs)](https://artifacthub.io/packages/search?repo=seaweedfs)

![SeaweedFS Logo](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png)

&lt;h2 align=&quot;center&quot;&gt;&lt;a href=&quot;https://www.patreon.com/seaweedfs&quot;&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt;

SeaweedFS is an independent Apache-licensed open source project with its ongoing development made
possible entirely thanks to the support of these awesome [backers](https://github.com/seaweedfs/seaweedfs/blob/master/backers.md).
If you&#039;d like to grow SeaweedFS even stronger, please consider joining our
&lt;a href=&quot;https://www.patreon.com/seaweedfs&quot;&gt;sponsors on Patreon&lt;/a&gt;.

Your support will be really appreciated by me and other supporters!

&lt;!--
&lt;h4 align=&quot;center&quot;&gt;Platinum&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;&quot; target=&quot;_blank&quot;&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt;

### Gold Sponsors
[![nodion](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png)](https://www.nodion.com)
[![piknik](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png)](https://www.piknik.com)
[![keepsec](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png)](https://www.keepsec.ca)

---

- [Download Binaries for different platforms](https://github.com/seaweedfs/seaweedfs/releases/latest)
- [SeaweedFS on Slack](https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY)
- [SeaweedFS on Twitter](https://twitter.com/SeaweedFS)
- [SeaweedFS on Telegram](https://t.me/Seaweedfs) 
- [SeaweedFS on Reddit](https://www.reddit.com/r/SeaweedFS/)
- [SeaweedFS Mailing List](https://groups.google.com/d/forum/seaweedfs)
- [Wiki Documentation](https://github.com/seaweedfs/seaweedfs/wiki)
- [SeaweedFS White Paper](https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf)
- [SeaweedFS Introduction Slides 2025.5](https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing)
- [SeaweedFS Introduction Slides 2021.5](https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing)
- [SeaweedFS Introduction Slides 2019.3](https://www.slideshare.net/chrislusf/seaweedfs-introduction)

Table of Contents
=================

* [Quick Start](#quick-start)
    * [Quick Start with weed mini](#quick-start-with-weed-mini)
    * [Quick Start for S3 API on Docker](#quick-start-for-s3-api-on-docker)
    * [Quick Start with Single Binary](#quick-start-with-single-binary)
* [Introduction](#introduction)
* [Features](#features)
    * [Additional Features](#additional-features)
    * [Filer Features](#filer-features)
* [Example: Using Seaweed Object Store](#example-using-seaweed-object-store)
* [Architecture](#object-store-architecture)
* [Compared to Other File Systems](#compared-to-other-file-systems)
    * [Compared to HDFS](#compared-to-hdfs)
    * [Compared to GlusterFS, Ceph](#compared-to-glusterfs-ceph)
    * [Compared to GlusterFS](#compared-to-glusterfs)
    * [Compared to Ceph](#compared-to-ceph)
    * [Compared to Minio](#compared-to-minio)
* [Dev Plan](#dev-plan)
* [Installation Guide](#installation-guide)
* [Disk Related Topics](#disk-related-topics)
* [Benchmark](#benchmark)
* [Enterprise](#enterprise)
* [License](#license)

# Quick Start #


## Quick Start with weed mini ##
The easiest way to get started with SeaweedFS for development and testing:

* Download the latest binary from https://github.com/seaweedfs/seaweedfs/releases and unzip a single binary file `weed` or `weed.exe`.

Example:

```bash
# remove quarantine on macOS
# xattr -d com.apple.quarantine  ./weed

./weed mini -dir=/data
```

This single command starts a complete SeaweedFS setup with:
- **Master UI**: http://localhost:9333
- **Volume Server**: http://localhost:9340
- **Filer UI**: http://localhost:8888
- **S3 Endpoint**: http://localhost:8333
- **WebDAV**: http://localhost:7333
- **Admin UI**: http://localhost:23646

Perfect for development, testing, learning SeaweedFS, and single node deployments!

## Quick Start for S3 API on Docker ##

`docker run -p 8333:8333 chrislusf/seaweedfs server -s3`

## Quick Start with Single Binary ##
* Download the latest binary from https://github.com/seaweedfs/seaweedfs/releases and unzip a single binary file `weed` or `weed.exe`. Or run `go install github.com/seaweedfs/seaweedfs/weed@latest`.
* `export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key` as the admin credentials to access the object store.
* Run `weed server -dir=/some/data/dir -s3` to start one master, one volume server, one filer, and one S3 gateway. The difference with `weed mini` is that `weed mini` can auto configure based on the single host environment, while `weed server` requires manual configuration and are designed for production use.

Also, to increase capacity, just add more volume servers by running `weed volume -dir=&quot;/some/data/dir2&quot; -master=&quot;&lt;master_host&gt;:9333&quot; -port=8081` locally, or on a different machine, or on thousands of machines. That is it!

# Introduction #

SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:

1. to store billions of files!
2. to serve the files fast!

SeaweedFS started as a blob store to handle small files efficiently. 
Instead of managing all file metadata in a central master, 
the central master only manages volumes on volume servers, 
and these volume servers manage files and their metadata. 
This relieves concurrency pressure from the central master and spreads file metadata into volume servers, 
allowing faster file access (O(1), usually just one disk read operation).

There is only 40 bytes of disk storage overhead for each file&#039;s metadata. 
It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.

SeaweedFS started by implementing [Facebook&#039;s Haystack design paper](http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf). 
Also, SeaweedFS implements erasure coding with ideas from 
[f4: Facebook‚Äôs Warm BLOB Storage System](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf), and has a lot of similarities with [Facebook‚Äôs Tectonic Filesystem](https://www.usenix.org/system/files/fast21-pan.pdf) and [Google&#039;s Colossus File System](https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system)

On top of the blob store, optional [Filer] can support directories and POSIX attributes. 
Filer is a separate linearly-scalable stateless server with customizable metadata stores, 
e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.

SeaweedFS can transparently integrate with the cloud. 
With hot data on local cluster, and warm data on the cloud with O(1) access time, 
SeaweedFS can achieve both fast local access time and elastic cloud storage capacity.
What&#039;s more, the cloud storage access API cost is minimized. 
Faster and cheaper than direct cloud storage!

[Back to TOC](#table-of-contents)

# Features #
## Additional Blob Store Features ##
* Support different replication levels, with rack and data center aware.
* Automatic master servers failover - no single point of failure (SPOF).
* Automatic compression depending on file MIME type.
* Automatic compaction to reclaim disk space after deletion or update.
* [Automatic entry TTL expiration][VolumeServerTTL].
* Flexible Capacity Expansion: Any server with some disk space can add to the total storage space.
* Adding/Removing servers does **not** cause any data re-balancing unless triggered by admin commands.
* Optional picture resizing.
* Support ETag, Accept-Range, Last-Modified, etc.
* Support in-memory/leveldb/readonly mode tuning for memory/performance balance.
* Support rebalancing the writable and readonly volumes.
* [Customizable Multiple Storage Tiers][TieredStorage]: Customizable storage disk types to balance performance and cost.
* [Transparent cloud integration][CloudTier]: unlimited capacity via tiered cloud storage for warm data.
* [Erasure Coding for warm storage][ErasureCoding]  Rack-Aware 10.4 erasure coding reduces storage cost and increases availability. Enterprise version can customize EC ratio.

[Back to TOC](#table-of-contents)

## Filer Features ##
* [Filer server][Filer] provides &quot;normal&quot; directories and files via HTTP.
* [File TTL][FilerTTL] automatically expires file metadata and actual file data.
* [Mount filer][Mount] reads and writes files directly as a local directory via FUSE.
* [Filer Store Replication][FilerStoreReplication] enables HA for filer meta data stores.
* [Active-Active Replication][ActiveActiveAsyncReplication] enables asynchronous one-way or two-way cross cluster continuous replication.
* [Amazon S3 compatible API][AmazonS3API] accesses files with S3 tooling.
* [Hadoop Compatible File System][Hadoop] accesses files from Hadoop/Spark/Flink/etc or even runs HBase.
* [Async Replication To Cloud][BackupToCloud] has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.
* [WebDAV] accesses as a mapped drive on Mac and Windows, or from mobile devices.
* [AES256-GCM Encrypted Storage][FilerDataEncryption] safely stores the encrypted data.
* [Super Large Files][SuperLargeFiles] stores large or super large files in tens of TB.
* [Cloud Drive][CloudDrive] mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.
* [Gateway to Remote Object Store][GatewayToRemoteObjectStore] mirrors bucket operations to remote object storage, in addition to [Cloud Drive][CloudDrive]

## Kubernetes ##
* [Kubernetes CSI Driver][SeaweedFsCsiDriver] A Container Storage Interface (CSI) Driver. [![Docker Pulls](https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800)](https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/)
* [SeaweedFS Operator](https://github.com/seaweedfs/seaweedfs-operator)

[Filer]: https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files
[SuperLargeFiles]: https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files
[Mount]: https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount
[AmazonS3API]: https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API
[BackupToCloud]: https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud
[Hadoop]: https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System
[WebDAV]: https://github.com/seaweedfs/seaweedfs/wiki/WebDAV
[ErasureCoding]: https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage
[TieredStorage]: https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage
[CloudTier]: https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier
[FilerDataEncryption]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption
[FilerTTL]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores
[VolumeServerTTL]: https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live
[SeaweedFsCsiDriver]: https://github.com/seaweedfs/seaweedfs-csi-driver
[ActiveActiveAsyncReplication]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization
[FilerStoreReplication]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication
[KeyLargeValueStore]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store
[CloudDrive]: https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture
[GatewayToRemoteObjectStore]: https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage


[Back to TOC](#table-of-contents)

## Example: Using Seaweed Blob Store ##

By default, the master node runs on port 9333, and the volume nodes run on port 8080.
Let&#039;s start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We&#039;ll use localhost as an example.

SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.

### Start Master Server ###

```
&gt; ./weed master
```

### Start Volume Servers ###

```
&gt; weed volume -dir=&quot;/tmp/data1&quot; -max=5  -master=&quot;localhost:9333&quot; -port=8080 &amp;
&gt; weed volume -dir=&quot;/tmp/data2&quot; -max=10 -master=&quot;localhost:9333&quot; -port=8081 &amp;
```

### Write A Blob ###

A blob, also referred as a needle, a chunk, or mistakenly as a file, is just a byte array. It can have attributes, such as name, mime type, create or update time, etc. But basically it is just a byte array of a relatively small size, such as 2 MB ~ 64 MB. The size is not fixed.

To upload a blob: first, send a HTTP POST, PUT, or GET request to `/dir/assign` to get an `fid` and a volume server URL:

```
&gt; curl http://localhost:9333/dir/assign
{&quot;count&quot;:1,&quot;fid&quot;:&quot;3,01637037d6&quot;,&quot;url&quot;:&quot;127.0.0.1:8080&quot;,&quot;publicUrl&quot;:&quot;localhost:8080&quot;}
```

Second, to store the blob content, send a HTTP multi-part POST request to `url + &#039;/&#039; + fid` from the response:

```
&gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{&quot;name&quot;:&quot;myphoto.jpg&quot;,&quot;size&quot;:43234,&quot;eTag&quot;:&quot;1cc0118e&quot;}
```

To update, send another POST request with updated blob content.

For deletion, send an HTTP DELETE request to the same `url + &#039;/&#039; + fid` URL:

```
&gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
```

### Save Blob Id ###

Now, you can save the `fid`, 3,01637037d6 in this case, to a database field.

The number 3 at the start represents a volume id. After the comma, it&#039;s one file key, 01, and a file cookie, 637037d6.

The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.

The file key and file cookie are both coded in hex. You can store the &lt;volume id, file key, file cookie&gt; tuple in your own format, or simply store the `fid` as a string.

If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.

If space is really a concern, you can store the file id in the binary format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.

### Read a Blob ###

Here is an example of how to render the URL.

First look up the volume server&#039;s URLs by the file&#039;s volumeId:

```
&gt; curl http://localhost:9333/dir/lookup?volumeId=3
{&quot;volumeId&quot;:&quot;3&quot;,&quot;locations&quot;:[{&quot;publicUrl&quot;:&quot;localhost:8080&quot;,&quot;url&quot;:&quot;localhost:8080&quot;}]}
```

Since (usually) there are not too many volume servers, and volumes don&#039;t move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.

Now you can take the public URL, render the URL or directly read from the volume server via URL:

```
 http://localhost:8080/3,01637037d6.jpg
```

Notice we add a file extension &quot;.jpg&quot; here. It&#039;s optional and just one way for the client to specify the file content type.

If you want a nicer URL, you can use one of these alternative URL formats:

```
 http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
```

If you want to get a scaled version of an image, you can add some params:

```
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200&amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200&amp;mode=fill
```

### Rack-Aware and Data Center-Aware Replication ###

SeaweedFS applies the replication strategy at a volume level. So, when you are getting a blob id, you can specify the replication strategy. For example:

```
curl http://localhost:9333/dir/assign?replication=001
```

The replication parameter options are:

```
000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
```

More details about replication can be found [on the wiki][Replication].

[Replication]: https://github.com/seaweedfs/seaweedfs/wiki/Replication

You can also set the default replication strategy when starting the master server.

### Allocate Blob Key on Specific Data Center ###

Volume servers can be started with a specific data center name:

```
 weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
```

When requesting a blob key, an optional &quot;dataCenter&quot; parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to &#039;dc1&#039;:

```
 http://localhost:9333/dir/assign?dataCenter=dc1
```

### Other Features ###
  * [No Single Point of Failure][feat-1]
  * [Insert with your own keys][feat-2]
  * [Chunking large files][feat-3]
  * [Collection as a Simple Name Space][feat-4]

[feat-1]: https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server
[feat-2]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys
[feat-3]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files
[feat-4]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space

[Back to TOC](#table-of-contents)

## Blob Store Architecture ##

Usually distributed file systems split each file into chunks. A central server keeps a mapping of filenames to chunks, and also which chunks each chunk server has.

The main drawback is that the central server can&#039;t handle many small files efficiently, and since all read requests need to go through the central master, so it might not scale well for many concurrent users.

Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of blobs. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.

The actual blob metadata, which are the blob volume, offset, and size, is stored in each volume on volume servers. Since each volume server only manages metadata of blobs on its own disk, with only 16 bytes for each blob, all access can read the metadata just from memory and only needs one disk operation to actually read file data.

For comparison, consider that an xfs inode structure in Linux is 536 bytes.



... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>