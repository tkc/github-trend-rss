<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Tue, 16 Sep 2025 00:05:30 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[sst/opencode]]></title>
            <link>https://github.com/sst/opencode</link>
            <guid>https://github.com/sst/opencode</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[AI coding agent, built for the terminal.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sst/opencode">sst/opencode</a></h1>
            <p>AI coding agent, built for the terminal.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 23,428</p>
            <p>Forks: 1,625</p>
            <p>Stars today: 189 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencode.ai&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;packages/web/src/assets/logo-ornate-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;packages/web/src/assets/logo-ornate-light.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;packages/web/src/assets/logo-ornate-light.svg&quot; alt=&quot;opencode logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;AI coding agent, built for the terminal.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencode.ai/discord&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;label=discord&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/opencode-ai&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/opencode-ai?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/sst/opencode/actions/workflows/publish.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/sst/opencode/publish.yml?style=flat-square&amp;branch=dev&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

[![opencode Terminal UI](packages/web/src/assets/lander/screenshot.png)](https://opencode.ai)

---

### Installation

```bash
# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
brew install sst/tap/opencode      # macOS and Linux
paru -S opencode-bin               # Arch Linux
```

&gt; [!TIP]
&gt; Remove versions older than 0.1.x before installing.

#### Installation Directory

The install script respects the following priority order for the installation path:

1. `$OPENCODE_INSTALL_DIR` - Custom installation directory
2. `$XDG_BIN_DIR` - XDG Base Directory Specification compliant path
3. `$HOME/bin` - Standard user binary directory (if exists or can be created)
4. `$HOME/.opencode/bin` - Default fallback

```bash
# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
```

### Documentation

For more info on how to configure opencode [**head over to our docs**](https://opencode.ai/docs).

### Contributing

opencode is an opinionated tool so any fundamental feature needs to go through a
design process with the core team.

&gt; [!IMPORTANT]
&gt; We do not accept PRs for core features.

However we still merge a ton of PRs - you can contribute:

- Bug fixes
- Improvements to LLM performance
- Support for new providers
- Fixes for env specific quirks
- Missing standard behavior
- Documentation

Take a look at the git history to see what kind of PRs we end up merging.

&gt; [!NOTE]
&gt; If you do not follow the above guidelines we might close your PR.

To run opencode locally you need.

- Bun
- Golang 1.24.x

And run.

```bash
$ bun install
$ bun dev
```

#### Development Notes

**API Client**: After making changes to the TypeScript API endpoints in `packages/opencode/src/server/server.ts`, you will need the opencode team to generate a new stainless sdk for the clients.

### FAQ

#### How is this different than Claude Code?

It&#039;s very similar to Claude Code in terms of capability. Here are the key differences:

- 100% open source
- Not coupled to any provider. Although Anthropic is recommended, opencode can be used with OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.
- A focus on TUI. opencode is built by neovim users and the creators of [terminal.shop](https://terminal.shop); we are going to push the limits of what&#039;s possible in the terminal.
- A client/server architecture. This for example can allow opencode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.

#### What&#039;s the other repo?

The other confusingly named repo has no relation to this one. You can [read the story behind it here](https://x.com/thdxr/status/1933561254481666466).

---

**Join our community** [Discord](https://discord.gg/opencode) | [X.com](https://x.com/opencode)
</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[lharries/whatsapp-mcp]]></title>
            <link>https://github.com/lharries/whatsapp-mcp</link>
            <guid>https://github.com/lharries/whatsapp-mcp</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[WhatsApp MCP server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lharries/whatsapp-mcp">lharries/whatsapp-mcp</a></h1>
            <p>WhatsApp MCP server</p>
            <p>Language: Go</p>
            <p>Stars: 4,846</p>
            <p>Forks: 722</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre># WhatsApp MCP Server

This is a Model Context Protocol (MCP) server for WhatsApp.

With this you can search and read your personal Whatsapp messages (including images, videos, documents, and audio messages), search your contacts and send messages to either individuals or groups. You can also send media files including images, videos, documents, and audio messages.

It connects to your **personal WhatsApp account** directly via the Whatsapp web multidevice API (using the [whatsmeow](https://github.com/tulir/whatsmeow) library). All your messages are stored locally in a SQLite database and only sent to an LLM (such as Claude) when the agent accesses them through tools (which you control).

Here&#039;s an example of what you can do when it&#039;s connected to Claude.

![WhatsApp MCP](./example-use.png)

&gt; To get updates on this and other projects I work on [enter your email here](https://docs.google.com/forms/d/1rTF9wMBTN0vPfzWuQa2BjfGKdKIpTbyeKxhPMcEzgyI/preview)

&gt; *Caution:* as with many MCP servers, the WhatsApp MCP is subject to [the lethal trifecta](https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/). This means that project injection could lead to private data exfiltration.

## Installation

### Prerequisites

- Go
- Python 3.6+
- Anthropic Claude Desktop app (or Cursor)
- UV (Python package manager), install with `curl -LsSf https://astral.sh/uv/install.sh | sh`
- FFmpeg (_optional_) - Only needed for audio messages. If you want to send audio files as playable WhatsApp voice messages, they must be in `.ogg` Opus format. With FFmpeg installed, the MCP server will automatically convert non-Opus audio files. Without FFmpeg, you can still send raw audio files using the `send_file` tool.

### Steps

1. **Clone this repository**

   ```bash
   git clone https://github.com/lharries/whatsapp-mcp.git
   cd whatsapp-mcp
   ```

2. **Run the WhatsApp bridge**

   Navigate to the whatsapp-bridge directory and run the Go application:

   ```bash
   cd whatsapp-bridge
   go run main.go
   ```

   The first time you run it, you will be prompted to scan a QR code. Scan the QR code with your WhatsApp mobile app to authenticate.

   After approximately 20 days, you will might need to re-authenticate.

3. **Connect to the MCP server**

   Copy the below json with the appropriate {{PATH}} values:

   ```json
   {
     &quot;mcpServers&quot;: {
       &quot;whatsapp&quot;: {
         &quot;command&quot;: &quot;{{PATH_TO_UV}}&quot;, // Run `which uv` and place the output here
         &quot;args&quot;: [
           &quot;--directory&quot;,
           &quot;{{PATH_TO_SRC}}/whatsapp-mcp/whatsapp-mcp-server&quot;, // cd into the repo, run `pwd` and enter the output here + &quot;/whatsapp-mcp-server&quot;
           &quot;run&quot;,
           &quot;main.py&quot;
         ]
       }
     }
   }
   ```

   For **Claude**, save this as `claude_desktop_config.json` in your Claude Desktop configuration directory at:

   ```
   ~/Library/Application Support/Claude/claude_desktop_config.json
   ```

   For **Cursor**, save this as `mcp.json` in your Cursor configuration directory at:

   ```
   ~/.cursor/mcp.json
   ```

4. **Restart Claude Desktop / Cursor**

   Open Claude Desktop and you should now see WhatsApp as an available integration.

   Or restart Cursor.

### Windows Compatibility

If you&#039;re running this project on Windows, be aware that `go-sqlite3` requires **CGO to be enabled** in order to compile and work properly. By default, **CGO is disabled on Windows**, so you need to explicitly enable it and have a C compiler installed.

#### Steps to get it working:

1. **Install a C compiler**  
   We recommend using [MSYS2](https://www.msys2.org/) to install a C compiler for Windows. After installing MSYS2, make sure to add the `ucrt64\bin` folder to your `PATH`.  
   → A step-by-step guide is available [here](https://code.visualstudio.com/docs/cpp/config-mingw).

2. **Enable CGO and run the app**

   ```bash
   cd whatsapp-bridge
   go env -w CGO_ENABLED=1
   go run main.go
   ```

Without this setup, you&#039;ll likely run into errors like:

&gt; `Binary was compiled with &#039;CGO_ENABLED=0&#039;, go-sqlite3 requires cgo to work.`

## Architecture Overview

This application consists of two main components:

1. **Go WhatsApp Bridge** (`whatsapp-bridge/`): A Go application that connects to WhatsApp&#039;s web API, handles authentication via QR code, and stores message history in SQLite. It serves as the bridge between WhatsApp and the MCP server.

2. **Python MCP Server** (`whatsapp-mcp-server/`): A Python server implementing the Model Context Protocol (MCP), which provides standardized tools for Claude to interact with WhatsApp data and send/receive messages.

### Data Storage

- All message history is stored in a SQLite database within the `whatsapp-bridge/store/` directory
- The database maintains tables for chats and messages
- Messages are indexed for efficient searching and retrieval

## Usage

Once connected, you can interact with your WhatsApp contacts through Claude, leveraging Claude&#039;s AI capabilities in your WhatsApp conversations.

### MCP Tools

Claude can access the following tools to interact with WhatsApp:

- **search_contacts**: Search for contacts by name or phone number
- **list_messages**: Retrieve messages with optional filters and context
- **list_chats**: List available chats with metadata
- **get_chat**: Get information about a specific chat
- **get_direct_chat_by_contact**: Find a direct chat with a specific contact
- **get_contact_chats**: List all chats involving a specific contact
- **get_last_interaction**: Get the most recent message with a contact
- **get_message_context**: Retrieve context around a specific message
- **send_message**: Send a WhatsApp message to a specified phone number or group JID
- **send_file**: Send a file (image, video, raw audio, document) to a specified recipient
- **send_audio_message**: Send an audio file as a WhatsApp voice message (requires the file to be an .ogg opus file or ffmpeg must be installed)
- **download_media**: Download media from a WhatsApp message and get the local file path

### Media Handling Features

The MCP server supports both sending and receiving various media types:

#### Media Sending

You can send various media types to your WhatsApp contacts:

- **Images, Videos, Documents**: Use the `send_file` tool to share any supported media type.
- **Voice Messages**: Use the `send_audio_message` tool to send audio files as playable WhatsApp voice messages.
  - For optimal compatibility, audio files should be in `.ogg` Opus format.
  - With FFmpeg installed, the system will automatically convert other audio formats (MP3, WAV, etc.) to the required format.
  - Without FFmpeg, you can still send raw audio files using the `send_file` tool, but they won&#039;t appear as playable voice messages.

#### Media Downloading

By default, just the metadata of the media is stored in the local database. The message will indicate that media was sent. To access this media you need to use the download_media tool which takes the `message_id` and `chat_jid` (which are shown when printing messages containing the meda), this downloads the media and then returns the file path which can be then opened or passed to another tool.

## Technical Details

1. Claude sends requests to the Python MCP server
2. The MCP server queries the Go bridge for WhatsApp data or directly to the SQLite database
3. The Go accesses the WhatsApp API and keeps the SQLite database up to date
4. Data flows back through the chain to Claude
5. When sending messages, the request flows from Claude through the MCP server to the Go bridge and to WhatsApp

## Troubleshooting

- If you encounter permission issues when running uv, you may need to add it to your PATH or use the full path to the executable.
- Make sure both the Go application and the Python server are running for the integration to work properly.

### Authentication Issues

- **QR Code Not Displaying**: If the QR code doesn&#039;t appear, try restarting the authentication script. If issues persist, check if your terminal supports displaying QR codes.
- **WhatsApp Already Logged In**: If your session is already active, the Go bridge will automatically reconnect without showing a QR code.
- **Device Limit Reached**: WhatsApp limits the number of linked devices. If you reach this limit, you&#039;ll need to remove an existing device from WhatsApp on your phone (Settings &gt; Linked Devices).
- **No Messages Loading**: After initial authentication, it can take several minutes for your message history to load, especially if you have many chats.
- **WhatsApp Out of Sync**: If your WhatsApp messages get out of sync with the bridge, delete both database files (`whatsapp-bridge/store/messages.db` and `whatsapp-bridge/store/whatsapp.db`) and restart the bridge to re-authenticate.

For additional Claude Desktop integration troubleshooting, see the [MCP documentation](https://modelcontextprotocol.io/quickstart/server#claude-for-desktop-integration-issues). The documentation includes helpful tips for checking logs and resolving common issues.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[tbphp/gpt-load]]></title>
            <link>https://github.com/tbphp/gpt-load</link>
            <guid>https://github.com/tbphp/gpt-load</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[Multi-channel AI proxy with intelligent key rotation. 智能密钥轮询的多渠道 AI 代理。]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tbphp/gpt-load">tbphp/gpt-load</a></h1>
            <p>Multi-channel AI proxy with intelligent key rotation. 智能密钥轮询的多渠道 AI 代理。</p>
            <p>Language: Go</p>
            <p>Stars: 4,895</p>
            <p>Forks: 420</p>
            <p>Stars today: 69 stars today</p>
            <h2>README</h2><pre># GPT-Load

English | [中文](README_CN.md) | [日本語](README_JP.md)

[![Release](https://img.shields.io/github/v/release/tbphp/gpt-load)](https://github.com/tbphp/gpt-load/releases)
![Go Version](https://img.shields.io/badge/Go-1.23+-blue.svg)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

A high-performance, enterprise-grade AI API transparent proxy service designed specifically for enterprises and developers who need to integrate multiple AI services. Built with Go, featuring intelligent key management, load balancing, and comprehensive monitoring capabilities, designed for high-concurrency production environments.

For detailed documentation, please visit [Official Documentation](https://www.gpt-load.com/docs?lang=en)

&lt;a href=&quot;https://hellogithub.com/repository/tbphp/gpt-load&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.hellogithub.com/v1/widgets/recommend.svg?rid=554dc4c46eb14092b9b0c56f1eb9021c&amp;claim_uid=Qlh8vzrWJ0HCneG&quot; alt=&quot;Featured｜HelloGitHub&quot; style=&quot;width: 250px; height: 54px;&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;&lt;/a&gt;

## Features

- **Transparent Proxy**: Complete preservation of native API formats, supporting OpenAI, Google Gemini, and Anthropic Claude among other formats
- **Intelligent Key Management**: High-performance key pool with group-based management, automatic rotation, and failure recovery
- **Load Balancing**: Weighted load balancing across multiple upstream endpoints to enhance service availability
- **Smart Failure Handling**: Automatic key blacklist management and recovery mechanisms to ensure service continuity
- **Dynamic Configuration**: System settings and group configurations support hot-reload without requiring restarts
- **Enterprise Architecture**: Distributed leader-follower deployment supporting horizontal scaling and high availability
- **Modern Management**: Vue 3-based web management interface that is intuitive and user-friendly
- **Comprehensive Monitoring**: Real-time statistics, health checks, and detailed request logging
- **High-Performance Design**: Zero-copy streaming, connection pool reuse, and atomic operations
- **Production Ready**: Graceful shutdown, error recovery, and comprehensive security mechanisms
- **Dual Authentication**: Separate authentication for management and proxy, with proxy authentication supporting global and group-level keys

## Supported AI Services

GPT-Load serves as a transparent proxy service, completely preserving the native API formats of various AI service providers:

- **OpenAI Format**: Official OpenAI API, Azure OpenAI, and other OpenAI-compatible services
- **Google Gemini Format**: Native APIs for Gemini Pro, Gemini Pro Vision, and other models
- **Anthropic Claude Format**: Claude series models, supporting high-quality conversations and text generation

## Quick Start

### System Requirements

- Go 1.23+ (for source builds)
- Docker (for containerized deployment)
- MySQL, PostgreSQL, or SQLite (for database storage)
- Redis (for caching and distributed coordination, optional)

### Method 1: Docker Quick Start

```bash
docker run -d --name gpt-load \
    -p 3001:3001 \
    -e AUTH_KEY=your-secure-key-here \
    -v &quot;$(pwd)/data&quot;:/app/data \
    ghcr.io/tbphp/gpt-load:latest
```

&gt; Please change `your-secure-key-here` to a strong password (never use the default value), then you can log in to the management interface: &lt;http://localhost:3001&gt;

### Method 2: Using Docker Compose (Recommended)

**Installation Commands:**

```bash
# Create Directory
mkdir -p gpt-load &amp;&amp; cd gpt-load

# Download configuration files
wget https://raw.githubusercontent.com/tbphp/gpt-load/refs/heads/main/docker-compose.yml
wget -O .env https://raw.githubusercontent.com/tbphp/gpt-load/refs/heads/main/.env.example

# Edit the .env file and change AUTH_KEY to a strong password. Never use default or simple keys like sk-123456.

# Start services
docker compose up -d
```

Before deployment, you must change the default admin key (AUTH_KEY). A recommended format is: sk-prod-[32-character random string].

The default installation uses the SQLite version, which is suitable for lightweight, single-instance applications.

If you need to install MySQL, PostgreSQL, and Redis, please uncomment the required services in the `docker-compose.yml` file, configure the corresponding environment variables, and restart.

**Other Commands:**

```bash
# Check service status
docker compose ps

# View logs
docker compose logs -f

# Restart Service
docker compose down &amp;&amp; docker compose up -d

# Update to latest version
docker compose pull &amp;&amp; docker compose down &amp;&amp; docker compose up -d
```

After deployment:

- Access Web Management Interface: &lt;http://localhost:3001&gt;
- API Proxy Address: &lt;http://localhost:3001/proxy&gt;

&gt; Use your modified AUTH_KEY to log in to the management interface.

### Method 3: Source Build

Source build requires a locally installed database (SQLite, MySQL, or PostgreSQL) and Redis (optional).

```bash
# Clone and build
git clone https://github.com/tbphp/gpt-load.git
cd gpt-load
go mod tidy

# Create configuration
cp .env.example .env

# Edit the .env file and change AUTH_KEY to a strong password. Never use default or simple keys like sk-123456.
# Modify DATABASE_DSN and REDIS_DSN configurations in .env
# REDIS_DSN is optional; if not configured, memory storage will be enabled

# Run
make run
```

After deployment:

- Access Web Management Interface: &lt;http://localhost:3001&gt;
- API Proxy Address: &lt;http://localhost:3001/proxy&gt;

&gt; Use your modified AUTH_KEY to log in to the management interface.

### Method 4: Cluster Deployment

Cluster deployment requires all nodes to connect to the same MySQL (or PostgreSQL) and Redis, with Redis being mandatory. It&#039;s recommended to use unified distributed MySQL and Redis clusters.

**Deployment Requirements:**

- All nodes must configure identical `AUTH_KEY`, `DATABASE_DSN`, `REDIS_DSN`
- Leader-follower architecture where follower nodes must configure environment variable: `IS_SLAVE=true`

For details, please refer to [Cluster Deployment Documentation](https://www.gpt-load.com/docs/cluster?lang=en)

## Configuration System

### Configuration Architecture Overview

GPT-Load adopts a dual-layer configuration architecture:

#### 1. Static Configuration (Environment Variables)

- **Characteristics**: Read at application startup, immutable during runtime, requires application restart to take effect
- **Purpose**: Infrastructure configuration such as database connections, server ports, authentication keys, etc.
- **Management**: Set via `.env` files or system environment variables

#### 2. Dynamic Configuration (Hot-Reload)

- **System Settings**: Stored in database, providing unified behavioral standards for the entire application
- **Group Configuration**: Behavior parameters customized for specific groups, can override system settings
- **Configuration Priority**: Group Configuration &gt; System Settings &gt; Environment Configuration
- **Characteristics**: Supports hot-reload, takes effect immediately after modification without application restart

&lt;details&gt;
&lt;summary&gt;Static Configuration (Environment Variables)&lt;/summary&gt;

**Server Configuration:**

| Setting                   | Environment Variable               | Default         | Description                                     |
| ------------------------- | ---------------------------------- | --------------- | ----------------------------------------------- |
| Service Port              | `PORT`                             | 3001            | HTTP server listening port                      |
| Service Address           | `HOST`                             | 0.0.0.0         | HTTP server binding address                     |
| Read Timeout              | `SERVER_READ_TIMEOUT`              | 60              | HTTP server read timeout (seconds)              |
| Write Timeout             | `SERVER_WRITE_TIMEOUT`             | 600             | HTTP server write timeout (seconds)             |
| Idle Timeout              | `SERVER_IDLE_TIMEOUT`              | 120             | HTTP connection idle timeout (seconds)          |
| Graceful Shutdown Timeout | `SERVER_GRACEFUL_SHUTDOWN_TIMEOUT` | 10              | Service graceful shutdown wait time (seconds)   |
| Follower Mode             | `IS_SLAVE`                         | false           | Follower node identifier for cluster deployment |
| Timezone                  | `TZ`                               | `Asia/Shanghai` | Specify timezone                                |

**Security Configuration:**

| Setting        | Environment Variable | Default | Description                                                                       |
| -------------- | -------------------- | ------- | --------------------------------------------------------------------------------- |
| Admin Key      | `AUTH_KEY`           | -       | Access authentication key for the **management end**, please change it to a strong password |
| Encryption Key | `ENCRYPTION_KEY`     | -       | Encrypts API keys at rest. Supports any string or leave empty to disable encryption. See [Data Encryption Migration](#data-encryption-migration) |

**Database Configuration:**

| Setting             | Environment Variable | Default              | Description                                         |
| ------------------- | -------------------- | -------------------- | --------------------------------------------------- |
| Database Connection | `DATABASE_DSN`       | `./data/gpt-load.db` | Database connection string (DSN) or file path       |
| Redis Connection    | `REDIS_DSN`          | -                    | Redis connection string, uses memory storage when empty |

**Performance &amp; CORS Configuration:**

| Setting                 | Environment Variable      | Default                       | Description                                     |
| ----------------------- | ------------------------- | ----------------------------- | ----------------------------------------------- |
| Max Concurrent Requests | `MAX_CONCURRENT_REQUESTS` | 100                           | Maximum concurrent requests allowed by system   |
| Enable CORS             | `ENABLE_CORS`             | false                          | Whether to enable Cross-Origin Resource Sharing |
| Allowed Origins         | `ALLOWED_ORIGINS`         | -                             | Allowed origins, comma-separated                |
| Allowed Methods         | `ALLOWED_METHODS`         | `GET,POST,PUT,DELETE,OPTIONS` | Allowed HTTP methods                            |
| Allowed Headers         | `ALLOWED_HEADERS`         | `*`                           | Allowed request headers, comma-separated        |
| Allow Credentials       | `ALLOW_CREDENTIALS`       | false                         | Whether to allow sending credentials            |

**Logging Configuration:**

| Setting             | Environment Variable | Default               | Description                         |
| ------------------- | -------------------- | --------------------- | ----------------------------------- |
| Log Level           | `LOG_LEVEL`          | `info`                | Log level: debug, info, warn, error |
| Log Format          | `LOG_FORMAT`         | `text`                | Log format: text, json              |
| Enable File Logging | `LOG_ENABLE_FILE`    | false                 | Whether to enable file log output   |
| Log File Path       | `LOG_FILE_PATH`      | `./data/logs/app.log` | Log file storage path               |

**Proxy Configuration:**

GPT-Load automatically reads proxy settings from environment variables to make requests to upstream AI providers.

| Setting     | Environment Variable | Default | Description                                     |
| ----------- | -------------------- | ------- | ----------------------------------------------- |
| HTTP Proxy  | `HTTP_PROXY`         | -       | Proxy server address for HTTP requests          |
| HTTPS Proxy | `HTTPS_PROXY`        | -       | Proxy server address for HTTPS requests         |
| No Proxy    | `NO_PROXY`           | -       | Comma-separated list of hosts or domains to bypass the proxy |

Supported Proxy Protocol Formats:

- **HTTP**: `http://user:pass@host:port`
- **HTTPS**: `https://user:pass@host:port`
- **SOCKS5**: `socks5://user:pass@host:port`
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Dynamic Configuration (Hot-Reload)&lt;/summary&gt;

**Basic Settings:**

| Setting            | Field Name                           | Default                 | Group Override | Description                                  |
| ------------------ | ------------------------------------ | ----------------------- | -------------- | -------------------------------------------- |
| Project URL        | `app_url`                            | `http://localhost:3001` | ❌             | Project base URL                             |
| Global Proxy Keys  | `proxy_keys`                         | Initial value from `AUTH_KEY` | ❌         | Globally effective proxy keys, comma-separated |
| Log Retention Days | `request_log_retention_days`         | 7                       | ❌             | Request log retention days, 0 for no cleanup |
| Log Write Interval | `request_log_write_interval_minutes` | 1                       | ❌             | Log write to database cycle (minutes)        |
| Enable Request Body Logging | `enable_request_body_logging` | false | ✅ | Whether to log complete request body content in request logs |

**Request Settings:**

| Setting                       | Field Name                | Default | Group Override | Description                                                         |
| ----------------------------- | ------------------------- | ------- | -------------- | ------------------------------------------------------------------- |
| Request Timeout               | `request_timeout`         | 600     | ✅             | Forward request complete lifecycle timeout (seconds)                |
| Connection Timeout            | `connect_timeout`         | 15      | ✅             | Timeout for establishing connection with upstream service (seconds) |
| Idle Connection Timeout       | `idle_conn_timeout`       | 120     | ✅             | HTTP client idle connection timeout (seconds)                       |
| Response Header Timeout       | `response_header_timeout` | 600     | ✅             | Timeout for waiting upstream response headers (seconds)             |
| Max Idle Connections          | `max_idle_conns`          | 100     | ✅             | Connection pool maximum total idle connections                      |
| Max Idle Connections Per Host | `max_idle_conns_per_host` | 50      | ✅             | Maximum idle connections per upstream host                          |
| Proxy URL                     | `proxy_url`               | -       | ✅             | HTTP/HTTPS proxy for forwarding requests, uses environment if empty |

**Key Configuration:**

| Setting                    | Field Name                        | Default | Group Override | Description                                                                |
| -------------------------- | --------------------------------- | ------- | -------------- | -------------------------------------------------------------------------- |
| Max Retries                | `max_retries`                     | 3       | ✅             | Maximum retry count using different keys for single request                |
| Blacklist Threshold        | `blacklist_threshold`             | 3       | ✅             | Number of consecutive failures before key enters blacklist                 |
| Key Validation Interval    | `key_validation_interval_minutes` | 60      | ✅             | Background scheduled key validation cycle (minutes)                        |
| Key Validation Concurrency | `key_validation_concurrency`      | 10      | ✅             | Concurrency for background validation of invalid keys                      |
| Key Validation Timeout     | `key_validation_timeout_seconds`  | 20      | ✅             | API request timeout for validating individual keys in background (seconds) |

&lt;/details&gt;

## Data Encryption Migration

GPT-Load supports encrypted storage of API keys. You can enable, disable, or change the encryption key at any time.

&lt;details&gt;
&lt;summary&gt;View Data Encryption Migration Details&lt;/summary&gt;

### Migration Scenarios

- **Enable Encryption**: Encrypt plaintext data for storage - Use `--to &lt;new-key&gt;`
- **Disable Encryption**: Decrypt encrypted data to plaintext - Use `--from &lt;current-key&gt;`
- **Change Encryption Key**: Replace the encryption key - Use `--from &lt;current-key&gt; --to &lt;new-key&gt;`

### Operation Steps

#### Docker Compose Deployment

```bash
# 1. Update the image (ensure using the latest version)
docker compose pull

# 2. Stop the service
docker compose down

# 3. Backup the database (strongly recommended)
# Before migration, you must manually backup the database or export your keys to avoid key loss due to operations or exceptions.

# 4. Execute migration command
# Enable encryption (your-32-char-secret-key is your key, recommend using 32+ character random string)
docker compose run --rm gpt-load migrate-keys --to &quot;your-32-char-secret-key&quot;

# Disable encryption
docker compose run --rm gpt-load migrate-keys --from &quot;your-current-key&quot;

# Change encryption key
docker compose run --rm gpt-load migrate-keys --from &quot;old-key&quot; --to &quot;new-32-char-secret-key&quot;

# 5. Update configuration file
# Edit .env file, set ENCRYPTION_KEY to match the --to parameter
# If disabling encryption, remove ENCRYPTION_KEY or set it to empty
vim .env
# Add or modify: ENCRYPTION_KEY=your-32-char-secret-key

# 6. Restart the service
docker compose up -d
```

#### Source Build Deployment

```bash
# 1. Stop the service
# Stop the running service process (Ctrl+C or kill process)

# 2. Backup the database (strongly recommended)
# Before migration, you must manually backup the database or export your keys to avoid key loss due to operations or exceptions.

# 3. Execute migration command
# Enable encryption
make migrate-keys ARGS=&quot;--to your-32-char-secret-key&quot;

# Disable encryption
make migrate-keys ARGS=&quot;--from your-current-key&quot;

# Change encryption key
make migrate-keys ARGS=&quot;--from old-key --to new-32-char-secret-key&quot;

# 4. Update configuration file
# Edit .env file, set ENCRYPTION_KEY to match the --to parameter
echo &quot;ENCRYPTION_KEY=your-32-char-secret-key&quot; &gt;&gt; .env

# 5. Restart the service
make run
```

### Important Notes

⚠️ **Important Reminders**:
- **Once ENCRYPTION_KEY is lost, encrypted data CANNOT be recovered!** Please securely backup this key. Consider using a password manager or secure key management system
- **Service must be stopped** before migration to avoid data inconsistency
- Strongly recommended to **backup the database** in case migration fails and recovery is needed
- Keys should use **32 characters or longer random strings** for security
- Ensure `ENCRYPTION_KEY` in `.env` matches the `--to` parameter after migration
- If disabling encryption, remove or clear the `ENCRYPTION_KEY` configuration

### Key Generation Examples

```bash
# Generate secure random key (32 characters)
openssl rand -base64 32 | tr -d &quot;=+/&quot; | cut -c1-32
```

&lt;/details&gt;

## Web Management Interface

Access the management console at: &lt;http://localhost:3001&gt; (default address)

### Interface Overview

&lt;img src=&quot;screenshot/dashboard.png&quot; alt=&quot;Dashboard&quot; width=&quot;600&quot;/&gt;

&lt;br/&gt;

&lt;img src=&quot;screenshot/keys.png&quot; alt=&quot;Key Management&quot; width=&quot;600&quot;/&gt;

&lt;br/&gt;

The web management interface provides the following features:

- **Dashboard**: Real-time statistics and system status overview
- **Key Management**: Create and configure AI service provider groups, add, delete, and monitor API keys
- **Request Logs**: Detailed request history and debugging information
- **System Settings**: Global configuration management and hot-reload

## API Usage Guide

&lt;details&gt;
&lt;summary&gt;Proxy Interface Invocation&lt;/summary

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[milvus-io/milvus]]></title>
            <link>https://github.com/milvus-io/milvus</link>
            <guid>https://github.com/milvus-io/milvus</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[Milvus is a high-performance, cloud-native vector database built for scalable vector ANN search]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/milvus-io/milvus">milvus-io/milvus</a></h1>
            <p>Milvus is a high-performance, cloud-native vector database built for scalable vector ANN search</p>
            <p>Language: Go</p>
            <p>Stars: 37,372</p>
            <p>Forks: 3,415</p>
            <p>Stars today: 61 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://github.com/user-attachments/assets/51e33300-7f85-43ff-a05a-3a0317a961f3&quot; alt=&quot;milvus banner&quot;&gt;

&lt;div class=&quot;column&quot; align=&quot;middle&quot;&gt;
  &lt;a href=&quot;https://github.com/milvus-io/milvus/blob/master/LICENSE&quot;&gt;&lt;img height=&quot;20&quot; src=&quot;https://img.shields.io/github/license/milvus-io/milvus&quot; alt=&quot;license&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://milvus.io/docs/install_standalone-docker.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/milvusdb/milvus&quot; alt=&quot;docker-pull-count&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://milvus.io/docs/roadmap.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/2025-roadmap-orange&quot; alt=&quot;fully-managed-milvus&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://cloud.zilliz.com/signup?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/fully_managed-milvus-blue&quot; alt=&quot;fully-managed-milvus&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://milvus.io/docs/tutorials-overview.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/tutorials-green&quot; alt=&quot;tutorials&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/mKc3R95yE5&quot;&gt;&lt;img height=&quot;20&quot; src=&quot;https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;discord&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/milvusio&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/milvusio&quot; alt=&quot;twitter&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

## What is Milvus?

🐦 [Milvus](https://milvus.io/) is a high-performance vector database built for scale. It powers AI applications by efficiently organizing and searching vast amounts of unstructured data, such as text, images, and multi-modal information.

🧑‍💻 Written in Go and C++, Milvus implements hardware accelaration for CPU/GPU to achieve best-in-class vector search performance. Thanks to its [fully-distributed and K8s-native architecture](https://milvus.io/docs/overview.md#What-Makes-Milvus-so-Scalable), Milvus can scale horizontally, handle tens of thousands of search queries on billions of vectors, and keep data fresh with real-time streaming updates. Milvus also supports [Standalone mode](https://milvus.io/docs/install_standalone-docker.md) for single machine deployment. [Milvus Lite](https://milvus.io/docs/milvus_lite.md) is a lightweight version good for quickstart in python with `pip install`.

Want to use Milvus with zero setup? Try out [Zilliz Cloud ☁️](https://cloud.zilliz.com/signup?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global) for free. Milvus is available as a fully managed service on Zilliz Cloud, with [Serverless](https://zilliz.com/serverless?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global), [Dedicated](https://zilliz.com/cloud?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global) and [BYOC](https://zilliz.com/bring-your-own-cloud?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global) options available.

For questions about how to use Milvus, join the community on [Discord](https://discord.gg/33mfvwep3J) to get help. For reporting problems, file bugs and feature requests in GitHub [Issues](https://github.com/milvus-io/milvus/issues) or ask in [Discussions](https://github.com/milvus-io/milvus/discussions).

The Milvus open-source project is
under [LF AI &amp; Data Foundation](https://lfaidata.foundation/projects/milvus/), distributed with [Apache 2.0](https://github.com/milvus-io/milvus/blob/master/LICENSE) License, with Zilliz as its major contributor.

## Quickstart

```python
$ pip install -U pymilvus
```
This installs `pymilvus`, the Python SDK for Milvus. Use `MilvusClient` to create a client:
```python
from pymilvus import MilvusClient
```

* `pymilvus` also includes Milvus Lite for quickstart. To create a local vector database, simply instantiate a client with a local file name for persisting data:

  ```python
  client = MilvusClient(&quot;milvus_demo.db&quot;)
  ```

* You can also specify the credentials to connect to your deployed [Milvus server](https://milvus.io/docs/authenticate.md?tab=docker) or [Zilliz Cloud](https://docs.zilliz.com/docs/quick-start):

  ```python
  client = MilvusClient(
    uri=&quot;&lt;endpoint_of_self_hosted_milvus_or_zilliz_cloud&gt;&quot;,
    token=&quot;&lt;username_and_password_or_zilliz_cloud_api_key&gt;&quot;)
  ```

With the client, you can create collection:
```python
client.create_collection(
    collection_name=&quot;demo_collection&quot;,
    dimension=768,  # The vectors we will use in this demo have 768 dimensions
)
```

Ingest data:
```python
res = client.insert(collection_name=&quot;demo_collection&quot;, data=data)
```

Perform vector search:

```python
query_vectors = embedding_fn.encode_queries([&quot;Who is Alan Turing?&quot;, &quot;What is AI?&quot;])
res = client.search(
    collection_name=&quot;demo_collection&quot;,  # target collection
    data=query_vectors,  # a list of one or more query vectors, supports batch
    limit=2,  # how many results to return (topK)
    output_fields=[&quot;vector&quot;, &quot;text&quot;, &quot;subject&quot;],  # what fields to return
)
```

## Why Milvus

Milvus is designed to handle vector search at scale. It stores vectors, which are learned representations of unstructured data, together with other scalar data types such as integers, strings, and JSON objects. Users can conduct efficient vector search with metadata filtering or hybrid search. Here are why developers choose Milvus as the vector database for AI applications:

**High Performance at Scale and High Availability**  
  * Milvus features a [distributed architecture](https://milvus.io/docs/architecture_overview.md ) that separates [compute](https://milvus.io/docs/data_processing.md#Data-query) and [storage](https://milvus.io/docs/data_processing.md#Data-insertion). Milvus can horizontally scale and adapt to diverse traffic patterns, achieving optimal performance by independently increasing query nodes for read-heavy workload and data node for write-heavy workload. The stateless microservices on K8s allow [quick recovery](https://milvus.io/docs/coordinator_ha.md#Coordinator-HA) from failure, ensuring high availability. The support for [replicas](https://milvus.io/docs/replica.md) further enhances fault tolerance and throughput by loading data segments on multiple query nodes. See [benchmark](https://zilliz.com/vector-database-benchmark-tool) for performance comparison.


**Support for Various Vector Index Types and Hardware Acceleration**  
  * Milvus separates the system and core vector search engine, allowing it to support all major vector index types that are optimized for different scenarios, including HNSW, IVF, FLAT (brute-force), SCANN, and DiskANN, with [quantization-based](https://milvus.io/docs/index.md?tab=floating#IVFPQ) variations and [mmap](https://milvus.io/docs/mmap.md). Milvus optimizes vector search for advanced features such as [metadata filtering](https://milvus.io/docs/scalar_index.md#Scalar-Index) and [range search](https://milvus.io/docs/single-vector-search.md#Range-search). Additionally, Milvus implements hardware acceleration to enhance vector search performance and supports GPU indexing, such as NVIDIA&#039;s [CAGRA](https://github.com/rapidsai/cuvs).


**Flexible Multi-tenancy and Hot/Cold Storage**
  * Milvus supports [multi-tenancy](https://milvus.io/docs/multi_tenancy.md#Multi-tenancy-strategies) through isolation at database, collection, partition, or partition key level. The flexible strategies allow a single cluster to handle hundreds to millions of tenants, also ensures optimized search performance and flexible access control. Milvus enhances cost-effectiveness with hot/cold storage. Frequently accessed hot data can be stored in memory or on SSDs for better performance, while less-accessed cold data is kept on slower, cost-effective storage. This mechanism can significantly reduce costs while maintaining high performance for critical tasks.

**Sparse Vector for Full Text Search and Hybrid Search**
  * In addition to semantic search through dense vector, Milvus also natively supports [full text search](https://milvus.io/docs/full-text-search.md) with BM25 as well as learned sparse embedding such as SPLADE and BGE-M3. Users can store sparse vector and dense vector in the same collection, and define functions to rerank results from multiple search requests. See examples of [Hybrid Search with semantic search + full text search](https://milvus.io/docs/full_text_search_with_milvus.md).

**Data Security and Fine-grain Access Control**
  * Milvus ensures data security by implementing mandatory user authentication, TLS encryption, and Role-Based Access Control (RBAC). User authentication ensures that only authorized users with valid credentials can access the database, while TLS encryption secures all communications within the network. Additionally, RBAC allows for fine-grained access control by assigning specific permissions to users based on their roles. These features make Milvus a robust and secure choice for enterprise applications, protecting sensitive data from unauthorized access and potential breaches.

Milvus is trusted by AI developers to build applications such as text and image search, Retrieval-Augmented Generation (RAG), and recommendation systems. Milvus powers [many mission-critical business]((https://milvus.io/use-cases)) for startups and enterprises.

## Demos and Tutorials

Here is a selection of demos and tutorials to show how to build various types of AI applications made with Milvus:

You can explore a comprehensive [Tutorials Overview](https://milvus.io/docs/tutorials-overview.md) covering topics such as Retrieval-Augmented Generation (RAG), Semantic Search, Hybrid Search, Question Answering, Recommendation Systems, and various quick-start guides. These resources are designed to help you get started quickly and efficiently.

| Tutorial | Use Case | Related Milvus Features |
| -------- | -------- | --------- |
| [Build RAG with Milvus](https://milvus.io/docs/build-rag-with-milvus.md) |  RAG | vector search |
| [Advanced RAG Optimizations](https://milvus.io/docs/how_to_enhance_your_rag.md) | RAG | vector search, full text search |
| [Full Text Search with Milvus](https://milvus.io/docs/full_text_search_with_milvus.md) | Text Search | full text search |
| [Hybrid Search with Milvus](https://milvus.io/docs/hybrid_search_with_milvus.md) | Hybrid Search | hybrid search, multi vector, dense embedding, sparse embedding |
| [Image Search with Milvus](https://milvus.io/docs/image_similarity_search.md) | Semantic Search | vector search, dynamic field |
| [Multimodal Search using Multi Vectors](https://milvus.io/docs/multimodal_rag_with_milvus.md) | Semantic Search | multi vector, hybrid search |
| [Movie Recommendation with Milvus](https://milvus.io/docs/movie_recommendation_with_milvus.md) | Recommendation System | vector search |
| [Graph RAG with Milvus](https://milvus.io/docs/graph_rag_with_milvus.md) | RAG | graph search |
| [Contextual Retrieval with Milvus](https://milvus.io/docs/contextual_retrieval_with_milvus.md) | Quickstart | vector search |
| [Vector Visualization](https://milvus.io/docs/vector_visualization.md) | Quickstart | vector search |
| [HDBSCAN Clustering with Milvus](https://milvus.io/docs/hdbscan_clustering_with_milvus.md) | Quickstart | vector search |
| [Use ColPali for Multi-Modal Retrieval with Milvus](https://milvus.io/docs/use_ColPali_with_milvus.md) | Quickstart | vector search |

&lt;table&gt;
  &lt;tr&gt;
    &lt;td width=&quot;30%&quot;&gt;
      &lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;
        &lt;img src=&quot;https://assets.zilliz.com/image_search_59a64e4f22.gif&quot; /&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;30%&quot;&gt;
&lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;
&lt;img src=&quot;https://assets.zilliz.com/qa_df5ee7bd83.gif&quot; /&gt;
&lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;30%&quot;&gt;
&lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;
&lt;img src=&quot;https://assets.zilliz.com/mole_search_76f8340572.gif&quot; /&gt;
&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;
      &lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;Image Search&lt;/a&gt;
    &lt;/th&gt;
    &lt;th&gt;
      &lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;RAG&lt;/a&gt;
    &lt;/th&gt;
    &lt;th&gt;
      &lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;Drug Discovery&lt;/a&gt;
    &lt;/th&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Ecosystem and Integration
   Milvus integrates with a comprehensive suite of [AI development tools](https://milvus.io/docs/integrations_overview.md), such as LangChain, LlamaIndex, OpenAI and HuggingFace, making it an ideal vector store for GenAI applications such as Retrieval-Augmented Generation (RAG). Milvus works with both open-source embedding models and embedding service, in text, image and video modalities. Milvus also provides a convenient util [`pymilvus[model]`](https://milvus.io/docs/embeddings.md), users can use the simple wrapper code to transform unstructured data into vector embeddings and leverage reranking models for optimized search results. The Milvus ecosystem also includes [Attu](https://github.com/zilliztech/attu?tab=readme-ov-file#attu) for GUI-based administration, [Birdwatcher](https://milvus.io/docs/birdwatcher_overview.md) for system debugging, [Prometheus/Grafana](https://milvus.io/docs/monitor_overview.md) for monitoring, [Milvus CDC](https://milvus.io/docs/milvus-cdc-overview.md) for data synchronization, [VTS](https://github.com/zilliztech/vts?tab=readme-ov-file#vts) for data migration and data connectors for [Spark](https://milvus.io/docs/integrate_with_spark.md#Spark-Milvus-Connector-User-Guide), [Kafka](https://github.com/zilliztech/kafka-connect-milvus?tab=readme-ov-file#kafka-connect-milvus-connector), [Fivetran](https://fivetran.com/docs/destinations/milvus), and [Airbyte](https://milvus.io/docs/integrate_with_airbyte.md) to build search pipelines.

Check out https://milvus.io/docs/integrations_overview.md for more details.

## Documentation

For guidance on installation, usage, deployment, and administration, check out [Milvus Docs](https://milvus.io/docs). For technical milestones and enhancement proposals, check out [issues on GitHub](https://github.com/milvus-io/milvus/issues).

## Contributing

The Milvus open-source project accepts contribution from everyone. See [Guidelines for Contributing](https://github.com/milvus-io/milvus/blob/master/CONTRIBUTING.md) for details on submitting patches and the development workflow. See our [community repository](https://github.com/milvus-io/community) to learn about project governance and access more community resources.

### Build Milvus from Source Code

Requirements:

* Linux systems (Ubuntu 20.04 or later recommended):
  ```bash
  go: &gt;= 1.21
  cmake: &gt;= 3.26.4
  gcc: 9.5
  python: &gt; 3.8 and  &lt;= 3.11
  ```

* MacOS systems with x86_64 (Big Sur 11.5 or later recommended):
  ```bash
  go: &gt;= 1.21
  cmake: &gt;= 3.26.4
  llvm: &gt;= 15
  python: &gt; 3.8 and  &lt;= 3.11
  ```

* MacOS systems with Apple Silicon (Monterey 12.0.1 or later recommended):
  ```bash
  go: &gt;= 1.21 (Arch=ARM64)
  cmake: &gt;= 3.26.4
  llvm: &gt;= 15
  python: &gt; 3.8 and  &lt;= 3.11
  ```

Clone Milvus repo and build.

```bash
# Clone github repository.
$ git clone https://github.com/milvus-io/milvus.git

# Install third-party dependencies.
$ cd milvus/
$ ./scripts/install_deps.sh

# Compile Milvus.
$ make
```

For full instructions, see [developer&#039;s documentation](https://github.com/milvus-io/milvus/blob/master/DEVELOPMENT.md).

## Community

Join the Milvus community on [Discord](https://discord.gg/8uyFbECzPX) to share your suggestions, advice, and questions with our engineering team.

To learn latest news about Milvus, follow us on social media:

- [X](https://twitter.com/milvusio)
- [LinkedIn](https://www.linkedin.com/company/the-milvus-project)
- [Youtube](https://www.youtube.com/channel/UCMCo_F7pKjMHBlfyxwOPw-g)
- [Medium](https://medium.com/@milvusio)

You can also check out our [FAQ page](https://milvus.io/docs/performance_faq.md) to discover solutions or answers to your issues or questions, and subscribe to Milvus mailing lists:

- [Technical Steering Committee](https://lists.lfai.foundation/g/milvus-tsc)
- [Technical Discussions](https://lists.lfai.foundation/g/milvus-technical-discuss)
- [Announcement](https://lists.lfai.foundation/g/milvus-announce)

## Reference

Reference to cite when you use Milvus in a research paper:

```
@inproceedings{2021milvus,
  title={Milvus: A Purpose-Built Vector Data Management System},
  author={Wang, Jianguo and Yi, Xiaomeng and Guo, Rentong and Jin, Hai and Xu, Peng and Li, Shengjun and Wang, Xiangyu and Guo, Xiangzhou and Li, Chengming and Xu, Xiaohai and others},
  booktitle={Proceedings of the 2021 International Conference on Management of Data},
  pages={2614--2627},
  year={2021}
}

@article{2022manu,
  title={Manu: a cloud native vector database management system},
  author={Guo, Rentong and Luan, Xiaofan and Xiang, Long and Yan, Xiao and Yi, Xiaomeng and Luo, Jigao and Cheng, Qianya and Xu, Weizhi and Luo, Jiarui and Liu, Frank and others},
  journal={Proceedings of the VLDB Endowment},
  volume={15},
  number={12},
  pages={3548--3561},
  year={2022},
  publisher={VLDB Endowment}
}
```
&lt;!-- Do not remove start of hero-bot --&gt;
&lt;img src=&quot;https://img.shields.io/badge/all--contributors-414-orange&quot;&gt;&lt;br&gt;
&lt;a href=&quot;https://github.com/0xflotus&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/26602940?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/9Eurydice9&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/220225099?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ABNER-1&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/24547351?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Abhijnan-Bajpai&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/57059194?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Accagain2014&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/9635216?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Ahmetyasin&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/34247619?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Ald392&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/166891594?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/AliDotS&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/33119433?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/AllenYu1987&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/12489985?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Anosh21&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/90505226?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/AnthonyTsu1984&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/115786031?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Aredcap&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/40494761?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ArenaSu&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/21214629?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Armaggheddon&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/47779194?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/BUPTAnderson&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/13449703?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Ben-Aaron-Bio-Rad&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/54123439?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Bennu-Li&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/53458891?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Biki-das&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/72331432?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/BossZou&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/40255591?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/CNLHC&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/21005146?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/CaoHaiNam&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/47685795?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Chisdo&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/36720318?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ChunelFeng&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/37905059?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/CocytusElias&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/79587688?v=4&quot; width=&quot;30px&quot; 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[putyy/res-downloader]]></title>
            <link>https://github.com/putyy/res-downloader</link>
            <guid>https://github.com/putyy/res-downloader</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[视频号、小程序、抖音、快手、小红书、直播流、m3u8、酷狗、QQ音乐等常见网络资源下载!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/putyy/res-downloader">putyy/res-downloader</a></h1>
            <p>视频号、小程序、抖音、快手、小红书、直播流、m3u8、酷狗、QQ音乐等常见网络资源下载!</p>
            <p>Language: Go</p>
            <p>Stars: 10,136</p>
            <p>Forks: 1,204</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://github.com/putyy/res-downloader&quot;&gt;&lt;img src=&quot;build/appicon.png&quot; width=&quot;120&quot;/&gt;&lt;/a&gt;
&lt;h1&gt;res-downloader&lt;/h1&gt;
&lt;h4&gt;📖 中文 | &lt;a href=&quot;https://github.com/putyy/res-downloader/blob/master/README-EN.md&quot;&gt;English&lt;/a&gt;&lt;/h4&gt;

[![GitHub stars](https://img.shields.io/github/stars/putyy/res-downloader)](https://github.com/putyy/res-downloader/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/putyy/res-downloader)](https://github.com/putyy/res-downloader/fork)
[![GitHub release](https://img.shields.io/github/release/putyy/res-downloader)](https://github.com/putyy/res-downloader/releases)
![GitHub All Releases](https://img.shields.io/github/downloads/putyy/res-downloader/total)
[![License](https://img.shields.io/github/license/putyy/res-downloader)](https://github.com/putyy/res-downloader/blob/master/LICENSE)

&lt;/div&gt;

---

### 🎉 爱享素材下载器

&gt; 一款基于 Go + [Wails](https://github.com/wailsapp/wails) 的跨平台资源下载工具，简洁易用，支持多种资源嗅探与下载。

## ✨ 功能特色

- 🚀 **简单易用**：操作简单，界面清晰美观
- 🖥️ **多平台支持**：Windows / macOS / Linux
- 🌐 **多资源类型支持**：视频 / 音频 / 图片 / m3u8 / 直播流等
- 📱 **平台兼容广泛**：支持微信视频号、小程序、抖音、快手、小红书、酷狗音乐、QQ音乐等
- 🌍 **代理抓包**：支持设置代理获取受限网络下的资源

## 📚 文档 &amp; 版本

- 📘 [在线文档](https://res.putyy.com/)
- 💬 [加入交流群](https://www.putyy.com/app/admin/upload/img/20250418/6801d9554dc7.webp)
- 🧩 [最新版](https://github.com/putyy/res-downloader/releases) ｜ [Mini版 使用默认浏览器展示UI](https://github.com/putyy/resd-mini) ｜ [Electron旧版 支持Win7](https://github.com/putyy/res-downloader/tree/old)
  &gt; *群满时可加微信 `AmorousWorld`，请备注“github”*

## 🧩 下载地址

- 🆕 [GitHub 下载](https://github.com/putyy/res-downloader/releases)
- 🆕 [蓝奏云下载（密码：9vs5）](https://wwjv.lanzoum.com/b04wgtfyb)
- ⚠️ *Win7 用户请下载 `2.3.0` 版本*


## 🖼️ 预览

![预览](docs/images/show.webp)
--- 

## 🚀 使用方法

&gt; 请按以下步骤操作以正确使用软件：

1. 安装时务必 **允许安装证书文件** 并 **允许网络访问**
2. 打开软件 → 首页左上角点击 **“启动代理”**
3. 选择要获取的资源类型（默认全部）
4. 在外部打开资源页面（如视频号、小程序、网页等）
5. 返回软件首页，即可看到资源列表

## ❓ 常见问题

### 📺 m3u8 视频资源

- 在线预览：[m3u8play](https://m3u8play.com/)
- 视频下载：[m3u8-down](https://m3u8-down.gowas.cn/)

### 📡 直播流资源

- 推荐使用 [OBS](https://obsproject.com/) 进行录制（教程请百度）

### 🐢 下载慢、大文件失败？

- 推荐工具：
  - [Neat Download Manager](https://www.neatdownloadmanager.com/index.php/en/)
  - [Motrix](https://motrix.app/download)
- 视频号资源下载后可在操作项点击 `视频解密（视频号）`

### 🧩 软件无法拦截资源？

- 检查是否正确设置系统代理：  
  地址：127.0.0.1
  端口：8899

### 🌐 关闭软件后无法上网？

- 手动关闭系统代理设置

### 🧠 更多问题

- [GitHub Issues](https://github.com/putyy/res-downloader/issues)
- [爱享论坛讨论帖](https://s.gowas.cn/d/4089)

## 💡 实现原理 &amp; 初衷

本工具通过代理方式实现网络抓包，并筛选可用资源。与 Fiddler、Charles、浏览器 DevTools 原理类似，但对资源进行了更友好的筛选、展示和处理，大幅度降低了使用门槛，更适合大众用户使用。

---

## ⚠️ 免责声明

&gt; 本软件仅供学习与研究用途，禁止用于任何商业或违法用途。  
如因此产生的任何法律责任，概与作者无关！
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[keploy/keploy]]></title>
            <link>https://github.com/keploy/keploy</link>
            <guid>https://github.com/keploy/keploy</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[Unit, API & Integration Testing Agent for Developers. Generate tests, mocks/stubs for your APIs that actually work!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/keploy/keploy">keploy/keploy</a></h1>
            <p>Unit, API & Integration Testing Agent for Developers. Generate tests, mocks/stubs for your APIs that actually work!</p>
            <p>Language: Go</p>
            <p>Stars: 10,728</p>
            <p>Forks: 1,582</p>
            <p>Stars today: 188 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot;&gt;
  &lt;img align=&quot;center&quot; src=&quot;https://docs.keploy.io/img/keploy-logo-dark.svg?s=200&amp;v=4&quot; height=&quot;40%&quot; width=&quot;40%&quot;  alt=&quot;keploy logo&quot;/&gt;
&lt;/p&gt;
&lt;h3 align=&quot;center&quot;&gt;
&lt;b&gt;
⚡️ API tests faster than unit tests, from user traffic ⚡️
&lt;/b&gt;
&lt;/h3 &gt;
&lt;p align=&quot;center&quot;&gt;
🌟 The must-have tool for developers in the AI-Gen era 🌟
&lt;/p&gt;

---

&lt;h4 align=&quot;center&quot;&gt;

   &lt;a href=&quot;https://x.com/Keployio&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/follow-%40keployio-1DA1F2?logo=X&amp;style=social&quot; alt=&quot;Keploy X!&quot; /&gt;
  &lt;/a&gt;
  
  &lt;a href=&quot;https://github.com/Keploy/Keploy/&quot;&gt;
   &lt;img src=&quot;https://img.shields.io/github/stars/keploy/keploy?color=%23EAC54F&amp;logo=github&amp;label=Help%20us%20reach%2020K%20stars!%20Now%20at:&quot; alt=&quot;Help us reach 20k stars!&quot; /&gt;
&lt;/a&gt;

  &lt;a href=&quot;https://landscape.cncf.io/?item=app-definition-and-development--continuous-integration-delivery--keploy&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/CNCF%20Landscape-5699C6?logo=cncf&amp;style=social&quot; alt=&quot;Keploy CNCF Landscape&quot; /&gt;
  &lt;/a&gt;

[![Slack](https://img.shields.io/badge/Slack-4A154B?style=for-the-badge&amp;logo=slack&amp;logoColor=white)](https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg)
[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white)](https://www.linkedin.com/company/keploy/)
[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&amp;logo=YouTube&amp;logoColor=white)](https://www.youtube.com/channel/UC6OTg7F4o0WkmNtSoob34lg)
[![X](https://img.shields.io/badge/X-%231DA1F2.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white)](https://x.com/Keployio)

&lt;a href=&quot;https://trendshift.io/repositories/3262&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/3262&quot; alt=&quot;keploy%2Fkeploy | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/h4&gt;


[Keploy](https://keploy.io) is **developer-centric** API testing tool that creates **tests along with built-in-mocks**, faster than unit tests.

Keploy not only records API calls, but also records database calls and replays them during testing, making it **easy to use, powerful, and extensible**.

&lt;img src=&quot;https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-tc.gif&quot; width=&quot;60%&quot; alt=&quot;Convert API calls to test cases&quot;/&gt;

&gt; 🐰 **Fun fact:** Keploy uses itself for testing! Check out our swanky coverage badge: [![Coverage Status](https://coveralls.io/repos/github/keploy/keploy/badge.svg?branch=main&amp;kill_cache=1)](https://coveralls.io/github/keploy/keploy?branch=main&amp;kill_cache=1) &amp;nbsp;

## 🚨 Here for  [Unit Test Generator](README-UnitGen.md) (ut-gen)? 
Keploy has newly launched the world&#039;s first unit test generator(ut-gen) implementation of [Meta LLM research paper](https://arxiv.org/pdf/2402.09171), it understands code semantics and generates meaningful unit tests, aiming to:

- **Automate unit test generation (UTG)**: Quickly generate comprehensive unit tests and reduce redundant manual effort.

- **Improve edge cases**: Extend and improve the scope of automated tests to cover more complex scenarios, often missed manually.

- **Boost test coverage**: As codebases grow, ensuring exhaustive coverage should become feasible, aligning with our mission.

### 📜 Follow [Unit Test Generator README](README-UnitGen.md)! ✅

## 📘 Documentation!
Become a Keploy pro with **[Keploy Documentation](https://keploy.io/docs/)**.

&lt;img src=&quot;https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-replay.gif&quot; width=&quot;100%&quot; alt=&quot;Record Replay Testing&quot;/&gt;

# 🚀 Quick Installation (API test generator)

Integrate Keploy by installing the agent locally. No code-changes required.

```shell
curl --silent -O -L https://keploy.io/install.sh &amp;&amp; source install.sh
```

##  🎬 Recording Testcases

Start your app with Keploy to convert API calls as Tests and Mocks/Stubs.

```zsh
keploy record -c &quot;CMD_TO_RUN_APP&quot; 
```
For example, if you&#039;re using a simple Python app the `CMD_TO_RUN_APP` would resemble to `python main.py`, for  Golang `go run main.go`, for java `java -jar xyz.jar`, for node `npm start`..

```zsh
keploy record -c &quot;python main.py&quot;
```

## 🧪 Running Tests
Shut down the databases, redis, kafka or any other services your application uses. Keploy doesn&#039;t need those during test.
```zsh
keploy test -c &quot;CMD_TO_RUN_APP&quot; --delay 10
```

## ✅ Test Coverage Integration
To integrate with your unit-testing library and see combine test coverage, follow this [test-coverage guide](https://keploy.io/docs/server/sdk-installation/go/).

&gt; ####  **If You Had Fun:** Please leave a 🌟 star on this repo! It&#039;s free and will bring a smile. 😄 👏

## One-Click Setup 🚀

Setup and run keploy quickly, with no local machine installation required:

[![GitHub Codescape](https://img.shields.io/badge/GH%20codespace-3670A0?style=for-the-badge&amp;logo=github&amp;logoColor=fff)]([https://github.dev/Sonichigo/mux-sql](https://github.dev/Sonichigo/mux-sql))

## 🤔 Questions?
Reach out to us. We&#039;re here to help!

[![Slack](https://img.shields.io/badge/Slack-4A154B?style=for-the-badge&amp;logo=slack&amp;logoColor=white)](https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg)
[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white)](https://www.linkedin.com/company/keploy/)
[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&amp;logo=YouTube&amp;logoColor=white)](https://www.youtube.com/channel/UC6OTg7F4o0WkmNtSoob34lg)
[![X](https://img.shields.io/badge/X-%231DA1F2.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white)](https://x.com/Keployio)


## 🌐 Language Support
From Go&#039;s gopher 🐹 to Python&#039;s snake 🐍, we support:

![Go](https://img.shields.io/badge/go-%2300ADD8.svg?style=for-the-badge&amp;logo=go&amp;logoColor=white)
![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&amp;logo=java&amp;logoColor=white)
![NodeJS](https://img.shields.io/badge/node.js-6DA55F?style=for-the-badge&amp;logo=node.js&amp;logoColor=white)
![Rust](https://img.shields.io/badge/Rust-darkred?style=for-the-badge&amp;logo=rust&amp;logoColor=white)
![C#](https://img.shields.io/badge/csharp-purple?style=for-the-badge&amp;logo=csharp&amp;logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&amp;logo=python&amp;logoColor=ffdd54)

## 🫰 Keploy Adopters 🧡

So you and your organisation are using Keploy? That’s great. Please add yourselves to [**this list,**](https://github.com/orgs/keploy/discussions/1765) and we&#039;ll send you goodies! 💖


We are happy and proud to have you all as part of our community! 💖

## 🎩 How&#039;s the Magic Happen?
Keploy proxy captures and replays **ALL** (CRUD operations, including non-idempotent APIs) of your app&#039;s network interactions.


Take a journey to **[How Keploy Works?](https://keploy.io/docs/keploy-explained/how-keploy-works/)** to discover the tricks behind the curtain!

  ## 🔧 Core Features

- ♻️ **Combined Test Coverage:** Merge your Keploy Tests with your fave testing libraries(JUnit, go-test, py-test, jest) to see a combined test coverage.


- 🤖 **EBPF Instrumentation:** Keploy uses EBPF like a secret sauce to make integration code-less, language-agnostic, and oh-so-lightweight.


- 🌐 **CI/CD Integration:** Run tests with mocks anywhere you like—locally on the CLI, in your CI pipeline (Jenkins, Github Actions..) , or even across a Kubernetes cluster.


- 📽️ **Record-Replay Complex Flows:** Keploy can record and replay complex, distributed API flows as mocks and stubs. It&#039;s like having a time machine for your tests—saving you tons of time!


- 🎭 **Multi-Purpose Mocks:** You can also use Keploy-generated Mocks, as server Tests!


👉 **Explore the code on GitHub**: [github.com/keploy/keploy](https://github.com/keploy/keploy)


## 👨🏻‍💻 Let&#039;s Build Together! 👩🏻‍💻
Whether you&#039;re a newbie coder or a wizard 🧙‍♀️, your perspective is golden. Take a peek at our:

📜 [Contribution Guidelines](https://github.com/keploy/keploy/blob/main/CONTRIBUTING.md)

❤️ [Code of Conduct](https://github.com/keploy/keploy/blob/main/CODE_OF_CONDUCT.md)


## 🐲 Current Limitations!
- **Unit Testing:** While Keploy is designed to run alongside unit testing frameworks (Go test, JUnit..) and can add to the overall code coverage, it still generates integration tests.
- **Production Lands**: Keploy is currently focused on generating tests for developers. These tests can be captured from any environment, but we have not tested it on high volume production environments. This would need robust deduplication to avoid too many redundant tests being captured. We do have ideas on building a robust deduplication system [#27](https://github.com/keploy/keploy/issues/27)

## ✨ Resources!
🤔 [FAQs](https://keploy.io/docs/keploy-explained/faq/)

🕵️‍️ [Why Keploy](https://keploy.io/docs/keploy-explained/why-keploy/)

⚙️ [Installation Guide](https://keploy.io/docs/application-development/)

📖 [Contribution Guide](https://keploy.io/docs/keploy-explained/contribution-guide/)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[docker/mcp-gateway]]></title>
            <link>https://github.com/docker/mcp-gateway</link>
            <guid>https://github.com/docker/mcp-gateway</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[docker mcp CLI plugin / MCP Gateway]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/docker/mcp-gateway">docker/mcp-gateway</a></h1>
            <p>docker mcp CLI plugin / MCP Gateway</p>
            <p>Language: Go</p>
            <p>Stars: 554</p>
            <p>Forks: 66</p>
            <p>Stars today: 151 stars today</p>
            <h2>README</h2><pre># Docker MCP Plugin and Docker MCP Gateway

![build](https://github.com/docker/mcp-gateway/actions/workflows/ci.yml/badge.svg)

The [MCP Toolkit](https://docs.docker.com/ai/mcp-catalog-and-toolkit/toolkit/), in Docker Desktop, allows
developers to configure and consume MCP servers from the [Docker MCP Catalog](https://hub.docker.com/mcp).

Underneath, the Toolkit is powered by a docker CLI plugin: `docker-mcp`. This repository is the code of this CLI plugin. It can work in Docker Desktop or independently.

The main feature of this CLI is the **Docker MCP Gateway** which allows easy and secure running and deployment of MCP servers. See [Features](#Features) for a list of all the features.

## What is MCP?

The [Model Context Protocol (MCP)](https://spec.modelcontextprotocol.io/) is an open protocol that standardizes how AI applications connect to external data sources and tools. It provides a secure, controlled way for language models to access and interact with various services, databases, and APIs.

## Overview

Developers face criticial barriers when integrating Model Context Protocol (MCP) tools into production workflows:

- **Managing MCP server lifecycle** Each local MCP sever in the catalog runs in an isolated Docker container. npx and uvx servers are granted minimal host privileges.
- **Providing a unified interface** AI models access MCP servers through a single Gateway.
- **Handling authentication and security** Keep secrets out of environment variables using Docker Desktop&#039;s secrets management.
- **Supports dynamic tool discovery** and configuration. Each MCP client (eg VS Code, Cursor, Claude Desktop, etc.) connects to the same Gateway configuration, ensuring consistency across different clients.
- **Enables OAuth flows** for MCPs that require OAuth access token service connections.

## Features

- 🐳 **Container-based Servers**: Run MCP servers as Docker containers with proper isolation.
- 🔧 **Server Management**: List, inspect, and call MCP tools, resources and prompts from multiple servers.
- 🔐 **Secrets Management**: Secure handling of API keys and credentials via Docker Desktop.
- 🌐 **OAuth Integration**: Built-in OAuth flows for service authentication.
- 📋 **Server Catalog**: Manage and configure multiple MCP catalogs.
- 🔍 **Dynamic Discovery**: Automatic tool, prompt, and resource discovery from running servers.
- 📊 **Monitoring**: Built-in logging and call tracing capabilities.

## Installation

### Prerequisites

- Docker Desktop (with MCP Toolkit feature enabled)

&lt;div align=&quot;left&quot;&gt;
  &lt;img src=&quot;./img/enable_toolkit.png&quot; width=&quot;400&quot;/&gt;
&lt;/div&gt;
- Go 1.24+ (for development)

### Install as Docker CLI Plugin

The MCP cli will already be installed on recent versions of Docker Desktop but you can buildand install the latest version by following these steps:

```bash
# Clone the repository
git clone https://github.com/docker/mcp-gateway.git
cd mcp-gateway
mkdir -p &quot;$HOME/.docker/cli-plugins/&quot;

# Build and install the plugin
make docker-mcp
```

After installation, the plugin will be available as:

```bash
docker mcp --help
```

## Usage

### Catalog Management

Manage the catalogs available to the MCP gateway. The [default catalog](https://hub.docker.com/mcp) is available with the name &#039;docker-mcp&#039;.

```bash
# Manage server catalogs
docker mcp catalog --help

# Initialize the default Docker MCP Catalog
docker mcp catalog init

# List available catalogs
docker mcp catalog ls

# Show all servers in a catalog
docker mcp catalog show docker-mcp
```

More about [the MCP Catalog](docs/catalog.md).

### MCP Gateway Operations

Start up an MCP Gateway. This can be used for one client, or to service multiple clients if using either `sse` or `streaming` transports.

```bash
# Run the MCP gateway (stdio)
docker mcp gateway run

# Run the MCP gateway (streaming)
docker mcp gateway run --port 8080 --transport streaming
```

More about [the MCP Gateway](docs/mcp-gateway.md).

### Server Management

Enable and disable the set of MCP servers that will be available for default clients. The MCP gateway can be configured to expose different sets of servers and tools but enabling and disabling servers here impacts the default gateway configuration.

```bash
# List enabled servers
docker mcp server list

# Enable one or more servers
docker mcp server enable &lt;server-name&gt; [server-name...]

# Disable servers
docker mcp server disable &lt;server-name&gt; [server-name...]

# Get detailed information about a server
docker mcp server inspect &lt;server-name&gt;

# Reset (disable all servers)
docker mcp server reset
```

### Configuration Management

Configure any MCP servers that require custom runtime configuration.

```bash
# Read current configuration
docker mcp config read

# Write new configuration
docker mcp config write &#039;&lt;yaml-config&gt;&#039;

# Reset configuration to defaults
docker mcp config reset
```

### Secrets and OAuth

Configure MCP servers that require either secrets or OAuth.

```bash
# Manage secrets
docker mcp secret --help

# Handle OAuth flows
docker mcp oauth --help

# Manage access policies
docker mcp policy --help

# export any desktop secrets needed by either server1 or server2
#   (temporary requirement to export secrets for docker cloud runs - this command
#    will no longer be required once Docker Cloud can access secret stores) 
docker mcp secret export server1 server2
```

### Tool Management

```bash
# Show available commands
docker mcp --help

# Count available tools
docker mcp tools count

# List all available MCP tools
docker mcp tools list

# List all available MCP tools in JSON format
docker mcp tools list --format=json

# Inspect a specific tool
docker mcp tools inspect &lt;tool-name&gt;

# Call a tool with arguments
docker mcp tools call &lt;tool-name&gt; [arguments...]
```

## Configuration

The MCP CLI uses several configuration files:

- **`docker-mcp.yaml`**: Server catalog defining available MCP servers
- **`registry.yaml`**: Registry of enabled servers
- **`config.yaml`**: Configuration per server
- **`tools.yaml`**: Enabled tools per server

Configuration files are typically stored in `~/.docker/mcp/`. This is in this directory that Docker Desktop&#039;s
MCP Toolkit with store its configuration.

## Architecture

The Docker MCP CLI implements a gateway pattern:

```
AI Client → MCP Gateway → MCP Servers (Docker Containers)
```

- **AI Client**: Language model or AI application
- **MCP Gateway**: This CLI tool managing protocol translation and routing
- **MCP Servers**: Individual MCP servers running in Docker containers

See [docs/message-flow.md](docs/message-flow.md) for detailed message flow diagrams.

## Contributing

The build instructions are available in the [contribution guide](CONTRIBUTING.md).

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Support

- 💬 [Troubleshooting](/docs/troubleshooting.md)
- 📖 [MCP Specification](https://spec.modelcontextprotocol.io/)
- 🐳 [Docker Desktop Documentation](https://docs.docker.com/desktop/)
- 🐛 [Report Issues](https://github.com/docker/mcp-gateway/issues)
- 💬 [Discussions](https://github.com/docker/mcp-gateway/discussions)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[docker/mcp-registry]]></title>
            <link>https://github.com/docker/mcp-registry</link>
            <guid>https://github.com/docker/mcp-registry</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[Official Docker MCP registry]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/docker/mcp-registry">docker/mcp-registry</a></h1>
            <p>Official Docker MCP registry</p>
            <p>Language: Go</p>
            <p>Stars: 210</p>
            <p>Forks: 278</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># 🐳 Official Docker MCP Registry

Welcome to the Official Docker MCP (Model Context Protocol) Registry! This repository serves as a curated catalog of MCP servers that can be easily discovered, deployed, and integrated with any MCP Client and compatible with Docker tooling. 

Entries in this catalog will be available at: 
- [MCP catalog](https://hub.docker.com/mcp) 
- [Docker Desktop&#039;s MCP Toolkit](https://www.docker.com/products/docker-desktop/) 
- [Docker Hub `mcp` namespace](https://hub.docker.com/u/mcp) (for MCP servers built by Docker)

## 🤖 What is MCP?
The Model Context Protocol (MCP) is an open standard that enables AI assistants to securely connect with external data sources and tools. Read more at [MCP Official Documentation](https://modelcontextprotocol.io/introduction).

## ✨ Why Use the Docker MCP Registry?
- **Enterprise Security**: MCP servers built by Docker include cryptographic signatures, provenance tracking, and Software Bills of Materials (SBOMs) for maximum trust and compliance
- **Container Isolation**: All MCP servers run in isolated containers, protecting your host system from potential security vulnerabilities
- **Curated Quality**: All MCP servers undergo review to ensure they meet quality and security standards
- **Easy Discovery**: Browse and find MCP servers for your specific use cases or share yours to millions of developers using Docker tools
- **Docker Integration**: Seamless deployment with Docker containers

## 🤝 Contributing to the Docker MCP Registry
We welcome contributions to the Official Docker MCP Registry! If you&#039;d like to contribute, you can submit a PR with the metadata information and it will be added to the [MCP catalog](https://hub.docker.com/mcp), to [Docker Desktop&#039;s MCP Toolkit](https://www.docker.com/products/docker-desktop/), and (for MCP servers images built by Docker) in `mcp` namespace in [Docker Hub](https://hub.docker.com/u/mcp).

To add your MCP server to the registry, please review the [CONTRIBUTING](CONTRIBUTING.md) guide for detailed instructions. We support two types of submissions:

### 🏗️ Option A: Docker-Built Image (Recommended)
Have Docker build and maintain your server image with enhanced security features. You&#039;ll submit the required information via pull request and upon approval Docker will build, sign, and publish your image to mcp/your-server-name on Docker Hub and the catalog entry will be available in the catalog in 24 hours.

_**Benefits: Your image will include cryptographic signatures, provenance tracking, SBOMs, and automatic security updates**_

### 📦 Option B: Self-Provided Pre-Built Image
In this option, you&#039;ll provide an already built image which will be used directly in the catalog. 

_**Note: Self-built images still benefit from container isolation but won&#039;t include the enhanced security features of Docker-built images.**_

## ✏️ Modifying or Removing Servers
To request modifications or removal of an existing MCP Server please open an issue explaining the reason for the edit/removal.

## ✅ Compliance and Quality Standards
All MCP servers in this registry must:
- Follow security best practices
- Include comprehensive documentation
- Provide working Docker deployment
- Maintain compatibility with MCP standards
- Include proper error handling and logging

_**Non-compliant servers will be reviewed and may be removed from the registry.**_

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grpc/grpc-go]]></title>
            <link>https://github.com/grpc/grpc-go</link>
            <guid>https://github.com/grpc/grpc-go</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[The Go language implementation of gRPC. HTTP/2 based RPC]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grpc/grpc-go">grpc/grpc-go</a></h1>
            <p>The Go language implementation of gRPC. HTTP/2 based RPC</p>
            <p>Language: Go</p>
            <p>Stars: 22,317</p>
            <p>Forks: 4,573</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre># gRPC-Go

[![GoDoc](https://pkg.go.dev/badge/google.golang.org/grpc)][API]
[![GoReportCard](https://goreportcard.com/badge/grpc/grpc-go)](https://goreportcard.com/report/github.com/grpc/grpc-go)
[![codecov](https://codecov.io/gh/grpc/grpc-go/graph/badge.svg)](https://codecov.io/gh/grpc/grpc-go)

The [Go][] implementation of [gRPC][]: A high performance, open source, general
RPC framework that puts mobile and HTTP/2 first. For more information see the
[Go gRPC docs][], or jump directly into the [quick start][].

## Prerequisites

- **[Go][]**: any one of the **two latest major** [releases][go-releases].

## Installation

Simply add the following import to your code, and then `go [build|run|test]`
will automatically fetch the necessary dependencies:


```go
import &quot;google.golang.org/grpc&quot;
```

&gt; **Note:** If you are trying to access `grpc-go` from **China**, see the
&gt; [FAQ](#FAQ) below.

## Learn more

- [Go gRPC docs][], which include a [quick start][] and [API
  reference][API] among other resources
- [Low-level technical docs](Documentation) from this repository
- [Performance benchmark][]
- [Examples](examples)
- [Contribution guidelines](CONTRIBUTING.md)

## FAQ

### I/O Timeout Errors

The `golang.org` domain may be blocked from some countries. `go get` usually
produces an error like the following when this happens:

```console
$ go get -u google.golang.org/grpc
package google.golang.org/grpc: unrecognized import path &quot;google.golang.org/grpc&quot; (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)
```

To build Go code, there are several options:

- Set up a VPN and access google.golang.org through that.

- With Go module support: it is possible to use the `replace` feature of `go
  mod` to create aliases for golang.org packages.  In your project&#039;s directory:

  ```sh
  go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest
  go mod tidy
  go mod vendor
  go build -mod=vendor
  ```

  Again, this will need to be done for all transitive dependencies hosted on
  golang.org as well. For details, refer to [golang/go issue
  #28652](https://github.com/golang/go/issues/28652).

### Compiling error, undefined: grpc.SupportPackageIsVersion

Please update to the latest version of gRPC-Go using
`go get google.golang.org/grpc`.

### How to turn on logging

The default logger is controlled by environment variables. Turn everything on
like this:

```console
$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99
$ export GRPC_GO_LOG_SEVERITY_LEVEL=info
```

### The RPC failed with error `&quot;code = Unavailable desc = transport is closing&quot;`

This error means the connection the RPC is using was closed, and there are many
possible reasons, including:
 1. mis-configured transport credentials, connection failed on handshaking
 1. bytes disrupted, possibly by a proxy in between
 1. server shutdown
 1. Keepalive parameters caused connection shutdown, for example if you have
    configured your server to terminate connections regularly to [trigger DNS
    lookups](https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779).
    If this is the case, you may want to increase your
    [MaxConnectionAgeGrace](https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters),
    to allow longer RPC calls to finish.

It can be tricky to debug this because the error happens on the client side but
the root cause of the connection being closed is on the server side. Turn on
logging on __both client and server__, and see if there are any transport
errors.

[API]: https://pkg.go.dev/google.golang.org/grpc
[Go]: https://golang.org
[Go module]: https://github.com/golang/go/wiki/Modules
[gRPC]: https://grpc.io
[Go gRPC docs]: https://grpc.io/docs/languages/go
[Performance benchmark]: https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608
[quick start]: https://grpc.io/docs/languages/go/quickstart
[go-releases]: https://golang.org/doc/devel/release.html
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[tailscale/tailscale]]></title>
            <link>https://github.com/tailscale/tailscale</link>
            <guid>https://github.com/tailscale/tailscale</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[The easiest, most secure way to use WireGuard and 2FA.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tailscale/tailscale">tailscale/tailscale</a></h1>
            <p>The easiest, most secure way to use WireGuard and 2FA.</p>
            <p>Language: Go</p>
            <p>Stars: 24,765</p>
            <p>Forks: 1,987</p>
            <p>Stars today: 31 stars today</p>
            <h2>README</h2><pre># Tailscale

https://tailscale.com

Private WireGuard® networks made easy

## Overview

This repository contains the majority of Tailscale&#039;s open source code.
Notably, it includes the `tailscaled` daemon and
the `tailscale` CLI tool. The `tailscaled` daemon runs on Linux, Windows,
[macOS](https://tailscale.com/kb/1065/macos-variants/), and to varying degrees
on FreeBSD and OpenBSD. The Tailscale iOS and Android apps use this repo&#039;s
code, but this repo doesn&#039;t contain the mobile GUI code.

Other [Tailscale repos](https://github.com/orgs/tailscale/repositories) of note:

* the Android app is at https://github.com/tailscale/tailscale-android
* the Synology package is at https://github.com/tailscale/tailscale-synology
* the QNAP package is at https://github.com/tailscale/tailscale-qpkg
* the Chocolatey packaging is at https://github.com/tailscale/tailscale-chocolatey

For background on which parts of Tailscale are open source and why,
see [https://tailscale.com/opensource/](https://tailscale.com/opensource/).

## Using

We serve packages for a variety of distros and platforms at
[https://pkgs.tailscale.com](https://pkgs.tailscale.com/).

## Other clients

The [macOS, iOS, and Windows clients](https://tailscale.com/download)
use the code in this repository but additionally include small GUI
wrappers. The GUI wrappers on non-open source platforms are themselves
not open source.

## Building

We always require the latest Go release, currently Go 1.23. (While we build
releases with our [Go fork](https://github.com/tailscale/go/), its use is not
required.)

```
go install tailscale.com/cmd/tailscale{,d}
```

If you&#039;re packaging Tailscale for distribution, use `build_dist.sh`
instead, to burn commit IDs and version info into the binaries:

```
./build_dist.sh tailscale.com/cmd/tailscale
./build_dist.sh tailscale.com/cmd/tailscaled
```

If your distro has conventions that preclude the use of
`build_dist.sh`, please do the equivalent of what it does in your
distro&#039;s way, so that bug reports contain useful version information.

## Bugs

Please file any issues about this code or the hosted service on
[the issue tracker](https://github.com/tailscale/tailscale/issues).

## Contributing

PRs welcome! But please file bugs. Commit messages should [reference
bugs](https://docs.github.com/en/github/writing-on-github/autolinked-references-and-urls).

We require [Developer Certificate of
Origin](https://en.wikipedia.org/wiki/Developer_Certificate_of_Origin)
`Signed-off-by` lines in commits.

See [commit-messages.md](docs/commit-messages.md) (or skim `git log`) for our commit message style.

## About Us

[Tailscale](https://tailscale.com/) is primarily developed by the
people at https://github.com/orgs/tailscale/people. For other contributors,
see:

* https://github.com/tailscale/tailscale/graphs/contributors
* https://github.com/tailscale/tailscale-android/graphs/contributors

## Legal

WireGuard is a registered trademark of Jason A. Donenfeld.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[opentofu/opentofu]]></title>
            <link>https://github.com/opentofu/opentofu</link>
            <guid>https://github.com/opentofu/opentofu</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[OpenTofu lets you declaratively manage your cloud infrastructure.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/opentofu/opentofu">opentofu/opentofu</a></h1>
            <p>OpenTofu lets you declaratively manage your cloud infrastructure.</p>
            <p>Language: Go</p>
            <p>Stars: 26,518</p>
            <p>Forks: 1,082</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># OpenTofu

- [HomePage](https://opentofu.org/)
- [How to install](https://opentofu.org/docs/intro/install)
- [Join our Slack community!](https://opentofu.org/slack)

![](https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-dark.svg#gh-dark-mode-only)
![](https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-light.svg#gh-light-mode-only)

[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10508/badge)](https://www.bestpractices.dev/projects/10508)

OpenTofu is an OSS tool for building, changing, and versioning infrastructure safely and efficiently. OpenTofu can manage existing and popular service providers as well as custom in-house solutions.

The key features of OpenTofu are:

- **Infrastructure as Code**: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.

- **Execution Plans**: OpenTofu has a &quot;planning&quot; step where it generates an execution plan. The execution plan shows what OpenTofu will do when you call apply. This lets you avoid any surprises when OpenTofu manipulates infrastructure.

- **Resource Graph**: OpenTofu builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, OpenTofu builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.

- **Change Automation**: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what OpenTofu will change and in what order, avoiding many possible human errors.

## Getting help and contributing

- Have a question?
  - Post it in [GitHub Discussions](https://github.com/orgs/opentofu/discussions)
  - Open a [GitHub issue](https://github.com/opentofu/opentofu/issues/new/choose)
  - Join the [OpenTofu Slack](https://opentofu.org/slack/)!
- Want to contribute?
  - Please read the [Contribution Guide](CONTRIBUTING.md).
- Recurring Events
  - [Community Meetings](https://meet.google.com/xfm-cgms-has) on Wednesdays at 12:30 UTC at this link: https://meet.google.com/xfm-cgms-has ([📅 calendar link](https://calendar.google.com/calendar/event?eid=NDg0aWl2Y3U1aHFva3N0bGhyMHBhNzdpZmsgY18zZjJkZDNjMWZlMGVmNGU5M2VmM2ZjNDU2Y2EyZGQyMTlhMmU4ZmQ4NWY2YjQwNzUwYWYxNmMzZGYzNzBiZjkzQGc))
  - [Technical Steering Committee Meetings](https://meet.google.com/cry-houa-qbk) every other Tuesday at 4pm UTC at this link: https://meet.google.com/cry-houa-qbk ([📅 calendar link](https://calendar.google.com/calendar/u/0/event?eid=M3JyMWtuYWptdXI0Zms4ZnJpNmppcDczb3RfMjAyNTA1MjdUMTYwMDAwWiBjXzNmMmRkM2MxZmUwZWY0ZTkzZWYzZmM0NTZjYTJkZDIxOWEyZThmZDg1ZjZiNDA3NTBhZjE2YzNkZjM3MGJmOTNAZw))

&gt; [!TIP]
&gt; For more OpenTofu events, subscribe to the [OpenTofu Events Calendar](https://calendar.google.com/calendar/embed?src=c_3f2dd3c1fe0ef4e93ef3fc456ca2dd219a2e8fd85f6b40750af16c3df370bf93%40group.calendar.google.com)!

## Reporting security vulnerabilities
If you&#039;ve found a vulnerability or a potential vulnerability in OpenTofu please follow [Security Policy](https://github.com/opentofu/opentofu/security/policy). We&#039;ll send a confirmation email to acknowledge your report, and we&#039;ll send an additional email when we&#039;ve identified the issue positively or negatively.

## Reporting possible copyright issues

If you believe you have found any possible copyright or intellectual property issues, please contact liaison@opentofu.org. We&#039;ll send a confirmation email to acknowledge your report.

## Registry Access

In an effort to comply with applicable sanctions, we block access from specific countries of origin.

## License

[Mozilla Public License v2.0](https://github.com/opentofu/opentofu/blob/main/LICENSE)

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ccfos/nightingale]]></title>
            <link>https://github.com/ccfos/nightingale</link>
            <guid>https://github.com/ccfos/nightingale</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[Nightingale for monitoring and alerting, just as Grafana for visualization.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ccfos/nightingale">ccfos/nightingale</a></h1>
            <p>Nightingale for monitoring and alerting, just as Grafana for visualization.</p>
            <p>Language: Go</p>
            <p>Stars: 12,165</p>
            <p>Forks: 1,606</p>
            <p>Stars today: 62 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/ccfos/nightingale&quot;&gt;
    &lt;img src=&quot;doc/img/Nightingale_L_V.png&quot; alt=&quot;nightingale - cloud native monitoring&quot; width=&quot;100&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Open-Source Alerting Expert&lt;/b&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://flashcat.cloud/docs/&quot;&gt;
  &lt;img alt=&quot;Docs&quot; src=&quot;https://img.shields.io/badge/docs-get%20started-brightgreen&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://hub.docker.com/u/flashcatcloud&quot;&gt;
  &lt;img alt=&quot;Docker pulls&quot; src=&quot;https://img.shields.io/docker/pulls/flashcatcloud/nightingale&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ccfos/nightingale/graphs/contributors&quot;&gt;
  &lt;img alt=&quot;GitHub contributors&quot; src=&quot;https://img.shields.io/github/contributors-anon/ccfos/nightingale&quot;/&gt;&lt;/a&gt;
&lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/ccfos/nightingale&quot;&gt;
&lt;img alt=&quot;GitHub forks&quot; src=&quot;https://img.shields.io/github/forks/ccfos/nightingale&quot;&gt;
&lt;br/&gt;&lt;img alt=&quot;GitHub Repo issues&quot; src=&quot;https://img.shields.io/github/issues/ccfos/nightingale&quot;&gt;
&lt;img alt=&quot;GitHub Repo issues closed&quot; src=&quot;https://img.shields.io/github/issues-closed/ccfos/nightingale&quot;&gt;
&lt;img alt=&quot;GitHub latest release&quot; src=&quot;https://img.shields.io/github/v/release/ccfos/nightingale&quot;/&gt;
&lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/license-Apache--2.0-blue&quot;/&gt;
&lt;a href=&quot;https://n9e-talk.slack.com/&quot;&gt;
  &lt;img alt=&quot;GitHub contributors&quot; src=&quot;https://img.shields.io/badge/join%20slack-%23n9e-brightgreen.svg&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;



[English](./README.md) | [中文](./README_zh.md)

## 🎯 What is Nightingale

Nightingale is an open-source monitoring project that focuses on alerting. Similar to Grafana, Nightingale also connects with various existing data sources. However, while Grafana emphasizes visualization, Nightingale places greater emphasis on the alerting engine, as well as the processing and distribution of alarms.

&gt; The Nightingale project was initially developed and open-sourced by DiDi.inc. On May 11, 2022, it was donated to the Open Source Development Committee of the China Computer Federation (CCF ODC).

![](https://n9e.github.io/img/global/arch-bg.png)

## 💡 How Nightingale Works

Many users have already collected metrics and log data. In this case, you can connect your storage repositories (such as VictoriaMetrics, ElasticSearch, etc.) as data sources in Nightingale. This allows you to configure alerting rules and notification rules within Nightingale, enabling the generation and distribution of alarms.

![Nightingale Product Architecture](doc/img/readme/20240221152601.png)

Nightingale itself does not provide monitoring data collection capabilities. We recommend using [Categraf](https://github.com/flashcatcloud/categraf) as the collector, which integrates seamlessly with Nightingale.

[Categraf](https://github.com/flashcatcloud/categraf) can collect monitoring data from operating systems, network devices, various middleware, and databases. It pushes this data to Nightingale via the `Prometheus Remote Write` protocol. Nightingale then stores the monitoring data in a time-series database (such as Prometheus, VictoriaMetrics, etc.) and provides alerting and visualization capabilities.

For certain edge data centers with poor network connectivity to the central Nightingale server, we offer a distributed deployment mode for the alerting engine. In this mode, even if the network is disconnected, the alerting functionality remains unaffected.

![Edge Deployment Mode](doc/img/readme/20240222102119.png)

&gt; In the above diagram, Data Center A has a good network with the central data center, so it uses the Nightingale process in the central data center as the alerting engine. Data Center B has a poor network with the central data center, so it deploys `n9e-edge` as the alerting engine to handle alerting for its own data sources.

## 🔕 Alert Noise Reduction, Escalation, and Collaboration

Nightingale focuses on being an alerting engine, responsible for generating alarms and flexibly distributing them based on rules. It supports 20 built-in notification medias (such as phone calls, SMS, email, DingTalk, Slack, etc.).

If you have more advanced requirements, such as:
- Want to consolidate events from multiple monitoring systems into one platform for unified noise reduction, response handling, and data analysis.
- Want to support personnel scheduling, practice on-call culture, and support alert escalation (to avoid missing alerts) and collaborative handling.

Then Nightingale is not suitable. It is recommended that you choose on-call products such as PagerDuty and FlashDuty. These products are simple and easy to use.

## 🗨️ Communication Channels

- **Report Bugs:** It is highly recommended to submit issues via the [Nightingale GitHub Issue tracker](https://github.com/ccfos/nightingale/issues/new?assignees=&amp;labels=kind%2Fbug&amp;projects=&amp;template=bug_report.yml).
- **Documentation:** For more information, we recommend thoroughly browsing the [Nightingale Documentation Site](https://n9e.github.io/).

## 🔑 Key Features

![Nightingale Alerting rules](doc/img/readme/2025-05-23_18-43-37.png)

- Nightingale supports alerting rules, mute rules, subscription rules, and notification rules. It natively supports 20 types of notification media and allows customization of message templates.  
- It supports event pipelines for Pipeline processing of alarms, facilitating automated integration with in-house systems. For example, it can append metadata to alarms or perform relabeling on events. 
- It introduces the concept of business groups and a permission system to manage various rules in a categorized manner.  
- Many databases and middleware come with built-in alert rules that can be directly imported and used. It also supports direct import of Prometheus alerting rules.  
- It supports alerting self-healing, which automatically triggers a script to execute predefined logic after an alarm is generated—such as cleaning up disk space or capturing the current system state.

![Nightingale Alarm Dashboard](doc/img/readme/2025-05-30_08-49-28.png)

- Nightingale archives historical alarms and supports multi-dimensional query and statistics.  
- It supports flexible aggregation grouping, allowing a clear view of the distribution of alarms across the company.

![Nightingale Integration Center](doc/img/readme/2025-05-23_18-46-06.png)

- Nightingale has built-in metric descriptions, dashboards, and alerting rules for common operating systems, middleware, and databases, which are contributed by the community with varying quality.  
- It directly receives data via multiple protocols such as Remote Write, OpenTSDB, Datadog, and Falcon, integrates with various Agents.  
- It supports data sources like Prometheus, ElasticSearch, Loki, ClickHouse, MySQL, Postgres, allowing alerting based on data from these sources.  
- Nightingale can be easily embedded into internal enterprise systems (e.g. Grafana, CMDB), and even supports configuring menu visibility for these embedded systems.

![Nightingale dashboards](doc/img/readme/2025-05-23_18-49-02.png)

- Nightingale supports dashboard functionality, including common chart types, and comes with pre-built dashboards. The image above is a screenshot of one of these dashboards.  
- If you are already accustomed to Grafana, it is recommended to continue using Grafana for visualization, as Grafana has deeper expertise in this area.  
- For machine-related monitoring data collected by Categraf, it is advisable to use Nightingale&#039;s built-in dashboards for viewing. This is because Categraf&#039;s metric naming follows Telegraf&#039;s convention, which differs from that of Node Exporter.  
- Due to Nightingale&#039;s concept of business groups (where machines can belong to different groups), there may be scenarios where you only want to view machines within the current business group on the dashboard. Thus, Nightingale&#039;s dashboards can be linked with business groups for interactive filtering.

## 🌟 Stargazers over time

[![Stargazers over time](https://api.star-history.com/svg?repos=ccfos/nightingale&amp;type=Date)](https://star-history.com/#ccfos/nightingale&amp;Date)

## 🔥 Users

![User Logos](doc/img/readme/logos.png)

## 🤝 Community Co-Building

- ❇️ Please read the [Nightingale Open Source Project and Community Governance Draft](./doc/community-governance.md). We sincerely welcome every user, developer, company, and organization to use Nightingale, actively report bugs, submit feature requests, share best practices, and help build a professional and active open-source community.
- ❤️ Nightingale Contributors
&lt;a href=&quot;https://github.com/ccfos/nightingale/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=ccfos/nightingale&quot; /&gt;
&lt;/a&gt;

## 📜 License
- [Apache License V2.0](https://github.com/didi/nightingale/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[FiloSottile/age]]></title>
            <link>https://github.com/FiloSottile/age</link>
            <guid>https://github.com/FiloSottile/age</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[A simple, modern and secure encryption tool (and Go library) with small explicit keys, no config options, and UNIX-style composability.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/FiloSottile/age">FiloSottile/age</a></h1>
            <p>A simple, modern and secure encryption tool (and Go library) with small explicit keys, no config options, and UNIX-style composability.</p>
            <p>Language: Go</p>
            <p>Stars: 19,694</p>
            <p>Forks: 574</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/FiloSottile/age/blob/main/logo/logo_white.svg&quot;&gt;
        &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/FiloSottile/age/blob/main/logo/logo.svg&quot;&gt;
        &lt;img alt=&quot;The age logo, a wireframe of St. Peters dome in Rome, with the text: age, file encryption&quot; width=&quot;600&quot; src=&quot;https://github.com/FiloSottile/age/blob/main/logo/logo.svg&quot;&gt;
    &lt;/picture&gt;
&lt;/p&gt;

[![Go Reference](https://pkg.go.dev/badge/filippo.io/age.svg)](https://pkg.go.dev/filippo.io/age)
[![man page](&lt;https://img.shields.io/badge/age(1)-man%20page-lightgrey&gt;)](https://filippo.io/age/age.1)
[![C2SP specification](https://img.shields.io/badge/%C2%A7%23-specification-blueviolet)](https://age-encryption.org/v1)

age is a simple, modern and secure file encryption tool, format, and Go library.

It features small explicit keys, no config options, and UNIX-style composability.

```
$ age-keygen -o key.txt
Public key: age1ql3z7hjy54pw3hyww5ayyfg7zqgvc7w3j2elw8zmrj2kg5sfn9aqmcac8p
$ tar cvz ~/data | age -r age1ql3z7hjy54pw3hyww5ayyfg7zqgvc7w3j2elw8zmrj2kg5sfn9aqmcac8p &gt; data.tar.gz.age
$ age --decrypt -i key.txt data.tar.gz.age &gt; data.tar.gz
```

📜 The format specification is at [age-encryption.org/v1](https://age-encryption.org/v1). age was designed by [@benjojo](https://github.com/benjojo) and [@FiloSottile](https://github.com/FiloSottile).

🦀 An alternative interoperable Rust implementation is available at [github.com/str4d/rage](https://github.com/str4d/rage).

🌍 [Typage](https://github.com/FiloSottile/typage) is a TypeScript implementation. It works in the browser, in Node.js, and in Bun.

🔑 Hardware PIV tokens such as YubiKeys are supported through the [age-plugin-yubikey](https://github.com/str4d/age-plugin-yubikey) plugin.

✨ For more plugins, implementations, tools, and integrations, check out the [awesome age](https://github.com/FiloSottile/awesome-age) list.

💬 The author pronounces it `[aɡe̞]` [with a hard *g*](https://translate.google.com/?sl=it&amp;text=aghe), like GIF, and is always spelled lowercase.

## Installation

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;Homebrew (macOS or Linux)&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;brew install age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;MacPorts&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;port install age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Windows&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;winget install --id FiloSottile.age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Alpine Linux v3.15+&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;apk add age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Arch Linux&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;pacman -S age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Debian 12+ (Bookworm)&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;apt install age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Debian 11 (Bullseye)&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;apt install age/bullseye-backports&lt;/code&gt;
            (&lt;a href=&quot;https://backports.debian.org/Instructions/#index2h2&quot;&gt;enable backports&lt;/a&gt; for age v1.0.0+)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Fedora 33+&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;dnf install age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Gentoo Linux&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;emerge app-crypt/age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;NixOS / Nix&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;nix-env -i age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;openSUSE Tumbleweed&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;zypper install age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Ubuntu 22.04+&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;apt install age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Void Linux&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;xbps-install age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;FreeBSD&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;pkg install age&lt;/code&gt; (security/age)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;OpenBSD 6.7+&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;pkg_add age&lt;/code&gt; (security/age)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Chocolatey (Windows)&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;choco install age.portable&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Scoop (Windows)&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;scoop bucket add extras &amp;&amp; scoop install age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;pkgx&lt;/td&gt;
        &lt;td&gt;
            &lt;code&gt;pkgx install age&lt;/code&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

On Windows, Linux, macOS, and FreeBSD you can use the pre-built binaries.

```
https://dl.filippo.io/age/latest?for=linux/amd64
https://dl.filippo.io/age/v1.1.1?for=darwin/arm64
...
```

If your system has [a supported version of Go](https://go.dev/dl/), you can build from source.

```
go install filippo.io/age/cmd/...@latest
```

Help from new packagers is very welcome.

### Verifying the release signatures

If you download the pre-built binaries, you can check their
[Sigsum](https://www.sigsum.org) proofs, which are like signatures with extra
transparency: you can cryptographically verify that every proof is logged in a
public append-only log, so you can hold the age project accountable for every
binary release we ever produced. This is similar to what the [Go Checksum
Database](https://go.dev/blog/module-mirror-launch) provides.

```
cat &lt;&lt; EOF &gt; age-sigsum-key.pub
ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIM1WpnEswJLPzvXJDiswowy48U+G+G1kmgwUE2eaRHZG
ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAz2WM5CyPLqiNjk7CLl4roDXwKhQ0QExXLebukZEZFS
EOF
cat &lt;&lt; EOF &gt; sigsum-trust-policy.txt
log 154f49976b59ff09a123675f58cb3e346e0455753c3c3b15d465dcb4f6512b0b https://poc.sigsum.org/jellyfish
witness poc.sigsum.org/nisse 1c25f8a44c635457e2e391d1efbca7d4c2951a0aef06225a881e46b98962ac6c
witness rgdd.se/poc-witness  28c92a5a3a054d317c86fc2eeb6a7ab2054d6217100d0be67ded5b74323c5806
group  demo-quorum-rule all poc.sigsum.org/nisse rgdd.se/poc-witness
quorum demo-quorum-rule
EOF

curl -JLO &quot;https://dl.filippo.io/age/v1.2.0?for=darwin/arm64&quot;
curl -JLO &quot;https://dl.filippo.io/age/v1.2.0?for=darwin/arm64&amp;proof&quot;

go install sigsum.org/sigsum-go/cmd/sigsum-verify@v0.8.0
sigsum-verify -k age-sigsum-key.pub -p sigsum-trust-policy.txt \
    age-v1.2.0-darwin-arm64.tar.gz.proof &lt; age-v1.2.0-darwin-arm64.tar.gz
```

You can learn more about what&#039;s happening above in the [Sigsum
docs](https://www.sigsum.org/getting-started/).

## Usage

For the full documentation, read [the age(1) man page](https://filippo.io/age/age.1).

```
Usage:
    age [--encrypt] (-r RECIPIENT | -R PATH)... [--armor] [-o OUTPUT] [INPUT]
    age [--encrypt] --passphrase [--armor] [-o OUTPUT] [INPUT]
    age --decrypt [-i PATH]... [-o OUTPUT] [INPUT]

Options:
    -e, --encrypt               Encrypt the input to the output. Default if omitted.
    -d, --decrypt               Decrypt the input to the output.
    -o, --output OUTPUT         Write the result to the file at path OUTPUT.
    -a, --armor                 Encrypt to a PEM encoded format.
    -p, --passphrase            Encrypt with a passphrase.
    -r, --recipient RECIPIENT   Encrypt to the specified RECIPIENT. Can be repeated.
    -R, --recipients-file PATH  Encrypt to recipients listed at PATH. Can be repeated.
    -i, --identity PATH         Use the identity file at PATH. Can be repeated.

INPUT defaults to standard input, and OUTPUT defaults to standard output.
If OUTPUT exists, it will be overwritten.

RECIPIENT can be an age public key generated by age-keygen (&quot;age1...&quot;)
or an SSH public key (&quot;ssh-ed25519 AAAA...&quot;, &quot;ssh-rsa AAAA...&quot;).

Recipient files contain one or more recipients, one per line. Empty lines
and lines starting with &quot;#&quot; are ignored as comments. &quot;-&quot; may be used to
read recipients from standard input.

Identity files contain one or more secret keys (&quot;AGE-SECRET-KEY-1...&quot;),
one per line, or an SSH key. Empty lines and lines starting with &quot;#&quot; are
ignored as comments. Passphrase encrypted age files can be used as
identity files. Multiple key files can be provided, and any unused ones
will be ignored. &quot;-&quot; may be used to read identities from standard input.

When --encrypt is specified explicitly, -i can also be used to encrypt to an
identity file symmetrically, instead or in addition to normal recipients.
```

### Multiple recipients

Files can be encrypted to multiple recipients by repeating `-r/--recipient`. Every recipient will be able to decrypt the file.

```
$ age -o example.jpg.age -r age1ql3z7hjy54pw3hyww5ayyfg7zqgvc7w3j2elw8zmrj2kg5sfn9aqmcac8p \
    -r age1lggyhqrw2nlhcxprm67z43rta597azn8gknawjehu9d9dl0jq3yqqvfafg example.jpg
```

#### Recipient files

Multiple recipients can also be listed one per line in one or more files passed with the `-R/--recipients-file` flag.

```
$ cat recipients.txt
# Alice
age1ql3z7hjy54pw3hyww5ayyfg7zqgvc7w3j2elw8zmrj2kg5sfn9aqmcac8p
# Bob
age1lggyhqrw2nlhcxprm67z43rta597azn8gknawjehu9d9dl0jq3yqqvfafg
$ age -R recipients.txt example.jpg &gt; example.jpg.age
```

If the argument to `-R` (or `-i`) is `-`, the file is read from standard input.

### Passphrases

Files can be encrypted with a passphrase by using `-p/--passphrase`. By default age will automatically generate a secure passphrase. Passphrase protected files are automatically detected at decrypt time.

```
$ age -p secrets.txt &gt; secrets.txt.age
Enter passphrase (leave empty to autogenerate a secure one):
Using the autogenerated passphrase &quot;release-response-step-brand-wrap-ankle-pair-unusual-sword-train&quot;.
$ age -d secrets.txt.age &gt; secrets.txt
Enter passphrase:
```

### Passphrase-protected key files

If an identity file passed to `-i` is a passphrase encrypted age file, it will be automatically decrypted.

```
$ age-keygen | age -p &gt; key.age
Public key: age1yhm4gctwfmrpz87tdslm550wrx6m79y9f2hdzt0lndjnehwj0ukqrjpyx5
Enter passphrase (leave empty to autogenerate a secure one):
Using the autogenerated passphrase &quot;hip-roast-boring-snake-mention-east-wasp-honey-input-actress&quot;.
$ age -r age1yhm4gctwfmrpz87tdslm550wrx6m79y9f2hdzt0lndjnehwj0ukqrjpyx5 secrets.txt &gt; secrets.txt.age
$ age -d -i key.age secrets.txt.age &gt; secrets.txt
Enter passphrase for identity file &quot;key.age&quot;:
```

Passphrase-protected identity files are not necessary for most use cases, where access to the encrypted identity file implies access to the whole system. However, they can be useful if the identity file is stored remotely.

### SSH keys

As a convenience feature, age also supports encrypting to `ssh-rsa` and `ssh-ed25519` SSH public keys, and decrypting with the respective private key file. (`ssh-agent` is not supported.)

```
$ age -R ~/.ssh/id_ed25519.pub example.jpg &gt; example.jpg.age
$ age -d -i ~/.ssh/id_ed25519 example.jpg.age &gt; example.jpg
```

Note that SSH key support employs more complex cryptography, and embeds a public key tag in the encrypted file, making it possible to track files that are encrypted to a specific public key.

#### Encrypting to a GitHub user

Combining SSH key support and `-R`, you can easily encrypt a file to the SSH keys listed on a GitHub profile.

```
$ curl https://github.com/benjojo.keys | age -R - example.jpg &gt; example.jpg.age
```

Keep in mind that people might not protect SSH keys long-term, since they are revokable when used only for authentication, and that SSH keys held on YubiKeys can&#039;t be used to decrypt files.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[livekit/livekit]]></title>
            <link>https://github.com/livekit/livekit</link>
            <guid>https://github.com/livekit/livekit</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[End-to-end realtime stack for connecting humans and AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/livekit/livekit">livekit/livekit</a></h1>
            <p>End-to-end realtime stack for connecting humans and AI</p>
            <p>Language: Go</p>
            <p>Stars: 14,794</p>
            <p>Forks: 1,394</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>&lt;!--BEGIN_BANNER_IMAGE--&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;/.github/banner_dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;/.github/banner_light.png&quot;&gt;
  &lt;img style=&quot;width:100%;&quot; alt=&quot;The LiveKit icon, the name of the repository and some sample code in the background.&quot; src=&quot;https://raw.githubusercontent.com/livekit/livekit/main/.github/banner_light.png&quot;&gt;
&lt;/picture&gt;

&lt;!--END_BANNER_IMAGE--&gt;

# LiveKit: Real-time video, audio and data for developers

[LiveKit](https://livekit.io) is an open source project that provides scalable, multi-user conferencing based on WebRTC.
It&#039;s designed to provide everything you need to build real-time video audio data capabilities in your applications.

LiveKit&#039;s server is written in Go, using the awesome [Pion WebRTC](https://github.com/pion/webrtc) implementation.

[![GitHub stars](https://img.shields.io/github/stars/livekit/livekit?style=social&amp;label=Star&amp;maxAge=2592000)](https://github.com/livekit/livekit/stargazers/)
[![Slack community](https://img.shields.io/endpoint?url=https%3A%2F%2Flivekit.io%2Fbadges%2Fslack)](https://livekit.io/join-slack)
[![Twitter Follow](https://img.shields.io/twitter/follow/livekit)](https://twitter.com/livekit)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/livekit/livekit)
[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/livekit/livekit)](https://github.com/livekit/livekit/releases/latest)
[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/livekit/livekit/buildtest.yaml?branch=master)](https://github.com/livekit/livekit/actions/workflows/buildtest.yaml)
[![License](https://img.shields.io/github/license/livekit/livekit)](https://github.com/livekit/livekit/blob/master/LICENSE)

## Features

-   Scalable, distributed WebRTC SFU (Selective Forwarding Unit)
-   Modern, full-featured client SDKs
-   Built for production, supports JWT authentication
-   Robust networking and connectivity, UDP/TCP/TURN
-   Easy to deploy: single binary, Docker or Kubernetes
-   Advanced features including:
    -   [speaker detection](https://docs.livekit.io/home/client/tracks/subscribe/#speaker-detection)
    -   [simulcast](https://docs.livekit.io/home/client/tracks/publish/#video-simulcast)
    -   [end-to-end optimizations](https://blog.livekit.io/livekit-one-dot-zero/)
    -   [selective subscription](https://docs.livekit.io/home/client/tracks/subscribe/#selective-subscription)
    -   [moderation APIs](https://docs.livekit.io/home/server/managing-participants/)
    -   end-to-end encryption
    -   SVC codecs (VP9, AV1)
    -   [webhooks](https://docs.livekit.io/home/server/webhooks/)
    -   [distributed and multi-region](https://docs.livekit.io/home/self-hosting/distributed/)

## Documentation &amp; Guides

https://docs.livekit.io

## Live Demos

-   [LiveKit Meet](https://meet.livekit.io) ([source](https://github.com/livekit-examples/meet))
-   [Spatial Audio](https://spatial-audio-demo.livekit.io/) ([source](https://github.com/livekit-examples/spatial-audio))
-   Livestreaming from OBS Studio ([source](https://github.com/livekit-examples/livestream))
-   [AI voice assistant using ChatGPT](https://livekit.io/kitt) ([source](https://github.com/livekit-examples/kitt))

## Ecosystem

-   [Agents](https://github.com/livekit/agents): build real-time multimodal AI applications with programmable backend participants
-   [Egress](https://github.com/livekit/egress): record or multi-stream rooms and export individual tracks
-   [Ingress](https://github.com/livekit/ingress): ingest streams from external sources like RTMP, WHIP, HLS, or OBS Studio

## SDKs &amp; Tools

### Client SDKs

Client SDKs enable your frontend to include interactive, multi-user experiences.

&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;Language&lt;/th&gt;
    &lt;th&gt;Repo&lt;/th&gt;
    &lt;th&gt;
        &lt;a href=&quot;https://docs.livekit.io/home/client/events/#declarative-ui&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Declarative UI&lt;/a&gt;
    &lt;/th&gt;
    &lt;th&gt;Links&lt;/th&gt;
  &lt;/tr&gt;
  &lt;!-- BEGIN Template
  &lt;tr&gt;
    &lt;td&gt;Language&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  END --&gt;
  &lt;!-- JavaScript --&gt;
  &lt;tr&gt;
    &lt;td&gt;JavaScript (TypeScript)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-js&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-js&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/livekit-react&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;React&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-js/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-js/tree/main/example&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;JS example&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-js/tree/main/example&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;React example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Swift --&gt;
  &lt;tr&gt;
    &lt;td&gt;Swift (iOS / MacOS)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-swift&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-swift&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;Swift UI&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-swift/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-example-swift&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Kotlin --&gt;
  &lt;tr&gt;
    &lt;td&gt;Kotlin (Android)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-android&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-android&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;Compose&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-android/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-android/tree/main/sample-app/src/main/java/io/livekit/android/sample&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;example&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-android/tree/main/sample-app-compose/src/main/java/io/livekit/android/composesample&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Compose example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;!-- Flutter --&gt;
  &lt;tr&gt;
    &lt;td&gt;Flutter (all platforms)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-flutter&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;native&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-flutter/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter/tree/main/example&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Unity --&gt;
  &lt;tr&gt;
    &lt;td&gt;Unity WebGL&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-unity-web&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-unity-web&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://livekit.github.io/client-sdk-unity-web/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- React Native --&gt;
  &lt;tr&gt;
    &lt;td&gt;React Native (beta)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-react-native&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-react-native&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;native&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Rust --&gt;
  &lt;tr&gt;
    &lt;td&gt;Rust&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-rust&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-rust&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

### Server SDKs

Server SDKs enable your backend to generate [access tokens](https://docs.livekit.io/home/get-started/authentication/),
call [server APIs](https://docs.livekit.io/reference/server/server-apis/), and
receive [webhooks](https://docs.livekit.io/home/server/webhooks/). In addition, the Go SDK includes client capabilities,
enabling you to build automations that behave like end-users.

| Language                | Repo                                                                                    | Docs                                                        |
| :---------------------- | :-------------------------------------------------------------------------------------- | :---------------------------------------------------------- |
| Go                      | [server-sdk-go](https://github.com/livekit/server-sdk-go)                               | [docs](https://pkg.go.dev/github.com/livekit/server-sdk-go) |
| JavaScript (TypeScript) | [server-sdk-js](https://github.com/livekit/server-sdk-js)                               | [docs](https://docs.livekit.io/server-sdk-js/)              |
| Ruby                    | [server-sdk-ruby](https://github.com/livekit/server-sdk-ruby)                           |                                                             |
| Java (Kotlin)           | [server-sdk-kotlin](https://github.com/livekit/server-sdk-kotlin)                       |                                                             |
| Python (community)      | [python-sdks](https://github.com/livekit/python-sdks)                                   |                                                             |
| PHP (community)         | [agence104/livekit-server-sdk-php](https://github.com/agence104/livekit-server-sdk-php) |                                                             |

### Tools

-   [CLI](https://github.com/livekit/livekit-cli) - command line interface &amp; load tester
-   [Docker image](https://hub.docker.com/r/livekit/livekit-server)
-   [Helm charts](https://github.com/livekit/livekit-helm)

## Install

&gt; [!TIP]
&gt; We recommend installing [LiveKit CLI](https://github.com/livekit/livekit-cli) along with the server. It lets you access
&gt; server APIs, create tokens, and generate test traffic.

The following will install LiveKit&#039;s media server:

### MacOS

```shell
brew install livekit
```

### Linux

```shell
curl -sSL https://get.livekit.io | bash
```

### Windows

Download the [latest release here](https://github.com/livekit/livekit/releases/latest)

## Getting Started

### Starting LiveKit

Start LiveKit in development mode by running `livekit-server --dev`. It&#039;ll use a placeholder API key/secret pair.

```
API Key: devkey
API Secret: secret
```

To customize your setup for production, refer to our [deployment docs](https://docs.livekit.io/deploy/)

### Creating access token

A user connecting to a LiveKit room requires an [access token](https://docs.livekit.io/home/get-started/authentication/#creating-a-token). Access
tokens (JWT) encode the user&#039;s identity and the room permissions they&#039;ve been granted. You can generate a token with our
CLI:

```shell
lk token create \
    --api-key devkey --api-secret secret \
    --join --room my-first-room --identity user1 \
    --valid-for 24h
```

### Test with example app

Head over to our [example app](https://example.livekit.io) and enter a generated token to connect to your LiveKit
server. This app is built with our [React SDK](https://github.com/livekit/livekit-react).

Once connected, your video and audio are now being published to your new LiveKit instance!

### Simulating a test publisher

```shell
lk room join \
    --url ws://localhost:7880 \
    --api-key devkey --api-secret secret \
    --identity bot-user1 \
    --publish-demo \
    my-first-room
```

This command publishes a looped demo video to a room. Due to how the video clip was encoded (keyframes every 3s),
there&#039;s a slight delay before the browser has sufficient data to begin rendering frames. This is an artifact of the
simulation.

## Deployment

### Use LiveKit Cloud

LiveKit Cloud is the fastest and most reliable way to run LiveKit. Every project gets free monthly bandwidth and
transcoding credits.

Sign up for [LiveKit Cloud](https://cloud.livekit.io/).

### Self-host

Read our [deployment docs](https://docs.livekit.io/deploy/) for more information.

## Building from source

Pre-requisites:

-   Go 1.23+ is installed
-   GOPATH/bin is in your PATH

Then run

```shell
git clone https://github.com/livekit/livekit
cd livekit
./bootstrap.sh
mage
```

## Contributing

We welcome your contributions toward improving LiveKit! Please join us
[on Slack](http://livekit.io/join-slack) to discuss your ideas and/or PRs.

## License

LiveKit server is licensed under Apache License v2.0.

&lt;!--BEGIN_REPO_NAV--&gt;
&lt;br/&gt;&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;LiveKit Ecosystem&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;LiveKit SDKs&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/client-sdk-js&quot;&gt;Browser&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-swift&quot;&gt;iOS/macOS/visionOS&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-android&quot;&gt;Android&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter&quot;&gt;Flutter&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-react-native&quot;&gt;React Native&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/rust-sdks&quot;&gt;Rust&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/node-sdks&quot;&gt;Node.js&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/python-sdks&quot;&gt;Python&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-unity&quot;&gt;Unity&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-unity-web&quot;&gt;Unity (WebGL)&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-esp32&quot;&gt;ESP32&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Server APIs&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/node-sdks&quot;&gt;Node.js&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/server-sdk-go&quot;&gt;Golang&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/server-sdk-ruby&quot;&gt;Ruby&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/server-sdk-kotlin&quot;&gt;Java/Kotlin&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/python-sdks&quot;&gt;Python&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/rust-sdks&quot;&gt;Rust&lt;/a&gt; · &lt;a href=&quot;https://github.com/agence104/livekit-server-sdk-php&quot;&gt;PHP (community)&lt;/a&gt; · &lt;a href=&quot;https://github.com/pabloFuente/livekit-server-sdk-dotnet&quot;&gt;.NET (community)&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;UI Components&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/components-js&quot;&gt;React&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/components-android&quot;&gt;Android Compose&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/components-swift&quot;&gt;SwiftUI&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/components-flutter&quot;&gt;Flutter&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Agents Frameworks&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/agents&quot;&gt;Python&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/agents-js&quot;&gt;Node.js&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/agent-playground&quot;&gt;Playground&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Services&lt;/td&gt;&lt;td&gt;&lt;b&gt;LiveKit server&lt;/b&gt; · &lt;a href=&quot;https://github.com/livekit/egress&quot;&gt;Egress&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/ingress&quot;&gt;Ingress&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/sip&quot;&gt;SIP&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Resources&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://docs.livekit.io&quot;&gt;Docs&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit-examples&quot;&gt;Example apps&lt;/a&gt; · &lt;a href=&quot;https://livekit.io/cloud&quot;&gt;Cloud&lt;/a&gt; · &lt;a href=&quot;https://docs.livekit.io/home/self-hosting/deployment&quot;&gt;Self-hosting&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/livekit-cli&quot;&gt;CLI&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!--END_REPO_NAV--&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[external-secrets/external-secrets]]></title>
            <link>https://github.com/external-secrets/external-secrets</link>
            <guid>https://github.com/external-secrets/external-secrets</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[External Secrets Operator reads information from a third-party service like AWS Secrets Manager and automatically injects the values as Kubernetes Secrets.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/external-secrets/external-secrets">external-secrets/external-secrets</a></h1>
            <p>External Secrets Operator reads information from a third-party service like AWS Secrets Manager and automatically injects the values as Kubernetes Secrets.</p>
            <p>Language: Go</p>
            <p>Stars: 5,844</p>
            <p>Forks: 1,074</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;assets/eso-logo-large.png&quot; width=&quot;30%&quot; align=&quot;center&quot; alt=&quot;external-secrets&quot;&gt;
&lt;/p&gt;

# External Secrets

![ci](https://github.com/external-secrets/external-secrets/actions/workflows/ci.yml/badge.svg?branch=main)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5327/badge)](https://bestpractices.coreinfrastructure.org/projects/5947)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/external-secrets/external-secrets/badge)](https://securityscorecards.dev/viewer/?uri=github.com/external-secrets/external-secrets)
[![Go Report Card](https://goreportcard.com/badge/github.com/external-secrets/external-secrets)](https://goreportcard.com/report/github.com/external-secrets/external-secrets)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets?ref=badge_shield)
&lt;a href=&quot;https://artifacthub.io/packages/helm/external-secrets-operator/external-secrets&quot;&gt;&lt;img alt=&quot;Artifact Hub&quot; src=&quot;https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/external-secrets&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://operatorhub.io/operator/external-secrets-operator&quot;&gt;&lt;img alt=&quot;operatorhub.io&quot; src=&quot;https://img.shields.io/badge/operatorhub.io-external--secrets-brightgreen&quot; /&gt;&lt;/a&gt;

**External Secrets Operator** is a Kubernetes operator that integrates external
secret management systems like [AWS Secrets
Manager](https://aws.amazon.com/secrets-manager/), [HashiCorp
Vault](https://www.vaultproject.io/), [Google Secrets
Manager](https://cloud.google.com/secret-manager), [Azure Key
Vault](https://azure.microsoft.com/en-us/services/key-vault/), [IBM Cloud Secrets Manager](https://www.ibm.com/cloud/secrets-manager), [Akeyless](https://akeyless.io), [CyberArk Conjur](https://www.conjur.org), [Pulumi ESC](https://www.pulumi.com/product/esc/) and many more. The
operator reads information from external APIs and automatically injects the
values into a [Kubernetes
Secret](https://kubernetes.io/docs/concepts/configuration/secret/).

Multiple people and organizations are joining efforts to create a single External Secrets solution based on existing projects. If you are curious about the origins of this project, check out [this issue](https://github.com/external-secrets/kubernetes-external-secrets/issues/47) and [this PR](https://github.com/external-secrets/kubernetes-external-secrets/pull/477).

## Documentation

External Secrets Operator guides and reference documentation is available at [external-secrets.io](https://external-secrets.io). Also see our [stability and support](https://external-secrets.io/main/introduction/stability-support/) policy.

## Contributing

We welcome and encourage contributions to this project! Please read the [Developer](https://www.external-secrets.io/main/contributing/devguide/) and [Contribution process](https://www.external-secrets.io/main/contributing/process/) guides. Also make sure to check the [Code of Conduct](https://www.external-secrets.io/main/contributing/coc/) and adhere to its guidelines.

Also, please take a look our [Contribution Ladder](CONTRIBUTOR_LADDER.md) for a _very_ detailed explanation of what roles and tracks are available for people to try and help this project.

### Sponsoring

Please consider sponsoring this project, there are many ways you can help us with: engineering time, providing infrastructure, donating money, etc. We are open to cooperations, feel free to approach as and we discuss how this could look like. We can keep your contribution anonymized if that&#039;s required (depending on the type of contribution), and anonymous donations are possible inside [Opencollective](https://opencollective.com/external-secrets-org).

## Bi-weekly Development Meeting

We host our development meeting every odd wednesday on [Jitsi](https://meet.jit.si/eso-community-meeting). We run the meeting with alternating times [8:00 PM Berlin Time](https://dateful.com/time-zone-converter?t=20:00&amp;tz=Europe/Berlin) and [1:00 PM Berlin Time](https://dateful.com/time-zone-converter?t=13:00&amp;tz=Europe/Berlin), we&#039;ll announce the time in our [Kubernetes Slack
  channel](https://kubernetes.slack.com/messages/external-secrets). Meeting notes are recorded on [hackmd](https://hackmd.io/GSGEpTVdRZCP6LDxV3FHJA).

Anyone is welcome to join. Feel free to ask questions, request feedback, raise awareness for an issue, or just say hi. ;)

## Security

Please report vulnerabilities by email to cncf-ExternalSecretsOp-maintainers@lists.cncf.io. Also see our [SECURITY.md file](SECURITY.md) for details.

## software bill of materials
We attach SBOM and provenance file to our GitHub release. Also, they are attached to container images.

## Adopters

Please create a PR and add your company or project to our [ADOPTERS.md file](ADOPTERS.md) if you are using our project!

## Roadmap

You can find the roadmap in our documentation: https://external-secrets.io/main/contributing/roadmap/

## Kicked off by

![](assets/Godaddylogo_2020.png)

## Sponsored by

![External Secrets Inc.](assets/ESI_Logo.svg)
![Container Solutions](assets/CS_logo_1.png)
![Form 3](assets/form3_logo.png)
![Pento ](assets/pento_logo.png)


## License
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets?ref=badge_large)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[alireza0/s-ui]]></title>
            <link>https://github.com/alireza0/s-ui</link>
            <guid>https://github.com/alireza0/s-ui</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[An advanced Web Panel • Built for SagerNet/Sing-Box]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/alireza0/s-ui">alireza0/s-ui</a></h1>
            <p>An advanced Web Panel • Built for SagerNet/Sing-Box</p>
            <p>Language: Go</p>
            <p>Stars: 5,096</p>
            <p>Forks: 845</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># S-UI
**An Advanced Web Panel • Built on SagerNet/Sing-Box**

![](https://img.shields.io/github/v/release/alireza0/s-ui.svg)
![S-UI Docker pull](https://img.shields.io/docker/pulls/alireza7/s-ui.svg)
[![Go Report Card](https://goreportcard.com/badge/github.com/alireza0/s-ui)](https://goreportcard.com/report/github.com/alireza0/s-ui)
[![Downloads](https://img.shields.io/github/downloads/alireza0/s-ui/total.svg)](https://img.shields.io/github/downloads/alireza0/s-ui/total.svg)
[![License](https://img.shields.io/badge/license-GPL%20V3-blue.svg?longCache=true)](https://www.gnu.org/licenses/gpl-3.0.en.html)

&gt; **Disclaimer:** This project is only for personal learning and communication, please do not use it for illegal purposes, please do not use it in a production environment

**If you think this project is helpful to you, you may wish to give a**:star2:

[![&quot;Buy Me A Coffee&quot;](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://www.buymeacoffee.com/alireza7)

- USDT (TRC20): `TYTq73Gj6dJ67qe58JVPD9zpjW2cc9XgVz`

## Quick Overview
| Features                               |      Enable?       |
| -------------------------------------- | :----------------: |
| Multi-Protocol                         | :heavy_check_mark: |
| Multi-Language                         | :heavy_check_mark: |
| Multi-Client/Inbound                   | :heavy_check_mark: |
| Advanced Traffic Routing Interface     | :heavy_check_mark: |
| Client &amp; Traffic &amp; System Status       | :heavy_check_mark: |
| Subscription Service (link/json + info)| :heavy_check_mark: |
| Dark/Light Theme                       | :heavy_check_mark: |
| API Interface                          | :heavy_check_mark: |

## Supported Platforms
| Platform | Architecture | Status |
|----------|--------------|---------|
| Linux    | amd64, arm64, armv7, armv6, armv5, 386, s390x | ✅ Supported |
| Windows  | amd64, 386, arm64 | ✅ Supported |
| macOS    | amd64, arm64 | 🚧 Experimental |

## Screenshots

![&quot;Main&quot;](https://github.com/alireza0/s-ui-frontend/raw/main/media/main.png)

[Other UI Screenshots](https://github.com/alireza0/s-ui-frontend/blob/main/screenshots.md)

## API Documentation

[API-Documentation Wiki](https://github.com/alireza0/s-ui/wiki/API-Documentation)

## Default Installation Information
- Panel Port: 2095
- Panel Path: /app/
- Subscription Port: 2096
- Subscription Path: /sub/
- User/Password: admin

## Install &amp; Upgrade to Latest Version

### Linux/macOS
```sh
bash &lt;(curl -Ls https://raw.githubusercontent.com/alireza0/s-ui/master/install.sh)
```

### Windows
1. Download the latest Windows release from [GitHub Releases](https://github.com/alireza0/s-ui/releases/latest)
2. Extract the ZIP file
3. Run `install-windows.bat` as Administrator
4. Follow the installation wizard

## Install legacy Version

**Step 1:** To install your desired legacy version, add the version to the end of the installation command. e.g., ver `1.0.0`:

```sh
VERSION=1.0.0 &amp;&amp; bash &lt;(curl -Ls https://raw.githubusercontent.com/alireza0/s-ui/$VERSION/install.sh) $VERSION
```

## Manual installation

### Linux/macOS
1. Get the latest version of S-UI based on your OS/Architecture from GitHub: [https://github.com/alireza0/s-ui/releases/latest](https://github.com/alireza0/s-ui/releases/latest)
2. **OPTIONAL** Get the latest version of `s-ui.sh` [https://raw.githubusercontent.com/alireza0/s-ui/master/s-ui.sh](https://raw.githubusercontent.com/alireza0/s-ui/master/s-ui.sh)
3. **OPTIONAL** Copy `s-ui.sh` to /usr/bin/ and run `chmod +x /usr/bin/s-ui`.
4. Extract s-ui tar.gz file to a directory of your choice and navigate to the directory where you extracted the tar.gz file.
5. Copy *.service files to /etc/systemd/system/ and run `systemctl daemon-reload`.
6. Enable autostart and start S-UI service using `systemctl enable s-ui --now`
7. Start sing-box service using `systemctl enable sing-box --now`

### Windows
1. Get the latest Windows version from GitHub: [https://github.com/alireza0/s-ui/releases/latest](https://github.com/alireza0/s-ui/releases/latest)
2. Download the appropriate Windows package (e.g., `s-ui-windows-amd64.zip`)
3. Extract the ZIP file to a directory of your choice
4. Run `install-windows.bat` as Administrator
5. Follow the installation wizard
6. Access the panel at http://localhost:2095/app

## Uninstall S-UI

```sh
sudo -i

systemctl disable s-ui  --now

rm -f /etc/systemd/system/sing-box.service
systemctl daemon-reload

rm -fr /usr/local/s-ui
rm /usr/bin/s-ui
```

## Install using Docker

&lt;details&gt;
   &lt;summary&gt;Click for details&lt;/summary&gt;

### Usage

**Step 1:** Install Docker

```shell
curl -fsSL https://get.docker.com | sh
```

**Step 2:** Install S-UI

&gt; Docker compose method

```shell
mkdir s-ui &amp;&amp; cd s-ui
wget -q https://raw.githubusercontent.com/alireza0/s-ui/master/docker-compose.yml
docker compose up -d
```

&gt; Use docker

```shell
mkdir s-ui &amp;&amp; cd s-ui
docker run -itd \
    -p 2095:2095 -p 2096:2096 -p 443:443 -p 80:80 \
    -v $PWD/db/:/app/db/ \
    -v $PWD/cert/:/root/cert/ \
    --name s-ui --restart=unless-stopped \
    alireza7/s-ui:latest
```

&gt; Build your own image

```shell
git clone https://github.com/alireza0/s-ui
git submodule update --init --recursive
docker build -t s-ui .
```

&lt;/details&gt;

## Manual run ( contribution )

&lt;details&gt;
   &lt;summary&gt;Click for details&lt;/summary&gt;

### Build and run whole project
```shell
./runSUI.sh
```

### Clone the repository
```shell
# clone repository
git clone https://github.com/alireza0/s-ui
# clone submodules
git submodule update --init --recursive
```


### - Frontend

Visit [s-ui-frontend](https://github.com/alireza0/s-ui-frontend) for frontend code

### - Backend
&gt; Please build frontend once before!

To build backend:
```shell
# remove old frontend compiled files
rm -fr web/html/*
# apply new frontend compiled files
cp -R frontend/dist/ web/html/
# build
go build -o sui main.go
```

To run backend (from root folder of repository):
```shell
./sui
```

&lt;/details&gt;

## Languages

- English
- Farsi
- Vietnamese
- Chinese (Simplified)
- Chinese (Traditional)
- Russian

## Features

- Supported protocols:
  - General:  Mixed, SOCKS, HTTP, HTTPS, Direct, Redirect, TProxy
  - V2Ray based: VLESS, VMess, Trojan, Shadowsocks
  - Other protocols: ShadowTLS, Hysteria, Hysteria2, Naive, TUIC
- Supports XTLS protocols
- An advanced interface for routing traffic, incorporating PROXY Protocol, External, and Transparent Proxy, SSL Certificate, and Port
- An advanced interface for inbound and outbound configuration
- Clients’ traffic cap and expiration date
- Displays online clients, inbounds and outbounds with traffic statistics, and system status monitoring
- Subscription service with ability to add external links and subscription
- HTTPS for secure access to the web panel and subscription service (self-provided domain + SSL certificate)
- Dark/Light theme

## Environment Variables

&lt;details&gt;
  &lt;summary&gt;Click for details&lt;/summary&gt;

### Usage

| Variable       |                      Type                      | Default       |
| -------------- | :--------------------------------------------: | :------------ |
| SUI_LOG_LEVEL  | `&quot;debug&quot;` \| `&quot;info&quot;` \| `&quot;warn&quot;` \| `&quot;error&quot;` | `&quot;info&quot;`      |
| SUI_DEBUG      |                   `boolean`                    | `false`       |
| SUI_BIN_FOLDER |                    `string`                    | `&quot;bin&quot;`       |
| SUI_DB_FOLDER  |                    `string`                    | `&quot;db&quot;`        |
| SINGBOX_API    |                    `string`                    | -             |

&lt;/details&gt;

## SSL Certificate

&lt;details&gt;
  &lt;summary&gt;Click for details&lt;/summary&gt;

### Certbot

```bash
snap install core; snap refresh core
snap install --classic certbot
ln -s /snap/bin/certbot /usr/bin/certbot

certbot certonly --standalone --register-unsafely-without-email --non-interactive --agree-tos -d &lt;Your Domain Name&gt;
```

&lt;/details&gt;

## Stargazers over Time
[![Stargazers over time](https://starchart.cc/alireza0/s-ui.svg)](https://starchart.cc/alireza0/s-ui)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[XIU2/CloudflareSpeedTest]]></title>
            <link>https://github.com/XIU2/CloudflareSpeedTest</link>
            <guid>https://github.com/XIU2/CloudflareSpeedTest</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[🌩「自选优选 IP」测试 Cloudflare CDN 延迟和速度，获取最快 IP ！当然也支持其他 CDN / 多个解析 IP 的网站 ~]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/XIU2/CloudflareSpeedTest">XIU2/CloudflareSpeedTest</a></h1>
            <p>🌩「自选优选 IP」测试 Cloudflare CDN 延迟和速度，获取最快 IP ！当然也支持其他 CDN / 多个解析 IP 的网站 ~</p>
            <p>Language: Go</p>
            <p>Stars: 22,961</p>
            <p>Forks: 4,528</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># XIU2/CloudflareSpeedTest

[![Go Version](https://img.shields.io/github/go-mod/go-version/XIU2/CloudflareSpeedTest.svg?style=flat-square&amp;label=Go&amp;color=00ADD8&amp;logo=go)](https://github.com/XIU2/CloudflareSpeedTest/)
[![Release Version](https://img.shields.io/github/v/release/XIU2/CloudflareSpeedTest.svg?style=flat-square&amp;label=Release&amp;color=00ADD8&amp;logo=github)](https://github.com/XIU2/CloudflareSpeedTest/releases/latest)
[![GitHub license](https://img.shields.io/github/license/XIU2/CloudflareSpeedTest.svg?style=flat-square&amp;label=License&amp;color=00ADD8&amp;logo=github)](https://github.com/XIU2/CloudflareSpeedTest/)
[![GitHub Star](https://img.shields.io/github/stars/XIU2/CloudflareSpeedTest.svg?style=flat-square&amp;label=Star&amp;color=00ADD8&amp;logo=github)](https://github.com/XIU2/CloudflareSpeedTest/)
[![GitHub Fork](https://img.shields.io/github/forks/XIU2/CloudflareSpeedTest.svg?style=flat-square&amp;label=Fork&amp;color=00ADD8&amp;logo=github)](https://github.com/XIU2/CloudflareSpeedTest/)

国外很多网站都在使用 Cloudflare CDN，但分配给中国内地访客的 IP 并不友好（延迟高、丢包多、速度慢）。  
虽然 Cloudflare 公开了所有 [IP 段](https://www.cloudflare.com/zh-cn/ips/) ，但想要在这么多 IP 中找到适合自己的，怕是要累死，于是就有了这个软件。

**「自选优选 IP」测试 Cloudflare CDN 延迟和速度，获取最快 IP (IPv4+IPv6)**！好用的话**点个`⭐`鼓励一下叭~**

&gt; _分享我其他开源项目：[**TrackersList.com** - 全网热门 BT Tracker 列表！有效提高 BT 下载速度~](https://github.com/XIU2/TrackersListCollection) &lt;img src=&quot;https://img.shields.io/github/stars/XIU2/TrackersListCollection.svg?style=flat-square&amp;label=Star&amp;color=4285dd&amp;logo=github&quot; height=&quot;16px&quot; /&gt;_  
&gt; _[**UserScript** - 🐵 Github 高速下载、知乎增强、自动无缝翻页、护眼模式 等十几个**油猴脚本**~](https://github.com/XIU2/UserScript) &lt;img src=&quot;https://img.shields.io/github/stars/XIU2/UserScript.svg?style=flat-square&amp;label=Star&amp;color=4285dd&amp;logo=github&quot; height=&quot;16px&quot; /&gt;_  
&gt; _[**SNIProxy** - 🧷 自用的简单 SNI Proxy（支持全平台、全系统、前置代理、配置简单等~](https://github.com/XIU2/SNIProxy) &lt;img src=&quot;https://img.shields.io/github/stars/XIU2/SNIProxy.svg?style=flat-square&amp;label=Star&amp;color=4285dd&amp;logo=github&quot; height=&quot;16px&quot; /&gt;_  

当然了，本项目也支持对 **`其他 CDN / 多个解析 IP 的网站`** 延迟测速，但相对应的下载测速地址需自行寻找。

&gt; [!IMPORTANT]
&gt; Cloudflare CDN 已**明文禁止代理**方式使用，对于**代理套 CDN** 的自行承担风险，请勿过度依赖 [#382](https://github.com/XIU2/CloudflareSpeedTest/discussions/382) [#383](https://github.com/XIU2/CloudflareSpeedTest/discussions/383)

****
## \# 快速使用

### 下载运行

1. 下载编译好的可执行文件（ [Github Releases](https://github.com/XIU2/CloudflareSpeedTest/releases) / [蓝奏云](https://xiu.lanzoub.com/b0742hkxe) ）并解压。  
2. 双击运行 `cfst.exe` 文件（Windows 系统），等待测速完成...

&lt;details&gt;
&lt;summary&gt;&lt;code&gt;&lt;strong&gt;「 点击查看 Windows 系统下其他安装方式」&lt;/strong&gt;&lt;/code&gt;&lt;/summary&gt;

****

如果你有 scoop(Windows 下的命令行安装程序)，则可以这样安装:

```sh
# 添加最多人使用的中文软件包仓库：dorado
scoop bucket add dorado https://github.com/chawyehsu/dorado
# 安装cloudflare-speedtest
scoop install dorado/cloudflare-speedtest
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;code&gt;&lt;strong&gt;「 点击查看 Linux 系统下的使用示例 」&lt;/strong&gt;&lt;/code&gt;&lt;/summary&gt;

****

以下命令仅为示例，版本号和文件名请前往 [**Releases**](https://github.com/XIU2/CloudflareSpeedTest/releases) 查看。

``` yaml
# 如果是第一次使用，则建议创建新文件夹（后续更新时，跳过该步骤）
mkdir cfst

# 进入文件夹（后续更新，只需要从这里重复下面的下载、解压命令即可）
cd cfst

# 下载 CFST 压缩包（自行根据需求替换 URL 中 [版本号] 和 [文件名]）
wget -N https://github.com/XIU2/CloudflareSpeedTest/releases/download/v2.3.4/cfst_linux_amd64.tar.gz
# 如果你是在国内网络环境中下载，那么请使用下面这几个镜像加速之一：
# wget -N https://ghfast.top/https://github.com/XIU2/CloudflareSpeedTest/releases/download/v2.3.4/cfst_linux_arm64.tar.gz
# wget -N https://wget.la/https://github.com/XIU2/CloudflareSpeedTest/releases/download/v2.3.4/cfst_linux_arm64.tar.gz
# wget -N https://ghproxy.net/https://github.com/XIU2/CloudflareSpeedTest/releases/download/v2.3.4/cfst_linux_arm64.tar.gz
# wget -N https://gh-proxy.com/https://github.com/XIU2/CloudflareSpeedTest/releases/download/v2.3.4/cfst_linux_arm64.tar.gz
# wget -N https://hk.gh-proxy.com/https://github.com/XIU2/CloudflareSpeedTest/releases/download/v2.3.4/cfst_linux_arm64.tar.gz
# 如果下载失败的话，尝试删除 -N 参数（如果是为了更新，则记得提前删除旧压缩包 rm cfst_linux_amd64.tar.gz ）

# 解压（不需要删除旧文件，会直接覆盖，自行根据需求替换 文件名）
tar -zxf cfst_linux_amd64.tar.gz

# 赋予执行权限
chmod +x cfst

# 运行（不带参数）
./cfst

# 运行（带参数示例）
./cfst -tl 200 -dn 20
```

&gt; 如果平**均延迟非常低**（如 0.xx），则说明 CFST **测速时走了代理**，请先关闭代理软件后再测速。  
&gt; 如果在**路由器**上运行，建议先关闭路由器内的代理（或将其排除），否则测速结果可能会**不准确/无法使用**。

&lt;/details&gt;

****

&gt; _在**手机**上独立运行 CFST 测速的简单教程：**[Android](https://github.com/XIU2/CloudflareSpeedTest/discussions/61)、[Android APP](https://github.com/xianshenglu/cloudflare-ip-tester-app)、[IOS](https://github.com/XIU2/CloudflareSpeedTest/discussions/321)**_

&gt; [!NOTE]
&gt; 注意！本软件仅适用于网站，**不支持给使用 UDP 协议的 Cloudflare WARP 优选 IP**，具体见：[#392](https://github.com/XIU2/CloudflareSpeedTest/discussions/392)

### 结果示例

测速完毕后，默认会显示**最快的 10 个 IP**，示例（仅为输出内容示例）：

``` bash
IP 地址           已发送  已接收  丢包率  平均延迟  下载速度(MB/s)  地区码
104.27.200.69     4      4       0.00   146.23    28.64          LAX
172.67.60.78      4      4       0.00   139.82    15.02          SEA
104.25.140.153    4      4       0.00   146.49    14.90          SJC
104.27.192.65     4      4       0.00   140.28    14.07          LAX
172.67.62.214     4      4       0.00   139.29    12.71          LAX
104.27.207.5      4      4       0.00   145.92    11.95          LAX
172.67.54.193     4      4       0.00   146.71    11.55          LAX
104.22.66.8       4      4       0.00   147.42    11.11          SEA
104.27.197.63     4      4       0.00   131.29    10.26          FRA
172.67.58.91      4      4       0.00   140.19    9.14           SJC
...

# 如果平均延迟非常低（如 0.xx），则说明 CFST 测速时走了代理，请先关闭代理软件后再测速。
# 如果在路由器上运行，请先关闭路由器内的代理（或将其排除），否则测速结果可能会不准确/无法使用。

# 因为每次测速都是在每个 IP 段中随机 IP，所以每次的测速结果都不可能相同，这是正常的！

# 注意！我发现电脑开机后第一次测速延迟会明显偏高（手动 TCPing 也一样），后续测速都正常
# 因此建议大家开机后第一次正式测速前，先随便测几个 IP（无需等待延迟测速完成，只要进度条动了就可以直接关了）

# 软件在 默认参数 下的整个流程大概步骤：
# 1. 延迟测速（默认 TCPing 模式，HTTPing 模式需要手动加上参数）
# 2. 延迟排序（延迟 从低到高 排序并按条件过滤，不同丢包率会分开排序，因此可能会有一些延迟低但丢包的 IP 排到后面）
# 3. 下载测速（从延迟最低的 IP 开始依次下载测速，默认测够 10 个就会停止）
# 4. 速度排序（速度从高到低排序）
# 5. 输出结果（通过参数控制是否输出到命令行(-p 0)或输出到文件(-o &quot;&quot;)）

# 注意：输出的结果文件 result.csv 通过微软 Excel 表格打开会中文乱码，这是正常的，其他表格软件/记事本都显示正常
```

测速结果第一行就是**既下载速度最快、又平均延迟最低的最快 IP**！

完整结果保存在当前目录下的 `result.csv` 文件中，用**记事本/表格软件**打开，格式如下：

```
IP 地址,已发送,已接收,丢包率,平均延迟,下载速度(MB/s),地区码
104.27.200.69,4,4,0.00,146.23,28.64,LAX
```

&gt; [!NOTE]
&gt; _如果你发现**下载速度为 0.00**，那么可以用**调试模式 `-debug`** 排查一下，详见：[**# 下载测速都是 0.00 ？**](https://github.com/XIU2/CloudflareSpeedTest#-%E4%B8%8B%E8%BD%BD%E6%B5%8B%E9%80%9F%E9%83%BD%E6%98%AF-000-)_

&gt; _大家可以按自己需求，对完整结果**进一步筛选处理**，或者去看一看进阶使用**指定过滤条件**！_

****
## \# 进阶使用

直接运行使用的是默认参数，如果想要测速结果更全面、更符合自己的要求，可以自定义参数。

```Dart
C:\&gt;cfst.exe -h

CloudflareSpeedTest vX.X.X
测试各个 CDN 或网站所有 IP 的延迟和速度，获取最快 IP (IPv4+IPv6)！
https://github.com/XIU2/CloudflareSpeedTest

参数：
    -n 200
        延迟测速线程；越多延迟测速越快，性能弱的设备 (如路由器) 请勿太高；(默认 200 最多 1000)
    -t 4
        延迟测速次数；单个 IP 延迟测速的次数；(默认 4 次)
    -dn 10
        下载测速数量；延迟测速并排序后，从最低延迟起下载测速的数量；(默认 10 个)
    -dt 10
        下载测速时间；单个 IP 下载测速最长时间，不能太短；(默认 10 秒)
    -tp 443
        指定测速端口；延迟测速/下载测速时使用的端口；(默认 443 端口)
    -url https://cf.xiu2.xyz/url
        指定测速地址；延迟测速(HTTPing)/下载测速时使用的地址，默认地址不保证可用性，建议自建；
        当下载测速时，软件会从 HTTP 响应头中获取该 IP 当前地区码（支持 Cloudflare、AWS CloudFront、Fastly、Gcore、CDN77、Bunny 等 CDN）并显示出来。

    -httping
        切换测速模式；延迟测速模式改为 HTTP 协议，所用测试地址为 [-url] 参数；(默认 TCPing)
        当使用 HTTP 测速模式时，软件会从 HTTP 响应头中获取该 IP 当前地区码（支持 Cloudflare、AWS CloudFront、Fastly、Gcore、CDN77、Bunny 等 CDN）并显示出来。
        注意：HTTPing 本质上也算一种 网络扫描 行为，因此如果你在服务器上面运行，需要降低并发(-n)，否则可能会被一些严格的商家暂停服务。
        如果你遇到 HTTPing 首次测速可用 IP 数量正常，后续测速越来越少甚至直接为 0，但停一段时间后又恢复了的情况，那么也可能是被 运营商、Cloudflare CDN 认为你在网络扫描而 触发临时限制机制，因此才会过一会儿就恢复了，建议降低并发(-n)减少这种情况的发生。
    -httping-code 200
        有效状态代码；HTTPing 延迟测速时网页返回的有效 HTTP 状态码，仅限一个；(默认 200 301 302)
    -cfcolo HKG,KHH,NRT,LAX,SEA,SJC,FRA,MAD
        匹配指定地区；IATA 机场地区码或国家/城市码，英文逗号分隔，大小写均可，仅 HTTPing 模式可用；(默认 所有地区)
        支持 Cloudflare、AWS CloudFront、Fastly、Gcore、CDN77、Bunny 等 CDN
        其中 Cloudflare、AWS CloudFront、Fastly 使用的是 IATA 三字机场地区码，如：HKG,LAX
        其中 CDN77、Bunny 使用的是 二字国家/区域码，如：US,CN
        其中 Gcore 使用的是 二字城市码，如：FR,AM
        因此大家使用 -cfcolo 指定地区码时要根据不同的 CDN 来指定不同类型的地区码。

    -tl 200
        平均延迟上限；只输出低于指定平均延迟的 IP，各上下限条件可搭配使用；(默认 9999 ms)
    -tll 40
        平均延迟下限；只输出高于指定平均延迟的 IP；(默认 0 ms)
    -tlr 0.2
        丢包几率上限；只输出低于/等于指定丢包率的 IP，范围 0.00~1.00，0 过滤掉任何丢包的 IP；(默认 1.00)
    -sl 5
        下载速度下限；只输出高于指定下载速度的 IP，凑够指定数量 [-dn] 才会停止测速；(默认 0.00 MB/s)

    -p 10
        显示结果数量；测速后直接显示指定数量的结果，为 0 时不显示结果直接退出；(默认 10 个)
    -f ip.txt
        IP段数据文件；如路径含有空格请加上引号；支持其他 CDN IP段；(默认 ip.txt)
    -ip 1.1.1.1,2.2.2.2/24,2606:4700::/32
        指定IP段数据；直接通过参数指定要测速的 IP 段数据，英文逗号分隔；(默认 空)
    -o result.csv
        写入结果文件；如路径含有空格请加上引号；值为空时不写入文件 [-o &quot;&quot;]；(默认 result.csv)

    -dd
        禁用下载测速；禁用后测速结果会按延迟排序 (默认按下载速度排序)；(默认 启用)
    -allip
        测速全部的IP；对 IP 段中的每个 IP (仅支持 IPv4) 进行测速；(默认 每个 /24 段随机测速一个 IP)

    -debug
        调试输出模式；会在一些非预期情况下输出更多日志以便判断原因；(默认 关闭)
        目前该功能仅针对 HTTPing 延迟测速过程 及 下载测速过程，当过程中因为各种原因导致当前 IP 测速中断都会输出错误原因
        例如：HTTPing 延迟测速过程中，因为 HTTP 状态码不符合或测速地址有问题或超时等原因而终止测速
        例如：下载测速过程中，因为下载测速地址有问题（被阻断、403状态码、超时）等原因而终止测速（导致显示 0.00）

    -v
        打印程序版本 + 检查版本更新
    -h
        打印帮助说明
```

### 界面解释

为了避免大家对测速过程中的**输出内容产生误解（可用、队列等数字，下载测速一半就&quot;中断&quot;？下载测速&quot;卡住&quot;不动？）**，我特意解释下。

&lt;details&gt;
&lt;summary&gt;&lt;code&gt;&lt;strong&gt;「 点击展开 查看内容 」&lt;/strong&gt;&lt;/code&gt;&lt;/summary&gt;

****

&gt; 该示例把常用参数都给加上了，即为：`-tll 40 -tl 150 -sl 1 -dn 5`，最后输出结果如下：

```python
# XIU2/CloudflareSpeedTest vX.X.X

开始延迟测速（模式：TCP, 端口：443, 范围：40 ~ 150 ms, 丢包：1.00)
321 / 321 [-----------------------------------------------------------] 可用: 30
开始下载测速（下限：1.00 MB/s, 数量：5, 队列：10）
3 / 5 [-----------------------------------------↗--------------------]
IP 地址           已发送  已接收  丢包率  平均延迟  下载速度(MB/s)  地区码
XXX.XXX.XXX.XXX   4      4       0.00   83.32     3.66           LAX
XXX.XXX.XXX.XXX   4      4       0.00   107.81    2.49           LAX
XXX.XXX.XXX.XXX   4      3       0.25   149.59    1.04           N/A

完整测速结果已写入 result.csv 文件，可使用记事本/表格软件查看。
按下 回车键 或 Ctrl+C 退出。
```

****

&gt; 刚接触 CFST 的人，可能会迷惑**明明延迟测速可用 IP 有 30 个，怎么最后只剩下 3 个了呢？**  
&gt; 下载测速里的队列又是什么意思？难道我下载测速还要排队？

CFST 会先延迟测速，在这过程中进度条右侧会实时显示可用 IP 数量（`可用: 30`），但注意该可用数量指的是**测试通过没有超时的 IP 数量**，和延迟上下限、丢包条件无关。当延迟测速完成后，因为还指定了**延迟上下限、丢包**的条件，所以按照条件过滤后只剩下 `10` 个了（也就是等待下载测速的 `队列：10`）。

即以上示例中，`321` 个 IP 延迟测速完成后，只有 `30` 个 IP 测试通过没有超时，然后根据延迟上下限范围：`40 ~ 150 ms` 及丢包上限条件过滤后，只剩下 `10` 个满足要求的 IP 了。如果你 `-dd` 禁用了下载测速，那么就会直接输出这 `10` 个 IP 了。当然该示例并未禁用，因此接下来软件会继续对这 `10` 个 IP 进行下载测速（`队列：10`）。

&gt; 因为下载测速是单线程一个个 IP 挨着排队测速的，因此等待下载测速的 IP 数量才会叫做 `队列`。

****

&gt; 你可能注意到了，**明明指定了要找到 5 个满足下载速度条件的 IP，怎么才 3 个就 “中断” 了呢？**

下载测速进度条中的 `3 / 5`，前者指的是找到了 `3` 个满足下载速度下限条件的 IP（即下载速度高于 `1 MB/s` ），后者 `5` 指的是你要求找到 `5` 个满足下载速度下限条件的 IP（`-dn 5`）。

&gt; 另外，提醒一下，如果你指定的 `-dn` 大于下载测速队列，比如你延迟测速后只剩下 `4` 个 IP 了，那么下载测速进度条中后面的数字就会和下载测速队列一样都是 `4` 个，而非你 `-dn` 指定的 `5` 个了。

软件在测速完这 `10` 个 IP 后，只找到了 `3` 个下载速度高于 `1 MB/s` 的 IP，剩下的 `7` 个 IP 都是 “不及格” 的。

因此，这不是 `“每次测速都不到 5 就中断了”`，而是所有 IP 都下载测速完了，但却只找到了 `3` 个满足条件的。

****

还有一种情况，那就是当可用 IP 很多时（几百几千），你还设置了下载速度条件，那么可能就会遇到：**怎么下载测速进度条老是卡在 `X / 5` 了呢？**

这其实并不是卡住了，而是只有当找到一个满足条件的 IP 时，进度条才会 +1，因此如果一直找不到，那么 CFST 就会一直下载测速下去，因此在表现为进度条卡住不动，但这也是在提醒你：你设置的下载速度条件对你来说已经高于实际了，你需要适当调低预期。

****

如果不想遇到这种全部测速一遍都没几个满足条件的情况，那么就要**调低下载速度上限参数 `-sl`**，或者移除。

因为只要指定了 `-sl` 参数，那么只要没有凑够 `-dn` 的数量（默认 10 个），就会一直测速下去，直到凑够或全部测速完。移除 `-sl` 并添加 `-dn 20` 参数，这样就是只测速延迟最低的前 20 个 IP，测速完就停止，节省时间。

****

另外，如果全部队列 IP 都测速完了，但一个满足下载速度条件的 IP 都没有，你可能需要调低预期的下载测速下限条件，但你需要知道当前的大概测速速度都在什么范围，那么你就可以加上 `-debug` 参数开启调试模式，这样再遇到这种情况时，就会**忽略条件返回所有测速结果**，你就能看到这些 IP 的下载速度都有多少，心里也就有数了，然后**适当调低 `-sl` 再试试**。

&gt; 注意，如果你**没有指定**下载测速下限 `-sl` 条件，那么无论什么情况下 CFST 都会**输出所有测速结果**。

同样，延迟测速方面，`可用: 30`、`队列：10` 这两个数值也可以让你清楚，你设置的延迟条件对你来说是否过于苛刻。如果可用 IP 一大堆，但条件过滤后只剩下 2、3 个，那不用说就知道需要**调低预期的延迟/丢包条件**了。

这两个机制，一个是告诉你**延迟丢包条件**是否合适的，一个是告诉你**下载速度条件**是否合适的。

&lt;/details&gt;

****

### 使用示例

Windows 要指定参数需要在 CMD 中运行，或者把参数添加到快捷方式目标中。

&gt; [!TIP]
&gt; - 各参数均有**默认值**，当使用默认值时参数可以省略（**按需选择**），参数**不分前后顺序**。  
&gt; - Windows **PowerShell** 只需把下面命令中的 `cfst.exe` 改为 `.\cfst.exe` 即可。  
&gt; - Linux / macOS 系统只需要把下面命令中的 `cfst.exe` 改为 `./cfst` 即可。

****

#### \# CMD 带参数运行

对命令行程序不熟悉的人，可能不知道该如何带参数运行，我就简单说一下。

&lt;details&gt;
&lt;summary&gt;&lt;code&gt;&lt;strong&gt;「 点击展开 查看内容 」&lt;/strong&gt;&lt;/code&gt;&lt;/summary&gt;

****

很多人打开 CMD 直接就以**绝对路径**运行 CFST 会报错，这是因为默认的 `-f ip.txt` 参数是相对路径，需要指定绝对路径的 ip.txt 才行，但这样毕竟太麻烦了，因此还是建议进入 CFST 程序目录下，以**相对路径**方式运行：

**方式 一**：
1. 打开 CFST 程序所在目录  
2. 空白处按下 &lt;kbd&gt;Shift + 鼠标右键&lt;/kbd&gt; 显示右键菜单  
3. 选择 **\[在此处打开命令窗口\]** 来打开 CMD 窗口，此时默认就位于当前目录下  
4. 输入带参数的命令，如：`cfst.exe -tl 200 -dn 20` 即可运行

**方式 二**：
1. 打开 CFST 程序所在目录  
2. 直接在文件夹地址栏中全选(或清空)并输入 `cmd` 回车就能打开 CMD 窗口，此时默认就位于当前目录下  
4. 输入带参数的命令，如：`cfst.exe -tl 200 -dn 20` 即可运行

&gt; 当然你也可以随便打开一个 CMD 窗口，然后输入如 `cd /d &quot;D:\Program Files\cfst&quot;` 来进入程序目录

&gt; **提示**：如果用的是 **PowerShell** 只需把命令中的 `cfst.exe` 改为 `.\cfst.exe` 即可。

&lt;/details&gt;

****

#### \# Windows 快捷方式带参数运行

如果不经常修改运行参数（比如平时都是直接双击运行）的人，建议使用快捷方式，更方便点。

&lt;details&gt;
&lt;summary&gt;&lt;code&gt;&lt;strong&gt;「 点击展开 查看内容 」&lt;/strong&gt;&lt;/code&gt;&lt;/summary&gt;

****

右键 `cfst.exe` 文件 - **\[创建快捷方式\]**，然后右键该快捷方式 - **\[属性\]**，修改其**目标**：

``` bash
# 如果要不输出结果文件，那么请加上 -o &quot; &quot;，引号里的是空格（没有空格会导致该参数被省略）。
D:\ABC\cfst\cfst.exe -tl 200 -dn 20 -o &quot; &quot;

# 如果文件路径包含引号，则需要把启动参数放在引号外面，记得引号和 - 之间有空格。
&quot;D:\Program Files\cfst\cfst.exe&quot; -tl 200 -dn 20 -o &quot; &quot;

# 注意！快捷方式 - 起始位置 不能是空的，否则就会因为绝对路径而找不到 ip.txt 文件
```

&lt;/details&gt;

****

#### \# IPv4/IPv6

&lt;details&gt;
&lt;summary&gt;&lt;code&gt;&lt;strong&gt;「 点击展开 查看内容 」&lt;/strong&gt;&lt;/code&gt;&lt;/summary&gt;

****
``` bash
# 指定自带的 IPv4 数据文件可测速这些 IPv4 地址（-f 默认值就是 ip.txt，所以该参数可省略）
cfst.exe -f ip.txt

# 指定自带的 IPv6 数据文件可测速这些 IPv6 地址
# 另外，v2.1.0 版本后支持 IPv4+IPv6 混合测速并移除了 -ipv6 参数，因此一个文件内可以同时包含 IPv4+IPv6 地址
cfst.exe -f ipv6.txt

# 也可以直接通过参数指定要测速的 IP
cfst.exe -ip 1.1.1.1,2606:4700::/32
```

&gt; 测速 IPv6 时，可能会注意到每次测速数量都不一样，了解原因： [#120](https://github.com/XIU2/CloudflareSpeedTest/issues/120)  
&gt; 因为 IPv6 太多（以亿为单位），且绝大部分 IP 段压根未启用，所以我只扫了一部分可用的 IPv6 段写到 `ipv6.txt` 文件中，有兴趣的可以自行扫描增删，ASN 数据源来自：[bgp.he.net](https://bgp.he.net/AS13335#_prefixes6)

&lt;/details&gt;

****

#### \# HTTPing

&lt;details&gt;
&lt;summary&gt;&lt;code&gt;&lt;strong&gt;「 点击展开 查看内容 」&lt;/strong&gt;&lt;/code&gt;&lt;/summary&gt;

****

目前有两种延迟测速模式，分别为 **TCP 协议、HTTP 协议**。  
TCP 协议耗时更短、消耗资源更少，超时时间为 1 秒，该协议为默认模式。  
HTTP 协议适用于快速测试某域名指向某 IP 时是否可以访问，超时时间为 2 秒。  
同一个 IP，各协议去 Ping 得到的延迟一般为：**ICMP &lt; TCP &lt; HTTP**，越靠右对丢包等网络波动越敏感。

&gt; 注意：HTTPing 本质上也算一种**网络扫描**行为，因此如果你在服务器上面运行，需要**降低并发**(`-n`)，否则可能会被一些严格的商家暂停服务。如果你遇到 HTTPing 首次测速可用 IP 数量正常，后续测速越来越少甚至直接为 0，但停一段时间后又恢复了的情况，那么也可能是被 运营商、Cloudflare CDN 认为你在网络扫描而**触发临时限制机制**，因此才会过一会儿就恢复了，建议**降低并发**(`-n`)减少这种情况的发生。

&gt; 另外，本软件 HTTPing 仅获取**响应头(response headers)**，并不获取正文内容（即 URL 文件大小不影响 HTTPing 测试，但如果你还要下载测速的话，那么还是需要一个大文件的），类似于 curl -i 功能。

&gt; 另外，HTTPing 过程中，软件会从 HTTP 响应头中获取该 IP 当前地区码（支持 Cloudflare、AWS CloudFront、Fastly、Gcore、CDN77、Bunny 等 CDN）并显示出来，而 TCPing 过程中无法这样做（但 下载测速 时也会这样做来获取地区码，毕竟下载测速也是个 HTTP 链接）

``` bash
# 只需加上 -httping 参数即可切换到 HTTP 协议延迟测速模式
cfst.exe -httping

# 软件会根据访问时网页返回的有效 HTTP 状态码来判断可用性（当然超时也算），默认对返回 200 301 302 这三个 HTTP 状态码的视为有效，可以手动指定认为有效的 HTTP 状态码，但只能指定一个（你需要提前确定测试地址正常情况下会返回哪个状态码）
cfst.exe -httping -httping-code 200

# 通过 -url 参数来指定 HTTPing 测试地址（可以是任意网页 URL，不局限于具体文件地址）
cfst.exe -httping -url https://cf.xiu2.xyz/url
# 如果你要 HTTPing 测试其他网站/CDN，那么指定一个该网站/使用该 CDN 的地址（因为软件默认地址是 Cloudflare 的，只能用于测试 Cloudflare 的 IP）

# 注意：如果测速地址为 HTTP 协议，记得加上 -tp 80（这个参数会影响 延迟测速/下载测速 时使用的端口）
# 同理，如果要测速 80 端口，那么也需要加上 -url 参数来指定一个 http:// 协议的地址才行（且该地址不会强制重定向至 HTTPS），如果是非 80 443 端口，那么需要确定该下载测速地址是否支持通过该端口访问。
cfst.exe -httping -tp 80 -url http://cdn.cloudflare.steamstatic.com/steam/apps/5952/movie_max.webm
```

&lt;/details&gt;

****

#### \# 匹配指定地区

&lt;details&gt;
&lt;summary&gt;&lt;code&gt;&lt;strong&gt;「 点击展开 查看内容 」&lt;/strong&gt;&lt;/code&gt;&lt;/summary&gt;

****

Cloudflare CDN 的节点 IP 是 Anycast IP，即每个 IP 对应的服务器节点及地区不是固定的，而是动态变化的，**不同地区、不同运营商、不同时间段**访问**同一个 IP** 分配到的服务器节点地区和路线也都是不一样的（比如同一个 IP，美国人访问就是分配到就近的美国节点服务器，日本人访问则就又变成了就近的日本节点服务器了，国内内地就比较特殊了，只能给你分配到其他国家，当然不同的 IP 段路由变化/分配逻辑也是不同的，有的 IP 段会较为固定）。

&gt; **注意**！虽然 Cloudflare CDN 有很多亚洲节点，但**不代表你就能用上**，新加坡人测速可能随便一抓一大把的新加坡节点，但你全部扫一遍可能都遇不到一个，因为这是由 CDN 控制的。Anycast IP 的路由是经常变的，同一个 IP 今天可能是美国，明天你再访问可能就又分配到欧洲节点了（当然这只是个例子，一般没有那么频繁，这也和很多因素有关，比如线路拥塞程度，成本变动等），因此**不要对该功能有过高期待**~

或者你随便找个 Cloudflare CDN 的 IP（比如官网域名的解析 IP `104.16.123.96`），然后去那些有全球节点的[在线 Ping 测试](https://ping.sx/ping?t=104.16.123.96)网站，你就会发现这个 IP 在全球大部分地区的延迟都是个位数（而且很多都是 0.X ms），就算一些地方延迟高一些但也基本都控制在 几十ms，只有在国内才会发现突然变成了 上百ms 了。

这就是 Anycast 技术，也就只有国内大陆这种特殊的网络情况，才需要对 Anycast 的 CDN IP 进行优选。

因此，对于这种 Anycast IP 的实际服务器位置，就不能靠那些在线 IP 地址位置查询网站来判断了。

除了通过 **HTTP 响应头**获取地区码外（该功能的实现方式），还可以手动访问 `http://CloudflareIP/cdn-cgi/trace` 来获知 CDN 分配给你的实际节点地区码。

&gt; 该功能支持 **Cloudflare、AWS CloudFront、Fastly、Gcore、CDN77、Bunny** 等 CDN。  
&gt; 但注意，不是所有 CDN 都支持 Anycast 技术的，很多 CDN 会限制一个网站能使用的 IP 范围。

&gt; 其中 **Cloudflare、AWS CloudFront、Fastly** 都使用的是 **`IATA 三字机场地区码`**，如：HKG,LAX  
&gt; 而 **CDN77、Bunny** 使用的是 **`二字国家/区域码`**，如：US,CN  
&gt; **Gcore** 则使用的是 **`二字城市码`**，如：FR,AM  
&gt; 因此大家使用 `-cfcolo` 指定地区码时要根据不同的 CDN 来指定不同类型的地区码。

&gt; **注意**：如果你要用于筛选 AWS CloudFront CDN 地区，那么要通过 `-url` 参数指定一个使用 AWS CloudFront CDN 的下载测速地址（因为软件默认下载测速地址是 Cloudflare CDN 的），另外有时候 HTTPing 模式测速一些 AWS CloudFront 地址会返回 403 错误，这种情况下需要加上 `-httping-code 403` 才能正确获取地区码。

``` bash
# 指定地区名后，延迟测速后得到的结果就都是指定地区的 IP 了（如果没有指定 -dd 的话则会继续进行下载测速）
# 如果延迟测速后结果为 0，则说明没有找到任何一个（未超时可用的）指定地区的 IP。
# 节点地区名为当地 IATA 机场地区码或国家/城市码，指定多个时用英文逗号分隔，v2.2.3 版本后支持小写

cfst.exe -httping -cfcolo HKG,KHH,NRT,LAX,SEA,SJC,FRA,MAD

# 注意，该参数只有在 HTTPing 延迟测速模式下才可用（因为软件是通过 HTTP 链接中的响应头来获得该 IP 的实际地区码）

# 另外，HTTPing 过程中，软件会从 HTTP 响应头中获取该 IP 当前地区码（支持 Cloudflare、AWS CloudFront、Fastly、Gcore、CDN77、Bunny 等 CDN）并显示出来，而 TCPing 过程中无法这样做（但 下载测速 时也会这样做来获取地区码，毕竟下载测速也是个 HTTP 链接）
```

&gt; **`IATA 三字机场地区码`**，可见：https://www.cloudflarestatus.com/  
&gt; **`二字国家码`**，可见：[https://zh.wikipedia.org/wiki/ISO_3166-1二位字母代码#正式分配代码](https://zh.wikipedia.org/wiki/ISO_3166-1%E4%BA%8C%E4%BD%8D%E5%AD%97%E6%AF%8D%E4%BB%A3%E7%A0%81#%E6%AD%A3%E5%BC%8F%E5%88%86%E9%85%8D%E4%BB%A3%E7%A0%81)

&lt;/details&gt;

****

#### \# 文件相对/绝对路径

&lt;details&gt;
&lt;summary&gt;&lt;code&gt;&lt;strong&gt;「 点击展开 查看内容 」&lt;/strong&gt;&lt;/code&gt;&lt;/summary&gt;

****

``` bash
# 指定 IPv4 数据文件，不显示结果直接退出，输出结果到文件（-p 值为 0）
cfst.exe -f 1.txt -p 0 -dd

# 指定 IPv4 数据文件，不输出结果到文件，直接显示结果（-p 值为 10 条，-o 值为空但引号不能少）
cfst.exe -f 2.txt -o &quot;&quot; -p 10 -dd

# 指定 IPv4 数据文件 及 输出结果到文件（相对路径，即当前目录下，如含空格请加上引号）
cfst.exe -f 3.txt -o result.txt -dd


# 指定 IPv4 数据文件 及 输出结果到文件（相对路径，即当前目录内的 abc 文件夹下，如含空格请加上引号）
# Linux（CFST 程序所在目录内的 abc 文件夹下）
./cfst -f abc/3.txt -o abc/result.txt -dd

# Windows（注意是反斜杠）
cfst.exe -f abc\3.txt -o abc\result.txt -dd


# 指定 IPv4 数据文件 及 输出结果到文件（绝对路径，即 C:\abc\ 目录下，如含空格请加上引号）
# Linux（/abc/ 目录下）
./cfst -f /abc/4.txt -o /abc/result.csv -dd

# Windows（注意是反斜杠）
cfst.exe -f C:\abc\4.txt -o C:\abc\result.csv -dd


# 如果要以【绝对路径】运行 CFST，那么 -f / -o 参数中的文件名也必须是【绝对路径】，否则会报错找不到文件！
# Linux（/abc/ 目录下）
/abc/cfst -f /abc/4.txt -o /abc/result.csv -dd

# Windows（注意是反斜杠）
C:\abc\cfst.exe -f C:\abc\4.txt -o C:\abc\result.csv -dd
```
&lt;/details&gt;

****

#### \# 测速其他端口

&lt;details&gt;
&lt;summary&gt;&lt;code&gt;&lt;strong&gt;「 点击展开 查看内容 」&lt;/strong&gt;&lt;/code&gt;&lt;/summary&gt;

****

``` bash
# 如果你想要测速非默认 443 的其他端口，则需要通过 -tp 参数指定（该参数会影响 延迟测速/下载测速 时使用的端口）

# 如果要延迟测速 80 端口+下载测速（如果 -dd 禁用了下载测速则不需要），那么还需要指定 http:// 协议的下载测速地址才行（且该地址不会强制重定向至 HTTPS，因为那样就变成 443 端口了）
cfst.exe -tp 80 -url http://cdn.cloudflare.steamstatic.com/steam/apps/5952/movie_max.webm

# 如果是非 80 443 的其他端口，那么需要确定你使用的下载测速地址是否支持通过该非标端口访问。
```

&lt;/details&gt;

****

#### \# 自定义测速地址

&lt;details&gt;
&lt;summary&gt;&lt;code&gt;&lt;strong&gt;「 点击展开 查看内容 」&lt;/strong&gt;&lt;/code&gt;&lt;/summary&gt;

****

``` bash
# 该参数适用于下载测速 及 HTTP 协议的延迟测速，对于后者该地址可以是任意网页 URL（不局限于具体文件地址）

# 地址要求：可以直接下载、文件大小超过 200MB、用的是 Cloudflare CDN
cfst.exe -url https://cf.xiu2.xyz/url

# 注意：如果测速地址为 HTTP 协议（该地址不能强制重定向至 HTTPS），记得加上 -tp 80（这个参数会影响 延迟测速/下载测速 时使用的端口），如果是非 80 443 端口，那么需要确定下载测速地址是否支持通过该端口访问。
cfst.exe -tp 80 -url http://cdn.cloudflare.steamstatic.com/steam/apps/5

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[iam-veeramalla/observability-zero-to-hero]]></title>
            <link>https://github.com/iam-veeramalla/observability-zero-to-hero</link>
            <guid>https://github.com/iam-veeramalla/observability-zero-to-hero</guid>
            <pubDate>Tue, 16 Sep 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[Repo for learning observability]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/iam-veeramalla/observability-zero-to-hero">iam-veeramalla/observability-zero-to-hero</a></h1>
            <p>Repo for learning observability</p>
            <p>Language: Go</p>
            <p>Stars: 2,364</p>
            <p>Forks: 3,700</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>
# 📚 7-Day Observability Tutorial Series

Welcome to the 7-Day Observability Tutorial Series! This repository contains the code and detailed explanations for setting up and understanding observability in Kubernetes using Prometheus, Grafana, Elasticsearch Fluentbit, Kibana, Jaeger, groundcover(eBPF), opentelemetry e.t.c.,.

## 📅 Overview of Each Day

### Day 1: Introduction to Observability
- **Concepts Covered**:
  - Introduction to Observability, Monitoring, Logging, and Tracing.
  - The difference between Monitoring and Observability.
  - Tools available for Monitoring and Observability.
  - Comparison between monitoring and observing in Bare-Metal Servers vs. Kubernetes.
- **Key Learning**:
  - Understand the fundamental concepts of observability.
  - Learn why monitoring and observability are crucial in modern IT environments.

### Day 2: Prometheus - Setting Up Monitoring
- **Concepts Covered**:
  - Introduction to Prometheus and its architecture.
  - Setup and configuration of Prometheus in an EKS cluster.
  - Installation of kube-prometheus-stack with Helm and integrating it with Grafana.
  - Basic queries and setup for monitoring with Prometheus and Grafana.
- **Key Learning**:
  - Get hands-on experience with Prometheus and Grafana.
  - Learn to install and configure Prometheus on Kubernetes.

### Day 3: Metrics and PromQL in Prometheus
- **Concepts Covered**:
  - Introduction to PromQL and basic querying techniques.
  - Aggregation and functions in PromQL to analyze metrics data.
- **Key Learning**:
  - Master the Prometheus Query Language (PromQL) for querying and analyzing metrics.

### Day 4: Instrumentation and Custom Metrics
- **Concepts Covered**:
  - Instrumentation for adding monitoring capabilities to applications.
  - Understanding different types of metrics in Prometheus: Counter, Gauge, Histogram, and Summary.
  - Writing custom metrics in a Node.js application using the `prom-client` library.
  - Dockerizing the application and deploying it on Kubernetes.
  - Setting up Alertmanager for alerting based on custom metrics.
- **Key Learning**:
  - Learn how to instrument applications to expose custom metrics.
  - Configure alerts in Alertmanager to monitor application performance.
  - Understand how to work with different types of metrics in Prometheus.

### Day 5: Logging with EFK Stack
- **Concepts Covered**:
  - Introduction to logging in distributed systems and Kubernetes.
  - Setting up the EFK stack (Elasticsearch, Fluentbit, Kibana) on Kubernetes.
  - Detailed setup and configuration for collecting and visualizing logs.
  - Cleaning up the Kubernetes cluster and resources.
- **Key Learning**:
  - Understand the importance of logging and how to set up

### Day 6: Distributed Tracing with Jaeger
- **Concepts Covered**:
  - Introduction to Jaeger and its architecture for distributed tracing.
  - Setting up Jaeger in a Kubernetes cluster using Helm.
  - Instrumenting services using OpenTelemetry to enable tracing.
  - Viewing and analyzing traces in the Jaeger UI.
  - Cleaning up the environment after setting up Jaeger.
- **Key Learning**:
  - Gain insights into distributed tracing and how it helps in debugging and performance optimization.
  - Learn how to set up and configure Jaeger for tracing in a microservices architecture.

### Day 7: OpenTelemetry – Setting Up Unified Observability
- **Concepts Covered**:
  - Introduction to OpenTelemetry, a unified framework for observability.
  - Understanding how OpenTelemetry integrates tracing, metrics, and logging.
  - Comparison of OpenTelemetry with prior observability tools like Jaeger, Prometheus
  - Supported programming languages and multi-language support in OpenTelemetry.
  - Step-by-step setup of OpenTelemetry in Kubernetes.
- **Key Learning**:
  - Learn how OpenTelemetry simplifies the process of collecting and exporting telemetry data.
  - Understand the benefits of a unified observability approach using OpenTelemetry.
  - Gain hands-on experience with setting up OpenTelemetry Collector, Prometheus, Jaeger, and Elasticsearch to monitor a Golang microservice application.

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>