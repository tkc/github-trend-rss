<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Wed, 17 Dec 2025 00:05:21 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[kopia/kopia]]></title>
            <link>https://github.com/kopia/kopia</link>
            <guid>https://github.com/kopia/kopia</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[Cross-platform backup tool for Windows, macOS & Linux with fast, incremental backups, client-side end-to-end encryption, compression and data deduplication. CLI and GUI included.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kopia/kopia">kopia/kopia</a></h1>
            <p>Cross-platform backup tool for Windows, macOS & Linux with fast, incremental backups, client-side end-to-end encryption, compression and data deduplication. CLI and GUI included.</p>
            <p>Language: Go</p>
            <p>Stars: 12,084</p>
            <p>Forks: 579</p>
            <p>Stars today: 40 stars today</p>
            <h2>README</h2><pre>Kopia
=====

![Kopia](icons/kopia.svg)
[![Build Status](https://github.com/kopia/kopia/workflows/Build/badge.svg)](https://github.com/kopia/kopia/actions?query=workflow%3ABuild)
[![Slack](https://img.shields.io/badge/discuss-slack-blue.svg)](https://slack.kopia.io/) 
[![GoDoc](https://godoc.org/github.com/kopia/kopia/repo?status.svg)](https://godoc.org/github.com/kopia/kopia/repo)
[![Coverage Status](https://codecov.io/gh/kopia/kopia/branch/master/graph/badge.svg?token=CRK4RMRFSH)](https://codecov.io/gh/kopia/kopia)[![Go Report Card](https://goreportcard.com/badge/github.com/kopia/kopia)](https://goreportcard.com/report/github.com/kopia/kopia)
[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg)](CODE_OF_CONDUCT.md)
[![Docker Pulls](https://img.shields.io/docker/pulls/kopia/kopia)](https://hub.docker.com/r/kopia/kopia/tags?page=1&amp;ordering=name)
[![Downloads](https://img.shields.io/github/downloads/kopia/kopia/total.svg)](https://github.com/kopia/kopia/releases)
[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Kopia%20Guru-006BFF)](https://gurubase.io/g/kopia)

&gt; _n._
&gt;
&gt; 1. _[copy, replica](https://en.wikipedia.org/wiki/Replica) (Polish)_
&gt; 2. _[lance, spear](https://en.wikipedia.org/wiki/Kopia)_
&gt; 3. _[fast and secure backup tool](https://kopia.io)_


Kopia is a fast and secure open-source backup/restore tool that allows you to create [encrypted](https://kopia.io/docs/features/#user-controlled-end-to-end-encryption) snapshots of your data and save the snapshots to [remote or cloud storage](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage) of your choice, [to network-attached storage or server](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage), or [locally on your machine](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage). Kopia does not &#039;image&#039; your whole machine. Rather, Kopia allows you to backup/restore any and all files/directories that you deem are important or critical.

Kopia has both [CLI (command-line interface)](https://kopia.io/docs/features/#both-command-line-and-graphical-user-interfaces) and [GUI (graphical user interface)](https://kopia.io/docs/features/#both-command-line-and-graphical-user-interfaces) versions, making it the perfect tool for both advanced and regular users. You can read more about Kopia&#039;s unique [features](https://kopia.io/docs/features/) -- which include [compression](https://kopia.io/docs/features/#compression), [deduplication](https://kopia.io/docs/features/#backup-files-and-directories-using-snapshots), [user-controlled end-to-end encryption](https://kopia.io/docs/features/#user-controlled-end-to-end-encryption), and [error correction](https://kopia.io/docs/features/#error-correction) -- to get a better understanding of how Kopia works.

When ready, head to the [installation](https://kopia.io/docs/installation/) page to download and install Kopia, and make sure to read the [Getting Started Guide](https://kopia.io/docs/getting-started/) for a step-by-step walkthrough of how to use Kopia.

Pick the Cloud Storage Provider You Want
---

Kopia supports saving your [encrypted](https://kopia.io/docs/features/#user-controlled-end-to-end-encryption) and [compressed](https://kopia.io/docs/features/#compression) snapshots to all of the following [storage locations](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage):

* **Amazon S3** and any **cloud storage that is compatible with S3**
* **Azure Blob Storage**
* **Backblaze B2**
* **Google Cloud Storage**
* Any remote server or cloud storage that supports **WebDAV**
* Any remote server or cloud storage that supports **SFTP**
* Some of the cloud storage options supported by **Rclone**
  * Requires you to download and setup Rclone in addition to Kopia, but after that Kopia manages/runs Rclone for you
  * Rclone support is experimental: not all the cloud storage products supported by Rclone have been tested to work with Kopia, and some may not work with Kopia; Kopia has been tested to work with **Dropbox**, **OneDrive**, and **Google Drive** through Rclone
* Your local machine and any network-attached storage or server
* Your own server by setting up a [Kopia Repository Server](https://kopia.io/docs/repository-server/)

And Kopia uses [data deduplication](https://kopia.io/docs/features/#backup-files-and-directories-using-snapshots) to save you money! Read the [repositories help page](https://kopia.io/docs/repositories/) for more information on supported storage locations.

With Kopia you are in full control of where to store your snapshots, that is, you pick the storage provider you want to use. You must provision and pay for the storage provider for whatever storage locations you want to use, and then tell Kopia what those storage locations are. You can even use multiple storage locations for different backup repositories if you want. Kopia also supports backing up multiple machines to the same storage location.

Kopia in Action
---

Using Kopia via command-line interface:

[![asciicast](https://asciinema.org/a/ykx6uzEhKY3451fWEnX9nm9uo.svg)](https://asciinema.org/a/ykx6uzEhKY3451fWEnX9nm9uo)

Using Kopia via graphical user interface (note: the video is of an older version of Kopia and the interface is different in the current version of Kopia, but the main principles of the interface are the same):

[![Kopia UI Tutorial](https://img.youtube.com/vi/sHJjSpasWIo/0.jpg)](https://www.youtube.com/watch?v=sHJjSpasWIo)

Getting Started
---
See [Kopia Documentation](https://kopia.io/docs/) for more information.

Building Kopia
---
See [Build Infrastructure](BUILD.md) for more information on building Kopia and working with the source code.

Licensing
---
Kopia is licensed under the Apache License, Version 2.0. See [LICENSE](LICENSE) for the full license text.

Contribution Guidelines
---
Kopia is open source and contributions are welcome. For more information on how to contribute see the [Contribution Guidelines](https://kopia.io/docs/contribution-guidelines/).

Reporting Security Issues
---
If you find a security issue you&#039;d like to disclose privately, please contact `security@kopia.io` or via direct message to maintainers on [Slack](https://slack.kopia.io).

[![Netlify Status](https://api.netlify.com/api/v1/badges/6b5c1fe4-a0da-4e7e-939b-ff1105251985/deploy-status)](https://app.netlify.com/sites/kopia/deploys)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[livekit/livekit]]></title>
            <link>https://github.com/livekit/livekit</link>
            <guid>https://github.com/livekit/livekit</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[End-to-end realtime stack for connecting humans and AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/livekit/livekit">livekit/livekit</a></h1>
            <p>End-to-end realtime stack for connecting humans and AI</p>
            <p>Language: Go</p>
            <p>Stars: 16,110</p>
            <p>Forks: 1,619</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>&lt;!--BEGIN_BANNER_IMAGE--&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;/.github/banner_dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;/.github/banner_light.png&quot;&gt;
  &lt;img style=&quot;width:100%;&quot; alt=&quot;The LiveKit icon, the name of the repository and some sample code in the background.&quot; src=&quot;https://raw.githubusercontent.com/livekit/livekit/main/.github/banner_light.png&quot;&gt;
&lt;/picture&gt;

&lt;!--END_BANNER_IMAGE--&gt;

# LiveKit: Real-time video, audio and data for developers

[LiveKit](https://livekit.io) is an open source project that provides scalable, multi-user conferencing based on WebRTC.
It&#039;s designed to provide everything you need to build real-time video audio data capabilities in your applications.

LiveKit&#039;s server is written in Go, using the awesome [Pion WebRTC](https://github.com/pion/webrtc) implementation.

[![GitHub stars](https://img.shields.io/github/stars/livekit/livekit?style=social&amp;label=Star&amp;maxAge=2592000)](https://github.com/livekit/livekit/stargazers/)
[![Slack community](https://img.shields.io/endpoint?url=https%3A%2F%2Flivekit.io%2Fbadges%2Fslack)](https://livekit.io/join-slack)
[![Twitter Follow](https://img.shields.io/twitter/follow/livekit)](https://twitter.com/livekit)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/livekit/livekit)
[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/livekit/livekit)](https://github.com/livekit/livekit/releases/latest)
[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/livekit/livekit/buildtest.yaml?branch=master)](https://github.com/livekit/livekit/actions/workflows/buildtest.yaml)
[![License](https://img.shields.io/github/license/livekit/livekit)](https://github.com/livekit/livekit/blob/master/LICENSE)

## Features

-   Scalable, distributed WebRTC SFU (Selective Forwarding Unit)
-   Modern, full-featured client SDKs
-   Built for production, supports JWT authentication
-   Robust networking and connectivity, UDP/TCP/TURN
-   Easy to deploy: single binary, Docker or Kubernetes
-   Advanced features including:
    -   [speaker detection](https://docs.livekit.io/home/client/tracks/subscribe/#speaker-detection)
    -   [simulcast](https://docs.livekit.io/home/client/tracks/publish/#video-simulcast)
    -   [end-to-end optimizations](https://blog.livekit.io/livekit-one-dot-zero/)
    -   [selective subscription](https://docs.livekit.io/home/client/tracks/subscribe/#selective-subscription)
    -   [moderation APIs](https://docs.livekit.io/home/server/managing-participants/)
    -   end-to-end encryption
    -   SVC codecs (VP9, AV1)
    -   [webhooks](https://docs.livekit.io/home/server/webhooks/)
    -   [distributed and multi-region](https://docs.livekit.io/home/self-hosting/distributed/)

## Documentation &amp; Guides

https://docs.livekit.io

## Live Demos

-   [LiveKit Meet](https://meet.livekit.io) ([source](https://github.com/livekit-examples/meet))
-   [Spatial Audio](https://spatial-audio-demo.livekit.io/) ([source](https://github.com/livekit-examples/spatial-audio))
-   Livestreaming from OBS Studio ([source](https://github.com/livekit-examples/livestream))
-   [AI voice assistant using ChatGPT](https://livekit.io/kitt) ([source](https://github.com/livekit-examples/kitt))

## Ecosystem

-   [Agents](https://github.com/livekit/agents): build real-time multimodal AI applications with programmable backend participants
-   [Egress](https://github.com/livekit/egress): record or multi-stream rooms and export individual tracks
-   [Ingress](https://github.com/livekit/ingress): ingest streams from external sources like RTMP, WHIP, HLS, or OBS Studio

## SDKs &amp; Tools

### Client SDKs

Client SDKs enable your frontend to include interactive, multi-user experiences.

&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;Language&lt;/th&gt;
    &lt;th&gt;Repo&lt;/th&gt;
    &lt;th&gt;
        &lt;a href=&quot;https://docs.livekit.io/home/client/events/#declarative-ui&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Declarative UI&lt;/a&gt;
    &lt;/th&gt;
    &lt;th&gt;Links&lt;/th&gt;
  &lt;/tr&gt;
  &lt;!-- BEGIN Template
  &lt;tr&gt;
    &lt;td&gt;Language&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  END --&gt;
  &lt;!-- JavaScript --&gt;
  &lt;tr&gt;
    &lt;td&gt;JavaScript (TypeScript)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-js&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-js&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/livekit-react&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;React&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-js/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-js/tree/main/example&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;JS example&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-js/tree/main/example&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;React example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Swift --&gt;
  &lt;tr&gt;
    &lt;td&gt;Swift (iOS / MacOS)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-swift&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-swift&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;Swift UI&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-swift/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-example-swift&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Kotlin --&gt;
  &lt;tr&gt;
    &lt;td&gt;Kotlin (Android)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-android&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-android&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;Compose&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-android/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-android/tree/main/sample-app/src/main/java/io/livekit/android/sample&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;example&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-android/tree/main/sample-app-compose/src/main/java/io/livekit/android/composesample&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Compose example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;!-- Flutter --&gt;
  &lt;tr&gt;
    &lt;td&gt;Flutter (all platforms)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-flutter&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;native&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-flutter/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter/tree/main/example&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Unity --&gt;
  &lt;tr&gt;
    &lt;td&gt;Unity WebGL&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-unity-web&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-unity-web&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://livekit.github.io/client-sdk-unity-web/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- React Native --&gt;
  &lt;tr&gt;
    &lt;td&gt;React Native (beta)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-react-native&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-react-native&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;native&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Rust --&gt;
  &lt;tr&gt;
    &lt;td&gt;Rust&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-rust&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-rust&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

### Server SDKs

Server SDKs enable your backend to generate [access tokens](https://docs.livekit.io/home/get-started/authentication/),
call [server APIs](https://docs.livekit.io/reference/server/server-apis/), and
receive [webhooks](https://docs.livekit.io/home/server/webhooks/). In addition, the Go SDK includes client capabilities,
enabling you to build automations that behave like end-users.

| Language                | Repo                                                                                    | Docs                                                        |
| :---------------------- | :-------------------------------------------------------------------------------------- | :---------------------------------------------------------- |
| Go                      | [server-sdk-go](https://github.com/livekit/server-sdk-go)                               | [docs](https://pkg.go.dev/github.com/livekit/server-sdk-go) |
| JavaScript (TypeScript) | [server-sdk-js](https://github.com/livekit/server-sdk-js)                               | [docs](https://docs.livekit.io/server-sdk-js/)              |
| Ruby                    | [server-sdk-ruby](https://github.com/livekit/server-sdk-ruby)                           |                                                             |
| Java (Kotlin)           | [server-sdk-kotlin](https://github.com/livekit/server-sdk-kotlin)                       |                                                             |
| Python (community)      | [python-sdks](https://github.com/livekit/python-sdks)                                   |                                                             |
| PHP (community)         | [agence104/livekit-server-sdk-php](https://github.com/agence104/livekit-server-sdk-php) |                                                             |

### Tools

-   [CLI](https://github.com/livekit/livekit-cli) - command line interface &amp; load tester
-   [Docker image](https://hub.docker.com/r/livekit/livekit-server)
-   [Helm charts](https://github.com/livekit/livekit-helm)

## Install

&gt; [!TIP]
&gt; We recommend installing [LiveKit CLI](https://github.com/livekit/livekit-cli) along with the server. It lets you access
&gt; server APIs, create tokens, and generate test traffic.

The following will install LiveKit&#039;s media server:

### MacOS

```shell
brew install livekit
```

### Linux

```shell
curl -sSL https://get.livekit.io | bash
```

### Windows

Download the [latest release here](https://github.com/livekit/livekit/releases/latest)

## Getting Started

### Starting LiveKit

Start LiveKit in development mode by running `livekit-server --dev`. It&#039;ll use a placeholder API key/secret pair.

```
API Key: devkey
API Secret: secret
```

To customize your setup for production, refer to our [deployment docs](https://docs.livekit.io/deploy/)

### Creating access token

A user connecting to a LiveKit room requires an [access token](https://docs.livekit.io/home/get-started/authentication/#creating-a-token). Access
tokens (JWT) encode the user&#039;s identity and the room permissions they&#039;ve been granted. You can generate a token with our
CLI:

```shell
lk token create \
    --api-key devkey --api-secret secret \
    --join --room my-first-room --identity user1 \
    --valid-for 24h
```

### Test with example app

Head over to our [example app](https://example.livekit.io) and enter a generated token to connect to your LiveKit
server. This app is built with our [React SDK](https://github.com/livekit/livekit-react).

Once connected, your video and audio are now being published to your new LiveKit instance!

### Simulating a test publisher

```shell
lk room join \
    --url ws://localhost:7880 \
    --api-key devkey --api-secret secret \
    --identity bot-user1 \
    --publish-demo \
    my-first-room
```

This command publishes a looped demo video to a room. Due to how the video clip was encoded (keyframes every 3s),
there&#039;s a slight delay before the browser has sufficient data to begin rendering frames. This is an artifact of the
simulation.

## Deployment

### Use LiveKit Cloud

LiveKit Cloud is the fastest and most reliable way to run LiveKit. Every project gets free monthly bandwidth and
transcoding credits.

Sign up for [LiveKit Cloud](https://cloud.livekit.io/).

### Self-host

Read our [deployment docs](https://docs.livekit.io/deploy/) for more information.

## Building from source

Pre-requisites:

-   Go 1.23+ is installed
-   GOPATH/bin is in your PATH

Then run

```shell
git clone https://github.com/livekit/livekit
cd livekit
./bootstrap.sh
mage
```

## Contributing

We welcome your contributions toward improving LiveKit! Please join us
[on Slack](http://livekit.io/join-slack) to discuss your ideas and/or PRs.

## License

LiveKit server is licensed under Apache License v2.0.

&lt;!--BEGIN_REPO_NAV--&gt;
&lt;br/&gt;&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;LiveKit Ecosystem&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;LiveKit SDKs&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/client-sdk-js&quot;&gt;Browser&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-swift&quot;&gt;iOS/macOS/visionOS&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-android&quot;&gt;Android&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter&quot;&gt;Flutter&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-react-native&quot;&gt;React Native&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/rust-sdks&quot;&gt;Rust&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/node-sdks&quot;&gt;Node.js&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/python-sdks&quot;&gt;Python&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-unity&quot;&gt;Unity&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-unity-web&quot;&gt;Unity (WebGL)&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/client-sdk-esp32&quot;&gt;ESP32&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Server APIs&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/node-sdks&quot;&gt;Node.js&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/server-sdk-go&quot;&gt;Golang&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/server-sdk-ruby&quot;&gt;Ruby&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/server-sdk-kotlin&quot;&gt;Java/Kotlin&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/python-sdks&quot;&gt;Python&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/rust-sdks&quot;&gt;Rust&lt;/a&gt; · &lt;a href=&quot;https://github.com/agence104/livekit-server-sdk-php&quot;&gt;PHP (community)&lt;/a&gt; · &lt;a href=&quot;https://github.com/pabloFuente/livekit-server-sdk-dotnet&quot;&gt;.NET (community)&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;UI Components&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/components-js&quot;&gt;React&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/components-android&quot;&gt;Android Compose&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/components-swift&quot;&gt;SwiftUI&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/components-flutter&quot;&gt;Flutter&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Agents Frameworks&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/agents&quot;&gt;Python&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/agents-js&quot;&gt;Node.js&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/agent-playground&quot;&gt;Playground&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Services&lt;/td&gt;&lt;td&gt;&lt;b&gt;LiveKit server&lt;/b&gt; · &lt;a href=&quot;https://github.com/livekit/egress&quot;&gt;Egress&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/ingress&quot;&gt;Ingress&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/sip&quot;&gt;SIP&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Resources&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://docs.livekit.io&quot;&gt;Docs&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit-examples&quot;&gt;Example apps&lt;/a&gt; · &lt;a href=&quot;https://livekit.io/cloud&quot;&gt;Cloud&lt;/a&gt; · &lt;a href=&quot;https://docs.livekit.io/home/self-hosting/deployment&quot;&gt;Self-hosting&lt;/a&gt; · &lt;a href=&quot;https://github.com/livekit/livekit-cli&quot;&gt;CLI&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!--END_REPO_NAV--&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[danielmiessler/Fabric]]></title>
            <link>https://github.com/danielmiessler/Fabric</link>
            <guid>https://github.com/danielmiessler/Fabric</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/danielmiessler/Fabric">danielmiessler/Fabric</a></h1>
            <p>Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.</p>
            <p>Language: Go</p>
            <p>Stars: 35,215</p>
            <p>Forks: 3,592</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://go.warp.dev/fabric&quot; target=&quot;_blank&quot;&gt;
        &lt;sup&gt;Special thanks to:&lt;/sup&gt;
        &lt;br&gt;
        &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png&quot;&gt;
        &lt;br&gt;
        &lt;h&gt;Warp, built for coding with multiple AI agents&lt;/b&gt;
        &lt;br&gt;
        &lt;sup&gt;Available for macOS, Linux and Windows&lt;/sup&gt;
    &lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;./docs/images/fabric-logo-gif.gif&quot; alt=&quot;fabriclogo&quot; width=&quot;400&quot; height=&quot;400&quot;/&gt;

# `fabric`

![Static Badge](https://img.shields.io/badge/mission-human_flourishing_via_AI_augmentation-purple)
&lt;br /&gt;
![GitHub top language](https://img.shields.io/github/languages/top/danielmiessler/fabric)
![GitHub last commit](https://img.shields.io/github/last-commit/danielmiessler/fabric)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/danielmiessler/fabric)

&lt;div align=&quot;center&quot;&gt;
&lt;h4&gt;&lt;code&gt;fabric&lt;/code&gt; is an open-source framework for augmenting humans using AI.&lt;/h4&gt;
&lt;/div&gt;

![Screenshot of fabric](./docs/images/fabric-summarize.png)

&lt;/div&gt;

[Updates](#updates) •
[What and Why](#what-and-why) •
[Philosophy](#philosophy) •
[Installation](#installation) •
[Usage](#usage) •
[Examples](#examples) •
[Just Use the Patterns](#just-use-the-patterns) •
[Custom Patterns](#custom-patterns) •
[Helper Apps](#helper-apps) •
[Meta](#meta)

&lt;/div&gt;

## What and why

Since the start of modern AI in late 2022 we&#039;ve seen an **_extraordinary_** number of AI applications for accomplishing tasks. There are thousands of websites, chat-bots, mobile apps, and other interfaces for using all the different AI out there.

It&#039;s all really exciting and powerful, but _it&#039;s not easy to integrate this functionality into our lives._

&lt;div class=&quot;align center&quot;&gt;
&lt;h4&gt;In other words, AI doesn&#039;t have a capabilities problem—it has an &lt;em&gt;integration&lt;/em&gt; problem.&lt;/h4&gt;
&lt;/div&gt;

**Fabric was created to address this by creating and organizing the fundamental units of AI—the prompts themselves!**

Fabric organizes prompts by real-world task, allowing people to create, collect, and organize their most important AI solutions in a single place for use in their favorite tools. And if you&#039;re command-line focused, you can use Fabric itself as the interface!

## Updates

&lt;details&gt;
&lt;summary&gt;Click to view recent updates&lt;/summary&gt;

Dear Users,

We&#039;ve been doing so many exciting things here at Fabric, I wanted to give a quick summary here to give you a sense of our development velocity!

Below are the **new features and capabilities** we&#039;ve added (newest first):

### Recent Major Features

- [v1.4.338](https://github.com/danielmiessler/fabric/releases/tag/v1.4.338) (Dec 4, 2025) — Add Abacus vendor support for Chat-LLM
  models (see [RouteLLM APIs](https://abacus.ai/app/route-llm-apis)).
- [v1.4.337](https://github.com/danielmiessler/fabric/releases/tag/v1.4.337) (Dec 4, 2025) — Add &quot;Z AI&quot; vendor support. See the [Z AI overview](https://docs.z.ai/guides/overview/overview) page for more details.
- [v1.4.334](https://github.com/danielmiessler/fabric/releases/tag/v1.4.334) (Nov 26, 2025) — **Claude Opus 4.5**: Updates the Anthropic SDK to the latest and adds the new [Claude Opus 4.5](https://www.anthropic.com/news/claude-opus-4-5) to the available models.
- [v1.4.331](https://github.com/danielmiessler/fabric/releases/tag/v1.4.331) (Nov 23, 2025) — **Support for GitHub Models**: Adds support for using GitHub Models.
- [v1.4.322](https://github.com/danielmiessler/fabric/releases/tag/v1.4.322) (Nov 5, 2025) — **Interactive HTML Concept Maps and Claude Sonnet 4.5**: Adds `create_conceptmap` pattern for visual knowledge representation using Vis.js, introduces WELLNESS category with psychological analysis patterns, and upgrades to Claude Sonnet 4.5
- [v1.4.317](https://github.com/danielmiessler/fabric/releases/tag/v1.4.317) (Sep 21, 2025) — **Portuguese Language Variants**: Adds BCP 47 locale normalization with support for Brazilian Portuguese (pt-BR) and European Portuguese (pt-PT) with intelligent fallback chains
- [v1.4.314](https://github.com/danielmiessler/fabric/releases/tag/v1.4.314) (Sep 17, 2025) — **Azure OpenAI Migration**: Migrates to official `openai-go/azure` SDK with improved authentication and default API version support
- [v1.4.311](https://github.com/danielmiessler/fabric/releases/tag/v1.4.311) (Sep 13, 2025) — **More internationalization support**: Adds de (German), fa (Persian / Farsi), fr (French), it (Italian),
  ja (Japanese), pt (Portuguese), zh (Chinese)
- [v1.4.309](https://github.com/danielmiessler/fabric/releases/tag/v1.4.309) (Sep 9, 2025) — **Comprehensive internationalization support**: Includes English and Spanish locale files.
- [v1.4.303](https://github.com/danielmiessler/fabric/releases/tag/v1.4.303) (Aug 29, 2025) — **New Binary Releases**: Linux ARM and Windows ARM targets. You can run Fabric on the Raspberry PI and on your Windows Surface!
- [v1.4.294](https://github.com/danielmiessler/fabric/releases/tag/v1.4.294) (Aug 20, 2025) — **Venice AI Support**: Added the Venice AI provider. Venice is a Privacy-First, Open-Source AI provider. See their [&quot;About Venice&quot;](https://docs.venice.ai/overview/about-venice) page for details.
- [v1.4.291](https://github.com/danielmiessler/fabric/releases/tag/v1.4.291) (Aug 18, 2025) — **Speech To Text**: Add OpenAI speech-to-text support with `--transcribe-file`, `--transcribe-model`, and `--split-media-file` flags.
- [v1.4.287](https://github.com/danielmiessler/fabric/releases/tag/v1.4.287) (Aug 16, 2025) — **AI Reasoning**: Add Thinking to Gemini models and introduce `readme_updates` python script
- [v1.4.286](https://github.com/danielmiessler/fabric/releases/tag/v1.4.286) (Aug 14, 2025) — **AI Reasoning**: Introduce Thinking Config Across Anthropic and OpenAI Providers
- [v1.4.285](https://github.com/danielmiessler/fabric/releases/tag/v1.4.285) (Aug 13, 2025) — **Extended Context**: Enable One Million Token Context Beta Feature for Sonnet-4
- [v1.4.284](https://github.com/danielmiessler/fabric/releases/tag/v1.4.284) (Aug 12, 2025) — **Easy Shell Completions Setup**: Introduce One-Liner Curl Install for Completions
- [v1.4.283](https://github.com/danielmiessler/fabric/releases/tag/v1.4.283) (Aug 12, 2025) — **Model Management**: Add Vendor Selection Support for Models
- [v1.4.282](https://github.com/danielmiessler/fabric/releases/tag/v1.4.282) (Aug 11, 2025) — **Enhanced Shell Completions**: Enhanced Shell Completions for Fabric CLI Binaries
- [v1.4.281](https://github.com/danielmiessler/fabric/releases/tag/v1.4.281) (Aug 11, 2025) — **Gemini Search Tool**: Add Web Search Tool Support for Gemini Models
- [v1.4.278](https://github.com/danielmiessler/fabric/releases/tag/v1.4.278) (Aug 9, 2025) — **Enhance YouTube Transcripts**: Enhance YouTube Support with Custom yt-dlp Arguments
- [v1.4.277](https://github.com/danielmiessler/fabric/releases/tag/v1.4.277) (Aug 8, 2025) — **Desktop Notifications**: Add cross-platform desktop notifications to Fabric CLI
- [v1.4.274](https://github.com/danielmiessler/fabric/releases/tag/v1.4.274) (Aug 7, 2025) — **Claude 4.1 Added**: Add Support for Claude Opus 4.1 Model
- [v1.4.271](https://github.com/danielmiessler/fabric/releases/tag/v1.4.271) (Jul 28, 2025) — **AI Summarized Release Notes**: Enable AI summary updates for GitHub releases
- [v1.4.268](https://github.com/danielmiessler/fabric/releases/tag/v1.4.268) (Jul 26, 2025) — **Gemini TTS Voice Selection**: add Gemini TTS voice selection and listing functionality
- [v1.4.267](https://github.com/danielmiessler/fabric/releases/tag/v1.4.267) (Jul 26, 2025) — **Text-to-Speech**: Update Gemini Plugin to New SDK with TTS Support
- [v1.4.258](https://github.com/danielmiessler/fabric/releases/tag/v1.4.258) (Jul 17, 2025) — **Onboarding Improved**: Add startup check to initialize config and .env file automatically
- [v1.4.257](https://github.com/danielmiessler/fabric/releases/tag/v1.4.257) (Jul 17, 2025) — **OpenAI Routing Control**: Introduce CLI Flag to Disable OpenAI Responses API
- [v1.4.252](https://github.com/danielmiessler/fabric/releases/tag/v1.4.252) (Jul 16, 2025) — **Hide Thinking Block**: Optional Hiding of Model Thinking Process with Configurable Tags
- [v1.4.246](https://github.com/danielmiessler/fabric/releases/tag/v1.4.246) (Jul 14, 2025) — **Automatic ChangeLog Updates**: Add AI-powered changelog generation with high-performance Go tool and comprehensive caching
- [v1.4.245](https://github.com/danielmiessler/fabric/releases/tag/v1.4.245) (Jul 11, 2025) — **Together AI**: Together AI Support with OpenAI Fallback Mechanism Added
- [v1.4.232](https://github.com/danielmiessler/fabric/releases/tag/v1.4.232) (Jul 6, 2025) — **Add Custom**: Add Custom Patterns Directory Support
- [v1.4.231](https://github.com/danielmiessler/fabric/releases/tag/v1.4.231) (Jul 5, 2025) — **OAuth Auto-Auth**: OAuth Authentication Support for Anthropic (Use your Max Subscription)
- [v1.4.230](https://github.com/danielmiessler/fabric/releases/tag/v1.4.230) (Jul 5, 2025) — **Model Management**: Add advanced image generation parameters for OpenAI models with four new CLI flags
- [v1.4.227](https://github.com/danielmiessler/fabric/releases/tag/v1.4.227) (Jul 4, 2025) — **Add Image**: Add Image Generation Support to Fabric
- [v1.4.226](https://github.com/danielmiessler/fabric/releases/tag/v1.4.226) (Jul 4, 2025) — **Web Search**: OpenAI Plugin Now Supports Web Search Functionality
- [v1.4.225](https://github.com/danielmiessler/fabric/releases/tag/v1.4.225) (Jul 4, 2025) — **Web Search**: Runtime Web Search Control via Command-Line `--search` Flag
- [v1.4.224](https://github.com/danielmiessler/fabric/releases/tag/v1.4.224) (Jul 1, 2025) — **Add code_review**: Add code_review pattern and updates in Pattern_Descriptions
- [v1.4.222](https://github.com/danielmiessler/fabric/releases/tag/v1.4.222) (Jul 1, 2025) — **OpenAI Plugin**: OpenAI Plugin Migrates to New Responses API
- [v1.4.218](https://github.com/danielmiessler/fabric/releases/tag/v1.4.218) (Jun 27, 2025) — **Model Management**: Add Support for OpenAI Search and Research Model Variants
- [v1.4.217](https://github.com/danielmiessler/fabric/releases/tag/v1.4.217) (Jun 26, 2025) — **New YouTube**: New YouTube Transcript Endpoint Added to REST API
- [v1.4.212](https://github.com/danielmiessler/fabric/releases/tag/v1.4.212) (Jun 23, 2025) — **Add Langdock**: Add Langdock AI and enhance generic OpenAI compatible support
- [v1.4.211](https://github.com/danielmiessler/fabric/releases/tag/v1.4.211) (Jun 19, 2025) — **REST API**: REST API and Web UI Now Support Dynamic Pattern Variables
- [v1.4.210](https://github.com/danielmiessler/fabric/releases/tag/v1.4.210) (Jun 18, 2025) — **Add Citations**: Add Citation Support to Perplexity Response
- [v1.4.208](https://github.com/danielmiessler/fabric/releases/tag/v1.4.208) (Jun 17, 2025) — **Add Perplexity**: Add Perplexity AI Provider with Token Limits Support
- [v1.4.203](https://github.com/danielmiessler/fabric/releases/tag/v1.4.203) (Jun 14, 2025) — **Add Amazon Bedrock**: Add support for Amazon Bedrock

These features represent our commitment to making Fabric the most powerful and flexible AI augmentation framework available!

&lt;/details&gt;

## Intro videos

Keep in mind that many of these were recorded when Fabric was Python-based, so remember to use the current [install instructions](#installation) below.

- [Network Chuck](https://www.youtube.com/watch?v=UbDyjIIGaxQ)
- [David Bombal](https://www.youtube.com/watch?v=vF-MQmVxnCs)
- [My Own Intro to the Tool](https://www.youtube.com/watch?v=wPEyyigh10g)
- [More Fabric YouTube Videos](https://www.youtube.com/results?search_query=fabric+ai)

## Navigation

- [`fabric`](#fabric)
  - [What and why](#what-and-why)
  - [Updates](#updates)
    - [Recent Major Features](#recent-major-features)
  - [Intro videos](#intro-videos)
  - [Navigation](#navigation)
  - [Changelog](#changelog)
  - [Philosophy](#philosophy)
    - [Breaking problems into components](#breaking-problems-into-components)
    - [Too many prompts](#too-many-prompts)
  - [Installation](#installation)
    - [One-Line Install (Recommended)](#one-line-install-recommended)
    - [Manual Binary Downloads](#manual-binary-downloads)
    - [Using package managers](#using-package-managers)
      - [macOS (Homebrew)](#macos-homebrew)
      - [Arch Linux (AUR)](#arch-linux-aur)
      - [Windows](#windows)
    - [From Source](#from-source)
    - [Docker](#docker)
    - [Environment Variables](#environment-variables)
    - [Setup](#setup)
    - [Per-Pattern Model Mapping](#per-pattern-model-mapping)
    - [Add aliases for all patterns](#add-aliases-for-all-patterns)
      - [Save your files in markdown using aliases](#save-your-files-in-markdown-using-aliases)
    - [Migration](#migration)
    - [Upgrading](#upgrading)
    - [Shell Completions](#shell-completions)
      - [Quick install (no clone required)](#quick-install-no-clone-required)
      - [Zsh Completion](#zsh-completion)
      - [Bash Completion](#bash-completion)
      - [Fish Completion](#fish-completion)
  - [Usage](#usage)
    - [Debug Levels](#debug-levels)
    - [Extensions](#extensions)
  - [Our approach to prompting](#our-approach-to-prompting)
  - [Examples](#examples)
  - [Just use the Patterns](#just-use-the-patterns)
    - [Prompt Strategies](#prompt-strategies)
  - [Custom Patterns](#custom-patterns)
    - [Setting Up Custom Patterns](#setting-up-custom-patterns)
    - [Using Custom Patterns](#using-custom-patterns)
    - [How It Works](#how-it-works)
  - [Helper Apps](#helper-apps)
    - [`to_pdf`](#to_pdf)
    - [`to_pdf` Installation](#to_pdf-installation)
    - [`code_helper`](#code_helper)
  - [pbpaste](#pbpaste)
  - [Web Interface (Fabric Web App)](#web-interface-fabric-web-app)
  - [Meta](#meta)
    - [Primary contributors](#primary-contributors)
    - [Contributors](#contributors)

&lt;br /&gt;

## Changelog

Fabric is evolving rapidly.

Stay current with the latest features by reviewing the [CHANGELOG](./CHANGELOG.md) for all recent changes.

## Philosophy

&gt; AI isn&#039;t a thing; it&#039;s a _magnifier_ of a thing. And that thing is **human creativity**.

We believe the purpose of technology is to help humans flourish, so when we talk about AI we start with the **human** problems we want to solve.

### Breaking problems into components

Our approach is to break problems into individual pieces (see below) and then apply AI to them one at a time. See below for some examples.

&lt;img width=&quot;2078&quot; alt=&quot;augmented_challenges&quot; src=&quot;https://github.com/danielmiessler/fabric/assets/50654/31997394-85a9-40c2-879b-b347e4701f06&quot;&gt;

### Too many prompts

Prompts are good for this, but the biggest challenge I faced in 2023——which still exists today—is **the sheer number of AI prompts out there**. We all have prompts that are useful, but it&#039;s hard to discover new ones, know if they are good or not, _and manage different versions of the ones we like_.

One of `fabric`&#039;s primary features is helping people collect and integrate prompts, which we call _Patterns_, into various parts of their lives.

Fabric has Patterns for all sorts of life and work activities, including:

- Extracting the most interesting parts of YouTube videos and podcasts
- Writing an essay in your own voice with just an idea as an input
- Summarizing opaque academic papers
- Creating perfectly matched AI art prompts for a piece of writing
- Rating the quality of content to see if you want to read/watch the whole thing
- Getting summaries of long, boring content
- Explaining code to you
- Turning bad documentation into usable documentation
- Creating social media posts from any content input
- And a million more…

## Installation

### One-Line Install (Recommended)

**Unix/Linux/macOS:**

```bash
curl -fsSL https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.sh | bash
```

**Windows PowerShell:**

```powershell
iwr -useb https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.ps1 | iex
```

&gt; See [scripts/installer/README.md](./scripts/installer/README.md) for custom installation options and troubleshooting.

### Manual Binary Downloads

The latest release binary archives and their expected SHA256 hashes can be found at &lt;https://github.com/danielmiessler/fabric/releases/latest&gt;

### Using package managers

**NOTE:** using Homebrew or the Arch Linux package managers makes `fabric` available as `fabric-ai`, so add
the following alias to your shell startup files to account for this:

```bash
alias fabric=&#039;fabric-ai&#039;
```

#### macOS (Homebrew)

`brew install fabric-ai`

#### Arch Linux (AUR)

`yay -S fabric-ai`

#### Windows

Use the official Microsoft supported `Winget` tool:

`winget install danielmiessler.Fabric`

### From Source

To install Fabric, [make sure Go is installed](https://go.dev/doc/install), and then run the following command.

```bash
# Install Fabric directly from the repo
go install github.com/danielmiessler/fabric/cmd/fabric@latest
```

### Docker

Run Fabric using pre-built Docker images:

```bash
# Use latest image from Docker Hub
docker run --rm -it kayvan/fabric:latest --version

# Use specific version from GHCR
docker run --rm -it ghcr.io/ksylvan/fabric:v1.4.305 --version

# Run setup (first time)
mkdir -p $HOME/.fabric-config
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --setup

# Use Fabric with your patterns
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest -p summarize

# Run the REST API server
docker run --rm -it -p 8080:8080 -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --serve
```

**Images available at:**

- Docker Hub: [kayvan/fabric](https://hub.docker.com/repository/docker/kayvan/fabric/general)
- GHCR: [ksylvan/fabric](https://github.com/ksylvan/fabric/pkgs/container/fabric)

See [scripts/docker/README.md](./scripts/docker/README.md) for building custom images and advanced configuration.

### Environment Variables

You may need to set some environment variables in your `~/.bashrc` on linux or `~/.zshrc` file on mac to be able to run the `fabric` command. Here is an example of what you can add:

For Intel based macs or linux

```bash
# Golang environment variables
export GOROOT=/usr/local/go
export GOPATH=$HOME/go

# Update PATH to include GOPATH and GOROOT binaries
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
```

for Apple Silicon based macs

```bash
# Golang environment variables
export GOROOT=$(brew --prefix go)/libexec
export GOPATH=$HOME/go
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
```

### Setup

Now run the following command

```bash
# Run the setup to set up your directories and keys
fabric --setup
```

If everything works you are good to go.

### Per-Pattern Model Mapping

 You can configure specific models for individual patterns using environment variables
 like `FABRIC_MODEL_PATTERN_NAME=vendor|model`

 This makes it easy to maintain these per-pattern model mappings in your shell startup files.

### Add aliases for all patterns

In order to add aliases for all your patterns and use them directly as commands, for example, `summarize` instead of `fabric --pattern summarize`
You can add the following to your `.zshrc` or `.bashrc` file. You
can also optionally set the `FABRIC_ALIAS_PREFIX` environment variable
before, if you&#039;d prefer all the fabric aliases to start with the same prefix.

```bash
# Loop through all files in the ~/.config/fabric/patterns directory
for pattern_file in $HOME/.config/fabric/patterns/*; do
    # Get the base name of the file (i.e., remove the directory path)
    pattern_name=&quot;$(basename &quot;$pattern_file&quot;)&quot;
    alias_name=&quot;${FABRIC_ALIAS_PREFIX:-}${pattern_name}&quot;

    # Create an alias in th

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[NVIDIA/KAI-Scheduler]]></title>
            <link>https://github.com/NVIDIA/KAI-Scheduler</link>
            <guid>https://github.com/NVIDIA/KAI-Scheduler</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[KAI Scheduler is an open source Kubernetes Native scheduler for AI workloads at large scale]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NVIDIA/KAI-Scheduler">NVIDIA/KAI-Scheduler</a></h1>
            <p>KAI Scheduler is an open source Kubernetes Native scheduler for AI workloads at large scale</p>
            <p>Language: Go</p>
            <p>Stars: 995</p>
            <p>Forks: 120</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](LICENSE) [![Coverage](https://github.com/NVIDIA/KAI-Scheduler/raw/coverage-badge/badges/coverage.svg)](https://github.com/NVIDIA/KAI-Scheduler/blob/main/.github/workflows/update-coverage-badge.yaml)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/NVIDIA/KAI-Scheduler)
# KAI Scheduler
KAI Scheduler is a robust, efficient, and scalable [Kubernetes scheduler](https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/) that optimizes GPU resource allocation for AI and machine learning workloads.

Designed to manage large-scale GPU clusters, including thousands of nodes, and high-throughput of workloads, makes the KAI Scheduler ideal for extensive and demanding environments.
KAI Scheduler allows administrators of Kubernetes clusters to dynamically allocate GPU resources to workloads. 

KAI Scheduler supports the entire AI lifecycle, from small, interactive jobs that require minimal resources to large training and inference, all within the same cluster. 
It ensures optimal resource allocation while maintaining resource fairness between the different consumers.
It can run alongside other schedulers installed on the cluster.

## Latest News 🔥

- [2025/11] **KubeCon NA 2025 Talk:** Watch the recording of the presentation &quot;[Lightning Talk: Mind the Topology: Smarter Scheduling for AI Workloads on Kubernetes](https://youtu.be/o5i7pTWZjfo?si=su5iTOAS4r4O1TPa)&quot; to learn how KAI&#039;s Topology-Aware Scheduling (TAS) optimizes placement for modern disaggregated serving architectures.
- [2025/11] **Integration with [Grove](https://github.com/ai-dynamo/grove) &amp; Dynamo:** KAI&#039;s Topology-Aware and Hierarchical Gang Scheduling capabilities are integrated with Grove to orchestrate complex, multi-component workloads like disaggregated serving and agentic pipelines at scale. Read the [blog post](https://developer.nvidia.com/blog/streamline-complex-ai-inference-on-kubernetes-with-nvidia-grove/) for more details.
- [2025/10] [**v0.10.0 Release:**](https://github.com/NVIDIA/KAI-Scheduler/releases/tag/v0.10.0) Major features released, including [Topology-Aware Scheduling (TAS)](https://github.com/NVIDIA/KAI-Scheduler/tree/main/docs/topology), [Hierarchical PodGroups](https://github.com/NVIDIA/KAI-Scheduler/tree/main/docs/developer/designs/hierarchical-podgroup), and [Time-aware Fairness](https://github.com/NVIDIA/KAI-Scheduler/tree/main/docs/timeaware).
- [2025/10] **KubeRay Integration:** KAI Scheduler is now natively integrated for [Ray workloads on Kubernetes](https://docs.ray.io/en/master/cluster/kubernetes/k8s-ecosystem/kai-scheduler.html).
- [2025/08] **Time-Aware Fair-Sharing:** [Proposal for Time-aware fair-sharing](https://github.com/NVIDIA/KAI-Scheduler/blob/main/docs/developer/designs/time-aware-fairness/time-aware-fairness.md) is discussed at batch-wg. [Watch the recording.](https://zoom.us/rec/play/uW5ex5dmQP8_7UqOv5UjOGq8IqZeIa8AhKILqvDUQ6CnBAIdJjPY-BLfUWnoYblvDP-ZIvAp48p7XJNv.Cx5t7x1DwGqJgIYB?eagerLoadZvaPages=&amp;accessLevel=meeting&amp;canPlayFromShare=true&amp;from=share_recording_detail&amp;startTime=1755010542000&amp;componentName=rec-play&amp;originRequestUrl=https%3A%2F%2Fzoom.us%2Frec%2Fshare%2Frd_j_7ZDpC8lXxGNdQwguK2ZunoM3R93HR1Eo4A9rxD7b5lWSbmojDKc8OZ00ZMK.QxgEeMOxMcuiDkIY%3FstartTime%3D1755010542000)
- [2025/04] **Project Introduction:** Recording of the [KAI Scheduler introduction presented at the batch-wg meeting](https://zoom.us/rec/play/E1weaHroJpuTdXx6s9pjMu6oS78BiA53wsnvV9MWe_rIdwmDLFOG8J4XEPNW8-hIp4-HSFNdsbbP7mcv.YstbxFdS7z7tOfKw?eagerLoadZvaPages=&amp;accessLevel=meeting&amp;canPlayFromShare=true&amp;from=share_recording_detail&amp;startTime=1744124229000&amp;componentName=rec-play&amp;originRequestUrl=https%3A%2F%2Fzoom.us%2Frec%2Fshare%2FwP2WH6bqd7Dj8dupZD3YQTMWgG4AP5361_0h5vicI69LNb25JdQB8wn6fkvtLw2f.rLrRcQTSO1OCyRNu%3FstartTime%3D1744124229000).

## Key Features
* [Batch Scheduling](docs/batch/README.md): Ensure all pods in a group are scheduled simultaneously or not at all.
* Bin Packing &amp; Spread Scheduling: Optimize node usage either by minimizing fragmentation (bin-packing) or increasing resiliency and load balancing (spread scheduling).
* [Workload Priority](docs/priority/README.md): Prioritize workloads effectively within queues.
* [Hierarchical Queues](docs/queues/README.md): Manage workloads with two-level queue hierarchies for flexible organizational control.
* [Resource distribution](docs/fairness/README.md#resource-division-algorithm): Customize quotas, over-quota weights, limits, and priorities per queue.
* [Fairness Policies](docs/fairness/README.md#reclaim-strategies): Ensure equitable resource distribution using Dominant Resource Fairness (DRF) and resource reclamation across queues.
* Workload Consolidation: Reallocate running workloads intelligently to reduce fragmentation and increase cluster utilization.
* [Elastic Workloads](docs/elastic/README.md): Dynamically scale workloads within defined minimum and maximum pod counts.
* Dynamic Resource Allocation (DRA): Support vendor-specific hardware resources through Kubernetes ResourceClaims (e.g., GPUs from NVIDIA or AMD).
* [GPU Sharing](docs/gpu-sharing/README.md): Allow multiple workloads to efficiently share single or multiple GPUs, maximizing resource utilization.
* Cloud &amp; On-premise Support: Fully compatible with dynamic cloud infrastructures (including auto-scalers like Karpenter) as well as static on-premise deployments.

&gt; [!NOTE]
&gt; KAI Scheduler is built based on [kube-batch](https://github.com/kubernetes-sigs/kube-batch).

## Prerequisites
Before installing KAI Scheduler, ensure you have:

- A running Kubernetes cluster
- [Helm](https://helm.sh/docs/intro/install) CLI installed
- [NVIDIA GPU-Operator](https://github.com/NVIDIA/gpu-operator) installed in order to schedule workloads that request GPU resources

## Installation
KAI Scheduler will be installed in `kai-scheduler` namespace.
&gt; ⚠️ When submitting workloads, make sure to use a dedicated namespace. Do not use the `kai-scheduler` namespace for workload submission.

### Installation Methods
KAI Scheduler can be installed:

- **From Production (Recommended)**
- **From Source (Build it Yourself)**

#### Install from Production
Locate the latest release version in [releases](https://github.com/NVIDIA/KAI-Scheduler/releases) page.
Run the following command after replacing `&lt;VERSION&gt;` with the desired release version:
```sh
helm upgrade -i kai-scheduler oci://ghcr.io/nvidia/kai-scheduler/kai-scheduler -n kai-scheduler --create-namespace --version &lt;VERSION&gt;
```
#### Build from Source
Follow the instructions [here](docs/developer/building-from-source.md)

## Flavor Specific Instructions
### Openshift
When `gpu-operator` &lt;v25.10.0 is installed, the following flag should be added to the installation command:
```
--set admission.gpuPodRuntimeClassName=null
```

## Support &amp; Breaking changes
For details on our release lifecycle, LTS versions, and supported releases, see the [Support Policy](SUPPORT.md).

Refer to the [Breaking Changes](https://github.com/NVIDIA/KAI-Scheduler/blob/main/docs/migrationguides/README.md) doc for more info

## Quick Start
To start scheduling workloads with KAI Scheduler, please continue to [Quick Start example](docs/quickstart/README.md)

## Roadmap

### High-level overview of the main priorities for 2025
* Refactor the codebase to enhance vendor neutrality https://github.com/NVIDIA/KAI-Scheduler/issues/134
* Support Scheduling Gates https://github.com/NVIDIA/KAI-Scheduler/issues/63
* Research on possible integration with Kueue https://github.com/NVIDIA/KAI-Scheduler/issues/68
* Add Topology Aware Scheduling support of pod-group https://github.com/NVIDIA/KAI-Scheduler/issues/66
* Support Min Run Time per workloads https://github.com/NVIDIA/KAI-Scheduler/issues/136
* Support Max Run Time per workload (with delayed requeue)
* Add more PriorityClasses as part of the default KAI install
* Support JobSet
* Support LWS (LeaderWorkerSet) https://github.com/NVIDIA/KAI-Scheduler/issues/124
* Add metrics for pod and pod-group preemptions
* Decouple Priority and Preemption

### Long term goals
* Support per queue time decay
* Hyper scale improvements
* Support Consolidation of Inference workloads for cluster defragmentation
* Support n-levels of hierarchical queues
* Graceful rollout of Inference workloads (new revision update using queue temporary over-quota)

## Community, Discussion, and Support

We’d love to hear from you! Here are the best ways to connect:

### Contributing
Contributions are encouraged and appreciated! 
Please have a look at KAI-scheduler&#039;s [contribution guide](https://github.com/NVIDIA/KAI-Scheduler/blob/main/CONTRIBUTING.md) before submitting PRs.

### Slack
Join the [CNCF Slack](https://communityinviter.com/apps/cloud-native/cncf) first and visit the [#kai-scheduler](https://cloud-native.slack.com/archives/kai-scheduler) channel.

### Bi-weekly Community Call  
**When:** Every other Monday at 17:00 CEST  
[Convert to your time zone](https://dateful.com/time-zone-converter?t=17&amp;tz2=Germany) | [Add to your calendar](https://calendar.google.com/calendar/event?action=TEMPLATE&amp;tmeid=N2Q2bjhoNXAzMGc0cWpnZTQ4OGtpdXFhanFfMjAyNTA2MDlUMTUwMDAwWiAxZjQ2OTZiOWVlM2JiMWE1ZWIzMTAwODBkNDZiZmMwMDZjNTUxYWFiZmU1YTM3ZGM2YTc0NTFhYmNhMmE1ODk0QGc&amp;tmsrc=1f4696b9ee3bb1a5eb310080d46bfc006c551aabfe5a37dc6a7451abca2a5894%40group.calendar.google.com&amp;scp=ALL)  | [Meeting notes &amp; agenda](https://docs.google.com/document/d/13K7NGdPebOstlrsif1YLjGz1x-aJafMXeIgqbO7WghI/edit?usp=sharing)

### Mailing List  
Join the [kai-scheduler mailing list](https://groups.google.com/g/kai-scheduler) to receive updates on biweekly meetings.

### Technical Issues &amp; Feature Requests  
Please open a [GitHub issue](https://github.com/NVIDIA/KAI-Scheduler/issues/new/choose) for bugs, feature suggestions, or technical help. This helps us keep track of requests and respond effectively.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[AlexxIT/go2rtc]]></title>
            <link>https://github.com/AlexxIT/go2rtc</link>
            <guid>https://github.com/AlexxIT/go2rtc</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Ultimate camera streaming application with support RTSP, RTMP, HTTP-FLV, WebRTC, MSE, HLS, MP4, MJPEG, HomeKit, FFmpeg, etc.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AlexxIT/go2rtc">AlexxIT/go2rtc</a></h1>
            <p>Ultimate camera streaming application with support RTSP, RTMP, HTTP-FLV, WebRTC, MSE, HLS, MP4, MJPEG, HomeKit, FFmpeg, etc.</p>
            <p>Language: Go</p>
            <p>Stars: 10,846</p>
            <p>Forks: 824</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;

  ![go2rtc](assets/logo.gif)
  &lt;br&gt;
  [![stars](https://img.shields.io/github/stars/AlexxIT/go2rtc?style=flat-square&amp;logo=github)](https://github.com/AlexxIT/go2rtc/stargazers) 
  [![docker pulls](https://img.shields.io/docker/pulls/alexxit/go2rtc?style=flat-square&amp;logo=docker&amp;logoColor=white&amp;label=pulls)](https://hub.docker.com/r/alexxit/go2rtc) 
  [![releases](https://img.shields.io/github/downloads/AlexxIT/go2rtc/total?color=blue&amp;style=flat-square&amp;logo=github)](https://github.com/AlexxIT/go2rtc/releases)
  [![goreport](https://goreportcard.com/badge/github.com/AlexxIT/go2rtc)](https://goreportcard.com/report/github.com/AlexxIT/go2rtc)
&lt;/h1&gt;

Ultimate camera streaming application with support for RTSP, WebRTC, HomeKit, FFmpeg, RTMP, etc.

![](assets/go2rtc.png)

- zero-dependency and zero-config [small app](#go2rtc-binary) for all OS (Windows, macOS, Linux, ARM)
- zero-delay for many supported protocols (lowest possible streaming latency)
- streaming from [RTSP](#source-rtsp), [RTMP](#source-rtmp), [DVRIP](#source-dvrip), [HTTP](#source-http) (FLV/MJPEG/JPEG/TS), [USB Cameras](#source-ffmpeg-device) and [other sources](#module-streams)
- streaming from any sources, supported by [FFmpeg](#source-ffmpeg)
- streaming to [RTSP](#module-rtsp), [WebRTC](#module-webrtc), [MSE/MP4](#module-mp4), [HomeKit](#module-homekit) [HLS](#module-hls) or [MJPEG](#module-mjpeg)
- [publish](#publish-stream) any source to popular streaming services (YouTube, Telegram, etc.)
- first project in the World with support streaming from [HomeKit Cameras](#source-homekit)
- on-the-fly transcoding for unsupported codecs via [FFmpeg](#source-ffmpeg)
- play audio files and live streams on some cameras with [speaker](#stream-to-camera)
- multi-source two-way [codecs negotiation](#codecs-negotiation)
   - mixing tracks from different sources to single stream
   - auto-match client-supported codecs
   - [two-way audio](#two-way-audio) for some cameras
- can be [integrated to](#module-api) any smart home platform or be used as [standalone app](#go2rtc-binary)

**Inspired by:**

- series of streaming projects from [@deepch](https://github.com/deepch)
- [webrtc](https://github.com/pion/webrtc) go library and whole [@pion](https://github.com/pion) team
- [rtsp-simple-server](https://github.com/aler9/rtsp-simple-server) idea from [@aler9](https://github.com/aler9)
- [GStreamer](https://gstreamer.freedesktop.org/) framework pipeline idea
- [MediaSoup](https://mediasoup.org/) framework routing idea
- HomeKit Accessory Protocol from [@brutella](https://github.com/brutella/hap)
- creator of the project&#039;s logo [@v_novoseltsev](https://www.instagram.com/v_novoseltsev) 

&gt; [!CAUTION]
&gt; There is NO existing website for go2rtc project other than this GitHub repository. The website go2rtc[.]com is in no way associated with the authors of this project.

---

* [Fast start](#fast-start)
  * [go2rtc: Binary](#go2rtc-binary)
  * [go2rtc: Docker](#go2rtc-docker)
  * [go2rtc: Home Assistant Add-on](#go2rtc-home-assistant-add-on)
  * [go2rtc: Home Assistant Integration](#go2rtc-home-assistant-integration)
  * [go2rtc: Dev version](#go2rtc-dev-version)
* [Configuration](#configuration)
  * [Module: Streams](#module-streams)
    * [Two way audio](#two-way-audio)
    * [Source: RTSP](#source-rtsp)
    * [Source: RTMP](#source-rtmp)
    * [Source: HTTP](#source-http)
    * [Source: ONVIF](#source-onvif)
    * [Source: FFmpeg](#source-ffmpeg)
    * [Source: FFmpeg Device](#source-ffmpeg-device)
    * [Source: Exec](#source-exec)
    * [Source: Echo](#source-echo)
    * [Source: Expr](#source-expr)
    * [Source: HomeKit](#source-homekit)
    * [Source: Bubble](#source-bubble)
    * [Source: DVRIP](#source-dvrip)
    * [Source: Tapo](#source-tapo)
    * [Source: Kasa](#source-kasa)
    * [Source: Tuya](#source-tuya)
    * [Source: Xiaomi](#source-xiaomi)
    * [Source: GoPro](#source-gopro)
    * [Source: Ivideon](#source-ivideon)
    * [Source: Hass](#source-hass)
    * [Source: ISAPI](#source-isapi)
    * [Source: Nest](#source-nest)
    * [Source: Ring](#source-ring)
    * [Source: Roborock](#source-roborock)
    * [Source: Doorbird](#source-doorbird)
    * [Source: WebRTC](#source-webrtc)
    * [Source: WebTorrent](#source-webtorrent)
    * [Incoming sources](#incoming-sources)
    * [Stream to camera](#stream-to-camera)
    * [Publish stream](#publish-stream)
    * [Preload stream](#preload-stream)
  * [Module: API](#module-api)
  * [Module: RTSP](#module-rtsp)
  * [Module: RTMP](#module-rtmp)
  * [Module: WebRTC](#module-webrtc)
  * [Module: HomeKit](#module-homekit)
  * [Module: WebTorrent](#module-webtorrent)
  * [Module: ngrok](#module-ngrok)
  * [Module: Hass](#module-hass)
  * [Module: MP4](#module-mp4)
  * [Module: HLS](#module-hls)
  * [Module: MJPEG](#module-mjpeg)
  * [Module: Log](#module-log)
* [Security](#security)
* [Codecs filters](#codecs-filters)
* [Codecs madness](#codecs-madness)
* [Codecs negotiation](#codecs-negotiation)
* [Projects using go2rtc](#projects-using-go2rtc)
* [Camera experience](#cameras-experience)
* [TIPS](#tips)
* [FAQ](#faq)

## Fast start

1. Download [binary](#go2rtc-binary) or use [Docker](#go2rtc-docker) or Home Assistant [Add-on](#go2rtc-home-assistant-add-on) or [Integration](#go2rtc-home-assistant-integration)
2. Open web interface: `http://localhost:1984/`

**Optionally:**

- add your [streams](#module-streams) to [config](#configuration) file
- setup [external access](#module-webrtc) to webrtc

**Developers:**

- write your own [web interface](#module-api)
- integrate [web api](#module-api) into your smart home platform

### go2rtc: Binary

Download binary for your OS from [latest release](https://github.com/AlexxIT/go2rtc/releases/):

- `go2rtc_win64.zip` - Windows 10+ 64-bit
- `go2rtc_win32.zip` - Windows 10+ 32-bit
- `go2rtc_win_arm64.zip` - Windows ARM 64-bit
- `go2rtc_linux_amd64` - Linux 64-bit
- `go2rtc_linux_i386` - Linux 32-bit
- `go2rtc_linux_arm64` - Linux ARM 64-bit (ex. Raspberry 64-bit OS)
- `go2rtc_linux_arm` - Linux ARM 32-bit (ex. Raspberry 32-bit OS)
- `go2rtc_linux_armv6` - Linux ARMv6 (for old Raspberry 1 and Zero)
- `go2rtc_linux_mipsel` - Linux MIPS (ex. [Xiaomi Gateway 3](https://github.com/AlexxIT/XiaomiGateway3), [Wyze cameras](https://github.com/gtxaspec/wz_mini_hacks))
- `go2rtc_mac_amd64.zip` - macOS 11+ Intel 64-bit
- `go2rtc_mac_arm64.zip` - macOS ARM 64-bit
- `go2rtc_freebsd_amd64.zip` - FreeBSD 64-bit
- `go2rtc_freebsd_arm64.zip` - FreeBSD ARM 64-bit

Don&#039;t forget to fix the rights `chmod +x go2rtc_xxx_xxx` on Linux and Mac.

### go2rtc: Docker

The Docker container [`alexxit/go2rtc`](https://hub.docker.com/r/alexxit/go2rtc) supports multiple architectures including `amd64`, `386`, `arm64`, and `arm`. This container offers the same functionality as the [Home Assistant Add-on](#go2rtc-home-assistant-add-on) but is designed to operate independently of Home Assistant. It comes preinstalled with [FFmpeg](#source-ffmpeg) and [Python](#source-echo).

### go2rtc: Home Assistant Add-on

[![](https://my.home-assistant.io/badges/supervisor_addon.svg)](https://my.home-assistant.io/redirect/supervisor_addon/?addon=a889bffc_go2rtc&amp;repository_url=https%3A%2F%2Fgithub.com%2FAlexxIT%2Fhassio-addons)

1. Install Add-On:
    - Settings &gt; Add-ons &gt; Plus &gt; Repositories &gt; Add `https://github.com/AlexxIT/hassio-addons`
    - go2rtc &gt; Install &gt; Start
2. Setup [Integration](#module-hass)

### go2rtc: Home Assistant Integration

[WebRTC Camera](https://github.com/AlexxIT/WebRTC) custom component can be used on any [Home Assistant installation](https://www.home-assistant.io/installation/), including [HassWP](https://github.com/AlexxIT/HassWP) on Windows. It can automatically download and use the latest version of go2rtc. Or it can connect to an existing version of go2rtc. Addon installation in this case is optional.

### go2rtc: Dev version

Latest, but maybe unstable version:

- Binary: [latest nightly release](https://nightly.link/AlexxIT/go2rtc/workflows/build/master)
- Docker: `alexxit/go2rtc:master` or `alexxit/go2rtc:master-hardware` versions
- Hass Add-on: `go2rtc master` or `go2rtc master hardware` versions

## Configuration

- by default go2rtc will search `go2rtc.yaml` in the current work directory
- `api` server will start on default **1984 port** (TCP)
- `rtsp` server will start on default **8554 port** (TCP)
- `webrtc` will use port **8555** (TCP/UDP) for connections
- `ffmpeg` will use default transcoding options

Configuration options and a complete list of settings can be found in [the wiki](https://github.com/AlexxIT/go2rtc/wiki/Configuration).

Available modules:

- [streams](#module-streams)
- [api](#module-api) - HTTP API (important for WebRTC support)
- [rtsp](#module-rtsp) - RTSP Server (important for FFmpeg support)
- [webrtc](#module-webrtc) - WebRTC Server
- [mp4](#module-mp4) - MSE, MP4 stream and MP4 snapshot Server
- [hls](#module-hls) - HLS TS or fMP4 stream Server
- [mjpeg](#module-mjpeg) - MJPEG Server
- [ffmpeg](#source-ffmpeg) - FFmpeg integration
- [ngrok](#module-ngrok) - ngrok integration (external access for private network)
- [hass](#module-hass) - Home Assistant integration
- [log](#module-log) - logs config

### Module: Streams

**go2rtc** supports different stream source types. You can config one or multiple links of any type as a stream source.

Available source types:

- [rtsp](#source-rtsp) - `RTSP` and `RTSPS` cameras with [two-way audio](#two-way-audio) support
- [rtmp](#source-rtmp) - `RTMP` streams
- [http](#source-http) - `HTTP-FLV`, `MPEG-TS`, `JPEG` (snapshots), `MJPEG` streams
- [onvif](#source-onvif) - get camera `RTSP` link and snapshot link using `ONVIF` protocol
- [ffmpeg](#source-ffmpeg) - FFmpeg integration (`HLS`, `files` and many others)
- [ffmpeg:device](#source-ffmpeg-device) - local USB Camera or Webcam
- [exec](#source-exec) - get media from external app output
- [echo](#source-echo) - get stream link from bash or python
- [expr](#source-expr) - get stream link via built-in expression language
- [homekit](#source-homekit) - streaming from HomeKit Camera
- [bubble](#source-bubble) - streaming from ESeeCloud/dvr163 NVR
- [dvrip](#source-dvrip) - streaming from DVR-IP NVR
- [eseecloud](#source-eseecloud) - streaming from ESeeCloud/dvr163 NVR
- [tapo](#source-tapo) - TP-Link Tapo cameras with [two way audio](#two-way-audio) support
- [ring](#source-ring) - Ring cameras with [two way audio](#two-way-audio) support
- [tuya](#source-tuya) - Tuya cameras with [two way audio](#two-way-audio) support
- [xiaomi](#source-xiaomi) - Xiaomi cameras with [two way audio](#two-way-audio) support
- [kasa](#source-tapo) - TP-Link Kasa cameras
- [gopro](#source-gopro) - GoPro cameras
- [ivideon](#source-ivideon) - public cameras from [Ivideon](https://tv.ivideon.com/) service
- [hass](#source-hass) - Home Assistant integration
- [isapi](#source-isapi) - two-way audio for Hikvision (ISAPI) cameras
- [roborock](#source-roborock) - Roborock vacuums with cameras
- [doorbird](#source-doorbird) - Doorbird cameras with [two way audio](#two-way-audio) support
- [webrtc](#source-webrtc) - WebRTC/WHEP sources
- [webtorrent](#source-webtorrent) - WebTorrent source from another go2rtc

Read more about [incoming sources](#incoming-sources)

#### Two-way audio

Supported sources:

- [RTSP cameras](#source-rtsp) with [ONVIF Profile T](https://www.onvif.org/specs/stream/ONVIF-Streaming-Spec.pdf) (back channel connection)
- [DVRIP](#source-dvrip) cameras
- [TP-Link Tapo](#source-tapo) cameras
- [Hikvision ISAPI](#source-isapi) cameras
- [Roborock vacuums](#source-roborock) models with cameras
- [Doorbird](#source-doorbird) cameras
- [Exec](#source-exec) audio on server
- [Ring](#source-ring) cameras
- [Tuya](#source-tuya) cameras
- [Xiaomi](#source-xiaomi) cameras
- [Any Browser](#incoming-browser) as IP-camera

Two-way audio can be used in browser with [WebRTC](#module-webrtc) technology. The browser will give access to the microphone only for HTTPS sites ([read more](https://stackoverflow.com/questions/52759992/how-to-access-camera-and-microphone-in-chrome-without-https)).

go2rtc also supports [play audio](#stream-to-camera) files and live streams on this cameras.

#### Source: RTSP

```yaml
streams:
  sonoff_camera: rtsp://rtsp:12345678@192.168.1.123/av_stream/ch0
  dahua_camera:
    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=0&amp;unicast=true&amp;proto=Onvif
    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=1#backchannel=0
  amcrest_doorbell:
    - rtsp://username:password@192.168.1.123:554/cam/realmonitor?channel=1&amp;subtype=0#backchannel=0
  unifi_camera: rtspx://192.168.1.123:7441/fD6ouM72bWoFijxK
  glichy_camera: ffmpeg:rtsp://username:password@192.168.1.123/live/ch00_1 
```

**Recommendations**

- **Amcrest Doorbell** users may want to disable two-way audio, because with an active stream, you won&#039;t have a working call button. You need to add `#backchannel=0` to the end of your RTSP link in YAML config file
- **Dahua Doorbell** users may want to change [audio codec](https://github.com/AlexxIT/go2rtc/issues/49#issuecomment-2127107379) for proper 2-way audio. Make sure not to request backchannel multiple times by adding `#backchannel=0` to other stream sources of the same doorbell. The `unicast=true&amp;proto=Onvif` is preferred for 2-way audio as this makes the doorbell accept multiple codecs for the incoming audio
- **Reolink** users may want NOT to use RTSP protocol at all, some camera models have a very awful, unusable stream implementation
- **Ubiquiti UniFi** users may want to disable HTTPS verification. Use `rtspx://` prefix instead of `rtsps://`. And don&#039;t use `?enableSrtp` [suffix](https://github.com/AlexxIT/go2rtc/issues/81)
- **TP-Link Tapo** users may skip login and password, because go2rtc support login [without them](https://drmnsamoliu.github.io/video.html)
- If your camera has two RTSP links, you can add both as sources. This is useful when streams have different codecs, for example AAC audio with main stream and PCMU/PCMA audio with second stream
- If the stream from your camera is glitchy, try using [ffmpeg source](#source-ffmpeg). It will not add CPU load if you don&#039;t use transcoding
- If the stream from your camera is very glitchy, try to use transcoding with [ffmpeg source](#source-ffmpeg)

**Other options**

Format: `rtsp...#{param1}#{param2}#{param3}`

- Add custom timeout `#timeout=30` (in seconds)
- Ignore audio - `#media=video` or ignore video - `#media=audio` 
- Ignore two-way audio API `#backchannel=0` - important for some glitchy cameras
- Use WebSocket transport `#transport=ws...`

**RTSP over WebSocket**

```yaml
streams:
  # WebSocket with authorization, RTSP - without
  axis-rtsp-ws:  rtsp://192.168.1.123:4567/axis-media/media.amp?overview=0&amp;camera=1&amp;resolution=1280x720&amp;videoframeskipmode=empty&amp;Axis-Orig-Sw=true#transport=ws://user:pass@192.168.1.123:4567/rtsp-over-websocket
  # WebSocket without authorization, RTSP - with
  dahua-rtsp-ws: rtsp://user:pass@192.168.1.123/cam/realmonitor?channel=1&amp;subtype=1&amp;proto=Private3#transport=ws://192.168.1.123/rtspoverwebsocket
```

#### Source: RTMP

You can get a stream from an RTMP server, for example [Nginx with nginx-rtmp-module](https://github.com/arut/nginx-rtmp-module).

```yaml
streams:
  rtmp_stream: rtmp://192.168.1.123/live/camera1
```

#### Source: HTTP

Support Content-Type:

- **HTTP-FLV** (`video/x-flv`) - same as RTMP, but over HTTP
- **HTTP-JPEG** (`image/jpeg`) - camera snapshot link, can be converted by go2rtc to MJPEG stream
- **HTTP-MJPEG** (`multipart/x`) - simple MJPEG stream over HTTP
- **MPEG-TS** (`video/mpeg`) - legacy [streaming format](https://en.wikipedia.org/wiki/MPEG_transport_stream)

Source also supports HTTP and TCP streams with autodetection for different formats: **MJPEG**, **H.264/H.265 bitstream**, **MPEG-TS**.

```yaml
streams:
  # [HTTP-FLV] stream in video/x-flv format
  http_flv: http://192.168.1.123:20880/api/camera/stream/780900131155/657617
  
  # [JPEG] snapshots from Dahua camera, will be converted to MJPEG stream
  dahua_snap: http://admin:password@192.168.1.123/cgi-bin/snapshot.cgi?channel=1

  # [MJPEG] stream will be proxied without modification
  http_mjpeg: https://mjpeg.sanford.io/count.mjpeg

  # [MJPEG or H.264/H.265 bitstream or MPEG-TS]
  tcp_magic: tcp://192.168.1.123:12345

  # Add custom header
  custom_header: &quot;https://mjpeg.sanford.io/count.mjpeg#header=Authorization: Bearer XXX&quot;
```

**PS.** Dahua camera has a bug: if you select MJPEG codec for RTSP second stream, snapshot won&#039;t work.

#### Source: ONVIF

*[New in v1.5.0](https://github.com/AlexxIT/go2rtc/releases/tag/v1.5.0)*

The source is not very useful if you already know RTSP and snapshot links for your camera. But it can be useful if you don&#039;t.

**WebUI &gt; Add** webpage support ONVIF autodiscovery. Your server must be on the same subnet as the camera. If you use Docker, you must use &quot;network host&quot;.

```yaml
streams:
  dahua1: onvif://admin:password@192.168.1.123
  reolink1: onvif://admin:password@192.168.1.123:8000
  tapo1: onvif://admin:password@192.168.1.123:2020
```

#### Source: FFmpeg

You can get any stream, file or device via FFmpeg and push it to go2rtc. The app will automatically start FFmpeg with the proper arguments when someone starts watching the stream.

- FFmpeg preistalled for **Docker** and **Hass Add-on** users
- **Hass Add-on** users can target files from [/media](https://www.home-assistant.io/more-info/local-media/setup-media/) folder

Format: `ffmpeg:{input}#{param1}#{param2}#{param3}`. Examples:

```yaml
streams:
  # [FILE] all tracks will be copied without transcoding codecs
  file1: ffmpeg:/media/BigBuckBunny.mp4

  # [FILE] video will be transcoded to H264, audio will be skipped
  file2: ffmpeg:/media/BigBuckBunny.mp4#video=h264

  # [FILE] video will be copied, audio will be transcoded to PCMU
  file3: ffmpeg:/media/BigBuckBunny.mp4#video=copy#audio=pcmu

  # [HLS] video will be copied, audio will be skipped
  hls: ffmpeg:https://devstreaming-cdn.apple.com/videos/streaming/examples/bipbop_16x9/gear5/prog_index.m3u8#video=copy

  # [MJPEG] video will be transcoded to H264
  mjpeg: ffmpeg:http://185.97.122.128/cgi-bin/faststream.jpg#video=h264

  # [RTSP] video with rotation, should be transcoded, so select H264
  rotate: ffmpeg:rtsp://12345678@192.168.1.123/av_stream/ch0#video=h264#rotate=90
```

All transcoding formats have [built-in templates](https://github.com/AlexxIT/go2rtc/blob/master/internal/ffmpeg/ffmpeg.go): `h264`, `h265`, `opus`, `pcmu`, `pcmu/16000`, `pcmu/48000`, `pcma`, `pcma/16000`, `pcma/48000`, `aac`, `aac/16000`.

But you can override them via YAML config. You can also add your own formats to the config and use them with source params.

```yaml
ffmpeg:
  bin: ffmpeg  # path to ffmpeg binary
  h264: &quot;-codec:v libx264 -g:v 30 -preset:v superfast -tune:v zerolatency -profile:v main -level:v 4.1&quot;
  mycodec: &quot;-any args that supported by ffmpeg...&quot;
  myinput: &quot;-fflags nobuffer -flags low_delay -timeout 5000000 -i {input}&quot;
  myraw: &quot;-ss 00:00:20&quot;
```

- You can use go2rtc stream name as ffmpeg input (ex. `ffmpeg:camera1#video=h264`)
- You can use `video` and `audio` params multiple times (ex. `#video=copy#audio=copy#audio=pcmu`)
- You can use `rotate` param with `90`, `180`, `270` or `-90` values, important with transcoding (ex. `#video=h264#rotate=90`)
- You can use `width` and/or `height` params, important with transcoding (ex. `#video=h264#width=1280`)
- You can use `drawtext` to add a timestamp (ex. `drawtext=x=2:y=2:fontsize=12:fontcolor=white:box=1:boxcolor=black`)
  - This will greatly increase the CPU of the server, even with hardware acceleration
- You can use `raw` param for any additional FFmpeg arguments (ex. `#raw=-vf transpose=1`)
- You can use `input` param to override default input template (ex. `#input=rtsp/udp` will change RTSP transport from TCP to UDP+TCP)
  - You can use raw

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[argoproj/argo-workflows]]></title>
            <link>https://github.com/argoproj/argo-workflows</link>
            <guid>https://github.com/argoproj/argo-workflows</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[Workflow Engine for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/argoproj/argo-workflows">argoproj/argo-workflows</a></h1>
            <p>Workflow Engine for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 16,285</p>
            <p>Forks: 3,431</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable-next-line MD041 --&gt;
[![Security Status](https://github.com/argoproj/argo-workflows/actions/workflows/snyk.yml/badge.svg?branch=main)](https://github.com/argoproj/argo-workflows/actions/workflows/snyk.yml?query=branch%3Amain)
[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/3830/badge)](https://bestpractices.coreinfrastructure.org/projects/3830)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-workflows/badge)](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-workflows)
[![FOSSA License Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fargoproj%2Fargo-workflows.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fargoproj%2Fargo-workflows?ref=badge_shield)
[![Slack](https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack)](https://argoproj.github.io/community/join-slack)
[![X Follow](https://img.shields.io/twitter/follow/argoproj?style=social)](https://x.com/argoproj)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-argoproj-blue.svg?logo=linkedin)](https://www.linkedin.com/company/argoproj/)
[![Release Version](https://img.shields.io/github/v/release/argoproj/argo-workflows?label=argo-workflows)](https://github.com/argoproj/argo-workflows/releases/latest)
[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-workflows)](https://artifacthub.io/packages/helm/argo/argo-workflows)

## What is Argo Workflows?

Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes.
Argo Workflows is implemented as a Kubernetes CRD (Custom Resource Definition).

* Define workflows where each step is a container.
* Model multi-step workflows as a sequence of tasks or capture the dependencies between tasks using a directed acyclic graph (DAG).
* Easily run compute intensive jobs for machine learning or data processing in a fraction of the time using Argo Workflows on Kubernetes.

Argo is a [Cloud Native Computing Foundation (CNCF)](https://cncf.io/) graduated project.

## Use Cases

* [Machine Learning pipelines](https://argo-workflows.readthedocs.io/en/latest/use-cases/machine-learning/)
* [Data and batch processing](https://argo-workflows.readthedocs.io/en/latest/use-cases/data-processing/)
* [Infrastructure automation](https://argo-workflows.readthedocs.io/en/latest/use-cases/infrastructure-automation/)
* [CI/CD](https://argo-workflows.readthedocs.io/en/latest/use-cases/ci-cd/)
* [Other use cases](https://argo-workflows.readthedocs.io/en/latest/use-cases/other/)

## Why Argo Workflows?

* Argo Workflows is the most popular workflow execution engine for Kubernetes.
* Light-weight, scalable, and easier to use.
    * Including for Python users through [the Hera Python SDK for Argo Workflows](https://hera.readthedocs.io/en/stable/).
* Designed from the ground up for containers without the overhead and limitations of legacy VM and server-based environments.
* Cloud agnostic and can run on any Kubernetes cluster.

[Read what people said in our latest survey](https://blog.argoproj.io/argo-workflows-events-2023-user-survey-results-82c53bc30543)

## Try Argo Workflows

You can try Argo Workflows via one of the following:

1. [Interactive Training Material](https://killercoda.com/argoproj/course/argo-workflows/)
1. [Access the demo environment](https://workflows.apps.argoproj.io/workflows/argo)

![Screenshot](docs/assets/screenshot.png)

## Who uses Argo Workflows?

[About 200+ organizations are officially using Argo Workflows](USERS.md)

## Ecosystem

Just some of the projects that use or rely on Argo Workflows (complete list [here](https://github.com/akuity/awesome-argo#ecosystem-projects)):

* [Argo Events](https://github.com/argoproj/argo-events)
* [Couler](https://github.com/couler-proj/couler)
* [Hera](https://github.com/argoproj-labs/hera-workflows)
* [Katib](https://github.com/kubeflow/katib)
* [Kedro](https://kedro.readthedocs.io/en/stable/)
* [Kubeflow Pipelines](https://github.com/kubeflow/pipelines)
* [Netflix Metaflow](https://metaflow.org)
* [Onepanel](https://github.com/onepanelio/onepanel)
* [Orchest](https://github.com/orchest/orchest/)
* [Piper](https://github.com/quickube/piper)
* [Ploomber](https://github.com/ploomber/ploomber)
* [Seldon](https://github.com/SeldonIO/seldon-core)
* [SQLFlow](https://github.com/sql-machine-learning/sqlflow)

## Client Libraries

Check out our [Java, Golang, and Python (Hera) clients](docs/client-libraries.md).

## Quickstart

* [Get started here](https://argo-workflows.readthedocs.io/en/latest/quick-start/)
* [Walk-through examples](https://argo-workflows.readthedocs.io/en/latest/walk-through/)

## Documentation

[View the docs](https://argo-workflows.readthedocs.io/en/latest/)

## Features

An incomplete list of features Argo Workflows provides:

* UI to visualize and manage Workflows
* Artifact support (S3, Artifactory, Alibaba Cloud OSS, Azure Blob Storage, HTTP, Git, GCS, raw, plugins)
* Workflow templating to store commonly used Workflows in the cluster
* Archiving Workflows after executing for later access
* Scheduled workflows using cron
* Server interface with REST API (HTTP and GRPC)
* DAG or Steps based declaration of workflows
* Step level input &amp; outputs (artifacts/parameters)
* Loops
* Parameterization
* Conditionals
* Timeouts (step &amp; workflow level)
* Retry (step &amp; workflow level)
* Resubmit (memoized)
* Suspend &amp; Resume
* Cancellation
* K8s resource orchestration
* Exit Hooks (notifications, cleanup)
* Garbage collection of completed workflow
* Scheduling (affinity/tolerations/node selectors)
* Volumes (ephemeral/existing)
* Parallelism limits
* Daemoned steps
* DinD (docker-in-docker)
* Script steps
* Event emission
* Prometheus metrics
* Multiple executors
* Multiple pod and workflow garbage collection strategies
* Automatically calculated resource usage per step
* Java, Golang, and Python (Hera) SDKs
* Pod Disruption Budget support
* Single-sign on (OAuth2/OIDC)
* Webhook triggering
* CLI
* Out-of-the box and custom Prometheus metrics
* Windows container support
* Embedded widgets
* Multiplex log viewer

## Community Meetings

We host monthly community meetings where we and the community showcase demos and discuss the current and future state of the project. Feel free to join us!
For Community Meeting information, minutes and recordings, please [see here](https://bit.ly/argo-wf-cmty-mtng).

Participation in Argo Workflows is governed by the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/master/code-of-conduct.md)

## Community Blogs and Presentations

* [Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo](https://github.com/terrytangyuan/awesome-argo)
* [Automation of Everything - How To Combine Argo Events, Workflows &amp; Pipelines, CD, and Rollouts](https://youtu.be/XNXJtxkUKeY)
* [Argo Workflows and Pipelines - CI/CD, Machine Learning, and Other Kubernetes Workflows](https://youtu.be/UMaivwrAyTA)
* [Argo Ansible role: Provisioning Argo Workflows on OpenShift](https://medium.com/@marekermk/provisioning-argo-on-openshift-with-ansible-and-kustomize-340a1fda8b50)
* [Argo Workflows vs Apache Airflow](http://bit.ly/30YNIvT)
* [Beyond Prototypes: Production-Ready ML Systems with Metaflow and Argo](https://github.com/terrytangyuan/public-talks/tree/main/talks/kubecon-na-2023-metaflow-argo)
* [CI/CD with Argo on Kubernetes](https://medium.com/@bouwe.ceunen/ci-cd-with-argo-on-kubernetes-28c1a99616a9)
* [Define Your CI/CD Pipeline with Argo Workflows](https://haque-zubair.medium.com/define-your-ci-cd-pipeline-with-argo-workflows-25aefb02fa63)
* [Distributed Machine Learning Patterns from Manning Publication](https://github.com/terrytangyuan/distributed-ml-patterns)
* [Engineering Cloud Native AI Platform](https://github.com/terrytangyuan/public-talks/tree/main/talks/platform-con-2024-engineering-cloud-native-ai-platform)
* [Managing Thousands of Automatic Machine Learning Experiments with Argo and Katib](https://github.com/terrytangyuan/public-talks/blob/main/talks/argocon-automl-experiments-2022)
* [Autonomous Driving Data Pipelines Reconstruction With Argo Workflows](https://www.youtube.com/watch?v=oTgIQxbsLhU)
* [Revolutionizing Scientific Simulations with Argo Workflows](https://www.youtube.com/watch?v=BYVf7GhfiRg)
* [Running Argo Workflows Across Multiple Kubernetes Clusters](https://admiralty.io/blog/running-argo-workflows-across-multiple-kubernetes-clusters/)
* [Scaling Kubernetes: Best Practices for Managing Large-Scale Batch Jobs with Spark and Argo Workflow](https://www.youtube.com/watch?v=KqEKRPjy4aE)
* [Open Source Model Management Roundup: Polyaxon, Argo, and Seldon](https://www.anaconda.com/blog/developer-blog/open-source-model-management-roundup-polyaxon-argo-and-seldon/)
* [Producing 200 OpenStreetMap extracts in 35 minutes using a scalable data workflow](https://www.interline.io/blog/scaling-openstreetmap-data-workflows/)
* [Production-Ready AI Platform on Kubernetes](https://github.com/terrytangyuan/public-talks/tree/main/talks/kubecon-europe-2024-production-ai-platform-on-k8s)
* [Argo integration review](http://dev.matt.hillsdon.net/2018/03/24/argo-integration-review.html)
* TGI Kubernetes with Joe Beda: [Argo workflow system](https://www.youtube.com/watch?v=M_rxPPLG8pU&amp;start=859)

## Project Resources

* [Argo Project GitHub organization](https://github.com/argoproj)
* [Argo Website](https://argoproj.github.io/)
* [Argo Slack](https://argoproj.github.io/community/join-slack)

## Security

See [SECURITY.md](SECURITY.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Tencent/WeKnora]]></title>
            <link>https://github.com/Tencent/WeKnora</link>
            <guid>https://github.com/Tencent/WeKnora</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Tencent/WeKnora">Tencent/WeKnora</a></h1>
            <p>LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.</p>
            <p>Language: Go</p>
            <p>Stars: 9,104</p>
            <p>Forks: 978</p>
            <p>Stars today: 121 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;img src=&quot;./docs/images/logo.png&quot; alt=&quot;WeKnora Logo&quot; height=&quot;120&quot;/&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/15289&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://trendshift.io/api/badge/repositories/15289&quot; alt=&quot;Tencent%2FWeKnora | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
    &lt;/a&gt;
  &lt;/picture&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://weknora.weixin.qq.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;官方网站&quot; src=&quot;https://img.shields.io/badge/官方网站-WeKnora-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://chatbot.weixin.qq.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;微信对话开放平台&quot; src=&quot;https://img.shields.io/badge/微信对话开放平台-5ac725&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/Tencent/WeKnora/blob/main/LICENSE&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;License&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;./CHANGELOG.md&quot;&gt;
        &lt;img alt=&quot;Version&quot; src=&quot;https://img.shields.io/badge/version-0.2.0-2e6cc4?labelColor=d4eaf7&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
| &lt;b&gt;English&lt;/b&gt; | &lt;a href=&quot;./README_CN.md&quot;&gt;&lt;b&gt;简体中文&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;./README_JA.md&quot;&gt;&lt;b&gt;日本語&lt;/b&gt;&lt;/a&gt; |
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;h4 align=&quot;center&quot;&gt;

  [Overview](#-overview) • [Architecture](#-architecture) • [Key Features](#-key-features) • [Getting Started](#-getting-started) • [API Reference](#-api-reference) • [Developer Guide](#-developer-guide)
  
  &lt;/h4&gt;
&lt;/p&gt;

# 💡 WeKnora - LLM-Powered Document Understanding &amp; Retrieval Framework

## 📌 Overview

[**WeKnora**](https://weknora.weixin.qq.com) is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents. 

It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the **RAG (Retrieval-Augmented Generation)** paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.

**Website:** https://weknora.weixin.qq.com

## ✨ Latest Updates

**v0.2.0 Highlights:**

- 🤖 **Agent Mode**: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection
- 📚 **Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry
- ⚙️ **Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior
- 🌐 **Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine
- 🔌 **MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods
- 🎨 **New UI**: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade
- ⚡ **Infrastructure Upgrade**: Introduced MQ async task management, support for automatic database migration, and fast development mode

## 🔒 Security Notice

**Important:** Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:

- Deploy WeKnora services in internal/private network environments rather than public internet
- Avoid exposing the service directly to public networks to prevent potential information leakage
- Configure proper firewall rules and access controls for your deployment environment
- Regularly update to the latest version for security patches and improvements

## 🏗️ Architecture

![weknora-architecture.png](./docs/images/architecture.png)

WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.

## 🎯 Key Features

- **🤖 Agent Mode**: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection
- **🔍 Precise Understanding**: Structured content extraction from PDFs, Word documents, images and more into unified semantic views
- **🧠 Intelligent Reasoning**: Leverages LLMs to understand document context and user intent for accurate Q&amp;A and multi-turn conversations
- **📚 Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities
- **🔧 Flexible Extension**: All components from parsing and embedding to retrieval and generation are decoupled for easy customization
- **⚡ Efficient Retrieval**: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support
- **🌐 Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine
- **🔌 MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods
- **⚙️ Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior
- **🎯 User-Friendly**: Intuitive web interface and standardized APIs for zero technical barriers
- **🔒 Secure &amp; Controlled**: Support for local deployment and private cloud, ensuring complete data sovereignty

## 📊 Application Scenarios

| Scenario | Applications | Core Value |
|---------|----------|----------|
| **Enterprise Knowledge Management** | Internal document retrieval, policy Q&amp;A, operation manual search | Improve knowledge discovery efficiency, reduce training costs |
| **Academic Research Analysis** | Paper retrieval, research report analysis, scholarly material organization | Accelerate literature review, assist research decisions |
| **Product Technical Support** | Product manual Q&amp;A, technical documentation search, troubleshooting | Enhance customer service quality, reduce support burden |
| **Legal &amp; Compliance Review** | Contract clause retrieval, regulatory policy search, case analysis | Improve compliance efficiency, reduce legal risks |
| **Medical Knowledge Assistance** | Medical literature retrieval, treatment guideline search, case analysis | Support clinical decisions, improve diagnosis quality |

## 🧩 Feature Matrix

| Module | Support | Description |
|---------|---------|------|
| Agent Mode | ✅ ReACT Agent Mode | Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations |
| Knowledge Base Types | ✅ FAQ / Document | Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry |
| Document Formats | ✅ PDF / Word / Txt / Markdown / Images (with OCR / Caption) | Support for structured and unstructured documents with text extraction from images |
| Model Management | ✅ Centralized configuration, built-in model sharing | Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models |
| Embedding Models | ✅ Local models, BGE / GTE APIs, etc. | Customizable embedding models, compatible with local deployment and cloud vector generation APIs |
| Vector DB Integration | ✅ PostgreSQL (pgvector), Elasticsearch | Support for mainstream vector index backends, flexible switching for different retrieval scenarios |
| Retrieval Strategies | ✅ BM25 / Dense Retrieval / GraphRAG | Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines |
| LLM Integration | ✅ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching | Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration |
| Conversation Strategy | ✅ Agent models, normal mode models, retrieval thresholds, Prompt configuration | Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior |
| Web Search | ✅ Extensible search engines, DuckDuckGo | Support for extensible web search engines with built-in DuckDuckGo search engine |
| MCP Tools | ✅ uvx, npx launchers, Stdio/HTTP Streamable/SSE | Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods |
| QA Capabilities | ✅ Context-aware, multi-turn dialogue, prompt templates | Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;A with configurable prompts and context windows |
| E2E Testing | ✅ Retrieval+generation process visualization and metric evaluation | End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics |
| Deployment Modes | ✅ Support for local deployment / Docker images | Meets private, offline deployment and flexible operation requirements, with fast development mode support |
| User Interfaces | ✅ Web UI + RESTful API | Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display |
| Task Management | ✅ MQ async tasks, automatic database migration | MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades |

## 🚀 Getting Started

### 🛠 Prerequisites

Make sure the following tools are installed on your system:

* [Docker](https://www.docker.com/)
* [Docker Compose](https://docs.docker.com/compose/)
* [Git](https://git-scm.com/)

### 📦 Installation

#### ① Clone the repository

```bash
# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
```

#### ② Configure environment variables

```bash
# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
```

#### ③ Start the services (include Ollama)

Check the images that need to be started in the .env file.

```bash
./scripts/start_all.sh
```

or

```bash
make start-all
```

#### ③.0 Start ollama services (Optional)

```bash
ollama serve &gt; /dev/null 2&gt;&amp;1 &amp;
```

#### ③.1 Activate different combinations of features

- Minimum core services
```bash
docker compose up -d
```

- All features enabled
```bash
docker-compose --profile full up -d
```

- Tracing logs required
```bash
docker-compose --profile jaeger up -d
```

- Neo4j knowledge graph required
```bash
docker-compose --profile neo4j up -d
```

- Minio file storage service required
```bash
docker-compose --profile minio up -d
```

- Multiple options combination
```bash
docker-compose --profile neo4j --profile minio up -d
```

#### ④ Stop the services

```bash
./scripts/start_all.sh --stop
# Or
make stop-all
```

### 🌐 Access Services

Once started, services will be available at:

* Web UI: `http://localhost`
* Backend API: `http://localhost:8080`
* Jaeger Tracing: `http://localhost:16686`

### 🔌 Using WeChat Dialog Open Platform

WeKnora serves as the core technology framework for the [WeChat Dialog Open Platform](https://chatbot.weixin.qq.com), providing a more convenient usage approach:

- **Zero-code Deployment**: Simply upload knowledge to quickly deploy intelligent Q&amp;A services within the WeChat ecosystem, achieving an &quot;ask and answer&quot; experience
- **Efficient Question Management**: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers
- **WeChat Ecosystem Integration**: Through the WeChat Dialog Open Platform, WeKnora&#039;s intelligent Q&amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences

### 🔗 Access WeKnora via MCP Server

#### 1️⃣ Clone the repository
```
git clone https://github.com/Tencent/WeKnora
```

#### 2️⃣ Configure MCP Server
&gt; It is recommended to directly refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for configuration.

Configure the MCP client to connect to the server:
```json
{
  &quot;mcpServers&quot;: {
    &quot;weknora&quot;: {
      &quot;args&quot;: [
        &quot;path/to/WeKnora/mcp-server/run_server.py&quot;
      ],
      &quot;command&quot;: &quot;python&quot;,
      &quot;env&quot;:{
        &quot;WEKNORA_API_KEY&quot;:&quot;Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk&quot;,
        &quot;WEKNORA_BASE_URL&quot;:&quot;http(s)://your-weknora-address/api/v1&quot;
      }
    }
  }
}
```

Run directly using stdio command:
```
pip install weknora-mcp-server
python -m weknora-mcp-server
```

## 🔧 Initialization Configuration Guide

To help users quickly configure various models and reduce trial-and-error costs, we&#039;ve improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows:
If this is your first time using this project, you can skip steps ①② and go directly to steps ③④.

### ① Stop the services

```bash
./scripts/start_all.sh --stop
```

### ② Clear existing data tables (recommended when no important data exists)

```bash
make clean-db
```

### ③ Compile and start services

```bash
./scripts/start_all.sh
```

### ④ Access Web UI

http://localhost

On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.

## 📱 Interface Showcase

### Web UI Interface

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/knowledgebases.png&quot; alt=&quot;Knowledge Base Management&quot;&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/settings.png&quot; alt=&quot;Conversation Settings&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td colspan=&quot;2&quot;&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/agent-qa.png&quot; alt=&quot;Agent Mode Tool Call Process&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

**Knowledge Base Management:** Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.

**Agent Mode:** Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.

**Conversation Strategy:** Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.

### Document Knowledge Graph

WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.

For detailed configuration, please refer to the [Knowledge Graph Configuration Guide](./docs/KnowledgeGraph.md).

### MCP Server

Please refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for the necessary setup.

## 📘 API Reference

Troubleshooting FAQ: [Troubleshooting FAQ](./docs/QA.md)

Detailed API documentation is available at: [API Docs](./docs/API.md)

## 🧭 Developer Guide

### ⚡ Fast Development Mode (Recommended)

If you need to frequently modify code, **you don&#039;t need to rebuild Docker images every time**! Use fast development mode:

```bash
# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
```

**Development Advantages:**
- ✅ Frontend modifications auto hot-reload (no restart needed)
- ✅ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)
- ✅ No need to rebuild Docker images
- ✅ Support IDE breakpoint debugging

**Detailed Documentation:** [Development Environment Quick Start](./docs/开发指南.md)

### 📁 Directory Structure

```
WeKnora/
├── client/      # go client
├── cmd/         # Main entry point
├── config/      # Configuration files
├── docker/      # docker images files
├── docreader/   # Document parsing app
├── docs/        # Project documentation
├── frontend/    # Frontend app
├── internal/    # Core business logic
├── mcp-server/  # MCP server
├── migrations/  # DB migration scripts
└── scripts/     # Shell scripts
```

## 🤝 Contributing

We welcome community contributions! For suggestions, bugs, or feature requests, please submit an [Issue](https://github.com/Tencent/WeKnora/issues) or directly create a Pull Request.

### 🎯 How to Contribute

- 🐛 **Bug Fixes**: Discover and fix system defects
- ✨ **New Features**: Propose and implement new capabilities
- 📚 **Documentation**: Improve project documentation
- 🧪 **Test Cases**: Write unit and integration tests
- 🎨 **UI/UX Enhancements**: Improve user interface and experience

### 📋 Contribution Process

1. **Fork the project** to your GitHub account
2. **Create a feature branch** `git checkout -b feature/amazing-feature`
3. **Commit changes** `git commit -m &#039;Add amazing feature&#039;`
4. **Push branch** `git push origin feature/amazing-feature`
5. **Create a Pull Request** with detailed description of changes

### 🎨 Code Standards

- Follow [Go Code Review Comments](https://github.com/golang/go/wiki/CodeReviewComments)
- Format code using `gofmt`
- Add necessary unit tests
- Update relevant documentation

### 📝 Commit Guidelines

Use [Conventional Commits](https://www.conventionalcommits.org/) standard:

```
feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
```

## 👥 Contributors

Thanks to these excellent contributors:

[![Contributors](https://contrib.rocks/image?repo=Tencent/WeKnora)](https://github.com/Tencent/WeKnora/graphs/contributors)

## 📄 License

This project is licensed under the [MIT License](./LICENSE).
You are free to use, modify, and distribute the code with proper attribution.

## 📈 Project Statistics

&lt;a href=&quot;https://www.star-history.com/#Tencent/WeKnora&amp;type=date&amp;legend=top-left&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;type=date&amp;theme=dark&amp;

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[wavetermdev/waveterm]]></title>
            <link>https://github.com/wavetermdev/waveterm</link>
            <guid>https://github.com/wavetermdev/waveterm</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[An open-source, cross-platform terminal for seamless workflows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wavetermdev/waveterm">wavetermdev/waveterm</a></h1>
            <p>An open-source, cross-platform terminal for seamless workflows</p>
            <p>Language: Go</p>
            <p>Stars: 15,305</p>
            <p>Forks: 642</p>
            <p>Stars today: 53 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.waveterm.dev&quot;&gt;
	&lt;picture&gt;
		&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./assets/wave-dark.png&quot;&gt;
		&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./assets/wave-light.png&quot;&gt;
		&lt;img alt=&quot;Wave Terminal Logo&quot; src=&quot;./assets/wave-light.png&quot; width=&quot;240&quot;&gt;
	&lt;/picture&gt;
  &lt;/a&gt;
  &lt;br/&gt;
&lt;/p&gt;

# Wave Terminal

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm?ref=badge_shield)

Wave is an open-source terminal that combines traditional terminal features with graphical capabilities like file previews, web browsing, and AI assistance. It runs on MacOS, Linux, and Windows.

Modern development involves constantly switching between terminals and browsers - checking documentation, previewing files, monitoring systems, and using AI tools. Wave brings these graphical tools directly into the terminal, letting you control them from the command line. This means you can stay in your terminal workflow while still having access to the visual interfaces you need.

![WaveTerm Screenshot](./assets/wave-screenshot.webp)

## Key Features

- Flexible drag &amp; drop interface to organize terminal blocks, editors, web browsers, and AI assistants
- Built-in editor for seamlessly editing remote files with syntax highlighting and modern editor features
- Rich file preview system for remote files (markdown, images, video, PDFs, CSVs, directories)
- Quick full-screen toggle for any block - expand terminals, editors, and previews for better visibility, then instantly return to multi-block view
- Wave AI - Context-aware terminal assistant that reads your terminal output, analyzes widgets, and performs file operations
- AI chat widget with support for multiple models (OpenAI, Claude, Azure, Perplexity, Ollama)
- Command Blocks for isolating and monitoring individual commands with auto-close options
- One-click remote connections with full terminal and file system access
- Secure secret storage using native system backends - store API keys and credentials locally, access them across SSH sessions
- Rich customization including tab themes, terminal styles, and background images
- Powerful `wsh` command system for managing your workspace from the CLI and sharing data between terminal sessions
- Connected file management with `wsh file` - seamlessly copy and sync files between local, remote SSH hosts, Wave filesystem, and S3

## Wave AI

Wave AI is your context-aware terminal assistant with access to your workspace:

- **Terminal Context**: Reads terminal output and scrollback for debugging and analysis
- **File Operations**: Read, write, and edit files with automatic backups and user approval
- **CLI Integration**: Use `wsh ai` to pipe output or attach files directly from the command line
- **Free Beta**: Included AI credits while we refine the experience
- **Coming Soon**: Command execution (with approval), local model support, and alternate AI providers (BYOK)

Learn more in our [Wave AI documentation](https://docs.waveterm.dev/waveai).

## Installation

Wave Terminal works on macOS, Linux, and Windows.

Platform-specific installation instructions can be found [here](https://docs.waveterm.dev/gettingstarted).

You can also install Wave Terminal directly from: [www.waveterm.dev/download](https://www.waveterm.dev/download).

### Minimum requirements

Wave Terminal runs on the following platforms:

- macOS 11 or later (arm64, x64)
- Windows 10 1809 or later (x64)
- Linux based on glibc-2.28 or later (Debian 10, RHEL 8, Ubuntu 20.04, etc.) (arm64, x64)

The WSH helper runs on the following platforms:

- macOS 11 or later (arm64, x64)
- Windows 10 or later (arm64, x64)
- Linux Kernel 2.6.32 or later (x64), Linux Kernel 3.1 or later (arm64)

## Roadmap

Wave is constantly improving! Our roadmap will be continuously updated with our goals for each release. You can find it [here](./ROADMAP.md).

Want to provide input to our future releases? Connect with us on [Discord](https://discord.gg/XfvZ334gwU) or open a [Feature Request](https://github.com/wavetermdev/waveterm/issues/new/choose)!

## Links

- Homepage &amp;mdash; https://www.waveterm.dev
- Download Page &amp;mdash; https://www.waveterm.dev/download
- Documentation &amp;mdash; https://docs.waveterm.dev
- Legacy Documentation &amp;mdash; https://legacydocs.waveterm.dev
- Blog &amp;mdash; https://blog.waveterm.dev
- X &amp;mdash; https://x.com/wavetermdev
- Discord Community &amp;mdash; https://discord.gg/XfvZ334gwU

## Building from Source

See [Building Wave Terminal](BUILD.md).

## Contributing

Wave uses GitHub Issues for issue tracking.

Find more information in our [Contributions Guide](CONTRIBUTING.md), which includes:

- [Ways to contribute](CONTRIBUTING.md#contributing-to-wave-terminal)
- [Contribution guidelines](CONTRIBUTING.md#before-you-start)

## License

Wave Terminal is licensed under the Apache-2.0 License. For more information on our dependencies, see [here](./ACKNOWLEDGEMENTS.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[junegunn/fzf]]></title>
            <link>https://github.com/junegunn/fzf</link>
            <guid>https://github.com/junegunn/fzf</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[🌸 A command-line fuzzy finder]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/junegunn/fzf">junegunn/fzf</a></h1>
            <p>🌸 A command-line fuzzy finder</p>
            <p>Language: Go</p>
            <p>Stars: 75,911</p>
            <p>Forks: 2,639</p>
            <p>Stars today: 95 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;
  &lt;sup&gt;Special thanks to:&lt;/sup&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://tuple.app/fzf&quot;&gt;
    &lt;img alt=&quot;Tuple&#039;s sponsorship image&quot; src=&quot;https://raw.githubusercontent.com/junegunn/i/master/tuple.png&quot; width=&quot;400&quot;&gt;
  &lt;/a&gt;

### [Tuple, the premier screen sharing app for developers](https://tuple.app/fzf)
[Available for MacOS &amp; Windows](https://tuple.app/fzf)&lt;br&gt;

---

   &lt;sup&gt;Special thanks to:&lt;/sup&gt;
   &lt;br&gt;
   &lt;a href=&quot;https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=fzf&quot;&gt;
      &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd7ecac94eae&quot;&gt;
   &lt;/a&gt;

### [Warp, the intelligent terminal for developers](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=fzf)
[Available for MacOS, Linux, &amp; Windows](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=fzf)&lt;br&gt;

&lt;/div&gt;

---

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-color.png&quot; alt=&quot;fzf - a command-line fuzzy finder&quot;&gt;
  &lt;a href=&quot;https://github.com/junegunn/fzf/actions&quot;&gt;&lt;img src=&quot;https://github.com/junegunn/fzf/actions/workflows/linux.yml/badge.svg?branch=master&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;http://github.com/junegunn/fzf/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/tag/junegunn/fzf&quot; alt=&quot;Version&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/junegunn/fzf?tab=MIT-1-ov-file#readme&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/junegunn/fzf&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/junegunn/fzf/graphs/contributors&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/junegunn/fzf&quot; alt=&quot;Contributors&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/sponsors/junegunn&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/sponsors/junegunn&quot; alt=&quot;Sponsors&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/junegunn/fzf/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/junegunn/fzf?style=flat&quot; alt=&quot;Stars&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

---

fzf is a general-purpose command-line fuzzy finder.

&lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-preview.png&quot; width=640&gt;

It&#039;s an interactive filter program for any kind of list; files, command
history, processes, hostnames, bookmarks, git commits, etc. It implements
a &quot;fuzzy&quot; matching algorithm, so you can quickly type in patterns with omitted
characters and still get the results you want.

Highlights
----------

- **Portable** — Distributed as a single binary for easy installation
- **Fast** — Optimized to process millions of items instantly
- **Versatile** — Fully customizable through an event-action binding mechanism
- **All-inclusive** — Comes with integrations for Bash, Zsh, Fish, Vim, and Neovim

Table of Contents
-----------------

&lt;!-- vim-markdown-toc GFM --&gt;

* [Installation](#installation)
    * [Using Homebrew](#using-homebrew)
    * [Linux packages](#linux-packages)
    * [Windows packages](#windows-packages)
    * [Using git](#using-git)
    * [Binary releases](#binary-releases)
    * [Setting up shell integration](#setting-up-shell-integration)
    * [Vim/Neovim plugin](#vimneovim-plugin)
* [Upgrading fzf](#upgrading-fzf)
* [Building fzf](#building-fzf)
* [Usage](#usage)
    * [Using the finder](#using-the-finder)
    * [Display modes](#display-modes)
        * [`--height` mode](#--height-mode)
        * [`--tmux` mode](#--tmux-mode)
    * [Search syntax](#search-syntax)
    * [Environment variables](#environment-variables)
    * [Customizing the look](#customizing-the-look)
    * [Options](#options)
    * [Demo](#demo)
* [Examples](#examples)
* [Key bindings for command-line](#key-bindings-for-command-line)
* [Fuzzy completion for bash and zsh](#fuzzy-completion-for-bash-and-zsh)
    * [Files and directories](#files-and-directories)
    * [Process IDs](#process-ids)
    * [Host names](#host-names)
    * [Environment variables / Aliases](#environment-variables--aliases)
    * [Customizing fzf options for completion](#customizing-fzf-options-for-completion)
    * [Customizing completion source for paths and directories](#customizing-completion-source-for-paths-and-directories)
    * [Supported commands](#supported-commands)
    * [Custom fuzzy completion](#custom-fuzzy-completion)
* [Vim plugin](#vim-plugin)
* [Advanced topics](#advanced-topics)
    * [Customizing for different types of input](#customizing-for-different-types-of-input)
    * [Performance](#performance)
    * [Executing external programs](#executing-external-programs)
    * [Turning into a different process](#turning-into-a-different-process)
    * [Reloading the candidate list](#reloading-the-candidate-list)
        * [1. Update the list of processes by pressing CTRL-R](#1-update-the-list-of-processes-by-pressing-ctrl-r)
        * [2. Switch between sources by pressing CTRL-D or CTRL-F](#2-switch-between-sources-by-pressing-ctrl-d-or-ctrl-f)
        * [3. Interactive ripgrep integration](#3-interactive-ripgrep-integration)
    * [Preview window](#preview-window)
    * [Previewing an image](#previewing-an-image)
* [Tips](#tips)
    * [Respecting `.gitignore`](#respecting-gitignore)
    * [Fish shell](#fish-shell)
    * [fzf Theme Playground](#fzf-theme-playground)
* [Related projects](#related-projects)
* [License](#license)
* [Goods](#goods)
* [Sponsors :heart:](#sponsors-heart)

&lt;!-- vim-markdown-toc --&gt;

Installation
------------

### Using Homebrew

You can use [Homebrew](https://brew.sh/) (on macOS or Linux) to install fzf.

```sh
brew install fzf
```

&gt; [!IMPORTANT]
&gt; To set up shell integration (key bindings and fuzzy completion),
&gt; see [the instructions below](#setting-up-shell-integration).

fzf is also available [via MacPorts][portfile]: `sudo port install fzf`

[portfile]: https://github.com/macports/macports-ports/blob/master/sysutils/fzf/Portfile

### Linux packages

| Package Manager | Linux Distribution      | Command                            |
| --------------- | ----------------------- | ---------------------------------- |
| APK             | Alpine Linux            | `sudo apk add fzf`                 |
| APT             | Debian 9+/Ubuntu 19.10+ | `sudo apt install fzf`             |
| Conda           |                         | `conda install -c conda-forge fzf` |
| DNF             | Fedora                  | `sudo dnf install fzf`             |
| Nix             | NixOS, etc.             | `nix-env -iA nixpkgs.fzf`          |
| Pacman          | Arch Linux              | `sudo pacman -S fzf`               |
| pkg             | FreeBSD                 | `pkg install fzf`                  |
| pkgin           | NetBSD                  | `pkgin install fzf`                |
| pkg_add         | OpenBSD                 | `pkg_add fzf`                      |
| Portage         | Gentoo                  | `emerge --ask app-shells/fzf`      |
| Spack           |                         | `spack install fzf`                |
| XBPS            | Void Linux              | `sudo xbps-install -S fzf`         |
| Zypper          | openSUSE                | `sudo zypper install fzf`          |

&gt; [!IMPORTANT]
&gt; To set up shell integration (key bindings and fuzzy completion),
&gt; see [the instructions below](#setting-up-shell-integration).

[![Packaging status](https://repology.org/badge/vertical-allrepos/fzf.svg?columns=3)](https://repology.org/project/fzf/versions)

### Windows packages

On Windows, fzf is available via [Chocolatey][choco], [Scoop][scoop],
[Winget][winget], and [MSYS2][msys2]:

| Package manager | Command                               |
| --------------- | ------------------------------------- |
| Chocolatey      | `choco install fzf`                   |
| Scoop           | `scoop install fzf`                   |
| Winget          | `winget install fzf`                  |
| MSYS2 (pacman)  | `pacman -S $MINGW_PACKAGE_PREFIX-fzf` |

[choco]: https://chocolatey.org/packages/fzf
[scoop]: https://github.com/ScoopInstaller/Main/blob/master/bucket/fzf.json
[winget]: https://github.com/microsoft/winget-pkgs/tree/master/manifests/j/junegunn/fzf
[msys2]: https://packages.msys2.org/base/mingw-w64-fzf

### Using git

Alternatively, you can &quot;git clone&quot; this repository to any directory and run
[install](https://github.com/junegunn/fzf/blob/master/install) script.

```sh
git clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf
~/.fzf/install
```

The install script will add lines to your shell configuration file to modify
`$PATH` and set up shell integration.

### Binary releases

You can download the official fzf binaries from the releases page.

* https://github.com/junegunn/fzf/releases

### Setting up shell integration

Add the following line to your shell configuration file.

* bash
  ```sh
  # Set up fzf key bindings and fuzzy completion
  eval &quot;$(fzf --bash)&quot;
  ```
* zsh
  ```sh
  # Set up fzf key bindings and fuzzy completion
  source &lt;(fzf --zsh)
  ```
* fish
  ```fish
  # Set up fzf key bindings
  fzf --fish | source
  ```

&gt; [!NOTE]
&gt; `--bash`, `--zsh`, and `--fish` options are only available in fzf 0.48.0 or
&gt; later. If you have an older version of fzf, or want finer control, you can
&gt; source individual script files in the [/shell](/shell) directory. The
&gt; location of the files may vary depending on the package manager you use.
&gt; Please refer to the package documentation for more information.
&gt; (e.g. `apt show fzf`)

&gt; [!TIP]
&gt; You can disable CTRL-T, CTRL-R, or ALT-C bindings by setting the
&gt; corresponding `*_COMMAND` variable to an empty string when sourcing the
&gt; script. For example, to disable CTRL-R and ALT-C:
&gt;
&gt; * bash: `FZF_CTRL_R_COMMAND= FZF_ALT_C_COMMAND= eval &quot;$(fzf --bash)&quot;`
&gt; * zsh: `FZF_CTRL_R_COMMAND= FZF_ALT_C_COMMAND= source &lt;(fzf --zsh)`
&gt; * fish: `fzf --fish | FZF_CTRL_R_COMMAND= FZF_ALT_C_COMMAND= source`
&gt;
&gt; Setting the variables after sourcing the script will have no effect.

### Vim/Neovim plugin

If you use [vim-plug](https://github.com/junegunn/vim-plug), add this to
your Vim configuration file:

```vim
Plug &#039;junegunn/fzf&#039;, { &#039;do&#039;: { -&gt; fzf#install() } }
Plug &#039;junegunn/fzf.vim&#039;
```

* `junegunn/fzf` provides the basic library functions
    * `fzf#install()` makes sure that you have the latest binary
* `junegunn/fzf.vim` is [a separate project](https://github.com/junegunn/fzf.vim)
  that provides a variety of useful commands

To learn more about the Vim integration, see [README-VIM.md](README-VIM.md).

&gt; [!TIP]
&gt; If you use Neovim and prefer Lua-based plugins, check out
&gt; [fzf-lua](https://github.com/ibhagwan/fzf-lua).

Upgrading fzf
-------------

fzf is being actively developed, and you might want to upgrade it once in a
while. Please follow the instruction below depending on the installation
method used.

- git: `cd ~/.fzf &amp;&amp; git pull &amp;&amp; ./install`
- brew: `brew update; brew upgrade fzf`
- macports: `sudo port upgrade fzf`
- chocolatey: `choco upgrade fzf`
- vim-plug: `:PlugUpdate fzf`

Building fzf
------------

See [BUILD.md](BUILD.md).

Usage
-----

fzf will launch interactive finder, read the list from STDIN, and write the
selected item to STDOUT.

```sh
find * -type f | fzf &gt; selected
```

Without STDIN pipe, fzf will traverse the file system under the current
directory to get the list of files.

```sh
vim $(fzf)
```

&gt; [!NOTE]
&gt; You can override the default behavior
&gt; * Either by setting `$FZF_DEFAULT_COMMAND` to a command that generates the desired list
&gt; * Or by setting `--walker`, `--walker-root`, and `--walker-skip` options in `$FZF_DEFAULT_OPTS`

&gt; [!WARNING]
&gt; A more robust solution would be to use `xargs` but we&#039;ve presented
&gt; the above as it&#039;s easier to grasp
&gt; ```sh
&gt; fzf --print0 | xargs -0 -o vim
&gt; ```

&gt; [!TIP]
&gt; fzf also has the ability to turn itself into a different process.
&gt;
&gt; ```sh
&gt; fzf --bind &#039;enter:become(vim {})&#039;
&gt; ```
&gt;
&gt; *See [Turning into a different process](#turning-into-a-different-process)
&gt; for more information.*

### Using the finder

- `CTRL-K` / `CTRL-J` (or `CTRL-P` / `CTRL-N`) to move cursor up and down
- `Enter` key to select the item, `CTRL-C` / `CTRL-G` / `ESC` to exit
- On multi-select mode (`-m`), `TAB` and `Shift-TAB` to mark multiple items
- Emacs style key bindings
- Mouse: scroll, click, double-click; shift-click and shift-scroll on
  multi-select mode

### Display modes

fzf by default runs in fullscreen mode, but there are other display modes.

#### `--height` mode

With `--height HEIGHT[%]`, fzf will start below the cursor with the given height.

```sh
fzf --height 40%
```

`reverse` layout and `--border` goes well with this option.

```sh
fzf --height 40% --layout reverse --border
```

By prepending `~` to the height, you&#039;re setting the maximum height.

```sh
# Will take as few lines as possible to display the list
seq 3 | fzf --height ~100%
seq 3000 | fzf --height ~100%
```

Height value can be a negative number.

```sh
# Screen height - 3
fzf --height -3
```

#### `--tmux` mode

With `--tmux` option, fzf will start in a tmux popup.

```sh
# --tmux [center|top|bottom|left|right][,SIZE[%]][,SIZE[%][,border-native]]

fzf --tmux center         # Center, 50% width and height
fzf --tmux 80%            # Center, 80% width and height
fzf --tmux 100%,50%       # Center, 100% width and 50% height
fzf --tmux left,40%       # Left, 40% width
fzf --tmux left,40%,90%   # Left, 40% width, 90% height
fzf --tmux top,40%        # Top, 40% height
fzf --tmux bottom,80%,40% # Bottom, 80% width, 40% height
```

`--tmux` is silently ignored when you&#039;re not on tmux.

&gt; [!NOTE]
&gt; If you&#039;re stuck with an old version of tmux that doesn&#039;t support popup,
&gt; or if you want to open fzf in a regular tmux pane, check out
&gt; [fzf-tmux](bin/fzf-tmux) script.

&gt; [!TIP]
&gt; You can add these options to `$FZF_DEFAULT_OPTS` so that they&#039;re applied by
&gt; default. For example,
&gt;
&gt; ```sh
&gt; # Open in tmux popup if on tmux, otherwise use --height mode
&gt; export FZF_DEFAULT_OPTS=&#039;--height 40% --tmux bottom,40% --layout reverse --border top&#039;
&gt; ```

### Search syntax

Unless otherwise specified, fzf starts in &quot;extended-search mode&quot; where you can
type in multiple search terms delimited by spaces. e.g. `^music .mp3$ sbtrkt
!fire`

| Token     | Match type                              | Description                                  |
| --------- | --------------------------------------  | ------------------------------------------   |
| `sbtrkt`  | fuzzy-match                             | Items that match `sbtrkt`                    |
| `&#039;wild`   | exact-match (quoted)                    | Items that include `wild`                    |
| `&#039;wild&#039;`  | exact-boundary-match (quoted both ends) | Items that include `wild` at word boundaries |
| `^music`  | prefix-exact-match                      | Items that start with `music`                |
| `.mp3$`   | suffix-exact-match                      | Items that end with `.mp3`                   |
| `!fire`   | inverse-exact-match                     | Items that do not include `fire`             |
| `!^music` | inverse-prefix-exact-match              | Items that do not start with `music`         |
| `!.mp3$`  | inverse-suffix-exact-match              | Items that do not end with `.mp3`            |

If you don&#039;t prefer fuzzy matching and do not wish to &quot;quote&quot; every word,
start fzf with `-e` or `--exact` option. Note that when  `--exact` is set,
`&#039;`-prefix &quot;unquotes&quot; the term.

A single bar character term acts as an OR operator. For example, the following
query matches entries that start with `core` and end with either `go`, `rb`,
or `py`.

```
^core go$ | rb$ | py$
```

### Environment variables

- `FZF_DEFAULT_COMMAND`
    - Default command to use when input is tty
    - e.g. `export FZF_DEFAULT_COMMAND=&#039;fd --type f&#039;`
- `FZF_DEFAULT_OPTS`
    - Default options
    - e.g. `export FZF_DEFAULT_OPTS=&quot;--layout=reverse --inline-info&quot;`
- `FZF_DEFAULT_OPTS_FILE`
    - If you prefer to manage default options in a file, set this variable to
      point to the location of the file
    - e.g. `export FZF_DEFAULT_OPTS_FILE=~/.fzfrc`

&gt; [!WARNING]
&gt; `FZF_DEFAULT_COMMAND` is not used by shell integration due to the
&gt; slight difference in requirements.
&gt;
&gt; * `CTRL-T` runs `$FZF_CTRL_T_COMMAND` to get a list of files and directories
&gt; * `ALT-C` runs `$FZF_ALT_C_COMMAND` to get a list of directories
&gt; * `vim ~/**&lt;tab&gt;` runs `fzf_compgen_path()` with the prefix (`~/`) as the first argument
&gt; * `cd foo**&lt;tab&gt;` runs `fzf_compgen_dir()` with the prefix (`foo`) as the first argument
&gt;
&gt; The available options are described later in this document.

### Customizing the look

The user interface of fzf is fully customizable with a large number of
configuration options. For a quick setup, you can start with one of the style
presets — `default`, `full`, or `minimal` — using the `--style` option.

```sh
fzf --style full \
    --preview &#039;fzf-preview.sh {}&#039; --bind &#039;focus:transform-header:file --brief {}&#039;
```

| Preset    | Screenshot                                                                             |
| :---      | :---                                                                                   |
| `default` | &lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-style-default.png&quot;/&gt; |
| `full`    | &lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-style-full.png&quot;/&gt;    |
| `minimal` | &lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-style-minimal.png&quot;/&gt; |

Here&#039;s an example based on the `full` preset:

&lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-4-borders.png&quot;/&gt;

&lt;details&gt;

```sh
git ls-files | fzf --style full \
    --border --padding 1,2 \
    --border-label &#039; Demo &#039; --input-label &#039; Input &#039; --header-label &#039; File Type &#039; \
    --preview &#039;fzf-preview.sh {}&#039; \
    --bind &#039;result:transform-list-label:
        if [[ -z $FZF_QUERY ]]; then
          echo &quot; $FZF_MATCH_COUNT items &quot;
        else
          echo &quot; $FZF_MATCH_COUNT matches for [$FZF_QUERY] &quot;
        fi
        &#039; \
    --bind &#039;focus:transform-preview-label:[[ -n {} ]] &amp;&amp; printf &quot; Previewing [%s] &quot; {}&#039; \
    --bind &#039;focus:+transform-header:file --brief {} || echo &quot;No file selected&quot;&#039; \
    --bind &#039;ctrl-r:change-list-label( Reloading the list )+reload(sleep 2; git ls-files)&#039; \
    --color &#039;border:#aaaaaa,label:#cccccc&#039; \
    --color &#039;preview-border:#9999cc,preview-label:#ccccff&#039; \
    --color &#039;list-border:#669966,list-label:#99cc99&#039; \
    --color &#039;input-border:#996666,input-label:#ffcccc&#039; \
    --color &#039;header-border:#6699cc,header-label:#99ccff&#039;
```

&lt;/details&gt;

### Options

See the man page (`fzf --man` or `man fzf`) for the full list of options.

### Demo
If you learn by watching videos, check out this screencast by [@samoshkin](https://github.com/samoshkin) to explore `fzf` features.

&lt;a title=&quot;fzf - command-line fuzzy finder&quot; href=&quot;https://www.youtube.com/watch?v=qgG5Jhi_Els&quot;&gt;
  &lt;img src=&quot;https://i.imgur.com/vtG8olE.png&quot; width=&quot;640&quot;&gt;
&lt;/a&gt;

Examples
--------

* [Wiki page of examples](https://github.com/junegunn/fzf/wiki/examples)
    * *Disclaimer: The examples on this page are maintained by the community
      and are not thoroughly tested*
* [Advanced fzf examples](https://github.com/junegunn/fzf/blob/master/ADVANCED.md)

Key bindings for command-line
-----------------------------

By [setting up shell integration](#setting-up-shell-integration), you can use
the following key bindings in bash, zsh, and fish.

- `CTRL-T` - Paste the selected files and directories onto the command-line
    - The list is generated using `--walker file,dir,follow,hidden` option
        - You can override the behavior by setting `FZF_CTRL_T_COMMAND` to a custom command that generates the desired list
        - Or you can set `--walker*` options in `FZF_CTRL_T_OPTS`
    - Set `FZF_CTRL_T_OPTS` to pass additional options to fzf
      ```sh
      # Preview file content using bat (https://github.com/sharkdp/bat)
      export FZF_CTRL_T_OPTS=&quot;
        --walker-skip .git,node_modules,target
        --preview &#039;bat -n --color=always {}&#039;
        --bind &#039;ctrl-/:change-preview-window(down|hidden|)&#039;&quot;
      ```
    - Ca

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kgretzky/evilginx2]]></title>
            <link>https://github.com/kgretzky/evilginx2</link>
            <guid>https://github.com/kgretzky/evilginx2</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[Standalone man-in-the-middle attack framework used for phishing login credentials along with session cookies, allowing for the bypass of 2-factor authentication]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kgretzky/evilginx2">kgretzky/evilginx2</a></h1>
            <p>Standalone man-in-the-middle attack framework used for phishing login credentials along with session cookies, allowing for the bypass of 2-factor authentication</p>
            <p>Language: Go</p>
            <p>Stars: 14,300</p>
            <p>Forks: 2,502</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Evilginx2 Logo&quot; src=&quot;https://raw.githubusercontent.com/kgretzky/evilginx2/master/media/img/evilginx2-logo-512.png&quot; height=&quot;160&quot; /&gt;
  &lt;p align=&quot;center&quot;&gt;
    &lt;img alt=&quot;Evilginx2 Title&quot; src=&quot;https://raw.githubusercontent.com/kgretzky/evilginx2/master/media/img/evilginx2-title-black-512.png&quot; height=&quot;60&quot; /&gt;
  &lt;/p&gt;
&lt;/p&gt;

# Evilginx 3.0

**Evilginx** is a man-in-the-middle attack framework used for phishing login credentials along with session cookies, which in turn allows to bypass 2-factor authentication protection.

This tool is a successor to [Evilginx](https://github.com/kgretzky/evilginx), released in 2017, which used a custom version of nginx HTTP server to provide man-in-the-middle functionality to act as a proxy between a browser and phished website.
Present version is fully written in GO as a standalone application, which implements its own HTTP and DNS server, making it extremely easy to set up and use.

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Screenshot&quot; src=&quot;https://raw.githubusercontent.com/kgretzky/evilginx2/master/media/img/screen.png&quot; height=&quot;320&quot; /&gt;
&lt;/p&gt;

## Disclaimer

I am very much aware that Evilginx can be used for nefarious purposes. This work is merely a demonstration of what adept attackers can do. It is the defender&#039;s responsibility to take such attacks into consideration and find ways to protect their users against this type of phishing attacks. Evilginx should be used only in legitimate penetration testing assignments with written permission from to-be-phished parties.

## Evilginx Pro is now available!

This is it! After over two years of development, countless delays, and hundreds of manual company verifications, concluded with multiple hurdles related to export regulations, [Evilginx Pro is finally live!](https://evilginx.com)

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://evilginx.com&quot;&gt;&lt;img alt=&quot;Evilginx Mastery&quot; src=&quot;https://breakdev.org/content/images/size/w2000/2025/03/evilginx_pro_release_cover.png&quot; height=&quot;320&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

Evilginx Pro is the fruit of a passion I&#039;ve had for a long time in developing offensive security tools for cybersecurity enthusiasts. The journey has just begun, and now that the product is officially released, I can focus on making it even better by implementing all the ideas I&#039;ve planned for it.

### Key features:

- Out-of-the-box **phishing detection evasion** (including Chrome&#039;s Enchanced Browser Protection)
- Tested and maintained **official phishlets database**
- **Botguard** to **prevent bot traffic** by default (same concept as Cloudflare Turnstile)
- **Evilpuppet** for advanced phishing capability (Google)
- External **DNS providers** with multi-domain support
- **Website spoofing** for unauthorized requests
- **JavaScript** &amp; **HTML obfuscation**
- **Wildcard TLS certificates**
- **Automated** server deployment
- **SQLite** database support

Find out more on the [official release blog post](https://breakdev.org/evilginx-pro-release/).

## Evilginx Mastery Training Course

If you want everything about reverse proxy phishing with **Evilginx** - check out my [Evilginx Mastery](https://academy.breakdev.org/evilginx-mastery) course!

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://academy.breakdev.org/evilginx-mastery&quot;&gt;&lt;img alt=&quot;Evilginx Mastery&quot; src=&quot;https://raw.githubusercontent.com/kgretzky/evilginx2/master/media/img/evilginx_mastery.jpg&quot; height=&quot;320&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

Learn everything about the latest methods of phishing, using reverse proxying to bypass Multi-Factor Authentication. Learn to think like an attacker, during your red team engagements, and become the master of phishing with Evilginx.

Grab it here:
https://academy.breakdev.org/evilginx-mastery

## Official Gophish integration

If you&#039;d like to use Gophish to send out phishing links compatible with Evilginx, please use the official Gophish integration with Evilginx 3.3.
You can find the custom version here in the forked repository: [Gophish with Evilginx integration](https://github.com/kgretzky/gophish/)

If you want to learn more about how to set it up, please follow the instructions in [this blog post](https://breakdev.org/evilginx-3-3-go-phish/)

## Write-ups

If you want to learn more about reverse proxy phishing, I&#039;ve published extensive blog posts about **Evilginx** here:

[Evilginx 2.0 - Release](https://breakdev.org/evilginx-2-next-generation-of-phishing-2fa-tokens)

[Evilginx 2.1 - First Update](https://breakdev.org/evilginx-2-1-the-first-post-release-update/)

[Evilginx 2.2 - Jolly Winter Update](https://breakdev.org/evilginx-2-2-jolly-winter-update/)

[Evilginx 2.3 - Phisherman&#039;s Dream](https://breakdev.org/evilginx-2-3-phishermans-dream/)

[Evilginx 2.4 - Gone Phishing](https://breakdev.org/evilginx-2-4-gone-phishing/)

[Evilginx 3.0](https://breakdev.org/evilginx-3-0-evilginx-mastery/)

[Evilginx 3.2](https://breakdev.org/evilginx-3-2/)

[Evilginx 3.3](https://breakdev.org/evilginx-3-3-go-phish/)

## Help

In case you want to learn how to install and use **Evilginx**, please refer to online documentation available at:

https://help.evilginx.com

## Support

I DO NOT offer support for providing or creating phishlets. I will also NOT help you with creation of your own phishlets. Please look for ready-to-use phishlets, provided by other people.

## License

**evilginx2** is made by Kuba Gretzky ([@mrgretzky](https://twitter.com/mrgretzky)) and it&#039;s released under BSD-3 license.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Altinity/clickhouse-operator]]></title>
            <link>https://github.com/Altinity/clickhouse-operator</link>
            <guid>https://github.com/Altinity/clickhouse-operator</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[Altinity Kubernetes Operator for ClickHouse creates, configures and manages ClickHouse® clusters running on Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Altinity/clickhouse-operator">Altinity/clickhouse-operator</a></h1>
            <p>Altinity Kubernetes Operator for ClickHouse creates, configures and manages ClickHouse® clusters running on Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 2,342</p>
            <p>Forks: 521</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># Altinity® Kubernetes Operator for ClickHouse®

The Altinity Kubernetes Operator for ClickHouse creates, configures and manages ClickHouse clusters running on Kubernetes.

[![Build Master](https://github.com/Altinity/clickhouse-operator/actions/workflows/build_master.yaml/badge.svg)](https://github.com/Altinity/clickhouse-operator/actions/workflows/build_master.yaml)
[![GitHub release](https://img.shields.io/github/v/release/altinity/clickhouse-operator?include_prereleases)](https://img.shields.io/github/v/release/altinity/clickhouse-operator?include_prereleases)
[![tags](https://img.shields.io/github/tag/altinity/clickhouse-operator.svg)](https://github.com/altinity/clickhouse-operator/tags)
[![Docker Pulls](https://img.shields.io/docker/pulls/altinity/clickhouse-operator.svg)](https://hub.docker.com/r/altinity/clickhouse-operator)
[![Go version](https://img.shields.io/github/go-mod/go-version/altinity/clickhouse-operator)](https://img.shields.io/github/go-mod/go-version/altinity/clickhouse-operator)
[![Go Report Card](https://goreportcard.com/badge/github.com/altinity/clickhouse-operator)](https://goreportcard.com/report/github.com/altinity/clickhouse-operator)
[![issues](https://img.shields.io/github/issues/altinity/clickhouse-operator.svg)](https://github.com/altinity/clickhouse-operator/issues)
&lt;a href=&quot;https://altinity.com/slack&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/static/v1?logo=slack&amp;logoColor=959DA5&amp;label=Slack&amp;labelColor=333a41&amp;message=join%20conversation&amp;color=3AC358&quot; alt=&quot;AltinityDB Slack&quot; /&gt;
&lt;/a&gt;

## Features

- Creates ClickHouse clusters defined as custom resources
- Customized storage provisioning (VolumeClaim templates)
- Customized pod templates
- Customized service templates for endpoints
- ClickHouse configuration management
- ClickHouse users management
- ClickHouse cluster scaling including automatic schema propagation
- ClickHouse version upgrades
- Exporting ClickHouse metrics to Prometheus

## Community

The Altinity Kubernetes Operator for ClickHouse is a community effort sponsored by Altinity. The best way to reach us or ask questions is:

* Join the [Altinity Slack](https://altinity.com/slack) - Chat with the developers and other users
* Log an [issue on GitHub](https://github.com/Altinity/clickhouse-operator/issues) - Ask questions, log bugs and feature requests

## Requirements

 * Kubernetes 1.19+
 * ClickHouse 21.11+. For older ClickHouse versions use operator 0.23.7 or earlier.
 
## Documentation

[Quick Start Guide][quick_start_guide]

**Advanced configuration**
 * [Detailed Operator Installation Instructions][detailed_installation_instructions]
   * [Operator Configuration][operator_configuration]
 * [Setup ClickHouse cluster with replication][replication_setup]
   * [Setting up Zookeeper][zookeeper_setup]
 * [Persistent Storage Configuration][storage_configuration]
 * [Security Hardening][security_hardening]
 * [ClickHouse Installation Custom Resource specification][crd_explained]
 
**Maintenance tasks**
 * [Add replication to an existing ClickHouse cluster][update_cluster_add_replication]
 * [Schema maintenance][schema_migration]
 * [Update ClickHouse version][update_clickhouse_version]
 * [Update Operator version][update_operator]

**Monitoring**
 * [Setup Monitoring][monitoring_setup]
 * [Prometheus &amp; clickhouse-operator integration][prometheus_setup]
 * [Grafana &amp; Prometheus integration][grafana_setup]

**How to contribute**
 * [How to contribute/submit a patch][contributing_manual]
 * [How to easy development process with devspace.sh][devspace_manual]
 
---
 * [Documentation index][all_docs_list]
---
 
## License

Copyright (c) 2019-2025, Altinity Inc and/or its affiliates. All rights reserved.

Altinity Kubernetes Operator for ClickHouse is licensed under the Apache License 2.0.

See [LICENSE](./LICENSE) for more details.

## Commercial Support

Altinity is the primary maintainer of the operator. It is the basis of Altinity.Cloud and
is also used in self-managed installations. Altinity offers a range of 
services related to ClickHouse and analytic applications on Kubernetes. 

- [Official website](https://altinity.com/) - Get a high level overview of Altinity and our offerings.
- [Altinity.Cloud](https://altinity.com/cloud-database/) - Run ClickHouse in our cloud or yours.
- [Altinity Support](https://altinity.com/support/) - Get Enterprise-class support for ClickHouse.
- [Slack](https://altinity.com/slack) - Talk directly with ClickHouse users and Altinity devs.
- [Contact us](https://hubs.la/Q020sH3Z0) - Contact Altinity with your questions or issues.
- [Free consultation](https://hubs.la/Q020sHkv0) - Get a free consultation with a ClickHouse expert today.
 
[chi_max_yaml]: ./docs/chi-examples/99-clickhouseinstallation-max.yaml
[intro]: ./docs/introduction.md
[quick_start_guide]: ./docs/quick_start.md
[detailed_installation_instructions]: ./docs/operator_installation_details.md
[replication_setup]: ./docs/replication_setup.md
[crd_explained]: ./docs/custom_resource_explained.md
[zookeeper_setup]: ./docs/zookeeper_setup.md
[monitoring_setup]: ./docs/monitoring_setup.md
[prometheus_setup]: ./docs/prometheus_setup.md
[grafana_setup]: ./docs/grafana_setup.md
[storage_configuration]: ./docs/storage.md
[update_cluster_add_replication]: ./docs/chi_update_add_replication.md
[update_clickhouse_version]: ./docs/chi_update_clickhouse_version.md
[update_operator]: ./docs/operator_upgrade.md
[schema_migration]: ./docs/schema_migration.md
[operator_configuration]: ./docs/operator_configuration.md
[contributing_manual]: ./CONTRIBUTING.md
[devspace_manual]: ./docs/devspace.md
[all_docs_list]: ./docs/README.md
[security_hardening]: ./docs/security_hardening.md
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Jguer/yay]]></title>
            <link>https://github.com/Jguer/yay</link>
            <guid>https://github.com/Jguer/yay</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[Yet another Yogurt - An AUR Helper written in Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Jguer/yay">Jguer/yay</a></h1>
            <p>Yet another Yogurt - An AUR Helper written in Go</p>
            <p>Language: Go</p>
            <p>Stars: 12,875</p>
            <p>Forks: 390</p>
            <p>Stars today: 29 stars today</p>
            <h2>README</h2><pre>[![yay](https://img.shields.io/aur/version/yay?color=1793d1&amp;label=yay&amp;logo=arch-linux&amp;style=for-the-badge)](https://aur.archlinux.org/packages/yay/)
[![yay-bin](https://img.shields.io/aur/version/yay-bin?color=1793d1&amp;label=yay-bin&amp;logo=arch-linux&amp;style=for-the-badge)](https://aur.archlinux.org/packages/yay-bin/)
[![yay-git](https://img.shields.io/aur/version/yay-git?color=1793d1&amp;label=yay-git&amp;logo=arch-linux&amp;style=for-the-badge)](https://aur.archlinux.org/packages/yay-git/)
![AUR votes](https://img.shields.io/aur/votes/yay?color=333333&amp;style=for-the-badge)
[![GitHub license](https://img.shields.io/github/license/jguer/yay?color=333333&amp;style=for-the-badge)](https://github.com/Jguer/yay/blob/master/LICENSE)

# Yay

Yet Another Yogurt - An AUR Helper Written in Go

### Help translate yay: [Transifex](https://app.transifex.com/yay-1/yay/)

## Features

- Advanced dependency solving
- PKGBUILD downloading from ABS or AUR
- Completions for AUR packages
- Query user up-front for all input (prior to starting builds)
- Narrow search (`yay linux header` will first search `linux` and then narrow on `header`)
- Find matching package providers during search and allow selection
- Remove make dependencies at the end of the build process
- Build local PKGBUILDs with AUR dependencies
- Un/Vote for packages

[![asciicast](https://asciinema.org/a/399431.svg)](https://asciinema.org/a/399431)

[![asciicast](https://asciinema.org/a/399433.svg)](https://asciinema.org/a/399433)

## Installation

If you are migrating from another AUR helper, you can simply install Yay with that helper.

&gt; [!WARNING]  
&gt; We are using `sudo` in these examples, you can switch that out for a different privilege escalation tool.

### Source

The initial installation of Yay can be done by cloning the PKGBUILD and
building with makepkg:

We make sure we have the `base-devel` package group installed.

```sh
sudo pacman -S --needed git base-devel
git clone https://aur.archlinux.org/yay.git
cd yay
makepkg -si
```

If you want to do all of this at once, we can chain the commands like so:

```sh
sudo pacman -S --needed git base-devel &amp;&amp; git clone https://aur.archlinux.org/yay.git &amp;&amp; cd yay &amp;&amp; makepkg -si
```

### Binary

If you do not want to compile yay yourself you can use the builds generated by
GitHub Actions.

```sh
sudo pacman -S --needed git base-devel
git clone https://aur.archlinux.org/yay-bin.git
cd yay-bin
makepkg -si
```

If you want to do all of this at once, we can chain the commands like so:

```sh
sudo pacman -S --needed git base-devel &amp;&amp; git clone https://aur.archlinux.org/yay-bin.git &amp;&amp; cd yay-bin &amp;&amp; makepkg -si
```

### Other distributions

If you&#039;re using Manjaro or [another distribution that packages `yay`](https://repology.org/project/yay/versions)
you can simply install yay using pacman (as root):

```sh
pacman -S --needed git base-devel yay
```
&gt; [!WARNING]  
&gt; distributions sometimes lag updating yay on their repositories.

## First Use

#### Development packages upgrade

- Use `yay -Y --gendb` to generate a development package database for `*-git`
  packages that were installed without yay.
  This command should only be run once.

- `yay -Syu --devel` will then check for development package updates

- Use `yay -Y --devel --save` to make development package updates permanently
  enabled (`yay` and `yay -Syu` will then always check dev packages)

## Examples of Custom Operations

| Command                           | Description                                                                                                |
| --------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| `yay`                             | Alias to `yay -Syu`.                                                                                       |
| `yay &lt;Search Term&gt;`               | Present package-installation selection menu.                                                               |
| `yay -Bi &lt;dir&gt;`                   | Install dependencies and build a local PKGBUILD.                                                           |
| `yay -G &lt;AUR Package&gt;`            | Download PKGBUILD from ABS or AUR. (yay v12.0+)                                                            |
| `yay -Gp &lt;AUR Package&gt;`           | Print to stdout PKGBUILD from ABS or AUR.                                                                  |
| `yay -Ps`                         | Print system statistics.                                                                                   |
| `yay -Syu --devel`                | Perform system upgrade, but also check for development package updates.                                    |
| `yay -Syu --timeupdate`           | Perform system upgrade and use PKGBUILD modification time (not version number) to determine update.        |
| `yay -Wu &lt;AUR Package&gt;`           | Unvote for package (Requires setting `AUR_USERNAME` and `AUR_PASSWORD` environment variables) (yay v11.3+) |
| `yay -Wv &lt;AUR Package&gt;`           | Vote for package (Requires setting `AUR_USERNAME` and `AUR_PASSWORD` environment variables). (yay v11.3+)  |
| `yay -Y --combinedupgrade --save` | Make combined upgrade the default mode.                                                                    |
| `yay -Y --gendb`                  | Generate development package database used for devel update.                                               |
| `yay -Yc`                         | Clean unneeded dependencies.                                                                               |

## Frequently Asked Questions

- **Yay does not display colored output. How do I fix it?**

  Make sure you have the `Color` option in your `/etc/pacman.conf`
  (see issue [#123](https://github.com/Jguer/yay/issues/123)).

- **Sometimes diffs are printed to the terminal, and other times they are paged via less. How do I fix this?**

  Yay uses `git diff` to display diffs, which by default tells less not to
  page if the output can fit into one terminal length. This behavior can be
  overridden by exporting your own flags (`export LESS=SRX`).

- **Yay is not asking me to edit PKGBUILDS, and I don&#039;t like the diff menu! What can I do?**

  `yay --editmenu --diffmenu=false --save`

- **How can I tell Yay to act only on AUR packages, or only on repo packages?**

  `yay -{OPERATION} --aur`
  `yay -{OPERATION} --repo`

- **A `Flagged Out Of Date AUR Packages` message is displayed. Why doesn&#039;t Yay update them?**

  This message does not mean that updated AUR packages are available. It means
  the packages have been flagged out of date on the AUR, but
  their maintainers have not yet updated the `PKGBUILD`s
  (see [outdated AUR packages](https://wiki.archlinux.org/index.php/Arch_User_Repository#Foo_in_the_AUR_is_outdated.3B_what_should_I_do.3F)).

- **Yay doesn&#039;t install dependencies added to a PKGBUILD during installation.**

  Yay resolves all dependencies ahead of time. You are free to edit the
  PKGBUILD in any way, but any problems you cause are your own and should not be
  reported unless they can be reproduced with the original PKGBUILD.

- **I know my `-git` package has updates but yay doesn&#039;t offer to update it**

  Yay uses a hash cache for development packages. Normally it is updated at the end of the package install with the message `Found git repo`.
  If you transition between aur helpers and did not install the devel package using yay at some point, it is possible it never got added to the cache. `yay -Y --gendb` will fix the current version of every devel package and start checking from there.

- **I want to help out!**

  Check [CONTRIBUTING.md](./CONTRIBUTING.md) for more information.

## Support

All support related to Yay should be requested via GitHub issues. Since Yay is not
officially supported by Arch Linux, support should not be sought out on the
forums, AUR comments or other official channels.

A broken AUR package should be reported as a comment on the package&#039;s AUR page.
A package may only be considered broken if it fails to build with makepkg.

Reports should be made using makepkg and include the full output as well as any
other relevant information. Never make reports using Yay or any other external
tools.

## Images

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/Jguer/jguer.github.io/refs/heads/master/yay/yay.png&quot; width=&quot;42%&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/Jguer/jguer.github.io/refs/heads/master/yay/yay-s.png&quot; width=&quot;42%&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/Jguer/jguer.github.io/refs/heads/master/yay/yay-y.png&quot; width=&quot;42%&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/Jguer/jguer.github.io/refs/heads/master/yay/yay-ps.png&quot; width=&quot;42%&quot;&gt;
&lt;/p&gt;

### Other AUR helpers/tools

- [paru](https://github.com/morganamilo/paru)
- [aurutils](https://github.com/AladW/aurutils)
- [pikaur](https://github.com/actionless/pikaur)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[sashabaranov/go-openai]]></title>
            <link>https://github.com/sashabaranov/go-openai</link>
            <guid>https://github.com/sashabaranov/go-openai</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[OpenAI ChatGPT, GPT-5, GPT-Image-1, Whisper API clients for Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sashabaranov/go-openai">sashabaranov/go-openai</a></h1>
            <p>OpenAI ChatGPT, GPT-5, GPT-Image-1, Whisper API clients for Go</p>
            <p>Language: Go</p>
            <p>Stars: 10,451</p>
            <p>Forks: 1,678</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># Go OpenAI
[![Go Reference](https://pkg.go.dev/badge/github.com/sashabaranov/go-openai.svg)](https://pkg.go.dev/github.com/sashabaranov/go-openai)
[![Go Report Card](https://goreportcard.com/badge/github.com/sashabaranov/go-openai)](https://goreportcard.com/report/github.com/sashabaranov/go-openai)
[![codecov](https://codecov.io/gh/sashabaranov/go-openai/branch/master/graph/badge.svg?token=bCbIfHLIsW)](https://codecov.io/gh/sashabaranov/go-openai)

This library provides unofficial Go clients for [OpenAI API](https://platform.openai.com/). We support: 

* ChatGPT 4o, o1
* GPT-3, GPT-4
* DALL·E 2, DALL·E 3, GPT Image 1
* Whisper

## Installation

```
go get github.com/sashabaranov/go-openai
```
Currently, go-openai requires Go version 1.18 or greater.


## Usage

### ChatGPT example usage:

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	client := openai.NewClient(&quot;your token&quot;)
	resp, err := client.CreateChatCompletion(
		context.Background(),
		openai.ChatCompletionRequest{
			Model: openai.GPT3Dot5Turbo,
			Messages: []openai.ChatCompletionMessage{
				{
					Role:    openai.ChatMessageRoleUser,
					Content: &quot;Hello!&quot;,
				},
			},
		},
	)

	if err != nil {
		fmt.Printf(&quot;ChatCompletion error: %v\n&quot;, err)
		return
	}

	fmt.Println(resp.Choices[0].Message.Content)
}

```

### Getting an OpenAI API Key:

1. Visit the OpenAI website at [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys).
2. If you don&#039;t have an account, click on &quot;Sign Up&quot; to create one. If you do, click &quot;Log In&quot;.
3. Once logged in, navigate to your API key management page.
4. Click on &quot;Create new secret key&quot;.
5. Enter a name for your new key, then click &quot;Create secret key&quot;.
6. Your new API key will be displayed. Use this key to interact with the OpenAI API.

**Note:** Your API key is sensitive information. Do not share it with anyone.

### Other examples:

&lt;details&gt;
&lt;summary&gt;ChatGPT streaming completion&lt;/summary&gt;

```go
package main

import (
	&quot;context&quot;
	&quot;errors&quot;
	&quot;fmt&quot;
	&quot;io&quot;
	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	c := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	req := openai.ChatCompletionRequest{
		Model:     openai.GPT3Dot5Turbo,
		MaxTokens: 20,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleUser,
				Content: &quot;Lorem ipsum&quot;,
			},
		},
		Stream: true,
	}
	stream, err := c.CreateChatCompletionStream(ctx, req)
	if err != nil {
		fmt.Printf(&quot;ChatCompletionStream error: %v\n&quot;, err)
		return
	}
	defer stream.Close()

	fmt.Printf(&quot;Stream response: &quot;)
	for {
		response, err := stream.Recv()
		if errors.Is(err, io.EOF) {
			fmt.Println(&quot;\nStream finished&quot;)
			return
		}

		if err != nil {
			fmt.Printf(&quot;\nStream error: %v\n&quot;, err)
			return
		}

		fmt.Printf(response.Choices[0].Delta.Content)
	}
}
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;GPT-3 completion&lt;/summary&gt;

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	c := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	req := openai.CompletionRequest{
		Model:     openai.GPT3Babbage002,
		MaxTokens: 5,
		Prompt:    &quot;Lorem ipsum&quot;,
	}
	resp, err := c.CreateCompletion(ctx, req)
	if err != nil {
		fmt.Printf(&quot;Completion error: %v\n&quot;, err)
		return
	}
	fmt.Println(resp.Choices[0].Text)
}
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;GPT-3 streaming completion&lt;/summary&gt;

```go
package main

import (
	&quot;errors&quot;
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;io&quot;
	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	c := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	req := openai.CompletionRequest{
		Model:     openai.GPT3Babbage002,
		MaxTokens: 5,
		Prompt:    &quot;Lorem ipsum&quot;,
		Stream:    true,
	}
	stream, err := c.CreateCompletionStream(ctx, req)
	if err != nil {
		fmt.Printf(&quot;CompletionStream error: %v\n&quot;, err)
		return
	}
	defer stream.Close()

	for {
		response, err := stream.Recv()
		if errors.Is(err, io.EOF) {
			fmt.Println(&quot;Stream finished&quot;)
			return
		}

		if err != nil {
			fmt.Printf(&quot;Stream error: %v\n&quot;, err)
			return
		}


		fmt.Printf(&quot;Stream response: %v\n&quot;, response)
	}
}
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Audio Speech-To-Text&lt;/summary&gt;

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;

	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	c := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	req := openai.AudioRequest{
		Model:    openai.Whisper1,
		FilePath: &quot;recording.mp3&quot;,
	}
	resp, err := c.CreateTranscription(ctx, req)
	if err != nil {
		fmt.Printf(&quot;Transcription error: %v\n&quot;, err)
		return
	}
	fmt.Println(resp.Text)
}
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Audio Captions&lt;/summary&gt;

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;os&quot;

	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	c := openai.NewClient(os.Getenv(&quot;OPENAI_KEY&quot;))

	req := openai.AudioRequest{
		Model:    openai.Whisper1,
		FilePath: os.Args[1],
		Format:   openai.AudioResponseFormatSRT,
	}
	resp, err := c.CreateTranscription(context.Background(), req)
	if err != nil {
		fmt.Printf(&quot;Transcription error: %v\n&quot;, err)
		return
	}
	f, err := os.Create(os.Args[1] + &quot;.srt&quot;)
	if err != nil {
		fmt.Printf(&quot;Could not open file: %v\n&quot;, err)
		return
	}
	defer f.Close()
	if _, err := f.WriteString(resp.Text); err != nil {
		fmt.Printf(&quot;Error writing to file: %v\n&quot;, err)
		return
	}
}
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;DALL-E 2 image generation&lt;/summary&gt;

```go
package main

import (
	&quot;bytes&quot;
	&quot;context&quot;
	&quot;encoding/base64&quot;
	&quot;fmt&quot;
	openai &quot;github.com/sashabaranov/go-openai&quot;
	&quot;image/png&quot;
	&quot;os&quot;
)

func main() {
	c := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	// Sample image by link
	reqUrl := openai.ImageRequest{
		Prompt:         &quot;Parrot on a skateboard performs a trick, cartoon style, natural light, high detail&quot;,
		Size:           openai.CreateImageSize256x256,
		ResponseFormat: openai.CreateImageResponseFormatURL,
		N:              1,
	}

	respUrl, err := c.CreateImage(ctx, reqUrl)
	if err != nil {
		fmt.Printf(&quot;Image creation error: %v\n&quot;, err)
		return
	}
	fmt.Println(respUrl.Data[0].URL)

	// Example image as base64
	reqBase64 := openai.ImageRequest{
		Prompt:         &quot;Portrait of a humanoid parrot in a classic costume, high detail, realistic light, unreal engine&quot;,
		Size:           openai.CreateImageSize256x256,
		ResponseFormat: openai.CreateImageResponseFormatB64JSON,
		N:              1,
	}

	respBase64, err := c.CreateImage(ctx, reqBase64)
	if err != nil {
		fmt.Printf(&quot;Image creation error: %v\n&quot;, err)
		return
	}

	imgBytes, err := base64.StdEncoding.DecodeString(respBase64.Data[0].B64JSON)
	if err != nil {
		fmt.Printf(&quot;Base64 decode error: %v\n&quot;, err)
		return
	}

	r := bytes.NewReader(imgBytes)
	imgData, err := png.Decode(r)
	if err != nil {
		fmt.Printf(&quot;PNG decode error: %v\n&quot;, err)
		return
	}

	file, err := os.Create(&quot;example.png&quot;)
	if err != nil {
		fmt.Printf(&quot;File creation error: %v\n&quot;, err)
		return
	}
	defer file.Close()

	if err := png.Encode(file, imgData); err != nil {
		fmt.Printf(&quot;PNG encode error: %v\n&quot;, err)
		return
	}

	fmt.Println(&quot;The image was saved as example.png&quot;)
}

```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;GPT Image 1 image generation&lt;/summary&gt;

```go
package main

import (
	&quot;context&quot;
	&quot;encoding/base64&quot;
	&quot;fmt&quot;
	&quot;os&quot;

	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	c := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	req := openai.ImageRequest{
		Prompt:            &quot;Parrot on a skateboard performing a trick. Large bold text \&quot;SKATE MASTER\&quot; banner at the bottom of the image. Cartoon style, natural light, high detail, 1:1 aspect ratio.&quot;,
		Background:        openai.CreateImageBackgroundOpaque,
		Model:             openai.CreateImageModelGptImage1,
		Size:              openai.CreateImageSize1024x1024,
		N:                 1,
		Quality:           openai.CreateImageQualityLow,
		OutputCompression: 100,
		OutputFormat:      openai.CreateImageOutputFormatJPEG,
		// Moderation: 		 openai.CreateImageModerationLow,
		// User: 					 &quot;&quot;,
	}

	resp, err := c.CreateImage(ctx, req)
	if err != nil {
		fmt.Printf(&quot;Image creation Image generation with GPT Image 1error: %v\n&quot;, err)
		return
	}

	fmt.Println(&quot;Image Base64:&quot;, resp.Data[0].B64JSON)

	// Decode the base64 data
	imgBytes, err := base64.StdEncoding.DecodeString(resp.Data[0].B64JSON)
	if err != nil {
		fmt.Printf(&quot;Base64 decode error: %v\n&quot;, err)
		return
	}

	// Write image to file
	outputPath := &quot;generated_image.jpg&quot;
	err = os.WriteFile(outputPath, imgBytes, 0644)
	if err != nil {
		fmt.Printf(&quot;Failed to write image file: %v\n&quot;, err)
		return
	}

	fmt.Printf(&quot;The image was saved as %s\n&quot;, outputPath)
}
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Configuring proxy&lt;/summary&gt;

```go
config := openai.DefaultConfig(&quot;token&quot;)
proxyUrl, err := url.Parse(&quot;http://localhost:{port}&quot;)
if err != nil {
	panic(err)
}
transport := &amp;http.Transport{
	Proxy: http.ProxyURL(proxyUrl),
}
config.HTTPClient = &amp;http.Client{
	Transport: transport,
}

c := openai.NewClientWithConfig(config)
```

See also: https://pkg.go.dev/github.com/sashabaranov/go-openai#ClientConfig
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ChatGPT support context&lt;/summary&gt;

```go
package main

import (
	&quot;bufio&quot;
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;os&quot;
	&quot;strings&quot;

	&quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	client := openai.NewClient(&quot;your token&quot;)
	messages := make([]openai.ChatCompletionMessage, 0)
	reader := bufio.NewReader(os.Stdin)
	fmt.Println(&quot;Conversation&quot;)
	fmt.Println(&quot;---------------------&quot;)

	for {
		fmt.Print(&quot;-&gt; &quot;)
		text, _ := reader.ReadString(&#039;\n&#039;)
		// convert CRLF to LF
		text = strings.Replace(text, &quot;\n&quot;, &quot;&quot;, -1)
		messages = append(messages, openai.ChatCompletionMessage{
			Role:    openai.ChatMessageRoleUser,
			Content: text,
		})

		resp, err := client.CreateChatCompletion(
			context.Background(),
			openai.ChatCompletionRequest{
				Model:    openai.GPT3Dot5Turbo,
				Messages: messages,
			},
		)

		if err != nil {
			fmt.Printf(&quot;ChatCompletion error: %v\n&quot;, err)
			continue
		}

		content := resp.Choices[0].Message.Content
		messages = append(messages, openai.ChatCompletionMessage{
			Role:    openai.ChatMessageRoleAssistant,
			Content: content,
		})
		fmt.Println(content)
	}
}
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Azure OpenAI ChatGPT&lt;/summary&gt;

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;

	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	config := openai.DefaultAzureConfig(&quot;your Azure OpenAI Key&quot;, &quot;https://your Azure OpenAI Endpoint&quot;)
	// If you use a deployment name different from the model name, you can customize the AzureModelMapperFunc function
	// config.AzureModelMapperFunc = func(model string) string {
	// 	azureModelMapping := map[string]string{
	// 		&quot;gpt-3.5-turbo&quot;: &quot;your gpt-3.5-turbo deployment name&quot;,
	// 	}
	// 	return azureModelMapping[model]
	// }

	client := openai.NewClientWithConfig(config)
	resp, err := client.CreateChatCompletion(
		context.Background(),
		openai.ChatCompletionRequest{
			Model: openai.GPT3Dot5Turbo,
			Messages: []openai.ChatCompletionMessage{
				{
					Role:    openai.ChatMessageRoleUser,
					Content: &quot;Hello Azure OpenAI!&quot;,
				},
			},
		},
	)
	if err != nil {
		fmt.Printf(&quot;ChatCompletion error: %v\n&quot;, err)
		return
	}

	fmt.Println(resp.Choices[0].Message.Content)
}

```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Embedding Semantic Similarity&lt;/summary&gt;

```go
package main

import (
	&quot;context&quot;
	&quot;log&quot;
	openai &quot;github.com/sashabaranov/go-openai&quot;

)

func main() {
	client := openai.NewClient(&quot;your-token&quot;)

	// Create an EmbeddingRequest for the user query
	queryReq := openai.EmbeddingRequest{
		Input: []string{&quot;How many chucks would a woodchuck chuck&quot;},
		Model: openai.AdaEmbeddingV2,
	}

	// Create an embedding for the user query
	queryResponse, err := client.CreateEmbeddings(context.Background(), queryReq)
	if err != nil {
		log.Fatal(&quot;Error creating query embedding:&quot;, err)
	}

	// Create an EmbeddingRequest for the target text
	targetReq := openai.EmbeddingRequest{
		Input: []string{&quot;How many chucks would a woodchuck chuck if the woodchuck could chuck wood&quot;},
		Model: openai.AdaEmbeddingV2,
	}

	// Create an embedding for the target text
	targetResponse, err := client.CreateEmbeddings(context.Background(), targetReq)
	if err != nil {
		log.Fatal(&quot;Error creating target embedding:&quot;, err)
	}

	// Now that we have the embeddings for the user query and the target text, we
	// can calculate their similarity.
	queryEmbedding := queryResponse.Data[0]
	targetEmbedding := targetResponse.Data[0]

	similarity, err := queryEmbedding.DotProduct(&amp;targetEmbedding)
	if err != nil {
		log.Fatal(&quot;Error calculating dot product:&quot;, err)
	}

	log.Printf(&quot;The similarity score between the query and the target is %f&quot;, similarity)
}

```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Azure OpenAI Embeddings&lt;/summary&gt;

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;

	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {

	config := openai.DefaultAzureConfig(&quot;your Azure OpenAI Key&quot;, &quot;https://your Azure OpenAI Endpoint&quot;)
	config.APIVersion = &quot;2023-05-15&quot; // optional update to latest API version

	//If you use a deployment name different from the model name, you can customize the AzureModelMapperFunc function
	//config.AzureModelMapperFunc = func(model string) string {
	//    azureModelMapping := map[string]string{
	//        &quot;gpt-3.5-turbo&quot;:&quot;your gpt-3.5-turbo deployment name&quot;,
	//    }
	//    return azureModelMapping[model]
	//}

	input := &quot;Text to vectorize&quot;

	client := openai.NewClientWithConfig(config)
	resp, err := client.CreateEmbeddings(
		context.Background(),
		openai.EmbeddingRequest{
			Input: []string{input},
			Model: openai.AdaEmbeddingV2,
		})

	if err != nil {
		fmt.Printf(&quot;CreateEmbeddings error: %v\n&quot;, err)
		return
	}

	vectors := resp.Data[0].Embedding // []float32 with 1536 dimensions

	fmt.Println(vectors[:10], &quot;...&quot;, vectors[len(vectors)-10:])
}
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;JSON Schema for function calling&lt;/summary&gt;

It is now possible for chat completion to choose to call a function for more information ([see developer docs here](https://platform.openai.com/docs/guides/gpt/function-calling)).

In order to describe the type of functions that can be called, a JSON schema must be provided. Many JSON schema libraries exist and are more advanced than what we can offer in this library, however we have included a simple `jsonschema` package for those who want to use this feature without formatting their own JSON schema payload.

The developer documents give this JSON schema definition as an example:

```json
{
  &quot;name&quot;:&quot;get_current_weather&quot;,
  &quot;description&quot;:&quot;Get the current weather in a given location&quot;,
  &quot;parameters&quot;:{
    &quot;type&quot;:&quot;object&quot;,
    &quot;properties&quot;:{
        &quot;location&quot;:{
          &quot;type&quot;:&quot;string&quot;,
          &quot;description&quot;:&quot;The city and state, e.g. San Francisco, CA&quot;
        },
        &quot;unit&quot;:{
          &quot;type&quot;:&quot;string&quot;,
          &quot;enum&quot;:[
              &quot;celsius&quot;,
              &quot;fahrenheit&quot;
          ]
        }
    },
    &quot;required&quot;:[
        &quot;location&quot;
    ]
  }
}
```

Using the `jsonschema` package, this schema could be created using structs as such:

```go
FunctionDefinition{
  Name: &quot;get_current_weather&quot;,
  Parameters: jsonschema.Definition{
    Type: jsonschema.Object,
    Properties: map[string]jsonschema.Definition{
      &quot;location&quot;: {
        Type: jsonschema.String,
        Description: &quot;The city and state, e.g. San Francisco, CA&quot;,
      },
      &quot;unit&quot;: {
        Type: jsonschema.String,
        Enum: []string{&quot;celsius&quot;, &quot;fahrenheit&quot;},
      },
    },
    Required: []string{&quot;location&quot;},
  },
}
```

The `Parameters` field of a `FunctionDefinition` can accept either of the above styles, or even a nested struct from another library (as long as it can be marshalled into JSON).
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Error handling&lt;/summary&gt;

Open-AI maintains clear documentation on how to [handle API errors](https://platform.openai.com/docs/guides/error-codes/api-errors)

example:
```
e := &amp;openai.APIError{}
if errors.As(err, &amp;e) {
  switch e.HTTPStatusCode {
    case 401:
      // invalid auth or key (do not retry)
    case 429:
      // rate limiting or engine overload (wait and retry) 
    case 500:
      // openai server error (retry)
    default:
      // unhandled
  }
}

```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Fine Tune Model&lt;/summary&gt;

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	client := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	// create a .jsonl file with your training data for conversational model
	// {&quot;prompt&quot;: &quot;&lt;prompt text&gt;&quot;, &quot;completion&quot;: &quot;&lt;ideal generated text&gt;&quot;}
	// {&quot;prompt&quot;: &quot;&lt;prompt text&gt;&quot;, &quot;completion&quot;: &quot;&lt;ideal generated text&gt;&quot;}
	// {&quot;prompt&quot;: &quot;&lt;prompt text&gt;&quot;, &quot;completion&quot;: &quot;&lt;ideal generated text&gt;&quot;}

	// chat models are trained using the following file format:
	// {&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Marv is a factual chatbot that is also sarcastic.&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What&#039;s the capital of France?&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Paris, as if everyone doesn&#039;t know that already.&quot;}]}
	// {&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Marv is a factual chatbot that is also sarcastic.&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Who wrote &#039;Romeo and Juliet&#039;?&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Oh, just some guy named William Shakespeare. Ever heard of him?&quot;}]}
	// {&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Marv is a factual chatbot that is also sarcastic.&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;How far is the Moon from Earth?&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Around 384,400 kilometers. Give or take a few, like that really matters.&quot;}]}

	// you can use openai cli tool to validate the data
	// For more info - https://platform.openai.com/docs/guides/fine-tuning

	file, err := client.CreateFile(ctx, openai.FileRequest{
		FilePath: &quot;training_prepared.jsonl&quot;,
		Purpose:  &quot;fine-tune&quot;,
	})
	if err != nil {
		fmt.Printf(&quot;Upload JSONL file error: %v\n&quot;, err)
		return
	}

	// create a fine tuning job
	// Streams events until the job is done (this often takes minutes, but can take hours if there are many jobs in the queue or your dataset is large)
	// use below get method to know the status of your model
	fineTuningJob, err := client.CreateFineTuningJob(ctx, openai.FineTuningJobRequest{
		TrainingFile: file.ID,
		Model:        &quot;davinci-002&quot;, // gpt-3.5-turbo-0613, babbage-002.
	})
	if err != nil {
		fmt.Printf(&quot;Creating new fine tune model error: %v\n&quot;, err)
		return
	}

	fineTuningJob, err = client.RetrieveFineTuningJob(ctx, fineTuningJob.ID)
	if err != nil {
		fmt.Printf(&quot;Getting fine tune model error: %v\n&quot;, err)
		return
	}
	fmt.Println(fineTuningJob.FineTunedModel)

	// once the status of fineTuningJob is `succeeded`, you can use your fine tune model in Completion Request or Chat Completion Request

	// resp, err := client.CreateCompletion(ctx, openai.CompletionRequest{
	//	 Model:  fineTuningJob.FineTunedModel,
	//	 Prompt: &quot;your prompt&quot;,
	// })
	// if err != nil {
	//	 fmt.Printf(&quot;Create completion error %v\n&quot;, err)
	//	 return
	// }
	//
	// fmt.Println(resp.Choices[0].Text)
}
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Structured Outputs&lt;/summary&gt;

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;log&quot;

	&quot;github.com/sashabaranov/go-openai&quot;
	&quot;github.com/sashabaranov/go-openai/jsonschema&quot;
)

func main() {
	client := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	type Result struct {
		Steps []struct {
			Explanation string `json:&quot;explanation&quot;`
			Output      string `json:&quot;output&quot;`
		} `json:&quot;steps&quot;`
		FinalAnswer string `json:&quot;final_answer&quot;`
	}
	var result Result
	schema, err := jsonschema.GenerateSchemaForType(result)
	if err != nil {
		log.Fatalf(&quot;GenerateSchemaForType error: %v&quot;, err)
	}
	resp, err := client.CreateChatCompletion(ctx, openai.ChatCompletionRequest{
		Model: openai.GPT4oMini,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleSystem,
				Con

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[openfga/openfga]]></title>
            <link>https://github.com/openfga/openfga</link>
            <guid>https://github.com/openfga/openfga</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[A high performance and flexible authorization/permission engine built for developers and inspired by Google Zanzibar]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openfga/openfga">openfga/openfga</a></h1>
            <p>A high performance and flexible authorization/permission engine built for developers and inspired by Google Zanzibar</p>
            <p>Language: Go</p>
            <p>Stars: 4,551</p>
            <p>Forks: 332</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![OpenFGA Logo](./openfga-logo.png)
# OpenFGA

[![Join our community](https://img.shields.io/badge/slack-cncf_%23openfga-40abb8.svg?logo=slack)](https://openfga.dev/community)
[![DeepWiki](https://img.shields.io/badge/DeepWiki-openfga%2Fopenfga-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/openfga/openfga)
[![Go Reference](https://pkg.go.dev/badge/github.com/openfga/openfga.svg)](https://pkg.go.dev/github.com/openfga/openfga)
![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/openfga/openfga?sort=semver&amp;color=green)
[![Docker Pulls](https://img.shields.io/docker/pulls/openfga/openfga)](https://hub.docker.com/r/openfga/openfga/tags)
[![Codecov](https://img.shields.io/codecov/c/github/openfga/openfga)](https://app.codecov.io/gh/openfga/openfga)
[![Go Report](https://goreportcard.com/badge/github.com/openfga/openfga)](https://goreportcard.com/report/github.com/openfga/openfga)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6374/badge)](https://bestpractices.coreinfrastructure.org/projects/6374)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fopenfga%2Fopenfga.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fopenfga%2Fopenfga?ref=badge_shield)
[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/openfga)](https://artifacthub.io/packages/helm/openfga/openfga)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/openfga/openfga/badge)](https://securityscorecards.dev/viewer/?uri=github.com/openfga/openfga)
[![SLSA 3](https://slsa.dev/images/gh-badge-level3.svg)](https://slsa.dev)

&lt;/div&gt;

---

**OpenFGA** is a high-performance, flexible authorization/permission engine inspired by [Google Zanzibar](https://research.google/pubs/pub48190/).
It helps developers easily model and enforce fine-grained access control in their applications.

## Highlights

- ⚡ High-performance, developer-friendly APIs (HTTP &amp; gRPC)
- 🔌 Flexible storage backends (In-Memory, PostgreSQL, MySQL, SQLite beta)
- 🧰 SDKs for [Java](https://central.sonatype.com/artifact/dev.openfga/openfga-sdk), [Node.js](https://www.npmjs.com/package/@openfga/sdk), [Go](https://github.com/openfga/go-sdk), [Python](https://github.com/openfga/python-sdk), [.NET](https://www.nuget.org/packages/OpenFga.Sdk)
- 🌐  Several additional SDKs and tools [contributed by the community](https://github.com/openfga/community#community-projects)
- 🧪 [CLI](https://github.com/openfga/cli) for interacting with an OpenFGA server and [testing authorization models](https://openfga.dev/docs/modeling/testing)
- 🌿 [Terraform Provider](https://github.com/openfga/terraform-provider-openfga) for configuring OpenFGA servers as code
- 🎮 [Playground](https://openfga.dev/docs/getting-started/setup-openfga/playground) for modeling and testing
- 🛠 Can also be embedded as a [Go library](https://pkg.go.dev/github.com/openfga/openfga/pkg/server#example-NewServerWithOpts)
- 🤝 Adopted by [Auth0](https://fga.dev), [Grafana Labs](https://grafana.com/), [Canonical](https://canonical.com/), [Docker](https://docker.com),  [Agicap](https://agicap.com), [Read.AI](https://read.ai) and [others](https://github.com/openfga/community/blob/main/ADOPTERS.md)

---

## Table of Contents
- [Quickstart](#quickstart)
- [Installation](#installation)
    - [Docker](#docker)
    - [Docker Compose](#docker-compose)
    - [Homebrew](#homebrew)
    - [Precompiled Binaries](#precompiled-binaries)
    - [Build from Source](#build-from-source)
    - [Verify Installation](#verify-installation)
- [Playground](#playground)
- [Next Steps](#next-steps)
- [Limitations](#limitations)
- [Production Readiness](#production-readiness)
- [Contributing &amp; Community](#contributing--community)

---

## Quickstart

&gt; [!IMPORTANT]  
&gt; The following steps are meant for quick local setup and evaluation.  
&gt; When using the default **in-memory storage engine**, data is ephemeral and will be discarded once the service stops.
&gt;
&gt; For [details on configuring](https://openfga.dev/docs/getting-started/setup-openfga/configure-openfga) storage 
&gt; backends, tuning performance, and deploying OpenFGA securely in production-ready environments, refer to the 
&gt; documentation: [Running in Production](https://openfga.dev/docs/getting-started/running-in-production).


Run OpenFGA with in-memory storage (⚠️ **not for production**):

```shell
docker run -p 8080:8080 -p 3000:3000 openfga/openfga run
```

Once running, create a store:

```shell
curl -X POST &#039;localhost:8080/stores&#039; \
  --header &#039;Content-Type: application/json&#039; \
  --data-raw &#039;{&quot;name&quot;: &quot;openfga-demo&quot;}&#039;
```

## Installation

### Docker

OpenFGA is available on [Docker Hub](https://hub.docker.com/r/openfga/openfga), so you can quickly start it using the
in-memory datastore by running the following commands:

```shell
docker pull openfga/openfga
docker run -p 8080:8080 -p 3000:3000 openfga/openfga run
```

### Docker Compose

[`docker-compose.yaml`](./docker-compose.yaml) provides an example of how to launch OpenFGA with Postgres using `docker compose`.

```shell
curl -LO https://openfga.dev/docker-compose.yaml
docker compose up
```

### Homebrew

If you are a [Homebrew](https://brew.sh/) user, you can install [OpenFGA](https://formulae.brew.sh/formula/openfga) with the following command:

```shell
brew install openfga
```

### Precompiled Binaries

Download your platform&#039;s [latest release](https://github.com/openfga/openfga/releases/latest) and extract it.
Then run the binary with the command:

```shell
./openfga run
```

### Build from Source

&gt; [!NOTE]  
&gt; Make sure you have the latest version of Go installed. See the [Go downloads](https://go.dev/dl/) page.

#### `go install`

```shell
export PATH=$PATH:$(go env GOBIN) # make sure $GOBIN is on your $PATH
go install github.com/openfga/openfga/cmd/openfga
openfga run
```

#### `go build`

```shell
git clone https://github.com/openfga/openfga.git &amp;&amp; cd openfga
go build -o ./openfga ./cmd/openfga
./openfga run
```

### Verify Installation

Now that you have [installed](#installation) OpenFGA, you can test your installation by [creating an OpenFGA Store](https://openfga.dev/docs/getting-started/create-store).

```shell
curl -X POST &#039;localhost:8080/stores&#039; \
  --header &#039;Content-Type: application/json&#039; \
  --data-raw &#039;{&quot;name&quot;: &quot;openfga-demo&quot;}&#039;
```

If everything is running correctly, you should get a response with information about the newly created store, for example:

```json
{
  &quot;id&quot;: &quot;01G3EMTKQRKJ93PFVDA1SJHWD2&quot;,
  &quot;name&quot;: &quot;openfga-demo&quot;,
  &quot;created_at&quot;: &quot;2022-05-19T17:11:12.888680Z&quot;,
  &quot;updated_at&quot;: &quot;2022-05-19T17:11:12.888680Z&quot;
}
```

## Playground

The Playground lets you model, visualize, and test authorization setups.
By default, it’s available at: [http://localhost:3000/playground](http://localhost:3000/playground)

&gt; [!NOTE]  
&gt; The Playground is intended for **local development only**.  
&gt; It can currently only be configured to connect to an OpenFGA server running on `localhost`.

Disable it with:

```shell
./openfga run --playground-enabled=false
```

Change port:

```shell
./openfga run --playground-enabled --playground-port 3001
```

&gt; [!TIP]
&gt; The `OPENFGA_HTTP_ADDR` environment variable can be used to configure the address at which the Playground expects the OpenFGA server to be.
&gt;
&gt; For example:
&gt;
&gt; ```shell
&gt; docker run -e OPENFGA_PLAYGROUND_ENABLED=true \
&gt; -e OPENFGA_HTTP_ADDR=0.0.0.0:4000 \
&gt; -p 4000:4000 -p 3000:3000 openfga/openfga run
&gt; ```
&gt;
&gt; This starts OpenFGA on port 4000 and configures the Playground accordingly.

## Next Steps

Take a look at examples of how to:

- [Write an Authorization Model](https://openfga.dev/api/service#/Authorization%20Models/WriteAuthorizationModel)
- [Write Relationship Tuples](https://openfga.dev/api/service#/Relationship%20Tuples/Write)
- [Perform Authorization Checks](https://openfga.dev/api/service#/Relationship%20Queries/Check)
- [Add Authentication to your OpenFGA server](https://openfga.dev/docs/getting-started/setup-openfga/docker#configuring-authentication)

📚 Explore the [Documentation](https://openfga.dev/) and [API Reference](https://openfga.dev/api/service).

## Limitations

### MySQL Storage engine

The MySQL storage engine has stricter length limits on tuple properties than other backends. See [docs](https://openfga.dev/docs/getting-started/setup-openfga/docker#configuring-data-storage).

💡 OpenFGA’s MySQL adapter was contributed by @twintag — thank you!

## Production Readiness

- ✅ Used in production by [Auth0 FGA](https://auth0.com/fine-grained-authorization) since December 2021
- ⚠️ Memory storage adapter is **for development only**
- 🗄 Supported storage: PostgreSQL 14+, MySQL 8, SQLite (beta)
- 📘 See [Running in Production](https://openfga.dev/docs/best-practices/running-in-production)

The OpenFGA team treats **production-impacting issues with highest priority**.

See organizations using OpenFGA in production: [ADOPTERS.md](https://github.com/openfga/community/blob/main/ADOPTERS.md).
If your organization is using OpenFGA, please consider adding it to the list.

## Contributing &amp; Community

We welcome contributions and community participation.

- 🤝 See [CONTRIBUTING](https://github.com/openfga/.github/blob/main/CONTRIBUTING.md)
- 🗓 [Monthly Community Meetings](https://github.com/openfga/community/blob/main/community-meetings.md)
- 💬 Join us on [Slack](https://openfga.dev/docs/community)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[vllm-project/semantic-router]]></title>
            <link>https://github.com/vllm-project/semantic-router</link>
            <guid>https://github.com/vllm-project/semantic-router</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[Intelligent Router for Mixture-of-Models]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vllm-project/semantic-router">vllm-project/semantic-router</a></h1>
            <p>Intelligent Router for Mixture-of-Models</p>
            <p>Language: Go</p>
            <p>Stars: 2,434</p>
            <p>Forks: 313</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;website/static/img/code.png&quot; alt=&quot;vLLM Semantic Router&quot; width=&quot;100%&quot;/&gt;

[![Documentation](https://img.shields.io/badge/docs-read%20the%20docs-blue)](https://vllm-semantic-router.com)
[![Hugging Face](https://img.shields.io/badge/🤗%20Hugging%20Face-Community-yellow)](https://huggingface.co/LLM-Semantic-Router)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![Crates.io](https://img.shields.io/crates/v/candle-semantic-router.svg)](https://crates.io/crates/candle-semantic-router)
![Test And Build](https://github.com/vllm-project/semantic-router/workflows/Test%20And%20Build/badge.svg)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/vllm-project/semantic-router)

**📚 [Complete Documentation](https://vllm-semantic-router.com) | 🚀 [Quick Start](https://vllm-semantic-router.com/docs/installation) | 📣 [Blog](https://vllm-semantic-router.com/blog/) | 📖 [Publications](https://vllm-semantic-router.com/publications/)**

&lt;/div&gt;

---

*Latest News* 🔥

- [2025/12/15] New Blog: [Token-Level Truth: Real-Time Hallucination Detection for Production LLMs](https://blog.vllm.ai/2025/12/14/halugate.html) 🚪
- [2025/11/19] New Blog: [Signal-Decision Driven Architecture: Reshaping Semantic Routing at Scale](https://blog.vllm.ai/2025/11/19/signal-decision.html) 🧠
- [2025/11/03] **Our paper** [Category-Aware Semantic Caching for Heterogeneous LLM Workloads](https://arxiv.org/abs/2510.26835) published 📝
- [2025/10/21] We announced the [2025 Q4 Roadmap: Journey to Iris](https://vllm-semantic-router.com/blog/q4-roadmap-iris) 📅.
- [2025/10/12] **Our paper** [When to Reason: Semantic Router for vLLM](https://arxiv.org/abs/2510.08731) accepted by NeurIPS 2025 MLForSys 🧠.
- [2025/10/08] We announced the integration with [vLLM Production Stack](https://github.com/vllm-project/production-stack) Team 👋.
- [2025/10/01] We supported to deploy on [Kubernetes](https://vllm-semantic-router.com/docs/installation/k8s/ai-gateway) 🌊.
- [2025/09/01] We released the project officially: [vLLM Semantic Router: Next Phase in LLM inference](https://blog.vllm.ai/2025/09/11/semantic-router.html) 🚀.

---

## Innovations ✨

![architecture](./website/static/img/architecture.png)

### Intelligent Routing 🧠

#### Auto-Selection of Models and LoRA Adapters

A **Mixture-of-Models** (MoM) router that intelligently directs OpenAI API requests to the most suitable models or LoRA adapters from a defined pool based on **Semantic Understanding** of the request&#039;s intent (Complexity, Task, Tools).

![mom-overview](./website/static/img/mom-overview.png)

Conceptually similar to Mixture-of-Experts (MoE) which lives *within* a model, this system selects the best *entire model* for the nature of the task.

As such, the overall inference accuracy is improved by using a pool of models that are better suited for different types of tasks:

![Model Accuracy](./website/static/img/category_accuracies.png)

The router is implemented in two ways:

- Golang (with Rust FFI based on the [candle](https://github.com/huggingface/candle) rust ML framework)
- Python
Benchmarking will be conducted to determine the best implementation.

#### Request Flow

![architecture](./website/static/img/flow.png)

#### Auto-Selection of Tools

Select the tools to use based on the prompt, avoiding the use of tools that are not relevant to the prompt so as to reduce the number of prompt tokens and improve tool selection accuracy by the LLM.

#### Domain Aware System Prompts

Automatically inject specialized system prompts based on query classification, ensuring optimal model behavior for different domains (math, coding, business, etc.) without manual prompt engineering.

#### Domain Aware Similarity Caching ⚡️

Cache the semantic representation of the prompt so as to reduce the number of prompt tokens and improve the overall inference latency.

### Enterprise Security 🔒

#### PII detection

Detect PII in the prompt, avoiding sending PII to the LLM so as to protect the privacy of the user.

#### Prompt guard

Detect if the prompt is a jailbreak prompt, avoiding sending jailbreak prompts to the LLM so as to prevent the LLM from misbehaving. Can be configured globally or at the category level for fine-grained security control.

## Quick Start 🚀

Get up and running in seconds with our interactive setup script:

```bash
bash ./scripts/quickstart.sh
```

This command will:

- 🔍 Check all prerequisites automatically
- 📦 Install HuggingFace CLI if needed
- 📥 Download all required AI models (~1.5GB)
- 🐳 Start all Docker services
- ⏳ Wait for services to become healthy
- 🌐 Show you all the endpoints and next steps

For detailed installation and configuration instructions, see the [Complete Documentation](https://vllm-semantic-router.com/docs/installation/).

## Documentation 📖

For comprehensive documentation including detailed setup instructions, architecture guides, and API references, visit:

**👉 [Complete Documentation at Read the Docs](https://vllm-semantic-router.com/)**

The documentation includes:

- **[Installation Guide](https://vllm-semantic-router.com/docs/installation/)** - Complete setup instructions
- **[System Architecture](https://vllm-semantic-router.com/docs/overview/architecture/system-architecture/)** - Technical deep dive
- **[Model Training](https://vllm-semantic-router.com/docs/training/training-overview/)** - How classification models work
- **[API Reference](https://vllm-semantic-router.com/docs/api/router/)** - Complete API documentation
- **[Dashboard](https://vllm-semantic-router.com/docs/overview/dashboard)** - vLLM Semantic Router Dashboard

## Community 👋

For questions, feedback, or to contribute, please join `#semantic-router` channel in vLLM Slack.

### Community Meetings 📅

We host bi-weekly community meetings to sync up with contributors across different time zones:

- **First Tuesday of the month**: 9:00-10:00 AM EST (accommodates US EST, EU, and Asia Pacific contributors)
  - [Zoom Link](https://us05web.zoom.us/j/84122485631?pwd=BB88v03mMNLVHn60YzVk4PihuqBV9d.1)
  - [Google Calendar Invite](https://us05web.zoom.us/meeting/tZAsdeuspj4sGdVraOOR4UaXSstrH2jjPYFq/calendar/google/add?meetingMasterEventId=4jjzUKSLSLiBHtIKZpGc3g)
  - [ics file](https://drive.google.com/file/d/15wO8cg0ZjNxdr8OtGiZyAgkSS8_Wry0J/view?usp=sharing)
- **Third Tuesday of the month**: 1:00-2:00 PM EST (accommodates US EST and California contributors)
  - [Zoom Link](https://us06web.zoom.us/j/86871492845?pwd=LcTtXm9gtGu23JeWqXxbnLLCCvbumB.1)
  - [Google Calendar Invite](https://us05web.zoom.us/meeting/tZIlcOispzkiHtH2dlkWlLym68bEqvuf3MU5/calendar/google/add?meetingMasterEventId=PqWz2vk7TOCszPXqconGAA)
  - [ics file](https://drive.google.com/file/d/1T54mwYpXXoV9QfR76I56BFBPNbykSsTw/view?usp=sharing)
- Meeting Recordings: [YouTube](https://www.youtube.com/@vLLMSemanticRouter/videos)

Join us to discuss the latest developments, share ideas, and collaborate on the project!

## Citation

If you find Semantic Router helpful in your research or projects, please consider citing it:

```
@misc{semanticrouter2025,
  title={vLLM Semantic Router},
  author={vLLM Semantic Router Team},
  year={2025},
  howpublished={\url{https://github.com/vllm-project/semantic-router}},
}
```

## Star History 🔥

We opened the project at Aug 31, 2025. We love open source  and collaboration ❤️

[![Star History Chart](https://api.star-history.com/svg?repos=vllm-project/semantic-router&amp;type=Date)](https://www.star-history.com/#vllm-project/semantic-router&amp;Date)

## Sponsors 👋

We are grateful to our sponsors who support us:

---

[**AMD**](https://www.amd.com) provides us with GPU resources and [ROCm™](https://www.amd.com/en/products/software/rocm.html) Software for training and researching the frontier router models, enhancing e2e testing, and building online models playground.

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.amd.com&quot;&gt;
  &lt;img src=&quot;website/static/img/amd-logo.svg&quot; alt=&quot;AMD&quot; width=&quot;40%&quot;/&gt;
&lt;/a&gt;
&lt;/div&gt;

---
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[expr-lang/expr]]></title>
            <link>https://github.com/expr-lang/expr</link>
            <guid>https://github.com/expr-lang/expr</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[Expression language and expression evaluation for Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/expr-lang/expr">expr-lang/expr</a></h1>
            <p>Expression language and expression evaluation for Go</p>
            <p>Language: Go</p>
            <p>Stars: 7,511</p>
            <p>Forks: 473</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;&lt;a href=&quot;https://expr-lang.org&quot;&gt;&lt;img src=&quot;https://expr-lang.org/img/logo.png&quot; alt=&quot;Zx logo&quot; height=&quot;48&quot;align=&quot;right&quot;&gt;&lt;/a&gt; Expr&lt;/h1&gt;

&gt; [!IMPORTANT]
&gt; The repository [github.com/antonmedv/expr](https://github.com/antonmedv/expr) moved to [github.com/**expr-lang**/expr](https://github.com/expr-lang/expr).

[![test](https://github.com/expr-lang/expr/actions/workflows/test.yml/badge.svg)](https://github.com/expr-lang/expr/actions/workflows/test.yml) 
[![Go Report Card](https://goreportcard.com/badge/github.com/expr-lang/expr)](https://goreportcard.com/report/github.com/expr-lang/expr) 
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/expr.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:expr)
[![GoDoc](https://godoc.org/github.com/expr-lang/expr?status.svg)](https://godoc.org/github.com/expr-lang/expr)

**Expr** is a Go-centric expression language designed to deliver dynamic configurations with unparalleled accuracy, safety, and speed. 
**Expr** combines simple [syntax](https://expr-lang.org/docs/language-definition) with powerful features for ease of use:

```js
// Allow only admins and moderators to moderate comments.
user.Group in [&quot;admin&quot;, &quot;moderator&quot;] || user.Id == comment.UserId
```

```js
// Determine whether the request is in the permitted time window.
request.Time - resource.Age &lt; duration(&quot;24h&quot;)
```

```js
// Ensure all tweets are less than 240 characters.
all(tweets, len(.Content) &lt;= 240)
```

## Features

**Expr** is a safe, fast, and intuitive expression evaluator optimized for the Go language. 
Here are its standout features:

### Safety and Isolation
* **Memory-Safe**: Expr is designed with a focus on safety, ensuring that programs do not access unrelated memory or introduce memory vulnerabilities.
* **Side-Effect-Free**: Expressions evaluated in Expr only compute outputs from their inputs, ensuring no side-effects that can change state or produce unintended results.
* **Always Terminating**: Expr is designed to prevent infinite loops, ensuring that every program will conclude in a reasonable amount of time.

### Go Integration
* **Seamless with Go**: Integrate Expr into your Go projects without the need to redefine types.

### Static Typing
* Ensures type correctness and prevents runtime type errors.
  ```go
  out, err := expr.Compile(`name + age`)
  // err: invalid operation + (mismatched types string and int)
  // | name + age
  // | .....^
  ```

### User-Friendly
* Provides user-friendly error messages to assist with debugging and development.

### Flexibility and Utility
* **Rich Operators**: Offers a reasonable set of basic operators for a variety of applications.
* **Built-in Functions**: Functions like `all`, `none`, `any`, `one`, `filter`, and `map` are provided out-of-the-box.

### Performance
* **Optimized for Speed**: Expr stands out in its performance, utilizing an optimizing compiler and a bytecode virtual machine. Check out these [benchmarks](https://github.com/antonmedv/golang-expression-evaluation-comparison#readme) for more details.

## Install

```
go get github.com/expr-lang/expr
```

## Documentation

* See [Getting Started](https://expr-lang.org/docs/Getting-Started) page for developer documentation.
* See [Language Definition](https://expr-lang.org/docs/language-definition) page to learn the syntax.

## Examples

[Play Online](https://go.dev/play/p/XCoNXEjm3TS)

```go
package main

import (
	&quot;fmt&quot;
	&quot;github.com/expr-lang/expr&quot;
)

func main() {
	env := map[string]interface{}{
		&quot;greet&quot;:   &quot;Hello, %v!&quot;,
		&quot;names&quot;:   []string{&quot;world&quot;, &quot;you&quot;},
		&quot;sprintf&quot;: fmt.Sprintf,
	}

	code := `sprintf(greet, names[0])`

	program, err := expr.Compile(code, expr.Env(env))
	if err != nil {
		panic(err)
	}

	output, err := expr.Run(program, env)
	if err != nil {
		panic(err)
	}

	fmt.Println(output)
}
```

[Play Online](https://go.dev/play/p/tz-ZneBfSuw)

```go
package main

import (
	&quot;fmt&quot;
	&quot;github.com/expr-lang/expr&quot;
)

type Tweet struct {
	Len int
}

type Env struct {
	Tweets []Tweet
}

func main() {
	code := `all(Tweets, {.Len &lt;= 240})`

	program, err := expr.Compile(code, expr.Env(Env{}))
	if err != nil {
		panic(err)
	}

	env := Env{
		Tweets: []Tweet{{42}, {98}, {69}},
	}
	output, err := expr.Run(program, env)
	if err != nil {
		panic(err)
	}

	fmt.Println(output)
}
```

## Who uses Expr?

* [Google](https://google.com) uses Expr as one of its expression languages on the [Google Cloud Platform](https://cloud.google.com).
* [Uber](https://uber.com) uses Expr to allow customization of its Uber Eats marketplace.
* [GoDaddy](https://godaddy.com) employs Expr for the customization of its GoDaddy Pro product.
* [ByteDance](https://bytedance.com) incorporates Expr into its internal business rule engine.
* [Aviasales](https://aviasales.ru) utilizes Expr as a business rule engine for its flight search engine.
* [Alibaba](https://alibaba.com) uses Expr in a web framework for building recommendation services.
* [Argo](https://argoproj.github.io) integrates Expr into Argo Rollouts and Argo Workflows for Kubernetes.
* [Wish.com](https://www.wish.com) employs Expr in its decision-making rule engine for the Wish Assistant.
* [OpenTelemetry](https://opentelemetry.io) integrates Expr into the OpenTelemetry Collector.
* [Philips Labs](https://github.com/philips-labs/tabia) employs Expr in Tabia, a tool designed to collect insights on their code bases.
* [CrowdSec](https://crowdsec.net) incorporates Expr into its security automation tool.
* [CoreDNS](https://coredns.io) uses Expr in CoreDNS, which is a DNS server.
* [qiniu](https://www.qiniu.com) implements Expr in its trade systems.
* [Junglee Games](https://www.jungleegames.com/) uses Expr for its in-house marketing retention tool, Project Audience.
* [Faceit](https://www.faceit.com) uses Expr to enhance customization of its eSports matchmaking algorithm.
* [Chaos Mesh](https://chaos-mesh.org) incorporates Expr into Chaos Mesh, a cloud-native Chaos Engineering platform.
* [Visually.io](https://visually.io) employs Expr as a business rule engine for its personalization targeting algorithm.
* [Akvorado](https://github.com/akvorado/akvorado) utilizes Expr to classify exporters and interfaces in network flows.
* [keda.sh](https://keda.sh) uses Expr to allow customization of its Kubernetes-based event-driven autoscaling.
* [Span Digital](https://spandigital.com/) uses Expr in its Knowledge Management products.
* [Xiaohongshu](https://www.xiaohongshu.com/) combining yaml with Expr for dynamically policies delivery.
* [Melrōse](https://melrōse.org) uses Expr to implement its music programming language.
* [Tork](https://www.tork.run/) integrates Expr into its workflow execution.
* [Critical Moments](https://criticalmoments.io) uses Expr for its mobile realtime conditional targeting system.
* [WoodpeckerCI](https://woodpecker-ci.org) uses Expr for [filtering workflows/steps](https://woodpecker-ci.org/docs/usage/workflow-syntax#evaluate).
* [FastSchema](https://github.com/fastschema/fastschema) - A BaaS leveraging Expr for its customizable and dynamic Access Control system.
* [WunderGraph Cosmo](https://github.com/wundergraph/cosmo) - GraphQL Federeration Router uses Expr to customize Middleware behaviour
* [SOLO](https://solo.one) uses Expr interally to allow dynamic code execution with custom defined functions.
* [Naoma.AI](https://www.naoma.ai) uses Expr as a part of its call scoring engine.

[Add your company too](https://github.com/expr-lang/expr/edit/master/README.md)

## License

[MIT](https://github.com/expr-lang/expr/blob/master/LICENSE)

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://expr-lang.org/img/gopher-small.png&quot; width=&quot;150&quot; /&gt;&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[shopspring/decimal]]></title>
            <link>https://github.com/shopspring/decimal</link>
            <guid>https://github.com/shopspring/decimal</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[Arbitrary-precision fixed-point decimal numbers in Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/shopspring/decimal">shopspring/decimal</a></h1>
            <p>Arbitrary-precision fixed-point decimal numbers in Go</p>
            <p>Language: Go</p>
            <p>Stars: 7,136</p>
            <p>Forks: 651</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># decimal

[![ci](https://github.com/shopspring/decimal/actions/workflows/ci.yml/badge.svg?branch=master)](https://github.com/shopspring/decimal/actions/workflows/ci.yml)
[![GoDoc](https://godoc.org/github.com/shopspring/decimal?status.svg)](https://godoc.org/github.com/shopspring/decimal) 
[![Go Report Card](https://goreportcard.com/badge/github.com/shopspring/decimal)](https://goreportcard.com/report/github.com/shopspring/decimal)

Arbitrary-precision fixed-point decimal numbers in go.

_Note:_ Decimal library can &quot;only&quot; represent numbers with a maximum of 2^31 digits after the decimal point.

## Features

 * The zero-value is 0, and is safe to use without initialization
 * Addition, subtraction, multiplication with no loss of precision
 * Division with specified precision
 * Database/sql serialization/deserialization
 * JSON and XML serialization/deserialization

## Install

Run `go get github.com/shopspring/decimal`

## Requirements 

Decimal library requires Go version `&gt;=1.10`

## Documentation

http://godoc.org/github.com/shopspring/decimal


## Usage

```go
package main

import (
	&quot;fmt&quot;
	&quot;github.com/shopspring/decimal&quot;
)

func main() {
	price, err := decimal.NewFromString(&quot;136.02&quot;)
	if err != nil {
		panic(err)
	}

	quantity := decimal.NewFromInt(3)

	fee, _ := decimal.NewFromString(&quot;.035&quot;)
	taxRate, _ := decimal.NewFromString(&quot;.08875&quot;)

	subtotal := price.Mul(quantity)

	preTax := subtotal.Mul(fee.Add(decimal.NewFromFloat(1)))

	total := preTax.Mul(taxRate.Add(decimal.NewFromFloat(1)))

	fmt.Println(&quot;Subtotal:&quot;, subtotal)                      // Subtotal: 408.06
	fmt.Println(&quot;Pre-tax:&quot;, preTax)                         // Pre-tax: 422.3421
	fmt.Println(&quot;Taxes:&quot;, total.Sub(preTax))                // Taxes: 37.482861375
	fmt.Println(&quot;Total:&quot;, total)                            // Total: 459.824961375
	fmt.Println(&quot;Tax rate:&quot;, total.Sub(preTax).Div(preTax)) // Tax rate: 0.08875
}
```

## Alternative libraries

When working with decimal numbers, you might face problems this library is not perfectly suited for. 
Fortunately, thanks to the wonderful community we have a dozen other libraries that you can choose from.  
Explore other alternatives to find the one that best fits your needs :)  

* [cockroachdb/apd](https://github.com/cockroachdb/apd) - arbitrary precision, mutable and rich API similar to `big.Int`, more performant than this library 
* [alpacahq/alpacadecimal](https://github.com/alpacahq/alpacadecimal) - high performance, low precision (12 digits), fully compatible API with this library 
* [govalues/decimal](https://github.com/govalues/decimal) - high performance, zero-allocation, low precision (19 digits)
* [greatcloak/decimal](https://github.com/greatcloak/decimal) - fork focusing on billing and e-commerce web application related use cases, includes out-of-the-box BSON marshaling support

## FAQ

#### Why don&#039;t you just use float64?

Because float64 (or any binary floating point type, actually) can&#039;t represent
numbers such as `0.1` exactly.

Consider this code: http://play.golang.org/p/TQBd4yJe6B You might expect that
it prints out `10`, but it actually prints `9.999999999999831`. Over time,
these small errors can really add up!

#### Why don&#039;t you just use big.Rat?

big.Rat is fine for representing rational numbers, but Decimal is better for
representing money. Why? Here&#039;s a (contrived) example:

Let&#039;s say you use big.Rat, and you have two numbers, x and y, both
representing 1/3, and you have `z = 1 - x - y = 1/3`. If you print each one
out, the string output has to stop somewhere (let&#039;s say it stops at 3 decimal
digits, for simplicity), so you&#039;ll get 0.333, 0.333, and 0.333. But where did
the other 0.001 go?

Here&#039;s the above example as code: http://play.golang.org/p/lCZZs0w9KE

With Decimal, the strings being printed out represent the number exactly. So,
if you have `x = y = 1/3` (with precision 3), they will actually be equal to
0.333, and when you do `z = 1 - x - y`, `z` will be equal to .334. No money is
unaccounted for!

You still have to be careful. If you want to split a number `N` 3 ways, you
can&#039;t just send `N/3` to three different people. You have to pick one to send
`N - (2/3*N)` to. That person will receive the fraction of a penny remainder.

But, it is much easier to be careful with Decimal than with big.Rat.

#### Why isn&#039;t the API similar to big.Int&#039;s?

big.Int&#039;s API is built to reduce the number of memory allocations for maximal
performance. This makes sense for its use-case, but the trade-off is that the
API is awkward and easy to misuse.

For example, to add two big.Ints, you do: `z := new(big.Int).Add(x, y)`. A
developer unfamiliar with this API might try to do `z := a.Add(a, b)`. This
modifies `a` and sets `z` as an alias for `a`, which they might not expect. It
also modifies any other aliases to `a`.

Here&#039;s an example of the subtle bugs you can introduce with big.Int&#039;s API:
https://play.golang.org/p/x2R_78pa8r

In contrast, it&#039;s difficult to make such mistakes with decimal. Decimals
behave like other go numbers types: even though `a = b` will not deep copy
`b` into `a`, it is impossible to modify a Decimal, since all Decimal methods
return new Decimals and do not modify the originals. The downside is that
this causes extra allocations, so Decimal is less performant.  My assumption
is that if you&#039;re using Decimals, you probably care more about correctness
than performance.

## License

The MIT License (MIT)

This is a heavily modified fork of [fpd.Decimal](https://github.com/oguzbilgic/fpd), which was also released under the MIT License.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[pion/webrtc]]></title>
            <link>https://github.com/pion/webrtc</link>
            <guid>https://github.com/pion/webrtc</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[Pure Go implementation of the WebRTC API]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pion/webrtc">pion/webrtc</a></h1>
            <p>Pure Go implementation of the WebRTC API</p>
            <p>Language: Go</p>
            <p>Stars: 15,805</p>
            <p>Forks: 1,802</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pion.ly&quot;&gt;&lt;img src=&quot;./.github/pion-gopher-webrtc.png&quot; alt=&quot;Pion WebRTC&quot; height=&quot;250px&quot;&gt;&lt;/a&gt;
  &lt;br&gt;
  Pion WebRTC
  &lt;br&gt;
&lt;/h1&gt;
&lt;h4 align=&quot;center&quot;&gt;A pure Go implementation of the WebRTC API&lt;/h4&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pion.ly&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/pion-webrtc-gray.svg?longCache=true&amp;colorB=brightgreen&quot; alt=&quot;Pion WebRTC&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://sourcegraph.com/github.com/pion/webrtc?badge&quot;&gt;&lt;img src=&quot;https://sourcegraph.com/github.com/pion/webrtc/-/badge.svg&quot; alt=&quot;Sourcegraph Widget&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/PngbdqpFbt&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/join-us%20on%20discord-gray.svg?longCache=true&amp;logo=discord&amp;colorB=brightblue&quot; alt=&quot;join us on Discord&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://bsky.app/profile/pion.ly&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/follow-us%20on%20bluesky-gray.svg?longCache=true&amp;logo=bluesky&amp;colorB=brightblue&quot; alt=&quot;Follow us on Bluesky&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/_pion?ref_src=twsrc%5Etfw&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/url.svg?label=Follow%20%40_pion&amp;style=social&amp;url=https%3A%2F%2Ftwitter.com%2F_pion&quot; alt=&quot;Twitter Widget&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/pion/awesome-pion&quot; alt=&quot;Awesome Pion&quot;&gt;&lt;img src=&quot;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg&quot;&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;img alt=&quot;GitHub Workflow Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/pion/webrtc/test.yaml&quot;&gt;
  &lt;a href=&quot;https://pkg.go.dev/github.com/pion/webrtc/v4&quot;&gt;&lt;img src=&quot;https://pkg.go.dev/badge/github.com/pion/webrtc/v4.svg&quot; alt=&quot;Go Reference&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/pion/webrtc&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/pion/webrtc/branch/master/graph/badge.svg&quot; alt=&quot;Coverage Status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/pion/webrtc/v4&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/pion/webrtc/v4&quot; alt=&quot;Go Report Card&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-yellow.svg&quot; alt=&quot;License: MIT&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;br&gt;

### New Release

Pion WebRTC v4.0.0 has been released! See the [release notes](https://github.com/pion/webrtc/wiki/Release-WebRTC@v4.0.0) to learn about new features and breaking changes.

If you aren&#039;t able to upgrade yet check the [tags](https://github.com/pion/webrtc/tags) for the latest `v3` release.

We would love your feedback! Please create GitHub issues or Join the [Discord](https://discord.gg/PngbdqpFbt) to follow development and speak with the maintainers.

-----

### Usage
[Go Modules](https://blog.golang.org/using-go-modules) are mandatory for using Pion WebRTC. So make sure you set `export GO111MODULE=on`, and explicitly specify `/v4` (or an earlier version) when importing.


**[example applications](examples/README.md)** contains code samples of common things people build with Pion WebRTC.

**[example-webrtc-applications](https://github.com/pion/example-webrtc-applications)** contains more full featured examples that use 3rd party libraries.

**[awesome-pion](https://github.com/pion/awesome-pion)** contains projects that have used Pion, and serve as real world examples of usage.

**[GoDoc](https://pkg.go.dev/github.com/pion/webrtc/v4)** is an auto generated API reference. All our Public APIs are commented.

**[FAQ](https://github.com/pion/webrtc/wiki/FAQ)** has answers to common questions. If you have a question not covered please ask in [Discord](https://discord.gg/PngbdqpFbt) we are always looking to expand it.

Now go build something awesome! Here are some **ideas** to get your creative juices flowing:
* Send a video file to multiple browser in real time for perfectly synchronized movie watching.
* Send a webcam on an embedded device to your browser with no additional server required!
* Securely send data between two servers, without using pub/sub.
* Record your webcam and do special effects server side.
* Build a conferencing application that processes audio/video and make decisions off of it.
* Remotely control a robots and stream its cameras in realtime.

### Need Help?
Check out [WebRTC for the Curious](https://webrtcforthecurious.com). A book about WebRTC in depth, not just about the APIs.
Learn the full details of ICE, SCTP, DTLS, SRTP, and how they work together to make up the WebRTC stack. This is also a great
resource if you are trying to debug. Learn the tools of the trade and how to approach WebRTC issues. This book is vendor
agnostic and will not have any Pion specific information.

Pion has an active community on [Discord](https://discord.gg/PngbdqpFbt). Please ask for help about anything, questions don&#039;t have to be Pion specific!
Come share your interesting project you are working on. We are here to support you.

One of the maintainers of Pion [Sean-Der](https://github.com/sean-der) is available to help. Schedule at [siobud.com/meeting](https://siobud.com/meeting)
He is available to talk about Pion or general WebRTC questions, feel free to reach out about anything!

### Features
#### PeerConnection API
* Go implementation of [webrtc-pc](https://w3c.github.io/webrtc-pc/) and [webrtc-stats](https://www.w3.org/TR/webrtc-stats/)
* DataChannels
* Send/Receive audio and video
* Renegotiation
* Plan-B and Unified Plan
* [SettingEngine](https://pkg.go.dev/github.com/pion/webrtc/v4#SettingEngine) for Pion specific extensions


#### Connectivity
* Full ICE Agent
* ICE Restart
* Trickle ICE
* STUN
* TURN (UDP, TCP, DTLS and TLS)
* mDNS candidates

#### DataChannels
* Ordered/Unordered
* Lossy/Lossless

#### Media
* API with direct RTP/RTCP access
* Opus, PCM, H264, VP8 and VP9 packetizer
* API also allows developer to pass their own packetizer
* IVF, Ogg, H264 and Matroska provided for easy sending and saving
* [getUserMedia](https://github.com/pion/mediadevices) implementation (Requires Cgo)
* Easy integration with x264, libvpx, GStreamer and ffmpeg.
* [Simulcast](https://github.com/pion/webrtc/tree/master/examples/simulcast)
* [SVC](https://github.com/pion/rtp/blob/master/codecs/vp9_packet.go#L138)
* [NACK](https://github.com/pion/interceptor/pull/4)
* [Sender/Receiver Reports](https://github.com/pion/interceptor/tree/master/pkg/report)
* [Transport Wide Congestion Control Feedback](https://github.com/pion/interceptor/tree/master/pkg/twcc)
* [Bandwidth Estimation](https://github.com/pion/webrtc/tree/master/examples/bandwidth-estimation-from-disk)

#### Security
* TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 and TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA for DTLS v1.2
* SRTP_AEAD_AES_256_GCM and SRTP_AES128_CM_HMAC_SHA1_80 for SRTP
* Hardware acceleration available for GCM suites

#### Pure Go
* No Cgo usage
* Wide platform support
  * Windows, macOS, Linux, FreeBSD
  * iOS, Android
  * [WASM](https://github.com/pion/webrtc/wiki/WebAssembly-Development-and-Testing) see [examples](examples/README.md#webassembly)
  *  386, amd64, arm, mips, ppc64
* Easy to build *Numbers generated on Intel(R) Core(TM) i5-2520M CPU @ 2.50GHz*
  * **Time to build examples/play-from-disk** - 0.66s user 0.20s system 306% cpu 0.279 total
  * **Time to run entire test suite** - 25.60s user 9.40s system 45% cpu 1:16.69 total
* Tools to measure performance [provided](https://github.com/pion/rtsp-bench)

### Roadmap
The library is in active development, please refer to the [roadmap](https://github.com/pion/webrtc/issues/9) to track our major milestones.
We also maintain a list of [Big Ideas](https://github.com/pion/webrtc/wiki/Big-Ideas) these are things we want to build but don&#039;t have a clear plan or the resources yet.
If you are looking to get involved this is a great place to get started! We would also love to hear your ideas! Even if you can&#039;t implement it yourself, it could inspire others.

### Sponsoring
Work on Pion&#039;s congestion control and bandwidth estimation was funded through the [User-Operated Internet](https://nlnet.nl/useroperated/) fund, a fund established by [NLnet](https://nlnet.nl/) made possible by financial support from the [PKT Community](https://pkt.cash/)/[The Network Steward](https://pkt.cash/network-steward) and stichting [Technology Commons Trust](https://technologycommons.org/).

### Community
Pion has an active community on the [Discord](https://discord.gg/PngbdqpFbt).

Follow the [Pion Bluesky](https://bsky.app/profile/pion.ly) or [Pion Twitter](https://twitter.com/_pion) for project updates and important WebRTC news.

We are always looking to support **your projects**. Please reach out if you have something to build!
If you need commercial support or don&#039;t want to use public methods you can contact us at [team@pion.ly](mailto:team@pion.ly)

### Contributing
Check out the [contributing wiki](https://github.com/pion/webrtc/wiki/Contributing) to join the group of amazing people making this project possible

### License
MIT License - see [LICENSE](LICENSE) for full text
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[volcano-sh/volcano]]></title>
            <link>https://github.com/volcano-sh/volcano</link>
            <guid>https://github.com/volcano-sh/volcano</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[A Cloud Native Batch System (Project under CNCF)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/volcano-sh/volcano">volcano-sh/volcano</a></h1>
            <p>A Cloud Native Batch System (Project under CNCF)</p>
            <p>Language: Go</p>
            <p>Stars: 5,164</p>
            <p>Forks: 1,231</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://volcano.sh/&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/volcano-sh/volcano/master/docs/images/volcano-horizontal-color.png&quot;/&gt;
&lt;/a&gt;

-------

[![Build Status](https://travis-ci.org/volcano-sh/volcano.svg?branch=master)](https://travis-ci.org/volcano-sh/volcano)
[![Go Report Card](https://goreportcard.com/badge/github.com/volcano-sh/volcano)](https://goreportcard.com/report/github.com/volcano-sh/volcano)
[![RepoSize](https://img.shields.io/github/repo-size/volcano-sh/volcano.svg)](https://github.com/volcano-sh/volcano)
[![Release](https://img.shields.io/github/release/volcano-sh/volcano.svg)](https://github.com/volcano-sh/volcano/releases)
[![LICENSE](https://img.shields.io/github/license/volcano-sh/volcano.svg)](https://github.com/volcano-sh/volcano/blob/master/LICENSE)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3012/badge)](https://bestpractices.coreinfrastructure.org/projects/3012)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/volcano-sh/volcano/badge)](https://scorecard.dev/viewer/?uri=github.com/volcano-sh/volcano)
[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Volcano%20Guru-006BFF)](https://gurubase.io/g/volcano)



[Volcano](https://volcano.sh/) is a Kubernetes-native batch scheduling system, extending and enhancing the capabilities of the standard kube-scheduler. It provides a comprehensive set of features specifically designed to manage and optimize various batch and elastic workloads, including Artificial Intelligence (AI) / machine learning (ML) / deep learning (DL), bioinformatics / genomics, and other &quot;Big Data&quot; applications.

These workloads commonly leverage AI, Big Data, and HPC frameworks such as Spark, Flink, Ray, TensorFlow, PyTorch, Argo, MindSpore, PaddlePaddle, Kubeflow, MPI, Horovod, MXNet, KubeGene, and others, with which Volcano offers robust integration.

Volcano incorporates over fifteen years of collective experience in operating diverse high-performance workloads at scale across multiple systems and platforms. It combines proven best practices and innovative concepts from the open-source community to deliver a powerful and flexible scheduling solution.

As of 2025, Volcano has seen widespread adoption across numerous industries globally, including Internet/Cloud, Finance, Manufacturing, and Medical sectors. Many organizations and institutions are not only end-users but also active contributors to the project. Hundreds of contributors actively participate in code commits, pull request reviews, issue discussions, documentation updates, and design proposals. We encourage your participation in the ongoing development and growth of the Volcano project.


&gt; [!NOTE]
&gt; the scheduler is built based on [kube-batch](https://github.com/kubernetes-sigs/kube-batch);
refer to [#241](https://github.com/volcano-sh/volcano/issues/241) and [#288](https://github.com/volcano-sh/volcano/pull/288) for more detail.

![cncf_logo](docs/images/cncf-logo.png)

Volcano is an incubating project of the [Cloud Native Computing Foundation](https://cncf.io/) (CNCF). Please consider joining the CNCF if you are an organization that wants to take an active role in supporting the growth and evolution of the cloud native ecosystem. 

## Overall Architecture

![volcano](docs/images/volcano-architecture.png)

## Talks

- [Intro: Kubernetes Batch Scheduling @ KubeCon 2019 EU](https://sched.co/MPi7)
- [Volcano 在 Kubernetes 中运行高性能作业实践 @ ArchSummit 2019](https://archsummit.infoq.cn/2019/shenzhen/presentation/1817)
- [Volcano：基于云原生的高密计算解决方案 @ Huawei Connection 2019](https://e.huawei.com/cn/material/event/HC/09099dce0070415e9f26ada51b2216d7)
- [Improving Performance of Deep Learning Workloads With Volcano @ KubeCon 2019 NA](https://sched.co/UaZi)
- [Batch Capability of Kubernetes Intro @ KubeCon 2019 NA](https://sched.co/Uajv)
- [Optimizing Knowledge Distillation Training With Volcano @ KubeCon 2021 EU](https://www.youtube.com/watch?v=cDPGmhVcj7Y&amp;t=143s)
- [Exploration About Mixing Technology of Online Services and Offline Jobs Based On Volcano @ KubeCon 2021 China](https://www.youtube.com/watch?v=daqkUlT5ReY)
- [Volcano - Cloud Native Batch System for AI, Big Data and HPC @ KubeCon 2022 EU](https://www.youtube.com/watch?v=wjy35HfIP_k)
- [How to Leverage Volcano to Improve the Resource Utilization of AI Pharmaceuticals, Autonomous Driving, and Smart Buildings @ KubeCon 2023 EU](https://www.youtube.com/watch?v=ujHDV5xteqU)
- [Run Your AI Workloads and Microservices on Kubernetes More Easily and Efficiently @ KubeCon 2023 China](https://www.youtube.com/watch?v=OO7zpyf7fgs)
- [Optimize LLM Workflows with Smart Infrastructure Enhanced by Volcano @ KubeCon 2024 China](https://www.youtube.com/watch?v=77Qn1-I-muQ)
- [How Volcano Enable Next Wave of Intelligent Applications @ KubeCon 2024 China](https://www.youtube.com/watch?v=IzR7zJQ8vMw)
- [Leverage Topology Modeling and Topology-Aware Scheduling to Accelerate LLM Training @ KubeCon 2024 China](https://www.youtube.com/watch?v=IB54LHQQ8lI)


## Ecosystem

- [Spark Operator](https://www.kubeflow.org/docs/components/spark-operator/user-guide/volcano-integration/)
- [Native Spark](https://spark.apache.org/docs/3.5.0/running-on-kubernetes.html#using-volcano-as-customized-scheduler-for-spark-on-kubernetes)
- [Flink](https://github.com/GoogleCloudPlatform/flink-on-k8s-operator/blob/master/docs/volcano_integration.md)
- [KubeRay](https://docs.ray.io/en/master/cluster/kubernetes/k8s-ecosystem/volcano.html)
- [PyTorch](https://github.com/volcano-sh/volcano/blob/master/docs/user-guide/how_to_use_pytorch_plugin.md)
- [TensorFlow](https://github.com/volcano-sh/volcano/tree/master/example/integrations/tensorflow)
- [kubeflow/training-operator](https://www.kubeflow.org/docs/components/training/user-guides/job-scheduling/)
- [kubeflow/arena](https://github.com/kubeflow/arena/blob/master/docs/training/volcanojob/volcanojob.md)
- [MPI](https://github.com/volcano-sh/volcano/tree/master/example/integrations/mpi)
- [Horovod](https://github.com/volcano-sh/volcano/blob/master/example/kubecon-2019-china/horovod-sample/lm-horovod-tf-mnist-v0.5.yaml)
- [PaddlePaddle](https://github.com/volcano-sh/volcano/tree/master/example/integrations/paddlepaddle)
- [Cromwell](https://github.com/broadinstitute/cromwell/blob/develop/docs/backends/Volcano.md)
- [MindSpore](https://github.com/volcano-sh/volcano/tree/master/example/MindSpore-example)
- [MXNet](https://github.com/volcano-sh/volcano/tree/master/example/integrations/mxnet/train)
- [Argo](https://github.com/volcano-sh/volcano/tree/master/example/integrations/argo)
- [KubeGene](https://github.com/volcano-sh/kubegene)

## Use Cases
- [Why Spark chooses Volcano as built-in batch scheduler on Kubernetes?](https://www.cncf.io/blog/2022/06/30/why-spark-chooses-volcano-as-built-in-batch-scheduler-on-kubernetes/)
- [ING Bank: How Volcano empowers its big data analytics platform](https://www.cncf.io/blog/2023/02/21/ing-bank-how-volcano-empowers-its-big-data-analytics-platform/)
- [Using Volcano as a custom scheduler for Apache Spark on Amazon EMR on EKS](https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/tutorial-volcano.html)
- [Deploy Azure Machine Learning extension on AKS or Arc Kubernetes cluster](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-kubernetes-extension?view=azureml-api-2&amp;tabs=deploy-extension-with-cli)
- [Practical Tips for Preventing GPU Fragmentation for Volcano Scheduler](https://developer.nvidia.com/blog/practical-tips-for-preventing-gpu-fragmentation-for-volcano-scheduler/)
- [Using Volcano in Large-Scale, Distributed Offline Computing](https://volcano.sh/en/blog/ruitian2-en/)
- [OpenI-Octopus: How to Avoid Resource Preemption in Kubernetes Clusters](https://volcano.sh/en/blog/pengcheng-en/)
- [How Does Volcano Empower a Content Recommendation Engine in Xiaohongshu](https://volcano.sh/en/blog/xiaohongshu-en/)
- [How Ruitian Used Volcano to Run Large-Scale Offline HPC Jobs](https://volcano.sh/en/blog/ruitian-en/)
- [Integrating Volcano into the Leinao Cloud OS](https://volcano.sh/en/blog/leinao-en/)
- [HPC on Volcano: How Containers Support HPC Applications in the Meteorological Industry](https://volcano.sh/en/blog/hpc-en/)
- [iQIYI:Volcano-based Cloud Native Migration Practices](https://volcano.sh/en/blog/aiqiyi-en/)
- [PaddlePaddle Distributed Training on Volcano](https://volcano.sh/en/blog/paddlepaddle-en/)

## Quick Start Guide

### Prerequisites

- Kubernetes 1.12+ with CRD support


You can try Volcano by one of the following two ways.

&gt; [!NOTE]
&gt; * For Kubernetes v1.17 and above, use CRDs under config/crd/bases (recommended)
&gt; * For Kubernetes v1.16 and below, use CRDs under config/crd/v1beta1 (deprecated)

### Install with YAML files

Install Volcano on an existing Kubernetes cluster. This way is both available for x86_64 and arm64 architecture.

```
kubectl apply -f https://raw.githubusercontent.com/volcano-sh/volcano/master/installer/volcano-development.yaml
```

Enjoy! Volcano will create the following resources in `volcano-system` namespace.


```
NAME                                       READY   STATUS      RESTARTS   AGE
pod/volcano-admission-5bd5756f79-dnr4l     1/1     Running     0          96s
pod/volcano-controllers-687948d9c8-nw4b4   1/1     Running     0          96s
pod/volcano-scheduler-94998fc64-4z8kh      1/1     Running     0          96s

NAME                                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/volcano-admission-service   ClusterIP   10.98.152.108   &lt;none&gt;        443/TCP   96s

NAME                                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/volcano-admission     1/1     1            1           96s
deployment.apps/volcano-controllers   1/1     1            1           96s
deployment.apps/volcano-scheduler     1/1     1            1           96s

NAME                                             DESIRED   CURRENT   READY   AGE
replicaset.apps/volcano-admission-5bd5756f79     1         1         1       96s
replicaset.apps/volcano-controllers-687948d9c8   1         1         1       96s
replicaset.apps/volcano-scheduler-94998fc64      1         1         1       96s

NAME                               COMPLETIONS   DURATION   AGE
job.batch/volcano-admission-init   1/1           48s        96s

```

### Install via helm

To install official release, please visit [helm-charts](https://github.com/volcano-sh/helm-charts) for details.

```bash
helm repo add volcano-sh https://volcano-sh.github.io/helm-charts
helm install volcano volcano-sh/volcano -n volcano-system --create-namespace
```

Install from source code for developers:

```bash
helm install volcano installer/helm/chart/volcano --namespace volcano-system --create-namespace

# list helm release
helm list -n volcano-system
```

### Install from code

If you don&#039;t have a kubernetes cluster, try one-click install from code base:

```bash
./hack/local-up-volcano.sh
```

This way is only available for x86_64 temporarily.

### Install volcano agent

Please follow the guide [Volcano Agent](https://volcano.sh/en/docs/colocation) to install volcano agent.

### Install monitoring system

If you want to get prometheus and grafana volcano dashboard after volcano installed, try following commands:

```bash
kubectl create -f installer/volcano-monitoring.yaml
```

### Install dashboard

Please follow the guide [Volcano Dashboard](https://github.com/volcano-sh/dashboard#volcano-dashboard) to install volcano dashboard.

## Kubernetes compatibility
|                       | Kubernetes 1.17 | Kubernetes 1.18 | Kubernetes 1.19 | Kubernetes 1.20 | Kubernetes 1.21 | Kubernetes 1.22 | Kubernetes 1.23 | Kubernetes 1.24 | Kubernetes 1.25 | Kubernetes 1.26 | Kubernetes 1.27 | Kubernetes 1.28 | Kubernetes 1.29 | Kubernetes 1.30 | Kubernetes 1.31 | Kubernetes 1.32 | Kubernetes 1.33 |
|-----------------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|------------------|------------------|------------------|------------------|
| Volcano v1.6          | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | -               | -               | -               | -               | -               | -               | -                | -                | -                | -                |
| Volcano v1.7          | -               | -               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | -               | -                | -                | -                | -                |
| Volcano v1.8          | -               | -               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | -               | -                | -                | -                | -                |
| Volcano v1.9          | -               | -               | -               | -               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | -                | -                | -                | -                |
| Volcano v1.10         | -               | -               | -               | -               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓                | -                | -                | -                |
| Volcano v1.11         | -               | -               | -               | -               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓                | ✓                | -                | -                |
| Volcano v1.12         | -               | -               | -               | -               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓                | ✓                | ✓                | -                |
| Volcano HEAD (master) | -               | -               | -               | -               | -               | -               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓               | ✓                | ✓                | ✓                | ✓                |

Key:
* `✓` Volcano and the Kubernetes version are exactly compatible.
* `+` Volcano has features or API objects that may not be present in the Kubernetes version.
* `-` The Kubernetes version has features or API objects that Volcano can&#039;t use.


## Citing Volcano

If Volcano helps your research, we appreciate your citations. Here is the BibTeX entry:

```bibtex
@misc{volcano2025,
  title={Volcano: A Cloud Native Batch System},
  author={Klaus Ma and Kevin Wang and others},
  year={2025},
  howpublished={\url{https://github.com/volcano-sh/volcano}},
}
```

## Meeting

Community weekly meeting for Asia: 15:00 - 16:00 (UTC+8) Friday. ([Convert to your timezone.](https://www.thetimezoneconverter.com/?t=10%3A00&amp;tz=GMT%2B8&amp;))

Community biweekly meeting for America: 08:30 - 09:30 (UTC-8) Thursday. ([Convert to your timezone.](https://www.thetimezoneconverter.com/?t=10%3A00&amp;tz=GMT%2B8&amp;))

Community meeting for Europe is ongoing on demand now. If you have some ideas or topics to discuss, please leave message
in the [slack](https://cloud-native.slack.com/archives/C011GJDQS0N). Maintainers will contact with you and book an open meeting for that.

Resources:
- [Meeting notes and agenda](https://docs.google.com/document/d/1YLbF8zjZBiR9PbXQPB22iuc_L0Oui5A1lddVfRnZrqs/edit)
- [Meeting link](https://zoom.us/j/91804791393)
- [Meeting Calendar](https://calendar.google.com/calendar/b/1/embed?src=volcano.sh.bot@gmail.com) | [Subscribe](https://calendar.google.com/calendar/b/1?cid=dm9sY2Fuby5zaC5ib3RAZ21haWwuY29t)

## Contact

If you have any question, feel free to reach out to us in the following ways:

[Volcano Slack Channel](https://cloud-native.slack.com/archives/C011GJDQS0N) | [Join](https://slack.cncf.io/)

[Mailing List](https://groups.google.com/forum/#!forum/volcano-sh)

WeChat: Please add WeChat account `k8s2222` and request an invitation to the group chat.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[go-gorm/gorm]]></title>
            <link>https://github.com/go-gorm/gorm</link>
            <guid>https://github.com/go-gorm/gorm</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[The fantastic ORM library for Golang, aims to be developer friendly]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/go-gorm/gorm">go-gorm/gorm</a></h1>
            <p>The fantastic ORM library for Golang, aims to be developer friendly</p>
            <p>Language: Go</p>
            <p>Stars: 39,257</p>
            <p>Forks: 4,123</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># GORM

The fantastic ORM library for Golang, aims to be developer friendly.

[![go report card](https://goreportcard.com/badge/github.com/go-gorm/gorm &quot;go report card&quot;)](https://goreportcard.com/report/github.com/go-gorm/gorm)
[![test status](https://github.com/go-gorm/gorm/actions/workflows/tests.yml/badge.svg)](https://github.com/go-gorm/gorm/actions)
[![MIT license](https://img.shields.io/badge/license-MIT-brightgreen.svg)](https://opensource.org/licenses/MIT)
[![Go.Dev reference](https://img.shields.io/badge/go.dev-reference-blue?logo=go&amp;logoColor=white)](https://pkg.go.dev/gorm.io/gorm?tab=doc)

## Overview

* Full-Featured ORM
* Associations (Has One, Has Many, Belongs To, Many To Many, Polymorphism, Single-table inheritance)
* Hooks (Before/After Create/Save/Update/Delete/Find)
* Eager loading with `Preload`, `Joins`
* Transactions, Nested Transactions, Save Point, RollbackTo to Saved Point
* Context, Prepared Statement Mode, DryRun Mode
* Batch Insert, FindInBatches, Find To Map
* SQL Builder, Upsert, Locking, Optimizer/Index/Comment Hints, NamedArg, Search/Update/Create with SQL Expr
* Composite Primary Key
* Auto Migrations
* Logger
* Extendable, flexible plugin API: Database Resolver (Multiple Databases, Read/Write Splitting) / Prometheus…
* Every feature comes with tests
* Developer Friendly

## Getting Started

* GORM Guides [https://gorm.io](https://gorm.io)
* Gen Guides [https://gorm.io/gen/index.html](https://gorm.io/gen/index.html)

## Contributing

[You can help to deliver a better GORM, check out things you can do](https://gorm.io/contribute.html)

## Contributors

[Thank you](https://github.com/go-gorm/gorm/graphs/contributors) for contributing to the GORM framework!

## License

© Jinzhu, 2013~time.Now

Released under the [MIT License](https://github.com/go-gorm/gorm/blob/master/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[qax-os/excelize]]></title>
            <link>https://github.com/qax-os/excelize</link>
            <guid>https://github.com/qax-os/excelize</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[Go language library for reading and writing Microsoft Excel™ (XLAM / XLSM / XLSX / XLTM / XLTX) spreadsheets]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/qax-os/excelize">qax-os/excelize</a></h1>
            <p>Go language library for reading and writing Microsoft Excel™ (XLAM / XLSM / XLSX / XLTM / XLTX) spreadsheets</p>
            <p>Language: Go</p>
            <p>Stars: 20,040</p>
            <p>Forks: 1,857</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;650&quot; src=&quot;./excelize.svg&quot; alt=&quot;Excelize logo&quot;&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/xuri/excelize/actions/workflows/go.yml&quot;&gt;&lt;img src=&quot;https://github.com/xuri/excelize/actions/workflows/go.yml/badge.svg&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://codecov.io/gh/qax-os/excelize&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/qax-os/excelize/branch/master/graph/badge.svg&quot; alt=&quot;Code Coverage&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://goreportcard.com/report/github.com/xuri/excelize/v2&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/xuri/excelize/v2&quot; alt=&quot;Go Report Card&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://pkg.go.dev/github.com/xuri/excelize/v2&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;logoColor=white&quot; alt=&quot;go.dev&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://opensource.org/licenses/BSD-3-Clause&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-bsd-orange.svg&quot; alt=&quot;Licenses&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.paypal.com/paypalme/xuri&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Donate-PayPal-green.svg&quot; alt=&quot;Donate&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

# Excelize

## Introduction

Excelize is a library written in pure Go providing a set of functions that allow you to write to and read from XLAM / XLSM / XLSX / XLTM / XLTX files. Supports reading and writing spreadsheet documents generated by Microsoft Excel&amp;trade; 2007 and later. Supports complex components by high compatibility, and provided streaming API for generating or reading data from a worksheet with huge amounts of data. This library needs Go version 1.24.0 or later. The full docs can be seen using go&#039;s built-in documentation tool, or online at [go.dev](https://pkg.go.dev/github.com/xuri/excelize/v2) and [docs reference](https://xuri.me/excelize/).

## Basic Usage

### Installation

```bash
go get github.com/xuri/excelize
```

- If your packages are managed using [Go Modules](https://go.dev/blog/using-go-modules), please install with following command.

```bash
go get github.com/xuri/excelize/v2
```

### Create spreadsheet

Here is a minimal example usage that will create spreadsheet file.

```go
package main

import (
    &quot;fmt&quot;

    &quot;github.com/xuri/excelize/v2&quot;
)

func main() {
    f := excelize.NewFile()
    defer func() {
        if err := f.Close(); err != nil {
            fmt.Println(err)
        }
    }()
    // Create a new sheet.
    index, err := f.NewSheet(&quot;Sheet2&quot;)
    if err != nil {
        fmt.Println(err)
        return
    }
    // Set value of a cell.
    f.SetCellValue(&quot;Sheet2&quot;, &quot;A2&quot;, &quot;Hello world.&quot;)
    f.SetCellValue(&quot;Sheet1&quot;, &quot;B2&quot;, 100)
    // Set active sheet of the workbook.
    f.SetActiveSheet(index)
    // Save spreadsheet by the given path.
    if err := f.SaveAs(&quot;Book1.xlsx&quot;); err != nil {
        fmt.Println(err)
    }
}
```

### Reading spreadsheet

The following constitutes the bare to read a spreadsheet document.

```go
package main

import (
    &quot;fmt&quot;

    &quot;github.com/xuri/excelize/v2&quot;
)

func main() {
    f, err := excelize.OpenFile(&quot;Book1.xlsx&quot;)
    if err != nil {
        fmt.Println(err)
        return
    }
    defer func() {
        // Close the spreadsheet.
        if err := f.Close(); err != nil {
            fmt.Println(err)
        }
    }()
    // Get value from cell by given worksheet name and cell reference.
    cell, err := f.GetCellValue(&quot;Sheet1&quot;, &quot;B2&quot;)
    if err != nil {
        fmt.Println(err)
        return
    }
    fmt.Println(cell)
    // Get all the rows in the Sheet1.
    rows, err := f.GetRows(&quot;Sheet1&quot;)
    if err != nil {
        fmt.Println(err)
        return
    }
    for _, row := range rows {
        for _, colCell := range row {
            fmt.Print(colCell, &quot;\t&quot;)
        }
        fmt.Println()
    }
}
```

### Add chart to spreadsheet file

With Excelize chart generation and management is as easy as a few lines of code. You can build charts based on data in your worksheet or generate charts without any data in your worksheet at all.

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;650&quot; src=&quot;./test/images/chart.png&quot; alt=&quot;Excelize&quot;&gt;&lt;/p&gt;

```go
package main

import (
    &quot;fmt&quot;

    &quot;github.com/xuri/excelize/v2&quot;
)

func main() {
    f := excelize.NewFile()
    defer func() {
        if err := f.Close(); err != nil {
            fmt.Println(err)
        }
    }()
    for idx, row := range [][]interface{}{
        {nil, &quot;Apple&quot;, &quot;Orange&quot;, &quot;Pear&quot;}, {&quot;Small&quot;, 2, 3, 3},
        {&quot;Normal&quot;, 5, 2, 4}, {&quot;Large&quot;, 6, 7, 8},
    } {
        cell, err := excelize.CoordinatesToCellName(1, idx+1)
        if err != nil {
            fmt.Println(err)
            return
        }
        f.SetSheetRow(&quot;Sheet1&quot;, cell, &amp;row)
    }
    if err := f.AddChart(&quot;Sheet1&quot;, &quot;E1&quot;, &amp;excelize.Chart{
        Type: excelize.Col3DClustered,
        Series: []excelize.ChartSeries{
            {
                Name:       &quot;Sheet1!$A$2&quot;,
                Categories: &quot;Sheet1!$B$1:$D$1&quot;,
                Values:     &quot;Sheet1!$B$2:$D$2&quot;,
            },
            {
                Name:       &quot;Sheet1!$A$3&quot;,
                Categories: &quot;Sheet1!$B$1:$D$1&quot;,
                Values:     &quot;Sheet1!$B$3:$D$3&quot;,
            },
            {
                Name:       &quot;Sheet1!$A$4&quot;,
                Categories: &quot;Sheet1!$B$1:$D$1&quot;,
                Values:     &quot;Sheet1!$B$4:$D$4&quot;,
            }},
        Title: []excelize.RichTextRun{
            {
                Text: &quot;Fruit 3D Clustered Column Chart&quot;,
            },
        },
    }); err != nil {
        fmt.Println(err)
        return
    }
    // Save spreadsheet by the given path.
    if err := f.SaveAs(&quot;Book1.xlsx&quot;); err != nil {
        fmt.Println(err)
    }
}
```

### Add picture to spreadsheet file

```go
package main

import (
    &quot;fmt&quot;
    _ &quot;image/gif&quot;
    _ &quot;image/jpeg&quot;
    _ &quot;image/png&quot;

    &quot;github.com/xuri/excelize/v2&quot;
)

func main() {
    f, err := excelize.OpenFile(&quot;Book1.xlsx&quot;)
    if err != nil {
        fmt.Println(err)
        return
    }
    defer func() {
        // Close the spreadsheet.
        if err := f.Close(); err != nil {
            fmt.Println(err)
        }
    }()
    // Insert a picture.
    if err := f.AddPicture(&quot;Sheet1&quot;, &quot;A2&quot;, &quot;image.png&quot;, nil); err != nil {
        fmt.Println(err)
    }
    // Insert a picture to worksheet with scaling.
    if err := f.AddPicture(&quot;Sheet1&quot;, &quot;D2&quot;, &quot;image.jpg&quot;,
        &amp;excelize.GraphicOptions{ScaleX: 0.5, ScaleY: 0.5}); err != nil {
        fmt.Println(err)
    }
    // Insert a picture offset in the cell with printing support.
    enable, disable := true, false
    if err := f.AddPicture(&quot;Sheet1&quot;, &quot;H2&quot;, &quot;image.gif&quot;,
        &amp;excelize.GraphicOptions{
            PrintObject:     &amp;enable,
            LockAspectRatio: false,
            OffsetX:         15,
            OffsetY:         10,
            Locked:          &amp;disable,
        }); err != nil {
        fmt.Println(err)
    }
    // Save the spreadsheet with the origin path.
    if err = f.Save(); err != nil {
        fmt.Println(err)
    }
}
```

## Contributing

Contributions are welcome! Open a pull request to fix a bug, or open an issue to discuss a new feature or change. XML is compliant with [part 1 of the 5th edition of the ECMA-376 Standard for Office Open XML](https://www.ecma-international.org/publications-and-standards/standards/ecma-376/).

## Licenses

This program is under the terms of the BSD 3-Clause License. See [https://opensource.org/licenses/BSD-3-Clause](https://opensource.org/licenses/BSD-3-Clause).

The Excel logo is a trademark of [Microsoft Corporation](https://aka.ms/trademarks-usage). This artwork is an adaptation.

The Go gopher was created by [Renee French](https://go.dev/doc/gopher/README). Licensed under the [Creative Commons 4.0 Attributions license](http://creativecommons.org/licenses/by/4.0/).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[beclab/Olares]]></title>
            <link>https://github.com/beclab/Olares</link>
            <guid>https://github.com/beclab/Olares</guid>
            <pubDate>Wed, 17 Dec 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[Olares: An Open-Source Personal Cloud to Reclaim Your Data]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/beclab/Olares">beclab/Olares</a></h1>
            <p>Olares: An Open-Source Personal Cloud to Reclaim Your Data</p>
            <p>Language: Go</p>
            <p>Stars: 3,660</p>
            <p>Forks: 179</p>
            <p>Stars today: 46 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# Olares: An Open-Source Personal Cloud to &lt;/br&gt;Reclaim Your Data&lt;!-- omit in toc --&gt;

[![Mission](https://img.shields.io/badge/Mission-Let%20people%20own%20their%20data%20again-purple)](#)&lt;br/&gt;
[![Last Commit](https://img.shields.io/github/last-commit/beclab/olares)](https://github.com/beclab/olares/commits/main)
![Build Status](https://github.com/beclab/olares/actions/workflows/release-daily.yaml/badge.svg)
[![GitHub release (latest by date)](https://img.shields.io/github/v/release/beclab/olares)](https://github.com/beclab/olares/releases)
[![GitHub Repo stars](https://img.shields.io/github/stars/beclab/olares?style=social)](https://github.com/beclab/olares/stargazers)
[![Discord](https://img.shields.io/badge/Discord-7289DA?logo=discord&amp;logoColor=white)](https://discord.gg/olares)
[![License](https://img.shields.io/badge/License-AGPL--3.0-blue)](https://github.com/beclab/olares/blob/main/LICENSE)

&lt;a href=&quot;https://trendshift.io/repositories/15376&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15376&quot; alt=&quot;beclab%2FOlares | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;p&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;Readme in English&quot; src=&quot;https://img.shields.io/badge/English-FFFFFF&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_CN.md&quot;&gt;&lt;img alt=&quot;Readme in Chinese&quot; src=&quot;https://img.shields.io/badge/简体中文-FFFFFF&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_JP.md&quot;&gt;&lt;img alt=&quot;Readme in Japanese&quot; src=&quot;https://img.shields.io/badge/日本語-FFFFFF&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://olares.com&quot;&gt;Website&lt;/a&gt; ·
  &lt;a href=&quot;https://docs.olares.com&quot;&gt;Documentation&lt;/a&gt; ·
  &lt;a href=&quot;https://www.olares.com/larepass&quot;&gt;Download LarePass&lt;/a&gt; ·
  &lt;a href=&quot;https://github.com/beclab/apps&quot;&gt;Olares Apps&lt;/a&gt; ·
  &lt;a href=&quot;https://space.olares.com&quot;&gt;Olares Space&lt;/a&gt;
&lt;/p&gt;

&gt;*The modern internet built on public clouds is increasingly threatening your personal data privacy. As reliance on services like ChatGPT, Midjourney, and Facebook grows, so does the risk to your digital autonomy. Your data lives on their servers, subject to their terms, tracking, and potential censorship.*
&gt;
&gt;*It&#039;s time for a change.* 

![Personal Cloud](https://app.cdn.olares.com/github/olares/public-cloud-to-personal-cloud.jpg)
We believe you have a fundamental right to control your digital life. The most effective way to uphold this right is by hosting your data locally, on your own hardware.

Olares is an **open-source personal cloud operating system** designed to empower you to own and manage your digital assets locally. Instead of relying on public cloud services, you can deploy powerful open-source alternatives locally on Olares, such as Ollama for hosting LLMs, ComfyUI for image generation, and Perplexica for private, AI-driven search and reasoning. Imagine the power of the cloud, but with you in complete command.

&gt; 🌟 *Star us to receive instant notifications about new releases and updates.* 

## Architecture 

Just as Public clouds offer IaaS, PaaS, and SaaS layers, Olares provides open-source alternatives to each of these layers.

  ![Tech Stacks](https://app.cdn.olares.com/github/olares/olares-architecture.jpg)

 For detailed description of each component, refer to [Olares architecture](https://docs.olares.com/manual/concepts/system-architecture.html).

&gt; 🔍 **How is Olares different from traditional NAS?**
&gt;
&gt; Olares focuses on building an all-in-one self-hosted personal cloud experience. Its core features and target users differ significantly from traditional Network Attached Storage (NAS) systems, which primarily focus on network storage. For more details, see [Compare Olares and NAS](https://docs.olares.com/manual/olares-vs-nas.html).

## Features

Olares offers a wide array of features designed to enhance security, ease of use, and development flexibility:

- **Enterprise-grade security**: Simplified network configuration using Tailscale, Headscale, Cloudflare Tunnel, and FRP.
- **Secure and permissionless application ecosystem**: Sandboxing ensures application isolation and security.
- **Unified file system and database**: Automated scaling, backups, and high availability.
- **Single sign-on**: Log in once to access all applications within Olares with a shared authentication service.
- **AI capabilities**: Comprehensive solution for GPU management, local AI model hosting, and private knowledge bases while maintaining data privacy.
- **Built-in applications**: Includes file manager, sync drive, vault, reader, app market, settings, and dashboard.
- **Seamless anywhere access**: Access your devices from anywhere using dedicated clients for mobile, desktop, and browsers.
- **Development tools**: Comprehensive development tools for effortless application development and porting.

Here are some screenshots from the UI for a sneak peek:

| **Desktop–Streamlined and familiar portal**     |  **Files–A secure home to your data**
| :--------: | :-------: |
| ![Desktop](https://app.cdn.olares.com/github/terminus/v2/desktop.jpg) | ![Files](https://app.cdn.olares.com/github/terminus/v2/files.jpg) |
| **Vault–1Password alternative**|**Market–App ecosystem in your control** |
| ![vault](https://app.cdn.olares.com/github/terminus/v2/vault.jpg) | ![market](https://app.cdn.olares.com/github/terminus/v2/market.jpg) |
|**Wise–Your digital secret garden** | **Settings–Manage Olares efficiently** |
| ![settings](https://app.cdn.olares.com/github/terminus/v2/wise.jpg) | ![](https://app.cdn.olares.com/github/terminus/v2/settings.jpg) |
|**Dashboard–Constant system monitoring**  | **Profile–Your unique homepage** |
| ![dashboard](https://app.cdn.olares.com/github/terminus/v2/dashboard.jpg) | ![profile](https://app.cdn.olares.com/github/terminus/v2/profile.jpg) |
| **Studio–Develop, debug, and deploy**|**Control Hub–Manage Kubernetes clusters easily**  |
| ![Studio](https://app.cdn.olares.com/github/terminus/v2/devbox.jpg) | ![Controlhub](https://app.cdn.olares.com/github/terminus/v2/controlhub.jpg)|


## Key use cases

Here is why and where you can count on Olares for private, powerful, and secure sovereign cloud experience:

🤖 **Edge AI**: Run cutting-edge open AI models locally, including large language models, computer vision, and speech recognition. Create private AI services tailored to your data for enhanced functionality and privacy. &lt;br&gt;

📊 **Personal data repository**: Securely store, sync, and manage your important files, photos, and documents across devices and locations.&lt;br&gt;

🚀 **Self-hosted workspace**: Build a free collaborative workspace for your team using secure, open-source SaaS alternatives.&lt;br&gt;

🎥 **Private media server**: Host your own streaming services with your personal media collections. &lt;br&gt;

🏡 **Smart Home Hub**: Create a central control point for your IoT devices and home automation. &lt;br&gt;

🤝 **User-owned decentralized social media**: Easily install decentralized social media apps such as Mastodon, Ghost, and WordPress on Olares, allowing you to build a personal brand without the risk of being banned or paying platform commissions.&lt;br&gt;

📚 **Learning platform**: Explore self-hosting, container orchestration, and cloud technologies hands-on.

## Getting started

### System compatibility

Olares has been tested and verified on the following Linux platforms:

- Ubuntu 24.04 LTS or later
- Debian 11 or later

### Set up Olares
To get started with Olares on your own device, follow the [Getting Started Guide](https://docs.olares.com/manual/get-started/) for step-by-step instructions.

## Project navigation
This section lists the main directories in the Olares repository:

* **[`apps`](./apps)**: Contains the code for system applications, primarily for `larepass`.
* **[`cli`](./cli)**: Contains the code for `olares-cli`, the command-line interface tool for Olares.
* **[`daemon`](./daemon)**: Contains the code for `olaresd`, the system daemon process.
* **[`docs`](./docs)**: Contains documentation for the project.
* **[`framework`](./framework)**: Contains the Olares system services.
* **[`infrastructure`](./infrastructure)**: Contains code related to infrastructure components such as computing, storage, networking, and GPUs.
* **[`platform`](./platform)**: Contains code for cloud-native components like databases and message queues.
* **`vendor`**: Contains code from third-party hardware vendors.

## Contributing to Olares

We are welcoming contributions in any form:

- If you want to develop your own applications on Olares, refer to:&lt;br&gt;
https://docs.olares.com/developer/develop/


- If you want to help improve Olares, refer to:&lt;br&gt;
https://docs.olares.com/developer/contribute/olares.html

## Community &amp; contact

* [**GitHub Discussion**](https://github.com/beclab/olares/discussions). Best for sharing feedback and asking questions.
* [**GitHub Issues**](https://github.com/beclab/olares/issues). Best for filing bugs you encounter using Olares and submitting feature proposals. 
* [**Discord**](https://discord.gg/olares). Best for sharing anything Olares.

## Special thanks

The Olares project has incorporated numerous third-party open source projects, including: [Kubernetes](https://kubernetes.io/), [Kubesphere](https://github.com/kubesphere/kubesphere), [Padloc](https://padloc.app/), [K3S](https://k3s.io/), [JuiceFS](https://github.com/juicedata/juicefs), [MinIO](https://github.com/minio/minio), [Envoy](https://github.com/envoyproxy/envoy), [Authelia](https://github.com/authelia/authelia), [Infisical](https://github.com/Infisical/infisical), [Dify](https://github.com/langgenius/dify), [Seafile](https://github.com/haiwen/seafile),[HeadScale](https://headscale.net/), [tailscale](https://tailscale.com/), [Redis Operator](https://github.com/spotahome/redis-operator), [Nitro](https://nitro.jan.ai/), [RssHub](http://rsshub.app/), [predixy](https://github.com/joyieldInc/predixy), [nvshare](https://github.com/grgalex/nvshare), [LangChain](https://www.langchain.com/), [Quasar](https://quasar.dev/), [TrustWallet](https://trustwallet.com/), [Restic](https://restic.net/), [ZincSearch](https://zincsearch-docs.zinc.dev/), [filebrowser](https://filebrowser.org/), [lego](https://go-acme.github.io/lego/), [Velero](https://velero.io/), [s3rver](https://github.com/jamhall/s3rver), [Citusdata](https://www.citusdata.com/).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[v2fly/domain-list-community]]></title>
            <link>https://github.com/v2fly/domain-list-community</link>
            <guid>https://github.com/v2fly/domain-list-community</guid>
            <pubDate>Wed, 17 Dec 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[Community managed domain list. Generate geosite.dat for V2Ray.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/v2fly/domain-list-community">v2fly/domain-list-community</a></h1>
            <p>Community managed domain list. Generate geosite.dat for V2Ray.</p>
            <p>Language: Go</p>
            <p>Stars: 6,966</p>
            <p>Forks: 1,150</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># Domain list community

This project manages a list of domains, to be used as geosites for routing purpose in Project V.

## Purpose of this project

This project is not opinionated. In other words, it does NOT endorse, claim or imply that a domain should be blocked or proxied. It can be used to generate routing rules on demand.

## Download links

- **dlc.dat**：[https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat](https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat)
- **dlc.dat.sha256sum**：[https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum](https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum)

## Usage example

Each file in the `data` directory can be used as a rule in this format: `geosite:filename`.

```json
&quot;routing&quot;: {
  &quot;domainStrategy&quot;: &quot;IPIfNonMatch&quot;,
  &quot;rules&quot;: [
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Reject&quot;,
      &quot;domain&quot;: [
        &quot;geosite:category-ads-all&quot;,
        &quot;geosite:category-porn&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Direct&quot;,
      &quot;domain&quot;: [
        &quot;domain:icloud.com&quot;,
        &quot;domain:icloud-content.com&quot;,
        &quot;domain:cdn-apple.com&quot;,
        &quot;geosite:cn&quot;,
        &quot;geosite:private&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Proxy-1&quot;,
      &quot;domain&quot;: [
        &quot;geosite:category-anticensorship&quot;,
        &quot;geosite:category-media&quot;,
        &quot;geosite:category-vpnservices&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Proxy-2&quot;,
      &quot;domain&quot;: [
        &quot;geosite:category-dev&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Proxy-3&quot;,
      &quot;domain&quot;: [
        &quot;geosite:geolocation-!cn&quot;
      ]
    }
  ]
}
```

## Generate `dlc.dat` manually

- Install `golang` and `git`
- Clone project code: `git clone https://github.com/v2fly/domain-list-community.git`
- Navigate to project root directory: `cd domain-list-community`
- Install project dependencies: `go mod download`
- Generate `dlc.dat` (without `datapath` option means to use domain lists in `data` directory of current working directory):
  - `go run ./`
  - `go run ./ --datapath=/path/to/your/custom/data/directory`

Run `go run ./ --help` for more usage information.

## Structure of data

All data are under `data` directory. Each file in the directory represents a sub-list of domains, named by the file name. File content is in the following format.

```
# comments
include:another-file
domain:google.com @attr1 @attr2
keyword:google
regexp:www\.google\.com$
full:www.google.com
```

**Syntax:**

&gt; The following types of rules are **NOT** fully compatible with the ones that defined by user in V2Ray config file. Do **Not** copy and paste directly.

- Comment begins with `#`. It may begin anywhere in the file. The content in the line after `#` is treated as comment and ignored in production.
- Inclusion begins with `include:`, followed by the file name of an existing file in the same directory.
- Subdomain begins with `domain:`, followed by a valid domain name. The prefix `domain:` may be omitted.
- Keyword begins with `keyword:`, followed by a string.
- Regular expression begins with `regexp:`, followed by a valid regular expression (per Golang&#039;s standard).
- Full domain begins with `full:`, followed by a complete and valid domain name.
- Domains (including `domain`, `keyword`, `regexp` and `full`) may have one or more attributes. Each attribute begins with `@` and followed by the name of the attribute.

&gt; **Note:** Adding new `regexp` and `keyword` rules is discouraged because it is easy to use them incorrectly, and proxy software cannot efficiently match these types of rules.

## How it works

The entire `data` directory will be built into an external `geosite` file for Project V. Each file in the directory represents a section in the generated file.

To generate a section:

1. Remove all the comments in the file.
2. Replace `include:` lines with the actual content of the file.
3. Omit all empty lines.
4. Generate each `domain:` line into a [sub-domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/routercommon/common.proto#L21).
5. Generate each `full:` line into a [full domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/routercommon/common.proto#L23).
6. Generate each `keyword:` line into a [plain domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/routercommon/common.proto#L17).
7. Generate each `regexp:` line into a [regex domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/routercommon/common.proto#L19).

## How to organize domains

### File name

Theoretically any string can be used as the name, as long as it is a valid file name. In practice, we prefer names for determinic group of domains, such as the owner (usually a company name) of the domains, e.g., &quot;google&quot;, &quot;netflix&quot;. Names with unclear scope are generally unrecommended, such as &quot;evil&quot;, or &quot;local&quot;.

### Attributes

Attribute is useful for sub-group of domains, especially for filtering purpose. For example, the list of `google` domains may contains its main domains, as well as domains that serve ads. The ads domains may be marked by attribute `@ads`, and can be used as `geosite:google@ads` in V2Ray routing.

## Contribution guideline

- Fork this repo, make modifications to your own repo, file a PR.
- Please begin with small size PRs, say modification in a single file.
- A PR must be reviewed and approved by another member.
- A script will verify your pull request to test whether your PR is correct or not every time you update the PR. Only the PR which passes the test will be merged. Please go to the Action label to get detailed information if you didn&#039;t pass it. We also provide the file which has been generated to make you test.
- After a few successful PRs, you may apply for manager access to this repository.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cloudnative-pg/cloudnative-pg]]></title>
            <link>https://github.com/cloudnative-pg/cloudnative-pg</link>
            <guid>https://github.com/cloudnative-pg/cloudnative-pg</guid>
            <pubDate>Wed, 17 Dec 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[CloudNativePG is a comprehensive platform designed to seamlessly manage PostgreSQL databases within Kubernetes environments, covering the entire operational lifecycle from initial deployment to ongoing maintenance]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudnative-pg/cloudnative-pg">cloudnative-pg/cloudnative-pg</a></h1>
            <p>CloudNativePG is a comprehensive platform designed to seamlessly manage PostgreSQL databases within Kubernetes environments, covering the entire operational lifecycle from initial deployment to ongoing maintenance</p>
            <p>Language: Go</p>
            <p>Stars: 7,588</p>
            <p>Forks: 567</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>[![CNCF Landscape](https://img.shields.io/badge/CNCF%20Landscape-5699C6)][cncf-landscape]
[![Latest Release](https://img.shields.io/github/v/release/cloudnative-pg/cloudnative-pg.svg)][latest-release]
[![GitHub License](https://img.shields.io/github/license/cloudnative-pg/cloudnative-pg)][license]
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9933/badge)][openssf]
[![OpenSSF Scorecard Badge][openssf-scorecard-badge]][openssf-socrecard-view]
[![Documentation][documentation-badge]][documentation]
[![Stack Overflow](https://img.shields.io/badge/stackoverflow-cloudnative--pg-blue?logo=stackoverflow&amp;logoColor=%23F48024&amp;link=https%3A%2F%2Fstackoverflow.com%2Fquestions%2Ftagged%2Fcloudnative-pg)][stackoverflow]
[![FOSSA Status][fossa-badge]][fossa]
[![CLOMonitor](https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/cloudnative-pg/badge)](https://clomonitor.io/projects/cncf/cloudnative-pg)
[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/cloudnative-pg)](https://artifacthub.io/packages/search?repo=cloudnative-pg)

# Welcome to the CloudNativePG Project!

**CloudNativePG (CNPG)** is an open-source platform designed to seamlessly
manage [PostgreSQL](https://www.postgresql.org/) databases in Kubernetes
environments. It covers the entire operational lifecycle—from deployment to
ongoing maintenance—through its core component, the CloudNativePG operator.

## Table of Contents

- [Code of Conduct](CODE_OF_CONDUCT.md)
- [Governance Policies](https://github.com/cloudnative-pg/governance/blob/main/GOVERNANCE.md)
- [Contributing](CONTRIBUTING.md)
- [Adopters](ADOPTERS.md)
- [Commercial Support](https://cloudnative-pg.io/support/)
- [License](LICENSE)

## Getting Started

The best way to get started is the [Quickstart Guide](https://cloudnative-pg.io/documentation/current/quickstart/).

## Scope

### Mission

CloudNativePG aims to increase PostgreSQL adoption within Kubernetes by making
it an integral part of the development process and GitOps-driven CI/CD
automation.

### Core Principles &amp; Features

Designed by PostgreSQL experts for Kubernetes administrators, CloudNativePG
follows a Kubernetes-native approach to PostgreSQL primary/standby cluster
management. Instead of relying on external high-availability tools (like
Patroni, repmgr, or Stolon), it integrates directly with the Kubernetes API to
automate database operations that a skilled DBA would perform manually.

Key design decisions include:

- Direct integration with Kubernetes API: The PostgreSQL cluster’s status is
  available directly in the `Cluster` resource, allowing users to inspect it
  via the Kubernetes API.
- Operator pattern: The operator ensures that the desired PostgreSQL state is
  reconciled automatically, following Kubernetes best practices.
- Immutable application containers: Updates follow an immutable infrastructure
  model, as explained in
  [&quot;Why EDB Chose Immutable Application Containers&quot;](https://www.enterprisedb.com/blog/why-edb-chose-immutable-application-containers).

### How CloudNativePG Works

The operator continuously monitors and updates the PostgreSQL cluster state.
Examples of automated actions include:

- Failover management: If the primary instance fails, the operator elects a new
  primary, updates the cluster status, and orchestrates the transition.
- Scaling read replicas: When the number of desired replicas changes, the
  operator provisions or removes resources such as persistent volumes, secrets,
  and config maps while managing streaming replication.
- Service updates: Kubernetes remains the single source of truth, ensuring
  that PostgreSQL service endpoints are always up to date.
- Rolling updates: When an image is updated, the operator follows a rolling
  strategy—first updating replica pods before performing a controlled
  switchover for the primary.

CloudNativePG manages additional Kubernetes resources to enhance PostgreSQL
management, including: `Backup`, `ClusterImageCatalog`, `Database`,
`ImageCatalog`, `Pooler`, `Publication`, `ScheduledBackup`, and `Subscription`.

## Out of Scope

- **Kubernetes only:** CloudNativePG is dedicated to vanilla Kubernetes
  maintained by the [Cloud Native Computing Foundation
  (CNCF)](https://kubernetes.io/).
- **PostgreSQL only:** CloudNativePG is dedicated to vanilla PostgreSQL
  maintained by the [PostgreSQL Global Development Group
  (PGDG)](https://www.postgresql.org/about/).
- **No support for forks:** Features from PostgreSQL forks will only be
  considered if they can be integrated as extensions or pluggable frameworks.
- **Not a general-purpose database operator:** CloudNativePG does not support
  other databases (e.g., MariaDB).

CloudNativePG can be extended via the [CNPG-I plugin interface](https://github.com/cloudnative-pg/cnpg-i).

## Communications

- [Github Discussions](https://github.com/cloudnative-pg/cloudnative-pg/discussions)
- [Slack](https://cloud-native.slack.com/archives/C08MAUJ7NPM)
  (join the [CNCF Slack Workspace](https://communityinviter.com/apps/cloud-native/cncf)).
- [Twitter](https://twitter.com/CloudNativePg)
- [Mastodon](https://mastodon.social/@CloudNativePG)
- [Bluesky](https://bsky.app/profile/cloudnativepg.bsky.social)

## Resources

- [Roadmap](ROADMAP.md)
- [Website](https://cloudnative-pg.io)
- [FAQ](docs/src/faq.md)
- [Blog](https://cloudnative-pg.io/blog/)
- [CloudNativePG plugin Interface (CNPG-I)](https://github.com/cloudnative-pg/cnpg-i).

## Adopters

A list of publicly known users of the CloudNativePG operator is in [ADOPTERS.md](ADOPTERS.md).
Help us grow our community and CloudNativePG by adding yourself and your
organization to this list!

### CloudNativePG at KubeCon

- November 10, 2025, KubeCon North America 2025 in Atlanta: [&quot;Project Lightning Talk: CloudNativePG: Running Postgres The Kubernetes Way&quot;](https://www.youtube.com/watch?v=pYwYwehQX3U&amp;t=4s) - Gabriele Bartolini, EDB
- November 11, 2025, KubeCon North America 2025 in Atlanta: [&quot;Modern PostgreSQL Authorization With Keycloak: Cloud Native Identity Meets Database Security&quot;](https://www.youtube.com/watch?v=TYgPemq06fg) - Yoshiyuki Tabata, Hitachi, Ltd. &amp; Gabriele Bartolini, EDB
- November 13, 2025, KubeCon North America 2025 in Atlanta: [&quot;Quorum-Based Consistency for Cluster Changes With CloudNativePG Operator&quot;](https://www.youtube.com/watch?v=iQUOO3-JRK4&amp;list=PLj6h78yzYM2MLSW4tUDO2gs2pR5UpiD0C&amp;index=67) - Jeremy Schneider, GEICO Tech &amp; Gabriele Bartolini, EDB
- April 4, 2025, KubeCon Europe in London: [&quot;Consistent Volume Group Snapshots, Unraveling the Magic&quot;](https://sched.co/1tx8g) - Leonardo Cecchi (EDB) and Xing Yang (VMware)
- November 11, 2024, Cloud Native Rejekts NA 2024: [&quot;Maximising Microservice Databases with Kubernetes, Postgres, and CloudNativePG&quot;](https://www.youtube.com/watch?v=uBzl_stoxoc&amp;ab_channel=CloudNativeRejekts) - Gabriele Bartolini (EDB) and Leonardo Cecchi (EDB)
- March 21, 2024, KubeCon Europe 2024 in Paris: [&quot;Scaling Heights: Mastering Postgres Database Vertical Scalability with Kubernetes Storage Magic&quot;](https://kccnceu2024.sched.com/event/1YeM4/scaling-heights-mastering-postgres-database-vertical-scalability-with-kubernetes-storage-magic-gabriele-bartolini-edb-gari-singh-google) - Gari Singh, Google &amp; Gabriele Bartolini, EDB
- March 19, 2024, Data on Kubernetes Day at KubeCon Europe 2024 in Paris: [&quot;From Zero to Hero: Scaling Postgres in Kubernetes Using the Power of CloudNativePG&quot;](https://colocatedeventseu2024.sched.com/event/1YFha/from-zero-to-hero-scaling-postgres-in-kubernetes-using-the-power-of-cloudnativepg-gabriele-bartolini-edb) - Gabriele Bartolini, EDB
- November 7, 2023, KubeCon North America 2023 in Chicago: [&quot;Disaster Recovery with Very Large Postgres Databases (in Kubernetes)&quot;](https://kccncna2023.sched.com/event/1R2ml/disaster-recovery-with-very-large-postgres-databases-gabriele-bartolini-edb-michelle-au-google) - Michelle Au, Google &amp; Gabriele Bartolini, EDB
- October 27, 2022, KubeCon North America 2022 in Detroit: [&quot;Data On Kubernetes, Deploying And Running PostgreSQL And Patterns For Databases In a Kubernetes Cluster&quot;](https://kccncna2022.sched.com/event/182GB/data-on-kubernetes-deploying-and-running-postgresql-and-patterns-for-databases-in-a-kubernetes-cluster-chris-milsted-ondat-gabriele-bartolini-edb) - Chris Milsted, Ondat &amp; Gabriele Bartolini, EDB

### Useful links

- [&quot;Quorum-Based Consistency for Cluster Changes With CloudNativePG Operator&quot;](https://www.youtube.com/watch?v=sRF09UMAlsI) (webinar) - Jeremy Schneider, GEICO Tech &amp; Leonardo Cecchi, EDB
- [Data on Kubernetes (DoK) Community](https://dok.community/)
- [&quot;Cloud Neutral Postgres Databases with Kubernetes and CloudNativePG&quot; by Gabriele Bartolini](https://www.cncf.io/blog/2024/11/20/cloud-neutral-postgres-databases-with-kubernetes-and-cloudnativepg/) (November 2024)
- [&quot;How to migrate your PostgreSQL database in Kubernetes with ~0 downtime from anywhere&quot; by Gabriele Bartolini](https://gabrielebartolini.it/articles/2024/03/cloudnativepg-recipe-5-how-to-migrate-your-postgresql-database-in-kubernetes-with-~0-downtime-from-anywhere/) (March 2024)
- [&quot;Maximizing Microservice Databases with Kubernetes, Postgres, and CloudNativePG&quot; by Gabriele Bartolini](https://gabrielebartolini.it/articles/2024/02/maximizing-microservice-databases-with-kubernetes-postgres-and-cloudnativepg/) (February 2024)
- [&quot;Recommended Architectures for PostgreSQL in Kubernetes&quot; by Gabriele Bartolini](https://www.cncf.io/blog/2023/09/29/recommended-architectures-for-postgresql-in-kubernetes/) (September 2023)
- [&quot;The Current State of Major PostgreSQL Upgrades with CloudNativePG&quot; by Gabriele Bartolini](https://www.enterprisedb.com/blog/current-state-major-postgresql-upgrades-cloudnativepg-kubernetes) (August 2023)
- [&quot;The Rise of the Kubernetes Native Database&quot; by Jeff Carpenter](https://thenewstack.io/the-rise-of-the-kubernetes-native-database/) (December 2022)
- [&quot;Why Run Postgres in Kubernetes?&quot; by Gabriele Bartolini](https://cloudnativenow.com/kubecon-cnc-eu-2022/why-run-postgres-in-kubernetes/) (May 2022)
- [&quot;Shift-Left Security: The Path To PostgreSQL On Kubernetes&quot; by Gabriele Bartolini](https://www.tfir.io/shift-left-security-the-path-to-postgresql-on-kubernetes/) (April 2021)
- [&quot;Local Persistent Volumes and PostgreSQL usage in Kubernetes&quot; by Gabriele Bartolini](https://www.2ndquadrant.com/en/blog/local-persistent-volumes-and-postgresql-usage-in-kubernetes/) (June 2020)

---

&lt;p align=&quot;center&quot;&gt;
We are a &lt;a href=&quot;https://www.cncf.io/sandbox-projects/&quot;&gt;Cloud Native Computing Foundation Sandbox project&lt;/a&gt;.
&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; align=&quot;center&quot;&gt;
      &lt;picture align=&quot;center&quot;&gt;
         &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/white/cncf-white.svg?raw=true&quot;&gt;
         &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/color/cncf-color.svg?raw=true&quot;&gt;
         &lt;img align=&quot;center&quot; src=&quot;https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/color/cncf-color.svg?raw=true&quot; alt=&quot;CNCF logo&quot; width=&quot;50%&quot;/&gt;
      &lt;/picture&gt;
&lt;/p&gt;

---

&lt;p align=&quot;center&quot;&gt;
CloudNativePG was originally built and sponsored by &lt;a href=&quot;https://www.enterprisedb.com&quot;&gt;EDB&lt;/a&gt;.
&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; align=&quot;center&quot;&gt;
      &lt;picture align=&quot;center&quot;&gt;
         &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_white.svg&quot;&gt;
         &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_grey.svg&quot;&gt;
         &lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_grey.svg&quot; alt=&quot;EDB logo&quot; width=&quot;25%&quot;/&gt;
      &lt;/picture&gt;
&lt;/p&gt;

---

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.postgresql.org/about/policies/trademarks/&quot;&gt;Postgres, PostgreSQL, and the Slonik Logo&lt;/a&gt;
are trademarks or registered trademarks of the PostgreSQL Community Association
of Canada, and used with their permission.
&lt;/p&gt;

---

[cncf-landscape]: https://landscape.cncf.io/?item=app-definition-and-development--database--cloudnativepg
[stackoverflow]: https://stackoverflow.com/questions/tagged/cloudnative-pg
[latest-release]: https://github.com/cloudnative-pg/cloudnative-pg/releases/latest
[documentation]: https://cloudnative-pg.io/documentation/current/
[license]: https://github.com/cloudnative-pg/cloudnative-pg?tab=Apache-2.0-1-ov-file#readme
[openssf]: https://www.bestpractices.dev/projects/9933
[openssf-scorecard-badge]: https://api.scorecard.dev/projects/github.com/cloudnative-pg/cloudnative-pg/badge
[openssf-socrecard-view]: https://scorecard.dev/viewer/?uri=github.com/cloudnative-pg/cloudnative-pg
[documentation-badge]: https://img.shields.io/badge/Documentation-white?logo=data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAGN0lEQVR4nJRXXWwcVxU%2B8%2F%2BzP%2BPZtR2v7dqy07jUJUALNaiK6lZyUVVKWgGKaIv8QCMekBAVQlQICcEzVZFQVYFKQhASEBHlISJPCRJEshTFChgrIYHEiYMh69jetffHM7Mzc%2B9Bs7vjnTs7yZpZWbt37s%2F5zne%2Bc861CD0eXRkbHc3NfjeffvxNAGEAgULD2756v35%2B3qe1Nc4fnQVEXlA2LnOcXlCF8S%2B6vvVgq%2FL3M65X3e51PvfQCU4WJgZe%2B8GQ8fS7AKgjBB8KEHwjDXZSjkf0CREAaXM2eI9c65siqWxWl360Xl74ANHz%2Fy8AitxnTBfmz%2BhyYS4wGhwObQCIHSA0AigOMBzvOsXzd4pnjyL6NMmWEH8hi2b28Og3%2FqRJA0ewfQy0v1vGO2NovwPo%2FEU%2FwVgSU1PI%2BSu79v3lJAB8HM%2BTI%2FO%2FUUXzM4xHIe0xI4DdRqOAwnF%2F38ePPyzaDIDh%2FMxcWh462m08aojuGY97C0nrAEHg9BlF0fmeAPr0J15vbaKsp0BZQzEDEAlP9B209UIIVXUta%2FQEQHwxgxFjTc%2BRskAwrgVWmHtg22vMPJwLDqGUNJIAMHVAkGu3WdpZz6NAkgSXpINSycluV28er1a3rJ4M3F2%2F9AtCvXKycRrTQttrjINjxxxIL9jevxdaDHU%2FTBr6pL5ruzuLZubgUQBOY2hPij3GBUe7tBCMBRE2KrXVSz0BBI%2FtPVgtV%2F%2FxkZ5WSjI%2F%2BFIXC3sHJwgT4yFqrZFFTSlVrp3sGYLwcfxSmXCbS00j2Ms4K7qkOsFx6qdTuiHtG4AimfmM8NyvOvR2G48qXtZ2fsfrN7%2BqpcRyUp0glKiimDm4TwAcHBp%2B9WeA4ki0GMWNR9OVF8BZvn7xtI%2FF09H8jzLEgz6yLwCDuelnFXHkTZZOytCOEdqDOtGwsm%2BNj00fXt%2B6%2Bj4vcA7bwNrZwENmXwAKuZnvsNRThs5ozMPfPiHyoDF7xiduHcXb70A8dRFheHjiySQATBZk0nl9MHPkBEWUoEtYjyrPFNwGzfdlD37Zdu98KCv%2BMmD2BYpUCvcST39e0%2BS1Wr249FAAg7mPzWrS5NstEbE0xrsiA6QN1PfRFLnhr%2BspxVJTlY8Mw1DqNXeyCQFREEXz9cHB0QOev73QaNhOF4B%2B45PHFHFgDhJTqjuubJFqX1KQco7NTTuW8kq95k2G4eLEGzM7lfItnjNeTKcOfV%2FT8hOuV77A9IK0XjgMpCO0ZiuV3L%2F6njCFAOmucGB3OII5XgCXEJTDdZLElVbu3Vz0fWexvL30k0B6ggBACOmIUBAEUKX0dDTvW7RCYcdZPq6n%2FSsQnUO2RuyBRgQ9Rc5mMvJ6CNIj1nXfd9qWAsCkaZzJAk1L8UjVqY737dSjfCGrPHWqXL32Q0mB%2F2BXnke00WaEYv2aTzAbnuV5pcWkDGAAGJmhSafh6hjr%2BW2SVYHrP7bb%2BOdPW%2FUgflGlTM2gaK%2Ft7tp6%2BN6yixdN89DcIwGktIFPABfNbwoQqQWEUnDJzg1g0jDeK5p7Kp7nensXFI7uyAr%2FLyM7fYLnpa6LYScE8vDnot5hrKlslm%2BfE3nVxJgO4o3KcYu%2FF8XM8yFQ27n%2F65Te%2FzKl3Jhpjj6TCIDneRD5%2FItxr1vdkALw7p1qfeWPpjHxMtsXaPxu6FLc%2BrnbSB1r7fcrlr36nqwMzQfnplJDryQCGOh%2FbLjhcM%2FEvQ4Pdund9xRV5m1LfTXaF%2BK9gsLGB9nsgddcz8thM%2FarPzYM8%2FFazf9sMFaU%2Fi%2FwvNANwEhPvUGR8ozn7d%2BiDKXixtKpbHp81nV9E7puRy31ixKUbOe%2Fv3Ud891ghhDrL5Z975eaOvV%2BCNRp0Gfz%2BcJjDABdTwlpdfKbId0t5XYAcHz5D5ZVtWUp9%2Flog2L7PgVJqZx0HOE5Cqghemv1%2Bt%2FeGBmZ%2BdB2yNN72UEpnzXG32YADA186i3bIpPxMhuKrFK%2Fd77JUnbkKbYvRJlC8DzKSZK76Lq1he2dKy%2BZuSfesSz5a2xHDbLJ%2BJaqdv5H4EUY%2BzbG2m9HgN7mg81bfw4W1uu7AjvHaqDhqF%2FZ3Fq5XFy%2FcESSDsx5fvZ7wLEsNfXk%2BjlVHfpSCOB%2FAQAA%2F%2F8zd8orZc2N9AAAAABJRU5ErkJggg%3D%3D
[fossa-badge]: https://app.fossa.com/api/projects/git%2Bgithub.com%2Fcloudnative-pg%2Fcloudnative-pg.svg?type=small
[fossa]: https://app.fossa.com/projects/git%2Bgithub.com%2Fcloudnative-pg%2Fcloudnative-pg?ref=badge_small
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>