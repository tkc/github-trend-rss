<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Wed, 19 Mar 2025 00:05:26 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[glanceapp/glance]]></title>
            <link>https://github.com/glanceapp/glance</link>
            <guid>https://github.com/glanceapp/glance</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[A self-hosted dashboard that puts all your feeds in one place]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/glanceapp/glance">glanceapp/glance</a></h1>
            <p>A self-hosted dashboard that puts all your feeds in one place</p>
            <p>Language: Go</p>
            <p>Stars: 18,280</p>
            <p>Forks: 650</p>
            <p>Stars today: 2,158 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;em&gt;What if you could see everything at a...&lt;/em&gt;&lt;/p&gt;
&lt;h1 align=&quot;center&quot;&gt;Glance&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;#installation&quot;&gt;Install&lt;/a&gt; • &lt;a href=&quot;docs/configuration.md&quot;&gt;Configuration&lt;/a&gt; • &lt;a href=&quot;docs/preconfigured-pages.md&quot;&gt;Preconfigured pages&lt;/a&gt; • &lt;a href=&quot;docs/themes.md&quot;&gt;Themes&lt;/a&gt; • &lt;a href=&quot;https://discord.com/invite/7KQ7Xa9kJd&quot;&gt;Discord&lt;/a&gt;&lt;/p&gt;

![](docs/images/readme-main-image.png)

## Features
### Various widgets
* RSS feeds
* Subreddit posts
* Hacker News posts
* Weather forecasts
* YouTube channel uploads
* Twitch channels
* Market prices
* Docker containers status
* Server stats
* Custom widgets
* [and many more...](docs/configuration.md)

### Fast and lightweight
* Low memory usage
* Few dependencies
* Minimal vanilla JS
* Single &lt;20mb binary available for multiple OSs &amp; architectures and just as small Docker container
* Uncached pages usually load within ~1s (depending on internet speed and number of widgets)

### Tons of customizability
* Different layouts
* As many pages/tabs as you need
* Numerous configuration options for each widget
* Multiple styles for some widgets
* Custom CSS

### Optimized for mobile devices
Because you&#039;ll want to take it with you on the go.

![](docs/images/mobile-preview.png)

### Themeable
Easily create your own theme by tweaking a few numbers or choose from one of the [already available themes](docs/themes.md).

![](docs/images/themes-example.png)

&lt;br&gt;

## Configuration
Configuration is done through YAML files, to learn more about how the layout works, how to add more pages and how to configure widgets, visit the [configuration documentation](docs/configuration.md).

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Preview example configuration file&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

```yaml
pages:
  - name: Home
    columns:
      - size: small
        widgets:
          - type: calendar
            first-day-of-week: monday

          - type: rss
            limit: 10
            collapse-after: 3
            cache: 12h
            feeds:
              - url: https://selfh.st/rss/
                title: selfh.st
                limit: 4
              - url: https://ciechanow.ski/atom.xml
              - url: https://www.joshwcomeau.com/rss.xml
                title: Josh Comeau
              - url: https://samwho.dev/rss.xml
              - url: https://ishadeed.com/feed.xml
                title: Ahmad Shadeed

          - type: twitch-channels
            channels:
              - theprimeagen
              - j_blow
              - piratesoftware
              - cohhcarnage
              - christitustech
              - EJ_SA

      - size: full
        widgets:
          - type: group
            widgets:
              - type: hacker-news
              - type: lobsters

          - type: videos
            channels:
              - UCXuqSBlHAE6Xw-yeJA0Tunw # Linus Tech Tips
              - UCR-DXc1voovS8nhAvccRZhg # Jeff Geerling
              - UCsBjURrPoezykLs9EqgamOA # Fireship
              - UCBJycsmduvYEL83R_U4JriQ # Marques Brownlee
              - UCHnyfMqiRRG1u-2MsSQLbXA # Veritasium

          - type: group
            widgets:
              - type: reddit
                subreddit: technology
                show-thumbnails: true
              - type: reddit
                subreddit: selfhosted
                show-thumbnails: true

      - size: small
        widgets:
          - type: weather
            location: London, United Kingdom
            units: metric
            hour-format: 12h

          - type: markets
            markets:
              - symbol: SPY
                name: S&amp;P 500
              - symbol: BTC-USD
                name: Bitcoin
              - symbol: NVDA
                name: NVIDIA
              - symbol: AAPL
                name: Apple
              - symbol: MSFT
                name: Microsoft

          - type: releases
            cache: 1d
            repositories:
              - glanceapp/glance
              - go-gitea/gitea
              - immich-app/immich
              - syncthing/syncthing
```
&lt;/details&gt;

&lt;br&gt;

## Installation

Choose one of the following methods:

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Docker compose using provided directory structure (recommended)&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

Create a new directory called `glance` as well as the template files within it by running:

```bash
mkdir glance &amp;&amp; cd glance &amp;&amp; curl -sL https://github.com/glanceapp/docker-compose-template/archive/refs/heads/main.tar.gz | tar -xzf - --strip-components 2
```

*[click here to view the files that will be created](https://github.com/glanceapp/docker-compose-template/tree/main/root)*

Then, edit the following files as desired:
* `docker-compose.yml` to configure the port, volumes and other containery things
* `config/home.yml` to configure the widgets or layout of the home page
* `config/glance.yml` if you want to change the theme or add more pages

&lt;details&gt;
&lt;summary&gt;Other files you may want to edit&lt;/summary&gt;

* `.env` to configure environment variables that will be available inside configuration files
* `assets/user.css` to add custom CSS
&lt;/details&gt;

When ready, run:

```bash
docker compose up -d
```

If you encounter any issues, you can check the logs by running:

```bash
docker compose logs
```

&lt;hr&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Docker compose manual&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

Create a `docker-compose.yml` file with the following contents:

```yaml
services:
  glance:
    container_name: glance
    image: glanceapp/glance
    volumes:
      - ./config:/app/config
    ports:
      - 8080:8080
```

Then, create a new directory called `config` and download the example starting [`glance.yml`](https://github.com/glanceapp/glance/blob/main/docs/glance.yml) file into it by running:

```bash
mkdir config &amp;&amp; wget -O config/glance.yml https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml
```

Feel free to edit the `glance.yml` file to your liking, and when ready run:

```bash
docker compose up -d
```

If you encounter any issues, you can check the logs by running:

```bash
docker logs glance
```

&lt;hr&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Manual binary installation&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

Precompiled binaries are available for Linux, Windows and macOS (x86, x86_64, ARM and ARM64 architectures).

### Linux

Visit the [latest release page](https://github.com/glanceapp/glance/releases/latest) for available binaries. You can place the binary in `/opt/glance/` and have it start with your server via a [systemd service](https://linuxhandbook.com/create-systemd-services/). By default, when running the binary, it will look for a `glance.yml` file in the directory it&#039;s placed in. To specify a different path for the config file, use the `--config` option:

```bash
/opt/glance/glance --config /etc/glance.yml
```

To grab a starting template for the config file, run:

```bash
wget https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml
```

### Windows

Download and extract the executable from the [latest release](https://github.com/glanceapp/glance/releases/latest) (most likely the file called `glance-windows-amd64.zip` if you&#039;re on a 64-bit system) and place it in a folder of your choice. Then, create a new text file called `glance.yml` in the same folder and paste the content from [here](https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml) in it. You should then be able to run the executable and access the dashboard by visiting `http://localhost:8080` in your browser.



&lt;hr&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Other&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

Glance can also be installed through the following 3rd party channels:
* [Proxmox VE Helper Script](https://community-scripts.github.io/ProxmoxVE/scripts?id=glance)
* [NixOS package](https://search.nixos.org/packages?channel=unstable&amp;show=glance)
* [Coolify.io](https://coolify.io/docs/services/glance/)

&lt;hr&gt;
&lt;/details&gt;

&lt;br&gt;

## Building from source

Choose one of the following methods:

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Build binary with Go&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

Requirements: [Go](https://go.dev/dl/) &gt;= v1.23

To build the project for your current OS and architecture, run:

```bash
go build -o build/glance .
```

To build for a specific OS and architecture, run:

```bash
GOOS=linux GOARCH=amd64 go build -o build/glance .
```

[*click here for a full list of GOOS and GOARCH combinations*](https://go.dev/doc/install/source#:~:text=$GOOS%20and%20$GOARCH)

Alternatively, if you just want to run the app without creating a binary, like when you&#039;re testing out changes, you can run:

```bash
go run .
```
&lt;hr&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Build project and Docker image with Docker&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

Requirements: [Docker](https://docs.docker.com/engine/install/)

To build the project and image using just Docker, run:

*(replace `owner` with your name or organization)*

```bash
docker build -t owner/glance:latest .
```

If you wish to push the image to a registry (by default Docker Hub), run:

```bash
docker push owner/glance:latest
```

&lt;hr&gt;
&lt;/details&gt;

&lt;br&gt;

## FAQ
&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Does the information on the page update automatically?&lt;/strong&gt;&lt;/summary&gt;
No, a page refresh is required to update the information. Some things do dynamically update where it makes sense, like the clock widget and the relative time showing how long ago something happened.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;How frequently do widgets update?&lt;/strong&gt;&lt;/summary&gt;
No requests are made periodically in the background, information is only fetched upon loading the page and then cached. The default cache lifetime is different for each widget and can be configured.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Can I create my own widgets?&lt;/strong&gt;&lt;/summary&gt;

Yes, there are multiple ways to create custom widgets:
* `iframe` widget - allows you to embed things from other websites
* `html` widget - allows you to insert your own static HTML
* `extension` widget - fetch HTML from a URL
* `custom-api` widget - fetch JSON from a URL and render it using custom HTML
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Can I change the title of a widget?&lt;/strong&gt;&lt;/summary&gt;

Yes, the title of all widgets can be changed by specifying the `title` property in the widget&#039;s configuration:

```yaml
- type: rss
  title: My custom title

- type: markets
  title: My custom title

- type: videos
  title: My custom title

# and so on for all widgets...
```
&lt;/details&gt;

&lt;br&gt;

## Feature requests

New feature suggestions are always welcome and will be considered, though please keep in mind that some of them may be out of scope for what the project is trying to achieve (or is reasonably capable of). If you have an idea for a new feature and would like to share it, you can do so [here](https://github.com/glanceapp/glance/issues/new?template=feature_request.yml).

Feature requests are tagged with one of the following:

* [Roadmap](https://github.com/glanceapp/glance/labels/roadmap) - will be implemented in a future release
* [Backlog](https://github.com/glanceapp/glance/labels/backlog) - may be implemented in the future but needs further feedback or interest from the community
* [Icebox](https://github.com/glanceapp/glance/labels/icebox) - no plans to implement as it doesn&#039;t currently align with the project&#039;s goals or capabilities, may be revised at a later date

&lt;br&gt;

## Contributing guidelines

* Before working on a new feature it&#039;s preferable to submit a feature request first and state that you&#039;d like to implement it yourself
* Please don&#039;t submit PRs for feature requests that are either in the roadmap&lt;sup&gt;[1]&lt;/sup&gt;, backlog&lt;sup&gt;[2]&lt;/sup&gt; or icebox&lt;sup&gt;[3]&lt;/sup&gt;
* Use `dev` for the base branch if you&#039;re adding new features or fixing bugs, otherwise use `main`
* Avoid introducing new dependencies
* Avoid making backwards-incompatible configuration changes
* Avoid introducing new colors or hard-coding colors, use the standard `primary`, `positive` and `negative`
* For icons, try to use [heroicons](https://heroicons.com/) where applicable
* Provide a screenshot of the changes if UI related where possible
* No `package.json`

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;&lt;sup&gt;[1] [2] [3]&lt;/sup&gt;&lt;/strong&gt;&lt;/summary&gt;

[1] The feature likely already has work put into it that may conflict with your implementation

[2] The demand, implementation or functionality for this feature is not yet clear

[3] No plans to add this feature for the time being

&lt;/details&gt;

&lt;br&gt;

## Thank you

To all the people who were generous enough to [sponsor](https://github.com/sponsors/glanceapp) the project and to everyone who has contributed in any way, be it PRs, submitting issues, helping others in the discussions or Discord server, creating guides and tools or just mentioning Glance on social media. Your support is greatly appreciated and helps keep the project going.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[DiceDB/dice]]></title>
            <link>https://github.com/DiceDB/dice</link>
            <guid>https://github.com/DiceDB/dice</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[DiceDB is an open-source, fast, reactive, in-memory database optimized for modern hardware.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DiceDB/dice">DiceDB/dice</a></h1>
            <p>DiceDB is an open-source, fast, reactive, in-memory database optimized for modern hardware.</p>
            <p>Language: Go</p>
            <p>Stars: 8,932</p>
            <p>Forks: 1,244</p>
            <p>Stars today: 462 stars today</p>
            <h2>README</h2><pre>DiceDB
===

&lt;a href=&quot;https://dicedb.io&quot;&gt;![slatedb.io](https://img.shields.io/badge/site-dicedb.io-00A1FF?style=flat-square)&lt;/a&gt;
&lt;a href=&quot;https://dicedb.io/get-started/installation/&quot;&gt;![Docs](https://img.shields.io/badge/docs-00A1FF?style=flat-square)&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://discord.gg/6r8uXWtXh7&quot;&gt;&lt;img src=&quot;https://dcbadge.limes.pink/api/server/6r8uXWtXh7?style=flat&quot; alt=&quot;discord community&quot; /&gt;&lt;/a&gt;
[![License](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)](LICENSE)

### What is DiceDB?

DiceDB is an open-source, fast, reactive, in-memory database optimized for modern hardware. Commonly used as a cache, it offers a familiar interface while enabling real-time data updates through query subscriptions. It delivers higher throughput and lower median latencies, making it ideal for modern workloads.

## Get started

### Setting up DiceDB with Docker

The easiest way to get started with DiceDB is using [Docker](https://www.docker.com/) by running the following command.

```bash
$ docker run -p 7379:7379 dicedb/dicedb:latest
```

The above command will start the DiceDB server running locally on the port `7379` and you can connect
to it using [DiceDB CLI](https://github.com/DiceDB/dicedb-cli) and SDKs.

### Build from source

To build DiceDB from source, you need to have the following

1. [Golang](https://go.dev/)
2. Any of the below supported platform environments:
    1. [Linux based environment](https://en.wikipedia.org/wiki/Comparison_of_Linux_distributions)
    2. [OSX (Darwin) based environment](https://en.wikipedia.org/wiki/MacOS)
    3. WSL under Windows

```sh
$ git clone https://github.com/dicedb/dice
$ cd dice
$ make build
```

The above command will create a binary `dicedb`. Execute the binary and that will
start the DiceDB server., or, you can run the following command to run like a usual
Go program

```sh
$ go run main.go
```

You can skip passing the flag if you are not working with `.WATCH` feature.

## Setting up CLI

### Using cURL

The best way to connect to DiceDB is using [DiceDB CLI](https://github.com/DiceDB/dicedb-cli) and you can install it by running the following command

```bash
$ sudo su
$ curl -sL https://raw.githubusercontent.com/DiceDB/dicedb-cli/refs/heads/master/install.sh | sh
```

If you are working on unsupported OS (as per above script), you can always follow the installation instructions mentioned in the [dicedb/cli](https://github.com/DiceDB/dicedb-cli) repository.

### Building from source

```sh
$ git clone https://github.com/DiceDB/dicedb-cli
$ cd dicedb-cli
$ make build
```

The above command will create a binary `dicedb-cli`. Execute the binary will
start the CLI and will try to connect to the DiceDB server.

## Want to contribute?

We have multiple repositories where you can contribute. So, as per your interest, you can pick one and build a deeper understanding of the project on the go.

- [dicedb/dice](https://github.com/dicedb/dice) for core database features and engine / Stack - Go
- [dicedb/dicedb-cli](https://github.com/dicedb/dicedb-cli) command line interface for DiceDB / Stack - Go
- [dicedb/dicedb-go](https://github.com/dicedb/dicedb-go) Go Client for DiceDB

## Essentials for Development

### Pointing to local checked-out `dicedb-go`

It is advised to checkout [dicedb-go](https://github.com/DiceDB/dicedb-go) repository also because `dice` takes
a strong dependency on it. To point to the local copy add the following line
at the end of the `go.mod` file.

```
replace github.com/dicedb/dicedb-go =&gt; ../dicedb-go
```

Note: this is the literal line that needs to be added at the end of the go.mod file.
Refer to [this article](https://thewebivore.com/using-replace-in-go-mod-to-point-to-your-local-module/), to understand what it is and why it is needed.

Do not check-in the `go.mod` file with this change.

### Install GoLangCI

```bash
$ sudo su
$ sudo curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sudo sh -s -- -b /bin v1.64.6
```

### Local Setup with Custom Config

Follow these steps to generate and customize your dicedb configuration in a local setup:

```bash
$ go run main.go config-init
```

This will generate configuration file (`dicedb.yaml`) in metadata directory.
Metadata directory is OS-specific,

 - macOS: `/usr/local/etc/dicedb/dicedb.yaml`
 - Linux: `/etc/dicedb/dicedb.yaml`

If you run with a `sudo` privileges, then these directories are used, otherwise
the current working directory is used as the metada directory.

### Running Tests

Unit tests and integration tests are essential for ensuring correctness and in the case of DiceDB, both types of tests are available to validate its functionality.

For unit testing, you can execute individual unit tests by specifying the name of the test function using the `TEST_FUNC` environment variable and running the `make unittest-one` command. Alternatively, running `make unittest` will execute all unit tests.

### Executing one unit test

```bash
TEST_FUNC=&lt;name of the test function&gt; make unittest-one
TEST_FUNC=TestByteList make unittest-one
```

### Running all unit tests

```bash
make unittest
```

Integration tests, on the other hand, involve starting up the DiceDB server and running a series of commands to verify the expected end state and output. To execute a single integration test, you can set the `TEST_FUNC` environment variable to the name of the test function and run `make test-one`. Running `make test` will execute all integration tests.

### Executing a single integration test

Make sure you have DiceDB running before you run the following commands.
By default it connects to the local instance of DiceDB running on port `7379`.

```bash
TEST_FUNC=&lt;name of the test function&gt; make test-one
TEST_FUNC=^TestSet$ make test-one
```

### Running all integration tests

```bash
$ make test
```

## Getting Started

To get started with building and contributing to DiceDB, please refer to the [issues](https://github.com/DiceDB/dice/issues) created in this repository.

## Docs

We use [Astro](https://astro.build/) framework to power the [dicedb.io website](https://dicedb.io) and [Starlight](https://starlight.astro.build/) to power the docs. Once you have NodeJS installed, fire the following commands to get your local version of [dicedb.io](https://dicedb.io) running.

```bash
$ cd docs
$ npm install
$ npm run dev
```

Once the server starts, visit http://localhost:4321/ in your favourite browser. This runs with a hot reload which means any changes you make in the website and the documentation can be instantly viewed on the browser.

### Docs directory structure

1. `docs/src/content/docs/commands` is where all the commands are documented
2. `docs/src/content/docs/tutorials` is where all the tutorials are documented

## How to contribute

The Code Contribution Guidelines are published at [CONTRIBUTING/README.md](CONTRIBUTING/README.md); please read them before you start making any changes. This would allow us to have a consistent standard of coding practices and developer experience.

Contributors can join the [Discord Server](https://discord.gg/6r8uXWtXh7) for quick collaboration.

## Contributors

&lt;a href = &quot;https://github.com/dicedb/dice/graphs/contributors&quot;&gt;
  &lt;img src = &quot;https://contrib.rocks/image?repo=dicedb/dice&quot;/&gt;
&lt;/a&gt;

## License

This project is licensed under the BSD 3-Clause License. See the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[prometheus/prometheus]]></title>
            <link>https://github.com/prometheus/prometheus</link>
            <guid>https://github.com/prometheus/prometheus</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[The Prometheus monitoring system and time series database.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prometheus/prometheus">prometheus/prometheus</a></h1>
            <p>The Prometheus monitoring system and time series database.</p>
            <p>Language: Go</p>
            <p>Stars: 57,750</p>
            <p>Forks: 9,450</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot; style=&quot;border-bottom: none&quot;&gt;
    &lt;a href=&quot;https://prometheus.io&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Prometheus&quot; src=&quot;/documentation/images/prometheus-logo.svg&quot;&gt;&lt;/a&gt;&lt;br&gt;Prometheus
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;Visit &lt;a href=&quot;https://prometheus.io&quot; target=&quot;_blank&quot;&gt;prometheus.io&lt;/a&gt; for the full documentation,
examples and guides.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![CI](https://github.com/prometheus/prometheus/actions/workflows/ci.yml/badge.svg)](https://github.com/prometheus/prometheus/actions/workflows/ci.yml)
[![Docker Repository on Quay](https://quay.io/repository/prometheus/prometheus/status)][quay]
[![Docker Pulls](https://img.shields.io/docker/pulls/prom/prometheus.svg?maxAge=604800)][hub]
[![Go Report Card](https://goreportcard.com/badge/github.com/prometheus/prometheus)](https://goreportcard.com/report/github.com/prometheus/prometheus)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/486/badge)](https://bestpractices.coreinfrastructure.org/projects/486)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/prometheus/prometheus/badge)](https://securityscorecards.dev/viewer/?uri=github.com/prometheus/prometheus)
[![CLOMonitor](https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/prometheus/badge)](https://clomonitor.io/projects/cncf/prometheus)
[![Gitpod ready-to-code](https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod)](https://gitpod.io/#https://github.com/prometheus/prometheus)
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/prometheus.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:prometheus)

&lt;/div&gt;

Prometheus, a [Cloud Native Computing Foundation](https://cncf.io/) project, is a systems and service monitoring system. It collects metrics
from configured targets at given intervals, evaluates rule expressions,
displays the results, and can trigger alerts when specified conditions are observed.

The features that distinguish Prometheus from other metrics and monitoring systems are:

* A **multi-dimensional** data model (time series defined by metric name and set of key/value dimensions)
* PromQL, a **powerful and flexible query language** to leverage this dimensionality
* No dependency on distributed storage; **single server nodes are autonomous**
* An HTTP **pull model** for time series collection
* **Pushing time series** is supported via an intermediary gateway for batch jobs
* Targets are discovered via **service discovery** or **static configuration**
* Multiple modes of **graphing and dashboarding support**
* Support for hierarchical and horizontal **federation**

## Architecture overview

![Architecture overview](documentation/images/architecture.svg)

## Install

There are various ways of installing Prometheus.

### Precompiled binaries

Precompiled binaries for released versions are available in the
[*download* section](https://prometheus.io/download/)
on [prometheus.io](https://prometheus.io). Using the latest production release binary
is the recommended way of installing Prometheus.
See the [Installing](https://prometheus.io/docs/introduction/install/)
chapter in the documentation for all the details.

### Docker images

Docker images are available on [Quay.io](https://quay.io/repository/prometheus/prometheus) or [Docker Hub](https://hub.docker.com/r/prom/prometheus/).

You can launch a Prometheus container for trying it out with

```bash
docker run --name prometheus -d -p 127.0.0.1:9090:9090 prom/prometheus
```

Prometheus will now be reachable at &lt;http://localhost:9090/&gt;.

### Building from source

To build Prometheus from source code, You need:

* Go [version 1.22 or greater](https://golang.org/doc/install).
* NodeJS [version 22 or greater](https://nodejs.org/).
* npm [version 8 or greater](https://www.npmjs.com/).

Start by cloning the repository:

```bash
git clone https://github.com/prometheus/prometheus.git
cd prometheus
```

You can use the `go` tool to build and install the `prometheus`
and `promtool` binaries into your `GOPATH`:

```bash
GO111MODULE=on go install github.com/prometheus/prometheus/cmd/...
prometheus --config.file=your_config.yml
```

*However*, when using `go install` to build Prometheus, Prometheus will expect to be able to
read its web assets from local filesystem directories under `web/ui/static` and
`web/ui/templates`. In order for these assets to be found, you will have to run Prometheus
from the root of the cloned repository. Note also that these directories do not include the
React UI unless it has been built explicitly using `make assets` or `make build`.

An example of the above configuration file can be found [here.](https://github.com/prometheus/prometheus/blob/main/documentation/examples/prometheus.yml)

You can also build using `make build`, which will compile in the web assets so that
Prometheus can be run from anywhere:

```bash
make build
./prometheus --config.file=your_config.yml
```

The Makefile provides several targets:

* *build*: build the `prometheus` and `promtool` binaries (includes building and compiling in web assets)
* *test*: run the tests
* *test-short*: run the short tests
* *format*: format the source code
* *vet*: check the source code for common errors
* *assets*: build the React UI

### Service discovery plugins

Prometheus is bundled with many service discovery plugins.
When building Prometheus from source, you can edit the [plugins.yml](./plugins.yml)
file to disable some service discoveries. The file is a yaml-formatted list of go
import path that will be built into the Prometheus binary.

After you have changed the file, you
need to run `make build` again.

If you are using another method to compile Prometheus, `make plugins` will
generate the plugins file accordingly.

If you add out-of-tree plugins, which we do not endorse at the moment,
additional steps might be needed to adjust the `go.mod` and `go.sum` files. As
always, be extra careful when loading third party code.

### Building the Docker image

The `make docker` target is designed for use in our CI system.
You can build a docker image locally with the following commands:

```bash
make promu
promu crossbuild -p linux/amd64
make npm_licenses
make common-docker-amd64
```

## Using Prometheus as a Go Library

### Remote Write

We are publishing our Remote Write protobuf independently at
[buf.build](https://buf.build/prometheus/prometheus/assets).

You can use that as a library:

```shell
go get buf.build/gen/go/prometheus/prometheus/protocolbuffers/go@latest
```

This is experimental.

### Prometheus code base

In order to comply with [go mod](https://go.dev/ref/mod#versions) rules,
Prometheus release number do not exactly match Go module releases.

For the
Prometheus v3.y.z releases, we are publishing equivalent v0.3y.z tags. The y in v0.3y.z is always padded to two digits, with a leading zero if needed.

Therefore, a user that would want to use Prometheus v3.0.0 as a library could do:

```shell
go get github.com/prometheus/prometheus@v0.300.0
```

For the
Prometheus v2.y.z releases, we published the equivalent v0.y.z tags.

Therefore, a user that would want to use Prometheus v2.35.0 as a library could do:

```shell
go get github.com/prometheus/prometheus@v0.35.0
```

This solution makes it clear that we might break our internal Go APIs between
minor user-facing releases, as [breaking changes are allowed in major version
zero](https://semver.org/#spec-item-4).

## React UI Development

For more information on building, running, and developing on the React-based UI, see the React app&#039;s [README.md](web/ui/README.md).

## More information

* Godoc documentation is available via [pkg.go.dev](https://pkg.go.dev/github.com/prometheus/prometheus). Due to peculiarities of Go Modules, v3.y.z will be displayed as v0.3y.z (the y in v0.3y.z is always padded to two digits, with a leading zero if needed), while v2.y.z will be displayed as v0.y.z.
* See the [Community page](https://prometheus.io/community) for how to reach the Prometheus developers and users on various communication channels.

## Contributing

Refer to [CONTRIBUTING.md](https://github.com/prometheus/prometheus/blob/main/CONTRIBUTING.md)

## License

Apache License 2.0, see [LICENSE](https://github.com/prometheus/prometheus/blob/main/LICENSE).

[hub]: https://hub.docker.com/r/prom/prometheus/
[quay]: https://quay.io/repository/prometheus/prometheus
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ent/ent]]></title>
            <link>https://github.com/ent/ent</link>
            <guid>https://github.com/ent/ent</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[An entity framework for Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ent/ent">ent/ent</a></h1>
            <p>An entity framework for Go</p>
            <p>Language: Go</p>
            <p>Stars: 15,973</p>
            <p>Forks: 955</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>## ent - An Entity Framework For Go

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/entgo_io.svg?style=social&amp;label=Follow%20%40entgo_io)](https://twitter.com/entgo_io)
[![Discord](https://img.shields.io/discord/885059418646003782?label=discord&amp;logo=discord&amp;style=flat-square&amp;logoColor=white)](https://discord.gg/qZmPgTE6RX)

[English](README.md) | [中文](README_zh.md) | [日本語](README_jp.md) | [한국어](README_kr.md)

&lt;img width=&quot;50%&quot;
align=&quot;right&quot;
style=&quot;display: block; margin:40px auto;&quot;
src=&quot;https://s3.eu-central-1.amazonaws.com/entgo.io/assets/gopher_graph.png&quot;/&gt;

Simple, yet powerful entity framework for Go, that makes it easy to build and maintain applications
with large data-models.

- **Schema As Code** - model any database schema as Go objects.
- **Easily Traverse Any Graph** - run queries, aggregations and traverse any graph structure easily.
- **Statically Typed And Explicit API** - 100% statically typed and explicit API using code generation.
- **Multi Storage Driver** - supports MySQL, MariaDB, TiDB, PostgreSQL, CockroachDB, SQLite and Gremlin.
- **Extendable** - simple to extend and customize using Go templates.

## Quick Installation
```console
go install entgo.io/ent/cmd/ent@latest
```

For proper installation using [Go modules], visit [entgo.io website][entgo install].

## Docs and Support
The documentation for developing and using ent is available at: https://entgo.io

For discussion and support, [open an issue](https://github.com/ent/ent/issues/new/choose) or join our [Discord server](https://discord.gg/qZmPgTE6RX).

## Developed and Sponsored by the [Atlas](https://atlasgo.io) Team

[![image](https://github.com/user-attachments/assets/2a35b1b7-325f-4844-a2d7-d450c60de0dc)](https://atlasgo.io?utm_source=ent-readme)

## About the Project
The `ent` project was inspired by Ent, an entity framework used internally at Meta (Facebook). It was created by [a8m](https://github.com/a8m) and [alexsn](https://github.com/alexsn) from the [Facebook Connectivity][fbc] team. These days, it is developed and maintained by the [Atlas](https://github.com/ariga/atlas) team, and the roadmap for its v1 release is described [here](https://github.com/ent/ent/issues/46).

## Join the ent Community
Building `ent` would not have been possible without the collective work of our entire community. We maintain a [contributors page](doc/md/contributors.md)
which lists the contributors to this `ent`. 

In order to contribute to `ent`, see the [CONTRIBUTING](CONTRIBUTING.md) file for how to go get started.
If your company or your product is using `ent`, please let us know by adding yourself to the [ent users page](https://github.com/ent/ent/wiki/ent-users).

For updates, follow us on Twitter at https://twitter.com/entgo_io

## License
ent is licensed under Apache 2.0 as found in the [LICENSE file](LICENSE).


[entgo install]: https://entgo.io/docs/code-gen/#version-compatibility-between-entc-and-ent
[Go modules]: https://github.com/golang/go/wiki/Modules#quick-start
[fbc]: https://connectivity.fb.com
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ehang-io/nps]]></title>
            <link>https://github.com/ehang-io/nps</link>
            <guid>https://github.com/ehang-io/nps</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[一款轻量级、高性能、功能强大的内网穿透代理服务器。支持tcp、udp、socks5、http等几乎所有流量转发，可用来访问内网网站、本地支付接口调试、ssh访问、远程桌面，内网dns解析、内网socks5代理等等……，并带有功能强大的web管理端。a lightweight, high-performance, powerful intranet penetration proxy server, with a powerful web management terminal.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ehang-io/nps">ehang-io/nps</a></h1>
            <p>一款轻量级、高性能、功能强大的内网穿透代理服务器。支持tcp、udp、socks5、http等几乎所有流量转发，可用来访问内网网站、本地支付接口调试、ssh访问、远程桌面，内网dns解析、内网socks5代理等等……，并带有功能强大的web管理端。a lightweight, high-performance, powerful intranet penetration proxy server, with a powerful web management terminal.</p>
            <p>Language: Go</p>
            <p>Stars: 31,466</p>
            <p>Forks: 5,711</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>
# NPS
![](https://img.shields.io/github/stars/ehang-io/nps.svg)   ![](https://img.shields.io/github/forks/ehang-io/nps.svg)
[![Gitter](https://badges.gitter.im/cnlh-nps/community.svg)](https://gitter.im/cnlh-nps/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge)
![Release](https://github.com/ehang-io/nps/workflows/Release/badge.svg)
![GitHub All Releases](https://img.shields.io/github/downloads/ehang-io/nps/total)

[README](https://github.com/ehang-io/nps/blob/master/README.md)|[中文文档](https://github.com/ehang-io/nps/blob/master/README_zh.md)

NPS is a lightweight, high-performance, powerful **intranet penetration** proxy server, with a powerful web management terminal.


![image](https://github.com/ehang-io/nps/blob/master/image/web.png?raw=true)

## Feature

- Comprehensive protocol support, compatible with almost all commonly used protocols, such as tcp, udp, http(s), socks5, p2p, http proxy ...
- Full platform compatibility (linux, windows, macos, Synology, etc.), support installation as a system service simply.
- Comprehensive control, both client and server control are allowed.
- Https integration, support to convert backend proxy and web services to https, and support multiple certificates.
- Just simple configuration on web ui can complete most requirements.
- Complete information display, such as traffic, system information, real-time bandwidth, client version, etc.
- Powerful extension functions, everything is available (cache, compression, encryption, traffic limit, bandwidth limit, port reuse, etc.)
- Domain name resolution has functions such as custom headers, 404 page configuration, host modification, site protection, URL routing, and pan-resolution.
- Multi-user and user registration support on server.

**Didn&#039;t find the feature you want? It doesn&#039;t matter, click [Enter the document](https://ehang-io.github.io/nps/) to find it!**

## Quick start

### Installation

&gt; [releases](https://github.com/ehang-io/nps/releases)

Download the corresponding system version, the server and client are separate.

### Server start

After downloading the server compressed package, unzip it, and then enter the unzipped folder.

- execute installation command

For linux、darwin ```sudo ./nps install```

For windows, run cmd as administrator and enter the installation directory ```nps.exe install```

- default ports

The default configuration file of nps use 80，443，8080，8024 ports

80 and 443 ports for host mode default ports

8080 for web management access port

8024 for net bridge port, to communicate between server and client

- start up

For linux、darwin ```sudo nps start```

For windows, run cmd as administrator and enter the program directory ```nps.exe start```

```After installation, the windows configuration file is located at C:\Program Files\nps, linux or darwin is located at /etc/nps```

**If you don&#039;t find it started successfully, you can check the log (Windows log files are located in the current running directory, linux and darwin are located in /var/log/nps.log).**

- Access server IP:web service port (default is 8080).
- Login with username and password (default is admin/123, must be modified when officially used).
- Create a client.

### Client connection
- Click the + sign in front of the client in web management and copy the startup command.
- Execute the startup command, Linux can be executed directly, Windows will replace ./npc with npc.exe and execute it with cmd.


If you need to register to the system service, you can check [Register to the system service](https://ehang-io.github.io/nps/#/use?id=注册到系统服务)

### Configuration
- After the client connects, configure the corresponding penetration service in the web.
- For more advanced usage, see [Complete Documentation](https://ehang-io.github.io/nps/)

## Contribution
- If you encounter a bug, you can submit it to the dev branch directly.
- If you encounter a problem, you can feedback through the issue.
- The project is under development, and there is still a lot of room for improvement. If you can contribute code, please submit PR to the dev branch.
- If there is feedback on new features, you can feedback via issues or qq group.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gofiber/fiber]]></title>
            <link>https://github.com/gofiber/fiber</link>
            <guid>https://github.com/gofiber/fiber</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[⚡️ Express inspired web framework written in Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gofiber/fiber">gofiber/fiber</a></h1>
            <p>⚡️ Express inspired web framework written in Go</p>
            <p>Language: Go</p>
            <p>Stars: 35,450</p>
            <p>Forks: 1,744</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[googleapis/google-cloud-go]]></title>
            <link>https://github.com/googleapis/google-cloud-go</link>
            <guid>https://github.com/googleapis/google-cloud-go</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[Google Cloud Client Libraries for Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/googleapis/google-cloud-go">googleapis/google-cloud-go</a></h1>
            <p>Google Cloud Client Libraries for Go.</p>
            <p>Language: Go</p>
            <p>Stars: 3,897</p>
            <p>Forks: 1,360</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># Google Cloud Client Libraries for Go

[![Go Reference](https://pkg.go.dev/badge/cloud.google.com/go.svg)](https://pkg.go.dev/cloud.google.com/go)

Go packages for [Google Cloud Platform](https://cloud.google.com) services.

## Installation

```bash
go get cloud.google.com/go/firestore@latest # Replace firestore with the package you want to use.
```

**NOTE:** Some of these packages are under development, and may occasionally
make backwards-incompatible changes.

## Supported APIs

For an updated list of all of our released APIs please see our
[reference docs](https://cloud.google.com/go/docs/reference).

## [Go Versions Supported](#supported-versions)

Our libraries are compatible with the two most recent major Go
releases, the same [policy](https://go.dev/doc/devel/release#policy) the Go
programming language follows. This means the currently supported versions are:

- Go 1.23
- Go 1.24

## Authorization

By default, each API will use [Google Application Default Credentials](https://developers.google.com/identity/protocols/application-default-credentials)
for authorization credentials used in calling the API endpoints. This will allow your
application to run in many environments without requiring explicit configuration.

```go
client, err := storage.NewClient(ctx)
```

To authorize using a
[JSON key file](https://cloud.google.com/iam/docs/managing-service-account-keys),
pass
[`option.WithCredentialsFile`](https://pkg.go.dev/google.golang.org/api/option#WithCredentialsFile)
to the `NewClient` function of the desired package. For example:

```go
client, err := storage.NewClient(ctx, option.WithCredentialsFile(&quot;path/to/keyfile.json&quot;))
```

You can exert more control over authorization by using the
[credentials](https://pkg.go.dev/cloud.google.com/go/auth/credentials) package to
create an [auth.Credentials](https://pkg.go.dev/cloud.google.com/go/auth#Credentials).
Then pass [`option.WithAuthCredentials`](https://pkg.go.dev/google.golang.org/api/option#WithAuthCredentials)
to the `NewClient` function:

```go
creds := ...
client, err := storage.NewClient(ctx, option.WithAuthCredentials(creds))
```

## Contributing

Contributions are welcome. Please, see the
[CONTRIBUTING](https://github.com/GoogleCloudPlatform/google-cloud-go/blob/main/CONTRIBUTING.md)
document for details.

Please note that this project is released with a Contributor Code of Conduct.
By participating in this project you agree to abide by its terms.
See [Contributor Code of Conduct](https://github.com/GoogleCloudPlatform/google-cloud-go/blob/main/CONTRIBUTING.md#contributor-code-of-conduct)
for more information.

## Links

- [Go on Google Cloud](https://cloud.google.com/go/home)
- [Getting started with Go on Google Cloud](https://cloud.google.com/go/getting-started)
- [App Engine Quickstart](https://cloud.google.com/appengine/docs/standard/go/quickstart)
- [Cloud Functions Quickstart](https://cloud.google.com/functions/docs/quickstart-go)
- [Cloud Run Quickstart](https://cloud.google.com/run/docs/quickstarts/build-and-deploy#go)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[spf13/viper]]></title>
            <link>https://github.com/spf13/viper</link>
            <guid>https://github.com/spf13/viper</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[Go configuration with fangs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/spf13/viper">spf13/viper</a></h1>
            <p>Go configuration with fangs</p>
            <p>Language: Go</p>
            <p>Stars: 28,082</p>
            <p>Forks: 2,036</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&gt; ## Viper v2 feedback
&gt; Viper is heading towards v2 and we would love to hear what _**you**_ would like to see in it. Share your thoughts here: https://forms.gle/R6faU74qPRPAzchZ9
&gt;
&gt; **Thank you!**

![viper logo](https://github.com/user-attachments/assets/acae9193-2974-41f3-808d-2d433f5ada5e)


[![Mentioned in Awesome Go](https://awesome.re/mentioned-badge-flat.svg)](https://github.com/avelino/awesome-go#configuration)
[![run on repl.it](https://repl.it/badge/github/sagikazarmark/Viper-example)](https://repl.it/@sagikazarmark/Viper-example#main.go)

[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/spf13/viper/ci.yaml?branch=master&amp;style=flat-square)](https://github.com/spf13/viper/actions?query=workflow%3ACI)
[![Join the chat at https://gitter.im/spf13/viper](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/spf13/viper?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge)
[![Go Report Card](https://goreportcard.com/badge/github.com/spf13/viper?style=flat-square)](https://goreportcard.com/report/github.com/spf13/viper)
![Go Version](https://img.shields.io/badge/go%20version-%3E=1.21-61CFDD.svg?style=flat-square)
[![PkgGoDev](https://pkg.go.dev/badge/mod/github.com/spf13/viper)](https://pkg.go.dev/mod/github.com/spf13/viper)

**Go configuration with fangs!**

Many Go projects are built using Viper including:

* [Hugo](http://gohugo.io)
* [EMC RexRay](http://rexray.readthedocs.org/en/stable/)
* [Imgur’s Incus](https://github.com/Imgur/incus)
* [Nanobox](https://github.com/nanobox-io/nanobox)/[Nanopack](https://github.com/nanopack)
* [Docker Notary](https://github.com/docker/Notary)
* [BloomApi](https://www.bloomapi.com/)
* [doctl](https://github.com/digitalocean/doctl)
* [Clairctl](https://github.com/jgsqware/clairctl)
* [Mercure](https://mercure.rocks)
* [Meshery](https://github.com/meshery/meshery)
* [Bearer](https://github.com/bearer/bearer)
* [Coder](https://github.com/coder/coder)
* [Vitess](https://vitess.io/)


## Install

```shell
go get github.com/spf13/viper
```

**Note:** Viper uses [Go Modules](https://go.dev/wiki/Modules) to manage dependencies.


## What is Viper?

Viper is a complete configuration solution for Go applications including [12-Factor apps](https://12factor.net/#the_twelve_factors).
It is designed to work within an application, and can handle all types of configuration needs
and formats. It supports:

* setting defaults
* reading from JSON, TOML, YAML, HCL, envfile and Java properties config files
* live watching and re-reading of config files (optional)
* reading from environment variables
* reading from remote config systems (etcd or Consul), and watching changes
* reading from command line flags
* reading from buffer
* setting explicit values

Viper can be thought of as a registry for all of your applications configuration needs.


## Why Viper?

When building a modern application, you don’t want to worry about
configuration file formats; you want to focus on building awesome software.
Viper is here to help with that.

Viper does the following for you:

1. Find, load, and unmarshal a configuration file in JSON, TOML, YAML, HCL, INI, envfile or Java properties formats.
2. Provide a mechanism to set default values for your different configuration options.
3. Provide a mechanism to set override values for options specified through command line flags.
4. Provide an alias system to easily rename parameters without breaking existing code.
5. Make it easy to tell the difference between when a user has provided a command line or config file which is the same as the default.

Viper uses the following precedence order. Each item takes precedence over the item below it:

 * explicit call to `Set`
 * flag
 * env
 * config
 * key/value store
 * default

**Important:** Viper configuration keys are case insensitive.
There are ongoing discussions about making that optional.


## Putting Values into Viper

### Establishing Defaults

A good configuration system will support default values. A default value is not
required for a key, but it’s useful in the event that a key hasn&#039;t been set via
config file, environment variable, remote configuration or flag.

Examples:

```go
viper.SetDefault(&quot;ContentDir&quot;, &quot;content&quot;)
viper.SetDefault(&quot;LayoutDir&quot;, &quot;layouts&quot;)
viper.SetDefault(&quot;Taxonomies&quot;, map[string]string{&quot;tag&quot;: &quot;tags&quot;, &quot;category&quot;: &quot;categories&quot;})
```

### Reading Config Files

Viper requires minimal configuration so it knows where to look for config files.
Viper supports JSON, TOML, YAML, HCL, INI, envfile and Java Properties files. Viper can search multiple paths, but
currently a single Viper instance only supports a single configuration file.
Viper does not default to any configuration search paths leaving defaults decision
to an application.

Here is an example of how to use Viper to search for and read a configuration file.
None of the specific paths are required, but at least one path should be provided
where a configuration file is expected.

```go
viper.SetConfigName(&quot;config&quot;) // name of config file (without extension)
viper.SetConfigType(&quot;yaml&quot;) // REQUIRED if the config file does not have the extension in the name
viper.AddConfigPath(&quot;/etc/appname/&quot;)   // path to look for the config file in
viper.AddConfigPath(&quot;$HOME/.appname&quot;)  // call multiple times to add many search paths
viper.AddConfigPath(&quot;.&quot;)               // optionally look for config in the working directory
err := viper.ReadInConfig() // Find and read the config file
if err != nil { // Handle errors reading the config file
	panic(fmt.Errorf(&quot;fatal error config file: %w&quot;, err))
}
```

You can handle the specific case where no config file is found like this:

```go
if err := viper.ReadInConfig(); err != nil {
	if _, ok := err.(viper.ConfigFileNotFoundError); ok {
		// Config file not found; ignore error if desired
	} else {
		// Config file was found but another error was produced
	}
}

// Config file found and successfully parsed
```

*NOTE [since 1.6]:* You can also have a file without an extension and specify the format programmatically. For those configuration files that lie in the home of the user without any extension like `.bashrc`

### Writing Config Files

Reading from config files is useful, but at times you want to store all modifications made at run time.
For that, a bunch of commands are available, each with its own purpose:

* WriteConfig - writes the current viper configuration to the predefined path, if exists. Errors if no predefined path. Will overwrite the current config file, if it exists.
* SafeWriteConfig - writes the current viper configuration to the predefined path. Errors if no predefined path. Will not overwrite the current config file, if it exists.
* WriteConfigAs - writes the current viper configuration to the given filepath. Will overwrite the given file, if it exists.
* SafeWriteConfigAs - writes the current viper configuration to the given filepath. Will not overwrite the given file, if it exists.

As a rule of the thumb, everything marked with safe won&#039;t overwrite any file, but just create if not existent, whilst the default behavior is to create or truncate.

A small examples section:

```go
viper.WriteConfig() // writes current config to predefined path set by &#039;viper.AddConfigPath()&#039; and &#039;viper.SetConfigName&#039;
viper.SafeWriteConfig()
viper.WriteConfigAs(&quot;/path/to/my/.config&quot;)
viper.SafeWriteConfigAs(&quot;/path/to/my/.config&quot;) // will error since it has already been written
viper.SafeWriteConfigAs(&quot;/path/to/my/.other_config&quot;)
```

### Watching and re-reading config files

Viper supports the ability to have your application live read a config file while running.

Gone are the days of needing to restart a server to have a config take effect,
viper powered applications can read an update to a config file while running and
not miss a beat.

Simply tell the viper instance to watchConfig.
Optionally you can provide a function for Viper to run each time a change occurs.

**Make sure you add all of the configPaths prior to calling `WatchConfig()`**

```go
viper.OnConfigChange(func(e fsnotify.Event) {
	fmt.Println(&quot;Config file changed:&quot;, e.Name)
})
viper.WatchConfig()
```

### Reading Config from io.Reader

Viper predefines many configuration sources such as files, environment
variables, flags, and remote K/V store, but you are not bound to them. You can
also implement your own required configuration source and feed it to viper.

```go
viper.SetConfigType(&quot;yaml&quot;) // or viper.SetConfigType(&quot;YAML&quot;)

// any approach to require this configuration into your program.
var yamlExample = []byte(`
Hacker: true
name: steve
hobbies:
- skateboarding
- snowboarding
- go
clothing:
  jacket: leather
  trousers: denim
age: 35
eyes : brown
beard: true
`)

viper.ReadConfig(bytes.NewBuffer(yamlExample))

viper.Get(&quot;name&quot;) // this would be &quot;steve&quot;
```

### Setting Overrides

These could be from a command line flag, or from your own application logic.

```go
viper.Set(&quot;Verbose&quot;, true)
viper.Set(&quot;LogFile&quot;, LogFile)
viper.Set(&quot;host.port&quot;, 5899)   // set subset
```

### Registering and Using Aliases

Aliases permit a single value to be referenced by multiple keys

```go
viper.RegisterAlias(&quot;loud&quot;, &quot;Verbose&quot;)

viper.Set(&quot;verbose&quot;, true) // same result as next line
viper.Set(&quot;loud&quot;, true)   // same result as prior line

viper.GetBool(&quot;loud&quot;) // true
viper.GetBool(&quot;verbose&quot;) // true
```

### Working with Environment Variables

Viper has full support for environment variables. This enables 12 factor
applications out of the box. There are five methods that exist to aid working
with ENV:

 * `AutomaticEnv()`
 * `BindEnv(string...) : error`
 * `SetEnvPrefix(string)`
 * `SetEnvKeyReplacer(string...) *strings.Replacer`
 * `AllowEmptyEnv(bool)`

_When working with ENV variables, it’s important to recognize that Viper
treats ENV variables as case sensitive._

Viper provides a mechanism to try to ensure that ENV variables are unique. By
using `SetEnvPrefix`, you can tell Viper to use a prefix while reading from
the environment variables. Both `BindEnv` and `AutomaticEnv` will use this
prefix.

`BindEnv` takes one or more parameters. The first parameter is the key name, the
rest are the name of the environment variables to bind to this key. If more than
one are provided, they will take precedence in the specified order. The name of
the environment variable is case sensitive. If the ENV variable name is not provided, then
Viper will automatically assume that the ENV variable matches the following format: prefix + &quot;_&quot; + the key name in ALL CAPS. When you explicitly provide the ENV variable name (the second parameter),
it **does not** automatically add the prefix. For example if the second parameter is &quot;id&quot;,
Viper will look for the ENV variable &quot;ID&quot;.

One important thing to recognize when working with ENV variables is that the
value will be read each time it is accessed. Viper does not fix the value when
the `BindEnv` is called.

`AutomaticEnv` is a powerful helper especially when combined with
`SetEnvPrefix`. When called, Viper will check for an environment variable any
time a `viper.Get` request is made. It will apply the following rules. It will
check for an environment variable with a name matching the key uppercased and
prefixed with the `EnvPrefix` if set.

`SetEnvKeyReplacer` allows you to use a `strings.Replacer` object to rewrite Env
keys to an extent. This is useful if you want to use `-` or something in your
`Get()` calls, but want your environmental variables to use `_` delimiters. An
example of using it can be found in `viper_test.go`.

Alternatively, you can use `EnvKeyReplacer` with `NewWithOptions` factory function.
Unlike `SetEnvKeyReplacer`, it accepts a `StringReplacer` interface allowing you to write custom string replacing logic.

By default empty environment variables are considered unset and will fall back to
the next configuration source. To treat empty environment variables as set, use
the `AllowEmptyEnv` method.

#### Env example

```go
SetEnvPrefix(&quot;spf&quot;) // will be uppercased automatically
BindEnv(&quot;id&quot;)

os.Setenv(&quot;SPF_ID&quot;, &quot;13&quot;) // typically done outside of the app

id := Get(&quot;id&quot;) // 13
```

### Working with Flags

Viper has the ability to bind to flags. Specifically, Viper supports `Pflags`
as used in the [Cobra](https://github.com/spf13/cobra) library.

Like `BindEnv`, the value is not set when the binding method is called, but when
it is accessed. This means you can bind as early as you want, even in an
`init()` function.

For individual flags, the `BindPFlag()` method provides this functionality.

Example:

```go
serverCmd.Flags().Int(&quot;port&quot;, 1138, &quot;Port to run Application server on&quot;)
viper.BindPFlag(&quot;port&quot;, serverCmd.Flags().Lookup(&quot;port&quot;))
```

You can also bind an existing set of pflags (pflag.FlagSet):

Example:

```go
pflag.Int(&quot;flagname&quot;, 1234, &quot;help message for flagname&quot;)

pflag.Parse()
viper.BindPFlags(pflag.CommandLine)

i := viper.GetInt(&quot;flagname&quot;) // retrieve values from viper instead of pflag
```

The use of [pflag](https://github.com/spf13/pflag/) in Viper does not preclude
the use of other packages that use the [flag](https://golang.org/pkg/flag/)
package from the standard library. The pflag package can handle the flags
defined for the flag package by importing these flags. This is accomplished
by a calling a convenience function provided by the pflag package called
AddGoFlagSet().

Example:

```go
package main

import (
	&quot;flag&quot;
	&quot;github.com/spf13/pflag&quot;
)

func main() {

	// using standard library &quot;flag&quot; package
	flag.Int(&quot;flagname&quot;, 1234, &quot;help message for flagname&quot;)

	pflag.CommandLine.AddGoFlagSet(flag.CommandLine)
	pflag.Parse()
	viper.BindPFlags(pflag.CommandLine)

	i := viper.GetInt(&quot;flagname&quot;) // retrieve value from viper

	// ...
}
```

#### Flag interfaces

Viper provides two Go interfaces to bind other flag systems if you don’t use `Pflags`.

`FlagValue` represents a single flag. This is a very simple example on how to implement this interface:

```go
type myFlag struct {}
func (f myFlag) HasChanged() bool { return false }
func (f myFlag) Name() string { return &quot;my-flag-name&quot; }
func (f myFlag) ValueString() string { return &quot;my-flag-value&quot; }
func (f myFlag) ValueType() string { return &quot;string&quot; }
```

Once your flag implements this interface, you can simply tell Viper to bind it:

```go
viper.BindFlagValue(&quot;my-flag-name&quot;, myFlag{})
```

`FlagValueSet` represents a group of flags. This is a very simple example on how to implement this interface:

```go
type myFlagSet struct {
	flags []myFlag
}

func (f myFlagSet) VisitAll(fn func(FlagValue)) {
	for _, flag := range flags {
		fn(flag)
	}
}
```

Once your flag set implements this interface, you can simply tell Viper to bind it:

```go
fSet := myFlagSet{
	flags: []myFlag{myFlag{}, myFlag{}},
}
viper.BindFlagValues(&quot;my-flags&quot;, fSet)
```

### Remote Key/Value Store Support

To enable remote support in Viper, do a blank import of the `viper/remote`
package:

`import _ &quot;github.com/spf13/viper/remote&quot;`

Viper will read a config string (as JSON, TOML, YAML, HCL or envfile) retrieved from a path
in a Key/Value store such as etcd or Consul.  These values take precedence over
default values, but are overridden by configuration values retrieved from disk,
flags, or environment variables.

Viper supports multiple hosts. To use, pass a list of endpoints separated by `;`. For example `http://127.0.0.1:4001;http://127.0.0.1:4002`.

Viper uses [crypt](https://github.com/sagikazarmark/crypt) to retrieve
configuration from the K/V store, which means that you can store your
configuration values encrypted and have them automatically decrypted if you have
the correct gpg keyring.  Encryption is optional.

You can use remote configuration in conjunction with local configuration, or
independently of it.

`crypt` has a command-line helper that you can use to put configurations in your
K/V store. `crypt` defaults to etcd on http://127.0.0.1:4001.

```bash
$ go get github.com/sagikazarmark/crypt/bin/crypt
$ crypt set -plaintext /config/hugo.json /Users/hugo/settings/config.json
```

Confirm that your value was set:

```bash
$ crypt get -plaintext /config/hugo.json
```

See the `crypt` documentation for examples of how to set encrypted values, or
how to use Consul.

### Remote Key/Value Store Example - Unencrypted

#### etcd
```go
viper.AddRemoteProvider(&quot;etcd&quot;, &quot;http://127.0.0.1:4001&quot;,&quot;/config/hugo.json&quot;)
viper.SetConfigType(&quot;json&quot;) // because there is no file extension in a stream of bytes, supported extensions are &quot;json&quot;, &quot;toml&quot;, &quot;yaml&quot;, &quot;yml&quot;, &quot;properties&quot;, &quot;props&quot;, &quot;prop&quot;, &quot;env&quot;, &quot;dotenv&quot;
err := viper.ReadRemoteConfig()
```

#### etcd3
```go
viper.AddRemoteProvider(&quot;etcd3&quot;, &quot;http://127.0.0.1:4001&quot;,&quot;/config/hugo.json&quot;)
viper.SetConfigType(&quot;json&quot;) // because there is no file extension in a stream of bytes, supported extensions are &quot;json&quot;, &quot;toml&quot;, &quot;yaml&quot;, &quot;yml&quot;, &quot;properties&quot;, &quot;props&quot;, &quot;prop&quot;, &quot;env&quot;, &quot;dotenv&quot;
err := viper.ReadRemoteConfig()
```

#### Consul
You need to set a key to Consul key/value storage with JSON value containing your desired config.
For example, create a Consul key/value store key `MY_CONSUL_KEY` with value:

```json
{
    &quot;port&quot;: 8080,
    &quot;hostname&quot;: &quot;myhostname.com&quot;
}
```

```go
viper.AddRemoteProvider(&quot;consul&quot;, &quot;localhost:8500&quot;, &quot;MY_CONSUL_KEY&quot;)
viper.SetConfigType(&quot;json&quot;) // Need to explicitly set this to json
err := viper.ReadRemoteConfig()

fmt.Println(viper.Get(&quot;port&quot;)) // 8080
fmt.Println(viper.Get(&quot;hostname&quot;)) // myhostname.com
```

#### Firestore

```go
viper.AddRemoteProvider(&quot;firestore&quot;, &quot;google-cloud-project-id&quot;, &quot;collection/document&quot;)
viper.SetConfigType(&quot;json&quot;) // Config&#039;s format: &quot;json&quot;, &quot;toml&quot;, &quot;yaml&quot;, &quot;yml&quot;
err := viper.ReadRemoteConfig()
```

Of course, you&#039;re allowed to use `SecureRemoteProvider` also


#### NATS

```go
viper.AddRemoteProvider(&quot;nats&quot;, &quot;nats://127.0.0.1:4222&quot;, &quot;myapp.config&quot;)
viper.SetConfigType(&quot;json&quot;)
err := viper.ReadRemoteConfig()
```

### Remote Key/Value Store Example - Encrypted

```go
viper.AddSecureRemoteProvider(&quot;etcd&quot;,&quot;http://127.0.0.1:4001&quot;,&quot;/config/hugo.json&quot;,&quot;/etc/secrets/mykeyring.gpg&quot;)
viper.SetConfigType(&quot;json&quot;) // because there is no file extension in a stream of bytes,  supported extensions are &quot;json&quot;, &quot;toml&quot;, &quot;yaml&quot;, &quot;yml&quot;, &quot;properties&quot;, &quot;props&quot;, &quot;prop&quot;, &quot;env&quot;, &quot;dotenv&quot;
err := viper.ReadRemoteConfig()
```

### Watching Changes in etcd - Unencrypted

```go
// alternatively, you can create a new viper instance.
var runtime_viper = viper.New()

runtime_viper.AddRemoteProvider(&quot;etcd&quot;, &quot;http://127.0.0.1:4001&quot;, &quot;/config/hugo.yml&quot;)
runtime_viper.SetConfigType(&quot;yaml&quot;) // because there is no file extension in a stream of bytes, supported extensions are &quot;json&quot;, &quot;toml&quot;, &quot;yaml&quot;, &quot;yml&quot;, &quot;properties&quot;, &quot;props&quot;, &quot;prop&quot;, &quot;env&quot;, &quot;dotenv&quot;

// read from remote config the first time.
err := runtime_viper.ReadRemoteConfig()

// unmarshal config
runtime_viper.Unmarshal(&amp;runtime_conf)

// open a goroutine to watch remote changes forever
go func(){
	for {
		time.Sleep(time.Second * 5) // delay after each request

		// currently, only tested with etcd support
		err := runtime_viper.WatchRemoteConfig()
		if err != nil {
			log.Errorf(&quot;unable to read remote config: %v&quot;, err)
			continue
		}

		// unmarshal new config into our runtime config struct. you can also use channel
		// to implement a signal to notify the system of the changes
		runtime_viper.Unmarshal(&amp;runtime_conf)
	}
}()
```

## Getting Values From Viper

In Viper, there are a few ways to get a value depending on the value’s type.
The following functions and methods exist:

 * `Get(key string) : any`
 * `GetBool(key string) : bool`
 * `GetFloat64(key string) : float64`
 * `GetInt(key string) : int`
 * `GetIntSlice(key string) : []int`
 * `GetString(key string) : string`
 * `GetStringMap(key string) : map[string]any`
 * `GetStringMapString(key string) : map[string]string`
 * `GetStringSlice(key string) : []string`
 * `GetTime(key string) : time.Time`
 * `GetDuration(key string) : time.Duration`
 * `IsSet(ke

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[google/osv-scanner]]></title>
            <link>https://github.com/google/osv-scanner</link>
            <guid>https://github.com/google/osv-scanner</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[Vulnerability scanner written in Go which uses the data provided by https://osv.dev]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google/osv-scanner">google/osv-scanner</a></h1>
            <p>Vulnerability scanner written in Go which uses the data provided by https://osv.dev</p>
            <p>Language: Go</p>
            <p>Stars: 6,643</p>
            <p>Forks: 385</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
    &lt;source srcset=&quot;/docs/images/osv-scanner-full-logo-darkmode.svg&quot;  media=&quot;(prefers-color-scheme: dark)&quot;&gt;
    &lt;img src=&quot;/docs/images/osv-scanner-full-logo-lightmode.svg&quot;&gt;
&lt;/picture&gt;

---

[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/google/osv-scanner/badge)](https://scorecard.dev/viewer/?uri=github.com/google/osv-scanner)
[![Go Report Card](https://goreportcard.com/badge/github.com/google/osv-scanner)](https://goreportcard.com/report/github.com/google/osv-scanner)
[![codecov](https://codecov.io/gh/google/osv-scanner/graph/badge.svg?token=C8IDVX9LP5)](https://codecov.io/gh/google/osv-scanner)
[![SLSA 3](https://slsa.dev/images/gh-badge-level3.svg)](https://slsa.dev)
[![GitHub Release](https://img.shields.io/github/v/release/google/osv-scanner)](https://github.com/google/osv-scanner/releases)

Use OSV-Scanner to find existing vulnerabilities affecting your project&#039;s dependencies.
OSV-Scanner provides an officially supported frontend to the [OSV database](https://osv.dev/) and CLI interface to [OSV-Scalibr](https://github.com/google/osv-scalibr) that connects a project’s list of dependencies with the vulnerabilities that affect them.

OSV-Scanner supports a wide range of project types, package managers and features, including but not limited to:

- **Languages:** C/C++, Dart, Elixir, Go, Java, Javascript, PHP, Python, R, Ruby, Rust.
- **Package Managers:** npm, pip, yarn, maven, go modules, cargo, gem, composer, nuget and others.
- **Operating Systems:** Detects vulnerabilities in OS packages on Linux systems.
- **Containers:** Scans container images for vulnerabilities in their base images and included packages.
- **Guided Remediation:** Provides recommendations for package version upgrades based on criteria such as dependency depth, minimum severity, fix strategy, and return on investment.

OSV-Scanner uses the extensible [OSV-Scalibr](https://github.com/google/osv-scalibr) library under the hood to provide this functionality. If a language or package manager is not supported currently, please file a [feature request.](https://github.com/google/osv-scanner/issues)

#### Underlying database

The underlying database, [OSV.dev](https://osv.dev/) has several benefits in comparison with closed source advisory databases and scanners:

- Covering most open source language and OS ecosystems (including [Git](https://osv.dev/list?q=&amp;ecosystem=GIT)), it’s comprehensive.
- Each advisory comes from an open and authoritative source (e.g. [GitHub Security Advisories](https://github.com/github/advisory-database), [RustSec Advisory Database](https://github.com/rustsec/advisory-db), [Ubuntu security notices](https://github.com/canonical/ubuntu-security-notices/tree/main/osv))
- Anyone can suggest improvements to advisories, resulting in a very high quality database.
- The OSV format unambiguously stores information about affected versions in a machine-readable format that precisely maps onto a developer’s list of packages

The above all results in accurate and actionable vulnerability notifications, which reduces the time needed to resolve them. Check out [OSV.dev](https://osv.dev/) for more details!

## Basic installation

To install OSV-Scanner, please refer to the [installation section](https://google.github.io/osv-scanner/installation) of our documentation. OSV-Scanner releases can be found on the [releases page](https://github.com/google/osv-scanner/releases) of the GitHub repository. The recommended method is to download a prebuilt binary for your platform. Alternatively, you can use
`go install github.com/google/osv-scanner/v2/cmd/osv-scanner@latest` to build it from source.

## Key Features

For more information, please read our [detailed documentation](https://google.github.io/osv-scanner) to learn how to use OSV-Scanner. For detailed information about each feature, click their titles in this README.

Please note: These are the instructions for the latest OSV-Scanner V2 beta. If you are using V1, checkout the V1 [README](https://github.com/google/osv-scanner-v1) and [documentation](https://google.github.io/osv-scanner-v1/) instead.

### [Scanning a source directory](https://google.github.io/osv-scanner/usage)

```bash
$ osv-scanner scan source -r /path/to/your/dir
```

This command will recursively scan the specified directory for any supported package files, such as `package.json`, `go.mod`, `pom.xml`, etc. and output any discovered vulnerabilities.

OSV-Scanner has the option of using call analysis to determine if a vulnerable function is actually being used in the project, resulting in fewer false positives, and actionable alerts.

OSV-Scanner can also detect vendored C/C++ code for vulnerability scanning. See [here](https://google.github.io/osv-scanner/usage/#cc-scanning) for details.

#### Supported Lockfiles

OSV-Scanner supports 11+ language ecosystems and 19+ lockfile types. To check if your ecosystem is covered, please check out our [detailed documentation](https://google.github.io/osv-scanner/supported-languages-and-lockfiles/#supported-lockfiles).

### [Container Scanning](https://google.github.io/osv-scanner/usage/scan-image)

OSV-Scanner also supports comprehensive, layer-aware scanning for container images to detect vulnerabilities the following operating system packages and language-specific dependencies.

| Distro Support | Language Artifacts Support |
| -------------- | -------------------------- |
| Alpine OS      | Go                         |
| Debian         | Java                       |
| Ubuntu         | Node                       |
|                | Python                     |

See the [full documentation](https://google.github.io/osv-scanner/supported-languages-and-lockfiles/#supported-artifacts) for details on support.

**Usage**:

```bash
$ osv-scanner scan image my-image-name:tag
```

![screencast of html output of container scanning](https://github.com/user-attachments/assets/8bb95366-27ec-45d1-86ed-e42890f2fb46)

### [License Scanning](https://google.github.io/osv-scanner/experimental/license-scanning/)

Check your dependencies&#039; licenses using deps.dev data. For a summary:

```bash
osv-scanner --licenses path/to/repository
```

To check against an allowed license list (SPDX format):

```bash
osv-scanner --licenses=&quot;MIT,Apache-2.0&quot; path/to/directory
```

### [Offline Scanning](https://google.github.io/osv-scanner/experimental/offline-mode/)

Scan your project against a local OSV database. No network connection is required after the initial database download. The database can also be manually downloaded.

```bash
osv-scanner --offline --download-offline-databases ./path/to/your/dir
```

### [Guided Remediation](https://google.github.io/osv-scanner/experimental/guided-remediation/) (Experimental)

OSV-Scanner provides guided remediation, a feature that suggests package version upgrades based on criteria such as dependency depth, minimum severity, fix strategy, and return on investment.
We currently support remediating vulnerabilities in the following files:

| Ecosystem | File Format (Type)             | Supported Remediation Strategies                                                                                  |
| :-------- | :----------------------------- | :---------------------------------------------------------------------------------------------------------------- |
| npm       | `package-lock.json` (lockfile) | [`in-place`](https://google.github.io/osv-scanner/experimental/guided-remediation/#in-place-lockfile-remediation) |
| npm       | `package.json` (manifest)      | [`relock`](https://google.github.io/osv-scanner/experimental/guided-remediation/#in-place-lockfile-remediation)   |
| Maven     | `pom.xml` (manifest)           | [`override`](https://google.github.io/osv-scanner/experimental/guided-remediation/#override-dependency-versions)  |

This is available as a headless CLI command, as well as an interactive mode.

#### Example (for npm)

```bash
$ osv-scanner fix \
    --max-depth=3 \
    --min-severity=5 \
    --ignore-dev  \
    --strategy=in-place \
    -L path/to/package-lock.json
```

#### Interactive mode (for npm)

```bash
$ osv-scanner fix \
    -M path/to/package.json \
    -L path/to/package-lock.json
```

&lt;img src=&quot;https://google.github.io/osv-scanner/images/guided-remediation-relock-patches.png&quot; alt=&quot;Screenshot of the interactive relock results screen with some relaxation patches selected&quot;&gt;

## Contribute

### Report Problems

If you have what looks like a bug, please use the [GitHub issue tracking system](https://github.com/google/osv-scanner/issues). Before you file an issue, please search existing issues to see if your issue is already covered.

### Contributing code to `osv-scanner`

See [CONTRIBUTING.md](CONTRIBUTING.md) for documentation on how to contribute code.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=google/osv-scanner&amp;type=Date)](https://star-history.com/#google/osv-scanner&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[metoro-io/mcp-golang]]></title>
            <link>https://github.com/metoro-io/mcp-golang</link>
            <guid>https://github.com/metoro-io/mcp-golang</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Write Model Context Protocol servers in few lines of go code. Docs at https://mcpgolang.com]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/metoro-io/mcp-golang">metoro-io/mcp-golang</a></h1>
            <p>Write Model Context Protocol servers in few lines of go code. Docs at https://mcpgolang.com</p>
            <p>Language: Go</p>
            <p>Stars: 379</p>
            <p>Forks: 37</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;./resources/mcp-golang-logo.webp&quot; height=&quot;300&quot; alt=&quot;Statusphere logo&quot;&gt;
&lt;/div&gt;
&lt;br/&gt;
&lt;div align=&quot;center&quot;&gt;

![GitHub stars](https://img.shields.io/github/stars/metoro-io/mcp-golang?style=social)
![GitHub forks](https://img.shields.io/github/forks/metoro-io/mcp-golang?style=social)
![GitHub issues](https://img.shields.io/github/issues/metoro-io/mcp-golang)
![GitHub pull requests](https://img.shields.io/github/issues-pr/metoro-io/mcp-golang)
![GitHub license](https://img.shields.io/github/license/metoro-io/mcp-golang)
![GitHub contributors](https://img.shields.io/github/contributors/metoro-io/mcp-golang)
![GitHub last commit](https://img.shields.io/github/last-commit/metoro-io/mcp-golang)
[![GoDoc](https://pkg.go.dev/badge/github.com/metoro-io/mcp-golang.svg)](https://pkg.go.dev/github.com/metoro-io/mcp-golang)
[![Go Report Card](https://goreportcard.com/badge/github.com/metoro-io/mcp-golang)](https://goreportcard.com/report/github.com/metoro-io/mcp-golang)
![Tests](https://github.com/metoro-io/mcp-golang/actions/workflows/go-test.yml/badge.svg)




&lt;/div&gt;

# mcp-golang 

mcp-golang is an unofficial implementation of the [Model Context Protocol](https://modelcontextprotocol.io/) in Go.

Write MCP servers and clients in golang with a few lines of code.

Docs at [https://mcpgolang.com](https://mcpgolang.com)

## Highlights
- 🛡️**Type safety** - Define your tool arguments as native go structs, have mcp-golang handle the rest. Automatic schema generation, deserialization, error handling etc.
- 🚛 **Custom transports** - Use the built-in transports (stdio for full feature support, HTTP for stateless communication) or write your own.
- ⚡ **Low boilerplate** - mcp-golang generates all the MCP endpoints for you apart from your tools, prompts and resources.
- 🧩 **Modular** - The library is split into three components: transport, protocol and server/client. Use them all or take what you need.
- 🔄 **Bi-directional** - Full support for both server and client implementations through stdio transport.

## Example Usage

Install with `go get github.com/metoro-io/mcp-golang`

### Server Example

```go
package main

import (
	&quot;fmt&quot;
	&quot;github.com/metoro-io/mcp-golang&quot;
	&quot;github.com/metoro-io/mcp-golang/transport/stdio&quot;
)

// Tool arguments are just structs, annotated with jsonschema tags
// More at https://mcpgolang.com/tools#schema-generation
type Content struct {
	Title       string  `json:&quot;title&quot; jsonschema:&quot;required,description=The title to submit&quot;`
	Description *string `json:&quot;description&quot; jsonschema:&quot;description=The description to submit&quot;`
}
type MyFunctionsArguments struct {
	Submitter string  `json:&quot;submitter&quot; jsonschema:&quot;required,description=The name of the thing calling this tool (openai, google, claude, etc)&quot;`
	Content   Content `json:&quot;content&quot; jsonschema:&quot;required,description=The content of the message&quot;`
}

func main() {
	done := make(chan struct{})

	server := mcp_golang.NewServer(stdio.NewStdioServerTransport())
	err := server.RegisterTool(&quot;hello&quot;, &quot;Say hello to a person&quot;, func(arguments MyFunctionsArguments) (*mcp_golang.ToolResponse, error) {
		return mcp_golang.NewToolResponse(mcp_golang.NewTextContent(fmt.Sprintf(&quot;Hello, %server!&quot;, arguments.Submitter))), nil
	})
	if err != nil {
		panic(err)
	}

	err = server.RegisterPrompt(&quot;promt_test&quot;, &quot;This is a test prompt&quot;, func(arguments Content) (*mcp_golang.PromptResponse, error) {
		return mcp_golang.NewPromptResponse(&quot;description&quot;, mcp_golang.NewPromptMessage(mcp_golang.NewTextContent(fmt.Sprintf(&quot;Hello, %server!&quot;, arguments.Title)), mcp_golang.RoleUser)), nil
	})
	if err != nil {
		panic(err)
	}

	err = server.RegisterResource(&quot;test://resource&quot;, &quot;resource_test&quot;, &quot;This is a test resource&quot;, &quot;application/json&quot;, func() (*mcp_golang.ResourceResponse, error) {
		return mcp_golang.NewResourceResponse(mcp_golang.NewTextEmbeddedResource(&quot;test://resource&quot;, &quot;This is a test resource&quot;, &quot;application/json&quot;)), nil
	})

	err = server.Serve()
	if err != nil {
		panic(err)
	}

	&lt;-done
}
```

### HTTP Server Example

You can also create an HTTP-based server using either the standard HTTP transport or Gin framework:

```go
// Standard HTTP
transport := http.NewHTTPTransport(&quot;/mcp&quot;)
transport.WithAddr(&quot;:8080&quot;)
server := mcp_golang.NewServer(transport)

// Or with Gin framework
transport := http.NewGinTransport()
router := gin.Default()
router.POST(&quot;/mcp&quot;, transport.Handler())
server := mcp_golang.NewServer(transport)
```

Note: HTTP transports are stateless and don&#039;t support bidirectional features like notifications. Use stdio transport if you need those features.

### Client Example

Checkout the [examples/client](./examples/client) directory for a more complete example.

```go
package main

import (
    &quot;context&quot;
    &quot;log&quot;
    mcp &quot;github.com/metoro-io/mcp-golang&quot;
    &quot;github.com/metoro-io/mcp-golang/transport/stdio&quot;
)

// Define type-safe arguments
type CalculateArgs struct {
    Operation string `json:&quot;operation&quot;`
    A         int    `json:&quot;a&quot;`
    B         int    `json:&quot;b&quot;`
}

func main() {
   cmd := exec.Command(&quot;go&quot;, &quot;run&quot;, &quot;./server/main.go&quot;)
   stdin, err := cmd.StdinPipe()
   if err != nil {
    log.Fatalf(&quot;Failed to get stdin pipe: %v&quot;, err)
   }
   stdout, err := cmd.StdoutPipe()
   if err != nil {
    log.Fatalf(&quot;Failed to get stdout pipe: %v&quot;, err)
   }

   if err := cmd.Start(); err != nil {
    log.Fatalf(&quot;Failed to start server: %v&quot;, err)
   }
   defer cmd.Process.Kill()
    // Create and initialize client
    transport := stdio.NewStdioServerTransportWithIO(stdout, stdin)
    client := mcp.NewClient(transport)
    
    if _, err := client.Initialize(context.Background()); err != nil {
        log.Fatalf(&quot;Failed to initialize: %v&quot;, err)
    }

    // Call a tool with typed arguments
    args := CalculateArgs{
        Operation: &quot;add&quot;,
        A:         10,
        B:         5,
    }
    
    response, err := client.CallTool(context.Background(), &quot;calculate&quot;, args)
    if err != nil {
        log.Fatalf(&quot;Failed to call tool: %v&quot;, err)
    }
    
    if response != nil &amp;&amp; len(response.Content) &gt; 0 {
        log.Printf(&quot;Result: %s&quot;, response.Content[0].TextContent.Text)
    }
}
```

### Using with Claude Desktop

Create a file in ~/Library/Application Support/Claude/claude_desktop_config.json with the following contents:

```json
{
&quot;mcpServers&quot;: {
  &quot;golang-mcp-server&quot;: {
      &quot;command&quot;: &quot;&lt;your path to golang MCP server go executable&gt;&quot;,
      &quot;args&quot;: [],
      &quot;env&quot;: {}
    }
  }
}
``` 

## Contributions

Contributions are more than welcome! Please check out [our contribution guidelines](./CONTRIBUTING.md).

## Discord

Got any suggestions, have a question on the api or usage? Ask on the [discord server](https://discord.gg/33saRwE3pT). 
A maintainer will be happy to help you out.

## Examples

Some more extensive examples using the library found here:

- &lt;img height=&quot;12&quot; width=&quot;12&quot; src=&quot;https://metoro.io/static/images/logos/Metoro.svg&quot; /&gt; **[Metoro](https://github.com/metoro-io/metoro-mcp-server)** - Query and interact with kubernetes environments monitored by Metoro

Open a PR to add your own projects!

## Server Feature Implementation

### Tools
- [x] Tool Calls
- [x] Native go structs as arguments
- [x] Programatically generated tool list endpoint
- [x] Change notifications
- [x] Pagination

### Prompts
- [x] Prompt Calls
- [x] Programatically generated prompt list endpoint
- [x] Change notifications
- [x] Pagination

### Resources
- [x] Resource Calls
- [x] Programatically generated resource list endpoint
- [x] Change notifications
- [x] Pagination

### Transports
- [x] Stdio - Full support for all features including bidirectional communication
- [x] HTTP - Stateless transport for simple request-response scenarios (no notifications support)
- [x] Gin - HTTP transport with Gin framework integration (stateless, no notifications support)
- [x] SSE
- [x] Custom transport support
- [ ] HTTPS with custom auth support - in progress. Not currently part of the spec but we&#039;ll be adding experimental support for it.

### Client
- [x] Call tools
- [x] Call prompts
- [x] Call resources
- [x] List tools
- [x] List prompts
- [x] List resources

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-go-contrib]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-go-contrib</link>
            <guid>https://github.com/open-telemetry/opentelemetry-go-contrib</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[Collection of extensions for OpenTelemetry-Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-go-contrib">open-telemetry/opentelemetry-go-contrib</a></h1>
            <p>Collection of extensions for OpenTelemetry-Go.</p>
            <p>Language: Go</p>
            <p>Stars: 1,337</p>
            <p>Forks: 608</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># OpenTelemetry-Go Contrib

[![build_and_test](https://github.com/open-telemetry/opentelemetry-go-contrib/workflows/build_and_test/badge.svg)](https://github.com/open-telemetry/opentelemetry-go-contrib/actions?query=workflow%3Abuild_and_test+branch%3Amain)
[![codecov.io](https://codecov.io/gh/open-telemetry/opentelemetry-go-contrib/coverage.svg?branch=main)](https://app.codecov.io/gh/open-telemetry/opentelemetry-go-contrib?branch=main)
[![Docs](https://godoc.org/go.opentelemetry.io/contrib?status.svg)](https://pkg.go.dev/go.opentelemetry.io/contrib)
[![Go Report Card](https://goreportcard.com/badge/go.opentelemetry.io/contrib)](https://goreportcard.com/report/go.opentelemetry.io/contrib)
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry-go-contrib.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:opentelemetry-go-contrib)
[![Slack](https://img.shields.io/badge/slack-@cncf/otel--go-brightgreen.svg?logo=slack)](https://cloud-native.slack.com/archives/C01NPAXACKT)

Collection of 3rd-party packages for [OpenTelemetry-Go](https://github.com/open-telemetry/opentelemetry-go).

## Contents

- [Examples](./examples/): Examples of OpenTelemetry libraries usage.
- [Instrumentation](./instrumentation/): Packages providing OpenTelemetry instrumentation for 3rd-party libraries.
- [Propagators](./propagators/): Packages providing OpenTelemetry context propagators for 3rd-party propagation formats.
- [Detectors](./detectors/): Packages providing OpenTelemetry resource detectors for 3rd-party cloud computing environments.
- [Exporters](./exporters/): Packages providing OpenTelemetry exporters for 3rd-party export formats.
- [Samplers](./samplers/): Packages providing additional implementations of OpenTelemetry samplers.
- [Bridges](./bridges/): Packages providing adapters for 3rd-party instrumentation frameworks.
- [Processors](./processors/): Packages providing additional implementations of OpenTelemetry processors.

## Project Status

This project contains both stable and unstable modules.
Refer to the module for its version or our [versioning manifest](./versions.yaml).

Project versioning information and stability guarantees can be found in the [versioning documentation](https://github.com/open-telemetry/opentelemetry-go/blob/a724cf884287e04785eaa91513d26a6ef9699288/VERSIONING.md).

Progress and status specific to this repository is tracked in our local [project boards](https://github.com/open-telemetry/opentelemetry-go-contrib/projects?query=is%3Aopen) and [milestones](https://github.com/open-telemetry/opentelemetry-go-contrib/milestones).

### Compatibility

OpenTelemetry-Go Contrib ensures compatibility with the current supported
versions of
the [Go language](https://golang.org/doc/devel/release#policy):

&gt; Each major Go release is supported until there are two newer major releases.
&gt; For example, Go 1.5 was supported until the Go 1.7 release, and Go 1.6 was supported until the Go 1.8 release.

For versions of Go that are no longer supported upstream, opentelemetry-go-contrib will
stop ensuring compatibility with these versions in the following manner:

- A minor release of opentelemetry-go-contrib will be made to add support for the new
  supported release of Go.
- The following minor release of opentelemetry-go-contrib will remove compatibility
  testing for the oldest (now archived upstream) version of Go. This, and
  future, releases of opentelemetry-go-contrib may include features only supported by
  the currently supported versions of Go.

This project is tested on the following systems.

| OS       | Go Version | Architecture |
| -------- | ---------- | ------------ |
| Ubuntu   | 1.24       | amd64        |
| Ubuntu   | 1.23       | amd64        |
| Ubuntu   | 1.24       | 386          |
| Ubuntu   | 1.23       | 386          |
| macOS 13 | 1.24       | amd64        |
| macOS 13 | 1.23       | amd64        |
| macOS    | 1.24       | arm64        |
| macOS    | 1.23       | arm64        |
| Windows  | 1.24       | amd64        |
| Windows  | 1.23       | amd64        |
| Windows  | 1.24       | 386          |
| Windows  | 1.23       | 386          |

While this project should work for other systems, no compatibility guarantees
are made for those systems currently.

## Contributing

For information on how to contribute, consult [the contributing guidelines](./CONTRIBUTING.md)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[expr-lang/expr]]></title>
            <link>https://github.com/expr-lang/expr</link>
            <guid>https://github.com/expr-lang/expr</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Expression language and expression evaluation for Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/expr-lang/expr">expr-lang/expr</a></h1>
            <p>Expression language and expression evaluation for Go</p>
            <p>Language: Go</p>
            <p>Stars: 6,666</p>
            <p>Forks: 429</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;&lt;a href=&quot;https://expr-lang.org&quot;&gt;&lt;img src=&quot;https://expr-lang.org/img/logo.png&quot; alt=&quot;Zx logo&quot; height=&quot;48&quot;align=&quot;right&quot;&gt;&lt;/a&gt; Expr&lt;/h1&gt;

&gt; [!IMPORTANT]
&gt; The repository [github.com/antonmedv/expr](https://github.com/antonmedv/expr) moved to [github.com/**expr-lang**/expr](https://github.com/expr-lang/expr).

[![test](https://github.com/expr-lang/expr/actions/workflows/test.yml/badge.svg)](https://github.com/expr-lang/expr/actions/workflows/test.yml) 
[![Go Report Card](https://goreportcard.com/badge/github.com/expr-lang/expr)](https://goreportcard.com/report/github.com/expr-lang/expr) 
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/expr.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:expr)
[![GoDoc](https://godoc.org/github.com/expr-lang/expr?status.svg)](https://godoc.org/github.com/expr-lang/expr)

**Expr** is a Go-centric expression language designed to deliver dynamic configurations with unparalleled accuracy, safety, and speed. 
**Expr** combines simple [syntax](https://expr-lang.org/docs/language-definition) with powerful features for ease of use:

```js
// Allow only admins and moderators to moderate comments.
user.Group in [&quot;admin&quot;, &quot;moderator&quot;] || user.Id == comment.UserId
```

```js
// Determine whether the request is in the permitted time window.
request.Time - resource.Age &lt; duration(&quot;24h&quot;)
```

```js
// Ensure all tweets are less than 240 characters.
all(tweets, len(.Content) &lt;= 240)
```

## Features

**Expr** is a safe, fast, and intuitive expression evaluator optimized for the Go language. 
Here are its standout features:

### Safety and Isolation
* **Memory-Safe**: Expr is designed with a focus on safety, ensuring that programs do not access unrelated memory or introduce memory vulnerabilities.
* **Side-Effect-Free**: Expressions evaluated in Expr only compute outputs from their inputs, ensuring no side-effects that can change state or produce unintended results.
* **Always Terminating**: Expr is designed to prevent infinite loops, ensuring that every program will conclude in a reasonable amount of time.

### Go Integration
* **Seamless with Go**: Integrate Expr into your Go projects without the need to redefine types.

### Static Typing
* Ensures type correctness and prevents runtime type errors.
  ```go
  out, err := expr.Compile(`name + age`)
  // err: invalid operation + (mismatched types string and int)
  // | name + age
  // | .....^
  ```

### User-Friendly
* Provides user-friendly error messages to assist with debugging and development.

### Flexibility and Utility
* **Rich Operators**: Offers a reasonable set of basic operators for a variety of applications.
* **Built-in Functions**: Functions like `all`, `none`, `any`, `one`, `filter`, and `map` are provided out-of-the-box.

### Performance
* **Optimized for Speed**: Expr stands out in its performance, utilizing an optimizing compiler and a bytecode virtual machine. Check out these [benchmarks](https://github.com/antonmedv/golang-expression-evaluation-comparison#readme) for more details.

## Install

```
go get github.com/expr-lang/expr
```

## Documentation

* See [Getting Started](https://expr-lang.org/docs/Getting-Started) page for developer documentation.
* See [Language Definition](https://expr-lang.org/docs/language-definition) page to learn the syntax.

## Examples

[Play Online](https://go.dev/play/p/XCoNXEjm3TS)

```go
package main

import (
	&quot;fmt&quot;
	&quot;github.com/expr-lang/expr&quot;
)

func main() {
	env := map[string]interface{}{
		&quot;greet&quot;:   &quot;Hello, %v!&quot;,
		&quot;names&quot;:   []string{&quot;world&quot;, &quot;you&quot;},
		&quot;sprintf&quot;: fmt.Sprintf,
	}

	code := `sprintf(greet, names[0])`

	program, err := expr.Compile(code, expr.Env(env))
	if err != nil {
		panic(err)
	}

	output, err := expr.Run(program, env)
	if err != nil {
		panic(err)
	}

	fmt.Println(output)
}
```

[Play Online](https://go.dev/play/p/tz-ZneBfSuw)

```go
package main

import (
	&quot;fmt&quot;
	&quot;github.com/expr-lang/expr&quot;
)

type Tweet struct {
	Len int
}

type Env struct {
	Tweets []Tweet
}

func main() {
	code := `all(Tweets, {.Len &lt;= 240})`

	program, err := expr.Compile(code, expr.Env(Env{}))
	if err != nil {
		panic(err)
	}

	env := Env{
		Tweets: []Tweet{{42}, {98}, {69}},
	}
	output, err := expr.Run(program, env)
	if err != nil {
		panic(err)
	}

	fmt.Println(output)
}
```

## Who uses Expr?

* [Google](https://google.com) uses Expr as one of its expression languages on the [Google Cloud Platform](https://cloud.google.com).
* [Uber](https://uber.com) uses Expr to allow customization of its Uber Eats marketplace.
* [GoDaddy](https://godaddy.com) employs Expr for the customization of its GoDaddy Pro product.
* [ByteDance](https://bytedance.com) incorporates Expr into its internal business rule engine.
* [Aviasales](https://aviasales.ru) utilizes Expr as a business rule engine for its flight search engine.
* [Wish.com](https://www.wish.com) employs Expr in its decision-making rule engine for the Wish Assistant.
* [Argo](https://argoproj.github.io) integrates Expr into Argo Rollouts and Argo Workflows for Kubernetes.
* [OpenTelemetry](https://opentelemetry.io) integrates Expr into the OpenTelemetry Collector.
* [Philips Labs](https://github.com/philips-labs/tabia) employs Expr in Tabia, a tool designed to collect insights on their code bases.
* [CrowdSec](https://crowdsec.net) incorporates Expr into its security automation tool.
* [CoreDNS](https://coredns.io) uses Expr in CoreDNS, which is a DNS server.
* [qiniu](https://www.qiniu.com) implements Expr in its trade systems.
* [Junglee Games](https://www.jungleegames.com/) uses Expr for its in-house marketing retention tool, Project Audience.
* [Faceit](https://www.faceit.com) uses Expr to enhance customization of its eSports matchmaking algorithm.
* [Chaos Mesh](https://chaos-mesh.org) incorporates Expr into Chaos Mesh, a cloud-native Chaos Engineering platform.
* [Visually.io](https://visually.io) employs Expr as a business rule engine for its personalization targeting algorithm.
* [Akvorado](https://github.com/akvorado/akvorado) utilizes Expr to classify exporters and interfaces in network flows.
* [keda.sh](https://keda.sh) uses Expr to allow customization of its Kubernetes-based event-driven autoscaling.
* [Span Digital](https://spandigital.com/) uses Expr in its Knowledge Management products.
* [Xiaohongshu](https://www.xiaohongshu.com/) combining yaml with Expr for dynamically policies delivery.
* [Melrōse](https://melrōse.org) uses Expr to implement its music programming language.
* [Tork](https://www.tork.run/) integrates Expr into its workflow execution.
* [Critical Moments](https://criticalmoments.io) uses Expr for its mobile realtime conditional targeting system.
* [WoodpeckerCI](https://woodpecker-ci.org) uses Expr for [filtering workflows/steps](https://woodpecker-ci.org/docs/usage/workflow-syntax#evaluate).
* [FastSchema](https://github.com/fastschema/fastschema) - A BaaS leveraging Expr for its customizable and dynamic Access Control system.
* [WunderGraph Cosmo](https://github.com/wundergraph/cosmo) - GraphQL Federeration Router uses Expr to customize Middleware behaviour
* [SOLO](https://solo.one) uses Expr interally to allow dynamic code execution with custom defined functions.

[Add your company too](https://github.com/expr-lang/expr/edit/master/README.md)

## License

[MIT](https://github.com/expr-lang/expr/blob/master/LICENSE)

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://expr-lang.org/img/gopher-small.png&quot; width=&quot;150&quot; /&gt;&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[vektra/mockery]]></title>
            <link>https://github.com/vektra/mockery</link>
            <guid>https://github.com/vektra/mockery</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[A mock code autogenerator for Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vektra/mockery">vektra/mockery</a></h1>
            <p>A mock code autogenerator for Go</p>
            <p>Language: Go</p>
            <p>Stars: 6,383</p>
            <p>Forks: 428</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>
mockery
=======
[![Release](https://github.com/vektra/mockery/actions/workflows/release.yml/badge.svg)](https://github.com/vektra/mockery/actions/workflows/release.yml) [![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;logoColor=white&amp;style=flat-square)](https://pkg.go.dev/github.com/vektra/mockery/v2?tab=overview) ![GitHub go.mod Go version](https://img.shields.io/github/go-mod/go-version/vektra/mockery) ![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/vektra/mockery) [![Go Report Card](https://goreportcard.com/badge/github.com/vektra/mockery)](https://goreportcard.com/report/github.com/vektra/mockery) [![codecov](https://codecov.io/gh/vektra/mockery/branch/master/graph/badge.svg)](https://codecov.io/gh/vektra/mockery)

mockery provides the ability to easily generate mocks for Golang interfaces using the [stretchr/testify/mock](https://pkg.go.dev/github.com/stretchr/testify/mock?tab=doc) package. It removes the boilerplate coding required to use mocks.

Documentation
--------------

Documentation is found at our [GitHub Pages site](https://vektra.github.io/mockery/).

Development
------------

taskfile.dev is used for build tasks. Initialize all go build tools:

```
go mod download -x
```

You can run any of the steps listed in `Taskfile.yml`:

```
$ task test
task: [test] go test -v -coverprofile=coverage.txt ./...
```

Stargazers
----------

[![Stargazers over time](https://starchart.cc/vektra/mockery.svg)](https://starchart.cc/vektra/mockery)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kedacore/keda]]></title>
            <link>https://github.com/kedacore/keda</link>
            <guid>https://github.com/kedacore/keda</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kedacore/keda">kedacore/keda</a></h1>
            <p>KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 8,869</p>
            <p>Forks: 1,117</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;images/logos/keda-word-colour.png&quot; width=&quot;300&quot;/&gt;&lt;/p&gt;
&lt;p style=&quot;font-size: 25px&quot; align=&quot;center&quot;&gt;&lt;b&gt;Kubernetes-based Event Driven Autoscaling&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;font-size: 25px&quot; align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/kedacore/keda/actions?query=workflow%3Amain-build&quot;&gt;&lt;img src=&quot;https://github.com/kedacore/keda/actions/workflows/main-build.yml/badge.svg&quot; alt=&quot;main build&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/kedacore/keda/actions?query=workflow%3Anightly-e2e-test&quot;&gt;&lt;img src=&quot;https://github.com/kedacore/keda/actions/workflows/nightly-e2e.yml/badge.svg&quot; alt=&quot;nightly e2e&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://bestpractices.coreinfrastructure.org/projects/3791&quot;&gt;&lt;img src=&quot;https://bestpractices.coreinfrastructure.org/projects/3791/badge&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://api.scorecard.dev/projects/github.com/kedacore/keda/badge&quot;&gt;&lt;img src=&quot;https://img.shields.io/ossf-scorecard/github.com/kedacore/keda?label=openssf%20scorecard&amp;style=flat&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://artifacthub.io/packages/helm/kedacore/keda&quot;&gt;&lt;img src=&quot;https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/kedacore&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fkedacore%2Fkeda?ref=badge_shield&quot; alt=&quot;FOSSA Status&quot;&gt;&lt;img src=&quot;https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fkedacore%2Fkeda.svg?type=shield&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://twitter.com/kedaorg&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/kedaorg?style=social&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;&lt;/p&gt;

KEDA allows for fine-grained autoscaling (including to/from zero) for event driven Kubernetes workloads. KEDA serves
as a Kubernetes Metrics Server and allows users to define autoscaling rules using a dedicated Kubernetes custom
resource definition.

KEDA can run on both the cloud and the edge, integrates natively with Kubernetes components such as the Horizontal
Pod Autoscaler, and has no external dependencies.

We are a Cloud Native Computing Foundation (CNCF) graduated project.
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/kedacore/keda/main/images/logo-cncf.svg&quot; height=&quot;75px&quot;&gt;&lt;/p&gt;

&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt;
&lt;!-- DON&#039;T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt;
**Table of contents**

- [Getting started](#getting-started)
  - [Deploying KEDA](#deploying-keda)
- [Documentation](#documentation)
- [Community](#community)
- [Adopters - Become a listed KEDA user!](#adopters---become-a-listed-keda-user)
- [Governance &amp; Policies](#governance--policies)
- [Support](#support)
- [Roadmap](#roadmap)
- [Releases](#releases)
- [Contributing](#contributing)
  - [Building &amp; deploying locally](#building--deploying-locally)
  - [Testing strategy](#testing-strategy)

&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt;

## Getting started

* [QuickStart - RabbitMQ and Go](https://github.com/kedacore/sample-go-rabbitmq)
* [QuickStart - Azure Functions and Queues](https://github.com/kedacore/sample-hello-world-azure-functions)
* [QuickStart - Azure Functions and Kafka on Openshift 4](https://github.com/kedacore/sample-azure-functions-on-ocp4)
* [QuickStart - Azure Storage Queue with ScaledJob](https://github.com/kedacore/sample-go-storage-queue)

You can find several samples for various event sources [here](https://github.com/kedacore/samples).

### Deploying KEDA

There are many ways to [deploy KEDA including Helm, Operator Hub and YAML files](https://keda.sh/docs/latest/deploy/).

## Documentation

Interested to learn more? Head over to [keda.sh](https://keda.sh).

## Community

If interested in contributing or participating in the direction of KEDA, you can join our community meetings! Learn more about them on [our website](https://keda.sh/community/).

Just want to learn or chat about KEDA? Feel free to join the conversation in
**[#KEDA](https://kubernetes.slack.com/messages/CKZJ36A5D)** on the **[Kubernetes Slack](https://slack.k8s.io/)**!

## Adopters - Become a listed KEDA user!

We are always happy to [list users](https://keda.sh/community/#users) who run KEDA in production, learn more about it [here](https://github.com/kedacore/keda-docs#become-a-listed-keda-user).

## Governance &amp; Policies

You can learn about the governance of KEDA [here](https://github.com/kedacore/governance).

## Support

Details on the KEDA support policy can found [here](https://keda.sh/support/).

## Roadmap

We use GitHub issues to build our backlog, a complete overview of all open items and our planning.

Learn more about our roadmap [here](ROADMAP.md).

## Releases

You can find the latest releases [here](https://github.com/kedacore/keda/releases).

## Contributing

You can find contributing guide [here](./CONTRIBUTING.md).

### Building &amp; deploying locally
Learn how to build &amp; deploy KEDA locally [here](./BUILD.md).

### Testing strategy
Learn more about our testing strategy [here](./TESTING.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[containerd/containerd]]></title>
            <link>https://github.com/containerd/containerd</link>
            <guid>https://github.com/containerd/containerd</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[An open and reliable container runtime]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/containerd/containerd">containerd/containerd</a></h1>
            <p>An open and reliable container runtime</p>
            <p>Language: Go</p>
            <p>Stars: 18,120</p>
            <p>Forks: 3,548</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>![containerd banner light mode](https://raw.githubusercontent.com/cncf/artwork/master/projects/containerd/horizontal/color/containerd-horizontal-color.png#gh-light-mode-only)
![containerd banner dark mode](https://raw.githubusercontent.com/cncf/artwork/master/projects/containerd/horizontal/white/containerd-horizontal-white.png#gh-dark-mode-only)

[![PkgGoDev](https://pkg.go.dev/badge/github.com/containerd/containerd/v2)](https://pkg.go.dev/github.com/containerd/containerd/v2)
[![Build Status](https://github.com/containerd/containerd/actions/workflows/ci.yml/badge.svg?event=merge_group)](https://github.com/containerd/containerd/actions?query=workflow%3ACI+event%3Amerge_group)
[![Nightlies](https://github.com/containerd/containerd/workflows/Nightly/badge.svg)](https://github.com/containerd/containerd/actions?query=workflow%3ANightly)
[![Go Report Card](https://goreportcard.com/badge/github.com/containerd/containerd/v2)](https://goreportcard.com/report/github.com/containerd/containerd/v2)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1271/badge)](https://bestpractices.coreinfrastructure.org/projects/1271)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/containerd/containerd/badge)](https://scorecard.dev/viewer/?uri=github.com/containerd/containerd)
[![Check Links](https://github.com/containerd/containerd/actions/workflows/links.yml/badge.svg)](https://github.com/containerd/containerd/actions/workflows/links.yml)

containerd is an industry-standard container runtime with an emphasis on simplicity, robustness, and portability. It is available as a daemon for Linux and Windows, which can manage the complete container lifecycle of its host system: image transfer and storage, container execution and supervision, low-level storage and network attachments, etc.

containerd is a member of CNCF with [&#039;graduated&#039;](https://landscape.cncf.io/?selected=containerd) status.

containerd is designed to be embedded into a larger system, rather than being used directly by developers or end-users.

![architecture](docs/historical/design/architecture.png)

## Announcements

### containerd v2.0 is now released!
See [`docs/containerd-2.0.md`](docs/containerd-2.0.md).

### Now Recruiting

We are a large inclusive OSS project that is welcoming help of any kind shape or form:
* Documentation help is needed to make the product easier to consume and extend.
* We need OSS community outreach/organizing help to get the word out; manage
and create messaging and educational content; and help with social media, community forums/groups, and google groups.
* We are actively inviting new [security advisors](https://github.com/containerd/project/blob/main/GOVERNANCE.md#security-advisors) to join the team.
* New subprojects are being created, core and non-core that could use additional development help.
* Each of the [containerd projects](https://github.com/containerd) has a list of issues currently being worked on or that need help resolving.
  - If the issue has not already been assigned to someone or has not made recent progress, and you are interested, please inquire.
  - If you are interested in starting with a smaller/beginner-level issue, look for issues with an `exp/beginner` tag, for example [containerd/containerd beginner issues.](https://github.com/containerd/containerd/issues?q=is%3Aissue+is%3Aopen+label%3Aexp%2Fbeginner)

## Getting Started

See our documentation on [containerd.io](https://containerd.io):
* [for ops and admins](docs/ops.md)
* [namespaces](docs/namespaces.md)
* [client options](docs/client-opts.md)

To get started contributing to containerd, see [CONTRIBUTING](CONTRIBUTING.md).

If you are interested in trying out containerd see our example at [Getting Started](docs/getting-started.md).

## Nightly builds

There are nightly builds available for download [here](https://github.com/containerd/containerd/actions?query=workflow%3ANightly).
Binaries are generated from `main` branch every night for `Linux` and `Windows`.

Please be aware: nightly builds might have critical bugs, it&#039;s not recommended for use in production and no support provided.

## Kubernetes (k8s) CI Dashboard Group

The [k8s CI dashboard group for containerd](https://testgrid.k8s.io/containerd) contains test results regarding
the health of kubernetes when run against main and a number of containerd release branches.

- [containerd-periodics](https://testgrid.k8s.io/containerd-periodic)

## Runtime Requirements

Runtime requirements for containerd are very minimal. Most interactions with
the Linux and Windows container feature sets are handled via [runc](https://github.com/opencontainers/runc) and/or
OS-specific libraries (e.g. [hcsshim](https://github.com/Microsoft/hcsshim) for Microsoft).
The current required version of `runc` is described in [RUNC.md](docs/RUNC.md).

There are specific features
used by containerd core code and snapshotters that will require a minimum kernel
version on Linux. With the understood caveat of distro kernel versioning, a
reasonable starting point for Linux is a minimum 4.x kernel version.

The overlay filesystem snapshotter, used by default, uses features that were
finalized in the 4.x kernel series. If you choose to use btrfs, there may
be more flexibility in kernel version (minimum recommended is 3.18), but will
require the btrfs kernel module and btrfs tools to be installed on your Linux
distribution.

To use Linux checkpoint and restore features, you will need `criu` installed on
your system. See more details in [Checkpoint and Restore](#checkpoint-and-restore).

Build requirements for developers are listed in [BUILDING](BUILDING.md).


## Supported Registries

Any registry which is compliant with the [OCI Distribution Specification](https://github.com/opencontainers/distribution-spec)
is supported by containerd.

For configuring registries, see [registry host configuration documentation](docs/hosts.md)

## Features

For a detailed overview of containerd&#039;s core concepts and the features it supports,
please refer to the [FEATURES.MD](./docs/features.md) document.

### Releases and API Stability

Please see [RELEASES.md](RELEASES.md) for details on versioning and stability
of containerd components.

Downloadable 64-bit Intel/AMD binaries of all official releases are available on
our [releases page](https://github.com/containerd/containerd/releases).

For other architectures and distribution support, you will find that many
Linux distributions package their own containerd and provide it across several
architectures, such as [Canonical&#039;s Ubuntu packaging](https://launchpad.net/ubuntu/bionic/+package/containerd).

#### Enabling command auto-completion

Starting with containerd 1.4, the urfave client feature for auto-creation of bash and zsh
autocompletion data is enabled. To use the autocomplete feature in a bash shell for example, source
the autocomplete/ctr file in your `.bashrc`, or manually like:

```
$ source ./contrib/autocomplete/ctr
```

#### Distribution of `ctr` autocomplete for bash and zsh

For bash, copy the `contrib/autocomplete/ctr` script into
`/etc/bash_completion.d/` and rename it to `ctr`. The `zsh_autocomplete`
file is also available and can be used similarly for zsh users.

Provide documentation to users to `source` this file into their shell if
you don&#039;t place the autocomplete file in a location where it is automatically
loaded for the user&#039;s shell environment.

### CRI

`cri` is a [containerd](https://containerd.io/) plugin implementation of the Kubernetes [container runtime interface (CRI)](https://github.com/kubernetes/cri-api/blob/master/pkg/apis/runtime/v1/api.proto). With it, you are able to use containerd as the container runtime for a Kubernetes cluster.

![cri](./docs/cri/cri.png)

#### CRI Status

`cri` is a native plugin of containerd. Since containerd 1.1, the cri plugin is built into the release binaries and enabled by default.

The `cri` plugin has reached GA status, representing that it is:
* Feature complete
* Works with Kubernetes 1.10 and above
* Passes all [CRI validation tests](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/cri-validation.md).
* Passes all [node e2e tests](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/e2e-node-tests.md).
* Passes all [e2e tests](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-testing/e2e-tests.md).

See results on the containerd k8s [test dashboard](https://testgrid.k8s.io/containerd)

#### Validating Your `cri` Setup
A Kubernetes incubator project, [cri-tools](https://github.com/kubernetes-sigs/cri-tools), includes programs for exercising CRI implementations. More importantly, cri-tools includes the program `critest` which is used for running [CRI Validation Testing](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/cri-validation.md).

#### CRI Guides
* [Installing with Ansible and Kubeadm](contrib/ansible/README.md)
* [For Non-Ansible Users, Preforming a Custom Installation Using the Release Tarball and Kubeadm](docs/getting-started.md)
* [CRI Plugin Testing Guide](./docs/cri/testing.md)
* [Debugging Pods, Containers, and Images with `crictl`](./docs/cri/crictl.md)
* [Configuring `cri` Plugins](./docs/cri/config.md)
* [Configuring containerd](https://github.com/containerd/containerd/blob/main/docs/man/containerd-config.8.md)

### Communication

For async communication and long-running discussions please use issues and pull requests on the GitHub repo.
This will be the best place to discuss design and implementation.

For sync communication catch us in the `#containerd` and `#containerd-dev` Slack channels on Cloud Native Computing Foundation&#039;s (CNCF) Slack - `cloud-native.slack.com`. Everyone is welcome to join and chat. [Get Invite to CNCF Slack.](https://slack.cncf.io)

Join our next community meeting hosted on Zoom. The schedule is posted on the [CNCF Calendar](https://www.cncf.io/calendar/) (search &#039;containerd&#039; to filter).

### Security audit

Security audits for the containerd project are hosted on our website. Please see the [security page at containerd.io](https://containerd.io/security/) for more information.

### Reporting security issues

Please follow the instructions at [containerd/project](https://github.com/containerd/project/blob/main/SECURITY.md#reporting-a-vulnerability)

## Licenses

The containerd codebase is released under the [Apache 2.0 license](LICENSE).
The README.md file and files in the &quot;docs&quot; folder are licensed under the
Creative Commons Attribution 4.0 International License. You may obtain a
copy of the license, titled CC-BY-4.0, at http://creativecommons.org/licenses/by/4.0/.

## Project details

**containerd** is the primary open source project within the broader containerd GitHub organization.
However, all projects within the repo have common maintainership, governance, and contributing
guidelines which are stored in a `project` repository commonly for all containerd projects.

Please find all these core project documents, including the:
 * [Project governance](https://github.com/containerd/project/blob/main/GOVERNANCE.md),
 * [Maintainers](https://github.com/containerd/project/blob/main/MAINTAINERS),
 * and [Contributing guidelines](https://github.com/containerd/project/blob/main/CONTRIBUTING.md)

information in our [`containerd/project`](https://github.com/containerd/project) repository.

## Adoption

Interested to see who is using containerd? Are you using containerd in a project?
Please add yourself via pull request to our [ADOPTERS.md](./ADOPTERS.md) file.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[argoproj/argo-workflows]]></title>
            <link>https://github.com/argoproj/argo-workflows</link>
            <guid>https://github.com/argoproj/argo-workflows</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[Workflow Engine for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/argoproj/argo-workflows">argoproj/argo-workflows</a></h1>
            <p>Workflow Engine for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 15,456</p>
            <p>Forks: 3,263</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable-next-line MD041 --&gt;
[![Security Status](https://github.com/argoproj/argo-workflows/actions/workflows/snyk.yml/badge.svg?branch=main)](https://github.com/argoproj/argo-workflows/actions/workflows/snyk.yml?query=branch%3Amain)
[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/3830/badge)](https://bestpractices.coreinfrastructure.org/projects/3830)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-workflows/badge)](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-workflows)
[![FOSSA License Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fargoproj%2Fargo-workflows.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fargoproj%2Fargo-workflows?ref=badge_shield)
[![Slack](https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack)](https://argoproj.github.io/community/join-slack)
[![Twitter Follow](https://img.shields.io/twitter/follow/argoproj?style=social)](https://twitter.com/argoproj)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-argoproj-blue.svg?logo=linkedin)](https://www.linkedin.com/company/argoproj/)
[![Release Version](https://img.shields.io/github/v/release/argoproj/argo-workflows?label=argo-workflows)](https://github.com/argoproj/argo-workflows/releases/latest)
[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-workflows)](https://artifacthub.io/packages/helm/argo/argo-workflows)

## What is Argo Workflows?

Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes.
Argo Workflows is implemented as a Kubernetes CRD (Custom Resource Definition).

* Define workflows where each step is a container.
* Model multi-step workflows as a sequence of tasks or capture the dependencies between tasks using a directed acyclic graph (DAG).
* Easily run compute intensive jobs for machine learning or data processing in a fraction of the time using Argo Workflows on Kubernetes.

Argo is a [Cloud Native Computing Foundation (CNCF)](https://cncf.io/) graduated project.

## Use Cases

* [Machine Learning pipelines](https://argo-workflows.readthedocs.io/en/latest/use-cases/machine-learning/)
* [Data and batch processing](https://argo-workflows.readthedocs.io/en/latest/use-cases/data-processing/)
* [Infrastructure automation](https://argo-workflows.readthedocs.io/en/latest/use-cases/infrastructure-automation/)
* [CI/CD](https://argo-workflows.readthedocs.io/en/latest/use-cases/ci-cd/)
* [Other use cases](https://argo-workflows.readthedocs.io/en/latest/use-cases/other/)

## Why Argo Workflows?

* Argo Workflows is the most popular workflow execution engine for Kubernetes.
* Light-weight, scalable, and easier to use.
* Designed from the ground up for containers without the overhead and limitations of legacy VM and server-based environments.
* Cloud agnostic and can run on any Kubernetes cluster.

[Read what people said in our latest survey](https://blog.argoproj.io/argo-workflows-events-2023-user-survey-results-82c53bc30543)

## Try Argo Workflows

You can try Argo Workflows via one of the following:

1. [Interactive Training Material](https://killercoda.com/argoproj/course/argo-workflows/)
1. [Access the demo environment](https://workflows.apps.argoproj.io/workflows/argo)

![Screenshot](docs/assets/screenshot.png)

## Who uses Argo Workflows?

[About 200+ organizations are officially using Argo Workflows](USERS.md)

## Ecosystem

Just some of the projects that use or rely on Argo Workflows (complete list [here](https://github.com/akuity/awesome-argo#ecosystem-projects)):

* [Argo Events](https://github.com/argoproj/argo-events)
* [Couler](https://github.com/couler-proj/couler)
* [Hera](https://github.com/argoproj-labs/hera-workflows)
* [Katib](https://github.com/kubeflow/katib)
* [Kedro](https://kedro.readthedocs.io/en/stable/)
* [Kubeflow Pipelines](https://github.com/kubeflow/pipelines)
* [Netflix Metaflow](https://metaflow.org)
* [Onepanel](https://github.com/onepanelio/onepanel)
* [Orchest](https://github.com/orchest/orchest/)
* [Piper](https://github.com/quickube/piper)
* [Ploomber](https://github.com/ploomber/ploomber)
* [Seldon](https://github.com/SeldonIO/seldon-core)
* [SQLFlow](https://github.com/sql-machine-learning/sqlflow)

## Client Libraries

Check out our [Java, Golang and Python clients](docs/client-libraries.md).

## Quickstart

* [Get started here](https://argo-workflows.readthedocs.io/en/latest/quick-start/)
* [Walk-through examples](https://argo-workflows.readthedocs.io/en/latest/walk-through/)

## Documentation

[View the docs](https://argo-workflows.readthedocs.io/en/latest/)

## Features

An incomplete list of features Argo Workflows provide:

* UI to visualize and manage Workflows
* Artifact support (S3, Artifactory, Alibaba Cloud OSS, Azure Blob Storage, HTTP, Git, GCS, raw)
* Workflow templating to store commonly used Workflows in the cluster
* Archiving Workflows after executing for later access
* Scheduled workflows using cron
* Server interface with REST API (HTTP and GRPC)
* DAG or Steps based declaration of workflows
* Step level input &amp; outputs (artifacts/parameters)
* Loops
* Parameterization
* Conditionals
* Timeouts (step &amp; workflow level)
* Retry (step &amp; workflow level)
* Resubmit (memoized)
* Suspend &amp; Resume
* Cancellation
* K8s resource orchestration
* Exit Hooks (notifications, cleanup)
* Garbage collection of completed workflow
* Scheduling (affinity/tolerations/node selectors)
* Volumes (ephemeral/existing)
* Parallelism limits
* Daemoned steps
* DinD (docker-in-docker)
* Script steps
* Event emission
* Prometheus metrics
* Multiple executors
* Multiple pod and workflow garbage collection strategies
* Automatically calculated resource usage per step
* Java/Golang/Python SDKs
* Pod Disruption Budget support
* Single-sign on (OAuth2/OIDC)
* Webhook triggering
* CLI
* Out-of-the box and custom Prometheus metrics
* Windows container support
* Embedded widgets
* Multiplex log viewer

## Community Meetings

We host monthly community meetings where we and the community showcase demos and discuss the current and future state of the project. Feel free to join us!
For Community Meeting information, minutes and recordings, please [see here](https://bit.ly/argo-wf-cmty-mtng).

Participation in Argo Workflows is governed by the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/master/code-of-conduct.md)

## Community Blogs and Presentations

* [Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo](https://github.com/terrytangyuan/awesome-argo)
* [Automation of Everything - How To Combine Argo Events, Workflows &amp; Pipelines, CD, and Rollouts](https://youtu.be/XNXJtxkUKeY)
* [Argo Workflows and Pipelines - CI/CD, Machine Learning, and Other Kubernetes Workflows](https://youtu.be/UMaivwrAyTA)
* [Argo Ansible role: Provisioning Argo Workflows on OpenShift](https://medium.com/@marekermk/provisioning-argo-on-openshift-with-ansible-and-kustomize-340a1fda8b50)
* [Argo Workflows vs Apache Airflow](http://bit.ly/30YNIvT)
* [Beyond Prototypes: Production-Ready ML Systems with Metaflow and Argo](https://github.com/terrytangyuan/public-talks/tree/main/talks/kubecon-na-2023-metaflow-argo)
* [CI/CD with Argo on Kubernetes](https://medium.com/@bouwe.ceunen/ci-cd-with-argo-on-kubernetes-28c1a99616a9)
* [Define Your CI/CD Pipeline with Argo Workflows](https://haque-zubair.medium.com/define-your-ci-cd-pipeline-with-argo-workflows-25aefb02fa63)
* [Distributed Machine Learning Patterns from Manning Publication](https://github.com/terrytangyuan/distributed-ml-patterns)
* [Engineering Cloud Native AI Platform](https://github.com/terrytangyuan/public-talks/tree/main/talks/platform-con-2024-engineering-cloud-native-ai-platform)
* [Managing Thousands of Automatic Machine Learning Experiments with Argo and Katib](https://github.com/terrytangyuan/public-talks/blob/main/talks/argocon-automl-experiments-2022)
* [Revolutionizing Scientific Simulations with Argo Workflows](https://www.youtube.com/watch?v=BYVf7GhfiRg)
* [Running Argo Workflows Across Multiple Kubernetes Clusters](https://admiralty.io/blog/running-argo-workflows-across-multiple-kubernetes-clusters/)
* [Scaling Kubernetes: Best Practices for Managing Large-Scale Batch Jobs with Spark and Argo Workflow](https://www.youtube.com/watch?v=KqEKRPjy4aE)
* [Open Source Model Management Roundup: Polyaxon, Argo, and Seldon](https://www.anaconda.com/blog/developer-blog/open-source-model-management-roundup-polyaxon-argo-and-seldon/)
* [Producing 200 OpenStreetMap extracts in 35 minutes using a scalable data workflow](https://www.interline.io/blog/scaling-openstreetmap-data-workflows/)
* [Production-Ready AI Platform on Kubernetes](https://github.com/terrytangyuan/public-talks/tree/main/talks/kubecon-europe-2024-production-ai-platform-on-k8s)
* [Argo integration review](http://dev.matt.hillsdon.net/2018/03/24/argo-integration-review.html)
* TGI Kubernetes with Joe Beda: [Argo workflow system](https://www.youtube.com/watch?v=M_rxPPLG8pU&amp;start=859)

## Project Resources

* [Argo Project GitHub organization](https://github.com/argoproj)
* [Argo Website](https://argoproj.github.io/)
* [Argo Slack](https://argoproj.github.io/community/join-slack)

## Security

See [SECURITY.md](SECURITY.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grafana/k6]]></title>
            <link>https://github.com/grafana/k6</link>
            <guid>https://github.com/grafana/k6</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[A modern load testing tool, using Go and JavaScript - https://k6.io]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grafana/k6">grafana/k6</a></h1>
            <p>A modern load testing tool, using Go and JavaScript - https://k6.io</p>
            <p>Language: Go</p>
            <p>Stars: 27,060</p>
            <p>Forks: 1,323</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://grafana.com/oss/k6/&quot;&gt;
    &lt;picture&gt;
      &lt;img src=&quot;assets/logo.svg&quot; alt=&quot;Grafana k6&quot; width=&quot;210&quot; height=&quot;210&quot; /&gt;&lt;br&gt;
    &lt;/picture&gt;
    &lt;br&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/grafana-labs-dark-theme.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/grafana-labs.svg&quot;&gt;
      &lt;img src=&quot;assets/grafana-labs.svg&quot; alt=&quot;Grafana Labs&quot; width=&quot;210&quot; /&gt;
    &lt;/picture&gt;
    &lt;br&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;Like unit testing, for performance&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;Modern load testing for developers and testers in the DevOps era.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/grafana/k6/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/grafana/k6.svg&quot; alt=&quot;Github release&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/grafana/k6/actions/workflows/all.yml&quot;&gt;&lt;img src=&quot;https://github.com/grafana/k6/actions/workflows/build.yml/badge.svg&quot; alt=&quot;Build status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/grafana/k6&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/grafana/k6&quot; alt=&quot;Go Report Card&quot;&gt;&lt;/a&gt;
 &lt;a href=&quot;https://codecov.io/gh/grafana/k6&quot;&gt;&lt;img src=&quot;https://img.shields.io/codecov/c/github/grafana/k6/master.svg&quot; alt=&quot;Codecov branch&quot;&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://twitter.com/k6_io&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/twitter-@k6_io-55acee.svg&quot; alt=&quot;@k6_io on Twitter&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/grafana/k6/releases&quot;&gt;Download&lt;/a&gt; ·
    &lt;a href=&quot;https://grafana.com/docs/k6/latest/&quot;&gt;Documentation&lt;/a&gt; ·
    &lt;a href=&quot;https://community.grafana.com/c/grafana-k6/70&quot;&gt;Community Forum&lt;/a&gt; ·
    &lt;a href=&quot;https://github.com/orgs/grafana/projects/443/views/1&quot;&gt;Public Roadmap&lt;/a&gt;
&lt;/p&gt;

&lt;br/&gt;
&lt;img src=&quot;assets/github-hr.png&quot; alt=&quot;---&quot; /&gt;
&lt;br/&gt;

**k6** is a modern load-testing tool, built on [our years of experience](https://k6.io/about) in the performance and testing industries.
It&#039;s built to be powerful, extensible, and full-featured. The key design goal is to provide **the best developer experience**.

Its core features are:

- **Configurable load generation.** Even lower-end machines can simulate lots of traffic.
- **Tests as code.** Reuse scripts, modularize logic, version control, and integrate tests with your CI.
- **A full-featured API.** The scripting API is packed with features that help you simulate real application traffic.
- **An embedded JavaScript engine.** The performance of Go, the scripting familiarity of JavaScript.
- **Multiple Protocol support**. HTTP, WebSockets, gRPC, Browser, and more.
- **Large extension ecosystem.** You can extend k6 to support your needs. And many people have already shared their extensions with the community!
- **Flexible metrics storage and visualization**. Summary statistics or granular metrics, exported to the service of your choice.
- **Native integration with Grafana cloud**. [SaaS solution](https://grafana.com/products/cloud/k6/) for test execution, metrics correlation, data analysis, and more.

This is what load testing looks like in the 21st century.

## Example script


```js
import http from &quot;k6/http&quot;;
import { check, sleep } from &quot;k6&quot;;

// Test configuration
export const options = {
  thresholds: {
    // Assert that 99% of requests finish within 3000ms.
    http_req_duration: [&quot;p(99) &lt; 3000&quot;],
  },
  // Ramp the number of virtual users up and down
  stages: [
    { duration: &quot;30s&quot;, target: 15 },
    { duration: &quot;1m&quot;, target: 15 },
    { duration: &quot;20s&quot;, target: 0 },
  ],
};

// Simulated user behavior
export default function () {
  let res = http.get(&quot;https://quickpizza.grafana.com&quot;);
  // Validate response status
  check(res, { &quot;status was 200&quot;: (r) =&gt; r.status == 200 });
  sleep(1);
}
```

You can run scripts like this on the CLI, or in your CI, or across a Kubernetes cluster.

## Documentation

The docs cover all aspects of using k6. Some highlights include:

- [Get Started](https://grafana.com/docs/k6/latest/). Install, run a test, inspect results.
- [HTTP requests](https://grafana.com/docs/k6/latest/using-k6/http-requests/). Have your virtual users use HTTP methods.
  Or, check the other [Protocols](https://grafana.com/docs/k6/latest/using-k6/protocols/).
- [Thresholds](https://grafana.com/docs/k6/latest/using-k6/thresholds/). Set goals for your test, and codify your SLOs.
- [Options](https://grafana.com/docs/k6/latest/using-k6/k6-options/). Configure your load, duration, TLS certificates, and much, much more.
- [Scenarios](https://grafana.com/docs/k6/latest/using-k6/scenarios/).
  Choose how to model your workload: open models, closed models, constant RPS, fixed iterations, and more.
- [Results output](https://grafana.com/docs/k6/latest/results-output/). Study, filter, and export your test results.
- [JavaScript API](https://grafana.com/docs/k6/latest/javascript-api/). Reference and examples of all k6 modules.
- [Extensions](https://grafana.com/docs/k6/latest/extensions/). Extend k6 for new protocols and use cases.

These links barely scratch the surface! If you&#039;re looking for conceptual information, you can read about [Test types](https://grafana.com/docs/k6/latest/testing-guides/test-types/), [Test strategies](https://grafana.com/docs/k6/latest/testing-guides/), or one of the many informative [Blog posts](https://k6.io/blog).

## Roadmap

Our team is dedicated to continuously improving and providing the best user experience possible. The [public roadmap](https://github.com/orgs/grafana/projects/443/views/1) covers user-oriented features, UX improvements and JavaScript support that our team will focus on. Remember that timeframes and priorities may shift, but we believe it&#039;s important to share our vision.

We hope it provides a clear overview of our plans for future development. We welcome feedback, corrections, and suggestions via GitHub to make it more comprehensive, accessible, and valuable for the community.

It&#039;s worth mentioning that we consider [upvotes (thumbs-up)](https://github.com/grafana/k6/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc) to be one of the essential metrics for determining community needs. If you want to show us the importance of a feature, please give it a thumbs-up.

## Contribute

If you want to contribute or help with the development of k6, start by reading [CONTRIBUTING.md](CONTRIBUTING.md). Before you start coding, it might be a good idea to first discuss your plans and implementation details with the k6 maintainers—especially when it comes to big changes and features. You can do this in the [GitHub issue](https://github.com/grafana/k6/issues) for the problem you&#039;re solving (create one if it doesn&#039;t exist).

&gt; **Note:** To disclose security issues, refer to [SECURITY.md](SECURITY.md).

## Support

To get help, report bugs, suggest features, and discuss k6 with others, refer to [SUPPORT.md](SUPPORT.md).

## License

k6 is distributed under the [AGPL-3.0 license](https://github.com/grafana/k6/blob/master/LICENSE.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[stretchr/testify]]></title>
            <link>https://github.com/stretchr/testify</link>
            <guid>https://github.com/stretchr/testify</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[A toolkit with common assertions and mocks that plays nicely with the standard library]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stretchr/testify">stretchr/testify</a></h1>
            <p>A toolkit with common assertions and mocks that plays nicely with the standard library</p>
            <p>Language: Go</p>
            <p>Stars: 24,258</p>
            <p>Forks: 1,623</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>Testify - Thou Shalt Write Tests
================================

&gt; [!NOTE]
&gt; Testify is being maintained at v1, no breaking changes will be accepted in this repo.  
&gt; [See discussion about v2](https://github.com/stretchr/testify/discussions/1560).

[![Build Status](https://github.com/stretchr/testify/actions/workflows/main.yml/badge.svg?branch=master)](https://github.com/stretchr/testify/actions/workflows/main.yml) [![Go Report Card](https://goreportcard.com/badge/github.com/stretchr/testify)](https://goreportcard.com/report/github.com/stretchr/testify) [![PkgGoDev](https://pkg.go.dev/badge/github.com/stretchr/testify)](https://pkg.go.dev/github.com/stretchr/testify)

Go code (golang) set of packages that provide many tools for testifying that your code will behave as you intend.

Features include:

  * [Easy assertions](#assert-package)
  * [Mocking](#mock-package)
  * [Testing suite interfaces and functions](#suite-package)

Get started:

  * Install testify with [one line of code](#installation), or [update it with another](#staying-up-to-date)
  * For an introduction to writing test code in Go, see https://go.dev/doc/code#Testing
  * Check out the API Documentation https://pkg.go.dev/github.com/stretchr/testify
  * Use [testifylint](https://github.com/Antonboom/testifylint) (via [golangci-lint](https://golangci-lint.run/)) to avoid common mistakes
  * A little about [Test-Driven Development (TDD)](https://en.wikipedia.org/wiki/Test-driven_development)

[`assert`](https://pkg.go.dev/github.com/stretchr/testify/assert &quot;API documentation&quot;) package
-------------------------------------------------------------------------------------------

The `assert` package provides some helpful methods that allow you to write better test code in Go.

  * Prints friendly, easy to read failure descriptions
  * Allows for very readable code
  * Optionally annotate each assertion with a message

See it in action:

```go
package yours

import (
  &quot;testing&quot;
  &quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {

  // assert equality
  assert.Equal(t, 123, 123, &quot;they should be equal&quot;)

  // assert inequality
  assert.NotEqual(t, 123, 456, &quot;they should not be equal&quot;)

  // assert for nil (good for errors)
  assert.Nil(t, object)

  // assert for not nil (good when you expect something)
  if assert.NotNil(t, object) {

    // now we know that object isn&#039;t nil, we are safe to make
    // further assertions without causing any errors
    assert.Equal(t, &quot;Something&quot;, object.Value)

  }

}
```

  * Every assert func takes the `testing.T` object as the first argument.  This is how it writes the errors out through the normal `go test` capabilities.
  * Every assert func returns a bool indicating whether the assertion was successful or not, this is useful for if you want to go on making further assertions under certain conditions.

if you assert many times, use the below:

```go
package yours

import (
  &quot;testing&quot;
  &quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
  assert := assert.New(t)

  // assert equality
  assert.Equal(123, 123, &quot;they should be equal&quot;)

  // assert inequality
  assert.NotEqual(123, 456, &quot;they should not be equal&quot;)

  // assert for nil (good for errors)
  assert.Nil(object)

  // assert for not nil (good when you expect something)
  if assert.NotNil(object) {

    // now we know that object isn&#039;t nil, we are safe to make
    // further assertions without causing any errors
    assert.Equal(&quot;Something&quot;, object.Value)
  }
}
```

[`require`](https://pkg.go.dev/github.com/stretchr/testify/require &quot;API documentation&quot;) package
---------------------------------------------------------------------------------------------

The `require` package provides same global functions as the `assert` package, but instead of returning a boolean result they terminate current test.
These functions must be called from the goroutine running the test or benchmark function, not from other goroutines created during the test.
Otherwise race conditions may occur.

See [t.FailNow](https://pkg.go.dev/testing#T.FailNow) for details.

[`mock`](https://pkg.go.dev/github.com/stretchr/testify/mock &quot;API documentation&quot;) package
----------------------------------------------------------------------------------------

The `mock` package provides a mechanism for easily writing mock objects that can be used in place of real objects when writing test code.

An example test function that tests a piece of code that relies on an external object `testObj`, can set up expectations (testify) and assert that they indeed happened:

```go
package yours

import (
  &quot;testing&quot;
  &quot;github.com/stretchr/testify/mock&quot;
)

/*
  Test objects
*/

// MyMockedObject is a mocked object that implements an interface
// that describes an object that the code I am testing relies on.
type MyMockedObject struct{
  mock.Mock
}

// DoSomething is a method on MyMockedObject that implements some interface
// and just records the activity, and returns what the Mock object tells it to.
//
// In the real object, this method would do something useful, but since this
// is a mocked object - we&#039;re just going to stub it out.
//
// NOTE: This method is not being tested here, code that uses this object is.
func (m *MyMockedObject) DoSomething(number int) (bool, error) {

  args := m.Called(number)
  return args.Bool(0), args.Error(1)

}

/*
  Actual test functions
*/

// TestSomething is an example of how to use our test object to
// make assertions about some target code we are testing.
func TestSomething(t *testing.T) {

  // create an instance of our test object
  testObj := new(MyMockedObject)

  // set up expectations
  testObj.On(&quot;DoSomething&quot;, 123).Return(true, nil)

  // call the code we are testing
  targetFuncThatDoesSomethingWithObj(testObj)

  // assert that the expectations were met
  testObj.AssertExpectations(t)


}

// TestSomethingWithPlaceholder is a second example of how to use our test object to
// make assertions about some target code we are testing.
// This time using a placeholder. Placeholders might be used when the
// data being passed in is normally dynamically generated and cannot be
// predicted beforehand (eg. containing hashes that are time sensitive)
func TestSomethingWithPlaceholder(t *testing.T) {

  // create an instance of our test object
  testObj := new(MyMockedObject)

  // set up expectations with a placeholder in the argument list
  testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

  // call the code we are testing
  targetFuncThatDoesSomethingWithObj(testObj)

  // assert that the expectations were met
  testObj.AssertExpectations(t)


}

// TestSomethingElse2 is a third example that shows how you can use
// the Unset method to cleanup handlers and then add new ones.
func TestSomethingElse2(t *testing.T) {

  // create an instance of our test object
  testObj := new(MyMockedObject)

  // set up expectations with a placeholder in the argument list
  mockCall := testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

  // call the code we are testing
  targetFuncThatDoesSomethingWithObj(testObj)

  // assert that the expectations were met
  testObj.AssertExpectations(t)

  // remove the handler now so we can add another one that takes precedence
  mockCall.Unset()

  // return false now instead of true
  testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(false, nil)

  testObj.AssertExpectations(t)
}
```

For more information on how to write mock code, check out the [API documentation for the `mock` package](https://pkg.go.dev/github.com/stretchr/testify/mock).

You can use the [mockery tool](https://vektra.github.io/mockery/latest/) to autogenerate the mock code against an interface as well, making using mocks much quicker.

[`suite`](https://pkg.go.dev/github.com/stretchr/testify/suite &quot;API documentation&quot;) package
-----------------------------------------------------------------------------------------
&gt; [!WARNING]
&gt; The suite package does not support parallel tests. See [#934](https://github.com/stretchr/testify/issues/934).

The `suite` package provides functionality that you might be used to from more common object-oriented languages.  With it, you can build a testing suite as a struct, build setup/teardown methods and testing methods on your struct, and run them with &#039;go test&#039; as per normal.

An example suite is shown below:

```go
// Basic imports
import (
    &quot;testing&quot;
    &quot;github.com/stretchr/testify/assert&quot;
    &quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including a T() method which
// returns the current testing context
type ExampleTestSuite struct {
    suite.Suite
    VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
    suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
    assert.Equal(suite.T(), 5, suite.VariableThatShouldStartAtFive)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
    suite.Run(t, new(ExampleTestSuite))
}
```

For a more complete example, using all of the functionality provided by the suite package, look at our [example testing suite](https://github.com/stretchr/testify/blob/master/suite/suite_test.go)

For more information on writing suites, check out the [API documentation for the `suite` package](https://pkg.go.dev/github.com/stretchr/testify/suite).

`Suite` object has assertion methods:

```go
// Basic imports
import (
    &quot;testing&quot;
    &quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including assertion methods.
type ExampleTestSuite struct {
    suite.Suite
    VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
    suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
    suite.Equal(suite.VariableThatShouldStartAtFive, 5)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
    suite.Run(t, new(ExampleTestSuite))
}
```

------

Installation
============

To install Testify, use `go get`:

    go get github.com/stretchr/testify

This will then make the following packages available to you:

    github.com/stretchr/testify/assert
    github.com/stretchr/testify/require
    github.com/stretchr/testify/mock
    github.com/stretchr/testify/suite
    github.com/stretchr/testify/http (deprecated)

Import the `testify/assert` package into your code using this template:

```go
package yours

import (
  &quot;testing&quot;
  &quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {

  assert.True(t, true, &quot;True is true!&quot;)

}
```

------

Staying up to date
==================

To update Testify to the latest version, use `go get -u github.com/stretchr/testify`.

------

Supported go versions
==================

We currently support the most recent major Go versions from 1.19 onward.

------

Contributing
============

Please feel free to submit issues, fork the repository and send pull requests!

When submitting an issue, we ask that you please include a complete test function that demonstrates the issue. Extra credit for those using Testify to write the test code that demonstrates it.

Code generation is used. [Look for `Code generated with`](https://github.com/search?q=repo%3Astretchr%2Ftestify%20%22Code%20generated%20with%22&amp;type=code) at the top of some files. Run `go generate ./...` to update generated files.

We also chat on the [Gophers Slack](https://gophers.slack.com) group in the `#testify` and `#testify-dev` channels.

------

License
=======

This project is licensed under the terms of the MIT license.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes-sigs/metrics-server]]></title>
            <link>https://github.com/kubernetes-sigs/metrics-server</link>
            <guid>https://github.com/kubernetes-sigs/metrics-server</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[Scalable and efficient source of container resource metrics for Kubernetes built-in autoscaling pipelines.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes-sigs/metrics-server">kubernetes-sigs/metrics-server</a></h1>
            <p>Scalable and efficient source of container resource metrics for Kubernetes built-in autoscaling pipelines.</p>
            <p>Language: Go</p>
            <p>Stars: 6,027</p>
            <p>Forks: 1,917</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># Kubernetes Metrics Server

Metrics Server is a scalable, efficient source of container resource metrics for Kubernetes
built-in autoscaling pipelines.

Metrics Server collects resource metrics from Kubelets and exposes them in Kubernetes apiserver through [Metrics API]
for use by [Horizontal Pod Autoscaler] and [Vertical Pod Autoscaler]. Metrics API can also be accessed by `kubectl top`,
making it easier to debug autoscaling pipelines.

&gt; [!CAUTION]
&gt; Metrics Server is meant only for autoscaling purposes. For example, don&#039;t use it to forward metrics to monitoring solutions, or as a source of monitoring solution metrics. In such cases please collect metrics from Kubelet `/metrics/resource` endpoint directly.

Metrics Server offers:

- A single deployment that works on most clusters (see [Requirements](#requirements))
- Fast autoscaling, collecting metrics every 15 seconds.
- Resource efficiency, using 1 mili core of CPU and 2 MB of memory for each node in a cluster.
- Scalable support up to 5,000 node clusters.

[Metrics API]: https://github.com/kubernetes/metrics
[Horizontal Pod Autoscaler]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
[Vertical Pod Autoscaler]: https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/

## Use cases

You can use Metrics Server for:

- CPU/Memory based horizontal autoscaling (learn more about [Horizontal Autoscaling])
- Automatically adjusting/suggesting resources needed by containers (learn more about [Vertical Autoscaling])

Don&#039;t use Metrics Server when you need:

- Non-Kubernetes clusters
- An accurate source of resource usage metrics
- Horizontal autoscaling based on other resources than CPU/Memory

For unsupported use cases, check out full monitoring solutions like [Prometheus](https://github.com/prometheus/prometheus).

[Horizontal Autoscaling]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
[Vertical Autoscaling]: https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/

## Requirements

Metrics Server has specific requirements for cluster and network configuration. These requirements aren&#039;t the default for all cluster
distributions. Please ensure that your cluster distribution supports these requirements before using Metrics Server:

- The kube-apiserver must [enable an aggregation layer].
- Nodes must have Webhook [authentication and authorization] enabled.
- Kubelet certificate needs to be signed by cluster Certificate Authority (or disable certificate validation by passing `--kubelet-insecure-tls` to Metrics Server)
- Container runtime must implement a [container metrics RPCs] (or have [cAdvisor] support)
- Network should support following communication:
  - Control plane to Metrics Server. Control plane node needs to reach Metrics Server&#039;s pod IP and port 10250 (or node IP and custom port if `hostNetwork` is enabled). Read more about [control plane to node communication](https://kubernetes.io/docs/concepts/architecture/control-plane-node-communication/#control-plane-to-node).
  - Metrics Server to Kubelet on all nodes. Metrics server needs to reach node address and Kubelet port. Addresses and ports are configured in Kubelet and published as part of Node object. Addresses in `.status.addresses` and port in `.status.daemonEndpoints.kubeletEndpoint.port` field (default 10250). Metrics Server will pick first node address based on the list provided by `kubelet-preferred-address-types` command line flag (default `InternalIP,ExternalIP,Hostname` in manifests).

[reachable from kube-apiserver]: https://kubernetes.io/docs/concepts/architecture/master-node-communication/#master-to-cluster
[enable an aggregation layer]: https://kubernetes.io/docs/tasks/access-kubernetes-api/configure-aggregation-layer/
[authentication and authorization]: https://kubernetes.io/docs/reference/access-authn-authz/kubelet-authn-authz/
[container metrics RPCs]: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/cri-container-stats.md
[cAdvisor]: https://github.com/google/cadvisor

## Installation

Metrics Server can be installed either directly from YAML manifest or via the official [Helm chart](https://artifacthub.io/packages/helm/metrics-server/metrics-server). To install the latest Metrics Server release from the _components.yaml_ manifest, run the following command.

```shell
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

Installation instructions for previous releases can be found in [Metrics Server releases](https://github.com/kubernetes-sigs/metrics-server/releases).

### Compatibility Matrix

Metrics Server | Metrics API group/version | Supported Kubernetes version
---------------|---------------------------|-----------------------------
0.7.x          | `metrics.k8s.io/v1beta1`  | 1.19+
0.6.x          | `metrics.k8s.io/v1beta1`  | 1.19+
0.5.x          | `metrics.k8s.io/v1beta1`  | *1.8+
0.4.x          | `metrics.k8s.io/v1beta1`  | *1.8+
0.3.x          | `metrics.k8s.io/v1beta1`  | 1.8-1.21

*Kubernetes versions lower than v1.16 require passing the `--authorization-always-allow-paths=/livez,/readyz` command line flag

### High Availability

Metrics Server can be installed in high availability mode directly from a YAML manifest or via the official [Helm chart](https://artifacthub.io/packages/helm/metrics-server/metrics-server) by setting the `replicas` value greater than `1`. To install the latest Metrics Server release in high availability mode from the  _high-availability.yaml_ manifest, run the following command.

On Kubernetes v1.21+:
```
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/high-availability-1.21+.yaml
```

On Kubernetes v1.19-1.21:
```shell
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/high-availability.yaml
```

&gt;[!NOTE]
&gt; This configuration **requires** having a cluster with at least 2 nodes on which Metrics Server can be scheduled.

Also, to maximize the efficiency of this highly available configuration, it is **recommended** to add the `--enable-aggregator-routing=true` CLI flag to the kube-apiserver so that requests sent to Metrics Server are load balanced between the 2 instances.

### Helm Chart

The [Helm chart](https://artifacthub.io/packages/helm/metrics-server/metrics-server) is maintained as an additional component within this repo and released into a chart repository backed on the `gh-pages` branch. A new version of the chart will be released for each Metrics Server release and can also be released independently if there is a need. The chart on the `master` branch shouldn&#039;t be referenced directly as it might contain modifications since it was last released, to view the chart code use the chart release tag.

## Security context

Metrics Server requires the `CAP_NET_BIND_SERVICE` capability in order to bind to a privileged ports as non-root.
If you are running Metrics Server in an environment that uses [PSSs](https://kubernetes.io/docs/concepts/security/pod-security-standards/) or other mechanisms to restrict pod capabilities, ensure that Metrics Server is allowed
to use this capability.
This applies even if you use the `--secure-port` flag to change the port that Metrics Server binds to a non-privileged port.

## Scaling

Starting from v0.5.0 Metrics Server comes with default resource requests that should guarantee good performance for most cluster configurations up to 100 nodes:

- 100m core of CPU
- 200MiB of memory

Metrics Server resource usage depends on multiple independent dimensions, creating a [Scalability Envelope].
Default Metrics Server configuration should work in clusters that don&#039;t exceed any of the thresholds listed below:

Quantity               | Namespace threshold | Cluster threshold
-----------------------|---------------------|------------------
#Nodes                 | n/a                 | 100
#Pods per node         | 70                  | 70
#Deployments with HPAs | 100                 | 100

Resources can be adjusted proportionally based on number of nodes in the cluster.
For clusters of more than 100 nodes, allocate additionally:

- 1m core per node
- 2MiB memory per node

You can use the same approach to lower resource requests, but there is a boundary
where this may impact other scalability dimensions like maximum number of pods per node.

[Scalability Envelope]: https://github.com/kubernetes/community/blob/master/sig-scalability/configs-and-limits/thresholds.md

### Configuration

Depending on your cluster setup, you may also need to change flags passed to the Metrics Server container.
Most useful flags:

- `--kubelet-preferred-address-types` - The priority of node address types used when determining an address for connecting to a particular node (default [Hostname,InternalDNS,InternalIP,ExternalDNS,ExternalIP])
- `--kubelet-insecure-tls` - Do not verify the CA of serving certificates presented by Kubelets. For testing purposes only.
- `--requestheader-client-ca-file` - Specify a root certificate bundle for verifying client certificates on incoming requests.
- `--node-selector` -Can complete to scrape the metrics from the Specified nodes based on labels

You can get a full list of Metrics Server configuration flags by running:

```shell
docker run --rm registry.k8s.io/metrics-server/metrics-server:v0.7.0 --help
```

## Design

Metrics Server is a component in the core metrics pipeline described in [Kubernetes monitoring architecture].

For more information, see:

- [Metrics API design]
- [Metrics Server design]

[Kubernetes monitoring architecture]: https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/monitoring_architecture.md
[Metrics API design]: https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/resource-metrics-api.md
[Metrics Server design]: https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/metrics-server.md

## Have a question?

Before posting an issue, first checkout [Frequently Asked Questions] and [Known Issues].

[Frequently Asked Questions]: FAQ.md
[Known Issues]: KNOWN_ISSUES.md

## Community, discussion, contribution, and support

Learn how to engage with the Kubernetes community on the [community page].

You can reach the maintainers of this project at:

- [Slack channel]
- [Mailing list]

This project is maintained by [SIG Instrumentation]

[community page]: http://kubernetes.io/community/
[Slack channel]: https://kubernetes.slack.com/messages/sig-instrumentation
[Mailing list]: https://groups.google.com/forum/#!forum/kubernetes-sig-instrumentation
[SIG Instrumentation]: https://github.com/kubernetes/community/tree/master/sig-instrumentation

### Code of conduct

Participation in the Kubernetes community is governed by the [Kubernetes Code of Conduct].

[Kubernetes Code of Conduct]: code-of-conduct.md
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cilium/cilium]]></title>
            <link>https://github.com/cilium/cilium</link>
            <guid>https://github.com/cilium/cilium</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[eBPF-based Networking, Security, and Observability]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cilium/cilium">cilium/cilium</a></h1>
            <p>eBPF-based Networking, Security, and Observability</p>
            <p>Language: Go</p>
            <p>Stars: 21,149</p>
            <p>Forks: 3,126</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes-sigs/external-dns]]></title>
            <link>https://github.com/kubernetes-sigs/external-dns</link>
            <guid>https://github.com/kubernetes-sigs/external-dns</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[Configure external DNS servers (AWS Route53, Google CloudDNS and others) for Kubernetes Ingresses and Services]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes-sigs/external-dns">kubernetes-sigs/external-dns</a></h1>
            <p>Configure external DNS servers (AWS Route53, Google CloudDNS and others) for Kubernetes Ingresses and Services</p>
            <p>Language: Go</p>
            <p>Stars: 8,002</p>
            <p>Forks: 2,637</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>---
hide:
  - toc
  - navigation
---

&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;docs/img/external-dns.png&quot; width=&quot;40%&quot; align=&quot;center&quot; alt=&quot;ExternalDNS&quot;&gt;
&lt;/p&gt;

# ExternalDNS

[![Build Status](https://github.com/kubernetes-sigs/external-dns/workflows/Go/badge.svg)](https://github.com/kubernetes-sigs/external-dns/actions)
[![Coverage Status](https://coveralls.io/repos/github/kubernetes-sigs/external-dns/badge.svg)](https://coveralls.io/github/kubernetes-sigs/external-dns)
[![GitHub release](https://img.shields.io/github/release/kubernetes-sigs/external-dns.svg)](https://github.com/kubernetes-sigs/external-dns/releases)
[![go-doc](https://godoc.org/github.com/kubernetes-sigs/external-dns?status.svg)](https://godoc.org/github.com/kubernetes-sigs/external-dns)
[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes-sigs/external-dns)](https://goreportcard.com/report/github.com/kubernetes-sigs/external-dns)
[![ExternalDNS docs](https://img.shields.io/badge/docs-external--dns-blue)](https://kubernetes-sigs.github.io/external-dns/)

ExternalDNS synchronizes exposed Kubernetes Services and Ingresses with DNS providers.

## Documentation

This README is a part of the complete documentation, available [here](https://kubernetes-sigs.github.io/external-dns/).

## What It Does

Inspired by [Kubernetes DNS](https://github.com/kubernetes/dns), Kubernetes&#039; cluster-internal DNS server, ExternalDNS makes Kubernetes resources discoverable via public DNS servers.
Like KubeDNS, it retrieves a list of resources (Services, Ingresses, etc.) from the [Kubernetes API](https://kubernetes.io/docs/api/) to determine a desired list of DNS records.
*Unlike* KubeDNS, however, it&#039;s not a DNS server itself, but merely configures other DNS providers accordingly—e.g. [AWS Route 53](https://aws.amazon.com/route53/) or [Google Cloud DNS](https://cloud.google.com/dns/docs/).

In a broader sense, ExternalDNS allows you to control DNS records dynamically via Kubernetes resources in a DNS provider-agnostic way.

The [FAQ](docs/faq.md) contains additional information and addresses several questions about key concepts of ExternalDNS.

To see ExternalDNS in action, have a look at this [video](https://www.youtube.com/watch?v=9HQ2XgL9YVI) or read this [blogpost](https://codemine.be/posts/20190125-devops-eks-externaldns/).

## The Latest Release

- [current release process](./docs/release.md)

ExternalDNS allows you to keep selected zones (via `--domain-filter`) synchronized with Ingresses and Services of `type=LoadBalancer` and nodes in various DNS providers:

- [Google Cloud DNS](https://cloud.google.com/dns/docs/)
- [AWS Route 53](https://aws.amazon.com/route53/)
- [AWS Cloud Map](https://docs.aws.amazon.com/cloud-map/)
- [AzureDNS](https://azure.microsoft.com/en-us/services/dns)
- [Civo](https://www.civo.com)
- [CloudFlare](https://www.cloudflare.com/dns)
- [DigitalOcean](https://www.digitalocean.com/products/networking)
- [DNSimple](https://dnsimple.com/)
- [PowerDNS](https://www.powerdns.com/)
- [CoreDNS](https://coredns.io/)
- [Exoscale](https://www.exoscale.com/dns/)
- [Oracle Cloud Infrastructure DNS](https://docs.cloud.oracle.com/iaas/Content/DNS/Concepts/dnszonemanagement.htm)
- [Linode DNS](https://www.linode.com/docs/networking/dns/)
- [RFC2136](https://tools.ietf.org/html/rfc2136)
- [NS1](https://ns1.com/)
- [TransIP](https://www.transip.eu/domain-name/)
- [OVHcloud](https://www.ovhcloud.com)
- [Scaleway](https://www.scaleway.com)
- [Akamai Edge DNS](https://learn.akamai.com/en-us/products/cloud_security/edge_dns.html)
- [GoDaddy](https://www.godaddy.com)
- [Gandi](https://www.gandi.net)
- [IBM Cloud DNS](https://www.ibm.com/cloud/dns)
- [TencentCloud PrivateDNS](https://cloud.tencent.com/product/privatedns)
- [TencentCloud DNSPod](https://cloud.tencent.com/product/cns)
- [Plural](https://www.plural.sh/)
- [Pi-hole](https://pi-hole.net/)

ExternalDNS is, by default, aware of the records it is managing, therefore it can safely manage non-empty hosted zones.
We strongly encourage you to set `--txt-owner-id` to a unique value that doesn&#039;t change for the lifetime of your cluster.
You might also want to run ExternalDNS in a dry run mode (`--dry-run` flag) to see the changes to be submitted to your DNS Provider API.

Note that all flags can be replaced with environment variables; for instance,
`--dry-run` could be replaced with `EXTERNAL_DNS_DRY_RUN=1`.

## New providers

No new provider will be added to ExternalDNS *in-tree*.

ExternalDNS has introduced a webhook system, which can be used to add a new provider.
See PR #3063 for all the discussions about it.

Known providers using webhooks:

| Provider              | Repo                                                                 |
| --------------------- | -------------------------------------------------------------------- |
| Abion                 | https://github.com/abiondevelopment/external-dns-webhook-abion       |
| Adguard Home Provider | https://github.com/muhlba91/external-dns-provider-adguard            |
| Anexia                | https://github.com/ProbstenHias/external-dns-anexia-webhook          |
| Bizfly Cloud          | https://github.com/bizflycloud/external-dns-bizflycloud-webhook      |
| ClouDNS               | https://github.com/rwunderer/external-dns-cloudns-webhook            |
| Dreamhost             | https://github.com/asymingt/external-dns-dreamhost-webhook           |
| Efficient IP          | https://github.com/EfficientIP-Labs/external-dns-efficientip-webhook |
| Gcore                 | https://github.com/G-Core/external-dns-gcore-webhook                 |
| GleSYS                | https://github.com/glesys/external-dns-glesys                        |
| Hetzner               | https://github.com/mconfalonieri/external-dns-hetzner-webhook        |
| Huawei Cloud          | https://github.com/setoru/external-dns-huaweicloud-webhook           |
| IONOS                 | https://github.com/ionos-cloud/external-dns-ionos-webhook            |
| Infoblox              | https://github.com/AbsaOSS/external-dns-infoblox-webhook             |
| Mikrotik              | https://github.com/mirceanton/external-dns-provider-mikrotik         |
| Netcup                | https://github.com/mrueg/external-dns-netcup-webhook                 |
| Netic                 | https://github.com/neticdk/external-dns-tidydns-webhook              |
| OpenStack Designate   | https://github.com/inovex/external-dns-designate-webhook             |
| OpenWRT               | https://github.com/renanqts/external-dns-openwrt-webhook             |
| RouterOS              | https://github.com/benfiola/external-dns-routeros-provider           |
| STACKIT               | https://github.com/stackitcloud/external-dns-stackit-webhook         |
| Unifi                 | https://github.com/kashalls/external-dns-unifi-webhook               |
| Vultr                 | https://github.com/vultr/external-dns-vultr-webhook                  |
| Yandex Cloud          | https://github.com/ismailbaskin/external-dns-yandex-webhook/         |

## Status of in-tree providers

ExternalDNS supports multiple DNS providers which have been implemented by the [ExternalDNS contributors](https://github.com/kubernetes-sigs/external-dns/graphs/contributors).
Maintaining all of those in a central repository is a challenge, which introduces lots of toil and potential risks.

This mean that `external-dns` has begun the process to move providers out of tree. See #4347 for more details.
Those who are interested can create a webhook provider based on an *in-tree* provider and after submit a PR to reference it here.

We define the following stability levels for providers:

- **Stable**: Used for smoke tests before a release, used in production and maintainers are active.
- **Beta**: Community supported, well tested, but maintainers have no access to resources to execute integration tests on the real platform and/or are not using it in production.
- **Alpha**: Community provided with no support from the maintainers apart from reviewing PRs.

The following table clarifies the current status of the providers according to the aforementioned stability levels:

| Provider | Status | Maintainers |
| -------- | ------ | ----------- |
| Google Cloud DNS | Stable | |
| AWS Route 53 | Stable | |
| AWS Cloud Map | Beta | |
| Akamai Edge DNS | Beta | |
| AzureDNS | Stable | |
| Civo | Alpha | @alejandrojnm |
| CloudFlare | Beta | |
| DigitalOcean | Alpha | |
| DNSimple | Alpha | |
| PowerDNS | Alpha | |
| CoreDNS | Alpha | |
| Exoscale | Alpha | |
| Oracle Cloud Infrastructure DNS | Alpha | |
| Linode DNS | Alpha | |
| RFC2136 | Alpha | |
| NS1 | Alpha | |
| TransIP | Alpha | |
| OVHcloud | Beta | @rbeuque74 |
| Scaleway DNS | Alpha | @Sh4d1 |
| UltraDNS | Alpha | |
| GoDaddy | Alpha | |
| Gandi | Alpha | @packi |
| IBMCloud | Alpha | @hughhuangzh |
| TencentCloud | Alpha | @Hyzhou |
| Plural | Alpha | @michaeljguarino |
| Pi-hole | Alpha | @tinyzimmer |

## Kubernetes version compatibility

A [breaking change](https://github.com/kubernetes-sigs/external-dns/pull/2281) was added in external-dns v0.10.0.

| ExternalDNS                    |      &lt;= 0.9.x      |     &gt;= 0.10.0      |
| ------------------------------ | :----------------: | :----------------: |
| Kubernetes &lt;= 1.18             | :white_check_mark: |        :x:         |
| Kubernetes &gt;= 1.19 and &lt;= 1.21 | :white_check_mark: | :white_check_mark: |
| Kubernetes &gt;= 1.22             |        :x:         | :white_check_mark: |

## Running ExternalDNS

The are two ways of running ExternalDNS:

- Deploying to a Cluster
- Running Locally

### Deploying to a Cluster

The following tutorials are provided:

- [Akamai Edge DNS](docs/tutorials/akamai-edgedns.md)
- [Alibaba Cloud](docs/tutorials/alibabacloud.md)
- AWS
  - [AWS Load Balancer Controller](docs/tutorials/aws-load-balancer-controller.md)
  - [Route53](docs/tutorials/aws.md)
    - [Same domain for public and private Route53 zones](docs/tutorials/aws-public-private-route53.md)
  - [Cloud Map](docs/tutorials/aws-sd.md)
  - [Kube Ingress AWS Controller](docs/tutorials/kube-ingress-aws.md)
- [Azure DNS](docs/tutorials/azure.md)
- [Azure Private DNS](docs/tutorials/azure-private-dns.md)
- [Civo](docs/tutorials/civo.md)
- [Cloudflare](docs/tutorials/cloudflare.md)
- [CoreDNS](docs/tutorials/coredns.md)
- [DigitalOcean](docs/tutorials/digitalocean.md)
- [DNSimple](docs/tutorials/dnsimple.md)
- [Exoscale](docs/tutorials/exoscale.md)
- [ExternalName Services](docs/tutorials/externalname.md)
- Google Kubernetes Engine
  - [Using Google&#039;s Default Ingress Controller](docs/tutorials/gke.md)
  - [Using the Nginx Ingress Controller](docs/tutorials/gke-nginx.md)
- [Headless Services](docs/tutorials/hostport.md)
- [Istio Gateway Source](docs/sources/istio.md)
- [Linode](docs/tutorials/linode.md)
- [NS1](docs/tutorials/ns1.md)
- [NS Record Creation with CRD Source](docs/sources/ns-record.md)
- [MX Record Creation with CRD Source](docs/sources/mx-record.md)
- [TXT Record Creation with CRD Source](docs/sources/txt-record.md)
- [Oracle Cloud Infrastructure (OCI) DNS](docs/tutorials/oracle.md)
- [PowerDNS](docs/tutorials/pdns.md)
- [RFC2136](docs/tutorials/rfc2136.md)
- [TransIP](docs/tutorials/transip.md)
- [OVHcloud](docs/tutorials/ovh.md)
- [Scaleway](docs/tutorials/scaleway.md)
- [UltraDNS](docs/tutorials/ultradns.md)
- [GoDaddy](docs/tutorials/godaddy.md)
- [Gandi](docs/tutorials/gandi.md)
- [IBM Cloud](docs/tutorials/ibmcloud.md)
- [Nodes as source](docs/sources/nodes.md)
- [TencentCloud](docs/tutorials/tencentcloud.md)
- [Plural](docs/tutorials/plural.md)
- [Pi-hole](docs/tutorials/pihole.md)

### Running Locally

See the [contributor guide](docs/contributing/getting-started.md) for details on compiling
from source.

#### Setup Steps

Next, run an application and expose it via a Kubernetes Service:

```console
kubectl run nginx --image=nginx --port=80
kubectl expose pod nginx --port=80 --target-port=80 --type=LoadBalancer
```

Annotate the Service with your desired external DNS name. Make sure to change `example.org` to your domain.

```console
kubectl annotate service nginx &quot;external-dns.alpha.kubernetes.io/hostname=nginx.example.org.&quot;
```

Optionally, you can customize the TTL value of the resulting DNS record by using the `external-dns.alpha.kubernetes.io/ttl` annotation:

```console
kubectl annotate service nginx &quot;external-dns.alpha.kubernetes.io/ttl=10&quot;
```

For more details on configuring TTL, see [here](docs/ttl.md).

Use the internal-hostname annotation to create DNS records with ClusterIP as the target.

```console
kubectl annotate service nginx &quot;external-dns.alpha.kubernetes.io/internal-hostname=nginx.internal.example.org.&quot;
```

If the service is not of type Loadbalancer you need the --publish-internal-services flag.

Locally run a single sync loop of ExternalDNS.

```console
external-dns --txt-owner-id my-cluster-id --provider google --google-project example-project --source service --once --dry-run
```

This should output the DNS records it will modify to match the managed zone with the DNS records you desire.
It also assumes you are running in the `default` namespace. See the [FAQ](docs/faq.md) for more information regarding namespaces.

Note: TXT records will have the `my-cluster-id` value embedded. Those are used to ensure that ExternalDNS is aware of the records it manages.

Once you&#039;re satisfied with the result, you can run ExternalDNS like you would run it in your cluster: as a control loop, and **not in dry-run** mode:

```console
external-dns --txt-owner-id my-cluster-id --provider google --google-project example-project --source service
```

Check that ExternalDNS has created the desired DNS record for your Service and that it points to its load balancer&#039;s IP. Then try to resolve it:

```console
dig +short nginx.example.org.
104.155.60.49
```

Now you can experiment and watch how ExternalDNS makes sure that your DNS records are configured as desired. Here are a couple of things you can try out:

- Change the desired hostname by modifying the Service&#039;s annotation.
- Recreate the Service and see that the DNS record will be updated to point to the new load balancer IP.
- Add another Service to create more DNS records.
- Remove Services to clean up your managed zone.

The **tutorials** section contains examples, including Ingress resources, and shows you how to set up ExternalDNS in different environments such as other cloud providers and alternative Ingress controllers.

# Note

If using a txt registry and attempting to use a CNAME the `--txt-prefix` must be set to avoid conflicts.  Changing `--txt-prefix` will result in lost ownership over previously created records.

If `externalIPs` list is defined for a `LoadBalancer` service, this list will be used instead of an assigned load balancer IP to create a DNS record.
It&#039;s useful when you run bare metal Kubernetes clusters behind NAT or in a similar setup, where a load balancer IP differs from a public IP (e.g. with [MetalLB](https://metallb.universe.tf)).

## Contributing

Are you interested in contributing to external-dns? We, the maintainers and community, would love your
suggestions, contributions, and help! Also, the maintainers can be contacted at any time to learn more
about how to get involved.

We also encourage ALL active community participants to act as if they are maintainers, even if you don&#039;t have
&quot;official&quot; write permissions. This is a community effort, we are here to serve the Kubernetes community. If you
have an active interest and you want to get involved, you have real power! Don&#039;t assume that the only people who
can get things done around here are the &quot;maintainers&quot;. We also would love to add more &quot;official&quot; maintainers, so
show us what you can do!

The external-dns project is currently in need of maintainers for specific DNS providers. Ideally each provider
would have at least two maintainers. It would be nice if the maintainers run the provider in production, but it
is not strictly required. Provider listed [here](https://github.com/kubernetes-sigs/external-dns#status-of-in-tree-providers)
that do not have a maintainer listed are in need of assistance.

Read the [contributing guidelines](CONTRIBUTING.md) and have a look at [the contributing docs](docs/contributing/dev-guide.md) to learn about building the project, the project structure, and the purpose of each package.

For an overview on how to write new Sources and Providers check out [Sources and Providers](docs/contributing/sources-and-providers.md).

## Heritage

ExternalDNS is an effort to unify the following similar projects in order to bring the Kubernetes community an easy and predictable way of managing DNS records across cloud providers based on their Kubernetes resources:

- Kops&#039; [DNS Controller](https://github.com/kubernetes/kops/tree/HEAD/dns-controller)
- Zalando&#039;s [Mate](https://github.com/linki/mate)
- Molecule Software&#039;s [route53-kubernetes](https://github.com/wearemolecule/route53-kubernetes)

### User Demo How-To Blogs and Examples

- A full demo on GKE Kubernetes. See [How-to Kubernetes with DNS management (ssl-manager pre-req)](https://medium.com/@jpantjsoha/how-to-kubernetes-with-dns-management-for-gitops-31239ea75d8d)
- Run external-dns on GKE with workload identity. See [Kubernetes, ingress-nginx, cert-manager &amp; external-dns](https://blog.atomist.com/kubernetes-ingress-nginx-cert-manager-external-dns/)
- [ExternalDNS integration with Azure DNS using workload identity](https://cloudchronicles.blog/blog/ExternalDNS-integration-with-Azure-DNS-using-workload-identity/)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gorilla/websocket]]></title>
            <link>https://github.com/gorilla/websocket</link>
            <guid>https://github.com/gorilla/websocket</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[Package gorilla/websocket is a fast, well-tested and widely used WebSocket implementation for Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gorilla/websocket">gorilla/websocket</a></h1>
            <p>Package gorilla/websocket is a fast, well-tested and widely used WebSocket implementation for Go.</p>
            <p>Language: Go</p>
            <p>Stars: 23,232</p>
            <p>Forks: 3,524</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># Gorilla WebSocket

[![GoDoc](https://godoc.org/github.com/gorilla/websocket?status.svg)](https://godoc.org/github.com/gorilla/websocket)
[![CircleCI](https://circleci.com/gh/gorilla/websocket.svg?style=svg)](https://circleci.com/gh/gorilla/websocket)

Gorilla WebSocket is a [Go](http://golang.org/) implementation of the
[WebSocket](http://www.rfc-editor.org/rfc/rfc6455.txt) protocol.


### Documentation

* [API Reference](https://pkg.go.dev/github.com/gorilla/websocket?tab=doc)
* [Chat example](https://github.com/gorilla/websocket/tree/main/examples/chat)
* [Command example](https://github.com/gorilla/websocket/tree/main/examples/command)
* [Client and server example](https://github.com/gorilla/websocket/tree/main/examples/echo)
* [File watch example](https://github.com/gorilla/websocket/tree/main/examples/filewatch)

### Status

The Gorilla WebSocket package provides a complete and tested implementation of
the [WebSocket](http://www.rfc-editor.org/rfc/rfc6455.txt) protocol. The
package API is stable.

### Installation

    go get github.com/gorilla/websocket

### Protocol Compliance

The Gorilla WebSocket package passes the server tests in the [Autobahn Test
Suite](https://github.com/crossbario/autobahn-testsuite) using the application in the [examples/autobahn
subdirectory](https://github.com/gorilla/websocket/tree/main/examples/autobahn).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[openai/openai-go]]></title>
            <link>https://github.com/openai/openai-go</link>
            <guid>https://github.com/openai/openai-go</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[The official Go library for the OpenAI API]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/openai-go">openai/openai-go</a></h1>
            <p>The official Go library for the OpenAI API</p>
            <p>Language: Go</p>
            <p>Stars: 1,384</p>
            <p>Forks: 95</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre># OpenAI Go API Library

&lt;a href=&quot;https://pkg.go.dev/github.com/openai/openai-go&quot;&gt;&lt;img src=&quot;https://pkg.go.dev/badge/github.com/openai/openai-go.svg&quot; alt=&quot;Go Reference&quot;&gt;&lt;/a&gt;

&gt; [!WARNING]
&gt; **This release is currently in beta**. Minor breaking changes may occur.

The OpenAI Go library provides convenient access to [the OpenAI REST
API](https://platform.openai.com/docs) from applications written in Go. The full API of this library can be found in [api.md](api.md).

## Installation

&lt;!-- x-release-please-start-version --&gt;

```go
import (
	&quot;github.com/openai/openai-go&quot; // imported as openai
)
```

&lt;!-- x-release-please-end --&gt;

Or to pin the version:

&lt;!-- x-release-please-start-version --&gt;

```sh
go get -u &#039;github.com/openai/openai-go@v0.1.0-alpha.65&#039;
```

&lt;!-- x-release-please-end --&gt;

## Requirements

This library requires Go 1.18+.

## Usage

The full API of this library can be found in [api.md](api.md).

See the [examples](./examples/) directory for complete and runnable examples.

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;

	&quot;github.com/openai/openai-go&quot;
	&quot;github.com/openai/openai-go/option&quot;
	&quot;github.com/openai/openai-go/shared&quot;
)

func main() {
	client := openai.NewClient(
		option.WithAPIKey(&quot;My API Key&quot;), // defaults to os.LookupEnv(&quot;OPENAI_API_KEY&quot;)
	)
	chatCompletion, err := client.Chat.Completions.New(context.TODO(), openai.ChatCompletionNewParams{
		Messages: openai.F([]openai.ChatCompletionMessageParamUnion{
			 openai.UserMessage(&quot;Say this is a test&quot;),
		}),
		Model: openai.F(openai.ChatModelGPT4o),
	})
	if err != nil {
		panic(err.Error())
	}
	println(chatCompletion.Choices[0].Message.Content)
}

```


&lt;details&gt;
&lt;summary&gt;Conversations&lt;/summary&gt;

```go
param := openai.ChatCompletionNewParams{
	Messages: openai.F([]openai.ChatCompletionMessageParamUnion{
		openai.UserMessage(&quot;What kind of houseplant is easy to take care of?&quot;),
  	}),
	Seed:     openai.Int(1),
	Model:    openai.F(openai.ChatModelGPT4o),
}

completion, err := client.Chat.Completions.New(ctx, param)

param.Messages.Value = append(param.Messages.Value, completion.Choices[0].Message)
param.Messages.Value = append(param.Messages.Value, openai.UserMessage(&quot;How big are those?&quot;))

// continue the conversation
completion, err = client.Chat.Completions.New(ctx, param)
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Streaming responses&lt;/summary&gt;

```go
question := &quot;Write an epic&quot;

stream := client.Chat.Completions.NewStreaming(ctx, openai.ChatCompletionNewParams{
	Messages: openai.F([]openai.ChatCompletionMessageParamUnion{
		openai.UserMessage(question),
	}),
	Seed:  openai.Int(0),
	Model: openai.F(openai.ChatModelGPT4o),
})

// optionally, an accumulator helper can be used
acc := openai.ChatCompletionAccumulator{}

for stream.Next() {
	chunk := stream.Current()
	acc.AddChunk(chunk)

	if content, ok := acc.JustFinishedContent(); ok {
		println(&quot;Content stream finished:&quot;, content)
	}

	// if using tool calls
	if tool, ok := acc.JustFinishedToolCall(); ok {
		println(&quot;Tool call stream finished:&quot;, tool.Index, tool.Name, tool.Arguments)
	}

	if refusal, ok := acc.JustFinishedRefusal(); ok {
		println(&quot;Refusal stream finished:&quot;, refusal)
	}

	// it&#039;s best to use chunks after handling JustFinished events
	if len(chunk.Choices) &gt; 0 {
		println(chunk.Choices[0].Delta.Content)
	}
}

if err := stream.Err(); err != nil {
	panic(err)
}

// After the stream is finished, acc can be used like a ChatCompletion
_ = acc.Choices[0].Message.Content
```

&gt; See the [full streaming and accumulation example](./examples/chat-completion-accumulating/main.go)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Tool calling&lt;/summary&gt;

```go
import (
	&quot;encoding/json&quot;
	// ...
)

// ...

question := &quot;What is the weather in New York City?&quot;

params := openai.ChatCompletionNewParams{
	Messages: openai.F([]openai.ChatCompletionMessageParamUnion{
		openai.UserMessage(question),
	}),
	Tools: openai.F([]openai.ChatCompletionToolParam{
		{
			Type: openai.F(openai.ChatCompletionToolTypeFunction),
			Function: openai.F(openai.FunctionDefinitionParam{
				Name:        openai.String(&quot;get_weather&quot;),
				Description: openai.String(&quot;Get weather at the given location&quot;),
				Parameters: openai.F(openai.FunctionParameters{
					&quot;type&quot;: &quot;object&quot;,
					&quot;properties&quot;: map[string]interface{}{
						&quot;location&quot;: map[string]string{
							&quot;type&quot;: &quot;string&quot;,
						},
					},
					&quot;required&quot;: []string{&quot;location&quot;},
				}),
			}),
		},
	}),
	Model: openai.F(openai.ChatModelGPT4o),
}

// chat completion request with tool calls
completion, _ := client.Chat.Completions.New(ctx, params)

for _, toolCall := range completion.Choices[0].Message.ToolCalls {
	if toolCall.Function.Name == &quot;get_weather&quot; {
		// extract the location from the function call arguments
		var args map[string]interface{}
		_ := json.Unmarshal([]byte(toolCall.Function.Arguments), &amp;args)

		// call a weather API with the arguments requested by the model
		weatherData := getWeather(args[&quot;location&quot;].(string))
		params.Messages.Value = append(params.Messages.Value, openai.ToolMessage(toolCall.ID, weatherData))
	}
}

// ... continue the conversation with the information provided by the tool
```

&gt; See the [full tool calling example](./examples/chat-completion-tool-calling/main.go)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Structured outputs&lt;/summary&gt;

```go
import (
	&quot;encoding/json&quot;
	&quot;github.com/invopop/jsonschema&quot;
	// ...
)

// A struct that will be converted to a Structured Outputs response schema
type HistoricalComputer struct {
	Origin       Origin   `json:&quot;origin&quot; jsonschema_description:&quot;The origin of the computer&quot;`
	Name         string   `json:&quot;full_name&quot; jsonschema_description:&quot;The name of the device model&quot;`
	NotableFacts []string `json:&quot;notable_facts&quot; jsonschema_description:&quot;A few key facts about the computer&quot;`
}

type Origin struct {
	YearBuilt    int64  `json:&quot;year_of_construction&quot; jsonschema_description:&quot;The year it was made&quot;`
	Organization string `json:&quot;organization&quot; jsonschema_description:&quot;The organization that was in charge of its development&quot;`
}

func GenerateSchema[T any]() interface{} {
	reflector := jsonschema.Reflector{
		AllowAdditionalProperties: false,
		DoNotReference:            true,
	}
	var v T
	schema := reflector.Reflect(v)
	return schema
}

// Generate the JSON schema at initialization time
var HistoricalComputerResponseSchema = GenerateSchema[HistoricalComputer]()

func main() {

	// ...

	question := &quot;What computer ran the first neural network?&quot;

	schemaParam := openai.ResponseFormatJSONSchemaJSONSchemaParam{
		Name:        openai.F(&quot;biography&quot;),
		Description: openai.F(&quot;Notable information about a person&quot;),
		Schema:      openai.F(HistoricalComputerResponseSchema),
		Strict:      openai.Bool(true),
	}

	chat, _ := client.Chat.Completions.New(ctx, openai.ChatCompletionNewParams{
		// ...
		ResponseFormat: openai.F[openai.ChatCompletionNewParamsResponseFormatUnion](
			openai.ResponseFormatJSONSchemaParam{
				Type:       openai.F(openai.ResponseFormatJSONSchemaTypeJSONSchema),
				JSONSchema: openai.F(schemaParam),
			},
		),
		// only certain models can perform structured outputs
		Model: openai.F(openai.ChatModelGPT4o2024_08_06),
	})

	// extract into a well-typed struct
	historicalComputer := HistoricalComputer{}
	_ = json.Unmarshal([]byte(chat.Choices[0].Message.Content), &amp;historicalComputer)

	historicalComputer.Name
	historicalComputer.Origin.YearBuilt
	historicalComputer.Origin.Organization
	for i, fact := range historicalComputer.NotableFacts {
		// ...
	}
}
```

&gt; See the [full structured outputs example](./examples/structured-outputs/main.go)

&lt;/details&gt;

### Request fields

All request parameters are wrapped in a generic `Field` type,
which we use to distinguish zero values from null or omitted fields.

This prevents accidentally sending a zero value if you forget a required parameter,
and enables explicitly sending `null`, `false`, `&#039;&#039;`, or `0` on optional parameters.
Any field not specified is not sent.

To construct fields with values, use the helpers `String()`, `Int()`, `Float()`, or most commonly, the generic `F[T]()`.
To send a null, use `Null[T]()`, and to send a nonconforming value, use `Raw[T](any)`. For example:

```go
params := FooParams{
	Name: openai.F(&quot;hello&quot;),

	// Explicitly send `&quot;description&quot;: null`
	Description: openai.Null[string](),

	Point: openai.F(openai.Point{
		X: openai.Int(0),
		Y: openai.Int(1),

		// In cases where the API specifies a given type,
		// but you want to send something else, use `Raw`:
		Z: openai.Raw[int64](0.01), // sends a float
	}),
}
```

### Response objects

All fields in response structs are value types (not pointers or wrappers).

If a given field is `null`, not present, or invalid, the corresponding field
will simply be its zero value.

All response structs also include a special `JSON` field, containing more detailed
information about each property, which you can use like so:

```go
if res.Name == &quot;&quot; {
	// true if `&quot;name&quot;` is either not present or explicitly null
	res.JSON.Name.IsNull()

	// true if the `&quot;name&quot;` key was not present in the response JSON at all
	res.JSON.Name.IsMissing()

	// When the API returns data that cannot be coerced to the expected type:
	if res.JSON.Name.IsInvalid() {
		raw := res.JSON.Name.Raw()

		legacyName := struct{
			First string `json:&quot;first&quot;`
			Last  string `json:&quot;last&quot;`
		}{}
		json.Unmarshal([]byte(raw), &amp;legacyName)
		name = legacyName.First + &quot; &quot; + legacyName.Last
	}
}
```

These `.JSON` structs also include an `Extras` map containing
any properties in the json response that were not specified
in the struct. This can be useful for API features not yet
present in the SDK.

```go
body := res.JSON.ExtraFields[&quot;my_unexpected_field&quot;].Raw()
```

### RequestOptions

This library uses the functional options pattern. Functions defined in the
`option` package return a `RequestOption`, which is a closure that mutates a
`RequestConfig`. These options can be supplied to the client or at individual
requests. For example:

```go
client := openai.NewClient(
	// Adds a header to every request made by the client
	option.WithHeader(&quot;X-Some-Header&quot;, &quot;custom_header_info&quot;),
)

client.Chat.Completions.New(context.TODO(), ...,
	// Override the header
	option.WithHeader(&quot;X-Some-Header&quot;, &quot;some_other_custom_header_info&quot;),
	// Add an undocumented field to the request body, using sjson syntax
	option.WithJSONSet(&quot;some.json.path&quot;, map[string]string{&quot;my&quot;: &quot;object&quot;}),
)
```

See the [full list of request options](https://pkg.go.dev/github.com/openai/openai-go/option).

### Pagination

This library provides some conveniences for working with paginated list endpoints.

You can use `.ListAutoPaging()` methods to iterate through items across all pages:

```go
iter := client.FineTuning.Jobs.ListAutoPaging(context.TODO(), openai.FineTuningJobListParams{
	Limit: openai.F(int64(20)),
})
// Automatically fetches more pages as needed.
for iter.Next() {
	fineTuningJob := iter.Current()
	fmt.Printf(&quot;%+v\n&quot;, fineTuningJob)
}
if err := iter.Err(); err != nil {
	panic(err.Error())
}
```

Or you can use simple `.List()` methods to fetch a single page and receive a standard response object
with additional helper methods like `.GetNextPage()`, e.g.:

```go
page, err := client.FineTuning.Jobs.List(context.TODO(), openai.FineTuningJobListParams{
	Limit: openai.F(int64(20)),
})
for page != nil {
	for _, job := range page.Data {
		fmt.Printf(&quot;%+v\n&quot;, job)
	}
	page, err = page.GetNextPage()
}
if err != nil {
	panic(err.Error())
}
```

### Errors

When the API returns a non-success status code, we return an error with type
`*openai.Error`. This contains the `StatusCode`, `*http.Request`, and
`*http.Response` values of the request, as well as the JSON of the error body
(much like other response objects in the SDK).

To handle errors, we recommend that you use the `errors.As` pattern:

```go
_, err := client.FineTuning.Jobs.New(context.TODO(), openai.FineTuningJobNewParams{
	Model:        openai.F(openai.FineTuningJobNewParamsModelBabbage002),
	TrainingFile: openai.F(&quot;file-abc123&quot;),
})
if err != nil {
	var apierr *openai.Error
	if errors.As(err, &amp;apierr) {
		println(string(apierr.DumpRequest(true)))  // Prints the serialized HTTP request
		println(string(apierr.DumpResponse(true))) // Prints the serialized HTTP response
	}
	panic(err.Error()) // GET &quot;/fine_tuning/jobs&quot;: 400 Bad Request { ... }
}
```

When other errors occur, they are returned unwrapped; for example,
if HTTP transport fails, you might receive `*url.Error` wrapping `*net.OpError`.

### Timeouts

Requests do not time out by default; use context to configure a timeout for a request lifecycle.

Note that if a request is [retried](#retries), the context timeout does not start over.
To set a per-retry timeout, use `option.WithRequestTimeout()`.

```go
// This sets the timeout for the request, including all the retries.
ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
defer cancel()
client.Chat.Completions.New(
	ctx,
	openai.ChatCompletionNewParams{
		Messages: openai.F([]openai.ChatCompletionMessageParamUnion{
			 openai.UserMessage(&quot;Say this is a test&quot;),
		}),
		Model: openai.F(openai.ChatModelGPT4o),
	},
	// This sets the per-retry timeout
	option.WithRequestTimeout(20*time.Second),
)
```

### File uploads

Request parameters that correspond to file uploads in multipart requests are typed as
`param.Field[io.Reader]`. The contents of the `io.Reader` will by default be sent as a multipart form
part with the file name of &quot;anonymous_file&quot; and content-type of &quot;application/octet-stream&quot;.

The file name and content-type can be customized by implementing `Name() string` or `ContentType()
string` on the run-time type of `io.Reader`. Note that `os.File` implements `Name() string`, so a
file returned by `os.Open` will be sent with the file name on disk.

We also provide a helper `openai.FileParam(reader io.Reader, filename string, contentType string)`
which can be used to wrap any `io.Reader` with the appropriate file name and content type.

```go
// A file from the file system
file, err := os.Open(&quot;input.jsonl&quot;)
openai.FileNewParams{
	File:    openai.F[io.Reader](file),
	Purpose: openai.F(openai.FilePurposeFineTune),
}

// A file from a string
openai.FileNewParams{
	File:    openai.F[io.Reader](strings.NewReader(&quot;my file contents&quot;)),
	Purpose: openai.F(openai.FilePurposeFineTune),
}

// With a custom filename and contentType
openai.FileNewParams{
	File:    openai.FileParam(strings.NewReader(`{&quot;hello&quot;: &quot;foo&quot;}`), &quot;file.go&quot;, &quot;application/json&quot;),
	Purpose: openai.F(openai.FilePurposeFineTune),
}
```

### Retries

Certain errors will be automatically retried 2 times by default, with a short exponential backoff.
We retry by default all connection errors, 408 Request Timeout, 409 Conflict, 429 Rate Limit,
and &gt;=500 Internal errors.

You can use the `WithMaxRetries` option to configure or disable this:

```go
// Configure the default for all requests:
client := openai.NewClient(
	option.WithMaxRetries(0), // default is 2
)

// Override per-request:
client.Chat.Completions.New(
	context.TODO(),
	openai.ChatCompletionNewParams{
		Messages: openai.F([]openai.ChatCompletionMessageParamUnion{
			 openai.UserMessage(&quot;Say this is a test&quot;),
		}),
		Model: openai.F(openai.ChatModelGPT4o),
	},
	option.WithMaxRetries(5),
)
```

### Accessing raw response data (e.g. response headers)

You can access the raw HTTP response data by using the `option.WithResponseInto()` request option. This is useful when
you need to examine response headers, status codes, or other details.

```go
// Create a variable to store the HTTP response
var response *http.Response
chatCompletion, err := client.Chat.Completions.New(
	context.TODO(),
	openai.ChatCompletionNewParams{
		Messages: openai.F([]openai.ChatCompletionMessageParamUnion{openai.ChatCompletionUserMessageParam{
			Role:    openai.F(openai.ChatCompletionUserMessageParamRoleUser),
			Content: openai.F([]openai.ChatCompletionContentPartUnionParam{openai.ChatCompletionContentPartTextParam{Text: openai.F(&quot;text&quot;), Type: openai.F(openai.ChatCompletionContentPartTextTypeText)}}),
		}}),
		Model: openai.F(shared.ChatModelO3Mini),
	},
	option.WithResponseInto(&amp;response),
)
if err != nil {
	// handle error
}
fmt.Printf(&quot;%+v\n&quot;, chatCompletion)

fmt.Printf(&quot;Status Code: %d\n&quot;, response.StatusCode)
fmt.Printf(&quot;Headers: %+#v\n&quot;, response.Header)
```

### Making custom/undocumented requests

This library is typed for convenient access to the documented API. If you need to access undocumented
endpoints, params, or response properties, the library can still be used.

#### Undocumented endpoints

To make requests to undocumented endpoints, you can use `client.Get`, `client.Post`, and other HTTP verbs.
`RequestOptions` on the client, such as retries, will be respected when making these requests.

```go
var (
    // params can be an io.Reader, a []byte, an encoding/json serializable object,
    // or a &quot;…Params&quot; struct defined in this library.
    params map[string]interface{}

    // result can be an []byte, *http.Response, a encoding/json deserializable object,
    // or a model defined in this library.
    result *http.Response
)
err := client.Post(context.Background(), &quot;/unspecified&quot;, params, &amp;result)
if err != nil {
    …
}
```

#### Undocumented request params

To make requests using undocumented parameters, you may use either the `option.WithQuerySet()`
or the `option.WithJSONSet()` methods.

```go
params := FooNewParams{
    ID:   openai.F(&quot;id_xxxx&quot;),
    Data: openai.F(FooNewParamsData{
        FirstName: openai.F(&quot;John&quot;),
    }),
}
client.Foo.New(context.Background(), params, option.WithJSONSet(&quot;data.last_name&quot;, &quot;Doe&quot;))
```

#### Undocumented response properties

To access undocumented response properties, you may either access the raw JSON of the response as a string
with `result.JSON.RawJSON()`, or get the raw JSON of a particular field on the result with
`result.JSON.Foo.Raw()`.

Any fields that are not present on the response struct will be saved and can be accessed by `result.JSON.ExtraFields()` which returns the extra fields as a `map[string]Field`.

### Middleware

We provide `option.WithMiddleware` which applies the given
middleware to requests.

```go
func Logger(req *http.Request, next option.MiddlewareNext) (res *http.Response, err error) {
	// Before the request
	start := time.Now()
	LogReq(req)

	// Forward the request to the next handler
	res, err = next(req)

	// Handle stuff after the request
	end := time.Now()
	LogRes(res, err, start - end)

    return res, err
}

client := openai.NewClient(
	option.WithMiddleware(Logger),
)
```

When multiple middlewares are provided as variadic arguments, the middlewares
are applied left to right. If `option.WithMiddleware` is given
multiple times, for example first in the client then the method, the
middleware in the client will run first and the middleware given in the method
will run next.

You may also replace the default `http.Client` with
`option.WithHTTPClient(client)`. Only one http client is
accepted (this overwrites any previous client) and receives requests after any
middleware has been applied.

## Microsoft Azure OpenAI

To use this library with [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/overview), use the option.RequestOption functions in the `azure` package.

```go
package main

import (
	&quot;github.com/Azure/azure-sdk-for-go/sdk/azidentity&quot;
	&quot;github.com/openai/openai-go&quot;
	&quot;github.com/openai/openai-go/azure&quot;
)

func main() {
	const azureOpenAIEndpoint = &quot;https://&lt;azure-openai-resource&gt;.openai.azure.com&quot;

	// The latest API versions, including previews, can be found here:
	// https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning
	const azureOpenAIAPIVersion = &quot;2024-06-01&quot;

	tokenCredential, err := azidentity.NewDefaultAzureCredential(nil)

	if err != nil {
		fmt.Printf(&quot;Failed to create the DefaultAzureCredential: %s&quot;, err)
		os.Exit(1)
	}

	client := openai.NewClient(
		azure.WithEndpoint(azureOpenAIEn

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gin-gonic/gin]]></title>
            <link>https://github.com/gin-gonic/gin</link>
            <guid>https://github.com/gin-gonic/gin</guid>
            <pubDate>Wed, 19 Mar 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[Gin is a HTTP web framework written in Go (Golang). It features a Martini-like API with much better performance -- up to 40 times faster. If you need smashing performance, get yourself some Gin.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gin-gonic/gin">gin-gonic/gin</a></h1>
            <p>Gin is a HTTP web framework written in Go (Golang). It features a Martini-like API with much better performance -- up to 40 times faster. If you need smashing performance, get yourself some Gin.</p>
            <p>Language: Go</p>
            <p>Stars: 80,869</p>
            <p>Forks: 8,135</p>
            <p>Stars today: 36 stars today</p>
            <h2>README</h2><pre># Gin Web Framework

&lt;img align=&quot;right&quot; width=&quot;159px&quot; src=&quot;https://raw.githubusercontent.com/gin-gonic/logo/master/color.png&quot;&gt;

[![Build Status](https://github.com/gin-gonic/gin/workflows/Run%20Tests/badge.svg?branch=master)](https://github.com/gin-gonic/gin/actions?query=branch%3Amaster)
[![codecov](https://codecov.io/gh/gin-gonic/gin/branch/master/graph/badge.svg)](https://codecov.io/gh/gin-gonic/gin)
[![Go Report Card](https://goreportcard.com/badge/github.com/gin-gonic/gin)](https://goreportcard.com/report/github.com/gin-gonic/gin)
[![Go Reference](https://pkg.go.dev/badge/github.com/gin-gonic/gin?status.svg)](https://pkg.go.dev/github.com/gin-gonic/gin?tab=doc)
[![Sourcegraph](https://sourcegraph.com/github.com/gin-gonic/gin/-/badge.svg)](https://sourcegraph.com/github.com/gin-gonic/gin?badge)
[![Open Source Helpers](https://www.codetriage.com/gin-gonic/gin/badges/users.svg)](https://www.codetriage.com/gin-gonic/gin)
[![Release](https://img.shields.io/github/release/gin-gonic/gin.svg?style=flat-square)](https://github.com/gin-gonic/gin/releases)
[![TODOs](https://badgen.net/https/api.tickgit.com/badgen/github.com/gin-gonic/gin)](https://www.tickgit.com/browse?repo=github.com/gin-gonic/gin)

Gin is a web framework written in [Go](https://go.dev/). It features a martini-like API with performance that is up to 40 times faster thanks to [httprouter](https://github.com/julienschmidt/httprouter).
If you need performance and good productivity, you will love Gin.

**Gin&#039;s key features are:**

- Zero allocation router
- Speed
- Middleware support
- Crash-free
- JSON validation
- Route grouping
- Error management
- Built-in rendering
- Extensible

## Getting started

### Prerequisites

Gin requires [Go](https://go.dev/) version [1.22](https://go.dev/doc/devel/release#go1.22.0) or above.

### Getting Gin

With [Go&#039;s module support](https://go.dev/wiki/Modules#how-to-use-modules), `go [build|run|test]` automatically fetches the necessary dependencies when you add the import in your code:

```sh
import &quot;github.com/gin-gonic/gin&quot;
```

Alternatively, use `go get`:

```sh
go get -u github.com/gin-gonic/gin
```

### Running Gin

A basic example:

```go
package main

import (
  &quot;net/http&quot;

  &quot;github.com/gin-gonic/gin&quot;
)

func main() {
  r := gin.Default()
  r.GET(&quot;/ping&quot;, func(c *gin.Context) {
    c.JSON(http.StatusOK, gin.H{
      &quot;message&quot;: &quot;pong&quot;,
    })
  })
  r.Run() // listen and serve on 0.0.0.0:8080 (for windows &quot;localhost:8080&quot;)
}
```

To run the code, use the `go run` command, like:

```sh
$ go run example.go
```

Then visit [`0.0.0.0:8080/ping`](http://0.0.0.0:8080/ping) in your browser to see the response!

### See more examples

#### Quick Start

Learn and practice with the [Gin Quick Start](docs/doc.md), which includes API examples and builds tag.

#### Examples

A number of ready-to-run examples demonstrating various use cases of Gin are available in the [Gin examples](https://github.com/gin-gonic/examples) repository.

## Documentation

See the [API documentation on go.dev](https://pkg.go.dev/github.com/gin-gonic/gin).

The documentation is also available on [gin-gonic.com](https://gin-gonic.com) in several languages:

- [English](https://gin-gonic.com/docs/)
- [简体中文](https://gin-gonic.com/zh-cn/docs/)
- [繁體中文](https://gin-gonic.com/zh-tw/docs/)
- [日本語](https://gin-gonic.com/ja/docs/)
- [Español](https://gin-gonic.com/es/docs/)
- [한국어](https://gin-gonic.com/ko-kr/docs/)
- [Turkish](https://gin-gonic.com/tr/docs/)
- [Persian](https://gin-gonic.com/fa/docs/)
- [Português](https://gin-gonic.com/pt/docs/)

### Articles

- [Tutorial: Developing a RESTful API with Go and Gin](https://go.dev/doc/tutorial/web-service-gin)

## Benchmarks

Gin uses a custom version of [HttpRouter](https://github.com/julienschmidt/httprouter), [see all benchmarks](/BENCHMARKS.md).

| Benchmark name                 |       (1) |             (2) |          (3) |             (4) |
| ------------------------------ | --------: | --------------: | -----------: | --------------: |
| BenchmarkGin_GithubAll         | **43550** | **27364 ns/op** |   **0 B/op** | **0 allocs/op** |
| BenchmarkAce_GithubAll         |     40543 |     29670 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkAero_GithubAll        |     57632 |     20648 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkBear_GithubAll        |      9234 |    216179 ns/op |   86448 B/op |   943 allocs/op |
| BenchmarkBeego_GithubAll       |      7407 |    243496 ns/op |   71456 B/op |   609 allocs/op |
| BenchmarkBone_GithubAll        |       420 |   2922835 ns/op |  720160 B/op |  8620 allocs/op |
| BenchmarkChi_GithubAll         |      7620 |    238331 ns/op |   87696 B/op |   609 allocs/op |
| BenchmarkDenco_GithubAll       |     18355 |     64494 ns/op |   20224 B/op |   167 allocs/op |
| BenchmarkEcho_GithubAll        |     31251 |     38479 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkGocraftWeb_GithubAll  |      4117 |    300062 ns/op |  131656 B/op |  1686 allocs/op |
| BenchmarkGoji_GithubAll        |      3274 |    416158 ns/op |   56112 B/op |   334 allocs/op |
| BenchmarkGojiv2_GithubAll      |      1402 |    870518 ns/op |  352720 B/op |  4321 allocs/op |
| BenchmarkGoJsonRest_GithubAll  |      2976 |    401507 ns/op |  134371 B/op |  2737 allocs/op |
| BenchmarkGoRestful_GithubAll   |       410 |   2913158 ns/op |  910144 B/op |  2938 allocs/op |
| BenchmarkGorillaMux_GithubAll  |       346 |   3384987 ns/op |  251650 B/op |  1994 allocs/op |
| BenchmarkGowwwRouter_GithubAll |     10000 |    143025 ns/op |   72144 B/op |   501 allocs/op |
| BenchmarkHttpRouter_GithubAll  |     55938 |     21360 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkHttpTreeMux_GithubAll |     10000 |    153944 ns/op |   65856 B/op |   671 allocs/op |
| BenchmarkKocha_GithubAll       |     10000 |    106315 ns/op |   23304 B/op |   843 allocs/op |
| BenchmarkLARS_GithubAll        |     47779 |     25084 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkMacaron_GithubAll     |      3266 |    371907 ns/op |  149409 B/op |  1624 allocs/op |
| BenchmarkMartini_GithubAll     |       331 |   3444706 ns/op |  226551 B/op |  2325 allocs/op |
| BenchmarkPat_GithubAll         |       273 |   4381818 ns/op | 1483152 B/op | 26963 allocs/op |
| BenchmarkPossum_GithubAll      |     10000 |    164367 ns/op |   84448 B/op |   609 allocs/op |
| BenchmarkR2router_GithubAll    |     10000 |    160220 ns/op |   77328 B/op |   979 allocs/op |
| BenchmarkRivet_GithubAll       |     14625 |     82453 ns/op |   16272 B/op |   167 allocs/op |
| BenchmarkTango_GithubAll       |      6255 |    279611 ns/op |   63826 B/op |  1618 allocs/op |
| BenchmarkTigerTonic_GithubAll  |      2008 |    687874 ns/op |  193856 B/op |  4474 allocs/op |
| BenchmarkTraffic_GithubAll     |       355 |   3478508 ns/op |  820744 B/op | 14114 allocs/op |
| BenchmarkVulcan_GithubAll      |      6885 |    193333 ns/op |   19894 B/op |   609 allocs/op |

- (1): Total Repetitions achieved in constant time, higher means more confident result
- (2): Single Repetition Duration (ns/op), lower is better
- (3): Heap Memory (B/op), lower is better
- (4): Average Allocations per Repetition (allocs/op), lower is better

## Middleware

You can find many useful Gin middlewares at [gin-contrib](https://github.com/gin-contrib).

## Uses

Here are some awesome projects that are using the [Gin](https://github.com/gin-gonic/gin) web framework.

- [gorush](https://github.com/appleboy/gorush): A push notification server.
- [fnproject](https://github.com/fnproject/fn): A container native, cloud agnostic serverless platform.
- [photoprism](https://github.com/photoprism/photoprism): Personal photo management powered by Google TensorFlow.
- [lura](https://github.com/luraproject/lura): Ultra performant API Gateway with middleware.
- [picfit](https://github.com/thoas/picfit): An image resizing server.
- [dkron](https://github.com/distribworks/dkron): Distributed, fault tolerant job scheduling system.

## Contributing

Gin is the work of hundreds of contributors. We appreciate your help!

Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details on submitting patches and the contribution workflow.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>