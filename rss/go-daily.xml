<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Sun, 05 Oct 2025 00:05:34 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[netbirdio/netbird]]></title>
            <link>https://github.com/netbirdio/netbird</link>
            <guid>https://github.com/netbirdio/netbird</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[Connect your devices into a secure WireGuard®-based overlay network with SSO, MFA and granular access controls.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/netbirdio/netbird">netbirdio/netbird</a></h1>
            <p>Connect your devices into a secure WireGuard®-based overlay network with SSO, MFA and granular access controls.</p>
            <p>Language: Go</p>
            <p>Stars: 18,741</p>
            <p>Forks: 892</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>
&lt;div align=&quot;center&quot;&gt;
&lt;br/&gt;
  &lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;234&quot; src=&quot;docs/media/logo-full.png&quot;/&gt;
&lt;/p&gt;
  &lt;p&gt;
   &lt;a href=&quot;https://img.shields.io/badge/license-BSD--3-blue)&quot;&gt;
       &lt;img src=&quot;https://sonarcloud.io/api/project_badges/measure?project=netbirdio_netbird&amp;metric=alert_status&quot; /&gt;
     &lt;/a&gt; 
     &lt;a href=&quot;https://github.com/netbirdio/netbird/blob/main/LICENSE&quot;&gt;
       &lt;img src=&quot;https://img.shields.io/badge/license-BSD--3-blue&quot; /&gt;
     &lt;/a&gt; 
    &lt;br&gt;
    &lt;a href=&quot;https://docs.netbird.io/slack-url&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/slack-@netbird-red.svg?logo=slack&quot;/&gt;
     &lt;/a&gt;
    &lt;a href=&quot;https://forum.netbird.io&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/community forum-@netbird-red.svg?logo=discourse&quot;/&gt;
     &lt;/a&gt;  
     &lt;br&gt;
    &lt;a href=&quot;https://gurubase.io/g/netbird&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/Gurubase-Ask%20NetBird%20Guru-006BFF&quot;/&gt;
     &lt;/a&gt;    
  &lt;/p&gt;
&lt;/div&gt;


&lt;p align=&quot;center&quot;&gt;
&lt;strong&gt;
  Start using NetBird at &lt;a href=&quot;https://netbird.io/pricing&quot;&gt;netbird.io&lt;/a&gt;
  &lt;br/&gt;
  See &lt;a href=&quot;https://netbird.io/docs/&quot;&gt;Documentation&lt;/a&gt;
  &lt;br/&gt;
   Join our &lt;a href=&quot;https://docs.netbird.io/slack-url&quot;&gt;Slack channel&lt;/a&gt; or our &lt;a href=&quot;https://forum.netbird.io&quot;&gt;Community forum&lt;/a&gt;
  &lt;br/&gt;
 
&lt;/strong&gt;
&lt;br&gt;
&lt;a href=&quot;https://registry.terraform.io/providers/netbirdio/netbird/latest&quot;&gt;
    New: NetBird terraform provider
  &lt;/a&gt; 
&lt;/p&gt;

&lt;br&gt;

**NetBird combines a configuration-free peer-to-peer private network and a centralized access control system in a single platform, making it easy to create secure private networks for your organization or home.**

**Connect.** NetBird creates a WireGuard-based overlay network that automatically connects your machines over an encrypted tunnel, leaving behind the hassle of opening ports, complex firewall rules, VPN gateways, and so forth.

**Secure.** NetBird enables secure remote access by applying granular access policies while allowing you to manage them intuitively from a single place. Works universally on any infrastructure.

### Open Source Network Security in a Single Platform

https://github.com/user-attachments/assets/10cec749-bb56-4ab3-97af-4e38850108d2

### NetBird on Lawrence Systems (Video)
[![Watch the video](https://img.youtube.com/vi/Kwrff6h0rEw/0.jpg)](https://www.youtube.com/watch?v=Kwrff6h0rEw)

### Key features

| Connectivity | Management | Security | Automation| Platforms |
|----|----|----|----|----|
| &lt;ul&gt;&lt;li&gt;- \[x] Kernel WireGuard&lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Admin Web UI](https://github.com/netbirdio/dashboard)&lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [SSO &amp; MFA support](https://docs.netbird.io/how-to/installation#running-net-bird-with-sso-login)&lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Public API](https://docs.netbird.io/api)&lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] Linux&lt;/ul&gt;&lt;/li&gt; |
| &lt;ul&gt;&lt;li&gt;- \[x] Peer-to-peer connections&lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] Auto peer discovery and configuration&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Access control - groups &amp; rules](https://docs.netbird.io/how-to/manage-network-access)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Setup keys for bulk network provisioning](https://docs.netbird.io/how-to/register-machines-using-setup-keys)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] Mac&lt;/ui&gt;&lt;/li&gt; |
| &lt;ul&gt;&lt;li&gt;- \[x] Connection relay fallback&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [IdP integrations](https://docs.netbird.io/selfhosted/identity-providers)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Activity logging](https://docs.netbird.io/how-to/audit-events-logging)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Self-hosting quickstart script](https://docs.netbird.io/selfhosted/selfhosted-quickstart)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] Windows&lt;/ui&gt;&lt;/li&gt; |
| &lt;ul&gt;&lt;li&gt;- \[x] [Routes to external networks](https://docs.netbird.io/how-to/routing-traffic-to-private-networks)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Private DNS](https://docs.netbird.io/how-to/manage-dns-in-your-network)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Device posture checks](https://docs.netbird.io/how-to/manage-posture-checks)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] IdP groups sync with JWT&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] Android&lt;/ui&gt;&lt;/li&gt; |
| &lt;ul&gt;&lt;li&gt;- \[x] NAT traversal with BPF&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Multiuser support](https://docs.netbird.io/how-to/add-users-to-your-network)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] Peer-to-peer encryption&lt;/ui&gt;&lt;/li&gt; || &lt;ul&gt;&lt;li&gt;- \[x] iOS&lt;/ui&gt;&lt;/li&gt; |
||| &lt;ul&gt;&lt;li&gt;- \[x] [Quantum-resistance with Rosenpass](https://netbird.io/knowledge-hub/the-first-quantum-resistant-mesh-vpn)&lt;/ui&gt;&lt;/li&gt; || &lt;ul&gt;&lt;li&gt;- \[x] OpenWRT&lt;/ui&gt;&lt;/li&gt; |
||| &lt;ul&gt;&lt;li&gt;- \[x] [Periodic re-authentication](https://docs.netbird.io/how-to/enforce-periodic-user-authentication)&lt;/ui&gt;&lt;/li&gt; || &lt;ul&gt;&lt;li&gt;- \[x] [Serverless](https://docs.netbird.io/how-to/netbird-on-faas)&lt;/ui&gt;&lt;/li&gt; |
||||| &lt;ul&gt;&lt;li&gt;- \[x] Docker&lt;/ui&gt;&lt;/li&gt; |

### Quickstart with NetBird Cloud

- Download and install NetBird at [https://app.netbird.io/install](https://app.netbird.io/install)
- Follow the steps to sign-up with Google, Microsoft, GitHub or your email address.
- Check NetBird [admin UI](https://app.netbird.io/).
- Add more machines.

### Quickstart with self-hosted NetBird

&gt; This is the quickest way to try self-hosted NetBird. It should take around 5 minutes to get started if you already have a public domain and a VM.
Follow the [Advanced guide with a custom identity provider](https://docs.netbird.io/selfhosted/selfhosted-guide#advanced-guide-with-a-custom-identity-provider) for installations with different IDPs.

**Infrastructure requirements:**
- A Linux VM with at least **1CPU** and **2GB** of memory.
- The VM should be publicly accessible on TCP ports **80** and **443** and UDP ports: **3478**, **49152-65535**.
- **Public domain** name pointing to the VM.

**Software requirements:**
- Docker installed on the VM with the docker-compose plugin ([Docker installation guide](https://docs.docker.com/engine/install/)) or docker with docker-compose in version 2 or higher.
- [jq](https://jqlang.github.io/jq/) installed. In most distributions
  Usually available in the official repositories and can be installed with `sudo apt install jq` or `sudo yum install jq`
- [curl](https://curl.se/) installed.
  Usually available in the official repositories and can be installed with `sudo apt install curl` or `sudo yum install curl`

**Steps**
- Download and run the installation script:
```bash
export NETBIRD_DOMAIN=netbird.example.com; curl -fsSL https://github.com/netbirdio/netbird/releases/latest/download/getting-started-with-zitadel.sh | bash
```
- Once finished, you can manage the resources via `docker-compose`

### A bit on NetBird internals
-  Every machine in the network runs [NetBird Agent (or Client)](client/) that manages WireGuard.
-  Every agent connects to [Management Service](management/) that holds network state, manages peer IPs, and distributes network updates to agents (peers).
-  NetBird agent uses WebRTC ICE implemented in [pion/ice library](https://github.com/pion/ice) to discover connection candidates when establishing a peer-to-peer connection between machines.
-  Connection candidates are discovered with the help of [STUN](https://en.wikipedia.org/wiki/STUN) servers.
-  Agents negotiate a connection through [Signal Service](signal/) passing p2p encrypted messages with candidates.
-  Sometimes the NAT traversal is unsuccessful due to strict NATs (e.g. mobile carrier-grade NAT) and a p2p connection isn&#039;t possible. When this occurs the system falls back to a relay server called [TURN](https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT), and a secure WireGuard tunnel is established via the TURN server. 
 
[Coturn](https://github.com/coturn/coturn) is the one that has been successfully used for STUN and TURN in NetBird setups.

&lt;p float=&quot;left&quot; align=&quot;middle&quot;&gt;
  &lt;img src=&quot;https://docs.netbird.io/docs-static/img/architecture/high-level-dia.png&quot; width=&quot;700&quot;/&gt;
&lt;/p&gt;

See a complete [architecture overview](https://docs.netbird.io/about-netbird/how-netbird-works#architecture) for details.

### Community projects
-  [NetBird installer script](https://github.com/physk/netbird-installer)
-  [NetBird ansible collection by Dominion Solutions](https://galaxy.ansible.com/ui/repo/published/dominion_solutions/netbird/)

**Note**: The `main` branch may be in an *unstable or even broken state* during development.
For stable versions, see [releases](https://github.com/netbirdio/netbird/releases).

### Support acknowledgement

In November 2022, NetBird joined the [StartUpSecure program](https://www.forschung-it-sicherheit-kommunikationssysteme.de/foerderung/bekanntmachungen/startup-secure) sponsored by The Federal Ministry of Education and Research of The Federal Republic of Germany. Together with [CISPA Helmholtz Center for Information Security](https://cispa.de/en) NetBird brings the security best practices and simplicity to private networking.

![CISPA_Logo_BLACK_EN_RZ_RGB (1)](https://user-images.githubusercontent.com/700848/203091324-c6d311a0-22b5-4b05-a288-91cbc6cdcc46.png)

### Testimonials
We use open-source technologies like [WireGuard®](https://www.wireguard.com/), [Pion ICE (WebRTC)](https://github.com/pion/ice), [Coturn](https://github.com/coturn/coturn), and [Rosenpass](https://rosenpass.eu). We very much appreciate the work these guys are doing and we&#039;d greatly appreciate if you could support them in any way (e.g., by giving a star or a contribution).

### Legal
This repository is licensed under BSD-3-Clause license that applies to all parts of the repository except for the directories management/, signal/ and relay/.
Those directories are licensed under the GNU Affero General Public License version 3.0 (AGPLv3). See the respective LICENSE files inside each directory.

_WireGuard_ and the _WireGuard_ logo are [registered trademarks](https://www.wireguard.com/trademark-policy/) of Jason A. Donenfeld.
 

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[istio/istio]]></title>
            <link>https://github.com/istio/istio</link>
            <guid>https://github.com/istio/istio</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[Connect, secure, control, and observe services.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/istio/istio">istio/istio</a></h1>
            <p>Connect, secure, control, and observe services.</p>
            <p>Language: Go</p>
            <p>Stars: 37,477</p>
            <p>Forks: 8,084</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># Istio

[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1395/badge)](https://bestpractices.coreinfrastructure.org/projects/1395)
[![Go Report Card](https://goreportcard.com/badge/github.com/istio/istio)](https://goreportcard.com/report/github.com/istio/istio)
[![GoDoc](https://godoc.org/istio.io/istio?status.svg)](https://godoc.org/istio.io/istio)

&lt;a href=&quot;https://istio.io/&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/projects/istio/icon/color/istio-icon-color.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/istio/istio/raw/master/logo/istio-bluelogo-whitebackground-unframed.svg&quot;&gt;
      &lt;img title=&quot;Istio&quot; height=&quot;100&quot; width=&quot;100&quot; alt=&quot;Istio logo&quot; src=&quot;https://github.com/istio/istio/raw/master/logo/istio-bluelogo-whitebackground-unframed.svg&quot;&gt;
    &lt;/picture&gt;
&lt;/a&gt;

---

Istio is an open source service mesh that layers transparently onto existing distributed applications. Istio’s powerful features provide a uniform and more efficient way to secure, connect, and monitor services. Istio is the path to load balancing, service-to-service authentication, and monitoring – with few or no service code changes.

- For in-depth information about how to use Istio, visit [istio.io](https://istio.io)
- To ask questions and get assistance from our community, visit [Github Discussions](https://github.com/istio/istio/discussions)
- To learn how to participate in our overall community, visit [our community page](https://istio.io/about/community)

In this README:

- [Introduction](#introduction)
- [Repositories](#repositories)
- [Issue management](#issue-management)

In addition, here are some other documents you may wish to read:

- [Istio Community](https://github.com/istio/community#istio-community) - describes how to get involved and contribute to the Istio project
- [Istio Developer&#039;s Guide](https://github.com/istio/istio/wiki/Preparing-for-Development) - explains how to set up and use an Istio development environment
- [Project Conventions](https://github.com/istio/istio/wiki/Development-Conventions) - describes the conventions we use within the code base
- [Creating Fast and Lean Code](https://github.com/istio/istio/wiki/Writing-Fast-and-Lean-Code) - performance-oriented advice and guidelines for the code base

You&#039;ll find many other useful documents on our [Wiki](https://github.com/istio/istio/wiki).

## Introduction

[Istio](https://istio.io/latest/docs/concepts/what-is-istio/) is an open platform for providing a uniform way to [integrate
microservices](https://istio.io/latest/docs/examples/microservices-istio/), manage [traffic flow](https://istio.io/latest/docs/concepts/traffic-management/) across microservices, enforce policies
and aggregate telemetry data. Istio&#039;s control plane provides an abstraction
layer over the underlying cluster management platform, such as Kubernetes.

Istio is composed of these components:

- **Envoy** - Sidecar proxies per microservice to handle ingress/egress traffic
   between services in the cluster and from a service to external
   services. The proxies form a _secure microservice mesh_ providing a rich
   set of functions like discovery, rich layer-7 routing, circuit breakers,
   policy enforcement and telemetry recording/reporting
   functions.

  &gt; Note: The service mesh is not an overlay network. It
  &gt; simplifies and enhances how microservices in an application talk to each
  &gt; other over the network provided by the underlying platform.

- **Istiod** - The Istio control plane. It provides service discovery, configuration and certificate management. It consists of the following sub-components:

    - **Pilot** - Responsible for configuring the proxies at runtime.

    - **Citadel** - Responsible for certificate issuance and rotation.

    - **Galley** - Responsible for validating, ingesting, aggregating, transforming and distributing config within Istio.

- **Operator** - The component provides user friendly options to operate the Istio service mesh.

## Repositories

The Istio project is divided across a few GitHub repositories:

- [istio/api](https://github.com/istio/api). This repository defines
component-level APIs and common configuration formats for the Istio platform.

- [istio/community](https://github.com/istio/community). This repository contains
information on the Istio community, including the various documents that govern
the Istio open source project.

- [istio/istio](README.md). This is the main code repository. It hosts Istio&#039;s
core components, install artifacts, and sample programs. It includes:

    - [istioctl](istioctl/). This directory contains code for the
[_istioctl_](https://istio.io/latest/docs/reference/commands/istioctl/) command line utility.

    - [pilot](pilot/). This directory
contains platform-specific code to populate the
[abstract service model](https://istio.io/docs/concepts/traffic-management/#pilot), dynamically reconfigure the proxies
when the application topology changes, as well as translate
[routing rules](https://istio.io/latest/docs/reference/config/networking/) into proxy specific configuration.

    - [security](security/). This directory contains [security](https://istio.io/latest/docs/concepts/security/) related code,
including Citadel (acting as Certificate Authority), citadel agent, etc.

- [istio/proxy](https://github.com/istio/proxy). The Istio proxy contains
extensions to the [Envoy proxy](https://github.com/envoyproxy/envoy) (in the form of
Envoy filters) that support authentication, authorization, and telemetry collection.

- [istio/ztunnel](https://github.com/istio/ztunnel). The repository contains the Rust implementation of the ztunnel
component of Ambient mesh.

- [istio/client-go](https://github.com/istio/client-go). This repository defines
  auto-generated Kubernetes clients for interacting with Istio resources programmatically.

&gt; [!NOTE]
&gt; Only the `istio/api` and `istio/client-go` repositories expose stable interfaces intended for direct usage as libraries.

## Issue management

We use GitHub to track all of our bugs and feature requests. Each issue we track has a variety of metadata:

- **Epic**. An epic represents a feature area for Istio as a whole. Epics are fairly broad in scope and are basically product-level things.
Each issue is ultimately part of an epic.

- **Milestone**. Each issue is assigned a milestone. This is 0.1, 0.2, ..., or &#039;Nebulous Future&#039;. The milestone indicates when we
think the issue should get addressed.

- **Priority**. Each issue has a priority which is represented by the column in the [Prioritization](https://github.com/orgs/istio/projects/6) project. Priority can be one of
P0, P1, P2, or &gt;P2. The priority indicates how important it is to address the issue within the milestone. P0 says that the
milestone cannot be considered achieved if the issue isn&#039;t resolved.

---

&lt;div align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color-whitetext/cncf-color-whitetext.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/cncf/artwork/master/other/cncf/horizontal/color/cncf-color.svg&quot;&gt;
      &lt;img width=&quot;300&quot; alt=&quot;Cloud Native Computing Foundation logo&quot; src=&quot;https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color-whitetext/cncf-color-whitetext.svg&quot;&gt;
    &lt;/picture&gt;
    &lt;p&gt;Istio is a &lt;a href=&quot;https://cncf.io&quot;&gt;Cloud Native Computing Foundation&lt;/a&gt; project.&lt;/p&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[fyne-io/fyne]]></title>
            <link>https://github.com/fyne-io/fyne</link>
            <guid>https://github.com/fyne-io/fyne</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[Cross platform GUI toolkit in Go inspired by Material Design]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fyne-io/fyne">fyne-io/fyne</a></h1>
            <p>Cross platform GUI toolkit in Go inspired by Material Design</p>
            <p>Language: Go</p>
            <p>Stars: 27,215</p>
            <p>Forks: 1,482</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pkg.go.dev/fyne.io/fyne/v2?tab=doc&quot; title=&quot;Go API Reference&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/go-documentation-blue.svg?style=flat&quot; alt=&quot;Go API Reference&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://img.shields.io/github/v/release/fyne-io/fyne?include_prereleases&quot; title=&quot;Latest Release&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/fyne-io/fyne?include_prereleases&quot; alt=&quot;Latest Release&quot;&gt;&lt;/a&gt;
  &lt;a href=&#039;https://gophers.slack.com/messages/fyne&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/join-us%20on%20slack-gray.svg?longCache=true&amp;logo=slack&amp;colorB=blue&#039; alt=&#039;Join us on Slack&#039; /&gt;&lt;/a&gt;
  &lt;br /&gt;
  &lt;a href=&quot;https://goreportcard.com/report/fyne.io/fyne/v2&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/fyne.io/fyne/v2&quot; alt=&quot;Code Status&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/fyne-io/fyne/actions&quot;&gt;&lt;img src=&quot;https://github.com/fyne-io/fyne/workflows/Platform%20Tests/badge.svg&quot; alt=&quot;Build Status&quot; /&gt;&lt;/a&gt;
  &lt;a href=&#039;https://coveralls.io/github/fyne-io/fyne?branch=develop&#039;&gt;&lt;img src=&#039;https://coveralls.io/repos/github/fyne-io/fyne/badge.svg?branch=develop&#039; alt=&#039;Coverage Status&#039; /&gt;&lt;/a&gt;
&lt;/p&gt;

# About

[Fyne](https://fyne.io) is an easy-to-use UI toolkit and app API written in Go.
It is designed to build applications that run on desktop and mobile devices with a
single codebase.

# Prerequisites

To develop apps using Fyne you will need Go version 1.17 or later, a C compiler and your system&#039;s development tools.
If you&#039;re not sure if that&#039;s all installed or you don&#039;t know how then check out our
[Getting Started](https://fyne.io/develop/) document.

Using the standard go tools you can install Fyne&#039;s core library using:

    go get fyne.io/fyne/v2@latest

After importing a new module, run the following command before compiling the code for the first time. Avoid running it before writing code that uses the module to prevent accidental removal of dependencies:

    go mod tidy

# Widget demo

To run a showcase of the features of Fyne execute the following:

    go install fyne.io/fyne/v2/cmd/fyne_demo@latest
    fyne_demo

And you should see something like this (after you click a few buttons):

&lt;p align=&quot;center&quot; markdown=&quot;1&quot; style=&quot;max-width: 100%&quot;&gt;
  &lt;img src=&quot;img/widgets-dark.png&quot; width=&quot;752&quot; alt=&quot;Fyne Demo Dark Theme&quot; style=&quot;max-width: 100%&quot; /&gt;
&lt;/p&gt;

Or if you are using the light theme:

&lt;p align=&quot;center&quot; markdown=&quot;1&quot; style=&quot;max-width: 100%&quot;&gt;
  &lt;img src=&quot;img/widgets-light.png&quot; width=&quot;752&quot; alt=&quot;Fyne Demo Light Theme&quot; style=&quot;max-width: 100%&quot; /&gt;
&lt;/p&gt;

And even running on a mobile device:

&lt;p align=&quot;center&quot; markdown=&quot;1&quot; style=&quot;max-width: 100%&quot;&gt;
  &lt;img src=&quot;img/widgets-mobile-light.png&quot; width=&quot;348&quot; alt=&quot;Fyne Demo Mobile Light Theme&quot; style=&quot;max-width: 100%&quot; /&gt;
&lt;/p&gt;

# Getting Started

Fyne is designed to be really easy to code with.
If you have followed the prerequisite steps above then all you need is a
Go IDE (or a text editor).

Open a new file and you&#039;re ready to write your first app!

```go
package main

import (
	&quot;fyne.io/fyne/v2/app&quot;
	&quot;fyne.io/fyne/v2/container&quot;
	&quot;fyne.io/fyne/v2/widget&quot;
)

func main() {
	a := app.New()
	w := a.NewWindow(&quot;Hello&quot;)

	hello := widget.NewLabel(&quot;Hello Fyne!&quot;)
	w.SetContent(container.NewVBox(
		hello,
		widget.NewButton(&quot;Hi!&quot;, func() {
			hello.SetText(&quot;Welcome :)&quot;)
		}),
	))

	w.ShowAndRun()
}
```

And you can run that simply as:

    go run main.go

&gt; [!NOTE]  
&gt; The first compilation of Fyne on Windows _can_ take up to 10 minutes, depending on your hardware. Subsequent builds will be fast.

It should look like this:

&lt;div align=&quot;center&quot;&gt;
  &lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; style=&quot;margin: auto; border-collapse: collapse;&quot;&gt;
    &lt;tr style=&quot;border: none;&quot;&gt;&lt;td style=&quot;border: none;&quot;&gt;
      &lt;img src=&quot;img/hello-light.png&quot; width=&quot;207&quot; alt=&quot;Fyne Hello Dark Theme&quot; /&gt;
    &lt;/td&gt;&lt;td style=&quot;border: none;&quot;&gt;
      &lt;img src=&quot;img/hello-dark.png&quot; width=&quot;207&quot; alt=&quot;Fyne Hello Dark Theme&quot; /&gt;
    &lt;/td&gt;&lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

## Run in mobile simulation

There is a helpful mobile simulation mode that gives a hint of how your app would work on a mobile device:

    go run -tags mobile main.go

Another option is to use `fyne` command, see [Packaging for mobile](#packaging-for-mobile).

# Installing

Using `go install` will copy the executable into your go `bin` dir.
To install the application with icons etc into your operating system&#039;s standard
application location you can use the fyne utility and the &quot;install&quot; subcommand.

    go install fyne.io/fyne/v2/cmd/fyne@latest
    fyne install

# Packaging for mobile

To run on a mobile device it is necessary to package up the application.
To do this we can use the fyne utility &quot;package&quot; subcommand.
You will need to add appropriate parameters as prompted, but the basic command is shown below.
Once packaged you can install using the platform development tools or the fyne &quot;install&quot; subcommand.

    fyne package -os android -appID my.domain.appname
    fyne install -os android

The built Android application can run either in a real device or an Android emulator.
However, building for iOS is slightly different.
If the &quot;-os&quot; argument is &quot;ios&quot;, it is build only for a real iOS device.
Specify &quot;-os&quot; to &quot;iossimulator&quot; allows the application be able to run in an iOS simulator:

    fyne package -os ios -appID my.domain.appname
    fyne package -os iossimulator -appID my.domain.appname

# Preparing a release

Using the fyne utility &quot;release&quot; subcommand you can package up your app for release
to app stores and market places. Make sure you have the standard build tools installed
and have followed the platform documentation for setting up accounts and signing.
Then you can execute something like the following, notice the `-os ios` parameter allows
building an iOS app from macOS computer. Other combinations work as well :)

    $ fyne release -os ios -certificate &quot;Apple Distribution&quot; -profile &quot;My App Distribution&quot; -appID &quot;com.example.myapp&quot;

The above command will create a &#039;.ipa&#039; file that can then be uploaded to the iOS App Store.

# Documentation

More documentation is available at the [Fyne developer website](https://developer.fyne.io/) or on [pkg.go.dev](https://pkg.go.dev/fyne.io/fyne/v2?tab=doc).

# Examples

You can find many example applications in the [examples repository](https://github.com/fyne-io/examples/).
Alternatively a list of applications using fyne can be found at [our website](https://apps.fyne.io/).

# Shipping the Fyne Toolkit

All Fyne apps will work without pre-installed libraries, this is one reason the apps are so portable.
However, if looking to support Fyne in a bigger way on your operating system then you can install some utilities that help to make a more complete experience.

## Additional apps

It is recommended that you install the following additional apps:

| app           | go install                          | description                                                            |
| ------------- | ----------------------------------- | ---------------------------------------------------------------------- |
| fyne_settings | `fyne.io/fyne/v2/cmd/fyne_settings` | A GUI for managing your global Fyne settings like theme and scaling    |
| apps          | `github.com/fyne-io/apps`           | A graphical installer for the Fyne apps listed at https://apps.fyne.io |

These are optional applications but can help to create a more complete desktop experience.

## FyneDesk (Linux / BSD)

To go all the way with Fyne on your desktop / laptop computer you could install [FyneDesk](https://github.com/fyshos/fynedesk) as well :)

![FyneDesk screenshopt in dark mode](https://fyshos.com/img/desktop.png)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[microsoft/typescript-go]]></title>
            <link>https://github.com/microsoft/typescript-go</link>
            <guid>https://github.com/microsoft/typescript-go</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[Staging repo for development of native port of TypeScript]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/typescript-go">microsoft/typescript-go</a></h1>
            <p>Staging repo for development of native port of TypeScript</p>
            <p>Language: Go</p>
            <p>Stars: 22,338</p>
            <p>Forks: 709</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># TypeScript 7

[Not sure what this is? Read the announcement post!](https://devblogs.microsoft.com/typescript/typescript-native-port/)

## Preview

A preview build is available on npm as [`@typescript/native-preview`](https://www.npmjs.com/package/@typescript/native-preview).

```sh
npm install @typescript/native-preview
npx tsgo # Use this as you would tsc.
```

A preview VS Code extension is [available on the VS Code marketplace](https://marketplace.visualstudio.com/items?itemName=TypeScriptTeam.native-preview).

To use this, set this in your VS Code settings:

```json
{
    &quot;typescript.experimental.useTsgo&quot;: true
}
```

## What Works So Far?

This is still a work in progress and is not yet at full feature parity with TypeScript. Bugs may exist. Please check this list carefully before logging a new issue or assuming an intentional change.

| Feature | Status | Notes |
|---------|--------|-------|
| Program creation | done | Same files and module resolution as TS 5.8. Not all resolution modes supported yet. |
| Parsing/scanning | done | Exact same syntax errors as TS 5.8 |
| Commandline and `tsconfig.json` parsing | mostly done | Missing --help, --init. |
| Type resolution | done | Same types as TS 5.8. |
| Type checking | done | Same errors, locations, and messages as TS 5.8. Types printback in errors may display differently. |
| JavaScript-specific inference and JSDoc | in progress | Mostly complete, but intentionally lacking some features. Declaration emit not complete. |
| JSX | done | - |
| Declaration emit | in progress | Most common features are in place, but some edge cases and feature flags are still unhandled. |
| Emit (JS output) | in progress | `target: esnext` well-supported, other targets may have gaps. |
| Watch mode | prototype | Watches files and rebuilds, but no incremental rechecking. Not optimized. |
| Build mode / project references | done | - |
| Incremental build | done | - |
| Language service (LSP) | in progress | Some functionality (errors, hover, go to def, refs, sig help). More features coming soon. |
| API | not ready | - |

Definitions:

 * **done** aka &quot;believed done&quot;: We&#039;re not currently aware of any deficits or major left work to do. OK to log bugs
 * **in progress**: currently being worked on; some features may work and some might not. OK to log panics, but nothing else please
 * **prototype**: proof-of-concept only; do not log bugs
 * **not ready**: either haven&#039;t even started yet, or far enough from ready that you shouldn&#039;t bother messing with it yet

## Other Notes

Long-term, we expect that this repo and its contents will be merged into `microsoft/TypeScript`.
As a result, the repo and issue tracker for typescript-go will eventually be closed, so treat discussions/issues accordingly.

For a list of intentional changes with respect to TypeScript 5.7, see CHANGES.md.

## Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit [Contributor License Agreements](https://cla.opensource.microsoft.com).

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
[Microsoft&#039;s Trademark &amp; Brand Guidelines](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party&#039;s policies.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[evcc-io/evcc]]></title>
            <link>https://github.com/evcc-io/evcc</link>
            <guid>https://github.com/evcc-io/evcc</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[solar charging ☀️🚘]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/evcc-io/evcc">evcc-io/evcc</a></h1>
            <p>solar charging ☀️🚘</p>
            <p>Language: Go</p>
            <p>Stars: 5,366</p>
            <p>Forks: 1,042</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># evcc 🚘☀️

[![Build](https://github.com/evcc-io/evcc/actions/workflows/nightly.yml/badge.svg)](https://github.com/evcc-io/evcc/actions/workflows/nightly.yml)
[![Translation](https://hosted.weblate.org/widgets/evcc/-/evcc/svg-badge.svg)](https://hosted.weblate.org/engage/evcc/)
![Docker Pulls](https://img.shields.io/docker/pulls/evcc/evcc)
[![OSS hosting by cloudsmith](https://img.shields.io/badge/OSS%20hosting%20by-cloudsmith-blue?logo=cloudsmith)](https://cloudsmith.io/~evcc/packages/)
[![Latest Version](https://img.shields.io/github/release/evcc-io/evcc.svg)](https://github.com/evcc-io/evcc/releases)&lt;br/&gt;
[![Built with Depot](https://depot.dev/badges/built-with-depot.svg)](https://depot.dev/?utm_source=evcc)

evcc is an extensible EV Charge Controller and home energy management system.

![Screenshot](assets/github/screenshot.webp)

Our goal is to provide local energy management, without relying on cloud services.
Featured in [PV Magazine](https://www.pv-magazine.de/2022/01/14/mit-open-source-lademanager-schnittstellen-zu-wallbox-und-photovoltaik-anlage-meistern/) and [c’t Magazin](https://www.youtube.com/watch?v=MoBpEXHMNjI).

## Features

- simple and clean user interface
- support for many [EV chargers](https://docs.evcc.io/en/docs/devices/chargers):
  - ABB, ABL, Alfen, Alphatec, Amperfied, Ampure, Audi, AUTEL, Autoaid, Bender, BMW, cFos, Charge Amps, Compleo, CUBOS, Cupra, Dadapower, DaheimLaden, Delta, E.ON Drive, E3/DC, Easee, Ebee, echarge, EcoHarmony, Edgetech, Elecq, eledio, Elli, EM2GO, EN+, enercab, Ensto, EntraTek, ESL, eSystems, Etrel, EVBox, Free2Move, Free2move eSolutions, Fronius, Garo, go-e, Hardy Barth, Heidelberg, Hesotec, Homecharge, Huawei, Innogy, INRO, Juice, Kathrein, KEBA, Kontron Solar, Kostal, KSE, LadeFoxx, LRT, Mennekes, NRGkick, OBO Bettermann, OpenEVSE, openWB, Optec, Orbis, PC Electric, Peblar, Phoenix Contact, Plugchoice, Porsche, Pracht, Pulsares, Pulsatrix, Qcells, Schneider, Schrack, SENEC, Siemens, Skoda, SMA, Smartfox, SolarEdge, Solax, Sonnen, Spelsberg, Stark in Strom, Sungrow, TechniSat, Tesla, Tigo, TinkerForge, Ubitricity, V2C Trydan, Vestel, Victron, Viridian EV, Volkswagen, Volt Time, Wallbe, wallbox, Walther Werke, Webasto, Weidmüller, Zaptec, ZJ Beny. [Read more.](https://docs.evcc.io/en/docs/devices/chargers)
  - **EEBus** support (Elli, PMCC)
  - **OCPP** support
  - **build-your-own:** Phoenix Contact (includes ESL Walli), EVSE DIN
  - **smart switches:** AVM, FRITZ!, Home Assistant, Homematic IP, HomeWizard, myStrom, Shelly, Tasmota, TP-Link. [Read more.](https://docs.evcc.io/en/docs/devices/smartswitches)
  - **heat pumps and electric heaters:** alpha innotec, Bosch, Buderus, Bösch, CTA All-In-One, Daikin, Elco, IDM, Junkers, Kermi, Lambda, my-PV, Nibe, Novelan, Roth, Stiebel Eltron, Tecalor, Vaillant, Viessmann, Wolf, Zewotherm. [Read more.](https://docs.evcc.io/en/docs/devices/heating)
- support for many [energy meters](https://docs.evcc.io/en/docs/devices/meters):
  - **solar inverters and battery systems:** A-Tronix, Acrel, Ads-tec, Alpha ESS, Ampere, Anker, APsystems, AVM, Axitec, BGEtech, Bosch, Bosswerk, Carlo Gavazzi, Deye, E3/DC, Eastron, Enphase, FENECON, FRITZ!, FoxESS, Fronius, Ginlong, go-e, GoodWe, Growatt, Homematic IP, HomeWizard, Hoymiles, Huawei, IAMMETER, IGEN Tech, Kostal, LG, Loxone, M-TEC, Marstek, myStrom, OpenEMS, Powerfox, Qcells, RCT, SAJ, SAX, SENEC, Senergy, Shelly, Siemens, Sigenergy, SMA, Smartfox, SofarSolar, Solaranzeige, SolarEdge, SolarMax, Solarwatt, Solax, Solinteng, Sonnen, St-ems, Steca, Sungrow, Sunsynk, Sunway, Tasmota, Tesla, TP-Link, VARTA, Victron, Wattsonic, Youless, ZCS Azzurro, Zendure. [Read more.](https://docs.evcc.io/en/docs/devices/meters)
  - **general energy meters:** A-Tronix, ABB, Acrel, Alpha ESS, Ampere, AVM, Axitec, Bernecker Engineering, BGEtech, Bosch, Carlo Gavazzi, cFos, Deye, DSMR, DZG, E3/DC, Eastron, Enphase, ESPHome, FENECON, FoxESS, FRITZ!, Fronius, Ginlong, go-e, GoodWe, Growatt, Homematic IP, HomeWizard, Huawei, IAMMETER, inepro, IOmeter, Janitza, KEBA, Kostal, LG, Loxone, M-TEC, mhendriks, my-PV, myStrom, OpenEMS, ORNO, P1Monitor, Powerfox, Qcells, RCT, Saia-Burgess Controls (SBC), SAJ, SAX, Schneider Electric, SENEC, Shelly, Siemens, Sigenergy, SMA, Smartfox, SofarSolar, Solaranzeige, SolarEdge, SolarMax, Solarwatt, Solax, Solinteng, Sonnen, St-ems, Sungrow, Sunsynk, Sunway, Tasmota, Tesla, Tibber, TQ, VARTA, Victron, Volkszähler, Wago, Wattsonic, Weidmüller, Youless, ZCS Azzurro, Zuidwijk. [Read more.](https://docs.evcc.io/en/docs/devices/meters)
  - **integrated systems**: SMA Sunny Home Manager and Energy Meter, KOSTAL Smart Energy Meter (KSEM, EMxx)
  - **sunspec**-compatible inverter or home battery devices
  - **mbmd**-compatible devices, see [volkszaehler/mbmd](https://github.com/volkszaehler/mbmd#supported-devices) for a complete list
- [vehicle](https://docs.evcc.io/en/docs/devices/vehicles) integrations (state of charge, remote charge, battery and preconditioning status):
  - Aiways, Audi, BMW, Citroën, Dacia, DS, Fiat, Ford, Hyundai, Jeep, Kia, Mercedes-Benz, MG, Mini, Nissan, NIU, Opel, Peugeot, Polestar, Renault, Seat, Skoda, Smart, Tesla, Toyota, Volkswagen, Volvo, Zero Motorcycles. [Read more.](https://docs.evcc.io/en/docs/devices/vehicles)
  - **services:** OVMS, Tronity, evNotify, ioBroker.bmw, mg2mqtt, mz2mqtt, TeslaLogger, TeslaMate, Tessi, volvo2mqtt
- [plugins](https://docs.evcc.io/en/docs/devices/plugins) for integrating with any charger, smartswitch, heatpump, electric heater, meter, solar- / battery-inverter or vehicle:
  - Modbus, HTTP, MQTT, JavaScript, WebSocket, Go and shell scripts
- status [notifications](https://docs.evcc.io/en/docs/reference/configuration/messaging) using [Telegram](https://telegram.org), [PushOver](https://pushover.net) and [many more](https://containrrr.dev/shoutrrr/)
- logging using [InfluxDB](https://www.influxdata.com) and [Grafana](https://grafana.com/grafana/)
- [REST](https://docs.evcc.io/en/docs/integrations/rest-api) and [MQTT](https://docs.evcc.io/en/docs/integrations/mqtt-api) APIs for integration with home automation systems
- Add-ons for [Home Assistant](https://docs.evcc.io/en/docs/integrations/home-assistant) and [openHAB](https://www.openhab.org/addons/bindings/evcc) (not maintained by the evcc core team)

## Getting Started

You&#039;ll find everything you need in our [documentation](https://docs.evcc.io/en/).

## Contributing

Technical details on how to contribute, how to add translations and how to build evcc from source can be found [here](CONTRIBUTING.md).

[![Weblate Hosted](https://hosted.weblate.org/widgets/evcc/-/evcc/287x66-grey.png)](https://hosted.weblate.org/engage/evcc/)

## Sponsorship

&lt;img src=&quot;assets/github/evcc-gopher.png&quot; align=&quot;right&quot; width=&quot;150&quot; /&gt;

evcc believes in open source software. We&#039;re committed to provide best in class EV charging experience.
Maintaining evcc consumes time and effort. With the vast amount of different devices to support, we depend on community and vendor support to keep evcc alive.

While evcc is open source, we would also like to encourage vendors to provide open source hardware devices, public documentation and support open source projects like ours that provide additional value to otherwise closed hardware. Where this is not the case, evcc requires &quot;sponsor token&quot; to finance ongoing development and support of evcc.

Learn more about our [sponsorship model](https://docs.evcc.io/en/docs/sponsorship).

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

For additional license information regarding fonts, icons, and other assets, please see the [LICENSES](LICENSES/) folder.

**Note:** All sponsor-required components are excluded from the MIT License.
See file license header for details.
If you want to use them in your own project, one evcc sponsorship token is required per evcc instance.
Custom licensing agreements are available - please [contact us](mailto:info@evcc.io) to discuss your specific requirements.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[coder/coder]]></title>
            <link>https://github.com/coder/coder</link>
            <guid>https://github.com/coder/coder</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[Secure environments for developers and their agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/coder/coder">coder/coder</a></h1>
            <p>Secure environments for developers and their agents</p>
            <p>Language: Go</p>
            <p>Stars: 11,102</p>
            <p>Forks: 1,024</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable MD041 --&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://coder.com#gh-light-mode-only&quot;&gt;
    &lt;img src=&quot;./docs/images/logo-black.png&quot; alt=&quot;Coder Logo Light&quot; style=&quot;width: 128px&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://coder.com#gh-dark-mode-only&quot;&gt;
    &lt;img src=&quot;./docs/images/logo-white.png&quot; alt=&quot;Coder Logo Dark&quot; style=&quot;width: 128px&quot;&gt;
  &lt;/a&gt;

  &lt;h1&gt;
  Self-Hosted Cloud Development Environments
  &lt;/h1&gt;

  &lt;a href=&quot;https://coder.com#gh-light-mode-only&quot;&gt;
    &lt;img src=&quot;./docs/images/banner-black.png&quot; alt=&quot;Coder Banner Light&quot; style=&quot;width: 650px&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://coder.com#gh-dark-mode-only&quot;&gt;
    &lt;img src=&quot;./docs/images/banner-white.png&quot; alt=&quot;Coder Banner Dark&quot; style=&quot;width: 650px&quot;&gt;
  &lt;/a&gt;

  &lt;br&gt;
  &lt;br&gt;

[Quickstart](#quickstart) | [Docs](https://coder.com/docs) | [Why Coder](https://coder.com/why) | [Premium](https://coder.com/pricing#compare-plans)

[![discord](https://img.shields.io/discord/747933592273027093?label=discord)](https://discord.gg/coder)
[![release](https://img.shields.io/github/v/release/coder/coder)](https://github.com/coder/coder/releases/latest)
[![godoc](https://pkg.go.dev/badge/github.com/coder/coder.svg)](https://pkg.go.dev/github.com/coder/coder)
[![Go Report Card](https://goreportcard.com/badge/github.com/coder/coder/v2)](https://goreportcard.com/report/github.com/coder/coder/v2)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9511/badge)](https://www.bestpractices.dev/projects/9511)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/coder/coder/badge)](https://scorecard.dev/viewer/?uri=github.com%2Fcoder%2Fcoder)
[![license](https://img.shields.io/github/license/coder/coder)](./LICENSE)

&lt;/div&gt;

[Coder](https://coder.com) enables organizations to set up development environments in their public or private cloud infrastructure. Cloud development environments are defined with Terraform, connected through a secure high-speed Wireguard® tunnel, and automatically shut down when not used to save on costs. Coder gives engineering teams the flexibility to use the cloud for workloads most beneficial to them.

- Define cloud development environments in Terraform
  - EC2 VMs, Kubernetes Pods, Docker Containers, etc.
- Automatically shutdown idle resources to save on costs
- Onboard developers in seconds instead of days

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/hero-image.png&quot; alt=&quot;Coder Hero Image&quot;&gt;
&lt;/p&gt;

## Quickstart

The most convenient way to try Coder is to install it on your local machine and experiment with provisioning cloud development environments using Docker (works on Linux, macOS, and Windows).

```shell
# First, install Coder
curl -L https://coder.com/install.sh | sh

# Start the Coder server (caches data in ~/.cache/coder)
coder server

# Navigate to http://localhost:3000 to create your initial user,
# create a Docker template and provision a workspace
```

## Install

The easiest way to install Coder is to use our
[install script](https://github.com/coder/coder/blob/main/install.sh) for Linux
and macOS. For Windows, use the latest `..._installer.exe` file from GitHub
Releases.

```shell
curl -L https://coder.com/install.sh | sh
```

You can run the install script with `--dry-run` to see the commands that will be used to install without executing them. Run the install script with `--help` for additional flags.

&gt; See [install](https://coder.com/docs/install) for additional methods.

Once installed, you can start a production deployment with a single command:

```shell
# Automatically sets up an external access URL on *.try.coder.app
coder server

# Requires a PostgreSQL instance (version 13 or higher) and external access URL
coder server --postgres-url &lt;url&gt; --access-url &lt;url&gt;
```

Use `coder --help` to get a list of flags and environment variables. Use our [install guides](https://coder.com/docs/install) for a complete walkthrough.

## Documentation

Browse our docs [here](https://coder.com/docs) or visit a specific section below:

- [**Templates**](https://coder.com/docs/templates): Templates are written in Terraform and describe the infrastructure for workspaces
- [**Workspaces**](https://coder.com/docs/workspaces): Workspaces contain the IDEs, dependencies, and configuration information needed for software development
- [**IDEs**](https://coder.com/docs/ides): Connect your existing editor to a workspace
- [**Administration**](https://coder.com/docs/admin): Learn how to operate Coder
- [**Premium**](https://coder.com/pricing#compare-plans): Learn about our paid features built for large teams

## Support

Feel free to [open an issue](https://github.com/coder/coder/issues/new) if you have questions, run into bugs, or have a feature request.

[Join our Discord](https://discord.gg/coder) to provide feedback on in-progress features and chat with the community using Coder!

## Integrations

We are always working on new integrations. Please feel free to open an issue and ask for an integration. Contributions are welcome in any official or community repositories.

### Official

- [**VS Code Extension**](https://marketplace.visualstudio.com/items?itemName=coder.coder-remote): Open any Coder workspace in VS Code with a single click
- [**JetBrains Toolbox Plugin**](https://plugins.jetbrains.com/plugin/26968-coder): Open any Coder workspace from JetBrains Toolbox with a single click
- [**JetBrains Gateway Plugin**](https://plugins.jetbrains.com/plugin/19620-coder): Open any Coder workspace in JetBrains Gateway with a single click
- [**Dev Container Builder**](https://github.com/coder/envbuilder): Build development environments using `devcontainer.json` on Docker, Kubernetes, and OpenShift
- [**Coder Registry**](https://registry.coder.com): Build and extend development environments with common use-cases
- [**Kubernetes Log Stream**](https://github.com/coder/coder-logstream-kube): Stream Kubernetes Pod events to the Coder startup logs
- [**Self-Hosted VS Code Extension Marketplace**](https://github.com/coder/code-marketplace): A private extension marketplace that works in restricted or airgapped networks integrating with [code-server](https://github.com/coder/code-server).
- [**Setup Coder**](https://github.com/marketplace/actions/setup-coder): An action to setup coder CLI in GitHub workflows.

### Community

- [**Provision Coder with Terraform**](https://github.com/ElliotG/coder-oss-tf): Provision Coder on Google GKE, Azure AKS, AWS EKS, DigitalOcean DOKS, IBMCloud K8s, OVHCloud K8s, and Scaleway K8s Kapsule with Terraform
- [**Coder Template GitHub Action**](https://github.com/marketplace/actions/update-coder-template): A GitHub Action that updates Coder templates

## Contributing

We are always happy to see new contributors to Coder. If you are new to the Coder codebase, we have
[a guide on how to get started](https://coder.com/docs/CONTRIBUTING). We&#039;d love to see your
contributions!

## Hiring

Apply [here](https://jobs.ashbyhq.com/coder?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=unknown) if you&#039;re interested in joining our team.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[dbos-inc/dbos-transact-golang]]></title>
            <link>https://github.com/dbos-inc/dbos-transact-golang</link>
            <guid>https://github.com/dbos-inc/dbos-transact-golang</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[Durable Workflow Orchestration with Golang and Postgres]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dbos-inc/dbos-transact-golang">dbos-inc/dbos-transact-golang</a></h1>
            <p>Durable Workflow Orchestration with Golang and Postgres</p>
            <p>Language: Go</p>
            <p>Stars: 436</p>
            <p>Forks: 37</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

[![Go Reference](https://pkg.go.dev/badge/github.com/dbos-inc/dbos-transact-golang.svg)](https://pkg.go.dev/github.com/dbos-inc/dbos-transact-golang)
[![Go Report Card](https://goreportcard.com/badge/github.com/dbos-inc/dbos-transact-golang)](https://goreportcard.com/report/github.com/dbos-inc/dbos-transact-golang)
[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/dbos-inc/dbos-transact-golang?sort=semver)](https://github.com/dbos-inc/dbos-transact-golang/releases)
[![Join Discord](https://img.shields.io/badge/Discord-Join%20Chat-5865F2?logo=discord&amp;logoColor=white)](https://discord.com/invite/jsmC6pXGgX)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![GitHub Stars](https://img.shields.io/github/stars/dbos-inc/dbos-transact-golang?style=social)](https://github.com/dbos-inc/dbos-transact-golang)


# DBOS Transact: Lightweight Durable Workflow Orchestration with Postgres

#### [Documentation](https://docs.dbos.dev/) &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;  [Examples](https://docs.dbos.dev/examples) &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; [Github](https://github.com/dbos-inc)
&lt;/div&gt;

---

## What is DBOS?

DBOS provides lightweight durable workflow orchestration on top of Postgres. Instead of managing your own workflow orchestrator or task queue system, you can use DBOS to add durable workflows and queues to your program in just a few lines of code.


## When Should I Use DBOS?

You should consider using DBOS if your application needs to **reliably handle failures**.
For example, you might be building a payments service that must reliably process transactions even if servers crash mid-operation, or a long-running data pipeline that needs to resume seamlessly from checkpoints rather than restart from the beginning when interrupted.

Handling failures is costly and complicated, requiring complex state management and recovery logic as well as heavyweight tools like external orchestration services.
DBOS makes it simpler: annotate your code to checkpoint it in Postgres and automatically recover from any failure.
DBOS also provides powerful Postgres-backed primitives that makes it easier to write and operate reliable code, including durable queues, notifications, scheduling, event processing, and programmatic workflow management.


## Features
&lt;details open&gt;&lt;summary&gt;&lt;strong&gt;💾 Durable Workflows&lt;/strong&gt;&lt;/summary&gt;
 
DBOS workflows make your program **durable** by checkpointing its state in Postgres.
If your program ever fails, when it restarts all your workflows will automatically resume from the last completed step.

You add durable workflows to your existing Golang program by registering ordinary functions as workflows or running them as steps:

```golang
package main

import (
    &quot;context&quot;
    &quot;fmt&quot;
    &quot;os&quot;
    &quot;time&quot;

    &quot;github.com/dbos-inc/dbos-transact-golang/dbos&quot;
)

func workflow(dbosCtx dbos.DBOSContext, _ string) (string, error) {
    _, err := dbos.RunAsStep(dbosCtx, stepOne)
    if err != nil {
        return &quot;&quot;, err
    }
    return dbos.RunAsStep(dbosCtx, stepTwo)
}

func stepOne(ctx context.Context) (string, error) {
    fmt.Println(&quot;Step one completed!&quot;)
    return &quot;Step 1 completed&quot;, nil
}

func stepTwo(ctx context.Context) (string, error) {
    fmt.Println(&quot;Step two completed!&quot;)
    return &quot;Step 2 completed - Workflow finished successfully&quot;, nil
}

func main() {
    // Initialize a DBOS context
    ctx, err := dbos.NewDBOSContext(context.Background(), dbos.Config{
        DatabaseURL: os.Getenv(&quot;DBOS_SYSTEM_DATABASE_URL&quot;),
        AppName:     &quot;myapp&quot;,
    })
    if err != nil {
        panic(err)
    }

    // Register a workflow
    dbos.RegisterWorkflow(ctx, workflow)

    // Launch DBOS
    err = dbos.Launch(ctx)
    if err != nil {
        panic(err)
    }
    defer dbos.Shutdown(ctx, 2 * time.Second)

    // Run a durable workflow and get its result
    handle, err := dbos.RunWorkflow(ctx, workflow, &quot;&quot;)
    if err != nil {
        panic(err)
    }
    res, err := handle.GetResult()
    if err != nil {
        panic(err)
    }
    fmt.Println(&quot;Workflow result:&quot;, res)
}
```


Workflows are particularly useful for 

- Orchestrating business processes so they seamlessly recover from any failure.
- Building observable and fault-tolerant data pipelines.
- Operating an AI agent, or any application that relies on unreliable or non-deterministic APIs.

&lt;/details&gt;

&lt;details&gt;&lt;summary&gt;&lt;strong&gt;📒 Durable Queues&lt;/strong&gt;&lt;/summary&gt;

####

DBOS queues help you **durably** run tasks in the background.
When you enqueue a workflow, one of your processes will pick it up for execution.
DBOS manages the execution of your tasks: it guarantees that tasks complete, and that their callers get their results without needing to resubmit them, even if your application is interrupted.

Queues also provide flow control, so you can limit the concurrency of your tasks on a per-queue or per-process basis.
You can also set timeouts for tasks, rate limit how often queued tasks are executed, deduplicate tasks, or prioritize tasks.

You can add queues to your workflows in just a couple lines of code.
They don&#039;t require a separate queueing service or message broker&amp;mdash;just Postgres.

```golang
package main

import (
    &quot;context&quot;
    &quot;fmt&quot;
    &quot;os&quot;
    &quot;time&quot;

    &quot;github.com/dbos-inc/dbos-transact-golang/dbos&quot;
)

func task(ctx dbos.DBOSContext, i int) (int, error) {
    dbos.Sleep(ctx, 5*time.Second)
    fmt.Printf(&quot;Task %d completed\n&quot;, i)
    return i, nil
}

func main() {
    // Initialize a DBOS context
    ctx, err := dbos.NewDBOSContext(context.Background(), dbos.Config{
        DatabaseURL: os.Getenv(&quot;DBOS_SYSTEM_DATABASE_URL&quot;),
        AppName:     &quot;myapp&quot;,
    })
    if err != nil {
        panic(err)
    }

    // Register the workflow and create a durable queue
    dbos.RegisterWorkflow(ctx, task)
    queue := dbos.NewWorkflowQueue(ctx, &quot;queue&quot;)

    // Launch DBOS
    err = dbos.Launch(ctx)
    if err != nil {
        panic(err)
    }
    defer dbos.Shutdown(ctx, 2 * time.Second)

    // Enqueue tasks and gather results
    fmt.Println(&quot;Enqueuing workflows&quot;)
    handles := make([]dbos.WorkflowHandle[int], 10)
    for i := range 10 {
        handle, err := dbos.RunWorkflow(ctx, task, i, dbos.WithQueue(queue.Name))
        if err != nil {
            panic(fmt.Sprintf(&quot;failed to enqueue step %d: %v&quot;, i, err))
        }
        handles[i] = handle
    }
    results := make([]int, 10)
    for i, handle := range handles {
        result, err := handle.GetResult()
        if err != nil {
            panic(fmt.Sprintf(&quot;failed to get result for step %d: %v&quot;, i, err))
        }
        results[i] = result
    }
    fmt.Printf(&quot;Successfully completed %d steps\n&quot;, len(results))
}
```
&lt;/details&gt;

&lt;details&gt;&lt;summary&gt;&lt;strong&gt;🎫 Exactly-Once Event Processing&lt;/strong&gt;&lt;/summary&gt;

####

Use DBOS to build reliable webhooks, event listeners, or Kafka consumers by starting a workflow exactly-once in response to an event.
Acknowledge the event immediately while reliably processing it in the background.

For example:

```golang
_, err := dbos.RunWorkflow(ctx, task, i, dbos.WithWorkflowID(exactlyOnceEventID))
```
&lt;/details&gt;

&lt;details&gt;&lt;summary&gt;&lt;strong&gt;📅 Durable Scheduling&lt;/strong&gt;&lt;/summary&gt;

####

Schedule workflows using cron syntax, or use durable sleep to pause workflows for as long as you like (even days or weeks) before executing.

```golang
dbos.RegisterWorkflow(dbosCtx, func(ctx dbos.DBOSContext, scheduledTime time.Time) (string, error) {
    return fmt.Sprintf(&quot;Workflow executed at %s&quot;, scheduledTime), nil
}, dbos.WithSchedule(&quot;* * * * * *&quot;)) // Every second
```

You can add a durable sleep to any workflow with a single line of code.
It stores its wakeup time in Postgres so the workflow sleeps through any interruption or restart, then always resumes on schedule.

```golang
func workflow(ctx dbos.DBOSContext, duration time.Duration) (string, error) {
    dbos.Sleep(ctx, duration)
    return fmt.Sprintf(&quot;Workflow slept for %s&quot;, duration), nil
}

handle, err := dbos.RunWorkflow(dbosCtx, workflow, time.Second*5)
_, err = handle.GetResult()
```

&lt;/details&gt;

&lt;details&gt;&lt;summary&gt;&lt;strong&gt;📫 Durable Notifications&lt;/strong&gt;&lt;/summary&gt;

####

Pause your workflow executions until a notification is received, or emit events from your workflow to send progress updates to external clients.
All notifications are stored in Postgres, so they can be sent and received with exactly-once semantics.
Set durable timeouts when waiting for events, so you can wait for as long as you like (even days or weeks) through interruptions or restarts, then resume once a notification arrives or the timeout is reached.

For example, build a reliable billing workflow that durably waits for a notification from a payments service, processing it exactly-once:

```golang
func sendWorkflow(ctx dbos.DBOSContext, message string) (string, error) {
    err := dbos.Send(ctx, &quot;receiverID&quot;, message, &quot;topic&quot;)
    return &quot;sent&quot;, err
}

func receiveWorkflow(ctx dbos.DBOSContext, topic string) (string, error) {
    return dbos.Recv[string](ctx, topic, 48 * time.Hour)
}

// Start a receiver in the background
recvHandle, err := dbos.RunWorkflow(dbosCtx, receiveWorkflow, &quot;topic&quot;, dbos.WithWorkflowID(&quot;receiverID&quot;))

// Send a message
sendHandle, err := dbos.RunWorkflow(dbosCtx, sendWorkflow, &quot;hola!&quot;)
_, err = sendHandle.GetResult()

// Eventually get the response
recvResult, err := recvHandle.GetResult()
```

&lt;/details&gt;

## Getting Started

To get started, follow the [quickstart](https://docs.dbos.dev/quickstart) to install this open-source library and connect it to a Postgres database.
Then, check out the [programming guide](https://docs.dbos.dev/python/programming-guide) to learn how to build with durable workflows and queues.

## Documentation

[https://docs.dbos.dev](https://docs.dbos.dev)

## Examples

[https://docs.dbos.dev/examples](https://docs.dbos.dev/examples)

## DBOS vs. Other Systems

&lt;details&gt;&lt;summary&gt;&lt;strong&gt;DBOS vs. Temporal&lt;/strong&gt;&lt;/summary&gt;

####

Both DBOS and Temporal provide durable execution, but DBOS is implemented in a lightweight Postgres-backed library whereas Temporal is implemented in an externally orchestrated server.

You can add DBOS to your program by installing this open-source library, connecting it to Postgres, and annotating workflows and steps.
By contrast, to add Temporal to your program, you must rearchitect your program to move your workflows and steps (activities) to a Temporal worker, configure a Temporal server to orchestrate those workflows, and access your workflows only through a Temporal client.
[This blog post](https://www.dbos.dev/blog/durable-execution-coding-comparison) makes the comparison in more detail.

**When to use DBOS:** You need to add durable workflows to your applications with minimal rearchitecting, or you are using Postgres.

**When to use Temporal:** You don&#039;t want to add Postgres to your stack, or you need a language DBOS doesn&#039;t support yet.

&lt;/details&gt;

&lt;details&gt;&lt;summary&gt;&lt;strong&gt;DBOS vs. Airflow&lt;/strong&gt;&lt;/summary&gt;

####

DBOS and Airflow both provide workflow abstractions.
Airflow is targeted at data science use cases, providing many out-of-the-box connectors but requiring workflows be written as explicit DAGs and externally orchestrating them from an Airflow cluster.
Airflow is designed for batch operations and does not provide good performance for streaming or real-time use cases.
DBOS is general-purpose, but is often used for data pipelines, allowing developers to write workflows as code and requiring no infrastructure except Postgres.

**When to use DBOS:** You need the flexibility of writing workflows as code, or you need higher performance than Airflow is capable of (particularly for streaming or real-time use cases).

**When to use Airflow:** You need Airflow&#039;s ecosystem of connectors.

&lt;/details&gt;

&lt;details&gt;&lt;summary&gt;&lt;strong&gt;DBOS vs. Celery/BullMQ&lt;/strong&gt;&lt;/summary&gt;

####

DBOS provides a similar queue abstraction to dedicated queueing systems like Celery or BullMQ: you can declare queues, submit tasks to them, and control their flow with concurrency limits, rate limits, timeouts, prioritization, etc.
However, DBOS queues are **durable and Postgres-backed** and integrate with durable workflows.
For example, in DBOS you can write a durable workflow that enqueues a thousand tasks and waits for their results.
DBOS checkpoints the workflow and each of its tasks in Postgres, guaranteeing that even if failures or interruptions occur, the tasks will complete and the workflow will collect their results.
By contrast, Celery/BullMQ are Redis-backed and don&#039;t provide workflows, so they provide fewer guarantees but better performance.

**When to use DBOS:** You need the reliability of enqueueing tasks from durable workflows.

**When to use Celery/BullMQ**: You don&#039;t need durability, or you need very high throughput beyond what your Postgres server can support.
&lt;/details&gt;

## ⭐️ Like this project?
[Star it on GitHub](https://github.com/dbos-inc/dbos-transact-golang)
[![GitHub Stars](https://img.shields.io/github/stars/dbos-inc/dbos-transact-golang?style=social)](https://github.com/dbos-inc/dbos-transact-golang)</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[go-gitea/gitea]]></title>
            <link>https://github.com/go-gitea/gitea</link>
            <guid>https://github.com/go-gitea/gitea</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[Git with a cup of tea! Painless self-hosted all-in-one software development service, including Git hosting, code review, team collaboration, package registry and CI/CD]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/go-gitea/gitea">go-gitea/gitea</a></h1>
            <p>Git with a cup of tea! Painless self-hosted all-in-one software development service, including Git hosting, code review, team collaboration, package registry and CI/CD</p>
            <p>Language: Go</p>
            <p>Stars: 50,974</p>
            <p>Forks: 6,098</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre># Gitea

[![](https://github.com/go-gitea/gitea/actions/workflows/release-nightly.yml/badge.svg?branch=main)](https://github.com/go-gitea/gitea/actions/workflows/release-nightly.yml?query=branch%3Amain &quot;Release Nightly&quot;)
[![](https://img.shields.io/discord/322538954119184384.svg?logo=discord&amp;logoColor=white&amp;label=Discord&amp;color=5865F2)](https://discord.gg/Gitea &quot;Join the Discord chat at https://discord.gg/Gitea&quot;)
[![](https://goreportcard.com/badge/code.gitea.io/gitea)](https://goreportcard.com/report/code.gitea.io/gitea &quot;Go Report Card&quot;)
[![](https://pkg.go.dev/badge/code.gitea.io/gitea?status.svg)](https://pkg.go.dev/code.gitea.io/gitea &quot;GoDoc&quot;)
[![](https://img.shields.io/github/release/go-gitea/gitea.svg)](https://github.com/go-gitea/gitea/releases/latest &quot;GitHub release&quot;)
[![](https://www.codetriage.com/go-gitea/gitea/badges/users.svg)](https://www.codetriage.com/go-gitea/gitea &quot;Help Contribute to Open Source&quot;)
[![](https://opencollective.com/gitea/tiers/backers/badge.svg?label=backers&amp;color=brightgreen)](https://opencollective.com/gitea &quot;Become a backer/sponsor of gitea&quot;)
[![](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT &quot;License: MIT&quot;)
[![Contribute with Gitpod](https://img.shields.io/badge/Contribute%20with-Gitpod-908a85?logo=gitpod&amp;color=green)](https://gitpod.io/#https://github.com/go-gitea/gitea)
[![](https://badges.crowdin.net/gitea/localized.svg)](https://translate.gitea.com &quot;Crowdin&quot;)

[繁體中文](./README.zh-tw.md) | [简体中文](./README.zh-cn.md)

## Purpose

The goal of this project is to make the easiest, fastest, and most
painless way of setting up a self-hosted Git service.

As Gitea is written in Go, it works across **all** the platforms and
architectures that are supported by Go, including Linux, macOS, and
Windows on x86, amd64, ARM and PowerPC architectures.
This project has been
[forked](https://blog.gitea.com/welcome-to-gitea/) from
[Gogs](https://gogs.io) since November of 2016, but a lot has changed.

For online demonstrations, you can visit [demo.gitea.com](https://demo.gitea.com).

For accessing free Gitea service (with a limited number of repositories), you can visit [gitea.com](https://gitea.com/user/login).

To quickly deploy your own dedicated Gitea instance on Gitea Cloud, you can start a free trial at [cloud.gitea.com](https://cloud.gitea.com).

## Documentation

You can find comprehensive documentation on our official [documentation website](https://docs.gitea.com/).

It includes installation, administration, usage, development, contributing guides, and more to help you get started and explore all features effectively.

If you have any suggestions or would like to contribute to it, you can visit the [documentation repository](https://gitea.com/gitea/docs)

## Building

From the root of the source tree, run:

    TAGS=&quot;bindata&quot; make build

or if SQLite support is required:

    TAGS=&quot;bindata sqlite sqlite_unlock_notify&quot; make build

The `build` target is split into two sub-targets:

- `make backend` which requires [Go Stable](https://go.dev/dl/), the required version is defined in [go.mod](/go.mod).
- `make frontend` which requires [Node.js LTS](https://nodejs.org/en/download/) or greater and [pnpm](https://pnpm.io/installation).

Internet connectivity is required to download the go and npm modules. When building from the official source tarballs which include pre-built frontend files, the `frontend` target will not be triggered, making it possible to build without Node.js.

More info: https://docs.gitea.com/installation/install-from-source

## Using

After building, a binary file named `gitea` will be generated in the root of the source tree by default. To run it, use:

    ./gitea web

&gt; [!NOTE]
&gt; If you&#039;re interested in using our APIs, we have experimental support with [documentation](https://docs.gitea.com/api).

## Contributing

Expected workflow is: Fork -&gt; Patch -&gt; Push -&gt; Pull Request

&gt; [!NOTE]
&gt;
&gt; 1. **YOU MUST READ THE [CONTRIBUTORS GUIDE](CONTRIBUTING.md) BEFORE STARTING TO WORK ON A PULL REQUEST.**
&gt; 2. If you have found a vulnerability in the project, please write privately to **security@gitea.io**. Thanks!

## Translating

[![Crowdin](https://badges.crowdin.net/gitea/localized.svg)](https://translate.gitea.com)

Translations are done through [Crowdin](https://translate.gitea.com). If you want to translate to a new language, ask one of the managers in the Crowdin project to add a new language there.

You can also just create an issue for adding a language or ask on Discord on the #translation channel. If you need context or find some translation issues, you can leave a comment on the string or ask on Discord. For general translation questions there is a section in the docs. Currently a bit empty, but we hope to fill it as questions pop up.

Get more information from [documentation](https://docs.gitea.com/contributing/localization).

## Official and Third-Party Projects

We provide an official [go-sdk](https://gitea.com/gitea/go-sdk), a CLI tool called [tea](https://gitea.com/gitea/tea) and an [action runner](https://gitea.com/gitea/act_runner) for Gitea Action.

We maintain a list of Gitea-related projects at [gitea/awesome-gitea](https://gitea.com/gitea/awesome-gitea), where you can discover more third-party projects, including SDKs, plugins, themes, and more.

## Communication

[![](https://img.shields.io/discord/322538954119184384.svg?logo=discord&amp;logoColor=white&amp;label=Discord&amp;color=5865F2)](https://discord.gg/Gitea &quot;Join the Discord chat at https://discord.gg/Gitea&quot;)

If you have questions that are not covered by the [documentation](https://docs.gitea.com/), you can get in contact with us on our [Discord server](https://discord.gg/Gitea) or create a post in the [discourse forum](https://forum.gitea.com/).

## Authors

- [Maintainers](https://github.com/orgs/go-gitea/people)
- [Contributors](https://github.com/go-gitea/gitea/graphs/contributors)
- [Translators](options/locale/TRANSLATORS)

## Backers

Thank you to all our backers! 🙏 [[Become a backer](https://opencollective.com/gitea#backer)]

&lt;a href=&quot;https://opencollective.com/gitea#backers&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/backers.svg?width=890&quot;&gt;&lt;/a&gt;

## Sponsors

Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [[Become a sponsor](https://opencollective.com/gitea#sponsor)]

&lt;a href=&quot;https://opencollective.com/gitea/sponsor/0/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/0/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/1/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/1/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/2/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/2/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/3/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/3/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/4/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/4/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/5/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/5/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/6/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/6/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/7/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/7/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/8/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/8/avatar.svg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opencollective.com/gitea/sponsor/9/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/gitea/sponsor/9/avatar.svg&quot;&gt;&lt;/a&gt;

## FAQ

**How do you pronounce Gitea?**

Gitea is pronounced [/ɡɪ’ti:/](https://youtu.be/EM71-2uDAoY) as in &quot;gi-tea&quot; with a hard g.

**Why is this not hosted on a Gitea instance?**

We&#039;re [working on it](https://github.com/go-gitea/gitea/issues/1029).

**Where can I find the security patches?**

In the [release log](https://github.com/go-gitea/gitea/releases) or the [change log](https://github.com/go-gitea/gitea/blob/main/CHANGELOG.md), search for the keyword `SECURITY` to find the security patches.

## License

This project is licensed under the MIT License.
See the [LICENSE](https://github.com/go-gitea/gitea/blob/main/LICENSE) file
for the full license text.

## Further information

&lt;details&gt;
&lt;summary&gt;Looking for an overview of the interface? Check it out!&lt;/summary&gt;

### Login/Register Page

![Login](https://dl.gitea.com/screenshots/login.png)
![Register](https://dl.gitea.com/screenshots/register.png)

### User Dashboard

![Home](https://dl.gitea.com/screenshots/home.png)
![Issues](https://dl.gitea.com/screenshots/issues.png)
![Pull Requests](https://dl.gitea.com/screenshots/pull_requests.png)
![Milestones](https://dl.gitea.com/screenshots/milestones.png)

### User Profile

![Profile](https://dl.gitea.com/screenshots/user_profile.png)

### Explore

![Repos](https://dl.gitea.com/screenshots/explore_repos.png)
![Users](https://dl.gitea.com/screenshots/explore_users.png)
![Orgs](https://dl.gitea.com/screenshots/explore_orgs.png)

### Repository

![Home](https://dl.gitea.com/screenshots/repo_home.png)
![Commits](https://dl.gitea.com/screenshots/repo_commits.png)
![Branches](https://dl.gitea.com/screenshots/repo_branches.png)
![Labels](https://dl.gitea.com/screenshots/repo_labels.png)
![Milestones](https://dl.gitea.com/screenshots/repo_milestones.png)
![Releases](https://dl.gitea.com/screenshots/repo_releases.png)
![Tags](https://dl.gitea.com/screenshots/repo_tags.png)

#### Repository Issue

![List](https://dl.gitea.com/screenshots/repo_issues.png)
![Issue](https://dl.gitea.com/screenshots/repo_issue.png)

#### Repository Pull Requests

![List](https://dl.gitea.com/screenshots/repo_pull_requests.png)
![Pull Request](https://dl.gitea.com/screenshots/repo_pull_request.png)
![File](https://dl.gitea.com/screenshots/repo_pull_request_file.png)
![Commits](https://dl.gitea.com/screenshots/repo_pull_request_commits.png)

#### Repository Actions

![List](https://dl.gitea.com/screenshots/repo_actions.png)
![Details](https://dl.gitea.com/screenshots/repo_actions_run.png)

#### Repository Activity

![Activity](https://dl.gitea.com/screenshots/repo_activity.png)
![Contributors](https://dl.gitea.com/screenshots/repo_contributors.png)
![Code Frequency](https://dl.gitea.com/screenshots/repo_code_frequency.png)
![Recent Commits](https://dl.gitea.com/screenshots/repo_recent_commits.png)

### Organization

![Home](https://dl.gitea.com/screenshots/org_home.png)

&lt;/details&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[aquasecurity/trivy]]></title>
            <link>https://github.com/aquasecurity/trivy</link>
            <guid>https://github.com/aquasecurity/trivy</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aquasecurity/trivy">aquasecurity/trivy</a></h1>
            <p>Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more</p>
            <p>Language: Go</p>
            <p>Stars: 29,298</p>
            <p>Forks: 2,762</p>
            <p>Stars today: 36 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;docs/imgs/logo.png&quot; width=&quot;200&quot;&gt;

[![GitHub Release][release-img]][release]
[![Test][test-img]][test]
[![Go Report Card][go-report-img]][go-report]
[![License: Apache-2.0][license-img]][license]
[![GitHub Downloads][github-downloads-img]][release]
![Docker Pulls][docker-pulls]

[📖 Documentation][docs]
&lt;/div&gt;

Trivy ([pronunciation][pronunciation]) is a comprehensive and versatile security scanner.
Trivy has *scanners* that look for security issues, and *targets* where it can find those issues.

Targets (what Trivy can scan):

- Container Image
- Filesystem
- Git Repository (remote)
- Virtual Machine Image
- Kubernetes

Scanners (what Trivy can find there):

- OS packages and software dependencies in use (SBOM)
- Known vulnerabilities (CVEs)
- IaC issues and misconfigurations
- Sensitive information and secrets
- Software licenses

Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the [Scanning Coverage] page.

To learn more, go to the [Trivy homepage][homepage] for feature highlights, or to the [Documentation site][docs] for detailed information.

## Quick Start

### Get Trivy

Trivy is available in most common distribution channels. The full list of installation options is available in the [Installation] page. Here are a few popular examples:

- `brew install trivy`
- `docker run aquasec/trivy`
- Download binary from &lt;https://github.com/aquasecurity/trivy/releases/latest/&gt;
- See [Installation] for more

Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the [Ecosystem] page. Here are a few popular examples:

- [GitHub Actions](https://github.com/aquasecurity/trivy-action)
- [Kubernetes operator](https://github.com/aquasecurity/trivy-operator)
- [VS Code plugin](https://github.com/aquasecurity/trivy-vscode-extension)
- See [Ecosystem] for more

### Canary builds
There are canary builds ([Docker Hub](https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;name=canary), [GitHub](https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary), [ECR](https://gallery.ecr.aws/aquasecurity/trivy#canary) images and [binaries](https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml)) as generated every push to main branch.

Please be aware: canary builds might have critical bugs, it&#039;s not recommended for use in production.

### General usage

```bash
trivy &lt;target&gt; [--scanners &lt;scanner1,scanner2&gt;] &lt;subject&gt;
```

Examples:

```bash
trivy image python:3.4-alpine
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov

&lt;/details&gt;

```bash
trivy fs --scanners vuln,secret,misconfig myproject/
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov

&lt;/details&gt;

```bash
trivy k8s --report summary cluster
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

![k8s summary](docs/imgs/trivy-k8s.png)

&lt;/details&gt;

## FAQ

### How to pronounce the name &quot;Trivy&quot;?

`tri` is pronounced like **tri**gger, `vy` is pronounced like en**vy**.

## Want more? Check out Aqua

If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.  
You can find a high level comparison table specific to Trivy users [here](https://trivy.dev/latest/commercial/compare/).
In addition check out the &lt;https://aquasec.com&gt; website for more information about our products and services.
If you&#039;d like to contact Aqua or request a demo, please use this form: &lt;https://www.aquasec.com/demo&gt;

## Community

Trivy is an [Aqua Security][aquasec] open source project.  
Learn about our open source work and portfolio [here][oss].  
Contact us about any matter by opening a GitHub Discussion [here][discussions]

Please ensure to abide by our [Code of Conduct][code-of-conduct] during all interactions.

[test]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml
[test-img]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg
[go-report]: https://goreportcard.com/report/github.com/aquasecurity/trivy
[go-report-img]: https://goreportcard.com/badge/github.com/aquasecurity/trivy
[release]: https://github.com/aquasecurity/trivy/releases
[release-img]: https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github
[github-downloads-img]: https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github
[docker-pulls]: https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;label=docker%20pulls%20%2F%20trivy
[license]: https://github.com/aquasecurity/trivy/blob/main/LICENSE
[license-img]: https://img.shields.io/badge/License-Apache%202.0-blue.svg
[homepage]: https://trivy.dev
[docs]: https://trivy.dev/latest/docs/
[pronunciation]: #how-to-pronounce-the-name-trivy
[code-of-conduct]: https://github.com/aquasecurity/community/blob/main/CODE_OF_CONDUCT.md

[Installation]:https://trivy.dev/latest/getting-started/installation/
[Ecosystem]: https://trivy.dev/latest/ecosystem/
[Scanning Coverage]: https://trivy.dev/latest/docs/coverage/

[alpine]: https://ariadne.space/2021/06/08/the-vulnerability-remediation-lifecycle-of-alpine-containers/
[rego]: https://www.openpolicyagent.org/docs/latest/#rego
[sigstore]: https://www.sigstore.dev/

[aquasec]: https://aquasec.com
[oss]: https://www.aquasec.com/products/open-source-projects/
[discussions]: https://github.com/aquasecurity/trivy/discussions
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ava-labs/avalanchego]]></title>
            <link>https://github.com/ava-labs/avalanchego</link>
            <guid>https://github.com/ava-labs/avalanchego</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[Go implementation of an Avalanche node.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ava-labs/avalanchego">ava-labs/avalanchego</a></h1>
            <p>Go implementation of an Avalanche node.</p>
            <p>Language: Go</p>
            <p>Stars: 2,295</p>
            <p>Forks: 807</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;resources/AvalancheLogoRed.png?raw=true&quot;&gt;
&lt;/div&gt;

---

Node implementation for the [Avalanche](https://avax.network) network -
a blockchains platform with high throughput, and blazing fast transactions.

## Installation

Avalanche is an incredibly lightweight protocol, so the minimum computer requirements are quite modest.
Note that as network usage increases, hardware requirements may change.

The minimum recommended hardware specification for nodes connected to Mainnet is:

- CPU: Equivalent of 8 AWS vCPU
- RAM: 16 GiB
- Storage: 1 TiB
  - Nodes running for very long periods of time or nodes with custom configurations may observe higher storage requirements.
- OS: Ubuntu 22.04/24.04 or macOS &gt;= 12
- Network: Reliable IPv4 or IPv6 network connection, with an open public port.

If you plan to build AvalancheGo from source, you will also need the following software:

- [Go](https://golang.org/doc/install) version &gt;= 1.24.7
- [gcc](https://gcc.gnu.org/)
- g++

### Building From Source

#### Clone The Repository

Clone the AvalancheGo repository:

```sh
git clone git@github.com:ava-labs/avalanchego.git
cd avalanchego
```

This will clone and checkout the `master` branch.

#### Building AvalancheGo

Build AvalancheGo by running the build task:

```sh
./scripts/run_task.sh build
```

The `avalanchego` binary is now in the `build` directory. To run:

```sh
./build/avalanchego
```

### Binary Repository

Install AvalancheGo using an `apt` repository.

#### Adding the APT Repository

If you already have the APT repository added, you do not need to add it again.

To add the repository on Ubuntu, run:

```sh
sudo su -
wget -qO - https://downloads.avax.network/avalanchego.gpg.key | tee /etc/apt/trusted.gpg.d/avalanchego.asc
source /etc/os-release &amp;&amp; echo &quot;deb https://downloads.avax.network/apt $UBUNTU_CODENAME main&quot; &gt; /etc/apt/sources.list.d/avalanche.list
exit
```

#### Installing the Latest Version

After adding the APT repository, install `avalanchego` by running:

```sh
sudo apt update
sudo apt install avalanchego
```

### Binary Install

Download the [latest build](https://github.com/ava-labs/avalanchego/releases/latest) for your operating system and architecture.

The Avalanche binary to be executed is named `avalanchego`.

### Docker Install

Make sure Docker is installed on the machine - so commands like `docker run` etc. are available.

Building the Docker image of latest `avalanchego` branch can be done by running:

```sh
./scripts/run-task.sh build-image
```

To check the built image, run:

```sh
docker image ls
```

The image should be tagged as `avaplatform/avalanchego:xxxxxxxx`, where `xxxxxxxx` is the shortened commit of the Avalanche source it was built from. To run the Avalanche node, run:

```sh
docker run -ti -p 9650:9650 -p 9651:9651 avaplatform/avalanchego:xxxxxxxx /avalanchego/build/avalanchego
```

## Running Avalanche

### Connecting to Mainnet

To connect to the Avalanche Mainnet, run:

```sh
./build/avalanchego
```

You should see some pretty ASCII art and log messages.

You can use `Ctrl+C` to kill the node.

### Connecting to Fuji

To connect to the Fuji Testnet, run:

```sh
./build/avalanchego --network-id=fuji
```

### Creating a Local Testnet

The [avalanche-cli](https://github.com/ava-labs/avalanche-cli) is the easiest way to start a local network.

```sh
avalanche network start
avalanche network status
```

## Bootstrapping

A node needs to catch up to the latest network state before it can participate in consensus and serve API calls. This process (called bootstrapping) currently takes several days for a new node connected to Mainnet.

A node will not [report healthy](https://build.avax.network/docs/api-reference/health-api) until it is done bootstrapping.

Improvements that reduce the amount of time it takes to bootstrap are under development.

The bottleneck during bootstrapping is typically database IO. Using a more powerful CPU or increasing the database IOPS on the computer running a node will decrease the amount of time bootstrapping takes.

## Generating Code

AvalancheGo uses multiple tools to generate efficient and boilerplate code.

### Running protobuf codegen

To regenerate the protobuf go code, run `scripts/run-task.sh generate-protobuf` from the root of the repo.

This should only be necessary when upgrading protobuf versions or modifying .proto definition files.

To use this script, you must have [buf](https://docs.buf.build/installation) (v1.31.0), protoc-gen-go (v1.33.0) and protoc-gen-go-grpc (v1.3.0) installed.

To install the buf dependencies:

```sh
go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.33.0
go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.3.0
```

If you have not already, you may need to add `$GOPATH/bin` to your `$PATH`:

```sh
export PATH=&quot;$PATH:$(go env GOPATH)/bin&quot;
```

If you extract buf to ~/software/buf/bin, the following should work:

```sh
export PATH=$PATH:~/software/buf/bin/:~/go/bin
go get google.golang.org/protobuf/cmd/protoc-gen-go
go get google.golang.org/protobuf/cmd/protoc-gen-go-grpc
scripts/run_task.sh generate-protobuf
```

For more information, refer to the [GRPC Golang Quick Start Guide](https://grpc.io/docs/languages/go/quickstart/).

### Running mock codegen

See [the Contributing document autogenerated mocks section](CONTRIBUTING.md####Autogenerated-mocks).

## Versioning

### Version Semantics

AvalancheGo is first and foremost a client for the Avalanche network. The versioning of AvalancheGo follows that of the Avalanche network.

- `v0.x.x` indicates a development network version.
- `v1.x.x` indicates a production network version.
- `vx.[Upgrade].x` indicates the number of network upgrades that have occurred.
- `vx.x.[Patch]` indicates the number of client upgrades that have occurred since the last network upgrade.

### Library Compatibility Guarantees

Because AvalancheGo&#039;s version denotes the network version, it is expected that interfaces exported by AvalancheGo&#039;s packages may change in `Patch` version updates.

### API Compatibility Guarantees

APIs exposed when running AvalancheGo will maintain backwards compatibility, unless the functionality is explicitly deprecated and announced when removed.

## Supported Platforms

AvalancheGo can run on different platforms, with different support tiers:

- **Tier 1**: Fully supported by the maintainers, guaranteed to pass all tests including e2e and stress tests.
- **Tier 2**: Passes all unit and integration tests but not necessarily e2e tests.
- **Tier 3**: Builds but lightly tested (or not), considered _experimental_.
- **Not supported**: May not build and not tested, considered _unsafe_. To be supported in the future.

The following table lists currently supported platforms and their corresponding
AvalancheGo support tiers:

| Architecture | Operating system | Support tier  |
| :----------: | :--------------: | :-----------: |
|    amd64     |      Linux       |       1       |
|    arm64     |      Linux       |       2       |
|    amd64     |      Darwin      |       2       |
|    amd64     |     Windows      | Not supported |
|     arm      |      Linux       | Not supported |
|     i386     |      Linux       | Not supported |
|    arm64     |      Darwin      | Not supported |

To officially support a new platform, one must satisfy the following requirements:

| AvalancheGo continuous integration | Tier 1  | Tier 2  | Tier 3  |
| ---------------------------------- | :-----: | :-----: | :-----: |
| Build passes                       | &amp;check; | &amp;check; | &amp;check; |
| Unit and integration tests pass    | &amp;check; | &amp;check; |         |
| End-to-end and stress tests pass   | &amp;check; |         |         |

## Security Bugs

**We and our community welcome responsible disclosures.**

Please refer to our [Security Policy](SECURITY.md) and [Security Advisories](https://github.com/ava-labs/avalanchego/security/advisories).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[modelcontextprotocol/go-sdk]]></title>
            <link>https://github.com/modelcontextprotocol/go-sdk</link>
            <guid>https://github.com/modelcontextprotocol/go-sdk</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[The official Go SDK for Model Context Protocol servers and clients. Maintained in collaboration with Google.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/modelcontextprotocol/go-sdk">modelcontextprotocol/go-sdk</a></h1>
            <p>The official Go SDK for Model Context Protocol servers and clients. Maintained in collaboration with Google.</p>
            <p>Language: Go</p>
            <p>Stars: 2,325</p>
            <p>Forks: 205</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>&lt;!-- Autogenerated by weave; DO NOT EDIT --&gt;
# MCP Go SDK

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/modelcontextprotocol/go-sdk)

[![PkgGoDev](https://pkg.go.dev/badge/github.com/modelcontextprotocol/go-sdk)](https://pkg.go.dev/github.com/modelcontextprotocol/go-sdk)

This repository contains an implementation of the official Go software
development kit (SDK) for the Model Context Protocol (MCP).

## Package / Feature documentation

The SDK consists of several importable packages:

- The
  [`github.com/modelcontextprotocol/go-sdk/mcp`](https://pkg.go.dev/github.com/modelcontextprotocol/go-sdk/mcp)
  package defines the primary APIs for constructing and using MCP clients and
  servers.
- The
  [`github.com/modelcontextprotocol/go-sdk/jsonrpc`](https://pkg.go.dev/github.com/modelcontextprotocol/go-sdk/jsonrpc) package is for users implementing
  their own transports.
- The
  [`github.com/modelcontextprotocol/go-sdk/auth`](https://pkg.go.dev/github.com/modelcontextprotocol/go-sdk/auth)
  package provides some primitives for supporting OAuth.
- The
  [`github.com/modelcontextprotocol/go-sdk/oauthex`](https://pkg.go.dev/github.com/modelcontextprotocol/go-sdk/oauthex)
  package provides extensions to the OAuth protocol, such as ProtectedResourceMetadata.

The SDK endeavors to implement the full MCP spec. The [`docs/`](/docs/) directory
contains feature documentation, mapping the MCP spec to the packages above.

## Getting started

To get started creating an MCP server, create an `mcp.Server` instance, add
features to it, and then run it over an `mcp.Transport`. For example, this
server adds a single simple tool, and then connects it to clients over
stdin/stdout:

```go
package main

import (
	&quot;context&quot;
	&quot;log&quot;

	&quot;github.com/modelcontextprotocol/go-sdk/mcp&quot;
)

type Input struct {
	Name string `json:&quot;name&quot; jsonschema:&quot;the name of the person to greet&quot;`
}

type Output struct {
	Greeting string `json:&quot;greeting&quot; jsonschema:&quot;the greeting to tell to the user&quot;`
}

func SayHi(ctx context.Context, req *mcp.CallToolRequest, input Input) (
	*mcp.CallToolResult,
	Output,
	error,
) {
	return nil, Output{Greeting: &quot;Hi &quot; + input.Name}, nil
}

func main() {
	// Create a server with a single tool.
	server := mcp.NewServer(&amp;mcp.Implementation{Name: &quot;greeter&quot;, Version: &quot;v1.0.0&quot;}, nil)
	mcp.AddTool(server, &amp;mcp.Tool{Name: &quot;greet&quot;, Description: &quot;say hi&quot;}, SayHi)
	// Run the server over stdin/stdout, until the client disconnects.
	if err := server.Run(context.Background(), &amp;mcp.StdioTransport{}); err != nil {
		log.Fatal(err)
	}
}
```

To communicate with that server, create an `mcp.Client` and connect it to the
corresponding server, by running the server command and communicating over its
stdin/stdout:

```go
package main

import (
	&quot;context&quot;
	&quot;log&quot;
	&quot;os/exec&quot;

	&quot;github.com/modelcontextprotocol/go-sdk/mcp&quot;
)

func main() {
	ctx := context.Background()

	// Create a new client, with no features.
	client := mcp.NewClient(&amp;mcp.Implementation{Name: &quot;mcp-client&quot;, Version: &quot;v1.0.0&quot;}, nil)

	// Connect to a server over stdin/stdout.
	transport := &amp;mcp.CommandTransport{Command: exec.Command(&quot;myserver&quot;)}
	session, err := client.Connect(ctx, transport, nil)
	if err != nil {
		log.Fatal(err)
	}
	defer session.Close()

	// Call a tool on the server.
	params := &amp;mcp.CallToolParams{
		Name:      &quot;greet&quot;,
		Arguments: map[string]any{&quot;name&quot;: &quot;you&quot;},
	}
	res, err := session.CallTool(ctx, params)
	if err != nil {
		log.Fatalf(&quot;CallTool failed: %v&quot;, err)
	}
	if res.IsError {
		log.Fatal(&quot;tool failed&quot;)
	}
	for _, c := range res.Content {
		log.Print(c.(*mcp.TextContent).Text)
	}
}
```

The [`examples/`](/examples/) directory contains more example clients and
servers.

## Contributing

We welcome contributions to the SDK! Please see See
[CONTRIBUTING.md](/CONTRIBUTING.md) for details of how to contribute.

## Acknowledgements / Alternatives

Several third party Go MCP SDKs inspired the development and design of this
official SDK, and continue to be viable alternatives, notably
[mcp-go](https://github.com/mark3labs/mcp-go), originally authored by Ed Zynda.
We are grateful to Ed as well as the other contributors to mcp-go, and to
authors and contributors of other SDKs such as
[mcp-golang](https://github.com/metoro-io/mcp-golang) and
[go-mcp](https://github.com/ThinkInAIXYZ/go-mcp). Thanks to their work, there
is a thriving ecosystem of Go MCP clients and servers.

## License

This project is licensed under the MIT License - see the [LICENSE](./LICENSE)
file for details.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[googleapis/genai-toolbox]]></title>
            <link>https://github.com/googleapis/genai-toolbox</link>
            <guid>https://github.com/googleapis/genai-toolbox</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[MCP Toolbox for Databases is an open source MCP server for databases.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/googleapis/genai-toolbox">googleapis/genai-toolbox</a></h1>
            <p>MCP Toolbox for Databases is an open source MCP server for databases.</p>
            <p>Language: Go</p>
            <p>Stars: 10,799</p>
            <p>Forks: 885</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>![logo](./logo.png)

# MCP Toolbox for Databases

[![Docs](https://img.shields.io/badge/docs-MCP_Toolbox-blue)](https://googleapis.github.io/genai-toolbox/)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=flat&amp;logo=discord&amp;logoColor=white)](https://discord.gg/Dmm69peqjh)
[![Medium](https://img.shields.io/badge/Medium-12100E?style=flat&amp;logo=medium&amp;logoColor=white)](https://medium.com/@mcp_toolbox)
[![Go Report Card](https://goreportcard.com/badge/github.com/googleapis/genai-toolbox)](https://goreportcard.com/report/github.com/googleapis/genai-toolbox)

&gt; [!NOTE]
&gt; MCP Toolbox for Databases is currently in beta, and may see breaking
&gt; changes until the first stable release (v1.0).

MCP Toolbox for Databases is an open source MCP server for databases. It enables
you to develop tools easier, faster, and more securely by handling the complexities
such as connection pooling, authentication, and more.

This README provides a brief overview. For comprehensive details, see the [full
documentation](https://googleapis.github.io/genai-toolbox/).

&gt; [!NOTE]
&gt; This solution was originally named “Gen AI Toolbox for Databases” as
&gt; its initial development predated MCP, but was renamed to align with recently
&gt; added MCP compatibility.

&lt;!-- TOC ignore:true --&gt;
## Table of Contents

&lt;!-- TOC --&gt;

- [Why Toolbox?](#why-toolbox)
- [General Architecture](#general-architecture)
- [Getting Started](#getting-started)
  - [Installing the server](#installing-the-server)
  - [Running the server](#running-the-server)
  - [Integrating your application](#integrating-your-application)
- [Configuration](#configuration)
  - [Sources](#sources)
  - [Tools](#tools)
  - [Toolsets](#toolsets)
- [Versioning](#versioning)
  - [Pre-1.0.0 Versioning](#pre-100-versioning)
  - [Post-1.0.0 Versioning](#post-100-versioning)
- [Contributing](#contributing)
- [Community](#community)

&lt;!-- /TOC --&gt;

## Why Toolbox?

Toolbox helps you build Gen AI tools that let your agents access data in your
database. Toolbox provides:

- **Simplified development**: Integrate tools to your agent in less than 10
  lines of code, reuse tools between multiple agents or frameworks, and deploy
  new versions of tools more easily.
- **Better performance**: Best practices such as connection pooling,
  authentication, and more.
- **Enhanced security**: Integrated auth for more secure access to your data
- **End-to-end observability**: Out of the box metrics and tracing with built-in
  support for OpenTelemetry.

**⚡ Supercharge Your Workflow with an AI Database Assistant ⚡**

Stop context-switching and let your AI assistant become a true co-developer. By
[connecting your IDE to your databases with MCP Toolbox][connect-ide], you can
delegate complex and time-consuming database tasks, allowing you to build faster
and focus on what matters. This isn&#039;t just about code completion; it&#039;s about
giving your AI the context it needs to handle the entire development lifecycle.

Here’s how it will save you time:

- **Query in Plain English**: Interact with your data using natural language
  right from your IDE. Ask complex questions like, *&quot;How many orders were
  delivered in 2024, and what items were in them?&quot;* without writing any SQL.
- **Automate Database Management**: Simply describe your data needs, and let the
  AI assistant manage your database for you. It can handle generating queries,
  creating tables, adding indexes, and more.
- **Generate Context-Aware Code**: Empower your AI assistant to generate
  application code and tests with a deep understanding of your real-time
  database schema.  This accelerates the development cycle by ensuring the
  generated code is directly usable.
- **Slash Development Overhead**: Radically reduce the time spent on manual
  setup and boilerplate. MCP Toolbox helps streamline lengthy database
  configurations, repetitive code, and error-prone schema migrations.

Learn [how to connect your AI tools (IDEs) to Toolbox using MCP][connect-ide].

[connect-ide]: https://googleapis.github.io/genai-toolbox/how-to/connect-ide/

## General Architecture

Toolbox sits between your application&#039;s orchestration framework and your
database, providing a control plane that is used to modify, distribute, or
invoke tools. It simplifies the management of your tools by providing you with a
centralized location to store and update tools, allowing you to share tools
between agents and applications and update those tools without necessarily
redeploying your application.

![architecture](./docs/en/getting-started/introduction/architecture.png)

## Getting Started

### Installing the server

For the latest version, check the [releases page][releases] and use the
following instructions for your OS and CPU architecture.

[releases]: https://github.com/googleapis/genai-toolbox/releases

&lt;details open&gt;
&lt;summary&gt;Binary&lt;/summary&gt;

To install Toolbox as a binary:

&lt;!-- {x-release-please-start-version} --&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;Linux (AMD64)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on Linux (AMD64):
&gt; ```sh
&gt; # see releases page for other versions
&gt; export VERSION=0.16.0
&gt; curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/linux/amd64/toolbox
&gt; chmod +x toolbox
&gt; ```
&gt;
&gt; &lt;/details&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;macOS (Apple Silicon)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on macOS (Apple Silicon):
&gt; ```sh
&gt; # see releases page for other versions
&gt; export VERSION=0.16.0
&gt; curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/darwin/arm64/toolbox
&gt; chmod +x toolbox
&gt; ```
&gt;
&gt; &lt;/details&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;macOS (Intel)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on macOS (Intel):
&gt; ```sh
&gt; # see releases page for other versions
&gt; export VERSION=0.16.0
&gt; curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/darwin/amd64/toolbox
&gt; chmod +x toolbox
&gt; ```
&gt;
&gt; &lt;/details&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;Windows (AMD64)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on Windows (AMD64):
&gt; ```powershell
&gt; # see releases page for other versions
&gt; $VERSION = &quot;0.16.0&quot;
&gt; Invoke-WebRequest -Uri &quot;https://storage.googleapis.com/genai-toolbox/v$VERSION/windows/amd64/toolbox.exe&quot; -OutFile &quot;toolbox.exe&quot;
&gt; ```
&gt;
&gt; &lt;/details&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Container image&lt;/summary&gt;
You can also install Toolbox as a container:

```sh
# see releases page for other versions
export VERSION=0.16.0
docker pull us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Homebrew&lt;/summary&gt;

To install Toolbox using Homebrew on macOS or Linux:

```sh
brew install mcp-toolbox
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Compile from source&lt;/summary&gt;

To install from source, ensure you have the latest version of
[Go installed](https://go.dev/doc/install), and then run the following command:

```sh
go install github.com/googleapis/genai-toolbox@v0.16.0
```
&lt;!-- {x-release-please-end} --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Gemini CLI Extensions&lt;/summary&gt;

To install Gemini CLI Extensions for MCP Toolbox, run the following command:

```sh
gemini extensions install https://github.com/gemini-cli-extensions/mcp-toolbox
```

&lt;/details&gt;

### Running the server

[Configure](#configuration) a `tools.yaml` to define your tools, and then
execute `toolbox` to start the server:

&lt;details open&gt;
&lt;summary&gt;Binary&lt;/summary&gt;

To run Toolbox from binary:

```sh
./toolbox --tools-file &quot;tools.yaml&quot;
```

ⓘ **NOTE:**  
Toolbox enables dynamic reloading by default. To disable, use the
`--disable-reload` flag.

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Container image&lt;/summary&gt;

To run the server after pulling the [container image](#installing-the-server):

```sh
export VERSION=0.11.0 # Use the version you pulled
docker run -p 5000:5000 \
-v $(pwd)/tools.yaml:/app/tools.yaml \
us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION \
--tools-file &quot;/app/tools.yaml&quot;
```

ⓘ **NOTE:**  
The `-v` flag mounts your local `tools.yaml` into the container, and `-p` maps
the container&#039;s port `5000` to your host&#039;s port `5000`.

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Source&lt;/summary&gt;

To run the server directly from source, navigate to the project root directory
and run:

```sh
go run .
```

ⓘ **NOTE:**  
This command runs the project from source, and is more suitable for development
and testing. It does **not** compile a binary into your `$GOPATH`. If you want
to compile a binary instead, refer the [Developer
Documentation](./DEVELOPER.md#building-the-binary).

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Homebrew&lt;/summary&gt;

If you installed Toolbox using [Homebrew](https://brew.sh/), the `toolbox`
binary is available in your system path. You can start the server with the same
command:

```sh
toolbox --tools-file &quot;tools.yaml&quot;
```

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Gemini CLI&lt;/summary&gt;

Interact with your custom tools using natural language. Check
[gemini-cli-extensions/mcp-toolbox](https://github.com/gemini-cli-extensions/mcp-toolbox)
for more information.

&lt;/details&gt;

You can use `toolbox help` for a full list of flags! To stop the server, send a
terminate signal (`ctrl+c` on most platforms).

For more detailed documentation on deploying to different environments, check
out the resources in the [How-to
section](https://googleapis.github.io/genai-toolbox/how-to/)

### Integrating your application

Once your server is up and running, you can load the tools into your
application. See below the list of Client SDKs for using various frameworks:

&lt;details open&gt;
  &lt;summary&gt;Python (&lt;a href=&quot;https://github.com/googleapis/mcp-toolbox-sdk-python&quot;&gt;Github&lt;/a&gt;)&lt;/summary&gt;
  &lt;br&gt;
  &lt;blockquote&gt;

  &lt;details open&gt;
    &lt;summary&gt;Core&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core]:

    ```bash
    pip install toolbox-core
    ```

1. Load tools:

    ```python
    from toolbox_core import ToolboxClient

    # update the url to point to your server
    async with ToolboxClient(&quot;http://127.0.0.1:5000&quot;) as client:

        # these tools can be passed to your application!
        tools = await client.load_toolset(&quot;toolset_name&quot;)
    ```

For more detailed instructions on using the Toolbox Core SDK, see the
[project&#039;s README][toolbox-core-readme].

[toolbox-core]: https://pypi.org/project/toolbox-core/
[toolbox-core-readme]: https://github.com/googleapis/mcp-toolbox-sdk-python/tree/main/packages/toolbox-core/README.md

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;LangChain / LangGraph&lt;/summary&gt;

1. Install [Toolbox LangChain SDK][toolbox-langchain]:

    ```bash
    pip install toolbox-langchain
    ```

1. Load tools:

    ```python
    from toolbox_langchain import ToolboxClient

    # update the url to point to your server
    async with ToolboxClient(&quot;http://127.0.0.1:5000&quot;) as client:

        # these tools can be passed to your application!
        tools = client.load_toolset()
    ```

    For more detailed instructions on using the Toolbox LangChain SDK, see the
    [project&#039;s README][toolbox-langchain-readme].

    [toolbox-langchain]: https://pypi.org/project/toolbox-langchain/
    [toolbox-langchain-readme]: https://github.com/googleapis/mcp-toolbox-sdk-python/blob/main/packages/toolbox-langchain/README.md

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;LlamaIndex&lt;/summary&gt;

1. Install [Toolbox Llamaindex SDK][toolbox-llamaindex]:

    ```bash
    pip install toolbox-llamaindex
    ```

1. Load tools:

    ```python
    from toolbox_llamaindex import ToolboxClient

    # update the url to point to your server
    async with ToolboxClient(&quot;http://127.0.0.1:5000&quot;) as client:

        # these tools can be passed to your application!
        tools = client.load_toolset()
    ```

    For more detailed instructions on using the Toolbox Llamaindex SDK, see the
    [project&#039;s README][toolbox-llamaindex-readme].

    [toolbox-llamaindex]: https://pypi.org/project/toolbox-llamaindex/
    [toolbox-llamaindex-readme]: https://github.com/googleapis/genai-toolbox-llamaindex-python/blob/main/README.md

  &lt;/details&gt;
&lt;/details&gt;
&lt;/blockquote&gt;
&lt;details&gt;
  &lt;summary&gt;Javascript/Typescript (&lt;a href=&quot;https://github.com/googleapis/mcp-toolbox-sdk-js&quot;&gt;Github&lt;/a&gt;)&lt;/summary&gt;
  &lt;br&gt;
  &lt;blockquote&gt;

  &lt;details open&gt;
    &lt;summary&gt;Core&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core-js]:

    ```bash
    npm install @toolbox-sdk/core
    ```

1. Load tools:

    ```javascript
    import { ToolboxClient } from &#039;@toolbox-sdk/core&#039;;

    // update the url to point to your server
    const URL = &#039;http://127.0.0.1:5000&#039;;
    let client = new ToolboxClient(URL);

    // these tools can be passed to your application!
    const tools = await client.loadToolset(&#039;toolsetName&#039;);
    ```

    For more detailed instructions on using the Toolbox Core SDK, see the
    [project&#039;s README][toolbox-core-js-readme].

    [toolbox-core-js]: https://www.npmjs.com/package/@toolbox-sdk/core
    [toolbox-core-js-readme]: https://github.com/googleapis/mcp-toolbox-sdk-js/blob/main/packages/toolbox-core/README.md

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;LangChain / LangGraph&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core-js]:

    ```bash
    npm install @toolbox-sdk/core
    ```

2. Load tools:

    ```javascript
    import { ToolboxClient } from &#039;@toolbox-sdk/core&#039;;

    // update the url to point to your server
    const URL = &#039;http://127.0.0.1:5000&#039;;
    let client = new ToolboxClient(URL);

    // these tools can be passed to your application!
    const toolboxTools = await client.loadToolset(&#039;toolsetName&#039;);

    // Define the basics of the tool: name, description, schema and core logic
    const getTool = (toolboxTool) =&gt; tool(currTool, {
        name: toolboxTool.getName(),
        description: toolboxTool.getDescription(),
        schema: toolboxTool.getParamSchema()
    });

    // Use these tools in your Langchain/Langraph applications
    const tools = toolboxTools.map(getTool);
    ```

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;Genkit&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core-js]:

    ```bash
    npm install @toolbox-sdk/core
    ```

2. Load tools:

    ```javascript
    import { ToolboxClient } from &#039;@toolbox-sdk/core&#039;;
    import { genkit } from &#039;genkit&#039;;

    // Initialise genkit
    const ai = genkit({
        plugins: [
            googleAI({
                apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY
            })
        ],
        model: googleAI.model(&#039;gemini-2.0-flash&#039;),
    });

    // update the url to point to your server
    const URL = &#039;http://127.0.0.1:5000&#039;;
    let client = new ToolboxClient(URL);

    // these tools can be passed to your application!
    const toolboxTools = await client.loadToolset(&#039;toolsetName&#039;);

    // Define the basics of the tool: name, description, schema and core logic
    const getTool = (toolboxTool) =&gt; ai.defineTool({
        name: toolboxTool.getName(),
        description: toolboxTool.getDescription(),
        schema: toolboxTool.getParamSchema()
    }, toolboxTool)

    // Use these tools in your Genkit applications
    const tools = toolboxTools.map(getTool);
    ```

  &lt;/details&gt;
&lt;/details&gt;
&lt;/blockquote&gt;
&lt;details&gt;
  &lt;summary&gt;Go (&lt;a href=&quot;https://github.com/googleapis/mcp-toolbox-sdk-go&quot;&gt;Github&lt;/a&gt;)&lt;/summary&gt;
  &lt;br&gt;
  &lt;blockquote&gt;

  &lt;details open&gt;
    &lt;summary&gt;Core&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

1. Load tools:

    ```go
    package main

    import (
      &quot;github.com/googleapis/mcp-toolbox-sdk-go/core&quot;
      &quot;context&quot;
    )

    func main() {
      // Make sure to add the error checks
      // update the url to point to your server
      URL := &quot;http://127.0.0.1:5000&quot;;
      ctx := context.Background()

      client, err := core.NewToolboxClient(URL)

      // Framework agnostic tools
      tools, err := client.LoadToolset(&quot;toolsetName&quot;, ctx)
    }
    ```

    For more detailed instructions on using the Toolbox Go SDK, see the
    [project&#039;s README][toolbox-core-go-readme].

    [toolbox-go]: https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core
    [toolbox-core-go-readme]: https://github.com/googleapis/mcp-toolbox-sdk-go/blob/main/core/README.md

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;LangChain Go&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

2. Load tools:

    ```go
    package main

    import (
      &quot;context&quot;
      &quot;encoding/json&quot;

      &quot;github.com/googleapis/mcp-toolbox-sdk-go/core&quot;
      &quot;github.com/tmc/langchaingo/llms&quot;
    )

    func main() {
      // Make sure to add the error checks
      // update the url to point to your server
      URL := &quot;http://127.0.0.1:5000&quot;
      ctx := context.Background()

      client, err := core.NewToolboxClient(URL)

      // Framework agnostic tool
      tool, err := client.LoadTool(&quot;toolName&quot;, ctx)

      // Fetch the tool&#039;s input schema
      inputschema, err := tool.InputSchema()

      var paramsSchema map[string]any
      _ = json.Unmarshal(inputschema, &amp;paramsSchema)

      // Use this tool with LangChainGo
      langChainTool := llms.Tool{
        Type: &quot;function&quot;,
        Function: &amp;llms.FunctionDefinition{
          Name:        tool.Name(),
          Description: tool.Description(),
          Parameters:  paramsSchema,
        },
      }
    }

    ```

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;Genkit&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

2. Load tools:

    ```go
    package main
    import (
      &quot;context&quot;
      &quot;encoding/json&quot;

      &quot;github.com/firebase/genkit/go/ai&quot;
      &quot;github.com/firebase/genkit/go/genkit&quot;
      &quot;github.com/googleapis/mcp-toolbox-sdk-go/core&quot;
      &quot;github.com/googleapis/mcp-toolbox-sdk-go/tbgenkit&quot;
      &quot;github.com/invopop/jsonschema&quot;
    )

    func main() {
      // Make sure to add the error checks
      // Update the url to point to your server
      URL := &quot;http://127.0.0.1:5000&quot;
      ctx := context.Background()
      g, err := genkit.Init(ctx)

      client, err := core.NewToolboxClient(URL)

      // Framework agnostic tool
      tool, err := client.LoadTool(&quot;toolName&quot;, ctx)

      // Convert the tool using the tbgenkit package
      // Use this tool with Genkit Go
      genkitTool, err := tbgenkit.ToGenkitTool(tool, g)
      if err != nil {
        log.Fatalf(&quot;Failed to convert tool: %v\n&quot;, err)
      }
    }
    ```

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;Go GenAI&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

2. Load tools:

    ```go
    package main

    import (
      &quot;context&quot;
      &quot;encoding/json&quot;

      &quot;github.com/googleapis/mcp-toolbox-sdk-go/core&quot;
      &quot;google.golang.org/genai&quot;
    )

    func main() {
      // Make sure to add the error checks
      // Update the url to point to your server
      URL := &quot;http://127.0.0.1:5000&quot;
      ctx := context.Background()

      client, err := core.NewToolboxClient(URL)

      // Framework agnostic tool
      tool, err := client.LoadTool(&quot;toolName&quot;, ctx)

      // Fetch the tool&#039;s input schema
      inputschema, err := tool.InputSchema()

      var schema *genai.Schema
      _ = json.Unmarshal(inputschema, &amp;schema)

      funcDeclaration := &amp;genai.FunctionDeclaration{
        Name:        tool.Name(),
        Description: tool.Description(),
        Parameters:  schema,
      }

      // Use this tool with Go GenAI
      genAITool := &amp;genai.Tool{
        FunctionDeclarations: []*genai.FunctionDeclaration{funcDeclaration},
      }
    }
    ```

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;OpenAI Go&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

2. Load tools:

    ```go
    package main

    import (
      &quot;context&quot;
      &quot;encoding/json&quot;

      &quot;github.com/googleapis/mcp-toolbox-sdk-go/core&quot;
      openai &quot;github.com/openai/openai-go&quot;
    )

    func main() {
      // Make sure to add

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[NVIDIA/gpu-operator]]></title>
            <link>https://github.com/NVIDIA/gpu-operator</link>
            <guid>https://github.com/NVIDIA/gpu-operator</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[NVIDIA GPU Operator creates, configures, and manages GPUs in Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NVIDIA/gpu-operator">NVIDIA/gpu-operator</a></h1>
            <p>NVIDIA GPU Operator creates, configures, and manages GPUs in Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 2,328</p>
            <p>Forks: 389</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>[![license](https://img.shields.io/github/license/NVIDIA/gpu-operator?style=flat-square)](https://raw.githubusercontent.com/NVIDIA/gpu-operator/master/LICENSE)
[![pipeline status](https://gitlab.com/nvidia/kubernetes/gpu-operator/badges/master/pipeline.svg)](https://gitlab.com/nvidia/kubernetes/gpu-operator/-/pipelines)
[![coverage report](https://gitlab.com/nvidia/kubernetes/gpu-operator/badges/master/coverage.svg)](https://gitlab.com/nvidia/kubernetes/gpu-operator/-/pipelines)

# NVIDIA GPU Operator

![nvidia-gpu-operator](https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/egx/nvidia-egx-platform-gold-image-full-2c50-d@2x.jpg)

Kubernetes provides access to special hardware resources such as NVIDIA GPUs, NICs, Infiniband adapters and other devices through the [device plugin framework](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/). However, configuring and managing nodes with these hardware resources requires configuration of multiple software components such as drivers, container runtimes or other libraries which  are difficult and prone to errors.
The NVIDIA GPU Operator uses the [operator framework](https://cloud.redhat.com/blog/introducing-the-operator-framework) within Kubernetes to automate the management of all NVIDIA software components needed to provision GPU. These components include the NVIDIA drivers (to enable CUDA), Kubernetes device plugin for GPUs, the NVIDIA Container Runtime, automatic node labelling, [DCGM](https://developer.nvidia.com/dcgm) based monitoring and others.

## Audience and Use-Cases
The GPU Operator allows administrators of Kubernetes clusters to manage GPU nodes just like CPU nodes in the cluster. Instead of provisioning a special OS image for GPU nodes, administrators can rely on a standard OS image for both CPU and GPU nodes and then rely on the GPU Operator to provision the required software components for GPUs.

Note that the GPU Operator is specifically useful for scenarios where the Kubernetes cluster needs to scale quickly - for example provisioning additional GPU nodes on the cloud or on-prem and managing the lifecycle of the underlying software components. Since the GPU Operator runs everything as containers including NVIDIA drivers, the administrators can easily swap various components - simply by starting or stopping containers.

## Product Documentation
For information on platform support and getting started, visit the official documentation [repository](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/overview.html).

## Webinar
[How to easily use GPUs on Kubernetes](https://info.nvidia.com/how-to-use-gpus-on-kubernetes-webinar.html)

## Contributions
[Read the document on contributions](https://github.com/NVIDIA/gpu-operator/blob/master/CONTRIBUTING.md). You can contribute by opening a [pull request](https://help.github.com/en/articles/about-pull-requests).

## Support and Getting Help
Please open [an issue on the GitHub project](https://github.com/NVIDIA/gpu-operator/issues/new) for any questions. Your feedback is appreciated.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[jackc/pgx]]></title>
            <link>https://github.com/jackc/pgx</link>
            <guid>https://github.com/jackc/pgx</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[PostgreSQL driver and toolkit for Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jackc/pgx">jackc/pgx</a></h1>
            <p>PostgreSQL driver and toolkit for Go</p>
            <p>Language: Go</p>
            <p>Stars: 12,572</p>
            <p>Forks: 947</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>[![Go Reference](https://pkg.go.dev/badge/github.com/jackc/pgx/v5.svg)](https://pkg.go.dev/github.com/jackc/pgx/v5)
[![Build Status](https://github.com/jackc/pgx/actions/workflows/ci.yml/badge.svg)](https://github.com/jackc/pgx/actions/workflows/ci.yml)

# pgx - PostgreSQL Driver and Toolkit

pgx is a pure Go driver and toolkit for PostgreSQL.

The pgx driver is a low-level, high performance interface that exposes PostgreSQL-specific features such as `LISTEN` /
`NOTIFY` and `COPY`. It also includes an adapter for the standard `database/sql` interface.

The toolkit component is a related set of packages that implement PostgreSQL functionality such as parsing the wire protocol
and type mapping between PostgreSQL and Go. These underlying packages can be used to implement alternative drivers,
proxies, load balancers, logical replication clients, etc.

## Example Usage

```go
package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;os&quot;

	&quot;github.com/jackc/pgx/v5&quot;
)

func main() {
	// urlExample := &quot;postgres://username:password@localhost:5432/database_name&quot;
	conn, err := pgx.Connect(context.Background(), os.Getenv(&quot;DATABASE_URL&quot;))
	if err != nil {
		fmt.Fprintf(os.Stderr, &quot;Unable to connect to database: %v\n&quot;, err)
		os.Exit(1)
	}
	defer conn.Close(context.Background())

	var name string
	var weight int64
	err = conn.QueryRow(context.Background(), &quot;select name, weight from widgets where id=$1&quot;, 42).Scan(&amp;name, &amp;weight)
	if err != nil {
		fmt.Fprintf(os.Stderr, &quot;QueryRow failed: %v\n&quot;, err)
		os.Exit(1)
	}

	fmt.Println(name, weight)
}
```

See the [getting started guide](https://github.com/jackc/pgx/wiki/Getting-started-with-pgx) for more information.

## Features

* Support for approximately 70 different PostgreSQL types
* Automatic statement preparation and caching
* Batch queries
* Single-round trip query mode
* Full TLS connection control
* Binary format support for custom types (allows for much quicker encoding/decoding)
* `COPY` protocol support for faster bulk data loads
* Tracing and logging support
* Connection pool with after-connect hook for arbitrary connection setup
* `LISTEN` / `NOTIFY`
* Conversion of PostgreSQL arrays to Go slice mappings for integers, floats, and strings
* `hstore` support
* `json` and `jsonb` support
* Maps `inet` and `cidr` PostgreSQL types to `netip.Addr` and `netip.Prefix`
* Large object support
* NULL mapping to pointer to pointer
* Supports `database/sql.Scanner` and `database/sql/driver.Valuer` interfaces for custom types
* Notice response handling
* Simulated nested transactions with savepoints

## Choosing Between the pgx and database/sql Interfaces

The pgx interface is faster. Many PostgreSQL specific features such as `LISTEN` / `NOTIFY` and `COPY` are not available
through the `database/sql` interface.

The pgx interface is recommended when:

1. The application only targets PostgreSQL.
2. No other libraries that require `database/sql` are in use.

It is also possible to use the `database/sql` interface and convert a connection to the lower-level pgx interface as needed.

## Testing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for setup instructions.

## Architecture

See the presentation at Golang Estonia, [PGX Top to Bottom](https://www.youtube.com/watch?v=sXMSWhcHCf8) for a description of pgx architecture.

## Supported Go and PostgreSQL Versions

pgx supports the same versions of Go and PostgreSQL that are supported by their respective teams. For [Go](https://golang.org/doc/devel/release.html#policy) that is the two most recent major releases and for [PostgreSQL](https://www.postgresql.org/support/versioning/) the major releases in the last 5 years. This means pgx supports Go 1.24 and higher and PostgreSQL 13 and higher. pgx also is tested against the latest version of [CockroachDB](https://www.cockroachlabs.com/product/).

## Version Policy

pgx follows semantic versioning for the documented public API on stable releases. `v5` is the latest stable major version.

## PGX Family Libraries

### [github.com/jackc/pglogrepl](https://github.com/jackc/pglogrepl)

pglogrepl provides functionality to act as a client for PostgreSQL logical replication.

### [github.com/jackc/pgmock](https://github.com/jackc/pgmock)

pgmock offers the ability to create a server that mocks the PostgreSQL wire protocol. This is used internally to test pgx by purposely inducing unusual errors. pgproto3 and pgmock together provide most of the foundational tooling required to implement a PostgreSQL proxy or MitM (such as for a custom connection pooler).

### [github.com/jackc/tern](https://github.com/jackc/tern)

tern is a stand-alone SQL migration system.

### [github.com/jackc/pgerrcode](https://github.com/jackc/pgerrcode)

pgerrcode contains constants for the PostgreSQL error codes.

## Adapters for 3rd Party Types

* [github.com/jackc/pgx-gofrs-uuid](https://github.com/jackc/pgx-gofrs-uuid)
* [github.com/jackc/pgx-shopspring-decimal](https://github.com/jackc/pgx-shopspring-decimal)
* [github.com/twpayne/pgx-geos](https://github.com/twpayne/pgx-geos) ([PostGIS](https://postgis.net/) and [GEOS](https://libgeos.org/) via [go-geos](https://github.com/twpayne/go-geos))
* [github.com/vgarvardt/pgx-google-uuid](https://github.com/vgarvardt/pgx-google-uuid)


## Adapters for 3rd Party Tracers

* [github.com/jackhopner/pgx-xray-tracer](https://github.com/jackhopner/pgx-xray-tracer)
* [github.com/exaring/otelpgx](https://github.com/exaring/otelpgx)

## Adapters for 3rd Party Loggers

These adapters can be used with the tracelog package.

* [github.com/jackc/pgx-go-kit-log](https://github.com/jackc/pgx-go-kit-log)
* [github.com/jackc/pgx-log15](https://github.com/jackc/pgx-log15)
* [github.com/jackc/pgx-logrus](https://github.com/jackc/pgx-logrus)
* [github.com/jackc/pgx-zap](https://github.com/jackc/pgx-zap)
* [github.com/jackc/pgx-zerolog](https://github.com/jackc/pgx-zerolog)
* [github.com/mcosta74/pgx-slog](https://github.com/mcosta74/pgx-slog)
* [github.com/kataras/pgx-golog](https://github.com/kataras/pgx-golog)

## 3rd Party Libraries with PGX Support

### [github.com/pashagolub/pgxmock](https://github.com/pashagolub/pgxmock)

pgxmock is a mock library implementing pgx interfaces.
pgxmock has one and only purpose - to simulate pgx behavior in tests, without needing a real database connection.

### [github.com/georgysavva/scany](https://github.com/georgysavva/scany)

Library for scanning data from a database into Go structs and more.

### [github.com/vingarcia/ksql](https://github.com/vingarcia/ksql)

A carefully designed SQL client for making using SQL easier,
more productive, and less error-prone on Golang.

### [github.com/otan/gopgkrb5](https://github.com/otan/gopgkrb5)

Adds GSSAPI / Kerberos authentication support.

### [github.com/wcamarao/pmx](https://github.com/wcamarao/pmx)

Explicit data mapping and scanning library for Go structs and slices.

### [github.com/stephenafamo/scan](https://github.com/stephenafamo/scan)

Type safe and flexible package for scanning database data into Go types.
Supports, structs, maps, slices and custom mapping functions.

### [github.com/z0ne-dev/mgx](https://github.com/z0ne-dev/mgx)

Code first migration library for native pgx (no database/sql abstraction).

### [github.com/amirsalarsafaei/sqlc-pgx-monitoring](https://github.com/amirsalarsafaei/sqlc-pgx-monitoring)

A database monitoring/metrics library for pgx and sqlc. Trace, log and monitor your sqlc query performance using OpenTelemetry.

### [https://github.com/nikolayk812/pgx-outbox](https://github.com/nikolayk812/pgx-outbox)

Simple Golang implementation for transactional outbox pattern for PostgreSQL using jackc/pgx driver.

### [https://github.com/Arlandaren/pgxWrappy](https://github.com/Arlandaren/pgxWrappy)

Simplifies working with the pgx library, providing convenient scanning of nested structures.

### [https://github.com/KoNekoD/pgx-colon-query-rewriter](https://github.com/KoNekoD/pgx-colon-query-rewriter)

Implementation of the pgx query rewriter to use &#039;:&#039; instead of &#039;@&#039; in named query parameters.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[amacneil/dbmate]]></title>
            <link>https://github.com/amacneil/dbmate</link>
            <guid>https://github.com/amacneil/dbmate</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[🚀 A lightweight, framework-agnostic database migration tool.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/amacneil/dbmate">amacneil/dbmate</a></h1>
            <p>🚀 A lightweight, framework-agnostic database migration tool.</p>
            <p>Language: Go</p>
            <p>Stars: 6,392</p>
            <p>Forks: 323</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># Dbmate

[![Release](https://img.shields.io/github/release/amacneil/dbmate.svg)](https://github.com/amacneil/dbmate/releases)
[![Go Report](https://goreportcard.com/badge/github.com/amacneil/dbmate)](https://goreportcard.com/report/github.com/amacneil/dbmate)
[![Reference](https://img.shields.io/badge/go.dev-reference-blue?logo=go&amp;logoColor=white)](https://pkg.go.dev/github.com/amacneil/dbmate/v2/pkg/dbmate)

Dbmate is a database migration tool that will keep your database schema in sync across multiple developers and your production servers.

It is a standalone command line tool that can be used with Go, Node.js, Python, Ruby, PHP, Rust, C++, or any other language or framework you are using to write database-backed applications. This is especially helpful if you are writing multiple services in different languages, and want to maintain some sanity with consistent development tools.

For a comparison between dbmate and other popular database schema migration tools, please see [Alternatives](#alternatives).

## Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Commands](#commands)
  - [Command Line Options](#command-line-options)
- [Usage](#usage)
  - [Connecting to the Database](#connecting-to-the-database)
    - [PostgreSQL](#postgresql)
    - [MySQL](#mysql)
    - [SQLite](#sqlite)
    - [ClickHouse](#clickhouse)
    - [BigQuery](#bigquery)
    - [Spanner](#spanner)
  - [Creating Migrations](#creating-migrations)
  - [Running Migrations](#running-migrations)
  - [Rolling Back Migrations](#rolling-back-migrations)
  - [Migration Options](#migration-options)
  - [Waiting For The Database](#waiting-for-the-database)
  - [Exporting Schema File](#exporting-schema-file)
- [Library](#library)
  - [Use dbmate as a library](#use-dbmate-as-a-library)
  - [Embedding migrations](#embedding-migrations)
- [Concepts](#concepts)
  - [Migration files](#migration-files)
  - [Schema file](#schema-file)
  - [Schema migrations table](#schema-migrations-table)
- [Alternatives](#alternatives)
- [Contributing](#contributing)

## Features

- Supports MySQL, PostgreSQL, SQLite, and ClickHouse
- Uses plain SQL for writing schema migrations
- Migrations are timestamp-versioned, to avoid version number conflicts with multiple developers
- Migrations are run atomically inside a transaction
- Supports creating and dropping databases (handy in development/test)
- Supports saving a `schema.sql` file to easily diff schema changes in git
- Database connection URL is defined using an environment variable (`DATABASE_URL` by default), or specified on the command line
- Built-in support for reading environment variables from your `.env` file
- Easy to distribute, single self-contained binary
- Doesn&#039;t try to upsell you on a SaaS service

## Installation

**NPM**

Install using [NPM](https://www.npmjs.com/):

```sh
npm install --save-dev dbmate
npx dbmate --help
```

**macOS**

Install using [Homebrew](https://brew.sh/):

```sh
brew install dbmate
dbmate --help
```

**Linux**

Install the binary directly:

```sh
sudo curl -fsSL -o /usr/local/bin/dbmate https://github.com/amacneil/dbmate/releases/latest/download/dbmate-linux-amd64
sudo chmod +x /usr/local/bin/dbmate
/usr/local/bin/dbmate --help
```

**Windows**

Install using [Scoop](https://scoop.sh)

```pwsh
scoop install dbmate
dbmate --help
```

**Docker**

Docker images are published to GitHub Container Registry ([`ghcr.io/amacneil/dbmate`](https://ghcr.io/amacneil/dbmate)).

Remember to set `--network=host` or see [this comment](https://github.com/amacneil/dbmate/issues/128#issuecomment-615924611) for more tips on using dbmate with docker networking):

```sh
docker run --rm -it --network=host ghcr.io/amacneil/dbmate --help
```

If you wish to create or apply migrations, you will need to use Docker&#039;s [bind mount](https://docs.docker.com/storage/bind-mounts/) feature to make your local working directory (`pwd`) available inside the dbmate container:

```sh
docker run --rm -it --network=host -v &quot;$(pwd)/db:/db&quot; ghcr.io/amacneil/dbmate new create_users_table
```

## Commands

```sh
dbmate --help    # print usage help
dbmate new       # generate a new migration file
dbmate up        # create the database (if it does not already exist) and run any pending migrations
dbmate create    # create the database
dbmate drop      # drop the database
dbmate migrate   # run any pending migrations
dbmate rollback  # roll back the most recent migration
dbmate down      # alias for rollback
dbmate status    # show the status of all migrations (supports --exit-code and --quiet)
dbmate dump      # write the database schema.sql file
dbmate load      # load schema.sql file to the database
dbmate wait      # wait for the database server to become available
```

### Command Line Options

The following options are available with all commands. You must use command line arguments in the order `dbmate [global options] command [command options]`. Most options can also be configured via environment variables (and loaded from your `.env` file, which is helpful to share configuration between team members).

- `--url, -u &quot;protocol://host:port/dbname&quot;` - specify the database url directly. _(env: `DATABASE_URL`)_
- `--env, -e &quot;DATABASE_URL&quot;` - specify an environment variable to read the database connection URL from.
- `--env-file &quot;.env&quot;` - specify an alternate environment variables file(s) to load.
- `--migrations-dir, -d &quot;./db/migrations&quot;` - where to keep the migration files. _(env: `DBMATE_MIGRATIONS_DIR`)_
- `--migrations-table &quot;schema_migrations&quot;` - database table to record migrations in. _(env: `DBMATE_MIGRATIONS_TABLE`)_
- `--schema-file, -s &quot;./db/schema.sql&quot;` - a path to keep the schema.sql file. _(env: `DBMATE_SCHEMA_FILE`)_
- `--no-dump-schema` - don&#039;t auto-update the schema.sql file on migrate/rollback _(env: `DBMATE_NO_DUMP_SCHEMA`)_
- `--strict` - fail if migrations would be applied out of order _(env: `DBMATE_STRICT`)_
- `--wait` - wait for the db to become available before executing the subsequent command _(env: `DBMATE_WAIT`)_
- `--wait-timeout 60s` - timeout for --wait flag _(env: `DBMATE_WAIT_TIMEOUT`)_

## Usage

### Connecting to the Database

Dbmate locates your database using the `DATABASE_URL` environment variable by default. If you are writing a [twelve-factor app](http://12factor.net/), you should be storing all connection strings in environment variables.

To make this easy in development, dbmate looks for a `.env` file in the current directory, and treats any variables listed there as if they were specified in the current environment (existing environment variables take preference, however).

If you do not already have a `.env` file, create one and add your database connection URL:

```sh
$ cat .env
DATABASE_URL=&quot;postgres://postgres@127.0.0.1:5432/myapp_development?sslmode=disable&quot;
```

`DATABASE_URL` should be specified in the following format:

```
protocol://username:password@host:port/database_name?options
```

- `protocol` must be one of `mysql`, `postgres`, `postgresql`, `sqlite`, `sqlite3`, `clickhouse`
- `username` and `password` must be URL encoded (you will get an error if you use special charactors)
- `host` can be either a hostname or IP address
- `options` are driver-specific (refer to the underlying Go SQL drivers if you wish to use these)

Dbmate can also load the connection URL from a different environment variable. For example, before running your test suite, you may wish to drop and recreate the test database. One easy way to do this is to store your test database connection URL in the `TEST_DATABASE_URL` environment variable:

```sh
$ cat .env
DATABASE_URL=&quot;postgres://postgres@127.0.0.1:5432/myapp_dev?sslmode=disable&quot;
TEST_DATABASE_URL=&quot;postgres://postgres@127.0.0.1:5432/myapp_test?sslmode=disable&quot;
```

You can then specify this environment variable in your test script (Makefile or similar):

```sh
$ dbmate -e TEST_DATABASE_URL drop
Dropping: myapp_test
$ dbmate -e TEST_DATABASE_URL --no-dump-schema up
Creating: myapp_test
Applying: 20151127184807_create_users_table.sql
Applied: 20151127184807_create_users_table.sql in 123µs
```

Alternatively, you can specify the url directly on the command line:

```sh
$ dbmate -u &quot;postgres://postgres@127.0.0.1:5432/myapp_test?sslmode=disable&quot; up
```

The only advantage of using `dbmate -e TEST_DATABASE_URL` over `dbmate -u $TEST_DATABASE_URL` is that the former takes advantage of dbmate&#039;s automatic `.env` file loading.

#### PostgreSQL

When connecting to Postgres, you may need to add the `sslmode=disable` option to your connection string, as dbmate by default requires a TLS connection (some other frameworks/languages allow unencrypted connections by default).

```sh
DATABASE_URL=&quot;postgres://username:password@127.0.0.1:5432/database_name?sslmode=disable&quot;
```

A `socket` or `host` parameter can be specified to connect through a unix socket (note: specify the directory only):

```sh
DATABASE_URL=&quot;postgres://username:password@/database_name?socket=/var/run/postgresql&quot;
```

A `search_path` parameter can be used to specify the [current schema](https://www.postgresql.org/docs/13/ddl-schemas.html#DDL-SCHEMAS-PATH) while applying migrations, as well as for dbmate&#039;s `schema_migrations` table.
If the schema does not exist, it will be created automatically. If multiple comma-separated schemas are passed, the first will be used for the `schema_migrations` table.

```sh
DATABASE_URL=&quot;postgres://username:password@127.0.0.1:5432/database_name?search_path=myschema&quot;
```

```sh
DATABASE_URL=&quot;postgres://username:password@127.0.0.1:5432/database_name?search_path=myschema,public&quot;
```

#### MySQL

```sh
DATABASE_URL=&quot;mysql://username:password@127.0.0.1:3306/database_name&quot;
```

A `socket` parameter can be specified to connect through a unix socket:

```sh
DATABASE_URL=&quot;mysql://username:password@/database_name?socket=/var/run/mysqld/mysqld.sock&quot;
```

#### SQLite

SQLite databases are stored on the filesystem, so you do not need to specify a host. By default, files are relative to the current directory. For example, the following will create a database at `./db/database.sqlite3`:

```sh
DATABASE_URL=&quot;sqlite:db/database.sqlite3&quot;
```

To specify an absolute path, add a forward slash to the path. The following will create a database at `/tmp/database.sqlite3`:

```sh
DATABASE_URL=&quot;sqlite:/tmp/database.sqlite3&quot;
```

Note that for some common [settings](https://sqlite.org/pragma.html) like `journal_mode` to improve performance, transactions need to be disabled for that migration file, e.g.

```sql
-- migrate:up transaction:false
PRAGMA journal_mode = WAL;
```

Otherwise the migration will fail with &quot;Error: cannot change into wal mode from within a transaction&quot;.

#### ClickHouse

```sh
DATABASE_URL=&quot;clickhouse://username:password@127.0.0.1:9000/database_name&quot;
```

To work with ClickHouse cluster, there are 4 connection query parameters that can be supplied:

- `on_cluster` - Indicataion to use cluster statements and replicated migration table. (default: `false`) If this parameter is not supplied, other cluster related query parameters are ignored.

```sh
DATABASE_URL=&quot;clickhouse://username:password@127.0.0.1:9000/database_name?on_cluster&quot;

DATABASE_URL=&quot;clickhouse://username:password@127.0.0.1:9000/database_name?on_cluster=true&quot;
```

- `cluster_macro` (Optional) - Macro value to be used for ON CLUSTER statements and for the replciated migration table engine zookeeper path. (default: `{cluster}`)

```sh
DATABASE_URL=&quot;clickhouse://username:password@127.0.0.1:9000/database_name?on_cluster&amp;cluster_macro={my_cluster}&quot;
```

- `replica_macro` (Optional) - Macro value to be used for the replica name in the replciated migration table engine. (default: `{replica}`)

```sh
DATABASE_URL=&quot;clickhouse://username:password@127.0.0.1:9000/database_name?on_cluster&amp;replica_macro={my_replica}&quot;
```

- `zoo_path` (Optional) - The path to the table migration in ClickHouse/Zoo Keeper. (default: `/clickhouse/tables/&lt;cluster_macro&gt;/{table}`)

```sh
DATABASE_URL=&quot;clickhouse://username:password@127.0.0.1:9000/database_name?on_cluster&amp;zoo_path=/zk/path/tables&quot;
```

[See other supported connection options](https://github.com/ClickHouse/clickhouse-go#dsn).

#### BigQuery

Follow the following format for `DATABASE_URL` when connecting to actual BigQuery in GCP:

```
bigquery://projectid/location/dataset
```

`projectid` (mandatory) - Project ID

`dataset` (mandatory) - Dataset name within the Project

`location` (optional) - Where Dataset is created

_NOTE: Follow [this doc](https://cloud.google.com/docs/authentication/provide-credentials-adc) on how to set `GOOGLE_APPLICATION_CREDENTIALS` environment variable for proper Authentication_

Follow the following format if trying to connect to a custom endpoint e.g. [BigQuery Emulator](https://github.com/goccy/bigquery-emulator)

```
bigquery://host:port/projectid/location/dataset?disable_auth=true
```

`disable_auth` (optional) - Pass `true` to skip Authentication, use only for testing and connecting to emulator.

#### Spanner

Spanner support is currently limited to databases using the [PostgreSQL Dialect](https://cloud.google.com/spanner/docs/postgresql-interface), which must be chosen during database creation. For future Spanner with GoogleSQL support, see [this discussion](https://github.com/amacneil/dbmate/discussions/369).

Spanner with the Postgres interface requires that the [PGAdapter](https://cloud.google.com/spanner/docs/pgadapter) is running. Use the following format for `DATABASE_URL`, with the host and port set to where the PGAdapter is running:

```shell
DATABASE_URL=&quot;spanner-postgres://127.0.0.1:5432/database_name?sslmode=disable&quot;
```

Note that specifying a username and password is not necessary, as authentication is handled by the PGAdapter (they will be ignored by the PGAdapter if specified).

Other options of the [postgres driver](#postgresql) are supported.

Spanner also doesn&#039;t allow DDL to be executed inside explicit transactions. You must therefore specify `transaction:false` on migrations that include DDL:

```sql
-- migrate:up transaction:false
CREATE TABLE ...

-- migrate:down transaction:false
DROP TABLE ...
```

Schema dumps are not currently supported, as `pg_dump` uses functions that are not provided by Spanner.

### Creating Migrations

To create a new migration, run `dbmate new create_users_table`. You can name the migration anything you like. This will create a file `db/migrations/20151127184807_create_users_table.sql` in the current directory:

```sql
-- migrate:up

-- migrate:down
```

To write a migration, simply add your SQL to the `migrate:up` section:

```sql
-- migrate:up
create table users (
  id integer,
  name varchar(255),
  email varchar(255) not null
);

-- migrate:down
```

For related changes, it is possible to include multiple migrations in a single file using additional `migrate:up` and `migrate:down` sections. Migration file either succeeds or fails as a whole.

```sql
-- migrate:up
CREATE TABLE users (id SERIAL PRIMARY KEY);

-- migrate:down
DROP TABLE users;

-- migrate:up
ALTER TABLE users ADD COLUMN email VARCHAR;

-- migrate:down
ALTER TABLE users DROP COLUMN email;
```

&gt; Note: Migration files are named in the format `[version]_[description].sql`. Only the version (defined as all leading numeric characters in the file name) is recorded in the database, so you can safely rename a migration file without having any effect on its current application state.

### Running Migrations

Run `dbmate up` to run any pending migrations.

```sh
$ dbmate up
Creating: myapp_development
Applying: 20151127184807_create_users_table.sql
Applied: 20151127184807_create_users_table.sql in 123µs
Writing: ./db/schema.sql
```

&gt; Note: `dbmate up` will create the database if it does not already exist (assuming the current user has permission to create databases). If you want to run migrations without creating the database, run `dbmate migrate`.

Pending migrations are always applied in numerical order. However, dbmate does not prevent migrations from being applied out of order if they are committed independently (for example: if a developer has been working on a branch for a long time, and commits a migration which has a lower version number than other already-applied migrations, dbmate will simply apply the pending migration). See [#159](https://github.com/amacneil/dbmate/issues/159) for a more detailed explanation.

### Rolling Back Migrations

By default, dbmate doesn&#039;t know how to roll back a migration. In development, it&#039;s often useful to be able to revert your database to a previous state. To accomplish this, implement the `migrate:down` section:

```sql
-- migrate:up
create table users (
  id integer,
  name varchar(255),
  email varchar(255) not null
);

-- migrate:down
drop table users;
```

Run `dbmate rollback` to roll back the most recent migration:

```sh
$ dbmate rollback
Rolling back: 20151127184807_create_users_table.sql
Rolled back: 20151127184807_create_users_table.sql in 123µs
Writing: ./db/schema.sql
```

### Migration Options

dbmate supports options passed to a migration block in the form of `key:value` pairs. List of supported options:

- `transaction`

**transaction**

`transaction` is useful if you do not want to run SQL inside a transaction:

```sql
-- migrate:up transaction:false
ALTER TYPE colors ADD VALUE &#039;orange&#039; AFTER &#039;red&#039;;
```

`transaction` will default to `true` if your database supports it.

### Waiting For The Database

If you use a Docker development environment for your project, you may encounter issues with the database not being immediately ready when running migrations or unit tests. This can be due to the database server having only just started.

In general, your application should be resilient to not having a working database connection on startup. However, for the purpose of running migrations or unit tests, this is not practical. The `wait` command avoids this situation by allowing you to pause a script or other application until the database is available. Dbmate will attempt a connection to the database server every second, up to a maximum of 60 seconds.

If the database is available, `wait` will return no output:

```sh
$ dbmate wait
```

If the database is unavailable, `wait` will block until the database becomes available:

```sh
$ dbmate wait
Waiting for database....
```

You can also use the `--wait` flag with other commands if you sometimes see failures caused by the database not yet being ready:

```sh
$ dbmate --wait up
Waiting for database....
Creating: myapp_development
```

You can customize the timeout using `--wait-timeout` (default 60s). If the database is still not available, the command will return an error:

```sh
$ dbmate --wait-timeout=5s wait
Waiting for database.....
Error: unable to connect to database: dial tcp 127.0.0.1:5432: connect: connection refused
```

Please note that the `wait` command does not verify whether your specified database exists, only that the server is available and ready (so it will return success if the database server is available, but your database has not yet been created).

### Exporting Schema File

When you run the `up`, `migrate`, or `rollback` commands, dbmate will automatically create a `./db/schema.sql` file containing a complete representation of your database schema. Dbmate keeps this file up to date for you, so you should not manually edit it.

It is recommended to check this file into source control, so that you can easily review changes to the schema in commits or pull requests. It&#039;s also possible to use this file when you want to quickly load a database schema, without running each migration sequentially (for example in your test harness). However, if you do not wish to save this file, you could add it to your `.gitignore`, or pass the `--no-dump-schema` command line option.

To dump the `schema.sql` file without performing any other actions, run `dbmate dump`. Unlike other dbmate actions, this command 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[tulir/whatsmeow]]></title>
            <link>https://github.com/tulir/whatsmeow</link>
            <guid>https://github.com/tulir/whatsmeow</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[Go library for the WhatsApp web multidevice API]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tulir/whatsmeow">tulir/whatsmeow</a></h1>
            <p>Go library for the WhatsApp web multidevice API</p>
            <p>Language: Go</p>
            <p>Stars: 4,418</p>
            <p>Forks: 697</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># whatsmeow
[![Go Reference](https://pkg.go.dev/badge/go.mau.fi/whatsmeow.svg)](https://pkg.go.dev/go.mau.fi/whatsmeow)

whatsmeow is a Go library for the WhatsApp web multidevice API.

## Discussion
Matrix room: [#whatsmeow:maunium.net](https://matrix.to/#/#whatsmeow:maunium.net)

For questions about the WhatsApp protocol (like how to send a specific type of
message), you can also use the [WhatsApp protocol Q&amp;A] section on GitHub
discussions.

[WhatsApp protocol Q&amp;A]: https://github.com/tulir/whatsmeow/discussions/categories/whatsapp-protocol-q-a

## Usage
The [godoc](https://pkg.go.dev/go.mau.fi/whatsmeow) includes docs for all methods and event types.
There&#039;s also a [simple example](https://pkg.go.dev/go.mau.fi/whatsmeow#example-package) at the top.

## Features
Most core features are already present:

* Sending messages to private chats and groups (both text and media)
* Receiving all messages
* Managing groups and receiving group change events
* Joining via invite messages, using and creating invite links
* Sending and receiving typing notifications
* Sending and receiving delivery and read receipts
* Reading and writing app state (contact list, chat pin/mute status, etc)
* Sending and handling retry receipts if message decryption fails
* Sending status messages (experimental, may not work for large contact lists)

Things that are not yet implemented:

* Sending broadcast list messages (this is not supported on WhatsApp web either)
* Calls
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[aldinokemal/go-whatsapp-web-multidevice]]></title>
            <link>https://github.com/aldinokemal/go-whatsapp-web-multidevice</link>
            <guid>https://github.com/aldinokemal/go-whatsapp-web-multidevice</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[GOWA - WhatsApp REST API with support for UI, Webhooks, and MCP. Built with Golang for efficient memory use.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aldinokemal/go-whatsapp-web-multidevice">aldinokemal/go-whatsapp-web-multidevice</a></h1>
            <p>GOWA - WhatsApp REST API with support for UI, Webhooks, and MCP. Built with Golang for efficient memory use.</p>
            <p>Language: Go</p>
            <p>Stars: 2,529</p>
            <p>Forks: 638</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[openbao/openbao]]></title>
            <link>https://github.com/openbao/openbao</link>
            <guid>https://github.com/openbao/openbao</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[OpenBao exists to provide a software solution to manage, store, and distribute sensitive data including secrets, certificates, and keys.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openbao/openbao">openbao/openbao</a></h1>
            <p>OpenBao exists to provide a software solution to manage, store, and distribute sensitive data including secrets, certificates, and keys.</p>
            <p>Language: Go</p>
            <p>Stars: 4,617</p>
            <p>Forks: 261</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># OpenBao

----

**Please note**: We take OpenBao&#039;s security and our users&#039; trust very seriously. If you believe you have found a security issue in OpenBao, _please responsibly disclose_ by contacting us at [openbao-security@lists.openssf.org](mailto:openbao-security@lists.openssf.org).

----

- [Website](https://www.openbao.org)
- [Mailing List](https://lists.openssf.org/g/openbao)
- [GitHub Discussions](https://github.com/openbao/openbao/discussions)
- [Chat Server](https://chat.lfx.linuxfoundation.org/)
  - `#openbao-announcements` ([matrix client](https://matrix.to/#/#openbao-announcements:chat.lfx.linuxfoundation.org), [home server](https://chat.lfx.linuxfoundation.org/#/room/#openbao-announcements:chat.lfx.linuxfoundation.org))
  - `#openbao-development` ([matrix client](https://matrix.to/#/#openbao-development:chat.lfx.linuxfoundation.org), [home server](https://chat.lfx.linuxfoundation.org/#/room/#openbao-development:chat.lfx.linuxfoundation.org))
  - `#openbao-general` ([matrix client](https://matrix.to/#/#openbao-general:chat.lfx.linuxfoundation.org), [home server](https://chat.lfx.linuxfoundation.org/#/room/#openbao-general:chat.lfx.linuxfoundation.org))
  - `#openbao-questions` ([matrix client](https://matrix.to/#/#openbao-questions:chat.lfx.linuxfoundation.org), [home server](https://chat.lfx.linuxfoundation.org/#/room/#openbao-questions:chat.lfx.linuxfoundation.org))
  - `#openbao-random` ([matrix client](https://matrix.to/#/#openbao-random:chat.lfx.linuxfoundation.org), [home server](https://chat.lfx.linuxfoundation.org/#/room/#openbao-random:chat.lfx.linuxfoundation.org))

&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;300&quot; alt=&quot;OpenBao Mascot&quot; src=&quot;https://raw.githubusercontent.com/openbao/artwork/main/color/openbao-color.svg&quot;&gt;
&lt;/p&gt;

**OpenBao exists to provide a software solution to manage, store, and distribute sensitive data including secrets, certificates, and keys. The OpenBao community intends to provide this software under an OSI-approved open-source license, led by a community run under open governance principles.**

A modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where OpenBao steps in.

The key features of OpenBao are:

* **Secure Secret Storage**: Arbitrary key/value secrets can be stored
  in OpenBao. OpenBao encrypts these secrets prior to writing them to persistent
  storage, so gaining access to the raw storage isn&#039;t enough to access
  your secrets. OpenBao can write to disk, [PostgreSQL](https://www.postgresql.org/),
  and more.

* **Dynamic Secrets**: OpenBao can generate secrets on-demand for some
  systems, such as AWS or SQL databases. For example, when an application
  needs to access an S3 bucket, it asks OpenBao for credentials, and OpenBao
  will generate an AWS keypair with valid permissions on demand. After
  creating these dynamic secrets, OpenBao will also automatically revoke them
  after the lease is up.

* **Data Encryption**: OpenBao can encrypt and decrypt data without storing
  it. This allows security teams to define encryption parameters and
  developers to store encrypted data in a location such as a SQL database without
  having to design their own encryption methods.

* **Leasing and Renewal**: All secrets in OpenBao have a _lease_ associated
  with them. At the end of the lease, OpenBao will automatically revoke that
  secret. Clients are able to renew leases via built-in renew APIs.

* **Revocation**: OpenBao has built-in support for secret revocation. OpenBao
  can revoke not only single secrets, but a tree of secrets, for example,
  all secrets read by a specific user, or all secrets of a particular type.
  Revocation assists in key rolling as well as locking down systems in the
  case of an intrusion.

Documentation, Getting Started, and Certification Exams
-------------------------------

Documentation is available on the [OpenBao website](https://www.openbao.org/docs/).

Developing OpenBao
--------------------

If you wish to work on OpenBao itself or any of its built-in systems, you&#039;ll
first need [Go](https://www.golang.org) installed on your machine.

For local dev first make sure Go is properly installed, including setting up a
[GOPATH](https://golang.org/doc/code.html#GOPATH). Ensure that `$GOPATH/bin` is in
your path as some distributions bundle the old version of build tools. Next, clone this
repository. OpenBao uses [Go Modules](https://github.com/golang/go/wiki/Modules),
so it is recommended that you clone the repository ***outside*** of the GOPATH.
You can then download any required build tools by bootstrapping your environment:

```sh
$ make bootstrap
...
```

To compile a development version of OpenBao, run `make` or `make dev`. This will
put the OpenBao binary in the `bin` and `$GOPATH/bin` folders:

```sh
$ make dev
...
$ bin/bao
...
```

To compile a development version of OpenBao with the UI, run `make static-dist dev-ui`. This will
put the OpenBao binary in the `bin` and `$GOPATH/bin` folders:

```sh
$ make static-dist dev-ui
...
$ bin/bao
...
```

To run tests, type `make test`. Note: this requires Docker to be installed. If
this exits with exit status 0, then everything is working!

```sh
$ make test
...
```

If you&#039;re developing a specific package, you can run tests for just that
package by specifying the `TEST` variable. For example below, only
`vault` package tests will be run.

```sh
$ make test TEST=./vault
...
```

### Importing OpenBao

This repository publishes two libraries that may be imported by other projects:
`github.com/openbao/openbao/api/v2` and `github.com/openbao/openbao/sdk/v2`.

Note that this repository also contains OpenBao (the product), and as with most Go
projects, OpenBao uses Go modules to manage its dependencies. The mechanism to do
that is the [go.mod](./go.mod) file. As it happens, the presence of that file
also makes it theoretically possible to import OpenBao as a dependency into other
projects. Some other projects have made a practice of doing so in order to take
advantage of testing tooling that was developed for testing OpenBao itself. This
is not, and has never been, a supported way to use the OpenBao project. We aren&#039;t
likely to fix bugs relating to failure to import `github.com/openbao/openbao`
into your project.

See also the section &quot;Docker-based tests&quot; below.

### Acceptance Tests

OpenBao has comprehensive [acceptance tests](https://en.wikipedia.org/wiki/Acceptance_testing)
covering most of the features of the secret and auth methods.

If you&#039;re working on a feature of a secret or auth method and want to
verify it is functioning (and also hasn&#039;t broken anything else), we recommend
running the acceptance tests.

**Warning:** The acceptance tests create/destroy/modify *real resources*, which
may incur real costs in some cases. In the presence of a bug, it is technically
possible that broken backends could leave dangling data behind. Therefore,
please run the acceptance tests at your own risk. At the very least,
we recommend running them in their own private account for whatever backend
you&#039;re testing.

To run the acceptance tests, invoke `make testacc`:

```sh
$ make testacc TEST=./builtin/logical/pki
...
```

The `TEST` variable is required, and you should specify the folder where the
backend is. The `TESTARGS` variable is recommended to filter down to a specific
resource to test, since testing all of them at once can sometimes take a very
long time.

Acceptance tests typically require other environment variables to be set for
things such as access keys. The test itself should error early and tell
you what to set, so it is not documented here.

### Docker-based Tests

We have created an experimental new testing mechanism inspired by NewTestCluster.
An example of how to use it:

```go
import (
  &quot;testing&quot;
  &quot;github.com/openbao/openbao/sdk/v2/helper/testcluster/docker&quot;
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;docker.DockerClusterOptions{
    ImageRepo: &quot;openbao/openbao&quot;,
    ImageTag:    &quot;latest&quot;,
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()

  client := cluster.Nodes()[0].APIClient()
  _, err := client.Logical().Read(&quot;sys/storage/raft/configuration&quot;)
  if err != nil {
    t.Fatal(err)
  }
}
```

Here is a more realistic example of how we use it in practice.  `DefaultOptions` uses
`hashicorp/vault:latest` as the repo and tag, but it also looks at the environment
variable `BAO_BINARY`. If populated, it will copy the local file referenced by
`BAO_BINARY` into the container. This is useful when testing local changes.

Optionally you can set `COMMIT_SHA`, which will be appended to the image name we
build as a debugging convenience.

```go
func Test_Custom_Build_With_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
```

Finally, here&#039;s an example of running an existing OSS docker test with a custom binary:

```bash
$ GOOS=linux make dev
$ VAULT_BINARY=$(pwd)/bin/bao go test -run &#039;TestRaft_Configuration_Docker&#039; ./vault/external_tests/raft/raft_binary
ok      github.com/openbao/openbao/vault/external_tests/raft/raft_binary        20.960s
```
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hashicorp/terraform]]></title>
            <link>https://github.com/hashicorp/terraform</link>
            <guid>https://github.com/hashicorp/terraform</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[Terraform enables you to safely and predictably create, change, and improve infrastructure. It is a source-available tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hashicorp/terraform">hashicorp/terraform</a></h1>
            <p>Terraform enables you to safely and predictably create, change, and improve infrastructure. It is a source-available tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.</p>
            <p>Language: Go</p>
            <p>Stars: 46,693</p>
            <p>Forks: 10,052</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># Terraform

- Website: https://developer.hashicorp.com/terraform
- Forums: [HashiCorp Discuss](https://discuss.hashicorp.com/c/terraform-core)
- Documentation: [https://developer.hashicorp.com/terraform/docs](https://developer.hashicorp.com/terraform/docs)
- Tutorials: [HashiCorp&#039;s Learn Platform](https://developer.hashicorp.com/terraform/tutorials)
- Certification Exam: [HashiCorp Certified: Terraform Associate](https://www.hashicorp.com/certification/#hashicorp-certified-terraform-associate)

&lt;img alt=&quot;Terraform&quot; src=&quot;https://www.datocms-assets.com/2885/1731373310-terraform_white.svg&quot; width=&quot;600px&quot;&gt;

Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions.

The key features of Terraform are:

- **Infrastructure as Code**: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.

- **Execution Plans**: Terraform has a &quot;planning&quot; step where it generates an execution plan. The execution plan shows what Terraform will do when you call apply. This lets you avoid any surprises when Terraform manipulates infrastructure.

- **Resource Graph**: Terraform builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, Terraform builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.

- **Change Automation**: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what Terraform will change and in what order, avoiding many possible human errors.

For more information, refer to the [What is Terraform?](https://www.terraform.io/intro) page on the Terraform website.

## Getting Started &amp; Documentation

Documentation is available on the [Terraform website](https://developer.hashicorp.com/terraform):

- [Introduction](https://developer.hashicorp.com/terraform/intro)
- [Documentation](https://developer.hashicorp.com/terraform/docs)

If you&#039;re new to Terraform and want to get started creating infrastructure, please check out our [Getting Started guides](https://learn.hashicorp.com/terraform#getting-started) on HashiCorp&#039;s learning platform. There are also [additional guides](https://learn.hashicorp.com/terraform#operations-and-development) to continue your learning.

Show off your Terraform knowledge by passing a certification exam. Visit the [certification page](https://www.hashicorp.com/certification/) for information about exams and find [study materials](https://learn.hashicorp.com/terraform/certification/terraform-associate) on HashiCorp&#039;s learning platform.

## Developing Terraform

This repository contains only Terraform core, which includes the command line interface and the main graph engine. Providers are implemented as plugins, and Terraform can automatically download providers that are published on [the Terraform Registry](https://registry.terraform.io). HashiCorp develops some providers, and others are developed by other organizations. For more information, refer to [Plugin development](https://developer.hashicorp.com/terraform/plugin).

- To learn more about compiling Terraform and contributing suggested changes, refer to [the contributing guide](.github/CONTRIBUTING.md).

- To learn more about how we handle bug reports, refer to the [bug triage guide](./BUGPROCESS.md).

- To learn how to contribute to the Terraform documentation, refer to the [Web Unified Docs repository](https://github.com/hashicorp/web-unified-docs).

## License

[Business Source License 1.1](https://github.com/hashicorp/terraform/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[pulumi/pulumi]]></title>
            <link>https://github.com/pulumi/pulumi</link>
            <guid>https://github.com/pulumi/pulumi</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Pulumi - Infrastructure as Code in any programming language 🚀]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pulumi/pulumi">pulumi/pulumi</a></h1>
            <p>Pulumi - Infrastructure as Code in any programming language 🚀</p>
            <p>Language: Go</p>
            <p>Stars: 23,898</p>
            <p>Forks: 1,243</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.pulumi.com/?utm_source=github.com&amp;utm_medium=referral&amp;utm_campaign=pulumi-pulumi-github-repo&amp;utm_content=top+logo&quot; title=&quot;Pulumi - Modern Infrastructure as Code - AWS Azure Kubernetes Containers Serverless&quot;&gt;
        &lt;img src=&quot;https://www.pulumi.com/images/logo/logo-on-white-box.svg?&quot; width=&quot;350&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

[![Slack](http://www.pulumi.com/images/docs/badges/slack.svg)](https://slack.pulumi.com/)
[![GitHub Discussions](https://img.shields.io/github/discussions/pulumi/pulumi)](https://github.com/pulumi/pulumi/discussions)
[![NPM version](https://badge.fury.io/js/%40pulumi%2Fpulumi.svg)](https://npmjs.com/package/@pulumi/pulumi)
[![Python version](https://badge.fury.io/py/pulumi.svg)](https://pypi.org/project/pulumi)
[![NuGet version](https://badge.fury.io/nu/pulumi.svg)](https://badge.fury.io/nu/pulumi)
[![GoDoc](https://godoc.org/github.com/pulumi/pulumi?status.svg)](https://godoc.org/github.com/pulumi/pulumi)
[![License](https://img.shields.io/github/license/pulumi/pulumi)](LICENSE)

# Infrastructure as Code in any Programming Language

&lt;a href=&quot;https://www.pulumi.com/docs/iac/get-started/&quot;&gt;
    &lt;img src=&quot;https://www.pulumi.com/images/get-started.svg?&quot; align=&quot;right&quot; width=&quot;120&quot;&gt;
&lt;/a&gt;

**Pulumi Infrastructure as Code** is the easiest way to build and deploy infrastructure, of any architecture and on any cloud, using programming languages that you already know and love. Code and ship infrastructure faster with your favorite languages and tools, and embed IaC anywhere with [Automation API](https://www.pulumi.com/docs/iac/using-pulumi/automation-api/).

Simply write code in your favorite language and Pulumi automatically provisions and manages your resources on
[AWS](https://www.pulumi.com/docs/iac/clouds/aws/),
[Azure](https://www.pulumi.com/docs/iac/clouds/azure/),
[Google Cloud Platform](https://www.pulumi.com/docs/iac/clouds/gcp/), 
[Kubernetes](https://www.pulumi.com/docs/iac/clouds/kubernetes/), and [120+ providers](https://www.pulumi.com/registry/) using an
[infrastructure-as-code](https://www.pulumi.com/what-is/what-is-infrastructure-as-code/) approach.
Skip the YAML, and use standard language features like loops, functions, classes,
and package management that you already know and love.

For example, create three web servers:

```typescript
const aws = require(&quot;@pulumi/aws&quot;);
const sg = new aws.ec2.SecurityGroup(&quot;web-sg&quot;, {
    ingress: [{ protocol: &quot;tcp&quot;, fromPort: 80, toPort: 80, cidrBlocks: [&quot;0.0.0.0/0&quot;] }],
});
for (let i = 0; i &lt; 3; i++) {
    new aws.ec2.Instance(`web-${i}`, {
        ami: &quot;ami-7172b611&quot;,
        instanceType: &quot;t2.micro&quot;,
        vpcSecurityGroupIds: [sg.id],
        userData: `#!/bin/bash
            echo &quot;Hello, World!&quot; &gt; index.html
            nohup python -m SimpleHTTPServer 80 &amp;`,
    });
}
```

Or a simple serverless timer that archives Hacker News every day at 8:30AM:

```typescript
const aws = require(&quot;@pulumi/aws&quot;);

const snapshots = new aws.dynamodb.Table(&quot;snapshots&quot;, {
    attributes: [{ name: &quot;id&quot;, type: &quot;S&quot;, }],
    hashKey: &quot;id&quot;, billingMode: &quot;PAY_PER_REQUEST&quot;,
});

aws.cloudwatch.onSchedule(&quot;daily-yc-snapshot&quot;, &quot;cron(30 8 * * ? *)&quot;, () =&gt; {
    require(&quot;https&quot;).get(&quot;https://news.ycombinator.com&quot;, res =&gt; {
        let content = &quot;&quot;;
        res.setEncoding(&quot;utf8&quot;);
        res.on(&quot;data&quot;, chunk =&gt; content += chunk);
        res.on(&quot;end&quot;, () =&gt; new aws.sdk.DynamoDB.DocumentClient().put({
            TableName: snapshots.name.get(),
            Item: { date: Date.now(), content },
        }).promise());
    }).end();
});
```

Many examples are available spanning containers, serverless, and infrastructure in
[pulumi/examples](https://github.com/pulumi/examples).

Pulumi is open source under the [Apache 2.0 license](https://github.com/pulumi/pulumi/blob/master/LICENSE), supports many languages and clouds, and is easy to extend.  This
repo contains the `pulumi` CLI, language SDKs, and core Pulumi engine, and individual libraries are in their own repos.

## Welcome

&lt;img align=&quot;right&quot; width=&quot;400&quot; src=&quot;https://www.pulumi.com/images/docs/quickstart/console.png&quot; /&gt;

* **[Get Started with Pulumi](https://www.pulumi.com/docs/iac/get-started/)**: Deploy a simple application in AWS, Azure, Google Cloud, or Kubernetes using Pulumi.

* **[Learn](https://www.pulumi.com/tutorials/)**: Follow Pulumi learning pathways to learn best practices and architectural patterns through authentic examples.

* **[Examples](https://github.com/pulumi/examples)**: Browse several examples across many languages,
  clouds, and scenarios including containers, serverless, and infrastructure.

* **[Docs](https://www.pulumi.com/docs/)**: Learn about Pulumi concepts, follow user-guides, and consult the reference documentation.

* **[Registry](https://www.pulumi.com/registry/)**: Find the Pulumi Package with the resources you need. Install the package directly into your project, browse the API documentation, and start building.

* **[Secrets Management](https://www.pulumi.com/product/secrets-management/)**: Tame secrets sprawl and configuration complexity securely across all your cloud infrastructure and applications with Pulumi ESC.

* **[Pulumi Roadmap](https://github.com/orgs/pulumi/projects/44)**: Review the planned work for the upcoming quarter and a selected backlog of issues that are on our mind but not yet scheduled.

* **[Community Slack](https://slack.pulumi.com/)**: Join us in Pulumi Community Slack. All conversations and questions are welcome.

* **[GitHub Discussions](https://github.com/pulumi/pulumi/discussions)**: Ask questions or share what you&#039;re building with Pulumi.

## &lt;a name=&quot;getting-started&quot;&gt;&lt;/a&gt;Getting Started

[![Watch the video](/youtube_preview_image.png)](https://www.youtube.com/watch?v=6f8KF6UGN7g)

See the [Get Started](https://www.pulumi.com/docs/iac/get-started/) guide to quickly get started with
Pulumi on your platform and cloud of choice.

Otherwise, the following steps demonstrate how to deploy your first Pulumi program, using AWS
Serverless Lambdas, in minutes:

1. **Install**:

    To install the latest Pulumi release, run the following (see full
    [installation instructions](https://www.pulumi.com/docs/iac/download-install/) for additional installation options):

    ```bash
    $ curl -fsSL https://get.pulumi.com/ | sh
    ```

2. **Create a Project**:

    After installing, you can get started with the `pulumi new` command:

    ```bash
    $ mkdir pulumi-demo &amp;&amp; cd pulumi-demo
    $ pulumi new hello-aws-javascript
    ```

    The `new` command offers templates for all languages and clouds.  Run it without an argument and it&#039;ll prompt
    you with available projects.  This command created an AWS Serverless Lambda project written in JavaScript.

3. **Deploy to the Cloud**:

    Run `pulumi up` to get your code to the cloud:

    ```bash
    $ pulumi up
    ```

    This makes all cloud resources needed to run your code.  Simply make edits to your project, and subsequent
    `pulumi up`s will compute the minimal diff to deploy your changes.

4. **Use Your Program**:

    Now that your code is deployed, you can interact with it.  In the above example, we can curl the endpoint:

    ```bash
    $ curl $(pulumi stack output url)
    ```

5. **Access the Logs**:

    If you&#039;re using containers or functions, Pulumi&#039;s unified logging command will show all of your logs:

    ```bash
    $ pulumi logs -f
    ```

6. **Destroy your Resources**:

    After you&#039;re done, you can remove all resources created by your program:

    ```bash
    $ pulumi destroy -y
    ```

To learn more, head over to [pulumi.com](https://pulumi.com/) for much more information, including
[tutorials](https://www.pulumi.com/tutorials/), [examples](https://github.com/pulumi/examples), and
details of the core Pulumi CLI and [programming model concepts](https://www.pulumi.com/docs/iac/concepts/).

## &lt;a name=&quot;platform&quot;&gt;&lt;/a&gt;Platform

### Languages

|    | Language | Status | Runtime | Versions |
| -- | -------- | ------ | ------- | -------- |
| &lt;img src=&quot;https://www.pulumi.com/logos/tech/logo-js.png&quot; height=38 /&gt;     | [JavaScript](https://www.pulumi.com/docs/iac/languages-sdks/javascript/) | Stable  | Node.js | [Current, Active and Maintenance LTS versions](https://nodejs.org/en/about/previous-releases)  |
| &lt;img src=&quot;https://www.pulumi.com/logos/tech/logo-ts.png&quot; height=38 /&gt;     | [TypeScript](https://www.pulumi.com/docs/iac/languages-sdks/javascript/) | Stable  | Node.js | [Current, Active and Maintenance LTS versions](https://nodejs.org/en/about/previous-releases)  |
| &lt;img src=&quot;https://www.pulumi.com/logos/tech/logo-python.svg&quot; height=38 /&gt; | [Python](https://www.pulumi.com/docs/iac/languages-sdks/python/)     | Stable  | Python | [Supported versions](https://devguide.python.org/versions/#versions) |
| &lt;img src=&quot;https://www.pulumi.com/logos/tech/logo-golang.png&quot; height=38 /&gt; | [Go](https://www.pulumi.com/docs/iac/languages-sdks/go/)             | Stable  | Go | [Supported versions](https://go.dev/doc/devel/release#policy) |
| &lt;img src=&quot;https://www.pulumi.com/logos/tech/dotnet.svg&quot; height=38 /&gt;      | [.NET (C#/F#/VB.NET)](https://www.pulumi.com/docs/iac/languages-sdks/dotnet/)     | Stable  | .NET | [Supported versions](https://dotnet.microsoft.com/en-us/platform/support/policy/dotnet-core#lifecycle)  |
| &lt;img src=&quot;https://www.pulumi.com/logos/tech/java.svg&quot; height=38 /&gt;      | [Java](https://www.pulumi.com/docs/iac/languages-sdks/java/)     | Stable  | JDK | 11+  |
| &lt;img src=&quot;https://www.pulumi.com/logos/tech/yaml.svg&quot; height=38 /&gt;      | [YAML](https://www.pulumi.com/docs/iac/languages-sdks/yaml/)     | Stable  | n/a  | n/a  |

### EOL Releases

The Pulumi CLI v1 and v2 are no longer supported. If you are not yet running v3, please consider migrating to v3 to continue getting the latest and greatest Pulumi has to offer! :muscle:

* To migrate from v2 to v3, please see our [v3 Migration Guide](https://www.pulumi.com/docs/iac/download-install/migrating-3.0/).

### Clouds

Visit the [Registry](https://www.pulumi.com/registry/) for the full list of supported cloud and infrastructure providers.

## Contributing

Visit [CONTRIBUTING.md](https://github.com/pulumi/pulumi/blob/master/CONTRIBUTING.md) for information on building Pulumi from source or contributing improvements.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[keploy/keploy]]></title>
            <link>https://github.com/keploy/keploy</link>
            <guid>https://github.com/keploy/keploy</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[API, Integration, E2E Testing Agent for Developers that actually work. Generate tests, mocks/stubs for your APIs!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/keploy/keploy">keploy/keploy</a></h1>
            <p>API, Integration, E2E Testing Agent for Developers that actually work. Generate tests, mocks/stubs for your APIs!</p>
            <p>Language: Go</p>
            <p>Stars: 11,368</p>
            <p>Forks: 1,666</p>
            <p>Stars today: 168 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://docs.keploy.io/img/keploy-logo-dark.svg?s=200&amp;v=4&quot; height=&quot;80&quot; alt=&quot;Keploy Logo&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
 &lt;a href=&quot;https://trendshift.io/repositories/3262&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/3262&quot; alt=&quot;keploy%2Fkeploy | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;&lt;b&gt;⚡️ API tests faster than unit tests, from user traffic ⚡️&lt;/b&gt;&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;🌟 The must-have tool for developers in the AI-Gen era for 90% test coverage 🌟&lt;/p&gt;


---

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Slack-4A154B?style=flat&amp;logo=slack&amp;logoColor=white&quot; alt=&quot;Slack&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.linkedin.com/company/keploy/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/LinkedIn-%230077B5.svg?style=flat&amp;logo=linkedin&amp;logoColor=white&quot; alt=&quot;LinkedIn&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.youtube.com/channel/UC6OTg7F4o0WkmNtSoob34lg&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/YouTube-%23FF0000.svg?style=flat&amp;logo=YouTube&amp;logoColor=white&quot; alt=&quot;YouTube&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/Keployio&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/X-%231DA1F2.svg?style=flat&amp;logo=X&amp;logoColor=white&quot; alt=&quot;X&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://landscape.cncf.io/?item=app-definition-and-development--continuous-integration-delivery--keploy&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/CNCF%20Landscape-5699C6?logo=cncf&amp;style=social&quot; alt=&quot;Keploy CNCF Landscape&quot; /&gt;
  &lt;/a&gt;
&lt;a href=&quot;https://github.com/Keploy/Keploy/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/keploy/keploy?color=%23EAC54F&amp;logo=github&quot; alt=&quot;GitHub Stars&quot; /&gt;&lt;/a&gt;

  &lt;a href=&quot;https://github.com/Keploy/Keploy/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/keploy/keploy?color=%23EAC54F&amp;logo=github&amp;label=Help%20us%20reach%2020K%20stars!%20Now%20at:&quot; alt=&quot;Help us reach 20k stars!&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;


[Keploy](https://keploy.io) is a **developer‑centric API and integration testing tool** that auto‑generates **tests and data‑mocks** faster than unit tests.  

It records API calls, database queries, and streaming events — then replays them as tests. Under the hood, Keploy **uses eBPF to capture traffic at the network layer,** but for you it’s completely **code‑less** and **language‑agnostic**.


&lt;img align=&quot;center&quot; src=&quot;https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-replay.gif&quot; width=&quot;100%&quot; alt=&quot;Convert API calls to API tests test cases and Data Mocks using AI&quot;/&gt;

&gt; 🐰 **Fun fact:** Keploy uses itself for testing! Check out our swanky coverage badge: [![Coverage Status](https://coveralls.io/repos/github/keploy/keploy/badge.svg?branch=main&amp;kill_cache=1)](https://coveralls.io/github/keploy/keploy?branch=main&amp;kill_cache=1) &amp;nbsp;

---

# Key Highlights

## 🎯 No code changes

Just run your app with `keploy record`. Real API + integration flows are automatically captured as tests and mocks. *(Keploy uses eBPF under the hood to capture traffic, so you **don’t need** to add any SDKs or modify code.)* 

## 📹 Record and Replay complex Flows
Keploy can record and replay complex, distributed API flows as mocks and stubs.  It&#039;s like having a very light-weight time machine for your tests—saving you tons of time!

👉 [Read the docs on record-replay](https://keploy.io/docs/keploy-explained/introduction/)

&lt;img src=&quot;https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-tc.gif&quot; width=&quot;60%&quot; alt=&quot;Convert API calls to test cases&quot;/&gt;

## 🐇 Complete Infra‑Virtualization (beyond HTTP mocks)

Unlike tools that only mock HTTP endpoints, Keploy records **databases** (Postgres, MySQL, MongoDB), **streaming/queues** (Kafka, RabbitMQ), external APIs, and more. 

It replays them deterministically so you can run tests without re‑provisioning infra.

👉 [Read the docs on infra virtualisation](https://keploy.io/docs/keploy-explained/how-keploy-works/)

&lt;img src=&quot;https://keploy-devrel.s3.us-west-2.amazonaws.com/Group+1261152745.png&quot; width=&quot;100%&quot; alt=&quot;Convert API calls to test cases&quot;/&gt;

## 🧪 Combined Test Coverage

If you’re a **developer**, you probably care about *statement* and *branch* coverage — Keploy calculates that for you. 

If you’re a **QA**, you focus more on *API schema* and *business use‑case coverage* — Keploy calculates that too. This way coverage isn’t subjective anymore. 

👉 [Read the docs on coverage](https://keploy.io/docs/server/sdk-installation/go/)

&lt;img src=&quot;https://keploy-devrel.s3.us-west-2.amazonaws.com/keploy+ai+test+gen+for+api+statement+schema+and+branch+coverage.jpg&quot; width=&quot;100%&quot; alt=&quot;ai test gen for api statement schema and branch coverage&quot;/&gt;

## 🤖 Expand API Coverage using AI

Keploy uses existing recordings, Swagger/OpenAPI Schema to find: boundary values, missing/extra fields, wrong types, out‑of‑order sequences, retries/timeouts. 

This helps expand API Schema, Statement, and Branch Coverage. 

👉 [Read the docs on coverage](https://app.keploy.io/)

&lt;img src=&quot;https://keploy-devrel.s3.us-west-2.amazonaws.com/ai+test+case+generation+that+works.png&quot; width=&quot;100%&quot; alt=&quot;ai test gen for api statement schema and branch coverage&quot;/&gt;


### Other Capabilities

- 🌐 **CI/CD Integration:** Run tests with mocks anywhere you like—locally on the CLI, in your CI pipeline (Jenkins, Github Actions..) , or even across a Kubernetes cluster. [Read more](https://keploy.io/docs/running-keploy/api-testing-cicd/)

- 🎭 **Multi-Purpose Mocks**: You can also use Keploy-generated Mocks, as server Tests!

- 📊 **Reporting:** Unified reports for API, integration, unit, and e2e coverage with insights directly in your CI or PRs.
- 🖥️ **Console:** A developer-friendly console to view, manage, and debug recorded tests and mocks.
- ⏱️ **Time Freezing:** Deterministically replay tests by freezing system time during execution. [Read more](https://keploy.io/docs/keploy-cloud/time-freezing/)
- 📚 **Mock Registry:** Centralized registry to manage, reuse, and version mocks across teams and environments. [Read more](https://keploy.io/docs/keploy-cloud/mock-registry/)

---

## Quick Start

### 1. Install Keploy Agent

```bash
curl --silent -O -L https://keploy.io/install.sh &amp;&amp; source install.sh
```

### 2. Record Test Cases

Start your app under Keploy to convert real API calls into tests and mocks.

```bash
keploy record -c &quot;CMD_TO_RUN_APP&quot;
```

Example for Python:

```bash
keploy record -c &quot;python main.py&quot;
```

### 3. Run Tests

Run tests offline without external dependencies.

```bash
keploy test -c &quot;CMD_TO_RUN_APP&quot; --delay 10
```

## Resources
### - 📘 [Installation](https://keploy.io/docs/server/installation/)
### - 🏁 [QuickStarts](https://keploy.io/docs/quickstart/quickstart-filter/)


---


## Languages &amp;amp; Frameworks (Any stack)

Because Keploy intercepts at the **network layer (eBPF)**, it works with **any language, framework, or runtime**—no SDK required. 
&gt; Note: Some of the dependencies are not open-source by nature because their protocols and parsings are not open-sourced. It&#039;s not supported in Keploy enterprise. 

&lt;p align=&quot;center&quot;&gt;

&lt;!-- Languages --&gt;
&lt;img src=&quot;https://img.shields.io/badge/Go-00ADD8?logo=go&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Java-ED8B00?logo=openjdk&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Node.js-43853D?logo=node.js&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Python-3776AB?logo=python&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Rust-000000?logo=rust&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/C%23-239120?logo=csharp&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/C/C++-00599C?logo=cplusplus&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/TypeScript-3178C6?logo=typescript&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Scala-DC322F?logo=scala&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Kotlin-7F52FF?logo=kotlin&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Swift-FA7343?logo=swift&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Dart-0175C2?logo=dart&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/PHP-777BB4?logo=php&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Ruby-CC342D?logo=ruby&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Elixir-4B275F?logo=elixir&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/.NET-512BD4?logo=dotnet&amp;amp;logoColor=white&quot; /&gt;

&lt;!-- Protocols &amp;amp; infra commonly virtualized --&gt;
&lt;img src=&quot;https://img.shields.io/badge/gRPC-5E35B1?logo=grpc&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/GraphQL-E10098?logo=graphql&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/HTTP%2FREST-0A84FF?logo=httpie&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Kafka-231F20?logo=apachekafka&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/RabbitMQ-FF6600?logo=rabbitmq&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/PostgreSQL-4169E1?logo=postgresql&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/MySQL-4479A1?logo=mysql&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/MongoDB-47A248?logo=mongodb&amp;amp;logoColor=white&quot; /&gt;
&lt;img src=&quot;https://img.shields.io/badge/Redis-DC382D?logo=redis&amp;amp;logoColor=white&quot; /&gt;
&lt;/p&gt;

---

## Questions? 

### Book a Live Demo / Enterprise Support

Want a guided walkthrough, dedicated support, or help planning enterprise rollout?

&lt;p&gt;
  &lt;a href=&quot;https://calendar.app.google/4ZKd1nz9A5wLuP4W7&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Request%20a%20Demo-Email-2ea44f?logo=gmail&quot; /&gt;
  &lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Chat%20with%20Us-Slack-4A154B?logo=slack&amp;amp;logoColor=white&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Optional: replace with your scheduling link (Cal.com/Calendly) --&gt;
  &lt;!-- &lt;a href=&quot;https://cal.com/keploy/demo&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Book%20via%20Calendar-Cal.com-111111&quot; /&gt;&lt;/a&gt; --&gt;
&lt;/p&gt;

Prefer a calendar invite? Mention your availability in the email—we’ll send a **calendar invite** right away.

---

## Documentation &amp; Community

- 📘 [Documentation](https://keploy.io/docs/) — Explore the full docs
- 💬 [Slack Community](https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg) — Join the conversation
- 📜 [Contribution Guidelines](https://keploy.io/docs/keploy-explained/contribution-guide/)
- ❤️ [Code of Conduct](https://github.com/keploy/keploy/blob/main/CODE_OF_CONDUCT.md)
- 📢 [Blog](https://keploy.io/blog/) — Read articles and updates

---

## Contribute &amp; Collaborate

Whether you&#039;re new or experienced, your input matters. Help us improve Keploy by contributing code, reporting issues, or sharing feedback.

Together, let&#039;s build better testing tools for modern applications.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[temporalio/temporal]]></title>
            <link>https://github.com/temporalio/temporal</link>
            <guid>https://github.com/temporalio/temporal</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[Temporal service]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/temporalio/temporal">temporalio/temporal</a></h1>
            <p>Temporal service</p>
            <p>Language: Go</p>
            <p>Stars: 15,972</p>
            <p>Forks: 1,126</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>&lt;div class=&quot;title-block&quot; style=&quot;text-align: center;&quot; align=&quot;center&quot;&gt;

# Temporal—durable execution platform

&lt;p&gt;&lt;img title=&quot;temporal logo&quot; src=&quot;https://avatars.githubusercontent.com/u/56493103?s=320&quot; width=&quot;320&quot; height=&quot;320&quot;&gt;&lt;/p&gt;

[![GitHub Release](https://img.shields.io/github/v/release/temporalio/temporal)](https://github.com/temporalio/temporal/releases/latest)
[![GitHub License](https://img.shields.io/github/license/temporalio/temporal)](https://github.com/temporalio/temporal/blob/main/LICENSE)
[![Code Coverage](https://img.shields.io/badge/codecov-report-blue)](https://app.codecov.io/gh/temporalio/temporal)
[![Community](https://img.shields.io/static/v1?label=community&amp;message=get%20help&amp;color=informational)](https://community.temporal.io)
[![Go Report Card](https://goreportcard.com/badge/github.com/temporalio/temporal)](https://goreportcard.com/report/github.com/temporalio/temporal)

**[Introduction](#introduction) &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Getting Started](#getting-started) &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Contributing](#contributing) &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Temporal Docs](https://docs.temporal.io/) &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Temporal 101](https://learn.temporal.io/courses/temporal_101/)**

&lt;/div&gt;

## Introduction

Temporal is a durable execution platform that enables developers to build scalable applications without sacrificing productivity or reliability.
The Temporal server executes units of application logic called Workflows in a resilient manner that automatically handles intermittent failures, and retries failed operations.

Temporal is a mature technology that originated as a fork of Uber&#039;s Cadence.
It is developed by [Temporal Technologies](https://temporal.io/), a startup by the creators of Cadence.

[![image](https://github.com/temporalio/temporal/assets/251288/693d18b5-01de-4a3b-b47b-96347b84f610)](https://youtu.be/wIpz4ioK0gI &#039;Getting to know Temporal&#039;)

## Getting Started

### Download and Start Temporal Server Locally

Execute the following commands to start a pre-built image along with all the dependencies.

```bash
brew install temporal
temporal server start-dev
```

Refer to [Temporal CLI](https://docs.temporal.io/cli/#installation) documentation for more installation options.

### Run the Samples

Clone or download samples for [Go](https://github.com/temporalio/samples-go) or [Java](https://github.com/temporalio/samples-java) and run them with the local Temporal server.
We have a number of [HelloWorld type scenarios](https://github.com/temporalio/samples-java#helloworld) available, as well as more advanced ones. Note that the sets of samples are currently different between Go and Java.

### Use CLI

Use [Temporal CLI](https://docs.temporal.io/cli/) to interact with the running Temporal server.

```bash
temporal operator namespace list
temporal workflow list
```

### Use Temporal Web UI

Try [Temporal Web UI](https://docs.temporal.io/web-ui) by opening [http://localhost:8233](http://localhost:8233) for viewing your sample workflows executing on Temporal.

## Repository

This repository contains the source code of the Temporal server. To implement Workflows, Activities and Workers, use one of the [supported languages](https://docs.temporal.io/dev-guide/).

## Contributing

We&#039;d love your help in making Temporal great.

Helpful links to get started:

- [work on or propose a new feature](https://github.com/temporalio/proposals)
- [learn about the Temporal Server architecture](./docs/architecture/README.md)
- [learn how to build and run the Temporal Server locally](./CONTRIBUTING.md)
- [learn about Temporal Server testing tools and best practices](./docs/development/testing.md)
- join the Temporal community [forum](https://community.temporal.io) and [Slack](https://t.mp/slack)

## License

[MIT License](https://github.com/temporalio/temporal/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[stacklok/toolhive]]></title>
            <link>https://github.com/stacklok/toolhive</link>
            <guid>https://github.com/stacklok/toolhive</guid>
            <pubDate>Sun, 05 Oct 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[ToolHive makes deploying MCP servers easy, secure and fun]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stacklok/toolhive">stacklok/toolhive</a></h1>
            <p>ToolHive makes deploying MCP servers easy, secure and fun</p>
            <p>Language: Go</p>
            <p>Stars: 1,255</p>
            <p>Forks: 121</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p float=&quot;left&quot;&gt;
  &lt;picture&gt;
    &lt;img src=&quot;docs/images/toolhive-icon-1024.png&quot; alt=&quot;ToolHive Studio logo&quot; height=&quot;100&quot; align=&quot;middle&quot; /&gt;
  &lt;/picture&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/images/toolhive-wordmark-white.png&quot;&gt;
    &lt;img src=&quot;docs/images/toolhive-wordmark-black.png&quot; alt=&quot;ToolHive wordmark&quot; width=&quot;500&quot; align=&quot;middle&quot; hspace=&quot;20&quot; /&gt;
  &lt;/picture&gt;
  &lt;picture&gt;
    &lt;img src=&quot;docs/images/toolhive.png&quot; alt=&quot;ToolHive mascot&quot; width=&quot;125&quot; align=&quot;middle&quot;/&gt;
  &lt;/picture&gt;
&lt;/p&gt;

[![Release][release-img]][release] [![Build status][ci-img]][ci]
[![Coverage Status][coveralls-img]][coveralls]
[![License: Apache 2.0][license-img]][license]
[![Star on GitHub][stars-img]][stars] [![Discord][discord-img]][discord]

# ToolHive - simplify and secure MCP servers

**Run any Model Context Protocol (MCP) server — securely, instantly, anywhere.**

ToolHive is the easiest way to discover, deploy, and manage MCP servers. Launch
any MCP server in a locked-down container with a single command. No manual
setup, no security headaches, no runtime hassles.

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/images/toolhive-diagram-dark.svg&quot;&gt;
  &lt;img src=&quot;docs/images/toolhive-diagram-light.svg&quot; alt=&quot;ToolHive diagram&quot; width=&quot;800&quot; style=&quot;padding: 20px 0&quot; /&gt;
&lt;/picture&gt;

---

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;

## Why ToolHive?

- **Instant deployment:** Start any MCP server with one click or command, using
  Docker or Kubernetes.
- **Secure by default:** Every server runs in an isolated container with only
  the permissions it needs. Secrets are managed securely, never in plaintext.
- **Works everywhere:** Use the UI and CLI for local development, or the
  Kubernetes Operator for production and scale.
- **Seamless integration:** ToolHive auto-configures popular clients like GitHub
  Copilot, Cursor, and more.

ToolHive is available as a GUI desktop app, CLI, and Kubernetes Operator.

&lt;br&gt;
&lt;/td&gt;
&lt;td width=&quot;50%&quot; align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/images/toolhive-sources-dark.svg&quot;&gt;
    &lt;img src=&quot;docs/images/toolhive-sources-light.svg&quot; alt=&quot;ToolHive sources diagram&quot; width=&quot;400px&quot; /&gt;
  &lt;/picture&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

## Quick links

- 📚 [Documentation](https://docs.stacklok.com/toolhive/)
- 🚀 Quickstart guides:
  - [Desktop app](https://docs.stacklok.com/toolhive/tutorials/quickstart-ui)
  - [CLI](https://docs.stacklok.com/toolhive/tutorials/quickstart-cli)
  - [Kubernetes Operator](https://docs.stacklok.com/toolhive/tutorials/quickstart-k8s)
- 💬 [Discord](https://discord.gg/stacklok)

---

## Contributing

We welcome contributions and feedback from the community!

- 🐛 [Report issues](https://github.com/stacklok/toolhive/issues)
- 💬 [Join our Discord](https://discord.gg/stacklok)

If you have ideas, suggestions, or want to get involved, check out our
contributing guide or open an issue. Join us in making ToolHive even better!

Contribute to the CLI, API, and Kubernetes Operator:

- 🤝 [Contributing guide](./CONTRIBUTING.md)
- 📖 [Developer guide](./docs/README.md)

Contribute to the desktop UI:

- 🖥️ [Desktop UI repository](https://github.com/stacklok/toolhive-studio)

Contribute to the documentation:

- 📚 [Documentation repository](https://github.com/stacklok/docs-website)

---

## License

This project is licensed under the [Apache 2.0 License](./LICENSE).

&lt;!-- Badge links --&gt;
&lt;!-- prettier-ignore-start --&gt;
[release-img]: https://img.shields.io/github/v/release/stacklok/toolhive?style=flat&amp;label=Latest%20version
[release]: https://github.com/stacklok/toolhive/releases/latest
[ci-img]: https://img.shields.io/github/actions/workflow/status/stacklok/toolhive/run-on-main.yml?style=flat&amp;logo=github&amp;label=Build
[ci]: https://github.com/stacklok/toolhive/actions/workflows/run-on-main.yml
[coveralls-img]: https://coveralls.io/repos/github/stacklok/toolhive/badge.svg?branch=main
[coveralls]: https://coveralls.io/github/stacklok/toolhive?branch=main
[license-img]: https://img.shields.io/badge/License-Apache2.0-blue.svg?style=flat
[license]: https://opensource.org/licenses/Apache-2.0
[stars-img]: https://img.shields.io/github/stars/stacklok/toolhive.svg?style=flat&amp;logo=github&amp;label=Stars
[stars]: https://github.com/stacklok/toolhive
[discord-img]: https://img.shields.io/discord/1184987096302239844?style=flat&amp;logo=discord&amp;logoColor=white&amp;label=Discord
[discord]: https://discord.gg/stacklok
&lt;!-- prettier-ignore-end --&gt;

&lt;!-- markdownlint-disable-file first-line-heading no-inline-html --&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>