<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Sun, 24 Aug 2025 00:05:26 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[SpecterOps/BloodHound]]></title>
            <link>https://github.com/SpecterOps/BloodHound</link>
            <guid>https://github.com/SpecterOps/BloodHound</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[Six Degrees of Domain Admin]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/SpecterOps/BloodHound">SpecterOps/BloodHound</a></h1>
            <p>Six Degrees of Domain Admin</p>
            <p>Language: Go</p>
            <p>Stars: 2,225</p>
            <p>Forks: 227</p>
            <p>Stars today: 153 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
        &lt;img src=&quot;cmd/ui/public/img/BHCE_Vertical_RedField.svg&quot; alt=&quot;BloodHound Community Edition&quot; width=&#039;400&#039; /&gt;
    &lt;/picture&gt;
&lt;/p&gt;

&lt;hr /&gt;

BloodHound is a monolithic web application composed of an embedded React frontend with [Sigma.js](https://www.sigmajs.org/) and a [Go](https://go.dev/) based REST API backend. It is deployed with a [Postgresql](https://www.postgresql.org/) application database and a [Neo4j](https://neo4j.com/) graph database, and is fed by the [SharpHound](https://github.com/SpecterOps/SharpHound) and [AzureHound](https://github.com/SpecterOps/AzureHound) data collectors.

BloodHound leverages graph theory to reveal hidden and often unintended relationships across identity and access management systems. Powered by [OpenGraph](https://specterops.io/opengraph/), BloodHound now supports comprehensive analysis beyond Active Directory and Azure environments, enabling users to map complex privilege relationships across [diverse identity platforms](https://bloodhound.specterops.io/opengraph/library). Attackers can utilize BloodHound to rapidly discover sophisticated attack paths otherwise impossible to identify manually, while defenders can proactively identify and mitigate these risks. Both red and blue teams benefit from BloodHound&#039;s expanded capabilities, gaining deeper insights into identity and privilege structures across their entire security landscape.

BloodHound CE is created and maintained by the [SpecterOps](https://specterops.io/) team who also brought you [BloodHound Enterprise](https://specterops.io/bloodhound-overview/). The original BloodHound was created by [@\_wald0](https://www.twitter.com/_wald0), [@CptJesus](https://twitter.com/CptJesus), and [@harmj0y](https://twitter.com/harmj0y).

## Running BloodHound Community Edition
Please refer to the [Quickstart Guide for BloodHound Community Edition](https://bloodhound.specterops.io/get-started/quickstart/community-edition-quickstart), which is part of the [BloodHound documentation](https://bloodhound.specterops.io).

## Useful Links

- [BloodHound Documentation](https://bloodhound.specterops.io/)
- [BloodHound Community Edition Quickstart Guide](https://bloodhound.specterops.io/get-started/quickstart/community-edition-quickstart)
- [BloodHound Slack](https://slack.specterops.io)
- [OpenGraph Documentation](https://bloodhound.specterops.io/opengraph/overview)
- [Wiki](https://github.com/SpecterOps/BloodHound/wiki)
- [Docker Compose Example](./examples/docker-compose/README.md)
- [Developer Quick Start Guide](https://github.com/SpecterOps/BloodHound/wiki/Development)
- [Contributing Guide](https://github.com/SpecterOps/BloodHound/wiki/Contributing)
- [Contributors](./CONTRIBUTORS.md)

## Contact

Please check out the [Contact page](https://github.com/SpecterOps/BloodHound/wiki/Contact) in our wiki for details on how to reach out with questions and suggestions.

## Licensing

```
Copyright 2025 Specter Ops, Inc.

Licensed under the Apache License, Version 2.0
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```

Unless otherwise annotated by a lower-level LICENSE file or license header, all files in this repository are released
under the `Apache-2.0` license. A full copy of the license may be found in the top-level [LICENSE](LICENSE) file.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[oauth2-proxy/oauth2-proxy]]></title>
            <link>https://github.com/oauth2-proxy/oauth2-proxy</link>
            <guid>https://github.com/oauth2-proxy/oauth2-proxy</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oauth2-proxy/oauth2-proxy">oauth2-proxy/oauth2-proxy</a></h1>
            <p>A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.</p>
            <p>Language: Go</p>
            <p>Stars: 11,840</p>
            <p>Forks: 1,779</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>[![Continuous Integration](https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml/badge.svg)](https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml)
[![Go Report Card](https://goreportcard.com/badge/github.com/oauth2-proxy/oauth2-proxy)](https://goreportcard.com/report/github.com/oauth2-proxy/oauth2-proxy)
[![GoDoc](https://godoc.org/github.com/oauth2-proxy/oauth2-proxy?status.svg)](https://godoc.org/github.com/oauth2-proxy/oauth2-proxy)
[![MIT licensed](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)
[![Maintainability](https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/maintainability)](https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/maintainability)
[![Test Coverage](https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/test_coverage)](https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/test_coverage)

![OAuth2 Proxy](docs/static/img/logos/OAuth2_Proxy_horizontal.svg)

OAuth2-Proxy is a flexible, open-source tool that can act as either a standalone reverse proxy or a middleware component integrated into existing reverse proxy or load balancer setups. It provides a simple and secure way to protect your web applications with OAuth2 / OIDC authentication. As a reverse proxy, it intercepts requests to your application and redirects users to an OAuth2 provider for authentication. As a middleware, it can be seamlessly integrated into your existing infrastructure to handle authentication for multiple applications.

OAuth2-Proxy supports a lot of OAuth2 as well as OIDC providers. Either through a generic OIDC client or a specific implementation for Google, Microsoft Entra ID, GitHub, login.gov and others. Through specialised provider implementations oauth2-proxy can extract more details about the user like preferred usernames and groups. Those details can then be forwarded as HTTP headers to your upstream applications.

![Simplified Architecture](docs/static/img/simplified-architecture.svg)

## Get Started

OAuth2-Proxy&#039;s [Installation Docs](https://oauth2-proxy.github.io/oauth2-proxy/installation) cover how to install and configure your setup. Additionally you can take a further look at the [example setup files](https://github.com/oauth2-proxy/oauth2-proxy/tree/master/contrib/local-environment).

## Releases

### Binaries
We publish oauth2-proxy as compiled binaries on GitHub for all major architectures as well as more exotic ones like `ppc64le` as well as `s390x`.

Check out the [latest release](https://github.com/oauth2-proxy/oauth2-proxy/releases/latest).

### Images

From `v7.6.0` and up the base image has been changed from Alpine to [GoogleContainerTools/distroless](https://github.com/GoogleContainerTools/distroless).
This image comes with even fewer installed dependencies and thus should improve security. The image therefore is also slightly smaller than Alpine.
For debugging purposes (and those who really need it. e.g. `armv6`) we still provide images based on Alpine. The tags of these images are suffixed with `-alpine`.

Since 2023-11-18 we build nightly images directly from the `master` branch and provide them at `quay.io/oauth2-proxy/oauth2-proxy-nightly`.
These images are considered unstable and therefore should **NOT** be used for production purposes unless you know what you&#039;re doing.

## Sponsors

![Microsoft](https://upload.wikimedia.org/wikipedia/commons/9/96/Microsoft_logo_%282012%29.svg)
Microsoft Azure credits for open source projects

Would you like to sponsor the project then please contact us at [sponsors@oauth2-proxy.dev](mailto:sponsors@oauth2-proxy.dev)

## Getting Involved
[![Slack](https://img.shields.io/badge/slack-Gopher_%23oauth2--proxy-red?logo=slack)](https://gophers.slack.com/archives/CM2RSS25N)

Join the #oauth2-proxy [Slack channel](https://gophers.slack.com/archives/CM2RSS25N) to chat with other users of oauth2-proxy or reach out to the maintainers directly. Use the [public invite link](https://invite.slack.golangbridge.org/) to get an invite for the Gopher Slack space.

OAuth2-Proxy is a community-driven project. We rely on the contribut️ions of our users to continually improve it. While review times can vary, we appreciate your patience and understanding. As a volunteer-driven project, we strive to keep this project stable and might take longer to merge changes.

If you want to contribute to the project. Please see our [Contributing](https://oauth2-proxy.github.io/oauth2-proxy/community/contribution) guide.

Who uses OAuth2-Proxy? Have a look at our new [ADOPTERS](ADOPTERS.md) file and
feel free to open a PR to add your organisation.

Thanks to all the people who already contributed ❤

&lt;a href=&quot;https://github.com/oauth2-proxy/oauth2-proxy/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=oauth2-proxy/oauth2-proxy&amp;columns=15&amp;max=75&quot; /&gt;
  &lt;img src=&quot;https://img.shields.io/github/contributors/oauth2-proxy/oauth2-proxy&quot; /&gt;
&lt;/a&gt;

Made with [contrib.rocks](https://contrib.rocks).

## Security

If you believe you have found a vulnerability within OAuth2 Proxy or any of its dependencies, please do **NOT** open an issue or PR on GitHub, please do **NOT** post any details publicly.

Security disclosures **MUST** be done in private. If you have found an issue that you would like to bring to the attention of the maintainers, please compose an email and send it to the list of people listed in our [MAINTAINERS](MAINTAINERS) file.

For more details read our full [Security Docs](https://oauth2-proxy.github.io/oauth2-proxy/community/security#security-disclosures)

### Security Notice for v6.0.0 and older

If you are running a version older than v6.0.0 we **strongly recommend** to the current version.

See [open redirect vulnerability](https://github.com/oauth2-proxy/oauth2-proxy/security/advisories/GHSA-5m6c-jp6f-2vcv) for details.

## Repository History

**2018-11-27:** This repository was forked from [bitly/OAuth2_Proxy](https://github.com/bitly/oauth2_proxy). Versions v3.0.0 and up are from this fork and will have diverged from any changes in the original fork. A list of changes can be seen in the [CHANGELOG](CHANGELOG.md).

**2020-03-29:** This project was formerly hosted as `pusher/oauth2_proxy` but has been renamed to `oauth2-proxy/oauth2-proxy`. Going forward, all images shall be available at `quay.io/oauth2-proxy/oauth2-proxy` and binaries will be named `oauth2-proxy`.

## License

OAuth2-Proxy is distributed under [The MIT License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[edoardottt/cariddi]]></title>
            <link>https://github.com/edoardottt/cariddi</link>
            <guid>https://github.com/edoardottt/cariddi</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[Take a list of domains, crawl urls and scan for endpoints, secrets, api keys, file extensions, tokens and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/edoardottt/cariddi">edoardottt/cariddi</a></h1>
            <p>Take a list of domains, crawl urls and scan for endpoints, secrets, api keys, file extensions, tokens and more</p>
            <p>Language: Go</p>
            <p>Stars: 2,658</p>
            <p>Forks: 237</p>
            <p>Stars today: 50 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/edoardottt/images/blob/main/cariddi/logo.png&quot;&gt;&lt;br&gt;
  &lt;b&gt;Take a list of domains, crawl urls and scan for endpoints, secrets, api keys, file extensions, tokens and more&lt;/b&gt;&lt;br&gt;
  &lt;br&gt;
  &lt;!-- go-report-card --&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/edoardottt/cariddi&quot;&gt;
    &lt;img src=&quot;https://goreportcard.com/badge/github.com/edoardottt/cariddi&quot; alt=&quot;go-report-card&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- workflows --&gt;
  &lt;a href=&quot;https://github.com/edoardottt/cariddi/actions&quot;&gt;
    &lt;img src=&quot;https://github.com/edoardottt/cariddi/actions/workflows/go.yml/badge.svg?branch=main&quot; alt=&quot;workflows&quot; /&gt;
  &lt;/a&gt;
  &lt;br&gt;
  &lt;sub&gt;
    Coded with 💙 by edoardottt
  &lt;/sub&gt;
  &lt;br&gt;
  &lt;!--Tweet button--&gt;
  &lt;a href=&quot;https://twitter.com/intent/tweet?url=https://github.com/edoardottt/cariddi&amp;text=Take%20a%20list%20of%20domains,%20crawl%20urls%20and%20scan%20for%20endpoints,%20secrets,%20api%20keys,%20file%20extensions,%20tokens%20and%20more...%20%23network%20%23security%20%23infosec%20%23oss%20%23github%20%23bugbounty%20%23linux&quot; target=&quot;_blank&quot;&gt;Share on Twitter!
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#installation-&quot;&gt;Install&lt;/a&gt; •
  &lt;a href=&quot;#usage-&quot;&gt;Usage&lt;/a&gt; •
  &lt;a href=&quot;#get-started-&quot;&gt;Get Started&lt;/a&gt; •
  &lt;a href=&quot;#changelog-&quot;&gt;Changelog&lt;/a&gt; •
  &lt;a href=&quot;#contributing-&quot;&gt;Contributing&lt;/a&gt; •
  &lt;a href=&quot;#license-&quot;&gt;License&lt;/a&gt;
&lt;/p&gt;

&lt;!--[![asciicast](https://asciinema.org/a/415989.svg)](https://asciinema.org/a/415989)--&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/edoardottt/images/blob/main/cariddi/cariddi.gif&quot;&gt;
&lt;/p&gt;

Installation 📡
----------

### Homebrew

```console
brew install cariddi
```

### Snap

```console
sudo snap install cariddi
```

### Golang

```console
go install -v github.com/edoardottt/cariddi/cmd/cariddi@latest
```

### Pacman

```console
pacman -Syu cariddi
```

### Building from source

You need [Go](https://go.dev/) (&gt;=1.23)

&lt;details&gt;
  &lt;summary&gt;Building from source for Linux and Windows&lt;/summary&gt;

#### Linux

```console
git clone https://github.com/edoardottt/cariddi.git
cd cariddi
go get ./...
make linux # (to install)
make unlinux # (to uninstall)
```

One-liner: `git clone https://github.com/edoardottt/cariddi.git &amp;&amp; cd cariddi &amp;&amp; go get ./... &amp;&amp; make linux`

#### Windows 

Note that the executable works only in cariddi folder.

```console
git clone https://github.com/edoardottt/cariddi.git
cd cariddi
go get ./...
.\make.bat windows # (to install)
.\make.bat unwindows # (to uninstall)
```

&lt;/details&gt;

Usage 💡
----------

If you want to scan only a single target you can use

```console
echo https://edoardottt.com/ | cariddi
```

With multiple targets you can use a file instead, e.g. urls.txt containing:

```console
https://edoardottt.com/
http://testphp.vulnweb.com/
```

For Windows:

- use `powershell.exe -Command &quot;cat urls.txt | .\cariddi.exe&quot;` inside the Command prompt
- or just `cat urls.txt | cariddi.exe` using PowerShell

### Basics

- `cariddi -version` (Print the version)
- `cariddi -h` (Print the help)
- `cariddi -examples` (Print the examples)

### Scan options

- `cat urls.txt | cariddi -intensive` (Crawl searching also subdomains, same as `*.target.com`)
- `cat urls.txt | cariddi -s` (Hunt for secrets)
- `cat urls.txt | cariddi -err` (Hunt for errors in websites)
- `cat urls.txt | cariddi -e` (Hunt for juicy endpoints)
- `cat urls.txt | cariddi -info` (Hunt for useful informations in websites)
- `cat urls.txt | cariddi -ext 2` (Hunt for juicy (level 2 out of 7) files)
- `cat urls.txt | cariddi -e -ef endpoints_file` (Hunt for custom endpoints)
- `cat urls.txt | cariddi -s -sf secrets_file` (Hunt for custom secrets)
- `cat urls.txt | cariddi -ie pdf,png,jpg` (Ignore these extensions while scanning)

Default: png, svg, jpg, jpeg, bmp, jfif, gif, webp, woff, woff2, ttf, tiff, tif are ignored while scanning for secrets, info and errors.

### Configuration

- `cat urls.txt | cariddi -proxy http://127.0.0.1:8080` (Set a Proxy, http and socks5 supported)
- `cat urls.txt | cariddi -d 2` (2 seconds between a page crawled and another)
- `cat urls.txt | cariddi -c 200` (Set the concurrency level to 200)
- `cat urls.txt | cariddi -i forum,blog,community,open` (Ignore urls containing these words)
- `cat urls.txt | cariddi -it ignore_file` (Ignore urls containing at least one line in the input file)
- `cat urls.txt | cariddi -cache` (Use the .cariddi_cache folder as cache)
- `cat urls.txt | cariddi -t 5` (Set the timeout for the requests)
- `cat urls.txt | cariddi -headers &quot;Cookie: auth=admin;type=2;; X-Custom: customHeader&quot;`
- `cat urls.txt | cariddi -headersfile headers.txt` (Read from an external file custom headers)
- `cat urls.txt | cariddi -ua &quot;Custom User Agent&quot;` (Use a custom User Agent)
- `cat urls.txt | cariddi -rua` (Use a random browser user agent on every request)

### Output

- `cat urls.txt | cariddi -plain` (Print only results)
- `cat urls.txt | cariddi -ot target_name` (Results in txt file)
- `cat urls.txt | cariddi -oh target_name` (Results in html file)
- `cat urls.txt | cariddi -json` (Print the output as JSON in stdout)
- `cat urls.txt | cariddi -sr` (Store HTTP responses)
- `cat urls.txt | cariddi -debug` (Print debug information while crawling)
- `cat urls.txt | cariddi -md 3` (Max 3 depth levels)

Get Started 🎉
----------

`cariddi -h` prints the help.

```console
Usage of cariddi:
  -c int
     Concurrency level. (default 20)
  -cache
     Use the .cariddi_cache folder as cache.
  -d int
     Delay between a page crawled and another.
  -debug
     Print debug information while crawling.
  -e Hunt for juicy endpoints.
  -ef string
     Use an external file (txt, one per line) to use custom parameters for endpoints hunting.
  -err
     Hunt for errors in websites.
  -examples
     Print the examples.
  -ext int
     Hunt for juicy file extensions. Integer from 1(juicy) to 7(not juicy).
  -h Print the help.
  -headers string
     Use custom headers for each request E.g. -headers &quot;Cookie: auth=yes;;Client: type=2&quot;.
  -headersfile string
     Read from an external file custom headers (same format of headers flag).
  -json
     Print the output as JSON in stdout.
  -md
     Maximum depth level the crawler will follow from the initial target URL.
  -i string
     Ignore the URL containing at least one of the elements of this array.
  -ie value
     Comma-separated list of extensions to ignore while scanning.
  -info
     Hunt for useful informations in websites.
  -intensive
     Crawl searching for resources matching 2nd level domain.
  -it string
     Ignore the URL containing at least one of the lines of this file.
  -oh string
     Write the output into an HTML file.
  -ot string
     Write the output into a TXT file.
  -plain
     Print only the results.
  -proxy string
     Set a Proxy to be used (http and socks5 supported).
  -rua
     Use a random browser user agent on every request.
  -s Hunt for secrets.
  -sf string
     Use an external file (txt, one per line) to use custom regexes for secrets hunting.
  -sr
     Store HTTP responses.
  -t int
     Set timeout for the requests. (default 10)
  -ua string
     Use a custom User Agent.
  -version
     Print the version.
```

&lt;details&gt;
  &lt;summary&gt;Click to understand &lt;strong&gt;How to integrate cariddi with Burpsuite&lt;/strong&gt;&lt;/summary&gt;

   Normally you use Burpsuite within your browser, so you just have to trust the burpsuite&#039;s certificate in the browser and you&#039;re done.  
   In order to use cariddi with the BurpSuite proxy you should do some steps further.  

   If you try to use cariddi with the option `-proxy http://127.0.0.1:8080` you will find this error in the burpsuite error log section:  

   ```bash
   Received fatal alert: bad_certificate (or something similar related to the certificate).
   ```

   To make cariddi working fine with Burpsuite you have also to trust the certificate within your entire pc, not just only the browser. These are the steps you have to follow:

   Go to Proxy tab in Bupsuite, then Options. Click on the CA Certificate button and export Certificate in DER format  

   ```bash
   openssl x509 -in burp.der -inform DER -out burp.pem -outform PEM
   sudo chown root:root burp.pem
   sudo chmod 644 burp.pem
   sudo cp burp.pem /usr/local/share/ca-certificates/
   sudo c_rehash
   cd /etc/ssl/certs/
   sudo ln -s /usr/local/share/ca-certificates/burp.pem
   sudo c_rehash .
   ```

   Source: Trust Burp Proxy certificate in Debian/Ubuntu  

   After these steps, in order to use cariddi with Burpsuite you have to:  

   1. Open Burpsuite, making sure that the proxy is listening.  
   2. Use cariddi with the flag `-proxy http://127.0.0.1:8080`.  
   3. You will see that requests and responses will be logged in Burpsuite.

&lt;/details&gt;

Changelog 📌
-------

Detailed changes for each release are documented in the [release notes](https://github.com/edoardottt/cariddi/releases).

Contributing 🛠
-------

Just open an [issue](https://github.com/edoardottt/cariddi/issues)/[pull request](https://github.com/edoardottt/cariddi/pulls).

Before opening a pull request, download [golangci-lint](https://golangci-lint.run/usage/install/) and run

```console
golangci-lint run
```

If there aren&#039;t errors, go ahead :)

Test using [https://edoardottt.github.io/cariddi-test/](https://edoardottt.github.io/cariddi-test/)

```console
echo &quot;https://edoardottt.github.io/cariddi-test/&quot; | cariddi
```

**Help me build this!**

Special thanks to: [go-colly](http://go-colly.org/), [ocervell](https://github.com/ocervell), [zricethezav](https://github.com/gitleaks/gitleaks/blob/master/config/gitleaks.toml), [projectdiscovery](https://github.com/projectdiscovery/nuclei-templates/tree/master/file/keys), [tomnomnom](https://github.com/tomnomnom/gf/tree/master/examples), [RegexPassive](https://github.com/hahwul/RegexPassive) and [all the contributors](https://github.com/edoardottt/cariddi/graphs/contributors).

License 📝
-------

This repository is under [GNU General Public License v3.0](https://github.com/edoardottt/cariddi/blob/main/LICENSE).  
[edoardottt.com](https://edoardottt.com/) to contact me.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[GoogleCloudPlatform/kubectl-ai]]></title>
            <link>https://github.com/GoogleCloudPlatform/kubectl-ai</link>
            <guid>https://github.com/GoogleCloudPlatform/kubectl-ai</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[AI powered Kubernetes Assistant]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GoogleCloudPlatform/kubectl-ai">GoogleCloudPlatform/kubectl-ai</a></h1>
            <p>AI powered Kubernetes Assistant</p>
            <p>Language: Go</p>
            <p>Stars: 6,715</p>
            <p>Forks: 588</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># kubectl-ai

[![Go Report Card](https://goreportcard.com/badge/github.com/GoogleCloudPlatform/kubectl-ai)](https://goreportcard.com/report/github.com/GoogleCloudPlatform/kubectl-ai)
![GitHub License](https://img.shields.io/github/license/GoogleCloudPlatform/kubectl-ai)
[![GitHub stars](https://img.shields.io/github/stars/GoogleCloudPlatform/kubectl-ai.svg)](https://github.com/GoogleCloudPlatform/kubectl-ai/stargazers)

`kubectl-ai` acts as an intelligent interface, translating user intent into
precise Kubernetes operations, making Kubernetes management more accessible and
efficient.

![kubectl-ai demo GIF using: kubectl-ai &quot;how&#039;s nginx app doing in my cluster&quot;](./.github/kubectl-ai.gif)

## Quick Start

First, ensure that kubectl is installed and configured.

### Installation

#### Quick Install (Linux &amp; MacOS only)

```shell
curl -sSL https://raw.githubusercontent.com/GoogleCloudPlatform/kubectl-ai/main/install.sh | bash
```

&lt;details&gt;

&lt;summary&gt;Other Installation Methods&lt;/summary&gt;

#### Manual Installation (Linux, MacOS and Windows)

1. Download the latest release from the [releases page](https://github.com/GoogleCloudPlatform/kubectl-ai/releases/latest) for your target machine.

2. Untar the release, make the binary executable and move it to a directory in your $PATH (as shown below).

```shell
tar -zxvf kubectl-ai_Darwin_arm64.tar.gz
chmod a+x kubectl-ai
sudo mv kubectl-ai /usr/local/bin/
```

#### Install with Krew (Linux/macOS/Windows)

First of all, you need to have krew insatlled, refer to [krew document](https://krew.sigs.k8s.io/docs/user-guide/setup/install/) for more details
Then you can install with krew

```shell
kubectl krew install ai
```

Now you can invoke `kubectl-ai` as a kubectl plugin like this: `kubectl ai`.

#### Install on NixOS

There are multiple ways to install `kubectl-ai` on NixOS. For a permantent installation add the following to your NixOS-Configuration:

```nix
  environment.systemPackages = with pkgs; [
    kubectl-ai
  ];
```

For a temporary installation, you can use the following command:

```
nix-shell -p kubectl-ai
```

&lt;/details&gt;

### Usage

`kubectl-ai` supports AI models from `gemini`, `vertexai`, `azopenai`, `openai`, `grok`, `bedrock` and local LLM providers such as `ollama` and `llama.cpp`.

#### Using Gemini (Default)

Set your Gemini API key as an environment variable. If you don&#039;t have a key, get one from [Google AI Studio](https://aistudio.google.com).

```bash
export GEMINI_API_KEY=your_api_key_here
kubectl-ai

# Use different gemini model
kubectl-ai --model gemini-2.5-pro-exp-03-25

# Use 2.5 flash (faster) model
kubectl-ai --quiet --model gemini-2.5-flash-preview-04-17 &quot;check logs for nginx app in hello namespace&quot;
```

&lt;details&gt;

&lt;summary&gt;Use other AI models&lt;/summary&gt;

#### Using AI models running locally (ollama or llama.cpp)

You can use `kubectl-ai` with AI models running locally. `kubectl-ai` supports [ollama](https://ollama.com/) and [llama.cpp](https://github.com/ggml-org/llama.cpp) to use the AI models running locally.

Additionally, the [`modelserving`](modelserving/) directory provides tools and instructions for deploying your own `llama.cpp`-based LLM serving endpoints locally or on a Kubernetes cluster. This allows you to host models like Gemma directly in your environment.

An example of using Google&#039;s `gemma3` model with `ollama`:

```shell
# assuming ollama is already running and you have pulled one of the gemma models
# ollama pull gemma3:12b-it-qat

# if your ollama server is at remote, use OLLAMA_HOST variable to specify the host
# export OLLAMA_HOST=http://192.168.1.3:11434/

# enable-tool-use-shim because models require special prompting to enable tool calling
kubectl-ai --llm-provider ollama --model gemma3:12b-it-qat --enable-tool-use-shim

# you can use `models` command to discover the locally available models
&gt;&gt; models
```

#### Using Grok

You can use X.AI&#039;s Grok model by setting your X.AI API key:

```bash
export GROK_API_KEY=your_xai_api_key_here
kubectl-ai --llm-provider=grok --model=grok-3-beta
```

#### Using AWS Bedrock

You can use AWS Bedrock Claude models with your AWS credentials:

```bash
# Configure AWS credentials using AWS SSO
aws sso login --profile your-profile-name
# Or use other AWS credential methods (IAM roles, environment variables, etc.)

# Use Claude 4 Sonnet (default)
kubectl-ai --llm-provider=bedrock --model=us.anthropic.claude-sonnet-4-20250514-v1:0

# Use Claude 3.7 Sonnet
kubectl-ai --llm-provider=bedrock --model=us.anthropic.claude-3-7-sonnet-20250219-v1:0

# Override model via environment variable
export BEDROCK_MODEL=us.anthropic.claude-sonnet-4-20250514-v1:0
kubectl-ai --llm-provider=bedrock
```

AWS Bedrock uses the standard AWS SDK credential chain, supporting:
- AWS SSO profiles
- IAM roles (for EC2/ECS/Lambda)
- Environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
- AWS CLI configuration files

#### Using Azure OpenAI

You can also use Azure OpenAI deployment by setting your OpenAI API key and specifying the provider:

```bash
export AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
export AZURE_OPENAI_ENDPOINT=https://your_azure_openai_endpoint_here
kubectl-ai --llm-provider=azopenai --model=your_azure_openai_deployment_name_here
# or
az login
kubectl-ai --llm-provider=openai://your_azure_openai_endpoint_here --model=your_azure_openai_deployment_name_here
```

#### Using OpenAI

You can also use OpenAI models by setting your OpenAI API key and specifying the provider:

```bash
export OPENAI_API_KEY=your_openai_api_key_here
kubectl-ai --llm-provider=openai --model=gpt-4.1
```

#### Using OpenAI Compatible API

For example, you can use aliyun qwen-xxx models as follows

```bash
export OPENAI_API_KEY=your_openai_api_key_here
export OPENAI_ENDPOINT=https://dashscope.aliyuncs.com/compatible-mode/v1
kubectl-ai --llm-provider=openai --model=qwen-plus
```

&lt;/details&gt;

Run interactively:

```shell
kubectl-ai
```

The interactive mode allows you to have a chat with `kubectl-ai`, asking multiple questions in sequence while maintaining context from previous interactions. Simply type your queries and press Enter to receive responses. To exit the interactive shell, type `exit` or press Ctrl+C.

Or, run with a task as input:

```shell
kubectl-ai --quiet &quot;fetch logs for nginx app in hello namespace&quot;
```

Combine it with other unix commands:

```shell
kubectl-ai &lt; query.txt
# OR
echo &quot;list pods in the default namespace&quot; | kubectl-ai
```

You can even combine a positional argument with stdin input. The positional argument will be used as a prefix to the stdin content:

```shell
cat error.log | kubectl-ai &quot;explain the error&quot;
```

We also support persistence between runs with an opt-in. This lets you save a session to the local filesystem, and resume it to maintain previous context. It even works between different interfaces!

```shell
kubectl-ai --new-session # start a new session
kubectl-ai --list-sessions # list all saved sessions
kubectl-ai --resume-session 20250807-510872 # resume session 20250807-510872
kubectl-ai --delete-session 20250807-510872 # delete session 20250807-510872
```

## Configuration

You can also configure `kubectl-ai` using a YAML configuration file at `~/.config/kubectl-ai/config.yaml`:

```shell
mkdir -p ~/.config/kubectl-ai/
cat &lt;&lt;EOF &gt; ~/.config/kubectl-ai/config.yaml
model: gemini-2.5-flash-preview-04-17
llmProvider: gemini
toolConfigPaths: ~/.config/kubectl-ai/tools.yaml
EOF
```

Verify your configuration:

```shell
kubectl-ai --quiet model
```

&lt;details&gt;

&lt;summary&gt;More configuration Options&lt;/summary&gt;

Here&#039;s a complete configuration file with all available options and their default values:

```yaml
# LLM provider configuration
llmProvider: &quot;gemini&quot;               # Default LLM provider
model: &quot;gemini-2.5-pro-preview-06-05&quot; # Default model
skipVerifySSL: false              # Skip SSL verification for LLM API calls

# Tool and permission settings
toolConfigPaths: [&quot;~/.config/kubectl-ai/tools.yaml&quot;]  # Custom tools configuration paths
skipPermissions: false             # Skip confirmation for resource-modifying commands
enableToolUseShim: false        # Enable tool use shim for certain models

# MCP configuration
mcpServer: false                  # Run in MCP server mode
mcpClient: false                  # Enable MCP client mode
externalTools: false             # Discover external MCP tools (requires mcp-server)

# Runtime settings
maxIterations: 20                 # Maximum iterations for the agent
quiet: false                       # Run in non-interactive mode
removeWorkdir: false             # Remove temporary working directory after execution

# Kubernetes configuration
kubeconfig: &quot;~/.kube/config&quot;      # Path to kubeconfig file

# UI configuration
uiType: &quot;terminal&quot;                # UI mode: &quot;terminal&quot; or &quot;web&quot;
uiListenAddress: &quot;localhost:8888&quot; # Address for HTML UI server

# Prompt configuration
promptTemplateFilePath: &quot;&quot;      # Custom prompt template file
extraPromptPaths: []            # Additional prompt template paths

# Debug and trace settings
tracePath: &quot;/tmp/kubectl-ai-trace.txt&quot; # Path to trace file
```

&lt;/details&gt;

All these settings can be configured through either:

1. Command line flags (e.g., `--model=gemini-2.5-pro`)
2. Configuration file (`~/.config/kubectl-ai/config.yaml`)
3. Environment variables (e.g., `GEMINI_API_KEY`)

Command line flags take precedence over configuration file settings.

## Tools

`kubectl-ai` leverages LLMs to suggest and execute Kubernetes operations using a set of powerful tools. It comes with built-in tools like `kubectl` and `bash`.

You can also extend its capabilities by defining your own custom tools. By default, `kubectl-ai` looks for your tool configurations in `~/.config/kubectl-ai/tools.yaml`.

To specify tools configuration files or directories containing tools configuration files, use:

```sh
./kubectl-ai --custom-tools-config=&lt;path-to-tools-directory&gt; &quot;your prompt here&quot;
```

For further details on how to configure your own tools, [go here](docs/tools.md).

## Docker Quick Start 
This project provides a Docker image that gives you a standalone environment for running kubectl-ai, including against a GKE cluster.

### Running the container against GKE

#### Step 1: Build the Image

Clone the repository and build the image with the following command 

```bash
git clone https://github.com/GoogleCloudPlatform/kubectl-ai.git
cd kubectl-ai
docker build -t kubectl-ai:latest -f images/kubectl-ai/Dockerfile .
```

#### Step 2: Connect to Your GKE Cluster
Set up application default credentials and connect to your GKE cluster.
```bash
gcloud auth application-default login # If in a gcloud shell this is not necessary
gcloud container clusters get-credentials &lt;cluster-name&gt; --zone &lt;zone&gt;
```

#### Step 3: Run the kubectl-ai container
Below is a sample command that can be used to launch the container with a locally hosted web-ui. Be sure to replace the placeholder values with your specific Google Cloud project ID and location. Note you 
do not need to mount the gcloud config directory if you&#039;re on a cloudshell machine. 

```bash
docker run --rm -it -p 8080:8080 -v ~/.kube:/root/.kube -v ~/.config/gcloud:/root/.config/gcloud -e GOOGLE_CLOUD_LOCATION=us-central1 -e GOOGLE_CLOUD_PROJECT=my-gcp-project kubectl-ai:latest --llm-provider vertexai --ui-listen-address 0.0.0.0:8080 --ui-type web
```

For more info about running from the container image see [CONTAINER.md](CONTAINER.md)

## MCP Client Mode

&gt; **Note:** MCP Client Mode is available in `kubectl-ai` version v0.0.12 and onwards.

`kubectl-ai` can connect to external [MCP](https://modelcontextprotocol.io/examples) Servers to access additional tools in addition to built-in tools.

### Quick Start

Enable MCP client mode:

```bash
kubectl-ai --mcp-client
```

### Configuration

Create or edit `~/.config/kubectl-ai/mcp.yaml` to customize MCP servers:

```yaml
servers:
  # Local MCP server (stdio-based)
  # sequential-thinking: Advanced reasoning and step-by-step analysis
  - name: sequential-thinking
    command: npx
    args:
      - -y
      - &quot;@modelcontextprotocol/server-sequential-thinking&quot;
  
  # Remote MCP server (HTTP-based)
  - name: cloudflare-documentation
    url: https://docs.mcp.cloudflare.com/mcp
    
  # Optional: Remote MCP server with authentication
  - name: custom-api
    url: https://api.example.com/mcp
    auth:
      type: &quot;bearer&quot;
      token: &quot;${MCP_TOKEN}&quot;
```

The system automatically:

- Converts parameter names (snake_case → camelCase)
- Handles type conversion (strings → numbers/booleans when appropriate)
- Provides fallback behavior for unknown servers

No additional setup required - just use the `--mcp-client` flag and the AI will have access to all configured MCP tools.

📖 **For detailed configuration options, troubleshooting, and advanced features for MCP Client mode, see the [MCP Client Documentation](pkg/mcp/README.md).**

📖 **For multi-server orchestration and security automation examples, see the [MCP Client Integration Guide](docs/mcp-client.md).**

## Extras

You can use the following special keywords for specific actions:

- `model`: Display the currently selected model.
- `models`: List all available models.
- `tools`: List all available tools.
- `version`: Display the `kubectl-ai` version.
- `reset`: Clear the conversational context.
- `clear`: Clear the terminal screen.
- `exit` or `quit`: Terminate the interactive shell (Ctrl+C also works).

### Invoking as kubectl plugin

You can also run `kubectl ai`. `kubectl` finds any executable file in your `PATH` whose name begins with `kubectl-` as a [plugin](https://kubernetes.io/docs/tasks/extend-kubectl/kubectl-plugins/).

## MCP Server Mode

`kubectl-ai` can act as an MCP server that exposes kubectl tools to other MCP clients (like Claude, Cursor, or VS Code). The server can run in two modes:

### Basic MCP Server (Built-in tools only)

Expose only kubectl-ai&#039;s native Kubernetes tools:

```bash
kubectl-ai --mcp-server
```

### Enhanced MCP Server (With external tool discovery)

Additionally discover and expose tools from other MCP servers as a unified interface:

```bash
kubectl-ai --mcp-server --external-tools
```

This creates a powerful **tool aggregation hub** where kubectl-ai acts as both:

- **MCP Server**: Exposing kubectl tools to clients
- **MCP Client**: Consuming tools from other MCP servers

The enhanced mode provides AI clients with access to both Kubernetes operations and general-purpose tools (filesystem, web search, databases, etc.) through a single MCP endpoint.

📖 **For detailed configuration, examples, and troubleshooting, see the [MCP Server Documentation](./docs/mcp-server.md).**

## k8s-bench

kubectl-ai project includes [k8s-bench](./k8s-bench/README.md) - a benchmark to evaluate performance of different LLM models on kubernetes related tasks. 

### Latest Benchmark Results (August 2025)

Comprehensive evaluation on identical 10-task Kubernetes benchmark with proper CNI environment:

| Model | Success | Fail | Success Rate |
|-------|---------|------|--------------|
| gemini-2.5-flash-preview-04-17 | 10 | 0 | 100% |
| gemini-2.5-pro-preview-03-25 | 10 | 0 | 100% |
| gemma-3-27b-it | 8 | 2 | 80% |
| AWS Bedrock Claude 3.7 Sonnet | 10 | 0 | 100% |
| AWS Bedrock Claude Sonnet 4 | 9 | 1 | 90% |

**Test Environment**: Kind cluster v1.27.3 with Calico CNI (full NetworkPolicy support)  
**Tasks**: create-pod, create-pod-mount-configmaps, create-pod-resources-limits, create-network-policy, fix-crashloop, fix-image-pull, fix-service-routing, list-images-for-pods, scale-deployment, scale-down-deployment

See [full report](./k8s-bench.md) for more details.

## Start Contributing

We welcome contributions to `kubectl-ai` from the community. Take a look at our
[contribution guide](contributing.md) to get started.

---

*Note: This is not an officially supported Google product. This project is not
eligible for the [Google Open Source Software Vulnerability Rewards
Program](https://bughunters.google.com/open-source-security).*
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[databus23/helm-diff]]></title>
            <link>https://github.com/databus23/helm-diff</link>
            <guid>https://github.com/databus23/helm-diff</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[A helm plugin that shows a diff explaining what a helm upgrade would change]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/databus23/helm-diff">databus23/helm-diff</a></h1>
            <p>A helm plugin that shows a diff explaining what a helm upgrade would change</p>
            <p>Language: Go</p>
            <p>Stars: 3,092</p>
            <p>Forks: 300</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># Helm Diff Plugin
[![Go Report Card](https://goreportcard.com/badge/github.com/databus23/helm-diff)](https://goreportcard.com/report/github.com/databus23/helm-diff)
[![GoDoc](https://godoc.org/github.com/databus23/helm-diff?status.svg)](https://godoc.org/github.com/databus23/helm-diff)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/databus23/helm-diff/blob/master/LICENSE)

This is a Helm plugin giving you a preview of what a `helm upgrade` would change.
It basically generates a diff between the latest deployed version of a release
and a `helm upgrade --debug --dry-run`. This can also be used to compare two
revisions/versions of your helm release.

&lt;a href=&quot;https://asciinema.org/a/105326&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://asciinema.org/a/105326.png&quot; /&gt;&lt;/a&gt;

## Install

### Using Helm plugin manager (&gt; 2.3.x)

```shell
helm plugin install https://github.com/databus23/helm-diff
```

### Pre Helm 2.3.0 Installation
Pick a release tarball from the [releases](https://github.com/databus23/helm-diff/releases) page.

Unpack the tarball in your helm plugins directory (`$(helm home)/plugins`).

E.g.
```
curl -L $TARBALL_URL | tar -C $(helm home)/plugins -xzv
```

### From Source
#### Prerequisites
 - GoLang `&gt;= 1.21`

Make sure you do not have a version of `helm-diff` installed. You can remove it by running `helm plugin uninstall diff`

#### Installation Steps
The first step is to download the repository and enter the directory. You can do this via `git clone` or downloading and extracting the release. If you clone via git, remember to checkout the latest tag for the latest release.

Next, install the plugin into helm.

```bash
make install/helm3
```


## Usage

```
The Helm Diff Plugin

* Shows a diff explaining what a helm upgrade would change:
    This fetches the currently deployed version of a release
  and compares it to a local chart plus values. This can be
  used to visualize what changes a helm upgrade will perform.

* Shows a diff explaining what had changed between two revisions:
    This fetches previously deployed versions of a release
  and compares them. This can be used to visualize what changes
  were made during revision change.

* Shows a diff explaining what a helm rollback would change:
    This fetches the currently deployed version of a release
  and compares it to the previously deployed version of the release, that you
  want to rollback. This can be used to visualize what changes a
  helm rollback will perform.

Usage:
  diff [flags]
  diff [command]

Available Commands:
  completion  Generate the autocompletion script for the specified shell
  release     Shows diff between release&#039;s manifests
  revision    Shows diff between revision&#039;s manifests
  rollback    Show a diff explaining what a helm rollback could perform
  upgrade     Show a diff explaining what a helm upgrade would change.
  version     Show version of the helm diff plugin

Flags:
      --allow-unreleased                         enables diffing of releases that are not yet deployed via Helm
  -a, --api-versions stringArray                 Kubernetes api versions used for Capabilities.APIVersions
      --color                                    color output. You can control the value for this flag via HELM_DIFF_COLOR=[true|false]. If both --no-color and --color are unspecified, coloring enabled only when the stdout is a term and TERM is not &quot;dumb&quot;
  -C, --context int                              output NUM lines of context around changes (default -1)
      --detailed-exitcode                        return a non-zero exit code when there are changes
      --devel                                    use development versions, too. Equivalent to version &#039;&gt;0.0.0-0&#039;. If --version is set, this is ignored.
      --disable-openapi-validation               disables rendered templates validation against the Kubernetes OpenAPI Schema
      --disable-validation                       disables rendered templates validation against the Kubernetes cluster you are currently pointing to. This is the same validation performed on an install
      --dry-run string[=&quot;client&quot;]                --dry-run, --dry-run=client, or --dry-run=true disables cluster access and show diff as if it was install. Implies --install, --reset-values, and --disable-validation. --dry-run=server enables the cluster access with helm-get and the lookup template function.
      --enable-dns                               enable DNS lookups when rendering templates
  -D, --find-renames float32                     Enable rename detection if set to any value greater than 0. If specified, the value denotes the maximum fraction of changed content as lines added + removed compared to total lines in a diff for considering it a rename. Only objects of the same Kind are attempted to be matched
  -h, --help                                     help for diff
      --include-crds                             include CRDs in the diffing
      --include-tests                            enable the diffing of the helm test hooks
      --insecure-skip-tls-verify                 skip tls certificate checks for the chart download
      --install                                  enables diffing of releases that are not yet deployed via Helm (equivalent to --allow-unreleased, added to match &quot;helm upgrade --install&quot; command
      --kube-version string                      Kubernetes version used for Capabilities.KubeVersion
      --kubeconfig string                        This flag is ignored, to allow passing of this top level flag to helm
      --no-color                                 remove colors from the output. If both --no-color and --color are unspecified, coloring enabled only when the stdout is a term and TERM is not &quot;dumb&quot;
      --no-hooks                                 disable diffing of hooks
      --normalize-manifests                      normalize manifests before running diff to exclude style differences from the output
      --output string                            Possible values: diff, simple, template, dyff. When set to &quot;template&quot;, use the env var HELM_DIFF_TPL to specify the template. (default &quot;diff&quot;)
      --post-renderer string                     the path to an executable to be used for post rendering. If it exists in $PATH, the binary will be used, otherwise it will try to look for the executable at the given path
      --post-renderer-args stringArray           an argument to the post-renderer (can specify multiple)
      --repo string                              specify the chart repository url to locate the requested chart
      --reset-then-reuse-values                  reset the values to the ones built into the chart, apply the last release&#039;s values and merge in any new values. If &#039;--reset-values&#039; or &#039;--reuse-values&#039; is specified, this is ignored
      --reset-values                             reset the values to the ones built into the chart and merge in any new values
      --reuse-values                             reuse the last release&#039;s values and merge in any new values. If &#039;--reset-values&#039; is specified, this is ignored
      --set stringArray                          set values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2)
      --set-file stringArray                     set values from respective files specified via the command line (can specify multiple or separate values with commas: key1=path1,key2=path2)
      --set-json stringArray                     set JSON values on the command line (can specify multiple or separate values with commas: key1=jsonval1,key2=jsonval2)
      --set-literal stringArray                  set STRING literal values on the command line
      --set-string stringArray                   set STRING values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2)
      --show-secrets                             do not redact secret values in the output
      --show-secrets-decoded                     decode secret values in the output
      --skip-schema-validation                   skip validation of the rendered manifests against the Kubernetes OpenAPI schema
      --strip-trailing-cr                        strip trailing carriage return on input
      --suppress stringArray                     allows suppression of the kinds listed in the diff output (can specify multiple, like &#039;--suppress Deployment --suppress Service&#039;)
      --suppress-output-line-regex stringArray   a regex to suppress diff output lines that match
  -q, --suppress-secrets                         suppress secrets in the output
      --take-ownership                           if set, upgrade will ignore the check for helm annotations and take ownership of the existing resources
      --three-way-merge                          use three-way-merge to compute patch and generate diff output
  -f, --values valueFiles                        specify values in a YAML file (can specify multiple) (default [])
      --version string                           specify the exact chart version to use. If this is not specified, the latest version is used

Additional help topcis:
  diff            

Use &quot;diff [command] --help&quot; for more information about a command.
```

## Commands:

### upgrade:

```
$ helm diff upgrade -h
Show a diff explaining what a helm upgrade would change.

This fetches the currently deployed version of a release
and compares it to a chart plus values.
This can be used to visualize what changes a helm upgrade will
perform.

Usage:
  diff upgrade [flags] [RELEASE] [CHART]

Examples:
  helm diff upgrade my-release stable/postgresql --values values.yaml

  # Set HELM_DIFF_IGNORE_UNKNOWN_FLAGS=true to ignore unknown flags
  # It&#039;s useful when you&#039;re using `helm-diff` in a `helm upgrade` wrapper.
  # See https://github.com/databus23/helm-diff/issues/278 for more information.
  HELM_DIFF_IGNORE_UNKNOWN_FLAGS=true helm diff upgrade my-release stable/postgres --wait

  # Set HELM_DIFF_USE_UPGRADE_DRY_RUN=true to
  # use `helm upgrade --dry-run` instead of `helm template` to render manifests from the chart.
  # See https://github.com/databus23/helm-diff/issues/253 for more information.
  HELM_DIFF_USE_UPGRADE_DRY_RUN=true helm diff upgrade my-release datadog/datadog

  # Set HELM_DIFF_THREE_WAY_MERGE=true to
  # enable the three-way-merge on diff.
  # This is equivalent to specifying the --three-way-merge flag.
  # Read the flag usage below for more information on --three-way-merge.
  HELM_DIFF_THREE_WAY_MERGE=true helm diff upgrade my-release datadog/datadog

  # Set HELM_DIFF_NORMALIZE_MANIFESTS=true to
  # normalize the yaml file content when using helm diff.
  # This is equivalent to specifying the --normalize-manifests flag.
  # Read the flag usage below for more information on --normalize-manifests.
  HELM_DIFF_NORMALIZE_MANIFESTS=true helm diff upgrade my-release datadog/datadog

# Set HELM_DIFF_OUTPUT_CONTEXT=n to configure the output context to n lines.
# This is equivalent to specifying the --context flag.
# Read the flag usage below for more information on --context.
HELM_DIFF_OUTPUT_CONTEXT=5 helm diff upgrade my-release datadog/datadog

Flags:
      --allow-unreleased                         enables diffing of releases that are not yet deployed via Helm
  -a, --api-versions stringArray                 Kubernetes api versions used for Capabilities.APIVersions
  -C, --context int                              output NUM lines of context around changes (default -1)
      --detailed-exitcode                        return a non-zero exit code when there are changes
      --devel                                    use development versions, too. Equivalent to version &#039;&gt;0.0.0-0&#039;. If --version is set, this is ignored.
      --disable-openapi-validation               disables rendered templates validation against the Kubernetes OpenAPI Schema
      --disable-validation                       disables rendered templates validation against the Kubernetes cluster you are currently pointing to. This is the same validation performed on an install
      --dry-run string[=&quot;client&quot;]                --dry-run, --dry-run=client, or --dry-run=true disables cluster access and show diff as if it was install. Implies --install, --reset-values, and --disable-validation. --dry-run=server enables the cluster access with helm-get and the lookup template function.
      --enable-dns                               enable DNS lookups when rendering templates
  -D, --find-renames float32                     Enable rename detection if set to any value greater than 0. If specified, the value denotes the maximum fraction of changed content as lines added + removed compared to total lines in a diff for considering it a rename. Only objects of the same Kind are attempted to be matched
  -h, --help                                     help for upgrade
      --include-crds                             include CRDs in the diffing
      --include-tests                            enable the diffing of the helm test hooks
      --insecure-skip-tls-verify                 skip tls certificate checks for the chart download
      --install                                  enables diffing of releases that are not yet deployed via Helm (equivalent to --allow-unreleased, added to match &quot;helm upgrade --install&quot; command
      --kube-version string                      Kubernetes version used for Capabilities.KubeVersion
      --kubeconfig string                        This flag is ignored, to allow passing of this top level flag to helm
      --no-hooks                                 disable diffing of hooks
      --normalize-manifests                      normalize manifests before running diff to exclude style differences from the output
      --output string                            Possible values: diff, simple, template, dyff. When set to &quot;template&quot;, use the env var HELM_DIFF_TPL to specify the template. (default &quot;diff&quot;)
      --post-renderer string                     the path to an executable to be used for post rendering. If it exists in $PATH, the binary will be used, otherwise it will try to look for the executable at the given path
      --post-renderer-args stringArray           an argument to the post-renderer (can specify multiple)
      --repo string                              specify the chart repository url to locate the requested chart
      --reset-then-reuse-values                  reset the values to the ones built into the chart, apply the last release&#039;s values and merge in any new values. If &#039;--reset-values&#039; or &#039;--reuse-values&#039; is specified, this is ignored
      --reset-values                             reset the values to the ones built into the chart and merge in any new values
      --reuse-values                             reuse the last release&#039;s values and merge in any new values. If &#039;--reset-values&#039; is specified, this is ignored
      --set stringArray                          set values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2)
      --set-file stringArray                     set values from respective files specified via the command line (can specify multiple or separate values with commas: key1=path1,key2=path2)
      --set-json stringArray                     set JSON values on the command line (can specify multiple or separate values with commas: key1=jsonval1,key2=jsonval2)
      --set-literal stringArray                  set STRING literal values on the command line
      --set-string stringArray                   set STRING values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2)
      --show-secrets                             do not redact secret values in the output
      --show-secrets-decoded                     decode secret values in the output
      --skip-schema-validation                   skip validation of the rendered manifests against the Kubernetes OpenAPI schema
      --strip-trailing-cr                        strip trailing carriage return on input
      --suppress stringArray                     allows suppression of the kinds listed in the diff output (can specify multiple, like &#039;--suppress Deployment --suppress Service&#039;)
      --suppress-output-line-regex stringArray   a regex to suppress diff output lines that match
  -q, --suppress-secrets                         suppress secrets in the output
      --take-ownership                           if set, upgrade will ignore the check for helm annotations and take ownership of the existing resources
      --three-way-merge                          use three-way-merge to compute patch and generate diff output
  -f, --values valueFiles                        specify values in a YAML file (can specify multiple) (default [])
      --version string                           specify the exact chart version to use. If this is not specified, the latest version is used

Global Flags:
      --color      color output. You can control the value for this flag via HELM_DIFF_COLOR=[true|false]. If both --no-color and --color are unspecified, coloring enabled only when the stdout is a term and TERM is not &quot;dumb&quot;
      --no-color   remove colors from the output. If both --no-color and --color are unspecified, coloring enabled only when the stdout is a term and TERM is not &quot;dumb&quot;
```

### release:

```
$ helm diff release -h

This command compares the manifests details of a different releases created from the same chart.
The release name may be specified using namespace/release syntax.

It can be used to compare the manifests of

 - release1 with release2
        $ helm diff release [flags] release1 release2
   Example:
        $ helm diff release my-prod my-stage
        $ helm diff release prod/my-prod stage/my-stage

Usage:
  diff release [flags] RELEASE release1 [release2]

Flags:
  -C, --context int                              output NUM lines of context around changes (default -1)
      --detailed-exitcode                        return a non-zero exit code when there are changes
  -D, --find-renames float32                     Enable rename detection if set to any value greater than 0. If specified, the value denotes the maximum fraction of changed content as lines added + removed compared to total lines in a diff for considering it a rename. Only objects of the same Kind are attempted to be matched
  -h, --help                                     help for release
      --include-tests                            enable the diffing of the helm test hooks
      --normalize-manifests                      normalize manifests before running diff to exclude style differences from the output
      --output string                            Possible values: diff, simple, template, dyff. When set to &quot;template&quot;, use the env var HELM_DIFF_TPL to specify the template. (default &quot;diff&quot;)
      --show-secrets                             do not redact secret values in the output
      --strip-trailing-cr                        strip trailing carriage return on input
      --suppress stringArray                     allows suppression of the kinds listed in the diff output (can specify multiple, like &#039;--suppress Deployment --suppress Service&#039;)
      --suppress-output-line-regex stringArray   a regex to suppress diff output lines that match
  -q, --suppress-secrets                         suppress secrets in the output

Global Flags:
      --color      color output. You can control the value for this flag via HELM_DIFF_COLOR=[true|false]. If both --no-color and --color are unspecified, coloring enabled only when the stdout is a term and TERM is not &quot;dumb&quot;
      --no-color   remove colors from the output. If both --no-color and --color are unspecified, coloring enabled only when the stdout is a term and TERM is not &quot;dumb&quot;
```

### revision:

```
$ helm diff revision -h

This command compares the manifests d

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ory/kratos]]></title>
            <link>https://github.com/ory/kratos</link>
            <guid>https://github.com/ory/kratos</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[Headless cloud-native authentication and identity management written in Go. Scales to a billion+ users. Replace Homegrown, Auth0, Okta, Firebase with better UX and DX. Passkeys, Social Sign In, OIDC, Magic Link, Multi-Factor Auth, SMS, SAML, TOTP, and more. Runs everywhere, runs best on Ory Network.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ory/kratos">ory/kratos</a></h1>
            <p>Headless cloud-native authentication and identity management written in Go. Scales to a billion+ users. Replace Homegrown, Auth0, Okta, Firebase with better UX and DX. Passkeys, Social Sign In, OIDC, Magic Link, Multi-Factor Auth, SMS, SAML, TOTP, and more. Runs everywhere, runs best on Ory Network.</p>
            <p>Language: Go</p>
            <p>Stars: 12,242</p>
            <p>Forks: 1,026</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/banners/kratos.svg&quot; alt=&quot;Ory Kratos - Cloud native Identity and User Management&quot;&gt;&lt;/h1&gt;

&lt;h4 align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.ory.sh/chat&quot;&gt;Chat&lt;/a&gt; |
    &lt;a href=&quot;https://github.com/ory/kratos/discussions&quot;&gt;Discussions&lt;/a&gt; |
    &lt;a href=&quot;https://www.ory.sh/l/sign-up-newsletter&quot;&gt;Newsletter&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;
    &lt;a href=&quot;https://www.ory.sh/kratos/docs/&quot;&gt;Guide&lt;/a&gt; |
    &lt;a href=&quot;https://www.ory.sh/kratos/docs/sdk/api&quot;&gt;API Docs&lt;/a&gt; |
    &lt;a href=&quot;https://godoc.org/github.com/ory/kratos&quot;&gt;Code Docs&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;
    &lt;a href=&quot;https://console.ory.sh/&quot;&gt;Support this project!&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;
    &lt;a href=&quot;https://www.ory.sh/jobs/&quot;&gt;Work in Open Source, Ory is hiring!&lt;/a&gt;
&lt;/h4&gt;

---

&lt;p align=&quot;left&quot;&gt;
    &lt;a href=&quot;https://github.com/ory/kratos/actions/workflows/ci.yaml&quot;&gt;&lt;img src=&quot;https://github.com/ory/kratos/actions/workflows/ci.yaml/badge.svg?branch=master&amp;event=push&quot; alt=&quot;CI Tasks for Ory Kratos&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://codecov.io/gh/ory/kratos&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/ory/kratos/branch/master/graph/badge.svg?token=6t0QqOdurR&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://bestpractices.coreinfrastructure.org/projects/4979&quot;&gt;&lt;img src=&quot;https://bestpractices.coreinfrastructure.org/projects/4979/badge&quot; alt=&quot;CII Best Practices&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://opencollective.com/ory&quot; alt=&quot;sponsors on Open Collective&quot;&gt;&lt;img src=&quot;https://opencollective.com/ory/backers/badge.svg&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://opencollective.com/ory&quot; alt=&quot;Sponsors on Open Collective&quot;&gt;&lt;img src=&quot;https://opencollective.com/ory/sponsors/badge.svg&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/ory/kratos/blob/master/CODE_OF_CONDUCT.md&quot; alt=&quot;Ory Code of Conduct&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/ory-code%20of%20conduct-green&quot; /&gt;&lt;/a&gt;
&lt;/&gt;

Ory Kratos is _the_ developer-friendly, security-hardened and battle-tested
Identity, User Management and Authentication system for the Cloud. Finally, it
is no longer necessary to implement User Login for the umpteenth time!

## Ory Kratos on the Ory Network

The [Ory Network](https://www.ory.sh/cloud) is the fastest, most secure and
worry-free way to use Ory&#039;s Services. **Ory Identities** is powered by the Ory
Kratos open source identity server, and it&#039;s fully API-compatible.

The Ory Network provides the infrastructure for modern end-to-end security:

- **Identity &amp; credential management scaling to billions of users and devices**
- **Registration, Login and Account management flows for passkey, biometric,
  social, SSO and multi-factor authentication**
- **Pre-built login, registration and account management pages and components**
- OAuth2 and OpenID provider for single sign on, API access and
  machine-to-machine authorization
- Low-latency permission checks based on Google&#039;s Zanzibar model and with
  built-in support for the Ory Permission Language

It&#039;s fully managed, highly available, developer &amp; compliance-friendly!

- GDPR-friendly secure storage with data locality
- Cloud-native APIs, compatible with Ory&#039;s Open Source servers
- Comprehensive admin tools with the web-based Ory Console and the Ory Command
  Line Interface (CLI)
- Extensive documentation, straightforward examples and easy-to-follow guides
- Fair, usage-based [pricing](https://www.ory.sh/pricing)

Sign up for a
[**free developer account**](https://console.ory.sh/registration?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=kratos-readme)
today!

## Ory Kratos On-premise support

Are you running Ory Kratos in a mission-critical, commercial environment? The
Ory Enterprise License (OEL) provides enhanced features, security, and expert
support directly from the Ory core maintainers.

Organizations that require advanced features, enhanced security, and
enterprise-grade support for Ory&#039;s identity and access management solutions
benefit from the Ory Enterprise License (OEL) as a self-hosted, premium offering
including:

- Additional features not available in the open-source version.
- Regular releases that address CVEs and security vulnerabilities, with strict
  SLAs for patching based on severity.
- Support for advanced scaling and multi-tenancy features.
- Premium support options, including SLAs, direct engineer access, and concierge
  onboarding.
- Access to private Docker registry for a faster, more reliable access to vetted
  enterprise builds.

A valid Ory Enterprise License and access to the Ory Enterprise Docker Registry
are required to use these features. OEL is designed for mission-critical,
production, and global applications where organizations need maximum control and
flexibility over their identity infrastructure. Ory&#039;s offering is the only
official program for qualified support from the maintainers. For more
information book a meeting with the Ory team to
**[discuss your needs](https://www.ory.sh/contact/)**!

### Quickstart

Install the [Ory CLI](https://www.ory.sh/docs/guides/cli/installation) and
create a new project to get started with Ory Identities right away:

```
# If you don&#039;t have Ory CLI installed yet:
bash &lt;(curl https://raw.githubusercontent.com/ory/meta/master/install.sh) -b . ory
sudo mv ./ory /usr/local/bin/

# Sign up
ory auth

# Create project
ory create project
```

&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt;
&lt;!-- DON&#039;T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt;

**Table of Contents**

- [Ory Kratos on the Ory Network](#ory-kratos-on-the-ory-network)
  - [Quickstart](#quickstart)
- [What is Ory Kratos?](#what-is-ory-kratos)
  - [Who is using it?](#who-is-using-it)
- [Getting Started](#getting-started)
  - [Installation](#installation)
- [Ecosystem](#ecosystem)
  - [Ory Kratos: Identity and User Infrastructure and Management](#ory-kratos-identity-and-user-infrastructure-and-management)
  - [Ory Hydra: OAuth2 &amp; OpenID Connect Server](#ory-hydra-oauth2--openid-connect-server)
  - [Ory Oathkeeper: Identity &amp; Access Proxy](#ory-oathkeeper-identity--access-proxy)
  - [Ory Keto: Access Control Policies as a Server](#ory-keto-access-control-policies-as-a-server)
- [Security](#security)
  - [Disclosing vulnerabilities](#disclosing-vulnerabilities)
- [Telemetry](#telemetry)
- [Documentation](#documentation)
  - [Guide](#guide)
  - [HTTP API documentation](#http-api-documentation)
  - [Upgrading and Changelog](#upgrading-and-changelog)
  - [Command line documentation](#command-line-documentation)
  - [Develop](#develop)
    - [Dependencies](#dependencies)
    - [Install from source](#install-from-source)
    - [Formatting Code](#formatting-code)
    - [Running Tests](#running-tests)
      - [Short Tests](#short-tests)
      - [Regular Tests](#regular-tests)
      - [Updating Test Fixtures](#updating-test-fixtures)
      - [End-to-End Tests](#end-to-end-tests)
    - [Build Docker](#build-docker)
    - [Documentation Tests](#documentation-tests)
    - [Preview API documentation](#preview-api-documentation)

&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt;

## What is Ory Kratos?

Ory Kratos is an API-first Identity and User Management system that is built
according to
[cloud architecture best practices](https://www.ory.sh/docs/ecosystem/software-architecture-philosophy).
It implements core use cases that almost every software application needs to
deal with:

- **Self-service Login and Registration**: Allow end-users to create and sign
  into accounts (we call them **identities**) using Username / Email and
  password combinations, Social Sign In (&quot;Sign in with Google, GitHub&quot;),
  Passwordless flows, and others.
- **Multi-Factor Authentication (MFA/2FA)**: Support protocols such as TOTP
  ([RFC 6238](https://tools.ietf.org/html/rfc6238) and
  [IETF RFC 4226](https://tools.ietf.org/html/rfc4226) - better known as
  [Google Authenticator](https://en.wikipedia.org/wiki/Google_Authenticator))
- **Account Verification**: Verify that an E-Mail address, phone number, or
  physical address actually belong to that identity.
- **Account Recovery**: Recover access using &quot;Forgot Password&quot; flows, Security
  Codes (in case of MFA device loss), and others.
- **Profile and Account Management**: Update passwords, personal details, email
  addresses, linked social profiles using secure flows.
- **Admin APIs**: Import, update, delete identities.

We highly recommend reading the
[Ory Kratos introduction docs](https://www.ory.sh/kratos/docs/) to learn more
about Ory Krato&#039;s background, feature set, and differentiation from other
products.

### Who is using it?

&lt;!--BEGIN ADOPTERS--&gt;

The Ory community stands on the shoulders of individuals, companies, and
maintainers. The Ory team thanks everyone involved - from submitting bug reports
and feature requests, to contributing patches and documentation. The Ory
community counts more than 50.000 members and is growing. The Ory stack protects
7.000.000.000+ API requests every day across thousands of companies. None of
this would have been possible without each and everyone of you!

The following list represents companies that have accompanied us along the way
and that have made outstanding contributions to our ecosystem. _If you think
that your company deserves a spot here, reach out to
&lt;a href=&quot;mailto:office@ory.sh&quot;&gt;office@ory.sh&lt;/a&gt; now_!

&lt;table&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;Name&lt;/th&gt;
            &lt;th&gt;Logo&lt;/th&gt;
            &lt;th&gt;Website&lt;/th&gt;
            &lt;th&gt;Case Study&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;OpenAI&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/openai.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/openai.svg&quot; alt=&quot;OpenAI&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://openai.com/&quot;&gt;openai.com&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/openai&quot;&gt;OpenAI Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Fandom&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/fandom.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/fandom.svg&quot; alt=&quot;Fandom&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.fandom.com/&quot;&gt;fandom.com&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/fandom&quot;&gt;Fandom Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Lumin&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/lumin.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/lumin.svg&quot; alt=&quot;Lumin&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.luminpdf.com/&quot;&gt;luminpdf.com&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/lumin&quot;&gt;Lumin Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Sencrop&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/sencrop.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/sencrop.svg&quot; alt=&quot;Sencrop&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://sencrop.com/&quot;&gt;sencrop.com&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/sencrop&quot;&gt;Sencrop Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;OSINT Industries&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/osint.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/osint.svg&quot; alt=&quot;OSINT Industries&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.osint.industries/&quot;&gt;osint.industries&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/osint&quot;&gt;OSINT Industries Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;HGV&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/hgv.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/hgv.svg&quot; alt=&quot;HGV&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.hgv.it/&quot;&gt;hgv.it&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/hgv&quot;&gt;HGV Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Maxroll&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/maxroll.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/maxroll.svg&quot; alt=&quot;Maxroll&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://maxroll.gg/&quot;&gt;maxroll.gg&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/maxroll&quot;&gt;Maxroll Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Zezam&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/zezam.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/zezam.svg&quot; alt=&quot;Zezam&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.zezam.io/&quot;&gt;zezam.io&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.ory.sh/case-studies/zezam&quot;&gt;Zezam Case Study&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;T.RowePrice&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/troweprice.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/troweprice.svg&quot; alt=&quot;T.RowePrice&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.troweprice.com/&quot;&gt;troweprice.com&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Mistral&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/mistral.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/mistral.svg&quot; alt=&quot;Mistral&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.mistral.ai/&quot;&gt;mistral.ai&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Axel Springer&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/axelspringer.svg&quot; /&gt;
                    &lt;img height=&quot;22px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/axelspringer.svg&quot; alt=&quot;Axel Springer&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.axelspringer.com/&quot;&gt;axelspringer.com&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Hemnet&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/hemnet.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/hemnet.svg&quot; alt=&quot;Hemnet&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.hemnet.se/&quot;&gt;hemnet.se&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Cisco&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/cisco.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/cisco.svg&quot; alt=&quot;Cisco&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.cisco.com/&quot;&gt;cisco.com&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Presidencia de la República Dominicana&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/republica-dominicana.svg&quot; /&gt;
                    &lt;img height=&quot;42px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/republica-dominicana.svg&quot; alt=&quot;Presidencia de la República Dominicana&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.presidencia.gob.do/&quot;&gt;presidencia.gob.do&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Moonpig&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/moonpig.svg&quot; /&gt;
                    &lt;img height=&quot;32px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/moonpig.svg&quot; alt=&quot;Moonpig&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.moonpig.com/&quot;&gt;moonpig.com&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Booster&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/booster.svg&quot; /&gt;
                    &lt;img height=&quot;18px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/booster.svg&quot; alt=&quot;Booster&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.choosebooster.com/&quot;&gt;choosebooster.com&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Zaptec&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/zaptec.svg&quot; /&gt;
                    &lt;img height=&quot;24px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/zaptec.svg&quot; alt=&quot;Zaptec&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.zaptec.com/&quot;&gt;zaptec.com&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Klarna&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
                &lt;picture&gt;
                    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/light/klarna.svg&quot; /&gt;
                    &lt;img height=&quot;24px&quot; src=&quot;https://raw.githubusercontent.com/ory/meta/master/static/adopters/dark/klarna.svg&quot; alt=&quot;Klarna&quot;&gt;
                &lt;/picture&gt;
            &lt;/td&gt;
            &lt;td&gt;&lt;a href=&quot;https://www.klarna.com/&quot;&gt;klarna.com&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Raspberry PI Foundation&lt;/td&gt;
            &lt;td align=&quot;center&quot;&gt;
             

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[flexprice/flexprice]]></title>
            <link>https://github.com/flexprice/flexprice</link>
            <guid>https://github.com/flexprice/flexprice</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[Usage-based pricing and billing for developers 🔓 Cloud or self-hosted ⚙️ No-code UI 💰 Realtime usage metering 🎟 Credits & top-ups 🔑 Control feature access]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/flexprice/flexprice">flexprice/flexprice</a></h1>
            <p>Usage-based pricing and billing for developers 🔓 Cloud or self-hosted ⚙️ No-code UI 💰 Realtime usage metering 🎟 Credits & top-ups 🔑 Control feature access</p>
            <p>Language: Go</p>
            <p>Stars: 1,103</p>
            <p>Forks: 22</p>
            <p>Stars today: 145 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img align=&quot;center&quot; src=&quot;./assets/flexprice_logo.png&quot; height=&quot;30%&quot; width=&quot;30%&quot;  alt=&quot;fleprice logo&quot;/&gt;
&lt;/p&gt;
&lt;h3 align=&quot;center&quot;&gt;
&lt;b&gt;
⚡️ Usage based metering &amp; billing for developers ⚡️
&lt;/b&gt;
&lt;/h3 &gt;
&lt;p align=&quot;center&quot;&gt;
Build usage-based, credit-based, or hybrid pricing models with full control. Flexprice handles metering, pricing, and invoicing so you can focus on building, not billing.
&lt;/p&gt;

&lt;h5 align=&quot;center&quot;&gt;

[Documentation](https://docs.flexprice.io) • [Demo](https://www.loom.com/share/60d8308781254fe0bc5be341501f9fd5) • [Website](https://flexprice.io/) • [LinkedIn](https://www.linkedin.com/company/flexpriceio)


[![Go](https://img.shields.io/badge/go-%2300ADD8.svg?style=for-the-badge&amp;logo=go&amp;logoColor=white)](https://pkg.go.dev/github.com/flexprice/go-sdk) [![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&amp;logo=python&amp;logoColor=ffdd54)](https://pypi.org/project/flexprice) [![JavaScript](https://img.shields.io/badge/javascript-%23323330.svg?style=for-the-badge&amp;logo=javascript&amp;logoColor=%23F7DF1E)](https://www.npmjs.com/package/@flexprice/sdk) 

&lt;/h5&gt;

---

## Open architecture
The Flexprice core (metering, credits, pricing, billing) has an open and composable design. 

&lt;p align=&quot;center&quot;&gt;
  &lt;img align=&quot;center&quot; src=&quot;./assets/open-arch.jpg&quot; alt=&quot;open architechture&quot;/&gt;
&lt;/p&gt;

Your application, whether it&#039;s running backend APIs, AI agents, or custom workflows, can send usage data to Flexprice. You can directly stream data from data warehouses or analytics pipelines as well.

At the core, Flexprice processes this data in real time. We handle everything that usually ends up as custom logic built by developers. Our platform calculates pricing based on the customer’s plan, applies any prepaid or promotional credits, enforces feature limits, and generates accurate invoices automatically. Whether you&#039;re using seat-based subscriptions, usage-based pricing, or prepaid credit bundles, you can set up and iterate on your pricing model without writing billing infrastructure from scratch.

After billing is computed, our platform connects to your existing tools for payments, CPQ, CRM, and accounting, ensuring billing information flows into the systems your business already uses. It can sync invoices to your payment processor, update customer data in your CRM, and push revenue numbers to your accounting tools.

With this architecture, you get full control over how billing works inside your product, while saving your team from the complexity of maintaining it all.

## Why billing is a developer problem?

##### TL;DR
*When existing billing tools don’t flex to your product’s needs, developers shoulder the burden eating up valuable development time and causing ongoing maintenance headaches.*

&lt;p align=&quot;center&quot;&gt;
  &lt;img align=&quot;center&quot; src=&quot;./assets/struggle.png&quot; alt=&quot;struggle is real&quot;/&gt;
&lt;/p&gt;

Modern app developers often find themselves wrestling with billing systems. Here are some of the biggest pain points that turn billing into a “developer problem”:

- **Rigid billing tools (lack of flexibility):** Traditional billing services handle simple subscriptions or payments, but anything beyond that – usage metering, credit systems, feature gating, custom invoice logic – usually isn’t supported out of the box. Developers end up writing countless workarounds or custom code to accommodate these needs. In other words, if your pricing model doesn’t fit the tool, you’re stuck bending your product or building logic from scratch.

- **Complex usage metering at scale:** Implementing accurate usage tracking is hard. It involves capturing high-volume events, aggregating them in real time, handling edge cases (prorations, time zones, etc.), and ensuring it all works reliably at scale. Few teams anticipate how many moving parts this requires until they’re deep in the weeds of building it.

- **Vendor lock-in and black boxes:** Relying on third-party billing platforms can mean surrendering flexibility. Many SaaS billing providers are closed systems or charge a percentage fee on revenue, which frustrates engineers who want full control over their pricing logic and data. Changing providers later can be a massive undertaking, so teams feel “stuck” with a less-than-ideal solution.

- **Delayed monetization &amp; opportunity cost:** Every week spent building or patching a billing system is a week not spent on core product features. If it takes months to implement a new pricing model or usage-based feature, that’s delayed revenue and lost agility for the business. What might be scoped as a “quick two-month project” can quickly spiral into a multi-year maintenance headache, tying up engineering resources and slowing time-to-market for new offerings.

## How Flexprice solves this

Flexprice’s approach is to abstract away the hard parts of billing while preserving maximum flexibility and transparency for developers. It addresses the above pain points in several key ways:

- **Developer-first design:** Flexprice is built API-first with easy integrations. You can instrument your app by simply sending usage events via SDKs, and Flexprice handles the aggregation, metering, and billing logic in real time. This means minimal code to write on your end and no need to reinvent metering or invoice calculations.

* **Open-source and self-hostable:** Flexprice is open-source, so you can run it on your own infrastructure for full transparency and control. There’s no black-box dependency or surprise fees and you’re free from vendor lock-in. You can inspect the code, extend functionality, and trust that your billing logic is fully in your hands.
    
    
- **Composable with your stack:** Rather than replacing your existing billing or payment provider, Flexprice augments it. You can build it from scratch or build on top of your existing billing providers like Stripe or Chargebee to manage usage data, pricing rules, credits, and entitlements. You can easily integrate with your existing payment gateways, CRM, CPQ, etc. This layered approach preserves your current workflows and customer touchpoints.
    
    
* **Flexible pricing models out-of-the-box:** Whether you need pure usage-based billing, tiered plans, seat-based subscriptions, prepaid credits, free tiers with overage, or any hybrid model, Flexprice’s data model and rules engine can support it. Flexprice is designed to accommodate changing pricing strategies in minutues that would normally require schema updates and migration scripts.

- **Transparency and visibility:** Because Flexprice meters every event and ties it to billing, you (and your customers) get clear visibility into usage and charges. It can provide real-time usage summaries and cost reports, helping both engineering and finance teams ensure everything lines up correctly. Customers get detailed invoices that show exactly what they’re paying for, reducing billing disputes or confusion.

By handling the heavy lifting from real-time usage tracking to invoice generation, Flexprice lets your team focus on building your actual product, not the billing system around it

## **Features**

Flexprice provides a rich set of features to power usage-based and hybrid billing models. Key features include:

&lt;p align=&quot;center&quot;&gt;
  &lt;img align=&quot;center&quot; src=&quot;./assets/features.jpg&quot; alt=&quot;features&quot;/&gt;
&lt;/p&gt;

*  [**Usage Metering:**](https://docs.flexprice.io/api-reference/events/get-raw-events) Define custom usage events (API calls, compute time, database queries, etc.) at a granular level and track them in real time. Flexprice’s metering system can handle millions of events and aggregates usage data reliably, even at peak load. This ensures your billing is always up-to-date with actual customer usage.
- [**Credit Grants (Prepaid &amp; Promotional Credits):**](https://docs.flexprice.io/docs/Wallet/Creating%20a%20wallet) Support credit-based workflows with full control. You can grant prepaid credits or promotional credits to customers, set up automatic top-ups at thresholds, and expire unused credits as needed. Flexprice’s credit system is built-in, so you don’t need extra custom logic to handle one-time credits or wallets.
* [**Pricing Plans:**](https://docs.flexprice.io/docs/Product%20catalogue/Plans/Overview) Design and iterate on pricing models with total flexibility – whether seat-based subscriptions, pure pay-as-you-go, volume-tiered pricing, or hybrids. You can launch new plans or modify existing ones (e.g. special pricing for a particular customer) without additional engineering effort. Flexprice lets you override plan settings per customer and manage plan versioning over time, making it easy to evolve pricing as your product and market strategy change.
- [**Feature Management:**](https://docs.flexprice.io/docs/Product%20catalogue/Features/Overview) Manage feature entitlements and usage limits per plan or per customer. Flexprice lets you define feature toggles (on/off), metered feature limits, or configuration values tied to plans. You can enforce usage limits in your application by checking with Flexprice (for example, limit API calls per month or enable/disable certain features based on plan) without building complex entitlement logic yourself. This ensures that your product’s feature access is always in sync with what the customer has paid for.
* [**Subscriptions &amp; Invoicing:**](https://docs.flexprice.io/docs/Invoices/Overview) Flexprice generates clear, accurate invoices based on real-time usage data, subscriptions, and credits. It automates billing cycles – handling proration, overages, and credit application – and produces invoice line items that give customers full visibility into their charges. Finance teams can easily reconcile billing because every charge is linked to tracked usage or a defined price. You can also integrate this with your payment processor to automate charging customers once an invoice is finalized.

Each of these features is accessible via Flexprice’s APIs and dashboard, allowing you to mix and match to build the exact billing experience you need.


### 🚀 Setting up Flexprice from source for development and contributions

To run Flexprice for local development or running from source, you will need

1. [Golang](https://go.dev/)
2. [Docker](https://www.docker.com/) and [Docker Compose](https://docs.docker.com/compose/)
3. Any of the below supported platform environments:
    1. [Linux based environment](https://en.wikipedia.org/wiki/Comparison_of_Linux_distributions)
    2. [OSX (Darwin) based environment](https://en.wikipedia.org/wiki/MacOS)
    3. WSL under Windows

#### Quick Setup with Docker Compose

The easiest way to get started is using our Docker Compose setup:

```bash
# Clone the repository
git clone https://github.com/flexprice/flexprice
cd flexprice

# Set up the complete development environment
make dev-setup
```

This will:
1. Start all required infrastructure (PostgreSQL, Kafka, ClickHouse, Temporal)
2. Build the FlexPrice application image
3. Run database migrations and initialize Kafka
4. Start all FlexPrice services (API, Consumer, Worker)

Once complete, you can access:
- FlexPrice API: http://localhost:8080
- Temporal UI: http://localhost:8088
- Kafka UI: http://localhost:8084 (with profile &#039;dev&#039;)
- ClickHouse UI: http://localhost:8123

#### Useful Commands

```bash
# Restart only the FlexPrice services
make restart-flexprice

# Stop all services
make down

# Clean everything and start fresh
make clean-start

# Build the FlexPrice image separately
make build-image

# Start only the FlexPrice services
make start-flexprice
```

#### Running Without Docker

If you prefer to run the application directly:

```bash
# Start the required infrastructure
docker compose up -d postgres kafka clickhouse temporal temporal-ui

# Run the application locally
go run cmd/server/main.go
```


## 👨🏻‍💻 Let&#039;s Build Together! 👩🏻‍💻

Whether you&#039;re a newbie coder or a wizard 🧙‍♀️, your perspective is golden. Take a peek at our:

📜 [Contribution Guidelines](CONTRIBUTING.md)

🏗️ [Local Development Setup](SETUP.md)

❤️ [Code of Conduct](CODE_OF_CONDUCT.md)

[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/flexprice/flexprice)

## Contributors

&lt;a href=&quot;https://github.com/flexprice/flexprice/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=flexprice/flexprice&quot; /&gt;
&lt;/a&gt;

## Repo Activity

![Alt](https://repobeats.axiom.co/api/embed/4d6e208eab20ff0615787615c4fa022591adfa6b.svg &quot;Repobeats analytics image&quot;)

&lt;!-- LICENSE --&gt;

## License

Flexprice is a commercial open source company, which means some parts of this open source repository require a commercial license. The concept is called &quot;Open Core&quot; where the core technology (99%) is fully open source, licensed under [AGPLv3](https://opensource.org/license/agpl-v3) and the last 1% is covered under a commercial license ([&quot;/ee&quot; Enterprise Edition&quot;]).

&gt; [!TIP]
&gt; We work closely with the community and always invite feedback about what should be open and what is fine to be commercial. This list is not set and stone and we have moved things from commercial to open in the past. Please open a [discussion](https://github.com/flexprice/flexprice/discussions) if you feel like something is wrong.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grpc-ecosystem/grpc-gateway]]></title>
            <link>https://github.com/grpc-ecosystem/grpc-gateway</link>
            <guid>https://github.com/grpc-ecosystem/grpc-gateway</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[gRPC to JSON proxy generator following the gRPC HTTP spec]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grpc-ecosystem/grpc-gateway">grpc-ecosystem/grpc-gateway</a></h1>
            <p>gRPC to JSON proxy generator following the gRPC HTTP spec</p>
            <p>Language: Go</p>
            <p>Stars: 19,491</p>
            <p>Forks: 2,341</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;h1&gt;gRPC-Gateway&lt;/h1&gt;
&lt;p&gt;
gRPC to JSON proxy generator following the gRPC HTTP spec
&lt;/p&gt;
&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/grpc-ecosystem/grpc-gateway/ci.yml?color=379c9c&amp;label=build&amp;logo=github&amp;logoColor=ffffff&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://app.slack.com/client/T029RQSE6/CBATURP1D&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/slack-grpc--gateway-379c9c?logo=slack&amp;logoColor=ffffff&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/grpc-ecosystem/grpc-gateway?color=379c9c&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/grpc-ecosystem/grpc-gateway?color=379c9c&amp;logoColor=ffffff&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/grpc-ecosystem/grpc-gateway?color=379c9c&amp;style=flat-square&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://slsa.dev/images/gh-badge-level3.svg&quot;&gt;&lt;img src=&quot;https://slsa.dev/images/gh-badge-level3.svg&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

## About

The gRPC-Gateway is a plugin of the Google protocol buffers compiler
[protoc](https://github.com/protocolbuffers/protobuf).
It reads protobuf service definitions and generates a reverse-proxy server which
translates a RESTful HTTP API into gRPC. This server is generated according to the
[`google.api.http`](https://github.com/googleapis/googleapis/blob/master/google/api/http.proto#L46)
annotations in your service definitions.

This helps you provide your APIs in both gRPC and RESTful style at the same time.

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;docs/assets/images/architecture_introduction_diagram.svg&quot; /&gt;
&lt;/div&gt;

## Docs

You can read our docs at:

- https://grpc-ecosystem.github.io/grpc-gateway/

## Testimonials

&gt; We use the gRPC-Gateway to serve millions of API requests per day,
&gt; and have been since 2018 and through all of that,
&gt; we have never had any issues with it.
&gt;
&gt; _- William Mill, [Ad Hoc](http://adhocteam.us/)_

## Background

gRPC is great -- it generates API clients and server stubs in many programming
languages, it is fast, easy-to-use, bandwidth-efficient and its design is
combat-proven by Google. However, you might still want to provide a traditional
RESTful JSON API as well. Reasons can range from maintaining
backward-compatibility, supporting languages or clients that are not well supported by
gRPC, to simply maintaining the aesthetics and tooling involved with a RESTful
JSON architecture.

This project aims to provide that HTTP+JSON interface to your gRPC service.
A small amount of configuration in your service to attach HTTP semantics is all
that&#039;s needed to generate a reverse-proxy with this library.

## Installation

### Compile from source

The following instructions assume you are using
[Go Modules](https://go.dev/wiki/Modules) for dependency
management. Use a
[tool dependency](https://go.dev/wiki/Modules#how-can-i-track-tool-dependencies-for-a-module)
to track the versions of the following executable packages:

```go
// +build tools

package tools

import (
    _ &quot;github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway&quot;
    _ &quot;github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2&quot;
    _ &quot;google.golang.org/grpc/cmd/protoc-gen-go-grpc&quot;
    _ &quot;google.golang.org/protobuf/cmd/protoc-gen-go&quot;
)
```

Run `go mod tidy` to resolve the versions. Install by running

```sh
go install \
    github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway \
    github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2 \
    google.golang.org/protobuf/cmd/protoc-gen-go \
    google.golang.org/grpc/cmd/protoc-gen-go-grpc
```

This will place four binaries in your `$GOBIN`;

- `protoc-gen-grpc-gateway`
- `protoc-gen-openapiv2`
- `protoc-gen-go`
- `protoc-gen-go-grpc`

Make sure that your `$GOBIN` is in your `$PATH`.

### **Using the `tool` Directive in Go 1.24**

Starting from Go 1.24, the `tool` directive in `go.mod` provides a structured way to track and manage executable dependencies. This replaces the previous workaround of using a separate `tools.go` file with blank imports.

#### **Tracking Tools in `go.mod`**

Instead of manually importing tool dependencies in a Go source file, you can now use the `tool` directive in `go.mod` to declare the tools your project depends on. For example:

```go
module tools

go 1.24

tool (
	github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway
	github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2
	google.golang.org/grpc/cmd/protoc-gen-go-grpc
	google.golang.org/protobuf/cmd/protoc-gen-go
)
```

#### **Managing Tool Dependencies**

To add tools to your module, use the `-tool` flag with `go get`:

```sh
go get -tool github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway
go get -tool github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2
go get -tool google.golang.org/protobuf/cmd/protoc-gen-go
go get -tool google.golang.org/grpc/cmd/protoc-gen-go-grpc
```

This automatically updates `go.mod`, adding the tools under the `tool` directive along with `require` statements to ensure version tracking.

### Install Tools

Once the tool dependencies are properly recorded in the `go.mod` file, simply execute the following command in the root directory of your project:

```sh
go install tool
```

This will place four binaries in your `$GOBIN`;

- `protoc-gen-grpc-gateway`
- `protoc-gen-openapiv2`
- `protoc-gen-go`
- `protoc-gen-go-grpc`

Make sure that your `$GOBIN` is in your `$PATH`.

### Download the binaries

You may alternatively download the binaries from the [GitHub releases page](https://github.com/grpc-ecosystem/grpc-gateway/releases/latest).
We generate [SLSA3 signatures](slsa.dev) using the OpenSSF&#039;s [slsa-framework/slsa-github-generator](https://github.com/slsa-framework/slsa-github-generator) during the release process. To verify a release binary:

1. Install the verification tool from [slsa-framework/slsa-verifier#installation](https://github.com/slsa-framework/slsa-verifier#installation).
2. Download the provenance file `attestation.intoto.jsonl` from the [GitHub releases page](https://github.com/grpc-ecosystem/grpc-gateway/releases/latest).
3. Run the verifier:

```shell
slsa-verifier -artifact-path &lt;the-binary&gt; -provenance attestation.intoto.jsonl -source github.com/grpc-ecosystem/grpc-gateway -tag &lt;the-tag&gt;
```

Alternatively, see the section on remotely managed plugin versions below.

## Usage

### 1.Define your [gRPC](https://grpc.io/docs/) service using protocol buffers

`your_service.proto`:

```protobuf
 syntax = &quot;proto3&quot;;
 package your.service.v1;
 option go_package = &quot;github.com/yourorg/yourprotos/gen/go/your/service/v1&quot;;

 message StringMessage {
   string value = 1;
 }

 service YourService {
   rpc Echo(StringMessage) returns (StringMessage) {}
 }
```

### 2. Generate gRPC stubs

This step generates the gRPC stubs that you can use to implement the service and consume from clients:

Here&#039;s an example `buf.gen.yaml` you can use to generate the stubs with [buf](https://github.com/bufbuild/buf):

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
```

With this file in place, you can generate your files using `buf generate`.

&gt; For a complete example of using `buf generate` to generate protobuf stubs, see
&gt; [the boilerplate repo](https://github.com/johanbrandhorst/grpc-gateway-boilerplate).
&gt; For more information on generating the stubs with buf, see
&gt; [the official documentation](https://docs.buf.build/generate-usage).

If you are using `protoc` to generate stubs, here&#039;s an example of what a command
might look like:

```sh
protoc -I . \
    --go_out ./gen/go/ --go_opt paths=source_relative \
    --go-grpc_out ./gen/go/ --go-grpc_opt paths=source_relative \
    your/service/v1/your_service.proto
```

### 3. Implement your service in gRPC as usual.

### 4. Generate reverse-proxy using `protoc-gen-grpc-gateway`

At this point, you have 3 options:

- no further modifications, use the default mapping to HTTP semantics (method, path, etc.)
  - this will work on any `.proto` file, but will not allow setting HTTP paths, request parameters or similar
- additional `.proto` modifications to use a custom mapping
  - relies on parameters in the `.proto` file to set custom HTTP mappings
- no `.proto` modifications, but use an external configuration file
  - relies on an external configuration file to set custom HTTP mappings
  - mostly useful when the source proto file isn&#039;t under your control

#### 1. Using the default mapping

This requires no additional modification to the `.proto` file but does require enabling a specific option when executing the plugin.
The `generate_unbound_methods` should be enabled.

Here&#039;s what a `buf.gen.yaml` file might look like with this option enabled:

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - generate_unbound_methods=true
```

With `protoc` (just the grpc-gateway stubs):

```sh
protoc -I . --grpc-gateway_out ./gen/go \
    --grpc-gateway_opt paths=source_relative \
    --grpc-gateway_opt generate_unbound_methods=true \
    your/service/v1/your_service.proto
```

#### 2. With custom annotations

Add a [`google.api.http`](https://github.com/googleapis/googleapis/blob/master/google/api/http.proto#L46)
annotation to your .proto file

`your_service.proto`:

```diff
 syntax = &quot;proto3&quot;;
 package your.service.v1;
 option go_package = &quot;github.com/yourorg/yourprotos/gen/go/your/service/v1&quot;;
+
+import &quot;google/api/annotations.proto&quot;;
+
 message StringMessage {
   string value = 1;
 }

 service YourService {
-  rpc Echo(StringMessage) returns (StringMessage) {}
+  rpc Echo(StringMessage) returns (StringMessage) {
+    option (google.api.http) = {
+      post: &quot;/v1/example/echo&quot;
+      body: &quot;*&quot;
+    };
+  }
 }
```

&gt; You will need to provide the required third party protobuf files to the protobuf compiler.
&gt; If you are using [buf](https://github.com/bufbuild/buf), this dependency can
&gt; be added to the `deps` array in your `buf.yaml` under the name
&gt; `buf.build/googleapis/googleapis`:
&gt;
&gt; ```yaml
&gt; version: v2
&gt; name: buf.build/yourorg/myprotos
&gt; deps:
&gt;   - buf.build/googleapis/googleapis
&gt; ```
&gt;
&gt; Always run `buf dep update` after adding a dependency to your `buf.yaml`.

See [a_bit_of_everything.proto](examples/internal/proto/examplepb/a_bit_of_everything.proto)
for examples of more annotations you can add to customize gateway behavior
and generated OpenAPI output.

Here&#039;s what a `buf.gen.yaml` file might look like:

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
```

If you are using `protoc` to generate stubs, you need to ensure the required
dependencies are available to the compiler at compile time. These can be found
by manually cloning and copying the relevant files from the
[googleapis repository](https://github.com/googleapis/googleapis), and providing
them to `protoc` when running. The files you will need are:

```
google/api/annotations.proto
google/api/field_behavior.proto
google/api/http.proto
google/api/httpbody.proto
```

Here&#039;s what a `protoc` execution might look like:

```sh
protoc -I . --grpc-gateway_out ./gen/go \
    --grpc-gateway_opt paths=source_relative \
    your/service/v1/your_service.proto
```

#### 3. External configuration

If you do not want to (or cannot) modify the proto file for use with gRPC-Gateway you can
alternatively use an external
[gRPC Service Configuration](https://cloud.google.com/endpoints/docs/grpc/grpc-service-config) file.
[Check our documentation](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/grpc_api_configuration/)
for more information. This is best combined with the `standalone=true` option
to generate a file that can live in its own package, separate from the files
generated by the source protobuf file.

Here&#039;s what a `buf.gen.yaml` file might look like with this option enabled:

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - grpc_api_configuration=path/to/config.yaml
      - standalone=true
```

With `protoc` (just the grpc-gateway stubs):

```sh
protoc -I . --grpc-gateway_out ./gen/go \
    --grpc-gateway_opt paths=source_relative \
    --grpc-gateway_opt grpc_api_configuration=path/to/config.yaml \
    --grpc-gateway_opt standalone=true \
    your/service/v1/your_service.proto
```

### 5. Write an entrypoint for the HTTP reverse-proxy server

```go
package main

import (
  &quot;context&quot;
  &quot;flag&quot;
  &quot;net/http&quot;

  &quot;github.com/grpc-ecosystem/grpc-gateway/v2/runtime&quot;
  &quot;google.golang.org/grpc&quot;
  &quot;google.golang.org/grpc/credentials/insecure&quot;
  &quot;google.golang.org/grpc/grpclog&quot;

  gw &quot;github.com/yourorg/yourrepo/proto/gen/go/your/service/v1/your_service&quot;  // Update
)

var (
  // command-line options:
  // gRPC server endpoint
  grpcServerEndpoint = flag.String(&quot;grpc-server-endpoint&quot;,  &quot;localhost:9090&quot;, &quot;gRPC server endpoint&quot;)
)

func run() error {
  ctx := context.Background()
  ctx, cancel := context.WithCancel(ctx)
  defer cancel()

  // Register gRPC server endpoint
  // Note: Make sure the gRPC server is running properly and accessible
  mux := runtime.NewServeMux()
  opts := []grpc.DialOption{grpc.WithTransportCredentials(insecure.NewCredentials())}
  err := gw.RegisterYourServiceHandlerFromEndpoint(ctx, mux,  *grpcServerEndpoint, opts)
  if err != nil {
    return err
  }

  // Start HTTP server (and proxy calls to gRPC server endpoint)
  return http.ListenAndServe(&quot;:8081&quot;, mux)
}

func main() {
  flag.Parse()

  if err := run(); err != nil {
    grpclog.Fatal(err)
  }
}
```

### 6. (Optional) Generate OpenAPI definitions using `protoc-gen-openapiv2`

Here&#039;s what a `buf.gen.yaml` file might look like:

```yaml
version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - generate_unbound_methods=true
  - local: protoc-gen-openapiv2
    out: gen/go
```

To use the custom protobuf annotations supported by `protoc-gen-openapiv2`, we need
another dependency added to our protobuf generation step. If you are using
`buf`, you can add the `buf.build/grpc-ecosystem/grpc-gateway` dependency
to your `deps` array:

```yaml
version: v2
name: buf.build/yourorg/myprotos
deps:
  - buf.build/googleapis/googleapis
  - buf.build/grpc-ecosystem/grpc-gateway
```

With `protoc` (just the swagger file):

```sh
protoc -I . --openapiv2_out ./gen/openapiv2 \
    your/service/v1/your_service.proto
```

If you are using `protoc` to generate stubs, you will need to copy the protobuf
files from the `protoc-gen-openapiv2/options` directory of this repository,
and providing them to `protoc` when running.

Note that this plugin also supports generating OpenAPI definitions for unannotated methods;
use the `generate_unbound_methods` option to enable this.

It is possible with the HTTP mapping for a gRPC service method to create duplicate mappings
with the only difference being constraints on the path parameter.

`/v1/{name=projects/*}` and `/v1/{name=organizations/*}` both become `/v1/{name}`. When
this occurs the plugin will rename the path parameter with a &quot;\_1&quot; (or &quot;\_2&quot; etc) suffix
to differentiate the different operations. So in the above example, the 2nd path would become
`/v1/{name_1=organizations/*}`. This can also cause OpenAPI clients to URL encode the &quot;/&quot; that is
part of the path parameter as that is what OpenAPI defines in the specification. To allow gRPC gateway to
accept the URL encoded slash and still route the request, use the UnescapingModeAllCharacters or
UnescapingModeLegacy (which is the default currently though may change in future versions). See
[Customizing Your Gateway](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/customizing_your_gateway/)
for more information.

## Usage with remote plugins

As an alternative to all of the above, you can use `buf` with
[remote plugins](https://buf.build/docs/bsr/remote-plugins/usage)
to manage plugin versions and generation. An example `buf.gen.yaml` using remote
plugin generation looks like this:

```yaml
version: v2
plugins:
  - remote: buf.build/protocolbuffers/go:v1.31.0
    out: gen/go
    opt:
      - paths=source_relative
  - remote: buf.build/grpc/go:v1.3.0
    out: gen/go
    opt:
      - paths=source_relative
  - remote: buf.build/grpc-ecosystem/gateway:v2.16.2
    out: gen/go
    opt:
      - paths=source_relative
  - remote: buf.build/grpc-ecosystem/openapiv2:v2.16.2
    out: gen/openapiv2
```

This requires no local installation of any plugins. Be careful to use the same
version of the generator as the runtime library, i.e. if using `v2.16.2`, run

```shell
$ go get github.com/grpc-ecosystem/grpc-gateway/v2@v2.16.2
```

To get the same version of the runtime in your `go.mod`.

Note that usage of remote plugins is incompatible with usage of external configuration files like [grpc_api_configuration](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/grpc_api_configuration/#using-an-external-configuration-file).

## Video intro

This GopherCon UK 2019 presentation from our maintainer [@JohanBrandhorst](https://github.com/johanbrandhorst) provides a good intro to using the gRPC-Gateway. It uses the following boilerplate repo as a base: https://github.com/johanbrandhorst/grpc-gateway-boilerplate.

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.youtube.com/watch?v=Pq1paKC-fXk&quot;&gt;
&lt;img src=&quot;https://img.youtube.com/vi/Pq1paKC-fXk/0.jpg&quot; /&gt;
&lt;/a&gt;
&lt;/div&gt;

## Parameters and flags

When using `buf` to generate stubs, flags and parameters are passed through
the `opt` field in your `buf.gen.yaml` file, for example:

```yaml
version: v2
plugins:
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - grpc_api_configuration=path/to/config.yaml
      - standalone=true
```

During code generation with `protoc`, flags to gRPC-Gateway tools must be passed
through `protoc` using one of 2 patterns:

- as part of the `--&lt;tool_suffix&gt;_out` `protoc` parameter: `--&lt;tool_suffix&gt;_out=&lt;flags&gt;:&lt;path&gt;`

```sh
--grpc-gateway_out=repeated_path_param_separator=ssv:.
--openapiv2_out=repeated_path_param_separator=ssv:.
```

- using additional `--&lt;tool_suffix&gt;_opt` parameters: `--&lt;tool_suffix&gt;_opt=&lt;flag&gt;[,&lt;flag&gt;]*`

```sh
--grpc-gateway_opt repeated_path_param_separator=ssv
--openapiv2_opt repeated_path_param_separator=ssv
```

## More examples

More examples are available under the `examples` directory.

- `proto/examplepb/echo_service.proto`, `proto/examplepb/a_bit_of_everything.proto`, `proto/examplepb/unannotated_echo_service.proto`: service definition
  - `proto/examplepb/echo_service.pb.go`, `proto/examplepb/a_bit_of_everything.pb.go`, `proto/examplepb/unannotated_echo_service.pb.go`: [generated] stub of the service
  - `proto/examplepb/echo_service.pb.gw.go`, `proto/examplepb/a_bit_of_everything.pb.gw.go`, `proto/examplepb/uannotated_echo_service.pb.gw.go`: [generate

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[yorukot/superfile]]></title>
            <link>https://github.com/yorukot/superfile</link>
            <guid>https://github.com/yorukot/superfile</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[Pretty fancy and modern terminal file manager]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/yorukot/superfile">yorukot/superfile</a></h1>
            <p>Pretty fancy and modern terminal file manager</p>
            <p>Language: Go</p>
            <p>Stars: 14,665</p>
            <p>Forks: 366</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;p&gt;
  &lt;h4&gt;
    &lt;a href=&quot;https://ko-fi.com/yorukot&quot;&gt;superfile is supported by the community.&lt;/a&gt;
  &lt;/h4&gt;
&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;
   &lt;sup&gt;Special thanks to:&lt;/sup&gt;
   &lt;br&gt;
   &lt;br&gt;
   &lt;a href=&quot;https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=superfile&quot;&gt;
      &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;300&quot; src=&quot;/asset/warp.png&quot;&gt;
   &lt;/a&gt;

### [Warp, the AI terminal for developers](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=superfile)
[Available for MacOS, Linux, &amp; Windows](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=superfile)&lt;br&gt;

&lt;/div&gt;
&lt;hr&gt;

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;/asset/superfilelogowhite.png&quot; /&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;/asset/superfilelogoblack.png&quot; /&gt;
  &lt;img alt=&quot;superfile LOGO&quot; src=&quot;/asset/superfilelogowhite.png&quot; /&gt;
&lt;/picture&gt;

[![Go Report Card](https://goreportcard.com/badge/github.com/yorukot/superfile)](https://goreportcard.com/report/github.com/yorukot/superfile)
[![License MIT](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/yorukot/superfile/refs/heads/main/LICENSE)
[![Discord Link](https://img.shields.io/discord/1338415256875307110?label=discord&amp;logo=discord&amp;logoColor=white)](https://discord.gg/YYtJ23Du7B)
[![Release](https://img.shields.io/github/v/release/yorukot/superfile.svg?style=flat-square)](https://github.com/yorukot/superfile/releases/latest)
[![CodeRabbit Pull Request Reviews](https://img.shields.io/coderabbit/prs/github/yorukot/superfile?utm_source=oss&amp;utm_medium=github&amp;utm_campaign=yorukot%2Fsuperfile&amp;labelColor=171717&amp;color=FF570A&amp;&amp;label=CodeRabbit+Reviews)](https://www.coderabbit.ai/)

![](/asset/demo.png)

&lt;/div&gt;

## Demo

| Perform common operations |
| ------------------------- |
| ![](/asset/demo.gif)      |

## Content

- [Installation](#installation)
- [Build](#build)
- [Supported Systems](#supported-systems)
- [Tutorial](#tutorial)
- [Plugins](#plugins)
- [Themes](#themes)
- [Hotkeys](#hotkeys)
- [Notes](#notes)
- [Contributing](#contributing)
- [Troubleshooting](#troubleshooting)
- [Thanks](#thanks)
  - [Support](#Support)
  - [Contributors](#contributors)
  - [Star History](#star-history)

## Installation

### MacOS and Linux

```bash
bash -c &quot;$(curl -sLo- https://superfile.netlify.app/install.sh)&quot;
```
If you want to inspect the script, see : [install.sh](./website/public/install.sh)

### Windows

#### Powershell
```powershell
powershell -ExecutionPolicy Bypass -Command &quot;Invoke-Expression ((New-Object System.Net.WebClient).DownloadString(&#039;https://superfile.netlify.app/install.ps1&#039;))&quot;
```
If you want to inspect the script, see : [install.ps1](./website/public/install.ps1)

#### [Winget](https://winget.run/)
```powershell
winget install --id yorukot.superfile
```

#### [Scoop](https://scoop.sh/)
```
scoop install superfile
```

### More installation methods
[Click me to check on how to install](https://superfile.netlify.app/getting-started/installation/)

## Build

You can build the source code yourself by using these steps:

**Requirements**

- [golang](https://go.dev/doc/install)

**Build Steps**

Clone this repository using the following command:

```
git clone https://github.com/yorukot/superfile.git --depth=1
```

Enter the downloaded directory:

```bash
cd superfile
```

### For MacOS/Linux
Run the `build.sh` file:

```bash
./build.sh
```

Add the binary file to your $PATH, e.g., in `/usr/local/bin`:

```bash
sudo mv ./bin/spf /usr/local/bin
```

### For Windows

```bash
go build -o bin/spf.exe
```

Edit System Environment Variables and add superfile repo&#039;s `bin` directory to your PATH  

## Start superfile

```bash
spf
```

## Supported Systems

- \[x\] Linux
- \[x\] MacOS
- \[x\] Windows (Not fully supported yet)

## Tutorial

After you install superfile, you can go [here](https://superfile.netlify.app/getting-started/tutorial/) to briefly understand how to use superfile!

## Plugins

[Click me to the plugins wiki](https://superfile.netlify.app/list/plugin-list/)

## Themes

[Click me to the theme wiki](https://superfile.netlify.app/configure/custom-theme/)

## Hotkeys

&gt; [!WARNING]
&gt; If you are vim/nvim user please change your default hotkeys config to vim version!

[**Click me to see the hotkey wiki**](https://superfile.netlify.app/configure/custom-hotkeys/)

## Notes

We have an auto update functionality, that fetches superfile&#039;s latest released version from github (if last timestamp of last version check was less than 24 hours) and prints a prompt to user, if there is a newer version available.

You can turn this off, by setting `auto_check_update` to false in superfile config. [**Click me to see the config wiki**](https://superfile.netlify.app/configure/superfile-config/) 

## Troubleshooting

[**Click me to see common problem fix**](https://superfile.netlify.app/troubleshooting/)

## Uninstalling

### MacOS and Linux

On MacOS and Linux, you can uninstall superfile by simply removing the binary. If you installed superfile with sudo, runw

```bash
sudo rm /usr/local/bin/spf
```

If you installed superfile without sudo, run

```bash
rm ~/.local/bin/spf
```

If you don&#039;t rember, just try removing both.


### Window

To uninstall superfile on Windows, use this powershell script.

```powershell
powershell -ExecutionPolicy Bypass -Command &quot;Invoke-Expression ((New-Object System.Net.WebClient).DownloadString(&#039;https://superfile.netlify.app/uninstall.ps1&#039;))&quot;
```

## Contributing

If you want to contribute please follow the [contribution guide](./CONTRIBUTING.md)

[**Click me to see changelog**](https://superfile.netlify.app/changelog)

## Thanks

### Support

- a Star on my GitHub repository would be nice 🌟
- You can buy a coffee for me 💖

[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/G2G1JEGGC)

### Contributors

**Thanks to all the contributors for making this project even greater!**

&lt;a href=&quot;https://github.com/yorukot/superfile/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=yorukot/superfile&quot; /&gt;
&lt;/a&gt;

### Star History

**THANKS FOR All OF YOUR STARS!**
Your stars are my motivation to keep updating!

&lt;a href=&quot;https://star-history.com/#yorukot/superfile&amp;Timeline&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=yorukot/superfile&amp;type=Timeline&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=yorukot/superfile&amp;type=Timeline&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=yorukot/superfile&amp;type=Timeline&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;


&lt;div align=&quot;center&quot;&gt;

## ༼ つ ◕_◕ ༽つ  Please share.

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[vmware-tanzu/velero]]></title>
            <link>https://github.com/vmware-tanzu/velero</link>
            <guid>https://github.com/vmware-tanzu/velero</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Backup and migrate Kubernetes applications and their persistent volumes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vmware-tanzu/velero">vmware-tanzu/velero</a></h1>
            <p>Backup and migrate Kubernetes applications and their persistent volumes</p>
            <p>Language: Go</p>
            <p>Stars: 9,412</p>
            <p>Forks: 1,466</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>![100]

[![Build Status][1]][2] [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3811/badge)](https://bestpractices.coreinfrastructure.org/projects/3811)
![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/vmware-tanzu/velero)

## Overview

Velero (formerly Heptio Ark) gives you tools to back up and restore your Kubernetes cluster resources and persistent volumes. You can run Velero with a public cloud platform or on-premises. 

Velero lets you:

* Take backups of your cluster and restore in case of loss.
* Migrate cluster resources to other clusters.
* Replicate your production cluster to development and testing clusters.

Velero consists of:

* A server that runs on your cluster
* A command-line client that runs locally

## Documentation

[The documentation][29] provides a getting started guide and information about building from source, architecture, extending Velero and more.

Please use the version selector at the top of the site to ensure you are using the appropriate documentation for your version of Velero.

## Troubleshooting

If you encounter issues, review the [troubleshooting docs][30], [file an issue][4], or talk to us on the [#velero channel][25] on the Kubernetes Slack server.

## Contributing

If you are ready to jump in and test, add code, or help with documentation, follow the instructions on our [Start contributing][31] documentation for guidance on how to setup Velero for development.

## Changelog

See [the list of releases][6] to find out about feature changes.

### Velero compatibility matrix

The following is a list of the supported Kubernetes versions for each Velero version.

| Velero version | Expected Kubernetes version compatibility | Tested on Kubernetes version        |
|----------------|-------------------------------------------|-------------------------------------|
| 1.16           | 1.18-latest                               | 1.31.4, 1.32.3, and 1.33.0          |
| 1.15           | 1.18-latest                               | 1.28.8, 1.29.8, 1.30.4 and 1.31.1   |
| 1.14           | 1.18-latest                               | 1.27.9, 1.28.9, and 1.29.4          |
| 1.13           | 1.18-latest                               | 1.26.5, 1.27.3, 1.27.8, and 1.28.3  |
| 1.12           | 1.18-latest                               | 1.25.7, 1.26.5, 1.26.7, and 1.27.3  |
| 1.11           | 1.18-latest                               | 1.23.10, 1.24.9, 1.25.5, and 1.26.1 |

Velero supports IPv4, IPv6, and dual stack environments. Support for this was tested against Velero v1.8.

The Velero maintainers are continuously working to expand testing coverage, but are not able to test every combination of Velero and supported Kubernetes versions for each Velero release. The table above is meant to track the current testing coverage and the expected supported Kubernetes versions for each Velero version.

If you are interested in using a different version of Kubernetes with a given Velero version, we&#039;d recommend that you perform testing before installing or upgrading your environment. For full information around capabilities within a release, also see the Velero [release notes](https://github.com/vmware-tanzu/velero/releases) or Kubernetes [release notes](https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG). See the Velero [support page](https://velero.io/docs/latest/support-process/) for information about supported versions of Velero.

For each release, Velero maintainers run the test to ensure the upgrade path from n-2 minor release.  For example, before the release of v1.10.x, the test will verify that the backup created by v1.9.x and v1.8.x can be restored using the build to be tagged as v1.10.x.

[1]: https://github.com/vmware-tanzu/velero/workflows/Main%20CI/badge.svg
[2]: https://github.com/vmware-tanzu/velero/actions?query=workflow%3A&quot;Main+CI&quot;
[4]: https://github.com/vmware-tanzu/velero/issues
[6]: https://github.com/vmware-tanzu/velero/releases
[9]: https://kubernetes.io/docs/setup/
[10]: https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-with-homebrew-on-macos
[11]: https://kubernetes.io/docs/tasks/tools/install-kubectl/#tabset-1
[12]: https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/dns/README.md
[14]: https://github.com/kubernetes/kubernetes
[24]: https://groups.google.com/forum/#!forum/projectvelero
[25]: https://kubernetes.slack.com/messages/velero
[29]: https://velero.io/docs/
[30]: https://velero.io/docs/troubleshooting
[31]: https://velero.io/docs/start-contributing
[100]: https://velero.io/docs/main/img/velero.png
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[korotovsky/slack-mcp-server]]></title>
            <link>https://github.com/korotovsky/slack-mcp-server</link>
            <guid>https://github.com/korotovsky/slack-mcp-server</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[The most powerful MCP Slack Server with no permission requirements, Apps support, multiple transports Stdio and SSE, DMs, Group DMs and smart history fetch logic.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/korotovsky/slack-mcp-server">korotovsky/slack-mcp-server</a></h1>
            <p>The most powerful MCP Slack Server with no permission requirements, Apps support, multiple transports Stdio and SSE, DMs, Group DMs and smart history fetch logic.</p>
            <p>Language: Go</p>
            <p>Stars: 547</p>
            <p>Forks: 69</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># Slack MCP Server
[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/korotovsky/slack-mcp-server)](https://archestra.ai/mcp-catalog/korotovsky__slack-mcp-server)

Model Context Protocol (MCP) server for Slack Workspaces. The most powerful MCP Slack server — supports Stdio and SSE transports, proxy settings, DMs, Group DMs, Smart History fetch (by date or count), may work via OAuth or in complete stealth mode with no permissions and scopes in Workspace 😏.

&gt; [!IMPORTANT]  
&gt; We need your support! Each month, over 30,000 engineers visit this repository, and more than 9,000 are already using it.
&gt; 
&gt; If you appreciate the work our [contributors](https://github.com/korotovsky/slack-mcp-server/graphs/contributors) have put into this project, please consider giving the repository a star.

This feature-rich Slack MCP Server has:
- **Stealth and OAuth Modes**: Run the server without requiring additional permissions or bot installations (stealth mode), or use secure OAuth tokens for access without needing to refresh or extract tokens from the browser (OAuth mode).
- **Enterprise Workspaces Support**: Possibility to integrate with Enterprise Slack setups.
- **Channel and Thread Support with `#Name` `@Lookup`**: Fetch messages from channels and threads, including activity messages, and retrieve channels using their names (e.g., #general) as well as their IDs.
- **Smart History**: Fetch messages with pagination by date (d1, 7d, 1m) or message count.
- **Search Messages**: Search messages in channels, threads, and DMs using various filters like date, user, and content.
- **Safe Message Posting**: The `conversations_add_message` tool is disabled by default for safety. Enable it via an environment variable, with optional channel restrictions.
- **DM and Group DM support**: Retrieve direct messages and group direct messages.
- **Embedded user information**: Embed user information in messages, for better context.
- **Cache support**: Cache users and channels for faster access.
- **Stdio/SSE Transports &amp; Proxy Support**: Use the server with any MCP client that supports Stdio or SSE transports, and configure it to route outgoing requests through a proxy if needed.

### Analytics Demo

![Analytics](images/feature-1.gif)

### Add Message Demo

![Add Message](images/feature-2.gif)

## Tools

### 1. conversations_history:
Get messages from the channel (or DM) by channel_id, the last row/column in the response is used as &#039;cursor&#039; parameter for pagination if not empty
- **Parameters:**
  - `channel_id` (string, required):     - `channel_id` (string): ID of the channel in format Cxxxxxxxxxx or its name starting with `#...` or `@...` aka `#general` or `@username_dm`.
  - `include_activity_messages` (boolean, default: false): If true, the response will include activity messages such as `channel_join` or `channel_leave`. Default is boolean false.
  - `cursor` (string, optional): Cursor for pagination. Use the value of the last row and column in the response as next_cursor field returned from the previous request.
  - `limit` (string, default: &quot;1d&quot;): Limit of messages to fetch in format of maximum ranges of time (e.g. 1d - 1 day, 1w - 1 week, 30d - 30 days, 90d - 90 days which is a default limit for free tier history) or number of messages (e.g. 50). Must be empty when &#039;cursor&#039; is provided.

### 2. conversations_replies:
Get a thread of messages posted to a conversation by channelID and `thread_ts`, the last row/column in the response is used as `cursor` parameter for pagination if not empty.
- **Parameters:**
  - `channel_id` (string, required): ID of the channel in format `Cxxxxxxxxxx` or its name starting with `#...` or `@...` aka `#general` or `@username_dm`.
  - `thread_ts` (string, required): Unique identifier of either a thread’s parent message or a message in the thread. ts must be the timestamp in format `1234567890.123456` of an existing message with 0 or more replies.
  - `include_activity_messages` (boolean, default: false): If true, the response will include activity messages such as &#039;channel_join&#039; or &#039;channel_leave&#039;. Default is boolean false.
  - `cursor` (string, optional): Cursor for pagination. Use the value of the last row and column in the response as next_cursor field returned from the previous request.
  - `limit` (string, default: &quot;1d&quot;): Limit of messages to fetch in format of maximum ranges of time (e.g. 1d - 1 day, 1w - 1 week, 30d - 30 days, 90d - 90 days which is a default limit for free tier history) or number of messages (e.g. 50). Must be empty when &#039;cursor&#039; is provided.

### 3. conversations_add_message
Add a message to a public channel, private channel, or direct message (DM, or IM) conversation by channel_id and thread_ts.

&gt; **Note:** Posting messages is disabled by default for safety. To enable, set the `SLACK_MCP_ADD_MESSAGE_TOOL` environment variable. If set to a comma-separated list of channel IDs, posting is enabled only for those specific channels. See the Environment Variables section below for details.

- **Parameters:**
  - `channel_id` (string, required): ID of the channel in format `Cxxxxxxxxxx` or its name starting with `#...` or `@...` aka `#general` or `@username_dm`.
  - `thread_ts` (string, optional): Unique identifier of either a thread’s parent message or a message in the thread_ts must be the timestamp in format `1234567890.123456` of an existing message with 0 or more replies. Optional, if not provided the message will be added to the channel itself, otherwise it will be added to the thread.
  - `payload` (string, required): Message payload in specified content_type format. Example: &#039;Hello, world!&#039; for text/plain or &#039;# Hello, world!&#039; for text/markdown.
  - `content_type` (string, default: &quot;text/markdown&quot;): Content type of the message. Default is &#039;text/markdown&#039;. Allowed values: &#039;text/markdown&#039;, &#039;text/plain&#039;.

### 4. conversations_search_messages
Search messages in a public channel, private channel, or direct message (DM, or IM) conversation using filters. All filters are optional, if not provided then search_query is required.
- **Parameters:**
  - `search_query` (string, optional): Search query to filter messages. Example: &#039;marketing report&#039; or full URL of Slack message e.g. &#039;https://slack.com/archives/C1234567890/p1234567890123456&#039;, then the tool will return a single message matching given URL, herewith all other parameters will be ignored.
  - `filter_in_channel` (string, optional): Filter messages in a specific channel by its ID or name. Example: `C1234567890` or `#general`. If not provided, all channels will be searched.
  - `filter_in_im_or_mpim` (string, optional): Filter messages in a direct message (DM) or multi-person direct message (MPIM) conversation by its ID or name. Example: `D1234567890` or `@username_dm`. If not provided, all DMs and MPIMs will be searched.
  - `filter_users_with` (string, optional): Filter messages with a specific user by their ID or display name in threads and DMs. Example: `U1234567890` or `@username`. If not provided, all threads and DMs will be searched.
  - `filter_users_from` (string, optional): Filter messages from a specific user by their ID or display name. Example: `U1234567890` or `@username`. If not provided, all users will be searched.
  - `filter_date_before` (string, optional): Filter messages sent before a specific date in format `YYYY-MM-DD`. Example: `2023-10-01`, `July`, `Yesterday` or `Today`. If not provided, all dates will be searched.
  - `filter_date_after` (string, optional): Filter messages sent after a specific date in format `YYYY-MM-DD`. Example: `2023-10-01`, `July`, `Yesterday` or `Today`. If not provided, all dates will be searched.
  - `filter_date_on` (string, optional): Filter messages sent on a specific date in format `YYYY-MM-DD`. Example: `2023-10-01`, `July`, `Yesterday` or `Today`. If not provided, all dates will be searched.
  - `filter_date_during` (string, optional): Filter messages sent during a specific period in format `YYYY-MM-DD`. Example: `July`, `Yesterday` or `Today`. If not provided, all dates will be searched.
  - `filter_threads_only` (boolean, default: false): If true, the response will include only messages from threads. Default is boolean false.
  - `cursor` (string, default: &quot;&quot;): Cursor for pagination. Use the value of the last row and column in the response as next_cursor field returned from the previous request.
  - `limit` (number, default: 20): The maximum number of items to return. Must be an integer between 1 and 100.

### 5. channels_list:
Get list of channels
- **Parameters:**
  - `channel_types` (string, required): Comma-separated channel types. Allowed values: `mpim`, `im`, `public_channel`, `private_channel`. Example: `public_channel,private_channel,im`
  - `sort` (string, optional): Type of sorting. Allowed values: `popularity` - sort by number of members/participants in each channel.
  - `limit` (number, default: 100): The maximum number of items to return. Must be an integer between 1 and 1000 (maximum 999).
  - `cursor` (string, optional): Cursor for pagination. Use the value of the last row and column in the response as next_cursor field returned from the previous request.

## Resources

The Slack MCP Server exposes two special directory resources for easy access to workspace metadata:

### 1. `slack://&lt;workspace&gt;/channels` — Directory of Channels

Fetches a CSV directory of all channels in the workspace, including public channels, private channels, DMs, and group DMs.

- **URI:** `slack://&lt;workspace&gt;/channels`
- **Format:** `text/csv`
- **Fields:**
  - `id`: Channel ID (e.g., `C1234567890`)
  - `name`: Channel name (e.g., `#general`, `@username_dm`)
  - `topic`: Channel topic (if any)
  - `purpose`: Channel purpose/description
  - `memberCount`: Number of members in the channel

### 2. `slack://&lt;workspace&gt;/users` — Directory of Users

Fetches a CSV directory of all users in the workspace.

- **URI:** `slack://&lt;workspace&gt;/users`
- **Format:** `text/csv`
- **Fields:**
  - `userID`: User ID (e.g., `U1234567890`)
  - `userName`: Slack username (e.g., `john`)
  - `realName`: User’s real name (e.g., `John Doe`)

## Setup Guide

- [Authentication Setup](docs/01-authentication-setup.md)
- [Installation](docs/02-installation.md)
- [Configuration and Usage](docs/03-configuration-and-usage.md)

### Environment Variables (Quick Reference)

| Variable                          | Required? | Default                   | Description                                                                                                                                                                                                                                                                               |
|-----------------------------------|-----------|---------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `SLACK_MCP_XOXC_TOKEN`            | Yes*      | `nil`                     | Slack browser token (`xoxc-...`)                                                                                                                                                                                                                                                          |
| `SLACK_MCP_XOXD_TOKEN`            | Yes*      | `nil`                     | Slack browser cookie `d` (`xoxd-...`)                                                                                                                                                                                                                                                     |
| `SLACK_MCP_XOXP_TOKEN`            | Yes*      | `nil`                     | User OAuth token (`xoxp-...`) — alternative to xoxc/xoxd                                                                                                                                                                                                                                  |
| `SLACK_MCP_PORT`                  | No        | `13080`                   | Port for the MCP server to listen on                                                                                                                                                                                                                                                      |
| `SLACK_MCP_HOST`                  | No        | `127.0.0.1`               | Host for the MCP server to listen on                                                                                                                                                                                                                                                      |
| `SLACK_MCP_SSE_API_KEY`           | No        | `nil`                     | Bearer token for SSE transport                                                                                                                                                                                                                                                            |
| `SLACK_MCP_PROXY`                 | No        | `nil`                     | Proxy URL for outgoing requests                                                                                                                                                                                                                                                           |
| `SLACK_MCP_USER_AGENT`            | No        | `nil`                     | Custom User-Agent (for Enterprise Slack environments)                                                                                                                                                                                                                                     |
| `SLACK_MCP_CUSTOM_TLS`            | No        | `nil`                     | Send custom TLS-handshake to Slack servers based on `SLACK_MCP_USER_AGENT` or default User-Agent. (for Enterprise Slack environments)                                                                                                                                                     |
| `SLACK_MCP_SERVER_CA`             | No        | `nil`                     | Path to CA certificate                                                                                                                                                                                                                                                                    |
| `SLACK_MCP_SERVER_CA_TOOLKIT`     | No        | `nil`                     | Inject HTTPToolkit CA certificate to root trust-store for MitM debugging                                                                                                                                                                                                                  |
| `SLACK_MCP_SERVER_CA_INSECURE`    | No        | `false`                   | Trust all insecure requests (NOT RECOMMENDED)                                                                                                                                                                                                                                             |
| `SLACK_MCP_ADD_MESSAGE_TOOL`      | No        | `nil`                     | Enable message posting via `conversations_add_message` by setting it to true for all channels, a comma-separated list of channel IDs to whitelist specific channels, or use `!` before a channel ID to allow all except specified ones, while an empty value disables posting by default. |
| `SLACK_MCP_ADD_MESSAGE_MARK`      | No        | `nil`                     | When the `conversations_add_message` tool is enabled, any new message sent will automatically be marked as read.                                                                                                                                                                          |
| `SLACK_MCP_ADD_MESSAGE_UNFURLING` | No        | `nil`                     | Enable to let Slack unfurl posted links or set comma-separated list of domains e.g. `github.com,slack.com` to whitelist unfurling only for them. If text contains whitelisted and unknown domain unfurling will be disabled for security reasons.                                         |
| `SLACK_MCP_USERS_CACHE`           | No        | `.users_cache.json`       | Path to the users cache file. Used to cache Slack user information to avoid repeated API calls on startup.                                                                                                                                                                                |
| `SLACK_MCP_CHANNELS_CACHE`        | No        | `.channels_cache_v2.json` | Path to the channels cache file. Used to cache Slack channel information to avoid repeated API calls on startup.                                                                                                                                                                          |
| `SLACK_MCP_LOG_LEVEL`             | No        | `info`                    | Log-level for stdout or stderr. Valid values are: `debug`, `info`, `warn`, `error`, `panic` and `fatal`                                                                                                                                                                                   |

*You need either `xoxp` **or** both `xoxc`/`xoxd` tokens for authentication.

### Limitations matrix &amp; Cache

| Users Cache        | Channels Cache     | Limitations                                                                                                                                                                                                                                                                                                                  |
|--------------------|--------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| :x:                | :x:                | No cache, No LLM context enhancement with user data, tool `channels_list` will be fully not functional. Tools `conversations_*` will have limited capabilities and you won&#039;t be able to search messages by `@userHandle` or `#channel-name`, getting messages by `@userHandle` or `#channel-name` won&#039;t be available either. |
| :white_check_mark: | :x:                | No channels cache, tool `channels_list` will be fully not functional. Tools `conversations_*` will have limited capabilities and you won&#039;t be able to search messages by `@userHandle` or `#channel-name`, getting messages by `@userHandle` or `#channel-name` won&#039;t be available either.                                   |
| :white_check_mark: | :white_check_mark: | No limitations, fully functional Slack MCP Server.                                                                                                                                                                                                                                                                           |

### Debugging Tools

```bash
# Run the inspector with stdio transport
npx @modelcontextprotocol/inspector go run mcp/mcp-server.go --transport stdio

# View logs
tail -n 20 -f ~/Library/Logs/Claude/mcp*.log
```

## Security

- Never share API tokens
- Keep .env files secure and private

## License

Licensed under MIT - see [LICENSE](LICENSE) file. This is not an official Slack product.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[NVIDIA/gpu-operator]]></title>
            <link>https://github.com/NVIDIA/gpu-operator</link>
            <guid>https://github.com/NVIDIA/gpu-operator</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[NVIDIA GPU Operator creates, configures, and manages GPUs in Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NVIDIA/gpu-operator">NVIDIA/gpu-operator</a></h1>
            <p>NVIDIA GPU Operator creates, configures, and manages GPUs in Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 2,258</p>
            <p>Forks: 376</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>[![license](https://img.shields.io/github/license/NVIDIA/gpu-operator?style=flat-square)](https://raw.githubusercontent.com/NVIDIA/gpu-operator/master/LICENSE)
[![pipeline status](https://gitlab.com/nvidia/kubernetes/gpu-operator/badges/master/pipeline.svg)](https://gitlab.com/nvidia/kubernetes/gpu-operator/-/pipelines)
[![coverage report](https://gitlab.com/nvidia/kubernetes/gpu-operator/badges/master/coverage.svg)](https://gitlab.com/nvidia/kubernetes/gpu-operator/-/pipelines)

# NVIDIA GPU Operator

![nvidia-gpu-operator](https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/egx/nvidia-egx-platform-gold-image-full-2c50-d@2x.jpg)

Kubernetes provides access to special hardware resources such as NVIDIA GPUs, NICs, Infiniband adapters and other devices through the [device plugin framework](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/). However, configuring and managing nodes with these hardware resources requires configuration of multiple software components such as drivers, container runtimes or other libraries which  are difficult and prone to errors.
The NVIDIA GPU Operator uses the [operator framework](https://cloud.redhat.com/blog/introducing-the-operator-framework) within Kubernetes to automate the management of all NVIDIA software components needed to provision GPU. These components include the NVIDIA drivers (to enable CUDA), Kubernetes device plugin for GPUs, the NVIDIA Container Runtime, automatic node labelling, [DCGM](https://developer.nvidia.com/dcgm) based monitoring and others.

## Audience and Use-Cases
The GPU Operator allows administrators of Kubernetes clusters to manage GPU nodes just like CPU nodes in the cluster. Instead of provisioning a special OS image for GPU nodes, administrators can rely on a standard OS image for both CPU and GPU nodes and then rely on the GPU Operator to provision the required software components for GPUs.

Note that the GPU Operator is specifically useful for scenarios where the Kubernetes cluster needs to scale quickly - for example provisioning additional GPU nodes on the cloud or on-prem and managing the lifecycle of the underlying software components. Since the GPU Operator runs everything as containers including NVIDIA drivers, the administrators can easily swap various components - simply by starting or stopping containers.

## Product Documentation
For information on platform support and getting started, visit the official documentation [repository](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/overview.html).

## Webinar
[How to easily use GPUs on Kubernetes](https://info.nvidia.com/how-to-use-gpus-on-kubernetes-webinar.html)

## Contributions
[Read the document on contributions](https://github.com/NVIDIA/gpu-operator/blob/master/CONTRIBUTING.md). You can contribute by opening a [pull request](https://help.github.com/en/articles/about-pull-requests).

## Support and Getting Help
Please open [an issue on the GitHub project](https://github.com/NVIDIA/gpu-operator/issues/new) for any questions. Your feedback is appreciated.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[influxdata/telegraf]]></title>
            <link>https://github.com/influxdata/telegraf</link>
            <guid>https://github.com/influxdata/telegraf</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/influxdata/telegraf">influxdata/telegraf</a></h1>
            <p>Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.</p>
            <p>Language: Go</p>
            <p>Stars: 16,125</p>
            <p>Forks: 5,685</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># ![tiger](assets/TelegrafTigerSmall.png &quot;tiger&quot;) Telegraf

[![GoDoc](https://img.shields.io/badge/doc-reference-00ADD8.svg?logo=go)](https://godoc.org/github.com/influxdata/telegraf)
[![Docker pulls](https://img.shields.io/docker/pulls/library/telegraf.svg)](https://hub.docker.com/_/telegraf/)
[![Go Report Card](https://goreportcard.com/badge/github.com/influxdata/telegraf)](https://goreportcard.com/report/github.com/influxdata/telegraf)
[![Circle CI](https://circleci.com/gh/influxdata/telegraf.svg?style=svg)](https://circleci.com/gh/influxdata/telegraf)

Telegraf is an agent for collecting, processing, aggregating, and writing
metrics, logs, and other arbitrary data.

* Offers a comprehensive suite of over 300 plugins, covering a wide range of
  functionalities including system monitoring, cloud services, and message
  passing
* Enables the integration of user-defined code to collect, transform, and
  transmit data efficiently
* Compiles into a standalone static binary without any external dependencies,
  ensuring a streamlined deployment process
* Utilizes TOML for configuration, providing a user-friendly and unambiguous
  setup experience
* Developed with contributions from a diverse community of over 1,200
  contributors

Users can choose plugins from a wide range of topics, including but not limited
to:

* Devices: [OPC UA][], [Modbus][]
* Logs: [File][], [Tail][], [Directory Monitor][]
* Messaging: [AMQP][], [Kafka][], [MQTT][]
* Monitoring: [OpenTelemetry][], [Prometheus][]
* Networking: [Cisco TelemetryMDT][], [gNMI][]
* System monitoring: [CPU][], [Memory][], [Disk][], [Network][], [SMART][],
  [Docker][], [Nvidia SMI][], etc.
* Universal: [Exec][], [HTTP][], [HTTP Listener][], [SNMP][], [SQL][]
* Windows: [Event Log][], [Management Instrumentation][],
  [Performance Counters][]

## 🔨 Installation

For binary builds, Docker images, RPM &amp; DEB packages, and other builds of
Telegraf, please see the [install guide](/docs/INSTALL_GUIDE.md).

See the [releases documentation](/docs/RELEASES.md) for details on versioning
and when releases are made.

## 💻 Usage

Users define a TOML configuration with the plugins and settings they wish to
use, then pass that configuration to Telegraf. The Telegraf agent then
collects data from inputs at each interval and sends data to outputs at each
flush interval.

For a basic walkthrough see [quick start](/docs/QUICK_START.md).

## 📖 Documentation

For a full list of documentation including tutorials, reference and other
material, start with the [/docs directory](/docs/README.md).

Additionally, each plugin has its own README that includes details about how to
configure, use, and sometimes debug or troubleshoot. Look under the
[/plugins directory](/plugins/) for specific plugins.

Here are some commonly used documents:

* [Changelog](/CHANGELOG.md)
* [Configuration](/docs/CONFIGURATION.md)
* [FAQ](/docs/FAQ.md)
* [Releases](https://github.com/influxdata/telegraf/releases)
* [Security](/SECURITY.md)

## ❤️ Contribute

[![Contribute](https://img.shields.io/badge/contribute-to_telegraf-blue.svg?logo=influxdb)](https://github.com/influxdata/telegraf/blob/master/CONTRIBUTING.md)

We love our community of over 1,200 contributors! Many of the plugins included
in Telegraf were originally contributed by community members. Check out
our [contributing guide](CONTRIBUTING.md) if you are interested in helping out.
Also, join us on our [Community Slack](https://influxdata.com/slack) or
[Community Forums](https://community.influxdata.com/) if you have questions or
comments for our engineering teams.

If you are completely new to Telegraf and InfluxDB, you can also enroll for free
at [InfluxDB university](https://www.influxdata.com/university/) to take courses
to learn more.

## ℹ️ Support

[![Slack](https://img.shields.io/badge/slack-join_chat-blue.svg?logo=slack)](https://www.influxdata.com/slack)
[![Forums](https://img.shields.io/badge/discourse-join_forums-blue.svg?logo=discourse)](https://community.influxdata.com/)

Please use the [Community Slack](https://influxdata.com/slack) or
[Community Forums](https://community.influxdata.com/) if you have questions or
comments for our engineering teams. GitHub issues are limited to actual issues
and feature requests only.

## 📜 License

[![MIT](https://img.shields.io/badge/license-MIT-blue)](https://github.com/influxdata/telegraf/blob/master/LICENSE)

[OPC UA]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opcua
[Modbus]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/modbus
[File]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/file
[Tail]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/tail
[Directory Monitor]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/directory_monitor
[AMQP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/amqp_consumer
[Kafka]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/kafka_consumer
[MQTT]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mqtt_consumer
[OpenTelemetry]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opentelemetry
[Prometheus]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/prometheus
[Cisco TelemetryMDT]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cisco_telemetry_mdt
[gNMI]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/gnmi
[CPU]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cpu
[Memory]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mem
[Disk]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/disk
[Network]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/net
[SMART]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/smartctl
[Docker]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker
[Nvidia SMI]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/nvidia_smi
[Exec]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/exec
[HTTP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http
[HTTP Listener]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http_listener_v2
[SNMP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/snmp
[SQL]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/sql
[Event Log]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_eventlog
[Management Instrumentation]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_wmi
[Performance Counters]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[charmbracelet/bubbletea]]></title>
            <link>https://github.com/charmbracelet/bubbletea</link>
            <guid>https://github.com/charmbracelet/bubbletea</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[A powerful little TUI framework 🏗]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/charmbracelet/bubbletea">charmbracelet/bubbletea</a></h1>
            <p>A powerful little TUI framework 🏗</p>
            <p>Language: Go</p>
            <p>Stars: 34,625</p>
            <p>Forks: 980</p>
            <p>Stars today: 49 stars today</p>
            <h2>README</h2><pre># Bubble Tea

&lt;p&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://stuff.charm.sh/bubbletea/bubble-tea-v2-light.png&quot; width=&quot;308&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://stuff.charm.sh/bubbletea/bubble-tea-v2-dark.png&quot; width=&quot;312&quot;&gt;
      &lt;img src=&quot;https://stuff.charm.sh/bubbletea/bubble-tea-v2-light.png&quot; width=&quot;308&quot; /&gt;
    &lt;/picture&gt;
    &lt;br&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/bubbletea/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/charmbracelet/bubbletea.svg&quot; alt=&quot;Latest Release&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://pkg.go.dev/github.com/charmbracelet/bubbletea?tab=doc&quot;&gt;&lt;img src=&quot;https://godoc.org/github.com/charmbracelet/bubbletea?status.svg&quot; alt=&quot;GoDoc&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/bubbletea/actions&quot;&gt;&lt;img src=&quot;https://github.com/charmbracelet/bubbletea/actions/workflows/build.yml/badge.svg?branch=main&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

The fun, functional and stateful way to build terminal apps. A Go framework
based on [The Elm Architecture][elm]. Bubble Tea is well-suited for simple and
complex terminal applications, either inline, full-window, or a mix of both.

&lt;p&gt;
    &lt;img src=&quot;https://stuff.charm.sh/bubbletea/bubbletea-example.gif&quot; width=&quot;100%&quot; alt=&quot;Bubble Tea Example&quot;&gt;
&lt;/p&gt;

Bubble Tea is in use in production and includes a number of features and
performance optimizations we’ve added along the way. Among those is
a framerate-based renderer, mouse support, focus reporting and more.

To get started, see the tutorial below, the [examples][examples], the
[docs][docs], the [video tutorials][youtube] and some common [resources](#libraries-we-use-with-bubble-tea).

[youtube]: https://charm.sh/yt

## By the way

Be sure to check out [Bubbles][bubbles], a library of common UI components for Bubble Tea.

&lt;p&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/bubbles&quot;&gt;&lt;img src=&quot;https://stuff.charm.sh/bubbles/bubbles-badge.png&quot; width=&quot;174&quot; alt=&quot;Bubbles Badge&quot;&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/charmbracelet/bubbles&quot;&gt;&lt;img src=&quot;https://stuff.charm.sh/bubbles-examples/textinput.gif&quot; width=&quot;400&quot; alt=&quot;Text Input Example from Bubbles&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

---

## Tutorial

Bubble Tea is based on the functional design paradigms of [The Elm
Architecture][elm], which happens to work nicely with Go. It&#039;s a delightful way
to build applications.

This tutorial assumes you have a working knowledge of Go.

By the way, the non-annotated source code for this program is available
[on GitHub][tut-source].

[elm]: https://guide.elm-lang.org/architecture/
[tut-source]: https://github.com/charmbracelet/bubbletea/tree/main/tutorials/basics

### Enough! Let&#039;s get to it.

For this tutorial, we&#039;re making a shopping list.

To start we&#039;ll define our package and import some libraries. Our only external
import will be the Bubble Tea library, which we&#039;ll call `tea` for short.

```go
package main

// These imports will be used later on the tutorial. If you save the file
// now, Go might complain they are unused, but that&#039;s fine.
// You may also need to run `go mod tidy` to download bubbletea and its
// dependencies.
import (
    &quot;fmt&quot;
    &quot;os&quot;

    tea &quot;github.com/charmbracelet/bubbletea&quot;
)
```

Bubble Tea programs are comprised of a **model** that describes the application
state and three simple methods on that model:

- **Init**, a function that returns an initial command for the application to run.
- **Update**, a function that handles incoming events and updates the model accordingly.
- **View**, a function that renders the UI based on the data in the model.

### The Model

So let&#039;s start by defining our model which will store our application&#039;s state.
It can be any type, but a `struct` usually makes the most sense.

```go
type model struct {
    choices  []string           // items on the to-do list
    cursor   int                // which to-do list item our cursor is pointing at
    selected map[int]struct{}   // which to-do items are selected
}
```

### Initialization

Next, we’ll define our application’s initial state. In this case, we’re defining
a function to return our initial model, however, we could just as easily define
the initial model as a variable elsewhere, too.

```go
func initialModel() model {
	return model{
		// Our to-do list is a grocery list
		choices:  []string{&quot;Buy carrots&quot;, &quot;Buy celery&quot;, &quot;Buy kohlrabi&quot;},

		// A map which indicates which choices are selected. We&#039;re using
		// the  map like a mathematical set. The keys refer to the indexes
		// of the `choices` slice, above.
		selected: make(map[int]struct{}),
	}
}
```

Next, we define the `Init` method. `Init` can return a `Cmd` that could perform
some initial I/O. For now, we don&#039;t need to do any I/O, so for the command,
we&#039;ll just return `nil`, which translates to &quot;no command.&quot;

```go
func (m model) Init() tea.Cmd {
    // Just return `nil`, which means &quot;no I/O right now, please.&quot;
    return nil
}
```

### The Update Method

Next up is the update method. The update function is called when ”things
happen.” Its job is to look at what has happened and return an updated model in
response. It can also return a `Cmd` to make more things happen, but for now
don&#039;t worry about that part.

In our case, when a user presses the down arrow, `Update`’s job is to notice
that the down arrow was pressed and move the cursor accordingly (or not).

The “something happened” comes in the form of a `Msg`, which can be any type.
Messages are the result of some I/O that took place, such as a keypress, timer
tick, or a response from a server.

We usually figure out which type of `Msg` we received with a type switch, but
you could also use a type assertion.

For now, we&#039;ll just deal with `tea.KeyMsg` messages, which are automatically
sent to the update function when keys are pressed.

```go
func (m model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
    switch msg := msg.(type) {

    // Is it a key press?
    case tea.KeyMsg:

        // Cool, what was the actual key pressed?
        switch msg.String() {

        // These keys should exit the program.
        case &quot;ctrl+c&quot;, &quot;q&quot;:
            return m, tea.Quit

        // The &quot;up&quot; and &quot;k&quot; keys move the cursor up
        case &quot;up&quot;, &quot;k&quot;:
            if m.cursor &gt; 0 {
                m.cursor--
            }

        // The &quot;down&quot; and &quot;j&quot; keys move the cursor down
        case &quot;down&quot;, &quot;j&quot;:
            if m.cursor &lt; len(m.choices)-1 {
                m.cursor++
            }

        // The &quot;enter&quot; key and the spacebar (a literal space) toggle
        // the selected state for the item that the cursor is pointing at.
        case &quot;enter&quot;, &quot; &quot;:
            _, ok := m.selected[m.cursor]
            if ok {
                delete(m.selected, m.cursor)
            } else {
                m.selected[m.cursor] = struct{}{}
            }
        }
    }

    // Return the updated model to the Bubble Tea runtime for processing.
    // Note that we&#039;re not returning a command.
    return m, nil
}
```

You may have noticed that &lt;kbd&gt;ctrl+c&lt;/kbd&gt; and &lt;kbd&gt;q&lt;/kbd&gt; above return
a `tea.Quit` command with the model. That’s a special command which instructs
the Bubble Tea runtime to quit, exiting the program.

### The View Method

At last, it’s time to render our UI. Of all the methods, the view is the
simplest. We look at the model in its current state and use it to return
a `string`. That string is our UI!

Because the view describes the entire UI of your application, you don’t have to
worry about redrawing logic and stuff like that. Bubble Tea takes care of it
for you.

```go
func (m model) View() string {
    // The header
    s := &quot;What should we buy at the market?\n\n&quot;

    // Iterate over our choices
    for i, choice := range m.choices {

        // Is the cursor pointing at this choice?
        cursor := &quot; &quot; // no cursor
        if m.cursor == i {
            cursor = &quot;&gt;&quot; // cursor!
        }

        // Is this choice selected?
        checked := &quot; &quot; // not selected
        if _, ok := m.selected[i]; ok {
            checked = &quot;x&quot; // selected!
        }

        // Render the row
        s += fmt.Sprintf(&quot;%s [%s] %s\n&quot;, cursor, checked, choice)
    }

    // The footer
    s += &quot;\nPress q to quit.\n&quot;

    // Send the UI for rendering
    return s
}
```

### All Together Now

The last step is to simply run our program. We pass our initial model to
`tea.NewProgram` and let it rip:

```go
func main() {
    p := tea.NewProgram(initialModel())
    if _, err := p.Run(); err != nil {
        fmt.Printf(&quot;Alas, there&#039;s been an error: %v&quot;, err)
        os.Exit(1)
    }
}
```

## What’s Next?

This tutorial covers the basics of building an interactive terminal UI, but
in the real world you&#039;ll also need to perform I/O. To learn about that have a
look at the [Command Tutorial][cmd]. It&#039;s pretty simple.

There are also several [Bubble Tea examples][examples] available and, of course,
there are [Go Docs][docs].

[cmd]: https://github.com/charmbracelet/bubbletea/tree/main/tutorials/commands/
[examples]: https://github.com/charmbracelet/bubbletea/tree/main/examples
[docs]: https://pkg.go.dev/github.com/charmbracelet/bubbletea?tab=doc

## Debugging

### Debugging with Delve

Since Bubble Tea apps assume control of stdin and stdout, you’ll need to run
delve in headless mode and then connect to it:

```bash
# Start the debugger
$ dlv debug --headless --api-version=2 --listen=127.0.0.1:43000 .
API server listening at: 127.0.0.1:43000

# Connect to it from another terminal
$ dlv connect 127.0.0.1:43000
```

If you do not explicitly supply the `--listen` flag, the port used will vary
per run, so passing this in makes the debugger easier to use from a script
or your IDE of choice.

Additionally, we pass in `--api-version=2` because delve defaults to version 1
for backwards compatibility reasons. However, delve recommends using version 2
for all new development and some clients may no longer work with version 1.
For more information, see the [Delve documentation](https://github.com/go-delve/delve/tree/master/Documentation/api).

### Logging Stuff

You can’t really log to stdout with Bubble Tea because your TUI is busy
occupying that! You can, however, log to a file by including something like
the following prior to starting your Bubble Tea program:

```go
if len(os.Getenv(&quot;DEBUG&quot;)) &gt; 0 {
	f, err := tea.LogToFile(&quot;debug.log&quot;, &quot;debug&quot;)
	if err != nil {
		fmt.Println(&quot;fatal:&quot;, err)
		os.Exit(1)
	}
	defer f.Close()
}
```

To see what’s being logged in real time, run `tail -f debug.log` while you run
your program in another window.

## Libraries we use with Bubble Tea

- [Bubbles][bubbles]: Common Bubble Tea components such as text inputs, viewports, spinners and so on
- [Lip Gloss][lipgloss]: Style, format and layout tools for terminal applications
- [Harmonica][harmonica]: A spring animation library for smooth, natural motion
- [BubbleZone][bubblezone]: Easy mouse event tracking for Bubble Tea components
- [ntcharts][ntcharts]: A terminal charting library built for Bubble Tea and [Lip Gloss][lipgloss]

[bubbles]: https://github.com/charmbracelet/bubbles
[lipgloss]: https://github.com/charmbracelet/lipgloss
[harmonica]: https://github.com/charmbracelet/harmonica
[bubblezone]: https://github.com/lrstanley/bubblezone
[ntcharts]: https://github.com/NimbleMarkets/ntcharts

## Bubble Tea in the Wild

There are over [10,000 applications](https://github.com/charmbracelet/bubbletea/network/dependents) built with Bubble Tea! Here are a handful of ’em.

### Staff favourites

- [chezmoi](https://github.com/twpayne/chezmoi): securely manage your dotfiles across multiple machines
- [circumflex](https://github.com/bensadeh/circumflex): read Hacker News in the terminal
- [gh-dash](https://www.github.com/dlvhdr/gh-dash): a GitHub CLI extension for PRs and issues
- [Tetrigo](https://github.com/Broderick-Westrope/tetrigo): Tetris in the terminal
- [Signls](https://github.com/emprcl/signls): a generative midi sequencer designed for composition and live performance
- [Superfile](https://github.com/yorukot/superfile): a super file manager

### In Industry

- Microsoft Azure – [Aztify](https://github.com/Azure/aztfy): bring Microsoft Azure resources under Terraform
- Daytona – [Daytona](https://github.com/daytonaio/daytona): open source dev environment manager
- Cockroach Labs – [CockroachDB](https://github.com/cockroachdb/cockroach): a cloud-native, high-availability distributed SQL database
- Truffle Security Co. – [Trufflehog](https://github.com/trufflesecurity/trufflehog): find leaked credentials
- NVIDIA – [container-canary](https://github.com/NVIDIA/container-canary): a container validator
- AWS – [eks-node-viewer](https://github.com/awslabs/eks-node-viewer): a tool for visualizing dynamic node usage within an EKS cluster
- MinIO – [mc](https://github.com/minio/mc): the official [MinIO](https://min.io) client
- Ubuntu – [Authd](https://github.com/ubuntu/authd): an authentication daemon for cloud-based identity providers

### Charm stuff

- [Glow](https://github.com/charmbracelet/glow): a markdown reader, browser, and online markdown stash
- [Huh?](https://github.com/charmbracelet/huh): an interactive prompt and form toolkit
- [Mods](https://github.com/charmbracelet/mods): AI on the CLI, built for pipelines
- [Wishlist](https://github.com/charmbracelet/wishlist): an SSH directory (and bastion!)

### There’s so much more where that came from

For more applications built with Bubble Tea see [Charm &amp; Friends][community].
Is there something cool you made with Bubble Tea you want to share? [PRs][community] are
welcome!

## Contributing

See [contributing][contribute].

[contribute]: https://github.com/charmbracelet/bubbletea/contribute

## Feedback

We’d love to hear your thoughts on this project. Feel free to drop us a note!

- [Twitter](https://twitter.com/charmcli)
- [The Fediverse](https://mastodon.social/@charmcli)
- [Discord](https://charm.sh/chat)

## Acknowledgments

Bubble Tea is based on the paradigms of [The Elm Architecture][elm] by Evan
Czaplicki et alia and the excellent [go-tea][gotea] by TJ Holowaychuk. It’s
inspired by the many great [_Zeichenorientierte Benutzerschnittstellen_][zb]
of days past.

[elm]: https://guide.elm-lang.org/architecture/
[gotea]: https://github.com/tj/go-tea
[zb]: https://de.wikipedia.org/wiki/Zeichenorientierte_Benutzerschnittstelle
[community]: https://github.com/charm-and-friends/charm-in-the-wild

## License

[MIT](https://github.com/charmbracelet/bubbletea/raw/main/LICENSE)

---

Part of [Charm](https://charm.sh).

&lt;a href=&quot;https://charm.sh/&quot;&gt;&lt;img alt=&quot;The Charm logo&quot; src=&quot;https://stuff.charm.sh/charm-banner-next.jpg&quot; width=&quot;400&quot;&gt;&lt;/a&gt;

Charm热爱开源 • Charm loves open source • نحنُ نحب المصادر المفتوحة
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-go]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-go</link>
            <guid>https://github.com/open-telemetry/opentelemetry-go</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[OpenTelemetry Go API and SDK]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-go">open-telemetry/opentelemetry-go</a></h1>
            <p>OpenTelemetry Go API and SDK</p>
            <p>Language: Go</p>
            <p>Stars: 6,034</p>
            <p>Forks: 1,220</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre># OpenTelemetry-Go

[![ci](https://github.com/open-telemetry/opentelemetry-go/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/open-telemetry/opentelemetry-go/actions/workflows/ci.yml)
[![codecov.io](https://codecov.io/gh/open-telemetry/opentelemetry-go/coverage.svg?branch=main)](https://app.codecov.io/gh/open-telemetry/opentelemetry-go?branch=main)
[![PkgGoDev](https://pkg.go.dev/badge/go.opentelemetry.io/otel)](https://pkg.go.dev/go.opentelemetry.io/otel)
[![Go Report Card](https://goreportcard.com/badge/go.opentelemetry.io/otel)](https://goreportcard.com/report/go.opentelemetry.io/otel)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/open-telemetry/opentelemetry-go/badge)](https://scorecard.dev/viewer/?uri=github.com/open-telemetry/opentelemetry-go)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9996/badge)](https://www.bestpractices.dev/projects/9996)
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry-go.svg)](https://issues.oss-fuzz.com/issues?q=project:opentelemetry-go)
[![FOSSA Status](https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-go.svg?type=shield&amp;issueType=license)](https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-go?ref=badge_shield&amp;issueType=license)
[![Slack](https://img.shields.io/badge/slack-@cncf/otel--go-brightgreen.svg?logo=slack)](https://cloud-native.slack.com/archives/C01NPAXACKT)

OpenTelemetry-Go is the [Go](https://golang.org/) implementation of [OpenTelemetry](https://opentelemetry.io/).
It provides a set of APIs to directly measure performance and behavior of your software and send this data to observability platforms.

## Project Status

| Signal  | Status             |
|---------|--------------------|
| Traces  | Stable             |
| Metrics | Stable             |
| Logs    | Beta[^1]           |

Progress and status specific to this repository is tracked in our
[project boards](https://github.com/open-telemetry/opentelemetry-go/projects)
and
[milestones](https://github.com/open-telemetry/opentelemetry-go/milestones).

Project versioning information and stability guarantees can be found in the
[versioning documentation](VERSIONING.md).

[^1]: https://github.com/orgs/open-telemetry/projects/43

### Compatibility

OpenTelemetry-Go ensures compatibility with the current supported versions of
the [Go language](https://golang.org/doc/devel/release#policy):

&gt; Each major Go release is supported until there are two newer major releases.
&gt; For example, Go 1.5 was supported until the Go 1.7 release, and Go 1.6 was supported until the Go 1.8 release.

For versions of Go that are no longer supported upstream, opentelemetry-go will
stop ensuring compatibility with these versions in the following manner:

- A minor release of opentelemetry-go will be made to add support for the new
  supported release of Go.
- The following minor release of opentelemetry-go will remove compatibility
  testing for the oldest (now archived upstream) version of Go. This, and
  future, releases of opentelemetry-go may include features only supported by
  the currently supported versions of Go.

Currently, this project supports the following environments.

| OS       | Go Version | Architecture |
|----------|------------|--------------|
| Ubuntu   | 1.25       | amd64        |
| Ubuntu   | 1.24       | amd64        |
| Ubuntu   | 1.23       | amd64        |
| Ubuntu   | 1.25       | 386          |
| Ubuntu   | 1.24       | 386          |
| Ubuntu   | 1.23       | 386          |
| Ubuntu   | 1.25       | arm64        |
| Ubuntu   | 1.24       | arm64        |
| Ubuntu   | 1.23       | arm64        |
| macOS 13 | 1.25       | amd64        |
| macOS 13 | 1.24       | amd64        |
| macOS 13 | 1.23       | amd64        |
| macOS    | 1.25       | arm64        |
| macOS    | 1.24       | arm64        |
| macOS    | 1.23       | arm64        |
| Windows  | 1.25       | amd64        |
| Windows  | 1.24       | amd64        |
| Windows  | 1.23       | amd64        |
| Windows  | 1.25       | 386          |
| Windows  | 1.24       | 386          |
| Windows  | 1.23       | 386          |

While this project should work for other systems, no compatibility guarantees
are made for those systems currently.

## Getting Started

You can find a getting started guide on [opentelemetry.io](https://opentelemetry.io/docs/languages/go/getting-started/).

OpenTelemetry&#039;s goal is to provide a single set of APIs to capture distributed
traces and metrics from your application and send them to an observability
platform. This project allows you to do just that for applications written in
Go. There are two steps to this process: instrument your application, and
configure an exporter.

### Instrumentation

To start capturing distributed traces and metric events from your application
it first needs to be instrumented. The easiest way to do this is by using an
instrumentation library for your code. Be sure to check out [the officially
supported instrumentation
libraries](https://github.com/open-telemetry/opentelemetry-go-contrib/tree/main/instrumentation).

If you need to extend the telemetry an instrumentation library provides or want
to build your own instrumentation for your application directly you will need
to use the
[Go otel](https://pkg.go.dev/go.opentelemetry.io/otel)
package. The [examples](https://github.com/open-telemetry/opentelemetry-go-contrib/tree/main/examples)
are a good way to see some practical uses of this process.

### Export

Now that your application is instrumented to collect telemetry, it needs an
export pipeline to send that telemetry to an observability platform.

All officially supported exporters for the OpenTelemetry project are contained in the [exporters directory](./exporters).

| Exporter                              | Logs | Metrics | Traces |
|---------------------------------------|:----:|:-------:|:------:|
| [OTLP](./exporters/otlp/)             |  ✓   |    ✓    |   ✓    |
| [Prometheus](./exporters/prometheus/) |      |    ✓    |        |
| [stdout](./exporters/stdout/)         |  ✓   |    ✓    |   ✓    |
| [Zipkin](./exporters/zipkin/)         |      |         |   ✓    |

## Contributing

See the [contributing documentation](CONTRIBUTING.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[anchore/grype]]></title>
            <link>https://github.com/anchore/grype</link>
            <guid>https://github.com/anchore/grype</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[A vulnerability scanner for container images and filesystems]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anchore/grype">anchore/grype</a></h1>
            <p>A vulnerability scanner for container images and filesystems</p>
            <p>Language: Go</p>
            <p>Stars: 10,499</p>
            <p>Forks: 680</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img alt=&quot;Grype logo&quot; src=&quot;https://user-images.githubusercontent.com/5199289/136855393-d0a9eef9-ccf1-4e2b-9d7c-7aad16a567e5.png&quot; width=&quot;234&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype/actions?query=workflow%3A%22Static+Analysis+%2B+Unit+%2B+Integration%22&quot;&gt;&lt;img src=&quot;https://github.com/anchore/grype/workflows/Static%20Analysis%20+%20Unit%20+%20Integration/badge.svg&quot; alt=&quot;Static Analysis + Unit + Integration&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype/actions/workflows/validations.yaml&quot;&gt;&lt;img src=&quot;https://github.com/anchore/grype/workflows/Validations/badge.svg&quot; alt=&quot;Validations&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://goreportcard.com/report/github.com/anchore/grype&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/anchore/grype&quot; alt=&quot;Go Report Card&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype/releases/latest&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/anchore/grype.svg&quot; alt=&quot;GitHub release&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/go-mod/go-version/anchore/grype.svg&quot; alt=&quot;GitHub go.mod Go version&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &lt;br&gt;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-blue.svg&quot; alt=&quot;License: Apache-2.0&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://anchore.com/discourse&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discourse-Join-blue?logo=discourse&quot; alt=&quot;Join our Discourse&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a rel=&quot;me&quot; href=&quot;https://fosstodon.org/@grype&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Mastodon-Follow-blue?logoColor=white&amp;amp;logo=mastodon&quot; alt=&quot;Follow on Mastodon&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://scorecard.dev/viewer/?uri=github.com/anchore/grype&quot;&gt;&lt;img src=&quot;https://api.securityscorecards.dev/projects/github.com/anchore/grype/badge&quot; alt=&quot;OpenSSF Scorecard&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://www.bestpractices.dev/projects/6708&quot;&gt;&lt;img src=&quot;https://www.bestpractices.dev/projects/6708/badge&quot; alt=&quot;OpenSSF Best Practices&quot;&gt;&lt;/a&gt;&amp;nbsp;
&lt;p&gt;

A vulnerability scanner for container images and filesystems. Easily [install the binary](#installation) to try it out. Works with [Syft](https://github.com/anchore/syft), the powerful SBOM (software bill of materials) tool for container images and filesystems.

### Join our community meetings!

- Calendar: https://calendar.google.com/calendar/u/0/r?cid=Y182OTM4dGt0MjRtajI0NnNzOThiaGtnM29qNEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t
- Agenda: https://docs.google.com/document/d/1ZtSAa6fj2a6KRWviTn3WoJm09edvrNUp4Iz_dOjjyY8/edit?usp=sharing (join [this group](https://groups.google.com/g/anchore-oss-community) for write access)
- All are welcome!

For commercial support options with Syft or Grype, please [contact Anchore](https://get.anchore.com/contact/).

![grype-demo](https://user-images.githubusercontent.com/590471/90276236-9868f300-de31-11ea-8068-4268b6b68529.gif)

## Features

- Scan the contents of a container image or filesystem to find known vulnerabilities.
- Find vulnerabilities for major operating system packages:
  - Alpine
  - Amazon Linux
  - Azure Linux (previously CBL-Mariner)
  - BusyBox
  - CentOS
  - Debian
  - Echo
  - Distroless
  - MinimOS
  - Oracle Linux
  - Red Hat (RHEL)
  - Ubuntu
  - Wolfi
- Find vulnerabilities for language-specific packages:
  - Ruby (Gems)
  - Java (JAR, WAR, EAR, JPI, HPI)
  - JavaScript (NPM, Yarn)
  - Python (Egg, Wheel, Poetry, requirements.txt/setup.py files)
  - Dotnet (deps.json)
  - Golang (go.mod)
  - PHP (Composer)
  - Rust (Cargo)
- Supports Docker, OCI and [Singularity](https://github.com/sylabs/singularity) image formats.
- [OpenVEX](https://github.com/openvex) support for filtering and augmenting scanning results.

If you encounter an issue, please [let us know using the issue tracker](https://github.com/anchore/grype/issues).

## Installation

### Recommended

```bash
curl -sSfL https://get.anchore.io/grype | sudo sh -s -- -b /usr/local/bin
```
Install script options:
-	`-b`: Specify a custom installation directory (defaults to `./bin`)
-	`-d`: More verbose logging levels (`-d` for debug, `-dd` for trace)
-	`-v`: Verify the signature of the downloaded artifact before installation (requires [`cosign`](https://github.com/sigstore/cosign) to be installed)

### Chocolatey

The chocolatey distribution of grype is community-maintained and not distributed by the anchore team.

```bash
choco install grype -y
```

### Homebrew

```bash
brew tap anchore/grype
brew install grype
```

### MacPorts

On macOS, Grype can additionally be installed from the [community-maintained port](https://ports.macports.org/port/grype/) via MacPorts:

```bash
sudo port install grype
```

**Note**: Currently, Grype is built only for macOS and Linux.

### From source

See [DEVELOPING.md](DEVELOPING.md#native-development) for instructions to build and run from source.

### GitHub Actions

If you&#039;re using GitHub Actions, you can use our [Grype-based action](https://github.com/marketplace/actions/anchore-container-scan) to run vulnerability scans on your code or container images during your CI workflows.

## Verifying the artifacts

Checksums are applied to all artifacts, and the resulting checksum file is signed using cosign.

You need the following tool to verify signature:

- [Cosign](https://docs.sigstore.dev/cosign/system_config/installation/)

Verification steps are as follow:

1. Download the files you want, and the checksums.txt, checksums.txt.pem and checksums.txt.sig files from the [releases](https://github.com/anchore/grype/releases) page:

2. Verify the signature:

```shell
cosign verify-blob &lt;path to checksum.txt&gt; \
--certificate &lt;path to checksums.txt.pem&gt; \
--signature &lt;path to checksums.txt.sig&gt; \
--certificate-identity-regexp &#039;https://github\.com/anchore/grype/\.github/workflows/.+&#039; \
--certificate-oidc-issuer &quot;https://token.actions.githubusercontent.com&quot;
```

3. Once the signature is confirmed as valid, you can proceed to validate that the SHA256 sums align with the downloaded artifact:

```shell
sha256sum --ignore-missing -c checksums.txt
```

## Getting started

[Install the binary](#installation), and make sure that `grype` is available in your path. To scan for vulnerabilities in an image:

```
grype &lt;image&gt;
```

The above command scans for vulnerabilities visible in the container (i.e., the squashed representation of the image). To include software from all image layers in the vulnerability scan, regardless of its presence in the final image, provide `--scope all-layers`:

```
grype &lt;image&gt; --scope all-layers
```

To run grype from a Docker container so it can scan a running container, use the following command:

```yml
docker run --rm \
--volume /var/run/docker.sock:/var/run/docker.sock \
--name Grype anchore/grype:latest \
$(ImageName):$(ImageTag)
```

## Supported sources

Grype can scan a variety of sources beyond those found in Docker.

```
# scan a container image archive (from the result of `docker image save ...`, `podman save ...`, or `skopeo copy` commands)
grype path/to/image.tar

# scan a Singularity Image Format (SIF) container
grype path/to/image.sif

# scan a directory
grype dir:path/to/dir
```

Sources can be explicitly provided with a scheme:

```
podman:yourrepo/yourimage:tag          use images from the Podman daemon
docker:yourrepo/yourimage:tag          use images from the Docker daemon
docker-archive:path/to/yourimage.tar   use a tarball from disk for archives created from &quot;docker save&quot;
oci-archive:path/to/yourimage.tar      use a tarball from disk for OCI archives (from Skopeo or otherwise)
oci-dir:path/to/yourimage              read directly from a path on disk for OCI layout directories (from Skopeo or otherwise)
singularity:path/to/yourimage.sif      read directly from a Singularity Image Format (SIF) container on disk
dir:path/to/yourproject                read directly from a path on disk (any directory)
file:path/to/yourfile                  read directly from a file on disk
sbom:path/to/syft.json                 read Syft JSON from path on disk
registry:yourrepo/yourimage:tag        pull image directly from a registry (no container runtime required)
```

If an image source is not provided and cannot be detected from the given reference it is assumed the image should be pulled from the Docker daemon.
If docker is not present, then the Podman daemon is attempted next, followed by reaching out directly to the image registry last.


This default behavior can be overridden with the `default-image-pull-source` configuration option (See [Configuration](https://github.com/anchore/grype#configuration) for more details).

Use SBOMs for even faster vulnerability scanning in Grype:

```
# Then scan for new vulnerabilities as frequently as needed
grype sbom:./sbom.json

# (You can also pipe the SBOM into Grype)
cat ./sbom.json | grype
```

Grype supports input of [Syft](https://github.com/anchore/syft), [SPDX](https://spdx.dev/), and [CycloneDX](https://cyclonedx.org/)
SBOM formats. If Syft has generated any of these file types, they should have the appropriate information to work properly with Grype.
It is also possible to use SBOMs generated by other tools with varying degrees of success. Two things that make Grype matching
more successful are the inclusion of CPE and Linux distribution information. If an SBOM does not include any CPE information, it
is possible to generate these based on package information using the `--add-cpes-if-none` flag. To specify a distribution,
use the `--distro &lt;distro&gt;:&lt;version&gt;` flag. A full example is:

```
grype --add-cpes-if-none --distro alpine:3.10 sbom:some-alpine-3.10.spdx.json
```

## Threat &amp; Risk Prioritization

This section explains the columns and UI cues that help prioritize remediation efforts:

- **Severity**: String severity based on CVSS scores and indicate the significance of a vulnerability in levels.
  This balances concerns such as ease of exploitability, and the potential to affect 
  confidentiality, integrity, and availability of software and services.

- **EPSS**:
  [Exploit Prediction Scoring System](https://www.first.org/epss/model) is a metric expressing the likelihood
  that a vulnerability will be 
  exploited in the wild over the next 30 days (on a 0–1 scale); higher values signal a greater likelihood of 
  exploitation.
  The table output shows the EPSS percentile, a one-way transform of the EPSS score showing the 
  proportion of all scored vulnerabilities with an equal or lower probability.
  Percentiles linearize a heavily skewed distribution, making threshold choice (e.g. “only CVEs above the 
  90th percentile”) straightforward.

- **KEV Indicator**: Flags entries from CISA’s [Known Exploited Vulnerabilities Catalog](https://www.cisa.gov/known-exploited-vulnerabilities-catalog)
  --an authoritative list of flaws observed being exploited in the wild.

- **Risk Score**: A composite 0–100 metric calculated as:
  ```markdown
  risk = min(1, threat * average(severity)) * 100
  ```
  Where: 
  - `severity` is the average of all CVSS scores and string severity for a vulnerability (scaled between 0–1).
  - `threat` is the EPSS score (between 0–1). If the vulnerability is on the KEV list then `threat` is 
    `1.05`, or `1.1` if the vulnerability is associated with a ransomware campaign.
  This metric is one way to combine EPSS and CVSS suggested in the [EPSS user guide](https://www.first.org/epss/user-guide).

- **Suggested Fixes**: All possible fixes for a package are listed, however, when multiple fixes are available, we de-emphasize all 
  upgrade paths except for the minimal upgrade path (which highlights the smallest, safest version bump).

Results default to sorting by Risk Score and can be overridden with `--sort-by &lt;value&gt;`:

- `severity`: sort by severity
- `epss`: sort by EPSS percentile (aka, &quot;threat&quot;)
- `risk`: sort by risk score
- `kev`: just like risk, except that KEV entries are always above non-KEV entries
- `package`: sort by package name, version, type
- `vulnerability`: sort by vulnerability ID

### Supported versions

Software updates are always applied to the latest version of Grype; fixes are not backported to any previous versions of Grype.

In terms of database updates, any version of Grype before v0.51.0 (Oct 2022, before schema v5) will not receive
vulnerability database updates. You can still build vulnerability databases for unsupported Grype releases by using previous
releases of [vunnel](https://github.com/anchore/vunnel) to gather the upstream data and [grype-db](https://github.com/anchore/grype-db)
to build databases for unsupported schemas.

Only the latest database schema is considered to be supported. When a new database schema is introduced then the one it replaces is
marked as deprecated. Deprecated schemas will continue to receive updates for at least one year after they are marked
as deprecated at which point they will no longer be supported.

### Working with attestations
Grype supports scanning SBOMs as input via stdin. Users can use [cosign](https://github.com/sigstore/cosign) to verify attestations
with an SBOM as its content to scan an image for vulnerabilities:
```
COSIGN_EXPERIMENTAL=1 cosign verify-attestation caphill4/java-spdx-tools:latest \
| jq -r .payload \
| base64 --decode \
| jq -r .predicate.Data \
| grype
```

### Vulnerability Summary

#### Basic Grype Vulnerability Data Shape

```json
 {
  &quot;vulnerability&quot;: {
    ...
  },
  &quot;relatedVulnerabilities&quot;: [
    ...
  ],
  &quot;matchDetails&quot;: [
    ...
  ],
  &quot;artifact&quot;: {
    ...
  }
}
```

- **Vulnerability**: All information on the specific vulnerability that was directly matched on (e.g. ID, severity, CVSS score, fix information, links for more information)
- **RelatedVulnerabilities**: Information pertaining to vulnerabilities found to be related to the main reported vulnerability. Maybe the vulnerability we matched on was a GitHub Security Advisory, which has an upstream CVE (in the authoritative national vulnerability database). In these cases we list the upstream vulnerabilities here.
- **MatchDetails**: This section tries to explain what we searched for while looking for a match and exactly what details on the package and vulnerability that lead to a match.
- **Artifact**: This is a subset of the information that we know about the package (when compared to the [Syft](https://github.com/anchore/syft) json output, we summarize the metadata section).
  This has information about where within the container image or directory we found the package, what kind of package it is, licensing info, pURLs, CPEs, etc.

### Excluding file paths

Grype can exclude files and paths from being scanned within a source by using glob expressions
with one or more `--exclude` parameters:

```
grype &lt;source&gt; --exclude &#039;./out/**/*.json&#039; --exclude /etc
```

**Note:** in the case of _image scanning_, since the entire filesystem is scanned it is
possible to use absolute paths like `/etc` or `/usr/**/*.txt` whereas _directory scans_
exclude files _relative to the specified directory_. For example: scanning `/usr/foo` with
`--exclude ./package.json` would exclude `/usr/foo/package.json` and `--exclude &#039;**/package.json&#039;`
would exclude all `package.json` files under `/usr/foo`. For _directory scans_,
it is required to begin path expressions with `./`, `*/`, or `**/`, all of which
will be resolved _relative to the specified scan directory_. Keep in mind, your shell
may attempt to expand wildcards, so put those parameters in single quotes, like:
`&#039;**/*.json&#039;`.

### External Sources

Grype can be configured to incorporate external data sources for added fidelity in vulnerability matching. This
feature is currently disabled by default. To enable this feature add the following to the grype config:

```yaml
external-sources:
  enable: true
  maven:
    search-upstream-by-sha1: true
    base-url: https://search.maven.org/solrsearch/select
    rate-limit: 300ms # Time between Maven API requests
```

You can also configure the base-url if you&#039;re using another registry as your maven endpoint.

The rate at which Maven API requests are made can be configured to match your environment&#039;s requirements. The default is 300ms between requests.

### Output formats

The output format for Grype is configurable as well:

```
grype &lt;image&gt; -o &lt;format&gt;
```

Where the formats available are:

- `table`: A columnar summary (default).
- `cyclonedx`: An XML report conforming to the [CycloneDX 1.6 specification](https://cyclonedx.org/specification/overview/).
- `cyclonedx-json`: A JSON report conforming to the [CycloneDX 1.6 specification](https://cyclonedx.org/specification/overview/).
- `json`: Use this to get as much information out of Grype as possible!
- `sarif`: Use this option to get a [SARIF](https://docs.oasis-open.org/sarif/sarif/v2.1.0/sarif-v2.1.0.html) report (Static Analysis Results Interchange Format)
- `template`: Lets the user specify the output format. See [&quot;Using templates&quot;](#using-templates) below.

### Using templates

Grype lets you define custom output formats, using [Go templates](https://golang.org/pkg/text/template/). Here&#039;s how it works:

- Define your format as a Go template, and save this template as a file.

- Set the output format to &quot;template&quot; (`-o template`).

- Specify the path to the template file (`-t ./path/to/custom.template`).

- Grype&#039;s template processing uses the same data models as the `json` output format — so if you&#039;re wondering what data is available as you author a template, you can use the output from `grype &lt;image&gt; -o json` as a reference.

**Please note:** Templates can access information about the system they are running on, such as environment variables. You should never run untrusted templates.

There are several example templates in the [templates](https://github.com/anchore/grype/tree/main/templates) directory in the Grype source which can serve as a starting point for a custom output format. For example, [csv.tmpl](https://github.com/anchore/grype/blob/main/templates/csv.tmpl) produces a vulnerability report in CSV (comma separated value) format:

```text
&quot;Package&quot;,&quot;Version Installed&quot;,&quot;Vulnerability ID&quot;,&quot;Severity&quot;
&quot;coreutils&quot;,&quot;8.30-3ubuntu2&quot;,&quot;CVE-2016-2781&quot;,&quot;Low&quot;
&quot;libc-bin&quot;,&quot;2.31-0ubuntu9&quot;,&quot;CVE-2016-10228&quot;,&quot;Negligible&quot;
&quot;libc-bin&quot;,&quot;2.31-0ubuntu9&quot;,&quot;CVE-2020-6096&quot;,&quot;Low&quot;
...
```

You can also find the template for the default &quot;table&quot; output format in the same place.

Grype also includes a vast array of utility templating functions from [sprig](http://masterminds.github.io/sprig/) apart from the default golang [text/template](https://pkg.go.dev/text/template#hdr-Functions) to allow users to customize the output from Grype.

### Gating on severity of vulnerabilities

You can have Grype exit with an error if any vulnerabilities are reported at or above the specified severity level. This comes in handy when using Grype within a script or CI pipeline. To do this, use the `--fail-on &lt;severity&gt;` CLI flag.

For example, here&#039;s how you could trigger a CI pipeline failure if any vulnerabilities are found in the `ubuntu:latest` image with a severity of &quot;medium&quot; or higher:

```
grype ubuntu:latest --fail-on medium
```

**Note:** Grype returns exit code `2` on vulnerability errors.

### Specifying matches to ignore

If you&#039;re seeing Grype report **false positives** or any other vulnerability matches that you just don&#039;t want to see, you can tell Grype to **ignore** matches by specifying one or more _&quot;ignore rules&quot;_ in your Grype configuration file (e.g. `~/.grype.yaml`). This causes Grype not to report any vulnerability matches that meet the criteria specified by any of your ignore rules.

Each rule can specify any combination of the following criteria:

- vulnerability ID (e.g. `&quot;CVE-2008-4318&quot;`)
- namespace (e.g. `&quot;nvd&quot;`)
- fix state (allowed values: `&quot;fixed&quot;`, `&quot;not-fixed&quot;`, `&quot;wont-fix&quot;`, or `&quot;unknown&quot;`)
- package name (e.g. `&quot;libcurl&quot;`)
- package version (e.g

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[casdoor/casdoor]]></title>
            <link>https://github.com/casdoor/casdoor</link>
            <guid>https://github.com/casdoor/casdoor</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[An open-source UI-first Identity and Access Management (IAM) / Single-Sign-On (SSO) platform with web UI supporting OAuth 2.0, OIDC, SAML, CAS, LDAP, SCIM, WebAuthn, TOTP, MFA, Face ID, RADIUS, Google Workspace, Active Directory and Kerberos]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/casdoor/casdoor">casdoor/casdoor</a></h1>
            <p>An open-source UI-first Identity and Access Management (IAM) / Single-Sign-On (SSO) platform with web UI supporting OAuth 2.0, OIDC, SAML, CAS, LDAP, SCIM, WebAuthn, TOTP, MFA, Face ID, RADIUS, Google Workspace, Active Directory and Kerberos</p>
            <p>Language: Go</p>
            <p>Stars: 12,094</p>
            <p>Forks: 1,414</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot; style=&quot;border-bottom: none;&quot;&gt;📦⚡️ Casdoor&lt;/h1&gt;
&lt;h3 align=&quot;center&quot;&gt;An open-source UI-first Identity and Access Management (IAM) / Single-Sign-On (SSO) platform with web UI supporting OAuth 2.0, OIDC, SAML, CAS, LDAP, SCIM, WebAuthn, TOTP, MFA and RADIUS&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#badge&quot;&gt;
    &lt;img alt=&quot;semantic-release&quot; src=&quot;https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://hub.docker.com/r/casbin/casdoor&quot;&gt;
    &lt;img alt=&quot;docker pull casbin/casdoor&quot; src=&quot;https://img.shields.io/docker/pulls/casbin/casdoor.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/casdoor/casdoor/actions/workflows/build.yml&quot;&gt;
    &lt;img alt=&quot;GitHub Workflow Status (branch)&quot; src=&quot;https://github.com/casdoor/casdoor/workflows/Build/badge.svg?style=flat-square&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/casdoor/casdoor/releases/latest&quot;&gt;
    &lt;img alt=&quot;GitHub Release&quot; src=&quot;https://img.shields.io/github/v/release/casdoor/casdoor.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://hub.docker.com/r/casbin/casdoor&quot;&gt;
    &lt;img alt=&quot;Docker Image Version (latest semver)&quot; src=&quot;https://img.shields.io/badge/Docker%20Hub-latest-brightgreen&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/casdoor/casdoor&quot;&gt;
    &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/casdoor/casdoor?style=flat-square&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/casdoor/casdoor/blob/master/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/casdoor/casdoor?style=flat-square&quot; alt=&quot;license&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/casdoor/casdoor/issues&quot;&gt;
    &lt;img alt=&quot;GitHub issues&quot; src=&quot;https://img.shields.io/github/issues/casdoor/casdoor?style=flat-square&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;#&quot;&gt;
    &lt;img alt=&quot;GitHub stars&quot; src=&quot;https://img.shields.io/github/stars/casdoor/casdoor?style=flat-square&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/casdoor/casdoor/network&quot;&gt;
    &lt;img alt=&quot;GitHub forks&quot; src=&quot;https://img.shields.io/github/forks/casdoor/casdoor?style=flat-square&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://crowdin.com/project/casdoor-site&quot;&gt;
    &lt;img alt=&quot;Crowdin&quot; src=&quot;https://badges.crowdin.net/casdoor-site/localized.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/5rPsrAzK7S&quot;&gt;
    &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1022748306096537660?style=flat-square&amp;logo=discord&amp;label=discord&amp;color=5865F2&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;sup&gt;Sponsored by&lt;/sup&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://stytch.com/docs?utm_source=oss-sponsorship&amp;utm_medium=paid_sponsorship&amp;utm_campaign=casbin&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://cdn.casbin.org/img/stytch-white.png&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://cdn.casbin.org/img/stytch-charcoal.png&quot;&gt;
      &lt;img src=&quot;https://cdn.casbin.org/img/stytch-charcoal.png&quot; width=&quot;275&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;&lt;br/&gt;
  &lt;a href=&quot;https://stytch.com/docs?utm_source=oss-sponsorship&amp;utm_medium=paid_sponsorship&amp;utm_campaign=casbin&quot;&gt;&lt;b&gt;Build auth with fraud prevention, faster.&lt;/b&gt;&lt;br/&gt; Try Stytch for API-first authentication, user &amp; org management, multi-tenant SSO, MFA, device fingerprinting, and more.&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;

## Online demo

- Read-only site: https://door.casdoor.com (any modification operation will fail)
- Writable site: https://demo.casdoor.com (original data will be restored for every 5 minutes)

## Documentation

https://casdoor.org

## Install

- By source code: https://casdoor.org/docs/basic/server-installation
- By Docker: https://casdoor.org/docs/basic/try-with-docker
- By Kubernetes Helm: https://casdoor.org/docs/basic/try-with-helm

## How to connect to Casdoor?

https://casdoor.org/docs/how-to-connect/overview

## Casdoor Public API

- Docs: https://casdoor.org/docs/basic/public-api
- Swagger: https://door.casdoor.com/swagger

## Integrations

https://casdoor.org/docs/category/integrations

## How to contact?

- Discord: https://discord.gg/5rPsrAzK7S
- Contact: https://casdoor.org/help

## Contribute

For casdoor, if you have any questions, you can give Issues, or you can also directly start Pull Requests(but we recommend giving issues first to communicate with the community).

### I18n translation

If you are contributing to casdoor, please note that we use [Crowdin](https://crowdin.com/project/casdoor-site) as translating platform and i18next as translating tool. When you add some words using i18next in the `web/` directory, please remember to add what you have added to the `web/src/locales/en/data.json` file.

## License

[Apache-2.0](https://github.com/casdoor/casdoor/blob/master/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[golangci/golangci-lint]]></title>
            <link>https://github.com/golangci/golangci-lint</link>
            <guid>https://github.com/golangci/golangci-lint</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[Fast linters runner for Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/golangci/golangci-lint">golangci/golangci-lint</a></h1>
            <p>Fast linters runner for Go</p>
            <p>Language: Go</p>
            <p>Stars: 17,543</p>
            <p>Forks: 1,493</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;golangci-lint logo&quot; src=&quot;assets/go.png&quot; height=&quot;150&quot; /&gt;
  &lt;h3 align=&quot;center&quot;&gt;golangci-lint&lt;/h3&gt;
  &lt;p align=&quot;center&quot;&gt;Fast linters runner for Go&lt;/p&gt;
&lt;/p&gt;

---

`golangci-lint` is a fast Go linters runner.

It runs linters in parallel, uses caching, supports YAML configuration,
integrates with all major IDEs, and includes over a hundred linters.

## Install `golangci-lint`

- [On my machine](https://golangci-lint.run/docs/welcome/install/#local-installation);
- [On CI/CD systems](https://golangci-lint.run/docs/welcome/install/#ci-installation).

## Documentation

Documentation is hosted at https://golangci-lint.run.

## Social Networks

[![Join Slack](https://img.shields.io/badge/Slack-4285F4?logo=slack&amp;logoColor=white)](https://gophers.slack.com/archives/CS0TBRKPC)
[![Follow on Mastodon](https://img.shields.io/badge/Mastodon-6364FF?logo=mastodon&amp;logoColor=white)](https://fosstodon.org/@golangcilint)
[![Follow on Bluesky](https://img.shields.io/badge/Bluesky-0a7aff?logo=bluesky&amp;logoColor=white)](https://bsky.app/profile/golangci-lint.run)
[![Follow on Twitter](https://img.shields.io/badge/Twitter-1DA1F2?logo=x&amp;logoColor=white)](https://twitter.com/golangci)

## Support Us

`golangci-lint` is a free and open-source project built by volunteers.

If you value it, consider supporting us, we appreciate it! :heart:

[![Golangci-lint](https://img.shields.io/badge/Support-golangci_lint-blue?style=for-the-badge)](https://donate.golangci.org)
[![Linter Authors](https://img.shields.io/badge/Support-Linter_Authors-blue?style=for-the-badge)](https://golangci-lint.run/docs/product/thanks/)

## Badges

![Build Status](https://github.com/golangci/golangci-lint/workflows/CI/badge.svg)
[![License](https://img.shields.io/github/license/golangci/golangci-lint)](/LICENSE)
[![Release](https://img.shields.io/github/release/golangci/golangci-lint.svg)](https://github.com/golangci/golangci-lint/releases/latest)
[![Docker](https://img.shields.io/docker/pulls/golangci/golangci-lint)](https://hub.docker.com/r/golangci/golangci-lint)
[![GitHub Releases Stats of golangci-lint](https://img.shields.io/github/downloads/golangci/golangci-lint/total.svg?logo=github)](https://somsubhra.github.io/github-release-stats/?username=golangci&amp;repository=golangci-lint)

## Contributors

This project exists thanks to all the people who contribute. [How to contribute](https://golangci-lint.run/docs/contributing/).

&lt;a href=&quot;https://github.com/golangci/golangci-lint/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://opencollective.com/golangci-lint/contributors.svg?width=890&amp;button=false&amp;skip=golangcidev,CLAassistant,renovate,fossabot,golangcibot,kortschak,golangci-releaser,dependabot%5Bbot%5D&quot; /&gt;
&lt;/a&gt;

## Sponsors

&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p float=&quot;left&quot;&gt;
  &lt;a href=&quot;https://www.jetbrains.com/go/?utm_source=OSS&amp;utm_medium=referral&amp;utm_campaign=golangci&quot; target=&quot;_blank&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/goland-white.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/goland.svg&quot;&gt;
      &lt;img alt=&quot;The complete IDE crafted for professional Go developers.&quot; src=&quot;assets/goland.svg&quot; width=&quot;150&quot; /&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

## Stargazers over time

[![Stargazers over time](https://starchart.cc/golangci/golangci-lint.svg?variant=adaptive)](https://starchart.cc/golangci/golangci-lint)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grafana/tempo]]></title>
            <link>https://github.com/grafana/tempo</link>
            <guid>https://github.com/grafana/tempo</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[Grafana Tempo is a high volume, minimal dependency distributed tracing backend.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grafana/tempo">grafana/tempo</a></h1>
            <p>Grafana Tempo is a high volume, minimal dependency distributed tracing backend.</p>
            <p>Language: Go</p>
            <p>Stars: 4,709</p>
            <p>Forks: 604</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/sources/tempo/logo_and_name.png&quot; alt=&quot;Tempo Logo&quot;&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/grafana/tempo/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/grafana/tempo?display_name=tag&amp;sort=semver&quot; alt=&quot;Latest Release&quot;/&gt;&lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/github/license/grafana/tempo&quot; alt=&quot;License&quot; /&gt;
  &lt;a href=&quot;https://hub.docker.com/r/grafana/tempo/tags&quot;&gt;&lt;image src=&quot;https://img.shields.io/docker/pulls/grafana/tempo&quot; alt=&quot;Docker Pulls&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://grafana.slack.com/archives/C01D981PEE5&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/join%20slack-%23tempo-brightgreen.svg&quot; alt=&quot;Slack&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://community.grafana.com/c/grafana-tempo/40&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/discuss-tempo%20forum-orange.svg&quot; alt=&quot;Community Forum&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/grafana/tempo&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/grafana/tempo&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

Grafana Tempo is an open source, easy-to-use, and high-scale distributed tracing backend. Tempo is cost-efficient, requiring only object storage to operate, and is deeply integrated with Grafana, Prometheus, and Loki.


## Business value of distributed tracing

Distributed tracing helps teams quickly pinpoint performance issues and understand the flow of requests across services. The Traces Drilldown UI simplifies this process by offering a user-friendly interface to view and analyze trace data, making it easier to identify and resolve issues without needing to write complex queries.

Refer to [Use traces to find solutions](https://grafana.com/docs/tempo/latest/introduction/solutions-with-traces/) to learn more about how you can use distributed tracing to investigate and solve issues.

## Traces Drilldown UI: A better way to get value from your tracing data
We are excited to introduce the [Traces Drilldown](https://github.com/grafana/traces-drilldown) (formerly Explore Traces) app as part of the Grafana Explore suite. This app provides a queryless and intuitive experience for analyzing tracing data, allowing teams to quickly identify performance issues, latency bottlenecks, and errors without needing to write complex queries or use TraceQL.

Key Features:
- **Intuitive Trace Analysis**: Spot slow or error-prone traces with easy, point-and-click interactions.
- **RED Metrics Overview**: Use Rate, Errors, and Duration metrics to highlight performance issues.
- **Automated Comparison**: Identify problematic attributes with automatic trace comparison.
- **Simplified Visualizations**: Access rich visual data without needing to construct TraceQL queries.

![image](https://github.com/user-attachments/assets/991205df-1b27-489f-8ef0-1a05ee158996)

To learn more see the following links:
- [Traces Drilldown repo](https://github.com/grafana/traces-drilldown)
- [Traces Drilldown documentation](https://grafana.com/docs/grafana/latest/explore/simplified-exploration/traces/)
- [Demo video](https://www.youtube.com/watch?v=a3uB1C2oHA4)

## TraceQL

Tempo implements [TraceQL](https://grafana.com/docs/tempo/latest/traceql/), a traces-first query language inspired by LogQL and PromQL, which enables targeted queries or rich UI-driven analyses.

### TraceQL metrics

[TraceQL metrics](https://grafana.com/docs/tempo/latest/traceql/metrics-queries/) is an experimental feature in Grafana Tempo that creates metrics from traces. Metric queries extend trace queries by applying a function to trace query results. This powerful feature allows for ad hoc aggregation of any existing TraceQL query by any dimension available in your traces, much in the same way that LogQL metric queries create metrics from logs.

Tempo is Jaeger, Zipkin, Kafka, OpenCensus, and OpenTelemetry compatible. It ingests batches in any of the mentioned formats, buffers them, and then writes them to Azure, GCS, S3, or local disk. As such, it&#039;s robust, cheap, and easy to operate.

## Getting started with Tempo

- [Get started documentation](https://grafana.com/docs/tempo/latest/getting-started/)
- [Deployment Examples](./example)
  - [Docker Compose](./example/docker-compose)
  - [Helm](./example/helm)
  - [Jsonnet](./example/tk)

## Further reading

To learn more about Tempo, consult the following documents &amp; talks:

- [How to get started with Tempo with Joe Elliott (video)](https://www.youtube.com/watch?v=zDrA7Ly3ovU)
- [Grafana blog posts about Tempo](https://grafana.com/tags/tempo/)
- [New in Grafana Tempo 2.0: Apache Parquet as the default storage format, support for TraceQL][tempo_20_announce]
- [Get to know TraceQL: A powerful new query language for distributed tracing][traceql-post]

[tempo_20_announce]: https://grafana.com/blog/2023/02/01/new-in-grafana-tempo-2.0-apache-parquet-as-the-default-storage-format-support-for-traceql/
[traceql-post]: https://grafana.com/blog/2023/02/07/get-to-know-traceql-a-powerful-new-query-language-for-distributed-tracing/

## Getting help

If you have any questions or feedback regarding Tempo:

- Grafana Labs hosts a [forum](https://community.grafana.com/c/grafana-tempo/40) for Tempo. This is a great place to post questions and search for answers.
- Ask a question on the [Tempo Slack channel](https://grafana.slack.com/archives/C01D981PEE5).
- [File an issue](https://github.com/grafana/tempo/issues/new/choose) for bugs, issues and feature suggestions.
- UI issues should be filed with [Grafana](https://github.com/grafana/grafana/issues/new/choose).

## OpenTelemetry

Tempo&#039;s receiver layer, wire format and storage format are all based directly on [standards](https://github.com/open-telemetry/opentelemetry-proto) and [code](https://github.com/open-telemetry/opentelemetry-collector) established by [OpenTelemetry](https://opentelemetry.io/).  We support open standards at Grafana!

Check out the [Integration Guides](https://grafana.com/docs/tempo/latest/guides/instrumentation/) to see examples of OpenTelemetry instrumentation with Tempo.

## Other components

### tempo-vulture
[tempo-vulture](https://github.com/grafana/tempo/tree/main/cmd/tempo-vulture) is Tempo&#039;s bird themed consistency checking tool.  It writes traces to Tempo and then queries them back in a variety of ways.

### tempo-cli
[tempo-cli](https://github.com/grafana/tempo/tree/main/cmd/tempo-cli) is the place to put any utility functionality related to Tempo. See [Documentation](https://grafana.com/docs/tempo/latest/operations/tempo_cli/) for more info.

## License

Grafana Tempo is distributed under [AGPL-3.0-only](LICENSE). For Apache-2.0 exceptions, see [LICENSING.md](LICENSING.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[dapr/dapr]]></title>
            <link>https://github.com/dapr/dapr</link>
            <guid>https://github.com/dapr/dapr</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[Dapr is a portable runtime for building distributed applications across cloud and edge, combining event-driven architecture with workflow orchestration.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dapr/dapr">dapr/dapr</a></h1>
            <p>Dapr is a portable runtime for building distributed applications across cloud and edge, combining event-driven architecture with workflow orchestration.</p>
            <p>Language: Go</p>
            <p>Stars: 25,078</p>
            <p>Forks: 1,995</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;div style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/img/dapr_logo.svg&quot; height=&quot;120px&quot;&gt;
&lt;h2&gt;APIs for Building Secure and Reliable Microservices&lt;/h2&gt;
&lt;/div&gt;

[![Go Report][go-report-badge]][go-report-url] [![OpenSSF][openssf-badge]][openssf-url] [![Docker Pulls][docker-badge]][docker-url] [![Build Status][actions-badge]][actions-url] [![Test Status][e2e-badge]][e2e-url] [![Code Coverage][codecov-badge]][codecov-url] [![License: Apache 2.0][apache-badge]][apache-url] [![FOSSA Status][fossa-badge]][fossa-url] [![TODOs][todo-badge]][todo-url] [![Good First Issues][gfi-badge]][gfi-url] [![discord][discord-badge]][discord-url] [![YouTube][youtube-badge]][youtube-link] [![Bluesky][bluesky-badge]][bluesky-link] [![X/Twitter][x-badge]][x-link]

[go-report-badge]: https://goreportcard.com/badge/github.com/dapr/dapr
[go-report-url]: https://goreportcard.com/report/github.com/dapr/dapr
[openssf-badge]: https://www.bestpractices.dev/projects/5044/badge
[openssf-url]: https://www.bestpractices.dev/projects/5044
[docker-badge]: https://img.shields.io/docker/pulls/daprio/daprd?style=flat&amp;logo=docker
[docker-url]: https://hub.docker.com/r/daprio/dapr
[apache-badge]: https://img.shields.io/github/license/dapr/dapr?style=flat&amp;label=License&amp;logo=github
[apache-url]: https://github.com/dapr/dapr/blob/master/LICENSE
[actions-badge]: https://github.com/dapr/dapr/workflows/dapr/badge.svg?event=push&amp;branch=master
[actions-url]: https://github.com/dapr/dapr/actions?workflow=dapr
[e2e-badge]: https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/dapr-bot/14e974e8fd6c6eab03a2475beb1d547a/raw/dapr-test-badge.json
[e2e-url]: https://github.com/dapr/dapr/actions?workflow=dapr-test&amp;event=schedule
[codecov-badge]: https://codecov.io/gh/dapr/dapr/branch/master/graph/badge.svg
[codecov-url]: https://codecov.io/gh/dapr/dapr
[fossa-badge]: https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fdapr%2Fdapr.svg?type=shield
[fossa-url]: https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fdapr%2Fdapr?ref=badge_shield
[todo-badge]: https://badgen.net/https/api.tickgit.com/badgen/github.com/dapr/dapr
[todo-url]: https://www.tickgit.com/browse?repo=github.com/dapr/dapr
[gfi-badge]:https://img.shields.io/github/issues-search/dapr/dapr?query=type%3Aissue%20is%3Aopen%20label%3A%22good%20first%20issue%22&amp;label=Good%20first%20issues&amp;style=flat&amp;logo=github
[gfi-url]:https://github.com/dapr/dapr/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22
[discord-badge]: https://img.shields.io/discord/778680217417809931?label=Discord&amp;style=flat&amp;logo=discord
[discord-url]: http://bit.ly/dapr-discord
[youtube-badge]:https://img.shields.io/youtube/channel/views/UCtpSQ9BLB_3EXdWAUQYwnRA?style=flat&amp;label=YouTube%20views&amp;logo=youtube
[youtube-link]:https://youtube.com/@daprdev
[bluesky-badge]:https://img.shields.io/badge/Follow-%40daprdev.bsky.social-0056A1?logo=bluesky
[bluesky-link]:https://bsky.app/profile/daprdev.bsky.social
[x-badge]:https://img.shields.io/twitter/follow/daprdev?logo=x&amp;style=flat
[x-link]:https://twitter.com/daprdev

Dapr is a set of integrated APIs with built-in best practices and patterns to build distributed applications. Dapr increases your developer productivity by 20-40% with out-of-the-box features such as workflow, pub/sub, state management, secret stores, external configuration, bindings, actors, distributed lock, and cryptography. You benefit from the built-in security, reliability, and observability capabilities, so you don&#039;t need to write boilerplate code to achieve production-ready applications.

With Dapr, a graduated CNCF project, platform teams can configure complex setups while exposing simple interfaces to application development teams, making it easier for them to build highly scalable distributed applications. Many platform teams have adopted Dapr to provide governance and golden paths for API-based infrastructure interaction.

![Dapr overview](./img/overview.png)

We are a Cloud Native Computing Foundation (CNCF) graduated project.
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/kedacore/keda/main/images/logo-cncf.svg&quot; height=&quot;75px&quot;&gt;&lt;/p&gt;

## Goals

- Enable developers using *any* language or framework to write distributed applications
- Solve the hard problems developers face building microservice applications by providing best practice building blocks
- Be community driven, open and vendor neutral
- Gain new contributors
- Provide consistency and portability through open APIs
- Be platform agnostic across cloud and edge
- Embrace extensibility and provide pluggable components without vendor lock-in
- Enable IoT and edge scenarios by being highly performant and lightweight
- Be incrementally adoptable from existing code, with no runtime dependency

## How it works

Dapr injects a side-car (container or process) to each compute unit. The side-car interacts with event triggers and communicates with the compute unit via standard HTTP or gRPC protocols. This enables Dapr to support all existing and future programming languages without requiring you to import frameworks or libraries.

Dapr offers built-in state management, reliable messaging (at least once delivery), triggers and bindings through standard HTTP verbs or gRPC interfaces. This allows you to write stateless, stateful and actor-like services following the same programming paradigm. You can freely choose consistency model, threading model and message delivery patterns.

Dapr runs natively on Kubernetes, as a self hosted binary on your machine, on an IoT device, or as a container that can be injected into any system, in the cloud or on-premises.

Dapr uses pluggable component state stores and message buses such as Redis as well as gRPC to offer a wide range of communication methods, including direct dapr-to-dapr using gRPC and async Pub-Sub with guaranteed delivery and at-least-once semantics.


## Why Dapr?

Writing highly performant, scalable and reliable distributed application is hard. Dapr brings proven patterns and practices to you. It unifies event-driven and actors semantics into a simple, consistent programming model. It supports all programming languages without framework lock-in. You are not exposed to low-level primitives such as threading, concurrency control, partitioning and scaling. Instead, you can write your code by implementing a simple web server using familiar web frameworks of your choice.

Dapr is flexible in threading and state consistency models. You can leverage multi-threading if you choose to, and you can choose among different consistency models. This flexibility enables you to implement advanced scenarios without artificial constraints. Dapr is unique because you can transition seamlessly between platforms and underlying implementations without rewriting your code.

## Features

* Event-driven Pub-Sub system with pluggable providers and at-least-once semantics
* Input and output bindings with pluggable providers
* State management with pluggable data stores
* Consistent service-to-service discovery and invocation
* Opt-in stateful models: Strong/Eventual consistency, First-write/Last-write wins
* Cross platform virtual actors
* Secret management to retrieve secrets from secure key vaults
* Rate limiting
* Built-in [Observability](https://docs.dapr.io/concepts/observability-concept/) support
* Runs natively on Kubernetes using a dedicated Operator and CRDs
* Supports all programming languages via HTTP and gRPC
* Multi-Cloud, open components (bindings, pub-sub, state) from Azure, AWS, GCP
* Runs anywhere, as a process or containerized
* Lightweight (58MB binary, 4MB physical memory)
* Runs as a sidecar - removes the need for special SDKs or libraries
* Dedicated CLI - developer friendly experience with easy debugging
* Clients for Java, .NET Core, Go, Javascript, Python, Rust and C++

## Get Started using Dapr

See our [Getting Started](https://docs.dapr.io/getting-started/) guide over in our docs.

## Quickstarts and Samples

* See the [quickstarts repository](https://github.com/dapr/quickstarts) for code examples that can help you get started with Dapr.
* Explore additional samples in the Dapr [samples repository](https://github.com/dapr/samples).

## Community
We want your contributions and suggestions! One of the easiest ways to contribute is to participate in discussions on the mailing list, chat on IM or the bi-weekly community calls.
For more information on the community engagement, developer and contributing guidelines and more, head over to the [Dapr community repo](https://github.com/dapr/community#dapr-community).

### Contact Us

Reach out with any questions you may have and we&#039;ll make sure to answer them as soon as possible!

| Platform  | Link        |
|:----------|:------------|
| 💬 Discord (preferred) | [![Discord Banner](https://discord.com/api/guilds/778680217417809931/widget.png?style=banner2)](https://aka.ms/dapr-discord)
| 💭 LinkedIn | [@daprdev](https://www.linkedin.com/company/daprdev)
| 🦋 BlueSky | [@daprdev.bsky.social](https://bsky.app/profile/daprdev.bsky.social)
| 🐤 Twitter | [@daprdev](https://twitter.com/daprdev)


### Community Call

Every two weeks we host a community call to showcase new features, review upcoming milestones, and engage in a Q&amp;A. All are welcome!

📞 Visit [Upcoming Dapr Community Calls](https://github.com/dapr/community/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22community%20call%22) for upcoming dates and the meeting link.

📺 Visit https://www.youtube.com/@DaprDev/streams for previous community call live streams.

### Videos and Podcasts

We have a variety of keynotes, podcasts, and presentations available to reference and learn from.

📺 Visit https://docs.dapr.io/contributing/presentations/ for previous talks and slide decks or our YouTube channel https://www.youtube.com/@DaprDev/videos.

### Contributing to Dapr

See the [Development Guide](https://docs.dapr.io/contributing/) to get started with building and developing.

## Repositories

| Repo | Description |
|:-----|:------------|
| [Dapr](https://github.com/dapr/dapr) | The main repository that you are currently in. Contains the Dapr runtime code and overview documentation.
| [CLI](https://github.com/dapr/cli) | The Dapr CLI allows you to setup Dapr on your local dev machine or on a Kubernetes cluster, provides debugging support, launches and manages Dapr instances.
| [Docs](https://docs.dapr.io) | The documentation for Dapr.
| [Quickstarts](https://github.com/dapr/quickstarts) | This repository contains a series of simple code samples that highlight the main Dapr capabilities.
| [Samples](https://github.com/dapr/samples) | This repository holds community maintained samples for various Dapr use cases.
| [Components-contrib ](https://github.com/dapr/components-contrib) | The purpose of components contrib is to provide open, community driven reusable components for building distributed applications.
| [Dashboard ](https://github.com/dapr/dashboard) | General purpose dashboard for Dapr
| [Go-sdk](https://github.com/dapr/go-sdk) | Dapr SDK for Go
| [Java-sdk](https://github.com/dapr/java-sdk) | Dapr SDK for Java
| [JS-sdk](https://github.com/dapr/js-sdk) | Dapr SDK for JavaScript
| [Python-sdk](https://github.com/dapr/python-sdk) | Dapr SDK for Python
| [Dotnet-sdk](https://github.com/dapr/dotnet-sdk) | Dapr SDK for .NET
| [Rust-sdk](https://github.com/dapr/rust-sdk) | Dapr SDK for Rust
| [Cpp-sdk](https://github.com/dapr/cpp-sdk) | Dapr SDK for C++
| [PHP-sdk](https://github.com/dapr/php-sdk) | Dapr SDK for PHP


## Code of Conduct

Please refer to our [Dapr Community Code of Conduct](https://github.com/dapr/community/blob/master/CODE-OF-CONDUCT.md)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[aquasecurity/trivy]]></title>
            <link>https://github.com/aquasecurity/trivy</link>
            <guid>https://github.com/aquasecurity/trivy</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aquasecurity/trivy">aquasecurity/trivy</a></h1>
            <p>Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more</p>
            <p>Language: Go</p>
            <p>Stars: 28,025</p>
            <p>Forks: 2,682</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;docs/imgs/logo.png&quot; width=&quot;200&quot;&gt;

[![GitHub Release][release-img]][release]
[![Test][test-img]][test]
[![Go Report Card][go-report-img]][go-report]
[![License: Apache-2.0][license-img]][license]
[![GitHub Downloads][github-downloads-img]][release]
![Docker Pulls][docker-pulls]

[📖 Documentation][docs]
&lt;/div&gt;

Trivy ([pronunciation][pronunciation]) is a comprehensive and versatile security scanner.
Trivy has *scanners* that look for security issues, and *targets* where it can find those issues.

Targets (what Trivy can scan):

- Container Image
- Filesystem
- Git Repository (remote)
- Virtual Machine Image
- Kubernetes

Scanners (what Trivy can find there):

- OS packages and software dependencies in use (SBOM)
- Known vulnerabilities (CVEs)
- IaC issues and misconfigurations
- Sensitive information and secrets
- Software licenses

Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the [Scanning Coverage] page.

To learn more, go to the [Trivy homepage][homepage] for feature highlights, or to the [Documentation site][docs] for detailed information.

## Quick Start

### Get Trivy

Trivy is available in most common distribution channels. The full list of installation options is available in the [Installation] page. Here are a few popular examples:

- `brew install trivy`
- `docker run aquasec/trivy`
- Download binary from &lt;https://github.com/aquasecurity/trivy/releases/latest/&gt;
- See [Installation] for more

Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the [Ecosystem] page. Here are a few popular examples:

- [GitHub Actions](https://github.com/aquasecurity/trivy-action)
- [Kubernetes operator](https://github.com/aquasecurity/trivy-operator)
- [VS Code plugin](https://github.com/aquasecurity/trivy-vscode-extension)
- See [Ecosystem] for more

### Canary builds
There are canary builds ([Docker Hub](https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;name=canary), [GitHub](https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary), [ECR](https://gallery.ecr.aws/aquasecurity/trivy#canary) images and [binaries](https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml)) as generated every push to main branch.

Please be aware: canary builds might have critical bugs, it&#039;s not recommended for use in production.

### General usage

```bash
trivy &lt;target&gt; [--scanners &lt;scanner1,scanner2&gt;] &lt;subject&gt;
```

Examples:

```bash
trivy image python:3.4-alpine
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov

&lt;/details&gt;

```bash
trivy fs --scanners vuln,secret,misconfig myproject/
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov

&lt;/details&gt;

```bash
trivy k8s --report summary cluster
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

![k8s summary](docs/imgs/trivy-k8s.png)

&lt;/details&gt;

## FAQ

### How to pronounce the name &quot;Trivy&quot;?

`tri` is pronounced like **tri**gger, `vy` is pronounced like en**vy**.

## Want more? Check out Aqua

If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.  
You can find a high level comparison table specific to Trivy users [here](https://trivy.dev/latest/commercial/compare/).
In addition check out the &lt;https://aquasec.com&gt; website for more information about our products and services.
If you&#039;d like to contact Aqua or request a demo, please use this form: &lt;https://www.aquasec.com/demo&gt;

## Community

Trivy is an [Aqua Security][aquasec] open source project.  
Learn about our open source work and portfolio [here][oss].  
Contact us about any matter by opening a GitHub Discussion [here][discussions]

Please ensure to abide by our [Code of Conduct][code-of-conduct] during all interactions.

[test]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml
[test-img]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg
[go-report]: https://goreportcard.com/report/github.com/aquasecurity/trivy
[go-report-img]: https://goreportcard.com/badge/github.com/aquasecurity/trivy
[release]: https://github.com/aquasecurity/trivy/releases
[release-img]: https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github
[github-downloads-img]: https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github
[docker-pulls]: https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;label=docker%20pulls%20%2F%20trivy
[license]: https://github.com/aquasecurity/trivy/blob/main/LICENSE
[license-img]: https://img.shields.io/badge/License-Apache%202.0-blue.svg
[homepage]: https://trivy.dev
[docs]: https://trivy.dev/latest/docs/
[pronunciation]: #how-to-pronounce-the-name-trivy
[code-of-conduct]: https://github.com/aquasecurity/community/blob/main/CODE_OF_CONDUCT.md

[Installation]:https://trivy.dev/latest/getting-started/installation/
[Ecosystem]: https://trivy.dev/latest/ecosystem/
[Scanning Coverage]: https://trivy.dev/latest/docs/coverage/

[alpine]: https://ariadne.space/2021/06/08/the-vulnerability-remediation-lifecycle-of-alpine-containers/
[rego]: https://www.openpolicyagent.org/docs/latest/#rego
[sigstore]: https://www.sigstore.dev/

[aquasec]: https://aquasec.com
[oss]: https://www.aquasec.com/products/open-source-projects/
[discussions]: https://github.com/aquasecurity/trivy/discussions
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grpc/grpc-go]]></title>
            <link>https://github.com/grpc/grpc-go</link>
            <guid>https://github.com/grpc/grpc-go</guid>
            <pubDate>Sun, 24 Aug 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[The Go language implementation of gRPC. HTTP/2 based RPC]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grpc/grpc-go">grpc/grpc-go</a></h1>
            <p>The Go language implementation of gRPC. HTTP/2 based RPC</p>
            <p>Language: Go</p>
            <p>Stars: 22,121</p>
            <p>Forks: 4,551</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># gRPC-Go

[![GoDoc](https://pkg.go.dev/badge/google.golang.org/grpc)][API]
[![GoReportCard](https://goreportcard.com/badge/grpc/grpc-go)](https://goreportcard.com/report/github.com/grpc/grpc-go)
[![codecov](https://codecov.io/gh/grpc/grpc-go/graph/badge.svg)](https://codecov.io/gh/grpc/grpc-go)

The [Go][] implementation of [gRPC][]: A high performance, open source, general
RPC framework that puts mobile and HTTP/2 first. For more information see the
[Go gRPC docs][], or jump directly into the [quick start][].

## Prerequisites

- **[Go][]**: any one of the **two latest major** [releases][go-releases].

## Installation

Simply add the following import to your code, and then `go [build|run|test]`
will automatically fetch the necessary dependencies:


```go
import &quot;google.golang.org/grpc&quot;
```

&gt; **Note:** If you are trying to access `grpc-go` from **China**, see the
&gt; [FAQ](#FAQ) below.

## Learn more

- [Go gRPC docs][], which include a [quick start][] and [API
  reference][API] among other resources
- [Low-level technical docs](Documentation) from this repository
- [Performance benchmark][]
- [Examples](examples)
- [Contribution guidelines](CONTRIBUTING.md)

## FAQ

### I/O Timeout Errors

The `golang.org` domain may be blocked from some countries. `go get` usually
produces an error like the following when this happens:

```console
$ go get -u google.golang.org/grpc
package google.golang.org/grpc: unrecognized import path &quot;google.golang.org/grpc&quot; (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)
```

To build Go code, there are several options:

- Set up a VPN and access google.golang.org through that.

- With Go module support: it is possible to use the `replace` feature of `go
  mod` to create aliases for golang.org packages.  In your project&#039;s directory:

  ```sh
  go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest
  go mod tidy
  go mod vendor
  go build -mod=vendor
  ```

  Again, this will need to be done for all transitive dependencies hosted on
  golang.org as well. For details, refer to [golang/go issue
  #28652](https://github.com/golang/go/issues/28652).

### Compiling error, undefined: grpc.SupportPackageIsVersion

Please update to the latest version of gRPC-Go using
`go get google.golang.org/grpc`.

### How to turn on logging

The default logger is controlled by environment variables. Turn everything on
like this:

```console
$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99
$ export GRPC_GO_LOG_SEVERITY_LEVEL=info
```

### The RPC failed with error `&quot;code = Unavailable desc = transport is closing&quot;`

This error means the connection the RPC is using was closed, and there are many
possible reasons, including:
 1. mis-configured transport credentials, connection failed on handshaking
 1. bytes disrupted, possibly by a proxy in between
 1. server shutdown
 1. Keepalive parameters caused connection shutdown, for example if you have
    configured your server to terminate connections regularly to [trigger DNS
    lookups](https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779).
    If this is the case, you may want to increase your
    [MaxConnectionAgeGrace](https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters),
    to allow longer RPC calls to finish.

It can be tricky to debug this because the error happens on the client side but
the root cause of the connection being closed is on the server side. Turn on
logging on __both client and server__, and see if there are any transport
errors.

[API]: https://pkg.go.dev/google.golang.org/grpc
[Go]: https://golang.org
[Go module]: https://github.com/golang/go/wiki/Modules
[gRPC]: https://grpc.io
[Go gRPC docs]: https://grpc.io/docs/languages/go
[Performance benchmark]: https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608
[quick start]: https://grpc.io/docs/languages/go/quickstart
[go-releases]: https://golang.org/doc/devel/release.html
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>