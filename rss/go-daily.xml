<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Thu, 01 Jan 2026 00:06:49 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[looplj/axonhub]]></title>
            <link>https://github.com/looplj/axonhub</link>
            <guid>https://github.com/looplj/axonhub</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:49 GMT</pubDate>
            <description><![CDATA[AxonHub is a modern AI gateway system that provides a unified OpenAI ( Chat Completion, Responses), Anthropic, Gemini and AI SDK compatible API]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/looplj/axonhub">looplj/axonhub</a></h1>
            <p>AxonHub is a modern AI gateway system that provides a unified OpenAI ( Chat Completion, Responses), Anthropic, Gemini and AI SDK compatible API</p>
            <p>Language: Go</p>
            <p>Stars: 1,158</p>
            <p>Forks: 128</p>
            <p>Stars today: 38 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# AxonHub - All-in-one AI Development Platform

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![Test Status](https://github.com/looplj/axonhub/actions/workflows/test.yml/badge.svg)](https://github.com/looplj/axonhub/actions/workflows/test.yml)
[![Lint Status](https://github.com/looplj/axonhub/actions/workflows/lint.yml/badge.svg)](https://github.com/looplj/axonhub/actions/workflows/lint.yml)
[![Go Version](https://img.shields.io/github/go-mod/go-version/looplj/axonhub?logo=go&amp;logoColor=white)](https://golang.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Docker Ready](https://img.shields.io/badge/docker-ready-2496ED?logo=docker&amp;logoColor=white)](https://docker.com)

[English](README.md) | [‰∏≠Êñá](README.zh-CN.md)

&lt;/div&gt;

---

## üìñ Project Introduction

### All-in-one AI Development Platform

AxonHub is an all-in-one AI development platform that provides unified API gateway, project management, and comprehensive development tools. It offers OpenAI, Anthropic, and AI SDK compatible API layers, transforming requests to various AI providers through a transformer pipeline architecture. The platform features comprehensive tracing capabilities, project-based organization, and integrated playground for rapid prototyping, helping developers and enterprises better manage AI development workflows.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/axonhub-architecture-light.svg&quot; alt=&quot;AxonHub Architecture&quot; width=&quot;700&quot;/&gt;
&lt;/div&gt;

### Core Features

1. [**Unified API**](docs/en/api-reference/unified-api.md): OpenAI- and Anthropic-compatible interface with automatic API translation lets you use one API format to access any supported model provider.
2. [**Tracing / Threads**](docs/en/guides/tracing.md): Thread-aware tracing captures full request timelines for deep observability and faster debugging.
3. [**Fine-grained Permission**](docs/en/guides/permissions.md): RBAC-based policies help teams govern access, usage, and data segregation precisely.
4. [**Adaptive Load Balancing**](docs/en/guides/load-balance.md): Intelligent multi-strategy load balancing automatically selects optimal AI channels based on health, performance, and session consistency.

---

## üìö Documentation

For detailed technical documentation, API references, architecture design, and more, please visit
- [![DeepWiki](https://img.shields.io/badge/DeepWiki-looplj%2Faxonhub-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/looplj/axonhub)
- [![zread](https://img.shields.io/badge/Ask_Zread-_.svg?style=flat&amp;color=00b0aa&amp;labelColor=000000&amp;logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQuOTYxNTYgMS42MDAxSDIuMjQxNTZDMS44ODgxIDEuNjAwMSAxLjYwMTU2IDEuODg2NjQgMS42MDE1NiAyLjI0MDFWNC45NjAxQzEuNjAxNTYgNS4zMTM1NiAxLjg4ODEgNS42MDAxIDIuMjQxNTYgNS42MDAxSDQuOTYxNTZDNS4zMTUwMiA1LjYwMDEgNS42MDE1NiA1LjMxMzU2IDUuNjAxNTYgNC45NjAxVjIuMjQwMUM1LjYwMTU2IDEuODg2NjQgNS4zMTUwMiAxLjYwMDEgNC45NjE1NiAxLjYwMDFaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00Ljk2MTU2IDEwLjM5OTlIMi4yNDE1NkMxLjg4ODEgMTAuMzk5OSAxLjYwMTU2IDEwLjY4NjQgMS42MDE1NiAxMS4wMzk5VjEzLjc1OTlDMS42MDE1NiAxNC4xMTM0IDEuODg4MSAxNC4zOTk5IDIuMjQxNTYgMTQuMzk5OUg0Ljk2MTU2QzUuMzE1MDIgMTQuMzk5OSA1LjYwMTU2IDE0LjExMzQgNS42MDE1NiAxMy43NTk5VjExLjAzOTlDNS42MDE1NiAxMC42ODY0IDUuMzE1MDIgMTAuMzk5OSA0Ljk2MTU2IDEwLjM5OTlaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik0xMy43NTg0IDEuNjAwMUgxMS4wMzg0QzEwLjY4NSAxLjYwMDEgMTAuMzk4NCAxLjg4NjY0IDEwLjM5ODQgMi4yNDAxVjQuOTYwMUMxMC4zOTg0IDUuMzEzNTYgMTAuNjg1IDUuNjAwMSAxMS4wMzg0IDUuNjAwMUgxMy43NTg0QzE0LjExMTkgNS42MDAxIDE0LjM5ODQgNS4zMTM1NiAxNC4zOTg0IDQuOTYwMVYyLjI0MDFDMTQuMzk4NCAxLjg4NjY0IDE0LjExMTkgMS42MDAxIDEzLjc1ODQgMS42MDAxWiIgZmlsbD0iI2ZmZiIvPgo8cGF0aCBkPSJNNCAxMkwxMiA0TDQgMTJaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00IDEyTDEyIDQiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIvPgo8L3N2Zz4K&amp;logoColor=ffffff)](https://zread.ai/looplj/axonhub)

---

## üéØ Demo

Try AxonHub live at our [demo instance](https://axonhub.onrender.com)!

**Note**ÔºöThe demo instance currently configures Zhipu and OpenRouter free models.

### Demo Account

- **Email**: demo@example.com
- **Password**: 12345678

---

## ‚≠ê Features

### üì∏ Screenshots

Here are some screenshots of AxonHub in action:

&lt;table&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;docs/screenshots/axonhub-dashboard.png&quot;&gt;
        &lt;img src=&quot;docs/screenshots/axonhub-dashboard.png&quot; alt=&quot;System Dashboard&quot; width=&quot;250&quot;/&gt;
      &lt;/a&gt;
      &lt;br/&gt;
      System Dashboard
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;docs/screenshots/axonhub-channels.png&quot;&gt;
        &lt;img src=&quot;docs/screenshots/axonhub-channels.png&quot; alt=&quot;Channel Management&quot; width=&quot;250&quot;/&gt;
      &lt;/a&gt;
      &lt;br/&gt;
      Channel Management
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;docs/screenshots/axonhub-models.png&quot;&gt;
        &lt;img src=&quot;docs/screenshots/axonhub-models.png&quot; alt=&quot;Models&quot; width=&quot;250&quot;/&gt;
      &lt;/a&gt;
      &lt;br/&gt;
      Models
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;docs/screenshots/axonhub-trace.png&quot;&gt;
        &lt;img src=&quot;docs/screenshots/axonhub-trace.png&quot; alt=&quot;Trace Viewer&quot; width=&quot;250&quot;/&gt;
      &lt;/a&gt;
      &lt;br/&gt;
      Trace Viewer
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;docs/screenshots/axonhub-requests.png&quot;&gt;
        &lt;img src=&quot;docs/screenshots/axonhub-requests.png&quot; alt=&quot;Request Monitoring&quot; width=&quot;250&quot;/&gt;
      &lt;/a&gt;
      &lt;br/&gt;
      Request Monitoring
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;docs/screenshots/axonhub-usage-logs.png&quot;&gt;
        &lt;img src=&quot;docs/screenshots/axonhub-usage-logs.png&quot; alt=&quot;Usage Logs&quot; width=&quot;250&quot;/&gt;
      &lt;/a&gt;
      &lt;br/&gt;
      Usage Logs
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

---

### üöÄ API Types

| API Type             | Status     | Description                    | Document                                     |
| -------------------- | ---------- | ------------------------------ | -------------------------------------------- |
| **Text Generation**  | ‚úÖ Done    | Conversational interface       | [Unified API](docs/en/api-reference/unified-api.md) |
| **Image Generation** | ‚ö†Ô∏è Partial | Image generation               | [Image Generation](docs/en/api-reference/image-generation.md) |
| **Rerank**           | ‚úÖ Done    | Results ranking                | [Unified API](docs/en/api-reference/unified-api.md#rerank-api) |
| **Embedding**        | ‚úÖ Done    | Vector embedding generation    | [Unified API](docs/en/api-reference/unified-api.md#embedding-api) |
| **Realtime**         | üìù Todo    | Live conversation capabilities | -                                            |

---

### üåê Multi-Provider AI Gateway

| Feature                   | Technical Implementation                        | Business Value                              |
| ------------------------- | ----------------------------------------------- | ------------------------------------------- |
| **Unified API Interface** | OpenAI compatible standard, zero learning curve | Avoid vendor lock-in, reduce migration risk |
| **Automatic Failover**    | Multi-channel retry + load balancing            | Service interruption time &lt; 100ms           |
| **Stream Processing**     | Native SSE support, real-time response          | 60% user experience improvement             |

---

### üßµ Threads &amp; Tracing

AxonHub records every request as part of a thread-aware trace without requiring you to adopt any vendor-specific SDK. Bring your existing OpenAI-compatible client, and AxonHub will:

- Require incoming `AH-Trace-Id` headers to stitch multiple requests into the same trace. If the header is omitted, AxonHub will still record the request but cannot automatically link it to related activity.
- Link traces to threads so you can follow the entire conversation journey end to end
- Capture model metadata, prompt / response spans, and timing information for fast root-cause analysis

Learn more about how tracing works and how to integrate it in the [Tracing Guide](docs/en/guides/tracing.md).

### üîß API Format Support

| Format                      | Status     | Compatibility       | Modalities      |
| --------------------------- | ---------- | ------------------- | --------------- |
| **OpenAI Chat Completions** | ‚úÖ Done    | Fully compatible    | Text, Image     |
| **OpenAI Responses**        | ‚ö†Ô∏è Partial | No `previous_response_id` | Text        |
| **Anthropic Messages**      | ‚úÖ Done    | Fully supported     | Text            |
| **Gemini**                  | ‚úÖ Done    | Fully supported     | Text, Image     |
| **AI SDK**                  | ‚ö†Ô∏è Partial | Partially supported | Text            |

**Key Feature**: Use OpenAI API to call Anthropic models, or Anthropic API to call OpenAI models - AxonHub handles automatic API translation!

---

### üè¢ Permission Control

| Security Feature                    | Implementation                     |
| ----------------------------------- | ---------------------------------- |
| **Fine-grained Permission Control** | Role-based access control (RBAC)   |
| **Data Localization**               | Configurable data storage policies |
| **API Key Management**              | JWT + scope control                |

---

## üöÄ Quick Start

### 1-click Deploy to Render

Deploy AxonHub with 1-click on [Render](https://render.com) for free.

&lt;div&gt;

&lt;a href=&quot;https://render.com/deploy?repo=https://github.com/looplj/axonhub&quot;&gt;
  &lt;img src=&quot;https://render.com/images/deploy-to-render-button.svg&quot; alt=&quot;Deploy to Render&quot;&gt;
&lt;/a&gt;

&lt;/div&gt;

---

## üöÄ Deployment Guide

### üíª Personal Computer Deployment

Perfect for individual developers and small teams. No complex configuration required.

#### Quick Download &amp; Run

1. **Download the latest release** from [GitHub Releases](https://github.com/looplj/axonhub/releases)

   - Choose the appropriate version for your operating system:

2. **Extract and run**

   ```bash
   # Extract the downloaded file
   unzip axonhub_*.zip
   cd axonhub_*

   # Add execution permissions (only for Linux/macOS)
   chmod +x axonhub

   # Run directly - default SQLite database

   # Install AxonHub to system
   sudo ./install.sh

   # Start AxonHub service
   ./start.sh

   # Stop AxonHub service
   ./stop.sh
   ```

3. **Access the application**
   ```
   http://localhost:8090
   ```

---

### üñ•Ô∏è Server Deployment

For production environments, high availability, and enterprise deployments.

#### Database Support

AxonHub supports multiple databases to meet different scale deployment needs:

| Database       | Supported Versions | Recommended Scenario                             | Auto Migration | Links                                                       |
| -------------- | ------------------ | ------------------------------------------------ | -------------- | ----------------------------------------------------------- |
| **TiDB Cloud** | Starter            | Serverless, Free tier, Auto Scale                | ‚úÖ Supported   | [TiDB Cloud](https://www.pingcap.com/tidb-cloud-starter/)   |
| **TiDB Cloud** | Dedicated          | Distributed deployment, large scale              | ‚úÖ Supported   | [TiDB Cloud](https://www.pingcap.com/tidb-cloud-dedicated/) |
| **TiDB**       | V8.0+              | Distributed deployment, large scale              | ‚úÖ Supported   | [TiDB](https://tidb.io/)                                    |
| **Neon DB**    | -                  | Serverless, Free tier, Auto Scale                | ‚úÖ Supported   | [Neon DB](https://neon.com/)                                |
| **PostgreSQL** | 15+                | Production environment, medium-large deployments | ‚úÖ Supported   | [PostgreSQL](https://www.postgresql.org/)                   |
| **MySQL**      | 8.0+               | Production environment, medium-large deployments | ‚úÖ Supported   | [MySQL](https://www.mysql.com/)                             |
| **SQLite**     | 3.0+               | Development environment, small deployments       | ‚úÖ Supported   | [SQLite](https://www.sqlite.org/index.html)                 |

#### Configuration

AxonHub uses YAML configuration files with environment variable override support:

```yaml
# config.yml
server:
  port: 8090
  name: &quot;AxonHub&quot;
  debug: false

db:
  dialect: &quot;tidb&quot;
  dsn: &quot;&lt;USER&gt;.root:&lt;PASSWORD&gt;@tcp(gateway01.us-west-2.prod.aws.tidbcloud.com:4000)/axonhub?tls=true&quot;

log:
  level: &quot;info&quot;
  encoding: &quot;json&quot;
```

Environment variables:

```bash
AXONHUB_SERVER_PORT=8090
AXONHUB_DB_DIALECT=&quot;tidb&quot;
AXONHUB_DB_DSN=&quot;&lt;USER&gt;.root:&lt;PASSWORD&gt;@tcp(gateway01.us-west-2.prod.aws.tidbcloud.com:4000)/axonhub?tls=true&quot;
AXONHUB_LOG_LEVEL=info
```

For detailed configuration instructions, please refer to [configuration documentation](docs/en/deployment/configuration.md).

#### Docker Compose Deployment

```bash
# Clone project
git clone https://github.com/looplj/axonhub.git
cd axonhub

# Set environment variables
export AXONHUB_DB_DIALECT=&quot;tidb&quot;
export AXONHUB_DB_DSN=&quot;&lt;USER&gt;.root:&lt;PASSWORD&gt;@tcp(gateway01.us-west-2.prod.aws.tidbcloud.com:4000)/axonhub?tls=true&quot;

# Start services
docker-compose up -d

# Check status
docker-compose ps
```

#### Virtual Machine Deployment

Download the latest release from [GitHub Releases](https://github.com/looplj/axonhub/releases)

```bash
# Extract and run
unzip axonhub_*.zip
cd axonhub_*

# Set environment variables
export AXONHUB_DB_DIALECT=&quot;tidb&quot;
export AXONHUB_DB_DSN=&quot;&lt;USER&gt;.root:&lt;PASSWORD&gt;@tcp(gateway01.us-west-2.prod.aws.tidbcloud.com:4000)/axonhub?tls=true&quot;

sudo ./install.sh

# Configuration file check
axonhub config check

# Start service
#  For simplicity, we recommend managing AxonHub with the helper scripts:

# Start
./start.sh

# Stop
./stop.sh
```

---

## üìñ Usage Guide

### Unified API Overview

AxonHub provides a unified API gateway that supports both OpenAI Chat Completions and Anthropic Messages APIs. This means you can:

- **Use OpenAI API to call Anthropic models** - Keep using your OpenAI SDK while accessing Claude models
- **Use Anthropic API to call OpenAI models** - Use Anthropic&#039;s native API format with GPT models
- **Use Gemini API to call OpenAI models** - Use Gemini&#039;s native API format with GPT models
- **Automatic API translation** - AxonHub handles format conversion automatically
- **Zero code changes** - Your existing OpenAI or Anthropic client code continues to work

### 1. Initial Setup

1. **Access Management Interface**

   ```
   http://localhost:8090
   ```

2. **Configure AI Providers**

   - Add API keys in the management interface
   - Test connections to ensure correct configuration

3. **Create Users and Roles**
   - Set up permission management
   - Assign appropriate access permissions

### 2. Channel Configuration

Configure AI provider channels in the management interface. For detailed information on channel configuration, including model mappings, parameter overrides, and troubleshooting, see the [Channel Configuration Guide](docs/en/guides/channel-management.md).

### 3. Model Management

AxonHub provides a flexible model management system that supports mapping abstract models to specific channels and model implementations through Model Associations. This enables:

- **Unified Model Interface** - Use abstract model IDs (e.g., `gpt-4`, `claude-3-opus`) instead of channel-specific names
- **Intelligent Channel Selection** - Automatically route requests to optimal channels based on association rules and load balancing
- **Flexible Mapping Strategies** - Support for precise channel-model matching, regex patterns, and tag-based selection
- **Priority-based Fallback** - Configure multiple associations with priorities for automatic failover

For comprehensive information on model management, including association types, configuration examples, and best practices, see the [Model Management Guide](docs/en/guides/model-management.md).

### 4. Create API Keys

Create API keys to authenticate your applications with AxonHub. Each API key can be configured with multiple profiles that define:

- **Model Mappings** - Transform user-requested models to actual available models using exact match or regex patterns
- **Channel Restrictions** - Limit which channels an API key can use by channel IDs or tags
- **Model Access Control** - Control which models are accessible through a specific profile
- **Profile Switching** - Change behavior on-the-fly by activating different profiles

For detailed information on API key profiles, including configuration examples, validation rules, and best practices, see the [API Key Profile Guide](docs/en/guides/api-key-profiles.md).

### 5. Claude Code/Codex Integration

See the dedicated [Claude Code &amp; Codex Integration Guide](docs/en/guides/claude-code-integration.md) for detailed setup steps, troubleshooting, and tips on combining these tools with AxonHub model profiles.

---

### 6. SDK Usage

For detailed SDK usage examples and code samples, please refer to the [Unified API documentation](docs/en/api-reference/unified-api.md).

## üõ†Ô∏è Development Guide

For detailed development instructions, architecture design, and contribution guidelines, please see [docs/en/guides/development.md](docs/en/guides/development.md).

---

## ü§ù Acknowledgments

- üôè [musistudio/llms](https://github.com/musistudio/llms) - LLM transformation framework, source of inspiration
- üé® [satnaing/shadcn-admin](https://github.com/satnaing/shadcn-admin) - Admin interface template
- üîß [99designs/gqlgen](https://github.com/99designs/gqlgen) - GraphQL code generation
- üåê [gin-gonic/gin](https://github.com/gin-gonic/gin) - HTTP framework
- üóÑÔ∏è [ent/ent](https://github.com/ent/ent) - ORM framework
- üîß [air-verse/air](https://github.com/air-verse/air) - Auto reload Go service
- ‚òÅÔ∏è [Render](https://render.com) - Free cloud deployment platform for hosting our demo
- üóÉÔ∏è [TiDB Cloud](https://www.pingcap.com/tidb-cloud/) - Serverless database platform for demo deployment

---

## üìÑ License

This project is open source under the MIT License. See [LICENSE](LICENSE) file for details.

---

&lt;div align=&quot;center&quot;&gt;

**AxonHub** - All-in-one AI Development Platform, making AI development simpler

[üè† Homepage](https://github.com/looplj/axonhub) ‚Ä¢ [üìö Documentation](https://deepwiki.com/looplj/axonhub) ‚Ä¢ [üêõ Issue Feedback](https://github.com/looplj/axonhub/issues)

Built with ‚ù§Ô∏è by the AxonHub team

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cloudwego/eino]]></title>
            <link>https://github.com/cloudwego/eino</link>
            <guid>https://github.com/cloudwego/eino</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:48 GMT</pubDate>
            <description><![CDATA[The ultimate LLM/AI application development framework in Golang.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudwego/eino">cloudwego/eino</a></h1>
            <p>The ultimate LLM/AI application development framework in Golang.</p>
            <p>Language: Go</p>
            <p>Stars: 8,894</p>
            <p>Forks: 693</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre># Eino

![coverage](https://raw.githubusercontent.com/cloudwego/eino/badges/.badges/main/coverage.svg)
[![Release](https://img.shields.io/github/v/release/cloudwego/eino)](https://github.com/cloudwego/eino/releases)
[![WebSite](https://img.shields.io/website?up_message=cloudwego&amp;url=https%3A%2F%2Fwww.cloudwego.io%2F)](https://www.cloudwego.io/)
[![License](https://img.shields.io/github/license/cloudwego/eino)](https://github.com/cloudwego/eino/blob/main/LICENSE)
[![Go Report Card](https://goreportcard.com/badge/github.com/cloudwego/eino)](https://goreportcard.com/report/github.com/cloudwego/eino)
[![OpenIssue](https://img.shields.io/github/issues/cloudwego/eino)](https://github.com/cloudwego/kitex/eino)
[![ClosedIssue](https://img.shields.io/github/issues-closed/cloudwego/eino)](https://github.com/cloudwego/eino/issues?q=is%3Aissue+is%3Aclosed)
![Stars](https://img.shields.io/github/stars/cloudwego/eino)
![Forks](https://img.shields.io/github/forks/cloudwego/eino)

English | [‰∏≠Êñá](README.zh_CN.md)

# Overview

**Eino[&#039;aino]** (pronounced similarly to &quot;I know&quot;) aims to be the ultimate LLM application development framework in Golang. Drawing inspirations from many excellent LLM application development frameworks in the open-source community such as LangChain &amp; LlamaIndex, etc., as well as learning from cutting-edge research and real world applications, Eino offers an LLM application development framework that emphasizes on simplicity, scalability, reliability and effectiveness that better aligns with Golang programming conventions.

What Eino provides are:
- a carefully curated list of **component** abstractions and implementations that can be easily reused and combined to build LLM applications
- a powerful **composition** framework that does the heavy lifting of strong type checking, stream processing, concurrency management, aspect injection, option assignment, etc. for the user.
- a set of meticulously designed **API** that obsesses on simplicity and clarity.
- an ever-growing collection of best practices in the form of bundled **flows** and **examples**.
- a useful set of tools that covers the entire development cycle, from visualized development and debugging to online tracing and evaluation.

With the above arsenal, Eino can standardize, simplify, and improve efficiency at different stages of the AI application development cycle:
![](.github/static/img/eino/eino_concept.jpeg)

# A quick walkthrough

Use a component directly:
```Go
model, _ := openai.NewChatModel(ctx, config) // create an invokable LLM instance
message, _ := model.Generate(ctx, []*Message{
    SystemMessage(&quot;you are a helpful assistant.&quot;),
    UserMessage(&quot;what does the future AI App look like?&quot;)})
```

Of course, you can do that, Eino provides lots of useful components to use out of the box. But you can do more by using orchestration, for three reasons:
- orchestration encapsulates common patterns of LLM application.
- orchestration solves the difficult problem of processing stream response by the LLM.
- orchestration handles type safety, concurrency management, aspect injection and option assignment for you.

Eino provides three set of APIs for orchestration

| API      | Characteristics and usage                                             |
| -------- |-----------------------------------------------------------------------|
| Chain    | Simple chained directed graph that can only go forward.               |
| Graph    | Cyclic or Acyclic directed graph. Powerful and flexible.              |
| Workflow | Acyclic graph that supports data mapping at struct field level. |

Let&#039;s create a simple chain: a ChatTemplate followed by a ChatModel.

![](.github/static/img/eino/simple_chain.png)

```Go
chain, _ := NewChain[map[string]any, *Message]().
           AppendChatTemplate(prompt).
           AppendChatModel(model).
           Compile(ctx)

chain.Invoke(ctx, map[string]any{&quot;query&quot;: &quot;what&#039;s your name?&quot;})
```

Now let&#039;s create a graph that uses a ChatModel to generate answer or tool calls, then uses a ToolsNode to execute those tools if needed.

![](.github/static/img/eino/tool_call_graph.png)

```Go
graph := NewGraph[map[string]any, *schema.Message]()

_ = graph.AddChatTemplateNode(&quot;node_template&quot;, chatTpl)
_ = graph.AddChatModelNode(&quot;node_model&quot;, chatModel)
_ = graph.AddToolsNode(&quot;node_tools&quot;, toolsNode)
_ = graph.AddLambdaNode(&quot;node_converter&quot;, takeOne)

_ = graph.AddEdge(START, &quot;node_template&quot;)
_ = graph.AddEdge(&quot;node_template&quot;, &quot;node_model&quot;)
_ = graph.AddBranch(&quot;node_model&quot;, branch)
_ = graph.AddEdge(&quot;node_tools&quot;, &quot;node_converter&quot;)
_ = graph.AddEdge(&quot;node_converter&quot;, END)

compiledGraph, err := graph.Compile(ctx)
if err != nil {
return err
}
out, err := compiledGraph.Invoke(ctx, map[string]any{&quot;query&quot;:&quot;Beijing&#039;s weather this weekend&quot;})
```

Now let&#039;s create a workflow that flexibly maps input &amp; output at the field level:

![](.github/static/img/eino/simple_workflow.png)

```Go
type Input1 struct {
    Input string
}

type Output1 struct {
    Output string
}

type Input2 struct {
    Role schema.RoleType
}

type Output2 struct {
    Output string
}

type Input3 struct {
    Query string
    MetaData string
}

var (
    ctx context.Context
    m model.BaseChatModel
    lambda1 func(context.Context, Input1) (Output1, error)
    lambda2 func(context.Context, Input2) (Output2, error)
    lambda3 func(context.Context, Input3) (*schema.Message, error)
)

wf := NewWorkflow[[]*schema.Message, *schema.Message]()
wf.AddChatModelNode(&quot;model&quot;, m).AddInput(START)
wf.AddLambdaNode(&quot;lambda1&quot;, InvokableLambda(lambda1)).
    AddInput(&quot;model&quot;, MapFields(&quot;Content&quot;, &quot;Input&quot;))
wf.AddLambdaNode(&quot;lambda2&quot;, InvokableLambda(lambda2)).
    AddInput(&quot;model&quot;, MapFields(&quot;Role&quot;, &quot;Role&quot;))
wf.AddLambdaNode(&quot;lambda3&quot;, InvokableLambda(lambda3)).
    AddInput(&quot;lambda1&quot;, MapFields(&quot;Output&quot;, &quot;Query&quot;)).
    AddInput(&quot;lambda2&quot;, MapFields(&quot;Output&quot;, &quot;MetaData&quot;))
wf.End().AddInput(&quot;lambda3&quot;)
runnable, err := wf.Compile(ctx)
if err != nil {
    return err
}
our, err := runnable.Invoke(ctx, []*schema.Message{
    schema.UserMessage(&quot;kick start this workflow!&quot;),
})
```

Now let&#039;s create a &#039;ReAct&#039; agent: A ChatModel binds to Tools. It receives input Messages and decides independently whether to call the Tool or output the final result. The execution result of the Tool will again become the input Message for the ChatModel and serve as the context for the next round of independent judgment.

![](.github/static/img/eino/react.png)

We provide a complete implementation for ReAct Agent out of the box in the `flow` package. Check out the code here: [flow/agent/react](https://github.com/cloudwego/eino/blob/main/flow/agent/react/react.go)

Our implementation of ReAct Agent uses Eino&#039;s **graph orchestration** exclusively, which provides the following benefits out of the box:
- Type checking: it makes sure the two nodes&#039; input and output types match at compile time.
- Stream processing: concatenates message stream before passing to chatModel and toolsNode if needed, and copies the stream into callback handlers.
- Concurrency management: the shared state can be safely read and written because the StatePreHandler is concurrency safe.
- Aspect injection: injects callback aspects before and after the execution of ChatModel if the specified ChatModel implementation hasn&#039;t injected itself.
- Option assignment: call options are assigned either globally, to specific component type or to specific node.

For example, you could easily extend the compiled graph with callbacks:
```Go
handler := NewHandlerBuilder().
  OnStartFn(
    func(ctx context.Context, info *RunInfo, input CallbackInput) context.Context) {
        log.Infof(&quot;onStart, runInfo: %v, input: %v&quot;, info, input)
    }).
  OnEndFn(
    func(ctx context.Context, info *RunInfo, output CallbackOutput) context.Context) {
        log.Infof(&quot;onEnd, runInfo: %v, out: %v&quot;, info, output)
    }).
  Build()
  
compiledGraph.Invoke(ctx, input, WithCallbacks(handler))
```

or you could easily assign options to different nodes:
```Go
// assign to All nodes
compiledGraph.Invoke(ctx, input, WithCallbacks(handler))

// assign only to ChatModel nodes
compiledGraph.Invoke(ctx, input, WithChatModelOption(WithTemperature(0.5))

// assign only to node_1
compiledGraph.Invoke(ctx, input, WithCallbacks(handler).DesignateNode(&quot;node_1&quot;))
```

# Key Features

## Rich Components

- Encapsulates common building blocks into **component abstractions**, each have multiple **component implementations** that are ready to be used out of the box.
    - component abstractions such as ChatModel, Tool, ChatTemplate, Retriever, Document Loader, Lambda, etc.
    - each component type has an interface of its own: defined Input &amp; Output Type, defined Option type, and streaming paradigms that make sense.
    - implementations are transparent. Abstractions are all you care about when orchestrating components together.

- Implementations can be nested and captures complex business logic.
    - ReAct Agent, MultiQueryRetriever, Host MultiAgent, etc. They consist of multiple components and non-trivial business logic.
    - They are still transparent from the outside. A MultiQueryRetriever can be used anywhere that accepts a Retriever.

## Powerful Orchestration

- Data flows from Retriever / Document Loaders / ChatTemplate to ChatModel, then flows to Tools and parsed as Final Answer. This directed, controlled flow of data through multiple components can be implemented through **graph orchestration**.
- Component instances are graph nodes, and edges are data flow channels.
- Graph orchestration is powerful and flexible enough to implement complex business logic:
  - type checking, stream processing, concurrency management, aspect injection and option assignment are handled by the framework.
  - branch out execution at runtime, read and write global state, or do field level data mapping using workflow(currently in alpha stage).


## Complete Stream Processing

- Stream processing is important because ChatModel outputs chunks of messages in real time as it generates them. It&#039;s especially important with orchestration because more components need to handle streaming data.
- Eino automatically **concatenates** stream chunks for downstream nodes that only accepts non-stream input, such as ToolsNode.
- Eino automatically **boxes** non stream into stream when stream is needed during graph execution.  
- Eino automatically **merges** multiple streams as they converge into a single downward node.
- Eino automatically **copies** stream as they fan out to different downward node, or is passed to callback handlers.
- Orchestration elements such as **branch** and **state handlers** are also stream aware.
- With these streaming processing abilities, the streaming paradigms of components themselves become transparent to the user. 
- A compiled Graph can run with 4 different streaming paradigms:

| Streaming Paradigm | Explanation                                                                 |
| ------------------ | --------------------------------------------------------------------------- |
| Invoke             | Accepts non-stream type I and returns non-stream type O                     |
| Stream             | Accepts non-stream type I and returns stream type StreamReader[O]           |
| Collect            | Accepts stream type StreamReader[I] and returns non-stream type O           |
| Transform          | Accepts stream type StreamReader[I] and returns stream type StreamReader[O] |

## Highly Extensible Aspects (Callbacks)

- Aspects handle cross-cutting concerns such as logging, tracing, metrics, etc., as well as exposing internal details of component implementations.
- Five aspects are supported: **OnStart, OnEnd, OnError, OnStartWithStreamInput, OnEndWithStreamOutput**.
- Developers can easily create custom callback handlers, add them during graph run via options, and they will be invoked during graph run.
- Graph can also inject aspects to those component implementations that do not support callbacks on their own.

# Eino Framework Structure

![](.github/static/img/eino/eino_framework.jpeg)

The Eino framework consists of several parts:

- Eino(this repo): Contains Eino&#039;s type definitions, streaming mechanism, component abstractions, orchestration capabilities, aspect mechanisms, etc.

- [EinoExt](https://github.com/cloudwego/eino-ext): Component implementations, callback handlers implementations, component usage examples, and various tools such as evaluators, prompt optimizers.

- [Eino Devops](https://github.com/cloudwego/eino-ext/tree/main/devops): visualized developing, visualized debugging
  etc.

- [EinoExamples](https://github.com/cloudwego/eino-examples) is the repo containing example applications and best practices for Eino.

## Detailed Documentation

For learning and using Eino, we provide a comprehensive Eino User Manual to help you quickly understand the concepts in Eino and master the skills of developing AI applications based on Eino. Start exploring through the [Eino User Manual](https://www.cloudwego.io/zh/docs/eino/) now!

For a quick introduction to building AI applications with Eino, we recommend starting with [Eino: Quick Start](https://www.cloudwego.io/zh/docs/eino/quick_start/)

## Dependencies
- Go 1.18 and above.

## Security

If you discover a potential security issue in this project, or think you may
have discovered a security issue, we ask that you notify Bytedance Security via our [security center](https://security.bytedance.com/src) or [vulnerability reporting email](sec@bytedance.com).

Please do **not** create a public GitHub issue.

## Contact US
- How to become a member: [COMMUNITY MEMBERSHIP](https://github.com/cloudwego/community/blob/main/COMMUNITY_MEMBERSHIP.md)
- Issues: [Issues](https://github.com/cloudwego/eino/issues)
- Lark: Scan the QR code below with [Register Feishu](https://www.feishu.cn/en/) to join our CloudWeGo/eino user group.

&amp;ensp;&amp;ensp;&amp;ensp; &lt;img src=&quot;.github/static/img/eino/lark_group_zh.png&quot; alt=&quot;LarkGroup&quot; width=&quot;200&quot;/&gt;

## License

This project is licensed under the [Apache-2.0 License](LICENSE-APACHE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[temporalio/temporal]]></title>
            <link>https://github.com/temporalio/temporal</link>
            <guid>https://github.com/temporalio/temporal</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:47 GMT</pubDate>
            <description><![CDATA[Temporal service]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/temporalio/temporal">temporalio/temporal</a></h1>
            <p>Temporal service</p>
            <p>Language: Go</p>
            <p>Stars: 17,323</p>
            <p>Forks: 1,256</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;div class=&quot;title-block&quot; style=&quot;text-align: center;&quot; align=&quot;center&quot;&gt;

# Temporal‚Äîdurable execution platform

&lt;p&gt;&lt;img title=&quot;temporal logo&quot; src=&quot;https://avatars.githubusercontent.com/u/56493103?s=320&quot; width=&quot;320&quot; height=&quot;320&quot;&gt;&lt;/p&gt;

[![GitHub Release](https://img.shields.io/github/v/release/temporalio/temporal)](https://github.com/temporalio/temporal/releases/latest)
[![GitHub License](https://img.shields.io/github/license/temporalio/temporal)](https://github.com/temporalio/temporal/blob/main/LICENSE)
[![Code Coverage](https://img.shields.io/badge/codecov-report-blue)](https://app.codecov.io/gh/temporalio/temporal)
[![Community](https://img.shields.io/static/v1?label=community&amp;message=get%20help&amp;color=informational)](https://community.temporal.io)
[![Go Report Card](https://goreportcard.com/badge/github.com/temporalio/temporal)](https://goreportcard.com/report/github.com/temporalio/temporal)

**[Introduction](#introduction) &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Getting Started](#getting-started) &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Contributing](#contributing) &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Temporal Docs](https://docs.temporal.io/) &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Temporal 101](https://learn.temporal.io/courses/temporal_101/)**

&lt;/div&gt;

## Introduction

Temporal is a durable execution platform that enables developers to build scalable applications without sacrificing productivity or reliability.
The Temporal server executes units of application logic called Workflows in a resilient manner that automatically handles intermittent failures, and retries failed operations.

Temporal is a mature technology that originated as a fork of Uber&#039;s Cadence.
It is developed by [Temporal Technologies](https://temporal.io/), a startup by the creators of Cadence.

[![image](https://github.com/temporalio/temporal/assets/251288/693d18b5-01de-4a3b-b47b-96347b84f610)](https://youtu.be/wIpz4ioK0gI &#039;Getting to know Temporal&#039;)

## Getting Started

### Download and Start Temporal Server Locally

Execute the following commands to start a pre-built image along with all the dependencies.

```bash
brew install temporal
temporal server start-dev
```

Refer to [Temporal CLI](https://docs.temporal.io/cli/#installation) documentation for more installation options.

### Run the Samples

Clone or download samples for [Go](https://github.com/temporalio/samples-go) or [Java](https://github.com/temporalio/samples-java) and run them with the local Temporal server.
We have a number of [HelloWorld type scenarios](https://github.com/temporalio/samples-java#helloworld) available, as well as more advanced ones. Note that the sets of samples are currently different between Go and Java.

### Use CLI

Use [Temporal CLI](https://docs.temporal.io/cli/) to interact with the running Temporal server.

```bash
temporal operator namespace list
temporal workflow list
```

### Use Temporal Web UI

Try [Temporal Web UI](https://docs.temporal.io/web-ui) by opening [http://localhost:8233](http://localhost:8233) for viewing your sample workflows executing on Temporal.

## Repository

This repository contains the source code of the Temporal server. To implement Workflows, Activities and Workers, use one of the [supported languages](https://docs.temporal.io/dev-guide/).

## Contributing

We&#039;d love your help in making Temporal great.

Helpful links to get started:

- [work on or propose a new feature](https://github.com/temporalio/proposals)
- [learn about the Temporal Server architecture](./docs/architecture/README.md)
- [learn how to build and run the Temporal Server locally](./CONTRIBUTING.md)
- [learn about Temporal Server testing tools and best practices](./docs/development/testing.md)
- join the Temporal community [forum](https://community.temporal.io) and [Slack](https://t.mp/slack)

## License

[MIT License](https://github.com/temporalio/temporal/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[junegunn/fzf]]></title>
            <link>https://github.com/junegunn/fzf</link>
            <guid>https://github.com/junegunn/fzf</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:46 GMT</pubDate>
            <description><![CDATA[üå∏ A command-line fuzzy finder]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/junegunn/fzf">junegunn/fzf</a></h1>
            <p>üå∏ A command-line fuzzy finder</p>
            <p>Language: Go</p>
            <p>Stars: 76,423</p>
            <p>Forks: 2,651</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;
  &lt;sup&gt;Special thanks to:&lt;/sup&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://tuple.app/fzf&quot;&gt;
    &lt;img alt=&quot;Tuple&#039;s sponsorship image&quot; src=&quot;https://raw.githubusercontent.com/junegunn/i/master/tuple.png&quot; width=&quot;400&quot;&gt;
  &lt;/a&gt;

### [Tuple, the premier screen sharing app for developers](https://tuple.app/fzf)
[Available for MacOS &amp; Windows](https://tuple.app/fzf)&lt;br&gt;

---

   &lt;sup&gt;Special thanks to:&lt;/sup&gt;
   &lt;br&gt;
   &lt;a href=&quot;https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=fzf&quot;&gt;
      &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd7ecac94eae&quot;&gt;
   &lt;/a&gt;

### [Warp, the intelligent terminal for developers](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=fzf)
[Available for MacOS, Linux, &amp; Windows](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=fzf)&lt;br&gt;

&lt;/div&gt;

---

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-color.png&quot; alt=&quot;fzf - a command-line fuzzy finder&quot;&gt;
  &lt;a href=&quot;https://github.com/junegunn/fzf/actions&quot;&gt;&lt;img src=&quot;https://github.com/junegunn/fzf/actions/workflows/linux.yml/badge.svg?branch=master&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;http://github.com/junegunn/fzf/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/tag/junegunn/fzf&quot; alt=&quot;Version&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/junegunn/fzf?tab=MIT-1-ov-file#readme&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/junegunn/fzf&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/junegunn/fzf/graphs/contributors&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/junegunn/fzf&quot; alt=&quot;Contributors&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/sponsors/junegunn&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/sponsors/junegunn&quot; alt=&quot;Sponsors&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/junegunn/fzf/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/junegunn/fzf?style=flat&quot; alt=&quot;Stars&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

---

fzf is a general-purpose command-line fuzzy finder.

&lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-preview.png&quot; width=640&gt;

It&#039;s an interactive filter program for any kind of list; files, command
history, processes, hostnames, bookmarks, git commits, etc. It implements
a &quot;fuzzy&quot; matching algorithm, so you can quickly type in patterns with omitted
characters and still get the results you want.

Highlights
----------

- **Portable** ‚Äî Distributed as a single binary for easy installation
- **Fast** ‚Äî Optimized to process millions of items instantly
- **Versatile** ‚Äî Fully customizable through an event-action binding mechanism
- **All-inclusive** ‚Äî Comes with integrations for Bash, Zsh, Fish, Vim, and Neovim

Table of Contents
-----------------

&lt;!-- vim-markdown-toc GFM --&gt;

* [Installation](#installation)
    * [Using Homebrew](#using-homebrew)
    * [Using Mise](#using-mise)
    * [Linux packages](#linux-packages)
    * [Windows packages](#windows-packages)
    * [Using git](#using-git)
    * [Binary releases](#binary-releases)
    * [Setting up shell integration](#setting-up-shell-integration)
    * [Vim/Neovim plugin](#vimneovim-plugin)
* [Upgrading fzf](#upgrading-fzf)
* [Building fzf](#building-fzf)
* [Usage](#usage)
    * [Using the finder](#using-the-finder)
    * [Display modes](#display-modes)
        * [`--height` mode](#--height-mode)
        * [`--tmux` mode](#--tmux-mode)
    * [Search syntax](#search-syntax)
    * [Environment variables](#environment-variables)
    * [Customizing the look](#customizing-the-look)
    * [Options](#options)
    * [Demo](#demo)
* [Examples](#examples)
* [Key bindings for command-line](#key-bindings-for-command-line)
* [Fuzzy completion for bash and zsh](#fuzzy-completion-for-bash-and-zsh)
    * [Files and directories](#files-and-directories)
    * [Process IDs](#process-ids)
    * [Host names](#host-names)
    * [Environment variables / Aliases](#environment-variables--aliases)
    * [Customizing fzf options for completion](#customizing-fzf-options-for-completion)
    * [Customizing completion source for paths and directories](#customizing-completion-source-for-paths-and-directories)
    * [Supported commands](#supported-commands)
    * [Custom fuzzy completion](#custom-fuzzy-completion)
* [Vim plugin](#vim-plugin)
* [Advanced topics](#advanced-topics)
    * [Customizing for different types of input](#customizing-for-different-types-of-input)
    * [Performance](#performance)
    * [Executing external programs](#executing-external-programs)
    * [Turning into a different process](#turning-into-a-different-process)
    * [Reloading the candidate list](#reloading-the-candidate-list)
        * [1. Update the list of processes by pressing CTRL-R](#1-update-the-list-of-processes-by-pressing-ctrl-r)
        * [2. Switch between sources by pressing CTRL-D or CTRL-F](#2-switch-between-sources-by-pressing-ctrl-d-or-ctrl-f)
        * [3. Interactive ripgrep integration](#3-interactive-ripgrep-integration)
    * [Preview window](#preview-window)
    * [Previewing an image](#previewing-an-image)
* [Tips](#tips)
    * [Respecting `.gitignore`](#respecting-gitignore)
    * [Fish shell](#fish-shell)
    * [fzf Theme Playground](#fzf-theme-playground)
* [Related projects](#related-projects)
* [License](#license)
* [Goods](#goods)
* [Sponsors :heart:](#sponsors-heart)

&lt;!-- vim-markdown-toc --&gt;

Installation
------------

### Using Homebrew

You can use [Homebrew](https://brew.sh/) (on macOS or Linux) to install fzf.

```sh
brew install fzf
```

&gt; [!IMPORTANT]
&gt; To set up shell integration (key bindings and fuzzy completion),
&gt; see [the instructions below](#setting-up-shell-integration).

fzf is also available [via MacPorts][portfile]: `sudo port install fzf`

[portfile]: https://github.com/macports/macports-ports/blob/master/sysutils/fzf/Portfile

### Using Mise

You can use [mise](https://github.com/jdx/mise) to install fzf.

```sh
mise use -g fzf@latest
```

### Linux packages

| Package Manager | Linux Distribution      | Command                            |
| --------------- | ----------------------- | ---------------------------------- |
| APK             | Alpine Linux            | `sudo apk add fzf`                 |
| APT             | Debian 9+/Ubuntu 19.10+ | `sudo apt install fzf`             |
| Conda           |                         | `conda install -c conda-forge fzf` |
| DNF             | Fedora                  | `sudo dnf install fzf`             |
| Nix             | NixOS, etc.             | `nix-env -iA nixpkgs.fzf`          |
| Pacman          | Arch Linux              | `sudo pacman -S fzf`               |
| pkg             | FreeBSD                 | `pkg install fzf`                  |
| pkgin           | NetBSD                  | `pkgin install fzf`                |
| pkg_add         | OpenBSD                 | `pkg_add fzf`                      |
| Portage         | Gentoo                  | `emerge --ask app-shells/fzf`      |
| Spack           |                         | `spack install fzf`                |
| XBPS            | Void Linux              | `sudo xbps-install -S fzf`         |
| Zypper          | openSUSE                | `sudo zypper install fzf`          |

&gt; [!IMPORTANT]
&gt; To set up shell integration (key bindings and fuzzy completion),
&gt; see [the instructions below](#setting-up-shell-integration).

[![Packaging status](https://repology.org/badge/vertical-allrepos/fzf.svg?columns=3)](https://repology.org/project/fzf/versions)

### Windows packages

On Windows, fzf is available via [Chocolatey][choco], [Scoop][scoop],
[Winget][winget], and [MSYS2][msys2]:

| Package manager | Command                               |
| --------------- | ------------------------------------- |
| Chocolatey      | `choco install fzf`                   |
| Scoop           | `scoop install fzf`                   |
| Winget          | `winget install fzf`                  |
| MSYS2 (pacman)  | `pacman -S $MINGW_PACKAGE_PREFIX-fzf` |

[choco]: https://chocolatey.org/packages/fzf
[scoop]: https://github.com/ScoopInstaller/Main/blob/master/bucket/fzf.json
[winget]: https://github.com/microsoft/winget-pkgs/tree/master/manifests/j/junegunn/fzf
[msys2]: https://packages.msys2.org/base/mingw-w64-fzf

### Using git

Alternatively, you can &quot;git clone&quot; this repository to any directory and run
[install](https://github.com/junegunn/fzf/blob/master/install) script.

```sh
git clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf
~/.fzf/install
```

The install script will add lines to your shell configuration file to modify
`$PATH` and set up shell integration.

### Binary releases

You can download the official fzf binaries from the releases page.

* https://github.com/junegunn/fzf/releases

### Setting up shell integration

Add the following line to your shell configuration file.

* bash
  ```sh
  # Set up fzf key bindings and fuzzy completion
  eval &quot;$(fzf --bash)&quot;
  ```
* zsh
  ```sh
  # Set up fzf key bindings and fuzzy completion
  source &lt;(fzf --zsh)
  ```
* fish
  ```fish
  # Set up fzf key bindings
  fzf --fish | source
  ```

&gt; [!NOTE]
&gt; `--bash`, `--zsh`, and `--fish` options are only available in fzf 0.48.0 or
&gt; later. If you have an older version of fzf, or want finer control, you can
&gt; source individual script files in the [/shell](/shell) directory. The
&gt; location of the files may vary depending on the package manager you use.
&gt; Please refer to the package documentation for more information.
&gt; (e.g. `apt show fzf`)

&gt; [!TIP]
&gt; You can disable CTRL-T, CTRL-R, or ALT-C bindings by setting the
&gt; corresponding `*_COMMAND` variable to an empty string when sourcing the
&gt; script. For example, to disable CTRL-R and ALT-C:
&gt;
&gt; * bash: `FZF_CTRL_R_COMMAND= FZF_ALT_C_COMMAND= eval &quot;$(fzf --bash)&quot;`
&gt; * zsh: `FZF_CTRL_R_COMMAND= FZF_ALT_C_COMMAND= source &lt;(fzf --zsh)`
&gt; * fish: `fzf --fish | FZF_CTRL_R_COMMAND= FZF_ALT_C_COMMAND= source`
&gt;
&gt; Setting the variables after sourcing the script will have no effect.

### Vim/Neovim plugin

If you use [vim-plug](https://github.com/junegunn/vim-plug), add this to
your Vim configuration file:

```vim
Plug &#039;junegunn/fzf&#039;, { &#039;do&#039;: { -&gt; fzf#install() } }
Plug &#039;junegunn/fzf.vim&#039;
```

* `junegunn/fzf` provides the basic library functions
    * `fzf#install()` makes sure that you have the latest binary
* `junegunn/fzf.vim` is [a separate project](https://github.com/junegunn/fzf.vim)
  that provides a variety of useful commands

To learn more about the Vim integration, see [README-VIM.md](README-VIM.md).

&gt; [!TIP]
&gt; If you use Neovim and prefer Lua-based plugins, check out
&gt; [fzf-lua](https://github.com/ibhagwan/fzf-lua).

Upgrading fzf
-------------

fzf is being actively developed, and you might want to upgrade it once in a
while. Please follow the instruction below depending on the installation
method used.

- git: `cd ~/.fzf &amp;&amp; git pull &amp;&amp; ./install`
- brew: `brew update; brew upgrade fzf`
- macports: `sudo port upgrade fzf`
- chocolatey: `choco upgrade fzf`
- vim-plug: `:PlugUpdate fzf`

Building fzf
------------

See [BUILD.md](BUILD.md).

Usage
-----

fzf will launch interactive finder, read the list from STDIN, and write the
selected item to STDOUT.

```sh
find * -type f | fzf &gt; selected
```

Without STDIN pipe, fzf will traverse the file system under the current
directory to get the list of files.

```sh
vim $(fzf)
```

&gt; [!NOTE]
&gt; You can override the default behavior
&gt; * Either by setting `$FZF_DEFAULT_COMMAND` to a command that generates the desired list
&gt; * Or by setting `--walker`, `--walker-root`, and `--walker-skip` options in `$FZF_DEFAULT_OPTS`

&gt; [!WARNING]
&gt; A more robust solution would be to use `xargs` but we&#039;ve presented
&gt; the above as it&#039;s easier to grasp
&gt; ```sh
&gt; fzf --print0 | xargs -0 -o vim
&gt; ```

&gt; [!TIP]
&gt; fzf also has the ability to turn itself into a different process.
&gt;
&gt; ```sh
&gt; fzf --bind &#039;enter:become(vim {})&#039;
&gt; ```
&gt;
&gt; *See [Turning into a different process](#turning-into-a-different-process)
&gt; for more information.*

### Using the finder

- `CTRL-K` / `CTRL-J` (or `CTRL-P` / `CTRL-N`) to move cursor up and down
- `Enter` key to select the item, `CTRL-C` / `CTRL-G` / `ESC` to exit
- On multi-select mode (`-m`), `TAB` and `Shift-TAB` to mark multiple items
- Emacs style key bindings
- Mouse: scroll, click, double-click; shift-click and shift-scroll on
  multi-select mode

### Display modes

fzf by default runs in fullscreen mode, but there are other display modes.

#### `--height` mode

With `--height HEIGHT[%]`, fzf will start below the cursor with the given height.

```sh
fzf --height 40%
```

`reverse` layout and `--border` goes well with this option.

```sh
fzf --height 40% --layout reverse --border
```

By prepending `~` to the height, you&#039;re setting the maximum height.

```sh
# Will take as few lines as possible to display the list
seq 3 | fzf --height ~100%
seq 3000 | fzf --height ~100%
```

Height value can be a negative number.

```sh
# Screen height - 3
fzf --height -3
```

#### `--tmux` mode

With `--tmux` option, fzf will start in a tmux popup.

```sh
# --tmux [center|top|bottom|left|right][,SIZE[%]][,SIZE[%][,border-native]]

fzf --tmux center         # Center, 50% width and height
fzf --tmux 80%            # Center, 80% width and height
fzf --tmux 100%,50%       # Center, 100% width and 50% height
fzf --tmux left,40%       # Left, 40% width
fzf --tmux left,40%,90%   # Left, 40% width, 90% height
fzf --tmux top,40%        # Top, 40% height
fzf --tmux bottom,80%,40% # Bottom, 80% width, 40% height
```

`--tmux` is silently ignored when you&#039;re not on tmux.

&gt; [!NOTE]
&gt; If you&#039;re stuck with an old version of tmux that doesn&#039;t support popup,
&gt; or if you want to open fzf in a regular tmux pane, check out
&gt; [fzf-tmux](bin/fzf-tmux) script.

&gt; [!TIP]
&gt; You can add these options to `$FZF_DEFAULT_OPTS` so that they&#039;re applied by
&gt; default. For example,
&gt;
&gt; ```sh
&gt; # Open in tmux popup if on tmux, otherwise use --height mode
&gt; export FZF_DEFAULT_OPTS=&#039;--height 40% --tmux bottom,40% --layout reverse --border top&#039;
&gt; ```

### Search syntax

Unless otherwise specified, fzf starts in &quot;extended-search mode&quot; where you can
type in multiple search terms delimited by spaces. e.g. `^music .mp3$ sbtrkt
!fire`

| Token     | Match type                              | Description                                  |
| --------- | --------------------------------------  | ------------------------------------------   |
| `sbtrkt`  | fuzzy-match                             | Items that match `sbtrkt`                    |
| `&#039;wild`   | exact-match (quoted)                    | Items that include `wild`                    |
| `&#039;wild&#039;`  | exact-boundary-match (quoted both ends) | Items that include `wild` at word boundaries |
| `^music`  | prefix-exact-match                      | Items that start with `music`                |
| `.mp3$`   | suffix-exact-match                      | Items that end with `.mp3`                   |
| `!fire`   | inverse-exact-match                     | Items that do not include `fire`             |
| `!^music` | inverse-prefix-exact-match              | Items that do not start with `music`         |
| `!.mp3$`  | inverse-suffix-exact-match              | Items that do not end with `.mp3`            |

If you don&#039;t prefer fuzzy matching and do not wish to &quot;quote&quot; every word,
start fzf with `-e` or `--exact` option. Note that when  `--exact` is set,
`&#039;`-prefix &quot;unquotes&quot; the term.

A single bar character term acts as an OR operator. For example, the following
query matches entries that start with `core` and end with either `go`, `rb`,
or `py`.

```
^core go$ | rb$ | py$
```

### Environment variables

- `FZF_DEFAULT_COMMAND`
    - Default command to use when input is tty
    - e.g. `export FZF_DEFAULT_COMMAND=&#039;fd --type f&#039;`
- `FZF_DEFAULT_OPTS`
    - Default options
    - e.g. `export FZF_DEFAULT_OPTS=&quot;--layout=reverse --inline-info&quot;`
- `FZF_DEFAULT_OPTS_FILE`
    - If you prefer to manage default options in a file, set this variable to
      point to the location of the file
    - e.g. `export FZF_DEFAULT_OPTS_FILE=~/.fzfrc`

&gt; [!WARNING]
&gt; `FZF_DEFAULT_COMMAND` is not used by shell integration due to the
&gt; slight difference in requirements.
&gt;
&gt; * `CTRL-T` runs `$FZF_CTRL_T_COMMAND` to get a list of files and directories
&gt; * `ALT-C` runs `$FZF_ALT_C_COMMAND` to get a list of directories
&gt; * `vim ~/**&lt;tab&gt;` runs `fzf_compgen_path()` with the prefix (`~/`) as the first argument
&gt; * `cd foo**&lt;tab&gt;` runs `fzf_compgen_dir()` with the prefix (`foo`) as the first argument
&gt;
&gt; The available options are described later in this document.

### Customizing the look

The user interface of fzf is fully customizable with a large number of
configuration options. For a quick setup, you can start with one of the style
presets ‚Äî `default`, `full`, or `minimal` ‚Äî using the `--style` option.

```sh
fzf --style full \
    --preview &#039;fzf-preview.sh {}&#039; --bind &#039;focus:transform-header:file --brief {}&#039;
```

| Preset    | Screenshot                                                                             |
| :---      | :---                                                                                   |
| `default` | &lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-style-default.png&quot;/&gt; |
| `full`    | &lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-style-full.png&quot;/&gt;    |
| `minimal` | &lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-style-minimal.png&quot;/&gt; |

Here&#039;s an example based on the `full` preset:

&lt;img src=&quot;https://raw.githubusercontent.com/junegunn/i/master/fzf-4-borders.png&quot;/&gt;

&lt;details&gt;

```sh
git ls-files | fzf --style full \
    --border --padding 1,2 \
    --border-label &#039; Demo &#039; --input-label &#039; Input &#039; --header-label &#039; File Type &#039; \
    --preview &#039;fzf-preview.sh {}&#039; \
    --bind &#039;result:transform-list-label:
        if [[ -z $FZF_QUERY ]]; then
          echo &quot; $FZF_MATCH_COUNT items &quot;
        else
          echo &quot; $FZF_MATCH_COUNT matches for [$FZF_QUERY] &quot;
        fi
        &#039; \
    --bind &#039;focus:transform-preview-label:[[ -n {} ]] &amp;&amp; printf &quot; Previewing [%s] &quot; {}&#039; \
    --bind &#039;focus:+transform-header:file --brief {} || echo &quot;No file selected&quot;&#039; \
    --bind &#039;ctrl-r:change-list-label( Reloading the list )+reload(sleep 2; git ls-files)&#039; \
    --color &#039;border:#aaaaaa,label:#cccccc&#039; \
    --color &#039;preview-border:#9999cc,preview-label:#ccccff&#039; \
    --color &#039;list-border:#669966,list-label:#99cc99&#039; \
    --color &#039;input-border:#996666,input-label:#ffcccc&#039; \
    --color &#039;header-border:#6699cc,header-label:#99ccff&#039;
```

&lt;/details&gt;

### Options

See the man page (`fzf --man` or `man fzf`) for the full list of options.

### Demo
If you learn by watching videos, check out this screencast by [@samoshkin](https://github.com/samoshkin) to explore `fzf` features.

&lt;a title=&quot;fzf - command-line fuzzy finder&quot; href=&quot;https://www.youtube.com/watch?v=qgG5Jhi_Els&quot;&gt;
  &lt;img src=&quot;https://i.imgur.com/vtG8olE.png&quot; width=&quot;640&quot;&gt;
&lt;/a&gt;

Examples
--------

* [Wiki page of examples](https://github.com/junegunn/fzf/wiki/examples)
    * *Disclaimer: The examples on this page are maintained by the community
      and are not thoroughly tested*
* [Advanced fzf examples](https://github.com/junegunn/fzf/blob/master/ADVANCED.md)

Key bindings for command-line
-----------------------------

By [setting up shell integration](#setting-up-shell-integration), you can use
the following key bindings in bash, zsh, and fish.

- `CTRL-T` - Paste the selected files and directories onto the command-line
    - The list is generated using `--walker file,dir,follow,hidden` option
        - You can override the behavior by setting `FZF_CTRL_T_COMMAND` to a custom command that generates the desired list
        - Or you can set `--walker*` options in `FZF_CTRL_T_OPTS`
    - Set `FZF_CTRL_T_OPTS` to pass additional options to fzf
      ```sh
      # Preview file content using bat (https://github.com/sharkdp/bat)
      export FZF_CTRL_T_OPTS=&quot;
        --walker-skip .g

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[zitadel/zitadel]]></title>
            <link>https://github.com/zitadel/zitadel</link>
            <guid>https://github.com/zitadel/zitadel</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:45 GMT</pubDate>
            <description><![CDATA[ZITADEL - Identity infrastructure, simplified for¬†you.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zitadel/zitadel">zitadel/zitadel</a></h1>
            <p>ZITADEL - Identity infrastructure, simplified for¬†you.</p>
            <p>Language: Go</p>
            <p>Stars: 12,591</p>
            <p>Forks: 902</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;./docs/static/logos/zitadel-logo-dark@2x.png#gh-light-mode-only&quot; alt=&quot;Zitadel Logo&quot; max-height=&quot;200px&quot; width=&quot;auto&quot; /&gt;
    &lt;img src=&quot;./docs/static/logos/zitadel-logo-light@2x.png#gh-dark-mode-only&quot; alt=&quot;Zitadel Logo&quot; max-height=&quot;200px&quot; width=&quot;auto&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/zitadel/zitadel&quot; alt=&quot;Open in Dev Container&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&quot; /&gt; &lt;/a&gt;
    &lt;a href=&quot;https://github.com/zitadel/zitadel/blob/main/LICENSE&quot; alt=&quot;License&quot;&gt;
        &lt;img src=&quot;https://badgen.net/github/license/zitadel/zitadel/&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://bestpractices.coreinfrastructure.org/projects/6662&quot;&gt;&lt;img src=&quot;https://bestpractices.coreinfrastructure.org/projects/6662/badge&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/semantic-release/semantic-release&quot; alt=&quot;semantic-release&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/zitadel/zitadel/actions&quot; alt=&quot;ZITADEL Release&quot;&gt;
        &lt;img alt=&quot;GitHub Workflow Status (with event)&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/zitadel/zitadel/build.yml?event=pull_request&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://zitadel.com/docs/support/software-release-cycles-support&quot; alt=&quot;Release&quot;&gt;
        &lt;img src=&quot;https://badgen.net/github/release/zitadel/zitadel/stable&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://goreportcard.com/report/github.com/zitadel/zitadel&quot; alt=&quot;Go Report Card&quot;&gt;
        &lt;img src=&quot;https://goreportcard.com/badge/github.com/zitadel/zitadel&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://codecov.io/gh/zitadel/zitadel&quot; alt=&quot;Code Coverage&quot;&gt;
        &lt;img src=&quot;https://codecov.io/gh/zitadel/zitadel/branch/main/graph/badge.svg&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/zitadel/zitadel/graphs/contributors&quot; alt=&quot;Release&quot;&gt;
        &lt;img alt=&quot;GitHub contributors&quot; src=&quot;https://img.shields.io/github/contributors/zitadel/zitadel&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/YgjEuJzZ3x&quot; alt=&quot;Discord Chat&quot;&gt;
        &lt;img src=&quot;https://badgen.net/discord/online-members/YgjEuJzZ3x&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://openid.net/certification/#OPs&quot; alt=&quot;OpenID Connect Certified&quot;&gt;
        &lt;img src=&quot;./docs/static/logos/oidc-cert.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

Are you searching for a user management tool that is quickly set up like Auth0 and open source like Keycloak?

Do you have a project that requires multi-tenant user management with self-service for your customers?

Look no further ‚Äî ZITADEL is the identity infrastructure, simplified for you.

We provide you with a wide range of out-of-the-box features to accelerate your project, including:

:white_check_mark: Multi-tenancy with team management  
:white_check_mark: Secure login  
:white_check_mark: Self-service  
:white_check_mark: OpenID Connect  
:white_check_mark: OAuth2.x  
:white_check_mark: SAML2  
:white_check_mark: LDAP  
:white_check_mark: Passkeys / FIDO2  
:white_check_mark: OTP  
:white_check_mark: SCIM 2.0 Server
and an unlimited audit trail is there for you, ready to use.

With ZITADEL, you are assured of a robust and customizable turnkey solution for all your authentication and authorization needs.

---

**[üè° Website](https://zitadel.com) [üí¨ Chat](https://zitadel.com/chat) [üìã Docs](https://zitadel.com/docs/) [üßë‚Äçüíª Blog](https://zitadel.com/blog) [üìû Contact](https://zitadel.com/contact/)**

## Get started

üëâ [Quick Start Guide](https://zitadel.com/docs/guides/start/quickstart)

### Deploy ZITADEL (Self-Hosted)

Deploying ZITADEL locally takes less than 3 minutes. Go ahead and give it a try!

* [Linux](https://zitadel.com/docs/self-hosting/deploy/linux)
* [MacOS](https://zitadel.com/docs/self-hosting/deploy/macos)
* [Docker compose](https://zitadel.com/docs/self-hosting/deploy/compose)
* [Kubernetes](https://zitadel.com/docs/self-hosting/deploy/kubernetes)

See all guides [here](https://zitadel.com/docs/self-hosting/deploy/overview)

&gt; If you are interested to get professional support for your self-hosted ZITADEL [please reach out to us](https://zitadel.com/contact)!

### Setup ZITADEL Cloud (SaaS)

If you want to experience a hands-free ZITADEL, you should use [ZITADEL Cloud](https://zitadel.com).
Available data regions are: 
* üá∫üá∏ United States
* üá™üá∫ European Union
* üá¶üá∫ Australia
* üá®üá≠ Switzerland

ZITADEL Cloud comes with a free tier, providing you with all the same features as the open-source version.
Learn more about the [pay-as-you-go pricing](https://zitadel.com/pricing).

## Adopters

We are grateful to the organizations and individuals who are using ZITADEL. If you are using ZITADEL, please consider adding your name to our [Adopters list](./ADOPTERS.md) by submitting a pull request.

### Example applications

Clone one of our [example applications](https://zitadel.com/docs/sdk-examples/introduction) or deploy them directly to Vercel.

### SDKs

Use our [SDKs](https://zitadel.com/docs/sdk-examples/introduction) for your favorite language and framework.

## Why choose ZITADEL

We built ZITADEL with a complex multi-tenancy architecture in mind and provide the best solution to handle [B2B customers and partners](https://zitadel.com/docs/guides/solution-scenarios/b2b).
Yet it offers everything you need for a customer identity ([CIAM](https://zitadel.com/docs/guides/solution-scenarios/b2c)) use case.

- [API-first approach](https://zitadel.com/docs/apis/introduction)
- [Multi-tenancy](https://zitadel.com/docs/guides/solution-scenarios/b2b) authentication and access management
- [Strong audit trail](https://zitadel.com/docs/concepts/features/audit-trail) thanks to [event sourcing](https://zitadel.com/docs/concepts/eventstore/overview) as storage pattern
- [Actions](https://zitadel.com/docs/apis/actions/introduction) to react on events with custom code and extended ZITADEL for you needs
- [Branding](https://zitadel.com/docs/guides/manage/customize/branding) for a uniform user experience across multiple organizations
- [Self-service](https://zitadel.com/docs/concepts/features/selfservice) for end-users, business customers, and administrators
- [Postgres](https://www.postgresql.org/) database as reliable and widespread storage option

## Features

Authentication

- Single Sign On (SSO)
- [Passkeys support (FIDO2 / WebAuthN)](https://zitadel.com/docs/concepts/features/passkeys)
- Username / Password
- Multifactor authentication with OTP, U2F, Email OTP, SMS OTP
- [LDAP](https://zitadel.com/docs/guides/integrate/identity-providers/ldap)
- [External enterprise identity providers and social logins](https://zitadel.com/docs/guides/integrate/identity-providers/introduction)
- [Device authorization](https://zitadel.com/docs/guides/solution-scenarios/device-authorization)
- [OpenID Connect certified](https://openid.net/certification/#OPs) =&gt; [OIDC Endpoints](https://zitadel.com/docs/apis/openidoauth/endpoints)
- [SAML 2.0](http://docs.oasis-open.org/security/saml/Post2.0/sstc-saml-tech-overview-2.0.html) =&gt; [SAML Endpoints](https://zitadel.com/docs/apis/saml/endpoints)
- [Custom sessions](https://zitadel.com/docs/guides/integrate/login-ui/username-password) if you need to go beyond OIDC or SAML 
- [Machine-to-machine](https://zitadel.com/docs/guides/integrate/service-users/authenticate-service-users) with JWT profile, Personal Access Tokens (PAT), and Client Credentials
- [Token exchange and impersonation](https://zitadel.com/docs/guides/integrate/token-exchange)
- [Beta: Hosted Login V2](https://zitadel.com/docs/guides/integrate/login/hosted-login#hosted-login-version-2-beta) our new Login version 2.0

Multi-Tenancy

- [Identity Brokering](https://zitadel.com/docs/guides/integrate/identity-brokering) with templates for popular identity providers
- [Customizable onboarding](https://zitadel.com/docs/guides/solution-scenarios/onboarding) for B2B and their users
- [Delegate role management to third-parties](https://zitadel.com/docs/guides/manage/console/projects)
- [Domain discovery](https://zitadel.com/docs/guides/solution-scenarios/domain-discovery)

Integration

- [GRPC and REST APIs](https://zitadel.com/docs/apis/introduction) for every functionality and resource
- [Actions](https://zitadel.com/docs/apis/actions/introduction) to call any API, send webhooks, adjust workflows, or customize tokens
- [Role Based Access Control (RBAC)](https://zitadel.com/docs/guides/integrate/retrieve-user-roles)
- [SCIM 2.0 Server](https://zitadel.com/docs/apis/scim2)
- [Examples and SDKs](https://zitadel.com/docs/sdk-examples/introduction)
- [Audit Log and SOC/SIEM](https://zitadel.com/docs/guides/integrate/external-audit-log)
- [User registration and onboarding](https://zitadel.com/docs/guides/integrate/onboarding)
- [Hosted and custom Login user interface](https://zitadel.com/docs/guides/integrate/login/login-users)

Self-Service
- [Self-registration](https://zitadel.com/docs/concepts/features/selfservice#registration) including verification
- [Self-service](https://zitadel.com/docs/concepts/features/selfservice) for end-users, business customers, and administrators
- [Administration UI (Console)](https://zitadel.com/docs/guides/manage/console/overview)

Deployment
- [Postgres](https://zitadel.com/docs/self-hosting/manage/database#postgres) (version &gt;= 14)
- [Zero Downtime Updates](https://zitadel.com/docs/concepts/architecture/solution#zero-downtime-updates)
- [High scalability](https://zitadel.com/docs/self-hosting/manage/production)

Track upcoming features on our [roadmap](https://zitadel.com/roadmap) and follow our [changelog](https://zitadel.com/changelog) for recent updates.

## How To Contribute

Find details about how you can contribute in our [Contribution Guide](./CONTRIBUTING.md).
Join our [Discord Chat](https://zitadel.com/chat) to get help.

## Contributors

&lt;a href=&quot;https://github.com/zitadel/zitadel/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=zitadel/zitadel&quot; /&gt;
&lt;/a&gt;

Made with [contrib.rocks](https://contrib.rocks/preview?repo=zitadel/zitadel).

## Showcase

### Quick Start Guide

Secure a React Application using OpenID Connect Authorization Code with PKCE

[![Quick Start Guide](https://user-images.githubusercontent.com/1366906/223662449-f17b734d-405c-4945-a8a1-200440c459e5.gif)](http://www.youtube.com/watch?v=5THbQljoPKg &quot;Quick Start Guide&quot;)

### Login with Passkeys

Use our Login widget to allow easy and secure access to your applications and enjoy all the benefits of Passkeys (FIDO 2 / WebAuthN):

[![Passkeys](https://user-images.githubusercontent.com/1366906/223664178-4132faef-4832-4014-b9ab-90c2a8d15436.gif)](https://www.youtube.com/watch?v=cZjHQYurSjw&amp;list=PLTDa7jTlOyRLdABgD2zL0LGM7rx5GZ1IR&amp;index=2 &quot;Passkeys&quot;)

### Admin Console

Use [Console](https://zitadel.com/docs/guides/manage/console/overview) or our [APIs](https://zitadel.com/docs/apis/introduction) to setup organizations, projects and applications.

[![Console Showcase](https://user-images.githubusercontent.com/1366906/223663344-67038d5f-4415-4285-ab20-9a4d397e2138.gif)](http://www.youtube.com/watch?v=RPpHktAcCtk &quot;Console Showcase&quot;)

### Login V2

Check out our new Login V2 version in our [documentation](https://zitadel.com/docs/guides/integrate/login/hosted-login#hosted-login-version-2-beta)
![New Login Showcase](https://github.com/user-attachments/assets/cb5c5212-128b-4dc9-b11d-cabfd3f73e26)

## Security

You can find our security policy [here](./SECURITY.md).

[Technical Advisories](https://zitadel.com/docs/support/technical_advisory) are published regarding major issues with the ZITADEL platform that could potentially impact security or stability in production environments.

## License

[here](./LICENSE) are our exact licensing terms.

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See our [license](./LICENSE) for detailed information governing permissions and limitations on use.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[henrygd/beszel]]></title>
            <link>https://github.com/henrygd/beszel</link>
            <guid>https://github.com/henrygd/beszel</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:44 GMT</pubDate>
            <description><![CDATA[Lightweight server monitoring hub with historical data, docker stats, and alerts.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/henrygd/beszel">henrygd/beszel</a></h1>
            <p>Lightweight server monitoring hub with historical data, docker stats, and alerts.</p>
            <p>Language: Go</p>
            <p>Stars: 18,187</p>
            <p>Forks: 574</p>
            <p>Stars today: 53 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[pingcap/tidb]]></title>
            <link>https://github.com/pingcap/tidb</link>
            <guid>https://github.com/pingcap/tidb</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:43 GMT</pubDate>
            <description><![CDATA[TiDB - the open-source, cloud-native, distributed SQL database designed for modern applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pingcap/tidb">pingcap/tidb</a></h1>
            <p>TiDB - the open-source, cloud-native, distributed SQL database designed for modern applications.</p>
            <p>Language: Go</p>
            <p>Stars: 39,545</p>
            <p>Forks: 6,082</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&#039;https://www.pingcap.com/?utm_source=github&amp;utm_medium=tidb&#039;&gt;
&lt;img src=&quot;docs/tidb-logo.png&quot; alt=&quot;TiDB, a distributed SQL database&quot; height=100&gt;&lt;/img&gt;
&lt;/a&gt;

---

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://github.com/pingcap/tidb/blob/master/LICENSE)
[![Language](https://img.shields.io/badge/Language-Go-blue.svg)](https://golang.org/)

[![Build Status](https://prow.tidb.net/badge.svg?jobs=merged-tidb-build)](https://prow.tidb.net/?repo=pingcap%2Ftidb&amp;type=postsubmit&amp;job=merged-tidb-build)
[![Go Report Card](https://goreportcard.com/badge/github.com/pingcap/tidb)](https://goreportcard.com/report/github.com/pingcap/tidb)
[![GitHub release](https://img.shields.io/github/tag/pingcap/tidb.svg?label=release)](https://github.com/pingcap/tidb/releases)
&lt;/div&gt;

# TiDB

TiDB (/‚Äôta…™diÀêbi:/, &quot;Ti&quot; stands for Titanium) is an open-source, cloud-native, distributed SQL database designed for high availability, horizontal and vertical scalability, strong consistency, and high performance.

- [Key Features](#key-features)
- [Quick Start](#quick-start)
- [Need Help?](#need-help)
- [Architecture](#architecture)
- [Contributing](#contributing)
- [License](#license)
- [See Also](#see-also)
- [Acknowledgments](#acknowledgments)

## Key Features

- **[Distributed Transactions](https://www.pingcap.com/blog/distributed-transactions-tidb?utm_source=github&amp;utm_medium=tidb)**: TiDB uses a two-phase commit protocol to ensure ACID compliance, providing strong consistency. Transactions span multiple nodes, and TiDB&#039;s distributed nature ensures data correctness even in the presence of network partitions or node failures.

- **[Horizontal and Vertical Scalability](https://docs.pingcap.com/tidb/stable/scale-tidb-using-tiup?utm_source=github&amp;utm_medium=tidb)**: TiDB can be scaled horizontally by adding more nodes or vertically by increasing resources of existing nodes, all without downtime. TiDB&#039;s architecture separates computing from storage, enabling you to adjust both independently as needed for flexibility and growth.

- **[High Availability](https://docs.pingcap.com/tidbcloud/high-availability-with-multi-az?utm_source=github&amp;utm_medium=tidb)**: Built-in Raft consensus protocol ensures reliability and automated failover. Data is stored in multiple replicas, and transactions are committed only after writing to the majority of replicas, guaranteeing strong consistency and availability, even if some replicas fail. Geographic placement of replicas can be configured for different disaster tolerance levels.

- **[Hybrid Transactional/Analytical Processing (HTAP)](https://www.pingcap.com/blog/htap-demystified-defining-modern-data-architecture-tidb?utm_source=github&amp;utm_medium=tidb)**: TiDB provides two storage engines: TiKV, a row-based storage engine, and TiFlash, a columnar storage engine. TiFlash uses the Multi-Raft Learner protocol to replicate data from TiKV in real time, ensuring consistent data between the TiKV row-based storage engine and the TiFlash columnar storage engine. The TiDB Server coordinates query execution across both TiKV and TiFlash to optimize performance.

- **[Cloud-Native](https://www.pingcap.com/cloud-native?utm_source=github&amp;utm_medium=tidb)**: TiDB can be deployed in public clouds, on-premises, or natively in Kubernetes. [TiDB Operator](https://docs.pingcap.com/tidb-in-kubernetes/stable/tidb-operator-overview/?utm_source=github&amp;utm_medium=tidb) helps manage TiDB on Kubernetes, automating cluster operations, while [TiDB Cloud](https://tidbcloud.com/?utm_source=github&amp;utm_medium=tidb) provides a fully-managed service for easy and economical deployment, allowing users to set up clusters with just a few clicks.

- **[MySQL Compatibility](https://docs.pingcap.com/tidb/stable/mysql-compatibility?utm_source=github&amp;utm_medium=tidb)**: TiDB is compatible with MySQL 8.0, allowing you to use familiar protocols, frameworks and tools. You can migrate applications to TiDB without changing any code, or with minimal modifications. Additionally, TiDB provides a suite of [data migration tools](https://docs.pingcap.com/tidb/stable/ecosystem-tool-user-guide?utm_source=github&amp;utm_medium=tidb) to help easily migrate application data into TiDB.

- **[Open Source Commitment](https://www.pingcap.com/blog/open-source-is-in-our-dna-reaffirming-tidb-commitment?utm_source=github&amp;utm_medium=tidb)**: Open source is at the core of TiDB&#039;s identity. All source code is available on GitHub under the Apache 2.0 license, including enterprise-grade features. TiDB is built with the belief that open source enables transparency, innovation, and collaboration. We actively encourage contributions from the community to help build a vibrant and inclusive ecosystem, reaffirming our commitment to open development and accessibility for everyone.

## Quick Start

1. Start a TiDB cluster.

    - **On local playground**. To start a local test cluster, refer to the [TiDB quick start guide](https://docs.pingcap.com/tidb/stable/quick-start-with-tidb#deploy-a-local-test-cluster?utm_source=github&amp;utm_medium=tidb).

    - **On Kubernetes**. TiDB can be easily deployed in a self-managed Kubernetes environment or Kubernetes services on public clouds using TiDB Operator. For more details, refer to the [TiDB on Kubernetes quick start guide](https://docs.pingcap.com/tidb-in-kubernetes/stable/get-started?utm_source=github&amp;utm_medium=tidb).

    - **Using TiDB Cloud (recommended)**. TiDB Cloud offers a fully managed version of TiDB with a free plan, no credit card required, so you can get a free cluster in seconds and start easily: [Sign up for TiDB Cloud](https://tidbcloud.com/free-trial?utm_source=github&amp;utm_medium=tidb).

2. Learn about TiDB SQL: To explore the SQL capabilities of TiDB, refer to the [TiDB SQL documentation](https://docs.pingcap.com/tidb/stable/sql-statement-overview?utm_source=github&amp;utm_medium=tidb).

3. Use a MySQL driver or an ORM to [Build an App with TiDB](https://docs.pingcap.com/tidbcloud/dev-guide-overview?utm_source=github&amp;utm_medium=tidb).

4. Explore key features, such as [data migration](https://docs.pingcap.com/tidbcloud/tidb-cloud-migration-overview?utm_source=github&amp;utm_medium=tidb), [changefeed](https://docs.pingcap.com/tidbcloud/changefeed-overview?utm_source=github&amp;utm_medium=tidb), [vector search](https://docs.pingcap.com/tidbcloud/vector-search-overview?utm_source=github&amp;utm_medium=tidb), [HTAP](https://docs.pingcap.com/tidbcloud/tidb-cloud-htap-quickstart?utm_source=github&amp;utm_medium=tidb), [disaster recovery](https://docs.pingcap.com/tidb/stable/dr-solution-introduction?utm_source=github&amp;utm_medium=tidb), etc.


## Need Help?

- You can connect with TiDB users, ask questions, find answers, and help others on our community platforms: [Discord](https://discord.gg/KVRZBR2DrG?utm_source=github), Slack ([English](https://slack.tidb.io/invite?team=tidb-community&amp;channel=everyone&amp;ref=pingcap-tidb), [Japanese](https://slack.tidb.io/invite?team=tidb-community&amp;channel=tidb-japan&amp;ref=github-tidb)), [Stack Overflow](https://stackoverflow.com/questions/tagged/tidb), [TiDB Chinese Forum](https://asktug.com), X [@PingCAP](https://twitter.com/PingCAP)

- For filing bugs, suggesting improvements, or requesting new features, use [Github Issues](https://github.com/pingcap/tidb/issues) or join discussions on [Github Discussions](https://github.com/orgs/pingcap/discussions).

- To troubleshoot TiDB, refer to [Troubleshooting documentation](https://docs.pingcap.com/tidb/stable/tidb-troubleshooting-map?utm_source=github&amp;utm_medium=tidb).

## Architecture

![TiDB architecture](./docs/tidb-architecture.png)

Learn more details about TiDB architecture in our [Docs](https://docs.pingcap.com/tidb/stable/tidb-architecture?utm_source=github&amp;utm_medium=tidb).

## Contributing

TiDB is built on a commitment to open source, and we welcome contributions from everyone. Whether you are interested in improving documentation, fixing bugs, or developing new features, we invite you to shape the future of TiDB.

- See our [Contributor Guide](https://github.com/pingcap/community/blob/master/contributors/README.md#how-to-contribute) and [TiDB Development Guide](https://pingcap.github.io/tidb-dev-guide/index.html) to get started.

- If you&#039;re looking for issues to work on, try looking at the [good first issues](https://github.com/pingcap/tidb/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) or [help wanted issues](https://github.com/pingcap/tidb/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22).

- The [contribution map](https://github.com/pingcap/tidb-map/blob/master/maps/contribution-map.md#a-map-that-guides-what-and-how-contributors-can-contribute) lists everything you can contribute.

- The [community repository](https://github.com/pingcap/community) contains everything else you need.

- Don&#039;t forget to claim your contribution swag by filling in and submitting this [form](https://forms.pingcap.com/f/tidb-contribution-swag).


&lt;a href=&quot;https://next.ossinsight.io/widgets/official/compose-recent-active-contributors?repo_id=41986369&amp;limit=30&quot; target=&quot;_blank&quot; style=&quot;display: block&quot; align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-recent-active-contributors/thumbnail.png?repo_id=41986369&amp;limit=30&amp;image_size=auto&amp;color_scheme=dark&quot; width=&quot;655&quot; height=&quot;auto&quot;&gt;
    &lt;img alt=&quot;Active Contributors of pingcap/tidb - Last 28 days&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-recent-active-contributors/thumbnail.png?repo_id=41986369&amp;limit=30&amp;image_size=auto&amp;color_scheme=light&quot; width=&quot;655&quot; height=&quot;auto&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;

## License

TiDB is under the Apache 2.0 license. See the [LICENSE](./LICENSE) file for details.

## See Also

- [TiDB Online Playground](https://play.tidbcloud.com/?utm_source=github&amp;utm_medium=tidb_readme)
- TiDB Case Studies: [TiDB Customers](https://www.pingcap.com/customers/?utm_source=github&amp;utm_medium=tidb), [TiDB ‰∫ã‰æãË®ò‰∫ã](https://pingcap.co.jp/case-study/?utm_source=github&amp;utm_medium=tidb), [TiDB ‰∏≠ÊñáÁî®Êà∑Ê°à‰æã](https://cn.pingcap.com/case/?utm_source=github&amp;utm_medium=tidb)
- [TiDB User Documentation](https://docs.pingcap.com/tidb/stable?utm_source=github&amp;utm_medium=tidb)
- [TiDB Design Docs](/docs/design)
- [TiDB Release Notes](https://docs.pingcap.com/tidb/dev/release-notes?utm_source=github&amp;utm_medium=tidb)
- [TiDB Blog](https://www.pingcap.com/blog/?utm_source=github&amp;utm_medium=tidb)
- [TiDB Roadmap](roadmap.md)

## Acknowledgments

- Thanks [cznic](https://github.com/cznic) for providing some great open source tools.
- Thanks [GolevelDB](https://github.com/syndtr/goleveldb), [BoltDB](https://github.com/boltdb/bolt), and [RocksDB](https://github.com/facebook/rocksdb) for their powerful storage engines.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[WuKongIM/WuKongIM]]></title>
            <link>https://github.com/WuKongIM/WuKongIM</link>
            <guid>https://github.com/WuKongIM/WuKongIM</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:42 GMT</pubDate>
            <description><![CDATA[More than just IM ‰∏çÂè™ÊòØÂç≥Êó∂ÈÄöËÆØ( IM )]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/WuKongIM/WuKongIM">WuKongIM/WuKongIM</a></h1>
            <p>More than just IM ‰∏çÂè™ÊòØÂç≥Êó∂ÈÄöËÆØ( IM )</p>
            <p>Language: Go</p>
            <p>Stars: 4,653</p>
            <p>Forks: 620</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>##  WuKongIM (Making Communication Simpler)

A high-performance universal communication service, refined over 10 years (2015-2025). Supports instant messaging, in-app/system notifications, messaging middleware, IoT communication, audio/video signaling, live streaming comments, customer service systems, AI communication, instant communities, and more.


`This project requires Go 1.20.0 or higher to compile`

`Windows is no longer supported`



Key Features of Distributed IM: Automatic failover, decentralized design, data redundancy between nodes, fast auto-scaling, proxy node mechanism

Technical Highlights: Custom protocol, Distributed Raft (modified pull mode), Multi-group Raft (modified pull mode), Relational database internals, Distributed database design, Reactors architecture, Innovative multi-layer distributed leadership mechanism, and more


[‰∏≠Êñá](./README_CN.md)

&lt;p align=&quot;center&quot;&gt;
&lt;img align=&quot;left&quot; height=&quot;160&quot; src=&quot;./docs/logo.png&quot;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Website&lt;/strong&gt;: https://githubim.com&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protocol 1&lt;/strong&gt;: &lt;a href=&quot;https://githubim.com/server/advance/proto.html&quot;&gt;WuKongIM Binary Protocol&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protocol 2&lt;/strong&gt;: &lt;a href=&quot;https://githubim.com/server/advance/jsonrpc.html&quot;&gt;WuKongIM JSON Protocol (WebSocket only)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: https://github.com/WuKongIM/WuKongIM/issues&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: https://githubim.com&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Architecture Docs&lt;/strong&gt;: https://deepwiki.com/WuKongIM/WuKongIM&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;

[![](https://img.shields.io/github/license/WuKongIM/WuKongIM?color=yellow&amp;style=flat-square)](./LICENSE)
[![](https://img.shields.io/badge/go-%3E%3D1.20-30dff3?style=flat-square&amp;logo=go)](https://github.com/WuKongIM/WuKongIM)
[![](https://img.shields.io/badge/go%20report-A+-brightgreen.svg?style=flat)](https://goreportcard.com/report/github.com/WuKongIM/WuKongIM)
&lt;a href=&quot;https://join.slack.com/t/wukongim/shared_invite/zt-22o7we8on-2iKNUmgigB9ERdF9XUivmw&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Slack-99%2B-blueviolet?logo=slack&amp;amp;logoColor=white&quot;&gt;&lt;/a&gt;

Architecture
--------

![Architecture](./docs/architecture_v2_en.svg)

![Cluster Architecture](./docs/architecture/cluster_v2_en.svg)


Video Demonstrations
--------


&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center;&quot;&gt;Failover Demo&lt;/th&gt;
      &lt;th style=&quot;text-align: center;&quot;&gt;AI Demo&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center;&quot;&gt;
        &lt;img src=&quot;./docs/architecture/cluster-failover.webp&quot; alt=&quot;Failover&quot;&gt;
      &lt;/td&gt;
      &lt;td style=&quot;text-align: center;&quot;&gt;
         &lt;img src=&quot;./docs/video/stream.webp&quot; alt=&quot;AI + Streaming&quot;&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;




Live Demo
--------

**Chat Demo**

Web chat demo: http://imdemo.githubim.com

Backend monitoring demo: http://monitor.githubim.com/web

Stress test report: https://githubim.com/server/advance/stressSingleReport.html


Highlights
--------

The only `decentralized` distributed IM in open source

The only IM capable of `200,000+` concurrent sends on a single machine in open source

The only IM with built-in self-developed distributed storage in open source

The only distributed IM that doesn&#039;t depend on any middleware in open source

Features
--------

üé¶ **Uniqueness**

No limit on group members, easily supports 100,000-member group chats, messages can be stored permanently.

üìö **Low Resource Consumption**

Self-developed binary protocol, heartbeat packets are only 1 byte, saves bandwidth and battery, faster transmission.

üîê **Security**

End-to-end encryption for message channels and content, prevents man-in-the-middle attacks and message tampering, real-time server data backup, no data loss.


üöÄ **Performance**

Built on PebbleDB KV database, we developed a specialized distributed database for IM services, eliminating performance overhead from generic databases. Fast storage means fast messaging.

üî• **High Availability**

Modified Raft distributed protocol enables automatic disaster recovery - when one machine goes down, another automatically takes over, seamless to users.

Decentralized, no single point of failure, no central node, every node is independent and equal, all can provide service.

Easy scaling, just add machines, no downtime needed, no data migration required, automatic data distribution by policy.

0‚É£Ô∏è **Ease of Use**

No dependency on any third-party middleware, simple deployment, start with a single command.

Channel-based publish/subscribe design philosophy, easy to understand, easy to get started.

Simple like Redis, high-performance like Kafka, reliable like MySQL

üå≤ **Technical Support**

Official team provides technical support, documentation, community discussion groups, and issue feedback.


Feature List
---------------


- [x] Custom message support
- [x] Subscribe/Publish pattern support
- [x] Personal/Group/Customer Service/Community channels
- [x] Channel blacklist support
- [x] Channel whitelist support
- [x] Permanent message roaming, no message loss when switching devices
- [x] Online status, multi-device online for same account
- [x] Real-time message sync across devices
- [x] Server-maintained recent conversation list
- [x] Command messages support
- [x] Offline command interface
- [x] Webhook support for easy business system integration
- [x] Datasource support for seamless business data integration
- [x] WebSocket connection support
- [x] TLS 1.3 support
- [x] Proxy protocol support
- [x] JSON protocol communication
- [x] Prometheus monitoring support
- [x] Monitoring system development
- [x] Streaming messages (like ChatGPT output stream)
- [x] Distributed support
    - [x] Decentralized design, cluster auto-repairs when any node goes down
    - [x] Data redundancy between cluster nodes, any node damage doesn&#039;t affect data integrity
    - [x] Fast automatic cluster scaling


Quick Start
---------------

```shell

git clone https://github.com/WuKongIM/WuKongIM.git

cd WuKongIM/docker/cluster

sudo docker compose up -d

```

Admin panel: http://127.0.0.1:15300/web

Chat demo: http://127.0.0.1:15172/login



Development
---------------

### Standalone

```shell


go run main.go

(or go run main.go --config config/wk.yaml)

```

### Distributed
    
```yaml

# Start first node
go run main.go --config  ./exampleconfig/cluster1.yaml

# Start second node
go run main.go --config  ./exampleconfig/cluster2.yaml

# Start third node
go run main.go --config  ./exampleconfig/cluster3.yaml

```


### Access

Admin panel: http://127.0.0.1:5300/web

Chat demo: http://127.0.0.1:5172/chatdemo

### Client Usage

```typescript
import { WKIM, WKIMChannelType, WKIMEvent } from &#039;easyjssdk&#039;;

// 1. Initialize
const im = WKIM.init(&quot;ws://your-wukongim-server.com:5200&quot;, {
    uid: &quot;your_user_id&quot;, // Current user&#039;s uid
    token: &quot;your_auth_token&quot; // Auth token (optional if auth is disabled)
});

// 2. Listen
im.on(WKIMEvent.Connect, () =&gt; {
    console.log(&quot;IM Connected!&quot;);
    // Send message
    const result = await im.send(&quot;target user&quot;,WKIMChannelType.Person,{ type: &quot;text&quot;, content: &quot;Hello from EasyJSSDK!&quot; })
});

// Listen for incoming messages
im.on(WKIMEvent.Message, (message) =&gt; {
    console.log(&quot;Received:&quot;, message);
});

// Listen for errors
im.on(WKIMEvent.Error, (error) =&gt; {
    console.error(&quot;IM Error:&quot;, error);
});

// 3. Connect
await im.connect()




```


Production Deployment
---------------

Please refer to the [Deployment Guide](https://githubim.com/install)




SDKs and Demos
---------------



| Project | Github | Example | Docs | Description |
| ---- | ---------- | --------- | ---- |  ---- |
|   WuKongIM   |   [Github](https://github.com/WuKongIM/WuKongIM)         |     N/A |  [Docs](https://githubim.com)  &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;       |    WuKongIM server, handles connections and message delivery |
|   WuKongIMAndroidSDK   |   [Github](https://github.com/WuKongIM/WuKongIMAndroidSDK)         |     [Example](https://github.com/WuKongIM/WuKongIMAndroidSDK/tree/master/app) | [Docs](https://githubim.com/sdk/android/intro.html)    |    WuKongIM Android SDK  |
|   WuKongIMiOSSDK   |   [Github](https://github.com/WuKongIM/WuKongIMiOSSDK)         |     [Example](https://github.com/WuKongIM/WuKongIMiOSSDK/tree/main/Example)  | [Docs](https://githubim.com/sdk/iossdk/intro.html)     |    WuKongIM iOS SDK  |
|   WuKongIMUniappSDK   |   [Github](https://github.com/WuKongIM/WuKongIMUniappSDK)         |     [Example](https://github.com/WuKongIM/WuKongIMUniappSDK/tree/main/examples)  | [Docs](https://githubim.com/sdk/uniapp.html)      |    WuKongIM Uniapp SDK  |
|   WuKongIMJSSDK   |   [Github](https://github.com/WuKongIM/WuKongIMJSSDK)         |     [Example](https://github.com/WuKongIM/WuKongIMJSSDK/tree/main/examples)   | [Docs](https://githubim.com/sdk/jssdk/intro.html)     |    WuKongIM JS SDK  |
|   WuKongIMFlutterSDK   |    [Github](https://github.com/WuKongIM/WuKongIMFlutterSDK)        |    [Example](https://github.com/WuKongIM/WuKongIMFlutterSDK/tree/master/example)   |[Docs](https://githubim.com/sdk/flutter/intro.html)    |    WuKongIM Flutter SDK |
|   WuKongIMReactNativeDemo   |   [Github](https://github.com/wengqianshan/WuKongIMReactNative)         |     N/A  |  N/A  |    WuKongIM React Native Demo (contributed by [wengqianshan](https://github.com/wengqianshan))  |
|   WuKongIMHarmonyOSSDK   |   [Github](https://github.com/WuKongIM/WuKongIMHarmonyOSSDK)         |     [Example](https://github.com/WuKongIM/WuKongIMHarmonyOSSDK/tree/main/entry)  |  [Docs](https://githubim.com/sdk/harmonyos/intro.html)   |   WuKongIM HarmonyOS SDK  |




Node Failover Demo
--------

![Node Failover Demo](./docs/architecture/cluster-failover.webp)


Screenshots
---------------


||||
|:---:|:---:|:--:|
|![](./docs/2.0-screen/screen-01.png)|![](./docs/2.0-screen/screen-02.png)|![](./docs/2.0-screen/screen-03.png)|
|![](./docs/2.0-screen/screen-04.png)|![](./docs/2.0-screen/screen-05.png)|![](./docs/2.0-screen/screen-06.png)|
|![](./docs/2.0-screen/screen-07.png)|![](./docs/2.0-screen/screen-08.png)|![](./docs/2.0-screen/screen-09.png)|
|![](./docs/2.0-screen/screen-10.png)|![](./docs/2.0-screen/screen-11.png)| ![](./docs/2.0-screen/screen-12.png) |
| ![](./docs/2.0-screen/screen-13.png) | ![](./docs/2.0-screen/screen-14.png) |

Star
---------------

Our team has been dedicated to instant messaging development. We need your encouragement! If you find this project helpful, please give us a star. Your support is our greatest motivation.

Case Study
---------------

**Project Name**

TangSengDaoDao

**Open Source**

https://github.com/TangSengDaoDao/TangSengDaoDaoServer

**Screenshots**

||||
|:---:|:---:|:--:|
|![](./docs/case/tsdaodao/screenshot/conversationlist.webp)|![](./docs/case/tsdaodao/screenshot/messages.webp)|![](./docs/case/tsdaodao/screenshot/robot.webp)|


|||          |
|:---:|:---:|:-------------------:|

![](./docs/case/tsdaodao/screenshot/pc11.png)




Contact
---------------

WeChat ID: wukongimgo (mention you want to join the group)

![image](./wechat.png)



License
---------------

WuKongIM is licensed under the [Apache License 2.0](./LICENSE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[dundee/gdu]]></title>
            <link>https://github.com/dundee/gdu</link>
            <guid>https://github.com/dundee/gdu</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:41 GMT</pubDate>
            <description><![CDATA[Fast disk usage analyzer with console interface written in Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dundee/gdu">dundee/gdu</a></h1>
            <p>Fast disk usage analyzer with console interface written in Go</p>
            <p>Language: Go</p>
            <p>Stars: 5,169</p>
            <p>Forks: 186</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># go DiskUsage()

&lt;img src=&quot;./gdu.png&quot; alt=&quot;Gdu &quot; width=&quot;200&quot; align=&quot;right&quot;&gt;

[![Codecov](https://codecov.io/gh/dundee/gdu/branch/master/graph/badge.svg)](https://codecov.io/gh/dundee/gdu)
[![Go Report Card](https://goreportcard.com/badge/github.com/dundee/gdu)](https://goreportcard.com/report/github.com/dundee/gdu)
[![Maintainability](https://api.codeclimate.com/v1/badges/30d793274607f599e658/maintainability)](https://codeclimate.com/github/dundee/gdu/maintainability)
[![CodeScene Code Health](https://codescene.io/projects/13129/status-badges/code-health)](https://codescene.io/projects/13129)

Pretty fast disk usage analyzer written in Go.

Gdu is intended primarily for SSD disks where it can fully utilize parallel processing.
However HDDs work as well, but the performance gain is not so huge.

[![asciicast](https://asciinema.org/a/382738.svg)](https://asciinema.org/a/382738)

&lt;a href=&quot;https://repology.org/project/gdu/versions&quot;&gt;
    &lt;img src=&quot;https://repology.org/badge/vertical-allrepos/gdu.svg&quot; alt=&quot;Packaging status&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

## Installation

Head for the [releases page](https://github.com/dundee/gdu/releases) and download the binary for your system.

Using curl:

    curl -L https://github.com/dundee/gdu/releases/latest/download/gdu_linux_amd64.tgz | tar xz
    chmod +x gdu_linux_amd64
    mv gdu_linux_amd64 /usr/bin/gdu

See the [installation page](./INSTALL.md) for other ways how to install Gdu to your system.

Or you can use Gdu directly via Docker:

    docker run --rm --init --interactive --tty --privileged --volume /:/mnt/root ghcr.io/dundee/gdu /mnt/root

## Usage

```
  gdu [directory_to_scan] [flags]

Flags:
      --config-file string            Read config from file (default is $HOME/.gdu.yaml)
  -g, --const-gc                      Enable memory garbage collection during analysis with constant level set by GOGC
      --enable-profiling              Enable collection of profiling data and provide it on http://localhost:6060/debug/pprof/
  -L, --follow-symlinks               Follow symlinks for files, i.e. show the size of the file to which symlink points to (symlinks to directories are not followed)
  -h, --help                          help for gdu
  -i, --ignore-dirs strings           Paths to ignore (separated by comma). Can be absolute or relative to current directory (default [/proc,/dev,/sys,/run])
  -I, --ignore-dirs-pattern strings   Path patterns to ignore (separated by comma)
  -X, --ignore-from string            Read path patterns to ignore from file
  -f, --input-file string             Import analysis from JSON file
  -l, --log-file string               Path to a logfile (default &quot;/dev/null&quot;)
  -m, --max-cores int                 Set max cores that Gdu will use
      --mouse                         Use mouse
  -c, --no-color                      Do not use colorized output
  -x, --no-cross                      Do not cross filesystem boundaries
      --no-delete                     Do not allow deletions
  -H, --no-hidden                     Ignore hidden directories (beginning with dot)
      --no-prefix                     Show sizes as raw numbers without any prefixes (SI or binary) in non-interactive mode
  -p, --no-progress                   Do not show progress in non-interactive mode
      --no-spawn-shell                Do not allow spawning shell
  -u, --no-unicode                    Do not use Unicode symbols (for size bar)
  -n, --non-interactive               Do not run in interactive mode
  -o, --output-file string            Export all info into file as JSON
  -r, --read-from-storage             Read analysis data from persistent key-value storage
      --reverse-sort                  Reverse sorting order (smallest to largest) in non-interactive mode
      --sequential                    Use sequential scanning (intended for rotating HDDs)
  -A, --show-annexed-size             Use apparent size of git-annex&#039;ed files in case files are not present locally (real usage is zero)
  -a, --show-apparent-size            Show apparent size
  -d, --show-disks                    Show all mounted disks
  -C, --show-item-count               Show number of items in directory
  -M, --show-mtime                    Show latest mtime of items in directory
  -B, --show-relative-size            Show relative size
      --si                            Show sizes with decimal SI prefixes (kB, MB, GB) instead of binary prefixes (KiB, MiB, GiB)
      --storage-path string           Path to persistent key-value storage directory (default &quot;/tmp/badger&quot;)
  -s, --summarize                     Show only a total in non-interactive mode
  -t, --top int                       Show only top X largest files in non-interactive mode
      --use-storage                   Use persistent key-value storage for analysis data (experimental)
  -v, --version                       Print version
      --write-config                  Write current configuration to file (default is $HOME/.gdu.yaml)

Basic list of actions in interactive mode (show help modal for more):
  ‚Üë or k                              Move cursor up
  ‚Üì or j                              Move cursor down
  ‚Üí or Enter or l                     Go to highlighted directory
  ‚Üê or h                              Go to parent directory
  d                                   Delete the selected file or directory
  e                                   Empty the selected directory
  n                                   Sort by name
  s                                   Sort by size
  c                                   Show number of items in directory
  ?                                   Show help modal
```

## Examples

    gdu                                   # analyze current dir
    gdu -a                                # show apparent size instead of disk usage
    gdu --no-delete                       # prevent write operations
    gdu &lt;some_dir_to_analyze&gt;             # analyze given dir
    gdu -d                                # show all mounted disks
    gdu -l ./gdu.log &lt;some_dir&gt;           # write errors to log file
    gdu -i /sys,/proc /                   # ignore some paths
    gdu -I &#039;.*[abc]+&#039;                     # ignore paths by regular pattern
    gdu -X ignore_file /                  # ignore paths by regular patterns from file
    gdu -c /                              # use only white/gray/black colors

    gdu -n /                              # only print stats, do not start interactive mode
    gdu -p /                              # do not show progress, useful when using its output in a script
    gdu -ps /some/dir                     # show only total usage for given dir
    gdu -t 10 /                           # show top 10 largest files
    gdu --reverse-sort -n /               # show files sorted from smallest to largest in non-interactive mode
    gdu / &gt; file                          # write stats to file, do not start interactive mode

    gdu -o- / | gzip -c &gt;report.json.gz   # write all info to JSON file for later analysis
    zcat report.json.gz | gdu -f-         # read analysis from file

    GOGC=10 gdu -g --use-storage /        # use persistent key-value storage for saving analysis data
    gdu -r /                              # read saved analysis data from persistent key-value storage

## Modes

Gdu has three modes: interactive (default), non-interactive and export.

Non-interactive mode is started automatically when TTY is not detected (using [go-isatty](https://github.com/mattn/go-isatty)), for example if the output is being piped to a file, or it can be started explicitly by using a flag.

Export mode (flag `-o`) outputs all usage data as JSON, which can be later opened using the `-f` flag.

Hard links are counted only once.

## File flags

Files and directories may be prefixed by a one-character
flag with following meaning:

* `!` An error occurred while reading this directory.

* `.` An error occurred while reading a subdirectory, size may be not correct.

* `@` File is symlink or socket.

* `H` Same file was already counted (hard link).

* `e` Directory is empty.

## Configuration file

Gdu can read (and write) YAML configuration file.

`$HOME/.config/gdu/gdu.yaml` and `$HOME/.gdu.yaml` are checked for the presence of the config file by default.

See the [full list of all configuration options](configuration.md).

### Examples

* To configure gdu to permanently run in gray-scale color mode:

```
echo &quot;no-color: true&quot; &gt;&gt; ~/.gdu.yaml
```

* To set default sorting in configuration file:

```
sorting:
    by: name // size, name, itemCount, mtime
    order: desc
```

* To configure gdu to set CWD variable when browsing directories:

```
echo &quot;change-cwd: true&quot; &gt;&gt; ~/.gdu.yaml
```

* To save the current configuration

```
gdu --write-config
```

## Styling

There are wide options for how terminals can be colored.
Some gdu primitives (like basic text) adapt to different color schemas, but the selected/highlighted row does not.

If the default look is not sufficient, it can be changed in configuration file, e.g.:

```
style:
    selected-row:
        text-color: black
        background-color: &quot;#ff0000&quot;
```

## Deletion in background and in parallel (experimental)

Gdu can delete items in the background, thus not blocking the UI for additional work.
To enable:

```
echo &quot;delete-in-background: true&quot; &gt;&gt; ~/.gdu.yaml
```

Directory items can be also deleted in parallel, which might increase the speed of deletion.
To enable:

```
echo &quot;delete-in-parallel: true&quot; &gt;&gt; ~/.gdu.yaml
```

## Memory usage

### Automatic balancing

Gdu tries to balance performance and memory usage.

When less memory is used by gdu than the total free memory of the host,
then Garbage Collection is disabled during the analysis phase completely to gain maximum speed.

Otherwise GC is enabled.
The more memory is used and the less memory is free, the more often will the GC happen.

### Manual memory usage control

If you want manual control over Garbage Collection, you can use `--const-gc` / `-g` flag.
It will run Garbage Collection during the analysis phase with constant level of aggressiveness.
As a result, the analysis will be about 25% slower and will consume about 30% less memory.
To change the level, you can set the `GOGC` environment variable to specify how often the garbage collection will happen.
Lower value (than 100) means GC will run more often. Higher means less often. Negative number will stop GC.

Example running gdu with constant GC, but not so aggressive as default:

```
GOGC=200 gdu -g /
```

## Saving analysis data to persistent key-value storage (experimental)

Gdu can store the analysis data to persistent key-value storage instead of just memory.
Gdu will run much slower (approx 10x) but it should use much less memory (when using small GOGC as well).
Gdu can also reopen with the saved data.
Currently only BadgerDB is supported as the key-value storage (embedded).

```
GOGC=10 gdu -g --use-storage /    # saves analysis data to key-value storage
gdu -r /                          # reads just saved data, does not run analysis again
```

## Running tests

    make install-dev-dependencies
    make test

## Profiling

Gdu can collect profiling data when the `--enable-profiling` flag is set.
The data are provided via embedded http server on URL `http://localhost:6060/debug/pprof/`.

You can then use e.g. `go tool pprof -web http://localhost:6060/debug/pprof/heap`
to open the heap profile as SVG image in your web browser.

## Benchmarks

Benchmarks were performed on 50G directory (100k directories, 400k files) on 500 GB SSD using [hyperfine](https://github.com/sharkdp/hyperfine).
See `benchmark` target in [Makefile](Makefile) for more info.

### Cold cache

Filesystem cache was cleared using `sync; echo 3 | sudo tee /proc/sys/vm/drop_caches`.

| Command | Mean [s] | Min [s] | Max [s] | Relative |
|:---|---:|---:|---:|---:|
| `diskus ~` | 3.074 ¬± 0.010 | 3.056 | 3.094 | 1.00 |
| `gdu -npc ~` | 3.133 ¬± 0.013 | 3.116 | 3.159 | 1.02 ¬± 0.01 |
| `gdu -gnpc ~` | 3.157 ¬± 0.013 | 3.139 | 3.180 | 1.03 ¬± 0.01 |
| `pdu ~` | 3.772 ¬± 0.149 | 3.630 | 4.071 | 1.23 ¬± 0.05 |
| `dust -d0 ~` | 4.001 ¬± 0.162 | 3.786 | 4.305 | 1.30 ¬± 0.05 |
| `dua ~` | 5.315 ¬± 3.210 | 4.068 | 14.447 | 1.73 ¬± 1.04 |
| `gdu -npc --use-storage ~` | 12.690 ¬± 0.527 | 11.325 | 13.091 | 4.13 ¬± 0.17 |
| `du -hs ~` | 14.940 ¬± 0.064 | 14.852 | 15.048 | 4.86 ¬± 0.03 |
| `duc index ~` | 15.501 ¬± 0.136 | 15.386 | 15.849 | 5.04 ¬± 0.05 |
| `ncdu -0 -o /dev/null ~` | 15.688 ¬± 0.053 | 15.610 | 15.789 | 5.10 ¬± 0.02 |

### Warm cache

| Command | Mean [ms] | Min [ms] | Max [ms] | Relative |
|:---|---:|---:|---:|---:|
| `diskus ~` | 211.4 ¬± 3.7 | 206.4 | 219.3 | 1.00 |
| `pdu ~` | 221.8 ¬± 2.4 | 219.3 | 226.3 | 1.05 ¬± 0.02 |
| `dust -d0 ~` | 363.6 ¬± 5.4 | 357.3 | 373.2 | 1.72 ¬± 0.04 |
| `gdu -npc ~` | 434.3 ¬± 3.4 | 426.0 | 437.8 | 2.05 ¬± 0.04 |
| `dua ~` | 451.2 ¬± 4.2 | 444.9 | 457.9 | 2.13 ¬± 0.04 |
| `gdu -gnpc ~` | 521.0 ¬± 14.0 | 510.9 | 558.5 | 2.46 ¬± 0.08 |
| `du -hs ~` | 809.4 ¬± 3.2 | 804.8 | 816.0 | 3.83 ¬± 0.07 |
| `duc index ~` | 952.3 ¬± 4.8 | 946.0 | 961.7 | 4.50 ¬± 0.08 |
| `ncdu -0 -o /dev/null ~` | 1432.8 ¬± 3.4 | 1428.0 | 1439.0 | 6.78 ¬± 0.12 |
| `gdu -npc --use-storage ~` | 9950.0 ¬± 474.1 | 9117.5 | 10647.4 | 47.07 ¬± 2.39 |

## Alternatives

* [ncdu](https://dev.yorhel.nl/ncdu) - NCurses based tool written in pure `C` (LTS) or `zig` (Stable)
* [godu](https://github.com/viktomas/godu) - Analyzer with a carousel like user interface
* [dua](https://github.com/Byron/dua-cli) - Tool written in `Rust` with interface similar to gdu (and ncdu)
* [diskus](https://github.com/sharkdp/diskus) - Very simple but very fast tool written in `Rust`
* [duc](https://duc.zevv.nl/) - Collection of tools with many possibilities for inspecting and visualising disk usage
* [dust](https://github.com/bootandy/dust) - Tool written in `Rust` showing tree like structures of disk usage
* [pdu](https://github.com/KSXGitHub/parallel-disk-usage) - Tool written in `Rust` showing tree like structures of disk usage

## Notes

[HDD icon created by Nikita Golubev - Flaticon](https://www.flaticon.com/free-icons/hdd)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[docker/cagent]]></title>
            <link>https://github.com/docker/cagent</link>
            <guid>https://github.com/docker/cagent</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:40 GMT</pubDate>
            <description><![CDATA[Agent Builder and Runtime by Docker Engineering]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/docker/cagent">docker/cagent</a></h1>
            <p>Agent Builder and Runtime by Docker Engineering</p>
            <p>Language: Go</p>
            <p>Stars: 1,794</p>
            <p>Forks: 205</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># ü§ñ `cagent` ü§ñ

&gt; A powerful, easy-to-use, customizable multi-agent runtime that orchestrates AI
&gt; agents with specialized capabilities and tools, and the interactions between
&gt; agents.

![cagent in action](docs/demo.gif)

## ‚ú® What is `cagent`? ‚ú®

`cagent` lets you create and run intelligent AI agents, where each agent has
specialized knowledge, tools and capabilities.

Think of it as allowing you to quickly build, share and run a team of virtual
experts that collaborate to solve complex problems for you.

And it&#039;s dead easy to use!

‚ö†Ô∏è Note: `cagent` is in active development, **breaking changes are to be
expected** ‚ö†Ô∏è

### Your First Agent

Example [basic_agent.yaml](/examples/basic_agent.yaml):

Creating agents with cagent is straightforward. They are described in a short .yaml
file, like this one:

```yaml
agents:
  root:
    model: openai/gpt-5-mini
    description: A helpful AI assistant
    instruction: |
      You are a knowledgeable assistant that helps users with various tasks.
      Be helpful, accurate, and concise in your responses.
```

Run it in a terminal with `cagent run basic_agent.yaml`.

Many more examples can be found [here](/examples/README.md)!

### Improving an agent with MCP tools

`cagent` supports MCP servers, enabling agents to use a wide variety of external
tools and services.

It supports three transport types: `stdio`, `http` and `sse`.

Giving an agent access to tools via MCP is a quick way to greatly improve its
capabilities, the quality of its results and its general usefulness.

Get started quickly with the [Docker MCP
Toolkit](https://docs.docker.com/ai/mcp-catalog-and-toolkit/toolkit/) and
[catalog](https://docs.docker.com/ai/mcp-catalog-and-toolkit/catalog/)

Here, we&#039;re giving the same basic agent from the example above access to a
**containerized** `duckduckgo` mcp server and its tools by using Docker&#039;s MCP
Gateway:

```yaml
agents:
  root:
    model: openai/gpt-5-mini
    description: A helpful AI assistant
    instruction: |
      You are a knowledgeable assistant that helps users with various tasks.
      Be helpful, accurate, and concise in your responses.
    toolsets:
      - type: mcp
        ref: docker:duckduckgo # stdio transport
```

When using a containerized server via the Docker MCP gateway, you can configure
any required settings/secrets/authentication using the [Docker MCP
Toolkit](https://docs.docker.com/ai/mcp-catalog-and-toolkit/toolkit/#example-use-the-github-official-mcp-server)
in Docker Desktop.

Aside from the containerized MCP servers the Docker MCP Gateway provides, any
standard MCP server can be used with cagent!

Here&#039;s an example similar to the above but adding `read_file` and `write_file`
tools from the `rust-mcp-filesystem` MCP server:

```yaml
agents:
  root:
    model: openai/gpt-5-mini
    description: A helpful AI assistant
    instruction: |
      You are a knowledgeable assistant that helps users with various tasks.
      Be helpful, accurate, and concise in your responses. Write your search results to disk.
    toolsets:
      - type: mcp
        ref: docker:duckduckgo
      - type: mcp
        command: rust-mcp-filesystem # installed with `cargo install rust-mcp-filesystem`
        args: [&quot;--allow-write&quot;, &quot;.&quot;]
        tools: [&quot;read_file&quot;, &quot;write_file&quot;] # Optional: specific tools only
        env:
          - &quot;RUST_LOG=debug&quot;
```

See [the USAGE docs](./docs/USAGE.md#tool-configuration) for more detailed
information and examples

### Exposing agents as MCP tools

`cagent` can expose agents as MCP tools via the `cagent mcp` command, allowing other MCP clients to use your agents.

Each agent in your configuration becomes an MCP tool with its description.

```bash
# Start MCP server with local file
cagent mcp ./examples/dev-team.yaml

# Or use an OCI artifact
cagent mcp agentcatalog/pirate
```

This exposes each agent as a tool (e.g., `root`, `designer`, `awesome_engineer`) that MCP clients can call:

```json
{
  &quot;method&quot;: &quot;tools/call&quot;,
  &quot;params&quot;: {
    &quot;name&quot;: &quot;designer&quot;,
    &quot;arguments&quot;: {
      &quot;message&quot;: &quot;Design a login page&quot;
    }
  }
}
```

See [MCP Mode documentation](./docs/MCP-MODE.md) for detailed instructions on exposing your agents through MCP with Claude Desktop, Claude Code, and other MCP clients.

### üéØ Key Features

- **üèóÔ∏è Multi-agent architecture** - Create specialized agents for different
  domains.
- **üîß Rich tool ecosystem** - Agents can use external tools and APIs via the
  MCP protocol.
- **üîÑ Smart delegation** - Agents can automatically route tasks to the most
  suitable specialist.
- **üìù YAML configuration** - Declarative model and agent configuration.
- **üí≠ Advanced reasoning** - Built-in &quot;think&quot;, &quot;todo&quot; and &quot;memory&quot; tools for
  complex problem-solving.
- **üîç RAG (Retrieval-Augmented Generation)** - Pluggable retrieval strategies
  (BM25, chunked-embeddings, semantic-embeddings) with hybrid retrieval, result fusion and reranking support.
- **üåê Multiple AI providers** - Support for OpenAI, Anthropic, Gemini, xAI,
  Mistral, Nebius and [Docker Model
  Runner](https://docs.docker.com/ai/model-runner/).

## üöÄ Quick Start üöÄ

### Installation

#### Using Homebrew

Install `cagent` with a single command using [homebrew](https://brew.sh/)!

```sh
$ brew install cagent
```

#### Using binary releases

[Prebuilt binaries](https://github.com/docker/cagent/releases) for Windows,
macOS and Linux can be found on the release page of the [project&#039;s GitHub
repository](https://github.com/docker/cagent/releases)

Once you&#039;ve downloaded the appropriate binary for your platform, you may need to
give it executable permissions. On macOS and Linux, this is done with the
following command:

```sh
# linux amd64 build example
chmod +x /path/to/downloads/cagent-linux-amd64
```

You can then rename the binary to `cagent` and configure your `PATH` to be able
to find it (configuration varies by platform).

### **Set your API keys**

Based on the models you configure your agents to use, you will need to set the
corresponding provider API key accordingly, all these keys are optional, you
will likely need at least one of these, though:

```bash
# For OpenAI models
export OPENAI_API_KEY=your_api_key_here

# For Anthropic models
export ANTHROPIC_API_KEY=your_api_key_here

# For Gemini models
export GOOGLE_API_KEY=your_api_key_here

# For xAI models
export XAI_API_KEY=your_api_key_here

# For Nebius models
export NEBIUS_API_KEY=your_api_key_here

# For Mistral models
export MISTRAL_API_KEY=your_api_key_here
```

### Run Agents!

```bash
# Run an agent!
cagent run ./examples/pirate.yaml

# or specify a different starting agent from the config, useful for agent teams
cagent run ./examples/pirate.yaml -a root

# or run directly from an image reference here I&#039;m pulling the pirate agent from the creek repository
cagent run creek/pirate
```

### Multi-agent team example

```yaml
agents:
  root:
    model: claude
    description: &quot;Main coordinator agent that delegates tasks and manages workflow&quot;
    instruction: |
      You are the root coordinator agent. Your job is to:
      1. Understand user requests and break them down into manageable tasks
      2. Delegate appropriate tasks to your helper agent
      3. Coordinate responses and ensure tasks are completed properly
      4. Provide final responses to the user
      When you receive a request, analyze what needs to be done and decide whether to:
      - Handle it yourself if it&#039;s simple
      - Delegate to the helper agent if it requires specific assistance
      - Break complex requests into multiple sub-tasks
    sub_agents: [&quot;helper&quot;]

  helper:
    model: claude
    description: &quot;Assistant agent that helps with various tasks as directed by the root agent&quot;
    instruction: |
      You are a helpful assistant agent. Your role is to:
      1. Complete specific tasks assigned by the root agent
      2. Provide detailed and accurate responses
      3. Ask for clarification if tasks are unclear
      4. Report back to the root agent with your results

      Focus on being thorough and helpful in whatever task you&#039;re given.

models:
  claude:
    provider: anthropic
    model: claude-sonnet-4-0
    max_tokens: 64000
```

You&#039;ll find a curated list of agents examples, spread into 3 categories,
[Basic](https://github.com/docker/cagent/tree/main/examples#basic-configurations),
[Advanced](https://github.com/docker/cagent/tree/main/examples#advanced-configurations)
and
[multi-agents](https://github.com/docker/cagent/tree/main/examples#multi-agent-configurations)
in the `/examples/` directory.

### DMR (Docker Model Runner) provider options

When using the `dmr` provider, you can use the `provider_opts` key for DMR
runtime-specific (e.g. llama.cpp/vllm) options and speculative decoding:

```yaml
models:
  local-qwen:
    provider: dmr
    model: ai/qwen3
    max_tokens: 8192
    provider_opts:
      # general flags passed to the underlying model runtime
      runtime_flags: [&quot;--ngl=33&quot;, &quot;--repeat-penalty=1.2&quot;, ...] # or comma/space-separated string
      # speculative decoding for faster inference
      speculative_draft_model: ai/qwen3:1B
      speculative_num_tokens: 5
      speculative_acceptance_rate: 0.8
```

The default base_url `cagent` will use for DMR providers is
`http://localhost:12434/engines/llama.cpp/v1`. DMR itself might need to be
enabled via [Docker Desktop&#039;s
settings](https://docs.docker.com/ai/model-runner/get-started/#enable-dmr-in-docker-desktop)
on macOS and Windows, and via the command-line on [Docker CE on
Linux](https://docs.docker.com/ai/model-runner/get-started/#enable-dmr-in-docker-engine).

See the [DMR Provider documentation](docs/USAGE.md#dmr-docker-model-runner-provider-usage) for more details on runtime flags and speculative decoding options.

## RAG (Retrieval-Augmented Generation)

Give your agents access to your documents with cagent&#039;s modular RAG system. It supports multiple retrieval strategies that can be used individually or combined for hybrid search.

### Quick RAG Example

```yaml
models:
  embedder:
    provider: openai
    model: text-embedding-3-small

rag:
  my_knowledge_base:
    docs: [./documents, ./pdfs]
    strategies:
      - type: chunked-embeddings
        model: embedder
        threshold: 0.5
        chunking:
          size: 1000
          overlap: 100
    results:
      limit: 5

agents:
  root:
    model: openai/gpt-4o
    instruction: |
      You are an assistant with access to an internal knowledge base.
      Use the knowledge base to gather context before answering user questions
    rag: [my_knowledge_base]
```

### Hybrid Retrieval (Chunked-Embeddings + BM25)

Combine semantic search (chunked-embeddings) with keyword search (BM25) for best results:

```yaml
rag:
  hybrid_search:
    docs: [./shared_docs]
    
    strategies:
      - type: chunked-embeddings
        model: embedder
        threshold: 0.5
        limit: 20
        chunking:
          size: 1000
          overlap: 100
      
      - type: bm25
        k1: 1.5
        b: 0.75
        threshold: 0.3
        limit: 15
        chunking:
          size: 1000
          overlap: 100
    
    results:
      fusion:
        strategy: rrf  # Reciprocal Rank Fusion
        k: 60
      deduplicate: true
      limit: 5

agents:
  root:
    model: openai/gpt-4o
    rag: [hybrid_search]
```

**Features:**
- **Multiple strategies**: Vector embeddings, semantic embeddings, BM25 (keyword), or combinations
- **Parallel execution**: Strategies run concurrently for fast results
- **Pluggable fusion**: RRF, weighted, or max score combining
- **Result reranking**: Re-score results with specialized models for improved relevance
- **Per-strategy configuration**: Different thresholds, limits, and documents
- **Auto file watching**: Reindex automatically on file changes

### Result Reranking

Improve search quality by re-scoring retrieved results with a reranking model:

```yaml
rag:
  knowledge_base:
    docs: [./documents]
    strategies:
      - type: chunked-embeddings
        model: openai/text-embedding-3-small
        limit: 20  # Retrieve more candidates for reranking
    
    results:
      reranking:
        model: openai/gpt-4.1-mini   # Any chat model or DMR reranker
        top_k: 10                   # Only rerank top 10 (optional)
        threshold: 0.3              # Filter low-scoring results (optional)
        criteria: |                 # Domain-specific relevance guidance (optional, not used with DMR reranking specific models)
          Prioritize recent documentation and practical examples.
          Documents from official sources are more relevant.
      limit: 5  # Final top results after reranking
```

**Supported providers:** DMR (native `/rerank` endpoint), OpenAI, Anthropic, Gemini (via structured outputs)  
**Note:** Temperature defaults to 0.0 for more deterministic scoring when not explicitly set.

See the [RAG documentation in USAGE.md](docs/USAGE.md#rag-configuration) for complete details, examples, and debugging guides.

## Quickly generate agents and agent teams with `cagent new`

Using the command `cagent new` you can quickly generate agents or multi-agent
teams using a single prompt!  
`cagent` has a built-in agent dedicated to this task.

To use the feature, you must have an Anthropic, OpenAI or Google API key
available in your environment or specify a local model to run with DMR (Docker
Model Runner).

You can choose what provider and model gets used by passing the `--model
provider/modelname` flag to `cagent new`

If `--model` is unspecified, `cagent new` will automatically choose between
these three providers in order based on the first api key it finds in your
environment.

```sh
export ANTHROPIC_API_KEY=your_api_key_here  # first choice. default model claude-sonnet-4-0
export OPENAI_API_KEY=your_api_key_here     # if anthropic key not set. default model gpt-5-mini
export GOOGLE_API_KEY=your_api_key_here     # if anthropic and openai keys are not set. default model gemini-2.5-flash
```

`--max-tokens` can be specified to override the context limit used.  
When using DMR, the default is 16k to limit memory usage. With all other
providers the default is 64k

`--max-iterations` can be specified to override how many times the agent is
allowed to loop when doing tool calling etc. When using DMR, the default is set
to 20 (small local models have the highest chance of getting confused and
looping endlessly). For all other providers, the default is 0 (unlimited).

Example of provider, model, context size and max iterations overriding:

```sh
# Use GPT-5 via OpenAI
cagent new --model openai/gpt-5

# Use a local model (ai/gemma3-qat:12B) via DMR
cagent new --model dmr/ai/gemma3-qat:12B

# Override the max_tokens used during generation, default is 64k, 16k when using the dmr provider
cagent new --model openai/gpt-5-mini --max-tokens 32000

# Override max_iterations to limit how much the model can loop autonomously when tool calling
cagent new --model dmr/ai/gemma3n:2B-F16 --max-iterations 15
```

---

```
$ cagent new

------- Welcome to cagent! -------
(Ctrl+C to stop the agent and exit)

What should your agent/agent team do? (describe its purpose):

&gt; I need an agent team that connects to &lt;some-service&gt; and does...
```

## Pushing and pulling agents from Docker Hub

### `cagent push`

Agent configurations can be packaged and shared to Docker Hub using the `cagent
push` command

```sh
cagent push ./&lt;agent-file&gt;.yaml namespace/reponame
```

`cagent` will automatically build an OCI image and push it to the desired
repository using your Docker credentials

### `cagent pull`

Pulling agents from Docker Hub is also just one `cagent pull` command away.

```sh
cagent pull creek/pirate
```

`cagent` will pull the image, extract the .yaml file and place it in your working
directory for ease of use.

`cagent run creek.yaml` will run your newly pulled agent

## Usage

More details on the usage and configuration of `cagent` can be found in
[USAGE.md](/docs/USAGE.md)

## Telemetry

We track anonymous usage data to improve the tool. See
[TELEMETRY.md](/docs/TELEMETRY.md) for details.

## Contributing

Want to hack on `cagent`, or help us fix bugs and build out some features? üîß

Read the information on how to build from source and contribute to the project
in [CONTRIBUTING.md](/docs/CONTRIBUTING.md)

## DogFooding: using `cagent` to code on `cagent`

A smart way to improve `cagent`&#039;s codebase and feature set is to do it with the
help of a `cagent` agent!

We have one that we use and that you should use too:

```sh
cd cagent
cagent run ./golang_developer.yaml
```

This agent is an _expert Golang developer specializing in the cagent multi-agent
AI system architecture_.

Ask it anything about `cagent`. It can be questions about the current code or
about improvements to the code. It can also fix issues and implement new
features!

## Share your feedback

We‚Äôd love to hear your thoughts on this project. You can find us on
[Slack](https://dockercommunity.slack.com/archives/C09DASHHRU4)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[aquasecurity/trivy]]></title>
            <link>https://github.com/aquasecurity/trivy</link>
            <guid>https://github.com/aquasecurity/trivy</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:39 GMT</pubDate>
            <description><![CDATA[Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aquasecurity/trivy">aquasecurity/trivy</a></h1>
            <p>Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more</p>
            <p>Language: Go</p>
            <p>Stars: 30,753</p>
            <p>Forks: 2,862</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;docs/imgs/logo.png&quot; width=&quot;200&quot;&gt;

[![GitHub Release][release-img]][release]
[![Test][test-img]][test]
[![Go Report Card][go-report-img]][go-report]
[![License: Apache-2.0][license-img]][license]
[![GitHub Downloads][github-downloads-img]][release]
![Docker Pulls][docker-pulls]

[üìñ Documentation][docs]
&lt;/div&gt;

Trivy ([pronunciation][pronunciation]) is a comprehensive and versatile security scanner.
Trivy has *scanners* that look for security issues, and *targets* where it can find those issues.

Targets (what Trivy can scan):

- Container Image
- Filesystem
- Git Repository (remote)
- Virtual Machine Image
- Kubernetes

Scanners (what Trivy can find there):

- OS packages and software dependencies in use (SBOM)
- Known vulnerabilities (CVEs)
- IaC issues and misconfigurations
- Sensitive information and secrets
- Software licenses

Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the [Scanning Coverage] page.

To learn more, go to the [Trivy homepage][homepage] for feature highlights, or to the [Documentation site][docs] for detailed information.

## Quick Start

### Get Trivy

Trivy is available in most common distribution channels. The full list of installation options is available in the [Installation] page. Here are a few popular examples:

- `brew install trivy`
- `docker run aquasec/trivy`
- Download binary from &lt;https://github.com/aquasecurity/trivy/releases/latest/&gt;
- See [Installation] for more

Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the [Ecosystem] page. Here are a few popular examples:

- [GitHub Actions](https://github.com/aquasecurity/trivy-action)
- [Kubernetes operator](https://github.com/aquasecurity/trivy-operator)
- [VS Code plugin](https://github.com/aquasecurity/trivy-vscode-extension)
- See [Ecosystem] for more

### Canary builds
There are canary builds ([Docker Hub](https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;name=canary), [GitHub](https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary), [ECR](https://gallery.ecr.aws/aquasecurity/trivy#canary) images and [binaries](https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml)) generated with every push to the main branch.

Please be aware: canary builds might have critical bugs, so they are not recommended for use in production.

### General usage

```bash
trivy &lt;target&gt; [--scanners &lt;scanner1,scanner2&gt;] &lt;subject&gt;
```

Examples:

```bash
trivy image python:3.4-alpine
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov

&lt;/details&gt;

```bash
trivy fs --scanners vuln,secret,misconfig myproject/
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov

&lt;/details&gt;

```bash
trivy k8s --report summary cluster
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

![k8s summary](docs/imgs/trivy-k8s.png)

&lt;/details&gt;

## FAQ

### How to pronounce the name &quot;Trivy&quot;?

`tri` is pronounced like **tri**gger, `vy` is pronounced like en**vy**.

## Want more? Check out Aqua

If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.  
You can find a high level comparison table specific to Trivy users [here](https://trivy.dev/docs/latest/commercial/compare/).
In addition check out the &lt;https://aquasec.com&gt; website for more information about our products and services.
If you&#039;d like to contact Aqua or request a demo, please use this form: &lt;https://www.aquasec.com/demo&gt;

## Community

Trivy is an [Aqua Security][aquasec] open source project.  
Learn about our open source work and portfolio [here][oss].  
Contact us about any matter by opening a GitHub Discussion [here][discussions]

Please ensure to abide by our [Code of Conduct][code-of-conduct] during all interactions.

[test]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml
[test-img]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg
[go-report]: https://goreportcard.com/report/github.com/aquasecurity/trivy
[go-report-img]: https://goreportcard.com/badge/github.com/aquasecurity/trivy
[release]: https://github.com/aquasecurity/trivy/releases
[release-img]: https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github
[github-downloads-img]: https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github
[docker-pulls]: https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;label=docker%20pulls%20%2F%20trivy
[license]: https://github.com/aquasecurity/trivy/blob/main/LICENSE
[license-img]: https://img.shields.io/badge/License-Apache%202.0-blue.svg
[homepage]: https://trivy.dev
[docs]: https://trivy.dev/docs/latest/
[pronunciation]: #how-to-pronounce-the-name-trivy
[code-of-conduct]: https://github.com/aquasecurity/community/blob/main/CODE_OF_CONDUCT.md

[Installation]:https://trivy.dev/docs/latest/getting-started/installation/
[Ecosystem]: https://trivy.dev/docs/latest/ecosystem/
[Scanning Coverage]: https://trivy.dev/docs/latest/coverage/

[alpine]: https://ariadne.space/2021/06/08/the-vulnerability-remediation-lifecycle-of-alpine-containers/
[rego]: https://www.openpolicyagent.org/docs/latest/#rego
[sigstore]: https://www.sigstore.dev/

[aquasec]: https://aquasec.com
[oss]: https://www.aquasec.com/products/open-source-projects/
[discussions]: https://github.com/aquasecurity/trivy/discussions
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[golang-migrate/migrate]]></title>
            <link>https://github.com/golang-migrate/migrate</link>
            <guid>https://github.com/golang-migrate/migrate</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:38 GMT</pubDate>
            <description><![CDATA[Database migrations. CLI and Golang library.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/golang-migrate/migrate">golang-migrate/migrate</a></h1>
            <p>Database migrations. CLI and Golang library.</p>
            <p>Language: Go</p>
            <p>Stars: 17,877</p>
            <p>Forks: 1,539</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>[![GitHub Workflow Status (branch)](https://img.shields.io/github/actions/workflow/status/golang-migrate/migrate/ci.yaml?branch=master)](https://github.com/golang-migrate/migrate/actions/workflows/ci.yaml?query=branch%3Amaster)
[![GoDoc](https://pkg.go.dev/badge/github.com/golang-migrate/migrate)](https://pkg.go.dev/github.com/golang-migrate/migrate/v4)
[![Coverage Status](https://img.shields.io/coveralls/github/golang-migrate/migrate/master.svg)](https://coveralls.io/github/golang-migrate/migrate?branch=master)
[![packagecloud.io](https://img.shields.io/badge/deb-packagecloud.io-844fec.svg)](https://packagecloud.io/golang-migrate/migrate?filter=debs)
[![Docker Pulls](https://img.shields.io/docker/pulls/migrate/migrate.svg)](https://hub.docker.com/r/migrate/migrate/)
![Supported Go Versions](https://img.shields.io/badge/Go-1.24%2C%201.25-lightgrey.svg)
[![GitHub Release](https://img.shields.io/github/release/golang-migrate/migrate.svg)](https://github.com/golang-migrate/migrate/releases)
[![Go Report Card](https://goreportcard.com/badge/github.com/golang-migrate/migrate/v4)](https://goreportcard.com/report/github.com/golang-migrate/migrate/v4)

# migrate

__Database migrations written in Go. Use as [CLI](#cli-usage) or import as [library](#use-in-your-go-project).__

* Migrate reads migrations from [sources](#migration-sources)
   and applies them in correct order to a [database](#databases).
* Drivers are &quot;dumb&quot;, migrate glues everything together and makes sure the logic is bulletproof.
   (Keeps the drivers lightweight, too.)
* Database drivers don&#039;t assume things or try to correct user input. When in doubt, fail.

Forked from [mattes/migrate](https://github.com/mattes/migrate)

## Databases

Database drivers run migrations. [Add a new database?](database/driver.go)

* [PostgreSQL](database/postgres)
* [PGX v4](database/pgx)
* [PGX v5](database/pgx/v5)
* [Redshift](database/redshift)
* [Ql](database/ql)
* [Cassandra / ScyllaDB](database/cassandra)
* [SQLite](database/sqlite)
* [SQLite3](database/sqlite3) ([todo #165](https://github.com/mattes/migrate/issues/165))
* [SQLCipher](database/sqlcipher)
* [MySQL / MariaDB](database/mysql)
* [Neo4j](database/neo4j)
* [MongoDB](database/mongodb)
* [CrateDB](database/crate) ([todo #170](https://github.com/mattes/migrate/issues/170))
* [Shell](database/shell) ([todo #171](https://github.com/mattes/migrate/issues/171))
* [Google Cloud Spanner](database/spanner)
* [CockroachDB](database/cockroachdb)
* [YugabyteDB](database/yugabytedb)
* [ClickHouse](database/clickhouse)
* [Firebird](database/firebird)
* [MS SQL Server](database/sqlserver)
* [rqlite](database/rqlite)

### Database URLs

Database connection strings are specified via URLs. The URL format is driver dependent but generally has the form: `dbdriver://username:password@host:port/dbname?param1=true&amp;param2=false`

Any [reserved URL characters](https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_reserved_characters) need to be escaped. Note, the `%` character also [needs to be escaped](https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_the_percent_character)

Explicitly, the following characters need to be escaped:
`!`, `#`, `$`, `%`, `&amp;`, `&#039;`, `(`, `)`, `*`, `+`, `,`, `/`, `:`, `;`, `=`, `?`, `@`, `[`, `]`

It&#039;s easiest to always run the URL parts of your DB connection URL (e.g. username, password, etc) through an URL encoder. See the example Python snippets below:

```bash
$ python3 -c &#039;import urllib.parse; print(urllib.parse.quote(input(&quot;String to encode: &quot;), &quot;&quot;))&#039;
String to encode: FAKEpassword!#$%&amp;&#039;()*+,/:;=?@[]
FAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D
$ python2 -c &#039;import urllib; print urllib.quote(raw_input(&quot;String to encode: &quot;), &quot;&quot;)&#039;
String to encode: FAKEpassword!#$%&amp;&#039;()*+,/:;=?@[]
FAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D
$
```

## Migration Sources

Source drivers read migrations from local or remote sources. [Add a new source?](source/driver.go)

* [Filesystem](source/file) - read from filesystem
* [io/fs](source/iofs) - read from a Go [io/fs](https://pkg.go.dev/io/fs#FS)
* [Go-Bindata](source/go_bindata) - read from embedded binary data ([jteeuwen/go-bindata](https://github.com/jteeuwen/go-bindata))
* [pkger](source/pkger) - read from embedded binary data ([markbates/pkger](https://github.com/markbates/pkger))
* [GitHub](source/github) - read from remote GitHub repositories
* [GitHub Enterprise](source/github_ee) - read from remote GitHub Enterprise repositories
* [Bitbucket](source/bitbucket) - read from remote Bitbucket repositories
* [Gitlab](source/gitlab) - read from remote Gitlab repositories
* [AWS S3](source/aws_s3) - read from Amazon Web Services S3
* [Google Cloud Storage](source/google_cloud_storage) - read from Google Cloud Platform Storage

## CLI usage

* Simple wrapper around this library.
* Handles ctrl+c (SIGINT) gracefully.
* No config search paths, no config files, no magic ENV var injections.

[CLI Documentation](cmd/migrate) (includes CLI install instructions)

### Basic usage

```bash
$ migrate -source file://path/to/migrations -database postgres://localhost:5432/database up 2
```

### Docker usage

```bash
$ docker run -v {{ migration dir }}:/migrations --network host migrate/migrate
    -path=/migrations/ -database postgres://localhost:5432/database up 2
```

## Use in your Go project

* API is stable and frozen for this release (v3 &amp; v4).
* Uses [Go modules](https://golang.org/cmd/go/#hdr-Modules__module_versions__and_more) to manage dependencies.
* To help prevent database corruptions, it supports graceful stops via `GracefulStop chan bool`.
* Bring your own logger.
* Uses `io.Reader` streams internally for low memory overhead.
* Thread-safe and no goroutine leaks.

__[Go Documentation](https://pkg.go.dev/github.com/golang-migrate/migrate/v4)__

```go
import (
    &quot;github.com/golang-migrate/migrate/v4&quot;
    _ &quot;github.com/golang-migrate/migrate/v4/database/postgres&quot;
    _ &quot;github.com/golang-migrate/migrate/v4/source/github&quot;
)

func main() {
    m, err := migrate.New(
        &quot;github://mattes:personal-access-token@mattes/migrate_test&quot;,
        &quot;postgres://localhost:5432/database?sslmode=enable&quot;)
    m.Steps(2)
}
```

Want to use an existing database client?

```go
import (
    &quot;database/sql&quot;
    _ &quot;github.com/lib/pq&quot;
    &quot;github.com/golang-migrate/migrate/v4&quot;
    &quot;github.com/golang-migrate/migrate/v4/database/postgres&quot;
    _ &quot;github.com/golang-migrate/migrate/v4/source/file&quot;
)

func main() {
    db, err := sql.Open(&quot;postgres&quot;, &quot;postgres://localhost:5432/database?sslmode=enable&quot;)
    driver, err := postgres.WithInstance(db, &amp;postgres.Config{})
    m, err := migrate.NewWithDatabaseInstance(
        &quot;file:///migrations&quot;,
        &quot;postgres&quot;, driver)
    m.Up() // or m.Steps(2) if you want to explicitly set the number of migrations to run
}
```

## Getting started

Go to [getting started](GETTING_STARTED.md)

## Tutorials

* [CockroachDB](database/cockroachdb/TUTORIAL.md)
* [PostgreSQL](database/postgres/TUTORIAL.md)

(more tutorials to come)

## Migration files

Each migration has an up and down migration. [Why?](FAQ.md#why-two-separate-files-up-and-down-for-a-migration)

```bash
1481574547_create_users_table.up.sql
1481574547_create_users_table.down.sql
```

[Best practices: How to write migrations.](MIGRATIONS.md)

## Coming from another db migration tool?

Check out [migradaptor](https://github.com/musinit/migradaptor/).
*Note: migradaptor is not affiliated or supported by this project*

## Versions

Version | Supported? | Import | Notes
--------|------------|--------|------
**master** | :white_check_mark: | `import &quot;github.com/golang-migrate/migrate/v4&quot;` | New features and bug fixes arrive here first |
**v4** | :white_check_mark: | `import &quot;github.com/golang-migrate/migrate/v4&quot;` | Used for stable releases |
**v3** | :x: | `import &quot;github.com/golang-migrate/migrate&quot;` (with package manager) or `import &quot;gopkg.in/golang-migrate/migrate.v3&quot;` (not recommended) | **DO NOT USE** - No longer supported |

## Development and Contributing

Yes, please! [`Makefile`](Makefile) is your friend,
read the [development guide](CONTRIBUTING.md).

Also have a look at the [FAQ](FAQ.md).

---

Looking for alternatives? [https://awesome-go.com/#database](https://awesome-go.com/#database).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[v2fly/v2ray-core]]></title>
            <link>https://github.com/v2fly/v2ray-core</link>
            <guid>https://github.com/v2fly/v2ray-core</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:37 GMT</pubDate>
            <description><![CDATA[A platform for building proxies to bypass network restrictions.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/v2fly/v2ray-core">v2fly/v2ray-core</a></h1>
            <p>A platform for building proxies to bypass network restrictions.</p>
            <p>Language: Go</p>
            <p>Stars: 32,873</p>
            <p>Forks: 4,952</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;div&gt;
  &lt;img width=&quot;190&quot; height=&quot;210&quot; align=&quot;left&quot; src=&quot;https://raw.githubusercontent.com/v2fly/v2fly-github-io/master/docs/.vuepress/public/readme-logo.png&quot; alt=&quot;V2Ray&quot;/&gt;
  &lt;br&gt;
  &lt;h1&gt;Project V&lt;/h1&gt;
  &lt;p&gt;Project V is a set of network tools that helps you to build your own computer network. It secures your network connections and thus protects your privacy.&lt;/p&gt;
&lt;/div&gt;

[![GitHub Test Badge](https://github.com/v2fly/v2ray-core/actions/workflows/test.yml/badge.svg)](https://github.com/v2fly/v2ray-core/actions/workflows/test.yml)
[![codecov.io](https://codecov.io/gh/v2fly/v2ray-core/branch/master/graph/badge.svg?branch=master)](https://codecov.io/gh/v2fly/v2ray-core?branch=master)
[![goreportcard](https://goreportcard.com/badge/github.com/v2fly/v2ray-core/v5)](https://goreportcard.com/report/github.com/v2fly/v2ray-core/v5)
[![Codacy Badge](https://app.codacy.com/project/badge/Grade/e150b7ede2114388921943bf23d95161)](https://app.codacy.com/gh/v2fly/v2ray-core/dashboard)
[![Downloads](https://img.shields.io/github/downloads/v2fly/v2ray-core/total.svg)](https://github.com/v2fly/v2ray-core/releases/latest)

## Related Links

- [Documentation](https://www.v2fly.org) and [Newcomer&#039;s Instructions](https://www.v2fly.org/guide/start.html)
- Welcome to translate V2Ray documents via [Transifex](https://www.transifex.com/v2fly/public/)

## Packaging Status

&gt; If you are willing to package V2Ray for other distros/platforms, please let us know or seek for help via [GitHub issues](https://github.com/v2fly/v2ray-core/issues).

[![Packaging status](https://repology.org/badge/vertical-allrepos/v2ray.svg)](https://repology.org/project/v2ray/versions)

## License

[The MIT License (MIT)](https://raw.githubusercontent.com/v2fly/v2ray-core/master/LICENSE)

## Credits

This repo relies on the following third-party projects:

- In production:
  - [gorilla/websocket](https://github.com/gorilla/websocket)
  - [quic-go/quic-go](https://github.com/quic-go/quic-go)
  - [pires/go-proxyproto](https://github.com/pires/go-proxyproto)
  - [seiflotfy/cuckoofilter](https://github.com/seiflotfy/cuckoofilter)
  - [google/starlark-go](https://github.com/google/starlark-go)
  - [jhump/protoreflect](https://github.com/jhump/protoreflect)
  - [inetaf/netaddr](https://github.com/inetaf/netaddr)

- For testing only:
  - [miekg/dns](https://github.com/miekg/dns)
  - [h12w/socks](https://github.com/h12w/socks)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[samber/lo]]></title>
            <link>https://github.com/samber/lo</link>
            <guid>https://github.com/samber/lo</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:36 GMT</pubDate>
            <description><![CDATA[üí• A Lodash-style Go library based on Go 1.18+ Generics (map, filter, contains, find...)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/samber/lo">samber/lo</a></h1>
            <p>üí• A Lodash-style Go library based on Go 1.18+ Generics (map, filter, contains, find...)</p>
            <p>Language: Go</p>
            <p>Stars: 20,813</p>
            <p>Forks: 921</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>
# lo - Iterate over slices, maps, channels...

[![tag](https://img.shields.io/github/tag/samber/lo.svg)](https://github.com/samber/lo/releases)
![Go Version](https://img.shields.io/badge/Go-%3E%3D%201.18-%23007d9c)
[![GoDoc](https://godoc.org/github.com/samber/lo?status.svg)](https://pkg.go.dev/github.com/samber/lo)
![Build Status](https://github.com/samber/lo/actions/workflows/test.yml/badge.svg)
[![Go report](https://goreportcard.com/badge/github.com/samber/lo)](https://goreportcard.com/report/github.com/samber/lo)
[![Coverage](https://img.shields.io/codecov/c/github/samber/lo)](https://codecov.io/gh/samber/lo)
[![Contributors](https://img.shields.io/github/contributors/samber/lo)](https://github.com/samber/lo/graphs/contributors)
[![License](https://img.shields.io/github/license/samber/lo)](./LICENSE)

‚ú® **`samber/lo` is a Lodash-style Go library based on Go 1.18+ Generics.**

A utility library based on Go 1.18+ generics that makes it easier to work with slices, maps, strings, channels, and functions. It provides dozens of handy methods to simplify common coding tasks and improve code readability. It may look like [Lodash](https://github.com/lodash/lodash) in some aspects.

5 to 10 helpers may overlap with those from the Go standard library, in packages `slices` and `maps`. I feel this library is legitimate and offers many more valuable abstractions.

**See also:**

- [samber/ro](https://github.com/samber/ro): Reactive Programming for Go: declarative and composable API for event-driven applications
- [samber/do](https://github.com/samber/do): A dependency injection toolkit based on Go 1.18+ Generics
- [samber/mo](https://github.com/samber/mo): Monads based on Go 1.18+ Generics (Option, Result, Either...)

What makes it different from **samber/ro**?
- lo: synchronous helpers across finite sequences (maps, slices...)
- ro: processing of infinite data streams for event-driven scenarios

----

&lt;h3 align=&quot;center&quot;&gt;üíñ Support This Project&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
	I‚Äôm going all-in on open-source for the coming months.
	&lt;br&gt;
	Help sustain development: Become an &lt;a href=&quot;http://github.com/sponsors/samber&quot;&gt;individual sponsor&lt;/a&gt; or join as a &lt;a href=&quot;mailto:hey@samuel-berthe.fr&quot;&gt;corporate sponsor&lt;/a&gt;.
&lt;/p&gt;

----

**Why this name?**

I wanted a **short name**, similar to &quot;Lodash&quot;, and no Go package uses this name.

![lo](docs/static/img/logo-full.png)

## üöÄ Install

```sh
go get github.com/samber/lo@v1
```

This library is v1 and follows SemVer strictly.

No breaking changes will be made to exported APIs before v2.0.0.

This library has no dependencies outside the Go standard library.

## üí° Usage

You can import `lo` using:

```go
import (
    &quot;github.com/samber/lo&quot;
    lop &quot;github.com/samber/lo/parallel&quot;
    lom &quot;github.com/samber/lo/mutable&quot;
    loi &quot;github.com/samber/lo/it&quot;
)
```

Then use one of the helpers below:

```go
names := lo.Uniq([]string{&quot;Samuel&quot;, &quot;John&quot;, &quot;Samuel&quot;})
// []string{&quot;Samuel&quot;, &quot;John&quot;}
```

### Tips for lazy developers

I cannot recommend it, but in case you are too lazy for repeating `lo.` everywhere, you can import the entire library into the namespace.

```go
import (
    . &quot;github.com/samber/lo&quot;
)
```

I take no responsibility for this junk. üòÅ üí©

## ü§† Spec

GoDoc: [godoc.org/github.com/samber/lo](https://godoc.org/github.com/samber/lo)

Documentation: [lo.samber.dev](https://lo.samber.dev/docs/about)

Supported helpers for slices:

- [Filter](#filter)
- [Map](#map)
- [UniqMap](#uniqmap)
- [FilterMap](#filtermap)
- [FlatMap](#flatmap)
- [Reduce](#reduce)
- [ReduceRight](#reduceright)
- [ForEach](#foreach)
- [ForEachWhile](#foreachwhile)
- [Times](#times)
- [Uniq](#uniq)
- [UniqBy](#uniqby)
- [GroupBy](#groupby)
- [GroupByMap](#groupbymap)
- [Chunk](#chunk)
- [PartitionBy](#partitionby)
- [Flatten](#flatten)
- [Concat](#concat)
- [Interleave](#interleave)
- [Shuffle](#shuffle)
- [Reverse](#reverse)
- [Fill](#fill)
- [Repeat](#repeat)
- [RepeatBy](#repeatby)
- [KeyBy](#keyby)
- [SliceToMap / Associate](#slicetomap-alias-associate)
- [FilterSliceToMap](#filterslicetomap)
- [Keyify](#keyify)
- [Drop](#drop)
- [DropRight](#dropright)
- [DropWhile](#dropwhile)
- [DropRightWhile](#droprightwhile)
- [DropByIndex](#DropByIndex)
- [Reject](#reject)
- [RejectMap](#rejectmap)
- [FilterReject](#filterreject)
- [Count](#count)
- [CountBy](#countby)
- [CountValues](#countvalues)
- [CountValuesBy](#countvaluesby)
- [Subset](#subset)
- [Slice](#slice)
- [Replace](#replace)
- [ReplaceAll](#replaceall)
- [Clone](#clone)
- [Compact](#compact)
- [IsSorted](#issorted)
- [IsSortedBy](#issortedby)
- [Splice](#Splice)
- [Cut](#Cut)
- [CutPrefix](#CutPrefix)
- [CutSuffix](#CutSuffix)
- [Trim](#Trim)
- [TrimLeft](#TrimLeft)
- [TrimPrefix](#TrimPrefix)
- [TrimRight](#TrimRight)
- [TrimSuffix](#TrimSuffix)

Supported helpers for maps:

- [Keys](#keys)
- [UniqKeys](#uniqkeys)
- [HasKey](#haskey)
- [ValueOr](#valueor)
- [Values](#values)
- [UniqValues](#uniqvalues)
- [PickBy](#pickby)
- [PickByKeys](#pickbykeys)
- [PickByValues](#pickbyvalues)
- [OmitBy](#omitby)
- [OmitByKeys](#omitbykeys)
- [OmitByValues](#omitbyvalues)
- [Entries / ToPairs](#entries-alias-topairs)
- [FromEntries / FromPairs](#fromentries-alias-frompairs)
- [Invert](#invert)
- [Assign (merge of maps)](#assign)
- [ChunkEntries](#chunkentries)
- [MapKeys](#mapkeys)
- [MapValues](#mapvalues)
- [MapEntries](#mapentries)
- [MapToSlice](#maptoslice)
- [FilterMapToSlice](#FilterMapToSlice)
- [FilterKeys](#FilterKeys)
- [FilterValues](#FilterValues)

Supported math helpers:

- [Range / RangeFrom / RangeWithSteps](#range--rangefrom--rangewithsteps)
- [Clamp](#clamp)
- [Sum](#sum)
- [SumBy](#sumby)
- [Product](#product)
- [ProductBy](#productby)
- [Mean](#mean)
- [MeanBy](#meanby)
- [Mode](#mode)

Supported helpers for strings:

- [RandomString](#randomstring)
- [Substring](#substring)
- [ChunkString](#chunkstring)
- [RuneLength](#runelength)
- [PascalCase](#pascalcase)
- [CamelCase](#camelcase)
- [KebabCase](#kebabcase)
- [SnakeCase](#snakecase)
- [Words](#words)
- [Capitalize](#capitalize)
- [Ellipsis](#ellipsis)

Supported helpers for tuples:

- [T2 -&gt; T9](#t2---t9)
- [Unpack2 -&gt; Unpack9](#unpack2---unpack9)
- [Zip2 -&gt; Zip9](#zip2---zip9)
- [ZipBy2 -&gt; ZipBy9](#zipby2---zipby9)
- [Unzip2 -&gt; Unzip9](#unzip2---unzip9)
- [UnzipBy2 -&gt; UnzipBy9](#unzipby2---unzipby9)
- [CrossJoin2 -&gt; CrossJoin2](#crossjoin2---crossjoin9)
- [CrossJoinBy2 -&gt; CrossJoinBy2](#crossjoinby2---crossjoinby9)

Supported helpers for time and duration:

- [Duration](#duration)
- [Duration0 -&gt; Duration10](#duration0---duration10)

Supported helpers for channels:

- [ChannelDispatcher](#channeldispatcher)
- [SliceToChannel](#slicetochannel)
- [ChannelToSlice](#channeltoslice)
- [Generator](#generator)
- [Buffer](#buffer)
- [BufferWithContext](#bufferwithcontext)
- [BufferWithTimeout](#bufferwithtimeout)
- [FanIn](#fanin)
- [FanOut](#fanout)

Supported intersection helpers:

- [Contains](#contains)
- [ContainsBy](#containsby)
- [Every](#every)
- [EveryBy](#everyby)
- [Some](#some)
- [SomeBy](#someby)
- [None](#none)
- [NoneBy](#noneby)
- [Intersect](#intersect)
- [IntersectBy](#intersectby)
- [Difference](#difference)
- [Union](#union)
- [Without](#without)
- [WithoutBy](#withoutby)
- [WithoutEmpty](#withoutempty)
- [WithoutNth](#withoutnth)
- [ElementsMatch](#ElementsMatch)
- [ElementsMatchBy](#ElementsMatchBy)

Supported search helpers:

- [IndexOf](#indexof)
- [LastIndexOf](#lastindexof)
- [HasPrefix](#hasprefix)
- [HasSuffix](#hassuffix)
- [Find](#find)
- [FindIndexOf](#findindexof)
- [FindLastIndexOf](#findlastindexof)
- [FindOrElse](#findorelse)
- [FindKey](#findkey)
- [FindKeyBy](#findkeyby)
- [FindUniques](#finduniques)
- [FindUniquesBy](#finduniquesby)
- [FindDuplicates](#findduplicates)
- [FindDuplicatesBy](#findduplicatesby)
- [Min](#min)
- [MinIndex](#minindex)
- [MinBy](#minby)
- [MinIndexBy](#minindexby)
- [Earliest](#earliest)
- [EarliestBy](#earliestby)
- [Max](#max)
- [MaxIndex](#maxindex)
- [MaxBy](#maxby)
- [MaxIndexBy](#maxindexby)
- [Latest](#latest)
- [LatestBy](#latestby)
- [First](#first)
- [FirstOrEmpty](#FirstOrEmpty)
- [FirstOr](#FirstOr)
- [Last](#last)
- [LastOrEmpty](#LastOrEmpty)
- [LastOr](#LastOr)
- [Nth](#nth)
- [NthOr](#nthor)
- [NthOrEmpty](#nthorempty)
- [Sample](#sample)
- [SampleBy](#sampleby)
- [Samples](#samples)
- [SamplesBy](#samplesby)

Conditional helpers:

- [Ternary](#ternary)
- [TernaryF](#ternaryf)
- [If / ElseIf / Else](#if--elseif--else)
- [Switch / Case / Default](#switch--case--default)

Type manipulation helpers:

- [IsNil](#isnil)
- [IsNotNil](#isnotnil)
- [ToPtr](#toptr)
- [Nil](#nil)
- [EmptyableToPtr](#emptyabletoptr)
- [FromPtr](#fromptr)
- [FromPtrOr](#fromptror)
- [ToSlicePtr](#tosliceptr)
- [FromSlicePtr](#fromsliceptr)
- [FromSlicePtrOr](#fromsliceptror)
- [ToAnySlice](#toanyslice)
- [FromAnySlice](#fromanyslice)
- [Empty](#empty)
- [IsEmpty](#isempty)
- [IsNotEmpty](#isnotempty)
- [Coalesce](#coalesce)
- [CoalesceOrEmpty](#coalesceorempty)
- [CoalesceSlice](#coalesceslice)
- [CoalesceSliceOrEmpty](#coalescesliceorempty)
- [CoalesceMap](#coalescemap)
- [CoalesceMapOrEmpty](#coalescemaporempty)

Function helpers:

- [Partial](#partial)
- [Partial2 -&gt; Partial5](#partial2---partial5)

Concurrency helpers:

- [Attempt](#attempt)
- [AttemptWhile](#attemptwhile)
- [AttemptWithDelay](#attemptwithdelay)
- [AttemptWhileWithDelay](#attemptwhilewithdelay)
- [Debounce](#debounce)
- [DebounceBy](#debounceby)
- [Throttle](#throttle)
- [ThrottleWithCount](#throttle)
- [ThrottleBy](#throttle)
- [ThrottleByWithCount](#throttle)
- [Synchronize](#synchronize)
- [Async](#async)
- [Async{0-&gt;6}](#async0-6)
- [Transaction](#transaction)
- [WaitFor](#waitfor)
- [WaitForWithContext](#waitforwithcontext)

Error handling:

- [Validate](#validate)
- [Must](#must)
- [Try](#try)
- [Try1 -&gt; Try6](#try0-6)
- [TryOr](#tryor)
- [TryOr1 -&gt; TryOr6](#tryor0-6)
- [TryCatch](#trycatch)
- [TryWithErrorValue](#trywitherrorvalue)
- [TryCatchWithErrorValue](#trycatchwitherrorvalue)
- [ErrorsAs](#errorsas)
- [Assert](#assert)
- [Assertf](#assertf)

Constraints:

- Clonable

### Filter

Iterates over a collection and returns a slice of all the elements the predicate function returns `true` for.

```go
even := lo.Filter([]int{1, 2, 3, 4}, func(x int, index int) bool {
    return x%2 == 0
})
// []int{2, 4}
```

[[play](https://go.dev/play/p/Apjg3WeSi7K)]

Mutable: like `lo.Filter()`, but the slice is updated in place.

```go
import lom &quot;github.com/samber/lo/mutable&quot;

list := []int{1, 2, 3, 4}
newList := lom.Filter(list, func(x int) bool {
    return x%2 == 0
})

list
// []int{2, 4, 3, 4}

newList
// []int{2, 4}
```

### Map

Manipulates a slice of one type and transforms it into a slice of another type:

```go
import &quot;github.com/samber/lo&quot;

lo.Map([]int64{1, 2, 3, 4}, func(x int64, index int) string {
    return strconv.FormatInt(x, 10)
})
// []string{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;}
```

[[play](https://go.dev/play/p/OkPcYAhBo0D)]

Parallel processing: like `lo.Map()`, but the transform function is called in a goroutine. Results are returned in the same order.

```go
import lop &quot;github.com/samber/lo/parallel&quot;

lop.Map([]int64{1, 2, 3, 4}, func(x int64, _ int) string {
    return strconv.FormatInt(x, 10)
})
// []string{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;}
```

[[play](https://go.dev/play/p/sCJaB3quRMC)]

Mutable: like `lo.Map()`, but the slice is updated in place.

```go
import lom &quot;github.com/samber/lo/mutable&quot;

list := []int{1, 2, 3, 4}
lom.Map(list, func(x int) int {
    return x*2
})
// []int{2, 4, 6, 8}
```

[[play](https://go.dev/play/p/0jY3Z0B7O_5)]

### UniqMap

Manipulates a slice and transforms it to a slice of another type with unique values.

```go
type User struct {
    Name string
    Age  int
}
users := []User{{Name: &quot;Alex&quot;, Age: 10}, {Name: &quot;Alex&quot;, Age: 12}, {Name: &quot;Bob&quot;, Age: 11}, {Name: &quot;Alice&quot;, Age: 20}}

names := lo.UniqMap(users, func(u User, index int) string {
    return u.Name
})
// []string{&quot;Alex&quot;, &quot;Bob&quot;, &quot;Alice&quot;}
```

[[play](https://go.dev/play/p/fygzLBhvUdB)]

### FilterMap

Returns a slice obtained after both filtering and mapping using the given callback function.

The callback function should return two values: the result of the mapping operation and whether the result element should be included or not.

```go
matching := lo.FilterMap([]string{&quot;cpu&quot;, &quot;gpu&quot;, &quot;mouse&quot;, &quot;keyboard&quot;}, func(x string, _ int) (string, bool) {
    if strings.HasSuffix(x, &quot;pu&quot;) {
        return &quot;xpu&quot;, true
    }
    return &quot;&quot;, false
})
// []string{&quot;xpu&quot;, &quot;xpu&quot;}
```

[[play](https://go.dev/play/p/-AuYXfy7opz)]

### FlatMap

Manipulates a slice and transforms and flattens it to a slice of another type. The transform function can either return a slice or a `nil`, and in the `nil` case no value is added to the final slice.

```go
lo.FlatMap([]int64{0, 1, 2}, func(x int64, _ int) []string {
    return []string{
        strconv.FormatInt(x, 10),
        strconv.FormatInt(x, 10),
    }
})
// []string{&quot;0&quot;, &quot;0&quot;, &quot;1&quot;, &quot;1&quot;, &quot;2&quot;, &quot;2&quot;}
```

[[play](https://go.dev/play/p/YSoYmQTA8-U)]

### Reduce

Reduces a collection to a single value. The value is calculated by accumulating the result of running each element in the collection through an accumulator function. Each successive invocation is supplied with the return value returned by the previous call.

```go
sum := lo.Reduce([]int{1, 2, 3, 4}, func(agg int, item int, _ int) int {
    return agg + item
}, 0)
// 10
```

[[play](https://go.dev/play/p/R4UHXZNaaUG)]

### ReduceRight

Like `lo.Reduce` except that it iterates over elements of collection from right to left.

```go
result := lo.ReduceRight([][]int{{0, 1}, {2, 3}, {4, 5}}, func(agg []int, item []int, _ int) []int {
    return append(agg, item...)
}, []int{})
// []int{4, 5, 2, 3, 0, 1}
```

[[play](https://go.dev/play/p/Fq3W70l7wXF)]

### ForEach

Iterates over elements of a collection and invokes the function over each element.

```go
import &quot;github.com/samber/lo&quot;

lo.ForEach([]string{&quot;hello&quot;, &quot;world&quot;}, func(x string, _ int) {
    println(x)
})
// prints &quot;hello\nworld\n&quot;
```

[[play](https://go.dev/play/p/oofyiUPRf8t)]

Parallel processing: like `lo.ForEach()`, but the callback is called as a goroutine.

```go
import lop &quot;github.com/samber/lo/parallel&quot;

lop.ForEach([]string{&quot;hello&quot;, &quot;world&quot;}, func(x string, _ int) {
    println(x)
})
// prints &quot;hello\nworld\n&quot; or &quot;world\nhello\n&quot;
```

### ForEachWhile

Iterates over collection elements and invokes iteratee for each element collection return value decide to continue or break, like do while().

```go
list := []int64{1, 2, -42, 4}

lo.ForEachWhile(list, func(x int64, _ int) bool {
	if x &lt; 0 {
		return false
	}
	fmt.Println(x)
	return true
})
// 1
// 2
```

[[play](https://go.dev/play/p/QnLGt35tnow)]

### Times

Times invokes the iteratee n times, returning a slice of the results of each invocation. The iteratee is invoked with index as argument.

```go
import &quot;github.com/samber/lo&quot;

lo.Times(3, func(i int) string {
    return strconv.FormatInt(int64(i), 10)
})
// []string{&quot;0&quot;, &quot;1&quot;, &quot;2&quot;}
```

[[play](https://go.dev/play/p/vgQj3Glr6lT)]

Parallel processing: like `lo.Times()`, but callback is called in goroutine.

```go
import lop &quot;github.com/samber/lo/parallel&quot;

lop.Times(3, func(i int) string {
    return strconv.FormatInt(int64(i), 10)
})
// []string{&quot;0&quot;, &quot;1&quot;, &quot;2&quot;}
```

### Uniq

Returns a duplicate-free version of a slice, in which only the first occurrence of each element is kept. The order of result values is determined by the order they occur in the slice.

```go
uniqValues := lo.Uniq([]int{1, 2, 2, 1})
// []int{1, 2}
```

[[play](https://go.dev/play/p/DTzbeXZ6iEN)]

### UniqBy

Returns a duplicate-free version of a slice, in which only the first occurrence of each element is kept. The order of result values is determined by the order they occur in the slice. It accepts `iteratee` which is invoked for each element in the slice to generate the criterion by which uniqueness is computed.

```go
uniqValues := lo.UniqBy([]int{0, 1, 2, 3, 4, 5}, func(i int) int {
    return i%3
})
// []int{0, 1, 2}
```

[[play](https://go.dev/play/p/g42Z3QSb53u)]

### GroupBy

Returns an object composed of keys generated from the results of running each element of collection through iteratee.

```go
import lo &quot;github.com/samber/lo&quot;

groups := lo.GroupBy([]int{0, 1, 2, 3, 4, 5}, func(i int) int {
    return i%3
})
// map[int][]int{0: []int{0, 3}, 1: []int{1, 4}, 2: []int{2, 5}}
```

[[play](https://go.dev/play/p/XnQBd_v6brd)]

Parallel processing: like `lo.GroupBy()`, but callback is called in goroutine.

```go
import lop &quot;github.com/samber/lo/parallel&quot;

lop.GroupBy([]int{0, 1, 2, 3, 4, 5}, func(i int) int {
    return i%3
})
// map[int][]int{0: []int{0, 3}, 1: []int{1, 4}, 2: []int{2, 5}}
```

### GroupByMap

Returns an object composed of keys generated from the results of running each element of collection through iteratee.

```go
import lo &quot;github.com/samber/lo&quot;

groups := lo.GroupByMap([]int{0, 1, 2, 3, 4, 5}, func(i int) (int, int) {
    return i%3, i*2
})
// map[int][]int{0: []int{0, 6}, 1: []int{2, 8}, 2: []int{4, 10}}
```

[[play](https://go.dev/play/p/iMeruQ3_W80)]

### Chunk

Returns a slice of elements split into groups of length size. If the slice can&#039;t be split evenly, the final chunk will be the remaining elements.

```go
lo.Chunk([]int{0, 1, 2, 3, 4, 5}, 2)
// [][]int{{0, 1}, {2, 3}, {4, 5}}

lo.Chunk([]int{0, 1, 2, 3, 4, 5, 6}, 2)
// [][]int{{0, 1}, {2, 3}, {4, 5}, {6}}

lo.Chunk([]int{}, 2)
// [][]int{}

lo.Chunk([]int{0}, 2)
// [][]int{{0}}
```

[[play](https://go.dev/play/p/kEMkFbdu85g)]

### PartitionBy

Returns a slice of elements split into groups. The order of grouped values is determined by the order they occur in collection. The grouping is generated from the results of running each element of collection through iteratee.

```go
import lo &quot;github.com/samber/lo&quot;

partitions := lo.PartitionBy([]int{-2, -1, 0, 1, 2, 3, 4, 5}, func(x int) string {
    if x &lt; 0 {
        return &quot;negative&quot;
    } else if x%2 == 0 {
        return &quot;even&quot;
    }
    return &quot;odd&quot;
})
// [][]int{{-2, -1}, {0, 2, 4}, {1, 3, 5}}
```

[[play](https://go.dev/play/p/NfQ_nGjkgXW)]

Parallel processing: like `lo.PartitionBy()`, but callback is called in goroutine. Results are returned in the same order.

```go
import lop &quot;github.com/samber/lo/parallel&quot;

partitions := lop.PartitionBy([]int{-2, -1, 0, 1, 2, 3, 4, 5}, func(x int) string {
    if x &lt; 0 {
        return &quot;negative&quot;
    } else if x%2 == 0 {
        return &quot;even&quot;
    }
    return &quot;odd&quot;
})
// [][]int{{-2, -1}, {0, 2, 4}, {1, 3, 5}}
```

### Flatten

Returns a slice a single level deep.

```go
flat := lo.Flatten([][]int{{0, 1}, {2, 3, 4, 5}})
// []int{0, 1, 2, 3, 4, 5}
```

[[play](https://go.dev/play/p/rbp9ORaMpjw)]

### Concat

Returns a new slice containing all the elements in collections. Concat conserves the order of the elements.

```go
slice := lo.Concat([]int{1, 2}, []int{3, 4})
// []int{1, 2, 3, 4}

slice := lo.Concat(nil, []int{1, 2}, nil, []int{3, 4}, nil)
// []int{1, 2, 3, 4}

slice := lo.Concat[int]()
// []int{}
```
### Interleave

Round-robin alternating input slices and sequentially appending value at index into result.

```go
interleaved := lo.Interleave([]int{1, 4, 7}, []int{2, 5, 8}, []int{3, 6, 9})
// []int{1, 2, 3, 4, 5, 6, 7, 8, 9}

interleaved := lo.Interleave([]int{1}, []int{2, 5, 8}, []int{3, 6}, []int{4, 7, 9, 10})
// []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}
```

[[play](https://go.dev/play/p/-RJkTLQEDVt)]

### Shuffle

Returns a slice of shuffled values. Uses the Fisher-Yates shuffle algorithm.

‚ö†Ô∏è This helper is **mutable**.

```go
import lom &quot;github.com/samber/lo/mutable&quot;

list := []int{0, 1, 2, 3, 4, 5}
lom.Shuffle(list)

list
// []int{1, 4, 0, 3, 5, 2}
```

[[play](https://go.dev/play/p/2xb3WdLjeSJ)]

### Reverse

Reverses a slice so that the first element becomes the last, the second element becomes the second to last, and so on.

‚ö†Ô∏è This helper is **mutable**.

```go
import lom &quot;github.com/samber/lo/mutable&quot;

lis

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gruntwork-io/terragrunt]]></title>
            <link>https://github.com/gruntwork-io/terragrunt</link>
            <guid>https://github.com/gruntwork-io/terragrunt</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:35 GMT</pubDate>
            <description><![CDATA[Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in OpenTofu/Terraform to scale.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gruntwork-io/terragrunt">gruntwork-io/terragrunt</a></h1>
            <p>Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in OpenTofu/Terraform to scale.</p>
            <p>Language: Go</p>
            <p>Stars: 9,184</p>
            <p>Forks: 1,127</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre># Terragrunt

[![Maintained by Gruntwork.io](https://img.shields.io/badge/maintained%20by-gruntwork.io-%235849a6.svg)](https://gruntwork.io/?ref=repo_terragrunt)
[![Go Report Card](https://goreportcard.com/badge/github.com/gruntwork-io/terragrunt)](https://goreportcard.com/report/github.com/gruntwork-io/terragrunt)
[![GoDoc](https://godoc.org/github.com/gruntwork-io/terragrunt?status.svg)](https://godoc.org/github.com/gruntwork-io/terragrunt)
![OpenTofu Version](https://img.shields.io/badge/tofu-%3E%3D1.6.0-blue.svg)
![Terraform Version](https://img.shields.io/badge/tf-%3E%3D0.12.0-blue.svg)

Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in [OpenTofu](https://opentofu.org)/[Terraform](https://www.terraform.io) to scale.

Please see the following for more info, including install instructions and complete documentation:

* [Terragrunt Website](https://terragrunt.gruntwork.io)
* [Getting started with Terragrunt](https://terragrunt.gruntwork.io/docs/getting-started/quick-start/)
* [Terragrunt Documentation](https://terragrunt.gruntwork.io/docs)
* [Contributing to Terragrunt](https://terragrunt.gruntwork.io/docs/community/contributing)
* [Commercial Support](https://gruntwork.io/support/)

## Join the Discord!

Join [our community](https://discord.gg/YENaT9h8jh) for discussions, support, and contributions:

[![](https://dcbadge.limes.pink/api/server/https://discord.gg/YENaT9h8jh)](https://discord.gg/YENaT9h8jh)

## License

This code is released under the MIT License. See [LICENSE.txt](LICENSE.txt).

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grafana/mimir]]></title>
            <link>https://github.com/grafana/mimir</link>
            <guid>https://github.com/grafana/mimir</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:34 GMT</pubDate>
            <description><![CDATA[Grafana Mimir provides horizontally scalable, highly available, multi-tenant, long-term storage for Prometheus.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grafana/mimir">grafana/mimir</a></h1>
            <p>Grafana Mimir provides horizontally scalable, highly available, multi-tenant, long-term storage for Prometheus.</p>
            <p>Language: Go</p>
            <p>Stars: 4,865</p>
            <p>Forks: 690</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># Grafana Mimir

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;images/logo.png&quot; alt=&quot;Grafana Mimir logo&quot; width=&quot;400&quot;&gt;&lt;/p&gt;

Grafana Mimir is an open source software project that provides a scalable long-term storage for [Prometheus](https://prometheus.io). Some of the core strengths of Grafana Mimir include:

- **Easy to install and maintain:** Grafana Mimir‚Äôs extensive documentation, tutorials, and deployment tooling make it quick to get started. Using its monolithic mode, you can get Grafana Mimir up and running with just one binary and no additional dependencies. Once deployed, the best-practice dashboards, alerts, and runbooks packaged with Grafana Mimir make it easy to monitor the health of the system.
- **Massive scalability:** You can run Grafana Mimir&#039;s horizontally-scalable architecture across multiple machines, resulting in the ability to process orders of magnitude more time series than a single Prometheus instance. Internal testing shows that Grafana Mimir handles up to 1 billion active time series.
- **Global view of metrics:** Grafana Mimir enables you to run queries that aggregate series from multiple Prometheus instances, giving you a global view of your systems. Its query engine extensively parallelizes query execution, so that even the highest-cardinality queries complete with blazing speed.
- **Cheap, durable metric storage:** Grafana Mimir uses object storage for long-term data storage, allowing it to take advantage of this ubiquitous, cost-effective, high-durability technology. It is compatible with multiple object store implementations, including AWS S3, Google Cloud Storage, Azure Blob Storage, OpenStack Swift, as well as any S3-compatible object storage.
- **High availability:** Grafana Mimir replicates incoming metrics, ensuring that no data is lost in the event of machine failure. Its horizontally scalable architecture also means that it can be restarted, upgraded, or downgraded with zero downtime, which means no interruptions to metrics ingestion or querying.
- **Natively multi-tenant:** Grafana Mimir‚Äôs multi-tenant architecture enables you to isolate data and queries from independent teams or business units, making it possible for these groups to share the same cluster. Advanced limits and quality-of-service controls ensure that capacity is shared fairly among tenants.

## Migrating to Grafana Mimir

If you&#039;re migrating to Grafana Mimir, refer to the following documents:

- [Migrating from Thanos or Prometheus to Grafana Mimir](https://grafana.com/docs/mimir/latest/set-up/migrate/migrate-from-thanos-or-prometheus/).
- [Migrating from Cortex to Grafana Mimir](https://grafana.com/docs/mimir/latest/set-up/migrate/migrate-from-cortex/)

## Deploying Grafana Mimir

For information about how to deploy Grafana Mimir, refer to [Deploy Grafana Mimir](https://grafana.com/docs/mimir/latest/operators-guide/deploy-grafana-mimir/).

## Getting started

If you‚Äôre new to Grafana Mimir, read the [Get started guide](https://grafana.com/docs/mimir/latest/get-started/).

Before deploying Grafana Mimir in a production environment, read:

1. [An overview of Grafana Mimir‚Äôs architecture](https://grafana.com/docs/mimir/latest/operators-guide/architecture/)
1. [Configure Grafana Mimir](https://grafana.com/docs/mimir/latest/operators-guide/configure/)
1. [Run Grafana Mimir in production](https://grafana.com/docs/mimir/latest/operators-guide/run-production-environment/)

## Documentation

Refer to the following links to access Grafana Mimir documentation:

- [Latest release](https://grafana.com/docs/mimir/latest/)
- [Upcoming release](https://grafana.com/docs/mimir/next/), at the tip of the `main` branch

## Contributing

To contribute to Grafana Mimir, refer to [Contributing to Grafana Mimir](https://github.com/grafana/mimir/tree/main/docs/internal/contributing).

## Join the Grafana Mimir discussion

If you have any questions or feedback regarding Grafana Mimir, join the [Grafana Mimir Discussion](https://github.com/grafana/mimir/discussions). Alternatively, consider joining the monthly [Grafana Mimir Community Call](https://docs.google.com/document/d/1E4jJcGicvLTyMEY6cUFFZUg_I8ytrBuW8r5yt1LyMv4).

Your feedback is always welcome, and you can also share it via the [`#mimir` Slack channel](https://slack.grafana.com/).

## License

Grafana Mimir is distributed under [AGPL-3.0-only](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[maximhq/bifrost]]></title>
            <link>https://github.com/maximhq/bifrost</link>
            <guid>https://github.com/maximhq/bifrost</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:33 GMT</pubDate>
            <description><![CDATA[Fastest LLM gateway (50x faster than LiteLLM) with adaptive load balancer, cluster mode, guardrails, 1000+ models support & <100 ¬µs overhead at 5k RPS.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/maximhq/bifrost">maximhq/bifrost</a></h1>
            <p>Fastest LLM gateway (50x faster than LiteLLM) with adaptive load balancer, cluster mode, guardrails, 1000+ models support & <100 ¬µs overhead at 5k RPS.</p>
            <p>Language: Go</p>
            <p>Stars: 1,487</p>
            <p>Forks: 151</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre># Bifrost

[![Go Report Card](https://goreportcard.com/badge/github.com/maximhq/bifrost/core)](https://goreportcard.com/report/github.com/maximhq/bifrost/core)
[![Discord badge](https://dcbadge.limes.pink/api/server/https://discord.gg/exN5KAydbU?style=flat)](https://discord.gg/exN5KAydbU)
[![Known Vulnerabilities](https://snyk.io/test/github/maximhq/bifrost/badge.svg)](https://snyk.io/test/github/maximhq/bifrost)
[![codecov](https://codecov.io/gh/maximhq/bifrost/branch/main/graph/badge.svg)](https://codecov.io/gh/maximhq/bifrost)
![Docker Pulls](https://img.shields.io/docker/pulls/maximhq/bifrost)
[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 95px; height: 21px;&quot;&gt;](https://app.getpostman.com/run-collection/31642484-2ba0e658-4dcd-49f4-845a-0c7ed745b916?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D31642484-2ba0e658-4dcd-49f4-845a-0c7ed745b916%26entityType%3Dcollection%26workspaceId%3D63e853c8-9aec-477f-909c-7f02f543150e)
[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/bifrost)](https://artifacthub.io/packages/search?repo=bifrost)
[![License](https://img.shields.io/github/license/maximhq/bifrost)](LICENSE)

## The fastest way to build AI applications that never go down

Bifrost is a high-performance AI gateway that unifies access to 15+ providers (OpenAI, Anthropic, AWS Bedrock, Google Vertex, and more) through a single OpenAI-compatible API. Deploy in seconds with zero configuration and get automatic failover, load balancing, semantic caching, and enterprise-grade features.

## Quick Start

![Get started](./docs/media/getting-started.png)

**Go from zero to production-ready AI gateway in under a minute.**

**Step 1:** Start Bifrost Gateway

```bash
# Install and run locally
npx -y @maximhq/bifrost

# Or use Docker
docker run -p 8080:8080 maximhq/bifrost
```

**Step 2:** Configure via Web UI

```bash
# Open the built-in web interface
open http://localhost:8080
```

**Step 3:** Make your first API call

```bash
curl -X POST http://localhost:8080/v1/chat/completions \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;openai/gpt-4o-mini&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello, Bifrost!&quot;}]
  }&#039;
```

**That&#039;s it!** Your AI gateway is running with a web interface for visual configuration, real-time monitoring, and analytics.

**Complete Setup Guides:**

- [Gateway Setup](https://docs.getbifrost.ai/quickstart/gateway/setting-up) - HTTP API deployment
- [Go SDK Setup](https://docs.getbifrost.ai/quickstart/go-sdk/setting-up) - Direct integration

---

## Key Features

### Core Infrastructure

- **[Unified Interface](https://docs.getbifrost.ai/features/unified-interface)** - Single OpenAI-compatible API for all providers
- **[Multi-Provider Support](https://docs.getbifrost.ai/quickstart/gateway/provider-configuration)** - OpenAI, Anthropic, AWS Bedrock, Google Vertex, Azure, Cerebras, Cohere, Mistral, Ollama, Groq, and more
- **[Automatic Fallbacks](https://docs.getbifrost.ai/features/fallbacks)** - Seamless failover between providers and models with zero downtime
- **[Load Balancing](https://docs.getbifrost.ai/features/fallbacks)** - Intelligent request distribution across multiple API keys and providers

### Advanced Features

- **[Model Context Protocol (MCP)](https://docs.getbifrost.ai/features/mcp)** - Enable AI models to use external tools (filesystem, web search, databases)
- **[Semantic Caching](https://docs.getbifrost.ai/features/semantic-caching)** - Intelligent response caching based on semantic similarity to reduce costs and latency
- **[Multimodal Support](https://docs.getbifrost.ai/quickstart/gateway/streaming)** - Support for text,images, audio, and streaming, all behind a common interface.
- **[Custom Plugins](https://docs.getbifrost.ai/enterprise/custom-plugins)** - Extensible middleware architecture for analytics, monitoring, and custom logic
- **[Governance](https://docs.getbifrost.ai/features/governance)** - Usage tracking, rate limiting, and fine-grained access control

### Enterprise &amp; Security

- **[Budget Management](https://docs.getbifrost.ai/features/governance)** - Hierarchical cost control with virtual keys, teams, and customer budgets
- **[SSO Integration](https://docs.getbifrost.ai/features/sso-with-google-github)** - Google and GitHub authentication support
- **[Observability](https://docs.getbifrost.ai/features/observability)** - Native Prometheus metrics, distributed tracing, and comprehensive logging
- **[Vault Support](https://docs.getbifrost.ai/enterprise/vault-support)** - Secure API key management with HashiCorp Vault integration

### Developer Experience

- **[Zero-Config Startup](https://docs.getbifrost.ai/quickstart/gateway/setting-up)** - Start immediately with dynamic provider configuration
- **[Drop-in Replacement](https://docs.getbifrost.ai/features/drop-in-replacement)** - Replace OpenAI/Anthropic/GenAI APIs with one line of code
- **[SDK Integrations](https://docs.getbifrost.ai/integrations/what-is-an-integration)** - Native support for popular AI SDKs with zero code changes
- **[Configuration Flexibility](https://docs.getbifrost.ai/quickstart/gateway/provider-configuration)** - Web UI, API-driven, or file-based configuration options

---

## Repository Structure

Bifrost uses a modular architecture for maximum flexibility:

```text
bifrost/
‚îú‚îÄ‚îÄ npx/                 # NPX script for easy installation
‚îú‚îÄ‚îÄ core/                # Core functionality and shared components
‚îÇ   ‚îú‚îÄ‚îÄ providers/       # Provider-specific implementations (OpenAI, Anthropic, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ schemas/         # Interfaces and structs used throughout Bifrost
‚îÇ   ‚îî‚îÄ‚îÄ bifrost.go       # Main Bifrost implementation
‚îú‚îÄ‚îÄ framework/           # Framework components for data persistence
‚îÇ   ‚îú‚îÄ‚îÄ configstore/     # Configuration storages
‚îÇ   ‚îú‚îÄ‚îÄ logstore/        # Request logging storages
‚îÇ   ‚îî‚îÄ‚îÄ vectorstore/     # Vector storages
‚îú‚îÄ‚îÄ transports/          # HTTP gateway and other interface layers
‚îÇ   ‚îî‚îÄ‚îÄ bifrost-http/    # HTTP transport implementation
‚îú‚îÄ‚îÄ ui/                  # Web interface for HTTP gateway
‚îú‚îÄ‚îÄ plugins/             # Extensible plugin system
‚îÇ   ‚îú‚îÄ‚îÄ governance/      # Budget management and access control
‚îÇ   ‚îú‚îÄ‚îÄ jsonparser/      # JSON parsing and manipulation utilities
‚îÇ   ‚îú‚îÄ‚îÄ logging/         # Request logging and analytics
‚îÇ   ‚îú‚îÄ‚îÄ maxim/           # Maxim&#039;s observability integration
‚îÇ   ‚îú‚îÄ‚îÄ mocker/          # Mock responses for testing and development
‚îÇ   ‚îú‚îÄ‚îÄ semanticcache/   # Intelligent response caching
‚îÇ   ‚îî‚îÄ‚îÄ telemetry/       # Monitoring and observability
‚îú‚îÄ‚îÄ docs/                # Documentation and guides
‚îî‚îÄ‚îÄ tests/               # Comprehensive test suites
```

---

## Getting Started Options

Choose the deployment method that fits your needs:

### 1. Gateway (HTTP API)

**Best for:** Language-agnostic integration, microservices, and production deployments

```bash
# NPX - Get started in 30 seconds
npx -y @maximhq/bifrost

# Docker - Production ready
docker run -p 8080:8080 -v $(pwd)/data:/app/data maximhq/bifrost
```

**Features:** Web UI, real-time monitoring, multi-provider management, zero-config startup

**Learn More:** [Gateway Setup Guide](https://docs.getbifrost.ai/quickstart/gateway/setting-up)

### 2. Go SDK

**Best for:** Direct Go integration with maximum performance and control

```bash
go get github.com/maximhq/bifrost/core
```

**Features:** Native Go APIs, embedded deployment, custom middleware integration

**Learn More:** [Go SDK Guide](https://docs.getbifrost.ai/quickstart/go-sdk/setting-up)

### 3. Drop-in Replacement

**Best for:** Migrating existing applications with zero code changes

```diff
# OpenAI SDK
- base_url = &quot;https://api.openai.com&quot;
+ base_url = &quot;http://localhost:8080/openai&quot;

# Anthropic SDK  
- base_url = &quot;https://api.anthropic.com&quot;
+ base_url = &quot;http://localhost:8080/anthropic&quot;

# Google GenAI SDK
- api_endpoint = &quot;https://generativelanguage.googleapis.com&quot;
+ api_endpoint = &quot;http://localhost:8080/genai&quot;
```

**Learn More:** [Integration Guides](https://docs.getbifrost.ai/integrations/what-is-an-integration)

---

## Performance

Bifrost adds virtually zero overhead to your AI requests. In sustained 5,000 RPS benchmarks, the gateway added only **11 ¬µs** of overhead per request.

| Metric | t3.medium | t3.xlarge | Improvement |
|--------|-----------|-----------|-------------|
| Added latency (Bifrost overhead) | 59 ¬µs | **11 ¬µs** | **-81%** |
| Success rate @ 5k RPS | 100% | 100% | No failed requests |
| Avg. queue wait time | 47 ¬µs | **1.67 ¬µs** | **-96%** |
| Avg. request latency (incl. provider) | 2.12 s | **1.61 s** | **-24%** |

**Key Performance Highlights:**

- **Perfect Success Rate** - 100% request success rate even at 5k RPS
- **Minimal Overhead** - Less than 15 ¬µs additional latency per request
- **Efficient Queuing** - Sub-microsecond average wait times
- **Fast Key Selection** - ~10 ns to pick weighted API keys

**Complete Benchmarks:** [Performance Analysis](https://docs.getbifrost.ai/benchmarking/getting-started)

---

## Documentation

**Complete Documentation:** [https://docs.getbifrost.ai](https://docs.getbifrost.ai)

### Quick Start

- [Gateway Setup](https://docs.getbifrost.ai/quickstart/gateway/setting-up) - HTTP API deployment in 30 seconds
- [Go SDK Setup](https://docs.getbifrost.ai/quickstart/go-sdk/setting-up) - Direct Go integration
- [Provider Configuration](https://docs.getbifrost.ai/quickstart/gateway/provider-configuration) - Multi-provider setup

### Features

- [Multi-Provider Support](https://docs.getbifrost.ai/features/unified-interface) - Single API for all providers
- [MCP Integration](https://docs.getbifrost.ai/features/mcp) - External tool calling
- [Semantic Caching](https://docs.getbifrost.ai/features/semantic-caching) - Intelligent response caching
- [Fallbacks &amp; Load Balancing](https://docs.getbifrost.ai/features/fallbacks) - Reliability features
- [Budget Management](https://docs.getbifrost.ai/features/governance) - Cost control and governance

### Integrations

- [OpenAI SDK](https://docs.getbifrost.ai/integrations/openai-sdk) - Drop-in OpenAI replacement
- [Anthropic SDK](https://docs.getbifrost.ai/integrations/anthropic-sdk) - Drop-in Anthropic replacement
- [AWS Bedrock SDK](https://docs.getbifrost.ai/integrations/bedrock-sdk) - AWS Bedrock integration
- [Google GenAI SDK](https://docs.getbifrost.ai/integrations/genai-sdk) - Drop-in GenAI replacement
- [LiteLLM SDK](https://docs.getbifrost.ai/integrations/litellm-sdk) - LiteLLM integration
- [Langchain SDK](https://docs.getbifrost.ai/integrations/langchain-sdk) - Langchain integration

### Enterprise

- [Custom Plugins](https://docs.getbifrost.ai/enterprise/custom-plugins) - Extend functionality
- [Clustering](https://docs.getbifrost.ai/enterprise/clustering) - Multi-node deployment
- [Vault Support](https://docs.getbifrost.ai/enterprise/vault-support) - Secure key management
- [Production Deployment](https://docs.getbifrost.ai/deployment/docker-setup) - Scaling and monitoring

---

## Need Help?

**[Join our Discord](https://discord.gg/exN5KAydbU)** for community support and discussions.

Get help with:

- Quick setup assistance and troubleshooting
- Best practices and configuration tips  
- Community discussions and support
- Real-time help with integrations

---

## Contributing

We welcome contributions of all kinds! See our [Contributing Guide](https://docs.getbifrost.ai/contributing/setting-up-repo) for:

- Setting up the development environment
- Code conventions and best practices
- How to submit pull requests
- Building and testing locally

For development requirements and build instructions, see our [Development Setup Guide](https://docs.getbifrost.ai/contributing/building-a-plugins).

---

## License

This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.

Built with ‚ù§Ô∏è by [Maxim](https://github.com/maximhq)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[influxdata/telegraf]]></title>
            <link>https://github.com/influxdata/telegraf</link>
            <guid>https://github.com/influxdata/telegraf</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:32 GMT</pubDate>
            <description><![CDATA[Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/influxdata/telegraf">influxdata/telegraf</a></h1>
            <p>Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.</p>
            <p>Language: Go</p>
            <p>Stars: 16,608</p>
            <p>Forks: 5,747</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># ![tiger](assets/TelegrafTigerSmall.png &quot;tiger&quot;) Telegraf

[![GoDoc](https://img.shields.io/badge/doc-reference-00ADD8.svg?logo=go)](https://godoc.org/github.com/influxdata/telegraf)
[![Docker pulls](https://img.shields.io/docker/pulls/library/telegraf.svg)](https://hub.docker.com/_/telegraf/)
[![Go Report Card](https://goreportcard.com/badge/github.com/influxdata/telegraf)](https://goreportcard.com/report/github.com/influxdata/telegraf)
[![Circle CI](https://circleci.com/gh/influxdata/telegraf.svg?style=svg)](https://circleci.com/gh/influxdata/telegraf)

Telegraf is an agent for collecting, processing, aggregating, and writing
metrics, logs, and other arbitrary data.

* Offers a comprehensive suite of over 300 plugins, covering a wide range of
  functionalities including system monitoring, cloud services, and message
  passing
* Enables the integration of user-defined code to collect, transform, and
  transmit data efficiently
* Compiles into a standalone static binary without any external dependencies,
  ensuring a streamlined deployment process
* Utilizes TOML for configuration, providing a user-friendly and unambiguous
  setup experience
* Developed with contributions from a diverse community of over 1,200
  contributors

Users can choose plugins from a wide range of topics, including but not limited
to:

* Devices: [OPC UA][], [Modbus][]
* Logs: [File][], [Tail][], [Directory Monitor][]
* Messaging: [AMQP][], [Kafka][], [MQTT][]
* Monitoring: [OpenTelemetry][], [Prometheus][]
* Networking: [Cisco TelemetryMDT][], [gNMI][]
* System monitoring: [CPU][], [Memory][], [Disk][], [Network][], [SMART][],
  [Docker][], [Nvidia SMI][], etc.
* Universal: [Exec][], [HTTP][], [HTTP Listener][], [SNMP][], [SQL][]
* Windows: [Event Log][], [Management Instrumentation][],
  [Performance Counters][]

## üî® Installation

For binary builds, Docker images, RPM &amp; DEB packages, and other builds of
Telegraf, please see the [install guide](/docs/INSTALL_GUIDE.md).

See the [releases documentation](/docs/RELEASES.md) for details on versioning
and when releases are made.

## üíª Usage

Users define a TOML configuration with the plugins and settings they wish to
use, then pass that configuration to Telegraf. The Telegraf agent then
collects data from inputs at each interval and sends data to outputs at each
flush interval.

For a basic walkthrough see [quick start](/docs/QUICK_START.md).

## üìñ Documentation

For a full list of documentation including tutorials, reference and other
material, start with the [/docs directory](/docs/README.md).

Additionally, each plugin has its own README that includes details about how to
configure, use, and sometimes debug or troubleshoot. Look under the
[/plugins directory](/plugins/) for specific plugins.

Here are some commonly used documents:

* [Changelog](/CHANGELOG.md)
* [Configuration](/docs/CONFIGURATION.md)
* [FAQ](/docs/FAQ.md)
* [Releases](https://github.com/influxdata/telegraf/releases)
* [Security](/SECURITY.md)

## ‚ù§Ô∏è Contribute

[![Contribute](https://img.shields.io/badge/contribute-to_telegraf-blue.svg?logo=influxdb)](https://github.com/influxdata/telegraf/blob/master/CONTRIBUTING.md)

We love our community of over 1,200 contributors! Many of the plugins included
in Telegraf were originally contributed by community members. Check out
our [contributing guide](CONTRIBUTING.md) if you are interested in helping out.
Also, join us on our [Community Slack](https://influxdata.com/slack) or
[Community Forums](https://community.influxdata.com/) if you have questions or
comments for our engineering teams.

If you are completely new to Telegraf and InfluxDB, you can also enroll for free
at [InfluxDB university](https://www.influxdata.com/university/) to take courses
to learn more.

## ‚ÑπÔ∏è Support

[![Slack](https://img.shields.io/badge/slack-join_chat-blue.svg?logo=slack)](https://www.influxdata.com/slack)
[![Forums](https://img.shields.io/badge/discourse-join_forums-blue.svg?logo=discourse)](https://community.influxdata.com/)

Please use the [Community Slack](https://influxdata.com/slack) or
[Community Forums](https://community.influxdata.com/) if you have questions or
comments for our engineering teams. GitHub issues are limited to actual issues
and feature requests only.

## üìú License

[![MIT](https://img.shields.io/badge/license-MIT-blue)](https://github.com/influxdata/telegraf/blob/master/LICENSE)

[OPC UA]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opcua
[Modbus]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/modbus
[File]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/file
[Tail]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/tail
[Directory Monitor]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/directory_monitor
[AMQP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/amqp_consumer
[Kafka]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/kafka_consumer
[MQTT]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mqtt_consumer
[OpenTelemetry]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opentelemetry
[Prometheus]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/prometheus
[Cisco TelemetryMDT]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cisco_telemetry_mdt
[gNMI]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/gnmi
[CPU]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cpu
[Memory]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mem
[Disk]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/disk
[Network]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/net
[SMART]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/smartctl
[Docker]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker
[Nvidia SMI]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/nvidia_smi
[Exec]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/exec
[HTTP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http
[HTTP Listener]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http_listener_v2
[SNMP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/snmp
[SQL]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/sql
[Event Log]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_eventlog
[Management Instrumentation]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_wmi
[Performance Counters]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gohugoio/hugo]]></title>
            <link>https://github.com/gohugoio/hugo</link>
            <guid>https://github.com/gohugoio/hugo</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:31 GMT</pubDate>
            <description><![CDATA[The world‚Äôs fastest framework for building websites.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gohugoio/hugo">gohugoio/hugo</a></h1>
            <p>The world‚Äôs fastest framework for building websites.</p>
            <p>Language: Go</p>
            <p>Stars: 85,695</p>
            <p>Forks: 8,156</p>
            <p>Stars today: 36 stars today</p>
            <h2>README</h2><pre>[bep]: https://github.com/bep
[bugs]: https://github.com/gohugoio/hugo/issues?q=is%3Aopen+is%3Aissue+label%3ABug
[contributing]: CONTRIBUTING.md
[create a proposal]: https://github.com/gohugoio/hugo/issues/new?labels=Proposal%2C+NeedsTriage&amp;template=feature_request.md
[documentation repository]: https://github.com/gohugoio/hugoDocs
[documentation]: https://gohugo.io/documentation
[dragonfly bsd, freebsd, netbsd, and openbsd]: https://gohugo.io/installation/bsd
[features]: https://gohugo.io/about/features/
[forum]: https://discourse.gohugo.io
[friends]: https://github.com/gohugoio/hugo/graphs/contributors
[go]: https://go.dev/
[hugo modules]: https://gohugo.io/hugo-modules/
[installation]: https://gohugo.io/installation
[issue queue]: https://github.com/gohugoio/hugo/issues
[linux]: https://gohugo.io/installation/linux
[macos]: https://gohugo.io/installation/macos
[prebuilt binary]: https://github.com/gohugoio/hugo/releases/latest
[requesting help]: https://discourse.gohugo.io/t/requesting-help/9132
[spf13]: https://github.com/spf13
[static site generator]: https://en.wikipedia.org/wiki/Static_site_generator
[support]: https://discourse.gohugo.io
[themes]: https://themes.gohugo.io/
[website]: https://gohugo.io
[windows]: https://gohugo.io/installation/windows

&lt;a href=&quot;https://gohugo.io/&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/gohugoio/gohugoioTheme/master/static/images/hugo-logo-wide.svg?sanitize=true&quot; alt=&quot;Hugo&quot; width=&quot;565&quot;&gt;&lt;/a&gt;

A fast and flexible static site generator built with love by [bep], [spf13], and [friends] in [Go].

---

[![GoDoc](https://godoc.org/github.com/gohugoio/hugo?status.svg)](https://godoc.org/github.com/gohugoio/hugo)
[![Tests on Linux, MacOS and Windows](https://github.com/gohugoio/hugo/workflows/Test/badge.svg)](https://github.com/gohugoio/hugo/actions?query=workflow%3ATest)
[![Go Report Card](https://goreportcard.com/badge/github.com/gohugoio/hugo)](https://goreportcard.com/report/github.com/gohugoio/hugo)

[Website] | [Installation] | [Documentation] | [Support] | [Contributing] | &lt;a rel=&quot;me&quot; href=&quot;https://fosstodon.org/@gohugoio&quot;&gt;Mastodon&lt;/a&gt;

## Overview

Hugo is a [static site generator] written in [Go], optimized for speed and designed for flexibility. With its advanced templating system and fast asset pipelines, Hugo renders a complete site in seconds, often less.

Due to its flexible framework, multilingual support, and powerful taxonomy system, Hugo is widely used to create:

- Corporate, government, nonprofit, education, news, event, and project sites
- Documentation sites
- Image portfolios
- Landing pages
- Business, professional, and personal blogs
- Resumes and CVs

Use Hugo&#039;s embedded web server during development to instantly see changes to content, structure, behavior, and presentation. Then deploy the site to your host, or push changes to your Git provider for automated builds and deployment.

Hugo&#039;s fast asset pipelines include:

- Image processing &amp;ndash; Convert, resize, crop, rotate, adjust colors, apply filters, overlay text and images, and extract EXIF data
- JavaScript bundling &amp;ndash; Transpile TypeScript and JSX to JavaScript, bundle, tree shake, minify, create source maps, and perform SRI hashing.
- Sass processing &amp;ndash; Transpile Sass to CSS, bundle, tree shake, minify, create source maps, perform SRI hashing, and integrate with PostCSS
- Tailwind CSS processing &amp;ndash; Compile Tailwind CSS utility classes into standard CSS, bundle, tree shake, optimize, minify, perform SRI hashing, and integrate with PostCSS

And with [Hugo Modules], you can share content, assets, data, translations, themes, templates, and configuration with other projects via public or private Git repositories.

See the [features] section of the documentation for a comprehensive summary of Hugo&#039;s capabilities.

## Sponsors

&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p float=&quot;left&quot;&gt;
  &lt;a href=&quot;https://www.jetbrains.com/go/?utm_source=OSS&amp;utm_medium=referral&amp;utm_campaign=hugo&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/gohugoio/hugoDocs/master/assets/images/sponsors/goland.svg&quot; width=&quot;200&quot; alt=&quot;The complete IDE crafted for professional Go developers.&quot;&gt;&lt;/a&gt;
  &amp;nbsp;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://cloudcannon.com/hugo-cms/?utm_campaign=HugoSponsorship&amp;utm_source=sponsor&amp;utm_content=gohugo&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/gohugoio/hugoDocs/master/assets/images/sponsors/cloudcannon-cms-logo.svg&quot; width=&quot;200&quot; alt=&quot;CloudCannon&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

## Editions

Hugo offers a standard edition with core features, plus extended and extended/deploy editions with more. Use the standard edition unless you need the features below.

Feature|extended edition|extended/deploy edition
:--|:-:|:-:
[Transpile Sass to CSS] via embedded LibSass. Note that embedded LibSass was deprecated in v0.153.0 and will be removed in a future release. Use the [Dart Sass] transpiler instead, which is compatible with any edition.|:heavy_check_mark:|:heavy_check_mark:
Deploy your site directly to a Google Cloud Storage bucket, an AWS S3 bucket, or an Azure Storage container. See&amp;nbsp;[details].|:x:|:heavy_check_mark:

[dart sass]: https://gohugo.io/functions/css/sass/#dart-sass
[transpile sass to css]: https://gohugo.io/functions/css/sass/
[details]: https://gohugo.io/hosting-and-deployment/hugo-deploy/

## Installation

Install Hugo from a [prebuilt binary], package manager, or package repository. Please see the installation instructions for your operating system:

- [macOS]
- [Linux]
- [Windows]
- [DragonFly BSD, FreeBSD, NetBSD, and OpenBSD]

## Build from source

Prerequisites to build Hugo from source:

- Standard edition: Go 1.24.0 or later
- Extended edition: Go 1.24.0 or later, and GCC
- Extended/deploy edition: Go 1.24.0 or later, and GCC

Build the standard edition:

```text
go install github.com/gohugoio/hugo@latest
```

Build the extended edition:

```text
CGO_ENABLED=1 go install -tags extended github.com/gohugoio/hugo@latest
```

Build the extended/deploy edition:

```text
CGO_ENABLED=1 go install -tags extended,withdeploy github.com/gohugoio/hugo@latest
```

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=gohugoio/hugo&amp;type=Timeline)](https://star-history.com/#gohugoio/hugo&amp;Timeline)

## Documentation

Hugo&#039;s [documentation] includes installation instructions, a quick start guide, conceptual explanations, reference information, and examples.

Please submit documentation issues and pull requests to the [documentation repository].

## Support

Please **do not use the issue queue** for questions or troubleshooting. Unless you are certain that your issue is a software defect, use the [forum].

Hugo‚Äôs [forum] is an active community of users and developers who answer questions, share knowledge, and provide examples. A quick search of over 20,000 topics will often answer your question. Please be sure to read about [requesting help] before asking your first question.

## Contributing

You can contribute to the Hugo project by:

- Answering questions on the [forum]
- Improving the [documentation]
- Monitoring the [issue queue]
- Creating or improving [themes]
- Squashing [bugs]

Please submit documentation issues and pull requests to the [documentation repository].

If you have an idea for an enhancement or new feature, create a new topic on the [forum] in the &quot;Feature&quot; category. This will help you to:

- Determine if the capability already exists
- Measure interest
- Refine the concept

If there is sufficient interest, [create a proposal]. Do not submit a pull request until the project lead accepts the proposal.

For a complete guide to contributing to Hugo, see the [Contribution Guide](CONTRIBUTING.md).

## Dependencies

Hugo stands on the shoulders of great open source libraries. Run `hugo env --logLevel info` to display a list of dependencies.

&lt;details&gt;
&lt;summary&gt;See current dependencies&lt;/summary&gt;

```text
github.com/BurntSushi/locker=&quot;v0.0.0-20171006230638-a6e239ea1c69&quot;
github.com/JohannesKaufmann/dom=&quot;v0.2.0&quot;
github.com/JohannesKaufmann/html-to-markdown/v2=&quot;v2.5.0&quot;
github.com/alecthomas/chroma/v2=&quot;v2.21.1&quot;
github.com/aymerick/douceur=&quot;v0.2.0&quot;
github.com/bep/clocks=&quot;v0.5.0&quot;
github.com/bep/debounce=&quot;v1.2.0&quot;
github.com/bep/gitmap=&quot;v1.9.0&quot;
github.com/bep/goat=&quot;v0.5.0&quot;
github.com/bep/godartsass/v2=&quot;v2.5.0&quot;
github.com/bep/golibsass=&quot;v1.2.0&quot;
github.com/bep/goportabletext=&quot;v0.1.0&quot;
github.com/bep/helpers=&quot;v0.6.0&quot;
github.com/bep/imagemeta=&quot;v0.12.0&quot;
github.com/bep/lazycache=&quot;v0.8.0&quot;
github.com/bep/logg=&quot;v0.4.0&quot;
github.com/bep/mclib=&quot;v1.20400.20402&quot;
github.com/bep/overlayfs=&quot;v0.10.0&quot;
github.com/bep/simplecobra=&quot;v0.6.1&quot;
github.com/bep/textandbinarywriter=&quot;v0.0.0-20251212174530-cd9f0732f60f&quot;
github.com/bep/tmc=&quot;v0.5.1&quot;
github.com/bits-and-blooms/bitset=&quot;v1.24.4&quot;
github.com/cespare/xxhash/v2=&quot;v2.3.0&quot;
github.com/clbanning/mxj/v2=&quot;v2.7.0&quot;
github.com/clipperhouse/displaywidth=&quot;v0.6.0&quot;
github.com/clipperhouse/stringish=&quot;v0.1.1&quot;
github.com/clipperhouse/uax29/v2=&quot;v2.3.0&quot;
github.com/cpuguy83/go-md2man/v2=&quot;v2.0.6&quot;
github.com/disintegration/gift=&quot;v1.2.1&quot;
github.com/dlclark/regexp2=&quot;v1.11.5&quot;
github.com/evanw/esbuild=&quot;v0.27.2&quot;
github.com/fatih/color=&quot;v1.18.0&quot;
github.com/frankban/quicktest=&quot;v1.14.6&quot;
github.com/fsnotify/fsnotify=&quot;v1.9.0&quot;
github.com/getkin/kin-openapi=&quot;v0.133.0&quot;
github.com/go-openapi/jsonpointer=&quot;v0.21.0&quot;
github.com/go-openapi/swag=&quot;v0.23.0&quot;
github.com/gobuffalo/flect=&quot;v1.0.3&quot;
github.com/gobwas/glob=&quot;v0.2.3&quot;
github.com/goccy/go-yaml=&quot;v1.19.1&quot;
github.com/gohugoio/go-i18n/v2=&quot;v2.1.3-0.20251018145728-cfcc22d823c6&quot;
github.com/gohugoio/go-radix=&quot;v1.2.0&quot;
github.com/gohugoio/hashstructure=&quot;v0.6.0&quot;
github.com/gohugoio/httpcache=&quot;v0.8.0&quot;
github.com/gohugoio/hugo-goldmark-extensions/extras=&quot;v0.5.0&quot;
github.com/gohugoio/hugo-goldmark-extensions/passthrough=&quot;v0.3.1&quot;
github.com/gohugoio/locales=&quot;v0.14.0&quot;
github.com/gohugoio/localescompressed=&quot;v1.0.1&quot;
github.com/google/go-cmp=&quot;v0.7.0&quot;
github.com/gorilla/css=&quot;v1.0.1&quot;
github.com/gorilla/websocket=&quot;v1.5.3&quot;
github.com/hairyhenderson/go-codeowners=&quot;v0.7.0&quot;
github.com/hashicorp/golang-lru/v2=&quot;v2.0.7&quot;
github.com/jdkato/prose=&quot;v1.2.1&quot;
github.com/josharian/intern=&quot;v1.0.0&quot;
github.com/kr/pretty=&quot;v0.3.1&quot;
github.com/kr/text=&quot;v0.2.0&quot;
github.com/kyokomi/emoji/v2=&quot;v2.2.13&quot;
github.com/mailru/easyjson=&quot;v0.7.7&quot;
github.com/makeworld-the-better-one/dither/v2=&quot;v2.4.0&quot;
github.com/marekm4/color-extractor=&quot;v1.2.1&quot;
github.com/mattn/go-colorable=&quot;v0.1.13&quot;
github.com/mattn/go-isatty=&quot;v0.0.20&quot;
github.com/mattn/go-runewidth=&quot;v0.0.19&quot;
github.com/microcosm-cc/bluemonday=&quot;v1.0.27&quot;
github.com/mitchellh/mapstructure=&quot;v1.5.1-0.20231216201459-8508981c8b6c&quot;
github.com/mohae/deepcopy=&quot;v0.0.0-20170929034955-c48cc78d4826&quot;
github.com/muesli/smartcrop=&quot;v0.3.0&quot;
github.com/niklasfasching/go-org=&quot;v1.9.1&quot;
github.com/oasdiff/yaml3=&quot;v0.0.0-20250309153720-d2182401db90&quot;
github.com/oasdiff/yaml=&quot;v0.0.0-20250309154309-f31be36b4037&quot;
github.com/olekukonko/cat=&quot;v0.0.0-20250911104152-50322a0618f6&quot;
github.com/olekukonko/errors=&quot;v1.1.0&quot;
github.com/olekukonko/ll=&quot;v0.1.3&quot;
github.com/olekukonko/tablewriter=&quot;v1.1.2&quot;
github.com/pbnjay/memory=&quot;v0.0.0-20210728143218-7b4eea64cf58&quot;
github.com/pelletier/go-toml/v2=&quot;v2.2.4&quot;
github.com/perimeterx/marshmallow=&quot;v1.1.5&quot;
github.com/pkg/browser=&quot;v0.0.0-20240102092130-5ac0b6a4141c&quot;
github.com/pkg/errors=&quot;v0.9.1&quot;
github.com/rogpeppe/go-internal=&quot;v1.14.1&quot;
github.com/russross/blackfriday/v2=&quot;v2.1.0&quot;
github.com/sass/dart-sass/compiler=&quot;1.97.1&quot;
github.com/sass/dart-sass/implementation=&quot;1.97.1&quot;
github.com/sass/dart-sass/protocol=&quot;3.2.0&quot;
github.com/spf13/afero=&quot;v1.15.0&quot;
github.com/spf13/cast=&quot;v1.10.0&quot;
github.com/spf13/cobra=&quot;v1.10.2&quot;
github.com/spf13/fsync=&quot;v0.10.1&quot;
github.com/spf13/pflag=&quot;v1.0.9&quot;
github.com/tdewolff/minify/v2=&quot;v2.24.8&quot;
github.com/tdewolff/parse/v2=&quot;v2.8.5&quot;
github.com/tetratelabs/wazero=&quot;v1.10.1&quot;
github.com/webmproject/libwebp=&quot;v1.6.0&quot;
github.com/woodsbury/decimal128=&quot;v1.3.0&quot;
github.com/yuin/goldmark-emoji=&quot;v1.0.6&quot;
github.com/yuin/goldmark=&quot;v1.7.13&quot;
go.uber.org/automaxprocs=&quot;v1.5.3&quot;
go.yaml.in/yaml/v3=&quot;v3.0.4&quot;
golang.org/x/crypto=&quot;v0.46.0&quot;
golang.org/x/image=&quot;v0.34.0&quot;
golang.org/x/mod=&quot;v0.31.0&quot;
golang.org/x/net=&quot;v0.48.0&quot;
golang.org/x/sync=&quot;v0.19.0&quot;
golang.org/x/sys=&quot;v0.39.0&quot;
golang.org/x/text=&quot;v0.32.0&quot;
golang.org/x/tools=&quot;v0.40.0&quot;
google.golang.org/protobuf=&quot;v1.36.10&quot;
gopkg.in/yaml.v3=&quot;v3.0.1&quot;
rsc.io/qr=&quot;v0.2.0&quot;
software.sslmate.com/src/go-pkcs12=&quot;v0.2.0&quot;
```
&lt;/details&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[googleapis/google-cloud-go]]></title>
            <link>https://github.com/googleapis/google-cloud-go</link>
            <guid>https://github.com/googleapis/google-cloud-go</guid>
            <pubDate>Thu, 01 Jan 2026 00:06:30 GMT</pubDate>
            <description><![CDATA[Google Cloud Client Libraries for Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/googleapis/google-cloud-go">googleapis/google-cloud-go</a></h1>
            <p>Google Cloud Client Libraries for Go.</p>
            <p>Language: Go</p>
            <p>Stars: 4,389</p>
            <p>Forks: 1,500</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># Google Cloud Client Libraries for Go

[![Go Reference](https://pkg.go.dev/badge/cloud.google.com/go.svg)](https://pkg.go.dev/cloud.google.com/go)

Go packages for [Google Cloud Platform](https://cloud.google.com) services.

## Installation

```bash
go get cloud.google.com/go/firestore@latest # Replace firestore with the package you want to use.
```

**NOTE:** Some of these packages are under development, and may occasionally
make backwards-incompatible changes.

## Supported APIs

For an updated list of all of our released APIs please see our
[reference docs](https://cloud.google.com/go/docs/reference).

## [Go Versions Supported](#supported-versions)

Our libraries are compatible with the two most recent major Go
releases, the same [policy](https://go.dev/doc/devel/release#policy) the Go
programming language follows. This means the currently supported versions are:

- Go 1.24
- Go 1.25

## Authentication

By default, each client library will use [Application Default Credentials](https://developers.google.com/identity/protocols/application-default-credentials)
(ADC) to automatically configure the credentials used in calling the API endpoint.
When using the libraries in a Google Cloud Platform environment such as Compute
Engine, Kubernetes Engine, or App Engine, no additional authentication steps are
necessary. See [Authentication methods at Google](https://cloud.google.com/docs/authentication)
and [Authenticate for using client libraries](https://cloud.google.com/docs/authentication/client-libraries)
for more information.

```go
client, err := storage.NewClient(ctx)
```

For applications running elsewhere, such as your local development environment,
you can use the `gcloud auth application-default login` command from the
[Google Cloud CLI](https://cloud.google.com/cli) to set user credentials in
your local filesystem. Application Default Credentials will automatically detect
these credentials. See [Set up ADC for a local development
environment](https://cloud.google.com/docs/authentication/set-up-adc-local-dev-environment)
for more information.

Alternately, you may need to provide an explicit path to your credentials. To authenticate
using a [service account](https://cloud.google.com/docs/authentication#service-accounts)
key file, either set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable to the path
to your key file, or programmatically pass
[`option.WithCredentialsFile`](https://pkg.go.dev/google.golang.org/api/option#WithCredentialsFile)
to the `NewClient` function of the desired package. For example:

```go
client, err := storage.NewClient(ctx, option.WithCredentialsFile(&quot;path/to/keyfile.json&quot;))
```

You can exert even more control over authentication by using the
[credentials](https://pkg.go.dev/cloud.google.com/go/auth/credentials) package to
create an [auth.Credentials](https://pkg.go.dev/cloud.google.com/go/auth#Credentials).
Then pass [`option.WithAuthCredentials`](https://pkg.go.dev/google.golang.org/api/option#WithAuthCredentials)
to the `NewClient` function:

```go
creds, err := credentials.DetectDefault(&amp;credentials.DetectOptions{...})
...
client, err := storage.NewClient(ctx, option.WithAuthCredentials(creds))
```

## Contributing

Contributions are welcome. Please, see the
[CONTRIBUTING](https://github.com/GoogleCloudPlatform/google-cloud-go/blob/main/CONTRIBUTING.md)
document for details.

Please note that this project is released with a Contributor Code of Conduct.
By participating in this project you agree to abide by its terms.
See [Contributor Code of Conduct](https://github.com/GoogleCloudPlatform/google-cloud-go/blob/main/CONTRIBUTING.md#contributor-code-of-conduct)
for more information.

## Links

- [Go on Google Cloud](https://cloud.google.com/go/home)
- [Getting started with Go on Google Cloud](https://cloud.google.com/go/getting-started)
- [App Engine Quickstart](https://cloud.google.com/appengine/docs/standard/go/quickstart)
- [Cloud Functions Quickstart](https://cloud.google.com/functions/docs/quickstart-go)
- [Cloud Run Quickstart](https://cloud.google.com/run/docs/quickstarts/build-and-deploy#go)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>