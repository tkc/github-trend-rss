<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Sat, 01 Nov 2025 00:52:49 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-collector]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-collector</link>
            <guid>https://github.com/open-telemetry/opentelemetry-collector</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:49 GMT</pubDate>
            <description><![CDATA[OpenTelemetry Collector]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-collector">open-telemetry/opentelemetry-collector</a></h1>
            <p>OpenTelemetry Collector</p>
            <p>Language: Go</p>
            <p>Stars: 6,154</p>
            <p>Forks: 1,766</p>
            <p>Stars today: 85 stars today</p>
            <h2>README</h2><pre>---

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/getting-started/&quot;&gt;Getting Started&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;Getting Involved&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;Getting In Touch&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/actions/workflows/build-and-test.yml?query=branch%3Amain&quot;&gt;
    &lt;img alt=&quot;Build Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector/build-and-test.yml?branch=main&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector&quot;&gt;
    &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/open-telemetry/opentelemetry-collector/branch/main/&quot;&gt;
    &lt;img alt=&quot;Codecov Status&quot; src=&quot;https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest by date including pre-releases)&quot; src=&quot;https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector?include_prereleases&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;/br&gt;
  &lt;a href=&quot;https://www.bestpractices.dev/projects/8404&quot;&gt;&lt;img src=&quot;https://www.bestpractices.dev/projects/8404/badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:opentelemetry&quot;&gt;
    &lt;img alt=&quot;Fuzzing Status&quot; src=&quot;https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry.svg&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;docs/vision.md&quot;&gt;Vision&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/configuration/&quot;&gt;Configuration&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/internal-telemetry/#use-internal-telemetry-to-monitor-the-collector&quot;&gt;Monitoring&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;docs/security-best-practices.md&quot;&gt;Security&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://pkg.go.dev/go.opentelemetry.io/collector&quot;&gt;Package&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

---

# &lt;img src=&quot;https://opentelemetry.io/img/logos/opentelemetry-logo-nav.png&quot; alt=&quot;OpenTelemetry Icon&quot; width=&quot;45&quot; height=&quot;&quot;&gt; OpenTelemetry Collector

The OpenTelemetry Collector offers a vendor-agnostic implementation on how to
receive, process and export telemetry data. In addition, it removes the need
to run, operate and maintain multiple agents/collectors in order to support
open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) to
multiple open-source or commercial back-ends.

Objectives:

- Usable: Reasonable default configuration, supports popular protocols, runs and collects out of the box.
- Performant: Highly stable and performant under varying loads and configurations.
- Observable: An exemplar of an observable service.
- Extensible: Customizable without touching the core code.
- Unified: Single codebase, deployable as an agent or collector with support for traces, metrics and logs.

## Community

The OpenTelemetry Collector SIG is present at the [#otel-collector](https://cloud-native.slack.com/archives/C01N6P7KR6W)
channel on the CNCF Slack and [meets once a week](https://github.com/open-telemetry/community#implementation-sigs) via
video calls. Everyone is invited to join those calls, which typically serves the following purposes:

- meet the humans behind the project
- get an opinion about specific proposals
- look for a sponsor for a proposed component after trying already via GitHub and Slack
- get attention to a specific pull-request that got stuck and is difficult to discuss asynchronously

We rotate our video calls between three time slots, in order to
allow everyone to join at least once every three meetings. The rotation order is as follows:

Tuesday:

- [17:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=1700)

Wednesday:

- [09:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=0900)
- [05:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=0500)

Contributors to the project are also welcome to have ad-hoc meetings for synchronous discussions about specific points.
Post a note in #otel-collector-dev on Slack inviting others, specifying the topic to be discussed. Unless there are strong
reasons to keep the meeting private, please make it an open invitation for other contributors to join. Try also to
identify who would be the other contributors interested on that topic and in which timezones they are.

Remember that our source of truth is GitHub: every decision made via Slack or video calls has to be recorded in the
relevant GitHub issue. Ideally, the agenda items from the meeting notes would include a link to the issue or pull
request where a discussion is happening already. We acknowledge that not everyone can join Slack or the synchronous
calls and don&#039;t want them to feel excluded.

## Supported OTLP version

This code base is currently built against using OTLP protocol v1.5.0,
considered Stable. [See the OpenTelemetry Protocol Stability
definition
here.](https://github.com/open-telemetry/opentelemetry-proto?tab=readme-ov-file#stability-definition)

## Stability levels

See [Stability Levels and versioning](docs/component-stability.md) for more details.

## Compatibility

When used as a library, the OpenTelemetry Collector attempts to track the currently supported versions of Go, as [defined by the Go team](https://go.dev/doc/devel/release#policy).
Removing support for an unsupported Go version is not considered a breaking change.

Support for Go versions on the OpenTelemetry Collector is updated as follows:

1. The first release after the release of a new Go minor version `N` will add build and tests steps for the new Go minor version.
2. The first release after the release of a new Go minor version `N` will remove support for Go version `N-2`.

Official OpenTelemetry Collector distro binaries will be built with a release in the latest Go minor version series.

## Verifying the images signatures

&gt; [!NOTE]
&gt; To verify a signed artifact or blob, first [install Cosign](https://docs.sigstore.dev/cosign/system_config/installation/), then follow the instructions below.

We are signing the images `otel/opentelemetry-collector` and `otel/opentelemetry-collector-contrib` using [sigstore cosign](https://github.com/sigstore/cosign) tool and to verify the signatures you can run the following command:

```console
$ cosign verify \
  --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/&lt;RELEASE_TAG&gt; \
  --certificate-oidc-issuer=https://token.actions.githubusercontent.com \
  &lt;OTEL_COLLECTOR_IMAGE&gt;
```

where:

- `&lt;RELEASE_TAG&gt;`: is the release that you want to validate
- `&lt;OTEL_COLLECTOR_IMAGE&gt;`: is the image that you want to check

Example:

```console
$ cosign verify --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0 --certificate-oidc-issuer=https://token.actions.githubusercontent.com ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0

Verification for ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0 --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - Existence of the claims in the transparency log was verified offline
  - The code-signing certificate was verified using trusted certificate authority certificates

[{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:{&quot;1.3.6.1.4.1.57264.1.1&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;1.3.6.1.4.1.57264.1.2&quot;:&quot;push&quot;,&quot;1.3.6.1.4.1.57264.1.3&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;1.3.6.1.4.1.57264.1.4&quot;:&quot;Release Contrib&quot;,&quot;1.3.6.1.4.1.57264.1.5&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;1.3.6.1.4.1.57264.1.6&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;Bundle&quot;:{&quot;SignedEntryTimestamp&quot;:&quot;MEUCIQDdlmNeKXQrHnonwWiHLhLLwFDVDNoOBCn2sv85J9P8mgIgDQFssWJImo1hn38VlojvSCL7Qq5FMmtnGu0oLsNdOm8=&quot;,&quot;Payload&quot;:{&quot;body&quot;:&quot;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&quot;,&quot;integratedTime&quot;:1712809120,&quot;logIndex&quot;:84797936,&quot;logID&quot;:&quot;c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d&quot;}},&quot;Issuer&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;Subject&quot;:&quot;https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0&quot;,&quot;githubWorkflowName&quot;:&quot;Release Contrib&quot;,&quot;githubWorkflowRef&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;githubWorkflowRepository&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;githubWorkflowSha&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;githubWorkflowTrigger&quot;:&quot;push&quot;}},{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:{&quot;1.3.6.1.4.1.57264.1.1&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;1.3.6.1.4.1.57264.1.2&quot;:&quot;push&quot;,&quot;1.3.6.1.4.1.57264.1.3&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;1.3.6.1.4.1.57264.1.4&quot;:&quot;Release Contrib&quot;,&quot;1.3.6.1.4.1.57264.1.5&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;1.3.6.1.4.1.57264.1.6&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;Bundle&quot;:{&quot;SignedEntryTimestamp&quot;:&quot;MEUCIQD1ehDnPO6fzoPIpeQ3KFuYHHBiX7RcEbpo9B2r7JAlzwIgZ1bsuQz7gAXbNU1IEdsTQgfAnRk3xVXO16GnKXM2sAQ=&quot;,&quot;Payload&quot;:{&quot;body&quot;:&quot;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

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[smartcontractkit/chainlink]]></title>
            <link>https://github.com/smartcontractkit/chainlink</link>
            <guid>https://github.com/smartcontractkit/chainlink</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:48 GMT</pubDate>
            <description><![CDATA[node of the decentralized oracle network, bridging on and off-chain computation]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/smartcontractkit/chainlink">smartcontractkit/chainlink</a></h1>
            <p>node of the decentralized oracle network, bridging on and off-chain computation</p>
            <p>Language: Go</p>
            <p>Stars: 8,022</p>
            <p>Forks: 1,896</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://chain.link&quot; target=&quot;_blank&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/smartcontractkit/chainlink/develop/docs/logo-chainlink-blue.svg&quot; width=&quot;225&quot; alt=&quot;Chainlink logo&quot;&gt;
&lt;/a&gt;
&lt;/p&gt;
&lt;br/&gt;

[![GitHub tag (latest SemVer)](https://img.shields.io/github/v/tag/smartcontractkit/chainlink?style=flat-square)](https://hub.docker.com/r/smartcontract/chainlink/tags)
[![GitHub license](https://img.shields.io/github/license/smartcontractkit/chainlink?style=flat-square)](https://github.com/smartcontractkit/chainlink/blob/master/LICENSE)
[![GitHub workflow changeset](https://img.shields.io/github/actions/workflow/status/smartcontractkit/chainlink/changeset.yml)](https://github.com/smartcontractkit/chainlink/actions/workflows/changeset.yml?query=workflow%3AChangeset)
[![GitHub contributors](https://img.shields.io/github/contributors-anon/smartcontractkit/chainlink?style=flat-square)](https://github.com/smartcontractkit/chainlink/graphs/contributors)
[![GitHub commit activity](https://img.shields.io/github/commit-activity/y/smartcontractkit/chainlink?style=flat-square)](https://github.com/smartcontractkit/chainlink/commits/master)
[![Official documentation](https://img.shields.io/static/v1?label=docs&amp;message=latest&amp;color=blue)](https://docs.chain.link/)

[Chainlink](https://chain.link/) expands the capabilities of smart contracts by enabling access to real-world data and off-chain computation while maintaining the security and reliability guarantees inherent to blockchain technology.

This repo contains the Chainlink core node and contracts. The core node is the bundled binary available to be run by node operators participating in a [decentralized oracle network](https://link.smartcontract.com/whitepaper).
All major release versions have pre-built docker images available for download from the [Chainlink dockerhub](https://hub.docker.com/r/smartcontract/chainlink/tags).
If you are interested in contributing please see our [contribution guidelines](./docs/CONTRIBUTING.md).
If you are here to report a bug or request a feature, please [check currently open Issues](https://github.com/smartcontractkit/chainlink/issues).
For more information about how to get started with Chainlink, check our [official documentation](https://docs.chain.link/).

## Community

Chainlink has an active and ever growing community. [Discord](https://discordapp.com/invite/aSK4zew)
is the primary communication channel used for day to day communication,
answering development questions, and aggregating Chainlink related content. Take
a look at the [community docs](./docs/COMMUNITY.md) for more information
regarding Chainlink social accounts, news, and networking.

## Build Chainlink

1. [Install Go 1.23](https://golang.org/doc/install), and add your GOPATH&#039;s [bin directory to your PATH](https://golang.org/doc/code.html#GOPATH)
   - Example Path for macOS `export PATH=$GOPATH/bin:$PATH` &amp; `export GOPATH=/Users/$USER/go`
2. Install [NodeJS v20](https://nodejs.org/en/download/package-manager/) &amp; [pnpm v10 via npm](https://pnpm.io/installation#using-npm).
   - It might be easier long term to use [nvm](https://nodejs.org/en/download/package-manager/#nvm) to switch between node versions for different projects. For example, assuming $NODE_VERSION was set to a valid version of NodeJS, you could run: `nvm install $NODE_VERSION &amp;&amp; nvm use $NODE_VERSION`
3. Install [Postgres (&gt;= 12.x)](https://wiki.postgresql.org/wiki/Detailed_installation_guides). It is recommended to run the latest major version of postgres.
   - Note if you are running the official Chainlink docker image, the highest supported Postgres version is 16.x due to the bundled client.
   - You should [configure Postgres](https://www.postgresql.org/docs/current/ssl-tcp.html) to use SSL connection (or for testing you can set `?sslmode=disable` in your Postgres query string).
4. Download Chainlink: `git clone https://github.com/smartcontractkit/chainlink &amp;&amp; cd chainlink`
5. Build and install Chainlink: `make install`
6. Run the node: `chainlink help`

For the latest information on setting up a development environment, see the [Development Setup Guide](https://github.com/smartcontractkit/chainlink/wiki/Development-Setup-Guide).

### Build from PR

To build an unofficial testing-only image from a feature branch or PR. You can do one of the following:

1. Send a workflow dispatch event from our [`docker-build` workflow](https://github.com/smartcontractkit/chainlink/actions/workflows/docker-build.yml).
2. Add the `build-publish` label to your PR and then either retry the `docker-build` workflow, or push a new commit.

### Build Plugins

Plugins are defined in yaml files within the `plugins/` directory. Each plugin file is a yaml file and has a `plugins.` prefix name. Plugins are installed with [loopinstall](https://github.com/smartcontractkit/chainlink-common/tree/main/pkg/loop/cmd/loopinstall).

To install the plugins, run:

```bash
make install-plugins
```

Some plugins (such as those in `plugins/plugins.private.yaml`) reference private GitHub repositories. To build these plugins, you must have a GITHUB_TOKEN environment variable set, or preferably use the [gh](https://cli.github.com/manual/gh) GitHub CLI tool to use the [GitHub CLI credential helper](https://cli.github.com/manual/gh_auth_setup-git) like:

```shell
# Sets up a credential helper.
gh auth setup-git
```

Then you can build the plugins with:

```shell
make install-plugins-private
```

### Docker Builds

To build the experimental &quot;plugins&quot; Chainlink docker image, you can run this from the root of the repository:

```shell
# The GITHUB_TOKEN is required to access private repos which are used by some plugins.
export GITHUB_TOKEN=$(gh auth token) # requires the `gh` cli tool.
make docker-plugins
```

### Ethereum Execution Client Requirements

In order to run the Chainlink node you must have access to a running Ethereum node with an open websocket connection.
Any Ethereum based network will work once you&#039;ve [configured](https://github.com/smartcontractkit/chainlink#configure) the chain ID.
Ethereum node versions currently tested and supported:

[Officially supported]

- [Parity/Openethereum](https://github.com/openethereum/openethereum) (NOTE: Parity is deprecated and support for this client may be removed in future)
- [Geth](https://github.com/ethereum/go-ethereum/releases)
- [Besu](https://github.com/hyperledger/besu)

[Supported but broken]
These clients are supported by Chainlink, but have bugs that prevent Chainlink from working reliably on these execution clients.

- [Nethermind](https://github.com/NethermindEth/nethermind)
  Blocking issues:
  - ~https://github.com/NethermindEth/nethermind/issues/4384~
- [Erigon](https://github.com/ledgerwatch/erigon)
  Blocking issues:
  - https://github.com/ledgerwatch/erigon/discussions/4946
  - https://github.com/ledgerwatch/erigon/issues/4030#issuecomment-1113964017

We cannot recommend specific version numbers for ethereum nodes since the software is being continually updated, but you should usually try to run the latest version available.

## Running a local Chainlink node

**NOTE**: By default, chainlink will run in TLS mode. For local development you can disable this by using a `dev build` using `make chainlink-dev` and setting the TOML fields:

```toml
[WebServer]
SecureCookies = false
TLS.HTTPSPort = 0

[Insecure]
DevWebServer = true
```

Alternatively, you can generate self signed certificates using `tools/bin/self-signed-certs` or [manually](https://github.com/smartcontractkit/chainlink/wiki/Creating-Self-Signed-Certificates).

To start your Chainlink node, simply run:

```bash
chainlink node start
```

By default this will start on port 6688. You should be able to access the UI at [http://localhost:6688/](http://localhost:6688/).

Chainlink provides a remote CLI client as well as a UI. Once your node has started, you can open a new terminal window to use the CLI. You will need to log in to authorize the client first:

```bash
chainlink admin login
```

(You can also set `ADMIN_CREDENTIALS_FILE=/path/to/credentials/file` in future if you like, to avoid having to login again).

Now you can view your current jobs with:

```bash
chainlink jobs list
```

To find out more about the Chainlink CLI, you can always run `chainlink help`.

Check out the [doc](https://docs.chain.link/) pages on [Jobs](https://docs.chain.link/docs/jobs/) to learn more about how to create Jobs.

### Configuration

Node configuration is managed by a combination of environment variables and direct setting via API/UI/CLI.

Check the [official documentation](https://docs.chain.link/docs/configuration-variables) for more information on how to configure your node.

### External Adapters

External adapters are what make Chainlink easily extensible, providing simple integration of custom computations and specialized APIs. A Chainlink node communicates with external adapters via a simple REST API.

For more information on creating and using external adapters, please see our [external adapters page](https://docs.chain.link/docs/external-adapters).

## Verify Official Chainlink Releases

We use `cosign` with OIDC keyless signing during the [Build, Sign and Publish Chainlink](https://github.com/smartcontractkit/chainlink/actions/workflows/build-publish.yml) workflow.

It is encourage for any node operator building from the official Chainlink docker image to verify the tagged release version was did indeed built from this workflow.

You will need `cosign` in order to do this verification. [Follow the instruction here to install cosign](https://docs.sigstore.dev/system_config/installation/).

```bash
# tag is the tagged release version - ie. 2.16.0
cosign verify index.docker.io/smartcontract/chainlink:${tag} \
      --certificate-oidc-issuer https://token.actions.githubusercontent.com \
      --certificate-identity &quot;https://github.com/smartcontractkit/chainlink/.github/workflows/build-publish.yml@refs/tags/v${tag}&quot;
```

## Development

### Running tests

1. [Install pnpm 10 via npm](https://pnpm.io/installation#using-npm)

2. Install [gencodec](https://github.com/fjl/gencodec) and [jq](https://stedolan.github.io/jq/download/) to be able to run `go generate ./...` and `make abigen`

3. Install mockery

`make mockery`

Using the `make` command will install the correct version.

4. Generate and compile static assets:

```bash
make generate
```

5. Prepare your development environment:

The tests require a postgres database. In turn, the environment variable
`CL_DATABASE_URL` must be set to value that can connect to `_test` database, and the user must be able to create and drop
the given `_test` database.

Note: Other environment variables should not be set for all tests to pass

There helper script for initial setup to create an appropriate test user. It requires postgres to be running on localhost at port 5432. You will be prompted for
the `postgres` user password

```bash
make setup-testdb
```

This script will save the `CL_DATABASE_URL` in `.dbenv`

Changes to database require migrations to be run. Similarly, `pull`&#039;ing the repo may require migrations to run.
After the one-time setup above:

```
source .dbenv
make testdb
```

If you encounter the error `database accessed by other users (SQLSTATE 55006) exit status 1`
and you want force the database creation then use

```
source .dbenv
make testdb-force
```

7. Run tests:

```bash
go test ./...
```

#### Notes

- The `parallel` flag can be used to limit CPU usage, for running tests in the background (`-parallel=4`) - the default is `GOMAXPROCS`
- The `p` flag can be used to limit the number of _packages_ tested concurrently, if they are interferring with one another (`-p=1`)
- The `-short` flag skips tests which depend on the database, for quickly spot checking simpler tests in around one minute

#### Race Detector

As of Go 1.1, the runtime includes a data race detector, enabled with the `-race` flag. This is used in CI via the
`tools/bin/go_core_race_tests` script. If the action detects a race, the artifact on the summary page will include
`race.*` files with detailed stack traces.

&gt; _**It will not issue false positives, so take its warnings seriously.**_

For local, targeted race detection, you can run:

```bash
GORACE=&quot;log_path=$PWD/race&quot; go test -race ./core/path/to/pkg -count 10
GORACE=&quot;log_path=$PWD/race&quot; go test -race ./core/path/to/pkg -count 100 -run TestFooBar/sub_test
```

https://go.dev/doc/articles/race_detector

#### Fuzz tests

As of Go 1.18, fuzz tests `func FuzzXXX(*testing.F)` are included as part of the normal test suite, so existing cases are executed with `go test`.

Additionally, you can run active fuzzing to search for new cases:

```bash
go test ./pkg/path -run=XXX -fuzz=FuzzTestName
```

https://go.dev/doc/fuzz/

### Go Modules

This repository contains three Go modules:

```mermaid
flowchart RL
    github.com/smartcontractkit/chainlink/v2
    github.com/smartcontractkit/chainlink/integration-tests --&gt; github.com/smartcontractkit/chainlink/v2
    github.com/smartcontractkit/chainlink/core/scripts --&gt; github.com/smartcontractkit/chainlink/v2

```

The `integration-tests` and `core/scripts` modules import the root module using a relative replace in their `go.mod` files,
so dependency changes in the root `go.mod` often require changes in those modules as well. After making a change, `go mod tidy`
can be run on all three modules using:

```
make gomodtidy
```

### Code Generation

Go generate is used to generate mocks in this project. Mocks are generated with [mockery](https://github.com/vektra/mockery) and live in core/internal/mocks.

### Nix

A [shell.nix](https://nixos.wiki/wiki/Development_environment_with_nix-shell) is provided for use with the [Nix package manager](https://nixos.org/). By default,we utilize the shell through [Nix Flakes](https://nixos.wiki/wiki/Flakes).

Nix defines a declarative, reproducible development environment. Flakes version use deterministic, frozen (`flake.lock`) dependencies to
gain more consistency/reproducibility on the built artifacts.

To use it:

1. Install [nix package manager](https://nixos.org/download.html) in your system.

- Enable [flakes support](https://nixos.wiki/wiki/Flakes#Enable_flakes)

2. Run `nix develop`. You will be put in shell containing all the dependencies.

- Optionally, `nix develop --command $SHELL` will make use of your current shell instead of the default (bash).
- You can use `direnv` to enable it automatically when `cd`-ing into the folder; for that, enable [nix-direnv](https://github.com/nix-community/nix-direnv) and `use flake` on it.

3. Create a local postgres database:

```sh
mkdir -p $PGDATA &amp;&amp; cd $PGDATA/
initdb
pg_ctl -l postgres.log -o &quot;--unix_socket_directories=&#039;$PWD&#039;&quot; start
createdb chainlink_test -h localhost
createuser --superuser --password chainlink -h localhost
# then type a test password, e.g.: chainlink, and set it in shell.nix CL_DATABASE_URL
```

4. When re-entering project, you can restart postgres: `cd $PGDATA; pg_ctl -l postgres.log -o &quot;--unix_socket_directories=&#039;$PWD&#039;&quot; start`
   Now you can run tests or compile code as usual.
5. When you&#039;re done, stop it: `cd $PGDATA; pg_ctl -o &quot;--unix_socket_directories=&#039;$PWD&#039;&quot; stop`

### Changesets

We use [changesets](https://github.com/changesets/changesets) to manage versioning for libs and the services.

Every PR that modifies any configuration or code, should most likely accompanied by a changeset file.

To install `changesets`:

1. Install `pnpm` if it is not already installed - [docs](https://pnpm.io/installation).
2. Run `pnpm install`.

Either after or before you create a commit, run the `pnpm changeset` command to create an accompanying changeset entry which will reflect on the CHANGELOG for the next release.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),

and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

### Tips

For more tips on how to build and test Chainlink, see our [development tips page](https://github.com/smartcontractkit/chainlink/wiki/Development-Tips).

### Contributing

Contributions are welcome to Chainlink&#039;s source code.

Please check out our [contributing guidelines](./docs/CONTRIBUTING.md) for more details.

Thank you!
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[helm/helm]]></title>
            <link>https://github.com/helm/helm</link>
            <guid>https://github.com/helm/helm</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:47 GMT</pubDate>
            <description><![CDATA[The Kubernetes Package Manager]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/helm/helm">helm/helm</a></h1>
            <p>The Kubernetes Package Manager</p>
            <p>Language: Go</p>
            <p>Stars: 28,852</p>
            <p>Forks: 7,379</p>
            <p>Stars today: 97 stars today</p>
            <h2>README</h2><pre># Helm

[![Build Status](https://github.com/helm/helm/workflows/release/badge.svg)](https://github.com/helm/helm/actions?workflow=release)
[![Go Report Card](https://goreportcard.com/badge/helm.sh/helm/v4)](https://goreportcard.com/report/helm.sh/helm/v4)
[![GoDoc](https://img.shields.io/static/v1?label=godoc&amp;message=reference&amp;color=blue)](https://pkg.go.dev/helm.sh/helm/v4)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3131/badge)](https://bestpractices.coreinfrastructure.org/projects/3131)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/helm/helm/badge)](https://scorecard.dev/viewer/?uri=github.com/helm/helm)
[![LFX Health Score](https://insights.production.lfx.dev/api/badge/health-score?project=helm)](https://insights.linuxfoundation.org/project/helm)

Helm is a tool for managing Charts. Charts are packages of pre-configured Kubernetes resources.

Use Helm to:

- Find and use [popular software packaged as Helm Charts](https://artifacthub.io/packages/search?kind=0) to run in Kubernetes
- Share your own applications as Helm Charts
- Create reproducible builds of your Kubernetes applications
- Intelligently manage your Kubernetes manifest files
- Manage releases of Helm packages

## Helm in a Handbasket

Helm is a tool that streamlines installing and managing Kubernetes applications.
Think of it like apt/yum/homebrew for Kubernetes.

- Helm renders your templates and communicates with the Kubernetes API
- Helm runs on your laptop, CI/CD, or wherever you want it to run.
- Charts are Helm packages that contain at least two things:
  - A description of the package (`Chart.yaml`)
  - One or more templates, which contain Kubernetes manifest files
- Charts can be stored on disk, or fetched from remote chart repositories
  (like Debian or RedHat packages)

## Helm Development and Stable Versions

Helm v4 is currently under development on the `main` branch. This is unstable and the APIs within the Go SDK and at the command line are changing.
Helm v3 (current stable) is maintained on the `dev-v3` branch. APIs there follow semantic versioning.

## Install

Binary downloads of the Helm client can be found on [the Releases page](https://github.com/helm/helm/releases/latest).

Unpack the `helm` binary and add it to your PATH and you are good to go!

If you want to use a package manager:

- [Homebrew](https://brew.sh/) users can use `brew install helm`.
- [Chocolatey](https://chocolatey.org/) users can use `choco install kubernetes-helm`.
- [Winget](https://learn.microsoft.com/en-us/windows/package-manager/) users can use `winget install Helm.Helm`.
- [Scoop](https://scoop.sh/) users can use `scoop install helm`.
- [Snapcraft](https://snapcraft.io/) users can use `snap install helm --classic`.
- [Flox](https://flox.dev) users can use `flox install kubernetes-helm`.

To rapidly get Helm up and running, start with the [Quick Start Guide](https://helm.sh/docs/intro/quickstart/).

See the [installation guide](https://helm.sh/docs/intro/install/) for more options,
including installing pre-releases.

## Docs

Get started with the [Quick Start guide](https://helm.sh/docs/intro/quickstart/) or plunge into the [complete documentation](https://helm.sh/docs).

## Roadmap

The [Helm roadmap uses GitHub milestones](https://github.com/helm/helm/milestones) to track the progress of the project.

The development of Helm v4 is currently happening on the `main` branch while the development of Helm v3, the stable branch, is happening on the `dev-v3` branch. Changes should be made to the `main` branch prior to being added to the `dev-v3` branch so that all changes are carried along to Helm v4.

## Community, discussion, contribution, and support

You can reach the Helm community and developers via the following channels:

- [Kubernetes Slack](https://kubernetes.slack.com):
  - [#helm-users](https://kubernetes.slack.com/messages/helm-users)
  - [#helm-dev](https://kubernetes.slack.com/messages/helm-dev)
  - [#charts](https://kubernetes.slack.com/messages/charts)
- Mailing List:
  - [Helm Mailing List](https://lists.cncf.io/g/cncf-helm)
- Developer Call: Thursdays at 9:30-10:00 Pacific ([meeting details](https://github.com/helm/community/blob/master/communication.md#meetings))

### Contribution

If you&#039;re interested in contributing, please refer to the [Contributing Guide](CONTRIBUTING.md) **before submitting a pull request**.

### Code of conduct

Participation in the Helm community is governed by the [Code of Conduct](code-of-conduct.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[aquasecurity/trivy]]></title>
            <link>https://github.com/aquasecurity/trivy</link>
            <guid>https://github.com/aquasecurity/trivy</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:46 GMT</pubDate>
            <description><![CDATA[Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aquasecurity/trivy">aquasecurity/trivy</a></h1>
            <p>Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more</p>
            <p>Language: Go</p>
            <p>Stars: 29,634</p>
            <p>Forks: 2,802</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;docs/imgs/logo.png&quot; width=&quot;200&quot;&gt;

[![GitHub Release][release-img]][release]
[![Test][test-img]][test]
[![Go Report Card][go-report-img]][go-report]
[![License: Apache-2.0][license-img]][license]
[![GitHub Downloads][github-downloads-img]][release]
![Docker Pulls][docker-pulls]

[ðŸ“– Documentation][docs]
&lt;/div&gt;

Trivy ([pronunciation][pronunciation]) is a comprehensive and versatile security scanner.
Trivy has *scanners* that look for security issues, and *targets* where it can find those issues.

Targets (what Trivy can scan):

- Container Image
- Filesystem
- Git Repository (remote)
- Virtual Machine Image
- Kubernetes

Scanners (what Trivy can find there):

- OS packages and software dependencies in use (SBOM)
- Known vulnerabilities (CVEs)
- IaC issues and misconfigurations
- Sensitive information and secrets
- Software licenses

Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the [Scanning Coverage] page.

To learn more, go to the [Trivy homepage][homepage] for feature highlights, or to the [Documentation site][docs] for detailed information.

## Quick Start

### Get Trivy

Trivy is available in most common distribution channels. The full list of installation options is available in the [Installation] page. Here are a few popular examples:

- `brew install trivy`
- `docker run aquasec/trivy`
- Download binary from &lt;https://github.com/aquasecurity/trivy/releases/latest/&gt;
- See [Installation] for more

Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the [Ecosystem] page. Here are a few popular examples:

- [GitHub Actions](https://github.com/aquasecurity/trivy-action)
- [Kubernetes operator](https://github.com/aquasecurity/trivy-operator)
- [VS Code plugin](https://github.com/aquasecurity/trivy-vscode-extension)
- See [Ecosystem] for more

### Canary builds
There are canary builds ([Docker Hub](https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;name=canary), [GitHub](https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary), [ECR](https://gallery.ecr.aws/aquasecurity/trivy#canary) images and [binaries](https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml)) as generated every push to main branch.

Please be aware: canary builds might have critical bugs, it&#039;s not recommended for use in production.

### General usage

```bash
trivy &lt;target&gt; [--scanners &lt;scanner1,scanner2&gt;] &lt;subject&gt;
```

Examples:

```bash
trivy image python:3.4-alpine
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov

&lt;/details&gt;

```bash
trivy fs --scanners vuln,secret,misconfig myproject/
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov

&lt;/details&gt;

```bash
trivy k8s --report summary cluster
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

![k8s summary](docs/imgs/trivy-k8s.png)

&lt;/details&gt;

## FAQ

### How to pronounce the name &quot;Trivy&quot;?

`tri` is pronounced like **tri**gger, `vy` is pronounced like en**vy**.

## Want more? Check out Aqua

If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.  
You can find a high level comparison table specific to Trivy users [here](https://trivy.dev/latest/commercial/compare/).
In addition check out the &lt;https://aquasec.com&gt; website for more information about our products and services.
If you&#039;d like to contact Aqua or request a demo, please use this form: &lt;https://www.aquasec.com/demo&gt;

## Community

Trivy is an [Aqua Security][aquasec] open source project.  
Learn about our open source work and portfolio [here][oss].  
Contact us about any matter by opening a GitHub Discussion [here][discussions]

Please ensure to abide by our [Code of Conduct][code-of-conduct] during all interactions.

[test]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml
[test-img]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg
[go-report]: https://goreportcard.com/report/github.com/aquasecurity/trivy
[go-report-img]: https://goreportcard.com/badge/github.com/aquasecurity/trivy
[release]: https://github.com/aquasecurity/trivy/releases
[release-img]: https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github
[github-downloads-img]: https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github
[docker-pulls]: https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;label=docker%20pulls%20%2F%20trivy
[license]: https://github.com/aquasecurity/trivy/blob/main/LICENSE
[license-img]: https://img.shields.io/badge/License-Apache%202.0-blue.svg
[homepage]: https://trivy.dev
[docs]: https://trivy.dev/latest/docs/
[pronunciation]: #how-to-pronounce-the-name-trivy
[code-of-conduct]: https://github.com/aquasecurity/community/blob/main/CODE_OF_CONDUCT.md

[Installation]:https://trivy.dev/latest/getting-started/installation/
[Ecosystem]: https://trivy.dev/latest/ecosystem/
[Scanning Coverage]: https://trivy.dev/latest/docs/coverage/

[alpine]: https://ariadne.space/2021/06/08/the-vulnerability-remediation-lifecycle-of-alpine-containers/
[rego]: https://www.openpolicyagent.org/docs/latest/#rego
[sigstore]: https://www.sigstore.dev/

[aquasec]: https://aquasec.com
[oss]: https://www.aquasec.com/products/open-source-projects/
[discussions]: https://github.com/aquasecurity/trivy/discussions
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Tencent/WeKnora]]></title>
            <link>https://github.com/Tencent/WeKnora</link>
            <guid>https://github.com/Tencent/WeKnora</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:45 GMT</pubDate>
            <description><![CDATA[LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Tencent/WeKnora">Tencent/WeKnora</a></h1>
            <p>LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.</p>
            <p>Language: Go</p>
            <p>Stars: 7,070</p>
            <p>Forks: 804</p>
            <p>Stars today: 248 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;img src=&quot;./docs/images/logo.png&quot; alt=&quot;WeKnora Logo&quot; height=&quot;120&quot;/&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://weknora.weixin.qq.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;å®˜æ–¹ç½‘ç«™&quot; src=&quot;https://img.shields.io/badge/å®˜æ–¹ç½‘ç«™-WeKnora-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://chatbot.weixin.qq.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;å¾®ä¿¡å¯¹è¯å¼€æ”¾å¹³å°&quot; src=&quot;https://img.shields.io/badge/å¾®ä¿¡å¯¹è¯å¼€æ”¾å¹³å°-5ac725&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/Tencent/WeKnora/blob/main/LICENSE&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;License&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;./CHANGELOG.md&quot;&gt;
        &lt;img alt=&quot;Version&quot; src=&quot;https://img.shields.io/badge/version-0.1.3-2e6cc4?labelColor=d4eaf7&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
| &lt;b&gt;English&lt;/b&gt; | &lt;a href=&quot;./README_CN.md&quot;&gt;&lt;b&gt;ç®€ä½“ä¸­æ–‡&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;./README_JA.md&quot;&gt;&lt;b&gt;æ—¥æœ¬èªž&lt;/b&gt;&lt;/a&gt; |
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;h4 align=&quot;center&quot;&gt;

  [Overview](#-overview) â€¢ [Architecture](#-architecture) â€¢ [Key Features](#-key-features) â€¢ [Getting Started](#-getting-started) â€¢ [API Reference](#-api-reference) â€¢ [Developer Guide](#-developer-guide)
  
  &lt;/h4&gt;
&lt;/p&gt;

# ðŸ’¡ WeKnora - LLM-Powered Document Understanding &amp; Retrieval Framework

## ðŸ“Œ Overview

[**WeKnora**](https://weknora.weixin.qq.com) is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents. 

It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the **RAG (Retrieval-Augmented Generation)** paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.

**Website:** https://weknora.weixin.qq.com

## ðŸ”’ Security Notice

**Important:** Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:

- Deploy WeKnora services in internal/private network environments rather than public internet
- Avoid exposing the service directly to public networks to prevent potential information leakage
- Configure proper firewall rules and access controls for your deployment environment
- Regularly update to the latest version for security patches and improvements

## ðŸ—ï¸ Architecture

![weknora-pipeline.png](./docs/images/pipeline.jpg)

WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.

## ðŸŽ¯ Key Features

- **ðŸ” Precise Understanding**: Structured content extraction from PDFs, Word documents, images and more into unified semantic views
- **ðŸ§  Intelligent Reasoning**: Leverages LLMs to understand document context and user intent for accurate Q&amp;A and multi-turn conversations
- **ðŸ”§ Flexible Extension**: All components from parsing and embedding to retrieval and generation are decoupled for easy customization
- **âš¡ Efficient Retrieval**: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs
- **ðŸŽ¯ User-Friendly**: Intuitive web interface and standardized APIs for zero technical barriers
- **ðŸ”’ Secure &amp; Controlled**: Support for local deployment and private cloud, ensuring complete data sovereignty

## ðŸ“Š Application Scenarios

| Scenario | Applications | Core Value |
|---------|----------|----------|
| **Enterprise Knowledge Management** | Internal document retrieval, policy Q&amp;A, operation manual search | Improve knowledge discovery efficiency, reduce training costs |
| **Academic Research Analysis** | Paper retrieval, research report analysis, scholarly material organization | Accelerate literature review, assist research decisions |
| **Product Technical Support** | Product manual Q&amp;A, technical documentation search, troubleshooting | Enhance customer service quality, reduce support burden |
| **Legal &amp; Compliance Review** | Contract clause retrieval, regulatory policy search, case analysis | Improve compliance efficiency, reduce legal risks |
| **Medical Knowledge Assistance** | Medical literature retrieval, treatment guideline search, case analysis | Support clinical decisions, improve diagnosis quality |

## ðŸ§© Feature Matrix

| Module | Support | Description |
|---------|---------|------|
| Document Formats | âœ… PDF / Word / Txt / Markdown / Images (with OCR / Caption) | Support for structured and unstructured documents with text extraction from images |
| Embedding Models | âœ… Local models, BGE / GTE APIs, etc. | Customizable embedding models, compatible with local deployment and cloud vector generation APIs |
| Vector DB Integration | âœ… PostgreSQL (pgvector), Elasticsearch | Support for mainstream vector index backends, flexible switching for different retrieval scenarios |
| Retrieval Strategies | âœ… BM25 / Dense Retrieval / GraphRAG | Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines |
| LLM Integration | âœ… Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching | Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration |
| QA Capabilities | âœ… Context-aware, multi-turn dialogue, prompt templates | Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;A with configurable prompts and context windows |
| E2E Testing | âœ… Retrieval+generation process visualization and metric evaluation | End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics |
| Deployment Modes | âœ… Support for local deployment / Docker images | Meets private, offline deployment and flexible operation requirements |
| User Interfaces | âœ… Web UI + RESTful API | Interactive interface and standard API endpoints, suitable for both developers and business users |

## ðŸš€ Getting Started

### ðŸ›  Prerequisites

Make sure the following tools are installed on your system:

* [Docker](https://www.docker.com/)
* [Docker Compose](https://docs.docker.com/compose/)
* [Git](https://git-scm.com/)

### ðŸ“¦ Installation

#### â‘  Clone the repository

```bash
# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
```

#### â‘¡ Configure environment variables

```bash
# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
```

#### â‘¢ Start the services

```bash
# Start all services (Ollama + backend containers)
./scripts/start_all.sh
# Or
make start-all
```

#### â‘¢ Start the services (backup)

```bash
# Start ollama services (Optional)
ollama serve &gt; /dev/null 2&gt;&amp;1 &amp;

# Start the service
docker compose up -d
```

#### â‘£ Stop the services

```bash
./scripts/start_all.sh --stop
# Or
make stop-all
```

### ðŸŒ Access Services

Once started, services will be available at:

* Web UI: `http://localhost`
* Backend API: `http://localhost:8080`
* Jaeger Tracing: `http://localhost:16686`

### ðŸ”Œ Using WeChat Dialog Open Platform

WeKnora serves as the core technology framework for the [WeChat Dialog Open Platform](https://chatbot.weixin.qq.com), providing a more convenient usage approach:

- **Zero-code Deployment**: Simply upload knowledge to quickly deploy intelligent Q&amp;A services within the WeChat ecosystem, achieving an &quot;ask and answer&quot; experience
- **Efficient Question Management**: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers
- **WeChat Ecosystem Integration**: Through the WeChat Dialog Open Platform, WeKnora&#039;s intelligent Q&amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences

### ðŸ”— Access WeKnora via MCP Server

#### 1ï¸âƒ£ Clone the repository
```
git clone https://github.com/Tencent/WeKnora
```

#### 2ï¸âƒ£ Configure MCP Server
&gt; It is recommended to directly refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for configuration.

Configure the MCP client to connect to the server:
```json
{
  &quot;mcpServers&quot;: {
    &quot;weknora&quot;: {
      &quot;args&quot;: [
        &quot;path/to/WeKnora/mcp-server/run_server.py&quot;
      ],
      &quot;command&quot;: &quot;python&quot;,
      &quot;env&quot;:{
        &quot;WEKNORA_API_KEY&quot;:&quot;Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk&quot;,
        &quot;WEKNORA_BASE_URL&quot;:&quot;http(s)://your-weknora-address/api/v1&quot;
      }
    }
  }
}
```

Run directly using stdio command:
```
pip install weknora-mcp-server
python -m weknora-mcp-server
```

## ðŸ”§ Initialization Configuration Guide

To help users quickly configure various models and reduce trial-and-error costs, we&#039;ve improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows:
If this is your first time using this project, you can skip steps â‘ â‘¡ and go directly to steps â‘¢â‘£.

### â‘  Stop the services

```bash
./scripts/start_all.sh --stop
```

### â‘¡ Clear existing data tables (recommended when no important data exists)

```bash
make clean-db
```

### â‘¢ Compile and start services

```bash
./scripts/start_all.sh
```

### â‘£ Access Web UI

http://localhost

On first access, it will automatically redirect to the initialization configuration page. After configuration is complete, it will automatically redirect to the knowledge base page. Please follow the page instructions to complete model configuration.

![Configuration Page](./docs/images/config.png)

## ðŸ“± Interface Showcase

### Web UI Interface

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Knowledge Upload&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/knowledges.png&quot; alt=&quot;Knowledge Upload Interface&quot;&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;Q&amp;A Entry&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/qa.png&quot; alt=&quot;Q&amp;A Entry Interface&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td colspan=&quot;2&quot;&gt;&lt;b&gt;Rich Text &amp; Image Responses&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/answer.png&quot; alt=&quot;Rich Answer Interface&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

**Knowledge Base Management:** Support for dragging and dropping various documents, automatically identifying document structures and extracting core knowledge to establish indexes. The system clearly displays processing progress and document status, achieving efficient knowledge base management.

### Document Knowledge Graph

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;img src=&quot;./docs/images/graph2.png&quot; alt=&quot;Knowledge Graph View 1&quot;&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;./docs/images/graph1.png&quot; alt=&quot;Knowledge Graph View 2&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.

### MCP Server Integration Effects
&lt;img width=&quot;950&quot; height=&quot;2063&quot; alt=&quot;MCP Server Integration Demo&quot; src=&quot;https://github.com/user-attachments/assets/09111ec8-0489-415c-969d-aa3835778e14&quot; /&gt;

## ðŸ“˜ API Reference

Troubleshooting FAQ: [Troubleshooting FAQ](./docs/QA.md)

Detailed API documentation is available at: [API Docs](./docs/API.md)

## ðŸ§­ Developer Guide

### ðŸ“ Directory Structure

```
WeKnora/
â”œâ”€â”€ cmd/         # Main entry point
â”œâ”€â”€ internal/    # Core business logic
â”œâ”€â”€ config/      # Configuration files
â”œâ”€â”€ migrations/  # DB migration scripts
â”œâ”€â”€ scripts/     # Shell scripts
â”œâ”€â”€ services/    # Microservice logic
â”œâ”€â”€ frontend/    # Frontend app
â””â”€â”€ docs/        # Project documentation
```

### ðŸ”§ Common Commands

```bash
# Wipe all data from DB (use with caution)
make clean-db
```

## ðŸ¤ Contributing

We welcome community contributions! For suggestions, bugs, or feature requests, please submit an [Issue](https://github.com/Tencent/WeKnora/issues) or directly create a Pull Request.

### ðŸŽ¯ How to Contribute

- ðŸ› **Bug Fixes**: Discover and fix system defects
- âœ¨ **New Features**: Propose and implement new capabilities
- ðŸ“š **Documentation**: Improve project documentation
- ðŸ§ª **Test Cases**: Write unit and integration tests
- ðŸŽ¨ **UI/UX Enhancements**: Improve user interface and experience

### ðŸ“‹ Contribution Process

1. **Fork the project** to your GitHub account
2. **Create a feature branch** `git checkout -b feature/amazing-feature`
3. **Commit changes** `git commit -m &#039;Add amazing feature&#039;`
4. **Push branch** `git push origin feature/amazing-feature`
5. **Create a Pull Request** with detailed description of changes

### ðŸŽ¨ Code Standards

- Follow [Go Code Review Comments](https://github.com/golang/go/wiki/CodeReviewComments)
- Format code using `gofmt`
- Add necessary unit tests
- Update relevant documentation

### ðŸ“ Commit Guidelines

Use [Conventional Commits](https://www.conventionalcommits.org/) standard:

```
feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
```

## ðŸ“„ License

This project is licensed under the [MIT License](./LICENSE).
You are free to use, modify, and distribute the code with proper attribution.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[milvus-io/milvus]]></title>
            <link>https://github.com/milvus-io/milvus</link>
            <guid>https://github.com/milvus-io/milvus</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:44 GMT</pubDate>
            <description><![CDATA[Milvus is a high-performance, cloud-native vector database built for scalable vector ANN search]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/milvus-io/milvus">milvus-io/milvus</a></h1>
            <p>Milvus is a high-performance, cloud-native vector database built for scalable vector ANN search</p>
            <p>Language: Go</p>
            <p>Stars: 38,216</p>
            <p>Forks: 3,489</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://github.com/user-attachments/assets/51e33300-7f85-43ff-a05a-3a0317a961f3&quot; alt=&quot;milvus banner&quot;&gt;

&lt;div class=&quot;column&quot; align=&quot;middle&quot;&gt;
  &lt;a href=&quot;https://github.com/milvus-io/milvus/blob/master/LICENSE&quot;&gt;&lt;img height=&quot;20&quot; src=&quot;https://img.shields.io/github/license/milvus-io/milvus&quot; alt=&quot;license&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://milvus.io/docs/install_standalone-docker.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/milvusdb/milvus&quot; alt=&quot;docker-pull-count&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://milvus.io/docs/roadmap.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/2025-roadmap-orange&quot; alt=&quot;fully-managed-milvus&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://cloud.zilliz.com/signup?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/fully_managed-milvus-blue&quot; alt=&quot;fully-managed-milvus&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://milvus.io/docs/tutorials-overview.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/tutorials-green&quot; alt=&quot;tutorials&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/mKc3R95yE5&quot;&gt;&lt;img height=&quot;20&quot; src=&quot;https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;discord&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/milvusio&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/milvusio&quot; alt=&quot;twitter&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

## What is Milvus?

ðŸ¦ [Milvus](https://milvus.io/) is a high-performance vector database built for scale. It powers AI applications by efficiently organizing and searching vast amounts of unstructured data, such as text, images, and multi-modal information.

ðŸ§‘â€ðŸ’» Written in Go and C++, Milvus implements hardware acceleration for CPU/GPU to achieve best-in-class vector search performance. Thanks to its [fully-distributed and K8s-native architecture](https://milvus.io/docs/overview.md#What-Makes-Milvus-so-Scalable), Milvus can scale horizontally, handle tens of thousands of search queries on billions of vectors, and keep data fresh with real-time streaming updates. Milvus also supports [Standalone mode](https://milvus.io/docs/install_standalone-docker.md) for single machine deployment. [Milvus Lite](https://milvus.io/docs/milvus_lite.md) is a lightweight version good for quickstart in python with `pip install`.

Want to use Milvus with zero setup? Try out [Zilliz Cloud â˜ï¸](https://cloud.zilliz.com/signup?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global) for free. Milvus is available as a fully managed service on Zilliz Cloud, with [Serverless](https://zilliz.com/serverless?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global), [Dedicated](https://zilliz.com/cloud?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global) and [BYOC](https://zilliz.com/bring-your-own-cloud?utm_source=partner&amp;utm_medium=referral&amp;utm_campaign=2024-11-04_web_github-readme_global) options available.

For questions about how to use Milvus, join the community on [Discord](https://discord.gg/33mfvwep3J) to get help. For reporting problems, file bugs and feature requests in GitHub [Issues](https://github.com/milvus-io/milvus/issues) or ask in [Discussions](https://github.com/milvus-io/milvus/discussions).

The Milvus open-source project is
under [LF AI &amp; Data Foundation](https://lfaidata.foundation/projects/milvus/), distributed with [Apache 2.0](https://github.com/milvus-io/milvus/blob/master/LICENSE) License, with Zilliz as its major contributor.

## Quickstart

```python
$ pip install -U pymilvus
```
This installs `pymilvus`, the Python SDK for Milvus. Use `MilvusClient` to create a client:
```python
from pymilvus import MilvusClient
```

* `pymilvus` also includes Milvus Lite for quickstart. To create a local vector database, simply instantiate a client with a local file name for persisting data:

  ```python
  client = MilvusClient(&quot;milvus_demo.db&quot;)
  ```

* You can also specify the credentials to connect to your deployed [Milvus server](https://milvus.io/docs/authenticate.md?tab=docker) or [Zilliz Cloud](https://docs.zilliz.com/docs/quick-start):

  ```python
  client = MilvusClient(
    uri=&quot;&lt;endpoint_of_self_hosted_milvus_or_zilliz_cloud&gt;&quot;,
    token=&quot;&lt;username_and_password_or_zilliz_cloud_api_key&gt;&quot;)
  ```

With the client, you can create collection:
```python
client.create_collection(
    collection_name=&quot;demo_collection&quot;,
    dimension=768,  # The vectors we will use in this demo have 768 dimensions
)
```

Ingest data:
```python
res = client.insert(collection_name=&quot;demo_collection&quot;, data=data)
```

Perform vector search:

```python
query_vectors = embedding_fn.encode_queries([&quot;Who is Alan Turing?&quot;, &quot;What is AI?&quot;])
res = client.search(
    collection_name=&quot;demo_collection&quot;,  # target collection
    data=query_vectors,  # a list of one or more query vectors, supports batch
    limit=2,  # how many results to return (topK)
    output_fields=[&quot;vector&quot;, &quot;text&quot;, &quot;subject&quot;],  # what fields to return
)
```

## Why Milvus

Milvus is designed to handle vector search at scale. It stores vectors, which are learned representations of unstructured data, together with other scalar data types such as integers, strings, and JSON objects. Users can conduct efficient vector search with metadata filtering or hybrid search. Here are why developers choose Milvus as the vector database for AI applications:

**High Performance at Scale and High Availability**  
  * Milvus features a [distributed architecture](https://milvus.io/docs/architecture_overview.md ) that separates [compute](https://milvus.io/docs/data_processing.md#Data-query) and [storage](https://milvus.io/docs/data_processing.md#Data-insertion). Milvus can horizontally scale and adapt to diverse traffic patterns, achieving optimal performance by independently increasing query nodes for read-heavy workload and data node for write-heavy workload. The stateless microservices on K8s allow [quick recovery](https://milvus.io/docs/coordinator_ha.md#Coordinator-HA) from failure, ensuring high availability. The support for [replicas](https://milvus.io/docs/replica.md) further enhances fault tolerance and throughput by loading data segments on multiple query nodes. See [benchmark](https://zilliz.com/vector-database-benchmark-tool) for performance comparison.


**Support for Various Vector Index Types and Hardware Acceleration**  
  * Milvus separates the system and core vector search engine, allowing it to support all major vector index types that are optimized for different scenarios, including HNSW, IVF, FLAT (brute-force), SCANN, and DiskANN, with [quantization-based](https://milvus.io/docs/index.md?tab=floating#IVFPQ) variations and [mmap](https://milvus.io/docs/mmap.md). Milvus optimizes vector search for advanced features such as [metadata filtering](https://milvus.io/docs/scalar_index.md#Scalar-Index) and [range search](https://milvus.io/docs/single-vector-search.md#Range-search). Additionally, Milvus implements hardware acceleration to enhance vector search performance and supports GPU indexing, such as NVIDIA&#039;s [CAGRA](https://github.com/rapidsai/cuvs).


**Flexible Multi-tenancy and Hot/Cold Storage**
  * Milvus supports [multi-tenancy](https://milvus.io/docs/multi_tenancy.md#Multi-tenancy-strategies) through isolation at database, collection, partition, or partition key level. The flexible strategies allow a single cluster to handle hundreds to millions of tenants, also ensures optimized search performance and flexible access control. Milvus enhances cost-effectiveness with hot/cold storage. Frequently accessed hot data can be stored in memory or on SSDs for better performance, while less-accessed cold data is kept on slower, cost-effective storage. This mechanism can significantly reduce costs while maintaining high performance for critical tasks.

**Sparse Vector for Full Text Search and Hybrid Search**
  * In addition to semantic search through dense vector, Milvus also natively supports [full text search](https://milvus.io/docs/full-text-search.md) with BM25 as well as learned sparse embeddings such as SPLADE and BGE-M3. Users can store sparse vectors and dense vectors in the same collection, and define functions to rerank results from multiple search requests. See examples of [Hybrid Search with semantic search + full text search](https://milvus.io/docs/full_text_search_with_milvus.md).

**Data Security and Fine-grain Access Control**
  * Milvus ensures data security by implementing mandatory user authentication, TLS encryption, and Role-Based Access Control (RBAC). User authentication ensures that only authorized users with valid credentials can access the database, while TLS encryption secures all communications within the network. Additionally, RBAC allows for fine-grained access control by assigning specific permissions to users based on their roles. These features make Milvus a robust and secure choice for enterprise applications, protecting sensitive data from unauthorized access and potential breaches.

Milvus is trusted by AI developers to build applications such as text and image search, Retrieval-Augmented Generation (RAG), and recommendation systems. Milvus powers [many mission-critical businesses](https://milvus.io/use-cases) for startups and enterprises.

## Demos and Tutorials

Here is a selection of demos and tutorials to show how to build various types of AI applications made with Milvus:

You can explore a comprehensive [Tutorials Overview](https://milvus.io/docs/tutorials-overview.md) covering topics such as Retrieval-Augmented Generation (RAG), Semantic Search, Hybrid Search, Question Answering, Recommendation Systems, and various quick-start guides. These resources are designed to help you get started quickly and efficiently.

| Tutorial | Use Case | Related Milvus Features |
| -------- | -------- | --------- |
| [Build RAG with Milvus](https://milvus.io/docs/build-rag-with-milvus.md) |  RAG | vector search |
| [Advanced RAG Optimizations](https://milvus.io/docs/how_to_enhance_your_rag.md) | RAG | vector search, full text search |
| [Full Text Search with Milvus](https://milvus.io/docs/full_text_search_with_milvus.md) | Text Search | full text search |
| [Hybrid Search with Milvus](https://milvus.io/docs/hybrid_search_with_milvus.md) | Hybrid Search | hybrid search, multi vector, dense embedding, sparse embedding |
| [Image Search with Milvus](https://milvus.io/docs/image_similarity_search.md) | Semantic Search | vector search, dynamic field |
| [Multimodal Search using Multi Vectors](https://milvus.io/docs/multimodal_rag_with_milvus.md) | Semantic Search | multi vector, hybrid search |
| [Movie Recommendation with Milvus](https://milvus.io/docs/movie_recommendation_with_milvus.md) | Recommendation System | vector search |
| [Graph RAG with Milvus](https://milvus.io/docs/graph_rag_with_milvus.md) | RAG | graph search |
| [Contextual Retrieval with Milvus](https://milvus.io/docs/contextual_retrieval_with_milvus.md) | Quickstart | vector search |
| [Vector Visualization](https://milvus.io/docs/vector_visualization.md) | Quickstart | vector search |
| [HDBSCAN Clustering with Milvus](https://milvus.io/docs/hdbscan_clustering_with_milvus.md) | Quickstart | vector search |
| [Use ColPali for Multi-Modal Retrieval with Milvus](https://milvus.io/docs/use_ColPali_with_milvus.md) | Quickstart | vector search |

&lt;table&gt;
  &lt;tr&gt;
    &lt;td width=&quot;30%&quot;&gt;
      &lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;
        &lt;img src=&quot;https://assets.zilliz.com/image_search_59a64e4f22.gif&quot; /&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;30%&quot;&gt;
&lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;
&lt;img src=&quot;https://assets.zilliz.com/qa_df5ee7bd83.gif&quot; /&gt;
&lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;30%&quot;&gt;
&lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;
&lt;img src=&quot;https://assets.zilliz.com/mole_search_76f8340572.gif&quot; /&gt;
&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;
      &lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;Image Search&lt;/a&gt;
    &lt;/th&gt;
    &lt;th&gt;
      &lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;RAG&lt;/a&gt;
    &lt;/th&gt;
    &lt;th&gt;
      &lt;a href=&quot;https://milvus.io/milvus-demos&quot;&gt;Drug Discovery&lt;/a&gt;
    &lt;/th&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Ecosystem and Integration
   Milvus integrates with a comprehensive suite of [AI development tools](https://milvus.io/docs/integrations_overview.md), such as LangChain, LlamaIndex, OpenAI and HuggingFace, making it an ideal vector store for GenAI applications such as Retrieval-Augmented Generation (RAG). Milvus works with both open-source embedding models and embedding services, in text, image and video modalities. Milvus also provides a convenient utility [`pymilvus[model]`](https://milvus.io/docs/embeddings.md), users can use the simple wrapper code to transform unstructured data into vector embeddings and leverage reranking models for optimized search results. The Milvus ecosystem also includes [Attu](https://github.com/zilliztech/attu?tab=readme-ov-file#attu) for GUI-based administration, [Birdwatcher](https://milvus.io/docs/birdwatcher_overview.md) for system debugging, [Prometheus/Grafana](https://milvus.io/docs/monitor_overview.md) for monitoring, [Milvus CDC](https://milvus.io/docs/milvus-cdc-overview.md) for data synchronization, [VTS](https://github.com/zilliztech/vts?tab=readme-ov-file#vts) for data migration and data connectors for [Spark](https://milvus.io/docs/integrate_with_spark.md#Spark-Milvus-Connector-User-Guide), [Kafka](https://github.com/zilliztech/kafka-connect-milvus?tab=readme-ov-file#kafka-connect-milvus-connector), [Fivetran](https://fivetran.com/docs/destinations/milvus), and [Airbyte](https://milvus.io/docs/integrate_with_airbyte.md) to build search pipelines.

Check out https://milvus.io/docs/integrations_overview.md for more details.

## Documentation

For guidance on installation, usage, deployment, and administration, check out [Milvus Docs](https://milvus.io/docs). For technical milestones and enhancement proposals, check out [issues on GitHub](https://github.com/milvus-io/milvus/issues).

## Contributing

The Milvus open-source project accepts contributions from everyone. See [Guidelines for Contributing](https://github.com/milvus-io/milvus/blob/master/CONTRIBUTING.md) for details on submitting patches and the development workflow. See our [community repository](https://github.com/milvus-io/community) to learn about project governance and access more community resources.

### Build Milvus from Source Code

Requirements:

* Linux systems (Ubuntu 20.04 or later recommended):
  ```bash
  Go: &gt;= 1.21
  CMake: &gt;= 3.26.4 &amp;&amp; CMake &lt; 4
  GCC: 9.5
  Python: &gt; 3.8 and  &lt;= 3.11
  ```

* MacOS systems with x86_64 (Big Sur 11.5 or later recommended):
  ```bash
  Go: &gt;= 1.21
  CMake: &gt;= 3.26.4 &amp;&amp; CMake &lt; 4
  llvm: &gt;= 15
  Python: &gt; 3.8 and  &lt;= 3.11
  ```

* MacOS systems with Apple Silicon (Monterey 12.0.1 or later recommended):
  ```bash
  Go: &gt;= 1.21 (Arch=ARM64)
  CMake: &gt;= 3.26.4 &amp;&amp; CMake &lt; 4
  llvm: &gt;= 15
  Python: &gt; 3.8 and  &lt;= 3.11
  ```

Clone Milvus repo and build.

```bash
# Clone github repository.
$ git clone https://github.com/milvus-io/milvus.git

# Install third-party dependencies.
$ cd milvus/
$ ./scripts/install_deps.sh

# Compile Milvus.
$ make
```

For full instructions, see [developer&#039;s documentation](https://github.com/milvus-io/milvus/blob/master/DEVELOPMENT.md).

## Community

Join the Milvus community on [Discord](https://discord.gg/8uyFbECzPX) to share your suggestions, advice, and questions with our engineering team.

To learn the latest news about Milvus, follow us on social media:

- [X](https://twitter.com/milvusio)
- [LinkedIn](https://www.linkedin.com/company/the-milvus-project)
- [YouTube](https://www.youtube.com/channel/UCMCo_F7pKjMHBlfyxwOPw-g)
- [Medium](https://medium.com/@milvusio)

You can also check out our [FAQ page](https://milvus.io/docs/performance_faq.md) to discover solutions or answers to your issues or questions, and subscribe to Milvus mailing lists:

- [Technical Steering Committee](https://lists.lfai.foundation/g/milvus-tsc)
- [Technical Discussions](https://lists.lfai.foundation/g/milvus-technical-discuss)
- [Announcement](https://lists.lfai.foundation/g/milvus-announce)

## Reference

Reference to cite when you use Milvus in a research paper:

```
@inproceedings{2021milvus,
  title={Milvus: A Purpose-Built Vector Data Management System},
  author={Wang, Jianguo and Yi, Xiaomeng and Guo, Rentong and Jin, Hai and Xu, Peng and Li, Shengjun and Wang, Xiangyu and Guo, Xiangzhou and Li, Chengming and Xu, Xiaohai and others},
  booktitle={Proceedings of the 2021 International Conference on Management of Data},
  pages={2614--2627},
  year={2021}
}

@article{2022manu,
  title={Manu: a cloud native vector database management system},
  author={Guo, Rentong and Luan, Xiaofan and Xiang, Long and Yan, Xiao and Yi, Xiaomeng and Luo, Jigao and Cheng, Qianya and Xu, Weizhi and Luo, Jiarui and Liu, Frank and others},
  journal={Proceedings of the VLDB Endowment},
  volume={15},
  number={12},
  pages={3548--3561},
  year={2022},
  publisher={VLDB Endowment}
}
```
&lt;!-- Do not remove start of hero-bot --&gt;
&lt;img src=&quot;https://img.shields.io/badge/all--contributors-432-orange&quot;&gt;&lt;br&gt;
&lt;a href=&quot;https://github.com/0xflotus&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/26602940?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/404-P4rziv4L&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/57059194?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/9Eurydice9&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/220225099?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ABNER-1&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/24547351?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Accagain2014&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/9635216?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/AgNess-G&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/79598409?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Ahmetyasin&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/34247619?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Ald392&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/166891594?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/AliDotS&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/33119433?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/AlintaLu&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/18751867?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/AllenYu1987&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/12489985?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Anosh21&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/90505226?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/AnthonyTsu1984&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/115786031?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Aredcap&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/40494761?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ArenaSu&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/21214629?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Armaggheddon&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/47779194?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/BUPTAnderson&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/13449703?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Ben-Aaron-Bio-Rad&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/54123439?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Bennu-Li&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/53458891?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Biki-das&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/72331432?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/BossZou&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/40255591?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/CNLHC&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/21005146?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/CaoHaiNam&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/47685795?v=4&quot; width=&quot;30px&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ChelseyZ&quot;&gt;&lt;img src=&quot;https://avatars.githubu

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes/dashboard]]></title>
            <link>https://github.com/kubernetes/dashboard</link>
            <guid>https://github.com/kubernetes/dashboard</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:43 GMT</pubDate>
            <description><![CDATA[General-purpose web UI for Kubernetes clusters]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes/dashboard">kubernetes/dashboard</a></h1>
            <p>General-purpose web UI for Kubernetes clusters</p>
            <p>Language: Go</p>
            <p>Stars: 15,299</p>
            <p>Forks: 4,273</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># Kubernetes Dashboard

[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/dashboard)](https://goreportcard.com/report/github.com/kubernetes/dashboard)
[![Coverage Status](https://codecov.io/github/kubernetes/dashboard/coverage.svg?branch=master)](https://codecov.io/github/kubernetes/dashboard?branch=master)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/kubernetes/dashboard/blob/master/LICENSE)

## Introduction

Kubernetes Dashboard is a general purpose, web-based UI for Kubernetes clusters. It allows users to manage applications running in the cluster and troubleshoot them, as well as manage the cluster itself.

As of version 7.0.0, we have dropped support for Manifest-based installation. Only Helm-based installation is supported now. Due to multi-container setup and hard dependency on Kong gateway API proxy
it would not be feasible to easily support Manifest-based installation.

Additionally, we have changed the versioning scheme and dropped `appVersion` from Helm chart. It is because, with a multi-container setup, every module is now versioned separately. Helm chart version
can be considered an app version now.

![Dashboard UI workloads page](docs/images/overview.png)

## Installation

Kubernetes Dashboard supports only Helm-based installation currently as it is faster and gives us better control
over all dependencies required by Dashboard to run. We now use a single-container, DBless [Kong](https://hub.docker.com/r/kong/kong-gateway) installation
as a gateway that connects all our containers and exposes the UI. Users can then use any ingress controller or proxy
in front of kong gateway. To find out more about ways to customize your installation check out [helm chart values](charts/kubernetes-dashboard/values.yaml).

In order to install Kubernetes Dashboard simply run:
```console
# Add kubernetes-dashboard repository
helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/
# Deploy a Helm Release named &quot;kubernetes-dashboard&quot; using the kubernetes-dashboard chart
helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard --create-namespace --namespace kubernetes-dashboard
```

For more information about our Helm chart visit [ArtifactHub](https://artifacthub.io/packages/helm/k8s-dashboard/kubernetes-dashboard).

## Documentation

Dashboard documentation can be found in the [docs](docs/README.md) directory which contains:

* [Common](docs/common/README.md): Entry-level overview.
* [User Guide](docs/user/README.md): Helpful information for users.
* [How to access Dashboard](docs/user/accessing-dashboard/README.md) - Everything you need to know to get access to you Kubernetes Dashboard instance after installation.
* [Access Control](docs/user/access-control/README.md): Find out how to control access to your Kubernetes Dashboard and [create sample user](docs/user/access-control/creating-sample-user.md) that can be used to log in.
* [Developer Guide](DEVELOPMENT.md): Important information for contributors that would like to test, run and work on Dashboard locally.

## Community, discussion, contribution, and support

Learn how to engage with the Kubernetes community on the [community page](http://kubernetes.io/community/).

You can reach the maintainers of this project at:

* [**#sig-ui on Kubernetes Slack**](https://kubernetes.slack.com)
* [**kubernetes-sig-ui mailing list** ](https://groups.google.com/forum/#!forum/kubernetes-sig-ui)
* [**Issue tracker**](https://github.com/kubernetes/dashboard/issues)
* [**SIG info**](https://github.com/kubernetes/community/tree/master/sig-ui)
* [**Roles**](ROLES.md)

### Contribution

Learn how to start contributing to the [Contributing Guideline](CONTRIBUTING.md).

### Code of conduct

Participation in the Kubernetes community is governed by the [Kubernetes Code of Conduct](code-of-conduct.md).

## License

[Apache License 2.0](https://github.com/kubernetes/dashboard/blob/master/LICENSE)

----
_Copyright 2019 [The Kubernetes Dashboard Authors](https://github.com/kubernetes/dashboard/graphs/contributors)_
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[influxdata/telegraf]]></title>
            <link>https://github.com/influxdata/telegraf</link>
            <guid>https://github.com/influxdata/telegraf</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:42 GMT</pubDate>
            <description><![CDATA[Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/influxdata/telegraf">influxdata/telegraf</a></h1>
            <p>Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.</p>
            <p>Language: Go</p>
            <p>Stars: 16,422</p>
            <p>Forks: 5,735</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># ![tiger](assets/TelegrafTigerSmall.png &quot;tiger&quot;) Telegraf

[![GoDoc](https://img.shields.io/badge/doc-reference-00ADD8.svg?logo=go)](https://godoc.org/github.com/influxdata/telegraf)
[![Docker pulls](https://img.shields.io/docker/pulls/library/telegraf.svg)](https://hub.docker.com/_/telegraf/)
[![Go Report Card](https://goreportcard.com/badge/github.com/influxdata/telegraf)](https://goreportcard.com/report/github.com/influxdata/telegraf)
[![Circle CI](https://circleci.com/gh/influxdata/telegraf.svg?style=svg)](https://circleci.com/gh/influxdata/telegraf)

Telegraf is an agent for collecting, processing, aggregating, and writing
metrics, logs, and other arbitrary data.

* Offers a comprehensive suite of over 300 plugins, covering a wide range of
  functionalities including system monitoring, cloud services, and message
  passing
* Enables the integration of user-defined code to collect, transform, and
  transmit data efficiently
* Compiles into a standalone static binary without any external dependencies,
  ensuring a streamlined deployment process
* Utilizes TOML for configuration, providing a user-friendly and unambiguous
  setup experience
* Developed with contributions from a diverse community of over 1,200
  contributors

Users can choose plugins from a wide range of topics, including but not limited
to:

* Devices: [OPC UA][], [Modbus][]
* Logs: [File][], [Tail][], [Directory Monitor][]
* Messaging: [AMQP][], [Kafka][], [MQTT][]
* Monitoring: [OpenTelemetry][], [Prometheus][]
* Networking: [Cisco TelemetryMDT][], [gNMI][]
* System monitoring: [CPU][], [Memory][], [Disk][], [Network][], [SMART][],
  [Docker][], [Nvidia SMI][], etc.
* Universal: [Exec][], [HTTP][], [HTTP Listener][], [SNMP][], [SQL][]
* Windows: [Event Log][], [Management Instrumentation][],
  [Performance Counters][]

## ðŸ”¨ Installation

For binary builds, Docker images, RPM &amp; DEB packages, and other builds of
Telegraf, please see the [install guide](/docs/INSTALL_GUIDE.md).

See the [releases documentation](/docs/RELEASES.md) for details on versioning
and when releases are made.

## ðŸ’» Usage

Users define a TOML configuration with the plugins and settings they wish to
use, then pass that configuration to Telegraf. The Telegraf agent then
collects data from inputs at each interval and sends data to outputs at each
flush interval.

For a basic walkthrough see [quick start](/docs/QUICK_START.md).

## ðŸ“– Documentation

For a full list of documentation including tutorials, reference and other
material, start with the [/docs directory](/docs/README.md).

Additionally, each plugin has its own README that includes details about how to
configure, use, and sometimes debug or troubleshoot. Look under the
[/plugins directory](/plugins/) for specific plugins.

Here are some commonly used documents:

* [Changelog](/CHANGELOG.md)
* [Configuration](/docs/CONFIGURATION.md)
* [FAQ](/docs/FAQ.md)
* [Releases](https://github.com/influxdata/telegraf/releases)
* [Security](/SECURITY.md)

## â¤ï¸ Contribute

[![Contribute](https://img.shields.io/badge/contribute-to_telegraf-blue.svg?logo=influxdb)](https://github.com/influxdata/telegraf/blob/master/CONTRIBUTING.md)

We love our community of over 1,200 contributors! Many of the plugins included
in Telegraf were originally contributed by community members. Check out
our [contributing guide](CONTRIBUTING.md) if you are interested in helping out.
Also, join us on our [Community Slack](https://influxdata.com/slack) or
[Community Forums](https://community.influxdata.com/) if you have questions or
comments for our engineering teams.

If you are completely new to Telegraf and InfluxDB, you can also enroll for free
at [InfluxDB university](https://www.influxdata.com/university/) to take courses
to learn more.

## â„¹ï¸ Support

[![Slack](https://img.shields.io/badge/slack-join_chat-blue.svg?logo=slack)](https://www.influxdata.com/slack)
[![Forums](https://img.shields.io/badge/discourse-join_forums-blue.svg?logo=discourse)](https://community.influxdata.com/)

Please use the [Community Slack](https://influxdata.com/slack) or
[Community Forums](https://community.influxdata.com/) if you have questions or
comments for our engineering teams. GitHub issues are limited to actual issues
and feature requests only.

## ðŸ“œ License

[![MIT](https://img.shields.io/badge/license-MIT-blue)](https://github.com/influxdata/telegraf/blob/master/LICENSE)

[OPC UA]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opcua
[Modbus]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/modbus
[File]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/file
[Tail]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/tail
[Directory Monitor]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/directory_monitor
[AMQP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/amqp_consumer
[Kafka]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/kafka_consumer
[MQTT]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mqtt_consumer
[OpenTelemetry]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opentelemetry
[Prometheus]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/prometheus
[Cisco TelemetryMDT]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cisco_telemetry_mdt
[gNMI]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/gnmi
[CPU]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cpu
[Memory]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mem
[Disk]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/disk
[Network]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/net
[SMART]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/smartctl
[Docker]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker
[Nvidia SMI]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/nvidia_smi
[Exec]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/exec
[HTTP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http
[HTTP Listener]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http_listener_v2
[SNMP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/snmp
[SQL]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/sql
[Event Log]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_eventlog
[Management Instrumentation]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_wmi
[Performance Counters]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gtsteffaniak/filebrowser]]></title>
            <link>https://github.com/gtsteffaniak/filebrowser</link>
            <guid>https://github.com/gtsteffaniak/filebrowser</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:41 GMT</pubDate>
            <description><![CDATA[ðŸ“‚ Web File Browser]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gtsteffaniak/filebrowser">gtsteffaniak/filebrowser</a></h1>
            <p>ðŸ“‚ Web File Browser</p>
            <p>Language: Go</p>
            <p>Stars: 4,271</p>
            <p>Forks: 176</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

  [![Go Report Card](https://goreportcard.com/badge/github.com/gtsteffaniak/filebrowser/backend)](https://goreportcard.com/report/github.com/gtsteffaniak/filebrowser/backend)
  [![Codacy Badge](https://app.codacy.com/project/badge/Grade/1c48cfb7646d4009aa8c6f71287670b8)](https://www.codacy.com/gh/gtsteffaniak/filebrowser/dashboard)
  [![latest version](https://img.shields.io/github/release/gtsteffaniak/filebrowser/all.svg)](https://github.com/gtsteffaniak/filebrowser/releases)
  [![DockerHub Pulls](https://img.shields.io/docker/pulls/gtstef/filebrowser?label=latest%20Docker%20pulls)](https://hub.docker.com/r/gtstef/filebrowser)
  [![Apache-2.0 License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)

  [![Donate](https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif)](https://github.com/gtsteffaniak/filebrowser/wiki/Q&amp;A#is-there-a-way-to-donate-or-support-this-project)

  &lt;img width=&quot;150&quot; src=&quot;https://github.com/user-attachments/assets/c40b22c9-33da-47b7-bc4c-ce69bb5cc174&quot; title=&quot;Logo&quot;&gt;
  &lt;h3&gt;FileBrowser Quantum&lt;/h3&gt;
  The best free self-hosted web-based file manager.
  &lt;br/&gt;&lt;br/&gt;
  &lt;img width=&quot;800&quot; src=&quot;https://github.com/user-attachments/assets/162d7a95-33b7-49bd-976c-dd6822c0d22b&quot;&gt;
&lt;/div&gt;

&gt; [!WARNING]
&gt; There is no stable version -- :construction: coming very soon!

## Pinned

:loudspeaker: [Stable Release &amp; v1.0.0 Update](https://github.com/gtsteffaniak/filebrowser/discussions/1293)

:pushpin: [Read The Official Docs](https://filebrowserquantum.com/) (currently english-only)

## About

FileBrowser Quantum provides an easy way to access and manage your files from the web. It has a modern responsive interface that has many advanced features to manage users, access, sharing, and file preview and editing.

This version is called &quot;Quantum&quot; because it packs tons of advanced features into a tiny easy to run file. Unlike the majority of alternative options, FileBrowser Quantum is simple to install and easy to configure.

The goal for this repo is to become the best open-source self-hosted file browsing application that exists -- **all for free**. This repo will always be free and open-source.

Ready to try it out? See [Getting Started Docs](https://filebrowserquantum.com/en/docs/getting-started/).

## How its different

FileBrowser Quantum is a massive fork of the file browser open-source project with the following changes:

  1. âœ… Multiple sources support
  2. âœ… Login support for OIDC, password + 2FA, and proxy.
  3. âœ… Beautiful, Responsive, and Customizable user interface.
  4. âœ… Simplified configuration via `config.yaml` config file.
  5. âœ… Ultra-efficient [indexing](https://github.com/gtsteffaniak/filebrowser/wiki/Indexing) and real-time updates
     - Real-time search results as you type.
     - Real-time monitoring and updates in the UI.
     - Search supports file and folder sizes, along with various filters.
  6. âœ… Better listing browsing
     - More file type previews, such as **office** and **video** file previews
     - Instantly switches view modes and sort order without reloading data.
     - Folder sizes are displayed.
     - Navigating remembers the last scroll position.
  7. âœ… Highly configurable and customizable sharing options, incuding:
     - share expiration time
     - users who can access share (including anonymous)
     - styling and themes
     - file viewing, editing, and uploading permissions
  8. âœ… Directory-level access control that can be scoped to user or group.
  8. âœ… Developer API support
     - Ability to create long-lived API Tokens.
     - A helpful Swagger page is available at `/swagger` endpoint for API enabled users.

Notable features that this fork *does not* have (removed):

 - :construction: jobs are not supported yet.
 - âŒ shell commands are completely removed and will not be returned.

FileBrowser Quantum differs significantly from the original version. Many of these changes required a significant overhaul. Creating a fork was a necessary process to make the program better. There have been many growing pains, but a stable release is planned and coming soon.

## System Requirements

&gt; [!WARNING]
&gt; Every file and directory in the source gets indexed (by default). This enables powerful features such as instant search, but large source filesystems can increase your system requirements. [See indexing wiki](https://github.com/gtsteffaniak/filebrowser/wiki/Indexing) for more info.

 - **Memory**: depends on configured source complexity. See [how much RAM does it require?](https://github.com/gtsteffaniak/filebrowser/discussions/787)
 - **GPU**: Not currently used (planned)

## The UI

The UI has a simple three-component navigation system:

  1. (Left) Multi-action button with slide-out panel.
  2. (Middle) The powerful search bar.
  3. (Right) The view change toggle.

All other functions are moved either into the action menu or pop-up menus.
If the action does not depend on context, it will exist in the slide-out
action panel. If the action is available based on context, it will show up as
a pop-up menu.

&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;1000&quot; src=&quot;https://github.com/user-attachments/assets/aa32b05c-f917-47bb-b07f-857edc5e47f7&quot; title=&quot;Search GIF&quot;&gt;
&lt;/p&gt;

## Official Docs

See the [Official Docs](https://filebrowserquantum.com/). Contributions are welcome and encouraged! See [FilebrowserDocs Github](https://github.com/quantumx-apps/filebrowserDocs).

## Comparison Chart
Application Name | &lt;img width=&quot;48&quot; src=&quot;https://github.com/user-attachments/assets/c40b22c9-33da-47b7-bc4c-ce69bb5cc174&quot; &gt; Quantum | &lt;img width=&quot;48&quot; src=&quot;https://github.com/filebrowser/filebrowser/blob/master/frontend/public/img/logo.svg&quot; &gt; Filebrowser | &lt;img width=&quot;48&quot; src=&quot;https://github.com/mickael-kerjean/filestash/blob/master/public/assets/logo/app_icon.png?raw=true&quot; &gt; Filestash | &lt;img width=&quot;48&quot; src=&quot;https://avatars.githubusercontent.com/u/19211038?s=200&amp;v=4&quot; &gt;  Nextcloud | &lt;img width=&quot;48&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Google_Drive_logo.png/480px-Google_Drive_logo.png&quot; &gt; Google_Drive | &lt;img width=&quot;48&quot; src=&quot;https://avatars.githubusercontent.com/u/6422152?v=4&quot; &gt; FileRun
--- | --- | --- | --- | --- | --- | --- |
Filesystem support            | âœ… | âœ… | âœ… | âŒ | âŒ | âœ… |
Linux                         | âœ… | âœ… | âœ… | âœ… | âŒ | âœ… |
Windows                       | âœ… | âœ… | âœ… | âŒ | âŒ | âœ… |
Mac                           | âœ… | âœ… | âœ… | âŒ | âŒ | âœ… |
Self hostable                 | âœ… | âœ… | âœ… | âœ… | âŒ | âœ… |
Has Stable Release?           | :construction: | âœ… | âœ… | âœ… | âœ… | âœ… |
S3 support                    | âŒ | âŒ | âœ… | âœ… | âŒ | âŒ |
webdav support                | âŒ | âŒ | âœ… | âœ… | âŒ | âœ… |
FTP support                   | âŒ | âŒ | âœ… | âœ… | âŒ | âœ… |
Dedicated docs site?          | :construction: | âœ… | âœ… | âœ… | âŒ | âœ… |
Multiple sources at once      | âœ… | âŒ | âœ… | âœ… | âŒ | âœ… |
Docker image size             | 180 MB (with ffmpeg) | 31 MB  | 240 MB (main image) | 250 MB | âŒ | &gt; 2 GB |
Min. Memory Requirements      | 256 MB | 128 MB | 128 MB (main image) | 512 MB | âŒ | 512 MB   |
has standalone binary         | âœ… | âœ… | âŒ | âŒ | âŒ | âŒ |
price                         | free | free | free | free tier | free tier | $99+ |
rich media preview            | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
Upload files from the web?    | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
Advanced Search?              | âœ… | âŒ | âŒ | configurable | âœ… | âœ… |
Indexed Search?               | âœ… | âŒ | âŒ | configurable | âœ… | âœ… |
Content-aware search?         | âŒ | âŒ | âŒ | configurable | âœ… | âœ… |
Custom job support            | :construction: | âœ… | âŒ | âœ… | âŒ | âœ… |
Multiple users                | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
Single sign-on support        | âœ… | âŒ | âŒ | âœ… | âœ… | âœ… |
LDAP sign-on support          | :construction: | âŒ | âŒ | âœ… | âŒ | âœ… |
Long-live API key support     | âœ… | âŒ | âœ… | âœ… | âœ… | âœ… |
API documentation page        | âœ… | âŒ | âœ… | âœ… | âŒ | âœ… |
Mobile App                    | âŒ | âŒ | âŒ | âœ… | âœ… | âŒ |
open source?                  | âœ… | âœ… | âœ… | âœ… | âŒ | âŒ |
tags support                  | :construction: | âŒ | âŒ | âœ… | âŒ | âœ… |
shareable web links?          | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
Event-based notifications     | :construction: | âŒ | âŒ | âŒ | âŒ | âœ… |
Metrics                       | :construction: | âŒ | âŒ | âŒ | âŒ | âŒ |
file space quotas             | :construction: | âŒ | âŒ | âŒ | âœ… | âœ… |
text-based files editor       | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
Office file support           | âœ… | âŒ | âœ… | âœ… | âœ… | âœ… |
Office file previews          | âœ… | âŒ | âŒ | âœ… | âœ… | âœ… |
Themes                        | âœ… | âœ… | âŒ | âŒ | âŒ | âœ… |
Branding support              | âœ… | âœ… | âŒ | âŒ | âŒ | âœ… |
activity log                  | :construction: | âŒ | âŒ | âœ… | âœ… | âœ… |
Comments support              | âŒ | âŒ | âŒ | âœ… | âœ… | âœ… |
trash support                 | :construction: | âŒ | âŒ | âœ… | âœ… | âœ… |
Starred/pinned files          | âŒ | âŒ | âŒ | âŒ | âœ… | âœ… |
Chromecast support            | âŒ | âŒ | âœ… | âŒ | âŒ | âŒ |
Share collections of files    | :construction: | âŒ | âŒ | âŒ | âŒ | âœ… |
Can archive selected files    | :construction: | âŒ | âŒ | âŒ | âŒ | âœ… |
Can browse archive files      | :construction: | âŒ | âŒ | âŒ | âŒ | âœ… |
Can convert documents         | :construction: | âŒ | âŒ | âŒ | âŒ | âœ… |
Can convert videos            | :construction: | âŒ | âŒ | âŒ | âŒ | âŒ |
Can convert photos            | :construction: | âŒ | âŒ | âŒ | âŒ | âŒ |
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grpc/grpc-go]]></title>
            <link>https://github.com/grpc/grpc-go</link>
            <guid>https://github.com/grpc/grpc-go</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:40 GMT</pubDate>
            <description><![CDATA[The Go language implementation of gRPC. HTTP/2 based RPC]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grpc/grpc-go">grpc/grpc-go</a></h1>
            <p>The Go language implementation of gRPC. HTTP/2 based RPC</p>
            <p>Language: Go</p>
            <p>Stars: 22,486</p>
            <p>Forks: 4,603</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># gRPC-Go

[![GoDoc](https://pkg.go.dev/badge/google.golang.org/grpc)][API]
[![GoReportCard](https://goreportcard.com/badge/grpc/grpc-go)](https://goreportcard.com/report/github.com/grpc/grpc-go)
[![codecov](https://codecov.io/gh/grpc/grpc-go/graph/badge.svg)](https://codecov.io/gh/grpc/grpc-go)

The [Go][] implementation of [gRPC][]: A high performance, open source, general
RPC framework that puts mobile and HTTP/2 first. For more information see the
[Go gRPC docs][], or jump directly into the [quick start][].

## Prerequisites

- **[Go][]**: any one of the **two latest major** [releases][go-releases].

## Installation

Simply add the following import to your code, and then `go [build|run|test]`
will automatically fetch the necessary dependencies:


```go
import &quot;google.golang.org/grpc&quot;
```

&gt; **Note:** If you are trying to access `grpc-go` from **China**, see the
&gt; [FAQ](#FAQ) below.

## Learn more

- [Go gRPC docs][], which include a [quick start][] and [API
  reference][API] among other resources
- [Low-level technical docs](Documentation) from this repository
- [Performance benchmark][]
- [Examples](examples)
- [Contribution guidelines](CONTRIBUTING.md)

## FAQ

### I/O Timeout Errors

The `golang.org` domain may be blocked from some countries. `go get` usually
produces an error like the following when this happens:

```console
$ go get -u google.golang.org/grpc
package google.golang.org/grpc: unrecognized import path &quot;google.golang.org/grpc&quot; (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)
```

To build Go code, there are several options:

- Set up a VPN and access google.golang.org through that.

- With Go module support: it is possible to use the `replace` feature of `go
  mod` to create aliases for golang.org packages.  In your project&#039;s directory:

  ```sh
  go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest
  go mod tidy
  go mod vendor
  go build -mod=vendor
  ```

  Again, this will need to be done for all transitive dependencies hosted on
  golang.org as well. For details, refer to [golang/go issue
  #28652](https://github.com/golang/go/issues/28652).

### Compiling error, undefined: grpc.SupportPackageIsVersion

Please update to the latest version of gRPC-Go using
`go get google.golang.org/grpc`.

### How to turn on logging

The default logger is controlled by environment variables. Turn everything on
like this:

```console
$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99
$ export GRPC_GO_LOG_SEVERITY_LEVEL=info
```

### The RPC failed with error `&quot;code = Unavailable desc = transport is closing&quot;`

This error means the connection the RPC is using was closed, and there are many
possible reasons, including:
 1. mis-configured transport credentials, connection failed on handshaking
 1. bytes disrupted, possibly by a proxy in between
 1. server shutdown
 1. Keepalive parameters caused connection shutdown, for example if you have
    configured your server to terminate connections regularly to [trigger DNS
    lookups](https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779).
    If this is the case, you may want to increase your
    [MaxConnectionAgeGrace](https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters),
    to allow longer RPC calls to finish.

It can be tricky to debug this because the error happens on the client side but
the root cause of the connection being closed is on the server side. Turn on
logging on __both client and server__, and see if there are any transport
errors.

[API]: https://pkg.go.dev/google.golang.org/grpc
[Go]: https://golang.org
[Go module]: https://github.com/golang/go/wiki/Modules
[gRPC]: https://grpc.io
[Go gRPC docs]: https://grpc.io/docs/languages/go
[Performance benchmark]: https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608
[quick start]: https://grpc.io/docs/languages/go/quickstart
[go-releases]: https://golang.org/doc/devel/release.html
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gin-gonic/gin]]></title>
            <link>https://github.com/gin-gonic/gin</link>
            <guid>https://github.com/gin-gonic/gin</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:39 GMT</pubDate>
            <description><![CDATA[Gin is a high-performance HTTP web framework written in Go. It provides a Martini-like API but with significantly better performanceâ€”up to 40 times fasterâ€”thanks to httprouter. Gin is designed for building REST APIs, web applications, and microservices.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gin-gonic/gin">gin-gonic/gin</a></h1>
            <p>Gin is a high-performance HTTP web framework written in Go. It provides a Martini-like API but with significantly better performanceâ€”up to 40 times fasterâ€”thanks to httprouter. Gin is designed for building REST APIs, web applications, and microservices.</p>
            <p>Language: Go</p>
            <p>Stars: 86,775</p>
            <p>Forks: 8,467</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre># Gin Web Framework

&lt;img align=&quot;right&quot; width=&quot;159px&quot; src=&quot;https://raw.githubusercontent.com/gin-gonic/logo/master/color.png&quot;&gt;

[![Build Status](https://github.com/gin-gonic/gin/actions/workflows/gin.yml/badge.svg?branch=master)](https://github.com/gin-gonic/gin/actions/workflows/gin.yml)
[![codecov](https://codecov.io/gh/gin-gonic/gin/branch/master/graph/badge.svg)](https://codecov.io/gh/gin-gonic/gin)
[![Go Report Card](https://goreportcard.com/badge/github.com/gin-gonic/gin)](https://goreportcard.com/report/github.com/gin-gonic/gin)
[![Go Reference](https://pkg.go.dev/badge/github.com/gin-gonic/gin?status.svg)](https://pkg.go.dev/github.com/gin-gonic/gin?tab=doc)
[![Sourcegraph](https://sourcegraph.com/github.com/gin-gonic/gin/-/badge.svg)](https://sourcegraph.com/github.com/gin-gonic/gin?badge)
[![Open Source Helpers](https://www.codetriage.com/gin-gonic/gin/badges/users.svg)](https://www.codetriage.com/gin-gonic/gin)
[![Release](https://img.shields.io/github/release/gin-gonic/gin.svg?style=flat-square)](https://github.com/gin-gonic/gin/releases)

## ðŸ“° [Announcing Gin 1.11.0!](https://gin-gonic.com/en/blog/news/gin-1-11-0-release-announcement/)

Read about the latest features and improvements in Gin 1.11.0 on our official blog.

---

Gin is a high-performance HTTP web framework written in [Go](https://go.dev/). It provides a Martini-like API but with significantly better performanceâ€”up to 40 times fasterâ€”thanks to [httprouter](https://github.com/julienschmidt/httprouter). Gin is designed for building REST APIs, web applications, and microservices where speed and developer productivity are essential.

**Why choose Gin?**

Gin combines the simplicity of Express.js-style routing with Go&#039;s performance characteristics, making it ideal for:

- Building high-throughput REST APIs
- Developing microservices that need to handle many concurrent requests
- Creating web applications that require fast response times
- Prototyping web services quickly with minimal boilerplate

**Gin&#039;s key features:**

- **Zero allocation router** - Extremely memory-efficient routing with no heap allocations
- **High performance** - Benchmarks show superior speed compared to other Go web frameworks
- **Middleware support** - Extensible middleware system for authentication, logging, CORS, etc.
- **Crash-free** - Built-in recovery middleware prevents panics from crashing your server
- **JSON validation** - Automatic request/response JSON binding and validation
- **Route grouping** - Organize related routes and apply common middleware
- **Error management** - Centralized error handling and logging
- **Built-in rendering** - Support for JSON, XML, HTML templates, and more
- **Extensible** - Large ecosystem of community middleware and plugins

## Getting Started

### Prerequisites

- **Go version**: Gin requires [Go](https://go.dev/) version [1.24](https://go.dev/doc/devel/release#go1.24.0) or above
- **Basic Go knowledge**: Familiarity with Go syntax and package management is helpful

### Installation

With [Go&#039;s module support](https://go.dev/wiki/Modules#how-to-use-modules), simply import Gin in your code and Go will automatically fetch it during build:

```go
import &quot;github.com/gin-gonic/gin&quot;
```

### Your First Gin Application

Here&#039;s a complete example that demonstrates Gin&#039;s simplicity:

```go
package main

import (
  &quot;net/http&quot;

  &quot;github.com/gin-gonic/gin&quot;
)

func main() {
  // Create a Gin router with default middleware (logger and recovery)
  r := gin.Default()
  
  // Define a simple GET endpoint
  r.GET(&quot;/ping&quot;, func(c *gin.Context) {
    // Return JSON response
    c.JSON(http.StatusOK, gin.H{
      &quot;message&quot;: &quot;pong&quot;,
    })
  })
  
  // Start server on port 8080 (default)
  // Server will listen on 0.0.0.0:8080 (localhost:8080 on Windows)
  r.Run()
}
```

**Running the application:**

1. Save the code above as `main.go`
2. Run the application:

   ```sh
   go run main.go
   ```

3. Open your browser and visit [`http://localhost:8080/ping`](http://localhost:8080/ping)
4. You should see: `{&quot;message&quot;:&quot;pong&quot;}`

**What this example demonstrates:**

- Creating a Gin router with default middleware
- Defining HTTP endpoints with simple handler functions
- Returning JSON responses
- Starting an HTTP server

### Next Steps

After running your first Gin application, explore these resources to learn more:

#### ðŸ“š Learning Resources

- **[Gin Quick Start Guide](docs/doc.md)** - Comprehensive tutorial with API examples and build configurations
- **[Example Repository](https://github.com/gin-gonic/examples)** - Ready-to-run examples demonstrating various Gin use cases:
  - REST API development
  - Authentication &amp; middleware
  - File uploads and downloads
  - WebSocket connections
  - Template rendering

## ðŸ“– Documentation

### API Reference

- **[Go.dev API Documentation](https://pkg.go.dev/github.com/gin-gonic/gin)** - Complete API reference with examples

### User Guides

The comprehensive documentation is available on [gin-gonic.com](https://gin-gonic.com) in multiple languages:

- [English](https://gin-gonic.com/en/docs/) | [ç®€ä½“ä¸­æ–‡](https://gin-gonic.com/zh-cn/docs/) | [ç¹é«”ä¸­æ–‡](https://gin-gonic.com/zh-tw/docs/)
- [æ—¥æœ¬èªž](https://gin-gonic.com/ja/docs/) | [í•œêµ­ì–´](https://gin-gonic.com/ko-kr/docs/) | [EspaÃ±ol](https://gin-gonic.com/es/docs/)
- [Turkish](https://gin-gonic.com/tr/docs/) | [Persian](https://gin-gonic.com/fa/docs/) | [PortuguÃªs](https://gin-gonic.com/pt/docs/)
- [Russian](https://gin-gonic.com/ru/docs/) | [Indonesian](https://gin-gonic.com/id/docs/)

### Official Tutorials

- [Go.dev Tutorial: Developing a RESTful API with Go and Gin](https://go.dev/doc/tutorial/web-service-gin)

## âš¡ Performance Benchmarks

Gin demonstrates exceptional performance compared to other Go web frameworks. It uses a custom version of [HttpRouter](https://github.com/julienschmidt/httprouter) for maximum efficiency. [View detailed benchmarks â†’](/BENCHMARKS.md)

**Gin vs. Other Go Frameworks** (GitHub API routing benchmark):

| Benchmark name                 |       (1) |             (2) |          (3) |             (4) |
| ------------------------------ | --------: | --------------: | -----------: | --------------: |
| BenchmarkGin_GithubAll         | **43550** | **27364 ns/op** |   **0 B/op** | **0 allocs/op** |
| BenchmarkAce_GithubAll         |     40543 |     29670 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkAero_GithubAll        |     57632 |     20648 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkBear_GithubAll        |      9234 |    216179 ns/op |   86448 B/op |   943 allocs/op |
| BenchmarkBeego_GithubAll       |      7407 |    243496 ns/op |   71456 B/op |   609 allocs/op |
| BenchmarkBone_GithubAll        |       420 |   2922835 ns/op |  720160 B/op |  8620 allocs/op |
| BenchmarkChi_GithubAll         |      7620 |    238331 ns/op |   87696 B/op |   609 allocs/op |
| BenchmarkDenco_GithubAll       |     18355 |     64494 ns/op |   20224 B/op |   167 allocs/op |
| BenchmarkEcho_GithubAll        |     31251 |     38479 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkGocraftWeb_GithubAll  |      4117 |    300062 ns/op |  131656 B/op |  1686 allocs/op |
| BenchmarkGoji_GithubAll        |      3274 |    416158 ns/op |   56112 B/op |   334 allocs/op |
| BenchmarkGojiv2_GithubAll      |      1402 |    870518 ns/op |  352720 B/op |  4321 allocs/op |
| BenchmarkGoJsonRest_GithubAll  |      2976 |    401507 ns/op |  134371 B/op |  2737 allocs/op |
| BenchmarkGoRestful_GithubAll   |       410 |   2913158 ns/op |  910144 B/op |  2938 allocs/op |
| BenchmarkGorillaMux_GithubAll  |       346 |   3384987 ns/op |  251650 B/op |  1994 allocs/op |
| BenchmarkGowwwRouter_GithubAll |     10000 |    143025 ns/op |   72144 B/op |   501 allocs/op |
| BenchmarkHttpRouter_GithubAll  |     55938 |     21360 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkHttpTreeMux_GithubAll |     10000 |    153944 ns/op |   65856 B/op |   671 allocs/op |
| BenchmarkKocha_GithubAll       |     10000 |    106315 ns/op |   23304 B/op |   843 allocs/op |
| BenchmarkLARS_GithubAll        |     47779 |     25084 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkMacaron_GithubAll     |      3266 |    371907 ns/op |  149409 B/op |  1624 allocs/op |
| BenchmarkMartini_GithubAll     |       331 |   3444706 ns/op |  226551 B/op |  2325 allocs/op |
| BenchmarkPat_GithubAll         |       273 |   4381818 ns/op | 1483152 B/op | 26963 allocs/op |
| BenchmarkPossum_GithubAll      |     10000 |    164367 ns/op |   84448 B/op |   609 allocs/op |
| BenchmarkR2router_GithubAll    |     10000 |    160220 ns/op |   77328 B/op |   979 allocs/op |
| BenchmarkRivet_GithubAll       |     14625 |     82453 ns/op |   16272 B/op |   167 allocs/op |
| BenchmarkTango_GithubAll       |      6255 |    279611 ns/op |   63826 B/op |  1618 allocs/op |
| BenchmarkTigerTonic_GithubAll  |      2008 |    687874 ns/op |  193856 B/op |  4474 allocs/op |
| BenchmarkTraffic_GithubAll     |       355 |   3478508 ns/op |  820744 B/op | 14114 allocs/op |
| BenchmarkVulcan_GithubAll      |      6885 |    193333 ns/op |   19894 B/op |   609 allocs/op |

- (1): Total Repetitions achieved in constant time, higher means more confident result
- (2): Single Repetition Duration (ns/op), lower is better
- (3): Heap Memory (B/op), lower is better
- (4): Average Allocations per Repetition (allocs/op), lower is better

## ðŸ”Œ Middleware Ecosystem

Gin has a rich ecosystem of middleware for common web development needs. Explore community-contributed middleware:

- **[gin-contrib](https://github.com/gin-contrib)** - Official middleware collection including:
  - Authentication (JWT, Basic Auth, Sessions)
  - CORS, Rate limiting, Compression
  - Logging, Metrics, Tracing
  - Static file serving, Template engines
  
- **[gin-gonic/contrib](https://github.com/gin-gonic/contrib)** - Additional community middleware

## ðŸ¢ Production Usage

Gin powers many high-traffic applications and services in production:

- **[gorush](https://github.com/appleboy/gorush)** - High-performance push notification server
- **[fnproject](https://github.com/fnproject/fn)** - Container-native, serverless platform
- **[photoprism](https://github.com/photoprism/photoprism)** - AI-powered personal photo management
- **[lura](https://github.com/luraproject/lura)** - Ultra-performant API Gateway framework
- **[picfit](https://github.com/thoas/picfit)** - Real-time image processing server
- **[dkron](https://github.com/distribworks/dkron)** - Distributed job scheduling system

## ðŸ¤ Contributing

Gin is the work of hundreds of contributors from around the world. We welcome and appreciate your contributions!

### How to Contribute

- ðŸ› **Report bugs** - Help us identify and fix issues
- ðŸ’¡ **Suggest features** - Share your ideas for improvements
- ðŸ“ **Improve documentation** - Help make our docs clearer
- ðŸ”§ **Submit code** - Fix bugs or implement new features
- ðŸ§ª **Write tests** - Improve our test coverage

### Getting Started with Contributing

1. Check out our [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines
2. Join our community discussions and ask questions

**All contributions are valued and help make Gin better for everyone!**
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ethereum/go-ethereum]]></title>
            <link>https://github.com/ethereum/go-ethereum</link>
            <guid>https://github.com/ethereum/go-ethereum</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:38 GMT</pubDate>
            <description><![CDATA[Go implementation of the Ethereum protocol]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ethereum/go-ethereum">ethereum/go-ethereum</a></h1>
            <p>Go implementation of the Ethereum protocol</p>
            <p>Language: Go</p>
            <p>Stars: 50,186</p>
            <p>Forks: 21,487</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>## Go Ethereum

Golang execution layer implementation of the Ethereum protocol.

[![API Reference](
https://pkg.go.dev/badge/github.com/ethereum/go-ethereum
)](https://pkg.go.dev/github.com/ethereum/go-ethereum?tab=doc)
[![Go Report Card](https://goreportcard.com/badge/github.com/ethereum/go-ethereum)](https://goreportcard.com/report/github.com/ethereum/go-ethereum)
[![Travis](https://app.travis-ci.com/ethereum/go-ethereum.svg?branch=master)](https://app.travis-ci.com/github/ethereum/go-ethereum)
[![Discord](https://img.shields.io/badge/discord-join%20chat-blue.svg)](https://discord.gg/nthXNEv)
[![Twitter](https://img.shields.io/twitter/follow/go_ethereum)](https://x.com/go_ethereum)

Automated builds are available for stable releases and the unstable master branch. Binary
archives are published at https://geth.ethereum.org/downloads/.

## Building the source

For prerequisites and detailed build instructions please read the [Installation Instructions](https://geth.ethereum.org/docs/getting-started/installing-geth).

Building `geth` requires both a Go (version 1.23 or later) and a C compiler. You can install
them using your favourite package manager. Once the dependencies are installed, run

```shell
make geth
```

or, to build the full suite of utilities:

```shell
make all
```

## Executables

The go-ethereum project comes with several wrappers/executables found in the `cmd`
directory.

|  Command   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| :--------: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`geth`** | Our main Ethereum CLI client. It is the entry point into the Ethereum network (main-, test- or private net), capable of running as a full node (default), archive node (retaining all historical state) or a light node (retrieving data live). It can be used by other processes as a gateway into the Ethereum network via JSON RPC endpoints exposed on top of HTTP, WebSocket and/or IPC transports. `geth --help` and the [CLI page](https://geth.ethereum.org/docs/fundamentals/command-line-options) for command line options. |
|   `clef`   | Stand-alone signing tool, which can be used as a backend signer for `geth`.                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
|  `devp2p`  | Utilities to interact with nodes on the networking layer, without running a full blockchain.                                                                                                                                                                                                                                                                                                                                                                                                                                       |
|  `abigen`  | Source code generator to convert Ethereum contract definitions into easy-to-use, compile-time type-safe Go packages. It operates on plain [Ethereum contract ABIs](https://docs.soliditylang.org/en/develop/abi-spec.html) with expanded functionality if the contract bytecode is also available. However, it also accepts Solidity source files, making development much more streamlined. Please see our [Native DApps](https://geth.ethereum.org/docs/developers/dapp-developer/native-bindings) page for details.                                  |
|   `evm`    | Developer utility version of the EVM (Ethereum Virtual Machine) that is capable of running bytecode snippets within a configurable environment and execution mode. Its purpose is to allow isolated, fine-grained debugging of EVM opcodes (e.g. `evm --code 60ff60ff --debug run`).                                                                                                                                                                                                                                               |
| `rlpdump`  | Developer utility tool to convert binary RLP ([Recursive Length Prefix](https://ethereum.org/en/developers/docs/data-structures-and-encoding/rlp)) dumps (data encoding used by the Ethereum protocol both network as well as consensus wise) to user-friendlier hierarchical representation (e.g. `rlpdump --hex CE0183FFFFFFC4C304050583616263`).                                                                                                                                                                                |

## Running `geth`

Going through all the possible command line flags is out of scope here (please consult our
[CLI Wiki page](https://geth.ethereum.org/docs/fundamentals/command-line-options)),
but we&#039;ve enumerated a few common parameter combos to get you up to speed quickly
on how you can run your own `geth` instance.

### Hardware Requirements

Minimum:

* CPU with 4+ cores
* 8GB RAM
* 1TB free storage space to sync the Mainnet
* 8 MBit/sec download Internet service

Recommended:

* Fast CPU with 8+ cores
* 16GB+ RAM
* High-performance SSD with at least 1TB of free space
* 25+ MBit/sec download Internet service

### Full node on the main Ethereum network

By far the most common scenario is people wanting to simply interact with the Ethereum
network: create accounts; transfer funds; deploy and interact with contracts. For this
particular use case, the user doesn&#039;t care about years-old historical data, so we can
sync quickly to the current state of the network. To do so:

```shell
$ geth console
```

This command will:
 * Start `geth` in snap sync mode (default, can be changed with the `--syncmode` flag),
   causing it to download more data in exchange for avoiding processing the entire history
   of the Ethereum network, which is very CPU intensive.
 * Start the built-in interactive [JavaScript console](https://geth.ethereum.org/docs/interacting-with-geth/javascript-console),
   (via the trailing `console` subcommand) through which you can interact using [`web3` methods](https://github.com/ChainSafe/web3.js/blob/0.20.7/DOCUMENTATION.md) 
   (note: the `web3` version bundled within `geth` is very old, and not up to date with official docs),
   as well as `geth`&#039;s own [management APIs](https://geth.ethereum.org/docs/interacting-with-geth/rpc).
   This tool is optional and if you leave it out you can always attach it to an already running
   `geth` instance with `geth attach`.

### A Full node on the Holesky test network

Transitioning towards developers, if you&#039;d like to play around with creating Ethereum
contracts, you almost certainly would like to do that without any real money involved until
you get the hang of the entire system. In other words, instead of attaching to the main
network, you want to join the **test** network with your node, which is fully equivalent to
the main network, but with play-Ether only.

```shell
$ geth --holesky console
```

The `console` subcommand has the same meaning as above and is equally
useful on the testnet too.

Specifying the `--holesky` flag, however, will reconfigure your `geth` instance a bit:

 * Instead of connecting to the main Ethereum network, the client will connect to the Holesky 
   test network, which uses different P2P bootnodes, different network IDs and genesis
   states.
 * Instead of using the default data directory (`~/.ethereum` on Linux for example), `geth`
   will nest itself one level deeper into a `holesky` subfolder (`~/.ethereum/holesky` on
   Linux). Note, on OSX and Linux this also means that attaching to a running testnet node
   requires the use of a custom endpoint since `geth attach` will try to attach to a
   production node endpoint by default, e.g.,
   `geth attach &lt;datadir&gt;/holesky/geth.ipc`. Windows users are not affected by
   this.

*Note: Although some internal protective measures prevent transactions from
crossing over between the main network and test network, you should always
use separate accounts for play and real money. Unless you manually move
accounts, `geth` will by default correctly separate the two networks and will not make any
accounts available between them.*

### Configuration

As an alternative to passing the numerous flags to the `geth` binary, you can also pass a
configuration file via:

```shell
$ geth --config /path/to/your_config.toml
```

To get an idea of how the file should look like you can use the `dumpconfig` subcommand to
export your existing configuration:

```shell
$ geth --your-favourite-flags dumpconfig
```

#### Docker quick start

One of the quickest ways to get Ethereum up and running on your machine is by using
Docker:

```shell
docker run -d --name ethereum-node -v /Users/alice/ethereum:/root \
           -p 8545:8545 -p 30303:30303 \
           ethereum/client-go
```

This will start `geth` in snap-sync mode with a DB memory allowance of 1GB, as the
above command does.  It will also create a persistent volume in your home directory for
saving your blockchain as well as map the default ports. There is also an `alpine` tag
available for a slim version of the image.

Do not forget `--http.addr 0.0.0.0`, if you want to access RPC from other containers
and/or hosts. By default, `geth` binds to the local interface and RPC endpoints are not
accessible from the outside.

### Programmatically interfacing `geth` nodes

As a developer, sooner rather than later you&#039;ll want to start interacting with `geth` and the
Ethereum network via your own programs and not manually through the console. To aid
this, `geth` has built-in support for a JSON-RPC based APIs ([standard APIs](https://ethereum.org/en/developers/docs/apis/json-rpc/)
and [`geth` specific APIs](https://geth.ethereum.org/docs/interacting-with-geth/rpc)).
These can be exposed via HTTP, WebSockets and IPC (UNIX sockets on UNIX based
platforms, and named pipes on Windows).

The IPC interface is enabled by default and exposes all the APIs supported by `geth`,
whereas the HTTP and WS interfaces need to manually be enabled and only expose a
subset of APIs due to security reasons. These can be turned on/off and configured as
you&#039;d expect.

HTTP based JSON-RPC API options:

  * `--http` Enable the HTTP-RPC server
  * `--http.addr` HTTP-RPC server listening interface (default: `localhost`)
  * `--http.port` HTTP-RPC server listening port (default: `8545`)
  * `--http.api` API&#039;s offered over the HTTP-RPC interface (default: `eth,net,web3`)
  * `--http.corsdomain` Comma separated list of domains from which to accept cross-origin requests (browser enforced)
  * `--ws` Enable the WS-RPC server
  * `--ws.addr` WS-RPC server listening interface (default: `localhost`)
  * `--ws.port` WS-RPC server listening port (default: `8546`)
  * `--ws.api` API&#039;s offered over the WS-RPC interface (default: `eth,net,web3`)
  * `--ws.origins` Origins from which to accept WebSocket requests
  * `--ipcdisable` Disable the IPC-RPC server
  * `--ipcpath` Filename for IPC socket/pipe within the datadir (explicit paths escape it)

You&#039;ll need to use your own programming environments&#039; capabilities (libraries, tools, etc) to
connect via HTTP, WS or IPC to a `geth` node configured with the above flags and you&#039;ll
need to speak [JSON-RPC](https://www.jsonrpc.org/specification) on all transports. You
can reuse the same connection for multiple requests!

**Note: Please understand the security implications of opening up an HTTP/WS based
transport before doing so! Hackers on the internet are actively trying to subvert
Ethereum nodes with exposed APIs! Further, all browser tabs can access locally
running web servers, so malicious web pages could try to subvert locally available
APIs!**

### Operating a private network

Maintaining your own private network is more involved as a lot of configurations taken for
granted in the official networks need to be manually set up.

Unfortunately since [the Merge](https://ethereum.org/en/roadmap/merge/) it is no longer possible
to easily set up a network of geth nodes without also setting up a corresponding beacon chain.

There are three different solutions depending on your use case:

  * If you are looking for a simple way to test smart contracts from go in your CI, you can use the [Simulated Backend](https://geth.ethereum.org/docs/developers/dapp-developer/native-bindings#blockchain-simulator).
  * If you want a convenient single node environment for testing, you can use our [Dev Mode](https://geth.ethereum.org/docs/developers/dapp-developer/dev-mode).
  * If you are looking for a multiple node test network, you can set one up quite easily with [Kurtosis](https://geth.ethereum.org/docs/fundamentals/kurtosis).

## Contribution

Thank you for considering helping out with the source code! We welcome contributions
from anyone on the internet, and are grateful for even the smallest of fixes!

If you&#039;d like to contribute to go-ethereum, please fork, fix, commit and send a pull request
for the maintainers to review and merge into the main code base. If you wish to submit
more complex changes though, please check up with the core devs first on [our Discord Server](https://discord.gg/invite/nthXNEv)
to ensure those changes are in line with the general philosophy of the project and/or get
some early feedback which can make both your efforts much lighter as well as our review
and merge procedures quick and simple.

Please make sure your contributions adhere to our coding guidelines:

 * Code must adhere to the official Go [formatting](https://golang.org/doc/effective_go.html#formatting)
   guidelines (i.e. uses [gofmt](https://golang.org/cmd/gofmt/)).
 * Code must be documented adhering to the official Go [commentary](https://golang.org/doc/effective_go.html#commentary)
   guidelines.
 * Pull requests need to be based on and opened against the `master` branch.
 * Commit messages should be prefixed with the package(s) they modify.
   * E.g. &quot;eth, rpc: make trace configs optional&quot;

Please see the [Developers&#039; Guide](https://geth.ethereum.org/docs/developers/geth-developer/dev-guide)
for more details on configuring your environment, managing project dependencies, and
testing procedures.

### Contributing to geth.ethereum.org

For contributions to the [go-ethereum website](https://geth.ethereum.org), please checkout and raise pull requests against the `website` branch.
For more detailed instructions please see the `website` branch [README](https://github.com/ethereum/go-ethereum/tree/website#readme) or the 
[contributing](https://geth.ethereum.org/docs/developers/geth-developer/contributing) page of the website.

## License

The go-ethereum library (i.e. all code outside of the `cmd` directory) is licensed under the
[GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html),
also included in our repository in the `COPYING.LESSER` file.

The go-ethereum binaries (i.e. all code inside of the `cmd` directory) are licensed under the
[GNU General Public License v3.0](https://www.gnu.org/licenses/gpl-3.0.en.html), also
included in our repository in the `COPYING` file.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cosmos/cosmos-sdk]]></title>
            <link>https://github.com/cosmos/cosmos-sdk</link>
            <guid>https://github.com/cosmos/cosmos-sdk</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:37 GMT</pubDate>
            <description><![CDATA[â›“ï¸ A Framework for Building High Value Public Blockchains âœ¨]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cosmos/cosmos-sdk">cosmos/cosmos-sdk</a></h1>
            <p>â›“ï¸ A Framework for Building High Value Public Blockchains âœ¨</p>
            <p>Language: Go</p>
            <p>Stars: 6,827</p>
            <p>Forks: 4,080</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;left&quot;&gt;
  &lt;h1&gt; Cosmos SDK &lt;/h1&gt;
&lt;/div&gt;

![banner](docs/static/img/banner.svg)

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/cosmos/cosmos-sdk/blob/main/LICENSE&quot;&gt;
    &lt;img alt=&quot;License: Apache-2.0&quot; src=&quot;https://img.shields.io/github/license/cosmos/cosmos-sdk.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pkg.go.dev/github.com/cosmos/cosmos-sdk&quot;&gt;
    &lt;img src=&quot;https://pkg.go.dev/badge/github.com/cosmos/cosmos-sdk.svg&quot; alt=&quot;Go Reference&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/cosmos/cosmos-sdk&quot;&gt;
    &lt;img alt=&quot;Go report card&quot; src=&quot;https://goreportcard.com/badge/github.com/cosmos/cosmos-sdk&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.com/invite/interchain&quot;&gt;
    &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/669268347736686612.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://sourcegraph.com/github.com/cosmos/cosmos-sdk?badge&quot;&gt;
    &lt;img alt=&quot;Imported by&quot; src=&quot;https://sourcegraph.com/github.com/cosmos/cosmos-sdk/-/badge.svg&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

The Cosmos SDK is a modular, open-source blockchain SDK for building secure, high-performance Layer 1 chains with full customizability used by 200+ chains in production.   Developers can use the Cosmos SDK to easily and quickly spin up custom blockchains that can natively interoperate.

The Cosmos SDK is tailored for building secure, sovereign application-specific blockchains. Developers building with the Cosmos SDK can use predefined modules that cover standard blockchain functionality or create custom modules for their specific use case. This composable architecture enables robust customization. The SDK provides abstractions for permissioning, governance, state management, account abstraction, tokenization processes, application logic, and more.

Cosmos SDK blockchains get interoperability out-of-the-box via a native integration with the [Inter-Blockchain Communication Protocol (IBC)](https://github.com/cosmos/ibc-go). Ibc-go is implemented as a Go module in the Cosmos SDK. 

While the Cosmos SDK is plug-and-play with any consensus engine, we recommend using [CometBFT](https://github.com/cometbft/cometbft) for a fast, battle-tested, high-throughput, configurable BFT state machine. CometBFT is developed as part of the Cosmos Stack and its releases are updated alongside the SDK.

**WARNING**: The Cosmos SDK has mostly stabilized, but we are still making some breaking changes.

## Quick Start

To learn how the Cosmos SDK works from a high-level perspective, see the Cosmos SDK [High-Level Intro](https://docs.cosmos.network/main/intro/overview).

If you want to get started quickly and learn how to build on top of Cosmos SDK, visit [Cosmos SDK Tutorials](https://tutorials.cosmos.network). You can also fork the tutorial&#039;s repository to get started building your own Cosmos SDK application.

Note: We advise to always use the latest maintained [Go version](https://go.dev/dl/) for building Cosmos SDK applications.

## Modules

The Cosmos SDK maintains a set of modules that can be included in your blockchain application.  For more information
on modules, see our [introduction doc](./x/README.md).

## Maintainers
[Cosmos Labs](https://cosmoslabs.io/) maintains the core components of the stack: Cosmos SDK, CometBFT, IBC, Cosmos EVM, and various developer tools and frameworks. The detailed maintenance policy can be found [here](https://github.com/cosmos/security/blob/main/POLICY.md). In addition to developing and maintaining the Cosmos Stack, Cosmos Labs provides advisory and engineering services for blockchain solutions. [Get in touch with Cosmos Labs](https://www.cosmoslabs.io/contact).

Cosmos Labs is a wholly-owned subsidiary of the [Interchain Foundation](https://interchain.io/), the Swiss nonprofit responsible for treasury management, funding public goods, and supporting governance for Cosmos. 

The Cosmos Stack is supported by a robust community of open-source contributors. 

## History
The Cosmos SDK was first released in 2019, and the first blockchain to use the SDK in production was the [Cosmos Hub](https://hub.cosmos.network/main). Today, the Cosmos SDK is a popular, battle-tested, open-source framework used by hundreds of chains.

The Cosmos Hub still receives the most up-to-date Cosmos SDK versions. The Cosmos Hub application, `gaia`, has its own [cosmos/gaia repository](https://github.com/cosmos/gaia). 

## Developer Community and Support

The issue list of this repo is exclusively for bug reports and feature requests. We have active, helpful communities on Discord, Telegram, and Slack.

**| Need Help? | Support &amp; Community: [Discord](https://discord.com/invite/interchain) - [Telegram](https://t.me/CosmosOG) - [Talk to an Expert](https://cosmos.network/interest-form) - [Join the #Cosmos-tech Slack Channel](https://forms.gle/A8jawLgB8zuL1FN36) |**

## Documentation and Resources
**View the Cosmos SDK documentation: https://docs.cosmos.network/**

### Cosmos Stack Libraries

- [CometBFT](https://github.com/cometbft/cometbft) - High-performance, 10k+ TPS configurable BFT consensus engine.
- [The Inter-Blockchain Communication Protocol (IBC)](https://github.com/cosmos/ibc-go/) - A blockchain interoperability protocol that allows blockchains to transfer any type of data encoded in bytes.
- [Cosmos EVM](https://github.com/cosmos/evm) - Native EVM layer for Cosmos SDK chains. 

## Disambiguation

This Cosmos SDK project is not related to the [React-Cosmos](https://github.com/react-cosmos/react-cosmos) project (yet). Many thanks to Evan Coury and Ovidiu (@skidding) for this Github organization name. As per our agreement, this disambiguation notice will stay here.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[nektos/act]]></title>
            <link>https://github.com/nektos/act</link>
            <guid>https://github.com/nektos/act</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:36 GMT</pubDate>
            <description><![CDATA[Run your GitHub Actions locally ðŸš€]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nektos/act">nektos/act</a></h1>
            <p>Run your GitHub Actions locally ðŸš€</p>
            <p>Language: Go</p>
            <p>Stars: 66,734</p>
            <p>Forks: 1,771</p>
            <p>Stars today: 45 stars today</p>
            <h2>README</h2><pre>![act-logo](https://raw.githubusercontent.com/wiki/nektos/act/img/logo-150.png)

# Overview [![push](https://github.com/nektos/act/workflows/push/badge.svg?branch=master&amp;event=push)](https://github.com/nektos/act/actions) [![Go Report Card](https://goreportcard.com/badge/github.com/nektos/act)](https://goreportcard.com/report/github.com/nektos/act) [![awesome-runners](https://img.shields.io/badge/listed%20on-awesome--runners-blue.svg)](https://github.com/jonico/awesome-runners)

&gt; &quot;Think globally, `act` locally&quot;

Run your [GitHub Actions](https://developer.github.com/actions/) locally! Why would you want to do this? Two reasons:

- **Fast Feedback** - Rather than having to commit/push every time you want to test out the changes you are making to your `.github/workflows/` files (or for any changes to embedded GitHub actions), you can use `act` to run the actions locally. The [environment variables](https://help.github.com/en/actions/configuring-and-managing-workflows/using-environment-variables#default-environment-variables) and [filesystem](https://help.github.com/en/actions/reference/virtual-environments-for-github-hosted-runners#filesystems-on-github-hosted-runners) are all configured to match what GitHub provides.
- **Local Task Runner** - I love [make](&lt;https://en.wikipedia.org/wiki/Make_(software)&gt;). However, I also hate repeating myself. With `act`, you can use the GitHub Actions defined in your `.github/workflows/` to replace your `Makefile`!

&gt; [!TIP]
&gt; **Now Manage and Run Act Directly From VS Code!**&lt;br/&gt;
&gt; Check out the [GitHub Local Actions](https://sanjulaganepola.github.io/github-local-actions-docs/) Visual Studio Code extension which allows you to leverage the power of `act` to run and test workflows locally without leaving your editor.

# How Does It Work?

When you run `act` it reads in your GitHub Actions from `.github/workflows/` and determines the set of actions that need to be run. It uses the Docker API to either pull or build the necessary images, as defined in your workflow files and finally determines the execution path based on the dependencies that were defined. Once it has the execution path, it then uses the Docker API to run containers for each action based on the images prepared earlier. The [environment variables](https://help.github.com/en/actions/configuring-and-managing-workflows/using-environment-variables#default-environment-variables) and [filesystem](https://docs.github.com/en/actions/using-github-hosted-runners/about-github-hosted-runners#file-systems) are all configured to match what GitHub provides.

Let&#039;s see it in action with a [sample repo](https://github.com/cplee/github-actions-demo)!

![Demo](https://raw.githubusercontent.com/wiki/nektos/act/quickstart/act-quickstart-2.gif)

# Act User Guide

Please look at the [act user guide](https://nektosact.com) for more documentation.

# Support

Need help? Ask in [discussions](https://github.com/nektos/act/discussions)!

# Contributing

Want to contribute to act? Awesome! Check out the [contributing guidelines](CONTRIBUTING.md) to get involved.

## Manually building from source

- Install Go tools 1.20+ - (&lt;https://golang.org/doc/install&gt;)
- Clone this repo `git clone git@github.com:nektos/act.git`
- Run unit tests with `make test`
- Build and install: `make install`
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[bluenviron/mediamtx]]></title>
            <link>https://github.com/bluenviron/mediamtx</link>
            <guid>https://github.com/bluenviron/mediamtx</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:35 GMT</pubDate>
            <description><![CDATA[Ready-to-use SRT / WebRTC / RTSP / RTMP / LL-HLS / MPEG-TS / RTP media server and media proxy that allows to read, publish, proxy, record and playback video and audio streams.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bluenviron/mediamtx">bluenviron/mediamtx</a></h1>
            <p>Ready-to-use SRT / WebRTC / RTSP / RTMP / LL-HLS / MPEG-TS / RTP media server and media proxy that allows to read, publish, proxy, record and playback video and audio streams.</p>
            <p>Language: Go</p>
            <p>Stars: 16,842</p>
            <p>Forks: 2,007</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mediamtx.org&quot;&gt;
    &lt;img src=&quot;logo.png&quot; alt=&quot;MediaMTX&quot;&gt;
  &lt;/a&gt;

  &lt;br&gt;
  &lt;br&gt;

  [![Website](https://img.shields.io/badge/website-mediamtx.org-1c94b5)](https://mediamtx.org)
  [![Test](https://github.com/bluenviron/mediamtx/actions/workflows/code_test.yml/badge.svg)](https://github.com/bluenviron/mediamtx/actions/workflows/code_test.yml)
  [![Lint](https://github.com/bluenviron/mediamtx/actions/workflows/code_lint.yml/badge.svg)](https://github.com/bluenviron/mediamtx/actions/workflows/code_lint.yml)
  [![CodeCov](https://codecov.io/gh/bluenviron/mediamtx/branch/main/graph/badge.svg)](https://app.codecov.io/gh/bluenviron/mediamtx/tree/main)
  [![Release](https://img.shields.io/github/v/release/bluenviron/mediamtx)](https://github.com/bluenviron/mediamtx/releases)
  [![Docker Hub](https://img.shields.io/badge/docker-bluenviron/mediamtx-blue)](https://hub.docker.com/r/bluenviron/mediamtx)
&lt;/h1&gt;

&lt;br&gt;

_MediaMTX_ is a ready-to-use and zero-dependency real-time media server and media proxy that allows to publish, read, proxy, record and playback video and audio streams. It has been conceived as a &quot;media router&quot; that routes media streams from one end to the other.

&lt;div align=&quot;center&quot;&gt;

  |[Install](https://mediamtx.org/docs/kickoff/install)|[Documentation](https://mediamtx.org/docs/kickoff/introduction)|
  |-|-|

&lt;/div&gt;

&lt;h3&gt;Features&lt;/h3&gt;

- [Publish](https://mediamtx.org/docs/usage/publish) live streams to the server with SRT, WebRTC, RTSP, RTMP, HLS, MPEG-TS, RTP
- [Read](https://mediamtx.org/docs/usage/read) live streams from the server with SRT, WebRTC, RTSP, RTMP, HLS
- Streams are automatically converted from a protocol to another
- Serve several streams at once in separate paths
- Reload the configuration without disconnecting existing clients (hot reloading)
- [Record](https://mediamtx.org/docs/usage/record) streams to disk in fMP4 or MPEG-TS format
- [Playback](https://mediamtx.org/docs/usage/playback) recorded streams
- [Authenticate](https://mediamtx.org/docs/usage/authentication) users with internal, HTTP or JWT authentication
- [Forward](https://mediamtx.org/docs/usage/forward) streams to other servers
- [Proxy](https://mediamtx.org/docs/usage/proxy) requests to other servers
- [Control](https://mediamtx.org/docs/usage/control-api) the server through the Control API
- [Extract metrics](https://mediamtx.org/docs/usage/metrics) from the server in a Prometheus-compatible format
- [Monitor performance](https://mediamtx.org/docs/usage/performance) to investigate CPU and RAM consumption
- [Run hooks](https://mediamtx.org/docs/usage/hooks) (external commands) when clients connect, disconnect, read or publish streams
- Compatible with Linux, Windows and macOS, does not require any dependency or interpreter, it&#039;s a single executable
- ...and many [others](https://mediamtx.org/docs/kickoff/introduction).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[NVIDIA/k8s-device-plugin]]></title>
            <link>https://github.com/NVIDIA/k8s-device-plugin</link>
            <guid>https://github.com/NVIDIA/k8s-device-plugin</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:34 GMT</pubDate>
            <description><![CDATA[NVIDIA device plugin for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NVIDIA/k8s-device-plugin">NVIDIA/k8s-device-plugin</a></h1>
            <p>NVIDIA device plugin for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 3,510</p>
            <p>Forks: 752</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># NVIDIA device plugin for Kubernetes

[![End-to-end Tests](https://github.com/NVIDIA/k8s-device-plugin/actions/workflows/e2e.yaml/badge.svg)](https://github.com/NVIDIA/k8s-device-plugin/actions/workflows/e2e.yaml) [![Go Report Card](https://goreportcard.com/badge/github.com/NVIDIA/k8s-device-plugin)](https://goreportcard.com/report/github.com/NVIDIA/k8s-device-plugin) [![Latest Release](https://img.shields.io/github/v/release/NVIDIA/k8s-device-plugin)](https://github.com/NVIDIA/k8s-device-plugin/releases/latest)

## Table of Contents

- [About](#about)
- [Prerequisites](#prerequisites)
- [Quick Start](#quick-start)
  - [Preparing your GPU Nodes](#preparing-your-gpu-nodes)
    - [Example for debian-based systems with `docker` and `containerd`](#example-for-debian-based-systems-with-docker-and-containerd)
      - [Install the NVIDIA Container Toolkit](#install-the-nvidia-container-toolkit)
      - [Notes on `CRI-O` configuration](#notes-on-cri-o-configuration)
  - [Enabling GPU Support in Kubernetes](#enabling-gpu-support-in-kubernetes)
  - [Running GPU Jobs](#running-gpu-jobs)
- [Configuring the NVIDIA device plugin binary](#configuring-the-nvidia-device-plugin-binary)
  - [As command line flags or envvars](#as-command-line-flags-or-envvars)
  - [As a configuration file](#as-a-configuration-file)
  - [Configuration Option Details](#configuration-option-details)
  - [Shared Access to GPUs](#shared-access-to-gpus)
    - [With CUDA Time-Slicing](#with-cuda-time-slicing)
    - [With CUDA MPS](#with-cuda-mps)
  - [IMEX Support](#imex-support)
- [Catalog of Labels](#catalog-of-labels)
- [Deployment via `helm`](#deployment-via-helm)
  - [Configuring the device plugin&#039;s `helm` chart](#configuring-the-device-plugins-helm-chart)
    - [Passing configuration to the plugin via a `ConfigMap`](#passing-configuration-to-the-plugin-via-a-configmap)
      - [Single Config File Example](#single-config-file-example)
      - [Multiple Config File Example](#multiple-config-file-example)
      - [Updating Per-Node Configuration With a Node Label](#updating-per-node-configuration-with-a-node-label)
    - [Setting other helm chart values](#setting-other-helm-chart-values)
    - [Deploying with gpu-feature-discovery for automatic node labels](#deploying-with-gpu-feature-discovery-for-automatic-node-labels)
    - [Deploying gpu-feature-discovery in standalone mode](#deploying-gpu-feature-discovery-in-standalone-mode)
  - [Deploying via `helm install` with a direct URL to the `helm` package](#deploying-via-helm-install-with-a-direct-url-to-the-helm-package)
- [Building and Running Locally](#building-and-running-locally)
  - [With Docker](#with-docker)
    - [Build](#build)
    - [Run](#run)
  - [Without Docker](#without-docker)
    - [Build](#build-1)
    - [Run](#run-1)
- [Changelog](#changelog)
- [Issues and Contributing](#issues-and-contributing)
  - [Versioning](#versioning)
  - [Upgrading Kubernetes with the Device Plugin](#upgrading-kubernetes-with-the-device-plugin)

## About

The NVIDIA device plugin for Kubernetes is a Daemonset that allows you to automatically:

- Expose the number of GPUs on each nodes of your cluster
- Keep track of the health of your GPUs
- Run GPU enabled containers in your Kubernetes cluster.

This repository contains NVIDIA&#039;s official implementation of the [Kubernetes device plugin](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/).
As of v0.15.0 this repository also holds the implementation for GPU Feature Discovery labels,
for further information on GPU Feature Discovery see [here](docs/gpu-feature-discovery/README.md).

Please note that:

- The NVIDIA device plugin API is beta as of Kubernetes v1.10.
- The NVIDIA device plugin is currently lacking
  - Comprehensive GPU health checking features
  - GPU cleanup features
- Support will only be provided for the official NVIDIA device plugin (and not
  for forks or other variants of this plugin).

## Prerequisites

The list of prerequisites for running the NVIDIA device plugin is described below:

- NVIDIA drivers ~= 384.81
- nvidia-docker &gt;= 2.0 || nvidia-container-toolkit &gt;= 1.7.0 (&gt;= 1.11.0 to use integrated GPUs on Tegra-based systems)
- nvidia-container-runtime configured as the default low-level runtime
- Kubernetes version &gt;= 1.10

## Quick Start

### Preparing your GPU Nodes

The following steps need to be executed on all your GPU nodes.
This README assumes that the NVIDIA drivers and the `nvidia-container-toolkit` have been pre-installed.
It also assumes that you have configured the `nvidia-container-runtime` as the default low-level runtime to use.

Please see: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html

#### Example for debian-based systems with `docker` and `containerd`

##### Install the NVIDIA Container Toolkit

For instructions on installing and getting started with the NVIDIA Container Toolkit, refer to the [installation guide](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installation-guide).

Also note the configuration instructions for:

- [`containerd`](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuring-containerd-for-kubernetes)
- [`CRI-O`](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuring-cri-o)
- [`docker` (Deprecated)](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuring-docker)

Remembering to restart each runtime after applying the configuration changes.

If the `nvidia` runtime should be set as the default runtime (with non-cri docker versions, for example), the `--set-as-default` argument
must also be included in the commands above. If this is not done, a RuntimeClass needs to be defined:

```yaml
apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: nvidia
handler: nvidia
```

##### Notes on `CRI-O` configuration

When running `kubernetes` with `CRI-O`, add the config file to set the
`nvidia-container-runtime` as the default low-level OCI runtime under
`/etc/crio/crio.conf.d/99-nvidia.conf`. This will take priority over the default
`crun` config file at `/etc/crio/crio.conf.d/10-crun.conf`:

```toml
[crio]

  [crio.runtime]
    default_runtime = &quot;nvidia&quot;

    [crio.runtime.runtimes]

      [crio.runtime.runtimes.nvidia]
        runtime_path = &quot;/usr/bin/nvidia-container-runtime&quot;
        runtime_type = &quot;oci&quot;
```

As stated in the linked documentation, this file can automatically be generated with the nvidia-ctk command:

```shell
sudo nvidia-ctk runtime configure --runtime=crio --set-as-default --config=/etc/crio/crio.conf.d/99-nvidia.conf
```

`CRI-O` uses `crun` as default low-level OCI runtime so `crun` needs to be added
to the runtimes of the `nvidia-container-runtime` in the config file at `/etc/nvidia-container-runtime/config.toml`:

```toml
[nvidia-container-runtime]
runtimes = [&quot;crun&quot;, &quot;docker-runc&quot;, &quot;runc&quot;]
```

And then restart `CRI-O`:

```shell
sudo systemctl restart crio
```

### Enabling GPU Support in Kubernetes

Once you have configured the options above on all the GPU nodes in your
cluster, you can enable GPU support by deploying the following Daemonset:

```shell
kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.17.1/deployments/static/nvidia-device-plugin.yml
```

**Note:** This is a simple static daemonset meant to demonstrate the basic
features of the `nvidia-device-plugin`. Please see the instructions below for
[Deployment via `helm`](#deployment-via-helm) when deploying the plugin in a
production setting.

### Running GPU Jobs

With the daemonset deployed, NVIDIA GPUs can now be requested by a container
using the `nvidia.com/gpu` resource type:

```shell
cat &lt;&lt;EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  restartPolicy: Never
  containers:
    - name: cuda-container
      image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda12.5.0
      resources:
        limits:
          nvidia.com/gpu: 1 # requesting 1 GPU
  tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule
EOF
```

```shell
$ kubectl logs gpu-pod
[Vector addition of 50000 elements]
Copy input data from the host memory to the CUDA device
CUDA kernel launch with 196 blocks of 256 threads
Copy output data from the CUDA device to the host memory
Test PASSED
Done
```

&gt; [!WARNING]
&gt; If you do not request GPUs when you use the device plugin, the plugin exposes all the GPUs on the machine inside your container.

## Configuring the NVIDIA device plugin binary

The NVIDIA device plugin has a number of options that can be configured for it.
These options can be configured as command line flags, environment variables,
or via a config file when launching the device plugin. Here we explain what
each of these options are and how to configure them directly against the plugin
binary. The following section explains how to set these configurations when
deploying the plugin via `helm`.

### As command line flags or envvars

| Flag                     | Environment Variable    | Default Value   |
|--------------------------|-------------------------|-----------------|
| `--mig-strategy`         | `$MIG_STRATEGY`         | `&quot;none&quot;`        |
| `--fail-on-init-error`   | `$FAIL_ON_INIT_ERROR`   | `true`          |
| `--nvidia-driver-root`   | `$NVIDIA_DRIVER_ROOT`   | `&quot;/&quot;`           |
| `--pass-device-specs`    | `$PASS_DEVICE_SPECS`    | `false`         |
| `--device-list-strategy` | `$DEVICE_LIST_STRATEGY` | `&quot;envvar&quot;`      |
| `--device-id-strategy`   | `$DEVICE_ID_STRATEGY`   | `&quot;uuid&quot;`        |
| `--config-file`          | `$CONFIG_FILE`          | `&quot;&quot;`            |

### As a configuration file

```yaml
version: v1
flags:
  migStrategy: &quot;none&quot;
  failOnInitError: true
  nvidiaDriverRoot: &quot;/&quot;
  plugin:
    passDeviceSpecs: false
    deviceListStrategy: &quot;envvar&quot;
    deviceIDStrategy: &quot;uuid&quot;
```

**Note:** The configuration file has an explicit `plugin` section because it
is a shared configuration between the plugin and
[`gpu-feature-discovery`](https://github.com/NVIDIA/gpu-feature-discovery).
All options inside the `plugin` section are specific to the plugin. All
options outside of this section are shared.

### Configuration Option Details

**`MIG_STRATEGY`**:
  the desired strategy for exposing MIG devices on GPUs that support it

  `[none | single | mixed] (default &#039;none&#039;)`

  The `MIG_STRATEGY` option configures the daemonset to be able to expose
  Multi-Instance GPUs (MIG) on GPUs that support them. More information on what
  these strategies are and how they should be used can be found in [Supporting
  Multi-Instance GPUs (MIG) in
  Kubernetes](https://docs.google.com/document/d/1mdgMQ8g7WmaI_XVVRrCvHPFPOMCm5LQD5JefgAh6N8g).

  **Note:** With a `MIG_STRATEGY` of mixed, you will have additional resources
  available to you of the form `nvidia.com/mig-&lt;slice_count&gt;g.&lt;memory_size&gt;gb`
  that you can set in your pod spec to get access to a specific MIG device.

**`FAIL_ON_INIT_ERROR`**:
  fail the plugin if an error is encountered during initialization, otherwise block indefinitely

  `(default &#039;true&#039;)`

  When set to true, the `FAIL_ON_INIT_ERROR` option fails the plugin if an error is
  encountered during initialization. When set to false, it prints an error
  message and blocks the plugin indefinitely instead of failing. Blocking
  indefinitely follows legacy semantics that allow the plugin to deploy
  successfully on nodes that don&#039;t have GPUs on them (and aren&#039;t supposed to have
  GPUs on them) without throwing an error. In this way, you can blindly deploy a
  daemonset with the plugin on all nodes in your cluster, whether they have GPUs
  on them or not, without encountering an error.  However, doing so means that
  there is no way to detect an actual error on nodes that are supposed to have
  GPUs on them. Failing if an initialization error is encountered is now the
  default and should be adopted by all new deployments.

**`NVIDIA_DRIVER_ROOT`**:
  the root path for the NVIDIA driver installation

  `(default &#039;/&#039;)`

  When the NVIDIA drivers are installed directly on the host, this should be
  set to `&#039;/&#039;`. When installed elsewhere (e.g. via a driver container), this
  should be set to the root filesystem where the drivers are installed (e.g.
  `&#039;/run/nvidia/driver&#039;`).

  **Note:** This option is only necessary when used in conjunction with the
  `$PASS_DEVICE_SPECS` option described below. It tells the plugin what prefix
  to add to any device file paths passed back as part of the device specs.

**`PASS_DEVICE_SPECS`**:
  pass the paths and desired device node permissions for any NVIDIA devices
  being allocated to the container

  `(default &#039;false&#039;)`

  This option exists for the sole purpose of allowing the device plugin to
  interoperate with the `CPUManager` in Kubernetes. Setting this flag also
  requires one to deploy the daemonset with elevated privileges, so only do so if
  you know you need to interoperate with the `CPUManager`.

**`DEVICE_LIST_STRATEGY`**:
  the desired strategy for passing the device list to the underlying runtime

  `[envvar | volume-mounts | cdi-annotations | cdi-cri ] (default &#039;envvar&#039;)`

  **Note**: Multiple device list strategies can be specified (as a comma-separated list).

  The `DEVICE_LIST_STRATEGY` flag allows one to choose which strategy the plugin
  will use to advertise the list of GPUs allocated to a container. Possible values are:

  - `envvar` (default): the `NVIDIA_VISIBLE_DEVICES` environment variable
  as described
  [here](https://github.com/NVIDIA/nvidia-container-runtime#nvidia_visible_devices)
  is used to select the devices that are to be injected by the NVIDIA Container Runtime.
  - `volume-mounts`: the list of devices is passed as a set of volume mounts instead of as an environment variable
  to instruct the NVIDIA Container Runtime to inject the devices.
  Details for the
  rationale behind this strategy can be found
  [here](https://docs.google.com/document/d/1uXVF-NWZQXgP1MLb87_kMkQvidpnkNWicdpO2l9g-fw/edit#heading=h.b3ti65rojfy5).
  - `cdi-annotations`: CDI annotations are used to select the devices that are to be injected.
  Note that this does not require the NVIDIA Container Runtime, but does required a CDI-enabled container engine.
  - `cdi-cri`: the `CDIDevices` CRI field is used to select the CDI devices that are to be injected.
  This requires support in Kubernetes to forward these requests in the CRI to a CDI-enabled container engine.

**`DEVICE_ID_STRATEGY`**:
  the desired strategy for passing device IDs to the underlying runtime

  `[uuid | index] (default &#039;uuid&#039;)`

  The `DEVICE_ID_STRATEGY` flag allows one to choose which strategy the plugin will
  use to pass the device ID of the GPUs allocated to a container. The device ID
  has traditionally been passed as the UUID of the GPU. This flag lets a user
  decide if they would like to use the UUID or the index of the GPU (as seen in
  the output of `nvidia-smi`) as the identifier passed to the underlying runtime.
  Passing the index may be desirable in situations where pods that have been
  allocated GPUs by the plugin get restarted with different physical GPUs
  attached to them.

**`CONFIG_FILE`**:
  point the plugin at a configuration file instead of relying on command line
  flags or environment variables

  `(default &#039;&#039;)`

  The order of precedence for setting each option is (1) command line flag, (2)
  environment variable, (3) configuration file. In this way, one could use a
  pre-defined configuration file, but then override the values set in it at
  launch time. As described below, a `ConfigMap` can be used to point the
  plugin at a desired configuration file when deploying via `helm`.

### Shared Access to GPUs

The NVIDIA device plugin allows oversubscription of GPUs through a set of
extended options in its configuration file. There are two flavors of sharing
available: Time-Slicing and MPS.

&gt; [!NOTE]
&gt; Time-slicing and MPS are mutually exclusive.

In the case of time-slicing, CUDA time-slicing is used to allow workloads sharing a GPU to
interleave with each other. However, nothing special is done to isolate workloads that are
granted replicas from the same underlying GPU, and each workload has access to
the GPU memory and runs in the same fault-domain as of all the others (meaning
if one workload crashes, they all do).

In the case of MPS, a control daemon is used to manage access to the shared GPU.
In contrast to time-slicing, MPS does space partitioning and allows memory and
compute resources to be explicitly partitioned and enforces these limits per
workload.

With both time-slicing and MPS, the same sharing method is applied to all GPUs on
a node. You cannot configure sharing on a per-GPU basis.

#### With CUDA Time-Slicing

The extended options for sharing using time-slicing can be seen below:

```yaml
version: v1
sharing:
  timeSlicing:
    renameByDefault: &lt;bool&gt;
    failRequestsGreaterThanOne: &lt;bool&gt;
    resources:
    - name: &lt;resource-name&gt;
      replicas: &lt;num-replicas&gt;
    ...
```

That is, for each named resource under `sharing.timeSlicing.resources`, a number
of replicas can now be specified for that resource type. These replicas
represent the number of shared accesses that will be granted for a GPU
represented by that resource type.

If `renameByDefault=true`, then each resource will be advertised under the name
`&lt;resource-name&gt;.shared` instead of simply `&lt;resource-name&gt;`.

If `failRequestsGreaterThanOne=true`, then the plugin will fail to allocate any
shared resources to a container if they request more than one. The containerâ€™s
pod will fail with an `UnexpectedAdmissionError` and need to be manually deleted,
updated, and redeployed.

For example:

```yaml
version: v1
sharing:
  timeSlicing:
    resources:
    - name: nvidia.com/gpu
      replicas: 10
```

If this configuration were applied to a node with 8 GPUs on it, the plugin
would now advertise 80 `nvidia.com/gpu` resources to Kubernetes instead of 8.

```shell
$ kubectl describe node
...
Capacity:
  nvidia.com/gpu: 80
...
```

Likewise, if the following configuration were applied to a node, then 80
`nvidia.com/gpu.shared` resources would be advertised to Kubernetes instead of 8
`nvidia.com/gpu` resources.

```yaml
version: v1
sharing:
  timeSlicing:
    renameByDefault: true
    resources:
    - name: nvidia.com/gpu
      replicas: 10
    ...
```

```shell
$ kubectl describe node
...
Capacity:
  nvidia.com/gpu.shared: 80
...
```

In both cases, the plugin simply creates 10 references to each GPU and
indiscriminately hands them out to anyone that asks for them.

If `failRequestsGreaterThanOne=true` were set in either of these
configurations and a user requested more than one `nvidia.com/gpu` or
`nvidia.com/gpu.shared` resource in their pod spec, then the container would
fail with the resulting error:

```shell
$ kubectl describe pod gpu-pod
...
Events:
  Type     Reason                    Age   From               Message
  ----     ------                    ----  ----               -------
  Warning  UnexpectedAdmissionError  13s   kubelet            Allocate failed due to rpc error: code = Unknown desc = request for &#039;nvidia.com/gpu: 2&#039; too large: maximum request size for shared resources is 1, which is unexpected
...
```

**Note:** Unlike with &quot;normal&quot; GPU requests, requesting more than one shared
GPU does not imply that you will get guaranteed access to a proportional amount
of compute power. It only implies that you will get access to a GPU that is
shared by other clients (each of which has the freedom to run as many processes
on the underlying GPU as they want). Under the hood CUDA will simply give an
equal share of time to all of the GPU processes across all of the clients. The
`failRequestsGreaterThanOne` flag is meant to help users understand this
subtlety, by treating a reque

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mudler/LocalAI]]></title>
            <link>https://github.com/mudler/LocalAI</link>
            <guid>https://github.com/mudler/LocalAI</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:33 GMT</pubDate>
            <description><![CDATA[ðŸ¤– The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mudler/LocalAI">mudler/LocalAI</a></h1>
            <p>ðŸ¤– The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference</p>
            <p>Language: Go</p>
            <p>Stars: 36,175</p>
            <p>Forks: 2,875</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;img width=&quot;300&quot; src=&quot;./core/http/static/logo.png&quot;&gt; &lt;br&gt;
&lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/fork&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI forks&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/stargazers&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI stars&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/pulls&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI pull-requests&quot;/&gt;
&lt;/a&gt;
&lt;a href=&#039;https://github.com/go-skynet/LocalAI/releases&#039;&gt;
&lt;img src=&#039;https://img.shields.io/github/release/go-skynet/LocalAI?&amp;label=Latest&amp;style=for-the-badge&#039;&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://hub.docker.com/r/localai/localai&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker&quot; alt=&quot;LocalAI Docker hub&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;tag=latest&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/quay.io-images-important.svg?&quot; alt=&quot;LocalAI Quay.io&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://twitter.com/LocalAI_API&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white&amp;label=LocalAI_API&quot; alt=&quot;Follow LocalAI_API&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://discord.gg/uJAeKSAGDy&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://dcbadge.vercel.app/api/server/uJAeKSAGDy?style=flat-square&amp;theme=default-inverted&quot; alt=&quot;Join LocalAI Discord Community&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/5539&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/5539&quot; alt=&quot;mudler%2FLocalAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; :bulb: Get help - [â“FAQ](https://localai.io/faq/) [ðŸ’­Discussions](https://github.com/go-skynet/LocalAI/discussions) [:speech_balloon: Discord](https://discord.gg/uJAeKSAGDy) [:book: Documentation website](https://localai.io/)
&gt;
&gt; [ðŸ’» Quickstart](https://localai.io/basics/getting_started/) [ðŸ–¼ï¸ Models](https://models.localai.io/) [ðŸš€ Roadmap](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap) [ðŸŒ Explorer](https://explorer.localai.io) [ðŸ›« Examples](https://github.com/mudler/LocalAI-examples) Try on 
[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;logo=telegram&amp;logoColor=white)](https://t.me/localaiofficial_bot)

[![tests](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml)[![Build and Release](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml)[![build container images](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml)[![Bump dependencies](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml)[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai)](https://artifacthub.io/packages/search?repo=localai)

**LocalAI** is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that&#039;s compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by [Ettore Di Giacinto](https://github.com/mudler).


## ðŸ“šðŸ†• Local Stack Family

ðŸ†• LocalAI is now part of a comprehensive suite of AI tools designed to work together:

&lt;table&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png&quot; width=&quot;300&quot; alt=&quot;LocalAGI Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI&#039;s Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png&quot; width=&quot;300&quot; alt=&quot;LocalRecall Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Screenshots


| Talk Interface | Generate Audio |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk](./docs/assets/images/screenshots/screenshot_tts.png) | ![Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low](./docs/assets/images/screenshots/screenshot_tts.png) |

| Models Overview | Generate Images |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-20 LocalAI - Models](./docs/assets/images/screenshots/screenshot_gallery.png) | ![Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev](./docs/assets/images/screenshots/screenshot_image.png) |

| Chat Interface | Home |
| --- | --- |
| ![Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5](./docs/assets/images/screenshots/screenshot_chat.png) | ![Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)](./docs/assets/images/screenshots/screenshot_home.png) |

| Login | Swarm |
| --- | --- |
|![Screenshot 2025-03-31 at 12-09-59 ](./docs/assets/images/screenshots/screenshot_login.png) | ![Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard](./docs/assets/images/screenshots/screenshot_p2p.png) |

## ðŸ’» Quickstart

Run the installer script:

```bash
# Basic installation
curl https://localai.io/install.sh | sh
```

For more installation options, see [Installer Options](https://localai.io/docs/advanced/installer/).

### macOS Download:

&lt;a href=&quot;https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;logo=apple&amp;logoColor=white&quot; alt=&quot;Download LocalAI for macOS&quot;/&gt;
&lt;/a&gt;

Or run with docker:

&gt; **ðŸ’¡ Docker Run vs Docker Start**
&gt; 
&gt; - `docker run` creates and starts a new container. If a container with the same name already exists, this command will fail.
&gt; - `docker start` starts an existing container that was previously created with `docker run`.
&gt; 
&gt; If you&#039;ve already run LocalAI before and want to start it again, use: `docker start -i local-ai`

### CPU only image:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
```

### NVIDIA GPU Images:

```bash
# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# CUDA 11.7
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-11

# NVIDIA Jetson (L4T) ARM64
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64
```

### AMD GPU Images (ROCm):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
```

### Intel GPU Images (oneAPI):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
```

### Vulkan GPU Images:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
```

### AIO Images (pre-downloaded models):

```bash
# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# NVIDIA CUDA 11 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-11

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
```

For more information about the AIO images and pre-downloaded models, see [Container Documentation](https://localai.io/basics/container/).

To load models:

```bash
# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
```

&gt; âš¡ **Automatic Backend Detection**: When you install models from the gallery or YAML files, LocalAI automatically detects your system&#039;s GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see [GPU Acceleration](https://localai.io/features/gpu-acceleration/#automatic-backend-detection).

For more information, see [ðŸ’» Getting started](https://localai.io/basics/getting_started/index.html)

## ðŸ“° Latest project news

- October 2025: ðŸ”Œ [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) support added for agentic capabilities with external tools
- September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.
- August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with `development` suffix in the gallery ): https://github.com/mudler/LocalAI/pull/6049 https://github.com/mudler/LocalAI/pull/6119 https://github.com/mudler/LocalAI/pull/6121 https://github.com/mudler/LocalAI/pull/6060
- July/August 2025: ðŸ” [Object Detection](https://localai.io/features/object-detection/) added to the API featuring [rf-detr](https://github.com/roboflow/rf-detr)
- July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. [Read the release notes](https://github.com/mudler/LocalAI/releases/tag/v3.2.0)
- June 2025: [Backend management](https://github.com/mudler/LocalAI/pull/5607) has been added. Attention: extras images are going to be deprecated from the next release! Read [the backend management PR](https://github.com/mudler/LocalAI/pull/5607).
- May 2025: [Audio input](https://github.com/mudler/LocalAI/pull/5466) and [Reranking](https://github.com/mudler/LocalAI/pull/5396) in llama.cpp backend, [Realtime API](https://github.com/mudler/LocalAI/pull/5392),  Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).
- May 2025: Important: image name changes [See release](https://github.com/mudler/LocalAI/releases/tag/v2.29.0)
- Apr 2025: Rebrand, WebUI enhancements
- Apr 2025: [LocalAGI](https://github.com/mudler/LocalAGI) and [LocalRecall](https://github.com/mudler/LocalRecall) join the LocalAI family stack.
- Apr 2025: WebUI overhaul, AIO images updates
- Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images
- Jan 2025: LocalAI model release: https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3, SANA support in diffusers: https://github.com/mudler/LocalAI/pull/4603
- Dec 2024: stablediffusion.cpp backend (ggml) added ( https://github.com/mudler/LocalAI/pull/4289 )
- Nov 2024: Bark.cpp backend added ( https://github.com/mudler/LocalAI/pull/4287 )
- Nov 2024: Voice activity detection models (**VAD**) added to the API: https://github.com/mudler/LocalAI/pull/4204
- Oct 2024: examples moved to [LocalAI-examples](https://github.com/mudler/LocalAI-examples)
- Aug 2024:  ðŸ†• FLUX-1, [P2P Explorer](https://explorer.localai.io)
- July 2024: ðŸ”¥ðŸ”¥ ðŸ†• P2P Dashboard, LocalAI Federated mode and AI Swarms: https://github.com/mudler/LocalAI/pull/2723. P2P Global community pools: https://github.com/mudler/LocalAI/issues/3113
- May 2024: ðŸ”¥ðŸ”¥ Decentralized P2P llama.cpp:  https://github.com/mudler/LocalAI/pull/2343 (peer2peer llama.cpp!) ðŸ‘‰ Docs  https://localai.io/features/distribute/
- May 2024: ðŸ”¥ðŸ”¥ Distributed inferencing: https://github.com/mudler/LocalAI/pull/2324
- April 2024: Reranker API: https://github.com/mudler/LocalAI/pull/2121

Roadmap items: [List of issues](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)

## ðŸš€ [Features](https://localai.io/features/)

- ðŸ§© [Backend Gallery](https://localai.io/backends/): Install/remove backends on the fly, powered by OCI images â€” fully customizable and API-driven.
- ðŸ“– [Text generation with GPTs](https://localai.io/features/text-generation/) (`llama.cpp`, `transformers`, `vllm` ... [:book: and more](https://localai.io/model-compatibility/index.html#model-compatibility-table))
- ðŸ—£ [Text to Audio](https://localai.io/features/text-to-audio/)
- ðŸ”ˆ [Audio to Text](https://localai.io/features/audio-to-text/) (Audio transcription with `whisper.cpp`)
- ðŸŽ¨ [Image generation](https://localai.io/features/image-generation)
- ðŸ”¥ [OpenAI-alike tools API](https://localai.io/features/openai-functions/) 
- ðŸ§  [Embeddings generation for vector databases](https://localai.io/features/embeddings/)
- âœï¸ [Constrained grammars](https://localai.io/features/constrained_grammars/)
- ðŸ–¼ï¸ [Download Models directly from Huggingface ](https://localai.io/models/)
- ðŸ¥½ [Vision API](https://localai.io/features/gpt-vision/)
- ðŸ” [Object Detection](https://localai.io/features/object-detection/)
- ðŸ“ˆ [Reranker API](https://localai.io/features/reranker/)
- ðŸ†•ðŸ–§ [P2P Inferencing](https://localai.io/features/distribute/)
- ðŸ†•ðŸ”Œ [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) - Agentic capabilities with external tools and [LocalAGI&#039;s Agentic capabilities](https://github.com/mudler/LocalAGI)
- ðŸ”Š Voice activity detection (Silero-VAD support)
- ðŸŒ Integrated WebUI!

## ðŸ§© Supported Backends &amp; Acceleration

LocalAI supports a comprehensive range of AI backends with multiple acceleration options:

### Text Generation &amp; Language Models
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **llama.cpp** | LLM inference in C/C++ | CUDA 11/12, ROCm, Intel SYCL, Vulkan, Metal, CPU |
| **vLLM** | Fast LLM inference with PagedAttention | CUDA 12, ROCm, Intel |
| **transformers** | HuggingFace transformers framework | CUDA 11/12, ROCm, Intel, CPU |
| **exllama2** | GPTQ inference library | CUDA 12 |
| **MLX** | Apple Silicon LLM inference | Metal (M1/M2/M3+) |
| **MLX-VLM** | Apple Silicon Vision-Language Models | Metal (M1/M2/M3+) |

### Audio &amp; Speech Processing
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **whisper.cpp** | OpenAI Whisper in C/C++ | CUDA 12, ROCm, Intel SYCL, Vulkan, CPU |
| **faster-whisper** | Fast Whisper with CTranslate2 | CUDA 12, ROCm, Intel, CPU |
| **bark** | Text-to-audio generation | CUDA 12, ROCm, Intel |
| **bark-cpp** | C++ implementation of Bark | CUDA, Metal, CPU |
| **coqui** | Advanced TTS with 1100+ languages | CUDA 12, ROCm, Intel, CPU |
| **kokoro** | Lightweight TTS model | CUDA 12, ROCm, Intel, CPU |
| **chatterbox** | Production-grade TTS | CUDA 11/12, CPU |
| **piper** | Fast neural TTS system | CPU |
| **kitten-tts** | Kitten TTS models | CPU |
| **silero-vad** | Voice Activity Detection | CPU |
| **neutts** | Text-to-speech with voice cloning | CUDA 12, ROCm, CPU |

### Image &amp; Video Generation
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **stablediffusion.cpp** | Stable Diffusion in C/C++ | CUDA 12, Intel SYCL, Vulkan, CPU |
| **diffusers** | HuggingFace diffusion models | CUDA 11/12, ROCm, Intel, Metal, CPU |

### Specialized AI Tasks
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **rfdetr** | Real-time object detection | CUDA 12, Intel, CPU |
| **rerankers** | Document reranking API | CUDA 11/12, ROCm, Intel, CPU |
| **local-store** | Vector database | CPU |
| **huggingface** | HuggingFace API integration | API-based |

### Hardware Acceleration Matrix

| Acceleration Type | Supported Backends | Hardware Support |
|-------------------|-------------------|------------------|
| **NVIDIA CUDA 11** | llama.cpp, whisper, stablediffusion, diffusers, rerankers, bark, chatterbox | Nvidia hardware |
| **NVIDIA CUDA 12** | All CUDA-compatible backends | Nvidia hardware |
| **AMD ROCm** | llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts | AMD Graphics |
| **Intel oneAPI** | llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark | Intel Arc, Intel iGPUs |
| **Apple Metal** | llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp | Apple M1/M2/M3+ |
| **Vulkan** | llama.cpp, whisper, stablediffusion | Cross-platform GPUs |
| **NVIDIA Jetson** | llama.cpp, whisper, stablediffusion, diffusers, rfdetr | ARM64 embedded AI |
| **CPU Optimized** | All backends | AVX/AVX2/AVX512, quantization support |

### ðŸ”— Community and integrations

Build and deploy custom containers:
- https://github.com/sozercan/aikit

WebUIs:
- https://github.com/Jirubizu/localai-admin
- https://github.com/go-skynet/LocalAI-frontend
- QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) https://github.com/reid41/QA-Pilot

Agentic Libraries:
- https://github.com/mudler/cogito

MCPs:
- https://github.com/mudler/MCPs

Model galleries
- https://github.com/go-skynet/model-gallery

Voice:
- https://github.com/richiejp/VoxInput

Other:
- Helm chart https://github.com/go-skynet/helm-charts
- VSCode extension https://github.com/badgooooor/localai-vscode-plugin
- Langchain: https://python.langchain.com/docs/integrations/providers/localai/
- Terminal utility https://github.com/djcopley/ShellOracle
- Local Smart assistant https://github.com/mudler/LocalAGI
- Home Assistant https://github.com/sammcj/homeassistant-localai / https://github.com/drndos/hass-openai-custom-conversation / https://github.com/valentinfrlch/ha-gpt4vision
- Discord bot https://github.com/mudler/LocalAGI/tree/main/examples/discord
- Slack bot https://github.com/mudler/LocalAGI/tree/main/examples/slack
- Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) https://github.com/reid41/shell-pilot
- Telegram bot https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot
- Another Telegram Bot https://github.com/JackBekket/Hellper
- Auto-documentation https://github.com/JackBekket/Reflexia
- Github bot which answer on issues, with code and documentation as context https://github.com/JackBekket/GitHelper
- Github Actions: https://github.com/marketplace/actions/start-localai
- Examples: https://github.com/mudler/Lo

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[projectdiscovery/nuclei]]></title>
            <link>https://github.com/projectdiscovery/nuclei</link>
            <guid>https://github.com/projectdiscovery/nuclei</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:32 GMT</pubDate>
            <description><![CDATA[Nuclei is a fast, customizable vulnerability scanner powered by the global security community and built on a simple YAML-based DSL, enabling collaboration to tackle trending vulnerabilities on the internet. It helps you find vulnerabilities in your applications, APIs, networks, DNS, and cloud configurations.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/projectdiscovery/nuclei">projectdiscovery/nuclei</a></h1>
            <p>Nuclei is a fast, customizable vulnerability scanner powered by the global security community and built on a simple YAML-based DSL, enabling collaboration to tackle trending vulnerabilities on the internet. It helps you find vulnerabilities in your applications, APIs, networks, DNS, and cloud configurations.</p>
            <p>Language: Go</p>
            <p>Stars: 25,277</p>
            <p>Forks: 2,932</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>![nuclei](/static/nuclei-cover-image.png)

&lt;div align=&quot;center&quot;&gt;
  
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README.md&quot;&gt;`English`&lt;/a&gt; â€¢
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README_CN.md&quot;&gt;`ä¸­æ–‡`&lt;/a&gt; â€¢
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README_KR.md&quot;&gt;`Korean`&lt;/a&gt; â€¢
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README_ID.md&quot;&gt;`Indonesia`&lt;/a&gt; â€¢
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README_ES.md&quot;&gt;`Spanish`&lt;/a&gt; â€¢
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README_JP.md&quot;&gt;`æ—¥æœ¬èªž`&lt;/a&gt; â€¢
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README_PT-BR.md&quot;&gt;`Portuguese`&lt;/a&gt;
  
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;

&lt;img src=&quot;https://img.shields.io/badge/go-1.22-%2300ADD8.svg?style=for-the-badge&amp;logo=go&amp;logoColor=white&quot;&gt;
&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://docs.projectdiscovery.io/tools/nuclei/overview?utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Documentation-%23000000.svg?style=for-the-badge&amp;logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9IiNmZmZmZmYiIHN0cm9rZS13aWR0aD0iMiIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIiBjbGFzcz0ibHVjaWRlIGx1Y2lkZS1ib29rLW9wZW4iPjxwYXRoIGQ9Ik0xMiA3djE0Ii8+PHBhdGggZD0iTTMgMThhMSAxIDAgMCAxLTEtMVY0YTEgMSAwIDAgMSAxLTFoNWE0IDQgMCAwIDEgNCA0IDQgNCAwIDAgMSA0LTRoNWExIDEgMCAwIDEgMSAxdjEzYTEgMSAwIDAgMS0xIDFoLTZhMyAzIDAgMCAwLTMgMyAzIDMgMCAwIDAtMy0zeiIvPjwvc3ZnPg==&amp;logoColor=white&quot;&gt;&lt;/a&gt;
&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://github.com/projectdiscovery/nuclei-templates&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Templates Library-%23000000.svg?style=for-the-badge&amp;logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgaGVpZ2h0PSIxNiIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9IiNmZmZmZmYiIHN0cm9rZS13aWR0aD0iMS41IiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLXNoaWVsZCI+PHBhdGggZD0iTTIwIDEzYzAgNS0zLjUgNy41LTcuNjYgOC45NWExIDEgMCAwIDEtLjY3LS4wMUM3LjUgMjAuNSA0IDE4IDQgMTNWNmExIDEgMCAwIDEgMS0xYzIgMCA0LjUtMS4yIDYuMjQtMi43MmExLjE3IDEuMTcgMCAwIDEgMS41MiAwQzE0LjUxIDMuODEgMTcgNSAxOSA1YTEgMSAwIDAgMSAxIDF6Ii8+PC9zdmc+&amp;logoColor=white&quot;&gt;&lt;/a&gt;
&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://discord.gg/projectdiscovery?utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot;&gt;&lt;/a&gt;

&lt;hr&gt;

&lt;/p&gt;

&lt;br&gt;

**Nuclei is a modern, high-performance vulnerability scanner that leverages simple YAML-based templates. It empowers you to design custom vulnerability detection scenarios that mimic real-world conditions, leading to zero false positives.**

- Simple YAML format for creating and customizing vulnerability templates.
- Contributed by thousands of security professionals to tackle trending vulnerabilities.
- Reduce false positives by simulating real-world steps to verify a vulnerability.
- Ultra-fast parallel scan processing and request clustering.
- Integrate into CI/CD pipelines for vulnerability detection and regression testing.
- Supports multiple protocols like TCP, DNS, HTTP, SSL, WHOIS JavaScript, Code and more.
- Integrate with Jira, Splunk, GitHub, Elastic, GitLab.

&lt;br&gt;
&lt;br&gt;

## Table of Contents

- [**`Get Started`**](#get-started)
  - [_`1. Nuclei CLI`_](#1-nuclei-cli)
  - [_`2. Pro and Enterprise Editions`_](#2-pro-and-enterprise-editions)
- [**`Documentation`**](#documentation)
  - [_`Command Line Flags`_](#command-line-flags)
  - [_`Single target scan`_](#single-target-scan)
  - [_`Scanning multiple targets`_](#scanning-multiple-targets)
  - [_`Network scan`_](#network-scan)
  - [_`Scanning with your custom template`_](#scanning-with-your-custom-template)
  - [_`Connect Nuclei to ProjectDiscovery_`_](#connect-nuclei-to-projectdiscovery)
- [**`Nuclei Templates, Community and Rewards`**](#nuclei-templates-community-and-rewards-) ðŸ’Ž
- [**`Our Mission`**](#our-mission)
- [**`Contributors`**](#contributors-heart) â¤
- [**`License`**](#license)

&lt;br&gt;
&lt;br&gt;

## Get Started

### **1. Nuclei CLI**

_Install Nuclei on your machine. Get started by following the installation guide [**`here`**](https://docs.projectdiscovery.io/tools/nuclei/install?utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme). Additionally, We provide [**`a free cloud tier`**](https://cloud.projectdiscovery.io/sign-up) and comes with a generous monthly free limits:_

- Store and visualize your vulnerability findings
- Write and manage your nuclei templates
- Access latest nuclei templates
- Discover and store your targets

&gt; [!Important]
&gt; |**This project is in active development**. Expect breaking changes with releases. Review the release changelog before updating.|
&gt; |:--------------------------------|
&gt; | This project is primarily built to be used as a standalone CLI tool. **Running nuclei as a service may pose security risks.** It&#039;s recommended to use with caution and additional security measures. |

&lt;br&gt;

### **2. Pro and Enterprise Editions**

_For security teams and enterprises, we provide a cloud-hosted service built on top of Nuclei OSS, fine-tuned to help you continuously run vulnerability scans at scale with your team and existing workflows:_

- 50x faster scans
- Large scale scanning with high accuracy
- Integrations with cloud services (AWS, GCP, Azure, CloudFlare, Fastly, Terraform, Kubernetes)
- Jira, Slack, Linear, APIs and Webhooks
- Executive and compliance reporting
- Plus: Real-time scanning, SAML SSO, SOC 2 compliant platform (with EU and US hosting options), shared team workspaces, and more
- We&#039;re constantly [**`adding new features`**](https://feedback.projectdiscovery.io/changelog)!
- **Ideal for:** Pentesters, security teams, and enterprises

[**`Sign up to Pro`**](https://projectdiscovery.io/pricing?utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme) or [**`Talk to our team`**](https://projectdiscovery.io/request-demo?utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme) if you have large organization and complex requirements.

&lt;br&gt;
&lt;br&gt;

## Documentation

Browse the full Nuclei [**`documentation here`**](https://docs.projectdiscovery.io/tools/nuclei/running). If youâ€™re new to Nuclei, check out our [**`foundational Youtube series`**](https://www.youtube.com/playlist?list=PLZRbR9aMzTTpItEdeNSulo8bYsvil80Rl).

&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://www.youtube.com/watch?v=b5qMyQvL1ZA&amp;list=PLZRbR9aMzTTpItEdeNSulo8bYsvil80Rl&amp;utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/static/nuclei-getting-started.png&quot; width=&quot;350px&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.youtube.com/watch?v=nFXygQdtjyw&amp;utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/static/nuclei-write-your-first-template.png&quot; width=&quot;350px&quot;&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;br&gt;

### Installation

`nuclei` requires **go1.23** to install successfully. Run the following command to get the repo:

```sh
go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest
```

To learn more about installing nuclei, see `https://docs.projectdiscovery.io/tools/nuclei/install`.

### Command Line Flags

To display all the flags for the tool:

```sh
nuclei -h
```

&lt;details&gt;
  &lt;summary&gt;Expand full help flags&lt;/summary&gt;

```yaml
Nuclei is a fast, template based vulnerability scanner focusing
on extensive configurability, massive extensibility and ease of use.

Usage:
  ./nuclei [flags]

Flags:
TARGET:
   -u, -target string[]          target URLs/hosts to scan
   -l, -list string              path to file containing a list of target URLs/hosts to scan (one per line)
   -eh, -exclude-hosts string[]  hosts to exclude to scan from the input list (ip, cidr, hostname)
   -resume string                resume scan using resume.cfg (clustering will be disabled)
   -sa, -scan-all-ips            scan all the IP&#039;s associated with dns record
   -iv, -ip-version string[]     IP version to scan of hostname (4,6) - (default 4)

TARGET-FORMAT:
   -im, -input-mode string        mode of input file (list, burp, jsonl, yaml, openapi, swagger) (default &quot;list&quot;)
   -ro, -required-only            use only required fields in input format when generating requests
   -sfv, -skip-format-validation  skip format validation (like missing vars) when parsing input file

TEMPLATES:
   -nt, -new-templates                    run only new templates added in latest nuclei-templates release
   -ntv, -new-templates-version string[]  run new templates added in specific version
   -as, -automatic-scan                   automatic web scan using wappalyzer technology detection to tags mapping
   -t, -templates string[]                list of template or template directory to run (comma-separated, file)
   -turl, -template-url string[]          template url or list containing template urls to run (comma-separated, file)
   -ai, -prompt string                    generate and run template using ai prompt
   -w, -workflows string[]                list of workflow or workflow directory to run (comma-separated, file)
   -wurl, -workflow-url string[]          workflow url or list containing workflow urls to run (comma-separated, file)
   -validate                              validate the passed templates to nuclei
   -nss, -no-strict-syntax                disable strict syntax check on templates
   -td, -template-display                 displays the templates content
   -tl                                    list all available templates
   -tgl                                   list all available tags
   -sign                                  signs the templates with the private key defined in NUCLEI_SIGNATURE_PRIVATE_KEY env variable
   -code                                  enable loading code protocol-based templates
   -dut, -disable-unsigned-templates      disable running unsigned templates or templates with mismatched signature
   -esc, -enable-self-contained           enable loading self-contained templates
   -egm, -enable-global-matchers          enable loading global matchers templates
   -file                                  enable loading file templates

FILTERING:
   -a, -author string[]               templates to run based on authors (comma-separated, file)
   -tags string[]                     templates to run based on tags (comma-separated, file)
   -etags, -exclude-tags string[]     templates to exclude based on tags (comma-separated, file)
   -itags, -include-tags string[]     tags to be executed even if they are excluded either by default or configuration
   -id, -template-id string[]         templates to run based on template ids (comma-separated, file, allow-wildcard)
   -eid, -exclude-id string[]         templates to exclude based on template ids (comma-separated, file)
   -it, -include-templates string[]   path to template file or directory to be executed even if they are excluded either by default or configuration
   -et, -exclude-templates string[]   path to template file or directory to exclude (comma-separated, file)
   -em, -exclude-matchers string[]    template matchers to exclude in result
   -s, -severity value[]              templates to run based on severity. Possible values: info, low, medium, high, critical, unknown
   -es, -exclude-severity value[]     templates to exclude based on severity. Possible values: info, low, medium, high, critical, unknown
   -pt, -type value[]                 templates to run based on protocol type. Possible values: dns, file, http, headless, tcp, workflow, ssl, websocket, whois, code, javascript
   -ept, -exclude-type value[]        templates to exclude based on protocol type. Possible values: dns, file, http, headless, tcp, workflow, ssl, websocket, whois, code, javascript
   -tc, -template-condition string[]  templates to run based on expression condition

OUTPUT:
   -o, -output string            output file to write found issues/vulnerabilities
   -sresp, -store-resp           store all request/response passed through nuclei to output directory
   -srd, -store-resp-dir string  store all request/response passed through nuclei to custom directory (default &quot;output&quot;)
   -silent                       display findings only
   -nc, -no-color                disable output content coloring (ANSI escape codes)
   -j, -jsonl                    write output in JSONL(ines) format
   -irr, -include-rr -omit-raw   include request/response pairs in the JSON, JSONL, and Markdown outputs (for findings only) [DEPRECATED use -omit-raw] (default true)
   -or, -omit-raw                omit request/response pairs in the JSON, JSONL, and Markdown outputs (for findings only)
   -ot, -omit-template           omit encoded template in the JSON, JSONL output
   -nm, -no-meta                 disable printing result metadata in cli output
   -ts, -timestamp               enables printing timestamp in cli output
   -rdb, -report-db string       nuclei reporting database (always use this to persist report data)
   -ms, -matcher-status          display match failure status
   -me, -markdown-export string  directory to export results in markdown format
   -se, -sarif-export string     file to export results in SARIF format
   -je, -json-export string      file to export results in JSON format
   -jle, -jsonl-export string    file to export results in JSONL(ine) format
   -rd, -redact string[]         redact given list of keys from query parameter, request header and body

CONFIGURATIONS:
   -config string                        path to the nuclei configuration file
   -tp, -profile string                  template profile config file to run
   -tpl, -profile-list                   list community template profiles
   -fr, -follow-redirects                enable following redirects for http templates
   -fhr, -follow-host-redirects          follow redirects on the same host
   -mr, -max-redirects int               max number of redirects to follow for http templates (default 10)
   -dr, -disable-redirects               disable redirects for http templates
   -rc, -report-config string            nuclei reporting module configuration file
   -H, -header string[]                  custom header/cookie to include in all http request in header:value format (cli, file)
   -V, -var value                        custom vars in key=value format
   -r, -resolvers string                 file containing resolver list for nuclei
   -sr, -system-resolvers                use system DNS resolving as error fallback
   -dc, -disable-clustering              disable clustering of requests
   -passive                              enable passive HTTP response processing mode
   -fh2, -force-http2                    force http2 connection on requests
   -ev, -env-vars                        enable environment variables to be used in template
   -cc, -client-cert string              client certificate file (PEM-encoded) used for authenticating against scanned hosts
   -ck, -client-key string               client key file (PEM-encoded) used for authenticating against scanned hosts
   -ca, -client-ca string                client certificate authority file (PEM-encoded) used for authenticating against scanned hosts
   -sml, -show-match-line                show match lines for file templates, works with extractors only
   -ztls                                 use ztls library with autofallback to standard one for tls13 [Deprecated] autofallback to ztls is enabled by default
   -sni string                           tls sni hostname to use (default: input domain name)
   -dka, -dialer-keep-alive value        keep-alive duration for network requests.
   -lfa, -allow-local-file-access        allows file (payload) access anywhere on the system
   -lna, -restrict-local-network-access  blocks connections to the local / private network
   -i, -interface string                 network interface to use for network scan
   -at, -attack-type string              type of payload combinations to perform (batteringram,pitchfork,clusterbomb)
   -sip, -source-ip string               source ip address to use for network scan
   -rsr, -response-size-read int         max response size to read in bytes
   -rss, -response-size-save int         max response size to read in bytes (default 1048576)
   -reset                                reset removes all nuclei configuration and data files (including nuclei-templates)
   -tlsi, -tls-impersonate               enable experimental client hello (ja3) tls randomization
   -hae, -http-api-endpoint string       experimental http api endpoint

INTERACTSH:
   -iserver, -interactsh-server string  interactsh server url for self-hosted instance (default: oast.pro,oast.live,oast.site,oast.online,oast.fun,oast.me)
   -itoken, -interactsh-token string    authentication token for self-hosted interactsh server
   -interactions-cache-size int         number of requests to keep in the interactions cache (default 5000)
   -interactions-eviction int           number of seconds to wait before evicting requests from cache (default 60)
   -interactions-poll-duration int      number of seconds to wait before each interaction poll request (default 5)
   -interactions-cooldown-period int    extra time for interaction polling before exiting (default 5)
   -ni, -no-interactsh                  disable interactsh server for OAST testing, exclude OAST based templates

FUZZING:
   -ft, -fuzzing-type string           overrides fuzzing type set in template (replace, prefix, postfix, infix)
   -fm, -fuzzing-mode string           overrides fuzzing mode set in template (multiple, single)
   -fuzz                               enable loading fuzzing templates (Deprecated: use -dast instead)
   -dast                               enable / run dast (fuzz) nuclei templates
   -dts, -dast-server                  enable dast server mode (live fuzzing)
   -dtr, -dast-report                  write dast scan report to file
   -dtst, -dast-server-token string    dast server token (optional)
   -dtsa, -dast-server-address string  dast server address (default &quot;localhost:9055&quot;)
   -dfp, -display-fuzz-points          display fuzz points in the output for debugging
   -fuzz-param-frequency int           frequency of uninteresting parameters for fuzzing before skipping (default 10)
   -fa, -fuzz-aggression string        fuzzing aggression level controls payload count for fuzz (low, medium, high) (default &quot;low&quot;)
   -cs, -fuzz-scope string[]           in scope url regex to be followed by fuzzer
   -cos, -fuzz-out-scope string[]      out of scope url regex to be excluded by fuzzer

UNCOVER:
   -uc, -uncover                  enable uncover engine
   -uq, -uncover-query string[]   uncover search query
   -ue, -uncover-engine string[]  uncover search engine (shodan,censys,fofa,shodan-idb,quake,hunter,zoomeye,netlas,criminalip,publicwww,hunterhow,google) (default shodan)
   -uf, -uncover-field string     uncover fields to return (ip,port,host) (default &quot;ip:port&quot;)
   -ul, -uncover-limit int        uncover results to return (default 100)
   -ur, -uncover-ratelimit int    override ratelimit of engines with unknown ratelimit (default 60 req/min) (default 60)

RATE-LIMIT:
   -rl, -rate-limit int               maximum number of requests to send per second (default 150)
   -rld, -rate-limit-duration value   maximum number of requests to send per second (default 1s)
   -rlm, -rate-limit-minute int       maximum number of requests to send per minute (DEPRECATED)
   -bs, -bulk-size int                maximum number of hosts to be analyzed in parallel per template (default 25)
   -c, -concurrency int               maximum number of templates to be executed in parallel (default 25)
   -hbs, -headless-bulk-size int      maximum number of headless hosts to be analyzed in parallel per template (default 10)
   -headc, -headles

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hashicorp/terraform]]></title>
            <link>https://github.com/hashicorp/terraform</link>
            <guid>https://github.com/hashicorp/terraform</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:31 GMT</pubDate>
            <description><![CDATA[Terraform enables you to safely and predictably create, change, and improve infrastructure. It is a source-available tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hashicorp/terraform">hashicorp/terraform</a></h1>
            <p>Terraform enables you to safely and predictably create, change, and improve infrastructure. It is a source-available tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.</p>
            <p>Language: Go</p>
            <p>Stars: 47,002</p>
            <p>Forks: 10,095</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># Terraform

- Website: https://developer.hashicorp.com/terraform
- Forums: [HashiCorp Discuss](https://discuss.hashicorp.com/c/terraform-core)
- Documentation: [https://developer.hashicorp.com/terraform/docs](https://developer.hashicorp.com/terraform/docs)
- Tutorials: [HashiCorp&#039;s Learn Platform](https://developer.hashicorp.com/terraform/tutorials)
- Certification Exam: [HashiCorp Certified: Terraform Associate](https://www.hashicorp.com/certification/#hashicorp-certified-terraform-associate)

&lt;img alt=&quot;Terraform&quot; src=&quot;https://www.datocms-assets.com/2885/1731373310-terraform_white.svg&quot; width=&quot;600px&quot;&gt;

Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions.

The key features of Terraform are:

- **Infrastructure as Code**: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.

- **Execution Plans**: Terraform has a &quot;planning&quot; step where it generates an execution plan. The execution plan shows what Terraform will do when you call apply. This lets you avoid any surprises when Terraform manipulates infrastructure.

- **Resource Graph**: Terraform builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, Terraform builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.

- **Change Automation**: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what Terraform will change and in what order, avoiding many possible human errors.

For more information, refer to the [What is Terraform?](https://www.terraform.io/intro) page on the Terraform website.

## Getting Started &amp; Documentation

Documentation is available on the [Terraform website](https://developer.hashicorp.com/terraform):

- [Introduction](https://developer.hashicorp.com/terraform/intro)
- [Documentation](https://developer.hashicorp.com/terraform/docs)

If you&#039;re new to Terraform and want to get started creating infrastructure, please check out our [Getting Started guides](https://learn.hashicorp.com/terraform#getting-started) on HashiCorp&#039;s learning platform. There are also [additional guides](https://learn.hashicorp.com/terraform#operations-and-development) to continue your learning.

Show off your Terraform knowledge by passing a certification exam. Visit the [certification page](https://www.hashicorp.com/certification/) for information about exams and find [study materials](https://learn.hashicorp.com/terraform/certification/terraform-associate) on HashiCorp&#039;s learning platform.

## Developing Terraform

This repository contains only Terraform core, which includes the command line interface and the main graph engine. Providers are implemented as plugins, and Terraform can automatically download providers that are published on [the Terraform Registry](https://registry.terraform.io). HashiCorp develops some providers, and others are developed by other organizations. For more information, refer to [Plugin development](https://developer.hashicorp.com/terraform/plugin).

- To learn more about compiling Terraform and contributing suggested changes, refer to [the contributing guide](.github/CONTRIBUTING.md).

- To learn more about how we handle bug reports, refer to the [bug triage guide](./BUGPROCESS.md).

- To learn how to contribute to the Terraform documentation, refer to the [Web Unified Docs repository](https://github.com/hashicorp/web-unified-docs).

## License

[Business Source License 1.1](https://github.com/hashicorp/terraform/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[seaweedfs/seaweedfs]]></title>
            <link>https://github.com/seaweedfs/seaweedfs</link>
            <guid>https://github.com/seaweedfs/seaweedfs</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:30 GMT</pubDate>
            <description><![CDATA[SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/seaweedfs/seaweedfs">seaweedfs/seaweedfs</a></h1>
            <p>SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.</p>
            <p>Language: Go</p>
            <p>Stars: 27,024</p>
            <p>Forks: 2,524</p>
            <p>Stars today: 262 stars today</p>
            <h2>README</h2><pre># SeaweedFS


[![Slack](https://img.shields.io/badge/slack-purple)](https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY)
[![Twitter](https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;label=Follow)](https://twitter.com/intent/follow?screen_name=seaweedfs)
[![Build Status](https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml)](https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml)
[![GoDoc](https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg)](https://godoc.org/github.com/seaweedfs/seaweedfs/weed)
[![Wiki](https://img.shields.io/badge/docs-wiki-blue.svg)](https://github.com/seaweedfs/seaweedfs/wiki)
[![Docker Pulls](https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800)](https://hub.docker.com/r/chrislusf/seaweedfs/)
[![SeaweedFS on Maven Central](https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client)](https://search.maven.org/search?q=g:com.github.chrislusf)
[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs)](https://artifacthub.io/packages/search?repo=seaweedfs)

![SeaweedFS Logo](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png)

&lt;h2 align=&quot;center&quot;&gt;&lt;a href=&quot;https://www.patreon.com/seaweedfs&quot;&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt;

SeaweedFS is an independent Apache-licensed open source project with its ongoing development made
possible entirely thanks to the support of these awesome [backers](https://github.com/seaweedfs/seaweedfs/blob/master/backers.md).
If you&#039;d like to grow SeaweedFS even stronger, please consider joining our
&lt;a href=&quot;https://www.patreon.com/seaweedfs&quot;&gt;sponsors on Patreon&lt;/a&gt;.

Your support will be really appreciated by me and other supporters!

&lt;!--
&lt;h4 align=&quot;center&quot;&gt;Platinum&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;&quot; target=&quot;_blank&quot;&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt;

### Gold Sponsors
[![nodion](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png)](https://www.nodion.com)
[![piknik](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png)](https://www.piknik.com)
[![keepsec](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png)](https://www.keepsec.ca)

---

- [Download Binaries for different platforms](https://github.com/seaweedfs/seaweedfs/releases/latest)
- [SeaweedFS on Slack](https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY)
- [SeaweedFS on Twitter](https://twitter.com/SeaweedFS)
- [SeaweedFS on Telegram](https://t.me/Seaweedfs) 
- [SeaweedFS on Reddit](https://www.reddit.com/r/SeaweedFS/)
- [SeaweedFS Mailing List](https://groups.google.com/d/forum/seaweedfs)
- [Wiki Documentation](https://github.com/seaweedfs/seaweedfs/wiki)
- [SeaweedFS White Paper](https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf)
- [SeaweedFS Introduction Slides 2025.5](https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing)
- [SeaweedFS Introduction Slides 2021.5](https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing)
- [SeaweedFS Introduction Slides 2019.3](https://www.slideshare.net/chrislusf/seaweedfs-introduction)

Table of Contents
=================

* [Quick Start](#quick-start)
    * [Quick Start for S3 API on Docker](#quick-start-for-s3-api-on-docker)
    * [Quick Start with Single Binary](#quick-start-with-single-binary)
    * [Quick Start SeaweedFS S3 on AWS](#quick-start-seaweedfs-s3-on-aws)
* [Introduction](#introduction)
* [Features](#features)
    * [Additional Features](#additional-features)
    * [Filer Features](#filer-features)
* [Example: Using Seaweed Object Store](#example-using-seaweed-object-store)
* [Architecture](#object-store-architecture)
* [Compared to Other File Systems](#compared-to-other-file-systems)
    * [Compared to HDFS](#compared-to-hdfs)
    * [Compared to GlusterFS, Ceph](#compared-to-glusterfs-ceph)
    * [Compared to GlusterFS](#compared-to-glusterfs)
    * [Compared to Ceph](#compared-to-ceph)
    * [Compared to Minio](#compared-to-minio)
* [Dev Plan](#dev-plan)
* [Installation Guide](#installation-guide)
* [Disk Related Topics](#disk-related-topics)
* [Benchmark](#benchmark)
* [Enterprise](#enterprise)
* [License](#license)

# Quick Start #

## Quick Start for S3 API on Docker ##

`docker run -p 8333:8333 chrislusf/seaweedfs server -s3`

## Quick Start with Single Binary ##
* Download the latest binary from https://github.com/seaweedfs/seaweedfs/releases and unzip a single binary file `weed` or `weed.exe`. Or run `go install github.com/seaweedfs/seaweedfs/weed@latest`.
* `export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key` as the admin credentials to access the object store.
* Run `weed server -dir=/some/data/dir -s3` to start one master, one volume server, one filer, and one S3 gateway.

Also, to increase capacity, just add more volume servers by running `weed volume -dir=&quot;/some/data/dir2&quot; -mserver=&quot;&lt;master_host&gt;:9333&quot; -port=8081` locally, or on a different machine, or on thousands of machines. That is it!

## Quick Start SeaweedFS S3 on AWS ##
* Setup fast production-ready [SeaweedFS S3 on AWS with cloudformation](https://aws.amazon.com/marketplace/pp/prodview-nzelz5gprlrjc)

# Introduction #

SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:

1. to store billions of files!
2. to serve the files fast!

SeaweedFS started as an Object Store to handle small files efficiently. 
Instead of managing all file metadata in a central master, 
the central master only manages volumes on volume servers, 
and these volume servers manage files and their metadata. 
This relieves concurrency pressure from the central master and spreads file metadata into volume servers, 
allowing faster file access (O(1), usually just one disk read operation).

There is only 40 bytes of disk storage overhead for each file&#039;s metadata. 
It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.

SeaweedFS started by implementing [Facebook&#039;s Haystack design paper](http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf). 
Also, SeaweedFS implements erasure coding with ideas from 
[f4: Facebookâ€™s Warm BLOB Storage System](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf), and has a lot of similarities with [Facebookâ€™s Tectonic Filesystem](https://www.usenix.org/system/files/fast21-pan.pdf)

On top of the object store, optional [Filer] can support directories and POSIX attributes. 
Filer is a separate linearly-scalable stateless server with customizable metadata stores, 
e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.

For any distributed key value stores, the large values can be offloaded to SeaweedFS. 
With the fast access speed and linearly scalable capacity, 
SeaweedFS can work as a distributed [Key-Large-Value store][KeyLargeValueStore].

SeaweedFS can transparently integrate with the cloud. 
With hot data on local cluster, and warm data on the cloud with O(1) access time, 
SeaweedFS can achieve both fast local access time and elastic cloud storage capacity.
What&#039;s more, the cloud storage access API cost is minimized. 
Faster and cheaper than direct cloud storage!

[Back to TOC](#table-of-contents)

# Features #
## Additional Features ##
* Can choose no replication or different replication levels, rack and data center aware.
* Automatic master servers failover - no single point of failure (SPOF).
* Automatic Gzip compression depending on file MIME type.
* Automatic compaction to reclaim disk space after deletion or update.
* [Automatic entry TTL expiration][VolumeServerTTL].
* Any server with some disk space can add to the total storage space.
* Adding/Removing servers does **not** cause any data re-balancing unless triggered by admin commands.
* Optional picture resizing.
* Support ETag, Accept-Range, Last-Modified, etc.
* Support in-memory/leveldb/readonly mode tuning for memory/performance balance.
* Support rebalancing the writable and readonly volumes.
* [Customizable Multiple Storage Tiers][TieredStorage]: Customizable storage disk types to balance performance and cost.
* [Transparent cloud integration][CloudTier]: unlimited capacity via tiered cloud storage for warm data.
* [Erasure Coding for warm storage][ErasureCoding]  Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.

[Back to TOC](#table-of-contents)

## Filer Features ##
* [Filer server][Filer] provides &quot;normal&quot; directories and files via HTTP.
* [File TTL][FilerTTL] automatically expires file metadata and actual file data.
* [Mount filer][Mount] reads and writes files directly as a local directory via FUSE.
* [Filer Store Replication][FilerStoreReplication] enables HA for filer meta data stores.
* [Active-Active Replication][ActiveActiveAsyncReplication] enables asynchronous one-way or two-way cross cluster continuous replication.
* [Amazon S3 compatible API][AmazonS3API] accesses files with S3 tooling.
* [Hadoop Compatible File System][Hadoop] accesses files from Hadoop/Spark/Flink/etc or even runs HBase.
* [Async Replication To Cloud][BackupToCloud] has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.
* [WebDAV] accesses as a mapped drive on Mac and Windows, or from mobile devices.
* [AES256-GCM Encrypted Storage][FilerDataEncryption] safely stores the encrypted data.
* [Super Large Files][SuperLargeFiles] stores large or super large files in tens of TB.
* [Cloud Drive][CloudDrive] mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.
* [Gateway to Remote Object Store][GatewayToRemoteObjectStore] mirrors bucket operations to remote object storage, in addition to [Cloud Drive][CloudDrive]

## Kubernetes ##
* [Kubernetes CSI Driver][SeaweedFsCsiDriver] A Container Storage Interface (CSI) Driver. [![Docker Pulls](https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800)](https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/)
* [SeaweedFS Operator](https://github.com/seaweedfs/seaweedfs-operator)

[Filer]: https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files
[SuperLargeFiles]: https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files
[Mount]: https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount
[AmazonS3API]: https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API
[BackupToCloud]: https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud
[Hadoop]: https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System
[WebDAV]: https://github.com/seaweedfs/seaweedfs/wiki/WebDAV
[ErasureCoding]: https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage
[TieredStorage]: https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage
[CloudTier]: https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier
[FilerDataEncryption]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption
[FilerTTL]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores
[VolumeServerTTL]: https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live
[SeaweedFsCsiDriver]: https://github.com/seaweedfs/seaweedfs-csi-driver
[ActiveActiveAsyncReplication]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization
[FilerStoreReplication]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication
[KeyLargeValueStore]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store
[CloudDrive]: https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture
[GatewayToRemoteObjectStore]: https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage


[Back to TOC](#table-of-contents)

## Example: Using Seaweed Object Store ##

By default, the master node runs on port 9333, and the volume nodes run on port 8080.
Let&#039;s start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We&#039;ll use localhost as an example.

SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.

### Start Master Server ###

```
&gt; ./weed master
```

### Start Volume Servers ###

```
&gt; weed volume -dir=&quot;/tmp/data1&quot; -max=5  -mserver=&quot;localhost:9333&quot; -port=8080 &amp;
&gt; weed volume -dir=&quot;/tmp/data2&quot; -max=10 -mserver=&quot;localhost:9333&quot; -port=8081 &amp;
```

### Write File ###

To upload a file: first, send a HTTP POST, PUT, or GET request to `/dir/assign` to get an `fid` and a volume server URL:

```
&gt; curl http://localhost:9333/dir/assign
{&quot;count&quot;:1,&quot;fid&quot;:&quot;3,01637037d6&quot;,&quot;url&quot;:&quot;127.0.0.1:8080&quot;,&quot;publicUrl&quot;:&quot;localhost:8080&quot;}
```

Second, to store the file content, send a HTTP multi-part POST request to `url + &#039;/&#039; + fid` from the response:

```
&gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{&quot;name&quot;:&quot;myphoto.jpg&quot;,&quot;size&quot;:43234,&quot;eTag&quot;:&quot;1cc0118e&quot;}
```

To update, send another POST request with updated file content.

For deletion, send an HTTP DELETE request to the same `url + &#039;/&#039; + fid` URL:

```
&gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
```

### Save File Id ###

Now, you can save the `fid`, 3,01637037d6 in this case, to a database field.

The number 3 at the start represents a volume id. After the comma, it&#039;s one file key, 01, and a file cookie, 637037d6.

The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.

The file key and file cookie are both coded in hex. You can store the &lt;volume id, file key, file cookie&gt; tuple in your own format, or simply store the `fid` as a string.

If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.

If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.

### Read File ###

Here is an example of how to render the URL.

First look up the volume server&#039;s URLs by the file&#039;s volumeId:

```
&gt; curl http://localhost:9333/dir/lookup?volumeId=3
{&quot;volumeId&quot;:&quot;3&quot;,&quot;locations&quot;:[{&quot;publicUrl&quot;:&quot;localhost:8080&quot;,&quot;url&quot;:&quot;localhost:8080&quot;}]}
```

Since (usually) there are not too many volume servers, and volumes don&#039;t move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.

Now you can take the public URL, render the URL or directly read from the volume server via URL:

```
 http://localhost:8080/3,01637037d6.jpg
```

Notice we add a file extension &quot;.jpg&quot; here. It&#039;s optional and just one way for the client to specify the file content type.

If you want a nicer URL, you can use one of these alternative URL formats:

```
 http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
```

If you want to get a scaled version of an image, you can add some params:

```
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200&amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200&amp;mode=fill
```

### Rack-Aware and Data Center-Aware Replication ###

SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:

```
curl http://localhost:9333/dir/assign?replication=001
```

The replication parameter options are:

```
000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
```

More details about replication can be found [on the wiki][Replication].

[Replication]: https://github.com/seaweedfs/seaweedfs/wiki/Replication

You can also set the default replication strategy when starting the master server.

### Allocate File Key on Specific Data Center ###

Volume servers can be started with a specific data center name:

```
 weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
```

When requesting a file key, an optional &quot;dataCenter&quot; parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to &#039;dc1&#039;:

```
 http://localhost:9333/dir/assign?dataCenter=dc1
```

### Other Features ###
  * [No Single Point of Failure][feat-1]
  * [Insert with your own keys][feat-2]
  * [Chunking large files][feat-3]
  * [Collection as a Simple Name Space][feat-4]

[feat-1]: https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server
[feat-2]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys
[feat-3]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files
[feat-4]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space

[Back to TOC](#table-of-contents)

## Object Store Architecture ##

Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.

The main drawback is that the central master can&#039;t handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.

Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.

The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.

For comparison, consider that an xfs inode structure in Linux is 536 bytes.

### Master Server and Volume Server ###

The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.

All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.

On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.

### Write and Read files ###

When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.

When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for t

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[base/node]]></title>
            <link>https://github.com/base/node</link>
            <guid>https://github.com/base/node</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:29 GMT</pubDate>
            <description><![CDATA[Everything required to run your own Base node]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/base/node">base/node</a></h1>
            <p>Everything required to run your own Base node</p>
            <p>Language: Go</p>
            <p>Stars: 68,642</p>
            <p>Forks: 2,939</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>![Base](logo.webp)

# Base Node

Base is a secure, low-cost, developer-friendly Ethereum L2 built on Optimism&#039;s [OP Stack](https://docs.optimism.io/). This repository contains Docker builds to run your own node on the Base network.

[![Website base.org](https://img.shields.io/website-up-down-green-red/https/base.org.svg)](https://base.org)
[![Docs](https://img.shields.io/badge/docs-up-green)](https://docs.base.org/)
[![Discord](https://img.shields.io/discord/1067165013397213286?label=discord)](https://base.org/discord)
[![Twitter Base](https://img.shields.io/twitter/follow/Base?style=social)](https://x.com/Base)
[![Farcaster Base](https://img.shields.io/badge/Farcaster_Base-3d8fcc)](https://farcaster.xyz/base)

## Quick Start

1. Ensure you have an Ethereum L1 full node RPC available
2. Choose your network:
   - For mainnet: Use `.env.mainnet`
   - For testnet: Use `.env.sepolia`
3. Configure your L1 endpoints in the appropriate `.env` file:
   ```bash
   OP_NODE_L1_ETH_RPC=&lt;your-preferred-l1-rpc&gt;
   OP_NODE_L1_BEACON=&lt;your-preferred-l1-beacon&gt;
   OP_NODE_L1_BEACON_ARCHIVER=&lt;your-preferred-l1-beacon-archiver&gt;
   ```
4. Start the node:

   ```bash
   # For mainnet (default):
   docker compose up --build

   # For testnet:
   NETWORK_ENV=.env.sepolia docker compose up --build

   # To use a specific client (optional):
   CLIENT=reth docker compose up --build

   # For testnet with a specific client:
   NETWORK_ENV=.env.sepolia CLIENT=reth docker compose up --build
   ```

### Supported Clients

- `reth` (default)
- `geth`
- `nethermind`

## Requirements

### Minimum Requirements

- Modern Multicore CPU
- 32GB RAM (64GB Recommended)
- NVMe SSD drive
- Storage: (2 \* [current chain size](https://base.org/stats) + [snapshot size](https://basechaindata.vercel.app) + 20% buffer) (to accommodate future growth)
- Docker and Docker Compose

### Production Hardware Specifications

The following are the hardware specifications we use in production:

#### Reth Archive Node (recommended)

- **Instance**: AWS i7i.12xlarge
- **Storage**: RAID 0 of all local NVMe drives (`/dev/nvme*`)
- **Filesystem**: ext4

#### Geth Full Node

- **Instance**: AWS i7i.12xlarge
- **Storage**: RAID 0 of all local NVMe drives (`/dev/nvme*`)
- **Filesystem**: ext4

&gt; [!NOTE]
To run the node using a supported client, you can use the following command:
`CLIENT=supported_client docker compose up --build`
 
Supported clients:
 - reth (with Flashblocks support option, see [Reth Node README](./reth/README.md))
 - geth
 - nethermind

## Configuration

### Required Settings

- L1 Configuration:
  - `OP_NODE_L1_ETH_RPC`: Your Ethereum L1 node RPC endpoint
  - `OP_NODE_L1_BEACON`: Your L1 beacon node endpoint
  - `OP_NODE_L1_BEACON_ARCHIVER`: Your L1 beacon archiver endpoint
  - `OP_NODE_L1_RPC_KIND`: The type of RPC provider being used (default: &quot;debug_geth&quot;). Supported values:
    - `alchemy`: Alchemy RPC provider
    - `quicknode`: QuickNode RPC provider
    - `infura`: Infura RPC provider
    - `parity`: Parity RPC provider
    - `nethermind`: Nethermind RPC provider
    - `debug_geth`: Debug Geth RPC provider
    - `erigon`: Erigon RPC provider
    - `basic`: Basic RPC provider (standard receipt fetching only)
    - `any`: Any available RPC method
    - `standard`: Standard RPC methods including newer optimized methods

### Network Settings

- Mainnet:
  - `RETH_CHAIN=base`
  - `OP_NODE_NETWORK=base-mainnet`
  - Sequencer: `https://mainnet-sequencer.base.org`

### Performance Settings

- Cache Settings:
  - `GETH_CACHE=&quot;20480&quot;` (20GB)
  - `GETH_CACHE_DATABASE=&quot;20&quot;` (4GB)
  - `GETH_CACHE_GC=&quot;12&quot;`
  - `GETH_CACHE_SNAPSHOT=&quot;24&quot;`
  - `GETH_CACHE_TRIE=&quot;44&quot;`

### Optional Features

- EthStats Monitoring (uncomment to enable)
- Trusted RPC Mode (uncomment to enable)
- Snap Sync (experimental)

For full configuration options, see the `.env.mainnet` file.

## Snapshots

Snapshots are available to help you sync your node more quickly. See [docs.base.org](https://docs.base.org/chain/run-a-base-node#snapshots) for links and more details on how to restore from a snapshot.

## Supported Networks

| Network | Status |
| ------- | ------ |
| Mainnet | âœ…     |
| Testnet | âœ…     |

## Troubleshooting

For support please join our [Discord](https://discord.gg/buildonbase) post in `ðŸ› ï½œnode-operators`. You can alternatively open a new GitHub issue.

## Disclaimer

THE NODE SOFTWARE IS PROVIDED &quot;AS IS&quot; WITHOUT WARRANTY OF ANY KIND. We make no guarantees about asset protection or security. Usage is subject to applicable laws and regulations.

For more information, visit [docs.base.org](https://docs.base.org/).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ava-labs/avalanchego]]></title>
            <link>https://github.com/ava-labs/avalanchego</link>
            <guid>https://github.com/ava-labs/avalanchego</guid>
            <pubDate>Sat, 01 Nov 2025 00:52:28 GMT</pubDate>
            <description><![CDATA[Go implementation of an Avalanche node.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ava-labs/avalanchego">ava-labs/avalanchego</a></h1>
            <p>Go implementation of an Avalanche node.</p>
            <p>Language: Go</p>
            <p>Stars: 2,308</p>
            <p>Forks: 816</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;resources/AvalancheLogoRed.png?raw=true&quot;&gt;
&lt;/div&gt;

---

Node implementation for the [Avalanche](https://avax.network) network -
a blockchains platform with high throughput, and blazing fast transactions.

## Installation

Avalanche is an incredibly lightweight protocol, so the minimum computer requirements are quite modest.
Note that as network usage increases, hardware requirements may change.

The minimum recommended hardware specification for nodes connected to Mainnet is:

- CPU: Equivalent of 8 AWS vCPU
- RAM: 16 GiB
- Storage: 1 TiB
  - Nodes running for very long periods of time or nodes with custom configurations may observe higher storage requirements.
- OS: Ubuntu 22.04/24.04 or macOS &gt;= 12
- Network: Reliable IPv4 or IPv6 network connection, with an open public port.

If you plan to build AvalancheGo from source, you will also need the following software:

- [Go](https://golang.org/doc/install) version &gt;= 1.24.9
- [gcc](https://gcc.gnu.org/)
- g++

### Building From Source

#### Clone The Repository

Clone the AvalancheGo repository:

```sh
git clone git@github.com:ava-labs/avalanchego.git
cd avalanchego
```

This will clone and checkout the `master` branch.

#### Building AvalancheGo

Build AvalancheGo by running the build task:

```sh
./scripts/run_task.sh build
```

The `avalanchego` binary is now in the `build` directory. To run:

```sh
./build/avalanchego
```

### Binary Repository

Install AvalancheGo using an `apt` repository.

#### Adding the APT Repository

If you already have the APT repository added, you do not need to add it again.

To add the repository on Ubuntu, run:

```sh
sudo su -
wget -qO - https://downloads.avax.network/avalanchego.gpg.key | tee /etc/apt/trusted.gpg.d/avalanchego.asc
source /etc/os-release &amp;&amp; echo &quot;deb https://downloads.avax.network/apt $UBUNTU_CODENAME main&quot; &gt; /etc/apt/sources.list.d/avalanche.list
exit
```

#### Installing the Latest Version

After adding the APT repository, install `avalanchego` by running:

```sh
sudo apt update
sudo apt install avalanchego
```

### Binary Install

Download the [latest build](https://github.com/ava-labs/avalanchego/releases/latest) for your operating system and architecture.

The Avalanche binary to be executed is named `avalanchego`.

### Docker Install

Make sure Docker is installed on the machine - so commands like `docker run` etc. are available.

Building the Docker image of latest `avalanchego` branch can be done by running:

```sh
./scripts/run-task.sh build-image
```

To check the built image, run:

```sh
docker image ls
```

The image should be tagged as `avaplatform/avalanchego:xxxxxxxx`, where `xxxxxxxx` is the shortened commit of the Avalanche source it was built from. To run the Avalanche node, run:

```sh
docker run -ti -p 9650:9650 -p 9651:9651 avaplatform/avalanchego:xxxxxxxx /avalanchego/build/avalanchego
```

## Running Avalanche

### Connecting to Mainnet

To connect to the Avalanche Mainnet, run:

```sh
./build/avalanchego
```

You should see some pretty ASCII art and log messages.

You can use `Ctrl+C` to kill the node.

### Connecting to Fuji

To connect to the Fuji Testnet, run:

```sh
./build/avalanchego --network-id=fuji
```

### Creating a Local Testnet

The [avalanche-cli](https://github.com/ava-labs/avalanche-cli) is the easiest way to start a local network.

```sh
avalanche network start
avalanche network status
```

## Bootstrapping

A node needs to catch up to the latest network state before it can participate in consensus and serve API calls. This process (called bootstrapping) currently takes several days for a new node connected to Mainnet.

A node will not [report healthy](https://build.avax.network/docs/api-reference/health-api) until it is done bootstrapping.

Improvements that reduce the amount of time it takes to bootstrap are under development.

The bottleneck during bootstrapping is typically database IO. Using a more powerful CPU or increasing the database IOPS on the computer running a node will decrease the amount of time bootstrapping takes.

## Generating Code

AvalancheGo uses multiple tools to generate efficient and boilerplate code.

### Running protobuf codegen

To regenerate the protobuf go code, run `scripts/run-task.sh generate-protobuf` from the root of the repo.

This should only be necessary when upgrading protobuf versions or modifying .proto definition files.

To use this script, you must have [buf](https://docs.buf.build/installation) (v1.31.0), protoc-gen-go (v1.33.0) and protoc-gen-go-grpc (v1.3.0) installed.

To install the buf dependencies:

```sh
go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.33.0
go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.3.0
```

If you have not already, you may need to add `$GOPATH/bin` to your `$PATH`:

```sh
export PATH=&quot;$PATH:$(go env GOPATH)/bin&quot;
```

If you extract buf to ~/software/buf/bin, the following should work:

```sh
export PATH=$PATH:~/software/buf/bin/:~/go/bin
go get google.golang.org/protobuf/cmd/protoc-gen-go
go get google.golang.org/protobuf/cmd/protoc-gen-go-grpc
scripts/run_task.sh generate-protobuf
```

For more information, refer to the [GRPC Golang Quick Start Guide](https://grpc.io/docs/languages/go/quickstart/).

### Running mock codegen

See [the Contributing document autogenerated mocks section](CONTRIBUTING.md####Autogenerated-mocks).

## Versioning

### Version Semantics

AvalancheGo is first and foremost a client for the Avalanche network. The versioning of AvalancheGo follows that of the Avalanche network.

- `v0.x.x` indicates a development network version.
- `v1.x.x` indicates a production network version.
- `vx.[Upgrade].x` indicates the number of network upgrades that have occurred.
- `vx.x.[Patch]` indicates the number of client upgrades that have occurred since the last network upgrade.

### Library Compatibility Guarantees

Because AvalancheGo&#039;s version denotes the network version, it is expected that interfaces exported by AvalancheGo&#039;s packages may change in `Patch` version updates.

### API Compatibility Guarantees

APIs exposed when running AvalancheGo will maintain backwards compatibility, unless the functionality is explicitly deprecated and announced when removed.

## Supported Platforms

AvalancheGo can run on different platforms, with different support tiers:

- **Tier 1**: Fully supported by the maintainers, guaranteed to pass all tests including e2e and stress tests.
- **Tier 2**: Passes all unit and integration tests but not necessarily e2e tests.
- **Tier 3**: Builds but lightly tested (or not), considered _experimental_.
- **Not supported**: May not build and not tested, considered _unsafe_. To be supported in the future.

The following table lists currently supported platforms and their corresponding
AvalancheGo support tiers:

| Architecture | Operating system | Support tier  |
| :----------: | :--------------: | :-----------: |
|    amd64     |      Linux       |       1       |
|    arm64     |      Linux       |       2       |
|    amd64     |      Darwin      |       2       |
|    amd64     |     Windows      | Not supported |
|     arm      |      Linux       | Not supported |
|     i386     |      Linux       | Not supported |
|    arm64     |      Darwin      | Not supported |

To officially support a new platform, one must satisfy the following requirements:

| AvalancheGo continuous integration | Tier 1  | Tier 2  | Tier 3  |
| ---------------------------------- | :-----: | :-----: | :-----: |
| Build passes                       | &amp;check; | &amp;check; | &amp;check; |
| Unit and integration tests pass    | &amp;check; | &amp;check; |         |
| End-to-end and stress tests pass   | &amp;check; |         |         |

## Security Bugs

**We and our community welcome responsible disclosures.**

Please refer to our [Security Policy](SECURITY.md) and [Security Advisories](https://github.com/ava-labs/avalanchego/security/advisories).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>