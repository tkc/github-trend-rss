<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Wed, 16 Apr 2025 00:05:38 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[gofiber/fiber]]></title>
            <link>https://github.com/gofiber/fiber</link>
            <guid>https://github.com/gofiber/fiber</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:38 GMT</pubDate>
            <description><![CDATA[‚ö°Ô∏è Express inspired web framework written in Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gofiber/fiber">gofiber/fiber</a></h1>
            <p>‚ö°Ô∏è Express inspired web framework written in Go</p>
            <p>Language: Go</p>
            <p>Stars: 36,016</p>
            <p>Forks: 1,758</p>
            <p>Stars today: 65 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[krillinai/KrillinAI]]></title>
            <link>https://github.com/krillinai/KrillinAI</link>
            <guid>https://github.com/krillinai/KrillinAI</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:37 GMT</pubDate>
            <description><![CDATA[A video translation and dubbing tool powered by LLMs, offering professional-grade translations and one-click full-process deployment. It can generate content optimized for platforms like YouTubeÔºåTikTok, and Shorts. Âü∫‰∫éAIÂ§ßÊ®°ÂûãÁöÑËßÜÈ¢ëÁøªËØëÂíåÈÖçÈü≥Â∑•ÂÖ∑Ôºå‰∏ì‰∏öÁ∫ßÁøªËØëÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÂÖ®ÊµÅÁ®ãÔºåÂèØ‰ª•ÁîüÊàêÈÄÇÈÖçÊäñÈü≥ÔºåÂ∞èÁ∫¢‰π¶ÔºåÂìîÂì©ÂìîÂì©ÔºåËßÜÈ¢ëÂè∑ÔºåTikTokÔºåYoutube ShortsÁ≠âÂΩ¢ÊÄÅÁöÑÂÜÖÂÆπ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/krillinai/KrillinAI">krillinai/KrillinAI</a></h1>
            <p>A video translation and dubbing tool powered by LLMs, offering professional-grade translations and one-click full-process deployment. It can generate content optimized for platforms like YouTubeÔºåTikTok, and Shorts. Âü∫‰∫éAIÂ§ßÊ®°ÂûãÁöÑËßÜÈ¢ëÁøªËØëÂíåÈÖçÈü≥Â∑•ÂÖ∑Ôºå‰∏ì‰∏öÁ∫ßÁøªËØëÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÂÖ®ÊµÅÁ®ãÔºåÂèØ‰ª•ÁîüÊàêÈÄÇÈÖçÊäñÈü≥ÔºåÂ∞èÁ∫¢‰π¶ÔºåÂìîÂì©ÂìîÂì©ÔºåËßÜÈ¢ëÂè∑ÔºåTikTokÔºåYoutube ShortsÁ≠âÂΩ¢ÊÄÅÁöÑÂÜÖÂÆπ</p>
            <p>Language: Go</p>
            <p>Stars: 4,503</p>
            <p>Forks: 335</p>
            <p>Stars today: 623 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/logo.png&quot; alt=&quot;KrillinAI&quot; height=&quot;90&quot;&gt;


  # AI Audio&amp;Video Translation and Dubbing Tool

&lt;a href=&quot;https://trendshift.io/repositories/13360&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13360&quot; alt=&quot;krillinai%2FKrillinAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

  **[English](./README.md)ÔΩú[ÁÆÄ‰Ωì‰∏≠Êñá](./docs/README_zh.md)ÔΩú[Êó•Êú¨Ë™û](./docs/README_jp.md)ÔΩú[ÌïúÍµ≠Ïñ¥](./docs/README_kr.md)ÔΩú[Fran√ßais](./docs/README_fr.md)ÔΩú[Deutsch](./docs/README_de.md)ÔΩú[Espa√±ol](./docs/README_es.md)ÔΩú[Portugu√™s](./docs/README_pt.md)ÔΩú[–†—É—Å—Å–∫–∏–π](./docs/README_rus.md)ÔΩú[ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](./docs/README_ar.md)**

  [![Twitter](https://img.shields.io/badge/Twitter-KrillinAI-orange?logo=twitter)](https://x.com/KrillinAI)
[![Bilibili](https://img.shields.io/badge/dynamic/json?label=Bilibili&amp;query=%24.data.follower&amp;suffix=%20followers&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Frelation%2Fstat%3Fvmid%3D242124650&amp;logo=bilibili&amp;color=00A1D6&amp;labelColor=FE7398&amp;logoColor=FFFFFF)](https://space.bilibili.com/242124650)
[![QQ Áæ§](https://img.shields.io/badge/QQ%20Áæ§-754069680-green?logo=tencent-qq)](https://jq.qq.com/?_wv=1027&amp;k=754069680)

&lt;/div&gt;

### üì¢ New Release for Win &amp; Mac Desktop Version ‚Äì Welcome to Test and Provide Feedback

## Overview

Krillin AI is an all-in-one solution for effortless video localization and enhancement. This minimalist yet powerful tool handles everything from translation, dubbing to voice cloningÔºåformatting‚Äîseamlessly converting videos between landscape and portrait modes for optimal display across all content platforms(YouTube, TikTok, Bilibili, Douyin, WeChat Channel, RedNote, Kuaishou). With its end-to-end workflow, Krillin AI transforms raw footage into polished, platform-ready content in just a few clicks.

## Key Features:
üéØ **One-Click Start** - Launch your workflow instantly,New desktop version available‚Äîeasier to use!

üì• **Video download** - yt-dlp and local file uploading supported

üìú **Precise Subtitles** - Whisper-powered high-accuracy recognition

üß† **Smart Segmentation** - LLM-based subtitle chunking &amp; alignment

üåç **Professional Translation** - Paragraph-level translation for consistency 

üîÑ **Term Replacement** - One-click domain-specific vocabulary swap 

üéôÔ∏è **Dubbing and Voice Cloning** - CosyVoice selected or cloning voices

üé¨ **Video Composition** - Auto-formatting for horizontal/vertical layouts

## Showcase
The following picture demonstrates the effect after the subtitle file, which was generated through a one-click operation after importing a 46-minute local video, was inserted into the track. There was no manual adjustment involved at all. There are no missing or overlapping subtitles, the sentence segmentation is natural, and the translation quality is also quite high.
![Alignment](./docs/images/alignment.png)

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;33%&quot;&gt;

### Subtitle Translation
---
https://github.com/user-attachments/assets/bba1ac0a-fe6b-4947-b58d-ba99306d0339

&lt;/td&gt;
&lt;td width=&quot;33%&quot;&gt;

### Dubbing
---
https://github.com/user-attachments/assets/0b32fad3-c3ad-4b6a-abf0-0865f0dd2385

&lt;/td&gt;

&lt;td width=&quot;33%&quot;&gt;

### Portrait
---
https://github.com/user-attachments/assets/c2c7b528-0ef8-4ba9-b8ac-f9f92f6d4e71

&lt;/td&gt;

&lt;/tr&gt;
&lt;/table&gt;

## üîç Speech Recognition Support
_**All local models in the table below support automatic installation of executable files + model files. Just make your selection, and KrillinAI will handle everything else for you.**_

| Service         | Supported Platforms          | Model Options                     | Local/Cloud | Notes          |
|-----------------|------------------------------|-----------------------------------|-------------|----------------|
| **OpenAI Whisper** | Cross-platform       | -                                 | Cloud       | Fast with excellent results |
| **FasterWhisper** | Windows/Linux     | `tiny`/`medium`/`large-v2` (recommend medium+) | Local    | Faster speed, no cloud service overhead |
| **WhisperKit**    | macOS (Apple Silicon only)   | `large-v2`                        | Local       | Native optimization for Apple chips |
| **Alibaba Cloud ASR** | Cross-platform    | -                                 | Cloud       | Bypasses China mainland network issues |

## üöÄ Large Language Model Support

‚úÖ Compatible with all **OpenAI API-compatible** cloud/local LLM services including but not limited to:
- OpenAI
- DeepSeek
- Qwen (Tongyi Qianwen)
- Self-hosted open-source models
- Other OpenAI-format compatible API services

## üåç Language Support
Input languages: Chinese, English, Japanese, German, Turkish supported (more languages being added)  
Translation languages: 56 languages supported, including English, Chinese, Russian, Spanish, French, etc.

## Interface Preview
![ui preview](./docs/images/ui_desktop.png)

## üöÄ Quick Start
### Basic Steps
First, download the Release executable file that matches your device&#039;s system. Follow the instructions below to choose between the desktop or non-desktop version, then place the software in an empty folder. Running the program will generate some directories, so keeping it in an empty folder makes management easier.

[For the desktop version (release files with &quot;desktop&quot; in the name), refer here]  
_The desktop version is newly released to address the difficulty beginners face in editing configuration files correctly. It still has some bugs and is being continuously updated._  

Double-click the file to start using it.

[For the non-desktop version (release files without &quot;desktop&quot; in the name), refer here]  
_The non-desktop version is the original release, with more complex configuration but stable functionality. It is also suitable for server deployment, as it provides a web-based UI._  

Create a `config` folder in the directory, then create a `config.toml` file inside it. Copy the contents of the `config-example.toml` file from the source code&#039;s `config` directory into your `config.toml` and fill in your configuration details. (If you want to use OpenAI models but don‚Äôt know how to get a key, you can join the group for free trial access.)

Double-click the executable or run it in the terminal to start the service.

Open your browser and enter http://127.0.0.1:8888 to begin using it. (Replace 8888 with the port number you specified in the config file.)

### To: macOS Users
[For the desktop version, i.e., release files with &quot;desktop&quot; in the name, refer here]  
The current packaging method for the desktop version cannot support direct double-click execution or DMG installation due to signing issues. Manual trust configuration is required as follows:

1. Open the directory containing the executable file (assuming the filename is KrillinAI_1.0.0_desktop_macOS_arm64) in Terminal

2. Execute the following commands sequentially:

```
sudo xattr -cr ./KrillinAI_1.0.0_desktop_macOS_arm64  
sudo chmod +x ./KrillinAI_1.0.0_desktop_macOS_arm64  
./KrillinAI_1.0.0_desktop_macOS_arm64  
```

[For the non-desktop version, i.e., release files without &quot;desktop&quot; in the name, refer here]  
This software is not signed, so after completing the file configuration in the &quot;Basic Steps,&quot; you will need to manually trust the application on macOS. Follow these steps:
1. Open the terminal and navigate to the directory where the executable file (assuming the file name is `KrillinAI_1.0.0_macOS_arm64`) is located.
2. Execute the following commands in sequence:
```
sudo xattr -rd com.apple.quarantine ./KrillinAI_1.0.0_macOS_arm64
sudo chmod +x ./KrillinAI_1.0.0_macOS_arm64
./KrillinAI_1.0.0_macOS_arm64
```
This will start the service.

### Docker Deployment
This project supports Docker deployment. Please refer to the [Docker Deployment Instructions](./docs/docker.md).

### Cookie Configuration Instructions

If you encounter video download failures, please refer to the [Cookie Configuration Instructions](./docs/get_cookies.md) to configure your cookie information.

### Configuration Help
The quickest and most convenient configuration method:
* Select `openai` for both `transcription_provider` and `llm_provider`. In this way, you only need to fill in `openai.apikey` in the following three major configuration item categories, namely `openai`, `local_model`, and `aliyun`, and then you can conduct subtitle translation. (Fill in `app.proxy`, `model` and `openai.base_url` as per your own situation.)

The configuration method for using the local speech recognition model (macOS is not supported for the time being) (a choice that takes into account cost, speed, and quality):
* Fill in `fasterwhisper` for `transcription_provider` and `openai` for `llm_provider`. In this way, you only need to fill in `openai.apikey` and `local_model.faster_whisper` in the following three major configuration item categories, namely `openai` and `local_model`, and then you can conduct subtitle translation. The local model will be downloaded automatically. (The same applies to `app.proxy` and `openai.base_url` as mentioned above.)

The following usage situations require the configuration of Alibaba Cloud:
* If `llm_provider` is filled with `aliyun`, it indicates that the large model service of Alibaba Cloud will be used. Consequently, the configuration of the `aliyun.bailian` item needs to be set up.
* If `transcription_provider` is filled with `aliyun`, or if the &quot;voice dubbing&quot; function is enabled when starting a task, the voice service of Alibaba Cloud will be utilized. Therefore, the configuration of the `aliyun.speech` item needs to be filled in.
* If the &quot;voice dubbing&quot; function is enabled and local audio files are uploaded for voice timbre cloning at the same time, the OSS cloud storage service of Alibaba Cloud will also be used. Hence, the configuration of the `aliyun.oss` item needs to be filled in.
Configuration Guide: [Alibaba Cloud Configuration Instructions](./docs/aliyun.md)

## Frequently Asked Questions
Please refer to [Frequently Asked Questions](./docs/faq.md)

## Contribution Guidelines

- Do not submit unnecessary files like `.vscode`, `.idea`, etc. Please make good use of `.gitignore` to filter them.
- Do not submit `config.toml`; instead, submit `config-example.toml`.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=krillinai/KrillinAI&amp;type=Date)](https://star-history.com/#krillinai/KrillinAI&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gofr-dev/gofr]]></title>
            <link>https://github.com/gofr-dev/gofr</link>
            <guid>https://github.com/gofr-dev/gofr</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:36 GMT</pubDate>
            <description><![CDATA[An opinionated GoLang framework for accelerated microservice development. Built in support for databases and observability.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gofr-dev/gofr">gofr-dev/gofr</a></h1>
            <p>An opinionated GoLang framework for accelerated microservice development. Built in support for databases and observability.</p>
            <p>Language: Go</p>
            <p>Stars: 9,241</p>
            <p>Forks: 1,690</p>
            <p>Stars today: 379 stars today</p>
            <h2>README</h2><pre>&lt;h1 style=&quot;text-align: center; font-size: 100px; font-weight: 500;&quot;&gt;
    &lt;i&gt;Go&lt;/i&gt;Fr
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img align=&quot;center&quot; width=&quot;300&quot; alt=&quot;logo&quot; src=&quot;https://github.com/gofr-dev/gofr/assets/44036979/916fe7b1-42fb-4af1-9e0b-4a7a064c243c&quot;&gt;
&lt;/p&gt;

&lt;h2 align=&quot;center&quot; style=&quot;font-size: 28px;&quot;&gt;&lt;b&gt;GoFr: An Opinionated Microservice Development Framework&lt;/b&gt;&lt;/h2&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://pkg.go.dev/gofr.dev&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GoDoc-Read%20Documentation-blue?style=for-the-badge&quot; alt=&quot;godoc&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://gofr.dev/docs&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GoFr-Docs-orange?style=for-the-badge&quot; alt=&quot;gofr-docs&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://codeclimate.com/github/gofr-dev/gofr/maintainability&quot;&gt;&lt;img src=&quot;https://img.shields.io/codeclimate/maintainability/gofr-dev/gofr?style=for-the-badge&quot; alt=&quot;maintainability&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://codeclimate.com/github/gofr-dev/gofr/test_coverage&quot;&gt;&lt;img src=&quot;https://img.shields.io/codeclimate/coverage/gofr-dev/gofr?style=for-the-badge&quot; alt=&quot;test-coverage&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://goreportcard.com/report/gofr.dev&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/gofr.dev?style=for-the-badge&quot; alt=&quot;Go Report Card&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue?style=for-the-badge&quot; alt=&quot;Apache 2.0 License&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://discord.gg/wsaSkQTdgq&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/discord-join-us?style=for-the-badge&amp;logo=discord&amp;color=7289DA&quot; alt=&quot;discord&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://gurubase.io/g/gofr&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Gurubase-Ask%20GoFr%20Guru-006BFF?style=for-the-badge&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;h2 align=&quot;center&quot;&gt;Listed in the &lt;a href=&quot;https://landscape.cncf.io/?selected=go-fr&quot;&gt;CNCF Landscape&lt;/a&gt;&lt;/h2&gt;

## üéØ **Goal**
GoFr is designed to **simplify microservice development**, with key focuses on **Kubernetes deployment** and **out-of-the-box observability**. While capable of building generic applications, **microservices** remain at its core.

---

## üí° **Key Features**

1. **Simple API Syntax**
2. **REST Standards by Default**
3. **Configuration Management**
4. **[Observability](https://gofr.dev/docs/quick-start/observability)** (Logs, Traces, Metrics)
5. **Inbuilt [Auth Middleware](https://gofr.dev/docs/advanced-guide/http-authentication)** &amp; Custom Middleware Support
6. **[gRPC Support](https://gofr.dev/docs/advanced-guide/grpc)**
7. **[HTTP Service](https://gofr.dev/docs/advanced-guide/http-communication)** with Circuit Breaker Support
8. **[Pub/Sub](https://gofr.dev/docs/advanced-guide/using-publisher-subscriber)**
9. **[Health Check](https://gofr.dev/docs/advanced-guide/monitoring-service-health)** for All Datasources
10. **[Database Migration](https://gofr.dev/docs/advanced-guide/handling-data-migrations)**
11. **[Cron Jobs](https://gofr.dev/docs/advanced-guide/using-cron)**
12. **Support for [Changing Log Level](https://gofr.dev/docs/advanced-guide/remote-log-level-change) Without Restarting**
13. **[Swagger Rendering](https://gofr.dev/docs/advanced-guide/swagger-documentation)**
14. **[Abstracted File Systems](https://gofr.dev/docs/advanced-guide/handling-file)**
15. **[Websockets](https://gofr.dev/docs/advanced-guide/handling-file)**

---

## üöÄ **Getting Started**

### **Prerequisites**
- GoFr requires **[Go](https://go.dev/)** version **[1.21](https://go.dev/doc/devel/release#go1.21.0)** or above.

### **Installation**
To get started with GoFr, add the following import to your code and use Go‚Äôs module support to automatically fetch dependencies:

```go
import &quot;gofr.dev/pkg/gofr&quot;
```

Alternatively, use the command:

```bash
go get -u gofr.dev/pkg/gofr
```

---

## üèÉ **Running GoFr**

Here&#039;s a simple example to get a GoFr application up and running:

```go
package main

import &quot;gofr.dev/pkg/gofr&quot;

func main() {
	app := gofr.New()

	app.GET(&quot;/greet&quot;, func(ctx *gofr.Context) (any, error) {
		return &quot;Hello World!&quot;, nil
	})

	app.Run() // listens and serves on localhost:8000
}
```

To run this code:

```bash
$ go run main.go
```

Visit [`localhost:8000/greet`](http://localhost:8000/greet) to see the result.

---

## üìÇ **More Examples**

Explore a variety of ready-to-run examples in the [GoFr examples directory](https://github.com/gofr-dev/gofr/tree/development/examples).

---

## üë©‚Äçüíª **Documentation**

- **[GoDoc](https://pkg.go.dev/gofr.dev)**: Official API documentation.
- **[GoFr Documentation](https://gofr.dev/docs)**: Comprehensive guides and resources.

---

## üëç **Contribute**

Help us make GoFr even better:

1. **Star** this repo on GitHub! üåü
2. Write a review or tutorial on **[Medium](https://medium.com/)**, **[Dev.to](https://dev.to/)**, or your blog.
3. Review the **[CONTRIBUTING.md](CONTRIBUTING.md)** guide to learn how to contribute to the project.

---

## üîí **Secure Cloning**
To securely clone the GoFr repository, you can use HTTPS or SSH:

### Cloning with HTTPS
```bash
git clone https://github.com/gofr-dev/gofr.git
```
### Cloning with SSH
```bash
git clone git@github.com:gofr-dev/gofr.git
```

### üéÅ **Get a GoFr T-Shirt &amp; Stickers!**

If your PR is merged, or if you contribute by writing articles or promoting GoFr, we invite you to fill out [this form](https://forms.gle/R1Yz7ZzY3U5WWTgy5) to claim your GoFr merchandise as a token of our appreciation! 

### Partners

&lt;img src=&quot;https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.png&quot; alt=&quot;JetBrains logo&quot; width=&quot;200&quot;&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[stretchr/testify]]></title>
            <link>https://github.com/stretchr/testify</link>
            <guid>https://github.com/stretchr/testify</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:35 GMT</pubDate>
            <description><![CDATA[A toolkit with common assertions and mocks that plays nicely with the standard library]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stretchr/testify">stretchr/testify</a></h1>
            <p>A toolkit with common assertions and mocks that plays nicely with the standard library</p>
            <p>Language: Go</p>
            <p>Stars: 24,425</p>
            <p>Forks: 1,634</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>Testify - Thou Shalt Write Tests
================================

&gt; [!NOTE]
&gt; Testify is being maintained at v1, no breaking changes will be accepted in this repo.  
&gt; [See discussion about v2](https://github.com/stretchr/testify/discussions/1560).

[![Build Status](https://github.com/stretchr/testify/actions/workflows/main.yml/badge.svg?branch=master)](https://github.com/stretchr/testify/actions/workflows/main.yml) [![Go Report Card](https://goreportcard.com/badge/github.com/stretchr/testify)](https://goreportcard.com/report/github.com/stretchr/testify) [![PkgGoDev](https://pkg.go.dev/badge/github.com/stretchr/testify)](https://pkg.go.dev/github.com/stretchr/testify)

Go code (golang) set of packages that provide many tools for testifying that your code will behave as you intend.

Features include:

  * [Easy assertions](#assert-package)
  * [Mocking](#mock-package)
  * [Testing suite interfaces and functions](#suite-package)

Get started:

  * Install testify with [one line of code](#installation), or [update it with another](#staying-up-to-date)
  * For an introduction to writing test code in Go, see https://go.dev/doc/code#Testing
  * Check out the API Documentation https://pkg.go.dev/github.com/stretchr/testify
  * Use [testifylint](https://github.com/Antonboom/testifylint) (via [golangci-lint](https://golangci-lint.run/)) to avoid common mistakes
  * A little about [Test-Driven Development (TDD)](https://en.wikipedia.org/wiki/Test-driven_development)

[`assert`](https://pkg.go.dev/github.com/stretchr/testify/assert &quot;API documentation&quot;) package
-------------------------------------------------------------------------------------------

The `assert` package provides some helpful methods that allow you to write better test code in Go.

  * Prints friendly, easy to read failure descriptions
  * Allows for very readable code
  * Optionally annotate each assertion with a message

See it in action:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	// assert equality
	assert.Equal(t, 123, 123, &quot;they should be equal&quot;)

	// assert inequality
	assert.NotEqual(t, 123, 456, &quot;they should not be equal&quot;)

	// assert for nil (good for errors)
	assert.Nil(t, object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(t, object) {
		// now we know that object isn&#039;t nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(t, &quot;Something&quot;, object.Value)
	}
}
```

  * Every assert func takes the `testing.T` object as the first argument.  This is how it writes the errors out through the normal `go test` capabilities.
  * Every assert func returns a bool indicating whether the assertion was successful or not, this is useful for if you want to go on making further assertions under certain conditions.

if you assert many times, use the below:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	assert := assert.New(t)

	// assert equality
	assert.Equal(123, 123, &quot;they should be equal&quot;)

	// assert inequality
	assert.NotEqual(123, 456, &quot;they should not be equal&quot;)

	// assert for nil (good for errors)
	assert.Nil(object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(object) {
		// now we know that object isn&#039;t nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(&quot;Something&quot;, object.Value)
	}
}
```

[`require`](https://pkg.go.dev/github.com/stretchr/testify/require &quot;API documentation&quot;) package
---------------------------------------------------------------------------------------------

The `require` package provides same global functions as the `assert` package, but instead of returning a boolean result they terminate current test.
These functions must be called from the goroutine running the test or benchmark function, not from other goroutines created during the test.
Otherwise race conditions may occur.

See [t.FailNow](https://pkg.go.dev/testing#T.FailNow) for details.

[`mock`](https://pkg.go.dev/github.com/stretchr/testify/mock &quot;API documentation&quot;) package
----------------------------------------------------------------------------------------

The `mock` package provides a mechanism for easily writing mock objects that can be used in place of real objects when writing test code.

An example test function that tests a piece of code that relies on an external object `testObj`, can set up expectations (testify) and assert that they indeed happened:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/mock&quot;
)

/*
  Test objects
*/

// MyMockedObject is a mocked object that implements an interface
// that describes an object that the code I am testing relies on.
type MyMockedObject struct {
	mock.Mock
}

// DoSomething is a method on MyMockedObject that implements some interface
// and just records the activity, and returns what the Mock object tells it to.
//
// In the real object, this method would do something useful, but since this
// is a mocked object - we&#039;re just going to stub it out.
//
// NOTE: This method is not being tested here, code that uses this object is.
func (m *MyMockedObject) DoSomething(number int) (bool, error) {
	args := m.Called(number)
	return args.Bool(0), args.Error(1)
}

/*
  Actual test functions
*/

// TestSomething is an example of how to use our test object to
// make assertions about some target code we are testing.
func TestSomething(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations
	testObj.On(&quot;DoSomething&quot;, 123).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)
}

// TestSomethingWithPlaceholder is a second example of how to use our test object to
// make assertions about some target code we are testing.
// This time using a placeholder. Placeholders might be used when the
// data being passed in is normally dynamically generated and cannot be
// predicted beforehand (eg. containing hashes that are time sensitive)
func TestSomethingWithPlaceholder(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

}

// TestSomethingElse2 is a third example that shows how you can use
// the Unset method to cleanup handlers and then add new ones.
func TestSomethingElse2(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	mockCall := testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

	// remove the handler now so we can add another one that takes precedence
	mockCall.Unset()

	// return false now instead of true
	testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(false, nil)

	testObj.AssertExpectations(t)
}
```

For more information on how to write mock code, check out the [API documentation for the `mock` package](https://pkg.go.dev/github.com/stretchr/testify/mock).

You can use the [mockery tool](https://vektra.github.io/mockery/latest/) to autogenerate the mock code against an interface as well, making using mocks much quicker.

[`suite`](https://pkg.go.dev/github.com/stretchr/testify/suite &quot;API documentation&quot;) package
-----------------------------------------------------------------------------------------
&gt; [!WARNING]
&gt; The suite package does not support parallel tests. See [#934](https://github.com/stretchr/testify/issues/934).

The `suite` package provides functionality that you might be used to from more common object-oriented languages.  With it, you can build a testing suite as a struct, build setup/teardown methods and testing methods on your struct, and run them with &#039;go test&#039; as per normal.

An example suite is shown below:

```go
// Basic imports
import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
	&quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including a T() method which
// returns the current testing context
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	assert.Equal(suite.T(), 5, suite.VariableThatShouldStartAtFive)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
```

For a more complete example, using all of the functionality provided by the suite package, look at our [example testing suite](https://github.com/stretchr/testify/blob/master/suite/suite_test.go)

For more information on writing suites, check out the [API documentation for the `suite` package](https://pkg.go.dev/github.com/stretchr/testify/suite).

`Suite` object has assertion methods:

```go
// Basic imports
import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including assertion methods.
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	suite.Equal(suite.VariableThatShouldStartAtFive, 5)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
```

------

Installation
============

To install Testify, use `go get`:

    go get github.com/stretchr/testify

This will then make the following packages available to you:

    github.com/stretchr/testify/assert
    github.com/stretchr/testify/require
    github.com/stretchr/testify/mock
    github.com/stretchr/testify/suite
    github.com/stretchr/testify/http (deprecated)

Import the `testify/assert` package into your code using this template:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	assert.True(t, true, &quot;True is true!&quot;)
}
```

------

Staying up to date
==================

To update Testify to the latest version, use `go get -u github.com/stretchr/testify`.

------

Supported go versions
==================

We currently support the most recent major Go versions from 1.19 onward.

------

Contributing
============

Please feel free to submit issues, fork the repository and send pull requests!

When submitting an issue, we ask that you please include a complete test function that demonstrates the issue. Extra credit for those using Testify to write the test code that demonstrates it.

Code generation is used. [Look for `Code generated with`](https://github.com/search?q=repo%3Astretchr%2Ftestify%20%22Code%20generated%20with%22&amp;type=code) at the top of some files. Run `go generate ./...` to update generated files.

We also chat on the [Gophers Slack](https://gophers.slack.com) group in the `#testify` and `#testify-dev` channels.

------

License
=======

This project is licensed under the terms of the MIT license.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[pressly/goose]]></title>
            <link>https://github.com/pressly/goose</link>
            <guid>https://github.com/pressly/goose</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[A database migration tool. Supports SQL migrations and Go functions.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pressly/goose">pressly/goose</a></h1>
            <p>A database migration tool. Supports SQL migrations and Go functions.</p>
            <p>Language: Go</p>
            <p>Stars: 8,134</p>
            <p>Forks: 568</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre># goose

&lt;img align=&quot;right&quot; width=&quot;125&quot; src=&quot;assets/goose_logo.png&quot;&gt;

[![Goose
CI](https://github.com/pressly/goose/actions/workflows/ci.yaml/badge.svg)](https://github.com/pressly/goose/actions/workflows/ci.yaml)
[![Go
Reference](https://pkg.go.dev/badge/github.com/pressly/goose/v3.svg)](https://pkg.go.dev/github.com/pressly/goose/v3)
[![Go Report
Card](https://goreportcard.com/badge/github.com/pressly/goose/v3)](https://goreportcard.com/report/github.com/pressly/goose/v3)

Goose is a database migration tool. Both a CLI and a library.

Manage your **database schema** by creating incremental SQL changes or Go functions.

#### Features

- Works against multiple databases:
  - Postgres, MySQL, SQLite, YDB, ClickHouse, MSSQL, Vertica, and
    more.
- Supports Go migrations written as plain functions.
- Supports [embedded](https://pkg.go.dev/embed/) migrations.
- Out-of-order migrations.
- Seeding data.
- Environment variable substitution in SQL migrations.
- ... and more.

# Install

```shell
go install github.com/pressly/goose/v3/cmd/goose@latest
```

This will install the `goose` binary to your `$GOPATH/bin` directory.

Binary too big? Build a lite version by excluding the drivers you don&#039;t need:

```shell
go build -tags=&#039;no_postgres no_mysql no_sqlite3 no_ydb&#039; -o goose ./cmd/goose

# Available build tags:
#   no_clickhouse  no_libsql   no_mssql    no_mysql
#   no_postgres    no_sqlite3  no_vertica  no_ydb
```

For macOS users `goose` is available as a [Homebrew
Formulae](https://formulae.brew.sh/formula/goose#default):

```shell
brew install goose
```

See [installation documentation](https://pressly.github.io/goose/installation/) for more details.

# Usage

&lt;details&gt;
&lt;summary&gt;Click to show &lt;code&gt;goose help&lt;/code&gt; output&lt;/summary&gt;

```
Usage: goose [OPTIONS] DRIVER DBSTRING COMMAND

or

Set environment key
GOOSE_DRIVER=DRIVER
GOOSE_DBSTRING=DBSTRING
GOOSE_MIGRATION_DIR=MIGRATION_DIR

Usage: goose [OPTIONS] COMMAND

Drivers:
    postgres
    mysql
    sqlite3
    mssql
    redshift
    tidb
    clickhouse
    vertica
    ydb
    starrocks

Examples:
    goose sqlite3 ./foo.db status
    goose sqlite3 ./foo.db create init sql
    goose sqlite3 ./foo.db create add_some_column sql
    goose sqlite3 ./foo.db create fetch_user_data go
    goose sqlite3 ./foo.db up

    goose postgres &quot;user=postgres dbname=postgres sslmode=disable&quot; status
    goose mysql &quot;user:password@/dbname?parseTime=true&quot; status
    goose redshift &quot;postgres://user:password@qwerty.us-east-1.redshift.amazonaws.com:5439/db&quot; status
    goose tidb &quot;user:password@/dbname?parseTime=true&quot; status
    goose mssql &quot;sqlserver://user:password@hostname:1433?database=master&quot; status
    goose clickhouse &quot;tcp://127.0.0.1:9000&quot; status
    goose vertica &quot;vertica://user:password@localhost:5433/dbname?connection_load_balance=1&quot; status
    goose ydb &quot;grpcs://localhost:2135/local?go_query_mode=scripting&amp;go_fake_tx=scripting&amp;go_query_bind=declare,numeric&quot; status
    goose starrocks &quot;user:password@/dbname?parseTime=true&amp;interpolateParams=true&quot; status

    GOOSE_DRIVER=sqlite3 GOOSE_DBSTRING=./foo.db goose status
    GOOSE_DRIVER=sqlite3 GOOSE_DBSTRING=./foo.db goose create init sql
    GOOSE_DRIVER=postgres GOOSE_DBSTRING=&quot;user=postgres dbname=postgres sslmode=disable&quot; goose status
    GOOSE_DRIVER=mysql GOOSE_DBSTRING=&quot;user:password@/dbname&quot; goose status
    GOOSE_DRIVER=redshift GOOSE_DBSTRING=&quot;postgres://user:password@qwerty.us-east-1.redshift.amazonaws.com:5439/db&quot; goose status
    GOOSE_DRIVER=clickhouse GOOSE_DBSTRING=&quot;clickhouse://user:password@qwerty.clickhouse.cloud:9440/dbname?secure=true&amp;skip_verify=false&quot; goose status

Options:

  -allow-missing
        applies missing (out-of-order) migrations
  -certfile string
        file path to root CA&#039;s certificates in pem format (only support on mysql)
  -dir string
        directory with migration files (default &quot;.&quot;, can be set via the GOOSE_MIGRATION_DIR env variable).
  -h    print help
  -no-color
        disable color output (NO_COLOR env variable supported)
  -no-versioning
        apply migration commands with no versioning, in file order, from directory pointed to
  -s    use sequential numbering for new migrations
  -ssl-cert string
        file path to SSL certificates in pem format (only support on mysql)
  -ssl-key string
        file path to SSL key in pem format (only support on mysql)
  -table string
        migrations table name (default &quot;goose_db_version&quot;)
  -timeout duration
        maximum allowed duration for queries to run; e.g., 1h13m
  -v    enable verbose mode
  -version
        print version

Commands:
    up                   Migrate the DB to the most recent version available
    up-by-one            Migrate the DB up by 1
    up-to VERSION        Migrate the DB to a specific VERSION
    down                 Roll back the version by 1
    down-to VERSION      Roll back to a specific VERSION
    redo                 Re-run the latest migration
    reset                Roll back all migrations
    status               Dump the migration status for the current DB
    version              Print the current version of the database
    create NAME [sql|go] Creates new migration file with the current timestamp
    fix                  Apply sequential ordering to migrations
    validate             Check migration files without running them
```

&lt;/details&gt;

Commonly used commands:

[create](#create)&lt;span&gt;&amp;nbsp;‚Ä¢&amp;nbsp;&lt;/span&gt; [up](#up)&lt;span&gt;&amp;nbsp;‚Ä¢&amp;nbsp;&lt;/span&gt; [up-to](#up-to)&lt;span&gt;&amp;nbsp;‚Ä¢&amp;nbsp;&lt;/span&gt; [down](#down)&lt;span&gt;&amp;nbsp;‚Ä¢&amp;nbsp;&lt;/span&gt; [down-to](#down-to)&lt;span&gt;&amp;nbsp;‚Ä¢&amp;nbsp;&lt;/span&gt; [status](#status)&lt;span&gt;&amp;nbsp;‚Ä¢&amp;nbsp;&lt;/span&gt; [version](#version)

## create

Create a new SQL migration.

    $ goose create add_some_column sql
    $ Created new file: 20170506082420_add_some_column.sql

    $ goose -s create add_some_column sql
    $ Created new file: 00001_add_some_column.sql

Edit the newly created file to define the behavior of your migration.

You can also create a Go migration, if you then invoke it with [your own goose
binary](#go-migrations):

    $ goose create fetch_user_data go
    $ Created new file: 20170506082421_fetch_user_data.go

## up

Apply all available migrations.

    $ goose up
    $ OK    001_basics.sql
    $ OK    002_next.sql
    $ OK    003_and_again.go

## up-to

Migrate up to a specific version.

    $ goose up-to 20170506082420
    $ OK    20170506082420_create_table.sql

## up-by-one

Migrate up a single migration from the current version

    $ goose up-by-one
    $ OK    20170614145246_change_type.sql

## down

Roll back a single migration from the current version.

    $ goose down
    $ OK    003_and_again.go

## down-to

Roll back migrations to a specific version.

    $ goose down-to 20170506082527
    $ OK    20170506082527_alter_column.sql

Or, roll back all migrations (careful!):

    $ goose down-to 0

## status

Print the status of all migrations:

    $ goose status
    $   Applied At                  Migration
    $   =======================================
    $   Sun Jan  6 11:25:03 2013 -- 001_basics.sql
    $   Sun Jan  6 11:25:03 2013 -- 002_next.sql
    $   Pending                  -- 003_and_again.go

Note: for MySQL [parseTime flag](https://github.com/go-sql-driver/mysql#parsetime) must be enabled.

Note: for MySQL
[`multiStatements`](https://github.com/go-sql-driver/mysql?tab=readme-ov-file#multistatements) must
be enabled. This is required when writing multiple queries separated by &#039;;&#039; characters in a single
sql file.

## version

Print the current version of the database:

    $ goose version
    $ goose: version 002

# Environment Variables

If you prefer to use environment variables, instead of passing the driver and database string as
arguments, you can set the following environment variables:

**1. Via environment variables:**

```shell
export GOOSE_DRIVER=DRIVER
export GOOSE_DBSTRING=DBSTRING
export GOOSE_MIGRATION_DIR=MIGRATION_DIR
export GOOSE_TABLE=TABLENAME
```

**2. Via `.env` files with corresponding variables. `.env` file example**:

```env
GOOSE_DRIVER=postgres
GOOSE_DBSTRING=postgres://admin:admin@localhost:5432/admin_db
GOOSE_MIGRATION_DIR=./migrations
GOOSE_TABLE=custom.goose_migrations
```

Loading from `.env` files is enabled by default. To disable this feature, set the `-env=none` flag.
If you want to load from a specific file, set the `-env` flag to the file path.

For more details about environment variables, see the [official documentation on environment
variables](https://pressly.github.io/goose/documentation/environment-variables/).

# Migrations

goose supports migrations written in SQL or in Go.

## SQL Migrations

A sample SQL migration looks like:

```sql
-- +goose Up
CREATE TABLE post (
    id int NOT NULL,
    title text,
    body text,
    PRIMARY KEY(id)
);

-- +goose Down
DROP TABLE post;
```

Each migration file must have exactly one `-- +goose Up` annotation. The `-- +goose Down` annotation
is optional. If the file has both annotations, then the `-- +goose Up` annotation **must** come
first.

Notice the annotations in the comments. Any statements following `-- +goose Up` will be executed as
part of a forward migration, and any statements following `-- +goose Down` will be executed as part
of a rollback.

By default, all migrations are run within a transaction. Some statements like `CREATE DATABASE`,
however, cannot be run within a transaction. You may optionally add `-- +goose NO TRANSACTION` to
the top of your migration file in order to skip transactions within that specific migration file.
Both Up and Down migrations within this file will be run without transactions.

By default, SQL statements are delimited by semicolons - in fact, query statements must end with a
semicolon to be properly recognized by goose.

More complex statements (PL/pgSQL) that have semicolons within them must be annotated with `--
+goose StatementBegin` and `-- +goose StatementEnd` to be properly recognized. For example:

```sql
-- +goose Up
-- +goose StatementBegin
CREATE OR REPLACE FUNCTION histories_partition_creation( DATE, DATE )
returns void AS $$
DECLARE
  create_query text;
BEGIN
  FOR create_query IN SELECT
      &#039;CREATE TABLE IF NOT EXISTS histories_&#039;
      || TO_CHAR( d, &#039;YYYY_MM&#039; )
      || &#039; ( CHECK( created_at &gt;= timestamp &#039;&#039;&#039;
      || TO_CHAR( d, &#039;YYYY-MM-DD 00:00:00&#039; )
      || &#039;&#039;&#039; AND created_at &lt; timestamp &#039;&#039;&#039;
      || TO_CHAR( d + INTERVAL &#039;1 month&#039;, &#039;YYYY-MM-DD 00:00:00&#039; )
      || &#039;&#039;&#039; ) ) inherits ( histories );&#039;
    FROM generate_series( $1, $2, &#039;1 month&#039; ) AS d
  LOOP
    EXECUTE create_query;
  END LOOP;  -- LOOP END
END;         -- FUNCTION END
$$
language plpgsql;
-- +goose StatementEnd
```

Goose supports environment variable substitution in SQL migrations through annotations. To enable
this feature, use the `-- +goose ENVSUB ON` annotation before the queries where you want
substitution applied. It stays active until the `-- +goose ENVSUB OFF` annotation is encountered.
You can use these annotations multiple times within a file.

This feature is disabled by default for backward compatibility with existing scripts.

For `PL/pgSQL` functions or other statements where substitution is not desired, wrap the annotations
explicitly around the relevant parts. For example, to exclude escaping the `**` characters:

```sql
-- +goose StatementBegin
CREATE OR REPLACE FUNCTION test_func()
RETURNS void AS $$
-- +goose ENVSUB ON
BEGIN
	RAISE NOTICE &#039;${SOME_ENV_VAR}&#039;;
END;
-- +goose ENVSUB OFF
$$ LANGUAGE plpgsql;
-- +goose StatementEnd
```

&lt;details&gt;
&lt;summary&gt;Supported expansions (click here to expand):&lt;/summary&gt;

- `${VAR}` or $VAR - expands to the value of the environment variable `VAR`
- `${VAR:-default}` - expands to the value of the environment variable `VAR`, or `default` if `VAR`
  is unset or null
- `${VAR-default}` - expands to the value of the environment variable `VAR`, or `default` if `VAR`
  is unset
- `${VAR?err_msg}` - expands to the value of the environment variable `VAR`, or prints `err_msg` and
  error if `VAR` unset
- ~~`${VAR:?err_msg}` - expands to the value of the environment variable `VAR`, or prints `err_msg`
  and error if `VAR` unset or null.~~ **THIS IS NOT SUPPORTED**

See
[mfridman/interpolate](https://github.com/mfridman/interpolate?tab=readme-ov-file#supported-expansions)
for more details on supported expansions.

&lt;/details&gt;

## Embedded sql migrations

Go 1.16 introduced new feature: [compile-time embedding](https://pkg.go.dev/embed/) files into
binary and corresponding [filesystem abstraction](https://pkg.go.dev/io/fs/).

This feature can be used only for applying existing migrations. Modifying operations such as `fix`
and `create` will continue to operate on OS filesystem even if using embedded files. This is
expected behaviour because `io/fs` interfaces allows read-only access.

Make sure to configure the correct SQL dialect, see [dialect.go](./dialect.go) for supported SQL
dialects.

Example usage, assuming that SQL migrations are placed in the `migrations` directory:

```go
package main

import (
    &quot;database/sql&quot;
    &quot;embed&quot;

    &quot;github.com/pressly/goose/v3&quot;
)

//go:embed migrations/*.sql
var embedMigrations embed.FS

func main() {
    var db *sql.DB
    // setup database

    goose.SetBaseFS(embedMigrations)

    if err := goose.SetDialect(&quot;postgres&quot;); err != nil {
        panic(err)
    }

    if err := goose.Up(db, &quot;migrations&quot;); err != nil {
        panic(err)
    }

    // run app
}
```

Note that we pass `&quot;migrations&quot;` as directory argument in `Up` because embedding saves directory
structure.

## Go Migrations

1. Create your own goose binary, see [example](./examples/go-migrations)
2. Import `github.com/pressly/goose`
3. Register your migration functions
4. Run goose command, ie. `goose.Up(db *sql.DB, dir string)`

A [sample Go migration 00002_users_add_email.go file](./examples/go-migrations/00002_rename_root.go)
looks like:

```go
package migrations

import (
	&quot;database/sql&quot;

	&quot;github.com/pressly/goose/v3&quot;
)

func init() {
	goose.AddMigration(Up, Down)
}

func Up(tx *sql.Tx) error {
	_, err := tx.Exec(&quot;UPDATE users SET username=&#039;admin&#039; WHERE username=&#039;root&#039;;&quot;)
	if err != nil {
		return err
	}
	return nil
}

func Down(tx *sql.Tx) error {
	_, err := tx.Exec(&quot;UPDATE users SET username=&#039;root&#039; WHERE username=&#039;admin&#039;;&quot;)
	if err != nil {
		return err
	}
	return nil
}
```

Note that Go migration files must begin with a numeric value, followed by an underscore, and must
not end with `*_test.go`.

# Hybrid Versioning

Please, read the [versioning
problem](https://github.com/pressly/goose/issues/63#issuecomment-428681694) first.

By default, if you attempt to apply missing (out-of-order) migrations `goose` will raise an error.
However, If you want to apply these missing migrations pass goose the `-allow-missing` flag, or if
using as a library supply the functional option `goose.WithAllowMissing()` to Up, UpTo or UpByOne.

However, we strongly recommend adopting a hybrid versioning approach, using both timestamps and
sequential numbers. Migrations created during the development process are timestamped and sequential
versions are ran on production. We believe this method will prevent the problem of conflicting
versions when writing software in a team environment.

To help you adopt this approach, `create` will use the current timestamp as the migration version.
When you&#039;re ready to deploy your migrations in a production environment, we also provide a helpful
`fix` command to convert your migrations into sequential order, while preserving the timestamp
ordering. We recommend running `fix` in the CI pipeline, and only when the migrations are ready for
production.

## Credit

The gopher mascot was designed by [Ren√©e French](https://reneefrench.blogspot.com/) / [CC
3.0.](https://creativecommons.org/licenses/by/3.0/) For more info check out the [Go
Blog](https://go.dev/blog/gopher). Adapted by Ellen.

## License

Licensed under [MIT License](./LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gohugoio/hugo]]></title>
            <link>https://github.com/gohugoio/hugo</link>
            <guid>https://github.com/gohugoio/hugo</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[The world‚Äôs fastest framework for building websites.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gohugoio/hugo">gohugoio/hugo</a></h1>
            <p>The world‚Äôs fastest framework for building websites.</p>
            <p>Language: Go</p>
            <p>Stars: 79,506</p>
            <p>Forks: 7,739</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>[bep]: https://github.com/bep
[bugs]: https://github.com/gohugoio/hugo/issues?q=is%3Aopen+is%3Aissue+label%3ABug
[contributing]: CONTRIBUTING.md
[create a proposal]: https://github.com/gohugoio/hugo/issues/new?labels=Proposal%2C+NeedsTriage&amp;template=feature_request.md
[documentation repository]: https://github.com/gohugoio/hugoDocs
[documentation]: https://gohugo.io/documentation
[dragonfly bsd, freebsd, netbsd, and openbsd]: https://gohugo.io/installation/bsd
[features]: https://gohugo.io/about/features/
[forum]: https://discourse.gohugo.io
[friends]: https://github.com/gohugoio/hugo/graphs/contributors
[go]: https://go.dev/
[hugo modules]: https://gohugo.io/hugo-modules/
[installation]: https://gohugo.io/installation
[issue queue]: https://github.com/gohugoio/hugo/issues
[linux]: https://gohugo.io/installation/linux
[macos]: https://gohugo.io/installation/macos
[prebuilt binary]: https://github.com/gohugoio/hugo/releases/latest
[requesting help]: https://discourse.gohugo.io/t/requesting-help/9132
[spf13]: https://github.com/spf13
[static site generator]: https://en.wikipedia.org/wiki/Static_site_generator
[support]: https://discourse.gohugo.io
[themes]: https://themes.gohugo.io/
[website]: https://gohugo.io
[windows]: https://gohugo.io/installation/windows

&lt;a href=&quot;https://gohugo.io/&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/gohugoio/gohugoioTheme/master/static/images/hugo-logo-wide.svg?sanitize=true&quot; alt=&quot;Hugo&quot; width=&quot;565&quot;&gt;&lt;/a&gt;

A fast and flexible static site generator built with love by [bep], [spf13], and [friends] in [Go].

---

[![GoDoc](https://godoc.org/github.com/gohugoio/hugo?status.svg)](https://godoc.org/github.com/gohugoio/hugo)
[![Tests on Linux, MacOS and Windows](https://github.com/gohugoio/hugo/workflows/Test/badge.svg)](https://github.com/gohugoio/hugo/actions?query=workflow%3ATest)
[![Go Report Card](https://goreportcard.com/badge/github.com/gohugoio/hugo)](https://goreportcard.com/report/github.com/gohugoio/hugo)

[Website] | [Installation] | [Documentation] | [Support] | [Contributing] | &lt;a rel=&quot;me&quot; href=&quot;https://fosstodon.org/@gohugoio&quot;&gt;Mastodon&lt;/a&gt;

## Overview

Hugo is a [static site generator] written in [Go], optimized for speed and designed for flexibility. With its advanced templating system and fast asset pipelines, Hugo renders a complete site in seconds, often less.

Due to its flexible framework, multilingual support, and powerful taxonomy system, Hugo is widely used to create:

- Corporate, government, nonprofit, education, news, event, and project sites
- Documentation sites
- Image portfolios
- Landing pages
- Business, professional, and personal blogs
- Resumes and CVs

Use Hugo&#039;s embedded web server during development to instantly see changes to content, structure, behavior, and presentation. Then deploy the site to your host, or push changes to your Git provider for automated builds and deployment.

Hugo&#039;s fast asset pipelines include:

- Image processing &amp;ndash; Convert, resize, crop, rotate, adjust colors, apply filters, overlay text and images, and extract EXIF data
- JavaScript bundling &amp;ndash; Transpile TypeScript and JSX to JavaScript, bundle, tree shake, minify, create source maps, and perform SRI hashing.
- Sass processing &amp;ndash; Transpile Sass to CSS, bundle, tree shake, minify, create source maps, perform SRI hashing, and integrate with PostCSS
- Tailwind CSS processing &amp;ndash; Compile Tailwind CSS utility classes into standard CSS, bundle, tree shake, optimize, minify, perform SRI hashing, and integrate with PostCSS

And with [Hugo Modules], you can share content, assets, data, translations, themes, templates, and configuration with other projects via public or private Git repositories.

See the [features] section of the documentation for a comprehensive summary of Hugo&#039;s capabilities.

## Sponsors

&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p float=&quot;left&quot;&gt;
  &lt;a href=&quot;https://www.linode.com/?utm_campaign=hugosponsor&amp;utm_medium=banner&amp;utm_source=hugogithub&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/gohugoio/gohugoioTheme/master/assets/images/sponsors/linode-logo_standard_light_medium.png&quot; width=&quot;200&quot; alt=&quot;Linode&quot;&gt;&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;
  &lt;a href=&quot;https://www.jetbrains.com/go/?utm_source=OSS&amp;utm_medium=referral&amp;utm_campaign=hugo&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/gohugoio/gohugoioTheme/master/assets/images/sponsors/goland.svg&quot; width=&quot;200&quot; alt=&quot;The complete IDE crafted for professional Go developers.&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

## Editions

Hugo is available in three editions: standard, extended, and extended/deploy. While the standard edition provides core functionality, the extended and extended/deploy editions offer advanced features.

Feature|extended edition|extended/deploy edition
:--|:-:|:-:
Encode to the WebP format when [processing images]. You can decode WebP images with any edition.|:heavy_check_mark:|:heavy_check_mark:
[Transpile Sass to CSS] using the embedded LibSass transpiler. You can use the [Dart Sass] transpiler with any edition.|:heavy_check_mark:|:heavy_check_mark:
Deploy your site directly to a Google Cloud Storage bucket, an AWS S3 bucket, or an Azure Storage container. See&amp;nbsp;[details].|:x:|:heavy_check_mark:

[dart sass]: https://gohugo.io/functions/css/sass/#dart-sass
[processing images]: https://gohugo.io/content-management/image-processing/
[transpile sass to css]: https://gohugo.io/functions/css/sass/
[details]: https://gohugo.io/hosting-and-deployment/hugo-deploy/

Unless your specific deployment needs require the extended/deploy edition, we recommend the extended edition.

## Installation

Install Hugo from a [prebuilt binary], package manager, or package repository. Please see the installation instructions for your operating system:

- [macOS]
- [Linux]
- [Windows]
- [DragonFly BSD, FreeBSD, NetBSD, and OpenBSD]

## Build from source

Prerequisites to build Hugo from source:

- Standard edition: Go 1.23.0 or later
- Extended edition: Go 1.23.0 or later, and GCC
- Extended/deploy edition: Go 1.23.0 or later, and GCC

Build the standard edition:

```text
go install github.com/gohugoio/hugo@latest
```

Build the extended edition:

```text
CGO_ENABLED=1 go install -tags extended github.com/gohugoio/hugo@latest
```

Build the extended/deploy edition:

```text
CGO_ENABLED=1 go install -tags extended,withdeploy github.com/gohugoio/hugo@latest
```

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=gohugoio/hugo&amp;type=Timeline)](https://star-history.com/#gohugoio/hugo&amp;Timeline)

## Documentation

Hugo&#039;s [documentation] includes installation instructions, a quick start guide, conceptual explanations, reference information, and examples.

Please submit documentation issues and pull requests to the [documentation repository].

## Support

Please **do not use the issue queue** for questions or troubleshooting. Unless you are certain that your issue is a software defect, use the [forum].

Hugo‚Äôs [forum] is an active community of users and developers who answer questions, share knowledge, and provide examples. A quick search of over 20,000 topics will often answer your question. Please be sure to read about [requesting help] before asking your first question.

## Contributing

You can contribute to the Hugo project by:

- Answering questions on the [forum]
- Improving the [documentation]
- Monitoring the [issue queue]
- Creating or improving [themes]
- Squashing [bugs]

Please submit documentation issues and pull requests to the [documentation repository].

If you have an idea for an enhancement or new feature, create a new topic on the [forum] in the &quot;Feature&quot; category. This will help you to:

- Determine if the capability already exists
- Measure interest
- Refine the concept

If there is sufficient interest, [create a proposal]. Do not submit a pull request until the project lead accepts the proposal.

For a complete guide to contributing to Hugo, see the [Contribution Guide](CONTRIBUTING.md).

## Dependencies

Hugo stands on the shoulders of great open source libraries. Run `hugo env --logLevel info` to display a list of dependencies.

&lt;details&gt;
&lt;summary&gt;See current dependencies&lt;/summary&gt;

```text
github.com/BurntSushi/locker=&quot;v0.0.0-20171006230638-a6e239ea1c69&quot;
github.com/PuerkitoBio/goquery=&quot;v1.10.1&quot;
github.com/alecthomas/chroma/v2=&quot;v2.15.0&quot;
github.com/andybalholm/cascadia=&quot;v1.3.3&quot;
github.com/armon/go-radix=&quot;v1.0.1-0.20221118154546-54df44f2176c&quot;
github.com/bep/clocks=&quot;v0.5.0&quot;
github.com/bep/debounce=&quot;v1.2.0&quot;
github.com/bep/gitmap=&quot;v1.6.0&quot;
github.com/bep/goat=&quot;v0.5.0&quot;
github.com/bep/godartsass/v2=&quot;v2.3.2&quot;
github.com/bep/golibsass=&quot;v1.2.0&quot;
github.com/bep/gowebp=&quot;v0.3.0&quot;
github.com/bep/imagemeta=&quot;v0.8.4&quot;
github.com/bep/lazycache=&quot;v0.7.0&quot;
github.com/bep/logg=&quot;v0.4.0&quot;
github.com/bep/mclib=&quot;v1.20400.20402&quot;
github.com/bep/overlayfs=&quot;v0.9.2&quot;
github.com/bep/simplecobra=&quot;v0.5.0&quot;
github.com/bep/tmc=&quot;v0.5.1&quot;
github.com/cespare/xxhash/v2=&quot;v2.3.0&quot;
github.com/clbanning/mxj/v2=&quot;v2.7.0&quot;
github.com/cpuguy83/go-md2man/v2=&quot;v2.0.4&quot;
github.com/disintegration/gift=&quot;v1.2.1&quot;
github.com/dlclark/regexp2=&quot;v1.11.5&quot;
github.com/dop251/goja=&quot;v0.0.0-20250125213203-5ef83b82af17&quot;
github.com/evanw/esbuild=&quot;v0.24.2&quot;
github.com/fatih/color=&quot;v1.18.0&quot;
github.com/frankban/quicktest=&quot;v1.14.6&quot;
github.com/fsnotify/fsnotify=&quot;v1.8.0&quot;
github.com/getkin/kin-openapi=&quot;v0.129.0&quot;
github.com/ghodss/yaml=&quot;v1.0.0&quot;
github.com/go-openapi/jsonpointer=&quot;v0.21.0&quot;
github.com/go-openapi/swag=&quot;v0.23.0&quot;
github.com/go-sourcemap/sourcemap=&quot;v2.1.4+incompatible&quot;
github.com/gobuffalo/flect=&quot;v1.0.3&quot;
github.com/gobwas/glob=&quot;v0.2.3&quot;
github.com/gohugoio/go-i18n/v2=&quot;v2.1.3-0.20230805085216-e63c13218d0e&quot;
github.com/gohugoio/hashstructure=&quot;v0.5.0&quot;
github.com/gohugoio/httpcache=&quot;v0.7.0&quot;
github.com/gohugoio/hugo-goldmark-extensions/extras=&quot;v0.2.0&quot;
github.com/gohugoio/hugo-goldmark-extensions/passthrough=&quot;v0.3.0&quot;
github.com/gohugoio/locales=&quot;v0.14.0&quot;
github.com/gohugoio/localescompressed=&quot;v1.0.1&quot;
github.com/golang/freetype=&quot;v0.0.0-20170609003504-e2365dfdc4a0&quot;
github.com/google/go-cmp=&quot;v0.6.0&quot;
github.com/google/pprof=&quot;v0.0.0-20250208200701-d0013a598941&quot;
github.com/gorilla/websocket=&quot;v1.5.3&quot;
github.com/hairyhenderson/go-codeowners=&quot;v0.7.0&quot;
github.com/hashicorp/golang-lru/v2=&quot;v2.0.7&quot;
github.com/jdkato/prose=&quot;v1.2.1&quot;
github.com/josharian/intern=&quot;v1.0.0&quot;
github.com/kr/pretty=&quot;v0.3.1&quot;
github.com/kr/text=&quot;v0.2.0&quot;
github.com/kyokomi/emoji/v2=&quot;v2.2.13&quot;
github.com/lucasb-eyer/go-colorful=&quot;v1.2.0&quot;
github.com/mailru/easyjson=&quot;v0.7.7&quot;
github.com/makeworld-the-better-one/dither/v2=&quot;v2.4.0&quot;
github.com/marekm4/color-extractor=&quot;v1.2.1&quot;
github.com/mattn/go-colorable=&quot;v0.1.13&quot;
github.com/mattn/go-isatty=&quot;v0.0.20&quot;
github.com/mattn/go-runewidth=&quot;v0.0.9&quot;
github.com/mazznoer/csscolorparser=&quot;v0.1.5&quot;
github.com/mitchellh/mapstructure=&quot;v1.5.1-0.20231216201459-8508981c8b6c&quot;
github.com/mohae/deepcopy=&quot;v0.0.0-20170929034955-c48cc78d4826&quot;
github.com/muesli/smartcrop=&quot;v0.3.0&quot;
github.com/niklasfasching/go-org=&quot;v1.7.0&quot;
github.com/oasdiff/yaml3=&quot;v0.0.0-20241210130736-a94c01f36349&quot;
github.com/oasdiff/yaml=&quot;v0.0.0-20241210131133-6b86fb107d80&quot;
github.com/olekukonko/tablewriter=&quot;v0.0.5&quot;
github.com/pbnjay/memory=&quot;v0.0.0-20210728143218-7b4eea64cf58&quot;
github.com/pelletier/go-toml/v2=&quot;v2.2.3&quot;
github.com/perimeterx/marshmallow=&quot;v1.1.5&quot;
github.com/pkg/browser=&quot;v0.0.0-20240102092130-5ac0b6a4141c&quot;
github.com/pkg/errors=&quot;v0.9.1&quot;
github.com/rivo/uniseg=&quot;v0.4.7&quot;
github.com/rogpeppe/go-internal=&quot;v1.13.1&quot;
github.com/russross/blackfriday/v2=&quot;v2.1.0&quot;
github.com/sass/libsass=&quot;3.6.6&quot;
github.com/spf13/afero=&quot;v1.11.0&quot;
github.com/spf13/cast=&quot;v1.7.1&quot;
github.com/spf13/cobra=&quot;v1.8.1&quot;
github.com/spf13/fsync=&quot;v0.10.1&quot;
github.com/spf13/pflag=&quot;v1.0.6&quot;
github.com/tdewolff/minify/v2=&quot;v2.20.37&quot;
github.com/tdewolff/parse/v2=&quot;v2.7.15&quot;
github.com/tetratelabs/wazero=&quot;v1.8.2&quot;
github.com/webmproject/libwebp=&quot;v1.3.2&quot;
github.com/yuin/goldmark-emoji=&quot;v1.0.4&quot;
github.com/yuin/goldmark=&quot;v1.7.8&quot;
go.uber.org/automaxprocs=&quot;v1.5.3&quot;
golang.org/x/crypto=&quot;v0.33.0&quot;
golang.org/x/exp=&quot;v0.0.0-20250210185358-939b2ce775ac&quot;
golang.org/x/image=&quot;v0.24.0&quot;
golang.org/x/mod=&quot;v0.23.0&quot;
golang.org/x/net=&quot;v0.35.0&quot;
golang.org/x/sync=&quot;v0.11.0&quot;
golang.org/x/sys=&quot;v0.30.0&quot;
golang.org/x/text=&quot;v0.22.0&quot;
golang.org/x/tools=&quot;v0.30.0&quot;
golang.org/x/xerrors=&quot;v0.0.0-20240903120638-7835f813f4da&quot;
gonum.org/v1/plot=&quot;v0.15.0&quot;
google.golang.org/protobuf=&quot;v1.36.5&quot;
gopkg.in/yaml.v2=&quot;v2.4.0&quot;
gopkg.in/yaml.v3=&quot;v3.0.1&quot;
oss.terrastruct.com/d2=&quot;v0.6.9&quot;
oss.terrastruct.com/util-go=&quot;v0.0.0-20241005222610-44c011a04896&quot;
rsc.io/qr=&quot;v0.2.0&quot;
software.sslmate.com/src/go-pkcs12=&quot;v0.2.0&quot;
```
&lt;/details&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gitleaks/gitleaks]]></title>
            <link>https://github.com/gitleaks/gitleaks</link>
            <guid>https://github.com/gitleaks/gitleaks</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[Find secrets with Gitleaks üîë]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gitleaks/gitleaks">gitleaks/gitleaks</a></h1>
            <p>Find secrets with Gitleaks üîë</p>
            <p>Language: Go</p>
            <p>Stars: 19,526</p>
            <p>Forks: 1,586</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># Gitleaks

```
‚îå‚îÄ‚óã‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚îÇ‚ï≤  ‚îÇ
‚îÇ ‚îÇ ‚óã ‚îÇ
‚îÇ ‚óã ‚ñë ‚îÇ
‚îî‚îÄ‚ñë‚îÄ‚îÄ‚îÄ‚îò
```

[license]: ./LICENSE
[badge-license]: https://img.shields.io/github/license/gitleaks/gitleaks.svg
[go-docs-badge]: https://pkg.go.dev/badge/github.com/gitleaks/gitleaks/v8?status
[go-docs]: https://pkg.go.dev/github.com/zricethezav/gitleaks/v8
[badge-build]: https://github.com/gitleaks/gitleaks/actions/workflows/test.yml/badge.svg
[build]: https://github.com/gitleaks/gitleaks/actions/workflows/test.yml
[go-report-card-badge]: https://goreportcard.com/badge/github.com/gitleaks/gitleaks/v8
[go-report-card]: https://goreportcard.com/report/github.com/gitleaks/gitleaks/v8
[dockerhub]: https://hub.docker.com/r/zricethezav/gitleaks
[dockerhub-badge]: https://img.shields.io/docker/pulls/zricethezav/gitleaks.svg
[gitleaks-action]: https://github.com/gitleaks/gitleaks-action
[gitleaks-badge]: https://img.shields.io/badge/protected%20by-gitleaks-blue
[gitleaks-playground-badge]: https://img.shields.io/badge/gitleaks%20-playground-blue
[gitleaks-playground]: https://gitleaks.io/playground


[![Github Action Test][badge-build]][build]
[![Docker Hub][dockerhub-badge]][dockerhub]
[![Gitleaks Playground][gitleaks-playground-badge]][gitleaks-playground]
[![Gitleaks Action][gitleaks-badge]][gitleaks-action]
[![GoDoc][go-docs-badge]][go-docs]
[![GoReportCard][go-report-card-badge]][go-report-card]
[![License][badge-license]][license]


### Join our Discord! [![Discord](https://img.shields.io/discord/1102689410522284044.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/8Hzbrnkr7E)

Gitleaks is a tool for **detecting** secrets like passwords, API keys, and tokens in git repos, files, and whatever else you wanna throw at it via `stdin`.

```
‚ûú  ~/code(master) gitleaks git -v

    ‚óã
    ‚îÇ‚ï≤
    ‚îÇ ‚óã
    ‚óã ‚ñë
    ‚ñë    gitleaks


Finding:     &quot;export BUNDLE_ENTERPRISE__CONTRIBSYS__COM=cafebabe:deadbeef&quot;,
Secret:      cafebabe:deadbeef
RuleID:      sidekiq-secret
Entropy:     2.609850
File:        cmd/generate/config/rules/sidekiq.go
Line:        23
Commit:      cd5226711335c68be1e720b318b7bc3135a30eb2
Author:      John
Email:       john@users.noreply.github.com
Date:        2022-08-03T12:31:40Z
Fingerprint: cd5226711335c68be1e720b318b7bc3135a30eb2:cmd/generate/config/rules/sidekiq.go:sidekiq-secret:23
```

## Getting Started

Gitleaks can be installed using Homebrew, Docker, or Go. Gitleaks is also available in binary form for many popular platforms and OS types on the [releases page](https://github.com/gitleaks/gitleaks/releases). In addition, Gitleaks can be implemented as a pre-commit hook directly in your repo or as a GitHub action using [Gitleaks-Action](https://github.com/gitleaks/gitleaks-action).

### Installing

```bash
# MacOS
brew install gitleaks

# Docker (DockerHub)
docker pull zricethezav/gitleaks:latest
docker run -v ${path_to_host_folder_to_scan}:/path zricethezav/gitleaks:latest [COMMAND] [OPTIONS] [SOURCE_PATH]

# Docker (ghcr.io)
docker pull ghcr.io/gitleaks/gitleaks:latest
docker run -v ${path_to_host_folder_to_scan}:/path ghcr.io/gitleaks/gitleaks:latest [COMMAND] [OPTIONS] [SOURCE_PATH]

# From Source (make sure `go` is installed)
git clone https://github.com/gitleaks/gitleaks.git
cd gitleaks
make build
```

### GitHub Action

Check out the official [Gitleaks GitHub Action](https://github.com/gitleaks/gitleaks-action)

```
name: gitleaks
on: [pull_request, push, workflow_dispatch]
jobs:
  scan:
    name: gitleaks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
      - uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE}} # Only required for Organizations, not personal accounts.
```

### Pre-Commit

1. Install pre-commit from https://pre-commit.com/#install
2. Create a `.pre-commit-config.yaml` file at the root of your repository with the following content:

   ```
   repos:
     - repo: https://github.com/gitleaks/gitleaks
       rev: v8.24.2
       hooks:
         - id: gitleaks
   ```

   for a [native execution of GitLeaks](https://github.com/gitleaks/gitleaks/releases) or use the [`gitleaks-docker` pre-commit ID](https://github.com/gitleaks/gitleaks/blob/master/.pre-commit-hooks.yaml) for executing GitLeaks using the [official Docker images](#docker)

3. Auto-update the config to the latest repos&#039; versions by executing `pre-commit autoupdate`
4. Install with `pre-commit install`
5. Now you&#039;re all set!

```
‚ûú git commit -m &quot;this commit contains a secret&quot;
Detect hardcoded secrets.................................................Failed
```

Note: to disable the gitleaks pre-commit hook you can prepend `SKIP=gitleaks` to the commit command
and it will skip running gitleaks

```
‚ûú SKIP=gitleaks git commit -m &quot;skip gitleaks check&quot;
Detect hardcoded secrets................................................Skipped
```

## Usage

```
Usage:
  gitleaks [command]

Available Commands:
  completion  generate the autocompletion script for the specified shell
  dir         scan directories or files for secrets
  git         scan git repositories for secrets
  help        Help about any command
  stdin       detect secrets from stdin
  version     display gitleaks version

Flags:
  -b, --baseline-path string          path to baseline with issues that can be ignored
  -c, --config string                 config file path
                                      order of precedence:
                                      1. --config/-c
                                      2. env var GITLEAKS_CONFIG
                                      3. env var GITLEAKS_CONFIG_TOML with the file content
                                      4. (target path)/.gitleaks.toml
                                      If none of the four options are used, then gitleaks will use the default config
      --enable-rule strings           only enable specific rules by id
      --exit-code int                 exit code when leaks have been encountered (default 1)
  -i, --gitleaks-ignore-path string   path to .gitleaksignore file or folder containing one (default &quot;.&quot;)
  -h, --help                          help for gitleaks
      --ignore-gitleaks-allow         ignore gitleaks:allow comments
  -l, --log-level string              log level (trace, debug, info, warn, error, fatal) (default &quot;info&quot;)
      --max-decode-depth int          allow recursive decoding up to this depth (default &quot;0&quot;, no decoding is done)
      --max-target-megabytes int      files larger than this will be skipped
      --no-banner                     suppress banner
      --no-color                      turn off color for verbose output
      --redact uint[=100]             redact secrets from logs and stdout. To redact only parts of the secret just apply a percent value from 0..100. For example --redact=20 (default 100%)
  -f, --report-format string          output format (json, csv, junit, sarif) (default &quot;json&quot;)
  -r, --report-path string            report file
      --report-template string        template file used to generate the report (implies --report-format=template)
  -v, --verbose                       show verbose output from scan
      --version                       version for gitleaks

Use &quot;gitleaks [command] --help&quot; for more information about a command.
```

### Commands

‚ö†Ô∏è v8.19.0 introduced a change that deprecated `detect` and `protect`. Those commands are still available but
are hidden in the `--help` menu. Take a look at this [gist](https://gist.github.com/zricethezav/b325bb93ebf41b9c0b0507acf12810d2) for easy command translations.
If you find v8.19.0 broke an existing command (`detect`/`protect`), please open an issue.

There are three scanning modes: `git`, `dir`, and `stdin`.

#### Git
The `git` command lets you scan local git repos. Under the hood, gitleaks uses the `git log -p` command to scan patches.
You can configure the behavior of `git log -p` with the `log-opts` option.
For example, if you wanted to run gitleaks on a range of commits you could use the following
command: `gitleaks git -v --log-opts=&quot;--all commitA..commitB&quot; path_to_repo`. See the [git log](https://git-scm.com/docs/git-log) documentation for more information.
If there is no target specified as a positional argument, then gitleaks will attempt to scan the current working directory as a git repo.

#### Dir
The `dir` (aliases include `files`, `directory`) command lets you scan directories and files. Example: `gitleaks dir -v path_to_directory_or_file`.
If there is no target specified as a positional argument, then gitleaks will scan the current working directory.

#### Stdin
You can also stream data to gitleaks with the `stdin` command. Example: `cat some_file | gitleaks -v stdin`

### Creating a baseline

When scanning large repositories or repositories with a long history, it can be convenient to use a baseline. When using a baseline,
gitleaks will ignore any old findings that are present in the baseline. A baseline can be any gitleaks report. To create a gitleaks report, run gitleaks with the `--report-path` parameter.

```
gitleaks git --report-path gitleaks-report.json # This will save the report in a file called gitleaks-report.json
```

Once as baseline is created it can be applied when running the detect command again:

```
gitleaks git --baseline-path gitleaks-report.json --report-path findings.json
```

After running the detect command with the --baseline-path parameter, report output (findings.json) will only contain new issues.

## Pre-Commit hook

You can run Gitleaks as a pre-commit hook by copying the example `pre-commit.py` script into
your `.git/hooks/` directory.

## Load Configuration

The order of precedence is:

1. `--config/-c` option:
      ```bash
      gitleaks git --config /home/dev/customgitleaks.toml .
      ```
2. Environment variable `GITLEAKS_CONFIG` with the file path:
      ```bash
      export GITLEAKS_CONFIG=&quot;/home/dev/customgitleaks.toml&quot;
      gitleaks git .
      ```
3. Environment variable `GITLEAKS_CONFIG_TOML` with the file content:
      ```bash
      export GITLEAKS_CONFIG_TOML=`cat customgitleaks.toml`
      gitleaks git .
      ```
4. A `.gitleaks.toml` file within the target path:
      ```bash
      gitleaks git .
      ```

If none of the four options are used, then gitleaks will use the default config.

## Configuration

Gitleaks offers a configuration format you can follow to write your own secret detection rules:

```toml
# Title for the gitleaks configuration file.
title = &quot;Custom Gitleaks configuration&quot;

# You have basically two options for your custom configuration:
#
# 1. define your own configuration, default rules do not apply
#
#    use e.g., the default configuration as starting point:
#    https://github.com/gitleaks/gitleaks/blob/master/config/gitleaks.toml
#
# 2. extend a configuration, the rules are overwritten or extended
#
#    When you extend a configuration the extended rules take precedence over the
#    default rules. I.e., if there are duplicate rules in both the extended
#    configuration and the default configuration the extended rules or
#    attributes of them will override the default rules.
#    Another thing to know with extending configurations is you can chain
#    together multiple configuration files to a depth of 2. Allowlist arrays are
#    appended and can contain duplicates.

# useDefault and path can NOT be used at the same time. Choose one.
[extend]
# useDefault will extend the default gitleaks config built in to the binary
# the latest version is located at:
# https://github.com/gitleaks/gitleaks/blob/master/config/gitleaks.toml
useDefault = true
# or you can provide a path to a configuration to extend from.
# The path is relative to where gitleaks was invoked,
# not the location of the base config.
# path = &quot;common_config.toml&quot;
# If there are any rules you don&#039;t want to inherit, they can be specified here.
disabledRules = [ &quot;generic-api-key&quot;]

# An array of tables that contain information that define instructions
# on how to detect secrets
[[rules]]

# Unique identifier for this rule
id = &quot;awesome-rule-1&quot;

# Short human readable description of the rule.
description = &quot;awesome rule 1&quot;

# Golang regular expression used to detect secrets. Note Golang&#039;s regex engine
# does not support lookaheads.
regex = &#039;&#039;&#039;one-go-style-regex-for-this-rule&#039;&#039;&#039;

# Int used to extract secret from regex match and used as the group that will have
# its entropy checked if `entropy` is set.
secretGroup = 3

# Float representing the minimum shannon entropy a regex group must have to be considered a secret.
entropy = 3.5

# Golang regular expression used to match paths. This can be used as a standalone rule or it can be used
# in conjunction with a valid `regex` entry.
path = &#039;&#039;&#039;a-file-path-regex&#039;&#039;&#039;

# Keywords are used for pre-regex check filtering. Rules that contain
# keywords will perform a quick string compare check to make sure the
# keyword(s) are in the content being scanned. Ideally these values should
# either be part of the identiifer or unique strings specific to the rule&#039;s regex
# (introduced in v8.6.0)
keywords = [
  &quot;auth&quot;,
  &quot;password&quot;,
  &quot;token&quot;,
]

# Array of strings used for metadata and reporting purposes.
tags = [&quot;tag&quot;,&quot;another tag&quot;]

    # ‚ö†Ô∏è In v8.21.0 `[rules.allowlist]` was replaced with `[[rules.allowlists]]`.
    # This change was backwards-compatible: instances of `[rules.allowlist]` still  work.
    #
    # You can define multiple allowlists for a rule to reduce false positives.
    # A finding will be ignored if _ANY_ `[[rules.allowlists]]` matches.
    [[rules.allowlists]]
    description = &quot;ignore commit A&quot;
    # When multiple criteria are defined the default condition is &quot;OR&quot;.
    # e.g., this can match on |commits| OR |paths| OR |stopwords|.
    condition = &quot;OR&quot;
    commits = [ &quot;commit-A&quot;, &quot;commit-B&quot;]
    paths = [
      &#039;&#039;&#039;go\.mod&#039;&#039;&#039;,
      &#039;&#039;&#039;go\.sum&#039;&#039;&#039;
    ]
    # note: stopwords targets the extracted secret, not the entire regex match
    # like &#039;regexes&#039; does. (stopwords introduced in 8.8.0)
    stopwords = [
      &#039;&#039;&#039;client&#039;&#039;&#039;,
      &#039;&#039;&#039;endpoint&#039;&#039;&#039;,
    ]

    [[rules.allowlists]]
    # The &quot;AND&quot; condition can be used to make sure all criteria match.
    # e.g., this matches if |regexes| AND |paths| are satisfied.
    condition = &quot;AND&quot;
    # note: |regexes| defaults to check the _Secret_ in the finding.
    # Acceptable values for |regexTarget| are &quot;secret&quot; (default), &quot;match&quot;, and &quot;line&quot;.
    regexTarget = &quot;match&quot;
    regexes = [ &#039;&#039;&#039;(?i)parseur[il]&#039;&#039;&#039; ]
    paths = [ &#039;&#039;&#039;package-lock\.json&#039;&#039;&#039; ]

# You can extend a particular rule from the default config. e.g., gitlab-pat
# if you have defined a custom token prefix on your GitLab instance
[[rules]]
id = &quot;gitlab-pat&quot;
# all the other attributes from the default rule are inherited

    [[rules.allowlists]]
    regexTarget = &quot;line&quot;
    regexes = [ &#039;&#039;&#039;MY-glpat-&#039;&#039;&#039; ]

# This is a global allowlist which has a higher order of precedence than rule-specific allowlists.
# If a commit listed in the `commits` field below is encountered then that commit will be skipped and no
# secrets will be detected for said commit. The same logic applies for regexes and paths.
[allowlist]
description = &quot;global allow list&quot;
commits = [ &quot;commit-A&quot;, &quot;commit-B&quot;, &quot;commit-C&quot;]
paths = [
  &#039;&#039;&#039;gitleaks\.toml&#039;&#039;&#039;,
  &#039;&#039;&#039;(.*?)(jpg|gif|doc)&#039;&#039;&#039;
]

# note: (global) regexTarget defaults to check the _Secret_ in the finding.
# if regexTarget is not specified then _Secret_ will be used.
# Acceptable values for regexTarget are &quot;match&quot; and &quot;line&quot;
regexTarget = &quot;match&quot;
regexes = [
  &#039;&#039;&#039;219-09-9999&#039;&#039;&#039;,
  &#039;&#039;&#039;078-05-1120&#039;&#039;&#039;,
  &#039;&#039;&#039;(9[0-9]{2}|666)-\d{2}-\d{4}&#039;&#039;&#039;,
]
# note: stopwords targets the extracted secret, not the entire regex match
# like &#039;regexes&#039; does. (stopwords introduced in 8.8.0)
stopwords = [
  &#039;&#039;&#039;client&#039;&#039;&#039;,
  &#039;&#039;&#039;endpoint&#039;&#039;&#039;,
]
```

Refer to the default [gitleaks config](https://github.com/gitleaks/gitleaks/blob/master/config/gitleaks.toml) for examples or follow the [contributing guidelines](https://github.com/gitleaks/gitleaks/blob/master/CONTRIBUTING.md) if you would like to contribute to the default configuration. Additionally, you can check out [this gitleaks blog post](https://blog.gitleaks.io/stop-leaking-secrets-configuration-2-3-aeed293b1fbf) which covers advanced configuration setups.

### Additional Configuration

#### gitleaks:allow

If you are knowingly committing a test secret that gitleaks will catch you can add a `gitleaks:allow` comment to that line which will instruct gitleaks
to ignore that secret. Ex:

```
class CustomClass:
    discord_client_secret = &#039;8dyfuiRyq=vVc3RRr_edRk-fK__JItpZ&#039;  #gitleaks:allow

```

#### .gitleaksignore

You can ignore specific findings by creating a `.gitleaksignore` file at the root of your repo. In release v8.10.0 Gitleaks added a `Fingerprint` value to the Gitleaks report. Each leak, or finding, has a Fingerprint that uniquely identifies a secret. Add this fingerprint to the `.gitleaksignore` file to ignore that specific secret. See Gitleaks&#039; [.gitleaksignore](https://github.com/gitleaks/gitleaks/blob/master/.gitleaksignore) for an example. Note: this feature is experimental and is subject to change in the future.

#### Decoding

Sometimes secrets are encoded in a way that can make them difficult to find
with just regex. Now you can tell gitleaks to automatically find and decode
encoded text. The flag `--max-decode-depth` enables this feature (the default
value &quot;0&quot; means the feature is disabled by default).

Recursive decoding is supported since decoded text can also contain encoded
text.  The flag `--max-decode-depth` sets the recursion limit. Recursion stops
when there are no new segments of encoded text to decode, so setting a really
high max depth doesn&#039;t mean it will make that many passes. It will only make as
many as it needs to decode the text. Overall, decoding only minimally increases
scan times.

The findings for encoded text differ from normal findings in the following
ways:

- The location points the bounds of the encoded text
  - If the rule matches outside the encoded text, the bounds are adjusted to
    include that as well
- The match and secret contain the decoded value
- Two tags are added `decoded:&lt;encoding&gt;` and `decode-depth:&lt;depth&gt;`

Currently supported encodings:

- `base64` (both standard and base64url)

#### Reporting

Gitleaks has built-in support for several report formats: [`json`](https://github.com/gitleaks/gitleaks/blob/master/testdata/expected/report/json_simple.json), [`csv`](https://github.com/gitleaks/gitleaks/blob/master/testdata/expected/report/csv_simple.csv?plain=1), [`junit`](https://github.com/gitleaks/gitleaks/blob/master/testdata/expected/report/junit_simple.xml), and [`sarif`](https://github.com/gitleaks/gitleaks/blob/master/testdata/expected/report/sarif_simple.sarif).

If none of these formats fit your need, you can create your own report format with a [Go `text/template` .tmpl file](https://www.digitalocean.com/community/tutorials/how-to-use-templates-in-go#step-4-writing-a-template) and the `--report-template` flag. The template can use [extended functionality from the `Masterminds/sprig` template library](https://masterminds.github.io/sprig/).

For example, the following template provides a custom JSON output:
```gotemplate
# jsonextra.tmpl
[{{ $lastFinding := (sub (len . ) 1) }}
{{- range $i, $finding := . }}{{with $finding}}
    {
        &quot;Description&quot;: {{ quote .Description }},
        &quot;StartLine&quot;: {{ .StartLine }},
        &quot;EndLine&quot;: {{ .EndLine }},
        &quot;StartColumn&quot;: {{ .StartColumn }},
        &quot;EndColumn&quot;: {{ .EndColumn }},
        &quot;Line&quot;: {{ quote .Line }},
        &quot;Match&quot;: {{ quote .Match }},
        &quot;Secret&quot;: {{ quote .Secret }},
        &quot;File&quot;: &quot;{{ .File }}&quot;,
        &quot;SymlinkFile&quot;: {{ quote .SymlinkFile }},
        &quot;Commit&quot;: {{ quote .Commit }},
        &quot;Entropy&quot;: {{ .Entropy }},
        &quot;Author&quot;: {{ quote .Author }},
  

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Azure/azure-sdk-for-go]]></title>
            <link>https://github.com/Azure/azure-sdk-for-go</link>
            <guid>https://github.com/Azure/azure-sdk-for-go</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[This repository is for active development of the Azure SDK for Go. For consumers of the SDK we recommend visiting our public developer docs at:]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Azure/azure-sdk-for-go">Azure/azure-sdk-for-go</a></h1>
            <p>This repository is for active development of the Azure SDK for Go. For consumers of the SDK we recommend visiting our public developer docs at:</p>
            <p>Language: Go</p>
            <p>Stars: 1,711</p>
            <p>Forks: 898</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># Azure SDK for Go

[![godoc](https://godoc.org/github.com/Azure/azure-sdk-for-go?status.svg)](https://godoc.org/github.com/Azure/azure-sdk-for-go)

This repository is for active development of the Azure SDK for Go. For consumers of the SDK you can follow the links below to visit the documentation you are interested in
* [Overview of Azure SDK for Go](https://docs.microsoft.com/azure/developer/go/)
* [SDK Reference](https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk)
* [Code Samples for Azure Go SDK](https://github.com/azure-samples/azure-sdk-for-go-samples)
* [Azure REST API Docs](https://docs.microsoft.com/rest/api/)
* [General Azure Docs](https://docs.microsoft.com/azure)
* [Share your feedback to our Azure SDK](https://www.surveymonkey.com/r/FWPGFGG)

## Getting Started

To get started with a module, see the README.md file located in the module&#039;s project folder.  You can find these module folders grouped by service in the `/sdk` directory.

&lt;a id=&quot;go-version-support&quot;&gt;&lt;/a&gt;
&gt; [!IMPORTANT]
&gt; Our libraries are compatible with the two most recent major Go releases, the same [policy](https://go.dev/doc/devel/release#policy) the Go programming language follows.

&gt; [!IMPORTANT]
&gt; Projects are highly encouraged to use the latest version of Go. This ensures your product has all the latest security fixes and is included in [Go&#039;s support lifecycle](https://go.dev/doc/devel/release).

&gt; [!WARNING]
&gt; The [root azure-sdk-for-go Go module](https://godoc.org/github.com/Azure/azure-sdk-for-go) which contains subpaths of `/services/**/mgmt/**` (also known as track 1) is [deprecated and no longer recieving support](https://azure.github.io/azure-sdk/releases/deprecated/go.html). See [the migration guide](https://github.com/Azure/azure-sdk-for-go/blob/main/documentation/MIGRATION_GUIDE.md) to learn how to migrate to the current version.

## Packages available

Each service can have both &#039;client&#039; and &#039;management&#039; modules. &#039;Client&#039; modules are used to consume the service, whereas &#039;management&#039; modules are used to configure and manage the service.

### Client modules

Our client modules follow the [Azure Go SDK guidelines](https://azure.github.io/azure-sdk/golang_introduction.html). These modules allow you to use, consume, and interact with existing resources, for example, uploading a blob. They also share a number of core functionalities including retries, logging, transport protocols, authentication protocols, etc. that can be found in the [azcore](https://github.com/Azure/azure-sdk-for-go/blob/main/sdk/azcore) module.

You can find the most up-to-date list of new modules on our [latest page](https://azure.github.io/azure-sdk/releases/latest/index.html#go).

&gt; [!NOTE]
&gt; If you need to ensure your code is ready for production use one of the stable, non-beta modules.

### Management modules
Similar to our client modules, the management modules follow the [Azure Go SDK guidelines](https://azure.github.io/azure-sdk/golang_introduction.html). All management modules are available at `sdk/resourcemanager`. These modules provide a number of core capabilities that are shared amongst all Azure SDKs, including the intuitive Azure Identity module, an HTTP Pipeline with custom policies, error-handling, distributed tracing, and much more.

To get started, please follow the [quickstart guide here](https://aka.ms/azsdk/go/mgmt). To see the benefits of migrating and how to migrate to the new modules, please visit the [migration guide](https://aka.ms/azsdk/go/mgmt/migration).

You can find the [most up to date list of all of the new packages on our page](https://azure.github.io/azure-sdk/releases/latest/mgmt/go.html)

&gt; [!NOTE]
&gt; If you need to ensure your code is ready for production use one of the stable, non-beta modules. Also, if you are experiencing authentication issues with the management modules after upgrading certain packages, it&#039;s possible that you upgraded to the new versions of SDK without changing the authentication code. Please refer to the migration guide for proper instructions.

* [Quickstart tutorial for new releases](https://aka.ms/azsdk/go/mgmt). Documentation is also available at each readme file of the individual module (Example: [Readme for Compute Module](https://github.com/Azure/azure-sdk-for-go/tree/main/sdk/resourcemanager/compute/armcompute))

## Samples

More code samples for using the management modules for Go SDK can be found in the following locations
- [Go SDK Code Samples Repo](https://aka.ms/azsdk/go/mgmt/samples)
- Example files under each package. For example, examples for Network packages can be [found here](https://github.com/Azure/azure-sdk-for-go/blob/main/sdk/resourcemanager/network/armnetwork/loadbalancernetworkinterfaces_client_example_test.go)

## Historical releases

Note that the latest modules from Microsoft are grouped by service in the `/sdk` directory. If you&#039;re using packages with prefix `github.com/Azure/azure-sdk-for-go/services`, `github.com/Azure/azure-sdk-for-go/storage`, `github.com/Azure/azure-sdk-for-go/profiles`, please consider migrating to the latest modules. You can find a mapping table from these historical releases to their equivalent [here](https://azure.github.io/azure-sdk/releases/deprecated/index.html#go). 

## Reporting security issues and security bugs

Security issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) &lt;secure@microsoft.com&gt;. You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the MSRC PGP key, can be found in the [Security TechCenter](https://www.microsoft.com/msrc/faqs-report-an-issue).

## Need help?

* File an issue via [Github Issues](https://github.com/Azure/azure-sdk-for-go/issues)
* Check [previous questions](https://stackoverflow.com/questions/tagged/azure+go) or ask new ones on StackOverflow using `azure` and `go` tags.

## Community

* Chat with us in the **[#Azure SDK
channel](https://gophers.slack.com/messages/CA7HK8EEP)** on the [Gophers
Slack](https://gophers.slack.com/). Sign up
[here](https://invite.slack.golangbridge.org) first if necessary.

## Contribute

See [CONTRIBUTING.md](https://github.com/Azure/azure-sdk-for-go/blob/main/CONTRIBUTING.md).

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow [Microsoft&#039;s Trademark &amp; Brand Guidelines](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general). Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#039;s policies.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[golang-migrate/migrate]]></title>
            <link>https://github.com/golang-migrate/migrate</link>
            <guid>https://github.com/golang-migrate/migrate</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[Database migrations. CLI and Golang library.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/golang-migrate/migrate">golang-migrate/migrate</a></h1>
            <p>Database migrations. CLI and Golang library.</p>
            <p>Language: Go</p>
            <p>Stars: 16,454</p>
            <p>Forks: 1,461</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>[![GitHub Workflow Status (branch)](https://img.shields.io/github/actions/workflow/status/golang-migrate/migrate/ci.yaml?branch=master)](https://github.com/golang-migrate/migrate/actions/workflows/ci.yaml?query=branch%3Amaster)
[![GoDoc](https://pkg.go.dev/badge/github.com/golang-migrate/migrate)](https://pkg.go.dev/github.com/golang-migrate/migrate/v4)
[![Coverage Status](https://img.shields.io/coveralls/github/golang-migrate/migrate/master.svg)](https://coveralls.io/github/golang-migrate/migrate?branch=master)
[![packagecloud.io](https://img.shields.io/badge/deb-packagecloud.io-844fec.svg)](https://packagecloud.io/golang-migrate/migrate?filter=debs)
[![Docker Pulls](https://img.shields.io/docker/pulls/migrate/migrate.svg)](https://hub.docker.com/r/migrate/migrate/)
![Supported Go Versions](https://img.shields.io/badge/Go-1.22%2C%201.23-lightgrey.svg)
[![GitHub Release](https://img.shields.io/github/release/golang-migrate/migrate.svg)](https://github.com/golang-migrate/migrate/releases)
[![Go Report Card](https://goreportcard.com/badge/github.com/golang-migrate/migrate/v4)](https://goreportcard.com/report/github.com/golang-migrate/migrate/v4)

# migrate

__Database migrations written in Go. Use as [CLI](#cli-usage) or import as [library](#use-in-your-go-project).__

* Migrate reads migrations from [sources](#migration-sources)
   and applies them in correct order to a [database](#databases).
* Drivers are &quot;dumb&quot;, migrate glues everything together and makes sure the logic is bulletproof.
   (Keeps the drivers lightweight, too.)
* Database drivers don&#039;t assume things or try to correct user input. When in doubt, fail.

Forked from [mattes/migrate](https://github.com/mattes/migrate)

## Databases

Database drivers run migrations. [Add a new database?](database/driver.go)

* [PostgreSQL](database/postgres)
* [PGX v4](database/pgx)
* [PGX v5](database/pgx/v5)
* [Redshift](database/redshift)
* [Ql](database/ql)
* [Cassandra / ScyllaDB](database/cassandra)
* [SQLite](database/sqlite)
* [SQLite3](database/sqlite3) ([todo #165](https://github.com/mattes/migrate/issues/165))
* [SQLCipher](database/sqlcipher)
* [MySQL / MariaDB](database/mysql)
* [Neo4j](database/neo4j)
* [MongoDB](database/mongodb)
* [CrateDB](database/crate) ([todo #170](https://github.com/mattes/migrate/issues/170))
* [Shell](database/shell) ([todo #171](https://github.com/mattes/migrate/issues/171))
* [Google Cloud Spanner](database/spanner)
* [CockroachDB](database/cockroachdb)
* [YugabyteDB](database/yugabytedb)
* [ClickHouse](database/clickhouse)
* [Firebird](database/firebird)
* [MS SQL Server](database/sqlserver)
* [rqlite](database/rqlite)

### Database URLs

Database connection strings are specified via URLs. The URL format is driver dependent but generally has the form: `dbdriver://username:password@host:port/dbname?param1=true&amp;param2=false`

Any [reserved URL characters](https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_reserved_characters) need to be escaped. Note, the `%` character also [needs to be escaped](https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_the_percent_character)

Explicitly, the following characters need to be escaped:
`!`, `#`, `$`, `%`, `&amp;`, `&#039;`, `(`, `)`, `*`, `+`, `,`, `/`, `:`, `;`, `=`, `?`, `@`, `[`, `]`

It&#039;s easiest to always run the URL parts of your DB connection URL (e.g. username, password, etc) through an URL encoder. See the example Python snippets below:

```bash
$ python3 -c &#039;import urllib.parse; print(urllib.parse.quote(input(&quot;String to encode: &quot;), &quot;&quot;))&#039;
String to encode: FAKEpassword!#$%&amp;&#039;()*+,/:;=?@[]
FAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D
$ python2 -c &#039;import urllib; print urllib.quote(raw_input(&quot;String to encode: &quot;), &quot;&quot;)&#039;
String to encode: FAKEpassword!#$%&amp;&#039;()*+,/:;=?@[]
FAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D
$
```

## Migration Sources

Source drivers read migrations from local or remote sources. [Add a new source?](source/driver.go)

* [Filesystem](source/file) - read from filesystem
* [io/fs](source/iofs) - read from a Go [io/fs](https://pkg.go.dev/io/fs#FS)
* [Go-Bindata](source/go_bindata) - read from embedded binary data ([jteeuwen/go-bindata](https://github.com/jteeuwen/go-bindata))
* [pkger](source/pkger) - read from embedded binary data ([markbates/pkger](https://github.com/markbates/pkger))
* [GitHub](source/github) - read from remote GitHub repositories
* [GitHub Enterprise](source/github_ee) - read from remote GitHub Enterprise repositories
* [Bitbucket](source/bitbucket) - read from remote Bitbucket repositories
* [Gitlab](source/gitlab) - read from remote Gitlab repositories
* [AWS S3](source/aws_s3) - read from Amazon Web Services S3
* [Google Cloud Storage](source/google_cloud_storage) - read from Google Cloud Platform Storage

## CLI usage

* Simple wrapper around this library.
* Handles ctrl+c (SIGINT) gracefully.
* No config search paths, no config files, no magic ENV var injections.

__[CLI Documentation](cmd/migrate)__

### Basic usage

```bash
$ migrate -source file://path/to/migrations -database postgres://localhost:5432/database up 2
```

### Docker usage

```bash
$ docker run -v {{ migration dir }}:/migrations --network host migrate/migrate
    -path=/migrations/ -database postgres://localhost:5432/database up 2
```

## Use in your Go project

* API is stable and frozen for this release (v3 &amp; v4).
* Uses [Go modules](https://golang.org/cmd/go/#hdr-Modules__module_versions__and_more) to manage dependencies.
* To help prevent database corruptions, it supports graceful stops via `GracefulStop chan bool`.
* Bring your own logger.
* Uses `io.Reader` streams internally for low memory overhead.
* Thread-safe and no goroutine leaks.

__[Go Documentation](https://pkg.go.dev/github.com/golang-migrate/migrate/v4)__

```go
import (
    &quot;github.com/golang-migrate/migrate/v4&quot;
    _ &quot;github.com/golang-migrate/migrate/v4/database/postgres&quot;
    _ &quot;github.com/golang-migrate/migrate/v4/source/github&quot;
)

func main() {
    m, err := migrate.New(
        &quot;github://mattes:personal-access-token@mattes/migrate_test&quot;,
        &quot;postgres://localhost:5432/database?sslmode=enable&quot;)
    m.Steps(2)
}
```

Want to use an existing database client?

```go
import (
    &quot;database/sql&quot;
    _ &quot;github.com/lib/pq&quot;
    &quot;github.com/golang-migrate/migrate/v4&quot;
    &quot;github.com/golang-migrate/migrate/v4/database/postgres&quot;
    _ &quot;github.com/golang-migrate/migrate/v4/source/file&quot;
)

func main() {
    db, err := sql.Open(&quot;postgres&quot;, &quot;postgres://localhost:5432/database?sslmode=enable&quot;)
    driver, err := postgres.WithInstance(db, &amp;postgres.Config{})
    m, err := migrate.NewWithDatabaseInstance(
        &quot;file:///migrations&quot;,
        &quot;postgres&quot;, driver)
    m.Up() // or m.Steps(2) if you want to explicitly set the number of migrations to run
}
```

## Getting started

Go to [getting started](GETTING_STARTED.md)

## Tutorials

* [CockroachDB](database/cockroachdb/TUTORIAL.md)
* [PostgreSQL](database/postgres/TUTORIAL.md)

(more tutorials to come)

## Migration files

Each migration has an up and down migration. [Why?](FAQ.md#why-two-separate-files-up-and-down-for-a-migration)

```bash
1481574547_create_users_table.up.sql
1481574547_create_users_table.down.sql
```

[Best practices: How to write migrations.](MIGRATIONS.md)

## Coming from another db migration tool?

Check out [migradaptor](https://github.com/musinit/migradaptor/).
*Note: migradaptor is not affiliated or supported by this project*

## Versions

Version | Supported? | Import | Notes
--------|------------|--------|------
**master** | :white_check_mark: | `import &quot;github.com/golang-migrate/migrate/v4&quot;` | New features and bug fixes arrive here first |
**v4** | :white_check_mark: | `import &quot;github.com/golang-migrate/migrate/v4&quot;` | Used for stable releases |
**v3** | :x: | `import &quot;github.com/golang-migrate/migrate&quot;` (with package manager) or `import &quot;gopkg.in/golang-migrate/migrate.v3&quot;` (not recommended) | **DO NOT USE** - No longer supported |

## Development and Contributing

Yes, please! [`Makefile`](Makefile) is your friend,
read the [development guide](CONTRIBUTING.md).

Also have a look at the [FAQ](FAQ.md).

---

Looking for alternatives? [https://awesome-go.com/#database](https://awesome-go.com/#database).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[pingcap/tidb]]></title>
            <link>https://github.com/pingcap/tidb</link>
            <guid>https://github.com/pingcap/tidb</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[TiDB - the open-source, cloud-native, distributed SQL database designed for modern applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pingcap/tidb">pingcap/tidb</a></h1>
            <p>TiDB - the open-source, cloud-native, distributed SQL database designed for modern applications.</p>
            <p>Language: Go</p>
            <p>Stars: 38,271</p>
            <p>Forks: 5,913</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&#039;https://www.pingcap.com/?utm_source=github&amp;utm_medium=tidb&#039;&gt;
&lt;img src=&quot;docs/tidb-logo.png&quot; alt=&quot;TiDB, a distributed SQL database&quot; height=100&gt;&lt;/img&gt;
&lt;/a&gt;

---

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://github.com/pingcap/tidb/blob/master/LICENSE)
[![Language](https://img.shields.io/badge/Language-Go-blue.svg)](https://golang.org/)
[![Build Status](https://prow.tidb.net/badge.svg?jobs=pingcap/tidb/merged_build)](https://prow.tidb.net/?repo=pingcap%2Ftidb&amp;type=postsubmit&amp;job=pingcap%2Ftidb%2Fmerged_build)
[![Go Report Card](https://goreportcard.com/badge/github.com/pingcap/tidb)](https://goreportcard.com/report/github.com/pingcap/tidb)
[![GitHub release](https://img.shields.io/github/tag/pingcap/tidb.svg?label=release)](https://github.com/pingcap/tidb/releases)
&lt;/div&gt;

# TiDB

TiDB (/‚Äôta…™diÀêbi:/, &quot;Ti&quot; stands for Titanium) is an open-source, cloud-native, distributed SQL database designed for high availability, horizontal and vertical scalability, strong consistency, and high performance.

- [Key Features](#key-features)
- [Quick Start](#quick-start)
- [Need Help?](#need-help)
- [Architecture](#architecture)
- [Contributing](#contributing)
- [License](#license)
- [See Also](#see-also)
- [Acknowledgments](#acknowledgments)

## Key Features

- **[Distributed Transactions](https://www.pingcap.com/blog/distributed-transactions-tidb?utm_source=github&amp;utm_medium=tidb)**: TiDB uses a two-phase commit protocol to ensure ACID compliance, providing strong consistency. Transactions span multiple nodes, and TiDB&#039;s distributed nature ensures data correctness even in the presence of network partitions or node failures.

- **[Horizontal and Vertical Scalability](https://docs.pingcap.com/tidb/stable/scale-tidb-using-tiup?utm_source=github&amp;utm_medium=tidb)**: TiDB can be scaled horizontally by adding more nodes or vertically by increasing resources of existing nodes, all without downtime. TiDB&#039;s architecture separates computing from storage, enabling you to adjust both independently as needed for flexibility and growth.

- **[High Availability](https://docs.pingcap.com/tidbcloud/high-availability-with-multi-az?utm_source=github&amp;utm_medium=tidb)**: Built-in Raft consensus protocol ensures reliability and automated failover. Data is stored in multiple replicas, and transactions are committed only after writing to the majority of replicas, guaranteeing strong consistency and availability, even if some replicas fail. Geographic placement of replicas can be configured for different disaster tolerance levels.

- **[Hybrid Transactional/Analytical Processing (HTAP)](https://www.pingcap.com/blog/htap-demystified-defining-modern-data-architecture-tidb?utm_source=github&amp;utm_medium=tidb)**: TiDB provides two storage engines: TiKV, a row-based storage engine, and TiFlash, a columnar storage engine. TiFlash uses the Multi-Raft Learner protocol to replicate data from TiKV in real time, ensuring consistent data between the TiKV row-based storage engine and the TiFlash columnar storage engine. The TiDB Server coordinates query execution across both TiKV and TiFlash to optimize performance.

- **[Cloud-Native](https://www.pingcap.com/cloud-native?utm_source=github&amp;utm_medium=tidb)**: TiDB can be deployed in public clouds, on-premises, or natively in Kubernetes. [TiDB Operator](https://docs.pingcap.com/tidb-in-kubernetes/stable/tidb-operator-overview/?utm_source=github&amp;utm_medium=tidb) helps manage TiDB on Kubernetes, automating cluster operations, while [TiDB Cloud](https://tidbcloud.com/?utm_source=github&amp;utm_medium=tidb) provides a fully-managed service for easy and economical deployment, allowing users to set up clusters with just a few clicks.

- **[MySQL Compatibility](https://docs.pingcap.com/tidb/stable/mysql-compatibility?utm_source=github&amp;utm_medium=tidb)**: TiDB is compatible with MySQL 8.0, allowing you to use familiar protocols, frameworks and tools. You can migrate applications to TiDB without changing any code, or with minimal modifications. Additionally, TiDB provides a suite of [data migration tools](https://docs.pingcap.com/tidb/stable/ecosystem-tool-user-guide?utm_source=github&amp;utm_medium=tidb) to help easily migrate application data into TiDB.

- **[Open Source Commitment](https://www.pingcap.com/blog/open-source-is-in-our-dna-reaffirming-tidb-commitment?utm_source=github&amp;utm_medium=tidb)**: Open source is at the core of TiDB&#039;s identity. All source code is available on GitHub under the Apache 2.0 license, including enterprise-grade features. TiDB is built with the belief that open source enables transparency, innovation, and collaboration. We actively encourage contributions from the community to help build a vibrant and inclusive ecosystem, reaffirming our commitment to open development and accessibility for everyone.

## Quick start

&gt; [!Tip]  
&gt; As part of our commitment to open source, we want to reward all GitHub users. In addition to the free tier, you can get up to $2000 in TiDB Cloud Serverless credits for your open-source contributions - [Claim here](https://ossinsight.io/open-source-heroes/?utm_source=ossinsight&amp;utm_medium=referral&amp;utm_campaign=plg_OSScontribution_credit_05).

1. Start a TiDB Cluser

    - **On Local Playground**. To start a local test cluster, please refer to the [TiDB quick start guide](https://docs.pingcap.com/tidb/stable/quick-start-with-tidb#deploy-a-local-test-cluster?utm_source=github&amp;utm_medium=tidb).

    - **On Kubernetes**. TiDB can be easily deployed in a self-managed Kubernetes environment or Kubernetes services on public clouds using TiDB Operator. For more details, please refer to the [TiDB on Kubernetes quick start guide](https://docs.pingcap.com/tidb-in-kubernetes/stable/get-started?utm_source=github&amp;utm_medium=tidb).

    - **Using TiDB Cloud (Recommended)**. TiDB Cloud offers a fully managed version of TiDB with a free tier, no credit card required, so you can get a free cluster in seconds and start easily: [Sign up for TiDB Cloud](https://tidbcloud.com/free-trial?utm_source=github&amp;utm_medium=tidb).

2. Learn About TiDB SQL: To explore the SQL capabilities of TiDB, refer to the [TiDB SQL documentation](https://docs.pingcap.com/tidb/stable/sql-statement-overview?utm_source=github&amp;utm_medium=tidb).

3. Use MySQL Driver or ORM to [Build an App with TiDB with TiDB](https://docs.pingcap.com/tidbcloud/dev-guide-overview?utm_source=github&amp;utm_medium=tidb).

4. Explore key features, such as [data migration](https://docs.pingcap.com/tidbcloud/tidb-cloud-migration-overview?utm_source=github&amp;utm_medium=tidb), [changefeed](https://docs.pingcap.com/tidbcloud/changefeed-overview?utm_source=github&amp;utm_medium=tidb), [vector search](https://docs.pingcap.com/tidbcloud/vector-search-overview?utm_source=github&amp;utm_medium=tidb), [HTAP](https://docs.pingcap.com/tidbcloud/tidb-cloud-htap-quickstart?utm_source=github&amp;utm_medium=tidb), [disaster recovery](https://docs.pingcap.com/tidb/stable/dr-solution-introduction?utm_source=github&amp;utm_medium=tidb), etc.


## Need Help?

- You can connect with TiDB users, ask questions, find answers, and help others on our community platforms: [Discord](https://discord.gg/KVRZBR2DrG?utm_source=github), Slack ([English](https://slack.tidb.io/invite?team=tidb-community&amp;channel=everyone&amp;ref=pingcap-tidb), [Japanese](https://slack.tidb.io/invite?team=tidb-community&amp;channel=tidb-japan&amp;ref=github-tidb)), [Stack Overflow](https://stackoverflow.com/questions/tagged/tidb), TiDB Forum ([English](https://ask.pingcap.com/), [Chinese](https://asktug.com)), X [@PingCAP](https://twitter.com/PingCAP)

- For filing bugs, suggesting improvements, or requesting new features, use [Github Issues](https://github.com/pingcap/tidb/issues) or join discussions on [Github Discussions](https://github.com/orgs/pingcap/discussions).

- To troubleshoot TiDB, refer to [Toubleshooting documentation](https://docs.pingcap.com/tidb/stable/tidb-troubleshooting-map?utm_source=github&amp;utm_medium=tidb).

## Architecture

![TiDB architecture](./docs/tidb-architecture.png)

Learn more details about TiDB architecture in our [Docs](https://docs.pingcap.com/tidb/stable/tidb-architecture?utm_source=github&amp;utm_medium=tidb).

## Contributing

TiDB is built on a commitment to open source, and we welcome contributions from everyone. Whether you are interested in improving documentation, fixing bugs, or developing new features, we invite you to shape the future of TiDB.

- See our [Contributor Guide](https://github.com/pingcap/community/blob/master/contributors/README.md#how-to-contribute) and [TiDB Development Guide](https://pingcap.github.io/tidb-dev-guide/index.html) to get started.

- If you&#039;re looking for issues to work on, try looking at the [good first issues](https://github.com/pingcap/tidb/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) or [help wanted issues](https://github.com/pingcap/tidb/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22).

- The [contribution map](https://github.com/pingcap/tidb-map/blob/master/maps/contribution-map.md#a-map-that-guides-what-and-how-contributors-can-contribute) lists everything you can contribute.

- The [community repository](https://github.com/pingcap/community) contains everything else you need.

- Don&#039;t forget to claim your contribution swag by filling in and submitting this [form](https://forms.pingcap.com/f/tidb-contribution-swag).


&lt;a href=&quot;https://next.ossinsight.io/widgets/official/compose-recent-active-contributors?repo_id=41986369&amp;limit=30&quot; target=&quot;_blank&quot; style=&quot;display: block&quot; align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-recent-active-contributors/thumbnail.png?repo_id=41986369&amp;limit=30&amp;image_size=auto&amp;color_scheme=dark&quot; width=&quot;655&quot; height=&quot;auto&quot;&gt;
    &lt;img alt=&quot;Active Contributors of pingcap/tidb - Last 28 days&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-recent-active-contributors/thumbnail.png?repo_id=41986369&amp;limit=30&amp;image_size=auto&amp;color_scheme=light&quot; width=&quot;655&quot; height=&quot;auto&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;

## License

TiDB is under the Apache 2.0 license. See the [LICENSE](./LICENSE) file for details.

## See Also

- [TiDB Online Playgroud](https://play.tidbcloud.com/?utm_source=github&amp;utm_medium=tidb_readme)
- TiDB Case Studies: [TiDB Customers](https://www.pingcap.com/customers/?utm_source=github&amp;utm_medium=tidb), [TiDB ‰∫ã‰æãË®ò‰∫ã](https://pingcap.co.jp/case-study/?utm_source=github&amp;utm_medium=tidb), [TiDB ‰∏≠ÊñáÁî®Êà∑Ê°à‰æã](https://cn.pingcap.com/case/?utm_source=github&amp;utm_medium=tidb)
- [TiDB User Documentation](https://docs.pingcap.com/tidb/stable?utm_source=github&amp;utm_medium=tidb)
- [TiDB Design Docs](/docs/design)
- [TiDB Release Notes](https://docs.pingcap.com/tidb/dev/release-notes?utm_source=github&amp;utm_medium=tidb)
- [TiDB Blog](https://www.pingcap.com/blog/?utm_source=github&amp;utm_medium=tidb)
- [TiDB Roadmap](roadmap.md)

## Acknowledgments

- Thanks [cznic](https://github.com/cznic) for providing some great open source tools.
- Thanks [GolevelDB](https://github.com/syndtr/goleveldb), [BoltDB](https://github.com/boltdb/bolt), and [RocksDB](https://github.com/facebook/rocksdb) for their powerful storage engines.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[bluenviron/mediamtx]]></title>
            <link>https://github.com/bluenviron/mediamtx</link>
            <guid>https://github.com/bluenviron/mediamtx</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[Ready-to-use SRT / WebRTC / RTSP / RTMP / LL-HLS media server and media proxy that allows to read, publish, proxy, record and playback video and audio streams.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bluenviron/mediamtx">bluenviron/mediamtx</a></h1>
            <p>Ready-to-use SRT / WebRTC / RTSP / RTMP / LL-HLS media server and media proxy that allows to read, publish, proxy, record and playback video and audio streams.</p>
            <p>Language: Go</p>
            <p>Stars: 13,964</p>
            <p>Forks: 1,713</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img src=&quot;logo.png&quot; alt=&quot;MediaMTX / rtsp-simple-server&quot;&gt;

  &lt;br&gt;
  &lt;br&gt;

  [![Test](https://github.com/bluenviron/mediamtx/actions/workflows/code_test.yml/badge.svg)](https://github.com/bluenviron/mediamtx/actions/workflows/code_test.yml)
  [![Lint](https://github.com/bluenviron/mediamtx/actions/workflows/code_lint.yml/badge.svg)](https://github.com/bluenviron/mediamtx/actions/workflows/code_lint.yml)
  [![CodeCov](https://codecov.io/gh/bluenviron/mediamtx/branch/main/graph/badge.svg)](https://app.codecov.io/gh/bluenviron/mediamtx/tree/main)
  [![Release](https://img.shields.io/github/v/release/bluenviron/mediamtx)](https://github.com/bluenviron/mediamtx/releases)
  [![Docker Hub](https://img.shields.io/badge/docker-bluenviron/mediamtx-blue)](https://hub.docker.com/r/bluenviron/mediamtx)
  [![API Documentation](https://img.shields.io/badge/api-documentation-blue)](https://bluenviron.github.io/mediamtx)
&lt;/h1&gt;

&lt;br&gt;

_MediaMTX_ is a ready-to-use and zero-dependency real-time media server and media proxy that allows to publish, read, proxy, record and playback video and audio streams. It has been conceived as a &quot;media router&quot; that routes media streams from one end to the other.

Live streams can be published to the server with:

|protocol|variants|video codecs|audio codecs|
|--------|--------|------------|------------|
|[SRT clients](#srt-clients)||H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3|
|[SRT cameras and servers](#srt-cameras-and-servers)||H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3|
|[WebRTC clients](#webrtc-clients)|WHIP|AV1, VP9, VP8, [H265](#supported-browsers), H264|Opus, G722, G711 (PCMA, PCMU)|
|[WebRTC servers](#webrtc-servers)|WHEP|AV1, VP9, VP8, [H265](#supported-browsers), H264|Opus, G722, G711 (PCMA, PCMU)|
|[RTSP clients](#rtsp-clients)|UDP, TCP, RTSPS|AV1, VP9, VP8, H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video, M-JPEG and any RTP-compatible codec|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G726, G722, G711 (PCMA, PCMU), LPCM and any RTP-compatible codec|
|[RTSP cameras and servers](#rtsp-cameras-and-servers)|UDP, UDP-Multicast, TCP, RTSPS|AV1, VP9, VP8, H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video, M-JPEG and any RTP-compatible codec|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G726, G722, G711 (PCMA, PCMU), LPCM and any RTP-compatible codec|
|[RTMP clients](#rtmp-clients)|RTMP, RTMPS, Enhanced RTMP|AV1, VP9, H265, H264|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G711 (PCMA, PCMU), LPCM|
|[RTMP cameras and servers](#rtmp-cameras-and-servers)|RTMP, RTMPS, Enhanced RTMP|AV1, VP9, H265, H264|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G711 (PCMA, PCMU), LPCM|
|[HLS cameras and servers](#hls-cameras-and-servers)|Low-Latency HLS, MP4-based HLS, legacy HLS|AV1, VP9, [H265](#supported-browsers-1), H264|Opus, MPEG-4 Audio (AAC)|
|[UDP/MPEG-TS](#udpmpeg-ts)|Unicast, broadcast, multicast|H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3|
|[Raspberry Pi Cameras](#raspberry-pi-cameras)||H264||

Live streams can be read from the server with:

|protocol|variants|video codecs|audio codecs|
|--------|--------|------------|------------|
|[SRT](#srt)||H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3|
|[WebRTC](#webrtc)|WHEP|AV1, VP9, VP8, [H265](#supported-browsers), H264|Opus, G722, G711 (PCMA, PCMU)|
|[RTSP](#rtsp)|UDP, UDP-Multicast, TCP, RTSPS|AV1, VP9, VP8, H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video, M-JPEG and any RTP-compatible codec|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G726, G722, G711 (PCMA, PCMU), LPCM and any RTP-compatible codec|
|[RTMP](#rtmp)|RTMP, RTMPS, Enhanced RTMP|H264|MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3)|
|[HLS](#hls)|Low-Latency HLS, MP4-based HLS, legacy HLS|AV1, VP9, [H265](#supported-browsers-1), H264|Opus, MPEG-4 Audio (AAC)|

Live streams be recorded and played back with:

|format|video codecs|audio codecs|
|------|------------|------------|
|[fMP4](#record-streams-to-disk)|AV1, VP9, H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video, M-JPEG|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G711 (PCMA, PCMU), LPCM|
|[MPEG-TS](#record-streams-to-disk)|H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3|

**Features**

* Publish live streams to the server
* Read live streams from the server
* Streams are automatically converted from a protocol to another
* Serve multiple streams at once in separate paths
* Record streams to disk
* Playback recorded streams
* Authenticate users
* Redirect readers to other RTSP servers (load balancing)
* Control the server through the Control API
* Reload the configuration without disconnecting existing clients (hot reloading)
* Read Prometheus-compatible metrics
* Run hooks (external commands) when clients connect, disconnect, read or publish streams
* Compatible with Linux, Windows and macOS, does not require any dependency or interpreter, it&#039;s a single executable

**Note about rtsp-simple-server**

_rtsp-simple-server_ has been rebranded as _MediaMTX_. The reason is pretty obvious: this project started as a RTSP server but has evolved into a much more versatile product that is not tied to the RTSP protocol anymore. Nothing will change regarding license, features and backward compatibility.

## Table of contents

* [Installation](#installation)
  * [Standalone binary](#standalone-binary)
  * [Docker image](#docker-image)
  * [Arch Linux package](#arch-linux-package)
  * [OpenWrt binary](#openwrt-binary)
* [Basic usage](#basic-usage)
* [Publish to the server](#publish-to-the-server)
  * [By software](#by-software)
    * [FFmpeg](#ffmpeg)
    * [GStreamer](#gstreamer)
    * [OBS Studio](#obs-studio)
    * [OpenCV](#opencv)
    * [Unity](#unity)
    * [Web browsers](#web-browsers)
  * [By device](#by-device)
    * [Generic webcam](#generic-webcam)
    * [Raspberry Pi Cameras](#raspberry-pi-cameras)
      * [Adding audio](#adding-audio)
      * [Secondary stream](#secondary-stream)
  * [By protocol](#by-protocol)
    * [SRT clients](#srt-clients)
    * [SRT cameras and servers](#srt-cameras-and-servers)
    * [WebRTC clients](#webrtc-clients)
    * [WebRTC servers](#webrtc-servers)
    * [RTSP clients](#rtsp-clients)
    * [RTSP cameras and servers](#rtsp-cameras-and-servers)
    * [RTMP clients](#rtmp-clients)
    * [RTMP cameras and servers](#rtmp-cameras-and-servers)
    * [HLS cameras and servers](#hls-cameras-and-servers)
    * [UDP/MPEG-TS](#udpmpeg-ts)
* [Read from the server](#read-from-the-server)
  * [By software](#by-software-1)
    * [FFmpeg](#ffmpeg-1)
    * [GStreamer](#gstreamer-1)
    * [VLC](#vlc)
    * [Unity](#unity-1)
    * [Web browsers](#web-browsers-1)
  * [By protocol](#by-protocol-1)
    * [SRT](#srt)
    * [WebRTC](#webrtc)
    * [RTSP](#rtsp)
    * [RTMP](#rtmp)
    * [HLS](#hls)
* [Other features](#other-features)
  * [Configuration](#configuration)
  * [Authentication](#authentication)
    * [Internal](#internal)
    * [HTTP-based](#http-based)
    * [JWT-based](#jwt-based)
  * [Encrypt the configuration](#encrypt-the-configuration)
  * [Remuxing, re-encoding, compression](#remuxing-re-encoding-compression)
  * [Record streams to disk](#record-streams-to-disk)
  * [Playback recorded streams](#playback-recorded-streams)
  * [Forward streams to other servers](#forward-streams-to-other-servers)
  * [Proxy requests to other servers](#proxy-requests-to-other-servers)
  * [On-demand publishing](#on-demand-publishing)
  * [Route absolute timestamps](#route-absolute-timestamps)
  * [Expose the server in a subfolder](#expose-the-server-in-a-subfolder)
  * [Start on boot](#start-on-boot)
    * [Linux](#linux)
    * [OpenWrt](#openwrt)
    * [Windows](#windows)
  * [Hooks](#hooks)
  * [Control API](#control-api)
  * [Metrics](#metrics)
  * [pprof](#pprof)
  * [SRT-specific features](#srt-specific-features)
    * [Standard stream ID syntax](#standard-stream-id-syntax)
  * [WebRTC-specific features](#webrtc-specific-features)
    * [Authenticating with WHIP/WHEP](#authenticating-with-whipwhep)
    * [Solving WebRTC connectivity issues](#solving-webrtc-connectivity-issues)
    * [Supported browsers](#supported-browsers)
  * [HLS-specific features](#hls-specific-features)
    * [Supported browsers](#supported-browsers-1)
  * [RTSP-specific features](#rtsp-specific-features)
    * [Transport protocols](#transport-protocols)
    * [Encryption](#encryption)
    * [Corrupted frames](#corrupted-frames)
  * [RTMP-specific features](#rtmp-specific-features)
    * [Encryption](#encryption-1)
* [Compile from source](#compile-from-source)
  * [Standard](#standard)
  * [OpenWrt](#openwrt-1)
  * [Custom libcamera](#custom-libcamera)
  * [Cross compile](#cross-compile)
  * [Compile for all supported platforms](#compile-for-all-supported-platforms)
* [License](#license)
* [Specifications](#specifications)
* [Related projects](#related-projects)

## Installation

There are several installation methods available: standalone binary, Docker image, Arch Linux package and OpenWrt binary.

### Standalone binary

1. Download and extract a standalone binary from the [release page](https://github.com/bluenviron/mediamtx/releases) that corresponds to your operating system and architecture.

2. Start the server:

   ```sh
   ./mediamtx
   ```

### Docker image

Download and launch the image:

```
docker run --rm -it --network=host bluenviron/mediamtx:latest
```

Available images:

|name|FFmpeg included|RPI Camera support|
|----|---------------|------------------|
|bluenviron/mediamtx:latest|:x:|:x:|
|bluenviron/mediamtx:latest-ffmpeg|:heavy_check_mark:|:x:|
|bluenviron/mediamtx:latest-rpi|:x:|:heavy_check_mark:|
|bluenviron/mediamtx:latest-ffmpeg-rpi|:heavy_check_mark:|:heavy_check_mark:|

The `--network=host` flag is mandatory for RTSP to work, since Docker can change the source port of UDP packets for routing reasons, and this doesn&#039;t allow the server to identify the senders of the packets.

If the `--network=host` cannot be used (for instance, it is not compatible with Windows or Kubernetes), you can disable the RTSP UDP transport protocol, add the server IP to `MTX_WEBRTCADDITIONALHOSTS` and expose ports manually:

```
docker run --rm -it \
-e MTX_RTSPTRANSPORTS=tcp \
-e MTX_WEBRTCADDITIONALHOSTS=192.168.x.x \
-p 8554:8554 \
-p 1935:1935 \
-p 8888:8888 \
-p 8889:8889 \
-p 8890:8890/udp \
-p 8189:8189/udp \
bluenviron/mediamtx
```

### Arch Linux package

If you are running the Arch Linux distribution, run:

```sh
git clone https://aur.archlinux.org/mediamtx.git
cd mediamtx
makepkg -si
```

### OpenWrt binary

If the architecture of the OpenWrt device is amd64, armv6, armv7 or arm64, use the [standalone binary method](#standalone-binary) and download a Linux binary that corresponds to your architecture.

Otherwise, [compile the server from source](#openwrt-1).

## Basic usage

1. Publish a stream. For instance, you can publish a video/audio file with _FFmpeg_:

   ```sh
   ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:8554/mystream
   ```

   or _GStreamer_:

   ```sh
   gst-launch-1.0 rtspclientsink name=s location=rtsp://localhost:8554/mystream filesrc location=file.mp4 \
   ! qtdemux name=d d.video_0 ! queue ! s.sink_0 d.audio_0 ! queue ! s.sink_1
   ```

2. Open the stream. For instance, you can open the stream with _VLC_:

   ```sh
   vlc --network-caching=50 rtsp://localhost:8554/mystream
   ```

   or _GStreamer_:

   ```sh
   gst-play-1.0 rtsp://localhost:8554/mystream
   ```

   or _FFmpeg_:

   ```sh
   ffmpeg -i rtsp://localhost:8554/mystream -c copy output.mp4
   ```

## Publish to the server

### By software

#### FFmpeg

FFmpeg can publish a stream to the server in multiple ways (SRT client, SRT server, RTSP client, RTMP client, UDP/MPEG-TS, WebRTC with WHIP). The recommended one consists in publishing as a [RTSP client](#rtsp-clients):

```
ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:8554/mystream
```

The RTSP protocol supports multiple underlying transport protocols, each with its own characteristics (see [RTSP-specific features](#rtsp-specific-features)). You can set the transport protocol by using the `rtsp_transport` flag, for instance, in order to use TCP:

```sh
ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp -rtsp_transport tcp rtsp://localhost:8554/mystream
```

The resulting stream is available in path `/mystream`.

#### GStreamer

GStreamer can publish a stream to the server in multiple ways (SRT client, SRT server, RTSP client, RTMP client, UDP/MPEG-TS, WebRTC with WHIP). The recommended one consists in publishing as a [RTSP client](#rtsp-clients):

```sh
gst-launch-1.0 rtspclientsink name=s location=rtsp://localhost:8554/mystream \
filesrc location=file.mp4 ! qtdemux name=d \
d.video_0 ! queue ! s.sink_0 \
d.audio_0 ! queue ! s.sink_1
```

If the stream is video only:

```sh
gst-launch-1.0 filesrc location=file.mp4 ! qtdemux name=d \
d.video_0 ! rtspclientsink location=rtsp://localhost:8554/mystream
```

The RTSP protocol supports multiple underlying transport protocols, each with its own characteristics (see [RTSP-specific features](#rtsp-specific-features)). You can set the transport protocol by using the `protocols` flag:

```sh
gst-launch-1.0 filesrc location=file.mp4 ! qtdemux name=d \
d.video_0 ! rtspclientsink protocols=tcp name=s location=rtsp://localhost:8554/mystream
```

The resulting stream is available in path `/mystream`.

GStreamer can also publish a stream by using the [WebRTC / WHIP protocol](#webrtc). Make sure that GStreamer version is at least 1.22, and that if the codec is H264, the profile is baseline. Use the `whipclientsink` element:

```
gst-launch-1.0 videotestsrc \
! video/x-raw,width=1920,height=1080,format=I420 \
! x264enc speed-preset=ultrafast bitrate=2000 \
! video/x-h264,profile=baseline \
! whipclientsink signaller::whip-endpoint=http://localhost:8889/mystream/whip
```

#### OBS Studio

OBS Studio can publish to the server in multiple ways (SRT client, RTMP client, WebRTC client). The recommended one consists in publishing as a [RTMP client](#rtmp-clients). In `Settings -&gt; Stream` (or in the Auto-configuration Wizard), use the following parameters:

* Service: `Custom...`
* Server: `rtmp://localhost`
* Stream key: `mystream`

If credentials are in use, use the following parameters:

* Service: `Custom...`
* Server: `rtmp://localhost`
* Stream key: `mystream?user=myuser&amp;pass=mypass`

Save the configuration and click `Start streaming`.

If you want to generate a stream that can be read with WebRTC, open `Settings -&gt; Output -&gt; Recording` and use the following parameters:

* FFmpeg output type: `Output to URL`
* File path or URL: `rtsp://localhost:8554/mystream`
* Container format: `rtsp`
* Check `show all codecs (even if potentically incompatible)`
* Video encoder: `h264_nvenc (libx264)`
* Video encoder settings (if any): `bf=0`
* Audio track: `1`
* Audio encoder: `libopus`

Then use the button `Start Recording` (instead of `Start Streaming`) to start streaming.

Latest versions of OBS Studio can publish to the server with the [WebRTC / WHIP protocol](#webrtc). Use the following parameters:

* Service: `WHIP`
* Server: `http://localhost:8889/mystream/whip`
* Bearer Token: `myuser:mypass` (if internal authentication is enabled) or JWT (if JWT-based authentication is enabled)

Save the configuration and click `Start streaming`.

The resulting stream is available in path `/mystream`.

#### OpenCV

Software which uses the OpenCV library can publish to the server through its GStreamer plugin, as a [RTSP client](#rtsp-clients). It must be compiled with GStreamer support, by following this procedure:

```sh
sudo apt install -y libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev gstreamer1.0-plugins-ugly gstreamer1.0-rtsp python3-dev python3-numpy
git clone --depth=1 -b 4.5.4 https://github.com/opencv/opencv
cd opencv
mkdir build &amp;&amp; cd build
cmake -D CMAKE_INSTALL_PREFIX=/usr -D WITH_GSTREAMER=ON ..
make -j$(nproc)
sudo make install
```

You can check that OpenCV has been installed correctly by running:

```sh
python3 -c &#039;import cv2; print(cv2.getBuildInformation())&#039;
```

Check that the output contains `GStreamer: YES`.

Videos can be published with `cv2.VideoWriter`:

```python
from datetime import datetime
from time import sleep, time

import cv2
import numpy as np

fps = 15
width = 800
height = 600
colors = [
    (0, 0, 255),
    (255, 0, 0),
    (0, 255, 0),
]

out = cv2.VideoWriter(&#039;appsrc ! videoconvert&#039; + \
    &#039; ! video/x-raw,format=I420&#039; + \
    &#039; ! x264enc speed-preset=ultrafast bitrate=600 key-int-max=&#039; + str(fps * 2) + \
    &#039; ! video/x-h264,profile=baseline&#039; + \
    &#039; ! rtspclientsink location=rtsp://localhost:8554/mystream&#039;,
    cv2.CAP_GSTREAMER, 0, fps, (width, height), True)
if not out.isOpened():
    raise Exception(&quot;can&#039;t open video writer&quot;)

curcolor = 0
start = time()

while True:
    frame = np.zeros((height, width, 3), np.uint8)

    # create a rectangle
    color = colors[curcolor]
    curcolor += 1
    curcolor %= len(colors)
    for y in range(0, int(frame.shape[0] / 2)):
        for x in range(0, int(frame.shape[1] / 2)):
            frame[y][x] = color

    out.write(frame)
    print(&quot;%s frame written to the server&quot; % datetime.now())

    now = time()
    diff = (1 / fps) - now - start
    if diff &gt; 0:
        sleep(diff)
    start = now
```

The resulting stream is available in path `/mystream`.

#### Unity

Software written with the Unity Engine can publish a stream to the server by using the [WebRTC protocol](#webrtc).

Create a new Unity project or open an existing open.

Open _Window -&gt; Package Manager_, click on the plus sign, _Add Package by name..._ and insert `com.unity.webrtc`. Wait for the package to be installed.

In the _Project_ window, under `Assets`, create a new C# Script called `WebRTCPublisher.cs` with this content:

```cs
using System.Collections;
using UnityEngine;
using Unity.WebRTC;
using UnityEngine.Networking;

public class WebRTCPublisher : MonoBehaviour
{
    public string url = &quot;http://localhost:8889/unity/whip&quot;;
    public int videoWidth = 1280;
    public int videoHeight = 720;

    private RTCPeerConnection pc;
    private MediaStream videoStream;

    void Start()
    {
        pc = new RTCPeerConnection();
        Camera sourceCamera = gameObject.GetComponent&lt;Camera&gt;();
        videoStream = sourceCamera.CaptureStream(videoWidth, videoHeight);
        foreach (var track in videoStream.GetTracks())
        {
            pc.AddTrack(track);
        }

        StartCoroutine(WebRTC.Update());
        StartCoroutine(createOffer());
    }

    private IEnumerator createOffer()
    {
        var op = pc.CreateOffer();
        yield return op;
        if (op.IsError) {
            Debug.LogError(&quot;CreateOffer() failed&quot;);
            yield break;
        }

        yield return setLocalDescription(op.Desc);
    }

    private IEnumerator setLocalDescription(RTCSessionDescription offer)
    {
        var op = pc.SetLocalDescription(ref offer);
        yield return op;
        if (op.IsError) {
            Debug.LogError(&quot;SetLocalDescription() failed&quot;);
            yield break;
        }

        yield return postOffer(offer);
    }

    private IEnumerator postOffer(RTCSessionDescription offer)
    {
        var content = new System.Net.Http.StringContent(offer.sdp);
        content.Headers.ContentType = new System.Net.Http.Headers.MediaTypeHeaderValue(&quot;application/sdp&quot;);
        var client = new System.Net.Http.HttpClient();

        var task = System.Threading.Tasks.Task.Run(async () =&gt; {
            var res = await client.PostAsync(new System.UriBuilder(url).Uri, content);
            res.EnsureSuccessS

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[googleapis/genai-toolbox]]></title>
            <link>https://github.com/googleapis/genai-toolbox</link>
            <guid>https://github.com/googleapis/genai-toolbox</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[MCP Toolbox for Databases is an open source MCP server for databases, designed and built with enterprise-quality and production-grade usage in mind.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/googleapis/genai-toolbox">googleapis/genai-toolbox</a></h1>
            <p>MCP Toolbox for Databases is an open source MCP server for databases, designed and built with enterprise-quality and production-grade usage in mind.</p>
            <p>Language: Go</p>
            <p>Stars: 615</p>
            <p>Forks: 74</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>
![logo](./logo.png)
# MCP Toolbox for Databases

&gt; [!NOTE] 
&gt; MCP Toolbox for Databases is currently in beta, and may see breaking 
&gt; changes until the first stable release (v1.0).

MCP Toolbox for Databases is an open source MCP server for databases It was
designed with enterprise-grade and production-quality in mind. It enables you to
develop tools easier, faster, and more securely by handling the complexities
such as connection pooling, authentication, and more.

This README provides a brief overview. For comprehensive details, see the [full
documentation](https://googleapis.github.io/genai-toolbox/).


&gt; [!NOTE] 
&gt; This product was originally named ‚ÄúGen AI Toolbox for Databases‚Äù as
&gt; its initial development predated MCP, but was renamed to align with recently
&gt; added MCP compatibility. 

&lt;!-- TOC ignore:true --&gt;
## Table of Contents

&lt;!-- TOC --&gt;

- [Why Toolbox?](#why-toolbox)
- [General Architecture](#general-architecture)
- [Getting Started](#getting-started)
    - [Installing the server](#installing-the-server)
    - [Running the server](#running-the-server)
    - [Integrating your application](#integrating-your-application)
- [Configuration](#configuration)
    - [Sources](#sources)
    - [Tools](#tools)
    - [Toolsets](#toolsets)
- [Versioning](#versioning)
- [Contributing](#contributing)

&lt;!-- /TOC --&gt;


##  Why Toolbox?

Toolbox helps you build Gen AI tools that let your agents access data in your
database. Toolbox provides:
- **Simplified development**: Integrate tools to your agent in less than 10
  lines of code, reuse tools between multiple agents or frameworks, and deploy
  new versions of tools more easily.
- **Better performance**: Best practices such as connection pooling,
  authentication, and more.
- **Enhanced security**: Integrated auth for more secure access to your data
- **End-to-end observability**: Out of the box metrics and tracing with built-in
  support for OpenTelemetry.


## General Architecture

Toolbox sits between your application&#039;s orchestration framework and your
database, providing a control plane that is used to modify, distribute, or
invoke tools. It simplifies the management of your tools by providing you with a
centralized location to store and update tools, allowing you to share tools
between agents and applications and update those tools without necessarily
redeploying your application.

![architecture](./docs/en/getting-started/introduction/architecture.png)

## Getting Started

### Installing the server
For the latest version, check the [releases page][releases] and use the
following instructions for your OS and CPU architecture.

[releases]: https://github.com/googleapis/genai-toolbox/releases

&lt;details open&gt;
&lt;summary&gt;Binary&lt;/summary&gt;

To install Toolbox as a binary:

&lt;!-- {x-release-please-start-version} --&gt;
```sh
# see releases page for other versions
export VERSION=0.3.0
curl -O https://storage.googleapis.com/genai-toolbox/v$VERSION/linux/amd64/toolbox
chmod +x toolbox
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Container image&lt;/summary&gt;
You can also install Toolbox as a container:

```sh
# see releases page for other versions
export VERSION=0.3.0
docker pull us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Compile from source&lt;/summary&gt;

To install from source, ensure you have the latest version of
[Go installed](https://go.dev/doc/install), and then run the following command:

```sh
go install github.com/googleapis/genai-toolbox@v0.3.0
```
&lt;!-- {x-release-please-end} --&gt;

&lt;/details&gt;

### Running the server

[Configure](#configuration) a `tools.yaml` to define your tools, and then
execute `toolbox` to start the server:

```sh
./toolbox --tools_file &quot;tools.yaml&quot;
```

You can use `toolbox help` for a full list of flags! To stop the server, send a
terminate signal (`ctrl+c` on most platforms).

For more detailed documentation on deploying to different environments, check
out the resources in the [How-to
section](https://googleapis.github.io/genai-toolbox/how-to/)

### Integrating your application

Once your server is up and running, you can load the tools into your
application. See below the list of Client SDKs for using various frameworks:

&lt;details open&gt;
&lt;summary&gt;Core&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core]:
    ```bash
    pip install toolbox-core
    ```
1. Load tools:
    ```python
    from toolbox_core import ToolboxClient

    # update the url to point to your server
    client = ToolboxClient(&quot;http://127.0.0.1:5000&quot;)

    # these tools can be passed to your application! 
    tools = await client.load_toolset(&quot;toolset_name&quot;)
    ```

For more detailed instructions on using the Toolbox Core SDK, see the
[project&#039;s README][toolbox-core-readme].

[toolbox-core]: https://pypi.org/project/toolbox-core/
[toolbox-core-readme]: https://github.com/googleapis/mcp-toolbox-sdk-python/tree/main/packages/toolbox-core/README.md

&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;LangChain / LangGraph&lt;/summary&gt;

1. Install [Toolbox LangChain SDK][toolbox-langchain]:
    ```bash
    pip install toolbox-langchain
    ```
1. Load tools:
    ```python
    from toolbox_langchain import ToolboxClient

    # update the url to point to your server
    client = ToolboxClient(&quot;http://127.0.0.1:5000&quot;)

    # these tools can be passed to your application! 
    tools = client.load_toolset()
    ```

For more detailed instructions on using the Toolbox LangChain SDK, see the
[project&#039;s README][toolbox-langchain-readme].

[toolbox-langchain]: https://pypi.org/project/toolbox-langchain/
[toolbox-langchain-readme]: https://github.com/googleapis/mcp-toolbox-sdk-python/blob/main/packages/toolbox-langchain/README.md

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;LlamaIndex&lt;/summary&gt;

1. Install [Toolbox Llamaindex SDK][toolbox-llamaindex]:
    ```bash
    pip install toolbox-llamaindex
    ```
1. Load tools:
    ```python
    from toolbox_llamaindex import ToolboxClient

    # update the url to point to your server
    client = ToolboxClient(&quot;http://127.0.0.1:5000&quot;)

    # these tools can be passed to your application! 
    tools = client.load_toolset()
    ```

For more detailed instructions on using the Toolbox Llamaindex SDK, see the
[project&#039;s README][toolbox-llamaindex-readme].

[toolbox-llamaindex]: https://pypi.org/project/toolbox-llamaindex/
[toolbox-llamaindex-readme]: https://github.com/googleapis/genai-toolbox-llamaindex-python/blob/main/README.md

&lt;/details&gt;

## Configuration

The primary way to configure Toolbox is through the `tools.yaml` file. If you
have multiple files, you can tell toolbox which to load with the `--tools_file
tools.yaml` flag.

You can find more detailed reference documentation to all resource types in the
[Resources](https://googleapis.github.io/genai-toolbox/resources/).
### Sources

The `sources` section of your `tools.yaml` defines what data sources your
Toolbox should have access to. Most tools will have at least one source to
execute against.

```yaml
sources:
  my-pg-source:
    kind: postgres
    host: 127.0.0.1
    port: 5432
    database: toolbox_db
    user: toolbox_user
    password: my-password
```

For more details on configuring different types of sources, see the
[Sources](https://googleapis.github.io/genai-toolbox/resources/sources).

### Tools

The `tools` section of a `tools.yaml` define the actions an agent can take: what
kind of tool it is, which source(s) it affects, what parameters it uses, etc.

```yaml
tools:
  search-hotels-by-name:
    kind: postgres-sql
    source: my-pg-source
    description: Search for hotels based on name.
    parameters:
      - name: name
        type: string
        description: The name of the hotel.
    statement: SELECT * FROM hotels WHERE name ILIKE &#039;%&#039; || $1 || &#039;%&#039;;
```

For more details on configuring different types of tools, see the
[Tools](https://googleapis.github.io/genai-toolbox/resources/tools).


### Toolsets

The `toolsets` section of your `tools.yaml` allows you to define groups of tools
that you want to be able to load together. This can be useful for defining
different groups based on agent or application.

```yaml
toolsets:
    my_first_toolset:
        - my_first_tool
        - my_second_tool
    my_second_toolset:
        - my_second_tool
        - my_third_tool
```

You can load toolsets by name:

```python
# This will load all tools
all_tools = client.load_toolset()

# This will only load the tools listed in &#039;my_second_toolset&#039;
my_second_toolset = client.load_toolset(&quot;my_second_toolset&quot;)
```

## Versioning

This project uses [semantic versioning](https://semver.org/), including a
`MAJOR.MINOR.PATCH` version number that increments with:

- MAJOR version when we make incompatible API changes
- MINOR version when we add functionality in a backward compatible manner
- PATCH version when we make backward compatible bug fixes

The public API that this applies to is the CLI associated with Toolbox, the
interactions with official SDKs, and the definitions in the `tools.yaml` file. 

## Contributing

Contributions are welcome. Please, see the [CONTRIBUTING](CONTRIBUTING.md)
to get started.

Please note that this project is released with a Contributor Code of Conduct.
By participating in this project you agree to abide by its terms. See
[Contributor Code of Conduct](CODE_OF_CONDUCT.md) for more information.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[stakater/Reloader]]></title>
            <link>https://github.com/stakater/Reloader</link>
            <guid>https://github.com/stakater/Reloader</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[A Kubernetes controller to watch changes in ConfigMap and Secrets and do rolling upgrades on Pods with their associated Deployment, StatefulSet, DaemonSet and DeploymentConfig ‚Äì [‚ú©Star] if you're using it!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stakater/Reloader">stakater/Reloader</a></h1>
            <p>A Kubernetes controller to watch changes in ConfigMap and Secrets and do rolling upgrades on Pods with their associated Deployment, StatefulSet, DaemonSet and DeploymentConfig ‚Äì [‚ú©Star] if you're using it!</p>
            <p>Language: Go</p>
            <p>Stars: 8,299</p>
            <p>Forks: 540</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/web/reloader.jpg&quot; alt=&quot;Reloader&quot; width=&quot;40%&quot;/&gt;
&lt;/p&gt;

[![Go Report Card](https://goreportcard.com/badge/github.com/stakater/reloader?style=flat-square)](https://goreportcard.com/report/github.com/stakater/reloader)
[![Go Doc](https://img.shields.io/badge/godoc-reference-blue.svg?style=flat-square)](https://godoc.org/github.com/stakater/reloader)
[![Release](https://img.shields.io/github/release/stakater/reloader.svg?style=flat-square)](https://github.com/stakater/reloader/releases/latest)
[![GitHub tag](https://img.shields.io/github/tag/stakater/reloader.svg?style=flat-square)](https://github.com/stakater/reloader/releases/latest)
[![Docker Pulls](https://img.shields.io/docker/pulls/stakater/reloader.svg?style=flat-square)](https://hub.docker.com/r/stakater/reloader/)
[![Docker Stars](https://img.shields.io/docker/stars/stakater/reloader.svg?style=flat-square)](https://hub.docker.com/r/stakater/reloader/)
[![license](https://img.shields.io/github/license/stakater/reloader.svg?style=flat-square)](LICENSE)

## üîÅ What is Reloader?

Reloader is a Kubernetes controller that automatically triggers rollouts of workloads (like Deployments, StatefulSets, and more) whenever referenced `Secrets` or `ConfigMaps` are updated.

In a traditional Kubernetes setup, updating a `Secret` or `ConfigMap` does not automatically restart or redeploy your workloads. This can lead to stale configurations running in production, especially when dealing with dynamic values like credentials, feature flags, or environment configs.

Reloader bridges that gap by ensuring your workloads stay in sync with configuration changes ‚Äî automatically and safely.

## üöÄ Why Reloader?

- ‚úÖ **Zero manual restarts**: No need to manually rollout workloads after config/secret changes.
- üîí **Secure by design**: Ensure your apps always use the most up-to-date credentials or tokens.
- üõ†Ô∏è **Flexible**: Works with all major workload types ‚Äî Deployment, StatefulSet, Daemonset, ArgoRollout, and more.
- ‚ö° **Fast feedback loop**: Ideal for CI/CD pipelines where secrets/configs change frequently.
- üîÑ **Out-of-the-box integration**: Just label your workloads and let Reloader do the rest.

## üîß How It Works?

```mermaid
flowchart LR
  ExternalSecret --&gt;|Creates| Secret
  SealedSecret --&gt;|Creates| Secret
  Secret --&gt;|Watched by| Reloader
  ConfigMap --&gt;|Watched by| Reloader

  Reloader --&gt;|Triggers Rollout| Deployment
  Reloader --&gt;|Triggers Rollout| DeploymentConfig
  Reloader --&gt;|Triggers Rollout| Daemonset
  Reloader --&gt;|Triggers Rollout| Statefulset
  Reloader --&gt;|Triggers Rollout| ArgoRollout
  Reloader --&gt;|Triggers Job| CronJob
  Reloader --&gt;|Sends Notification| Slack,Teams,Webhook
```

- Sources like `ExternalSecret` or `SealedSecret` create or manage your Kubernetes Secrets.
- `Secrets` and `ConfigMaps` are watched by Reloader.
- When changes are detected, Reloader automatically triggers a rollout of the associated workloads, ensuring your app always runs with the latest configuration.

## ‚ö° Quick Start

### 1. Install Reloader

Follow any of this [installation options](#-installation).

### 2. Annotate Your Workload

To enable automatic reload for a Deployment:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
  annotations:
    reloader.stakater.com/auto: &quot;true&quot;
spec:
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: app
          image: your-image
          envFrom:
            - configMapRef:
                name: my-config
            - secretRef:
                name: my-secret
```

This tells Reloader to watch the `ConfigMap` and `Secret` referenced in this deployment. When either is updated, it will trigger a rollout.

## üè¢ Enterprise Version

Stakater offers an enterprise-grade version of Reloader with:

1. SLA-backed support
1. Certified images
1. Private Slack support

Contact [`sales@stakater.com`](mailto:sales@stakater.com) for info about Reloader Enterprise.

## üß© Usage

Reloader supports multiple annotation-based controls to let you **customize when and how your Kubernetes workloads are reloaded** upon changes in `Secrets` or `ConfigMaps`.

Kubernetes does not trigger pod restarts when a referenced `Secret` or `ConfigMap` is updated. Reloader bridges this gap by watching for changes and automatically performing rollouts ‚Äî but it gives you full control via annotations, so you can:

- Reload **all** resources by default
- Restrict reloads to only **Secrets** or only **ConfigMaps**
- Watch only **specific resources**
- Use **opt-in via tagging** (`search` + `match`)
- Exclude workloads you don‚Äôt want to reload

### 1. üîÅ Automatic Reload (Default)

Use these annotations to automatically restart the workload when referenced `Secrets` or `ConfigMaps` change.

| Annotation                                 | Description                                                          |
|--------------------------------------------|----------------------------------------------------------------------|
| `reloader.stakater.com/auto: &quot;true&quot;`       | Reloads workload when any referenced ConfigMap or Secret changes     |
| `secret.reloader.stakater.com/auto: &quot;true&quot;`| Reloads only when referenced Secret(s) change                        |
| `configmap.reloader.stakater.com/auto: &quot;true&quot;`| Reloads only when referenced ConfigMap(s) change                  |

### 2. üìõ Named Resource Reload (Specific Resource Annotations)

These annotations allow you to manually define which ConfigMaps or Secrets should trigger a reload, regardless of whether they&#039;re used in the pod spec.

| Annotation                                          | Description                                                                          |
|-----------------------------------------------------|--------------------------------------------------------------------------------------|
| `secret.reloader.stakater.com/reload: &quot;my-secret&quot;`  | Reloads when specific Secret(s) change, regardless of how they&#039;re used              |
| `configmap.reloader.stakater.com/reload: &quot;my-config&quot;`| Reloads when specific ConfigMap(s) change, regardless of how they&#039;re used         |

#### Use when

1. ‚úÖ This is useful in tightly scoped scenarios where config is shared but reloads are only relevant in certain cases.
1. ‚úÖ Use this when you know exactly which resource(s) matter and want to avoid auto-discovery or searching altogether.

### 3. üéØ Targeted Reload (Match + Search Annotations)

This pattern allows fine-grained reload control ‚Äî workloads only restart if the Secret/ConfigMap is both:

1. Referenced by the workload
1. Explicitly annotated with `match: true`

| Annotation                                | Applies To   | Description                                                                 |
|-------------------------------------------|--------------|-----------------------------------------------------------------------------|
| `reloader.stakater.com/search: &quot;true&quot;`    | Workload     | Enables search mode (only reloads if matching secrets/configMaps are found) |
| `reloader.stakater.com/match: &quot;true&quot;`     | ConfigMap/Secret | Marks the config/secret as eligible for reload in search mode              |

#### How it works

1. The workload must have: `reloader.stakater.com/search: &quot;true&quot;`
1. The ConfigMap or Secret must have: `reloader.stakater.com/match: &quot;true&quot;`
1. The resource (ConfigMap or Secret) must also be referenced in the workload (via env, `volumeMount`, etc.)

#### Use when

1. ‚úÖ You want to reload a workload only if it references a ConfigMap or Secret that has been explicitly tagged with `reloader.stakater.com/match: &quot;true&quot;`.
1. ‚úÖ Use this when you want full control over which shared or system-wide resources trigger reloads. Great in multi-tenant clusters or shared configs.

### 4. ‚öôÔ∏è Workload-Specific Rollout Strategy

By default, Reloader uses the **rollout** strategy ‚Äî it updates the pod template to trigger a new rollout. This works well in most cases, but it can cause problems if you&#039;re using GitOps tools like ArgoCD, which detect this as configuration drift.

To avoid that, you can switch to the **restart** strategy, which simply restarts the pod without changing the pod template.

```yaml
metadata:
  annotations:
    reloader.stakater.com/rollout-strategy: &quot;restart&quot;
```

| Value              | Behavior                                                        |
|--------------------|-----------------------------------------------------------------|
| `rollout` (default) | Updates pod template metadata to trigger a rollout             |
| `restart`           | Deletes the pod to restart it without patching the template    |

‚úÖ Use `restart` if:

1. You&#039;re using GitOps and want to avoid drift
1. You want a quick restart without changing the workload spec
1. Your platform restricts metadata changes

### 5. ‚ùó Annotation Behavior Rules &amp; Compatibility

- `reloader.stakater.com/auto` and `reloader.stakater.com/search` **cannot be used together** ‚Äî the `auto` annotation takes precedence.
- If both `auto` and its typed versions (`secret.reloader.stakater.com/auto`, `configmap.reloader.stakater.com/auto`) are used, **only one needs to be true** to trigger a reload.
- Setting `reloader.stakater.com/auto: &quot;false&quot;` explicitly disables reload for that workload.
- If `--auto-reload-all` is enabled on the controller:
    - All workloads are treated as if they have `auto: &quot;true&quot;` unless they explicitly set it to `&quot;false&quot;`.
    - Missing or unrecognized annotation values are treated as `&quot;false&quot;`.

### 6. üîî Alerting on Reload

Reloader can optionally **send alerts** whenever it triggers a rolling upgrade for a workload (e.g., `Deployment`, `StatefulSet`, etc.).

These alerts are sent to a configured **webhook endpoint**, which can be a generic receiver or services like Slack or Microsoft Teams.

To enable this feature, update the `reloader.env.secret` section in your `values.yaml` (when installing via Helm):

```yaml
reloader:
  env:
    secret:
      ALERT_ON_RELOAD: &quot;true&quot;                    # Enable alerting (default: false)
      ALERT_SINK: &quot;slack&quot;                        # Options: slack, teams, webhook (default: webhook)
      ALERT_WEBHOOK_URL: &quot;&lt;your-webhook-url&gt;&quot;    # Required if ALERT_ON_RELOAD is true
      ALERT_ADDITIONAL_INFO: &quot;Triggered by Reloader in staging environment&quot;
```

## üöÄ Installation

### 1. üì¶ Helm

Reloader can be installed in multiple ways depending on your Kubernetes setup and preference. Below are the supported methods:

```bash
helm repo add stakater https://stakater.github.io/stakater-charts
helm repo update
helm install reloader stakater/reloader
```

‚û°Ô∏è See full Helm configuration in the [chart README](./deployments/kubernetes/chart/reloader/README.md).

### 2. üìÑ Vanilla Manifests

Apply raw Kubernetes manifests directly:

```bash
kubectl apply -f https://raw.githubusercontent.com/stakater/Reloader/master/deployments/kubernetes/reloader.yaml
```

### 3. üß± Vanilla Kustomize

Use the built-in Kustomize support:

```bash
kubectl apply -k https://github.com/stakater/Reloader/deployments/kubernetes
```

### 4. üõ†Ô∏è Custom Kustomize Setup

You can create your own `kustomization.yaml` and use Reloader‚Äôs as a base:

```yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - https://github.com/stakater/Reloader/deployments/kubernetes

namespace: reloader
```

### 5. ‚öñÔ∏è Default Resource Requests and Limits

By default, Reloader is deployed with the following resource requests and limits:

```yaml
resources:
  limits:
    cpu: 150m
    memory: 512Mi
  requests:
    cpu: 10m
    memory: 128Mi
```

### 6. ‚öôÔ∏è Optional runtime configurations

These flags let you customize Reloader&#039;s behavior globally, at the Reloader controller level.

#### 1. üîÅ Reload Behavior

| Flag | Description |
|------|-------------|
| `--reload-on-create=true` | Reload workloads when a watched ConfigMap or Secret is created |
| `--reload-on-delete=true` | Reload workloads when a watched ConfigMap or Secret is deleted |
| `--auto-reload-all=true` | Automatically reload all workloads unless opted out (`auto: &quot;false&quot;`) |
| `--reload-strategy=env-vars` | Strategy to use for triggering reload (`env-vars` or `annotations`) |
| `--log-format=json` | Enable JSON-formatted logs for better machine readability |

#### 2. üö´ Resource Filtering

| Flag | Description |
|------|-------------|
| `--resources-to-ignore=configmaps` | Ignore ConfigMaps (only one type can be ignored at a time) |
| `--resources-to-ignore=secrets` | Ignore Secrets (cannot combine with configMaps) |
| `--resource-label-selector=key=value` | Only watch ConfigMaps/Secrets with matching labels |

&gt; **‚ö†Ô∏è Note:**  
&gt; Only **one** resource type can be ignored at a time.  
&gt; Trying to ignore **both `configmaps` and `secrets`** will cause an error in Reloader.  
&gt; ‚úÖ **Workaround:** Scale the Reloader deployment to `0` replicas if you want to disable it completely.

#### 3. üß© Namespace Filtering

| Flag | Description |
|------|-------------|
| `--namespace-selector=key=value` | Watch only namespaces with matching labels |
| `--namespaces-to-ignore=ns1,ns2` | Skip specific namespaces from being watched |

#### 4. üìù Annotation Key Overrides

These flags allow you to redefine annotation keys used in your workloads or resources:

| Flag | Overrides |
|------|-----------|
| `--auto-annotation` | Overrides `reloader.stakater.com/auto` |
| `--secret-auto-annotation` | Overrides `secret.reloader.stakater.com/auto` |
| `--configmap-auto-annotation` | Overrides `configmap.reloader.stakater.com/auto` |
| `--auto-search-annotation` | Overrides `reloader.stakater.com/search` |
| `--search-match-annotation` | Overrides `reloader.stakater.com/match` |
| `--secret-annotation` | Overrides `secret.reloader.stakater.com/reload` |
| `--configmap-annotation` | Overrides `configmap.reloader.stakater.com/reload` |

#### 5. üîÅ Reload Strategies

Reloader supports multiple strategies for triggering rolling updates when a watched `ConfigMap` or `Secret` changes. You can configure the strategy using the `--reload-strategy` flag.

##### üß© Available Strategies

| Strategy     | Description |
|--------------|-------------|
| `env-vars` (default) | Adds a dummy environment variable to any container referencing the changed resource (e.g., `Deployment`, `StatefulSet`, etc.). This forces Kubernetes to perform a rolling update. |
| `annotations` | Adds a `reloader.stakater.com/last-reloaded-from` annotation to the pod template metadata. Ideal for GitOps tools like ArgoCD, as it avoids triggering unwanted sync diffs. |

##### üîç Strategy Notes

- The `env-vars` strategy is the default and works in most setups.
- The `annotations` strategy is preferred in **GitOps environments** to prevent config drift in tools like ArgoCD or Flux.
- In `annotations` mode, a `ConfigMap` or `Secret` that is deleted and re-created will still trigger a reload (since previous state is not tracked).

## Compatibility

Reloader is compatible with Kubernetes &gt;= 1.19

## Help

### Documentation

The Reloader documentation can be viewed from [the doc site](https://docs.stakater.com/reloader/). The doc source is in the [docs](./docs/) folder.

### Have a question?

File a GitHub [issue](https://github.com/stakater/Reloader/issues).

### Talk to us on Slack

Join and talk to us on Slack for discussing Reloader:

[![Join Slack](https://stakater.github.io/README/stakater-join-slack-btn.png)](https://slack.stakater.com/)
[![Chat](https://stakater.github.io/README/stakater-chat-btn.png)](https://stakater-community.slack.com/messages/CC5S05S12)

## Contributing

### Bug Reports &amp; Feature Requests

Please use the [issue tracker](https://github.com/stakater/Reloader/issues) to report any bugs or file feature requests.

### Developing

1. Deploy Reloader
1. Run `okteto up` to activate your development container
1. `make build`
1. `./Reloader`

PRs are welcome. In general, we follow the &quot;fork-and-pull&quot; Git workflow:

1. **Fork** the repo on GitHub
1. **Clone** the project to your own machine
1. **Commit** changes to your own branch
1. **Push** your work back up to your fork
1. Submit a **Pull request** so that we can review your changes

**NOTE:** Be sure to merge the latest from &quot;upstream&quot; before making a pull request!

## Release Processes

_Repository GitHub releases_: As requested by the community in [issue 685](https://github.com/stakater/Reloader/issues/685), Reloader is now based on a manual release process. Releases are no longer done on every merged PR to the main branch, but manually on request.

To make a GitHub release:

1. Code owners create a release branch `release-vX.Y.Z`
1. Code owners run a dispatch mode workflow to automatically generate version and manifests on the release branch
1. A PR is created to bump the image version on the release branch, example: [PR-798](https://github.com/stakater/Reloader/pull/798)
1. Code owners create a GitHub release with tag `vX.Y.Z` and target branch `release-vX.Y.Z`, which triggers creation of images
1. Code owners create a PR to update the Helm chart version, example: [PR-846](https://github.com/stakater/Reloader/pull/846)

_Repository git tagging_: Push to the main branch will create a merge-image and merge-tag named `merge-${{ github.event.number }}`, for example `merge-800` when pull request number 800 is merged.

## Changelog

View the [releases page](https://github.com/stakater/Reloader/releases) to see what has changed in each release.

## License

Apache2 ¬© [Stakater][website]

## About Stakater

[![Get started with Stakater](https://stakater.github.io/README/stakater-github-banner.png)](https://stakater.com/?utm_source=Reloader&amp;utm_medium=github)

`Reloader` is maintained by [Stakater][website]. Like it? Please let us know at [hello@stakater.com](hello@stakater.com)

See [our other projects](https://github.com/stakater) or contact us in case of professional services and queries on [hello@stakater.com](hello@stakater.com)

[website]: https://stakater.com
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[swaggo/swag]]></title>
            <link>https://github.com/swaggo/swag</link>
            <guid>https://github.com/swaggo/swag</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[Automatically generate RESTful API documentation with Swagger 2.0 for Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/swaggo/swag">swaggo/swag</a></h1>
            <p>Automatically generate RESTful API documentation with Swagger 2.0 for Go.</p>
            <p>Language: Go</p>
            <p>Stars: 11,573</p>
            <p>Forks: 1,249</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># swag

üåç *[English](README.md) ‚àô [ÁÆÄ‰Ωì‰∏≠Êñá](README_zh-CN.md) ‚àô [Portugu√™s](README_pt.md)*

&lt;img align=&quot;right&quot; width=&quot;180px&quot; src=&quot;https://raw.githubusercontent.com/swaggo/swag/master/assets/swaggo.png&quot;&gt;

[![Build Status](https://github.com/swaggo/swag/actions/workflows/ci.yml/badge.svg?branch=master)](https://github.com/features/actions)
[![Coverage Status](https://img.shields.io/codecov/c/github/swaggo/swag/master.svg)](https://codecov.io/gh/swaggo/swag)
[![Go Report Card](https://goreportcard.com/badge/github.com/swaggo/swag)](https://goreportcard.com/report/github.com/swaggo/swag)
[![codebeat badge](https://codebeat.co/badges/71e2f5e5-9e6b-405d-baf9-7cc8b5037330)](https://codebeat.co/projects/github-com-swaggo-swag-master)
[![Go Doc](https://godoc.org/github.com/swaggo/swagg?status.svg)](https://godoc.org/github.com/swaggo/swag)
[![Backers on Open Collective](https://opencollective.com/swag/backers/badge.svg)](#backers)
[![Sponsors on Open Collective](https://opencollective.com/swag/sponsors/badge.svg)](#sponsors) [![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fswaggo%2Fswag.svg?type=shield)](https://app.fossa.io/projects/git%2Bgithub.com%2Fswaggo%2Fswag?ref=badge_shield)
[![Release](https://img.shields.io/github/release/swaggo/swag.svg?style=flat-square)](https://github.com/swaggo/swag/releases)


Swag converts Go annotations to Swagger Documentation 2.0. We&#039;ve created a variety of plugins for popular [Go web frameworks](#supported-web-frameworks). This allows you to quickly integrate with an existing Go project (using Swagger UI).

## Contents
 - [Getting started](#getting-started)
 - [Supported Web Frameworks](#supported-web-frameworks)
 - [How to use it with Gin](#how-to-use-it-with-gin)
 - [The swag formatter](#the-swag-formatter)
 - [Implementation Status](#implementation-status)
 - [Declarative Comments Format](#declarative-comments-format)
	- [General API Info](#general-api-info)
	- [API Operation](#api-operation)
	- [Security](#security)
 - [Examples](#examples)
	- [Descriptions over multiple lines](#descriptions-over-multiple-lines)
	- [User defined structure with an array type](#user-defined-structure-with-an-array-type)
	- [Function scoped struct declaration](#function-scoped-struct-declaration)
	- [Model composition in response](#model-composition-in-response)
        - [Add request headers](#add-request-headers)
	- [Add response headers](#add-response-headers)
	- [Use multiple path params](#use-multiple-path-params)
	- [Example value of struct](#example-value-of-struct)
	- [SchemaExample of body](#schemaexample-of-body)
	- [Description of struct](#description-of-struct)
	- [Use swaggertype tag to supported custom type](#use-swaggertype-tag-to-supported-custom-type)
	- [Use global overrides to support a custom type](#use-global-overrides-to-support-a-custom-type)
	- [Use swaggerignore tag to exclude a field](#use-swaggerignore-tag-to-exclude-a-field)
	- [Add extension info to struct field](#add-extension-info-to-struct-field)
	- [Rename model to display](#rename-model-to-display)
	- [How to use security annotations](#how-to-use-security-annotations)
	- [Add a description for enum items](#add-a-description-for-enum-items)
	- [Generate only specific docs file types](#generate-only-specific-docs-file-types)
    - [How to use Go generic types](#how-to-use-generics)
- [About the Project](#about-the-project)

## Getting started

1. Add comments to your API source code, See [Declarative Comments Format](#declarative-comments-format).

2. Install swag by using:
```sh
go install github.com/swaggo/swag/cmd/swag@latest
```
To build from source you need [Go](https://golang.org/dl/) (1.19 or newer).

Alternatively you can run the docker image:
```sh
docker run --rm -v $(pwd):/code ghcr.io/swaggo/swag:latest
```

Or download a pre-compiled binary from the [release page](https://github.com/swaggo/swag/releases).

3. Run `swag init` in the project&#039;s root folder which contains the `main.go` file. This will parse your comments and generate the required files (`docs` folder and `docs/docs.go`).
```sh
swag init
```

  Make sure to import the generated `docs/docs.go` so that your specific configuration gets `init`&#039;ed. If your General API annotations do not live in `main.go`, you can let swag know with `-g` flag.
  ```go
  import _ &quot;example-module-name/docs&quot;
  ```
  ```sh
  swag init -g http/api.go
  ```

4. (optional) Use `swag fmt` format the SWAG comment. (Please upgrade to the latest version)

  ```sh
  swag fmt
  ```

## swag cli

```sh
swag init -h
NAME:
   swag init - Create docs.go

USAGE:
   swag init [command options] [arguments...]

OPTIONS:
   --quiet, -q                            Make the logger quiet. (default: false)
   --generalInfo value, -g value          Go file path in which &#039;swagger general API Info&#039; is written (default: &quot;main.go&quot;)
   --dir value, -d value                  Directories you want to parse,comma separated and general-info file must be in the first one (default: &quot;./&quot;)
   --exclude value                        Exclude directories and files when searching, comma separated
   --propertyStrategy value, -p value     Property Naming Strategy like snakecase,camelcase,pascalcase (default: &quot;camelcase&quot;)
   --output value, -o value               Output directory for all the generated files(swagger.json, swagger.yaml and docs.go) (default: &quot;./docs&quot;)
   --outputTypes value, --ot value        Output types of generated files (docs.go, swagger.json, swagger.yaml) like go,json,yaml (default: &quot;go,json,yaml&quot;)
   --parseVendor                          Parse go files in &#039;vendor&#039; folder, disabled by default (default: false)
   --parseDependency, --pd                Parse go files inside dependency folder, disabled by default (default: false)
   --parseDependencyLevel, --pdl          Enhancement of &#039;--parseDependency&#039;, parse go files inside dependency folder, 0 disabled, 1 only parse models, 2 only parse operations, 3 parse all (default: 0)
   --markdownFiles value, --md value      Parse folder containing markdown files to use as description, disabled by default
   --codeExampleFiles value, --cef value  Parse folder containing code example files to use for the x-codeSamples extension, disabled by default
   --parseInternal                        Parse go files in internal packages, disabled by default (default: false)
   --generatedTime                        Generate timestamp at the top of docs.go, disabled by default (default: false)
   --parseDepth value                     Dependency parse depth (default: 100)
   --requiredByDefault                    Set validation required for all fields by default (default: false)
   --instanceName value                   This parameter can be used to name different swagger document instances. It is optional.
   --overridesFile value                  File to read global type overrides from. (default: &quot;.swaggo&quot;)
   --parseGoList                          Parse dependency via &#039;go list&#039; (default: true)
   --tags value, -t value                 A comma-separated list of tags to filter the APIs for which the documentation is generated.Special case if the tag is prefixed with the &#039;!&#039; character then the APIs with that tag will be excluded
   --templateDelims value, --td value     Provide custom delimiters for Go template generation. The format is leftDelim,rightDelim. For example: &quot;[[,]]&quot;
   --collectionFormat value, --cf value   Set default collection format (default: &quot;csv&quot;)
   --state value                          Initial state for the state machine (default: &quot;&quot;), @HostState in root file, @State in other files
   --parseFuncBody                        Parse API info within body of functions in go files, disabled by default (default: false)
   --help, -h                             show help (default: false)
```

```bash
swag fmt -h
NAME:
   swag fmt - format swag comments

USAGE:
   swag fmt [command options] [arguments...]

OPTIONS:
   --dir value, -d value          Directories you want to parse,comma separated and general-info file must be in the first one (default: &quot;./&quot;)
   --exclude value                Exclude directories and files when searching, comma separated
   --generalInfo value, -g value  Go file path in which &#039;swagger general API Info&#039; is written (default: &quot;main.go&quot;)
   --help, -h                     show help (default: false)

```

## Supported Web Frameworks

- [gin](http://github.com/swaggo/gin-swagger)
- [echo](http://github.com/swaggo/echo-swagger)
- [buffalo](https://github.com/swaggo/buffalo-swagger)
- [net/http](https://github.com/swaggo/http-swagger)
- [gorilla/mux](https://github.com/swaggo/http-swagger)
- [go-chi/chi](https://github.com/swaggo/http-swagger)
- [flamingo](https://github.com/i-love-flamingo/swagger)
- [fiber](https://github.com/gofiber/swagger)
- [atreugo](https://github.com/Nerzal/atreugo-swagger)
- [hertz](https://github.com/hertz-contrib/swagger)

## How to use it with Gin

Find the example source code [here](https://github.com/swaggo/swag/tree/master/example/celler).

Finish the steps in [Getting started](#getting-started)
1. After using `swag init` to generate Swagger 2.0 docs, import the following packages:
```go
import &quot;github.com/swaggo/gin-swagger&quot; // gin-swagger middleware
import &quot;github.com/swaggo/files&quot; // swagger embed files
```

2. Add [General API](#general-api-info) annotations in `main.go` code:

```go
// @title           Swagger Example API
// @version         1.0
// @description     This is a sample server celler server.
// @termsOfService  http://swagger.io/terms/

// @contact.name   API Support
// @contact.url    http://www.swagger.io/support
// @contact.email  support@swagger.io

// @license.name  Apache 2.0
// @license.url   http://www.apache.org/licenses/LICENSE-2.0.html

// @host      localhost:8080
// @BasePath  /api/v1

// @securityDefinitions.basic  BasicAuth

// @externalDocs.description  OpenAPI
// @externalDocs.url          https://swagger.io/resources/open-api/
func main() {
	r := gin.Default()

	c := controller.NewController()

	v1 := r.Group(&quot;/api/v1&quot;)
	{
		accounts := v1.Group(&quot;/accounts&quot;)
		{
			accounts.GET(&quot;:id&quot;, c.ShowAccount)
			accounts.GET(&quot;&quot;, c.ListAccounts)
			accounts.POST(&quot;&quot;, c.AddAccount)
			accounts.DELETE(&quot;:id&quot;, c.DeleteAccount)
			accounts.PATCH(&quot;:id&quot;, c.UpdateAccount)
			accounts.POST(&quot;:id/images&quot;, c.UploadAccountImage)
		}
    //...
	}
	r.GET(&quot;/swagger/*any&quot;, ginSwagger.WrapHandler(swaggerFiles.Handler))
	r.Run(&quot;:8080&quot;)
}
//...
```

Additionally some general API info can be set dynamically. The generated code package `docs` exports `SwaggerInfo` variable which we can use to set the title, description, version, host and base path programmatically. Example using Gin:

```go
package main

import (
	&quot;github.com/gin-gonic/gin&quot;
	&quot;github.com/swaggo/files&quot;
	&quot;github.com/swaggo/gin-swagger&quot;

	&quot;./docs&quot; // docs is generated by Swag CLI, you have to import it.
)

// @contact.name   API Support
// @contact.url    http://www.swagger.io/support
// @contact.email  support@swagger.io

// @license.name  Apache 2.0
// @license.url   http://www.apache.org/licenses/LICENSE-2.0.html
func main() {

	// programmatically set swagger info
	docs.SwaggerInfo.Title = &quot;Swagger Example API&quot;
	docs.SwaggerInfo.Description = &quot;This is a sample server Petstore server.&quot;
	docs.SwaggerInfo.Version = &quot;1.0&quot;
	docs.SwaggerInfo.Host = &quot;petstore.swagger.io&quot;
	docs.SwaggerInfo.BasePath = &quot;/v2&quot;
	docs.SwaggerInfo.Schemes = []string{&quot;http&quot;, &quot;https&quot;}

	r := gin.New()

	// use ginSwagger middleware to serve the API docs
	r.GET(&quot;/swagger/*any&quot;, ginSwagger.WrapHandler(swaggerFiles.Handler))

	r.Run()
}
```

3. Add [API Operation](#api-operation) annotations in `controller` code

``` go
package controller

import (
    &quot;fmt&quot;
    &quot;net/http&quot;
    &quot;strconv&quot;

    &quot;github.com/gin-gonic/gin&quot;
    &quot;github.com/swaggo/swag/example/celler/httputil&quot;
    &quot;github.com/swaggo/swag/example/celler/model&quot;
)

// ShowAccount godoc
// @Summary      Show an account
// @Description  get string by ID
// @Tags         accounts
// @Accept       json
// @Produce      json
// @Param        id   path      int  true  &quot;Account ID&quot;
// @Success      200  {object}  model.Account
// @Failure      400  {object}  httputil.HTTPError
// @Failure      404  {object}  httputil.HTTPError
// @Failure      500  {object}  httputil.HTTPError
// @Router       /accounts/{id} [get]
func (c *Controller) ShowAccount(ctx *gin.Context) {
  id := ctx.Param(&quot;id&quot;)
  aid, err := strconv.Atoi(id)
  if err != nil {
    httputil.NewError(ctx, http.StatusBadRequest, err)
    return
  }
  account, err := model.AccountOne(aid)
  if err != nil {
    httputil.NewError(ctx, http.StatusNotFound, err)
    return
  }
  ctx.JSON(http.StatusOK, account)
}

// ListAccounts godoc
// @Summary      List accounts
// @Description  get accounts
// @Tags         accounts
// @Accept       json
// @Produce      json
// @Param        q    query     string  false  &quot;name search by q&quot;  Format(email)
// @Success      200  {array}   model.Account
// @Failure      400  {object}  httputil.HTTPError
// @Failure      404  {object}  httputil.HTTPError
// @Failure      500  {object}  httputil.HTTPError
// @Router       /accounts [get]
func (c *Controller) ListAccounts(ctx *gin.Context) {
  q := ctx.Request.URL.Query().Get(&quot;q&quot;)
  accounts, err := model.AccountsAll(q)
  if err != nil {
    httputil.NewError(ctx, http.StatusNotFound, err)
    return
  }
  ctx.JSON(http.StatusOK, accounts)
}
//...
```

```console
swag init
```

4. Run your app, and browse to http://localhost:8080/swagger/index.html. You will see Swagger 2.0 Api documents as shown below:

![swagger_index.html](https://raw.githubusercontent.com/swaggo/swag/master/assets/swagger-image.png)

## The swag formatter

The Swag Comments can be automatically formatted, just like &#039;go fmt&#039;.
Find the result of formatting [here](https://github.com/swaggo/swag/tree/master/example/celler).

Usage:
```shell
swag fmt
```

Exclude folderÔºö
```shell
swag fmt -d ./ --exclude ./internal
```

When using `swag fmt`, you need to ensure that you have a doc comment for the function to ensure correct formatting.
This is due to `swag fmt` indenting swag comments with tabs, which is only allowed *after* a standard doc comment.

For example, use

```go
// ListAccounts lists all existing accounts
//
//  @Summary      List accounts
//  @Description  get accounts
//  @Tags         accounts
//  @Accept       json
//  @Produce      json
//  @Param        q    query     string  false  &quot;name search by q&quot;  Format(email)
//  @Success      200  {array}   model.Account
//  @Failure      400  {object}  httputil.HTTPError
//  @Failure      404  {object}  httputil.HTTPError
//  @Failure      500  {object}  httputil.HTTPError
//  @Router       /accounts [get]
func (c *Controller) ListAccounts(ctx *gin.Context) {
```

## Implementation Status

[Swagger 2.0 document](https://swagger.io/docs/specification/2-0/basic-structure/)

- [x] Basic Structure
- [x] API Host and Base Path
- [x] Paths and Operations
- [x] Describing Parameters
- [x] Describing Request Body
- [x] Describing Responses
- [x] MIME Types
- [x] Authentication
  - [x] Basic Authentication
  - [x] API Keys
- [x] Adding Examples
- [x] File Upload
- [x] Enums
- [x] Grouping Operations With Tags
- [ ] Swagger Extensions

# Declarative Comments Format

## General API Info

**Example**
[celler/main.go](https://github.com/swaggo/swag/blob/master/example/celler/main.go)

| annotation  | description                                | example                         |
|-------------|--------------------------------------------|---------------------------------|
| title       | **Required.** The title of the application.| // @title Swagger Example API   |
| version     | **Required.** Provides the version of the application API.| // @version 1.0  |
| description | A short description of the application.    |// @description This is a sample server celler server.         																 |
| tag.name    | Name of a tag.| // @tag.name This is the name of the tag                     |
| tag.description   | Description of the tag  | // @tag.description Cool Description         |
| tag.docs.url      | Url of the external Documentation of the tag | // @tag.docs.url https://example.com|
| tag.docs.description  | Description of the external Documentation of the tag| // @tag.docs.description Best example documentation |
| termsOfService | The Terms of Service for the API.| // @termsOfService http://swagger.io/terms/                     |
| contact.name | The contact information for the exposed API.| // @contact.name API Support  |
| contact.url  | The URL pointing to the contact information. MUST be in the format of a URL.  | // @contact.url http://www.swagger.io/support|
| contact.email| The email address of the contact person/organization. MUST be in the format of an email address.| // @contact.email support@swagger.io                                   |
| license.name | **Required.** The license name used for the API.|// @license.name Apache 2.0|
| license.url  | A URL to the license used for the API. MUST be in the format of a URL.                       | // @license.url http://www.apache.org/licenses/LICENSE-2.0.html |
| host        | The host (name or ip) serving the API.     | // @host localhost:8080         |
| BasePath    | The base path on which the API is served. | // @BasePath /api/v1             |
| accept      | A list of MIME types the APIs can consume. Note that Accept only affects operations with a request body, such as POST, PUT and PATCH.  Value MUST be as described under [Mime Types](#mime-types).                     | // @accept json |
| produce     | A list of MIME types the APIs can produce. Value MUST be as described under [Mime Types](#mime-types).                     | // @produce json |
| query.collection.format | The default collection(array) param format in query,enums:csv,multi,pipes,tsv,ssv. If not set, csv is the default.| // @query.collection.format multi
| schemes     | The transfer protocol for the operation that separated by spaces. | // @schemes http https |
| externalDocs.description | Description of the external document. | // @externalDocs.description OpenAPI |
| externalDocs.url         | URL of the external document. | // @externalDocs.url https://swagger.io/resources/open-api/ |
| x-name      | The extension key, must be start by x- and take only json value | // @x-example-key {&quot;key&quot;: &quot;value&quot;} |

### Using markdown descriptions
When a short string in your documentation is insufficient, or you need images, code examples and things like that you may want to use markdown descriptions. In order to use markdown descriptions use the following annotations.


| annotation  | description                                | example                         |
|-------------|--------------------------------------------|---------------------------------|
| title       | **Required.** The title of the application.| // @title Swagger Example API   |
| version     | **Required.** Provides the version of the application API.| // @version 1.0  |
| description.markdown  | A short description of the application. Parsed from the api.md file. This is an alternative to @description    |// @description.markdown No value needed, this parses the description from api.md         																 |
| tag.name    | Name of a tag.| // @tag.name This is the name of the tag                     |
| tag.description.markdown   | Description of the tag this is an alternative to tag.description. The description will be read from a file named like tagname.md  | // @tag.description.markdown         |
| tag.x-name  | The extension key, must be start by x- and take only string value | // @x-example-key value |


## API Operation

**Example**
[celler/controller](https://github.com/swaggo/swag/tree/master/example/celler/controller)


| annotation           | description                                                                                              

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hashicorp/terraform-provider-azurerm]]></title>
            <link>https://github.com/hashicorp/terraform-provider-azurerm</link>
            <guid>https://github.com/hashicorp/terraform-provider-azurerm</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[Terraform provider for Azure Resource Manager]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hashicorp/terraform-provider-azurerm">hashicorp/terraform-provider-azurerm</a></h1>
            <p>Terraform provider for Azure Resource Manager</p>
            <p>Language: Go</p>
            <p>Stars: 4,708</p>
            <p>Forks: 4,741</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://terraform.io&quot;&gt;
    &lt;img src=&quot;.github/tf.png&quot; alt=&quot;Terraform logo&quot; title=&quot;Terraform&quot; align=&quot;left&quot; height=&quot;50&quot; /&gt;
&lt;/a&gt;

# Terraform Provider for Azure (Resource Manager)

The AzureRM Terraform Provider allows managing resources within Azure Resource Manager.

When using version 4.0 of the AzureRM Provider we recommend using the latest version of Terraform Core ([the latest version can be found here](https://developer.hashicorp.com/terraform/install)). 

* [Terraform Website](https://www.terraform.io)
* [AzureRM Provider Documentation](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs)
* [AzureRM Provider Usage Examples](https://github.com/hashicorp/terraform-provider-azurerm/tree/main/examples)
* [Slack Workspace for Contributors](https://terraform-azure.slack.com) ([Request Invite](https://join.slack.com/t/terraform-azure/shared_invite/enQtNDMzNjQ5NzcxMDc3LWNiY2ZhNThhNDgzNmY0MTM0N2MwZjE4ZGU0MjcxYjUyMzRmN2E5NjZhZmQ0ZTA1OTExMGNjYzA4ZDkwZDYxNDE))

## Usage Example

```hcl
# 1. Specify the version of the AzureRM Provider to use
terraform {
  required_providers {
    azurerm = {
      source = &quot;hashicorp/azurerm&quot;
      version = &quot;=3.0.1&quot;
    }
  }
}

# 2. Configure the AzureRM Provider
provider &quot;azurerm&quot; {
  # The AzureRM Provider supports authenticating using via the Azure CLI, a Managed Identity
  # and a Service Principal. More information on the authentication methods supported by
  # the AzureRM Provider can be found here:
  # https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs#authenticating-to-azure

  # The features block allows changing the behaviour of the Azure Provider, more
  # information can be found here:
  # https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/guides/features-block
  features {}
}

# 3. Create a resource group
resource &quot;azurerm_resource_group&quot; &quot;example&quot; {
  name     = &quot;example-resources&quot;
  location = &quot;West Europe&quot;
}

# 4. Create a virtual network within the resource group
resource &quot;azurerm_virtual_network&quot; &quot;example&quot; {
  name                = &quot;example-network&quot;
  resource_group_name = azurerm_resource_group.example.name
  location            = azurerm_resource_group.example.location
  address_space       = [&quot;10.0.0.0/16&quot;]
}
```

* [Usage documentation for the AzureRM Provider can be found in the Terraform Registry](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs).
* [Learn more about Terraform and the AzureRM Provider on HashiCorp Learn](https://learn.hashicorp.com/collections/terraform/azure-get-started).
* [Additional examples can be found in the `./examples` folder within this repository](https://github.com/hashicorp/terraform-provider-azurerm/tree/main/examples).

## Developing &amp; Contributing to the Provider

The [DEVELOPER.md](DEVELOPER.md) file is a basic outline on how to build and develop the provider while more detailed guides geared towards contributors can be found in the [`/contributing`](https://github.com/hashicorp/terraform-provider-azurerm/tree/main/contributing) directory of this repository.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[nektos/act]]></title>
            <link>https://github.com/nektos/act</link>
            <guid>https://github.com/nektos/act</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[Run your GitHub Actions locally üöÄ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nektos/act">nektos/act</a></h1>
            <p>Run your GitHub Actions locally üöÄ</p>
            <p>Language: Go</p>
            <p>Stars: 59,657</p>
            <p>Forks: 1,513</p>
            <p>Stars today: 199 stars today</p>
            <h2>README</h2><pre>![act-logo](https://raw.githubusercontent.com/wiki/nektos/act/img/logo-150.png)

# Overview [![push](https://github.com/nektos/act/workflows/push/badge.svg?branch=master&amp;event=push)](https://github.com/nektos/act/actions) [![Join the chat at https://gitter.im/nektos/act](https://badges.gitter.im/nektos/act.svg)](https://gitter.im/nektos/act?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge) [![Go Report Card](https://goreportcard.com/badge/github.com/nektos/act)](https://goreportcard.com/report/github.com/nektos/act) [![awesome-runners](https://img.shields.io/badge/listed%20on-awesome--runners-blue.svg)](https://github.com/jonico/awesome-runners)

&gt; &quot;Think globally, `act` locally&quot;

Run your [GitHub Actions](https://developer.github.com/actions/) locally! Why would you want to do this? Two reasons:

- **Fast Feedback** - Rather than having to commit/push every time you want to test out the changes you are making to your `.github/workflows/` files (or for any changes to embedded GitHub actions), you can use `act` to run the actions locally. The [environment variables](https://help.github.com/en/actions/configuring-and-managing-workflows/using-environment-variables#default-environment-variables) and [filesystem](https://help.github.com/en/actions/reference/virtual-environments-for-github-hosted-runners#filesystems-on-github-hosted-runners) are all configured to match what GitHub provides.
- **Local Task Runner** - I love [make](&lt;https://en.wikipedia.org/wiki/Make_(software)&gt;). However, I also hate repeating myself. With `act`, you can use the GitHub Actions defined in your `.github/workflows/` to replace your `Makefile`!

&gt; [!TIP]
&gt; **Now Manage and Run Act Directly From VS Code!**&lt;br/&gt;
&gt; Check out the [GitHub Local Actions](https://sanjulaganepola.github.io/github-local-actions-docs/) Visual Studio Code extension which allows you to leverage the power of `act` to run and test workflows locally without leaving your editor.

# How Does It Work?

When you run `act` it reads in your GitHub Actions from `.github/workflows/` and determines the set of actions that need to be run. It uses the Docker API to either pull or build the necessary images, as defined in your workflow files and finally determines the execution path based on the dependencies that were defined. Once it has the execution path, it then uses the Docker API to run containers for each action based on the images prepared earlier. The [environment variables](https://help.github.com/en/actions/configuring-and-managing-workflows/using-environment-variables#default-environment-variables) and [filesystem](https://docs.github.com/en/actions/using-github-hosted-runners/about-github-hosted-runners#file-systems) are all configured to match what GitHub provides.

Let&#039;s see it in action with a [sample repo](https://github.com/cplee/github-actions-demo)!

![Demo](https://raw.githubusercontent.com/wiki/nektos/act/quickstart/act-quickstart-2.gif)

# Act User Guide

Please look at the [act user guide](https://nektosact.com) for more documentation.

# Support

Need help? Ask on [Gitter](https://gitter.im/nektos/act)!

# Contributing

Want to contribute to act? Awesome! Check out the [contributing guidelines](CONTRIBUTING.md) to get involved.

## Manually building from source

- Install Go tools 1.20+ - (&lt;https://golang.org/doc/install&gt;)
- Clone this repo `git clone git@github.com:nektos/act.git`
- Run unit tests with `make test`
- Build and install: `make install`
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-collector-contrib]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-collector-contrib</link>
            <guid>https://github.com/open-telemetry/opentelemetry-collector-contrib</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Contrib repository for the OpenTelemetry Collector]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-collector-contrib">open-telemetry/opentelemetry-collector-contrib</a></h1>
            <p>Contrib repository for the OpenTelemetry Collector</p>
            <p>Language: Go</p>
            <p>Stars: 3,493</p>
            <p>Forks: 2,684</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>---

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/getting-started/&quot;&gt;Getting Started&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md&quot;&gt;Getting Involved&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;Getting In Touch&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/actions/workflows/build-and-test.yml?query=branch%3Amain&quot;&gt;
    &lt;img alt=&quot;Build Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector-contrib/build-and-test.yml?branch=main&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector-contrib&quot;&gt;
    &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/branch/main/&quot;&gt;
    &lt;img alt=&quot;Codecov Status&quot; src=&quot;https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest by date including pre-releases)&quot; src=&quot;https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector-contrib?include_prereleases&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;img alt=&quot;Beta&quot; src=&quot;https://img.shields.io/badge/status-beta-informational?style=for-the-badge&amp;logo=data:image/png;base64,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&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/vision.md&quot;&gt;Vision&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/observability.md&quot;&gt;Observability&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md&quot;&gt;Security&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
  &lt;/strong&gt;
&lt;/p&gt;

---

# OpenTelemetry Collector Contrib

This is a repository for OpenTelemetry Collector components that are not suitable for the  [core repository](https://github.com/open-telemetry/opentelemetry-collector) of the collector. 

The official distributions, core and contrib, are available as part of the [opentelemetry-collector-releases](https://github.com/open-telemetry/opentelemetry-collector-releases) repository. Some of the components in this repository are part of the &quot;core&quot; distribution, such as the Jaeger and Prometheus components, but most of the components here are only available as part of the &quot;contrib&quot; distribution. Users of the OpenTelemetry Collector are also encouraged to build their own custom distributions with the [OpenTelemetry Collector Builder](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder), using the components they need from the core repository, the contrib repository, and possibly third-party or internal repositories.

Each component has its own support levels, as defined in the following sections. For each signal that a component supports, there&#039;s a stability level, setting the right expectations. It is possible then that a component will be **Stable** for traces but **Alpha** for metrics and **Development** for logs.

## Stability levels

Stability level for components in this repository follow the [definitions](https://github.com/open-telemetry/opentelemetry-collector#stability-levels) from the OpenTelemetry Collector repository.

## Gated features

Some features are hidden behind feature gates before they are part of the main code path for the component. Note that the feature gates themselves might be at different [lifecycle stages](https://github.com/open-telemetry/opentelemetry-collector/tree/main/featuregate#feature-lifecycle).

## Support

Each component is supported either by the community of OpenTelemetry Collector Contrib maintainers, as defined by the GitHub group [@open-telemetry/collector-contrib-maintainer](https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer), or by specific vendors. See the individual README files for information about the specific components.

The OpenTelemetry Collector Contrib maintainers may at any time downgrade specific components if they are deemed unmaintained or if they pose a risk to the repository and/or binary distribution.

Even though the OpenTelemetry Collector Contrib maintainers are ultimately responsible for the components hosted here, actual support will likely be provided by individual contributors, typically a code owner for the specific component.

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md).

Triagers ([@open-telemetry/collector-contrib-triagers](https://github.com/orgs/open-telemetry/teams/collector-contrib-triagers))

- [Benedikt Bongartz](https://github.com/frzifus), Red Hat
- [Braydon Kains](https://github.com/braydonk), Google
- [Florian Bacher](https://github.com/bacherfl), Dynatrace
- [Israel Blancas](https://github.com/iblancasa), Coralogix
- [James Moessis](https://github.com/jamesmoessis), Atlassian
- [Jared Tan](https://github.com/JaredTan95), DaoCloud
- [Murphy Chen](https://github.com/Frapschen), DaoCloud
- [Ondrej Dubaj](https://github.com/odubajDT), Dynatrace
- [Paulo Janotti](https://github.com/pjanotti), Splunk
- [Vihas Makwana](https://github.com/VihasMakwana), Elastic
- Actively seeking contributors to triage issues

Emeritus Triagers:

- [Alolita Sharma](https://github.com/alolita)
- [Gabriel Aszalos](https://github.com/gbbr)
- [Goutham Veeramachaneni](https://github.com/gouthamve)
- [Punya Biswal](https://github.com/punya)
- [Steve Flanders](https://github.com/flands)

Approvers ([@open-telemetry/collector-contrib-approvers](https://github.com/orgs/open-telemetry/teams/collector-contrib-approvers)):

- [Arthur Silva Sens](https://github.com/ArthurSens), Grafana Labs
- [Christos Markou](https://github.com/ChrsMark), Elastic
- [Curtis Robert](https://github.com/crobert-1), Splunk
- [David Ashpole](https://github.com/dashpole), Google (on leave)
- [Edmo Vamerlatti Costa](https://github.com/edmocosta), Elastic
- [Matt Wear](https://github.com/mwear), Lightstep
- [Sam DeHaan](https://github.com/dehaansa), Grafana Labs
- [Ziqi Zhao](https://github.com/fatsheep9146), Alibaba

Emeritus Approvers:

- [Anthony Mirabella](https://github.com/Aneurysm9)
- [Bryan Aguilar](https://github.com/bryan-aguilar)
- [Przemek Maciolek](https://github.com/pmm-sumo)
- [Ruslan Kovalov](https://github.com/kovrus)

Maintainers ([@open-telemetry/collector-contrib-maintainer](https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer)):

- [Alex Boten](https://github.com/codeboten), Honeycomb
- [Andrzej Stencel](https://github.com/andrzej-stencel), Elastic
- [Antoine Toulme](https://github.com/atoulme), Splunk
- [Bogdan Drutu](https://github.com/bogdandrutu), Snowflake
- [Daniel Jaglowski](https://github.com/djaglowski), observIQ
- [Dmitrii Anoshin](https://github.com/dmitryax), Splunk
- [Evan Bradley](https://github.com/evan-bradley), Dynatrace
- [Pablo Baeyens](https://github.com/mx-psi), DataDog
- [Sean Marciniak](https://github.com/MovieStoreGuy), Splunk
- [Tyler Helmuth](https://github.com/TylerHelmuth), Honeycomb
- [Yang Song](https://github.com/songy23), DataDog

Emeritus Maintainers

- [Juraci Paix√£o Kr√∂hling](https://github.com/jpkrohling), OllyGarden
- [Tigran Najaryan](https://github.com/tigrannajaryan)

Learn more about roles in the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md).

### No Over-Representation

A community member cannot be promoted to be a Collector contrib maintainer if, after their promotion, the resulting maintainers group has more than one-fourth (25%) of the members affiliated with the same employer. Job changes and similar events might result in over-representation, and no new maintainers from the same company can be promoted until representation is balanced again. In the event of confusion or concern, the OpenTelemetry Collector SIG will defer to the CNCF definition of &quot;same employer&quot;.

## PRs and Reviews

When creating a PR please follow the process [described
here](https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md#how-to-structure-prs-to-get-expedient-reviews).

New PRs will be automatically associated with the reviewers based on
[CODEOWNERS](.github/CODEOWNERS). PRs will be also automatically assigned to one of the
maintainers or approvers for facilitation.

The facilitator is responsible for helping the PR author and reviewers to make progress
or if progress cannot be made for closing the PR.

If the reviewers do not have approval rights the facilitator is also responsible
for the official approval that is required for the PR to be merged and if the facilitator
is a maintainer they are responsible for merging the PR as well.

The facilitator is not required to perform a thorough review, but they are encouraged to
enforce Collector best practices and consistency across the codebase and component
behavior. The facilitators will typically rely on codeowner&#039;s detailed review of the code
when making the final approval decision. 
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[alecthomas/kong]]></title>
            <link>https://github.com/alecthomas/kong</link>
            <guid>https://github.com/alecthomas/kong</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[Kong is a command-line parser for Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/alecthomas/kong">alecthomas/kong</a></h1>
            <p>Kong is a command-line parser for Go</p>
            <p>Language: Go</p>
            <p>Stars: 2,562</p>
            <p>Forks: 144</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable MD013 MD033 --&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;90%&quot; src=&quot;kong.png&quot; /&gt;&lt;/p&gt;

# Kong is a command-line parser for Go

[![](https://godoc.org/github.com/alecthomas/kong?status.svg)](http://godoc.org/github.com/alecthomas/kong) [![CircleCI](https://img.shields.io/circleci/project/github/alecthomas/kong.svg)](https://circleci.com/gh/alecthomas/kong) [![Go Report Card](https://goreportcard.com/badge/github.com/alecthomas/kong)](https://goreportcard.com/report/github.com/alecthomas/kong) [![Slack chat](https://img.shields.io/static/v1?logo=slack&amp;style=flat&amp;label=slack&amp;color=green&amp;message=gophers)](https://gophers.slack.com/messages/CN9DS8YF3)

- [Version 1.0.0 Release](#version-100-release)
- [Introduction](#introduction)
- [Help](#help)
  - [Help as a user of a Kong application](#help-as-a-user-of-a-kong-application)
  - [Defining help in Kong](#defining-help-in-kong)
- [Command handling](#command-handling)
  - [Switch on the command string](#switch-on-the-command-string)
  - [Attach a `Run(...) error` method to each command](#attach-a-run-error-method-to-each-command)
- [Hooks: BeforeReset(), BeforeResolve(), BeforeApply(), AfterApply()](#hooks-beforereset-beforeresolve-beforeapply-afterapply)
- [The Bind() option](#the-bind-option)
- [Flags](#flags)
- [Commands and sub-commands](#commands-and-sub-commands)
- [Branching positional arguments](#branching-positional-arguments)
- [Positional arguments](#positional-arguments)
- [Slices](#slices)
- [Maps](#maps)
- [Pointers](#pointers)
- [Nested data structure](#nested-data-structure)
- [Custom named decoders](#custom-named-decoders)
- [Supported field types](#supported-field-types)
- [Custom decoders (mappers)](#custom-decoders-mappers)
- [Supported tags](#supported-tags)
- [Plugins](#plugins)
- [Dynamic Commands](#dynamic-commands)
- [Variable interpolation](#variable-interpolation)
- [Validation](#validation)
- [Modifying Kong&#039;s behaviour](#modifying-kongs-behaviour)
  - [`Name(help)` and `Description(help)` - set the application name description](#namehelp-and-descriptionhelp---set-the-application-name-description)
  - [`Configuration(loader, paths...)` - load defaults from configuration files](#configurationloader-paths---load-defaults-from-configuration-files)
  - [`Resolver(...)` - support for default values from external sources](#resolver---support-for-default-values-from-external-sources)
  - [`*Mapper(...)` - customising how the command-line is mapped to Go values](#mapper---customising-how-the-command-line-is-mapped-to-go-values)
  - [`ConfigureHelp(HelpOptions)` and `Help(HelpFunc)` - customising help](#configurehelphelpoptions-and-helphelpfunc---customising-help)
  - [Injecting values into `Run()` methods](#injecting-values-into-run-methods)
  - [Other options](#other-options)

## Version 1.0.0 Release

Kong has been stable for a long time, so it seemed appropriate to cut a 1.0 release.

There is one breaking change, [#436](https://github.com/alecthomas/kong/pull/436), which should effect relatively few users.

## Introduction

Kong aims to support arbitrarily complex command-line structures with as little developer effort as possible.

To achieve that, command-lines are expressed as Go types, with the structure and tags directing how the command line is mapped onto the struct.

For example, the following command-line:

    shell rm [-f] [-r] &lt;paths&gt; ...
    shell ls [&lt;paths&gt; ...]

Can be represented by the following command-line structure:

```go
package main

import &quot;github.com/alecthomas/kong&quot;

var CLI struct {
  Rm struct {
    Force     bool `help:&quot;Force removal.&quot;`
    Recursive bool `help:&quot;Recursively remove files.&quot;`

    Paths []string `arg:&quot;&quot; name:&quot;path&quot; help:&quot;Paths to remove.&quot; type:&quot;path&quot;`
  } `cmd:&quot;&quot; help:&quot;Remove files.&quot;`

  Ls struct {
    Paths []string `arg:&quot;&quot; optional:&quot;&quot; name:&quot;path&quot; help:&quot;Paths to list.&quot; type:&quot;path&quot;`
  } `cmd:&quot;&quot; help:&quot;List paths.&quot;`
}

func main() {
  ctx := kong.Parse(&amp;CLI)
  switch ctx.Command() {
  case &quot;rm &lt;path&gt;&quot;:
  case &quot;ls&quot;:
  default:
    panic(ctx.Command())
  }
}
```

## Help

### Help as a user of a Kong application

Every Kong application includes a `--help` flag that will display auto-generated help.

eg.

    $ shell --help
    usage: shell &lt;command&gt;

    A shell-like example app.

    Flags:
      --help   Show context-sensitive help.
      --debug  Debug mode.

    Commands:
      rm &lt;path&gt; ...
        Remove files.

      ls [&lt;path&gt; ...]
        List paths.

If a command is provided, the help will show full detail on the command including all available flags.

eg.

    $ shell --help rm
    usage: shell rm &lt;paths&gt; ...

    Remove files.

    Arguments:
      &lt;paths&gt; ...  Paths to remove.

    Flags:
          --debug        Debug mode.

      -f, --force        Force removal.
      -r, --recursive    Recursively remove files.

### Defining help in Kong

Help is automatically generated from the command-line structure itself,
including `help:&quot;&quot;` and other tags. [Variables](#variable-interpolation) will
also be interpolated into the help string.

Finally, any command, or argument type implementing the interface
`Help() string` will have this function called to retrieve more detail to
augment the help tag. This allows for much more descriptive text than can
fit in Go tags. [See \_examples/shell/help](./_examples/shell/help)

#### Showing the _command_&#039;s detailed help

A command&#039;s additional help text is _not_ shown from top-level help, but can be displayed within contextual help:

**Top level help**

```bash
 $ go run ./_examples/shell/help --help
Usage: help &lt;command&gt;

An app demonstrating HelpProviders

Flags:
  -h, --help    Show context-sensitive help.
      --flag    Regular flag help

Commands:
  echo    Regular command help
```

**Contextual**

```bash
 $ go run ./_examples/shell/help echo --help
Usage: help echo &lt;msg&gt;

Regular command help

üöÄ additional command help

Arguments:
  &lt;msg&gt;    Regular argument help

Flags:
  -h, --help    Show context-sensitive help.
      --flag    Regular flag help
```

#### Showing an _argument_&#039;s detailed help

Custom help will only be shown for _positional arguments with named fields_ ([see the README section on positional arguments for more details on what that means](../../../README.md#branching-positional-arguments))

**Contextual argument help**

```bash
 $ go run ./_examples/shell/help msg --help
Usage: help echo &lt;msg&gt;

Regular argument help

üì£ additional argument help

Flags:
  -h, --help    Show context-sensitive help.
      --flag    Regular flag help
```

## Command handling

There are two ways to handle commands in Kong.

### Switch on the command string

When you call `kong.Parse()` it will return a unique string representation of the command. Each command branch in the hierarchy will be a bare word and each branching argument or required positional argument will be the name surrounded by angle brackets. Here&#039;s an example:

There&#039;s an example of this pattern [here](https://github.com/alecthomas/kong/blob/master/_examples/shell/commandstring/main.go).

eg.

```go
package main

import &quot;github.com/alecthomas/kong&quot;

var CLI struct {
  Rm struct {
    Force     bool `help:&quot;Force removal.&quot;`
    Recursive bool `help:&quot;Recursively remove files.&quot;`

    Paths []string `arg:&quot;&quot; name:&quot;path&quot; help:&quot;Paths to remove.&quot; type:&quot;path&quot;`
  } `cmd:&quot;&quot; help:&quot;Remove files.&quot;`

  Ls struct {
    Paths []string `arg:&quot;&quot; optional:&quot;&quot; name:&quot;path&quot; help:&quot;Paths to list.&quot; type:&quot;path&quot;`
  } `cmd:&quot;&quot; help:&quot;List paths.&quot;`
}

func main() {
  ctx := kong.Parse(&amp;CLI)
  switch ctx.Command() {
  case &quot;rm &lt;path&gt;&quot;:
  case &quot;ls&quot;:
  default:
    panic(ctx.Command())
  }
}
```

This has the advantage that it is convenient, but the downside that if you modify your CLI structure, the strings may change. This can be fragile.

### Attach a `Run(...) error` method to each command

A more robust approach is to break each command out into their own structs:

1. Break leaf commands out into separate structs.
2. Attach a `Run(...) error` method to all leaf commands.
3. Call `kong.Kong.Parse()` to obtain a `kong.Context`.
4. Call `kong.Context.Run(bindings...)` to call the selected parsed command.

Once a command node is selected by Kong it will search from that node back to the root. Each
encountered command node with a `Run(...) error` will be called in reverse order. This allows
sub-trees to be re-used fairly conveniently.

In addition to values bound with the `kong.Bind(...)` option, any values
passed through to `kong.Context.Run(...)` are also bindable to the target&#039;s
`Run()` arguments.

Finally, hooks can also contribute bindings via `kong.Context.Bind()` and `kong.Context.BindTo()`.

There&#039;s a full example emulating part of the Docker CLI [here](https://github.com/alecthomas/kong/tree/master/_examples/docker).

eg.

```go
type Context struct {
  Debug bool
}

type RmCmd struct {
  Force     bool `help:&quot;Force removal.&quot;`
  Recursive bool `help:&quot;Recursively remove files.&quot;`

  Paths []string `arg:&quot;&quot; name:&quot;path&quot; help:&quot;Paths to remove.&quot; type:&quot;path&quot;`
}

func (r *RmCmd) Run(ctx *Context) error {
  fmt.Println(&quot;rm&quot;, r.Paths)
  return nil
}

type LsCmd struct {
  Paths []string `arg:&quot;&quot; optional:&quot;&quot; name:&quot;path&quot; help:&quot;Paths to list.&quot; type:&quot;path&quot;`
}

func (l *LsCmd) Run(ctx *Context) error {
  fmt.Println(&quot;ls&quot;, l.Paths)
  return nil
}

var cli struct {
  Debug bool `help:&quot;Enable debug mode.&quot;`

  Rm RmCmd `cmd:&quot;&quot; help:&quot;Remove files.&quot;`
  Ls LsCmd `cmd:&quot;&quot; help:&quot;List paths.&quot;`
}

func main() {
  ctx := kong.Parse(&amp;cli)
  // Call the Run() method of the selected parsed command.
  err := ctx.Run(&amp;Context{Debug: cli.Debug})
  ctx.FatalIfErrorf(err)
}

```

## Hooks: BeforeReset(), BeforeResolve(), BeforeApply(), AfterApply()

If a node in the CLI, or any of its embedded fields, implements a `BeforeReset(...) error`, `BeforeResolve
(...) error`, `BeforeApply(...) error` and/or `AfterApply(...) error` method, those will be called as Kong
resets, resolves, validates, and assigns values to the node.

| Hook            | Description                                                                                                 |
| --------------- | ----------------------------------------------------------------------------------------------------------- |
| `BeforeReset`   | Invoked before values are reset to their defaults (as defined by the grammar) or to zero values             |
| `BeforeResolve` | Invoked before resolvers are applied to a node                                                              |
| `BeforeApply`   | Invoked before the traced command line arguments are applied to the grammar                                 |
| `AfterApply`    | Invoked after command line arguments are applied to the grammar **and validated**`                          |

The `--help` flag is implemented with a `BeforeReset` hook.

eg.

```go
// A flag with a hook that, if triggered, will set the debug loggers output to stdout.
type debugFlag bool

func (d debugFlag) BeforeApply(logger *log.Logger) error {
  logger.SetOutput(os.Stdout)
  return nil
}

var cli struct {
  Debug debugFlag `help:&quot;Enable debug logging.&quot;`
}

func main() {
  // Debug logger going to discard.
  logger := log.New(io.Discard, &quot;&quot;, log.LstdFlags)

  ctx := kong.Parse(&amp;cli, kong.Bind(logger))

  // ...
}
```

It&#039;s also possible to register these hooks with the functional options
`kong.WithBeforeReset`, `kong.WithBeforeResolve`, `kong.WithBeforeApply`, and
`kong.WithAfterApply`.

##  The Bind() option

Arguments to hooks are provided via the `Run(...)` method or `Bind(...)` option. `*Kong`, `*Context`, `*Path` and parent commands are also bound and finally, hooks can also contribute bindings via `kong.Context.Bind()` and `kong.Context.BindTo()`.

eg:

```go
type CLI struct {
  Debug bool `help:&quot;Enable debug mode.&quot;`

  Rm RmCmd `cmd:&quot;&quot; help:&quot;Remove files.&quot;`
  Ls LsCmd `cmd:&quot;&quot; help:&quot;List paths.&quot;`
}

type AuthorName string

// ...
func (l *LsCmd) Run(cli *CLI) error {
// use cli.Debug here !!
  return nil
}

func (r *RmCmD) Run(author AuthorName) error{
// use binded author here
  return nil
}

func main() {
  var cli CLI
  
  ctx := kong.Parse(&amp;cli, Bind(AuthorName(&quot;penguin&quot;)))
  err := ctx.Run()
```

## Flags

Any [mapped](#mapper---customising-how-the-command-line-is-mapped-to-go-values) field in the command structure _not_ tagged with `cmd` or `arg` will be a flag. Flags are optional by default.

eg. The command-line `app [--flag=&quot;foo&quot;]` can be represented by the following.

```go
type CLI struct {
  Flag string
}
```

## Commands and sub-commands

Sub-commands are specified by tagging a struct field with `cmd`. Kong supports arbitrarily nested commands.

eg. The following struct represents the CLI structure `command [--flag=&quot;str&quot;] sub-command`.

```go
type CLI struct {
  Command struct {
    Flag string

    SubCommand struct {
    } `cmd`
  } `cmd`
}
```

If a sub-command is tagged with `default:&quot;1&quot;` it will be selected if there are no further arguments. If a sub-command is tagged with `default:&quot;withargs&quot;` it will be selected even if there are further arguments or flags and those arguments or flags are valid for the sub-command. This allows the user to omit the sub-command name on the CLI if its arguments/flags are not ambiguous with the sibling commands or flags.

## Branching positional arguments

In addition to sub-commands, structs can also be configured as branching positional arguments.

This is achieved by tagging an [unmapped](#mapper---customising-how-the-command-line-is-mapped-to-go-values) nested struct field with `arg`, then including a positional argument field inside that struct _with the same name_. For example, the following command structure:

    app rename &lt;name&gt; to &lt;name&gt;

Can be represented with the following:

```go
var CLI struct {
  Rename struct {
    Name struct {
      Name string `arg` // &lt;-- NOTE: identical name to enclosing struct field.
      To struct {
        Name struct {
          Name string `arg`
        } `arg`
      } `cmd`
    } `arg`
  } `cmd`
}
```

This looks a little verbose in this contrived example, but typically this will not be the case.

## Positional arguments

If a field is tagged with `arg:&quot;&quot;` it will be treated as the final positional
value to be parsed on the command line. By default positional arguments are
required, but specifying `optional:&quot;&quot;` will alter this.

If a positional argument is a slice, all remaining arguments will be appended
to that slice.

## Slices

Slice values are treated specially. First the input is split on the `sep:&quot;&lt;rune&gt;&quot;` tag (defaults to `,`), then each element is parsed by the slice element type and appended to the slice. If the same value is encountered multiple times, elements continue to be appended.

To represent the following command-line:

    cmd ls &lt;file&gt; &lt;file&gt; ...

You would use the following:

```go
var CLI struct {
  Ls struct {
    Files []string `arg:&quot;&quot; type:&quot;existingfile&quot;`
  } `cmd`
}
```

## Maps

Maps are similar to slices except that only one key/value pair can be assigned per value, and the `sep` tag denotes the assignment character and defaults to `=`.

To represent the following command-line:

    cmd config set &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...

You would use the following:

```go
var CLI struct {
  Config struct {
    Set struct {
      Config map[string]float64 `arg:&quot;&quot; type:&quot;file:&quot;`
    } `cmd`
  } `cmd`
}
```

For flags, multiple key+value pairs should be separated by `mapsep:&quot;rune&quot;` tag (defaults to `;`) eg. `--set=&quot;key1=value1;key2=value2&quot;`.

## Pointers

Pointers work like the underlying type, except that you can differentiate between the presence of the zero value and no value being supplied.

For example:

```go
var CLI struct {
	Foo *int
}
```

Would produce a nil value for `Foo` if no `--foo` argument is supplied, but would have a pointer to the value 0 if the argument `--foo=0` was supplied.

## Nested data structure

Kong support a nested data structure as well with `embed:&quot;&quot;`. You can combine `embed:&quot;&quot;` with `prefix:&quot;&quot;`:

```go
var CLI struct {
  Logging struct {
    Level string `enum:&quot;debug,info,warn,error&quot; default:&quot;info&quot;`
    Type string `enum:&quot;json,console&quot; default:&quot;console&quot;`
  } `embed:&quot;&quot; prefix:&quot;logging.&quot;`
}
```

This configures Kong to accept flags `--logging.level` and `--logging.type`.

## Custom named decoders

Kong includes a number of builtin custom type mappers. These can be used by
specifying the tag `type:&quot;&lt;type&gt;&quot;`. They are registered with the option
function `NamedMapper(name, mapper)`.

| Name           | Description                                                                                                            |
| -------------- | ---------------------------------------------------------------------------------------------------------------------- |
| `path`         | A path. ~ expansion is applied. `-` is accepted for stdout, and will be passed unaltered.                              |
| `existingfile` | An existing file. ~ expansion is applied. `-` is accepted for stdin, and will be passed unaltered.                     |
| `existingdir`  | An existing directory. ~ expansion is applied.                                                                         |
| `counter`      | Increment a numeric field. Useful for `-vvv`. Can accept `-s`, `--long` or `--long=N`.                                 |
| `filecontent`  | Read the file at path into the field. ~ expansion is applied. `-` is accepted for stdin, and will be passed unaltered. |

Slices and maps treat type tags specially. For slices, the `type:&quot;&quot;` tag
specifies the element type. For maps, the tag has the format
`tag:&quot;[&lt;key&gt;]:[&lt;value&gt;]&quot;` where either may be omitted.

## Supported field types

## Custom decoders (mappers)

Any field implementing `encoding.TextUnmarshaler` or `json.Unmarshaler` will use those interfaces
for decoding values. Kong also includes builtin support for many common Go types:

| Type            | Description                                                                                                 |
| --------------- | ----------------------------------------------------------------------------------------------------------- |
| `time.Duration` | Populated using `time.ParseDuration()`.                                                                     |
| `time.Time`     | Populated using `time.Parse()`. Format defaults to RFC3339 but can be overridden with the `format:&quot;X&quot;` tag. |
| `*os.File`      | Path to a file that will be opened, or `-` for `os.Stdin`. File must be closed by the user.                 |
| `*url.URL`      | Populated with `url.Parse()`.                                                                               |

For more fine-grained control, if a field implements the
[MapperValue](https://godoc.org/github.com/alecthomas/kong#MapperValue)
interface it will be used to decode arguments into the field.

## Supported tags

Tags can be in two forms:

1. Standard Go syntax, eg. `kong:&quot;required,name=&#039;foo&#039;&quot;`.
2. Bare tags, eg. `required:&quot;&quot; name:&quot;foo&quot;`

Both can coexist with standard Tag parsing.

| Tag                  | Description                                                                                                                                                                                                                                                                                                                    |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `cmd:&quot;&quot;`             | If present, struct is a command.                                                                                                                                                                                         

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[traefik/traefik]]></title>
            <link>https://github.com/traefik/traefik</link>
            <guid>https://github.com/traefik/traefik</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[The Cloud Native Application Proxy]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/traefik/traefik">traefik/traefik</a></h1>
            <p>The Cloud Native Application Proxy</p>
            <p>Language: Go</p>
            <p>Stars: 54,179</p>
            <p>Forks: 5,295</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/content/assets/img/traefik.logo-dark.png&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/content/assets/img/traefik.logo.png&quot;&gt;
      &lt;img alt=&quot;Traefik&quot; title=&quot;Traefik&quot; src=&quot;docs/content/assets/img/traefik.logo.png&quot;&gt;
    &lt;/picture&gt;
&lt;/p&gt;

[![Build Status SemaphoreCI](https://traefik-oss.semaphoreci.com/badges/traefik/branches/master.svg?style=shields)](https://traefik-oss.semaphoreci.com/projects/traefik)
[![Docs](https://img.shields.io/badge/docs-current-brightgreen.svg)](https://doc.traefik.io/traefik)
[![Go Report Card](https://goreportcard.com/badge/traefik/traefik)](https://goreportcard.com/report/traefik/traefik)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/traefik/traefik/blob/master/LICENSE.md)
[![Join the community support forum at https://community.traefik.io/](https://img.shields.io/badge/style-register-green.svg?style=social&amp;label=Discourse)](https://community.traefik.io/)
[![Twitter](https://img.shields.io/twitter/follow/traefik.svg?style=social)](https://twitter.com/intent/follow?screen_name=traefik)

Traefik (pronounced _traffic_) is a modern HTTP reverse proxy and load balancer that makes deploying microservices easy.
Traefik integrates with your existing infrastructure components ([Docker](https://www.docker.com/), [Swarm mode](https://docs.docker.com/engine/swarm/), [Kubernetes](https://kubernetes.io), [Consul](https://www.consul.io/), [Etcd](https://coreos.com/etcd/), [Rancher v2](https://rancher.com), [Amazon ECS](https://aws.amazon.com/ecs), ...) and configures itself automatically and dynamically.
Pointing Traefik at your orchestrator should be the _only_ configuration step you need.

---

. **[Overview](#overview)** .
**[Features](#features)** .
**[Supported backends](#supported-backends)** .
**[Quickstart](#quickstart)** .
**[Web UI](#web-ui)** .
**[Documentation](#documentation)** .

. **[Support](#support)** .
**[Release cycle](#release-cycle)** .
**[Contributing](#contributing)** .
**[Maintainers](#maintainers)** .
**[Credits](#credits)** .

---

:warning: When migrating to a new major version of Traefik, please refer to the [migration guide](https://doc.traefik.io/traefik/migration/v2-to-v3/) to ensure a smooth transition and to be aware of any breaking changes.


## Overview

Imagine that you have deployed a bunch of microservices with the help of an orchestrator (like Swarm or Kubernetes) or a service registry (like etcd or consul).
Now you want users to access these microservices, and you need a reverse proxy.

Traditional reverse-proxies require that you configure _each_ route that will connect paths and subdomains to _each_ microservice. 
In an environment where you add, remove, kill, upgrade, or scale your services _many_ times a day, the task of keeping the routes up to date becomes tedious. 

**This is when Traefik can help you!**

Traefik listens to your service registry/orchestrator API and instantly generates the routes so your microservices are connected to the outside world -- without further intervention from your part. 

**Run Traefik and let it do the work for you!** 
_(But if you&#039;d rather configure some of your routes manually, Traefik supports that too!)_

![Architecture](docs/content/assets/img/traefik-architecture.png)

## Features

- Continuously updates its configuration (No restarts!)
- Supports multiple load balancing algorithms
- Provides HTTPS to your microservices by leveraging [Let&#039;s Encrypt](https://letsencrypt.org) (wildcard certificates support)
- Circuit breakers, retry
- See the magic through its clean web UI
- WebSocket, HTTP/2, gRPC ready
- Provides metrics (Rest, Prometheus, Datadog, Statsd, InfluxDB 2.X)
- Keeps access logs (JSON, CLF)
- Fast
- Exposes a Rest API
- Packaged as a single binary file (made with :heart: with go) and available as an [official](https://hub.docker.com/r/_/traefik/) docker image

## Supported Backends

- [Docker](https://doc.traefik.io/traefik/providers/docker/) / [Swarm mode](https://doc.traefik.io/traefik/providers/docker/)
- [Kubernetes](https://doc.traefik.io/traefik/providers/kubernetes-crd/)
- [ECS](https://doc.traefik.io/traefik/providers/ecs/)
- [File](https://doc.traefik.io/traefik/providers/file/)

## Quickstart

To get your hands on Traefik, you can use the [5-Minute Quickstart](https://doc.traefik.io/traefik/getting-started/quick-start/) in our documentation (you will need Docker).

## Web UI

You can access the simple HTML frontend of Traefik.

![Web UI Providers](docs/content/assets/img/webui-dashboard.png)

## Documentation

You can find the complete documentation of Traefik v3 at [https://doc.traefik.io/traefik/](https://doc.traefik.io/traefik/).

## Support

To get community support, you can:

- join the Traefik community forum: [![Join the chat at https://community.traefik.io/](https://img.shields.io/badge/style-register-green.svg?style=social&amp;label=Discourse)](https://community.traefik.io/)

If you need commercial support, please contact [Traefik.io](https://traefik.io) by mail: &lt;mailto:support@traefik.io&gt;.

## Download

- Grab the latest binary from the [releases](https://github.com/traefik/traefik/releases) page and run it with the [sample configuration file](https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml):

```shell
./traefik --configFile=traefik.toml
```

- Or use the official tiny Docker image and run it with the [sample configuration file](https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml):

```shell
docker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik
```

- Or get the sources:

```shell
git clone https://github.com/traefik/traefik
```

## Introductory Videos

You can find high level and deep dive videos on [videos.traefik.io](https://videos.traefik.io).

## Maintainers

We are strongly promoting a philosophy of openness and sharing, and firmly standing against the elitist closed approach. Being part of the core team should be accessible to anyone who is motivated and want to be part of that journey!
This [document](docs/content/contributing/maintainers-guidelines.md) describes how to be part of the [maintainers&#039; team](docs/content/contributing/maintainers.md) as well as various responsibilities and guidelines for Traefik maintainers.
You can also find more information on our process to review pull requests and manage issues [in this document](https://github.com/traefik/contributors-guide/blob/master/issue_triage.md).

## Contributing

If you&#039;d like to contribute to the project, refer to the [contributing documentation](CONTRIBUTING.md).

Please note that this project is released with a [Contributor Code of Conduct](CODE_OF_CONDUCT.md).
By participating in this project, you agree to abide by its terms.

## Release Cycle

- We usually release 3/4 new versions (e.g. 1.1.0, 1.2.0, 1.3.0) per year.
- Release Candidates are available before the release (e.g. 1.1.0-rc1, 1.1.0-rc2, 1.1.0-rc3, 1.1.0-rc4, before 1.1.0).
- Bug-fixes (e.g. 1.1.1, 1.1.2, 1.2.1, 1.2.3) are released as needed (no additional features are delivered in those versions, bug-fixes only).

Each version is supported until the next one is released (e.g. 1.1.x will be supported until 1.2.0 is out).

We use [Semantic Versioning](https://semver.org/).

## Mailing Lists

- General announcements, new releases: mail at news+subscribe@traefik.io or on [the online viewer](https://groups.google.com/a/traefik.io/forum/#!forum/news).
- Security announcements: mail at security+subscribe@traefik.io or on [the online viewer](https://groups.google.com/a/traefik.io/forum/#!forum/security).

## Credits

Kudos to [Peka](http://peka.byethost11.com/photoblog/) for his awesome work on the gopher&#039;s logo!.

The gopher&#039;s logo of Traefik is licensed under the Creative Commons 3.0 Attributions license.

The gopher&#039;s logo of Traefik was inspired by the gopher stickers made by [Takuya Ueda](https://twitter.com/tenntenn).
The original Go gopher was designed by [Renee French](https://reneefrench.blogspot.com/).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[coreybutler/nvm-windows]]></title>
            <link>https://github.com/coreybutler/nvm-windows</link>
            <guid>https://github.com/coreybutler/nvm-windows</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[A node.js version management utility for Windows. Ironically written in Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/coreybutler/nvm-windows">coreybutler/nvm-windows</a></h1>
            <p>A node.js version management utility for Windows. Ironically written in Go.</p>
            <p>Language: Go</p>
            <p>Stars: 40,595</p>
            <p>Forks: 3,491</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;h2&gt;Notice: We are working full time work on &lt;a href=&quot;https://github.com/coreybutler/nvm-windows/wiki/Runtime&quot;&gt;Runtime&lt;/a&gt;, the successor to NVM for Windows.&lt;/h2&gt;Complete &lt;a href=&quot;https://t.co/oGqQCM9FPx&quot;&gt;this form&lt;/a&gt; to provide your thoughts and sign up for progress updates.&lt;br/&gt;&lt;br/&gt;Updates will also be posted on the &lt;A href=&quot;https://linkedin.com/company/authorsoftware&quot;&gt;Author Software LinkedIn Page&lt;/a&gt;.&lt;/div&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h1 align=&quot;center&quot;&gt;NVM for Windows&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;
  The &lt;a href=&quot;https://docs.microsoft.com/en-us/windows/nodejs/setup-on-windows&quot;&gt;Microsoft&lt;/a&gt;/&lt;a href=&quot;https://docs.npmjs.com/cli/v9/configuring-npm/install#windows-node-version-managers&quot;&gt;npm&lt;/a&gt;/&lt;a href=&quot;https://cloud.google.com/nodejs/docs/setup#installing_nvm&quot;&gt;Google&lt;/a&gt; recommended Node.js version manager for &lt;em&gt;Windows&lt;/em&gt;.&lt;br/&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;This is not the same thing as nvm!&lt;/b&gt; (expand for details)&lt;/summary&gt;

_The original [nvm](https://github.com/nvm-sh/nvm) is a completely separate project for Mac/Linux only._ This project uses an entirely different philosophy and is not just a clone of nvm. Details are listed in [Why another version manager?](#bulb-why-another-version-manager) and [what&amp;#39;s the big difference?](#bulb-whats-the-big-difference).
&lt;/details&gt;

[![Download Now](https://img.shields.io/badge/-Download%20Now!-%2322A6F2)](https://github.com/coreybutler/nvm-windows/releases) [![GitHub tag (latest SemVer)](https://img.shields.io/github/v/tag/coreybutler/nvm-windows?label=Latest%20Release&amp;style=social&amp;x=1)]((https://github.com/coreybutler/nvm-windows/releases)) ![GitHub Release Date](https://img.shields.io/github/release-date/coreybutler/nvm-windows?label=Released&amp;style=social) ![GitHub all releases](https://img.shields.io/github/downloads/coreybutler/nvm-windows/total?label=Downloads&amp;style=social) [![Discuss](https://img.shields.io/badge/-Discuss-blue)](https://github.com/coreybutler/nvm-windows/discussions) [![Twitter URL](https://img.shields.io/twitter/url?style=social&amp;url=https%3A%2F%2Ftwitter.com%2Fintent%2Ftweet%3Fhashtags%3Dnodejs%26original_referer%3Dhttp%253A%252F%252F127.0.0.1%253A91%252F%26text%3DCheck%2520out%2520NVM%2520for%2520Windows%21%26tw_p%3Dtweetbutton%26url%3Dhttp%253A%252F%252Fgithub.com%252Fcoreybutler%252Fnvm-windows%26via%3Dgoldglovecb)](https://twitter.com/intent/tweet?hashtags=nodejs&amp;original_referer=http%3A%2F%2F127.0.0.1%3A91%2F&amp;text=Check%20out%20NVM%20for%20Windows!&amp;tw_p=tweetbutton&amp;url=http%3A%2F%2Fgithub.com%2Fcoreybutler%2Fnvm-windows&amp;via=goldglovecb)
&lt;/div&gt;

&lt;h5 align=&quot;center&quot;&gt;Sponsors&lt;/h5&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;table cellpadding=&quot;5&quot; cellspacing=&quot;0&quot; border=&quot;0&quot; align=&quot;center&quot;&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://linkedin.com/company/authorsoftware&quot;&gt;&lt;img src=&quot;https://github.com/coreybutler/staticassets/blob/master/sponsors/logo_author_software_flat.png&quot; width=&quot;200px&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td width=&quot;33%&quot; align=&quot;center&quot;&gt;&lt;a href=&quot;https://ecorventures.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/8259581?s=200&amp;v=4&quot; height=&quot;30px&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td width=&quot;33%&quot; align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/770982/195955265-5c3dca78-7140-4ec6-b05a-f308518643ee.png&quot; height=&quot;30px&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td colspan=&quot;4&quot; align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://github.com/sponsors/coreybutler&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/sponsors/coreybutler?label=Individual%20Sponsors&amp;logo=github&amp;style=social&quot;/&gt;&lt;/a&gt;
        &amp;nbsp;&lt;a href=&quot;https://github.com/sponsors/coreybutler&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/-Become%20a%20Sponsor-yellow&quot;/&gt;&lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td colspan=&quot;4&quot; align=&quot;center&quot;&gt;
        &lt;img src=&quot;https://github.blog/wp-content/uploads/2020/09/github-stars-logo_Color.png&quot; width=&quot;50&quot;/&gt;&lt;br/&gt;
        &lt;b&gt;Can&#039;t sponsor?&lt;/b&gt;&lt;br/&gt;Consider &lt;a href=&quot;https://stars.github.com/nominate/&quot; target=&quot;_blank&quot;&gt;nominating @coreybutler for a Github star&lt;/a&gt;.
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;
&lt;br/&gt;

&lt;div align=&quot;center&quot;&gt;&lt;b&gt;Running into issues?&lt;/b&gt; See the &lt;a href=&quot;https://github.com/coreybutler/nvm-windows/wiki/Common-Issues&quot;&gt;common issues wiki&lt;/a&gt;.&lt;/div&gt;

&lt;br/&gt;
&lt;table style=&quot;background-color:red;padding:6px;border-radius:3px;&quot;&gt;
  &lt;tr&gt;&lt;td&gt;
    &lt;h3&gt;Seeking Feedback:&lt;/h3&gt;
    We&#039;re working on &lt;a href=&quot;https://github.com/coreybutler/nvm-windows/wiki/Runtime&quot;&gt;Runtime (rt)&lt;/a&gt;, the successor to NVM For Windows. Please contribute by taking a minute to complete &lt;a href=&quot;https://t.co/oGqQCM9FPx&quot;&gt;this form&lt;/a&gt;. Thank you!
    &lt;h3&gt;&lt;/h3&gt;
  &lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

## Overview

Manage multiple installations of node.js on a Windows computer.

**tl;dr** Similar (not identical) to [nvm](https://github.com/creationix/nvm), but for Windows. Has an installer. [Download Now](https://github.com/coreybutler/nvm-windows/releases)!

This has always been a node version manager, not an io.js manager, so there is no back-support for io.js. Node 4+ is supported. Remember when running `nvm install` or `nvm use`, Windows usually requires administrative rights (to create symlinks). To install the latest version of Node.js, run `nvm install latest`. To install the latest stable version, run `nvm install lts`.

![NVM for Windows](https://github.com/coreybutler/staticassets/raw/master/images/nvm-1.1.8-screenshot.jpg)

There are situations where the ability to switch between different versions of Node.js can be very useful. For example, if you want to test a module you&#039;re developing with the latest bleeding edge version without uninstalling the stable version of node, this utility can help.

![Switch between stable and unstable versions.](https://github.com/coreybutler/staticassets/raw/master/images/nvm-usage-highlighted.jpg)

### Installation &amp; Upgrades

#### :star: :star: Uninstall any pre-existing Node installations!! :star: :star:

The simplest (recommended) way to get NVM for Windows running properly is to uninstall any prior Node installation _before_ installing NVM for Windows. It avoids all of the pitfalls listed below. However; you may not wish to nuke your Node installation if you&#039;ve highly customized it. NVM for Windows _can_ assume management of an existing installation, but there are nuances to this (dependent entirely on the permissions of the user running the installation). If you have an administrative account, it&#039;s relatively safe to install NVM for Windows before uninstalling the original Node version. If you are working in a closed environment, such as a corporate Active Directory environment where installations/uninstallations are controlled by group policy, you should really consider removing the original version of Node before installing NVM4W.

_Permission Problems_
For security reasons, Windows will not allow an application from one vendor to &quot;uninstall&quot; an application from a different vendor. The official NVM4W installer will attempt assume management of an existing installation of Node., but it cannot actually uninstall the original Node.js version. To work around this, NVM for Windows installer attempts to copy the original Node.js installation files to the NVM root. This includes global npm modules and configurations. Once this process is complete, the original Node.js installation can be uninstalled without losing data.

_PATH Installation Problems_
If you attempt to configure the `NVM_SYMLINK` to use an existing directory (like `C:\Program Files\nodejs`), it will fail because a symlink cannot overwrite a physical directory. This is not a problem if you choose a different symlink path (such as `C:\nvm\node`).

_PATH Conflicts_
If you do not uninstall the original version, running `nvm use` may appear to do nothing at all. Running `node -v` will always show the original installation version. This is due to a [`PATH` conflict](https://github.com/coreybutler/nvm-windows/wiki/Common-Issues#why-do-i-need-to-uninstall-nodejs-before-installing-nvm-for-windows) that presents when the same application is installed multiple times. In NVM4W 1.1.11+, run `nvm debug` to determine if you have a `PATH` conflict.

For simpliciy, we recommend uninstalling any existing versions of Node.js before using NVM for Windows. Delete any existing Node.js installation directories (e.g., `%ProgramFiles%\nodejs`) that might remain. NVM&#039;s generated symlink will not overwrite an existing (even empty) installation directory.

:eyes: **Backup any global `npmrc` config** :eyes:
(e.g. `%AppData%\npm\etc\npmrc`)

Alternatively, copy the settings to the user config `%UserProfile%\.npmrc`. Delete the existing npm install location (e.g. `%AppData%\npm`) to prevent global module conflicts.

#### Install nvm-windows

Use the [latest installer](https://github.com/coreybutler/nvm/releases) (comes with an uninstaller). Alternatively, follow the  [manual installation](https://github.com/coreybutler/nvm-windows/wiki#manual-installation) guide.

_If NVM4W doesn&#039;t appear to work immediately after installation, restart the terminal/powershell (not the whole computer)._

![NVM for Windows Installer](https://github.com/coreybutler/staticassets/raw/master/images/nvm-installer.jpg)

#### Reinstall any global utilities

After install, reinstalling global utilities (e.g. yarn) will have to be done for each installed version of node:

```
nvm use 14.0.0
npm install -g yarn
nvm use 12.0.1
npm install -g yarn
```

### Upgrading nvm-windows

:bulb: _As of v1.1.8, there is an upgrade utility that will automate the upgrade process._

**To upgrade nvm-windows**, run the new installer. It will safely overwrite the files it needs to update without touching your node.js installations. Make sure you use the same installation and symlink folder. If you originally installed to the default locations, you just need to click &quot;next&quot; on each window until it finishes.

### Usage

**nvm-windows runs in an Admin shell**. You&#039;ll need to start `powershell` or Command Prompt as Administrator to use nvm-windows

NVM for Windows is a command line tool. Simply type `nvm` in the console for help. The basic commands are:

- **`nvm arch [32|64]`**: Show if node is running in 32 or 64 bit mode. Specify 32 or 64 to override the default architecture.
- **`nvm debug`**: Check the NVM4W process for known problems.
- **`nvm current`**: Display active version.
- **`nvm install &lt;version&gt; [arch]`**:  The version can be a specific version, &quot;latest&quot; for the latest current version, or &quot;lts&quot; for the most recent LTS version. Optionally specify whether to install the 32 or 64 bit version (defaults to system arch). Set [arch] to &quot;all&quot; to install 32 AND 64 bit versions. Add `--insecure` to the end of this command to bypass SSL validation of the remote download server.
- **`nvm list [available]`**: List the node.js installations. Type `available` at the end to show a list of versions available for download.
- **`nvm on`**: Enable node.js version management.
- **`nvm off`**: Disable node.js version management (does not uninstall anything).
- **`nvm proxy [url]`**: Set a proxy to use for downloads. Leave `[url]` blank to see the current proxy. Set `[url]` to &quot;none&quot; to remove the proxy.
- **`nvm uninstall &lt;version&gt;`**: Uninstall a specific version.
- **`nvm use &lt;version&gt; [arch]`**: Switch to use the specified version. Optionally use `latest`, `lts`, or `newest`. `newest` is the latest _installed_ version. Optionally specify 32/64bit architecture. `nvm use &lt;arch&gt;` will continue using the selected version, but switch to 32/64 bit mode. For information about using `use` in a specific directory (or using `.nvmrc`), please refer to [issue #16](https://github.com/coreybutler/nvm-windows/issues/16).
- **`nvm root &lt;path&gt;`**: Set the directory where nvm should store different versions of node.js. If `&lt;path&gt;` is not set, the current root will be displayed.
- **`nvm version`**: Displays the current running version of NVM for Windows.
- **`nvm node_mirror &lt;node_mirror_url&gt;`**: Set the node mirror.People in China can use *https://npmmirror.com/mirrors/node/*
- **`nvm npm_mirror &lt;npm_mirror_url&gt;`**: Set the npm mirror.People in China can use *https://npmmirror.com/mirrors/npm/*

### :warning: Gotcha!

Please note that any global npm modules you may have installed are **not** shared between the various versions of node.js you have installed. Additionally, some npm modules may not be supported in the version of node you&#039;re using, so be aware of your environment as you work.

### :name_badge: Antivirus

Users have reported some problems using antivirus, specifically McAfee. It appears the antivirus software is manipulating access to the VBScript engine. See [issue #133](https://github.com/coreybutler/nvm-windows/issues/133) for details and resolution.

**v1.1.8 is not code signed**, but all other versions are signed by [Ecor Ventures LLC](https://ecorventures.com)/[Author.io](https://author.io). This should help prevent false positives with most antivirus software.

&gt; v1.1.8+ was not code signed due to an expired certificate (see the [release notes](https://github.com/coreybutler/nvm-windows/releases/tag/1.1.8) for reasons). **v1.1.9 _is_ code signed** thanks to [ajyong](https://github.com/ajyong), who sponsored the new certificate.

### Using Yarn

**tldr;** `npm i -g yarn`

See the [wiki](https://github.com/coreybutler/nvm-windows/wiki/Common-Issues#how-do-i-use-yarn-with-nvm-windows) for details.

### Build from source

- Install go from http://golang.org
- Download source / Git Clone the repo
- Change GOARCH to amd64 in build.bat if you feel like building a 64-bit executable
- Fire up a Windows command prompt and change directory to project dir
- Execute `go get github.com/blang/semver`
- Execute `go get github.com/olekukonko/tablewriter`
- Execute `build.bat`
- Check the `dist`directory for generated setup program.

---

## :bulb: Why another version manager?

There are several version managers for node.js. Tools like [nvm](https://github.com/creationix/nvm) and [n](https://github.com/tj/n)
only run on Mac OSX and Linux. Windows users are left in the cold? No. [nvmw](https://github.com/hakobera/nvmw) and [nodist](https://github.com/marcelklehr/nodist)
are both designed for Windows. So, why another version manager for Windows?

The architecture of most node version managers for Windows rely on `.bat` files, which do some clever tricks to set or mimic environment variables. Some of them use node itself (once it&#039;s downloaded), which is admirable, but prone to problems. Right around node 0.10.30, the installation structure changed a little, causing some of these to just stop working with anything new.

Additionally, some users struggle to install these modules since it requires a little more knowledge of node&#039;s installation structure. I believe if it were easier for people to switch between versions, people might take the time to test their code on back and future versions... which is just good practice.

## :bulb: What&#039;s the big difference?

First and foremost, this version of nvm has no dependency on node. It&#039;s written in [Go](https://golang.org/), which is a much more structured approach than hacking around a limited `.bat` file. It does not rely on having an existing node installation. Go offers the ability to create a Mac/Linux version on the same code base. In fact, this is already underway.

The control mechanism is also quite different. There are two general ways to support multiple node installations with hot switching capabilities. The first is to modify the system `PATH` any time you switch versions, or bypass it by using a `.bat` file to mimic the node executable and redirect accordingly. This always seemed a little hackish to me, and there are some quirks as a result of this implementation.

The second option is to use a symlink. This concept requires putting the symlink in the system `PATH`, then updating its target to the node installation directory you want to use. This is a straightforward approach, and seems to be what people recommend.... until they realize just how much of a pain symlinks are on Windows. This is why it hasn&#039;t happened before.

In order to create/modify a symlink, you must be running as an admin, and you must get around Windows UAC (that annoying prompt). Luckily, this is a challenge I already solved with some helper scripts in [node-windows](https://github.com/coreybutler/node-windows). As a result, NVM for Windows maintains a single symlink that is put in the system `PATH` during installation only. Switching to different versions of node is a matter of switching the symlink target. As a result, this utility does **not** require you to run `nvm use x.x.x` every time you open a console window. When you _do_ run `nvm use x.x.x`, the active version of node is automatically updated across all open console windows. It also persists between system reboots, so you only need to use nvm when you want to make a change.

NVM for Windows comes with an installer, courtesy of a byproduct of my work on [Fenix Web Server](https://preview.fenixwebserver.com).

Overall, this project brings together some ideas, a few battle-hardened pieces of other modules, and support for newer versions of node.

NVM for Windows recognizes the &quot;latest&quot; versions using a [list](https://nodejs.org/download/release/index.json) provided by the Node project. Version 1.1.1+ use this list. Before this list existed, I was scraping releases and serving it as a standalone [data feed](https://github.com/coreybutler/nodedistro). This list was used in versions 1.1.0 and prior, but is now deprecated.

## Motivation

I needed it, plain and simple. Additionally, it&#039;s apparent that [support for multiple versions](https://github.com/nodejs/node-v0.x-archive/issues/8075) is not coming to node core. It was also an excuse to play with Go.

## Why Go? Why not Node?

I chose Go because it is cross-platform, felt like less overhead than Java, has been around longer than most people think. Plus, I wanted to experiment with it. I&#039;ve been asked why I didn&#039;t write it with Node. Trying to write a tool with the tool you&#039;re trying to install doesn&#039;t make sense to me. As a result, my project requirements for this were simple... something that&#039;s not Node. Node will continue to evolve and change. If you need a reminder of that, remember io.js, Ayo, all the breaking changes between 4.x.x and 6.x.x, and the shift to ES Modules in 12+. Change is inevitable in the world of software. JavaScript is extremely dynamic.

## :pray: Thanks

Thanks to everyone who has submitted issues on and off Github, made suggestions, and generally helped make this a better project. Special thanks to

- [@vkbansal](https://github.com/vkbansal), who provided significant early feedback throughout the early releases.
- [@rainabba](https://github.com/rainabba) and [@sullivanpt](https://github.com/sullivanpt) for getting Node v4 support integrated.
- [@s-h-a-d-o-w](https://github.com/s-h-a-d-o-w) who resolved the longstanding space escaping issue in path names ([#355](https://github.com/coreybutler/nvm-windows/pull/355)).
- [ajyong](https://github.com/ajyong) who sponsored the code signing certificate in late 2021.

&lt;br/&gt;

![Contributors](https://contrib.rocks/image?repo=coreybutler/nvm-windows)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[helm/helm]]></title>
            <link>https://github.com/helm/helm</link>
            <guid>https://github.com/helm/helm</guid>
            <pubDate>Wed, 16 Apr 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[The Kubernetes Package Manager]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/helm/helm">helm/helm</a></h1>
            <p>The Kubernetes Package Manager</p>
            <p>Language: Go</p>
            <p>Stars: 27,752</p>
            <p>Forks: 7,208</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># Helm

[![Build Status](https://github.com/helm/helm/workflows/release/badge.svg)](https://github.com/helm/helm/actions?workflow=release)
[![Go Report Card](https://goreportcard.com/badge/helm.sh/helm/v4)](https://goreportcard.com/report/helm.sh/helm/v4)
[![GoDoc](https://img.shields.io/static/v1?label=godoc&amp;message=reference&amp;color=blue)](https://pkg.go.dev/helm.sh/helm/v4)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3131/badge)](https://bestpractices.coreinfrastructure.org/projects/3131)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/helm/helm/badge)](https://scorecard.dev/viewer/?uri=github.com/helm/helm)

Helm is a tool for managing Charts. Charts are packages of pre-configured Kubernetes resources.

Use Helm to:

- Find and use [popular software packaged as Helm Charts](https://artifacthub.io/packages/search?kind=0) to run in Kubernetes
- Share your own applications as Helm Charts
- Create reproducible builds of your Kubernetes applications
- Intelligently manage your Kubernetes manifest files
- Manage releases of Helm packages

## Helm in a Handbasket

Helm is a tool that streamlines installing and managing Kubernetes applications.
Think of it like apt/yum/homebrew for Kubernetes.

- Helm renders your templates and communicates with the Kubernetes API
- Helm runs on your laptop, CI/CD, or wherever you want it to run.
- Charts are Helm packages that contain at least two things:
  - A description of the package (`Chart.yaml`)
  - One or more templates, which contain Kubernetes manifest files
- Charts can be stored on disk, or fetched from remote chart repositories
  (like Debian or RedHat packages)

## Helm Development and Stable Versions

Helm v4 is currently under development on the `main` branch. This is unstable and the APIs within the Go SDK and at the command line are changing.
Helm v3 (current stable) is maintained on the `dev-v3` branch. APIs there follow semantic versioning.

## Install

Binary downloads of the Helm client can be found on [the Releases page](https://github.com/helm/helm/releases/latest).

Unpack the `helm` binary and add it to your PATH and you are good to go!

If you want to use a package manager:

- [Homebrew](https://brew.sh/) users can use `brew install helm`.
- [Chocolatey](https://chocolatey.org/) users can use `choco install kubernetes-helm`.
- [Winget](https://learn.microsoft.com/en-us/windows/package-manager/) users can use `winget install Helm.Helm`.
- [Scoop](https://scoop.sh/) users can use `scoop install helm`.
- [Snapcraft](https://snapcraft.io/) users can use `snap install helm --classic`.
- [Flox](https://flox.dev) users can use `flox install kubernetes-helm`.

To rapidly get Helm up and running, start with the [Quick Start Guide](https://helm.sh/docs/intro/quickstart/).

See the [installation guide](https://helm.sh/docs/intro/install/) for more options,
including installing pre-releases.

## Docs

Get started with the [Quick Start guide](https://helm.sh/docs/intro/quickstart/) or plunge into the [complete documentation](https://helm.sh/docs)

## Roadmap

The [Helm roadmap uses GitHub milestones](https://github.com/helm/helm/milestones) to track the progress of the project.

The development of Helm v4 is currently happening on the `main` branch while the development of Helm v3, the stable branch, is happening on the `dev-v3` branch. Changes should be made to the `main` branch prior to being added to the `dev-v3` branch so that all changes are carried along to Helm v4.

## Community, discussion, contribution, and support

You can reach the Helm community and developers via the following channels:

- [Kubernetes Slack](https://kubernetes.slack.com):
  - [#helm-users](https://kubernetes.slack.com/messages/helm-users)
  - [#helm-dev](https://kubernetes.slack.com/messages/helm-dev)
  - [#charts](https://kubernetes.slack.com/messages/charts)
- Mailing List:
  - [Helm Mailing List](https://lists.cncf.io/g/cncf-helm)
- Developer Call: Thursdays at 9:30-10:00 Pacific ([meeting details](https://github.com/helm/community/blob/master/communication.md#meetings))

### Contribution

If you&#039;re interested in contributing, please refer to the [Contributing Guide](CONTRIBUTING.md) **before submitting a pull request**.

### Code of conduct

Participation in the Helm community is governed by the [Code of Conduct](code-of-conduct.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>