<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Sat, 08 Nov 2025 00:05:23 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[prometheus/alertmanager]]></title>
            <link>https://github.com/prometheus/alertmanager</link>
            <guid>https://github.com/prometheus/alertmanager</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[Prometheus Alertmanager]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prometheus/alertmanager">prometheus/alertmanager</a></h1>
            <p>Prometheus Alertmanager</p>
            <p>Language: Go</p>
            <p>Stars: 7,672</p>
            <p>Forks: 2,324</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre># Alertmanager [![CircleCI](https://circleci.com/gh/prometheus/alertmanager/tree/main.svg?style=shield)][circleci]

[![Docker Repository on Quay](https://quay.io/repository/prometheus/alertmanager/status &quot;Docker Repository on Quay&quot;)][quay]
[![Docker Pulls](https://img.shields.io/docker/pulls/prom/alertmanager.svg?maxAge=604800)][hub]

The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct [receiver integrations](https://prometheus.io/docs/alerting/latest/configuration/#receiver) such as email, PagerDuty, OpsGenie, or many other [mechanisms](https://prometheus.io/docs/operating/integrations/#alertmanager-webhook-receiver) thanks to the webhook receiver. It also takes care of silencing and inhibition of alerts.

* [Documentation](http://prometheus.io/docs/alerting/alertmanager/)

## Install

There are various ways of installing Alertmanager.

### Precompiled binaries

Precompiled binaries for released versions are available in the
[*download* section](https://prometheus.io/download/)
on [prometheus.io](https://prometheus.io). Using the latest production release binary
is the recommended way of installing Alertmanager.

### Docker images

Docker images are available on [Quay.io](https://quay.io/repository/prometheus/alertmanager) or [Docker Hub](https://hub.docker.com/r/prom/alertmanager/).

You can launch an Alertmanager container for trying it out with

    $ docker run --name alertmanager -d -p 127.0.0.1:9093:9093 quay.io/prometheus/alertmanager

Alertmanager will now be reachable at http://localhost:9093/.

### Compiling the binary

You can either `go install` it:

```
$ go install github.com/prometheus/alertmanager/cmd/...@latest
# cd $GOPATH/src/github.com/prometheus/alertmanager
$ alertmanager --config.file=&lt;your_file&gt;
```

Or clone the repository and build manually:

```
$ mkdir -p $GOPATH/src/github.com/prometheus
$ cd $GOPATH/src/github.com/prometheus
$ git clone https://github.com/prometheus/alertmanager.git
$ cd alertmanager
$ make build
$ ./alertmanager --config.file=&lt;your_file&gt;
```

You can also build just one of the binaries in this repo by passing a name to the build function:
```
$ make build BINARIES=amtool
```

## Example

This is an example configuration that should cover most relevant aspects of the new YAML configuration format. The full documentation of the configuration can be found [here](https://prometheus.io/docs/alerting/configuration/).

```yaml
global:
  # The smarthost and SMTP sender used for mail notifications.
  smtp_smarthost: &#039;localhost:25&#039;
  smtp_from: &#039;alertmanager@example.org&#039;

# The root route on which each incoming alert enters.
route:
  # The root route must not have any matchers as it is the entry point for
  # all alerts. It needs to have a receiver configured so alerts that do not
  # match any of the sub-routes are sent to someone.
  receiver: &#039;team-X-mails&#039;

  # The labels by which incoming alerts are grouped together. For example,
  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
  # be batched into a single group.
  #
  # To aggregate by all possible labels use &#039;...&#039; as the sole label name.
  # This effectively disables aggregation entirely, passing through all
  # alerts as-is. This is unlikely to be what you want, unless you have
  # a very low alert volume or your upstream notification system performs
  # its own grouping. Example: group_by: [...]
  group_by: [&#039;alertname&#039;, &#039;cluster&#039;]

  # When a new group of alerts is created by an incoming alert, wait at
  # least &#039;group_wait&#039; to send the initial notification.
  # This way ensures that you get multiple alerts for the same group that start
  # firing shortly after another are batched together on the first
  # notification.
  group_wait: 30s

  # When the first notification was sent, wait &#039;group_interval&#039; to send a batch
  # of new alerts that started firing for that group.
  group_interval: 5m

  # If an alert has successfully been sent, wait &#039;repeat_interval&#039; to
  # resend them.
  repeat_interval: 3h

  # All the above attributes are inherited by all child routes and can
  # overwritten on each.

  # The child route trees.
  routes:
  # This route performs a regular expression match on alert labels to
  # catch alerts that are related to a list of services.
  - matchers:
    - service=~&quot;^(foo1|foo2|baz)$&quot;
    receiver: team-X-mails

    # The service has a sub-route for critical alerts, any alerts
    # that do not match, i.e. severity != critical, fall-back to the
    # parent node and are sent to &#039;team-X-mails&#039;
    routes:
    - matchers:
      - severity=&quot;critical&quot;
      receiver: team-X-pager

  - matchers:
    - service=&quot;files&quot;
    receiver: team-Y-mails

    routes:
    - matchers:
      - severity=&quot;critical&quot;
      receiver: team-Y-pager

  # This route handles all alerts coming from a database service. If there&#039;s
  # no team to handle it, it defaults to the DB team.
  - matchers:
    - service=&quot;database&quot;

    receiver: team-DB-pager
    # Also group alerts by affected database.
    group_by: [alertname, cluster, database]

    routes:
    - matchers:
      - owner=&quot;team-X&quot;
      receiver: team-X-pager

    - matchers:
      - owner=&quot;team-Y&quot;
      receiver: team-Y-pager


# Inhibition rules allow to mute a set of alerts given that another alert is
# firing.
# We use this to mute any warning-level notifications if the same alert is
# already critical.
inhibit_rules:
- source_matchers:
    - severity=&quot;critical&quot;
  target_matchers:
    - severity=&quot;warning&quot;
  # Apply inhibition if the alertname is the same.
  # CAUTION: 
  #   If all label names listed in `equal` are missing 
  #   from both the source and target alerts,
  #   the inhibition rule will apply!
  equal: [&#039;alertname&#039;]


receivers:
- name: &#039;team-X-mails&#039;
  email_configs:
  - to: &#039;team-X+alerts@example.org, team-Y+alerts@example.org&#039;

- name: &#039;team-X-pager&#039;
  email_configs:
  - to: &#039;team-X+alerts-critical@example.org&#039;
  pagerduty_configs:
  - routing_key: &lt;team-X-key&gt;

- name: &#039;team-Y-mails&#039;
  email_configs:
  - to: &#039;team-Y+alerts@example.org&#039;

- name: &#039;team-Y-pager&#039;
  pagerduty_configs:
  - routing_key: &lt;team-Y-key&gt;

- name: &#039;team-DB-pager&#039;
  pagerduty_configs:
  - routing_key: &lt;team-DB-key&gt;
```

## API

The current Alertmanager API is version 2. This API is fully generated via the
[OpenAPI project](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md)
and [Go Swagger](https://github.com/go-swagger/go-swagger/) with the exception
of the HTTP handlers themselves. The API specification can be found in
[api/v2/openapi.yaml](api/v2/openapi.yaml). A HTML rendered version can be
accessed [here](http://petstore.swagger.io/?url=https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml).
Clients can be easily generated via any OpenAPI generator for all major languages.

APIv2 is accessed via the `/api/v2` prefix. APIv1 was deprecated in `0.16.0` and is removed as of version `0.27.0`.
The v2 `/status` endpoint would be `/api/v2/status`. If `--web.route-prefix` is set then API routes are
prefixed with that as well, so `--web.route-prefix=/alertmanager/` would
relate to `/alertmanager/api/v2/status`.

## amtool

`amtool` is a cli tool for interacting with the Alertmanager API. It is bundled with all releases of Alertmanager.

### Install

Alternatively you can install with:
```
$ go install github.com/prometheus/alertmanager/cmd/amtool@latest
```

### Examples

View all currently firing alerts:
```
$ amtool alert
Alertname        Starts At                Summary
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
```

View all currently firing alerts with extended output:
```
$ amtool -o extended alert
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname=&quot;Test_Alert&quot; instance=&quot;node0&quot;       link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname=&quot;Test_Alert&quot; instance=&quot;node1&quot;       link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname=&quot;Check_Foo_Fails&quot; instance=&quot;node0&quot;  link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname=&quot;Check_Foo_Fails&quot; instance=&quot;node1&quot;  link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
```

In addition to viewing alerts, you can use the rich query syntax provided by Alertmanager:
```
$ amtool -o extended alert query alertname=&quot;Test_Alert&quot;
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname=&quot;Test_Alert&quot; instance=&quot;node0&quot;  link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname=&quot;Test_Alert&quot; instance=&quot;node1&quot;  link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query instance=~&quot;.+1&quot;
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname=&quot;Test_Alert&quot; instance=&quot;node1&quot;       link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname=&quot;Check_Foo_Fails&quot; instance=&quot;node1&quot;  link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query alertname=~&quot;Test.*&quot; instance=~&quot;.+1&quot;
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname=&quot;Test_Alert&quot; instance=&quot;node1&quot;  link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
```

Silence an alert:
```
$ amtool silence add alertname=Test_Alert
b3ede22e-ca14-4aa0-932c-ca2f3445f926

$ amtool silence add alertname=&quot;Test_Alert&quot; instance=~&quot;.+0&quot;
e48cb58a-0b17-49ba-b734-3585139b1d25
```

View silences:
```
$ amtool silence query
ID                                    Matchers              Ends At                  Created By  Comment
b3ede22e-ca14-4aa0-932c-ca2f3445f926  alertname=Test_Alert  2017-08-02 19:54:50 UTC  kellel

$ amtool silence query instance=~&quot;.+0&quot;
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel
```

Expire a silence:
```
$ amtool silence expire b3ede22e-ca14-4aa0-932c-ca2f3445f926
```

Expire all silences matching a query:
```
$ amtool silence query instance=~&quot;.+0&quot;
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel

$ amtool silence expire $(amtool silence query -q instance=~&quot;.+0&quot;)

$ amtool silence query instance=~&quot;.+0&quot;

```

Expire all silences:
```
$ amtool silence expire $(amtool silence query -q)
```

Try out how a template works. Let&#039;s say you have this in your configuration file:
```
templates:
  - &#039;/foo/bar/*.tmpl&#039;
```

Then you can test out how a template would look like with example by using this command:
```
amtool template render --template.glob=&#039;/foo/bar/*.tmpl&#039; --template.text=&#039;{{ template &quot;slack.default.markdown.v1&quot; . }}&#039;
```

### Configuration

`amtool` allows a configuration file to specify some options for convenience. The default configuration file paths are `$HOME/.config/amtool/config.yml` or `/etc/amtool/config.yml`

An example configuration file might look like the following:

```
# Define the path that `amtool` can find your `alertmanager` instance
alertmanager.url: &quot;http://localhost:9093&quot;

# Override the default author. (unset defaults to your username)
author: me@example.com

# Force amtool to give you an error if you don&#039;t include a comment on a silence
comment_required: true

# Set a default output format. (unset defaults to simple)
output: extended

# Set a default receiver
receiver: team-X-pager
```

### Routes

`amtool` allows you to visualize the routes of your configuration in form of text tree view.
Also you can use it to test the routing by passing it label set of an alert
and it prints out all receivers the alert would match ordered and separated by `,`.
(If you use `--verify.receivers` amtool returns error code 1 on mismatch)

Example of usage:
```
# View routing tree of remote Alertmanager
$ amtool config routes --alertmanager.url=http://localhost:9090

# Test if alert matches expected receiver
$ amtool config routes test --config.file=doc/examples/simple.yml --tree --verify.receivers=team-X-pager service=database owner=team-X
```

## High Availability

Alertmanager&#039;s high availability is in production use at many companies and is enabled by default.

&gt; Important: Both UDP and TCP are needed in alertmanager 0.15 and higher for the cluster to work.
&gt;  - If you are using a firewall, make sure to whitelist the clustering port for both protocols.
&gt;  - If you are running in a container, make sure to expose the clustering port for both protocols.

To create a highly available cluster of the Alertmanager the instances need to
be configured to communicate with each other. This is configured using the
`--cluster.*` flags.

- `--cluster.listen-address` string: cluster listen address (default &quot;0.0.0.0:9094&quot;; empty string disables HA mode)
- `--cluster.advertise-address` string: cluster advertise address
- `--cluster.peer` value: initial peers (repeat flag for each additional peer)
- `--cluster.peer-timeout` value: peer timeout period (default &quot;15s&quot;)
- `--cluster.peers-resolve-timeout` value: peers resolve timeout period (default &quot;15s&quot;)
- `--cluster.gossip-interval` value: cluster message propagation speed
  (default &quot;200ms&quot;)
- `--cluster.pushpull-interval` value: lower values will increase
  convergence speeds at expense of bandwidth (default &quot;1m0s&quot;)
- `--cluster.settle-timeout` value: maximum time to wait for cluster
  connections to settle before evaluating notifications.
- `--cluster.tcp-timeout` value: timeout value for tcp connections, reads and writes (default &quot;10s&quot;)
- `--cluster.probe-timeout` value: time to wait for ack before marking node unhealthy
  (default &quot;500ms&quot;)
- `--cluster.probe-interval` value: interval between random node probes (default &quot;1s&quot;)
- `--cluster.reconnect-interval` value: interval between attempting to reconnect to lost peers (default &quot;10s&quot;)
- `--cluster.reconnect-timeout` value: length of time to attempt to reconnect to a lost peer (default: &quot;6h0m0s&quot;)
- `--cluster.label` value: the label is an optional string to include on each packet and stream. It uniquely identifies the cluster and prevents cross-communication issues when sending gossip messages (default:&quot;&quot;)

The chosen port in the `cluster.listen-address` flag is the port that needs to be
specified in the `cluster.peer` flag of the other peers.

The `cluster.advertise-address` flag is required if the instance doesn&#039;t have
an IP address that is part of [RFC 6890](https://tools.ietf.org/html/rfc6890)
with a default route.

To start a cluster of three peers on your local machine use [`goreman`](https://github.com/mattn/goreman) and the
Procfile within this repository.

	goreman start

To point your Prometheus 1.4, or later, instance to multiple Alertmanagers, configure them
in your `prometheus.yml` configuration file, for example:

```yaml
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager1:9093
      - alertmanager2:9093
      - alertmanager3:9093
```

&gt; Important: Do not load balance traffic between Prometheus and its Alertmanagers, but instead point Prometheus to a list of all Alertmanagers. The Alertmanager implementation expects all alerts to be sent to all Alertmanagers to ensure high availability.

### Turn off high availability

If running Alertmanager in high availability mode is not desired, setting `--cluster.listen-address=` prevents Alertmanager from listening to incoming peer requests.

## Contributing

Check the [Prometheus contributing page](https://github.com/prometheus/prometheus/blob/main/CONTRIBUTING.md).

To contribute to the user interface, refer to [ui/app/CONTRIBUTING.md](ui/app/CONTRIBUTING.md).

## Architecture

![](doc/arch.svg)

## License

Apache License 2.0, see [LICENSE](https://github.com/prometheus/alertmanager/blob/main/LICENSE).

[hub]: https://hub.docker.com/r/prom/alertmanager/
[circleci]: https://circleci.com/gh/prometheus/alertmanager
[quay]: https://quay.io/repository/prometheus/alertmanager
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[lima-vm/lima]]></title>
            <link>https://github.com/lima-vm/lima</link>
            <guid>https://github.com/lima-vm/lima</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Linux virtual machines, with a focus on running containers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lima-vm/lima">lima-vm/lima</a></h1>
            <p>Linux virtual machines, with a focus on running containers</p>
            <p>Language: Go</p>
            <p>Stars: 18,431</p>
            <p>Forks: 728</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>[[üåé**Web site**]](https://lima-vm.io/)
[[üìñ**Documentation**]](https://lima-vm.io/docs/)
[[üë§**Slack (`#lima`)**]](https://slack.cncf.io)

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;website/static/images/logo-dark.svg&quot;&gt;
  &lt;img alt=&quot;Shows a stylized &#039;Lima&#039; text in bold, modern font&quot; src=&quot;website/static/images/logo.svg&quot; width=400 /&gt;
&lt;/picture&gt;

# Lima: Linux Machines

[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/lima-vm/lima)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/6505/badge)](https://www.bestpractices.dev/projects/6505)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/lima-vm/lima/badge)](https://scorecard.dev/viewer/?uri=github.com/lima-vm/lima)

[Lima](https://lima-vm.io/) launches Linux virtual machines with automatic file sharing and port forwarding (similar to WSL2).

The original goal of Lima was to promote [containerd](https://containerd.io) including [nerdctl (contaiNERD ctl)](https://github.com/containerd/nerdctl)
to Mac users, but Lima can be used for non-container applications as well.

Lima also supports other container engines (Docker, Podman, Kubernetes, etc.) and non-macOS hosts (Linux, NetBSD, etc.).

## Getting started
Set up (Homebrew):
```bash
brew install lima
limactl start
```

To run Linux commands:
```bash
lima uname -a
```

To run containers with containerd:
```bash
lima nerdctl run --rm hello-world
```

To run containers with Docker:
```bash
limactl start template://docker
export DOCKER_HOST=$(limactl list docker --format &#039;unix://{{.Dir}}/sock/docker.sock&#039;)
docker run --rm hello-world
```

To run containers with Kubernetes:
```bash
limactl start template://k8s
export KUBECONFIG=$(limactl list k8s --format &#039;unix://{{.Dir}}/copied-from-guest/kubeconfig.yaml&#039;)
kubectl apply -f ...
```

See &lt;https://lima-vm.io/docs/&gt; for the further information.

## Contributing

We welcome contributions! Please see our [Contributing Guide](https://lima-vm.io/docs/community/contributing/) for details on:

- **Developer Certificate of Origin (DCO)**: All commits must be signed off with `git commit -s`
- Code licensing and pull request guidelines
- Testing requirements

## Community
### Adopters

Container environments:
- [Rancher Desktop](https://rancherdesktop.io/): Kubernetes and container management to the desktop
- [Colima](https://github.com/abiosoft/colima): Docker (and Kubernetes) on macOS with minimal setup
- [Finch](https://github.com/runfinch/finch): Finch is a command line client for local container development
- [Podman Desktop](https://podman-desktop.io/): Podman Desktop GUI has a plug-in for Lima virtual machines

GUI:
- [Lima xbar plugin](https://github.com/unixorn/lima-xbar-plugin): [xbar](https://xbarapp.com/) plugin to start/stop VMs from the menu bar and see their running status.
- [lima-gui](https://github.com/afbjorklund/lima-gui): Qt GUI for Lima

### Communication channels
&lt;!-- Duplicated from https://lima-vm.io/docs/community/ --&gt;
- [GitHub Discussions](https://github.com/lima-vm/lima/discussions)
- `#lima` channel in the CNCF Slack
  - New account: &lt;https://slack.cncf.io/&gt;
  - Login: &lt;https://cloud-native.slack.com/&gt;
- Zoom meetings (tentatively monthly)
  - Meeting notes &amp; agenda proposals: https://github.com/lima-vm/lima/discussions/categories/meetings
  - Calendar: https://zoom-lfx.platform.linuxfoundation.org/meetings/lima

### Code of Conduct
Lima follows the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/main/code-of-conduct.md).

- - -
**We are a [Cloud Native Computing Foundation](https://cncf.io/) incubating project.**

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://www.cncf.io/wp-content/uploads/2022/07/cncf-white-logo.svg&quot;&gt;
  &lt;img src=&quot;https://www.cncf.io/wp-content/uploads/2022/07/cncf-color-bg.svg&quot; width=300 /&gt;
&lt;/picture&gt;

The Linux Foundation¬Æ (TLF) has registered trademarks and uses trademarks. For a list of TLF trademarks, see [Trademark Usage](https://www.linuxfoundation.org/legal/trademark-usage).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[containerd/containerd]]></title>
            <link>https://github.com/containerd/containerd</link>
            <guid>https://github.com/containerd/containerd</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[An open and reliable container runtime]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/containerd/containerd">containerd/containerd</a></h1>
            <p>An open and reliable container runtime</p>
            <p>Language: Go</p>
            <p>Stars: 19,536</p>
            <p>Forks: 3,681</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>![containerd banner light mode](https://raw.githubusercontent.com/cncf/artwork/master/projects/containerd/horizontal/color/containerd-horizontal-color.png#gh-light-mode-only)
![containerd banner dark mode](https://raw.githubusercontent.com/cncf/artwork/master/projects/containerd/horizontal/white/containerd-horizontal-white.png#gh-dark-mode-only)

[![PkgGoDev](https://pkg.go.dev/badge/github.com/containerd/containerd/v2)](https://pkg.go.dev/github.com/containerd/containerd/v2)
[![Build Status](https://github.com/containerd/containerd/actions/workflows/ci.yml/badge.svg?event=merge_group)](https://github.com/containerd/containerd/actions?query=workflow%3ACI+event%3Amerge_group)
[![Nightlies](https://github.com/containerd/containerd/workflows/Nightly/badge.svg)](https://github.com/containerd/containerd/actions?query=workflow%3ANightly)
[![Go Report Card](https://goreportcard.com/badge/github.com/containerd/containerd/v2)](https://goreportcard.com/report/github.com/containerd/containerd/v2)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1271/badge)](https://bestpractices.coreinfrastructure.org/projects/1271)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/containerd/containerd/badge)](https://scorecard.dev/viewer/?uri=github.com/containerd/containerd)
[![Check Links](https://github.com/containerd/containerd/actions/workflows/links.yml/badge.svg)](https://github.com/containerd/containerd/actions/workflows/links.yml)

containerd is an industry-standard container runtime with an emphasis on simplicity, robustness, and portability. It is available as a daemon for Linux and Windows, which can manage the complete container lifecycle of its host system: image transfer and storage, container execution and supervision, low-level storage and network attachments, etc.

containerd is a member of CNCF with [&#039;graduated&#039;](https://landscape.cncf.io/?selected=containerd) status.

containerd is designed to be embedded into a larger system, rather than being used directly by developers or end-users.

![architecture](docs/historical/design/architecture.png)

## Announcements

### containerd v2.0 is now released!
See [`docs/containerd-2.0.md`](docs/containerd-2.0.md).

### Now Recruiting

We are a large inclusive OSS project that is welcoming help of any kind shape or form:
* Documentation help is needed to make the product easier to consume and extend.
* We need OSS community outreach/organizing help to get the word out; manage
and create messaging and educational content; and help with social media, community forums/groups, and google groups.
* We are actively inviting new [security advisors](https://github.com/containerd/project/blob/main/GOVERNANCE.md#security-advisors) to join the team.
* New subprojects are being created, core and non-core that could use additional development help.
* Each of the [containerd projects](https://github.com/containerd) has a list of issues currently being worked on or that need help resolving.
  - If the issue has not already been assigned to someone or has not made recent progress, and you are interested, please inquire.
  - If you are interested in starting with a smaller/beginner-level issue, look for issues with an `exp/beginner` tag, for example [containerd/containerd beginner issues.](https://github.com/containerd/containerd/issues?q=is%3Aissue+is%3Aopen+label%3Aexp%2Fbeginner)

## Getting Started

See our documentation on [containerd.io](https://containerd.io):
* [for ops and admins](docs/ops.md)
* [namespaces](docs/namespaces.md)
* [client options](docs/client-opts.md)

To get started contributing to containerd, see [CONTRIBUTING](CONTRIBUTING.md).

If you are interested in trying out containerd see our example at [Getting Started](docs/getting-started.md).

## Nightly builds

There are nightly builds available for download [here](https://github.com/containerd/containerd/actions?query=workflow%3ANightly).
Binaries are generated from `main` branch every night for `Linux` and `Windows`.

Please be aware: nightly builds might have critical bugs, it&#039;s not recommended for use in production and no support provided.

## Kubernetes (k8s) CI Dashboard Group

The [k8s CI dashboard group for containerd](https://testgrid.k8s.io/containerd) contains test results regarding
the health of kubernetes when run against main and a number of containerd release branches.

- [containerd-periodics](https://testgrid.k8s.io/containerd-periodic)

## Runtime Requirements

Runtime requirements for containerd are very minimal. Most interactions with
the Linux and Windows container feature sets are handled via [runc](https://github.com/opencontainers/runc) and/or
OS-specific libraries (e.g. [hcsshim](https://github.com/Microsoft/hcsshim) for Microsoft).
The current required version of `runc` is described in [RUNC.md](docs/RUNC.md).

There are specific features
used by containerd core code and snapshotters that will require a minimum kernel
version on Linux. With the understood caveat of distro kernel versioning, a
reasonable starting point for Linux is a minimum 4.x kernel version.

The overlay filesystem snapshotter, used by default, uses features that were
finalized in the 4.x kernel series. If you choose to use btrfs, there may
be more flexibility in kernel version (minimum recommended is 3.18), but will
require the btrfs kernel module and btrfs tools to be installed on your Linux
distribution.

To use Linux checkpoint and restore features, you will need `criu` installed on
your system. See more details in [Checkpoint and Restore](#checkpoint-and-restore).

Build requirements for developers are listed in [BUILDING](BUILDING.md).


## Supported Registries

Any registry which is compliant with the [OCI Distribution Specification](https://github.com/opencontainers/distribution-spec)
is supported by containerd.

For configuring registries, see [registry host configuration documentation](docs/hosts.md)

## Features

For a detailed overview of containerd&#039;s core concepts and the features it supports,
please refer to the [FEATURES.MD](./docs/features.md) document.

### Releases and API Stability

Please see [RELEASES.md](RELEASES.md) for details on versioning and stability
of containerd components.

Downloadable 64-bit Intel/AMD binaries of all official releases are available on
our [releases page](https://github.com/containerd/containerd/releases).

For other architectures and distribution support, you will find that many
Linux distributions package their own containerd and provide it across several
architectures, such as [Canonical&#039;s Ubuntu packaging](https://launchpad.net/ubuntu/bionic/+package/containerd).

#### Enabling command auto-completion

Starting with containerd 1.4, the urfave client feature for auto-creation of bash and zsh
autocompletion data is enabled. To use the autocomplete feature in a bash shell for example, source
the autocomplete/ctr file in your `.bashrc`, or manually like:

```
$ source ./contrib/autocomplete/ctr
```

#### Distribution of `ctr` autocomplete for bash and zsh

For bash, copy the `contrib/autocomplete/ctr` script into
`/etc/bash_completion.d/` and rename it to `ctr`. The `zsh_autocomplete`
file is also available and can be used similarly for zsh users.

Provide documentation to users to `source` this file into their shell if
you don&#039;t place the autocomplete file in a location where it is automatically
loaded for the user&#039;s shell environment.

### CRI

`cri` is a [containerd](https://containerd.io/) plugin implementation of the Kubernetes [container runtime interface (CRI)](https://github.com/kubernetes/cri-api/blob/master/pkg/apis/runtime/v1/api.proto). With it, you are able to use containerd as the container runtime for a Kubernetes cluster.

![cri](./docs/cri/cri.png)

#### CRI Status

`cri` is a native plugin of containerd. Since containerd 1.1, the cri plugin is built into the release binaries and enabled by default.

The `cri` plugin has reached GA status, representing that it is:
* Feature complete
* Works with Kubernetes 1.10 and above
* Passes all [CRI validation tests](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/cri-validation.md).
* Passes all [node e2e tests](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/e2e-node-tests.md).
* Passes all [e2e tests](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-testing/e2e-tests.md).

See results on the containerd k8s [test dashboard](https://testgrid.k8s.io/containerd)

#### Validating Your `cri` Setup
A Kubernetes incubator project, [cri-tools](https://github.com/kubernetes-sigs/cri-tools), includes programs for exercising CRI implementations. More importantly, cri-tools includes the program `critest` which is used for running [CRI Validation Testing](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/cri-validation.md).

#### CRI Guides
* [Installing with Ansible and Kubeadm](contrib/ansible/README.md)
* [For Non-Ansible Users, Preforming a Custom Installation Using the Release Tarball and Kubeadm](docs/getting-started.md)
* [CRI Plugin Testing Guide](./docs/cri/testing.md)
* [Debugging Pods, Containers, and Images with `crictl`](./docs/cri/crictl.md)
* [Configuring `cri` Plugins](./docs/cri/config.md)
* [Configuring containerd](https://github.com/containerd/containerd/blob/main/docs/man/containerd-config.8.md)

### Communication

For async communication and long-running discussions please use issues and pull requests on the GitHub repo.
This will be the best place to discuss design and implementation.

For sync communication catch us in the `#containerd` and `#containerd-dev` Slack channels on Cloud Native Computing Foundation&#039;s (CNCF) Slack - `cloud-native.slack.com`. Everyone is welcome to join and chat. [Get Invite to CNCF Slack.](https://slack.cncf.io)

Join our next community meeting hosted on Zoom. The schedule is posted on the [CNCF Calendar](https://www.cncf.io/calendar/) (search &#039;containerd&#039; to filter).

### Security audit

Security audits for the containerd project are hosted on our website. Please see the [security page at containerd.io](https://containerd.io/security/) for more information.

### Reporting security issues

Please follow the instructions at [containerd/project](https://github.com/containerd/project/blob/main/SECURITY.md#reporting-a-vulnerability)

## Licenses

The containerd codebase is released under the [Apache 2.0 license](LICENSE).
The README.md file and files in the &quot;docs&quot; folder are licensed under the
Creative Commons Attribution 4.0 International License. You may obtain a
copy of the license, titled CC-BY-4.0, at http://creativecommons.org/licenses/by/4.0/.

## Project details

**containerd** is the primary open source project within the broader containerd GitHub organization.
However, all projects within the repo have common maintainership, governance, and contributing
guidelines which are stored in a `project` repository commonly for all containerd projects.

Please find all these core project documents, including the:
 * [Project governance](https://github.com/containerd/project/blob/main/GOVERNANCE.md),
 * [Maintainers](https://github.com/containerd/project/blob/main/MAINTAINERS),
 * and [Contributing guidelines](https://github.com/containerd/project/blob/main/CONTRIBUTING.md)

information in our [`containerd/project`](https://github.com/containerd/project) repository.

## Adoption

Interested to see who is using containerd? Are you using containerd in a project?
Please add yourself via pull request to our [ADOPTERS.md](./ADOPTERS.md) file.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mudler/LocalAI]]></title>
            <link>https://github.com/mudler/LocalAI</link>
            <guid>https://github.com/mudler/LocalAI</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mudler/LocalAI">mudler/LocalAI</a></h1>
            <p>ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference</p>
            <p>Language: Go</p>
            <p>Stars: 37,785</p>
            <p>Forks: 2,982</p>
            <p>Stars today: 289 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;img width=&quot;300&quot; src=&quot;./core/http/static/logo.png&quot;&gt; &lt;br&gt;
&lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/fork&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI forks&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/stargazers&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI stars&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/pulls&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI pull-requests&quot;/&gt;
&lt;/a&gt;
&lt;a href=&#039;https://github.com/go-skynet/LocalAI/releases&#039;&gt;
&lt;img src=&#039;https://img.shields.io/github/release/go-skynet/LocalAI?&amp;label=Latest&amp;style=for-the-badge&#039;&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://hub.docker.com/r/localai/localai&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker&quot; alt=&quot;LocalAI Docker hub&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;tag=latest&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/quay.io-images-important.svg?&quot; alt=&quot;LocalAI Quay.io&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://twitter.com/LocalAI_API&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white&amp;label=LocalAI_API&quot; alt=&quot;Follow LocalAI_API&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://discord.gg/uJAeKSAGDy&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://dcbadge.vercel.app/api/server/uJAeKSAGDy?style=flat-square&amp;theme=default-inverted&quot; alt=&quot;Join LocalAI Discord Community&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/5539&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/5539&quot; alt=&quot;mudler%2FLocalAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; :bulb: Get help - [‚ùìFAQ](https://localai.io/faq/) [üí≠Discussions](https://github.com/go-skynet/LocalAI/discussions) [:speech_balloon: Discord](https://discord.gg/uJAeKSAGDy) [:book: Documentation website](https://localai.io/)
&gt;
&gt; [üíª Quickstart](https://localai.io/basics/getting_started/) [üñºÔ∏è Models](https://models.localai.io/) [üöÄ Roadmap](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap) [üõ´ Examples](https://github.com/mudler/LocalAI-examples) Try on 
[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;logo=telegram&amp;logoColor=white)](https://t.me/localaiofficial_bot)

[![tests](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml)[![Build and Release](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml)[![build container images](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml)[![Bump dependencies](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml)[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai)](https://artifacthub.io/packages/search?repo=localai)

**LocalAI** is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that&#039;s compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by [Ettore Di Giacinto](https://github.com/mudler).


## üìöüÜï Local Stack Family

üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:

&lt;table&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png&quot; width=&quot;300&quot; alt=&quot;LocalAGI Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI&#039;s Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png&quot; width=&quot;300&quot; alt=&quot;LocalRecall Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Screenshots


| Talk Interface | Generate Audio |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk](./docs/assets/images/screenshots/screenshot_tts.png) | ![Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low](./docs/assets/images/screenshots/screenshot_tts.png) |

| Models Overview | Generate Images |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-20 LocalAI - Models](./docs/assets/images/screenshots/screenshot_gallery.png) | ![Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev](./docs/assets/images/screenshots/screenshot_image.png) |

| Chat Interface | Home |
| --- | --- |
| ![Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5](./docs/assets/images/screenshots/screenshot_chat.png) | ![Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)](./docs/assets/images/screenshots/screenshot_home.png) |

| Login | Swarm |
| --- | --- |
|![Screenshot 2025-03-31 at 12-09-59 ](./docs/assets/images/screenshots/screenshot_login.png) | ![Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard](./docs/assets/images/screenshots/screenshot_p2p.png) |

## üíª Quickstart

Run the installer script:

```bash
# Basic installation
curl https://localai.io/install.sh | sh
```

For more installation options, see [Installer Options](https://localai.io/docs/advanced/installer/).

### macOS Download:

&lt;a href=&quot;https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;logo=apple&amp;logoColor=white&quot; alt=&quot;Download LocalAI for macOS&quot;/&gt;
&lt;/a&gt;

&gt; Note: the DMGs are not signed by Apple as quarantined. See https://github.com/mudler/LocalAI/issues/6268 for a workaround, fix is tracked here: https://github.com/mudler/LocalAI/issues/6244

Or run with docker:

&gt; **üí° Docker Run vs Docker Start**
&gt; 
&gt; - `docker run` creates and starts a new container. If a container with the same name already exists, this command will fail.
&gt; - `docker start` starts an existing container that was previously created with `docker run`.
&gt; 
&gt; If you&#039;ve already run LocalAI before and want to start it again, use: `docker start -i local-ai`

### CPU only image:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
```

### NVIDIA GPU Images:

```bash
# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# CUDA 11.7
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-11

# NVIDIA Jetson (L4T) ARM64
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64
```

### AMD GPU Images (ROCm):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
```

### Intel GPU Images (oneAPI):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
```

### Vulkan GPU Images:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
```

### AIO Images (pre-downloaded models):

```bash
# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# NVIDIA CUDA 11 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-11

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
```

For more information about the AIO images and pre-downloaded models, see [Container Documentation](https://localai.io/basics/container/).

To load models:

```bash
# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
```

&gt; ‚ö° **Automatic Backend Detection**: When you install models from the gallery or YAML files, LocalAI automatically detects your system&#039;s GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see [GPU Acceleration](https://localai.io/features/gpu-acceleration/#automatic-backend-detection).

For more information, see [üíª Getting started](https://localai.io/basics/getting_started/index.html), if you are interested in our roadmap items and future enhancements, you can see the [Issues labeled as Roadmap here](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)

## üì∞ Latest project news

- October 2025: üîå [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) support added for agentic capabilities with external tools
- September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.
- August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with `development` suffix in the gallery ): https://github.com/mudler/LocalAI/pull/6049 https://github.com/mudler/LocalAI/pull/6119 https://github.com/mudler/LocalAI/pull/6121 https://github.com/mudler/LocalAI/pull/6060
- July/August 2025: üîç [Object Detection](https://localai.io/features/object-detection/) added to the API featuring [rf-detr](https://github.com/roboflow/rf-detr)
- July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. [Read the release notes](https://github.com/mudler/LocalAI/releases/tag/v3.2.0)
- June 2025: [Backend management](https://github.com/mudler/LocalAI/pull/5607) has been added. Attention: extras images are going to be deprecated from the next release! Read [the backend management PR](https://github.com/mudler/LocalAI/pull/5607).
- May 2025: [Audio input](https://github.com/mudler/LocalAI/pull/5466) and [Reranking](https://github.com/mudler/LocalAI/pull/5396) in llama.cpp backend, [Realtime API](https://github.com/mudler/LocalAI/pull/5392),  Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).
- May 2025: Important: image name changes [See release](https://github.com/mudler/LocalAI/releases/tag/v2.29.0)
- Apr 2025: Rebrand, WebUI enhancements
- Apr 2025: [LocalAGI](https://github.com/mudler/LocalAGI) and [LocalRecall](https://github.com/mudler/LocalRecall) join the LocalAI family stack.
- Apr 2025: WebUI overhaul, AIO images updates
- Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images
- Jan 2025: LocalAI model release: https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3, SANA support in diffusers: https://github.com/mudler/LocalAI/pull/4603
- Dec 2024: stablediffusion.cpp backend (ggml) added ( https://github.com/mudler/LocalAI/pull/4289 )
- Nov 2024: Bark.cpp backend added ( https://github.com/mudler/LocalAI/pull/4287 )
- Nov 2024: Voice activity detection models (**VAD**) added to the API: https://github.com/mudler/LocalAI/pull/4204
- Oct 2024: examples moved to [LocalAI-examples](https://github.com/mudler/LocalAI-examples)
- Aug 2024:  üÜï FLUX-1, [P2P Explorer](https://explorer.localai.io)
- July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: https://github.com/mudler/LocalAI/pull/2723. P2P Global community pools: https://github.com/mudler/LocalAI/issues/3113
- May 2024: üî•üî• Decentralized P2P llama.cpp:  https://github.com/mudler/LocalAI/pull/2343 (peer2peer llama.cpp!) üëâ Docs  https://localai.io/features/distribute/
- May 2024: üî•üî• Distributed inferencing: https://github.com/mudler/LocalAI/pull/2324
- April 2024: Reranker API: https://github.com/mudler/LocalAI/pull/2121

Roadmap items: [List of issues](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)

## üöÄ [Features](https://localai.io/features/)

- üß© [Backend Gallery](https://localai.io/backends/): Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.
- üìñ [Text generation with GPTs](https://localai.io/features/text-generation/) (`llama.cpp`, `transformers`, `vllm` ... [:book: and more](https://localai.io/model-compatibility/index.html#model-compatibility-table))
- üó£ [Text to Audio](https://localai.io/features/text-to-audio/)
- üîà [Audio to Text](https://localai.io/features/audio-to-text/) (Audio transcription with `whisper.cpp`)
- üé® [Image generation](https://localai.io/features/image-generation)
- üî• [OpenAI-alike tools API](https://localai.io/features/openai-functions/) 
- üß† [Embeddings generation for vector databases](https://localai.io/features/embeddings/)
- ‚úçÔ∏è [Constrained grammars](https://localai.io/features/constrained_grammars/)
- üñºÔ∏è [Download Models directly from Huggingface ](https://localai.io/models/)
- ü•Ω [Vision API](https://localai.io/features/gpt-vision/)
- üîç [Object Detection](https://localai.io/features/object-detection/)
- üìà [Reranker API](https://localai.io/features/reranker/)
- üÜïüñß [P2P Inferencing](https://localai.io/features/distribute/)
- üÜïüîå [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) - Agentic capabilities with external tools and [LocalAGI&#039;s Agentic capabilities](https://github.com/mudler/LocalAGI)
- üîä Voice activity detection (Silero-VAD support)
- üåç Integrated WebUI!

## üß© Supported Backends &amp; Acceleration

LocalAI supports a comprehensive range of AI backends with multiple acceleration options:

### Text Generation &amp; Language Models
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **llama.cpp** | LLM inference in C/C++ | CUDA 11/12, ROCm, Intel SYCL, Vulkan, Metal, CPU |
| **vLLM** | Fast LLM inference with PagedAttention | CUDA 12, ROCm, Intel |
| **transformers** | HuggingFace transformers framework | CUDA 11/12, ROCm, Intel, CPU |
| **exllama2** | GPTQ inference library | CUDA 12 |
| **MLX** | Apple Silicon LLM inference | Metal (M1/M2/M3+) |
| **MLX-VLM** | Apple Silicon Vision-Language Models | Metal (M1/M2/M3+) |

### Audio &amp; Speech Processing
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **whisper.cpp** | OpenAI Whisper in C/C++ | CUDA 12, ROCm, Intel SYCL, Vulkan, CPU |
| **faster-whisper** | Fast Whisper with CTranslate2 | CUDA 12, ROCm, Intel, CPU |
| **bark** | Text-to-audio generation | CUDA 12, ROCm, Intel |
| **bark-cpp** | C++ implementation of Bark | CUDA, Metal, CPU |
| **coqui** | Advanced TTS with 1100+ languages | CUDA 12, ROCm, Intel, CPU |
| **kokoro** | Lightweight TTS model | CUDA 12, ROCm, Intel, CPU |
| **chatterbox** | Production-grade TTS | CUDA 11/12, CPU |
| **piper** | Fast neural TTS system | CPU |
| **kitten-tts** | Kitten TTS models | CPU |
| **silero-vad** | Voice Activity Detection | CPU |
| **neutts** | Text-to-speech with voice cloning | CUDA 12, ROCm, CPU |

### Image &amp; Video Generation
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **stablediffusion.cpp** | Stable Diffusion in C/C++ | CUDA 12, Intel SYCL, Vulkan, CPU |
| **diffusers** | HuggingFace diffusion models | CUDA 11/12, ROCm, Intel, Metal, CPU |

### Specialized AI Tasks
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **rfdetr** | Real-time object detection | CUDA 12, Intel, CPU |
| **rerankers** | Document reranking API | CUDA 11/12, ROCm, Intel, CPU |
| **local-store** | Vector database | CPU |
| **huggingface** | HuggingFace API integration | API-based |

### Hardware Acceleration Matrix

| Acceleration Type | Supported Backends | Hardware Support |
|-------------------|-------------------|------------------|
| **NVIDIA CUDA 11** | llama.cpp, whisper, stablediffusion, diffusers, rerankers, bark, chatterbox | Nvidia hardware |
| **NVIDIA CUDA 12** | All CUDA-compatible backends | Nvidia hardware |
| **AMD ROCm** | llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts | AMD Graphics |
| **Intel oneAPI** | llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark | Intel Arc, Intel iGPUs |
| **Apple Metal** | llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp | Apple M1/M2/M3+ |
| **Vulkan** | llama.cpp, whisper, stablediffusion | Cross-platform GPUs |
| **NVIDIA Jetson** | llama.cpp, whisper, stablediffusion, diffusers, rfdetr | ARM64 embedded AI |
| **CPU Optimized** | All backends | AVX/AVX2/AVX512, quantization support |

### üîó Community and integrations

Build and deploy custom containers:
- https://github.com/sozercan/aikit

WebUIs:
- https://github.com/Jirubizu/localai-admin
- https://github.com/go-skynet/LocalAI-frontend
- QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) https://github.com/reid41/QA-Pilot

Agentic Libraries:
- https://github.com/mudler/cogito

MCPs:
- https://github.com/mudler/MCPs

Model galleries
- https://github.com/go-skynet/model-gallery

Voice:
- https://github.com/richiejp/VoxInput

Other:
- Helm chart https://github.com/go-skynet/helm-charts
- VSCode extension https://github.com/badgooooor/localai-vscode-plugin
- Langchain: https://python.langchain.com/docs/integrations/providers/localai/
- Terminal utility https://github.com/djcopley/ShellOracle
- Local Smart assistant https://github.com/mudler/LocalAGI
- Home Assistant https://github.com/sammcj/homeassistant-localai / https://github.com/drndos/hass-openai-custom-conversation / https://github.com/valentinfrlch/ha-gpt4vision
- Discord bot https://github.com/mudler/LocalAGI/tree/main/examples/discord
- Slack bot https://github.com/mudler/LocalAGI/tree/main/examples/slack
- Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) https://github.com/reid41/shell-pilot
- Telegram bot https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[temporalio/temporal]]></title>
            <link>https://github.com/temporalio/temporal</link>
            <guid>https://github.com/temporalio/temporal</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[Temporal service]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/temporalio/temporal">temporalio/temporal</a></h1>
            <p>Temporal service</p>
            <p>Language: Go</p>
            <p>Stars: 16,491</p>
            <p>Forks: 1,169</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;div class=&quot;title-block&quot; style=&quot;text-align: center;&quot; align=&quot;center&quot;&gt;

# Temporal‚Äîdurable execution platform

&lt;p&gt;&lt;img title=&quot;temporal logo&quot; src=&quot;https://avatars.githubusercontent.com/u/56493103?s=320&quot; width=&quot;320&quot; height=&quot;320&quot;&gt;&lt;/p&gt;

[![GitHub Release](https://img.shields.io/github/v/release/temporalio/temporal)](https://github.com/temporalio/temporal/releases/latest)
[![GitHub License](https://img.shields.io/github/license/temporalio/temporal)](https://github.com/temporalio/temporal/blob/main/LICENSE)
[![Code Coverage](https://img.shields.io/badge/codecov-report-blue)](https://app.codecov.io/gh/temporalio/temporal)
[![Community](https://img.shields.io/static/v1?label=community&amp;message=get%20help&amp;color=informational)](https://community.temporal.io)
[![Go Report Card](https://goreportcard.com/badge/github.com/temporalio/temporal)](https://goreportcard.com/report/github.com/temporalio/temporal)

**[Introduction](#introduction) &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Getting Started](#getting-started) &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Contributing](#contributing) &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Temporal Docs](https://docs.temporal.io/) &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Temporal 101](https://learn.temporal.io/courses/temporal_101/)**

&lt;/div&gt;

## Introduction

Temporal is a durable execution platform that enables developers to build scalable applications without sacrificing productivity or reliability.
The Temporal server executes units of application logic called Workflows in a resilient manner that automatically handles intermittent failures, and retries failed operations.

Temporal is a mature technology that originated as a fork of Uber&#039;s Cadence.
It is developed by [Temporal Technologies](https://temporal.io/), a startup by the creators of Cadence.

[![image](https://github.com/temporalio/temporal/assets/251288/693d18b5-01de-4a3b-b47b-96347b84f610)](https://youtu.be/wIpz4ioK0gI &#039;Getting to know Temporal&#039;)

## Getting Started

### Download and Start Temporal Server Locally

Execute the following commands to start a pre-built image along with all the dependencies.

```bash
brew install temporal
temporal server start-dev
```

Refer to [Temporal CLI](https://docs.temporal.io/cli/#installation) documentation for more installation options.

### Run the Samples

Clone or download samples for [Go](https://github.com/temporalio/samples-go) or [Java](https://github.com/temporalio/samples-java) and run them with the local Temporal server.
We have a number of [HelloWorld type scenarios](https://github.com/temporalio/samples-java#helloworld) available, as well as more advanced ones. Note that the sets of samples are currently different between Go and Java.

### Use CLI

Use [Temporal CLI](https://docs.temporal.io/cli/) to interact with the running Temporal server.

```bash
temporal operator namespace list
temporal workflow list
```

### Use Temporal Web UI

Try [Temporal Web UI](https://docs.temporal.io/web-ui) by opening [http://localhost:8233](http://localhost:8233) for viewing your sample workflows executing on Temporal.

## Repository

This repository contains the source code of the Temporal server. To implement Workflows, Activities and Workers, use one of the [supported languages](https://docs.temporal.io/dev-guide/).

## Contributing

We&#039;d love your help in making Temporal great.

Helpful links to get started:

- [work on or propose a new feature](https://github.com/temporalio/proposals)
- [learn about the Temporal Server architecture](./docs/architecture/README.md)
- [learn how to build and run the Temporal Server locally](./CONTRIBUTING.md)
- [learn about Temporal Server testing tools and best practices](./docs/development/testing.md)
- join the Temporal community [forum](https://community.temporal.io) and [Slack](https://t.mp/slack)

## License

[MIT License](https://github.com/temporalio/temporal/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[prometheus/node_exporter]]></title>
            <link>https://github.com/prometheus/node_exporter</link>
            <guid>https://github.com/prometheus/node_exporter</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[Exporter for machine metrics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prometheus/node_exporter">prometheus/node_exporter</a></h1>
            <p>Exporter for machine metrics</p>
            <p>Language: Go</p>
            <p>Stars: 12,760</p>
            <p>Forks: 2,564</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># Node exporter

[![CircleCI](https://circleci.com/gh/prometheus/node_exporter/tree/master.svg?style=shield)][circleci]
![bsd workflow](https://github.com/prometheus/node_exporter/actions/workflows/bsd.yml/badge.svg)
![golangci-lint workflow](https://github.com/prometheus/node_exporter/actions/workflows/golangci-lint.yml/badge.svg)
[![Docker Repository on Quay](https://quay.io/repository/prometheus/node-exporter/status)][quay]
[![Docker Pulls](https://img.shields.io/docker/pulls/prom/node-exporter.svg?maxAge=604800)][hub]
[![Go Report Card](https://goreportcard.com/badge/github.com/prometheus/node_exporter)][goreportcard]

Prometheus exporter for hardware and OS metrics exposed by \*NIX kernels, written
in Go with pluggable metric collectors.

The [Windows exporter](https://github.com/prometheus-community/windows_exporter) is recommended for Windows users.
To expose NVIDIA GPU metrics, [prometheus-dcgm
](https://github.com/NVIDIA/dcgm-exporter)
can be used.

## Installation and Usage

If you are new to Prometheus and `node_exporter` there is a [simple step-by-step guide](https://prometheus.io/docs/guides/node-exporter/).

The `node_exporter` listens on HTTP port 9100 by default. See the `--help` output for more options.

### Ansible

For automated installs with [Ansible](https://www.ansible.com/), there is the [Prometheus Community role](https://github.com/prometheus-community/ansible).

### Docker

The `node_exporter` is designed to monitor the host system. Deploying in containers requires
extra care in order to avoid monitoring the container itself.

For situations where containerized deployment is needed, some extra flags must be used to allow
the `node_exporter` access to the host namespaces.

Be aware that any non-root mount points you want to monitor will need to be bind-mounted
into the container.

If you start container for host monitoring, specify `path.rootfs` argument.
This argument must match path in bind-mount of host root. The node\_exporter will use
`path.rootfs` as prefix to access host filesystem.

```bash
docker run -d \
  --net=&quot;host&quot; \
  --pid=&quot;host&quot; \
  -v &quot;/:/host:ro,rslave&quot; \
  quay.io/prometheus/node-exporter:latest \
  --path.rootfs=/host
```

For Docker compose, similar flag changes are needed.

```yaml
---
version: &#039;3.8&#039;

services:
  node_exporter:
    image: quay.io/prometheus/node-exporter:latest
    container_name: node_exporter
    command:
      - &#039;--path.rootfs=/host&#039;
    network_mode: host
    pid: host
    restart: unless-stopped
    volumes:
      - &#039;/:/host:ro,rslave&#039;
```

On some systems, the `timex` collector requires an additional Docker flag,
`--cap-add=SYS_TIME`, in order to access the required syscalls.

## Collectors

There is varying support for collectors on each operating system. The tables
below list all existing collectors and the supported systems.

Collectors are enabled by providing a `--collector.&lt;name&gt;` flag.
Collectors that are enabled by default can be disabled by providing a `--no-collector.&lt;name&gt;` flag.
To enable only some specific collector(s), use `--collector.disable-defaults --collector.&lt;name&gt; ...`.

### Include &amp; Exclude flags

A few collectors can be configured to include or exclude certain patterns using dedicated flags. The exclude flags are used to indicate &quot;all except&quot;, while the include flags are used to say &quot;none except&quot;. Note that these flags are mutually exclusive on collectors that support both.

Example:

```txt
--collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
```

List:

Collector | Scope | Include Flag | Exclude Flag
--- | --- | --- | ---
arp | device | --collector.arp.device-include | --collector.arp.device-exclude
cpu | bugs | --collector.cpu.info.bugs-include | N/A
cpu | flags | --collector.cpu.info.flags-include | N/A
diskstats | device | --collector.diskstats.device-include | --collector.diskstats.device-exclude
ethtool | device | --collector.ethtool.device-include | --collector.ethtool.device-exclude
ethtool | metrics | --collector.ethtool.metrics-include | N/A
filesystem | fs-types | --collector.filesystem.fs-types-include | --collector.filesystem.fs-types-exclude
filesystem | mount-points | --collector.filesystem.mount-points-include | --collector.filesystem.mount-points-exclude
hwmon | chip | --collector.hwmon.chip-include | --collector.hwmon.chip-exclude
hwmon | sensor | --collector.hwmon.sensor-include | --collector.hwmon.sensor-exclude
interrupts | name | --collector.interrupts.name-include | --collector.interrupts.name-exclude
netdev | device | --collector.netdev.device-include | --collector.netdev.device-exclude
qdisk | device | --collector.qdisk.device-include | --collector.qdisk.device-exclude
slabinfo | slab-names | --collector.slabinfo.slabs-include | --collector.slabinfo.slabs-exclude
sysctl | all | --collector.sysctl.include | N/A
systemd | unit | --collector.systemd.unit-include | --collector.systemd.unit-exclude

### Enabled by default

Name     | Description | OS
---------|-------------|----
arp | Exposes ARP statistics from `/proc/net/arp`. | Linux
bcache | Exposes bcache statistics from `/sys/fs/bcache/`. | Linux
bonding | Exposes the number of configured and active slaves of Linux bonding interfaces. | Linux
btrfs | Exposes btrfs statistics | Linux
boottime | Exposes system boot time derived from the `kern.boottime` sysctl. | Darwin, Dragonfly, FreeBSD, NetBSD, OpenBSD, Solaris
conntrack | Shows conntrack statistics (does nothing if no `/proc/sys/net/netfilter/` present). | Linux
cpu | Exposes CPU statistics | Darwin, Dragonfly, FreeBSD, Linux, Solaris, OpenBSD
cpufreq | Exposes CPU frequency statistics | Linux, Solaris
diskstats | Exposes disk I/O statistics. | Darwin, Linux, OpenBSD
dmi | Expose Desktop Management Interface (DMI) info from `/sys/class/dmi/id/` | Linux
edac | Exposes error detection and correction statistics. | Linux
entropy | Exposes available entropy. | Linux
exec | Exposes execution statistics. | Dragonfly, FreeBSD
fibrechannel | Exposes fibre channel information and statistics from `/sys/class/fc_host/`. | Linux
filefd | Exposes file descriptor statistics from `/proc/sys/fs/file-nr`. | Linux
filesystem | Exposes filesystem statistics, such as disk space used. | Darwin, Dragonfly, FreeBSD, Linux, OpenBSD
hwmon | Expose hardware monitoring and sensor data from `/sys/class/hwmon/`. | Linux
infiniband | Exposes network statistics specific to InfiniBand and Intel OmniPath configurations. | Linux
ipvs | Exposes IPVS status from `/proc/net/ip_vs` and stats from `/proc/net/ip_vs_stats`. | Linux
loadavg | Exposes load average. | Darwin, Dragonfly, FreeBSD, Linux, NetBSD, OpenBSD, Solaris
mdadm | Exposes statistics about devices in `/proc/mdstat` (does nothing if no `/proc/mdstat` present). | Linux
meminfo | Exposes memory statistics. | Darwin, Dragonfly, FreeBSD, Linux, OpenBSD
netclass | Exposes network interface info from `/sys/class/net/` | Linux
netdev | Exposes network interface statistics such as bytes transferred. | Darwin, Dragonfly, FreeBSD, Linux, OpenBSD
netisr | Exposes netisr statistics | FreeBSD
netstat | Exposes network statistics from `/proc/net/netstat`. This is the same information as `netstat -s`. | Linux
nfs | Exposes NFS client statistics from `/proc/net/rpc/nfs`. This is the same information as `nfsstat -c`. | Linux
nfsd | Exposes NFS kernel server statistics from `/proc/net/rpc/nfsd`. This is the same information as `nfsstat -s`. | Linux
nvme | Exposes NVMe info from `/sys/class/nvme/` | Linux
os | Expose OS release info from `/etc/os-release` or `/usr/lib/os-release` | _any_
powersupplyclass | Exposes Power Supply statistics from `/sys/class/power_supply` | Linux
pressure | Exposes pressure stall statistics from `/proc/pressure/`. | Linux (kernel 4.20+ and/or [CONFIG\_PSI](https://www.kernel.org/doc/html/latest/accounting/psi.html))
rapl | Exposes various statistics from `/sys/class/powercap`. | Linux
schedstat | Exposes task scheduler statistics from `/proc/schedstat`. | Linux
selinux | Exposes SELinux statistics. | Linux
sockstat | Exposes various statistics from `/proc/net/sockstat`. | Linux
softnet | Exposes statistics from `/proc/net/softnet_stat`. | Linux
stat | Exposes various statistics from `/proc/stat`. This includes boot time, forks and interrupts. | Linux
tapestats | Exposes statistics from `/sys/class/scsi_tape`. | Linux
textfile | Exposes statistics read from local disk. The `--collector.textfile.directory` flag must be set. | _any_
thermal | Exposes thermal statistics like `pmset -g therm`. | Darwin
thermal\_zone | Exposes thermal zone &amp; cooling device statistics from `/sys/class/thermal`. | Linux
time | Exposes the current system time. | _any_
timex | Exposes selected adjtimex(2) system call stats. | Linux
udp_queues | Exposes UDP total lengths of the rx_queue and tx_queue from `/proc/net/udp` and `/proc/net/udp6`. | Linux
uname | Exposes system information as provided by the uname system call. | Darwin, FreeBSD, Linux, OpenBSD
vmstat | Exposes statistics from `/proc/vmstat`. | Linux
watchdog | Exposes statistics from `/sys/class/watchdog` | Linux
xfs | Exposes XFS runtime statistics. | Linux (kernel 4.4+)
zfs | Exposes [ZFS](http://open-zfs.org/) performance statistics. | FreeBSD, [Linux](http://zfsonlinux.org/), Solaris

### Disabled by default

`node_exporter` also implements a number of collectors that are disabled by default.  Reasons for this vary by
collector, and may include:
* High cardinality
* Prolonged runtime that exceeds the Prometheus `scrape_interval` or `scrape_timeout`
* Significant resource demands on the host

You can enable additional collectors as desired by adding them to your
init system&#039;s or service supervisor&#039;s startup configuration for
`node_exporter` but caution is advised.  Enable at most one at a time,
testing first on a non-production system, then by hand on a single
production node.  When enabling additional collectors, you should
carefully monitor the change by observing the `
scrape_duration_seconds` metric to ensure that collection completes
and does not time out.  In addition, monitor the
`scrape_samples_post_metric_relabeling` metric to see the changes in
cardinality.

Name     | Description | OS
---------|-------------|----
buddyinfo | Exposes statistics of memory fragments as reported by /proc/buddyinfo. | Linux
cgroups | A summary of the number of active and enabled cgroups | Linux
cpu\_vulnerabilities | Exposes CPU vulnerability information from sysfs. | Linux
devstat | Exposes device statistics | Dragonfly, FreeBSD
drm | Expose GPU metrics using sysfs / DRM, `amdgpu` is the only driver which exposes this information through DRM | Linux
drbd | Exposes Distributed Replicated Block Device statistics (to version 8.4) | Linux
ethtool | Exposes network interface information and network driver statistics equivalent to `ethtool`, `ethtool -S`, and `ethtool -i`. | Linux
interrupts | Exposes detailed interrupts statistics. | Linux, OpenBSD
ksmd | Exposes kernel and system statistics from `/sys/kernel/mm/ksm`. | Linux
lnstat | Exposes stats from `/proc/net/stat/`. | Linux
logind | Exposes session counts from [logind](http://www.freedesktop.org/wiki/Software/systemd/logind/). | Linux
meminfo\_numa | Exposes memory statistics from `/sys/devices/system/node/node[0-9]*/meminfo`, `/sys/devices/system/node/node[0-9]*/numastat`. | Linux
mountstats | Exposes filesystem statistics from `/proc/self/mountstats`. Exposes detailed NFS client statistics. | Linux
network_route | Exposes the routing table as metrics | Linux
pcidevice | Exposes pci devices&#039; information including their link status and parent devices. | Linux
perf | Exposes perf based metrics (Warning: Metrics are dependent on kernel configuration and settings). | Linux
processes | Exposes aggregate process statistics from `/proc`. | Linux
qdisc | Exposes [queuing discipline](https://en.wikipedia.org/wiki/Network_scheduler#Linux_kernel) statistics | Linux
slabinfo | Exposes slab statistics from `/proc/slabinfo`. Note that permission of `/proc/slabinfo` is usually 0400, so set it appropriately. | Linux
softirqs | Exposes detailed softirq statistics from `/proc/softirqs`. | Linux
sysctl | Expose sysctl values from `/proc/sys`. Use `--collector.sysctl.include(-info)` to configure. | Linux
swap | Expose swap information from `/proc/swaps`. | Linux
systemd | Exposes service and system status from [systemd](http://www.freedesktop.org/wiki/Software/systemd/). | Linux
tcpstat | Exposes TCP connection status information from `/proc/net/tcp` and `/proc/net/tcp6`. (Warning: the current version has potential performance issues in high load situations.) | Linux
wifi | Exposes WiFi device and station statistics. | Linux
xfrm | Exposes statistics from `/proc/net/xfrm_stat` | Linux
zoneinfo | Exposes NUMA memory zone metrics. | Linux

### Deprecated

These collectors are deprecated and will be removed in the next major release.

Name     | Description | OS
---------|-------------|----
ntp | Exposes local NTP daemon health to check [time](./docs/TIME.md) | _any_
runit | Exposes service status from [runit](http://smarden.org/runit/). | _any_
supervisord | Exposes service status from [supervisord](http://supervisord.org/). | _any_

### Perf Collector

The `perf` collector may not work out of the box on some Linux systems due to kernel
configuration and security settings. To allow access, set the following `sysctl`
parameter:

```
sysctl -w kernel.perf_event_paranoid=X
```

- 2 allow only user-space measurements (default since Linux 4.6).
- 1 allow both kernel and user measurements (default before Linux 4.6).
- 0 allow access to CPU-specific data but not raw tracepoint samples.
- -1 no restrictions.

Depending on the configured value different metrics will be available, for most
cases `0` will provide the most complete set. For more information see [`man 2
perf_event_open`](http://man7.org/linux/man-pages/man2/perf_event_open.2.html).

By default, the `perf` collector will only collect metrics of the CPUs that
`node_exporter` is running on (ie
[`runtime.NumCPU`](https://golang.org/pkg/runtime/#NumCPU). If this is
insufficient (e.g. if you run `node_exporter` with its CPU affinity set to
specific CPUs), you can specify a list of alternate CPUs by using the
`--collector.perf.cpus` flag. For example, to collect metrics on CPUs 2-6, you
would specify: `--collector.perf --collector.perf.cpus=2-6`. The CPU
configuration is zero indexed and can also take a stride value; e.g.
`--collector.perf --collector.perf.cpus=1-10:5` would collect on CPUs
1, 5, and 10.

The `perf` collector is also able to collect
[tracepoint](https://www.kernel.org/doc/html/latest/core-api/tracepoint.html)
counts when using the `--collector.perf.tracepoint` flag. Tracepoints can be
found using [`perf list`](http://man7.org/linux/man-pages/man1/perf.1.html) or
from debugfs. And example usage of this would be
`--collector.perf.tracepoint=&quot;sched:sched_process_exec&quot;`.

### Sysctl Collector

The `sysctl` collector can be enabled with `--collector.sysctl`. It supports exposing numeric sysctl values
as metrics using the `--collector.sysctl.include` flag and string values as info metrics by using the
`--collector.sysctl.include-info` flag. The flags can be repeated. For sysctl with multiple numeric values,
an optional mapping can be given to expose each value as its own metric. Otherwise an `index` label is used
to identify the different fields.

#### Examples
##### Numeric values
###### Single values
Using `--collector.sysctl.include=vm.user_reserve_kbytes`:
`vm.user_reserve_kbytes = 131072` -&gt; `node_sysctl_vm_user_reserve_kbytes 131072`

###### Multiple values
A sysctl can contain multiple values, for example:
```
net.ipv4.tcp_rmem = 4096	131072	6291456
```
Using `--collector.sysctl.include=net.ipv4.tcp_rmem` the collector will expose:
```
node_sysctl_net_ipv4_tcp_rmem{index=&quot;0&quot;} 4096
node_sysctl_net_ipv4_tcp_rmem{index=&quot;1&quot;} 131072
node_sysctl_net_ipv4_tcp_rmem{index=&quot;2&quot;} 6291456
```
If the indexes have defined meaning like in this case, the values can be mapped to multiple metrics by appending the mapping to the --collector.sysctl.include flag:
Using `--collector.sysctl.include=net.ipv4.tcp_rmem:min,default,max` the collector will expose:
```
node_sysctl_net_ipv4_tcp_rmem_min 4096
node_sysctl_net_ipv4_tcp_rmem_default 131072
node_sysctl_net_ipv4_tcp_rmem_max 6291456
```

##### String values
String values need to be exposed as info metric. The user selects them by using the `--collector.sysctl.include-info` flag.

###### Single values
`kernel.core_pattern = core` -&gt; `node_sysctl_info{key=&quot;kernel.core_pattern_info&quot;, value=&quot;core&quot;} 1`

###### Multiple values
Given the following sysctl:
```
kernel.seccomp.actions_avail = kill_process kill_thread trap errno trace log allow
```
Setting `--collector.sysctl.include-info=kernel.seccomp.actions_avail` will yield:
```
node_sysctl_info{key=&quot;kernel.seccomp.actions_avail&quot;, index=&quot;0&quot;, value=&quot;kill_process&quot;} 1
node_sysctl_info{key=&quot;kernel.seccomp.actions_avail&quot;, index=&quot;1&quot;, value=&quot;kill_thread&quot;} 1
...
```

### Textfile Collector

The `textfile` collector is similar to the [Pushgateway](https://github.com/prometheus/pushgateway),
in that it allows exporting of statistics from batch jobs. It can also be used
to export static metrics, such as what role a machine has. The Pushgateway
should be used for service-level metrics. The `textfile` module is for metrics
that are tied to a machine.

To use it, set the `--collector.textfile.directory` flag on the `node_exporter` commandline. The
collector will parse all files in that directory matching the glob `*.prom`
using the [text
format](http://prometheus.io/docs/instrumenting/exposition_formats/). **Note:** Timestamps are not supported.

To atomically push completion time for a cron job:
```
echo my_batch_job_completion_time $(date +%s) &gt; /path/to/directory/my_batch_job.prom.$$
mv /path/to/directory/my_batch_job.prom.$$ /path/to/directory/my_batch_job.prom
```

To statically set roles for a machine using labels:
```
echo &#039;role{role=&quot;application_server&quot;} 1&#039; &gt; /path/to/directory/role.prom.$$
mv /path/to/directory/role.prom.$$ /path/to/directory/role.prom
```

### Filtering enabled collectors

The `node_exporter` will expose all metrics from enabled collectors by default.  This is the recommended way to collect metrics to avoid errors when comparing metrics of different families.

For advanced use the `node_exporter` can be passed an optional list of collectors to filter metrics. The parameters `collect[]` and `exclude[]` can be used multiple times (but cannot be combined).  In Prometheus configuration you can use this syntax under the [scrape config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#&lt;scrape_config&gt;).

Collect only `cpu` and `meminfo` collector metrics:
```
  params:
    collect[]:
      - cpu
      - meminfo
```

Collect all enabled collector metrics but exclude `netdev`:
```
  params:
    exclude[]:
      - netdev
```

This can be useful for having different Prometheus servers collect specific metrics from nodes.

## Development building and running

Prerequisites:

* [Go compiler](https://golang.org/dl/)
* RHEL/CentOS: `glibc-static` package.

Building:

    git clone https://github.com/prometheus/node_exporter.git
    cd node_exporter
    make build
    ./node_exporter &lt;flags&gt;

To see all available configuration flags:

    ./node_exporter -h

## Running tests

    make test

## TLS endpoint

**EXPERIMENTAL**

The exporter supports TLS via a new web configuration file.

```console
./node_exporter --web.config.file=web-config.yml
```

See the [exporter-toolkit web-configuration](https://github.com/prometheus/exporter-toolkit/blob/master/docs/web-configuration.md) for more details.

[travis]: https://travis-ci.org/prometheus/node_exporter
[hub]: https://hub.docker.com/r/prom/node-exporter/
[circleci]: https://circleci.com/gh/prometheus/node_exporter
[quay]: https://quay.io/rep

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes-sigs/metrics-server]]></title>
            <link>https://github.com/kubernetes-sigs/metrics-server</link>
            <guid>https://github.com/kubernetes-sigs/metrics-server</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Scalable and efficient source of container resource metrics for Kubernetes built-in autoscaling pipelines.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes-sigs/metrics-server">kubernetes-sigs/metrics-server</a></h1>
            <p>Scalable and efficient source of container resource metrics for Kubernetes built-in autoscaling pipelines.</p>
            <p>Language: Go</p>
            <p>Stars: 6,432</p>
            <p>Forks: 1,980</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># Kubernetes Metrics Server

Metrics Server is a scalable, efficient source of container resource metrics for Kubernetes
built-in autoscaling pipelines.

Metrics Server collects resource metrics from Kubelets and exposes them in Kubernetes apiserver through [Metrics API]
for use by [Horizontal Pod Autoscaler] and [Vertical Pod Autoscaler]. Metrics API can also be accessed by `kubectl top`,
making it easier to debug autoscaling pipelines.

&gt; [!CAUTION]
&gt; Metrics Server is meant only for autoscaling purposes. For example, don&#039;t use it to forward metrics to monitoring solutions, or as a source of monitoring solution metrics. In such cases please collect metrics from Kubelet `/metrics/resource` endpoint directly.

Metrics Server offers:

- A single deployment that works on most clusters (see [Requirements](#requirements))
- Fast autoscaling, collecting metrics every 15 seconds.
- Resource efficiency, using 1 mili core of CPU and 2 MB of memory for each node in a cluster.
- Scalable support up to 5,000 node clusters.

[Metrics API]: https://github.com/kubernetes/metrics
[Horizontal Pod Autoscaler]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
[Vertical Pod Autoscaler]: https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/

## Use cases

You can use Metrics Server for:

- CPU/Memory based horizontal autoscaling (learn more about [Horizontal Autoscaling])
- Automatically adjusting/suggesting resources needed by containers (learn more about [Vertical Autoscaling])

Don&#039;t use Metrics Server when you need:

- Non-Kubernetes clusters
- An accurate source of resource usage metrics
- Horizontal autoscaling based on other resources than CPU/Memory

For unsupported use cases, check out full monitoring solutions like [Prometheus](https://github.com/prometheus/prometheus).

[Horizontal Autoscaling]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
[Vertical Autoscaling]: https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/

## Requirements

Metrics Server has specific requirements for cluster and network configuration. These requirements aren&#039;t the default for all cluster
distributions. Please ensure that your cluster distribution supports these requirements before using Metrics Server:

- The kube-apiserver must [enable an aggregation layer].
- Nodes must have Webhook [authentication and authorization] enabled.
- Kubelet certificate needs to be signed by cluster Certificate Authority (or disable certificate validation by passing `--kubelet-insecure-tls` to Metrics Server)
- Container runtime must implement a [container metrics RPCs] (or have [cAdvisor] support)
- Network should support following communication:
  - Control plane to Metrics Server. Control plane node needs to reach Metrics Server&#039;s pod IP and port 10250 (or node IP and custom port if `hostNetwork` is enabled). Read more about [control plane to node communication](https://kubernetes.io/docs/concepts/architecture/control-plane-node-communication/#control-plane-to-node).
  - Metrics Server to Kubelet on all nodes. Metrics server needs to reach node address and Kubelet port. Addresses and ports are configured in Kubelet and published as part of Node object. Addresses in `.status.addresses` and port in `.status.daemonEndpoints.kubeletEndpoint.port` field (default 10250). Metrics Server will pick first node address based on the list provided by `kubelet-preferred-address-types` command line flag (default `InternalIP,ExternalIP,Hostname` in manifests).

[reachable from kube-apiserver]: https://kubernetes.io/docs/concepts/architecture/master-node-communication/#master-to-cluster
[enable an aggregation layer]: https://kubernetes.io/docs/tasks/access-kubernetes-api/configure-aggregation-layer/
[authentication and authorization]: https://kubernetes.io/docs/reference/access-authn-authz/kubelet-authn-authz/
[container metrics RPCs]: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/cri-container-stats.md
[cAdvisor]: https://github.com/google/cadvisor

## Installation

Metrics Server can be installed either directly from YAML manifest or via the official [Helm chart](https://artifacthub.io/packages/helm/metrics-server/metrics-server). To install the latest Metrics Server release from the _components.yaml_ manifest, run the following command.

```shell
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

Installation instructions for previous releases can be found in [Metrics Server releases](https://github.com/kubernetes-sigs/metrics-server/releases).

### Compatibility Matrix

Metrics Server | Metrics API group/version | Supported Kubernetes version
---------------|---------------------------|-----------------------------
0.8.x          | `metrics.k8s.io/v1beta1`  | 1.31+
0.7.x          | `metrics.k8s.io/v1beta1`  | 1.27+
0.6.x          | `metrics.k8s.io/v1beta1`  | 1.25+
0.5.x          | `metrics.k8s.io/v1beta1`  | *1.8+
0.4.x          | `metrics.k8s.io/v1beta1`  | *1.8+
0.3.x          | `metrics.k8s.io/v1beta1`  | 1.8-1.21

*Kubernetes versions lower than v1.16 require passing the `--authorization-always-allow-paths=/livez,/readyz` command line flag

### High Availability

Metrics Server can be installed in high availability mode directly from a YAML manifest or via the official [Helm chart](https://artifacthub.io/packages/helm/metrics-server/metrics-server) by setting the `replicas` value greater than `1`. To install the latest Metrics Server release in high availability mode from the  _high-availability.yaml_ manifest, run the following command.

On Kubernetes v1.21+:

```shell
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/high-availability-1.21+.yaml
```

On Kubernetes v1.19-1.21:

```shell
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/high-availability.yaml
```

&gt;[!NOTE]
&gt; This configuration **requires** having a cluster with at least 2 nodes on which Metrics Server can be scheduled.

Also, to maximize the efficiency of this highly available configuration, it is **recommended** to add the `--enable-aggregator-routing=true` CLI flag to the kube-apiserver so that requests sent to Metrics Server are load balanced between the 2 instances.

### Helm Chart

The [Helm chart](https://artifacthub.io/packages/helm/metrics-server/metrics-server) is maintained as an additional component within this repo and released into a chart repository backed on the `gh-pages` branch. A new version of the chart will be released for each Metrics Server release and can also be released independently if there is a need. The chart on the `master` branch shouldn&#039;t be referenced directly as it might contain modifications since it was last released, to view the chart code use the chart release tag.

## Security context

Metrics Server requires the `CAP_NET_BIND_SERVICE` capability in order to bind to a privileged ports as non-root.
If you are running Metrics Server in an environment that uses [PSSs](https://kubernetes.io/docs/concepts/security/pod-security-standards/) or other mechanisms to restrict pod capabilities, ensure that Metrics Server is allowed
to use this capability.
This applies even if you use the `--secure-port` flag to change the port that Metrics Server binds to a non-privileged port.

## Scaling

Starting from v0.5.0 Metrics Server comes with default resource requests that should guarantee good performance for most cluster configurations up to 100 nodes:

- 100m core of CPU
- 200MiB of memory

Metrics Server resource usage depends on multiple independent dimensions, creating a [Scalability Envelope].
Default Metrics Server configuration should work in clusters that don&#039;t exceed any of the thresholds listed below:

Quantity               | Namespace threshold | Cluster threshold
-----------------------|---------------------|------------------
#Nodes                 | n/a                 | 100
#Pods per node         | 70                  | 70
#Deployments with HPAs | 100                 | 100

Resources can be adjusted proportionally based on number of nodes in the cluster.
For clusters of more than 100 nodes, allocate additionally:

- 1m core per node
- 2MiB memory per node

You can use the same approach to lower resource requests, but there is a boundary
where this may impact other scalability dimensions like maximum number of pods per node.

[Scalability Envelope]: https://github.com/kubernetes/community/blob/master/sig-scalability/configs-and-limits/thresholds.md

### Configuration

Depending on your cluster setup, you may also need to change flags passed to the Metrics Server container.
Most useful flags:

- `--kubelet-preferred-address-types` - The priority of node address types used when determining an address for connecting to a particular node (default [Hostname,InternalDNS,InternalIP,ExternalDNS,ExternalIP])
- `--kubelet-insecure-tls` - Do not verify the CA of serving certificates presented by Kubelets. For testing purposes only.
- `--requestheader-client-ca-file` - Specify a root certificate bundle for verifying client certificates on incoming requests.
- `--node-selector` -Can complete to scrape the metrics from the Specified nodes based on labels

You can get a full list of Metrics Server configuration flags by running:

```shell
docker run --rm registry.k8s.io/metrics-server/metrics-server:v0.8.0 --help
```

## Design

Metrics Server is a component in the core metrics pipeline described in [Kubernetes monitoring architecture].

For more information, see:

- [Metrics API design]
- [Metrics Server design]

[Kubernetes monitoring architecture]: https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/monitoring_architecture.md
[Metrics API design]: https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/resource-metrics-api.md
[Metrics Server design]: https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/metrics-server.md

## Have a question?

Before posting an issue, first checkout [Frequently Asked Questions] and [Known Issues].

[Frequently Asked Questions]: FAQ.md
[Known Issues]: KNOWN_ISSUES.md

## Community, discussion, contribution, and support

Learn how to engage with the Kubernetes community on the [community page].

You can reach the maintainers of this project at:

- [Slack channel]
- [Mailing list]

This project is maintained by [SIG Instrumentation]

[community page]: http://kubernetes.io/community/
[Slack channel]: https://kubernetes.slack.com/messages/sig-instrumentation
[Mailing list]: https://groups.google.com/forum/#!forum/kubernetes-sig-instrumentation
[SIG Instrumentation]: https://github.com/kubernetes/community/tree/master/sig-instrumentation

### Code of conduct

Participation in the Kubernetes community is governed by the [Kubernetes Code of Conduct].

[Kubernetes Code of Conduct]: code-of-conduct.md
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[distribution/distribution]]></title>
            <link>https://github.com/distribution/distribution</link>
            <guid>https://github.com/distribution/distribution</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[The toolkit to pack, ship, store, and deliver container content]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/distribution/distribution">distribution/distribution</a></h1>
            <p>The toolkit to pack, ship, store, and deliver container content</p>
            <p>Language: Go</p>
            <p>Stars: 9,988</p>
            <p>Forks: 2,666</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;img style=&quot;align: center; padding-left: 10px; padding-right: 10px; padding-bottom: 10px;&quot; width=&quot;238px&quot; height=&quot;238px&quot; src=&quot;./distribution-logo.svg&quot; /&gt;
&lt;/p&gt;

[![Build Status](https://github.com/distribution/distribution/workflows/build/badge.svg?branch=main&amp;event=push)](https://github.com/distribution/distribution/actions/workflows/build.yml?query=workflow%3Abuild)
[![GoDoc](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;logoColor=white&amp;style=flat-square)](https://pkg.go.dev/github.com/distribution/distribution)
[![License: Apache-2.0](https://img.shields.io/badge/License-Apache--2.0-blue.svg)](LICENSE)
[![codecov](https://codecov.io/gh/distribution/distribution/branch/main/graph/badge.svg)](https://codecov.io/gh/distribution/distribution)
[![FOSSA Status](https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fdistribution%2Fdistribution.svg?type=shield)](https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fdistribution%2Fdistribution?ref=badge_shield)
[![OCI Conformance](https://github.com/distribution/distribution/workflows/conformance/badge.svg)](https://github.com/distribution/distribution/actions?query=workflow%3Aconformance)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/distribution/distribution/badge)](https://securityscorecards.dev/viewer/?uri=github.com/distribution/distribution)

The toolset to pack, ship, store, and deliver content.

This repository&#039;s main product is the Open Source Registry implementation
for storing and distributing container images and other content using the
[OCI Distribution Specification](https://github.com/opencontainers/distribution-spec).
The goal of this project is to provide a simple, secure, and scalable base
for building a large scale registry solution or running a simple private registry.
It is a core library for many registry operators including Docker Hub, GitHub Container Registry,
GitLab Container Registry and DigitalOcean Container Registry, as well as the CNCF Harbor
Project, and VMware Harbor Registry.

This repository contains the following components:

|**Component**       |Description                                                                                                                                                                                         |
|--------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **registry**       | An implementation of the [OCI Distribution Specification](https://github.com/opencontainers/distribution-spec).                                                                                                 |
| **libraries**      | A rich set of libraries for interacting with distribution components. Please see [godoc](https://pkg.go.dev/github.com/distribution/distribution) for details. **Note**: The interfaces for these libraries are **unstable**. |
| **documentation**  | Full documentation is available at [https://distribution.github.io/distribution](https://distribution.github.io/distribution/).

### How does this integrate with Docker, containerd, and other OCI client?

Clients implement against the OCI specification and communicate with the
registry using HTTP. This project contains a client implementation which
is currently in use by Docker, however, it is deprecated for the
[implementation in containerd](https://github.com/containerd/containerd/tree/master/remotes/docker)
and will not support new features.

### What are the long term goals of the Distribution project?

The _Distribution_ project has the further long term goal of providing a
secure tool chain for distributing content. The specifications, APIs and tools
should be as useful with Docker as they are without.

Our goal is to design a professional grade and extensible content distribution
system that allow users to:

* Enjoy an efficient, secured and reliable way to store, manage, package and
  exchange content
* Hack/roll their own on top of healthy open-source components
* Implement their own home made solution through good specs, and solid
  extensions mechanism.

## Contribution

Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details on how to contribute
issues, fixes, and patches to this project. If you are contributing code, see
the instructions for [building a development environment](BUILDING.md).

## Communication

For async communication and long running discussions please use issues and pull requests on the github repo.
This will be the best place to discuss design and implementation.

For sync communication we have a #distribution channel in the [CNCF Slack](https://slack.cncf.io/)
that everyone is welcome to join and chat about development.

## Licenses

The distribution codebase is released under the [Apache 2.0 license](LICENSE).
The README.md file, and files in the &quot;docs&quot; folder are licensed under the
Creative Commons Attribution 4.0 International License. You may obtain a
copy of the license, titled CC-BY-4.0, at http://creativecommons.org/licenses/by/4.0/.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[go-chi/chi]]></title>
            <link>https://github.com/go-chi/chi</link>
            <guid>https://github.com/go-chi/chi</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[lightweight, idiomatic and composable router for building Go HTTP services]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/go-chi/chi">go-chi/chi</a></h1>
            <p>lightweight, idiomatic and composable router for building Go HTTP services</p>
            <p>Language: Go</p>
            <p>Stars: 20,819</p>
            <p>Forks: 1,053</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># &lt;img alt=&quot;chi&quot; src=&quot;https://cdn.rawgit.com/go-chi/chi/master/_examples/chi.svg&quot; width=&quot;220&quot; /&gt;


[![GoDoc Widget]][GoDoc]

`chi` is a lightweight, idiomatic and composable router for building Go HTTP services. It&#039;s
especially good at helping you write large REST API services that are kept maintainable as your
project grows and changes. `chi` is built on the new `context` package introduced in Go 1.7 to
handle signaling, cancelation and request-scoped values across a handler chain.

The focus of the project has been to seek out an elegant and comfortable design for writing
REST API servers, written during the development of the Pressly API service that powers our
public API service, which in turn powers all of our client-side applications.

The key considerations of chi&#039;s design are: project structure, maintainability, standard http
handlers (stdlib-only), developer productivity, and deconstructing a large system into many small
parts. The core router `github.com/go-chi/chi` is quite small (less than 1000 LOC), but we&#039;ve also
included some useful/optional subpackages: [middleware](/middleware), [render](https://github.com/go-chi/render)
and [docgen](https://github.com/go-chi/docgen). We hope you enjoy it too!

## Install

```sh
go get -u github.com/go-chi/chi/v5
```


## Features

* **Lightweight** - cloc&#039;d in ~1000 LOC for the chi router
* **Fast** - yes, see [benchmarks](#benchmarks)
* **100% compatible with net/http** - use any http or middleware pkg in the ecosystem that is also compatible with `net/http`
* **Designed for modular/composable APIs** - middlewares, inline middlewares, route groups and sub-router mounting
* **Context control** - built on new `context` package, providing value chaining, cancellations and timeouts
* **Robust** - in production at Pressly, Cloudflare, Heroku, 99Designs, and many others (see [discussion](https://github.com/go-chi/chi/issues/91))
* **Doc generation** - `docgen` auto-generates routing documentation from your source to JSON or Markdown
* **Go.mod support** - as of v5, go.mod support (see [CHANGELOG](https://github.com/go-chi/chi/blob/master/CHANGELOG.md))
* **No external dependencies** - plain ol&#039; Go stdlib + net/http


## Examples

See [_examples/](https://github.com/go-chi/chi/blob/master/_examples/) for a variety of examples.


**As easy as:**

```go
package main

import (
	&quot;net/http&quot;

	&quot;github.com/go-chi/chi/v5&quot;
	&quot;github.com/go-chi/chi/v5/middleware&quot;
)

func main() {
	r := chi.NewRouter()
	r.Use(middleware.Logger)
	r.Get(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) {
		w.Write([]byte(&quot;welcome&quot;))
	})
	http.ListenAndServe(&quot;:3000&quot;, r)
}
```

**REST Preview:**

Here is a little preview of what routing looks like with chi. Also take a look at the generated routing docs
in JSON ([routes.json](https://github.com/go-chi/chi/blob/master/_examples/rest/routes.json)) and in
Markdown ([routes.md](https://github.com/go-chi/chi/blob/master/_examples/rest/routes.md)).

I highly recommend reading the source of the [examples](https://github.com/go-chi/chi/blob/master/_examples/) listed
above, they will show you all the features of chi and serve as a good form of documentation.

```go
import (
  //...
  &quot;context&quot;
  &quot;github.com/go-chi/chi/v5&quot;
  &quot;github.com/go-chi/chi/v5/middleware&quot;
)

func main() {
  r := chi.NewRouter()

  // A good base middleware stack
  r.Use(middleware.RequestID)
  r.Use(middleware.RealIP)
  r.Use(middleware.Logger)
  r.Use(middleware.Recoverer)

  // Set a timeout value on the request context (ctx), that will signal
  // through ctx.Done() that the request has timed out and further
  // processing should be stopped.
  r.Use(middleware.Timeout(60 * time.Second))

  r.Get(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) {
    w.Write([]byte(&quot;hi&quot;))
  })

  // RESTy routes for &quot;articles&quot; resource
  r.Route(&quot;/articles&quot;, func(r chi.Router) {
    r.With(paginate).Get(&quot;/&quot;, listArticles)                           // GET /articles
    r.With(paginate).Get(&quot;/{month}-{day}-{year}&quot;, listArticlesByDate) // GET /articles/01-16-2017

    r.Post(&quot;/&quot;, createArticle)                                        // POST /articles
    r.Get(&quot;/search&quot;, searchArticles)                                  // GET /articles/search

    // Regexp url parameters:
    r.Get(&quot;/{articleSlug:[a-z-]+}&quot;, getArticleBySlug)                // GET /articles/home-is-toronto

    // Subrouters:
    r.Route(&quot;/{articleID}&quot;, func(r chi.Router) {
      r.Use(ArticleCtx)
      r.Get(&quot;/&quot;, getArticle)                                          // GET /articles/123
      r.Put(&quot;/&quot;, updateArticle)                                       // PUT /articles/123
      r.Delete(&quot;/&quot;, deleteArticle)                                    // DELETE /articles/123
    })
  })

  // Mount the admin sub-router
  r.Mount(&quot;/admin&quot;, adminRouter())

  http.ListenAndServe(&quot;:3333&quot;, r)
}

func ArticleCtx(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    articleID := chi.URLParam(r, &quot;articleID&quot;)
    article, err := dbGetArticle(articleID)
    if err != nil {
      http.Error(w, http.StatusText(404), 404)
      return
    }
    ctx := context.WithValue(r.Context(), &quot;article&quot;, article)
    next.ServeHTTP(w, r.WithContext(ctx))
  })
}

func getArticle(w http.ResponseWriter, r *http.Request) {
  ctx := r.Context()
  article, ok := ctx.Value(&quot;article&quot;).(*Article)
  if !ok {
    http.Error(w, http.StatusText(422), 422)
    return
  }
  w.Write([]byte(fmt.Sprintf(&quot;title:%s&quot;, article.Title)))
}

// A completely separate router for administrator routes
func adminRouter() http.Handler {
  r := chi.NewRouter()
  r.Use(AdminOnly)
  r.Get(&quot;/&quot;, adminIndex)
  r.Get(&quot;/accounts&quot;, adminListAccounts)
  return r
}

func AdminOnly(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()
    perm, ok := ctx.Value(&quot;acl.permission&quot;).(YourPermissionType)
    if !ok || !perm.IsAdmin() {
      http.Error(w, http.StatusText(403), 403)
      return
    }
    next.ServeHTTP(w, r)
  })
}
```


## Router interface

chi&#039;s router is based on a kind of [Patricia Radix trie](https://en.wikipedia.org/wiki/Radix_tree).
The router is fully compatible with `net/http`.

Built on top of the tree is the `Router` interface:

```go
// Router consisting of the core routing methods used by chi&#039;s Mux,
// using only the standard net/http.
type Router interface {
	http.Handler
	Routes

	// Use appends one or more middlewares onto the Router stack.
	Use(middlewares ...func(http.Handler) http.Handler)

	// With adds inline middlewares for an endpoint handler.
	With(middlewares ...func(http.Handler) http.Handler) Router

	// Group adds a new inline-Router along the current routing
	// path, with a fresh middleware stack for the inline-Router.
	Group(fn func(r Router)) Router

	// Route mounts a sub-Router along a `pattern` string.
	Route(pattern string, fn func(r Router)) Router

	// Mount attaches another http.Handler along ./pattern/*
	Mount(pattern string, h http.Handler)

	// Handle and HandleFunc adds routes for `pattern` that matches
	// all HTTP methods.
	Handle(pattern string, h http.Handler)
	HandleFunc(pattern string, h http.HandlerFunc)

	// Method and MethodFunc adds routes for `pattern` that matches
	// the `method` HTTP method.
	Method(method, pattern string, h http.Handler)
	MethodFunc(method, pattern string, h http.HandlerFunc)

	// HTTP-method routing along `pattern`
	Connect(pattern string, h http.HandlerFunc)
	Delete(pattern string, h http.HandlerFunc)
	Get(pattern string, h http.HandlerFunc)
	Head(pattern string, h http.HandlerFunc)
	Options(pattern string, h http.HandlerFunc)
	Patch(pattern string, h http.HandlerFunc)
	Post(pattern string, h http.HandlerFunc)
	Put(pattern string, h http.HandlerFunc)
	Trace(pattern string, h http.HandlerFunc)

	// NotFound defines a handler to respond whenever a route could
	// not be found.
	NotFound(h http.HandlerFunc)

	// MethodNotAllowed defines a handler to respond whenever a method is
	// not allowed.
	MethodNotAllowed(h http.HandlerFunc)
}

// Routes interface adds two methods for router traversal, which is also
// used by the github.com/go-chi/docgen package to generate documentation for Routers.
type Routes interface {
	// Routes returns the routing tree in an easily traversable structure.
	Routes() []Route

	// Middlewares returns the list of middlewares in use by the router.
	Middlewares() Middlewares

	// Match searches the routing tree for a handler that matches
	// the method/path - similar to routing a http request, but without
	// executing the handler thereafter.
	Match(rctx *Context, method, path string) bool
}
```

Each routing method accepts a URL `pattern` and chain of `handlers`. The URL pattern
supports named params (ie. `/users/{userID}`) and wildcards (ie. `/admin/*`). URL parameters
can be fetched at runtime by calling `chi.URLParam(r, &quot;userID&quot;)` for named parameters
and `chi.URLParam(r, &quot;*&quot;)` for a wildcard parameter.


### Middleware handlers

chi&#039;s middlewares are just stdlib net/http middleware handlers. There is nothing special
about them, which means the router and all the tooling is designed to be compatible and
friendly with any middleware in the community. This offers much better extensibility and reuse
of packages and is at the heart of chi&#039;s purpose.

Here is an example of a standard net/http middleware where we assign a context key `&quot;user&quot;`
the value of `&quot;123&quot;`. This middleware sets a hypothetical user identifier on the request
context and calls the next handler in the chain.

```go
// HTTP middleware setting a value on the request context
func MyMiddleware(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    // create new context from `r` request context, and assign key `&quot;user&quot;`
    // to value of `&quot;123&quot;`
    ctx := context.WithValue(r.Context(), &quot;user&quot;, &quot;123&quot;)

    // call the next handler in the chain, passing the response writer and
    // the updated request object with the new context value.
    //
    // note: context.Context values are nested, so any previously set
    // values will be accessible as well, and the new `&quot;user&quot;` key
    // will be accessible from this point forward.
    next.ServeHTTP(w, r.WithContext(ctx))
  })
}
```


### Request handlers

chi uses standard net/http request handlers. This little snippet is an example of a http.Handler
func that reads a user identifier from the request context - hypothetically, identifying
the user sending an authenticated request, validated+set by a previous middleware handler.

```go
// HTTP handler accessing data from the request context.
func MyRequestHandler(w http.ResponseWriter, r *http.Request) {
  // here we read from the request context and fetch out `&quot;user&quot;` key set in
  // the MyMiddleware example above.
  user := r.Context().Value(&quot;user&quot;).(string)

  // respond to the client
  w.Write([]byte(fmt.Sprintf(&quot;hi %s&quot;, user)))
}
```


### URL parameters

chi&#039;s router parses and stores URL parameters right onto the request context. Here is
an example of how to access URL params in your net/http handlers. And of course, middlewares
are able to access the same information.

```go
// HTTP handler accessing the url routing parameters.
func MyRequestHandler(w http.ResponseWriter, r *http.Request) {
  // fetch the url parameter `&quot;userID&quot;` from the request of a matching
  // routing pattern. An example routing pattern could be: /users/{userID}
  userID := chi.URLParam(r, &quot;userID&quot;)

  // fetch `&quot;key&quot;` from the request context
  ctx := r.Context()
  key := ctx.Value(&quot;key&quot;).(string)

  // respond to the client
  w.Write([]byte(fmt.Sprintf(&quot;hi %v, %v&quot;, userID, key)))
}
```


## Middlewares

chi comes equipped with an optional `middleware` package, providing a suite of standard
`net/http` middlewares. Please note, any middleware in the ecosystem that is also compatible
with `net/http` can be used with chi&#039;s mux.

### Core middlewares

----------------------------------------------------------------------------------------------------
| chi/middleware Handler | description                                                             |
| :--------------------- | :---------------------------------------------------------------------- |
| [AllowContentEncoding] | Enforces a whitelist of request Content-Encoding headers                |
| [AllowContentType]     | Explicit whitelist of accepted request Content-Types                    |
| [BasicAuth]            | Basic HTTP authentication                                               |
| [Compress]             | Gzip compression for clients that accept compressed responses           |
| [ContentCharset]       | Ensure charset for Content-Type request headers                         |
| [CleanPath]            | Clean double slashes from request path                                  |
| [GetHead]              | Automatically route undefined HEAD requests to GET handlers             |
| [Heartbeat]            | Monitoring endpoint to check the servers pulse                          |
| [Logger]               | Logs the start and end of each request with the elapsed processing time |
| [NoCache]              | Sets response headers to prevent clients from caching                   |
| [Profiler]             | Easily attach net/http/pprof to your routers                            |
| [RealIP]               | Sets a http.Request&#039;s RemoteAddr to either X-Real-IP or X-Forwarded-For |
| [Recoverer]            | Gracefully absorb panics and prints the stack trace                     |
| [RequestID]            | Injects a request ID into the context of each request                   |
| [RedirectSlashes]      | Redirect slashes on routing paths                                       |
| [RouteHeaders]         | Route handling for request headers                                      |
| [SetHeader]            | Short-hand middleware to set a response header key/value                |
| [StripSlashes]         | Strip slashes on routing paths                                          |
| [Sunset]               | Sunset set Deprecation/Sunset header to response                        |
| [Throttle]             | Puts a ceiling on the number of concurrent requests                     |
| [Timeout]              | Signals to the request context when the timeout deadline is reached     |
| [URLFormat]            | Parse extension from url and put it on request context                  |
| [WithValue]            | Short-hand middleware to set a key/value on the request context         |
----------------------------------------------------------------------------------------------------

[AllowContentEncoding]: https://pkg.go.dev/github.com/go-chi/chi/middleware#AllowContentEncoding
[AllowContentType]: https://pkg.go.dev/github.com/go-chi/chi/middleware#AllowContentType
[BasicAuth]: https://pkg.go.dev/github.com/go-chi/chi/middleware#BasicAuth
[Compress]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Compress
[ContentCharset]: https://pkg.go.dev/github.com/go-chi/chi/middleware#ContentCharset
[CleanPath]: https://pkg.go.dev/github.com/go-chi/chi/middleware#CleanPath
[GetHead]: https://pkg.go.dev/github.com/go-chi/chi/middleware#GetHead
[GetReqID]: https://pkg.go.dev/github.com/go-chi/chi/middleware#GetReqID
[Heartbeat]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Heartbeat
[Logger]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Logger
[NoCache]: https://pkg.go.dev/github.com/go-chi/chi/middleware#NoCache
[Profiler]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Profiler
[RealIP]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RealIP
[Recoverer]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Recoverer
[RedirectSlashes]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RedirectSlashes
[RequestLogger]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RequestLogger
[RequestID]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RequestID
[RouteHeaders]: https://pkg.go.dev/github.com/go-chi/chi/middleware#RouteHeaders
[SetHeader]: https://pkg.go.dev/github.com/go-chi/chi/middleware#SetHeader
[StripSlashes]: https://pkg.go.dev/github.com/go-chi/chi/middleware#StripSlashes
[Sunset]: https://pkg.go.dev/github.com/go-chi/chi/v5/middleware#Sunset
[Throttle]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Throttle
[ThrottleBacklog]: https://pkg.go.dev/github.com/go-chi/chi/middleware#ThrottleBacklog
[ThrottleWithOpts]: https://pkg.go.dev/github.com/go-chi/chi/middleware#ThrottleWithOpts
[Timeout]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Timeout
[URLFormat]: https://pkg.go.dev/github.com/go-chi/chi/middleware#URLFormat
[WithLogEntry]: https://pkg.go.dev/github.com/go-chi/chi/middleware#WithLogEntry
[WithValue]: https://pkg.go.dev/github.com/go-chi/chi/middleware#WithValue
[Compressor]: https://pkg.go.dev/github.com/go-chi/chi/middleware#Compressor
[DefaultLogFormatter]: https://pkg.go.dev/github.com/go-chi/chi/middleware#DefaultLogFormatter
[EncoderFunc]: https://pkg.go.dev/github.com/go-chi/chi/middleware#EncoderFunc
[HeaderRoute]: https://pkg.go.dev/github.com/go-chi/chi/middleware#HeaderRoute
[HeaderRouter]: https://pkg.go.dev/github.com/go-chi/chi/middleware#HeaderRouter
[LogEntry]: https://pkg.go.dev/github.com/go-chi/chi/middleware#LogEntry
[LogFormatter]: https://pkg.go.dev/github.com/go-chi/chi/middleware#LogFormatter
[LoggerInterface]: https://pkg.go.dev/github.com/go-chi/chi/middleware#LoggerInterface
[ThrottleOpts]: https://pkg.go.dev/github.com/go-chi/chi/middleware#ThrottleOpts
[WrapResponseWriter]: https://pkg.go.dev/github.com/go-chi/chi/middleware#WrapResponseWriter

### Extra middlewares &amp; packages

Please see https://github.com/go-chi for additional packages.

--------------------------------------------------------------------------------------------------------------------
| package                                            | description                                                 |
|:---------------------------------------------------|:-------------------------------------------------------------
| [cors](https://github.com/go-chi/cors)             | Cross-origin resource sharing (CORS)                        |
| [docgen](https://github.com/go-chi/docgen)         | Print chi.Router routes at runtime                          |
| [jwtauth](https://github.com/go-chi/jwtauth)       | JWT authentication                                          |
| [hostrouter](https://github.com/go-chi/hostrouter) | Domain/host based request routing                           |
| [httplog](https://github.com/go-chi/httplog)       | Small but powerful structured HTTP request logging          |
| [httprate](https://github.com/go-chi/httprate)     | HTTP request rate limiter                                   |
| [httptracer](https://github.com/go-chi/httptracer) | HTTP request performance tracing library                    |
| [httpvcr](https://github.com/go-chi/httpvcr)       | Write deterministic tests for external sources              |
| [stampede](https://github.com/go-chi/stampede)     | HTTP request coalescer                                      |
--------------------------------------------------------------------------------------------------------------------


## context?

`context` is a tiny pkg that provides simple interface to signal context across call stacks
and goroutines. It was originally written by [Sameer Ajmani](https://github.com/Sajmani)
and is available in stdlib since go1.7.

Learn more at https://blog.golang.org/context

and..
* Docs: https://golang.org/pkg/context
* Source: https://github.com/golang/go/tree/master/src/context


## Benchmarks

The benchmark suite: https://github.com/pkieltyka/go-http-routing-benchmark

Results as of Nov 29, 2020 with Go 1.15.5 on Linux AMD 3950x

```shell
BenchmarkChi_Param          	3075895	        384 ns/op	      400 B/op      2 all

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes/autoscaler]]></title>
            <link>https://github.com/kubernetes/autoscaler</link>
            <guid>https://github.com/kubernetes/autoscaler</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[Autoscaling components for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes/autoscaler">kubernetes/autoscaler</a></h1>
            <p>Autoscaling components for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 8,666</p>
            <p>Forks: 4,248</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># Kubernetes Autoscaler

[![Release Charts](https://github.com/kubernetes/autoscaler/actions/workflows/release.yaml/badge.svg)](https://github.com/kubernetes/autoscaler/actions/workflows/release.yaml) [![Tests](https://github.com/kubernetes/autoscaler/actions/workflows/ci.yaml/badge.svg)](https://github.com/kubernetes/autoscaler/actions/workflows/ci.yaml) [![GoDoc Widget]][GoDoc]

This repository contains autoscaling-related components for Kubernetes.

## What&#039;s inside

[Cluster Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler) - a component that automatically adjusts the size of a Kubernetes
Cluster so that all pods have a place to run and there are no unneeded nodes. Supports several public cloud providers. Version 1.0 (GA) was released with kubernetes 1.8.

[Cluster Autoscaler Helm Chart](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler/charts) - Supported Helm chart for Cluster Autoscaler.

[Vertical Pod Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler) - a set of components that automatically adjust the
amount of CPU and memory requested by pods running in the Kubernetes Cluster. Current state - beta.

[Vertical Pod Autoscaler Helm Chart](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/charts) - Supported Helm chart for Vertical Pod Autoscaler.

[Addon Resizer](https://github.com/kubernetes/autoscaler/tree/master/addon-resizer) - a simplified version of vertical pod autoscaler that modifies
resource requests of a deployment based on the number of nodes in the Kubernetes Cluster. Current state - beta.

## Contact Info

Interested in autoscaling? Want to talk? Have questions, concerns or great ideas?

Please join us on #sig-autoscaling at https://kubernetes.slack.com/, or join one
of our weekly meetings.  See [the Kubernetes Community Repo](https://github.com/kubernetes/community/blob/master/sig-autoscaling/README.md) for more information.

## Getting the Code

Fork the repository in the cloud:
1. Visit https://github.com/kubernetes/autoscaler
1. Click Fork button (top right) to establish a cloud-based fork.

The code must be checked out as a subdirectory of `k8s.io`, and not `github.com`.

```shell
mkdir -p $GOPATH/src/k8s.io
cd $GOPATH/src/k8s.io
# Replace &quot;$YOUR_GITHUB_USERNAME&quot; below with your github username
git clone https://github.com/$YOUR_GITHUB_USERNAME/autoscaler.git
cd autoscaler
```

Please refer to Kubernetes [Github workflow guide] for more details.

[GoDoc]: https://godoc.org/k8s.io/autoscaler
[GoDoc Widget]: https://godoc.org/k8s.io/autoscaler?status.svg
[Github workflow guide]: https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[glanceapp/glance]]></title>
            <link>https://github.com/glanceapp/glance</link>
            <guid>https://github.com/glanceapp/glance</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[A self-hosted dashboard that puts all your feeds in one place]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/glanceapp/glance">glanceapp/glance</a></h1>
            <p>A self-hosted dashboard that puts all your feeds in one place</p>
            <p>Language: Go</p>
            <p>Stars: 29,356</p>
            <p>Forks: 1,096</p>
            <p>Stars today: 78 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/logo.png&quot;&gt;&lt;/p&gt;
&lt;h1 align=&quot;center&quot;&gt;Glance&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#installation&quot;&gt;Install&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;docs/configuration.md#configuring-glance&quot;&gt;Configuration&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://discord.com/invite/7KQ7Xa9kJd&quot;&gt;Discord&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://github.com/sponsors/glanceapp&quot;&gt;Sponsor&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/glanceapp/community-widgets&quot;&gt;Community widgets&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;docs/preconfigured-pages.md&quot;&gt;Preconfigured pages&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;docs/themes.md&quot;&gt;Themes&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;A lightweight, highly customizable dashboard that displays&lt;br&gt; your feeds in a beautiful, streamlined interface&lt;/p&gt;

![](docs/images/readme-main-image.png)

## Features
### Various widgets
* RSS feeds
* Subreddit posts
* Hacker News posts
* Weather forecasts
* YouTube channel uploads
* Twitch channels
* Market prices
* Docker containers status
* Server stats
* Custom widgets
* [and many more...](docs/configuration.md#configuring-glance)

### Fast and lightweight
* Low memory usage
* Few dependencies
* Minimal vanilla JS
* Single &lt;20mb binary available for multiple OSs &amp; architectures and just as small Docker container
* Uncached pages usually load within ~1s (depending on internet speed and number of widgets)

### Tons of customizability
* Different layouts
* As many pages/tabs as you need
* Numerous configuration options for each widget
* Multiple styles for some widgets
* Custom CSS

### Optimized for mobile devices
Because you&#039;ll want to take it with you on the go.

![](docs/images/mobile-preview.png)

### Themeable
Easily create your own theme by tweaking a few numbers or choose from one of the [already available themes](docs/themes.md).

![](docs/images/themes-example.png)

&lt;br&gt;

## Configuration
Configuration is done through YAML files, to learn more about how the layout works, how to add more pages and how to configure widgets, visit the [configuration documentation](docs/configuration.md#configuring-glance).
&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Preview example configuration file&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

```yaml
pages:
  - name: Home
    columns:
      - size: small
        widgets:
          - type: calendar
            first-day-of-week: monday

          - type: rss
            limit: 10
            collapse-after: 3
            cache: 12h
            feeds:
              - url: https://selfh.st/rss/
                title: selfh.st
                limit: 4
              - url: https://ciechanow.ski/atom.xml
              - url: https://www.joshwcomeau.com/rss.xml
                title: Josh Comeau
              - url: https://samwho.dev/rss.xml
              - url: https://ishadeed.com/feed.xml
                title: Ahmad Shadeed

          - type: twitch-channels
            channels:
              - theprimeagen
              - j_blow
              - piratesoftware
              - cohhcarnage
              - christitustech
              - EJ_SA

      - size: full
        widgets:
          - type: group
            widgets:
              - type: hacker-news
              - type: lobsters

          - type: videos
            channels:
              - UCXuqSBlHAE6Xw-yeJA0Tunw # Linus Tech Tips
              - UCR-DXc1voovS8nhAvccRZhg # Jeff Geerling
              - UCsBjURrPoezykLs9EqgamOA # Fireship
              - UCBJycsmduvYEL83R_U4JriQ # Marques Brownlee
              - UCHnyfMqiRRG1u-2MsSQLbXA # Veritasium

          - type: group
            widgets:
              - type: reddit
                subreddit: technology
                show-thumbnails: true
              - type: reddit
                subreddit: selfhosted
                show-thumbnails: true

      - size: small
        widgets:
          - type: weather
            location: London, United Kingdom
            units: metric
            hour-format: 12h

          - type: markets
            markets:
              - symbol: SPY
                name: S&amp;P 500
              - symbol: BTC-USD
                name: Bitcoin
              - symbol: NVDA
                name: NVIDIA
              - symbol: AAPL
                name: Apple
              - symbol: MSFT
                name: Microsoft

          - type: releases
            cache: 1d
            repositories:
              - glanceapp/glance
              - go-gitea/gitea
              - immich-app/immich
              - syncthing/syncthing
```
&lt;/details&gt;

&lt;br&gt;

## Installation

Choose one of the following methods:

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Docker compose using provided directory structure (recommended)&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

Create a new directory called `glance` as well as the template files within it by running:

```bash
mkdir glance &amp;&amp; cd glance &amp;&amp; curl -sL https://github.com/glanceapp/docker-compose-template/archive/refs/heads/main.tar.gz | tar -xzf - --strip-components 2
```

*[click here to view the files that will be created](https://github.com/glanceapp/docker-compose-template/tree/main/root)*

Then, edit the following files as desired:
* `docker-compose.yml` to configure the port, volumes and other containery things
* `config/home.yml` to configure the widgets or layout of the home page
* `config/glance.yml` if you want to change the theme or add more pages

&lt;details&gt;
&lt;summary&gt;Other files you may want to edit&lt;/summary&gt;

* `.env` to configure environment variables that will be available inside configuration files
* `assets/user.css` to add custom CSS
&lt;/details&gt;

When ready, run:

```bash
docker compose up -d
```

If you encounter any issues, you can check the logs by running:

```bash
docker compose logs
```

&lt;hr&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Docker compose manual&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

Create a `docker-compose.yml` file with the following contents:

```yaml
services:
  glance:
    container_name: glance
    image: glanceapp/glance
    restart: unless-stopped
    volumes:
      - ./config:/app/config
    ports:
      - 8080:8080
```

Then, create a new directory called `config` and download the example starting [`glance.yml`](https://github.com/glanceapp/glance/blob/main/docs/glance.yml) file into it by running:

```bash
mkdir config &amp;&amp; wget -O config/glance.yml https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml
```

Feel free to edit the `glance.yml` file to your liking, and when ready run:

```bash
docker compose up -d
```

If you encounter any issues, you can check the logs by running:

```bash
docker logs glance
```

&lt;hr&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Manual binary installation&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

Precompiled binaries are available for Linux, Windows and macOS (x86, x86_64, ARM and ARM64 architectures).

### Linux

Visit the [latest release page](https://github.com/glanceapp/glance/releases/latest) for available binaries. You can place the binary in `/opt/glance/` and have it start with your server via a [systemd service](https://linuxhandbook.com/create-systemd-services/). By default, when running the binary, it will look for a `glance.yml` file in the directory it&#039;s placed in. To specify a different path for the config file, use the `--config` option:

```bash
/opt/glance/glance --config /etc/glance.yml
```

To grab a starting template for the config file, run:

```bash
wget https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml
```

### Windows

Download and extract the executable from the [latest release](https://github.com/glanceapp/glance/releases/latest) (most likely the file called `glance-windows-amd64.zip` if you&#039;re on a 64-bit system) and place it in a folder of your choice. Then, create a new text file called `glance.yml` in the same folder and paste the content from [here](https://raw.githubusercontent.com/glanceapp/glance/refs/heads/main/docs/glance.yml) in it. You should then be able to run the executable and access the dashboard by visiting `http://localhost:8080` in your browser.



&lt;hr&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Other&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

Glance can also be installed through the following 3rd party channels:
* [Proxmox VE Helper Script](https://community-scripts.github.io/ProxmoxVE/scripts?id=glance)
* [NixOS package](https://search.nixos.org/packages?channel=unstable&amp;show=glance)
* [Coolify.io](https://coolify.io/docs/services/glance/)

&lt;hr&gt;
&lt;/details&gt;

&lt;br&gt;

## Common issues
&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Requests timing out&lt;/strong&gt;&lt;/summary&gt;

The most common cause of this is when using Pi-Hole, AdGuard Home or other ad-blocking DNS services, which by default have a fairly low rate limit. Depending on the number of widgets you have in a single page, this limit can very easily be exceeded. To fix this, increase the rate limit in the settings of your DNS service.

If using Podman, in some rare cases the timeout can be caused by an unknown issue, in which case it may be resolved by adding the following to the bottom of your `docker-compose.yml` file:
```yaml
networks:
  podman:
    external: true
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Broken layout for markets, bookmarks or other widgets&lt;/strong&gt;&lt;/summary&gt;

This is almost always caused by the browser extension Dark Reader. To fix this, disable dark mode for the domain where Glance is hosted.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;cannot unmarshal !!map into []glance.page&lt;/strong&gt;&lt;/summary&gt;

The most common cause of this is having a `pages` key in your `glance.yml` and then also having a `pages` key inside one of your included pages. To fix this, remove the `pages` key from the top of your included pages.

&lt;/details&gt;

&lt;br&gt;

## FAQ
&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Does the information on the page update automatically?&lt;/strong&gt;&lt;/summary&gt;
No, a page refresh is required to update the information. Some things do dynamically update where it makes sense, like the clock widget and the relative time showing how long ago something happened.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;How frequently do widgets update?&lt;/strong&gt;&lt;/summary&gt;
No requests are made periodically in the background, information is only fetched upon loading the page and then cached. The default cache lifetime is different for each widget and can be configured.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Can I create my own widgets?&lt;/strong&gt;&lt;/summary&gt;

Yes, there are multiple ways to create custom widgets:
* `iframe` widget - allows you to embed things from other websites
* `html` widget - allows you to insert your own static HTML
* `extension` widget - fetch HTML from a URL
* `custom-api` widget - fetch JSON from a URL and render it using custom HTML
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Can I change the title of a widget?&lt;/strong&gt;&lt;/summary&gt;

Yes, the title of all widgets can be changed by specifying the `title` property in the widget&#039;s configuration:

```yaml
- type: rss
  title: My custom title

- type: markets
  title: My custom title

- type: videos
  title: My custom title

# and so on for all widgets...
```
&lt;/details&gt;

&lt;br&gt;

## Feature requests

New feature suggestions are always welcome and will be considered, though please keep in mind that some of them may be out of scope for what the project is trying to achieve (or is reasonably capable of). If you have an idea for a new feature and would like to share it, you can do so [here](https://github.com/glanceapp/glance/issues/new?template=feature_request.yml).

Feature requests are tagged with one of the following:

* [Roadmap](https://github.com/glanceapp/glance/labels/roadmap) - will be implemented in a future release
* [Backlog](https://github.com/glanceapp/glance/labels/backlog) - may be implemented in the future but needs further feedback or interest from the community
* [Icebox](https://github.com/glanceapp/glance/labels/icebox) - no plans to implement as it doesn&#039;t currently align with the project&#039;s goals or capabilities, may be revised at a later date

&lt;br&gt;

## Building from source

Choose one of the following methods:

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Build binary with Go&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

Requirements: [Go](https://go.dev/dl/) &gt;= v1.23

To build the project for your current OS and architecture, run:

```bash
go build -o build/glance .
```

To build for a specific OS and architecture, run:

```bash
GOOS=linux GOARCH=amd64 go build -o build/glance .
```

[*click here for a full list of GOOS and GOARCH combinations*](https://go.dev/doc/install/source#:~:text=$GOOS%20and%20$GOARCH)

Alternatively, if you just want to run the app without creating a binary, like when you&#039;re testing out changes, you can run:

```bash
go run .
```
&lt;hr&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Build project and Docker image with Docker&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;

Requirements: [Docker](https://docs.docker.com/engine/install/)

To build the project and image using just Docker, run:

*(replace `owner` with your name or organization)*

```bash
docker build -t owner/glance:latest .
```

If you wish to push the image to a registry (by default Docker Hub), run:

```bash
docker push owner/glance:latest
```

&lt;hr&gt;
&lt;/details&gt;

&lt;br&gt;

## Contributing guidelines

* Before working on a new feature it&#039;s preferable to submit a feature request first and state that you&#039;d like to implement it yourself
* Please don&#039;t submit PRs for feature requests that are either in the roadmap&lt;sup&gt;[1]&lt;/sup&gt;, backlog&lt;sup&gt;[2]&lt;/sup&gt; or icebox&lt;sup&gt;[3]&lt;/sup&gt;
* Use `dev` for the base branch if you&#039;re adding new features or fixing bugs, otherwise use `main`
* Avoid introducing new dependencies
* Avoid making backwards-incompatible configuration changes
* Avoid introducing new colors or hard-coding colors, use the standard `primary`, `positive` and `negative`
* For icons, try to use [heroicons](https://heroicons.com/) where applicable
* Provide a screenshot of the changes if UI related where possible
* No `package.json`

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;&lt;sup&gt;[1] [2] [3]&lt;/sup&gt;&lt;/strong&gt;&lt;/summary&gt;

[1] The feature likely already has work put into it that may conflict with your implementation

[2] The demand, implementation or functionality for this feature is not yet clear

[3] No plans to add this feature for the time being

&lt;/details&gt;

&lt;br&gt;

## Thank you

To all the people who were generous enough to [sponsor](https://github.com/sponsors/glanceapp) the project and to everyone who has contributed in any way, be it PRs, submitting issues, helping others in the discussions or Discord server, creating guides and tools or just mentioning Glance on social media. Your support is greatly appreciated and helps keep the project going.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grafana/mcp-grafana]]></title>
            <link>https://github.com/grafana/mcp-grafana</link>
            <guid>https://github.com/grafana/mcp-grafana</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[MCP server for Grafana]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grafana/mcp-grafana">grafana/mcp-grafana</a></h1>
            <p>MCP server for Grafana</p>
            <p>Language: Go</p>
            <p>Stars: 1,828</p>
            <p>Forks: 184</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># Grafana MCP server

[![Unit Tests](https://github.com/grafana/mcp-grafana/actions/workflows/unit.yml/badge.svg)](https://github.com/grafana/mcp-grafana/actions/workflows/unit.yml)
[![Integration Tests](https://github.com/grafana/mcp-grafana/actions/workflows/integration.yml/badge.svg)](https://github.com/grafana/mcp-grafana/actions/workflows/integration.yml)
[![E2E Tests](https://github.com/grafana/mcp-grafana/actions/workflows/e2e.yml/badge.svg)](https://github.com/grafana/mcp-grafana/actions/workflows/e2e.yml)
[![Go Reference](https://pkg.go.dev/badge/github.com/grafana/mcp-grafana.svg)](https://pkg.go.dev/github.com/grafana/mcp-grafana)
[![MCP Catalog](https://archestra.ai/mcp-catalog/api/badge/quality/grafana/mcp-grafana)](https://archestra.ai/mcp-catalog/grafana__mcp-grafana)

A [Model Context Protocol][mcp] (MCP) server for Grafana.

This provides access to your Grafana instance and the surrounding ecosystem.

## Requirements

- **Grafana version 9.0 or later** is required for full functionality. Some features, particularly datasource-related operations, may not work correctly with earlier versions due to missing API endpoints.

## Features

_The following features are currently available in MCP server. This list is for informational purposes only and does not represent a roadmap or commitment to future features._

### Dashboards

- **Search for dashboards:** Find dashboards by title or other metadata
- **Get dashboard by UID:** Retrieve full dashboard details using its unique identifier. _Warning: Large dashboards can consume significant context window space._
- **Get dashboard summary:** Get a compact overview of a dashboard including title, panel count, panel types, variables, and metadata without the full JSON to minimize context window usage
- **Get dashboard property:** Extract specific parts of a dashboard using JSONPath expressions (e.g., `$.title`, `$.panels[*].title`) to fetch only needed data and reduce context window consumption
- **Update or create a dashboard:** Modify existing dashboards or create new ones. _Warning: Requires full dashboard JSON which can consume large amounts of context window space._
- **Patch dashboard:** Apply specific changes to a dashboard without requiring the full JSON, significantly reducing context window usage for targeted modifications
- **Get panel queries and datasource info:** Get the title, query string, and datasource information (including UID and type, if available) from every panel in a dashboard

#### Context Window Management

The dashboard tools now include several strategies to manage context window usage effectively ([issue #101](https://github.com/grafana/mcp-grafana/issues/101)):

- **Use `get_dashboard_summary`** for dashboard overview and planning modifications
- **Use `get_dashboard_property`** with JSONPath when you only need specific dashboard parts
- **Avoid `get_dashboard_by_uid`** unless you specifically need the complete dashboard JSON

### Datasources

- **List and fetch datasource information:** View all configured datasources and retrieve detailed information about each.
  - _Supported datasource types: Prometheus, Loki._

### Prometheus Querying

- **Query Prometheus:** Execute PromQL queries (supports both instant and range metric queries) against Prometheus datasources.
- **Query Prometheus metadata:** Retrieve metric metadata, metric names, label names, and label values from Prometheus datasources.

### Loki Querying

- **Query Loki logs and metrics:** Run both log queries and metric queries using LogQL against Loki datasources.
- **Query Loki metadata:** Retrieve label names, label values, and stream statistics from Loki datasources.

### Incidents

- **Search, create, and update incidents:** Manage incidents in Grafana Incident, including searching, creating, and adding activities to incidents.

### Sift Investigations

- **List Sift investigations:** Retrieve a list of Sift investigations, with support for a limit parameter.
- **Get Sift investigation:** Retrieve details of a specific Sift investigation by its UUID.
- **Get Sift analyses:** Retrieve a specific analysis from a Sift investigation.
- **Find error patterns in logs:** Detect elevated error patterns in Loki logs using Sift.
- **Find slow requests:** Detect slow requests using Sift (Tempo).

### Alerting

- **List and fetch alert rule information:** View alert rules and their statuses (firing/normal/error/etc.) in Grafana.
- **List contact points:** View configured notification contact points in Grafana.

### Grafana OnCall

- **List and manage schedules:** View and manage on-call schedules in Grafana OnCall.
- **Get shift details:** Retrieve detailed information about specific on-call shifts.
- **Get current on-call users:** See which users are currently on call for a schedule.
- **List teams and users:** View all OnCall teams and users.
- **List alert groups:** View and filter alert groups from Grafana OnCall by various criteria including state, integration, labels, and time range.
- **Get alert group details:** Retrieve detailed information about a specific alert group by its ID.

### Admin

- **List teams:** View all configured teams in Grafana.
- **List Users:** View all users in an organization in Grafana.

### Navigation

- **Generate deeplinks:** Create accurate deeplink URLs for Grafana resources instead of relying on LLM URL guessing.
  - **Dashboard links:** Generate direct links to dashboards using their UID (e.g., `http://localhost:3000/d/dashboard-uid`)
  - **Panel links:** Create links to specific panels within dashboards with viewPanel parameter (e.g., `http://localhost:3000/d/dashboard-uid?viewPanel=5`)
  - **Explore links:** Generate links to Grafana Explore with pre-configured datasources (e.g., `http://localhost:3000/explore?left={&quot;datasource&quot;:&quot;prometheus-uid&quot;}`)
  - **Time range support:** Add time range parameters to links (`from=now-1h&amp;to=now`)
  - **Custom parameters:** Include additional query parameters like dashboard variables or refresh intervals

### Annotations

- **Get Annotations:** Query annotations with filters. Supports time range, dashboard UID, tags, and match mode.
- **Create Annotation:** Create a new annotation on a dashboard or panel.
- **Create Graphite Annotation:** Create annotations using Graphite format (`what`, `when`, `tags`, `data`).
- **Update Annotation:** Replace all fields of an existing annotation (full update).
- **Patch Annotation:** Update only specific fields of an annotation (partial update).
- **Get Annotation Tags:** List available annotation tags with optional filtering.


The list of tools is configurable, so you can choose which tools you want to make available to the MCP client.
This is useful if you don&#039;t use certain functionality or if you don&#039;t want to take up too much of the context window.
To disable a category of tools, use the `--disable-&lt;category&gt;` flag when starting the server. For example, to disable
the OnCall tools, use `--disable-oncall`, or to disable navigation deeplink generation, use `--disable-navigation`.


#### RBAC Permissions

Each tool requires specific RBAC permissions to function properly. When creating a service account for the MCP server, ensure it has the necessary permissions based on which tools you plan to use. The permissions listed are the minimum required actions - you may also need appropriate scopes (e.g., `datasources:*`, `dashboards:*`, `folders:*`) depending on your use case.

Tip: If you&#039;re not familiar with Grafana RBAC or you want a quicker, simpler setup instead of configuring many granular scopes, you can assign a built-in role such as `Editor` to the service account. The `Editor` role grants broad read/write access that will allow most MCP server operations; it is less granular (and therefore less restrictive) than manually-applied scopes, so use it only when convenience is more important than strict least-privilege access.

**Note:** Grafana Incident and Sift tools use basic Grafana roles instead of fine-grained RBAC permissions:
- **Viewer role:** Required for read-only operations (list incidents, get investigations)
- **Editor role:** Required for write operations (create incidents, modify investigations)

For more information about Grafana RBAC, see the [official documentation](https://grafana.com/docs/grafana/latest/administration/roles-and-permissions/access-control/).

#### RBAC Scopes

Scopes define the specific resources that permissions apply to. Each action requires both the appropriate permission and scope combination.

**Common Scope Patterns:**

- **Broad access:** Use `*` wildcards for organization-wide access

  - `datasources:*` - Access to all datasources
  - `dashboards:*` - Access to all dashboards
  - `folders:*` - Access to all folders
  - `teams:*` - Access to all teams

- **Limited access:** Use specific UIDs or IDs to restrict access to individual resources
  - `datasources:uid:prometheus-uid` - Access only to a specific Prometheus datasource
  - `dashboards:uid:abc123` - Access only to dashboard with UID `abc123`
  - `folders:uid:xyz789` - Access only to folder with UID `xyz789`
  - `teams:id:5` - Access only to team with ID `5`
  - `global.users:id:123` - Access only to user with ID `123`

**Examples:**

- **Full MCP server access:** Grant broad permissions for all tools

  ```
  datasources:* (datasources:read, datasources:query)
  dashboards:* (dashboards:read, dashboards:create, dashboards:write)
  folders:* (for dashboard creation and alert rules)
  teams:* (teams:read)
  global.users:* (users:read)
  ```

- **Limited datasource access:** Only query specific Prometheus and Loki instances

  ```
  datasources:uid:prometheus-prod (datasources:query)
  datasources:uid:loki-prod (datasources:query)
  ```

- **Dashboard-specific access:** Read only specific dashboards
  ```
  dashboards:uid:monitoring-dashboard (dashboards:read)
  dashboards:uid:alerts-dashboard (dashboards:read)
  ```

### Tools

| Tool                              | Category    | Description                                                        | Required RBAC Permissions               | Required Scopes                                     |
| --------------------------------- | ----------- | ------------------------------------------------------------------ | --------------------------------------- | --------------------------------------------------- |
| `list_teams`                      | Admin       | List all teams                                                     | `teams:read`                            | `teams:*` or `teams:id:1`                           |
| `list_users_by_org`               | Admin       | List all users in an organization                                  | `users:read`                            | `global.users:*` or `global.users:id:123`           |
| `search_dashboards`               | Search      | Search for dashboards                                              | `dashboards:read`                       | `dashboards:*` or `dashboards:uid:abc123`           |
| `get_dashboard_by_uid`            | Dashboard   | Get a dashboard by uid                                             | `dashboards:read`                       | `dashboards:uid:abc123`                             |
| `update_dashboard`                | Dashboard   | Update or create a new dashboard                                   | `dashboards:create`, `dashboards:write` | `dashboards:*`, `folders:*` or `folders:uid:xyz789` |
| `get_dashboard_panel_queries`     | Dashboard   | Get panel title, queries, datasource UID and type from a dashboard | `dashboards:read`                       | `dashboards:uid:abc123`                             |
| `get_dashboard_property`          | Dashboard   | Extract specific parts of a dashboard using JSONPath expressions   | `dashboards:read`                       | `dashboards:uid:abc123`                             |
| `get_dashboard_summary`           | Dashboard   | Get a compact summary of a dashboard without full JSON             | `dashboards:read`                       | `dashboards:uid:abc123`                             |
| `list_datasources`                | Datasources | List datasources                                                   | `datasources:read`                      | `datasources:*`                                     |
| `get_datasource_by_uid`           | Datasources | Get a datasource by uid                                            | `datasources:read`                      | `datasources:uid:prometheus-uid`                    |
| `get_datasource_by_name`          | Datasources | Get a datasource by name                                           | `datasources:read`                      | `datasources:*` or `datasources:uid:loki-uid`       |
| `query_prometheus`                | Prometheus  | Execute a query against a Prometheus datasource                    | `datasources:query`                     | `datasources:uid:prometheus-uid`                    |
| `list_prometheus_metric_metadata` | Prometheus  | List metric metadata                                               | `datasources:query`                     | `datasources:uid:prometheus-uid`                    |
| `list_prometheus_metric_names`    | Prometheus  | List available metric names                                        | `datasources:query`                     | `datasources:uid:prometheus-uid`                    |
| `list_prometheus_label_names`     | Prometheus  | List label names matching a selector                               | `datasources:query`                     | `datasources:uid:prometheus-uid`                    |
| `list_prometheus_label_values`    | Prometheus  | List values for a specific label                                   | `datasources:query`                     | `datasources:uid:prometheus-uid`                    |
| `list_incidents`                  | Incident    | List incidents in Grafana Incident                                 | Viewer role                             | N/A                                                 |
| `create_incident`                 | Incident    | Create an incident in Grafana Incident                             | Editor role                             | N/A                                                 |
| `add_activity_to_incident`        | Incident    | Add an activity item to an incident in Grafana Incident            | Editor role                             | N/A                                                 |
| `get_incident`                    | Incident    | Get a single incident by ID                                        | Viewer role                             | N/A                                                 |
| `query_loki_logs`                 | Loki        | Query and retrieve logs using LogQL (either log or metric queries) | `datasources:query`                     | `datasources:uid:loki-uid`                          |
| `list_loki_label_names`           | Loki        | List all available label names in logs                             | `datasources:query`                     | `datasources:uid:loki-uid`                          |
| `list_loki_label_values`          | Loki        | List values for a specific log label                               | `datasources:query`                     | `datasources:uid:loki-uid`                          |
| `query_loki_stats`                | Loki        | Get statistics about log streams                                   | `datasources:query`                     | `datasources:uid:loki-uid`                          |
| `list_alert_rules`                | Alerting    | List alert rules                                                   | `alert.rules:read`                      | `folders:*` or `folders:uid:alerts-folder`          |
| `get_alert_rule_by_uid`           | Alerting    | Get alert rule by UID                                              | `alert.rules:read`                      | `folders:uid:alerts-folder`                         |
| `list_contact_points`             | Alerting    | List notification contact points                                   | `alert.notifications:read`              | Global scope                                        |
| `list_oncall_schedules`           | OnCall      | List schedules from Grafana OnCall                                 | `grafana-oncall-app.schedules:read`     | Plugin-specific scopes                              |
| `get_oncall_shift`                | OnCall      | Get details for a specific OnCall shift                            | `grafana-oncall-app.schedules:read`     | Plugin-specific scopes                              |
| `get_current_oncall_users`        | OnCall      | Get users currently on-call for a specific schedule                | `grafana-oncall-app.schedules:read`     | Plugin-specific scopes                              |
| `list_oncall_teams`               | OnCall      | List teams from Grafana OnCall                                     | `grafana-oncall-app.user-settings:read` | Plugin-specific scopes                              |
| `list_oncall_users`               | OnCall      | List users from Grafana OnCall                                     | `grafana-oncall-app.user-settings:read` | Plugin-specific scopes                              |
| `list_alert_groups`               | OnCall      | List alert groups from Grafana OnCall with filtering options       | `grafana-oncall-app.alert-groups:read`  | Plugin-specific scopes                              |
| `get_alert_group`                 | OnCall      | Get a specific alert group from Grafana OnCall by its ID           | `grafana-oncall-app.alert-groups:read`  | Plugin-specific scopes                              |
| `get_sift_investigation`          | Sift        | Retrieve an existing Sift investigation by its UUID                | Viewer role                             | N/A                                                 |
| `get_sift_analysis`               | Sift        | Retrieve a specific analysis from a Sift investigation             | Viewer role                             | N/A                                                 |
| `list_sift_investigations`        | Sift        | Retrieve a list of Sift investigations with an optional limit      | Viewer role                             | N/A                                                 |
| `find_error_pattern_logs`         | Sift        | Finds elevated error patterns in Loki logs.                        | Editor role                             | N/A                                                 |
| `find_slow_requests`              | Sift        | Finds slow requests from the relevant tempo datasources.           | Editor role                             | N/A                                                 |
| `list_pyroscope_label_names`      | Pyroscope   | List label names matching a selector                               | `datasources:query`                     | `datasources:uid:pyroscope-uid`                     |
| `list_pyroscope_label_values`     | Pyroscope   | List label values matching a selector for a label name             | `datasources:query`                     | `datasources:uid:pyroscope-uid`                     |
| `list_pyroscope_profile_types`    | Pyroscope   | List available profile types                                       | `datasources:query`                     | `datasources:uid:pyroscope-uid`                     |
| `fetch_pyroscope_profile`         | Pyroscope   | Fetches a profile in DOT format for analysis                       | `datasources:query`                     | `datasources:uid:pyroscope-uid`                     |
| `get_assertions`                  | Asserts     | Get assertion summary for a given entity                           | Plugin-specific permissions             | Plugin-specific scopes                              |
| `generate_deeplink`               | Navigation  | 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[moby/moby]]></title>
            <link>https://github.com/moby/moby</link>
            <guid>https://github.com/moby/moby</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/moby/moby">moby/moby</a></h1>
            <p>The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems</p>
            <p>Language: Go</p>
            <p>Stars: 71,017</p>
            <p>Forks: 18,832</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>The Moby Project
================

[![PkgGoDev](https://pkg.go.dev/badge/github.com/moby/moby/v2)](https://pkg.go.dev/github.com/moby/moby/v2)
![GitHub License](https://img.shields.io/github/license/moby/moby)
[![Go Report Card](https://goreportcard.com/badge/github.com/moby/moby/v2)](https://goreportcard.com/report/github.com/moby/moby/v2)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/moby/moby/badge)](https://scorecard.dev/viewer/?uri=github.com/moby/moby)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10989/badge)](https://www.bestpractices.dev/projects/10989)


![Moby Project logo](docs/static_files/moby-project-logo.png &quot;The Moby Project&quot;)

Moby is an open-source project created by Docker to enable and accelerate software containerization.

It provides a &quot;Lego set&quot; of toolkit components, the framework for assembling them into custom container-based systems, and a place for all container enthusiasts and professionals to experiment and exchange ideas.
Components include container build tools, a container registry, orchestration tools, a runtime and more, and these can be used as building blocks in conjunction with other tools and projects.

## Principles

Moby is an open project guided by strong principles, aiming to be modular, flexible and without too strong an opinion on user experience.
It is open to the community to help set its direction.

- Modular: the project includes lots of components that have well-defined functions and APIs that work together.
- Batteries included but swappable: Moby includes enough components to build fully featured container systems, but its modular architecture ensures that most of the components can be swapped by different implementations.
- Usable security: Moby provides secure defaults without compromising usability.
- Developer focused: The APIs are intended to be functional and useful to build powerful tools.
They are not necessarily intended as end user tools but as components aimed at developers.
Documentation and UX is aimed at developers not end users.

## Audience

The Moby Project is intended for engineers, integrators and enthusiasts looking to modify, hack, fix, experiment, invent and build systems based on containers.
It is not for people looking for a commercially supported system, but for people who want to work and learn with open source code.

## Relationship with Docker

The components and tools in the Moby Project are initially the open source components that Docker and the community have built for the Docker Project.
New projects can be added if they fit with the community goals. Docker is committed to using Moby as the upstream for the Docker Product.
However, other projects are also encouraged to use Moby as an upstream, and to reuse the components in diverse ways, and all these uses will be treated in the same way. External maintainers and contributors are welcomed.

The Moby project is not intended as a location for support or feature requests for Docker products, but as a place for contributors to work on open source code, fix bugs, and make the code more useful.
The releases are supported by the maintainers, community and users, on a best efforts basis only. For customers who want enterprise or commercial support, [Docker Desktop](https://www.docker.com/products/docker-desktop/) and [Mirantis Container Runtime](https://www.mirantis.com/software/mirantis-container-runtime/) are the appropriate products for these use cases.

-----

Legal
=====

*Brought to you courtesy of our legal counsel. For more context,
please see the [NOTICE](https://github.com/moby/moby/blob/master/NOTICE) document in this repo.*

Use and transfer of Moby may be subject to certain restrictions by the
United States and other governments.

It is your responsibility to ensure that your use and/or transfer does not
violate applicable laws.

For more information, please see https://www.bis.doc.gov

Licensing
=========
Moby is licensed under the Apache License, Version 2.0. See
[LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full
license text.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[opencontainers/runc]]></title>
            <link>https://github.com/opencontainers/runc</link>
            <guid>https://github.com/opencontainers/runc</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[CLI tool for spawning and running containers according to the OCI specification]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/opencontainers/runc">opencontainers/runc</a></h1>
            <p>CLI tool for spawning and running containers according to the OCI specification</p>
            <p>Language: Go</p>
            <p>Stars: 12,742</p>
            <p>Forks: 2,240</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># runc

[![Go Report Card](https://goreportcard.com/badge/github.com/opencontainers/runc)](https://goreportcard.com/report/github.com/opencontainers/runc)
[![Go Reference](https://pkg.go.dev/badge/github.com/opencontainers/runc.svg)](https://pkg.go.dev/github.com/opencontainers/runc)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/588/badge)](https://bestpractices.coreinfrastructure.org/projects/588)
[![gha/validate](https://github.com/opencontainers/runc/workflows/validate/badge.svg)](https://github.com/opencontainers/runc/actions?query=workflow%3Avalidate)
[![gha/ci](https://github.com/opencontainers/runc/workflows/ci/badge.svg)](https://github.com/opencontainers/runc/actions?query=workflow%3Aci)
[![CirrusCI](https://api.cirrus-ci.com/github/opencontainers/runc.svg)](https://cirrus-ci.com/github/opencontainers/runc)

## Introduction

`runc` is a CLI tool for spawning and running containers on Linux according to the OCI specification.

## Releases

You can find official releases of `runc` on the [release](https://github.com/opencontainers/runc/releases) page.

All releases are signed by one of the keys listed in the [`runc.keyring` file in the root of this repository](runc.keyring).

## Security

The reporting process and disclosure communications are outlined [here](https://github.com/opencontainers/org/blob/master/SECURITY.md).

### Security Audit
A third party security audit was performed by Cure53, you can see the full report [here](https://github.com/opencontainers/runc/blob/master/docs/Security-Audit.pdf).

## Building

`runc` only supports Linux. See the header of [`go.mod`](./go.mod) for the minimally required Go version.

### Pre-Requisites

#### Utilities and Libraries

In addition to Go, building `runc` requires multiple utilities and libraries to be installed on your system.

On Ubuntu/Debian, you can install the required dependencies with:

```bash
apt update &amp;&amp; apt install -y make gcc linux-libc-dev libseccomp-dev pkg-config git
```

On CentOS/Fedora, you can install the required dependencies with:

```bash
yum install -y make gcc kernel-headers libseccomp-devel pkg-config git
```

On Alpine Linux, you can install the required dependencies with:

```bash
apk --update add bash make gcc libseccomp-dev musl-dev linux-headers git
```

The following dependencies are optional:

* `libseccomp` - only required if you enable seccomp support; to disable, see [Build Tags](#build-tags)

### Build

```bash
# create a &#039;github.com/opencontainers&#039; in your GOPATH/src
cd github.com/opencontainers
git clone https://github.com/opencontainers/runc
cd runc

make
sudo make install
```

You can also use `go get` to install to your `GOPATH`, assuming that you have a `github.com` parent folder already created under `src`:

```bash
go get github.com/opencontainers/runc
cd $GOPATH/src/github.com/opencontainers/runc
make
sudo make install
```

`runc` will be installed to `/usr/local/sbin/runc` on your system.

#### Version string customization

You can see the runc version by running `runc --version`. You can append a custom string to the
version using the `EXTRA_VERSION` make variable when building, e.g.:

```bash
make EXTRA_VERSION=&quot;+build-1&quot;
```

Bear in mind to include some separator for readability.

#### Build Tags

`runc` supports optional build tags for compiling support of various features,
with some of them enabled by default (see `BUILDTAGS` in top-level `Makefile`).

To change build tags from the default, set the `BUILDTAGS` variable for make,
e.g. to disable seccomp:

```bash
make BUILDTAGS=&quot;&quot;
```

To add some more build tags to the default set, use the `EXTRA_BUILDTAGS`
make variable, e.g. to disable checkpoint/restore:

```bash
make EXTRA_BUILDTAGS=&quot;runc_nocriu&quot;
```

| Build Tag     | Feature                               | Enabled by Default | Dependencies        |
|---------------|---------------------------------------|--------------------|---------------------|
| `seccomp`     | Syscall filtering using `libseccomp`. | yes                | `libseccomp`        |
| `runc_nocriu` | **Disables** runc checkpoint/restore. | no                 | `criu`              |

The following build tags were used earlier, but are now obsoleted:
 - **runc_nodmz** (since runc v1.2.1 runc dmz binary is dropped)
 - **nokmem** (since runc v1.0.0-rc94 kernel memory settings are ignored)
 - **apparmor** (since runc v1.0.0-rc93 the feature is always enabled)
 - **selinux**  (since runc v1.0.0-rc93 the feature is always enabled)

### Running the test suite

`runc` currently supports running its test suite via Docker.
To run the suite just type `make test`.

```bash
make test
```

There are additional make targets for running the tests outside of a container but this is not recommended as the tests are written with the expectation that they can write and remove anywhere.

You can run a specific test case by setting the `TESTFLAGS` variable.

```bash
# make test TESTFLAGS=&quot;-run=SomeTestFunction&quot;
```

You can run a specific integration test by setting the `TESTPATH` variable.

```bash
# make test TESTPATH=&quot;/checkpoint.bats&quot;
```

You can run a specific rootless integration test by setting the `ROOTLESS_TESTPATH` variable.

```bash
# make test ROOTLESS_TESTPATH=&quot;/checkpoint.bats&quot;
```

You can run a test using your container engine&#039;s flags by setting `CONTAINER_ENGINE_BUILD_FLAGS` and `CONTAINER_ENGINE_RUN_FLAGS` variables.

```bash
# make test CONTAINER_ENGINE_BUILD_FLAGS=&quot;--build-arg http_proxy=http://yourproxy/&quot; CONTAINER_ENGINE_RUN_FLAGS=&quot;-e http_proxy=http://yourproxy/&quot;
```

### Go Dependencies Management

`runc` uses [Go Modules](https://github.com/golang/go/wiki/Modules) for dependencies management.
Please refer to [Go Modules](https://github.com/golang/go/wiki/Modules) for how to add or update
new dependencies.

```
# Update vendored dependencies
make vendor
# Verify all dependencies
make verify-dependencies
```

## Using runc

Please note that runc is a low level tool not designed with an end user
in mind. It is mostly employed by other higher level container software.

Therefore, unless there is some specific use case that prevents the use
of tools like Docker or Podman, it is not recommended to use runc directly.

If you still want to use runc, here&#039;s how.

### Creating an OCI Bundle

In order to use runc you must have your container in the format of an OCI bundle.
If you have Docker installed you can use its `export` method to acquire a root filesystem from an existing Docker container.

```bash
# create the top most bundle directory
mkdir /mycontainer
cd /mycontainer

# create the rootfs directory
mkdir rootfs

# export busybox via Docker into the rootfs directory
docker export $(docker create busybox) | tar -C rootfs -xvf -
```

After a root filesystem is populated you just generate a spec in the format of a `config.json` file inside your bundle.
`runc` provides a `spec` command to generate a base template spec that you are then able to edit.
To find features and documentation for fields in the spec please refer to the [specs](https://github.com/opencontainers/runtime-spec) repository.

```bash
runc spec
```

### Running Containers

Assuming you have an OCI bundle from the previous step you can execute the container in two different ways.

The first way is to use the convenience command `run` that will handle creating, starting, and deleting the container after it exits.

```bash
# run as root
cd /mycontainer
runc run mycontainerid
```

If you used the unmodified `runc spec` template this should give you a `sh` session inside the container.

The second way to start a container is using the specs lifecycle operations.
This gives you more power over how the container is created and managed while it is running.
This will also launch the container in the background so you will have to edit
the `config.json` to remove the `terminal` setting for the simple examples
below (see more details about [runc terminal handling](docs/terminals.md)).
Your process field in the `config.json` should look like this below with `&quot;terminal&quot;: false` and `&quot;args&quot;: [&quot;sleep&quot;, &quot;5&quot;]`.


```json
        &quot;process&quot;: {
                &quot;terminal&quot;: false,
                &quot;user&quot;: {
                        &quot;uid&quot;: 0,
                        &quot;gid&quot;: 0
                },
                &quot;args&quot;: [
                        &quot;sleep&quot;, &quot;5&quot;
                ],
                &quot;env&quot;: [
                        &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,
                        &quot;TERM=xterm&quot;
                ],
                &quot;cwd&quot;: &quot;/&quot;,
                &quot;capabilities&quot;: {
                        &quot;bounding&quot;: [
                                &quot;CAP_AUDIT_WRITE&quot;,
                                &quot;CAP_KILL&quot;,
                                &quot;CAP_NET_BIND_SERVICE&quot;
                        ],
                        &quot;effective&quot;: [
                                &quot;CAP_AUDIT_WRITE&quot;,
                                &quot;CAP_KILL&quot;,
                                &quot;CAP_NET_BIND_SERVICE&quot;
                        ],
                        &quot;inheritable&quot;: [
                                &quot;CAP_AUDIT_WRITE&quot;,
                                &quot;CAP_KILL&quot;,
                                &quot;CAP_NET_BIND_SERVICE&quot;
                        ],
                        &quot;permitted&quot;: [
                                &quot;CAP_AUDIT_WRITE&quot;,
                                &quot;CAP_KILL&quot;,
                                &quot;CAP_NET_BIND_SERVICE&quot;
                        ],
                        &quot;ambient&quot;: [
                                &quot;CAP_AUDIT_WRITE&quot;,
                                &quot;CAP_KILL&quot;,
                                &quot;CAP_NET_BIND_SERVICE&quot;
                        ]
                },
                &quot;rlimits&quot;: [
                        {
                                &quot;type&quot;: &quot;RLIMIT_NOFILE&quot;,
                                &quot;hard&quot;: 1024,
                                &quot;soft&quot;: 1024
                        }
                ],
                &quot;noNewPrivileges&quot;: true
        },
```

Now we can go through the lifecycle operations in your shell.


```bash
# run as root
cd /mycontainer
runc create mycontainerid

# view the container is created and in the &quot;created&quot; state
runc list

# start the process inside the container
runc start mycontainerid

# after 5 seconds view that the container has exited and is now in the stopped state
runc list

# now delete the container
runc delete mycontainerid
```

This allows higher level systems to augment the containers creation logic with setup of various settings after the container is created and/or before it is deleted. For example, the container&#039;s network stack is commonly set up after `create` but before `start`.

#### Rootless containers
`runc` has the ability to run containers without root privileges. This is called `rootless`. You need to pass some parameters to `runc` in order to run rootless containers. See below and compare with the previous version.

**Note:** In order to use this feature, &quot;User Namespaces&quot; must be compiled and enabled in your kernel. There are various ways to do this depending on your distribution:
- Confirm `CONFIG_USER_NS=y` is set in your kernel configuration (normally found in `/proc/config.gz`)
- Arch/Debian: `echo 1 &gt; /proc/sys/kernel/unprivileged_userns_clone`
- RHEL/CentOS 7: `echo 28633 &gt; /proc/sys/user/max_user_namespaces`

Run the following commands as an ordinary user:
```bash
# Same as the first example
mkdir ~/mycontainer
cd ~/mycontainer
mkdir rootfs
docker export $(docker create busybox) | tar -C rootfs -xvf -

# The --rootless parameter instructs runc spec to generate a configuration for a rootless container, which will allow you to run the container as a non-root user.
runc spec --rootless

# The --root parameter tells runc where to store the container state. It must be writable by the user.
runc --root /tmp/runc run mycontainerid
```

#### Supervisors

`runc` can be used with process supervisors and init systems to ensure that containers are restarted when they exit.
An example systemd unit file looks something like this.

```systemd
[Unit]
Description=Start My Container

[Service]
Type=forking
ExecStart=/usr/local/sbin/runc run -d --pid-file /run/mycontainerid.pid mycontainerid
ExecStopPost=/usr/local/sbin/runc delete mycontainerid
WorkingDirectory=/mycontainer
PIDFile=/run/mycontainerid.pid

[Install]
WantedBy=multi-user.target
```

## More documentation

* [Spec conformance](./docs/spec-conformance.md)
* [cgroup v2](./docs/cgroup-v2.md)
* [Checkpoint and restore](./docs/checkpoint-restore.md)
* [systemd cgroup driver](./docs/systemd.md)
* [Terminals and standard IO](./docs/terminals.md)
* [Experimental features](./docs/experimental.md)

## License

The code and docs are released under the [Apache 2.0 license](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[onsi/ginkgo]]></title>
            <link>https://github.com/onsi/ginkgo</link>
            <guid>https://github.com/onsi/ginkgo</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[A Modern Testing Framework for Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/onsi/ginkgo">onsi/ginkgo</a></h1>
            <p>A Modern Testing Framework for Go</p>
            <p>Language: Go</p>
            <p>Stars: 8,869</p>
            <p>Forks: 683</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>![Ginkgo](https://onsi.github.io/ginkgo/images/ginkgo.png)

[![test](https://github.com/onsi/ginkgo/actions/workflows/test.yml/badge.svg?branch=master)](https://github.com/onsi/ginkgo/actions?query=workflow%3Atest+branch%3Amaster) | [Ginkgo Docs](https://onsi.github.io/ginkgo/)

---

# Ginkgo

Ginkgo is a mature testing framework for Go designed to help you write expressive specs.  Ginkgo builds on top of Go&#039;s `testing` foundation and is complemented by the [Gomega](https://github.com/onsi/gomega) matcher library.  Together, Ginkgo and Gomega let you express the intent behind your specs clearly:

```go
import (
    . &quot;github.com/onsi/ginkgo/v2&quot;
    . &quot;github.com/onsi/gomega&quot;
    ...
)

var _ = Describe(&quot;Checking books out of the library&quot;, Label(&quot;library&quot;), func() {
    var library *libraries.Library
    var book *books.Book
    var valjean *users.User
    BeforeEach(func() {
        library = libraries.NewClient()
        book = &amp;books.Book{
            Title: &quot;Les Miserables&quot;,
            Author: &quot;Victor Hugo&quot;,
        }
        valjean = users.NewUser(&quot;Jean Valjean&quot;)
    })

    When(&quot;the library has the book in question&quot;, func() {
        BeforeEach(func(ctx SpecContext) {
            Expect(library.Store(ctx, book)).To(Succeed())
        })

        Context(&quot;and the book is available&quot;, func() {
            It(&quot;lends it to the reader&quot;, func(ctx SpecContext) {
                Expect(valjean.Checkout(ctx, library, &quot;Les Miserables&quot;)).To(Succeed())
                Expect(valjean.Books()).To(ContainElement(book))
                Expect(library.UserWithBook(ctx, book)).To(Equal(valjean))
            }, SpecTimeout(time.Second * 5))
        })

        Context(&quot;but the book has already been checked out&quot;, func() {
            var javert *users.User
            BeforeEach(func(ctx SpecContext) {
                javert = users.NewUser(&quot;Javert&quot;)
                Expect(javert.Checkout(ctx, library, &quot;Les Miserables&quot;)).To(Succeed())
            })

            It(&quot;tells the user&quot;, func(ctx SpecContext) {
                err := valjean.Checkout(ctx, library, &quot;Les Miserables&quot;)
                Expect(err).To(MatchError(&quot;Les Miserables is currently checked out&quot;))
            }, SpecTimeout(time.Second * 5))

            It(&quot;lets the user place a hold and get notified later&quot;, func(ctx SpecContext) {
                Expect(valjean.Hold(ctx, library, &quot;Les Miserables&quot;)).To(Succeed())
                Expect(valjean.Holds(ctx)).To(ContainElement(book))

                By(&quot;when Javert returns the book&quot;)
                Expect(javert.Return(ctx, library, book)).To(Succeed())

                By(&quot;it eventually informs Valjean&quot;)
                notification := &quot;Les Miserables is ready for pick up&quot;
                Eventually(ctx, valjean.Notifications).Should(ContainElement(notification))

                Expect(valjean.Checkout(ctx, library, &quot;Les Miserables&quot;)).To(Succeed())
                Expect(valjean.Books(ctx)).To(ContainElement(book))
                Expect(valjean.Holds(ctx)).To(BeEmpty())
            }, SpecTimeout(time.Second * 10))
        })  
    })

    When(&quot;the library does not have the book in question&quot;, func() {
        It(&quot;tells the reader the book is unavailable&quot;, func(ctx SpecContext) {
            err := valjean.Checkout(ctx, library, &quot;Les Miserables&quot;)
            Expect(err).To(MatchError(&quot;Les Miserables is not in the library catalog&quot;))
        }, SpecTimeout(time.Second * 5))
    })
})
```

Jump to the [docs](https://onsi.github.io/ginkgo/) to learn more.  It&#039;s easy to [bootstrap](https://onsi.github.io/ginkgo/#bootstrapping-a-suite) and start writing your [first specs](https://onsi.github.io/ginkgo/#adding-specs-to-a-suite).

If you have a question, comment, bug report, feature request, etc. please open a [GitHub issue](https://github.com/onsi/ginkgo/issues/new), or visit the [Ginkgo Slack channel](https://app.slack.com/client/T029RQSE6/CQQ50BBNW).

## Capabilities

Whether writing basic unit specs, complex integration specs, or even performance specs - Ginkgo gives you an expressive Domain-Specific Language (DSL) that will be familiar to users coming from frameworks such as [Quick](https://github.com/Quick/Quick), [RSpec](https://rspec.info), [Jasmine](https://jasmine.github.io), and [Busted](https://lunarmodules.github.io/busted/).  This style of testing is sometimes referred to as &quot;Behavior-Driven Development&quot; (BDD) though Ginkgo&#039;s utility extends beyond acceptance-level testing.

With Ginkgo&#039;s DSL you can use nestable [`Describe`, `Context` and `When` container nodes](https://onsi.github.io/ginkgo/#organizing-specs-with-container-nodes) to help you organize your specs.  [`BeforeEach` and `AfterEach` setup nodes](https://onsi.github.io/ginkgo/#extracting-common-setup-beforeeach) for setup and cleanup.  [`It` and `Specify` subject nodes](https://onsi.github.io/ginkgo/#spec-subjects-it) that hold your assertions. [`BeforeSuite` and `AfterSuite` nodes](https://onsi.github.io/ginkgo/#suite-setup-and-cleanup-beforesuite-and-aftersuite) to prep for and cleanup after a suite... and [much more!](https://onsi.github.io/ginkgo/#writing-specs).

At runtime, Ginkgo can run your specs in reproducibly [random order](https://onsi.github.io/ginkgo/#spec-randomization) and has sophisticated support for [spec parallelization](https://onsi.github.io/ginkgo/#spec-parallelization).  In fact, running specs in parallel is as easy as

```bash
ginkgo -p
```

By following [established patterns for writing parallel specs](https://onsi.github.io/ginkgo/#patterns-for-parallel-integration-specs) you can build even large, complex integration suites that parallelize cleanly and run performantly.  And you don&#039;t have to worry about your spec suite hanging or leaving a mess behind - Ginkgo provides a per-node `context.Context` and the capability to interrupt the spec after a set period of time - and then clean up.

As your suites grow Ginkgo helps you keep your specs organized with [labels](https://onsi.github.io/ginkgo/#spec-labels) and lets you easily run [subsets of specs](https://onsi.github.io/ginkgo/#filtering-specs), either [programmatically](https://onsi.github.io/ginkgo/#focused-specs) or on the [command line](https://onsi.github.io/ginkgo/#combining-filters).  And Ginkgo&#039;s reporting infrastructure generates machine-readable output in a [variety of formats](https://onsi.github.io/ginkgo/#generating-machine-readable-reports) _and_ allows you to build your own [custom reporting infrastructure](https://onsi.github.io/ginkgo/#generating-reports-programmatically).

Ginkgo ships with `ginkgo`, a [command line tool](https://onsi.github.io/ginkgo/#ginkgo-cli-overview) with support for generating, running, filtering, and profiling Ginkgo suites.  You can even have Ginkgo automatically run your specs when it detects a change with `ginkgo watch`, enabling rapid feedback loops during test-driven development.

And that&#039;s just Ginkgo!  [Gomega](https://onsi.github.io/gomega/) brings a rich, mature, family of [assertions and matchers](https://onsi.github.io/gomega/#provided-matchers) to your suites.  With Gomega you can easily mix [synchronous and asynchronous assertions](https://onsi.github.io/ginkgo/#patterns-for-asynchronous-testing) in your specs.  You can even build your own set of expressive domain-specific matchers quickly and easily by composing Gomega&#039;s [existing building blocks](https://onsi.github.io/ginkgo/#building-custom-matchers).

Happy Testing!

## License

Ginkgo is MIT-Licensed

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md)

## Sponsors

Sponsors commit to a [sponsorship](https://github.com/sponsors/onsi) for a year.  If you&#039;re an organization that makes use of Ginkgo please consider becoming a sponsor!

&lt;p style=&quot;font-size:21px; color:black;&quot;&gt;Browser testing via 
    &lt;a href=&quot;https://www.lambdatest.com/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://www.lambdatest.com/blue-logo.png&quot; style=&quot;vertical-align: middle;&quot; width=&quot;250&quot; height=&quot;45&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[opentofu/opentofu]]></title>
            <link>https://github.com/opentofu/opentofu</link>
            <guid>https://github.com/opentofu/opentofu</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[OpenTofu lets you declaratively manage your cloud infrastructure.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/opentofu/opentofu">opentofu/opentofu</a></h1>
            <p>OpenTofu lets you declaratively manage your cloud infrastructure.</p>
            <p>Language: Go</p>
            <p>Stars: 26,979</p>
            <p>Forks: 1,113</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># OpenTofu

- [HomePage](https://opentofu.org/)
- [How to install](https://opentofu.org/docs/intro/install)
- [Join our Slack community!](https://opentofu.org/slack)

![](https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-dark.svg#gh-dark-mode-only)
![](https://raw.githubusercontent.com/opentofu/brand-artifacts/main/full/transparent/SVG/on-light.svg#gh-light-mode-only)

[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10508/badge)](https://www.bestpractices.dev/projects/10508)

OpenTofu is an OSS tool for building, changing, and versioning infrastructure safely and efficiently. OpenTofu can manage existing and popular service providers as well as custom in-house solutions.

The key features of OpenTofu are:

- **Infrastructure as Code**: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.

- **Execution Plans**: OpenTofu has a &quot;planning&quot; step where it generates an execution plan. The execution plan shows what OpenTofu will do when you call apply. This lets you avoid any surprises when OpenTofu manipulates infrastructure.

- **Resource Graph**: OpenTofu builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, OpenTofu builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.

- **Change Automation**: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what OpenTofu will change and in what order, avoiding many possible human errors.

## Getting help and contributing

- Have a question?
  - Post it in [GitHub Discussions](https://github.com/orgs/opentofu/discussions)
  - Open a [GitHub issue](https://github.com/opentofu/opentofu/issues/new/choose)
  - Join the [OpenTofu Slack](https://opentofu.org/slack/)!
- Want to contribute?
  - Please read the [Contribution Guide](CONTRIBUTING.md).
- Recurring Events
  - [Community Meetings](https://meet.google.com/xfm-cgms-has) on Wednesdays at 12:30 UTC at this link: https://meet.google.com/xfm-cgms-has ([üìÖ calendar link](https://calendar.google.com/calendar/event?eid=NDg0aWl2Y3U1aHFva3N0bGhyMHBhNzdpZmsgY18zZjJkZDNjMWZlMGVmNGU5M2VmM2ZjNDU2Y2EyZGQyMTlhMmU4ZmQ4NWY2YjQwNzUwYWYxNmMzZGYzNzBiZjkzQGc))
  - [Technical Steering Committee Meetings](https://meet.google.com/cry-houa-qbk) every other Tuesday at 4pm UTC at this link: https://meet.google.com/cry-houa-qbk ([üìÖ calendar link](https://calendar.google.com/calendar/u/0/event?eid=M3JyMWtuYWptdXI0Zms4ZnJpNmppcDczb3RfMjAyNTA1MjdUMTYwMDAwWiBjXzNmMmRkM2MxZmUwZWY0ZTkzZWYzZmM0NTZjYTJkZDIxOWEyZThmZDg1ZjZiNDA3NTBhZjE2YzNkZjM3MGJmOTNAZw))

&gt; [!TIP]
&gt; For more OpenTofu events, subscribe to the [OpenTofu Events Calendar](https://calendar.google.com/calendar/embed?src=c_3f2dd3c1fe0ef4e93ef3fc456ca2dd219a2e8fd85f6b40750af16c3df370bf93%40group.calendar.google.com)!

## Reporting security vulnerabilities
If you&#039;ve found a vulnerability or a potential vulnerability in OpenTofu please follow [Security Policy](https://github.com/opentofu/opentofu/security/policy). We&#039;ll send a confirmation email to acknowledge your report, and we&#039;ll send an additional email when we&#039;ve identified the issue positively or negatively.

## Reporting possible copyright issues

If you believe you have found any possible copyright or intellectual property issues, please contact liaison@opentofu.org. We&#039;ll send a confirmation email to acknowledge your report.

## Registry Access

In an effort to comply with applicable sanctions, we block access from specific countries of origin.

## License

[Mozilla Public License v2.0](https://github.com/opentofu/opentofu/blob/main/LICENSE)

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gorilla/mux]]></title>
            <link>https://github.com/gorilla/mux</link>
            <guid>https://github.com/gorilla/mux</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[Package gorilla/mux is a powerful HTTP router and URL matcher for building Go web servers with ü¶ç]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gorilla/mux">gorilla/mux</a></h1>
            <p>Package gorilla/mux is a powerful HTTP router and URL matcher for building Go web servers with ü¶ç</p>
            <p>Language: Go</p>
            <p>Stars: 21,680</p>
            <p>Forks: 1,877</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># gorilla/mux

![testing](https://github.com/gorilla/mux/actions/workflows/test.yml/badge.svg)
[![codecov](https://codecov.io/github/gorilla/mux/branch/main/graph/badge.svg)](https://codecov.io/github/gorilla/mux)
[![godoc](https://godoc.org/github.com/gorilla/mux?status.svg)](https://godoc.org/github.com/gorilla/mux)
[![sourcegraph](https://sourcegraph.com/github.com/gorilla/mux/-/badge.svg)](https://sourcegraph.com/github.com/gorilla/mux?badge)


![Gorilla Logo](https://github.com/gorilla/.github/assets/53367916/d92caabf-98e0-473e-bfbf-ab554ba435e5)

Package `gorilla/mux` implements a request router and dispatcher for matching incoming requests to
their respective handler.

The name mux stands for &quot;HTTP request multiplexer&quot;. Like the standard `http.ServeMux`, `mux.Router` matches incoming requests against a list of registered routes and calls a handler for the route that matches the URL or other conditions. The main features are:

* It implements the `http.Handler` interface so it is compatible with the standard `http.ServeMux`.
* Requests can be matched based on URL host, path, path prefix, schemes, header and query values, HTTP methods or using custom matchers.
* URL hosts, paths and query values can have variables with an optional regular expression.
* Registered URLs can be built, or &quot;reversed&quot;, which helps maintaining references to resources.
* Routes can be used as subrouters: nested routes are only tested if the parent route matches. This is useful to define groups of routes that share common conditions like a host, a path prefix or other repeated attributes. As a bonus, this optimizes request matching.

---

* [Install](#install)
* [Examples](#examples)
* [Matching Routes](#matching-routes)
* [Static Files](#static-files)
* [Serving Single Page Applications](#serving-single-page-applications) (e.g. React, Vue, Ember.js, etc.)
* [Registered URLs](#registered-urls)
* [Walking Routes](#walking-routes)
* [Graceful Shutdown](#graceful-shutdown)
* [Middleware](#middleware)
* [Handling CORS Requests](#handling-cors-requests)
* [Testing Handlers](#testing-handlers)
* [Full Example](#full-example)

---

## Install

With a [correctly configured](https://golang.org/doc/install#testing) Go toolchain:

```sh
go get -u github.com/gorilla/mux
```

## Examples

Let&#039;s start registering a couple of URL paths and handlers:

```go
func main() {
    r := mux.NewRouter()
    r.HandleFunc(&quot;/&quot;, HomeHandler)
    r.HandleFunc(&quot;/products&quot;, ProductsHandler)
    r.HandleFunc(&quot;/articles&quot;, ArticlesHandler)
    http.Handle(&quot;/&quot;, r)
}
```

Here we register three routes mapping URL paths to handlers. This is equivalent to how `http.HandleFunc()` works: if an incoming request URL matches one of the paths, the corresponding handler is called passing (`http.ResponseWriter`, `*http.Request`) as parameters.

Paths can have variables. They are defined using the format `{name}` or `{name:pattern}`. If a regular expression pattern is not defined, the matched variable will be anything until the next slash. For example:

```go
r := mux.NewRouter()
r.HandleFunc(&quot;/products/{key}&quot;, ProductHandler)
r.HandleFunc(&quot;/articles/{category}/&quot;, ArticlesCategoryHandler)
r.HandleFunc(&quot;/articles/{category}/{id:[0-9]+}&quot;, ArticleHandler)
```

The names are used to create a map of route variables which can be retrieved calling `mux.Vars()`:

```go
func ArticlesCategoryHandler(w http.ResponseWriter, r *http.Request) {
    vars := mux.Vars(r)
    w.WriteHeader(http.StatusOK)
    fmt.Fprintf(w, &quot;Category: %v\n&quot;, vars[&quot;category&quot;])
}
```

And this is all you need to know about the basic usage. More advanced options are explained below.

### Matching Routes

Routes can also be restricted to a domain or subdomain. Just define a host pattern to be matched. They can also have variables:

```go
r := mux.NewRouter()
// Only matches if domain is &quot;www.example.com&quot;.
r.Host(&quot;www.example.com&quot;)
// Matches a dynamic subdomain.
r.Host(&quot;{subdomain:[a-z]+}.example.com&quot;)
```

There are several other matchers that can be added. To match path prefixes:

```go
r.PathPrefix(&quot;/products/&quot;)
```

...or HTTP methods:

```go
r.Methods(&quot;GET&quot;, &quot;POST&quot;)
```

...or URL schemes:

```go
r.Schemes(&quot;https&quot;)
```

...or header values:

```go
r.Headers(&quot;X-Requested-With&quot;, &quot;XMLHttpRequest&quot;)
```

...or query values:

```go
r.Queries(&quot;key&quot;, &quot;value&quot;)
```

...or to use a custom matcher function:

```go
r.MatcherFunc(func(r *http.Request, rm *RouteMatch) bool {
    return r.ProtoMajor == 0
})
```

...and finally, it is possible to combine several matchers in a single route:

```go
r.HandleFunc(&quot;/products&quot;, ProductsHandler).
  Host(&quot;www.example.com&quot;).
  Methods(&quot;GET&quot;).
  Schemes(&quot;http&quot;)
```

Routes are tested in the order they were added to the router. If two routes match, the first one wins:

```go
r := mux.NewRouter()
r.HandleFunc(&quot;/specific&quot;, specificHandler)
r.PathPrefix(&quot;/&quot;).Handler(catchAllHandler)
```

Setting the same matching conditions again and again can be boring, so we have a way to group several routes that share the same requirements. We call it &quot;subrouting&quot;.

For example, let&#039;s say we have several URLs that should only match when the host is `www.example.com`. Create a route for that host and get a &quot;subrouter&quot; from it:

```go
r := mux.NewRouter()
s := r.Host(&quot;www.example.com&quot;).Subrouter()
```

Then register routes in the subrouter:

```go
s.HandleFunc(&quot;/products/&quot;, ProductsHandler)
s.HandleFunc(&quot;/products/{key}&quot;, ProductHandler)
s.HandleFunc(&quot;/articles/{category}/{id:[0-9]+}&quot;, ArticleHandler)
```

The three URL paths we registered above will only be tested if the domain is `www.example.com`, because the subrouter is tested first. This is not only convenient, but also optimizes request matching. You can create subrouters combining any attribute matchers accepted by a route.

Subrouters can be used to create domain or path &quot;namespaces&quot;: you define subrouters in a central place and then parts of the app can register its paths relatively to a given subrouter.

There&#039;s one more thing about subroutes. When a subrouter has a path prefix, the inner routes use it as base for their paths:

```go
r := mux.NewRouter()
s := r.PathPrefix(&quot;/products&quot;).Subrouter()
// &quot;/products/&quot;
s.HandleFunc(&quot;/&quot;, ProductsHandler)
// &quot;/products/{key}/&quot;
s.HandleFunc(&quot;/{key}/&quot;, ProductHandler)
// &quot;/products/{key}/details&quot;
s.HandleFunc(&quot;/{key}/details&quot;, ProductDetailsHandler)
```


### Static Files

Note that the path provided to `PathPrefix()` represents a &quot;wildcard&quot;: calling
`PathPrefix(&quot;/static/&quot;).Handler(...)` means that the handler will be passed any
request that matches &quot;/static/\*&quot;. This makes it easy to serve static files with mux:

```go
func main() {
    var dir string

    flag.StringVar(&amp;dir, &quot;dir&quot;, &quot;.&quot;, &quot;the directory to serve files from. Defaults to the current dir&quot;)
    flag.Parse()
    r := mux.NewRouter()

    // This will serve files under http://localhost:8000/static/&lt;filename&gt;
    r.PathPrefix(&quot;/static/&quot;).Handler(http.StripPrefix(&quot;/static/&quot;, http.FileServer(http.Dir(dir))))

    srv := &amp;http.Server{
        Handler:      r,
        Addr:         &quot;127.0.0.1:8000&quot;,
        // Good practice: enforce timeouts for servers you create!
        WriteTimeout: 15 * time.Second,
        ReadTimeout:  15 * time.Second,
    }

    log.Fatal(srv.ListenAndServe())
}
```

### Serving Single Page Applications

Most of the time it makes sense to serve your SPA on a separate web server from your API,
but sometimes it&#039;s desirable to serve them both from one place. It&#039;s possible to write a simple
handler for serving your SPA (for use with React Router&#039;s [BrowserRouter](https://reacttraining.com/react-router/web/api/BrowserRouter) for example), and leverage
mux&#039;s powerful routing for your API endpoints.

```go
package main

import (
	&quot;encoding/json&quot;
	&quot;log&quot;
	&quot;net/http&quot;
	&quot;os&quot;
	&quot;path/filepath&quot;
	&quot;time&quot;

	&quot;github.com/gorilla/mux&quot;
)

// spaHandler implements the http.Handler interface, so we can use it
// to respond to HTTP requests. The path to the static directory and
// path to the index file within that static directory are used to
// serve the SPA in the given static directory.
type spaHandler struct {
	staticPath string
	indexPath  string
}

// ServeHTTP inspects the URL path to locate a file within the static dir
// on the SPA handler. If a file is found, it will be served. If not, the
// file located at the index path on the SPA handler will be served. This
// is suitable behavior for serving an SPA (single page application).
func (h spaHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
	// Join internally call path.Clean to prevent directory traversal
	path := filepath.Join(h.staticPath, r.URL.Path)

	// check whether a file exists or is a directory at the given path
	fi, err := os.Stat(path)
	if os.IsNotExist(err) || fi.IsDir() {
		// file does not exist or path is a directory, serve index.html
		http.ServeFile(w, r, filepath.Join(h.staticPath, h.indexPath))
		return
	}

	if err != nil {
		// if we got an error (that wasn&#039;t that the file doesn&#039;t exist) stating the
		// file, return a 500 internal server error and stop
		http.Error(w, err.Error(), http.StatusInternalServerError)
        return
	}

	// otherwise, use http.FileServer to serve the static file
	http.FileServer(http.Dir(h.staticPath)).ServeHTTP(w, r)
}

func main() {
	router := mux.NewRouter()

	router.HandleFunc(&quot;/api/health&quot;, func(w http.ResponseWriter, r *http.Request) {
		// an example API handler
		json.NewEncoder(w).Encode(map[string]bool{&quot;ok&quot;: true})
	})

	spa := spaHandler{staticPath: &quot;build&quot;, indexPath: &quot;index.html&quot;}
	router.PathPrefix(&quot;/&quot;).Handler(spa)

	srv := &amp;http.Server{
		Handler: router,
		Addr:    &quot;127.0.0.1:8000&quot;,
		// Good practice: enforce timeouts for servers you create!
		WriteTimeout: 15 * time.Second,
		ReadTimeout:  15 * time.Second,
	}

	log.Fatal(srv.ListenAndServe())
}
```

### Registered URLs

Now let&#039;s see how to build registered URLs.

Routes can be named. All routes that define a name can have their URLs built, or &quot;reversed&quot;. We define a name calling `Name()` on a route. For example:

```go
r := mux.NewRouter()
r.HandleFunc(&quot;/articles/{category}/{id:[0-9]+}&quot;, ArticleHandler).
  Name(&quot;article&quot;)
```

To build a URL, get the route and call the `URL()` method, passing a sequence of key/value pairs for the route variables. For the previous route, we would do:

```go
url, err := r.Get(&quot;article&quot;).URL(&quot;category&quot;, &quot;technology&quot;, &quot;id&quot;, &quot;42&quot;)
```

...and the result will be a `url.URL` with the following path:

```
&quot;/articles/technology/42&quot;
```

This also works for host and query value variables:

```go
r := mux.NewRouter()
r.Host(&quot;{subdomain}.example.com&quot;).
  Path(&quot;/articles/{category}/{id:[0-9]+}&quot;).
  Queries(&quot;filter&quot;, &quot;{filter}&quot;).
  HandlerFunc(ArticleHandler).
  Name(&quot;article&quot;)

// url.String() will be &quot;http://news.example.com/articles/technology/42?filter=gorilla&quot;
url, err := r.Get(&quot;article&quot;).URL(&quot;subdomain&quot;, &quot;news&quot;,
                                 &quot;category&quot;, &quot;technology&quot;,
                                 &quot;id&quot;, &quot;42&quot;,
                                 &quot;filter&quot;, &quot;gorilla&quot;)
```

All variables defined in the route are required, and their values must conform to the corresponding patterns. These requirements guarantee that a generated URL will always match a registered route -- the only exception is for explicitly defined &quot;build-only&quot; routes which never match.

Regex support also exists for matching Headers within a route. For example, we could do:

```go
r.HeadersRegexp(&quot;Content-Type&quot;, &quot;application/(text|json)&quot;)
```

...and the route will match both requests with a Content-Type of `application/json` as well as `application/text`

There&#039;s also a way to build only the URL host or path for a route: use the methods `URLHost()` or `URLPath()` instead. For the previous route, we would do:

```go
// &quot;http://news.example.com/&quot;
host, err := r.Get(&quot;article&quot;).URLHost(&quot;subdomain&quot;, &quot;news&quot;)

// &quot;/articles/technology/42&quot;
path, err := r.Get(&quot;article&quot;).URLPath(&quot;category&quot;, &quot;technology&quot;, &quot;id&quot;, &quot;42&quot;)
```

And if you use subrouters, host and path defined separately can be built as well:

```go
r := mux.NewRouter()
s := r.Host(&quot;{subdomain}.example.com&quot;).Subrouter()
s.Path(&quot;/articles/{category}/{id:[0-9]+}&quot;).
  HandlerFunc(ArticleHandler).
  Name(&quot;article&quot;)

// &quot;http://news.example.com/articles/technology/42&quot;
url, err := r.Get(&quot;article&quot;).URL(&quot;subdomain&quot;, &quot;news&quot;,
                                 &quot;category&quot;, &quot;technology&quot;,
                                 &quot;id&quot;, &quot;42&quot;)
```

To find all the required variables for a given route when calling `URL()`, the method `GetVarNames()` is available:
```go
r := mux.NewRouter()
r.Host(&quot;{domain}&quot;).
    Path(&quot;/{group}/{item_id}&quot;).
    Queries(&quot;some_data1&quot;, &quot;{some_data1}&quot;).
    Queries(&quot;some_data2&quot;, &quot;{some_data2}&quot;).
    Name(&quot;article&quot;)

// Will print [domain group item_id some_data1 some_data2] &lt;nil&gt;
fmt.Println(r.Get(&quot;article&quot;).GetVarNames())

```
### Walking Routes

The `Walk` function on `mux.Router` can be used to visit all of the routes that are registered on a router. For example,
the following prints all of the registered routes:

```go
package main

import (
	&quot;fmt&quot;
	&quot;net/http&quot;
	&quot;strings&quot;

	&quot;github.com/gorilla/mux&quot;
)

func handler(w http.ResponseWriter, r *http.Request) {
	return
}

func main() {
	r := mux.NewRouter()
	r.HandleFunc(&quot;/&quot;, handler)
	r.HandleFunc(&quot;/products&quot;, handler).Methods(&quot;POST&quot;)
	r.HandleFunc(&quot;/articles&quot;, handler).Methods(&quot;GET&quot;)
	r.HandleFunc(&quot;/articles/{id}&quot;, handler).Methods(&quot;GET&quot;, &quot;PUT&quot;)
	r.HandleFunc(&quot;/authors&quot;, handler).Queries(&quot;surname&quot;, &quot;{surname}&quot;)
	err := r.Walk(func(route *mux.Route, router *mux.Router, ancestors []*mux.Route) error {
		pathTemplate, err := route.GetPathTemplate()
		if err == nil {
			fmt.Println(&quot;ROUTE:&quot;, pathTemplate)
		}
		pathRegexp, err := route.GetPathRegexp()
		if err == nil {
			fmt.Println(&quot;Path regexp:&quot;, pathRegexp)
		}
		queriesTemplates, err := route.GetQueriesTemplates()
		if err == nil {
			fmt.Println(&quot;Queries templates:&quot;, strings.Join(queriesTemplates, &quot;,&quot;))
		}
		queriesRegexps, err := route.GetQueriesRegexp()
		if err == nil {
			fmt.Println(&quot;Queries regexps:&quot;, strings.Join(queriesRegexps, &quot;,&quot;))
		}
		methods, err := route.GetMethods()
		if err == nil {
			fmt.Println(&quot;Methods:&quot;, strings.Join(methods, &quot;,&quot;))
		}
		fmt.Println()
		return nil
	})

	if err != nil {
		fmt.Println(err)
	}

	http.Handle(&quot;/&quot;, r)
}
```

### Graceful Shutdown

Go 1.8 introduced the ability to [gracefully shutdown](https://golang.org/doc/go1.8#http_shutdown) a `*http.Server`. Here&#039;s how to do that alongside `mux`:

```go
package main

import (
    &quot;context&quot;
    &quot;flag&quot;
    &quot;log&quot;
    &quot;net/http&quot;
    &quot;os&quot;
    &quot;os/signal&quot;
    &quot;time&quot;

    &quot;github.com/gorilla/mux&quot;
)

func main() {
    var wait time.Duration
    flag.DurationVar(&amp;wait, &quot;graceful-timeout&quot;, time.Second * 15, &quot;the duration for which the server gracefully wait for existing connections to finish - e.g. 15s or 1m&quot;)
    flag.Parse()

    r := mux.NewRouter()
    // Add your routes as needed

    srv := &amp;http.Server{
        Addr:         &quot;0.0.0.0:8080&quot;,
        // Good practice to set timeouts to avoid Slowloris attacks.
        WriteTimeout: time.Second * 15,
        ReadTimeout:  time.Second * 15,
        IdleTimeout:  time.Second * 60,
        Handler: r, // Pass our instance of gorilla/mux in.
    }

    // Run our server in a goroutine so that it doesn&#039;t block.
    go func() {
        if err := srv.ListenAndServe(); err != nil {
            log.Println(err)
        }
    }()

    c := make(chan os.Signal, 1)
    // We&#039;ll accept graceful shutdowns when quit via SIGINT (Ctrl+C)
    // SIGKILL, SIGQUIT or SIGTERM (Ctrl+/) will not be caught.
    signal.Notify(c, os.Interrupt)

    // Block until we receive our signal.
    &lt;-c

    // Create a deadline to wait for.
    ctx, cancel := context.WithTimeout(context.Background(), wait)
    defer cancel()
    // Doesn&#039;t block if no connections, but will otherwise wait
    // until the timeout deadline.
    srv.Shutdown(ctx)
    // Optionally, you could run srv.Shutdown in a goroutine and block on
    // &lt;-ctx.Done() if your application should wait for other services
    // to finalize based on context cancellation.
    log.Println(&quot;shutting down&quot;)
    os.Exit(0)
}
```

### Middleware

Mux supports the addition of middlewares to a [Router](https://godoc.org/github.com/gorilla/mux#Router), which are executed in the order they are added if a match is found, including its subrouters.
Middlewares are (typically) small pieces of code which take one request, do something with it, and pass it down to another middleware or the final handler. Some common use cases for middleware are request logging, header manipulation, or `ResponseWriter` hijacking.

Mux middlewares are defined using the de facto standard type:

```go
type MiddlewareFunc func(http.Handler) http.Handler
```

Typically, the returned handler is a closure which does something with the http.ResponseWriter and http.Request passed to it, and then calls the handler passed as parameter to the MiddlewareFunc. This takes advantage of closures being able access variables from the context where they are created, while retaining the signature enforced by the receivers.

A very basic middleware which logs the URI of the request being handled could be written as:

```go
func loggingMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Do stuff here
        log.Println(r.RequestURI)
        // Call the next handler, which can be another middleware in the chain, or the final handler.
        next.ServeHTTP(w, r)
    })
}
```

Middlewares can be added to a router using `Router.Use()`:

```go
r := mux.NewRouter()
r.HandleFunc(&quot;/&quot;, handler)
r.Use(loggingMiddleware)
```

A more complex authentication middleware, which maps session token to users, could be written as:

```go
// Define our struct
type authenticationMiddleware struct {
	tokenUsers map[string]string
}

// Initialize it somewhere
func (amw *authenticationMiddleware) Populate() {
	amw.tokenUsers[&quot;00000000&quot;] = &quot;user0&quot;
	amw.tokenUsers[&quot;aaaaaaaa&quot;] = &quot;userA&quot;
	amw.tokenUsers[&quot;05f717e5&quot;] = &quot;randomUser&quot;
	amw.tokenUsers[&quot;deadbeef&quot;] = &quot;user0&quot;
}

// Middleware function, which will be called for each request
func (amw *authenticationMiddleware) Middleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        token := r.Header.Get(&quot;X-Session-Token&quot;)

        if user, found := amw.tokenUsers[token]; found {
        	// We found the token in our map
        	log.Printf(&quot;Authenticated user %s\n&quot;, user)
        	// Pass down the request to the next middleware (or final handler)
        	next.ServeHTTP(w, r)
        } else {
        	// Write an error and stop the handler chain
        	http.Error(w, &quot;Forbidden&quot;, http.StatusForbidden)
        }
    })
}
```

```go
r := mux.NewRouter()
r.HandleFunc(&quot;/&quot;, handler)

amw := authenticationMiddleware{tokenUsers: make(map[string]string)}
amw.Populate()

r.Use(amw.Middleware)
```

Note: The handler chain will be stopped if your middleware doesn&#039;t call `next.ServeHTTP()` with the corresponding parameters. This can be used to abort a request if the middleware writer wants to. Middlewares _should_ write to `ResponseWriter` if they _are_ going to terminate the request, and they _should not_ write to `ResponseWriter` if they _are not_ going to terminate it.

### Handling CORS Requests

[CORSMethodMiddleware](https://godoc.org/github.com/gorilla/mux#CORSMethodMiddleware) intends to make it easier to strictly set the `Access-Control-Allow-Methods` response header.

* You will still need to use your own CORS handler to set the other CORS headers such as `Access-Control-Allow-Origin`
* The middleware will set the `Access-Control-Allow-Methods` header to all the method matchers (e.g. `r.Methods(http.MethodGet, http.MethodPut, http.MethodOptions)` -&gt; `Access-Control-Allow-Methods: GET,PUT,OPTIONS`) on a route
* If you do not specify any methods, then:

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[googleapis/genai-toolbox]]></title>
            <link>https://github.com/googleapis/genai-toolbox</link>
            <guid>https://github.com/googleapis/genai-toolbox</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[MCP Toolbox for Databases is an open source MCP server for databases.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/googleapis/genai-toolbox">googleapis/genai-toolbox</a></h1>
            <p>MCP Toolbox for Databases is an open source MCP server for databases.</p>
            <p>Language: Go</p>
            <p>Stars: 11,355</p>
            <p>Forks: 985</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>![logo](./logo.png)

# MCP Toolbox for Databases

[![Docs](https://img.shields.io/badge/docs-MCP_Toolbox-blue)](https://googleapis.github.io/genai-toolbox/)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=flat&amp;logo=discord&amp;logoColor=white)](https://discord.gg/Dmm69peqjh)
[![Medium](https://img.shields.io/badge/Medium-12100E?style=flat&amp;logo=medium&amp;logoColor=white)](https://medium.com/@mcp_toolbox)
[![Go Report Card](https://goreportcard.com/badge/github.com/googleapis/genai-toolbox)](https://goreportcard.com/report/github.com/googleapis/genai-toolbox)

&gt; [!NOTE]
&gt; MCP Toolbox for Databases is currently in beta, and may see breaking
&gt; changes until the first stable release (v1.0).

MCP Toolbox for Databases is an open source MCP server for databases. It enables
you to develop tools easier, faster, and more securely by handling the complexities
such as connection pooling, authentication, and more.

This README provides a brief overview. For comprehensive details, see the [full
documentation](https://googleapis.github.io/genai-toolbox/).

&gt; [!NOTE]
&gt; This solution was originally named ‚ÄúGen AI Toolbox for Databases‚Äù as
&gt; its initial development predated MCP, but was renamed to align with recently
&gt; added MCP compatibility.

&lt;!-- TOC ignore:true --&gt;
## Table of Contents

&lt;!-- TOC --&gt;

- [Why Toolbox?](#why-toolbox)
- [General Architecture](#general-architecture)
- [Getting Started](#getting-started)
  - [Installing the server](#installing-the-server)
  - [Running the server](#running-the-server)
  - [Integrating your application](#integrating-your-application)
  - [Using Toolbox with Gemini CLI Extensions](#using-toolbox-with-gemini-cli-extensions)
- [Configuration](#configuration)
  - [Sources](#sources)
  - [Tools](#tools)
  - [Toolsets](#toolsets)
- [Versioning](#versioning)
  - [Pre-1.0.0 Versioning](#pre-100-versioning)
  - [Post-1.0.0 Versioning](#post-100-versioning)
- [Contributing](#contributing)
- [Community](#community)

&lt;!-- /TOC --&gt;

## Why Toolbox?

Toolbox helps you build Gen AI tools that let your agents access data in your
database. Toolbox provides:

- **Simplified development**: Integrate tools to your agent in less than 10
  lines of code, reuse tools between multiple agents or frameworks, and deploy
  new versions of tools more easily.
- **Better performance**: Best practices such as connection pooling,
  authentication, and more.
- **Enhanced security**: Integrated auth for more secure access to your data
- **End-to-end observability**: Out of the box metrics and tracing with built-in
  support for OpenTelemetry.

**‚ö° Supercharge Your Workflow with an AI Database Assistant ‚ö°**

Stop context-switching and let your AI assistant become a true co-developer. By
[connecting your IDE to your databases with MCP Toolbox][connect-ide], you can
delegate complex and time-consuming database tasks, allowing you to build faster
and focus on what matters. This isn&#039;t just about code completion; it&#039;s about
giving your AI the context it needs to handle the entire development lifecycle.

Here‚Äôs how it will save you time:

- **Query in Plain English**: Interact with your data using natural language
  right from your IDE. Ask complex questions like, *&quot;How many orders were
  delivered in 2024, and what items were in them?&quot;* without writing any SQL.
- **Automate Database Management**: Simply describe your data needs, and let the
  AI assistant manage your database for you. It can handle generating queries,
  creating tables, adding indexes, and more.
- **Generate Context-Aware Code**: Empower your AI assistant to generate
  application code and tests with a deep understanding of your real-time
  database schema.  This accelerates the development cycle by ensuring the
  generated code is directly usable.
- **Slash Development Overhead**: Radically reduce the time spent on manual
  setup and boilerplate. MCP Toolbox helps streamline lengthy database
  configurations, repetitive code, and error-prone schema migrations.

Learn [how to connect your AI tools (IDEs) to Toolbox using MCP][connect-ide].

[connect-ide]: https://googleapis.github.io/genai-toolbox/how-to/connect-ide/

## General Architecture

Toolbox sits between your application&#039;s orchestration framework and your
database, providing a control plane that is used to modify, distribute, or
invoke tools. It simplifies the management of your tools by providing you with a
centralized location to store and update tools, allowing you to share tools
between agents and applications and update those tools without necessarily
redeploying your application.

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;./docs/en/getting-started/introduction/architecture.png&quot; alt=&quot;architecture&quot; width=&quot;50%&quot;/&gt;
&lt;/p&gt;

## Getting Started

### Installing the server

For the latest version, check the [releases page][releases] and use the
following instructions for your OS and CPU architecture.

[releases]: https://github.com/googleapis/genai-toolbox/releases

&lt;details open&gt;
&lt;summary&gt;Binary&lt;/summary&gt;

To install Toolbox as a binary:

&lt;!-- {x-release-please-start-version} --&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;Linux (AMD64)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on Linux (AMD64):
&gt;
&gt; ```sh
&gt; # see releases page for other versions
&gt; export VERSION=0.19.1
&gt; curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/linux/amd64/toolbox
&gt; chmod +x toolbox
&gt; ```
&gt;
&gt; &lt;/details&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;macOS (Apple Silicon)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on macOS (Apple Silicon):
&gt;
&gt; ```sh
&gt; # see releases page for other versions
&gt; export VERSION=0.19.1
&gt; curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/darwin/arm64/toolbox
&gt; chmod +x toolbox
&gt; ```
&gt;
&gt; &lt;/details&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;macOS (Intel)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on macOS (Intel):
&gt;
&gt; ```sh
&gt; # see releases page for other versions
&gt; export VERSION=0.19.1
&gt; curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/darwin/amd64/toolbox
&gt; chmod +x toolbox
&gt; ```
&gt;
&gt; &lt;/details&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;Windows (AMD64)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on Windows (AMD64):
&gt;
&gt; ```powershell
&gt; # see releases page for other versions
&gt; $VERSION = &quot;0.19.1&quot;
&gt; Invoke-WebRequest -Uri &quot;https://storage.googleapis.com/genai-toolbox/v$VERSION/windows/amd64/toolbox.exe&quot; -OutFile &quot;toolbox.exe&quot;
&gt; ```
&gt;
&gt; &lt;/details&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Container image&lt;/summary&gt;
You can also install Toolbox as a container:

```sh
# see releases page for other versions
export VERSION=0.19.1
docker pull us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Homebrew&lt;/summary&gt;

To install Toolbox using Homebrew on macOS or Linux:

```sh
brew install mcp-toolbox
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Compile from source&lt;/summary&gt;

To install from source, ensure you have the latest version of
[Go installed](https://go.dev/doc/install), and then run the following command:

```sh
go install github.com/googleapis/genai-toolbox@v0.19.1
```
&lt;!-- {x-release-please-end} --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Gemini CLI Extensions&lt;/summary&gt;

To install Gemini CLI Extensions for MCP Toolbox, run the following command:

```sh
gemini extensions install https://github.com/gemini-cli-extensions/mcp-toolbox
```

&lt;/details&gt;

### Running the server

[Configure](#configuration) a `tools.yaml` to define your tools, and then
execute `toolbox` to start the server:

&lt;details open&gt;
&lt;summary&gt;Binary&lt;/summary&gt;

To run Toolbox from binary:

```sh
./toolbox --tools-file &quot;tools.yaml&quot;
```

&gt; ‚ìò Note  
&gt; Toolbox enables dynamic reloading by default. To disable, use the
&gt; `--disable-reload` flag.

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Container image&lt;/summary&gt;

To run the server after pulling the [container image](#installing-the-server):

```sh
export VERSION=0.11.0 # Use the version you pulled
docker run -p 5000:5000 \
-v $(pwd)/tools.yaml:/app/tools.yaml \
us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION \
--tools-file &quot;/app/tools.yaml&quot;
```

&gt; ‚ìò Note  
&gt; The `-v` flag mounts your local `tools.yaml` into the container, and `-p` maps
&gt; the container&#039;s port `5000` to your host&#039;s port `5000`.

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Source&lt;/summary&gt;

To run the server directly from source, navigate to the project root directory
and run:

```sh
go run .
```

&gt; ‚ìò Note  
&gt; This command runs the project from source, and is more suitable for development
&gt; and testing. It does **not** compile a binary into your `$GOPATH`. If you want
&gt; to compile a binary instead, refer the [Developer
&gt; Documentation](./DEVELOPER.md#building-the-binary).

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Homebrew&lt;/summary&gt;

If you installed Toolbox using [Homebrew](https://brew.sh/), the `toolbox`
binary is available in your system path. You can start the server with the same
command:

```sh
toolbox --tools-file &quot;tools.yaml&quot;
```

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Gemini CLI&lt;/summary&gt;

Interact with your custom tools using natural language. Check
[gemini-cli-extensions/mcp-toolbox](https://github.com/gemini-cli-extensions/mcp-toolbox)
for more information.

&lt;/details&gt;

You can use `toolbox help` for a full list of flags! To stop the server, send a
terminate signal (`ctrl+c` on most platforms).

For more detailed documentation on deploying to different environments, check
out the resources in the [How-to
section](https://googleapis.github.io/genai-toolbox/how-to/)

### Integrating your application

Once your server is up and running, you can load the tools into your
application. See below the list of Client SDKs for using various frameworks:

&lt;details open&gt;
  &lt;summary&gt;Python (&lt;a href=&quot;https://github.com/googleapis/mcp-toolbox-sdk-python&quot;&gt;Github&lt;/a&gt;)&lt;/summary&gt;
  &lt;br&gt;
  &lt;blockquote&gt;

  &lt;details open&gt;
    &lt;summary&gt;Core&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core]:

    ```bash
    pip install toolbox-core
    ```

1. Load tools:

    ```python
    from toolbox_core import ToolboxClient

    # update the url to point to your server
    async with ToolboxClient(&quot;http://127.0.0.1:5000&quot;) as client:

        # these tools can be passed to your application!
        tools = await client.load_toolset(&quot;toolset_name&quot;)
    ```

For more detailed instructions on using the Toolbox Core SDK, see the
[project&#039;s README][toolbox-core-readme].

[toolbox-core]: https://pypi.org/project/toolbox-core/
[toolbox-core-readme]: https://github.com/googleapis/mcp-toolbox-sdk-python/tree/main/packages/toolbox-core/README.md

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;LangChain / LangGraph&lt;/summary&gt;

1. Install [Toolbox LangChain SDK][toolbox-langchain]:

    ```bash
    pip install toolbox-langchain
    ```

1. Load tools:

    ```python
    from toolbox_langchain import ToolboxClient

    # update the url to point to your server
    async with ToolboxClient(&quot;http://127.0.0.1:5000&quot;) as client:

        # these tools can be passed to your application!
        tools = client.load_toolset()
    ```

    For more detailed instructions on using the Toolbox LangChain SDK, see the
    [project&#039;s README][toolbox-langchain-readme].

    [toolbox-langchain]: https://pypi.org/project/toolbox-langchain/
    [toolbox-langchain-readme]: https://github.com/googleapis/mcp-toolbox-sdk-python/blob/main/packages/toolbox-langchain/README.md

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;LlamaIndex&lt;/summary&gt;

1. Install [Toolbox Llamaindex SDK][toolbox-llamaindex]:

    ```bash
    pip install toolbox-llamaindex
    ```

1. Load tools:

    ```python
    from toolbox_llamaindex import ToolboxClient

    # update the url to point to your server
    async with ToolboxClient(&quot;http://127.0.0.1:5000&quot;) as client:

        # these tools can be passed to your application!
        tools = client.load_toolset()
    ```

    For more detailed instructions on using the Toolbox Llamaindex SDK, see the
    [project&#039;s README][toolbox-llamaindex-readme].

    [toolbox-llamaindex]: https://pypi.org/project/toolbox-llamaindex/
    [toolbox-llamaindex-readme]: https://github.com/googleapis/genai-toolbox-llamaindex-python/blob/main/README.md

  &lt;/details&gt;
&lt;/details&gt;
&lt;/blockquote&gt;
&lt;details&gt;
  &lt;summary&gt;Javascript/Typescript (&lt;a href=&quot;https://github.com/googleapis/mcp-toolbox-sdk-js&quot;&gt;Github&lt;/a&gt;)&lt;/summary&gt;
  &lt;br&gt;
  &lt;blockquote&gt;

  &lt;details open&gt;
    &lt;summary&gt;Core&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core-js]:

    ```bash
    npm install @toolbox-sdk/core
    ```

1. Load tools:

    ```javascript
    import { ToolboxClient } from &#039;@toolbox-sdk/core&#039;;

    // update the url to point to your server
    const URL = &#039;http://127.0.0.1:5000&#039;;
    let client = new ToolboxClient(URL);

    // these tools can be passed to your application!
    const tools = await client.loadToolset(&#039;toolsetName&#039;);
    ```

    For more detailed instructions on using the Toolbox Core SDK, see the
    [project&#039;s README][toolbox-core-js-readme].

    [toolbox-core-js]: https://www.npmjs.com/package/@toolbox-sdk/core
    [toolbox-core-js-readme]: https://github.com/googleapis/mcp-toolbox-sdk-js/blob/main/packages/toolbox-core/README.md

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;LangChain / LangGraph&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core-js]:

    ```bash
    npm install @toolbox-sdk/core
    ```

2. Load tools:

    ```javascript
    import { ToolboxClient } from &#039;@toolbox-sdk/core&#039;;

    // update the url to point to your server
    const URL = &#039;http://127.0.0.1:5000&#039;;
    let client = new ToolboxClient(URL);

    // these tools can be passed to your application!
    const toolboxTools = await client.loadToolset(&#039;toolsetName&#039;);

    // Define the basics of the tool: name, description, schema and core logic
    const getTool = (toolboxTool) =&gt; tool(currTool, {
        name: toolboxTool.getName(),
        description: toolboxTool.getDescription(),
        schema: toolboxTool.getParamSchema()
    });

    // Use these tools in your Langchain/Langraph applications
    const tools = toolboxTools.map(getTool);
    ```

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;Genkit&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core-js]:

    ```bash
    npm install @toolbox-sdk/core
    ```

2. Load tools:

    ```javascript
    import { ToolboxClient } from &#039;@toolbox-sdk/core&#039;;
    import { genkit } from &#039;genkit&#039;;

    // Initialise genkit
    const ai = genkit({
        plugins: [
            googleAI({
                apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY
            })
        ],
        model: googleAI.model(&#039;gemini-2.0-flash&#039;),
    });

    // update the url to point to your server
    const URL = &#039;http://127.0.0.1:5000&#039;;
    let client = new ToolboxClient(URL);

    // these tools can be passed to your application!
    const toolboxTools = await client.loadToolset(&#039;toolsetName&#039;);

    // Define the basics of the tool: name, description, schema and core logic
    const getTool = (toolboxTool) =&gt; ai.defineTool({
        name: toolboxTool.getName(),
        description: toolboxTool.getDescription(),
        schema: toolboxTool.getParamSchema()
    }, toolboxTool)

    // Use these tools in your Genkit applications
    const tools = toolboxTools.map(getTool);
    ```

  &lt;/details&gt;
&lt;/details&gt;
&lt;/blockquote&gt;
&lt;details&gt;
  &lt;summary&gt;Go (&lt;a href=&quot;https://github.com/googleapis/mcp-toolbox-sdk-go&quot;&gt;Github&lt;/a&gt;)&lt;/summary&gt;
  &lt;br&gt;
  &lt;blockquote&gt;

  &lt;details&gt;
    &lt;summary&gt;Core&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

2. Load tools:

    ```go
    package main

    import (
      &quot;github.com/googleapis/mcp-toolbox-sdk-go/core&quot;
      &quot;context&quot;
    )

    func main() {
      // Make sure to add the error checks
      // update the url to point to your server
      URL := &quot;http://127.0.0.1:5000&quot;;
      ctx := context.Background()

      client, err := core.NewToolboxClient(URL)

      // Framework agnostic tools
      tools, err := client.LoadToolset(&quot;toolsetName&quot;, ctx)
    }
    ```

    For more detailed instructions on using the Toolbox Go SDK, see the
    [project&#039;s README][toolbox-core-go-readme].

    [toolbox-go]: https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core
    [toolbox-core-go-readme]: https://github.com/googleapis/mcp-toolbox-sdk-go/blob/main/core/README.md

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;LangChain Go&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

2. Load tools:

    ```go
    package main

    import (
      &quot;context&quot;
      &quot;encoding/json&quot;

      &quot;github.com/googleapis/mcp-toolbox-sdk-go/core&quot;
      &quot;github.com/tmc/langchaingo/llms&quot;
    )

    func main() {
      // Make sure to add the error checks
      // update the url to point to your server
      URL := &quot;http://127.0.0.1:5000&quot;
      ctx := context.Background()

      client, err := core.NewToolboxClient(URL)

      // Framework agnostic tool
      tool, err := client.LoadTool(&quot;toolName&quot;, ctx)

      // Fetch the tool&#039;s input schema
      inputschema, err := tool.InputSchema()

      var paramsSchema map[string]any
      _ = json.Unmarshal(inputschema, &amp;paramsSchema)

      // Use this tool with LangChainGo
      langChainTool := llms.Tool{
        Type: &quot;function&quot;,
        Function: &amp;llms.FunctionDefinition{
          Name:        tool.Name(),
          Description: tool.Description(),
          Parameters:  paramsSchema,
        },
      }
    }

    ```

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;Genkit&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

2. Load tools:

    ```go
    package main
    import (
      &quot;context&quot;
      &quot;log&quot;

      &quot;github.com/firebase/genkit/go/genkit&quot;
      &quot;github.com/googleapis/mcp-toolbox-sdk-go/core&quot;
      &quot;github.com/googleapis/mcp-toolbox-sdk-go/tbgenkit&quot;
    )

    func main() {
      // Make sure to add the error checks
      // Update the url to point to your server
      URL := &quot;http://127.0.0.1:5000&quot;
      ctx := context.Background()
      g := genkit.Init(ctx)

      client, err := core.NewToolboxClient(URL)

      // Framework agnostic tool
      tool, err := client.LoadTool(&quot;toolName&quot;, ctx)

      // Convert the tool using the tbgenkit package
      // Use this tool with Genkit Go
      genkitTool, err := tbgenkit.ToGenkitTool(tool, g)
      if err != nil {
        log.Fatalf(&quot;Failed to convert tool: %v\n&quot;, err)
      }
      log.Printf(&quot;Successfully converted tool: %s&quot;, genkitTool.Name())
    }
    ```

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;Go GenAI&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

2. Load tools:

    ```go
    package main

    import (
      &quot;context&quot;
      &quot;encoding/json&quot;

      &quot;github.com/googleapis/mcp-toolbox-sdk-go/core&quot;
      &quot;google.golang.org/genai&quot;
    )

    func main() {
      // Make sure to add the error checks
      // Update the url to point to your server
      URL := &quot;http://127.0.0.1:5000&quot;
      ctx := context.Background()

      client, err := core.NewToolboxClient(URL)

      // Framework agnostic tool
      tool, err := client.LoadTool(&quot;toolName&quot;, ctx)

      // Fetch the tool&#039;s input schema
      inputschema, err := tool.InputSchema()

      var schema *genai.Schema
      _ = json.Unmarshal(inputschema, &amp;schema)

      funcDeclaration := &amp;genai.FunctionDeclaration{
        Name:        tool.Name(),
        Description: tool.Description(),
        Parameters:  schema,
      }

      // Use this tool with Go GenAI
      genAITool := &amp;genai.Tool{
        FunctionDeclarations: []*genai.FunctionDeclaration{funcDeclaration},
      }
    }
    ```

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;OpenAI Go&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

2. Load tools:

    ```go
    package main

    import (
      &quot;context&quot;
      &quot;encoding/json&quot;

      &quot;github.com/g

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[containers/skopeo]]></title>
            <link>https://github.com/containers/skopeo</link>
            <guid>https://github.com/containers/skopeo</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[Work with remote images registries - retrieving information, images, signing content]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/containers/skopeo">containers/skopeo</a></h1>
            <p>Work with remote images registries - retrieving information, images, signing content</p>
            <p>Language: Go</p>
            <p>Stars: 9,984</p>
            <p>Forks: 877</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
   &lt;img src=&quot;https://cdn.rawgit.com/containers/skopeo/main/docs/skopeo.svg&quot; width=&quot;250&quot; alt=&quot;Skopeo&quot;&gt;
&lt;/p&gt;

----
![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)
![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/containers/skopeo)
[![Go Report Card](https://goreportcard.com/badge/github.com/containers/skopeo)](https://goreportcard.com/report/github.com/containers/skopeo)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10516/badge)](https://www.bestpractices.dev/projects/10516)

`skopeo` is a command line utility that performs various operations on container images and image repositories.

`skopeo` does not require the user to be running as root to do most of its operations.

`skopeo` does not require a daemon to be running to perform its operations.

`skopeo` can work with [OCI images](https://github.com/opencontainers/image-spec) as well as the original Docker v2 images.

Skopeo works with API V2 container image registries such as [docker.io](https://docker.io) and [quay.io](https://quay.io) registries, private registries, local directories and local OCI-layout directories. Skopeo can perform operations which consist of:

 * Copying an image from and to various storage mechanisms.
   For example you can copy images from one registry to another, without requiring privilege.
 * Inspecting a remote image showing its properties including its layers, without requiring you to pull the image to the host.
 * Deleting an image from an image repository.
 * Syncing an external image repository to an internal registry for air-gapped deployments.
 * When required by the repository, skopeo can pass the appropriate credentials and certificates for authentication.

 Skopeo operates on the following image and repository types:

 * containers-storage:docker-reference
         An image located in a local containers/storage image store.  Both the location and image store are specified in /etc/containers/storage.conf. (This is  the backend for [Podman](https://podman.io), [CRI-O](https://cri-o.io), [Buildah](https://buildah.io) and friends)

 * dir:path
         An existing local directory path storing the manifest, layer tarballs and signatures as individual files. This is a non-standardized format, primarily useful for debugging or noninvasive container inspection.

 * docker://docker-reference
         An image in a registry implementing the &quot;Docker Registry HTTP API V2&quot;. By default, uses the authorization state in `$XDG_RUNTIME_DIR/containers/auth.json`, which is set using `skopeo login`.

 * docker-archive:path[:docker-reference]
         An image is stored in a `docker save`-formatted file.  docker-reference is only used when creating such a file, and it must not contain a digest.

 * docker-daemon:docker-reference
         An image docker-reference stored in the docker daemon internal storage.  docker-reference must contain either a tag or a digest.  Alternatively, when reading images, the format can also be docker-daemon:algo:digest (an image ID).

 * oci:path:tag
         An image tag in a directory compliant with &quot;Open Container Image Layout Specification&quot; at path.

[Obtaining skopeo](./install.md)
-

For a detailed description how to install or build skopeo, see
[install.md](./install.md).

Skopeo is also available as a Container Image on [quay.io](https://quay.io/skopeo/stable).  For more information, see the [Skopeo Image](https://github.com/containers/image_build/blob/main/skopeo/README.md) page.

## Inspecting a repository
`skopeo` is able to _inspect_ a repository on a container registry and fetch images layers.
The _inspect_ command fetches the repository&#039;s manifest and it is able to show you a `docker inspect`-like
json output about a whole repository or a tag. This tool, in contrast to `docker inspect`, helps you gather useful information about
a repository or a tag before pulling it (using disk space).  The inspect command can show you which tags are available for the given 
repository, the labels the image has, the creation date and operating system of the image and more.  

Examples:

#### Show properties of fedora:latest
```console
$ skopeo inspect docker://registry.fedoraproject.org/fedora:latest
{
    &quot;Name&quot;: &quot;registry.fedoraproject.org/fedora&quot;,
    &quot;Digest&quot;: &quot;sha256:0f65bee641e821f8118acafb44c2f8fe30c2fc6b9a2b3729c0660376391aa117&quot;,
    &quot;RepoTags&quot;: [
        &quot;34-aarch64&quot;,
        &quot;34&quot;,
        &quot;latest&quot;,
        ...
    ],
    &quot;Created&quot;: &quot;2022-11-24T13:54:18Z&quot;,
    &quot;DockerVersion&quot;: &quot;1.10.1&quot;,
    &quot;Labels&quot;: {
        &quot;license&quot;: &quot;MIT&quot;,
        &quot;name&quot;: &quot;fedora&quot;,
        &quot;vendor&quot;: &quot;Fedora Project&quot;,
        &quot;version&quot;: &quot;37&quot;
    },
    &quot;Architecture&quot;: &quot;amd64&quot;,
    &quot;Os&quot;: &quot;linux&quot;,
    &quot;Layers&quot;: [
        &quot;sha256:2a0fc6bf62e155737f0ace6142ee686f3c471c1aab4241dc3128904db46288f0&quot;
    ],
    &quot;LayersData&quot;: [
        {
            &quot;MIMEType&quot;: &quot;application/vnd.docker.image.rootfs.diff.tar.gzip&quot;,
            &quot;Digest&quot;: &quot;sha256:2a0fc6bf62e155737f0ace6142ee686f3c471c1aab4241dc3128904db46288f0&quot;,
            &quot;Size&quot;: 71355009,
            &quot;Annotations&quot;: null
        }
    ],
    &quot;Env&quot;: [
        &quot;DISTTAG=f37container&quot;,
        &quot;FGC=f37&quot;,
        &quot;container=oci&quot;
    ]
}
```

#### Show container configuration from `fedora:latest`

```console
$ skopeo inspect --config docker://registry.fedoraproject.org/fedora:latest  | jq
{
  &quot;created&quot;: &quot;2020-04-29T06:48:16Z&quot;,
  &quot;architecture&quot;: &quot;amd64&quot;,
  &quot;os&quot;: &quot;linux&quot;,
  &quot;config&quot;: {
    &quot;Env&quot;: [
      &quot;DISTTAG=f32container&quot;,
      &quot;FGC=f32&quot;,
      &quot;container=oci&quot;
    ],
    &quot;Cmd&quot;: [
      &quot;/bin/bash&quot;
    ],
    &quot;Labels&quot;: {
      &quot;license&quot;: &quot;MIT&quot;,
      &quot;name&quot;: &quot;fedora&quot;,
      &quot;vendor&quot;: &quot;Fedora Project&quot;,
      &quot;version&quot;: &quot;32&quot;
    }
  },
  &quot;rootfs&quot;: {
    &quot;type&quot;: &quot;layers&quot;,
    &quot;diff_ids&quot;: [
      &quot;sha256:a4c0fa2b217d3fd63d51e55a6fd59432e543d499c0df2b1acd48fbe424f2ddd1&quot;
    ]
  },
  &quot;history&quot;: [
    {
      &quot;created&quot;: &quot;2020-04-29T06:48:16Z&quot;,
      &quot;comment&quot;: &quot;Created by Image Factory&quot;
    }
  ]
}
```
#### Show unverified image&#039;s digest
```console
$ skopeo inspect docker://registry.fedoraproject.org/fedora:latest | jq &#039;.Digest&#039;
&quot;sha256:655721ff613ee766a4126cb5e0d5ae81598e1b0c3bcf7017c36c4d72cb092fe9&quot;
```

## Copying images

`skopeo` can copy container images between various storage mechanisms, including:
* Container registries

  -  The Quay, Docker Hub, OpenShift, GCR, Artifactory ...

* Container Storage backends

  -  [github.com/containers/storage](https://github.com/containers/storage) (Backend for [Podman](https://podman.io), [CRI-O](https://cri-o.io), [Buildah](https://buildah.io) and friends)

  -  Docker daemon storage

* Local directories

* Local OCI-layout directories

```console
$ skopeo copy docker://quay.io/buildah/stable docker://registry.internal.company.com/buildah
$ skopeo copy oci:busybox_ocilayout:latest dir:existingemptydirectory
```

## Deleting images
```console
$ skopeo delete docker://localhost:5000/imagename:latest
```

## Syncing registries
```console
$ skopeo sync --src docker --dest dir registry.example.com/busybox /media/usb
```

## Authenticating to a registry

#### Private registries with authentication
skopeo uses credentials from the --creds (for skopeo inspect|delete) or --src-creds|--dest-creds (for skopeo copy) flags, if set; otherwise it uses configuration set by skopeo login, podman login, buildah login, or docker login.

```console
$ skopeo login --username USER myregistrydomain.com:5000
Password:
$ skopeo inspect docker://myregistrydomain.com:5000/busybox
{&quot;Tag&quot;:&quot;latest&quot;,&quot;Digest&quot;:&quot;sha256:473bb2189d7b913ed7187a33d11e743fdc2f88931122a44d91a301b64419f092&quot;,&quot;RepoTags&quot;:[&quot;latest&quot;],&quot;Comment&quot;:&quot;&quot;,&quot;Created&quot;:&quot;2016-01-15T18:06:41.282540103Z&quot;,&quot;ContainerConfig&quot;:{&quot;Hostname&quot;:&quot;aded96b43f48&quot;,&quot;Domainname&quot;:&quot;&quot;,&quot;User&quot;:&quot;&quot;,&quot;AttachStdin&quot;:false,&quot;AttachStdout&quot;:false,&quot;AttachStderr&quot;:false,&quot;Tty&quot;:false,&quot;OpenStdin&quot;:false,&quot;StdinOnce&quot;:false,&quot;Env&quot;:null,&quot;Cmd&quot;:[&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;#(nop) CMD [\&quot;sh\&quot;]&quot;],&quot;Image&quot;:&quot;9e77fef7a1c9f989988c06620dabc4020c607885b959a2cbd7c2283c91da3e33&quot;,&quot;Volumes&quot;:null,&quot;WorkingDir&quot;:&quot;&quot;,&quot;Entrypoint&quot;:null,&quot;OnBuild&quot;:null,&quot;Labels&quot;:null},&quot;DockerVersion&quot;:&quot;1.8.3&quot;,&quot;Author&quot;:&quot;&quot;,&quot;Config&quot;:{&quot;Hostname&quot;:&quot;aded96b43f48&quot;,&quot;Domainname&quot;:&quot;&quot;,&quot;User&quot;:&quot;&quot;,&quot;AttachStdin&quot;:false,&quot;AttachStdout&quot;:false,&quot;AttachStderr&quot;:false,&quot;Tty&quot;:false,&quot;OpenStdin&quot;:false,&quot;StdinOnce&quot;:false,&quot;Env&quot;:null,&quot;Cmd&quot;:[&quot;sh&quot;],&quot;Image&quot;:&quot;9e77fef7a1c9f989988c06620dabc4020c607885b959a2cbd7c2283c91da3e33&quot;,&quot;Volumes&quot;:null,&quot;WorkingDir&quot;:&quot;&quot;,&quot;Entrypoint&quot;:null,&quot;OnBuild&quot;:null,&quot;Labels&quot;:null},&quot;Architecture&quot;:&quot;amd64&quot;,&quot;Os&quot;:&quot;linux&quot;}
$ skopeo logout myregistrydomain.com:5000
```

#### Using --creds directly

```console
$ skopeo inspect --creds=testuser:testpassword docker://myregistrydomain.com:5000/busybox
{&quot;Tag&quot;:&quot;latest&quot;,&quot;Digest&quot;:&quot;sha256:473bb2189d7b913ed7187a33d11e743fdc2f88931122a44d91a301b64419f092&quot;,&quot;RepoTags&quot;:[&quot;latest&quot;],&quot;Comment&quot;:&quot;&quot;,&quot;Created&quot;:&quot;2016-01-15T18:06:41.282540103Z&quot;,&quot;ContainerConfig&quot;:{&quot;Hostname&quot;:&quot;aded96b43f48&quot;,&quot;Domainname&quot;:&quot;&quot;,&quot;User&quot;:&quot;&quot;,&quot;AttachStdin&quot;:false,&quot;AttachStdout&quot;:false,&quot;AttachStderr&quot;:false,&quot;Tty&quot;:false,&quot;OpenStdin&quot;:false,&quot;StdinOnce&quot;:false,&quot;Env&quot;:null,&quot;Cmd&quot;:[&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;#(nop) CMD [\&quot;sh\&quot;]&quot;],&quot;Image&quot;:&quot;9e77fef7a1c9f989988c06620dabc4020c607885b959a2cbd7c2283c91da3e33&quot;,&quot;Volumes&quot;:null,&quot;WorkingDir&quot;:&quot;&quot;,&quot;Entrypoint&quot;:null,&quot;OnBuild&quot;:null,&quot;Labels&quot;:null},&quot;DockerVersion&quot;:&quot;1.8.3&quot;,&quot;Author&quot;:&quot;&quot;,&quot;Config&quot;:{&quot;Hostname&quot;:&quot;aded96b43f48&quot;,&quot;Domainname&quot;:&quot;&quot;,&quot;User&quot;:&quot;&quot;,&quot;AttachStdin&quot;:false,&quot;AttachStdout&quot;:false,&quot;AttachStderr&quot;:false,&quot;Tty&quot;:false,&quot;OpenStdin&quot;:false,&quot;StdinOnce&quot;:false,&quot;Env&quot;:null,&quot;Cmd&quot;:[&quot;sh&quot;],&quot;Image&quot;:&quot;9e77fef7a1c9f989988c06620dabc4020c607885b959a2cbd7c2283c91da3e33&quot;,&quot;Volumes&quot;:null,&quot;WorkingDir&quot;:&quot;&quot;,&quot;Entrypoint&quot;:null,&quot;OnBuild&quot;:null,&quot;Labels&quot;:null},&quot;Architecture&quot;:&quot;amd64&quot;,&quot;Os&quot;:&quot;linux&quot;}
```

```console
$ skopeo copy --src-creds=testuser:testpassword docker://myregistrydomain.com:5000/private oci:local_oci_image
```

Contributing
-

Please read the [contribution guide](CONTRIBUTING.md) if you want to collaborate in the project.

## Commands
| Command                                            | Description                                                                                  |
| -------------------------------------------------- | ---------------------------------------------------------------------------------------------|
| [skopeo-copy(1)](/docs/skopeo-copy.1.md)           | Copy an image (manifest, filesystem layers, signatures) from one location to another.        |
| [skopeo-delete(1)](/docs/skopeo-delete.1.md)       | Mark the image-name for later deletion by the registry&#039;s garbage collector.                                                                |
| [skopeo-generate-sigstore-key(1)](/docs/skopeo-generate-sigstore-key.1.md)    | Generate a sigstore public/private key pair.  |
| [skopeo-inspect(1)](/docs/skopeo-inspect.1.md)     | Return  low-level  information about image-name in a registry.                                |
| [skopeo-list-tags(1)](/docs/skopeo-list-tags.1.md) | Return a list of tags for the transport-specific image repository.                               |
| [skopeo-login(1)](/docs/skopeo-login.1.md)         | Login to a container registry.                                                               |
| [skopeo-logout(1)](/docs/skopeo-logout.1.md)       | Logout of a container registry.                                                              |
| [skopeo-manifest-digest(1)](/docs/skopeo-manifest-digest.1.md)    | Compute a manifest digest for a manifest-file and write it to standard output.   |
| [skopeo-standalone-sign(1)](/docs/skopeo-standalone-sign.1.md)    | Debugging tool - Sign an image locally without uploading.                     |
| [skopeo-standalone-verify(1)](/docs/skopeo-standalone-verify.1.md)| Debugging tool - Verify an image signature from local files.                  |
| [skopeo-sync(1)](/docs/skopeo-sync.1.md)           | Synchronize images between registry repositories and local directories.                      |

License
-
skopeo is licensed under the Apache License, Version 2.0. See
[LICENSE](LICENSE) for the full license text.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gruntwork-io/terragrunt]]></title>
            <link>https://github.com/gruntwork-io/terragrunt</link>
            <guid>https://github.com/gruntwork-io/terragrunt</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in OpenTofu/Terraform to scale.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gruntwork-io/terragrunt">gruntwork-io/terragrunt</a></h1>
            <p>Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in OpenTofu/Terraform to scale.</p>
            <p>Language: Go</p>
            <p>Stars: 9,078</p>
            <p>Forks: 1,111</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># Terragrunt

[![Maintained by Gruntwork.io](https://img.shields.io/badge/maintained%20by-gruntwork.io-%235849a6.svg)](https://gruntwork.io/?ref=repo_terragrunt)
[![Go Report Card](https://goreportcard.com/badge/github.com/gruntwork-io/terragrunt)](https://goreportcard.com/report/github.com/gruntwork-io/terragrunt)
[![GoDoc](https://godoc.org/github.com/gruntwork-io/terragrunt?status.svg)](https://godoc.org/github.com/gruntwork-io/terragrunt)
![OpenTofu Version](https://img.shields.io/badge/tofu-%3E%3D1.6.0-blue.svg)
![Terraform Version](https://img.shields.io/badge/tf-%3E%3D0.12.0-blue.svg)

Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in [OpenTofu](https://opentofu.org)/[Terraform](https://www.terraform.io) to scale.

Please see the following for more info, including install instructions and complete documentation:

* [Terragrunt Website](https://terragrunt.gruntwork.io)
* [Getting started with Terragrunt](https://terragrunt.gruntwork.io/docs/getting-started/quick-start/)
* [Terragrunt Documentation](https://terragrunt.gruntwork.io/docs)
* [Contributing to Terragrunt](https://terragrunt.gruntwork.io/docs/community/contributing)
* [Commercial Support](https://gruntwork.io/support/)

## Join the Discord!

Join [our community](https://discord.gg/YENaT9h8jh) for discussions, support, and contributions:

[![](https://dcbadge.limes.pink/api/server/https://discord.gg/YENaT9h8jh)](https://discord.gg/YENaT9h8jh)

## License

This code is released under the MIT License. See [LICENSE.txt](LICENSE.txt).

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ava-labs/avalanchego]]></title>
            <link>https://github.com/ava-labs/avalanchego</link>
            <guid>https://github.com/ava-labs/avalanchego</guid>
            <pubDate>Sat, 08 Nov 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[Go implementation of an Avalanche node.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ava-labs/avalanchego">ava-labs/avalanchego</a></h1>
            <p>Go implementation of an Avalanche node.</p>
            <p>Language: Go</p>
            <p>Stars: 2,311</p>
            <p>Forks: 818</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;resources/AvalancheLogoRed.png?raw=true&quot;&gt;
&lt;/div&gt;

---

Node implementation for the [Avalanche](https://avax.network) network -
a blockchains platform with high throughput, and blazing fast transactions.

## Installation

Avalanche is an incredibly lightweight protocol, so the minimum computer requirements are quite modest.
Note that as network usage increases, hardware requirements may change.

The minimum recommended hardware specification for nodes connected to Mainnet is:

- CPU: Equivalent of 8 AWS vCPU
- RAM: 16 GiB
- Storage: 1 TiB
  - Nodes running for very long periods of time or nodes with custom configurations may observe higher storage requirements.
- OS: Ubuntu 22.04/24.04 or macOS &gt;= 12
- Network: Reliable IPv4 or IPv6 network connection, with an open public port.

If you plan to build AvalancheGo from source, you will also need the following software:

- [Go](https://golang.org/doc/install) version &gt;= 1.24.9
- [gcc](https://gcc.gnu.org/)
- g++

### Building From Source

#### Clone The Repository

Clone the AvalancheGo repository:

```sh
git clone git@github.com:ava-labs/avalanchego.git
cd avalanchego
```

This will clone and checkout the `master` branch.

#### Building AvalancheGo

Build AvalancheGo by running the build task:

```sh
./scripts/run_task.sh build
```

The `avalanchego` binary is now in the `build` directory. To run:

```sh
./build/avalanchego
```

### Binary Repository

Install AvalancheGo using an `apt` repository.

#### Adding the APT Repository

If you already have the APT repository added, you do not need to add it again.

To add the repository on Ubuntu, run:

```sh
sudo su -
wget -qO - https://downloads.avax.network/avalanchego.gpg.key | tee /etc/apt/trusted.gpg.d/avalanchego.asc
source /etc/os-release &amp;&amp; echo &quot;deb https://downloads.avax.network/apt $UBUNTU_CODENAME main&quot; &gt; /etc/apt/sources.list.d/avalanche.list
exit
```

#### Installing the Latest Version

After adding the APT repository, install `avalanchego` by running:

```sh
sudo apt update
sudo apt install avalanchego
```

### Binary Install

Download the [latest build](https://github.com/ava-labs/avalanchego/releases/latest) for your operating system and architecture.

The Avalanche binary to be executed is named `avalanchego`.

### Docker Install

Make sure Docker is installed on the machine - so commands like `docker run` etc. are available.

Building the Docker image of latest `avalanchego` branch can be done by running:

```sh
./scripts/run-task.sh build-image
```

To check the built image, run:

```sh
docker image ls
```

The image should be tagged as `avaplatform/avalanchego:xxxxxxxx`, where `xxxxxxxx` is the shortened commit of the Avalanche source it was built from. To run the Avalanche node, run:

```sh
docker run -ti -p 9650:9650 -p 9651:9651 avaplatform/avalanchego:xxxxxxxx /avalanchego/build/avalanchego
```

## Running Avalanche

### Connecting to Mainnet

To connect to the Avalanche Mainnet, run:

```sh
./build/avalanchego
```

You should see some pretty ASCII art and log messages.

You can use `Ctrl+C` to kill the node.

### Connecting to Fuji

To connect to the Fuji Testnet, run:

```sh
./build/avalanchego --network-id=fuji
```

### Creating a Local Testnet

The [avalanche-cli](https://github.com/ava-labs/avalanche-cli) is the easiest way to start a local network.

```sh
avalanche network start
avalanche network status
```

## Bootstrapping

A node needs to catch up to the latest network state before it can participate in consensus and serve API calls. This process (called bootstrapping) currently takes several days for a new node connected to Mainnet.

A node will not [report healthy](https://build.avax.network/docs/api-reference/health-api) until it is done bootstrapping.

Improvements that reduce the amount of time it takes to bootstrap are under development.

The bottleneck during bootstrapping is typically database IO. Using a more powerful CPU or increasing the database IOPS on the computer running a node will decrease the amount of time bootstrapping takes.

## Generating Code

AvalancheGo uses multiple tools to generate efficient and boilerplate code.

### Running protobuf codegen

To regenerate the protobuf go code, run `scripts/run-task.sh generate-protobuf` from the root of the repo.

This should only be necessary when upgrading protobuf versions or modifying .proto definition files.

To use this script, you must have [buf](https://docs.buf.build/installation) (v1.31.0), protoc-gen-go (v1.33.0) and protoc-gen-go-grpc (v1.3.0) installed.

To install the buf dependencies:

```sh
go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.33.0
go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.3.0
```

If you have not already, you may need to add `$GOPATH/bin` to your `$PATH`:

```sh
export PATH=&quot;$PATH:$(go env GOPATH)/bin&quot;
```

If you extract buf to ~/software/buf/bin, the following should work:

```sh
export PATH=$PATH:~/software/buf/bin/:~/go/bin
go get google.golang.org/protobuf/cmd/protoc-gen-go
go get google.golang.org/protobuf/cmd/protoc-gen-go-grpc
scripts/run_task.sh generate-protobuf
```

For more information, refer to the [GRPC Golang Quick Start Guide](https://grpc.io/docs/languages/go/quickstart/).

### Running mock codegen

See [the Contributing document autogenerated mocks section](CONTRIBUTING.md####Autogenerated-mocks).

## Versioning

### Version Semantics

AvalancheGo is first and foremost a client for the Avalanche network. The versioning of AvalancheGo follows that of the Avalanche network.

- `v0.x.x` indicates a development network version.
- `v1.x.x` indicates a production network version.
- `vx.[Upgrade].x` indicates the number of network upgrades that have occurred.
- `vx.x.[Patch]` indicates the number of client upgrades that have occurred since the last network upgrade.

### Library Compatibility Guarantees

Because AvalancheGo&#039;s version denotes the network version, it is expected that interfaces exported by AvalancheGo&#039;s packages may change in `Patch` version updates.

### API Compatibility Guarantees

APIs exposed when running AvalancheGo will maintain backwards compatibility, unless the functionality is explicitly deprecated and announced when removed.

## Supported Platforms

AvalancheGo can run on different platforms, with different support tiers:

- **Tier 1**: Fully supported by the maintainers, guaranteed to pass all tests including e2e and stress tests.
- **Tier 2**: Passes all unit and integration tests but not necessarily e2e tests.
- **Tier 3**: Builds but lightly tested (or not), considered _experimental_.
- **Not supported**: May not build and not tested, considered _unsafe_. To be supported in the future.

The following table lists currently supported platforms and their corresponding
AvalancheGo support tiers:

| Architecture | Operating system | Support tier  |
| :----------: | :--------------: | :-----------: |
|    amd64     |      Linux       |       1       |
|    arm64     |      Linux       |       2       |
|    arm64     |      Darwin      |       2       |
|    amd64     |      Darwin      | Not supported |
|    amd64     |     Windows      | Not supported |
|     arm      |      Linux       | Not supported |
|     i386     |      Linux       | Not supported |

To officially support a new platform, one must satisfy the following requirements:

| AvalancheGo continuous integration | Tier 1  | Tier 2  | Tier 3  |
| ---------------------------------- | :-----: | :-----: | :-----: |
| Build passes                       | &amp;check; | &amp;check; | &amp;check; |
| Unit and integration tests pass    | &amp;check; | &amp;check; |         |
| End-to-end and stress tests pass   | &amp;check; |         |         |

## Security Bugs

**We and our community welcome responsible disclosures.**

Please refer to our [Security Policy](SECURITY.md) and [Security Advisories](https://github.com/ava-labs/avalanchego/security/advisories).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>