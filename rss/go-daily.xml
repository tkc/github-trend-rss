<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Fri, 05 Sep 2025 00:05:12 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[aquasecurity/trivy]]></title>
            <link>https://github.com/aquasecurity/trivy</link>
            <guid>https://github.com/aquasecurity/trivy</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aquasecurity/trivy">aquasecurity/trivy</a></h1>
            <p>Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more</p>
            <p>Language: Go</p>
            <p>Stars: 28,358</p>
            <p>Forks: 2,712</p>
            <p>Stars today: 175 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;docs/imgs/logo.png&quot; width=&quot;200&quot;&gt;

[![GitHub Release][release-img]][release]
[![Test][test-img]][test]
[![Go Report Card][go-report-img]][go-report]
[![License: Apache-2.0][license-img]][license]
[![GitHub Downloads][github-downloads-img]][release]
![Docker Pulls][docker-pulls]

[üìñ Documentation][docs]
&lt;/div&gt;

Trivy ([pronunciation][pronunciation]) is a comprehensive and versatile security scanner.
Trivy has *scanners* that look for security issues, and *targets* where it can find those issues.

Targets (what Trivy can scan):

- Container Image
- Filesystem
- Git Repository (remote)
- Virtual Machine Image
- Kubernetes

Scanners (what Trivy can find there):

- OS packages and software dependencies in use (SBOM)
- Known vulnerabilities (CVEs)
- IaC issues and misconfigurations
- Sensitive information and secrets
- Software licenses

Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the [Scanning Coverage] page.

To learn more, go to the [Trivy homepage][homepage] for feature highlights, or to the [Documentation site][docs] for detailed information.

## Quick Start

### Get Trivy

Trivy is available in most common distribution channels. The full list of installation options is available in the [Installation] page. Here are a few popular examples:

- `brew install trivy`
- `docker run aquasec/trivy`
- Download binary from &lt;https://github.com/aquasecurity/trivy/releases/latest/&gt;
- See [Installation] for more

Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the [Ecosystem] page. Here are a few popular examples:

- [GitHub Actions](https://github.com/aquasecurity/trivy-action)
- [Kubernetes operator](https://github.com/aquasecurity/trivy-operator)
- [VS Code plugin](https://github.com/aquasecurity/trivy-vscode-extension)
- See [Ecosystem] for more

### Canary builds
There are canary builds ([Docker Hub](https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;name=canary), [GitHub](https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary), [ECR](https://gallery.ecr.aws/aquasecurity/trivy#canary) images and [binaries](https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml)) as generated every push to main branch.

Please be aware: canary builds might have critical bugs, it&#039;s not recommended for use in production.

### General usage

```bash
trivy &lt;target&gt; [--scanners &lt;scanner1,scanner2&gt;] &lt;subject&gt;
```

Examples:

```bash
trivy image python:3.4-alpine
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov

&lt;/details&gt;

```bash
trivy fs --scanners vuln,secret,misconfig myproject/
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov

&lt;/details&gt;

```bash
trivy k8s --report summary cluster
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

![k8s summary](docs/imgs/trivy-k8s.png)

&lt;/details&gt;

## FAQ

### How to pronounce the name &quot;Trivy&quot;?

`tri` is pronounced like **tri**gger, `vy` is pronounced like en**vy**.

## Want more? Check out Aqua

If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.  
You can find a high level comparison table specific to Trivy users [here](https://trivy.dev/latest/commercial/compare/).
In addition check out the &lt;https://aquasec.com&gt; website for more information about our products and services.
If you&#039;d like to contact Aqua or request a demo, please use this form: &lt;https://www.aquasec.com/demo&gt;

## Community

Trivy is an [Aqua Security][aquasec] open source project.  
Learn about our open source work and portfolio [here][oss].  
Contact us about any matter by opening a GitHub Discussion [here][discussions]

Please ensure to abide by our [Code of Conduct][code-of-conduct] during all interactions.

[test]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml
[test-img]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg
[go-report]: https://goreportcard.com/report/github.com/aquasecurity/trivy
[go-report-img]: https://goreportcard.com/badge/github.com/aquasecurity/trivy
[release]: https://github.com/aquasecurity/trivy/releases
[release-img]: https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github
[github-downloads-img]: https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github
[docker-pulls]: https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;label=docker%20pulls%20%2F%20trivy
[license]: https://github.com/aquasecurity/trivy/blob/main/LICENSE
[license-img]: https://img.shields.io/badge/License-Apache%202.0-blue.svg
[homepage]: https://trivy.dev
[docs]: https://trivy.dev/latest/docs/
[pronunciation]: #how-to-pronounce-the-name-trivy
[code-of-conduct]: https://github.com/aquasecurity/community/blob/main/CODE_OF_CONDUCT.md

[Installation]:https://trivy.dev/latest/getting-started/installation/
[Ecosystem]: https://trivy.dev/latest/ecosystem/
[Scanning Coverage]: https://trivy.dev/latest/docs/coverage/

[alpine]: https://ariadne.space/2021/06/08/the-vulnerability-remediation-lifecycle-of-alpine-containers/
[rego]: https://www.openpolicyagent.org/docs/latest/#rego
[sigstore]: https://www.sigstore.dev/

[aquasec]: https://aquasec.com
[oss]: https://www.aquasec.com/products/open-source-projects/
[discussions]: https://github.com/aquasecurity/trivy/discussions
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[trufflesecurity/trufflehog]]></title>
            <link>https://github.com/trufflesecurity/trufflehog</link>
            <guid>https://github.com/trufflesecurity/trufflehog</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[Find, verify, and analyze leaked credentials]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/trufflesecurity/trufflehog">trufflesecurity/trufflehog</a></h1>
            <p>Find, verify, and analyze leaked credentials</p>
            <p>Language: Go</p>
            <p>Stars: 20,554</p>
            <p>Forks: 1,974</p>
            <p>Stars today: 53 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;GoReleaser Logo&quot; src=&quot;https://storage.googleapis.com/trufflehog-static-sources/pixel_pig.png&quot; height=&quot;140&quot; /&gt;
  &lt;h2 align=&quot;center&quot;&gt;TruffleHog&lt;/h2&gt;
  &lt;p align=&quot;center&quot;&gt;Find leaked credentials.&lt;/p&gt;
&lt;/p&gt;

---

&lt;div align=&quot;center&quot;&gt;

[![Go Report Card](https://goreportcard.com/badge/github.com/trufflesecurity/trufflehog/v3)](https://goreportcard.com/report/github.com/trufflesecurity/trufflehog/v3)
[![License](https://img.shields.io/badge/license-AGPL--3.0-brightgreen)](/LICENSE)
[![Total Detectors](https://img.shields.io/github/directory-file-count/trufflesecurity/truffleHog/pkg/detectors?label=Total%20Detectors&amp;type=dir)](/pkg/detectors)

&lt;/div&gt;

---

# :mag_right: _Now Scanning_

&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;assets/scanning_logos.svg&quot;&gt;

**...and more**

To learn more about TruffleHog and its features and capabilities, visit our [product page](https://trufflesecurity.com/trufflehog?gclid=CjwKCAjwouexBhAuEiwAtW_Zx5IW87JNj97Ci7heFnA5ar6-DuNzT2Y5nIl9DuZ-FOUqx0Qg3vb9nxoClcEQAvD_BwE).

&lt;/div&gt;

# :globe_with_meridians: TruffleHog Enterprise

Are you interested in continuously monitoring **Git, Jira, Slack, Confluence, Microsoft Teams, Sharepoint, and more..** for credentials? We have an enterprise product that can help! Learn more at &lt;https://trufflesecurity.com/trufflehog-enterprise&gt;.

We take the revenue from the enterprise product to fund more awesome open source projects that the whole community can benefit from.

&lt;/div&gt;

# What is TruffleHog üêΩ

TruffleHog is the most powerful secrets **Discovery, Classification, Validation,** and **Analysis** tool. In this context, secret refers to a credential a machine uses to authenticate itself to another machine. This includes API keys, database passwords, private encryption keys, and more...

## Discovery üîç

TruffleHog can look for secrets in many places including Git, chats, wikis, logs, API testing platforms, object stores, filesystems and more

## Classification üìÅ

TruffleHog classifies over 800 secret types, mapping them back to the specific identity they belong to. Is it an AWS secret? Stripe secret? Cloudflare secret? Postgres password? SSL Private key? Sometimes it&#039;s hard to tell looking at it, so TruffleHog classifies everything it finds.

## Validation ‚úÖ

For every secret TruffleHog can classify, it can also log in to confirm if that secret is live or not. This step is critical to know if there‚Äôs an active present danger or not.

## Analysis üî¨

For the 20 some of the most commonly leaked out credential types, instead of sending one request to check if the secret can log in, TruffleHog can send many requests to learn everything there is to know about the secret. Who created it? What resources can it access? What permissions does it have on those resources?

# :loudspeaker: Join Our Community

Have questions? Feedback? Jump into Slack or Discord and hang out with us.

Join our [Slack Community](https://join.slack.com/t/trufflehog-community/shared_invite/zt-pw2qbi43-Aa86hkiimstfdKH9UCpPzQ)

Join the [Secret Scanning Discord](https://discord.gg/8Hzbrnkr7E)

# :tv: Demo

![GitHub scanning demo](https://storage.googleapis.com/truffle-demos/non-interactive.svg)

```bash
docker run --rm -it -v &quot;$PWD:/pwd&quot; trufflesecurity/trufflehog:latest github --org=trufflesecurity
```

# :floppy_disk: Installation

Several options are available for you:

### MacOS users

```bash
brew install trufflehog
```

### Docker:

&lt;sub&gt;&lt;i&gt;_Ensure Docker engine is running before executing the following commands:_&lt;/i&gt;&lt;/sub&gt;

#### &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Unix

```bash
docker run --rm -it -v &quot;$PWD:/pwd&quot; trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
```

#### &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Windows Command Prompt

```bash
docker run --rm -it -v &quot;%cd:/=\%:/pwd&quot; trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
```

#### &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Windows PowerShell

```bash
docker run --rm -it -v &quot;${PWD}:/pwd&quot; trufflesecurity/trufflehog github --repo https://github.com/trufflesecurity/test_keys
```

#### &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;M1 and M2 Mac

```bash
docker run --platform linux/arm64 --rm -it -v &quot;$PWD:/pwd&quot; trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
```

### Binary releases

```bash
Download and unpack from https://github.com/trufflesecurity/trufflehog/releases
```

### Compile from source

```bash
git clone https://github.com/trufflesecurity/trufflehog.git
cd trufflehog; go install
```

### Using installation script

```bash
curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin
```

### Using installation script, verify checksum signature (requires cosign to be installed)

```bash
curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -v -b /usr/local/bin
```

### Using installation script to install a specific version

```bash
curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin &lt;ReleaseTag like v3.56.0&gt;
```

# :closed_lock_with_key: Verifying the artifacts

Checksums are applied to all artifacts, and the resulting checksum file is signed using cosign.

You need the following tool to verify signature:

- [Cosign](https://docs.sigstore.dev/cosign/system_config/installation/)

Verification steps are as follows:

1. Download the artifact files you want, and the following files from the [releases](https://github.com/trufflesecurity/trufflehog/releases) page.

   - trufflehog\_{version}\_checksums.txt
   - trufflehog\_{version}\_checksums.txt.pem
   - trufflehog\_{version}\_checksums.txt.sig

2. Verify the signature:

   ```shell
   cosign verify-blob &lt;path to trufflehog_{version}_checksums.txt&gt; \
   --certificate &lt;path to trufflehog_{version}_checksums.txt.pem&gt; \
   --signature &lt;path to trufflehog_{version}_checksums.txt.sig&gt; \
   --certificate-identity-regexp &#039;https://github\.com/trufflesecurity/trufflehog/\.github/workflows/.+&#039; \
   --certificate-oidc-issuer &quot;https://token.actions.githubusercontent.com&quot;
   ```

3. Once the signature is confirmed as valid, you can proceed to validate that the SHA256 sums align with the downloaded artifact:

   ```shell
   sha256sum --ignore-missing -c trufflehog_{version}_checksums.txt
   ```

Replace `{version}` with the downloaded files version

Alternatively, if you are using the installation script, pass `-v` option to perform signature verification.
This requires Cosign binary to be installed prior to running the installation script.

# :rocket: Quick Start

## 1: Scan a repo for only verified secrets

Command:

```bash
trufflehog git https://github.com/trufflesecurity/test_keys --results=verified,unknown
```

Expected output:

```
üê∑üîëüê∑  TruffleHog. Unearth your secrets. üê∑üîëüê∑

Found verified result üê∑üîë
Detector Type: AWS
Decoder Type: PLAIN
Raw result: AKIAYVP4CIPPERUVIFXG
Line: 4
Commit: fbc14303ffbf8fb1c2c1914e8dda7d0121633aca
File: keys
Email: counter &lt;counter@counters-MacBook-Air.local&gt;
Repository: https://github.com/trufflesecurity/test_keys
Timestamp: 2022-06-16 10:17:40 -0700 PDT
...
```

## 2: Scan a GitHub Org for only verified secrets

```bash
trufflehog github --org=trufflesecurity --results=verified,unknown
```

## 3: Scan a GitHub Repo for only verified keys and get JSON output

Command:

```bash
trufflehog git https://github.com/trufflesecurity/test_keys --results=verified,unknown --json
```

Expected output:

```
{&quot;SourceMetadata&quot;:{&quot;Data&quot;:{&quot;Git&quot;:{&quot;commit&quot;:&quot;fbc14303ffbf8fb1c2c1914e8dda7d0121633aca&quot;,&quot;file&quot;:&quot;keys&quot;,&quot;email&quot;:&quot;counter \u003ccounter@counters-MacBook-Air.local\u003e&quot;,&quot;repository&quot;:&quot;https://github.com/trufflesecurity/test_keys&quot;,&quot;timestamp&quot;:&quot;2022-06-16 10:17:40 -0700 PDT&quot;,&quot;line&quot;:4}}},&quot;SourceID&quot;:0,&quot;SourceType&quot;:16,&quot;SourceName&quot;:&quot;trufflehog - git&quot;,&quot;DetectorType&quot;:2,&quot;DetectorName&quot;:&quot;AWS&quot;,&quot;DecoderName&quot;:&quot;PLAIN&quot;,&quot;Verified&quot;:true,&quot;Raw&quot;:&quot;AKIAYVP4CIPPERUVIFXG&quot;,&quot;Redacted&quot;:&quot;AKIAYVP4CIPPERUVIFXG&quot;,&quot;ExtraData&quot;:{&quot;account&quot;:&quot;595918472158&quot;,&quot;arn&quot;:&quot;arn:aws:iam::595918472158:user/canarytokens.com@@mirux23ppyky6hx3l6vclmhnj&quot;,&quot;user_id&quot;:&quot;AIDAYVP4CIPPJ5M54LRCY&quot;},&quot;StructuredData&quot;:null}
...
```

## 4: Scan a GitHub Repo + its Issues and Pull Requests

```bash
trufflehog github --repo=https://github.com/trufflesecurity/test_keys --issue-comments --pr-comments
```

## 5: Scan an S3 bucket for verified keys

```bash
trufflehog s3 --bucket=&lt;bucket name&gt; --results=verified,unknown
```

## 6: Scan S3 buckets using IAM Roles

```bash
trufflehog s3 --role-arn=&lt;iam role arn&gt;
```

## 7: Scan a Github Repo using SSH authentication in Docker

```bash
docker run --rm -v &quot;$HOME/.ssh:/root/.ssh:ro&quot; trufflesecurity/trufflehog:latest git ssh://github.com/trufflesecurity/test_keys
```

## 8: Scan individual files or directories

```bash
trufflehog filesystem path/to/file1.txt path/to/file2.txt path/to/dir
```

## 9: Scan a local git repo

Clone the git repo. For example [test keys](git@github.com:trufflesecurity/test_keys.git) repo.
```bash
$ git clone git@github.com:trufflesecurity/test_keys.git
```

Run trufflehog from the parent directory (outside the git repo).
```bash
$ trufflehog git file://test_keys --results=verified,unknown
```

## 10: Scan GCS buckets for verified secrets

```bash
trufflehog gcs --project-id=&lt;project-ID&gt; --cloud-environment --results=verified,unknown
```

## 11: Scan a Docker image for verified secrets

Use the `--image` flag multiple times to scan multiple images.

```bash
# to scan from a remote registry
trufflehog docker --image trufflesecurity/secrets --results=verified,unknown

# to scan from the local docker daemon
trufflehog docker --image docker://new_image:tag --results=verified,unknown

# to scan from an image saved as a tarball
trufflehog docker --image file://path_to_image.tar --results=verified,unknown
```

## 12: Scan in CI

Set the `--since-commit` flag to your default branch that people merge into (ex: &quot;main&quot;). Set the `--branch` flag to your PR&#039;s branch name (ex: &quot;feature-1&quot;). Depending on the CI/CD platform you use, this value can be pulled in dynamically (ex: [CIRCLE_BRANCH in Circle CI](https://circleci.com/docs/variables/) and [TRAVIS_PULL_REQUEST_BRANCH in Travis CI](https://docs.travis-ci.com/user/environment-variables/)). If the repo is cloned and the target branch is already checked out during the CI/CD workflow, then `--branch HEAD` should be sufficient. The `--fail` flag will return an 183 error code if valid credentials are found.

```bash
trufflehog git file://. --since-commit main --branch feature-1 --results=verified,unknown --fail
```

## 13: Scan a Postman workspace

Use the `--workspace-id`, `--collection-id`, `--environment` flags multiple times to scan multiple targets.

```bash
trufflehog postman --token=&lt;postman api token&gt; --workspace-id=&lt;workspace id&gt;
```

## 14: Scan a Jenkins server

```bash
trufflehog jenkins --url https://jenkins.example.com --username admin --password admin
```

## 15: Scan an Elasticsearch server

### Scan a Local Cluster

There are two ways to authenticate to a local cluster with TruffleHog: (1) username and password, (2) service token.

#### Connect to a local cluster with username and password

```bash
trufflehog elasticsearch --nodes 192.168.14.3 192.168.14.4 --username truffle --password hog
```

#### Connect to a local cluster with a service token

```bash
trufflehog elasticsearch --nodes 192.168.14.3 192.168.14.4 --service-token ‚ÄòAAEWVaWM...Rva2VuaSDZ‚Äô
```

### Scan an Elastic Cloud Cluster

To scan a cluster on Elastic Cloud, you‚Äôll need a Cloud ID and API key.

```bash
trufflehog elasticsearch \
  --cloud-id &#039;search-prod:dXMtY2Vx...YjM1ODNlOWFiZGRlNjI0NA==&#039; \
  --api-key &#039;MlVtVjBZ...ZSYlduYnF1djh3NG5FQQ==&#039;
```

## 16. Scan a GitHub Repository for Cross Fork Object References and Deleted Commits

The following command will enumerate deleted and hidden commits on a GitHub repository and then scan them for secrets. This is an alpha release feature.

```bash
trufflehog github-experimental --repo https://github.com/&lt;USER&gt;/&lt;REPO&gt;.git --object-discovery
```

In addition to the normal TruffleHog output, the `--object-discovery` flag creates two files in a new `$HOME/.trufflehog` directory: `valid_hidden.txt` and `invalid.txt`. These are used to track state during commit enumeration, as well as to provide users with a complete list of all hidden and deleted commits (`valid_hidden.txt`). If you&#039;d like to automatically remove these files after scanning, please add the flag `--delete-cached-data`.

**Note**: Enumerating all valid commits on a repository using this method takes between 20 minutes and a few hours, depending on the size of your repository. We added a progress bar to keep you updated on how long the enumeration will take. The actual secret scanning runs extremely fast.

For more information on Cross Fork Object References, please [read our blog post](https://trufflesecurity.com/blog/anyone-can-access-deleted-and-private-repo-data-github).

## 17. Scan Hugging Face

### Scan a Hugging Face Model, Dataset or Space

```bash
trufflehog huggingface --model &lt;model_id&gt; --space &lt;space_id&gt; --dataset &lt;dataset_id&gt;
```

### Scan all Models, Datasets and Spaces belonging to a Hugging Face Organization or User

```bash
trufflehog huggingface --org &lt;orgname&gt; --user &lt;username&gt;
```

(Optionally) When scanning an organization or user, you can skip an entire class of resources with `--skip-models`, `--skip-datasets`, `--skip-spaces` OR a particular resource with `--ignore-models &lt;model_id&gt;`, `--ignore-datasets &lt;dataset_id&gt;`, `--ignore-spaces &lt;space_id&gt;`.

### Scan Discussion and PR Comments

```bash
trufflehog huggingface --model &lt;model_id&gt; --include-discussions --include-prs
```

## 18. Scan stdin Input

```bash
aws s3 cp s3://example/gzipped/data.gz - | gunzip -c | trufflehog stdin
```

# :question: FAQ

- All I see is `üê∑üîëüê∑  TruffleHog. Unearth your secrets. üê∑üîëüê∑` and the program exits, what gives?
  - That means no secrets were detected
- Why is the scan taking a long time when I scan a GitHub org
  - Unauthenticated GitHub scans have rate limits. To improve your rate limits, include the `--token` flag with a personal access token
- It says a private key was verified, what does that mean?
  - Check out our Driftwood blog post to learn how to do this, in short we&#039;ve confirmed the key can be used live for SSH or SSL [Blog post](https://trufflesecurity.com/blog/driftwood-know-if-private-keys-are-sensitive/)
- Is there an easy way to ignore specific secrets?
  - If the scanned source [supports line numbers](https://github.com/trufflesecurity/trufflehog/blob/d6375ba92172fd830abb4247cca15e3176448c5d/pkg/engine/engine.go#L358-L365), then you can add a `trufflehog:ignore` comment on the line containing the secret to ignore that secrets.

# :newspaper: What&#039;s new in v3?

TruffleHog v3 is a complete rewrite in Go with many new powerful features.

- We&#039;ve **added over 700 credential detectors that support active verification against their respective APIs**.
- We&#039;ve also added native **support for scanning GitHub, GitLab, Docker, filesystems, S3, GCS, Circle CI and Travis CI**.
- **Instantly verify private keys** against millions of github users and **billions** of TLS certificates using our [Driftwood](https://trufflesecurity.com/blog/driftwood) technology.
- Scan binaries, documents, and other file formats
- Available as a GitHub Action and a pre-commit hook

## What is credential verification?

For every potential credential that is detected, we&#039;ve painstakingly implemented programmatic verification against the API that we think it belongs to. Verification eliminates false positives. For example, the [AWS credential detector](pkg/detectors/aws/aws.go) performs a `GetCallerIdentity` API call against the AWS API to verify if an AWS credential is active.

# :memo: Usage

TruffleHog has a sub-command for each source of data that you may want to scan:

- git
- github
- gitlab
- docker
- s3
- filesystem (files and directories)
- syslog
- circleci
- travisci
- gcs (Google Cloud Storage)
- postman
- jenkins
- elasticsearch
- stdin
- multi-scan

Each subcommand can have options that you can see with the `--help` flag provided to the sub command:

```
$ trufflehog git --help
usage: TruffleHog git [&lt;flags&gt;] &lt;uri&gt;

Find credentials in git repositories.

Flags:
  -h, --help                Show context-sensitive help (also try --help-long and --help-man).
      --log-level=0         Logging verbosity on a scale of 0 (info) to 5 (trace). Can be disabled with &quot;-1&quot;.
      --profile             Enables profiling and sets a pprof and fgprof server on :18066.
  -j, --json                Output in JSON format.
      --json-legacy         Use the pre-v3.0 JSON format. Only works with git, gitlab, and github sources.
      --github-actions      Output in GitHub Actions format.
      --concurrency=20           Number of concurrent workers.
      --no-verification     Don&#039;t verify the results.
      --results=RESULTS          Specifies which type(s) of results to output: verified, unknown, unverified, filtered_unverified. Defaults to all types.
      --allow-verification-overlap
                                 Allow verification of similar credentials across detectors
      --filter-unverified   Only output first unverified result per chunk per detector if there are more than one results.
      --filter-entropy=FILTER-ENTROPY
                                 Filter unverified results with Shannon entropy. Start with 3.0.
      --config=CONFIG            Path to configuration file.
      --print-avg-detector-time
                                 Print the average time spent on each detector.
      --no-update           Don&#039;t check for updates.
      --fail                Exit with code 183 if results are found.
      --verifier=VERIFIER ...    Set custom verification endpoints.
      --custom-verifiers-only   Only use custom verification endpoints.
      --archive-max-size=ARCHIVE-MAX-SIZE
                                 Maximum size of archive to scan. (Byte units eg. 512B, 2KB, 4MB)
      --archive-max-depth=ARCHIVE-MAX-DEPTH
                                 Maximum depth of archive to scan.
      --archive-timeout=ARCHIVE-TIMEOUT
                                 Maximum time to spend extracting an archive.
      --include-detectors=&quot;all&quot;  Comma separated list of detector types to include. Protobuf name or IDs may be used, as well as ranges.
      --exclude-detectors=EXCLUDE-DETECTORS
                                 Comma separated list of detector types to exclude. Protobuf name or IDs may be used, as well as ranges. IDs defined here take precedence over the include list.
      --version             Show application version.
  -i, --include-paths=INCLUDE-PATHS
                                 Path to file with newline separated regexes for files to include in scan.
  -x, --exclude-paths=EXCLUDE-PATHS
                                 Path to file with newline separated regexes for files to exclude in scan.
      --exclude-globs=EXCLUDE-GLOBS
                                 Comma separated list of globs to exclude in scan. This option filters at the `git log` level, resulting in faster scans.
      --since-commit=SINCE-COMMIT
                                 Commit to start scan from.
      --branch=BRANCH            Branch to scan.
      --max-depth=MAX-DEPTH      Maximum depth of commits to scan.
      --bare                Scan bare repository (e.g. useful while using in pre-receive hooks)

Args:
  &lt;uri&gt;  Git repository URL. https://, file://, or ssh:// schema expected.
```

For example, to scan a `git` repository, start with

```
trufflehog git https://github.com/trufflesecurity/trufflehog.git
```

## Configuration

TruffleHog supports defining [custom regex detectors](#regex-detector-alpha)
and multiple sources in a configuration file provided via the `--config` flag.
The regex 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[pocketbase/pocketbase]]></title>
            <link>https://github.com/pocketbase/pocketbase</link>
            <guid>https://github.com/pocketbase/pocketbase</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[Open Source realtime backend in 1 file]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pocketbase/pocketbase">pocketbase/pocketbase</a></h1>
            <p>Open Source realtime backend in 1 file</p>
            <p>Language: Go</p>
            <p>Stars: 50,419</p>
            <p>Forks: 2,611</p>
            <p>Stars today: 77 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://pocketbase.io&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
        &lt;img src=&quot;https://i.imgur.com/5qimnm5.png&quot; alt=&quot;PocketBase - open source backend in 1 file&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/pocketbase/pocketbase/actions/workflows/release.yaml&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img src=&quot;https://github.com/pocketbase/pocketbase/actions/workflows/release.yaml/badge.svg&quot; alt=&quot;build&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/pocketbase/pocketbase/releases&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/pocketbase/pocketbase.svg&quot; alt=&quot;Latest releases&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://pkg.go.dev/github.com/pocketbase/pocketbase&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img src=&quot;https://godoc.org/github.com/pocketbase/pocketbase?status.svg&quot; alt=&quot;Go package documentation&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

[PocketBase](https://pocketbase.io) is an open source Go backend that includes:

- embedded database (_SQLite_) with **realtime subscriptions**
- built-in **files and users management**
- convenient **Admin dashboard UI**
- and simple **REST-ish API**

**For documentation and examples, please visit https://pocketbase.io/docs.**

&gt; [!WARNING]
&gt; Please keep in mind that PocketBase is still under active development
&gt; and therefore full backward compatibility is not guaranteed before reaching v1.0.0.

## API SDK clients

The easiest way to interact with the PocketBase Web APIs is to use one of the official SDK clients:

- **JavaScript - [pocketbase/js-sdk](https://github.com/pocketbase/js-sdk)** (_Browser, Node.js, React Native_)
- **Dart - [pocketbase/dart-sdk](https://github.com/pocketbase/dart-sdk)** (_Web, Mobile, Desktop, CLI_)

You could also check the recommendations in https://pocketbase.io/docs/how-to-use/.


## Overview

### Use as standalone app

You could download the prebuilt executable for your platform from the [Releases page](https://github.com/pocketbase/pocketbase/releases).
Once downloaded, extract the archive and run `./pocketbase serve` in the extracted directory.

The prebuilt executables are based on the [`examples/base/main.go` file](https://github.com/pocketbase/pocketbase/blob/master/examples/base/main.go) and comes with the JS VM plugin enabled by default which allows to extend PocketBase with JavaScript (_for more details please refer to [Extend with JavaScript](https://pocketbase.io/docs/js-overview/)_).

### Use as a Go framework/toolkit

PocketBase is distributed as a regular Go library package which allows you to build
your own custom app specific business logic and still have a single portable executable at the end.

Here is a minimal example:

0. [Install Go 1.23+](https://go.dev/doc/install) (_if you haven&#039;t already_)

1. Create a new project directory with the following `main.go` file inside it:
    ```go
    package main

    import (
        &quot;log&quot;

        &quot;github.com/pocketbase/pocketbase&quot;
        &quot;github.com/pocketbase/pocketbase/core&quot;
    )

    func main() {
        app := pocketbase.New()

        app.OnServe().BindFunc(func(se *core.ServeEvent) error {
            // registers new &quot;GET /hello&quot; route
            se.Router.GET(&quot;/hello&quot;, func(re *core.RequestEvent) error {
                return re.String(200, &quot;Hello world!&quot;)
            })

            return se.Next()
        })

        if err := app.Start(); err != nil {
            log.Fatal(err)
        }
    }
    ```

2. To init the dependencies, run `go mod init myapp &amp;&amp; go mod tidy`.

3. To start the application, run `go run main.go serve`.

4. To build a statically linked executable, you can run `CGO_ENABLED=0 go build` and then start the created executable with `./myapp serve`.

_For more details please refer to [Extend with Go](https://pocketbase.io/docs/go-overview/)._

### Building and running the repo main.go example

To build the minimal standalone executable, like the prebuilt ones in the releases page, you can simply run `go build` inside the `examples/base` directory:

0. [Install Go 1.23+](https://go.dev/doc/install) (_if you haven&#039;t already_)
1. Clone/download the repo
2. Navigate to `examples/base`
3. Run `GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build`
   (_https://go.dev/doc/install/source#environment_)
4. Start the created executable by running `./base serve`.

Note that the supported build targets by the pure Go SQLite driver at the moment are:

```
darwin  amd64
darwin  arm64
freebsd amd64
freebsd arm64
linux   386
linux   amd64
linux   arm
linux   arm64
linux   ppc64le
linux   riscv64
linux   s390x
windows amd64
windows arm64
```

### Testing

PocketBase comes with mixed bag of unit and integration tests.
To run them, use the standard `go test` command:

```sh
go test ./...
```

Check also the [Testing guide](http://pocketbase.io/docs/testing) to learn how to write your own custom application tests.

## Security

If you discover a security vulnerability within PocketBase, please send an e-mail to **support at pocketbase.io**.

All reports will be promptly addressed and you&#039;ll be credited in the fix release notes.

## Contributing

PocketBase is free and open source project licensed under the [MIT License](LICENSE.md).
You are free to do whatever you want with it, even offering it as a paid service.

You could help continuing its development by:

- [Contribute to the source code](CONTRIBUTING.md)
- [Suggest new features and report issues](https://github.com/pocketbase/pocketbase/issues)

PRs for new OAuth2 providers, bug fixes, code optimizations and documentation improvements are more than welcome.

But please refrain creating PRs for _new features_ without previously discussing the implementation details.
PocketBase has a [roadmap](https://github.com/orgs/pocketbase/projects/2) and I try to work on issues in specific order and such PRs often come in out of nowhere and skew all initial planning with tedious back-and-forth communication.

Don&#039;t get upset if I close your PR, even if it is well executed and tested. This doesn&#039;t mean that it will never be merged.
Later we can always refer to it and/or take pieces of your implementation when the time comes to work on the issue (don&#039;t worry you&#039;ll be credited in the release notes).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cilium/cilium]]></title>
            <link>https://github.com/cilium/cilium</link>
            <guid>https://github.com/cilium/cilium</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[eBPF-based Networking, Security, and Observability]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cilium/cilium">cilium/cilium</a></h1>
            <p>eBPF-based Networking, Security, and Observability</p>
            <p>Language: Go</p>
            <p>Stars: 22,370</p>
            <p>Forks: 3,387</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[influxdata/telegraf]]></title>
            <link>https://github.com/influxdata/telegraf</link>
            <guid>https://github.com/influxdata/telegraf</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/influxdata/telegraf">influxdata/telegraf</a></h1>
            <p>Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.</p>
            <p>Language: Go</p>
            <p>Stars: 16,165</p>
            <p>Forks: 5,698</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># ![tiger](assets/TelegrafTigerSmall.png &quot;tiger&quot;) Telegraf

[![GoDoc](https://img.shields.io/badge/doc-reference-00ADD8.svg?logo=go)](https://godoc.org/github.com/influxdata/telegraf)
[![Docker pulls](https://img.shields.io/docker/pulls/library/telegraf.svg)](https://hub.docker.com/_/telegraf/)
[![Go Report Card](https://goreportcard.com/badge/github.com/influxdata/telegraf)](https://goreportcard.com/report/github.com/influxdata/telegraf)
[![Circle CI](https://circleci.com/gh/influxdata/telegraf.svg?style=svg)](https://circleci.com/gh/influxdata/telegraf)

Telegraf is an agent for collecting, processing, aggregating, and writing
metrics, logs, and other arbitrary data.

* Offers a comprehensive suite of over 300 plugins, covering a wide range of
  functionalities including system monitoring, cloud services, and message
  passing
* Enables the integration of user-defined code to collect, transform, and
  transmit data efficiently
* Compiles into a standalone static binary without any external dependencies,
  ensuring a streamlined deployment process
* Utilizes TOML for configuration, providing a user-friendly and unambiguous
  setup experience
* Developed with contributions from a diverse community of over 1,200
  contributors

Users can choose plugins from a wide range of topics, including but not limited
to:

* Devices: [OPC UA][], [Modbus][]
* Logs: [File][], [Tail][], [Directory Monitor][]
* Messaging: [AMQP][], [Kafka][], [MQTT][]
* Monitoring: [OpenTelemetry][], [Prometheus][]
* Networking: [Cisco TelemetryMDT][], [gNMI][]
* System monitoring: [CPU][], [Memory][], [Disk][], [Network][], [SMART][],
  [Docker][], [Nvidia SMI][], etc.
* Universal: [Exec][], [HTTP][], [HTTP Listener][], [SNMP][], [SQL][]
* Windows: [Event Log][], [Management Instrumentation][],
  [Performance Counters][]

## üî® Installation

For binary builds, Docker images, RPM &amp; DEB packages, and other builds of
Telegraf, please see the [install guide](/docs/INSTALL_GUIDE.md).

See the [releases documentation](/docs/RELEASES.md) for details on versioning
and when releases are made.

## üíª Usage

Users define a TOML configuration with the plugins and settings they wish to
use, then pass that configuration to Telegraf. The Telegraf agent then
collects data from inputs at each interval and sends data to outputs at each
flush interval.

For a basic walkthrough see [quick start](/docs/QUICK_START.md).

## üìñ Documentation

For a full list of documentation including tutorials, reference and other
material, start with the [/docs directory](/docs/README.md).

Additionally, each plugin has its own README that includes details about how to
configure, use, and sometimes debug or troubleshoot. Look under the
[/plugins directory](/plugins/) for specific plugins.

Here are some commonly used documents:

* [Changelog](/CHANGELOG.md)
* [Configuration](/docs/CONFIGURATION.md)
* [FAQ](/docs/FAQ.md)
* [Releases](https://github.com/influxdata/telegraf/releases)
* [Security](/SECURITY.md)

## ‚ù§Ô∏è Contribute

[![Contribute](https://img.shields.io/badge/contribute-to_telegraf-blue.svg?logo=influxdb)](https://github.com/influxdata/telegraf/blob/master/CONTRIBUTING.md)

We love our community of over 1,200 contributors! Many of the plugins included
in Telegraf were originally contributed by community members. Check out
our [contributing guide](CONTRIBUTING.md) if you are interested in helping out.
Also, join us on our [Community Slack](https://influxdata.com/slack) or
[Community Forums](https://community.influxdata.com/) if you have questions or
comments for our engineering teams.

If you are completely new to Telegraf and InfluxDB, you can also enroll for free
at [InfluxDB university](https://www.influxdata.com/university/) to take courses
to learn more.

## ‚ÑπÔ∏è Support

[![Slack](https://img.shields.io/badge/slack-join_chat-blue.svg?logo=slack)](https://www.influxdata.com/slack)
[![Forums](https://img.shields.io/badge/discourse-join_forums-blue.svg?logo=discourse)](https://community.influxdata.com/)

Please use the [Community Slack](https://influxdata.com/slack) or
[Community Forums](https://community.influxdata.com/) if you have questions or
comments for our engineering teams. GitHub issues are limited to actual issues
and feature requests only.

## üìú License

[![MIT](https://img.shields.io/badge/license-MIT-blue)](https://github.com/influxdata/telegraf/blob/master/LICENSE)

[OPC UA]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opcua
[Modbus]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/modbus
[File]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/file
[Tail]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/tail
[Directory Monitor]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/directory_monitor
[AMQP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/amqp_consumer
[Kafka]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/kafka_consumer
[MQTT]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mqtt_consumer
[OpenTelemetry]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/opentelemetry
[Prometheus]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/prometheus
[Cisco TelemetryMDT]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cisco_telemetry_mdt
[gNMI]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/gnmi
[CPU]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cpu
[Memory]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mem
[Disk]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/disk
[Network]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/net
[SMART]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/smartctl
[Docker]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker
[Nvidia SMI]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/nvidia_smi
[Exec]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/exec
[HTTP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http
[HTTP Listener]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http_listener_v2
[SNMP]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/snmp
[SQL]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/sql
[Event Log]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_eventlog
[Management Instrumentation]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_wmi
[Performance Counters]: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[sigstore/cosign]]></title>
            <link>https://github.com/sigstore/cosign</link>
            <guid>https://github.com/sigstore/cosign</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[Code signing and transparency for containers and binaries]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sigstore/cosign">sigstore/cosign</a></h1>
            <p>Code signing and transparency for containers and binaries</p>
            <p>Language: Go</p>
            <p>Stars: 5,190</p>
            <p>Forks: 620</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img style=&quot;max-width: 100%;width: 300px;&quot; src=&quot;https://raw.githubusercontent.com/sigstore/community/main/artwork/cosign/horizontal/color/sigstore_cosign-horizontal-color.svg&quot; alt=&quot;Cosign logo&quot;/&gt;
&lt;/p&gt;

# cosign

Signing OCI containers (and other artifacts) using [Sigstore](https://sigstore.dev/)!

[![Go Report Card](https://goreportcard.com/badge/github.com/sigstore/cosign)](https://goreportcard.com/report/github.com/sigstore/cosign)
[![e2e-tests](https://github.com/sigstore/cosign/actions/workflows/e2e-tests.yml/badge.svg)](https://github.com/sigstore/cosign/actions/workflows/e2e-tests.yml)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5715/badge)](https://bestpractices.coreinfrastructure.org/projects/5715)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/sigstore/cosign/badge)](https://securityscorecards.dev/viewer/?uri=github.com/sigstore/cosign)

Cosign aims to make signatures **invisible infrastructure**.

Cosign supports:

* &quot;Keyless signing&quot; with the Sigstore public good Fulcio certificate authority and Rekor transparency log (default)
* Hardware and KMS signing
* Signing with a cosign generated encrypted private/public keypair
* Container Signing, Verification and Storage in an OCI registry.
* Bring-your-own PKI

## Info

`Cosign` is developed as part of the [`sigstore`](https://sigstore.dev) project.
We also use a [slack channel](https://sigstore.slack.com)!
Click [here](https://join.slack.com/t/sigstore/shared_invite/zt-mhs55zh0-XmY3bcfWn4XEyMqUUutbUQ) for the invite link.

## Installation

For Homebrew, Arch, Nix, GitHub Action, and Kubernetes installs see the [installation docs](https://docs.sigstore.dev/cosign/system_config/installation/).

For Linux and macOS binaries see the [GitHub release assets](https://github.com/sigstore/cosign/releases/latest).

:rotating_light: If you are downloading releases of cosign from our GCS bucket - please see more information on the July 31, 2023 [deprecation notice](https://blog.sigstore.dev/cosign-releases-bucket-deprecation/) :rotating_light:

## Developer Installation

If you have Go 1.22+, you can setup a development environment:

```shell
$ git clone https://github.com/sigstore/cosign
$ cd cosign
$ go install ./cmd/cosign
$ $(go env GOPATH)/bin/cosign
```

## Contributing

If you are interested in contributing to `cosign`, please read the [contributing documentation](./CONTRIBUTING.md).

Future Cosign development will be focused the next major release which will be based on
[sigstore-go](https://github.com/sigstore/sigstore-go). Maintainers will be focused on feature development within
sigstore-go. Contributions to sigstore-go, particularly around bring-your-own keys and signing, are appreciated.
Please see the [issue tracker](https://github.com/sigstore/sigstore-go/issues) for good first issues.

Cosign 2.x is a stable release and will continue to receive periodic feature updates and bug fixes. PRs
that are small in scope and size are most likely to be quickly reviewed.

PRs which significantly modify or break the API will not be accepted. PRs which are significant in size but do not
introduce breaking changes may be accepted, but will be considered lower priority than PRs in sigstore-go.

## Dockerfile

Here is how to install and use cosign inside a Dockerfile through the ghcr.io/sigstore/cosign/cosign image:

```shell
FROM ghcr.io/sigstore/cosign/cosign:v2.4.1 as cosign-bin

# Source: https://github.com/chainguard-images/static
FROM cgr.dev/chainguard/static:latest
COPY --from=cosign-bin /ko-app/cosign /usr/local/bin/cosign
ENTRYPOINT [ &quot;cosign&quot; ]
```

## Quick Start

This shows how to:
* sign a container image with the default identity-based &quot;keyless signing&quot; method (see [the documentation for more information](https://docs.sigstore.dev/cosign/signing/overview/))
* verify the container image

### Sign a container and store the signature in the registry

Note that you should always sign images based on their digest (`@sha256:...`)
rather than a tag (`:latest`) because otherwise you might sign something you
didn&#039;t intend to!

```shell
 cosign sign $IMAGE

Generating ephemeral keys...
Retrieving signed certificate...

	Note that there may be personally identifiable information associated with this signed artifact.
	This may include the email address associated with the account with which you authenticate.
	This information will be used for signing this artifact and will be stored in public transparency logs and cannot be removed later.

By typing &#039;y&#039;, you attest that you grant (or have permission to grant) and agree to have this information stored permanently in transparency logs.
Are you sure you would like to continue? [y/N] y
Your browser will now be opened to:
https://oauth2.sigstore.dev/auth/auth?access_type=online&amp;client_id=sigstore&amp;code_challenge=OrXitVKUZm2lEWHVt1oQWR4HZvn0rSlKhLcltglYxCY&amp;code_challenge_method=S256&amp;nonce=2KvOWeTFxYfxyzHtssvlIXmY6Jk&amp;redirect_uri=http%3A%2F%2Flocalhost%3A57102%2Fauth%2Fcallback&amp;response_type=code&amp;scope=openid+email&amp;state=2KvOWfbQJ1caqScgjwibzK2qJmb
Successfully verified SCT...
tlog entry created with index: 12086900
Pushing signature to: $IMAGE
```

Cosign will prompt you to authenticate via OIDC, where you&#039;ll sign in with your email address.
Under the hood, cosign will request a code signing certificate from the Fulcio certificate authority.
The subject of the certificate will match the email address you logged in with.
Cosign will then store the signature and certificate in the Rekor transparency log, and upload the signature to the OCI registry alongside the image you&#039;re signing.


### Verify a container

To verify the image, you&#039;ll need to pass in the expected certificate subject and certificate issuer via the `--certificate-identity` and `--certificate-oidc-issuer` flags:

```
cosign verify $IMAGE --certificate-identity=$IDENTITY --certificate-oidc-issuer=$OIDC_ISSUER
```

You can also pass in a regex for the certificate identity and issuer flags, `--certificate-identity-regexp` and `--certificate-oidc-issuer-regexp`.

### Verify a container against a public key

This command returns `0` if *at least one* `cosign` formatted signature for the image is found
matching the public key.
See the detailed usage below for information and caveats on other signature formats.

Any valid payloads are printed to stdout, in json format.
Note that these signed payloads include the digest of the container image, which is how we can be
sure these &quot;detached&quot; signatures cover the correct image.

```shell
$ cosign verify --key cosign.pub $IMAGE_URI:1h
The following checks were performed on these signatures:
  - The cosign claims were validated
  - The signatures were verified against the specified public key
{&quot;Critical&quot;:{&quot;Identity&quot;:{&quot;docker-reference&quot;:&quot;&quot;},&quot;Image&quot;:{&quot;Docker-manifest-digest&quot;:&quot;sha256:87ef60f558bad79beea6425a3b28989f01dd417164150ab3baab98dcbf04def8&quot;},&quot;Type&quot;:&quot;cosign container image signature&quot;},&quot;Optional&quot;:null}
```

### Verify a container in an air-gapped environment

Cosign can do completely offline verification by verifying a [bundle](./specs/SIGNATURE_SPEC.md#properties) which is typically distributed as an annotation on the image manifest.
As long as this annotation is present, then offline verification can be done.
This bundle annotation is always included by default for keyless signing, so the default `cosign sign` functionality will include all materials needed for offline verification.

To verify an image in an air-gapped environment, the image and signatures must be available locally on the filesystem.

An image can be saved locally using `cosign save` (note, this step must be done with a network connection):

```
cosign initialize # This will pull in the latest TUF root
cosign save $IMAGE_NAME --dir ./path/to/dir
```

Now, in an air-gapped environment, this local image can be verified:

```
cosign verify --certificate-identity $CERT_IDENTITY --certificate-oidc-issuer $CERT_OIDC_ISSUER --offline --local-image ./path/to/dir
```

You&#039;ll need to pass in expected values for `$CERT_IDENTITY` and `$CERT_OIDC_ISSUER` to correctly verify this image.
If you signed with a keypair, the same command will work, assuming the public key material is present locally:

```
cosign verify --key cosign.pub --offline --local-image ./path/to/dir
```

### What ** is not ** production ready?

While parts of `cosign` are stable, we are continuing to experiment and add new features.
The following feature set is not considered stable yet, but we are committed to stabilizing it over time!

#### Formats/Specifications

While the `cosign` code for uploading, signing, retrieving, and verifying several artifact types is stable,
the format specifications for some of those types may not be considered stable yet.
Some of these are developed outside of the `cosign` project, so we are waiting for them to stabilize first.

These include:

* The SBOM specification for storing SBOMs in a container registry
* The In-Toto attestation format

## Working with Other Artifacts

OCI registries are useful for storing more than just container images!
`Cosign` also includes some utilities for publishing generic artifacts, including binaries, scripts, and configuration files using the OCI protocol.

This section shows how to leverage these for an easy-to-use, backwards-compatible artifact distribution system that integrates well with the rest of Sigstore.

See [the documentation](https://docs.sigstore.dev/cosign/signing/other_types/) for more information.

### Blobs

You can publish an artifact with `cosign upload blob`:

```shell
$ echo &quot;my first artifact&quot; &gt; artifact
$ BLOB_SUM=$(shasum -a 256 artifact | cut -d&#039; &#039; -f 1) &amp;&amp; echo &quot;$BLOB_SUM&quot;
c69d72c98b55258f9026f984e4656f0e9fd3ef024ea3fac1d7e5c7e6249f1626
$ BLOB_NAME=my-artifact-$(uuidgen | head -c 8 | tr &#039;A-Z&#039; &#039;a-z&#039;)
$ BLOB_URI=ttl.sh/$BLOB_NAME:1h

$ BLOB_URI_DIGEST=$(cosign upload blob -f artifact $BLOB_URI) &amp;&amp; echo &quot;$BLOB_URI_DIGEST&quot;
Uploading file from [artifact] to [ttl.sh/my-artifact-f42c22e0:5m] with media type [text/plain]
File [artifact] is available directly at [ttl.sh/v2/my-artifact-f42c22e0/blobs/sha256:c69d72c98b55258f9026f984e4656f0e9fd3ef024ea3fac1d7e5c7e6249f1626]
Uploaded image to:
ttl.sh/my-artifact-f42c22e0@sha256:790d47850411e902aabebc3a684eeb78fcae853d4dd6e1cc554d70db7f05f99f
```

Your users can download it from the &quot;direct&quot; url with standard tools like curl or wget:

```shell
$ curl -L ttl.sh/v2/$BLOB_NAME/blobs/sha256:$BLOB_SUM &gt; artifact-fetched
```

The digest is baked right into the URL, so they can check that as well:

```shell
$ cat artifact-fetched | shasum -a 256
c69d72c98b55258f9026f984e4656f0e9fd3ef024ea3fac1d7e5c7e6249f1626  -
```

You can sign it with the normal `cosign sign` command and flags:

```shell
$ cosign sign --key cosign.key $BLOB_URI_DIGEST
Enter password for private key:
Pushing signature to: ttl.sh/my-artifact-f42c22e0
```

As usual, make sure to reference any images you sign by their digest to make sure you don&#039;t sign the wrong thing!

#### Tekton Bundles

[Tekton](https://tekton.dev) bundles can be uploaded and managed within an OCI registry.
The specification is [here](https://tekton.dev/docs/pipelines/tekton-bundle-contracts/).
This means they can also be signed and verified with `cosign`.

Tekton Bundles can currently be uploaded with the [tkn cli](https://github.com/tektoncd/cli), but we may add this support to
`cosign` in the future.

```shell
$ tkn bundle push us.gcr.io/dlorenc-vmtest2/pipeline:latest -f task-output-image.yaml
Creating Tekton Bundle:
        - Added TaskRun:  to image

Pushed Tekton Bundle to us.gcr.io/dlorenc-vmtest2/pipeline@sha256:124e1fdee94fe5c5f902bc94da2d6e2fea243934c74e76c2368acdc8d3ac7155
$ cosign sign --key cosign.key us.gcr.io/dlorenc-vmtest2/pipeline@sha256:124e1fdee94fe5c5f902bc94da2d6e2fea243934c74e76c2368acdc8d3ac7155
Enter password for private key:
tlog entry created with index: 5086
Pushing signature to: us.gcr.io/dlorenc-vmtest2/demo:sha256-124e1fdee94fe5c5f902bc94da2d6e2fea243934c74e76c2368acdc8d3ac7155.sig
```

#### WASM

Web Assembly Modules can also be stored in an OCI registry, using this [specification](https://github.com/solo-io/wasm/tree/master/spec).

Cosign can upload these using the `cosign wasm upload` command:

```shell
$ cosign upload wasm -f hello.wasm us.gcr.io/dlorenc-vmtest2/wasm
$ cosign sign --key cosign.key us.gcr.io/dlorenc-vmtest2/wasm@sha256:9e7a511fb3130ee4641baf1adc0400bed674d4afc3f1b81bb581c3c8f613f812
Enter password for private key:
tlog entry created with index: 5198
Pushing signature to: us.gcr.io/dlorenc-vmtest2/wasm:sha256-9e7a511fb3130ee4641baf1adc0400bed674d4afc3f1b81bb581c3c8f613f812.sig
```
#### eBPF

[eBPF](https://ebpf.io) modules can also be stored in an OCI registry, using this [specification](https://github.com/solo-io/bumblebee/tree/main/spec).

The image below was built using the `bee` tool. More information can be found [here](https://github.com/solo-io/bumblebee/)

Cosign can then sign these images as they can any other OCI image.

```shell
$ bee build ./examples/tcpconnect/tcpconnect.c localhost:5000/tcpconnect:test
$ bee push localhost:5000/tcpconnect:test
$ cosign sign  --key cosign.key localhost:5000/tcpconnect@sha256:7a91c50d922925f152fec96ed1d84b7bc6b2079c169d68826f6cf307f22d40e6
Enter password for private key:
Pushing signature to: localhost:5000/tcpconnect
$ cosign verify --key cosign.pub localhost:5000/tcpconnect:test

Verification for localhost:5000/tcpconnect:test --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - The signatures were verified against the specified public key

[{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;localhost:5000/tcpconnect&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:7a91c50d922925f152fec96ed1d84b7bc6b2079c169d68826f6cf307f22d40e6&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:null}]

```

#### In-Toto Attestations

Cosign also has built-in support for [in-toto](https://in-toto.io) attestations.
The specification for these is defined [here](https://github.com/in-toto/attestation).

You can create and sign one from a local predicate file using the following commands:

```shell
$ cosign attest --predicate &lt;file&gt; --key cosign.key $IMAGE_URI_DIGEST
```

All of the standard key management systems are supported.
Payloads are signed using the DSSE signing spec, defined [here](https://github.com/secure-systems-lab/dsse).

To verify:

```shell
$ cosign verify-attestation --key cosign.pub $IMAGE_URI
```

## Detailed Usage

See the [Usage documentation](https://docs.sigstore.dev/cosign/signing/overview/) for more information.

## Hardware-based Tokens

See the [Hardware Tokens documentation](https://docs.sigstore.dev/cosign/key_management/hardware-based-tokens/) for information on how to use `cosign` with hardware.

## Registry Support

`cosign` uses [go-containerregistry](https://github.com/google/go-containerregistry) for registry
interactions, which has generally excellent compatibility, but some registries may have quirks.

Today, `cosign` has been tested and works against the following registries:

* AWS Elastic Container Registry
* GCP&#039;s Artifact Registry and Container Registry
* Docker Hub
* Azure Container Registry
* JFrog Artifactory Container Registry
* The CNCF distribution/distribution Registry
* GitLab Container Registry
* GitHub Container Registry
* The CNCF Harbor Registry
* Digital Ocean Container Registry
* Sonatype Nexus Container Registry
* Alibaba Cloud Container Registry
* Red Hat Quay Container Registry 3.6+ / Red Hat quay.io
* Elastic Container Registry
* IBM Cloud Container Registry
* Cloudsmith Container Registry
* The CNCF zot Registry
* OVHcloud Managed Private Registry

We aim for wide registry support. To `sign` images in registries which do not yet fully support [OCI media types](https://github.com/sigstore/cosign/blob/main/specs/SIGNATURE_SPEC.md), one may need to use `COSIGN_DOCKER_MEDIA_TYPES` to fall back to legacy equivalents. For example:

```shell
COSIGN_DOCKER_MEDIA_TYPES=1 cosign sign --key cosign.key legacy-registry.example.com/my/image@$DIGEST
```

Please help test and file bugs if you see issues!
Instructions can be found in the [tracking issue](https://github.com/sigstore/cosign/issues/40).

## Caveats

### Intentionally Missing Features

`cosign` only generates ECDSA-P256 keys and uses SHA256 hashes, for both ephemeral keyless signing and managed key signing.
Keys are stored in PEM-encoded PKCS8 format.
However, you can use `cosign` to store and retrieve signatures in any format, from any algorithm.

### Things That Should Probably Change

#### Payload Formats

`cosign` only supports Red Hat&#039;s [simple signing](https://www.redhat.com/en/blog/container-image-signing)
format for payloads.
That looks like:

```json
{
    &quot;critical&quot;: {
           &quot;identity&quot;: {
               &quot;docker-reference&quot;: &quot;testing/manifest&quot;
           },
           &quot;image&quot;: {
               &quot;Docker-manifest-digest&quot;: &quot;sha256:20be...fe55&quot;
           },
           &quot;type&quot;: &quot;cosign container image signature&quot;
    },
    &quot;optional&quot;: {
           &quot;creator&quot;: &quot;Bob the Builder&quot;,
           &quot;timestamp&quot;: 1458239713
    }
}
```

**Note:** This can be generated for an image reference using `cosign generate $IMAGE_URI_DIGEST`.

I&#039;m happy to switch this format to something else if it makes sense.
See https://github.com/notaryproject/nv2/issues/40 for one option.

#### Registry Details

`cosign` signatures are stored as separate objects in the OCI registry, with only a weak
reference back to the object they &quot;sign&quot;.
This means this relationship is opaque to the registry, and signatures *will not* be deleted
or garbage-collected when the image is deleted.
Similarly, they **can** easily be copied from one environment to another, but this is not
automatic.

Multiple signatures are stored in a list which is unfortunately a race condition today.
To add a signature, clients orchestrate a &quot;read-append-write&quot; operation, so the last write
will win in the case of contention.

##### Specifying Registry

`cosign` will default to storing signatures in the same repo as the image it is signing.
To specify a different repo for signatures, you can set the `COSIGN_REPOSITORY` environment variable.

This will replace the repo in the provided image like this:

```shell
$ export COSIGN_REPOSITORY=gcr.io/my-new-repo
$ cosign sign --key cosign.key $IMAGE_URI_DIGEST
```

So the signature for `gcr.io/dlorenc-vmtest2/demo` will be stored in `gcr.io/my-new-repo/demo:sha256-DIGEST.sig`.

Note: different registries might expect different formats for the &quot;repository.&quot;

* To use [GCR](https://cloud.google.com/container-registry), a registry name
  like `gcr.io/$REPO` is sufficient, as in the example above.
* To use [Artifact Registry](https://cloud.google.com/artifact-registry),
  specify a full image name like
  `$LOCATION-docker.pkg.dev/$PROJECT/$REPO/$STORAGE_IMAGE`, not just a
  repository. For example,

  ```shell
  $ export COSIGN_REPOSITORY=us-docker.pkg.dev/my-new-repo/demo
  $ cosign sign --key cosign.key $IMAGE_URI_DIGEST
  ```

  where the `sha256-DIGEST` will match the digest for
  `gcr.io/dlorenc-vmtest2/demo`. Specifying just a repo like
  `$LOCATION-docker.pkg.dev/$PROJECT/$REPO` will not work in Artifact Registry.


## Signature Specification

`cosign` is inspired by tools like [minisign](https://jedisct1.github.io/minisign/) and
[signify](https://www.openbsd.org/papers/bsdcan-signify.html).

Generated private keys are stored in PEM format.
The keys encrypted under a password using scrypt as a KDF and nacl/secretbox for encryption.

They have a PEM header of `ENCRYPTED SIGSTORE PRIVATE KEY`:

```shell
-----BEGIN ENCRYPTED SIGSTORE PRIVATE KEY-----
...
-----END ENCRYPTED SIGSTORE PRIVATE KEY-----
```

Public keys are stored on disk in PEM-encoded standard PKIX format with a header of `PUBLIC KEY`.
```
-----BEGIN PUBLIC KEY-----
MFkwEwYHKoZIzj

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[google/mangle]]></title>
            <link>https://github.com/google/mangle</link>
            <guid>https://github.com/google/mangle</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:06 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google/mangle">google/mangle</a></h1>
            <p></p>
            <p>Language: Go</p>
            <p>Stars: 2,184</p>
            <p>Forks: 102</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre># Mangle

Mangle is a programming language for deductive database programming. It
is an extension of Datalog, with various extensions like aggregation, function
calls and optional type-checking.

Deductive database programming is useful for bringing data from multiple
data sources together since it enables us to represent and query that data in
a uniform way. It can also be used to model domain knowledge, similar
to machine-readable ontology but without being restricted to binary
predicates.

Datalog is an expressive declarative language similar to relational calculus
(think SQL and relational views). Unlike relational calculus, it also supports
recursive rules and program structuring in a straightforward way.

Mangle contains Datalog as a fragment and adds extensions that make its use
more practical. Some of the good properties like guaranteed termination are
lost when such extensions are used.

The goal of Mangle as an open source project is to convey the concepts in
a way that is accessible to developers and lends itself to easy experimentation.
This repository contains an implementation of Mangle as a go library that can be
easily embedded into applications.

Check out the [docs](docs/README.md) and the
[GitHub discussions](https://github.com/google/mangle/discussions) for more
information. There is also a Q&amp;A section.

For an example how to use Mangle library in a database-like grpc service,
see the separate [Mangle demo service repo](https://github.com/burakemir/mangle-service).

This is not an officially supported Google product. 

## Table of Contents
- [Examples](#examples)
- [Building](#building)

## Examples

### Simple Queries

Imagine you were asked to spot software affected by the
[log4j vulnerability discovered in late 2021](https://www.cisa.gov/uscert/apache-log4j-vulnerability-guidance).
We want to look for projects that contain a Java archive (jar file) of
log4j that is not updated to the patched version.

```prolog
projects_with_vulnerable_log4j(P) :-
  projects(P),
  contains_jar(P, &quot;log4j&quot;, Version),
  Version != &quot;2.17.1&quot;,
  Version != &quot;2.12.4&quot;,
  Version != &quot;2.3.2&quot;.
```

This is a Mangle *rule*: conceptually, the implementation retrieve all
possible values for variables `P` and `Version` that make all the subgoals true.

Simple Mangle rules like this correspond to select-project-join relational
queries. The same query in SQL would look like this:

```sql
SELECT projects.id as P
FROM projects JOIN contains_jar ON projects.id = contains_jar.project_id
WHERE contains_jar.version NOT IN (&quot;2.17.1&quot;, &quot;2.12.4&quot;, &quot;2.3.2&quot;)
```

Unlike SQL, our Mangle rule `projects_with_vulnerable_log4j` has a name
and can be referenced in other queries.

(If translating non-recursive Datalog into SQL queries sounds interesting, you
should check out the [Logica](https://logica.dev/) open source project.)

### Aggregation

In practice, querying is rarely enough and we also need grouping and
aggregation.

```
count_projects_with_vulnerable_log4j(Num) :-
  projects_with_vulnerable_log4j(P) |&gt; do fn:group_by(), let Num = fn:Count().
```

### Recursive Queries

The example does not specify what `contains_jar` does. Here is a possible
implementation for `contains_jar` that walks a dependency graph.
This shows that Mangle rules can be recursive. 

```
contains_jar(P, Name, Version) :-
  contains_jar_directly(P, Name, Version).

contains_jar(P, Name, Version) :-
  project_depends(P, Q),
  contains_jar(Q, Name, Version).
```

The two rules correspond to two cases in which a project may &quot;contain&quot; a jar:
either directly, or through some dependency.

### Knowledge Graphs, Property Graphs

In requirements engineering, one needs to captures real world concepts in a
domain model and controlled vocabulary. Description logics use
roles to describe how concepts interact, but these relationships are always
binary. Mangle can represent binary predicates, but also arbitrary n-ary
relations. Moreover it also has support for structured data.

```
one_or_two_leg_trip(Codes, Start, Destination, Price) :-
  direct_conn(Code, Start, Destination, Price)
  |&gt; let Codes = [Code].

one_or_two_leg_trip(Codes, Start, Destination, Price) :-
  direct_conn(FirstCode, Start, Connecting, FirstLegPrice).
  direct_conn(SecondCode, Connecting, Destination, SecondLegPrice)
  |&gt; let Code = [FirstCode, SecondCode],
     let Price = fn:plus(FirstLegPrice, SecondLegPrice).

```

```mermaid
graph LR
    /zurich --&gt;|/code/ZL &lt;br /&gt; 60 CHF| /lausanne
    /zurich --&gt;|/code/ZB &lt;br /&gt; 30 CHF| /bern
    /bern --&gt;|/code/BL &lt;br /&gt; 30 CHF| /lausanne
```

## Building &amp; Testing

Get the dependencies (see [go.mod](go.mod)), build the library, run tests:

```
go get -t ./...
go build ./...
go test ./...
```

### Regenerating the parser sources

If you want to regenerate the parser sources, you need to set up ANTLR first.
This requires a Java runtime environment.

```
wget http://www.antlr.org/download/antlr-4.13.2-complete.jar
alias antlr=&#039;java -jar $PWD/antlr-4.13.2-complete.jar&#039;
antlr -Dlanguage=Go -package gen -o ./ parse/gen/Mangle.g4 -visitor
```

## Contributing

The Mangle maintainers welcome external contributions to spec, documentation
and this implementation (see [CONTRIBUTING.md](CONTRIBUTING.md)) and also other
implementations. Pull requests will be handled
[like for tensorflow](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md),
to ensure our internal usage and tests will pass. 
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[keploy/keploy]]></title>
            <link>https://github.com/keploy/keploy</link>
            <guid>https://github.com/keploy/keploy</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[Unit, API & Integration Testing Agent for Developers. Generate tests, mocks/stubs for your APIs that actually work!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/keploy/keploy">keploy/keploy</a></h1>
            <p>Unit, API & Integration Testing Agent for Developers. Generate tests, mocks/stubs for your APIs that actually work!</p>
            <p>Language: Go</p>
            <p>Stars: 10,374</p>
            <p>Forks: 1,531</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot;&gt;
  &lt;img align=&quot;center&quot; src=&quot;https://docs.keploy.io/img/keploy-logo-dark.svg?s=200&amp;v=4&quot; height=&quot;40%&quot; width=&quot;40%&quot;  alt=&quot;keploy logo&quot;/&gt;
&lt;/p&gt;
&lt;h3 align=&quot;center&quot;&gt;
&lt;b&gt;
‚ö°Ô∏è API tests faster than unit tests, from user traffic ‚ö°Ô∏è
&lt;/b&gt;
&lt;/h3 &gt;
&lt;p align=&quot;center&quot;&gt;
üåü The must-have tool for developers in the AI-Gen era üåü
&lt;/p&gt;

---

&lt;h4 align=&quot;center&quot;&gt;

   &lt;a href=&quot;https://x.com/Keployio&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/follow-%40keployio-1DA1F2?logo=X&amp;style=social&quot; alt=&quot;Keploy X!&quot; /&gt;
  &lt;/a&gt;
  
  &lt;a href=&quot;https://github.com/Keploy/Keploy/&quot;&gt;
   &lt;img src=&quot;https://img.shields.io/github/stars/keploy/keploy?color=%23EAC54F&amp;logo=github&amp;label=Help%20us%20reach%2020K%20stars!%20Now%20at:&quot; alt=&quot;Help us reach 20k stars!&quot; /&gt;
&lt;/a&gt;

  &lt;a href=&quot;https://landscape.cncf.io/?item=app-definition-and-development--continuous-integration-delivery--keploy&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/CNCF%20Landscape-5699C6?logo=cncf&amp;style=social&quot; alt=&quot;Keploy CNCF Landscape&quot; /&gt;
  &lt;/a&gt;

[![Slack](https://img.shields.io/badge/Slack-4A154B?style=for-the-badge&amp;logo=slack&amp;logoColor=white)](https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg)
[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white)](https://www.linkedin.com/company/keploy/)
[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&amp;logo=YouTube&amp;logoColor=white)](https://www.youtube.com/channel/UC6OTg7F4o0WkmNtSoob34lg)
[![X](https://img.shields.io/badge/X-%231DA1F2.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white)](https://x.com/Keployio)

&lt;a href=&quot;https://trendshift.io/repositories/3262&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/3262&quot; alt=&quot;keploy%2Fkeploy | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/h4&gt;


[Keploy](https://keploy.io) is **developer-centric** API testing tool that creates **tests along with built-in-mocks**, faster than unit tests.

Keploy not only records API calls, but also records database calls and replays them during testing, making it **easy to use, powerful, and extensible**.

&lt;img src=&quot;https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-tc.gif&quot; width=&quot;60%&quot; alt=&quot;Convert API calls to test cases&quot;/&gt;

&gt; üê∞ **Fun fact:** Keploy uses itself for testing! Check out our swanky coverage badge: [![Coverage Status](https://coveralls.io/repos/github/keploy/keploy/badge.svg?branch=main&amp;kill_cache=1)](https://coveralls.io/github/keploy/keploy?branch=main&amp;kill_cache=1) &amp;nbsp;

## üö® Here for  [Unit Test Generator](README-UnitGen.md) (ut-gen)? 
Keploy has newly launched the world&#039;s first unit test generator(ut-gen) implementation of [Meta LLM research paper](https://arxiv.org/pdf/2402.09171), it understands code semantics and generates meaningful unit tests, aiming to:

- **Automate unit test generation (UTG)**: Quickly generate comprehensive unit tests and reduce redundant manual effort.

- **Improve edge cases**: Extend and improve the scope of automated tests to cover more complex scenarios, often missed manually.

- **Boost test coverage**: As codebases grow, ensuring exhaustive coverage should become feasible, aligning with our mission.

### üìú Follow [Unit Test Generator README](README-UnitGen.md)! ‚úÖ

## üìò Documentation!
Become a Keploy pro with **[Keploy Documentation](https://keploy.io/docs/)**.

&lt;img src=&quot;https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-replay.gif&quot; width=&quot;100%&quot; alt=&quot;Record Replay Testing&quot;/&gt;

# üöÄ Quick Installation (API test generator)

Integrate Keploy by installing the agent locally. No code-changes required.

```shell
curl --silent -O -L https://keploy.io/install.sh &amp;&amp; source install.sh
```

##  üé¨ Recording Testcases

Start your app with Keploy to convert API calls as Tests and Mocks/Stubs.

```zsh
keploy record -c &quot;CMD_TO_RUN_APP&quot; 
```
For example, if you&#039;re using a simple Python app the `CMD_TO_RUN_APP` would resemble to `python main.py`, for  Golang `go run main.go`, for java `java -jar xyz.jar`, for node `npm start`..

```zsh
keploy record -c &quot;python main.py&quot;
```

## üß™ Running Tests
Shut down the databases, redis, kafka or any other services your application uses. Keploy doesn&#039;t need those during test.
```zsh
keploy test -c &quot;CMD_TO_RUN_APP&quot; --delay 10
```

## ‚úÖ Test Coverage Integration
To integrate with your unit-testing library and see combine test coverage, follow this [test-coverage guide](https://keploy.io/docs/server/sdk-installation/go/).

&gt; ####  **If You Had Fun:** Please leave a üåü star on this repo! It&#039;s free and will bring a smile. üòÑ üëè

## One-Click Setup üöÄ

Setup and run keploy quickly, with no local machine installation required:

[![GitHub Codescape](https://img.shields.io/badge/GH%20codespace-3670A0?style=for-the-badge&amp;logo=github&amp;logoColor=fff)]([https://github.dev/Sonichigo/mux-sql](https://github.dev/Sonichigo/mux-sql))

## ü§î Questions?
Reach out to us. We&#039;re here to help!

[![Slack](https://img.shields.io/badge/Slack-4A154B?style=for-the-badge&amp;logo=slack&amp;logoColor=white)](https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg)
[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white)](https://www.linkedin.com/company/keploy/)
[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&amp;logo=YouTube&amp;logoColor=white)](https://www.youtube.com/channel/UC6OTg7F4o0WkmNtSoob34lg)
[![X](https://img.shields.io/badge/X-%231DA1F2.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white)](https://x.com/Keployio)


## üåê Language Support
From Go&#039;s gopher üêπ to Python&#039;s snake üêç, we support:

![Go](https://img.shields.io/badge/go-%2300ADD8.svg?style=for-the-badge&amp;logo=go&amp;logoColor=white)
![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&amp;logo=java&amp;logoColor=white)
![NodeJS](https://img.shields.io/badge/node.js-6DA55F?style=for-the-badge&amp;logo=node.js&amp;logoColor=white)
![Rust](https://img.shields.io/badge/Rust-darkred?style=for-the-badge&amp;logo=rust&amp;logoColor=white)
![C#](https://img.shields.io/badge/csharp-purple?style=for-the-badge&amp;logo=csharp&amp;logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&amp;logo=python&amp;logoColor=ffdd54)

## ü´∞ Keploy Adopters üß°

So you and your organisation are using Keploy? That‚Äôs great. Please add yourselves to [**this list,**](https://github.com/orgs/keploy/discussions/1765) and we&#039;ll send you goodies! üíñ


We are happy and proud to have you all as part of our community! üíñ

## üé© How&#039;s the Magic Happen?
Keploy proxy captures and replays **ALL** (CRUD operations, including non-idempotent APIs) of your app&#039;s network interactions.


Take a journey to **[How Keploy Works?](https://keploy.io/docs/keploy-explained/how-keploy-works/)** to discover the tricks behind the curtain!

  ## üîß Core Features

- ‚ôªÔ∏è **Combined Test Coverage:** Merge your Keploy Tests with your fave testing libraries(JUnit, go-test, py-test, jest) to see a combined test coverage.


- ü§ñ **EBPF Instrumentation:** Keploy uses EBPF like a secret sauce to make integration code-less, language-agnostic, and oh-so-lightweight.


- üåê **CI/CD Integration:** Run tests with mocks anywhere you like‚Äîlocally on the CLI, in your CI pipeline (Jenkins, Github Actions..) , or even across a Kubernetes cluster.


- üìΩÔ∏è **Record-Replay Complex Flows:** Keploy can record and replay complex, distributed API flows as mocks and stubs. It&#039;s like having a time machine for your tests‚Äîsaving you tons of time!


- üé≠ **Multi-Purpose Mocks:** You can also use Keploy-generated Mocks, as server Tests!


üëâ **Explore the code on GitHub**: [github.com/keploy/keploy](https://github.com/keploy/keploy)


## üë®üèª‚Äçüíª Let&#039;s Build Together! üë©üèª‚Äçüíª
Whether you&#039;re a newbie coder or a wizard üßô‚Äç‚ôÄÔ∏è, your perspective is golden. Take a peek at our:

üìú [Contribution Guidelines](https://github.com/keploy/keploy/blob/main/CONTRIBUTING.md)

‚ù§Ô∏è [Code of Conduct](https://github.com/keploy/keploy/blob/main/CODE_OF_CONDUCT.md)


## üê≤ Current Limitations!
- **Unit Testing:** While Keploy is designed to run alongside unit testing frameworks (Go test, JUnit..) and can add to the overall code coverage, it still generates integration tests.
- **Production Lands**: Keploy is currently focused on generating tests for developers. These tests can be captured from any environment, but we have not tested it on high volume production environments. This would need robust deduplication to avoid too many redundant tests being captured. We do have ideas on building a robust deduplication system [#27](https://github.com/keploy/keploy/issues/27)

## ‚ú® Resources!
ü§î [FAQs](https://keploy.io/docs/keploy-explained/faq/)

üïµÔ∏è‚ÄçÔ∏è [Why Keploy](https://keploy.io/docs/keploy-explained/why-keploy/)

‚öôÔ∏è [Installation Guide](https://keploy.io/docs/application-development/)

üìñ [Contribution Guide](https://keploy.io/docs/keploy-explained/contribution-guide/)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[vllm-project/aibrix]]></title>
            <link>https://github.com/vllm-project/aibrix</link>
            <guid>https://github.com/vllm-project/aibrix</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[Cost-efficient and pluggable Infrastructure components for GenAI inference]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vllm-project/aibrix">vllm-project/aibrix</a></h1>
            <p>Cost-efficient and pluggable Infrastructure components for GenAI inference</p>
            <p>Language: Go</p>
            <p>Stars: 4,188</p>
            <p>Forks: 452</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># AIBrix

Welcome to AIBrix, an open-source initiative designed to provide essential building blocks to construct scalable GenAI inference infrastructure. AIBrix delivers a cloud-native solution optimized for deploying, managing, and scaling large language model (LLM) inference, tailored specifically to enterprise needs.


&lt;p align=&quot;center&quot;&gt;
| &lt;a href=&quot;https://aibrix.readthedocs.io/latest/&quot;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://aibrix.github.io/&quot;&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://arxiv.org/abs/2504.03648&quot;&gt;&lt;b&gt;White Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://x.com/vllm_project&quot;&gt;&lt;b&gt;Twitter/X&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://vllm-dev.slack.com/archives/C08EQ883CSV&quot;&gt;&lt;b&gt;Developer Slack&lt;/b&gt;&lt;/a&gt; |
&lt;/p&gt;

## Latest News

- **[2025-08-05]** AIBrix v0.4.0 is released. Check out the [release notes](https://github.com/vllm-project/aibrix/releases/tag/v0.4.0) and [Blog Post](https://aibrix.github.io/posts/2025-08-04-v0.4.0-release/) for more details
- **[2025-06-10]** The AIBrix team delivered a talk at KubeCon China 2025 titled [AIBrix: Cost-Effective and Scalable Kubernetes Control Plane for vLLM](https://kccncchn2025.sched.com/event/1x5im/introducing-aibrix-cost-effective-and-scalable-kubernetes-control-plane-for-vllm-jiaxin-shan-liguang-xie-bytedance), discussing how the framework optimizes vLLM deployment via Kubernetes for cost efficiency and scalability.
- **[2025-05-21]** AIBrix v0.3.0 is released. Check out the [release notes](https://github.com/vllm-project/aibrix/releases/tag/v0.3.0) and [Blog Post](https://aibrix.github.io/posts/2025-05-21-v0.3.0-release/) for more details
- **[2025-04-04]** AIBrix co-delivered a KubeCon EU 2025 keynote with Google on [LLM-Aware Load Balancing in Kubernetes: A New Era of Efficiency](https://kccnceu2025.sched.com/event/1txC7/keynote-llm-aware-load-balancing-in-kubernetes-a-new-era-of-efficiency-clayton-coleman-distinguished-engineer-google-jiaxin-shan-software-engineer-bytedance), focusing on LLM specific routing solutions.
- **[2025-03-30]** AIBrix was featured at the [ASPLOS&#039;25](http://asplos-conference.org/asplos2025/) workshop with the presentation [AIBrix: An Open-Source, Large-Scale LLM Inference Infrastructure for System Research](https://docs.google.com/presentation/d/1YDVsPFTIgGXnROGaJ1VKuDDAB4T5fzpE/edit), showcasing its architecture for efficient LLM inference in system research scenarios.
- **[2025-03-09]** AIBrix v0.2.1 is released. DeepSeek-R1 full weights deployment is supported and gateway stability has been improved! Check [Blog Post](https://aibrix.github.io/posts/2025-03-10-deepseek-r1/) for more details.
- **[2025-02-19]** AIBrix v0.2.0 is released. Check out the [release notes](https://github.com/vllm-project/aibrix/releases/tag/v0.2.0) and [Blog Post](https://aibrix.github.io/posts/2025-02-05-v0.2.0-release/) for more details.
- **[2024-11-13]** AIBrix v0.1.0 is released. Check out the [release notes](https://github.com/vllm-project/aibrix/releases/tag/v0.1.0) and [Blog Post](https://aibrix.github.io/posts/2024-11-12-v0.1.0-release/) for more details.

## Key Features

The initial release includes the following key features:

- **High-Density LoRA Management**: Streamlined support for lightweight, low-rank adaptations of models.
- **LLM Gateway and Routing**: Efficiently manage and direct traffic across multiple models and replicas.
- **LLM App-Tailored Autoscaler**: Dynamically scale inference resources based on real-time demand.
- **Unified AI Runtime**: A versatile sidecar enabling metric standardization, model downloading, and management.
- **Distributed Inference**: Scalable architecture to handle large workloads across multiple nodes.
- **Distributed KV Cache**: Enables high-capacity, cross-engine KV reuse.
- **Cost-efficient Heterogeneous Serving**: Enables mixed GPU inference to reduce costs with SLO guarantees.
- **GPU Hardware Failure Detection**: Proactive detection of GPU hardware issues.

## Architecture

![aibrix-architecture-v1](docs/source/assets/images/aibrix-architecture-v1.jpeg)


## Quick Start

To get started with AIBrix, clone this repository and follow the setup instructions in the documentation. Our comprehensive guide will help you configure and deploy your first LLM infrastructure seamlessly.

```shell
# Local Testing
git clone https://github.com/vllm-project/aibrix.git
cd aibrix

# Install nightly aibrix dependencies
kubectl apply -k config/dependency --server-side

# Install nightly aibrix components
kubectl apply -k config/default
```

Install stable distribution
```shell
# Install component dependencies
kubectl apply -f &quot;https://github.com/vllm-project/aibrix/releases/download/v0.4.0/aibrix-dependency-v0.4.0.yaml&quot; --server-side

# Install aibrix components
kubectl apply -f &quot;https://github.com/vllm-project/aibrix/releases/download/v0.4.0/aibrix-core-v0.4.0.yaml&quot;
```

## Documentation

For detailed documentation on installation, configuration, and usage, please visit our [documentation page](https://aibrix.readthedocs.io/latest/).

## Contributing

We welcome contributions from the community! Check out our [contributing guidelines](./CONTRIBUTING.md) to see how you can make a difference.

Slack Channel: [#aibrix](https://vllm-dev.slack.com/archives/C08EQ883CSV)

## License

AIBrix is licensed under the [Apache 2.0 License](LICENSE).

## Support

If you have any questions or encounter any issues, please submit an issue on our [GitHub issues page](https://github.com/vllm-project/aibrix/issues).

Thank you for choosing AIBrix for your GenAI infrastructure needs!
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[anchore/grype]]></title>
            <link>https://github.com/anchore/grype</link>
            <guid>https://github.com/anchore/grype</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[A vulnerability scanner for container images and filesystems]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anchore/grype">anchore/grype</a></h1>
            <p>A vulnerability scanner for container images and filesystems</p>
            <p>Language: Go</p>
            <p>Stars: 10,577</p>
            <p>Forks: 682</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img alt=&quot;Grype logo&quot; src=&quot;https://user-images.githubusercontent.com/5199289/136855393-d0a9eef9-ccf1-4e2b-9d7c-7aad16a567e5.png&quot; width=&quot;234&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype/actions?query=workflow%3A%22Static+Analysis+%2B+Unit+%2B+Integration%22&quot;&gt;&lt;img src=&quot;https://github.com/anchore/grype/workflows/Static%20Analysis%20+%20Unit%20+%20Integration/badge.svg&quot; alt=&quot;Static Analysis + Unit + Integration&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype/actions/workflows/validations.yaml&quot;&gt;&lt;img src=&quot;https://github.com/anchore/grype/workflows/Validations/badge.svg&quot; alt=&quot;Validations&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://goreportcard.com/report/github.com/anchore/grype&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/anchore/grype&quot; alt=&quot;Go Report Card&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype/releases/latest&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/anchore/grype.svg&quot; alt=&quot;GitHub release&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/go-mod/go-version/anchore/grype.svg&quot; alt=&quot;GitHub go.mod Go version&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &lt;br&gt;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-blue.svg&quot; alt=&quot;License: Apache-2.0&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://anchore.com/discourse&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discourse-Join-blue?logo=discourse&quot; alt=&quot;Join our Discourse&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a rel=&quot;me&quot; href=&quot;https://fosstodon.org/@grype&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Mastodon-Follow-blue?logoColor=white&amp;amp;logo=mastodon&quot; alt=&quot;Follow on Mastodon&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://scorecard.dev/viewer/?uri=github.com/anchore/grype&quot;&gt;&lt;img src=&quot;https://api.securityscorecards.dev/projects/github.com/anchore/grype/badge&quot; alt=&quot;OpenSSF Scorecard&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://www.bestpractices.dev/projects/6708&quot;&gt;&lt;img src=&quot;https://www.bestpractices.dev/projects/6708/badge&quot; alt=&quot;OpenSSF Best Practices&quot;&gt;&lt;/a&gt;&amp;nbsp;
&lt;p&gt;

A vulnerability scanner for container images and filesystems. Easily [install the binary](#installation) to try it out. Works with [Syft](https://github.com/anchore/syft), the powerful SBOM (software bill of materials) tool for container images and filesystems.

### Join our community meetings!

- Calendar: https://calendar.google.com/calendar/u/0/r?cid=Y182OTM4dGt0MjRtajI0NnNzOThiaGtnM29qNEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t
- Agenda: https://docs.google.com/document/d/1ZtSAa6fj2a6KRWviTn3WoJm09edvrNUp4Iz_dOjjyY8/edit?usp=sharing (join [this group](https://groups.google.com/g/anchore-oss-community) for write access)
- All are welcome!

For commercial support options with Syft or Grype, please [contact Anchore](https://get.anchore.com/contact/).

![grype-demo](https://user-images.githubusercontent.com/590471/90276236-9868f300-de31-11ea-8068-4268b6b68529.gif)

## Features

- Scan the contents of a container image or filesystem to find known vulnerabilities.
- Find vulnerabilities for major operating system packages:
  - Alpine
  - Amazon Linux
  - Azure Linux (previously CBL-Mariner)
  - BusyBox
  - CentOS
  - Debian
  - Echo
  - Distroless
  - MinimOS
  - Oracle Linux
  - Red Hat (RHEL)
  - Ubuntu
  - Wolfi
- Find vulnerabilities for language-specific packages:
  - Ruby (Gems)
  - Java (JAR, WAR, EAR, JPI, HPI)
  - JavaScript (NPM, Yarn)
  - Python (Egg, Wheel, Poetry, requirements.txt/setup.py files)
  - Dotnet (deps.json)
  - Golang (go.mod)
  - PHP (Composer)
  - Rust (Cargo)
- Supports Docker, OCI and [Singularity](https://github.com/sylabs/singularity) image formats.
- [OpenVEX](https://github.com/openvex) support for filtering and augmenting scanning results.

If you encounter an issue, please [let us know using the issue tracker](https://github.com/anchore/grype/issues).

## Installation

### Recommended

```bash
curl -sSfL https://get.anchore.io/grype | sudo sh -s -- -b /usr/local/bin
```
Install script options:
-	`-b`: Specify a custom installation directory (defaults to `./bin`)
-	`-d`: More verbose logging levels (`-d` for debug, `-dd` for trace)
-	`-v`: Verify the signature of the downloaded artifact before installation (requires [`cosign`](https://github.com/sigstore/cosign) to be installed)

### Chocolatey

The chocolatey distribution of grype is community-maintained and not distributed by the anchore team.

```bash
choco install grype -y
```

### Homebrew

```bash
brew tap anchore/grype
brew install grype
```

### MacPorts

On macOS, Grype can additionally be installed from the [community-maintained port](https://ports.macports.org/port/grype/) via MacPorts:

```bash
sudo port install grype
```

**Note**: Currently, Grype is built only for macOS and Linux.

### From source

See [DEVELOPING.md](DEVELOPING.md#native-development) for instructions to build and run from source.

### GitHub Actions

If you&#039;re using GitHub Actions, you can use our [Grype-based action](https://github.com/marketplace/actions/anchore-container-scan) to run vulnerability scans on your code or container images during your CI workflows.

## Verifying the artifacts

Checksums are applied to all artifacts, and the resulting checksum file is signed using cosign.

You need the following tool to verify signature:

- [Cosign](https://docs.sigstore.dev/cosign/system_config/installation/)

Verification steps are as follow:

1. Download the files you want, and the checksums.txt, checksums.txt.pem and checksums.txt.sig files from the [releases](https://github.com/anchore/grype/releases) page:

2. Verify the signature:

```shell
cosign verify-blob &lt;path to checksum.txt&gt; \
--certificate &lt;path to checksums.txt.pem&gt; \
--signature &lt;path to checksums.txt.sig&gt; \
--certificate-identity-regexp &#039;https://github\.com/anchore/grype/\.github/workflows/.+&#039; \
--certificate-oidc-issuer &quot;https://token.actions.githubusercontent.com&quot;
```

3. Once the signature is confirmed as valid, you can proceed to validate that the SHA256 sums align with the downloaded artifact:

```shell
sha256sum --ignore-missing -c checksums.txt
```

## Getting started

[Install the binary](#installation), and make sure that `grype` is available in your path. To scan for vulnerabilities in an image:

```
grype &lt;image&gt;
```

The above command scans for vulnerabilities visible in the container (i.e., the squashed representation of the image). To include software from all image layers in the vulnerability scan, regardless of its presence in the final image, provide `--scope all-layers`:

```
grype &lt;image&gt; --scope all-layers
```

To run grype from a Docker container so it can scan a running container, use the following command:

```yml
docker run --rm \
--volume /var/run/docker.sock:/var/run/docker.sock \
--name Grype anchore/grype:latest \
$(ImageName):$(ImageTag)
```

## Supported sources

Grype can scan a variety of sources beyond those found in Docker.

```
# scan a container image archive (from the result of `docker image save ...`, `podman save ...`, or `skopeo copy` commands)
grype path/to/image.tar

# scan a Singularity Image Format (SIF) container
grype path/to/image.sif

# scan a directory
grype dir:path/to/dir
```

Sources can be explicitly provided with a scheme:

```
podman:yourrepo/yourimage:tag          use images from the Podman daemon
docker:yourrepo/yourimage:tag          use images from the Docker daemon
docker-archive:path/to/yourimage.tar   use a tarball from disk for archives created from &quot;docker save&quot;
oci-archive:path/to/yourimage.tar      use a tarball from disk for OCI archives (from Skopeo or otherwise)
oci-dir:path/to/yourimage              read directly from a path on disk for OCI layout directories (from Skopeo or otherwise)
singularity:path/to/yourimage.sif      read directly from a Singularity Image Format (SIF) container on disk
dir:path/to/yourproject                read directly from a path on disk (any directory)
file:path/to/yourfile                  read directly from a file on disk
sbom:path/to/syft.json                 read Syft JSON from path on disk
registry:yourrepo/yourimage:tag        pull image directly from a registry (no container runtime required)
```

If an image source is not provided and cannot be detected from the given reference it is assumed the image should be pulled from the Docker daemon.
If docker is not present, then the Podman daemon is attempted next, followed by reaching out directly to the image registry last.


This default behavior can be overridden with the `default-image-pull-source` configuration option (See [Configuration](https://github.com/anchore/grype#configuration) for more details).

Use SBOMs for even faster vulnerability scanning in Grype:

```
# Then scan for new vulnerabilities as frequently as needed
grype sbom:./sbom.json

# (You can also pipe the SBOM into Grype)
cat ./sbom.json | grype
```

Grype supports input of [Syft](https://github.com/anchore/syft), [SPDX](https://spdx.dev/), and [CycloneDX](https://cyclonedx.org/)
SBOM formats. If Syft has generated any of these file types, they should have the appropriate information to work properly with Grype.
It is also possible to use SBOMs generated by other tools with varying degrees of success. Two things that make Grype matching
more successful are the inclusion of CPE and Linux distribution information. If an SBOM does not include any CPE information, it
is possible to generate these based on package information using the `--add-cpes-if-none` flag. To specify a distribution,
use the `--distro &lt;distro&gt;:&lt;version&gt;` flag. A full example is:

```
grype --add-cpes-if-none --distro alpine:3.10 sbom:some-alpine-3.10.spdx.json
```

## Threat &amp; Risk Prioritization

This section explains the columns and UI cues that help prioritize remediation efforts:

- **Severity**: String severity based on CVSS scores and indicate the significance of a vulnerability in levels.
  This balances concerns such as ease of exploitability, and the potential to affect 
  confidentiality, integrity, and availability of software and services.

- **EPSS**:
  [Exploit Prediction Scoring System](https://www.first.org/epss/model) is a metric expressing the likelihood
  that a vulnerability will be 
  exploited in the wild over the next 30 days (on a 0‚Äì1 scale); higher values signal a greater likelihood of 
  exploitation.
  The table output shows the EPSS percentile, a one-way transform of the EPSS score showing the 
  proportion of all scored vulnerabilities with an equal or lower probability.
  Percentiles linearize a heavily skewed distribution, making threshold choice (e.g. ‚Äúonly CVEs above the 
  90th percentile‚Äù) straightforward.

- **KEV Indicator**: Flags entries from CISA‚Äôs [Known Exploited Vulnerabilities Catalog](https://www.cisa.gov/known-exploited-vulnerabilities-catalog)
  --an authoritative list of flaws observed being exploited in the wild.

- **Risk Score**: A composite 0‚Äì100 metric calculated as:
  ```markdown
  risk = min(1, threat * average(severity)) * 100
  ```
  Where: 
  - `severity` is the average of all CVSS scores and string severity for a vulnerability (scaled between 0‚Äì1).
  - `threat` is the EPSS score (between 0‚Äì1). If the vulnerability is on the KEV list then `threat` is 
    `1.05`, or `1.1` if the vulnerability is associated with a ransomware campaign.
  This metric is one way to combine EPSS and CVSS suggested in the [EPSS user guide](https://www.first.org/epss/user-guide).

- **Suggested Fixes**: All possible fixes for a package are listed, however, when multiple fixes are available, we de-emphasize all 
  upgrade paths except for the minimal upgrade path (which highlights the smallest, safest version bump).

Results default to sorting by Risk Score and can be overridden with `--sort-by &lt;value&gt;`:

- `severity`: sort by severity
- `epss`: sort by EPSS percentile (aka, &quot;threat&quot;)
- `risk`: sort by risk score
- `kev`: just like risk, except that KEV entries are always above non-KEV entries
- `package`: sort by package name, version, type
- `vulnerability`: sort by vulnerability ID

### Supported versions

Software updates are always applied to the latest version of Grype; fixes are not backported to any previous versions of Grype.

In terms of database updates, any version of Grype before v0.51.0 (Oct 2022, before schema v5) will not receive
vulnerability database updates. You can still build vulnerability databases for unsupported Grype releases by using previous
releases of [vunnel](https://github.com/anchore/vunnel) to gather the upstream data and [grype-db](https://github.com/anchore/grype-db)
to build databases for unsupported schemas.

Only the latest database schema is considered to be supported. When a new database schema is introduced then the one it replaces is
marked as deprecated. Deprecated schemas will continue to receive updates for at least one year after they are marked
as deprecated at which point they will no longer be supported.

### Working with attestations
Grype supports scanning SBOMs as input via stdin. Users can use [cosign](https://github.com/sigstore/cosign) to verify attestations
with an SBOM as its content to scan an image for vulnerabilities:
```
COSIGN_EXPERIMENTAL=1 cosign verify-attestation caphill4/java-spdx-tools:latest \
| jq -r .payload \
| base64 --decode \
| jq -r .predicate.Data \
| grype
```

### Vulnerability Summary

#### Basic Grype Vulnerability Data Shape

```json
 {
  &quot;vulnerability&quot;: {
    ...
  },
  &quot;relatedVulnerabilities&quot;: [
    ...
  ],
  &quot;matchDetails&quot;: [
    ...
  ],
  &quot;artifact&quot;: {
    ...
  }
}
```

- **Vulnerability**: All information on the specific vulnerability that was directly matched on (e.g. ID, severity, CVSS score, fix information, links for more information)
- **RelatedVulnerabilities**: Information pertaining to vulnerabilities found to be related to the main reported vulnerability. Maybe the vulnerability we matched on was a GitHub Security Advisory, which has an upstream CVE (in the authoritative national vulnerability database). In these cases we list the upstream vulnerabilities here.
- **MatchDetails**: This section tries to explain what we searched for while looking for a match and exactly what details on the package and vulnerability that lead to a match.
- **Artifact**: This is a subset of the information that we know about the package (when compared to the [Syft](https://github.com/anchore/syft) json output, we summarize the metadata section).
  This has information about where within the container image or directory we found the package, what kind of package it is, licensing info, pURLs, CPEs, etc.

### Excluding file paths

Grype can exclude files and paths from being scanned within a source by using glob expressions
with one or more `--exclude` parameters:

```
grype &lt;source&gt; --exclude &#039;./out/**/*.json&#039; --exclude /etc
```

**Note:** in the case of _image scanning_, since the entire filesystem is scanned it is
possible to use absolute paths like `/etc` or `/usr/**/*.txt` whereas _directory scans_
exclude files _relative to the specified directory_. For example: scanning `/usr/foo` with
`--exclude ./package.json` would exclude `/usr/foo/package.json` and `--exclude &#039;**/package.json&#039;`
would exclude all `package.json` files under `/usr/foo`. For _directory scans_,
it is required to begin path expressions with `./`, `*/`, or `**/`, all of which
will be resolved _relative to the specified scan directory_. Keep in mind, your shell
may attempt to expand wildcards, so put those parameters in single quotes, like:
`&#039;**/*.json&#039;`.

### External Sources

Grype can be configured to incorporate external data sources for added fidelity in vulnerability matching. This
feature is currently disabled by default. To enable this feature add the following to the grype config:

```yaml
external-sources:
  enable: true
  maven:
    search-upstream-by-sha1: true
    base-url: https://search.maven.org/solrsearch/select
    rate-limit: 300ms # Time between Maven API requests
```

You can also configure the base-url if you&#039;re using another registry as your maven endpoint.

The rate at which Maven API requests are made can be configured to match your environment&#039;s requirements. The default is 300ms between requests.

### Output formats

The output format for Grype is configurable as well:

```
grype &lt;image&gt; -o &lt;format&gt;
```

Where the formats available are:

- `table`: A columnar summary (default).
- `cyclonedx`: An XML report conforming to the [CycloneDX 1.6 specification](https://cyclonedx.org/specification/overview/).
- `cyclonedx-json`: A JSON report conforming to the [CycloneDX 1.6 specification](https://cyclonedx.org/specification/overview/).
- `json`: Use this to get as much information out of Grype as possible!
- `sarif`: Use this option to get a [SARIF](https://docs.oasis-open.org/sarif/sarif/v2.1.0/sarif-v2.1.0.html) report (Static Analysis Results Interchange Format)
- `template`: Lets the user specify the output format. See [&quot;Using templates&quot;](#using-templates) below.

### Using templates

Grype lets you define custom output formats, using [Go templates](https://golang.org/pkg/text/template/). Here&#039;s how it works:

- Define your format as a Go template, and save this template as a file.

- Set the output format to &quot;template&quot; (`-o template`).

- Specify the path to the template file (`-t ./path/to/custom.template`).

- Grype&#039;s template processing uses the same data models as the `json` output format ‚Äî so if you&#039;re wondering what data is available as you author a template, you can use the output from `grype &lt;image&gt; -o json` as a reference.

**Please note:** Templates can access information about the system they are running on, such as environment variables. You should never run untrusted templates.

There are several example templates in the [templates](https://github.com/anchore/grype/tree/main/templates) directory in the Grype source which can serve as a starting point for a custom output format. For example, [csv.tmpl](https://github.com/anchore/grype/blob/main/templates/csv.tmpl) produces a vulnerability report in CSV (comma separated value) format:

```text
&quot;Package&quot;,&quot;Version Installed&quot;,&quot;Vulnerability ID&quot;,&quot;Severity&quot;
&quot;coreutils&quot;,&quot;8.30-3ubuntu2&quot;,&quot;CVE-2016-2781&quot;,&quot;Low&quot;
&quot;libc-bin&quot;,&quot;2.31-0ubuntu9&quot;,&quot;CVE-2016-10228&quot;,&quot;Negligible&quot;
&quot;libc-bin&quot;,&quot;2.31-0ubuntu9&quot;,&quot;CVE-2020-6096&quot;,&quot;Low&quot;
...
```

You can also find the template for the default &quot;table&quot; output format in the same place.

Grype also includes a vast array of utility templating functions from [sprig](http://masterminds.github.io/sprig/) apart from the default golang [text/template](https://pkg.go.dev/text/template#hdr-Functions) to allow users to customize the output from Grype.

### Gating on severity of vulnerabilities

You can have Grype exit with an error if any vulnerabilities are reported at or above the specified severity level. This comes in handy when using Grype within a script or CI pipeline. To do this, use the `--fail-on &lt;severity&gt;` CLI flag.

For example, here&#039;s how you could trigger a CI pipeline failure if any vulnerabilities are found in the `ubuntu:latest` image with a severity of &quot;medium&quot; or higher:

```
grype ubuntu:latest --fail-on medium
```

**Note:** Grype returns exit code `2` on vulnerability errors.

### Specifying matches to ignore

If you&#039;re seeing Grype report **false positives** or any other vulnerability matches that you just don&#039;t want to see, you can tell Grype to **ignore** matches by specifying one or more _&quot;ignore rules&quot;_ in your Grype configuration file (e.g. `~/.grype.yaml`). This causes Grype not to report any vulnerability matches that meet the criteria specified by any of your ignore rules.

Each rule can specify any combination of the following criteria:

- vulnerability ID (e.g. `&quot;CVE-2008-4318&quot;`)
- namespace (e.g. `&quot;nvd&quot;`)
- fix state (allowed values: `&quot;fixed&quot;`, `&quot;not-fixed&quot;`, `&quot;wont-fix&quot;`, or `&quot;unknown&quot;`)
- package name (e.g. `&quot;libcurl&quot;`)
- package version (e.g

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-collector-contrib]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-collector-contrib</link>
            <guid>https://github.com/open-telemetry/opentelemetry-collector-contrib</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[Contrib repository for the OpenTelemetry Collector]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-collector-contrib">open-telemetry/opentelemetry-collector-contrib</a></h1>
            <p>Contrib repository for the OpenTelemetry Collector</p>
            <p>Language: Go</p>
            <p>Stars: 3,896</p>
            <p>Forks: 2,991</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>---

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/getting-started/&quot;&gt;Getting Started&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md&quot;&gt;Getting Involved&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;Getting In Touch&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/actions/workflows/build-and-test.yml?query=branch%3Amain&quot;&gt;
    &lt;img alt=&quot;Build Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector-contrib/build-and-test.yml?branch=main&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector-contrib&quot;&gt;
    &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/branch/main/&quot;&gt;
    &lt;img alt=&quot;Codecov Status&quot; src=&quot;https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest by date including pre-releases)&quot; src=&quot;https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector-contrib?include_prereleases&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;img alt=&quot;Beta&quot; src=&quot;https://img.shields.io/badge/status-beta-informational?style=for-the-badge&amp;logo=data:image/png;base64,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&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/vision.md&quot;&gt;Vision&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/observability.md&quot;&gt;Observability&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md&quot;&gt;Security&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
  &lt;/strong&gt;
&lt;/p&gt;

---

# OpenTelemetry Collector Contrib

This is a repository for OpenTelemetry Collector components that are not suitable for the  [core repository](https://github.com/open-telemetry/opentelemetry-collector) of the collector. 

The official distributions, core and contrib, are available as part of the [opentelemetry-collector-releases](https://github.com/open-telemetry/opentelemetry-collector-releases) repository. Some of the components in this repository are part of the &quot;core&quot; distribution, such as the Jaeger and Prometheus components, but most of the components here are only available as part of the &quot;contrib&quot; distribution. Users of the OpenTelemetry Collector are also encouraged to build their own custom distributions with the [OpenTelemetry Collector Builder](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder), using the components they need from the core repository, the contrib repository, and possibly third-party or internal repositories.

Each component has its own support levels, as defined in the following sections. For each signal that a component supports, there&#039;s a stability level, setting the right expectations. It is possible then that a component will be **Stable** for traces but **Alpha** for metrics and **Development** for logs.

## Stability levels

Stability level for components in this repository follow the [definitions](https://github.com/open-telemetry/opentelemetry-collector#stability-levels) from the OpenTelemetry Collector repository.

## Gated features

Some features are hidden behind feature gates before they are part of the main code path for the component. Note that the feature gates themselves might be at different [lifecycle stages](https://github.com/open-telemetry/opentelemetry-collector/tree/main/featuregate#feature-lifecycle).

## Support

Each component is supported either by the community of OpenTelemetry Collector Contrib maintainers, as defined by the GitHub group [@open-telemetry/collector-contrib-maintainer](https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer), or by specific vendors. See the individual README files for information about the specific components.

The OpenTelemetry Collector Contrib maintainers may at any time downgrade specific components if they are deemed unmaintained or if they pose a risk to the repository and/or binary distribution.

Even though the OpenTelemetry Collector Contrib maintainers are ultimately responsible for the components hosted here, actual support will likely be provided by individual contributors, typically a code owner for the specific component.

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md).

### Maintainers

- [Alex Boten](https://github.com/codeboten), Honeycomb
- [Andrzej Stencel](https://github.com/andrzej-stencel), Elastic
- [Antoine Toulme](https://github.com/atoulme), Splunk
- [Bogdan Drutu](https://github.com/bogdandrutu), Snowflake
- [Dmitrii Anoshin](https://github.com/dmitryax), Splunk
- [Edmo Vamerlatti Costa](https://github.com/edmocosta), Elastic
- [Evan Bradley](https://github.com/evan-bradley), Dynatrace
- [Pablo Baeyens](https://github.com/mx-psi), DataDog
- [Sean Marciniak](https://github.com/MovieStoreGuy), Splunk
- [Tyler Helmuth](https://github.com/TylerHelmuth), Honeycomb
- [Yang Song](https://github.com/songy23), DataDog

For more information about the maintainer role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#maintainer).

### Approvers

- [Andrew Wilkins](https://github.com/axw), Elastic
- [Arthur Silva Sens](https://github.com/ArthurSens), Grafana Labs
- [Braydon Kains](https://github.com/braydonk), Google
- [Christos Markou](https://github.com/ChrsMark), Elastic
- [Curtis Robert](https://github.com/crobert-1), Splunk
- [David Ashpole](https://github.com/dashpole), Google
- [Matt Wear](https://github.com/mwear), Lightstep
- [Paulo Janotti](https://github.com/pjanotti), Splunk
- [Sam DeHaan](https://github.com/dehaansa), Grafana Labs
- [Ziqi Zhao](https://github.com/fatsheep9146), Alibaba

For more information about the approver role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#approver).

### Triagers

- [Benedikt Bongartz](https://github.com/frzifus), Red Hat
- [Douglas Camata](https://github.com/douglascamata), Coralogix
- [Florian Bacher](https://github.com/bacherfl), Dynatrace
- [Israel Blancas](https://github.com/iblancasa), Coralogix
- [James Moessis](https://github.com/jamesmoessis), Atlassian
- [Jared Tan](https://github.com/JaredTan95), DaoCloud
- [Murphy Chen](https://github.com/Frapschen), DaoCloud
- [Ondrej Dubaj](https://github.com/odubajDT), Dynatrace
- [Roger Coll](https://github.com/rogercoll), Elastic
- [Vihas Makwana](https://github.com/VihasMakwana), Elastic
- Actively seeking contributors to triage issues

For more information about the triager role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#triager).

### Emeritus Maintainers

- [Daniel Jaglowski](https://github.com/djaglowski)
- [Juraci Paix√£o Kr√∂hling](https://github.com/jpkrohling)
- [Tigran Najaryan](https://github.com/tigrannajaryan)

For more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).

### Emeritus Approvers

- [Anthony Mirabella](https://github.com/Aneurysm9)
- [Bryan Aguilar](https://github.com/bryan-aguilar)
- [Przemek Maciolek](https://github.com/pmm-sumo)
- [Ruslan Kovalov](https://github.com/kovrus)

For more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).

### Emeritus Triagers

- [Alolita Sharma](https://github.com/alolita)
- [Gabriel Aszalos](https://github.com/gbbr)
- [Goutham Veeramachaneni](https://github.com/gouthamve)
- [Punya Biswal](https://github.com/punya)
- [Steve Flanders](https://github.com/flands)

For more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).

### No Over-Representation

A community member cannot be promoted to be a Collector contrib maintainer if, after their promotion, the resulting maintainers group has more than one-fourth (25%) of the members affiliated with the same employer. Job changes and similar events might result in over-representation, and no new maintainers from the same company can be promoted until representation is balanced again. In the event of confusion or concern, the OpenTelemetry Collector SIG will defer to the CNCF definition of &quot;same employer&quot;.

## PRs and Reviews

When creating a PR please follow the process [described
here](https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md#how-to-structure-prs-to-get-expedient-reviews).

New PRs will be automatically associated with the reviewers based on
[CODEOWNERS](.github/CODEOWNERS). PRs will be also automatically assigned to one of the
maintainers or approvers for facilitation.

The facilitator is responsible for helping the PR author and reviewers to make progress
or if progress cannot be made for closing the PR.

If the reviewers do not have approval rights the facilitator is also responsible
for the official approval that is required for the PR to be merged and if the facilitator
is a maintainer they are responsible for merging the PR as well.

The facilitator is not required to perform a thorough review, but they are encouraged to
enforce Collector best practices and consistency across the codebase and component
behavior. The facilitators will typically rely on codeowner&#039;s detailed review of the code
when making the final approval decision. 
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[wailsapp/wails]]></title>
            <link>https://github.com/wailsapp/wails</link>
            <guid>https://github.com/wailsapp/wails</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[Create beautiful applications using Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wailsapp/wails">wailsapp/wails</a></h1>
            <p>Create beautiful applications using Go</p>
            <p>Language: Go</p>
            <p>Stars: 29,930</p>
            <p>Forks: 1,464</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot; style=&quot;text-align: center&quot;&gt;
  &lt;img src=&quot;./assets/images/logo-universal.png&quot; width=&quot;55%&quot;&gt;&lt;br/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  Build desktop applications using Go &amp; Web Technologies.
  &lt;br/&gt;
  &lt;br/&gt;
  &lt;a href=&quot;https://github.com/wailsapp/wails/blob/master/LICENSE&quot;&gt;
    &lt;img alt=&quot;GitHub&quot; src=&quot;https://img.shields.io/github/license/wailsapp/wails&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/wailsapp/wails&quot;&gt;
    &lt;img src=&quot;https://goreportcard.com/badge/github.com/wailsapp/wails&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pkg.go.dev/github.com/wailsapp/wails&quot;&gt;
    &lt;img src=&quot;https://pkg.go.dev/badge/github.com/wailsapp/wails.svg&quot; alt=&quot;Go Reference&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/wailsapp/wails/issues&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&quot; alt=&quot;CodeFactor&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://app.fossa.com/projects/git%2Bgithub.com%2Fwailsapp%2Fwails?ref=badge_shield&quot; alt=&quot;FOSSA Status&quot;&gt;
    &lt;img src=&quot;https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwailsapp%2Fwails.svg?type=shield&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/avelino/awesome-go&quot; rel=&quot;nofollow&quot;&gt;
    &lt;img src=&quot;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg&quot; alt=&quot;Awesome&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/BrRSWTaxVK&quot;&gt;
    &lt;img alt=&quot;Discord&quot; src=&quot;https://dcbadge.vercel.app/api/server/BrRSWTaxVK?style=flat&quot;/&gt;
  &lt;/a&gt;
  &lt;br/&gt;
  &lt;a href=&quot;https://github.com/wailsapp/wails/actions/workflows/build-and-test.yml&quot; rel=&quot;nofollow&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/wailsapp/wails/build-and-test.yml?branch=master&amp;logo=Github&quot; alt=&quot;Build&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/wailsapp/wails/tags&quot; rel=&quot;nofollow&quot;&gt;
    &lt;img alt=&quot;GitHub tag (latest SemVer pre-release)&quot; src=&quot;https://img.shields.io/github/v/tag/wailsapp/wails?include_prereleases&amp;label=version&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;strong&gt;
&lt;samp&gt;

[English](README.md) ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](README.zh-Hans.md) ¬∑ [Êó•Êú¨Ë™û](README.ja.md) ¬∑
[ÌïúÍµ≠Ïñ¥](README.ko.md) ¬∑ [Espa√±ol](README.es.md) ¬∑ [Portugu√™s](README.pt-br.md) ¬∑
[–†—É—Å—Å–∫–∏–π](README.ru.md) ¬∑ [Francais](README.fr.md) ¬∑ [Uzbek](README.uz.md) ¬∑ [Deutsch](README.de.md) ¬∑
[T√ºrk√ße](README.tr.md)

&lt;/samp&gt;
&lt;/strong&gt;
&lt;/div&gt;

## Table of Contents

- [Table of Contents](#table-of-contents)
- [Introduction](#introduction)
- [Features](#features)
  - [Roadmap](#roadmap)
- [Getting Started](#getting-started)
- [Sponsors](#sponsors)
- [FAQ](#faq)
- [Stargazers over time](#stargazers-over-time)
- [Contributors](#contributors)
- [License](#license)
- [Inspiration](#inspiration)

## Introduction

The traditional method of providing web interfaces to Go programs is via a built-in web server. Wails offers a different
approach: it provides the ability to wrap both Go code and a web frontend into a single binary. Tools are provided to
make this easy for you by handling project creation, compilation and bundling. All you have to do is get creative!

## Features

- Use standard Go for the backend
- Use any frontend technology you are already familiar with to build your UI
- Quickly create rich frontends for your Go programs using pre-built templates
- Easily call Go methods from Javascript
- Auto-generated Typescript definitions for your Go structs and methods
- Native Dialogs &amp; Menus
- Native Dark / Light mode support
- Supports modern translucency and &quot;frosted window&quot; effects
- Unified eventing system between Go and Javascript
- Powerful cli tool to quickly generate and build your projects
- Multiplatform
- Uses native rendering engines - _no embedded browser_!

### Roadmap

The project roadmap may be found [here](https://github.com/wailsapp/wails/discussions/1484). Please consult
it before creating an enhancement request.

## Getting Started

The installation instructions are on the [official website](https://wails.io/docs/gettingstarted/installation).

## Sponsors

This project is supported by these kind people / companies:
&lt;img src=&quot;website/static/img/sponsors.svg&quot; style=&quot;width:100%;max-width:800px;&quot;/&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://wails.io/img/sponsor/jetbrains-grayscale.webp&quot; style=&quot;width: 100px&quot;/&gt;
&lt;/p&gt;

## FAQ

- Is this an alternative to Electron?

  Depends on your requirements. It&#039;s designed to make it easy for Go programmers to make lightweight desktop
  applications or add a frontend to their existing applications. Wails does offer native elements such as menus
  and dialogs, so it could be considered a lightweight electron alternative.

- Who is this project aimed at?

  Go programmers who want to bundle an HTML/JS/CSS frontend with their applications, without resorting to creating a
  server and opening a browser to view it.

- What&#039;s with the name?

  When I saw WebView, I thought &quot;What I really want is tooling around building a WebView app, a bit like Rails is to
  Ruby&quot;. So initially it was a play on words (Webview on Rails). It just so happened to also be a homophone of the
  English name for the [Country](https://en.wikipedia.org/wiki/Wales) I am from. So it stuck.

## Stargazers over time

&lt;a href=&quot;https://star-history.com/#wailsapp/wails&amp;Date&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=wailsapp/wails&amp;type=Date&amp;theme=dark&quot; /&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=wailsapp/wails&amp;type=Date&quot; /&gt;
    &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=wailsapp/wails&amp;type=Date&quot; /&gt;
  &lt;/picture&gt;
&lt;/a&gt;

## Contributors

The contributors list is getting too big for the readme! All the amazing people who have contributed to this
project have their own page [here](https://wails.io/credits#contributors).

## License

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwailsapp%2Fwails.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Fwailsapp%2Fwails?ref=badge_large)

## Inspiration

This project was mainly coded to the following albums:

- [Manic Street Preachers - Resistance Is Futile](https://open.spotify.com/album/1R2rsEUqXjIvAbzM0yHrxA)
- [Manic Street Preachers - This Is My Truth, Tell Me Yours](https://open.spotify.com/album/4VzCL9kjhgGQeKCiojK1YN)
- [The Midnight - Endless Summer](https://open.spotify.com/album/4Krg8zvprquh7TVn9OxZn8)
- [Gary Newman - Savage (Songs from a Broken World)](https://open.spotify.com/album/3kMfsD07Q32HRWKRrpcexr)
- [Steve Vai - Passion &amp; Warfare](https://open.spotify.com/album/0oL0OhrE2rYVns4IGj8h2m)
- [Ben Howard - Every Kingdom](https://open.spotify.com/album/1nJsbWm3Yy2DW1KIc1OKle)
- [Ben Howard - Noonday Dream](https://open.spotify.com/album/6astw05cTiXEc2OvyByaPs)
- [Adwaith - Melyn](https://open.spotify.com/album/2vBE40Rp60tl7rNqIZjaXM)
- [Gwidaith Hen Fran - Cedors Hen Wrach](https://open.spotify.com/album/3v2hrfNGINPLuDP0YDTOjm)
- [Metallica - Metallica](https://open.spotify.com/album/2Kh43m04B1UkVcpcRa1Zug)
- [Bloc Party - Silent Alarm](https://open.spotify.com/album/6SsIdN05HQg2GwYLfXuzLB)
- [Maxthor - Another World](https://open.spotify.com/album/3tklE2Fgw1hCIUstIwPBJF)
- [Alun Tan Lan - Y Distawrwydd](https://open.spotify.com/album/0c32OywcLpdJCWWMC6vB8v)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[go-gorm/gorm]]></title>
            <link>https://github.com/go-gorm/gorm</link>
            <guid>https://github.com/go-gorm/gorm</guid>
            <pubDate>Fri, 05 Sep 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[The fantastic ORM library for Golang, aims to be developer friendly]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/go-gorm/gorm">go-gorm/gorm</a></h1>
            <p>The fantastic ORM library for Golang, aims to be developer friendly</p>
            <p>Language: Go</p>
            <p>Stars: 38,818</p>
            <p>Forks: 4,095</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># GORM

The fantastic ORM library for Golang, aims to be developer friendly.

[![go report card](https://goreportcard.com/badge/github.com/go-gorm/gorm &quot;go report card&quot;)](https://goreportcard.com/report/github.com/go-gorm/gorm)
[![test status](https://github.com/go-gorm/gorm/workflows/tests/badge.svg?branch=master &quot;test status&quot;)](https://github.com/go-gorm/gorm/actions)
[![MIT license](https://img.shields.io/badge/license-MIT-brightgreen.svg)](https://opensource.org/licenses/MIT)
[![Go.Dev reference](https://img.shields.io/badge/go.dev-reference-blue?logo=go&amp;logoColor=white)](https://pkg.go.dev/gorm.io/gorm?tab=doc)

## Overview

* Full-Featured ORM
* Associations (Has One, Has Many, Belongs To, Many To Many, Polymorphism, Single-table inheritance)
* Hooks (Before/After Create/Save/Update/Delete/Find)
* Eager loading with `Preload`, `Joins`
* Transactions, Nested Transactions, Save Point, RollbackTo to Saved Point
* Context, Prepared Statement Mode, DryRun Mode
* Batch Insert, FindInBatches, Find To Map
* SQL Builder, Upsert, Locking, Optimizer/Index/Comment Hints, NamedArg, Search/Update/Create with SQL Expr
* Composite Primary Key
* Auto Migrations
* Logger
* Extendable, flexible plugin API: Database Resolver (Multiple Databases, Read/Write Splitting) / Prometheus‚Ä¶
* Every feature comes with tests
* Developer Friendly

## Getting Started

* GORM Guides [https://gorm.io](https://gorm.io)
* Gen Guides [https://gorm.io/gen/index.html](https://gorm.io/gen/index.html)

## Contributing

[You can help to deliver a better GORM, check out things you can do](https://gorm.io/contribute.html)

## Contributors

[Thank you](https://github.com/go-gorm/gorm/graphs/contributors) for contributing to the GORM framework!

## License

¬© Jinzhu, 2013~time.Now

Released under the [MIT License](https://github.com/go-gorm/gorm/blob/master/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[dexidp/dex]]></title>
            <link>https://github.com/dexidp/dex</link>
            <guid>https://github.com/dexidp/dex</guid>
            <pubDate>Fri, 05 Sep 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[OpenID Connect (OIDC) identity and OAuth 2.0 provider with pluggable connectors]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dexidp/dex">dexidp/dex</a></h1>
            <p>OpenID Connect (OIDC) identity and OAuth 2.0 provider with pluggable connectors</p>
            <p>Language: Go</p>
            <p>Stars: 10,111</p>
            <p>Forks: 1,831</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># dex - A federated OpenID Connect provider

![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/dexidp/dex/ci.yaml?style=flat-square&amp;branch=master)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/dexidp/dex/badge?style=flat-square)](https://api.securityscorecards.dev/projects/github.com/dexidp/dex)
[![Go Report Card](https://goreportcard.com/badge/github.com/dexidp/dex?style=flat-square)](https://goreportcard.com/report/github.com/dexidp/dex)
[![Gitpod ready-to-code](https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&amp;style=flat-square)](https://gitpod.io/#https://github.com/dexidp/dex)

![logo](docs/logos/dex-horizontal-color.png)

Dex is an identity service that uses [OpenID Connect][openid-connect] to drive authentication for other apps.

Dex acts as a portal to other identity providers through [&quot;connectors.&quot;](#connectors) This lets dex defer authentication to LDAP servers, SAML providers, or established identity providers like GitHub, Google, and Active Directory. Clients write their authentication logic once to talk to dex, then dex handles the protocols for a given backend.

## ID Tokens

ID Tokens are an OAuth2 extension introduced by OpenID Connect and dex&#039;s primary feature. ID Tokens are [JSON Web Tokens][jwt-io] (JWTs) signed by dex and returned as part of the OAuth2 response that attests to the end user&#039;s identity. An example JWT might look like:

```
eyJhbGciOiJSUzI1NiIsImtpZCI6IjlkNDQ3NDFmNzczYjkzOGNmNjVkZDMyNjY4NWI4NjE4MGMzMjRkOTkifQ.eyJpc3MiOiJodHRwOi8vMTI3LjAuMC4xOjU1NTYvZGV4Iiwic3ViIjoiQ2djeU16UXlOelE1RWdabmFYUm9kV0kiLCJhdWQiOiJleGFtcGxlLWFwcCIsImV4cCI6MTQ5Mjg4MjA0MiwiaWF0IjoxNDkyNzk1NjQyLCJhdF9oYXNoIjoiYmk5NmdPWFpTaHZsV1l0YWw5RXFpdyIsImVtYWlsIjoiZXJpYy5jaGlhbmdAY29yZW9zLmNvbSIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJncm91cHMiOlsiYWRtaW5zIiwiZGV2ZWxvcGVycyJdLCJuYW1lIjoiRXJpYyBDaGlhbmcifQ.OhROPq_0eP-zsQRjg87KZ4wGkjiQGnTi5QuG877AdJDb3R2ZCOk2Vkf5SdP8cPyb3VMqL32G4hLDayniiv8f1_ZXAde0sKrayfQ10XAXFgZl_P1yilkLdknxn6nbhDRVllpWcB12ki9vmAxklAr0B1C4kr5nI3-BZLrFcUR5sQbxwJj4oW1OuG6jJCNGHXGNTBTNEaM28eD-9nhfBeuBTzzO7BKwPsojjj4C9ogU4JQhGvm_l4yfVi0boSx8c0FX3JsiB0yLa1ZdJVWVl9m90XmbWRSD85pNDQHcWZP9hR6CMgbvGkZsgjG32qeRwUL_eNkNowSBNWLrGNPoON1gMg
```

ID Tokens contains standard claims assert which client app logged the user in, when the token expires, and the identity of the user.

```json
{
  &quot;iss&quot;: &quot;http://127.0.0.1:5556/dex&quot;,
  &quot;sub&quot;: &quot;CgcyMzQyNzQ5EgZnaXRodWI&quot;,
  &quot;aud&quot;: &quot;example-app&quot;,
  &quot;exp&quot;: 1492882042,
  &quot;iat&quot;: 1492795642,
  &quot;at_hash&quot;: &quot;bi96gOXZShvlWYtal9Eqiw&quot;,
  &quot;email&quot;: &quot;jane.doe@coreos.com&quot;,
  &quot;email_verified&quot;: true,
  &quot;groups&quot;: [
    &quot;admins&quot;,
    &quot;developers&quot;
  ],
  &quot;name&quot;: &quot;Jane Doe&quot;
}
```

Because these tokens are signed by dex and [contain standard-based claims][standard-claims] other services can consume them as service-to-service credentials. Systems that can already consume OpenID Connect ID Tokens issued by dex include:

* [Kubernetes][kubernetes]
* [AWS STS][aws-sts]

For details on how to request or validate an ID Token, see [_&quot;Writing apps that use dex&quot;_][using-dex].

## Kubernetes and Dex

Dex runs natively on top of any Kubernetes cluster using Custom Resource Definitions and can drive API server authentication through the OpenID Connect plugin. Clients, such as the [`kubernetes-dashboard`](https://github.com/kubernetes/dashboard) and `kubectl`, can act on behalf of users who can login to the cluster through any identity provider dex supports.

* More docs for running dex as a Kubernetes authenticator can be found [here](https://dexidp.io/docs/guides/kubernetes/).
* You can find more about companies and projects which use dex, [here](./ADOPTERS.md).

## Connectors

When a user logs in through dex, the user&#039;s identity is usually stored in another user-management system: a LDAP directory, a GitHub org, etc. Dex acts as a shim between a client app and the upstream identity provider. The client only needs to understand OpenID Connect to query dex, while dex implements an array of protocols for querying other user-management systems.

![](docs/img/dex-flow.png)

A &quot;connector&quot; is a strategy used by dex for authenticating a user against another identity provider. Dex implements connectors that target specific platforms such as GitHub, LinkedIn, and Microsoft as well as established protocols like LDAP and SAML.

Depending on the connectors limitations in protocols can prevent dex from issuing [refresh tokens][scopes] or returning [group membership][scopes] claims. For example, because SAML doesn&#039;t provide a non-interactive way to refresh assertions, if a user logs in through the SAML connector dex won&#039;t issue a refresh token to its client. Refresh token support is required for clients that require offline access, such as `kubectl`.

Dex implements the following connectors:

| Name | supports refresh tokens | supports groups claim | supports preferred_username claim | status | notes |
| ---- | ----------------------- | --------------------- | --------------------------------- | ------ | ----- |
| [LDAP](https://dexidp.io/docs/connectors/ldap/) | yes | yes | yes | stable | |
| [GitHub](https://dexidp.io/docs/connectors/github/) | yes | yes | yes | stable | |
| [SAML 2.0](https://dexidp.io/docs/connectors/saml/) | no | yes | no | stable | WARNING: Unmaintained and likely vulnerable to auth bypasses ([#1884](https://github.com/dexidp/dex/discussions/1884)) |
| [GitLab](https://dexidp.io/docs/connectors/gitlab/) | yes | yes | yes | beta | |
| [OpenID Connect](https://dexidp.io/docs/connectors/oidc/) | yes | yes | yes | beta | Includes Salesforce, Azure, etc. |
| [OAuth 2.0](https://dexidp.io/docs/connectors/oauth/) | no | yes | yes | alpha | |
| [Google](https://dexidp.io/docs/connectors/google/) | yes | yes | yes | alpha | |
| [LinkedIn](https://dexidp.io/docs/connectors/linkedin/) | yes | no | no | beta | |
| [Microsoft](https://dexidp.io/docs/connectors/microsoft/) | yes | yes | no | beta | |
| [AuthProxy](https://dexidp.io/docs/connectors/authproxy/) | no | yes | no | alpha | Authentication proxies such as Apache2 mod_auth, etc. |
| [Bitbucket Cloud](https://dexidp.io/docs/connectors/bitbucketcloud/) | yes | yes | no | alpha | |
| [OpenShift](https://dexidp.io/docs/connectors/openshift/) | yes | yes | no | alpha | |
| [Atlassian Crowd](https://dexidp.io/docs/connectors/atlassian-crowd/) | yes | yes | yes * | beta | preferred_username claim must be configured through config |
| [Gitea](https://dexidp.io/docs/connectors/gitea/) | yes | no | yes | beta | |
| [OpenStack Keystone](https://dexidp.io/docs/connectors/keystone/) | yes | yes | no | alpha | |

Stable, beta, and alpha are defined as:

* Stable: well tested, in active use, and will not change in backward incompatible ways.
* Beta: tested and unlikely to change in backward incompatible ways.
* Alpha: may be untested by core maintainers and is subject to change in backward incompatible ways.

All changes or deprecations of connector features will be announced in the [release notes][release-notes].

## Documentation

* [Getting started](https://dexidp.io/docs/getting-started/)
* [Intro to OpenID Connect](https://dexidp.io/docs/openid-connect/)
* [Writing apps that use dex][using-dex]
* [What&#039;s new in v2](https://dexidp.io/docs/archive/v2/)
* [Custom scopes, claims, and client features](https://dexidp.io/docs/custom-scopes-claims-clients/)
* [Storage options](https://dexidp.io/docs/storage/)
* [gRPC API](https://dexidp.io/docs/api/)
* [Using Kubernetes with dex](https://dexidp.io/docs/kubernetes/)
* Client libraries
  * [Go][go-oidc]

## Reporting a vulnerability

Please see our [security policy](.github/SECURITY.md) for details about reporting vulnerabilities.

## Getting help

- For feature requests and bugs, file an [issue](https://github.com/dexidp/dex/issues).
- For general discussion about both using and developing Dex:
    - join the [#dexidp](https://cloud-native.slack.com/messages/dexidp) on the CNCF Slack
    - open a new [discussion](https://github.com/dexidp/dex/discussions)
    - join the [dex-dev](https://groups.google.com/forum/#!forum/dex-dev) mailing list

[openid-connect]: https://openid.net/connect/
[standard-claims]: https://openid.net/specs/openid-connect-core-1_0.html#StandardClaims
[scopes]: https://dexidp.io/docs/custom-scopes-claims-clients/#scopes
[using-dex]: https://dexidp.io/docs/using-dex/
[jwt-io]: https://jwt.io/
[kubernetes]: https://kubernetes.io/docs/reference/access-authn-authz/authentication/#openid-connect-tokens
[aws-sts]: https://docs.aws.amazon.com/STS/latest/APIReference/Welcome.html
[go-oidc]: https://github.com/coreos/go-oidc
[issue-1065]: https://github.com/dexidp/dex/issues/1065
[release-notes]: https://github.com/dexidp/dex/releases

## Development

When all coding and testing is done, please run the test suite:

```shell
make testall
```

For the best developer experience, install [Nix](https://builtwithnix.org/) and [direnv](https://direnv.net/).

Alternatively, install Go and Docker manually or using a package manager. Install the rest of the dependencies by running `make deps`.

For release process, please read the [release documentation](https://dexidp.io/docs/development/releases/).

## License

The project is licensed under the [Apache License, Version 2.0](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[wavetermdev/waveterm]]></title>
            <link>https://github.com/wavetermdev/waveterm</link>
            <guid>https://github.com/wavetermdev/waveterm</guid>
            <pubDate>Fri, 05 Sep 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[An open-source, cross-platform terminal for seamless workflows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wavetermdev/waveterm">wavetermdev/waveterm</a></h1>
            <p>An open-source, cross-platform terminal for seamless workflows</p>
            <p>Language: Go</p>
            <p>Stars: 11,156</p>
            <p>Forks: 441</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.waveterm.dev&quot;&gt;
	&lt;picture&gt;
		&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./assets/wave-dark.png&quot;&gt;
		&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./assets/wave-light.png&quot;&gt;
		&lt;img alt=&quot;Wave Terminal Logo&quot; src=&quot;./assets/wave-light.png&quot; width=&quot;240&quot;&gt;
	&lt;/picture&gt;
  &lt;/a&gt;
  &lt;br/&gt;
&lt;/p&gt;

# Wave Terminal

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm?ref=badge_shield)

Wave is an open-source terminal that combines traditional terminal features with graphical capabilities like file previews, web browsing, and AI assistance. It runs on MacOS, Linux, and Windows.

Modern development involves constantly switching between terminals and browsers - checking documentation, previewing files, monitoring systems, and using AI tools. Wave brings these graphical tools directly into the terminal, letting you control them from the command line. This means you can stay in your terminal workflow while still having access to the visual interfaces you need.

![WaveTerm Screenshot](./assets/wave-screenshot.webp)

## Key Features

- Flexible drag &amp; drop interface to organize terminal blocks, editors, web browsers, and AI assistants
- Built-in editor for seamlessly editing remote files with syntax highlighting and modern editor features
- Rich file preview system for remote files (markdown, images, video, PDFs, CSVs, directories)
- Integrated AI chat with support for multiple models (OpenAI, Claude, Azure, Perplexity, Ollama)
- Command Blocks for isolating and monitoring individual commands with auto-close options
- One-click remote connections with full terminal and file system access
- Rich customization including tab themes, terminal styles, and background images
- Powerful `wsh` command system for managing your workspace from the CLI and sharing data between terminal sessions

## Installation

Wave Terminal works on macOS, Linux, and Windows.

Platform-specific installation instructions can be found [here](https://docs.waveterm.dev/gettingstarted).

You can also install Wave Terminal directly from: [www.waveterm.dev/download](https://www.waveterm.dev/download).

### Minimum requirements

Wave Terminal runs on the following platforms:

- macOS 11 or later (arm64, x64)
- Windows 10 1809 or later (x64)
- Linux based on glibc-2.28 or later (Debian 10, RHEL 8, Ubuntu 20.04, etc.) (arm64, x64)

The WSH helper runs on the following platforms:

- macOS 11 or later (arm64, x64)
- Windows 10 or later (arm64, x64)
- Linux Kernel 2.6.32 or later (x64), Linux Kernel 3.1 or later (arm64)

## Roadmap

Wave is constantly improving! Our roadmap will be continuously updated with our goals for each release. You can find it [here](./ROADMAP.md).

Want to provide input to our future releases? Connect with us on [Discord](https://discord.gg/XfvZ334gwU) or open a [Feature Request](https://github.com/wavetermdev/waveterm/issues/new/choose)!

## Links

- Homepage &amp;mdash; https://www.waveterm.dev
- Download Page &amp;mdash; https://www.waveterm.dev/download
- Documentation &amp;mdash; https://docs.waveterm.dev
- Legacy Documentation &amp;mdash; https://legacydocs.waveterm.dev
- Blog &amp;mdash; https://blog.waveterm.dev
- X &amp;mdash; https://x.com/wavetermdev
- Discord Community &amp;mdash; https://discord.gg/XfvZ334gwU

## Building from Source

See [Building Wave Terminal](BUILD.md).

## Contributing

Wave uses GitHub Issues for issue tracking.

Find more information in our [Contributions Guide](CONTRIBUTING.md), which includes:

- [Ways to contribute](CONTRIBUTING.md#contributing-to-wave-terminal)
- [Contribution guidelines](CONTRIBUTING.md#before-you-start)
- [Storybook](https://docs.waveterm.dev/storybook)

## License

Wave Terminal is licensed under the Apache-2.0 License. For more information on our dependencies, see [here](./ACKNOWLEDGEMENTS.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[aws/aws-sdk-go-v2]]></title>
            <link>https://github.com/aws/aws-sdk-go-v2</link>
            <guid>https://github.com/aws/aws-sdk-go-v2</guid>
            <pubDate>Fri, 05 Sep 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[AWS SDK for the Go programming language.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aws/aws-sdk-go-v2">aws/aws-sdk-go-v2</a></h1>
            <p>AWS SDK for the Go programming language.</p>
            <p>Language: Go</p>
            <p>Stars: 3,243</p>
            <p>Forks: 711</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># AWS SDK for Go v2

[![Go Build status](https://github.com/aws/aws-sdk-go-v2/actions/workflows/go.yml/badge.svg?branch=main)](https://github.com/aws/aws-sdk-go-v2/actions/workflows/go.yml)[![Codegen Build status](https://github.com/aws/aws-sdk-go-v2/actions/workflows/codegen.yml/badge.svg?branch=main)](https://github.com/aws/aws-sdk-go-v2/actions/workflows/codegen.yml) [![SDK Documentation](https://img.shields.io/badge/SDK-Documentation-blue)](https://aws.github.io/aws-sdk-go-v2/docs/) [![Migration Guide](https://img.shields.io/badge/Migration-Guide-blue)](https://aws.github.io/aws-sdk-go-v2/docs/migrating/) [![API Reference](https://img.shields.io/badge/api-reference-blue.svg)](https://pkg.go.dev/mod/github.com/aws/aws-sdk-go-v2) [![Apache V2 License](https://img.shields.io/badge/license-Apache%20V2-blue.svg)](https://github.com/aws/aws-sdk-go-v2/blob/main/LICENSE.txt)

`aws-sdk-go-v2` is the v2 AWS SDK for the Go programming language.

The v2 SDK requires a minimum version of `Go 1.22`.

Check out the [release notes](https://github.com/aws/aws-sdk-go-v2/blob/main/CHANGELOG.md) for information about the latest bug
fixes, updates, and features added to the SDK.

Jump To:
* [Getting Started](#getting-started)
* [Getting Help](#getting-help)
* [Contributing](#feedback-and-contributing)
* [More Resources](#resources)

## Maintenance and support for SDK major versions

For information about maintenance and support for SDK major versions and their underlying dependencies, see the
following in the AWS SDKs and Tools Shared Configuration and Credentials Reference Guide:

* [AWS SDKs and Tools Maintenance Policy](https://docs.aws.amazon.com/credref/latest/refdocs/maint-policy.html)
* [AWS SDKs and Tools Version Support Matrix](https://docs.aws.amazon.com/credref/latest/refdocs/version-support-matrix.html)

### Go version support policy

The v2 SDK follows the upstream [release policy](https://go.dev/doc/devel/release#policy)
with an additional six months of support for the most recently deprecated
language version.

**AWS reserves the right to drop support for unsupported Go versions earlier to
address critical security issues.**

## Getting started
To get started working with the SDK setup your project for Go modules, and retrieve the SDK dependencies with `go get`.
This example shows how you can use the v2 SDK to make an API request using the SDK&#039;s [Amazon DynamoDB] client.

###### Initialize Project
```sh
$ mkdir ~/helloaws
$ cd ~/helloaws
$ go mod init helloaws
```
###### Add SDK Dependencies
```sh
$ go get github.com/aws/aws-sdk-go-v2/aws
$ go get github.com/aws/aws-sdk-go-v2/config
$ go get github.com/aws/aws-sdk-go-v2/service/dynamodb
```

###### Write Code
In your preferred editor add the following content to `main.go`

```go
package main

import (
    &quot;context&quot;
    &quot;fmt&quot;
    &quot;log&quot;

    &quot;github.com/aws/aws-sdk-go-v2/aws&quot;
    &quot;github.com/aws/aws-sdk-go-v2/config&quot;
    &quot;github.com/aws/aws-sdk-go-v2/service/dynamodb&quot;
)

func main() {
    // Using the SDK&#039;s default configuration, load additional config
    // and credentials values from the environment variables, shared
    // credentials, and shared configuration files
    cfg, err := config.LoadDefaultConfig(context.TODO(), config.WithRegion(&quot;us-west-2&quot;))
    if err != nil {
        log.Fatalf(&quot;unable to load SDK config, %v&quot;, err)
    }

    // Using the Config value, create the DynamoDB client
    svc := dynamodb.NewFromConfig(cfg)

    // Build the request with its input parameters
    resp, err := svc.ListTables(context.TODO(), &amp;dynamodb.ListTablesInput{
        Limit: aws.Int32(5),
    })
    if err != nil {
        log.Fatalf(&quot;failed to list tables, %v&quot;, err)
    }

    fmt.Println(&quot;Tables:&quot;)
    for _, tableName := range resp.TableNames {
        fmt.Println(tableName)
    }
}
```

###### Compile and Execute
```sh
$ go run .
Tables:
tableOne
tableTwo
```

## Getting Help

Please use these community resources for getting help. We use the GitHub issues
for tracking bugs and feature requests.

* Ask us a [question](https://github.com/aws/aws-sdk-go-v2/discussions/new?category=q-a) or open a [discussion](https://github.com/aws/aws-sdk-go-v2/discussions/new?category=general).
* If you think you may have found a bug, please open an [issue](https://github.com/aws/aws-sdk-go-v2/issues/new/choose).
* Open a support ticket with [AWS Support](http://docs.aws.amazon.com/awssupport/latest/user/getting-started.html).

This SDK implements AWS service APIs. For general issues regarding the AWS services and their limitations, you may also take a look at the [Amazon Web Services Discussion Forums](https://forums.aws.amazon.com/).

### Opening Issues

If you encounter a bug with the AWS SDK for Go we would like to hear about it.
Search the [existing issues][Issues] and see
if others are also experiencing the same issue before opening a new issue. Please
include the version of AWS SDK for Go, Go language, and OS you‚Äôre using. Please
also include reproduction case when appropriate.

The GitHub issues are intended for bug reports and feature requests. For help
and questions with using AWS SDK for Go please make use of the resources listed
in the [Getting Help](#getting-help) section.
Keeping the list of open issues lean will help us respond in a timely manner.

## Feedback and contributing

The v2 SDK will use GitHub [Issues] to track feature requests and issues with the SDK. In addition, we&#039;ll use GitHub [Projects] to track large tasks spanning multiple pull requests, such as refactoring the SDK&#039;s internal request lifecycle. You can provide feedback to us in several ways.

**GitHub issues**. To provide feedback or report bugs, file GitHub [Issues] on the SDK. This is the preferred mechanism to give feedback so that other users can engage in the conversation, +1 issues, etc. Issues you open will be evaluated, and included in our roadmap for the GA launch.

**Contributing**. You can open pull requests for fixes or additions to the AWS SDK for Go 2.0. All pull requests must be submitted under the Apache 2.0 license and will be reviewed by an SDK team member before being merged in. Accompanying unit tests, where possible, are appreciated.

## Resources

[SDK Developer Guide](https://docs.aws.amazon.com/sdk-for-go/v2/developer-guide/welcome.html) - Use this document to learn how to get started and
use the AWS SDK for Go V2.


[SDK Migration Guide](https://docs.aws.amazon.com/sdk-for-go/v2/developer-guide/migrate-gosdk.html) - Use this document to learn how to migrate to V2 from the AWS SDK for Go.

[SDK API Reference Documentation](https://pkg.go.dev/mod/github.com/aws/aws-sdk-go-v2) - Use this
document to look up all API operation input and output parameters for AWS
services supported by the SDK. The API reference also includes documentation of
the SDK, and examples how to using the SDK, service client API operations, and
API operation require parameters.

[Service Documentation](https://aws.amazon.com/documentation/) - Use this
documentation to learn how to interface with AWS services. These guides are
great for getting started with a service, or when looking for more
information about a service. While this document is not required for coding,
services may supply helpful samples to look out for.

[Forum](https://forums.aws.amazon.com/forum.jspa?forumID=293) - Ask questions, get help, and give feedback

[Issues] - Report issues, submit pull requests, and get involved
  (see [Apache 2.0 License][license])

[Dep]: https://github.com/golang/dep
[Issues]: https://github.com/aws/aws-sdk-go-v2/issues
[Projects]: https://github.com/aws/aws-sdk-go-v2/projects
[CHANGELOG]: https://github.com/aws/aws-sdk-go-v2/blob/main/CHANGELOG.md
[Amazon DynamoDB]: https://aws.amazon.com/dynamodb/
[design]: https://github.com/aws/aws-sdk-go-v2/blob/main/DESIGN.md
[license]: http://aws.amazon.com/apache2.0/
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mudler/LocalAI]]></title>
            <link>https://github.com/mudler/LocalAI</link>
            <guid>https://github.com/mudler/LocalAI</guid>
            <pubDate>Fri, 05 Sep 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mudler/LocalAI">mudler/LocalAI</a></h1>
            <p>ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference</p>
            <p>Language: Go</p>
            <p>Stars: 35,037</p>
            <p>Forks: 2,734</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;img width=&quot;300&quot; src=&quot;./core/http/static/logo.png&quot;&gt; &lt;br&gt;
&lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/fork&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI forks&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/stargazers&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI stars&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/pulls&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI pull-requests&quot;/&gt;
&lt;/a&gt;
&lt;a href=&#039;https://github.com/go-skynet/LocalAI/releases&#039;&gt;
&lt;img src=&#039;https://img.shields.io/github/release/go-skynet/LocalAI?&amp;label=Latest&amp;style=for-the-badge&#039;&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://hub.docker.com/r/localai/localai&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker&quot; alt=&quot;LocalAI Docker hub&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;tag=latest&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/quay.io-images-important.svg?&quot; alt=&quot;LocalAI Quay.io&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://twitter.com/LocalAI_API&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white&amp;label=LocalAI_API&quot; alt=&quot;Follow LocalAI_API&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://discord.gg/uJAeKSAGDy&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://dcbadge.vercel.app/api/server/uJAeKSAGDy?style=flat-square&amp;theme=default-inverted&quot; alt=&quot;Join LocalAI Discord Community&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/5539&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/5539&quot; alt=&quot;mudler%2FLocalAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; :bulb: Get help - [‚ùìFAQ](https://localai.io/faq/) [üí≠Discussions](https://github.com/go-skynet/LocalAI/discussions) [:speech_balloon: Discord](https://discord.gg/uJAeKSAGDy) [:book: Documentation website](https://localai.io/)
&gt;
&gt; [üíª Quickstart](https://localai.io/basics/getting_started/) [üñºÔ∏è Models](https://models.localai.io/) [üöÄ Roadmap](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap) [ü•Ω Demo](https://demo.localai.io) [üåç Explorer](https://explorer.localai.io) [üõ´ Examples](https://github.com/mudler/LocalAI-examples) Try on 
[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;logo=telegram&amp;logoColor=white)](https://t.me/localaiofficial_bot)

[![tests](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml)[![Build and Release](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml)[![build container images](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml)[![Bump dependencies](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml)[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai)](https://artifacthub.io/packages/search?repo=localai)

**LocalAI** is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that&#039;s compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by [Ettore Di Giacinto](https://github.com/mudler).


## üìöüÜï Local Stack Family

üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:

&lt;table&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png&quot; width=&quot;300&quot; alt=&quot;LocalAGI Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI&#039;s Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png&quot; width=&quot;300&quot; alt=&quot;LocalRecall Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Screenshots


| Talk Interface | Generate Audio |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk](./docs/assets/images/screenshots/screenshot_tts.png) | ![Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low](./docs/assets/images/screenshots/screenshot_tts.png) |

| Models Overview | Generate Images |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-20 LocalAI - Models](./docs/assets/images/screenshots/screenshot_gallery.png) | ![Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev](./docs/assets/images/screenshots/screenshot_image.png) |

| Chat Interface | Home |
| --- | --- |
| ![Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5](./docs/assets/images/screenshots/screenshot_chat.png) | ![Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)](./docs/assets/images/screenshots/screenshot_home.png) |

| Login | Swarm |
| --- | --- |
|![Screenshot 2025-03-31 at 12-09-59 ](./docs/assets/images/screenshots/screenshot_login.png) | ![Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard](./docs/assets/images/screenshots/screenshot_p2p.png) |

## üíª Quickstart

Run the installer script:

```bash
# Basic installation
curl https://localai.io/install.sh | sh
```

For more installation options, see [Installer Options](https://localai.io/docs/advanced/installer/).

Or run with docker:

### CPU only image:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
```

### NVIDIA GPU Images:

```bash
# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# CUDA 11.7
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-11

# NVIDIA Jetson (L4T) ARM64
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64
```

### AMD GPU Images (ROCm):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
```

### Intel GPU Images (oneAPI):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
```

### Vulkan GPU Images:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
```

### AIO Images (pre-downloaded models):

```bash
# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# NVIDIA CUDA 11 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-11

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
```

For more information about the AIO images and pre-downloaded models, see [Container Documentation](https://localai.io/basics/container/).

To load models:

```bash
# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
```

&gt; ‚ö° **Automatic Backend Detection**: When you install models from the gallery or YAML files, LocalAI automatically detects your system&#039;s GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see [GPU Acceleration](https://localai.io/features/gpu-acceleration/#automatic-backend-detection).

For more information, see [üíª Getting started](https://localai.io/basics/getting_started/index.html)

## üì∞ Latest project news

- August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with `development` suffix in the gallery ): https://github.com/mudler/LocalAI/pull/6049 https://github.com/mudler/LocalAI/pull/6119 https://github.com/mudler/LocalAI/pull/6121 https://github.com/mudler/LocalAI/pull/6060
- July/August 2025: üîç [Object Detection](https://localai.io/features/object-detection/) added to the API featuring [rf-detr](https://github.com/roboflow/rf-detr)
- July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. [Read the release notes](https://github.com/mudler/LocalAI/releases/tag/v3.2.0)
- June 2025: [Backend management](https://github.com/mudler/LocalAI/pull/5607) has been added. Attention: extras images are going to be deprecated from the next release! Read [the backend management PR](https://github.com/mudler/LocalAI/pull/5607).
- May 2025: [Audio input](https://github.com/mudler/LocalAI/pull/5466) and [Reranking](https://github.com/mudler/LocalAI/pull/5396) in llama.cpp backend, [Realtime API](https://github.com/mudler/LocalAI/pull/5392),  Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).
- May 2025: Important: image name changes [See release](https://github.com/mudler/LocalAI/releases/tag/v2.29.0)
- Apr 2025: Rebrand, WebUI enhancements
- Apr 2025: [LocalAGI](https://github.com/mudler/LocalAGI) and [LocalRecall](https://github.com/mudler/LocalRecall) join the LocalAI family stack.
- Apr 2025: WebUI overhaul, AIO images updates
- Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images
- Jan 2025: LocalAI model release: https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3, SANA support in diffusers: https://github.com/mudler/LocalAI/pull/4603
- Dec 2024: stablediffusion.cpp backend (ggml) added ( https://github.com/mudler/LocalAI/pull/4289 )
- Nov 2024: Bark.cpp backend added ( https://github.com/mudler/LocalAI/pull/4287 )
- Nov 2024: Voice activity detection models (**VAD**) added to the API: https://github.com/mudler/LocalAI/pull/4204
- Oct 2024: examples moved to [LocalAI-examples](https://github.com/mudler/LocalAI-examples)
- Aug 2024:  üÜï FLUX-1, [P2P Explorer](https://explorer.localai.io)
- July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: https://github.com/mudler/LocalAI/pull/2723. P2P Global community pools: https://github.com/mudler/LocalAI/issues/3113
- May 2024: üî•üî• Decentralized P2P llama.cpp:  https://github.com/mudler/LocalAI/pull/2343 (peer2peer llama.cpp!) üëâ Docs  https://localai.io/features/distribute/
- May 2024: üî•üî• Distributed inferencing: https://github.com/mudler/LocalAI/pull/2324
- April 2024: Reranker API: https://github.com/mudler/LocalAI/pull/2121

Roadmap items: [List of issues](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)

## üöÄ [Features](https://localai.io/features/)

- üß© [Backend Gallery](https://localai.io/backends/): Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.
- üìñ [Text generation with GPTs](https://localai.io/features/text-generation/) (`llama.cpp`, `transformers`, `vllm` ... [:book: and more](https://localai.io/model-compatibility/index.html#model-compatibility-table))
- üó£ [Text to Audio](https://localai.io/features/text-to-audio/)
- üîà [Audio to Text](https://localai.io/features/audio-to-text/) (Audio transcription with `whisper.cpp`)
- üé® [Image generation](https://localai.io/features/image-generation)
- üî• [OpenAI-alike tools API](https://localai.io/features/openai-functions/) 
- üß† [Embeddings generation for vector databases](https://localai.io/features/embeddings/)
- ‚úçÔ∏è [Constrained grammars](https://localai.io/features/constrained_grammars/)
- üñºÔ∏è [Download Models directly from Huggingface ](https://localai.io/models/)
- ü•Ω [Vision API](https://localai.io/features/gpt-vision/)
- üîç [Object Detection](https://localai.io/features/object-detection/)
- üìà [Reranker API](https://localai.io/features/reranker/)
- üÜïüñß [P2P Inferencing](https://localai.io/features/distribute/)
- [Agentic capabilities](https://github.com/mudler/LocalAGI)
- üîä Voice activity detection (Silero-VAD support)
- üåç Integrated WebUI!

## üß© Supported Backends &amp; Acceleration

LocalAI supports a comprehensive range of AI backends with multiple acceleration options:

### Text Generation &amp; Language Models
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **llama.cpp** | LLM inference in C/C++ | CUDA 11/12, ROCm, Intel SYCL, Vulkan, Metal, CPU |
| **vLLM** | Fast LLM inference with PagedAttention | CUDA 12, ROCm, Intel |
| **transformers** | HuggingFace transformers framework | CUDA 11/12, ROCm, Intel, CPU |
| **exllama2** | GPTQ inference library | CUDA 12 |
| **MLX** | Apple Silicon LLM inference | Metal (M1/M2/M3+) |
| **MLX-VLM** | Apple Silicon Vision-Language Models | Metal (M1/M2/M3+) |

### Audio &amp; Speech Processing
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **whisper.cpp** | OpenAI Whisper in C/C++ | CUDA 12, ROCm, Intel SYCL, Vulkan, CPU |
| **faster-whisper** | Fast Whisper with CTranslate2 | CUDA 12, ROCm, Intel, CPU |
| **bark** | Text-to-audio generation | CUDA 12, ROCm, Intel |
| **bark-cpp** | C++ implementation of Bark | CUDA, Metal, CPU |
| **coqui** | Advanced TTS with 1100+ languages | CUDA 12, ROCm, Intel, CPU |
| **kokoro** | Lightweight TTS model | CUDA 12, ROCm, Intel, CPU |
| **chatterbox** | Production-grade TTS | CUDA 11/12, CPU |
| **piper** | Fast neural TTS system | CPU |
| **kitten-tts** | Kitten TTS models | CPU |
| **silero-vad** | Voice Activity Detection | CPU |

### Image &amp; Video Generation
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **stablediffusion.cpp** | Stable Diffusion in C/C++ | CUDA 12, Intel SYCL, Vulkan, CPU |
| **diffusers** | HuggingFace diffusion models | CUDA 11/12, ROCm, Intel, Metal, CPU |

### Specialized AI Tasks
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **rfdetr** | Real-time object detection | CUDA 12, Intel, CPU |
| **rerankers** | Document reranking API | CUDA 11/12, ROCm, Intel, CPU |
| **local-store** | Vector database | CPU |
| **huggingface** | HuggingFace API integration | API-based |

### Hardware Acceleration Matrix

| Acceleration Type | Supported Backends | Hardware Support |
|-------------------|-------------------|------------------|
| **NVIDIA CUDA 11** | llama.cpp, whisper, stablediffusion, diffusers, rerankers, bark, chatterbox | Nvidia hardware |
| **NVIDIA CUDA 12** | All CUDA-compatible backends | Nvidia hardware |
| **AMD ROCm** | llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark | AMD Graphics |
| **Intel oneAPI** | llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark | Intel Arc, Intel iGPUs |
| **Apple Metal** | llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp | Apple M1/M2/M3+ |
| **Vulkan** | llama.cpp, whisper, stablediffusion | Cross-platform GPUs |
| **NVIDIA Jetson** | llama.cpp, whisper, stablediffusion, diffusers, rfdetr | ARM64 embedded AI |
| **CPU Optimized** | All backends | AVX/AVX2/AVX512, quantization support |

### üîó Community and integrations

Build and deploy custom containers:
- https://github.com/sozercan/aikit

WebUIs:
- https://github.com/Jirubizu/localai-admin
- https://github.com/go-skynet/LocalAI-frontend
- QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) https://github.com/reid41/QA-Pilot

Model galleries
- https://github.com/go-skynet/model-gallery

Voice:
- https://github.com/richiejp/VoxInput

Other:
- Helm chart https://github.com/go-skynet/helm-charts
- VSCode extension https://github.com/badgooooor/localai-vscode-plugin
- Langchain: https://python.langchain.com/docs/integrations/providers/localai/
- Terminal utility https://github.com/djcopley/ShellOracle
- Local Smart assistant https://github.com/mudler/LocalAGI
- Home Assistant https://github.com/sammcj/homeassistant-localai / https://github.com/drndos/hass-openai-custom-conversation / https://github.com/valentinfrlch/ha-gpt4vision
- Discord bot https://github.com/mudler/LocalAGI/tree/main/examples/discord
- Slack bot https://github.com/mudler/LocalAGI/tree/main/examples/slack
- Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) https://github.com/reid41/shell-pilot
- Telegram bot https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot
- Another Telegram Bot https://github.com/JackBekket/Hellper
- Auto-documentation https://github.com/JackBekket/Reflexia
- Github bot which answer on issues, with code and documentation as context https://github.com/JackBekket/GitHelper
- Github Actions: https://github.com/marketplace/actions/start-localai
- Examples: https://github.com/mudler/LocalAI/tree/master/examples/
  

### üîó Resources

- [LLM finetuning guide](https://localai.io/docs/advanced/fine-tuning/)
- [How to build locally](https://localai.io/basics/build/index.html)
- [How to install in Kubernetes](https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes)
- [Projects integrating LocalAI](https://localai.io/docs/integrations/)
- [How tos section](https://io.midori-ai.xyz/howtos/) (curated by our community)

## :book: üé• [Media, Blogs, Social](https://localai.io/basics/news/#media-blogs-social)

- [Run Visual studio code with LocalAI (SUSE)](https://www.suse.com/c/running-ai-locally/)
- üÜï [Run LocalAI on Jetson Nano Devkit](https://mudler.pm/posts/local-ai-jetson-nano-devkit/)
- [Run LocalAI on AWS EKS with Pulumi](https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/)
- [Run LocalAI on AWS](https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance)
- [Create a slackbot for teams and OSS projects that answer to documentation](https://mudler.pm/posts/smart-slackbot-for-teams/)
- [LocalAI meets k8sgpt](https://www.youtube.com/watch?v=PKrDNuJ_dfE)
- [Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All](https://mudler.pm/posts/localai-question-answering/)
-

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hashicorp/consul]]></title>
            <link>https://github.com/hashicorp/consul</link>
            <guid>https://github.com/hashicorp/consul</guid>
            <pubDate>Fri, 05 Sep 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[Consul is a distributed, highly available, and data center aware solution to connect and configure applications across dynamic, distributed infrastructure.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hashicorp/consul">hashicorp/consul</a></h1>
            <p>Consul is a distributed, highly available, and data center aware solution to connect and configure applications across dynamic, distributed infrastructure.</p>
            <p>Language: Go</p>
            <p>Stars: 29,274</p>
            <p>Forks: 4,512</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;
  &lt;img src=&quot;./website/public/img/logo.svg&quot; align=&quot;left&quot; height=&quot;46px&quot; alt=&quot;Consul logo&quot;/&gt;
  &lt;span&gt;Consul&lt;/span&gt;
&lt;/h1&gt;

[![License: BUSL-1.1](https://img.shields.io/badge/License-BUSL--1.1-yellow.svg)](LICENSE)
[![Docker Pulls](https://img.shields.io/docker/pulls/hashicorp/consul.svg)](https://hub.docker.com/r/hashicorp/consul)
[![Go Report Card](https://goreportcard.com/badge/github.com/hashicorp/consul)](https://goreportcard.com/report/github.com/hashicorp/consul)

Consul is a distributed, highly available, and data center aware solution to connect and configure applications across dynamic, distributed infrastructure.

* Documentation and Tutorials: [https://developer.hashicorp.com/consul]
* Forum: [Discuss](https://discuss.hashicorp.com/c/consul)

Consul provides several key features:

* **Multi-Datacenter** - Consul is built to be datacenter aware, and can
  support any number of regions without complex configuration.

* **Service Mesh** - Consul Service Mesh enables secure service-to-service
  communication with automatic TLS encryption and identity-based authorization. Applications
  can use sidecar proxies in a service mesh configuration to establish TLS
  connections for inbound and outbound connections with Transparent Proxy.

* **API Gateway** - Consul API Gateway manages access to services within Consul Service Mesh, 
  allow users to define traffic and authorization policies to services deployed within the mesh.  

* **Service Discovery** - Consul makes it simple for services to register
  themselves and to discover other services via a DNS or HTTP interface.
  External services such as SaaS providers can be registered as well.

* **Health Checking** - Health Checking enables Consul to quickly alert
  operators about any issues in a cluster. The integration with service
  discovery prevents routing traffic to unhealthy hosts and enables service
  level circuit breakers.

* **Dynamic App Configuration** - An HTTP API that allows users to store indexed objects within Consul,
  for storing configuration parameters and application metadata.

Consul runs on Linux, macOS, FreeBSD, Solaris, and Windows and includes an
optional [browser based UI](https://demo.consul.io). A commercial version
called [Consul Enterprise](https://developer.hashicorp.com/docs/enterprise) is also
available.

**Please note**: We take Consul&#039;s security and our users&#039; trust very seriously. If you
believe you have found a security issue in Consul, please [responsibly disclose](https://www.hashicorp.com/security#vulnerability-reporting)
by contacting us at security@hashicorp.com.

## Quick Start

A few quick start guides are available on the Consul website:

* **Standalone binary install:** https://learn.hashicorp.com/collections/consul/get-started-vms
* **Minikube install:** https://learn.hashicorp.com/tutorials/consul/kubernetes-minikube
* **Kind install:** https://learn.hashicorp.com/tutorials/consul/kubernetes-kind
* **Kubernetes install:** https://learn.hashicorp.com/tutorials/consul/kubernetes-deployment-guide
* **Deploy HCP Consul:** https://learn.hashicorp.com/tutorials/consul/hcp-gs-deploy 

## Documentation

Full, comprehensive documentation is available on the Consul website: https://developer.hashicorp.com/consul/docs

## Contributing

Thank you for your interest in contributing! Please refer to [CONTRIBUTING.md](https://github.com/hashicorp/consul/blob/main/.github/CONTRIBUTING.md)
for guidance. For contributions specifically to the browser based UI, please
refer to the UI&#039;s [README.md](https://github.com/hashicorp/consul/blob/main/ui/packages/consul-ui/README.md)
for guidance.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes/kubernetes]]></title>
            <link>https://github.com/kubernetes/kubernetes</link>
            <guid>https://github.com/kubernetes/kubernetes</guid>
            <pubDate>Fri, 05 Sep 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[Production-Grade Container Scheduling and Management]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes/kubernetes">kubernetes/kubernetes</a></h1>
            <p>Production-Grade Container Scheduling and Management</p>
            <p>Language: Go</p>
            <p>Stars: 117,270</p>
            <p>Forks: 41,291</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre># Kubernetes (K8s)

[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/569/badge)](https://bestpractices.coreinfrastructure.org/projects/569) [![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/kubernetes)](https://goreportcard.com/report/github.com/kubernetes/kubernetes) ![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/kubernetes/kubernetes?sort=semver)

&lt;img src=&quot;https://github.com/kubernetes/kubernetes/raw/master/logo/logo.png&quot; width=&quot;100&quot;&gt;

----

Kubernetes, also known as K8s, is an open source system for managing [containerized applications]
across multiple hosts. It provides basic mechanisms for the deployment, maintenance,
and scaling of applications.

Kubernetes builds upon a decade and a half of experience at Google running
production workloads at scale using a system called [Borg],
combined with best-of-breed ideas and practices from the community.

Kubernetes is hosted by the Cloud Native Computing Foundation ([CNCF]).
If your company wants to help shape the evolution of
technologies that are container-packaged, dynamically scheduled,
and microservices-oriented, consider joining the CNCF.
For details about who&#039;s involved and how Kubernetes plays a role,
read the CNCF [announcement].

----

## To start using K8s

See our documentation on [kubernetes.io].

Take a free course on [Scalable Microservices with Kubernetes].

To use Kubernetes code as a library in other applications, see the [list of published components](https://git.k8s.io/kubernetes/staging/README.md).
Use of the `k8s.io/kubernetes` module or `k8s.io/kubernetes/...` packages as libraries is not supported.

## To start developing K8s

The [community repository] hosts all information about
building Kubernetes from source, how to contribute code
and documentation, who to contact about what, etc.

If you want to build Kubernetes right away there are two options:

##### You have a working [Go environment].

```
git clone https://github.com/kubernetes/kubernetes
cd kubernetes
make
```

##### You have a working [Docker environment].

```
git clone https://github.com/kubernetes/kubernetes
cd kubernetes
make quick-release
```

For the full story, head over to the [developer&#039;s documentation].

## Support

If you need support, start with the [troubleshooting guide],
and work your way through the process that we&#039;ve outlined.

That said, if you have questions, reach out to us
[one way or another][communication].

[announcement]: https://cncf.io/news/announcement/2015/07/new-cloud-native-computing-foundation-drive-alignment-among-container
[Borg]: https://research.google.com/pubs/pub43438.html?authuser=1
[CNCF]: https://www.cncf.io/about
[communication]: https://git.k8s.io/community/communication
[community repository]: https://git.k8s.io/community
[containerized applications]: https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/
[developer&#039;s documentation]: https://git.k8s.io/community/contributors/devel#readme
[Docker environment]: https://docs.docker.com/engine
[Go environment]: https://go.dev/doc/install
[kubernetes.io]: https://kubernetes.io
[Scalable Microservices with Kubernetes]: https://www.udacity.com/course/scalable-microservices-with-kubernetes--ud615
[troubleshooting guide]: https://kubernetes.io/docs/tasks/debug/

## Community Meetings 

The [Calendar](https://www.kubernetes.dev/resources/calendar/) has the list of all the meetings in the Kubernetes community in a single location.

## Adopters

The [User Case Studies](https://kubernetes.io/case-studies/) website has real-world use cases of organizations across industries that are deploying/migrating to Kubernetes.

## Governance 

Kubernetes project is governed by a framework of principles, values, policies and processes to help our community and constituents towards our shared goals.

The [Kubernetes Community](https://github.com/kubernetes/community/blob/master/governance.md) is the launching point for learning about how we organize ourselves.

The [Kubernetes Steering community repo](https://github.com/kubernetes/steering) is used by the Kubernetes Steering Committee, which oversees governance of the Kubernetes project.

## Roadmap 

The [Kubernetes Enhancements repo](https://github.com/kubernetes/enhancements) provides information about Kubernetes releases, as well as feature tracking and backlogs.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[DataDog/datadog-agent]]></title>
            <link>https://github.com/DataDog/datadog-agent</link>
            <guid>https://github.com/DataDog/datadog-agent</guid>
            <pubDate>Fri, 05 Sep 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[Main repository for Datadog Agent]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DataDog/datadog-agent">DataDog/datadog-agent</a></h1>
            <p>Main repository for Datadog Agent</p>
            <p>Language: Go</p>
            <p>Stars: 3,224</p>
            <p>Forks: 1,324</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># Datadog Agent

[![Coverage status](https://codecov.io/github/DataDog/datadog-agent/coverage.svg?branch=main)](https://codecov.io/github/DataDog/datadog-agent?branch=main)
[![GoDoc](https://godoc.org/github.com/DataDog/datadog-agent?status.svg)](https://godoc.org/github.com/DataDog/datadog-agent)

This repository contains the source code of the Datadog Agent version 7 and version 6. Please refer to the [Agent user documentation](https://docs.datadoghq.com/agent/) for information about differences between Agent v5, Agent v6 and Agent v7. Additionally, we provide a list of prepackaged binaries for an easy install process [here](https://app.datadoghq.com/fleet/install-agent/latest?platform=overview).

## Documentation

The [developer docs site](https://datadoghq.dev/datadog-agent/setup/) contains information about how to develop the Datadog Agent itself.

The source of the content is located under [the docs directory](docs) and may contain pages that are not yet published.

## Contributing code

You&#039;ll find information and help on how to contribute code to this project under
[the `docs/dev` directory](docs/dev) of the present repo.

## License

The Datadog Agent user space components are licensed under the
[Apache License, Version 2.0](LICENSE). The BPF code is licensed
under the [General Public License, Version 2.0](pkg/ebpf/c/COPYING).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Project-HAMi/HAMi]]></title>
            <link>https://github.com/Project-HAMi/HAMi</link>
            <guid>https://github.com/Project-HAMi/HAMi</guid>
            <pubDate>Fri, 05 Sep 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[Heterogeneous AI Computing Virtualization Middleware(Project under CNCF)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Project-HAMi/HAMi">Project-HAMi/HAMi</a></h1>
            <p>Heterogeneous AI Computing Virtualization Middleware(Project under CNCF)</p>
            <p>Language: Go</p>
            <p>Stars: 2,072</p>
            <p>Forks: 364</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>English version | [‰∏≠ÊñáÁâà](README_cn.md)

&lt;img src=&quot;imgs/hami-horizontal-colordark.png&quot; width=&quot;600px&quot;&gt;

[![LICENSE](https://img.shields.io/github/license/Project-HAMi/HAMi.svg)](/LICENSE)
[![build status](https://github.com/Project-HAMi/HAMi/actions/workflows/ci.yaml/badge.svg)](https://github.com/Project-HAMi/HAMi/actions/workflows/ci.yaml)
[![Releases](https://img.shields.io/github/v/release/Project-HAMi/HAMi)](https://github.com/Project-HAMi/HAMi/releases/latest)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9416/badge)](https://www.bestpractices.dev/en/projects/9416)
[![Go Report Card](https://goreportcard.com/badge/github.com/Project-HAMi/HAMi)](https://goreportcard.com/report/github.com/Project-HAMi/HAMi)
[![codecov](https://codecov.io/gh/Project-HAMi/HAMi/branch/master/graph/badge.svg?token=ROM8CMPXZ6)](https://codecov.io/gh/Project-HAMi/HAMi)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2FProject-HAMi%2FHAMi.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2FProject-HAMi%2FHAMi?ref=badge_shield)
[![docker pulls](https://img.shields.io/docker/pulls/projecthami/hami.svg)](https://hub.docker.com/r/projecthami/hami)
[![slack](https://img.shields.io/badge/Slack-Join%20Slack-blue)](https://cloud-native.slack.com/archives/C07T10BU4R2)
[![discuss](https://img.shields.io/badge/Discuss-Ask%20Questions-blue)](https://github.com/Project-HAMi/HAMi/discussions)
[![website](https://img.shields.io/badge/website-blue)](http://project-hami.io)
[![Contact Me](https://img.shields.io/badge/Contact%20Me-blue)](https://github.com/Project-HAMi/HAMi#contact)

## Project-HAMi: Heterogeneous AI Computing Virtualization Middleware

## Introduction

HAMi, formerly known as &#039;k8s-vGPU-scheduler&#039;, is a Heterogeneous device management middleware for Kubernetes. It can manage different types of heterogeneous devices (like GPU, NPU, etc.), share heterogeneous devices among pods, make better scheduling decisions based on topology of devices and scheduling policies.

It aims to remove the gap between different Heterogeneous devices, and provide a unified interface for users to manage with no changes to their applications. As of December 2024, HAMi has been widely used not only in Internet, public cloud and private cloud, but also broadly adopted in various vertical industries including finance, securities, energy, telecommunications, education, and manufacturing. More than 50 companies or institutions are not only end users but also active contributors. 

![cncf_logo](imgs/cncf-logo.png)

HAMi is a sandbox and [landscape](https://landscape.cncf.io/?item=orchestration-management--scheduling-orchestration--hami) project of  
[Cloud Native Computing Foundation](https://cncf.io/)(CNCF), 
[CNAI Landscape project](https://landscape.cncf.io/?group=cnai&amp;item=cnai--general-orchestration--hami).


## Device virtualization

HAMi provides device virtualization for several heterogeneous devices including GPU, by supporting device sharing and device resource isolation. For the list of devices supporting device virtualization, see [supported devices](#supported-devices)

### Device sharing

- Allows partial device allocation by specifying device core usage.
- Allows partial device allocation by specifying device memory.
- Imposes a hard limit on streaming multiprocessors.
- Requires zero changes to existing programs.
- Support [dynamic-mig](docs/dynamic-mig-support.md) feature, [example](examples/nvidia/dynamic_mig_example.yaml)

&lt;img src=&quot;./imgs/example.png&quot; width = &quot;500&quot; /&gt; 

### Device Resources Isolation

A simple demonstration of device isolation:
A task with the following resources will see 3000M device memory inside container:

```yaml
      resources:
        limits:
          nvidia.com/gpu: 1 # declare how many physical GPUs the pod needs
          nvidia.com/gpumem: 3000 # identifies 3G GPU memory each physical GPU allocates to the pod
```

![img](./imgs/hard_limit.jpg)

&gt; Note:
1. **After installing HAMi, the value of `nvidia.com/gpu` registered on the node defaults to the number of vGPUs.**
2. **When requesting resources in a pod, `nvidia.com/gpu` refers to the number of physical GPUs required by the current pod.**

### Supported devices

[NVIDIA GPU](https://github.com/Project-HAMi/HAMi#preparing-your-gpu-nodes)   
[Cambricon MLU](docs/cambricon-mlu-support.md)   
[HYGON DCU](docs/hygon-dcu-support.md)   
[Iluvatar CoreX GPU](docs/iluvatar-gpu-support.md)   
[Moore Threads GPU](docs/mthreads-support.md)   
[HUAWEI Ascend NPU](https://github.com/Project-HAMi/ascend-device-plugin/blob/main/README.md)   
[MetaX GPU](docs/metax-support.md)   

## Architect

&lt;img src=&quot;./imgs/hami-arch.png&quot; width = &quot;600&quot; /&gt; 

HAMi consists of several components, including a unified mutatingwebhook, a unified scheduler extender, different device-plugins and different in-container virtualization technics for each heterogeneous AI devices.

## Quick Start

### Choose your orchestrator

[![kube-scheduler](https://img.shields.io/badge/kube-scheduler-blue)](#prerequisites)
[![volcano-scheduler](https://img.shields.io/badge/volcano-scheduler-orange)](docs/how-to-use-volcano-vgpu.md)

### Prerequisites

The list of prerequisites for running the NVIDIA device plugin is described below:

- NVIDIA drivers &gt;= 440
- nvidia-docker version &gt; 2.0
- default runtime configured as nvidia for containerd/docker/cri-o container runtime
- Kubernetes version &gt;= 1.18
- glibc &gt;= 2.17 &amp; glibc &lt; 2.30
- kernel version &gt;= 3.10
- helm &gt; 3.0

### Install

First, Label your GPU nodes for scheduling with HAMi by adding the label &quot;gpu=on&quot;. Without this label, the nodes cannot be managed by our scheduler.

```
kubectl label nodes {nodeid} gpu=on
```

Add our repo in helm

```
helm repo add hami-charts https://project-hami.github.io/HAMi/
```

Use the following command for deployment:

```
helm install hami hami-charts/hami -n kube-system
```

Customize your installation by adjusting the [configs](docs/config.md).

Verify your installation using the following command:

```
kubectl get pods -n kube-system
```

If both `hami-device-plugin` (formerly known as `vgpu-device-plugin`)  and `hami-scheduler` (formerly known as `vgpu-scheduler`)  pods are in the *Running* state, your installation is successful. You can try examples [here](examples/nvidia/default_use.yaml) 

### WebUI

[HAMi-WebUI](https://github.com/Project-HAMi/HAMi-WebUI) is available after HAMi v2.4

For installation guide, click [here](https://github.com/Project-HAMi/HAMi-WebUI/blob/main/docs/installation/helm/index.md)

### Monitor

Monitoring is automatically enabled after installation. Obtain an overview of cluster information by visiting the following URL:

```
http://{scheduler ip}:{monitorPort}/metrics
```

The default monitorPort is 31993; other values can be set using `--set devicePlugin.service.httpPort` during installation.

Grafana dashboard [example](docs/dashboard.md)

&gt; **Note** The status of a node won&#039;t be collected before you submit a task

## Notes

- If you don&#039;t request vGPUs when using the device plugin with NVIDIA images all the GPUs on the machine may be exposed inside your container
- Currently, A100 MIG can be supported in only &quot;none&quot; and &quot;mixed&quot; modes.
- Tasks with the &quot;nodeName&quot; field cannot be scheduled at the moment; please use &quot;nodeSelector&quot; instead.

## RoadMap, Governance &amp; Contributing

The project is governed by a group of [Maintainers](./MAINTAINERS.md) and [Contributors](./AUTHORS.md). How they are selected and govern is outlined in our [Governance Document](https://github.com/Project-HAMi/community/blob/main/governance.md).

If you&#039;re interested in being a contributor and want to get involved in developing the HAMi code, please see [CONTRIBUTING](CONTRIBUTING.md) for details on submitting patches and the contribution workflow.

See [RoadMap](docs/develop/roadmap.md) to see anything you interested.

## Meeting &amp; Contact

The HAMi community is committed to fostering an open and welcoming environment, with several ways to engage with other users and developers.

If you have any questions, please feel free to reach out to us through the following channels:

- Regular Community Meeting: Friday at 16:00 UTC+8 (Chinese)(weekly). [Convert to your timezone](https://www.thetimezoneconverter.com/?t=14%3A30&amp;tz=GMT%2B8&amp;).
  - [Meeting Notes and Agenda](https://docs.google.com/document/d/1YC6hco03_oXbF9IOUPJ29VWEddmITIKIfSmBX8JtGBw/edit#heading=h.g61sgp7w0d0c)
  - [Meeting Link](https://meeting.tencent.com/dm/Ntiwq1BICD1P)
- Email: refer to the [MAINTAINERS.md](MAINTAINERS.md) to find the email addresses of all maintainers. Feel free to contact them via email to report any issues or ask questions.
- [mailing list](https://groups.google.com/forum/#!forum/hami-project)
- [slack](https://cloud-native.slack.com/archives/C07T10BU4R2) | [Join](https://slack.cncf.io/)

## Talks and References

|                  | Link                                                                                                                    |
|------------------|-------------------------------------------------------------------------------------------------------------------------|
| CHINA CLOUD COMPUTING INFRASTRUCTURE DEVELOPER CONFERENCE (Beijing 2024) | [Unlocking heterogeneous AI infrastructure on k8s clusters](https://live.csdn.net/room/csdnnews/3zwDP09S) Starting from 03:06:15 |
| KubeDay(Japan 2024) | [Unlocking Heterogeneous AI Infrastructure K8s Cluster:Leveraging the Power of HAMi](https://www.youtube.com/watch?v=owoaSb4nZwg) |
| KubeCon &amp; AI_dev Open Source GenAI &amp; ML Summit(China 2024) | [Is Your GPU Really Working Efficiently in the Data Center?N Ways to Improve GPU Usage](https://www.youtube.com/watch?v=ApkyK3zLF5Q) |
| KubeCon &amp; AI_dev Open Source GenAI &amp; ML Summit(China 2024) | [Unlocking Heterogeneous AI Infrastructure K8s Cluster](https://www.youtube.com/watch?v=kcGXnp_QShs)                                     |
| KubeCon(EU 2024)| [Cloud Native Batch Computing with Volcano: Updates and Future](https://youtu.be/fVYKk6xSOsw) |

## License

HAMi is under the Apache 2.0 license. See the [LICENSE](LICENSE) file for details.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Project-HAMi/HAMi&amp;type=Date)](https://star-history.com/#Project-HAMi/HAMi&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hashicorp/vault]]></title>
            <link>https://github.com/hashicorp/vault</link>
            <guid>https://github.com/hashicorp/vault</guid>
            <pubDate>Fri, 05 Sep 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[A tool for secrets management, encryption as a service, and privileged access management]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hashicorp/vault">hashicorp/vault</a></h1>
            <p>A tool for secrets management, encryption as a service, and privileged access management</p>
            <p>Language: Go</p>
            <p>Stars: 33,059</p>
            <p>Forks: 4,428</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># Vault [![build](https://github.com/hashicorp/vault/actions/workflows/build.yml/badge.svg)](https://github.com/hashicorp/vault/actions/workflows/build.yml) [![ci](https://github.com/hashicorp/vault/actions/workflows/ci.yml/badge.svg)](https://github.com/hashicorp/vault/actions/workflows/ci.yml)  [![vault enterprise](https://img.shields.io/badge/vault-enterprise-yellow.svg?colorB=7c8797&amp;colorA=000000)](https://www.hashicorp.com/products/vault/?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=github-vault-enterprise)

----

**Please note**: We take Vault&#039;s security and our users&#039; trust very seriously. If you believe you have found a security issue in Vault, _please responsibly disclose_ by contacting us at [security@hashicorp.com](mailto:security@hashicorp.com).

----

- Website: [developer.hashicorp.com/vault](https://developer.hashicorp.com/vault)
- Announcement list: [Google Groups](https://groups.google.com/group/hashicorp-announce)
- Discussion forum: [Discuss](https://discuss.hashicorp.com/c/vault)
- Documentation: [https://developer.hashicorp.com/vault/docs](https://developer.hashicorp.com/vault/docs)
- Tutorials: [https://developer.hashicorp.com/vault/tutorials](https://developer.hashicorp.com/vault/tutorials)
- Certification exam: [https://developer.hashicorp.com/certifications/security-automation](https://developer.hashicorp.com/certifications/security-automation)

&lt;img width=&quot;300&quot; alt=&quot;Vault Logo&quot; src=&quot;https://github.com/hashicorp/vault/blob/f22d202cde2018f9455dec755118a9b84586e082/Vault_PrimaryLogo_Black.png&quot;&gt;

Vault is a tool for securely accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, and more. Vault provides a unified interface to any secret, while providing tight access control and recording a detailed audit log.

A modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where Vault steps in.

The key features of Vault are:

* **Secure Secret Storage**: Vault can store arbitrary key/value pairs. Vault encrypts data before writing it to persistent
  storage, so gaining access to the raw storage isn&#039;t enough to access
  your secrets. Vault can write to disk, [Consul](https://www.consul.io),
  and more.

* **Dynamic Secrets**: Vault can generate secrets on-demand for some
  systems, such as AWS or SQL databases. For example, when an application
  needs to access an S3 bucket, it asks Vault for credentials, and Vault
  will generate an AWS keypair with valid permissions on demand. After
  creating these dynamic secrets, Vault will also automatically revoke them
  after the lease is up.

* **Data Encryption**: Vault can encrypt and decrypt data without storing
  it. This allows security teams to define encryption parameters and
  developers to store encrypted data in a location such as a SQL database without
  having to design their own encryption methods.

* **Leasing and Renewal**: Vault associates a **lease** with each secret.
  At the end of the lease, Vault automatically revokes the
  secret. Clients are able to renew leases via built-in renew APIs.

* **Revocation**: Vault has built-in support for secret revocation. Vault
  can revoke not only single secrets, but a tree of secrets, for example,
  all secrets read by a specific user, or all secrets of a particular type.
  Revocation assists in key rolling as well as locking down systems in the
  case of an intrusion.

Documentation, Getting Started, and Certification Exams
-------------------------------

Documentation is available on the [Vault website](https://developer.hashicorp.com/vault/docs).

If you&#039;re new to Vault and want to get started with security automation, please
check out our [Getting Started guides](https://learn.hashicorp.com/collections/vault/getting-started)
on HashiCorp&#039;s learning platform. There are also [additional guides](https://learn.hashicorp.com/vault)
to continue your learning.

For examples of how to interact with Vault from inside your application in different programming languages, see the [vault-examples](https://github.com/hashicorp/vault-examples) repo. An out-of-the-box [sample application](https://github.com/hashicorp/hello-vault-go) is also available.

Show off your Vault knowledge by passing a certification exam. Visit the
[certification page](https://www.hashicorp.com/certification/#hashicorp-certified-vault-associate)
for information about exams and find [study materials](https://learn.hashicorp.com/collections/vault/certification)
on HashiCorp&#039;s learning platform.

Developing Vault
--------------------

If you wish to work on Vault itself or any of its built-in systems, you&#039;ll
first need [Go](https://www.golang.org) installed on your machine.

For local dev first make sure Go is properly installed, including setting up a
[GOPATH](https://golang.org/doc/code.html#GOPATH), then setting the 
[GOBIN](https://pkg.go.dev/cmd/go#hdr-Environment_variables) variable to `$GOPATH/bin`. 
Ensure that `$GOPATH/bin` is in your path as some distributions bundle the old version 
of build tools. 

Next, clone this repository. Vault uses [Go Modules](https://github.com/golang/go/wiki/Modules),
so it is recommended that you clone the repository ***outside*** of the GOPATH.
You can then download any required build tools by bootstrapping your environment:

```sh
$ make bootstrap
...
```

To compile a development version of Vault, run `make` or `make dev`. This will
put the Vault binary in the `bin` and `$GOPATH/bin` folders:

```sh
$ make dev
...
$ bin/vault
...
```

To compile a development version of Vault with the UI, run `make static-dist dev-ui`. This will
put the Vault binary in the `bin` and `$GOPATH/bin` folders:

```sh
$ make static-dist dev-ui
...
$ bin/vault
...
```

To run tests, type `make test`. Note: this requires Docker to be installed. If
this exits with exit status 0, then everything is working!

```sh
$ make test
...
```

If you&#039;re developing a specific package, you can run tests for just that
package by specifying the `TEST` variable. For example below, only
`vault` package tests will be run.

```sh
$ make test TEST=./vault
...
```

### Troubleshooting

If you encounter an error like `could not read Username for &#039;https://github.com&#039;` you may need to adjust your git config like so:

```sh
$ git config --global --add url.&quot;git@github.com:&quot;.insteadOf &quot;https://github.com/&quot;
```


### Importing Vault

This repository publishes two libraries that may be imported by other projects:
`github.com/hashicorp/vault/api` and `github.com/hashicorp/vault/sdk`.

Note that this repository also contains Vault (the product), and as with most Go
projects, Vault uses Go modules to manage its dependencies. The mechanism to do
that is the [go.mod](./go.mod) file. As it happens, the presence of that file
also makes it theoretically possible to import Vault as a dependency into other
projects. Some other projects have made a practice of doing so in order to take
advantage of testing tooling that was developed for testing Vault itself. This
is not, and has never been, a supported way to use the Vault project. We aren&#039;t 
likely to fix bugs relating to failure to import `github.com/hashicorp/vault` 
into your project.

See also the section &quot;Docker-based tests&quot; below.

### Acceptance Tests

Vault has comprehensive [acceptance tests](https://en.wikipedia.org/wiki/Acceptance_testing)
covering most of the features of the secret and auth methods.

If you&#039;re working on a feature of a secret or auth method and want to
verify it is functioning (and also hasn&#039;t broken anything else), we recommend
running the acceptance tests.

**Warning:** The acceptance tests create/destroy/modify *real resources*, which
may incur real costs in some cases. In the presence of a bug, it is technically
possible that broken backends could leave dangling data behind. Therefore,
please run the acceptance tests at your own risk. At the very least,
we recommend running them in their own private account for whatever backend
you&#039;re testing.

To run the acceptance tests, invoke `make testacc`:

```sh
$ make testacc TEST=./builtin/logical/consul
...
```

The `TEST` variable is required, and you should specify the folder where the
backend is. The `TESTARGS` variable is recommended to filter down to a specific
resource to test, since testing all of them at once can sometimes take a very
long time.

Acceptance tests typically require other environment variables to be set for
things such as access keys. The test itself should error early and tell
you what to set, so it is not documented here.

For more information on Vault Enterprise features, visit the [Vault Enterprise site](https://www.hashicorp.com/products/vault/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=github-vault-enterprise).

### Docker-based Tests

We have created an experimental new testing mechanism inspired by NewTestCluster.
An example of how to use it:

```go
import (
  &quot;testing&quot;
  &quot;github.com/hashicorp/vault/sdk/helper/testcluster/docker&quot;
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;docker.DockerClusterOptions{
    ImageRepo: &quot;hashicorp/vault&quot;, // or &quot;hashicorp/vault-enterprise&quot;
    ImageTag:    &quot;latest&quot;,
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
  
  client := cluster.Nodes()[0].APIClient()
  _, err := client.Logical().Read(&quot;sys/storage/raft/configuration&quot;)
  if err != nil {
    t.Fatal(err)
  }
}
```

Or for Enterprise:

```go
import (
  &quot;testing&quot;
  &quot;github.com/hashicorp/vault/sdk/helper/testcluster/docker&quot;
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;docker.DockerClusterOptions{
    ImageRepo: &quot;hashicorp/vault-enterprise&quot;,
    ImageTag:  &quot;latest&quot;,
	VaultLicense: licenseString, // not a path, the actual license bytes
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
```

Here is a more realistic example of how we use it in practice.  DefaultOptions uses 
`hashicorp/vault`:`latest` as the repo and tag, but it also looks at the environment
variable VAULT_BINARY. If populated, it will copy the local file referenced by
VAULT_BINARY into the container. This is useful when testing local changes.

Instead of setting the VaultLicense option, you can set the VAULT_LICENSE_CI environment
variable, which is better than committing a license to version control.

Optionally you can set COMMIT_SHA, which will be appended to the image name we
build as a debugging convenience.

```go
func Test_Custom_Build_With_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
```

There are a variety of helpers in the `github.com/hashicorp/vault/sdk/helper/testcluster`
package, e.g. these tests below will create a pair of 3-node clusters and link them using
PR or DR replication respectively, and fail if the replication state doesn&#039;t become healthy
before the passed context expires.

Again, as written, these depend on having a Vault Enterprise binary locally and the env
var VAULT_BINARY set to point to it, as well as having VAULT_LICENSE_CI set.

```go
func TestStandardPerfReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
      t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardPerfReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}

func TestStandardDRReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
    t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardDRReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}
```

Finally, here&#039;s an example of running an existing OSS docker test with a custom binary:

```bash
$ GOOS=linux make dev
$ VAULT_BINARY=$(pwd)/bin/vault go test -run &#039;TestRaft_Configuration_Docker&#039; ./vault/external_tests/raft/raft_binary
ok      github.com/hashicorp/vault/vault/external_tests/raft/raft_binary        20.960s
```
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[coreybutler/nvm-windows]]></title>
            <link>https://github.com/coreybutler/nvm-windows</link>
            <guid>https://github.com/coreybutler/nvm-windows</guid>
            <pubDate>Fri, 05 Sep 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[A node.js version management utility for Windows. Ironically written in Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/coreybutler/nvm-windows">coreybutler/nvm-windows</a></h1>
            <p>A node.js version management utility for Windows. Ironically written in Go.</p>
            <p>Language: Go</p>
            <p>Stars: 42,688</p>
            <p>Forks: 3,597</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;h2&gt;Notice: We are working full time work on &lt;a href=&quot;https://github.com/coreybutler/nvm-windows/wiki/Runtime&quot;&gt;Runtime&lt;/a&gt;, the successor to NVM for Windows.&lt;/h2&gt;Complete &lt;a href=&quot;https://t.co/oGqQCM9FPx&quot;&gt;this form&lt;/a&gt; to provide your thoughts and sign up for progress updates.&lt;br/&gt;&lt;br/&gt;Updates will also be posted on the &lt;A href=&quot;https://linkedin.com/company/authorsoftware&quot;&gt;Author Software LinkedIn Page&lt;/a&gt;.&lt;/div&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h1 align=&quot;center&quot;&gt;NVM for Windows&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;
  The &lt;a href=&quot;https://docs.microsoft.com/en-us/windows/nodejs/setup-on-windows&quot;&gt;Microsoft&lt;/a&gt;/&lt;a href=&quot;https://docs.npmjs.com/cli/v9/configuring-npm/install#windows-node-version-managers&quot;&gt;npm&lt;/a&gt;/&lt;a href=&quot;https://cloud.google.com/nodejs/docs/setup#installing_nvm&quot;&gt;Google&lt;/a&gt; recommended Node.js version manager for &lt;em&gt;Windows&lt;/em&gt;.&lt;br/&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;This is not the same thing as nvm!&lt;/b&gt; (expand for details)&lt;/summary&gt;

_The original [nvm](https://github.com/nvm-sh/nvm) is a completely separate project for Mac/Linux only._ This project uses an entirely different philosophy and is not just a clone of nvm. Details are listed in [Why another version manager?](#bulb-why-another-version-manager) and [what&amp;#39;s the big difference?](#bulb-whats-the-big-difference).
&lt;/details&gt;

[![Download Now](https://img.shields.io/badge/-Download%20Now!-%2322A6F2)](https://github.com/coreybutler/nvm-windows/releases) [![GitHub tag (latest SemVer)](https://img.shields.io/github/v/tag/coreybutler/nvm-windows?label=Latest%20Release&amp;style=social&amp;x=1)]((https://github.com/coreybutler/nvm-windows/releases)) ![GitHub Release Date](https://img.shields.io/github/release-date/coreybutler/nvm-windows?label=Released&amp;style=social) ![GitHub all releases](https://img.shields.io/github/downloads/coreybutler/nvm-windows/total?label=Downloads&amp;style=social) [![Discuss](https://img.shields.io/badge/-Discuss-blue)](https://github.com/coreybutler/nvm-windows/discussions) [![Twitter URL](https://img.shields.io/twitter/url?style=social&amp;url=https%3A%2F%2Ftwitter.com%2Fintent%2Ftweet%3Fhashtags%3Dnodejs%26original_referer%3Dhttp%253A%252F%252F127.0.0.1%253A91%252F%26text%3DCheck%2520out%2520NVM%2520for%2520Windows%21%26tw_p%3Dtweetbutton%26url%3Dhttp%253A%252F%252Fgithub.com%252Fcoreybutler%252Fnvm-windows%26via%3Dgoldglovecb)](https://twitter.com/intent/tweet?hashtags=nodejs&amp;original_referer=http%3A%2F%2F127.0.0.1%3A91%2F&amp;text=Check%20out%20NVM%20for%20Windows!&amp;tw_p=tweetbutton&amp;url=http%3A%2F%2Fgithub.com%2Fcoreybutler%2Fnvm-windows&amp;via=goldglovecb)
&lt;/div&gt;

&lt;h5 align=&quot;center&quot;&gt;Sponsors&lt;/h5&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;table cellpadding=&quot;5&quot; cellspacing=&quot;0&quot; border=&quot;0&quot; align=&quot;center&quot;&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://linkedin.com/company/authorsoftware&quot;&gt;&lt;img src=&quot;https://github.com/coreybutler/staticassets/blob/master/sponsors/logo_author_software_flat.png&quot; width=&quot;200px&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td width=&quot;33%&quot; align=&quot;center&quot;&gt;&lt;a href=&quot;https://ecorventures.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/8259581?s=200&amp;v=4&quot; height=&quot;30px&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td width=&quot;33%&quot; align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/770982/195955265-5c3dca78-7140-4ec6-b05a-f308518643ee.png&quot; height=&quot;30px&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td colspan=&quot;4&quot; align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://github.com/sponsors/coreybutler&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/sponsors/coreybutler?label=Individual%20Sponsors&amp;logo=github&amp;style=social&quot;/&gt;&lt;/a&gt;
        &amp;nbsp;&lt;a href=&quot;https://github.com/sponsors/coreybutler&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/-Become%20a%20Sponsor-yellow&quot;/&gt;&lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td colspan=&quot;4&quot; align=&quot;center&quot;&gt;
        &lt;img src=&quot;https://github.blog/wp-content/uploads/2020/09/github-stars-logo_Color.png&quot; width=&quot;50&quot;/&gt;&lt;br/&gt;
        &lt;b&gt;Can&#039;t sponsor?&lt;/b&gt;&lt;br/&gt;Consider &lt;a href=&quot;https://stars.github.com/nominate/&quot; target=&quot;_blank&quot;&gt;nominating @coreybutler for a Github star&lt;/a&gt;.
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;
&lt;br/&gt;

&lt;div align=&quot;center&quot;&gt;&lt;b&gt;Running into issues?&lt;/b&gt; See the &lt;a href=&quot;https://github.com/coreybutler/nvm-windows/wiki/Common-Issues&quot;&gt;common issues wiki&lt;/a&gt;.&lt;/div&gt;

&lt;br/&gt;
&lt;table style=&quot;background-color:red;padding:6px;border-radius:3px;&quot;&gt;
  &lt;tr&gt;&lt;td&gt;
    &lt;h3&gt;Seeking Feedback:&lt;/h3&gt;
    We&#039;re working on &lt;a href=&quot;https://github.com/coreybutler/nvm-windows/wiki/Runtime&quot;&gt;Runtime (rt)&lt;/a&gt;, the successor to NVM For Windows. Please contribute by taking a minute to complete &lt;a href=&quot;https://t.co/oGqQCM9FPx&quot;&gt;this form&lt;/a&gt;. Thank you!
    &lt;h3&gt;&lt;/h3&gt;
  &lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

## Overview

Manage multiple installations of node.js on a Windows computer.

**tl;dr** Similar (not identical) to [nvm](https://github.com/creationix/nvm), but for Windows. Has an installer. [Download Now](https://github.com/coreybutler/nvm-windows/releases)!

This has always been a node version manager, not an io.js manager, so there is no back-support for io.js. Node 4+ is supported. Remember when running `nvm install` or `nvm use`, Windows usually requires administrative rights (to create symlinks). To install the latest version of Node.js, run `nvm install latest`. To install the latest stable version, run `nvm install lts`.

![NVM for Windows](https://github.com/coreybutler/staticassets/raw/master/images/nvm-1.1.8-screenshot.jpg)

There are situations where the ability to switch between different versions of Node.js can be very useful. For example, if you want to test a module you&#039;re developing with the latest bleeding edge version without uninstalling the stable version of node, this utility can help.

![Switch between stable and unstable versions.](https://github.com/coreybutler/staticassets/raw/master/images/nvm-usage-highlighted.jpg)

### Installation &amp; Upgrades

#### :star: :star: Uninstall any pre-existing Node installations!! :star: :star:

The simplest (recommended) way to get NVM for Windows running properly is to uninstall any prior Node installation _before_ installing NVM for Windows. It avoids all of the pitfalls listed below. However; you may not wish to nuke your Node installation if you&#039;ve highly customized it. NVM for Windows _can_ assume management of an existing installation, but there are nuances to this (dependent entirely on the permissions of the user running the installation). If you have an administrative account, it&#039;s relatively safe to install NVM for Windows before uninstalling the original Node version. If you are working in a closed environment, such as a corporate Active Directory environment where installations/uninstallations are controlled by group policy, you should really consider removing the original version of Node before installing NVM4W.

_Permission Problems_
For security reasons, Windows will not allow an application from one vendor to &quot;uninstall&quot; an application from a different vendor. The official NVM4W installer will attempt assume management of an existing installation of Node., but it cannot actually uninstall the original Node.js version. To work around this, NVM for Windows installer attempts to copy the original Node.js installation files to the NVM root. This includes global npm modules and configurations. Once this process is complete, the original Node.js installation can be uninstalled without losing data.

_PATH Installation Problems_
If you attempt to configure the `NVM_SYMLINK` to use an existing directory (like `C:\Program Files\nodejs`), it will fail because a symlink cannot overwrite a physical directory. This is not a problem if you choose a different symlink path (such as `C:\nvm\node`).

_PATH Conflicts_
If you do not uninstall the original version, running `nvm use` may appear to do nothing at all. Running `node -v` will always show the original installation version. This is due to a [`PATH` conflict](https://github.com/coreybutler/nvm-windows/wiki/Common-Issues#why-do-i-need-to-uninstall-nodejs-before-installing-nvm-for-windows) that presents when the same application is installed multiple times. In NVM4W 1.1.11+, run `nvm debug` to determine if you have a `PATH` conflict.

For simpliciy, we recommend uninstalling any existing versions of Node.js before using NVM for Windows. Delete any existing Node.js installation directories (e.g., `%ProgramFiles%\nodejs`) that might remain. NVM&#039;s generated symlink will not overwrite an existing (even empty) installation directory.

:eyes: **Backup any global `npmrc` config** :eyes:
(e.g. `%AppData%\npm\etc\npmrc`)

Alternatively, copy the settings to the user config `%UserProfile%\.npmrc`. Delete the existing npm install location (e.g. `%AppData%\npm`) to prevent global module conflicts.

#### Install nvm-windows

Use the [latest installer](https://github.com/coreybutler/nvm/releases) (comes with an uninstaller). Alternatively, follow the  [manual installation](https://github.com/coreybutler/nvm-windows/wiki#manual-installation) guide.

_If NVM4W doesn&#039;t appear to work immediately after installation, restart the terminal/powershell (not the whole computer)._

![NVM for Windows Installer](https://github.com/coreybutler/staticassets/raw/master/images/nvm-installer.jpg)

#### Reinstall any global utilities

After install, reinstalling global utilities (e.g. yarn) will have to be done for each installed version of node:

```
nvm use 14.0.0
npm install -g yarn
nvm use 12.0.1
npm install -g yarn
```

### Upgrading nvm-windows

:bulb: _As of v1.1.8, there is an upgrade utility that will automate the upgrade process._

**To upgrade nvm-windows**, run the new installer. It will safely overwrite the files it needs to update without touching your node.js installations. Make sure you use the same installation and symlink folder. If you originally installed to the default locations, you just need to click &quot;next&quot; on each window until it finishes.

### Usage

**nvm-windows runs in an Admin shell**. You&#039;ll need to start `powershell` or Command Prompt as Administrator to use nvm-windows

NVM for Windows is a command line tool. Simply type `nvm` in the console for help. The basic commands are:

- **`nvm arch [32|64]`**: Show if node is running in 32 or 64 bit mode. Specify 32 or 64 to override the default architecture.
- **`nvm debug`**: Check the NVM4W process for known problems.
- **`nvm current`**: Display active version.
- **`nvm install &lt;version&gt; [arch]`**:  The version can be a specific version, &quot;latest&quot; for the latest current version, or &quot;lts&quot; for the most recent LTS version. Optionally specify whether to install the 32 or 64 bit version (defaults to system arch). Set [arch] to &quot;all&quot; to install 32 AND 64 bit versions. Add `--insecure` to the end of this command to bypass SSL validation of the remote download server.
- **`nvm list [available]`**: List the node.js installations. Type `available` at the end to show a list of versions available for download.
- **`nvm on`**: Enable node.js version management.
- **`nvm off`**: Disable node.js version management (does not uninstall anything).
- **`nvm proxy [url]`**: Set a proxy to use for downloads. Leave `[url]` blank to see the current proxy. Set `[url]` to &quot;none&quot; to remove the proxy.
- **`nvm uninstall &lt;version&gt;`**: Uninstall a specific version.
- **`nvm use &lt;version&gt; [arch]`**: Switch to use the specified version. Optionally use `latest`, `lts`, or `newest`. `newest` is the latest _installed_ version. Optionally specify 32/64bit architecture. `nvm use &lt;arch&gt;` will continue using the selected version, but switch to 32/64 bit mode. For information about using `use` in a specific directory (or using `.nvmrc`), please refer to [issue #16](https://github.com/coreybutler/nvm-windows/issues/16).
- **`nvm root &lt;path&gt;`**: Set the directory where nvm should store different versions of node.js. If `&lt;path&gt;` is not set, the current root will be displayed.
- **`nvm version`**: Displays the current running version of NVM for Windows.
- **`nvm node_mirror &lt;node_mirror_url&gt;`**: Set the node mirror.People in China can use *https://npmmirror.com/mirrors/node/*
- **`nvm npm_mirror &lt;npm_mirror_url&gt;`**: Set the npm mirror.People in China can use *https://npmmirror.com/mirrors/npm/*

### :warning: Gotcha!

Please note that any global npm modules you may have installed are **not** shared between the various versions of node.js you have installed. Additionally, some npm modules may not be supported in the version of node you&#039;re using, so be aware of your environment as you work.

### :name_badge: Antivirus

Users have reported some problems using antivirus, specifically McAfee. It appears the antivirus software is manipulating access to the VBScript engine. See [issue #133](https://github.com/coreybutler/nvm-windows/issues/133) for details and resolution.

**v1.1.8 is not code signed**, but all other versions are signed by [Ecor Ventures LLC](https://ecorventures.com)/[Author.io](https://author.io). This should help prevent false positives with most antivirus software.

&gt; v1.1.8+ was not code signed due to an expired certificate (see the [release notes](https://github.com/coreybutler/nvm-windows/releases/tag/1.1.8) for reasons). **v1.1.9 _is_ code signed** thanks to [ajyong](https://github.com/ajyong), who sponsored the new certificate.

### Using Yarn

**tldr;** `npm i -g yarn`

See the [wiki](https://github.com/coreybutler/nvm-windows/wiki/Common-Issues#how-do-i-use-yarn-with-nvm-windows) for details.

### Build from source

- Install go from http://golang.org
- Download source / Git Clone the repo
- Change GOARCH to amd64 in build.bat if you feel like building a 64-bit executable
- Fire up a Windows command prompt and change directory to project dir
- Execute `go get github.com/blang/semver`
- Execute `go get github.com/olekukonko/tablewriter`
- Execute `build.bat`
- Check the `dist`directory for generated setup program.

---

## :bulb: Why another version manager?

There are several version managers for node.js. Tools like [nvm](https://github.com/creationix/nvm) and [n](https://github.com/tj/n)
only run on Mac OSX and Linux. Windows users are left in the cold? No. [nvmw](https://github.com/hakobera/nvmw) and [nodist](https://github.com/marcelklehr/nodist)
are both designed for Windows. So, why another version manager for Windows?

The architecture of most node version managers for Windows rely on `.bat` files, which do some clever tricks to set or mimic environment variables. Some of them use node itself (once it&#039;s downloaded), which is admirable, but prone to problems. Right around node 0.10.30, the installation structure changed a little, causing some of these to just stop working with anything new.

Additionally, some users struggle to install these modules since it requires a little more knowledge of node&#039;s installation structure. I believe if it were easier for people to switch between versions, people might take the time to test their code on back and future versions... which is just good practice.

## :bulb: What&#039;s the big difference?

First and foremost, this version of nvm has no dependency on node. It&#039;s written in [Go](https://golang.org/), which is a much more structured approach than hacking around a limited `.bat` file. It does not rely on having an existing node installation. Go offers the ability to create a Mac/Linux version on the same code base. In fact, this is already underway.

The control mechanism is also quite different. There are two general ways to support multiple node installations with hot switching capabilities. The first is to modify the system `PATH` any time you switch versions, or bypass it by using a `.bat` file to mimic the node executable and redirect accordingly. This always seemed a little hackish to me, and there are some quirks as a result of this implementation.

The second option is to use a symlink. This concept requires putting the symlink in the system `PATH`, then updating its target to the node installation directory you want to use. This is a straightforward approach, and seems to be what people recommend.... until they realize just how much of a pain symlinks are on Windows. This is why it hasn&#039;t happened before.

In order to create/modify a symlink, you must be running as an admin, and you must get around Windows UAC (that annoying prompt). Luckily, this is a challenge I already solved with some helper scripts in [node-windows](https://github.com/coreybutler/node-windows). As a result, NVM for Windows maintains a single symlink that is put in the system `PATH` during installation only. Switching to different versions of node is a matter of switching the symlink target. As a result, this utility does **not** require you to run `nvm use x.x.x` every time you open a console window. When you _do_ run `nvm use x.x.x`, the active version of node is automatically updated across all open console windows. It also persists between system reboots, so you only need to use nvm when you want to make a change.

NVM for Windows comes with an installer, courtesy of a byproduct of my work on [Fenix Web Server](https://preview.fenixwebserver.com).

Overall, this project brings together some ideas, a few battle-hardened pieces of other modules, and support for newer versions of node.

NVM for Windows recognizes the &quot;latest&quot; versions using a [list](https://nodejs.org/download/release/index.json) provided by the Node project. Version 1.1.1+ use this list. Before this list existed, I was scraping releases and serving it as a standalone [data feed](https://github.com/coreybutler/nodedistro). This list was used in versions 1.1.0 and prior, but is now deprecated.

## Motivation

I needed it, plain and simple. Additionally, it&#039;s apparent that [support for multiple versions](https://github.com/nodejs/node-v0.x-archive/issues/8075) is not coming to node core. It was also an excuse to play with Go.

## Why Go? Why not Node?

I chose Go because it is cross-platform, felt like less overhead than Java, has been around longer than most people think. Plus, I wanted to experiment with it. I&#039;ve been asked why I didn&#039;t write it with Node. Trying to write a tool with the tool you&#039;re trying to install doesn&#039;t make sense to me. As a result, my project requirements for this were simple... something that&#039;s not Node. Node will continue to evolve and change. If you need a reminder of that, remember io.js, Ayo, all the breaking changes between 4.x.x and 6.x.x, and the shift to ES Modules in 12+. Change is inevitable in the world of software. JavaScript is extremely dynamic.

## :pray: Thanks

Thanks to everyone who has submitted issues on and off Github, made suggestions, and generally helped make this a better project. Special thanks to

- [@vkbansal](https://github.com/vkbansal), who provided significant early feedback throughout the early releases.
- [@rainabba](https://github.com/rainabba) and [@sullivanpt](https://github.com/sullivanpt) for getting Node v4 support integrated.
- [@s-h-a-d-o-w](https://github.com/s-h-a-d-o-w) who resolved the longstanding space escaping issue in path names ([#355](https://github.com/coreybutler/nvm-windows/pull/355)).
- [ajyong](https://github.com/ajyong) who sponsored the code signing certificate in late 2021.

&lt;br/&gt;

![Contributors](https://contrib.rocks/image?repo=coreybutler/nvm-windows)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>